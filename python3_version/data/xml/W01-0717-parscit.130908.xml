<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.996882">
Coreference Resolution with
Syntactico-Semantic Rules and Corpus Statistics
</title>
<author confidence="0.993322">
Sven Hartrumpf
</author>
<affiliation confidence="0.977025">
Applied Computer Science VII
University of Hagen
</affiliation>
<address confidence="0.660598">
58084 Hagen, Germany
</address>
<email confidence="0.557137">
Sven.Hartrumpf©ifernuni-hagen.de
</email>
<sectionHeader confidence="0.930882" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999699166666666">
A new hybrid approach to the coreference res-
olution problem is presented. The COR,UDIS
system (COreference R,Ules with Disambigua-
tion Statistics) combines syntactico-semantic
rules with statistics derived from an annotated
corpus. First, the rules and corpus annotations
are described and exemplified. Then, the coref-
erence resolution algorithm and the involved
statistics are explained. Finally, the proposed
method is evaluated against a baseline model
and some directions for further research are in-
dicated.
</bodyText>
<sectionHeader confidence="0.996288" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999671222222222">
Coreference resolution is a central problem in
natural language understanding since corefer-
ence links play an important role for text coher-
ence.&apos; In sentence (1) for instance, one wants to
know what the German personal pronouns sic
and ihr refer to. Both can refer to Madchen or
Zeitung because grammatical gender agreement
in German can be overruled by natural gender
agreement in certain cases.
</bodyText>
<listItem confidence="0.558296">
(1) [Das Mddehenji hest [die
</listItem>
<bodyText confidence="0.971325133333333">
The girl+NEUT reads the
Zeitungli; danach geht
newspaper+FEM; afterwards goes
sie mit ihTi fins
she+FEM with her+FEM in the
Bitralk.
office.
&apos;The girl reads the newspaper; afterwards
she goes to the office with it.&apos;
11 would like to thank Hermann Helbig, Rainer Oss-
wald, and the anonymous reviewers for their helpful com-
ments and suggestions.
The task in this paper is similar to the
MUC coreference task (Hirschman and Chin-
chor, 1997)2:
</bodyText>
<listItem confidence="0.6759418">
• only identity coreference is treated (and
not part-whole or other complex semantic
relationships);
• only noun phrases (NPs) are considered as
markables for coreference (and not situa-
</listItem>
<bodyText confidence="0.99171025">
tions expressed by clauses etc.).
This kind of coreference is an equivalence rela-
tion so that coreference resolution comes down
to finding the correct partition3 of markables.
If there exists a genuine ambiguity for human
readers (and not just a spurious one for com-
puters), several partitions of markables would
be the correct answer to the coreference prob-
lem. But since such ambiguities are rare the
disambiguation method described in this paper
always delivers only one partition.
In this paper, the full MUC coreference task
is tackled with a new hybrid approach combin-
ing syntactico-semantic rules with rule statistics
derived from an annotated corpus. Two ques-
tion might arise. Why not a purely statistical
approach: first, because why throw away tradi-
tional linguistic knowledge, and second, because
statistics on rules reduce the sparse data prob-
lem since the applicability of one rule classifies
combinations of many relevant features into one
feature value. Why not a purely rule-based ap-
proach: because it would leave too many alter-
natives and would not indicate which to choose.
</bodyText>
<footnote confidence="0.71664275">
2Some problems of this task definition are discussed
by van Deemter and Kibble (2000).
3A partition of a set S is a set of pairwise disjoint
subsets of S (the partition elements) that cover S.
</footnote>
<sectionHeader confidence="0.766135" genericHeader="introduction">
2 Data
</sectionHeader>
<bodyText confidence="0.9974605">
Two kinds of data are required for the corefer-
ence resolution method described in section 3:
hand-crafted rules defining whether two mark-
ables can corefer or not and a corpus annotated
with coreference information. The rules license
possible coreferences; the corpus is used for scor-
ing alternative coreference partitions with esti-
mated probabilities.
</bodyText>
<subsectionHeader confidence="0.985399">
2.1 Coreference rules
</subsectionHeader>
<bodyText confidence="0.999784592592592">
The coreference rules are designed to license
possible coreference relations among two mark-
ables. Some rules are language-dependent, some
are universal; in this paper, the rules (and the
corpus) are for German, but the approach suits
other languages as well. Each rule consists of
a unique name, a premise, and a conclusion.
For development and maintenance reasons, a
rule is accompanied by a description, some pos-
itive example texts, and some negative example
texts. A positive example shows that the rule
premise is satisfied and the conclusion that the
two markables at hand are coreferential would
be correct, whereas a negative example shows
that the rule premise is not satisfied and the
conclusion would indeed be incorrect for the ex-
ample.
The rule premise is a conjunction of (possibly
negated) constraints; these can be constituent
constraints (c-constraints) referring to feature
values of one markable and interconstituent con-
straints (ic-constraints) referring to feature
values of both markables that are to be tested
for coreference. Both types of constraints can
be attribute-value equations. The features used
in coreference rules are listed in Table 1; the
feature values for markables stem from a parser
using a semantically oriented lexicon currently
containing 14000 German lexemes (HaGenLex).
A feature value can be a single type or a disjunc-
tion of types. Furthermore, one can construct
constraints with predicates. The most impor-
tant predicates are given in Table 2: they re-
alize concepts from Dependency Grammar (de-
pend/2) and Government and Binding Theory
(c-command/2) or define simple relationships
between constituents (e. g. compatible-gend-n-
gend/2).
The conclusion of a rule expresses a corefer-
ence relation with a semantic network (based
on the MultiNet formalism defined by Hel-
big (2001) which has been applied in several
other projects, see (Hartrumpf, 1999; Knoll et
al., 1998)). For identity coreference, a rela-
tion named EQU (equivalence) leading from the
anaphor (called c2 in rules)4 to the antecedent
(called c1 in rules) suffices.
Seven rules from the eighteen rules cur-
rently used are given in Figure 1. The rule
ident.gend_conflict would license a link between
das Mddchen and sic in sentence (1). The
premise and conclusion can also be viewed as
one attribute value matrix employing structure
sharing for expressing ic-constraints.
</bodyText>
<subsectionHeader confidence="0.994874">
2.2 Annotated corpus
</subsectionHeader>
<bodyText confidence="0.99773625">
A corpus (a collection of German newspaper ar-
ticles from the Sitddeutsche Zeitung) is anno-
tated for coreference according to the guidelines
for the MUC coreference task adapted from En-
glish to German. The annotations are inserted
as SGML tags into the corpus, which is already
marked up according to the Corpus Encoding
Standard (Ide et al., 1996). The annotation for
</bodyText>
<equation confidence="0.877321272727273">
sentence (1) is given as (2):
(2) (s) (coref id=&amp;quot; 125t129&amp;quot; Kw) Das ( / w)
(w)Madchen( /w) ( /coref) Kw) liest (/w)
(coref id=&amp;quot; 143t147&amp;quot; Kw) die ( /w)
(w)Zeitung( /w) ( / coref) Kw); (/w)
(w)danachK/w) (w)gehtK/w) (coref
ref=&amp;quot; 125t129&amp;quot;
type=&amp;quot; ident&amp;quot; Kw) sie( /w) ( /coref)
(w)mit ( /w) (coref ref=&amp;quot; 143t147&amp;quot;
type=&amp;quot; ident&amp;quot; Kw) ihr ( /w) ( /coref)
(w)insK/w) (w)BilroK/w) (w).K/w)(/s)
</equation>
<sectionHeader confidence="0.961017" genericHeader="method">
3 Coreference resolution
</sectionHeader>
<subsectionHeader confidence="0.999549">
3.1 Algorithm overview
</subsectionHeader>
<bodyText confidence="0.908729">
To resolve coreference ambiguities, one must
find the partition of markables that corresponds
to the correct coreference equivalence relation.
The search space is huge since the number of
different partitions for n markables is equal to
the Bell number B(n). These numbers are also
called Exponential numbers, see (Bell, 1934);
some example values are: B(1) = 1, B(2) = 2,
B(3) = 5, B(4) = 15, B(5) = 52, B(10) =
</bodyText>
<footnote confidence="0.689041333333333">
4R.ules for cataphora are also among the coreference
rules. In such rules, cl corresponds to the cataphor and
c2 to the postcedent.
</footnote>
<bodyText confidence="0.998153222222222">
feature name use* description
CAT syntactic category en (noun), perspro (personal pronoun), possdet (pos-
sessive determiner), reflpro (reflexive pronoun), etc.)
ENTITY ic semantic classification comprising the semantic sort (feature SORT) and
semantic Boolean features (currently 16, all defined for the MultiNet (mul-
tilayered extended semantic network) formalism by Helbig (2001))
ETYPE ic extension type (0 (an individual), 1 (a set), 2 (a set of sets), etc.), part
of the complex feature LAY containing other extensional and intensional
layer features like CARD (cardinality)
</bodyText>
<equation confidence="0.746236333333333">
GEND ic gender (syntactic; masculine, feminine, and neuter in German)
NUM c, ic number (syntactic; singular and plural in German)
PERS c, ic person (only tested jointly with the other agreement features GEND and
NUM)
PROPER proper noun (Boolean feature)
REFER c, ic reference type (determinate, indeterminate; based on article choice)
SENTENCE-ID ic sentence number in text
SORT semantic sort (45 hierarchically ordered values, 15 of them for nominal
concepts)
</equation>
<tableCaption confidence="0.7857735">
*c means: feature is used in c-constraints; ic means: feature is used in ic-constraints.
Table 1: Features in coreference rules
</tableCaption>
<bodyText confidence="0.605093">
predicate name/arity description
</bodyText>
<equation confidence="0.534749333333333">
=/2
c-command/2
compatible-gend-n-gend/2
</equation>
<bodyText confidence="0.996046529411765">
The values are unifiable.
The first argument (a constituent) c-commands the second.
The grammatical gender value at the first argument position is com-
patible with the natural gender value at the second argument posi-
tion.
The first argument (a possessive determiner) can refer to the second
argument (a constituent).
The arguments (two constituents) are related by a copula.
The first argument (a constituent) depends on the second.
Numerical difference between two feature values is greater than a
third value.
Two constituents containing (possibly complex) names match.
The argument (a feature value) is maximal, i. e., a leaf node in the
type hierarchy.
One argument (a constituent) is a compound suffix of the other
argument (a constituent) or both arguments have the same nominal
head.
</bodyText>
<equation confidence="0.948807857142857">
compatible-possdet/2
copula-related/2
depend/2
difference&gt;/3
matching-names/2
maximal/1
similar-nouns/2
</equation>
<tableCaption confidence="0.848521">
Table 2: Predicates in coreference rules
</tableCaption>
<bodyText confidence="0.959352166666667">
115975, B(15) 1.38x 109, B(20) 5.17x 1013,
B(25) 4.64 x 1018.
The evaluated algorithm for coreference res-
olution is implemented as the COR,UDIS sys-
tem (COreference R,Ules with Disambiguation
Statistics) and works as follows:
1. The markables in a given text are iden-
tified. For this task and for gaining the
syntactico-semantic feature values to be ac-
cessed by rules in step 2, each sentence in
the text is parsed independently. If a sen-
tence parse fails, a chunk parse is gener-
</bodyText>
<equation confidence="0.939804208333333">
desc.
exam.
id ident.n_perspro
pre. (el CAT) n
(e2 cm) perspro
(= (el Num) (e2 NUM))
(= (C1 PERS) (C2 PERS))
(= (C1 GEND) (C2 GEND))
(= (C1 ENTITY) (C2 ENTITY))
(not (c-command el e2))
(not (c-command (2 el))
desc. same gender - anaphoric
exam. Per Mann liest [das Buch]i lir versteht [es] nicht.
id ident.perspro_n
pre. (Ci CAT) perspro
(e2 eAT) n
(= (el Num) (e2 NUM))
(= (C1 PERS) (C2 PERS))
(= (C1 GEND) (C2 GEND))
(= (C1 ENTITY) (C2 ENTITY))
(not (c-command cl c2))
(not (c-command c2 Ci))
(difference&gt; (C1 SENTENCETD) (C2 SENTENCE-ID) 0)
desc. personal pronoun - cataphoric
</equation>
<bodyText confidence="0.69321925">
exam. [Sie]i will die Welt andern; und Mie Wissenschaftlerin]i
macht sich frisch ans Werk.
id ident.perspro_perspro
pre. (Ci CAT) perspro
</bodyText>
<equation confidence="0.975593944444445">
(C2 CAT) perspro
(= (el Num) (e2 NUM))
(= (Cl PERS) (C2 PERS))
(= (C1 GEND) (C2 GEND))
(= (C1 ENTITY) (C2 ENTITY))
(not (c-command cl c2))
(not (c-command c2 Ci))
desc. same gender - anaphoric
exam. [Sie]i schreiben viel. Und [sie] lesen viel.
id ident.gend_conflict
pre. (Ci CAT) n
(c2 CAT) perspro
(= (el Num) (e2 NUM))
(= (C1 PERS) (C2 PERS))
(not (= (C1 GEND) (C2 GEND)))
(compatible-gencl-n-gencl (C2 GEND) (C1 N-GEND))
(not (c-command cl c2))
(not (c-command c2 Ci))
</equation>
<bodyText confidence="0.854466333333333">
desc. A personal pronoun refers to an NY with a nominal head
and conflicting grammatical gender.
exam. [Das Madchen]i lacht. [Sie]i war stets so.
</bodyText>
<table confidence="0.917321363636363">
ident.nuna_conflict
(el CAT) n
(Cl PROPER) noproper
(C2 CAT) n
(e2 PROPER) noproper
(not (= (el Nem) (e2 Nem)))
(= (C1 =TYE) (C2 ETYPE))
(= (C1 ENTITY) (C2 ENTITY))
(not (c-command el e2))
(not (c-command C2 el))
different number values (one aggregate and one nonaggre-
gate but equal etype values)
Per Vorstand]i entschied riber die Entlassungen. [these
Manner ]i hatten keine Skrupel.
ident.sinailar_sem
(Ci CAT) n
(Ci soul]) co
(c2 CAT) n
(c2 Ithrhit) det
(e2 PROPER) noproper
(= (el Num) (e2 Nutt))
(similar-nouns cl c2)
(difference&gt; (C1 SENTENCE-ID) (C2 SENTENCE-ID) 0)
two semantically similar NPs. Cases contained in similar-
nouns: compound and base noun; synonyms.
Mer Buchautor]i ... [der Autor]i
Mie Grol3stadte]i Mie Stadte]i
[Krankenhaus]i [Klinik]i
ident.compatible_sem
(Ci CAT) n
(Ci soul]) co
(C1 PROPER) noproper
(e2 CAT) n
(e2 Ithrhit) det
(e2 PROPER) noproper
(= (el NUM) (C2 NUM))
(= (C1 =TYE) (C2 ETYPE))
(= (C1 ENTITY) (C2 ENTITY))
(not (similar-nouns cl c2))
(maximal (C1 ENTITY))
(maximal (c2 ENTITY))
(difference&gt; (C1 SENTENCE-ID) (C2 SENTENCE-ID) 0)
two semantically compatible NPs.
Mie Tater] Mie Manner] i
</table>
<figure confidence="0.93555175">
[einer hollandischen Fanailie]i [die entfiihrte
Deutsche]j
id
pre.
desc.
exam.
id
pre.
desc.
exam.
id
pre.
</figure>
<figureCaption confidence="0.999995">
Figure 1: Example coreference rules
</figureCaption>
<bodyText confidence="0.998138">
ated. (In such cases, constraints in rule
premises that involve predicates requiring
full parses (e. g. c-command) are ignored in
step 2.) For details on the parser, see (Hel-
big and Hartrumpf, 1997).
</bodyText>
<listItem confidence="0.993701538461538">
2. All possible coreference rule activations
that link an anaphor to an antecedent can-
didate are collected. This is done by test-
ing rule premises on all markable pairs
(constituent c1 must precede constituent
c2). For two markables, one rule (at most)
is activated since the rules have disjoint
premises for real text purposes.
3. For each anaphor, one antecedent candi-
date is selected. This decision is based on
rule statistics gained from the annotated
training corpus. The sparse data prob-
lem is alleviated by backed-off estimation
</listItem>
<bodyText confidence="0.998994523809524">
(see for example (Katz, 1987; Collins and
Brooks, 1995)).
The algorithm deals with three sets of ob-
jects: first, the possible anaphors (all identified
markables); second, the candidate antecedents
for each possible anaphor (all preceding mark-
ables and the artificial nonreferable mark-
able explained below); third, the coreference
rules. The nonreferable markable is used as
the artificial anaphor of a nonreferring mark-
able in order to represent all alternative refer-
ences for a possible anaphor as a pair. For first-
mentions, the disambiguation algorithm should
select a coreference with the nonreferable mark-
able as antecedent. Currently, one rule licenses
the nonreferable markable as antecedent. But
it might be useful to apply more finely grained
rules and not just one rough licensing rule, as
indicated by promising research results for def-
inite descriptions referring to discourse-new en-
tities (see (Vieira and Poesio, 2000)).
</bodyText>
<subsectionHeader confidence="0.9870605">
3.2 Disambiguating between
antecedent candidates
</subsectionHeader>
<bodyText confidence="0.994332207792208">
Step 3 of the algorithm given in section 3.1 is
the most interesting one and needs some expla-
nation. Leaving the issue of search algorithms
aside for a moment, all possible and licensed
partitions of identified markables are generated,
filtered, and finally scored using estimated prob-
abilities.
The partitions are generated incrementally
starting with the first possible anaphor in a sin-
gleton partition element. For each antecedent
candidate licensed by a coreference rule in
step 2, an extended partition with this an-
tecedent in the same partition element as the
anaphor in question is introduced. This process
is iterated until all possible anaphors have been
investigated.
Partitions are filtered out if they violate one
of the following distance and compatibility
constraints:
sentence distance The distance between the
anaphor and the antecedent measured in
sentences must be below the limit for the
linking coreference rule. These limits have
been learned from the training corpus.
paragraph distance The distance between
the linked markables measured in para-
graphs must be below the limit learned for
the licensing coreference rule. Typically,
pronominal anaphoras can span only two
paragraphs, while for example coreferences
between named entities can span arbitrary
distances.
semantic compatibility All markables in a
partition element must bear compatible se-
mantics (unifiable ENTITY and LAY feature
values, see Table 1).
Because of the huge search space (see sec-
tion 3.1), the generation of partitions and the
filtering is intertwined in a heuristic search al-
gorithm so that impossible alternatives in the
search tree are pruned early. Also the scor-
ing described below is done during the search
so that alternatives with low (bad) scores can
be delayed and possibly discarded early by the
search algorithm.
The score for a partition is constructed as
the sum of estimated probabilities for adding
the possible anaphor in currently under inves-
tigation to one of the antecedent candidates
C = Kei, e2, , ek). The candidates are ordered
by distance; each ci is a feature structure rep-
resenting the parse result from algorithm step 1
for the corresponding markable. Each corefer-
ence between in and ci is licensed by a corefer-
ence rule ri so that this coreference alterna-
tive can be represented as the triple (m,
In order to generalize from the token-based
representation (rn, ci,ri) and to make useful
statistics from an annotated corpus, an ab-
straction function a is applied that abstracts
from the given anaphor, antecedent candidate,
and linking coreference rule to a type-based
representation. The abstraction function in
equation (3) turned out to be a good compro-
mise between limited sparseness of statistical
matrices and distinctiveness for disambiguation
purposes: It reduces a coreference alternative
(m, ci,ri) to the candidate antecedent position
i and the licensing coreference rule
a(m, ci, ri) := (i,ri) (3)
Let ai be the abstracted coreference
alternative a(m, c, ri) and A be the list
(al, a2, , ak) of abstracted coreference alter-
natives for the possible anaphor in. Then, the
probability that ai corresponds to the closest
correct antecedent for in is estimated as the rel-
ative frequency rf (i, A):
</bodyText>
<equation confidence="0.697637">
rf (i, A) := kf (i, A) (4)
f (1, A)
1=1
</equation>
<bodyText confidence="0.994249032258064">
The equation uses the statistical values f (i, A),
which count how many times in the annotated
training corpus the abstracted coreference alter-
native ai wins as the one with the closest correct
antecedent in the context of abstracted corefer-
ence alternatives A.
Further experiments have shown that looking
at more than 5 antecedent candidates does not
improve disambiguation results. Therefore, k is
reduced to 5 if necessary.
Backed-off estimation can alleviate sparse
data problems. The basic idea is that if for a
context A no statistical values are known, they
are estimated by looking at increasingly smaller
parts of A until statistical values are found. One
might call such a backed-off estimation backed-
off estimation over alternatives. Backed-off
estimation as defined by equations (5) to (7)
is applied in the coreference resolution method
when all counts f (i, A) are zero and f3 (i, A) is
calculated for j = 1.
The parameter j is increased by one until one
of the f3 (i, A) becomes positive (then, the
rP (i, A) are used as scores for the antecedent
candidates) or j reaches k — 1 (in this case, all
candidates receive equal scores). If the back-
off process stops at j = b, the relative frequen-
cies rfb(i, A) are used as estimates for the con-
ditional probabilities P(i1C) that ci is the closest
correct antecedent given antecedent candidates
C:
</bodyText>
<equation confidence="0.996045">
P(ir) rfb (i, A) (8)
</equation>
<bodyText confidence="0.999964636363637">
One could add other scores to those based
on estimated probabilities. In the literature,
syntactic parallelism between anaphor and an-
tecedent (based on syntactic case), semantic
parallelism (based on semantic roles), and max-
imality of antecedent NPs are proposed among
others. In several experiments, such additional
scores have been applied for certain rules (e. g.
rules involving pronouns). Small improvements
have been achieved, but this topic has not been
investigated completely yet.
</bodyText>
<sectionHeader confidence="0.984086" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.99963925">
Evaluation results from 12-fold cross-validation
for 502 anaphors5 are listed in Table 3. The
standard definitions for recall and precision used
in information retrieval are as follows:
</bodyText>
<figure confidence="0.9695558">
#true positives
true positives ± #false negatives
#true positives
(10)
true positives ± #false positives
</figure>
<bodyText confidence="0.999772272727273">
For coreference resolution, true positives are
correct coreference links found, false negatives
are correct coreference links not reported, and
false positives are incorrect coreference links re-
ported. Vilain et al. (1995) illustrate that these
definitions sometimes yield counter-intuitive re-
sults for coreference evaluations and propose
model-theoretic definitions of recall and preci-
sion. The values in Table 3 are calculated with
these modified definitions.
There are three different evaluation results.
The first is the full coreference task. The second
one could be called markable-relative evalu-
ation since the numbers are calculated only for
the markables that have been successfully iden-
tified (in some sense, this concentrates on the
coreference relation aspect of the coreference
task). And the final evaluation result comes
from a baseline model: &amp;quot;always select the clos-
est antecedent candidate that is licensed by a
rule and fulfills the distance and compatibility
constraints from section 3.2&amp;quot;.
</bodyText>
<sectionHeader confidence="0.999498" genericHeader="related work">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999915777777778">
There are many recent approaches to this prob-
lem, e. g. syntax-based approaches (Lappin and
Leass, 1994), cooccurrence-based approaches
(Dagan and Itai, 1990), machine-learning ap-
proaches (Connolly et al., 1994; Aone and Ben-
nett, 1996; Soon et al., 1999), uncertainty
reasoning approaches (Mitkov, 1995; Mitkov,
1997), and robust knowledge-poor approaches
(Kennedy and Boguarev, 1996; Baldwin, 1997;
</bodyText>
<footnote confidence="0.995229285714286">
5The number of markables that are coreferential with
some other markable ranges from 28 to 63 for the folds
because the texts in the evaluation corpus were not bro-
ken up for cross-validation in order to yield statistical
data about whole texts. Therefore the training corpus
size varied between 439 and 474 and the test corpus be-
tween 28 and 63 during the cross-validation.
</footnote>
<figure confidence="0.7977927">
fo(i, A) f (i, A)
f3(i, A) := fi-&apos;
ajeA/CA,011=k—j
for 1 &lt; j &lt; k — 1
rf (i, A) := P (i, A)
1=i
for 0 &lt;j&lt;k-1
:=
P :=
(9)
</figure>
<table confidence="0.807116444444444">
method evaluation results in percentage
coreference (incl. markable identification)
markable-relative coreference evaluation
baseline: always closest candidate
recall precision F-measure
55 82 66
76 82 79
46 42 44
F-measure is calculated with equal weight to recall r and precision p as 2r•
</table>
<tableCaption confidence="0.995871">
Table 3: Coreference resolution results
</tableCaption>
<bodyText confidence="0.985441807692308">
r±p •
Mitkov, 1998b; Mitkov, 1999).6 The following
two systems tackle the MUC coreference task
and bear some similarities to COR,UDIS.
The system described by Cardie and Wagstaff
(1999) resembles the presented system in that
it views coreference resolution in a text as
partitioning (or clustering). The difference in
terms of clustering is that the first system uses
greedy clustering while COR,UDIS optimizes us-
ing global scores. The fundamental difference is
that the first system partitions based on a simi-
larity function over markable representations as
attribute value pairs, while COR,UDIS applies
linguistic rules to license possible coreference
links and applies corpus statistics to choose one
link because typically alternatives exist.
The SWIZZLE system (Harabagiu and Maio-
rano, 2000) applies heuristics and heuristic or-
dering by bootstrapping to pick one antecedent
per anaphor; in the COR,UDIS system, rules
license alternatives and one is selected based
on a learned statistical model. COR,UDIS uses
sentence parsing, SWIZZLE as an intention-
ally knowledge-poor approach only approximate
phrasal parsing.
</bodyText>
<sectionHeader confidence="0.999316" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.978421041666667">
I have presented a disambiguation method
which combines traditional linguistically moti-
vated rules and a backed-off statistical model
derived form an annotated corpus in a powerful
way. Comparison to other approaches is diffi-
cult since evaluation results for German are not
available for the MUC coreference task. But the
results presented seem to be competitive corn-
6 The cited works deal only with pronominal
anaphors, except the approaches by Aone and Bennett
(1996), Baldwin (1997), Connolly et al. (1994), and Soon
et al. (1999).
pared to the 60% F-measure results for English
in MUC-7.
Additional filtering conditions, additional
scores (preferences), and features from Center-
ing Theory (Grosz et al., 1995) might improve
the results reported in this paper significantly.
The use of a large lexical-semantic network like
GermaNet would solve some problematic coref-
erence cases. More sophisticated evaluations
centered around different error types as recom-
mended by Mitkov (1998a) and larger data sets
are planned for the future.
</bodyText>
<sectionHeader confidence="0.998435" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99962920979021">
Chinatsu Aone and Scott William Bennett. 1996.
Applying machine learning to anaphora reso-
lution. In Stefan Wermter, Ellen Riloff, and
Gabriele Scheler, editors, Connectionist, Statisti-
cal, and Symbolic Approaches to Learning for Nat-
ural Language Processing, volume 1040 of LNAI,
pages 302-314. Springer, Berlin.
Breck Baldwin. 1997. CogNIAC: High precision
coreference with limited knowledge and linguistic
resources. In Proceedings of the ACL-EACL &apos;97
workshop on operational factors in practical, ro-
bust anaphora resolution for unrestricted texts,
pages 38-45, Madrid, Spain.
Eric T. Bell. 1934. Exponential numbers. American
Mathematical Monthly, 41:411-419.
Claire Cardie and Kiri Wagstaff. 1999. Noun phrase
coreference as clustering. In Proceedings of the
Joint Conference on Empirical Methods in Natu-
ral Language Processing and Very Large Corpora
(Ell/INLP/VLC-99), pages 82-89, College Park,
Maryland.
Michael Collins and James Brooks. 1995. Prepo-
sitional phrase attachment through a backed-off
model. In Proceedings of the 3rd Workshop on
Very Large Corpora (WVLC-3), pages 27-38,
Cambridge, Massachusetts. http://xxx.lanl.gov/
abs/cmp-lg/9506021.
Dennis Connolly, John D. Burger, and David S.
Day. 1994. A machine learning approach to
anaphoric reference. In Proceedings of the Inter-
national Conference on New Methods in Language
Processing, pages 255-261, Manchester, England.
Ido Dagan and Alon Ital. 1990. Automatic process-
ing of large corpora for the resolution of anaphora
references. In Proceedings of the 13th Interna-
tional Conference on Computational Linguistics
(COLING 90), volume 3, pages 330-332, Helsinki,
Finland.
Barbara J. Grosz, Aaravind K. Joshi, and Scott We-
instein. 1995. Centering: A framework for mod-
eling the local coherence of discourse. Computa-
tional Linguistics, 21(2):203-225, June.
Sanda M. Harabagiu and Steven J. Maiorano. 2000.
Multilingual coreference resolution. In Proceed-
ings of the Language Technology Joint Confer-
ence on Applied Natural Language Processing
and the North American Chapter of the Asso-
ciation for Computational Linguistics (ANLP-
NA A CL &apos;2000), Seattle, Washington.
Sven Hartrumpf. 1999. Hybrid disambiguation of
prepositional phrase attachment and interpreta-
tion. In Proceedings of the Joint Conference on
Empirical Methods in Natural Language Process-
ing and Very Large Corpora (Ell/INLP/VLC-99),
pages 111-120, College Park, Maryland.
Hermann Helbig and Sven Hartrumpf. 1997. Word
class functions for syntactic-semantic analysis. In
Proceedings of the 2nd International Conference
on Recent Advances in Natural Language Process-
ing (R,ANLP&apos;97), pages 312-317, Tzigov Chark,
Bulgaria, September.
Hermann Helbig. 2001. Die semantische Struktur
natiirlicher Sprache: Wissensreprosentation mit
IfultiNet. Springer, Berlin.
Lynette Hirschman and Nancy Chinchor. 1997.
MUC-7 coreference task definition (version 3.0).
In Proceedings of the 7th Message Understanding
Conference (11/IUC-7). http: / /NATIATIAT.itl.nist.gov/
iaui/894.02/related_projects/muc/.
Nancy Ide, Greg Priest-Dorman, and Jean Veronis,
1996. Corpus Encoding Standard. http://lATIATIAT.
cs.vassar.edu/CES/.
Slava M. Katz. 1987. Estimation of probabilities
from sparse data for the language model com-
ponent of a speech recognizer. IEEE Transac-
tions on Acoustics. Speech and Signal Processing,
35(3):400-401, March.
Christopher Kennedy and Branimir Boguarev. 1996.
Anaphora for everyone: Pronominal anaphora
resolution without a parser. In Proceedings of the
16th International Conference on Computational
Linguistics (COLING 96), pages 113-118, Copen-
hagen, Denmark.
A. Knoll, C. Altenschmidt, J. Biskup, H.-M.
Blilthgen, I. Glockner, S. Hartrumpf, H. Helbig,
C. Henning, Y. Karabulut, R. Luling, B. Monien,
T. Noll, and N. Sensen. 1998. An integrated
approach to semantic evaluation and content-
based retrieval of multimedia documents. In
C. Nikolaou and C. Stephanidis, editors, Pro-
ceedings of the 2nd European Conference on Dig-
ital Libraries (ECDL&apos;98), number 1513 in Lec-
ture Notes in Computer Science, pages 409-428,
Berlin. Springer.
Shalom Lappin and Herbert Leass. 1994. An algo-
rithm for pronominal anaphora resolution. Com-
putational Linguistics, 20(4):535-561, December.
R,uslan Mitkov. 1995. An uncertainty reasoning ap-
proach for anaphora resolution. In Proceedings
of the Natural Language Processing Pacific Rim
Symposium (NLPR,S&apos;95), pages 149-154, Seoul,
Korea.
R,uslan Mitkov. 1997. Two engines are better than
one: Generating more power and confidence in the
search for the antecedent. In R,uslan Mitkov and
Nicolas Nicolov, editors, Recent Advances in Nat-
ural Language Processing: Selected Papers from
R,ANLP&apos;95, pages 225-234. John Benjamins, Am-
sterdam.
R,uslan Mitkov. 1998a. Evaluating anaphora reso-
lution approaches. In Proceedings of the Second
Colloquium on Discourse Anaphora and Anaphor
Resolution (DAAR,C 2), pages 164-177, Lan-
caster, England.
R,uslan Mitkov. 1998b. Robust pronoun resolution
with limited knowledge. In Proceedings of the
17th International Conference on Computational
Linguistics and 36th Annual Meeting of the Asso-
ciation for Computational Linguistics (COLING-
ACL&apos;98), pages 869-875, Montreal, Canada.
R,uslan Mitkov. 1999. Multilingual anaphora reso-
lution. Machine Translation, 14:281-299.
Wee Meng Soon, Hwee Tou Ng, and Chung Yong
Lim. 1999. Corpus-based learning for noun-
phrase coreference resolution. In Proceedings of
the Joint Conference on Empirical Methods in
Natural Language Processing and Very Large Cor-
pora (Ell/INLP/VLC-99), pages 285-291, College
Park, Maryland.
Kees van Deemter and Rodger Kibble. 2000. On
coreferring: Coreference in MUC and related
annotation schemes. Computational Linguistics,
26(4):629-637, December.
Renata Vieira and Massimo Poesio. 2000. An em-
pirically based system for processing definite de-
scriptions. Computational Linguistics, 26(4)539—
593, December.
Marc Vilain, John Burger, John Aberdeen, Den-
nis Connolly, and Lynette Hirschman. 1995. A
model-theoretic coreference scoring scheme. In
Proceedings of the 6th Message Understanding
Conference (11/IUC-6), pages 45-52, San Mateo.
Morgan Kaufmann.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.726403">
<title confidence="0.997978">Coreference Resolution Syntactico-Semantic Rules and Corpus Statistics</title>
<author confidence="0.989702">Sven</author>
<affiliation confidence="0.9997425">Computer Science University of</affiliation>
<address confidence="0.99926">58084 Hagen,</address>
<email confidence="0.975127">Sven.Hartrumpf©ifernuni-hagen.de</email>
<abstract confidence="0.981230769230769">A new hybrid approach to the coreference resolution problem is presented. The COR,UDIS system (COreference R,Ules with Disambiguation Statistics) combines syntactico-semantic rules with statistics derived from an annotated corpus. First, the rules and corpus annotations are described and exemplified. Then, the coreference resolution algorithm and the involved statistics are explained. Finally, the proposed method is evaluated against a baseline model and some directions for further research are indicated.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Chinatsu Aone</author>
<author>Scott William Bennett</author>
</authors>
<title>Applying machine learning to anaphora resolution.</title>
<date>1996</date>
<booktitle>Connectionist, Statistical, and Symbolic Approaches to Learning for Natural Language Processing,</booktitle>
<volume>1040</volume>
<pages>302--314</pages>
<editor>In Stefan Wermter, Ellen Riloff, and Gabriele Scheler, editors,</editor>
<publisher>Springer,</publisher>
<location>Berlin.</location>
<contexts>
<context position="20863" citStr="Aone and Bennett, 1996" startWordPosition="3278" endWordPosition="3282">ated only for the markables that have been successfully identified (in some sense, this concentrates on the coreference relation aspect of the coreference task). And the final evaluation result comes from a baseline model: &amp;quot;always select the closest antecedent candidate that is licensed by a rule and fulfills the distance and compatibility constraints from section 3.2&amp;quot;. 5 Related Work There are many recent approaches to this problem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches (Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Bennett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; 5The number of markables that are coreferential with some other markable ranges from 28 to 63 for the folds because the texts in the evaluation corpus were not broken up for cross-validation in order to yield statistical data about whole texts. Therefore the training corpus size varied between 439 and 474 and the test corpus between 28 and 63 during the cross-validation. fo(i, A) f (i, A) f3(i, A) := fi-&apos; ajeA/CA,011=k—j for 1 &lt; j</context>
</contexts>
<marker>Aone, Bennett, 1996</marker>
<rawString>Chinatsu Aone and Scott William Bennett. 1996. Applying machine learning to anaphora resolution. In Stefan Wermter, Ellen Riloff, and Gabriele Scheler, editors, Connectionist, Statistical, and Symbolic Approaches to Learning for Natural Language Processing, volume 1040 of LNAI, pages 302-314. Springer, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Breck Baldwin</author>
</authors>
<title>CogNIAC: High precision coreference with limited knowledge and linguistic resources.</title>
<date>1997</date>
<booktitle>In Proceedings of the ACL-EACL &apos;97</booktitle>
<pages>38--45</pages>
<location>Madrid,</location>
<contexts>
<context position="21027" citStr="Baldwin, 1997" startWordPosition="3302" endWordPosition="3303">al evaluation result comes from a baseline model: &amp;quot;always select the closest antecedent candidate that is licensed by a rule and fulfills the distance and compatibility constraints from section 3.2&amp;quot;. 5 Related Work There are many recent approaches to this problem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches (Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Bennett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; 5The number of markables that are coreferential with some other markable ranges from 28 to 63 for the folds because the texts in the evaluation corpus were not broken up for cross-validation in order to yield statistical data about whole texts. Therefore the training corpus size varied between 439 and 474 and the test corpus between 28 and 63 during the cross-validation. fo(i, A) f (i, A) f3(i, A) := fi-&apos; ajeA/CA,011=k—j for 1 &lt; j &lt; k — 1 rf (i, A) := P (i, A) 1=i for 0 &lt;j&lt;k-1 := P := (9) method evaluation results in percentage coreference (incl. markable identification) markable-relative co</context>
</contexts>
<marker>Baldwin, 1997</marker>
<rawString>Breck Baldwin. 1997. CogNIAC: High precision coreference with limited knowledge and linguistic resources. In Proceedings of the ACL-EACL &apos;97 workshop on operational factors in practical, robust anaphora resolution for unrestricted texts, pages 38-45, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric T Bell</author>
</authors>
<title>Exponential numbers.</title>
<date>1934</date>
<pages>41--411</pages>
<publisher>American Mathematical Monthly,</publisher>
<contexts>
<context position="6965" citStr="Bell, 1934" startWordPosition="1086" endWordPosition="1087"> /w) (w)Zeitung( /w) ( / coref) Kw); (/w) (w)danachK/w) (w)gehtK/w) (coref ref=&amp;quot; 125t129&amp;quot; type=&amp;quot; ident&amp;quot; Kw) sie( /w) ( /coref) (w)mit ( /w) (coref ref=&amp;quot; 143t147&amp;quot; type=&amp;quot; ident&amp;quot; Kw) ihr ( /w) ( /coref) (w)insK/w) (w)BilroK/w) (w).K/w)(/s) 3 Coreference resolution 3.1 Algorithm overview To resolve coreference ambiguities, one must find the partition of markables that corresponds to the correct coreference equivalence relation. The search space is huge since the number of different partitions for n markables is equal to the Bell number B(n). These numbers are also called Exponential numbers, see (Bell, 1934); some example values are: B(1) = 1, B(2) = 2, B(3) = 5, B(4) = 15, B(5) = 52, B(10) = 4R.ules for cataphora are also among the coreference rules. In such rules, cl corresponds to the cataphor and c2 to the postcedent. feature name use* description CAT syntactic category en (noun), perspro (personal pronoun), possdet (possessive determiner), reflpro (reflexive pronoun), etc.) ENTITY ic semantic classification comprising the semantic sort (feature SORT) and semantic Boolean features (currently 16, all defined for the MultiNet (multilayered extended semantic network) formalism by Helbig (2001)) </context>
</contexts>
<marker>Bell, 1934</marker>
<rawString>Eric T. Bell. 1934. Exponential numbers. American Mathematical Monthly, 41:411-419.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Cardie</author>
<author>Kiri Wagstaff</author>
</authors>
<title>Noun phrase coreference as clustering.</title>
<date>1999</date>
<booktitle>In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Very Large Corpora (Ell/INLP/VLC-99),</booktitle>
<pages>82--89</pages>
<location>College Park, Maryland.</location>
<contexts>
<context position="22039" citStr="Cardie and Wagstaff (1999)" startWordPosition="3473" endWordPosition="3476"> (i, A) f3(i, A) := fi-&apos; ajeA/CA,011=k—j for 1 &lt; j &lt; k — 1 rf (i, A) := P (i, A) 1=i for 0 &lt;j&lt;k-1 := P := (9) method evaluation results in percentage coreference (incl. markable identification) markable-relative coreference evaluation baseline: always closest candidate recall precision F-measure 55 82 66 76 82 79 46 42 44 F-measure is calculated with equal weight to recall r and precision p as 2r• Table 3: Coreference resolution results r±p • Mitkov, 1998b; Mitkov, 1999).6 The following two systems tackle the MUC coreference task and bear some similarities to COR,UDIS. The system described by Cardie and Wagstaff (1999) resembles the presented system in that it views coreference resolution in a text as partitioning (or clustering). The difference in terms of clustering is that the first system uses greedy clustering while COR,UDIS optimizes using global scores. The fundamental difference is that the first system partitions based on a similarity function over markable representations as attribute value pairs, while COR,UDIS applies linguistic rules to license possible coreference links and applies corpus statistics to choose one link because typically alternatives exist. The SWIZZLE system (Harabagiu and Maio</context>
</contexts>
<marker>Cardie, Wagstaff, 1999</marker>
<rawString>Claire Cardie and Kiri Wagstaff. 1999. Noun phrase coreference as clustering. In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Very Large Corpora (Ell/INLP/VLC-99), pages 82-89, College Park, Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>James Brooks</author>
</authors>
<title>Prepositional phrase attachment through a backed-off model.</title>
<date>1995</date>
<booktitle>In Proceedings of the 3rd Workshop on Very Large Corpora (WVLC-3),</booktitle>
<pages>27--38</pages>
<location>Cambridge, Massachusetts.</location>
<note>http://xxx.lanl.gov/ abs/cmp-lg/9506021.</note>
<contexts>
<context position="13238" citStr="Collins and Brooks, 1995" startWordPosition="2078" endWordPosition="2081"> see (Helbig and Hartrumpf, 1997). 2. All possible coreference rule activations that link an anaphor to an antecedent candidate are collected. This is done by testing rule premises on all markable pairs (constituent c1 must precede constituent c2). For two markables, one rule (at most) is activated since the rules have disjoint premises for real text purposes. 3. For each anaphor, one antecedent candidate is selected. This decision is based on rule statistics gained from the annotated training corpus. The sparse data problem is alleviated by backed-off estimation (see for example (Katz, 1987; Collins and Brooks, 1995)). The algorithm deals with three sets of objects: first, the possible anaphors (all identified markables); second, the candidate antecedents for each possible anaphor (all preceding markables and the artificial nonreferable markable explained below); third, the coreference rules. The nonreferable markable is used as the artificial anaphor of a nonreferring markable in order to represent all alternative references for a possible anaphor as a pair. For firstmentions, the disambiguation algorithm should select a coreference with the nonreferable markable as antecedent. Currently, one rule licens</context>
</contexts>
<marker>Collins, Brooks, 1995</marker>
<rawString>Michael Collins and James Brooks. 1995. Prepositional phrase attachment through a backed-off model. In Proceedings of the 3rd Workshop on Very Large Corpora (WVLC-3), pages 27-38, Cambridge, Massachusetts. http://xxx.lanl.gov/ abs/cmp-lg/9506021.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dennis Connolly</author>
<author>John D Burger</author>
<author>David S Day</author>
</authors>
<title>A machine learning approach to anaphoric reference.</title>
<date>1994</date>
<booktitle>In Proceedings of the International Conference on New Methods in Language Processing,</booktitle>
<pages>255--261</pages>
<location>Manchester, England.</location>
<contexts>
<context position="20839" citStr="Connolly et al., 1994" startWordPosition="3274" endWordPosition="3277"> the numbers are calculated only for the markables that have been successfully identified (in some sense, this concentrates on the coreference relation aspect of the coreference task). And the final evaluation result comes from a baseline model: &amp;quot;always select the closest antecedent candidate that is licensed by a rule and fulfills the distance and compatibility constraints from section 3.2&amp;quot;. 5 Related Work There are many recent approaches to this problem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches (Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Bennett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; 5The number of markables that are coreferential with some other markable ranges from 28 to 63 for the folds because the texts in the evaluation corpus were not broken up for cross-validation in order to yield statistical data about whole texts. Therefore the training corpus size varied between 439 and 474 and the test corpus between 28 and 63 during the cross-validation. fo(i, A) f (i, A) f3(i, A) := fi-&apos; a</context>
</contexts>
<marker>Connolly, Burger, Day, 1994</marker>
<rawString>Dennis Connolly, John D. Burger, and David S. Day. 1994. A machine learning approach to anaphoric reference. In Proceedings of the International Conference on New Methods in Language Processing, pages 255-261, Manchester, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Alon Ital</author>
</authors>
<title>Automatic processing of large corpora for the resolution of anaphora references.</title>
<date>1990</date>
<booktitle>In Proceedings of the 13th International Conference on Computational Linguistics (COLING 90),</booktitle>
<volume>3</volume>
<pages>330--332</pages>
<location>Helsinki, Finland.</location>
<marker>Dagan, Ital, 1990</marker>
<rawString>Ido Dagan and Alon Ital. 1990. Automatic processing of large corpora for the resolution of anaphora references. In Proceedings of the 13th International Conference on Computational Linguistics (COLING 90), volume 3, pages 330-332, Helsinki, Finland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Aaravind K Joshi</author>
<author>Scott Weinstein</author>
</authors>
<title>Centering: A framework for modeling the local coherence of discourse.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<pages>21--2</pages>
<marker>Grosz, Joshi, Weinstein, 1995</marker>
<rawString>Barbara J. Grosz, Aaravind K. Joshi, and Scott Weinstein. 1995. Centering: A framework for modeling the local coherence of discourse. Computational Linguistics, 21(2):203-225, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanda M Harabagiu</author>
<author>Steven J Maiorano</author>
</authors>
<title>Multilingual coreference resolution.</title>
<date>2000</date>
<booktitle>In Proceedings of the Language Technology Joint Conference on Applied Natural Language Processing and the North American Chapter of the Association for Computational Linguistics (ANLPNA A CL &apos;2000),</booktitle>
<location>Seattle, Washington.</location>
<contexts>
<context position="22650" citStr="Harabagiu and Maiorano, 2000" startWordPosition="3562" endWordPosition="3566">nd Wagstaff (1999) resembles the presented system in that it views coreference resolution in a text as partitioning (or clustering). The difference in terms of clustering is that the first system uses greedy clustering while COR,UDIS optimizes using global scores. The fundamental difference is that the first system partitions based on a similarity function over markable representations as attribute value pairs, while COR,UDIS applies linguistic rules to license possible coreference links and applies corpus statistics to choose one link because typically alternatives exist. The SWIZZLE system (Harabagiu and Maiorano, 2000) applies heuristics and heuristic ordering by bootstrapping to pick one antecedent per anaphor; in the COR,UDIS system, rules license alternatives and one is selected based on a learned statistical model. COR,UDIS uses sentence parsing, SWIZZLE as an intentionally knowledge-poor approach only approximate phrasal parsing. 6 Conclusion I have presented a disambiguation method which combines traditional linguistically motivated rules and a backed-off statistical model derived form an annotated corpus in a powerful way. Comparison to other approaches is difficult since evaluation results for Germa</context>
</contexts>
<marker>Harabagiu, Maiorano, 2000</marker>
<rawString>Sanda M. Harabagiu and Steven J. Maiorano. 2000. Multilingual coreference resolution. In Proceedings of the Language Technology Joint Conference on Applied Natural Language Processing and the North American Chapter of the Association for Computational Linguistics (ANLPNA A CL &apos;2000), Seattle, Washington.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sven Hartrumpf</author>
</authors>
<title>Hybrid disambiguation of prepositional phrase attachment and interpretation.</title>
<date>1999</date>
<booktitle>In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Very Large Corpora (Ell/INLP/VLC-99),</booktitle>
<pages>111--120</pages>
<location>College Park, Maryland.</location>
<contexts>
<context position="5335" citStr="Hartrumpf, 1999" startWordPosition="823" endWordPosition="824">ining 14000 German lexemes (HaGenLex). A feature value can be a single type or a disjunction of types. Furthermore, one can construct constraints with predicates. The most important predicates are given in Table 2: they realize concepts from Dependency Grammar (depend/2) and Government and Binding Theory (c-command/2) or define simple relationships between constituents (e. g. compatible-gend-ngend/2). The conclusion of a rule expresses a coreference relation with a semantic network (based on the MultiNet formalism defined by Helbig (2001) which has been applied in several other projects, see (Hartrumpf, 1999; Knoll et al., 1998)). For identity coreference, a relation named EQU (equivalence) leading from the anaphor (called c2 in rules)4 to the antecedent (called c1 in rules) suffices. Seven rules from the eighteen rules currently used are given in Figure 1. The rule ident.gend_conflict would license a link between das Mddchen and sic in sentence (1). The premise and conclusion can also be viewed as one attribute value matrix employing structure sharing for expressing ic-constraints. 2.2 Annotated corpus A corpus (a collection of German newspaper articles from the Sitddeutsche Zeitung) is annotate</context>
</contexts>
<marker>Hartrumpf, 1999</marker>
<rawString>Sven Hartrumpf. 1999. Hybrid disambiguation of prepositional phrase attachment and interpretation. In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Very Large Corpora (Ell/INLP/VLC-99), pages 111-120, College Park, Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hermann Helbig</author>
<author>Sven Hartrumpf</author>
</authors>
<title>Word class functions for syntactic-semantic analysis.</title>
<date>1997</date>
<booktitle>In Proceedings of the 2nd International Conference on Recent Advances in Natural Language Processing (R,ANLP&apos;97),</booktitle>
<pages>312--317</pages>
<location>Tzigov Chark, Bulgaria,</location>
<contexts>
<context position="12646" citStr="Helbig and Hartrumpf, 1997" startWordPosition="1981" endWordPosition="1985">rhit) det (e2 PROPER) noproper (= (el NUM) (C2 NUM)) (= (C1 =TYE) (C2 ETYPE)) (= (C1 ENTITY) (C2 ENTITY)) (not (similar-nouns cl c2)) (maximal (C1 ENTITY)) (maximal (c2 ENTITY)) (difference&gt; (C1 SENTENCE-ID) (C2 SENTENCE-ID) 0) two semantically compatible NPs. Mie Tater] Mie Manner] i [einer hollandischen Fanailie]i [die entfiihrte Deutsche]j id pre. desc. exam. id pre. desc. exam. id pre. Figure 1: Example coreference rules ated. (In such cases, constraints in rule premises that involve predicates requiring full parses (e. g. c-command) are ignored in step 2.) For details on the parser, see (Helbig and Hartrumpf, 1997). 2. All possible coreference rule activations that link an anaphor to an antecedent candidate are collected. This is done by testing rule premises on all markable pairs (constituent c1 must precede constituent c2). For two markables, one rule (at most) is activated since the rules have disjoint premises for real text purposes. 3. For each anaphor, one antecedent candidate is selected. This decision is based on rule statistics gained from the annotated training corpus. The sparse data problem is alleviated by backed-off estimation (see for example (Katz, 1987; Collins and Brooks, 1995)). The a</context>
</contexts>
<marker>Helbig, Hartrumpf, 1997</marker>
<rawString>Hermann Helbig and Sven Hartrumpf. 1997. Word class functions for syntactic-semantic analysis. In Proceedings of the 2nd International Conference on Recent Advances in Natural Language Processing (R,ANLP&apos;97), pages 312-317, Tzigov Chark, Bulgaria, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hermann Helbig</author>
</authors>
<title>Die semantische Struktur natiirlicher Sprache: Wissensreprosentation mit IfultiNet.</title>
<date>2001</date>
<publisher>Springer,</publisher>
<location>Berlin.</location>
<contexts>
<context position="5264" citStr="Helbig (2001)" startWordPosition="811" endWordPosition="813">m from a parser using a semantically oriented lexicon currently containing 14000 German lexemes (HaGenLex). A feature value can be a single type or a disjunction of types. Furthermore, one can construct constraints with predicates. The most important predicates are given in Table 2: they realize concepts from Dependency Grammar (depend/2) and Government and Binding Theory (c-command/2) or define simple relationships between constituents (e. g. compatible-gend-ngend/2). The conclusion of a rule expresses a coreference relation with a semantic network (based on the MultiNet formalism defined by Helbig (2001) which has been applied in several other projects, see (Hartrumpf, 1999; Knoll et al., 1998)). For identity coreference, a relation named EQU (equivalence) leading from the anaphor (called c2 in rules)4 to the antecedent (called c1 in rules) suffices. Seven rules from the eighteen rules currently used are given in Figure 1. The rule ident.gend_conflict would license a link between das Mddchen and sic in sentence (1). The premise and conclusion can also be viewed as one attribute value matrix employing structure sharing for expressing ic-constraints. 2.2 Annotated corpus A corpus (a collection </context>
<context position="7563" citStr="Helbig (2001)" startWordPosition="1179" endWordPosition="1180">ee (Bell, 1934); some example values are: B(1) = 1, B(2) = 2, B(3) = 5, B(4) = 15, B(5) = 52, B(10) = 4R.ules for cataphora are also among the coreference rules. In such rules, cl corresponds to the cataphor and c2 to the postcedent. feature name use* description CAT syntactic category en (noun), perspro (personal pronoun), possdet (possessive determiner), reflpro (reflexive pronoun), etc.) ENTITY ic semantic classification comprising the semantic sort (feature SORT) and semantic Boolean features (currently 16, all defined for the MultiNet (multilayered extended semantic network) formalism by Helbig (2001)) ETYPE ic extension type (0 (an individual), 1 (a set), 2 (a set of sets), etc.), part of the complex feature LAY containing other extensional and intensional layer features like CARD (cardinality) GEND ic gender (syntactic; masculine, feminine, and neuter in German) NUM c, ic number (syntactic; singular and plural in German) PERS c, ic person (only tested jointly with the other agreement features GEND and NUM) PROPER proper noun (Boolean feature) REFER c, ic reference type (determinate, indeterminate; based on article choice) SENTENCE-ID ic sentence number in text SORT semantic sort (45 hier</context>
</contexts>
<marker>Helbig, 2001</marker>
<rawString>Hermann Helbig. 2001. Die semantische Struktur natiirlicher Sprache: Wissensreprosentation mit IfultiNet. Springer, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lynette Hirschman</author>
<author>Nancy Chinchor</author>
</authors>
<title>MUC-7 coreference task definition (version 3.0).</title>
<date>1997</date>
<booktitle>In Proceedings of the 7th Message Understanding Conference (11/IUC-7). http: / /NATIATIAT.itl.nist.gov/ iaui/894.02/related_projects/muc/.</booktitle>
<contexts>
<context position="1590" citStr="Hirschman and Chinchor, 1997" startWordPosition="232" endWordPosition="236">and ihr refer to. Both can refer to Madchen or Zeitung because grammatical gender agreement in German can be overruled by natural gender agreement in certain cases. (1) [Das Mddehenji hest [die The girl+NEUT reads the Zeitungli; danach geht newspaper+FEM; afterwards goes sie mit ihTi fins she+FEM with her+FEM in the Bitralk. office. &apos;The girl reads the newspaper; afterwards she goes to the office with it.&apos; 11 would like to thank Hermann Helbig, Rainer Osswald, and the anonymous reviewers for their helpful comments and suggestions. The task in this paper is similar to the MUC coreference task (Hirschman and Chinchor, 1997)2: • only identity coreference is treated (and not part-whole or other complex semantic relationships); • only noun phrases (NPs) are considered as markables for coreference (and not situations expressed by clauses etc.). This kind of coreference is an equivalence relation so that coreference resolution comes down to finding the correct partition3 of markables. If there exists a genuine ambiguity for human readers (and not just a spurious one for computers), several partitions of markables would be the correct answer to the coreference problem. But since such ambiguities are rare the disambigu</context>
</contexts>
<marker>Hirschman, Chinchor, 1997</marker>
<rawString>Lynette Hirschman and Nancy Chinchor. 1997. MUC-7 coreference task definition (version 3.0). In Proceedings of the 7th Message Understanding Conference (11/IUC-7). http: / /NATIATIAT.itl.nist.gov/ iaui/894.02/related_projects/muc/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Ide</author>
<author>Greg Priest-Dorman</author>
<author>Jean Veronis</author>
</authors>
<title>Corpus Encoding Standard.</title>
<date>1996</date>
<note>http://lATIATIAT. cs.vassar.edu/CES/.</note>
<contexts>
<context position="6188" citStr="Ide et al., 1996" startWordPosition="959" endWordPosition="962">given in Figure 1. The rule ident.gend_conflict would license a link between das Mddchen and sic in sentence (1). The premise and conclusion can also be viewed as one attribute value matrix employing structure sharing for expressing ic-constraints. 2.2 Annotated corpus A corpus (a collection of German newspaper articles from the Sitddeutsche Zeitung) is annotated for coreference according to the guidelines for the MUC coreference task adapted from English to German. The annotations are inserted as SGML tags into the corpus, which is already marked up according to the Corpus Encoding Standard (Ide et al., 1996). The annotation for sentence (1) is given as (2): (2) (s) (coref id=&amp;quot; 125t129&amp;quot; Kw) Das ( / w) (w)Madchen( /w) ( /coref) Kw) liest (/w) (coref id=&amp;quot; 143t147&amp;quot; Kw) die ( /w) (w)Zeitung( /w) ( / coref) Kw); (/w) (w)danachK/w) (w)gehtK/w) (coref ref=&amp;quot; 125t129&amp;quot; type=&amp;quot; ident&amp;quot; Kw) sie( /w) ( /coref) (w)mit ( /w) (coref ref=&amp;quot; 143t147&amp;quot; type=&amp;quot; ident&amp;quot; Kw) ihr ( /w) ( /coref) (w)insK/w) (w)BilroK/w) (w).K/w)(/s) 3 Coreference resolution 3.1 Algorithm overview To resolve coreference ambiguities, one must find the partition of markables that corresponds to the correct coreference equivalence relation. The se</context>
</contexts>
<marker>Ide, Priest-Dorman, Veronis, 1996</marker>
<rawString>Nancy Ide, Greg Priest-Dorman, and Jean Veronis, 1996. Corpus Encoding Standard. http://lATIATIAT. cs.vassar.edu/CES/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slava M Katz</author>
</authors>
<title>Estimation of probabilities from sparse data for the language model component of a speech recognizer.</title>
<date>1987</date>
<journal>IEEE Transactions on Acoustics. Speech and Signal Processing,</journal>
<pages>35--3</pages>
<contexts>
<context position="13211" citStr="Katz, 1987" startWordPosition="2076" endWordPosition="2077"> the parser, see (Helbig and Hartrumpf, 1997). 2. All possible coreference rule activations that link an anaphor to an antecedent candidate are collected. This is done by testing rule premises on all markable pairs (constituent c1 must precede constituent c2). For two markables, one rule (at most) is activated since the rules have disjoint premises for real text purposes. 3. For each anaphor, one antecedent candidate is selected. This decision is based on rule statistics gained from the annotated training corpus. The sparse data problem is alleviated by backed-off estimation (see for example (Katz, 1987; Collins and Brooks, 1995)). The algorithm deals with three sets of objects: first, the possible anaphors (all identified markables); second, the candidate antecedents for each possible anaphor (all preceding markables and the artificial nonreferable markable explained below); third, the coreference rules. The nonreferable markable is used as the artificial anaphor of a nonreferring markable in order to represent all alternative references for a possible anaphor as a pair. For firstmentions, the disambiguation algorithm should select a coreference with the nonreferable markable as antecedent.</context>
</contexts>
<marker>Katz, 1987</marker>
<rawString>Slava M. Katz. 1987. Estimation of probabilities from sparse data for the language model component of a speech recognizer. IEEE Transactions on Acoustics. Speech and Signal Processing, 35(3):400-401, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Kennedy</author>
<author>Branimir Boguarev</author>
</authors>
<title>Anaphora for everyone: Pronominal anaphora resolution without a parser.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics (COLING 96),</booktitle>
<pages>113--118</pages>
<location>Copenhagen, Denmark.</location>
<contexts>
<context position="21012" citStr="Kennedy and Boguarev, 1996" startWordPosition="3298" endWordPosition="3301">reference task). And the final evaluation result comes from a baseline model: &amp;quot;always select the closest antecedent candidate that is licensed by a rule and fulfills the distance and compatibility constraints from section 3.2&amp;quot;. 5 Related Work There are many recent approaches to this problem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches (Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Bennett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; 5The number of markables that are coreferential with some other markable ranges from 28 to 63 for the folds because the texts in the evaluation corpus were not broken up for cross-validation in order to yield statistical data about whole texts. Therefore the training corpus size varied between 439 and 474 and the test corpus between 28 and 63 during the cross-validation. fo(i, A) f (i, A) f3(i, A) := fi-&apos; ajeA/CA,011=k—j for 1 &lt; j &lt; k — 1 rf (i, A) := P (i, A) 1=i for 0 &lt;j&lt;k-1 := P := (9) method evaluation results in percentage coreference (incl. markable identification) marka</context>
</contexts>
<marker>Kennedy, Boguarev, 1996</marker>
<rawString>Christopher Kennedy and Branimir Boguarev. 1996. Anaphora for everyone: Pronominal anaphora resolution without a parser. In Proceedings of the 16th International Conference on Computational Linguistics (COLING 96), pages 113-118, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="false">
<authors>
<author>A Knoll</author>
<author>C Altenschmidt</author>
<author>J Biskup</author>
<author>H-M Blilthgen</author>
<author>I Glockner</author>
<author>S Hartrumpf</author>
<author>H Helbig</author>
<author>C Henning</author>
<author>Y Karabulut</author>
<author>R Luling</author>
<author>B Monien</author>
</authors>
<marker>Knoll, Altenschmidt, Biskup, Blilthgen, Glockner, Hartrumpf, Helbig, Henning, Karabulut, Luling, Monien, </marker>
<rawString>A. Knoll, C. Altenschmidt, J. Biskup, H.-M. Blilthgen, I. Glockner, S. Hartrumpf, H. Helbig, C. Henning, Y. Karabulut, R. Luling, B. Monien,</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Noll</author>
<author>N Sensen</author>
</authors>
<title>An integrated approach to semantic evaluation and contentbased retrieval of multimedia documents.</title>
<date>1998</date>
<booktitle>Proceedings of the 2nd European Conference on Digital Libraries (ECDL&apos;98), number 1513 in Lecture Notes in Computer Science,</booktitle>
<pages>409--428</pages>
<editor>In C. Nikolaou and C. Stephanidis, editors,</editor>
<publisher>Springer.</publisher>
<location>Berlin.</location>
<marker>Noll, Sensen, 1998</marker>
<rawString>T. Noll, and N. Sensen. 1998. An integrated approach to semantic evaluation and contentbased retrieval of multimedia documents. In C. Nikolaou and C. Stephanidis, editors, Proceedings of the 2nd European Conference on Digital Libraries (ECDL&apos;98), number 1513 in Lecture Notes in Computer Science, pages 409-428, Berlin. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shalom Lappin</author>
<author>Herbert Leass</author>
</authors>
<title>An algorithm for pronominal anaphora resolution.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<pages>20--4</pages>
<contexts>
<context position="20733" citStr="Lappin and Leass, 1994" startWordPosition="3261" endWordPosition="3264">s. The first is the full coreference task. The second one could be called markable-relative evaluation since the numbers are calculated only for the markables that have been successfully identified (in some sense, this concentrates on the coreference relation aspect of the coreference task). And the final evaluation result comes from a baseline model: &amp;quot;always select the closest antecedent candidate that is licensed by a rule and fulfills the distance and compatibility constraints from section 3.2&amp;quot;. 5 Related Work There are many recent approaches to this problem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches (Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Bennett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; 5The number of markables that are coreferential with some other markable ranges from 28 to 63 for the folds because the texts in the evaluation corpus were not broken up for cross-validation in order to yield statistical data about whole texts. Therefore the training corpus size varied between 439 and 4</context>
</contexts>
<marker>Lappin, Leass, 1994</marker>
<rawString>Shalom Lappin and Herbert Leass. 1994. An algorithm for pronominal anaphora resolution. Computational Linguistics, 20(4):535-561, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>uslan Mitkov R</author>
</authors>
<title>An uncertainty reasoning approach for anaphora resolution.</title>
<date>1995</date>
<booktitle>In Proceedings of the Natural Language Processing Pacific Rim Symposium (NLPR,S&apos;95),</booktitle>
<pages>149--154</pages>
<location>Seoul,</location>
<marker>R, 1995</marker>
<rawString>R,uslan Mitkov. 1995. An uncertainty reasoning approach for anaphora resolution. In Proceedings of the Natural Language Processing Pacific Rim Symposium (NLPR,S&apos;95), pages 149-154, Seoul, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>uslan Mitkov R</author>
</authors>
<title>Two engines are better than one: Generating more power and confidence in the search for the antecedent.</title>
<date>1997</date>
<booktitle>In R,uslan Mitkov and Nicolas Nicolov, editors, Recent Advances in Natural Language Processing: Selected Papers from R,ANLP&apos;95,</booktitle>
<pages>225--234</pages>
<publisher>John Benjamins,</publisher>
<location>Amsterdam.</location>
<marker>R, 1997</marker>
<rawString>R,uslan Mitkov. 1997. Two engines are better than one: Generating more power and confidence in the search for the antecedent. In R,uslan Mitkov and Nicolas Nicolov, editors, Recent Advances in Natural Language Processing: Selected Papers from R,ANLP&apos;95, pages 225-234. John Benjamins, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>uslan Mitkov R</author>
</authors>
<title>Evaluating anaphora resolution approaches.</title>
<date>1998</date>
<booktitle>In Proceedings of the Second Colloquium on Discourse Anaphora and Anaphor Resolution (DAAR,C 2),</booktitle>
<pages>164--177</pages>
<location>Lancaster, England.</location>
<marker>R, 1998</marker>
<rawString>R,uslan Mitkov. 1998a. Evaluating anaphora resolution approaches. In Proceedings of the Second Colloquium on Discourse Anaphora and Anaphor Resolution (DAAR,C 2), pages 164-177, Lancaster, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>uslan Mitkov R</author>
</authors>
<title>Robust pronoun resolution with limited knowledge.</title>
<date>1998</date>
<booktitle>In Proceedings of the 17th International Conference on Computational Linguistics and 36th Annual Meeting of the Association for Computational Linguistics (COLINGACL&apos;98),</booktitle>
<pages>869--875</pages>
<location>Montreal, Canada.</location>
<marker>R, 1998</marker>
<rawString>R,uslan Mitkov. 1998b. Robust pronoun resolution with limited knowledge. In Proceedings of the 17th International Conference on Computational Linguistics and 36th Annual Meeting of the Association for Computational Linguistics (COLINGACL&apos;98), pages 869-875, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>uslan Mitkov R</author>
</authors>
<title>Multilingual anaphora resolution.</title>
<date>1999</date>
<journal>Machine Translation,</journal>
<pages>14--281</pages>
<marker>R, 1999</marker>
<rawString>R,uslan Mitkov. 1999. Multilingual anaphora resolution. Machine Translation, 14:281-299.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wee Meng Soon</author>
<author>Hwee Tou Ng</author>
<author>Chung Yong Lim</author>
</authors>
<title>Corpus-based learning for nounphrase coreference resolution.</title>
<date>1999</date>
<booktitle>In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Very Large Corpora (Ell/INLP/VLC-99),</booktitle>
<pages>285--291</pages>
<location>College Park, Maryland.</location>
<contexts>
<context position="20883" citStr="Soon et al., 1999" startWordPosition="3283" endWordPosition="3286">les that have been successfully identified (in some sense, this concentrates on the coreference relation aspect of the coreference task). And the final evaluation result comes from a baseline model: &amp;quot;always select the closest antecedent candidate that is licensed by a rule and fulfills the distance and compatibility constraints from section 3.2&amp;quot;. 5 Related Work There are many recent approaches to this problem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches (Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Bennett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; 5The number of markables that are coreferential with some other markable ranges from 28 to 63 for the folds because the texts in the evaluation corpus were not broken up for cross-validation in order to yield statistical data about whole texts. Therefore the training corpus size varied between 439 and 474 and the test corpus between 28 and 63 during the cross-validation. fo(i, A) f (i, A) f3(i, A) := fi-&apos; ajeA/CA,011=k—j for 1 &lt; j &lt; k — 1 rf (i, A) :</context>
</contexts>
<marker>Soon, Ng, Lim, 1999</marker>
<rawString>Wee Meng Soon, Hwee Tou Ng, and Chung Yong Lim. 1999. Corpus-based learning for nounphrase coreference resolution. In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Very Large Corpora (Ell/INLP/VLC-99), pages 285-291, College Park, Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kees van Deemter</author>
<author>Rodger Kibble</author>
</authors>
<title>On coreferring: Coreference in MUC and related annotation schemes.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<pages>26--4</pages>
<marker>van Deemter, Kibble, 2000</marker>
<rawString>Kees van Deemter and Rodger Kibble. 2000. On coreferring: Coreference in MUC and related annotation schemes. Computational Linguistics, 26(4):629-637, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Renata Vieira</author>
<author>Massimo Poesio</author>
</authors>
<title>An empirically based system for processing definite descriptions.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>26</volume>
<issue>4</issue>
<pages>593</pages>
<contexts>
<context position="14114" citStr="Vieira and Poesio, 2000" startWordPosition="2211" endWordPosition="2214">third, the coreference rules. The nonreferable markable is used as the artificial anaphor of a nonreferring markable in order to represent all alternative references for a possible anaphor as a pair. For firstmentions, the disambiguation algorithm should select a coreference with the nonreferable markable as antecedent. Currently, one rule licenses the nonreferable markable as antecedent. But it might be useful to apply more finely grained rules and not just one rough licensing rule, as indicated by promising research results for definite descriptions referring to discourse-new entities (see (Vieira and Poesio, 2000)). 3.2 Disambiguating between antecedent candidates Step 3 of the algorithm given in section 3.1 is the most interesting one and needs some explanation. Leaving the issue of search algorithms aside for a moment, all possible and licensed partitions of identified markables are generated, filtered, and finally scored using estimated probabilities. The partitions are generated incrementally starting with the first possible anaphor in a singleton partition element. For each antecedent candidate licensed by a coreference rule in step 2, an extended partition with this antecedent in the same partiti</context>
</contexts>
<marker>Vieira, Poesio, 2000</marker>
<rawString>Renata Vieira and Massimo Poesio. 2000. An empirically based system for processing definite descriptions. Computational Linguistics, 26(4)539— 593, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Vilain</author>
<author>John Burger</author>
<author>John Aberdeen</author>
<author>Dennis Connolly</author>
<author>Lynette Hirschman</author>
</authors>
<title>A model-theoretic coreference scoring scheme.</title>
<date>1995</date>
<booktitle>In Proceedings of the 6th Message Understanding Conference (11/IUC-6),</booktitle>
<pages>45--52</pages>
<publisher>Morgan Kaufmann.</publisher>
<location>San Mateo.</location>
<contexts>
<context position="19827" citStr="Vilain et al. (1995)" startWordPosition="3125" endWordPosition="3128">all improvements have been achieved, but this topic has not been investigated completely yet. 4 Evaluation Evaluation results from 12-fold cross-validation for 502 anaphors5 are listed in Table 3. The standard definitions for recall and precision used in information retrieval are as follows: #true positives true positives ± #false negatives #true positives (10) true positives ± #false positives For coreference resolution, true positives are correct coreference links found, false negatives are correct coreference links not reported, and false positives are incorrect coreference links reported. Vilain et al. (1995) illustrate that these definitions sometimes yield counter-intuitive results for coreference evaluations and propose model-theoretic definitions of recall and precision. The values in Table 3 are calculated with these modified definitions. There are three different evaluation results. The first is the full coreference task. The second one could be called markable-relative evaluation since the numbers are calculated only for the markables that have been successfully identified (in some sense, this concentrates on the coreference relation aspect of the coreference task). And the final evaluation</context>
</contexts>
<marker>Vilain, Burger, Aberdeen, Connolly, Hirschman, 1995</marker>
<rawString>Marc Vilain, John Burger, John Aberdeen, Dennis Connolly, and Lynette Hirschman. 1995. A model-theoretic coreference scoring scheme. In Proceedings of the 6th Message Understanding Conference (11/IUC-6), pages 45-52, San Mateo. Morgan Kaufmann.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>