<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000009">
<title confidence="0.995233">
Joint Dependency Parsing and Multiword Expression Tokenisation
</title>
<author confidence="0.996169">
Alexis Nasr, Carlos Ramisch, Jos´e Deulofeu, Andr´e Valli
</author>
<affiliation confidence="0.962195">
Aix Marseille Universit´e, CNRS, LIF UMR 7279
</affiliation>
<address confidence="0.88041">
Marseille, France
</address>
<email confidence="0.993463">
FirstName.LastName@lif.univ-mrs.fr
</email>
<sectionHeader confidence="0.993736" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999692555555556">
Complex conjunctions and determiners
are often considered as pretokenized units
in parsing. This is not always realistic,
since they can be ambiguous. We pro-
pose a model for joint dependency parsing
and multiword expressions identification,
in which complex function words are rep-
resented as individual tokens linked with
morphological dependencies. Our graph-
based parser includes standard second-
order features and verbal subcategoriza-
tion features derived from a syntactic lex-
icon.We train it on a modified version of
the French Treebank enriched with mor-
phological dependencies. It recognizes
81.79% of ADV+que conjunctions with
91.57% precision, and 82.74% of de+DET
determiners with 86.70% precision.
</bodyText>
<sectionHeader confidence="0.99899" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999819666666667">
Standard NLP tool suites for text analysis are of-
ten made of several processes that are organized
as a pipeline, in which the input of a process is
the output of the preceding one. Among these
processes, one commonly finds a tokenizer, which
segments a sentence into words, a part-of-speech
(POS) tagger, which associates to every word a
part-of-speech tag, and a syntactic parser, which
builds a parse tree for the sentence1. These three
processes correspond to three formal operations
on the string: segmentation into linguistically rel-
evant units (words), tagging the words with POS
tags and linking the (word, POS) pairs by means
of syntactic dependencies.
This setup is clearly not ideal, as some decisions
are made too early in the pipeline (Branco and
Silva, 2003). More specifically, some tokenization
and tagging choices are difficult to make without
</bodyText>
<footnote confidence="0.546219">
1This paper considers dependency syntactic structures.
</footnote>
<bodyText confidence="0.999524129032258">
taking syntax into account. To avoid the pitfall of
premature decisions, probabilistic tokenizers and
taggers can produce several solutions in the form
of lattices (Green and Manning, 2010; Goldberg
and Elhadad, 2011). Such approaches usually lead
to severe computational overhead due to the huge
search space in which the parser looks for the opti-
mal parse tree. Besides, the parser might be biased
towards short solutions, as it compares scores of
trees associated to sequences of different lengths
(De La Clergerie, 2013).
This problem is particularly hard when parsing
multiword expressions (MWEs), that is, groups of
tokens that must be treated as single units (Bald-
win and Kim, 2010). The solution we present
in this paper is different from the usual pipeline.
We propose to jointly parse and tokenize MWEs,
transforming segmentation decisions into linking
decisions. Our experiments concentrate on two
difficult tokenization cases. Hence, it is the parser
that will choose, in such cases, whether to group
or not several tokens.
Our first target phenomenon is the family of
ADV+que constructions, a type of complex con-
junction in French. They are formed by adverbs
like bien (well) or ainsi (likewise) followed by the
subordinative conjunction que (that). They func-
tion like English complex conjunctions so that and
now that. Due to their structure, ADV+que con-
structions are generally ambiguous, like in the fol-
lowing examples:
</bodyText>
<listItem confidence="0.9106665">
1. Je mange bien que je n’aie pas faim
I eat although I am not hungry
2. Je pense bien que je n’ai pas faim
I think indeed that I am not hungry
</listItem>
<bodyText confidence="0.9995962">
In example 1, the sequence bien que forms a
complex conjunction (although) whereas in exam-
ple 2, the adverb bien (indeed) modifies the verb
pense (think), and the conjunction que (that) intro-
duces the sentential complement je n’ai pas faim
</bodyText>
<page confidence="0.94235">
1116
</page>
<note confidence="0.976547333333333">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 1116–1126,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<bodyText confidence="0.998482">
(I am not hungry). In treebanks, the different read-
ings are represented through the use of words-
with-spaces in the case of complex conjunctions.
Our second target phenomenon is the family of
partitive articles which are made of the preposition
de (of) followed by the definite determiner le, la,
l’ or les2 (the). These de+DET constructions are
ambiguous, as shown in the following examples:
</bodyText>
<listItem confidence="0.994338333333333">
3. Il boit de la bi`ere
He drinks some beer
4. Il parle de la bi`ere
</listItem>
<bodyText confidence="0.994602914285714">
I talks about the beer
In example 3, the sequence de la forms a deter-
miner (some) whereas in example 4, de is a prepo-
sition (about) and la is the determiner (the) of the
noun bi`ere (bi`ere).
We focus on these constructions for two rea-
sons. First, because they are extremely frequent.
For instance, in the frWaC corpus, from a total of
54.8M sentences, 1.15M sentences (2.1%) contain
one or more occurrences of our target ADV+que
constructions and 26.7M sentences (48.6%) con-
tain a de+DET construction (see Tables 1 and 2).
Moreover, in a corpus of 370 M words in French,3
des is the 7th most frequent word. Second, be-
cause they are perfect examples of phenomena
which are difficult to process by a tokenizer. In or-
der to decide, in example 1, that bien que is a com-
plex subordinate conjunction, non-trivial morpho-
logical, lexical and syntactic clues must be taken
into account, such as the subcategorization frame
of the verb of the principal clause and the mood of
the subordinate clause. All these clues are difficult
to take into account during tokenization, where the
syntactic structure of the sentence is not yet ex-
plicit.
Ask the parser to perform tokenization will not
always solve the problem. Even state-of-the-art
parsers can fail to predict the right structure for
the cases we are dealing with. The main reason
is that they are trained on treebanks of limited
size, and some lexico-syntactic phenomena can-
not be well modeled. This brings us to the sec-
ond topic of this paper, which is the integration of
external linguistic resources in a treebank-trained
probabilistic parser. We show that, in order to cor-
</bodyText>
<footnote confidence="0.9079734">
2Sequences de le and de les do not appear as such in
French. They have undergone a morpho-phonetic process
known as amalgamation and are represented as tokens du and
des. In our pipeline, they are artificially detokenized.
3Newspaper Le Monde from 1986 to 2002.
</footnote>
<bodyText confidence="0.999939882352941">
rectly solve the two problems at hand, the parser
must have access to lexico-syntactic information
that can be found in a syntactic lexicon. We pro-
pose a simple way to introduce such information in
the parser by defining new linguistic features that
blend smoothly with treebank features used by the
parser when looking for the optimal parse tree.
The paper is organized as follows: Section 2 de-
scribes related work on MWE parsing. Section 3
proposes a way to represent multiword units by
means of syntactic dependencies. In Section 4, we
briefly describe the parser that has been used in
this work, and in Section 5, we propose a way to
integrate a syntactic lexicon into the parser. Sec-
tion 6 describes the data sets used for the experi-
ments, which results are presented and discussed
in Section 7. Section 8 concludes the paper.
</bodyText>
<sectionHeader confidence="0.999782" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999770875">
The famous “pain-in-the-neck” article by Sag et
al. (2002) discusses MWEs in parsers, contrasting
two representation alternatives in the LinGO ERG
HPSG grammar of English: compositional rules
and words-with-spaces. The addition of composi-
tional rules for flexible MWEs has been tested in a
small-scale experiment which showed significant
coverage improvements in HPSG parsing by the
addition of 21 new MWEs to the grammar (Villav-
icencio et al., 2007).
It has been demonstrated that pre-grouping
MWEs as words-with-spaces can improve the per-
formance of shallow parsing for English (Ko-
rkontzelos and Manandhar, 2010). Nivre and Nils-
son (2004) obtained similar results for dependency
parsing of Swedish. They compare models trained
on two representations: one where MWEs are
linked by a special ID dependency, and another
one based on gold pre-tokenization. Their results
show that the former model can recognize MWEs
with F1=71.1%, while the latter can significantly
improve parsing accuracy and robustness in gen-
eral. However, the authors admit that “it remains
to be seen how much of theoretically possible im-
provement can be realized when using automatic
methods for MWU recognition”.
Several methods of increasing complexity have
been proposed for fully automatic MWE tokeniza-
tion: simple lexicon projection onto a corpus
(Kulkarni and Finlayson, 2011), synchronous lex-
icon lookup and parsing (Wehrli et al., 2010; Sere-
tan, 2011), token-based classifiers trained using
</bodyText>
<page confidence="0.991794">
1117
</page>
<bodyText confidence="0.999914626865672">
association measures and other contextual features
(Vincze et al., 2013a), or contextual sequence
models like conditional random fields (Constant
and Sigogne, 2011; Constant et al., 2013b; Vincze
et al., 2013b) and structured perceptron (Schnei-
der et al., 2014). In theory, compound function
words like ADV+que and de+DET allow no inter-
nal variability, thus they should be represented as
words-with-spaces. However, to date no satisfac-
tory solution has been proposed for automatically
tokenizing ambiguous MWEs.
Green et al. (2013) propose a constituency pars-
ing model which, as a by-product, performs MWE
identification. They propose a flat representation
for contiguous expressions in which all elements
are attached to a special node, and then they com-
pare several parsing models, including an origi-
nal factored-lexicon PCFG and a tree substitution
grammar. These generic parsing models can be
used for parsing in general, but they have inter-
esting memorization properties which favor MWE
identification. Their experiments on French and
Arabic show that the proposed models beat the
baseline in MWE identification while producing
acceptable general parsing results.
Candito and Constant (2014) and Vincze et al.
(2013c) present experiments on dependency pars-
ing for MWE identification which are the closest
to our settings. Vincze et al. (2013c) focus on light
verb constructions in Hungarian. They propose
distinguishing regular verbal dependencies from
light verbs and their complements through four
special labels prefixed by LCV-. Then, they train
the Bohnet parser (Bohnet, 2010) using standard
parameters and features, and evaluate on a gold
test set. They report no significant changes in at-
tachment scores, whereas F1 for light verb iden-
tification is 75.63%, significantly higher than the
baseline methods of lexicon projection (21.25%)
and classification (74.45%).
Candito and Constant (2014) compare several
architectures for dependency parsing and MWE
identification in French. For regular MWEs like
noun compounds, they use regular expressions to
automatically generate an internal syntactic struc-
ture, combining standard and MWE-dedicated de-
pendency labels. Irregular expressions like com-
plex conjunctions are represented as separate to-
kens, with a special DEP CPD dependency that
links all tokens to the first MWE word (Constant
et al., 2013a). They compare different architec-
tures for MWE identification before, during and
after parsing, showing that the best architecture
depends on whether the target MWEs are regular
or irregular.
Similarly to these two papers, we use a special
dependency to model MWEs and evaluate pars-
ing and identification accuracy. Our work departs
from theirs on three important aspects. First, we
concentrate on syntactically irregular compounds,
that we represent with a new kind of dependency.
Second, we integrate into the parser a syntactic
lexicon in order to help disambiguate ADV+que
and de+DET constructions. Third, we built a spe-
cific evaluation corpus to get a better estimation of
the performances of our model on ADV+que and
de+DET constructions.
</bodyText>
<sectionHeader confidence="0.998408" genericHeader="method">
3 The MORPH Dependency
</sectionHeader>
<bodyText confidence="0.999973470588235">
In order to let the parser take the tokenization de-
cisions, we propose not to group sequences of to-
kens of the form ADV+que and de+DET at tok-
enization time. Instead, we transform the task of
segmentation decision into a parsing decision task.
We associate a syntactic structure to ADV+que
and de+DET constructions by introducing a new
type of dependency that we call MORPH. It is not
a standard syntactic dependency, but a reminiscent
of the morphological dependencies of Mel’ˇcuk
(1988), similar to the DEP CPD label proposed by
Candito and Constant (2014) or the ID depen-
dency of Nivre and Nilsson (2004), except that we
focus on syntactically-motivated MWEs, propos-
ing a regular structure for them.
The syntactic structures of examples 1 and 2,
introduced in Section 1, are represented below4.
</bodyText>
<construct confidence="0.375553">
Example 1.
CLS VRB ADV CSU ... VRB ...
Je mange bien que ... aie ...
Example 2.
CLS VRB ADV CSU ... VRB ...
Je pense bien que ... ai ...
</construct>
<footnote confidence="0.814225">
4In the examples, parts of speech CLS, VRB, ADV and CSU
respectively stand for subject clitic pronoun, verb, adverb and
subordinating conjunction. Syntactic labels SUJ, MOD, OBJ,
DE-OBJ and SPE stand for subject, modifier, object, indirect
object introduced by the preposition de and specifier.
</footnote>
<figure confidence="0.99238925">
SUJ
MOD
MORPH
OBJ
SUJ
MOD
OBJ
OBJ
</figure>
<page confidence="0.970609">
1118
</page>
<bodyText confidence="0.999867384615384">
In example 1, the complex conjunction bien que
is represented by the presence of the MORPH de-
pendency, whereas, in example 2, the adverb bien
modifies the verb pense and que introduces its ob-
ject. From an NLP perspective, the two readings
are treated the same way by the tokenizer and the
tagger. It is only at parsing time that the presence
of the complex conjunction is predicted.
The syntactic structures of examples 3 and 4 are
represented below. In example 3, the partitive ar-
ticle de la is represented by means of the MORPH
dependency. Example 4 exhibits a standard prepo-
sitional phrase structure.
</bodyText>
<figure confidence="0.598484833333333">
Example 3.
CLI VRB PRE DET NOM
Il boit de la bi`ere
Example 4.
CLI VRB PRE DET NOM
Il parle de la bi`ere
</figure>
<sectionHeader confidence="0.93367" genericHeader="method">
4 Parsing
</sectionHeader>
<bodyText confidence="0.9961116">
The parser used in this study is a second-order
graph-based parser (K¨ubler et al., 2009). Given
a sentence W = w1 ... wl, the parser looks for the
dependency tree Tˆ of W that maximizes the score
s:
</bodyText>
<equation confidence="0.9867705">
1: Tˆ = arg max s(F)
TET(W) FEF(T)
</equation>
<bodyText confidence="0.999951923076923">
where T (W) is the set of all possible depen-
dency trees for sentence W and F(T) is the set of
all relevant subparts, called factors, of tree T and
s(F) is the score of factor F. The values of these
scores are parameters estimated during training.
We can define different models of increasing
complexity depending on the decomposition of the
tree into factors. The most simple one is the arc-
factored or first-order model, which simply de-
composes a tree into single dependencies and as-
signs them a score, independently of their context.
We used a second-order parser which decomposes
a tree into factors of three types:
</bodyText>
<listItem confidence="0.918841333333333">
1. first-order factors, made of one dependency;
2. sibling factors, made of two dependencies
sharing a common governor;
3. grandchildren factors, made of two depen-
dencies where the dependent of one of them
is the governor of the other one.
</listItem>
<sectionHeader confidence="0.4883" genericHeader="method">
5 Integration with a Syntactic Lexicon
</sectionHeader>
<bodyText confidence="0.999984083333333">
Although this kind of parsers achieve state-of-the-
art performances (Bohnet, 2010), their predictions
are limited to the phenomena that occur in the tree-
banks they are trained on. In particular, they of-
ten fail at correctly distinguishing elements that
are subcategorized by a verb (henceforth comple-
ments) from others (modifiers). This is due to the
fact that the nature and number of the comple-
ments is specific to each verb. If the verb did not
occur, or did not occur often enough, in the tree-
bank, the nature and number of its complements
will not be correctly modeled by the parser.
A precise description of verb complements
plays an important role in the task of predicting
the MORPH dependency, as we illustrate in exam-
ple 1. In this example, the verb manger (eat) does
not accept an object introduced by the subordinate
conjunction que (that) . This is a vital information
in order to predict the correct syntactic structure
of the sentence. If the parser cannot link the con-
junction que to the verb manger with an OBJ de-
pendency, then it has to link it with a MOD depen-
dency (it has no other reasonable solution). But
que by itself cannot be a MOD of the verb unless it
is a complex conjunction. The parser has therefore
no other choice than linking que with the adverb
using a MORPH dependency.
In order to help the parser build the right
solution in such cases, we have introduced infor-
mation derived from a syntactic lexicon in the
parser. The syntactic lexicon associates, each
verb lemma, the features +/-QUE and +/-DE, that
indicate respectively if the verb accepts an object
introduced by the subordinating conjunction que
and by the preposition de. The verbs of our
examples would have the following values:
</bodyText>
<footnote confidence="0.479836">
manger -QUE -DE
penser +QUE -DE
boire -QUE -DE
parler -QUE +DE
</footnote>
<bodyText confidence="0.9999405">
We will call such features subcat features (SFs).
The semantics of positive feature values are quite
different from the semantics of negative ones. The
former indicates that a verb may (but does not need
to) license a complement introduced by the con-
junction que or the preposition de, whereas the
</bodyText>
<figure confidence="0.994384625">
SUJ
MORPH
OBJ
SPE
SUJ
DE-OBJ
OBJ
SPE
</figure>
<page confidence="0.990903">
1119
</page>
<bodyText confidence="0.999767533333333">
latter indicates that the verb cannot license such a
complement. Negative feature values have, there-
fore, a higher predictive power.
Every verbal lemma occurrence in the treebank
is enriched with subcat features and three new fac-
tor templates have been defined in the parser in or-
der to model the co-occurrence of subcat features
and some syntactic configurations. These tem-
plates are represented in Figure 1. The first one is
a first-order template and the others are grandchil-
dren templates. In the template description, G, D
and GD stand respectively for governor, dependent
and grand-dependent. SF, POS, FCT and LEM re-
spectively stand for subcat feature, part of speech,
syntactic function and lemma.
</bodyText>
<figure confidence="0.392839333333333">
1 G.SF G.POS D.FCT D.POS
2 G.SF G.POS D.FCT D.POS GD.POS
3 G.SF G.POS D.FCT D.LEM GD.POS
</figure>
<figureCaption confidence="0.937834">
Figure 1: Factor templates modeling the co-
</figureCaption>
<bodyText confidence="0.990732785714286">
occurrence of subcat features and syntactic con-
figurations.
Two factors, of the types 1 and 3, have been rep-
resented in Figure 2. The first one models the co-
occurrence of subcat feature -QUE and an object
introduced by a subordinating conjunction. Such
feature will receive a negative score at the end
of training, since a verb having the -QUE feature
should not license a direct object introduced by
a subordinating conjunction. The second feature
models the co-occurrence of the feature -QUE and
a modifier introduced by the subordinating con-
junction QUE and having an adverb as a depen-
dent. Such a feature will receive a positive score.
</bodyText>
<sectionHeader confidence="0.5573805" genericHeader="method">
1 -QUE VRB OBJ CSU
3 -QUE VRB MOD QUE ADV
</sectionHeader>
<figureCaption confidence="0.974996">
Figure 2: Two factors modeling the co-occurrence
of subcat features and syntactic configurations.
</figureCaption>
<sectionHeader confidence="0.998779" genericHeader="method">
6 Experimental Setup
</sectionHeader>
<bodyText confidence="0.99989095">
We test the proposed model to verify the linguistic
plausibility and computational feasibility of using
MORPH links to represent syntactically idiosyn-
cratic MWEs in a dependency parser enriched
with subcat features. Therefore, we train a prob-
abilistic dependency parsing model on modified
treebank, representing ADV+que and de+DET con-
structions using this special syntactic relation in-
stead of pretokenization. Furthermore, in addition
to regular features learned from the treebank, we
also introduce and evaluate subcat features based
on a lexicon of verbal valency, which helps iden-
tifying subordinative clauses and de prepositional
phrases (see Section 5). We evaluate parsing pre-
cision and MWE identification on a test treebank
and, more importantly, on a dataset built specifi-
cally to study the representation of our target con-
structions. All experiments used the NLP tool
suite MACAON5, which comprises a second-order
graph-based parser.
</bodyText>
<subsectionHeader confidence="0.999671">
6.1 Data Sets and Resources
</subsectionHeader>
<bodyText confidence="0.999628342857143">
French Treebank (FTB) The parser was trained
on the French Treebank, a syntactically annotated
corpus of news articles from Le Monde (Abeill´e et
al., 2003). We used the version which was trans-
formed into dependency trees by Candito et al.
(2009), and which was also used by Candito and
Constant (2014) for experiments on MWE pars-
ing. We used a standard split of 9,881 sentences
(278K words) for training and 1,235 sentences
for test (36K words). We applied simple rules to
transform the flat representation of ADV+que and
de+DET constructions into MORPH-linked individ-
ual tokens. All other MWEs are kept unchanged in
training and test data. They are represented as sin-
gle tokens, not decomposed into individual words.
MORPH Dataset The test portion of the FTB
contains relatively few instances of our target con-
structions (see Tables 4 and 6). Thus, we have
created two specific data sets to evaluate the pre-
diction of MORPH links. As for ADV+que con-
structions, we manually selected the 7 most po-
tentially ambiguous combinations from the top-20
most frequent combinations in the French Web as
Corpus – frWaC (Baroni and Bernardini, 2006).6
As for de+DET constructions, we selected all 4
possible combinations. For each target ADV+que
and de+DET construction, we randomly selected
1,000 sentences from the frWaC based on two cri-
teria: (1) sentences should contain only one oc-
currence of the target construction and (2) sen-
tences should have between 10 and 20 words, to
avoid distracting the annotators while still provid-
ing enough context. Additionally, for de+DET we
selected only sentences in which a verb preceded
the construction, in order to minimize the occur-
</bodyText>
<footnote confidence="0.999962">
5http://macaon.lif.univ-mrs.fr
6http://wacky.sslmit.unibo.it/
</footnote>
<page confidence="0.957076">
1120
</page>
<table confidence="0.999892333333333">
ADV+que #sent conj. other #occur
ainsi 103 76.7 23.3 498,377
alors 110 88.2 11.8 291,235
autant 107 86.0 14.0 39,401
bien 99 37.4 62.6 156,798
encore 93 21.5 78.5 18,394
maintenant 120 55.8 44.2 16,567
tant 98 20.4 79.6 168,485
Total 730 56.4 43.6 1,189,257
</table>
<tableCaption confidence="0.9398774">
Table 1: Annotations for ADV+que combinations
in MORPH dataset: number of annotated sen-
tences, proportion (%) of complex conjunction
uses (MORPH) and other uses, number of occur-
rences in frWaC.
</tableCaption>
<table confidence="0.999872833333333">
de+DET #sent det. other #occur
le (du) 136 33.1 66.9 16,609,049
la 138 21.0 79.0 10,849,384
les (des) 129 77.5 22.5 23,395,857
l’ 136 16.9 83.1 8,204,687
Total 539 36.5 63.5 59,058,977
</table>
<tableCaption confidence="0.907907">
Table 2: Annotations for de+DET combina-
</tableCaption>
<bodyText confidence="0.989894956521739">
tions MORPH dataset: number of annotated sen-
tences, proportion (%) of complex determiner uses
(MORPH) and other uses, number of occurrences
in frWaC.
rence of nominal complements (pr´esident de la
r´epublique - president of the republic) and focus
on the determiner/preposition ambiguity. Two ex-
pert French native speakers annotated around 100
sentences per construction. Malformed or am-
biguous sentences were discarded. Disagreements
were either discussed and resolved or the sentence
was discarded.7
We can see in Table 1 that ADV+que construc-
tions are highly ambiguous, with 56.4% of the
cases being complex conjunctions. However, they
also present high variability: even though they
share identical syntactic behavior, some of them
tend to form complex conjunctions very often
(alors) while others occur more often in other syn-
tactic configurations (tant and encore). As one can
see in Table 2, de+DET sequences tend to function
as prepositions followed by a determiner with the
notable exception of de les. The reason is that de
</bodyText>
<footnote confidence="0.963942666666667">
7The dataset is available at http://pageperso.
lif.univ-mrs.fr/%7Ecarlos.ramisch/?page=
downloads/morph
</footnote>
<bodyText confidence="0.99991225">
les (actually the amalgame des) is actually the plu-
ral of the indefinite article (un), used with any plu-
ral noun, while the other determiners are partitives
that tend to be used only with massive nouns. The
last column of these tables shows the number of
occurrences of each construction in the frWaC cor-
pus. We can see that they are very recurrent com-
binations, specially de+DET constructions, which
account for 3.7% of the total number of bigrams
in the corpus. This underlines the importance of
correctly predicting their syntactic structure in a
parser.
DicoValence Lexicon DicoValence (van den
Eynde and Mertens, 2003) is a lexical resource
which lists the subcategorization frames of more
than 3, 700 French verbs.8 It describes more
specifically the number and nature of the verbs’
complements. Dicovalence gives a more fine-
grained description of the complements than what
is needed in our feature templates. We have only
kept, as described in Section 5, the subcat features
-QUE, +QUE, -DE and +DE of each verb. Table 3
below shows the number of verbal entries having
each of our four subcat features. Although the
number of verbs described in DicoValence is mod-
erate, its coverage is high on our data sets. It is
equal to 97.82% on the FTB test set and is equal
to 95.48% on the MORPH dataset.
</bodyText>
<table confidence="0.9303215">
-QUE +QUE -DE +DE
3,814 356 3,450 720
</table>
<tableCaption confidence="0.9751475">
Table 3: Number of verbs in DicoValence per
value of subcat feature.
</tableCaption>
<subsectionHeader confidence="0.993287">
6.2 Evaluation
</subsectionHeader>
<bodyText confidence="0.99963">
We evaluate our models on two aspects: parsing
quality and MWE identification (Nivre and Nils-
son, 2004; Vincze et al., 2013c; Candito and Con-
stant, 2014). First, we use standard parsing at-
tachment scores to verify whether our models im-
pact parsing performance in general. We compare
the generated dependency trees with the reference
in the test portion of the FTB, reporting the pro-
portion of matched links, both in terms of struc-
ture – unlabeled attachment score (UAS) – and of
labeled links – labeled attachment score (LAS).
Since our focus is on MWE parsing, we are also
</bodyText>
<footnote confidence="0.9959555">
8http://bach.arts.kuleuven.be/
dicovalence/
</footnote>
<page confidence="0.996437">
1121
</page>
<bodyText confidence="0.999984976190476">
interested in MWE identification metrics. We fo-
cus on words whose dependency label is MORPH
and calculate the proportion of correctly predicted
MORPH links among those in the parser output
(precision), among those in the reference (recall)
and the F1 average. Since some of the phenomena
are quite rare in the FTB test portion, we focus
on the MORPH dataset, which contains around 100
instances of each target construction.
We compare our approach with two simple
baselines. The first one consists in pretokenizing
ADV+que systematically as a single token, while
de+DET is systematically left as two separate to-
kens. This baseline emulates the behavior of most
parsing pipelines, which deal with functional com-
plex words during tokenization. This corresponds
to choosing the majority classes in the last row of
Tables 1 and 2. For ADV+que, the precision of the
baseline is 56.4%. If we assume recall is 100%,
this yields an F1 score of 72.2%. For de+DET,
however, recall is 0% since no MORPH link is pre-
dicted at all. Therefore, we only look at the base-
line’s precision of 63.5%. A second, slightly more
sophisticated baseline, consists in choosing the
majority class for each individual construction and
average precisions over the constructions. In this
case, the average precision is 75.3% for ADV+que
and 76.6% for de+DET.
We compare our model to the one proposed
by Green et al. (2013). We used the pretrained
model available as part of the Stanford parser9.
Their model outputs constituent trees, which were
automatically converted to unlabeled dependency
structures. We ignore the nature of the dependency
link, only checking whether the target construction
elements are linked in the correct order.
Our experiments use the MACAON tool suite.
For the FTB, gold POS and gold lemmas are given
as input to the parser. In the case of the MORPH
dataset, for which we do not have gold POS and
lemmas, they are predicted by MACAON. The first
best prediction is given as input to the parser.
</bodyText>
<sectionHeader confidence="0.995885" genericHeader="evaluation">
7 Evaluation Results
</sectionHeader>
<subsectionHeader confidence="0.989774">
7.1 ADV+que Constructions
</subsectionHeader>
<bodyText confidence="0.9456675">
Table 4 reports the performances of the parser10
on the test set of FTB. The rows of the table
</bodyText>
<footnote confidence="0.9976566">
9http://nlp.stanford.edu/software/
lex-parser.shtml
10Trained on the modified train set of the FTB, where com-
plex conjunctions and partitive determiners have been repre-
sented by means of the MORPH dependency
</footnote>
<table confidence="0.641721333333333">
SF LAS UAS MORPH Prec. Rec.
no 88.98 90.63 27 87.10 100
yes 88.96 90.56 27 81.81 100
</table>
<tableCaption confidence="0.955631">
Table 4: Attachment scores, count, precision and
</tableCaption>
<bodyText confidence="0.999150177777778">
recall of the MORPH dependency for ADV+que in
FTB test, without and with subcat features (SF).
respectively display the results obtained without
and with the use of subcat features (SF). The sec-
ond and third columns represent standard attach-
ment metrics, column four displays the number of
ADV+que conjunctions present in the FTB test set
FTB and the two last columns show the precision
and recall of the MORPH dependency prediction.
The table shows that the number of occurrences
of ADV+que conjunctions is very small (27). It is
therefore difficult draw clear conclusions concern-
ing the task of predicting the MORPH dependency.
The precision and recall have nevertheless been re-
ported. The recall is perfect (all MORPH depen-
dencies have been predicted) and the the precision
is reasonable (the parser overpredicts a little). The
table also shows that the use of subcat features is
not beneficial, as attachment scores as well as pre-
cision decrease. The decrease of precision is mis-
leading, though, due to the small number of occur-
rences it has been computed on.
Table 5 displays the precision, recall and F1 of
the prediction of the MORPH dependency on the
730 ADV+que sentences of the MORPH dataset,
without and with the use of subcat features. The
scores obtained are lower than the same experi-
ments on the FTB.Precision is higher than recall,
which indicates that the parser has a tendency to
underpredict. We also present the precision of
the two baselines described in Section 6.2. Only
in two cases the per-construction majority base-
line (indiv.) outperforms our parser without sub-
cat features. These two constructions do not tend
to form complex conjunctions, that is, the parser
overgenerates MORPH dependencies. Here, subcat
features help increasing precision, systematically
outperforming the baselines.
The introduction of subcat features has a ben-
eficial but limited impact on the results, increas-
ing precision and lowering a bit recall, augment-
ing the tendency of the parser to under predict
MORPH dependencies. Overall, our models are
more precise than the Stanford parser at predict-
ing MORPH links, specially for bien que and en-
</bodyText>
<page confidence="0.981374">
1122
</page>
<table confidence="0.963924909090909">
Baseline prec. Green et Without SF With SF
al. (2013)
ADV+que global indiv. Prec. Recall F1 Prec. Recall F1
ainsi que 76.7 76.7 81.44 96.00 91.14 93.50 95.94 89.87 92.81
alors que 88.2 88.2 95.10 92.78 92.78 92.78 93.81 93.81 93.81
autant que 86.0 86.0 92.00 86.95 65.21 74.53 86.66 70.65 77.84
bien que 37.4 62.6 55.22 86.84 89.18 88.00 91.66 89.18 90.41
encore que 21.5 78.5 64.52 72.72 80.00 76.19 92.85 65.00 76.47
maintenant que 55.8 55.8 87.01 85.24 77.61 81.25 90.91 74.62 81.96
tant que 20.4 79.6 90.91 78.94 75.00 76.92 82.35 70.00 75.67
Total 56.4 75.3 83.06 88.71 82.03 85.24 91.57 81.79 86.41
</table>
<tableCaption confidence="0.994487">
Table 5: MORPH link prediction for ADV+que constructions: precision of global majority baseline, preci-
</tableCaption>
<bodyText confidence="0.983433470588235">
sion of individual per-construction baseline, precision of Green et al. (2013) constituent parser, precision,
recall and F1 of our dependency parser without and with subcat features.
core que. However, this is not verified for all in-
dividual ADV+que constructions. The table also
shows an important variety among the seven com-
plex conjunctions studied. Some of them are very
well predicted (F1 = 93.5) while others are poorly
predicted (F1 = 75.67). This is partly due to the
tendency of some ADV+que sequences to be part
of larger frozen or semi-frozen constructions and
to be used with a different semantico-syntactic be-
havior. An error analysis performed on the tant
que sequence revealed that 40% of the errors were
due to the occurrence of tant que as part of the
larger en tant que expression, while 20% of the
errors were due to the usage of tant que as a com-
parative expression.
</bodyText>
<subsectionHeader confidence="0.684511">
7.2 de+DET Constructions
</subsectionHeader>
<bodyText confidence="0.959269775">
SF LAS UAS MORPH Prec. Rec.
no 89.02 90.23 145 85.85 81.12
yes 88.37 89.67 145 86.52 83.92
Table 6: Attachment scores, count, precision and
recall of the MORPH dependency for de+DET in
FTB test, without and with subcat features (SF).
Table 6 reports the results of the same experi-
ments on de+DET constructions. It shows that the
frequency of de+DET constructions is higher than
ADV+que constructions. It also shows that the in-
troduction of subcat features has a positive impact
on the prediction of the MORPH dependency, but a
negative effect on the attachment scores.
Table 7 reveals that the prediction of the correct
structure of de+DET constructions is more difficult
than that of ADV+que constructions for the parser.
Here, not only the majority class is the non-MWE
analysis (63.5%), but also there is higher ambigu-
ity because of nominal and adverbial complements
that have the same structure. This impacts the per-
formance of the Stanford parser, which overgener-
ates MORPH links, achieving the lowest precision
for all constructions except for des. Results also
show that the introduction of subcat features has
an important impact on the quality of the predic-
tion (F1 jumps from 75% to 84.67%). The use
of subcat features slightly improves the identifi-
cation of de les, which is a determiner most of
the time. On the other hand, it greatly improves
F1 for other constructions, which appear less of-
ten as determiners. We believe that the higher im-
pact of subcat frames on de+DET is mainly due to
the fact that the number of verbs licensing comple-
ments introduced by the preposition de is higher
than the number of verbs licensing complements
introduced by the conjunction que (see Table 3).
Therefore, the parser trained without subcat fea-
tures can only rely on the examples present in the
FTB which are proportionally smaller in the first
case than in the second.
</bodyText>
<sectionHeader confidence="0.998874" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.9998494">
This paper introduced and evaluated a joint pars-
ing and MWE identification model that can ef-
fectively detect and represent ambiguous com-
plex function words. The difficulty of process-
ing such expressions is underestimated because
of their limited variability. They often are pre-
grouped as words-with-spaces in many parsing ar-
chitectures (Sag et al., 2002). However, we did
not use gold tokenization, unrealistic for ambigu-
ous MWEs (Nivre and Nilsson, 2004; Korkontze-
</bodyText>
<page confidence="0.907005">
1123
</page>
<table confidence="0.94593175">
Baseline prec. Green et Without SF With SF
al. (2013)
de+DET global indiv. Prec. Recall F1 Prec. Recall F1
de le 66.9 79.0 56.96 72.50 64.44 68.23 85.41 91.11 88.17
de la 79.0 77.5 22.83 58.13 86.20 69.44 81.25 89.65 85.24
de les 22.5 66.9 87.72 97.36 74.00 84.09 98.70 76.00 85.87
de l’ 83.1 83.1 18.55 57.14 69.56 62.74 64.51 86.95 74.07
Total 63.5 76.6 44.37 77.00 73.09 75.00 86.70 82.74 84.67
</table>
<tableCaption confidence="0.995806">
Table 7: MORPH link prediction for de+DET constructions: precision of global majority baseline, preci-
</tableCaption>
<bodyText confidence="0.992318926829268">
sion of individual per-construction baseline, precision of Green et al. (2013) constituent parser, precision,
recall and F1 of our dependency parser without and with subcat features.
los and Manandhar, 2010).
We proposed to deal with these constructions
during parsing, when the required syntactic infor-
mation to disambiguate them is available. Thus,
we trained a graph-based dependency parser on a
modified treebank where complex function words
were linked with a MORPH dependency. Our re-
sults demonstrate that a standard parsing model
can correctly learn such special links and predict
them for unseen constructions. Nonetheless, the
model is more accurate when we integrate exter-
nal information from a syntactic lexicon. This
improved precision for ADV+que and specially
de+DET constructions. For the latter, F1 improved
in almost 10%, going from 75% to 84.61%.
This study raised several linguistic and compu-
tational questions. Some complex function words
include more than two elements, like si bien que
(so much that) and d’autant (plus) que (especially
as). Moreover, they may contain nested expres-
sions with different meanings and structures, e.g.
tant que (as long as) is a conjunction but en tant
que (as) is a preposition. The same applies for
quantified partitive determiners, like beaucoup de
(much) and un (petit) peu de (a (little) bit of).
Their identification and representation is planned
as a future extension to this work.
We also would like to compare our approach to
sequence models (Schneider et al., 2014). Care-
ful error analysis could help us understand in
which cases syntactic features can help. More-
over, different variants of the syntactic features
and more sophisticated representation for syntac-
tic lexicons can help improve MWE parsing fur-
ther. For instance, we represent the subcat fea-
tures of pronominal verbs and their simple ver-
sions with the same features, but they should be
distinguished, e.g. se rappeler (remember) is +DE
but rappeler (remind) is -DE.
</bodyText>
<sectionHeader confidence="0.994731" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9986702">
This work has been funded by the French Agence
Nationale pour la Recherche, through the projects
ORFEO (ANR-12-CORP-0005) and ASFALDA
(ANR-12-CORD-023) and by FAPERGS and
CNRS through the AIM-WEST project.
</bodyText>
<sectionHeader confidence="0.998898" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998179387096774">
Anne Abeill´e, Lionel Cl´ement, and Franc¸ois Tou-
ssenel. 2003. Building a treebank for french. In
Anne Abeill´e, editor, Treebanks: building and using
parsed corpora, pages 165–168. Kluwer academic
publishers, Dordrecht, The Netherlands.
Timothy Baldwin and Su Nam Kim. 2010. Multi-
word expressions. In Nitin Indurkhya and Fred J.
Damerau, editors, Handbook of Natural Language
Processing, pages 267–292. CRC Press, Taylor and
Francis Group, Boca Raton, FL, USA, 2 edition.
Marco Baroni and Silvia Bernardini, editors. 2006.
Wacky! Working papers on the Web as Corpus.
GEDIT, Bologna, Italy. 224 p.
Bernd Bohnet. 2010. Top accuracy and fast depen-
dency parsing is not a contradiction. In Huang and
Jurafsky (Huang and Jurafsky, 2010), pages 89–97.
Ant´onio Horta Branco and Jo˜ao Ricardo Silva. 2003.
Contractions: Breaking the tokenization-tagging cir-
cularity. In Nuno J. Mamede, Jorge Baptista, Isabel
Trancoso, and Maria das Grac¸as Volpe Nunes, ed-
itors, Proc. of the 6th PROPOR (PROPOR 2003),
volume 2721 of LNCS (LNAI), pages 195–195, Faro,
Portugal, Jun. Springer.
Marie Candito and Matthieu Constant. 2014. Strate-
gies for contiguous multiword expression analysis
and dependency parsing. In Proc. of the 52nd ACL
(Volume 1: Long Papers), pages 743–753, Balti-
more, MD, USA, Jun. ACL.
Marie Candito, Benoit Crabb´e, Pascal Denis, and
Franc¸ois Gu´erin. 2009. Analyse syntaxique du
franc¸ais : des constituants aux d´ependances. In
</reference>
<page confidence="0.907269">
1124
</page>
<reference confidence="0.999897821428571">
Proc. of Traitement Automatique des Langues Na-
turelles, Senlis, France, Jun.
Matthieu Constant and Anthony Sigogne. 2011.
MWU-aware part-of-speech tagging with a CRF
model and lexical resources. In Kordoni et al. (Kor-
doni et al., 2011), pages 49–56.
Matthieu Constant, Marie Candito, and Djam´e Sed-
dah. 2013a. The LIGM-Alpage architecture for
the SPMRL 2013 shared task: Multiword expres-
sion analysis and dependency parsing. In Proceed-
ings of the Fourth Workshop on Statistical Parsing
of Morphologically-Rich Languages, pages 46–52,
Seattle, Washington, USA, October. Association for
Computational Linguistics.
Matthieu Constant, Joseph Le Roux, and Anthony Si-
gogne. 2013b. Combining compound recognition
and PCFG-LA parsing with word lattices and condi-
tional random fields. ACM Trans. Speech and Lang.
Process. Special Issue on MWEs: from theory to
practice and use, part 2 (TSLP), 10(3).
Eric De La Clergerie. 2013. Exploring beam-based
shift-reduce dependency parsing with DyALog: Re-
sults from the SPMRL 2013 shared task. In Pro-
ceedings of the Fourth Workshop on Statistical Pars-
ing of Morphologically-Rich Languages, pages 53–
62, Seattle, Washington, USA, October. Association
for Computational Linguistics.
Yoav Goldberg and Michael Elhadad. 2011. Joint he-
brew segmentation and parsing using a PCFGLA lat-
tice parser. In Proc. of the 49th ACL: HLT (ACL
HLT 2011), pages 704–709, Portland, OR, USA,
Jun. ACL.
Spence Green and Christopher D. Manning. 2010.
Better Arabic parsing: Baselines, evaluations, and
analysis. In Huang and Jurafsky (Huang and Juraf-
sky, 2010), pages 394–402.
Spence Green, Marie-Catherine de Marneffe, and
Christopher D. Manning. 2013. Parsing models
for identifying multiword expressions. Comp. Ling.,
39(1):195–227.
Chu-Ren Huang and Dan Jurafsky, editors. 2010.
Proc. of the 23rd COLING (COLING 2010), Beijing,
China, Aug. The Coling 2010 Organizing Commit-
tee.
Valia Kordoni, Carlos Ramisch, and Aline Villavicen-
cio, editors. 2011. Proc. of the ACL Workshop on
MWEs: from Parsing and Generation to the Real
World (MWE 2011), Portland, OR, USA, Jun. ACL.
Ioannis Korkontzelos and Suresh Manandhar. 2010.
Can recognising multiword expressions improve
shallow parsing? In Proc. of HLT: The 2010 Annual
Conf. of the NAACL (NAACL 2003), pages 636–644,
Los Angeles, California, Jun. ACL.
S. K¨ubler, R. McDonald, and J. Nivre. 2009. Depen-
dency parsing. Synthesis Lectures on Human Lan-
guage Technologies, 1(1):1–127.
Nidhi Kulkarni and Mark Finlayson. 2011. jMWE: A
Java toolkit for detecting multi-word expressions. In
Kordoni et al. (Kordoni et al., 2011), pages 122–124.
Igor A. Mel’ˇcuk. 1988. Dependency Syntax: Theory
and Practice. State University of New York Press,
New York.
Joakim Nivre and Jens Nilsson. 2004. Multiword units
in syntactic parsing. In Proc. of the LREC Work-
shop on Methodologies and Evaluation of Multi-
word Units in Real-World Applications (MEMURA),
Lisbon, Portugal.
Ivan Sag, Timothy Baldwin, Francis Bond, Ann Copes-
take, and Dan Flickinger. 2002. Multiword expres-
sions: A pain in the neck for NLP. In Proc. of the
3rd CICLing (CICLing-2002), volume 2276/2010
of LNCS, pages 1–15, Mexico City, Mexico, Feb.
Springer.
Nathan Schneider, Emily Danchik, Chris Dyer, and
A. Noah Smith. 2014. Discriminative lexical se-
mantic segmentation with gaps: Running the mwe
gamut. Transactions of the Association of Compu-
tational Linguistics – Volume 2, Issue 1, pages 193–
206.
Violeta Seretan. 2011. Syntax-Based Collocation Ex-
traction, volume 44 of Text, Speech and Language
Technology. Springer, Dordrecht, Netherlands, 1st
edition. 212 p.
Karel van den Eynde and Piet Mertens. 2003. La va-
lence: l’approche pronominale et son application au
lexique verbal. Journal of French Language Studies,
(13):63–104.
Aline Villavicencio, Valia Kordoni, Yi Zhang, Marco
Idiart, and Carlos Ramisch. 2007. Validation and
evaluation of automatically acquired multiword ex-
pressions for grammar engineering. In Jason Eis-
ner, editor, Proc. of the 2007 Joint Conference on
EMNLP and Computational NLL (EMNLP-CoNLL
2007), pages 1034–1043, Prague, Czech Republic,
Jun. ACL.
Veronika Vincze, Istv´an Nagy T., and Rich´ard Farkas.
2013a. Identifying English and Hungarian light verb
constructions: A contrastive approach. In Proc. of
the 51st ACL (Volume 2: Short Papers), pages 255–
261, Sofia, Bulgaria, Aug. ACL.
Veronika Vincze, Istv´an Nagy T., and J´anos Zsibrita.
2013b. Learning to detect english and hungarian
light verb constructions. ACM Trans. Speech and
Lang. Process. Special Issue on MWEs: from theory
to practice and use, part 1 (TSLP), 10(2).
Veronika Vincze, J´anos Zsibrita, and Istv´an Nagy T.
2013c. Dependency parsing for identifying hun-
garian light verb constructions. In Proceedings of
the Sixth International Joint Conference on Natu-
ral Language Processing, pages 207–215, Nagoya,
Japan, October. Asian Federation of Natural Lan-
guage Processing.
</reference>
<page confidence="0.855179">
1125
</page>
<reference confidence="0.996295285714286">
Eric Wehrli, Violeta Seretan, and Luka Nerima. 2010.
Sentence analysis and collocation identification. In
´Eric Laporte, Preslav Nakov, Carlos Ramisch, and
Aline Villavicencio, editors, Proc. of the COLING
Workshop on MWEs: from Theory to Applications
(MWE 2010), pages 27–35, Beijing, China, Aug.
ACL.
</reference>
<page confidence="0.994475">
1126
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.618422">
<title confidence="0.999608">Joint Dependency Parsing and Multiword Expression Tokenisation</title>
<author confidence="0.998515">Alexis Nasr</author>
<author confidence="0.998515">Carlos Ramisch</author>
<author confidence="0.998515">Jos´e Deulofeu</author>
<author confidence="0.998515">Andr´e</author>
<affiliation confidence="0.986281">Aix Marseille Universit´e, CNRS, LIF UMR</affiliation>
<address confidence="0.693797">Marseille,</address>
<email confidence="0.953039">FirstName.LastName@lif.univ-mrs.fr</email>
<abstract confidence="0.995907052631579">Complex conjunctions and determiners are often considered as pretokenized units in parsing. This is not always realistic, since they can be ambiguous. We propose a model for joint dependency parsing and multiword expressions identification, in which complex function words are represented as individual tokens linked with morphological dependencies. Our graphbased parser includes standard secondorder features and verbal subcategorization features derived from a syntactic lexicon.We train it on a modified version of the French Treebank enriched with morphological dependencies. It recognizes of with precision, and 82.74% of determiners with 86.70% precision.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anne Abeill´e</author>
<author>Lionel Cl´ement</author>
<author>Franc¸ois Toussenel</author>
</authors>
<title>Building a treebank for french.</title>
<date>2003</date>
<pages>165--168</pages>
<editor>In Anne Abeill´e, editor,</editor>
<publisher>Kluwer academic publishers,</publisher>
<location>Dordrecht, The Netherlands.</location>
<marker>Abeill´e, Cl´ement, Toussenel, 2003</marker>
<rawString>Anne Abeill´e, Lionel Cl´ement, and Franc¸ois Toussenel. 2003. Building a treebank for french. In Anne Abeill´e, editor, Treebanks: building and using parsed corpora, pages 165–168. Kluwer academic publishers, Dordrecht, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Su Nam Kim</author>
</authors>
<title>Multiword expressions.</title>
<date>2010</date>
<booktitle>In Nitin Indurkhya</booktitle>
<volume>2</volume>
<pages>267--292</pages>
<editor>and Fred J. Damerau, editors,</editor>
<publisher>CRC Press, Taylor and Francis Group,</publisher>
<location>Boca Raton, FL, USA,</location>
<contexts>
<context position="2553" citStr="Baldwin and Kim, 2010" startWordPosition="379" endWordPosition="383">ions, probabilistic tokenizers and taggers can produce several solutions in the form of lattices (Green and Manning, 2010; Goldberg and Elhadad, 2011). Such approaches usually lead to severe computational overhead due to the huge search space in which the parser looks for the optimal parse tree. Besides, the parser might be biased towards short solutions, as it compares scores of trees associated to sequences of different lengths (De La Clergerie, 2013). This problem is particularly hard when parsing multiword expressions (MWEs), that is, groups of tokens that must be treated as single units (Baldwin and Kim, 2010). The solution we present in this paper is different from the usual pipeline. We propose to jointly parse and tokenize MWEs, transforming segmentation decisions into linking decisions. Our experiments concentrate on two difficult tokenization cases. Hence, it is the parser that will choose, in such cases, whether to group or not several tokens. Our first target phenomenon is the family of ADV+que constructions, a type of complex conjunction in French. They are formed by adverbs like bien (well) or ainsi (likewise) followed by the subordinative conjunction que (that). They function like English</context>
</contexts>
<marker>Baldwin, Kim, 2010</marker>
<rawString>Timothy Baldwin and Su Nam Kim. 2010. Multiword expressions. In Nitin Indurkhya and Fred J. Damerau, editors, Handbook of Natural Language Processing, pages 267–292. CRC Press, Taylor and Francis Group, Boca Raton, FL, USA, 2 edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Silvia Bernardini</author>
<author>editors</author>
</authors>
<date>2006</date>
<booktitle>Wacky! Working papers on the Web as Corpus. GEDIT,</booktitle>
<volume>224</volume>
<pages>p.</pages>
<location>Bologna,</location>
<marker>Baroni, Bernardini, editors, 2006</marker>
<rawString>Marco Baroni and Silvia Bernardini, editors. 2006. Wacky! Working papers on the Web as Corpus. GEDIT, Bologna, Italy. 224 p.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernd Bohnet</author>
</authors>
<title>Top accuracy and fast dependency parsing is not a contradiction.</title>
<date>2010</date>
<booktitle>In Huang and Jurafsky (Huang and Jurafsky,</booktitle>
<pages>89--97</pages>
<contexts>
<context position="10206" citStr="Bohnet, 2010" startWordPosition="1616" endWordPosition="1617">s which favor MWE identification. Their experiments on French and Arabic show that the proposed models beat the baseline in MWE identification while producing acceptable general parsing results. Candito and Constant (2014) and Vincze et al. (2013c) present experiments on dependency parsing for MWE identification which are the closest to our settings. Vincze et al. (2013c) focus on light verb constructions in Hungarian. They propose distinguishing regular verbal dependencies from light verbs and their complements through four special labels prefixed by LCV-. Then, they train the Bohnet parser (Bohnet, 2010) using standard parameters and features, and evaluate on a gold test set. They report no significant changes in attachment scores, whereas F1 for light verb identification is 75.63%, significantly higher than the baseline methods of lexicon projection (21.25%) and classification (74.45%). Candito and Constant (2014) compare several architectures for dependency parsing and MWE identification in French. For regular MWEs like noun compounds, they use regular expressions to automatically generate an internal syntactic structure, combining standard and MWE-dedicated dependency labels. Irregular exp</context>
<context position="14946" citStr="Bohnet, 2010" startWordPosition="2408" endWordPosition="2409">ost simple one is the arcfactored or first-order model, which simply decomposes a tree into single dependencies and assigns them a score, independently of their context. We used a second-order parser which decomposes a tree into factors of three types: 1. first-order factors, made of one dependency; 2. sibling factors, made of two dependencies sharing a common governor; 3. grandchildren factors, made of two dependencies where the dependent of one of them is the governor of the other one. 5 Integration with a Syntactic Lexicon Although this kind of parsers achieve state-of-theart performances (Bohnet, 2010), their predictions are limited to the phenomena that occur in the treebanks they are trained on. In particular, they often fail at correctly distinguishing elements that are subcategorized by a verb (henceforth complements) from others (modifiers). This is due to the fact that the nature and number of the complements is specific to each verb. If the verb did not occur, or did not occur often enough, in the treebank, the nature and number of its complements will not be correctly modeled by the parser. A precise description of verb complements plays an important role in the task of predicting t</context>
</contexts>
<marker>Bohnet, 2010</marker>
<rawString>Bernd Bohnet. 2010. Top accuracy and fast dependency parsing is not a contradiction. In Huang and Jurafsky (Huang and Jurafsky, 2010), pages 89–97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ant´onio Horta Branco</author>
<author>Jo˜ao Ricardo Silva</author>
</authors>
<title>Contractions: Breaking the tokenization-tagging circularity.</title>
<date>2003</date>
<booktitle>Isabel Trancoso, and Maria das Grac¸as Volpe Nunes, editors, Proc. of the 6th PROPOR (PROPOR 2003), volume 2721 of LNCS (LNAI),</booktitle>
<pages>195--195</pages>
<editor>In Nuno J. Mamede, Jorge Baptista,</editor>
<publisher>Springer.</publisher>
<location>Faro, Portugal,</location>
<contexts>
<context position="1720" citStr="Branco and Silva, 2003" startWordPosition="253" endWordPosition="256">the output of the preceding one. Among these processes, one commonly finds a tokenizer, which segments a sentence into words, a part-of-speech (POS) tagger, which associates to every word a part-of-speech tag, and a syntactic parser, which builds a parse tree for the sentence1. These three processes correspond to three formal operations on the string: segmentation into linguistically relevant units (words), tagging the words with POS tags and linking the (word, POS) pairs by means of syntactic dependencies. This setup is clearly not ideal, as some decisions are made too early in the pipeline (Branco and Silva, 2003). More specifically, some tokenization and tagging choices are difficult to make without 1This paper considers dependency syntactic structures. taking syntax into account. To avoid the pitfall of premature decisions, probabilistic tokenizers and taggers can produce several solutions in the form of lattices (Green and Manning, 2010; Goldberg and Elhadad, 2011). Such approaches usually lead to severe computational overhead due to the huge search space in which the parser looks for the optimal parse tree. Besides, the parser might be biased towards short solutions, as it compares scores of trees </context>
</contexts>
<marker>Branco, Silva, 2003</marker>
<rawString>Ant´onio Horta Branco and Jo˜ao Ricardo Silva. 2003. Contractions: Breaking the tokenization-tagging circularity. In Nuno J. Mamede, Jorge Baptista, Isabel Trancoso, and Maria das Grac¸as Volpe Nunes, editors, Proc. of the 6th PROPOR (PROPOR 2003), volume 2721 of LNCS (LNAI), pages 195–195, Faro, Portugal, Jun. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie Candito</author>
<author>Matthieu Constant</author>
</authors>
<title>Strategies for contiguous multiword expression analysis and dependency parsing.</title>
<date>2014</date>
<booktitle>In Proc. of the 52nd ACL (Volume 1: Long Papers),</booktitle>
<pages>743--753</pages>
<publisher>ACL.</publisher>
<location>Baltimore, MD, USA,</location>
<contexts>
<context position="9815" citStr="Candito and Constant (2014)" startWordPosition="1555" endWordPosition="1558">which, as a by-product, performs MWE identification. They propose a flat representation for contiguous expressions in which all elements are attached to a special node, and then they compare several parsing models, including an original factored-lexicon PCFG and a tree substitution grammar. These generic parsing models can be used for parsing in general, but they have interesting memorization properties which favor MWE identification. Their experiments on French and Arabic show that the proposed models beat the baseline in MWE identification while producing acceptable general parsing results. Candito and Constant (2014) and Vincze et al. (2013c) present experiments on dependency parsing for MWE identification which are the closest to our settings. Vincze et al. (2013c) focus on light verb constructions in Hungarian. They propose distinguishing regular verbal dependencies from light verbs and their complements through four special labels prefixed by LCV-. Then, they train the Bohnet parser (Bohnet, 2010) using standard parameters and features, and evaluate on a gold test set. They report no significant changes in attachment scores, whereas F1 for light verb identification is 75.63%, significantly higher than </context>
<context position="12303" citStr="Candito and Constant (2014)" startWordPosition="1940" endWordPosition="1943">our model on ADV+que and de+DET constructions. 3 The MORPH Dependency In order to let the parser take the tokenization decisions, we propose not to group sequences of tokens of the form ADV+que and de+DET at tokenization time. Instead, we transform the task of segmentation decision into a parsing decision task. We associate a syntactic structure to ADV+que and de+DET constructions by introducing a new type of dependency that we call MORPH. It is not a standard syntactic dependency, but a reminiscent of the morphological dependencies of Mel’ˇcuk (1988), similar to the DEP CPD label proposed by Candito and Constant (2014) or the ID dependency of Nivre and Nilsson (2004), except that we focus on syntactically-motivated MWEs, proposing a regular structure for them. The syntactic structures of examples 1 and 2, introduced in Section 1, are represented below4. Example 1. CLS VRB ADV CSU ... VRB ... Je mange bien que ... aie ... Example 2. CLS VRB ADV CSU ... VRB ... Je pense bien que ... ai ... 4In the examples, parts of speech CLS, VRB, ADV and CSU respectively stand for subject clitic pronoun, verb, adverb and subordinating conjunction. Syntactic labels SUJ, MOD, OBJ, DE-OBJ and SPE stand for subject, modifier, </context>
<context position="19904" citStr="Candito and Constant (2014)" startWordPosition="3232" endWordPosition="3235"> Section 5). We evaluate parsing precision and MWE identification on a test treebank and, more importantly, on a dataset built specifically to study the representation of our target constructions. All experiments used the NLP tool suite MACAON5, which comprises a second-order graph-based parser. 6.1 Data Sets and Resources French Treebank (FTB) The parser was trained on the French Treebank, a syntactically annotated corpus of news articles from Le Monde (Abeill´e et al., 2003). We used the version which was transformed into dependency trees by Candito et al. (2009), and which was also used by Candito and Constant (2014) for experiments on MWE parsing. We used a standard split of 9,881 sentences (278K words) for training and 1,235 sentences for test (36K words). We applied simple rules to transform the flat representation of ADV+que and de+DET constructions into MORPH-linked individual tokens. All other MWEs are kept unchanged in training and test data. They are represented as single tokens, not decomposed into individual words. MORPH Dataset The test portion of the FTB contains relatively few instances of our target constructions (see Tables 4 and 6). Thus, we have created two specific data sets to evaluate </context>
<context position="24726" citStr="Candito and Constant, 2014" startWordPosition="4008" endWordPosition="4012">Section 5, the subcat features -QUE, +QUE, -DE and +DE of each verb. Table 3 below shows the number of verbal entries having each of our four subcat features. Although the number of verbs described in DicoValence is moderate, its coverage is high on our data sets. It is equal to 97.82% on the FTB test set and is equal to 95.48% on the MORPH dataset. -QUE +QUE -DE +DE 3,814 356 3,450 720 Table 3: Number of verbs in DicoValence per value of subcat feature. 6.2 Evaluation We evaluate our models on two aspects: parsing quality and MWE identification (Nivre and Nilsson, 2004; Vincze et al., 2013c; Candito and Constant, 2014). First, we use standard parsing attachment scores to verify whether our models impact parsing performance in general. We compare the generated dependency trees with the reference in the test portion of the FTB, reporting the proportion of matched links, both in terms of structure – unlabeled attachment score (UAS) – and of labeled links – labeled attachment score (LAS). Since our focus is on MWE parsing, we are also 8http://bach.arts.kuleuven.be/ dicovalence/ 1121 interested in MWE identification metrics. We focus on words whose dependency label is MORPH and calculate the proportion of correc</context>
</contexts>
<marker>Candito, Constant, 2014</marker>
<rawString>Marie Candito and Matthieu Constant. 2014. Strategies for contiguous multiword expression analysis and dependency parsing. In Proc. of the 52nd ACL (Volume 1: Long Papers), pages 743–753, Baltimore, MD, USA, Jun. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie Candito</author>
<author>Benoit Crabb´e</author>
<author>Pascal Denis</author>
<author>Franc¸ois Gu´erin</author>
</authors>
<title>Analyse syntaxique du franc¸ais : des constituants aux d´ependances.</title>
<date>2009</date>
<booktitle>In Proc. of Traitement Automatique des Langues Naturelles,</booktitle>
<location>Senlis, France,</location>
<marker>Candito, Crabb´e, Denis, Gu´erin, 2009</marker>
<rawString>Marie Candito, Benoit Crabb´e, Pascal Denis, and Franc¸ois Gu´erin. 2009. Analyse syntaxique du franc¸ais : des constituants aux d´ependances. In Proc. of Traitement Automatique des Langues Naturelles, Senlis, France, Jun.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthieu Constant</author>
<author>Anthony Sigogne</author>
</authors>
<title>MWU-aware part-of-speech tagging with a CRF model and lexical resources.</title>
<date>2011</date>
<booktitle>In Kordoni et al. (Kordoni</booktitle>
<pages>49--56</pages>
<contexts>
<context position="8782" citStr="Constant and Sigogne, 2011" startWordPosition="1400" endWordPosition="1403">al. However, the authors admit that “it remains to be seen how much of theoretically possible improvement can be realized when using automatic methods for MWU recognition”. Several methods of increasing complexity have been proposed for fully automatic MWE tokenization: simple lexicon projection onto a corpus (Kulkarni and Finlayson, 2011), synchronous lexicon lookup and parsing (Wehrli et al., 2010; Seretan, 2011), token-based classifiers trained using 1117 association measures and other contextual features (Vincze et al., 2013a), or contextual sequence models like conditional random fields (Constant and Sigogne, 2011; Constant et al., 2013b; Vincze et al., 2013b) and structured perceptron (Schneider et al., 2014). In theory, compound function words like ADV+que and de+DET allow no internal variability, thus they should be represented as words-with-spaces. However, to date no satisfactory solution has been proposed for automatically tokenizing ambiguous MWEs. Green et al. (2013) propose a constituency parsing model which, as a by-product, performs MWE identification. They propose a flat representation for contiguous expressions in which all elements are attached to a special node, and then they compare sev</context>
</contexts>
<marker>Constant, Sigogne, 2011</marker>
<rawString>Matthieu Constant and Anthony Sigogne. 2011. MWU-aware part-of-speech tagging with a CRF model and lexical resources. In Kordoni et al. (Kordoni et al., 2011), pages 49–56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthieu Constant</author>
<author>Marie Candito</author>
<author>Djam´e Seddah</author>
</authors>
<title>The LIGM-Alpage architecture for the SPMRL 2013 shared task: Multiword expression analysis and dependency parsing.</title>
<date>2013</date>
<booktitle>In Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages,</booktitle>
<pages>46--52</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Seattle, Washington, USA,</location>
<contexts>
<context position="8805" citStr="Constant et al., 2013" startWordPosition="1404" endWordPosition="1407">it that “it remains to be seen how much of theoretically possible improvement can be realized when using automatic methods for MWU recognition”. Several methods of increasing complexity have been proposed for fully automatic MWE tokenization: simple lexicon projection onto a corpus (Kulkarni and Finlayson, 2011), synchronous lexicon lookup and parsing (Wehrli et al., 2010; Seretan, 2011), token-based classifiers trained using 1117 association measures and other contextual features (Vincze et al., 2013a), or contextual sequence models like conditional random fields (Constant and Sigogne, 2011; Constant et al., 2013b; Vincze et al., 2013b) and structured perceptron (Schneider et al., 2014). In theory, compound function words like ADV+que and de+DET allow no internal variability, thus they should be represented as words-with-spaces. However, to date no satisfactory solution has been proposed for automatically tokenizing ambiguous MWEs. Green et al. (2013) propose a constituency parsing model which, as a by-product, performs MWE identification. They propose a flat representation for contiguous expressions in which all elements are attached to a special node, and then they compare several parsing models, in</context>
<context position="10977" citStr="Constant et al., 2013" startWordPosition="1728" endWordPosition="1731">t verb identification is 75.63%, significantly higher than the baseline methods of lexicon projection (21.25%) and classification (74.45%). Candito and Constant (2014) compare several architectures for dependency parsing and MWE identification in French. For regular MWEs like noun compounds, they use regular expressions to automatically generate an internal syntactic structure, combining standard and MWE-dedicated dependency labels. Irregular expressions like complex conjunctions are represented as separate tokens, with a special DEP CPD dependency that links all tokens to the first MWE word (Constant et al., 2013a). They compare different architectures for MWE identification before, during and after parsing, showing that the best architecture depends on whether the target MWEs are regular or irregular. Similarly to these two papers, we use a special dependency to model MWEs and evaluate parsing and identification accuracy. Our work departs from theirs on three important aspects. First, we concentrate on syntactically irregular compounds, that we represent with a new kind of dependency. Second, we integrate into the parser a syntactic lexicon in order to help disambiguate ADV+que and de+DET constructio</context>
</contexts>
<marker>Constant, Candito, Seddah, 2013</marker>
<rawString>Matthieu Constant, Marie Candito, and Djam´e Seddah. 2013a. The LIGM-Alpage architecture for the SPMRL 2013 shared task: Multiword expression analysis and dependency parsing. In Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages, pages 46–52, Seattle, Washington, USA, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthieu Constant</author>
<author>Joseph Le Roux</author>
<author>Anthony Sigogne</author>
</authors>
<title>Combining compound recognition and PCFG-LA parsing with word lattices and conditional random fields.</title>
<date>2013</date>
<journal>ACM Trans. Speech</journal>
<volume>10</volume>
<issue>3</issue>
<marker>Constant, Le Roux, Sigogne, 2013</marker>
<rawString>Matthieu Constant, Joseph Le Roux, and Anthony Sigogne. 2013b. Combining compound recognition and PCFG-LA parsing with word lattices and conditional random fields. ACM Trans. Speech and Lang. Process. Special Issue on MWEs: from theory to practice and use, part 2 (TSLP), 10(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric De La Clergerie</author>
</authors>
<title>Exploring beam-based shift-reduce dependency parsing with DyALog: Results from the SPMRL 2013 shared task.</title>
<date>2013</date>
<booktitle>In Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages,</booktitle>
<pages>53--62</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Seattle, Washington, USA,</location>
<contexts>
<context position="2388" citStr="Clergerie, 2013" startWordPosition="355" endWordPosition="356">hoices are difficult to make without 1This paper considers dependency syntactic structures. taking syntax into account. To avoid the pitfall of premature decisions, probabilistic tokenizers and taggers can produce several solutions in the form of lattices (Green and Manning, 2010; Goldberg and Elhadad, 2011). Such approaches usually lead to severe computational overhead due to the huge search space in which the parser looks for the optimal parse tree. Besides, the parser might be biased towards short solutions, as it compares scores of trees associated to sequences of different lengths (De La Clergerie, 2013). This problem is particularly hard when parsing multiword expressions (MWEs), that is, groups of tokens that must be treated as single units (Baldwin and Kim, 2010). The solution we present in this paper is different from the usual pipeline. We propose to jointly parse and tokenize MWEs, transforming segmentation decisions into linking decisions. Our experiments concentrate on two difficult tokenization cases. Hence, it is the parser that will choose, in such cases, whether to group or not several tokens. Our first target phenomenon is the family of ADV+que constructions, a type of complex co</context>
</contexts>
<marker>Clergerie, 2013</marker>
<rawString>Eric De La Clergerie. 2013. Exploring beam-based shift-reduce dependency parsing with DyALog: Results from the SPMRL 2013 shared task. In Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages, pages 53– 62, Seattle, Washington, USA, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Goldberg</author>
<author>Michael Elhadad</author>
</authors>
<title>Joint hebrew segmentation and parsing using a PCFGLA lattice parser.</title>
<date>2011</date>
<booktitle>In Proc. of the 49th ACL: HLT (ACL HLT 2011),</booktitle>
<pages>704--709</pages>
<publisher>ACL.</publisher>
<location>Portland, OR, USA,</location>
<contexts>
<context position="2081" citStr="Goldberg and Elhadad, 2011" startWordPosition="303" endWordPosition="306">mentation into linguistically relevant units (words), tagging the words with POS tags and linking the (word, POS) pairs by means of syntactic dependencies. This setup is clearly not ideal, as some decisions are made too early in the pipeline (Branco and Silva, 2003). More specifically, some tokenization and tagging choices are difficult to make without 1This paper considers dependency syntactic structures. taking syntax into account. To avoid the pitfall of premature decisions, probabilistic tokenizers and taggers can produce several solutions in the form of lattices (Green and Manning, 2010; Goldberg and Elhadad, 2011). Such approaches usually lead to severe computational overhead due to the huge search space in which the parser looks for the optimal parse tree. Besides, the parser might be biased towards short solutions, as it compares scores of trees associated to sequences of different lengths (De La Clergerie, 2013). This problem is particularly hard when parsing multiword expressions (MWEs), that is, groups of tokens that must be treated as single units (Baldwin and Kim, 2010). The solution we present in this paper is different from the usual pipeline. We propose to jointly parse and tokenize MWEs, tra</context>
</contexts>
<marker>Goldberg, Elhadad, 2011</marker>
<rawString>Yoav Goldberg and Michael Elhadad. 2011. Joint hebrew segmentation and parsing using a PCFGLA lattice parser. In Proc. of the 49th ACL: HLT (ACL HLT 2011), pages 704–709, Portland, OR, USA, Jun. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Spence Green</author>
<author>Christopher D Manning</author>
</authors>
<title>Better Arabic parsing: Baselines, evaluations, and analysis.</title>
<date>2010</date>
<booktitle>In Huang and Jurafsky (Huang and Jurafsky,</booktitle>
<pages>394--402</pages>
<contexts>
<context position="2052" citStr="Green and Manning, 2010" startWordPosition="299" endWordPosition="302">ations on the string: segmentation into linguistically relevant units (words), tagging the words with POS tags and linking the (word, POS) pairs by means of syntactic dependencies. This setup is clearly not ideal, as some decisions are made too early in the pipeline (Branco and Silva, 2003). More specifically, some tokenization and tagging choices are difficult to make without 1This paper considers dependency syntactic structures. taking syntax into account. To avoid the pitfall of premature decisions, probabilistic tokenizers and taggers can produce several solutions in the form of lattices (Green and Manning, 2010; Goldberg and Elhadad, 2011). Such approaches usually lead to severe computational overhead due to the huge search space in which the parser looks for the optimal parse tree. Besides, the parser might be biased towards short solutions, as it compares scores of trees associated to sequences of different lengths (De La Clergerie, 2013). This problem is particularly hard when parsing multiword expressions (MWEs), that is, groups of tokens that must be treated as single units (Baldwin and Kim, 2010). The solution we present in this paper is different from the usual pipeline. We propose to jointly</context>
</contexts>
<marker>Green, Manning, 2010</marker>
<rawString>Spence Green and Christopher D. Manning. 2010. Better Arabic parsing: Baselines, evaluations, and analysis. In Huang and Jurafsky (Huang and Jurafsky, 2010), pages 394–402.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Spence Green</author>
<author>Marie-Catherine de Marneffe</author>
<author>Christopher D Manning</author>
</authors>
<title>Parsing models for identifying multiword expressions.</title>
<date>2013</date>
<journal>Comp. Ling.,</journal>
<volume>39</volume>
<issue>1</issue>
<marker>Green, de Marneffe, Manning, 2013</marker>
<rawString>Spence Green, Marie-Catherine de Marneffe, and Christopher D. Manning. 2013. Parsing models for identifying multiword expressions. Comp. Ling., 39(1):195–227.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chu-Ren Huang</author>
<author>Dan Jurafsky</author>
<author>editors</author>
</authors>
<date>2010</date>
<booktitle>Proc. of the 23rd COLING (COLING 2010),</booktitle>
<location>Beijing, China,</location>
<marker>Huang, Jurafsky, editors, 2010</marker>
<rawString>Chu-Ren Huang and Dan Jurafsky, editors. 2010. Proc. of the 23rd COLING (COLING 2010), Beijing, China, Aug. The Coling 2010 Organizing Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Valia Kordoni</author>
<author>Carlos Ramisch</author>
<author>Aline Villavicencio</author>
<author>editors</author>
</authors>
<date>2011</date>
<booktitle>Proc. of the ACL Workshop on MWEs: from Parsing and Generation to the Real World (MWE 2011),</booktitle>
<publisher>ACL.</publisher>
<location>Portland, OR, USA,</location>
<marker>Kordoni, Ramisch, Villavicencio, editors, 2011</marker>
<rawString>Valia Kordoni, Carlos Ramisch, and Aline Villavicencio, editors. 2011. Proc. of the ACL Workshop on MWEs: from Parsing and Generation to the Real World (MWE 2011), Portland, OR, USA, Jun. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ioannis Korkontzelos</author>
<author>Suresh Manandhar</author>
</authors>
<title>Can recognising multiword expressions improve shallow parsing?</title>
<date>2010</date>
<booktitle>In Proc. of HLT: The 2010 Annual Conf. of the NAACL (NAACL</booktitle>
<pages>636--644</pages>
<publisher>ACL.</publisher>
<location>Los Angeles, California,</location>
<contexts>
<context position="7757" citStr="Korkontzelos and Manandhar, 2010" startWordPosition="1246" endWordPosition="1250">er. 2 Related Work The famous “pain-in-the-neck” article by Sag et al. (2002) discusses MWEs in parsers, contrasting two representation alternatives in the LinGO ERG HPSG grammar of English: compositional rules and words-with-spaces. The addition of compositional rules for flexible MWEs has been tested in a small-scale experiment which showed significant coverage improvements in HPSG parsing by the addition of 21 new MWEs to the grammar (Villavicencio et al., 2007). It has been demonstrated that pre-grouping MWEs as words-with-spaces can improve the performance of shallow parsing for English (Korkontzelos and Manandhar, 2010). Nivre and Nilsson (2004) obtained similar results for dependency parsing of Swedish. They compare models trained on two representations: one where MWEs are linked by a special ID dependency, and another one based on gold pre-tokenization. Their results show that the former model can recognize MWEs with F1=71.1%, while the latter can significantly improve parsing accuracy and robustness in general. However, the authors admit that “it remains to be seen how much of theoretically possible improvement can be realized when using automatic methods for MWU recognition”. Several methods of increasin</context>
</contexts>
<marker>Korkontzelos, Manandhar, 2010</marker>
<rawString>Ioannis Korkontzelos and Suresh Manandhar. 2010. Can recognising multiword expressions improve shallow parsing? In Proc. of HLT: The 2010 Annual Conf. of the NAACL (NAACL 2003), pages 636–644, Los Angeles, California, Jun. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S K¨ubler</author>
<author>R McDonald</author>
<author>J Nivre</author>
</authors>
<date>2009</date>
<booktitle>Dependency parsing. Synthesis Lectures on Human Language Technologies,</booktitle>
<volume>1</volume>
<issue>1</issue>
<marker>K¨ubler, McDonald, Nivre, 2009</marker>
<rawString>S. K¨ubler, R. McDonald, and J. Nivre. 2009. Dependency parsing. Synthesis Lectures on Human Language Technologies, 1(1):1–127.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nidhi Kulkarni</author>
<author>Mark Finlayson</author>
</authors>
<title>jMWE: A Java toolkit for detecting multi-word expressions.</title>
<date>2011</date>
<booktitle>In Kordoni et al. (Kordoni</booktitle>
<pages>122--124</pages>
<contexts>
<context position="8497" citStr="Kulkarni and Finlayson, 2011" startWordPosition="1360" endWordPosition="1363">ned on two representations: one where MWEs are linked by a special ID dependency, and another one based on gold pre-tokenization. Their results show that the former model can recognize MWEs with F1=71.1%, while the latter can significantly improve parsing accuracy and robustness in general. However, the authors admit that “it remains to be seen how much of theoretically possible improvement can be realized when using automatic methods for MWU recognition”. Several methods of increasing complexity have been proposed for fully automatic MWE tokenization: simple lexicon projection onto a corpus (Kulkarni and Finlayson, 2011), synchronous lexicon lookup and parsing (Wehrli et al., 2010; Seretan, 2011), token-based classifiers trained using 1117 association measures and other contextual features (Vincze et al., 2013a), or contextual sequence models like conditional random fields (Constant and Sigogne, 2011; Constant et al., 2013b; Vincze et al., 2013b) and structured perceptron (Schneider et al., 2014). In theory, compound function words like ADV+que and de+DET allow no internal variability, thus they should be represented as words-with-spaces. However, to date no satisfactory solution has been proposed for automat</context>
</contexts>
<marker>Kulkarni, Finlayson, 2011</marker>
<rawString>Nidhi Kulkarni and Mark Finlayson. 2011. jMWE: A Java toolkit for detecting multi-word expressions. In Kordoni et al. (Kordoni et al., 2011), pages 122–124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Igor A Mel’ˇcuk</author>
</authors>
<title>Dependency Syntax: Theory and Practice.</title>
<date>1988</date>
<publisher>State University of New York Press,</publisher>
<location>New York.</location>
<marker>Mel’ˇcuk, 1988</marker>
<rawString>Igor A. Mel’ˇcuk. 1988. Dependency Syntax: Theory and Practice. State University of New York Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Jens Nilsson</author>
</authors>
<title>Multiword units in syntactic parsing.</title>
<date>2004</date>
<booktitle>In Proc. of the LREC Workshop on Methodologies and Evaluation of Multiword Units in Real-World Applications (MEMURA),</booktitle>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="7783" citStr="Nivre and Nilsson (2004)" startWordPosition="1251" endWordPosition="1255">-in-the-neck” article by Sag et al. (2002) discusses MWEs in parsers, contrasting two representation alternatives in the LinGO ERG HPSG grammar of English: compositional rules and words-with-spaces. The addition of compositional rules for flexible MWEs has been tested in a small-scale experiment which showed significant coverage improvements in HPSG parsing by the addition of 21 new MWEs to the grammar (Villavicencio et al., 2007). It has been demonstrated that pre-grouping MWEs as words-with-spaces can improve the performance of shallow parsing for English (Korkontzelos and Manandhar, 2010). Nivre and Nilsson (2004) obtained similar results for dependency parsing of Swedish. They compare models trained on two representations: one where MWEs are linked by a special ID dependency, and another one based on gold pre-tokenization. Their results show that the former model can recognize MWEs with F1=71.1%, while the latter can significantly improve parsing accuracy and robustness in general. However, the authors admit that “it remains to be seen how much of theoretically possible improvement can be realized when using automatic methods for MWU recognition”. Several methods of increasing complexity have been pro</context>
<context position="12352" citStr="Nivre and Nilsson (2004)" startWordPosition="1950" endWordPosition="1953"> MORPH Dependency In order to let the parser take the tokenization decisions, we propose not to group sequences of tokens of the form ADV+que and de+DET at tokenization time. Instead, we transform the task of segmentation decision into a parsing decision task. We associate a syntactic structure to ADV+que and de+DET constructions by introducing a new type of dependency that we call MORPH. It is not a standard syntactic dependency, but a reminiscent of the morphological dependencies of Mel’ˇcuk (1988), similar to the DEP CPD label proposed by Candito and Constant (2014) or the ID dependency of Nivre and Nilsson (2004), except that we focus on syntactically-motivated MWEs, proposing a regular structure for them. The syntactic structures of examples 1 and 2, introduced in Section 1, are represented below4. Example 1. CLS VRB ADV CSU ... VRB ... Je mange bien que ... aie ... Example 2. CLS VRB ADV CSU ... VRB ... Je pense bien que ... ai ... 4In the examples, parts of speech CLS, VRB, ADV and CSU respectively stand for subject clitic pronoun, verb, adverb and subordinating conjunction. Syntactic labels SUJ, MOD, OBJ, DE-OBJ and SPE stand for subject, modifier, object, indirect object introduced by the preposi</context>
<context position="24675" citStr="Nivre and Nilsson, 2004" startWordPosition="3999" endWordPosition="4003"> templates. We have only kept, as described in Section 5, the subcat features -QUE, +QUE, -DE and +DE of each verb. Table 3 below shows the number of verbal entries having each of our four subcat features. Although the number of verbs described in DicoValence is moderate, its coverage is high on our data sets. It is equal to 97.82% on the FTB test set and is equal to 95.48% on the MORPH dataset. -QUE +QUE -DE +DE 3,814 356 3,450 720 Table 3: Number of verbs in DicoValence per value of subcat feature. 6.2 Evaluation We evaluate our models on two aspects: parsing quality and MWE identification (Nivre and Nilsson, 2004; Vincze et al., 2013c; Candito and Constant, 2014). First, we use standard parsing attachment scores to verify whether our models impact parsing performance in general. We compare the generated dependency trees with the reference in the test portion of the FTB, reporting the proportion of matched links, both in terms of structure – unlabeled attachment score (UAS) – and of labeled links – labeled attachment score (LAS). Since our focus is on MWE parsing, we are also 8http://bach.arts.kuleuven.be/ dicovalence/ 1121 interested in MWE identification metrics. We focus on words whose dependency la</context>
<context position="33779" citStr="Nivre and Nilsson, 2004" startWordPosition="5506" endWordPosition="5509">er trained without subcat features can only rely on the examples present in the FTB which are proportionally smaller in the first case than in the second. 8 Conclusions This paper introduced and evaluated a joint parsing and MWE identification model that can effectively detect and represent ambiguous complex function words. The difficulty of processing such expressions is underestimated because of their limited variability. They often are pregrouped as words-with-spaces in many parsing architectures (Sag et al., 2002). However, we did not use gold tokenization, unrealistic for ambiguous MWEs (Nivre and Nilsson, 2004; Korkontze1123 Baseline prec. Green et Without SF With SF al. (2013) de+DET global indiv. Prec. Recall F1 Prec. Recall F1 de le 66.9 79.0 56.96 72.50 64.44 68.23 85.41 91.11 88.17 de la 79.0 77.5 22.83 58.13 86.20 69.44 81.25 89.65 85.24 de les 22.5 66.9 87.72 97.36 74.00 84.09 98.70 76.00 85.87 de l’ 83.1 83.1 18.55 57.14 69.56 62.74 64.51 86.95 74.07 Total 63.5 76.6 44.37 77.00 73.09 75.00 86.70 82.74 84.67 Table 7: MORPH link prediction for de+DET constructions: precision of global majority baseline, precision of individual per-construction baseline, precision of Green et al. (2013) consti</context>
</contexts>
<marker>Nivre, Nilsson, 2004</marker>
<rawString>Joakim Nivre and Jens Nilsson. 2004. Multiword units in syntactic parsing. In Proc. of the LREC Workshop on Methodologies and Evaluation of Multiword Units in Real-World Applications (MEMURA), Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Sag</author>
<author>Timothy Baldwin</author>
<author>Francis Bond</author>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
</authors>
<title>Multiword expressions: A pain in the neck for NLP.</title>
<date>2002</date>
<booktitle>In Proc. of the 3rd CICLing (CICLing-2002),</booktitle>
<volume>2276</volume>
<pages>1--15</pages>
<publisher>Springer.</publisher>
<location>Mexico City, Mexico,</location>
<contexts>
<context position="7201" citStr="Sag et al. (2002)" startWordPosition="1164" endWordPosition="1167">used by the parser when looking for the optimal parse tree. The paper is organized as follows: Section 2 describes related work on MWE parsing. Section 3 proposes a way to represent multiword units by means of syntactic dependencies. In Section 4, we briefly describe the parser that has been used in this work, and in Section 5, we propose a way to integrate a syntactic lexicon into the parser. Section 6 describes the data sets used for the experiments, which results are presented and discussed in Section 7. Section 8 concludes the paper. 2 Related Work The famous “pain-in-the-neck” article by Sag et al. (2002) discusses MWEs in parsers, contrasting two representation alternatives in the LinGO ERG HPSG grammar of English: compositional rules and words-with-spaces. The addition of compositional rules for flexible MWEs has been tested in a small-scale experiment which showed significant coverage improvements in HPSG parsing by the addition of 21 new MWEs to the grammar (Villavicencio et al., 2007). It has been demonstrated that pre-grouping MWEs as words-with-spaces can improve the performance of shallow parsing for English (Korkontzelos and Manandhar, 2010). Nivre and Nilsson (2004) obtained similar </context>
<context position="33679" citStr="Sag et al., 2002" startWordPosition="5490" endWordPosition="5493">rbs licensing complements introduced by the conjunction que (see Table 3). Therefore, the parser trained without subcat features can only rely on the examples present in the FTB which are proportionally smaller in the first case than in the second. 8 Conclusions This paper introduced and evaluated a joint parsing and MWE identification model that can effectively detect and represent ambiguous complex function words. The difficulty of processing such expressions is underestimated because of their limited variability. They often are pregrouped as words-with-spaces in many parsing architectures (Sag et al., 2002). However, we did not use gold tokenization, unrealistic for ambiguous MWEs (Nivre and Nilsson, 2004; Korkontze1123 Baseline prec. Green et Without SF With SF al. (2013) de+DET global indiv. Prec. Recall F1 Prec. Recall F1 de le 66.9 79.0 56.96 72.50 64.44 68.23 85.41 91.11 88.17 de la 79.0 77.5 22.83 58.13 86.20 69.44 81.25 89.65 85.24 de les 22.5 66.9 87.72 97.36 74.00 84.09 98.70 76.00 85.87 de l’ 83.1 83.1 18.55 57.14 69.56 62.74 64.51 86.95 74.07 Total 63.5 76.6 44.37 77.00 73.09 75.00 86.70 82.74 84.67 Table 7: MORPH link prediction for de+DET constructions: precision of global majority </context>
</contexts>
<marker>Sag, Baldwin, Bond, Copestake, Flickinger, 2002</marker>
<rawString>Ivan Sag, Timothy Baldwin, Francis Bond, Ann Copestake, and Dan Flickinger. 2002. Multiword expressions: A pain in the neck for NLP. In Proc. of the 3rd CICLing (CICLing-2002), volume 2276/2010 of LNCS, pages 1–15, Mexico City, Mexico, Feb. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathan Schneider</author>
<author>Emily Danchik</author>
<author>Chris Dyer</author>
<author>A Noah Smith</author>
</authors>
<title>Discriminative lexical semantic segmentation with gaps: Running the mwe gamut.</title>
<date>2014</date>
<journal>Transactions of the Association of Computational Linguistics –</journal>
<volume>2</volume>
<pages>193--206</pages>
<contexts>
<context position="8880" citStr="Schneider et al., 2014" startWordPosition="1415" endWordPosition="1419">ment can be realized when using automatic methods for MWU recognition”. Several methods of increasing complexity have been proposed for fully automatic MWE tokenization: simple lexicon projection onto a corpus (Kulkarni and Finlayson, 2011), synchronous lexicon lookup and parsing (Wehrli et al., 2010; Seretan, 2011), token-based classifiers trained using 1117 association measures and other contextual features (Vincze et al., 2013a), or contextual sequence models like conditional random fields (Constant and Sigogne, 2011; Constant et al., 2013b; Vincze et al., 2013b) and structured perceptron (Schneider et al., 2014). In theory, compound function words like ADV+que and de+DET allow no internal variability, thus they should be represented as words-with-spaces. However, to date no satisfactory solution has been proposed for automatically tokenizing ambiguous MWEs. Green et al. (2013) propose a constituency parsing model which, as a by-product, performs MWE identification. They propose a flat representation for contiguous expressions in which all elements are attached to a special node, and then they compare several parsing models, including an original factored-lexicon PCFG and a tree substitution grammar. </context>
<context position="35822" citStr="Schneider et al., 2014" startWordPosition="5833" endWordPosition="5836"> computational questions. Some complex function words include more than two elements, like si bien que (so much that) and d’autant (plus) que (especially as). Moreover, they may contain nested expressions with different meanings and structures, e.g. tant que (as long as) is a conjunction but en tant que (as) is a preposition. The same applies for quantified partitive determiners, like beaucoup de (much) and un (petit) peu de (a (little) bit of). Their identification and representation is planned as a future extension to this work. We also would like to compare our approach to sequence models (Schneider et al., 2014). Careful error analysis could help us understand in which cases syntactic features can help. Moreover, different variants of the syntactic features and more sophisticated representation for syntactic lexicons can help improve MWE parsing further. For instance, we represent the subcat features of pronominal verbs and their simple versions with the same features, but they should be distinguished, e.g. se rappeler (remember) is +DE but rappeler (remind) is -DE. Acknowledgements This work has been funded by the French Agence Nationale pour la Recherche, through the projects ORFEO (ANR-12-CORP-000</context>
</contexts>
<marker>Schneider, Danchik, Dyer, Smith, 2014</marker>
<rawString>Nathan Schneider, Emily Danchik, Chris Dyer, and A. Noah Smith. 2014. Discriminative lexical semantic segmentation with gaps: Running the mwe gamut. Transactions of the Association of Computational Linguistics – Volume 2, Issue 1, pages 193– 206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Violeta Seretan</author>
</authors>
<title>Syntax-Based Collocation Extraction,</title>
<date>2011</date>
<journal>Text, Speech and Language</journal>
<volume>44</volume>
<pages>212</pages>
<publisher>Technology. Springer,</publisher>
<location>Dordrecht, Netherlands,</location>
<contexts>
<context position="8574" citStr="Seretan, 2011" startWordPosition="1374" endWordPosition="1376">r one based on gold pre-tokenization. Their results show that the former model can recognize MWEs with F1=71.1%, while the latter can significantly improve parsing accuracy and robustness in general. However, the authors admit that “it remains to be seen how much of theoretically possible improvement can be realized when using automatic methods for MWU recognition”. Several methods of increasing complexity have been proposed for fully automatic MWE tokenization: simple lexicon projection onto a corpus (Kulkarni and Finlayson, 2011), synchronous lexicon lookup and parsing (Wehrli et al., 2010; Seretan, 2011), token-based classifiers trained using 1117 association measures and other contextual features (Vincze et al., 2013a), or contextual sequence models like conditional random fields (Constant and Sigogne, 2011; Constant et al., 2013b; Vincze et al., 2013b) and structured perceptron (Schneider et al., 2014). In theory, compound function words like ADV+que and de+DET allow no internal variability, thus they should be represented as words-with-spaces. However, to date no satisfactory solution has been proposed for automatically tokenizing ambiguous MWEs. Green et al. (2013) propose a constituency </context>
</contexts>
<marker>Seretan, 2011</marker>
<rawString>Violeta Seretan. 2011. Syntax-Based Collocation Extraction, volume 44 of Text, Speech and Language Technology. Springer, Dordrecht, Netherlands, 1st edition. 212 p.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karel van den Eynde</author>
<author>Piet Mertens</author>
</authors>
<title>La valence: l’approche pronominale et son application au lexique verbal.</title>
<date>2003</date>
<journal>Journal of French Language Studies,</journal>
<marker>van den Eynde, Mertens, 2003</marker>
<rawString>Karel van den Eynde and Piet Mertens. 2003. La valence: l’approche pronominale et son application au lexique verbal. Journal of French Language Studies, (13):63–104.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aline Villavicencio</author>
<author>Valia Kordoni</author>
<author>Yi Zhang</author>
<author>Marco Idiart</author>
<author>Carlos Ramisch</author>
</authors>
<title>Validation and evaluation of automatically acquired multiword expressions for grammar engineering.</title>
<date>2007</date>
<booktitle>Proc. of the 2007 Joint Conference on EMNLP and Computational NLL (EMNLP-CoNLL 2007),</booktitle>
<pages>1034--1043</pages>
<editor>In Jason Eisner, editor,</editor>
<publisher>ACL.</publisher>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="7593" citStr="Villavicencio et al., 2007" startWordPosition="1222" endWordPosition="1226">to the parser. Section 6 describes the data sets used for the experiments, which results are presented and discussed in Section 7. Section 8 concludes the paper. 2 Related Work The famous “pain-in-the-neck” article by Sag et al. (2002) discusses MWEs in parsers, contrasting two representation alternatives in the LinGO ERG HPSG grammar of English: compositional rules and words-with-spaces. The addition of compositional rules for flexible MWEs has been tested in a small-scale experiment which showed significant coverage improvements in HPSG parsing by the addition of 21 new MWEs to the grammar (Villavicencio et al., 2007). It has been demonstrated that pre-grouping MWEs as words-with-spaces can improve the performance of shallow parsing for English (Korkontzelos and Manandhar, 2010). Nivre and Nilsson (2004) obtained similar results for dependency parsing of Swedish. They compare models trained on two representations: one where MWEs are linked by a special ID dependency, and another one based on gold pre-tokenization. Their results show that the former model can recognize MWEs with F1=71.1%, while the latter can significantly improve parsing accuracy and robustness in general. However, the authors admit that “</context>
</contexts>
<marker>Villavicencio, Kordoni, Zhang, Idiart, Ramisch, 2007</marker>
<rawString>Aline Villavicencio, Valia Kordoni, Yi Zhang, Marco Idiart, and Carlos Ramisch. 2007. Validation and evaluation of automatically acquired multiword expressions for grammar engineering. In Jason Eisner, editor, Proc. of the 2007 Joint Conference on EMNLP and Computational NLL (EMNLP-CoNLL 2007), pages 1034–1043, Prague, Czech Republic, Jun. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veronika Vincze</author>
<author>Istv´an Nagy T</author>
<author>Rich´ard Farkas</author>
</authors>
<title>Identifying English and Hungarian light verb constructions: A contrastive approach.</title>
<date>2013</date>
<booktitle>In Proc. of the 51st ACL (Volume 2: Short Papers),</booktitle>
<pages>255--261</pages>
<publisher>ACL.</publisher>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="8690" citStr="Vincze et al., 2013" startWordPosition="1388" endWordPosition="1391">, while the latter can significantly improve parsing accuracy and robustness in general. However, the authors admit that “it remains to be seen how much of theoretically possible improvement can be realized when using automatic methods for MWU recognition”. Several methods of increasing complexity have been proposed for fully automatic MWE tokenization: simple lexicon projection onto a corpus (Kulkarni and Finlayson, 2011), synchronous lexicon lookup and parsing (Wehrli et al., 2010; Seretan, 2011), token-based classifiers trained using 1117 association measures and other contextual features (Vincze et al., 2013a), or contextual sequence models like conditional random fields (Constant and Sigogne, 2011; Constant et al., 2013b; Vincze et al., 2013b) and structured perceptron (Schneider et al., 2014). In theory, compound function words like ADV+que and de+DET allow no internal variability, thus they should be represented as words-with-spaces. However, to date no satisfactory solution has been proposed for automatically tokenizing ambiguous MWEs. Green et al. (2013) propose a constituency parsing model which, as a by-product, performs MWE identification. They propose a flat representation for contiguous</context>
<context position="9965" citStr="Vincze et al. (2013" startWordPosition="1580" endWordPosition="1583">cial node, and then they compare several parsing models, including an original factored-lexicon PCFG and a tree substitution grammar. These generic parsing models can be used for parsing in general, but they have interesting memorization properties which favor MWE identification. Their experiments on French and Arabic show that the proposed models beat the baseline in MWE identification while producing acceptable general parsing results. Candito and Constant (2014) and Vincze et al. (2013c) present experiments on dependency parsing for MWE identification which are the closest to our settings. Vincze et al. (2013c) focus on light verb constructions in Hungarian. They propose distinguishing regular verbal dependencies from light verbs and their complements through four special labels prefixed by LCV-. Then, they train the Bohnet parser (Bohnet, 2010) using standard parameters and features, and evaluate on a gold test set. They report no significant changes in attachment scores, whereas F1 for light verb identification is 75.63%, significantly higher than the baseline methods of lexicon projection (21.25%) and classification (74.45%). Candito and Constant (2014) compare several architectures for depende</context>
<context position="24696" citStr="Vincze et al., 2013" startWordPosition="4004" endWordPosition="4007">kept, as described in Section 5, the subcat features -QUE, +QUE, -DE and +DE of each verb. Table 3 below shows the number of verbal entries having each of our four subcat features. Although the number of verbs described in DicoValence is moderate, its coverage is high on our data sets. It is equal to 97.82% on the FTB test set and is equal to 95.48% on the MORPH dataset. -QUE +QUE -DE +DE 3,814 356 3,450 720 Table 3: Number of verbs in DicoValence per value of subcat feature. 6.2 Evaluation We evaluate our models on two aspects: parsing quality and MWE identification (Nivre and Nilsson, 2004; Vincze et al., 2013c; Candito and Constant, 2014). First, we use standard parsing attachment scores to verify whether our models impact parsing performance in general. We compare the generated dependency trees with the reference in the test portion of the FTB, reporting the proportion of matched links, both in terms of structure – unlabeled attachment score (UAS) – and of labeled links – labeled attachment score (LAS). Since our focus is on MWE parsing, we are also 8http://bach.arts.kuleuven.be/ dicovalence/ 1121 interested in MWE identification metrics. We focus on words whose dependency label is MORPH and calc</context>
</contexts>
<marker>Vincze, T, Farkas, 2013</marker>
<rawString>Veronika Vincze, Istv´an Nagy T., and Rich´ard Farkas. 2013a. Identifying English and Hungarian light verb constructions: A contrastive approach. In Proc. of the 51st ACL (Volume 2: Short Papers), pages 255– 261, Sofia, Bulgaria, Aug. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veronika Vincze</author>
<author>Istv´an Nagy T</author>
<author>J´anos Zsibrita</author>
</authors>
<title>Learning to detect english and hungarian light verb constructions.</title>
<date>2013</date>
<journal>ACM Trans. Speech</journal>
<volume>10</volume>
<issue>2</issue>
<contexts>
<context position="8690" citStr="Vincze et al., 2013" startWordPosition="1388" endWordPosition="1391">, while the latter can significantly improve parsing accuracy and robustness in general. However, the authors admit that “it remains to be seen how much of theoretically possible improvement can be realized when using automatic methods for MWU recognition”. Several methods of increasing complexity have been proposed for fully automatic MWE tokenization: simple lexicon projection onto a corpus (Kulkarni and Finlayson, 2011), synchronous lexicon lookup and parsing (Wehrli et al., 2010; Seretan, 2011), token-based classifiers trained using 1117 association measures and other contextual features (Vincze et al., 2013a), or contextual sequence models like conditional random fields (Constant and Sigogne, 2011; Constant et al., 2013b; Vincze et al., 2013b) and structured perceptron (Schneider et al., 2014). In theory, compound function words like ADV+que and de+DET allow no internal variability, thus they should be represented as words-with-spaces. However, to date no satisfactory solution has been proposed for automatically tokenizing ambiguous MWEs. Green et al. (2013) propose a constituency parsing model which, as a by-product, performs MWE identification. They propose a flat representation for contiguous</context>
<context position="9965" citStr="Vincze et al. (2013" startWordPosition="1580" endWordPosition="1583">cial node, and then they compare several parsing models, including an original factored-lexicon PCFG and a tree substitution grammar. These generic parsing models can be used for parsing in general, but they have interesting memorization properties which favor MWE identification. Their experiments on French and Arabic show that the proposed models beat the baseline in MWE identification while producing acceptable general parsing results. Candito and Constant (2014) and Vincze et al. (2013c) present experiments on dependency parsing for MWE identification which are the closest to our settings. Vincze et al. (2013c) focus on light verb constructions in Hungarian. They propose distinguishing regular verbal dependencies from light verbs and their complements through four special labels prefixed by LCV-. Then, they train the Bohnet parser (Bohnet, 2010) using standard parameters and features, and evaluate on a gold test set. They report no significant changes in attachment scores, whereas F1 for light verb identification is 75.63%, significantly higher than the baseline methods of lexicon projection (21.25%) and classification (74.45%). Candito and Constant (2014) compare several architectures for depende</context>
<context position="24696" citStr="Vincze et al., 2013" startWordPosition="4004" endWordPosition="4007">kept, as described in Section 5, the subcat features -QUE, +QUE, -DE and +DE of each verb. Table 3 below shows the number of verbal entries having each of our four subcat features. Although the number of verbs described in DicoValence is moderate, its coverage is high on our data sets. It is equal to 97.82% on the FTB test set and is equal to 95.48% on the MORPH dataset. -QUE +QUE -DE +DE 3,814 356 3,450 720 Table 3: Number of verbs in DicoValence per value of subcat feature. 6.2 Evaluation We evaluate our models on two aspects: parsing quality and MWE identification (Nivre and Nilsson, 2004; Vincze et al., 2013c; Candito and Constant, 2014). First, we use standard parsing attachment scores to verify whether our models impact parsing performance in general. We compare the generated dependency trees with the reference in the test portion of the FTB, reporting the proportion of matched links, both in terms of structure – unlabeled attachment score (UAS) – and of labeled links – labeled attachment score (LAS). Since our focus is on MWE parsing, we are also 8http://bach.arts.kuleuven.be/ dicovalence/ 1121 interested in MWE identification metrics. We focus on words whose dependency label is MORPH and calc</context>
</contexts>
<marker>Vincze, T, Zsibrita, 2013</marker>
<rawString>Veronika Vincze, Istv´an Nagy T., and J´anos Zsibrita. 2013b. Learning to detect english and hungarian light verb constructions. ACM Trans. Speech and Lang. Process. Special Issue on MWEs: from theory to practice and use, part 1 (TSLP), 10(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veronika Vincze</author>
<author>J´anos Zsibrita</author>
<author>Istv´an Nagy T</author>
</authors>
<title>Dependency parsing for identifying hungarian light verb constructions.</title>
<date>2013</date>
<journal>Asian Federation of Natural Language Processing.</journal>
<booktitle>In Proceedings of the Sixth International Joint Conference on Natural Language Processing,</booktitle>
<pages>207--215</pages>
<location>Nagoya, Japan,</location>
<contexts>
<context position="8690" citStr="Vincze et al., 2013" startWordPosition="1388" endWordPosition="1391">, while the latter can significantly improve parsing accuracy and robustness in general. However, the authors admit that “it remains to be seen how much of theoretically possible improvement can be realized when using automatic methods for MWU recognition”. Several methods of increasing complexity have been proposed for fully automatic MWE tokenization: simple lexicon projection onto a corpus (Kulkarni and Finlayson, 2011), synchronous lexicon lookup and parsing (Wehrli et al., 2010; Seretan, 2011), token-based classifiers trained using 1117 association measures and other contextual features (Vincze et al., 2013a), or contextual sequence models like conditional random fields (Constant and Sigogne, 2011; Constant et al., 2013b; Vincze et al., 2013b) and structured perceptron (Schneider et al., 2014). In theory, compound function words like ADV+que and de+DET allow no internal variability, thus they should be represented as words-with-spaces. However, to date no satisfactory solution has been proposed for automatically tokenizing ambiguous MWEs. Green et al. (2013) propose a constituency parsing model which, as a by-product, performs MWE identification. They propose a flat representation for contiguous</context>
<context position="9965" citStr="Vincze et al. (2013" startWordPosition="1580" endWordPosition="1583">cial node, and then they compare several parsing models, including an original factored-lexicon PCFG and a tree substitution grammar. These generic parsing models can be used for parsing in general, but they have interesting memorization properties which favor MWE identification. Their experiments on French and Arabic show that the proposed models beat the baseline in MWE identification while producing acceptable general parsing results. Candito and Constant (2014) and Vincze et al. (2013c) present experiments on dependency parsing for MWE identification which are the closest to our settings. Vincze et al. (2013c) focus on light verb constructions in Hungarian. They propose distinguishing regular verbal dependencies from light verbs and their complements through four special labels prefixed by LCV-. Then, they train the Bohnet parser (Bohnet, 2010) using standard parameters and features, and evaluate on a gold test set. They report no significant changes in attachment scores, whereas F1 for light verb identification is 75.63%, significantly higher than the baseline methods of lexicon projection (21.25%) and classification (74.45%). Candito and Constant (2014) compare several architectures for depende</context>
<context position="24696" citStr="Vincze et al., 2013" startWordPosition="4004" endWordPosition="4007">kept, as described in Section 5, the subcat features -QUE, +QUE, -DE and +DE of each verb. Table 3 below shows the number of verbal entries having each of our four subcat features. Although the number of verbs described in DicoValence is moderate, its coverage is high on our data sets. It is equal to 97.82% on the FTB test set and is equal to 95.48% on the MORPH dataset. -QUE +QUE -DE +DE 3,814 356 3,450 720 Table 3: Number of verbs in DicoValence per value of subcat feature. 6.2 Evaluation We evaluate our models on two aspects: parsing quality and MWE identification (Nivre and Nilsson, 2004; Vincze et al., 2013c; Candito and Constant, 2014). First, we use standard parsing attachment scores to verify whether our models impact parsing performance in general. We compare the generated dependency trees with the reference in the test portion of the FTB, reporting the proportion of matched links, both in terms of structure – unlabeled attachment score (UAS) – and of labeled links – labeled attachment score (LAS). Since our focus is on MWE parsing, we are also 8http://bach.arts.kuleuven.be/ dicovalence/ 1121 interested in MWE identification metrics. We focus on words whose dependency label is MORPH and calc</context>
</contexts>
<marker>Vincze, Zsibrita, T, 2013</marker>
<rawString>Veronika Vincze, J´anos Zsibrita, and Istv´an Nagy T. 2013c. Dependency parsing for identifying hungarian light verb constructions. In Proceedings of the Sixth International Joint Conference on Natural Language Processing, pages 207–215, Nagoya, Japan, October. Asian Federation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Wehrli</author>
<author>Violeta Seretan</author>
<author>Luka Nerima</author>
</authors>
<title>Sentence analysis and collocation identification.</title>
<date>2010</date>
<booktitle>Proc. of the COLING Workshop on MWEs: from Theory to Applications (MWE 2010),</booktitle>
<pages>27--35</pages>
<editor>In ´Eric Laporte, Preslav Nakov, Carlos Ramisch, and Aline Villavicencio, editors,</editor>
<publisher>ACL.</publisher>
<location>Beijing, China,</location>
<contexts>
<context position="8558" citStr="Wehrli et al., 2010" startWordPosition="1370" endWordPosition="1373">ependency, and another one based on gold pre-tokenization. Their results show that the former model can recognize MWEs with F1=71.1%, while the latter can significantly improve parsing accuracy and robustness in general. However, the authors admit that “it remains to be seen how much of theoretically possible improvement can be realized when using automatic methods for MWU recognition”. Several methods of increasing complexity have been proposed for fully automatic MWE tokenization: simple lexicon projection onto a corpus (Kulkarni and Finlayson, 2011), synchronous lexicon lookup and parsing (Wehrli et al., 2010; Seretan, 2011), token-based classifiers trained using 1117 association measures and other contextual features (Vincze et al., 2013a), or contextual sequence models like conditional random fields (Constant and Sigogne, 2011; Constant et al., 2013b; Vincze et al., 2013b) and structured perceptron (Schneider et al., 2014). In theory, compound function words like ADV+que and de+DET allow no internal variability, thus they should be represented as words-with-spaces. However, to date no satisfactory solution has been proposed for automatically tokenizing ambiguous MWEs. Green et al. (2013) propose</context>
</contexts>
<marker>Wehrli, Seretan, Nerima, 2010</marker>
<rawString>Eric Wehrli, Violeta Seretan, and Luka Nerima. 2010. Sentence analysis and collocation identification. In ´Eric Laporte, Preslav Nakov, Carlos Ramisch, and Aline Villavicencio, editors, Proc. of the COLING Workshop on MWEs: from Theory to Applications (MWE 2010), pages 27–35, Beijing, China, Aug. ACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>