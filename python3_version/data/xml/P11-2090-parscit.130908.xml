<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.067752">
<title confidence="0.996481">
Typed Graph Models for Semi-Supervised Learning of Name Ethnicity
</title>
<author confidence="0.997044">
Delip Rao David Yarowsky
</author>
<affiliation confidence="0.901416">
Dept. of Computer Science Dept. of Computer Science
Johns Hopkins University Johns Hopkins University
</affiliation>
<email confidence="0.999512">
delip@cs.jhu.edu yarowsky@cs.jhu.edu
</email>
<sectionHeader confidence="0.995651" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998395">
This paper presents an original approach to
semi-supervised learning of personal name
ethnicity from typed graphs of morphophone-
mic features and first/last-name co-occurrence
statistics. We frame this as a general solu-
tion to an inference problem over typed graphs
where the edges represent labeled relations be-
tween features that are parameterized by the
edge types. We propose a framework for
parameter estimation on different construc-
tions of typed graphs for this problem us-
ing a gradient-free optimization method based
on grid search. Results on both in-domain
and out-of-domain data show significant gains
over 30% accuracy improvement using the
techniques presented in the paper.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999098033333333">
In the highly relational world of NLP, graphs are
a natural way to represent relations and constraints
among entities of interest. Even problems that are
not obviously graph based can be effectively and
productively encoded as a graph. Such an encoding
will often be comprised of nodes, edges that repre-
sent the relation, and weights on the edges that could
be a metric or a probability-based value, and type
information for the nodes and edges. Typed graphs
are a frequently-used formalism in natural language
problems including dependency parsing (McDonald
et al., 2005), entity disambiguation (Minkov and Co-
hen, 2007), and social networks to just mention a
few.
In this paper, we consider the problem of iden-
tifying a personal attribute such as ethnicity from
514
only an observed first-name/last-name pair. This has
important consequences in targeted advertising and
personalization in social networks, and in gathering
intelligence for business and government research.
We propose a parametrized typed graph framework
for this problem and perform the hidden attribute in-
ference using random walks on typed graphs. We
also propose a novel application of a gradient-free
optimization technique based on grid search for pa-
rameter estimation in typed graphs. Although, we
describe this in the context of person-attribute learn-
ing, the techniques are general enough to be applied
to various typed graph based problems.
</bodyText>
<sectionHeader confidence="0.990888" genericHeader="method">
2 Data for Person-Ethnicity Learning
</sectionHeader>
<bodyText confidence="0.9999615">
Name ethnicity detection is a particularly challeng-
ing (and practical) problem in Nigeria given that
it has more than 250 ethnicities1 with minor vari-
ations. We constructed a dictionary of Nigerian
names and their associated ethnicity by crawling
baby name sites and other Nigerian diaspora web-
sites (e.g. onlinenigeria.com) to compile a name dic-
tionary of 1980 names with their ethnicity. We re-
tained the top 4 ethnicities – Yoruba, Igbo, Efik
Ibibio, and Benin Edo2. In addition we also crawled
Facebook to identify Nigerians from different com-
munities. There are more details to this dataset that
</bodyText>
<footnote confidence="0.993852428571429">
1https://www.cia.gov/library/publications/the-world-
factbook/geos/ni.html
2Although the Hausa-Fulani is a populous community from
the north of Nigeria, we did not include it as our dictionary had
very few Hausa-Fulani names. Further, Hausa-Fulani names are
predominantly Arabic or Arabic derivatives and stand out from
the rest of the ethnic groups, making their detection easier.
</footnote>
<note confidence="0.836334">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 514–518,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.9898375">
will be made available with the data itself for future
research.
</bodyText>
<sectionHeader confidence="0.904228" genericHeader="method">
3 Random Walks on Typed Graphs
</sectionHeader>
<bodyText confidence="0.996486428571429">
Consider a graph G = (V, E), with edge set E de-
fined on the vertices in V . A typed graph is one
where every vertex v in V has an associated type
t„ E TV . Analogously, we also use edge types
TE C_ TV x TV . Some examples of typed edges
and vertices used in this paper are shown in Table 1.
These will be elaborated further in Section 4.
</bodyText>
<table confidence="0.998646166666667">
Vertices POSITIONAL BIGRAM, BIGRAM,
TRIGRAM, FIRST NAME, LAST NAME,...
Edges POSITION (POSITIONAL BIGRAM → BIGRAM),
32BACKOFF (TRIGRAM → BIGRAM),
CONCURRENCE (FIRST NAME → LAST NAME),
. . .
</table>
<tableCaption confidence="0.993937">
Table 1: Example types for vertices and edges in the
graph for name morpho-phonemics
</tableCaption>
<bodyText confidence="0.999648913043478">
With every edge type to E TE we associate a real-
valued parameter 0 E [0, 1]. Thus our graph is pa-
rameterized by a set of parameters O with |O |=
|TE|. We will need to learn these parameters from
the training data; more on this in Section 5. We re-
lax the estimation problem by forcing the graph to
be undirected. This effectively reduces the number
of parameters by half.
We now have a weighted graph with a weight
matrix W(0). The probability transition matrix
P(0) for the random walk is derived by noting
P(0) = D(0)−1W(0) where D(0) is the diagonal
weighted-degree matrix, i.e, dii(0) = Ej wij(0).
From this point on, we rely on standard label-
propagation based semi-supervised classification
techniques (Zhu et al., 2003; Baluja et al., 2008;
Talukdar et al., 2008) that work by spreading proba-
bility mass across the edges in the graph. While tra-
ditional label propagation methods proceed by con-
structing graphs using some kernel or arbitrary sim-
ilarity measures, our method estimates the appro-
priate weight matrix from training data using grid
search.
</bodyText>
<sectionHeader confidence="0.98552" genericHeader="method">
4 Graph construction
</sectionHeader>
<bodyText confidence="0.998986357142857">
Our graphs have two kinds of nodes – nodes we want
to classify – called target nodes and feature nodes
which correspond to different feature types. Some
of the target nodes can optionally have label infor-
mation, these are called seed nodes and are excluded
from evaluation. Every feature instance has its own
node and an edge exists between a target node and
a feature node if the target node instantiates the fea-
ture. Features are not independent. For example the
trigram aba also indicates the presence of the bi-
grams ab and ba . We encode this relationship
between features by adding typed edges. For in-
stance, in the previous case, a typed edge (32BACK-
OFF) is added between the trigram aba and the bi-
gram ab representing the backoff relation. In the
absence of these edges between features, our graph
would have been bipartite. We experimented with
three kinds of graphs for this task:
First name/Last name (FN LN) graph
As a first attempt, we only considered first and last
names as features generated by a name. The name
we wish to classify is treated as a target node. There
are two typed relations 1) between the first and last
name, called CONCURRENCE, where the first and
last names occur together and 2) Where an edge,
SHARED NAME, exists between two first (last)
names if they share a last (first) name. Hence there
are only two parameters to estimate here.
</bodyText>
<figureCaption confidence="0.994297">
Figure 1: A part of the First name/Last name graph:
Edges indicate co-occurrence or a shared name.
</figureCaption>
<subsectionHeader confidence="0.580698">
Character Ngram graph
</subsectionHeader>
<bodyText confidence="0.999808">
The ethnicity of personal names are often indi-
cated by morphophonemic features of the individ-
ual’s given/first or family/last names. For exam-
ple, the last names Polanski, Piotrowski, Soszyn-
ski, Sikorski with the suffix ski indicate Polish de-
scent. Instead of writing suffix rules, we generate
character n-gram features from names ranging from
</bodyText>
<page confidence="0.995908">
515
</page>
<figureCaption confidence="0.923798666666667">
Figure 2: A part of the character n-gram graph: Ob-
serve how the suffix osun contributes to the inference
of adeosun as a Yoruba name even though it was never
seen in training. The different colors on the edges rep-
resent edge types whose weights are estimated from the
data.
</figureCaption>
<bodyText confidence="0.989196">
bigrams to 5-grams and all orders in-between. We
further distinguish n-grams that appear in the begin-
ning (corresponding to prefixes), middle, and end
(corresponding to suffixes). Thus the last name,
mosun in the graph is connected to the follow-
ing positional trigrams mos-BEG , osu-MID ,
sun-END besides positional n-grams of other or-
</bodyText>
<sectionHeader confidence="0.895203" genericHeader="method">
5 Grid Search for Parameter Estimation
</sectionHeader>
<bodyText confidence="0.999262173913044">
The typed graph we constructed in the previous sec-
tion has as many parameters as the number of edge
types, i.e, |O |= |TE|. We further constrain the val-
ues taken by the parameters to be in the range [0, 1].
Note that there is no loss of representation in doing
so, as arbitrary real-valued weights on edges can be
normalized to the range [0, 1]. Our objective is to
find a set of values for O that maximizes the classi-
fication accuracy. Towards that effect, we quantize
the range [0, 1] into k equally sized bins and con-
vert this to a discrete-valued optimization problem.
While this is an approximation, our experience finds
that relative values of the various BZ E O are more
important than the absolute values for label propa-
gation.
ders. The positional trigram mos-BEG connected Figure 3: Grid search on a unit 2-simplex with k = 4.
to the position-independent trigram mos using the
typed edge POSITION. Further, the trigram mos
is connected to the bigrams mo and os using
a 32BACKOFF edge. The resulting graph has
four typed relations – 32BACKOFF, 43BACKOFF,
45BACKOFF, and POSITION – and four corre-
sponding parameters to be estimated.
</bodyText>
<subsectionHeader confidence="0.821278">
Combined graph
</subsectionHeader>
<bodyText confidence="0.99934">
Finally, we consider the union of the character n-
gram graph and the FirstName-LastName graph. Ta-
ble 2 lists some summary statistics for the various
graphs.
</bodyText>
<table confidence="0.9979925">
#Vertices #Edges Avg. degree
FN LN 22.8K 137.2K 3.6
CHAR. NGRAM 282.6K 1.2M 8.7
COMBINED 282.6K 1.3M 9.2
</table>
<tableCaption confidence="0.995651">
Table 2: Graphs for person name ethnicity classification
</tableCaption>
<bodyText confidence="0.999938111111111">
The complexity of this search procedure is O(kn)
for k bins and n parameters. For problems with
small number of parameters, like ours (n = 4 or
n = 2 depending on the graph model), and with
fewer bins this search is still tractable although com-
putationally expensive. We set k = 4; this results
in 256 combinations to be searched at most and we
evaluate each combination in parallel on a cluster.
Clearly, this exhaustive search works only for prob-
lems with few parameters. However, grid search can
still be used in problems with large number of edge
types using one of the following two techniques: 1)
Randomly sample with replacement from a Dirichlet
distribution with same order as the number of bins.
Evaluate using parameter values from each sample
on the development set. Select the parameter values
that result in highest accuracy on the development
set from a large number of samples. 2) Perform a
</bodyText>
<page confidence="0.99546">
516
</page>
<bodyText confidence="0.9999792">
coarse grained search first using a small k on the
range [0, 1] and use that result to shrink the search
range. Perform grid search again on this smaller
range. We simply search exhaustively given the na-
ture of our problem.
</bodyText>
<sectionHeader confidence="0.986307" genericHeader="evaluation">
6 Experiments &amp; Results
</sectionHeader>
<bodyText confidence="0.999829214285714">
We evaluated our three different model variants un-
der two settings: 1) When only a weak prior from
the dictionary data is present; we call this ‘out-of-
domain’ since we don’t use any labels from Face-
book and 2) when both the dictionary prior and some
labels from the Facebook data is present; we call this
‘in-domain’. The results are reported using 10-fold
cross-validation. In addition to the proposed typed
graph models, we show results from a smoothed-
Naive Bayes implementation and two standard base-
lines 1) where labels are assigned uniformly at ran-
dom (UNIFORM) and 2) where labels are assigned
according the empirical prior distribution (PRIOR).
The baseline accuracies are shown in Table 3.
</bodyText>
<table confidence="0.9985415">
Out-of-domain In-domain
UNIFORM 25.0 25.0
PRIOR 42.6 42.6
Naive Bayes 75.1 77.2
</table>
<tableCaption confidence="0.991221">
Table 3: Ethnicity-classification accuracy from baseline
classifiers.
</tableCaption>
<bodyText confidence="0.887515">
We performed similar in-domain and out-of-
domain experiments for each of the graph models
proposed in Section 4 and list the results in Table 4,
without using grid search.
</bodyText>
<table confidence="0.999149166666667">
Out-of-domain In-domain
FN LN 57.6 60.2
CHAR. NGRAM 73.2 76.8
%gain over FN LN 27% 27.6%
COMBINED 77.1 78.7
%gain over CHAR. NGRAM 5.3% 2.5%
</table>
<tableCaption confidence="0.81490175">
Table 4: Ethnicity-classification accuracy without grid
search
Some points to note about the results reported in
Table 4: 1) These results were obtained without us-
</tableCaption>
<bodyText confidence="0.994057214285714">
ing parameters from the grid search based optimiza-
tion. 2) The character n-gram graph model performs
better than the first-name/last-name graph model by
itself, as expected due to the smoothing induced by
the backoff edge types. 3) The combination of first-
name/last-name graph and the n-gram improves ac-
curacy by over 30%.
Table 5 reports results from using parameters es-
timated using grid search. The parameter estimation
was done on a development set that was not used
in the 10-fold cross-validation results reported in the
table. Observe that the parameters estimated via grid
search always improved performance of label prop-
agation.
</bodyText>
<table confidence="0.99892925">
Out-of-domain In-domain
FN LN 59.1 61.4
CHAR. NGRAM 76.7 78.5
COMBINED 78.6 80.1
Improvements by grid search (c.f., Table 4)
FN LN 2.6% 2%
CHAR. NGRAM 4.8% 2.2%
COMBINED 1.5% 1.7%
</table>
<tableCaption confidence="0.963201">
Table 5: Ethnicity-classification accuracy with grid
search
</tableCaption>
<sectionHeader confidence="0.99792" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.9999966">
We considered the problem of learning a person’s
ethnicity from his/her name as an inference prob-
lem over typed graphs, where the edges represent la-
beled relations between features that are parameter-
ized by the edge types. We developed a framework
for parameter estimation on different constructions
of typed graphs for this problem using a gradient-
free optimization method based on grid search. We
also proposed alternatives to scale up grid search for
large problem instances. Our results show a sig-
nificant performance improvement over the baseline
and this performance is further improved by param-
eter estimation resulting over 30% improvement in
accuracy using the conjunction of techniques pro-
posed for the task.
</bodyText>
<sectionHeader confidence="0.999477" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99975875">
Shumeet Baluja, Rohan Seth, D. Sivakumar, Yushi Jing,
Jay Yagnik, Shankar Kumar, Deepak Ravichandran,
and Mohamed Aly. 2008. Video suggestion and dis-
covery for youtube: taking random walks through the
view graph. In Proceeding of the 17th international
conference on World Wide Web.
Jonathan Chang, Itamar Rosenn, Lars Backstrom, and
Cameron Marlow. 2010. epluribus: Ethnicity on so-
</reference>
<page confidence="0.968297">
517
</page>
<reference confidence="0.999663">
cial networks. In Proceedings of the International
Conference in Weblogs and Social Media (ICWSM).
Ryan McDonald, Fernando Pereira, Kiril Ribarov, and
Jan Hajiˇc. 2005. Non-projective dependency pars-
ing using spanning tree algorithms. In Proceedings of
the conference on Human Language Technology and
Empirical Methods in Natural Language Processing.
Association for Computational Linguistics.
Einat Minkov and William Cohen. 2007. Learning to
rank typed graph walks: local and global approaches.
In Proceedings of the 9th WebKDD and 1st SNA-KDD
2007 workshop on Web mining and social network
analysis, New York, NY, USA. ACM.
Partha Pratim Talukdar, Joseph Reisinger, Marius Pas¸ca,
Deepak Ravichandran, Rahul Bhagat, and Fernando
Pereira. 2008. Weakly-supervised acquisition of la-
beled class instances using graph random walks. In
Proceedings of the Conference on Empirical Meth-
ods in Natural Language Processing. Association for
Computational Linguistics.
Xiaojin Zhu, Zoubin Ghahramani, and John Lafferty.
2003. Semi-supervised learning using gaussian fields
and harmonic functions. In Proceedings of the Inter-
national Conference in Machine Learning, pages 912–
919.
</reference>
<page confidence="0.993881">
518
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.973676">
<title confidence="0.994319">Typed Graph Models for Semi-Supervised Learning of Name Ethnicity</title>
<author confidence="0.999477">Delip Rao David Yarowsky</author>
<affiliation confidence="0.999486">Dept. of Computer Science Dept. of Computer Science Johns Hopkins University Johns Hopkins University</affiliation>
<email confidence="0.999021">delip@cs.jhu.eduyarowsky@cs.jhu.edu</email>
<abstract confidence="0.998900705882353">This paper presents an original approach to semi-supervised learning of personal name ethnicity from typed graphs of morphophonemic features and first/last-name co-occurrence statistics. We frame this as a general solution to an inference problem over typed graphs where the edges represent labeled relations between features that are parameterized by the edge types. We propose a framework for parameter estimation on different constructions of typed graphs for this problem using a gradient-free optimization method based on grid search. Results on both in-domain and out-of-domain data show significant gains over 30% accuracy improvement using the techniques presented in the paper.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Shumeet Baluja</author>
<author>Rohan Seth</author>
<author>D Sivakumar</author>
<author>Yushi Jing</author>
<author>Jay Yagnik</author>
<author>Shankar Kumar</author>
<author>Deepak Ravichandran</author>
<author>Mohamed Aly</author>
</authors>
<title>Video suggestion and discovery for youtube: taking random walks through the view graph.</title>
<date>2008</date>
<booktitle>In Proceeding of the 17th international conference on World Wide Web.</booktitle>
<contexts>
<context position="5031" citStr="Baluja et al., 2008" startWordPosition="794" endWordPosition="797">meters O with |O |= |TE|. We will need to learn these parameters from the training data; more on this in Section 5. We relax the estimation problem by forcing the graph to be undirected. This effectively reduces the number of parameters by half. We now have a weighted graph with a weight matrix W(0). The probability transition matrix P(0) for the random walk is derived by noting P(0) = D(0)−1W(0) where D(0) is the diagonal weighted-degree matrix, i.e, dii(0) = Ej wij(0). From this point on, we rely on standard labelpropagation based semi-supervised classification techniques (Zhu et al., 2003; Baluja et al., 2008; Talukdar et al., 2008) that work by spreading probability mass across the edges in the graph. While traditional label propagation methods proceed by constructing graphs using some kernel or arbitrary similarity measures, our method estimates the appropriate weight matrix from training data using grid search. 4 Graph construction Our graphs have two kinds of nodes – nodes we want to classify – called target nodes and feature nodes which correspond to different feature types. Some of the target nodes can optionally have label information, these are called seed nodes and are excluded from evalu</context>
</contexts>
<marker>Baluja, Seth, Sivakumar, Jing, Yagnik, Kumar, Ravichandran, Aly, 2008</marker>
<rawString>Shumeet Baluja, Rohan Seth, D. Sivakumar, Yushi Jing, Jay Yagnik, Shankar Kumar, Deepak Ravichandran, and Mohamed Aly. 2008. Video suggestion and discovery for youtube: taking random walks through the view graph. In Proceeding of the 17th international conference on World Wide Web.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Chang</author>
<author>Itamar Rosenn</author>
<author>Lars Backstrom</author>
<author>Cameron Marlow</author>
</authors>
<title>epluribus: Ethnicity on social networks.</title>
<date>2010</date>
<booktitle>In Proceedings of the International Conference in Weblogs and Social Media (ICWSM).</booktitle>
<marker>Chang, Rosenn, Backstrom, Marlow, 2010</marker>
<rawString>Jonathan Chang, Itamar Rosenn, Lars Backstrom, and Cameron Marlow. 2010. epluribus: Ethnicity on social networks. In Proceedings of the International Conference in Weblogs and Social Media (ICWSM).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
<author>Kiril Ribarov</author>
<author>Jan Hajiˇc</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing. Association for Computational Linguistics.</booktitle>
<marker>McDonald, Pereira, Ribarov, Hajiˇc, 2005</marker>
<rawString>Ryan McDonald, Fernando Pereira, Kiril Ribarov, and Jan Hajiˇc. 2005. Non-projective dependency parsing using spanning tree algorithms. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Einat Minkov</author>
<author>William Cohen</author>
</authors>
<title>Learning to rank typed graph walks: local and global approaches.</title>
<date>2007</date>
<booktitle>In Proceedings of the 9th WebKDD and 1st SNA-KDD</booktitle>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1561" citStr="Minkov and Cohen, 2007" startWordPosition="229" endWordPosition="233">on In the highly relational world of NLP, graphs are a natural way to represent relations and constraints among entities of interest. Even problems that are not obviously graph based can be effectively and productively encoded as a graph. Such an encoding will often be comprised of nodes, edges that represent the relation, and weights on the edges that could be a metric or a probability-based value, and type information for the nodes and edges. Typed graphs are a frequently-used formalism in natural language problems including dependency parsing (McDonald et al., 2005), entity disambiguation (Minkov and Cohen, 2007), and social networks to just mention a few. In this paper, we consider the problem of identifying a personal attribute such as ethnicity from 514 only an observed first-name/last-name pair. This has important consequences in targeted advertising and personalization in social networks, and in gathering intelligence for business and government research. We propose a parametrized typed graph framework for this problem and perform the hidden attribute inference using random walks on typed graphs. We also propose a novel application of a gradient-free optimization technique based on grid search fo</context>
</contexts>
<marker>Minkov, Cohen, 2007</marker>
<rawString>Einat Minkov and William Cohen. 2007. Learning to rank typed graph walks: local and global approaches. In Proceedings of the 9th WebKDD and 1st SNA-KDD 2007 workshop on Web mining and social network analysis, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Partha Pratim Talukdar</author>
<author>Joseph Reisinger</author>
<author>Marius Pas¸ca</author>
<author>Deepak Ravichandran</author>
<author>Rahul Bhagat</author>
<author>Fernando Pereira</author>
</authors>
<title>Weakly-supervised acquisition of labeled class instances using graph random walks.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics.</booktitle>
<marker>Talukdar, Reisinger, Pas¸ca, Ravichandran, Bhagat, Pereira, 2008</marker>
<rawString>Partha Pratim Talukdar, Joseph Reisinger, Marius Pas¸ca, Deepak Ravichandran, Rahul Bhagat, and Fernando Pereira. 2008. Weakly-supervised acquisition of labeled class instances using graph random walks. In Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaojin Zhu</author>
<author>Zoubin Ghahramani</author>
<author>John Lafferty</author>
</authors>
<title>Semi-supervised learning using gaussian fields and harmonic functions.</title>
<date>2003</date>
<booktitle>In Proceedings of the International Conference in Machine Learning,</booktitle>
<pages>912--919</pages>
<contexts>
<context position="5010" citStr="Zhu et al., 2003" startWordPosition="790" endWordPosition="793">d by a set of parameters O with |O |= |TE|. We will need to learn these parameters from the training data; more on this in Section 5. We relax the estimation problem by forcing the graph to be undirected. This effectively reduces the number of parameters by half. We now have a weighted graph with a weight matrix W(0). The probability transition matrix P(0) for the random walk is derived by noting P(0) = D(0)−1W(0) where D(0) is the diagonal weighted-degree matrix, i.e, dii(0) = Ej wij(0). From this point on, we rely on standard labelpropagation based semi-supervised classification techniques (Zhu et al., 2003; Baluja et al., 2008; Talukdar et al., 2008) that work by spreading probability mass across the edges in the graph. While traditional label propagation methods proceed by constructing graphs using some kernel or arbitrary similarity measures, our method estimates the appropriate weight matrix from training data using grid search. 4 Graph construction Our graphs have two kinds of nodes – nodes we want to classify – called target nodes and feature nodes which correspond to different feature types. Some of the target nodes can optionally have label information, these are called seed nodes and ar</context>
</contexts>
<marker>Zhu, Ghahramani, Lafferty, 2003</marker>
<rawString>Xiaojin Zhu, Zoubin Ghahramani, and John Lafferty. 2003. Semi-supervised learning using gaussian fields and harmonic functions. In Proceedings of the International Conference in Machine Learning, pages 912– 919.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>