<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.968855">
ParseTalk about Sentence- and Text-Level Anaphora
</title>
<author confidence="0.993792">
Michael Strube and Udo Hahn
</author>
<affiliation confidence="0.988131">
CCM- - Computational Linguistics Research Group
Freiburg University
</affiliation>
<address confidence="0.634497">
D-79085 Freiburg, Germany
</address>
<email confidence="0.675697">
Istrube, hahnjecoling.uni-freiburg.de
</email>
<sectionHeader confidence="0.980912" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999239428571429">
We provide a unified account of sentence-level
and text-level anaphora within the framework of
a dependency-based grammar model. Criteria for
anaphora resolution within sentence boundaries
rephrase major concepts from GB&apos;s binding theory,
while those for text-level anaphora incorporate an
adapted version of a Grosz-Sidner-style focus model.
</bodyText>
<sectionHeader confidence="0.998793" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999985875">
This paper treats the resolution of anaphora with-
in the framework of Parse Talk, a dependency-
oriented grammar model that incorporates strict
lexicalization, head-orientation (based on valency
specifications), feature unification, and inheri-
tance among lexicalized grammar specifications
(Broker et al., 1994; Hahn et al., 1994). The re-
sults we present rest upon two major assumptions:
</bodyText>
<listItem confidence="0.990818333333333">
1. As many forms of anaphors (e.g., nomi-
nal and pronominal anaphors) occur within
sentence boundaries (so-called intra-sentential
or sentence anaphora) and beyond (inter-
sentential or text anaphora), adequate theo-
ries of anaphora should allow the formulation
of grammatical regularities for both types us-
ing a common set of grammatical primitives.
2. Anaphora are only one, yet very prominent
</listItem>
<bodyText confidence="0.966811543859649">
phenomenon that yields textual cohesion in
discourse. Adequate grammars should there-
fore also be easily extensible to cover non-
anaphoric text phenomena (e.g., coherence re-
lations, rhetorical predicates), which provide
for additional levels of text (macro) structure,
with descriptions stated at the same level of
theoretical sophistkation as for anaphora.
First, we will briefly compare our approach with
work done in the context of government-binding
(GB) grammar and discourse representation the-
ory (DRT). As we conceive it, binding theory as
developed within the GB framework (Chomsky,
1981; Kuno, 1987) offers one of the most sophis-
ticated approaches for treating anaphora at the
sentence level of description. This has also been
recognized by advocates of competing grammar
formalisms, who have elaborated on GB&apos;s bind-
ing principles (cf., e.g., Pollard and Sag (1992)
within the context of HPSG, whose treatment is
nevertheless restricted to reflexive pronouns). In-
terestingly enough, when faced with some cru-
cial linguistic phenomena, such as topicalization,
GB must assume rather complex movement oper-
ations in order to cope with the data in a satisfac-
tory manner. Things get even more complicated
when languages with relatively free word order,
such as German, are taken into account. Finally,
considering the case of text anaphora, binding the-
ory has nothing to offer at all.
Another strong alternative for considering ana-
phora constitutes the framework of DRT (Kamp
and Reyle, 1993). Its development can be con-
sidered a landmark in the model-theoretic se-
mantic analysis of various forms of quantified
sentences, conditionals, and anaphorically linked
multi-sentential discourse. At this level of descrip-
tion, DRT is clearly superior to GB. On the other
hand, its lack of an equally thorough treatment of
complex syntactic constructions makes it inferior
to GB. These deficits are no wonder, since DRT is
not committed to any particular syntactic theory,
and thus cannot place strict enough syntactic con-
straints on the admissible constituent structures.
Focusing on the text analysis potential of DRT, its
complex machinery might work in a satisfactory
way for several well-studied forms of anaphora,
but it necessarily fails if various non-anaphoric
text phenomena need to be interpreted. This is
particularly true of conceptually-rooted and prag-
matically driven inferences necessary to build up
textual macro structures in terms of coherence
relations (Hobbs, 1982) or rhetorical structures
(Mann and Thompson, 1988). This shortcoming
is simply due to the fact that DRT is basically a se-
mantic theory, not a comprehensive model for text
understanding; it lacks any systematic connec-
</bodyText>
<page confidence="0.992612">
237
</page>
<bodyText confidence="0.999970461538462">
tion to comprehensive reasoning systems covering
the conceptual knowledge and specific problem-
solving models underlying the chosen domain.
Summing up, DRT is fairly restricted both with
respect to the incorporation of powerful syntactic
constraints at the sentence level and its extension
to the level of (non-anaphoric) text macro struc-
tures. GB, on the other hand, is strong with re-
spect to the specification of binding conditions at
the sentence level, but offers no opportunity at all
to extend its analytic scope beyond that sentential
level. We claim, however, that the dependency-
based grammar model underlying Parse Talk
</bodyText>
<listItem confidence="0.919169136363637">
1. covers intra-sentential anaphora at the same
level of descriptive adequacy as current GB, al-
though it provides less complex representation
structures than GB analyses; these structures
are nevertheless expressive enough to capture
the relevant distinctions,
2. does not exhibit an increasing level of struc-
tural complexity when faced with crucial lin-
guistic phenomena which cause considerable
problems for current GB theory,
3. goes beyond GB in that it allows the treat-
ment of anaphora at the text level of descrip-
tion within the same grammar formalism as is
used for sentence level anaphora, and,
4. goes beyond the anaphora-centered treatment
of text structure characteristic of the DRT ap-
proach in that it already accounts for the reso-
lution of text-level ellipsis (sometimes also re-
ferred to as functional anaphora, cf. Hahn and
Strube (1995)) and the interpretation of text
macro structures (a preliminary study is pre-
sented in Hahn (1992)).
</listItem>
<sectionHeader confidence="0.972157" genericHeader="method">
2 DG Constraints on Anaphora
</sectionHeader>
<bodyText confidence="0.999913322580645">
In this section, we present, quite informally, some
constraints on intra-sentential anaphora in terms
of dependency grammar (DG). We will reconsider
these constraints in Section 3, where our grammar
model is dealt with in more depth. We provide
here a definition of d-binding and two constraints
which describe the use of reflexive pronouns and
anaphors (personal pronouns and definite noun
phrases). These constraints cover approximately
the same phenomena as the binding theory of GB
(Chomsky (1981); for a computational treatment,
cf. Correa (1988)).
Dependency structures, by definition, refer to
the sentence level of linguistic description only.
The relation of dependency holds between a lexi-
cal head and one or several modifiers of that head,
such that the occurrence of a head allows for the
occurrence of one or several modifiers (in some
pre-specified linear ordering), but not vice versa.
Speaking in terms of dependency structure rep-
resentations, the head always precedes and, thus,
(transitively) governs its associated modifiers in
the dependency tree. This basic notion of govern-
ment must be further refined for the description
of anaphoric relations in dependency trees (we do
not claim a universal status for the following con-
straints, but restrict their validity to the descrip-
tion of the German language):
D-binding: A modifier M is d-bound by some
head H, if no node N intervenes between M and H
for which one of the following conditions holds:
</bodyText>
<listItem confidence="0.7682115">
(i) node N represents a finite verb, or
(ii) node N represents a noun with a possessive
</listItem>
<bodyText confidence="0.8685842">
modifier, i.e., possessive determiners, Saxon geni-
tive, genitival and prepositional attributes.
Based on the definition of d-binding, we are able
to specify several constraints on reflexive pronouns
and anaphors in DG terms:
</bodyText>
<subsectionHeader confidence="0.587498">
Reflexive pronoun:
</subsectionHeader>
<bodyText confidence="0.999925666666667">
The reflexive pronoun and the antecedent to which
the reflexive pronoun refers are d-bound by the
same head.
</bodyText>
<subsectionHeader confidence="0.898367">
Pronominal and nominal anaphors:
</subsectionHeader>
<bodyText confidence="0.901341333333333">
(i) The antecedent a to which an anaphor 7r
refers must not be governed by the same head
which d-binds 7r, unless (ii) applies.
(ii) The antecedent a to which an anaphor 7r refers
may only be governed by the same head 11.1 which
d-binds r, if a is a modifier of a head H2, H2 is
governed by H.1, and a precedes ir in the linear
sequence of text items. Hence, a is not d-bound
by the head Hi which d-binds 7r.&apos;
We will now illustrate the working of these con-
straints, starting with the consideration of reflex-
ives. Usually, the antecedent of a reflexive pro-
noun is the subject of the clause to which the re-
flexive belongs. In (1), the subject Maria is d-
bound by the same head as the reflexive sich.
(1) Maria, wascht sich,
[Mary, washes herself,.]
Of course, the government relation between an-
tecedent and reflexive need not be an immediate
one. For instance, a preposition may occur be-
tween reflexive and verb, since the notion of d-
binding does not discriminate between NPs and
PPs (cf. (2)). If the finite verb is a modal or aux-
iliary verb, one or more non-finite verbs may occur
between the reflexive and the finite verb (cf. (3)).
The definition of d-binding roughly corresponds to
the governing category in GB terminology, which relies
upon the notion of c-command, while the latter two
grammar constraints correspond to the three major
binding principles of GB.
</bodyText>
<page confidence="0.989774">
238
</page>
<listItem confidence="0.8760545">
(2) Maria; lacht fiber sich.
[Mary, laughs about herself.]
(3) Maria, mochte sich, verbessern.
[Mary, wants to improve herself.]
</listItem>
<bodyText confidence="0.999511230769231">
If an intermediate node occurs between reflexive
and antecedent which denotes a noun with a pos-
sessive modifier, the reflexive is d-bound by this
noun (cf. (4) vs. (5)); hence, that modifier is the
antecedent of the reflexive. Though Maria is the
subject of (4), only Peter can be considered the
antecedent of the reflexive, since it is d-bound by
the head which d-binds Peter, viz. Geschichte (cf.
Fig. 1). If the intermediate noun has no posses-
sive modifiers, the subject of the entire clause is
the antecedent of the reflexive, since the reflexive
is d-bound by the finite verb irrespective of the
occurrence of the (object) NP (cf. (6)).
</bodyText>
<figure confidence="0.983396285714286">
arsihlt
subj
Maria Geschiahte
saxGen ppAtt
Uber
/90:_s;N\N,
Isiah
</figure>
<figureCaption confidence="0.999759">
Figure 1: Dependency Tree for Examples 4 and 5
</figureCaption>
<listItem confidence="0.948399666666667">
(4) Maria erzahlt Peters, Geschichte fiber sich,.
[Mary tells Peter&apos;s, story about himself.]
(5) &amp;quot; Maria, erzahlt Peters Geschichte iiber sich,.
[ • Mary, tells Peter&apos;s story about herself.]
(6) Maria, erzahlt eine Geschichte fiber sich,.
[Mary, tells a story about herself.]
</listItem>
<bodyText confidence="0.999737">
We will now consider constraints on intra-
sentential anaphora (personal pronouns and def-
inite NPs). As a general rule, the anaphor must
not occupy the position of the reflexive pronoun.
Hence, for all the examples given above, any of
those sentences becomes ungrammatical if the re-
flexives are replaced by non-reflexive anaphoric
expressions (cf. (7) vs. (2)).
</bodyText>
<listItem confidence="0.924782">
(7) * Maria, lacht fiber sie,.
[* Mary, laughs about her,.]
</listItem>
<bodyText confidence="0.997071529411765">
It is also obvious that whenever the anaphor be-
longs to a clause which is subordinate to one that
contains the antecedent, both may be coreferent:
this holds independently of the ordering of an-
tecedent and pronoun (cf. (8) vs. (11)). On the
other hand, if the anaphor belongs to the ma-
trix clause and the antecedent to the subordinate
clause, coreference is excluded (cf. (9)). But one
can easily think of cases where this rule is overrid-
den. Consider, e.g., a subordinate clause preced-
ing its matrix, as is always true for topicalizations.
The claim that a pronoun in the superordinate
clause must not be coreferent to an antecedent
in a subordinate clause is then obviously false (cf.
(10) and (11)). In (10), the antecedent Peteris not
d-bound by the head which d-binds the anaphor
er, and Peter precedes er. Therefore, coreference
</bodyText>
<listItem confidence="0.930639666666667">
is possible.2
(8) Peter, erwartet, daB er, einen Brief bekommt.
[Peter, expects that he, will get a letter.]
(9) * Er, erwartet, daB Peter, einen Brief bekommt.
[ • He, expects that Peter, will get a letter.]
(10) Dail Peter; einen Brief bekommt, erwartet er,.
[That Peter, will get a letter, he, expects.]
(11) Dail er, einen Brief bekommt, erwartet Peter,.
[That he, will get a letter, Peter; expects.]
</listItem>
<bodyText confidence="0.9964855">
Another special case arises if the antecedent is a
modifier of the subject of a sentence. In this case
the antecedent of a pronoun may be governed by
the head which d-binds the pronoun. In (12) the
pronoun belongs to the subordinate clause, but in
(13) the antecedent of the pronoun belongs to the
subordinate clause, and the example seems to be
acceptable. In (14), where the subject Vater is
modified by the genitive attribute des Gewinners,
the antecedent is governed by the head which also
d-binds the pronoun. Both the relative clause and
the genitive attribute are modifiers of the subject,
which usually occurs at the first position in the
German main clause. In this case, the antecedent
precedes the anaphor. Hence, coreference between
anaphor and antecedent must be granted.3
</bodyText>
<listItem confidence="0.846991166666667">
(12) Der Mann, der sie, kennt, griiilt die Frau,.
[The man who knows her, greets the wornan,.]
(13) Der Mann, der die Frau, kennt, grfillt sie,.
[The man who knows the woman, greets herd.]
(14) Der Vater des Gewinnersi gratuliert ihm,.
[The winner&apos;s, father congratulates him,.]
</listItem>
<bodyText confidence="0.81494505">
The incorporation of an ordering constraint is
even more justified if one looks at sentences which
have a similar structure, but are different with re-
spect to word order (cf. (15) vs. (16)). In (15), the
subordinate clause immediately follows its head
word, while in (16) the subordinate clause is ex-
traposed. In (16) the anaphor precedes its an-
tecedent, which is governed by the head that d-
binds the anaphor. This violates the given con-
straints, hence coreference is excluded.
G B explains topicalization with a move of the top-
icalized CP into the SpecComp phrase of the highest
CP, so that the pronoun does not c-command its an-
tecedent (in these cases movements into an A-position
are assumed for which the binding principles of GB do
not apply).
3GB explains this phenomenon by linking the mod-
ifiers to the subject as adjuncts. In this position, the
pronoun does not c-command the antecedent, and the
adjunct of the subject is also in an A-position.
</bodyText>
<page confidence="0.988655">
239
</page>
<listItem confidence="0.78307">
(15) Die Frage, ob Peter, nach Dublin fahren sollte,
konnte er, noch nicht beantworten.
</listItem>
<bodyText confidence="0.5030755">
[The question, whether Peter, should go to Dublin,
he, couldn&apos;t decide.]
</bodyText>
<listItem confidence="0.739189">
(16) * Die Frage konnte er, noch nicht beantworten,
ob Peter, nach Dublin fahren sollte.
</listItem>
<construct confidence="0.443798">
r The question he, couldn&apos;t decide, whether Peter,
should go to Dublin.]
</construct>
<bodyText confidence="0.999619956521739">
Structural constraints are necessary conditions,
but additional criteria have to be considered when
determining the antecedent of an anaphor. Mor-
phosyntactic conditions require that a pronoun
must agree with its antecedent in gender, num-
ber and person, while a definite NP must agree
with its antecedent in number only. Moreover,
conceptual criteria have to be met as in the case
of nominal anaphors which must subsume their
antecedents at the conceptual level. Similarly,
for pronominal anaphors the selected antecedent
must be permitted in those conceptual roles con-
necting the pronominal anaphors and its gram-
matical head.
The DG constraints for the use of reflexives and
intra-sentential anaphora cover approximately the
same phenomena as GB, but the structures used
by DG analysis are less complex than those of
GB and do not require the formal machinery
of empty categories, binding chains and complex
movements (cf. Lappin and McCord (1990, p.205)
for a similar argument). Hence, our proposal pro-
vides a more tractable basis for implementation.
</bodyText>
<sectionHeader confidence="0.978231" genericHeader="method">
3 Major Grammatical Predicates
</sectionHeader>
<bodyText confidence="0.976385535714286">
The ParseTalk model of DG (Hahn et al., 1994)
exploits inheritance as a major abstraction mech-
anism. The entire lexical system is organized as
a hierarchy of lexical classes (isac denoting the
subclass relation among lexical classes), with con-
crete lexical items forming the leave nodes of the
corresponding lexicon grammar graph. Valency
constraints are attached to each lexical item, on
which the local computation of concrete depen-
dency relations between a head and its associated
modifier is based. These constraints incorporate
categorial knowledge about word classes and mor-
phosyntactic knowledge involving complex feature
terms as used in unification grammars.
The definition of the grammatical predicates be-
low is based on the following conventions: U de-
notes the unification operation, J. the inconsis-
tent element. Let u be a complex feature term
and 1 a feature, then the extraction u\1 yields
the value of / in u. By definition, u\1 gives 1
in all other cases. In addition, we supply ac-
cess to conceptual knowledge via a KL-ONE-style
classification-based knowledge representation Ian-
guage. The concept hierarchy consists of a set of
concept names .7&amp;quot; = {COMPUTERSYSTEM, NOTE-
BOOK, MOTHERBOARD, ...} and a subclass rela-
tion isaF = { (NOTEBOOK , COMPUTERSYSTEM),
(PCI-MOTHERBOARD, MOTHERBOARD), ...} C
x Y. roles C F x F is the set of relations
with role names 1?, = {has-part, has-cpu, ...} and
denotes the established relations in the knowledge
base, while R. characterizes the labels of admitted
conceptual relations. The relation permit c F x
R x ,7* characterizes the range of possible con-
ceptual relations among concepts, e.g., (MOTH-
ERBOARD, has-cpu, CPU) E permit. Furthermore,
object. attribute denotes the value of the property
attribute at object and the symbol self refers to
the current lexical item. The Parse Talk specifi-
cation language, in addition, incorporates topo-
logical primitives for relations within dependency
trees. The relations left and head denote &amp;quot;x oc-
curs left of y&amp;quot; and &amp;quot;x is head of y&amp;quot;, resp. These
primitive relations can be considered declarative
equivalents to the procedural specifications used
in several tree-walking algorithms for anaphora
resolution, e.g., by Hobbs (1978) or Ingria and
Stallard (1989). Note that in the description be-
low ref+ and rel* denote the transitive and transi-
tive/reflexive closure of a relation rel, respectively.
x d-binds y
(x head + y)
A z: ((x head + z) A (z head + y)
A (z isac* finiteVerb
V 3u: (z head u
A ((z spec u A u /sac* DetPossessive)
</bodyText>
<listItem confidence="0.807619428571429">
✓ (z saxGen u A u isact Noun)
✓ (z ppAtt u A u isac* Noun)
✓ (z genAtt u A u isac* Noun)))))
Box 1: D-binding
The possible antecedents that can be reached
via anaphoric relations are described by the pred-
icates isPotentialReflexiiieAntecedentOf (cf. Box
2) and isPotentialAnaphoricAntecedentOf (cf. Box
3). These incorporate the predicate d-binds (cf.
Box 1) which formally defines the corresponding
notion from Section 2. The evaluation of the ma-
x isPotentialReflexiveAntecedentOf y
3 z: (z d-binds y A z d-binds x)
Box 2: isPotentialReflexiveAntecedentOf
</listItem>
<bodyText confidence="0.621727">
jor predicate, isPotentialAnaphoricAntecedentOf
(cf. Box 3), determines the candidate set of possi-
ble antecedents for (pro)nominal anaphors, and
</bodyText>
<page confidence="0.882356">
240
</page>
<equation confidence="0.871689833333333">
x isPotentialAnaphoricAntecedentOf y
z: (z d-binds x A z d-binds y)
A (x left y
V —3 u: (u d-binds y
A (u head + x)))
Box 3: isPotentialAnaphoricAntecedentOf
</equation>
<bodyText confidence="0.99994572">
thus characterizes the notion of reachability in
formal terms. The use of constraints as filters
becomes evident through the further restriction
of this set by the predicates adapted to partic-
ular grammatical relations, thus taking the no-
tion of satisfiability into account. For instance,
the predicate PronAnaphorTest from Box 4 con-
tains the grammatical constraint for pronominal
anaphors according to which some pronoun and
its antecedent must agree in gender, number, and
person, and the conceptual constraint described
in Section 2. The predicate NomAnaphorTest
from Box 5 captures the conceptual constraint
for nominal anaphors such that the concept to
which the antecedent refers must be subsumed by
the concept to which the anaphoric noun phrase.
refers. Additionally it tests whether the defi-
nite NP agrees with the antecedent in number.
These two predicates cover the knowledge related
to the resolution of intro-sentential as well as
inter-sentential anaphora. Note the equivalence
of grammatical and conceptual conditions within
a single constraint. All these predicates form part
of the computation process aiming at the resolu-
tion of anaphora as described in Section 4.
</bodyText>
<equation confidence="0.752011578947368">
PronAnaphorTest (pro, ante):&lt;#.
ante isac* Noun A
((pro.features\self\ agr\ gen)
U(anteleatures \self\ agr\gen) 0 1) A
((pro.features \self\ agr\ num)
U(anteleatures \self\ agr\ num) 0 1) A
((pro.features\self\ agr\ pers)
U(anteleatures\self\agr\ pers) 1) A
Vx V role E R.:
(x head pro A
(x.concept, pro.concept) E roles
(x.concept, role, ante.concept) E permit)
Box 4: PronAnaphorTest
NomAnaphorTest (defNP, ante):4=&gt;
ante isac* Noun A
((defNP.features \self\agr\ num)
U(anteleatures \self\ agr\ num) 0 1) A
ante.concept isaF* defNP.concept
Box 5: NomAnaphorTesi
</equation>
<sectionHeader confidence="0.923153" genericHeader="method">
4 Resolution of Anaphora
</sectionHeader>
<bodyText confidence="0.999972057692308">
The Parse Talk environment builds on the actor
computation model (Agha and Hewitt, 1987) as
background for the procedural interpretation of
lexicalized dependency specifications in terms of
so-called word actors (cf. Schacht et al. 1994;
Hahn et al. 1994). Word actors combine object-
oriented features with concurrency yielding strict
lexical distribution and distributed computation
in a methodologically clean way. The model
assumes word actors to communicate via asyn-
chronous message passing. An actor can send mes-
sages only to other actors it knows about, its so-
called acquaintances. The arrival of a message at
an actor is called an event; it triggers the execu-
tion of a method that is composed of atomic ac-
tions — among them the evaluation of grammatical
predicates. As we will show, the specification of
a particular message protocol corresponds to the
treatment of fairly general linguistic tasks, such
as establishing dependencies, properly arranging
coordinations, and, of course, resolving anaphors.
Consequently, any of these subprotocols consti-
tutes part of the grammar specification proper.
We shall illustrate the linguistic aspects of
word actor-based parsing by introducing the basic
data structures for text-level anaphora as acquain-
tances of specific word actors, and then turn to the
general message-passing protocol that accounts
for intra- as well as inter-sentential anaphora.
Our exposition builds on the well-known focus-
ing mechanism (Sidner, 1983; Grosz and Sidner,
1986). Accordingly, we distinguish each sentence&apos;s
unique focus, a complementary list of alternate
potential foci, and a history list composed of dis-
course elements not in the list of potential foci,
but occurring in previous sentences of the current
discourse segment. These data structures are re-
alized as acquaintances of sentence delimiters to
restrict the search space beyond the sentence to
the relevant word actors.
The protocol &apos;level of analysis encompasses the
procedural interpretation of the declarative con-
straints given in Section 2. At that level, in the
case of reflexive pronouns, the search for the an-
tecedent is triggered by the occurrence of a reflex-
ive pronoun in the text. Upon instantiation of the
corresponding word actor, a SearchRefAntecedent
message will be issued. The distribution strategy
of the message incorporates the syntactic restric-
tions for the appearance of a reflexive pronoun and
its possible antecedent. This can be described in
terms of two phases:
</bodyText>
<footnote confidence="0.589769">
1. In phase 1 the message is forwarded from its
initiator to the word actor which d-binds the
</footnote>
<page confidence="0.996901">
241
</page>
<bodyText confidence="0.981098855855856">
initiator. Only if the message reaches a finite
verb or a noun which has a possessive modifier
is a new message with phase 2 sent, and the
message in phase I terminates. On any other
occasion (e.g., the head of the initiator is a
preposition or a non-finite verb) the message
is simply passed on to the receiver&apos;s head.
2. In phase 2 the message is forwarded to the
subject of the finite verb or, if a noun d-binds
the reflexive, to the possessive modifier of the
noun.
Only nouns or personal pronouns are capable of
responding to SearchRefAntecedent messages. If
the search for an antecedent is successful, a Ref-
AntecedentFound message is sent directly to the
initiator of the search message which changes its
concept identifier accordingly.
For pronominal anaphors, the search for the an-
tecedent is triggered by the occurrence of a per-
sonal pronoun. Upon instantiation of the cor-
responding word actor, a SearchPronAntecedent
message will be sent. For nominal anaphors, the
search for the antecedent is triggered by the at-
tachment of a definite article as a modifier to its
head noun, so that a SearchNomAntecedent mes-
sage will be issued. Since the structural criteria
for the sentence position of both types of anaphors
are the same, the distribution mechanisms under-
lying the corresponding messages can be described
by their common superclass, SearchAntecedent. Its
distribution strategy incorporates the syntactic
restrictions for the appearance of both elements
involved, anaphor and antecedent. This can be
described in terms of three main phases:
1. In phase I, the message is forwarded from its
initiator to the head which d-binds the initia-
tor. Only if the message reaches this head are
two further messages with phases I a and 2 sent
simultaneously, and the message in phase I ter-
minates. On any other occasion (e.g., the head
of the pronoun is a preposition) the message is
simply passed on to the receiver&apos;s head.
(a) In phase la the modifiers of the initia-
tor&apos;s direct head are tested, in order to
determine if any of these modifiers have
modifiers themselves. When the test suc-
ceeds, the message is forwarded to these
modifiers, where the anaphor predicates
(PronAnaphorTest or NomAnaphorTest)
are evaluated in parallel.
2. In phase 2 the message is forwarded from the
head which d-binds the initiator (the original
sender) to the word actor which represents the
sentence delimiter of the current sentence. If on
that path the message encounters a head which
d-binds the sender (mediating messages from
the initiator), that head may possibly govern
an antecedent in its subtree. New messages
with phase 2a are sent (their number depends
on how many modifiers of the head exist).
(a) In phase 2a the message is forwarded from
the head which d-binds the sender to each
of its modifiers (excluding the sender of the
message), where both anaphor predicates
are evaluated.
3. Phase 3 is triggered independently from phase
I and 2. The path leads from the initiator to
the sentence delimiter of the previous sentence,
where its state is set to phase 3a.
(a) In phase 3a the sentence delimiter&apos;s ac-
quaintances Focus and PotFoci are tested
for the anaphor predicates.
Note that only nouns or personal pronouns are
capable of responding to SearchAntecedent mes-
sages and test whether they fulfill the required
criteria for an anaphoric relation. If any of the
anaphor predicates succeeds, the determined an-
tecedent sends an AntecedentFound message di-
rectly to the initiator of SearchAntecedent; this
message carries the concept identifier of the an-
tecedent. The initiator of the SearchAntecedent
message, viz, the anaphor, upon receipt of the An-
tecedentFound message changes its concept identi-
fier accordingly. This update of the concept iden-
tifier is the final result of anaphora resolution, a
change which accounts for the coreference between
concepts denoted by different lexical items at the
text level.
We now discuss the protocol for establishing
anaphoric relations based on intra- and inter-
sentential anaphora considering the following text:
(17) Die Firma Compaq, die den LTE-Lite entwik-
kelt, bestiickt ihn mit einem PCI-Motherboard.
Der Rechner hat eine Taktfrequenz von 50 Mhz.
iThe company Compaq, which develops the LTE-
Lite, equips it with a PCI-motherboard. The sys-
tem comes with a clock frequency of 50Mhz.]
In the first sentence of (17), the SearchAntecedent
message is caused by the occurrence of the per-
sonal ihn (cf. Fig. 2 which depicts two instances
of anaphora resolution). In phase 1, the message
reaches the finite verb bestickt, where two new
instances of the message are created. In phase
2 it takes the path to the sentence delimiter of
the current sentence (no effect). In phase la, the
message reaches the subject Firma, which is the
leftmost modifier of the verb, and determines the
noun LTE-Lite as the only possible antecedent of
ihn. The success of PronAnaphorTest leads to the
sending of an AntecedentFound message, the re-
sult of which is the update of the concept identi-
</bodyText>
<page confidence="0.992629">
242
</page>
<figure confidence="0.3649685">
Die Firma Compaq, die den LTE-Lite entwickelt, bestiickt ihn mit einem PCI-Motherboard. Der Rechner hat ...
The company Compaq, which the LTD-Lite develops, equips It with a PCI-motherboard. The system comes
</figure>
<figureCaption confidence="0.931961">
Figure 2: Sample Communication Protocol
</figureCaption>
<figure confidence="0.999346086956522">
searchAntecedent message
antecedentFound message
I -
&apos;•-•,......, s
i
[bestfickt] t
____- -, .. ........ ....
&apos; ss l ,...s. [hat]
t
1 /3.
----- __ :::,.-
- [flan] (mit) ,&apos;
.4
[Die] [Compaq] [entwickelt) [PCI-Motherboard) me5r.
[die] [LTE-Lite] ---- - [einem]
[den)
• ,///Nss..„.
•
[Rechner]
[Firma] _ ---------------
rocya:‹Wirra Coapaqp.
PaCrocl:&lt;/M-Llte,PCI-NOtherboard]
atattiat: &lt; &gt;
</figure>
<bodyText confidence="0.963048666666667">
fier of ihn with that of LTE-Lite. Simultaneously,
a SearchPronAntecedent message in phase 3 takes
the path to the sentence delimiter of the previ-
ous sentence, where it evaluates PronAnaphorTest
with respect to its acquaintances Focus and Pot-
Foci (no effect).
The second sentence of (17) contains the def-
inite noun phrase der Rechner. The search of
an antecedent is triggered by the attachment of
the definite article to the noun. In phase 1 the
message reaches the finite verb hat, where new
instances of the message are created. Phase la
yields no positive results and the message termi-
nates. In phase 2 the message takes the path from
the finite verb to the sentence delimiter (no effect).
Since there are no possible antecedents within
the sentence, in phase 3 possible antecedents are
checked which are stored as the acquaintances Fo-
cus and PoiFoci of the sentence delimiter for the
previous sentence. Since Rechner subsumes LTE-
Lite at the conceptual level, NomAnaph,orTest
succeeds. An AntecedentFound message is cre-
ated, which changes the concept identifier of Rech-
ner appropriately.
</bodyText>
<sectionHeader confidence="0.981331" genericHeader="method">
5 Comparison to Related Work
</sectionHeader>
<bodyText confidence="0.999788675675676">
From the linguistic viewpoint, sentence anaphora,
so far, have only been sketchily dealt with by de-
pendency grammarians, e.g., by Hudson (1984;
1990). The most detailed description of grammat-
ical regularities and an associated parsing proce-
dure has been supplied by Lappin and McCord
(1990). It is based on the format of a slot grammar
(SG), a slight theory variant of DG. In particular,
they treat pronominal coreference and anaphora
(i.e., reflexives and reciprocals). Our approach
methodologically differs in three major aspects
from that study: First, unlike the SG proposal,
which is based on a second-pass algorithm operat-
ing on fully parsed clauses to determine anaphoric
relationships, our proposal is basically an incre-
mental single-pass parsing model. Most impor-
tant, however, is that our model incorporates the
text-level of anaphora resolution, a shortcoming of
the original SG approach that has recently been
removed (Lappin and Leass, 1994), but still is a
source of lots of problems. Third, unlike our ap-
proach, even the current SG model for anaphora
resolution does not incorporate conceptual knowl-
edge and global discourse structures (for reasons
discussed by Lappin and Laess). This decision
might nevertheless cause trouble if more conceptu-
ally rooted text cohesion and coherence structures
have to be accounted for (e.g., textual ellipses).
A particular problem we have not yet solved,
the plausible ranking of single antecedents from
a candidate set, is dealt with in depth by Lappin
and Laess (1994) and Hajicova et al. (1992). Both
define salience metrics capable of ordering alter-
native antecedents according to structural crite-
ria, several of which can directly be attributed to
the topological structure and topic/comment an-
notations of the underlying dependency trees.
</bodyText>
<page confidence="0.998128">
243
</page>
<sectionHeader confidence="0.999458" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.995059555555556">
We have outlined a model of anaphora resolution
which is founded on a dependency-based gram-
mar model. This model accounts for sentence-level
anaphora, with constraints adapted from GB, as
well as text-level anaphora, with concepts close
to Grosz-Sidner-style focus models. The associ-
ated text parser is based on the actor computation
model. Its message passing mechanisms constitute
the foundation for expressing specific linguistic
protocols, e.g., that for anaphora resolution. The
main advantage of our approach lies in the unified
framework for sentence- and text-level anaphora,
using a coherent grammar format, and the pro-
vision for access to grammatical and conceptual
knowledge without prioritizing either one of them.
It is also a striking fact that, given the same lin-
guistic phenomena, structural dependency config-
urations are considerably simpler than their GB
counterparts, though suitably expressive.
The anaphora resolution module (for reflexives,
intra- and inter-sentential anaphora) has been re-
alized as part of Parse Talk, a dependency parser
which forms part of a larger text understanding
system for the German language, currently under
development at our laboratory. The parser has
been implemented in Smalltalk; the Smalltalk sys-
tem itself, which runs on a SUN SparcStation net-
work, has been extended by asynchronous message
passing facilities and physical distribution mecha-
nisms (Xu, 1993). The current lexicon contains a
hierarchy of approximately 100 word class specifi-
cations with nearly 3.000 lexical entries and corre-
sponding concept descriptions from two domains
(information technology and medicine) available
from the LOOM knowledge representation system
(MacGregor and Bates, 1987).
Acknowledgments. We would like to thank our col-
leagues in the CCIF group who read earlier versions
of this paper. In particular, improvements are due to
discussions we had with S. Schacht, N. Braker, P. Neu-
haus, and M. Klenner. We also like to thank J. Alcan-
tara (Cornell U) who kindly took the role of the native
speaker via Internet. This work has been funded by
LGFG Baden-Wurttemberg (1.1.4-7631.0; M. Strube)
and a grant from DFG (Ha 2907/1-3; U. Hahn).
</bodyText>
<sectionHeader confidence="0.997866" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999865472972973">
Agha, G. and Hewitt, C. (1987). Concurrent program-
ming using actors. In A.Yonezawa and M.Tokoro
(Eds.), Object-Oriented Concurrent Programming.
Cambridge/MA: MIT Pr., pp.37-53.
Braker, N., Hahn, U., and Schacht, S. (1994). Concur-
rent lexicalized dependency parsing: the Parse Talk
model. Proc. COLING &apos;9.4. Kyoto, Japan. Vol.1,
pp.379-385.
Chomsky, N. (1981). Lectures on Government and
Binding. Dordrecht: Foris.
Correa, N. (1988). A binding rule for government-
binding parsing. Proc. COLING &apos;88. Budapest,
Hungary. Vol.1, pp.123-129.
Grosz, B. J. and Sidner, C. L. (1986). Attention, in-
tentions, and the structure of discourse. Computa-
tional Linguistics, 12. (3), 175-204.
Hahn, U. (1992). On text coherence parsing. Proc.
COLING &apos;92. Nantes, France, Vol. 1, pp.25-31.
Hahn, U., Schacht, S., and Broker, N. (1994). Con-
current, object-oriented dependency parsing: the
Parse Talk model. International Journal of Human-
Computer Studies, 41. (1/2), 179-222.
Hahn, U. and Strube, M. (1995). Parse Talk about
Text-Level Ellipsis. Freiburg University, CLIF Tech-
nical Report.
Hajicova, E., Kubon, V., and Kubon, P. (1992). Stock
of shared knowledge: a tool for solving pronominal
anaphora. Proc. COLING &apos;92. Nantes, France, Vol.
1, pp.127-133.
Hobbs, J. (1978). Resolving pronoun references. Lin-
gua, 44. 311-338.
Hobbs, J. R. (1982). Towards an understanding of co-
herence in discourse. In Lehnert, W. and Ringle, M.
(Eds.), Strategies for Natural Language Processing.
Hillsdale/NJ: Erlbaum, pp. 223-243.
Hudson, R. (1984). Word Grammar. Oxford: Black-
well.
Hudson, R. (1990). English Word Grammar. Oxford:
Blackwell.
Ingria, R. and Stallard, D. (1989). A computational
mechanism for pronominal reference. Proc. ACL
&apos;89. Vancouver, Canada, pp.262-271.
Kamp, H. and Reyle, U. (1993). From Discourse to
Logic. Dordrecht: Kluwer.
Kuno, S. (1987). Anaphora and discourse principles.
In Nagao, M. (Ed.), Language and Artificial Intel-
ligence. Amsterdam: North-Holland, pp.87-111.
Lappin, S. and Leass, H. J. (1994). An algorithm
for pronominal anaphora resolution. Computational
Linguistics, 20. (4), 535-561.
Lappin, S. and McCord, M. (1990). Anaphora reso-
lution in slot grammar. Computational Linguistics,
16. (4), 197-212.
MacGregor, R. and Bates, R. (1987). The LOOM
Knowledge Representation Language. ISI Reprint
Series, ISI/RS-87-188, Univ. of Southern California.
Mann, W. C. and Thompson, S. A. (1988). Rhetorical
structure theory: toward a functional theory of text
organization. Text, 8. (3), 243-281.
Pollard, C. and Sag, I. A. (1992). Anaphors in English
and the scope of binding theory. Linguistic Inquiry,
23. (2) 261-303.
Schacht, S., Hahn, U., and Braker, N. (1994). Concur-
rent lexicalized dependency parsing: a behavioral
view on Parse Talk events. Proc. COLING &apos;94. Ky-
oto, Japan, Vol.1., pp.489-493.
Sidner, C. L. (1983). Focusing in the comprehension
of definite anaphora. In Brady, M. and Berwick, R.
(Eds.), Computational Models of Discourse. Cam-
bridge/MA: MIT Pr., pp.267-330.
Xu, W. (1993). Distributed, Shared and Persistent Ob-
jects. A Model for Distributed Object-Oriented Pro-
gramming. London University, Dept. of Computer
Science (Ph.D.Diss.).
</reference>
<page confidence="0.998532">
244
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.912496">
<title confidence="0.995832">ParseTalk about Sentenceand Text-Level Anaphora</title>
<author confidence="0.995654">Strube Hahn</author>
<affiliation confidence="0.999954">Linguistics Research Group Freiburg University</affiliation>
<address confidence="0.999969">D-79085 Freiburg, Germany</address>
<email confidence="0.929081">Istrube,hahnjecoling.uni-freiburg.de</email>
<abstract confidence="0.998816125">We provide a unified account of sentence-level and text-level anaphora within the framework of a dependency-based grammar model. Criteria for anaphora resolution within sentence boundaries rephrase major concepts from GB&apos;s binding theory, while those for text-level anaphora incorporate an adapted version of a Grosz-Sidner-style focus model.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G Agha</author>
<author>C Hewitt</author>
</authors>
<title>Concurrent programming using actors.</title>
<date>1987</date>
<booktitle>In A.Yonezawa and M.Tokoro (Eds.), Object-Oriented Concurrent Programming. Cambridge/MA: MIT Pr.,</booktitle>
<pages>37--53</pages>
<contexts>
<context position="20466" citStr="Agha and Hewitt, 1987" startWordPosition="3260" endWordPosition="3263">.features\self\ agr\ gen) U(anteleatures \self\ agr\gen) 0 1) A ((pro.features \self\ agr\ num) U(anteleatures \self\ agr\ num) 0 1) A ((pro.features\self\ agr\ pers) U(anteleatures\self\agr\ pers) 1) A Vx V role E R.: (x head pro A (x.concept, pro.concept) E roles (x.concept, role, ante.concept) E permit) Box 4: PronAnaphorTest NomAnaphorTest (defNP, ante):4=&gt; ante isac* Noun A ((defNP.features \self\agr\ num) U(anteleatures \self\ agr\ num) 0 1) A ante.concept isaF* defNP.concept Box 5: NomAnaphorTesi 4 Resolution of Anaphora The Parse Talk environment builds on the actor computation model (Agha and Hewitt, 1987) as background for the procedural interpretation of lexicalized dependency specifications in terms of so-called word actors (cf. Schacht et al. 1994; Hahn et al. 1994). Word actors combine objectoriented features with concurrency yielding strict lexical distribution and distributed computation in a methodologically clean way. The model assumes word actors to communicate via asynchronous message passing. An actor can send messages only to other actors it knows about, its socalled acquaintances. The arrival of a message at an actor is called an event; it triggers the execution of a method that i</context>
</contexts>
<marker>Agha, Hewitt, 1987</marker>
<rawString>Agha, G. and Hewitt, C. (1987). Concurrent programming using actors. In A.Yonezawa and M.Tokoro (Eds.), Object-Oriented Concurrent Programming. Cambridge/MA: MIT Pr., pp.37-53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Braker</author>
<author>U Hahn</author>
<author>S Schacht</author>
</authors>
<title>Concurrent lexicalized dependency parsing: the Parse Talk model.</title>
<date>1994</date>
<booktitle>Proc. COLING &apos;9.4. Kyoto, Japan. Vol.1,</booktitle>
<pages>379--385</pages>
<marker>Braker, Hahn, Schacht, 1994</marker>
<rawString>Braker, N., Hahn, U., and Schacht, S. (1994). Concurrent lexicalized dependency parsing: the Parse Talk model. Proc. COLING &apos;9.4. Kyoto, Japan. Vol.1, pp.379-385.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chomsky</author>
</authors>
<date>1981</date>
<booktitle>Lectures on Government and Binding.</booktitle>
<location>Dordrecht: Foris.</location>
<contexts>
<context position="1947" citStr="Chomsky, 1981" startWordPosition="272" endWordPosition="273"> yet very prominent phenomenon that yields textual cohesion in discourse. Adequate grammars should therefore also be easily extensible to cover nonanaphoric text phenomena (e.g., coherence relations, rhetorical predicates), which provide for additional levels of text (macro) structure, with descriptions stated at the same level of theoretical sophistkation as for anaphora. First, we will briefly compare our approach with work done in the context of government-binding (GB) grammar and discourse representation theory (DRT). As we conceive it, binding theory as developed within the GB framework (Chomsky, 1981; Kuno, 1987) offers one of the most sophisticated approaches for treating anaphora at the sentence level of description. This has also been recognized by advocates of competing grammar formalisms, who have elaborated on GB&apos;s binding principles (cf., e.g., Pollard and Sag (1992) within the context of HPSG, whose treatment is nevertheless restricted to reflexive pronouns). Interestingly enough, when faced with some crucial linguistic phenomena, such as topicalization, GB must assume rather complex movement operations in order to cope with the data in a satisfactory manner. Things get even more </context>
<context position="6161" citStr="Chomsky (1981)" startWordPosition="927" endWordPosition="928">etation of text macro structures (a preliminary study is presented in Hahn (1992)). 2 DG Constraints on Anaphora In this section, we present, quite informally, some constraints on intra-sentential anaphora in terms of dependency grammar (DG). We will reconsider these constraints in Section 3, where our grammar model is dealt with in more depth. We provide here a definition of d-binding and two constraints which describe the use of reflexive pronouns and anaphors (personal pronouns and definite noun phrases). These constraints cover approximately the same phenomena as the binding theory of GB (Chomsky (1981); for a computational treatment, cf. Correa (1988)). Dependency structures, by definition, refer to the sentence level of linguistic description only. The relation of dependency holds between a lexical head and one or several modifiers of that head, such that the occurrence of a head allows for the occurrence of one or several modifiers (in some pre-specified linear ordering), but not vice versa. Speaking in terms of dependency structure representations, the head always precedes and, thus, (transitively) governs its associated modifiers in the dependency tree. This basic notion of government m</context>
</contexts>
<marker>Chomsky, 1981</marker>
<rawString>Chomsky, N. (1981). Lectures on Government and Binding. Dordrecht: Foris.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Correa</author>
</authors>
<title>A binding rule for governmentbinding parsing.</title>
<date>1988</date>
<booktitle>Proc. COLING &apos;88.</booktitle>
<volume>1</volume>
<pages>123--129</pages>
<location>Budapest,</location>
<contexts>
<context position="6211" citStr="Correa (1988)" startWordPosition="934" endWordPosition="935">dy is presented in Hahn (1992)). 2 DG Constraints on Anaphora In this section, we present, quite informally, some constraints on intra-sentential anaphora in terms of dependency grammar (DG). We will reconsider these constraints in Section 3, where our grammar model is dealt with in more depth. We provide here a definition of d-binding and two constraints which describe the use of reflexive pronouns and anaphors (personal pronouns and definite noun phrases). These constraints cover approximately the same phenomena as the binding theory of GB (Chomsky (1981); for a computational treatment, cf. Correa (1988)). Dependency structures, by definition, refer to the sentence level of linguistic description only. The relation of dependency holds between a lexical head and one or several modifiers of that head, such that the occurrence of a head allows for the occurrence of one or several modifiers (in some pre-specified linear ordering), but not vice versa. Speaking in terms of dependency structure representations, the head always precedes and, thus, (transitively) governs its associated modifiers in the dependency tree. This basic notion of government must be further refined for the description of anap</context>
</contexts>
<marker>Correa, 1988</marker>
<rawString>Correa, N. (1988). A binding rule for governmentbinding parsing. Proc. COLING &apos;88. Budapest, Hungary. Vol.1, pp.123-129.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Grosz</author>
<author>C L Sidner</author>
</authors>
<title>Attention, intentions, and the structure of discourse.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<volume>12</volume>
<pages>175--204</pages>
<contexts>
<context position="21874" citStr="Grosz and Sidner, 1986" startWordPosition="3472" endWordPosition="3475">airly general linguistic tasks, such as establishing dependencies, properly arranging coordinations, and, of course, resolving anaphors. Consequently, any of these subprotocols constitutes part of the grammar specification proper. We shall illustrate the linguistic aspects of word actor-based parsing by introducing the basic data structures for text-level anaphora as acquaintances of specific word actors, and then turn to the general message-passing protocol that accounts for intra- as well as inter-sentential anaphora. Our exposition builds on the well-known focusing mechanism (Sidner, 1983; Grosz and Sidner, 1986). Accordingly, we distinguish each sentence&apos;s unique focus, a complementary list of alternate potential foci, and a history list composed of discourse elements not in the list of potential foci, but occurring in previous sentences of the current discourse segment. These data structures are realized as acquaintances of sentence delimiters to restrict the search space beyond the sentence to the relevant word actors. The protocol &apos;level of analysis encompasses the procedural interpretation of the declarative constraints given in Section 2. At that level, in the case of reflexive pronouns, the sea</context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>Grosz, B. J. and Sidner, C. L. (1986). Attention, intentions, and the structure of discourse. Computational Linguistics, 12. (3), 175-204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Hahn</author>
</authors>
<title>On text coherence parsing.</title>
<date>1992</date>
<booktitle>Proc. COLING &apos;92.</booktitle>
<volume>1</volume>
<pages>25--31</pages>
<location>Nantes, France,</location>
<contexts>
<context position="5628" citStr="Hahn (1992)" startWordPosition="846" endWordPosition="847">with crucial linguistic phenomena which cause considerable problems for current GB theory, 3. goes beyond GB in that it allows the treatment of anaphora at the text level of description within the same grammar formalism as is used for sentence level anaphora, and, 4. goes beyond the anaphora-centered treatment of text structure characteristic of the DRT approach in that it already accounts for the resolution of text-level ellipsis (sometimes also referred to as functional anaphora, cf. Hahn and Strube (1995)) and the interpretation of text macro structures (a preliminary study is presented in Hahn (1992)). 2 DG Constraints on Anaphora In this section, we present, quite informally, some constraints on intra-sentential anaphora in terms of dependency grammar (DG). We will reconsider these constraints in Section 3, where our grammar model is dealt with in more depth. We provide here a definition of d-binding and two constraints which describe the use of reflexive pronouns and anaphors (personal pronouns and definite noun phrases). These constraints cover approximately the same phenomena as the binding theory of GB (Chomsky (1981); for a computational treatment, cf. Correa (1988)). Dependency str</context>
</contexts>
<marker>Hahn, 1992</marker>
<rawString>Hahn, U. (1992). On text coherence parsing. Proc. COLING &apos;92. Nantes, France, Vol. 1, pp.25-31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Hahn</author>
<author>S Schacht</author>
<author>N Broker</author>
</authors>
<title>Concurrent, object-oriented dependency parsing: the Parse Talk model.</title>
<date>1994</date>
<journal>International Journal of HumanComputer Studies,</journal>
<volume>41</volume>
<pages>179--222</pages>
<contexts>
<context position="904" citStr="Hahn et al., 1994" startWordPosition="114" endWordPosition="117">ora within the framework of a dependency-based grammar model. Criteria for anaphora resolution within sentence boundaries rephrase major concepts from GB&apos;s binding theory, while those for text-level anaphora incorporate an adapted version of a Grosz-Sidner-style focus model. 1 Introduction This paper treats the resolution of anaphora within the framework of Parse Talk, a dependencyoriented grammar model that incorporates strict lexicalization, head-orientation (based on valency specifications), feature unification, and inheritance among lexicalized grammar specifications (Broker et al., 1994; Hahn et al., 1994). The results we present rest upon two major assumptions: 1. As many forms of anaphors (e.g., nominal and pronominal anaphors) occur within sentence boundaries (so-called intra-sentential or sentence anaphora) and beyond (intersentential or text anaphora), adequate theories of anaphora should allow the formulation of grammatical regularities for both types using a common set of grammatical primitives. 2. Anaphora are only one, yet very prominent phenomenon that yields textual cohesion in discourse. Adequate grammars should therefore also be easily extensible to cover nonanaphoric text phenomen</context>
<context position="15264" citStr="Hahn et al., 1994" startWordPosition="2443" endWordPosition="2446">antecedent must be permitted in those conceptual roles connecting the pronominal anaphors and its grammatical head. The DG constraints for the use of reflexives and intra-sentential anaphora cover approximately the same phenomena as GB, but the structures used by DG analysis are less complex than those of GB and do not require the formal machinery of empty categories, binding chains and complex movements (cf. Lappin and McCord (1990, p.205) for a similar argument). Hence, our proposal provides a more tractable basis for implementation. 3 Major Grammatical Predicates The ParseTalk model of DG (Hahn et al., 1994) exploits inheritance as a major abstraction mechanism. The entire lexical system is organized as a hierarchy of lexical classes (isac denoting the subclass relation among lexical classes), with concrete lexical items forming the leave nodes of the corresponding lexicon grammar graph. Valency constraints are attached to each lexical item, on which the local computation of concrete dependency relations between a head and its associated modifier is based. These constraints incorporate categorial knowledge about word classes and morphosyntactic knowledge involving complex feature terms as used in</context>
<context position="20633" citStr="Hahn et al. 1994" startWordPosition="3285" endWordPosition="3288">eleatures\self\agr\ pers) 1) A Vx V role E R.: (x head pro A (x.concept, pro.concept) E roles (x.concept, role, ante.concept) E permit) Box 4: PronAnaphorTest NomAnaphorTest (defNP, ante):4=&gt; ante isac* Noun A ((defNP.features \self\agr\ num) U(anteleatures \self\ agr\ num) 0 1) A ante.concept isaF* defNP.concept Box 5: NomAnaphorTesi 4 Resolution of Anaphora The Parse Talk environment builds on the actor computation model (Agha and Hewitt, 1987) as background for the procedural interpretation of lexicalized dependency specifications in terms of so-called word actors (cf. Schacht et al. 1994; Hahn et al. 1994). Word actors combine objectoriented features with concurrency yielding strict lexical distribution and distributed computation in a methodologically clean way. The model assumes word actors to communicate via asynchronous message passing. An actor can send messages only to other actors it knows about, its socalled acquaintances. The arrival of a message at an actor is called an event; it triggers the execution of a method that is composed of atomic actions — among them the evaluation of grammatical predicates. As we will show, the specification of a particular message protocol corresponds to </context>
</contexts>
<marker>Hahn, Schacht, Broker, 1994</marker>
<rawString>Hahn, U., Schacht, S., and Broker, N. (1994). Concurrent, object-oriented dependency parsing: the Parse Talk model. International Journal of HumanComputer Studies, 41. (1/2), 179-222.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Hahn</author>
<author>M Strube</author>
</authors>
<title>Parse Talk about Text-Level Ellipsis. Freiburg University,</title>
<date>1995</date>
<tech>CLIF Technical Report.</tech>
<contexts>
<context position="5530" citStr="Hahn and Strube (1995)" startWordPosition="828" endWordPosition="831">pture the relevant distinctions, 2. does not exhibit an increasing level of structural complexity when faced with crucial linguistic phenomena which cause considerable problems for current GB theory, 3. goes beyond GB in that it allows the treatment of anaphora at the text level of description within the same grammar formalism as is used for sentence level anaphora, and, 4. goes beyond the anaphora-centered treatment of text structure characteristic of the DRT approach in that it already accounts for the resolution of text-level ellipsis (sometimes also referred to as functional anaphora, cf. Hahn and Strube (1995)) and the interpretation of text macro structures (a preliminary study is presented in Hahn (1992)). 2 DG Constraints on Anaphora In this section, we present, quite informally, some constraints on intra-sentential anaphora in terms of dependency grammar (DG). We will reconsider these constraints in Section 3, where our grammar model is dealt with in more depth. We provide here a definition of d-binding and two constraints which describe the use of reflexive pronouns and anaphors (personal pronouns and definite noun phrases). These constraints cover approximately the same phenomena as the bindi</context>
</contexts>
<marker>Hahn, Strube, 1995</marker>
<rawString>Hahn, U. and Strube, M. (1995). Parse Talk about Text-Level Ellipsis. Freiburg University, CLIF Technical Report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Hajicova</author>
<author>V Kubon</author>
<author>P Kubon</author>
</authors>
<title>Stock of shared knowledge: a tool for solving pronominal anaphora.</title>
<date>1992</date>
<booktitle>Proc. COLING &apos;92.</booktitle>
<volume>1</volume>
<pages>127--133</pages>
<location>Nantes, France,</location>
<contexts>
<context position="31274" citStr="Hajicova et al. (1992)" startWordPosition="4992" endWordPosition="4995">ved (Lappin and Leass, 1994), but still is a source of lots of problems. Third, unlike our approach, even the current SG model for anaphora resolution does not incorporate conceptual knowledge and global discourse structures (for reasons discussed by Lappin and Laess). This decision might nevertheless cause trouble if more conceptually rooted text cohesion and coherence structures have to be accounted for (e.g., textual ellipses). A particular problem we have not yet solved, the plausible ranking of single antecedents from a candidate set, is dealt with in depth by Lappin and Laess (1994) and Hajicova et al. (1992). Both define salience metrics capable of ordering alternative antecedents according to structural criteria, several of which can directly be attributed to the topological structure and topic/comment annotations of the underlying dependency trees. 243 6 Conclusions We have outlined a model of anaphora resolution which is founded on a dependency-based grammar model. This model accounts for sentence-level anaphora, with constraints adapted from GB, as well as text-level anaphora, with concepts close to Grosz-Sidner-style focus models. The associated text parser is based on the actor computation </context>
</contexts>
<marker>Hajicova, Kubon, Kubon, 1992</marker>
<rawString>Hajicova, E., Kubon, V., and Kubon, P. (1992). Stock of shared knowledge: a tool for solving pronominal anaphora. Proc. COLING &apos;92. Nantes, France, Vol. 1, pp.127-133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hobbs</author>
</authors>
<title>Resolving pronoun references.</title>
<date>1978</date>
<journal>Lingua,</journal>
<volume>44</volume>
<pages>311--338</pages>
<contexts>
<context position="17438" citStr="Hobbs (1978)" startWordPosition="2787" endWordPosition="2788">al relations among concepts, e.g., (MOTHERBOARD, has-cpu, CPU) E permit. Furthermore, object. attribute denotes the value of the property attribute at object and the symbol self refers to the current lexical item. The Parse Talk specification language, in addition, incorporates topological primitives for relations within dependency trees. The relations left and head denote &amp;quot;x occurs left of y&amp;quot; and &amp;quot;x is head of y&amp;quot;, resp. These primitive relations can be considered declarative equivalents to the procedural specifications used in several tree-walking algorithms for anaphora resolution, e.g., by Hobbs (1978) or Ingria and Stallard (1989). Note that in the description below ref+ and rel* denote the transitive and transitive/reflexive closure of a relation rel, respectively. x d-binds y (x head + y) A z: ((x head + z) A (z head + y) A (z isac* finiteVerb V 3u: (z head u A ((z spec u A u /sac* DetPossessive) ✓ (z saxGen u A u isact Noun) ✓ (z ppAtt u A u isac* Noun) ✓ (z genAtt u A u isac* Noun))))) Box 1: D-binding The possible antecedents that can be reached via anaphoric relations are described by the predicates isPotentialReflexiiieAntecedentOf (cf. Box 2) and isPotentialAnaphoricAntecedentOf (c</context>
</contexts>
<marker>Hobbs, 1978</marker>
<rawString>Hobbs, J. (1978). Resolving pronoun references. Lingua, 44. 311-338.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Hobbs</author>
</authors>
<title>Towards an understanding of coherence in discourse. In</title>
<date>1982</date>
<booktitle>Strategies for Natural Language Processing. Hillsdale/NJ: Erlbaum,</booktitle>
<pages>223--243</pages>
<contexts>
<context position="3831" citStr="Hobbs, 1982" startWordPosition="562" endWordPosition="563">o GB. These deficits are no wonder, since DRT is not committed to any particular syntactic theory, and thus cannot place strict enough syntactic constraints on the admissible constituent structures. Focusing on the text analysis potential of DRT, its complex machinery might work in a satisfactory way for several well-studied forms of anaphora, but it necessarily fails if various non-anaphoric text phenomena need to be interpreted. This is particularly true of conceptually-rooted and pragmatically driven inferences necessary to build up textual macro structures in terms of coherence relations (Hobbs, 1982) or rhetorical structures (Mann and Thompson, 1988). This shortcoming is simply due to the fact that DRT is basically a semantic theory, not a comprehensive model for text understanding; it lacks any systematic connec237 tion to comprehensive reasoning systems covering the conceptual knowledge and specific problemsolving models underlying the chosen domain. Summing up, DRT is fairly restricted both with respect to the incorporation of powerful syntactic constraints at the sentence level and its extension to the level of (non-anaphoric) text macro structures. GB, on the other hand, is strong wi</context>
</contexts>
<marker>Hobbs, 1982</marker>
<rawString>Hobbs, J. R. (1982). Towards an understanding of coherence in discourse. In Lehnert, W. and Ringle, M. (Eds.), Strategies for Natural Language Processing. Hillsdale/NJ: Erlbaum, pp. 223-243.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Hudson</author>
</authors>
<title>Word Grammar.</title>
<date>1984</date>
<publisher>Blackwell.</publisher>
<location>Oxford:</location>
<contexts>
<context position="29868" citStr="Hudson (1984" startWordPosition="4773" endWordPosition="4774">erb to the sentence delimiter (no effect). Since there are no possible antecedents within the sentence, in phase 3 possible antecedents are checked which are stored as the acquaintances Focus and PoiFoci of the sentence delimiter for the previous sentence. Since Rechner subsumes LTELite at the conceptual level, NomAnaph,orTest succeeds. An AntecedentFound message is created, which changes the concept identifier of Rechner appropriately. 5 Comparison to Related Work From the linguistic viewpoint, sentence anaphora, so far, have only been sketchily dealt with by dependency grammarians, e.g., by Hudson (1984; 1990). The most detailed description of grammatical regularities and an associated parsing procedure has been supplied by Lappin and McCord (1990). It is based on the format of a slot grammar (SG), a slight theory variant of DG. In particular, they treat pronominal coreference and anaphora (i.e., reflexives and reciprocals). Our approach methodologically differs in three major aspects from that study: First, unlike the SG proposal, which is based on a second-pass algorithm operating on fully parsed clauses to determine anaphoric relationships, our proposal is basically an incremental single-</context>
</contexts>
<marker>Hudson, 1984</marker>
<rawString>Hudson, R. (1984). Word Grammar. Oxford: Blackwell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Hudson</author>
</authors>
<title>English Word Grammar.</title>
<date>1990</date>
<publisher>Blackwell.</publisher>
<location>Oxford:</location>
<marker>Hudson, 1990</marker>
<rawString>Hudson, R. (1990). English Word Grammar. Oxford: Blackwell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Ingria</author>
<author>D Stallard</author>
</authors>
<title>A computational mechanism for pronominal reference.</title>
<date>1989</date>
<booktitle>Proc. ACL &apos;89.</booktitle>
<pages>262--271</pages>
<location>Vancouver, Canada,</location>
<contexts>
<context position="17468" citStr="Ingria and Stallard (1989)" startWordPosition="2790" endWordPosition="2793">ng concepts, e.g., (MOTHERBOARD, has-cpu, CPU) E permit. Furthermore, object. attribute denotes the value of the property attribute at object and the symbol self refers to the current lexical item. The Parse Talk specification language, in addition, incorporates topological primitives for relations within dependency trees. The relations left and head denote &amp;quot;x occurs left of y&amp;quot; and &amp;quot;x is head of y&amp;quot;, resp. These primitive relations can be considered declarative equivalents to the procedural specifications used in several tree-walking algorithms for anaphora resolution, e.g., by Hobbs (1978) or Ingria and Stallard (1989). Note that in the description below ref+ and rel* denote the transitive and transitive/reflexive closure of a relation rel, respectively. x d-binds y (x head + y) A z: ((x head + z) A (z head + y) A (z isac* finiteVerb V 3u: (z head u A ((z spec u A u /sac* DetPossessive) ✓ (z saxGen u A u isact Noun) ✓ (z ppAtt u A u isac* Noun) ✓ (z genAtt u A u isac* Noun))))) Box 1: D-binding The possible antecedents that can be reached via anaphoric relations are described by the predicates isPotentialReflexiiieAntecedentOf (cf. Box 2) and isPotentialAnaphoricAntecedentOf (cf. Box 3). These incorporate t</context>
</contexts>
<marker>Ingria, Stallard, 1989</marker>
<rawString>Ingria, R. and Stallard, D. (1989). A computational mechanism for pronominal reference. Proc. ACL &apos;89. Vancouver, Canada, pp.262-271.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Kamp</author>
<author>U Reyle</author>
</authors>
<title>From Discourse to Logic.</title>
<date>1993</date>
<publisher>Kluwer.</publisher>
<location>Dordrecht:</location>
<contexts>
<context position="2846" citStr="Kamp and Reyle, 1993" startWordPosition="412" endWordPosition="415">) within the context of HPSG, whose treatment is nevertheless restricted to reflexive pronouns). Interestingly enough, when faced with some crucial linguistic phenomena, such as topicalization, GB must assume rather complex movement operations in order to cope with the data in a satisfactory manner. Things get even more complicated when languages with relatively free word order, such as German, are taken into account. Finally, considering the case of text anaphora, binding theory has nothing to offer at all. Another strong alternative for considering anaphora constitutes the framework of DRT (Kamp and Reyle, 1993). Its development can be considered a landmark in the model-theoretic semantic analysis of various forms of quantified sentences, conditionals, and anaphorically linked multi-sentential discourse. At this level of description, DRT is clearly superior to GB. On the other hand, its lack of an equally thorough treatment of complex syntactic constructions makes it inferior to GB. These deficits are no wonder, since DRT is not committed to any particular syntactic theory, and thus cannot place strict enough syntactic constraints on the admissible constituent structures. Focusing on the text analysi</context>
</contexts>
<marker>Kamp, Reyle, 1993</marker>
<rawString>Kamp, H. and Reyle, U. (1993). From Discourse to Logic. Dordrecht: Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kuno</author>
</authors>
<title>Anaphora and discourse principles. In</title>
<date>1987</date>
<pages>87--111</pages>
<publisher>North-Holland,</publisher>
<location>Amsterdam:</location>
<contexts>
<context position="1960" citStr="Kuno, 1987" startWordPosition="274" endWordPosition="275">nent phenomenon that yields textual cohesion in discourse. Adequate grammars should therefore also be easily extensible to cover nonanaphoric text phenomena (e.g., coherence relations, rhetorical predicates), which provide for additional levels of text (macro) structure, with descriptions stated at the same level of theoretical sophistkation as for anaphora. First, we will briefly compare our approach with work done in the context of government-binding (GB) grammar and discourse representation theory (DRT). As we conceive it, binding theory as developed within the GB framework (Chomsky, 1981; Kuno, 1987) offers one of the most sophisticated approaches for treating anaphora at the sentence level of description. This has also been recognized by advocates of competing grammar formalisms, who have elaborated on GB&apos;s binding principles (cf., e.g., Pollard and Sag (1992) within the context of HPSG, whose treatment is nevertheless restricted to reflexive pronouns). Interestingly enough, when faced with some crucial linguistic phenomena, such as topicalization, GB must assume rather complex movement operations in order to cope with the data in a satisfactory manner. Things get even more complicated w</context>
</contexts>
<marker>Kuno, 1987</marker>
<rawString>Kuno, S. (1987). Anaphora and discourse principles. In Nagao, M. (Ed.), Language and Artificial Intelligence. Amsterdam: North-Holland, pp.87-111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Lappin</author>
<author>H J Leass</author>
</authors>
<title>An algorithm for pronominal anaphora resolution.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<pages>535--561</pages>
<contexts>
<context position="30680" citStr="Lappin and Leass, 1994" startWordPosition="4896" endWordPosition="4899">mmar (SG), a slight theory variant of DG. In particular, they treat pronominal coreference and anaphora (i.e., reflexives and reciprocals). Our approach methodologically differs in three major aspects from that study: First, unlike the SG proposal, which is based on a second-pass algorithm operating on fully parsed clauses to determine anaphoric relationships, our proposal is basically an incremental single-pass parsing model. Most important, however, is that our model incorporates the text-level of anaphora resolution, a shortcoming of the original SG approach that has recently been removed (Lappin and Leass, 1994), but still is a source of lots of problems. Third, unlike our approach, even the current SG model for anaphora resolution does not incorporate conceptual knowledge and global discourse structures (for reasons discussed by Lappin and Laess). This decision might nevertheless cause trouble if more conceptually rooted text cohesion and coherence structures have to be accounted for (e.g., textual ellipses). A particular problem we have not yet solved, the plausible ranking of single antecedents from a candidate set, is dealt with in depth by Lappin and Laess (1994) and Hajicova et al. (1992). Both</context>
</contexts>
<marker>Lappin, Leass, 1994</marker>
<rawString>Lappin, S. and Leass, H. J. (1994). An algorithm for pronominal anaphora resolution. Computational Linguistics, 20. (4), 535-561.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Lappin</author>
<author>M McCord</author>
</authors>
<title>Anaphora resolution in slot grammar.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<volume>16</volume>
<pages>197--212</pages>
<contexts>
<context position="15082" citStr="Lappin and McCord (1990" startWordPosition="2414" endWordPosition="2417">eover, conceptual criteria have to be met as in the case of nominal anaphors which must subsume their antecedents at the conceptual level. Similarly, for pronominal anaphors the selected antecedent must be permitted in those conceptual roles connecting the pronominal anaphors and its grammatical head. The DG constraints for the use of reflexives and intra-sentential anaphora cover approximately the same phenomena as GB, but the structures used by DG analysis are less complex than those of GB and do not require the formal machinery of empty categories, binding chains and complex movements (cf. Lappin and McCord (1990, p.205) for a similar argument). Hence, our proposal provides a more tractable basis for implementation. 3 Major Grammatical Predicates The ParseTalk model of DG (Hahn et al., 1994) exploits inheritance as a major abstraction mechanism. The entire lexical system is organized as a hierarchy of lexical classes (isac denoting the subclass relation among lexical classes), with concrete lexical items forming the leave nodes of the corresponding lexicon grammar graph. Valency constraints are attached to each lexical item, on which the local computation of concrete dependency relations between a hea</context>
<context position="30016" citStr="Lappin and McCord (1990)" startWordPosition="4794" endWordPosition="4797">are checked which are stored as the acquaintances Focus and PoiFoci of the sentence delimiter for the previous sentence. Since Rechner subsumes LTELite at the conceptual level, NomAnaph,orTest succeeds. An AntecedentFound message is created, which changes the concept identifier of Rechner appropriately. 5 Comparison to Related Work From the linguistic viewpoint, sentence anaphora, so far, have only been sketchily dealt with by dependency grammarians, e.g., by Hudson (1984; 1990). The most detailed description of grammatical regularities and an associated parsing procedure has been supplied by Lappin and McCord (1990). It is based on the format of a slot grammar (SG), a slight theory variant of DG. In particular, they treat pronominal coreference and anaphora (i.e., reflexives and reciprocals). Our approach methodologically differs in three major aspects from that study: First, unlike the SG proposal, which is based on a second-pass algorithm operating on fully parsed clauses to determine anaphoric relationships, our proposal is basically an incremental single-pass parsing model. Most important, however, is that our model incorporates the text-level of anaphora resolution, a shortcoming of the original SG </context>
</contexts>
<marker>Lappin, McCord, 1990</marker>
<rawString>Lappin, S. and McCord, M. (1990). Anaphora resolution in slot grammar. Computational Linguistics, 16. (4), 197-212.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R MacGregor</author>
<author>R Bates</author>
</authors>
<title>The LOOM Knowledge Representation Language.</title>
<date>1987</date>
<tech>ISI Reprint Series, ISI/RS-87-188,</tech>
<institution>Univ. of Southern California.</institution>
<marker>MacGregor, Bates, 1987</marker>
<rawString>MacGregor, R. and Bates, R. (1987). The LOOM Knowledge Representation Language. ISI Reprint Series, ISI/RS-87-188, Univ. of Southern California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W C Mann</author>
<author>S A Thompson</author>
</authors>
<title>Rhetorical structure theory: toward a functional theory of text organization.</title>
<date>1988</date>
<journal>Text,</journal>
<volume>8</volume>
<pages>243--281</pages>
<contexts>
<context position="3882" citStr="Mann and Thompson, 1988" startWordPosition="567" endWordPosition="570">ce DRT is not committed to any particular syntactic theory, and thus cannot place strict enough syntactic constraints on the admissible constituent structures. Focusing on the text analysis potential of DRT, its complex machinery might work in a satisfactory way for several well-studied forms of anaphora, but it necessarily fails if various non-anaphoric text phenomena need to be interpreted. This is particularly true of conceptually-rooted and pragmatically driven inferences necessary to build up textual macro structures in terms of coherence relations (Hobbs, 1982) or rhetorical structures (Mann and Thompson, 1988). This shortcoming is simply due to the fact that DRT is basically a semantic theory, not a comprehensive model for text understanding; it lacks any systematic connec237 tion to comprehensive reasoning systems covering the conceptual knowledge and specific problemsolving models underlying the chosen domain. Summing up, DRT is fairly restricted both with respect to the incorporation of powerful syntactic constraints at the sentence level and its extension to the level of (non-anaphoric) text macro structures. GB, on the other hand, is strong with respect to the specification of binding conditio</context>
</contexts>
<marker>Mann, Thompson, 1988</marker>
<rawString>Mann, W. C. and Thompson, S. A. (1988). Rhetorical structure theory: toward a functional theory of text organization. Text, 8. (3), 243-281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Pollard</author>
<author>I A Sag</author>
</authors>
<title>Anaphors in English and the scope of binding theory.</title>
<date>1992</date>
<journal>Linguistic Inquiry,</journal>
<volume>23</volume>
<pages>261--303</pages>
<contexts>
<context position="2226" citStr="Pollard and Sag (1992)" startWordPosition="314" endWordPosition="317">acro) structure, with descriptions stated at the same level of theoretical sophistkation as for anaphora. First, we will briefly compare our approach with work done in the context of government-binding (GB) grammar and discourse representation theory (DRT). As we conceive it, binding theory as developed within the GB framework (Chomsky, 1981; Kuno, 1987) offers one of the most sophisticated approaches for treating anaphora at the sentence level of description. This has also been recognized by advocates of competing grammar formalisms, who have elaborated on GB&apos;s binding principles (cf., e.g., Pollard and Sag (1992) within the context of HPSG, whose treatment is nevertheless restricted to reflexive pronouns). Interestingly enough, when faced with some crucial linguistic phenomena, such as topicalization, GB must assume rather complex movement operations in order to cope with the data in a satisfactory manner. Things get even more complicated when languages with relatively free word order, such as German, are taken into account. Finally, considering the case of text anaphora, binding theory has nothing to offer at all. Another strong alternative for considering anaphora constitutes the framework of DRT (K</context>
</contexts>
<marker>Pollard, Sag, 1992</marker>
<rawString>Pollard, C. and Sag, I. A. (1992). Anaphors in English and the scope of binding theory. Linguistic Inquiry, 23. (2) 261-303.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Schacht</author>
<author>U Hahn</author>
<author>N Braker</author>
</authors>
<title>Concurrent lexicalized dependency parsing: a behavioral view on Parse Talk events.</title>
<date>1994</date>
<booktitle>Proc. COLING &apos;94.</booktitle>
<pages>489--493</pages>
<location>Kyoto, Japan, Vol.1.,</location>
<contexts>
<context position="20614" citStr="Schacht et al. 1994" startWordPosition="3281" endWordPosition="3284">elf\ agr\ pers) U(anteleatures\self\agr\ pers) 1) A Vx V role E R.: (x head pro A (x.concept, pro.concept) E roles (x.concept, role, ante.concept) E permit) Box 4: PronAnaphorTest NomAnaphorTest (defNP, ante):4=&gt; ante isac* Noun A ((defNP.features \self\agr\ num) U(anteleatures \self\ agr\ num) 0 1) A ante.concept isaF* defNP.concept Box 5: NomAnaphorTesi 4 Resolution of Anaphora The Parse Talk environment builds on the actor computation model (Agha and Hewitt, 1987) as background for the procedural interpretation of lexicalized dependency specifications in terms of so-called word actors (cf. Schacht et al. 1994; Hahn et al. 1994). Word actors combine objectoriented features with concurrency yielding strict lexical distribution and distributed computation in a methodologically clean way. The model assumes word actors to communicate via asynchronous message passing. An actor can send messages only to other actors it knows about, its socalled acquaintances. The arrival of a message at an actor is called an event; it triggers the execution of a method that is composed of atomic actions — among them the evaluation of grammatical predicates. As we will show, the specification of a particular message proto</context>
</contexts>
<marker>Schacht, Hahn, Braker, 1994</marker>
<rawString>Schacht, S., Hahn, U., and Braker, N. (1994). Concurrent lexicalized dependency parsing: a behavioral view on Parse Talk events. Proc. COLING &apos;94. Kyoto, Japan, Vol.1., pp.489-493.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C L Sidner</author>
</authors>
<title>Focusing in the comprehension of definite anaphora. In</title>
<date>1983</date>
<pages>267--330</pages>
<publisher>MIT Pr.,</publisher>
<contexts>
<context position="21849" citStr="Sidner, 1983" startWordPosition="3470" endWordPosition="3471">treatment of fairly general linguistic tasks, such as establishing dependencies, properly arranging coordinations, and, of course, resolving anaphors. Consequently, any of these subprotocols constitutes part of the grammar specification proper. We shall illustrate the linguistic aspects of word actor-based parsing by introducing the basic data structures for text-level anaphora as acquaintances of specific word actors, and then turn to the general message-passing protocol that accounts for intra- as well as inter-sentential anaphora. Our exposition builds on the well-known focusing mechanism (Sidner, 1983; Grosz and Sidner, 1986). Accordingly, we distinguish each sentence&apos;s unique focus, a complementary list of alternate potential foci, and a history list composed of discourse elements not in the list of potential foci, but occurring in previous sentences of the current discourse segment. These data structures are realized as acquaintances of sentence delimiters to restrict the search space beyond the sentence to the relevant word actors. The protocol &apos;level of analysis encompasses the procedural interpretation of the declarative constraints given in Section 2. At that level, in the case of re</context>
</contexts>
<marker>Sidner, 1983</marker>
<rawString>Sidner, C. L. (1983). Focusing in the comprehension of definite anaphora. In Brady, M. and Berwick, R. (Eds.), Computational Models of Discourse. Cambridge/MA: MIT Pr., pp.267-330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Xu</author>
</authors>
<title>Distributed, Shared and Persistent Objects. A Model for Distributed Object-Oriented Programming.</title>
<date>1993</date>
<institution>London University, Dept. of Computer Science (Ph.D.Diss.).</institution>
<contexts>
<context position="32954" citStr="Xu, 1993" startWordPosition="5242" endWordPosition="5243">al dependency configurations are considerably simpler than their GB counterparts, though suitably expressive. The anaphora resolution module (for reflexives, intra- and inter-sentential anaphora) has been realized as part of Parse Talk, a dependency parser which forms part of a larger text understanding system for the German language, currently under development at our laboratory. The parser has been implemented in Smalltalk; the Smalltalk system itself, which runs on a SUN SparcStation network, has been extended by asynchronous message passing facilities and physical distribution mechanisms (Xu, 1993). The current lexicon contains a hierarchy of approximately 100 word class specifications with nearly 3.000 lexical entries and corresponding concept descriptions from two domains (information technology and medicine) available from the LOOM knowledge representation system (MacGregor and Bates, 1987). Acknowledgments. We would like to thank our colleagues in the CCIF group who read earlier versions of this paper. In particular, improvements are due to discussions we had with S. Schacht, N. Braker, P. Neuhaus, and M. Klenner. We also like to thank J. Alcantara (Cornell U) who kindly took the ro</context>
</contexts>
<marker>Xu, 1993</marker>
<rawString>Xu, W. (1993). Distributed, Shared and Persistent Objects. A Model for Distributed Object-Oriented Programming. London University, Dept. of Computer Science (Ph.D.Diss.).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>