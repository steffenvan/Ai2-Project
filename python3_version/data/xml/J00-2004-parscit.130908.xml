<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.995398">
Models of Translational Equivalence
among Words
</title>
<author confidence="0.836183">
I. Dan Melamed*
</author>
<affiliation confidence="0.406823">
West Group
</affiliation>
<bodyText confidence="0.995672666666667">
Parallel texts (bitexts) have properties that distinguish them from other kinds of parallel data.
First, most words translate to only one other word. Second, bitext correspondence is typically
only partial—many words in each text have no clear equivalent in the other text. This article
presents methods for biasing statistical translation models to reflect these properties. Evalua-
tion with respect to independent human judgments has confirmed that translation models biased
in this fashion are significantly more accurate than a baseline knowledge-free model. This arti-
cle also shows how a statistical translation model can take advantage of preexisting knowledge
that might be available about particular language pairs. Even the simplest kinds of language-
specific knowledge, such as the distinction between content words and function words, are
shown to reliably boost translation model performance on some tasks. Statistical models that
reflect knowledge about the model domain combine the best of both the rationalist and empiricist
paradigms.
</bodyText>
<sectionHeader confidence="0.993927" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.9999724">
The idea of a computer system for translating from one language to another is almost
as old as the idea of computer systems. Warren Weaver wrote about mechanical trans-
lation as early as 1949. More recently, Brown et al. (1988) suggested that it may be
possible to construct machine translation systems automatically. Instead of codifying
the human translation process from introspection, Brown and his colleagues proposed
machine learning techniques to induce models of the process from examples of its in-
put and output. The proposal generated much excitement, because it held the promise
of automating a task that forty years of research have proven very labor-intensive and
error-prone. Yet very few other researchers have taken up the cause, partly because
Brown et al.&apos;s (1988) approach was quite a departure from the paradigm in vogue at
the time.
Formally, Brown et al. (1988) built statistical models of translational equivalence
(or translation models&apos;, for short). In the context of computational linguistics, trans-
lational equivalence is a relation that holds between two expressions with the same
meaning, where the two expressions are in different languages. Empirical estimation
of statistical translation models is typically based on parallel texts or bitexts—pairs
of texts that are translations of each other. As with all statistical models, the best
translation models are those whose parameters correspond best with the sources of
variance in the data. Probabilistic translation models whose parameters reflect univer-
sal properties of translational equivalence and/or existing knowledge about particular
</bodyText>
<footnote confidence="0.997015">
* D1-66F, 610 Opperman Drive, Eagan, MN 55123. E-mail: dan.melamed@twestgroup.com
1 The term translation model, which is standard in the literature, refers to a mathematical relationship
between two data sets. hi this context, the term implies nothing about the process of translation
between natural languages, automated or otherwise.
</footnote>
<note confidence="0.8743085">
© 2000 Association for Computational Linguistics
Computational Linguistics Volume 26, Number 2
</note>
<bodyText confidence="0.9985882">
languages and language pairs benefit from the best of both the empiricist and ratio-
nalist traditions.
This article presents three such models, along with methods for efficiently esti-
mating their parameters. Each new method is designed to account for an additional
universal property of translational equivalence in bitexts:
</bodyText>
<listItem confidence="0.983203">
1. Most word tokens translate to only one word token. I approximate this
tendency with a one-to-one assumption.
2. Most text segments are not translated word-for-word. I build an explicit
noise model.
3. Different linguistic objects have statistically different behavior in
translation. I show a way to condition translation models on different
word classes to help account for the variety
</listItem>
<bodyText confidence="0.999614294117647">
Quantitative evaluation with respect to independent human judgments has shown
that each of these three estimation biases significantly improves translation model ac-
curacy over a baseline knowledge-free model. However, these biases will not produce
the best possible translation models by themselves. Anyone attempting to build an op-
timal translation model should infuse it with all available knowledge sources, includ-
ing syntactic, dictionary and cognate information. My goal here is only to demonstrate
the value of some previously unused kinds of information that are always available for
translation modeling, and to show how these information sources can be integrated
with others.
A review of some previously published translation models follows an introduction
to translation model taxonomy The core of the article is a presentation of the model
estimation biases described above. The last section reports the results of experiments
designed to evaluate these innovations.
Throughout this article, I shall use CAGEIg&apos;RAPHIC letters to denote entire text
corpora and other sets of sets, CAPITAL letters to denote collections, including se-
quences and bags, and italics for scalar variables. I shall also distinguish between
types and tokens by using bold font for the former and plain font for the latter.
</bodyText>
<sectionHeader confidence="0.995278" genericHeader="keywords">
2. Translation Model Decomposition
</sectionHeader>
<bodyText confidence="0.9969392">
There are two kinds of applications of translation models: those where word order
plays a crucial role and those where it doesn&apos;t. Empirically estimated models of trans-
lational equivalence among word types can play a central role in both kinds of appli-
cations.
Applications where word order is not essential include
</bodyText>
<listItem confidence="0.918207714285714">
• cross-language information retrieval (e.g., McCarley 1999),
• multilingual document filtering (e.g., Oard 1997),
• computer-assisted language learning (e.g., Nerbonne et al. 1997),
• certain machine-assisted translation tools (e.g., Macklovitch 1994;
Melamed 1996a),
• concordancing for bilingual lexicography (e.g., Catizone, Russell, and
Warwick 1989; Gale and Church 1991),
</listItem>
<page confidence="0.990843">
222
</page>
<note confidence="0.949409">
Melamed Models of Translational Equivalence
</note>
<listItem confidence="0.984753666666667">
• corpus linguistics (e.g., Svartvik 1992),
• &amp;quot;crummy&amp;quot; machine translation (e.g., Church and Hovy 1992; Resnik
1997).
</listItem>
<bodyText confidence="0.9998515">
For these applications, empirically estimated models have a number of advantages
over handcrafted models such as on-line versions of bilingual dictionaries. Two of
the advantages are the possibility of better coverage and the possibility of frequent
updates by nonexpert users to keep up with rapidly evolving vocabularies.
A third advantage is that statistical models can provide more accurate information
about the relative importance of different translations. Such information is crucial for
applications such as cross-language information retrieval (CUR). In the vector space
approach to CUR, the query vector Q&apos; is in a different language (a different vector
space) from the document vectors D. A word-to-word translation model T can map Q&apos;
into a vector Q in the vector space of D. In order for the mapping to be accurate, T must
be able to encode many levels of relative importance among the possible translations
of each element of Q&apos;. A typical bilingual dictionary says only what the possible
translations are, which is equivalent to positing a uniform translational distribution.
The performance of cross-language information retrieval with a uniform T is likely to
be limited in the same way as the performance of conventional information retrieval
without term-frequency information, i.e., where the system knows which terms occur
in which documents, but not how often (Buckley 1993).
Applications where word order is crucial include speech transcription for trans-
lation (Brousseau et al. 1995), bootstrapping of OCR systems for new languages (Philip
Resnik and Tapas Kanungo, personal communication), interactive translation
(Foster, Isabelle, and Plamondon 1996), and fully automatic high-quality machine
translation (e.g., Al-Onaizan et al. 1999). In such applications, a word-to-word trans-
lation model can serve as an independent module in a more complex sequence-to-
sequence translation model.&apos; The independence of such a module is desirable for two
reasons, one practical and one philosophical. The practical reason is illustrated in
this article: Order-independent translation models can be accurately estimated more
efficiently in isolation. The philosophical reason is that words are an important epis-
temological category in our naive mental representations of language. We have many
intuitions (and even some testable theories) about what words are and how they be-
have. We can bring these intuitions to bear on our translation models without being
distracted by other facets of language, such as phrase structure. For example, the
translation models presented in the last two chapters of Melamed (to appear) cap-
ture the intuitions that words can have multiple senses and that spaces in text do not
necessarily delimit words.
The independence of a word-to-word translation module in a sequence-to-sequence
translation model can be effected by a two-stage decomposition. The first stage is based
on the observation that every sequence L is just an ordered bag, and that the bag B
can be modeled independently of its order 0. For example, the sequence (abc) consists
of the bag {c, a, b} and the ordering relation {(b, 2), (a,1), (c, 3)1. If we represent each
sequence L as a pair (B, 0), then
</bodyText>
<equation confidence="0.9963545">
Pr (L) Pr(B, 0) (1)
= Pr(B) - Pr(01B). (2)
</equation>
<bodyText confidence="0.7412635">
2 &amp;quot;Sentence-to-sentence&amp;quot; might be a more transparent term than &amp;quot;sequence-to-sequence,&amp;quot; but all the
models that I&apos;m aware of apply equally well to sequences of words that are not sentences.
</bodyText>
<page confidence="0.997266">
223
</page>
<note confidence="0.882228">
Computational Linguistics Volume 26, Number 2
</note>
<bodyText confidence="0.9984646">
Now, let Li and L2 be two sequences and let A be a one-to-one mapping between
the elements of L1 and the elements of L2. Borrowing a term from the operations
research literature, I shall refer to such mappings as assignments.&apos; Let A be the set of
all possible assignments between L1 and L2. Using assignments, we can decompose
conditional and joint probabilities over sequences:
</bodyText>
<table confidence="0.78191075">
where Pr(1411-2) = Pr(Li, A11,2) (3)
Pr(Li, 1,2) -= AEA
E Pr(Li, A, L2) (4)
AEA
</table>
<equation confidence="0.917178625">
Pr(Li, AlL2) Pr(Bi, 01, A1L2) (5)
Pr(Bi,AIL2) • Pr(011131, A, L2) (6)
Pr(Li, A, L2) Pr(Bi, 01, A, B2, 02) (7)
Pr(Bi, A, B2) • Pr(0i, 021%, A, B2) (8)
Summing bag pair probabilities over all possible assignments, we obtain a bag-to-bag
translation model:
Pr(Bi, B2) = Pr(Bi, A, B2) (9)
AEA
</equation>
<bodyText confidence="0.984911">
The second stage of decomposition takes us from bags of words to the words
that they contain. The following bag pair generation process illustrates how a word-
to-word translation model can be embedded in a bag-to-bag translation model for
languages Li and £2:
</bodyText>
<listItem confidence="0.999572666666667">
1. Generate a bag size 1.4 1 is also the assignment size.
2. Generate 1 language-independent concepts Ci, ,C1.
3. From each concept C, 1 &lt; i &lt; 1, generate a pair of word sequences (fi,,zii)
</listItem>
<bodyText confidence="0.992704">
from LI x according to the distribution trans(ti, V), to lexicalize the
concept in the two languages.&apos; Some concepts are not lexicalized in some
languages, so one of it, and V, may be empty.
A pair of bags containing m and n nonempty word sequences can be generated by a
process where / is anywhere between 1 and m n.
For notational convenience, the elements of the two bags can be labeled so that
Bi ,10 and B2 {Irlt • • • , VI}, where some of the ti&apos;s and V&apos;s may be
empty. The elements of an assignment, then, are pairs of bag element labels: A
{(ii, (ii,.//)}, where each i ranges over {di, , each] ranges over {VI, • • • , V.1},
</bodyText>
<footnote confidence="0.948767571428571">
3 Assignments are different from Brown, Della Pietra, Della Pietra, and Mercer&apos;s (1993) alignments in
that assignments can range over pairs of arbitrary labels, not necessarily sequence position indexes.
Also, unlike alignments, assignments must be one-to-one.
4 The exact nature of the bag size distribution is immaterial for the present purposes.
5 Since they are put into bags, fii and could just as well be bags instead of sequences. I make them
sequences only to be consistent with more sophisticated models that account for noncompositional
compounds (e.g. Melamed, to appear, Chapter 8).
</footnote>
<page confidence="0.992076">
224
</page>
<note confidence="0.979436">
Melamed Models of Translational Equivalence
</note>
<bodyText confidence="0.99583775">
each i is distinct, and each j is distinct. The label pairs in a given assignment can be
generated in any order, so there are 1! ways to generate an assignment of size 1.6 It
follows that the probability of generating a pair of bags (B1, B2) with a particular
assignment A of size 1 is
</bodyText>
<equation confidence="0.8495595">
Pr(Bi, A, B21/, C , trans) = Pr (1) 1! ri E Pr(C)trans(tii, Ari1C). (10)
CEC
</equation>
<bodyText confidence="0.999913125">
The above equation holds regardless of how we represent concepts. There are
many plausible representations, such as pairs of trees from synchronous tree adjoining
grammars (Abeille et al. 1990; Shieber 1994; Candito 1998), lexical conceptual struc-
tures (Dorr 1992) and WordNet synsets (Fellbaum 1998; Vossen 1998). Of course, for a
representation to be used, a method must exist for estimating its distribution in data.
A useful representation will reduce the entropy of the trans distribution, which is con-
ditioned on the concept distribution as shown in Equation 10. This topic is beyond the
scope of this article, however. I mention it only to show how the models presented
here may be used as building blocks for models that are more psycholinguistically
sophisticated.
To make the translation model estimation methods presented here as general as
possible, I shall assume a totally uninformative concept representation—the trans dis-
tribution itself. In other words, I shall assume that each different pair of word sequence
types is deterministically generated from a different concept, so that trans (Ili, ViIC) is
zero for all concepts except one. Now, a bag-to-bag translation model can be fully
specified by the distributions of 1 and trans.
</bodyText>
<equation confidence="0.636643">
Pr (Bi, A, B21/, trans) = Pr(/) • 1! H trans(ii,Ari) (11)
(i•/) EA
</equation>
<bodyText confidence="0.999957">
The probability distribution trans (ii, it&apos;) is a word-to-word translation model. Unlike
the models proposed by Brown et al. (1993b), this model is symmetric, because both
word bags are generated together from a joint probability distribution. Brown and his
colleagues&apos; models, reviewed in Section 4.3, generate one half of the bitext given the
other half, so they are represented by conditional probability distributions. A sequence-
to-sequence translation model can be obtained from a word-to-word translation model
by combining Equation 11 with order information as in Equation 8.
</bodyText>
<subsectionHeader confidence="0.705466">
3. The One-to-One Assumption
</subsectionHeader>
<bodyText confidence="0.999814555555556">
The most general word-to-word translation model trans(ii, V), where ii and range
over sequences in Li and £2, has an infinite number of parameters. This model can
be constrained in various ways to make it more practical. The models presented in
this article are based on the one-to-one assumption: Each word is translated to at
most one other word. In these models, ü and ii may consist of at most one word each.
As before, one of the two sequences (but not both) may be empty. I shall describe
empty sequences as consisting of a special NULL word, so that each word sequence
will contain exactly one word and can be treated as a scalar. Henceforth, I shall write u
and v instead of ü and Under the one-to-one assumption, a pair of bags containing m
</bodyText>
<footnote confidence="0.9496975">
6 The number of permutations is smaller when either bag contains two or more identical elements, but
this detail will not affect the estimation algorithms presented here.
</footnote>
<page confidence="0.989587">
225
</page>
<note confidence="0.435848">
Computational Linguistics Volume 26, Number 2
</note>
<bodyText confidence="0.995297">
and n nonempty words can be generated by a process where the bag size / is anywhere
between max(m,n) and m + n.
The one-to-one assumption is not as restrictive as it may appear: The explanatory
power of a model based on this assumption may be raised to an arbitrary level by
extending Western notions of what words are to include words that contain spaces
(e.g., in English) or several characters (e.g., in Chinese). For example, I have shown
elsewhere how to estimate word-to-word translation models where a word can be a
noncompositional compound consisting of several space-delimited tokens (Melamed,
to appear). For the purposes of this article, however, words are the tokens generated
by my tokenizers and stemmers for the languages in question. Therefore, the models
in this article are only a first approximation to the vast complexities of translational
equivalence between natural languages. They are intended mainly as stepping stones
towards better models.
</bodyText>
<sectionHeader confidence="0.995263" genericHeader="introduction">
4. Previous Work
</sectionHeader>
<subsectionHeader confidence="0.999998">
4.1 Models of Co-occurrence
</subsectionHeader>
<bodyText confidence="0.9996742">
Most methods for estimating translation models from bitexts start with the following
intuition: Words that are translations of each other are more likely to appear in cor-
responding bitext regions than other pairs of words. Following this intuition, most
authors begin by counting the number of times that word types in one half of the
bitext co-occur with word types in the other half. Different co-occurrence counting
methods stem from different models of co-occurrence.
A model of co-occurrence is a Boolean predicate, which indicates whether a given
pair of word tokens co-occur in corresponding regions of the bitext space. Different
models of co-occurrence are possible, depending on the kind of bitext map that is avail-
able, the language-specific information that is available, and the assumptions made
about the nature of translational equivalence. All the translation models reviewed and
introduced in this article can be based on any of the co-occurrence models described
by Melamed (1998a). For expository purposes, however, I shall assume a boundary-
based model of co-occurrence throughout this article. A boundary-based model of
co-occurrence assumes that both halves of the bitext have been segmented into s seg-
ments, so that segment U, in one half of the bitext and segment V, in the other half
are mutual translations, 1 &lt; i &lt; s.
Under the boundary-based model of co-occurrence, there are several ways to com-
pute co-occurrence counts cooc(u, v) between word types u and v. In the models of
Brown, Della Pietra, Della Pietra, and Mercer (1993), reviewed in Section 4.3,
</bodyText>
<equation confidence="0.866005">
cooc(u, E e(u) .fi(v), (12)
</equation>
<bodyText confidence="0.9994">
where e, and f, are the urtigram frequencies of u and v, respectively, in each aligned
text segment i. For most translation models, this method produces suboptimal results,
however, when e,(u) &gt; 1 and J(v) &gt; 1. I argue elsewhere (Melamed 1998a) that
</bodyText>
<equation confidence="0.779596">
cooc(u, v) = min[ei(u),fi(v)] (13)
</equation>
<footnote confidence="0.638695">
is preferable, and this is the method used for the models introduced in Section 5.
</footnote>
<page confidence="0.996674">
226
</page>
<figure confidence="0.905972">
Melamed Models of Translational Equivalence
He nods his head
II I
hoche la tete
</figure>
<figureCaption confidence="0.995669">
Figure 1
</figureCaption>
<bodyText confidence="0.784141666666667">
nods and hoche often co-occur, as do nods and head. The direct association between nods and
hoche, and the direct association between nods and head give rise to an indirect association
between hoche and head.
</bodyText>
<subsectionHeader confidence="0.921191">
4.2 Nonprobabilistic Translation Lexicons
</subsectionHeader>
<bodyText confidence="0.999376">
Many researchers have proposed greedy algorithms for estimating nonprobabilistic
word-to-word translation models, also known as translation lexicons (e.g., Catizone,
Russell, and Warwick 1989; Gale and Church 1991; Fung 1995; Kumano and Hirakawa
</bodyText>
<listItem confidence="0.974166875">
1994; Melamed 1995; Wu and Xia 1994). Most of these algorithms can be summarized
as follows:
1. Choose a similarity function S between word types in Li and word types
in L.
2. Compute association scores S(u, v) for a set of word type pairs
(u, v) E (Li x £2) that occur in training data.
3. Sort the word pairs in descending order of their association scores.
4. Discard all word pairs for which S(u, v) is less than a chosen threshold.
</listItem>
<bodyText confidence="0.998674380952381">
The remaining word pairs become the entries in the translation lexicon.
The various proposals differ mainly in their choice of similarity function. Almost all
the similarity functions in the literature are based on a model of co-occurrence with
some linguistically motivated filtering (see Fung [1995] for a notable exception).
Given a reasonable similarity function, the greedy algorithm works remarkably
well, considering how simple it is. However, the association scores in Step 2 are typ-
ically computed independently of each other. The problem with this independence
assumption is illustrated in Figure 1. The two word sequences represent correspond-
ing regions of an English/French bitext. If nods and hoche co-occur much more often
than expected by chance, then any reasonable similarity metric will deem them likely
to be mutual translations. Nods and hoche are indeed mutual translations, so their ten-
dency to co-occur is called a direct association. Now, suppose that nods and head often
co-occur in English. Then hoche and head will also co-occur more often than expected
by chance. The dashed arrow between hoche and head in Figure 1 represents an indirect
association, since the association between hoche and head arises only by virtue of the
association between each of them and nods. Models of translational equivalence that
are ignorant of indirect associations have &amp;quot;a tendency ... to be confused by collocates&amp;quot;
(Dagan, Church, and Gale 1993,5).
Paradoxically, the irregularities (noise) in text and in translation mitigate the prob-
lem. If noise in the data reduces the strength of a direct association, then the same
noise will reduce the strengths of any indirect associations that are based on this direct
</bodyText>
<page confidence="0.99617">
227
</page>
<note confidence="0.403363">
Computational Linguistics Volume 26, Number 2
</note>
<tableCaption confidence="0.972065">
Table 1
Variables used to describe translation models.
</tableCaption>
<equation confidence="0.996219">
(U, V) =
(U, V) =
e(u) =
f (v) =
cooc(u, v) =
trans(vu) =
</equation>
<bodyText confidence="0.9866345">
the two halves of the bitext
a pair of aligned text segments in (U, V)
the unigram frequency of u in U
the unigram frequency of v in V
the number of times that u and v co-occur
the probability that a token of u will be translated as a token of v
association. On the other hand, noise can reduce the strength of an indirect associa-
tion without affecting any direct associations. Therefore, direct associations are usually
stronger than indirect associations. If all the entries in a translation lexicon are sorted
by their association scores, the direct associations will be very dense near the top of
the list, and sparser towards the bottom.
Gale and Church (1991) have shown that entries at the very top of the list can
be over 98% correct. Their algorithm gleaned lexicon entries for about 61% of the
word tokens in a sample of 800 English sentences. To obtain 98% precision, their
algorithm selected only entries for which it had high confidence that the association
score was high. These would be the word pairs that co-occur most frequently. A
random sample of 800 sentences from the same corpus showed that 61% of the word
tokens, where the tokens are of the most frequent types, represent 4.5% of all the word
types.
A similar strategy was employed by Wu and Xia (1994) and by Fung (1995).
Fung skimmed off the top 23.8% of the noun-noun entries in her lexicon to achieve a
precision of 71.6%. Wu and Xia have reported automatic acquisition of 6,517 lexicon
entries from a 3.3-million-word corpus, with a precision of 86%. The first 3.3 million
word tokens in an English corpus from a similar genre contained 33,490 different word
types, suggesting a recall of roughly 19%. Note, however, that Wu and Xia chose to
weight their precision estimates by the probabilities attached to each entry:
For example, if the translation set for English word detect has the
two correct Chinese candidates with 0.533 probability and with 0.277
probability, and the incorrect translation with 0.190 probability, then
we count this as 0.810 correct translations and 0.190 incorrect transla-
tions. (Wu and Xia 1994, 211)
This is a reasonable evaluation method, but it is not comparable to methods that
simply count each lexicon entry as either right or wrong (e.g., Daille, Gaussier, and
Lange 1994; Melamed 1996b). A weighted precision estimate pays more attention to
entries that are more frequent and hence easier to estimate. Therefore, weighted pre-
cision estimates are generally higher than unweighted ones.
</bodyText>
<subsectionHeader confidence="0.836043">
4.3 Reestimated Sequence-to-Sequence Translation Models
</subsectionHeader>
<bodyText confidence="0.998495">
Most probabilistic translation model reestimation algorithms published to date are
variations on the theme proposed by Brown et al. (1993b). These models involve con-
ditional probabilities, but they can be compared to symmetric models if the latter are
normalized by the appropriate marginal distribution. I shall review these models using
the notation in Table 1.
</bodyText>
<page confidence="0.998074">
228
</page>
<note confidence="0.874406">
Melamed Models of Translational Equivalence
</note>
<subsubsectionHeader confidence="0.842514">
4.3.1 Models Using Only Co-occurrence Information. Brown and his colleagues em-
</subsubsectionHeader>
<bodyText confidence="0.99812925">
ploy the expectation-maximization (EM) algorithm (Dempster, Laird, and Rubin 1977)
to estimate the parameters of their Model 1. On iteration i, the EM algorithm reesti-
mates the model parameters transi(vju) based on their estimates from iteration i — 1.
In Model 1, the relationship between the new parameter estimates and the old ones is
</bodyText>
<equation confidence="0.992937666666667">
transi(v1u) = z trans,_1(vju) • e(u) •f (v) (14)
Ei„Eu trans1_1(vju0
(U,V)E(U,V)
</equation>
<bodyText confidence="0.97938975">
where z is a normalizing factor.&apos;
It is instructive to consider the form of Equation 14 when all the translation prob-
abilities trans(v1u) for a particular u are initialized to the same constant p, as Brown
et al. (1993b, 273) actually do:
</bodyText>
<equation confidence="0.996682333333333">
transi(v1u) = z E p • e(u) • f (v)
P 1U1
(U,V)E(U,V)
E e(u) • f (v)
&apos;UI
(U,V)E(U,V)
</equation>
<bodyText confidence="0.9996425">
The initial translation probability trans1(v1u) is set proportional to the co-occurrence
count of u and v and inversely proportional to the length of each segment U in which
u occurs. The intuition behind the numerator is central to most bitext-based translation
models: The more often two words co-occur, the more likely they are to be mutual
translations. The intuition behind the denominator is that the co-occurrence count of
u and v should be discounted to the degree that v also co-occurs with other words in
the same segment pair.
Now consider how Equation 16 would behave if all the text segments on each
side were of the same length,&apos; so that each token of v co-occurs with exactly c words
(where c is constant):
</bodyText>
<equation confidence="0.997809">
trans]. (v1u) = zE e(u) • f (v)
(17)
(U,V)E(U,V)
z E e(u) • f (v) (18)
(u,v)e(U,V)
</equation>
<bodyText confidence="0.999919">
The normalizing coefficient is constant over all words. The only difference between
Equations 16 and 18 is that the former discounts co-occurrences proportionally to the
segment lengths. When information about segment lengths is not available, the only
information available to initialize Model 1 is the co-occurrence counts. This property
makes Model 1 an appropriate baseline for comparison to more sophisticated models
that use other information sources, both in the work of Brown and his colleagues and
in the work described here.
</bodyText>
<footnote confidence="0.874027">
7 This expression is obtained by substituting Brown, Della Pietra, Della Pietra, and Mercer&apos;s (1993)
Equation 17 into their Equation 14.
8 Or, equivalently, if the notion of segments were dispensed with altogether, as under the distance-based
model of co-occurrence (Melamed 1998a).
</footnote>
<page confidence="0.991419">
229
</page>
<figure confidence="0.2528465">
Computational Linguistics Volume 26, Number 2
4.3.2 Word Order Correlation Biases. In any bitext, the positions of words relative to
</figure>
<bodyText confidence="0.999623541666667">
the true bitext map correlate with the positions of their translations. The correlation is
stronger for language pairs with more similar word order. Brown et al. (1988) intro-
duced the idea that this correlation can be encoded in translation model parameters.
Dagan, Church, and Gale (1993) expanded on this idea by replacing Brown et al.&apos;s
(1988) word alignment parameters, which were based on absolute word positions in
aligned segments, with a much smaller set of relative offset parameters. The much
smaller number of parameters allowed Dagan, Church, and Gale&apos;s model to be effec-
tively trained on much smaller bitexts. Vogel, Ney, and Tillmann (1996) have shown
how some additional assumptions can turn this model into a hidden Markov model,
enabling even more efficient parameter estimation.
It cannot be overemphasized that the word order correlation bias is just knowledge
about the problem domain, which can be used to guide the search for the optimum
model parameters. Translational equivalence can be empirically modeled for any pair
of languages, but some models and model biases work better for some language pairs
than for others. The word order correlation bias is most useful when it has high
predictive power, i.e., when the distribution of alignments or offsets has low entropy.
The entropy of this distribution is indeed relatively low for the language pair that both
Brown and his colleagues and Dagan, Church, and Gale were working with—French
and English have very similar word order. A word order correlation bias, as well as
the phrase structure biases in Brown et al.&apos;s (1993b) Models 4 and 5, would be less
beneficial with noisier training bitexts or for language pairs with less similar word
order. Nevertheless, one should use all available information sources, if one wants to
build the best possible translation model. Section 5.3 suggests a way to add the word
order correlation bias to the models presented in this article.
</bodyText>
<subsectionHeader confidence="0.998653">
4.4 Reestimated Bag-to-Bag Translation Models
</subsectionHeader>
<bodyText confidence="0.999991125">
At about the same time that I developed the models in this article, Hiemstra (1996)
independently developed his own bag-to-bag model of translational equivalence. His
model is also based on a one-to-one assumption, but it differs from my models in that
it allows empty words in only one of the two bags, the one representing the shorter
sentence. Thus, Hiemstra&apos;s model is similar to the first model in Section 5, but it has
a little less explanatory power. Hiemstra&apos;s approach also differs from mine in his use
of the Iterative Proportional Fitting Procedure (IPFP) (Deming and Stephan 1940) for
parameter estimation.
The IPFP is quite sensitive to initial conditions, so Hiemstra investigated a num-
ber of initialization options. Choosing the most advantageous, Hiemstra has published
parts of the translational distributions of certain words, induced using both his method
and Brown et al.&apos;s (1993b) Model 1 from the same training bitext. Subjective compar-
ison of these examples suggests that Hiemstra&apos;s method is more accurate. Hiemstra
(1998) has also evaluated the recall and precision of his method and of Model 1 on a
small hand-constructed set of link tokens in a particular bitext. Model 1 fared worse,
on average.
</bodyText>
<sectionHeader confidence="0.875068" genericHeader="method">
5. Parameter Estimation
</sectionHeader>
<bodyText confidence="0.9999862">
This section describes my methods for estimating the parameters of a symmetric word-
to-word translation model from a bitext. For most applications, we are interested in
estimating the probability trans (u, v) of jointly generating the pair of words (u, v).
Unfortunately, these parameters cannot be directly inferred from a training bitext,
because we don&apos;t know which words in one half of the bitext were generated together
</bodyText>
<page confidence="0.981437">
230
</page>
<note confidence="0.796631">
Melamed Models of Translational Equivalence
</note>
<bodyText confidence="0.99899275">
with which words in the other half. The observable features of the bitext are only the
co-occurrence counts cooc(u, v) (see Section 4.1).
Methods for estimating translation parameters from co-occurrence counts typically
involve link counts links(u, v), which represent hypotheses about the number of times
that u and v were generated together, for each u and v in the bitext. A link token is
an ordered pair of word tokens, one from each half of the bitext. A link type is an
ordered pair of word types. The link counts links(u, v) range over link types. We can
always estimate trans (u, v) by normalizing link counts so that E trans (u, v) = 1:
</bodyText>
<equation confidence="0.900399">
links(u v)
trans (u, v) = (19)
Eu, links(u&apos;, v&apos;)
</equation>
<bodyText confidence="0.999475625">
For estimation purposes, it is convenient to also employ a separate set of non-
probabilistic parameters score(u, v), which represent the chances that u and v can ever
be mutual translations, i.e., that there exists some context where tokens u and v are
generated from the same concept. The relationship between score(u, v) and trans (u, v)
can be more or less direct, depending on the model and its estimation method. Each
of the models presented below uses a different score formulation.
All my methods for estimating the translation parameters trans (u, v) share the
following general outline:
</bodyText>
<listItem confidence="0.9994216">
1. Initialize the score parameters to a first approximation, based only on the
co-occurrence counts.
2. Approximate the expected link counts links(u, v), as a function of the
score parameters and the co-occurrence counts.
3. Estimate trans (u, v), by normalizing the link counts as in Equation 19. If
less than .0001 of the trans (u, v) distribution changed from the previous
iteration, then stop.
4. Reestirnate the parameters score(u, v), as a function of the link counts
and the co-occurrence counts.
5. Repeat from Step 2.
</listItem>
<bodyText confidence="0.998904285714286">
Under certain conditions, a parameter estimation process of this sort is an instance of
the expectation-maximization (EM) algorithm (Dempster, Laird, and Rubin 1977). As
explained below, meeting these conditions is computationally too expensive for my
models.&apos; Therefore, I employ some approximations, which lack the EM algorithm&apos;s
convergence guarantee.
The maximum likelihood approach to estimating the unknown parameters is to
find the set of parameters 6 that maximize the probability of the training bitext (U, V).
</bodyText>
<equation confidence="0.659406">
(3 -= arg msx Pr(LI, VI 0) (20)
</equation>
<bodyText confidence="0.79168">
The probability of the bitext is a sum over the distribution A of possible assignments:
</bodyText>
<equation confidence="0.54967275">
Pr(U, V18) = E Pr(U,A, V10). (21)
AEA
9 For example, the expectation in Step 2 would need to be computed exactly, rather than merely
approximated.
</equation>
<page confidence="0.974815">
231
</page>
<note confidence="0.422037">
Computational Linguistics Volume 26, Number 2
</note>
<bodyText confidence="0.9986296">
The number of possible assignments grows exponentially with the size of aligned
text segments in the bitext. Due to the parameter interdependencies introduced by
the one-to-one assumption, we are unlikely to find a method for decomposing the
assignments into parameters that can be estimated independently of each other as in
Brown et al. [1993b, Equation 26]). Barring such a decomposition method, the MLE
approach is infeasible. This is why we must make do with approximations to the EM
algorithm.
In this situation, Brown et al. (1993b, 293) recommend &amp;quot;evaluating the expectations
using only a single, probable alignment.&amp;quot; The single most probable assignment Amax
is the maximum a posteriori (MAP) assignment:
</bodyText>
<figure confidence="0.544415571428571">
Amax — arglinea!4(Pr(U,A, Vie)
arg max Pr(1) • 1! 11 trans(ui, V])
AEA
(i,j)EA
[
arg imic log Pr(1) • 1! IT trans(ui,Vi)
(i,j)EA
arg max
AEA log[Pr(1) • 1!] + log trans(ui,vi)
(i,DEA
To simplify things further, let us assume that Pr(/) • 1! is constant, so that
Amax = arg max log trans(ui,vi).
AEA
(i,i)EA
</figure>
<bodyText confidence="0.999891625">
If we represent the bitext as a bipartite graph and weight the edges by log trans(u, v),
then the right-hand side of Equation 26 is an instance of the weighted maximum
matching problem and Amax is its solution. For a bipartite graph G = (V1 U V2, E),
with v = 1V1 U V21 and e = El, the lowest currently known upper bound on the
computational complexity of this problem is 0(ve + v2 log v) (Ahuja, Magnati, and
Orlin 1993, 500). Although this upper bound is polynomial, it is still too expensive
for typical bitexts.1° Subsection 5.1.2 describes a greedy approximation to the MAP
approximation.
</bodyText>
<subsectionHeader confidence="0.99887">
5.1 Method A: The Competitive Linking Algorithm
</subsectionHeader>
<bodyText confidence="0.988972">
5.1.1 Step 1: Initialization. Almost every translation model estimation algorithm ex-
ploits the well-known correlation between translation probabilities and co-occurrence
counts. Many algorithms also normalize the co-occurrence counts cooc(u, v) by the
marginal frequencies of u and v. However, these quantities account for only the three
shaded cells in Table 2. The statistical interdependence between two word types can
be estimated more robustly by considering the whole table. For example, Gale and
Church (1991, 154) suggest that &amp;quot;02, a x2-like statistic, seems to be a particularly
good choice because it makes good use of the off-diagonal cells&amp;quot; in the contingency
table.
</bodyText>
<page confidence="0.501007">
10 At least for my current very inefficient implementation.
</page>
<figure confidence="0.836387">
(24)
</figure>
<page confidence="0.872516">
232
</page>
<note confidence="0.82329">
Melamed Models of Translational Equivalence
</note>
<tableCaption confidence="0.977509">
Table 2
</tableCaption>
<table confidence="0.947267125">
A co-occurrence contingency table.
Total
cooc(., v)
cooc(., —.v)
cooc(., .)
cooc(u,.v) cooc(-11, v)
cooc(u, —.v) COOC(—V,
Total cooc(-u, -)
</table>
<bodyText confidence="0.996276666666667">
In informal experiments described elsewhere (Melamed 1995), I found that the
G2 statistic suggested by Dunning (1993) slightly outperforms 02. Let the cells of the
contingency table be named as follows:
</bodyText>
<equation confidence="0.972552166666667">
a
Now,
G2(u, v) = —21og B(ala + b,pi)B(cic + d,p2)
(27)
B(aia + b,p)B(cic + d,p)
nk
</equation>
<bodyText confidence="0.8986652">
where B(kin,p) = () pk(1 p)n-k are binomial probabilities. The statistic uses maximum
likelihood estimates for the probability parameters: p1 = bf P2 — c±cd&apos; P = a±ab±±cc-Fd&apos;
G2 is easy to compute because the binomial coefficients in the numerator and in the
denominator cancel each other out. All my methods initialize the parameters score(u,v)
to G2(u, v), except that any pairing with NULL is initialized to an infinitesimal value.
I have also found it useful to smooth the co-occurrence counts, e.g., using the Simple
Good-Turing smoothing method (Gale and Sampson 1995), before computing G2.
5.1.2 Step 2: Estimation of Link Counts. To further reduce the complexity of esti-
mating link counts, I employ the competitive linking algorithm, which is a greedy
approximation to the MAP approximation:
</bodyText>
<listItem confidence="0.992428">
1. Sort all the score(u,v) from highest to lowest.
2. For each score(u,v), in order:
(a) If u (resp., v) is NULL, consider all tokens of v (resp., u) in the
</listItem>
<bodyText confidence="0.984274363636364">
bitext linked to NULL. Otherwise, link all co-occurring token
pairs (u, v) in the bitext.
(D) The one-to-one assumption implies that linked words cannot be
linked again. Therefore, remove all linked word tokens from
their respective halves of the bitext.
The competitive linking algorithm can be viewed as a heuristic search for the most
likely assignment in the space of all possible assignments. The heuristic is that the
most likely assignments contain links that are individually the most likely. The search
proceeds by a process of elimination. In the first search iteration, all the assignments
that do not contain the most likely link are discarded. In the second iteration, all
the assignments that do not contain the second most likely link are discarded, and
</bodyText>
<page confidence="0.990429">
233
</page>
<note confidence="0.631576">
Computational Linguistics Volume 26, Number 2
</note>
<bodyText confidence="0.999237464285714">
so on until only one assignment remains.&amp;quot; The algorithm greedily selects the most
likely links first, and then selects less likely links only if they don&apos;t conflict with
previous selections. The probability of a link being rejected increases with the number
of links that are selected before it, and thus decreases with the link&apos;s score. In this
problem domain, the competitive linking algorithm usually finds one of the most
likely assignments, as I will show in Section 6. Under an appropriate hashing scheme,
the expected running time of the competitive linking algorithm is linear in the size of
the input bitext.
The competitive linking algorithm and its one-to-one assumption are potent weap-
ons against the ever-present sparse data problem. They enable accurate estimation
of translational distributions even for words that occur only once, as long as the
surrounding words are more frequent. In most translation models, link scores are
correlated with co-occurrence frequency. So, links between tokens u and v for which
score(u,v) is highest are the ones for which there is the most evidence, and thus also the
ones that are easiest to predict correctly. Winner-take-all link assignment methods, such
as the competitive linking algorithm, can prevent links based on indirect associations
(see Section 4.2), thereby leveraging their accuracy on the more confident links to
raise the accuracy of the less confident links. For example, suppose that u1 and u2
co-occur with v1 and v2 in the training data, and the model estimates score(ui,vi) =
.05, score (u1, v2) = .02, and score(u2, v2) = .01. According to the one-to-one assumption,
(ui, v2) is an indirect association and the correct translation of 02 is u2. To the extent that
the one-to-one assumption is valid, it reduces the probability of spurious links for the
rarer words. The more incorrect candidate translations can be eliminated for a given
rare word, the more likely the correct translation is to be found. So, the probability of
a correct match for a rare word is proportional to the fraction of words around it that
can be linked with higher confidence. This fraction is largely determined by two bitext
properties: the distribution of word frequencies, and the distribution of co-occurrence
counts. Melamed (to appear) explores these properties in greater depth.
</bodyText>
<subsubsectionHeader confidence="0.940757">
5.1.3 Step 3: Reestimation of the Model Parameters. Method A reestimates the score
</subsubsectionHeader>
<bodyText confidence="0.9993665">
parameters as the logarithm of the trans parameters. The competitive linking algorithm
only cares about the relative magnitudes of the various score(u, v). However, Equation 26
is a sum rather than a product, so I scale the trans parameters logarithmically, to be
consistent with its probabilistic interpretation:
</bodyText>
<equation confidence="0.996586">
scoreA(u,v) = log trans(u,v) (28)
</equation>
<subsectionHeader confidence="0.99987">
5.2 Method B: Improved Estimation Using an Explicit Noise Model
</subsectionHeader>
<bodyText confidence="0.999987333333333">
Yarowsky (1993, 271) has shown that &amp;quot;for several definitions of sense and collocation,
an ambiguous word has only one sense in a given collocation with a probability of
90-99%.&amp;quot; In other words, a single contextual clue can be a highly reliable indicator of
a word&apos;s sense. One of the definitions of &amp;quot;sense&amp;quot; studied by Yarowsky was a word
token&apos;s translation in the other half of a bitext. For example, the English word sentence
may be considered to have two senses, corresponding to its French translations peine
(judicial sentence) and phrase (grammatical sentence). If a token of sentence occurs in
the vicinity of a word like jury or prison, then it is far more likely to be translated
as peine than as phrase. &amp;quot;In the vicinity of&amp;quot; is one kind of collocation. Co-occurrence
</bodyText>
<footnote confidence="0.968852333333333">
11 The competitive linking algorithm can be generalized to stop searching before the number of possible
assignments is reduced to one, at which point the link counts can be computed as probabilistically
weighted averages over the remaining assignments. I use this method to resolve ties.
</footnote>
<page confidence="0.96642">
234
</page>
<equation confidence="0.93309">
links(u,v) / cooc(u, v)
</equation>
<figureCaption confidence="0.591924">
Figure 2
</figureCaption>
<bodyText confidence="0.9633871">
The ratio links(u, v) I cooc (u, v), for several values of cooc(u, v).
in bitext space is another kind of collocation. If each word&apos;s translation is treated as
a sense tag (Resnik and Yarowsky 1997), then &amp;quot;translational&amp;quot; collocations have the
unique property that the collocate and the word sense are one and the same!
Method B exploits this property under the hypothesis that &amp;quot;one sense per collo-
cation&amp;quot; holds for translational collocations. This hypothesis implies that if u and v
are possible mutual translations, and a token u co-occurs with a token v in the bitext,
then with very high probability the pair (u, v) was generated from the same concept
and should be linked. To test this hypothesis, I ran one iteration of Method A on
300,000 aligned sentence pairs from the Canadian Hansards bitext. I then plotted the
</bodyText>
<equation confidence="0.8828366">
ratio links(u&apos;v) for several values of cooc(u, v) in Figure 2. The curves show that the ratio
cooc(u,v)
links(u,v)
tends to be either very high or very low. This bimodality is not an artifact
cooc(u,v)
</equation>
<bodyText confidence="0.9986622">
of the competitive linking process, because in the first iteration, linking decisions are
based only on the initial similarity metric.
Information about how often words co-occur without being linked can be used to
bias the estimation of translation model parameters. The smaller the ratio icionokcsuu&amp;quot;vv?, the
more likely it is that u and v are not mutual translations, and that links posited between
tokens of u and v are noise. The bias can be implemented via auxiliary parameters
that model the curve illustrated in Figure 2. The competitive linking algorithm creates
all the links of a given type independently of each other.&apos; So, the distribution of
the number links (u, v) of links connecting word types u and v can be modeled by a
binomial distribution with parameters cooc(u,v) and p(u, v). p(u, v) is the probability
</bodyText>
<footnote confidence="0.814346">
12 Except for the case when multiple tokens of the same word type occur near each other, which I hereby
sweep under the carpet.
</footnote>
<figure confidence="0.995677352941176">
1
I I I I
0.1 0.2 0.3 0.4 0.5
1
0.8
1
t
0.6 0.7
Melamed
700
600 -
400
45
43
.0 300
E
=
c
200
100
/cooc(u,v) = 8
cooc(u,v) = 9
cooc(u,v) = 12
cooc(u,v) = 16
Models of Translational Equivalence
-
i
0.9
1
-
-
_
_
-
</figure>
<page confidence="0.766861">
235
</page>
<table confidence="0.362481">
Computational Linguistics Volume 26, Number 2
</table>
<tableCaption confidence="0.95721">
Table 3
Variables used to describe Method B.
</tableCaption>
<table confidence="0.324303714285714">
the number of times that u and v are hypothesized to
co-occur as mutual translations
probability of k being generated from a binomial distribution
with parameters n and p
probability of a link given mutual translations
probability of a link given not mutual translations
probability of a link
</table>
<equation confidence="0.943312333333333">
T = probability of mutual translations
K = total number of links in the bitext
N = total number of co-occurrences in the bitext
</equation>
<bodyText confidence="0.9995068">
that u and v will be linked when they co-occur. There is never enough data to robustly
estimate each p parameter separately. Instead, I shall model all the p&apos;s with just two
parameters. For u and v that are mutual translations, p(u, v) will average to a relatively
high probability, which I will call A. for u and v that are not mutual translations,
p(u, v) will average to a relatively low probability, which I will call A. . A+ and A-
</bodyText>
<equation confidence="0.920701">
links(u,v)
</equation>
<bodyText confidence="0.99662775">
correspond to the two peaks of the distribution , which is illustrated in Figure 2.
The two parameters can also be interpreted as the rates of true and false positives. If
the translation in the bitext is consistent and the translation model is accurate, then
A+ will be close to one and A- will be close to zero.
To find the most likely values of the auxiliary parameters A+ and A-, I adopt the
standard method of maximum likelihood estimation, and find the values that maxi-
mize the probability of the link frequency distributions, under the usual independence
assumptions:
</bodyText>
<equation confidence="0.7350745">
Pr (linkslmodel) = 11Pr (links (u, v)lcooc(u, v), A+, A-) (29)
u,v
</equation>
<bodyText confidence="0.996498714285714">
Table 3 summarizes the variables involved in this auxiliary estimation process.
The factors on the right-hand side of Equation 29 can be written explicitly with
the help of a mixture coefficient. Let T be the probability that an arbitrary co-occurring
pair of word types are mutual translations. Let B (kIn , p) denote the probability that k
links are observed out of n co-occurrences, where k has a binomial distribution with
parameters n and p. Then the probability that word types u and v will be linked
links(u, v) times out of cooc(u, v) co-occurrences is a mixture of two binomials:
</bodyText>
<equation confidence="0.876036">
Pr (links (u, v)lcooc(u, v), A+, A-) = B(links(u, v)lcooc(u, v), A+)
+ (1- y)B (links (u, v)lcooc(u, v), ) . (30)
</equation>
<bodyText confidence="0.9995884">
One more variable allows us to express T in terms of A+ and A- : Let A be the
probability that an arbitrary co-occuring pair of word tokens will be linked, regardless
of whether they are mutual translations. Since T is constant over all word types, it
also represents the probability that an arbitrary co-occurring pair of word tokens are
mutual translations. Therefore,
</bodyText>
<figure confidence="0.948114913043478">
A = TA+ + (1 - T)A (31)
A can also be estimated empirically. Let K be the total number of links in the bitext
links(u, v)
B(kin, p) =
A+ =
A- =
A =
236
Melamed Models of Translational Equivalence
06 0.65
0.7 07S
• 0.8 0.85
0
0.002
0.004
0.006
0.008
0.01
log Pr(data I model) in millions
-1.2 -
-1.4
-1.6
-1.8
</figure>
<figureCaption confidence="0.984378">
Figure 3
</figureCaption>
<bodyText confidence="0.968847">
Pr(linkslmodel), as given in Equation 29, has only one global maximum in the region of
interest, where 1 &gt; A+ &gt; )&gt; A- &gt; 0.
and let N be the total number of word token pair co-occurrences:
</bodyText>
<equation confidence="0.968320333333333">
K= &gt; links(u,v), (32)
U,V
N= &gt; cooc(u,v). (33)
U,V
By definition,
A = K/N. (34)
</equation>
<bodyText confidence="0.930662">
Equating the right-hand sides of Equations 31 and 34 and rearranging the terms, we
get:
</bodyText>
<figure confidence="0.5183866">
-
K/N - A-
T
At - A-
(35)
</figure>
<figureCaption confidence="0.5238545">
Since 7 is now a function of A+ and A-, only the latter two variables represent degrees
of freedom in the model.
</figureCaption>
<bodyText confidence="0.9999680625">
In the preceding equations, either u or v can be NULL. However, the number
of times that a word co-occurs with NULL is not an observable feature of bitexts.
To make sense of co-occurrences with NULL, we can view co-occurrences as potential
links and cooc(u, v) as the maximum number of times that tokens of u and v might
be linked. From this point of view, cooc(u, NULL) should be set to the unigram fre-
quency of u, since each token of u represents one potential link to NULL. Similarly for
cooc( NULL, v). These co-occurrence counts should be summed together with all the
others in Equation 33.
The probability function expressed by Equations 29 and 30 may have many local
maxima. In practice, these local maxima are like pebbles on a mountain, invisible at
low resolution. I computed Equation 29 over various combinations of A+ and A- after
one iteration of Method A over 300,000 aligned sentence pairs from the Canadian
Hansard bitext. Figure 3 illustrates that the region of interest in the parameter space,
where 1 &gt; A+ &gt; A &gt; A- &gt; 0, has only one dominant global maximum. This global
maximum can be found by standard hill-climbing methods, as long as the step size is
large enough to avoid getting stuck on the pebbles.
</bodyText>
<page confidence="0.987395">
237
</page>
<note confidence="0.639993">
Computational Linguistics Volume 26, Number 2
</note>
<bodyText confidence="0.99979">
Given estimates for A+ and A-, we can compute B(links(u, v)lcooc(u, v), A+) and
B(links(u, v)icooc(u, v), A-) for each occurring combination of links and cooc values.
These are the probabilities that links (u, v) links were generated out of cooc(u, v) possible
links by a process that generates correct links and by a process that generates incorrect
links, respectively. The ratio of these probabilities is the likelihood ratio in favor of the
types u and v being possible mutual translations, for all u and v:
</bodyText>
<equation confidence="0.949464">
B(links(u, v) cooc(u, v), A+)
score B (u, v) = log B (links (u, v)lcooc(u, v), A- ) (36)
</equation>
<bodyText confidence="0.99952525">
Method B differs from Method A only in its redefinition of the score function in
Equation 36. The auxiliary parameters A+ and A- and the noise model that they
represent can be employed the same way in translation models that are not based on
the one-to-one assumption.
</bodyText>
<subsectionHeader confidence="0.997192">
5.3 Method C: Improved Estimation Using Preexisting Word Classes
</subsectionHeader>
<bodyText confidence="0.904356055555556">
In Method B, the estimation of the auxiliary parameters A+ and A- depends only on
the overall distribution of co-occurrence counts and link frequencies. All word pairs
that co-occur the same number of times and are linked the same number of times are
assigned the same score. More accurate models can be induced by taking into account
various features of the linked tokens. For example, frequent words are translated less
consistently than rare words (Catizone, Russell, and Warwick 1989). To account for
these differences, we can estimate separate values of A+ and A- for different ranges of
cooc(u, v). Similarly, the auxiliary parameters can be conditioned on the linked parts
of speech. A kind of word order correlation bias can be effected by conditioning the
auxiliary parameters on the relative positions of linked word tokens in their respective
texts. Just as easily, we can model link types that coincide with entries in an on-line
bilingual dictionary separately from those that do not (cf. Brown et al. 1993). When
the auxiliary parameters are conditioned on different link classes, their optimization
is carried out separately for each class:
B(links (u, v) Icooc(u, v), A-zF ) (37)
scorec (u, viz = class (u, v)) = log
B (links (u, v)lcooc(u, v), )
Section 6.1.1 describes the link classes used in the experiments below.
</bodyText>
<sectionHeader confidence="0.999122" genericHeader="evaluation">
6. Evaluation
</sectionHeader>
<subsectionHeader confidence="0.995808">
6.1 Evaluation at the Token Level
</subsectionHeader>
<bodyText confidence="0.999951416666667">
This section compares translation model estimation methods A, B, and C to each other
and to Brown et al.&apos;s (1993b) Model 1. To reiterate, Model 1 is based on co-occurrence
information only; Method A is based on the one-to-one assumption; Method B adds the
&amp;quot;one sense per collocation&amp;quot; hypothesis to Method A; Method C conditions the auxiliary
parameters of Method B on various word classes. Whereas Methods A and B and
Model 1 were fully specified in Section 4.3.1 and Section 5, the latter section described
a variety of features on which Method C might classify links. For the purposes of
the experiments described in this article, Method C employed the simple classification
in Table 4 for both languages in the bitext. All classification was performed by table
lookup; no context-aware part-of-speech tagger was used. In particular, words that
were ambiguous between open classes and closed classes were always deemed to be in
the closed class. The only language-specific knowledge involved in this classification
</bodyText>
<page confidence="0.99827">
238
</page>
<note confidence="0.964175">
Melamed Models of Translational Equivalence
</note>
<tableCaption confidence="0.784175666666667">
Table 4
Word classes used by Method C for the experiments described in this article.
Link classes were constructed by taking the cross-product of the word classes.
</tableCaption>
<table confidence="0.90577925">
Class Code Description
EOS End-Of-Sentence punctuation
EOP End-Of-Phrase punctuation, such as commas and colons
SCM Subordinate Clause Markers, such as &amp;quot; and (
SYM Symbols, such as - and *
NU the NULL word, in a class by itself
C Content words: nouns, adjectives, adverbs, non-auxiliary verbs
F all other words, i.e., function words
</table>
<bodyText confidence="0.991777972222222">
method is the list of function words in class F. Certainly, more sophisticated word
classification methods could produce better models, but even the simple classification
in Table 4 should suffice to demonstrate the method&apos;s potential.
6.1.1 Experiment 1. Until now, translation models have been evaluated either sub-
jectively (e.g. White and O&apos;Connell 1993) or using relative metrics, such as perplex-
ity with respect to other models (Brown et al. 1993b). Objective and more accurate
tests can be carried out using a &amp;quot;gold standard.&amp;quot; I hired bilingual annotators to link
roughly 16,000 corresponding words between on-line versions of the Bible in French
and English. This bitext was selected to facilitate widespread use and standardiza-
tion (see Melamed [1998c] for details). The entire Bible bitext comprised 29,614 verse
pairs, of which 250 verse pairs were hand-linked using a specially developed anno-
tation tool. The annotation style guide (Melamed 1998b) was based on the intuitions
of the annotators, so it was not biased towards any particular translation model. The
annotation was replicated five times by seven different annotators.
Each of the four methods was used to estimate a word-to-word translation model
from the 29,614 verse pairs in the Bible bitext. All methods were deemed to have
converged when less than .0001 of the translational probability distribution changed
from one iteration to the next. The links assigned by each of methods A, B, and C in the
last iteration were normalized into joint probability distributions using Equation 19. I
shall refer to these joint distributions as Model A, Model B, and Model C, respectively.
Each of the joint probability distributions was further normalized into two conditional
probability distributions, one in each direction. Since Model 1 is inherently directional,
its conditional probability distributions were estimated separately in each direction,
instead of being derived from a joint distribution.
The four models&apos; predictions were compared to the gold standard annotations.
Each model guessed one translation (either stochastically or deterministically, depend-
ing on the task) for each word on one side of the gold standard bitext. Therefore,
precision = recall here, and I shall refer to the results simply as &amp;quot;percent correct.&amp;quot; The
accuracy of each model was averaged over the two directions of translation: English to
French and French to English. The five-fold replication of annotations in the test data
enabled computation of the statistical significance of the differences in model accuracy.
The statistical significance of all results in this section was measured at the a = .05
level, using the Wilcoxon signed ranks test. Although the models were evaluated on
part of the same bitext on which they were trained, the evaluations were with respect
to the translational equivalence relation hidden in this bitext, not with respect to any
of the bitext&apos;s visible features. Such testing on training data is standard practice for
</bodyText>
<page confidence="0.994123">
239
</page>
<note confidence="0.642733">
Computational Linguistics Volume 26, Number 2
</note>
<bodyText confidence="0.99983066">
unsupervised learning algorithms, where the objective is to compare several methods.
Of course, performance would degrade on previously unseen data.
In addition to the different translation models, there were two other independent
variables in the experiment: method of translation and whether function words were
included. Some applications, such as query translation for CUR, don&apos;t care about func-
tion words. To get a sense of the relative effectiveness of the different translation model
estimation methods when function words are taken out of the equation, I removed
from the gold standard all link tokens where one or both of the linked words were
closed-class words. Then, I removed all closed-class words (including nonalphabetic
symbols) from the models and renormalized the conditional probabilities.
The method of translation was either single-best or whole distribution. Single-
best translation is the kind that somebody might use to get the gist of a foreign-
language document. The input to the task was one side of the gold standard bitext.
The output was the model&apos;s single best guess about the translation of each word in
the input, together with the input word. In other words, each model produced link
tokens consisting of input words and their translations. For some applications, it is
insufficient to guess only the single most likely translation of each word in the input.
The model is expected to output the whole distribution of possible translations for
each input word. This distribution is then combined with other distributions that are
relevant to the application. For example, for cross-language information retrieval, the
translational distribution can be combined with the distribution of term frequencies.
For statistical machine translation, the translational distribution can be decoded with
a source language model (Brown et al. 1988; Al-Onaizan et al. 1999). To predict how
the different models might perform in such applications, the whole distribution task
was to generate a whole set of links from each input word, weighted according to
the probability assigned by the model to each of the input word&apos;s translations. Each
model was tested on this task with and without function words.
The mean results are plotted in Figures 4 and 5 with 95% confidence intervals.
All four graphs in these figures are on the same scale to facilitate comparison. On
both tasks involving the entire vocabulary, each of the biases presented in this article
improves the efficiency of modeling the available training data. When closed-class
words were ignored, Model 1 performed better than Method A, because open-class
words are more likely to violate the one-to-one assumption. However, the explicit noise
model in Methods B and C boosted their scores significantly higher than Model 1 and
Method A. Method B was better than Method C at choosing the single best open-class
links, and the situation was reversed for the whole distribution of open-class links.
However, the differences in performance between these two methods were tiny on
the open-class tasks, because they left only two classes for Method C to distinguish:
content words and NULLS. Most of the scores on the whole distribution task were lower
than their counterparts on the single-best translation task, because it is more difficult
for any statistical method to correctly model the less common translations. The &amp;quot;best&amp;quot;
translations are usually the most common.
6.1.2 Experiment 2. To study how the benefits of the various biases vary with training
corpus size, I evaluated Models A, B, C, and 1 on the whole distribution translation
task, after training them on three different-size subsets of the Bible bitext. The first
subset consisted of only the 250 verse pairs in the gold standard. The second subset
included these 250 plus another random sample of 2,250 for a total of 2,500, an order
of magnitude larger than the first subset. The third subset contained all 29,614 verse
pairs in the Bible bitext, roughly an order of magnitude larger than the second subset.
All models were compared to the five gold standard annotations, and the scores were
</bodyText>
<page confidence="0.995728">
240
</page>
<figureCaption confidence="0.901521666666667">
Figure 4
Comparison of model performance on single-best translation task. (a) All links; (b) open-class
links only.
</figureCaption>
<figure confidence="0.979841666666667">
Melamed Models of Translational Equivalence
0.5
0.45
0.4
0.2
0.15
Model 1
Model A Model B Model C
Model 1 Model A Model B Model C
percent correct
0.45
0.25
0.35
0.15
0.4
0.5
0.2
0.3
241
Computational Linguistics Volume 26, Number 2
(a)
percent correct
0.5
0.45
0.4
0.35
0.3
0.25
0.2
0.15
Model 1 Model A Model B Model C
(b)
Model 1 Model A Model B Model C
</figure>
<figureCaption confidence="0.989621666666667">
Figure 5
Comparison of model performance on whole distribution task. (a) All links; (b) open-class
links only.
</figureCaption>
<figure confidence="0.987259466666667">
percent correct
0.5
0.45
0.4
0.35
0.3
0.25
0.2
0.15
242
Melamed
0.4
0.35
0.3
Models of Translational Equivalence
------
-x-- __ - -----------------
2.2 0.25 -
0
0.2
U)
E-2
a&gt; 0.15-
CL
Model C
Model B --
Model A
0.05 Modell 0 -
2500 29614
number of training verse pairs (on log scale)
</figure>
<figureCaption confidence="0.939224">
Figure 6
</figureCaption>
<subsectionHeader confidence="0.587089">
Effects of training set size on model accuracy on the whole distribution task.
</subsectionHeader>
<bodyText confidence="0.98649052">
averaged over the two directions of translation, as before. Again, because the total
probability assigned to all translations for each source word was one, precision =-
recall = percent correct on this task. The mean scores over the five gold standard
annotations are graphed in Figure 6, where the right edge of the figure corresponds to
the means of Figure 5(a). The figure supports the hypothesis in Melamed (to appear,
Chapter 7) that the biases presented in this article are even more valuable when the
training data are more sparse. The one-to-one assumption is useful, even though it
forces us to use a greedy approximation to maximum likelihood. In relative terms,
the advantage of the one-to-one assumption is much more pronounced on smaller
training sets. For example, Model A is 102% more accurate than Model 1 when trained
on only 250 verse pairs. The explicit noise model buys a considerable gain in accuracy
across all sizes of training data, as do the link classes of Model C. In concert, when
trained and tested only on the gold standard test set, the three biases outperformed
Model 1 by up to 125%. This difference is even more significant given the absolute
performance ceiling of 82% established by the interannotator agreement rates on the
gold standard.
6.2 Evaluation at the Type Level
An important application of statistical translation models is to help lexicographers
compile bilingual dictionaries. Dictionaries are written to answer the question, &amp;quot;What
are the possible translations of X?&amp;quot; This is a question about link types, rather than
about link tokens.
Evaluation by link type is a thorny issue. Human judges often disagree about the
degree to which context should play a role in judgments of translational equivalence.
For example, the Harper-Collins French Dictionary (Cousin et al. 1990) gives the following
French translations for English appoint: nommer, engager, fixer, designer. Likewise, most
</bodyText>
<figure confidence="0.937478">
0.1
0
250
</figure>
<page confidence="0.636875">
243
</page>
<figure confidence="0.988449">
Volume 26, Number 2
30000 60000 90000
entry number
</figure>
<figureCaption confidence="0.998928">
Figure 7
</figureCaption>
<bodyText confidence="0.97926325">
Distribution of link type scores. The long plateaus correspond to the most common
combinations of links(u&apos;v) • 1/1,2/2, and 3/3.
cooc(u,v) •
lay judges would not consider instituer a correct French translation of appoint. In actual
translations, however, when the object of the verb is commission, task force, panel, etc.,
English appoint is usually translated into French as instituer. To account for this kind of
context-dependent translational equivalence, link types must be evaluated with respect
to the bitext whence they were induced.
I performed a post hoc evaluation of the link types produced by an earlier version
of Method B (Melamed 1996b). The bitext used for this evaluation was the same aligned
Hansards bitext used by Gale and Church (1991), except that I used only 300,000
aligned segment pairs to save time. The bitext was automatically pretokenized to
delimit punctuation, English possessive pronouns, and French elisions. Morphological
variants in both halves of the bitext were stemmed to a canonical form.
The link types assigned by the converged model were sorted by the scores in
Equation 36. Figure 7 shows the distribution of these scores on a log scale. The log
scale helps to illustrate the plateaus in the curve. The longest plateau represents the
set of word pairs that were linked once out of one co-occurrence (1/1) in the bitext.
All these word pairs were equally likely to be correct. The second-longest plateau
resulted from word pairs that were linked twice out of two co-occurrences (2/2) and
the third longest plateau is from word pairs that were linked three times out of three
co-occurrences (3/3). As usual, the entries with higher scores were more likely to be
correct. By discarding entries with lower scores, coverage could be traded for accuracy.
This trade-off was measured at three points, representing cutoffs at the end of each of
the three longest plateaus.
The traditional method of measuring coverage requires knowledge of the correct
link types, which is impossible to determine without a gold standard. An approximate
coverage measure can be based on the number of different words in the corpus. For
</bodyText>
<figure confidence="0.9925591">
Computational Linguistics
100000
10000
log(score) on log scale
1 000
100
10
0.1
3/3 2/2
1/1
</figure>
<page confidence="0.996253">
244
</page>
<note confidence="0.972531">
Melamed Models of Translational Equivalence
</note>
<tableCaption confidence="0.8552725">
Table 5
Lexicon coverage at three different minimum score thresholds. The bitext
contained 41,028 different English words and 36,314 different French
words, for a total of 77,342.
</tableCaption>
<table confidence="0.993512666666667">
Total English French
Cutoff Minimum Lexicon Words Words
Plateau Score Entries Represented % Represented
3/3 28 32,274 14,299 35 13,409 37
2/2 18 43,075 18,533 45 17,133 47
1/1 9 88,633 36,371 89 33,017 91
</table>
<bodyText confidence="0.999226763157894">
lexicons extracted from corpora, perfect coverage implies at least one entry containing
each word in the corpus. One-sided variants, which consider only source words, have
also been used (Gale and Church 1991). Table 5 shows both the marginal (one-sided)
and the combined coverage at each of the three cutoff points. It also shows the absolute
number of (non-NULL) entries in each of the three lexicons. Of course, the size of
automatically induced lexicons depends on the size of the training bitext. Table 5
shows that, given a sufficiently large bitext, the method can automatically construct
translation lexicons with as many entries as published bilingual dictionaries.
The next task was to measure accuracy. It would have taken too long to evaluate
every lexicon entry manually. Instead, I took five random samples (with replacement)
of 100 entries each from each of the three lexicons. Each of the samples was first com-
pared to a translation lexicon extracted from a machine-readable bilingual dictionary
(Cousin et al. 1991). All the entries in the sample that appeared in the dictionary were
assumed to be correct. I checked the remaining entries in all the samples by hand. To
account for context-dependent translational equivalence, I evaluated the accuracy of
the translation lexicons in the context of the bitext whence they were extracted, using
a simple bilingual concordancer. A lexicon entry (u,v) was considered correct if u and
v ever appeared as direct translations of each other in an aligned segment pair. That
is, a link type was considered correct if any of its tokens were correct.
Direct translations come in different flavors. Most entries that I checked by hand
were of the plain vanilla variety that you might find in a bilingual dictionary (entry
type V). However, a significant number of words translated into a different part of
speech (entry type P). For instance, in the entry (protection, protégé), the English word
is a noun but the French word is an adjective. This entry appeared because to have
protection is often translated as etre protégé (&apos;to be protected&apos;) in the bitext. The entry
will never occur in a bilingual dictionary, but users of translation lexicons, be they
human or machine, will want to know that translations often happen this way.
The evaluation of translation models at the word type level is complicated by the
possibility of phrasal translations, such as immediatement 4-+ right away. All the methods
being evaluated here produce models of translational equivalence between individual
words only. How can we decide whether a single-word translation &amp;quot;matches&amp;quot; a phrasal
translation? The answer lies in the observation that corpus-based lexicography usually
involves a lexicographer. Bilingual lexicographers can work with bilingual concordanc-
ing software that can point them to instances of any link type induced from a bitext
and display these instances sorted by their contexts (e.g. Simard, Foster, and Perrault
1993). Given an incomplete link type, the lexicographer can usually reconstruct the
complete link type from the contexts in the concordance. For example, if the model
proposes an equivalence between irnmediatement and right, a bilingual concordance
</bodyText>
<page confidence="0.996341">
245
</page>
<note confidence="0.600974">
Computational Linguistics Volume 26, Number 2
</note>
<tableCaption confidence="0.985682">
Table 6
</tableCaption>
<table confidence="0.9906165">
Distribution of different types of correct lexicon entries at varying levels of
coverage (mean ± standard deviation).
Cutoff Coverage % Type V % Type P % Type I Total % Accuracy
3/3 36% 89 ± 2.2 3.4 ± 0.5 7.6 ± 3.2 99.2 ± 0.8
2/2 46% 81 + 3.0 8.0 ± 2.1 9.8 ± 1.8 99.0 ± 1.4
1/1 90% 82 + 2.5 4.4 ± 0.5 6.0 + 1.9 92.8 ± 1.1
</table>
<bodyText confidence="0.9981031">
can show the lexicographer that the model was really trying to capture the equiva-
lence between immediatement and right away or between immediatement and right now.
I counted incomplete entries in a third category (entry type I). Whether links in this
category should be considered correct depends on the application.
Table 6 shows the distribution of correct lexicon entries among the types V. P and I.
Figure 8 graphs the accuracy of the method against coverage, with 95% confidence
intervals. The upper curve represents accuracy when incomplete links are considered
correct, and the lower when they are considered incorrect. On the former metric, the
method can generate translation lexicons with accuracy and coverage both exceeding
90%, as well as dictionary-size translation lexicons that are over 99% correct.
</bodyText>
<sectionHeader confidence="0.906862" genericHeader="conclusions">
7. Conclusion
</sectionHeader>
<bodyText confidence="0.984248333333333">
There are many ways to model translational equivalence and many ways to estimate
translation models. &amp;quot;The mathematics of statistical machine translation&amp;quot; proposed by
Brown et al. (1993b) are just one kind of mathematics for one kind of statistical trans-
</bodyText>
<figureCaption confidence="0.91148">
Figure 8
</figureCaption>
<figure confidence="0.9666806875">
Translation lexicon accuracy with 95% confidence intervals at varying levels of coverage.
(99.2%)
99.0%)
incomplete = correct
100
98
96
_
-
&gt;,
o94
-
LT_
=
0 92
0 - (91.6%)
as
_
88
86
.1(89:2%)
------______
incomplete = incorrect
(92.8%)
(86.8%)
..,1,:. 90
0
i
i
36 46
(3/0 coverage
84
</figure>
<page confidence="0.9873835">
90
246
</page>
<note confidence="0.944177">
Melamed Models of Translational Equivalence
</note>
<bodyText confidence="0.999860857142857">
lation. In this article, I have proposed and evaluated new kinds of translation model
biases, alternative parameter estimation strategies, and techniques for exploiting pre-
existing knowledge that may be available about particular languages and language
pairs. On a variety of evaluation metrics, each infusion of knowledge about the prob-
lem domain resulted in better translation models.
Each innovation presented here opens the way for more research. Model biases can
be mixed and matched with each other, with previously published biases like the word
order correlation bias, and with other biases yet to be invented. The competitive linking
algorithm can be generalized in various ways. New kinds of preexisting knowledge
can be exploited to improve accuracy for particular language pairs or even just for
particular bitexts. It is difficult to say where the greatest advances will come from. Yet,
one thing is clear from our current vantage point: Research on empirical methods for
modeling translational equivalence has not run out of steam, as some have claimed,
but has only just begun.
</bodyText>
<sectionHeader confidence="0.992322" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9942768">
Much of this research was performed at the
Department of Computer and Information
Science at the University of Pennsylvania,
where it was supported by an equipment
grant from Sun MicroSystems Laboratories
and by ARPA Contract
#N66001-94C-6043. Many thanks to my
former colleagues at UPenn and to the
anonymous reviewers for their insightful
suggestions for improvement.
</bodyText>
<sectionHeader confidence="0.992001" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998701028169014">
Abeille, Anne, Yves Schabes, and Aravind
K. Joshi. 1990. Using lexicalized tree
adjoining grammars for machine
translation. In Proceedings of the 13th
International Conference on Computational
Linguistics. Helsinki, Finland.
Ahuja, Ravindra K., Thomas L. Magnati,
and James B. Orlin. 1993. Network Flows:
Theory, Algorithms, and Applications.
Prentice Hall, Englewood Cliffs, NJ.
Al-Onaizan, Yaser, Jan Curin, Michael Jahr,
Kevin Knight, John Lafferty, I. Dan
Melamed, Franz J. Och, David Purdy,
Noah A. Smith, and David Yarowsky.
1999. Statistical machine translation. CLSP
Technical Report. Baltimore, MD.
Available at www.clsp.jhu.edu/ws99/
projects/mt/final_report/mt-final-
report.ps
Brousseau, Julie, Caroline Drouin, George
Foster, Pierre Isabelle, Roland Kuhn, Yves
Normandin, and Pierre Plamondon. 1995.
French speech recognition in an automatic
dictation system for translators: The
TransTalk project. In Proceedings of
EuroSpeech&apos;95, pages 193-196, Madrid,
Spain.
Brown, Peter F., John Cocke, Stephen A.
Della Pietra, Vincent J. Della Pietra,
Fredrick Jelinek, Robert L. Mercer, and
Paul Roossin. 1988. A statistical approach
to language translation. In Proceedings of
the 12th International Conference on
Computational Linguistics, pages 71-76,
Budapest, Hungary.
Brown, Peter F., Stephen A. Della Pietra,
Vincent J. Della Pietra, Meredith J.
Goldsmith, Jan Hajic, Robert L. Mercer
and Surya Mohanty. 1993a. But
dictionaries are data too. In Proceedings of
the ARPA HLT Workshop, pages 202-205,
Princeton, NJ.
Brown, Peter F., Stephen A. Della Pietra,
Vincent J. Della Pietra, and Robert L.
Mercer. 1993b. The mathematics of
statistical machine translation: Parameter
estimation. Computational Linguistics
19(2):263-311.
Buckley, Chris. 1993. The importance of
proper weighting methods. In Proceedings
of the DARPA Workshop on Human Language
Technology, pages 349-352, Princeton, NJ.
Candito, Marie-Helene. 1998. Building
parallel LTAG for French and Italian. In
COLING-ACL &apos;98: 36 Annual Meeting of the
Association for Computational Linguistics and
17th International Conference on
Computational Linguistics, pages 211-217,
Montreal, Canada.
Catizone, Roberta, Graham Russell, and
Susan Warwick. 1989. Deriving
translation data from bilingual texts. In
Proceedings of the First International Lexical
Acquisition Workshop. Detroit, MI.
Church, Kenneth W., and Eduard H. Hovy.
1993. Good applications for crummy
machine translation. Machine Translation 8.
Cousin, Pierre-Henri, Lorna Sinclair,
Jean-Francois Allain, and Catherine E.
Love. 1990. The Harper Collins French
Dictionary. Harper Collins Publishers,
</reference>
<page confidence="0.989703">
247
</page>
<note confidence="0.688735">
Computational Linguistics Volume 26, Number 2
</note>
<reference confidence="0.999242663934426">
New York, NY.
Cousin, Pierre-Henri, Lorna Sinclair,
Jean-Francois Allain, and Catherine E.
Love. 1991. The Collins Paperback French
Dictionary. Harper Collins Publishers,
Glasgow.
Dagan, Ido, Kenneth W. Church, and
William A. Gale. 1993. Robust word
alignment for machine aided translation.
In Proceedings of the Workshop on Very Large
Corpora: Academic and Industrial
Perspectives, pages 1-8, Columbus, OH.
Daille, Beatrice, Eric Gaussier, and
Jean-Marc Lange. 1994. Towards
automatic extraction of monolingual and
bilingual terminology. Proceedings of the
15th International Conference on
Computational Linguistics, pages 515-521,
Kyoto, Japan.
Deming, W. Edwards, and Frederick F.
Stephan. 1940. On a least squares
adjustment of a sampled frequency table
when the expected marginal totals are
known. The Annals of Mathematical
Statistics, 11:427 444.
Dempster, Arthur P., N. M. Laird, and
Donald B. Rubin. 1977. Maximum
likelihood from incomplete data via the
EM algorithm. Journal of the Royal
Statistical Society, 39(B):1-38.
Dorr, Bonnie J. 1992. The use of lexical
semantics in interlingual machine
translation. Machine Translation,
7(3):135-193.
Dunning, Ted. 1993. Accurate methods for
the statistics of surprise and coincidence.
Computational Linguistics 19(1):61-74.
Fellbaum, Christiane, editor. 1998. WordNet:
An Electronic Lexical Database. MIT Press.
Foster, George, Pierre Isabelle, and Pierre
Plamondon. 1996. Word completion: A
first step toward target-text mediated
IMT. In Proceedings of the 16th International
Conference on Computational Linguistics,
pages 394-399, Copenhagen, Denmark.
Fung, Pascale. 1995. A pattern matching
method for finding noun and proper
noun translations from noisy parallel
corpora. In Proceedings of the 33rd Annual
Meeting, pages 236-243, Boston, MA.
Association for Computational
Linguistics.
Gale, William A., and Kenneth W. Church.
1991. Identifying word correspondences
in parallel texts. Proceedings of the DARPA
SNL Workshop, pages 152-157, Asilomar,
CA.
Gale, William A., and Geoff Sampson. 1995.
Good-Turing frequency estimation
without tears. Journal of Quantitative
Linguistics, 2:217-237. Swets &amp; Zeitlinger
Publishers, Sassenheim, The Netherlands.
Hiemstra, Djoerd. 1996. Using Statistical
Methods to Create a Bilingual Dictionary.
Masters thesis, University of Twente, The
Netherlands.
Hiemstra, Djoerd. 1998. Multilingual
domain modeling in twenty-one:
Automatic creation of a bi-directional
translation lexicon from a parallel corpus.
In Proceedings of the Eighth meeting of
Computational Linguistics in the Netherlands
(CLIN), pages 41-58.
Kumano, Akira, and Hideki Hirakawa. 1994.
Building an MT dictionary from parallel
texts based on linguistic and statistical
information. In Proceedings of the 15th
International Conference on Computational
Linguistics, pages 76-81, Kyoto, Japan.
McCarley, J. Scott. 1999. Should we translate
the documents or the queries in
cross-language information retrieval? In
Proceedings of the 37th Annual Meeting,
pages 208-214, College Park, MD.
Association for Computational
Linguistics.
Macklovitch, Elliott. 1994. Using bi-textual
alignment for translation validation: The
TransCheck system. In Proceedings of the
1st Conference of the Association for Machine
Translation in the Americas, pages 157-168.
Columbia, MD.
Melamed, I. Dan. 1995. Automatic
evaluation and uniform filter cascades for
inducing N-best translation lexicons. In
Proceedings of the Third Workshop on Very
Large Corpora, pages 184-198, Cambridge,
MA.
Melamed, I. Dan. 1996a. Automatic
detection of omissions in translations. In
Proceedings of the 16th International
Conference on Computational Linguistics,
pages 764-769, Copenhagen, Denmark.
Melamed, I. Dan. 1996b. Automatic
construction of clean broad-coverage
translation lexicons. In Proceedings of the
2nd Conference of the Association for Machine
Translation in the Americas, pages 125-134,
Montreal, Canada.
Melamed, I. Dan. 1998a. Models of
co-occurrence. Institute for Research in
Cognitive Science Technical Report
#98-05. University of Pennsylvania,
Philadelphia, PA.
Melamed, I. Dan. 1998b. Annotation style
guide for the blinker project. Institute for
Research in Cognitive Science Technical
Report #98-06. University of
Pennsylvania, Philadelphia, PA.
Melamed, I. Dan. 1998c. Manual annotation
of translational equivalence: The blinker
project. Institute for Research in Cognitive
</reference>
<page confidence="0.984069">
248
</page>
<note confidence="0.865174">
Melamed Models of Translational Equivalence
</note>
<reference confidence="0.99936580952381">
Science Technical Report #98-07.
University of Pennsylvania, Philadelphia,
PA.
Melamed, I. Dan. To appear. Empirical
Methods for Exploiting Parallel Texts, MIT
Press.
Nerbonne, John, Lauri Karttunen, Elena
Paskaleva, Gabor Proszeky, and Tiit
Roosmaa. 1997. Reading more into
foreign languages. In Proceedings of the 5th
ACL Conference on Applied Natural Language
Processing, pages 135-138, Washington,
DC.
Oard, Douglas W. 1997. Adaptive filtering
of multilingual document streams. In
Proceedings of the 5th RIAO Conference on
Computer-Assisted Information Retrieval,
pages 233-253, Montreal, Canada.
Resnik, Philip. 1997. Evaluating multilingual
gisting of Web pages. In Proceedings of the
AAAI Symposium on Natural Language
Processing for the World Wide Web. Stanford,
CA.
Resnik, Philip, and David Yarowsky. 1997.
A perspective on word sense
disambiguation methods and their
evaluation. hi Proceedings of the SIGLEX
Workshop on Tagging Text with Lexical
Semantics, pages 79-86, Washington, DC.
Shieber, Stuart. 1994. Restricting the
weak-generative capacity of synchronous
tree-adjoining grammars. Computational
Intelligence, 10(4):371-385.
Simard, Michel, George F. Foster, and
Francois Perrault. 1993. TransSearch: A
bilingual concordance tool. Centre
d&apos;innovation en technologies de
l&apos;information, Laval, Canada.
Svartvik, Jan. 1992. Directions in Corpus
Linguistics. Mouton de Gruyter, Berlin.
Vogel, Stephan, Hermann Ney, and
Christoph Tillmann. 1996. HMM-based
word alignment in statistical translation.
In Proceedings of the 16th International
Conference on Computational Linguistics.
Copenhagen, Denmark.
Piek, Vossen, editor. 1998. Eurowordnet: A
Multilingual Database with Lexical Semantic
Networks. Kluwer Academic Publishers.
White, John S., and Theresa A. O&apos;Connell.
1993. Evaluation of machine translation.
In Proceedings of the ARPA HLT Workshop,
pages 206-210, Princeton, NJ.
Wu, Dekai, and Xuanyin Xia. 1994. Learning
an English-Chinese lexicon from a
parallel corpus. In Proceedings of the First
Conference of the Association for Machine
Translation in the Americas, pages 206-213,
Columbia, MD.
Yarowsky, David. 1993. One sense per
collocation. In Proceedings of the DARPA
Workshop on Human Language Technology,
pages 266-271, Princeton, NJ.
</reference>
<page confidence="0.998912">
249
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.650730">
<title confidence="0.996891">Models of Translational Equivalence among Words</title>
<author confidence="0.998448">I Dan Melamed</author>
<affiliation confidence="0.926281">West Group</affiliation>
<abstract confidence="0.990795050847458">Parallel texts (bitexts) have properties that distinguish them from other kinds of parallel data. First, most words translate to only one other word. Second, bitext correspondence is typically only partial—many words in each text have no clear equivalent in the other text. This article presents methods for biasing statistical translation models to reflect these properties. Evaluation with respect to independent human judgments has confirmed that translation models biased in this fashion are significantly more accurate than a baseline knowledge-free model. This article also shows how a statistical translation model can take advantage of preexisting knowledge that might be available about particular language pairs. Even the simplest kinds of languagespecific knowledge, such as the distinction between content words and function words, are shown to reliably boost translation model performance on some tasks. Statistical models that reflect knowledge about the model domain combine the best of both the rationalist and empiricist paradigms. The idea of a computer system for translating from one language to another is almost as old as the idea of computer systems. Warren Weaver wrote about mechanical translation as early as 1949. More recently, Brown et al. (1988) suggested that it may be possible to construct machine translation systems automatically. Instead of codifying the human translation process from introspection, Brown and his colleagues proposed machine learning techniques to induce models of the process from examples of its input and output. The proposal generated much excitement, because it held the promise of automating a task that forty years of research have proven very labor-intensive and error-prone. Yet very few other researchers have taken up the cause, partly because Brown et al.&apos;s (1988) approach was quite a departure from the paradigm in vogue at the time. Brown et al. (1988) built statistical models of equivalence models&apos;, short). In the context of computational linguistics, translational equivalence is a relation that holds between two expressions with the same meaning, where the two expressions are in different languages. Empirical estimation statistical translation models is typically based on texts of texts that are translations of each other. As with all statistical models, the best translation models are those whose parameters correspond best with the sources of variance in the data. Probabilistic translation models whose parameters reflect universal properties of translational equivalence and/or existing knowledge about particular * D1-66F, 610 Opperman Drive, Eagan, MN 55123. E-mail: dan.melamed@twestgroup.com 1 The term translation model, which is standard in the literature, refers to a mathematical relationship two data sets. hi this context, the term implies nothing about the translation between natural languages, automated or otherwise. © 2000 Association for Computational Linguistics Computational Linguistics Volume 26, Number 2 languages and language pairs benefit from the best of both the empiricist and rationalist traditions. This article presents three such models, along with methods for efficiently estimating their parameters. Each new method is designed to account for an additional universal property of translational equivalence in bitexts: 1. Most word tokens translate to only one word token. I approximate this tendency with a one-to-one assumption. 2. Most text segments are not translated word-for-word. I build an explicit noise model. 3. Different linguistic objects have statistically different behavior in translation. I show a way to condition translation models on different word classes to help account for the variety Quantitative evaluation with respect to independent human judgments has shown that each of these three estimation biases significantly improves translation model accuracy over a baseline knowledge-free model. However, these biases will not produce the best possible translation models by themselves. Anyone attempting to build an optimal translation model should infuse it with all available knowledge sources, including syntactic, dictionary and cognate information. My goal here is only to demonstrate the value of some previously unused kinds of information that are always available for translation modeling, and to show how these information sources can be integrated with others.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anne Abeille</author>
<author>Yves Schabes</author>
<author>Aravind K Joshi</author>
</authors>
<title>Using lexicalized tree adjoining grammars for machine translation.</title>
<date>1990</date>
<booktitle>In Proceedings of the 13th International Conference on Computational Linguistics.</booktitle>
<location>Helsinki, Finland.</location>
<contexts>
<context position="12638" citStr="Abeille et al. 1990" startWordPosition="1976" endWordPosition="1979">ar, Chapter 8). 224 Melamed Models of Translational Equivalence each i is distinct, and each j is distinct. The label pairs in a given assignment can be generated in any order, so there are 1! ways to generate an assignment of size 1.6 It follows that the probability of generating a pair of bags (B1, B2) with a particular assignment A of size 1 is Pr(Bi, A, B21/, C , trans) = Pr (1) 1! ri E Pr(C)trans(tii, Ari1C). (10) CEC The above equation holds regardless of how we represent concepts. There are many plausible representations, such as pairs of trees from synchronous tree adjoining grammars (Abeille et al. 1990; Shieber 1994; Candito 1998), lexical conceptual structures (Dorr 1992) and WordNet synsets (Fellbaum 1998; Vossen 1998). Of course, for a representation to be used, a method must exist for estimating its distribution in data. A useful representation will reduce the entropy of the trans distribution, which is conditioned on the concept distribution as shown in Equation 10. This topic is beyond the scope of this article, however. I mention it only to show how the models presented here may be used as building blocks for models that are more psycholinguistically sophisticated. To make the transl</context>
</contexts>
<marker>Abeille, Schabes, Joshi, 1990</marker>
<rawString>Abeille, Anne, Yves Schabes, and Aravind K. Joshi. 1990. Using lexicalized tree adjoining grammars for machine translation. In Proceedings of the 13th International Conference on Computational Linguistics. Helsinki, Finland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ravindra K Ahuja</author>
<author>Thomas L Magnati</author>
<author>James B Orlin</author>
</authors>
<title>Network Flows: Theory, Algorithms, and Applications.</title>
<date>1993</date>
<publisher>Prentice Hall,</publisher>
<location>Englewood Cliffs, NJ.</location>
<marker>Ahuja, Magnati, Orlin, 1993</marker>
<rawString>Ahuja, Ravindra K., Thomas L. Magnati, and James B. Orlin. 1993. Network Flows: Theory, Algorithms, and Applications. Prentice Hall, Englewood Cliffs, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yaser Al-Onaizan</author>
<author>Jan Curin</author>
<author>Michael Jahr</author>
<author>Kevin Knight</author>
<author>John Lafferty</author>
<author>I Dan Melamed</author>
<author>Franz J Och</author>
<author>David Purdy</author>
<author>Noah A Smith</author>
<author>David Yarowsky</author>
</authors>
<date>1999</date>
<booktitle>Statistical machine translation. CLSP Technical Report.</booktitle>
<location>Baltimore, MD.</location>
<note>Available at www.clsp.jhu.edu/ws99/ projects/mt/final_report/mt-finalreport.ps</note>
<contexts>
<context position="7876" citStr="Al-Onaizan et al. 1999" startWordPosition="1160" endWordPosition="1163">trieval with a uniform T is likely to be limited in the same way as the performance of conventional information retrieval without term-frequency information, i.e., where the system knows which terms occur in which documents, but not how often (Buckley 1993). Applications where word order is crucial include speech transcription for translation (Brousseau et al. 1995), bootstrapping of OCR systems for new languages (Philip Resnik and Tapas Kanungo, personal communication), interactive translation (Foster, Isabelle, and Plamondon 1996), and fully automatic high-quality machine translation (e.g., Al-Onaizan et al. 1999). In such applications, a word-to-word translation model can serve as an independent module in a more complex sequence-tosequence translation model.&apos; The independence of such a module is desirable for two reasons, one practical and one philosophical. The practical reason is illustrated in this article: Order-independent translation models can be accurately estimated more efficiently in isolation. The philosophical reason is that words are an important epistemological category in our naive mental representations of language. We have many intuitions (and even some testable theories) about what w</context>
<context position="57556" citStr="Al-Onaizan et al. 1999" startWordPosition="9369" endWordPosition="9372">ions. For some applications, it is insufficient to guess only the single most likely translation of each word in the input. The model is expected to output the whole distribution of possible translations for each input word. This distribution is then combined with other distributions that are relevant to the application. For example, for cross-language information retrieval, the translational distribution can be combined with the distribution of term frequencies. For statistical machine translation, the translational distribution can be decoded with a source language model (Brown et al. 1988; Al-Onaizan et al. 1999). To predict how the different models might perform in such applications, the whole distribution task was to generate a whole set of links from each input word, weighted according to the probability assigned by the model to each of the input word&apos;s translations. Each model was tested on this task with and without function words. The mean results are plotted in Figures 4 and 5 with 95% confidence intervals. All four graphs in these figures are on the same scale to facilitate comparison. On both tasks involving the entire vocabulary, each of the biases presented in this article improves the effi</context>
</contexts>
<marker>Al-Onaizan, Curin, Jahr, Knight, Lafferty, Melamed, Och, Purdy, Smith, Yarowsky, 1999</marker>
<rawString>Al-Onaizan, Yaser, Jan Curin, Michael Jahr, Kevin Knight, John Lafferty, I. Dan Melamed, Franz J. Och, David Purdy, Noah A. Smith, and David Yarowsky. 1999. Statistical machine translation. CLSP Technical Report. Baltimore, MD. Available at www.clsp.jhu.edu/ws99/ projects/mt/final_report/mt-finalreport.ps</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julie Brousseau</author>
<author>Caroline Drouin</author>
<author>George Foster</author>
<author>Pierre Isabelle</author>
<author>Roland Kuhn</author>
<author>Yves Normandin</author>
<author>Pierre Plamondon</author>
</authors>
<title>French speech recognition in an automatic dictation system for translators: The TransTalk project.</title>
<date>1995</date>
<booktitle>In Proceedings of EuroSpeech&apos;95,</booktitle>
<pages>193--196</pages>
<location>Madrid,</location>
<contexts>
<context position="7621" citStr="Brousseau et al. 1995" startWordPosition="1128" endWordPosition="1131">nce among the possible translations of each element of Q&apos;. A typical bilingual dictionary says only what the possible translations are, which is equivalent to positing a uniform translational distribution. The performance of cross-language information retrieval with a uniform T is likely to be limited in the same way as the performance of conventional information retrieval without term-frequency information, i.e., where the system knows which terms occur in which documents, but not how often (Buckley 1993). Applications where word order is crucial include speech transcription for translation (Brousseau et al. 1995), bootstrapping of OCR systems for new languages (Philip Resnik and Tapas Kanungo, personal communication), interactive translation (Foster, Isabelle, and Plamondon 1996), and fully automatic high-quality machine translation (e.g., Al-Onaizan et al. 1999). In such applications, a word-to-word translation model can serve as an independent module in a more complex sequence-tosequence translation model.&apos; The independence of such a module is desirable for two reasons, one practical and one philosophical. The practical reason is illustrated in this article: Order-independent translation models can </context>
</contexts>
<marker>Brousseau, Drouin, Foster, Isabelle, Kuhn, Normandin, Plamondon, 1995</marker>
<rawString>Brousseau, Julie, Caroline Drouin, George Foster, Pierre Isabelle, Roland Kuhn, Yves Normandin, and Pierre Plamondon. 1995. French speech recognition in an automatic dictation system for translators: The TransTalk project. In Proceedings of EuroSpeech&apos;95, pages 193-196, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>John Cocke</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Fredrick Jelinek</author>
<author>Robert L Mercer</author>
<author>Paul Roossin</author>
</authors>
<title>A statistical approach to language translation.</title>
<date>1988</date>
<booktitle>In Proceedings of the 12th International Conference on Computational Linguistics,</booktitle>
<pages>71--76</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="1366" citStr="Brown et al. (1988)" startWordPosition="202" endWordPosition="205">ight be available about particular language pairs. Even the simplest kinds of languagespecific knowledge, such as the distinction between content words and function words, are shown to reliably boost translation model performance on some tasks. Statistical models that reflect knowledge about the model domain combine the best of both the rationalist and empiricist paradigms. 1. Introduction The idea of a computer system for translating from one language to another is almost as old as the idea of computer systems. Warren Weaver wrote about mechanical translation as early as 1949. More recently, Brown et al. (1988) suggested that it may be possible to construct machine translation systems automatically. Instead of codifying the human translation process from introspection, Brown and his colleagues proposed machine learning techniques to induce models of the process from examples of its input and output. The proposal generated much excitement, because it held the promise of automating a task that forty years of research have proven very labor-intensive and error-prone. Yet very few other researchers have taken up the cause, partly because Brown et al.&apos;s (1988) approach was quite a departure from the para</context>
<context position="26970" citStr="Brown et al. (1988)" startWordPosition="4315" endWordPosition="4318">nd in the work described here. 7 This expression is obtained by substituting Brown, Della Pietra, Della Pietra, and Mercer&apos;s (1993) Equation 17 into their Equation 14. 8 Or, equivalently, if the notion of segments were dispensed with altogether, as under the distance-based model of co-occurrence (Melamed 1998a). 229 Computational Linguistics Volume 26, Number 2 4.3.2 Word Order Correlation Biases. In any bitext, the positions of words relative to the true bitext map correlate with the positions of their translations. The correlation is stronger for language pairs with more similar word order. Brown et al. (1988) introduced the idea that this correlation can be encoded in translation model parameters. Dagan, Church, and Gale (1993) expanded on this idea by replacing Brown et al.&apos;s (1988) word alignment parameters, which were based on absolute word positions in aligned segments, with a much smaller set of relative offset parameters. The much smaller number of parameters allowed Dagan, Church, and Gale&apos;s model to be effectively trained on much smaller bitexts. Vogel, Ney, and Tillmann (1996) have shown how some additional assumptions can turn this model into a hidden Markov model, enabling even more eff</context>
<context position="57531" citStr="Brown et al. 1988" startWordPosition="9365" endWordPosition="9368"> and their translations. For some applications, it is insufficient to guess only the single most likely translation of each word in the input. The model is expected to output the whole distribution of possible translations for each input word. This distribution is then combined with other distributions that are relevant to the application. For example, for cross-language information retrieval, the translational distribution can be combined with the distribution of term frequencies. For statistical machine translation, the translational distribution can be decoded with a source language model (Brown et al. 1988; Al-Onaizan et al. 1999). To predict how the different models might perform in such applications, the whole distribution task was to generate a whole set of links from each input word, weighted according to the probability assigned by the model to each of the input word&apos;s translations. Each model was tested on this task with and without function words. The mean results are plotted in Figures 4 and 5 with 95% confidence intervals. All four graphs in these figures are on the same scale to facilitate comparison. On both tasks involving the entire vocabulary, each of the biases presented in this </context>
</contexts>
<marker>Brown, Cocke, Pietra, Pietra, Jelinek, Mercer, Roossin, 1988</marker>
<rawString>Brown, Peter F., John Cocke, Stephen A. Della Pietra, Vincent J. Della Pietra, Fredrick Jelinek, Robert L. Mercer, and Paul Roossin. 1988. A statistical approach to language translation. In Proceedings of the 12th International Conference on Computational Linguistics, pages 71-76, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Meredith J Goldsmith</author>
<author>Jan Hajic</author>
<author>Robert L Mercer</author>
<author>Surya Mohanty</author>
</authors>
<title>But dictionaries are data too.</title>
<date>1993</date>
<booktitle>In Proceedings of the ARPA HLT Workshop,</booktitle>
<pages>202--205</pages>
<location>Princeton, NJ.</location>
<contexts>
<context position="13893" citStr="Brown et al. (1993" startWordPosition="2177" endWordPosition="2180">ted here as general as possible, I shall assume a totally uninformative concept representation—the trans distribution itself. In other words, I shall assume that each different pair of word sequence types is deterministically generated from a different concept, so that trans (Ili, ViIC) is zero for all concepts except one. Now, a bag-to-bag translation model can be fully specified by the distributions of 1 and trans. Pr (Bi, A, B21/, trans) = Pr(/) • 1! H trans(ii,Ari) (11) (i•/) EA The probability distribution trans (ii, it&apos;) is a word-to-word translation model. Unlike the models proposed by Brown et al. (1993b), this model is symmetric, because both word bags are generated together from a joint probability distribution. Brown and his colleagues&apos; models, reviewed in Section 4.3, generate one half of the bitext given the other half, so they are represented by conditional probability distributions. A sequenceto-sequence translation model can be obtained from a word-to-word translation model by combining Equation 11 with order information as in Equation 8. 3. The One-to-One Assumption The most general word-to-word translation model trans(ii, V), where ii and range over sequences in Li and £2, has an i</context>
<context position="23947" citStr="Brown et al. (1993" startWordPosition="3822" endWordPosition="3825">slations. (Wu and Xia 1994, 211) This is a reasonable evaluation method, but it is not comparable to methods that simply count each lexicon entry as either right or wrong (e.g., Daille, Gaussier, and Lange 1994; Melamed 1996b). A weighted precision estimate pays more attention to entries that are more frequent and hence easier to estimate. Therefore, weighted precision estimates are generally higher than unweighted ones. 4.3 Reestimated Sequence-to-Sequence Translation Models Most probabilistic translation model reestimation algorithms published to date are variations on the theme proposed by Brown et al. (1993b). These models involve conditional probabilities, but they can be compared to symmetric models if the latter are normalized by the appropriate marginal distribution. I shall review these models using the notation in Table 1. 228 Melamed Models of Translational Equivalence 4.3.1 Models Using Only Co-occurrence Information. Brown and his colleagues employ the expectation-maximization (EM) algorithm (Dempster, Laird, and Rubin 1977) to estimate the parameters of their Model 1. On iteration i, the EM algorithm reestimates the model parameters transi(vju) based on their estimates from iteration i</context>
<context position="33714" citStr="Brown et al. (1993" startWordPosition="5408" endWordPosition="5411">ther than merely approximated. 231 Computational Linguistics Volume 26, Number 2 The number of possible assignments grows exponentially with the size of aligned text segments in the bitext. Due to the parameter interdependencies introduced by the one-to-one assumption, we are unlikely to find a method for decomposing the assignments into parameters that can be estimated independently of each other as in Brown et al. [1993b, Equation 26]). Barring such a decomposition method, the MLE approach is infeasible. This is why we must make do with approximations to the EM algorithm. In this situation, Brown et al. (1993b, 293) recommend &amp;quot;evaluating the expectations using only a single, probable alignment.&amp;quot; The single most probable assignment Amax is the maximum a posteriori (MAP) assignment: Amax — arglinea!4(Pr(U,A, Vie) arg max Pr(1) • 1! 11 trans(ui, V]) AEA (i,j)EA [ arg imic log Pr(1) • 1! IT trans(ui,Vi) (i,j)EA arg max AEA log[Pr(1) • 1!] + log trans(ui,vi) (i,DEA To simplify things further, let us assume that Pr(/) • 1! is constant, so that Amax = arg max log trans(ui,vi). AEA (i,i)EA If we represent the bitext as a bipartite graph and weight the edges by log trans(u, v), then the right-hand side of </context>
<context position="50682" citStr="Brown et al. 1993" startWordPosition="8293" endWordPosition="8296">are translated less consistently than rare words (Catizone, Russell, and Warwick 1989). To account for these differences, we can estimate separate values of A+ and A- for different ranges of cooc(u, v). Similarly, the auxiliary parameters can be conditioned on the linked parts of speech. A kind of word order correlation bias can be effected by conditioning the auxiliary parameters on the relative positions of linked word tokens in their respective texts. Just as easily, we can model link types that coincide with entries in an on-line bilingual dictionary separately from those that do not (cf. Brown et al. 1993). When the auxiliary parameters are conditioned on different link classes, their optimization is carried out separately for each class: B(links (u, v) Icooc(u, v), A-zF ) (37) scorec (u, viz = class (u, v)) = log B (links (u, v)lcooc(u, v), ) Section 6.1.1 describes the link classes used in the experiments below. 6. Evaluation 6.1 Evaluation at the Token Level This section compares translation model estimation methods A, B, and C to each other and to Brown et al.&apos;s (1993b) Model 1. To reiterate, Model 1 is based on co-occurrence information only; Method A is based on the one-to-one assumption;</context>
<context position="53058" citStr="Brown et al. 1993" startWordPosition="8675" endWordPosition="8678">bols, such as - and * NU the NULL word, in a class by itself C Content words: nouns, adjectives, adverbs, non-auxiliary verbs F all other words, i.e., function words method is the list of function words in class F. Certainly, more sophisticated word classification methods could produce better models, but even the simple classification in Table 4 should suffice to demonstrate the method&apos;s potential. 6.1.1 Experiment 1. Until now, translation models have been evaluated either subjectively (e.g. White and O&apos;Connell 1993) or using relative metrics, such as perplexity with respect to other models (Brown et al. 1993b). Objective and more accurate tests can be carried out using a &amp;quot;gold standard.&amp;quot; I hired bilingual annotators to link roughly 16,000 corresponding words between on-line versions of the Bible in French and English. This bitext was selected to facilitate widespread use and standardization (see Melamed [1998c] for details). The entire Bible bitext comprised 29,614 verse pairs, of which 250 verse pairs were hand-linked using a specially developed annotation tool. The annotation style guide (Melamed 1998b) was based on the intuitions of the annotators, so it was not biased towards any particular t</context>
<context position="70069" citStr="Brown et al. (1993" startWordPosition="11417" endWordPosition="11420">and I. Figure 8 graphs the accuracy of the method against coverage, with 95% confidence intervals. The upper curve represents accuracy when incomplete links are considered correct, and the lower when they are considered incorrect. On the former metric, the method can generate translation lexicons with accuracy and coverage both exceeding 90%, as well as dictionary-size translation lexicons that are over 99% correct. 7. Conclusion There are many ways to model translational equivalence and many ways to estimate translation models. &amp;quot;The mathematics of statistical machine translation&amp;quot; proposed by Brown et al. (1993b) are just one kind of mathematics for one kind of statistical transFigure 8 Translation lexicon accuracy with 95% confidence intervals at varying levels of coverage. (99.2%) 99.0%) incomplete = correct 100 98 96 _ - &gt;, o94 - LT_ = 0 92 0 - (91.6%) as _ 88 86 .1(89:2%) ------______ incomplete = incorrect (92.8%) (86.8%) ..,1,:. 90 0 i i 36 46 (3/0 coverage 84 90 246 Melamed Models of Translational Equivalence lation. In this article, I have proposed and evaluated new kinds of translation model biases, alternative parameter estimation strategies, and techniques for exploiting preexisting knowl</context>
</contexts>
<marker>Brown, Pietra, Pietra, Goldsmith, Hajic, Mercer, Mohanty, 1993</marker>
<rawString>Brown, Peter F., Stephen A. Della Pietra, Vincent J. Della Pietra, Meredith J. Goldsmith, Jan Hajic, Robert L. Mercer and Surya Mohanty. 1993a. But dictionaries are data too. In Proceedings of the ARPA HLT Workshop, pages 202-205, Princeton, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics</journal>
<pages>19--2</pages>
<contexts>
<context position="13893" citStr="Brown et al. (1993" startWordPosition="2177" endWordPosition="2180">ted here as general as possible, I shall assume a totally uninformative concept representation—the trans distribution itself. In other words, I shall assume that each different pair of word sequence types is deterministically generated from a different concept, so that trans (Ili, ViIC) is zero for all concepts except one. Now, a bag-to-bag translation model can be fully specified by the distributions of 1 and trans. Pr (Bi, A, B21/, trans) = Pr(/) • 1! H trans(ii,Ari) (11) (i•/) EA The probability distribution trans (ii, it&apos;) is a word-to-word translation model. Unlike the models proposed by Brown et al. (1993b), this model is symmetric, because both word bags are generated together from a joint probability distribution. Brown and his colleagues&apos; models, reviewed in Section 4.3, generate one half of the bitext given the other half, so they are represented by conditional probability distributions. A sequenceto-sequence translation model can be obtained from a word-to-word translation model by combining Equation 11 with order information as in Equation 8. 3. The One-to-One Assumption The most general word-to-word translation model trans(ii, V), where ii and range over sequences in Li and £2, has an i</context>
<context position="23947" citStr="Brown et al. (1993" startWordPosition="3822" endWordPosition="3825">slations. (Wu and Xia 1994, 211) This is a reasonable evaluation method, but it is not comparable to methods that simply count each lexicon entry as either right or wrong (e.g., Daille, Gaussier, and Lange 1994; Melamed 1996b). A weighted precision estimate pays more attention to entries that are more frequent and hence easier to estimate. Therefore, weighted precision estimates are generally higher than unweighted ones. 4.3 Reestimated Sequence-to-Sequence Translation Models Most probabilistic translation model reestimation algorithms published to date are variations on the theme proposed by Brown et al. (1993b). These models involve conditional probabilities, but they can be compared to symmetric models if the latter are normalized by the appropriate marginal distribution. I shall review these models using the notation in Table 1. 228 Melamed Models of Translational Equivalence 4.3.1 Models Using Only Co-occurrence Information. Brown and his colleagues employ the expectation-maximization (EM) algorithm (Dempster, Laird, and Rubin 1977) to estimate the parameters of their Model 1. On iteration i, the EM algorithm reestimates the model parameters transi(vju) based on their estimates from iteration i</context>
<context position="33714" citStr="Brown et al. (1993" startWordPosition="5408" endWordPosition="5411">ther than merely approximated. 231 Computational Linguistics Volume 26, Number 2 The number of possible assignments grows exponentially with the size of aligned text segments in the bitext. Due to the parameter interdependencies introduced by the one-to-one assumption, we are unlikely to find a method for decomposing the assignments into parameters that can be estimated independently of each other as in Brown et al. [1993b, Equation 26]). Barring such a decomposition method, the MLE approach is infeasible. This is why we must make do with approximations to the EM algorithm. In this situation, Brown et al. (1993b, 293) recommend &amp;quot;evaluating the expectations using only a single, probable alignment.&amp;quot; The single most probable assignment Amax is the maximum a posteriori (MAP) assignment: Amax — arglinea!4(Pr(U,A, Vie) arg max Pr(1) • 1! 11 trans(ui, V]) AEA (i,j)EA [ arg imic log Pr(1) • 1! IT trans(ui,Vi) (i,j)EA arg max AEA log[Pr(1) • 1!] + log trans(ui,vi) (i,DEA To simplify things further, let us assume that Pr(/) • 1! is constant, so that Amax = arg max log trans(ui,vi). AEA (i,i)EA If we represent the bitext as a bipartite graph and weight the edges by log trans(u, v), then the right-hand side of </context>
<context position="50682" citStr="Brown et al. 1993" startWordPosition="8293" endWordPosition="8296">are translated less consistently than rare words (Catizone, Russell, and Warwick 1989). To account for these differences, we can estimate separate values of A+ and A- for different ranges of cooc(u, v). Similarly, the auxiliary parameters can be conditioned on the linked parts of speech. A kind of word order correlation bias can be effected by conditioning the auxiliary parameters on the relative positions of linked word tokens in their respective texts. Just as easily, we can model link types that coincide with entries in an on-line bilingual dictionary separately from those that do not (cf. Brown et al. 1993). When the auxiliary parameters are conditioned on different link classes, their optimization is carried out separately for each class: B(links (u, v) Icooc(u, v), A-zF ) (37) scorec (u, viz = class (u, v)) = log B (links (u, v)lcooc(u, v), ) Section 6.1.1 describes the link classes used in the experiments below. 6. Evaluation 6.1 Evaluation at the Token Level This section compares translation model estimation methods A, B, and C to each other and to Brown et al.&apos;s (1993b) Model 1. To reiterate, Model 1 is based on co-occurrence information only; Method A is based on the one-to-one assumption;</context>
<context position="53058" citStr="Brown et al. 1993" startWordPosition="8675" endWordPosition="8678">bols, such as - and * NU the NULL word, in a class by itself C Content words: nouns, adjectives, adverbs, non-auxiliary verbs F all other words, i.e., function words method is the list of function words in class F. Certainly, more sophisticated word classification methods could produce better models, but even the simple classification in Table 4 should suffice to demonstrate the method&apos;s potential. 6.1.1 Experiment 1. Until now, translation models have been evaluated either subjectively (e.g. White and O&apos;Connell 1993) or using relative metrics, such as perplexity with respect to other models (Brown et al. 1993b). Objective and more accurate tests can be carried out using a &amp;quot;gold standard.&amp;quot; I hired bilingual annotators to link roughly 16,000 corresponding words between on-line versions of the Bible in French and English. This bitext was selected to facilitate widespread use and standardization (see Melamed [1998c] for details). The entire Bible bitext comprised 29,614 verse pairs, of which 250 verse pairs were hand-linked using a specially developed annotation tool. The annotation style guide (Melamed 1998b) was based on the intuitions of the annotators, so it was not biased towards any particular t</context>
<context position="70069" citStr="Brown et al. (1993" startWordPosition="11417" endWordPosition="11420">and I. Figure 8 graphs the accuracy of the method against coverage, with 95% confidence intervals. The upper curve represents accuracy when incomplete links are considered correct, and the lower when they are considered incorrect. On the former metric, the method can generate translation lexicons with accuracy and coverage both exceeding 90%, as well as dictionary-size translation lexicons that are over 99% correct. 7. Conclusion There are many ways to model translational equivalence and many ways to estimate translation models. &amp;quot;The mathematics of statistical machine translation&amp;quot; proposed by Brown et al. (1993b) are just one kind of mathematics for one kind of statistical transFigure 8 Translation lexicon accuracy with 95% confidence intervals at varying levels of coverage. (99.2%) 99.0%) incomplete = correct 100 98 96 _ - &gt;, o94 - LT_ = 0 92 0 - (91.6%) as _ 88 86 .1(89:2%) ------______ incomplete = incorrect (92.8%) (86.8%) ..,1,:. 90 0 i i 36 46 (3/0 coverage 84 90 246 Melamed Models of Translational Equivalence lation. In this article, I have proposed and evaluated new kinds of translation model biases, alternative parameter estimation strategies, and techniques for exploiting preexisting knowl</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Brown, Peter F., Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993b. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics 19(2):263-311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Buckley</author>
</authors>
<title>The importance of proper weighting methods.</title>
<date>1993</date>
<booktitle>In Proceedings of the DARPA Workshop on Human Language Technology,</booktitle>
<pages>349--352</pages>
<location>Princeton, NJ.</location>
<contexts>
<context position="7510" citStr="Buckley 1993" startWordPosition="1114" endWordPosition="1115">f D. In order for the mapping to be accurate, T must be able to encode many levels of relative importance among the possible translations of each element of Q&apos;. A typical bilingual dictionary says only what the possible translations are, which is equivalent to positing a uniform translational distribution. The performance of cross-language information retrieval with a uniform T is likely to be limited in the same way as the performance of conventional information retrieval without term-frequency information, i.e., where the system knows which terms occur in which documents, but not how often (Buckley 1993). Applications where word order is crucial include speech transcription for translation (Brousseau et al. 1995), bootstrapping of OCR systems for new languages (Philip Resnik and Tapas Kanungo, personal communication), interactive translation (Foster, Isabelle, and Plamondon 1996), and fully automatic high-quality machine translation (e.g., Al-Onaizan et al. 1999). In such applications, a word-to-word translation model can serve as an independent module in a more complex sequence-tosequence translation model.&apos; The independence of such a module is desirable for two reasons, one practical and on</context>
</contexts>
<marker>Buckley, 1993</marker>
<rawString>Buckley, Chris. 1993. The importance of proper weighting methods. In Proceedings of the DARPA Workshop on Human Language Technology, pages 349-352, Princeton, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Helene Candito</author>
</authors>
<title>Building parallel LTAG for French and Italian.</title>
<date>1998</date>
<booktitle>In COLING-ACL &apos;98: 36 Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics,</booktitle>
<pages>211--217</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="12667" citStr="Candito 1998" startWordPosition="1982" endWordPosition="1983">of Translational Equivalence each i is distinct, and each j is distinct. The label pairs in a given assignment can be generated in any order, so there are 1! ways to generate an assignment of size 1.6 It follows that the probability of generating a pair of bags (B1, B2) with a particular assignment A of size 1 is Pr(Bi, A, B21/, C , trans) = Pr (1) 1! ri E Pr(C)trans(tii, Ari1C). (10) CEC The above equation holds regardless of how we represent concepts. There are many plausible representations, such as pairs of trees from synchronous tree adjoining grammars (Abeille et al. 1990; Shieber 1994; Candito 1998), lexical conceptual structures (Dorr 1992) and WordNet synsets (Fellbaum 1998; Vossen 1998). Of course, for a representation to be used, a method must exist for estimating its distribution in data. A useful representation will reduce the entropy of the trans distribution, which is conditioned on the concept distribution as shown in Equation 10. This topic is beyond the scope of this article, however. I mention it only to show how the models presented here may be used as building blocks for models that are more psycholinguistically sophisticated. To make the translation model estimation method</context>
</contexts>
<marker>Candito, 1998</marker>
<rawString>Candito, Marie-Helene. 1998. Building parallel LTAG for French and Italian. In COLING-ACL &apos;98: 36 Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, pages 211-217, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberta Catizone</author>
<author>Graham Russell</author>
<author>Susan Warwick</author>
</authors>
<title>Deriving translation data from bilingual texts.</title>
<date>1989</date>
<booktitle>In Proceedings of the First International Lexical Acquisition Workshop.</booktitle>
<location>Detroit, MI.</location>
<marker>Catizone, Russell, Warwick, 1989</marker>
<rawString>Catizone, Roberta, Graham Russell, and Susan Warwick. 1989. Deriving translation data from bilingual texts. In Proceedings of the First International Lexical Acquisition Workshop. Detroit, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
<author>Eduard H Hovy</author>
</authors>
<title>Good applications for crummy machine translation.</title>
<date>1993</date>
<journal>Machine Translation</journal>
<volume>8</volume>
<marker>Church, Hovy, 1993</marker>
<rawString>Church, Kenneth W., and Eduard H. Hovy. 1993. Good applications for crummy machine translation. Machine Translation 8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierre-Henri Cousin</author>
<author>Lorna Sinclair</author>
<author>Jean-Francois Allain</author>
<author>Catherine E Love</author>
</authors>
<title>The Harper Collins French Dictionary.</title>
<date>1990</date>
<publisher>Harper Collins Publishers,</publisher>
<location>New York, NY.</location>
<contexts>
<context position="62585" citStr="Cousin et al. 1990" startWordPosition="10209" endWordPosition="10212">established by the interannotator agreement rates on the gold standard. 6.2 Evaluation at the Type Level An important application of statistical translation models is to help lexicographers compile bilingual dictionaries. Dictionaries are written to answer the question, &amp;quot;What are the possible translations of X?&amp;quot; This is a question about link types, rather than about link tokens. Evaluation by link type is a thorny issue. Human judges often disagree about the degree to which context should play a role in judgments of translational equivalence. For example, the Harper-Collins French Dictionary (Cousin et al. 1990) gives the following French translations for English appoint: nommer, engager, fixer, designer. Likewise, most 0.1 0 250 243 Volume 26, Number 2 30000 60000 90000 entry number Figure 7 Distribution of link type scores. The long plateaus correspond to the most common combinations of links(u&apos;v) • 1/1,2/2, and 3/3. cooc(u,v) • lay judges would not consider instituer a correct French translation of appoint. In actual translations, however, when the object of the verb is commission, task force, panel, etc., English appoint is usually translated into French as instituer. To account for this kind of </context>
</contexts>
<marker>Cousin, Sinclair, Allain, Love, 1990</marker>
<rawString>Cousin, Pierre-Henri, Lorna Sinclair, Jean-Francois Allain, and Catherine E. Love. 1990. The Harper Collins French Dictionary. Harper Collins Publishers, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierre-Henri Cousin</author>
<author>Lorna Sinclair</author>
<author>Jean-Francois Allain</author>
<author>Catherine E Love</author>
</authors>
<title>The Collins Paperback French Dictionary.</title>
<date>1991</date>
<publisher>Harper Collins Publishers,</publisher>
<location>Glasgow.</location>
<contexts>
<context position="66482" citStr="Cousin et al. 1991" startWordPosition="10834" endWordPosition="10837">, the size of automatically induced lexicons depends on the size of the training bitext. Table 5 shows that, given a sufficiently large bitext, the method can automatically construct translation lexicons with as many entries as published bilingual dictionaries. The next task was to measure accuracy. It would have taken too long to evaluate every lexicon entry manually. Instead, I took five random samples (with replacement) of 100 entries each from each of the three lexicons. Each of the samples was first compared to a translation lexicon extracted from a machine-readable bilingual dictionary (Cousin et al. 1991). All the entries in the sample that appeared in the dictionary were assumed to be correct. I checked the remaining entries in all the samples by hand. To account for context-dependent translational equivalence, I evaluated the accuracy of the translation lexicons in the context of the bitext whence they were extracted, using a simple bilingual concordancer. A lexicon entry (u,v) was considered correct if u and v ever appeared as direct translations of each other in an aligned segment pair. That is, a link type was considered correct if any of its tokens were correct. Direct translations come </context>
</contexts>
<marker>Cousin, Sinclair, Allain, Love, 1991</marker>
<rawString>Cousin, Pierre-Henri, Lorna Sinclair, Jean-Francois Allain, and Catherine E. Love. 1991. The Collins Paperback French Dictionary. Harper Collins Publishers, Glasgow.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Kenneth W Church</author>
<author>William A Gale</author>
</authors>
<title>Robust word alignment for machine aided translation.</title>
<date>1993</date>
<booktitle>In Proceedings of the Workshop on Very Large Corpora: Academic and Industrial Perspectives,</booktitle>
<pages>1--8</pages>
<location>Columbus, OH.</location>
<marker>Dagan, Church, Gale, 1993</marker>
<rawString>Dagan, Ido, Kenneth W. Church, and William A. Gale. 1993. Robust word alignment for machine aided translation. In Proceedings of the Workshop on Very Large Corpora: Academic and Industrial Perspectives, pages 1-8, Columbus, OH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beatrice Daille</author>
<author>Eric Gaussier</author>
<author>Jean-Marc Lange</author>
</authors>
<title>Towards automatic extraction of monolingual and bilingual terminology.</title>
<date>1994</date>
<booktitle>Proceedings of the 15th International Conference on Computational Linguistics,</booktitle>
<pages>515--521</pages>
<location>Kyoto, Japan.</location>
<marker>Daille, Gaussier, Lange, 1994</marker>
<rawString>Daille, Beatrice, Eric Gaussier, and Jean-Marc Lange. 1994. Towards automatic extraction of monolingual and bilingual terminology. Proceedings of the 15th International Conference on Computational Linguistics, pages 515-521, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Edwards Deming</author>
<author>Frederick F Stephan</author>
</authors>
<title>On a least squares adjustment of a sampled frequency table when the expected marginal totals are known. The Annals of Mathematical Statistics,</title>
<date>1940</date>
<pages>11--427</pages>
<contexts>
<context position="29395" citStr="Deming and Stephan 1940" startWordPosition="4706" endWordPosition="4709">d Bag-to-Bag Translation Models At about the same time that I developed the models in this article, Hiemstra (1996) independently developed his own bag-to-bag model of translational equivalence. His model is also based on a one-to-one assumption, but it differs from my models in that it allows empty words in only one of the two bags, the one representing the shorter sentence. Thus, Hiemstra&apos;s model is similar to the first model in Section 5, but it has a little less explanatory power. Hiemstra&apos;s approach also differs from mine in his use of the Iterative Proportional Fitting Procedure (IPFP) (Deming and Stephan 1940) for parameter estimation. The IPFP is quite sensitive to initial conditions, so Hiemstra investigated a number of initialization options. Choosing the most advantageous, Hiemstra has published parts of the translational distributions of certain words, induced using both his method and Brown et al.&apos;s (1993b) Model 1 from the same training bitext. Subjective comparison of these examples suggests that Hiemstra&apos;s method is more accurate. Hiemstra (1998) has also evaluated the recall and precision of his method and of Model 1 on a small hand-constructed set of link tokens in a particular bitext. M</context>
</contexts>
<marker>Deming, Stephan, 1940</marker>
<rawString>Deming, W. Edwards, and Frederick F. Stephan. 1940. On a least squares adjustment of a sampled frequency table when the expected marginal totals are known. The Annals of Mathematical Statistics, 11:427 444.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arthur P Dempster</author>
<author>N M Laird</author>
<author>Donald B Rubin</author>
</authors>
<title>Maximum likelihood from incomplete data via the EM algorithm.</title>
<date>1977</date>
<journal>Journal of the Royal Statistical Society,</journal>
<pages>39--1</pages>
<marker>Dempster, Laird, Rubin, 1977</marker>
<rawString>Dempster, Arthur P., N. M. Laird, and Donald B. Rubin. 1977. Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society, 39(B):1-38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie J Dorr</author>
</authors>
<title>The use of lexical semantics in interlingual machine translation.</title>
<date>1992</date>
<journal>Machine Translation,</journal>
<pages>7--3</pages>
<contexts>
<context position="12710" citStr="Dorr 1992" startWordPosition="1988" endWordPosition="1989">t, and each j is distinct. The label pairs in a given assignment can be generated in any order, so there are 1! ways to generate an assignment of size 1.6 It follows that the probability of generating a pair of bags (B1, B2) with a particular assignment A of size 1 is Pr(Bi, A, B21/, C , trans) = Pr (1) 1! ri E Pr(C)trans(tii, Ari1C). (10) CEC The above equation holds regardless of how we represent concepts. There are many plausible representations, such as pairs of trees from synchronous tree adjoining grammars (Abeille et al. 1990; Shieber 1994; Candito 1998), lexical conceptual structures (Dorr 1992) and WordNet synsets (Fellbaum 1998; Vossen 1998). Of course, for a representation to be used, a method must exist for estimating its distribution in data. A useful representation will reduce the entropy of the trans distribution, which is conditioned on the concept distribution as shown in Equation 10. This topic is beyond the scope of this article, however. I mention it only to show how the models presented here may be used as building blocks for models that are more psycholinguistically sophisticated. To make the translation model estimation methods presented here as general as possible, I </context>
</contexts>
<marker>Dorr, 1992</marker>
<rawString>Dorr, Bonnie J. 1992. The use of lexical semantics in interlingual machine translation. Machine Translation, 7(3):135-193.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Dunning</author>
</authors>
<title>Accurate methods for the statistics of surprise and coincidence.</title>
<date>1993</date>
<journal>Computational Linguistics</journal>
<pages>19--1</pages>
<contexts>
<context position="35896" citStr="Dunning (1993)" startWordPosition="5761" endWordPosition="5762">ustly by considering the whole table. For example, Gale and Church (1991, 154) suggest that &amp;quot;02, a x2-like statistic, seems to be a particularly good choice because it makes good use of the off-diagonal cells&amp;quot; in the contingency table. 10 At least for my current very inefficient implementation. (24) 232 Melamed Models of Translational Equivalence Table 2 A co-occurrence contingency table. Total cooc(., v) cooc(., —.v) cooc(., .) cooc(u,.v) cooc(-11, v) cooc(u, —.v) COOC(—V, Total cooc(-u, -) In informal experiments described elsewhere (Melamed 1995), I found that the G2 statistic suggested by Dunning (1993) slightly outperforms 02. Let the cells of the contingency table be named as follows: a Now, G2(u, v) = —21og B(ala + b,pi)B(cic + d,p2) (27) B(aia + b,p)B(cic + d,p) nk where B(kin,p) = () pk(1 p)n-k are binomial probabilities. The statistic uses maximum likelihood estimates for the probability parameters: p1 = bf P2 — c±cd&apos; P = a±ab±±cc-Fd&apos; G2 is easy to compute because the binomial coefficients in the numerator and in the denominator cancel each other out. All my methods initialize the parameters score(u,v) to G2(u, v), except that any pairing with NULL is initialized to an infinitesimal va</context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>Dunning, Ted. 1993. Accurate methods for the statistics of surprise and coincidence. Computational Linguistics 19(1):61-74.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Fellbaum, Christiane, editor.</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="29849" citStr="(1998)" startWordPosition="4776" endWordPosition="4776">xplanatory power. Hiemstra&apos;s approach also differs from mine in his use of the Iterative Proportional Fitting Procedure (IPFP) (Deming and Stephan 1940) for parameter estimation. The IPFP is quite sensitive to initial conditions, so Hiemstra investigated a number of initialization options. Choosing the most advantageous, Hiemstra has published parts of the translational distributions of certain words, induced using both his method and Brown et al.&apos;s (1993b) Model 1 from the same training bitext. Subjective comparison of these examples suggests that Hiemstra&apos;s method is more accurate. Hiemstra (1998) has also evaluated the recall and precision of his method and of Model 1 on a small hand-constructed set of link tokens in a particular bitext. Model 1 fared worse, on average. 5. Parameter Estimation This section describes my methods for estimating the parameters of a symmetric wordto-word translation model from a bitext. For most applications, we are interested in estimating the probability trans (u, v) of jointly generating the pair of words (u, v). Unfortunately, these parameters cannot be directly inferred from a training bitext, because we don&apos;t know which words in one half of the bitex</context>
</contexts>
<marker>1998</marker>
<rawString>Fellbaum, Christiane, editor. 1998. WordNet: An Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Foster</author>
<author>Pierre Isabelle</author>
<author>Pierre Plamondon</author>
</authors>
<title>Word completion: A first step toward target-text mediated IMT.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics,</booktitle>
<pages>394--399</pages>
<location>Copenhagen, Denmark.</location>
<marker>Foster, Isabelle, Plamondon, 1996</marker>
<rawString>Foster, George, Pierre Isabelle, and Pierre Plamondon. 1996. Word completion: A first step toward target-text mediated IMT. In Proceedings of the 16th International Conference on Computational Linguistics, pages 394-399, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
</authors>
<title>A pattern matching method for finding noun and proper noun translations from noisy parallel corpora.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd Annual Meeting,</booktitle>
<pages>236--243</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Boston, MA.</location>
<contexts>
<context position="18906" citStr="Fung 1995" startWordPosition="2989" endWordPosition="2990"> for the models introduced in Section 5. 226 Melamed Models of Translational Equivalence He nods his head II I hoche la tete Figure 1 nods and hoche often co-occur, as do nods and head. The direct association between nods and hoche, and the direct association between nods and head give rise to an indirect association between hoche and head. 4.2 Nonprobabilistic Translation Lexicons Many researchers have proposed greedy algorithms for estimating nonprobabilistic word-to-word translation models, also known as translation lexicons (e.g., Catizone, Russell, and Warwick 1989; Gale and Church 1991; Fung 1995; Kumano and Hirakawa 1994; Melamed 1995; Wu and Xia 1994). Most of these algorithms can be summarized as follows: 1. Choose a similarity function S between word types in Li and word types in L. 2. Compute association scores S(u, v) for a set of word type pairs (u, v) E (Li x £2) that occur in training data. 3. Sort the word pairs in descending order of their association scores. 4. Discard all word pairs for which S(u, v) is less than a chosen threshold. The remaining word pairs become the entries in the translation lexicon. The various proposals differ mainly in their choice of similarity fun</context>
<context position="22548" citStr="Fung (1995)" startWordPosition="3607" endWordPosition="3608">ries at the very top of the list can be over 98% correct. Their algorithm gleaned lexicon entries for about 61% of the word tokens in a sample of 800 English sentences. To obtain 98% precision, their algorithm selected only entries for which it had high confidence that the association score was high. These would be the word pairs that co-occur most frequently. A random sample of 800 sentences from the same corpus showed that 61% of the word tokens, where the tokens are of the most frequent types, represent 4.5% of all the word types. A similar strategy was employed by Wu and Xia (1994) and by Fung (1995). Fung skimmed off the top 23.8% of the noun-noun entries in her lexicon to achieve a precision of 71.6%. Wu and Xia have reported automatic acquisition of 6,517 lexicon entries from a 3.3-million-word corpus, with a precision of 86%. The first 3.3 million word tokens in an English corpus from a similar genre contained 33,490 different word types, suggesting a recall of roughly 19%. Note, however, that Wu and Xia chose to weight their precision estimates by the probabilities attached to each entry: For example, if the translation set for English word detect has the two correct Chinese candidat</context>
</contexts>
<marker>Fung, 1995</marker>
<rawString>Fung, Pascale. 1995. A pattern matching method for finding noun and proper noun translations from noisy parallel corpora. In Proceedings of the 33rd Annual Meeting, pages 236-243, Boston, MA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Gale</author>
<author>Kenneth W Church</author>
</authors>
<title>Identifying word correspondences in parallel texts.</title>
<date>1991</date>
<booktitle>Proceedings of the DARPA SNL Workshop,</booktitle>
<pages>152--157</pages>
<location>Asilomar, CA.</location>
<contexts>
<context position="5945" citStr="Gale and Church 1991" startWordPosition="874" endWordPosition="877">ord order plays a crucial role and those where it doesn&apos;t. Empirically estimated models of translational equivalence among word types can play a central role in both kinds of applications. Applications where word order is not essential include • cross-language information retrieval (e.g., McCarley 1999), • multilingual document filtering (e.g., Oard 1997), • computer-assisted language learning (e.g., Nerbonne et al. 1997), • certain machine-assisted translation tools (e.g., Macklovitch 1994; Melamed 1996a), • concordancing for bilingual lexicography (e.g., Catizone, Russell, and Warwick 1989; Gale and Church 1991), 222 Melamed Models of Translational Equivalence • corpus linguistics (e.g., Svartvik 1992), • &amp;quot;crummy&amp;quot; machine translation (e.g., Church and Hovy 1992; Resnik 1997). For these applications, empirically estimated models have a number of advantages over handcrafted models such as on-line versions of bilingual dictionaries. Two of the advantages are the possibility of better coverage and the possibility of frequent updates by nonexpert users to keep up with rapidly evolving vocabularies. A third advantage is that statistical models can provide more accurate information about the relative import</context>
<context position="18895" citStr="Gale and Church 1991" startWordPosition="2985" endWordPosition="2988">his is the method used for the models introduced in Section 5. 226 Melamed Models of Translational Equivalence He nods his head II I hoche la tete Figure 1 nods and hoche often co-occur, as do nods and head. The direct association between nods and hoche, and the direct association between nods and head give rise to an indirect association between hoche and head. 4.2 Nonprobabilistic Translation Lexicons Many researchers have proposed greedy algorithms for estimating nonprobabilistic word-to-word translation models, also known as translation lexicons (e.g., Catizone, Russell, and Warwick 1989; Gale and Church 1991; Fung 1995; Kumano and Hirakawa 1994; Melamed 1995; Wu and Xia 1994). Most of these algorithms can be summarized as follows: 1. Choose a similarity function S between word types in Li and word types in L. 2. Compute association scores S(u, v) for a set of word type pairs (u, v) E (Li x £2) that occur in training data. 3. Sort the word pairs in descending order of their association scores. 4. Discard all word pairs for which S(u, v) is less than a chosen threshold. The remaining word pairs become the entries in the translation lexicon. The various proposals differ mainly in their choice of sim</context>
<context position="21917" citStr="Gale and Church (1991)" startWordPosition="3492" endWordPosition="3495">ned text segments in (U, V) the unigram frequency of u in U the unigram frequency of v in V the number of times that u and v co-occur the probability that a token of u will be translated as a token of v association. On the other hand, noise can reduce the strength of an indirect association without affecting any direct associations. Therefore, direct associations are usually stronger than indirect associations. If all the entries in a translation lexicon are sorted by their association scores, the direct associations will be very dense near the top of the list, and sparser towards the bottom. Gale and Church (1991) have shown that entries at the very top of the list can be over 98% correct. Their algorithm gleaned lexicon entries for about 61% of the word tokens in a sample of 800 English sentences. To obtain 98% precision, their algorithm selected only entries for which it had high confidence that the association score was high. These would be the word pairs that co-occur most frequently. A random sample of 800 sentences from the same corpus showed that 61% of the word tokens, where the tokens are of the most frequent types, represent 4.5% of all the word types. A similar strategy was employed by Wu an</context>
<context position="35354" citStr="Gale and Church (1991" startWordPosition="5677" endWordPosition="5680">escribes a greedy approximation to the MAP approximation. 5.1 Method A: The Competitive Linking Algorithm 5.1.1 Step 1: Initialization. Almost every translation model estimation algorithm exploits the well-known correlation between translation probabilities and co-occurrence counts. Many algorithms also normalize the co-occurrence counts cooc(u, v) by the marginal frequencies of u and v. However, these quantities account for only the three shaded cells in Table 2. The statistical interdependence between two word types can be estimated more robustly by considering the whole table. For example, Gale and Church (1991, 154) suggest that &amp;quot;02, a x2-like statistic, seems to be a particularly good choice because it makes good use of the off-diagonal cells&amp;quot; in the contingency table. 10 At least for my current very inefficient implementation. (24) 232 Melamed Models of Translational Equivalence Table 2 A co-occurrence contingency table. Total cooc(., v) cooc(., —.v) cooc(., .) cooc(u,.v) cooc(-11, v) cooc(u, —.v) COOC(—V, Total cooc(-u, -) In informal experiments described elsewhere (Melamed 1995), I found that the G2 statistic suggested by Dunning (1993) slightly outperforms 02. Let the cells of the contingency</context>
<context position="63527" citStr="Gale and Church (1991)" startWordPosition="10358" endWordPosition="10361">,v) • lay judges would not consider instituer a correct French translation of appoint. In actual translations, however, when the object of the verb is commission, task force, panel, etc., English appoint is usually translated into French as instituer. To account for this kind of context-dependent translational equivalence, link types must be evaluated with respect to the bitext whence they were induced. I performed a post hoc evaluation of the link types produced by an earlier version of Method B (Melamed 1996b). The bitext used for this evaluation was the same aligned Hansards bitext used by Gale and Church (1991), except that I used only 300,000 aligned segment pairs to save time. The bitext was automatically pretokenized to delimit punctuation, English possessive pronouns, and French elisions. Morphological variants in both halves of the bitext were stemmed to a canonical form. The link types assigned by the converged model were sorted by the scores in Equation 36. Figure 7 shows the distribution of these scores on a log scale. The log scale helps to illustrate the plateaus in the curve. The longest plateau represents the set of word pairs that were linked once out of one co-occurrence (1/1) in the b</context>
<context position="65659" citStr="Gale and Church 1991" startWordPosition="10702" endWordPosition="10705"> Translational Equivalence Table 5 Lexicon coverage at three different minimum score thresholds. The bitext contained 41,028 different English words and 36,314 different French words, for a total of 77,342. Total English French Cutoff Minimum Lexicon Words Words Plateau Score Entries Represented % Represented 3/3 28 32,274 14,299 35 13,409 37 2/2 18 43,075 18,533 45 17,133 47 1/1 9 88,633 36,371 89 33,017 91 lexicons extracted from corpora, perfect coverage implies at least one entry containing each word in the corpus. One-sided variants, which consider only source words, have also been used (Gale and Church 1991). Table 5 shows both the marginal (one-sided) and the combined coverage at each of the three cutoff points. It also shows the absolute number of (non-NULL) entries in each of the three lexicons. Of course, the size of automatically induced lexicons depends on the size of the training bitext. Table 5 shows that, given a sufficiently large bitext, the method can automatically construct translation lexicons with as many entries as published bilingual dictionaries. The next task was to measure accuracy. It would have taken too long to evaluate every lexicon entry manually. Instead, I took five ran</context>
</contexts>
<marker>Gale, Church, 1991</marker>
<rawString>Gale, William A., and Kenneth W. Church. 1991. Identifying word correspondences in parallel texts. Proceedings of the DARPA SNL Workshop, pages 152-157, Asilomar, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Gale</author>
<author>Geoff Sampson</author>
</authors>
<title>Good-Turing frequency estimation without tears.</title>
<date>1995</date>
<journal>Journal of Quantitative Linguistics,</journal>
<pages>2--217</pages>
<publisher>Swets &amp; Zeitlinger Publishers,</publisher>
<location>Sassenheim, The Netherlands.</location>
<contexts>
<context position="36640" citStr="Gale and Sampson 1995" startWordPosition="5883" endWordPosition="5886">)B(cic + d,p2) (27) B(aia + b,p)B(cic + d,p) nk where B(kin,p) = () pk(1 p)n-k are binomial probabilities. The statistic uses maximum likelihood estimates for the probability parameters: p1 = bf P2 — c±cd&apos; P = a±ab±±cc-Fd&apos; G2 is easy to compute because the binomial coefficients in the numerator and in the denominator cancel each other out. All my methods initialize the parameters score(u,v) to G2(u, v), except that any pairing with NULL is initialized to an infinitesimal value. I have also found it useful to smooth the co-occurrence counts, e.g., using the Simple Good-Turing smoothing method (Gale and Sampson 1995), before computing G2. 5.1.2 Step 2: Estimation of Link Counts. To further reduce the complexity of estimating link counts, I employ the competitive linking algorithm, which is a greedy approximation to the MAP approximation: 1. Sort all the score(u,v) from highest to lowest. 2. For each score(u,v), in order: (a) If u (resp., v) is NULL, consider all tokens of v (resp., u) in the bitext linked to NULL. Otherwise, link all co-occurring token pairs (u, v) in the bitext. (D) The one-to-one assumption implies that linked words cannot be linked again. Therefore, remove all linked word tokens from t</context>
</contexts>
<marker>Gale, Sampson, 1995</marker>
<rawString>Gale, William A., and Geoff Sampson. 1995. Good-Turing frequency estimation without tears. Journal of Quantitative Linguistics, 2:217-237. Swets &amp; Zeitlinger Publishers, Sassenheim, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Djoerd Hiemstra</author>
</authors>
<title>Using Statistical Methods to Create a Bilingual Dictionary. Masters thesis,</title>
<date>1996</date>
<institution>University of Twente, The Netherlands.</institution>
<contexts>
<context position="28886" citStr="Hiemstra (1996)" startWordPosition="4625" endWordPosition="4626">nglish have very similar word order. A word order correlation bias, as well as the phrase structure biases in Brown et al.&apos;s (1993b) Models 4 and 5, would be less beneficial with noisier training bitexts or for language pairs with less similar word order. Nevertheless, one should use all available information sources, if one wants to build the best possible translation model. Section 5.3 suggests a way to add the word order correlation bias to the models presented in this article. 4.4 Reestimated Bag-to-Bag Translation Models At about the same time that I developed the models in this article, Hiemstra (1996) independently developed his own bag-to-bag model of translational equivalence. His model is also based on a one-to-one assumption, but it differs from my models in that it allows empty words in only one of the two bags, the one representing the shorter sentence. Thus, Hiemstra&apos;s model is similar to the first model in Section 5, but it has a little less explanatory power. Hiemstra&apos;s approach also differs from mine in his use of the Iterative Proportional Fitting Procedure (IPFP) (Deming and Stephan 1940) for parameter estimation. The IPFP is quite sensitive to initial conditions, so Hiemstra i</context>
</contexts>
<marker>Hiemstra, 1996</marker>
<rawString>Hiemstra, Djoerd. 1996. Using Statistical Methods to Create a Bilingual Dictionary. Masters thesis, University of Twente, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Djoerd Hiemstra</author>
</authors>
<title>Multilingual domain modeling in twenty-one: Automatic creation of a bi-directional translation lexicon from a parallel corpus.</title>
<date>1998</date>
<booktitle>In Proceedings of the Eighth meeting of Computational Linguistics in the Netherlands (CLIN),</booktitle>
<pages>41--58</pages>
<contexts>
<context position="29849" citStr="Hiemstra (1998)" startWordPosition="4775" endWordPosition="4776">le less explanatory power. Hiemstra&apos;s approach also differs from mine in his use of the Iterative Proportional Fitting Procedure (IPFP) (Deming and Stephan 1940) for parameter estimation. The IPFP is quite sensitive to initial conditions, so Hiemstra investigated a number of initialization options. Choosing the most advantageous, Hiemstra has published parts of the translational distributions of certain words, induced using both his method and Brown et al.&apos;s (1993b) Model 1 from the same training bitext. Subjective comparison of these examples suggests that Hiemstra&apos;s method is more accurate. Hiemstra (1998) has also evaluated the recall and precision of his method and of Model 1 on a small hand-constructed set of link tokens in a particular bitext. Model 1 fared worse, on average. 5. Parameter Estimation This section describes my methods for estimating the parameters of a symmetric wordto-word translation model from a bitext. For most applications, we are interested in estimating the probability trans (u, v) of jointly generating the pair of words (u, v). Unfortunately, these parameters cannot be directly inferred from a training bitext, because we don&apos;t know which words in one half of the bitex</context>
</contexts>
<marker>Hiemstra, 1998</marker>
<rawString>Hiemstra, Djoerd. 1998. Multilingual domain modeling in twenty-one: Automatic creation of a bi-directional translation lexicon from a parallel corpus. In Proceedings of the Eighth meeting of Computational Linguistics in the Netherlands (CLIN), pages 41-58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Akira Kumano</author>
<author>Hideki Hirakawa</author>
</authors>
<title>Building an MT dictionary from parallel texts based on linguistic and statistical information.</title>
<date>1994</date>
<booktitle>In Proceedings of the 15th International Conference on Computational Linguistics,</booktitle>
<pages>76--81</pages>
<location>Kyoto, Japan.</location>
<contexts>
<context position="18932" citStr="Kumano and Hirakawa 1994" startWordPosition="2991" endWordPosition="2994">dels introduced in Section 5. 226 Melamed Models of Translational Equivalence He nods his head II I hoche la tete Figure 1 nods and hoche often co-occur, as do nods and head. The direct association between nods and hoche, and the direct association between nods and head give rise to an indirect association between hoche and head. 4.2 Nonprobabilistic Translation Lexicons Many researchers have proposed greedy algorithms for estimating nonprobabilistic word-to-word translation models, also known as translation lexicons (e.g., Catizone, Russell, and Warwick 1989; Gale and Church 1991; Fung 1995; Kumano and Hirakawa 1994; Melamed 1995; Wu and Xia 1994). Most of these algorithms can be summarized as follows: 1. Choose a similarity function S between word types in Li and word types in L. 2. Compute association scores S(u, v) for a set of word type pairs (u, v) E (Li x £2) that occur in training data. 3. Sort the word pairs in descending order of their association scores. 4. Discard all word pairs for which S(u, v) is less than a chosen threshold. The remaining word pairs become the entries in the translation lexicon. The various proposals differ mainly in their choice of similarity function. Almost all the simi</context>
</contexts>
<marker>Kumano, Hirakawa, 1994</marker>
<rawString>Kumano, Akira, and Hideki Hirakawa. 1994. Building an MT dictionary from parallel texts based on linguistic and statistical information. In Proceedings of the 15th International Conference on Computational Linguistics, pages 76-81, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Scott McCarley</author>
</authors>
<title>Should we translate the documents or the queries in cross-language information retrieval?</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting,</booktitle>
<pages>208--214</pages>
<institution>College Park, MD. Association for Computational Linguistics.</institution>
<contexts>
<context position="5628" citStr="McCarley 1999" startWordPosition="835" endWordPosition="836"> to denote collections, including sequences and bags, and italics for scalar variables. I shall also distinguish between types and tokens by using bold font for the former and plain font for the latter. 2. Translation Model Decomposition There are two kinds of applications of translation models: those where word order plays a crucial role and those where it doesn&apos;t. Empirically estimated models of translational equivalence among word types can play a central role in both kinds of applications. Applications where word order is not essential include • cross-language information retrieval (e.g., McCarley 1999), • multilingual document filtering (e.g., Oard 1997), • computer-assisted language learning (e.g., Nerbonne et al. 1997), • certain machine-assisted translation tools (e.g., Macklovitch 1994; Melamed 1996a), • concordancing for bilingual lexicography (e.g., Catizone, Russell, and Warwick 1989; Gale and Church 1991), 222 Melamed Models of Translational Equivalence • corpus linguistics (e.g., Svartvik 1992), • &amp;quot;crummy&amp;quot; machine translation (e.g., Church and Hovy 1992; Resnik 1997). For these applications, empirically estimated models have a number of advantages over handcrafted models such as on</context>
</contexts>
<marker>McCarley, 1999</marker>
<rawString>McCarley, J. Scott. 1999. Should we translate the documents or the queries in cross-language information retrieval? In Proceedings of the 37th Annual Meeting, pages 208-214, College Park, MD. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elliott Macklovitch</author>
</authors>
<title>Using bi-textual alignment for translation validation: The TransCheck system.</title>
<date>1994</date>
<booktitle>In Proceedings of the 1st Conference of the Association for Machine Translation in the Americas,</booktitle>
<pages>157--168</pages>
<location>Columbia, MD.</location>
<contexts>
<context position="5819" citStr="Macklovitch 1994" startWordPosition="859" endWordPosition="860">r the latter. 2. Translation Model Decomposition There are two kinds of applications of translation models: those where word order plays a crucial role and those where it doesn&apos;t. Empirically estimated models of translational equivalence among word types can play a central role in both kinds of applications. Applications where word order is not essential include • cross-language information retrieval (e.g., McCarley 1999), • multilingual document filtering (e.g., Oard 1997), • computer-assisted language learning (e.g., Nerbonne et al. 1997), • certain machine-assisted translation tools (e.g., Macklovitch 1994; Melamed 1996a), • concordancing for bilingual lexicography (e.g., Catizone, Russell, and Warwick 1989; Gale and Church 1991), 222 Melamed Models of Translational Equivalence • corpus linguistics (e.g., Svartvik 1992), • &amp;quot;crummy&amp;quot; machine translation (e.g., Church and Hovy 1992; Resnik 1997). For these applications, empirically estimated models have a number of advantages over handcrafted models such as on-line versions of bilingual dictionaries. Two of the advantages are the possibility of better coverage and the possibility of frequent updates by nonexpert users to keep up with rapidly evolv</context>
</contexts>
<marker>Macklovitch, 1994</marker>
<rawString>Macklovitch, Elliott. 1994. Using bi-textual alignment for translation validation: The TransCheck system. In Proceedings of the 1st Conference of the Association for Machine Translation in the Americas, pages 157-168. Columbia, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>Automatic evaluation and uniform filter cascades for inducing N-best translation lexicons.</title>
<date>1995</date>
<booktitle>In Proceedings of the Third Workshop on Very Large Corpora,</booktitle>
<pages>184--198</pages>
<location>Cambridge, MA.</location>
<contexts>
<context position="18946" citStr="Melamed 1995" startWordPosition="2995" endWordPosition="2996"> 5. 226 Melamed Models of Translational Equivalence He nods his head II I hoche la tete Figure 1 nods and hoche often co-occur, as do nods and head. The direct association between nods and hoche, and the direct association between nods and head give rise to an indirect association between hoche and head. 4.2 Nonprobabilistic Translation Lexicons Many researchers have proposed greedy algorithms for estimating nonprobabilistic word-to-word translation models, also known as translation lexicons (e.g., Catizone, Russell, and Warwick 1989; Gale and Church 1991; Fung 1995; Kumano and Hirakawa 1994; Melamed 1995; Wu and Xia 1994). Most of these algorithms can be summarized as follows: 1. Choose a similarity function S between word types in Li and word types in L. 2. Compute association scores S(u, v) for a set of word type pairs (u, v) E (Li x £2) that occur in training data. 3. Sort the word pairs in descending order of their association scores. 4. Discard all word pairs for which S(u, v) is less than a chosen threshold. The remaining word pairs become the entries in the translation lexicon. The various proposals differ mainly in their choice of similarity function. Almost all the similarity functio</context>
<context position="35837" citStr="Melamed 1995" startWordPosition="5751" endWordPosition="5752">ependence between two word types can be estimated more robustly by considering the whole table. For example, Gale and Church (1991, 154) suggest that &amp;quot;02, a x2-like statistic, seems to be a particularly good choice because it makes good use of the off-diagonal cells&amp;quot; in the contingency table. 10 At least for my current very inefficient implementation. (24) 232 Melamed Models of Translational Equivalence Table 2 A co-occurrence contingency table. Total cooc(., v) cooc(., —.v) cooc(., .) cooc(u,.v) cooc(-11, v) cooc(u, —.v) COOC(—V, Total cooc(-u, -) In informal experiments described elsewhere (Melamed 1995), I found that the G2 statistic suggested by Dunning (1993) slightly outperforms 02. Let the cells of the contingency table be named as follows: a Now, G2(u, v) = —21og B(ala + b,pi)B(cic + d,p2) (27) B(aia + b,p)B(cic + d,p) nk where B(kin,p) = () pk(1 p)n-k are binomial probabilities. The statistic uses maximum likelihood estimates for the probability parameters: p1 = bf P2 — c±cd&apos; P = a±ab±±cc-Fd&apos; G2 is easy to compute because the binomial coefficients in the numerator and in the denominator cancel each other out. All my methods initialize the parameters score(u,v) to G2(u, v), except that </context>
</contexts>
<marker>Melamed, 1995</marker>
<rawString>Melamed, I. Dan. 1995. Automatic evaluation and uniform filter cascades for inducing N-best translation lexicons. In Proceedings of the Third Workshop on Very Large Corpora, pages 184-198, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>Automatic detection of omissions in translations.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics,</booktitle>
<pages>764--769</pages>
<location>Copenhagen, Denmark.</location>
<contexts>
<context position="5833" citStr="Melamed 1996" startWordPosition="861" endWordPosition="862">ranslation Model Decomposition There are two kinds of applications of translation models: those where word order plays a crucial role and those where it doesn&apos;t. Empirically estimated models of translational equivalence among word types can play a central role in both kinds of applications. Applications where word order is not essential include • cross-language information retrieval (e.g., McCarley 1999), • multilingual document filtering (e.g., Oard 1997), • computer-assisted language learning (e.g., Nerbonne et al. 1997), • certain machine-assisted translation tools (e.g., Macklovitch 1994; Melamed 1996a), • concordancing for bilingual lexicography (e.g., Catizone, Russell, and Warwick 1989; Gale and Church 1991), 222 Melamed Models of Translational Equivalence • corpus linguistics (e.g., Svartvik 1992), • &amp;quot;crummy&amp;quot; machine translation (e.g., Church and Hovy 1992; Resnik 1997). For these applications, empirically estimated models have a number of advantages over handcrafted models such as on-line versions of bilingual dictionaries. Two of the advantages are the possibility of better coverage and the possibility of frequent updates by nonexpert users to keep up with rapidly evolving vocabulari</context>
<context position="23553" citStr="Melamed 1996" startWordPosition="3770" endWordPosition="3771">owever, that Wu and Xia chose to weight their precision estimates by the probabilities attached to each entry: For example, if the translation set for English word detect has the two correct Chinese candidates with 0.533 probability and with 0.277 probability, and the incorrect translation with 0.190 probability, then we count this as 0.810 correct translations and 0.190 incorrect translations. (Wu and Xia 1994, 211) This is a reasonable evaluation method, but it is not comparable to methods that simply count each lexicon entry as either right or wrong (e.g., Daille, Gaussier, and Lange 1994; Melamed 1996b). A weighted precision estimate pays more attention to entries that are more frequent and hence easier to estimate. Therefore, weighted precision estimates are generally higher than unweighted ones. 4.3 Reestimated Sequence-to-Sequence Translation Models Most probabilistic translation model reestimation algorithms published to date are variations on the theme proposed by Brown et al. (1993b). These models involve conditional probabilities, but they can be compared to symmetric models if the latter are normalized by the appropriate marginal distribution. I shall review these models using the </context>
<context position="63420" citStr="Melamed 1996" startWordPosition="10342" endWordPosition="10343">long plateaus correspond to the most common combinations of links(u&apos;v) • 1/1,2/2, and 3/3. cooc(u,v) • lay judges would not consider instituer a correct French translation of appoint. In actual translations, however, when the object of the verb is commission, task force, panel, etc., English appoint is usually translated into French as instituer. To account for this kind of context-dependent translational equivalence, link types must be evaluated with respect to the bitext whence they were induced. I performed a post hoc evaluation of the link types produced by an earlier version of Method B (Melamed 1996b). The bitext used for this evaluation was the same aligned Hansards bitext used by Gale and Church (1991), except that I used only 300,000 aligned segment pairs to save time. The bitext was automatically pretokenized to delimit punctuation, English possessive pronouns, and French elisions. Morphological variants in both halves of the bitext were stemmed to a canonical form. The link types assigned by the converged model were sorted by the scores in Equation 36. Figure 7 shows the distribution of these scores on a log scale. The log scale helps to illustrate the plateaus in the curve. The lon</context>
</contexts>
<marker>Melamed, 1996</marker>
<rawString>Melamed, I. Dan. 1996a. Automatic detection of omissions in translations. In Proceedings of the 16th International Conference on Computational Linguistics, pages 764-769, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>Automatic construction of clean broad-coverage translation lexicons.</title>
<date>1996</date>
<booktitle>In Proceedings of the 2nd Conference of the Association for Machine Translation in the Americas,</booktitle>
<pages>125--134</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="5833" citStr="Melamed 1996" startWordPosition="861" endWordPosition="862">ranslation Model Decomposition There are two kinds of applications of translation models: those where word order plays a crucial role and those where it doesn&apos;t. Empirically estimated models of translational equivalence among word types can play a central role in both kinds of applications. Applications where word order is not essential include • cross-language information retrieval (e.g., McCarley 1999), • multilingual document filtering (e.g., Oard 1997), • computer-assisted language learning (e.g., Nerbonne et al. 1997), • certain machine-assisted translation tools (e.g., Macklovitch 1994; Melamed 1996a), • concordancing for bilingual lexicography (e.g., Catizone, Russell, and Warwick 1989; Gale and Church 1991), 222 Melamed Models of Translational Equivalence • corpus linguistics (e.g., Svartvik 1992), • &amp;quot;crummy&amp;quot; machine translation (e.g., Church and Hovy 1992; Resnik 1997). For these applications, empirically estimated models have a number of advantages over handcrafted models such as on-line versions of bilingual dictionaries. Two of the advantages are the possibility of better coverage and the possibility of frequent updates by nonexpert users to keep up with rapidly evolving vocabulari</context>
<context position="23553" citStr="Melamed 1996" startWordPosition="3770" endWordPosition="3771">owever, that Wu and Xia chose to weight their precision estimates by the probabilities attached to each entry: For example, if the translation set for English word detect has the two correct Chinese candidates with 0.533 probability and with 0.277 probability, and the incorrect translation with 0.190 probability, then we count this as 0.810 correct translations and 0.190 incorrect translations. (Wu and Xia 1994, 211) This is a reasonable evaluation method, but it is not comparable to methods that simply count each lexicon entry as either right or wrong (e.g., Daille, Gaussier, and Lange 1994; Melamed 1996b). A weighted precision estimate pays more attention to entries that are more frequent and hence easier to estimate. Therefore, weighted precision estimates are generally higher than unweighted ones. 4.3 Reestimated Sequence-to-Sequence Translation Models Most probabilistic translation model reestimation algorithms published to date are variations on the theme proposed by Brown et al. (1993b). These models involve conditional probabilities, but they can be compared to symmetric models if the latter are normalized by the appropriate marginal distribution. I shall review these models using the </context>
<context position="63420" citStr="Melamed 1996" startWordPosition="10342" endWordPosition="10343">long plateaus correspond to the most common combinations of links(u&apos;v) • 1/1,2/2, and 3/3. cooc(u,v) • lay judges would not consider instituer a correct French translation of appoint. In actual translations, however, when the object of the verb is commission, task force, panel, etc., English appoint is usually translated into French as instituer. To account for this kind of context-dependent translational equivalence, link types must be evaluated with respect to the bitext whence they were induced. I performed a post hoc evaluation of the link types produced by an earlier version of Method B (Melamed 1996b). The bitext used for this evaluation was the same aligned Hansards bitext used by Gale and Church (1991), except that I used only 300,000 aligned segment pairs to save time. The bitext was automatically pretokenized to delimit punctuation, English possessive pronouns, and French elisions. Morphological variants in both halves of the bitext were stemmed to a canonical form. The link types assigned by the converged model were sorted by the scores in Equation 36. Figure 7 shows the distribution of these scores on a log scale. The log scale helps to illustrate the plateaus in the curve. The lon</context>
</contexts>
<marker>Melamed, 1996</marker>
<rawString>Melamed, I. Dan. 1996b. Automatic construction of clean broad-coverage translation lexicons. In Proceedings of the 2nd Conference of the Association for Machine Translation in the Americas, pages 125-134, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>Models of co-occurrence. Institute for Research in Cognitive Science</title>
<date>1998</date>
<tech>Technical Report #98-05.</tech>
<institution>University of Pennsylvania,</institution>
<location>Philadelphia, PA.</location>
<contexts>
<context position="17356" citStr="Melamed (1998" startWordPosition="2737" endWordPosition="2738">. Different co-occurrence counting methods stem from different models of co-occurrence. A model of co-occurrence is a Boolean predicate, which indicates whether a given pair of word tokens co-occur in corresponding regions of the bitext space. Different models of co-occurrence are possible, depending on the kind of bitext map that is available, the language-specific information that is available, and the assumptions made about the nature of translational equivalence. All the translation models reviewed and introduced in this article can be based on any of the co-occurrence models described by Melamed (1998a). For expository purposes, however, I shall assume a boundarybased model of co-occurrence throughout this article. A boundary-based model of co-occurrence assumes that both halves of the bitext have been segmented into s segments, so that segment U, in one half of the bitext and segment V, in the other half are mutual translations, 1 &lt; i &lt; s. Under the boundary-based model of co-occurrence, there are several ways to compute co-occurrence counts cooc(u, v) between word types u and v. In the models of Brown, Della Pietra, Della Pietra, and Mercer (1993), reviewed in Section 4.3, cooc(u, E e(u)</context>
<context position="26661" citStr="Melamed 1998" startWordPosition="4269" endWordPosition="4270">n about segment lengths is not available, the only information available to initialize Model 1 is the co-occurrence counts. This property makes Model 1 an appropriate baseline for comparison to more sophisticated models that use other information sources, both in the work of Brown and his colleagues and in the work described here. 7 This expression is obtained by substituting Brown, Della Pietra, Della Pietra, and Mercer&apos;s (1993) Equation 17 into their Equation 14. 8 Or, equivalently, if the notion of segments were dispensed with altogether, as under the distance-based model of co-occurrence (Melamed 1998a). 229 Computational Linguistics Volume 26, Number 2 4.3.2 Word Order Correlation Biases. In any bitext, the positions of words relative to the true bitext map correlate with the positions of their translations. The correlation is stronger for language pairs with more similar word order. Brown et al. (1988) introduced the idea that this correlation can be encoded in translation model parameters. Dagan, Church, and Gale (1993) expanded on this idea by replacing Brown et al.&apos;s (1988) word alignment parameters, which were based on absolute word positions in aligned segments, with a much smaller </context>
<context position="53563" citStr="Melamed 1998" startWordPosition="8754" endWordPosition="8755">Connell 1993) or using relative metrics, such as perplexity with respect to other models (Brown et al. 1993b). Objective and more accurate tests can be carried out using a &amp;quot;gold standard.&amp;quot; I hired bilingual annotators to link roughly 16,000 corresponding words between on-line versions of the Bible in French and English. This bitext was selected to facilitate widespread use and standardization (see Melamed [1998c] for details). The entire Bible bitext comprised 29,614 verse pairs, of which 250 verse pairs were hand-linked using a specially developed annotation tool. The annotation style guide (Melamed 1998b) was based on the intuitions of the annotators, so it was not biased towards any particular translation model. The annotation was replicated five times by seven different annotators. Each of the four methods was used to estimate a word-to-word translation model from the 29,614 verse pairs in the Bible bitext. All methods were deemed to have converged when less than .0001 of the translational probability distribution changed from one iteration to the next. The links assigned by each of methods A, B, and C in the last iteration were normalized into joint probability distributions using Equatio</context>
</contexts>
<marker>Melamed, 1998</marker>
<rawString>Melamed, I. Dan. 1998a. Models of co-occurrence. Institute for Research in Cognitive Science Technical Report #98-05. University of Pennsylvania, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>Annotation style guide for the blinker project. Institute for Research in Cognitive Science</title>
<date>1998</date>
<tech>Technical Report #98-06.</tech>
<institution>University of Pennsylvania,</institution>
<location>Philadelphia, PA.</location>
<contexts>
<context position="17356" citStr="Melamed (1998" startWordPosition="2737" endWordPosition="2738">. Different co-occurrence counting methods stem from different models of co-occurrence. A model of co-occurrence is a Boolean predicate, which indicates whether a given pair of word tokens co-occur in corresponding regions of the bitext space. Different models of co-occurrence are possible, depending on the kind of bitext map that is available, the language-specific information that is available, and the assumptions made about the nature of translational equivalence. All the translation models reviewed and introduced in this article can be based on any of the co-occurrence models described by Melamed (1998a). For expository purposes, however, I shall assume a boundarybased model of co-occurrence throughout this article. A boundary-based model of co-occurrence assumes that both halves of the bitext have been segmented into s segments, so that segment U, in one half of the bitext and segment V, in the other half are mutual translations, 1 &lt; i &lt; s. Under the boundary-based model of co-occurrence, there are several ways to compute co-occurrence counts cooc(u, v) between word types u and v. In the models of Brown, Della Pietra, Della Pietra, and Mercer (1993), reviewed in Section 4.3, cooc(u, E e(u)</context>
<context position="26661" citStr="Melamed 1998" startWordPosition="4269" endWordPosition="4270">n about segment lengths is not available, the only information available to initialize Model 1 is the co-occurrence counts. This property makes Model 1 an appropriate baseline for comparison to more sophisticated models that use other information sources, both in the work of Brown and his colleagues and in the work described here. 7 This expression is obtained by substituting Brown, Della Pietra, Della Pietra, and Mercer&apos;s (1993) Equation 17 into their Equation 14. 8 Or, equivalently, if the notion of segments were dispensed with altogether, as under the distance-based model of co-occurrence (Melamed 1998a). 229 Computational Linguistics Volume 26, Number 2 4.3.2 Word Order Correlation Biases. In any bitext, the positions of words relative to the true bitext map correlate with the positions of their translations. The correlation is stronger for language pairs with more similar word order. Brown et al. (1988) introduced the idea that this correlation can be encoded in translation model parameters. Dagan, Church, and Gale (1993) expanded on this idea by replacing Brown et al.&apos;s (1988) word alignment parameters, which were based on absolute word positions in aligned segments, with a much smaller </context>
<context position="53563" citStr="Melamed 1998" startWordPosition="8754" endWordPosition="8755">Connell 1993) or using relative metrics, such as perplexity with respect to other models (Brown et al. 1993b). Objective and more accurate tests can be carried out using a &amp;quot;gold standard.&amp;quot; I hired bilingual annotators to link roughly 16,000 corresponding words between on-line versions of the Bible in French and English. This bitext was selected to facilitate widespread use and standardization (see Melamed [1998c] for details). The entire Bible bitext comprised 29,614 verse pairs, of which 250 verse pairs were hand-linked using a specially developed annotation tool. The annotation style guide (Melamed 1998b) was based on the intuitions of the annotators, so it was not biased towards any particular translation model. The annotation was replicated five times by seven different annotators. Each of the four methods was used to estimate a word-to-word translation model from the 29,614 verse pairs in the Bible bitext. All methods were deemed to have converged when less than .0001 of the translational probability distribution changed from one iteration to the next. The links assigned by each of methods A, B, and C in the last iteration were normalized into joint probability distributions using Equatio</context>
</contexts>
<marker>Melamed, 1998</marker>
<rawString>Melamed, I. Dan. 1998b. Annotation style guide for the blinker project. Institute for Research in Cognitive Science Technical Report #98-06. University of Pennsylvania, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>Manual annotation of translational equivalence: The blinker project. Institute for Research in Cognitive Science</title>
<date>1998</date>
<tech>Technical Report #98-07.</tech>
<contexts>
<context position="17356" citStr="Melamed (1998" startWordPosition="2737" endWordPosition="2738">. Different co-occurrence counting methods stem from different models of co-occurrence. A model of co-occurrence is a Boolean predicate, which indicates whether a given pair of word tokens co-occur in corresponding regions of the bitext space. Different models of co-occurrence are possible, depending on the kind of bitext map that is available, the language-specific information that is available, and the assumptions made about the nature of translational equivalence. All the translation models reviewed and introduced in this article can be based on any of the co-occurrence models described by Melamed (1998a). For expository purposes, however, I shall assume a boundarybased model of co-occurrence throughout this article. A boundary-based model of co-occurrence assumes that both halves of the bitext have been segmented into s segments, so that segment U, in one half of the bitext and segment V, in the other half are mutual translations, 1 &lt; i &lt; s. Under the boundary-based model of co-occurrence, there are several ways to compute co-occurrence counts cooc(u, v) between word types u and v. In the models of Brown, Della Pietra, Della Pietra, and Mercer (1993), reviewed in Section 4.3, cooc(u, E e(u)</context>
<context position="26661" citStr="Melamed 1998" startWordPosition="4269" endWordPosition="4270">n about segment lengths is not available, the only information available to initialize Model 1 is the co-occurrence counts. This property makes Model 1 an appropriate baseline for comparison to more sophisticated models that use other information sources, both in the work of Brown and his colleagues and in the work described here. 7 This expression is obtained by substituting Brown, Della Pietra, Della Pietra, and Mercer&apos;s (1993) Equation 17 into their Equation 14. 8 Or, equivalently, if the notion of segments were dispensed with altogether, as under the distance-based model of co-occurrence (Melamed 1998a). 229 Computational Linguistics Volume 26, Number 2 4.3.2 Word Order Correlation Biases. In any bitext, the positions of words relative to the true bitext map correlate with the positions of their translations. The correlation is stronger for language pairs with more similar word order. Brown et al. (1988) introduced the idea that this correlation can be encoded in translation model parameters. Dagan, Church, and Gale (1993) expanded on this idea by replacing Brown et al.&apos;s (1988) word alignment parameters, which were based on absolute word positions in aligned segments, with a much smaller </context>
<context position="53563" citStr="Melamed 1998" startWordPosition="8754" endWordPosition="8755">Connell 1993) or using relative metrics, such as perplexity with respect to other models (Brown et al. 1993b). Objective and more accurate tests can be carried out using a &amp;quot;gold standard.&amp;quot; I hired bilingual annotators to link roughly 16,000 corresponding words between on-line versions of the Bible in French and English. This bitext was selected to facilitate widespread use and standardization (see Melamed [1998c] for details). The entire Bible bitext comprised 29,614 verse pairs, of which 250 verse pairs were hand-linked using a specially developed annotation tool. The annotation style guide (Melamed 1998b) was based on the intuitions of the annotators, so it was not biased towards any particular translation model. The annotation was replicated five times by seven different annotators. Each of the four methods was used to estimate a word-to-word translation model from the 29,614 verse pairs in the Bible bitext. All methods were deemed to have converged when less than .0001 of the translational probability distribution changed from one iteration to the next. The links assigned by each of methods A, B, and C in the last iteration were normalized into joint probability distributions using Equatio</context>
</contexts>
<marker>Melamed, 1998</marker>
<rawString>Melamed, I. Dan. 1998c. Manual annotation of translational equivalence: The blinker project. Institute for Research in Cognitive Science Technical Report #98-07.</rawString>
</citation>
<citation valid="false">
<institution>University of Pennsylvania,</institution>
<location>Philadelphia, PA.</location>
<marker></marker>
<rawString>University of Pennsylvania, Philadelphia, PA.</rawString>
</citation>
<citation valid="false">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>To appear. Empirical Methods for Exploiting Parallel Texts,</title>
<publisher>MIT Press.</publisher>
<marker>Melamed, </marker>
<rawString>Melamed, I. Dan. To appear. Empirical Methods for Exploiting Parallel Texts, MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Nerbonne</author>
<author>Lauri Karttunen</author>
<author>Elena Paskaleva</author>
<author>Gabor Proszeky</author>
<author>Tiit Roosmaa</author>
</authors>
<title>Reading more into foreign languages.</title>
<date>1997</date>
<booktitle>In Proceedings of the 5th ACL Conference on Applied Natural Language Processing,</booktitle>
<pages>135--138</pages>
<location>Washington, DC.</location>
<contexts>
<context position="5749" citStr="Nerbonne et al. 1997" startWordPosition="849" endWordPosition="852">etween types and tokens by using bold font for the former and plain font for the latter. 2. Translation Model Decomposition There are two kinds of applications of translation models: those where word order plays a crucial role and those where it doesn&apos;t. Empirically estimated models of translational equivalence among word types can play a central role in both kinds of applications. Applications where word order is not essential include • cross-language information retrieval (e.g., McCarley 1999), • multilingual document filtering (e.g., Oard 1997), • computer-assisted language learning (e.g., Nerbonne et al. 1997), • certain machine-assisted translation tools (e.g., Macklovitch 1994; Melamed 1996a), • concordancing for bilingual lexicography (e.g., Catizone, Russell, and Warwick 1989; Gale and Church 1991), 222 Melamed Models of Translational Equivalence • corpus linguistics (e.g., Svartvik 1992), • &amp;quot;crummy&amp;quot; machine translation (e.g., Church and Hovy 1992; Resnik 1997). For these applications, empirically estimated models have a number of advantages over handcrafted models such as on-line versions of bilingual dictionaries. Two of the advantages are the possibility of better coverage and the possibilit</context>
</contexts>
<marker>Nerbonne, Karttunen, Paskaleva, Proszeky, Roosmaa, 1997</marker>
<rawString>Nerbonne, John, Lauri Karttunen, Elena Paskaleva, Gabor Proszeky, and Tiit Roosmaa. 1997. Reading more into foreign languages. In Proceedings of the 5th ACL Conference on Applied Natural Language Processing, pages 135-138, Washington, DC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas W Oard</author>
</authors>
<title>Adaptive filtering of multilingual document streams.</title>
<date>1997</date>
<booktitle>In Proceedings of the 5th RIAO Conference on Computer-Assisted Information Retrieval,</booktitle>
<pages>233--253</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="5681" citStr="Oard 1997" startWordPosition="842" endWordPosition="843"> italics for scalar variables. I shall also distinguish between types and tokens by using bold font for the former and plain font for the latter. 2. Translation Model Decomposition There are two kinds of applications of translation models: those where word order plays a crucial role and those where it doesn&apos;t. Empirically estimated models of translational equivalence among word types can play a central role in both kinds of applications. Applications where word order is not essential include • cross-language information retrieval (e.g., McCarley 1999), • multilingual document filtering (e.g., Oard 1997), • computer-assisted language learning (e.g., Nerbonne et al. 1997), • certain machine-assisted translation tools (e.g., Macklovitch 1994; Melamed 1996a), • concordancing for bilingual lexicography (e.g., Catizone, Russell, and Warwick 1989; Gale and Church 1991), 222 Melamed Models of Translational Equivalence • corpus linguistics (e.g., Svartvik 1992), • &amp;quot;crummy&amp;quot; machine translation (e.g., Church and Hovy 1992; Resnik 1997). For these applications, empirically estimated models have a number of advantages over handcrafted models such as on-line versions of bilingual dictionaries. Two of the </context>
</contexts>
<marker>Oard, 1997</marker>
<rawString>Oard, Douglas W. 1997. Adaptive filtering of multilingual document streams. In Proceedings of the 5th RIAO Conference on Computer-Assisted Information Retrieval, pages 233-253, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Evaluating multilingual gisting of Web pages.</title>
<date>1997</date>
<booktitle>In Proceedings of the AAAI Symposium on Natural Language Processing for the World Wide Web.</booktitle>
<location>Stanford, CA.</location>
<contexts>
<context position="6111" citStr="Resnik 1997" startWordPosition="899" endWordPosition="900">applications. Applications where word order is not essential include • cross-language information retrieval (e.g., McCarley 1999), • multilingual document filtering (e.g., Oard 1997), • computer-assisted language learning (e.g., Nerbonne et al. 1997), • certain machine-assisted translation tools (e.g., Macklovitch 1994; Melamed 1996a), • concordancing for bilingual lexicography (e.g., Catizone, Russell, and Warwick 1989; Gale and Church 1991), 222 Melamed Models of Translational Equivalence • corpus linguistics (e.g., Svartvik 1992), • &amp;quot;crummy&amp;quot; machine translation (e.g., Church and Hovy 1992; Resnik 1997). For these applications, empirically estimated models have a number of advantages over handcrafted models such as on-line versions of bilingual dictionaries. Two of the advantages are the possibility of better coverage and the possibility of frequent updates by nonexpert users to keep up with rapidly evolving vocabularies. A third advantage is that statistical models can provide more accurate information about the relative importance of different translations. Such information is crucial for applications such as cross-language information retrieval (CUR). In the vector space approach to CUR, </context>
</contexts>
<marker>Resnik, 1997</marker>
<rawString>Resnik, Philip. 1997. Evaluating multilingual gisting of Web pages. In Proceedings of the AAAI Symposium on Natural Language Processing for the World Wide Web. Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
<author>David Yarowsky</author>
</authors>
<title>A perspective on word sense disambiguation methods and their evaluation.</title>
<date>1997</date>
<booktitle>hi Proceedings of the SIGLEX Workshop on Tagging Text with Lexical Semantics,</booktitle>
<pages>79--86</pages>
<location>Washington, DC.</location>
<contexts>
<context position="41973" citStr="Resnik and Yarowsky 1997" startWordPosition="6750" endWordPosition="6753">be translated as peine than as phrase. &amp;quot;In the vicinity of&amp;quot; is one kind of collocation. Co-occurrence 11 The competitive linking algorithm can be generalized to stop searching before the number of possible assignments is reduced to one, at which point the link counts can be computed as probabilistically weighted averages over the remaining assignments. I use this method to resolve ties. 234 links(u,v) / cooc(u, v) Figure 2 The ratio links(u, v) I cooc (u, v), for several values of cooc(u, v). in bitext space is another kind of collocation. If each word&apos;s translation is treated as a sense tag (Resnik and Yarowsky 1997), then &amp;quot;translational&amp;quot; collocations have the unique property that the collocate and the word sense are one and the same! Method B exploits this property under the hypothesis that &amp;quot;one sense per collocation&amp;quot; holds for translational collocations. This hypothesis implies that if u and v are possible mutual translations, and a token u co-occurs with a token v in the bitext, then with very high probability the pair (u, v) was generated from the same concept and should be linked. To test this hypothesis, I ran one iteration of Method A on 300,000 aligned sentence pairs from the Canadian Hansards bit</context>
</contexts>
<marker>Resnik, Yarowsky, 1997</marker>
<rawString>Resnik, Philip, and David Yarowsky. 1997. A perspective on word sense disambiguation methods and their evaluation. hi Proceedings of the SIGLEX Workshop on Tagging Text with Lexical Semantics, pages 79-86, Washington, DC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Shieber</author>
</authors>
<title>Restricting the weak-generative capacity of synchronous tree-adjoining grammars.</title>
<date>1994</date>
<journal>Computational Intelligence,</journal>
<pages>10--4</pages>
<contexts>
<context position="12652" citStr="Shieber 1994" startWordPosition="1980" endWordPosition="1981">elamed Models of Translational Equivalence each i is distinct, and each j is distinct. The label pairs in a given assignment can be generated in any order, so there are 1! ways to generate an assignment of size 1.6 It follows that the probability of generating a pair of bags (B1, B2) with a particular assignment A of size 1 is Pr(Bi, A, B21/, C , trans) = Pr (1) 1! ri E Pr(C)trans(tii, Ari1C). (10) CEC The above equation holds regardless of how we represent concepts. There are many plausible representations, such as pairs of trees from synchronous tree adjoining grammars (Abeille et al. 1990; Shieber 1994; Candito 1998), lexical conceptual structures (Dorr 1992) and WordNet synsets (Fellbaum 1998; Vossen 1998). Of course, for a representation to be used, a method must exist for estimating its distribution in data. A useful representation will reduce the entropy of the trans distribution, which is conditioned on the concept distribution as shown in Equation 10. This topic is beyond the scope of this article, however. I mention it only to show how the models presented here may be used as building blocks for models that are more psycholinguistically sophisticated. To make the translation model es</context>
</contexts>
<marker>Shieber, 1994</marker>
<rawString>Shieber, Stuart. 1994. Restricting the weak-generative capacity of synchronous tree-adjoining grammars. Computational Intelligence, 10(4):371-385.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Simard</author>
<author>George F Foster</author>
<author>Francois Perrault</author>
</authors>
<title>TransSearch: A bilingual concordance tool. Centre d&apos;innovation en technologies de l&apos;information,</title>
<date>1993</date>
<location>Laval, Canada.</location>
<marker>Simard, Foster, Perrault, 1993</marker>
<rawString>Simard, Michel, George F. Foster, and Francois Perrault. 1993. TransSearch: A bilingual concordance tool. Centre d&apos;innovation en technologies de l&apos;information, Laval, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Svartvik</author>
</authors>
<date>1992</date>
<booktitle>Directions in Corpus Linguistics. Mouton de Gruyter,</booktitle>
<location>Berlin.</location>
<contexts>
<context position="6037" citStr="Svartvik 1992" startWordPosition="888" endWordPosition="889">ional equivalence among word types can play a central role in both kinds of applications. Applications where word order is not essential include • cross-language information retrieval (e.g., McCarley 1999), • multilingual document filtering (e.g., Oard 1997), • computer-assisted language learning (e.g., Nerbonne et al. 1997), • certain machine-assisted translation tools (e.g., Macklovitch 1994; Melamed 1996a), • concordancing for bilingual lexicography (e.g., Catizone, Russell, and Warwick 1989; Gale and Church 1991), 222 Melamed Models of Translational Equivalence • corpus linguistics (e.g., Svartvik 1992), • &amp;quot;crummy&amp;quot; machine translation (e.g., Church and Hovy 1992; Resnik 1997). For these applications, empirically estimated models have a number of advantages over handcrafted models such as on-line versions of bilingual dictionaries. Two of the advantages are the possibility of better coverage and the possibility of frequent updates by nonexpert users to keep up with rapidly evolving vocabularies. A third advantage is that statistical models can provide more accurate information about the relative importance of different translations. Such information is crucial for applications such as cross-l</context>
</contexts>
<marker>Svartvik, 1992</marker>
<rawString>Svartvik, Jan. 1992. Directions in Corpus Linguistics. Mouton de Gruyter, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Vogel</author>
<author>Hermann Ney</author>
<author>Christoph Tillmann</author>
</authors>
<title>HMM-based word alignment in statistical translation.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics.</booktitle>
<location>Copenhagen, Denmark.</location>
<marker>Vogel, Ney, Tillmann, 1996</marker>
<rawString>Vogel, Stephan, Hermann Ney, and Christoph Tillmann. 1996. HMM-based word alignment in statistical translation. In Proceedings of the 16th International Conference on Computational Linguistics. Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<date>1998</date>
<booktitle>Eurowordnet: A Multilingual Database with Lexical Semantic Networks.</booktitle>
<editor>Piek, Vossen, editor.</editor>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="29849" citStr="(1998)" startWordPosition="4776" endWordPosition="4776">xplanatory power. Hiemstra&apos;s approach also differs from mine in his use of the Iterative Proportional Fitting Procedure (IPFP) (Deming and Stephan 1940) for parameter estimation. The IPFP is quite sensitive to initial conditions, so Hiemstra investigated a number of initialization options. Choosing the most advantageous, Hiemstra has published parts of the translational distributions of certain words, induced using both his method and Brown et al.&apos;s (1993b) Model 1 from the same training bitext. Subjective comparison of these examples suggests that Hiemstra&apos;s method is more accurate. Hiemstra (1998) has also evaluated the recall and precision of his method and of Model 1 on a small hand-constructed set of link tokens in a particular bitext. Model 1 fared worse, on average. 5. Parameter Estimation This section describes my methods for estimating the parameters of a symmetric wordto-word translation model from a bitext. For most applications, we are interested in estimating the probability trans (u, v) of jointly generating the pair of words (u, v). Unfortunately, these parameters cannot be directly inferred from a training bitext, because we don&apos;t know which words in one half of the bitex</context>
</contexts>
<marker>1998</marker>
<rawString>Piek, Vossen, editor. 1998. Eurowordnet: A Multilingual Database with Lexical Semantic Networks. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John S White</author>
<author>Theresa A O&apos;Connell</author>
</authors>
<title>Evaluation of machine translation.</title>
<date>1993</date>
<booktitle>In Proceedings of the ARPA HLT Workshop,</booktitle>
<pages>206--210</pages>
<location>Princeton, NJ.</location>
<contexts>
<context position="52964" citStr="White and O&apos;Connell 1993" startWordPosition="8658" endWordPosition="8661">-Phrase punctuation, such as commas and colons SCM Subordinate Clause Markers, such as &amp;quot; and ( SYM Symbols, such as - and * NU the NULL word, in a class by itself C Content words: nouns, adjectives, adverbs, non-auxiliary verbs F all other words, i.e., function words method is the list of function words in class F. Certainly, more sophisticated word classification methods could produce better models, but even the simple classification in Table 4 should suffice to demonstrate the method&apos;s potential. 6.1.1 Experiment 1. Until now, translation models have been evaluated either subjectively (e.g. White and O&apos;Connell 1993) or using relative metrics, such as perplexity with respect to other models (Brown et al. 1993b). Objective and more accurate tests can be carried out using a &amp;quot;gold standard.&amp;quot; I hired bilingual annotators to link roughly 16,000 corresponding words between on-line versions of the Bible in French and English. This bitext was selected to facilitate widespread use and standardization (see Melamed [1998c] for details). The entire Bible bitext comprised 29,614 verse pairs, of which 250 verse pairs were hand-linked using a specially developed annotation tool. The annotation style guide (Melamed 1998b</context>
</contexts>
<marker>White, O&apos;Connell, 1993</marker>
<rawString>White, John S., and Theresa A. O&apos;Connell. 1993. Evaluation of machine translation. In Proceedings of the ARPA HLT Workshop, pages 206-210, Princeton, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
<author>Xuanyin Xia</author>
</authors>
<title>Learning an English-Chinese lexicon from a parallel corpus.</title>
<date>1994</date>
<booktitle>In Proceedings of the First Conference of the Association for Machine Translation in the Americas,</booktitle>
<pages>206--213</pages>
<location>Columbia, MD.</location>
<contexts>
<context position="18964" citStr="Wu and Xia 1994" startWordPosition="2997" endWordPosition="3000">d Models of Translational Equivalence He nods his head II I hoche la tete Figure 1 nods and hoche often co-occur, as do nods and head. The direct association between nods and hoche, and the direct association between nods and head give rise to an indirect association between hoche and head. 4.2 Nonprobabilistic Translation Lexicons Many researchers have proposed greedy algorithms for estimating nonprobabilistic word-to-word translation models, also known as translation lexicons (e.g., Catizone, Russell, and Warwick 1989; Gale and Church 1991; Fung 1995; Kumano and Hirakawa 1994; Melamed 1995; Wu and Xia 1994). Most of these algorithms can be summarized as follows: 1. Choose a similarity function S between word types in Li and word types in L. 2. Compute association scores S(u, v) for a set of word type pairs (u, v) E (Li x £2) that occur in training data. 3. Sort the word pairs in descending order of their association scores. 4. Discard all word pairs for which S(u, v) is less than a chosen threshold. The remaining word pairs become the entries in the translation lexicon. The various proposals differ mainly in their choice of similarity function. Almost all the similarity functions in the literatu</context>
<context position="22529" citStr="Wu and Xia (1994)" startWordPosition="3601" endWordPosition="3604">1991) have shown that entries at the very top of the list can be over 98% correct. Their algorithm gleaned lexicon entries for about 61% of the word tokens in a sample of 800 English sentences. To obtain 98% precision, their algorithm selected only entries for which it had high confidence that the association score was high. These would be the word pairs that co-occur most frequently. A random sample of 800 sentences from the same corpus showed that 61% of the word tokens, where the tokens are of the most frequent types, represent 4.5% of all the word types. A similar strategy was employed by Wu and Xia (1994) and by Fung (1995). Fung skimmed off the top 23.8% of the noun-noun entries in her lexicon to achieve a precision of 71.6%. Wu and Xia have reported automatic acquisition of 6,517 lexicon entries from a 3.3-million-word corpus, with a precision of 86%. The first 3.3 million word tokens in an English corpus from a similar genre contained 33,490 different word types, suggesting a recall of roughly 19%. Note, however, that Wu and Xia chose to weight their precision estimates by the probabilities attached to each entry: For example, if the translation set for English word detect has the two corre</context>
</contexts>
<marker>Wu, Xia, 1994</marker>
<rawString>Wu, Dekai, and Xuanyin Xia. 1994. Learning an English-Chinese lexicon from a parallel corpus. In Proceedings of the First Conference of the Association for Machine Translation in the Americas, pages 206-213, Columbia, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>One sense per collocation.</title>
<date>1993</date>
<booktitle>In Proceedings of the DARPA Workshop on Human Language Technology,</booktitle>
<pages>266--271</pages>
<location>Princeton, NJ.</location>
<contexts>
<context position="40687" citStr="Yarowsky (1993" startWordPosition="6534" endWordPosition="6535">he distribution of co-occurrence counts. Melamed (to appear) explores these properties in greater depth. 5.1.3 Step 3: Reestimation of the Model Parameters. Method A reestimates the score parameters as the logarithm of the trans parameters. The competitive linking algorithm only cares about the relative magnitudes of the various score(u, v). However, Equation 26 is a sum rather than a product, so I scale the trans parameters logarithmically, to be consistent with its probabilistic interpretation: scoreA(u,v) = log trans(u,v) (28) 5.2 Method B: Improved Estimation Using an Explicit Noise Model Yarowsky (1993, 271) has shown that &amp;quot;for several definitions of sense and collocation, an ambiguous word has only one sense in a given collocation with a probability of 90-99%.&amp;quot; In other words, a single contextual clue can be a highly reliable indicator of a word&apos;s sense. One of the definitions of &amp;quot;sense&amp;quot; studied by Yarowsky was a word token&apos;s translation in the other half of a bitext. For example, the English word sentence may be considered to have two senses, corresponding to its French translations peine (judicial sentence) and phrase (grammatical sentence). If a token of sentence occurs in the vicinity </context>
</contexts>
<marker>Yarowsky, 1993</marker>
<rawString>Yarowsky, David. 1993. One sense per collocation. In Proceedings of the DARPA Workshop on Human Language Technology, pages 266-271, Princeton, NJ.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>