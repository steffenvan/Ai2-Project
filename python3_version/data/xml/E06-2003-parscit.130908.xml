<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001011">
<title confidence="0.9974945">
LinguaStream: An Integrated Environment
for Computational Linguistics Experimentation
</title>
<author confidence="0.764626">
Fr´ed´erik Bilhaut
</author>
<affiliation confidence="0.683628">
GREYC-CNRS
University of Caen
</affiliation>
<email confidence="0.995057">
fbilhaut@info.unicaen.fr
</email>
<author confidence="0.399104">
Antoine Widl¨ocher
</author>
<affiliation confidence="0.512559">
GREYC-CNRS
University of Caen
</affiliation>
<email confidence="0.996896">
awidloch@info.unicaen.fr
</email>
<sectionHeader confidence="0.995606" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999626833333333">
By presenting the LinguaStream plat-
form, we introduce different methodolog-
ical principles and analysis models, which
make it possible to build hybrid experi-
mental NLP systems by articulating cor-
pus processing tasks.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999858169230769">
Several important tendencies have been emerging
recently in the NLP community. First of all, work
on corpora tends to become the norm, which con-
stitutes a fruitful convergence area between task-
driven, computational approaches and descriptive
linguistic ones. On corpora validation becomes
more and more important for theoretical models,
and the accuracy of these models can be evalu-
ated either with regard to their ability to account
for the reality of a given corpus (pursuing descrip-
tive aims), either with regard to their ability to
analyse it accurately (pursuing operational aims).
From this point of view, important questions have
to be considered regarding which methods should
be used in order to project efficiently and accu-
rately linguistic models on corpora.
It is indeed less and less appropriate to consider
corpora as raw materials to which models and pro-
cesses could be immediately applicable. On the
contrary, the multiplicity of approaches, would
they be lexical, syntactical, semantic, rhetorical
or pragmatical, would they focus on one of these
dimensions or cross them, raises questions about
how these different levels can be articulated within
operational models, and how the related process-
ing systems can be assembled, applied on a cor-
pus, and evaluated within an experimental process.
New NLP concerns confirm these needs: re-
cent works on automatic discourse structure anal-
ysis, for example regarding thematic structures or
rhetorical ones (Bilhaut, 2005; Widl¨ocher, 2004),
show that the results obtained from lower-grained
analysers (such as part-of-speech taggers or lo-
cal semantics analysers) can be successfully ex-
ploited to perform higher-grained analyses. In-
deed, such works rely on non-trivial process-
ing streams, where several modules collaborate
basing on the principles of incremental enrich-
ment of documents and progressive abstraction
from surface forms. The LinguaStream plat-
form (Widl¨ocher and Bilhaut, 2005; Ferrari et al.,
2005), which is presented here, promotes and fa-
cilitates such practices. It allows complex pro-
cessing streams to be designed and evaluated, as-
sembling analysis components of various types
and levels: part-of-speech, syntax, semantics, dis-
course or statistical. Each stage of the processing
stream discovers and produces new information,
on which the subsequent steps can rely. At the end
of the stream, various tools allow analysed docu-
ments and their annotations to be conveniently vi-
sualised. The uses of the platform range from cor-
pora exploration to the development of fully oper-
ational automatic analysers.
Other platform or tools pursue similar goals.
We share some principles with GATE (Cunning-
ham et al., 2002), HoG (Callmeier et al., 2004)
and NOOJ1 (Muller et al., 2004), but one impor-
tant difference is that the LinguaStream platform
promotes the combination of purely declarative
formalisms (when GATE is mostly based on the
JAPE language and NOOJ focuses on a unique
formalism), and allows processing streams to be
designed graphically as complex graphs (when
GATE relies on the pipeline paradigm). Also, the
</bodyText>
<footnote confidence="0.976009">
1Formerly known as INTEX.
</footnote>
<page confidence="0.998672">
95
</page>
<figureCaption confidence="0.999174">
Figure 1: LinguaStream Integrated Environment
</figureCaption>
<bodyText confidence="0.9998457">
low-level architecture of LinguaStream is compa-
rable to the HoG middleware, but we are more
interested in higher-level aspects such as analy-
sis models and methodological concerns. Finally,
when other platforms usually enforce the use of a
dedicated document format, LinguaStream is able
to process any XML document. On the other hand,
LinguaStream is more targeted to experimentation
tasks on low amounts of data, when tools such as
GATE or NOOJ allow to process larger ones.
</bodyText>
<sectionHeader confidence="0.82989" genericHeader="method">
2 The LinguaStream Platform
</sectionHeader>
<bodyText confidence="0.999958564102564">
LinguaStream is an integrated experimentation en-
vironment targeted to researchers in NLP. It al-
lows complex experiments on corpora to be re-
alised conveniently, using various declarative for-
malisms. Without appropriate tools, the devel-
opment costs that are induced by each new ex-
periment become a considerable obstacle to the
experimental approach. In order to address this
problem, LinguaStream facilitates the realisation
of complex processes while calling for minimal
technical skills.
Its integrated environment allows processing
streams to be assembled visually, picking individ-
ual components in a ”palette” (the standard set
contains about fifty components, and is easily ex-
tensible using a Java API, a macro-component sys-
tem, and templates). Some components are specif-
ically targeted to NLP, while others solve various
issues related to document engineering (especially
to XML processing). Other components are to
be used in order to perform computations on the
annotations produced by the analysers, to visu-
alise annotated documents, to generate charts, etc.
Each component has a set of parameters that al-
low their behaviour to be adapted, and a set of in-
put and/or output sockets, that are to be connected
using pipes in order to obtain the desired process-
ing stream (see figure 2). Annotations made on a
single document are organised in independent lay-
ers and may overlap. Thus, concurrent and am-
biguous annotations may be represented in order
to be solved afterwards, by subsequent analysers.
The platform is systematically based on XML rec-
ommendations and tools, and is able to process
any file in this format while preserving its original
structure. When running a processing stream, the
platform takes care of the scheduling of sub-tasks,
and various tools allow the results to be visualised
conveniently.
</bodyText>
<subsectionHeader confidence="0.778673">
Fundamental principles
</subsectionHeader>
<bodyText confidence="0.999990606060606">
First of all, the platform makes use of declarative
representations, as often as possible, in order to
define processing modules as well as their connec-
tions. Thus, available formalisms allow linguistic
knowledge to be directly “transcribed” and used.
Involved procedural mechanisms, committed to
the platform, can be ignored. In this way, given
rules are both descriptive (they provide a formal
representation for a linguistic phenomenon) and
operative (they can be considered as instructions
to drive a computational process).
Moreover, the platform takes advantage of the
complementarity of analysis models, rather than
considering one of them as “omnipotent”, that
is to say, as able to express all constraint types.
We indeed rely on the assumption that a complex
analyser can successively adopt several points of
view on the same linguistic data. Different for-
malisms and analysis models allow these differ-
ent points of view. In a same processing stream,
we can successively make use of regular expres-
sions at the morphologic level, a local unification
grammar at the phrasal level, finite state trans-
ducer at sentential level and constraint grammar
for discourse level analysis. The interoperabil-
ity between analysis models and the communica-
tion between components are ensured by a unified
representation of markups and annotations. The
latter are uniformly represented by feature sets,
which are commonly used in linguistics and NLP,
and allow rich and structured information repre-
sentation. Every component can produce its own
markup using preliminary markups and annota-
</bodyText>
<page confidence="0.959576">
96
</page>
<bodyText confidence="0.999958953488372">
tions. Available formalisms make it possible to ex-
press constraints on these annotations by means of
unification. Thereby, the platform promotes pro-
gressive abstraction from surface forms. Inso-
far as each step can access to annotations produced
upstream, high level analysers often only use these
annotations, ignoring raw textual data.
Another fundamental aspect consists in the
variability of analysis grain between different
analysis steps. Many analysis models require a
minimal grain to be defined, called token. For ex-
ample, formalisms such as grammar or transduc-
ers need a textual unit (such as character or word)
to which patterns are applied. When a component
requires such a minimal grain, the platform allows
to define locally the unit types which have to be
considered as tokens. Any previously marked unit
can be used as such: usual tokenisation in words
or any other beforehand analysed elements (syn-
tagms, sentences, paragraphs...). The minimal unit
may differ from an analysis step to another and the
scope of the available analysis models is conse-
quently increased. In addition, each analysis mod-
ule indicates antecedent markups to which it refers
and considers as relevant. Other markups can be
ignored and it makes it possible to partially rise
above textual linearity. Combining these function-
alities, it is possible to define different points of
view on the document for each analysis step.
The modularity of processing streams pro-
motes the reusability of components in various
contexts: a given module, developed for a first
processing stream may be used in other ones. In
addition, every stream may be used as a single
component, called macro-component, in a higher
level stream. Moreover, for a given stream, each
component may be replaced by any other func-
tionally equivalent component. For a given sub-
task, a rudimentary prototype may in fine be re-
placed by an equivalent, fully operational, compo-
nent. Thus, it is possible to compare processing
results in rigourously similar contexts, which is a
necessary condition for relevant comparisons.
</bodyText>
<figureCaption confidence="0.99463">
Figure 2: A Simple Processing Stream
</figureCaption>
<subsectionHeader confidence="0.868432">
Analysis models
</subsectionHeader>
<bodyText confidence="0.999931695652174">
We indicated above some of the components
which may be used in a processing stream. Among
those which are especially dedicated to NLP, two
categories have to be distinguished. Some of them
consist in ready-made analysers linked to a spe-
cific task. For example, morpho-syntactic tag-
ging (an interface with TreeTagger is provided by
default) consists in such a task. Although some
parameters allow to adapt the associated compo-
nents to the task (tag set for a given language...),
it is impossible to fundamentally modify their be-
haviour. Others, on the contrary, provide an anal-
ysis model, that is to say, firstly, a formalism
for representing linguistic constraints by means
of which the user can express expected process-
ing. This formalism will usually rely on a spe-
cific operational model. These analysis models
allow constraints to be expressed, on surface form
as well as on annotations produced by the prece-
dent analysers. All annotations are represented by
feature sets and the constraints are encoded by uni-
fication on these structures. Some of the available
systems follow.
</bodyText>
<listItem confidence="0.756675461538461">
• A system called EDCG (Extended-DCG) al-
lows local unification grammars to be writ-
ten, using the DCG (Definite Clause Gram-
mars) syntax of Prolog. Such a grammar
can be described in a pure declarative manner
even if the features of the logical language
may be accessed by expert users.
• A system called MRE (Macro-Regular-
Expressions) allows patterns to be described
using finite state transducers on surface
forms and previously computed annotations.
Its syntax is similar to regular expressions
commonly used in NLP. However, this for-
malism not only considers characters and
words, but may apply to any previously de-
limited textual unit.
• Another descriptive, prescriptive and declar-
ative formalism called CDML (Constraint-
Based Discourse Modelling Language) al-
lows a constraint-based approach of formal
description and computation of discourse
structure. It considers both textual segments
and discourse relations, and relies on expres-
sion and satisfaction of a set of primitive con-
straints (presence, size, boundaries...) on pre-
viously computed annotations.
</listItem>
<page confidence="0.981491">
97
</page>
<listItem confidence="0.5882995">
• A semantic lexicon marker, a configurable
tokenizer (using regular expressions at the
character level), a system allowing linguistic
units to be delimited relying on the XML tags
that are available in the original document,
etc.
</listItem>
<sectionHeader confidence="0.977532" genericHeader="conclusions">
3 Conclusion
</sectionHeader>
<bodyText confidence="0.714426444444444">
LinguaStream is used in several research and edu-
cational projects:
• Works on discourse semantics: discourse
framing (Ho-Dac and Laignelet, 2005; Bil-
haut et al., 2003b), thematic (Bilhaut, 2005;
Bilhaut and Enjalbert, 2005) and rhetorical
(Widl¨ocher, 2004) structures with a view to
information retrieval and theoretical linguis-
tics.
</bodyText>
<listItem confidence="0.9014312">
• Works on Geographical Information, as in
the GeoSem project (Bilhaut et al., 2003a;
Widl¨ocher et al., 2004), or in another research
project (Marquesuz`a et al., 2005).
• TCAN project: Temporal intervals and appli-
</listItem>
<bodyText confidence="0.902708">
cations to text linguistics, CNRS interdisci-
plinary project.
• The platform is also used for other research
or teaching purposes in several French lab-
oratories (including GREYC, ERSS and LI-
UPPA) in the fields of corpus linguistics, nat-
ural language processing and text mining.
More information can be obtained from the ded-
icated web site2.
</bodyText>
<sectionHeader confidence="0.998142" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.988673652173913">
Fr´ed´erik Bilhaut and Patrice Enjalbert. 2005. Dis-
course thematic organisation reveals domain knowl-
edge structure. In Proceedings of the Conference
Recent Advances in Natural Language Processing,
Pune, India.
Fr´ed´erik Bilhaut, Thierry Charnois, Patrice Enjalbert,
and Yann Mathet. 2003a. Passage extraction in geo-
graphical documents. In Proceedings of New Trends
in Intelligent Information Processing and Web Min-
ing, Zakopane, Poland.
Fr´ed´erik Bilhaut, Lydia-Mai Ho-Dac, Andr´ee Bo-
rillo, Thierry Charnois, Patrice Enjalbert, Anne Le
Draoulec, Yann Mathet, H´el`ene Miguet, Marie-
Paule P´ery-Woodley, and Laure Sarda. 2003b.
2http://www.linguastream.org
Indexation discursive pour la navigation intradoc-
umentaire : cadres temporels et spatiaux dans
l’information g´eographique. In Actes de Traitement
Automatique du Langage Naturel (TALN), Batz-sur-
Mer, France.
Fr´ed´erik Bilhaut. 2005. Composite topics in discourse.
In Proceedings of the Conference Recent Advances
in Natural Language Processing, Borovets, Bul-
garia.
Ulrich Callmeier, Andreas Eisele, Ulrich Sch¨afer, and
Melanie Siegel. 2004. The DeepThought Core Ar-
chitecture Framework. In Proceedings of the 4th In-
ternational Conference on Language Resources and
Evaluation, Lisbon, Portugal.
Hamish Cunningham, Diana Maynard, Kalina
Bontcheva, and Valentin Tablan. 2002. GATE:
A framework and graphical development environ-
ment for robust NLP tools and applications. In
Proceedings of the 40th Anniversary Meeting of the
Association for Computational Linguistics.
St´ephane Ferrari, Fr´ef´erik Bilhaut, Antoine Widl¨ocher,
and Marion Laignelet. 2005. Une plate-forme
logicielle et une d´emarche pour la validation de
ressources linguistiques sur corpus : application a`
l’´evaluation de la d´etection automatique de cadres
temporels. In Actes des 4`emes Journ´ees de Linguis-
tique de Corpus (JLC), Lorient, France.
Lydia-Mai Ho-Dac and Marion Laignelet. 2005. Tem-
poral structure and thematic progression: A case
study on french corpora. In Symposium on the
Exploration and Modelling of Meaning (SEM’O5),
Biarritz, France.
Christophe Marquesuz`a, Patrick Etcheverry, and Julien
Lesbegueries. 2005. Exploiting geospatial mark-
ers to explore and resocialize localized documents.
In Proceedings of the 1st Conference on GeoSpatial
Semantics (GEOS), Mexico City.
Claude Muller, Jean Royaute, and Max Silberztein, edi-
tors. 2004. INTEX pour la Linguistique et le Traite-
ment Automatique des Langues. Presses Universi-
taires de Franche-Comt´e.
Antoine Widl¨ocher and Fr´ed´erik Bilhaut. 2005. La
plate-forme linguastream : un outil d’exploration
linguistique sur corpus. In Actes de la 12e
Conf´erence Traitement Automatique du Langage
Naturel (TALN), Dourdan, France.
Antoine Widl¨ocher, Eric Faurot, and Fr´ed´erik Bilhaut.
2004. Multimodal indexation of contrastive struc-
tures in geographical documents. In Proceedings
of Recherche d’Information Assist´ee par Ordinateur
(RIAO), Avignon, France.
Antoine Widl¨ocher. 2004. Analyse macro-
s´emantique: vers une analyse rh´etorique du dis-
cours. In Actes de RECITAL’04, F`es, Maroc.
</reference>
<page confidence="0.996187">
98
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.877698">
<title confidence="0.9997905">LinguaStream: An Integrated Environment for Computational Linguistics Experimentation</title>
<author confidence="0.999513">Fr´ed´erik Bilhaut</author>
<affiliation confidence="0.980145">GREYC-CNRS University of Caen</affiliation>
<email confidence="0.993769">fbilhaut@info.unicaen.fr</email>
<author confidence="0.997592">Antoine Widl¨ocher</author>
<affiliation confidence="0.9709165">GREYC-CNRS University of Caen</affiliation>
<email confidence="0.987106">awidloch@info.unicaen.fr</email>
<abstract confidence="0.998659">By presenting the LinguaStream platform, we introduce different methodological principles and analysis models, which make it possible to build hybrid experimental NLP systems by articulating corpus processing tasks.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Fr´ed´erik Bilhaut</author>
<author>Patrice Enjalbert</author>
</authors>
<title>Discourse thematic organisation reveals domain knowledge structure.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference Recent Advances in Natural Language Processing,</booktitle>
<location>Pune, India.</location>
<contexts>
<context position="12300" citStr="Bilhaut and Enjalbert, 2005" startWordPosition="1892" endWordPosition="1895">se relations, and relies on expression and satisfaction of a set of primitive constraints (presence, size, boundaries...) on previously computed annotations. 97 • A semantic lexicon marker, a configurable tokenizer (using regular expressions at the character level), a system allowing linguistic units to be delimited relying on the XML tags that are available in the original document, etc. 3 Conclusion LinguaStream is used in several research and educational projects: • Works on discourse semantics: discourse framing (Ho-Dac and Laignelet, 2005; Bilhaut et al., 2003b), thematic (Bilhaut, 2005; Bilhaut and Enjalbert, 2005) and rhetorical (Widl¨ocher, 2004) structures with a view to information retrieval and theoretical linguistics. • Works on Geographical Information, as in the GeoSem project (Bilhaut et al., 2003a; Widl¨ocher et al., 2004), or in another research project (Marquesuz`a et al., 2005). • TCAN project: Temporal intervals and applications to text linguistics, CNRS interdisciplinary project. • The platform is also used for other research or teaching purposes in several French laboratories (including GREYC, ERSS and LIUPPA) in the fields of corpus linguistics, natural language processing and text mini</context>
</contexts>
<marker>Bilhaut, Enjalbert, 2005</marker>
<rawString>Fr´ed´erik Bilhaut and Patrice Enjalbert. 2005. Discourse thematic organisation reveals domain knowledge structure. In Proceedings of the Conference Recent Advances in Natural Language Processing, Pune, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fr´ed´erik Bilhaut</author>
<author>Thierry Charnois</author>
<author>Patrice Enjalbert</author>
<author>Yann Mathet</author>
</authors>
<title>Passage extraction in geographical documents.</title>
<date>2003</date>
<booktitle>In Proceedings of New Trends in Intelligent Information Processing and Web Mining,</booktitle>
<location>Zakopane, Poland.</location>
<contexts>
<context position="12243" citStr="Bilhaut et al., 2003" startWordPosition="1884" endWordPosition="1888">e. It considers both textual segments and discourse relations, and relies on expression and satisfaction of a set of primitive constraints (presence, size, boundaries...) on previously computed annotations. 97 • A semantic lexicon marker, a configurable tokenizer (using regular expressions at the character level), a system allowing linguistic units to be delimited relying on the XML tags that are available in the original document, etc. 3 Conclusion LinguaStream is used in several research and educational projects: • Works on discourse semantics: discourse framing (Ho-Dac and Laignelet, 2005; Bilhaut et al., 2003b), thematic (Bilhaut, 2005; Bilhaut and Enjalbert, 2005) and rhetorical (Widl¨ocher, 2004) structures with a view to information retrieval and theoretical linguistics. • Works on Geographical Information, as in the GeoSem project (Bilhaut et al., 2003a; Widl¨ocher et al., 2004), or in another research project (Marquesuz`a et al., 2005). • TCAN project: Temporal intervals and applications to text linguistics, CNRS interdisciplinary project. • The platform is also used for other research or teaching purposes in several French laboratories (including GREYC, ERSS and LIUPPA) in the fields of corp</context>
</contexts>
<marker>Bilhaut, Charnois, Enjalbert, Mathet, 2003</marker>
<rawString>Fr´ed´erik Bilhaut, Thierry Charnois, Patrice Enjalbert, and Yann Mathet. 2003a. Passage extraction in geographical documents. In Proceedings of New Trends in Intelligent Information Processing and Web Mining, Zakopane, Poland.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Fr´ed´erik Bilhaut</author>
<author>Lydia-Mai Ho-Dac</author>
<author>Andr´ee Borillo</author>
</authors>
<title>Thierry Charnois, Patrice Enjalbert, Anne Le Draoulec, Yann Mathet, H´el`ene Miguet, MariePaule P´ery-Woodley, and Laure Sarda. 2003b. Indexation discursive pour la navigation intradocumentaire : cadres temporels et spatiaux dans l’information g´eographique.</title>
<booktitle>In Actes de Traitement Automatique du Langage Naturel (TALN),</booktitle>
<location>Batz-surMer, France.</location>
<marker>Bilhaut, Ho-Dac, Borillo, </marker>
<rawString>Fr´ed´erik Bilhaut, Lydia-Mai Ho-Dac, Andr´ee Borillo, Thierry Charnois, Patrice Enjalbert, Anne Le Draoulec, Yann Mathet, H´el`ene Miguet, MariePaule P´ery-Woodley, and Laure Sarda. 2003b. Indexation discursive pour la navigation intradocumentaire : cadres temporels et spatiaux dans l’information g´eographique. In Actes de Traitement Automatique du Langage Naturel (TALN), Batz-surMer, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fr´ed´erik Bilhaut</author>
</authors>
<title>Composite topics in discourse.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference Recent Advances in Natural Language Processing,</booktitle>
<location>Borovets, Bulgaria.</location>
<contexts>
<context position="1953" citStr="Bilhaut, 2005" startWordPosition="284" endWordPosition="285">processes could be immediately applicable. On the contrary, the multiplicity of approaches, would they be lexical, syntactical, semantic, rhetorical or pragmatical, would they focus on one of these dimensions or cross them, raises questions about how these different levels can be articulated within operational models, and how the related processing systems can be assembled, applied on a corpus, and evaluated within an experimental process. New NLP concerns confirm these needs: recent works on automatic discourse structure analysis, for example regarding thematic structures or rhetorical ones (Bilhaut, 2005; Widl¨ocher, 2004), show that the results obtained from lower-grained analysers (such as part-of-speech taggers or local semantics analysers) can be successfully exploited to perform higher-grained analyses. Indeed, such works rely on non-trivial processing streams, where several modules collaborate basing on the principles of incremental enrichment of documents and progressive abstraction from surface forms. The LinguaStream platform (Widl¨ocher and Bilhaut, 2005; Ferrari et al., 2005), which is presented here, promotes and facilitates such practices. It allows complex processing streams to </context>
<context position="12270" citStr="Bilhaut, 2005" startWordPosition="1890" endWordPosition="1891">nts and discourse relations, and relies on expression and satisfaction of a set of primitive constraints (presence, size, boundaries...) on previously computed annotations. 97 • A semantic lexicon marker, a configurable tokenizer (using regular expressions at the character level), a system allowing linguistic units to be delimited relying on the XML tags that are available in the original document, etc. 3 Conclusion LinguaStream is used in several research and educational projects: • Works on discourse semantics: discourse framing (Ho-Dac and Laignelet, 2005; Bilhaut et al., 2003b), thematic (Bilhaut, 2005; Bilhaut and Enjalbert, 2005) and rhetorical (Widl¨ocher, 2004) structures with a view to information retrieval and theoretical linguistics. • Works on Geographical Information, as in the GeoSem project (Bilhaut et al., 2003a; Widl¨ocher et al., 2004), or in another research project (Marquesuz`a et al., 2005). • TCAN project: Temporal intervals and applications to text linguistics, CNRS interdisciplinary project. • The platform is also used for other research or teaching purposes in several French laboratories (including GREYC, ERSS and LIUPPA) in the fields of corpus linguistics, natural lan</context>
</contexts>
<marker>Bilhaut, 2005</marker>
<rawString>Fr´ed´erik Bilhaut. 2005. Composite topics in discourse. In Proceedings of the Conference Recent Advances in Natural Language Processing, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrich Callmeier</author>
<author>Andreas Eisele</author>
<author>Ulrich Sch¨afer</author>
<author>Melanie Siegel</author>
</authors>
<title>The DeepThought Core Architecture Framework.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation,</booktitle>
<location>Lisbon, Portugal.</location>
<marker>Callmeier, Eisele, Sch¨afer, Siegel, 2004</marker>
<rawString>Ulrich Callmeier, Andreas Eisele, Ulrich Sch¨afer, and Melanie Siegel. 2004. The DeepThought Core Architecture Framework. In Proceedings of the 4th International Conference on Language Resources and Evaluation, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hamish Cunningham</author>
<author>Diana Maynard</author>
<author>Kalina Bontcheva</author>
<author>Valentin Tablan</author>
</authors>
<title>GATE: A framework and graphical development environment for robust NLP tools and applications.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Anniversary Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="3158" citStr="Cunningham et al., 2002" startWordPosition="463" endWordPosition="467">cessing streams to be designed and evaluated, assembling analysis components of various types and levels: part-of-speech, syntax, semantics, discourse or statistical. Each stage of the processing stream discovers and produces new information, on which the subsequent steps can rely. At the end of the stream, various tools allow analysed documents and their annotations to be conveniently visualised. The uses of the platform range from corpora exploration to the development of fully operational automatic analysers. Other platform or tools pursue similar goals. We share some principles with GATE (Cunningham et al., 2002), HoG (Callmeier et al., 2004) and NOOJ1 (Muller et al., 2004), but one important difference is that the LinguaStream platform promotes the combination of purely declarative formalisms (when GATE is mostly based on the JAPE language and NOOJ focuses on a unique formalism), and allows processing streams to be designed graphically as complex graphs (when GATE relies on the pipeline paradigm). Also, the 1Formerly known as INTEX. 95 Figure 1: LinguaStream Integrated Environment low-level architecture of LinguaStream is comparable to the HoG middleware, but we are more interested in higher-level as</context>
</contexts>
<marker>Cunningham, Maynard, Bontcheva, Tablan, 2002</marker>
<rawString>Hamish Cunningham, Diana Maynard, Kalina Bontcheva, and Valentin Tablan. 2002. GATE: A framework and graphical development environment for robust NLP tools and applications. In Proceedings of the 40th Anniversary Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>St´ephane Ferrari</author>
<author>Fr´ef´erik Bilhaut</author>
<author>Antoine Widl¨ocher</author>
<author>Marion Laignelet</author>
</authors>
<title>Une plate-forme logicielle et une d´emarche pour la validation de ressources linguistiques sur corpus : application a` l’´evaluation de la d´etection automatique de cadres temporels.</title>
<date>2005</date>
<booktitle>In Actes des 4`emes Journ´ees de Linguistique de Corpus (JLC),</booktitle>
<location>Lorient, France.</location>
<marker>Ferrari, Bilhaut, Widl¨ocher, Laignelet, 2005</marker>
<rawString>St´ephane Ferrari, Fr´ef´erik Bilhaut, Antoine Widl¨ocher, and Marion Laignelet. 2005. Une plate-forme logicielle et une d´emarche pour la validation de ressources linguistiques sur corpus : application a` l’´evaluation de la d´etection automatique de cadres temporels. In Actes des 4`emes Journ´ees de Linguistique de Corpus (JLC), Lorient, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lydia-Mai Ho-Dac</author>
<author>Marion Laignelet</author>
</authors>
<title>Temporal structure and thematic progression: A case study on french corpora.</title>
<date>2005</date>
<booktitle>In Symposium on the Exploration and Modelling of Meaning (SEM’O5),</booktitle>
<location>Biarritz, France.</location>
<contexts>
<context position="12221" citStr="Ho-Dac and Laignelet, 2005" startWordPosition="1880" endWordPosition="1883">tation of discourse structure. It considers both textual segments and discourse relations, and relies on expression and satisfaction of a set of primitive constraints (presence, size, boundaries...) on previously computed annotations. 97 • A semantic lexicon marker, a configurable tokenizer (using regular expressions at the character level), a system allowing linguistic units to be delimited relying on the XML tags that are available in the original document, etc. 3 Conclusion LinguaStream is used in several research and educational projects: • Works on discourse semantics: discourse framing (Ho-Dac and Laignelet, 2005; Bilhaut et al., 2003b), thematic (Bilhaut, 2005; Bilhaut and Enjalbert, 2005) and rhetorical (Widl¨ocher, 2004) structures with a view to information retrieval and theoretical linguistics. • Works on Geographical Information, as in the GeoSem project (Bilhaut et al., 2003a; Widl¨ocher et al., 2004), or in another research project (Marquesuz`a et al., 2005). • TCAN project: Temporal intervals and applications to text linguistics, CNRS interdisciplinary project. • The platform is also used for other research or teaching purposes in several French laboratories (including GREYC, ERSS and LIUPPA)</context>
</contexts>
<marker>Ho-Dac, Laignelet, 2005</marker>
<rawString>Lydia-Mai Ho-Dac and Marion Laignelet. 2005. Temporal structure and thematic progression: A case study on french corpora. In Symposium on the Exploration and Modelling of Meaning (SEM’O5), Biarritz, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christophe Marquesuz`a</author>
<author>Patrick Etcheverry</author>
<author>Julien Lesbegueries</author>
</authors>
<title>Exploiting geospatial markers to explore and resocialize localized documents.</title>
<date>2005</date>
<booktitle>In Proceedings of the 1st Conference on GeoSpatial Semantics (GEOS),</booktitle>
<location>Mexico City.</location>
<marker>Marquesuz`a, Etcheverry, Lesbegueries, 2005</marker>
<rawString>Christophe Marquesuz`a, Patrick Etcheverry, and Julien Lesbegueries. 2005. Exploiting geospatial markers to explore and resocialize localized documents. In Proceedings of the 1st Conference on GeoSpatial Semantics (GEOS), Mexico City.</rawString>
</citation>
<citation valid="true">
<date>2004</date>
<booktitle>INTEX pour la Linguistique et le Traitement Automatique des Langues. Presses Universitaires de Franche-Comt´e.</booktitle>
<editor>Claude Muller, Jean Royaute, and Max Silberztein, editors.</editor>
<marker>2004</marker>
<rawString>Claude Muller, Jean Royaute, and Max Silberztein, editors. 2004. INTEX pour la Linguistique et le Traitement Automatique des Langues. Presses Universitaires de Franche-Comt´e.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antoine Widl¨ocher</author>
<author>Fr´ed´erik Bilhaut</author>
</authors>
<title>La plate-forme linguastream : un outil d’exploration linguistique sur corpus.</title>
<date>2005</date>
<booktitle>In Actes de la 12e Conf´erence Traitement Automatique du Langage Naturel (TALN),</booktitle>
<location>Dourdan, France.</location>
<marker>Widl¨ocher, Bilhaut, 2005</marker>
<rawString>Antoine Widl¨ocher and Fr´ed´erik Bilhaut. 2005. La plate-forme linguastream : un outil d’exploration linguistique sur corpus. In Actes de la 12e Conf´erence Traitement Automatique du Langage Naturel (TALN), Dourdan, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antoine Widl¨ocher</author>
<author>Eric Faurot</author>
<author>Fr´ed´erik Bilhaut</author>
</authors>
<title>Multimodal indexation of contrastive structures in geographical documents.</title>
<date>2004</date>
<booktitle>In Proceedings of Recherche d’Information Assist´ee par Ordinateur (RIAO),</booktitle>
<location>Avignon, France.</location>
<marker>Widl¨ocher, Faurot, Bilhaut, 2004</marker>
<rawString>Antoine Widl¨ocher, Eric Faurot, and Fr´ed´erik Bilhaut. 2004. Multimodal indexation of contrastive structures in geographical documents. In Proceedings of Recherche d’Information Assist´ee par Ordinateur (RIAO), Avignon, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antoine Widl¨ocher</author>
</authors>
<title>Analyse macros´emantique: vers une analyse rh´etorique du discours.</title>
<date>2004</date>
<booktitle>In Actes de RECITAL’04,</booktitle>
<location>F`es, Maroc.</location>
<marker>Widl¨ocher, 2004</marker>
<rawString>Antoine Widl¨ocher. 2004. Analyse macros´emantique: vers une analyse rh´etorique du discours. In Actes de RECITAL’04, F`es, Maroc.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>