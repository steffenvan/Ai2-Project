<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.850986">
Squibs and Discussions
Aligning Phonetic Segments for Children&apos;s
Articulation Assessment
</title>
<author confidence="0.894175">
Harold L. Somers*
</author>
<sectionHeader confidence="0.696767" genericHeader="abstract">
UMIST
</sectionHeader>
<bodyText confidence="0.993232">
In a recent paper published in this journal (Covington 1996), an algorithm is described which
aligns segments within a pair of words for the purpose of identifying historical cognates. This
algorithm could have a further application in the field of speech therapy, and in particular in
the practice of articulation assessment of young children. The present author developed a similar
algorithm some years ago for this purpose. In this paper, we explore some points of comparison
between the two applications.
</bodyText>
<sectionHeader confidence="0.906416" genericHeader="categories and subject descriptors">
1. Articulation Testing
</sectionHeader>
<bodyText confidence="0.974677785714286">
It is well known that a child&apos;s acquisition of phonology is gradual, and can be charted
according to the appearance of phonetic distinctions (e.g., stops vs. fricatives), the
disappearance of childish mispronunciations, especially due to assimilation ([gog] for
dog), and the ability to articulate particular phonetic configurations (e.g., consonant
clusters). Childhood speech impediments, often a symptom of other learning disor-
ders, can often be diagnosed early on by the identification of delayed acquisition of
these articulatory skills. Whether screening whole populations of children, or assessing
individual referrals, the articulation test is an important tool for the speech clinician.
A child&apos;s articulatory development is usually described with reference to an adult
model, and in terms of deviations from it: a number of phonological &amp;quot;processes&amp;quot;
(Table 1) can be identified (see Ingram [1976]), and their significance with respect
to the chronological age of the child assessed (though often processes interact, so
for example when spoon is pronounced [fun] we have consonant-cluster reduction
and assimilation). In Somers (1978a, 1979) I reported a computer program called CAT
(Computerised Articulation Test), which I had developed to automate the assessment
of children&apos;s articulation tests. At the heart of this program was an algorithm very
similar to the one reported by Covington.
Whereas Covington seeks to align the segments in possible historical cognates,
CAT aligns the segments of a child&apos;s articulation with those of the adult model, and on
the basis of this looks for evidence of the phonological processes listed in Table 1. For
example, if elephant [clifAnt] is pronounced [evat], we need to decide which of several
possible alignments is the most plausible (cf. Covington 1996, 481):
E--va—t EIT9- - -t E--vat— etc.
E1If ant ElIf ant Elif ant E 11f ant
If applied to a body of articulation data, e.g., a corpus of, say, 45 words elicited
from the child as in a standardized articulation test, the evidence of each phonological
process can be quantified, and the overall picture compared with the model of the
average child, to give an individual&apos;s &amp;quot;articulation age&amp;quot; and profile.
</bodyText>
<footnote confidence="0.736965">
* Centre for Computational Linguistics, UMIST, Manchester, England. E-mail: harold@ccLumistac.uk
</footnote>
<note confidence="0.517923">
© 1999 Association for Computational Linguistics
</note>
<tableCaption confidence="0.573356">
Computational Linguistics Volume 25, Number 2
Table 1
</tableCaption>
<table confidence="0.9897477">
Phonological processes.
Process Example Adult Model Child&apos;s Version
Final consonant deletion queen kwin kwi
Unstressed syllable deletion elephant elifant efant
Consonant cluster reduction stamps stamps tam
Stopping kiss kis kit
Fronting key ki ti
Denasalisation mummy mAmi bAbi
Affrication tent tent tents
Vocalisation (1) bottle botl botu
Vocalisation (2) chimney tfimni trimini
Depalatalisation fish fif fis
Devoicing dogs dog z doks
Voicing tent tent dent
Assimilation dog dog gog
Lisping kiss kis ki0
S-lateralisation fish fif fii
Ejectivisation tent tent tent&apos;
Metathesis remember rimemb a miremb a
Gliding look luk wuk
</table>
<subsectionHeader confidence="0.349654">
2. Use of the Computer by Speech Clinicians
</subsectionHeader>
<bodyText confidence="0.98592152173913">
Early studies reporting the use of computers by speech pathologists include Faircloth
(1971), van Demark and Tharp (1973), and Telage (1980), none of which involves au-
tomatic analysis of the input, though the last named uses binary articulatory features
in a way almost identical to CAT. Comparatively little has appeared in the speech-
language disorders literature on the specific topic of computerized articulation testing
in the nearly 20 years since the CAT program was developed. Software for computer-
ized language analysis does exist, but is mainly for grammatical and lexical analysis.
Fairly thorough overviews are given by Rushakoff (1984), Rushakoff and Schwartz
(1986), Long (1991), Long and Masterson (1993), and Miller and Klee (1995), though
of course these may be more or less out of date. Other very general works such as
Schwartz (1984), Curtis (1987), Silverman (1987), Cochran and Masterson (1995), and
Masterson (1995) cover the use of computers by clinicians for all aspects of their work,
including screening and diagnosis of various language skills (lexis, grammar, under-
standing, and auditory skills, as well as articulation) but also research (use of statistics),
treatment (computer-based games), and clerical uses.1
Those programs reported in the literature which specifically address the problem
of articulation testing are listed below. For many of these programs, it seems that
the only published information is in the user manual that accompanies the software.
As far as one can tell, in none of the packages is the data analysis fully automatic.
The following packages have been reviewed or discussed in the articles as cited: CAPP
(Computer Analysis of Phonological Processes) (Long 1991; Kennedy 1986); Computer
Managed Articulation Diagnosis (Bardzik 1986; Long 1991); Computerized Profiling
1.0 (Klee and Sahlie 1994); Computerized Profiling 2.0 (Gregg and Andrews 1995); ISPA
</bodyText>
<footnote confidence="0.9887875">
1 Several papers refer to articles in the Journal for Computer Users in Speech and Hearing, but at the time of
writing I was unfortunately unable to locate any copies of this obviously relevant journal.
</footnote>
<page confidence="0.98837">
268
</page>
<subsectionHeader confidence="0.897301">
Somers Aligning Phonetic Segments
</subsectionHeader>
<bodyText confidence="0.999502535714286">
(Interactive System for Phonological Analysis) (Ball 1994); Lingquest 2 (Long 1991); PAL
(Pye Analysis of Language) (Pye and Ingram 1988; Leonard 1989); PDAC (Phonological
Deviation Analysis by Computer) (Perry 1995); PEPPER (Programs to Examine Phonetic
and Phonological Evaluation Records) (Dyson 1987; Pollock 1988); Process Analysis 2.0
(Long 1991).
The best-known computer application in speech-language pathology research is
the CHILDES database of language samples and associated software (MacWhinney and
Snow 1985; MacWhinney 1992; Sokolov and Snow 1994). This is primarily aimed at fa-
cilitating the storage and search of large databases of transcribed clinical data, where
the transcription is basically orthographic, with mark-up for gestures, pauses, and
other conversational features. Provision is made for a phonetic transcription too, us-
ing a &amp;quot;translation&amp;quot; of the IPA (International Phonetic Association) alphabet into ASCII
symbols called &amp;quot;UNIBET&amp;quot; (MacWhinney 1992, 61ff). Although the organizers of the
CHILDES database have had input from computational linguists on the question of
mark-up, there is little or no automatic analysis. Crucially, no attempt is made to com-
pare on a phone-by-phone basis the child language data with adult models, so data
on the types of phonological process listed in Table 1 cannot be extracted.
This situation is typical of child language software, exemplified by Pye and Ingram
(1988), whose PAL system uses a simple transcription, based on the IPA consonant chart,
without the possibility of diacritics or special symbols to indicate specifically childish
articulations. The system is unable to compare adult models with the child&apos;s output,
and can only produce a &amp;quot;phonological lexicon&amp;quot;, i.e., a list of the different sounds
attested: it is then up to the clinician to analyze this inventory, e.g., to see if sounds
are used contrastively, or in complementary distribution. The authors suggest that
matching the child&apos;s utterances to an adult model would involve a procedure which
&amp;quot;would have to be very sophisticated indeed to handle complex cases of metathesis
and deletion&amp;quot; (p. 124). As we show in Somers (1979) and in the next section, CAT was
able to handle metathesis and deletion without being &amp;quot;very sophisticated indeed.&amp;quot;
</bodyText>
<sectionHeader confidence="0.974866" genericHeader="general terms">
3. The CAT Algorithm
</sectionHeader>
<bodyText confidence="0.9999504">
Since the Somers (1979) article was aimed at speech therapists, it did not describe
the alignment algorithm as such, which is described only in a local journal (Somers
1978a) and—in great detail—in an M.A. thesis (Somers 1978b). It bears comparison
with Covington&apos;s algorithm, though it should be said that the implementation in Pascal
would be judged crude in the light of modern programming practice.
</bodyText>
<subsectionHeader confidence="0.999881">
3.1 Coding the Input
</subsectionHeader>
<bodyText confidence="0.999974923076923">
The articulation data is coded as a narrow transcription, identifying phonetic detail
such as secondary articulations, which can be important in speech therapy, in a fairly
transparent notation, despite the limitations of the (capitals only) character set: pri-
mary phones are identified by single characters, with diacritics indicated in brackets,
for example N (D) would indicate a dental (rather than alveolar) En] . The notation is
interpreted internally as bundles of articulatory features. The adult models are stored
in a similar form. In each word, one vowel is marked as the primary stress, and
this is taken as an anchor point for the alignment. The program as a whole ignores
vowel quality, and in the CAT transcription any one of five vowel symbols (the vowel
characters AEIOU in fact) can be used, the choice of one or the other being merely cos-
metic. This treatment of vowels is a reasonable expedient. Primarily, CAT is aimed at
consonant articulation, which is also the main concern of speech clinicians: see Stoel-
Gammon and Herrington (1990) who state that &amp;quot;vowels are mastered earlier [than
</bodyText>
<page confidence="0.983494">
269
</page>
<figure confidence="0.839926625">
Computational Linguistics Volume 25, Number 2
TARGET RESPONSE F/L LAB DEN ALV RET PAL VEL UVU GLT STP FRC LAT NAS VWL
S OMITTED
T D /-/ - - + -----+ - - - -
A ( &apos; ) A ( &apos; ) -------------+
M 9 - /-/ - - - - /+/ -----+ -
P OMITTED
S X + - - /- / - -1+1- - - + - - -
</figure>
<figureCaption confidence="0.982433">
Figure 1
</figureCaption>
<bodyText confidence="0.992563428571429">
Alignment of stamps pronounced as [claw/. The features where the target and response differ
are highlighted with slant brackets.
consonants] and tend to evidence fewer errors&amp;quot; (p. 145). Regarding the identification
of a single stressed vowel as an anchor point for the alignment, stress patterning (at
least in stress-timed languages like English) is one of the first features of phonology
to be acquired by children: again, if this is still a problem, then the distinctions tested
by CAT will certainly be too fine-grained for such a subject.&apos;
</bodyText>
<subsectionHeader confidence="0.999115">
3.2 Alignment
</subsectionHeader>
<bodyText confidence="0.999986230769231">
The alignment is based on taking the highest-scoring matches in terms of features,
much as suggested by Covington (p. 490), so that in the elephant example above, the
alignment [v]:[f] is preferred over the alignment [v]:[1]. Since the number of features
for each segment remains constant, it is a simple matter of adding up the number of
common features (+ or —), and taking the highest total. The algorithm works on the
basis of &amp;quot;syllables&amp;quot; centred around a vowel. With the stressed vowel as an anchor
point, the search-space is reduced to a comparison of the syllables either side of it:
note that &amp;quot;vowel&amp;quot; is also marked as a feature. This is generally straightforward if the
words are mono- or disyllabic, or trisyllabic with the stress on the second syllable. In
other cases, if there is gross distortion of the consonants as well as inserted or omitted
syllables, alignment can become somewhat arbitrary
The algorithm takes some other factors into account, and is &amp;quot;tuned&amp;quot; to look out
for certain processes that undermine the simplistic sequential skip-and-match search
(which is also the basis of Covington&apos;s algorithm): two such processes are metathesis
(e.g., remember[miremba]) and merging. In merging, a consonant cluster is simplified
so that the resulting phone shares features of the two merged phones, e.g., box [boks]
pronounced [bot], where the [t] has the place of articulation of the [s], but the manner
of articulation of the [k]. Identifying metathesis can be rendered more complex by the
coincidence of some other process, e.g., stopping, so that elephant becomes [epilant]
with the [1] and [fl swopped round, and the [f] replaced by a [p]. The CAT alignment
algorithm looks for these explicitly. Figure 1 shows the result of the alignment of
stamps:[dapxs], as it was actually presented.
The algorithm first aligns the marked vowel. It then takes the sequence of seg-
ments either side of the vowel. For [st]:[d], [d] is aligned with [t] rather than [s] as
[t]:[d] represents a difference of only one feature, while [s]:[d] differs in three fea-
tures. The evidence for a merge is the same as for the simpler devoicing analysis,
</bodyText>
<page confidence="0.6695675">
2 I am grateful to the anonymous reviewer who queried this aspect of the algorithm.
270
</page>
<subsectionHeader confidence="0.638871">
Somers Aligning Phonetic Segments
</subsectionHeader>
<bodyText confidence="0.985981333333333">
so the latter is preferred. In the case of [mps]:[Dx], the algorithm compares the four
possibilities [m]:[D], [p]:[u], [p]:[x], and [s]:[x], as well as the possible merges [mp]:[D]
and [ps]:[x], in that order. It does not consider the matches [m]:[x] or [s]:[B] as these
would involve a simultaneous insertion and deletion (cf. Covington&apos;s &amp;quot;no-alternating-
skips rule,&amp;quot; p. 482). As usual, the solution with the least &amp;quot;cost&amp;quot; in terms of feature
differences is chosen. If the sequence includes a &amp;quot;no cost&amp;quot; match, this would imme-
diately be preferred. The test for metathesis would also be made when there is an
&amp;quot;unstressed&amp;quot; vowel in the sequence, though not in consonant clusters (so vest:[vets]
would be analyzed incorrectly).
</bodyText>
<subsectionHeader confidence="0.97166">
3.3 Comparing CAT and Covington&apos;s Algorithm
</subsectionHeader>
<bodyText confidence="0.999686583333334">
Comparing the CAT algorithm with Covington&apos;s, it seems that a key difference is the
manual identification of a favored segment—the &amp;quot;stressed&amp;quot; vowel— as an anchor
point. This can drastically reduce the search-space, especially if it happens to occur
near the middle of the string, as in the above example. Apart from this, both algorithms
work on a sequential match-or-skip, comparing the relative cost of each match, and
narrowing the search-space by halting the search if a perfect match is found. The CAT
algorithm has the additional task of searching explicitly under certain circumstances
for metathesis and merges.
Apart from Covington&apos;s more sophisticated programming style, the only other
difference between our techniques is in the scoring method. Covington&apos;s (p. 487)
seems simpler than my own, in that the penalties reflect different types of (mis-)match,
whereas in CAT the score derives more directly from the phonetic nature of the match.
Covington states, on the same page, that &amp;quot;excessively narrow phonetic transcriptions
do not help; they introduce too many subtle mismatches that should have been ig-
nored.&amp;quot; The CAT alignment algorithm, however, makes quite the opposite assumption,
since the nature of the task demands a particularly narrow transcription. Covington
also states (p. 490) that his algorithm could be improved by using phonetic features.
It is enlightening to take Covington&apos;s cognate alignment examples and to see what
CAT would make of them. Looking first at the Spanish-French pairs (pp. 488f), we find
that CAT agrees with Covington in 16 of the 20 cases. CAT has problems in three cases
where the French has lost syllables that are stressed in Spanish, as in cabiza:cap (1);3
in the case of cirbol:arbre (2), CAT gets the correct alignment as identified by Covington
(p. 488) if we omit the schwa in the French transcription (as would be normal for
Parisian French (Armstrong 1967, 117).
</bodyText>
<equation confidence="0.525526">
Example 1
(1) kabe0a kabe0a
k a p - k - - p -
</equation>
<listItem confidence="0.9082345">
(2) arb-ol arb-ol
arbra- aRb--R
</listItem>
<bodyText confidence="0.9986694">
For the English-German data (pp. 490f) CAT gets exactly the same alignments as
Covington for all 20 pairs (including the incorrect analysis of this:dieses), though in CAT
we would not transcribe the second element of the diphthongs in four of the examples.
Like Covington&apos;s algorithm, CAT would correctly assign the [0] of mouth with the [t]
rather than the [n] of Mund.
</bodyText>
<footnote confidence="0.973256">
3 In this and subsequent examples, the CAT alignments (on the right) are shown in IPA; an acute accent
marks the &amp;quot;stressed&amp;quot; vowel. Covington&apos;s alignments are shown on the left.
</footnote>
<page confidence="0.976427">
271
</page>
<note confidence="0.631297">
Computational Linguistics Volume 25, Number 2
</note>
<bodyText confidence="0.999473125">
The examples considered so far have been quite straightforward (and much easier
to align than typical child language data). The English-Latin cognates (pp. 492f) present
more of a challenge. Applying the accepted rules of Latin stress, the CAT and Cov-
ington alignments differ in five of the 20 cases: In four of these, blow:flare, fish:piscis,
full:plenus, and tooth:dentis (3), CAT does better than Covington, and in three other
cases (grass:gramen, heart:cordis, and mountain:mans), CAT gets as first choice the align-
ment Covington ranks third, second, and second respectively. With just one exception
(knee:gena), CAT does as well as or better than Covington.
</bodyText>
<equation confidence="0.5531685">
Example 2
(3) ---tuw0 - -
</equation>
<bodyText confidence="0.9363776">
dent i-s dent is
On the Fox-Menomini data (p. 494), CAT gets the same results as Covington on
all ten examples if we assume either the first or the second vowel is stressed. Finally,
Covington presents a variety of language-pair examples (p. 495). Again, the correct
placement of the stressed vowel is important, leading to a wrong alignment for cen-
tum:helcaton (4), and preventing the [g]:[x] alignment in thugater:Tochter (5). CAT does
worse than Covington in one other case didomi:do (6), but better in three cases daugh-
ter:thugater (7), ager:ajras (8), and bharami:phero (9). For centum:satem they both get the
same alignment.
Example 3
</bodyText>
<listItem confidence="0.878015555555555">
(4) kentum --k entum
heka-t on hekatein-
(5) thu gater thuga-ter
tox-tor t--Oxter
(6) didOmi didOmi
--d -- d--6- -
(7) doter d--otor
thugater thugater
(8) a-ger ager--
</listItem>
<bodyText confidence="0.965797416666667">
ajras a d3 -ras
In summary then, CAT does worse on the Spanish-French, better on the English-
Latin, and about the same on the rest. Considering that Covington&apos;s algorithm is aimed
at dealing with this sort of data, this is a good result for CAT.
In a reciprocal comparison, Michael Covington was kind enough to run his algo-
rithm on some child language data that I sent him. Of 25 examples, all of which CAT
handles correctly, Covington&apos;s algorithm also got the correct alignment, but often it
was unable to distinguish between alternative alignments, all of which received the
same score. For example, with the stamps:[dauxs] alignment mentioned above, all six
different combinations of consonant alignment either side of the vowel are proposed
with an equal score. This is because, as Covington (personal communication) readily
points out, &amp;quot;it doesn&apos;t know anything about place of articulation.&amp;quot;
</bodyText>
<page confidence="0.993255">
272
</page>
<note confidence="0.512196">
Somers Aligning Phonetic Segments
</note>
<sectionHeader confidence="0.981158" genericHeader="conclusions">
4. Conclusions
</sectionHeader>
<subsectionHeader confidence="0.999353">
4.1 Connolly&apos;s New Algorithm
</subsectionHeader>
<bodyText confidence="0.99999555">
Since the appearance of Covington&apos;s article (and even since the first draft of this reply),
a highly relevant article has appeared, which—coincidentally—addresses the issues
raised here (Connolly 1997). In this two-part article, Connolly first suggests ways of
quantifying the difference between two individual phones, on the basis of perceptual
and articulatory differences, and using either a Euclidean distance metric or, like CAT,
a feature-based metric. Connolly&apos;s proposals are more elaborate, however, in that they
permit specific differences to be weighted, so as to reflect the relative importance
of each opposition. In the second part of the article, Connolly introduces a distance
measure for comparing sequences of phones, based on the Levenshtein distance well-
known in the speech processing and corpus alignment literature (inter alia). Again, this
metric can be weighted, to allow substitutions to be valued differentially (presumably
on the basis of the individual phone distance measure as described in the first part),
and to deal with merging and metathesis. Connolly also considers briefly the effects
of nonlinear prosodic structure on the distance measure. Although his methods are
clearly computational in nature, Connolly reported (personal communication, 1997)
that he had not yet implemented them. Taken together, these measures are certainly
more sophisticated than either CAT&apos;S or Covington&apos;s, so this contribution could well be
an extremely significant one towards the development of articulation testing software.
In Somers (1998), I report an implementation and comparison of Connolly&apos;s measures
with my own earlier work.
</bodyText>
<subsectionHeader confidence="0.995306">
4.2 What Would a New Version of CAT Be Like?
</subsectionHeader>
<bodyText confidence="0.999997222222222">
In the light of the above remarks, it is interesting to think about how we might specify
a reimplementation of CAT. One area where there could be considerable improvement
is in the data input. CAT uses a very crude phonetic transcription based only on a
minimal character set, not even including lower-case letters. Clearly this restriction
would not be necessary nowadays. The software system PDAC (Phonological Devia-
tion Analysis by Computer) uses a software package called LIPP (Logical International
phonetic Programs) for input of transcriptions (Perry 1995). Alternatively, it seems
quite feasible to allow the transcriptions to be input using a standard word processor
and a phonetic font, and to interpret the symbols accordingly. For a commercial im-
plementation it would be better to follow the standard proposed by the IPA (Esling
and Gaylord 1993), which has been approved by the ISO, and included in the Unicode
definitions.
Despite the reservations of all the speech-language pathology experts, it seems
to me that the work on alignment discussed here (Somers 1978b; Covington 1996;
Connolly 1997) suggests that this aspect of computerized articulation test analysis is a
research aim well worth pursuing, especially if collaborators from the speech-language
pathology field can be found. It would be rewarding if this article were to awaken
interest in the problem.
</bodyText>
<sectionHeader confidence="0.84838" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.850189666666667">
I would like to thank the following people
for their help in gathering the information
presented in this paper: Catherine Adams
</bodyText>
<affiliation confidence="0.945444333333333">
(University of Manchester), Lawrence
Shriberg (University of Wisconsin-Madison),
Julie Masterson (Southwest Missouri State
University), Carol Stoel-Gammon
(University of Washington) and John
Connolly (Loughborough University);
</affiliation>
<footnote confidence="0.9133398">
Michael Covington, for collaborating on the
&amp;quot;bake-off&amp;quot;; Joe Somers, for providing some
of the example data; and the three
anonymous reviewers for their suggestions,
which have been extremely valuable.
</footnote>
<page confidence="0.992186">
273
</page>
<note confidence="0.777577">
Computational Linguistics Volume 25, Number 2
</note>
<sectionHeader confidence="0.608831" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997999363636364">
Armstrong, Lilias E. 1967. The Phonetics of
French: A Practical Handbook. G Bell,
London.
Ball, Martin J. 1994. Review of ISPA:
Interactive System for Phonological
Analysis. Child Language Teaching and
Therapy, 10:97-102.
Bardzik, Paul P. 1986. Review of Computer
Managed Articulation Analysis. ASHA,
28(2):74-75.
Cochran, Paula S. &amp; Julie J. Masterson. 1995.
NOT using a computer in language
assessment/intervention: In defense of
the reluctant clinician. Language, Speech,
and Hearing Services in Schools, 26:213-222.
Connolly, John H. 1997. Quantifying
target-realization differences. Clinical
Linguistics &amp; Phonetics, 11:267-298.
Covington, Michael A. 1996. An algorithm
to align words for historical comparison.
Computational Linguistics, 22:481-496.
Curtis, Jack F. 1987. An Introduction to
Microcomputers in Speech, Language, and
Hearing. College-Hill, Boston, MA.
Dyson, Alice T. 1987. Review of PEPPER:
Programs to Examine Phoentic and
Phonological Evaluation Records. Child
Language Teaching and Therapy, 3:329-335.
Esling, John H. &amp; Harry Gaylord. 1993.
Computer codes for phonetic symbols.
Journal of the International Phonetic
Association, 23:83-97.
Faircloth, Marjorie A. 1971.
Computer-assisted articulation analysis.
Paper presented at the Annual
Convention of the American Speech and
Hearing Association, Chicago, IL, Sept.
1971. ASHA, 13:534.
Gregg, Ellen Meyer. &amp; Valorie Andrews.
1995. Review of Computerized Profiling
(1993). Child Language Teaching and Therapy,
11:209-216.
Ingram, David. 1976. Phonological Disability
in Children. Edward Arnold, London.
Kennedy, Kathleen A. 1986. Review of
Computer Analysis of Phonological
Processes. ASHA, 28(8):71.
Klee, T. &amp; E. Sahlie. 1994. Review of
Computerized Profiling Version 1.0. Child
Language Teaching and Therapy, 3:87-93.
Leonard, Laurence B. 1989. Review of the
Pye Analysis of Language. Child Language
Teaching and Therapy, 5:79-86.
Long, Steven H. 1991. Integrating
microcomputer applications into speech
and language assessment. Topics in
Language Disorders, 11(2):1-17.
Long, Steven H. &amp; Julie J. Masterson. 1993.
Computer technology: Use in language
analysis. ASHA 35(9):40-41,51.
MacWhinney, Brain. 1992. The CHILDES
Project: Tools for Analyzing Talk. Lawrence
Erlbaum Associates, Hillsdale, NJ.
MacWhinney, Brian &amp; Catherine Snow. 1985.
The child language data exchange system.
Journal of Child Language, 12:271-296.
Masterson, Julie J. 1995. Computer
applications in the schools: What we can
do-what we should do. Language, Speech,
and Hearing Services in Schools, 26:211-212.
Miller, Jon F. &amp; Thomas Klee. 1995.
Computational approaches to the analysis
of language impairment. In Paul Fletcher
&amp; Brian MacWhinney, editors, The
Handbook of Child Language. Blackwell,
Oxford, pages 545-572.
Perry, Cecyle K. 1995. Review of
Phonological Deviation Analysis by
Computer (PoAc). Child Language Teaching
and Therapy, 11:331-340.
Pollock, Karen E. 1988. Review of PEPPER:
Programs to Examine Phonetic and
Phonological Evaluation Records. ASHA,
30(8):57-58.
Pye, Clifton &amp; David Ingram. 1988.
Automating the analysis of child
phonology. Clinical Linguistics &amp; Phonetics,
2:115-137.
Rushakoff, Gary E. 1984. Clinical
applications in communication disorders.
In Arthur H. Schwartz, editor, The
Handbook of Microcomputer Applications in
Communication Disorders. College-Hill
Press, San Diego, CA, pages 147-171.
Rushakoff, Gary E. &amp; Arthur H. Schwartz.
1986. Clinical assessment software. In
Michael L. Grossfeld &amp; Cathleen A.
Grossfeld, editors, Microcomputer
Applications in Rehabilitation of
Communication Disorders. Aspen,
Rockville, MD, pages 1-24.
Schwartz, Arthur H. 1984. Microcomputer
applications: Facts, functions, fads, and
fallacies. Journal of Childhood
Communication Disorders, 8:89-111.
Silverman, Franklin H. 1987. Microcomputers
in Speech-Language Pathology and Audiology:
A Primer. Prentice-Hall, Englewood Cliffs,
NJ.
Sokolov, Jeffrey L. &amp; Catherine E. Snow,
editors, 1994. Handbook of Research in
Language Development Using CHILDES.
Lawrence Erlbaum Associates, Hillsdale,
NJ.
Somers, H. 1978a. Computer analysis of
speech therapists&apos; articulation tests.
UMRCC Journal, 5(1):9-17 (University of
Manchester Regional Computing Centre).
Somers, H. L. 1978b. Computerised
Articulation Testing. M.A. thesis,
Department of General Linguistics,
</reference>
<page confidence="0.976613">
274
</page>
<note confidence="0.207887">
Somers Aligning Phonetic Segments
</note>
<reference confidence="0.9979388">
University of Manchester.
Somers, H. 1979. Using the computer to
analyse articulation test data. British
Journal of Disorders of Communication,
14:231-240.
Somers. H. 1998. Similarity metrics for
aligning children&apos;s articulation data. In
Proceedings of COLING-ACL &apos;98: 36th
Annual Meeting of the Association for
Computational Linguistics and 17th
International Conference on Computational
Linguistics, Montreal, Quebec, Canada,
pages 1227-1232.
Stoel-Gammon, Carol &amp; Paula Beckett
Herrington. 1990. Vowel systems of
normally developing and phonologically
disordered children. Clinical Linguistics &amp;
Phonetics, 4:145-160.
Telage, Kal M. 1980. A computerized
place-manner distinctive feature program
for articulation analyses. Journal of Speech
and Hearing Disorders, 45:481-494.
Van Demark, D. R. &amp; Rosemary Tharp. 1973.
A computer program for articulation
tests. Cleft Palate Journal, 10:378-386.
</reference>
<page confidence="0.998404">
275
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.997939">Squibs and Discussions Aligning Phonetic Segments for Children&apos;s Articulation Assessment</title>
<author confidence="0.999182">Harold L Somers</author>
<affiliation confidence="0.620137">UMIST</affiliation>
<abstract confidence="0.938999115384615">In a recent paper published in this journal (Covington 1996), an algorithm is described which aligns segments within a pair of words for the purpose of identifying historical cognates. This algorithm could have a further application in the field of speech therapy, and in particular in the practice of articulation assessment of young children. The present author developed a similar algorithm some years ago for this purpose. In this paper, we explore some points of comparison between the two applications. 1. Articulation Testing It is well known that a child&apos;s acquisition of phonology is gradual, and can be charted according to the appearance of phonetic distinctions (e.g., stops vs. fricatives), the disappearance of childish mispronunciations, especially due to assimilation ([gog] for the ability to articulate particular phonetic configurations (e.g., consonant clusters). Childhood speech impediments, often a symptom of other learning disorders, can often be diagnosed early on by the identification of delayed acquisition of these articulatory skills. Whether screening whole populations of children, or assessing individual referrals, the articulation test is an important tool for the speech clinician. A child&apos;s articulatory development is usually described with reference to an adult model, and in terms of deviations from it: a number of phonological &amp;quot;processes&amp;quot; (Table 1) can be identified (see Ingram [1976]), and their significance with respect to the chronological age of the child assessed (though often processes interact, so example when pronounced [fun] we have consonant-cluster reduction assimilation). In Somers (1978a, 1979) I reported a computer program called (Computerised Articulation Test), which I had developed to automate the assessment of children&apos;s articulation tests. At the heart of this program was an algorithm very similar to the one reported by Covington. Whereas Covington seeks to align the segments in possible historical cognates, the segments of a child&apos;s articulation with those of the adult model, and on the basis of this looks for evidence of the phonological processes listed in Table 1. For if is pronounced [evat], we need to decide which of several possible alignments is the most plausible (cf. Covington 1996, 481): etc. ant ElIf ant ant If applied to a body of articulation data, e.g., a corpus of, say, 45 words elicited from the child as in a standardized articulation test, the evidence of each phonological process can be quantified, and the overall picture compared with the model of the average child, to give an individual&apos;s &amp;quot;articulation age&amp;quot; and profile. * Centre for Computational Linguistics, UMIST, Manchester, England. E-mail: harold@ccLumistac.uk © 1999 Association for Computational Linguistics Computational Linguistics Volume 25, Number 2 Table 1 Phonological processes. Process Example Adult Model Child&apos;s Version Final consonant deletion queen kwin kwi Unstressed syllable deletion elephant elifant efant Consonant cluster reduction stamps stamps tam Stopping kiss kis kit Fronting key ki ti Denasalisation mummy mAmi bAbi Affrication tent tent tents Vocalisation (1) bottle botl botu Vocalisation (2) chimney tfimni trimini Depalatalisation fish fif fis Devoicing dogs dog z doks Voicing tent tent dent Assimilation dog dog gog Lisping kiss kis ki0 S-lateralisation fish fif fii Ejectivisation tent tent tent&apos; Metathesis remember Gliding look luk wuk 2. Use of the Computer by Speech Clinicians Early studies reporting the use of computers by speech pathologists include Faircloth (1971), van Demark and Tharp (1973), and Telage (1980), none of which involves automatic analysis of the input, though the last named uses binary articulatory features a way almost identical to little has appeared in the speechlanguage disorders literature on the specific topic of computerized articulation testing the nearly 20 years since the was developed. Software for computerlanguage analysis but is mainly for grammatical and lexical analysis. Fairly thorough overviews are given by Rushakoff (1984), Rushakoff and Schwartz (1986), Long (1991), Long and Masterson (1993), and Miller and Klee (1995), though of course these may be more or less out of date. Other very general works such as Schwartz (1984), Curtis (1987), Silverman (1987), Cochran and Masterson (1995), and Masterson (1995) cover the use of computers by clinicians for all aspects of their work, including screening and diagnosis of various language skills (lexis, grammar, understanding, and auditory skills, as well as articulation) but also research (use of statistics), (computer-based games), and clerical Those programs reported in the literature which specifically address the problem of articulation testing are listed below. For many of these programs, it seems that the only published information is in the user manual that accompanies the software.</abstract>
<note confidence="0.8731324">As far as one can tell, in none of the packages is the data analysis fully automatic. following packages have been reviewed or discussed in the articles as cited: (Computer Analysis of Phonological Processes) (Long 1991; Kennedy 1986); Computer Managed Articulation Diagnosis (Bardzik 1986; Long 1991); Computerized Profiling (Klee and Sahlie 1994); Computerized Profiling 2.0 (Gregg and Andrews 1995); Several papers refer to articles in the for Computer Users in Speech and Hearing, at the time of writing I was unfortunately unable to locate any copies of this obviously relevant journal. 268 Somers Aligning Phonetic Segments System for Phonological Analysis) (Ball 1994); Lingquest 2 (Long 1991); Analysis of Language) (Pye and Ingram 1988; Leonard 1989); Analysis by Computer) (Perry 1995); to Examine Phonetic and Phonological Evaluation Records) (Dyson 1987; Pollock 1988); Process Analysis 2.0 (Long 1991). The best-known computer application in speech-language pathology research is</note>
<abstract confidence="0.995329102564103">of language samples and associated software (MacWhinney and Snow 1985; MacWhinney 1992; Sokolov and Snow 1994). This is primarily aimed at facilitating the storage and search of large databases of transcribed clinical data, where the transcription is basically orthographic, with mark-up for gestures, pauses, and other conversational features. Provision is made for a phonetic transcription too, usa &amp;quot;translation&amp;quot; of the IPA (International Phonetic Association) alphabet into called 1992, 61ff). Although the organizers of have had input from computational linguists on the question of mark-up, there is little or no automatic analysis. Crucially, no attempt is made to compare on a phone-by-phone basis the child language data with adult models, so data on the types of phonological process listed in Table 1 cannot be extracted. This situation is typical of child language software, exemplified by Pye and Ingram whose uses a simple transcription, based on the IPA consonant chart, without the possibility of diacritics or special symbols to indicate specifically childish The system is unable to compare adult models with output, and can only produce a &amp;quot;phonological lexicon&amp;quot;, i.e., a list of the different sounds attested: it is then up to the clinician to analyze this inventory, e.g., to see if sounds used contrastively, or in complementary distribution. The authors suggest the child&apos;s utterances to adult model would involve a procedure which &amp;quot;would have to be very sophisticated indeed to handle complex cases of metathesis deletion&amp;quot; (p. 124). As we show in Somers (1979) and in the next section, able to handle metathesis and deletion without being &amp;quot;very sophisticated indeed.&amp;quot; The Since the Somers (1979) article was aimed at speech therapists, it did not describe alignment as such, which described only in a local journal (Somers 1978a) and—in great detail—in an M.A. thesis (Somers 1978b). It bears comparison Covington&apos;s though it should be said that the implementation in would be judged crude in the light of modern programming practice. 3.1 Coding the Input The articulation data is coded as a narrow transcription, identifying phonetic detail such as secondary articulations, which can be important in speech therapy, in a fairly transparent notation, despite the limitations of the (capitals only) character set: primary phones are identified by single characters, with diacritics indicated in brackets, example would indicate a dental (rather than alveolar) En] . The notation is interpreted internally as bundles of articulatory features. The adult models are stored in a similar form. In each word, one vowel is marked as the primary stress, and this is taken as an anchor point for the alignment. The program as a whole ignores quality, and in the any one of five vowel symbols (the vowel fact) can be used, the choice of one or the other being merely cos-</abstract>
<note confidence="0.7467488">This treatment of vowels is a reasonable expedient. Primarily, aimed at consonant articulation, which is also the main concern of speech clinicians: see Stoel- Gammon and Herrington (1990) who state that &amp;quot;vowels are mastered earlier [than 269 Computational Linguistics Volume 25, Number 2</note>
<title confidence="0.847393">TARGET RESPONSE F/L LAB DEN ALV RET PAL VEL UVU GLT STP FRC LAT NAS VWL S OMITTED T D /-/ - - + -----+ - - - - A ( &apos; ) A ( &apos; ) -------------+ M 9 - /-/ - - - - /+/ -----+ - P OMITTED</title>
<abstract confidence="0.990734317647059">X + - - /- / - - - + - - - Figure 1 of as [claw/. The features where the target and response differ are highlighted with slant brackets. consonants] and tend to evidence fewer errors&amp;quot; (p. 145). Regarding the identification of a single stressed vowel as an anchor point for the alignment, stress patterning (at least in stress-timed languages like English) is one of the first features of phonology to be acquired by children: again, if this is still a problem, then the distinctions tested certainly too fine-grained for such a subject.&apos; The alignment is based on taking the highest-scoring matches in terms of features, as suggested by Covington (p. 490), so that in the above, the alignment [v]:[f] is preferred over the alignment [v]:[1]. Since the number of features for each segment remains constant, it is a simple matter of adding up the number of common features (+ or —), and taking the highest total. The algorithm works on the &amp;quot;syllables&amp;quot; centred around a vowel. the stressed vowel as an anchor point, the search-space is reduced to a comparison of the syllables either side of it: note that &amp;quot;vowel&amp;quot; is also marked as a feature. This is generally straightforward if the words are monoor disyllabic, or trisyllabic with the stress on the second syllable. In other cases, if there is gross distortion of the consonants as well as inserted or omitted syllables, alignment can become somewhat arbitrary The algorithm takes some other factors into account, and is &amp;quot;tuned&amp;quot; to look out for certain processes that undermine the simplistic sequential skip-and-match search (which is also the basis of Covington&apos;s algorithm): two such processes are metathesis merging. In merging, a consonant cluster is simplified that the resulting phone shares features of the two merged phones, e.g., pronounced [bot], where the [t] has the place of articulation of the [s], but the manner of articulation of the [k]. Identifying metathesis can be rendered more complex by the of some other process, e.g., stopping, so that [epilant] the [1] and [fl swopped round, and the [f] replaced by a [p]. The algorithm looks for these explicitly. Figure 1 shows the result of the alignment of stamps:[dapxs], as it was actually presented. The algorithm first aligns the marked vowel. It then takes the sequence of segments either side of the vowel. For [st]:[d], [d] is aligned with [t] rather than [s] as [t]:[d] represents a difference of only one feature, while [s]:[d] differs in three features. The evidence for a merge is the same as for the simpler devoicing analysis, 2 I am grateful to the anonymous reviewer who queried this aspect of the algorithm. 270 Somers Aligning Phonetic Segments so the latter is preferred. In the case of [mps]:[Dx], the algorithm compares the four possibilities [m]:[D], [p]:[u], [p]:[x], and [s]:[x], as well as the possible merges [mp]:[D] and [ps]:[x], in that order. It does not consider the matches [m]:[x] or [s]:[B] as these would involve a simultaneous insertion and deletion (cf. Covington&apos;s &amp;quot;no-alternatingskips rule,&amp;quot; p. 482). As usual, the solution with the least &amp;quot;cost&amp;quot; in terms of feature differences is chosen. If the sequence includes a &amp;quot;no cost&amp;quot; match, this would immediately be preferred. The test for metathesis would also be made when there is an &amp;quot;unstressed&amp;quot; vowel in the sequence, though not in consonant clusters (so vest:[vets] would be analyzed incorrectly). Covington&apos;s Algorithm the with Covington&apos;s, it seems that a key difference is the manual identification of a favored segment—the &amp;quot;stressed&amp;quot; vowel— as an anchor point. This can drastically reduce the search-space, especially if it happens to occur near the middle of the string, as in the above example. Apart from this, both algorithms work on a sequential match-or-skip, comparing the relative cost of each match, and the search-space by halting the search if a perfect match is found. The algorithm has the additional task of searching explicitly under certain circumstances for metathesis and merges. Apart from Covington&apos;s more sophisticated programming style, the only other difference between our techniques is in the scoring method. Covington&apos;s (p. 487) seems simpler than my own, in that the penalties reflect different types of (mis-)match, in score derives more directly from the phonetic nature of the match. Covington states, on the same page, that &amp;quot;excessively narrow phonetic transcriptions do not help; they introduce too many subtle mismatches that should have been ig- The algorithm, however, makes quite the opposite assumption, since the nature of the task demands a particularly narrow transcription. Covington also states (p. 490) that his algorithm could be improved by using phonetic features. It is enlightening to take Covington&apos;s cognate alignment examples and to see what make of them. Looking first at the Spanish-French pairs (pp. 488f), we find with Covington in 16 of the 20 cases. problems in three cases the French has lost syllables that are stressed in Spanish, as in the case of the correct alignment as identified by Covington (p. 488) if we omit the schwa in the French transcription (as would be normal for Parisian French (Armstrong 1967, 117). Example 1 kabe0a a p k - p (2) arb-ol arb-ol arbraaRb--R the English-German data (pp. 490f) exactly the same alignments as for all 20 pairs (including the incorrect analysis of in we would not transcribe the second element of the diphthongs in four of the examples. Covington&apos;s algorithm, correctly assign the [0] of the [t] than the [n] of 3 In this and subsequent examples, the CAT alignments (on the right) are shown in IPA; an acute accent marks the &amp;quot;stressed&amp;quot; vowel. Covington&apos;s alignments are shown on the left. 271 Computational Linguistics Volume 25, Number 2 The examples considered so far have been quite straightforward (and much easier to align than typical child language data). The English-Latin cognates (pp. 492f) present of a challenge. Applying the accepted rules of Latin stress, the Covalignments differ in five of the 20 cases: In four of these, fish:piscis, better than Covington, and in three other heart:cordis, as first choice the alignment Covington ranks third, second, and second respectively. With just one exception as well as or better than Covington. Example 2 (3) ---tuw0 - dent i-s dent is the Fox-Menomini data (p. 494), the same results as Covington on all ten examples if we assume either the first or the second vowel is stressed. Finally, Covington presents a variety of language-pair examples (p. 495). Again, the correct of the stressed vowel is important, leading to a wrong alignment for cenand preventing the in than Covington in one other case better in three cases daugh- (7), ager:ajras For both get the same alignment. --k entum eka-t on hekateintox-tor t--Oxter (6) didOmi didOmi -d--6- (7) doter d--otor (8) a-ger ager-a -ras summary then, worse on the Spanish-French, better on the English- Latin, and about the same on the rest. Considering that Covington&apos;s algorithm is aimed dealing with this sort of data, this is a good result for a reciprocal comparison, Michael Covington was kind enough to run algoon some child language data that I sent him. Of 25 examples, all of which handles correctly, Covington&apos;s algorithm also got the correct alignment, but often it was unable to distinguish between alternative alignments, all of which received the same score. For example, with the stamps:[dauxs] alignment mentioned above, all six different combinations of consonant alignment either side of the vowel are proposed with an equal score. This is because, as Covington (personal communication) readily points out, &amp;quot;it doesn&apos;t know anything about place of articulation.&amp;quot; 272 Somers Aligning Phonetic Segments 4. Conclusions 4.1 Connolly&apos;s New Algorithm Since the appearance of Covington&apos;s article (and even since the first draft of this reply), a highly relevant article has appeared, which—coincidentally—addresses the issues raised here (Connolly 1997). In this two-part article, Connolly first suggests ways of the difference between two on the basis of perceptual articulatory differences, and using either a Euclidean distance metric or, like a feature-based metric. Connolly&apos;s proposals are more elaborate, however, in that they permit specific differences to be weighted, so as to reflect the relative importance of each opposition. In the second part of the article, Connolly introduces a distance for comparing phones, based on the Levenshtein distance wellknown in the speech processing and corpus alignment literature (inter alia). Again, this metric can be weighted, to allow substitutions to be valued differentially (presumably on the basis of the individual phone distance measure as described in the first part), and to deal with merging and metathesis. Connolly also considers briefly the effects of nonlinear prosodic structure on the distance measure. Although his methods are clearly computational in nature, Connolly reported (personal communication, 1997) that he had not yet implemented them. Taken together, these measures are certainly sophisticated than either Covington&apos;s, so this contribution could well be an extremely significant one towards the development of articulation testing software. In Somers (1998), I report an implementation and comparison of Connolly&apos;s measures with my own earlier work. What Would a New Version of Like? In the light of the above remarks, it is interesting to think about how we might specify reimplementation of where there could be considerable improvement in the data input. uses a crude phonetic transcription based only on a minimal character set, not even including lower-case letters. Clearly this restriction not be necessary nowadays. The software system Devia- Analysis by Computer) uses a software package called International phonetic Programs) for input of transcriptions (Perry 1995). Alternatively, it seems quite feasible to allow the transcriptions to be input using a standard word processor and a phonetic font, and to interpret the symbols accordingly. For a commercial implementation it would be better to follow the standard proposed by the IPA (Esling and Gaylord 1993), which has been approved by the ISO, and included in the Unicode definitions. Despite the reservations of all the speech-language pathology experts, it seems to me that the work on alignment discussed here (Somers 1978b; Covington 1996; Connolly 1997) suggests that this aspect of computerized articulation test analysis is a research aim well worth pursuing, especially if collaborators from the speech-language pathology field can be found. It would be rewarding if this article were to awaken interest in the problem. Acknowledgments I would like to thank the following people for their help in gathering the information</abstract>
<author confidence="0.519638">presented in this paper Catherine Adams</author>
<affiliation confidence="0.8763405">(University of Manchester), Lawrence Shriberg (University of Wisconsin-Madison),</affiliation>
<author confidence="0.798464">Julie Masterson</author>
<affiliation confidence="0.991406333333333">University), Carol Stoel-Gammon (University of Washington) and John Connolly (Loughborough University);</affiliation>
<abstract confidence="0.8716844">Michael Covington, for collaborating on the &amp;quot;bake-off&amp;quot;; Joe Somers, for providing some the example data; and the for their suggestions, which have been extremely valuable.</abstract>
<note confidence="0.503277142857143">273 Computational Linguistics Volume 25, Number 2 References Lilias E. 1967. Phonetics of A Practical Handbook. Bell, London. Martin J. 1994. Review of</note>
<title confidence="0.7774555">Interactive System for Phonological Language Teaching and</title>
<note confidence="0.96260225">Bardzik, Paul P. 1986. Review of Computer Articulation Analysis. 28(2):74-75. Cochran, Paula S. &amp; Julie J. Masterson. 1995.</note>
<abstract confidence="0.700209333333333">NOT using a computer in language assessment/intervention: In defense of reluctant clinician. Speech,</abstract>
<affiliation confidence="0.713242">Hearing Services in Schools,</affiliation>
<address confidence="0.926522">Connolly, John H. 1997. Quantifying</address>
<email confidence="0.673226">differences.</email>
<affiliation confidence="0.960336">amp; Phonetics,</affiliation>
<address confidence="0.976619">Covington, Michael A. 1996. An algorithm</address>
<abstract confidence="0.475146">to align words for historical comparison.</abstract>
<intro confidence="0.597359">Linguistics,</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Lilias E Armstrong</author>
</authors>
<title>The Phonetics of French: A Practical Handbook.</title>
<date>1967</date>
<publisher>G</publisher>
<location>Bell, London.</location>
<contexts>
<context position="15501" citStr="Armstrong 1967" startWordPosition="2450" endWordPosition="2451">) that his algorithm could be improved by using phonetic features. It is enlightening to take Covington&apos;s cognate alignment examples and to see what CAT would make of them. Looking first at the Spanish-French pairs (pp. 488f), we find that CAT agrees with Covington in 16 of the 20 cases. CAT has problems in three cases where the French has lost syllables that are stressed in Spanish, as in cabiza:cap (1);3 in the case of cirbol:arbre (2), CAT gets the correct alignment as identified by Covington (p. 488) if we omit the schwa in the French transcription (as would be normal for Parisian French (Armstrong 1967, 117). Example 1 (1) kabe0a kabe0a k a p - k - - p - (2) arb-ol arb-ol arbra- aRb--R For the English-German data (pp. 490f) CAT gets exactly the same alignments as Covington for all 20 pairs (including the incorrect analysis of this:dieses), though in CAT we would not transcribe the second element of the diphthongs in four of the examples. Like Covington&apos;s algorithm, CAT would correctly assign the [0] of mouth with the [t] rather than the [n] of Mund. 3 In this and subsequent examples, the CAT alignments (on the right) are shown in IPA; an acute accent marks the &amp;quot;stressed&amp;quot; vowel. Covington&apos;s </context>
</contexts>
<marker>Armstrong, 1967</marker>
<rawString>Armstrong, Lilias E. 1967. The Phonetics of French: A Practical Handbook. G Bell, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin J Ball</author>
</authors>
<title>Review of ISPA: Interactive System for Phonological Analysis. Child Language Teaching and Therapy,</title>
<date>1994</date>
<pages>10--97</pages>
<contexts>
<context position="5937" citStr="Ball 1994" startWordPosition="896" endWordPosition="897">ave been reviewed or discussed in the articles as cited: CAPP (Computer Analysis of Phonological Processes) (Long 1991; Kennedy 1986); Computer Managed Articulation Diagnosis (Bardzik 1986; Long 1991); Computerized Profiling 1.0 (Klee and Sahlie 1994); Computerized Profiling 2.0 (Gregg and Andrews 1995); ISPA 1 Several papers refer to articles in the Journal for Computer Users in Speech and Hearing, but at the time of writing I was unfortunately unable to locate any copies of this obviously relevant journal. 268 Somers Aligning Phonetic Segments (Interactive System for Phonological Analysis) (Ball 1994); Lingquest 2 (Long 1991); PAL (Pye Analysis of Language) (Pye and Ingram 1988; Leonard 1989); PDAC (Phonological Deviation Analysis by Computer) (Perry 1995); PEPPER (Programs to Examine Phonetic and Phonological Evaluation Records) (Dyson 1987; Pollock 1988); Process Analysis 2.0 (Long 1991). The best-known computer application in speech-language pathology research is the CHILDES database of language samples and associated software (MacWhinney and Snow 1985; MacWhinney 1992; Sokolov and Snow 1994). This is primarily aimed at facilitating the storage and search of large databases of transcrib</context>
</contexts>
<marker>Ball, 1994</marker>
<rawString>Ball, Martin J. 1994. Review of ISPA: Interactive System for Phonological Analysis. Child Language Teaching and Therapy, 10:97-102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul P Bardzik</author>
</authors>
<title>Review of Computer Managed Articulation Analysis.</title>
<date>1986</date>
<pages>28--2</pages>
<location>ASHA,</location>
<contexts>
<context position="5515" citStr="Bardzik 1986" startWordPosition="832" endWordPosition="833">atistics), treatment (computer-based games), and clerical uses.1 Those programs reported in the literature which specifically address the problem of articulation testing are listed below. For many of these programs, it seems that the only published information is in the user manual that accompanies the software. As far as one can tell, in none of the packages is the data analysis fully automatic. The following packages have been reviewed or discussed in the articles as cited: CAPP (Computer Analysis of Phonological Processes) (Long 1991; Kennedy 1986); Computer Managed Articulation Diagnosis (Bardzik 1986; Long 1991); Computerized Profiling 1.0 (Klee and Sahlie 1994); Computerized Profiling 2.0 (Gregg and Andrews 1995); ISPA 1 Several papers refer to articles in the Journal for Computer Users in Speech and Hearing, but at the time of writing I was unfortunately unable to locate any copies of this obviously relevant journal. 268 Somers Aligning Phonetic Segments (Interactive System for Phonological Analysis) (Ball 1994); Lingquest 2 (Long 1991); PAL (Pye Analysis of Language) (Pye and Ingram 1988; Leonard 1989); PDAC (Phonological Deviation Analysis by Computer) (Perry 1995); PEPPER (Programs t</context>
</contexts>
<marker>Bardzik, 1986</marker>
<rawString>Bardzik, Paul P. 1986. Review of Computer Managed Articulation Analysis. ASHA, 28(2):74-75.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paula S Cochran</author>
<author>Julie J Masterson</author>
</authors>
<title>NOT using a computer in language assessment/intervention:</title>
<date>1995</date>
<booktitle>In defense of the reluctant clinician. Language, Speech, and Hearing Services in Schools,</booktitle>
<pages>26--213</pages>
<contexts>
<context position="4641" citStr="Cochran and Masterson (1995)" startWordPosition="699" endWordPosition="702"> Comparatively little has appeared in the speechlanguage disorders literature on the specific topic of computerized articulation testing in the nearly 20 years since the CAT program was developed. Software for computerized language analysis does exist, but is mainly for grammatical and lexical analysis. Fairly thorough overviews are given by Rushakoff (1984), Rushakoff and Schwartz (1986), Long (1991), Long and Masterson (1993), and Miller and Klee (1995), though of course these may be more or less out of date. Other very general works such as Schwartz (1984), Curtis (1987), Silverman (1987), Cochran and Masterson (1995), and Masterson (1995) cover the use of computers by clinicians for all aspects of their work, including screening and diagnosis of various language skills (lexis, grammar, understanding, and auditory skills, as well as articulation) but also research (use of statistics), treatment (computer-based games), and clerical uses.1 Those programs reported in the literature which specifically address the problem of articulation testing are listed below. For many of these programs, it seems that the only published information is in the user manual that accompanies the software. As far as one can tell, </context>
</contexts>
<marker>Cochran, Masterson, 1995</marker>
<rawString>Cochran, Paula S. &amp; Julie J. Masterson. 1995. NOT using a computer in language assessment/intervention: In defense of the reluctant clinician. Language, Speech, and Hearing Services in Schools, 26:213-222.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John H Connolly</author>
</authors>
<title>Quantifying target-realization differences.</title>
<date>1997</date>
<journal>Clinical Linguistics &amp; Phonetics,</journal>
<pages>11--267</pages>
<contexts>
<context position="18860" citStr="Connolly 1997" startWordPosition="2993" endWordPosition="2994">ceived the same score. For example, with the stamps:[dauxs] alignment mentioned above, all six different combinations of consonant alignment either side of the vowel are proposed with an equal score. This is because, as Covington (personal communication) readily points out, &amp;quot;it doesn&apos;t know anything about place of articulation.&amp;quot; 272 Somers Aligning Phonetic Segments 4. Conclusions 4.1 Connolly&apos;s New Algorithm Since the appearance of Covington&apos;s article (and even since the first draft of this reply), a highly relevant article has appeared, which—coincidentally—addresses the issues raised here (Connolly 1997). In this two-part article, Connolly first suggests ways of quantifying the difference between two individual phones, on the basis of perceptual and articulatory differences, and using either a Euclidean distance metric or, like CAT, a feature-based metric. Connolly&apos;s proposals are more elaborate, however, in that they permit specific differences to be weighted, so as to reflect the relative importance of each opposition. In the second part of the article, Connolly introduces a distance measure for comparing sequences of phones, based on the Levenshtein distance wellknown in the speech process</context>
<context position="21467" citStr="Connolly 1997" startWordPosition="3390" endWordPosition="3391">ational phonetic Programs) for input of transcriptions (Perry 1995). Alternatively, it seems quite feasible to allow the transcriptions to be input using a standard word processor and a phonetic font, and to interpret the symbols accordingly. For a commercial implementation it would be better to follow the standard proposed by the IPA (Esling and Gaylord 1993), which has been approved by the ISO, and included in the Unicode definitions. Despite the reservations of all the speech-language pathology experts, it seems to me that the work on alignment discussed here (Somers 1978b; Covington 1996; Connolly 1997) suggests that this aspect of computerized articulation test analysis is a research aim well worth pursuing, especially if collaborators from the speech-language pathology field can be found. It would be rewarding if this article were to awaken interest in the problem. Acknowledgments I would like to thank the following people for their help in gathering the information presented in this paper: Catherine Adams (University of Manchester), Lawrence Shriberg (University of Wisconsin-Madison), Julie Masterson (Southwest Missouri State University), Carol Stoel-Gammon (University of Washington) and </context>
</contexts>
<marker>Connolly, 1997</marker>
<rawString>Connolly, John H. 1997. Quantifying target-realization differences. Clinical Linguistics &amp; Phonetics, 11:267-298.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael A Covington</author>
</authors>
<title>An algorithm to align words for historical comparison.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<pages>22--481</pages>
<contexts>
<context position="2453" citStr="Covington 1996" startWordPosition="366" endWordPosition="367">omputerised Articulation Test), which I had developed to automate the assessment of children&apos;s articulation tests. At the heart of this program was an algorithm very similar to the one reported by Covington. Whereas Covington seeks to align the segments in possible historical cognates, CAT aligns the segments of a child&apos;s articulation with those of the adult model, and on the basis of this looks for evidence of the phonological processes listed in Table 1. For example, if elephant [clifAnt] is pronounced [evat], we need to decide which of several possible alignments is the most plausible (cf. Covington 1996, 481): E--va—t EIT9- - -t E--vat— etc. E1If ant ElIf ant Elif ant E 11f ant If applied to a body of articulation data, e.g., a corpus of, say, 45 words elicited from the child as in a standardized articulation test, the evidence of each phonological process can be quantified, and the overall picture compared with the model of the average child, to give an individual&apos;s &amp;quot;articulation age&amp;quot; and profile. * Centre for Computational Linguistics, UMIST, Manchester, England. E-mail: harold@ccLumistac.uk © 1999 Association for Computational Linguistics Computational Linguistics Volume 25, Number 2 Tabl</context>
<context position="21451" citStr="Covington 1996" startWordPosition="3388" endWordPosition="3389"> (Logical International phonetic Programs) for input of transcriptions (Perry 1995). Alternatively, it seems quite feasible to allow the transcriptions to be input using a standard word processor and a phonetic font, and to interpret the symbols accordingly. For a commercial implementation it would be better to follow the standard proposed by the IPA (Esling and Gaylord 1993), which has been approved by the ISO, and included in the Unicode definitions. Despite the reservations of all the speech-language pathology experts, it seems to me that the work on alignment discussed here (Somers 1978b; Covington 1996; Connolly 1997) suggests that this aspect of computerized articulation test analysis is a research aim well worth pursuing, especially if collaborators from the speech-language pathology field can be found. It would be rewarding if this article were to awaken interest in the problem. Acknowledgments I would like to thank the following people for their help in gathering the information presented in this paper: Catherine Adams (University of Manchester), Lawrence Shriberg (University of Wisconsin-Madison), Julie Masterson (Southwest Missouri State University), Carol Stoel-Gammon (University of </context>
</contexts>
<marker>Covington, 1996</marker>
<rawString>Covington, Michael A. 1996. An algorithm to align words for historical comparison. Computational Linguistics, 22:481-496.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jack F Curtis</author>
</authors>
<title>An Introduction to Microcomputers in Speech, Language, and Hearing. College-Hill,</title>
<date>1987</date>
<location>Boston, MA.</location>
<contexts>
<context position="4593" citStr="Curtis (1987)" startWordPosition="695" endWordPosition="696">in a way almost identical to CAT. Comparatively little has appeared in the speechlanguage disorders literature on the specific topic of computerized articulation testing in the nearly 20 years since the CAT program was developed. Software for computerized language analysis does exist, but is mainly for grammatical and lexical analysis. Fairly thorough overviews are given by Rushakoff (1984), Rushakoff and Schwartz (1986), Long (1991), Long and Masterson (1993), and Miller and Klee (1995), though of course these may be more or less out of date. Other very general works such as Schwartz (1984), Curtis (1987), Silverman (1987), Cochran and Masterson (1995), and Masterson (1995) cover the use of computers by clinicians for all aspects of their work, including screening and diagnosis of various language skills (lexis, grammar, understanding, and auditory skills, as well as articulation) but also research (use of statistics), treatment (computer-based games), and clerical uses.1 Those programs reported in the literature which specifically address the problem of articulation testing are listed below. For many of these programs, it seems that the only published information is in the user manual that ac</context>
</contexts>
<marker>Curtis, 1987</marker>
<rawString>Curtis, Jack F. 1987. An Introduction to Microcomputers in Speech, Language, and Hearing. College-Hill, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alice T Dyson</author>
</authors>
<title>Review of PEPPER: Programs to Examine Phoentic and Phonological Evaluation Records. Child Language Teaching and Therapy,</title>
<date>1987</date>
<pages>3--329</pages>
<contexts>
<context position="6182" citStr="Dyson 1987" startWordPosition="930" endWordPosition="931"> 1994); Computerized Profiling 2.0 (Gregg and Andrews 1995); ISPA 1 Several papers refer to articles in the Journal for Computer Users in Speech and Hearing, but at the time of writing I was unfortunately unable to locate any copies of this obviously relevant journal. 268 Somers Aligning Phonetic Segments (Interactive System for Phonological Analysis) (Ball 1994); Lingquest 2 (Long 1991); PAL (Pye Analysis of Language) (Pye and Ingram 1988; Leonard 1989); PDAC (Phonological Deviation Analysis by Computer) (Perry 1995); PEPPER (Programs to Examine Phonetic and Phonological Evaluation Records) (Dyson 1987; Pollock 1988); Process Analysis 2.0 (Long 1991). The best-known computer application in speech-language pathology research is the CHILDES database of language samples and associated software (MacWhinney and Snow 1985; MacWhinney 1992; Sokolov and Snow 1994). This is primarily aimed at facilitating the storage and search of large databases of transcribed clinical data, where the transcription is basically orthographic, with mark-up for gestures, pauses, and other conversational features. Provision is made for a phonetic transcription too, using a &amp;quot;translation&amp;quot; of the IPA (International Phonet</context>
</contexts>
<marker>Dyson, 1987</marker>
<rawString>Dyson, Alice T. 1987. Review of PEPPER: Programs to Examine Phoentic and Phonological Evaluation Records. Child Language Teaching and Therapy, 3:329-335.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John H Esling</author>
<author>Harry Gaylord</author>
</authors>
<title>Computer codes for phonetic symbols.</title>
<date>1993</date>
<journal>Journal of the International Phonetic Association,</journal>
<pages>23--83</pages>
<contexts>
<context position="21215" citStr="Esling and Gaylord 1993" startWordPosition="3349" endWordPosition="3352">ion based only on a minimal character set, not even including lower-case letters. Clearly this restriction would not be necessary nowadays. The software system PDAC (Phonological Deviation Analysis by Computer) uses a software package called LIPP (Logical International phonetic Programs) for input of transcriptions (Perry 1995). Alternatively, it seems quite feasible to allow the transcriptions to be input using a standard word processor and a phonetic font, and to interpret the symbols accordingly. For a commercial implementation it would be better to follow the standard proposed by the IPA (Esling and Gaylord 1993), which has been approved by the ISO, and included in the Unicode definitions. Despite the reservations of all the speech-language pathology experts, it seems to me that the work on alignment discussed here (Somers 1978b; Covington 1996; Connolly 1997) suggests that this aspect of computerized articulation test analysis is a research aim well worth pursuing, especially if collaborators from the speech-language pathology field can be found. It would be rewarding if this article were to awaken interest in the problem. Acknowledgments I would like to thank the following people for their help in g</context>
</contexts>
<marker>Esling, Gaylord, 1993</marker>
<rawString>Esling, John H. &amp; Harry Gaylord. 1993. Computer codes for phonetic symbols. Journal of the International Phonetic Association, 23:83-97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marjorie A Faircloth</author>
</authors>
<title>Computer-assisted articulation analysis. Paper presented at the Annual Convention of the American Speech and Hearing Association,</title>
<date>1971</date>
<pages>13--534</pages>
<location>Chicago, IL,</location>
<contexts>
<context position="3818" citStr="Faircloth (1971)" startWordPosition="572" endWordPosition="573"> elifant efant Consonant cluster reduction stamps stamps tam Stopping kiss kis kit Fronting key ki ti Denasalisation mummy mAmi bAbi Affrication tent tent tents Vocalisation (1) bottle botl botu Vocalisation (2) chimney tfimni trimini Depalatalisation fish fif fis Devoicing dogs dog z doks Voicing tent tent dent Assimilation dog dog gog Lisping kiss kis ki0 S-lateralisation fish fif fii Ejectivisation tent tent tent&apos; Metathesis remember rimemb a miremb a Gliding look luk wuk 2. Use of the Computer by Speech Clinicians Early studies reporting the use of computers by speech pathologists include Faircloth (1971), van Demark and Tharp (1973), and Telage (1980), none of which involves automatic analysis of the input, though the last named uses binary articulatory features in a way almost identical to CAT. Comparatively little has appeared in the speechlanguage disorders literature on the specific topic of computerized articulation testing in the nearly 20 years since the CAT program was developed. Software for computerized language analysis does exist, but is mainly for grammatical and lexical analysis. Fairly thorough overviews are given by Rushakoff (1984), Rushakoff and Schwartz (1986), Long (1991),</context>
</contexts>
<marker>Faircloth, 1971</marker>
<rawString>Faircloth, Marjorie A. 1971. Computer-assisted articulation analysis. Paper presented at the Annual Convention of the American Speech and Hearing Association, Chicago, IL, Sept. 1971. ASHA, 13:534.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Valorie Andrews</author>
</authors>
<title>Review of Computerized Profiling</title>
<date>1995</date>
<pages>11--209</pages>
<contexts>
<context position="5631" citStr="Andrews 1995" startWordPosition="848" endWordPosition="849">ecifically address the problem of articulation testing are listed below. For many of these programs, it seems that the only published information is in the user manual that accompanies the software. As far as one can tell, in none of the packages is the data analysis fully automatic. The following packages have been reviewed or discussed in the articles as cited: CAPP (Computer Analysis of Phonological Processes) (Long 1991; Kennedy 1986); Computer Managed Articulation Diagnosis (Bardzik 1986; Long 1991); Computerized Profiling 1.0 (Klee and Sahlie 1994); Computerized Profiling 2.0 (Gregg and Andrews 1995); ISPA 1 Several papers refer to articles in the Journal for Computer Users in Speech and Hearing, but at the time of writing I was unfortunately unable to locate any copies of this obviously relevant journal. 268 Somers Aligning Phonetic Segments (Interactive System for Phonological Analysis) (Ball 1994); Lingquest 2 (Long 1991); PAL (Pye Analysis of Language) (Pye and Ingram 1988; Leonard 1989); PDAC (Phonological Deviation Analysis by Computer) (Perry 1995); PEPPER (Programs to Examine Phonetic and Phonological Evaluation Records) (Dyson 1987; Pollock 1988); Process Analysis 2.0 (Long 1991)</context>
</contexts>
<marker>Andrews, 1995</marker>
<rawString>Gregg, Ellen Meyer. &amp; Valorie Andrews. 1995. Review of Computerized Profiling (1993). Child Language Teaching and Therapy, 11:209-216.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Ingram</author>
</authors>
<title>Phonological Disability in Children. Edward</title>
<date>1976</date>
<location>Arnold, London.</location>
<marker>Ingram, 1976</marker>
<rawString>Ingram, David. 1976. Phonological Disability in Children. Edward Arnold, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathleen A Kennedy</author>
</authors>
<title>Review of Computer Analysis of Phonological Processes.</title>
<date>1986</date>
<location>ASHA,</location>
<contexts>
<context position="5460" citStr="Kennedy 1986" startWordPosition="826" endWordPosition="827">s, as well as articulation) but also research (use of statistics), treatment (computer-based games), and clerical uses.1 Those programs reported in the literature which specifically address the problem of articulation testing are listed below. For many of these programs, it seems that the only published information is in the user manual that accompanies the software. As far as one can tell, in none of the packages is the data analysis fully automatic. The following packages have been reviewed or discussed in the articles as cited: CAPP (Computer Analysis of Phonological Processes) (Long 1991; Kennedy 1986); Computer Managed Articulation Diagnosis (Bardzik 1986; Long 1991); Computerized Profiling 1.0 (Klee and Sahlie 1994); Computerized Profiling 2.0 (Gregg and Andrews 1995); ISPA 1 Several papers refer to articles in the Journal for Computer Users in Speech and Hearing, but at the time of writing I was unfortunately unable to locate any copies of this obviously relevant journal. 268 Somers Aligning Phonetic Segments (Interactive System for Phonological Analysis) (Ball 1994); Lingquest 2 (Long 1991); PAL (Pye Analysis of Language) (Pye and Ingram 1988; Leonard 1989); PDAC (Phonological Deviation</context>
</contexts>
<marker>Kennedy, 1986</marker>
<rawString>Kennedy, Kathleen A. 1986. Review of Computer Analysis of Phonological Processes. ASHA, 28(8):71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Klee</author>
<author>E Sahlie</author>
</authors>
<title>Review of Computerized Profiling Version 1.0. Child Language Teaching and Therapy,</title>
<date>1994</date>
<pages>3--87</pages>
<contexts>
<context position="5578" citStr="Klee and Sahlie 1994" startWordPosition="839" endWordPosition="842">cal uses.1 Those programs reported in the literature which specifically address the problem of articulation testing are listed below. For many of these programs, it seems that the only published information is in the user manual that accompanies the software. As far as one can tell, in none of the packages is the data analysis fully automatic. The following packages have been reviewed or discussed in the articles as cited: CAPP (Computer Analysis of Phonological Processes) (Long 1991; Kennedy 1986); Computer Managed Articulation Diagnosis (Bardzik 1986; Long 1991); Computerized Profiling 1.0 (Klee and Sahlie 1994); Computerized Profiling 2.0 (Gregg and Andrews 1995); ISPA 1 Several papers refer to articles in the Journal for Computer Users in Speech and Hearing, but at the time of writing I was unfortunately unable to locate any copies of this obviously relevant journal. 268 Somers Aligning Phonetic Segments (Interactive System for Phonological Analysis) (Ball 1994); Lingquest 2 (Long 1991); PAL (Pye Analysis of Language) (Pye and Ingram 1988; Leonard 1989); PDAC (Phonological Deviation Analysis by Computer) (Perry 1995); PEPPER (Programs to Examine Phonetic and Phonological Evaluation Records) (Dyson </context>
</contexts>
<marker>Klee, Sahlie, 1994</marker>
<rawString>Klee, T. &amp; E. Sahlie. 1994. Review of Computerized Profiling Version 1.0. Child Language Teaching and Therapy, 3:87-93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laurence B Leonard</author>
</authors>
<title>Review of the Pye Analysis of Language. Child Language Teaching and Therapy,</title>
<date>1989</date>
<pages>5--79</pages>
<contexts>
<context position="6030" citStr="Leonard 1989" startWordPosition="911" endWordPosition="912">ogical Processes) (Long 1991; Kennedy 1986); Computer Managed Articulation Diagnosis (Bardzik 1986; Long 1991); Computerized Profiling 1.0 (Klee and Sahlie 1994); Computerized Profiling 2.0 (Gregg and Andrews 1995); ISPA 1 Several papers refer to articles in the Journal for Computer Users in Speech and Hearing, but at the time of writing I was unfortunately unable to locate any copies of this obviously relevant journal. 268 Somers Aligning Phonetic Segments (Interactive System for Phonological Analysis) (Ball 1994); Lingquest 2 (Long 1991); PAL (Pye Analysis of Language) (Pye and Ingram 1988; Leonard 1989); PDAC (Phonological Deviation Analysis by Computer) (Perry 1995); PEPPER (Programs to Examine Phonetic and Phonological Evaluation Records) (Dyson 1987; Pollock 1988); Process Analysis 2.0 (Long 1991). The best-known computer application in speech-language pathology research is the CHILDES database of language samples and associated software (MacWhinney and Snow 1985; MacWhinney 1992; Sokolov and Snow 1994). This is primarily aimed at facilitating the storage and search of large databases of transcribed clinical data, where the transcription is basically orthographic, with mark-up for gesture</context>
</contexts>
<marker>Leonard, 1989</marker>
<rawString>Leonard, Laurence B. 1989. Review of the Pye Analysis of Language. Child Language Teaching and Therapy, 5:79-86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven H Long</author>
</authors>
<title>Integrating microcomputer applications into speech and language assessment. Topics in Language Disorders,</title>
<date>1991</date>
<pages>11--2</pages>
<contexts>
<context position="4417" citStr="Long (1991)" startWordPosition="664" endWordPosition="665">cloth (1971), van Demark and Tharp (1973), and Telage (1980), none of which involves automatic analysis of the input, though the last named uses binary articulatory features in a way almost identical to CAT. Comparatively little has appeared in the speechlanguage disorders literature on the specific topic of computerized articulation testing in the nearly 20 years since the CAT program was developed. Software for computerized language analysis does exist, but is mainly for grammatical and lexical analysis. Fairly thorough overviews are given by Rushakoff (1984), Rushakoff and Schwartz (1986), Long (1991), Long and Masterson (1993), and Miller and Klee (1995), though of course these may be more or less out of date. Other very general works such as Schwartz (1984), Curtis (1987), Silverman (1987), Cochran and Masterson (1995), and Masterson (1995) cover the use of computers by clinicians for all aspects of their work, including screening and diagnosis of various language skills (lexis, grammar, understanding, and auditory skills, as well as articulation) but also research (use of statistics), treatment (computer-based games), and clerical uses.1 Those programs reported in the literature which s</context>
<context position="5962" citStr="Long 1991" startWordPosition="900" endWordPosition="901">ussed in the articles as cited: CAPP (Computer Analysis of Phonological Processes) (Long 1991; Kennedy 1986); Computer Managed Articulation Diagnosis (Bardzik 1986; Long 1991); Computerized Profiling 1.0 (Klee and Sahlie 1994); Computerized Profiling 2.0 (Gregg and Andrews 1995); ISPA 1 Several papers refer to articles in the Journal for Computer Users in Speech and Hearing, but at the time of writing I was unfortunately unable to locate any copies of this obviously relevant journal. 268 Somers Aligning Phonetic Segments (Interactive System for Phonological Analysis) (Ball 1994); Lingquest 2 (Long 1991); PAL (Pye Analysis of Language) (Pye and Ingram 1988; Leonard 1989); PDAC (Phonological Deviation Analysis by Computer) (Perry 1995); PEPPER (Programs to Examine Phonetic and Phonological Evaluation Records) (Dyson 1987; Pollock 1988); Process Analysis 2.0 (Long 1991). The best-known computer application in speech-language pathology research is the CHILDES database of language samples and associated software (MacWhinney and Snow 1985; MacWhinney 1992; Sokolov and Snow 1994). This is primarily aimed at facilitating the storage and search of large databases of transcribed clinical data, where t</context>
</contexts>
<marker>Long, 1991</marker>
<rawString>Long, Steven H. 1991. Integrating microcomputer applications into speech and language assessment. Topics in Language Disorders, 11(2):1-17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven H Long</author>
<author>Julie J Masterson</author>
</authors>
<title>Computer technology: Use in language analysis.</title>
<date>1993</date>
<journal>ASHA</journal>
<pages>35--9</pages>
<contexts>
<context position="4444" citStr="Long and Masterson (1993)" startWordPosition="666" endWordPosition="669"> van Demark and Tharp (1973), and Telage (1980), none of which involves automatic analysis of the input, though the last named uses binary articulatory features in a way almost identical to CAT. Comparatively little has appeared in the speechlanguage disorders literature on the specific topic of computerized articulation testing in the nearly 20 years since the CAT program was developed. Software for computerized language analysis does exist, but is mainly for grammatical and lexical analysis. Fairly thorough overviews are given by Rushakoff (1984), Rushakoff and Schwartz (1986), Long (1991), Long and Masterson (1993), and Miller and Klee (1995), though of course these may be more or less out of date. Other very general works such as Schwartz (1984), Curtis (1987), Silverman (1987), Cochran and Masterson (1995), and Masterson (1995) cover the use of computers by clinicians for all aspects of their work, including screening and diagnosis of various language skills (lexis, grammar, understanding, and auditory skills, as well as articulation) but also research (use of statistics), treatment (computer-based games), and clerical uses.1 Those programs reported in the literature which specifically address the pro</context>
</contexts>
<marker>Long, Masterson, 1993</marker>
<rawString>Long, Steven H. &amp; Julie J. Masterson. 1993. Computer technology: Use in language analysis. ASHA 35(9):40-41,51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brain MacWhinney</author>
</authors>
<title>The CHILDES Project: Tools for Analyzing Talk. Lawrence Erlbaum Associates,</title>
<date>1992</date>
<location>Hillsdale, NJ.</location>
<contexts>
<context position="6417" citStr="MacWhinney 1992" startWordPosition="961" endWordPosition="962">es of this obviously relevant journal. 268 Somers Aligning Phonetic Segments (Interactive System for Phonological Analysis) (Ball 1994); Lingquest 2 (Long 1991); PAL (Pye Analysis of Language) (Pye and Ingram 1988; Leonard 1989); PDAC (Phonological Deviation Analysis by Computer) (Perry 1995); PEPPER (Programs to Examine Phonetic and Phonological Evaluation Records) (Dyson 1987; Pollock 1988); Process Analysis 2.0 (Long 1991). The best-known computer application in speech-language pathology research is the CHILDES database of language samples and associated software (MacWhinney and Snow 1985; MacWhinney 1992; Sokolov and Snow 1994). This is primarily aimed at facilitating the storage and search of large databases of transcribed clinical data, where the transcription is basically orthographic, with mark-up for gestures, pauses, and other conversational features. Provision is made for a phonetic transcription too, using a &amp;quot;translation&amp;quot; of the IPA (International Phonetic Association) alphabet into ASCII symbols called &amp;quot;UNIBET&amp;quot; (MacWhinney 1992, 61ff). Although the organizers of the CHILDES database have had input from computational linguists on the question of mark-up, there is little or no automati</context>
</contexts>
<marker>MacWhinney, 1992</marker>
<rawString>MacWhinney, Brain. 1992. The CHILDES Project: Tools for Analyzing Talk. Lawrence Erlbaum Associates, Hillsdale, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian MacWhinney</author>
<author>Catherine Snow</author>
</authors>
<title>The child language data exchange system.</title>
<date>1985</date>
<journal>Journal of Child Language,</journal>
<pages>12--271</pages>
<contexts>
<context position="6400" citStr="MacWhinney and Snow 1985" startWordPosition="957" endWordPosition="960"> unable to locate any copies of this obviously relevant journal. 268 Somers Aligning Phonetic Segments (Interactive System for Phonological Analysis) (Ball 1994); Lingquest 2 (Long 1991); PAL (Pye Analysis of Language) (Pye and Ingram 1988; Leonard 1989); PDAC (Phonological Deviation Analysis by Computer) (Perry 1995); PEPPER (Programs to Examine Phonetic and Phonological Evaluation Records) (Dyson 1987; Pollock 1988); Process Analysis 2.0 (Long 1991). The best-known computer application in speech-language pathology research is the CHILDES database of language samples and associated software (MacWhinney and Snow 1985; MacWhinney 1992; Sokolov and Snow 1994). This is primarily aimed at facilitating the storage and search of large databases of transcribed clinical data, where the transcription is basically orthographic, with mark-up for gestures, pauses, and other conversational features. Provision is made for a phonetic transcription too, using a &amp;quot;translation&amp;quot; of the IPA (International Phonetic Association) alphabet into ASCII symbols called &amp;quot;UNIBET&amp;quot; (MacWhinney 1992, 61ff). Although the organizers of the CHILDES database have had input from computational linguists on the question of mark-up, there is litt</context>
</contexts>
<marker>MacWhinney, Snow, 1985</marker>
<rawString>MacWhinney, Brian &amp; Catherine Snow. 1985. The child language data exchange system. Journal of Child Language, 12:271-296.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julie J Masterson</author>
</authors>
<title>Computer applications in the schools: What we can do-what we should do.</title>
<date>1995</date>
<booktitle>Language, Speech, and Hearing Services in Schools,</booktitle>
<pages>26--211</pages>
<contexts>
<context position="4641" citStr="Masterson (1995)" startWordPosition="701" endWordPosition="702">ly little has appeared in the speechlanguage disorders literature on the specific topic of computerized articulation testing in the nearly 20 years since the CAT program was developed. Software for computerized language analysis does exist, but is mainly for grammatical and lexical analysis. Fairly thorough overviews are given by Rushakoff (1984), Rushakoff and Schwartz (1986), Long (1991), Long and Masterson (1993), and Miller and Klee (1995), though of course these may be more or less out of date. Other very general works such as Schwartz (1984), Curtis (1987), Silverman (1987), Cochran and Masterson (1995), and Masterson (1995) cover the use of computers by clinicians for all aspects of their work, including screening and diagnosis of various language skills (lexis, grammar, understanding, and auditory skills, as well as articulation) but also research (use of statistics), treatment (computer-based games), and clerical uses.1 Those programs reported in the literature which specifically address the problem of articulation testing are listed below. For many of these programs, it seems that the only published information is in the user manual that accompanies the software. As far as one can tell, </context>
</contexts>
<marker>Masterson, 1995</marker>
<rawString>Masterson, Julie J. 1995. Computer applications in the schools: What we can do-what we should do. Language, Speech, and Hearing Services in Schools, 26:211-212.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon F Miller</author>
<author>Thomas Klee</author>
</authors>
<title>Computational approaches to the analysis of language impairment.</title>
<date>1995</date>
<booktitle>The Handbook of Child Language.</booktitle>
<pages>545--572</pages>
<editor>In Paul Fletcher &amp; Brian MacWhinney, editors,</editor>
<publisher>Blackwell,</publisher>
<location>Oxford,</location>
<contexts>
<context position="4472" citStr="Miller and Klee (1995)" startWordPosition="671" endWordPosition="674">nd Telage (1980), none of which involves automatic analysis of the input, though the last named uses binary articulatory features in a way almost identical to CAT. Comparatively little has appeared in the speechlanguage disorders literature on the specific topic of computerized articulation testing in the nearly 20 years since the CAT program was developed. Software for computerized language analysis does exist, but is mainly for grammatical and lexical analysis. Fairly thorough overviews are given by Rushakoff (1984), Rushakoff and Schwartz (1986), Long (1991), Long and Masterson (1993), and Miller and Klee (1995), though of course these may be more or less out of date. Other very general works such as Schwartz (1984), Curtis (1987), Silverman (1987), Cochran and Masterson (1995), and Masterson (1995) cover the use of computers by clinicians for all aspects of their work, including screening and diagnosis of various language skills (lexis, grammar, understanding, and auditory skills, as well as articulation) but also research (use of statistics), treatment (computer-based games), and clerical uses.1 Those programs reported in the literature which specifically address the problem of articulation testing</context>
</contexts>
<marker>Miller, Klee, 1995</marker>
<rawString>Miller, Jon F. &amp; Thomas Klee. 1995. Computational approaches to the analysis of language impairment. In Paul Fletcher &amp; Brian MacWhinney, editors, The Handbook of Child Language. Blackwell, Oxford, pages 545-572.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cecyle K Perry</author>
</authors>
<title>Review of Phonological Deviation Analysis by Computer (PoAc). Child Language Teaching and Therapy,</title>
<date>1995</date>
<pages>11--331</pages>
<contexts>
<context position="6095" citStr="Perry 1995" startWordPosition="919" endWordPosition="920">ulation Diagnosis (Bardzik 1986; Long 1991); Computerized Profiling 1.0 (Klee and Sahlie 1994); Computerized Profiling 2.0 (Gregg and Andrews 1995); ISPA 1 Several papers refer to articles in the Journal for Computer Users in Speech and Hearing, but at the time of writing I was unfortunately unable to locate any copies of this obviously relevant journal. 268 Somers Aligning Phonetic Segments (Interactive System for Phonological Analysis) (Ball 1994); Lingquest 2 (Long 1991); PAL (Pye Analysis of Language) (Pye and Ingram 1988; Leonard 1989); PDAC (Phonological Deviation Analysis by Computer) (Perry 1995); PEPPER (Programs to Examine Phonetic and Phonological Evaluation Records) (Dyson 1987; Pollock 1988); Process Analysis 2.0 (Long 1991). The best-known computer application in speech-language pathology research is the CHILDES database of language samples and associated software (MacWhinney and Snow 1985; MacWhinney 1992; Sokolov and Snow 1994). This is primarily aimed at facilitating the storage and search of large databases of transcribed clinical data, where the transcription is basically orthographic, with mark-up for gestures, pauses, and other conversational features. Provision is made f</context>
<context position="20920" citStr="Perry 1995" startWordPosition="3303" endWordPosition="3304">k. 4.2 What Would a New Version of CAT Be Like? In the light of the above remarks, it is interesting to think about how we might specify a reimplementation of CAT. One area where there could be considerable improvement is in the data input. CAT uses a very crude phonetic transcription based only on a minimal character set, not even including lower-case letters. Clearly this restriction would not be necessary nowadays. The software system PDAC (Phonological Deviation Analysis by Computer) uses a software package called LIPP (Logical International phonetic Programs) for input of transcriptions (Perry 1995). Alternatively, it seems quite feasible to allow the transcriptions to be input using a standard word processor and a phonetic font, and to interpret the symbols accordingly. For a commercial implementation it would be better to follow the standard proposed by the IPA (Esling and Gaylord 1993), which has been approved by the ISO, and included in the Unicode definitions. Despite the reservations of all the speech-language pathology experts, it seems to me that the work on alignment discussed here (Somers 1978b; Covington 1996; Connolly 1997) suggests that this aspect of computerized articulati</context>
</contexts>
<marker>Perry, 1995</marker>
<rawString>Perry, Cecyle K. 1995. Review of Phonological Deviation Analysis by Computer (PoAc). Child Language Teaching and Therapy, 11:331-340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karen E Pollock</author>
</authors>
<title>Review of PEPPER: Programs to Examine Phonetic and Phonological Evaluation Records.</title>
<date>1988</date>
<pages>30--8</pages>
<location>ASHA,</location>
<contexts>
<context position="6197" citStr="Pollock 1988" startWordPosition="932" endWordPosition="933">uterized Profiling 2.0 (Gregg and Andrews 1995); ISPA 1 Several papers refer to articles in the Journal for Computer Users in Speech and Hearing, but at the time of writing I was unfortunately unable to locate any copies of this obviously relevant journal. 268 Somers Aligning Phonetic Segments (Interactive System for Phonological Analysis) (Ball 1994); Lingquest 2 (Long 1991); PAL (Pye Analysis of Language) (Pye and Ingram 1988; Leonard 1989); PDAC (Phonological Deviation Analysis by Computer) (Perry 1995); PEPPER (Programs to Examine Phonetic and Phonological Evaluation Records) (Dyson 1987; Pollock 1988); Process Analysis 2.0 (Long 1991). The best-known computer application in speech-language pathology research is the CHILDES database of language samples and associated software (MacWhinney and Snow 1985; MacWhinney 1992; Sokolov and Snow 1994). This is primarily aimed at facilitating the storage and search of large databases of transcribed clinical data, where the transcription is basically orthographic, with mark-up for gestures, pauses, and other conversational features. Provision is made for a phonetic transcription too, using a &amp;quot;translation&amp;quot; of the IPA (International Phonetic Association)</context>
</contexts>
<marker>Pollock, 1988</marker>
<rawString>Pollock, Karen E. 1988. Review of PEPPER: Programs to Examine Phonetic and Phonological Evaluation Records. ASHA, 30(8):57-58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Clifton Pye</author>
<author>David Ingram</author>
</authors>
<title>Automating the analysis of child phonology.</title>
<date>1988</date>
<journal>Clinical Linguistics &amp; Phonetics,</journal>
<pages>2--115</pages>
<contexts>
<context position="6015" citStr="Pye and Ingram 1988" startWordPosition="907" endWordPosition="910">er Analysis of Phonological Processes) (Long 1991; Kennedy 1986); Computer Managed Articulation Diagnosis (Bardzik 1986; Long 1991); Computerized Profiling 1.0 (Klee and Sahlie 1994); Computerized Profiling 2.0 (Gregg and Andrews 1995); ISPA 1 Several papers refer to articles in the Journal for Computer Users in Speech and Hearing, but at the time of writing I was unfortunately unable to locate any copies of this obviously relevant journal. 268 Somers Aligning Phonetic Segments (Interactive System for Phonological Analysis) (Ball 1994); Lingquest 2 (Long 1991); PAL (Pye Analysis of Language) (Pye and Ingram 1988; Leonard 1989); PDAC (Phonological Deviation Analysis by Computer) (Perry 1995); PEPPER (Programs to Examine Phonetic and Phonological Evaluation Records) (Dyson 1987; Pollock 1988); Process Analysis 2.0 (Long 1991). The best-known computer application in speech-language pathology research is the CHILDES database of language samples and associated software (MacWhinney and Snow 1985; MacWhinney 1992; Sokolov and Snow 1994). This is primarily aimed at facilitating the storage and search of large databases of transcribed clinical data, where the transcription is basically orthographic, with mark</context>
<context position="7313" citStr="Pye and Ingram (1988)" startWordPosition="1096" endWordPosition="1099">e for a phonetic transcription too, using a &amp;quot;translation&amp;quot; of the IPA (International Phonetic Association) alphabet into ASCII symbols called &amp;quot;UNIBET&amp;quot; (MacWhinney 1992, 61ff). Although the organizers of the CHILDES database have had input from computational linguists on the question of mark-up, there is little or no automatic analysis. Crucially, no attempt is made to compare on a phone-by-phone basis the child language data with adult models, so data on the types of phonological process listed in Table 1 cannot be extracted. This situation is typical of child language software, exemplified by Pye and Ingram (1988), whose PAL system uses a simple transcription, based on the IPA consonant chart, without the possibility of diacritics or special symbols to indicate specifically childish articulations. The system is unable to compare adult models with the child&apos;s output, and can only produce a &amp;quot;phonological lexicon&amp;quot;, i.e., a list of the different sounds attested: it is then up to the clinician to analyze this inventory, e.g., to see if sounds are used contrastively, or in complementary distribution. The authors suggest that matching the child&apos;s utterances to an adult model would involve a procedure which &amp;quot;w</context>
</contexts>
<marker>Pye, Ingram, 1988</marker>
<rawString>Pye, Clifton &amp; David Ingram. 1988. Automating the analysis of child phonology. Clinical Linguistics &amp; Phonetics, 2:115-137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gary E Rushakoff</author>
</authors>
<title>Clinical applications in communication disorders.</title>
<date>1984</date>
<booktitle>The Handbook of Microcomputer Applications in Communication Disorders.</booktitle>
<pages>147--171</pages>
<editor>In Arthur H. Schwartz, editor,</editor>
<publisher>College-Hill Press,</publisher>
<location>San Diego, CA,</location>
<contexts>
<context position="4373" citStr="Rushakoff (1984)" startWordPosition="658" endWordPosition="659"> of computers by speech pathologists include Faircloth (1971), van Demark and Tharp (1973), and Telage (1980), none of which involves automatic analysis of the input, though the last named uses binary articulatory features in a way almost identical to CAT. Comparatively little has appeared in the speechlanguage disorders literature on the specific topic of computerized articulation testing in the nearly 20 years since the CAT program was developed. Software for computerized language analysis does exist, but is mainly for grammatical and lexical analysis. Fairly thorough overviews are given by Rushakoff (1984), Rushakoff and Schwartz (1986), Long (1991), Long and Masterson (1993), and Miller and Klee (1995), though of course these may be more or less out of date. Other very general works such as Schwartz (1984), Curtis (1987), Silverman (1987), Cochran and Masterson (1995), and Masterson (1995) cover the use of computers by clinicians for all aspects of their work, including screening and diagnosis of various language skills (lexis, grammar, understanding, and auditory skills, as well as articulation) but also research (use of statistics), treatment (computer-based games), and clerical uses.1 Those</context>
</contexts>
<marker>Rushakoff, 1984</marker>
<rawString>Rushakoff, Gary E. 1984. Clinical applications in communication disorders. In Arthur H. Schwartz, editor, The Handbook of Microcomputer Applications in Communication Disorders. College-Hill Press, San Diego, CA, pages 147-171.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gary E Rushakoff</author>
<author>Arthur H Schwartz</author>
</authors>
<title>Clinical assessment software.</title>
<date>1986</date>
<booktitle>Microcomputer Applications in Rehabilitation of Communication Disorders.</booktitle>
<pages>1--24</pages>
<editor>In Michael L. Grossfeld &amp; Cathleen A. Grossfeld, editors,</editor>
<location>Aspen, Rockville, MD,</location>
<contexts>
<context position="4404" citStr="Rushakoff and Schwartz (1986)" startWordPosition="660" endWordPosition="663">peech pathologists include Faircloth (1971), van Demark and Tharp (1973), and Telage (1980), none of which involves automatic analysis of the input, though the last named uses binary articulatory features in a way almost identical to CAT. Comparatively little has appeared in the speechlanguage disorders literature on the specific topic of computerized articulation testing in the nearly 20 years since the CAT program was developed. Software for computerized language analysis does exist, but is mainly for grammatical and lexical analysis. Fairly thorough overviews are given by Rushakoff (1984), Rushakoff and Schwartz (1986), Long (1991), Long and Masterson (1993), and Miller and Klee (1995), though of course these may be more or less out of date. Other very general works such as Schwartz (1984), Curtis (1987), Silverman (1987), Cochran and Masterson (1995), and Masterson (1995) cover the use of computers by clinicians for all aspects of their work, including screening and diagnosis of various language skills (lexis, grammar, understanding, and auditory skills, as well as articulation) but also research (use of statistics), treatment (computer-based games), and clerical uses.1 Those programs reported in the liter</context>
</contexts>
<marker>Rushakoff, Schwartz, 1986</marker>
<rawString>Rushakoff, Gary E. &amp; Arthur H. Schwartz. 1986. Clinical assessment software. In Michael L. Grossfeld &amp; Cathleen A. Grossfeld, editors, Microcomputer Applications in Rehabilitation of Communication Disorders. Aspen, Rockville, MD, pages 1-24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arthur H Schwartz</author>
</authors>
<title>Microcomputer applications: Facts, functions, fads, and fallacies.</title>
<date>1984</date>
<journal>Journal of Childhood Communication Disorders,</journal>
<pages>8--89</pages>
<contexts>
<context position="4578" citStr="Schwartz (1984)" startWordPosition="693" endWordPosition="694">ulatory features in a way almost identical to CAT. Comparatively little has appeared in the speechlanguage disorders literature on the specific topic of computerized articulation testing in the nearly 20 years since the CAT program was developed. Software for computerized language analysis does exist, but is mainly for grammatical and lexical analysis. Fairly thorough overviews are given by Rushakoff (1984), Rushakoff and Schwartz (1986), Long (1991), Long and Masterson (1993), and Miller and Klee (1995), though of course these may be more or less out of date. Other very general works such as Schwartz (1984), Curtis (1987), Silverman (1987), Cochran and Masterson (1995), and Masterson (1995) cover the use of computers by clinicians for all aspects of their work, including screening and diagnosis of various language skills (lexis, grammar, understanding, and auditory skills, as well as articulation) but also research (use of statistics), treatment (computer-based games), and clerical uses.1 Those programs reported in the literature which specifically address the problem of articulation testing are listed below. For many of these programs, it seems that the only published information is in the user</context>
</contexts>
<marker>Schwartz, 1984</marker>
<rawString>Schwartz, Arthur H. 1984. Microcomputer applications: Facts, functions, fads, and fallacies. Journal of Childhood Communication Disorders, 8:89-111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franklin H Silverman</author>
</authors>
<title>Microcomputers in Speech-Language Pathology and Audiology: A Primer. Prentice-Hall,</title>
<date>1987</date>
<location>Englewood Cliffs, NJ.</location>
<contexts>
<context position="4611" citStr="Silverman (1987)" startWordPosition="697" endWordPosition="698"> identical to CAT. Comparatively little has appeared in the speechlanguage disorders literature on the specific topic of computerized articulation testing in the nearly 20 years since the CAT program was developed. Software for computerized language analysis does exist, but is mainly for grammatical and lexical analysis. Fairly thorough overviews are given by Rushakoff (1984), Rushakoff and Schwartz (1986), Long (1991), Long and Masterson (1993), and Miller and Klee (1995), though of course these may be more or less out of date. Other very general works such as Schwartz (1984), Curtis (1987), Silverman (1987), Cochran and Masterson (1995), and Masterson (1995) cover the use of computers by clinicians for all aspects of their work, including screening and diagnosis of various language skills (lexis, grammar, understanding, and auditory skills, as well as articulation) but also research (use of statistics), treatment (computer-based games), and clerical uses.1 Those programs reported in the literature which specifically address the problem of articulation testing are listed below. For many of these programs, it seems that the only published information is in the user manual that accompanies the soft</context>
</contexts>
<marker>Silverman, 1987</marker>
<rawString>Silverman, Franklin H. 1987. Microcomputers in Speech-Language Pathology and Audiology: A Primer. Prentice-Hall, Englewood Cliffs, NJ.</rawString>
</citation>
<citation valid="true">
<date>1994</date>
<booktitle>Handbook of Research in Language Development Using CHILDES. Lawrence Erlbaum Associates,</booktitle>
<editor>Sokolov, Jeffrey L. &amp; Catherine E. Snow, editors,</editor>
<location>Hillsdale, NJ.</location>
<marker>1994</marker>
<rawString>Sokolov, Jeffrey L. &amp; Catherine E. Snow, editors, 1994. Handbook of Research in Language Development Using CHILDES. Lawrence Erlbaum Associates, Hillsdale, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Somers</author>
</authors>
<title>Computer analysis of speech therapists&apos; articulation tests.</title>
<date>1978</date>
<journal>UMRCC Journal,</journal>
<pages>5--1</pages>
<institution>(University of Manchester Regional Computing Centre).</institution>
<contexts>
<context position="1787" citStr="Somers (1978" startWordPosition="260" endWordPosition="261">atory skills. Whether screening whole populations of children, or assessing individual referrals, the articulation test is an important tool for the speech clinician. A child&apos;s articulatory development is usually described with reference to an adult model, and in terms of deviations from it: a number of phonological &amp;quot;processes&amp;quot; (Table 1) can be identified (see Ingram [1976]), and their significance with respect to the chronological age of the child assessed (though often processes interact, so for example when spoon is pronounced [fun] we have consonant-cluster reduction and assimilation). In Somers (1978a, 1979) I reported a computer program called CAT (Computerised Articulation Test), which I had developed to automate the assessment of children&apos;s articulation tests. At the heart of this program was an algorithm very similar to the one reported by Covington. Whereas Covington seeks to align the segments in possible historical cognates, CAT aligns the segments of a child&apos;s articulation with those of the adult model, and on the basis of this looks for evidence of the phonological processes listed in Table 1. For example, if elephant [clifAnt] is pronounced [evat], we need to decide which of sev</context>
<context position="8353" citStr="Somers 1978" startWordPosition="1265" endWordPosition="1266">nds are used contrastively, or in complementary distribution. The authors suggest that matching the child&apos;s utterances to an adult model would involve a procedure which &amp;quot;would have to be very sophisticated indeed to handle complex cases of metathesis and deletion&amp;quot; (p. 124). As we show in Somers (1979) and in the next section, CAT was able to handle metathesis and deletion without being &amp;quot;very sophisticated indeed.&amp;quot; 3. The CAT Algorithm Since the Somers (1979) article was aimed at speech therapists, it did not describe the alignment algorithm as such, which is described only in a local journal (Somers 1978a) and—in great detail—in an M.A. thesis (Somers 1978b). It bears comparison with Covington&apos;s algorithm, though it should be said that the implementation in Pascal would be judged crude in the light of modern programming practice. 3.1 Coding the Input The articulation data is coded as a narrow transcription, identifying phonetic detail such as secondary articulations, which can be important in speech therapy, in a fairly transparent notation, despite the limitations of the (capitals only) character set: primary phones are identified by single characters, with diacritics indicated in brackets, </context>
<context position="21434" citStr="Somers 1978" startWordPosition="3386" endWordPosition="3387">ge called LIPP (Logical International phonetic Programs) for input of transcriptions (Perry 1995). Alternatively, it seems quite feasible to allow the transcriptions to be input using a standard word processor and a phonetic font, and to interpret the symbols accordingly. For a commercial implementation it would be better to follow the standard proposed by the IPA (Esling and Gaylord 1993), which has been approved by the ISO, and included in the Unicode definitions. Despite the reservations of all the speech-language pathology experts, it seems to me that the work on alignment discussed here (Somers 1978b; Covington 1996; Connolly 1997) suggests that this aspect of computerized articulation test analysis is a research aim well worth pursuing, especially if collaborators from the speech-language pathology field can be found. It would be rewarding if this article were to awaken interest in the problem. Acknowledgments I would like to thank the following people for their help in gathering the information presented in this paper: Catherine Adams (University of Manchester), Lawrence Shriberg (University of Wisconsin-Madison), Julie Masterson (Southwest Missouri State University), Carol Stoel-Gammo</context>
</contexts>
<marker>Somers, 1978</marker>
<rawString>Somers, H. 1978a. Computer analysis of speech therapists&apos; articulation tests. UMRCC Journal, 5(1):9-17 (University of Manchester Regional Computing Centre).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H L Somers</author>
</authors>
<title>Computerised Articulation Testing.</title>
<date>1978</date>
<tech>M.A. thesis,</tech>
<institution>Department of General Linguistics, University of Manchester.</institution>
<contexts>
<context position="1787" citStr="Somers (1978" startWordPosition="260" endWordPosition="261">atory skills. Whether screening whole populations of children, or assessing individual referrals, the articulation test is an important tool for the speech clinician. A child&apos;s articulatory development is usually described with reference to an adult model, and in terms of deviations from it: a number of phonological &amp;quot;processes&amp;quot; (Table 1) can be identified (see Ingram [1976]), and their significance with respect to the chronological age of the child assessed (though often processes interact, so for example when spoon is pronounced [fun] we have consonant-cluster reduction and assimilation). In Somers (1978a, 1979) I reported a computer program called CAT (Computerised Articulation Test), which I had developed to automate the assessment of children&apos;s articulation tests. At the heart of this program was an algorithm very similar to the one reported by Covington. Whereas Covington seeks to align the segments in possible historical cognates, CAT aligns the segments of a child&apos;s articulation with those of the adult model, and on the basis of this looks for evidence of the phonological processes listed in Table 1. For example, if elephant [clifAnt] is pronounced [evat], we need to decide which of sev</context>
<context position="8353" citStr="Somers 1978" startWordPosition="1265" endWordPosition="1266">nds are used contrastively, or in complementary distribution. The authors suggest that matching the child&apos;s utterances to an adult model would involve a procedure which &amp;quot;would have to be very sophisticated indeed to handle complex cases of metathesis and deletion&amp;quot; (p. 124). As we show in Somers (1979) and in the next section, CAT was able to handle metathesis and deletion without being &amp;quot;very sophisticated indeed.&amp;quot; 3. The CAT Algorithm Since the Somers (1979) article was aimed at speech therapists, it did not describe the alignment algorithm as such, which is described only in a local journal (Somers 1978a) and—in great detail—in an M.A. thesis (Somers 1978b). It bears comparison with Covington&apos;s algorithm, though it should be said that the implementation in Pascal would be judged crude in the light of modern programming practice. 3.1 Coding the Input The articulation data is coded as a narrow transcription, identifying phonetic detail such as secondary articulations, which can be important in speech therapy, in a fairly transparent notation, despite the limitations of the (capitals only) character set: primary phones are identified by single characters, with diacritics indicated in brackets, </context>
<context position="21434" citStr="Somers 1978" startWordPosition="3386" endWordPosition="3387">ge called LIPP (Logical International phonetic Programs) for input of transcriptions (Perry 1995). Alternatively, it seems quite feasible to allow the transcriptions to be input using a standard word processor and a phonetic font, and to interpret the symbols accordingly. For a commercial implementation it would be better to follow the standard proposed by the IPA (Esling and Gaylord 1993), which has been approved by the ISO, and included in the Unicode definitions. Despite the reservations of all the speech-language pathology experts, it seems to me that the work on alignment discussed here (Somers 1978b; Covington 1996; Connolly 1997) suggests that this aspect of computerized articulation test analysis is a research aim well worth pursuing, especially if collaborators from the speech-language pathology field can be found. It would be rewarding if this article were to awaken interest in the problem. Acknowledgments I would like to thank the following people for their help in gathering the information presented in this paper: Catherine Adams (University of Manchester), Lawrence Shriberg (University of Wisconsin-Madison), Julie Masterson (Southwest Missouri State University), Carol Stoel-Gammo</context>
</contexts>
<marker>Somers, 1978</marker>
<rawString>Somers, H. L. 1978b. Computerised Articulation Testing. M.A. thesis, Department of General Linguistics, University of Manchester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Somers</author>
</authors>
<title>Using the computer to analyse articulation test data.</title>
<date>1979</date>
<journal>British Journal of Disorders of Communication,</journal>
<pages>14--231</pages>
<contexts>
<context position="8044" citStr="Somers (1979)" startWordPosition="1214" endWordPosition="1215">s or special symbols to indicate specifically childish articulations. The system is unable to compare adult models with the child&apos;s output, and can only produce a &amp;quot;phonological lexicon&amp;quot;, i.e., a list of the different sounds attested: it is then up to the clinician to analyze this inventory, e.g., to see if sounds are used contrastively, or in complementary distribution. The authors suggest that matching the child&apos;s utterances to an adult model would involve a procedure which &amp;quot;would have to be very sophisticated indeed to handle complex cases of metathesis and deletion&amp;quot; (p. 124). As we show in Somers (1979) and in the next section, CAT was able to handle metathesis and deletion without being &amp;quot;very sophisticated indeed.&amp;quot; 3. The CAT Algorithm Since the Somers (1979) article was aimed at speech therapists, it did not describe the alignment algorithm as such, which is described only in a local journal (Somers 1978a) and—in great detail—in an M.A. thesis (Somers 1978b). It bears comparison with Covington&apos;s algorithm, though it should be said that the implementation in Pascal would be judged crude in the light of modern programming practice. 3.1 Coding the Input The articulation data is coded as a nar</context>
</contexts>
<marker>Somers, 1979</marker>
<rawString>Somers, H. 1979. Using the computer to analyse articulation test data. British Journal of Disorders of Communication, 14:231-240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H</author>
</authors>
<title>Similarity metrics for aligning children&apos;s articulation data.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING-ACL &apos;98: 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics,</booktitle>
<pages>1227--1232</pages>
<location>Montreal, Quebec, Canada,</location>
<marker>H, 1998</marker>
<rawString>Somers. H. 1998. Similarity metrics for aligning children&apos;s articulation data. In Proceedings of COLING-ACL &apos;98: 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Montreal, Quebec, Canada, pages 1227-1232.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carol Stoel-Gammon</author>
<author>Paula Beckett Herrington</author>
</authors>
<title>Vowel systems of normally developing and phonologically disordered children.</title>
<date>1990</date>
<journal>Clinical Linguistics &amp; Phonetics,</journal>
<pages>4--145</pages>
<marker>Stoel-Gammon, Herrington, 1990</marker>
<rawString>Stoel-Gammon, Carol &amp; Paula Beckett Herrington. 1990. Vowel systems of normally developing and phonologically disordered children. Clinical Linguistics &amp; Phonetics, 4:145-160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kal M Telage</author>
</authors>
<title>A computerized place-manner distinctive feature program for articulation analyses.</title>
<date>1980</date>
<journal>Journal of Speech and Hearing Disorders,</journal>
<pages>45--481</pages>
<contexts>
<context position="3866" citStr="Telage (1980)" startWordPosition="580" endWordPosition="581">tamps tam Stopping kiss kis kit Fronting key ki ti Denasalisation mummy mAmi bAbi Affrication tent tent tents Vocalisation (1) bottle botl botu Vocalisation (2) chimney tfimni trimini Depalatalisation fish fif fis Devoicing dogs dog z doks Voicing tent tent dent Assimilation dog dog gog Lisping kiss kis ki0 S-lateralisation fish fif fii Ejectivisation tent tent tent&apos; Metathesis remember rimemb a miremb a Gliding look luk wuk 2. Use of the Computer by Speech Clinicians Early studies reporting the use of computers by speech pathologists include Faircloth (1971), van Demark and Tharp (1973), and Telage (1980), none of which involves automatic analysis of the input, though the last named uses binary articulatory features in a way almost identical to CAT. Comparatively little has appeared in the speechlanguage disorders literature on the specific topic of computerized articulation testing in the nearly 20 years since the CAT program was developed. Software for computerized language analysis does exist, but is mainly for grammatical and lexical analysis. Fairly thorough overviews are given by Rushakoff (1984), Rushakoff and Schwartz (1986), Long (1991), Long and Masterson (1993), and Miller and Klee </context>
</contexts>
<marker>Telage, 1980</marker>
<rawString>Telage, Kal M. 1980. A computerized place-manner distinctive feature program for articulation analyses. Journal of Speech and Hearing Disorders, 45:481-494.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D R Van Demark</author>
<author>Rosemary Tharp</author>
</authors>
<title>A computer program for articulation tests.</title>
<date>1973</date>
<journal>Cleft Palate Journal,</journal>
<pages>10--378</pages>
<marker>Van Demark, Tharp, 1973</marker>
<rawString>Van Demark, D. R. &amp; Rosemary Tharp. 1973. A computer program for articulation tests. Cleft Palate Journal, 10:378-386.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>