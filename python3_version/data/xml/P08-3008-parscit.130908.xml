<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.184217">
<title confidence="0.956458">
Impact of Initiative on Collaborative Problem Solving *
</title>
<author confidence="0.997469">
Cynthia Kersey
</author>
<affiliation confidence="0.839616666666667">
Department of Computer Science
University of Illinois at Chicago
Chicago, Illinois 60613
</affiliation>
<email confidence="0.998471">
ckerse2@uic.edu
</email>
<sectionHeader confidence="0.995619" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999073">
Even though collaboration in peer learning has
been shown to have a positive impact for stu-
dents, there has been little research into col-
laborative peer learning dialogues. We ana-
lyze such dialogues in order to derive a model
of knowledge co-construction that incorpo-
rates initiative and the balance of initiative.
This model will be embedded in an artificial
agent that will collaborate with students.
</bodyText>
<sectionHeader confidence="0.998796" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.996630236363637">
While collaboration in dialogue has long been re-
searched in computational linguistics (Chu-Carroll
and Carberry, 1998; Constantino-Gonz´alez and
Suthers, 2000; Jordan and Di Eugenio, 1997;
Lochbaum and Sidner, 1990; Soller, 2004; Vizcaino,
2005), there has been little research on collabora-
tion in peer learning. However, this is an important
area of study because collaboration has been shown
to promote learning, potentially for all of the par-
ticipants (Tin, 2003). Additionally, while there has
been a focus on using natural language for intelli-
gent tutoring systems (Evens et al., 1997; Graesser
et al., 2004; VanLehn et al., 2002), peer to peer in-
teractions are notably different from those of expert-
novice pairings, especially with respect to the rich-
ness of the problem-solving deliberations and ne-
gotiations. Using natural language in collaborative
learning could have a profound impact on the way
in which educational applications engage students in
learning.
*This work is funded by NSF grants 0536968 and 0536959.
There are various theories as to why collaboration
in peer learning is effective, but one of that is com-
monly referenced is co-construction (Hausmann et
al., 2004). This theory is a derivative of construc-
tivism which proposes that students construct an un-
derstanding of a topic by interpreting new material
in the context of prior knowledge (Chi et al., 2001).
Essentially, students who are active in the learn-
ing process are more successful. In a collaborative
situation this suggests that all collaborators should
be active participants in order to have a successful
learning experience. Given the lack of research in
modeling peer learning dialogues, there has been lit-
tle study of what features of dialogue characterize
co-construction. I hypothesize that since instances
of co-construction closely resemble the concepts of
control and initiative, these dialogue features can be
used as identifiers of co-construction.
While there is some dispute as to the definitions
of control and initiative (Jordan and Di Eugenio,
1997; Chu-Carroll and Brown, 1998), it is generally
accepted that one or more threads of control pass
between participants in a dialogue. Intuitively, this
suggests that tracking the transfer of control can be
useful in determining when co-construction is occur-
ring. Frequent transfer of control between partici-
pants would indicate that they are working together
to solve the problem and perhaps also to construct
knowledge.
The ultimate goal of this research is to develop a
model of co-construction that incorporates initiative
and the balance of initiative. This model will be em-
bedded in KSC-PaL, a natural language based peer
agent that will collaborate with students to solve
</bodyText>
<page confidence="0.998185">
43
</page>
<note confidence="0.7089545">
Proceedings of the ACL-08: HLT Student Research Workshop (Companion Volume), pages 43–48,
Columbus, June 2008. c�2008 Association for Computational Linguistics
</note>
<figureCaption confidence="0.999824">
Figure 1: The data collection interface
</figureCaption>
<bodyText confidence="0.999348">
problems in the domain of computer science data
structures.
In section 2, I will describe how we collected the
dialogues and the initial analysis of those dialogues.
Section 3 details the on-going annotation of the cor-
pus. Section 4 describes the future development of
the computational model and artificial agent. This is
followed by the conclusion in section 5.
</bodyText>
<sectionHeader confidence="0.975022" genericHeader="method">
2 Data Collection
</sectionHeader>
<bodyText confidence="0.999965181818182">
In a current research project on peer learning, we
have collected computer-mediated dialogues be-
tween pairs of students solving program comprehen-
sion and error diagnosis problems in the domain of
data structures. The data structures that we are fo-
cusing on are (1) linked lists, (2) stacks and (3) bi-
nary search trees. This domain was chosen because
data structures and their related algorithms are one
of the core components of computer science educa-
tion and a deep understanding of these topics is es-
sential to a strong computer science foundation.
</bodyText>
<subsectionHeader confidence="0.912997">
2.1 Interface
</subsectionHeader>
<bodyText confidence="0.998880571428572">
A computer mediated environment was chosen to
more closely mimic the situation a student will have
to face when interacting with KSC-PaL, the artificial
peer agent. After observing face-to-face interactions
of students solving these problems, I developed an
interface consisting of four distinct areas (see Fig-
ure 1):
</bodyText>
<listItem confidence="0.987138">
1. Problem display: Displays the problem de-
scription that is retrieved from a database.
2. Code display: Displays the code from the prob-
lem statement. The students are able to make
changes to the code, such as crossing-out lines
and inserting lines, as well as undoing these
corrections.
3. Chat Area: Allows for user input and an inter-
leaved dialogue history of both students partic-
ipating in the problem solving. The history is
logged for analysis.
4. Drawing area: Here users can diagram data
structures to aid in the explanation of parts of
the problem being solved. The drawing area
has objects representing nodes and links. These
objects can then be placed in the drawing area
to build lists, stacks or trees depending on the
type of problem being solved.
</listItem>
<bodyText confidence="0.999982333333333">
The changes made in the shared workspace
(drawing and code areas) are logged and propagated
to the partner’s window. In order to prevent users
from making changes at the same time, I imple-
mented a system that allows only one user to draw or
make changes to code at any point in time. In order
to make a change in the shared workspace, a user
must request the ”pencil” (Constantino-Gonz´alez
and Suthers, 2000). If the pencil is not currently al-
located to her partner, the user receives the pencil
and can make changes in the workspace. Otherwise,
the partner is informed, through both text and an au-
dible alert, that his peer is requesting the pencil. The
chat area, however, allows users to type at the same
time, although they are notified by a red circle at the
top of the screen when their partner is typing. While,
this potentially results in interleaved conversations,
it allows for more natural communication between
the peers.
Using this interface, we collected dialogues for
a total of 15 pairs where each pair was presented
with five problems. Prior to the collaborative prob-
lem solving activities, the participants were individ-
ually given pre-tests and at the conclusion of the ses-
sion, they were each given another test, the post-
test. During problem solving the participants were
seated in front of computers in separate rooms and
all problem solving activity was conducted using the
computer-mediated interface. The initial exercise let
the users become acquainted with the interface. The
</bodyText>
<page confidence="0.99676">
44
</page>
<table confidence="0.999766428571429">
Predictor Prob. 3 Prob.4 Prob. 5
(Lists) (Stacks) (Trees)
Pre-Test 0.530 0.657 0.663
(p=0.005) (p=0.000) (p=0.000)
Words 0.189
(p=0.021)
Words 0.141
per Turn (p=0.049)
Pencil 0.154
Time (p=0.039)
Total 0.108
Turns (p=0.088)
Code 0.136
Turns (p=0.076)
</table>
<tableCaption confidence="0.99975">
Table 1: Post-test Score Predictors (R2)
</tableCaption>
<bodyText confidence="0.999891166666667">
participants were allowed to ask questions regarding
the interface and were limited to 30 minutes to solve
the problem. The remaining exercises had no time
limits, however the total session, including pre-test
and post-test could not exceed three hours. There-
fore not all pairs completed all five problems.
</bodyText>
<subsectionHeader confidence="0.99761">
2.2 Initial Analysis
</subsectionHeader>
<bodyText confidence="0.999902536585366">
After the completion of data collection, I established
that the interface and task were conducive to learn-
ing by conducting a paired t-test on the pre-test and
post-test scores. This analysis showed that the post-
test score was moderately higher than the pre-test
score (t(30)=2.83; p=0.007; effect size = 0.3).
I then performed an initial analysis of the col-
lected dialogues using linear regression analysis to
identify correlations between actions of the dyads
and their success at solving the problems presented
to them. Besides the post-test, students solutions
to the problems were scored, as well; this is what
we refer to as problem solving success. The par-
ticipant actions were also correlated with post-test
scores and learning gains (the difference between
post-test score and pre-test score). The data that
was analyzed came from three of the five problems
for all 15 dyads, although not all dyads attempted
all three problems. Thus, I analyzed a total of 40
subdialogues. The problems that were analyzed are
all error diagnosis problems, but each problem in-
volves a different data structure - linked list, array-
based stack and binary search tree. Additionally,
I analyzed the relationship between initiative and
post-test score, learning gain and successful problem
solving. Before embarking on an exhaustive man-
ual annotation of initiative, I chose to get a sense of
whether initiative may indeed affect learning in this
context by automatically tagging for initiative using
an approximation of Walker and Whittaker’s utter-
ance based allocation of control rules (Walker and
Whittaker, 1990). In this scheme, first each turn in
the dialogue must be tagged as either: (1) an asser-
tion, (2) a command, (3) a question or (4) a prompt
(turns not expressing propositional content). This
was done automatically, by marking turns that end
in a question mark as questions, those that start with
a verb as commands, prompts from a list of com-
monly used prompts (e.g. ok, yeah) and the remain-
ing turns as assertions. Control is then allocated by
using the following rules based on the turn type:
</bodyText>
<listItem confidence="0.999947571428571">
1. Assertion: Control is allocated to the speaker
unless it is a response to a question.
2. Command: Control is allocated to the speaker.
3. Question: Control is allocated to the speaker,
unless it is a response to a question or a com-
mand.
4. Prompt: Control is allocated to the hearer.
</listItem>
<bodyText confidence="0.999879055555555">
Since the dialogues also have a graphics compo-
nent, all drawing and code change moves had con-
trol assigned to the peer drawing or making the code
change.
The results of the regression analysis are summa-
rized in tables 1 and 2, with blank cells representing
non-significant correlations. Pre-test score, which
represents the student’s initial knowledge and/or ap-
titude in the area, was selected as a feature because
it is important to understand the strength of the cor-
relation between previous knowledge and post test
score when identifying additional correlating fea-
tures (Yap, 1979). The same holds for the time re-
lated features (pencil time and total time). The re-
maining correlations and trends to correlation sug-
gest that participation is an important factor in suc-
cessful collaboration. Since a student is more likely
to take initiative when actively participating in prob-
</bodyText>
<page confidence="0.990706">
45
</page>
<table confidence="0.999953666666667">
Predictor Prob. 3 Prob.4 Prob. 5
(Lists) (Stacks) (Trees)
Pre-Test 0.334 0.214 0.269
(p=0.001) (p=0.017) (p=0.009)
Total 0.186 0.125 0.129
Time (p=0.022) (p=0.076) (p=0.085)
Total 0.129 0.134
Turns (p=0.061) (p=0.065)
Draw 0.116 0.122
Turns (p=0.076) (p=0.080)
Code 0.130
Turns (p=0.071)
</table>
<tableCaption confidence="0.997379">
Table 2: Problem Score Predictors (R2)
</tableCaption>
<bodyText confidence="0.999235111111111">
lem solving, potentially there there is a relation be-
tween these participation correlations and initiative.
An analysis of initiative shows that there is a cor-
relation of initiative and successful collaboration. In
problem 3, learning gain positively correlates with
the number of turns where a student has initiative
(R2 = 0.156, p = 0.037). And in problem 4, taking
initiative through drawing has a positive impact on
post-test score (R2 = 0.155,p = 0.047).
</bodyText>
<sectionHeader confidence="0.997434" genericHeader="method">
3 Annotation
</sectionHeader>
<bodyText confidence="0.999909782608696">
Since the preliminary analysis showed a correlation
of initiative with learning gain, I chose to begin a
thorough data analysis by annotating the dialogues
with initiative shifts. Walker and Whittaker claim
that initiative encompasses both dialogue control
and task control (Walker and Whittaker, 1990), how-
ever, several others disagree. Jordan and Di Eugenio
propose that control and initiative are two separate
features in collaborative problem solving dialogues
(Jordan and Di Eugenio, 1997). While control and
initiative might be synonymous for the dialogues an-
alyzed by Walker and Whittaker where a master-
slave assumption holds, it is not the case in collab-
orative dialogues where no such assumption exists.
Jordan and Di Eugenio argue that the notion of con-
trol should apply to the dialogue level, while ini-
tiative should pertain to the problem-solving goals.
In a similar vein, Chu-Carroll and Brown also ar-
gue for a distinction between control and initiative,
which they term task initiative and dialogue initia-
tive (Chu-Carroll and Brown, 1998). Since there is
no universally agreed upon definition for initiative, I
have decided to annotate for both dialogue initiative
and task initiative. For dialogue initiative annota-
tion, I am using Walker and Whittaker’s utterance
based allocation of control rules (Walker and Whit-
taker, 1990), which are widely used to identify di-
alogue initiative. For task initiative, I have derived
an annotation scheme based on other research in the
area. According to Jordan and Di Eugenio, in prob-
lem solving (task) initiative the agent takes it upon
himself to address domain goals by either (1)propos-
ing a solution or (2)reformulating goals. In a simi-
lar vein, Guinn (Guinn, 1998) defines task initiative
as belonging to the participant who dictates which
decomposition of the goal will be used by both par-
ticipants during problem-solving. A third definition
is from Chu-Carroll and Brown. They suggest that
task initiative tracks the lead in development of the
agent’s plan. Since the primary goal of the dialogues
studied by Chu-Carroll and Brown is to develop a
plan, this could be re-worded to state that task ini-
tiative tracks the lead in development of the agent’s
goal. Combining these definitions, task initiative can
be defined as any action by a participant to either
achieve a goal directly, decompose a goal or refor-
mulate a goal. Since the goals of our problems are
understanding and potentially correcting a program,
actions in our domain that show task initiative in-
clude actions such as explaining what a section of
code does or identifying a section of code that is in-
correct.
Two coders, the author and an outside annotator,
have coded 24 dialogues (1449 utterances) for both
dialogue and task initiative. This is approximately
45% of the corpus. The resulting intercoder reli-
ability, measured with the Kappa statistic, is 0.77
for dialogue initiative annotation and 0.68 for task
initiative, both of which are high enough to support
tentative conclusions. Using multiple linear regres-
sion analysis on these annotated dialogues, I found
that, in a subset of the problems, there was a sig-
nicant correlation between post-test score (after re-
moving the effects of pre-test scores) and the num-
ber of switches in dialogue initiative (R2 =0.157,
p=0.014). Also, in the same subset, there was a
correlation between post-test score and the number
of turns that a student had initiative (R2 =0.077,
p=0.065). This suggests that both taking the ini-
</bodyText>
<page confidence="0.998458">
46
</page>
<bodyText confidence="0.999815571428571">
tiative and taking turns in leading problem solving
results in learning.
Given my hypothesis that initiative can be used
to identify co-construction, the next step is to an-
notate the dialogues using a subset of the DAMSL
scheme (Core and Allen, 1997) to identify episodes
of co-construction. Once annotated, I will use ma-
chine learning techniques to identify co-construction
using initiative as a feature. Since this is a classi-
fication problem, algorithms such as Classification
Based on Associations (Liu, 2007) will be used. Ad-
ditionally, I will explore those algorithms that take
into account the sequence of actions, such as hidden
Markov models or neural networks.
</bodyText>
<sectionHeader confidence="0.9991" genericHeader="method">
4 Computational Model
</sectionHeader>
<bodyText confidence="0.999996114754099">
The model will be implemented as an artificial
agent, KSC-PaL, that interacts with a peer in collab-
orative problem solving using an interface similar to
the one that was used in data collection (see Fig-
ure 1). This agent will be an extension of the TuTalk
system, which is designed to support natural lan-
guage dialogues for educational applications (Jordan
et al., 2006). TuTalk contains a core set of dialogue
system modules that can be replaced or enhanced as
required by the application. The core modules are
understanding and generation, a dialogue manager
which is loosely characterized as a finite state ma-
chine with a stack and a student model. To imple-
ment the peer agent, I will replace TuTalk’s student
model and add a planner module.
Managing the information state of the dialogue
(Larsson and Traum, 2000), which includes the be-
liefs and intentions of the participants, is important
in the implementation of any dialogue agent. KSC-
PaL will use a student model to assist in manage-
ment of the information state. This student model
tracks the current state of problem solving as well
as estimates the student’s knowledge of concepts
involved in solving the problem by incorporating
problem solution graphs (Conati et al., 2002). So-
lution graphs are Bayesian networks where each
node represents either an action required to solve
the problem or a concept required as part of prob-
lem solving. After analyzing our dialogues, I real-
ized that the solutions to the problems in our do-
main are different from standard problem-solving
tasks. Given that our tasks are program compre-
hension tasks and that the dialogues are peer led,
there can be no assumption as to the order in which
a student will analyze code statements. Therefore
a graph comprised of connected subgraphs that each
represent a section of the code more closely matches
what I observed in our dialogues. So, we are using a
modified version of solution graphs that has clusters
of nodes representing facts that are relevant to the
problem. Each cluster contains facts that are depen-
dent on one another. For example, one cluster repre-
sents facts related to the push method for a stack. As
the code is written, it would be impossible to com-
prehend the method without understanding the pre-
fix notation for incrementing. A user’s utterances
and actions can then be matched to the nodes within
the clusters. This provides the agent with informa-
tion related to the student’s knowledge as well as the
current topic under discussion.
A planner module will be added to TuTalk to pro-
vide KSC-PaL with a more sophisticated method of
selecting scripts. Unlike TuTalk’s dialogue manager
which uses a simple matching of utterances to con-
cepts in order to determine the script to be followed,
KSC-PaL’s planner will incorporate the results of the
data analysis above and will also include the status
of the student’s knowledge, as reflected in the stu-
dent model, in making script selections. This plan-
ner will potentially be a probabilistic planner such
as the one in (Lu, 2007).
</bodyText>
<sectionHeader confidence="0.998904" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9999489">
In conclusion, we are developing a computational
model of knowledge construction which incorpo-
rates initiative and the balance of initiative. This
model will be embedded in an artificial agent that
collaborates with students to solve data structure
problems. As knowledge construction has been
shown to promote learning, this research could have
a profound impact on educational applications by
changing the way in which they engage students in
learning.
</bodyText>
<sectionHeader confidence="0.998296" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999201666666667">
The graphical interface is based on a graphical inter-
face developed by Davide Fossati for an intelligent
tutoring system in the same domain.
</bodyText>
<page confidence="0.999144">
47
</page>
<sectionHeader confidence="0.990036" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999875470588235">
Michelene T. H. Chi, Stephanie A. Siler, Jeong Heisawn,
Takashi Yamauchi, and Robert G. Hausmann. 2001.
Learning from human tutoring. Cognitive Science,
25(4):471–533.
Jennifer Chu-Carroll and Michael K. Brown. 1998. An
evidential model for tracking initiative in collabora-
tive dialogue interactions. User Modeling and User-
Adapted Interaction, 8(3–4):215–253, September.
Jennifer Chu-Carroll and Sandra Carberry. 1998. Col-
laborative response generation in planning dialogues.
Computational Linguistics, 24(3):355–400.
Cristina Conati, Abigail Gertner, and Kurt Vanlehn.
2002. Using bayesian networks to manage uncer-
tainty in student modeling. User Modeling and User-
Adapted Interaction, 12(4):371–417.
Mar´ıa de los Angeles Constantino-Gonz´alez and
Daniel D. Suthers. 2000. A coached collaborative
learning environment for entity-relationship modeling.
Intelligent Tutoring Systems, pages 324–333.
Mark G. Core and James F. Allen. 1997. Coding dia-
logues with the DAMSL annotation scheme. In David
Traum, editor, Working Notes: AAAI Fall Symposium
on Communicative Action in Humans and Machines,
pages 28–35, Menlo Park, California. American Asso-
ciation for Artificial Intelligence.
Martha W. Evens, Ru-Charn Chang, Yoon Hee Lee,
Leem Seop Shim, Chong Woo Woo, Yuemei Zhang,
Joel A. Michael, and Allen A. Rovick. 1997. Circsim-
tutor: an intelligent tutoring system using natural lan-
guage dialogue. In Proceedings of the fifth conference
on Applied natural language processing, pages 13–14,
San Francisco, CA, USA. Morgan Kaufmann Publish-
ers Inc.
Arthur C. Graesser, Shulan Lu, George Tanner Jackson,
Heather Hite Mitchell, Mathew Ventura, Andrew Ol-
ney, and Max M. Louwerse. 2004. Autotutor: A tutor
with dialogue in natural language. Behavior Research
Methods, Instruments, &amp; Computers, 36:180–192(13),
May.
Curry I. Guinn. 1998. An analysis of initiative selection
in collaborative task-oriented discourse. User Model-
ing and User-Adapted Interaction, 8(3-4):255–314.
Robert G.M. Hausmann, Michelee T.H. Chi, and Mar-
guerite Roy. 2004. Learning from collaborative prob-
lem solving: An analysis of three hypothesized mech-
anisms. In K.D Forbus, D. Gentner, and T. Regier, edi-
tors, 26th Annual Converence of the Cognitive Science
Society, pages 547–552, Mahwah, NJ.
Pamela W. Jordan and Barbara Di Eugenio. 1997. Con-
trol and initiative in collaborative problem solving di-
alogues. In Working Notes of the AAAI Spring Sympo-
sium on Computational Models for Mixed Initiative,
pages 81–84, Menlo Park, CA.
Pamela W. Jordan, Michael Ringenberg, and Brian Hall.
2006. Rapidly developing dialogue systems that sup-
port learning studies. In Proceedings of ITS06 Work-
shop on Teaching with Robots, Agents, and NLP, pages
1–8.
Staffan Larsson and David R. Traum. 2000. Information
state and dialogue management in the trindi dialogue
move engine toolkit. Nat. Lang. Eng., 6(3-4):323–340.
Bing Liu. 2007. Web data mining: exploring hyperlinks,
contents, and usage data. Springer.
Karen E. Lochbaum and Candice L. Sidner. 1990. Mod-
els of plans to support communication: An initial re-
port. In Thomas Dietterich and William Swartout, ed-
itors, Proceedings of the Eighth National Conference
on Artificial Intelligence, pages 485–490, Menlo Park,
California. AAAI Press.
Xin Lu. 2007. Expert Tutoring and Natural Language
Feedback in Intelligent Tutoring Systems. Ph.D. thesis,
University of Illinois at Chicago.
Amy Soller. 2004. Computational modeling and analysis
of knowledge sharing in collaborative distance learn-
ing. User Modeling and User-Adapted Interaction,
Volume 14(4):351–381, January.
Tan Bee Tin. 2003. Does talking with peers help learn-
ing? the role of expertise and talk in convergent group
discussion tasks. Journal of English for Academic
Purposes, 2(1):53–66.
Kurt VanLehn, Pamela W. Jordan, Carolyn Penstein
Ros´e, Dumisizwe Bhembe, Michael B¨ottner, Andy
Gaydos, Maxim Makatchev, Umarani Pappuswamy,
Michael A. Ringenberg, Antonio Roque, Stephanie
Siler, and Ramesh Srivastava. 2002. The architec-
ture of why2-atlas: A coach for qualitative physics es-
say writing. In ITS ’02: Proceedings of the 6th Inter-
national Conference on Intelligent Tutoring Systems,
pages 158–167, London, UK. Springer-Verlag.
Aurora Vizca´ıno. 2005. A simulated student can im-
prove collaborative learning. International Journal of
Artificial Intelligence in Education, 15(1):3–40.
Marilyn Walker and Steve Whittaker. 1990. Mixed ini-
tiative in dialogue: an investigation into discourse seg-
mentation. In Proceedings of the 28th annual meeting
on Association for Computational Linguistics, pages
70–78, Morristown, NJ, USA. Association for Com-
putational Linguistics.
Kim Onn Yap. 1979. Pretest-posttest correlation and
regression models. Presented at the Annual Meet-
ing of the American Educational Research Association
(63rd, San Francisco, California), April 8–12.
</reference>
<page confidence="0.999354">
48
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.978005">
<title confidence="0.999914">of Initiative on Collaborative Problem Solving</title>
<author confidence="0.999915">Cynthia Kersey</author>
<affiliation confidence="0.9999365">Department of Computer Science University of Illinois at Chicago</affiliation>
<address confidence="0.998544">Chicago, Illinois 60613</address>
<email confidence="0.995582">ckerse2@uic.edu</email>
<abstract confidence="0.9972151">Even though collaboration in peer learning has been shown to have a positive impact for students, there has been little research into collaborative peer learning dialogues. We analyze such dialogues in order to derive a model of knowledge co-construction that incorporates initiative and the balance of initiative. This model will be embedded in an artificial agent that will collaborate with students.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Michelene T H Chi</author>
<author>Stephanie A Siler</author>
<author>Jeong Heisawn</author>
<author>Takashi Yamauchi</author>
<author>Robert G Hausmann</author>
</authors>
<title>Learning from human tutoring.</title>
<date>2001</date>
<journal>Cognitive Science,</journal>
<volume>25</volume>
<issue>4</issue>
<contexts>
<context position="1987" citStr="Chi et al., 2001" startWordPosition="304" endWordPosition="307">e problem-solving deliberations and negotiations. Using natural language in collaborative learning could have a profound impact on the way in which educational applications engage students in learning. *This work is funded by NSF grants 0536968 and 0536959. There are various theories as to why collaboration in peer learning is effective, but one of that is commonly referenced is co-construction (Hausmann et al., 2004). This theory is a derivative of constructivism which proposes that students construct an understanding of a topic by interpreting new material in the context of prior knowledge (Chi et al., 2001). Essentially, students who are active in the learning process are more successful. In a collaborative situation this suggests that all collaborators should be active participants in order to have a successful learning experience. Given the lack of research in modeling peer learning dialogues, there has been little study of what features of dialogue characterize co-construction. I hypothesize that since instances of co-construction closely resemble the concepts of control and initiative, these dialogue features can be used as identifiers of co-construction. While there is some dispute as to th</context>
</contexts>
<marker>Chi, Siler, Heisawn, Yamauchi, Hausmann, 2001</marker>
<rawString>Michelene T. H. Chi, Stephanie A. Siler, Jeong Heisawn, Takashi Yamauchi, and Robert G. Hausmann. 2001. Learning from human tutoring. Cognitive Science, 25(4):471–533.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jennifer Chu-Carroll</author>
<author>Michael K Brown</author>
</authors>
<title>An evidential model for tracking initiative in collaborative dialogue interactions. User Modeling and UserAdapted Interaction,</title>
<date>1998</date>
<pages>8--3</pages>
<contexts>
<context position="2685" citStr="Chu-Carroll and Brown, 1998" startWordPosition="408" endWordPosition="411">e successful. In a collaborative situation this suggests that all collaborators should be active participants in order to have a successful learning experience. Given the lack of research in modeling peer learning dialogues, there has been little study of what features of dialogue characterize co-construction. I hypothesize that since instances of co-construction closely resemble the concepts of control and initiative, these dialogue features can be used as identifiers of co-construction. While there is some dispute as to the definitions of control and initiative (Jordan and Di Eugenio, 1997; Chu-Carroll and Brown, 1998), it is generally accepted that one or more threads of control pass between participants in a dialogue. Intuitively, this suggests that tracking the transfer of control can be useful in determining when co-construction is occurring. Frequent transfer of control between participants would indicate that they are working together to solve the problem and perhaps also to construct knowledge. The ultimate goal of this research is to develop a model of co-construction that incorporates initiative and the balance of initiative. This model will be embedded in KSC-PaL, a natural language based peer age</context>
<context position="12806" citStr="Chu-Carroll and Brown, 1998" startWordPosition="2038" endWordPosition="2041">collaborative problem solving dialogues (Jordan and Di Eugenio, 1997). While control and initiative might be synonymous for the dialogues analyzed by Walker and Whittaker where a masterslave assumption holds, it is not the case in collaborative dialogues where no such assumption exists. Jordan and Di Eugenio argue that the notion of control should apply to the dialogue level, while initiative should pertain to the problem-solving goals. In a similar vein, Chu-Carroll and Brown also argue for a distinction between control and initiative, which they term task initiative and dialogue initiative (Chu-Carroll and Brown, 1998). Since there is no universally agreed upon definition for initiative, I have decided to annotate for both dialogue initiative and task initiative. For dialogue initiative annotation, I am using Walker and Whittaker’s utterance based allocation of control rules (Walker and Whittaker, 1990), which are widely used to identify dialogue initiative. For task initiative, I have derived an annotation scheme based on other research in the area. According to Jordan and Di Eugenio, in problem solving (task) initiative the agent takes it upon himself to address domain goals by either (1)proposing a solut</context>
</contexts>
<marker>Chu-Carroll, Brown, 1998</marker>
<rawString>Jennifer Chu-Carroll and Michael K. Brown. 1998. An evidential model for tracking initiative in collaborative dialogue interactions. User Modeling and UserAdapted Interaction, 8(3–4):215–253, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jennifer Chu-Carroll</author>
<author>Sandra Carberry</author>
</authors>
<title>Collaborative response generation in planning dialogues.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>3</issue>
<contexts>
<context position="720" citStr="Chu-Carroll and Carberry, 1998" startWordPosition="103" endWordPosition="106">ter Science University of Illinois at Chicago Chicago, Illinois 60613 ckerse2@uic.edu Abstract Even though collaboration in peer learning has been shown to have a positive impact for students, there has been little research into collaborative peer learning dialogues. We analyze such dialogues in order to derive a model of knowledge co-construction that incorporates initiative and the balance of initiative. This model will be embedded in an artificial agent that will collaborate with students. 1 Introduction While collaboration in dialogue has long been researched in computational linguistics (Chu-Carroll and Carberry, 1998; Constantino-Gonz´alez and Suthers, 2000; Jordan and Di Eugenio, 1997; Lochbaum and Sidner, 1990; Soller, 2004; Vizcaino, 2005), there has been little research on collaboration in peer learning. However, this is an important area of study because collaboration has been shown to promote learning, potentially for all of the participants (Tin, 2003). Additionally, while there has been a focus on using natural language for intelligent tutoring systems (Evens et al., 1997; Graesser et al., 2004; VanLehn et al., 2002), peer to peer interactions are notably different from those of expertnovice pairi</context>
</contexts>
<marker>Chu-Carroll, Carberry, 1998</marker>
<rawString>Jennifer Chu-Carroll and Sandra Carberry. 1998. Collaborative response generation in planning dialogues. Computational Linguistics, 24(3):355–400.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cristina Conati</author>
<author>Abigail Gertner</author>
<author>Kurt Vanlehn</author>
</authors>
<title>Using bayesian networks to manage uncertainty in student modeling. User Modeling and UserAdapted Interaction,</title>
<date>2002</date>
<contexts>
<context position="17183" citStr="Conati et al., 2002" startWordPosition="2753" endWordPosition="2756">e with a stack and a student model. To implement the peer agent, I will replace TuTalk’s student model and add a planner module. Managing the information state of the dialogue (Larsson and Traum, 2000), which includes the beliefs and intentions of the participants, is important in the implementation of any dialogue agent. KSCPaL will use a student model to assist in management of the information state. This student model tracks the current state of problem solving as well as estimates the student’s knowledge of concepts involved in solving the problem by incorporating problem solution graphs (Conati et al., 2002). Solution graphs are Bayesian networks where each node represents either an action required to solve the problem or a concept required as part of problem solving. After analyzing our dialogues, I realized that the solutions to the problems in our domain are different from standard problem-solving tasks. Given that our tasks are program comprehension tasks and that the dialogues are peer led, there can be no assumption as to the order in which a student will analyze code statements. Therefore a graph comprised of connected subgraphs that each represent a section of the code more closely matche</context>
</contexts>
<marker>Conati, Gertner, Vanlehn, 2002</marker>
<rawString>Cristina Conati, Abigail Gertner, and Kurt Vanlehn. 2002. Using bayesian networks to manage uncertainty in student modeling. User Modeling and UserAdapted Interaction, 12(4):371–417.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mar´ıa de los Angeles Constantino-Gonz´alez</author>
<author>Daniel D Suthers</author>
</authors>
<title>A coached collaborative learning environment for entity-relationship modeling. Intelligent Tutoring Systems,</title>
<date>2000</date>
<pages>324--333</pages>
<marker>Constantino-Gonz´alez, Suthers, 2000</marker>
<rawString>Mar´ıa de los Angeles Constantino-Gonz´alez and Daniel D. Suthers. 2000. A coached collaborative learning environment for entity-relationship modeling. Intelligent Tutoring Systems, pages 324–333.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark G Core</author>
<author>James F Allen</author>
</authors>
<title>Coding dialogues with the DAMSL annotation scheme.</title>
<date>1997</date>
<booktitle>Working Notes: AAAI Fall Symposium on Communicative Action in Humans and Machines,</booktitle>
<pages>28--35</pages>
<editor>In David Traum, editor,</editor>
<publisher>American Association for Artificial Intelligence.</publisher>
<location>Menlo Park, California.</location>
<contexts>
<context position="15504" citStr="Core and Allen, 1997" startWordPosition="2480" endWordPosition="2483">, there was a signicant correlation between post-test score (after removing the effects of pre-test scores) and the number of switches in dialogue initiative (R2 =0.157, p=0.014). Also, in the same subset, there was a correlation between post-test score and the number of turns that a student had initiative (R2 =0.077, p=0.065). This suggests that both taking the ini46 tiative and taking turns in leading problem solving results in learning. Given my hypothesis that initiative can be used to identify co-construction, the next step is to annotate the dialogues using a subset of the DAMSL scheme (Core and Allen, 1997) to identify episodes of co-construction. Once annotated, I will use machine learning techniques to identify co-construction using initiative as a feature. Since this is a classification problem, algorithms such as Classification Based on Associations (Liu, 2007) will be used. Additionally, I will explore those algorithms that take into account the sequence of actions, such as hidden Markov models or neural networks. 4 Computational Model The model will be implemented as an artificial agent, KSC-PaL, that interacts with a peer in collaborative problem solving using an interface similar to the </context>
</contexts>
<marker>Core, Allen, 1997</marker>
<rawString>Mark G. Core and James F. Allen. 1997. Coding dialogues with the DAMSL annotation scheme. In David Traum, editor, Working Notes: AAAI Fall Symposium on Communicative Action in Humans and Machines, pages 28–35, Menlo Park, California. American Association for Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha W Evens</author>
<author>Ru-Charn Chang</author>
<author>Yoon Hee Lee</author>
<author>Leem Seop Shim</author>
<author>Chong Woo Woo</author>
<author>Yuemei Zhang</author>
<author>Joel A Michael</author>
<author>Allen A Rovick</author>
</authors>
<title>Circsimtutor: an intelligent tutoring system using natural language dialogue.</title>
<date>1997</date>
<booktitle>In Proceedings of the fifth conference on Applied natural language processing,</booktitle>
<pages>13--14</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="1192" citStr="Evens et al., 1997" startWordPosition="176" endWordPosition="179">ith students. 1 Introduction While collaboration in dialogue has long been researched in computational linguistics (Chu-Carroll and Carberry, 1998; Constantino-Gonz´alez and Suthers, 2000; Jordan and Di Eugenio, 1997; Lochbaum and Sidner, 1990; Soller, 2004; Vizcaino, 2005), there has been little research on collaboration in peer learning. However, this is an important area of study because collaboration has been shown to promote learning, potentially for all of the participants (Tin, 2003). Additionally, while there has been a focus on using natural language for intelligent tutoring systems (Evens et al., 1997; Graesser et al., 2004; VanLehn et al., 2002), peer to peer interactions are notably different from those of expertnovice pairings, especially with respect to the richness of the problem-solving deliberations and negotiations. Using natural language in collaborative learning could have a profound impact on the way in which educational applications engage students in learning. *This work is funded by NSF grants 0536968 and 0536959. There are various theories as to why collaboration in peer learning is effective, but one of that is commonly referenced is co-construction (Hausmann et al., 2004).</context>
</contexts>
<marker>Evens, Chang, Lee, Shim, Woo, Zhang, Michael, Rovick, 1997</marker>
<rawString>Martha W. Evens, Ru-Charn Chang, Yoon Hee Lee, Leem Seop Shim, Chong Woo Woo, Yuemei Zhang, Joel A. Michael, and Allen A. Rovick. 1997. Circsimtutor: an intelligent tutoring system using natural language dialogue. In Proceedings of the fifth conference on Applied natural language processing, pages 13–14, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arthur C Graesser</author>
<author>Shulan Lu</author>
<author>George Tanner Jackson</author>
<author>Heather Hite Mitchell</author>
<author>Mathew Ventura</author>
<author>Andrew Olney</author>
<author>Max M Louwerse</author>
</authors>
<title>Autotutor: A tutor with dialogue in natural language.</title>
<date>2004</date>
<journal>Behavior Research Methods, Instruments, &amp; Computers,</journal>
<volume>192</volume>
<issue>13</issue>
<contexts>
<context position="1215" citStr="Graesser et al., 2004" startWordPosition="180" endWordPosition="183">oduction While collaboration in dialogue has long been researched in computational linguistics (Chu-Carroll and Carberry, 1998; Constantino-Gonz´alez and Suthers, 2000; Jordan and Di Eugenio, 1997; Lochbaum and Sidner, 1990; Soller, 2004; Vizcaino, 2005), there has been little research on collaboration in peer learning. However, this is an important area of study because collaboration has been shown to promote learning, potentially for all of the participants (Tin, 2003). Additionally, while there has been a focus on using natural language for intelligent tutoring systems (Evens et al., 1997; Graesser et al., 2004; VanLehn et al., 2002), peer to peer interactions are notably different from those of expertnovice pairings, especially with respect to the richness of the problem-solving deliberations and negotiations. Using natural language in collaborative learning could have a profound impact on the way in which educational applications engage students in learning. *This work is funded by NSF grants 0536968 and 0536959. There are various theories as to why collaboration in peer learning is effective, but one of that is commonly referenced is co-construction (Hausmann et al., 2004). This theory is a deriv</context>
</contexts>
<marker>Graesser, Lu, Jackson, Mitchell, Ventura, Olney, Louwerse, 2004</marker>
<rawString>Arthur C. Graesser, Shulan Lu, George Tanner Jackson, Heather Hite Mitchell, Mathew Ventura, Andrew Olney, and Max M. Louwerse. 2004. Autotutor: A tutor with dialogue in natural language. Behavior Research Methods, Instruments, &amp; Computers, 36:180–192(13), May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Curry I Guinn</author>
</authors>
<title>An analysis of initiative selection in collaborative task-oriented discourse. User Modeling and User-Adapted Interaction,</title>
<date>1998</date>
<pages>8--3</pages>
<contexts>
<context position="13475" citStr="Guinn, 1998" startWordPosition="2148" endWordPosition="2149">r initiative, I have decided to annotate for both dialogue initiative and task initiative. For dialogue initiative annotation, I am using Walker and Whittaker’s utterance based allocation of control rules (Walker and Whittaker, 1990), which are widely used to identify dialogue initiative. For task initiative, I have derived an annotation scheme based on other research in the area. According to Jordan and Di Eugenio, in problem solving (task) initiative the agent takes it upon himself to address domain goals by either (1)proposing a solution or (2)reformulating goals. In a similar vein, Guinn (Guinn, 1998) defines task initiative as belonging to the participant who dictates which decomposition of the goal will be used by both participants during problem-solving. A third definition is from Chu-Carroll and Brown. They suggest that task initiative tracks the lead in development of the agent’s plan. Since the primary goal of the dialogues studied by Chu-Carroll and Brown is to develop a plan, this could be re-worded to state that task initiative tracks the lead in development of the agent’s goal. Combining these definitions, task initiative can be defined as any action by a participant to either ac</context>
</contexts>
<marker>Guinn, 1998</marker>
<rawString>Curry I. Guinn. 1998. An analysis of initiative selection in collaborative task-oriented discourse. User Modeling and User-Adapted Interaction, 8(3-4):255–314.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert G M Hausmann</author>
<author>Michelee T H Chi</author>
<author>Marguerite Roy</author>
</authors>
<title>Learning from collaborative problem solving: An analysis of three hypothesized mechanisms. In</title>
<date>2004</date>
<booktitle>26th Annual Converence of the Cognitive Science Society,</booktitle>
<pages>547--552</pages>
<editor>K.D Forbus, D. Gentner, and T. Regier, editors,</editor>
<location>Mahwah, NJ.</location>
<contexts>
<context position="1791" citStr="Hausmann et al., 2004" startWordPosition="271" endWordPosition="274">ems (Evens et al., 1997; Graesser et al., 2004; VanLehn et al., 2002), peer to peer interactions are notably different from those of expertnovice pairings, especially with respect to the richness of the problem-solving deliberations and negotiations. Using natural language in collaborative learning could have a profound impact on the way in which educational applications engage students in learning. *This work is funded by NSF grants 0536968 and 0536959. There are various theories as to why collaboration in peer learning is effective, but one of that is commonly referenced is co-construction (Hausmann et al., 2004). This theory is a derivative of constructivism which proposes that students construct an understanding of a topic by interpreting new material in the context of prior knowledge (Chi et al., 2001). Essentially, students who are active in the learning process are more successful. In a collaborative situation this suggests that all collaborators should be active participants in order to have a successful learning experience. Given the lack of research in modeling peer learning dialogues, there has been little study of what features of dialogue characterize co-construction. I hypothesize that sin</context>
</contexts>
<marker>Hausmann, Chi, Roy, 2004</marker>
<rawString>Robert G.M. Hausmann, Michelee T.H. Chi, and Marguerite Roy. 2004. Learning from collaborative problem solving: An analysis of three hypothesized mechanisms. In K.D Forbus, D. Gentner, and T. Regier, editors, 26th Annual Converence of the Cognitive Science Society, pages 547–552, Mahwah, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pamela W Jordan</author>
<author>Barbara Di Eugenio</author>
</authors>
<title>Control and initiative in collaborative problem solving dialogues.</title>
<date>1997</date>
<booktitle>In Working Notes of the AAAI Spring Symposium on Computational Models for Mixed Initiative,</booktitle>
<pages>81--84</pages>
<location>Menlo Park, CA.</location>
<marker>Jordan, Di Eugenio, 1997</marker>
<rawString>Pamela W. Jordan and Barbara Di Eugenio. 1997. Control and initiative in collaborative problem solving dialogues. In Working Notes of the AAAI Spring Symposium on Computational Models for Mixed Initiative, pages 81–84, Menlo Park, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pamela W Jordan</author>
<author>Michael Ringenberg</author>
<author>Brian Hall</author>
</authors>
<title>Rapidly developing dialogue systems that support learning studies.</title>
<date>2006</date>
<booktitle>In Proceedings of ITS06 Workshop on Teaching with Robots, Agents, and NLP,</booktitle>
<pages>1--8</pages>
<contexts>
<context position="16317" citStr="Jordan et al., 2006" startWordPosition="2610" endWordPosition="2613">m, algorithms such as Classification Based on Associations (Liu, 2007) will be used. Additionally, I will explore those algorithms that take into account the sequence of actions, such as hidden Markov models or neural networks. 4 Computational Model The model will be implemented as an artificial agent, KSC-PaL, that interacts with a peer in collaborative problem solving using an interface similar to the one that was used in data collection (see Figure 1). This agent will be an extension of the TuTalk system, which is designed to support natural language dialogues for educational applications (Jordan et al., 2006). TuTalk contains a core set of dialogue system modules that can be replaced or enhanced as required by the application. The core modules are understanding and generation, a dialogue manager which is loosely characterized as a finite state machine with a stack and a student model. To implement the peer agent, I will replace TuTalk’s student model and add a planner module. Managing the information state of the dialogue (Larsson and Traum, 2000), which includes the beliefs and intentions of the participants, is important in the implementation of any dialogue agent. KSCPaL will use a student mode</context>
</contexts>
<marker>Jordan, Ringenberg, Hall, 2006</marker>
<rawString>Pamela W. Jordan, Michael Ringenberg, and Brian Hall. 2006. Rapidly developing dialogue systems that support learning studies. In Proceedings of ITS06 Workshop on Teaching with Robots, Agents, and NLP, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Staffan Larsson</author>
<author>David R Traum</author>
</authors>
<title>Information state and dialogue management in the trindi dialogue move engine toolkit.</title>
<date>2000</date>
<journal>Nat. Lang. Eng.,</journal>
<pages>6--3</pages>
<contexts>
<context position="16764" citStr="Larsson and Traum, 2000" startWordPosition="2685" endWordPosition="2688"> (see Figure 1). This agent will be an extension of the TuTalk system, which is designed to support natural language dialogues for educational applications (Jordan et al., 2006). TuTalk contains a core set of dialogue system modules that can be replaced or enhanced as required by the application. The core modules are understanding and generation, a dialogue manager which is loosely characterized as a finite state machine with a stack and a student model. To implement the peer agent, I will replace TuTalk’s student model and add a planner module. Managing the information state of the dialogue (Larsson and Traum, 2000), which includes the beliefs and intentions of the participants, is important in the implementation of any dialogue agent. KSCPaL will use a student model to assist in management of the information state. This student model tracks the current state of problem solving as well as estimates the student’s knowledge of concepts involved in solving the problem by incorporating problem solution graphs (Conati et al., 2002). Solution graphs are Bayesian networks where each node represents either an action required to solve the problem or a concept required as part of problem solving. After analyzing o</context>
</contexts>
<marker>Larsson, Traum, 2000</marker>
<rawString>Staffan Larsson and David R. Traum. 2000. Information state and dialogue management in the trindi dialogue move engine toolkit. Nat. Lang. Eng., 6(3-4):323–340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Web data mining: exploring hyperlinks, contents, and usage data.</title>
<date>2007</date>
<publisher>Springer.</publisher>
<contexts>
<context position="15767" citStr="Liu, 2007" startWordPosition="2520" endWordPosition="2521">rns that a student had initiative (R2 =0.077, p=0.065). This suggests that both taking the ini46 tiative and taking turns in leading problem solving results in learning. Given my hypothesis that initiative can be used to identify co-construction, the next step is to annotate the dialogues using a subset of the DAMSL scheme (Core and Allen, 1997) to identify episodes of co-construction. Once annotated, I will use machine learning techniques to identify co-construction using initiative as a feature. Since this is a classification problem, algorithms such as Classification Based on Associations (Liu, 2007) will be used. Additionally, I will explore those algorithms that take into account the sequence of actions, such as hidden Markov models or neural networks. 4 Computational Model The model will be implemented as an artificial agent, KSC-PaL, that interacts with a peer in collaborative problem solving using an interface similar to the one that was used in data collection (see Figure 1). This agent will be an extension of the TuTalk system, which is designed to support natural language dialogues for educational applications (Jordan et al., 2006). TuTalk contains a core set of dialogue system mo</context>
</contexts>
<marker>Liu, 2007</marker>
<rawString>Bing Liu. 2007. Web data mining: exploring hyperlinks, contents, and usage data. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karen E Lochbaum</author>
<author>Candice L Sidner</author>
</authors>
<title>Models of plans to support communication: An initial report.</title>
<date>1990</date>
<booktitle>In Thomas Dietterich and William Swartout, editors, Proceedings of the Eighth National Conference on Artificial Intelligence,</booktitle>
<pages>485--490</pages>
<publisher>AAAI Press.</publisher>
<location>Menlo Park, California.</location>
<contexts>
<context position="817" citStr="Lochbaum and Sidner, 1990" startWordPosition="116" endWordPosition="119">ough collaboration in peer learning has been shown to have a positive impact for students, there has been little research into collaborative peer learning dialogues. We analyze such dialogues in order to derive a model of knowledge co-construction that incorporates initiative and the balance of initiative. This model will be embedded in an artificial agent that will collaborate with students. 1 Introduction While collaboration in dialogue has long been researched in computational linguistics (Chu-Carroll and Carberry, 1998; Constantino-Gonz´alez and Suthers, 2000; Jordan and Di Eugenio, 1997; Lochbaum and Sidner, 1990; Soller, 2004; Vizcaino, 2005), there has been little research on collaboration in peer learning. However, this is an important area of study because collaboration has been shown to promote learning, potentially for all of the participants (Tin, 2003). Additionally, while there has been a focus on using natural language for intelligent tutoring systems (Evens et al., 1997; Graesser et al., 2004; VanLehn et al., 2002), peer to peer interactions are notably different from those of expertnovice pairings, especially with respect to the richness of the problem-solving deliberations and negotiation</context>
</contexts>
<marker>Lochbaum, Sidner, 1990</marker>
<rawString>Karen E. Lochbaum and Candice L. Sidner. 1990. Models of plans to support communication: An initial report. In Thomas Dietterich and William Swartout, editors, Proceedings of the Eighth National Conference on Artificial Intelligence, pages 485–490, Menlo Park, California. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xin Lu</author>
</authors>
<title>Expert Tutoring and Natural Language Feedback in Intelligent Tutoring Systems.</title>
<date>2007</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Illinois at Chicago.</institution>
<contexts>
<context position="18977" citStr="Lu, 2007" startWordPosition="3060" endWordPosition="3061"> the student’s knowledge as well as the current topic under discussion. A planner module will be added to TuTalk to provide KSC-PaL with a more sophisticated method of selecting scripts. Unlike TuTalk’s dialogue manager which uses a simple matching of utterances to concepts in order to determine the script to be followed, KSC-PaL’s planner will incorporate the results of the data analysis above and will also include the status of the student’s knowledge, as reflected in the student model, in making script selections. This planner will potentially be a probabilistic planner such as the one in (Lu, 2007). 5 Conclusion In conclusion, we are developing a computational model of knowledge construction which incorporates initiative and the balance of initiative. This model will be embedded in an artificial agent that collaborates with students to solve data structure problems. As knowledge construction has been shown to promote learning, this research could have a profound impact on educational applications by changing the way in which they engage students in learning. Acknowledgments The graphical interface is based on a graphical interface developed by Davide Fossati for an intelligent tutoring </context>
</contexts>
<marker>Lu, 2007</marker>
<rawString>Xin Lu. 2007. Expert Tutoring and Natural Language Feedback in Intelligent Tutoring Systems. Ph.D. thesis, University of Illinois at Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amy Soller</author>
</authors>
<title>Computational modeling and analysis of knowledge sharing in collaborative distance learning. User Modeling and User-Adapted Interaction,</title>
<date>2004</date>
<volume>14</volume>
<issue>4</issue>
<contexts>
<context position="831" citStr="Soller, 2004" startWordPosition="120" endWordPosition="121">learning has been shown to have a positive impact for students, there has been little research into collaborative peer learning dialogues. We analyze such dialogues in order to derive a model of knowledge co-construction that incorporates initiative and the balance of initiative. This model will be embedded in an artificial agent that will collaborate with students. 1 Introduction While collaboration in dialogue has long been researched in computational linguistics (Chu-Carroll and Carberry, 1998; Constantino-Gonz´alez and Suthers, 2000; Jordan and Di Eugenio, 1997; Lochbaum and Sidner, 1990; Soller, 2004; Vizcaino, 2005), there has been little research on collaboration in peer learning. However, this is an important area of study because collaboration has been shown to promote learning, potentially for all of the participants (Tin, 2003). Additionally, while there has been a focus on using natural language for intelligent tutoring systems (Evens et al., 1997; Graesser et al., 2004; VanLehn et al., 2002), peer to peer interactions are notably different from those of expertnovice pairings, especially with respect to the richness of the problem-solving deliberations and negotiations. Using natur</context>
</contexts>
<marker>Soller, 2004</marker>
<rawString>Amy Soller. 2004. Computational modeling and analysis of knowledge sharing in collaborative distance learning. User Modeling and User-Adapted Interaction, Volume 14(4):351–381, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tan Bee Tin</author>
</authors>
<title>Does talking with peers help learning? the role of expertise and talk in convergent group discussion tasks.</title>
<date>2003</date>
<journal>Journal of English for Academic Purposes,</journal>
<volume>2</volume>
<issue>1</issue>
<contexts>
<context position="1069" citStr="Tin, 2003" startWordPosition="158" endWordPosition="159">nitiative and the balance of initiative. This model will be embedded in an artificial agent that will collaborate with students. 1 Introduction While collaboration in dialogue has long been researched in computational linguistics (Chu-Carroll and Carberry, 1998; Constantino-Gonz´alez and Suthers, 2000; Jordan and Di Eugenio, 1997; Lochbaum and Sidner, 1990; Soller, 2004; Vizcaino, 2005), there has been little research on collaboration in peer learning. However, this is an important area of study because collaboration has been shown to promote learning, potentially for all of the participants (Tin, 2003). Additionally, while there has been a focus on using natural language for intelligent tutoring systems (Evens et al., 1997; Graesser et al., 2004; VanLehn et al., 2002), peer to peer interactions are notably different from those of expertnovice pairings, especially with respect to the richness of the problem-solving deliberations and negotiations. Using natural language in collaborative learning could have a profound impact on the way in which educational applications engage students in learning. *This work is funded by NSF grants 0536968 and 0536959. There are various theories as to why coll</context>
</contexts>
<marker>Tin, 2003</marker>
<rawString>Tan Bee Tin. 2003. Does talking with peers help learning? the role of expertise and talk in convergent group discussion tasks. Journal of English for Academic Purposes, 2(1):53–66.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Kurt VanLehn</author>
<author>Pamela W Jordan</author>
<author>Carolyn Penstein Ros´e</author>
<author>Dumisizwe Bhembe</author>
<author>Michael B¨ottner</author>
<author>Andy Gaydos</author>
<author>Maxim Makatchev</author>
<author>Umarani Pappuswamy</author>
<author>Michael A Ringenberg</author>
<author>Antonio Roque</author>
<author>Stephanie Siler</author>
<author>Ramesh Srivastava</author>
</authors>
<title>The architecture of why2-atlas: A coach for qualitative physics essay writing.</title>
<date>2002</date>
<booktitle>In ITS ’02: Proceedings of the 6th International Conference on Intelligent Tutoring Systems,</booktitle>
<pages>158--167</pages>
<publisher>Springer-Verlag.</publisher>
<location>London, UK.</location>
<marker>VanLehn, Jordan, Ros´e, Bhembe, B¨ottner, Gaydos, Makatchev, Pappuswamy, Ringenberg, Roque, Siler, Srivastava, 2002</marker>
<rawString>Kurt VanLehn, Pamela W. Jordan, Carolyn Penstein Ros´e, Dumisizwe Bhembe, Michael B¨ottner, Andy Gaydos, Maxim Makatchev, Umarani Pappuswamy, Michael A. Ringenberg, Antonio Roque, Stephanie Siler, and Ramesh Srivastava. 2002. The architecture of why2-atlas: A coach for qualitative physics essay writing. In ITS ’02: Proceedings of the 6th International Conference on Intelligent Tutoring Systems, pages 158–167, London, UK. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aurora Vizca´ıno</author>
</authors>
<title>A simulated student can improve collaborative learning.</title>
<date>2005</date>
<journal>International Journal of Artificial Intelligence in Education,</journal>
<volume>15</volume>
<issue>1</issue>
<marker>Vizca´ıno, 2005</marker>
<rawString>Aurora Vizca´ıno. 2005. A simulated student can improve collaborative learning. International Journal of Artificial Intelligence in Education, 15(1):3–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn Walker</author>
<author>Steve Whittaker</author>
</authors>
<title>Mixed initiative in dialogue: an investigation into discourse segmentation.</title>
<date>1990</date>
<booktitle>In Proceedings of the 28th annual meeting on Association for Computational Linguistics,</booktitle>
<pages>70--78</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="9290" citStr="Walker and Whittaker, 1990" startWordPosition="1468" endWordPosition="1471">logues. The problems that were analyzed are all error diagnosis problems, but each problem involves a different data structure - linked list, arraybased stack and binary search tree. Additionally, I analyzed the relationship between initiative and post-test score, learning gain and successful problem solving. Before embarking on an exhaustive manual annotation of initiative, I chose to get a sense of whether initiative may indeed affect learning in this context by automatically tagging for initiative using an approximation of Walker and Whittaker’s utterance based allocation of control rules (Walker and Whittaker, 1990). In this scheme, first each turn in the dialogue must be tagged as either: (1) an assertion, (2) a command, (3) a question or (4) a prompt (turns not expressing propositional content). This was done automatically, by marking turns that end in a question mark as questions, those that start with a verb as commands, prompts from a list of commonly used prompts (e.g. ok, yeah) and the remaining turns as assertions. Control is then allocated by using the following rules based on the turn type: 1. Assertion: Control is allocated to the speaker unless it is a response to a question. 2. Command: Cont</context>
<context position="12055" citStr="Walker and Whittaker, 1990" startWordPosition="1918" endWordPosition="1921">re is a correlation of initiative and successful collaboration. In problem 3, learning gain positively correlates with the number of turns where a student has initiative (R2 = 0.156, p = 0.037). And in problem 4, taking initiative through drawing has a positive impact on post-test score (R2 = 0.155,p = 0.047). 3 Annotation Since the preliminary analysis showed a correlation of initiative with learning gain, I chose to begin a thorough data analysis by annotating the dialogues with initiative shifts. Walker and Whittaker claim that initiative encompasses both dialogue control and task control (Walker and Whittaker, 1990), however, several others disagree. Jordan and Di Eugenio propose that control and initiative are two separate features in collaborative problem solving dialogues (Jordan and Di Eugenio, 1997). While control and initiative might be synonymous for the dialogues analyzed by Walker and Whittaker where a masterslave assumption holds, it is not the case in collaborative dialogues where no such assumption exists. Jordan and Di Eugenio argue that the notion of control should apply to the dialogue level, while initiative should pertain to the problem-solving goals. In a similar vein, Chu-Carroll and B</context>
</contexts>
<marker>Walker, Whittaker, 1990</marker>
<rawString>Marilyn Walker and Steve Whittaker. 1990. Mixed initiative in dialogue: an investigation into discourse segmentation. In Proceedings of the 28th annual meeting on Association for Computational Linguistics, pages 70–78, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kim Onn Yap</author>
</authors>
<title>Pretest-posttest correlation and regression models.</title>
<date>1979</date>
<booktitle>Presented at the Annual Meeting of the American Educational Research Association (63rd,</booktitle>
<location>San Francisco, California),</location>
<contexts>
<context position="10656" citStr="Yap, 1979" startWordPosition="1705" endWordPosition="1706"> allocated to the hearer. Since the dialogues also have a graphics component, all drawing and code change moves had control assigned to the peer drawing or making the code change. The results of the regression analysis are summarized in tables 1 and 2, with blank cells representing non-significant correlations. Pre-test score, which represents the student’s initial knowledge and/or aptitude in the area, was selected as a feature because it is important to understand the strength of the correlation between previous knowledge and post test score when identifying additional correlating features (Yap, 1979). The same holds for the time related features (pencil time and total time). The remaining correlations and trends to correlation suggest that participation is an important factor in successful collaboration. Since a student is more likely to take initiative when actively participating in prob45 Predictor Prob. 3 Prob.4 Prob. 5 (Lists) (Stacks) (Trees) Pre-Test 0.334 0.214 0.269 (p=0.001) (p=0.017) (p=0.009) Total 0.186 0.125 0.129 Time (p=0.022) (p=0.076) (p=0.085) Total 0.129 0.134 Turns (p=0.061) (p=0.065) Draw 0.116 0.122 Turns (p=0.076) (p=0.080) Code 0.130 Turns (p=0.071) Table 2: Proble</context>
</contexts>
<marker>Yap, 1979</marker>
<rawString>Kim Onn Yap. 1979. Pretest-posttest correlation and regression models. Presented at the Annual Meeting of the American Educational Research Association (63rd, San Francisco, California), April 8–12.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>