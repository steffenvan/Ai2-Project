<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000014">
<title confidence="0.98427">
Learning Bilingual Lexicons from Monolingual Corpora
</title>
<author confidence="0.99958">
Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick and Dan Klein
</author>
<affiliation confidence="0.999376">
Computer Science Division, University of California at Berkeley
</affiliation>
<email confidence="0.995215">
faria42,pliang,tberg,kleinl@cs.berkeley.edu
</email>
<sectionHeader confidence="0.993806" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99972025">
We present a method for learning bilingual
translation lexicons from monolingual cor-
pora. Word types in each language are charac-
terized by purely monolingual features, such
as context counts and orthographic substrings.
Translations are induced using a generative
model based on canonical correlation analy-
sis, which explains the monolingual lexicons
in terms of latent matchings. We show that
high-precision lexicons can be learned in a va-
riety of language pairs and from a range of
corpus types.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999951301886793">
Current statistical machine translation systems use
parallel corpora to induce translation correspon-
dences, whether those correspondences be at the
level of phrases (Koehn, 2004), treelets (Galley et
al., 2006), or simply single words (Brown et al.,
1994). Although parallel text is plentiful for some
language pairs such as English-Chinese or English-
Arabic, it is scarce or even non-existent for most
others, such as English-Hindi or French-Japanese.
Moreover, parallel text could be scarce for a lan-
guage pair even if monolingual data is readily avail-
able for both languages.
In this paper, we consider the problem of learning
translations from monolingual sources alone. This
task, though clearly more difficult than the standard
parallel text approach, can operate on language pairs
and in domains where standard approaches cannot.
We take as input two monolingual corpora and per-
haps some seed translations, and we produce as out-
put a bilingual lexicon, defined as a list of word
pairs deemed to be word-level translations. Preci-
sion and recall are then measured over these bilin-
gual lexicons. This setting has been considered be-
fore, most notably in Koehn and Knight (2002) and
Fung (1995), but the current paper is the first to use
a probabilistic model and present results across a va-
riety of language pairs and data conditions.
In our method, we represent each language as a
monolingual lexicon (see figure 2): a list of word
types characterized by monolingual feature vectors,
such as context counts, orthographic substrings, and
so on (section 5). We define a generative model over
(1) a source lexicon, (2) a target lexicon, and (3) a
matching between them (section 2). Our model is
based on canonical correlation analysis (CCA)1 and
explains matched word pairs via vectors in a com-
mon latent space. Inference in the model is done
using an EM-style algorithm (section 3).
Somewhat surprisingly, we show that it is pos-
sible to learn or extend a translation lexicon us-
ing monolingual corpora alone, in a variety of lan-
guages and using a variety of corpora, even in the
absence of orthographic features. As might be ex-
pected, the task is harder when no seed lexicon is
provided, when the languages are strongly diver-
gent, or when the monolingual corpora are from dif-
ferent domains. Nonetheless, even in the more diffi-
cult cases, a sizable set of high-precision translations
can be extracted. As an example of the performance
of the system, in English-Spanish induction with our
best feature set, using corpora derived from topically
similar but non-parallel sources, the system obtains
89.0% precision at 33% recall.
</bodyText>
<note confidence="0.597504">
1See Hardoon et al. (2003) for an overview.
</note>
<page confidence="0.937549">
771
</page>
<note confidence="0.690738">
Proceedings ofACL-08: HLT, pages 771–779,
</note>
<page confidence="0.372582">
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</page>
<figureCaption confidence="0.987464">
Figure 1: Bilingual lexicon induction: source word types
s are listed on the left and target word types t on the
right. Dashed lines between nodes indicate translation
pairs which are in the matching m.
</figureCaption>
<sectionHeader confidence="0.951014" genericHeader="introduction">
2 Bilingual Lexicon Induction
</sectionHeader>
<bodyText confidence="0.999575777777778">
As input, we are given a monolingual corpus S (a
sequence of word tokens) in a source language and
a monolingual corpus T in a target language. Let
s = (s1, ... , snS) denote nS word types appearing
in the source language, and t = (t1, ... , tnT) denote
word types in the target language. Based on S and
T, our goal is to output a matching m between s
and t. We represent m as a set of integer pairs so
that (i, j) E m if and only if si is matched with tj.
</bodyText>
<sectionHeader confidence="0.887293" genericHeader="method">
2.1 Generative Model
</sectionHeader>
<bodyText confidence="0.996305666666667">
We propose the following generative model over
matchings m and word types (s, t), which we call
matching canonical correlation analysis (MCCA).
</bodyText>
<equation confidence="0.9667136">
MCCA model
m — MATCHING-PRIOR [matching m]
For each matched edge (i, j) E m:
zi,j — N (0, Id) [latent concept]
fS(si) — N(WSzi,j, FS) [source features]
fT(ti) — N(WTzi,j, FT) [target features]
For each unmatched source word type i:
fS(si) — N(0, σ2IdS) [source features]
For each unmatched target word type j:
fT (tj) — N(0, σ2Id&apos; ) [target features]
</equation>
<bodyText confidence="0.999939162790698">
First, we generate a matching m E M, where M
is the set of matchings in which each word type is
matched to at most one other word type.2 We take
MATCHING-PRIOR to be uniform over M.3
Then, for each matched pair of word types (i, j) E
m, we need to generate the observed feature vectors
of the source and target word types, fS(si) E RdS
and fT (tj) E RdT . The feature vector of each word
type is computed from the appropriate monolin-
gual corpus and summarizes the word’s monolingual
characteristics; see section 5 for details and figure 2
for an illustration. Since si and tj are translations of
each other, we expect fS(si) and fT(tj) to be con-
nected somehow by the generative process. In our
model, they are related through a vector zi,j E Rd
representing the shared, language-independent con-
cept.
Specifically, to generate the feature vectors, we
first generate a random concept zi,j — N(0, Id),
where Id is the d x d identity matrix. The source
feature vector fS(si) is drawn from a multivari-
ate Gaussian with mean WSzi,j and covariance FS,
where WS is a dS x d matrix which transforms the
language-independent concept zi,j into a language-
dependent vector in the source space. The arbitrary
covariance parameter FS �: 0 explains the source-
specific variations which are not captured by WS; it
does not play an explicit role in inference. The target
fT (tj) is generated analogously using WT and FT,
conditionally independent of the source given zi,j
(see figure 2). For each of the remaining unmatched
source word types si which have not yet been gen-
erated, we draw the word type features from a base-
line normal distribution with variance σ2IdS, with
hyperparameter σ2 » 0; unmatched target words
are similarly generated.
If two word types are truly translations, it will be
better to relate their feature vectors through the la-
tent space than to explain them independently via
the baseline distribution. However, if a source word
type is not a translation of any of the target word
types, we can just generate it independently without
requiring it to participate in the matching.
</bodyText>
<footnote confidence="0.922592">
2Our choice of M permits unmatched word types, but does
not allow words to have multiple translations. This setting facil-
itates comparison to previous work and admits simpler models.
3However, non-uniform priors could encode useful informa-
tion, such as rank similarities.
</footnote>
<figure confidence="0.998167133333333">
s m t
enlarge-
ment
control
society
import-
ance
state
amplifi-
caci—n
control
import-
ancia
sociedad
estado
</figure>
<page confidence="0.810615">
772
</page>
<figureCaption confidence="0.9982665">
Figure 2: Illustration of our MCCA model. Each latent concept zi,j originates in the canonical space. The observed
word vectors in the source and target spaces are generated independently given this concept.
</figureCaption>
<figure confidence="0.999775607843137">
Orthographic Features
Contextual Features
{
{
necessary
change
dawn
period
#ti
me#
ime
100.0
20.0
50.0
1.0
1.0
1.0
5.0
.
.
.
Source
Space
time tiempo
Si tj
Rd
Target
Space
Rd
suficiente
adicional
per’odo
mismo
mpo
#ti
pe#
120.0
40.0
65.0
45.0
1.0
1.0
1.0
.
.
.
fS(si)
Mt,)
Canonical
Space
Rd
</figure>
<sectionHeader confidence="0.986066" genericHeader="method">
3 Inference
</sectionHeader>
<bodyText confidence="0.998113">
Given our probabilistic model, we would like to
maximize the log-likelihood of the observed data
</bodyText>
<equation confidence="0.821947666666667">
(s, t):
e(0) = log p(s, t; 0) = log � p(m, s, t; 0)
m
</equation>
<bodyText confidence="0.976815714285714">
with respect to the model parameters 0 =
(WS, WT, `pS, &amp;T).
We use the hard (Viterbi) EM algorithm as a start-
ing point, but due to modeling and computational
considerations, we make several important modifi-
cations, which we describe later. The general form
of our algorithm is as follows:
</bodyText>
<subsectionHeader confidence="0.731779">
Summary of learning algorithm
</subsectionHeader>
<bodyText confidence="0.926365428571429">
E-step: Find the maximum weighted (partial) bi-
partite matching m E ✓Vl
M-step: Find the best parameters 0 by performing
canonical correlation analysis (CCA)
M-step Given a matching m, the M-step opti-
mizes logp(m, s, t; 0) with respect to 0, which can
be rewritten as
</bodyText>
<equation confidence="0.915294">
max
B � logp(si, tj; 0). (1)
(i,j)∈m
</equation>
<bodyText confidence="0.995337608695652">
This objective corresponds exactly to maximizing
the likelihood of the probabilistic CCA model pre-
sented in Bach and Jordan (2006), which proved
that the maximum likelihood estimate can be com-
puted by canonical correlation analysis (CCA). In-
tuitively, CCA finds d-dimensional subspaces US E
RdS×d of the source and UT E RdT ×d of the tar-
get such that the components of the projections
U&gt;S fS(si) and U&gt;T fT(tj) are maximally correlated.4
US and UT can be found by solving an eigenvalue
problem (see Hardoon et al. (2003) for details).
Then the maximum likelihood estimates are as fol-
lows: WS = CSSUSP1/2, WT = CTTUTP1/2,
q&apos;S =CSS − WSWS&gt; , and &apos;PT = CTT − WTWT&gt; ,
where P is a d x d diagonal matrix of the canonical
correlations, CSS = |m |E(i,j)∈m fS(si)fS(si)&gt; is
the empirical covariance matrix in the source do-
main, and CTT is defined analogously.
E-step To perform a conventional E-step, we
would need to compute the posterior over all match-
ings, which is #P-complete (Valiant, 1979). On the
other hand, hard EM only requires us to compute the
best matching under the current model:5
</bodyText>
<equation confidence="0.9890545">
m = argmax log p(m0, s, t; 0). (2)
m1
</equation>
<bodyText confidence="0.99967475">
We cast this optimization as a maximum weighted
bipartite matching problem as follows. Define the
edge weight between source word type i and target
word type j to be
</bodyText>
<equation confidence="0.9997545">
wi,j = log p(si, tj; 0) (3)
− log p(si; 0) − log p(tj; 0),
</equation>
<footnote confidence="0.675492428571429">
4Since dS and dT can be quite large in practice and of-
ten greater than Iml, we use Cholesky decomposition to re-
represent the feature vectors as Iml-dimensional vectors with
the same dot products, which is all that CCA depends on.
5If we wanted softer estimates, we could use the agreement-
based learning framework of Liang et al. (2008) to combine two
tractable models.
</footnote>
<page confidence="0.996696">
773
</page>
<bodyText confidence="0.999849142857143">
are presented for other languages in section 6. In
this section, we describe the data and experimental
methodology used throughout this work.
which can be loosely viewed as a pointwise mutual
information quantity. We can check that the ob-
jective logp(m, s, t; B) is equal to the weight of a
matching plus some constant C:
</bodyText>
<equation confidence="0.79615">
4.1 Data
log p(m, s, t; B) = � wz,7 + C. (4) Each experiment requires a source and target mono-
(z,7)Em lingual corpus. We use the following corpora:
</equation>
<bodyText confidence="0.99996096">
To find the optimal partial matching, edges with
weight wz,7 &lt; 0 are set to zero in the graph and the
optimal full matching is computed in 0((nS+nT)3)
time using the Hungarian algorithm (Kuhn, 1955). If
a zero edge is present in the solution, we remove the
involved word types from the matching.6
Bootstrapping Recall that the E-step produces a
partial matching of the word types. If too few
word types are matched, learning will not progress
quickly; if too many are matched, the model will be
swamped with noise. We found that it was helpful
to explicitly control the number of edges. Thus, we
adopt a bootstrapping-style approach that only per-
mits high confidence edges at first, and then slowly
permits more over time. In particular, we compute
the optimal full matching, but only retain the high-
est weighted edges. As we run EM, we gradually
increase the number of edges to retain.
In our context, bootstrapping has a similar moti-
vation to the annealing approach of Smith and Eisner
(2006), which also tries to alter the space of hidden
outputs in the E-step over time to facilitate learn-
ing in the M-step, though of course the use of boot-
strapping in general is quite widespread (Yarowsky,
1995).
</bodyText>
<sectionHeader confidence="0.999093" genericHeader="method">
4 Experimental Setup
</sectionHeader>
<bodyText confidence="0.992501166666667">
In section 5, we present developmental experiments
in English-Spanish lexicon induction; experiments
6Empirically, we obtained much better efficiency and even
increased accuracy by replacing these marginal likelihood
weights with a simple proxy, the distances between the words’
mean latent concepts:
</bodyText>
<equation confidence="0.974229">
�i,j = A � ��z� i � z� j ��2� (5)
</equation>
<bodyText confidence="0.9801475">
where A is a thresholding constant, zz = E(zi,j �fS(si)) =
P1/2Us fS(si), and zj* is defined analogously. The increased
accuracy may not be an accident: whether two words are trans-
lations is perhaps better characterized directly by how close
their latent concepts are, whereas log-probability is more sensi-
tive to perturbations in the source and target spaces.
</bodyText>
<listItem confidence="0.991777944444445">
• EN-ES-W: 3,851 Wikipedia articles with both
English and Spanish bodies (generally not di-
rect translations).
• EN-ES-P: 1st 100k sentences of text from the
parallel English and Spanish Europarl corpus
(Koehn, 2005).
• EN-ES(FR)-D: English: 1st 50k sentences of
Europarl; Spanish (French): 2nd 50k sentences
of Europarl.7
• EN-CH-D: English: 1st 50k sentences of Xin-
hua parallel news corpora;8 Chinese: 2nd 50k
sentences.
• EN-AR-D: English: 1st 50k sentences of 1994
proceedings of UN parallel corpora;9 Ara-
bic: 2nd 50k sentences.
• EN-ES-G: English: 100k sentences of English
Gigaword; Spanish: 100k sentences of Spanish
Gigaword.10
</listItem>
<bodyText confidence="0.9996086">
Note that even when corpora are derived from par-
allel sources, no explicit use is ever made of docu-
ment or sentence-level alignments. In particular, our
method is robust to permutations of the sentences in
the corpora.
</bodyText>
<subsectionHeader confidence="0.965031">
4.2 Lexicon
</subsectionHeader>
<bodyText confidence="0.999924666666667">
Each experiment requires a lexicon for evaluation.
Following Koehn and Knight (2002), we consider
lexicons over only noun word types, although this
is not a fundamental limitation of our model. We
consider a word type to be a noun if its most com-
mon tag is a noun in our monolingual corpus.11 For
</bodyText>
<footnote confidence="0.9298135">
7Note that the although the corpora here are derived from a
parallel corpus, there are no parallel sentences.
8LDC catalog # 2002E18.
9LDC catalog # 2004E13.
10These corpora contain no parallel sentences.
11We use the Tree Tagger (Schmid, 1994) for all POS tagging
except for Arabic, where we use the tagger described in Diab et
al. (2004).
</footnote>
<page confidence="0.992446">
774
</page>
<figure confidence="0.978089">
Precision
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8
Recall
</figure>
<figureCaption confidence="0.995109">
Figure 3: Example precision/recall curve of our system
on EN-ES-P and EN-ES-W settings. See section 6.1.
</figureCaption>
<bodyText confidence="0.999693409090909">
all languages pairs except English-Arabic, we ex-
tract evaluation lexicons from the Wiktionary on-
line dictionary. As we discuss in section 7, our ex-
tracted lexicons have low coverage, particularly for
proper nouns, and thus all performance measures are
(sometimes substantially) pessimistic. For English-
Arabic, we extract a lexicon from 100k parallel sen-
tences of UN parallel corpora by running the HMM
intersected alignment model (Liang et al., 2008),
adding (s, t) to the lexicon if s was aligned to t at
least three times and more than any other word.
Also, as in Koehn and Knight (2002), we make
use of a seed lexicon, which consists of a small, and
perhaps incorrect, set of initial translation pairs. We
used two methods to derive a seed lexicon. The
first is to use the evaluation lexicon Le and select
the hundred most common noun word types in the
source corpus which have translations in Le. The
second method is to heuristically induce, where ap-
plicable, a seed lexicon using edit distance, as is
done in Koehn and Knight (2002). Section 6.2 com-
pares the performance of these two methods.
</bodyText>
<subsectionHeader confidence="0.992712">
4.3 Evaluation
</subsectionHeader>
<bodyText confidence="0.999950666666667">
We evaluate a proposed lexicon Lp against the eval-
uation lexicon Le using the Fl measure in the stan-
dard fashion; precision is given by the number of
proposed translations contained in the evaluation
lexicon, and recall is given by the fraction of pos-
sible translation pairs proposed.12 Since our model
</bodyText>
<tableCaption confidence="0.865675">
12We should note that precision is not penalized for (s, t) if
s does not have a translation in .Ce, and recall is not penalized
for failing to recover multiple translations of s.
</tableCaption>
<table confidence="0.999894">
Setting p0.1 p0.25 p0.33 p0.50 Best-F1
EDITDIST 58.6 62.6 61.1 —- 47.4
ORTHO 76.0 81.3 80.1 52.3 55.0
CONTEXT 91.1 81.3 80.2 65.3 58.0
MCCA 87.2 89.7 89.0 89.7 72.0
</table>
<tableCaption confidence="0.9988385">
Table 1: Performance of EDITDIST and our model with
various features sets on EN-ES-W. See section 5.
</tableCaption>
<bodyText confidence="0.999835">
naturally produces lexicons in which each entry is
associated with a weight based on the model, we can
give a full precision/recall curve (see figure 3). We
summarize these curves with both the best Fl over
all possible thresholds and various precisions px at
recalls x. All reported numbers exclude evaluation
on the seed lexicon entries, regardless of how those
seeds are derived or whether they are correct.
In all experiments, unless noted otherwise, we
used a seed of size 100 obtained from Le and
considered lexicons between the top n = 2,000
most frequent source and target noun word types
which were not in the seed lexicon; each system
proposed an already-ranked one-to-one translation
lexicon amongst these n words. Where applica-
ble, we compare against the EDITDIST baseline,
which solves a maximum bipartite matching prob-
lem where edge weights are normalized edit dis-
tances. We will use MCCA (for matching CCA) to
denote our model using the optimal feature set (see
section 5.3).
</bodyText>
<sectionHeader confidence="0.999373" genericHeader="method">
5 Features
</sectionHeader>
<bodyText confidence="0.99997225">
In this section, we explore feature representations of
word types in our model. Recall that f�(·) and fT (·)
map source and target word types to vectors in RdS
and RdT, respectively (see section 2). The features
used in each representation are defined identically
and derived only from the appropriate monolingual
corpora. For a concrete example of a word type to
feature vector mapping, see figure 2.
</bodyText>
<subsectionHeader confidence="0.974839">
5.1 Orthographic Features
</subsectionHeader>
<bodyText confidence="0.9996208">
For closely related languages, such as English and
Spanish, translation pairs often share many ortho-
graphic features. One direct way to capture ortho-
graphic similarity between word pairs is edit dis-
tance. Running EDITDIST (see section 4.3) on EN-
</bodyText>
<figure confidence="0.998522">
1
0.95
0.9
0.85
0.8
0.75
0.7
0.65
0.6
EN-ES-P
EN-ES-W
</figure>
<page confidence="0.995491">
775
</page>
<bodyText confidence="0.999768">
ES-W yielded 61.1 p0.33, but precision quickly de-
grades for higher recall levels (see EDITDIST in ta-
ble 1). Nevertheless, when available, orthographic
clues are strong indicators of translation pairs.
We can represent orthographic features of a word
type w by assigning a feature to each substring of
length G 3. Note that MCCA can learn regular or-
thographic correspondences between source and tar-
get words, which is something edit distance cannot
capture (see table 5). Indeed, running our MCCA
model with only orthographic features on EN-ES-
W, labeled ORTHO in table 1, yielded 80.1 p0.33, a
31% error-reduction over EDITDIST in p0.33.
</bodyText>
<subsectionHeader confidence="0.997096">
5.2 Context Features
</subsectionHeader>
<bodyText confidence="0.999957">
While orthographic features are clearly effective for
historically related language pairs, they are more
limited for other language pairs, where we need to
appeal to other clues. One non-orthographic clue
that word types s and t form a translation pair is
that there is a strong correlation between the source
words used with s and the target words used with t.
To capture this information, we define context fea-
tures for each word type w, consisting of counts of
nouns which occur within a window of size 4 around
w. Consider the translation pair (time, tiempo)
illustrated in figure 2. As we become more con-
fident about other translation pairs which have ac-
tive period and periodico context features, we
learn that translation pairs tend to jointly generate
these features, which leads us to believe that time
and tiempo might be generated by a common un-
derlying concept vector (see section 2).13
Using context features alone on EN-ES-W, our
MCCA model (labeled CONTEXT in table 1) yielded
a 80.2 p0.33. It is perhaps surprising that context fea-
tures alone, without orthographic information, can
yield a best-F1comparable to EDITDIST.
</bodyText>
<subsectionHeader confidence="0.999561">
5.3 Combining Features
</subsectionHeader>
<bodyText confidence="0.999848">
We can of course combine context and orthographic
features. Doing so yielded 89.03 p0.33 (labeled
MCCA in table 1); this represents a 46.4% error re-
duction in p0.33 over the EDITDIST baseline. For the
remainder of this work, we will use MCCA to refer
</bodyText>
<footnote confidence="0.949149666666667">
13It is important to emphasize, however, that our current
model does not directly relate a word type’s role as a partici-
pant in the matching to that word’s role as a context feature.
</footnote>
<table confidence="0.971463176470588">
(a) Corpus Variation
Setting p0.1 p0.25 p0.33 p0.50 Best-F1
EN-ES-G 75.0 71.2 68.3 —- 49.0
EN-ES-W 87.2 89.7 89.0 89.7 72.0
EN-ES-D 91.4 94.3 92.3 89.7 63.7
EN-ES-P 97.3 94.8 93.8 92.9 77.0
(b) Seed Lexicon Variation
Corpus p0.1 p0.25 p0.33 p0.50 Best-F1
EDITDIST 58.6 62.6 61.1 — 47.4
MCCA 91.4 94.3 92.3 89.7 63.7
MCCA-AUTO 91.2 90.5 91.8 77.5 61.7
(c) Language Variation
Languages p0.1 p0.25 p0.33 p0.50 Best-F1
EN-ES 91.4 94.3 92.3 89.7 63.7
EN-FR 94.5 89.1 88.3 78.6 61.9
EN-CH 60.1 39.3 26.8 —- 30.8
EN-AR 70.0 50.0 31.1 —- 33.1
</table>
<tableCaption confidence="0.991309">
Table 2: (a) varying type of corpora used on system per-
</tableCaption>
<construct confidence="0.5639385">
formance (section 6.1), (b) using a heuristically chosen
seed compared to one taken from the evaluation lexicon
(section 6.2), (c) a variety of language pairs (see sec-
tion 6.3).
</construct>
<bodyText confidence="0.993825">
to our model using both orthographic and context
features.
</bodyText>
<sectionHeader confidence="0.999008" genericHeader="method">
6 Experiments
</sectionHeader>
<bodyText confidence="0.999661">
In this section we examine how system performance
varies when crucial elements are altered.
</bodyText>
<subsectionHeader confidence="0.999121">
6.1 Corpus Variation
</subsectionHeader>
<bodyText confidence="0.999000333333333">
There are many sources from which we can derive
monolingual corpora, and MCCA performance de-
pends on the degree of similarity between corpora.
We explored the following levels of relationships be-
tween corpora, roughly in order of closest to most
distant:
</bodyText>
<listItem confidence="0.9999155">
• Same Sentences: EN-ES-P
• Non-Parallel Similar Content: EN-ES-W
• Distinct Sentences, Same Domain: EN-ES-D
• Unrelated Corpora: EN-ES-G
</listItem>
<bodyText confidence="0.990379333333333">
Our results for all conditions are presented in ta-
ble 2(a). The predominant trend is that system per-
formance degraded when the corpora diverged in
</bodyText>
<page confidence="0.995897">
776
</page>
<bodyText confidence="0.999967833333333">
content, presumably due to context features becom-
ing less informative. However, it is notable that even
in the most extreme case of disjoint corpora from
different time periods and topics (e.g. EN-ES-G),
we are still able to recover lexicons of reasonable
accuracy.
</bodyText>
<subsectionHeader confidence="0.999827">
6.2 Seed Lexicon Variation
</subsectionHeader>
<bodyText confidence="0.999970842105263">
All of our experiments so far have exploited a small
seed lexicon which has been derived from the eval-
uation lexicon (see section 4.3). In order to explore
system robustness to heuristically chosen seed lexi-
cons, we automatically extracted a seed lexicon sim-
ilarly to Koehn and Knight (2002): we ran EDIT-
DIST on EN-ES-D and took the top 100 most con-
fident translation pairs. Using this automatically de-
rived seed lexicon, we ran our system on EN-ES-
D as before, evaluating on the top 2,000 noun word
types not included in the automatic lexicon.14 Us-
ing the automated seed lexicon, and still evaluat-
ing against our Wiktionary lexicon, MCCA-AUTO
yielded 91.8 p0.33 (see table 2(b)), indicating that
our system can produce lexicons of comparable ac-
curacy with a heuristically chosen seed. We should
note that this performance represents no knowledge
given to the system in the form of gold seed lexicon
entries.
</bodyText>
<subsectionHeader confidence="0.999291">
6.3 Language Variation
</subsectionHeader>
<bodyText confidence="0.9999849375">
We also explored how system performance varies
for language pairs other than English-Spanish. On
English-French, for the disjoint EN-FR-D corpus
(described in section 4.1), MCCA yielded 88.3 p0.33
(see table 2(c) for more performance measures).
This verified that our model can work for another
closely related language-pair on which no model de-
velopment was performed.
One concern is how our system performs on lan-
guage pairs where orthographic features are less ap-
plicable. Results on disjoint English-Chinese and
English-Arabic are given as EN-CH-D and EN-AR
in table 2(c), both using only context features. In
these cases, MCCA yielded much lower precisions
of 26.8 and 31.0 p0.33, respectively. For both lan-
guages, performance degraded compared to EN-ES-
</bodyText>
<footnote confidence="0.588436">
14Note that the 2,000 words evaluated here were not identical
to the words tested on when the seed lexicon is derived from the
evaluation lexicon.
</footnote>
<table confidence="0.983066">
(a) English-Spanish
Rank Source Target Correct
education educaci—n Y
pacto pact Y
stability estabilidad Y
6. corruption corrupci—n Y
7. tourism turismo Y
organisation organizaci—n Y
convenience conveniencia Y
syria siria Y
cooperation cooperaci—n Y
14. culture cultura Y
21. protocol protocolo Y
north norte Y
health salud Y
action reacci—n N
(b) English-French
Rank Source Target Correct
xenophobia xenophobie Y
corruption corruption Y
subsidiarity subsidiarit6 Y
programme programme-cadre N
8. traceability tragabilit6 Y
(c) English-Chinese
Rank Source Target Correct
prices %I,* Y
network M4 Y
population AQ Y
reporter N
oil Y
</table>
<tableCaption confidence="0.855783">
Table 3: Sample output from our (a) Spanish, (b) French,
and (c) Chinese systems. We present the highest con-
</tableCaption>
<bodyText confidence="0.864938555555555">
fidence system predictions, where the only editing done
is to ignore predictions which consist of identical source
and target words.
D and EN-FR-D, presumably due in part to the
lack of orthographic features. However, MCCA still
achieved surprising precision at lower recall levels.
For instance, at p0.1, MCCA yielded 60.1 and 70.0
on Chinese and Arabic, respectively. Figure 3 shows
the highest-confidence outputs in several languages.
</bodyText>
<subsectionHeader confidence="0.994225">
6.4 Comparison To Previous Work
</subsectionHeader>
<bodyText confidence="0.999972857142857">
There has been previous work in extracting trans-
lation pairs from non-parallel corpora (Rapp, 1995;
Fung, 1995; Koehn and Knight, 2002), but gener-
ally not in as extreme a setting as the one consid-
ered here. Due to unavailability of data and speci-
ficity in experimental conditions and evaluations, it
is not possible to perform exact comparisons. How-
</bodyText>
<page confidence="0.971949">
777
</page>
<figure confidence="0.940514769230769">
(a) Example Non-Cognate Pairs
health salud
traceability rastreabilidad
youth juventud
report informe
advantages ventajas
(b) Interesting Incorrect Pairs
liberal partido
Kirkhope Gorsel
action reacci´on
Albanians Bosnia
a.m. horas
Netherlands Breta˜na
</figure>
<tableCaption confidence="0.989502333333333">
Table 4: System analysis on EN-ES-W: (a) non-cognate
pairs proposed by our system, (b) hand-selected represen-
tative errors.
</tableCaption>
<table confidence="0.9818605">
(a) Orthographic Feature
Source Feat. Closest Target Feats. Example Translation
#st #es, est (statue, estatua)
ty# ad#, d# (felicity, felicidad)
ogy gia, gi (geology, geologia)
(b) Context Feature
Source Feat. Closest Context Features
party partido,izquierda
democrat socialistas, dem´ocratas
beijing pekin,kioto
</table>
<tableCaption confidence="0.847007">
Table 5: Hand selected examples of source and target fea-
tures which are close in canonical space: (a) orthographic
feature correspondences, (b) context features.
</tableCaption>
<bodyText confidence="0.999752666666667">
ever, we attempted to run an experiment as similar
as possible in setup to Koehn and Knight (2002), us-
ing English Gigaword and German Europarl. In this
setting, our MCCA system yielded 61.7% accuracy
on the 186 most confident predictions compared to
39% reported in Koehn and Knight (2002).
</bodyText>
<sectionHeader confidence="0.995431" genericHeader="evaluation">
7 Analysis
</sectionHeader>
<bodyText confidence="0.999997565217391">
We have presented a novel generative model for
bilingual lexicon induction and presented results un-
der a variety of data conditions (section 6.1) and lan-
guages (section 6.3) showing that our system can
produce accurate lexicons even in highly adverse
conditions. In this section, we broadly characterize
and analyze the behavior of our system.
We manually examined the top 100 errors in the
English-Spanish lexicon produced by our system
on EN-ES-W. Of the top 100 errors: 21 were cor-
rect translations not contained in the Wiktionary
lexicon (e.g. pintura to painting), 4 were
purely morphological errors (e.g. airport to
aeropuertos), 30 were semantically related (e.g.
basketball to b´eisbol), 15 were words with
strong orthographic similarities (e.g. coast to
costas), and 30 were difficult to categorize and
fell into none of these categories. Since many of
our ‘errors’ actually represent valid translation pairs
not contained in our extracted dictionary, we sup-
plemented our evaluation lexicon with one automat-
ically derived from 100k sentences of parallel Eu-
roparl data. We ran the intersected HMM word-
alignment model (Liang et al., 2008) and added
(s, t) to the lexicon if s was aligned to t at least
three times and more than any other word. Evaluat-
ing against the union of these lexicons yielded 98.0
p0.33, a significant improvement over the 92.3 us-
ing only the Wiktionary lexicon. Of the true errors,
the most common arose from semantically related
words which had strong context feature correlations
(see table 4(b)).
We also explored the relationships our model
learns between features of different languages. We
projected each source and target feature into the
shared canonical space, and for each projected
source feature we examined the closest projected
target features. In table 5(a), we present some of
the orthographic feature relationships learned by our
system. Many of these relationships correspond to
phonological and morphological regularities such as
the English suffix ing mapping to the Spanish suf-
fix gia. In table 5(b), we present context feature
correspondences. Here, the broad trend is for words
which are either translations or semantically related
across languages to be close in canonical space.
</bodyText>
<sectionHeader confidence="0.998706" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999898">
We have presented a generative model for bilingual
lexicon induction based on probabilistic CCA. Our
experiments show that high-precision translations
can be mined without any access to parallel corpora.
It remains to be seen how such lexicons can be best
utilized, but they invite new approaches to the statis-
tical translation of resource-poor languages.
</bodyText>
<page confidence="0.996751">
778
</page>
<sectionHeader confidence="0.995801" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999746959183673">
Francis R. Bach and Michael I. Jordan. 2006. A proba-
bilistic interpretation of canonical correlation analysis.
Technical report, University of California, Berkeley.
Peter F. Brown, Stephen Della Pietra, Vincent J. Della
Pietra, and Robert L. Mercer. 1994. The mathematic
of statistical machine translation: Parameter estima-
tion. Computational Linguistics, 19(2):263–311.
Mona Diab, Kadri Hacioglu, and Daniel Jurafsky. 2004.
Automatic tagging of arabic text: From raw text to
base phrase chunks. In HLT-NAACL.
Pascale Fung. 1995. Compiling bilingual lexicon entries
from a non-parallel english-chinese corpus. In Third
Annual Workshop on Very Large Corpora.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable inference and training
of context-rich syntactic translation models. In
COLING-ACL.
David R. Hardoon, Sandor Szedmak, and John Shawe-
Taylor. 2003. Canonical correlation analysis an
overview with application to learning methods. Tech-
nical Report CSD-TR-03-02, Royal Holloway Univer-
sity of London.
Philipp Koehn and Kevin Knight. 2002. Learning a
translation lexicon from monolingual corpora. In Pro-
ceedings of ACL Workshop on Unsupervised Lexical
Acquisition.
P. Koehn. 2004. Pharaoh: A beam search decoder
for phrase-based statistical machine translation mod-
els. In Proceedings of AMTA 2004.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In MT Summit.
H. W. Kuhn. 1955. The Hungarian method for the as-
signment problem. Naval Research Logistic Quar-
terly.
P. Liang, D. Klein, and M. I. Jordan. 2008. Agreement-
based learning. In NIPS.
Reinhard Rapp. 1995. Identifying word translation in
non-parallel texts. In ACL.
Helmut Schmid. 1994. Probabilistic part-of-speech tag-
ging using decision trees. In International Conference
on New Methods in Language Processing.
N. Smith and J. Eisner. 2006. Annealing structural bias
in multilingual weighted grammar induction. In ACL.
L. G. Valiant. 1979. The complexity of computing
the permanent. Theoretical Computer Science, 8:189–
201.
D. Yarowsky. 1995. Unsupervised word sense disam-
biguation rivaling supervised methods. In ACL.
</reference>
<page confidence="0.998646">
779
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.983144">
<title confidence="0.999553">Learning Bilingual Lexicons from Monolingual Corpora</title>
<author confidence="0.988931">Percy Liang Haghighi</author>
<author confidence="0.988931">Taylor Berg-Kirkpatrick Klein</author>
<affiliation confidence="0.99958">Computer Science Division, University of California at Berkeley</affiliation>
<abstract confidence="0.999596">We present a method for learning bilingual translation lexicons from monolingual corpora. Word types in each language are characterized by purely monolingual features, such as context counts and orthographic substrings. Translations are induced using a generative model based on canonical correlation analysis, which explains the monolingual lexicons in terms of latent matchings. We show that high-precision lexicons can be learned in a variety of language pairs and from a range of corpus types.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Francis R Bach</author>
<author>Michael I Jordan</author>
</authors>
<title>A probabilistic interpretation of canonical correlation analysis.</title>
<date>2006</date>
<tech>Technical report,</tech>
<institution>University of California, Berkeley.</institution>
<contexts>
<context position="8629" citStr="Bach and Jordan (2006)" startWordPosition="1447" endWordPosition="1450">modeling and computational considerations, we make several important modifications, which we describe later. The general form of our algorithm is as follows: Summary of learning algorithm E-step: Find the maximum weighted (partial) bipartite matching m E ✓Vl M-step: Find the best parameters 0 by performing canonical correlation analysis (CCA) M-step Given a matching m, the M-step optimizes logp(m, s, t; 0) with respect to 0, which can be rewritten as max B � logp(si, tj; 0). (1) (i,j)∈m This objective corresponds exactly to maximizing the likelihood of the probabilistic CCA model presented in Bach and Jordan (2006), which proved that the maximum likelihood estimate can be computed by canonical correlation analysis (CCA). Intuitively, CCA finds d-dimensional subspaces US E RdS×d of the source and UT E RdT ×d of the target such that the components of the projections U&gt;S fS(si) and U&gt;T fT(tj) are maximally correlated.4 US and UT can be found by solving an eigenvalue problem (see Hardoon et al. (2003) for details). Then the maximum likelihood estimates are as follows: WS = CSSUSP1/2, WT = CTTUTP1/2, q&apos;S =CSS − WSWS&gt; , and &apos;PT = CTT − WTWT&gt; , where P is a d x d diagonal matrix of the canonical correlations, </context>
</contexts>
<marker>Bach, Jordan, 2006</marker>
<rawString>Francis R. Bach and Michael I. Jordan. 2006. A probabilistic interpretation of canonical correlation analysis. Technical report, University of California, Berkeley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematic of statistical machine translation: Parameter estimation.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="1004" citStr="Brown et al., 1994" startWordPosition="137" endWordPosition="140">olingual features, such as context counts and orthographic substrings. Translations are induced using a generative model based on canonical correlation analysis, which explains the monolingual lexicons in terms of latent matchings. We show that high-precision lexicons can be learned in a variety of language pairs and from a range of corpus types. 1 Introduction Current statistical machine translation systems use parallel corpora to induce translation correspondences, whether those correspondences be at the level of phrases (Koehn, 2004), treelets (Galley et al., 2006), or simply single words (Brown et al., 1994). Although parallel text is plentiful for some language pairs such as English-Chinese or EnglishArabic, it is scarce or even non-existent for most others, such as English-Hindi or French-Japanese. Moreover, parallel text could be scarce for a language pair even if monolingual data is readily available for both languages. In this paper, we consider the problem of learning translations from monolingual sources alone. This task, though clearly more difficult than the standard parallel text approach, can operate on language pairs and in domains where standard approaches cannot. We take as input tw</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1994</marker>
<rawString>Peter F. Brown, Stephen Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1994. The mathematic of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
<author>Kadri Hacioglu</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic tagging of arabic text: From raw text to base phrase chunks.</title>
<date>2004</date>
<booktitle>In HLT-NAACL.</booktitle>
<contexts>
<context position="14116" citStr="Diab et al. (2004)" startWordPosition="2387" endWordPosition="2390">quires a lexicon for evaluation. Following Koehn and Knight (2002), we consider lexicons over only noun word types, although this is not a fundamental limitation of our model. We consider a word type to be a noun if its most common tag is a noun in our monolingual corpus.11 For 7Note that the although the corpora here are derived from a parallel corpus, there are no parallel sentences. 8LDC catalog # 2002E18. 9LDC catalog # 2004E13. 10These corpora contain no parallel sentences. 11We use the Tree Tagger (Schmid, 1994) for all POS tagging except for Arabic, where we use the tagger described in Diab et al. (2004). 774 Precision 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 Recall Figure 3: Example precision/recall curve of our system on EN-ES-P and EN-ES-W settings. See section 6.1. all languages pairs except English-Arabic, we extract evaluation lexicons from the Wiktionary online dictionary. As we discuss in section 7, our extracted lexicons have low coverage, particularly for proper nouns, and thus all performance measures are (sometimes substantially) pessimistic. For EnglishArabic, we extract a lexicon from 100k parallel sentences of UN parallel corpora by running the HMM intersected alignment model (Liang e</context>
</contexts>
<marker>Diab, Hacioglu, Jurafsky, 2004</marker>
<rawString>Mona Diab, Kadri Hacioglu, and Daniel Jurafsky. 2004. Automatic tagging of arabic text: From raw text to base phrase chunks. In HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
</authors>
<title>Compiling bilingual lexicon entries from a non-parallel english-chinese corpus.</title>
<date>1995</date>
<booktitle>In Third Annual Workshop on Very Large Corpora.</booktitle>
<contexts>
<context position="1944" citStr="Fung (1995)" startWordPosition="291" endWordPosition="292">s paper, we consider the problem of learning translations from monolingual sources alone. This task, though clearly more difficult than the standard parallel text approach, can operate on language pairs and in domains where standard approaches cannot. We take as input two monolingual corpora and perhaps some seed translations, and we produce as output a bilingual lexicon, defined as a list of word pairs deemed to be word-level translations. Precision and recall are then measured over these bilingual lexicons. This setting has been considered before, most notably in Koehn and Knight (2002) and Fung (1995), but the current paper is the first to use a probabilistic model and present results across a variety of language pairs and data conditions. In our method, we represent each language as a monolingual lexicon (see figure 2): a list of word types characterized by monolingual feature vectors, such as context counts, orthographic substrings, and so on (section 5). We define a generative model over (1) a source lexicon, (2) a target lexicon, and (3) a matching between them (section 2). Our model is based on canonical correlation analysis (CCA)1 and explains matched word pairs via vectors in a comm</context>
<context position="25071" citStr="Fung, 1995" startWordPosition="4190" endWordPosition="4191">ms. We present the highest confidence system predictions, where the only editing done is to ignore predictions which consist of identical source and target words. D and EN-FR-D, presumably due in part to the lack of orthographic features. However, MCCA still achieved surprising precision at lower recall levels. For instance, at p0.1, MCCA yielded 60.1 and 70.0 on Chinese and Arabic, respectively. Figure 3 shows the highest-confidence outputs in several languages. 6.4 Comparison To Previous Work There has been previous work in extracting translation pairs from non-parallel corpora (Rapp, 1995; Fung, 1995; Koehn and Knight, 2002), but generally not in as extreme a setting as the one considered here. Due to unavailability of data and specificity in experimental conditions and evaluations, it is not possible to perform exact comparisons. How777 (a) Example Non-Cognate Pairs health salud traceability rastreabilidad youth juventud report informe advantages ventajas (b) Interesting Incorrect Pairs liberal partido Kirkhope Gorsel action reacci´on Albanians Bosnia a.m. horas Netherlands Breta˜na Table 4: System analysis on EN-ES-W: (a) non-cognate pairs proposed by our system, (b) hand-selected repre</context>
</contexts>
<marker>Fung, 1995</marker>
<rawString>Pascale Fung. 1995. Compiling bilingual lexicon entries from a non-parallel english-chinese corpus. In Third Annual Workshop on Very Large Corpora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Jonathan Graehl</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
<author>Steve DeNeefe</author>
<author>Wei Wang</author>
<author>Ignacio Thayer</author>
</authors>
<title>Scalable inference and training of context-rich syntactic translation models.</title>
<date>2006</date>
<booktitle>In COLING-ACL.</booktitle>
<contexts>
<context position="959" citStr="Galley et al., 2006" startWordPosition="129" endWordPosition="132"> each language are characterized by purely monolingual features, such as context counts and orthographic substrings. Translations are induced using a generative model based on canonical correlation analysis, which explains the monolingual lexicons in terms of latent matchings. We show that high-precision lexicons can be learned in a variety of language pairs and from a range of corpus types. 1 Introduction Current statistical machine translation systems use parallel corpora to induce translation correspondences, whether those correspondences be at the level of phrases (Koehn, 2004), treelets (Galley et al., 2006), or simply single words (Brown et al., 1994). Although parallel text is plentiful for some language pairs such as English-Chinese or EnglishArabic, it is scarce or even non-existent for most others, such as English-Hindi or French-Japanese. Moreover, parallel text could be scarce for a language pair even if monolingual data is readily available for both languages. In this paper, we consider the problem of learning translations from monolingual sources alone. This task, though clearly more difficult than the standard parallel text approach, can operate on language pairs and in domains where st</context>
</contexts>
<marker>Galley, Graehl, Knight, Marcu, DeNeefe, Wang, Thayer, 2006</marker>
<rawString>Michel Galley, Jonathan Graehl, Kevin Knight, Daniel Marcu, Steve DeNeefe, Wei Wang, and Ignacio Thayer. 2006. Scalable inference and training of context-rich syntactic translation models. In COLING-ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David R Hardoon</author>
<author>Sandor Szedmak</author>
<author>John ShaweTaylor</author>
</authors>
<title>Canonical correlation analysis an overview with application to learning methods.</title>
<date>2003</date>
<tech>Technical Report CSD-TR-03-02,</tech>
<institution>Royal Holloway University of London.</institution>
<contexts>
<context position="3401" citStr="Hardoon et al. (2003)" startWordPosition="533" endWordPosition="536">ges and using a variety of corpora, even in the absence of orthographic features. As might be expected, the task is harder when no seed lexicon is provided, when the languages are strongly divergent, or when the monolingual corpora are from different domains. Nonetheless, even in the more difficult cases, a sizable set of high-precision translations can be extracted. As an example of the performance of the system, in English-Spanish induction with our best feature set, using corpora derived from topically similar but non-parallel sources, the system obtains 89.0% precision at 33% recall. 1See Hardoon et al. (2003) for an overview. 771 Proceedings ofACL-08: HLT, pages 771–779, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics Figure 1: Bilingual lexicon induction: source word types s are listed on the left and target word types t on the right. Dashed lines between nodes indicate translation pairs which are in the matching m. 2 Bilingual Lexicon Induction As input, we are given a monolingual corpus S (a sequence of word tokens) in a source language and a monolingual corpus T in a target language. Let s = (s1, ... , snS) denote nS word types appearing in the source language,</context>
<context position="9019" citStr="Hardoon et al. (2003)" startWordPosition="1515" endWordPosition="1518">s logp(m, s, t; 0) with respect to 0, which can be rewritten as max B � logp(si, tj; 0). (1) (i,j)∈m This objective corresponds exactly to maximizing the likelihood of the probabilistic CCA model presented in Bach and Jordan (2006), which proved that the maximum likelihood estimate can be computed by canonical correlation analysis (CCA). Intuitively, CCA finds d-dimensional subspaces US E RdS×d of the source and UT E RdT ×d of the target such that the components of the projections U&gt;S fS(si) and U&gt;T fT(tj) are maximally correlated.4 US and UT can be found by solving an eigenvalue problem (see Hardoon et al. (2003) for details). Then the maximum likelihood estimates are as follows: WS = CSSUSP1/2, WT = CTTUTP1/2, q&apos;S =CSS − WSWS&gt; , and &apos;PT = CTT − WTWT&gt; , where P is a d x d diagonal matrix of the canonical correlations, CSS = |m |E(i,j)∈m fS(si)fS(si)&gt; is the empirical covariance matrix in the source domain, and CTT is defined analogously. E-step To perform a conventional E-step, we would need to compute the posterior over all matchings, which is #P-complete (Valiant, 1979). On the other hand, hard EM only requires us to compute the best matching under the current model:5 m = argmax log p(m0, s, t; 0). </context>
</contexts>
<marker>Hardoon, Szedmak, ShaweTaylor, 2003</marker>
<rawString>David R. Hardoon, Sandor Szedmak, and John ShaweTaylor. 2003. Canonical correlation analysis an overview with application to learning methods. Technical Report CSD-TR-03-02, Royal Holloway University of London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Kevin Knight</author>
</authors>
<title>Learning a translation lexicon from monolingual corpora.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL Workshop on Unsupervised Lexical Acquisition.</booktitle>
<contexts>
<context position="1928" citStr="Koehn and Knight (2002)" startWordPosition="286" endWordPosition="289">e for both languages. In this paper, we consider the problem of learning translations from monolingual sources alone. This task, though clearly more difficult than the standard parallel text approach, can operate on language pairs and in domains where standard approaches cannot. We take as input two monolingual corpora and perhaps some seed translations, and we produce as output a bilingual lexicon, defined as a list of word pairs deemed to be word-level translations. Precision and recall are then measured over these bilingual lexicons. This setting has been considered before, most notably in Koehn and Knight (2002) and Fung (1995), but the current paper is the first to use a probabilistic model and present results across a variety of language pairs and data conditions. In our method, we represent each language as a monolingual lexicon (see figure 2): a list of word types characterized by monolingual feature vectors, such as context counts, orthographic substrings, and so on (section 5). We define a generative model over (1) a source lexicon, (2) a target lexicon, and (3) a matching between them (section 2). Our model is based on canonical correlation analysis (CCA)1 and explains matched word pairs via v</context>
<context position="13564" citStr="Koehn and Knight (2002)" startWordPosition="2289" endWordPosition="2292">CH-D: English: 1st 50k sentences of Xinhua parallel news corpora;8 Chinese: 2nd 50k sentences. • EN-AR-D: English: 1st 50k sentences of 1994 proceedings of UN parallel corpora;9 Arabic: 2nd 50k sentences. • EN-ES-G: English: 100k sentences of English Gigaword; Spanish: 100k sentences of Spanish Gigaword.10 Note that even when corpora are derived from parallel sources, no explicit use is ever made of document or sentence-level alignments. In particular, our method is robust to permutations of the sentences in the corpora. 4.2 Lexicon Each experiment requires a lexicon for evaluation. Following Koehn and Knight (2002), we consider lexicons over only noun word types, although this is not a fundamental limitation of our model. We consider a word type to be a noun if its most common tag is a noun in our monolingual corpus.11 For 7Note that the although the corpora here are derived from a parallel corpus, there are no parallel sentences. 8LDC catalog # 2002E18. 9LDC catalog # 2004E13. 10These corpora contain no parallel sentences. 11We use the Tree Tagger (Schmid, 1994) for all POS tagging except for Arabic, where we use the tagger described in Diab et al. (2004). 774 Precision 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.</context>
<context position="14867" citStr="Koehn and Knight (2002)" startWordPosition="2513" endWordPosition="2516">N-ES-W settings. See section 6.1. all languages pairs except English-Arabic, we extract evaluation lexicons from the Wiktionary online dictionary. As we discuss in section 7, our extracted lexicons have low coverage, particularly for proper nouns, and thus all performance measures are (sometimes substantially) pessimistic. For EnglishArabic, we extract a lexicon from 100k parallel sentences of UN parallel corpora by running the HMM intersected alignment model (Liang et al., 2008), adding (s, t) to the lexicon if s was aligned to t at least three times and more than any other word. Also, as in Koehn and Knight (2002), we make use of a seed lexicon, which consists of a small, and perhaps incorrect, set of initial translation pairs. We used two methods to derive a seed lexicon. The first is to use the evaluation lexicon Le and select the hundred most common noun word types in the source corpus which have translations in Le. The second method is to heuristically induce, where applicable, a seed lexicon using edit distance, as is done in Koehn and Knight (2002). Section 6.2 compares the performance of these two methods. 4.3 Evaluation We evaluate a proposed lexicon Lp against the evaluation lexicon Le using t</context>
<context position="22208" citStr="Koehn and Knight (2002)" startWordPosition="3740" endWordPosition="3743">raded when the corpora diverged in 776 content, presumably due to context features becoming less informative. However, it is notable that even in the most extreme case of disjoint corpora from different time periods and topics (e.g. EN-ES-G), we are still able to recover lexicons of reasonable accuracy. 6.2 Seed Lexicon Variation All of our experiments so far have exploited a small seed lexicon which has been derived from the evaluation lexicon (see section 4.3). In order to explore system robustness to heuristically chosen seed lexicons, we automatically extracted a seed lexicon similarly to Koehn and Knight (2002): we ran EDITDIST on EN-ES-D and took the top 100 most confident translation pairs. Using this automatically derived seed lexicon, we ran our system on EN-ESD as before, evaluating on the top 2,000 noun word types not included in the automatic lexicon.14 Using the automated seed lexicon, and still evaluating against our Wiktionary lexicon, MCCA-AUTO yielded 91.8 p0.33 (see table 2(b)), indicating that our system can produce lexicons of comparable accuracy with a heuristically chosen seed. We should note that this performance represents no knowledge given to the system in the form of gold seed </context>
<context position="25096" citStr="Koehn and Knight, 2002" startWordPosition="4192" endWordPosition="4195">nt the highest confidence system predictions, where the only editing done is to ignore predictions which consist of identical source and target words. D and EN-FR-D, presumably due in part to the lack of orthographic features. However, MCCA still achieved surprising precision at lower recall levels. For instance, at p0.1, MCCA yielded 60.1 and 70.0 on Chinese and Arabic, respectively. Figure 3 shows the highest-confidence outputs in several languages. 6.4 Comparison To Previous Work There has been previous work in extracting translation pairs from non-parallel corpora (Rapp, 1995; Fung, 1995; Koehn and Knight, 2002), but generally not in as extreme a setting as the one considered here. Due to unavailability of data and specificity in experimental conditions and evaluations, it is not possible to perform exact comparisons. How777 (a) Example Non-Cognate Pairs health salud traceability rastreabilidad youth juventud report informe advantages ventajas (b) Interesting Incorrect Pairs liberal partido Kirkhope Gorsel action reacci´on Albanians Bosnia a.m. horas Netherlands Breta˜na Table 4: System analysis on EN-ES-W: (a) non-cognate pairs proposed by our system, (b) hand-selected representative errors. (a) Ort</context>
<context position="26453" citStr="Koehn and Knight (2002)" startWordPosition="4391" endWordPosition="4394">ad) ogy gia, gi (geology, geologia) (b) Context Feature Source Feat. Closest Context Features party partido,izquierda democrat socialistas, dem´ocratas beijing pekin,kioto Table 5: Hand selected examples of source and target features which are close in canonical space: (a) orthographic feature correspondences, (b) context features. ever, we attempted to run an experiment as similar as possible in setup to Koehn and Knight (2002), using English Gigaword and German Europarl. In this setting, our MCCA system yielded 61.7% accuracy on the 186 most confident predictions compared to 39% reported in Koehn and Knight (2002). 7 Analysis We have presented a novel generative model for bilingual lexicon induction and presented results under a variety of data conditions (section 6.1) and languages (section 6.3) showing that our system can produce accurate lexicons even in highly adverse conditions. In this section, we broadly characterize and analyze the behavior of our system. We manually examined the top 100 errors in the English-Spanish lexicon produced by our system on EN-ES-W. Of the top 100 errors: 21 were correct translations not contained in the Wiktionary lexicon (e.g. pintura to painting), 4 were purely mor</context>
</contexts>
<marker>Koehn, Knight, 2002</marker>
<rawString>Philipp Koehn and Kevin Knight. 2002. Learning a translation lexicon from monolingual corpora. In Proceedings of ACL Workshop on Unsupervised Lexical Acquisition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Pharaoh: A beam search decoder for phrase-based statistical machine translation models.</title>
<date>2004</date>
<booktitle>In Proceedings of AMTA</booktitle>
<contexts>
<context position="927" citStr="Koehn, 2004" startWordPosition="126" endWordPosition="127">l corpora. Word types in each language are characterized by purely monolingual features, such as context counts and orthographic substrings. Translations are induced using a generative model based on canonical correlation analysis, which explains the monolingual lexicons in terms of latent matchings. We show that high-precision lexicons can be learned in a variety of language pairs and from a range of corpus types. 1 Introduction Current statistical machine translation systems use parallel corpora to induce translation correspondences, whether those correspondences be at the level of phrases (Koehn, 2004), treelets (Galley et al., 2006), or simply single words (Brown et al., 1994). Although parallel text is plentiful for some language pairs such as English-Chinese or EnglishArabic, it is scarce or even non-existent for most others, such as English-Hindi or French-Japanese. Moreover, parallel text could be scarce for a language pair even if monolingual data is readily available for both languages. In this paper, we consider the problem of learning translations from monolingual sources alone. This task, though clearly more difficult than the standard parallel text approach, can operate on langua</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>P. Koehn. 2004. Pharaoh: A beam search decoder for phrase-based statistical machine translation models. In Proceedings of AMTA 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In MT Summit.</booktitle>
<contexts>
<context position="12829" citStr="Koehn, 2005" startWordPosition="2177" endWordPosition="2178">: �i,j = A � ��z� i � z� j ��2� (5) where A is a thresholding constant, zz = E(zi,j �fS(si)) = P1/2Us fS(si), and zj* is defined analogously. The increased accuracy may not be an accident: whether two words are translations is perhaps better characterized directly by how close their latent concepts are, whereas log-probability is more sensitive to perturbations in the source and target spaces. • EN-ES-W: 3,851 Wikipedia articles with both English and Spanish bodies (generally not direct translations). • EN-ES-P: 1st 100k sentences of text from the parallel English and Spanish Europarl corpus (Koehn, 2005). • EN-ES(FR)-D: English: 1st 50k sentences of Europarl; Spanish (French): 2nd 50k sentences of Europarl.7 • EN-CH-D: English: 1st 50k sentences of Xinhua parallel news corpora;8 Chinese: 2nd 50k sentences. • EN-AR-D: English: 1st 50k sentences of 1994 proceedings of UN parallel corpora;9 Arabic: 2nd 50k sentences. • EN-ES-G: English: 100k sentences of English Gigaword; Spanish: 100k sentences of Spanish Gigaword.10 Note that even when corpora are derived from parallel sources, no explicit use is ever made of document or sentence-level alignments. In particular, our method is robust to permuta</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In MT Summit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H W Kuhn</author>
</authors>
<title>The Hungarian method for the assignment problem. Naval Research Logistic Quarterly.</title>
<date>1955</date>
<contexts>
<context position="10892" citStr="Kuhn, 1955" startWordPosition="1858" endWordPosition="1859">ection, we describe the data and experimental methodology used throughout this work. which can be loosely viewed as a pointwise mutual information quantity. We can check that the objective logp(m, s, t; B) is equal to the weight of a matching plus some constant C: 4.1 Data log p(m, s, t; B) = � wz,7 + C. (4) Each experiment requires a source and target mono(z,7)Em lingual corpus. We use the following corpora: To find the optimal partial matching, edges with weight wz,7 &lt; 0 are set to zero in the graph and the optimal full matching is computed in 0((nS+nT)3) time using the Hungarian algorithm (Kuhn, 1955). If a zero edge is present in the solution, we remove the involved word types from the matching.6 Bootstrapping Recall that the E-step produces a partial matching of the word types. If too few word types are matched, learning will not progress quickly; if too many are matched, the model will be swamped with noise. We found that it was helpful to explicitly control the number of edges. Thus, we adopt a bootstrapping-style approach that only permits high confidence edges at first, and then slowly permits more over time. In particular, we compute the optimal full matching, but only retain the hi</context>
</contexts>
<marker>Kuhn, 1955</marker>
<rawString>H. W. Kuhn. 1955. The Hungarian method for the assignment problem. Naval Research Logistic Quarterly.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Liang</author>
<author>D Klein</author>
<author>M I Jordan</author>
</authors>
<title>Agreementbased learning.</title>
<date>2008</date>
<booktitle>In NIPS.</booktitle>
<contexts>
<context position="10186" citStr="Liang et al. (2008)" startWordPosition="1730" endWordPosition="1733"> the current model:5 m = argmax log p(m0, s, t; 0). (2) m1 We cast this optimization as a maximum weighted bipartite matching problem as follows. Define the edge weight between source word type i and target word type j to be wi,j = log p(si, tj; 0) (3) − log p(si; 0) − log p(tj; 0), 4Since dS and dT can be quite large in practice and often greater than Iml, we use Cholesky decomposition to rerepresent the feature vectors as Iml-dimensional vectors with the same dot products, which is all that CCA depends on. 5If we wanted softer estimates, we could use the agreementbased learning framework of Liang et al. (2008) to combine two tractable models. 773 are presented for other languages in section 6. In this section, we describe the data and experimental methodology used throughout this work. which can be loosely viewed as a pointwise mutual information quantity. We can check that the objective logp(m, s, t; B) is equal to the weight of a matching plus some constant C: 4.1 Data log p(m, s, t; B) = � wz,7 + C. (4) Each experiment requires a source and target mono(z,7)Em lingual corpus. We use the following corpora: To find the optimal partial matching, edges with weight wz,7 &lt; 0 are set to zero in the grap</context>
<context position="14728" citStr="Liang et al., 2008" startWordPosition="2484" endWordPosition="2487"> (2004). 774 Precision 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 Recall Figure 3: Example precision/recall curve of our system on EN-ES-P and EN-ES-W settings. See section 6.1. all languages pairs except English-Arabic, we extract evaluation lexicons from the Wiktionary online dictionary. As we discuss in section 7, our extracted lexicons have low coverage, particularly for proper nouns, and thus all performance measures are (sometimes substantially) pessimistic. For EnglishArabic, we extract a lexicon from 100k parallel sentences of UN parallel corpora by running the HMM intersected alignment model (Liang et al., 2008), adding (s, t) to the lexicon if s was aligned to t at least three times and more than any other word. Also, as in Koehn and Knight (2002), we make use of a seed lexicon, which consists of a small, and perhaps incorrect, set of initial translation pairs. We used two methods to derive a seed lexicon. The first is to use the evaluation lexicon Le and select the hundred most common noun word types in the source corpus which have translations in Le. The second method is to heuristically induce, where applicable, a seed lexicon using edit distance, as is done in Koehn and Knight (2002). Section 6.</context>
<context position="27611" citStr="Liang et al., 2008" startWordPosition="4572" endWordPosition="4575">tionary lexicon (e.g. pintura to painting), 4 were purely morphological errors (e.g. airport to aeropuertos), 30 were semantically related (e.g. basketball to b´eisbol), 15 were words with strong orthographic similarities (e.g. coast to costas), and 30 were difficult to categorize and fell into none of these categories. Since many of our ‘errors’ actually represent valid translation pairs not contained in our extracted dictionary, we supplemented our evaluation lexicon with one automatically derived from 100k sentences of parallel Europarl data. We ran the intersected HMM wordalignment model (Liang et al., 2008) and added (s, t) to the lexicon if s was aligned to t at least three times and more than any other word. Evaluating against the union of these lexicons yielded 98.0 p0.33, a significant improvement over the 92.3 using only the Wiktionary lexicon. Of the true errors, the most common arose from semantically related words which had strong context feature correlations (see table 4(b)). We also explored the relationships our model learns between features of different languages. We projected each source and target feature into the shared canonical space, and for each projected source feature we exa</context>
</contexts>
<marker>Liang, Klein, Jordan, 2008</marker>
<rawString>P. Liang, D. Klein, and M. I. Jordan. 2008. Agreementbased learning. In NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Rapp</author>
</authors>
<title>Identifying word translation in non-parallel texts.</title>
<date>1995</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="25059" citStr="Rapp, 1995" startWordPosition="4188" endWordPosition="4189">hinese systems. We present the highest confidence system predictions, where the only editing done is to ignore predictions which consist of identical source and target words. D and EN-FR-D, presumably due in part to the lack of orthographic features. However, MCCA still achieved surprising precision at lower recall levels. For instance, at p0.1, MCCA yielded 60.1 and 70.0 on Chinese and Arabic, respectively. Figure 3 shows the highest-confidence outputs in several languages. 6.4 Comparison To Previous Work There has been previous work in extracting translation pairs from non-parallel corpora (Rapp, 1995; Fung, 1995; Koehn and Knight, 2002), but generally not in as extreme a setting as the one considered here. Due to unavailability of data and specificity in experimental conditions and evaluations, it is not possible to perform exact comparisons. How777 (a) Example Non-Cognate Pairs health salud traceability rastreabilidad youth juventud report informe advantages ventajas (b) Interesting Incorrect Pairs liberal partido Kirkhope Gorsel action reacci´on Albanians Bosnia a.m. horas Netherlands Breta˜na Table 4: System analysis on EN-ES-W: (a) non-cognate pairs proposed by our system, (b) hand-se</context>
</contexts>
<marker>Rapp, 1995</marker>
<rawString>Reinhard Rapp. 1995. Identifying word translation in non-parallel texts. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1994</date>
<booktitle>In International Conference on New Methods in Language Processing.</booktitle>
<contexts>
<context position="14021" citStr="Schmid, 1994" startWordPosition="2371" endWordPosition="2372"> is robust to permutations of the sentences in the corpora. 4.2 Lexicon Each experiment requires a lexicon for evaluation. Following Koehn and Knight (2002), we consider lexicons over only noun word types, although this is not a fundamental limitation of our model. We consider a word type to be a noun if its most common tag is a noun in our monolingual corpus.11 For 7Note that the although the corpora here are derived from a parallel corpus, there are no parallel sentences. 8LDC catalog # 2002E18. 9LDC catalog # 2004E13. 10These corpora contain no parallel sentences. 11We use the Tree Tagger (Schmid, 1994) for all POS tagging except for Arabic, where we use the tagger described in Diab et al. (2004). 774 Precision 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 Recall Figure 3: Example precision/recall curve of our system on EN-ES-P and EN-ES-W settings. See section 6.1. all languages pairs except English-Arabic, we extract evaluation lexicons from the Wiktionary online dictionary. As we discuss in section 7, our extracted lexicons have low coverage, particularly for proper nouns, and thus all performance measures are (sometimes substantially) pessimistic. For EnglishArabic, we extract a lexicon from 100k pa</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Helmut Schmid. 1994. Probabilistic part-of-speech tagging using decision trees. In International Conference on New Methods in Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Smith</author>
<author>J Eisner</author>
</authors>
<title>Annealing structural bias in multilingual weighted grammar induction.</title>
<date>2006</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="11688" citStr="Smith and Eisner (2006)" startWordPosition="1993" endWordPosition="1996">rd types. If too few word types are matched, learning will not progress quickly; if too many are matched, the model will be swamped with noise. We found that it was helpful to explicitly control the number of edges. Thus, we adopt a bootstrapping-style approach that only permits high confidence edges at first, and then slowly permits more over time. In particular, we compute the optimal full matching, but only retain the highest weighted edges. As we run EM, we gradually increase the number of edges to retain. In our context, bootstrapping has a similar motivation to the annealing approach of Smith and Eisner (2006), which also tries to alter the space of hidden outputs in the E-step over time to facilitate learning in the M-step, though of course the use of bootstrapping in general is quite widespread (Yarowsky, 1995). 4 Experimental Setup In section 5, we present developmental experiments in English-Spanish lexicon induction; experiments 6Empirically, we obtained much better efficiency and even increased accuracy by replacing these marginal likelihood weights with a simple proxy, the distances between the words’ mean latent concepts: �i,j = A � ��z� i � z� j ��2� (5) where A is a thresholding constant,</context>
</contexts>
<marker>Smith, Eisner, 2006</marker>
<rawString>N. Smith and J. Eisner. 2006. Annealing structural bias in multilingual weighted grammar induction. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L G Valiant</author>
</authors>
<title>The complexity of computing the permanent.</title>
<date>1979</date>
<journal>Theoretical Computer Science,</journal>
<volume>8</volume>
<pages>201</pages>
<contexts>
<context position="9487" citStr="Valiant, 1979" startWordPosition="1601" endWordPosition="1602">rojections U&gt;S fS(si) and U&gt;T fT(tj) are maximally correlated.4 US and UT can be found by solving an eigenvalue problem (see Hardoon et al. (2003) for details). Then the maximum likelihood estimates are as follows: WS = CSSUSP1/2, WT = CTTUTP1/2, q&apos;S =CSS − WSWS&gt; , and &apos;PT = CTT − WTWT&gt; , where P is a d x d diagonal matrix of the canonical correlations, CSS = |m |E(i,j)∈m fS(si)fS(si)&gt; is the empirical covariance matrix in the source domain, and CTT is defined analogously. E-step To perform a conventional E-step, we would need to compute the posterior over all matchings, which is #P-complete (Valiant, 1979). On the other hand, hard EM only requires us to compute the best matching under the current model:5 m = argmax log p(m0, s, t; 0). (2) m1 We cast this optimization as a maximum weighted bipartite matching problem as follows. Define the edge weight between source word type i and target word type j to be wi,j = log p(si, tj; 0) (3) − log p(si; 0) − log p(tj; 0), 4Since dS and dT can be quite large in practice and often greater than Iml, we use Cholesky decomposition to rerepresent the feature vectors as Iml-dimensional vectors with the same dot products, which is all that CCA depends on. 5If we</context>
</contexts>
<marker>Valiant, 1979</marker>
<rawString>L. G. Valiant. 1979. The complexity of computing the permanent. Theoretical Computer Science, 8:189– 201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>Unsupervised word sense disambiguation rivaling supervised methods.</title>
<date>1995</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="11895" citStr="Yarowsky, 1995" startWordPosition="2032" endWordPosition="2033"> Thus, we adopt a bootstrapping-style approach that only permits high confidence edges at first, and then slowly permits more over time. In particular, we compute the optimal full matching, but only retain the highest weighted edges. As we run EM, we gradually increase the number of edges to retain. In our context, bootstrapping has a similar motivation to the annealing approach of Smith and Eisner (2006), which also tries to alter the space of hidden outputs in the E-step over time to facilitate learning in the M-step, though of course the use of bootstrapping in general is quite widespread (Yarowsky, 1995). 4 Experimental Setup In section 5, we present developmental experiments in English-Spanish lexicon induction; experiments 6Empirically, we obtained much better efficiency and even increased accuracy by replacing these marginal likelihood weights with a simple proxy, the distances between the words’ mean latent concepts: �i,j = A � ��z� i � z� j ��2� (5) where A is a thresholding constant, zz = E(zi,j �fS(si)) = P1/2Us fS(si), and zj* is defined analogously. The increased accuracy may not be an accident: whether two words are translations is perhaps better characterized directly by how close </context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>D. Yarowsky. 1995. Unsupervised word sense disambiguation rivaling supervised methods. In ACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>