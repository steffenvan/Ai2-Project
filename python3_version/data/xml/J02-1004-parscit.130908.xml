<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.99441675">
Syllable-Pattern-Based Unknown-
Morpheme Segmentation and Estimation
for Hybrid Part-of-Speech Tagging of
Korean
</title>
<author confidence="0.999289">
Gary Geunbae Lee* Jeongwon Cha†
</author>
<affiliation confidence="0.954452">
Pohang University of Science and Pohang University of Science and
Technology Technology
</affiliation>
<author confidence="0.966451">
Jong-Hyeok Lee‡
</author>
<affiliation confidence="0.8306565">
Pohang University of Science and
Technology
</affiliation>
<bodyText confidence="0.982491769230769">
Most errors in Korean morphological analysis and part-of-speech (POS) tagging are caused
by unknown morphemes. This paper presents a syllable-pattern-based generalized unknown-
morpheme-estimation method with POSTAG (POStech TAGger),1 which is a statistical and
rule-based hybrid POS tagging system. This method of guessing unknown morphemes is based
on a combination ofa morpheme pattern dictionary that encodes general lexical patterns ofKorean
morphemes with a posteriori syllable trigram estimation. The syllable trigrams help to calculate
lexical probabilities of the unknown morphemes and are utilized to search for the best tagging
result. This method can guess the POS tags of unknown morphemes regardless of their numbers
and/or positions in an eojeol (a Korean spacing unit similar to an English word), which is not
possible with other systems for tagging Korean. In a series of experiments using three different
domain corpora, the system achieved a 97% tagging accuracy even though 10% of the morphemes
in the test corpora were unknown. It also achieved very high coverage and accuracy of estimation
for all classes of unknown morphemes.
</bodyText>
<sectionHeader confidence="0.997778" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.998976142857143">
Part-of-speech (POS) tagging involves many difficult problems, such as insufficient
amounts of training data, inherent POS ambiguities, and (most seriously) many types
of unknown words. Unknown words are ubiquitous in any application and cause
major tagging failures in many cases. Since Korean is an agglutinative language, it
presents more serious problems with unknown morphemes than with unknown words
because more than one morpheme can be unknown in a single word and morpheme
segmentation is usually very difficult.
</bodyText>
<footnote confidence="0.877996375">
* NLP Laboratory, Electrical and Computer Engineering Division, Pohang University of Science and
Technology (POSTECH), Pohang, 790-784, Korea. E-mail: gblee@postech.ac.kr.
† NLP Laboratory, Electrical and Computer Engineering Division, Pohang University of Science and
Technology (POSTECH), Pohang, 790-784, Korea. E-mail: himen@postech.ac.kr.
‡ NLP Laboratory, Electrical and Computer Engineering Division, Pohang University of Science and
Technology (POSTECH), Pohang, 790-784, Korea. E-mail: jhlee@postech.ac.kr.
1 The binary code of POSTAG is open to the public for research and evaluation purposes at
http://nlp.postech.ac.kr/. Follow the link OpenResources—&gt;DownLoad.
</footnote>
<note confidence="0.9514495">
© 2002 Association for Computational Linguistics
Computational Linguistics Volume 28, Number 1
</note>
<bodyText confidence="0.999844177777778">
Previous techniques for guessing unknown words mostly utilize the guessing rules
to analyze the word features by looking at leading and trailing characters. Most of them
employ the analysis of trailing characters and other features such as capitalization and
hyphenation (Kupiec 1992; Weischedel et al. 1993). Some of them use more morpho-
logically oriented word features such as suffixes, prefixes, and character lengths (Brill
1995; Voutilainen 1995). The guessing rules are usually handcrafted using knowledge
of morphology but sometimes are acquired automatically using lexicons and corpora
(Brill 1995; Mikheev 1996; Oflazer and T¨ur 1996). Previously developed methods for
guessing unknown morphemes in Korean are not much different from the methods
used for English. Basically, they rely on the rules that reflect knowledge of Korean
morphology and word formation. The usual way of handling unknown morphemes is
to guess all the possible POS tags for an unknown morpheme by checking connectable
functional morphemes in the same eojeol (Kang 1993).2 However, in this way, it is only
possible to guess probable POS tags for a single unknown morpheme when it occurs
at the beginning of an eojeol. Unlike in English, in Korean, more than one unknown
morpheme can appear in a single eojeol because an eojeol can include complex compo-
nents such as Chinese characters, Japanese words, and other foreign words. If an eojeol
contains more than one unknown morpheme or if the unknown morphemes appear
in other than first position in the eojeol, all previous methods fail to efficiently estimate
them. This is the reason why we try to avoid conventional guessing rules using word
morphology features such as those proposed in Mikheev (1996) and Oflazer and T¨ur
(1996).3
In this paper, we propose a syllable-pattern-based generalized unknown-morph-
eme estimation method using a morpheme pattern dictionary that enables us to treat
unknown morphemes in the same way as registered known morphemes, and thereby
to guess them regardless of their numbers or positions in an eojeol. The method for
estimating unknown morphemes using the morpheme pattern dictionary in Korean
needs to be tightly integrated into morphological analysis and POS disambiguation
systems.
POS disambiguation has usually been performed by statistical approaches, mainly
using the hidden Markov model (HMM) in English research communities (Cutting
et al. 1992; Kupiec 1992; Weischedel et al. 1993). These approaches are also domi-
nant for Korean, with slight improvements to accommodate the agglutinative nature
of Korean. For Korean, early HMM tagging was based on eojeols. The eojeol-based
tagging model calculates lexical and transition probabilities with eojeols as a unit; it
suffers from severe data sparseness problems since a single eojeol consists of many
different morphemes (Lee, Choi, and Kim 1993). Later, morpheme-based HMM tag-
ging was tried; such models assign a single tag to a morpheme regardless of the
space in a sentence. Morpheme-based tagging can reduce data sparseness problems
but incurs multiple observation sequences in Viterbi decoding since an eojeol can be
segmented in many different ways. Researchers then tried many ways of reducing
computation due to multiple observation sequences, such as shared word sequences
and virtual words (Kim, Lim, and Seo 1995) and two-ply HMM for morpheme unit
computation but restricted within an eojeol (Kim, Im, and Im 1996). However, since
statistical approaches take neighboring tags into account only within a limited win-
</bodyText>
<footnote confidence="0.9254728">
2 An eojeol is a Korean spacing unit (similar to an English word), which usually consists of one or more
stem morphemes and a series of functional morphemes.
3 Even though Turkish and Finnish are in the same class of agglutinative languages and German also
has very complex morphological structures, in our view word formation is more diverse and complex
in Korean than in these Western languages because of its mix of Oriental and Western culture.
</footnote>
<page confidence="0.993831">
54
</page>
<note confidence="0.93202">
Lee, Cha, and Lee Syllable-Pattern-Based Unknown-Morpheme Estimation
</note>
<bodyText confidence="0.999888045454545">
dow (usually two or three), sometimes the decision fails to cover important linguistic
contexts necessary for POS disambiguation. Also, approaches using only statistical
methods are inappropriate for idiomatic expressions, for which lexical terms need
to be directly referenced. And especially, statistical approaches alone do not suffice
for agglutinative languages, which usually have complex morphological structures.
In agglutinative languages, a word usually consists of one or more stem morphemes
plus a series of functional morphemes; therefore, each morpheme should receive a
POS tag appropriate to its functional role to cope with the complex morphological
phenomena in such languages. Recently, rule-based approaches, which learn symbolic
tagging rules automatically from a corpus, have been reconsidered, to overcome the
limitations of statistical approaches (Brill 1995). Some systems even perform POS tag-
ging as part of a syntactic analysis process (Voutilainen 1995). Following the success
of transformation-based approaches, attempts have been made to use transformation
rules in systems for tagging Korean (Im, Kim, and Im 1996). However, in general,
rule-based approaches alone are not very robust and are not portable enough to be
adjusted to new tagsets or new languages. Also, they usually perform no better than
their statistical counterparts (Brill 1995). To gain portability and robustness and also
to overcome the limited coverage of statistical approaches, we need to somehow com-
bine the two approaches to gain the advantages of each. In this paper, we propose
a hybrid method that combines statistical and rule-based approaches to POS disam-
biguation and can be tightly coupled with generalized unknown-morpheme-guessing
techniques.
</bodyText>
<sectionHeader confidence="0.950447" genericHeader="method">
2. Linguistic Characteristics of Korean
</sectionHeader>
<bodyText confidence="0.996370571428571">
Korean is classified as an agglutinative language. In Korean, an eojeol consists of sev-
eral morphemes that have clear-cut morpheme boundaries. For example, na-neun gam-
gi-e geol-lyeoss-dda ‘I caught a cold’ consists of 3 eojeols and 7 morphemes:4 na(‘I’)/T
+ neun(‘auxiliary particle’)/jS, gam-gi(‘cold’)/MC + e(‘adverb and conjunctive parti-
cle’)/jO, geol-li(‘catch’)/DR + eoss(‘past tense’)/eGS + dda(‘final ending’)/eGE. Below
are the characteristics of Korean that must be considered for morphological-level nat-
ural language processing and POS tagging.
</bodyText>
<listItem confidence="0.998219857142857">
• POS tagging of Korean is usually performed on a morpheme basis rather
than on an eojeol basis. Accordingly, morphological analysis is essential
to POS tagging because morpheme segmentation is much more
important and difficult than POS assignment. Moreover, morphological
analysis should segment eojeols that contain unknown morphemes as
well as known morphemes. Hence, unknown-morpheme handling
should be integrated into the morphological analysis process. Because a
single eojeol can have many possible analyses (e.g., na-neun: na(‘I’)/T +
neun(‘topic marker’)/jS, na(‘sprout’)/DR + neun(‘adnominal’)/eCNMG,
nal(‘fly’)/DI + neun(‘adnominal’)/eCNMG, morpheme segmentation is
inherently ambiguous.
• Korean is a postpositional language with many kinds of noun endings
(particles), verb endings, and prefinal verb endings. It is these functional
morphemes, rather than the order of eojeols, that determine grammatical
</listItem>
<page confidence="0.426615">
4 Here, “+” represents a morpheme boundary in an eojeol and “/” introduces the POS tag symbols (see
</page>
<tableCaption confidence="0.874112">
Table 2).
</tableCaption>
<page confidence="0.988065">
55
</page>
<note confidence="0.400073">
Computational Linguistics Volume 28, Number 1
</note>
<tableCaption confidence="0.75596">
Table 1
Sample distribution of unknown morphemes in
Korean.
</tableCaption>
<table confidence="0.999035333333333">
Tag # morphemes Tag # morphemes
MC 2,888 (29.7%) S 1,358 (14.0%)
MPN 650 (6.7%) B 603 (6.2%)
MPP 235 (2.4%) T 50 (0.5%)
MPC 56 (0.6%) Symbol 10 (0.1%)
MPO 728 (7.5%) Foreign word 3,140 (32.3%)
</table>
<bodyText confidence="0.998562833333333">
relations such as a noun’s syntactic function, a verb’s tense, aspect,
modals, and even modifying relations between eojeols. For example,
ga/jC is a case particle, so the eojeol uri(we)-ga has a subject role due to
the particle ga/jC. Korean has a clear syllable structure within the
morpheme; most nominal content morphemes keep their surface form
when they are combined with functional morphemes.
</bodyText>
<listItem confidence="0.98339512">
• Korean is basically an SOV language but has relatively free word order
compared with English. The weight a, 0 in Equation (1) (Section 4.1)
reflects the fact that transition probability is less important in Korean
than in English. However, Korean does have some word order
constraints: verbs must appear in sentence-final position, and modifiers
must be placed before the element they modify. So some order
constraints must be selectively utilized as contextual information in the
POS tagging process, which is taken well into account in the design of
error correction rules (Section 4.3).
• Complex spelling changes (irregular conjugations) frequently occur
between morphemes when two morphemes combine to form an eojeol.
These spelling changes make it difficult to segment the original
morphemes before the POS tag symbols are assigned.
• The unknown-morpheme problem in Korean differs in some ways from
the unknown-word problem in English. In English, it is easy to identify
unknown words because they occur between spaces. However, in
Korean, since unknown morphemes are hidden in an eojeol, we only
know that morphological analysis failed in that eojeol; pinpointing the
exact unknown morphemes is usually difficult. This is why, unlike in
English, it is not possible to fully guess an unknown morpheme using
only affixes. The distribution of POS tags for unknown morphemes
extracted from a 130,000-morpheme training corpus (9,718 unknown
morphemes) is shown in Table 1. The distribution from even a small
corpus shows that we need to estimate various parts of speech for
unknown morphemes rather than simply guess them as nouns.
</listItem>
<bodyText confidence="0.998755">
Table 2 shows the tagset that was used in the experiments reported in Section 5.
The tagset was selected from hierarchically organized POS tags for Korean. We defined
about 100 different POS tags, which can be used in morphological analysis as well as
in POS tagging. We also designed over 300 morphotactic adjacency symbols to be
used in morpheme connectivity checks for correct morpheme segmentation (to be
explained in the next section). The POS tags are hierarchically organized symbols
</bodyText>
<page confidence="0.998865">
56
</page>
<note confidence="0.900973">
Lee, Cha, and Lee Syllable-Pattern-Based Unknown-Morpheme Estimation
</note>
<tableCaption confidence="0.986797">
Table 2
</tableCaption>
<figure confidence="0.8450602">
A tagset with 41 tags.
Major category Tag Description
Nominal MC common noun
MPN person name
MPC country name
MPP place name
MPO other proper noun
MD bound noun
T pronoun
S numeral
Predicate DR regular verb
DI irregular verb
HR regular adjective
HI irregular adjective
I i-predicative particle
E existential predicate
b auxiliary verb
Modifier G adnoun
B adverb
Particle y predicative particle
jC case particle
jS auxiliary particle
jO adverb and conjunctive particle
Ending eGE final ending
eGS prefinal ending
eCNDI aux conj ending
eCNDC quote conj ending
eCNMM nominal ending
eCNMG adnominal ending
eCNB adverbial ending
eCC conjunctive ending
Affix + prefix
− suffix
Special symbol su unit symbol
s‘ left parenthesis
s’ right parenthesis
s. sentence closer
s- sentence connection
s, sentence comma
sf foreign word
sh Chinese character
so other symbol
Interjection K interjection
57
Computational Linguistics Volume 28, Number 1
</figure>
<bodyText confidence="0.9999495">
that were iteratively refined from the eight major grammatical categories of Korean:
nominal, predicate, modifier, particle, ending, affix, special symbol, and interjection.
For a given morpheme, the acronym of a path name in the symbol hierarchy up to a
certain level is assigned as a POS tag.5 The rest of the detailed hierarchies, which are
related only to morpheme connectivity, are independently assigned as morphotactic
adjacency symbols. Therefore, we can use either full or partial path names as POS tags
in order to adjust the total number of tags. The size of the tagset can thus be adapted
by refining grammatical categories that are more pertinent to a given application. For
example, for text-indexing applications, we refine nominals more than predicates since
index terms are usually nominals in these applications.
</bodyText>
<sectionHeader confidence="0.789375" genericHeader="method">
3. Unknown-Morpheme Segmentation during Morphological Analysis
</sectionHeader>
<bodyText confidence="0.999989882352941">
The agglutinative nature of Korean inevitably requires doing morphological analysis
before POS tagging. Morphological analysis, which segments input texts into morpho-
tactically connectable morphemes and assigns all possible POS tags to each morpheme
by looking them up in a morpheme dictionary, is a basic step in natural language pro-
cessing.
Our morphological analysis follows three general steps (Sproat 1992): morpheme
segmentation, recovering original morphemes from spelling changes, and morpho-
tactic modeling. Input texts are scanned from left to right, character by character,6
to be matched with morphemes in a morpheme dictionary. The morpheme dictio-
nary has a trie structured index for fast matching. It also has an independent entry
for each variant surface form (called allomorph) of the original morpheme so the
original morphemes can easily be reconstructed from spelling changes (see Table 3).
For morphotactic modeling, we used the POS tags and the morphotactic adjacency
symbols in the dictionary. The POS tags provide information about morpheme class,
while the morphotactic adjacency symbols provide information about grammatical
connectivity between morphemes needed to form an eojeol. The full hierarchy of POS
tags and morphotactic adjacency symbols is encoded in the morpheme dictionary
for each morpheme. Besides the morpheme dictionary, to model morphemes’ con-
nectability to one another the system uses an independent morpheme connectivity ta-
ble that encodes all the connectable pairs of morpheme groups using the morphemes’
tags and morphotactic adjacency symbol patterns. After an input eojeol is segmented
by trie indexed dictionary searches, the morphological analysis checks whether each
segmentation is grammatically connectable by looking in the morpheme connectivity
table.
For unknown-morpheme segmentation, we developed a generalized method for
estimating unknown morphemes regardless of their position and number. Using a
morpheme pattern dictionary, our system can look up unknown morphemes exactly
the same way it looks up known registered morphemes. The morpheme pattern dic-
tionary covers all the necessary syllable patterns for unknown morphemes, including
common nouns, proper nouns, adverbs, regular and irregular verbs, regular and ir-
regular adjectives, and special symbols for foreign words. The lexical patterns for
morphemes are collected from previous studies (Kang 1993) where the constraints on
Korean syllable patterns regarding morpheme connectivity are well described. Table 4
shows some sample entries in the morpheme pattern dictionary, where Z, V, “*” are
</bodyText>
<page confidence="0.741207333333333">
5 For example, nominal(M):proper-noun(P):person-name(N) is a three-level path name.
6 The character sequence in na-neun is n, a, n, eu, n.
58
</page>
<note confidence="0.91944">
Lee, Cha, and Lee Syllable-Pattern-Based Unknown-Morpheme Estimation
</note>
<tableCaption confidence="0.987149">
Table 3
</tableCaption>
<bodyText confidence="0.960882428571429">
Examples of morpheme dictionary entries. MCC is a full POS tag that
identifies a common noun consisting of Chinese characters. MCK identifies a
common noun consisting only of Korean characters. DIgeo-la represents a
geo-la irregular verb, and HIl represents an l irregular adjective. Yu represents
that ga-gong has a final consonant (ng). D-ha, H-ha, and D-doe are morphotactic
adjacency symbols for predicate particles. Nominals that have a D-ha as a
morphotactic adjacency symbol can be connected with predicate particles, and
they play the role of a verb or adjective. In verb or adjective, gyu represents a
regular form of an irregular conjugation, bul represents an irregular form of
an irregular conjugation. Eo is a morphotactic adjacency symbol for vowel
harmony when connecting with endings. Chug-yag represents that a particular
verb (or adjective) contains the special contracted ending. “&gt;” is a special
symbol for adjacent direction (“&gt;”= right connection; “&lt;”= left connection).
POS-tag&lt;original form&gt; (Allomorph) [Morphotactic adjacency symbols]
</bodyText>
<equation confidence="0.997559444444445">
MCC&lt;ga-gong&gt; (ga-gong) [yu&gt;D-ha&gt;H-ha&gt;D-doe&gt;]
MCK&lt;geo-leum&gt; (geo-leum) [yu&gt;D-ha&gt;]
DIgeo-la&lt;geon-neo-ga&gt; (geon-neo-ga) [gyu&gt;chug-yag&gt;]
DId&lt;al-a-deud&gt; (al-a-deud) [gyu&gt;]
DId&lt;al-a-deud&gt; (al-a-deul) [bul&gt;eo&gt;]
DIs&lt;heu-li-jeos&gt; (heu-li-jeo) [bul&gt;eo&gt;]
DIs&lt;heu-li-jeos&gt; (heu-li-jeos) [gyu&gt;]
HIl&lt;ga-neul&gt; (ga-neu) [bul&gt;]
HIl&lt;ga-neul&gt; (ga-neul) [gyu&gt;eo&gt;]
</equation>
<tableCaption confidence="0.907221">
Table 4
</tableCaption>
<bodyText confidence="0.451499333333333">
Sample entries in the morpheme pattern dictionary. Symbol meanings are
explained in Table 3.
POS-tag&lt;original form&gt; (Allomorph) [Morphotactic adjacency symbols]
</bodyText>
<equation confidence="0.993451333333333">
HIl&lt;ZV*gal&gt; (ZV*gal) [gyu&gt;eo&gt;]
HIl&lt;ZV*gal&gt; (ZV*ga) [bul&gt;]
HIb&lt;ZV*ZVb&gt; (ZV*u) [bul&gt;]
HIb&lt;ZV*ZVb&gt; (ZV*weo) [chug-yag&gt;]
HIb&lt;ZV*ZVb&gt; (ZV*wa) [chug-yag&gt;]
DIs&lt;ZV*jeos&gt; (ZV*jeos) [gyu&gt;]
DIs&lt;ZV*jeos&gt; (ZV*jeo) [bul&gt;eo&gt;]
DId&lt;ZV*deud&gt; (ZV*deud) [gyu&gt;]
DId&lt;ZV*deud&gt; (ZV*deul) [bul&gt;eo&gt;]
</equation>
<bodyText confidence="0.999913083333333">
metacharacters that indicate a consonant, a vowel, and any number of Korean charac-
ters, respectively. For example, go-ma-weo ‘thanks’, which is a morpheme and an eojeol
at the same time, is matched to (ZV*weo) (shown in Table 4, where it is b, irregular ad-
jective (HIb)) in the morpheme pattern dictionary, which allows the system to recover
its original morpheme form go-mab.
Once the unknown morphemes are identified and recovered using the pattern
dictionary, when checking the unknown morphemes to see if they are connectable,
the system can use the same information about adjacent morphemes in the unknown
morphemes’ eojeol that it would use if they were known morphemes. This is the reason
why our method can be called “generalized” and can identify unknown morphemes
regardless of their position and number in an eojeol. The actual POS estimation is inte-
grated into the POS tagging process that will be described in Section 4.2. The essential
</bodyText>
<page confidence="0.980084">
59
</page>
<figure confidence="0.999329935483871">
Computational Linguistics Volume 28, Number 1
lexical /
transition
probabilities
morpheme
connectivity
table
error-
correcting
rules
syllable
trigram
morphological
analyzer
statistical
POS tagger
post error-
corrector
tagged
sentence
Input
sentence
morpheme
graph
morpheme
graph
morpheme
dictionary
morpheme
pattern
dictionary
</figure>
<figureCaption confidence="0.992423">
Figure 1
</figureCaption>
<bodyText confidence="0.964215">
Statistical and rule-based hybrid architecture for POS tagging of Korean.
idea of the morpheme pattern dictionary is to pre-collect all the possible general lexical
patterns of Korean morphemes and encode each lexical syllable pattern with all the
candidate POS tags. Therefore, the system can assign initial POS tags to each unknown
morpheme simply by matching the syllable patterns in the pattern dictionary. In this
way, unlike previous approaches, ours does not need to incorporate a special rule-
based unknown-morpheme-handling module into its morphological analyzer, and all
the possible POS tags can be assigned to unknown morphemes just as they are to
known morphemes.
</bodyText>
<subsectionHeader confidence="0.493278">
4. A Statistical and Rule-Based Hybrid Tagging Model
</subsectionHeader>
<bodyText confidence="0.999609230769231">
Figure 1 shows a proposed hybrid architecture for POS tagging of Korean with syllable-
pattern-based generalized unknown-morpheme guessing. It has three major compo-
nents: the morphological analyzer with unknown-morpheme handler, the statistical
POS tagger, and the rule-based error corrector. The morphological analyzer segments
the morphemes from input eojeols and reconstructs the original morphemes from
spelling changes by recovering the irregular conjugations. It also assigns all possi-
ble POS tags to each morpheme by consulting a morpheme dictionary. The unknown-
morpheme handler, which is tightly integrated into the morphological analyzer, assigns
initial POS tags to morphemes that are not registered in the dictionary, as explained
in the previous section. The statistical POS tagger runs the Viterbi algorithm (Forney
1973) on the morpheme graph to search for the optimal tag sequence for POS dis-
ambiguation. To remedy the defects of a statistical POS tagger, we developed an a
posteriori error correction mechanism. The error corrector is a rule-based transformer
</bodyText>
<page confidence="0.99327">
60
</page>
<note confidence="0.869462">
Lee, Cha, and Lee Syllable-Pattern-Based Unknown-Morpheme Estimation
</note>
<bodyText confidence="0.9796525">
(Brill 1995), and it corrects mistagged morphemes by consulting lexical patterns and
necessary contextual information.
</bodyText>
<subsectionHeader confidence="0.998317">
4.1 The Statistical POS Tagger
</subsectionHeader>
<bodyText confidence="0.999225888888889">
The statistical POS tagging model takes the morpheme graph (output of the morpho-
logical analyzer) and selects the best morpheme and POS tag sequence7 for sentences
represented in the morpheme graph. The morpheme graph is a compact way of repre-
senting multiple morpheme sequences for a sentence. Each morpheme’s tag is a node
in the graph and its morpheme connectivity is a link. Our statistical tagging model is
modified from the standard bigrams (Cutting et al. 1992) using Viterbi search plus on-
the-fly extra computing of lexical probabilities for unknown morphemes. The equation
used for the statistical tagging model is a modified bigram model with left-to-right
search,
</bodyText>
<equation confidence="0.989545333333333">
T = argmaxT n ti_1)a Pr(ti  |mi)
i=1 Pr(ti 1 p (1)
C Pr(ti) /
</equation>
<bodyText confidence="0.999446833333333">
where T is an optimal tag sequence that maximizes the forward Viterbi scores.
Pr(ti  |ti−1) is a bigram tag transition probability and Pr(ti |)i) is a modified morpheme
Pr(tlexical probability. a and 0 are weights and are set at 0.4 and 0.6, respectively, which
means that lexical probability is more important than transition probability given the
relatively free word order of Korean. This equation was finally selected after extensive
experiments using the following six equations:
</bodyText>
<equation confidence="0.999116058823529">
n
T = argmaxT Pr(ti  |ti−1)Pr(mi  |ti) (2)
i=1
n
T = argmaxT Pr(ti  |ti−1)Pr(mi  |ti) (3)
i=1
n
T = argmaxT Pr(ti  |ti−1)Pr(ti  |mi) (4)
i=1
n
T = argmaxT Pr(ti  |ti−1)Pr(ti  |mi) (5)
i=1
T = argmaxT n Pr(ti  |ti−1)Pr(ti  |mi) (6)
i=1 Pr(ti)
T = argmaxT n ti—1) mi) 1  (7)
i=1 Pr(ti  |ti—
CPrPr(ti) /
</equation>
<bodyText confidence="0.999852">
In the experiments, we used the 10,204-morpheme training corpus from the Kemong
Encyclopedia.8 Table 5 shows the tagging performance of each equation.
Training of the statistical tagging model requires a parameter estimation process
for two different parameters, that is, morpheme lexical probabilities and bigram tag
transition probabilities. Several studies show that using as much tagged material as
</bodyText>
<footnote confidence="0.982171333333333">
7 Because a Korean eojeol can be segmented in many different ways, selecting the best morpheme
segmentation sequence is as important as selecting the best POS sequence in POS tagging.
8 Provided by the Electronics and Telecommunications Research Institute (ETRI).
</footnote>
<page confidence="0.997483">
61
</page>
<note confidence="0.533615">
Computational Linguistics Volume 28, Number 1
</note>
<tableCaption confidence="0.86097875">
Table 5
Tagging performance (all in %) of each equation. The “eojeol” row shows
eojeol-unit tagging performance, and the “morpheme” row shows
morpheme-unit performance.
</tableCaption>
<table confidence="0.776784333333333">
Eq. (2) Eq. (3) Eq. (4) Eq. (5) Eq. (6) Eq. (7) (Eq. (1))
Eojeol 86.80 90.48 89.40 89.62 91.73 92.48
Morpheme 91.32 94.93 94.40 94.48 95.77 96.12
</table>
<bodyText confidence="0.9727745">
possible for training gives much better performance than unsupervised training using
the Baum-Welch reestimation algorithm (Merialdo 1994). We therefore decided to use
supervised training using tagged corpora with relative frequency counts. The three
necessary probabilities can be estimated as in Equations (8)–(10),
</bodyText>
<equation confidence="0.999450111111111">
N(mi, ti)
Pr(ti  |mi) ,: f(ti  |mi) = (8)
N(mi)
N(ti)
Pr(ti) ,: f(ti) = (9)
ENn=1 N(tn)
N(ti−1, ti)
Pr(ti  |ti−1) ,: f(ti  |ti−1) = (10)
N(ti−1)
</equation>
<bodyText confidence="0.999953818181818">
where N(mi, ti) indicates the total number of occurrences of the morpheme mi together
with the specific tag ti, while N(mi) indicates the total number of occurrences of the
morpheme mi in the tagged training corpus. Ntg indicates the total number of POS tags
in the tagset. N(ti−1, ti) and N(ti−1) can be interpreted similarly for two consecutive
tags ti−1 and ti.
A beam search strategy is utilized for high-speed tagging. For each morpheme in
the sentence, the highest probability, Ph, of the tag is recorded. All other tags associated
with the same morpheme must have probabilities greater than Phγ for some constant
beam size y; otherwise, they are discarded. The beam may introduce search errors,
but, in practice, search efficiency can be greatly improved with virtually no loss of
accuracy.
</bodyText>
<subsectionHeader confidence="0.996914">
4.2 Lexical Probability Estimation for Unknown-Morpheme Guessing
</subsectionHeader>
<bodyText confidence="0.98849325">
The lexical probabilities for unknown morphemes cannot be precalculated using Equa-
tion (8) since we assume the unknown morphemes do not appear in the training cor-
pus, so a special on-the-fly estimation method must be applied. We suggest using
syllable trigrams since Korean syllables can play an important role in restricting units
for guessing the POS of a morpheme. The lexical probability Pr(ti|mi)
Pr(ti) for unknown mor-
phemes can be estimated using the frequency of syllable trigram products according
to the formula in (11)–(13) (Nagata 1994),
</bodyText>
<equation confidence="0.870924916666667">
m = e1e2 ... en (11)
Pr(t  |m) ,: Prt(e1  |#, #)Prt(e2  |#, e1)
Pr(t)
n
X 11 Prt(ei  |ei−2,ei−1)
i=3
62
Lee, Cha, and Lee Syllable-Pattern-Based Unknown-Morpheme Estimation
x Pr(#  |en−1,en) (12)
Prt(ei  |ei−2,ei−1) -= ft(ei  |ei−2,ei−1)
+ft(ei  |ei−1)
+ft(ei) (13)
</equation>
<bodyText confidence="0.999885333333333">
where m is a morpheme, e is a syllable, t is a POS tag, “#” is a morpheme boundary
symbol, and ft(ei  |ei−2,ei−1) is a frequency datum for tag t with co-occurrence syllables
ei−2, ei−1, and ei. Trigram probabilities are smoothed by Equation (13) to cope with the
data sparseness problem. For example, Park-jong-man is the name of a person, so it is
an unknown morpheme. The lexical probability that Park-jong-man should be assigned
the tag MPN (person name) is estimated using the following formula:
</bodyText>
<equation confidence="0.999619">
Pr(MPN  |Park − jong − man) -=
PrMPN(Park  |#, #)
Pr(MPN)
x PrMPN(jong  |#, Park)
x PrMPN(man  |Park,jong)
x PrMPN (#  |jong, man) (14)
</equation>
<bodyText confidence="0.999678875">
In Park-jong-man, Park is usually a family name. If the first position of this mor-
pheme is a family name, the probability that MPN is the correct tag becomes higher
than the probability that the other tags are correct. Table 6 shows the distribution of
Pr(Park  |#, #) for each possible tag. In Equation (14), PrMPN(Park  |#, #) represents
the popularity of the tag MPN for the morpheme Park-jong-man.
All the trigrams for Korean syllables were precalculated and stored in the database
and are applied with the candidate tags during the unknown-morpheme POS guessing
and smoothing portion of the statistical tagging process.
</bodyText>
<subsectionHeader confidence="0.99889">
4.3 A Posteriori Error Correction Rules
</subsectionHeader>
<bodyText confidence="0.999771666666667">
Statistical morpheme tagging is widely known to cover only a limited range of con-
textual information. Moreover, it cannot refer to lexical patterns as a context for POS
disambiguation. As mentioned earlier, because Korean eojeols have very complex mor-
phological structures, it is necessary to look at the functional morphemes selectively to
determine the grammatical relations between eojeols. For these reasons, we designed
error correction rules for eojeols to compensate for the estimation and modeling errors
</bodyText>
<tableCaption confidence="0.812257">
Table 6 #, #) for each tag.
</tableCaption>
<table confidence="0.958783444444445">
The distribution of Pr(Park
MC MPN MPC MPP MPO T
No. of “##Park” 125 2081 0 0 8 0
No. of “##” 115,841 25,915 589 1,209 50,671 4,255
Pr(Park I #, #) 0.001 0.080 0.000 0.000 0.000 0.000
B DR DI HR HI
No. of “##Park” 5 17 2 0 9
No. of “##” 9,169 21,119 13,555 2,243 5,217
Pr(Park I #, #) 0.000 0.000 0.000 0.000 0.001
</table>
<page confidence="0.771814">
63
</page>
<note confidence="0.407642">
Computational Linguistics Volume 28, Number 1
</note>
<tableCaption confidence="0.64006">
Table 7
Examples of rule schemata used to extract the error correction rules automatically from the
tagged corpus. The POSTAG system has about 24 rule schemata of this form.
Rule schema Acronym description
</tableCaption>
<footnote confidence="0.958206">
N1FT the tag of the first morpheme (FT) of the next eojeol (N1)
P1LT the tag of the last morpheme (LT) of the previous eojeol (P1)
N2FT the tag of the first morpheme (FT) of the eojeol after the next one (N2)
N3FT the tag of the first morpheme (FT) of the second eojeol after the next one (N3)
P1LM the lexical form of the last morpheme (LM) of the previous eojeol (P1)
P1FM the lexical form of the first morpheme (FM) of the previous eojeol (P1)
N1FM the lexical form of the first morpheme (FM) of the next eojeol (N1)
</footnote>
<bodyText confidence="0.864119">
[current eojeol or morpheme] [rule schemata, referenced morpheme or tag]
—&gt; [corrected eojeol or morpheme]
</bodyText>
<figureCaption confidence="0.806341">
Figure 2
</figureCaption>
<bodyText confidence="0.994456161290322">
Error correction rule format.
of the statistical morpheme tagger. However, designing the error correction rules with
knowledge engineering is tedious and error prone. Instead, we adopted Brill’s ap-
proach (Brill 1995) whereby the error correction rules are learned automatically from a
small amount of tagged corpus. Fortunately, Brill showed that one does not normally
need a large amount of tagged corpus to extract the symbolic tagging rules compared
with statistical tagging. Table 7 shows examples of carefully designed rule schemata
used to extract the error correction rules for Korean, where a rule schema designates
the context of rule applications (i.e., the morpheme position and the lexical/tag deci-
sion in a context eojeol).
The form of the rules that can be automatically learned using the schemata in
Table 7 is shown in Figure 2, where [current eojeol or morpheme] consists of the mor-
pheme (with current tag) sequence in an eojeol, and [corrected eojeol or morpheme]
consists of the morpheme (with corrected tag) sequence in the same eojeol. For exam-
ple, the rule [meog(‘Chinese ink&apos;)/MC + eun/jS][N1FT,MC] —&gt; [meog(‘to eat�)/DR +
eun/eCNMG] says that the current eojeol was statistically tagged as a common noun
(MC) plus auxiliary particle (jS), but if the next eojeol’s (N1) first-position morpheme
tag (FT) is also MC, the eojeol should be tagged as a regular verb (DR) plus ad-
nominal ending (eCNMG). This statistical error is caused by the ambiguity of the
morpheme meog, which has two meanings: ‘Chinese ink’ (noun) and ‘to eat’ (verb).
Since morpheme segmentation is very difficult in Korean, many tagging errors also
arise from the morpheme segmentation errors. Our error correction rules can also cope
with these morpheme segmentation errors by correcting the errors in the whole eojeol
at once. For example, the following rule can correct morpheme segmentation errors:
[jul/MC + i − go/jO][P1LM,] —&gt; [jul − i/DR + go/eCC]. This rule says that the eojeol
jul-i-go is usually segmented as a common noun, jul ‘string, rope’, plus the adverb
and conjunctive particle i-go, but when the morpheme eul appears before the eojeol,
it should be segmented as a regular verb, jul-i ‘shrink’, plus the conjunctive ending
go. This kind of segmentation error correction can greatly enhance the tagging perfor-
mance. The rules are automatically learned by comparing the correctly tagged corpus
with the output of the statistical tagger. The training is leveraged so the error correc-
</bodyText>
<page confidence="0.999184">
64
</page>
<note confidence="0.972266">
Lee, Cha, and Lee Syllable-Pattern-Based Unknown-Morpheme Estimation
</note>
<tableCaption confidence="0.93356">
Table 8
Performance of the statistical tagger (all in %) on
three document sets, using three progressively
degraded versions of the tagger.
</tableCaption>
<table confidence="0.9979856">
Document set Version 1 Version 2 Version 3
Set 1 96.4 89.5 87.1
Set 2 96.0 92.8 89.0
Set 3 96.7 88.7 84.8
Total 96.4 90.3 87.0
</table>
<bodyText confidence="0.6286355">
tion rules are gradually learned as the statistically tagged texts are corrected by the
rules learned so far.
</bodyText>
<sectionHeader confidence="0.997243" genericHeader="method">
5. Experimental Results
</sectionHeader>
<subsectionHeader confidence="0.997055">
5.1 Embedded Performance with Hybrid POS Tagging
</subsectionHeader>
<bodyText confidence="0.999572607142857">
For morphological analysis and POS tagging experiments, we used a 130,000-morph-
eme balanced training corpus for statistical parameter estimation and a 50,000-morph-
eme corpus for learning the a posteriori error correction rules. The training corpus was
collected from various sources such as Internet documents, encyclopedias, newspapers,
and school textbooks.
For test sets, we carefully selected three different document sets, aiming for broad
coverage. The first document set (Set 1: 25,299 morphemes, 1,338 sentences), which
was collected from the Kemong Encyclopedia,9 a hotel reservation dialogue corpus,10
and assorted Internet documents, contains about 10% unknown morphemes. The sec-
ond document set (Set 2: 15,250 morphemes, 574 sentences), which consists solely of
Internet documents from assorted domains, such as broadcasting scripts and news-
papers, contains about 8.5% unknown morphemes. The third document set (Set 3:
20,919 morphemes, 555 sentences), which comes from a standard Korean document
set called KTSET 2.011 including academic articles and electronic newspapers, con-
tains about 14% unknown morphemes (mainly technical jargon). Table 8 shows our
system’s statistical tagging performance for these three document sets, using three
progressively degraded versions of the tagging mechanism. Version 1 is a full version
using the statistical method. Version 2 is a somewhat degraded version that does not
use the system’s unknown-morpheme guessing capability but treats all the segmented
unknown morphemes as nouns (the typical method of estimation). Version 3 is an even
more degraded version that rejects all unknown morphemes as tagging failures; this
version does not even perform unknown-morpheme segmentation during morpho-
logical analysis. This experiment verifies the effectiveness of our unknown-morpheme
segmentation and guessing techniques, as shown by the sharp performance drops
between Versions 1, 2, and 3. As another experiment showed, the automatically ac-
quired a posteriori error correction rules also proved to be useful. In this experiment,
two versions of the hybrid tagger were tested on the three document sets. Version 1
was the full POSTAG system with unknown-morpheme segmentation, guessing, and
</bodyText>
<footnote confidence="0.363044">
9 From the Electronics and Telecommunications Research Institute (ETRI).
10 From Sogang University, Seoul, Korea.
11 From KT (Korea Telecom).
</footnote>
<page confidence="0.99595">
65
</page>
<note confidence="0.605237">
Computational Linguistics Volume 28, Number 1
</note>
<tableCaption confidence="0.54778275">
Table 9
Performance of the hybrid tagger (all
in %) on three document sets, using
two versions of the tagger.
</tableCaption>
<table confidence="0.9896726">
Document set Version 1 Version 2
Set 1 97.2 96.4
Set 2 96.9 96.0
Set 3 97.4 96.7
Total 97.2 96.4
</table>
<tableCaption confidence="0.997528">
Table 10
</tableCaption>
<bodyText confidence="0.680908555555556">
Unknown-morpheme estimation performance
(all in %). Experiments were performed on
three different document sets as before. #UKM
designates the number of unknown morphemes
in each document set and their percentage.
Recall (Rec.) measures the coverage of the
estimation and precision (Pre.) demonstrates its
accuracy.
Document set #UKM Rec. Pre.
Set 1 2,531 (10.0%) 93.9 94.8
Set 2 1,303 (8.5%) 92.9 88.9
Set 3 2,889 (13.8%) 98.0 85.5
Total 6,723 (10.8%) 94.9 89.7
rule-based error correction. Version 2 did not employ a posteriori error correction rules
(the same system as Version 1 in the first experiment). Performance dropped between
Version 1 and Version 2 (see Table 9); however, the drop rates were mild due to the
performance saturation at Version 1, which means that our statistical tagger alone
already achieves state-of-the-art performance for tagging of Korean morphemes.
</bodyText>
<subsectionHeader confidence="0.999852">
5.2 Unknown-Morpheme Segmentation and Guessing Performance
</subsectionHeader>
<bodyText confidence="0.9999304">
To see the independent performance of unknown-morpheme handling more precisely
(explained in Sections 3 and 4.2), we separated the unknown-morpheme performance
from hybrid tagging experiments. Using the same test corpus, we measured the cover-
age and correctness of our unknown-morpheme estimation techniques. Table 10 shows
the results, which were evaluated by the metrics defined as follows:
</bodyText>
<figure confidence="0.529534833333333">
#unknown morphemes detected
Recall = (segmentation performance)
#unknown morphemes
#unknown morphemes correctly estimated
Precision = (guessing performance)
# unknown morphemes detected
</figure>
<bodyText confidence="0.9997494">
When the morphological analyzer meets an unknown morpheme, it is important
to detect first whether it is unknown or not, because sometimes, due to incorrect
segmentation, an unknown morpheme can be incorrectly processed as a known one.
Our system reached an average recall level of 94.9%. Once the unknown morphemes
are detected, the correct POS needs to be estimated. Our system tries to guess the POS
</bodyText>
<page confidence="0.987408">
66
</page>
<note confidence="0.967531">
Lee, Cha, and Lee Syllable-Pattern-Based Unknown-Morpheme Estimation
</note>
<tableCaption confidence="0.882822">
Table 11
Unknown-morpheme estimation performance (all in %) for each POS tag. N/A
means the morpheme with the corresponding tag does not appear in the
corpus. Recall (Rec.) measures the coverage of the estimation, and precision
(Pre.) demonstrates its accuracy.
</tableCaption>
<table confidence="0.999779833333333">
POS tag Set 1 Set 2 Set 3 Total
Rec. Pre. Rec. Pre. Rec. Pre. Rec. Pre.
MC 96.9 95.4 94.5 91.7 93.9 72.5 95.1 86.5
MPN 80.0 86.7 87.4 95.0 100.0 100.0 89.1 93.9
MPC 54.3 73.7 72.7 37.5 N/A N/A 42.3 37.1
MPP 75.2 63.3 86.9 75.0 100.0 100.0 87.4 79.4
MPO 79.4 79.4 94.8 68.3 100.0 93.8 91.4 79.7
B 87.9 100.0 42.9 66.7 100.0 100.0 76.9 88.9
T N/A N/A 100.0 100.0 N/A N/A 100.0 100.0
S 99.8 100.0 99.0 100.0 100.0 100.0 99.6 100.0
Foreign word 100.0 100.0 100.0 100.0 100.0 100.0 100.0 100.0
Special symbol 100.0 100.0 N/A N/A 100.0 100.0 100.0 100.0
</table>
<bodyText confidence="0.9995311875">
of every open class item including common nouns, proper nouns, pronouns, numbers,
adverbs, and others.12 The average precision of 89.7% reflects very accurate guessing
considering the range of POSs that need to be estimated. Table 11 shows the system’s
unknown-morpheme guessing performance for each POS tag.
To show the pattern dictionary’s utility, we conducted another experiment in which
we gradually reduced the morpheme dictionary size to see the smooth hybrid tagging
performance (same as in Table 9) drops. As the morpheme dictionary gets smaller,
POSTAG becomes more dependent on the morpheme pattern dictionary and also on
the unknown-morpheme estimation process. From the full dictionary (with 65,000
nouns), we randomly deleted 5,000 nouns step by step for this series of experiments.
(We deleted only nouns because noun estimation is the best arena for showing the sys-
tem’s unknown-morpheme estimation power.) Figure 3 shows the results. Even if the
POSTAG system relies heavily on unknown-morpheme estimation instead of on more
accurate dictionary lookups, the performance drop is very slow. This result explains
why POSTAG can be used on open domain materials such as Internet documents even
when only a small morpheme dictionary is available.
</bodyText>
<sectionHeader confidence="0.99765" genericHeader="conclusions">
6. Conclusion
</sectionHeader>
<bodyText confidence="0.999638625">
This paper presents a pattern-dictionary-based unknown-morpheme estimation method
for generalized and powerful unknown-morpheme segmentation and guessing for a
hybrid POS tagging system. Generalized unknown-morpheme handling is a new and
powerful idea that adopts a morpheme pattern dictionary and syllable-based lexical
probability estimation. The morpheme pattern dictionary enables the system to seg-
ment unknown morphemes in the same way as registered morphemes without any
separate rules for Korean, and thereby to handle them regardless of their numbers
or positions in an eojeol. The paper also presents an error-corrective statistical and
</bodyText>
<footnote confidence="0.97317675">
12 Pronouns, numbers, and adverbs may be considered as closed classes. However, in real-world corpora,
we frequently find unexpectedly coined terms in these classes since Korean word formation is affected
by very diverse sources such as foreign words, old Chinese words, archaic pure-Korean words, and so
on.
</footnote>
<page confidence="0.997348">
67
</page>
<figure confidence="0.986921">
Computational Linguistics Volume 28, Number 1
0 2 4 6 8 10 12
</figure>
<figureCaption confidence="0.960338">
Figure 3
</figureCaption>
<bodyText confidence="0.9673597">
Hybrid tagging performance change (all in %), showing the utility of the pattern dictionary.
Experiments were performed on three different document sets as before. The x-axis designates
the number of deletion steps whereby the morpheme dictionary was decreased (by 5,000s)
from its full size of 65,000 nouns (Step 0) to 5,000 nouns (Step 12).
rule-based hybrid POS tagging method that exhibits many novel features such as an
experiment-based statistical model for Korean, rule-based error correction, and hier-
archically expandable tagsets. The POSTAG system was developed to test these novel
ideas, especially for agglutinative languages such as Korean. (Japanese, being similar
to Korean in linguistic characteristics, will be a good target for testing these ideas.)
Unlike previous systems, POSTAG is a hybrid tagging system; such a system has never
been tried before, but it turns out to be most suitable for agglutinative languages such
as Korean. POSTAG mainly applies a state-of-the-art HMM tagger for morphemes
but considers multiple observations in the Viterbi score calculation. Because of the
complexity of the morpheme sequence in a Korean eojeol, a morpheme-based HMM’s
tagging accuracy is relatively low for Korean, compared with its accuracy for English.
POSTAG compensates extremely well for the limitations of HMMs by rule-based error
correction. The error correction rules are automatically learned to selectively correct
HMM tagging errors. Similar hybrid methods have been tried for English, but they
integrate HMM tagging and rule-based tagging at the same level (Tapanainen and
Voutilainen 1994). POSTAG integrates morphological analysis with the generalized
</bodyText>
<page confidence="0.985321">
68
</page>
<figure confidence="0.9883374">
100
98
96
94
92
90
’set1’
’set2’
’set3’
’total’
</figure>
<figureCaption confidence="0.270988">
Lee, Cha, and Lee Syllable-Pattern-Based Unknown-Morpheme Estimation
</figureCaption>
<bodyText confidence="0.999660933333334">
unknown-morpheme segmentation so that unknown morphemes can be processed in
the same manner as registered morphemes during tagging. POSTAG also employs
hierarchical tagsets that are flexible enough to expand/shrink according to the given
application. The hierarchical tagset is a novel idea. Most tagging systems for Korean
have applied flat, fixed tagsets and have suffered from using varying tagsets in various
applications. However, POSTAG’s tagsets, based on the over 100 finely differentiated
POS symbols for Korean are hierarchically organized and are flexibly reorganizable ac-
cording to the application at hand. The hierarchical tagsets can be mapped to any other
existing tagset as long as they are fairly well classified and therefore can encourage cor-
pus sharing in the Korean-tagging community. POSTAG is constantly being improved
through expansion of its morpheme dictionary, pattern dictionary, and tagged cor-
pus for statistical and rule-based learning. Since the generalized unknown-morpheme
handling is integrated into the system, POSTAG proves to be a good tagger for open
domain applications such as Internet indexing, filtering, and summarization, and we
are now developing a Web indexer using POSTAG technology.
</bodyText>
<sectionHeader confidence="0.995348" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99787825">
This project was partly supported by
KOSEF (teukjeongkicho #970-1020-301-3,
1997.9-2000.8) and a Ministry of Education
BK21 program awarded to the Electrical
and Computer Engineering Division of
POSTECH. We would like to thank
JunHyeok Shim for coding the
unknown-morpheme estimation
experiments. An earlier version of this
paper was presented at the 6th Workshop
on Very Large Corpora in Montreal, 15–16
August 1998.
</bodyText>
<sectionHeader confidence="0.994428" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99952834375">
Brill, E. 1995. Transformation-based
error-driven learning and natural
language processing: A case study in
part-of-speech tagging. Computational
Linguistics, 21:543–565.
Cutting, D., J. Kupiec, J. Pedersen, and P.
Sibun. 1992. A practical part-of-speech
tagger. In Proceedings of the 3rd Conference
on Applied Natural Language Processing,
pages 133–140.
Forney, G. 1973. The Viterbi algorithm.
Proceedings of the IEEE, 61:268–278.
Im, H. S., J. D. Kim, and H. C. Im. 1996.
Transformation rule-based tagging
considering Korean characteristics. In
Proceedings of the Spring Conference of the AI
SIG Meeting of the Korean Information Science
Society, pages 3–10. (Written in Korean.)
Kang, S. S. 1993. Korean Morphological
Analysis Using Syllable Information and
Multiple-Word Units. Ph.D. thesis,
Department of Computer Engineering,
Seoul National University. (Written in
Korean.)
Kim, J. D., H. S. Im, and H. C. Im. 1996.
Morpheme-based Korean part-of-speech
tagging model considering eojeol-unit
contexts. In Proceedings of the Spring
Conference of the Korean Cognitive Science
Society, pages 97–106. (Written in Korean.)
Kim, J. H., C. S. Lim, and J. Seo. 1995. An
efficient Korean part-of-speech tagging
using a hidden Markov model. Journal of
the Korean Information Science Society,
22:136–146. (Written in Korean.)
Kupiec, J. 1992. Robust part-of-speech
tagging using a hidden Markov model.
Computer Speech and Language, 6:225–242.
Lee, U. J., K. S. Choi, and G. C. Kim. 1993.
Korean text-tagging system. In Proceedings
of the Spring Conference of the Korean
Information Science Society, pages 805–808.
(Written in Korean.)
Merialdo, B. 1994. Tagging English text with
a probabilistic model. Computational
Linguistics, 20:155–171.
Mikheev, A. 1996. Unsupervised learning of
word-category guessing rules. In
Proceedings of the 34th Annual Meeting of the
Association for the Computational Linguistics,
pages 327–334.
Nagata, M. 1994. A stochastic Japanese
morphological analyzer using a
forward-DP backward-A* N-best search
algorithm. In Proceedings of the 15th
International Conference on Computational
Linguistics, pages 201–207.
Oflazer, K. and G. T¨ur. 1996. Combining
hand-crafted rules and unsupervised
learning in constraint-based
morphological disambiguation. In
Proceedings of the Conference on Empirical
Methods in Natural Language Processing,
pages 69–81.
</reference>
<page confidence="0.966434">
69
</page>
<note confidence="0.363514">
Computational Linguistics Volume 28, Number 1
</note>
<reference confidence="0.999279588235294">
Sproat, R. 1992. Morphology and Computation.
MIT Press, Cambridge, MA.
Tapanainen, P. and A. Voutilainen. 1994.
Tagging accurately—don’t guess if you
know. In Proceedings of the Conference on
Applied Natural Language Processing,
pages 149–156.
Voutilainen, A. 1995. A syntax-based
part-of-speech analyzer. In Proceedings of
the 7th Conference of the European Chapter of
the Association for Computational Linguistics,
pages 157–164.
Weischedel, R., M. Meteer, R. Schwartz, L.
Rawshaw, and J. Ralmucci. 1993. Coping
with ambiguity and unknown words
through probabilistic models.
Computational Linguistics, 19:359–382.
</reference>
<page confidence="0.998482">
70
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.206753">
<title confidence="0.91554725">Unknown- Morpheme Segmentation and Estimation for Hybrid Part-of-Speech Tagging of Korean</title>
<author confidence="0.591022">Geunbae Jeongwon</author>
<affiliation confidence="0.998335666666667">Pohang University of Science and Pohang University of Science and Technology Technology Pohang University of Science and</affiliation>
<abstract confidence="0.953177714285714">Technology Most errors in Korean morphological analysis and part-of-speech (POS) tagging are caused by unknown morphemes. This paper presents a syllable-pattern-based generalized unknownmethod with POSTAG (POStech which is a statistical and rule-based hybrid POS tagging system. This method of guessing unknown morphemes is based on a combination ofa morpheme pattern dictionary that encodes general lexical patterns ofKorean morphemes with a posteriori syllable trigram estimation. The syllable trigrams help to calculate lexical probabilities of the unknown morphemes and are utilized to search for the best tagging result. This method can guess the POS tags of unknown morphemes regardless of their numbers positions in an Korean spacing unit similar to an English word), which is not possible with other systems for tagging Korean. In a series of experiments using three different domain corpora, the system achieved a 97% tagging accuracy even though 10% of the morphemes in the test corpora were unknown. It also achieved very high coverage and accuracy of estimation for all classes of unknown morphemes.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>Transformation-based error-driven learning and natural language processing: A case study in part-of-speech tagging.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<pages>21--543</pages>
<contexts>
<context position="3178" citStr="Brill 1995" startWordPosition="444" endWordPosition="445">on purposes at http://nlp.postech.ac.kr/. Follow the link OpenResources—&gt;DownLoad. © 2002 Association for Computational Linguistics Computational Linguistics Volume 28, Number 1 Previous techniques for guessing unknown words mostly utilize the guessing rules to analyze the word features by looking at leading and trailing characters. Most of them employ the analysis of trailing characters and other features such as capitalization and hyphenation (Kupiec 1992; Weischedel et al. 1993). Some of them use more morphologically oriented word features such as suffixes, prefixes, and character lengths (Brill 1995; Voutilainen 1995). The guessing rules are usually handcrafted using knowledge of morphology but sometimes are acquired automatically using lexicons and corpora (Brill 1995; Mikheev 1996; Oflazer and T¨ur 1996). Previously developed methods for guessing unknown morphemes in Korean are not much different from the methods used for English. Basically, they rely on the rules that reflect knowledge of Korean morphology and word formation. The usual way of handling unknown morphemes is to guess all the possible POS tags for an unknown morpheme by checking connectable functional morphemes in the sam</context>
<context position="7700" citStr="Brill 1995" startWordPosition="1130" endWordPosition="1131">renced. And especially, statistical approaches alone do not suffice for agglutinative languages, which usually have complex morphological structures. In agglutinative languages, a word usually consists of one or more stem morphemes plus a series of functional morphemes; therefore, each morpheme should receive a POS tag appropriate to its functional role to cope with the complex morphological phenomena in such languages. Recently, rule-based approaches, which learn symbolic tagging rules automatically from a corpus, have been reconsidered, to overcome the limitations of statistical approaches (Brill 1995). Some systems even perform POS tagging as part of a syntactic analysis process (Voutilainen 1995). Following the success of transformation-based approaches, attempts have been made to use transformation rules in systems for tagging Korean (Im, Kim, and Im 1996). However, in general, rule-based approaches alone are not very robust and are not portable enough to be adjusted to new tagsets or new languages. Also, they usually perform no better than their statistical counterparts (Brill 1995). To gain portability and robustness and also to overcome the limited coverage of statistical approaches, </context>
<context position="22784" citStr="Brill 1995" startWordPosition="3345" endWordPosition="3346">tionary. The unknownmorpheme handler, which is tightly integrated into the morphological analyzer, assigns initial POS tags to morphemes that are not registered in the dictionary, as explained in the previous section. The statistical POS tagger runs the Viterbi algorithm (Forney 1973) on the morpheme graph to search for the optimal tag sequence for POS disambiguation. To remedy the defects of a statistical POS tagger, we developed an a posteriori error correction mechanism. The error corrector is a rule-based transformer 60 Lee, Cha, and Lee Syllable-Pattern-Based Unknown-Morpheme Estimation (Brill 1995), and it corrects mistagged morphemes by consulting lexical patterns and necessary contextual information. 4.1 The Statistical POS Tagger The statistical POS tagging model takes the morpheme graph (output of the morphological analyzer) and selects the best morpheme and POS tag sequence7 for sentences represented in the morpheme graph. The morpheme graph is a compact way of representing multiple morpheme sequences for a sentence. Each morpheme’s tag is a node in the graph and its morpheme connectivity is a link. Our statistical tagging model is modified from the standard bigrams (Cutting et al.</context>
<context position="30863" citStr="Brill 1995" startWordPosition="4669" endWordPosition="4670">me (FT) of the second eojeol after the next one (N3) P1LM the lexical form of the last morpheme (LM) of the previous eojeol (P1) P1FM the lexical form of the first morpheme (FM) of the previous eojeol (P1) N1FM the lexical form of the first morpheme (FM) of the next eojeol (N1) [current eojeol or morpheme] [rule schemata, referenced morpheme or tag] —&gt; [corrected eojeol or morpheme] Figure 2 Error correction rule format. of the statistical morpheme tagger. However, designing the error correction rules with knowledge engineering is tedious and error prone. Instead, we adopted Brill’s approach (Brill 1995) whereby the error correction rules are learned automatically from a small amount of tagged corpus. Fortunately, Brill showed that one does not normally need a large amount of tagged corpus to extract the symbolic tagging rules compared with statistical tagging. Table 7 shows examples of carefully designed rule schemata used to extract the error correction rules for Korean, where a rule schema designates the context of rule applications (i.e., the morpheme position and the lexical/tag decision in a context eojeol). The form of the rules that can be automatically learned using the schemata in T</context>
</contexts>
<marker>Brill, 1995</marker>
<rawString>Brill, E. 1995. Transformation-based error-driven learning and natural language processing: A case study in part-of-speech tagging. Computational Linguistics, 21:543–565.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Cutting</author>
<author>J Kupiec</author>
<author>J Pedersen</author>
<author>P Sibun</author>
</authors>
<title>A practical part-of-speech tagger.</title>
<date>1992</date>
<booktitle>In Proceedings of the 3rd Conference on Applied Natural Language Processing,</booktitle>
<pages>133--140</pages>
<contexts>
<context position="5168" citStr="Cutting et al. 1992" startWordPosition="750" endWordPosition="753">pattern-based generalized unknown-morpheme estimation method using a morpheme pattern dictionary that enables us to treat unknown morphemes in the same way as registered known morphemes, and thereby to guess them regardless of their numbers or positions in an eojeol. The method for estimating unknown morphemes using the morpheme pattern dictionary in Korean needs to be tightly integrated into morphological analysis and POS disambiguation systems. POS disambiguation has usually been performed by statistical approaches, mainly using the hidden Markov model (HMM) in English research communities (Cutting et al. 1992; Kupiec 1992; Weischedel et al. 1993). These approaches are also dominant for Korean, with slight improvements to accommodate the agglutinative nature of Korean. For Korean, early HMM tagging was based on eojeols. The eojeol-based tagging model calculates lexical and transition probabilities with eojeols as a unit; it suffers from severe data sparseness problems since a single eojeol consists of many different morphemes (Lee, Choi, and Kim 1993). Later, morpheme-based HMM tagging was tried; such models assign a single tag to a morpheme regardless of the space in a sentence. Morpheme-based tag</context>
<context position="23390" citStr="Cutting et al. 1992" startWordPosition="3438" endWordPosition="3441">n (Brill 1995), and it corrects mistagged morphemes by consulting lexical patterns and necessary contextual information. 4.1 The Statistical POS Tagger The statistical POS tagging model takes the morpheme graph (output of the morphological analyzer) and selects the best morpheme and POS tag sequence7 for sentences represented in the morpheme graph. The morpheme graph is a compact way of representing multiple morpheme sequences for a sentence. Each morpheme’s tag is a node in the graph and its morpheme connectivity is a link. Our statistical tagging model is modified from the standard bigrams (Cutting et al. 1992) using Viterbi search plus onthe-fly extra computing of lexical probabilities for unknown morphemes. The equation used for the statistical tagging model is a modified bigram model with left-to-right search, T = argmaxT n ti_1)a Pr(ti |mi) i=1 Pr(ti 1 p (1) C Pr(ti) / where T is an optimal tag sequence that maximizes the forward Viterbi scores. Pr(ti |ti−1) is a bigram tag transition probability and Pr(ti |)i) is a modified morpheme Pr(tlexical probability. a and 0 are weights and are set at 0.4 and 0.6, respectively, which means that lexical probability is more important than transition prob</context>
</contexts>
<marker>Cutting, Kupiec, Pedersen, Sibun, 1992</marker>
<rawString>Cutting, D., J. Kupiec, J. Pedersen, and P. Sibun. 1992. A practical part-of-speech tagger. In Proceedings of the 3rd Conference on Applied Natural Language Processing, pages 133–140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Forney</author>
</authors>
<title>The Viterbi algorithm.</title>
<date>1973</date>
<booktitle>Proceedings of the IEEE,</booktitle>
<pages>61--268</pages>
<contexts>
<context position="22458" citStr="Forney 1973" startWordPosition="3296" endWordPosition="3297">ndler, the statistical POS tagger, and the rule-based error corrector. The morphological analyzer segments the morphemes from input eojeols and reconstructs the original morphemes from spelling changes by recovering the irregular conjugations. It also assigns all possible POS tags to each morpheme by consulting a morpheme dictionary. The unknownmorpheme handler, which is tightly integrated into the morphological analyzer, assigns initial POS tags to morphemes that are not registered in the dictionary, as explained in the previous section. The statistical POS tagger runs the Viterbi algorithm (Forney 1973) on the morpheme graph to search for the optimal tag sequence for POS disambiguation. To remedy the defects of a statistical POS tagger, we developed an a posteriori error correction mechanism. The error corrector is a rule-based transformer 60 Lee, Cha, and Lee Syllable-Pattern-Based Unknown-Morpheme Estimation (Brill 1995), and it corrects mistagged morphemes by consulting lexical patterns and necessary contextual information. 4.1 The Statistical POS Tagger The statistical POS tagging model takes the morpheme graph (output of the morphological analyzer) and selects the best morpheme and POS </context>
</contexts>
<marker>Forney, 1973</marker>
<rawString>Forney, G. 1973. The Viterbi algorithm. Proceedings of the IEEE, 61:268–278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H S Im</author>
<author>J D Kim</author>
<author>H C Im</author>
</authors>
<title>Transformation rule-based tagging considering Korean characteristics.</title>
<date>1996</date>
<booktitle>In Proceedings of the Spring Conference of the AI SIG Meeting of the Korean Information Science Society,</booktitle>
<pages>3--10</pages>
<note>(Written in Korean.)</note>
<marker>Im, Kim, Im, 1996</marker>
<rawString>Im, H. S., J. D. Kim, and H. C. Im. 1996. Transformation rule-based tagging considering Korean characteristics. In Proceedings of the Spring Conference of the AI SIG Meeting of the Korean Information Science Society, pages 3–10. (Written in Korean.)</rawString>
</citation>
<citation valid="true">
<authors>
<author>S S Kang</author>
</authors>
<title>Korean Morphological Analysis Using Syllable Information and Multiple-Word Units.</title>
<date>1993</date>
<tech>Ph.D. thesis,</tech>
<institution>Department of Computer Engineering, Seoul National University.</institution>
<note>(Written in Korean.)</note>
<contexts>
<context position="3798" citStr="Kang 1993" startWordPosition="537" endWordPosition="538">nen 1995). The guessing rules are usually handcrafted using knowledge of morphology but sometimes are acquired automatically using lexicons and corpora (Brill 1995; Mikheev 1996; Oflazer and T¨ur 1996). Previously developed methods for guessing unknown morphemes in Korean are not much different from the methods used for English. Basically, they rely on the rules that reflect knowledge of Korean morphology and word formation. The usual way of handling unknown morphemes is to guess all the possible POS tags for an unknown morpheme by checking connectable functional morphemes in the same eojeol (Kang 1993).2 However, in this way, it is only possible to guess probable POS tags for a single unknown morpheme when it occurs at the beginning of an eojeol. Unlike in English, in Korean, more than one unknown morpheme can appear in a single eojeol because an eojeol can include complex components such as Chinese characters, Japanese words, and other foreign words. If an eojeol contains more than one unknown morpheme or if the unknown morphemes appear in other than first position in the eojeol, all previous methods fail to efficiently estimate them. This is the reason why we try to avoid conventional gue</context>
<context position="17352" citStr="Kang 1993" startWordPosition="2577" endWordPosition="2578">or unknown-morpheme segmentation, we developed a generalized method for estimating unknown morphemes regardless of their position and number. Using a morpheme pattern dictionary, our system can look up unknown morphemes exactly the same way it looks up known registered morphemes. The morpheme pattern dictionary covers all the necessary syllable patterns for unknown morphemes, including common nouns, proper nouns, adverbs, regular and irregular verbs, regular and irregular adjectives, and special symbols for foreign words. The lexical patterns for morphemes are collected from previous studies (Kang 1993) where the constraints on Korean syllable patterns regarding morpheme connectivity are well described. Table 4 shows some sample entries in the morpheme pattern dictionary, where Z, V, “*” are 5 For example, nominal(M):proper-noun(P):person-name(N) is a three-level path name. 6 The character sequence in na-neun is n, a, n, eu, n. 58 Lee, Cha, and Lee Syllable-Pattern-Based Unknown-Morpheme Estimation Table 3 Examples of morpheme dictionary entries. MCC is a full POS tag that identifies a common noun consisting of Chinese characters. MCK identifies a common noun consisting only of Korean charac</context>
</contexts>
<marker>Kang, 1993</marker>
<rawString>Kang, S. S. 1993. Korean Morphological Analysis Using Syllable Information and Multiple-Word Units. Ph.D. thesis, Department of Computer Engineering, Seoul National University. (Written in Korean.)</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D Kim</author>
<author>H S Im</author>
<author>H C Im</author>
</authors>
<title>Morpheme-based Korean part-of-speech tagging model considering eojeol-unit contexts.</title>
<date>1996</date>
<booktitle>In Proceedings of the Spring Conference of the Korean Cognitive Science Society,</booktitle>
<pages>97--106</pages>
<note>(Written in Korean.)</note>
<marker>Kim, Im, Im, 1996</marker>
<rawString>Kim, J. D., H. S. Im, and H. C. Im. 1996. Morpheme-based Korean part-of-speech tagging model considering eojeol-unit contexts. In Proceedings of the Spring Conference of the Korean Cognitive Science Society, pages 97–106. (Written in Korean.)</rawString>
</citation>
<citation valid="true">
<authors>
<author>J H Kim</author>
<author>C S Lim</author>
<author>J Seo</author>
</authors>
<title>An efficient Korean part-of-speech tagging using a hidden Markov model.</title>
<date>1995</date>
<journal>Journal of the Korean Information Science Society,</journal>
<pages>22--136</pages>
<note>(Written in Korean.)</note>
<marker>Kim, Lim, Seo, 1995</marker>
<rawString>Kim, J. H., C. S. Lim, and J. Seo. 1995. An efficient Korean part-of-speech tagging using a hidden Markov model. Journal of the Korean Information Science Society, 22:136–146. (Written in Korean.)</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kupiec</author>
</authors>
<title>Robust part-of-speech tagging using a hidden Markov model.</title>
<date>1992</date>
<journal>Computer Speech and Language,</journal>
<pages>6--225</pages>
<contexts>
<context position="3029" citStr="Kupiec 1992" startWordPosition="421" endWordPosition="422">Technology (POSTECH), Pohang, 790-784, Korea. E-mail: jhlee@postech.ac.kr. 1 The binary code of POSTAG is open to the public for research and evaluation purposes at http://nlp.postech.ac.kr/. Follow the link OpenResources—&gt;DownLoad. © 2002 Association for Computational Linguistics Computational Linguistics Volume 28, Number 1 Previous techniques for guessing unknown words mostly utilize the guessing rules to analyze the word features by looking at leading and trailing characters. Most of them employ the analysis of trailing characters and other features such as capitalization and hyphenation (Kupiec 1992; Weischedel et al. 1993). Some of them use more morphologically oriented word features such as suffixes, prefixes, and character lengths (Brill 1995; Voutilainen 1995). The guessing rules are usually handcrafted using knowledge of morphology but sometimes are acquired automatically using lexicons and corpora (Brill 1995; Mikheev 1996; Oflazer and T¨ur 1996). Previously developed methods for guessing unknown morphemes in Korean are not much different from the methods used for English. Basically, they rely on the rules that reflect knowledge of Korean morphology and word formation. The usual wa</context>
<context position="5181" citStr="Kupiec 1992" startWordPosition="754" endWordPosition="755">ized unknown-morpheme estimation method using a morpheme pattern dictionary that enables us to treat unknown morphemes in the same way as registered known morphemes, and thereby to guess them regardless of their numbers or positions in an eojeol. The method for estimating unknown morphemes using the morpheme pattern dictionary in Korean needs to be tightly integrated into morphological analysis and POS disambiguation systems. POS disambiguation has usually been performed by statistical approaches, mainly using the hidden Markov model (HMM) in English research communities (Cutting et al. 1992; Kupiec 1992; Weischedel et al. 1993). These approaches are also dominant for Korean, with slight improvements to accommodate the agglutinative nature of Korean. For Korean, early HMM tagging was based on eojeols. The eojeol-based tagging model calculates lexical and transition probabilities with eojeols as a unit; it suffers from severe data sparseness problems since a single eojeol consists of many different morphemes (Lee, Choi, and Kim 1993). Later, morpheme-based HMM tagging was tried; such models assign a single tag to a morpheme regardless of the space in a sentence. Morpheme-based tagging can redu</context>
</contexts>
<marker>Kupiec, 1992</marker>
<rawString>Kupiec, J. 1992. Robust part-of-speech tagging using a hidden Markov model. Computer Speech and Language, 6:225–242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U J Lee</author>
<author>K S Choi</author>
<author>G C Kim</author>
</authors>
<title>Korean text-tagging system.</title>
<date>1993</date>
<booktitle>In Proceedings of the Spring Conference of the Korean Information Science Society,</booktitle>
<pages>805--808</pages>
<note>(Written in Korean.)</note>
<marker>Lee, Choi, Kim, 1993</marker>
<rawString>Lee, U. J., K. S. Choi, and G. C. Kim. 1993. Korean text-tagging system. In Proceedings of the Spring Conference of the Korean Information Science Society, pages 805–808. (Written in Korean.)</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Merialdo</author>
</authors>
<title>Tagging English text with a probabilistic model.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<pages>20--155</pages>
<contexts>
<context position="25615" citStr="Merialdo 1994" startWordPosition="3793" endWordPosition="3794">st POS sequence in POS tagging. 8 Provided by the Electronics and Telecommunications Research Institute (ETRI). 61 Computational Linguistics Volume 28, Number 1 Table 5 Tagging performance (all in %) of each equation. The “eojeol” row shows eojeol-unit tagging performance, and the “morpheme” row shows morpheme-unit performance. Eq. (2) Eq. (3) Eq. (4) Eq. (5) Eq. (6) Eq. (7) (Eq. (1)) Eojeol 86.80 90.48 89.40 89.62 91.73 92.48 Morpheme 91.32 94.93 94.40 94.48 95.77 96.12 possible for training gives much better performance than unsupervised training using the Baum-Welch reestimation algorithm (Merialdo 1994). We therefore decided to use supervised training using tagged corpora with relative frequency counts. The three necessary probabilities can be estimated as in Equations (8)–(10), N(mi, ti) Pr(ti |mi) ,: f(ti |mi) = (8) N(mi) N(ti) Pr(ti) ,: f(ti) = (9) ENn=1 N(tn) N(ti−1, ti) Pr(ti |ti−1) ,: f(ti |ti−1) = (10) N(ti−1) where N(mi, ti) indicates the total number of occurrences of the morpheme mi together with the specific tag ti, while N(mi) indicates the total number of occurrences of the morpheme mi in the tagged training corpus. Ntg indicates the total number of POS tags in the tagset. N(ti−</context>
</contexts>
<marker>Merialdo, 1994</marker>
<rawString>Merialdo, B. 1994. Tagging English text with a probabilistic model. Computational Linguistics, 20:155–171.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Mikheev</author>
</authors>
<title>Unsupervised learning of word-category guessing rules.</title>
<date>1996</date>
<booktitle>In Proceedings of the 34th Annual Meeting of the Association for the Computational Linguistics,</booktitle>
<pages>327--334</pages>
<contexts>
<context position="3365" citStr="Mikheev 1996" startWordPosition="469" endWordPosition="470">s techniques for guessing unknown words mostly utilize the guessing rules to analyze the word features by looking at leading and trailing characters. Most of them employ the analysis of trailing characters and other features such as capitalization and hyphenation (Kupiec 1992; Weischedel et al. 1993). Some of them use more morphologically oriented word features such as suffixes, prefixes, and character lengths (Brill 1995; Voutilainen 1995). The guessing rules are usually handcrafted using knowledge of morphology but sometimes are acquired automatically using lexicons and corpora (Brill 1995; Mikheev 1996; Oflazer and T¨ur 1996). Previously developed methods for guessing unknown morphemes in Korean are not much different from the methods used for English. Basically, they rely on the rules that reflect knowledge of Korean morphology and word formation. The usual way of handling unknown morphemes is to guess all the possible POS tags for an unknown morpheme by checking connectable functional morphemes in the same eojeol (Kang 1993).2 However, in this way, it is only possible to guess probable POS tags for a single unknown morpheme when it occurs at the beginning of an eojeol. Unlike in English, </context>
</contexts>
<marker>Mikheev, 1996</marker>
<rawString>Mikheev, A. 1996. Unsupervised learning of word-category guessing rules. In Proceedings of the 34th Annual Meeting of the Association for the Computational Linguistics, pages 327–334.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Nagata</author>
</authors>
<title>A stochastic Japanese morphological analyzer using a forward-DP backward-A* N-best search algorithm.</title>
<date>1994</date>
<booktitle>In Proceedings of the 15th International Conference on Computational Linguistics,</booktitle>
<pages>201--207</pages>
<contexts>
<context position="27347" citStr="Nagata 1994" startWordPosition="4070" endWordPosition="4071">.2 Lexical Probability Estimation for Unknown-Morpheme Guessing The lexical probabilities for unknown morphemes cannot be precalculated using Equation (8) since we assume the unknown morphemes do not appear in the training corpus, so a special on-the-fly estimation method must be applied. We suggest using syllable trigrams since Korean syllables can play an important role in restricting units for guessing the POS of a morpheme. The lexical probability Pr(ti|mi) Pr(ti) for unknown morphemes can be estimated using the frequency of syllable trigram products according to the formula in (11)–(13) (Nagata 1994), m = e1e2 ... en (11) Pr(t |m) ,: Prt(e1 |#, #)Prt(e2 |#, e1) Pr(t) n X 11 Prt(ei |ei−2,ei−1) i=3 62 Lee, Cha, and Lee Syllable-Pattern-Based Unknown-Morpheme Estimation x Pr(# |en−1,en) (12) Prt(ei |ei−2,ei−1) -= ft(ei |ei−2,ei−1) +ft(ei |ei−1) +ft(ei) (13) where m is a morpheme, e is a syllable, t is a POS tag, “#” is a morpheme boundary symbol, and ft(ei |ei−2,ei−1) is a frequency datum for tag t with co-occurrence syllables ei−2, ei−1, and ei. Trigram probabilities are smoothed by Equation (13) to cope with the data sparseness problem. For example, Park-jong-man is the name of a person, s</context>
</contexts>
<marker>Nagata, 1994</marker>
<rawString>Nagata, M. 1994. A stochastic Japanese morphological analyzer using a forward-DP backward-A* N-best search algorithm. In Proceedings of the 15th International Conference on Computational Linguistics, pages 201–207.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Oflazer</author>
<author>G T¨ur</author>
</authors>
<title>Combining hand-crafted rules and unsupervised learning in constraint-based morphological disambiguation.</title>
<date>1996</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>69--81</pages>
<marker>Oflazer, T¨ur, 1996</marker>
<rawString>Oflazer, K. and G. T¨ur. 1996. Combining hand-crafted rules and unsupervised learning in constraint-based morphological disambiguation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 69–81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Sproat</author>
</authors>
<title>Morphology and Computation.</title>
<date>1992</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="15345" citStr="Sproat 1992" startWordPosition="2288" endWordPosition="2289">le, for text-indexing applications, we refine nominals more than predicates since index terms are usually nominals in these applications. 3. Unknown-Morpheme Segmentation during Morphological Analysis The agglutinative nature of Korean inevitably requires doing morphological analysis before POS tagging. Morphological analysis, which segments input texts into morphotactically connectable morphemes and assigns all possible POS tags to each morpheme by looking them up in a morpheme dictionary, is a basic step in natural language processing. Our morphological analysis follows three general steps (Sproat 1992): morpheme segmentation, recovering original morphemes from spelling changes, and morphotactic modeling. Input texts are scanned from left to right, character by character,6 to be matched with morphemes in a morpheme dictionary. The morpheme dictionary has a trie structured index for fast matching. It also has an independent entry for each variant surface form (called allomorph) of the original morpheme so the original morphemes can easily be reconstructed from spelling changes (see Table 3). For morphotactic modeling, we used the POS tags and the morphotactic adjacency symbols in the dictiona</context>
</contexts>
<marker>Sproat, 1992</marker>
<rawString>Sproat, R. 1992. Morphology and Computation. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Tapanainen</author>
<author>A Voutilainen</author>
</authors>
<title>Tagging accurately—don’t guess if you know.</title>
<date>1994</date>
<booktitle>In Proceedings of the Conference on Applied Natural Language Processing,</booktitle>
<pages>149--156</pages>
<contexts>
<context position="43030" citStr="Tapanainen and Voutilainen 1994" startWordPosition="6540" endWordPosition="6543">-the-art HMM tagger for morphemes but considers multiple observations in the Viterbi score calculation. Because of the complexity of the morpheme sequence in a Korean eojeol, a morpheme-based HMM’s tagging accuracy is relatively low for Korean, compared with its accuracy for English. POSTAG compensates extremely well for the limitations of HMMs by rule-based error correction. The error correction rules are automatically learned to selectively correct HMM tagging errors. Similar hybrid methods have been tried for English, but they integrate HMM tagging and rule-based tagging at the same level (Tapanainen and Voutilainen 1994). POSTAG integrates morphological analysis with the generalized 68 100 98 96 94 92 90 ’set1’ ’set2’ ’set3’ ’total’ Lee, Cha, and Lee Syllable-Pattern-Based Unknown-Morpheme Estimation unknown-morpheme segmentation so that unknown morphemes can be processed in the same manner as registered morphemes during tagging. POSTAG also employs hierarchical tagsets that are flexible enough to expand/shrink according to the given application. The hierarchical tagset is a novel idea. Most tagging systems for Korean have applied flat, fixed tagsets and have suffered from using varying tagsets in various app</context>
</contexts>
<marker>Tapanainen, Voutilainen, 1994</marker>
<rawString>Tapanainen, P. and A. Voutilainen. 1994. Tagging accurately—don’t guess if you know. In Proceedings of the Conference on Applied Natural Language Processing, pages 149–156.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Voutilainen</author>
</authors>
<title>A syntax-based part-of-speech analyzer.</title>
<date>1995</date>
<booktitle>In Proceedings of the 7th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>157--164</pages>
<contexts>
<context position="3197" citStr="Voutilainen 1995" startWordPosition="446" endWordPosition="447">at http://nlp.postech.ac.kr/. Follow the link OpenResources—&gt;DownLoad. © 2002 Association for Computational Linguistics Computational Linguistics Volume 28, Number 1 Previous techniques for guessing unknown words mostly utilize the guessing rules to analyze the word features by looking at leading and trailing characters. Most of them employ the analysis of trailing characters and other features such as capitalization and hyphenation (Kupiec 1992; Weischedel et al. 1993). Some of them use more morphologically oriented word features such as suffixes, prefixes, and character lengths (Brill 1995; Voutilainen 1995). The guessing rules are usually handcrafted using knowledge of morphology but sometimes are acquired automatically using lexicons and corpora (Brill 1995; Mikheev 1996; Oflazer and T¨ur 1996). Previously developed methods for guessing unknown morphemes in Korean are not much different from the methods used for English. Basically, they rely on the rules that reflect knowledge of Korean morphology and word formation. The usual way of handling unknown morphemes is to guess all the possible POS tags for an unknown morpheme by checking connectable functional morphemes in the same eojeol (Kang 1993</context>
<context position="7798" citStr="Voutilainen 1995" startWordPosition="1146" endWordPosition="1147">ges, which usually have complex morphological structures. In agglutinative languages, a word usually consists of one or more stem morphemes plus a series of functional morphemes; therefore, each morpheme should receive a POS tag appropriate to its functional role to cope with the complex morphological phenomena in such languages. Recently, rule-based approaches, which learn symbolic tagging rules automatically from a corpus, have been reconsidered, to overcome the limitations of statistical approaches (Brill 1995). Some systems even perform POS tagging as part of a syntactic analysis process (Voutilainen 1995). Following the success of transformation-based approaches, attempts have been made to use transformation rules in systems for tagging Korean (Im, Kim, and Im 1996). However, in general, rule-based approaches alone are not very robust and are not portable enough to be adjusted to new tagsets or new languages. Also, they usually perform no better than their statistical counterparts (Brill 1995). To gain portability and robustness and also to overcome the limited coverage of statistical approaches, we need to somehow combine the two approaches to gain the advantages of each. In this paper, we pr</context>
</contexts>
<marker>Voutilainen, 1995</marker>
<rawString>Voutilainen, A. 1995. A syntax-based part-of-speech analyzer. In Proceedings of the 7th Conference of the European Chapter of the Association for Computational Linguistics, pages 157–164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Weischedel</author>
<author>M Meteer</author>
<author>R Schwartz</author>
<author>L Rawshaw</author>
<author>J Ralmucci</author>
</authors>
<title>Coping with ambiguity and unknown words through probabilistic models.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--359</pages>
<contexts>
<context position="3054" citStr="Weischedel et al. 1993" startWordPosition="423" endWordPosition="426">OSTECH), Pohang, 790-784, Korea. E-mail: jhlee@postech.ac.kr. 1 The binary code of POSTAG is open to the public for research and evaluation purposes at http://nlp.postech.ac.kr/. Follow the link OpenResources—&gt;DownLoad. © 2002 Association for Computational Linguistics Computational Linguistics Volume 28, Number 1 Previous techniques for guessing unknown words mostly utilize the guessing rules to analyze the word features by looking at leading and trailing characters. Most of them employ the analysis of trailing characters and other features such as capitalization and hyphenation (Kupiec 1992; Weischedel et al. 1993). Some of them use more morphologically oriented word features such as suffixes, prefixes, and character lengths (Brill 1995; Voutilainen 1995). The guessing rules are usually handcrafted using knowledge of morphology but sometimes are acquired automatically using lexicons and corpora (Brill 1995; Mikheev 1996; Oflazer and T¨ur 1996). Previously developed methods for guessing unknown morphemes in Korean are not much different from the methods used for English. Basically, they rely on the rules that reflect knowledge of Korean morphology and word formation. The usual way of handling unknown mor</context>
<context position="5206" citStr="Weischedel et al. 1993" startWordPosition="756" endWordPosition="759">morpheme estimation method using a morpheme pattern dictionary that enables us to treat unknown morphemes in the same way as registered known morphemes, and thereby to guess them regardless of their numbers or positions in an eojeol. The method for estimating unknown morphemes using the morpheme pattern dictionary in Korean needs to be tightly integrated into morphological analysis and POS disambiguation systems. POS disambiguation has usually been performed by statistical approaches, mainly using the hidden Markov model (HMM) in English research communities (Cutting et al. 1992; Kupiec 1992; Weischedel et al. 1993). These approaches are also dominant for Korean, with slight improvements to accommodate the agglutinative nature of Korean. For Korean, early HMM tagging was based on eojeols. The eojeol-based tagging model calculates lexical and transition probabilities with eojeols as a unit; it suffers from severe data sparseness problems since a single eojeol consists of many different morphemes (Lee, Choi, and Kim 1993). Later, morpheme-based HMM tagging was tried; such models assign a single tag to a morpheme regardless of the space in a sentence. Morpheme-based tagging can reduce data sparseness proble</context>
</contexts>
<marker>Weischedel, Meteer, Schwartz, Rawshaw, Ralmucci, 1993</marker>
<rawString>Weischedel, R., M. Meteer, R. Schwartz, L. Rawshaw, and J. Ralmucci. 1993. Coping with ambiguity and unknown words through probabilistic models. Computational Linguistics, 19:359–382.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>