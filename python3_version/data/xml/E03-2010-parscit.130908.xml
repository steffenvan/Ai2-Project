<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.060196">
<title confidence="0.9993335">
An Open Source Environment for Compiling Typed Unification
Grammars into Speech Recognisers
</title>
<author confidence="0.969319">
Manny Rayner, Beth Ann Hockey and John Dowding
</author>
<affiliation confidence="0.9207515">
RIACS, Mail Stop T27A-2
NASA Ames Research Center
</affiliation>
<address confidence="0.95499">
Moffett Field, CA 94035-1000, USA
</address>
<email confidence="0.996203">
fmrayner, bahockey, jdowdingl@riacs.edu
</email>
<sectionHeader confidence="0.995621" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999112">
We present REGULUS, an Open Source
environment which compiles typed uni-
fication grammars into context free
grammar language models compatible
with the Nuance Toolkit. The environ-
ment includes a large general unification
grammar of English and corpus-based
tools for creating efficient domain-
specific recognisers from it. We will
demo applications built using the sys-
tem, including a speech translator and a
command and control system for a sim-
ulated robotic domain, and show how
the development environment can be
used to edit and extend them.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999964130434783">
This demo presents REGULUS, an Open Source
environment that supports efficient compilation of
typed unification grammars into speech recognis-
ers. The basic intent is to provide a set of tools
to support rapid prototyping of spoken dialogue
applications in situations where little or no cor-
pus data exists. The environment has already been
used to build over half a dozen applications with
vocabularies of between 100 and 500 words. We
will be demoing some of them here, along with ex-
amples of how the development environment can
be used to edit and extend them.
The rest of this document is organised as fol-
lows. Section 2 describes the grammar formalism
and the grammar-to-recogniser compiler process.
This includes a tool which allows construction of
domain-specific grammars by corpus-based spe-
cialisation of a large general unification grammar
for English. Section 3 describes the interactive de-
velopment environment. Section 4 describes how
we intend to structure the actual demo. The final
section contains instructions for downloading and
installing REGULUS.
</bodyText>
<sectionHeader confidence="0.972763" genericHeader="method">
2 Compiling Unification Grammars into
Recognisers
</sectionHeader>
<bodyText confidence="0.999954869565218">
The core functionality provided by the REGU-
LUS environment is compilation of typed unifica-
tion grammars into annotated context-free gram-
mar language models expressed in Nuance Gram-
mar Specification Language (GSL) notation (Nu-
ance, 2002). GSL language models can be con-
verted into runnable speech recognisers by invok-
ing the Nuance Toolkit compiler utility, so the net
result is the ability to compile a unification gram-
mar into a speech recogniser.
The REGULUS unification grammar formalism
is closely related to the one used in the SRI Core
Language Engine (CLE) and Gemini systems (Al-
shawi, 1992; Dowding et al., 1993), and it is most
reasonable to compare it with Gemini, which of-
fers a broadly similar range of functionalities. One
important difference relates to the treatment of
semantics. CLE and Gemini support a general
unification-based semantics; REGULUS, however,
does not permit the use of unification when con-
structing semantic representations. Although this
involves a slight loss of expressive power, it of-
fers the very significant advantage of allowing the
</bodyText>
<page confidence="0.99777">
223
</page>
<bodyText confidence="0.9999520625">
semantics of the original grammar to be compiled
into semantic annotations on the target GSL rules.
The resulting recogniser can thus be used as a
stand-alone system, which both recognises spoken
utterances and produces semantic representations
for them. In contrast, recognisers compiled by the
Gemini system only produce word-string output,
which then has to be parsed by a separate process.
The basic algorithm used by REGULUS to com-
pile unification grammars into CFG form is de-
scribed in (Rayner et al., 2001). The central idea is
simply to perform an enumerative expansion of the
unification grammar by non-deterministically in-
stantiating each feature to all of its possible values;
the resulting grammar is then filtered to remove
non-reachable rules. As described in (Rayner et
al., 2001), the efficiency of the naive algorithm can
be greatly improved by adding a pre-processing
step which performs a suitable factoring of the
grammar. The current version of REGULUS fur-
ther refines the naive method by iteratively al-
ternating the expansion and filtering stages, non-
deterministically expanding each feature in turn
and then filtering the result before proceeding to
the next feature. On large grammars, this &amp;quot;iterative
expansion&amp;quot; technique can reduce time and space
requirements of the compilation algorithm by sev-
eral orders of magnitude. Use of iterative expan-
sion has allowed REGULUS successfully to com-
pile several grammars which exceeded resource
bounds for the Gemini compiler (Moore et al.,
1997; Moore, 1998).
</bodyText>
<subsectionHeader confidence="0.999673">
2.1 Using Grammar Specialisation
</subsectionHeader>
<bodyText confidence="0.999938897435897">
Experience with grammar-based spoken dialogue
systems shows that there is usually a substan-
tial overlap between the structures of grammars
for different domains. This is hardly surprising,
since they all ultimately have to model general
facts about the linguistic structure of English and
other natural languages. It is consequently natu-
ral to consider strategies which attempt to exploit
the overlap between domains by building a single,
general grammar valid for a wide variety of ap-
plications. A grammar of this kind will probably
offer more coverage (and hence lower accuracy)
than is desirable for any given specific application.
It is however feasible to address the problem us-
ing corpus-based techniques which extract a spe-
cialised version of the original general grammar.
REGULUS implements a version of the grammar
specialisation scheme which extends the Explana-
tion Based Learning method described in (Rayner
et al., 2002). There is a general unification gram-
mar, loosely based on the Core Language Engine
grammar for English (Pulman, 1992), which has
been developed over the course of about ten indi-
vidual projects. The cun-ent version of the gram-
mar contains 145 unification grammar rules, 465
function word entries, and 72 features. The gram-
mar for each individual domain also includes a
domain-specific content word lexicon, which typ-
ically contains 100 to 500 lexical entries. We have
intentionally used a variety of widely differing do-
mains, including a command and control system
for a simulated mobile robot, a speech enabled
home automation system, a travel planning system
and a medical speech translator.
The semantic representations produced by the
grammar are in a simplified version of the Core
Language Engine&apos;s Quasi Logical Form notation
(van Eijck and Moore, 1992). Thus for example
the representation of &amp;quot;turn on the fan&amp;quot; is
</bodyText>
<equation confidence="0.682424142857143">
[[imp,
form (imperative,
[[turn,
term(pro,you,[]),
term(the_sing,fan,[1),
on]]
1 ]
</equation>
<bodyText confidence="0.986489">
and that for &amp;quot;how long have you had headaches&amp;quot;
is
</bodyText>
<equation confidence="0.778508571428571">
f[whq.
form( [present , perfect ]
[ [have symptom,
term (pro, you, []) ,
term (null, headache, [] ) ] ,
[duration, how long] ]
1 1
</equation>
<bodyText confidence="0.99963">
A grammar built on top of the general grammar
is transformed into a specialised Nuance grammar
in the following processing stages:
</bodyText>
<page confidence="0.990516">
224
</page>
<bodyText confidence="0.984364592592593">
1. The training corpus is converted into a &amp;quot;tree-
bank&amp;quot; of parsed representations. This is done
using a left-corner parser representation of
the grammar.
2. The treebank is used to produce a &amp;quot;raw&amp;quot; spe-
cialised grammar in REGULUS format, us-
ing the EBL algorithm (van Harmelen and
Bundy, 1988; Rayner, 1988). The granularity
of the learned rules is determined by a user-
supplied parameter. This parameter can cur-
rently be set to the following values:
Lexical The learned grammar is completely
&amp;quot;flat&amp;quot;, with each training example pro-
ducing exactly one rule.
NP The learned grammar has two levels,
with only NP nodes between root nodes
and pre-lexical nodes.
NP_PP The learned grammar has three lev-
els, with NP and PP nodes between root
nodes and pre-lexical nodes.
S_NP_PP The learned grammar has four lev-
els, with S, NP and PP nodes between
root nodes and pre-lexical nodes.
3. The &amp;quot;raw&amp;quot; specialised grammar is post-
processed into the final specialised grammar.
The post-processing stage consists of three
steps:
</bodyText>
<listItem confidence="0.990287">
(a) Duplicate rules are merged, keeping the
different training examples as documen-
tation.
(b) Specialised rules are sorted by number
of training examples.
(c) If there are enough training examples
</listItem>
<bodyText confidence="0.848612782608696">
for a rule, it is further constrained to
unify with the the least common gener-
alisation of all the contexts in which it
has occurred. The threshold which de-
termines when this happens is defined
by another user-supplied parameter.
4. The final specialised grammar is compiled
into a Nuance GSL grammar.
For the applications we have so far worked with,
output GSL grammars vary in size from about 500
to about 15000 GSL rules. Compilation times on
a 2GHz PC vary from a few seconds to about 10
minutes, mainly depending on the size of the train-
ing corpus. Word error rates on in-coverage mate-
rial for the resulting recognisers vary from about
5% to about 15%. Interestingly, it appears that
there is no very strong correlation between recog-
nition performance and either vocabulary size or
size of the training corpus, with performance de-
pending rather more heavily on average utterance
length and the types of constructions covered by
the specialised grammar. We are actively investi-
gating these issues at the moment.
</bodyText>
<sectionHeader confidence="0.996451" genericHeader="method">
3 The Development Environment
</sectionHeader>
<bodyText confidence="0.999979071428571">
All the functionalities in the REGULUS environ-
ment are available via a command-line interface,
and also from within a top-loop designed primar-
ily for interactive grammar debugging. In this
mode, the grammar is compiled into an efficient
left-corner parser, using the algorithm of (Moore,
2000), and also into a Definite Clause Grammar
(DCG) form; the advantage of the DCG represen-
tation is that it can often be used to help diagnose
grammar bugs by attempting to parse non-top con-
stituents. Each separate domain-specific grammar
is defined though a config file, which also speci-
fies settings for the various user-defined parame-
ters relevant to the compilation process.
</bodyText>
<sectionHeader confidence="0.650133" genericHeader="method">
4 Structure of the demo
</sectionHeader>
<bodyText confidence="0.999984647058823">
We will demo two recognisers built using REGU-
LUS, one for a command and control application
and one for a medical speech translation applica-
tion. The command and control recogniser is an
extended version of the one for the Personal Satel-
lite Assistant, a speech enabled mobile robot cur-
rently being developed at the NASA Ames Re-
search Center (PSA, 2002). The domain-specific
lexicon contains 313 entries; coverage includes
commands (&amp;quot;go to flight deck&amp;quot;), Y-N and WH-
questions (&amp;quot;has the temperature increased dur-
ing the last five minutes&amp;quot;, &amp;quot;when did you mea-
sure the pressure at storage lockers&amp;quot;), conjunctions
(&amp;quot;what were oxygen and carbon dioxide five min-
utes ago&amp;quot;) and pronouns (&amp;quot;go to crew hatch and
open it&amp;quot;). Word error rates for this application on
in-coverage data are around 10-11%.
</bodyText>
<page confidence="0.996164">
225
</page>
<bodyText confidence="0.999955421052632">
The medical speech translator recogniser is an
extended English-language version of the system
described in (Rayner and Bouillon, 2002). The
domain-specific lexicon for this system contains
607 entries. Coverage includes Y-N and WH-
questions (&amp;quot;does the headache usually start sud-
denly&amp;quot;, &amp;quot;what makes your headache better&amp;quot;) and
elliptical phrases (&amp;quot;insomnia&amp;quot;, &amp;quot;in the left chest&amp;quot;,
&amp;quot;severe&amp;quot;). Although the medical speech applica-
tion has nearly twice as large a vocabulary, recog-
nition performance is in fact noticeably better than
for the command and control application; pre-
liminary results suggest a word error rate on in-
coverage data of around 6-7%.
We will demo speech recognition for each
recogniser, and show how the development envi-
ronment can be used to make rapid changes to cov-
erage by adding lexical entries and/or training ex-
amples.
</bodyText>
<sectionHeader confidence="0.96635" genericHeader="conclusions">
5 Downloading and installation
</sectionHeader>
<bodyText confidence="0.999753">
REGULUS requires the Nuance Toolkit (Nuance,
2002) and SICStus Prolog (Programming Systems
Group, 1995), and runs under Windows 2000 and
NT. As a minimum hardware configuration, we
recommend a 400MHz machine with 256M of
RAM. The whole system, including source code,
documentation and examples, is publicly avail-
able and can used freely under the terms of the
Lesser General Public Licence (LGPL). The cur-
rent release can be obtained as a zip-file by mailing
the authors, or by download from SourceForge at
http://sourceforge.net/projects/leonlp/.
</bodyText>
<sectionHeader confidence="0.998622" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999788545454545">
H. Alshawi, editor. 1992. The Core Language Engine.
MIT Press, Cambridge, Massachusetts.
J. Dowding, M. Gawron, D. Appelt, L. Cherny,
R. Moore, and D. Moran. 1993. Gemini- A nat-
ural language system for spoken language under-
standing. In Proceedings of the Thirty-First Annual
Meeting of the Association for Computational Lin-
guistics.
R. Moore, J. Dowding, H. Bratt, J. Gawron, Y. Gorfu,
and A. Cheyer. 1997. CommandTalk: A spoken-
language interface for battlefield simulations. In
Proceedings of the Fifth Conference on Applied Nat-
ural Language Processing, pages 1-7.
R. Moore. 1998. Using natural language knowledge
sources in speech recognition. In Proceedings of the
NATO Advanced Studies Institute.
R. Moore. 2000. Improved left-corner chart pars-
ing for large context-free grammars. In Proceedings
of the 6th International Workshop on Parsing Tech-
nologies, pages 171-182.
Nuance, 2002. http://www.nuance.com. As of 15
November 2002.
Programming Systems Group, 1995. SICStus Prolog
User&apos;s Manual. Swedish Institute of Computer Sci-
ence, Kista, Sweden.
PSA, 2002. Personal Satellite Assistant (PSA) Project.
http://ic.arc.nasa.gov/ic/projects/psa/. As of 1 Feb
2002.
S.G. Pulman. 1992. Syntactic and semantic process-
ing. In Alshawi (Alshawi, 1992), pages 129-148.
M. Rayner and P. Bouillon. 2002. A phrasebook style
medical speech translator. In Proceedings of the
40th Annual Meeting of the Association for Compu-
tational Linguistics (demo track), Philadelphia, PA.
M. Rayner, J. Dowding, and B.A. Hockey. 2001.
A baseline method for compiling typed unification
grammars into context free language models. In
Proceedings of Eurospeech 2001, pages 729-732,
Aalborg, Denmark.
M. Rayner, B.A. Hockey, and J. Dowding. 2002.
Grammar specialisation meets language modelling.
In Proceedings of the 7th International Conference
on Spoken Language Processing (ICSLP), Denver,
CO.
M. Rayner. 1988. Applying explanation-based gen-
eralization to natural-language processing. In Pro-
ceedings of the International Conference on Fifth
Generation Computer Systems, pages 1267-1274,
Tokyo, Japan.
J. van Eijck and R. Moore. 1992. Semantic rules for
English. In H. Alshawi, editor, The Core Language
Engine, pages 83-116. MIT Press.
T. van Harmelen and A. Bundy. 1988. Explanation-
based generalization = partial evaluation (research
note). Artificial Intelligence, 36:401-412.
</reference>
<page confidence="0.998844">
226
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.488427">
<title confidence="0.997021">An Open Source Environment for Compiling Typed Unification Grammars into Speech Recognisers</title>
<author confidence="0.998835">Manny Rayner</author>
<author confidence="0.998835">Beth Ann Hockey</author>
<author confidence="0.998835">John Dowding</author>
<address confidence="0.506211">RIACS, Mail Stop T27A-2</address>
<affiliation confidence="0.996178">NASA Ames Research Center</affiliation>
<address confidence="0.999788">Moffett Field, CA 94035-1000, USA</address>
<email confidence="0.999913">fmrayner,bahockey,jdowdingl@riacs.edu</email>
<abstract confidence="0.9986135625">present Open Source environment which compiles typed unification grammars into context free grammar language models compatible with the Nuance Toolkit. The environment includes a large general unification grammar of English and corpus-based tools for creating efficient domainspecific recognisers from it. We will demo applications built using the system, including a speech translator and a command and control system for a simulated robotic domain, and show how the development environment can be used to edit and extend them.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>H Alshawi</author>
<author>editor</author>
</authors>
<title>The Core Language Engine.</title>
<date>1992</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<marker>Alshawi, editor, 1992</marker>
<rawString>H. Alshawi, editor. 1992. The Core Language Engine. MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Dowding</author>
<author>M Gawron</author>
<author>D Appelt</author>
<author>L Cherny</author>
<author>R Moore</author>
<author>D Moran</author>
</authors>
<title>Gemini- A natural language system for spoken language understanding.</title>
<date>1993</date>
<booktitle>In Proceedings of the Thirty-First Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2567" citStr="Dowding et al., 1993" startWordPosition="392" endWordPosition="395"> The core functionality provided by the REGULUS environment is compilation of typed unification grammars into annotated context-free grammar language models expressed in Nuance Grammar Specification Language (GSL) notation (Nuance, 2002). GSL language models can be converted into runnable speech recognisers by invoking the Nuance Toolkit compiler utility, so the net result is the ability to compile a unification grammar into a speech recogniser. The REGULUS unification grammar formalism is closely related to the one used in the SRI Core Language Engine (CLE) and Gemini systems (Alshawi, 1992; Dowding et al., 1993), and it is most reasonable to compare it with Gemini, which offers a broadly similar range of functionalities. One important difference relates to the treatment of semantics. CLE and Gemini support a general unification-based semantics; REGULUS, however, does not permit the use of unification when constructing semantic representations. Although this involves a slight loss of expressive power, it offers the very significant advantage of allowing the 223 semantics of the original grammar to be compiled into semantic annotations on the target GSL rules. The resulting recogniser can thus be used </context>
</contexts>
<marker>Dowding, Gawron, Appelt, Cherny, Moore, Moran, 1993</marker>
<rawString>J. Dowding, M. Gawron, D. Appelt, L. Cherny, R. Moore, and D. Moran. 1993. Gemini- A natural language system for spoken language understanding. In Proceedings of the Thirty-First Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Moore</author>
<author>J Dowding</author>
<author>H Bratt</author>
<author>J Gawron</author>
<author>Y Gorfu</author>
<author>A Cheyer</author>
</authors>
<title>CommandTalk: A spokenlanguage interface for battlefield simulations.</title>
<date>1997</date>
<booktitle>In Proceedings of the Fifth Conference on Applied Natural Language Processing,</booktitle>
<pages>1--7</pages>
<contexts>
<context position="4534" citStr="Moore et al., 1997" startWordPosition="697" endWordPosition="700">which performs a suitable factoring of the grammar. The current version of REGULUS further refines the naive method by iteratively alternating the expansion and filtering stages, nondeterministically expanding each feature in turn and then filtering the result before proceeding to the next feature. On large grammars, this &amp;quot;iterative expansion&amp;quot; technique can reduce time and space requirements of the compilation algorithm by several orders of magnitude. Use of iterative expansion has allowed REGULUS successfully to compile several grammars which exceeded resource bounds for the Gemini compiler (Moore et al., 1997; Moore, 1998). 2.1 Using Grammar Specialisation Experience with grammar-based spoken dialogue systems shows that there is usually a substantial overlap between the structures of grammars for different domains. This is hardly surprising, since they all ultimately have to model general facts about the linguistic structure of English and other natural languages. It is consequently natural to consider strategies which attempt to exploit the overlap between domains by building a single, general grammar valid for a wide variety of applications. A grammar of this kind will probably offer more covera</context>
</contexts>
<marker>Moore, Dowding, Bratt, Gawron, Gorfu, Cheyer, 1997</marker>
<rawString>R. Moore, J. Dowding, H. Bratt, J. Gawron, Y. Gorfu, and A. Cheyer. 1997. CommandTalk: A spokenlanguage interface for battlefield simulations. In Proceedings of the Fifth Conference on Applied Natural Language Processing, pages 1-7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Moore</author>
</authors>
<title>Using natural language knowledge sources in speech recognition.</title>
<date>1998</date>
<booktitle>In Proceedings of the NATO Advanced Studies Institute.</booktitle>
<contexts>
<context position="4548" citStr="Moore, 1998" startWordPosition="701" endWordPosition="702">table factoring of the grammar. The current version of REGULUS further refines the naive method by iteratively alternating the expansion and filtering stages, nondeterministically expanding each feature in turn and then filtering the result before proceeding to the next feature. On large grammars, this &amp;quot;iterative expansion&amp;quot; technique can reduce time and space requirements of the compilation algorithm by several orders of magnitude. Use of iterative expansion has allowed REGULUS successfully to compile several grammars which exceeded resource bounds for the Gemini compiler (Moore et al., 1997; Moore, 1998). 2.1 Using Grammar Specialisation Experience with grammar-based spoken dialogue systems shows that there is usually a substantial overlap between the structures of grammars for different domains. This is hardly surprising, since they all ultimately have to model general facts about the linguistic structure of English and other natural languages. It is consequently natural to consider strategies which attempt to exploit the overlap between domains by building a single, general grammar valid for a wide variety of applications. A grammar of this kind will probably offer more coverage (and hence </context>
</contexts>
<marker>Moore, 1998</marker>
<rawString>R. Moore. 1998. Using natural language knowledge sources in speech recognition. In Proceedings of the NATO Advanced Studies Institute.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Moore</author>
</authors>
<title>Improved left-corner chart parsing for large context-free grammars.</title>
<date>2000</date>
<booktitle>In Proceedings of the 6th International Workshop on Parsing Technologies,</booktitle>
<pages>171--182</pages>
<contexts>
<context position="9377" citStr="Moore, 2000" startWordPosition="1483" endWordPosition="1484">tween recognition performance and either vocabulary size or size of the training corpus, with performance depending rather more heavily on average utterance length and the types of constructions covered by the specialised grammar. We are actively investigating these issues at the moment. 3 The Development Environment All the functionalities in the REGULUS environment are available via a command-line interface, and also from within a top-loop designed primarily for interactive grammar debugging. In this mode, the grammar is compiled into an efficient left-corner parser, using the algorithm of (Moore, 2000), and also into a Definite Clause Grammar (DCG) form; the advantage of the DCG representation is that it can often be used to help diagnose grammar bugs by attempting to parse non-top constituents. Each separate domain-specific grammar is defined though a config file, which also specifies settings for the various user-defined parameters relevant to the compilation process. 4 Structure of the demo We will demo two recognisers built using REGULUS, one for a command and control application and one for a medical speech translation application. The command and control recogniser is an extended vers</context>
</contexts>
<marker>Moore, 2000</marker>
<rawString>R. Moore. 2000. Improved left-corner chart parsing for large context-free grammars. In Proceedings of the 6th International Workshop on Parsing Technologies, pages 171-182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nuance</author>
</authors>
<title>http://www.nuance.com.</title>
<date>2002</date>
<journal>As of</journal>
<volume>15</volume>
<contexts>
<context position="2183" citStr="Nuance, 2002" startWordPosition="328" endWordPosition="330">nstruction of domain-specific grammars by corpus-based specialisation of a large general unification grammar for English. Section 3 describes the interactive development environment. Section 4 describes how we intend to structure the actual demo. The final section contains instructions for downloading and installing REGULUS. 2 Compiling Unification Grammars into Recognisers The core functionality provided by the REGULUS environment is compilation of typed unification grammars into annotated context-free grammar language models expressed in Nuance Grammar Specification Language (GSL) notation (Nuance, 2002). GSL language models can be converted into runnable speech recognisers by invoking the Nuance Toolkit compiler utility, so the net result is the ability to compile a unification grammar into a speech recogniser. The REGULUS unification grammar formalism is closely related to the one used in the SRI Core Language Engine (CLE) and Gemini systems (Alshawi, 1992; Dowding et al., 1993), and it is most reasonable to compare it with Gemini, which offers a broadly similar range of functionalities. One important difference relates to the treatment of semantics. CLE and Gemini support a general unifica</context>
</contexts>
<marker>Nuance, 2002</marker>
<rawString>Nuance, 2002. http://www.nuance.com. As of 15 November 2002.</rawString>
</citation>
<citation valid="true">
<title>SICStus Prolog User&apos;s Manual.</title>
<date>1995</date>
<institution>Programming Systems Group,</institution>
<marker>1995</marker>
<rawString>Programming Systems Group, 1995. SICStus Prolog User&apos;s Manual. Swedish Institute of Computer Science, Kista, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>PSA</author>
</authors>
<title>Personal Satellite Assistant (PSA) Project.</title>
<date>2002</date>
<journal>http://ic.arc.nasa.gov/ic/projects/psa/. As of</journal>
<volume>1</volume>
<contexts>
<context position="10130" citStr="PSA, 2002" startWordPosition="1610" endWordPosition="1611">mmar bugs by attempting to parse non-top constituents. Each separate domain-specific grammar is defined though a config file, which also specifies settings for the various user-defined parameters relevant to the compilation process. 4 Structure of the demo We will demo two recognisers built using REGULUS, one for a command and control application and one for a medical speech translation application. The command and control recogniser is an extended version of the one for the Personal Satellite Assistant, a speech enabled mobile robot currently being developed at the NASA Ames Research Center (PSA, 2002). The domain-specific lexicon contains 313 entries; coverage includes commands (&amp;quot;go to flight deck&amp;quot;), Y-N and WHquestions (&amp;quot;has the temperature increased during the last five minutes&amp;quot;, &amp;quot;when did you measure the pressure at storage lockers&amp;quot;), conjunctions (&amp;quot;what were oxygen and carbon dioxide five minutes ago&amp;quot;) and pronouns (&amp;quot;go to crew hatch and open it&amp;quot;). Word error rates for this application on in-coverage data are around 10-11%. 225 The medical speech translator recogniser is an extended English-language version of the system described in (Rayner and Bouillon, 2002). The domain-specific lex</context>
</contexts>
<marker>PSA, 2002</marker>
<rawString>PSA, 2002. Personal Satellite Assistant (PSA) Project. http://ic.arc.nasa.gov/ic/projects/psa/. As of 1 Feb 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S G Pulman</author>
</authors>
<title>Syntactic and semantic processing. In Alshawi (Alshawi,</title>
<date>1992</date>
<pages>129--148</pages>
<contexts>
<context position="5633" citStr="Pulman, 1992" startWordPosition="868" endWordPosition="869">, general grammar valid for a wide variety of applications. A grammar of this kind will probably offer more coverage (and hence lower accuracy) than is desirable for any given specific application. It is however feasible to address the problem using corpus-based techniques which extract a specialised version of the original general grammar. REGULUS implements a version of the grammar specialisation scheme which extends the Explanation Based Learning method described in (Rayner et al., 2002). There is a general unification grammar, loosely based on the Core Language Engine grammar for English (Pulman, 1992), which has been developed over the course of about ten individual projects. The cun-ent version of the grammar contains 145 unification grammar rules, 465 function word entries, and 72 features. The grammar for each individual domain also includes a domain-specific content word lexicon, which typically contains 100 to 500 lexical entries. We have intentionally used a variety of widely differing domains, including a command and control system for a simulated mobile robot, a speech enabled home automation system, a travel planning system and a medical speech translator. The semantic representat</context>
</contexts>
<marker>Pulman, 1992</marker>
<rawString>S.G. Pulman. 1992. Syntactic and semantic processing. In Alshawi (Alshawi, 1992), pages 129-148.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
<author>P Bouillon</author>
</authors>
<title>A phrasebook style medical speech translator.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (demo track),</booktitle>
<location>Philadelphia, PA.</location>
<contexts>
<context position="10705" citStr="Rayner and Bouillon, 2002" startWordPosition="1697" endWordPosition="1700">eloped at the NASA Ames Research Center (PSA, 2002). The domain-specific lexicon contains 313 entries; coverage includes commands (&amp;quot;go to flight deck&amp;quot;), Y-N and WHquestions (&amp;quot;has the temperature increased during the last five minutes&amp;quot;, &amp;quot;when did you measure the pressure at storage lockers&amp;quot;), conjunctions (&amp;quot;what were oxygen and carbon dioxide five minutes ago&amp;quot;) and pronouns (&amp;quot;go to crew hatch and open it&amp;quot;). Word error rates for this application on in-coverage data are around 10-11%. 225 The medical speech translator recogniser is an extended English-language version of the system described in (Rayner and Bouillon, 2002). The domain-specific lexicon for this system contains 607 entries. Coverage includes Y-N and WHquestions (&amp;quot;does the headache usually start suddenly&amp;quot;, &amp;quot;what makes your headache better&amp;quot;) and elliptical phrases (&amp;quot;insomnia&amp;quot;, &amp;quot;in the left chest&amp;quot;, &amp;quot;severe&amp;quot;). Although the medical speech application has nearly twice as large a vocabulary, recognition performance is in fact noticeably better than for the command and control application; preliminary results suggest a word error rate on incoverage data of around 6-7%. We will demo speech recognition for each recogniser, and show how the development envi</context>
</contexts>
<marker>Rayner, Bouillon, 2002</marker>
<rawString>M. Rayner and P. Bouillon. 2002. A phrasebook style medical speech translator. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (demo track), Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
<author>J Dowding</author>
<author>B A Hockey</author>
</authors>
<title>A baseline method for compiling typed unification grammars into context free language models.</title>
<date>2001</date>
<booktitle>In Proceedings of Eurospeech</booktitle>
<pages>729--732</pages>
<location>Aalborg, Denmark.</location>
<contexts>
<context position="3538" citStr="Rayner et al., 2001" startWordPosition="544" endWordPosition="547">s involves a slight loss of expressive power, it offers the very significant advantage of allowing the 223 semantics of the original grammar to be compiled into semantic annotations on the target GSL rules. The resulting recogniser can thus be used as a stand-alone system, which both recognises spoken utterances and produces semantic representations for them. In contrast, recognisers compiled by the Gemini system only produce word-string output, which then has to be parsed by a separate process. The basic algorithm used by REGULUS to compile unification grammars into CFG form is described in (Rayner et al., 2001). The central idea is simply to perform an enumerative expansion of the unification grammar by non-deterministically instantiating each feature to all of its possible values; the resulting grammar is then filtered to remove non-reachable rules. As described in (Rayner et al., 2001), the efficiency of the naive algorithm can be greatly improved by adding a pre-processing step which performs a suitable factoring of the grammar. The current version of REGULUS further refines the naive method by iteratively alternating the expansion and filtering stages, nondeterministically expanding each feature</context>
</contexts>
<marker>Rayner, Dowding, Hockey, 2001</marker>
<rawString>M. Rayner, J. Dowding, and B.A. Hockey. 2001. A baseline method for compiling typed unification grammars into context free language models. In Proceedings of Eurospeech 2001, pages 729-732, Aalborg, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
<author>B A Hockey</author>
<author>J Dowding</author>
</authors>
<title>Grammar specialisation meets language modelling.</title>
<date>2002</date>
<booktitle>In Proceedings of the 7th International Conference on Spoken Language Processing (ICSLP),</booktitle>
<location>Denver, CO.</location>
<contexts>
<context position="5515" citStr="Rayner et al., 2002" startWordPosition="847" endWordPosition="850">. It is consequently natural to consider strategies which attempt to exploit the overlap between domains by building a single, general grammar valid for a wide variety of applications. A grammar of this kind will probably offer more coverage (and hence lower accuracy) than is desirable for any given specific application. It is however feasible to address the problem using corpus-based techniques which extract a specialised version of the original general grammar. REGULUS implements a version of the grammar specialisation scheme which extends the Explanation Based Learning method described in (Rayner et al., 2002). There is a general unification grammar, loosely based on the Core Language Engine grammar for English (Pulman, 1992), which has been developed over the course of about ten individual projects. The cun-ent version of the grammar contains 145 unification grammar rules, 465 function word entries, and 72 features. The grammar for each individual domain also includes a domain-specific content word lexicon, which typically contains 100 to 500 lexical entries. We have intentionally used a variety of widely differing domains, including a command and control system for a simulated mobile robot, a spe</context>
</contexts>
<marker>Rayner, Hockey, Dowding, 2002</marker>
<rawString>M. Rayner, B.A. Hockey, and J. Dowding. 2002. Grammar specialisation meets language modelling. In Proceedings of the 7th International Conference on Spoken Language Processing (ICSLP), Denver, CO.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
</authors>
<title>Applying explanation-based generalization to natural-language processing.</title>
<date>1988</date>
<booktitle>In Proceedings of the International Conference on Fifth Generation Computer Systems,</booktitle>
<pages>1267--1274</pages>
<location>Tokyo, Japan.</location>
<contexts>
<context position="7138" citStr="Rayner, 1988" startWordPosition="1116" endWordPosition="1117">hat for &amp;quot;how long have you had headaches&amp;quot; is f[whq. form( [present , perfect ] [ [have symptom, term (pro, you, []) , term (null, headache, [] ) ] , [duration, how long] ] 1 1 A grammar built on top of the general grammar is transformed into a specialised Nuance grammar in the following processing stages: 224 1. The training corpus is converted into a &amp;quot;treebank&amp;quot; of parsed representations. This is done using a left-corner parser representation of the grammar. 2. The treebank is used to produce a &amp;quot;raw&amp;quot; specialised grammar in REGULUS format, using the EBL algorithm (van Harmelen and Bundy, 1988; Rayner, 1988). The granularity of the learned rules is determined by a usersupplied parameter. This parameter can currently be set to the following values: Lexical The learned grammar is completely &amp;quot;flat&amp;quot;, with each training example producing exactly one rule. NP The learned grammar has two levels, with only NP nodes between root nodes and pre-lexical nodes. NP_PP The learned grammar has three levels, with NP and PP nodes between root nodes and pre-lexical nodes. S_NP_PP The learned grammar has four levels, with S, NP and PP nodes between root nodes and pre-lexical nodes. 3. The &amp;quot;raw&amp;quot; specialised grammar i</context>
</contexts>
<marker>Rayner, 1988</marker>
<rawString>M. Rayner. 1988. Applying explanation-based generalization to natural-language processing. In Proceedings of the International Conference on Fifth Generation Computer Systems, pages 1267-1274, Tokyo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J van Eijck</author>
<author>R Moore</author>
</authors>
<title>Semantic rules for English. In</title>
<date>1992</date>
<booktitle>The Core Language Engine,</booktitle>
<pages>83--116</pages>
<editor>H. Alshawi, editor,</editor>
<publisher>MIT Press.</publisher>
<marker>van Eijck, Moore, 1992</marker>
<rawString>J. van Eijck and R. Moore. 1992. Semantic rules for English. In H. Alshawi, editor, The Core Language Engine, pages 83-116. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T van Harmelen</author>
<author>A Bundy</author>
</authors>
<title>Explanationbased generalization = partial evaluation (research note).</title>
<date>1988</date>
<journal>Artificial Intelligence,</journal>
<pages>36--401</pages>
<marker>van Harmelen, Bundy, 1988</marker>
<rawString>T. van Harmelen and A. Bundy. 1988. Explanationbased generalization = partial evaluation (research note). Artificial Intelligence, 36:401-412.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>