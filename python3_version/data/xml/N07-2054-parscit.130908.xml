<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.055116">
<title confidence="0.9986895">
Speech Summarization Without Lexical Features
for Mandarin Broadcast News
</title>
<author confidence="0.99876">
Jian Zhang
</author>
<affiliation confidence="0.995951666666667">
Human Language Technology Center
Electronic and Computer Engineering
University of Science and Technology
</affiliation>
<address confidence="0.730469">
Clear Water Bay,Hong Kong
</address>
<email confidence="0.989546">
zjustin@ust.hk
</email>
<author confidence="0.991474">
Pascale Fung
</author>
<affiliation confidence="0.994885666666667">
Human Language Technology Center
Electronic and Computer Engineering
University of Science and Technology
</affiliation>
<address confidence="0.733181">
Clear Water Bay,Hong Kong
</address>
<email confidence="0.993679">
pascale@ee.ust.hk
</email>
<sectionHeader confidence="0.99559" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999990722222222">
We present the first known empirical study
on speech summarization without lexi-
cal features for Mandarin broadcast news.
We evaluate acoustic, lexical and struc-
tural features as predictors of summary
sentences. We find that the summarizer
yields good performance at the average F-
measure of 0.5646 even by using the com-
bination of acoustic and structural features
alone, which are independent of lexical
features. In addition, we show that struc-
tural features are superior to lexical fea-
tures and our summarizer performs sur-
prisingly well at the average F-measure
of 0.3914 by using only acoustic features.
These findings enable us to summarize
speech without placing a stringent demand
on speech recognition accuracy.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999269375">
Speech summarization, a technique of extracting
key segments that convey the main content from
a spoken document or audio document, has be-
come a new area of study in the last few years.
There has been much significant progress made in
speech summarization for English or Japanese text
and audio sources (Hori and Furui, 2003; Inoue et
al., 2004; Koumpis and Renals, 2005; Maskey and
Hirschberg, 2003; Maskey and Hirschberg, 2005).
Some research efforts have focused on summariz-
ing Mandarin sources (Chen et al., 2006; Huang
et al., 2005), which are dependent on lexical fea-
tures. Considering the difficulty in obtaining high
quality transcriptions, some researchers proposed
speech summarization systems with non-lexical fea-
tures (Inoue et al., 2004; Koumpis and Renals,
2005; Maskey and Hirschberg, 2003; Maskey and
Hirschberg, 2006). However, there does not exist
any empirical study on speech summarization with-
out lexical features for Mandarin Chinese sources.
In this paper, we construct our summarizer with
acoustic and structural features, which are indepen-
dent of lexical features, and compare acoustic and
structural features against lexical features as predic-
tors of summary sentences.
In Section 2 we review previous work on broad-
cast news summarization. We describe the Mandarin
broadcast news corpus on which our system operates
in Section 3. In Section 4 we describe our summa-
rizer and these features used in experiments. We set
up our experiments and evaluate the results in Sec-
tion 5, followed by our conclusion in Section 6.
</bodyText>
<sectionHeader confidence="0.993999" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.999754090909091">
There have been many research efforts on speech
summarization. Some methods dependent on lexi-
cal features are presented (Inoue et al., 2004; Chen
et al., 2006; Huang et al., 2005). (Inoue et al.,
2004) uses statistical methods to identify words to
include in a summary, based on linguistic and acous-
tic/prosodic features of the Japanese broadcast news
transcriptions; while (Chen et al., 2006) proposes
the use of probabilistic latent topical information for
extractive summarization of Mandarin spoken docu-
ments. (Huang et al., 2005) presents Mandarin spo-
</bodyText>
<page confidence="0.990724">
213
</page>
<note confidence="0.4645255">
Proceedings of NAACL HLT 2007, Companion Volume, pages 213–216,
Rochester, NY, April 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.99914935">
ken document summarization scheme using acous-
tic, prosodic, and semantic information. Alterna-
tively, some methods which are independent of lex-
ical features are presented (Maskey and Hirschberg,
2003; Maskey and Hirschberg, 2006). (Maskey
and Hirschberg, 2003) extracts structural informa-
tion from audio documents to help summarization.
(Maskey and Hirschberg, 2006) focuses on how to
use acoustic information alone to help predict sen-
tences to be included in a summary and shows a
novel way of using continuous HMMs for summa-
rizing speech documents without transcriptions.
It is advantageous to build speech summarization
models without using lexical features: we can sum-
marize speech data without placing a stringent de-
mand on the speech recognition accuracy. In this pa-
per, we propose one such model on Mandarin broad-
cast news and compare the effectiveness of acous-
tic and structural features against lexical features as
predictors of summary sentences.
</bodyText>
<sectionHeader confidence="0.907652" genericHeader="method">
3 The Corpus and Manual Summaries
</sectionHeader>
<bodyText confidence="0.999966944444444">
We use a portion of the 1997 Hub4 Mandarin corpus
available via LDC as experiment data. The related
audio data were recorded from China Central Tele-
vision(CCTV) International News programs. They
include 23-day broadcast from 14th January, 1997
to 21st April, 1997, which contain 593 stories and
weather forecasts. Each broadcast lasts approxi-
mately 32 minutes, and has been hand-segmented
into speaker turns. For evaluation, we manually
annotated these broadcast news, and extracted seg-
ments as reference summaries. We divide these
broadcast news stories into 3 types: one-turn news,
weather forecast, and several-turns news. The con-
tent of each several-turn news is presented by more
than one reporter, and sometimes interviewees. We
evaluate our summarizer on the several-turns news
corpus. The corpus has 347 stories which contain
4748 sentences in total.
</bodyText>
<sectionHeader confidence="0.99475" genericHeader="method">
4 Features and Methodology
</sectionHeader>
<subsectionHeader confidence="0.972427">
4.1 Acoustic/Prosodic Features
</subsectionHeader>
<bodyText confidence="0.999506535714286">
Acoustic/prosodic features in speech summarization
system are usually extracted from audio data. Re-
searchers commonly use acoustic/prosodic variation
– changes in pitch, intensity, speaking rate – and du-
ration of pause for tagging the important contents
of their speeches (Hirschberg, 2002). We also use
these features for predicting summary sentences on
Mandarin broadcast news.
Our acoustic feature set contains thirteen features:
DurationI, DurationII, SpeakingRate, F0I, F0II,
F0III, F0IV, F0V, EI, EII, EIII, EIV and EV. Du-
rationI is the sentence duration. DurationII is the
average phoneme duration. General phonetic stud-
ies consider that the speaking rate of sentence is re-
flected in syllable duration. So we use average syl-
lable duration for representing SpeakingRate. F0I is
F0’s minimum value. F0II is F0’s maximum value.
F0III equals to the difference between F0II and F0I.
F0IV is the mean of F0. F0V is F0 slope. EI is min-
imum energy value. EII is maximum energy value.
EIII equals to the difference between EII and EI.
EIV is the mean of energy value. EV is energy slope.
We calculate DurationI from the annotated manual
transcriptions that align the audio documents. We
then obtain DurationII and SpeakingRate by pho-
netic forced alignment. Next we extract F0 fea-
tures and energy features from audio data by using
Praat (Boersma and Weenink, 1996).
</bodyText>
<subsectionHeader confidence="0.990788">
4.2 Structural Features
</subsectionHeader>
<bodyText confidence="0.999968125">
Each broadcast news of the 1997 Hub4 Mandarin
corpus has similar structure, which starts with an an-
chor, followed by the formal report of the story by
other reporters or interviewees.
Our structural feature set consists of 4 features:
Position, TurnI, TurnII and TurnIII. Position is de-
fined as follows: one news has k sentences, then we
set (1− (0/k)) as Position value of the first sentence
in the news, and set (1−((i−1)/k)) as Position value
of the ith sentence. TurnI is defined as follows: one
news has m turns, then we set (1 − (0/m)) as TurnI
value of the sentences which belong to the first turn’s
content, and set (1−((j −1)/m)) as TurnI values of
the sentences which belong to the jth turn’s content.
TurnII is the previous turn’s TurnI value. TurnIII is
the next turn’s TurnI value.
</bodyText>
<subsectionHeader confidence="0.998415">
4.3 Reference Lexical Features
</subsectionHeader>
<bodyText confidence="0.96296">
Most methods for text summarization mainly utilize
lexical features. We are interested in investigating
the role of lexical features in comparison to other
features. All reference lexical features are extracted
</bodyText>
<page confidence="0.993925">
214
</page>
<bodyText confidence="0.999641045454546">
from the manual transcriptions.
Our lexical feature set contains eight features:
LenI, LenII, LenIII, NEI, NEII, NEIII, TFIDF
and Cosine. For a sentence, we set the number of
words in the sentence as LenI value. LenII is the
previous sentence’s LenI value. LenIII is the next
sentence’s LenI value. For a sentence, we set the
number of Named Entities in the sentence as the
NEI value. We define the number of Named Enti-
ties which appear in the sentence at the first time in
a news as NEII value. NEIII value equals to the ra-
tio of the number of unique Named Entities to the
number of all Named Entities.
TFIDF is the product of tf and idf. tf is the frac-
tion: the numerator is the number of occurrences
of the considered word and the denominator is the
number of occurrences of all words in a story. idf is
the logarithm of the fraction: the numerator is the to-
tal number of sentences in the considered news and
the denominator is the number of sentences where
the considered word appears. Cosine means cosine
similarity measure between two sentence vectors.
</bodyText>
<subsectionHeader confidence="0.986459">
4.4 Summarizer
</subsectionHeader>
<bodyText confidence="0.99911975">
Our summarizer contains the preprocessing stage
and the estimating stage. The preprocessing stage
extracts features and normalizes all features by
equation (1).
</bodyText>
<equation confidence="0.997938666666667">
wj − mean(wj)
Nj = 1
dev(wj) ( )
</equation>
<bodyText confidence="0.999571272727273">
Here, wj is the original value of feature j which is
used to describe sentence i; mean(wj) is the mean
value of feature j in our training set or test set;
dev(wj) is the standard deviation value of feature
j in our training set or test set.
The estimating stage predicts whether each sen-
tence of the broadcast news is in a summary or not.
We use Radial Basis Function(RBF) kernel for con-
structing SVM classifier as our estimator referring to
LIBSVM (Chang and Lin, 2001), which is a library
for support vector machines.
</bodyText>
<sectionHeader confidence="0.996845" genericHeader="evaluation">
5 Experiments and Evaluation
</sectionHeader>
<bodyText confidence="0.999291666666667">
We use the several-turn news corpus, described in
Section 3, in our experiments. We use 70% of the
corpus consisting of 3294 sentences as training set
</bodyText>
<tableCaption confidence="0.998698">
Table 1: Feature set Evaluation by F-measure
</tableCaption>
<table confidence="0.962319875">
Feature Set SR10% SR15% SR20% Ave
Ac+St+Le .5961 .546 .5544 .5655
Ac+St .5888 .5489 .5562 .5646
St .5951 .5616 .537 .5645
Le .5175 .5219 .5329 .5241
Ac .3068 .4092 .4582 .3914
Baseline .21 .32 .43 .32
Ac: Acoustic; St: Structural; Le: Lexical
</table>
<bodyText confidence="0.9996354">
and the remaining 1454 sentences as held-out test
set, upon which our summarizer is tested.
We measure our summarizer’s performance by
precision, recall, and F-measure (Jing et al., 1998).
We explain these metrics as follows:
</bodyText>
<equation confidence="0.990586">
2 x precision x recall
F-Measure = (4)
precision + recall
</equation>
<bodyText confidence="0.999936826086956">
In equation (2), (3) and (4), Sman is the sentence
set of manual summaries or reference summaries;
Ssum is the sentence set of predicted summaries pro-
vided by our summarizer.
We have three versions of reference summaries
based on summarization ratio(SR): 10%, 15% and
20% respectively. So we build three baselines re-
ferring to different versions of reference summaries.
When using SR 10% summaries, we build the base-
lines by choosing the first 10% of sentences from
each story. Our baseline results in F-measure score
are given in Table 1.
We perform three sets of experiments with differ-
ent summarization ratios.
By using acoustic and structural features alone,
the summarizer produces the same performance as
by using all features. We can find the evidence from
Table 1 and Figure 1. On average, the combination
of acoustic and structural features yields good per-
formance: F-measure of 0.5646, 24.46% higher than
the baseline, only 0.09% lower than the average F-
measure produced by using all features. This find-
ing makes it possible to summarize speech without
</bodyText>
<figure confidence="0.998963285714286">
Sman I I Ssum
precision =
Ssum
Sman �Ssum
recall = (3)
Sman
(2)
</figure>
<page confidence="0.904577">
215
</page>
<bodyText confidence="0.967364">
Score
age F-measure of 0.5646, the same as by using all
features. We also found that structural features make
more important contribution than lexical features to
speech summarization because of the relatively con-
sistent distribution and flow of summary sentences
in the same Mandarin broadcast program. Moreover,
we have shown that our summarizer performed sur-
prisingly well by using only acoustic features: av-
erage F-measure of 0.3914, 7.14% higher than the
baseline. These findings also suggest that high qual-
ity speech summarization can be achieved without
stringent requirement on speech recognition accu-
racy.
</bodyText>
<figureCaption confidence="0.999091">
Figure 1: Performance comparison on SR10%
</figureCaption>
<bodyText confidence="0.999751571428571">
placing a stringent demand on the speech recogni-
tion accuracy.
In the same Mandarin broadcast program, the dis-
tribution and flow of summary sentences are rela-
tively consistent. Therefore, compared with speech
summarization on English sources, we can achieve
the different finding that structural features play
a key role in speech summarization for Mandarin
broadcast news. Table 1 shows the evidence. On
average, structural features are superior to lexical
features: F-measure of 0.5645, 24.45% higher than
the baseline and 4,04% higher than the average F-
measure produced by using lexical features.
Another conclusion we can draw from Table 1
is that acoustic features are important for speech
summarization on Mandarin broadcast news. On
average, even by using acoustic features alone our
summarizer yields competitive result: F-measure of
0.3914, 7.14% higher than the baseline. The similar
conclusion also holds for speech summarization on
English sources (Maskey and Hirschberg, 2006).
</bodyText>
<sectionHeader confidence="0.999681" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9954838">
In this paper, we have presented the results of an
empirical study on speech summarization for Man-
darin broadcast news. From these results, we found
that by using acoustic and structural features alone,
the summarizer produces good performance: aver-
</bodyText>
<sectionHeader confidence="0.999084" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999708028571429">
P. Boersma and D. Weenink. 1996. Praat, a system for doing
phonetics by computer, version 3.4. Institute of Phonetic
Sciences of the University of Amsterdam, Report, 132:182.
Chih-Chung Chang and Chih-Jen Lin, 2001. LIBSVM: a library
for support vector machines.
B. Chen, Y.M. Yeh, Y.M. Huang, and Y.T. Chen. 2006. Chi-
nese Spoken Document Summarization Using Probabilistic
Latent Topical Information. Proc. ICASSP.
J. Hirschberg. 2002. Communication and prosody: Functional
aspects of prosody. Speech Communication, 36(1):31–43.
C. Hori and S. Furui. 2003. A new approach to automatic
speech summarization. Multimedia, IEEE Transactions on,
5(3):368–378.
C.L. Huang, C.H. Hsieh, and C.H. Wu. 2005. Spoken Docu-
ment Summarization Using Acoustic, Prosodic and Seman-
tic Information. Multimedia and Expo, 2005. ICME 2005.
IEEE International Conference on, pages 434–437.
A. Inoue, T. Mikami, and Y. Yamashita. 2004. Improvement of
Speech Summarization Using Prosodic Information. Proc.
of Speech Prosody.
H. Jing, R. Barzilay, K. McKeown, and M. Elhadad. 1998.
Summarization evaluation methods: Experiments and anal-
ysis. AAAI Symposium on Intelligent Summarization.
K. Koumpis and S. Renals. 2005. Automatic summariza-
tion of voicemail messages using lexical and prosodic fea-
tures. ACM Transactions on Speech and Language Process-
ing (TSLP), 2(1):1–24.
S. Maskey and J. Hirschberg. 2003. Automatic summarization
of broadcast news using structural features. Proceedings of
Eurospeech 2003.
S. Maskey and J. Hirschberg. 2005. Comparing lexical, acous-
tic/prosodic, structural and discourse features for speech
summarization. Interspeech 2005 (Eurospeech).
S. Maskey and J. Hirschberg. 2006. Summarizing Speech
Without Text Using Hidden Markov Models. Proc. NAACL.
</reference>
<page confidence="0.999141">
216
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.334864">
<title confidence="0.9944415">Speech Summarization Without Lexical for Mandarin Broadcast News</title>
<author confidence="0.71566">Jian</author>
<affiliation confidence="0.895428333333333">Human Language Technology Electronic and Computer University of Science and</affiliation>
<address confidence="0.898734">Clear Water Bay,Hong</address>
<email confidence="0.954841">zjustin@ust.hk</email>
<author confidence="0.822367">Pascale</author>
<affiliation confidence="0.925411666666667">Human Language Technology Electronic and Computer University of Science and</affiliation>
<address confidence="0.908912">Clear Water Bay,Hong</address>
<email confidence="0.975146">pascale@ee.ust.hk</email>
<abstract confidence="0.998764526315789">We present the first known empirical study on speech summarization without lexical features for Mandarin broadcast news. We evaluate acoustic, lexical and structural features as predictors of summary sentences. We find that the summarizer yields good performance at the average Fmeasure of 0.5646 even by using the combination of acoustic and structural features alone, which are independent of lexical features. In addition, we show that structural features are superior to lexical features and our summarizer performs surprisingly well at the average F-measure of 0.3914 by using only acoustic features. These findings enable us to summarize speech without placing a stringent demand on speech recognition accuracy.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P Boersma</author>
<author>D Weenink</author>
</authors>
<title>Praat, a system for doing phonetics by computer, version 3.4.</title>
<date>1996</date>
<booktitle>Institute of Phonetic Sciences of the University of Amsterdam, Report,</booktitle>
<pages>132--182</pages>
<contexts>
<context position="6663" citStr="Boersma and Weenink, 1996" startWordPosition="1019" endWordPosition="1022">e duration for representing SpeakingRate. F0I is F0’s minimum value. F0II is F0’s maximum value. F0III equals to the difference between F0II and F0I. F0IV is the mean of F0. F0V is F0 slope. EI is minimum energy value. EII is maximum energy value. EIII equals to the difference between EII and EI. EIV is the mean of energy value. EV is energy slope. We calculate DurationI from the annotated manual transcriptions that align the audio documents. We then obtain DurationII and SpeakingRate by phonetic forced alignment. Next we extract F0 features and energy features from audio data by using Praat (Boersma and Weenink, 1996). 4.2 Structural Features Each broadcast news of the 1997 Hub4 Mandarin corpus has similar structure, which starts with an anchor, followed by the formal report of the story by other reporters or interviewees. Our structural feature set consists of 4 features: Position, TurnI, TurnII and TurnIII. Position is defined as follows: one news has k sentences, then we set (1− (0/k)) as Position value of the first sentence in the news, and set (1−((i−1)/k)) as Position value of the ith sentence. TurnI is defined as follows: one news has m turns, then we set (1 − (0/m)) as TurnI value of the sentences </context>
</contexts>
<marker>Boersma, Weenink, 1996</marker>
<rawString>P. Boersma and D. Weenink. 1996. Praat, a system for doing phonetics by computer, version 3.4. Institute of Phonetic Sciences of the University of Amsterdam, Report, 132:182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM: a library for support vector machines.</title>
<date>2001</date>
<contexts>
<context position="9468" citStr="Chang and Lin, 2001" startWordPosition="1506" endWordPosition="1509">age and the estimating stage. The preprocessing stage extracts features and normalizes all features by equation (1). wj − mean(wj) Nj = 1 dev(wj) ( ) Here, wj is the original value of feature j which is used to describe sentence i; mean(wj) is the mean value of feature j in our training set or test set; dev(wj) is the standard deviation value of feature j in our training set or test set. The estimating stage predicts whether each sentence of the broadcast news is in a summary or not. We use Radial Basis Function(RBF) kernel for constructing SVM classifier as our estimator referring to LIBSVM (Chang and Lin, 2001), which is a library for support vector machines. 5 Experiments and Evaluation We use the several-turn news corpus, described in Section 3, in our experiments. We use 70% of the corpus consisting of 3294 sentences as training set Table 1: Feature set Evaluation by F-measure Feature Set SR10% SR15% SR20% Ave Ac+St+Le .5961 .546 .5544 .5655 Ac+St .5888 .5489 .5562 .5646 St .5951 .5616 .537 .5645 Le .5175 .5219 .5329 .5241 Ac .3068 .4092 .4582 .3914 Baseline .21 .32 .43 .32 Ac: Acoustic; St: Structural; Le: Lexical and the remaining 1454 sentences as held-out test set, upon which our summarizer i</context>
</contexts>
<marker>Chang, Lin, 2001</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin, 2001. LIBSVM: a library for support vector machines.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Chen</author>
<author>Y M Yeh</author>
<author>Y M Huang</author>
<author>Y T Chen</author>
</authors>
<title>Chinese Spoken Document Summarization Using Probabilistic Latent Topical Information.</title>
<date>2006</date>
<booktitle>Proc. ICASSP.</booktitle>
<contexts>
<context position="1653" citStr="Chen et al., 2006" startWordPosition="245" endWordPosition="248">o summarize speech without placing a stringent demand on speech recognition accuracy. 1 Introduction Speech summarization, a technique of extracting key segments that convey the main content from a spoken document or audio document, has become a new area of study in the last few years. There has been much significant progress made in speech summarization for English or Japanese text and audio sources (Hori and Furui, 2003; Inoue et al., 2004; Koumpis and Renals, 2005; Maskey and Hirschberg, 2003; Maskey and Hirschberg, 2005). Some research efforts have focused on summarizing Mandarin sources (Chen et al., 2006; Huang et al., 2005), which are dependent on lexical features. Considering the difficulty in obtaining high quality transcriptions, some researchers proposed speech summarization systems with non-lexical features (Inoue et al., 2004; Koumpis and Renals, 2005; Maskey and Hirschberg, 2003; Maskey and Hirschberg, 2006). However, there does not exist any empirical study on speech summarization without lexical features for Mandarin Chinese sources. In this paper, we construct our summarizer with acoustic and structural features, which are independent of lexical features, and compare acoustic and s</context>
<context position="3088" citStr="Chen et al., 2006" startWordPosition="470" endWordPosition="473">operates in Section 3. In Section 4 we describe our summarizer and these features used in experiments. We set up our experiments and evaluate the results in Section 5, followed by our conclusion in Section 6. 2 Previous Work There have been many research efforts on speech summarization. Some methods dependent on lexical features are presented (Inoue et al., 2004; Chen et al., 2006; Huang et al., 2005). (Inoue et al., 2004) uses statistical methods to identify words to include in a summary, based on linguistic and acoustic/prosodic features of the Japanese broadcast news transcriptions; while (Chen et al., 2006) proposes the use of probabilistic latent topical information for extractive summarization of Mandarin spoken documents. (Huang et al., 2005) presents Mandarin spo213 Proceedings of NAACL HLT 2007, Companion Volume, pages 213–216, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics ken document summarization scheme using acoustic, prosodic, and semantic information. Alternatively, some methods which are independent of lexical features are presented (Maskey and Hirschberg, 2003; Maskey and Hirschberg, 2006). (Maskey and Hirschberg, 2003) extracts structural information f</context>
</contexts>
<marker>Chen, Yeh, Huang, Chen, 2006</marker>
<rawString>B. Chen, Y.M. Yeh, Y.M. Huang, and Y.T. Chen. 2006. Chinese Spoken Document Summarization Using Probabilistic Latent Topical Information. Proc. ICASSP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hirschberg</author>
</authors>
<title>Communication and prosody: Functional aspects of prosody.</title>
<date>2002</date>
<journal>Speech Communication,</journal>
<volume>36</volume>
<issue>1</issue>
<contexts>
<context position="5592" citStr="Hirschberg, 2002" startWordPosition="845" endWordPosition="846">r forecast, and several-turns news. The content of each several-turn news is presented by more than one reporter, and sometimes interviewees. We evaluate our summarizer on the several-turns news corpus. The corpus has 347 stories which contain 4748 sentences in total. 4 Features and Methodology 4.1 Acoustic/Prosodic Features Acoustic/prosodic features in speech summarization system are usually extracted from audio data. Researchers commonly use acoustic/prosodic variation – changes in pitch, intensity, speaking rate – and duration of pause for tagging the important contents of their speeches (Hirschberg, 2002). We also use these features for predicting summary sentences on Mandarin broadcast news. Our acoustic feature set contains thirteen features: DurationI, DurationII, SpeakingRate, F0I, F0II, F0III, F0IV, F0V, EI, EII, EIII, EIV and EV. DurationI is the sentence duration. DurationII is the average phoneme duration. General phonetic studies consider that the speaking rate of sentence is reflected in syllable duration. So we use average syllable duration for representing SpeakingRate. F0I is F0’s minimum value. F0II is F0’s maximum value. F0III equals to the difference between F0II and F0I. F0IV </context>
</contexts>
<marker>Hirschberg, 2002</marker>
<rawString>J. Hirschberg. 2002. Communication and prosody: Functional aspects of prosody. Speech Communication, 36(1):31–43.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Hori</author>
<author>S Furui</author>
</authors>
<title>A new approach to automatic speech summarization.</title>
<date>2003</date>
<journal>Multimedia, IEEE Transactions on,</journal>
<volume>5</volume>
<issue>3</issue>
<contexts>
<context position="1461" citStr="Hori and Furui, 2003" startWordPosition="215" endWordPosition="218">t structural features are superior to lexical features and our summarizer performs surprisingly well at the average F-measure of 0.3914 by using only acoustic features. These findings enable us to summarize speech without placing a stringent demand on speech recognition accuracy. 1 Introduction Speech summarization, a technique of extracting key segments that convey the main content from a spoken document or audio document, has become a new area of study in the last few years. There has been much significant progress made in speech summarization for English or Japanese text and audio sources (Hori and Furui, 2003; Inoue et al., 2004; Koumpis and Renals, 2005; Maskey and Hirschberg, 2003; Maskey and Hirschberg, 2005). Some research efforts have focused on summarizing Mandarin sources (Chen et al., 2006; Huang et al., 2005), which are dependent on lexical features. Considering the difficulty in obtaining high quality transcriptions, some researchers proposed speech summarization systems with non-lexical features (Inoue et al., 2004; Koumpis and Renals, 2005; Maskey and Hirschberg, 2003; Maskey and Hirschberg, 2006). However, there does not exist any empirical study on speech summarization without lexica</context>
</contexts>
<marker>Hori, Furui, 2003</marker>
<rawString>C. Hori and S. Furui. 2003. A new approach to automatic speech summarization. Multimedia, IEEE Transactions on, 5(3):368–378.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C L Huang</author>
<author>C H Hsieh</author>
<author>C H Wu</author>
</authors>
<title>Spoken Document Summarization Using Acoustic, Prosodic and Semantic Information. Multimedia and Expo,</title>
<date>2005</date>
<booktitle>ICME 2005. IEEE International Conference on,</booktitle>
<pages>434--437</pages>
<contexts>
<context position="1674" citStr="Huang et al., 2005" startWordPosition="249" endWordPosition="252">without placing a stringent demand on speech recognition accuracy. 1 Introduction Speech summarization, a technique of extracting key segments that convey the main content from a spoken document or audio document, has become a new area of study in the last few years. There has been much significant progress made in speech summarization for English or Japanese text and audio sources (Hori and Furui, 2003; Inoue et al., 2004; Koumpis and Renals, 2005; Maskey and Hirschberg, 2003; Maskey and Hirschberg, 2005). Some research efforts have focused on summarizing Mandarin sources (Chen et al., 2006; Huang et al., 2005), which are dependent on lexical features. Considering the difficulty in obtaining high quality transcriptions, some researchers proposed speech summarization systems with non-lexical features (Inoue et al., 2004; Koumpis and Renals, 2005; Maskey and Hirschberg, 2003; Maskey and Hirschberg, 2006). However, there does not exist any empirical study on speech summarization without lexical features for Mandarin Chinese sources. In this paper, we construct our summarizer with acoustic and structural features, which are independent of lexical features, and compare acoustic and structural features ag</context>
<context position="3229" citStr="Huang et al., 2005" startWordPosition="490" endWordPosition="493">e the results in Section 5, followed by our conclusion in Section 6. 2 Previous Work There have been many research efforts on speech summarization. Some methods dependent on lexical features are presented (Inoue et al., 2004; Chen et al., 2006; Huang et al., 2005). (Inoue et al., 2004) uses statistical methods to identify words to include in a summary, based on linguistic and acoustic/prosodic features of the Japanese broadcast news transcriptions; while (Chen et al., 2006) proposes the use of probabilistic latent topical information for extractive summarization of Mandarin spoken documents. (Huang et al., 2005) presents Mandarin spo213 Proceedings of NAACL HLT 2007, Companion Volume, pages 213–216, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics ken document summarization scheme using acoustic, prosodic, and semantic information. Alternatively, some methods which are independent of lexical features are presented (Maskey and Hirschberg, 2003; Maskey and Hirschberg, 2006). (Maskey and Hirschberg, 2003) extracts structural information from audio documents to help summarization. (Maskey and Hirschberg, 2006) focuses on how to use acoustic information alone to help predict sen</context>
</contexts>
<marker>Huang, Hsieh, Wu, 2005</marker>
<rawString>C.L. Huang, C.H. Hsieh, and C.H. Wu. 2005. Spoken Document Summarization Using Acoustic, Prosodic and Semantic Information. Multimedia and Expo, 2005. ICME 2005. IEEE International Conference on, pages 434–437.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Inoue</author>
<author>T Mikami</author>
<author>Y Yamashita</author>
</authors>
<title>Improvement of Speech Summarization Using Prosodic Information.</title>
<date>2004</date>
<booktitle>Proc. of Speech Prosody.</booktitle>
<contexts>
<context position="1481" citStr="Inoue et al., 2004" startWordPosition="219" endWordPosition="222">are superior to lexical features and our summarizer performs surprisingly well at the average F-measure of 0.3914 by using only acoustic features. These findings enable us to summarize speech without placing a stringent demand on speech recognition accuracy. 1 Introduction Speech summarization, a technique of extracting key segments that convey the main content from a spoken document or audio document, has become a new area of study in the last few years. There has been much significant progress made in speech summarization for English or Japanese text and audio sources (Hori and Furui, 2003; Inoue et al., 2004; Koumpis and Renals, 2005; Maskey and Hirschberg, 2003; Maskey and Hirschberg, 2005). Some research efforts have focused on summarizing Mandarin sources (Chen et al., 2006; Huang et al., 2005), which are dependent on lexical features. Considering the difficulty in obtaining high quality transcriptions, some researchers proposed speech summarization systems with non-lexical features (Inoue et al., 2004; Koumpis and Renals, 2005; Maskey and Hirschberg, 2003; Maskey and Hirschberg, 2006). However, there does not exist any empirical study on speech summarization without lexical features for Manda</context>
<context position="2834" citStr="Inoue et al., 2004" startWordPosition="429" endWordPosition="432"> features, and compare acoustic and structural features against lexical features as predictors of summary sentences. In Section 2 we review previous work on broadcast news summarization. We describe the Mandarin broadcast news corpus on which our system operates in Section 3. In Section 4 we describe our summarizer and these features used in experiments. We set up our experiments and evaluate the results in Section 5, followed by our conclusion in Section 6. 2 Previous Work There have been many research efforts on speech summarization. Some methods dependent on lexical features are presented (Inoue et al., 2004; Chen et al., 2006; Huang et al., 2005). (Inoue et al., 2004) uses statistical methods to identify words to include in a summary, based on linguistic and acoustic/prosodic features of the Japanese broadcast news transcriptions; while (Chen et al., 2006) proposes the use of probabilistic latent topical information for extractive summarization of Mandarin spoken documents. (Huang et al., 2005) presents Mandarin spo213 Proceedings of NAACL HLT 2007, Companion Volume, pages 213–216, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics ken document summarization scheme using</context>
</contexts>
<marker>Inoue, Mikami, Yamashita, 2004</marker>
<rawString>A. Inoue, T. Mikami, and Y. Yamashita. 2004. Improvement of Speech Summarization Using Prosodic Information. Proc. of Speech Prosody.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Jing</author>
<author>R Barzilay</author>
<author>K McKeown</author>
<author>M Elhadad</author>
</authors>
<title>Summarization evaluation methods: Experiments and analysis. AAAI Symposium on Intelligent Summarization.</title>
<date>1998</date>
<contexts>
<context position="10173" citStr="Jing et al., 1998" startWordPosition="1622" endWordPosition="1625">he several-turn news corpus, described in Section 3, in our experiments. We use 70% of the corpus consisting of 3294 sentences as training set Table 1: Feature set Evaluation by F-measure Feature Set SR10% SR15% SR20% Ave Ac+St+Le .5961 .546 .5544 .5655 Ac+St .5888 .5489 .5562 .5646 St .5951 .5616 .537 .5645 Le .5175 .5219 .5329 .5241 Ac .3068 .4092 .4582 .3914 Baseline .21 .32 .43 .32 Ac: Acoustic; St: Structural; Le: Lexical and the remaining 1454 sentences as held-out test set, upon which our summarizer is tested. We measure our summarizer’s performance by precision, recall, and F-measure (Jing et al., 1998). We explain these metrics as follows: 2 x precision x recall F-Measure = (4) precision + recall In equation (2), (3) and (4), Sman is the sentence set of manual summaries or reference summaries; Ssum is the sentence set of predicted summaries provided by our summarizer. We have three versions of reference summaries based on summarization ratio(SR): 10%, 15% and 20% respectively. So we build three baselines referring to different versions of reference summaries. When using SR 10% summaries, we build the baselines by choosing the first 10% of sentences from each story. Our baseline results in F</context>
</contexts>
<marker>Jing, Barzilay, McKeown, Elhadad, 1998</marker>
<rawString>H. Jing, R. Barzilay, K. McKeown, and M. Elhadad. 1998. Summarization evaluation methods: Experiments and analysis. AAAI Symposium on Intelligent Summarization.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Koumpis</author>
<author>S Renals</author>
</authors>
<title>Automatic summarization of voicemail messages using lexical and prosodic features.</title>
<date>2005</date>
<journal>ACM Transactions on Speech and Language Processing (TSLP),</journal>
<volume>2</volume>
<issue>1</issue>
<contexts>
<context position="1507" citStr="Koumpis and Renals, 2005" startWordPosition="223" endWordPosition="226">cal features and our summarizer performs surprisingly well at the average F-measure of 0.3914 by using only acoustic features. These findings enable us to summarize speech without placing a stringent demand on speech recognition accuracy. 1 Introduction Speech summarization, a technique of extracting key segments that convey the main content from a spoken document or audio document, has become a new area of study in the last few years. There has been much significant progress made in speech summarization for English or Japanese text and audio sources (Hori and Furui, 2003; Inoue et al., 2004; Koumpis and Renals, 2005; Maskey and Hirschberg, 2003; Maskey and Hirschberg, 2005). Some research efforts have focused on summarizing Mandarin sources (Chen et al., 2006; Huang et al., 2005), which are dependent on lexical features. Considering the difficulty in obtaining high quality transcriptions, some researchers proposed speech summarization systems with non-lexical features (Inoue et al., 2004; Koumpis and Renals, 2005; Maskey and Hirschberg, 2003; Maskey and Hirschberg, 2006). However, there does not exist any empirical study on speech summarization without lexical features for Mandarin Chinese sources. In th</context>
</contexts>
<marker>Koumpis, Renals, 2005</marker>
<rawString>K. Koumpis and S. Renals. 2005. Automatic summarization of voicemail messages using lexical and prosodic features. ACM Transactions on Speech and Language Processing (TSLP), 2(1):1–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Maskey</author>
<author>J Hirschberg</author>
</authors>
<title>Automatic summarization of broadcast news using structural features.</title>
<date>2003</date>
<booktitle>Proceedings of Eurospeech</booktitle>
<contexts>
<context position="1536" citStr="Maskey and Hirschberg, 2003" startWordPosition="227" endWordPosition="230">rizer performs surprisingly well at the average F-measure of 0.3914 by using only acoustic features. These findings enable us to summarize speech without placing a stringent demand on speech recognition accuracy. 1 Introduction Speech summarization, a technique of extracting key segments that convey the main content from a spoken document or audio document, has become a new area of study in the last few years. There has been much significant progress made in speech summarization for English or Japanese text and audio sources (Hori and Furui, 2003; Inoue et al., 2004; Koumpis and Renals, 2005; Maskey and Hirschberg, 2003; Maskey and Hirschberg, 2005). Some research efforts have focused on summarizing Mandarin sources (Chen et al., 2006; Huang et al., 2005), which are dependent on lexical features. Considering the difficulty in obtaining high quality transcriptions, some researchers proposed speech summarization systems with non-lexical features (Inoue et al., 2004; Koumpis and Renals, 2005; Maskey and Hirschberg, 2003; Maskey and Hirschberg, 2006). However, there does not exist any empirical study on speech summarization without lexical features for Mandarin Chinese sources. In this paper, we construct our su</context>
<context position="3593" citStr="Maskey and Hirschberg, 2003" startWordPosition="540" endWordPosition="543">ased on linguistic and acoustic/prosodic features of the Japanese broadcast news transcriptions; while (Chen et al., 2006) proposes the use of probabilistic latent topical information for extractive summarization of Mandarin spoken documents. (Huang et al., 2005) presents Mandarin spo213 Proceedings of NAACL HLT 2007, Companion Volume, pages 213–216, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics ken document summarization scheme using acoustic, prosodic, and semantic information. Alternatively, some methods which are independent of lexical features are presented (Maskey and Hirschberg, 2003; Maskey and Hirschberg, 2006). (Maskey and Hirschberg, 2003) extracts structural information from audio documents to help summarization. (Maskey and Hirschberg, 2006) focuses on how to use acoustic information alone to help predict sentences to be included in a summary and shows a novel way of using continuous HMMs for summarizing speech documents without transcriptions. It is advantageous to build speech summarization models without using lexical features: we can summarize speech data without placing a stringent demand on the speech recognition accuracy. In this paper, we propose one such mo</context>
</contexts>
<marker>Maskey, Hirschberg, 2003</marker>
<rawString>S. Maskey and J. Hirschberg. 2003. Automatic summarization of broadcast news using structural features. Proceedings of Eurospeech 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Maskey</author>
<author>J Hirschberg</author>
</authors>
<title>Comparing lexical, acoustic/prosodic, structural and discourse features for speech summarization. Interspeech</title>
<date>2005</date>
<contexts>
<context position="1566" citStr="Maskey and Hirschberg, 2005" startWordPosition="231" endWordPosition="234">ell at the average F-measure of 0.3914 by using only acoustic features. These findings enable us to summarize speech without placing a stringent demand on speech recognition accuracy. 1 Introduction Speech summarization, a technique of extracting key segments that convey the main content from a spoken document or audio document, has become a new area of study in the last few years. There has been much significant progress made in speech summarization for English or Japanese text and audio sources (Hori and Furui, 2003; Inoue et al., 2004; Koumpis and Renals, 2005; Maskey and Hirschberg, 2003; Maskey and Hirschberg, 2005). Some research efforts have focused on summarizing Mandarin sources (Chen et al., 2006; Huang et al., 2005), which are dependent on lexical features. Considering the difficulty in obtaining high quality transcriptions, some researchers proposed speech summarization systems with non-lexical features (Inoue et al., 2004; Koumpis and Renals, 2005; Maskey and Hirschberg, 2003; Maskey and Hirschberg, 2006). However, there does not exist any empirical study on speech summarization without lexical features for Mandarin Chinese sources. In this paper, we construct our summarizer with acoustic and str</context>
</contexts>
<marker>Maskey, Hirschberg, 2005</marker>
<rawString>S. Maskey and J. Hirschberg. 2005. Comparing lexical, acoustic/prosodic, structural and discourse features for speech summarization. Interspeech 2005 (Eurospeech).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Maskey</author>
<author>J Hirschberg</author>
</authors>
<title>Summarizing Speech Without Text Using Hidden Markov Models.</title>
<date>2006</date>
<booktitle>Proc. NAACL.</booktitle>
<contexts>
<context position="1971" citStr="Maskey and Hirschberg, 2006" startWordPosition="290" endWordPosition="293">significant progress made in speech summarization for English or Japanese text and audio sources (Hori and Furui, 2003; Inoue et al., 2004; Koumpis and Renals, 2005; Maskey and Hirschberg, 2003; Maskey and Hirschberg, 2005). Some research efforts have focused on summarizing Mandarin sources (Chen et al., 2006; Huang et al., 2005), which are dependent on lexical features. Considering the difficulty in obtaining high quality transcriptions, some researchers proposed speech summarization systems with non-lexical features (Inoue et al., 2004; Koumpis and Renals, 2005; Maskey and Hirschberg, 2003; Maskey and Hirschberg, 2006). However, there does not exist any empirical study on speech summarization without lexical features for Mandarin Chinese sources. In this paper, we construct our summarizer with acoustic and structural features, which are independent of lexical features, and compare acoustic and structural features against lexical features as predictors of summary sentences. In Section 2 we review previous work on broadcast news summarization. We describe the Mandarin broadcast news corpus on which our system operates in Section 3. In Section 4 we describe our summarizer and these features used in experiments</context>
<context position="3623" citStr="Maskey and Hirschberg, 2006" startWordPosition="544" endWordPosition="547">ic/prosodic features of the Japanese broadcast news transcriptions; while (Chen et al., 2006) proposes the use of probabilistic latent topical information for extractive summarization of Mandarin spoken documents. (Huang et al., 2005) presents Mandarin spo213 Proceedings of NAACL HLT 2007, Companion Volume, pages 213–216, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics ken document summarization scheme using acoustic, prosodic, and semantic information. Alternatively, some methods which are independent of lexical features are presented (Maskey and Hirschberg, 2003; Maskey and Hirschberg, 2006). (Maskey and Hirschberg, 2003) extracts structural information from audio documents to help summarization. (Maskey and Hirschberg, 2006) focuses on how to use acoustic information alone to help predict sentences to be included in a summary and shows a novel way of using continuous HMMs for summarizing speech documents without transcriptions. It is advantageous to build speech summarization models without using lexical features: we can summarize speech data without placing a stringent demand on the speech recognition accuracy. In this paper, we propose one such model on Mandarin broadcast news</context>
</contexts>
<marker>Maskey, Hirschberg, 2006</marker>
<rawString>S. Maskey and J. Hirschberg. 2006. Summarizing Speech Without Text Using Hidden Markov Models. Proc. NAACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>