<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.765582">
Association for
Computational Linguistics
</title>
<sectionHeader confidence="0.837997666666667" genericHeader="method">
Author Index
to the Proceedings of
ANLP-NAACL 2000
</sectionHeader>
<subsectionHeader confidence="0.672841">
and the
Student Research Workshop
</subsectionHeader>
<note confidence="0.6755465">
April 29--May 4, 2000
Seattle, Washington, USA
</note>
<title confidence="0.602948333333333">
Association for
Computational Linguistics
6th 13 Applied Natural Language Processing
Conference
1st Meeting of the North American Chapter of the
Association for Computational Linguistics
</title>
<note confidence="0.532881">
Proceedings of the Conferences
and
Proceedings of the ANLP-NAACL 2000
Student Research Workshop
April 29—May 4, 2000
Seattle, Washington, USA
</note>
<footnote confidence="0.897653">
Published by the Association for Computational Linguistics
http://www.acl.web.org/
Distributed by Morgan Kaufmann Publishers
http://www.tnicp.com
</footnote>
<note confidence="0.760445">
Production and Manufacturing by
Omipress, Inc.
</note>
<figure confidence="0.8977348">
Post Office Box 7214
Madison, WI 53707-7314
Copyright 0 2000 Association of Computational Linguistics
Order copies of this and other ACL publications from:
Morgan Kaufmann Publishers
San Francisco
http://www.mkp.com
orders@m1cp.com
1-800-745-7323
1-800-814-6418 (fax)
</figure>
<footnote confidence="0.599449">
ANLP-NAACL 2000
ISBN: 1-55860-704-8
</footnote>
<page confidence="0.659801">
II
</page>
<sectionHeader confidence="0.758718" genericHeader="method">
Author Index
</sectionHeader>
<table confidence="0.78104047761194">
Section 1: Applied Natural Language Processing Conference (ANLP)
Abney, Steven 296 Kashioka, Hideki 37
Amble, Tore 1 Kittredge, 60
Aone, Chinatsu 76 Klavans, Judith L. 302
Bagga, Amit 29 Korelsky, Tanya 60
Biermann, Alan W. 105 Kreuz, Roger 90
Boisen, Sean 316 Kuhns, Robert J. 262
Bookman, Lawrence A. 262 Langlais, Philippe 135
Brants, Thorsten 224 Lapalme, Guy 135
Braun, Christian 239 Lavoie, Benoit 60
Broker, Norbert 325 Li, Wei 166, 247
Buckley, Chris 180 Maiorano, Steven J. 142
Busemann, Stephan 158 Martin, Paul 262
Cahill, L. 119 Matsumoto, Yuji 232
Cancedda, Nicola 204 McGee, David 331
Cardie, Claire 180 Mellish, C 119
Chen, Jiang 21 Miller, David 316
Chu-Carroll, Jennifer 97 Moldovan, Dan 268
Clow, Josh 331 Neumann, Ginter 239
Cohen, Philip 331 Ng, Vincent 180
Collins, Michael 296 Nie, Jian-Yun 21
Dahlback, Nils 44 Niu, Cheng 247
Doran, C. 119 Paggio, Patrizia 255
Evans, David K. 302 Paiva, D. 119
Evans, R 119 Pierce, David 180
Flank, Sharon 13 Piskorski, Jakub 239
Foster, George 135 Prager, John 150
Frankie James 112 Radev, Dragomir R. 150
Freedman, Reva 52 Rajan, Jayant V 188
Fulkerson, Michael S. 105 Rajan, Sonya 90
Gaizauskas, Robert 84, 290 Rambow, Owen 60
Girju, Roxana 268 Ramos-Santacruz, Mila 76
Graesser, Art 90 Rayner, Manny 112
Green, Stephen 262 Reape, M 119
Grishman, Ralph 282 Rindflesch, Thomas C. 188
Haji, Jan 7 Roman G Arens 158
Harabagiu, Sanda M. 142 Rus, Vasile 268
Hockey, Beth Ann 112 Samn, Valerie 150
Houston, Ann 262 Samuelsson, Christer 204
Hric, Jan 7 Schmeier, Sven 158
Hunter, Lawrence 188 Schwartz, Richard 316
Huttunen, Silja 282 Scott, D. 119
Jing, Hongyan 310 Singhal, Amit 296
Jonsson, Arne 44 Srihari, Rohini 166, 247
Jutras, Jean-Marc 127 Stallard, David 68
Kambhatla, Nanda 210 Stevenson, Mark 84, 290
Karnavat, Ashish 90 Stone, Rebecca 316
All
Strzalkowski, Tomek 29
Sumita, Eiichiro 37
Tapanainen, Pasi 282
Tipper, N. 119
Toole, Janine 173
Vladislav Kuboil 7
Wacholder, Nina 302
Wasson, Mark 276
Weischedel, Ralph 316
Wiemer-Hastings, Katja 90
Wiemer-Hastings, Peter 90
Wise, G. Bowden 29
Woods, William A. 218, 262
Yamada, Setsuo 37
Yamashita, Tatsuo 232
Yangarber, Roman 282
Yoon, Juntae 196
Zadrozny, Wlodek 210
Section 2: North American Chapter of the Association for Computational Linguistics
</table>
<figure confidence="0.990664359550562">
(NAACL)
Alonge, Antonietta 42
Ando, Rie Kubota 241
Bertagna, Francesca 42
Blaheta, Don 234
Bouma, Gosse 303
Brill, Eric 34
Calzolari, Nicoletta 42
Carlson, Lynn 9
Carroll, John 162
Cavalli-Sforza, Violetta 86
Charniak, Eugene 132, 234
Chodorow, Martin 140
Choi, Freddy Y.Y. 26
Chu-Carroll, Jennifer 202
Eskin, Eleazar 148
Even-Zohar, Yair 124
Fillmore, Charles J. 56
Fox, Heidi 226
Fujio, Masakazu 110
Gardent, Claire 319
Gorin, Allen 210
Hahn, Udo 327
Hajie, Jan 94
Harper, M.P. 102
Heeman, Peter A 280
Helzerman, R.A. 102
Henderson, John C. 34
Hermjakob, Ulf 118
Hirschberg, Julia B. 218
Jing, Hongyan 178
Johnson, Christopher 56
Johnson, M.T. 102
Johnson, Mark 154
Kondrak, Grzegorz 288
Konrad, Karsten 319
Langkilde, Irene 170, 210
Leacock, Claudia 140
Lee, Lillian 241
Lin, Dekang 78
Litman, Diane 210, 218
Marcu, Daniel 9
Matheson, Colin 1
Matsumoto, Yuji 110
McCarthy, Diana 256
McKeown, Kathleen R. 178
Mikheev, Andrei 264
Miller, Scott 226
Mitamura, Teruko 86
Moore, Robert C 249
Nederhof, Mark-Jan 272
Nickerson, Jill Suzanne 202
Nishiokayama, Shigeyuki 110
Oepen, Stephan 162
Pantel, Patrick 78
Pedersen, Ted 63
Poe sio, Massimo 1
Pogodalla, Sylvain 70
Ramshaw, Lance 226
Ratnaparkhi, Adwait 194
Riezler, Stefan 154
Romacker, Martin 327
Rosé, Carolyn P. 311
Roth, Dan 124
Roventini, Adriana 42
Satta, Giorgio 272
Soudi, Abdelhadi 86
Strube, Michael 18
Swerts, Marc 218
Tjong Kim Sang, Erik F. 50
Traum, David 1
Utsuro, Takehito 110
Waibel, Alex 186
Walker, Marilyn 210
Walther, Markus 296
Wang, W. 102
Ward, Karen 280
Al2
Watanabe, Maki 9 Wright, Jerry 210
Weischedel, Ralph 226 Zampolli, Antonio 42
White, C.M. 102 Zechner, Klaus 186
Wolters, Maria 18
Section 3: ANLP-NAACL 2000 Student Research Workshop (SRW)
Cheng, Hua 1 Gojenola, Koldo 24
Czuba, Krzysztof 7 Higgins, Derrick 30
Diamond, Ted 35 Liu, Mary Xiaoyong 35
Diekema, Anne R. 35 Oates, Sarah Louise 41
Garibay, Ivan I. 13 Oronoz, Maite 24
Ghorbel, Hatem 19 Pallotta, Vincenzo 19
</figure>
<page confidence="0.661583">
Al3
</page>
<subsectionHeader confidence="0.529374">
Preface
</subsectionHeader>
<bodyText confidence="0.992722457142857">
The year 2000 marks the launch of the North American
chapter of the Association for Computational Linguistics
(NAACL). The ACL Executive committee under the
leadership of Phil Cohen used this as an opportunity to bring
industry and researchers together to explore the full spectrum
of computational linguistics and natural language processing
by planning a joint conference, combining the 6th Applied
Natural Language Processing Conference (ANLP) and the
1st Conference of NAACL. ANLP-NAACL2000 marks not
only the first major ACL sponsored conference of the new
millennium, but reflects a significant change in the field, as
we see speech and language applications leave the laboratory
and enter every day use.
The technical program covers all facets of the field, from
theory and methodology to its application in commercial
software. We chose to have two independent program chairs
so that papers from each of these two perspectives could be
evaluated independently and they appear in separate sections
of the proceedings. Janyce Wiebe, New Mexico State
University, was the NAACL Program Chair and Sergei
Nirenburg, also from New Mexico State University, was the
ANLP Program Chair. I would like to thank them and their
program committees and teams of reviewers, whose hard
work produced an exciting program with three parallel
sessions, reflecting the breadth of quality research and
application development being done throughout the world.
We were honored to have as invited speakers two industry
leaders: Dave Nagel, President, AT&amp;T Laboratories and
AT&amp;T Chief Technical Officer, speaking on &amp;quot;Voice access
to information&amp;quot;, and Rick Rashid, Vice President, Microsoft
Research, speaking on &amp;quot;The Future - It isn&apos;t what it used to
be&amp;quot;. From the academic community, Leonard Talmy, State
University of New York at Buffalo, an internationally
recognized researcher in cognitive science, speaking on
&amp;quot;How Language Structures Concepts&amp;quot;. These plenary
sessions have shown us how far the community has come in
bringing speech and language to the marketplace and to
remind us of the complexity of language and its relationship
to human cognition.
As is traditional at ACL conferences, the program goes
beyond the presentation of technical papers and plenary
sessions. There are also tutorials aimed at helping
participants broaden their knowledge, workshops for
exploring an area in depth, demonstrations to show the
software implementations behind the theories, and exhibits to
display the commercial products that have come out of the
research, much of which was presented at past ACLs. I
would like to thank the Tutorial Chair: Jennifer Chu Carroll
(Lucent Technologies), Workshop Chair: Scott Miller
(BBN), Demonstrations Chair: Jeff Reynar (Microsoft) and
Exhibits Chair: Deborah Dahl (Unisys), all of whom
composed quality programs.
One of the most valuable aspects of ACL conferences is the
opportunity it offers to students, who can get a broad
perspective on the field and meet the people whose papers
they read in their courses. They also have the opportunity
to present their own research, both in the main sessions
and in special student sessions designed to help those in
the early stages of their research. This year, we tried a
new approach with a Student Research Workshop held
before the conference with panelists to provide feedback
to students, for which we received NSF funding from the
Knowledge and Cognitive Systems Program under
Ephraim Glinert. I would like to thank Committee
members Donna Byron (University of Rochester) and
Peter Vanderheyden (University of Waterloo), Co-Chairs,
and Mary Harper (Purdue University), Faculty Advisor
and NSF Principal Investigator and all of the reviewers
who contributed to an excellent program and provided
feedback to the students on their research. I would also
like to thank the students who submitted papers and
attended the workshop. They are the future of our
organization.
Rick Wojcik (Boeing) as Local Arrangements Chair took
care of the myriad of arrangements that go into an event
of this size. Kathy McCoy, Secretary-Treasurer of the
ACL, and Priscilla Rasmussen, ACL Business Manager,
provided unending support in the planning, decision
making, and execution of all of the arrangements. Mark
Maybury (Mitre), Publicity Chair, expanded the number
of places we advertise the conference to help widen our
audience. June Santeusanio and Russell Kenyon from
GTE created and updated a terrific web site, bringing the
information about the conference to a central place.
Russell developed the on-line registration form and
provided support throughout the registration process.
I would especially like to thank Gary Coen (Boeing), who
was the Sponsorship Chair, and all of the commercial
companies who contributed to the conference. We had the
largest level of industry support of any ACL conference
in the past. Microsoft, Boeing, Sun, Intel (China), Xerox
PARC, Logos, Conversa, and General Electric all
contributed funds to support various events, allowing us
to have a commercial grade conference at a hotel facility
while keeping the conference fees at their usual level to
accommodate academic budgets. GTE (BBN),
Answerlogic, IBM, and Inxight provided scholarships to
allow more students to attend the conference.
There are many more people who deserve thanks for
contributing in one way or another. ACL is an all
volunteer organization and it is a credit to everyone who
participates that we can put on an event of this size and
scope, benefiting everyone who attends through the
exchange of ideas and inspiration we get from seeing the
leading edge of the field.
</bodyText>
<footnote confidence="0.805635">
Marie Meteer
General Chair, ANLP-NAACL 2000
April 2000
</footnote>
<figure confidence="0.987705949152543">
III
04
0
0
4./..;
114
to
en
IL;
..is
O
0.4 E
0 a
0 o
1.)
AA CZ
40=
-6
tN1 4-6`&amp;quot; oo 0 g (xl
t-i
a 6 Ft, 6
z
z
2
% o =
ao
.—
—rw r.o2 o t
O o
.1.i E--&apos;
es ..
7:4 .E.
.,...
L., nz cd to. o
x › a
0 0
._c) 0 ,N4
2
...., 00 ,
..-■ ccs ,.= —
at
tle ad gs ,
,.... 0 g
0
- ,
0 0
as ti.) O
A, 0
0 A
ez
4) ..-.
= tul
o
o
-o
a.
6
0
CONFERENCE PROGRAM
</figure>
<table confidence="0.980830705882353">
TUTORIALS, Saturday 29 April 2000, 8:30AM-5:00PM
Session 3 ANLP NAACL
PRELIMINARY PROGRAM ANLP c4 BusTUC-A Natural Language Bus Route Machine Translation Between Very Close Cross-Language Multimedia Information Automatic Construction of Parallel
o Oracle Languages Retrieval English-Chinese Corpus for Cross-
.2 &apos;Amble Tore Jan Hajic, Jan Hric, Vladislav Kuban Sharon Flank language Information Retrieval
a) Jiang Chen, lian-Yun Nie
z
II
VI
ANLP/NAACL NAACL Introductory Remarks Session 1 Modelling Grounding and Discourse The Automatic Translation of Discourse A Probabilistic Genre-independent Model of 1 &apos;S NAACL
TECHNICAL SESSIONS Obligations Using Update Rules Structures Pronominalization Advances in domain independent linear text 44
Cohn Matheson, David Traum, Massimo Poesio Panic! Marco, Lynn Carlson, Maki Watanabe Michael Strube, Maria Wolters egmentation C4
reddy Y.Y. Choi IZI
Monday, I&apos;-) 8 C tt-1 tt- o
May 1 -1- kt-1 cir■ ,--. .1-
88 c-1 6 6
ci —
</table>
<page confidence="0.258295">
V
</page>
<figure confidence="0.940011487804878">
Benoit Lavoie
Voice Access to Information
en
en
4t:
Cr)
C&apos;.&apos;en
Cr)
en
c&apos;e;
vi
•tt 0
Ci)
It) Ln
&apos;1? C
ar)
C..D
41 •■■•
14 tA
&amp;quot;0 0
O0
.12
0.) 0
g 10 ix
0
x E • o
O ea 41. E
O. cn
col =
..-■ .... ul
7. ,... 0 CI) ry
C 6) C 0.) ›.)
Co) .2 S
5 =
,,.) ,,g■ 8&apos;
...
• a 4 00 4/ ...
.... &gt;
c oo to n
c c 0 0
&amp;quot;&apos; ° §
to T,
E -N, r 1
0. 4a, c)
.c., ab i i al &amp;quot; =. - a 9 , . . 9 • . 8▪ °
14 4 E-
bL
0
CA
4-■
A
as1
Cr.
1r)
In
co
c0
ANLP/NAACL TECHNICAL SESSIONS
14;
tct
c
a c.• 1.1
d
&amp;quot;a
.tu Fa• &apos;
rco&amp;quot;
VI 0
&lt;IC a
NAACL BUSINESS MEETING
In
In
In
ix
0 0
1r)
c■i
41:
tr)
Cr)
TUTORIALS
Saturday 29 April 2000, 8:30AM-5:00PM
Information Retrieval, 8:30AM-12:00PM
</figure>
<figureCaption confidence="0.064425">
James Allan, University of Massachusetts, Amherst
</figureCaption>
<bodyText confidence="0.9375195">
This tutorial will examine the role of Natural Language Processing in Information Retrieval (IR). It will start with a
historical overview of how NLP has been used and abused over the 40 years of IR research, attempting to illustrate
why distrust of NLP was rampant in the IR community. We will next explore reasons that NLP might have been
doomed to failure in early IR contexts--where basic IR techniques already captured some of what NLP might have
offered, and NLP techniques with even small error rates were therefore unable to offer more. We will then focus on
NLP/IR success stories--both past and present--that show how NLP can be (and has been) successfully used in some
applications. The last portion of the tutorial will focus on very recent applications of NLP for retrieval and
organization purposes. We will discuss the use of NLP and IR as part of Web applications, and as applied to Web
pages. The tutorial will also include a discussion of the exciting Question and Answer track from TREC-8 (1999).
That task results showed that a combination of IR and NLP was highly effective, creating a great opportunity for
future collaboration between the two fields.
The State of the Art in Language Modeling, 8:30AM-12:00PM
Joshua Goodman, Microsoft Research
This tutorial will cover the state-of-the-art in language modeling. The goal of language models is to predict the
probability of words; this is directly useful for speech recognition, handwriting recognition, spelling correction, and
other areas. Because language modeling is one of the most explored areas of statistical modeling, the state of the art
is relatively advanced. Techniques from language modeling may be of interest to anyone pursuing probabilistic
modeling, including those interested in statistical parsing, information retrieval, machine translation, and
compression. The tutorial should be accessible to anyone with an elementary knowledge of probability.
The most basic language models -- n-gram models -- essentially just count occurrences of words in training data. I
will describe six improvements over this simple baseline: smoothing, caching, skipping, sentence-mixture models,
clustering, and parsing-based models.
1) Smoothing addresses the problem of data sparsity: there is rarely enough data to accurately estimate the
parameters of a language model. Smoothing gives a way to combine less specific, more accurate information with
more specific, but noisier data. I will describe two classic techniques: deleted interpolation and Katz (or Good-
Turing) smoothing, and one recent technique, Modified Kneser-Ney smoothing, which is the best available.
</bodyText>
<listItem confidence="0.993479">
2) Caching is a widely used technique that uses the observation that recently observed words are likely to occur
again. Models from recently observed data can be combined with more general models to improve performance.
3) Skipping models use the observation that even words that are not directly adjacent to the target word contain
useful
information.
4) Sentence-mixture models use the observation that there are many different kinds of sentences. By modeling each
sentence type separately, performance is improved.
5) Clustering is one of the most useful language modeling techniques. Words can be grouped together into clusters
through various automatic techniques; then the probability of a cluster can be predicted instead of the probability of
the word. Clustering can be used to make smaller models or better performing ones.
6) All of the previous techniques ignore the structure of language. Recently, Ciprian Chelba has shown that
techniques from statistical parsing can be used for improved models.
</listItem>
<bodyText confidence="0.920873833333333">
Finally, I will also talk about some practical aspects of language modeling. I will describe how freely available, off-
the-shelf tools can be used to easily build language models, and how to use methods such as count cutoffs to
compress language models.
xi
Those who attend the tutorial should walk away with a broad understanding of the current techniques, and the
background needed to either build their own language models, or to apply some of these techniques to other fields.
</bodyText>
<note confidence="0.5289805">
Finite-State Morphology/Phonology:Theory,Applications,and Recent Developments,
1:30PM-5:00PM
</note>
<bodyText confidence="0.967876545454546">
George Kiraz, Lucent Technologies Bell Labs
Morphology and phonology are crucial components in any large scale NLP and/or speech system. Finite-state (FS)
approaches to morphology/phonology are the state-of-the-art in the field; they aim at modeling the
morphology/phonology of language with computational devices whose computational power does not exceed that
of FS machines. Such machines are of interest because they are easy to implement, fast to run and mathematically
elegant. The purpose of this tutorial is to give a comprehensive introduction to the field of computational
morphology, with emphasis on recent developments and practical techniques to build real systems.
The first hour of the tutorial will be introductory, bringing all the participants to a common understanding of the
prerequisites involved: (1) morphology from a linguistics perspective, (2) automata theory from a computer-science
perspective, and (3) how the two fields make up &apos;FS computational morphology&apos;.
The second hour will concentrate on the theory of FS morphology. The various popular formalisms and notations
will be explained. Algorithms for compiling formalisms into FS machines (i.e., rule compilers) will be detailed with
comprehensive step-by-step examples. Algorithms for interpreting the formalisms directly will be outlined. Recent
developments in the field will be emphasized.
The third hour will concentrate on building practical applications. An introduction to the available tools (and how to
build such tools) will be given. This will be followed by building simple grammars, moving to more complex
grammars, including challenging morphological and morphotactic phenomena (e.g., long-distance dependencies,
heavy agglutinative morphology, reduplications, Semitic root-and-pattern, etc.). The tutorial will demonstrate how
various linguistic descriptions of morphology and phonology (segmental, Autosegmental, prosodic, templatic,
optimality theory, etc.) can be modeled with FS approaches.
The tutorial will end with &apos;Open Questions&apos; detailing some of the issues that await research.
Machine Translation, 1:30PM-5:00PM
Kevin Knight, USCASI
Mechanical translation of one human language into another is one of the oldest applications of computer science,
with roots going back to the 1940s and 1950s. It did not work very well then, and it does not work very well now.
But, people use it all the time! MT programs can translate email, web pages, and online chat; with human post
editing, they can translate corporate and government documents. There has also been an explosion in the number of
language pairs available. The major force that continues to drive machine translation research is the idea that if it
did work, people would use it a lot more. MT also provides a gauge of the breadth and depth of our scientific
understanding of human language, including both interpretation and generation aspects.
This tutorial will cover a number of practical and theoretical topics. Most of the tutorial will consist of an in-depth
look at several radically different types of MT systems. This will include both special-purpose and general-purpose
MT. We will discuss how various MT systems are constructed, and what their strengths and weaknesses are. We
will describe the workings of an interlingua-based system, and we will give a gentle yet rigorous description of a
corpus-based statistical MT system. We will go through examples during the tutorial and also distribute small-scale
(one-hour to eight-hour) assignments that can be done after the tutorial. These assignments demonstrate basic
principles without requiring extensive programming.
We will also discuss the evaluation of MT systems, the economics of machine translation (including existing
products and services), and the management of both source-language and target-language texts. This last topic
includes ways of authoring documents to reduce ambiguity (&amp;quot;controlled language&amp;quot;), ways of preserving unresolved
ambiguities in output text, and issues concerning pre-editing and post-editing of documents.
xii
Finally, we will briefly discuss the future of MT, taking special account of current research in integrating MT with
other natural language technologies (cross-language information retrieval, speech-to-speech translation,
</bodyText>
<reference confidence="0.931636606060606">
multilingual summarization, etc). We will also look at how current research in NLP is likely to affect MT in the
future.
Syllabus:
1. Introduction to MT. Why is MT important? History of MT research and commercial development. General-
purpose vs. special-purpose MT. Architectures that have been used for MT.
2. Building MT Systems. Syntactic transfer: building a lexicon, transfer rules. Interlingua-based MT: domain-
specific interlingua design, parsing, semantic interpretation, generation. Direct transfer: statistical algorithms trained
on bilingual corpora, text alignment, transliteration, example-based MT.
3. Managing the Input, Managing the Output. Pre-editing. Reducing ambiguity through controlled-language source
text. Post-editing. Ambiguity preservation.
4. Evaluation of MT Systems. Why it&apos;s hard. Metrics that have been proposed and used. Strengths and weaknesses.
5. The Economics of MT. Products and services available.
6. The Future of MT. Integrating MT with other natural language technologies: cross-language information
retrieval, speech-to-speech MT, summarizing foreign-language documents. How current NLP research bears on
MT.
Table of Contents
ANLP-NAACL 2000 Preface
Marie Meteer, General Chair iii
Conference Prognun
Tutorial Schedule xi
Section 1: Applied Natural Language Processing Conference (ANLP 2000)
ANLP 2000 Preface and List of Reviewers
Sergei Nirenburg, Program Committee Chair ANLPi
ANLP 2000 Proceedings Table of Contents ANLPiii
Section 2: North American Chapter of the Association for Computational
Linguistics (NAACL 2000)
NAACL 2000 Preface and List of Reviewers
Janyce Wiebe, Program Committee Chair NAACLi
NAACL 2000 Proceedings Table of Contents NAACLv
Section 3: ANLP-NAACL 2000 Student Research Workshop (SRW)
SRW Preface and List of Reviewers
Donna Byron and Peter B. Vanderheyden, Program Committee Chairs SRWi
SRW Proceedings Table of Contents SRWiii
</reference>
<sectionHeader confidence="0.973664" genericHeader="method">
Author Index All
</sectionHeader>
<page confidence="0.46768">
XV
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.526494714285714">Association for Computational Linguistics Author Index to the Proceedings of ANLP-NAACL 2000 and the Student Research Workshop</note>
<date confidence="0.769287">April 29--May 4, 2000</date>
<address confidence="0.866779">Seattle, Washington, USA</address>
<note confidence="0.9078121">Association for Computational Linguistics Applied Natural Language Processing Conference 1st Meeting of the North American Chapter of the Association for Computational Linguistics Proceedings of the Conferences and Proceedings of the ANLP-NAACL 2000 Student Research Workshop</note>
<date confidence="0.863843">April 29—May 4, 2000</date>
<address confidence="0.95155">Seattle, Washington, USA</address>
<note confidence="0.997207">Published by the Association for Computational Linguistics</note>
<web confidence="0.97208">http://www.acl.web.org/</web>
<note confidence="0.860202">Distributed by Morgan Kaufmann Publishers</note>
<web confidence="0.7567">http://www.tnicp.com</web>
<author confidence="0.584815">Production</author>
<author confidence="0.584815">Manufacturing by</author>
<affiliation confidence="0.986443">Omipress, Inc.</affiliation>
<address confidence="0.9971645">Post Office Box 7214 Madison, WI 53707-7314</address>
<note confidence="0.9744405">Copyright 0 2000 Association of Computational Linguistics Order copies of this and other ACL publications from:</note>
<title confidence="0.676444">Morgan Kaufmann Publishers</title>
<author confidence="0.80188">San Francisco</author>
<email confidence="0.7047425">http://www.mkp.comorders@m1cp.com</email>
<phone confidence="0.8553075">1-800-745-7323 1-800-814-6418 (fax)</phone>
<date confidence="0.623982">2000</date>
<note confidence="0.697593833333333">ISBN: 1-55860-704-8 II Author Index Section 1: Applied Natural Language Processing Conference (ANLP) Abney, Steven 296 Kashioka, Hideki 37 Amble, Tore 1 Kittredge, 60 Aone, Chinatsu 76 Klavans, Judith L. 302 Bagga, Amit 29 Korelsky, Tanya 60 Biermann, Alan W. 105 Kreuz, Roger 90 Boisen, Sean 316 Kuhns, Robert J. 262 Bookman, Lawrence A. 262 Langlais, Philippe 135 Brants, Thorsten 224 Lapalme, Guy 135</note>
<address confidence="0.7209202">Braun, Christian 239 Lavoie, Benoit 60 Broker, Norbert 325 Li, Wei 166, 247 Buckley, Chris 180 Maiorano, Steven J. 142 Busemann, Stephan 158 Martin, Paul 262 Cahill, L. 119 Matsumoto, Yuji 232 Cancedda, Nicola 204 McGee, David 331 Cardie, Claire 180 Mellish, C 119 Chen, Jiang 21 Miller, David 316 Chu-Carroll, Jennifer 97 Moldovan, Dan 268 Clow, Josh 331 Neumann, Ginter 239 Cohen, Philip 331 Ng, Vincent 180 Collins, Michael 296 Nie, Jian-Yun 21 Dahlback, Nils 44 Niu, Cheng 247 Doran, C. 119 Paggio, Patrizia 255 Evans, David K. 302 Paiva, D. 119 Evans, R 119 Pierce, David 180 Flank, Sharon 13 Piskorski, Jakub 239 Foster, George 135 Prager, John 150 Frankie James 112 Radev, Dragomir R. 150 Freedman, Reva 52 Rajan, Jayant V 188 Fulkerson, Michael S. 105 Rajan, Sonya 90 Gaizauskas, Robert 84, 290 Rambow, Owen 60 Girju, Roxana 268 Ramos-Santacruz, Mila 76 Graesser, Art 90 Rayner, Manny 112 Green, Stephen 262 Reape, M 119 Grishman, Ralph 282 Rindflesch, Thomas C. 188 Haji, Jan 7 Roman G Arens 158 Harabagiu, Sanda M. 142 Rus, Vasile 268 Hockey, Beth Ann 112 Samn, Valerie 150 Houston, Ann 262 Samuelsson, Christer 204 Hric, Jan 7 Schmeier, Sven 158 Hunter, Lawrence 188 Schwartz, Richard 316 Huttunen, Silja 282 Scott, D. 119 Jing, Hongyan 310 Singhal, Amit 296 Jonsson, Arne 44 Srihari, Rohini 166, 247 Jutras, Jean-Marc 127 Stallard, David 68 Kambhatla, Nanda 210 Stevenson, Mark 84, 290 Karnavat, Ashish 90 Stone, Rebecca 316 All Strzalkowski, Tomek 29 Sumita, Eiichiro 37 Tapanainen, Pasi 282 Tipper, N. 119 Toole, Janine 173 Vladislav Kuboil 7 Wacholder, Nina 302 Wasson, Mark 276 Weischedel, Ralph 316 Wiemer-Hastings, Katja 90 Wiemer-Hastings, Peter 90 Wise, G. Bowden 29 Woods, William A. 218, 262 Yamada, Setsuo 37 Yamashita, Tatsuo 232 Yangarber, Roman 282</address>
<note confidence="0.681881333333333">Yoon, Juntae 196 Zadrozny, Wlodek 210 Section 2: North American Chapter of the Association for Computational Linguistics (NAACL) Alonge, Antonietta 42 Ando, Rie Kubota 241</note>
<address confidence="0.94783348">Bertagna, Francesca 42 Blaheta, Don 234 Bouma, Gosse 303 Brill, Eric 34 Calzolari, Nicoletta 42 Carlson, Lynn 9 Carroll, John 162 Cavalli-Sforza, Violetta 86 Charniak, Eugene 132, 234 Chodorow, Martin 140 Choi, Freddy Y.Y. 26 Chu-Carroll, Jennifer 202 Eskin, Eleazar 148 Even-Zohar, Yair 124 Fillmore, Charles J. 56 Fox, Heidi 226 Fujio, Masakazu 110 Gardent, Claire 319 Gorin, Allen 210 Hahn, Udo 327 Hajie, Jan 94 Harper, M.P. 102 Heeman, Peter A 280 Helzerman, R.A. 102 Henderson, John C. 34 Hermjakob, Ulf 118 Hirschberg, Julia B. 218 Jing, Hongyan 178 Johnson, Christopher 56 Johnson, M.T. 102 Johnson, Mark 154 Kondrak, Grzegorz 288 Konrad, Karsten 319 Langkilde, Irene 170, 210 Leacock, Claudia 140 Lee, Lillian 241 Lin, Dekang 78 Litman, Diane 210, 218 Marcu, Daniel 9 Matheson, Colin 1 Matsumoto, Yuji 110 McCarthy, Diana 256 McKeown, Kathleen R. 178 Mikheev, Andrei 264 Miller, Scott 226 Mitamura, Teruko 86 Moore, Robert C 249 Nederhof, Mark-Jan 272 Nickerson, Jill Suzanne 202 Nishiokayama, Shigeyuki 110</address>
<note confidence="0.673449625">Oepen, Stephan 162 Pantel, Patrick 78 Pedersen, Ted 63 Poe sio, Massimo 1 Pogodalla, Sylvain 70 Ramshaw, Lance 226 Ratnaparkhi, Adwait 194 Riezler, Stefan 154</note>
<address confidence="0.794954375">Romacker, Martin 327 Rosé, Carolyn P. 311 Roth, Dan 124 Roventini, Adriana 42 Satta, Giorgio 272 Soudi, Abdelhadi 86 Strube, Michael 18 Swerts, Marc 218 Tjong Kim Sang, Erik F. 50 Traum, David 1 Utsuro, Takehito 110 Waibel, Alex 186 Walker, Marilyn 210 Walther, Markus 296 Wang, W. 102 Ward, Karen 280</address>
<note confidence="0.8019035">Al2 Watanabe, Maki 9 Wright, Jerry 210 Weischedel, Ralph 226 Zampolli, Antonio 42 White, C.M. 102 Zechner, Klaus 186 Wolters, Maria 18 3: ANLP-NAACL 2000 Student Research (SRW) Cheng, Hua 1 Gojenola, Koldo 24 Czuba, Krzysztof 7 Higgins, Derrick 30 Diamond, Ted 35 Liu, Mary Xiaoyong 35 Diekema, Anne R. 35 Oates, Sarah Louise 41 Garibay, Ivan I. 13 Oronoz, Maite 24 Ghorbel, Hatem 19 Pallotta, Vincenzo 19 Al3 Preface The year 2000 marks the launch of the North American chapter of the Association for Computational Linguistics</note>
<abstract confidence="0.959153922330097">(NAACL). The ACL Executive committee under the leadership of Phil Cohen used this as an opportunity to bring industry and researchers together to explore the full spectrum of computational linguistics and natural language processing by planning a joint conference, combining the 6th Applied Natural Language Processing Conference (ANLP) and the 1st Conference of NAACL. ANLP-NAACL2000 marks not only the first major ACL sponsored conference of the new millennium, but reflects a significant change in the field, as we see speech and language applications leave the laboratory and enter every day use. The technical program covers all facets of the field, from theory and methodology to its application in commercial software. We chose to have two independent program chairs so that papers from each of these two perspectives could be evaluated independently and they appear in separate sections of the proceedings. Janyce Wiebe, New Mexico State University, was the NAACL Program Chair and Sergei Nirenburg, also from New Mexico State University, was the ANLP Program Chair. I would like to thank them and their program committees and teams of reviewers, whose hard work produced an exciting program with three parallel sessions, reflecting the breadth of quality research and application development being done throughout the world. We were honored to have as invited speakers two industry leaders: Dave Nagel, President, AT&amp;T Laboratories and AT&amp;T Chief Technical Officer, speaking on &amp;quot;Voice access to information&amp;quot;, and Rick Rashid, Vice President, Microsoft Research, speaking on &amp;quot;The Future - It isn&apos;t what it used to be&amp;quot;. From the academic community, Leonard Talmy, State University of New York at Buffalo, an internationally recognized researcher in cognitive science, speaking on &amp;quot;How Language Structures Concepts&amp;quot;. These plenary sessions have shown us how far the community has come in bringing speech and language to the marketplace and to remind us of the complexity of language and its relationship to human cognition. As is traditional at ACL conferences, the program goes beyond the presentation of technical papers and plenary sessions. There are also tutorials aimed at helping participants broaden their knowledge, workshops for exploring an area in depth, demonstrations to show the software implementations behind the theories, and exhibits to display the commercial products that have come out of the research, much of which was presented at past ACLs. I would like to thank the Tutorial Chair: Jennifer Chu Carroll (Lucent Technologies), Workshop Chair: Scott Miller (BBN), Demonstrations Chair: Jeff Reynar (Microsoft) and Exhibits Chair: Deborah Dahl (Unisys), all of whom composed quality programs. One of the most valuable aspects of ACL conferences is the opportunity it offers to students, who can get a broad perspective on the field and meet the people whose papers they read in their courses. They also have the opportunity to present their own research, both in the main sessions and in special student sessions designed to help those in the early stages of their research. This year, we tried a new approach with a Student Research Workshop held before the conference with panelists to provide feedback to students, for which we received NSF funding from the Knowledge and Cognitive Systems Program under Ephraim Glinert. I would like to thank Committee members Donna Byron (University of Rochester) and Peter Vanderheyden (University of Waterloo), Co-Chairs, and Mary Harper (Purdue University), Faculty Advisor and NSF Principal Investigator and all of the reviewers who contributed to an excellent program and provided feedback to the students on their research. I would also like to thank the students who submitted papers and attended the workshop. They are the future of our organization. Rick Wojcik (Boeing) as Local Arrangements Chair took care of the myriad of arrangements that go into an event of this size. Kathy McCoy, Secretary-Treasurer of the ACL, and Priscilla Rasmussen, ACL Business Manager, provided unending support in the planning, decision making, and execution of all of the arrangements. Mark Maybury (Mitre), Publicity Chair, expanded the number of places we advertise the conference to help widen our audience. June Santeusanio and Russell Kenyon from GTE created and updated a terrific web site, bringing the information about the conference to a central place. Russell developed the on-line registration form and provided support throughout the registration process. I would especially like to thank Gary Coen (Boeing), who was the Sponsorship Chair, and all of the commercial companies who contributed to the conference. We had the largest level of industry support of any ACL conference in the past. Microsoft, Boeing, Sun, Intel (China), Xerox PARC, Logos, Conversa, and General Electric all contributed funds to support various events, allowing us to have a commercial grade conference at a hotel facility while keeping the conference fees at their usual level to accommodate academic budgets. GTE (BBN), Answerlogic, IBM, and Inxight provided scholarships to allow more students to attend the conference. There are many more people who deserve thanks for contributing in one way or another. ACL is an all volunteer organization and it is a credit to everyone who participates that we can put on an event of this size and scope, benefiting everyone who attends through the exchange of ideas and inspiration we get from seeing the leading edge of the field.</abstract>
<author confidence="0.988717">Marie Meteer</author>
<address confidence="0.388372">General Chair, ANLP-NAACL 2000</address>
<date confidence="0.936101">April 2000</date>
<note confidence="0.7850296">III 04 0 0 114</note>
<abstract confidence="0.9747416">to en IL; O 0 o 1.) AA CZ -6 4-6`&amp;quot; 0 g (xl t-i 6 z z 2 % o = ao .— t es .. .,... x › a ._c) 0 ,N4 2 ...., 00 , ,.= — at gs , ,.... 0 g 0 - , 0 0 as ti.) O 0 ez 4) ..-. = tul o o -o a.</abstract>
<note confidence="0.963858428571428">6 0 CONFERENCE PROGRAM TUTORIALS, Saturday 29 April 2000, 8:30AM-5:00PM Session 3 ANLP NAACL PRELIMINARY PROGRAM ANLP c4 o BusTUC-A Natural Language Bus Route Oracle Translation Very Cross-Language Multimedia Information Retrieval English-Chinese Corpus for Cross-language Information Retrieval Jiang Chen, lian-Yun Nie .2 a) z II VI &apos;Amble Tore Languages Sharon Flank</note>
<author confidence="0.912365">Jan Hajic</author>
<author confidence="0.912365">Jan Hric</author>
<author confidence="0.912365">Vladislav Kuban</author>
<abstract confidence="0.410718">ANLP/NAACL NAACL Introductory Remarks Modelling Grounding and Discourse Obligations Using Update Rules Automatic of Discourse Structures Genre-independent Model of Pronominalization 1 &apos;S NAACL TECHNICAL SESSIONS Cohn Matheson, David Traum, Massimo Poesio Marco, Lynn Carlson, Maki Watanabe Michael Strube, Maria Wolters in domain independent linear text C4 IZI egmentation reddy Y.Y. Choi Monday, May 1 I&apos;-) 8 C c-1 ci tt-1 cir■ ,--. o -1- 6 .1-</abstract>
<phone confidence="0.798738">88 6</phone>
<title confidence="0.7719305">V</title>
<author confidence="0.99333">Benoit Lavoie</author>
<affiliation confidence="0.530493">Voice Access to Information</affiliation>
<email confidence="0.4374235">enen</email>
<note confidence="0.877395076923077">4t: Cr) Cr) en vi •tt 0 Ci) &apos;1? Ln C C..D 41 •■■• &amp;quot;0 0 O0 .12 0</note>
<abstract confidence="0.87922285">E ea E O. cn col = ..-■ .... ul 0 ry ›.) .2 5 = ... a .... &gt; n c 00 &amp;quot;&apos; ° § to T, r1 4a, i i al &amp;quot; =. a 9 , . . • . ° 4 EbL 0 CA 4-■ A as1 Cr. 1r) In co c0 ANLP/NAACL TECHNICAL SESSIONS c d &amp;quot;a rco&amp;quot; VI 0 NAACL BUSINESS MEETING In In In ix 0 0 1r) c■i tr) Cr) TUTORIALS Saturday 29 April 2000, 8:30AM-5:00PM Information Retrieval, 8:30AM-12:00PM James Allan, University of Massachusetts, Amherst This tutorial will examine the role of Natural Language Processing in Information Retrieval (IR). It will start with a historical overview of how NLP has been used and abused over the 40 years of IR research, attempting to illustrate why distrust of NLP was rampant in the IR community. We will next explore reasons that NLP might have been doomed to failure in early IR contexts--where basic IR techniques already captured some of what NLP might have offered, and NLP techniques with even small error rates were therefore unable to offer more. We will then focus on NLP/IR success stories--both past and present--that show how NLP can be (and has been) successfully used in some applications. The last portion of the tutorial will focus on very recent applications of NLP for retrieval and organization purposes. We will discuss the use of NLP and IR as part of Web applications, and as applied to Web pages. The tutorial will also include a discussion of the exciting Question and Answer track from TREC-8 (1999). That task results showed that a combination of IR and NLP was highly effective, creating a great opportunity for future collaboration between the two fields. The State of the Art in Language Modeling, 8:30AM-12:00PM Joshua Goodman, Microsoft Research This tutorial will cover the state-of-the-art in language modeling. The goal of language models is to predict the probability of words; this is directly useful for speech recognition, handwriting recognition, spelling correction, and other areas. Because language modeling is one of the most explored areas of statistical modeling, the state of the art is relatively advanced. Techniques from language modeling may be of interest to anyone pursuing probabilistic modeling, including those interested in statistical parsing, information retrieval, machine translation, and compression. The tutorial should be accessible to anyone with an elementary knowledge of probability. The most basic language models -n-gram models -essentially just count occurrences of words in training data. I will describe six improvements over this simple baseline: smoothing, caching, skipping, sentence-mixture models, clustering, and parsing-based models. 1) Smoothing addresses the problem of data sparsity: there is rarely enough data to accurately estimate the parameters of a language model. Smoothing gives a way to combine less specific, more accurate information with more specific, but noisier data. I will describe two classic techniques: deleted interpolation and Katz (or Good- Turing) smoothing, and one recent technique, Modified Kneser-Ney smoothing, which is the best available. 2) Caching is a widely used technique that uses the observation that recently observed words are likely to occur again. Models from recently observed data can be combined with more general models to improve performance. 3) Skipping models use the observation that even words that are not directly adjacent to the target word contain useful information. 4) Sentence-mixture models use the observation that there are many different kinds of sentences. By modeling each sentence type separately, performance is improved. 5) Clustering is one of the most useful language modeling techniques. Words can be grouped together into clusters through various automatic techniques; then the probability of a cluster can be predicted instead of the probability of the word. Clustering can be used to make smaller models or better performing ones. 6) All of the previous techniques ignore the structure of language. Recently, Ciprian Chelba has shown that techniques from statistical parsing can be used for improved models. Finally, I will also talk about some practical aspects of language modeling. I will describe how freely available, offthe-shelf tools can be used to easily build language models, and how to use methods such as count cutoffs to compress language models. Those who attend the tutorial should walk away with a broad understanding of the current techniques, and the background needed to either build their own language models, or to apply some of these techniques to other fields. Finite-State Morphology/Phonology:Theory,Applications,and Recent Developments, 1:30PM-5:00PM George Kiraz, Lucent Technologies Bell Labs Morphology and phonology are crucial components in any large scale NLP and/or speech system. Finite-state (FS) approaches to morphology/phonology are the state-of-the-art in the field; they aim at modeling the morphology/phonology of language with computational devices whose computational power does not exceed that</abstract>
<intro confidence="0.506565">of FS machines. Such machines are of interest because they are easy to implement, fast to run and mathematically</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>multilingual summarization, etc). We will also look at how current research</title>
<note>in NLP is likely to affect MT in the future. Syllabus:</note>
<marker></marker>
<rawString> multilingual summarization, etc). We will also look at how current research in NLP is likely to affect MT in the future. Syllabus:</rawString>
</citation>
<citation valid="false">
<authors>
<author>Introduction to MT</author>
</authors>
<title>Why is MT important? History of MT research and commercial development. Generalpurpose vs. special-purpose MT. Architectures that have been used for MT.</title>
<contexts>
<context position="17975" citStr="(1)" startWordPosition="2894" endWordPosition="2894">he field; they aim at modeling the morphology/phonology of language with computational devices whose computational power does not exceed that of FS machines. Such machines are of interest because they are easy to implement, fast to run and mathematically elegant. The purpose of this tutorial is to give a comprehensive introduction to the field of computational morphology, with emphasis on recent developments and practical techniques to build real systems. The first hour of the tutorial will be introductory, bringing all the participants to a common understanding of the prerequisites involved: (1) morphology from a linguistics perspective, (2) automata theory from a computer-science perspective, and (3) how the two fields make up &apos;FS computational morphology&apos;. The second hour will concentrate on the theory of FS morphology. The various popular formalisms and notations will be explained. Algorithms for compiling formalisms into FS machines (i.e., rule compilers) will be detailed with comprehensive step-by-step examples. Algorithms for interpreting the formalisms directly will be outlined. Recent developments in the field will be emphasized. The third hour will concentrate on building pr</context>
</contexts>
<marker>1.</marker>
<rawString>Introduction to MT. Why is MT important? History of MT research and commercial development. Generalpurpose vs. special-purpose MT. Architectures that have been used for MT.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Building MT</author>
</authors>
<title>Systems. Syntactic transfer: building a lexicon, transfer rules. Interlingua-based MT: domainspecific interlingua design, parsing, semantic interpretation, generation. Direct transfer: statistical algorithms trained on bilingual corpora, text alignment, transliteration, example-based MT.</title>
<contexts>
<context position="18022" citStr="(2)" startWordPosition="2900" endWordPosition="2900">honology of language with computational devices whose computational power does not exceed that of FS machines. Such machines are of interest because they are easy to implement, fast to run and mathematically elegant. The purpose of this tutorial is to give a comprehensive introduction to the field of computational morphology, with emphasis on recent developments and practical techniques to build real systems. The first hour of the tutorial will be introductory, bringing all the participants to a common understanding of the prerequisites involved: (1) morphology from a linguistics perspective, (2) automata theory from a computer-science perspective, and (3) how the two fields make up &apos;FS computational morphology&apos;. The second hour will concentrate on the theory of FS morphology. The various popular formalisms and notations will be explained. Algorithms for compiling formalisms into FS machines (i.e., rule compilers) will be detailed with comprehensive step-by-step examples. Algorithms for interpreting the formalisms directly will be outlined. Recent developments in the field will be emphasized. The third hour will concentrate on building practical applications. An introduction to the av</context>
</contexts>
<marker>2.</marker>
<rawString>Building MT Systems. Syntactic transfer: building a lexicon, transfer rules. Interlingua-based MT: domainspecific interlingua design, parsing, semantic interpretation, generation. Direct transfer: statistical algorithms trained on bilingual corpora, text alignment, transliteration, example-based MT.</rawString>
</citation>
<citation valid="false">
<title>Managing the Input, Managing the Output. Pre-editing. Reducing ambiguity through controlled-language source text. Post-editing. Ambiguity preservation.</title>
<contexts>
<context position="18083" citStr="(3)" startWordPosition="2908" endWordPosition="2908">tional power does not exceed that of FS machines. Such machines are of interest because they are easy to implement, fast to run and mathematically elegant. The purpose of this tutorial is to give a comprehensive introduction to the field of computational morphology, with emphasis on recent developments and practical techniques to build real systems. The first hour of the tutorial will be introductory, bringing all the participants to a common understanding of the prerequisites involved: (1) morphology from a linguistics perspective, (2) automata theory from a computer-science perspective, and (3) how the two fields make up &apos;FS computational morphology&apos;. The second hour will concentrate on the theory of FS morphology. The various popular formalisms and notations will be explained. Algorithms for compiling formalisms into FS machines (i.e., rule compilers) will be detailed with comprehensive step-by-step examples. Algorithms for interpreting the formalisms directly will be outlined. Recent developments in the field will be emphasized. The third hour will concentrate on building practical applications. An introduction to the available tools (and how to build such tools) will be given. Th</context>
</contexts>
<marker>3.</marker>
<rawString>Managing the Input, Managing the Output. Pre-editing. Reducing ambiguity through controlled-language source text. Post-editing. Ambiguity preservation.</rawString>
</citation>
<citation valid="false">
<title>Evaluation of MT Systems. Why it&apos;s hard. Metrics that have been proposed and used. Strengths and weaknesses.</title>
<marker>4.</marker>
<rawString>Evaluation of MT Systems. Why it&apos;s hard. Metrics that have been proposed and used. Strengths and weaknesses.</rawString>
</citation>
<citation valid="false">
<title>The Economics of MT. Products and services available.</title>
<marker>5.</marker>
<rawString>The Economics of MT. Products and services available.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Donna Byron</author>
<author>Peter B Vanderheyden</author>
</authors>
<title>The Future of MT. Integrating MT with other natural language technologies: cross-language information retrieval, speech-to-speech MT, summarizing foreign-language documents. How current NLP research bears on MT. Table of Contents ANLP-NAACL</title>
<date>2000</date>
<booktitle>General Chair iii Conference Prognun Tutorial Schedule xi Section 1: Applied Natural Language Processing Conference (ANLP 2000) ANLP 2000 Preface and List of Reviewers Sergei Nirenburg, Program Committee Chair ANLPi ANLP 2000 Proceedings Table of Contents ANLPiii Section 2: North American Chapter of the Association for Computational Linguistics (NAACL 2000) NAACL 2000 Preface and List of Reviewers Janyce Wiebe, Program Committee Chair NAACLi NAACL 2000 Proceedings Table of Contents NAACLv Section 3: ANLP-NAACL 2000 Student Research Workshop (SRW) SRW Preface and List of Reviewers</booktitle>
<marker>6.</marker>
<rawString>The Future of MT. Integrating MT with other natural language technologies: cross-language information retrieval, speech-to-speech MT, summarizing foreign-language documents. How current NLP research bears on MT. Table of Contents ANLP-NAACL 2000 Preface Marie Meteer, General Chair iii Conference Prognun Tutorial Schedule xi Section 1: Applied Natural Language Processing Conference (ANLP 2000) ANLP 2000 Preface and List of Reviewers Sergei Nirenburg, Program Committee Chair ANLPi ANLP 2000 Proceedings Table of Contents ANLPiii Section 2: North American Chapter of the Association for Computational Linguistics (NAACL 2000) NAACL 2000 Preface and List of Reviewers Janyce Wiebe, Program Committee Chair NAACLi NAACL 2000 Proceedings Table of Contents NAACLv Section 3: ANLP-NAACL 2000 Student Research Workshop (SRW) SRW Preface and List of Reviewers Donna Byron and Peter B. Vanderheyden, Program Committee Chairs SRWi SRW Proceedings Table of Contents SRWiii</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>