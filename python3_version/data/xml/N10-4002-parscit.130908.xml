<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.016029">
<subsectionHeader confidence="0.298991">
Markov Logic in Natural Language Processing: Theory, Algorithms, and
Applications
</subsectionHeader>
<bodyText confidence="0.982282941176471">
Hoifung Poon, University of Washington
Natural languages are characterized by rich relational structures and
tight integration with world knowledge. As the field of NLP/CL moves
towards more complex and challenging tasks, there has been increasing
interest in applying joint inference to leverage such relations and
prior knowledge. Recent work in statistical relational learning
(a.k.a. structured prediction) has shown that joint inference can not
only substantially improve predictive accuracy, but also enable
effective learning with little or no labeled information. Markov logic
is the unifying framework for statistical relational learning, and has
spawned a series of successful NLP applications, ranging from
information extraction to unsupervised semantic parsing. In this
tutorial, I will introduce Markov logic to the NLP community and
survey existing NLP applications. The target audience of the tutorial
is all NLP researchers, students and practitioners. The audience will
gain the ability to efficiently develop state-of-the-art solutions to
NLP problems using Markov logic and the Alchemy open-source software.
</bodyText>
<sectionHeader confidence="0.587043" genericHeader="abstract">
1. Structure
</sectionHeader>
<bodyText confidence="0.9985255">
The tutorial will be structured as follows:
Part One: Markov Logic
In the first part I will motivate statistical relational learning
(SRL) for NLP problems, and introduce Markov logic as the unifying
framework. I will present state-of-the-art learning and inference
algorithms in Markov logic, and give an overview of the Alchemy
open-source software package. The duration of this part will be
approximately one hour and half.
Part Two: NLP Applications: Supervised Learning
In the second part I will describe how to use Markov logic and
Alchemy to develop state-of-the-art solutions very efficiently for a
variety of NLP problems, including: logistic regression, text and
hypertext classification, vector-space and link-based information
retrieval, entity resolution, information integration, hidden Markov
models, Bayesian networks, information extraction, semantic role
labeling, and biomedical text mining. This part will also cover
practical tips on using Markov logic and Alchemy — the kind of
information that is rarely found in research papers, but is key to
</bodyText>
<page confidence="0.997421">
3
</page>
<bodyText confidence="0.934934272727273">
developing successful applications. This part will focus on supervised
learning and the duration will be approximately an hour.
Part Three: NLP Applications: Unsupervised Learning
In the third and final part I will introduce the emerging direction
for statistical relation learning that leverages prior knowledge and
relational structures to enable effective learning with little or no
labeled data. As examples I will present recent work in applying
Markov logic to unsupervised coreference resolution and unsupervised
semantic parsing. I will also briefly touch on the exciting prospect
of machine reading from the Web. The duration will be about half an
hour.
</bodyText>
<sectionHeader confidence="0.942621" genericHeader="keywords">
2. Instructor
</sectionHeader>
<subsectionHeader confidence="0.291334">
Hoifung Poon
Department of Computer Science and Engineering
</subsectionHeader>
<bodyText confidence="0.888475352941176">
University of Washington
Seattle, WA 98195, USA
hoifung@cs.washington.edu
Hoifung Poon is a fifth-year Ph.D. student at the University of
Washington, working with Pedro Domingos. His main research interest
lies in advancing machine learning methods to handle both complexity
and uncertainty, and in applying them to solving challenging NLP
problems with little or no labeled data. His most recent work
developed unsupervised learning methods for a number of NLP problems
ranging from morphological segmentation to semantic parsing, and
received the Best Paper Awards in NAACL-09 and EMNLP-09. At
Washington, he helped design course materials for the first offering
of the undergraduate machine learning course, and gave guest lectures
in both undergraduate and graduate machine learning classes. His prior
experience includes teaching undergraduate math classes in West
Virginia University, for which he was awarded the Outstanding Graduate
Teaching Assistant by the University.
</bodyText>
<page confidence="0.992971">
4
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.059457">
<title confidence="0.94007">Markov Logic in Natural Language Processing: Theory, Algorithms, and Applications</title>
<affiliation confidence="0.94482">University of Washington</affiliation>
<abstract confidence="0.985147">Natural languages are characterized by rich relational structures and tight integration with world knowledge. As the field of NLP/CL moves towards more complex and challenging tasks, there has been increasing interest in applying joint inference to leverage such relations and prior knowledge. Recent work in statistical relational learning (a.k.a. structured prediction) has shown that joint inference can not only substantially improve predictive accuracy, but also enable effective learning with little or no labeled information. Markov logic is the unifying framework for statistical relational learning, and has spawned a series of successful NLP applications, ranging from information extraction to unsupervised semantic parsing. In this tutorial, I will introduce Markov logic to the NLP community and survey existing NLP applications. The target audience of the tutorial is all NLP researchers, students and practitioners. The audience will gain the ability to efficiently develop state-of-the-art solutions to NLP problems using Markov logic and the Alchemy open-source software. 1. Structure The tutorial will be structured as follows: Part One: Markov Logic In the first part I will motivate statistical relational learning (SRL) for NLP problems, and introduce Markov logic as the unifying framework. I will present state-of-the-art learning and inference algorithms in Markov logic, and give an overview of the Alchemy open-source software package. The duration of this part will be approximately one hour and half. Part Two: NLP Applications: Supervised Learning In the second part I will describe how to use Markov logic and Alchemy to develop state-of-the-art solutions very efficiently for a variety of NLP problems, including: logistic regression, text and hypertext classification, vector-space and link-based information retrieval, entity resolution, information integration, hidden Markov models, Bayesian networks, information extraction, semantic role labeling, and biomedical text mining. This part will also cover practical tips on using Markov logic and Alchemy — the kind of information that is rarely found in research papers, but is key to 3 developing successful applications. This part will focus on supervised learning and the duration will be approximately an hour. Part Three: NLP Applications: Unsupervised Learning In the third and final part I will introduce the emerging direction for statistical relation learning that leverages prior knowledge and relational structures to enable effective learning with little or no labeled data. As examples I will present recent work in applying Markov logic to unsupervised coreference resolution and unsupervised semantic parsing. I will also briefly touch on the exciting prospect of machine reading from the Web. The duration will be about half an hour. 2. Instructor</abstract>
<author confidence="0.949863">Hoifung Poon</author>
<affiliation confidence="0.9995485">Department of Computer Science and Engineering University of Washington</affiliation>
<address confidence="0.999934">Seattle, WA 98195, USA</address>
<email confidence="0.998783">hoifung@cs.washington.edu</email>
<degree confidence="0.397694">Hoifung Poon is a fifth-year Ph.D. student at the University of</degree>
<abstract confidence="0.917359384615384">Washington, working with Pedro Domingos. His main research interest lies in advancing machine learning methods to handle both complexity and uncertainty, and in applying them to solving challenging NLP problems with little or no labeled data. His most recent work developed unsupervised learning methods for a number of NLP problems ranging from morphological segmentation to semantic parsing, and received the Best Paper Awards in NAACL-09 and EMNLP-09. At Washington, he helped design course materials for the first offering of the undergraduate machine learning course, and gave guest lectures in both undergraduate and graduate machine learning classes. His prior experience includes teaching undergraduate math classes in West Virginia University, for which he was awarded the Outstanding Graduate Teaching Assistant by the University.</abstract>
<intro confidence="0.544661">4</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>