<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000362">
<title confidence="0.997848">
Elliphant: Improved Automatic Detection of
Zero Subjects and Impersonal Constructions in Spanish
</title>
<author confidence="0.905619">
Luz Rello* Ricardo Baeza-Yates Ruslan Mitkov
</author>
<affiliation confidence="0.673110333333333">
NLP and Web Research Groups Yahoo! Research Research Group in
Univ. Pompeu Fabra Barcelona, Spain Computational Linguistics
Barcelona, Spain Univ. of Wolverhampton, UK
</affiliation>
<sectionHeader confidence="0.956946" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999172190476191">
In pro-drop languages, the detection of
explicit subjects, zero subjects and non-
referential impersonal constructions is cru-
cial for anaphora and co-reference resolu-
tion. While the identification of explicit
and zero subjects has attracted the atten-
tion of researchers in the past, the auto-
matic identification of impersonal construc-
tions in Spanish has not been addressed yet
and this work is the first such study. In
this paper we present a corpus to under-
pin research on the automatic detection of
these linguistic phenomena in Spanish and
a novel machine learning-based methodol-
ogy for their computational treatment. This
study also provides an analysis of the fea-
tures, discusses performance across two
different genres and offers error analysis.
The evaluation results show that our system
performs better in detecting explicit sub-
jects than alternative systems.
</bodyText>
<sectionHeader confidence="0.999127" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999694666666667">
Subject ellipsis is the omission of the subject in
a sentence. We consider not only missing refer-
ential subject (zero subject) as manifestation of
ellipsis, but also non-referential impersonal con-
structions.
Various natural language processing (NLP)
tasks benefit from the identification of ellip-
tical subjects, primarily anaphora resolution
(Mitkov, 2002) and co-reference resolution (Ng
and Cardie, 2002). The difficulty in detect-
ing missing subjects and non-referential pronouns
has been acknowledged since the first studies on
</bodyText>
<footnote confidence="0.533538">
* This work was partially funded by a ‘La Caixa’ grant
for master students.
</footnote>
<bodyText confidence="0.999597444444445">
the computational treatment of anaphora (Hobbs,
1977; Hirst, 1981). However, this task is of cru-
cial importance when processing pro-drop lan-
guages since subject ellipsis is a pervasive phe-
nomenon in these languages (Chomsky, 1981).
For instance, in our Spanish corpus, 29% of the
subjects are elided.
Our method is based on classification of all ex-
pressions in subject position, including the recog-
nition of Spanish non-referential impersonal con-
structions which, to the best of our knowledge,
has not yet been addressed. The necessity of iden-
tifying such kind of elliptical constructions has
been specifically highlighted in work about Span-
ish zero pronouns (Ferr´andez and Peral, 2000)
and co-reference resolution (Recasens and Hovy,
2009).
The main contributions of this study are:
</bodyText>
<listItem confidence="0.9918477">
• A public annotated corpus in Spanish to
compare different strategies for detecting ex-
plicit subjects, zero subjects and impersonal
constructions.
• The first ML based approach to this problem
in Spanish and a thorough analysis regarding
features, learnability, genre and errors.
• The best performing algorithms to automati-
cally detect explicit subjects and impersonal
constructions in Spanish.
</listItem>
<bodyText confidence="0.999877857142857">
The remainder of the paper is organized as fol-
lows. Section 2 describes the classes of Spanish
subjects, while Section 3 provides a literature re-
view. Section 4 describes the creation and the an-
notation of the corpus and in Section 5 the ma-
chine learning (ML) method is presented. The
analysis of the features, the learning curves, the
</bodyText>
<page confidence="0.973851">
706
</page>
<note confidence="0.9765435">
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 706–715,
Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999832142857143">
genre impact and the error analysis are all detailed
in Section 6. Finally, in Section 7, conclusions
are drawn and plans for future work are discussed.
This work is an extension of the first author mas-
ter’s thesis (Rello, 2010) and a preliminary ver-
sion of the algorithm was presented in Rello et al.
(2010).
</bodyText>
<sectionHeader confidence="0.928159" genericHeader="introduction">
2 Classes of Spanish Subjects
</sectionHeader>
<bodyText confidence="0.945318913043478">
Literature related to ellipsis in NLP (Ferr´andez
and Peral, 2000; Rello and Illisei, 2009a; Mitkov,
2010) and linguistic theory (Bosque, 1989; Bru-
cart, 1999; Real Academia Espa˜nola, 2009) has
served as a basis for establishing the classes of
this work.
Explicit subjects are phonetically realized and
their syntactic position can be pre-verbal or post-
verbal. In the case of post-verbal subjects (a), the
syntactic position is restricted by some conditions
(Real Academia Espa˜nola, 2009).
(a) Carecer´an de validez las disposiciones que con-
tradigan otra de rango superior.1
The dispositions which contradict higher range
ones will not be valid.
Zero subjects (b) appear as the result of a nomi-
nal ellipsis. That is, a lexical element –the elliptic
subject–, which is needed for the interpretation of
the meaning and the structure of the sentence, is
elided; therefore, it can be retrieved from its con-
text. The elision of the subject can affect the en-
tire noun phrase and not just the noun head when
a definite article occurs (Brucart, 1999).
</bodyText>
<listItem confidence="0.6752745">
(b) Ø Fue refrendada por el pueblo espa˜nol.
(It) was countersigned by the people of Spain.
</listItem>
<bodyText confidence="0.979493">
The class of impersonal constructions is
formed by impersonal clauses (c) and reflex-
ive impersonal clauses with particle se (d) (Real
Academia Espa˜nola, 2009).
</bodyText>
<listItem confidence="0.96811075">
(c) No hay matrimonio sin consentimiento.
(There is) no marriage without consent.
(d) Se estar´a a lo que establece el apartado siguiente.
(It) will be what is established in the next section.
</listItem>
<footnote confidence="0.940767">
1All the examples provided are taken from our corpus.
In the examples, explicit subjects are presented in italics.
Zero subjects are presented by the symbol Ø and in the En-
glish translations the subjects which are elided in Spanish are
marked with parentheses. Impersonal constructions are not
explicitly indicated.
</footnote>
<sectionHeader confidence="0.999217" genericHeader="related work">
3 Related Work
</sectionHeader>
<bodyText confidence="0.999931214285714">
Identification of non-referential pronouns, al-
though a crucial step in co-reference and anaphora
resolution systems (Mitkov, 2010),2 has been ap-
plied only to the pleonastic it in English (Evans,
2001; Boyd et al., 2005; Bergsma et al., 2008)
and expletive pronouns in French (Danlos, 2005).
Machine learning methods are known to perform
better than rule-based techniques for identifying
non-referential expressions (Boyd et al., 2005).
However, there is some debate as to which ap-
proach may be optimal in anaphora resolution
systems (Mitkov and Hallett, 2007).
Both English and French texts use an ex-
plicit word, with some grammatical information
(a third person pronoun), which is non-referential
(Mitkov, 2010). By contrast, in Spanish, non-
referential expressions are not realized by exple-
tive or pleonastic pronouns but rather by a certain
kind of ellipsis. For this reason, it is easy to mis-
take them for zero pronouns, which are, in fact,
referential.
Previous work on detecting Spanish subject el-
lipsis focused on distinguishing verbs with ex-
plicit subjects and verbs with zero subjects (zero
pronouns), using rule-based methods (Ferr´andez
and Peral, 2000; Rello and Illisei, 2009b). The
Ferr´andez and Peral algorithm (2000) outper-
forms the (Rello and Illisei, 2009b) approach
with 57% accuracy in identifying zero subjects.
In (Ferr´andez and Peral, 2000), the implementa-
tion of a zero subject identification and resolution
module forms part of an anaphora resolution sys-
tem.
ML based studies on the identification of
explicit non-referential constructions in English
present accuracies of 71% (Evans, 2001), 87.5%
(Bergsma et al., 2008) and 88% (Boyd et al.,
2005), while 97.5% is achieved for French (Dan-
los, 2005). However, in these languages, non-
referential constructions are explicit and not omit-
ted which makes this task more challenging for
Spanish.
</bodyText>
<sectionHeader confidence="0.996308" genericHeader="method">
4 Corpus
</sectionHeader>
<bodyText confidence="0.999029">
We created and annotated a corpus composed
of legal texts (law) and health texts (psychiatric
</bodyText>
<footnote confidence="0.987538666666667">
2In zero anaphora resolution, the identification of zero
anaphors first requires that they be distinguished from non-
referential impersonal constructions (Mitkov, 2010).
</footnote>
<page confidence="0.997028">
707
</page>
<bodyText confidence="0.999930071428572">
papers) originally written in peninsular Spanish.
The corpus is named after its annotated content
“Explicit Subjects, Zero Subjects and Impersonal
Constructions” (ESZIC es Corpus).
To the best of our knowledge, the existing cor-
pora annotated with elliptical subjects belong to
other genres. The Blue Book (handbook) and
Lexesp (journalistic texts) used in (Ferr´andez and
Peral, 2000) contain zero subjects but not imper-
sonal constructions. On the other hand, the Span-
ish AnCora corpus based on journalistic texts in-
cludes zero pronouns and impersonal construc-
tions (Recasens and Marti, 2010) while the Z-
corpus (Rello and Illisei, 2009b) comprises legal,
instructional and encyclopedic texts but has no an-
notated impersonal constructions.
The ESZIC corpus contains a total of 6,827
verbs including 1,793 zero subjects. Except for
AnCora-ES, with 10,791 elliptic pronouns, our
corpus is larger than the ones used in previous ap-
proaches: about 1,830 verbs including zero and
explicit subjects in (Ferr´andez and Peral, 2000)
(the exact number is not mentioned in the pa-
per) and 1,202 zero subjects in (Rello and Illisei,
2009b).
The corpus was parsed by Connexor’s Ma-
chinese Syntax (Connexor Oy, 2006), which re-
turns lexical and morphological information as
well as the dependency relations between words
by employing a functional dependency grammar
(Tapanainen and J¨arvinen, 1997).
To annotate our corpus we created an annota-
tion tool that extracts the finite clauses and the
annotators assign to each example one of the de-
fined annotation tags. Two volunteer graduate stu-
dents of linguistics annotated the verbs after one
training session. The annotations of a third volun-
teer with the same profile were used to compute
the inter-annotator agreement. During the anno-
tation phase, we evaluated the adequacy and clar-
ity of the annotation guidelines and established a
typology of the rising borderline cases, which is
included in the annotation guidelines.
Table 1 shows the linguistic and formal criteria
used to identify the chosen categories that served
as the basis for the corpus annotation. For each
tag, in addition to the two criteria that are crucial
for identifying subject ellipsis ([f elliptic] and
[f referential]) a combination of syntactic, se-
mantic and discourse knowledge is also encoded
during the annotation. The linguistic motivation
for each of the three categories is shown against
the thirteen annotation tags to which they belong
(Table 1).
Afterwards, each of the tags are grouped in one
of the three main classes.
</bodyText>
<listItem confidence="0.9953805">
• Explicit subjects: [- elliptic, + referential].
• Zero subjects: [+ elliptic, + referential].
• Impersonal constructions: [+ elliptic, - refer-
ential].
</listItem>
<bodyText confidence="0.998471333333333">
Of these annotated verbs, 71% have an explicit
subject, 26% have a zero subject and 3% belong
to an impersonal construction (see Table 2).
</bodyText>
<table confidence="0.9908374">
Number of instances Legal Health All
Explicit subjects 2,739 2,116 4,855
Zero subjects 619 1,174 1,793
Impersonals 71 108 179
Total 3,429 3,398 6,827
</table>
<tableCaption confidence="0.999204">
Table 2: Instances per class in ESZIC Corpus.
</tableCaption>
<bodyText confidence="0.999941">
To measure inter-annotator reliability we use
Fleiss’ Kappa statistical measure (Fleiss, 1971).
We extracted 10% of the instances of each of the
texts of the corpus covering the two genres.
</bodyText>
<table confidence="0.973">
Fleiss’ Kappa Legal Health All
Two Annotators 0.934 0.870 0.902
Three Annotators 0.925 0.857 0.891
</table>
<tableCaption confidence="0.999463">
Table 3: Inter-annotator Agreement.
</tableCaption>
<bodyText confidence="0.999892571428571">
In Table 3 we present the Fleiss kappa inter-
annotator agreement for two and three annota-
tors. These results suggest that the annotation
is reliable since it is common practice among re-
searchers in computational linguistics to consider
0.8 as a minimum value of acceptance (Artstein
and Poesio, 2008).
</bodyText>
<sectionHeader confidence="0.99344" genericHeader="method">
5 Machine Learning Approach
</sectionHeader>
<bodyText confidence="0.9998335">
We opted for an ML approach given that our
previous rule-based methodology improved only
0.02 over the 0.55 F-measure of a simple base-
line (Rello and Illisei, 2009b). Besides, ML based
methods for the identification of explicit non-
referential constructions in English appear to per-
form better than than rule-based ones (Boyd et al.,
2005).
</bodyText>
<page confidence="0.993161">
708
</page>
<table confidence="0.999392833333333">
LINGUISTIC INFORMATION PHONETIC SYNTACTIC VERBAL SEMANTIC DISCOURSE
REALIZATION CATEGORY DIATHESIS INTERPR.
Annotation Annotation Elliptic Ell. noun Nominal Active Active Referential
Categories Tags noun phrase subject participant subject
phrase head
Explicit Explicit subject – – + + + +
subject
Reflex passive – – + + – +
subject
Passive subject – – + – – +
Zero Omitted subject + – + + + +
subject
Omitted subject – + + + + +
head
Non-nominal – – – + + +
subject
Reflex passive + – + + – +
omitted subject
Reflex pass. omit- – + + + – +
ted subject head
Reflex pass. non- – – – + – +
nominal subject
Passive omitted + – + – – +
subject
Pass. non-nominal – – – – – +
subject
Impersonal Reflex imp. clause – – n/a – n/a –
construction (with se)
Imp. construction – – n/a + n/a –
(without se)
</table>
<tableCaption confidence="0.999876">
Table 1: ESZIC Corpus Annotation Tags.
</tableCaption>
<subsectionHeader confidence="0.838902">
5.1 Features
</subsectionHeader>
<bodyText confidence="0.997846071428572">
We built the training data from the annotated cor-
pus and defined fourteen features. The linguisti-
cally motivated features are inspired by previous
ML approaches in Chinese (Zhao and Ng, 2007)
and English (Evans, 2001). The values for the fea-
tures (see Table 4) were derived from information
provided both by Connexor’s Machinese Syntax
parser and a set of lists.
We can describe each of the features as broadly
belonging to one of ten classes, as follows:
1 PARSER: the presence or absence of a sub-
ject in the clause, as identified by the parser.
We are not aware of a formal evaluation of
Connexor’s accuracy. It presents an accu-
racy of 74.9% evaluated against our corpus
and we used it as a simple baseline.
2 CLAUSE: the clause types considered are:
main clauses, relative clauses starting with a
complex conjunction, clauses starting with a
simple conjunction, and clauses introduced
using punctuation marks (commas, semi-
colons, etc). We implemented a method
to identify these different types of clauses,
as the parser does not explicitly mark the
boundaries of clauses within sentences. The
method took into account the existence of a
finite verb, its dependencies, the existence of
conjunctions and punctuation marks.
</bodyText>
<listItem confidence="0.84570675">
3 LEMMA: lexical information extracted from
the parser, the lemma of the finite verb.
4-5 NUMBER, PERSON: morphological infor-
mation of the verb, its grammatical number
and its person.
6 AGREE: feature which encodes the tense,
mood, person, and number of the verb in the
clause, and its agreement in person, number,
</listItem>
<page confidence="0.990734">
709
</page>
<table confidence="0.995753842105263">
Feature Definition Value
1 PARSER Parsed subject True, False
2 CLAUSE Clause type Main, Rel, Imp, Prop, Punct
3 LEMMA Verb lemma Parser’s lemma tag
4 NUMBER Verb morphological number SG, PL
5 PERSON Verb morphological person P1, P2, P3
6 AGREE Agreement in person, number, tense FTFF, TTTT, FFFF, TFTF, TTFF, FTFT, FTTF, TFTT,
and mood FFFT, TTTF, FFTF, TFFT, FFTT, FTTT, TFFF, TTFT
7 NHPREV Previous noun phrases Number of noun phrases previous to the verb
8 NHTOT Total noun phrases Number of noun phrases in the clause
9 INF Infinitive Number of infinitives in the clause
10 SE Spanish particle se True, False
11 A Spanish preposition a True, False
12 POSpTe Four parts of the speech previous to 292 different values combining the parser’s
the verb POS tags
14 POSpos Four parts of the speech following 280 different values combining the parser’s
the verb POS tags
14 VERBtype Type of verb: copulative, impersonal CIPX, XIXX, XXXT, XXPX, XXXI, CIXX, XXPT, XIPX,
pronominal, transitive and intransitive XIPT, XXXX, XIXI, CXPI, XXPI, XIPI, CXPX
</table>
<tableCaption confidence="0.99955">
Table 4: Features, definitions and values.
</tableCaption>
<bodyText confidence="0.9179569">
tense, and mood with the preceding verb in
the sentence and also with the main verb of
the sentence.3
7-9 NHPREV, NHTOT, INF: the candidates for
the subject of the clause are represented by
the number of noun phrases in the clause that
precede the verb, the total number of noun
phrases in the clause, and the number of in-
finitive verbs in the clause.
10 SE: a binary feature encoding the presence
or absence of the Spanish particle se when it
occurs immediately before or after the verb
or with a maximum of one token lying be-
tween the verb and itself. Particle se occurs
in passive reflex clauses with zero subjects
and in some impersonal constructions.
11 A: a binary feature encoding the presence or
absence of the Spanish preposition a in the
clause. Since the distinction between passive
reflex clauses with zero subjects and imper-
sonal constructions sometimes relies on the
appearance of preposition a (to, for, etc.).
For instance, example (e) is a passive reflex
clause containing a zero subject while exam-
ple (s) is an impersonal construction.
3In Spanish, when a finite verb appears in a subordinate
clause, its tense and mood can assist in recognition of these
features in the verb of the main clause and help to enforce
some restrictions required by this verb, especially when both
verbs share the same referent as subject.
</bodyText>
<listItem confidence="0.805967666666667">
(e) Se admiten los alumnos que re´unan los req-
uisitos.
Ø (They) accept the students who fulfill the
requirements.
(f) Se admite a los alumnos que re´unan los req-
uisitos.
</listItem>
<bodyText confidence="0.942441583333333">
(It) is accepted for the students who fulfill
the requirements.
12-3 POSpTe, POSpos: the part of the speech
(POS) of eight tokens, that is, the 4-grams
preceding and the 4-grams following the in-
stance.
14 VERBtype: the verb is classified as copula-
tive, pronominal, transitive, or with an im-
personal use.4 Verbs belonging to more than
one class are also accommodated with dif-
ferent feature values for each of the possible
combinations of verb type.
</bodyText>
<subsectionHeader confidence="0.989091">
5.2 Evaluation
</subsectionHeader>
<bodyText confidence="0.999947571428571">
To determine the most accurate algorithm for our
classification task, two comparisons of learning
algorithms implemented in WEKA (Witten and
Frank, 2005) were carried out. Firstly, the classi-
fication was performed using 20% of the training
instances. Secondly, the seven highest perform-
ing classifiers were compared using 100% of the
</bodyText>
<footnote confidence="0.99566475">
4We used four lists provided by Molino de Ideas s.a. con-
taining 11,060 different verb lemmas belonging to the Royal
Spanish Academy Dictionary (Real Academia Espa˜nola,
2001).
</footnote>
<page confidence="0.93994">
710
</page>
<table confidence="0.99984925">
Class P R F Acc.
Explicit subj. 90.1% 92.3% 91.2% 87.3%
Zero subj. 77.2% 74.0% 75.5% 87.4%
Impersonals 85.6% 63.1% 72.7% 98.8%
</table>
<tableCaption confidence="0.9947475">
Table 5: K* performance (87.6% accuracy for ten-fold
cross validation).
</tableCaption>
<bodyText confidence="0.999243860465116">
training data and ten-fold cross-validation. The
corpus was partitioned into training and tested
using ten-fold cross-validation for randomly or-
dered instances in both cases. The lazy learn-
ing classifier K* (Cleary and Trigg, 1995), us-
ing a blending parameter of 40%, was the best
performing one, with an accuracy of 87.6% for
ten-fold cross-validation. K* differs from other
instance-based learners in that it computes the dis-
tance between two instances using a method mo-
tivated by information theory, where a maximum
entropy-based distance function is used (Cleary
and Trigg, 1995). Table 5 shows the results
for each class using ten-fold cross-validation.
In contrast to previous work, the K* algorithm
(Cleary and Trigg, 1995) was found to provide the
most accurate classification in the current study.
Other approaches have employed various clas-
sification algorithms, including JRip in WEKA
(M¨uller, 2006), with precision of 74% and recall
of 60%, and K-nearest neighbors in TiMBL: both
in (Evans, 2001) with precision of 73% and recall
of 69%, and in (Boyd et al., 2005) with precision
of 82% and recall of 71%.
Since there is no previous ML approach for this
task in Spanish, our baselines for the explicit sub-
jects and the zero subjects are the parser output
and the previous rule-based work with the high-
est performance (Ferr´andez and Peral, 2000). For
the impersonal constructions the baseline is a sim-
ple greedy algorithm that classifies as an imper-
sonal construction every verb whose lemma is cat-
egorized as a verb with impersonal use according
to the RAE dictionary (Real Academia Espa˜nola,
2001).
Our method outperforms the Connexor parser
which identifies the explicit subjects but makes no
distinction between zero subjects and impersonal
constructions. Connexor yields 74.9% overall ac-
curacy and 80.2% and 65.6% F-measure for ex-
plicit and elliptic subjects, respectively.
To compare with Ferr´andez and Peral
(Ferr´andez and Peral, 2000) we do consider
</bodyText>
<table confidence="0.999416166666667">
Algorithm Explicit Zero Impersonals
subjects subjects
RAE – – 70.4%
Connexor 71.7% 83.0%
Ferr./Peral 79.7% 98.4% –
Elliphant 87.3% 87.4% 98.8%
</table>
<tableCaption confidence="0.9954895">
Table 6: Summary of accuracy comparison with previ-
ous work.
</tableCaption>
<bodyText confidence="0.99990795">
it without impersonal constructions. We achieve
a precision of 87% for explicit subjects compared
to 80%, and a precision of 87% for zero subjects
compared to their 98%. The overall accuracy
is the same for both techniques, 87.5%, but our
results are more balanced. Nevertheless, the
approaches and corpora used in both studies are
different, and hence it is not possible to do a fair
comparison. For example, their corpus has 46%
of zero subjects while ours has only 26%.
For impersonal constructions our method out-
performs the RAE baseline (precision 6.5%,
recall 77.7%, F-measure 12.0% and accuracy
70.4%). Table 6 summarizes the comparison. The
low performance of the RAE baseline is due to the
fact that verbs with impersonal use are often am-
biguous. For these cases, we first tagged them as
ambiguous and then, we defined additional crite-
ria after analyzing then manually. The resulting
annotated criteria are stated in Table 1.
</bodyText>
<sectionHeader confidence="0.993967" genericHeader="method">
6 Analysis
</sectionHeader>
<bodyText confidence="0.999972">
Through these analyses we aim to extract the most
effective features and the information that would
complement the output of an standard parser to
achieve this task. We also examine the learning
process of the algorithm to find out how many in-
stances are needed to train it efficiently and de-
termine how much Elliphant is genre dependent.
The analyses indicate that our approach is robust:
it performs nearly as well with just six features,
has a steep learning curve, and seems to general-
ize well to other text collections.
</bodyText>
<subsectionHeader confidence="0.999477">
6.1 Best Features
</subsectionHeader>
<bodyText confidence="0.999214166666667">
We carried out three different experiments to eval-
uate the most effective group of features, and
the features themselves considering the individ-
ual predictive ability of each one along with their
degree of redundancy.
Based on the following three feature selection
</bodyText>
<page confidence="0.994674">
711
</page>
<bodyText confidence="0.9992505">
methods we can state that there is a complex and
balanced interaction between the features.
</bodyText>
<subsectionHeader confidence="0.943481">
6.1.1 Grouping Features
</subsectionHeader>
<bodyText confidence="0.999447523809524">
In the first experiment we considered the 11
groups of relevant ordered features from the train-
ing data, which were selected using each WEKA
attribute selection algorithm and performed the
classifications over the complete training data, us-
ing only the different groups features selected.
The most effective group of six features (NH-
PREV, PARSER, NHTOT, POSpos, PERSON,
LEMMA) was the one selected by WEKA’s Sym-
metricalUncertAttribute technique, which gives
an accuracy of 83.5%. The most frequently
selected features by all methods are PARSER,
POSpos, and NHTOT, and they alone get an accu-
racy of 83.6% together. As expected, the two pairs
of features that perform best (both 74.8% accu-
racy) are PARSER with either POSpos or NHTOT.
Based on how frequent each feature is selected
by WEKA’s attribute selection algorithms, we can
rank the features as following: (1) PARSER,
(2) NHTOT, (3) POSpos, (4) NHPREV and (5)
LEMMA.
</bodyText>
<subsectionHeader confidence="0.858952">
6.1.2 “Complex” vs. “Simple” Features
</subsectionHeader>
<bodyText confidence="0.999815368421053">
Second, a set of experiments was conducted
in which features were selected on the basis
of the degree of computational effort needed to
generate them. We propose two sets of fea-
tures. One group corresponds to “simple” fea-
tures, whose values can be obtained by trivial
exploitation of the tags produced in the parser’s
output (PARSER, LEMMA, PERSON, POSpos,
POSpre). The second group of features, “com-
plex” features (CLAUSE, AGREE, NHPREV,
NHTOT, VERBtype) have values that required the
implementation of more sophisticated modules to
identify the boundaries of syntactic constituents
such as clauses and noun phrases. The accuracy
obtained when the classifier exclusively exploits
“complex” features is 82.6% while for “simple”
features is 79.9%. No impersonal constructions
are identified when only “complex” features are
used.
</bodyText>
<subsectionHeader confidence="0.762472">
6.1.3 One-left-out Feature
</subsectionHeader>
<bodyText confidence="0.99998">
In the third experiment, to estimate the weight
of each feature, classifications were made in
which each feature was omitted from the train-
ing instances that were presented to the classifier.
Omission of all but one of the “simple” features
led to a reduction in accuracy, justifying their in-
clusion in the training instances. Nevertheless, the
majority of features present low informativeness
except for feature A which does not make any
meaningful contribution to the classification. The
feature PARSER presents the greatest difference
in performance (86.3% total accuracy); however,
this is no big loss, considering it is the main fea-
ture. Hence, as most features do not bring a sig-
nificant loss in accuracy, the features need to be
combined to improve the performance.
</bodyText>
<subsectionHeader confidence="0.99994">
6.2 Learning Analysis
</subsectionHeader>
<bodyText confidence="0.99992472972973">
The learning curve of Figure 1 (left) presents the
increase of the performance obtained by Elliphant
using the training data randomly ordered. The
performance reaches its plateau using 90% of the
training instances. Using different ordering of the
training set we obtain the same result.
Figure 1 (right) presents the precision for each
class and overall in relation to the number of train-
ing instances for each one of them. Recall grows
similarly to precision. Under all conditions, sub-
jects are classified with a high precision since the
information given by the parser (collected in the
features) achieves an accuracy of 74.9% for the
identification of explicit subjects.
The impersonal construction class has the
fastest learning curve. When utilizing a training
set of only 163 instances (90% of the training
data), it reaches a precision of 63.2%. The un-
stable behaviour for impersonal constructions can
be attributed to not having enough training data
for that class, since impersonals are not frequent
in Spanish. On the other hand, the zero subject
class is learned more gradually.
The learning curve for the explicit subject class
is almost flat due to the great variety of subjects
occurring in the training data. In addition, reach-
ing a precision of 92.0% for explicit subjects us-
ing just 20% of the training data is far more ex-
pensive in terms of the number of training in-
stances (978) as seen in Figure 1 (right). Actually,
with just 20% of the training data we can already
achieve a precision of 85.9%.
This demonstrates that Elliphant does not need
very large sets of expensive training data and
is able to reach adequate levels of performance
when exploiting far fewer training instances. In
fact, we see that we only need a modest set of
</bodyText>
<page confidence="0.988854">
712
</page>
<figure confidence="0.963251466666667">
Precision (%)
10% 20% 30% 40% 50% 60% 70% 80% 90% 100%
Precision Recall F-measure
10% 20% 30% 40% 50% 60% 70% 80% 90% 100%
% 86.5% 86.6%
86.0%
86.4%
86.3%
85.5%
85.6% 85.3%
85.2%
85.8%
85.7%
86.60
86.00
85.40
84.80
84.20
83.60
83.00
498 978 1461 1929 2433 2898 3400 3899 4386 4854
93.00
Explicit subjects
86.71
Overall
80.43
354 537 735 898 1094 1249 1416 1593 1793
74.14
Zero subjects
67.86
61.57
55.29
49.00
167
49
17
32
Impersonal
constructions
66 82
103
129
146
179
163
</figure>
<figureCaption confidence="0.9981195">
Figure 1: Learning curve for precision, recall and F-measure (left) and with respect to the number of instances
of each class (right) for a given percentage of training data.
</figureCaption>
<bodyText confidence="0.9298965">
annotated instances (fewer than 1,500) to achieve
good results.
</bodyText>
<subsectionHeader confidence="0.999682">
6.3 Impact of Genre
</subsectionHeader>
<bodyText confidence="0.999812454545455">
To examine the influence of the different text gen-
res on this method, we divided our training data
into two subgroups belonging to different genres
(legal and health) and analyze the differences.
A comparative evaluation using ten-fold cross-
validation over the two subgroups shows that El-
liphant is more successful when classifying in-
stances of explicit subjects in legal texts (89.8%
accuracy) than health texts (85.4% accuracy).
This may be explained by the greater uniformity
of the sentences in the legal genre compared to
ones from the health genre, as well as the fact that
there are a larger number of explicit subjects in the
legal training data (2,739 compared with 2,116 in
the health texts). Further, texts from the health
genre present the additional complication of spe-
cialized named entities and acronyms, which are
used quite frequently. Similarly, better perfor-
mance in the detection of zero subjects and imper-
sonal sentences in the health texts may be due to
their more frequent occurrence and hence greater
learnability.
</bodyText>
<table confidence="0.998609">
Training/Testing Legal Health All
Legal 90.0% 86.8% 89.3%
Health 86.8% 85.9% 88.7%
All 92.5% 93.7% 87.6%
</table>
<tableCaption confidence="0.745039833333333">
Table 7: Accuracy of cross-genre training and testing
evaluation (ten-fold evaluation).
We have also studied the effect of training the
classifier on data derived from one genre and test-
ing on instances derived from a different genre.
Table 7 shows that instances from legal texts
</tableCaption>
<bodyText confidence="0.99944775">
are more homogeneous, as the classifier obtains
higher accuracy when testing and training only on
legal instances (90.0%). In addition, legal texts
are also more informative, because when both le-
gal and health genres are combined as training
data, only instances from the health genre show
a significant increased accuracy (93.7%). These
results reveal that the health texts are the most het-
erogeneous ones. In fact, we also found subsets of
the legal documents where our method achieves
an accuracy of 94.6%, implying more homoge-
neous texts.
</bodyText>
<subsectionHeader confidence="0.838799">
6.4 Error Analysis
</subsectionHeader>
<bodyText confidence="0.999982695652174">
Since the features of the system are linguisti-
cally motivated, we performed a linguistic anal-
ysis of the erroneously classified instances to find
out which patterns are more difficult to classify
and which type of information would improve the
method (Rello et al., 2011).
We extract the erroneously classified instances
of our training data and classify the errors. Ac-
cording to the distribution of the errors per class
(Table 8) we take into account the following four
classes of errors for the analysis: (a) impersonal
constructions classified as zero subjects, (b) im-
personal constructions classified as explicit sub-
jects, (c) zero subjects classified as explicit sub-
jects, and (d) explicit subjects classified as zero
subjects. The diagonal numbers are the true pre-
dicted cases. The classification of impersonal
constructions is less balanced than the ones for
explicit subjects and zero subjects. Most of the
wrongly identified instances are classified as ex-
plicit subject, given that this class is the largest
one. On the other hand, 25% of the zero subjects
are classified as explicit subject, while only 8% of
</bodyText>
<page confidence="0.996924">
713
</page>
<table confidence="0.974530666666667">
the explicit subjects are identified as zero subjects.
Class Zero Explicit Impers.
subjects subjects
Zero subj. 1327 453 (c) 13
Explicit subj. 368 (d) 4481 6
Impersonals 25 (a) 41 (b) 113
</table>
<tableCaption confidence="0.999507">
Table 8: Confusion Matrix (ten-fold validation).
</tableCaption>
<bodyText confidence="0.999585461538462">
For the analysis we first performed an explo-
ration of the feature values which allows us to
generate smaller samples of the groups of errors
for the further linguistic analyses. Then, we ex-
plore the linguistic characteristics of the instances
by examining the clause in which the instance ap-
pears in our corpus. A great variety of different
patterns are found. We mention only the linguistic
characteristics in the errors which at least double
the corpus general trends.
In all groups (a-d) there is a tendency of using
the following elements: post-verbal prepositions,
auxiliary verbs, future verbal tenses, subjunctive
verbal mode, negation, punctuation marks ap-
pearing before the verb and the preceding noun
phrases, concessive and adverbial subordinate
clauses. In groups (a) and (b) the lemma of the
verb may play a relevant role, for instance verb
haber (‘there is/are’) appears in the errors seven
times more than in the training while verb tratar
(‘to be about’, ‘to deal with’) appears 12 times
more. Finally, in groups (c) and (d) we notice
the frequent occurrence of idioms which include
verbs with impersonal uses, such as es decir (‘that
is to say’) and words which can be subject on their
own i.e. ambos (‘both’) or todo (‘all’).
</bodyText>
<sectionHeader confidence="0.997254" genericHeader="conclusions">
7 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999975545454545">
In this study we learn which is the most accurate
approach for identifying explicit subjects and im-
personal constructions in Spanish and which are
the linguistic characteristics and features that help
to perform this task. The corpus created is freely
available online.5 Our method complements pre-
vious work on Spanish anaphora resolution by ad-
dressing the identification of non-referential con-
structions. It outperforms current approaches in
explicit subject detection and impersonal con-
structions, doing better than the parser for every
</bodyText>
<footnote confidence="0.61735">
5ESZIC es Corpus is available at: http:
//luzrello.com/Projects.html.
</footnote>
<bodyText confidence="0.998889375">
class.
A possible future avenue to explore could be
to combine our approach with Ferr´andez and
Peral (Ferr´andez and Peral, 2000) by employing
both algorithms in sequence: first Ferr´andez and
Peral’s algorithm to detect all zero subjects and
then ours to identify explicit subjects and imper-
sonals. Assuming that the same accuracy could be
maintained, on our data set the combined perfor-
mance could potentially be in the range of 95%.
Future research goals are the extrinsic evalua-
tion of our system by integrating our system in
NLP tasks and its adaptation to other Romance
pro-drop languages. Finally, we believe that our
ML approach could be improved as it is the first
attempt of this kind.
</bodyText>
<sectionHeader confidence="0.996282" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9991685">
We thank Richard Evans, Julio Gonzalo and the
anonymous reviewers for their wise comments.
</bodyText>
<sectionHeader confidence="0.998183" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998533">
R. Artstein and M. Poesio. 2008. Inter-coder agree-
ment for computational linguistics. Computational
Linguistics, 34(4):555–596.
S. Bergsma, D. Lin, and R. Goebel. 2008. Distri-
butional identification of non-referential pronouns.
In Proceedings of the 46th Annual Meeting of the
Association for Computational Linguistics: Human
Language Technologies (ACL/HLT-08), pages 10–
18.
I. Bosque. 1989. Clases de sujetos t´acitos. In Julio
Borrego Nieto, editor, Philologica: homenaje a An-
tonio Llorente, volume 2, pages 91–112. Servicio
de Publicaciones, Universidad Pontificia de Sala-
manca, Salamanca.
A. Boyd, W. Gegg-Harrison, and D. Byron. 2005.
Identifying non-referential it: a machine learning
approach incorporating linguistically motivated pat-
terns. In Proceedings of the ACL Workshop on Fea-
ture Engineering for Machine Learning in Natural
Language Processing. 43rd Annual Meeting of the
Association for Computational Linguistics (ACL-
05), pages 40–47.
J. M. Brucart. 1999. La elipsis. In I. Bosque
and V. Demonte, editors, Gramdtica descriptiva de
la lengua espanola, volume 2, pages 2787–2863.
Espasa-Calpe, Madrid.
N. Chomsky. 1981. Lectures on Government and
Binding. Mouton de Gruyter, Berlin, New York.
J.G. Cleary and L.E. Trigg. 1995. K*: an instance-
based learner using an entropic distance measure.
In Proceedings of the 12th International Conference
on Machine Learning (ICML-95), pages 108–114.
</reference>
<page confidence="0.981149">
714
</page>
<reference confidence="0.99978973">
Connexor Oy, 2006. Machinese language model.
L. Danlos. 2005. Automatic recognition of French
expletive pronoun occurrences. In Robert Dale,
Kam-Fai Wong, Jiang Su, and Oi Yee Kwong, ed-
itors, Natural language processing. Proceedings of
the 2nd International Joint Conference on Natural
Language Processing (IJCNLP-05), pages 73–78,
Berlin, Heidelberg, New York. Springer. Lecture
Notes in Computer Science, Vol. 3651.
R. Evans. 2001. Applying machine learning: toward
an automatic classification of it. Literary and Lin-
guistic Computing, 16(1):45–57.
A. Ferr´andez and J. Peral. 2000. A computational ap-
proach to zero-pronouns in Spanish. In Proceedings
of the 38th Annual Meeting of the Association for
Computational Linguistics (ACL-2000), pages 166–
172.
J. L. Fleiss. 1971. Measuring nominal scale agree-
ment among many raters. Psychological Bulletin,
76(5):378–382.
G. Hirst. 1981. Anaphora in natural language under-
standing: a survey. Springer-Verlag.
J. Hobbs. 1977. Resolving pronoun references. Lin-
gua, 44:311–338.
R. Mitkov and C. Hallett. 2007. Comparing pronoun
resolution algorithms. Computational Intelligence,
23(2):262–297.
R. Mitkov. 2002. Anaphora resolution. Longman,
London.
R. Mitkov. 2010. Discourse processing. In Alexander
Clark, Chris Fox, and Shalom Lappin, editors, The
handbook of computational linguistics and natural
language processing, pages 599–629. Wiley Black-
well, Oxford.
C. M¨uller. 2006. Automatic detection of nonrefer-
ential it in spoken multi-party dialog. In Proceed-
ings of the 11th Conference of the European Chap-
ter of the Association for Computational Linguistics
(EACL-06), pages 49–56.
V. Ng and C. Cardie. 2002. Identifying anaphoric
and non-anaphoric noun phrases to improve coref-
erence resolution. In Proceedings of the 19th Inter-
national Conference on Computational Linguistics
(COLING-02), pages 1–7.
Real Academia Espa˜nola. 2001. Diccionario de la
lengua espa˜nola. Espasa-Calpe, Madrid, 22 edi-
tion.
Real Academia Espa˜nola. 2009. Nueva gram´atica de
la lengua espa˜nola. Espasa-Calpe, Madrid.
M. Recasens and E. Hovy. 2009. A deeper
look into features for coreference resolution. In
Lalitha Devi Sobha, Ant´onio Branco, and Ruslan
Mitkov, editors, Anaphora Processing and Applica-
tions. Proceedings of the 7th Discourse Anaphora
and Anaphor Resolution Colloquium (DAARC-09),
pages 29–42. Springer, Berlin, Heidelberg, New
York. Lecture Notes in Computer Science, Vol.
5847.
M. Recasens and M.A. Mart´ı. 2010. Ancora-
co: Coreferentially annotated corpora for Spanish
and Catalan. Language resources and evaluation,
44(4):315–345.
L. Rello and I. Illisei. 2009a. A comparative study
of Spanish zero pronoun distribution. In Proceed-
ings of the International Symposium on Data and
Sense Mining, Machine Translation and Controlled
Languages, and their application to emergencies
and safety critical domains (ISMTCL-09), pages
209–214. Presses Universitaires de Franche-Comt´e,
Besanc¸on.
L. Rello and I. Illisei. 2009b. A rule-based approach
to the identification of Spanish zero pronouns. In
Student Research Workshop. International Confer-
ence on Recent Advances in Natural Language Pro-
cessing (RANLP-09), pages 209–214.
L. Rello, P. Su´arez, and R. Mitkov. 2010. A machine
learning method for identifying non-referential im-
personal sentences and zero pronouns in Spanish.
Procesamiento del Lenguaje Natural, 45:281–287.
L. Rello, G. Ferraro, and A. Burga. 2011. Error analy-
sis for the improvement of subject ellipsis detection.
Procesamiento de Lenguaje Natural, 47:223–230.
L. Rello. 2010. Elliphant: A machine learning method
for identifying subject ellipsis and impersonal con-
structions in Spanish. Master’s thesis, Erasmus
Mundus, University of Wolverhampton &amp; Univer-
sitat Aut`onoma de Barcelona.
P. Tapanainen and T. J¨arvinen. 1997. A non-projective
dependency parser. In Proceedings of the 5th Con-
ference on Applied Natural Language Processing
(ANLP-97), pages 64–71.
I. H. Witten and E. Frank. 2005. Data mining: practi-
cal machine learning tools and techniques. Morgan
Kaufmann, London, 2 edition.
S. Zhao and H.T. Ng. 2007. Identification and resolu-
tion of Chinese zero pronouns: a machine learning
approach. In Proceedings of the 2007 Joint Con-
ference on Empirical Methods in Natural Language
Processing and Computational Natural Language
Learning (EMNLP/CNLL-07), pages 541–550.
</reference>
<page confidence="0.99854">
715
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.661632">
<title confidence="0.9688465">Elliphant: Improved Automatic Detection of Zero Subjects and Impersonal Constructions in Spanish</title>
<author confidence="0.790454">Baeza-Yates Ruslan Mitkov</author>
<affiliation confidence="0.8708965">NLP and Web Research Groups Yahoo! Research Research Group in Univ. Pompeu Fabra Barcelona, Spain Computational Linguistics</affiliation>
<address confidence="0.992657">Barcelona, Spain Univ. of Wolverhampton, UK</address>
<abstract confidence="0.999680045454545">In pro-drop languages, the detection of explicit subjects, zero subjects and nonreferential impersonal constructions is crucial for anaphora and co-reference resolution. While the identification of explicit and zero subjects has attracted the attention of researchers in the past, the automatic identification of impersonal constructions in Spanish has not been addressed yet and this work is the first such study. In this paper we present a corpus to underpin research on the automatic detection of these linguistic phenomena in Spanish and a novel machine learning-based methodology for their computational treatment. This study also provides an analysis of the features, discusses performance across two different genres and offers error analysis. The evaluation results show that our system performs better in detecting explicit subjects than alternative systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Artstein</author>
<author>M Poesio</author>
</authors>
<title>Inter-coder agreement for computational linguistics.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>4</issue>
<contexts>
<context position="11495" citStr="Artstein and Poesio, 2008" startWordPosition="1787" endWordPosition="1790">. To measure inter-annotator reliability we use Fleiss’ Kappa statistical measure (Fleiss, 1971). We extracted 10% of the instances of each of the texts of the corpus covering the two genres. Fleiss’ Kappa Legal Health All Two Annotators 0.934 0.870 0.902 Three Annotators 0.925 0.857 0.891 Table 3: Inter-annotator Agreement. In Table 3 we present the Fleiss kappa interannotator agreement for two and three annotators. These results suggest that the annotation is reliable since it is common practice among researchers in computational linguistics to consider 0.8 as a minimum value of acceptance (Artstein and Poesio, 2008). 5 Machine Learning Approach We opted for an ML approach given that our previous rule-based methodology improved only 0.02 over the 0.55 F-measure of a simple baseline (Rello and Illisei, 2009b). Besides, ML based methods for the identification of explicit nonreferential constructions in English appear to perform better than than rule-based ones (Boyd et al., 2005). 708 LINGUISTIC INFORMATION PHONETIC SYNTACTIC VERBAL SEMANTIC DISCOURSE REALIZATION CATEGORY DIATHESIS INTERPR. Annotation Annotation Elliptic Ell. noun Nominal Active Active Referential Categories Tags noun phrase subject partici</context>
</contexts>
<marker>Artstein, Poesio, 2008</marker>
<rawString>R. Artstein and M. Poesio. 2008. Inter-coder agreement for computational linguistics. Computational Linguistics, 34(4):555–596.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bergsma</author>
<author>D Lin</author>
<author>R Goebel</author>
</authors>
<title>Distributional identification of non-referential pronouns.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL/HLT-08),</booktitle>
<pages>10--18</pages>
<contexts>
<context position="5944" citStr="Bergsma et al., 2008" startWordPosition="922" endWordPosition="925">will be what is established in the next section. 1All the examples provided are taken from our corpus. In the examples, explicit subjects are presented in italics. Zero subjects are presented by the symbol Ø and in the English translations the subjects which are elided in Spanish are marked with parentheses. Impersonal constructions are not explicitly indicated. 3 Related Work Identification of non-referential pronouns, although a crucial step in co-reference and anaphora resolution systems (Mitkov, 2010),2 has been applied only to the pleonastic it in English (Evans, 2001; Boyd et al., 2005; Bergsma et al., 2008) and expletive pronouns in French (Danlos, 2005). Machine learning methods are known to perform better than rule-based techniques for identifying non-referential expressions (Boyd et al., 2005). However, there is some debate as to which approach may be optimal in anaphora resolution systems (Mitkov and Hallett, 2007). Both English and French texts use an explicit word, with some grammatical information (a third person pronoun), which is non-referential (Mitkov, 2010). By contrast, in Spanish, nonreferential expressions are not realized by expletive or pleonastic pronouns but rather by a certai</context>
<context position="7349" citStr="Bergsma et al., 2008" startWordPosition="1136" endWordPosition="1139">nguishing verbs with explicit subjects and verbs with zero subjects (zero pronouns), using rule-based methods (Ferr´andez and Peral, 2000; Rello and Illisei, 2009b). The Ferr´andez and Peral algorithm (2000) outperforms the (Rello and Illisei, 2009b) approach with 57% accuracy in identifying zero subjects. In (Ferr´andez and Peral, 2000), the implementation of a zero subject identification and resolution module forms part of an anaphora resolution system. ML based studies on the identification of explicit non-referential constructions in English present accuracies of 71% (Evans, 2001), 87.5% (Bergsma et al., 2008) and 88% (Boyd et al., 2005), while 97.5% is achieved for French (Danlos, 2005). However, in these languages, nonreferential constructions are explicit and not omitted which makes this task more challenging for Spanish. 4 Corpus We created and annotated a corpus composed of legal texts (law) and health texts (psychiatric 2In zero anaphora resolution, the identification of zero anaphors first requires that they be distinguished from nonreferential impersonal constructions (Mitkov, 2010). 707 papers) originally written in peninsular Spanish. The corpus is named after its annotated content “Expli</context>
</contexts>
<marker>Bergsma, Lin, Goebel, 2008</marker>
<rawString>S. Bergsma, D. Lin, and R. Goebel. 2008. Distributional identification of non-referential pronouns. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL/HLT-08), pages 10– 18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Bosque</author>
</authors>
<title>Clases de sujetos t´acitos.</title>
<date>1989</date>
<booktitle>Philologica: homenaje a Antonio Llorente,</booktitle>
<volume>2</volume>
<pages>91--112</pages>
<editor>In Julio Borrego Nieto, editor,</editor>
<location>Salamanca.</location>
<contexts>
<context position="4023" citStr="Bosque, 1989" startWordPosition="614" endWordPosition="615">r Computational Linguistics, pages 706–715, Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics genre impact and the error analysis are all detailed in Section 6. Finally, in Section 7, conclusions are drawn and plans for future work are discussed. This work is an extension of the first author master’s thesis (Rello, 2010) and a preliminary version of the algorithm was presented in Rello et al. (2010). 2 Classes of Spanish Subjects Literature related to ellipsis in NLP (Ferr´andez and Peral, 2000; Rello and Illisei, 2009a; Mitkov, 2010) and linguistic theory (Bosque, 1989; Brucart, 1999; Real Academia Espa˜nola, 2009) has served as a basis for establishing the classes of this work. Explicit subjects are phonetically realized and their syntactic position can be pre-verbal or postverbal. In the case of post-verbal subjects (a), the syntactic position is restricted by some conditions (Real Academia Espa˜nola, 2009). (a) Carecer´an de validez las disposiciones que contradigan otra de rango superior.1 The dispositions which contradict higher range ones will not be valid. Zero subjects (b) appear as the result of a nominal ellipsis. That is, a lexical element –the e</context>
</contexts>
<marker>Bosque, 1989</marker>
<rawString>I. Bosque. 1989. Clases de sujetos t´acitos. In Julio Borrego Nieto, editor, Philologica: homenaje a Antonio Llorente, volume 2, pages 91–112. Servicio de Publicaciones, Universidad Pontificia de Salamanca, Salamanca.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Boyd</author>
<author>W Gegg-Harrison</author>
<author>D Byron</author>
</authors>
<title>Identifying non-referential it: a machine learning approach incorporating linguistically motivated patterns.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Workshop on Feature Engineering for Machine Learning in Natural Language Processing. 43rd Annual Meeting of the Association for Computational Linguistics (ACL05),</booktitle>
<pages>40--47</pages>
<contexts>
<context position="5921" citStr="Boyd et al., 2005" startWordPosition="918" endWordPosition="921">do siguiente. (It) will be what is established in the next section. 1All the examples provided are taken from our corpus. In the examples, explicit subjects are presented in italics. Zero subjects are presented by the symbol Ø and in the English translations the subjects which are elided in Spanish are marked with parentheses. Impersonal constructions are not explicitly indicated. 3 Related Work Identification of non-referential pronouns, although a crucial step in co-reference and anaphora resolution systems (Mitkov, 2010),2 has been applied only to the pleonastic it in English (Evans, 2001; Boyd et al., 2005; Bergsma et al., 2008) and expletive pronouns in French (Danlos, 2005). Machine learning methods are known to perform better than rule-based techniques for identifying non-referential expressions (Boyd et al., 2005). However, there is some debate as to which approach may be optimal in anaphora resolution systems (Mitkov and Hallett, 2007). Both English and French texts use an explicit word, with some grammatical information (a third person pronoun), which is non-referential (Mitkov, 2010). By contrast, in Spanish, nonreferential expressions are not realized by expletive or pleonastic pronouns</context>
<context position="7377" citStr="Boyd et al., 2005" startWordPosition="1142" endWordPosition="1145">ubjects and verbs with zero subjects (zero pronouns), using rule-based methods (Ferr´andez and Peral, 2000; Rello and Illisei, 2009b). The Ferr´andez and Peral algorithm (2000) outperforms the (Rello and Illisei, 2009b) approach with 57% accuracy in identifying zero subjects. In (Ferr´andez and Peral, 2000), the implementation of a zero subject identification and resolution module forms part of an anaphora resolution system. ML based studies on the identification of explicit non-referential constructions in English present accuracies of 71% (Evans, 2001), 87.5% (Bergsma et al., 2008) and 88% (Boyd et al., 2005), while 97.5% is achieved for French (Danlos, 2005). However, in these languages, nonreferential constructions are explicit and not omitted which makes this task more challenging for Spanish. 4 Corpus We created and annotated a corpus composed of legal texts (law) and health texts (psychiatric 2In zero anaphora resolution, the identification of zero anaphors first requires that they be distinguished from nonreferential impersonal constructions (Mitkov, 2010). 707 papers) originally written in peninsular Spanish. The corpus is named after its annotated content “Explicit Subjects, Zero Subjects </context>
<context position="11863" citStr="Boyd et al., 2005" startWordPosition="1846" endWordPosition="1849">ator agreement for two and three annotators. These results suggest that the annotation is reliable since it is common practice among researchers in computational linguistics to consider 0.8 as a minimum value of acceptance (Artstein and Poesio, 2008). 5 Machine Learning Approach We opted for an ML approach given that our previous rule-based methodology improved only 0.02 over the 0.55 F-measure of a simple baseline (Rello and Illisei, 2009b). Besides, ML based methods for the identification of explicit nonreferential constructions in English appear to perform better than than rule-based ones (Boyd et al., 2005). 708 LINGUISTIC INFORMATION PHONETIC SYNTACTIC VERBAL SEMANTIC DISCOURSE REALIZATION CATEGORY DIATHESIS INTERPR. Annotation Annotation Elliptic Ell. noun Nominal Active Active Referential Categories Tags noun phrase subject participant subject phrase head Explicit Explicit subject – – + + + + subject Reflex passive – – + + – + subject Passive subject – – + – – + Zero Omitted subject + – + + + + subject Omitted subject – + + + + + head Non-nominal – – – + + + subject Reflex passive + – + + – + omitted subject Reflex pass. omit- – + + + – + ted subject head Reflex pass. non- – – – + – + nominal</context>
<context position="19106" citStr="Boyd et al., 2005" startWordPosition="3066" endWordPosition="3069">g a method motivated by information theory, where a maximum entropy-based distance function is used (Cleary and Trigg, 1995). Table 5 shows the results for each class using ten-fold cross-validation. In contrast to previous work, the K* algorithm (Cleary and Trigg, 1995) was found to provide the most accurate classification in the current study. Other approaches have employed various classification algorithms, including JRip in WEKA (M¨uller, 2006), with precision of 74% and recall of 60%, and K-nearest neighbors in TiMBL: both in (Evans, 2001) with precision of 73% and recall of 69%, and in (Boyd et al., 2005) with precision of 82% and recall of 71%. Since there is no previous ML approach for this task in Spanish, our baselines for the explicit subjects and the zero subjects are the parser output and the previous rule-based work with the highest performance (Ferr´andez and Peral, 2000). For the impersonal constructions the baseline is a simple greedy algorithm that classifies as an impersonal construction every verb whose lemma is categorized as a verb with impersonal use according to the RAE dictionary (Real Academia Espa˜nola, 2001). Our method outperforms the Connexor parser which identifies the</context>
</contexts>
<marker>Boyd, Gegg-Harrison, Byron, 2005</marker>
<rawString>A. Boyd, W. Gegg-Harrison, and D. Byron. 2005. Identifying non-referential it: a machine learning approach incorporating linguistically motivated patterns. In Proceedings of the ACL Workshop on Feature Engineering for Machine Learning in Natural Language Processing. 43rd Annual Meeting of the Association for Computational Linguistics (ACL05), pages 40–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Brucart</author>
</authors>
<title>La elipsis. In</title>
<date>1999</date>
<booktitle>Gramdtica descriptiva de la lengua espanola,</booktitle>
<volume>2</volume>
<pages>2787--2863</pages>
<editor>I. Bosque and V. Demonte, editors,</editor>
<publisher>Espasa-Calpe,</publisher>
<location>Madrid.</location>
<contexts>
<context position="4038" citStr="Brucart, 1999" startWordPosition="616" endWordPosition="618">l Linguistics, pages 706–715, Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics genre impact and the error analysis are all detailed in Section 6. Finally, in Section 7, conclusions are drawn and plans for future work are discussed. This work is an extension of the first author master’s thesis (Rello, 2010) and a preliminary version of the algorithm was presented in Rello et al. (2010). 2 Classes of Spanish Subjects Literature related to ellipsis in NLP (Ferr´andez and Peral, 2000; Rello and Illisei, 2009a; Mitkov, 2010) and linguistic theory (Bosque, 1989; Brucart, 1999; Real Academia Espa˜nola, 2009) has served as a basis for establishing the classes of this work. Explicit subjects are phonetically realized and their syntactic position can be pre-verbal or postverbal. In the case of post-verbal subjects (a), the syntactic position is restricted by some conditions (Real Academia Espa˜nola, 2009). (a) Carecer´an de validez las disposiciones que contradigan otra de rango superior.1 The dispositions which contradict higher range ones will not be valid. Zero subjects (b) appear as the result of a nominal ellipsis. That is, a lexical element –the elliptic subject</context>
</contexts>
<marker>Brucart, 1999</marker>
<rawString>J. M. Brucart. 1999. La elipsis. In I. Bosque and V. Demonte, editors, Gramdtica descriptiva de la lengua espanola, volume 2, pages 2787–2863. Espasa-Calpe, Madrid.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chomsky</author>
</authors>
<date>1981</date>
<booktitle>Lectures on Government and Binding. Mouton de Gruyter,</booktitle>
<location>Berlin, New York.</location>
<contexts>
<context position="2039" citStr="Chomsky, 1981" startWordPosition="300" endWordPosition="301"> language processing (NLP) tasks benefit from the identification of elliptical subjects, primarily anaphora resolution (Mitkov, 2002) and co-reference resolution (Ng and Cardie, 2002). The difficulty in detecting missing subjects and non-referential pronouns has been acknowledged since the first studies on * This work was partially funded by a ‘La Caixa’ grant for master students. the computational treatment of anaphora (Hobbs, 1977; Hirst, 1981). However, this task is of crucial importance when processing pro-drop languages since subject ellipsis is a pervasive phenomenon in these languages (Chomsky, 1981). For instance, in our Spanish corpus, 29% of the subjects are elided. Our method is based on classification of all expressions in subject position, including the recognition of Spanish non-referential impersonal constructions which, to the best of our knowledge, has not yet been addressed. The necessity of identifying such kind of elliptical constructions has been specifically highlighted in work about Spanish zero pronouns (Ferr´andez and Peral, 2000) and co-reference resolution (Recasens and Hovy, 2009). The main contributions of this study are: • A public annotated corpus in Spanish to com</context>
</contexts>
<marker>Chomsky, 1981</marker>
<rawString>N. Chomsky. 1981. Lectures on Government and Binding. Mouton de Gruyter, Berlin, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J G Cleary</author>
<author>L E Trigg</author>
</authors>
<title>K*: an instancebased learner using an entropic distance measure.</title>
<date>1995</date>
<booktitle>In Proceedings of the 12th International Conference on Machine Learning (ICML-95),</booktitle>
<pages>108--114</pages>
<contexts>
<context position="18260" citStr="Cleary and Trigg, 1995" startWordPosition="2930" endWordPosition="2933"> 100% of the 4We used four lists provided by Molino de Ideas s.a. containing 11,060 different verb lemmas belonging to the Royal Spanish Academy Dictionary (Real Academia Espa˜nola, 2001). 710 Class P R F Acc. Explicit subj. 90.1% 92.3% 91.2% 87.3% Zero subj. 77.2% 74.0% 75.5% 87.4% Impersonals 85.6% 63.1% 72.7% 98.8% Table 5: K* performance (87.6% accuracy for ten-fold cross validation). training data and ten-fold cross-validation. The corpus was partitioned into training and tested using ten-fold cross-validation for randomly ordered instances in both cases. The lazy learning classifier K* (Cleary and Trigg, 1995), using a blending parameter of 40%, was the best performing one, with an accuracy of 87.6% for ten-fold cross-validation. K* differs from other instance-based learners in that it computes the distance between two instances using a method motivated by information theory, where a maximum entropy-based distance function is used (Cleary and Trigg, 1995). Table 5 shows the results for each class using ten-fold cross-validation. In contrast to previous work, the K* algorithm (Cleary and Trigg, 1995) was found to provide the most accurate classification in the current study. Other approaches have em</context>
</contexts>
<marker>Cleary, Trigg, 1995</marker>
<rawString>J.G. Cleary and L.E. Trigg. 1995. K*: an instancebased learner using an entropic distance measure. In Proceedings of the 12th International Conference on Machine Learning (ICML-95), pages 108–114.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Connexor Oy</author>
</authors>
<date>2006</date>
<note>Machinese language model.</note>
<contexts>
<context position="9044" citStr="Oy, 2006" startWordPosition="1400" endWordPosition="1401">0) while the Zcorpus (Rello and Illisei, 2009b) comprises legal, instructional and encyclopedic texts but has no annotated impersonal constructions. The ESZIC corpus contains a total of 6,827 verbs including 1,793 zero subjects. Except for AnCora-ES, with 10,791 elliptic pronouns, our corpus is larger than the ones used in previous approaches: about 1,830 verbs including zero and explicit subjects in (Ferr´andez and Peral, 2000) (the exact number is not mentioned in the paper) and 1,202 zero subjects in (Rello and Illisei, 2009b). The corpus was parsed by Connexor’s Machinese Syntax (Connexor Oy, 2006), which returns lexical and morphological information as well as the dependency relations between words by employing a functional dependency grammar (Tapanainen and J¨arvinen, 1997). To annotate our corpus we created an annotation tool that extracts the finite clauses and the annotators assign to each example one of the defined annotation tags. Two volunteer graduate students of linguistics annotated the verbs after one training session. The annotations of a third volunteer with the same profile were used to compute the inter-annotator agreement. During the annotation phase, we evaluated the a</context>
</contexts>
<marker>Oy, 2006</marker>
<rawString>Connexor Oy, 2006. Machinese language model.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Danlos</author>
</authors>
<title>Automatic recognition of French expletive pronoun occurrences.</title>
<date>2005</date>
<journal>Lecture Notes in Computer Science,</journal>
<booktitle>Natural language processing. Proceedings of the 2nd International Joint Conference on Natural Language Processing (IJCNLP-05),</booktitle>
<volume>Vol.</volume>
<pages>73--78</pages>
<editor>In Robert Dale, Kam-Fai Wong, Jiang Su, and Oi Yee Kwong, editors,</editor>
<publisher>Springer.</publisher>
<location>Berlin, Heidelberg, New York.</location>
<contexts>
<context position="5992" citStr="Danlos, 2005" startWordPosition="931" endWordPosition="932">e examples provided are taken from our corpus. In the examples, explicit subjects are presented in italics. Zero subjects are presented by the symbol Ø and in the English translations the subjects which are elided in Spanish are marked with parentheses. Impersonal constructions are not explicitly indicated. 3 Related Work Identification of non-referential pronouns, although a crucial step in co-reference and anaphora resolution systems (Mitkov, 2010),2 has been applied only to the pleonastic it in English (Evans, 2001; Boyd et al., 2005; Bergsma et al., 2008) and expletive pronouns in French (Danlos, 2005). Machine learning methods are known to perform better than rule-based techniques for identifying non-referential expressions (Boyd et al., 2005). However, there is some debate as to which approach may be optimal in anaphora resolution systems (Mitkov and Hallett, 2007). Both English and French texts use an explicit word, with some grammatical information (a third person pronoun), which is non-referential (Mitkov, 2010). By contrast, in Spanish, nonreferential expressions are not realized by expletive or pleonastic pronouns but rather by a certain kind of ellipsis. For this reason, it is easy </context>
<context position="7428" citStr="Danlos, 2005" startWordPosition="1152" endWordPosition="1154">ing rule-based methods (Ferr´andez and Peral, 2000; Rello and Illisei, 2009b). The Ferr´andez and Peral algorithm (2000) outperforms the (Rello and Illisei, 2009b) approach with 57% accuracy in identifying zero subjects. In (Ferr´andez and Peral, 2000), the implementation of a zero subject identification and resolution module forms part of an anaphora resolution system. ML based studies on the identification of explicit non-referential constructions in English present accuracies of 71% (Evans, 2001), 87.5% (Bergsma et al., 2008) and 88% (Boyd et al., 2005), while 97.5% is achieved for French (Danlos, 2005). However, in these languages, nonreferential constructions are explicit and not omitted which makes this task more challenging for Spanish. 4 Corpus We created and annotated a corpus composed of legal texts (law) and health texts (psychiatric 2In zero anaphora resolution, the identification of zero anaphors first requires that they be distinguished from nonreferential impersonal constructions (Mitkov, 2010). 707 papers) originally written in peninsular Spanish. The corpus is named after its annotated content “Explicit Subjects, Zero Subjects and Impersonal Constructions” (ESZIC es Corpus). To</context>
</contexts>
<marker>Danlos, 2005</marker>
<rawString>L. Danlos. 2005. Automatic recognition of French expletive pronoun occurrences. In Robert Dale, Kam-Fai Wong, Jiang Su, and Oi Yee Kwong, editors, Natural language processing. Proceedings of the 2nd International Joint Conference on Natural Language Processing (IJCNLP-05), pages 73–78, Berlin, Heidelberg, New York. Springer. Lecture Notes in Computer Science, Vol. 3651.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Evans</author>
</authors>
<title>Applying machine learning: toward an automatic classification of it.</title>
<date>2001</date>
<booktitle>Literary and Linguistic Computing,</booktitle>
<pages>16--1</pages>
<contexts>
<context position="5902" citStr="Evans, 2001" startWordPosition="916" endWordPosition="917">ece el apartado siguiente. (It) will be what is established in the next section. 1All the examples provided are taken from our corpus. In the examples, explicit subjects are presented in italics. Zero subjects are presented by the symbol Ø and in the English translations the subjects which are elided in Spanish are marked with parentheses. Impersonal constructions are not explicitly indicated. 3 Related Work Identification of non-referential pronouns, although a crucial step in co-reference and anaphora resolution systems (Mitkov, 2010),2 has been applied only to the pleonastic it in English (Evans, 2001; Boyd et al., 2005; Bergsma et al., 2008) and expletive pronouns in French (Danlos, 2005). Machine learning methods are known to perform better than rule-based techniques for identifying non-referential expressions (Boyd et al., 2005). However, there is some debate as to which approach may be optimal in anaphora resolution systems (Mitkov and Hallett, 2007). Both English and French texts use an explicit word, with some grammatical information (a third person pronoun), which is non-referential (Mitkov, 2010). By contrast, in Spanish, nonreferential expressions are not realized by expletive or </context>
<context position="7319" citStr="Evans, 2001" startWordPosition="1133" endWordPosition="1134">psis focused on distinguishing verbs with explicit subjects and verbs with zero subjects (zero pronouns), using rule-based methods (Ferr´andez and Peral, 2000; Rello and Illisei, 2009b). The Ferr´andez and Peral algorithm (2000) outperforms the (Rello and Illisei, 2009b) approach with 57% accuracy in identifying zero subjects. In (Ferr´andez and Peral, 2000), the implementation of a zero subject identification and resolution module forms part of an anaphora resolution system. ML based studies on the identification of explicit non-referential constructions in English present accuracies of 71% (Evans, 2001), 87.5% (Bergsma et al., 2008) and 88% (Boyd et al., 2005), while 97.5% is achieved for French (Danlos, 2005). However, in these languages, nonreferential constructions are explicit and not omitted which makes this task more challenging for Spanish. 4 Corpus We created and annotated a corpus composed of legal texts (law) and health texts (psychiatric 2In zero anaphora resolution, the identification of zero anaphors first requires that they be distinguished from nonreferential impersonal constructions (Mitkov, 2010). 707 papers) originally written in peninsular Spanish. The corpus is named afte</context>
<context position="12931" citStr="Evans, 2001" startWordPosition="2049" endWordPosition="2050">– + + + subject Reflex passive + – + + – + omitted subject Reflex pass. omit- – + + + – + ted subject head Reflex pass. non- – – – + – + nominal subject Passive omitted + – + – – + subject Pass. non-nominal – – – – – + subject Impersonal Reflex imp. clause – – n/a – n/a – construction (with se) Imp. construction – – n/a + n/a – (without se) Table 1: ESZIC Corpus Annotation Tags. 5.1 Features We built the training data from the annotated corpus and defined fourteen features. The linguistically motivated features are inspired by previous ML approaches in Chinese (Zhao and Ng, 2007) and English (Evans, 2001). The values for the features (see Table 4) were derived from information provided both by Connexor’s Machinese Syntax parser and a set of lists. We can describe each of the features as broadly belonging to one of ten classes, as follows: 1 PARSER: the presence or absence of a subject in the clause, as identified by the parser. We are not aware of a formal evaluation of Connexor’s accuracy. It presents an accuracy of 74.9% evaluated against our corpus and we used it as a simple baseline. 2 CLAUSE: the clause types considered are: main clauses, relative clauses starting with a complex conjuncti</context>
<context position="19038" citStr="Evans, 2001" startWordPosition="3054" endWordPosition="3055">rs in that it computes the distance between two instances using a method motivated by information theory, where a maximum entropy-based distance function is used (Cleary and Trigg, 1995). Table 5 shows the results for each class using ten-fold cross-validation. In contrast to previous work, the K* algorithm (Cleary and Trigg, 1995) was found to provide the most accurate classification in the current study. Other approaches have employed various classification algorithms, including JRip in WEKA (M¨uller, 2006), with precision of 74% and recall of 60%, and K-nearest neighbors in TiMBL: both in (Evans, 2001) with precision of 73% and recall of 69%, and in (Boyd et al., 2005) with precision of 82% and recall of 71%. Since there is no previous ML approach for this task in Spanish, our baselines for the explicit subjects and the zero subjects are the parser output and the previous rule-based work with the highest performance (Ferr´andez and Peral, 2000). For the impersonal constructions the baseline is a simple greedy algorithm that classifies as an impersonal construction every verb whose lemma is categorized as a verb with impersonal use according to the RAE dictionary (Real Academia Espa˜nola, 20</context>
</contexts>
<marker>Evans, 2001</marker>
<rawString>R. Evans. 2001. Applying machine learning: toward an automatic classification of it. Literary and Linguistic Computing, 16(1):45–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ferr´andez</author>
<author>J Peral</author>
</authors>
<title>A computational approach to zero-pronouns in Spanish.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics (ACL-2000),</booktitle>
<pages>166--172</pages>
<marker>Ferr´andez, Peral, 2000</marker>
<rawString>A. Ferr´andez and J. Peral. 2000. A computational approach to zero-pronouns in Spanish. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics (ACL-2000), pages 166– 172.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J L Fleiss</author>
</authors>
<title>Measuring nominal scale agreement among many raters.</title>
<date>1971</date>
<journal>Psychological Bulletin,</journal>
<volume>76</volume>
<issue>5</issue>
<contexts>
<context position="10965" citStr="Fleiss, 1971" startWordPosition="1703" endWordPosition="1704">one of the three main classes. • Explicit subjects: [- elliptic, + referential]. • Zero subjects: [+ elliptic, + referential]. • Impersonal constructions: [+ elliptic, - referential]. Of these annotated verbs, 71% have an explicit subject, 26% have a zero subject and 3% belong to an impersonal construction (see Table 2). Number of instances Legal Health All Explicit subjects 2,739 2,116 4,855 Zero subjects 619 1,174 1,793 Impersonals 71 108 179 Total 3,429 3,398 6,827 Table 2: Instances per class in ESZIC Corpus. To measure inter-annotator reliability we use Fleiss’ Kappa statistical measure (Fleiss, 1971). We extracted 10% of the instances of each of the texts of the corpus covering the two genres. Fleiss’ Kappa Legal Health All Two Annotators 0.934 0.870 0.902 Three Annotators 0.925 0.857 0.891 Table 3: Inter-annotator Agreement. In Table 3 we present the Fleiss kappa interannotator agreement for two and three annotators. These results suggest that the annotation is reliable since it is common practice among researchers in computational linguistics to consider 0.8 as a minimum value of acceptance (Artstein and Poesio, 2008). 5 Machine Learning Approach We opted for an ML approach given that o</context>
</contexts>
<marker>Fleiss, 1971</marker>
<rawString>J. L. Fleiss. 1971. Measuring nominal scale agreement among many raters. Psychological Bulletin, 76(5):378–382.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Hirst</author>
</authors>
<title>Anaphora in natural language understanding: a survey.</title>
<date>1981</date>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="1875" citStr="Hirst, 1981" startWordPosition="274" endWordPosition="275">. We consider not only missing referential subject (zero subject) as manifestation of ellipsis, but also non-referential impersonal constructions. Various natural language processing (NLP) tasks benefit from the identification of elliptical subjects, primarily anaphora resolution (Mitkov, 2002) and co-reference resolution (Ng and Cardie, 2002). The difficulty in detecting missing subjects and non-referential pronouns has been acknowledged since the first studies on * This work was partially funded by a ‘La Caixa’ grant for master students. the computational treatment of anaphora (Hobbs, 1977; Hirst, 1981). However, this task is of crucial importance when processing pro-drop languages since subject ellipsis is a pervasive phenomenon in these languages (Chomsky, 1981). For instance, in our Spanish corpus, 29% of the subjects are elided. Our method is based on classification of all expressions in subject position, including the recognition of Spanish non-referential impersonal constructions which, to the best of our knowledge, has not yet been addressed. The necessity of identifying such kind of elliptical constructions has been specifically highlighted in work about Spanish zero pronouns (Ferr´a</context>
</contexts>
<marker>Hirst, 1981</marker>
<rawString>G. Hirst. 1981. Anaphora in natural language understanding: a survey. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hobbs</author>
</authors>
<title>Resolving pronoun references.</title>
<date>1977</date>
<journal>Lingua,</journal>
<pages>44--311</pages>
<contexts>
<context position="1861" citStr="Hobbs, 1977" startWordPosition="272" endWordPosition="273">in a sentence. We consider not only missing referential subject (zero subject) as manifestation of ellipsis, but also non-referential impersonal constructions. Various natural language processing (NLP) tasks benefit from the identification of elliptical subjects, primarily anaphora resolution (Mitkov, 2002) and co-reference resolution (Ng and Cardie, 2002). The difficulty in detecting missing subjects and non-referential pronouns has been acknowledged since the first studies on * This work was partially funded by a ‘La Caixa’ grant for master students. the computational treatment of anaphora (Hobbs, 1977; Hirst, 1981). However, this task is of crucial importance when processing pro-drop languages since subject ellipsis is a pervasive phenomenon in these languages (Chomsky, 1981). For instance, in our Spanish corpus, 29% of the subjects are elided. Our method is based on classification of all expressions in subject position, including the recognition of Spanish non-referential impersonal constructions which, to the best of our knowledge, has not yet been addressed. The necessity of identifying such kind of elliptical constructions has been specifically highlighted in work about Spanish zero pr</context>
</contexts>
<marker>Hobbs, 1977</marker>
<rawString>J. Hobbs. 1977. Resolving pronoun references. Lingua, 44:311–338.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mitkov</author>
<author>C Hallett</author>
</authors>
<title>Comparing pronoun resolution algorithms.</title>
<date>2007</date>
<journal>Computational Intelligence,</journal>
<volume>23</volume>
<issue>2</issue>
<contexts>
<context position="6262" citStr="Mitkov and Hallett, 2007" startWordPosition="969" endWordPosition="972">rsonal constructions are not explicitly indicated. 3 Related Work Identification of non-referential pronouns, although a crucial step in co-reference and anaphora resolution systems (Mitkov, 2010),2 has been applied only to the pleonastic it in English (Evans, 2001; Boyd et al., 2005; Bergsma et al., 2008) and expletive pronouns in French (Danlos, 2005). Machine learning methods are known to perform better than rule-based techniques for identifying non-referential expressions (Boyd et al., 2005). However, there is some debate as to which approach may be optimal in anaphora resolution systems (Mitkov and Hallett, 2007). Both English and French texts use an explicit word, with some grammatical information (a third person pronoun), which is non-referential (Mitkov, 2010). By contrast, in Spanish, nonreferential expressions are not realized by expletive or pleonastic pronouns but rather by a certain kind of ellipsis. For this reason, it is easy to mistake them for zero pronouns, which are, in fact, referential. Previous work on detecting Spanish subject ellipsis focused on distinguishing verbs with explicit subjects and verbs with zero subjects (zero pronouns), using rule-based methods (Ferr´andez and Peral, 2</context>
</contexts>
<marker>Mitkov, Hallett, 2007</marker>
<rawString>R. Mitkov and C. Hallett. 2007. Comparing pronoun resolution algorithms. Computational Intelligence, 23(2):262–297.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mitkov</author>
</authors>
<title>Anaphora resolution.</title>
<date>2002</date>
<publisher>Longman,</publisher>
<location>London.</location>
<contexts>
<context position="1558" citStr="Mitkov, 2002" startWordPosition="226" endWordPosition="227">tudy also provides an analysis of the features, discusses performance across two different genres and offers error analysis. The evaluation results show that our system performs better in detecting explicit subjects than alternative systems. 1 Introduction Subject ellipsis is the omission of the subject in a sentence. We consider not only missing referential subject (zero subject) as manifestation of ellipsis, but also non-referential impersonal constructions. Various natural language processing (NLP) tasks benefit from the identification of elliptical subjects, primarily anaphora resolution (Mitkov, 2002) and co-reference resolution (Ng and Cardie, 2002). The difficulty in detecting missing subjects and non-referential pronouns has been acknowledged since the first studies on * This work was partially funded by a ‘La Caixa’ grant for master students. the computational treatment of anaphora (Hobbs, 1977; Hirst, 1981). However, this task is of crucial importance when processing pro-drop languages since subject ellipsis is a pervasive phenomenon in these languages (Chomsky, 1981). For instance, in our Spanish corpus, 29% of the subjects are elided. Our method is based on classification of all exp</context>
</contexts>
<marker>Mitkov, 2002</marker>
<rawString>R. Mitkov. 2002. Anaphora resolution. Longman, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mitkov</author>
</authors>
<title>Discourse processing. In Alexander</title>
<date>2010</date>
<booktitle>The handbook of computational linguistics and natural language processing,</booktitle>
<pages>599--629</pages>
<editor>Clark, Chris Fox, and Shalom Lappin, editors,</editor>
<publisher>Wiley Blackwell,</publisher>
<location>Oxford.</location>
<contexts>
<context position="3987" citStr="Mitkov, 2010" startWordPosition="609" endWordPosition="610">uropean Chapter of the Association for Computational Linguistics, pages 706–715, Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics genre impact and the error analysis are all detailed in Section 6. Finally, in Section 7, conclusions are drawn and plans for future work are discussed. This work is an extension of the first author master’s thesis (Rello, 2010) and a preliminary version of the algorithm was presented in Rello et al. (2010). 2 Classes of Spanish Subjects Literature related to ellipsis in NLP (Ferr´andez and Peral, 2000; Rello and Illisei, 2009a; Mitkov, 2010) and linguistic theory (Bosque, 1989; Brucart, 1999; Real Academia Espa˜nola, 2009) has served as a basis for establishing the classes of this work. Explicit subjects are phonetically realized and their syntactic position can be pre-verbal or postverbal. In the case of post-verbal subjects (a), the syntactic position is restricted by some conditions (Real Academia Espa˜nola, 2009). (a) Carecer´an de validez las disposiciones que contradigan otra de rango superior.1 The dispositions which contradict higher range ones will not be valid. Zero subjects (b) appear as the result of a nominal ellipsi</context>
<context position="5833" citStr="Mitkov, 2010" startWordPosition="903" endWordPosition="904"> (There is) no marriage without consent. (d) Se estar´a a lo que establece el apartado siguiente. (It) will be what is established in the next section. 1All the examples provided are taken from our corpus. In the examples, explicit subjects are presented in italics. Zero subjects are presented by the symbol Ø and in the English translations the subjects which are elided in Spanish are marked with parentheses. Impersonal constructions are not explicitly indicated. 3 Related Work Identification of non-referential pronouns, although a crucial step in co-reference and anaphora resolution systems (Mitkov, 2010),2 has been applied only to the pleonastic it in English (Evans, 2001; Boyd et al., 2005; Bergsma et al., 2008) and expletive pronouns in French (Danlos, 2005). Machine learning methods are known to perform better than rule-based techniques for identifying non-referential expressions (Boyd et al., 2005). However, there is some debate as to which approach may be optimal in anaphora resolution systems (Mitkov and Hallett, 2007). Both English and French texts use an explicit word, with some grammatical information (a third person pronoun), which is non-referential (Mitkov, 2010). By contrast, in </context>
<context position="7839" citStr="Mitkov, 2010" startWordPosition="1213" endWordPosition="1214"> of explicit non-referential constructions in English present accuracies of 71% (Evans, 2001), 87.5% (Bergsma et al., 2008) and 88% (Boyd et al., 2005), while 97.5% is achieved for French (Danlos, 2005). However, in these languages, nonreferential constructions are explicit and not omitted which makes this task more challenging for Spanish. 4 Corpus We created and annotated a corpus composed of legal texts (law) and health texts (psychiatric 2In zero anaphora resolution, the identification of zero anaphors first requires that they be distinguished from nonreferential impersonal constructions (Mitkov, 2010). 707 papers) originally written in peninsular Spanish. The corpus is named after its annotated content “Explicit Subjects, Zero Subjects and Impersonal Constructions” (ESZIC es Corpus). To the best of our knowledge, the existing corpora annotated with elliptical subjects belong to other genres. The Blue Book (handbook) and Lexesp (journalistic texts) used in (Ferr´andez and Peral, 2000) contain zero subjects but not impersonal constructions. On the other hand, the Spanish AnCora corpus based on journalistic texts includes zero pronouns and impersonal constructions (Recasens and Marti, 2010) w</context>
</contexts>
<marker>Mitkov, 2010</marker>
<rawString>R. Mitkov. 2010. Discourse processing. In Alexander Clark, Chris Fox, and Shalom Lappin, editors, The handbook of computational linguistics and natural language processing, pages 599–629. Wiley Blackwell, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C M¨uller</author>
</authors>
<title>Automatic detection of nonreferential it in spoken multi-party dialog.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL-06),</booktitle>
<pages>49--56</pages>
<marker>M¨uller, 2006</marker>
<rawString>C. M¨uller. 2006. Automatic detection of nonreferential it in spoken multi-party dialog. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL-06), pages 49–56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Ng</author>
<author>C Cardie</author>
</authors>
<title>Identifying anaphoric and non-anaphoric noun phrases to improve coreference resolution.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Computational Linguistics (COLING-02),</booktitle>
<pages>1--7</pages>
<contexts>
<context position="1608" citStr="Ng and Cardie, 2002" startWordPosition="231" endWordPosition="234">res, discusses performance across two different genres and offers error analysis. The evaluation results show that our system performs better in detecting explicit subjects than alternative systems. 1 Introduction Subject ellipsis is the omission of the subject in a sentence. We consider not only missing referential subject (zero subject) as manifestation of ellipsis, but also non-referential impersonal constructions. Various natural language processing (NLP) tasks benefit from the identification of elliptical subjects, primarily anaphora resolution (Mitkov, 2002) and co-reference resolution (Ng and Cardie, 2002). The difficulty in detecting missing subjects and non-referential pronouns has been acknowledged since the first studies on * This work was partially funded by a ‘La Caixa’ grant for master students. the computational treatment of anaphora (Hobbs, 1977; Hirst, 1981). However, this task is of crucial importance when processing pro-drop languages since subject ellipsis is a pervasive phenomenon in these languages (Chomsky, 1981). For instance, in our Spanish corpus, 29% of the subjects are elided. Our method is based on classification of all expressions in subject position, including the recogn</context>
</contexts>
<marker>Ng, Cardie, 2002</marker>
<rawString>V. Ng and C. Cardie. 2002. Identifying anaphoric and non-anaphoric noun phrases to improve coreference resolution. In Proceedings of the 19th International Conference on Computational Linguistics (COLING-02), pages 1–7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Real Academia Espa˜nola</author>
</authors>
<title>Diccionario de la lengua espa˜nola.</title>
<date>2001</date>
<journal>Espasa-Calpe, Madrid,</journal>
<volume>22</volume>
<pages>edition.</pages>
<marker>Espa˜nola, 2001</marker>
<rawString>Real Academia Espa˜nola. 2001. Diccionario de la lengua espa˜nola. Espasa-Calpe, Madrid, 22 edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Real Academia Espa˜nola</author>
</authors>
<title>Nueva gram´atica de la lengua espa˜nola. Espasa-Calpe,</title>
<date>2009</date>
<location>Madrid.</location>
<marker>Espa˜nola, 2009</marker>
<rawString>Real Academia Espa˜nola. 2009. Nueva gram´atica de la lengua espa˜nola. Espasa-Calpe, Madrid.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Recasens</author>
<author>E Hovy</author>
</authors>
<title>A deeper look into features for coreference resolution.</title>
<date>2009</date>
<journal>Lecture Notes in Computer Science,</journal>
<booktitle>Anaphora Processing and Applications. Proceedings of the 7th Discourse Anaphora and Anaphor Resolution Colloquium (DAARC-09),</booktitle>
<volume>Vol.</volume>
<pages>29--42</pages>
<editor>In Lalitha Devi Sobha, Ant´onio Branco, and Ruslan Mitkov, editors,</editor>
<publisher>Springer,</publisher>
<location>Berlin, Heidelberg, New York.</location>
<contexts>
<context position="2550" citStr="Recasens and Hovy, 2009" startWordPosition="377" endWordPosition="380">processing pro-drop languages since subject ellipsis is a pervasive phenomenon in these languages (Chomsky, 1981). For instance, in our Spanish corpus, 29% of the subjects are elided. Our method is based on classification of all expressions in subject position, including the recognition of Spanish non-referential impersonal constructions which, to the best of our knowledge, has not yet been addressed. The necessity of identifying such kind of elliptical constructions has been specifically highlighted in work about Spanish zero pronouns (Ferr´andez and Peral, 2000) and co-reference resolution (Recasens and Hovy, 2009). The main contributions of this study are: • A public annotated corpus in Spanish to compare different strategies for detecting explicit subjects, zero subjects and impersonal constructions. • The first ML based approach to this problem in Spanish and a thorough analysis regarding features, learnability, genre and errors. • The best performing algorithms to automatically detect explicit subjects and impersonal constructions in Spanish. The remainder of the paper is organized as follows. Section 2 describes the classes of Spanish subjects, while Section 3 provides a literature review. Section </context>
</contexts>
<marker>Recasens, Hovy, 2009</marker>
<rawString>M. Recasens and E. Hovy. 2009. A deeper look into features for coreference resolution. In Lalitha Devi Sobha, Ant´onio Branco, and Ruslan Mitkov, editors, Anaphora Processing and Applications. Proceedings of the 7th Discourse Anaphora and Anaphor Resolution Colloquium (DAARC-09), pages 29–42. Springer, Berlin, Heidelberg, New York. Lecture Notes in Computer Science, Vol. 5847.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Recasens</author>
<author>M A Mart´ı</author>
</authors>
<title>Ancoraco: Coreferentially annotated corpora for Spanish and Catalan. Language resources and evaluation,</title>
<date>2010</date>
<pages>44--4</pages>
<marker>Recasens, Mart´ı, 2010</marker>
<rawString>M. Recasens and M.A. Mart´ı. 2010. Ancoraco: Coreferentially annotated corpora for Spanish and Catalan. Language resources and evaluation, 44(4):315–345.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Rello</author>
<author>I Illisei</author>
</authors>
<title>A comparative study of Spanish zero pronoun distribution.</title>
<date>2009</date>
<booktitle>In Proceedings of the International Symposium on Data and Sense Mining, Machine Translation and Controlled Languages, and</booktitle>
<pages>209--214</pages>
<institution>Presses Universitaires de Franche-Comt´e, Besanc¸on.</institution>
<contexts>
<context position="3971" citStr="Rello and Illisei, 2009" startWordPosition="605" endWordPosition="608">e 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 706–715, Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics genre impact and the error analysis are all detailed in Section 6. Finally, in Section 7, conclusions are drawn and plans for future work are discussed. This work is an extension of the first author master’s thesis (Rello, 2010) and a preliminary version of the algorithm was presented in Rello et al. (2010). 2 Classes of Spanish Subjects Literature related to ellipsis in NLP (Ferr´andez and Peral, 2000; Rello and Illisei, 2009a; Mitkov, 2010) and linguistic theory (Bosque, 1989; Brucart, 1999; Real Academia Espa˜nola, 2009) has served as a basis for establishing the classes of this work. Explicit subjects are phonetically realized and their syntactic position can be pre-verbal or postverbal. In the case of post-verbal subjects (a), the syntactic position is restricted by some conditions (Real Academia Espa˜nola, 2009). (a) Carecer´an de validez las disposiciones que contradigan otra de rango superior.1 The dispositions which contradict higher range ones will not be valid. Zero subjects (b) appear as the result of a</context>
<context position="6890" citStr="Rello and Illisei, 2009" startWordPosition="1068" endWordPosition="1071">h English and French texts use an explicit word, with some grammatical information (a third person pronoun), which is non-referential (Mitkov, 2010). By contrast, in Spanish, nonreferential expressions are not realized by expletive or pleonastic pronouns but rather by a certain kind of ellipsis. For this reason, it is easy to mistake them for zero pronouns, which are, in fact, referential. Previous work on detecting Spanish subject ellipsis focused on distinguishing verbs with explicit subjects and verbs with zero subjects (zero pronouns), using rule-based methods (Ferr´andez and Peral, 2000; Rello and Illisei, 2009b). The Ferr´andez and Peral algorithm (2000) outperforms the (Rello and Illisei, 2009b) approach with 57% accuracy in identifying zero subjects. In (Ferr´andez and Peral, 2000), the implementation of a zero subject identification and resolution module forms part of an anaphora resolution system. ML based studies on the identification of explicit non-referential constructions in English present accuracies of 71% (Evans, 2001), 87.5% (Bergsma et al., 2008) and 88% (Boyd et al., 2005), while 97.5% is achieved for French (Danlos, 2005). However, in these languages, nonreferential constructions ar</context>
<context position="8480" citStr="Rello and Illisei, 2009" startWordPosition="1309" endWordPosition="1312">inally written in peninsular Spanish. The corpus is named after its annotated content “Explicit Subjects, Zero Subjects and Impersonal Constructions” (ESZIC es Corpus). To the best of our knowledge, the existing corpora annotated with elliptical subjects belong to other genres. The Blue Book (handbook) and Lexesp (journalistic texts) used in (Ferr´andez and Peral, 2000) contain zero subjects but not impersonal constructions. On the other hand, the Spanish AnCora corpus based on journalistic texts includes zero pronouns and impersonal constructions (Recasens and Marti, 2010) while the Zcorpus (Rello and Illisei, 2009b) comprises legal, instructional and encyclopedic texts but has no annotated impersonal constructions. The ESZIC corpus contains a total of 6,827 verbs including 1,793 zero subjects. Except for AnCora-ES, with 10,791 elliptic pronouns, our corpus is larger than the ones used in previous approaches: about 1,830 verbs including zero and explicit subjects in (Ferr´andez and Peral, 2000) (the exact number is not mentioned in the paper) and 1,202 zero subjects in (Rello and Illisei, 2009b). The corpus was parsed by Connexor’s Machinese Syntax (Connexor Oy, 2006), which returns lexical and morpholo</context>
<context position="11688" citStr="Rello and Illisei, 2009" startWordPosition="1819" endWordPosition="1822">ss’ Kappa Legal Health All Two Annotators 0.934 0.870 0.902 Three Annotators 0.925 0.857 0.891 Table 3: Inter-annotator Agreement. In Table 3 we present the Fleiss kappa interannotator agreement for two and three annotators. These results suggest that the annotation is reliable since it is common practice among researchers in computational linguistics to consider 0.8 as a minimum value of acceptance (Artstein and Poesio, 2008). 5 Machine Learning Approach We opted for an ML approach given that our previous rule-based methodology improved only 0.02 over the 0.55 F-measure of a simple baseline (Rello and Illisei, 2009b). Besides, ML based methods for the identification of explicit nonreferential constructions in English appear to perform better than than rule-based ones (Boyd et al., 2005). 708 LINGUISTIC INFORMATION PHONETIC SYNTACTIC VERBAL SEMANTIC DISCOURSE REALIZATION CATEGORY DIATHESIS INTERPR. Annotation Annotation Elliptic Ell. noun Nominal Active Active Referential Categories Tags noun phrase subject participant subject phrase head Explicit Explicit subject – – + + + + subject Reflex passive – – + + – + subject Passive subject – – + – – + Zero Omitted subject + – + + + + subject Omitted subject – </context>
</contexts>
<marker>Rello, Illisei, 2009</marker>
<rawString>L. Rello and I. Illisei. 2009a. A comparative study of Spanish zero pronoun distribution. In Proceedings of the International Symposium on Data and Sense Mining, Machine Translation and Controlled Languages, and their application to emergencies and safety critical domains (ISMTCL-09), pages 209–214. Presses Universitaires de Franche-Comt´e, Besanc¸on.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Rello</author>
<author>I Illisei</author>
</authors>
<title>A rule-based approach to the identification of Spanish zero pronouns.</title>
<date>2009</date>
<booktitle>In Student Research Workshop. International Conference on Recent Advances in Natural Language Processing (RANLP-09),</booktitle>
<pages>209--214</pages>
<contexts>
<context position="3971" citStr="Rello and Illisei, 2009" startWordPosition="605" endWordPosition="608">e 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 706–715, Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics genre impact and the error analysis are all detailed in Section 6. Finally, in Section 7, conclusions are drawn and plans for future work are discussed. This work is an extension of the first author master’s thesis (Rello, 2010) and a preliminary version of the algorithm was presented in Rello et al. (2010). 2 Classes of Spanish Subjects Literature related to ellipsis in NLP (Ferr´andez and Peral, 2000; Rello and Illisei, 2009a; Mitkov, 2010) and linguistic theory (Bosque, 1989; Brucart, 1999; Real Academia Espa˜nola, 2009) has served as a basis for establishing the classes of this work. Explicit subjects are phonetically realized and their syntactic position can be pre-verbal or postverbal. In the case of post-verbal subjects (a), the syntactic position is restricted by some conditions (Real Academia Espa˜nola, 2009). (a) Carecer´an de validez las disposiciones que contradigan otra de rango superior.1 The dispositions which contradict higher range ones will not be valid. Zero subjects (b) appear as the result of a</context>
<context position="6890" citStr="Rello and Illisei, 2009" startWordPosition="1068" endWordPosition="1071">h English and French texts use an explicit word, with some grammatical information (a third person pronoun), which is non-referential (Mitkov, 2010). By contrast, in Spanish, nonreferential expressions are not realized by expletive or pleonastic pronouns but rather by a certain kind of ellipsis. For this reason, it is easy to mistake them for zero pronouns, which are, in fact, referential. Previous work on detecting Spanish subject ellipsis focused on distinguishing verbs with explicit subjects and verbs with zero subjects (zero pronouns), using rule-based methods (Ferr´andez and Peral, 2000; Rello and Illisei, 2009b). The Ferr´andez and Peral algorithm (2000) outperforms the (Rello and Illisei, 2009b) approach with 57% accuracy in identifying zero subjects. In (Ferr´andez and Peral, 2000), the implementation of a zero subject identification and resolution module forms part of an anaphora resolution system. ML based studies on the identification of explicit non-referential constructions in English present accuracies of 71% (Evans, 2001), 87.5% (Bergsma et al., 2008) and 88% (Boyd et al., 2005), while 97.5% is achieved for French (Danlos, 2005). However, in these languages, nonreferential constructions ar</context>
<context position="8480" citStr="Rello and Illisei, 2009" startWordPosition="1309" endWordPosition="1312">inally written in peninsular Spanish. The corpus is named after its annotated content “Explicit Subjects, Zero Subjects and Impersonal Constructions” (ESZIC es Corpus). To the best of our knowledge, the existing corpora annotated with elliptical subjects belong to other genres. The Blue Book (handbook) and Lexesp (journalistic texts) used in (Ferr´andez and Peral, 2000) contain zero subjects but not impersonal constructions. On the other hand, the Spanish AnCora corpus based on journalistic texts includes zero pronouns and impersonal constructions (Recasens and Marti, 2010) while the Zcorpus (Rello and Illisei, 2009b) comprises legal, instructional and encyclopedic texts but has no annotated impersonal constructions. The ESZIC corpus contains a total of 6,827 verbs including 1,793 zero subjects. Except for AnCora-ES, with 10,791 elliptic pronouns, our corpus is larger than the ones used in previous approaches: about 1,830 verbs including zero and explicit subjects in (Ferr´andez and Peral, 2000) (the exact number is not mentioned in the paper) and 1,202 zero subjects in (Rello and Illisei, 2009b). The corpus was parsed by Connexor’s Machinese Syntax (Connexor Oy, 2006), which returns lexical and morpholo</context>
<context position="11688" citStr="Rello and Illisei, 2009" startWordPosition="1819" endWordPosition="1822">ss’ Kappa Legal Health All Two Annotators 0.934 0.870 0.902 Three Annotators 0.925 0.857 0.891 Table 3: Inter-annotator Agreement. In Table 3 we present the Fleiss kappa interannotator agreement for two and three annotators. These results suggest that the annotation is reliable since it is common practice among researchers in computational linguistics to consider 0.8 as a minimum value of acceptance (Artstein and Poesio, 2008). 5 Machine Learning Approach We opted for an ML approach given that our previous rule-based methodology improved only 0.02 over the 0.55 F-measure of a simple baseline (Rello and Illisei, 2009b). Besides, ML based methods for the identification of explicit nonreferential constructions in English appear to perform better than than rule-based ones (Boyd et al., 2005). 708 LINGUISTIC INFORMATION PHONETIC SYNTACTIC VERBAL SEMANTIC DISCOURSE REALIZATION CATEGORY DIATHESIS INTERPR. Annotation Annotation Elliptic Ell. noun Nominal Active Active Referential Categories Tags noun phrase subject participant subject phrase head Explicit Explicit subject – – + + + + subject Reflex passive – – + + – + subject Passive subject – – + – – + Zero Omitted subject + – + + + + subject Omitted subject – </context>
</contexts>
<marker>Rello, Illisei, 2009</marker>
<rawString>L. Rello and I. Illisei. 2009b. A rule-based approach to the identification of Spanish zero pronouns. In Student Research Workshop. International Conference on Recent Advances in Natural Language Processing (RANLP-09), pages 209–214.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Rello</author>
<author>P Su´arez</author>
<author>R Mitkov</author>
</authors>
<title>A machine learning method for identifying non-referential impersonal sentences and zero pronouns in Spanish.</title>
<date>2010</date>
<booktitle>Procesamiento del Lenguaje Natural,</booktitle>
<pages>45--281</pages>
<marker>Rello, Su´arez, Mitkov, 2010</marker>
<rawString>L. Rello, P. Su´arez, and R. Mitkov. 2010. A machine learning method for identifying non-referential impersonal sentences and zero pronouns in Spanish. Procesamiento del Lenguaje Natural, 45:281–287.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Rello</author>
<author>G Ferraro</author>
<author>A Burga</author>
</authors>
<title>Error analysis for the improvement of subject ellipsis detection.</title>
<date>2011</date>
<booktitle>Procesamiento de Lenguaje Natural,</booktitle>
<pages>47--223</pages>
<contexts>
<context position="29441" citStr="Rello et al., 2011" startWordPosition="4746" endWordPosition="4749">es are combined as training data, only instances from the health genre show a significant increased accuracy (93.7%). These results reveal that the health texts are the most heterogeneous ones. In fact, we also found subsets of the legal documents where our method achieves an accuracy of 94.6%, implying more homogeneous texts. 6.4 Error Analysis Since the features of the system are linguistically motivated, we performed a linguistic analysis of the erroneously classified instances to find out which patterns are more difficult to classify and which type of information would improve the method (Rello et al., 2011). We extract the erroneously classified instances of our training data and classify the errors. According to the distribution of the errors per class (Table 8) we take into account the following four classes of errors for the analysis: (a) impersonal constructions classified as zero subjects, (b) impersonal constructions classified as explicit subjects, (c) zero subjects classified as explicit subjects, and (d) explicit subjects classified as zero subjects. The diagonal numbers are the true predicted cases. The classification of impersonal constructions is less balanced than the ones for expli</context>
</contexts>
<marker>Rello, Ferraro, Burga, 2011</marker>
<rawString>L. Rello, G. Ferraro, and A. Burga. 2011. Error analysis for the improvement of subject ellipsis detection. Procesamiento de Lenguaje Natural, 47:223–230.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Rello</author>
</authors>
<title>Elliphant: A machine learning method for identifying subject ellipsis and impersonal constructions in Spanish. Master’s thesis,</title>
<date>2010</date>
<institution>Erasmus Mundus, University of Wolverhampton &amp; Universitat Aut`onoma de Barcelona.</institution>
<contexts>
<context position="3769" citStr="Rello, 2010" startWordPosition="573" endWordPosition="574">ibes the creation and the annotation of the corpus and in Section 5 the machine learning (ML) method is presented. The analysis of the features, the learning curves, the 706 Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 706–715, Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics genre impact and the error analysis are all detailed in Section 6. Finally, in Section 7, conclusions are drawn and plans for future work are discussed. This work is an extension of the first author master’s thesis (Rello, 2010) and a preliminary version of the algorithm was presented in Rello et al. (2010). 2 Classes of Spanish Subjects Literature related to ellipsis in NLP (Ferr´andez and Peral, 2000; Rello and Illisei, 2009a; Mitkov, 2010) and linguistic theory (Bosque, 1989; Brucart, 1999; Real Academia Espa˜nola, 2009) has served as a basis for establishing the classes of this work. Explicit subjects are phonetically realized and their syntactic position can be pre-verbal or postverbal. In the case of post-verbal subjects (a), the syntactic position is restricted by some conditions (Real Academia Espa˜nola, 2009</context>
</contexts>
<marker>Rello, 2010</marker>
<rawString>L. Rello. 2010. Elliphant: A machine learning method for identifying subject ellipsis and impersonal constructions in Spanish. Master’s thesis, Erasmus Mundus, University of Wolverhampton &amp; Universitat Aut`onoma de Barcelona.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Tapanainen</author>
<author>T J¨arvinen</author>
</authors>
<title>A non-projective dependency parser.</title>
<date>1997</date>
<booktitle>In Proceedings of the 5th Conference on Applied Natural Language Processing (ANLP-97),</booktitle>
<pages>64--71</pages>
<marker>Tapanainen, J¨arvinen, 1997</marker>
<rawString>P. Tapanainen and T. J¨arvinen. 1997. A non-projective dependency parser. In Proceedings of the 5th Conference on Applied Natural Language Processing (ANLP-97), pages 64–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I H Witten</author>
<author>E Frank</author>
</authors>
<title>Data mining: practical machine learning tools and techniques.</title>
<date>2005</date>
<volume>2</volume>
<pages>edition.</pages>
<publisher>Morgan Kaufmann,</publisher>
<location>London,</location>
<contexts>
<context position="17469" citStr="Witten and Frank, 2005" startWordPosition="2808" endWordPosition="2811">sitos. (It) is accepted for the students who fulfill the requirements. 12-3 POSpTe, POSpos: the part of the speech (POS) of eight tokens, that is, the 4-grams preceding and the 4-grams following the instance. 14 VERBtype: the verb is classified as copulative, pronominal, transitive, or with an impersonal use.4 Verbs belonging to more than one class are also accommodated with different feature values for each of the possible combinations of verb type. 5.2 Evaluation To determine the most accurate algorithm for our classification task, two comparisons of learning algorithms implemented in WEKA (Witten and Frank, 2005) were carried out. Firstly, the classification was performed using 20% of the training instances. Secondly, the seven highest performing classifiers were compared using 100% of the 4We used four lists provided by Molino de Ideas s.a. containing 11,060 different verb lemmas belonging to the Royal Spanish Academy Dictionary (Real Academia Espa˜nola, 2001). 710 Class P R F Acc. Explicit subj. 90.1% 92.3% 91.2% 87.3% Zero subj. 77.2% 74.0% 75.5% 87.4% Impersonals 85.6% 63.1% 72.7% 98.8% Table 5: K* performance (87.6% accuracy for ten-fold cross validation). training data and ten-fold cross-validat</context>
</contexts>
<marker>Witten, Frank, 2005</marker>
<rawString>I. H. Witten and E. Frank. 2005. Data mining: practical machine learning tools and techniques. Morgan Kaufmann, London, 2 edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Zhao</author>
<author>H T Ng</author>
</authors>
<title>Identification and resolution of Chinese zero pronouns: a machine learning approach.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CNLL-07),</booktitle>
<pages>541--550</pages>
<contexts>
<context position="12905" citStr="Zhao and Ng, 2007" startWordPosition="2043" endWordPosition="2046"> + + + + + head Non-nominal – – – + + + subject Reflex passive + – + + – + omitted subject Reflex pass. omit- – + + + – + ted subject head Reflex pass. non- – – – + – + nominal subject Passive omitted + – + – – + subject Pass. non-nominal – – – – – + subject Impersonal Reflex imp. clause – – n/a – n/a – construction (with se) Imp. construction – – n/a + n/a – (without se) Table 1: ESZIC Corpus Annotation Tags. 5.1 Features We built the training data from the annotated corpus and defined fourteen features. The linguistically motivated features are inspired by previous ML approaches in Chinese (Zhao and Ng, 2007) and English (Evans, 2001). The values for the features (see Table 4) were derived from information provided both by Connexor’s Machinese Syntax parser and a set of lists. We can describe each of the features as broadly belonging to one of ten classes, as follows: 1 PARSER: the presence or absence of a subject in the clause, as identified by the parser. We are not aware of a formal evaluation of Connexor’s accuracy. It presents an accuracy of 74.9% evaluated against our corpus and we used it as a simple baseline. 2 CLAUSE: the clause types considered are: main clauses, relative clauses startin</context>
</contexts>
<marker>Zhao, Ng, 2007</marker>
<rawString>S. Zhao and H.T. Ng. 2007. Identification and resolution of Chinese zero pronouns: a machine learning approach. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CNLL-07), pages 541–550.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>