<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<sectionHeader confidence="0.7825145" genericHeader="method">
AN ISLAND PARSING INTERPRETER FOR THE FULL AUGMENTED
TRANSITION NETWORK FORMALISM
</sectionHeader>
<affiliation confidence="0.8118135">
John A. Carroll
University of Cambridge Computer Laboratory
</affiliation>
<address confidence="0.673077333333333">
Corn Exchange Street
Cambridge CB2 3QG
England
</address>
<email confidence="0.391215">
ABSTRACT
</email>
<bodyText confidence="0.999926333333333">
Island parsing is a powerful technique for
parsing with Augmented Transition Networks (ATNs)
which was developed and successfully applied in the
HWIM speech understanding project. The HWIM
application grammar did not, however, exploit Woods&apos;
original full ATN specification. This paper
describes an island parsing interpreter based on
HWIM, but containing substantial and important
extensions to enable it to interpret any grammar
which conforms to that full specification of 1970.
The most important contributions have been to
eliminate the need for prior specification of scope
clauses, to provide more power by implementing LIFTR
and SENDR actions within the island parsing
framework, and to improve the efficiency of the
techniques used to merge together partially—built
islands within the utterance.
This paper also presents some observations about
island parsing, based on the use of the parser
described, and some suggestions for future
directions for island parsing research.
</bodyText>
<sectionHeader confidence="0.92638" genericHeader="method">
I INTRODUCTION
</sectionHeader>
<bodyText confidence="0.977241291666667">
A. Island Parsing
In an ordinary ATN parser, the parsing of a
sentence is performed unidirectionally (normally
left—to—right); the parser traverses each arc in the
directed graph of the grammar in the same direction,
starting from the initial state.
An island ATN parser, on the other hand, can start
at any point in the transition network with a word
match from anywhere in the input string, not just at
the left end, and parse the rest of the string
working outwards to the left and right, adding words
to each end of the &apos;island&apos; formed. Indeed, any number
of islands can be built, the parser merging the
islands together as their boundaries meet. Clearly,
in speech processing, island parsing is well suited
to gearing sentence processing to the most solid
inputs from the acoustic analyser.
The main problems with previous implementations
of island parsing for ATNs have been with scope
clauses and LIFTR and SENDR actions; essentially,
these problems arise because in island parsing
structure determination has to work from right—to-
left as well as in the more usual left—to—right
direction, i.e. against the normal parsing flow.
</bodyText>
<subsectionHeader confidence="0.552518">
B. Scope Clauses
</subsectionHeader>
<bodyText confidence="0.999876">
The ATN formalism provides for actions on the
arcs of the network which can set and modify the
contents of &apos;registers&apos;, and arbitrary tests on an
arc to determine whether that arc is to be followed.
In an island parser, an action or test is referred to
as being context—sensitive when it either requires
the value of a register that is set somewhere to the
left, or changes the value of a register that is used
somewhere also to the left. For each context
sensitive action or test, there exists a set of
states to its left such that the action can safely be
performed if its execution is delayed until the
parse has passed through one of these states. This
list of states must be expressed, and in the HWIM
system (Woods, 1976), this is done when writing the
grammar by using a scope clause. The form of a scope
clause is
</bodyText>
<sectionHeader confidence="0.454813" genericHeader="method">
(SCOPE &lt;scope specification&gt;
</sectionHeader>
<bodyText confidence="0.975794222222222">
&lt;list of context—sensitive actions&gt;)
where the scope specification is the list of
precursor states. This requirement for prior
specification of scope clauses clearly adds to the
burden of the grammar writer.
I have implemented a more satisfactory treatment
of scope clauses. This is described below, following
the discussion of LIFTR and SENDR actions, which
require special handling in scoping.
</bodyText>
<sectionHeader confidence="0.70764" genericHeader="method">
II LIFTR AND SENDR ACTIONS
</sectionHeader>
<bodyText confidence="0.99991075">
Two important actions (indeed it is difficult to
write a grammar of any substantial subset of English
without them) defined by Woods (1970), namely LIFTR
and SENDR, present implementation difficulties in an
island parsing interpreter. These actions were
evidently excluded from the HWIM parser since there
is no mention of them by Woods (1976).
The action LIFTR can occur on any arc in the
network, to transmit the value of a register up to
the next higher level in the network, whereas SENDR
can only occur on a PUSH arc, to transmit the value
of a register down to a lower level.
</bodyText>
<page confidence="0.998053">
101
</page>
<bodyText confidence="0.923129375">
A. LIFTR
The same mechanism can be used to implement LIFTR
actions as is used to transmit the result of each
lower level computation up to the next higher level
as the value of the special register &apos;11&apos;.
However, LIFTR presents problems with scope
clauses in an island parsing ATN interpreter: if an
ac tion
</bodyText>
<figure confidence="0.399753">
(LIFTR &lt;register&gt; ...)
</figure>
<figureCaption confidence="0.8150905">
occurs in a sub-network, any action using that
register in any higher sub-network that PUSHes for
the one containing the LIFTR must be scoped so that
the action is not performed in a right-to-left parse
at least until after the PUSH has been executed. See
figure 1.
</figureCaption>
<bodyText confidence="0.7417885">
action using &lt;register&gt; here must
be scoped to before the PUSH arc
</bodyText>
<equation confidence="0.453476333333333">
k
PUSH \ FOP
(LIFTR &lt;reg ister&gt; )
</equation>
<figureCaption confidence="0.999091">
Figure 1. Scoping LIFTR actions.
</figureCaption>
<bodyText confidence="0.999859142857143">
So, for example, when parsing English from right
to left, tests that the verb and subject agree in
person and number (if this information is carried in
registers) must be postponed until the PUSH for the
beginning of the subject noun phrase. Section III
describes how my interpreter takes care of this
scoping problem.
</bodyText>
<listItem confidence="0.926357">
B. SENDR
1. Treatment of actions using SENDRed registers
</listItem>
<bodyText confidence="0.999722466666667">
Since in a right-to-left parse, lower level sub-
networks are traversed before the PUSH to them is
performed, there is no way of knowing the value of a
register that is being SENDRed at least until after
the PUSH. Thus all actions involving registers whose
values depend on the value of that register must be
saved to be executed at the higher level.
I have dealt with this by putting such actions
into SCOPE clauses containing a special new scope
specification, which I call scope SENDR. Actions with
scope SENDR are never executed at the current level
in the network, but are saved and incorporated into
the next higher level subnetwork (possibly with a
changed scope specification) during processing of
the PUSH at that higher level, as follows:-
</bodyText>
<listItem confidence="0.774757142857143">
(1) The form on the FOP arc to be returned as the
value of the special register &apos;it&apos; on return to
the next higher level is put into an explicit
LIFTR action.
(2) The scopes of all the saved actions are
changed to the same as those of the SENDR
actions on the PUSH arc.
(3) All LIFTR actions are changed to highlvl-setr
actions (see below).
(4) Scoped calls to lowlvl-start and lowlvl-
finish ( see below) are put respectively
before and after the saved actions.
(5) All the SENDR actions on the PUSH arc are put
in front of the lower level saved actions.
</listItem>
<bodyText confidence="0.999954">
The rest of the actions on the PUSH arc are then
processed as normal. The purposes of the actions
lowlvl-start and lowlvl-finish are to respectively
set up and restore a stack of register contexts
(hold-regs), each level in the stack holding the
register contents of one level in the network, with
the base of the stack representing the highest level
of saved actions. The action highlvl-setr performs a
SETR at the next higher level of register contexts
on the stack.
</bodyText>
<sectionHeader confidence="0.815419" genericHeader="method">
2. An Example
</sectionHeader>
<bodyText confidence="0.9624795">
A typical sequence of actions in a fragment of an
ATN network might be as in figure 2.
</bodyText>
<figure confidence="0.8714404">
\4---(SENDR regi ,nphrase)
PUSH POP with form
(BUILDQ/ (NP +) reg2)
4
(SETA reg2 (GETR regi))
</figure>
<figureCaption confidence="0.984182">
Figure 2. A typical fragment of a network.
</figureCaption>
<figure confidence="0.9916628">
(SENDR reg1 ,nphrase)
(lowlvl-start)
(SETR reg2 (GETR reg1))
(highlvl -setr * (BUILDQ (NP +) reg2))
(lowlvl-finish)
</figure>
<figureCaption confidence="0.997932">
Figure 3.
</figureCaption>
<construct confidence="0.94733675">
fregs: ((reg0 pphrase))
lowlvl-regs: NIL
hold-regs: NIL
lowlvl-regs &lt;- ((regi nphrase))
fhold-regs &lt;- (((reg0 pphrase)))
regs &lt;- ((regi nphrase))
lowlvl-regs &lt;- NIL
regs &lt;- ((reg2 nphrase) (regi nphrase))
hold-regs &lt;- (((* (NP nphrase)) (reg0 pphrase)))
fregs &lt;- ((* (NP nphrase)) (reg0 pphrase))
hold-regs &lt;- NIL
Treatment of SENDR actions.
</construct>
<page confidence="0.997927">
102
</page>
<bodyText confidence="0.999919666666667">
This would be translated into the list of saved
actions on the left of figure 3, and when control had
passed through a set of states such that the actions&apos;
scope specifications were satisfied, execution would
produce the sequence of operations shown on the
right of the figure.
</bodyText>
<sectionHeader confidence="0.832087" genericHeader="method">
3. Scope Problems
</sectionHeader>
<bodyText confidence="0.9999328">
As with LIFTR, SENDR actions need special scoping
treatment: since there can be any type of interaction
on a lower level between registers SENDRed and
registers to be LIFTRed, the only safe execution time
for actions using these registers and for actions
referencing registers whose values depend on them
(without engaging in full symbolic execution) is
when the higher level sub-network has been fully
traversed. There is a special scope specification
for this - scope T.
</bodyText>
<sectionHeader confidence="0.988301" genericHeader="method">
III AUTOMATIC SCOPE COMPUTATION
</sectionHeader>
<bodyText confidence="0.982749315789474">
The process of writing scope clauses into the
grammar for an island parser is laborious, and
therefore prone to error. The implementation
described here can automatically detect all context-
sensitive actions and tests and put them into scope
clauses containing suitable (and usually optimal)
scope specifications. Thus the parser can interpret
straight off an ATN grammar that has been written
for an ordinary left-to-right parser.
The scoping algorithm consists of five passes
over the grammar, the first four dealing with the
exceptional scoping required by LIFTR and SENDR
actions, and the fifth with the rest of the actions
and tests in the network. Comments on the algorithm
follow the necessarily technical account of it.
A. The Scoping Algorithm
The five passes of the scoping algorithm will now
be described, actions and tests in the network being
treated identically.
</bodyText>
<listItem confidence="0.720257">
1. Pass 1
</listItem>
<bodyText confidence="0.9990907">
Pass one takes care of the scoping problem with
LIFTR actions mentioned in the previous section -
that a register being LIFTRed must be scoped back at
the higher level to at least before the PUSH arc.
But if the register is used on the PUSH arc
itself, the scoping algorithm should produce correct
scope specifications without needing to treat this
as a special case. Thus the solution I have adopted
is for the algorithm to check whether the register .
appears on the PUSH arc, and if not, the dtxnmy action
</bodyText>
<listItem confidence="0.847836333333333">
(SETR &lt;register&gt; (GETR Cregister&gt;))
is added to the actions on the PUSH arc.
2. Pass 2
</listItem>
<bodyText confidence="0.999847428571429">
The second pass finds, for each sub-network, the
names of all the registers whose values depend on
other registers (for use in the subsequent scoping
passes). It does this by finding the registers used
in each register-setting action (SETR, LIFTR, or
SENDR), using knowledge of the register usage of each
function used, and for each register which is not
being assigned to, it appends onto the property-list
of the register the name of the register being set in
the current action, and a pointer to that register&apos;s
property-list.
Thus in the end, each register is associated with
a list of all the registers in the sub-network which
depend on the value of that register.
</bodyText>
<listItem confidence="0.738258">
3. Pass 3
</listItem>
<bodyText confidence="0.948257428571429">
Pass three deals with scoping SENDR actions,
giving them the treatment described at the end of
the last section - it assigns the scope
specification T to all actions which reference
registers whose values depend on any of the
registers used in actions on the same PUSH arc as a
SENDR action.
</bodyText>
<listItem confidence="0.723252">
4. Pass 4
</listItem>
<bodyText confidence="0.9527358">
Pass four finds all actions that use registers
that have been passed down from a higher level by a
SENDR, and also actions which use registers
dependent on those SENDRed registers, giving the
actions scope SENDR.
</bodyText>
<listItem confidence="0.611606">
5. Pass 5
</listItem>
<bodyText confidence="0.999909153846154">
The rest of the scoping is performed in pass five.
Each action is considered in turn, collecting the
names of all registers it uses, and the names of
those whose values depend on them. The scope
specification is then computed depending on the
common part of all possible paths from the start of
the current sub-network to any action which is
dependent on the action under consideration. This
list of states (&apos;left-states&apos;) is the intersection of
the states to the left of each action which uses any
of the collected registers.
The algorithm distinguishes the following four
cases for the contents of &apos;left-states&apos;:-
</bodyText>
<listItem confidence="0.951000384615385">
(1) If NIL - there are at least two non-
intersecting paths from the left to the arc
containing the action which reference
registers dependent on those in the action,
so return scope specification T.
(2) All states in &apos;left-states&apos; are in loops in
the network - it is very difficult to compute
the optimal scope specification, so return T
(which will always be correct though perhaps
not optimal). The problem with loops is that
no register should be changed or referenced
in a right-to-left parse until control has
finally passed out of the loop.
</listItem>
<page confidence="0.978809">
103
</page>
<listItem confidence="0.998483625">
(3) The left state of. the arc containing the
action being scoped is in &apos;left-states&apos;, and
the state is not in a loop - all dependent
actions are to the right of the arc, so return
NIL.
(4) Otherwise - return as scope specification a
list of all states in &apos;left-states, that are
not in loops.
</listItem>
<bodyText confidence="0.95526175">
If an action does not use any registers, it
obviously does not need scoping, and the algorithm
bypasses it. If a scope specification is returned for
an action that is already scoped, whether the new
scope &apos;overwrites, the old one depends on what is
already there:-
scope SENDR overwrites scope T
scope T overwrites scope &lt;list of states&gt;
scope &lt;list of states&gt; is appended to an
existing scope &lt;list of states&gt;
B. Discussion of the Scoping Algorithm
The algorithm does not produce totally optimal
scope specifications in all circumstances: that is,
actions may sometimes be scoped so they are saved
for longer in the parse before they are executed
than may strictly be necessary. The main shortcoming
is in dealing with networks where there are two or
more alternative separate paths containing actions
using registers computed to be interdependent; for
example in scoping the network fragment in figure 4,
</bodyText>
<figure confidence="0.726946583333333">
(NP/
(JUMP NP/DET T)
(CAT NPR T
(SETR noun (BUILDQ (npr *)))
(TO NP/POP)))
(NP/DET
(CAT ADJ T (TO NP/DET))
(CAT NOUN T
(SETR noun *)
(TO NP/POP)))
(NP/POP
(POP ... ))
</figure>
<figureCaption confidence="0.995035">
Figure 14. Scoping with alternative paths.
</figureCaption>
<bodyText confidence="0.999940444444445">
the two actions using register &apos;noun&apos; are scoped
(NP/) but the paths through them are independent and
the register is not used elsewhere, so the actions do
not need to be scoped at all. There does not seem to
be any way around this problem by modifying the
algorithm, but fortunately scope specifications that
are not entirely optimal (as in this case) should
only minimally affect the performance of the
interpreter when parsing a sentence.
configurations &apos;Sconfigs&apos;l at the boundaries of each
island that are compatible, and then splice those
that completely cover a sub-network into as many
successively higher levels as possible (by calling
Woods&apos; &apos;Complete-right, function as many times as
possible). In a real-time speech understanding
system (depending on the strategy it employed), the
time saved by this method could be critical to the
success of the system.
</bodyText>
<sectionHeader confidence="0.462898" genericHeader="method">
V OBSERVATIONS ON THE INTERPRETER IN USE
</sectionHeader>
<bodyText confidence="0.999903166666667">
The parser has been tested (Carroll, 1982) with
various sized (purely syntactic) grammars,
simulating speech processing by the arbitrary
selection of one or more words in a typed string as
parsing starting points, and the arbitrary addition
of words to the left and right of these.
It has been observed that the more complex the
structure of the sentence being parsed, the more
Sconfigs get generated, and consequently the longer
the parse takes. There are, however, other less
obvious factors influencing the number of Sconfigs
generated.
</bodyText>
<sectionHeader confidence="0.470941" genericHeader="method">
A. Saved Tests
</sectionHeader>
<bodyText confidence="0.99996280952381">
Sconfigs tend to proliferate embarrassingly when
there are many possible paths of JUMP arcs between
states on the same level of the grammar due to scoped
tests having to be saved and not being immediately
executable.
If there are no SENDR actions down to the sub-
network containing the JUMPs, then none of the saved
tests will have to be carried up to a higher level,
and so many of the Sconfigs will be filtered out when
the FOP arc at that level is processed. But if there
are SENDR actions, the Sconfigs will not be filtered
so effectively, will be carried up to higher levels,
and at each higher level the number of Sconfigs will
multiply.
This Sconfig proliferation and resulting
combinatorial explosion will always be associated
with island parsing using large complex grammars
that are purely syntactic ; unfortunately LIFTR and
SENDR actions aggravate the problem. However, the
utility of these actions more than outweighs the
consequent decrease in parse-time efficiency.
</bodyText>
<sectionHeader confidence="0.97573" genericHeader="method">
IV MERGING PARTIALLY BUILT ISLANDS
</sectionHeader>
<bodyText confidence="0.9995255">
In the HWIM system, to join together two adjacent
islands to make one island covering them both, the
smaller island was broken up and the words from it
added onto the end of the larger. This obviously
wastes all the effort expended in building the
smaller island.
A more efficient method of joining two islands
which I have implemented, is to merge all the segment
1 The state of the parse in an island parser is held
as a list of segment configurations, each of which
represents a partial parse covering one or more
words in the utterance.
2 It seems that the HWIM parser also encountered
these problems; their solution was to employ
semantic grammars, with a large number of WRD arcs,
to use both syntactic and semantic categories on
CAT arcs, and to expend the set of constituents
pushed for to include &amp;quot;semantic constituents&amp;quot;.
</bodyText>
<page confidence="0.996059">
104
</page>
<subsectionHeader confidence="0.649086">
B. Differing Word—Orders
</subsectionHeader>
<bodyText confidence="0.999135">
Parsing the same sentence with differing orders
of adding the words in it to islands usually results
in differing numbers of Sconfigs being created. For
example, two parses of the sentence
JOHN IS EAGER TO PLEASE.
gave the results:—
run 1 run 2
Sconfigs generated 388
parse time (secs.) 1.77
The difference was caused by the fact that in the
first run, &apos;IS&apos; was used as an initial island, setting
up expectations for more possible distinct final
sentence structures than in the second run, which
started with the word &apos;PLEASE&apos;. This difference in
expectation status reflects the different
structuring potential of the two words.
</bodyText>
<sectionHeader confidence="0.932704" genericHeader="method">
VI SOME FUTURE DIRECTIONS FOR RESEARCH
</sectionHeader>
<subsectionHeader confidence="0.676092">
A. Parsing Conjunctions
</subsectionHeader>
<bodyText confidence="0.99971425">
Island parsing appears to offer a promising
solution to the problem of parsing written as well
as spoken sentences containing conjunctions;
although the ATN formalism is quite powerful in
expressing natural language grammars, it faces
problems dealing with sentences containing
conjunctions: (WRD AND ...) arcs need to be inserted
almost everywhere since AND can conjoin any two
constituents of the same type. Eoguraev (1982) has
suggested that this problem might be overcome by
building islands at each conjunction and parsing
outwards from them.
</bodyText>
<subsectionHeader confidence="0.320602">
B. Cascaded Island Parsers
</subsectionHeader>
<bodyText confidence="0.998304846153846">
The nuisance of the combinatorial explosion of
Sconfig numbers when using large complex grammars
might be amenable to solution with cascaded island
ATN interpreters3 ; several island parsers could be
put on top of each other, each having a separate
domain of responsibility and each passing up
completed constituents to the next higher ATN. In his
1980 paper, Woods explains how cascading gains the
&amp;quot;factoring&amp;quot; advantage of allowing alternative
configurations in the later stages of the cascade to
share common processing in the earlier stages. This
processing would otherwise have to be done
independently — in the case of an island parser,
producing duplicate Sconfigs which would contribute
to a possible combinatorial explosion.
SENDR actions might cause problems, however, if
scoping due to them caused the actions intended to
form complete constituents to be saved so that the
actions would not be completely performed before the
time came to pass the constituents up to the next
3 The idea of cascading was first put forward by
Woods (1980), but only in terms of ordinary left—
to—right ATN parsers.
ATN. For this reason, restrictions might have to be
placed on the ATN grammars used, but this requires
further investigation.
</bodyText>
<sectionHeader confidence="0.92105" genericHeader="method">
VII ACKNOWLEDGEMENTS
</sectionHeader>
<bodyText confidence="0.9998506">
I would like to thank Bran Eoguraev for his
guidance during the writing of the interpreter, and
for supplying the ATN grammars I have used. Thanks
also to Karen Sparck Jones and John Tait for their
comments on earlier drafts of this paper.
</bodyText>
<sectionHeader confidence="0.656208" genericHeader="method">
VIII REFERENCES.
</sectionHeader>
<reference confidence="0.990709076923077">
Boguraev, B. (1982) personal communication.
Carroll, J. (1982) &amp;quot;An Island Parsing Interpreter for
Augmented Transition Networks&amp;quot;. University of
Cambridge Computer Laboratory Technical Report
No.33.
Woods, W. (1970) &amp;quot;Transition Network Grammars for
Natural Language Analysis&amp;quot;. Communications of the
ACM, 13, 10, 591-606.
Woods, W. et al. (1976) &amp;quot;Parsers&amp;quot; in &amp;quot;Speech
Understanding Systems&amp;quot;. Bolt, Beranek and Newman Inc.
Report No.3438, Vol.4, 1-21.
Woods, W. (1980) &amp;quot;Cascaded ATN Grammars&amp;quot;. American
Journal of Computational Linguistics, 6, 1, 1-12.
</reference>
<figure confidence="0.5412265">
182
1.08
</figure>
<page confidence="0.986579">
105
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.533650">
<title confidence="0.950672">AN ISLAND PARSING INTERPRETER FOR THE FULL AUGMENTED TRANSITION NETWORK FORMALISM</title>
<author confidence="0.999422">John A Carroll</author>
<affiliation confidence="0.858364">University of Cambridge Computer Laboratory Corn Exchange Street</affiliation>
<address confidence="0.920311">Cambridge CB2 3QG England</address>
<abstract confidence="0.998988045454546">Island parsing is a powerful technique for parsing with Augmented Transition Networks (ATNs) which was developed and successfully applied in the HWIM speech understanding project. The HWIM application grammar did not, however, exploit Woods&apos; original full ATN specification. This paper describes an island parsing interpreter based on HWIM, but containing substantial and important extensions to enable it to interpret any grammar which conforms to that full specification of 1970. The most important contributions have been to eliminate the need for prior specification of scope clauses, to provide more power by implementing LIFTR and SENDR actions within the island parsing framework, and to improve the efficiency of the techniques used to merge together partially—built islands within the utterance. This paper also presents some observations about island parsing, based on the use of the parser described, and some suggestions for future directions for island parsing research.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B Boguraev</author>
</authors>
<date>1982</date>
<note>personal communication.</note>
<marker>Boguraev, 1982</marker>
<rawString>Boguraev, B. (1982) personal communication.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carroll</author>
</authors>
<title>An Island Parsing Interpreter for Augmented Transition Networks&amp;quot;.</title>
<date>1982</date>
<tech>Technical Report No.33.</tech>
<institution>University of Cambridge Computer Laboratory</institution>
<contexts>
<context position="14812" citStr="Carroll, 1982" startWordPosition="2490" endWordPosition="2491">s in this case) should only minimally affect the performance of the interpreter when parsing a sentence. configurations &apos;Sconfigs&apos;l at the boundaries of each island that are compatible, and then splice those that completely cover a sub-network into as many successively higher levels as possible (by calling Woods&apos; &apos;Complete-right, function as many times as possible). In a real-time speech understanding system (depending on the strategy it employed), the time saved by this method could be critical to the success of the system. V OBSERVATIONS ON THE INTERPRETER IN USE The parser has been tested (Carroll, 1982) with various sized (purely syntactic) grammars, simulating speech processing by the arbitrary selection of one or more words in a typed string as parsing starting points, and the arbitrary addition of words to the left and right of these. It has been observed that the more complex the structure of the sentence being parsed, the more Sconfigs get generated, and consequently the longer the parse takes. There are, however, other less obvious factors influencing the number of Sconfigs generated. A. Saved Tests Sconfigs tend to proliferate embarrassingly when there are many possible paths of JUMP </context>
</contexts>
<marker>Carroll, 1982</marker>
<rawString>Carroll, J. (1982) &amp;quot;An Island Parsing Interpreter for Augmented Transition Networks&amp;quot;. University of Cambridge Computer Laboratory Technical Report No.33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Woods</author>
</authors>
<title>Transition Network Grammars for Natural Language Analysis&amp;quot;.</title>
<date>1970</date>
<journal>Communications of the ACM,</journal>
<volume>13</volume>
<pages>591--606</pages>
<contexts>
<context position="3762" citStr="Woods (1970)" startWordPosition="604" endWordPosition="605">of a scope clause is (SCOPE &lt;scope specification&gt; &lt;list of context—sensitive actions&gt;) where the scope specification is the list of precursor states. This requirement for prior specification of scope clauses clearly adds to the burden of the grammar writer. I have implemented a more satisfactory treatment of scope clauses. This is described below, following the discussion of LIFTR and SENDR actions, which require special handling in scoping. II LIFTR AND SENDR ACTIONS Two important actions (indeed it is difficult to write a grammar of any substantial subset of English without them) defined by Woods (1970), namely LIFTR and SENDR, present implementation difficulties in an island parsing interpreter. These actions were evidently excluded from the HWIM parser since there is no mention of them by Woods (1976). The action LIFTR can occur on any arc in the network, to transmit the value of a register up to the next higher level in the network, whereas SENDR can only occur on a PUSH arc, to transmit the value of a register down to a lower level. 101 A. LIFTR The same mechanism can be used to implement LIFTR actions as is used to transmit the result of each lower level computation up to the next highe</context>
</contexts>
<marker>Woods, 1970</marker>
<rawString>Woods, W. (1970) &amp;quot;Transition Network Grammars for Natural Language Analysis&amp;quot;. Communications of the ACM, 13, 10, 591-606.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Woods</author>
</authors>
<title>Parsers&amp;quot; in &amp;quot;Speech Understanding Systems&amp;quot;. Bolt, Beranek and Newman Inc.</title>
<date>1976</date>
<tech>Report No.3438, Vol.4,</tech>
<pages>1--21</pages>
<contexts>
<context position="3076" citStr="Woods, 1976" startWordPosition="495" endWordPosition="496">rs&apos;, and arbitrary tests on an arc to determine whether that arc is to be followed. In an island parser, an action or test is referred to as being context—sensitive when it either requires the value of a register that is set somewhere to the left, or changes the value of a register that is used somewhere also to the left. For each context sensitive action or test, there exists a set of states to its left such that the action can safely be performed if its execution is delayed until the parse has passed through one of these states. This list of states must be expressed, and in the HWIM system (Woods, 1976), this is done when writing the grammar by using a scope clause. The form of a scope clause is (SCOPE &lt;scope specification&gt; &lt;list of context—sensitive actions&gt;) where the scope specification is the list of precursor states. This requirement for prior specification of scope clauses clearly adds to the burden of the grammar writer. I have implemented a more satisfactory treatment of scope clauses. This is described below, following the discussion of LIFTR and SENDR actions, which require special handling in scoping. II LIFTR AND SENDR ACTIONS Two important actions (indeed it is difficult to writ</context>
</contexts>
<marker>Woods, 1976</marker>
<rawString>Woods, W. et al. (1976) &amp;quot;Parsers&amp;quot; in &amp;quot;Speech Understanding Systems&amp;quot;. Bolt, Beranek and Newman Inc. Report No.3438, Vol.4, 1-21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Woods</author>
</authors>
<title>Cascaded ATN Grammars&amp;quot;.</title>
<date>1980</date>
<journal>American Journal of Computational Linguistics,</journal>
<volume>6</volume>
<pages>1--12</pages>
<marker>Woods, 1980</marker>
<rawString>Woods, W. (1980) &amp;quot;Cascaded ATN Grammars&amp;quot;. American Journal of Computational Linguistics, 6, 1, 1-12.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>