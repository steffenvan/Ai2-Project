<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.018645">
<title confidence="0.997174">
IITP:Supervised Machine Learning for Aspect based Sentiment Analysis
</title>
<author confidence="0.993003">
Deepak Kumar Gupta
</author>
<affiliation confidence="0.8836955">
Indian Institute of Technology Patna
Patna, India
</affiliation>
<email confidence="0.947713">
deepak.mtmc13@iitp.ac.in
</email>
<author confidence="0.97861">
Asif Ekbal
</author>
<affiliation confidence="0.878771">
Indian Institute of Technology Patna
Patna, India
</affiliation>
<email confidence="0.984989">
asif@iitp.ac.in
</email>
<sectionHeader confidence="0.993556" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99995864">
The shared task on Aspect based Senti-
ment Analysis primarily focuses on mining
relevant information from the thousands
of online reviews available for a popular
product or service. In this paper we re-
port our works on aspect term extraction
and sentiment classification with respect
to our participation in the SemEval-2014
shared task. The aspect term extraction
method is based on supervised learning
algorithm, where we use different classi-
fiers, and finally combine their outputs us-
ing a majority voting technique. For senti-
ment classification we use Random Forest
classifier. Our system for aspect term ex-
traction shows the F-scores of 72.13% and
62.84% for the restaurants and laptops re-
views, respectively. Due to some techni-
cal problems our submission on sentiment
classification was not evaluated. However
we evaluate the submitted system with the
same evaluation metrics, and it shows the
accuracies of 67.37% and 67.07% for the
restaurants and laptops reviews, respec-
tively.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999737">
Nowadays user review is one of the means to drive
the sales of products or services. There is a grow-
ing trend among the customers who look at the on-
line reviews of products or services before taking
a final decision. In sentiment analysis and opinion
mining, aspect extraction aims to extract entity as-
pects or features on which opinions have been ex-
pressed (Hu and Liu, 2004; Liu, 2012). An aspect
is an attribute or component of the product that
</bodyText>
<footnote confidence="0.45922875">
This work is licensed under a Creative Commons At-
tribution 4.0 International License. Page numbers and pro-
ceedings footer are added by the organizers. License details:
http://creativecommons.org/licenses/by/4.0/
</footnote>
<bodyText confidence="0.999007368421053">
has been commented on in a review. For exam-
ple:“Dell Laptop has very good battery life and
click pads”. Here aspect terms are battery life and
click pads. Sentiment analysis is the task of iden-
tifying the polarity (positive, negative or neutral)
of review. Aspect terms can influence sentiment
polarity within a single domain. As an example,
for the restaurant domain cheap is usually posi-
tive with respect to food, but it denotes a negative
polarity when discussing the decor or ambiance
(Brody and Elhadad, 2010).
A key task of aspect based sentiment analysis
is to extract aspects of entities and determine the
sentiment corresponding to aspect terms that have
been commented in review document. In recent
times there has been huge interest to identify as-
pects and sentiments simultaneously. The method
proposed in (Hu and Liu, 2004) is based on infor-
mation extraction (IE) approach that identifies fre-
quently occurring noun phrases using association
mining. Some other works include the methods,
viz those that define aspect terms using a manually
specified subset of the Wikipedia category (Fahrni
and Klenner, 2008) hierarchy, unsupervised clus-
tering technique (Popescu and Etzionir, 2005) and
semantically motivated technique (Turney, 2002)
etc. Our proposed approach for aspect term ex-
traction is based on supervised machine learning,
where we build many models based on different
classifiers, and finally combine their outputs us-
ing majority voting. Before combining, the out-
put of each classifier is post-processed with a set
of heuristics. Each of these classifiers is trained
with a moderate set of features, which are gen-
erated without using any domain-specific knowl-
edge and/or resources. Our submitted system
for the second task is based on Random Forest
(Breiman, 2001).
</bodyText>
<page confidence="0.99182">
319
</page>
<note confidence="0.826998">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 319–323,
Dublin, Ireland, August 23-24, 2014.
</note>
<sectionHeader confidence="0.976143" genericHeader="introduction">
2 Tasks
</sectionHeader>
<bodyText confidence="0.99991765">
The SemEval-2014 shared task on Aspect based
Sentiment Analysis 1 focuses on identifying the
aspects of a given target entities and the senti-
ment expressed towards each aspect. A bench-
mark setup was provided with the datasets con-
sisting of customer reviews with human-annotated
annotations of the aspects and their polarity infor-
mation. There were four subtasks, and we partic-
ipated in the first two of them. These are defined
as follows:
Subtask-1: The first task is related to aspect
term extraction. Given a set of sentences with
pre-identified entities, identify the aspect terms
present in the sentence and return a list containing
all the distinct aspect terms.
Substask-2: The second task addresses the as-
pect term polarity. For a given set of aspect terms
within a sentence, determine whether the polarity
of each aspect term is positive, negative, neutral or
conflict (i.e. both positive and negative).
</bodyText>
<sectionHeader confidence="0.999633" genericHeader="method">
3 Methods
</sectionHeader>
<subsectionHeader confidence="0.99997">
3.1 Pre-processing
</subsectionHeader>
<bodyText confidence="0.999964714285714">
Each review is in the XML form. At first we ex-
tract the reviews along with their identifiers. Each
review is tokenized using the Stanford parser 2 and
Part-of-Speech tagged using the Stanford PoS tag-
ger 3. At the various levels we need the chunk-
level information. We extract these information
using the OpenNLP chunker available at 4.
</bodyText>
<subsectionHeader confidence="0.99979">
3.2 Aspect Term Extraction
</subsectionHeader>
<bodyText confidence="0.999769285714286">
The approach we adopted for aspect term extrac-
tion is based on the supervised machine learn-
ing algorithm. An aspect can be expressed by
a noun, adjective, verb or adverb. But the re-
cent research in (Liu, 2007) shows that 60-70%
of the aspect terms are explicit nouns. The aspect
terms could also consist of multiword entities such
as “battery life” and “spicy tuna rolls” etc. As
the classification algorithms we make use of Se-
quential minimal optimization (SMO), Multiclass
classifier, Random forest and Random tree. For
faster computation of Support Vector Machine,
SMO (Platt, 1998) was proposed. Random tree
(Breiman, 2001) is basically a decision tree, and
</bodyText>
<footnote confidence="0.99994125">
1http://alt.qcri.org/semeval2014/task4/
2http://nlp.stanford.edu/software/lexparser.shtml
3http://nlp.stanford.edu/software/tagger.shtml
4http://opennlp.sourceforge.net/models-1.5/
</footnote>
<bodyText confidence="0.999565818181818">
in general used as a weak learner to be included in
some ensemble learning method. Multiclass clas-
sifier is a meta learner based on binary SMO. This
has been converted to multiclass classifier using
the pairwise method. In order to reduce the errors
caused by the incorrect boundary identification we
define a set of heuristics, and apply on each output.
At the end these models are combined together us-
ing a simple majority voting.
We implement the following set of features for
aspect terms extraction.
</bodyText>
<listItem confidence="0.962491875">
• Local context: Local contexts that span the
preceding and following few tokens of the
current word are used as the features. Here
we use the previous two and next two tokens
as the features.
• Part-of-Speech information: Part-of-
Speech(PoS)information plays an important
role in identifying the aspect terms. We use
the PoS information of the current token as
the feature.
• Chunk Information: Chunk information
helps in identifying the boundaries of aspect
terms. This is particularly more helpful to
recognize multiword aspect terms.
• Root word: Roots of the surface forms are
used as the features. We use the Porter Stem-
mer algorithm 5 to extract the root forms.
• Stop word: We use the list of stop words
available at 6. A feature is defined that takes
the value equal to 1 or 0 depending upon
whether it appears in the training/test set or
not.
• Length: Length of token plays an important
role in identifying the aspect terms. We as-
sume an entity as the candidate aspect term
if its length exceeds a predefined threshold
value equal to five.
• Prefix and Suffix: Prefix and suffix of fixed
length character sequences are stripped from
each token and used as the features of classi-
fier. Here we use the prefixes and suffixes of
length upto three characters as the features.
</listItem>
<footnote confidence="0.999974">
5http://tartarus.org/martin/PorterStemmer/java.txt
6http://ir.dcs.gla.ac.uk/resources/linguistic utils/stop words
</footnote>
<page confidence="0.988953">
320
</page>
<listItem confidence="0.7079535">
• Frequent aspect term: We extract the the as-
pect terms from the training data, and prepare
a list by considering the most frequently oc-
curring terms. We consider an aspect term to
be frequent if it appears at least five times in
the training data. A feature is then defined
that fires if and only if the current token ap-
pears in this list.
</listItem>
<bodyText confidence="0.999211692307693">
The output of each classifiers is post-processed
with a set of hand-crafted rules, defined as below:
Rule 1: If the PoS tag of the target token is noun,
chunk tag is I-NP (denoting the intermediate to-
ken of a noun phrase) and the observed class of the
previous token is O (other than aspect terms) then
the current token should be assigned the class B-
Aspect (denotes the beginning of an aspect term).
Rule 2: If the current token has PoS tag noun,
chunk tag I-NP and the observed class of the im-
mediately preceding token is B-Aspect then the
current token should be assigned the class I-Aspect
(denoting the intermediate token).
</bodyText>
<subsectionHeader confidence="0.997682">
3.3 Polarity Identification
</subsectionHeader>
<bodyText confidence="0.999883538461538">
Polarity classification of aspect terms is the classi-
cal problem in sentiment analysis. The task is to
classify the sentiments or opinions into semantic
classes such as positive, negative, and neutral. We
develop a Random Forest classifier for this task.
In this particular task one more class conflict is in-
troduced. It is assigned if the sentiment can either
be positive or negative. For classification we make
use of some of the features such as local context,
PoS, Chunk, prefix and suffix etc., as defined in the
previous Subsection. Some other problem-specific
features that we implement for sentiment classifi-
cation are defined as below:
</bodyText>
<listItem confidence="0.994481909090909">
• MPQA feature: We make use of MPQA
subjectivity lexicon (Wiebe and Mihalcea,
2006) that contains sentiment bearing words
as feature in our classifier. This list was pre-
pared semi-automatically from the corpora of
MPQA7 and Movie Review dataset8. A fea-
ture is defined that takes the values as fol-
lows: 1 for positive; -1 for negative; 0 for
neutral and 2 for those words that do not ap-
pear in the list.
• Function words: A list of function words is
</listItem>
<footnote confidence="0.997358">
7http://cs.pitt.edu/mpqa/
8http://cs.cornell.edu/People/pabo/movie-review-data/
</footnote>
<bodyText confidence="0.998597333333333">
compiled from the web9. A binary-valued
feature is defined that fires for those words
that appear in this list.
</bodyText>
<sectionHeader confidence="0.987061" genericHeader="evaluation">
4 Experiments and Analysis
</sectionHeader>
<bodyText confidence="0.999678">
We use the datasets and the evaluation scripts as
provided by the SemEval-2014 shared task orga-
nizer.
</bodyText>
<subsectionHeader confidence="0.948413">
4.1 Datasets
</subsectionHeader>
<bodyText confidence="0.999952428571429">
The datasets comprise of the domains of restau-
rants and laptop reviews. The training sets con-
sist of 3,044 and 3,045 reviews. There are 3,699
and 2,358 aspect terms, respectively. The test set
contains 800 reviews for each domain. There are
1,134 and 654 test instances in the respective do-
mains.
</bodyText>
<subsectionHeader confidence="0.63943">
4.2 Results and Analysis
</subsectionHeader>
<bodyText confidence="0.999989357142857">
At first we develop several machine learning mod-
els based on the different classification algorithms.
All these classifiers were trained using the same
set of features as mentioned in Section 3. We
use the default implementations of these classi-
fiers in Weka10. We post-process the outputs of
all the models using some heuristics. Finally, all
these classifiers are combined together using ma-
jority voting. It is to be noted that we determine
the best configuration by carrying out different ex-
periments on the development set, which is con-
structed by taking a part of the training set, and fi-
nally blind evaluation is performed on the respec-
tive test set. We use the evaluation script provided
with the SemEval-2014 shared task. The training
sets contain multiword aspect terms, and so we use
the standard BIO notation11 for proper boundary
marking.
Experiments show the precision, recall and F-
score values 77.97%, 72.13% and 74.94%, respec-
tively for the restaurant dataset. This is approxi-
mately 10 points below compared to the best sys-
tem. But it shows the increments of 4.16 and
27.79 points over the average and baseline mod-
els, respectively. For the laptop dataset we ob-
tain the precision, recall and F-score values of
70.74%, 62.84% and 66.55%, respectively. This
is 8 points below the best one and 10.35 points
</bodyText>
<footnote confidence="0.99504525">
9http://www2.fs.u-bunkyo.ac.jp/ gilner/wordlists.html
10www.cs.waikato.ac.nz/ml/weka/
11B, I and O denote the beginning, intermediate and out-
side tokens
</footnote>
<page confidence="0.989907">
321
</page>
<table confidence="0.999798777777778">
Model precision recall F-score
Random Tree 65.21 59.63 62.29
Random Forest 70.93 62.69 66.55
SMO 71.18 64.22 67.52
Multiclass 73.44 68.50 70.88
Ensemble 77.97 72.13 74.94
Best system 85.35 82.71 84.01
Average 76.74 67.26 70.78
Baseline - - 47.15
</table>
<tableCaption confidence="0.96239">
Table 1: Result of Task-A for restaurants dataset
with different classifiers (in %).
</tableCaption>
<table confidence="0.999920222222222">
Model precision recall F-score
Random Tree 56.52 56.17 56.34
Random Forest 58.38 58.02 58.19
SMO 63.62 63.22 63.39
Multiclass 65.30 64.90 65.09
Ensemble 70.74 62.84 66.55
Best system 84.80 66.51 74.55
Average 68.97 50.45 56.20
Baseline - - 35.64
</table>
<tableCaption confidence="0.8576205">
Table 2: Results of aspect term extraction for lap-
tops dataset with different classifiers (in %).
</tableCaption>
<bodyText confidence="0.997441095238095">
above the average system. Compared to the base-
line it achieves more than 20 point increment. De-
tailed evaluation results for all the classifiers are
reported in Table 1 and Table 2 for restaurant and
laptop datasets, respectively. Results show that
multiclass classifier achieves the highest perfor-
mance with precision, recall and F-score values
of 73.44%, 68.50% and 70.88%, respectively for
the restaurant dataset. The same model shows the
highest performance with precision, recall and F-
score values of 65.30%, 64.90% and 65.09%, re-
spectively for the laptop dataset. Because of ma-
jority ensemble we observe increments of 4.06%
and 1.46% F-score points over the best individual
model, respectively.
We also perform error analysis to understand
the possible sources of errors. We show only the
confusion matrix for Task-A in Table 3. It shows
that in most cases I-ASP is misclassified as B-ASP.
System also suffers because of the misclassifica-
tion of aspect terms to others.
</bodyText>
<tableCaption confidence="0.948570666666667">
Experiments for classification are reported in
Table 4. Evaluation shows that the system
achieves the accuracies of 67.37% and 67.07% for
</tableCaption>
<table confidence="0.99756025">
B-ASP I-ASP Other
B-ASP 853 15 269
I-ASP 114 213 142
Other 123 35 11431
</table>
<tableCaption confidence="0.9397085">
Table 3: Confusion matrix for Task-A on restau-
rants dataset.
</tableCaption>
<table confidence="0.99987425">
Datasets #Aspect #Correct Accuracy
Terms Identification (in %)
Restaurants 1134 764 67.37
Laptops 654 438 67.07
</table>
<tableCaption confidence="0.999873">
Table 4: Results of aspect terms polarity (in %).
</tableCaption>
<bodyText confidence="0.99997745">
the restaurants and laptops datasets, respectively.
Please note that our system for the second task
was not officially evaluated because of the techni-
cal problems of the submitted zipped folder. How-
ever we evaluated the same system with the of-
ficial evaluation script, and it shows the accura-
cies as reported in Table 4. We observe that the
classifier performs reasonably well for the posi-
tive and negative classes, and suffers most for the
conflict classes. This may be due to the number
of instances present in the respective training set.
Results show that our system achieves much lower
classification accuracy (13.58 points below) com-
pared to the best system for the restaurant datasets.
However, for the laptop datasets the classification
accuracy is quite encouraging (just 3.42 points be-
low the best system). It is also to be noted that our
classifier achieves quite comparable performance
for both the datasets. Therefore it is more general
and not biased to any particular domain.
</bodyText>
<sectionHeader confidence="0.998959" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999469142857143">
In this paper we report our works on aspect term
extraction and sentiment classification as part of
our participation in the SemEval-2014 shared task.
For aspect term extraction we develop an ensem-
ble system. Our aspect term classification model is
based on Random Forest classifier. Runs for both
of our systems were constrained in nature, i.e. we
did not make use of any external resources. Evalu-
ation on the shared task dataset shows encouraging
results that need further investigation.
Our analysis suggests that there are many ways
to improve the performance of the system. In fu-
ture we will identify more features to improve the
performance of each of the tasks.
</bodyText>
<page confidence="0.997463">
322
</page>
<sectionHeader confidence="0.995622" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999680617647059">
Leo Breiman. 2001. Random forests. 45(1):5–32.
S. Brody and N. Elhadad. 2010. An unsupervised
aspect-sentiment model for online reviews. In Pro-
ceedings of NAACL, pages 804–812, Los Angeles,
CA.
Angela Fahrni and Manfred Klenner. 2008. Old wine
or warm beer: Target-specic sentiment analysis of
adjectives. In Symsposium on Affective Language in
Human and Machine, pages 60–63. The Society for
the Study of Artificial Intelligence and Simulation of
Behavior (AISB).
M. Hu and B. Liu. 2004. Mining and summarizing
customer reviews. In Proceedings of the 10th KDD,
pages 168–177, Seattle, WAs.
B. Liu. 2007. Exploring Hyperlinks, Contents, and
Usage Data. Springer.
Bing Liu. 2012. Sentiment Analysis and Opinion Min-
ing. Synthesis Lectures on Human Language Tech-
nologies. Morgan &amp; Claypool Publishers.
John C. Platt. 1998. Sequential minimal optimiza-
tion: A fast algorithm for training support vector ma-
chines. Technical report, ADVANCES IN KERNEL
METHODS - SUPPORT VECTOR LEARNING.
Ana-Maria Popescu and Oren Etzionir. 2005. Ex-
tracting product features and opinions from reviews.
In Proceedings of the Conference on HLT/EMNLP,
pages 339–346.
P. D. Turney. 2002. Thumbs up or thumbs down?:
Semantic orientation applied to unsupervised classi-
fication of reviews. In Proceedings of the 40th ACL,
pages 417–424.
Janyce Wiebe and Rada Mihalcea. 2006. Word
sense and subjectivity. In Proceedings of the COL-
ING/ACL, pages 065–1072, Australia.
</reference>
<page confidence="0.999393">
323
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.402265">
<title confidence="0.997966">IITP:Supervised Machine Learning for Aspect based Sentiment Analysis</title>
<author confidence="0.990472">Deepak Kumar</author>
<affiliation confidence="0.999961">Indian Institute of Technology</affiliation>
<address confidence="0.83026">Patna,</address>
<email confidence="0.927237">deepak.mtmc13@iitp.ac.in</email>
<author confidence="0.659357">Asif</author>
<affiliation confidence="0.999728">Indian Institute of Technology</affiliation>
<address confidence="0.912166">Patna,</address>
<email confidence="0.990315">asif@iitp.ac.in</email>
<abstract confidence="0.993994615384615">shared task on based Senti- Analysis focuses on mining relevant information from the thousands of online reviews available for a popular product or service. In this paper we report our works on aspect term extraction and sentiment classification with respect to our participation in the SemEval-2014 shared task. The aspect term extraction method is based on supervised learning algorithm, where we use different classifiers, and finally combine their outputs using a majority voting technique. For sentiment classification we use Random Forest classifier. Our system for aspect term extraction shows the F-scores of 72.13% and 62.84% for the restaurants and laptops reviews, respectively. Due to some technical problems our submission on sentiment classification was not evaluated. However we evaluate the submitted system with the same evaluation metrics, and it shows the accuracies of 67.37% and 67.07% for the restaurants and laptops reviews, respectively.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Leo Breiman</author>
</authors>
<date>2001</date>
<note>Random forests. 45(1):5–32.</note>
<contexts>
<context position="3695" citStr="Breiman, 2001" startWordPosition="574" endWordPosition="575">escu and Etzionir, 2005) and semantically motivated technique (Turney, 2002) etc. Our proposed approach for aspect term extraction is based on supervised machine learning, where we build many models based on different classifiers, and finally combine their outputs using majority voting. Before combining, the output of each classifier is post-processed with a set of heuristics. Each of these classifiers is trained with a moderate set of features, which are generated without using any domain-specific knowledge and/or resources. Our submitted system for the second task is based on Random Forest (Breiman, 2001). 319 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 319–323, Dublin, Ireland, August 23-24, 2014. 2 Tasks The SemEval-2014 shared task on Aspect based Sentiment Analysis 1 focuses on identifying the aspects of a given target entities and the sentiment expressed towards each aspect. A benchmark setup was provided with the datasets consisting of customer reviews with human-annotated annotations of the aspects and their polarity information. There were four subtasks, and we participated in the first two of them. These are defined as follows: Subtask-1:</context>
<context position="5776" citStr="Breiman, 2001" startWordPosition="910" endWordPosition="911">we adopted for aspect term extraction is based on the supervised machine learning algorithm. An aspect can be expressed by a noun, adjective, verb or adverb. But the recent research in (Liu, 2007) shows that 60-70% of the aspect terms are explicit nouns. The aspect terms could also consist of multiword entities such as “battery life” and “spicy tuna rolls” etc. As the classification algorithms we make use of Sequential minimal optimization (SMO), Multiclass classifier, Random forest and Random tree. For faster computation of Support Vector Machine, SMO (Platt, 1998) was proposed. Random tree (Breiman, 2001) is basically a decision tree, and 1http://alt.qcri.org/semeval2014/task4/ 2http://nlp.stanford.edu/software/lexparser.shtml 3http://nlp.stanford.edu/software/tagger.shtml 4http://opennlp.sourceforge.net/models-1.5/ in general used as a weak learner to be included in some ensemble learning method. Multiclass classifier is a meta learner based on binary SMO. This has been converted to multiclass classifier using the pairwise method. In order to reduce the errors caused by the incorrect boundary identification we define a set of heuristics, and apply on each output. At the end these models are c</context>
</contexts>
<marker>Breiman, 2001</marker>
<rawString>Leo Breiman. 2001. Random forests. 45(1):5–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Brody</author>
<author>N Elhadad</author>
</authors>
<title>An unsupervised aspect-sentiment model for online reviews.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL,</booktitle>
<pages>804--812</pages>
<location>Los Angeles, CA.</location>
<contexts>
<context position="2424" citStr="Brody and Elhadad, 2010" startWordPosition="376" endWordPosition="379"> proceedings footer are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/ has been commented on in a review. For example:“Dell Laptop has very good battery life and click pads”. Here aspect terms are battery life and click pads. Sentiment analysis is the task of identifying the polarity (positive, negative or neutral) of review. Aspect terms can influence sentiment polarity within a single domain. As an example, for the restaurant domain cheap is usually positive with respect to food, but it denotes a negative polarity when discussing the decor or ambiance (Brody and Elhadad, 2010). A key task of aspect based sentiment analysis is to extract aspects of entities and determine the sentiment corresponding to aspect terms that have been commented in review document. In recent times there has been huge interest to identify aspects and sentiments simultaneously. The method proposed in (Hu and Liu, 2004) is based on information extraction (IE) approach that identifies frequently occurring noun phrases using association mining. Some other works include the methods, viz those that define aspect terms using a manually specified subset of the Wikipedia category (Fahrni and Klenner</context>
</contexts>
<marker>Brody, Elhadad, 2010</marker>
<rawString>S. Brody and N. Elhadad. 2010. An unsupervised aspect-sentiment model for online reviews. In Proceedings of NAACL, pages 804–812, Los Angeles, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angela Fahrni</author>
<author>Manfred Klenner</author>
</authors>
<title>Old wine or warm beer: Target-specic sentiment analysis of adjectives.</title>
<date>2008</date>
<booktitle>In Symsposium on Affective Language in Human and Machine,</booktitle>
<pages>60--63</pages>
<contexts>
<context position="3031" citStr="Fahrni and Klenner, 2008" startWordPosition="471" endWordPosition="474">and Elhadad, 2010). A key task of aspect based sentiment analysis is to extract aspects of entities and determine the sentiment corresponding to aspect terms that have been commented in review document. In recent times there has been huge interest to identify aspects and sentiments simultaneously. The method proposed in (Hu and Liu, 2004) is based on information extraction (IE) approach that identifies frequently occurring noun phrases using association mining. Some other works include the methods, viz those that define aspect terms using a manually specified subset of the Wikipedia category (Fahrni and Klenner, 2008) hierarchy, unsupervised clustering technique (Popescu and Etzionir, 2005) and semantically motivated technique (Turney, 2002) etc. Our proposed approach for aspect term extraction is based on supervised machine learning, where we build many models based on different classifiers, and finally combine their outputs using majority voting. Before combining, the output of each classifier is post-processed with a set of heuristics. Each of these classifiers is trained with a moderate set of features, which are generated without using any domain-specific knowledge and/or resources. Our submitted syst</context>
</contexts>
<marker>Fahrni, Klenner, 2008</marker>
<rawString>Angela Fahrni and Manfred Klenner. 2008. Old wine or warm beer: Target-specic sentiment analysis of adjectives. In Symsposium on Affective Language in Human and Machine, pages 60–63. The Society for the Study of Artificial Intelligence and Simulation of Behavior (AISB).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hu</author>
<author>B Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the 10th KDD,</booktitle>
<pages>168--177</pages>
<location>Seattle, WAs.</location>
<contexts>
<context position="1625" citStr="Hu and Liu, 2004" startWordPosition="250" endWordPosition="253">on sentiment classification was not evaluated. However we evaluate the submitted system with the same evaluation metrics, and it shows the accuracies of 67.37% and 67.07% for the restaurants and laptops reviews, respectively. 1 Introduction Nowadays user review is one of the means to drive the sales of products or services. There is a growing trend among the customers who look at the online reviews of products or services before taking a final decision. In sentiment analysis and opinion mining, aspect extraction aims to extract entity aspects or features on which opinions have been expressed (Hu and Liu, 2004; Liu, 2012). An aspect is an attribute or component of the product that This work is licensed under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/ has been commented on in a review. For example:“Dell Laptop has very good battery life and click pads”. Here aspect terms are battery life and click pads. Sentiment analysis is the task of identifying the polarity (positive, negative or neutral) of review. Aspect terms can influence sentiment polarity within a sin</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>M. Hu and B. Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the 10th KDD, pages 168–177, Seattle, WAs.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Liu</author>
</authors>
<title>Exploring Hyperlinks, Contents, and Usage Data.</title>
<date>2007</date>
<publisher>Springer.</publisher>
<contexts>
<context position="5358" citStr="Liu, 2007" startWordPosition="846" endWordPosition="847">egative). 3 Methods 3.1 Pre-processing Each review is in the XML form. At first we extract the reviews along with their identifiers. Each review is tokenized using the Stanford parser 2 and Part-of-Speech tagged using the Stanford PoS tagger 3. At the various levels we need the chunklevel information. We extract these information using the OpenNLP chunker available at 4. 3.2 Aspect Term Extraction The approach we adopted for aspect term extraction is based on the supervised machine learning algorithm. An aspect can be expressed by a noun, adjective, verb or adverb. But the recent research in (Liu, 2007) shows that 60-70% of the aspect terms are explicit nouns. The aspect terms could also consist of multiword entities such as “battery life” and “spicy tuna rolls” etc. As the classification algorithms we make use of Sequential minimal optimization (SMO), Multiclass classifier, Random forest and Random tree. For faster computation of Support Vector Machine, SMO (Platt, 1998) was proposed. Random tree (Breiman, 2001) is basically a decision tree, and 1http://alt.qcri.org/semeval2014/task4/ 2http://nlp.stanford.edu/software/lexparser.shtml 3http://nlp.stanford.edu/software/tagger.shtml 4http://op</context>
</contexts>
<marker>Liu, 2007</marker>
<rawString>B. Liu. 2007. Exploring Hyperlinks, Contents, and Usage Data. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment Analysis and Opinion Mining. Synthesis Lectures on Human Language Technologies.</title>
<date>2012</date>
<publisher>Morgan &amp; Claypool Publishers.</publisher>
<contexts>
<context position="1637" citStr="Liu, 2012" startWordPosition="254" endWordPosition="255">ification was not evaluated. However we evaluate the submitted system with the same evaluation metrics, and it shows the accuracies of 67.37% and 67.07% for the restaurants and laptops reviews, respectively. 1 Introduction Nowadays user review is one of the means to drive the sales of products or services. There is a growing trend among the customers who look at the online reviews of products or services before taking a final decision. In sentiment analysis and opinion mining, aspect extraction aims to extract entity aspects or features on which opinions have been expressed (Hu and Liu, 2004; Liu, 2012). An aspect is an attribute or component of the product that This work is licensed under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/ has been commented on in a review. For example:“Dell Laptop has very good battery life and click pads”. Here aspect terms are battery life and click pads. Sentiment analysis is the task of identifying the polarity (positive, negative or neutral) of review. Aspect terms can influence sentiment polarity within a single domain. </context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Bing Liu. 2012. Sentiment Analysis and Opinion Mining. Synthesis Lectures on Human Language Technologies. Morgan &amp; Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John C Platt</author>
</authors>
<title>Sequential minimal optimization: A fast algorithm for training support vector machines.</title>
<date>1998</date>
<journal>ADVANCES IN KERNEL METHODS - SUPPORT VECTOR LEARNING.</journal>
<tech>Technical report,</tech>
<contexts>
<context position="5734" citStr="Platt, 1998" startWordPosition="904" endWordPosition="905">3.2 Aspect Term Extraction The approach we adopted for aspect term extraction is based on the supervised machine learning algorithm. An aspect can be expressed by a noun, adjective, verb or adverb. But the recent research in (Liu, 2007) shows that 60-70% of the aspect terms are explicit nouns. The aspect terms could also consist of multiword entities such as “battery life” and “spicy tuna rolls” etc. As the classification algorithms we make use of Sequential minimal optimization (SMO), Multiclass classifier, Random forest and Random tree. For faster computation of Support Vector Machine, SMO (Platt, 1998) was proposed. Random tree (Breiman, 2001) is basically a decision tree, and 1http://alt.qcri.org/semeval2014/task4/ 2http://nlp.stanford.edu/software/lexparser.shtml 3http://nlp.stanford.edu/software/tagger.shtml 4http://opennlp.sourceforge.net/models-1.5/ in general used as a weak learner to be included in some ensemble learning method. Multiclass classifier is a meta learner based on binary SMO. This has been converted to multiclass classifier using the pairwise method. In order to reduce the errors caused by the incorrect boundary identification we define a set of heuristics, and apply on </context>
</contexts>
<marker>Platt, 1998</marker>
<rawString>John C. Platt. 1998. Sequential minimal optimization: A fast algorithm for training support vector machines. Technical report, ADVANCES IN KERNEL METHODS - SUPPORT VECTOR LEARNING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ana-Maria Popescu</author>
<author>Oren Etzionir</author>
</authors>
<title>Extracting product features and opinions from reviews.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference on HLT/EMNLP,</booktitle>
<pages>339--346</pages>
<contexts>
<context position="3105" citStr="Popescu and Etzionir, 2005" startWordPosition="480" endWordPosition="483">extract aspects of entities and determine the sentiment corresponding to aspect terms that have been commented in review document. In recent times there has been huge interest to identify aspects and sentiments simultaneously. The method proposed in (Hu and Liu, 2004) is based on information extraction (IE) approach that identifies frequently occurring noun phrases using association mining. Some other works include the methods, viz those that define aspect terms using a manually specified subset of the Wikipedia category (Fahrni and Klenner, 2008) hierarchy, unsupervised clustering technique (Popescu and Etzionir, 2005) and semantically motivated technique (Turney, 2002) etc. Our proposed approach for aspect term extraction is based on supervised machine learning, where we build many models based on different classifiers, and finally combine their outputs using majority voting. Before combining, the output of each classifier is post-processed with a set of heuristics. Each of these classifiers is trained with a moderate set of features, which are generated without using any domain-specific knowledge and/or resources. Our submitted system for the second task is based on Random Forest (Breiman, 2001). 319 Proc</context>
</contexts>
<marker>Popescu, Etzionir, 2005</marker>
<rawString>Ana-Maria Popescu and Oren Etzionir. 2005. Extracting product features and opinions from reviews. In Proceedings of the Conference on HLT/EMNLP, pages 339–346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P D Turney</author>
</authors>
<title>Thumbs up or thumbs down?: Semantic orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th ACL,</booktitle>
<pages>417--424</pages>
<contexts>
<context position="3157" citStr="Turney, 2002" startWordPosition="488" endWordPosition="489">ing to aspect terms that have been commented in review document. In recent times there has been huge interest to identify aspects and sentiments simultaneously. The method proposed in (Hu and Liu, 2004) is based on information extraction (IE) approach that identifies frequently occurring noun phrases using association mining. Some other works include the methods, viz those that define aspect terms using a manually specified subset of the Wikipedia category (Fahrni and Klenner, 2008) hierarchy, unsupervised clustering technique (Popescu and Etzionir, 2005) and semantically motivated technique (Turney, 2002) etc. Our proposed approach for aspect term extraction is based on supervised machine learning, where we build many models based on different classifiers, and finally combine their outputs using majority voting. Before combining, the output of each classifier is post-processed with a set of heuristics. Each of these classifiers is trained with a moderate set of features, which are generated without using any domain-specific knowledge and/or resources. Our submitted system for the second task is based on Random Forest (Breiman, 2001). 319 Proceedings of the 8th International Workshop on Semanti</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>P. D. Turney. 2002. Thumbs up or thumbs down?: Semantic orientation applied to unsupervised classification of reviews. In Proceedings of the 40th ACL, pages 417–424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Rada Mihalcea</author>
</authors>
<title>Word sense and subjectivity.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL,</booktitle>
<pages>065--1072</pages>
<contexts>
<context position="9622" citStr="Wiebe and Mihalcea, 2006" startWordPosition="1528" endWordPosition="1531">classify the sentiments or opinions into semantic classes such as positive, negative, and neutral. We develop a Random Forest classifier for this task. In this particular task one more class conflict is introduced. It is assigned if the sentiment can either be positive or negative. For classification we make use of some of the features such as local context, PoS, Chunk, prefix and suffix etc., as defined in the previous Subsection. Some other problem-specific features that we implement for sentiment classification are defined as below: • MPQA feature: We make use of MPQA subjectivity lexicon (Wiebe and Mihalcea, 2006) that contains sentiment bearing words as feature in our classifier. This list was prepared semi-automatically from the corpora of MPQA7 and Movie Review dataset8. A feature is defined that takes the values as follows: 1 for positive; -1 for negative; 0 for neutral and 2 for those words that do not appear in the list. • Function words: A list of function words is 7http://cs.pitt.edu/mpqa/ 8http://cs.cornell.edu/People/pabo/movie-review-data/ compiled from the web9. A binary-valued feature is defined that fires for those words that appear in this list. 4 Experiments and Analysis We use the data</context>
</contexts>
<marker>Wiebe, Mihalcea, 2006</marker>
<rawString>Janyce Wiebe and Rada Mihalcea. 2006. Word sense and subjectivity. In Proceedings of the COLING/ACL, pages 065–1072, Australia.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>