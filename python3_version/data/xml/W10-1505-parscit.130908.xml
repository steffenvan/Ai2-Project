<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001762">
<title confidence="0.98061">
Google Web 1T 5-Grams Made Easy (but not for the computer)
</title>
<author confidence="0.99944">
Stefan Evert
</author>
<affiliation confidence="0.99825">
Institute of Cognitive Science
University of Osnabr¨uck
</affiliation>
<address confidence="0.867031">
49069 Osnabr¨uck, Germany
</address>
<email confidence="0.995016">
stefan.evert@uos.de
</email>
<sectionHeader confidence="0.995555" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999658571428571">
This paper introduces Web1T5-Easy, a sim-
ple indexing solution that allows interactive
searches of the Web 1T 5-gram database and
a derived database of quasi-collocations. The
latter is validated against co-occurrence data
from the BNC and ukWaC on the automatic
identification of non-compositional VPC.
</bodyText>
<sectionHeader confidence="0.99879" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999787625">
The Google Web 1T 5-gram (Web1T5) database
(Brants and Franz, 2006) consists of frequency
counts for bigram, trigrams, 4-grams and 5-grams
extracted from 1 trillion words of English Web text,
i.e. from a corpus 10,000 times the size of the British
National Corpus (Aston and Burnard, 1998). While
primarily designed as a resource to build better lan-
guage models for machine translation and other NLP
applications, its public release in 2006 was greeted
with great enthusiasm by many researchers in com-
putational linguistics. As one example, Mitchell et
al. (2008) used the Web1T5 data successfully to pre-
dict fMRI neural activation associated with concrete
noun concepts.
For linguistic applications, though, the Web1T5
database presents three major obstacles:
(i) The lack of linguistic annotation: Google’s to-
kenisation splits hyphenated compounds (e.g., part-
time is split into a three-token sequence part�-Mime)
and differs in many other ways from the rules used
in liguistic corpora. The n-grams are neither anno-
tated with part-of-speech tags nor lemmatised, and
there are separate entries for sentence-initial upper-
case and the corresponding lowercase forms.
</bodyText>
<page confidence="0.988468">
32
</page>
<bodyText confidence="0.997864875">
(ii) The application offrequency thresholds: De-
spite the enormous size of the database, its com-
pilers found it necessary to omit low-frequency n-
grams with fewer than 40 occurrences. This means
that non-adjacent word combinations are listed only
if the occur in a relatively frequent pattern. As a
consequence, it is impossible to obtain reliable fre-
quency estimates for latent phenomena by pooling
data (e.g. the co-occurrence frequency of a particu-
lar verb with nouns denoting animals).
(iii) The difficulty of interactive search: The com-
plete Web1T5 database consists of 24.4 GiB of
binary-sorted, compressed text files. While this for-
mat is suitable for building n-gram language models
and other offline processing, searching the database
is not efficient enough for interactive use. Except for
simple, case-sensitive prefix searches – which can
be restricted to a single file containing 50–90 MiB
of compressed text – every query requires a linear
scan of the full database.
This paper presents a simple open-source soft-
ware solution to the third problem, called Web1T5-
Easy. The n-gram data are encoded and indexed
in a relational database. Building on convenient
open-source tools such as SQLite and Perl, the
software aims to strike a good balance between
search efficiency and ease of use and implemen-
tation. With its focus on interactive, but accu-
rate search it complements the approximate index-
ing and batch processing approaches of Hawker et
al. (2007). Web1T5-Easy can be downloaded from
http://webascorpus.sf.net/Web1T5-Easy/.1
</bodyText>
<footnote confidence="0.9914255">
1An online demo of the complete Web1T5 database is avail-
able at http://cogsci.uos.de/~korpora/ws/Web1T5/.
</footnote>
<note confidence="0.968467">
Proceedings of the NAACL HLT 2010 Sixth Web as Corpus Workshop, pages 32–40,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.991397875">
word 1 word 2 word 3 f
supplement depend on 193
supplement depending on 174
supplement depends entirely 94
supplement depends on 338
supplement derived from 2668
supplement des coups 77
supplement described in 200
</bodyText>
<tableCaption confidence="0.9896415">
Table 1: Example of Web1T5 3-gram frequency data (ex-
cerpt from file 3gm-0088.gz).
</tableCaption>
<bodyText confidence="0.999831461538462">
The rest of this paper is organised as follows. Sec-
tion 2 describes the general system architecture in
more detail. Section 3 explains how collocations
(with a maximal span size of four tokens) and dis-
tributional semantic models (DSM) can be approxi-
mated on the basis of Web1T5 frequency data. Some
technical aspects are summarised in Section 4. Sec-
tion 5 addresses the consequences of problems (i)
and (ii). The linguistic usefulness of Web1T5 col-
location data is validated on a multiword extraction
task from the MWE 2008 workshop.2 Section 6 con-
cludes with a brief outlook on the future develop-
ment of Web1T5-Easy.
</bodyText>
<sectionHeader confidence="0.884807" genericHeader="method">
2 System architecture
</sectionHeader>
<bodyText confidence="0.999562166666667">
While designing the fastest possible indexing archi-
tecture for the Web1T5 database is an interesting
computer science problem, linguistic applications
typically do not require the millisecond response
times of a commercial search engine. It is sufficient
for interactive queries to be completed within a few
seconds, and many users will also be willing to wait
several minutes for the result of a complex search
operation. Given the tabular format of the Web1T5
n-gram frequency data (cf. Table 1), it was a natural
choice to make use of a standard relational database
(RDBMS). Database tables can be indexed on sin-
gle or multiple columns for fast access, and the SQL
query languge allows flexible analysis and aggrega-
tion of frequency data (see Section 2.2 for some ex-
amples). While the indexing procedure can be very
time-consuming, it is carried out offline and has to
run only once.
</bodyText>
<footnote confidence="0.840191">
2http://multiword.sf.net/mwe2008/
</footnote>
<bodyText confidence="0.998923222222222">
Web1T5-Easy was designed to balance com-
putational efficiency against implementation effort
and ease of use. Its main ingredients are the
public-domain embedded relational database engine
SQLite and the open-source scripting language Perl
which are connected through the portable DBI/DBD
interface.3 The Web1T5-Easy package consists of
two sets of Perl scripts. The first set automates
pre-processing and indexing, detailed in Section 2.1.
The second set, which facilitates command-line ac-
cess to the database and provides a Web-based GUI,
is described in Section 2.2. Technical details of the
representation format and performance figures are
presented in Section 4.
The embedded database engine SQLite was pre-
ferred over a full-fledged RDBMS such as MySQL
or PostgreSQL for several reasons: (i) running the
database as a user-level process gives better con-
trol over huge database files and expensive indexing
operations, which might otherwise clog up a ded-
icated MySQL server computer; (ii) each SQLite
database is stored in a single, platform-independent
file, so it can easily be copied to other locations or
servers; (iii) an embedded database avoids the over-
head of exchanging large amounts of data between
client and server; (iv) tight integration with the ap-
plication program allows more flexible use of the
database than pure SQL queries (e.g., a Perl script
can define its own SQL functions, cf. Section 3).
It is quite possible that the sophisticated query op-
timisers of MySQL and commercial RDMBS im-
plementations would improve performance on com-
plex SQL queries. Since Web1T5-Easy uses the
generic DBI interface, it can easily be adapted to any
RDMBS back-end for which DBI/DBD drivers are
available.
</bodyText>
<subsectionHeader confidence="0.988928">
2.1 The indexing procedure
</subsectionHeader>
<bodyText confidence="0.983373">
Indexing of the Web1T5 n-gram data is carried out
in four stages:
</bodyText>
<listItem confidence="0.641234">
1. In an optional pre-processing step, words are
filtered and normalised to lowercase.4 Each
</listItem>
<footnote confidence="0.998953833333333">
3See the Web pages at http://www.sqlite.org/, http:
//www.perl.org/ and http://dbi.perl.org/.
4The default filter replaces numbers by the code NUM, var-
ious punctuation symbols by the code PUN, and all “messy”
strings by the code UNK. It can easily be replaced by a user-
defined normalisation mapping.
</footnote>
<page confidence="0.99956">
33
</page>
<bodyText confidence="0.999699857142857">
word in an n-gram entry is then coded as a nu-
meric ID, which reduces database size and im-
proves both indexing and query performance
(see Section 4 for details on the representation
format). The resulting tuples of n + 1 integers
(n word IDs plus frequency count) are inserted
into a database table.
</bodyText>
<listItem confidence="0.930092555555555">
2. If normalisation was applied, the table will con-
tain multiple entries for many n-grams.5 In
Stage 2, their frequency counts are aggregated
with a suitable SQL query. This is one of the
most expensive and disk-intensive operations
of the entire indexing procedure.
3. A separate SQL index is created for each n-
gram position (e.g., word 1, word 2 and word 3
in Table 1). Multi-column indexes are currently
omitted, as they would drastically increase the
size of the database files.6 Moreover, the use of
an index only improves query execution speed
if it is highly selective, as explained in Sec-
tion 4. If desired, the Perl scripts can trivially
be extended to create additional indexes.
4. A statistical analysis of the database is per-
formed to improve query optimisation (i.e., ap-
propriate selection of indexes).
</listItem>
<bodyText confidence="0.9999675">
The indexing procedure is carried out separately for
bigrams, trigrams, 4-grams and 5-grams, using a
shared lexicon table to look up numeric IDs. Users
who do not need the larger n-grams can easily skip
them, resulting in a considerably smaller database
and much faster indexing.
</bodyText>
<subsectionHeader confidence="0.999434">
2.2 Database queries and the Web GUI
</subsectionHeader>
<bodyText confidence="0.91473666">
After the SQLite database has been populated and
indexed, it can be searched with standard SQL
queries (typically a join between one of the n-gram
tables and the lexicon table), e.g. using the sqlite3
5For example, with the default normalisation, bought 2 bot-
tles, bought 5 bottles, Bought 3 bottles, BOUGHT 2 BOT-
TLES and many other trigrams are mapped to the representation
bought NUM bottles. The database table thus contains multiple
entries of the trigram bought NUM bottles, whose frequency
counts have to be added up.
6For the 5-gram table, 10 different two-column indexes
would be required to cover a wide range of queries, more than
doubling the size of the database file.
command-line utility. Since this requires detailed
knowledge of SQL syntax as well as the database
layout and normalisation rules, the Web1T5-Easy
package offers a simpler, user-friendly query lan-
guage, which is internally translated into appropriate
SQL code.
A Web1T5-Easy query consists of 2–5 search
terms separated by blanks. Each search term is ei-
ther a literal word (e.g. sit), a set of words in square
brackets (e.g. [sit,sits,sat,sitting]), aprefix
(under%) or suffix (%ation) expression, * for an ar-
bitrary word, or ? to skip a word. The difference be-
tween the latter two is that positions marked by * are
included in the query result, while those marked by ?
are not. If a query term cannot match because of nor-
malisation, an informative error message is shown.
Matches can be ranked by frequency or by associa-
tion scores, according to one of the measures recom-
mended by Evert (2008): t-score (t), log-likelihood
(G2), chi-squared with Yates’ correction (X2), point-
wise MI, or a version of the Dice coefficient.
For example, the query web as corpus shows
that the trigram Web as Corpus occurs 1,104
times in the Google corpus (case-insensitive).
%ly good fun lists ways of having fun such
as really good fun (12,223x), jolly good fun
(3,730x) and extremely good fun (2,788x). The
query [sit,sits,sat,sitting] * ? chair re-
turns the patterns SIT in ... chair (201,084x), SIT
on ... chair (61,901x), SIT at ... chair (1,173x),
etc. Corpus frequencies are automatically summed
over all fillers in the third slot.
The query implementation is available as a
command-line version and as a CGI script that
provides a Web-based GUI to the Web1T5-Easy
database. The CGI version also offers CSV and
XML output formats for use as a Web service.
</bodyText>
<sectionHeader confidence="0.949082" genericHeader="method">
3 Quasi-collocations and DSM
</sectionHeader>
<bodyText confidence="0.999904125">
Many corpus linguists and lexicographers will par-
ticularly be interested in using the Web1T5 database
as a source of collocations (in the sense of Sinclair
(1991)). While the British National Corpus at best
provides sufficient data for a collocational analysis
of some 50,000 words (taking f &gt; 50 to be the min-
imum corpus frequency necessary), Web1T5 offers
comprehensive collocation data for almost 500,000
</bodyText>
<page confidence="0.997631">
34
</page>
<figureCaption confidence="0.999771">
Figure 1: Quasi-collocations for the node word corpus in the Web GUI of Web1T5-Easy.
</figureCaption>
<bodyText confidence="0.9999534">
words (which have at least 50 different collocates in
the database, and f &gt; 10,000 in the original Google
corpus).
Unfortunately, the Web1T5 distribution does not
include co-occurrence frequencies of word pairs,
except for data on immediately adjacent bigrams.
It is possible, though, to derive approximate co-
occurrence frequencies within a collocational span
of up to 4 tokens. In this approach, each n-gram ta-
ble yields information about a specific collocate po-
sition relative to the node. For instance, one can
use the 4-gram table to identify collocates of the
node word corpus at position +3 (i.e., 3 tokens to
the right of the node) with the Web1T5-Easy query
corpus ? ? *, and collocates at position −3 (i.e.,
3 tokens to the left of the node) with the query
* ? ? corpus. Co-occurrence frequencies within
a collocational span, e.g. (−3,+3), are obtained by
summation over all collocate positions in this win-
dow, collecting data from multiple n-gram tables.
It has to be kept in mind that such quasi-
collocations do not represent the true co-occurrence
frequencies, since an instance of co-occurrence of
two words is counted only if it forms part of an n-
gram with f &gt; 40 that has been included in Web1T5.
Especially for larger distances of 3 or 4 tokens, this
limitation is likely to discard most of the evidence
for co-occurrence and put a focus on collocations
that form part of a rigid multiword unit or insti-
tutionalised phrase. Thus, cars becomes the most
salient collocate of collectibles merely because the
two words appear in the slogan from collectibles to
cars (9,443,572x). Section 5 validates the linguistic
usefulness of Web1T5 quasi-collocations in a multi-
word extraction task.
Web1T5-Easy compiles frequency data for quasi-
collocations in an additional step after the complete
n-gram data have been indexed. For each pair of co-
occurring words, the number of co-occurrences in
each collocational position (−4,−3,...,+3,+4) is
recorded. If the user has chosen to skip the largest
n-gram tables, only a shorter collocational span will
be available.
The Web GUI generates SQL code to determine
co-occurrence frequencies within a user-defined col-
locational span on the fly, by summation over the
appropriate columns of the quasi-collocations table.
Collocates can be ranked by a range of association
measures (t, G2, X2, MI, Dice, or frequency f),
which are implemented as user-defined SQL func-
tions in the Perl code. In this way, sophisticated
statistical analyses can be performed even if they
are not directly supported by the RDBMS back-end.
Figure 1 shows an example of quasi-collocations in
the Web GUI, ranked according to the t-score mea-
sure. On the right-hand side of the table, the distri-
bution across collocate positions is visualised.
In computational linguistics, collocations play
an important role as the term-term co-occurrence
matrix underlying distributional semantic models
</bodyText>
<page confidence="0.981539">
35
</page>
<table confidence="0.999864125">
size (GiB) database file no. of rows
0.23 vocabulary 5,787,556
7.24 2-grams 153,634,491
32.81 3-grams 594,453,302
64.32 4-grams 933,385,623
75.09 5-grams 909,734,581
31.73 collocations 494,138,116
211.42 total 3,091,133,669
</table>
<tableCaption confidence="0.9976575">
Table 2: Size of the fully indexed Web1T5 database, in-
cluding quasi-collocations.
</tableCaption>
<bodyText confidence="0.999342571428571">
(DSM), with association scores used as feature
weights (see e.g. Curran (2004, Sec. 4.3)). The
Web1T5-Easy quasi-collocations table provides a
sparse representation of such a term-term matrix,
where only 494 x 106 or 0.0015% of the 5.8 x 106 �
5.8x106 = 33.5x1012 cells of a full co-occurrence
matrix are populated with nonzero entries.
</bodyText>
<sectionHeader confidence="0.99504" genericHeader="method">
4 Technical aspects
</sectionHeader>
<bodyText confidence="0.999983217391305">
An essential feature of Web1T5-Easy is the numeric
coding of words in the n-gram tables, which allows
for compact storage and more efficient indexing of
the data than a full character string representation. A
separate lexicon table lists every (normalised) word
form together with its corpus frequency and an in-
teger ID. The lexicon is sorted by decreasing fre-
quency: since SQLite encodes integers in a variable-
length format, it is advantageous to assign low ID
numbers to the most frequent terms.
Every table is stored in its own SQLite database
file, e.g. vocabulary for the lexicon table and
collocations for quasi-collocations (cf. Sec-
tion 3). The database files for different n-gram sizes
(2-grams, 3-grams, 4-grams, 5-grams) share
the same layout and differ only in the number of
columns. Table 2 lists the disk size and number of
rows of each database file, with default normalisa-
tion applied. While the total size of 211 GiB by far
exceeds the original Web1T5 distribution, it can eas-
ily be handled by modern commodity hardware and
is efficient enough for interactive queries.
Performance measurements were made on a
midrange 64-bit Linux server with 2.6 GHz AMD
Opteron CPUs (4 cores) and 16 GiB RAM. SQLite
database files and temporary data were stored on a
fast, locally mounted hard disk. Similar or better
hardware will be available at most academic institu-
tions, and even in recent personal desktop PCs.
Indexing the n-gram tables in SQLite took about
two weeks. Since the server was also used for mul-
tiple other memory- and disk-intensive tasks during
this period, the timings reported here should only
be understood as rough indications. The indexing
process might be considerably faster on a dedicated
server. Roughly equal amounts of time were spent
on each of the four stages listed in Section 2.1.
Database analysis in Stage 4 turned out to be of
limited value because the SQLite query optimiser
was not able to make good use of this information.
Therefore, a heuristic optimiser based on individual
term frequencies was added to the Perl query scripts.
This optimiser chooses the n-gram slot that is most
likely to speed up the query, and explicitly disables
the use of indexes for all other slots. Unless another
constraint is much more selective, preference is al-
ways given to the first slot, which represents a clus-
tered index (i.e. database rows are stored in index
order) and can be scanned very efficiently.
With these explicit optimisations, Stage 4 of the
indexing process can be omitted. If normalisation is
not required, Stage 2 can also be skipped, reducing
the total indexing time by half.
At first sight, it seems to be easy to compile the
database of quasi-collocations one node at a time,
based on the fully indexed n-gram tables. However,
the overhead of random disk access during index
lookups made this approach intractable.7 A brute-
force Perl script that performs multiple linear scans
of the complete n-gram tables, holding as much data
in RAM as possible, completed the compilation of
co-occurrence frequencies in about three days.
Table 3 shows execution times for a selection of
Web1T5-Easy queries entered in the Web GUI. In
general, prefix queries that start with a reasonably
specific term (such as time of *) are very fast,
even on a cold cache. The query %ly good fun
is a pathological case: none of the terms is selec-
tive enough to make good use of the corresponding
</bodyText>
<footnote confidence="0.99600275">
7In particular, queries like * ? ? corpus that scan for col-
locates to the left of the node word are extremely inefficient,
since the index on the last n-gram slot is not clustered and ac-
cesses matching database rows in random order.
</footnote>
<page confidence="0.996021">
36
</page>
<figure confidence="0.66836725">
Web1T5-Easy query
corpus linguistics
web as corpus
time of *
%ly good fun
[sit,sits,sat,sitting] * ? chair
* linguistics (association ranking)
university of * (association ranking)
</figure>
<figureCaption confidence="0.2602975">
collocations of linguistics
collocations of web
</figureCaption>
<table confidence="0.8913114">
cold cache warm cache
0.11s 0.01s
1.29s 0.44s
2.71s 1.09s
181.03s 24.37s
1.16s 0.31s
11.42s 0.05s
1.48s 0.48s
0.21s 0.13s
6.19s 3.89s
</table>
<tableCaption confidence="0.980014">
Table 3: Performance of interactive queries in the Web GUI of Web1T5-Easy. Separate timings are given for a cold
disk cache (first query) and warm disk cache (repeated query). Re-running a query with modified display or ranking
settings will only take the time listed in the last column.
</tableCaption>
<bodyText confidence="0.999289666666667">
index, and entries matching the wildcard expression
%ly in the first slot are scattered across the entire
trigram table.
</bodyText>
<sectionHeader confidence="0.650787" genericHeader="method">
5 Validation on a MWE extraction task
</sectionHeader>
<bodyText confidence="0.99987512">
In order to validate the linguistic usefulness
of Web1T5 quasi-collocations, they were evalu-
ated on the English VPC shared task from the
MWE 2008 workshop.8 This data set consists of
3,078 verb-particle constructions (VPC), which have
been manually annotated as compositional or non-
compositional (Baldwin, 2008). The task is to iden-
tify non-compositional VPC as true positives (TP)
and re-rank the data set accordingly. Evaluation is
carried out in terms of precision-recall graphs, using
average precision (AP, corresponding to the area un-
der a precision-recall curve) as a global measure of
accuracy.
Frequency data from the Web1T5 quasi-
collocations table was used to calculate association
scores and rankings. Since previous studies suggest
that no single association measure works equally
well for all tasks and data sets, several popular mea-
sures were included in the evaluation: t-score (t),
chi-squared with Yates’ continuity correction (X2),
Dice coefficient (Dice), co-occurrence frequency
(f), log-likelihood (G2) and Mutual Information
(MI); see e.g. Evert (2008) for full equations and
references. The results are compared against rank-
ings obtained from more traditional, linguistically
</bodyText>
<footnote confidence="0.802126">
8http://multiword.sf.net/mwe2008/
</footnote>
<bodyText confidence="0.99564721875">
annotated corpora of British English: the balanced,
100-million-word British National Corpus (Aston
and Burnard, 1998) and the 2-billion-word Web
corpus ukWaC (Baroni et al., 2009).
For BNC and ukWaC, three different extraction
methods were used: (i) adjacent bigrams of verb +
particle/preposition; (ii) shallow syntactic patterns
based on POS tags (allowing pronouns and simple
noun phrases between verb and particle); and (iii)
surface co-occurrence within a collocational span of
3 tokens to the right of the node (+1,+3), filtered
by POS tag. Association scores were calculated us-
ing the same measures as for the Web1T5 quasi-
collocations. Preliminary experiments with different
collocational spans showed consistently lower accu-
racy than for (+1,+3). In each case, the same asso-
ciation measures were applied as for Web1T5.
Evaluation results are shown in Figure 3 (graphs)
and Table 4 (AP). The latter also describes the cover-
age of the corpus data by listing the number of can-
didates for which no frequency information is avail-
able (second column). These candidates are always
ranked at the end of the list. While the BNC has
a coverage of 92%–94% (depending on extraction
method), scaling up to Web1T5 completely elimi-
nates the missing data problem.
However, identification of non-compositional
VPC with the Web1T5 quasi-collocations is consid-
erably less accurate than with linguistically anno-
tated data from the much smaller BNC. For recall
values above 50%, the precision of statistical associ-
ation measures such as t and X2 is particularly poor
</bodyText>
<page confidence="0.997649">
37
</page>
<table confidence="0.9997927">
coverage t average precision (%) MI
(missing) X2 Dice f G2
BNC (bigrams) 242 30.04 29.75 27.12 26.55 29.86 22.79
BNC (syntactic patterns) 201 30.42 30.49 27.48 25.87 30.64 22.48
BNC (span +1... +3) 185 29.15 32.12 30.13 24.33 31.06 22.58
ukWaC (bigrams) 171 29.28 30.32 27.79 25.37 29.63 25.13
ukWaC (syntactic patterns) 162 29.20 31.19 27.90 24.19 30.06 25.08
ukWaC (span +1... +3) 157 27.82 32.66 30.54 23.03 30.01 25.76
Web1T5 (span +1... + 3) 3 25.83 25.27 25.33 20.88 25.77 20.81
BNC untagged (+1... + 3) 39 27.22 27.85 28.98 22.51 28.13 19.60
</table>
<tableCaption confidence="0.9958335">
Table 4: Evaluation results for English non-compositional VPC (Baldwin, 2008): average precision (AP) as a global
indicator. The baseline AP for random candidate ranking is 14.29%. The best result in each row is highlighted in bold.
</tableCaption>
<bodyText confidence="0.999613875">
(Figure 3.h). On the annotated corpora, where nodes
and collocates are filtered by POS tags, best results
are obtained with the least constrained extraction
method and the chi-squared (X2) measure. Scal-
ing up to the 2-billion-word ukWaC corpus gives
slightly better coverage and precision than on the
BNC. Moreover, X2 is now almost uniformly better
than (or equal to) any other measure (Figure 3.f).
</bodyText>
<figure confidence="0.994474">
● ● ●
●
● ●
●
●
●
● ● ●
● ●
● ●
● ●
●
●
●
●
−4 −2 0 2 4 6
ukWaC (rescaled X2)
</figure>
<figureCaption confidence="0.995374">
Figure 2: Comparison of X2 association scores on ukWaC
and Web1T5. Axes are rescaled logarithmically, preserv-
ing sign to indicate positive vs. negative association.
</figureCaption>
<bodyText confidence="0.999981730769231">
In order to determine whether the poor perfor-
mance of Web1T5 is simply due to the lack of lin-
guistic annotation or whether it points to an intrin-
sic problem of the n-gram database, co-occurrence
data were extracted from an untagged version of the
BNC using the same method as for the Web1T5 data.
While there is a significant decrease in precision (cf.
Figure 3.g and the last row of Table 4), the results
are still considerably better than on Web1T5. In the
MWE 2008 competition, Ramisch et al. (2008) were
also unable to improve on the BNC results using a
phrase entropy measure based on search engine data.
The direct comparison of X2 association scores on
ukWaC and Web1T5 in Figure 2 reveals that the lat-
ter are divided into strongly positive and strongly
negative association, while scores on ukWaC are
spread evenly across the entire range. It is re-
markable that many true positives (TP) exhibit neg-
ative association in Web1T5, while all but a few
show the expected positive association in ukWaC.
This unusual pattern, which may well explain the
poor VPC evaluation results, can also be observed
for adjacent bigrams extracted from the 2-grams ta-
ble (not shown). It suggests a general problem of
the Web1T5 data that is compounded by the quasi-
collocations approach.
</bodyText>
<sectionHeader confidence="0.999371" genericHeader="conclusions">
6 Future work
</sectionHeader>
<bodyText confidence="0.999980714285714">
A new release of Web1T5-Easy is currently in
preparation. It will refactor the Perl code into
reusable and customisable modules that can easily
be embedded in user scripts and adapted to other
databases such as Brants and Franz (2009). We are
looking forward to Web1T5 v2, which promises eas-
ier indexing and much richer interactive queries.
</bodyText>
<figure confidence="0.996624197080292">
● TP
FP
●
●
●
● ●
●
●
●
●
●
●
●●
●
● ●
●
● ● ●
● ● ●
●
●
●
● ● ●
● ●
● ● ● ●
●
●
●
● ●
−5 0 5
Web1T5 (rescaled Xj
●
●
●
●
●
●
●
●
●
●
●
● ●
●
● ●
● ● ●
●
●
●●
●●
●
● ● ● ●
● ●
●
●
● ● ●
● ●
●
●
●
●
38
BNC (bigrams)
0 20 40 60 80 100
Recall (%)
BNC (syntactic pattern)
ukWaC (bigrams)
0 20 40 60 80 100
Recall (%)
ukWaC (syntactic pattern)
t
X2
Dice
f
t
X2
Dice
f
(b)
10 20 30 40 50
Precision (%)
(a) Precision (%) 10 20 30 40 50
(c)
(d)
10 20 30 40 50
10 20 30 40 50
Precision (%)
Precision (%)
t
X2
Dice
f
t
X2
Dice
f
0 20 40 60 80 100
Recall (%)
BNC (span +1,+3)
0 20 40 60 80 100
Recall (%)
BNC untagged (span +1,+3)
0 20 40 60 80 100
Recall (%)
ukWaC (span +1,+3)
0 20 40 60 80 100
Recall (%)
Web1T5 quasi−collocations (span +1,+3)
t
X2
Dice
f
t
X2
Dice
f
(f)
(e) Precision (%) 10 20 30 40 50
10 20 30 40 50
Precision (%)
Precision (%)
10 20 30 40 50
t
X2
Dice
f
(h)
(g)
Precision (%)
10 20 30 40 50
t
X2
Dice
f
0 20 40 60 80 100
Recall (%)
0 20 40 60 80 100
Recall (%)
</figure>
<figureCaption confidence="0.987409">
Figure 3: Evaluation results for English non-compositional VPC (Baldwin, 2008): precision-recall graphs. Rankings
according to the Web1T5 quasi-collocations are shown in the bottom right panel (h). The baseline precision is 14.29%.
</figureCaption>
<page confidence="0.998725">
39
</page>
<sectionHeader confidence="0.995847" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998069270833334">
Guy Aston and Lou Burnard. 1998. The BNC Hand-
book. Edinburgh University Press, Edinburgh. See
also the BNC homepage at http://www.natcorp.
ox.ac.uk/.
Timothy Baldwin. 2008. A resource for evaluating the
deep lexical acquisition of English verb-particle con-
structions. In Proceedings of the LREC Workshop To-
wards a Shared Taskfor Multiword Expressions (MWE
2008), pages 1–2, Marrakech, Morocco.
Marco Baroni, Silvia Bernardini, Adriano Ferraresi, and
Eros Zanchetta. 2009. The WaCky Wide Web: A
collection of very large linguistically processed Web-
crawled corpora. Language Resources and Evalua-
tion, 43(3):209–226.
Thorsten Brants and Alex Franz. 2006. Web 1T 5-gram
Version 1. Linguistic Data Consortium, Philadel-
phia, PA. http://www.ldc.upenn.edu/Catalog/
CatalogEntry.jsp?catalogId=LDC2006T13.
Thorsten Brants and Alex Franz. 2009. Web
1T 5-gram, 10 European Languages Version
1. Linguistic Data Consortium, Philadelphia,
PA. http://www.ldc.upenn.edu/Catalog/
CatalogEntry.jsp?catalogId=LDC2009T25.
James Richard Curran. 2004. From Distributional to Se-
mantic Similarity. Ph.D. thesis, University of Edin-
burgh.
Stefan Evert. 2008. Corpora and collocations. In Anke
Lideling and Merja Kyt¨o, editors, Corpus Linguistics.
An International Handbook, chapter 58. Mouton de
Gruyter, Berlin.
Tobias Hawker, Mary Gardiner, and Andrew Bennetts.
2007. Practical queries of a massive n-gram database.
In Proceedings of the Australasian Language Technol-
ogy Workshop 2007, pages 40–48, Melbourne, Aus-
tralia.
Tom M. Mitchell, Svetlana V. Shinkareva, Andrew Carl-
son, Kai-Min Chang, Vicente L. Malave, Robert A.
Mason, and Marcel Adam Just. 2008. Predicting
human brain activity associated with the meanings of
nouns. Science, 320:1191–1195.
Carlos Ramisch, Paulo Schreiner, Marco Idiart, and Aline
Villavicencio. 2008. An evaluation of methods for
the extraction of multiword expressions. In Proceed-
ings of the LREC Workshop Towards a Shared Task
for Multiword Expressions (MWE 2008), pages 50–53,
Marrakech, Morocco.
John Sinclair. 1991. Corpus, Concordance, Collocation.
Oxford University Press, Oxford.
</reference>
<page confidence="0.998663">
40
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.898224">
<title confidence="0.986997">Google Web 1T 5-Grams Made Easy (but not for the computer)</title>
<author confidence="0.996086">Stefan</author>
<affiliation confidence="0.9997955">Institute of Cognitive University of</affiliation>
<address confidence="0.959247">49069 Osnabr¨uck,</address>
<email confidence="0.995466">stefan.evert@uos.de</email>
<abstract confidence="0.994274">paper introduces a simple indexing solution that allows interactive searches of the Web 1T 5-gram database and a derived database of quasi-collocations. The latter is validated against co-occurrence data from the BNC and ukWaC on the automatic identification of non-compositional VPC.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Guy Aston</author>
<author>Lou Burnard</author>
</authors>
<title>The BNC Handbook.</title>
<date>1998</date>
<publisher>Edinburgh University Press,</publisher>
<location>Edinburgh.</location>
<note>See also the BNC homepage at http://www.natcorp. ox.ac.uk/.</note>
<contexts>
<context position="790" citStr="Aston and Burnard, 1998" startWordPosition="114" endWordPosition="117">@uos.de Abstract This paper introduces Web1T5-Easy, a simple indexing solution that allows interactive searches of the Web 1T 5-gram database and a derived database of quasi-collocations. The latter is validated against co-occurrence data from the BNC and ukWaC on the automatic identification of non-compositional VPC. 1 Introduction The Google Web 1T 5-gram (Web1T5) database (Brants and Franz, 2006) consists of frequency counts for bigram, trigrams, 4-grams and 5-grams extracted from 1 trillion words of English Web text, i.e. from a corpus 10,000 times the size of the British National Corpus (Aston and Burnard, 1998). While primarily designed as a resource to build better language models for machine translation and other NLP applications, its public release in 2006 was greeted with great enthusiasm by many researchers in computational linguistics. As one example, Mitchell et al. (2008) used the Web1T5 data successfully to predict fMRI neural activation associated with concrete noun concepts. For linguistic applications, though, the Web1T5 database presents three major obstacles: (i) The lack of linguistic annotation: Google’s tokenisation splits hyphenated compounds (e.g., parttime is split into a three-t</context>
<context position="21306" citStr="Aston and Burnard, 1998" startWordPosition="3401" endWordPosition="3404"> studies suggest that no single association measure works equally well for all tasks and data sets, several popular measures were included in the evaluation: t-score (t), chi-squared with Yates’ continuity correction (X2), Dice coefficient (Dice), co-occurrence frequency (f), log-likelihood (G2) and Mutual Information (MI); see e.g. Evert (2008) for full equations and references. The results are compared against rankings obtained from more traditional, linguistically 8http://multiword.sf.net/mwe2008/ annotated corpora of British English: the balanced, 100-million-word British National Corpus (Aston and Burnard, 1998) and the 2-billion-word Web corpus ukWaC (Baroni et al., 2009). For BNC and ukWaC, three different extraction methods were used: (i) adjacent bigrams of verb + particle/preposition; (ii) shallow syntactic patterns based on POS tags (allowing pronouns and simple noun phrases between verb and particle); and (iii) surface co-occurrence within a collocational span of 3 tokens to the right of the node (+1,+3), filtered by POS tag. Association scores were calculated using the same measures as for the Web1T5 quasicollocations. Preliminary experiments with different collocational spans showed consiste</context>
</contexts>
<marker>Aston, Burnard, 1998</marker>
<rawString>Guy Aston and Lou Burnard. 1998. The BNC Handbook. Edinburgh University Press, Edinburgh. See also the BNC homepage at http://www.natcorp. ox.ac.uk/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
</authors>
<title>A resource for evaluating the deep lexical acquisition of English verb-particle constructions.</title>
<date>2008</date>
<booktitle>In Proceedings of the LREC Workshop Towards a Shared Taskfor Multiword Expressions (MWE</booktitle>
<pages>1--2</pages>
<location>Marrakech, Morocco.</location>
<contexts>
<context position="20266" citStr="Baldwin, 2008" startWordPosition="3257" endWordPosition="3258">rm disk cache (repeated query). Re-running a query with modified display or ranking settings will only take the time listed in the last column. index, and entries matching the wildcard expression %ly in the first slot are scattered across the entire trigram table. 5 Validation on a MWE extraction task In order to validate the linguistic usefulness of Web1T5 quasi-collocations, they were evaluated on the English VPC shared task from the MWE 2008 workshop.8 This data set consists of 3,078 verb-particle constructions (VPC), which have been manually annotated as compositional or noncompositional (Baldwin, 2008). The task is to identify non-compositional VPC as true positives (TP) and re-rank the data set accordingly. Evaluation is carried out in terms of precision-recall graphs, using average precision (AP, corresponding to the area under a precision-recall curve) as a global measure of accuracy. Frequency data from the Web1T5 quasicollocations table was used to calculate association scores and rankings. Since previous studies suggest that no single association measure works equally well for all tasks and data sets, several popular measures were included in the evaluation: t-score (t), chi-squared w</context>
<context position="23372" citStr="Baldwin, 2008" startWordPosition="3737" endWordPosition="3738">verage precision (%) MI (missing) X2 Dice f G2 BNC (bigrams) 242 30.04 29.75 27.12 26.55 29.86 22.79 BNC (syntactic patterns) 201 30.42 30.49 27.48 25.87 30.64 22.48 BNC (span +1... +3) 185 29.15 32.12 30.13 24.33 31.06 22.58 ukWaC (bigrams) 171 29.28 30.32 27.79 25.37 29.63 25.13 ukWaC (syntactic patterns) 162 29.20 31.19 27.90 24.19 30.06 25.08 ukWaC (span +1... +3) 157 27.82 32.66 30.54 23.03 30.01 25.76 Web1T5 (span +1... + 3) 3 25.83 25.27 25.33 20.88 25.77 20.81 BNC untagged (+1... + 3) 39 27.22 27.85 28.98 22.51 28.13 19.60 Table 4: Evaluation results for English non-compositional VPC (Baldwin, 2008): average precision (AP) as a global indicator. The baseline AP for random candidate ranking is 14.29%. The best result in each row is highlighted in bold. (Figure 3.h). On the annotated corpora, where nodes and collocates are filtered by POS tags, best results are obtained with the least constrained extraction method and the chi-squared (X2) measure. Scaling up to the 2-billion-word ukWaC corpus gives slightly better coverage and precision than on the BNC. Moreover, X2 is now almost uniformly better than (or equal to) any other measure (Figure 3.f). ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●</context>
</contexts>
<marker>Baldwin, 2008</marker>
<rawString>Timothy Baldwin. 2008. A resource for evaluating the deep lexical acquisition of English verb-particle constructions. In Proceedings of the LREC Workshop Towards a Shared Taskfor Multiword Expressions (MWE 2008), pages 1–2, Marrakech, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Silvia Bernardini</author>
<author>Adriano Ferraresi</author>
<author>Eros Zanchetta</author>
</authors>
<title>The WaCky Wide Web: A collection of very large linguistically processed Webcrawled corpora. Language Resources and Evaluation,</title>
<date>2009</date>
<pages>43--3</pages>
<contexts>
<context position="21368" citStr="Baroni et al., 2009" startWordPosition="3411" endWordPosition="3414">well for all tasks and data sets, several popular measures were included in the evaluation: t-score (t), chi-squared with Yates’ continuity correction (X2), Dice coefficient (Dice), co-occurrence frequency (f), log-likelihood (G2) and Mutual Information (MI); see e.g. Evert (2008) for full equations and references. The results are compared against rankings obtained from more traditional, linguistically 8http://multiword.sf.net/mwe2008/ annotated corpora of British English: the balanced, 100-million-word British National Corpus (Aston and Burnard, 1998) and the 2-billion-word Web corpus ukWaC (Baroni et al., 2009). For BNC and ukWaC, three different extraction methods were used: (i) adjacent bigrams of verb + particle/preposition; (ii) shallow syntactic patterns based on POS tags (allowing pronouns and simple noun phrases between verb and particle); and (iii) surface co-occurrence within a collocational span of 3 tokens to the right of the node (+1,+3), filtered by POS tag. Association scores were calculated using the same measures as for the Web1T5 quasicollocations. Preliminary experiments with different collocational spans showed consistently lower accuracy than for (+1,+3). In each case, the same a</context>
</contexts>
<marker>Baroni, Bernardini, Ferraresi, Zanchetta, 2009</marker>
<rawString>Marco Baroni, Silvia Bernardini, Adriano Ferraresi, and Eros Zanchetta. 2009. The WaCky Wide Web: A collection of very large linguistically processed Webcrawled corpora. Language Resources and Evaluation, 43(3):209–226.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
<author>Alex Franz</author>
</authors>
<date>2006</date>
<booktitle>Web 1T 5-gram Version 1. Linguistic Data Consortium,</booktitle>
<location>Philadelphia, PA.</location>
<note>http://www.ldc.upenn.edu/Catalog/ CatalogEntry.jsp?catalogId=LDC2006T13.</note>
<marker>Brants, Franz, 2006</marker>
<rawString>Thorsten Brants and Alex Franz. 2006. Web 1T 5-gram Version 1. Linguistic Data Consortium, Philadelphia, PA. http://www.ldc.upenn.edu/Catalog/ CatalogEntry.jsp?catalogId=LDC2006T13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
<author>Alex Franz</author>
</authors>
<title>Web 1T 5-gram, 10 European Languages Version 1. Linguistic Data Consortium,</title>
<date>2009</date>
<location>Philadelphia, PA.</location>
<note>http://www.ldc.upenn.edu/Catalog/ CatalogEntry.jsp?catalogId=LDC2009T25.</note>
<contexts>
<context position="25693" citStr="Brants and Franz (2009)" startWordPosition="4141" endWordPosition="4144">ibit negative association in Web1T5, while all but a few show the expected positive association in ukWaC. This unusual pattern, which may well explain the poor VPC evaluation results, can also be observed for adjacent bigrams extracted from the 2-grams table (not shown). It suggests a general problem of the Web1T5 data that is compounded by the quasicollocations approach. 6 Future work A new release of Web1T5-Easy is currently in preparation. It will refactor the Perl code into reusable and customisable modules that can easily be embedded in user scripts and adapted to other databases such as Brants and Franz (2009). We are looking forward to Web1T5 v2, which promises easier indexing and much richer interactive queries. ● TP FP ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● −5 0 5 Web1T5 (rescaled Xj ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● 38 BNC (bigrams) 0 20 40 60 80 100 Recall (%) BNC (syntactic pattern) ukWaC (bigrams) 0 20 40 60 80 100 Recall (%) ukWaC (syntactic pattern) t X2 Dice f t X2 Dice f (b) 10 20 30 40 50 Precision (%) (a) Precision (%) 10 20 30 40 50 (c) (d) 10 20 30 40 50 10 20 30 40 50 Precision (%) Precision (%</context>
</contexts>
<marker>Brants, Franz, 2009</marker>
<rawString>Thorsten Brants and Alex Franz. 2009. Web 1T 5-gram, 10 European Languages Version 1. Linguistic Data Consortium, Philadelphia, PA. http://www.ldc.upenn.edu/Catalog/ CatalogEntry.jsp?catalogId=LDC2009T25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Richard Curran</author>
</authors>
<title>From Distributional to Semantic Similarity.</title>
<date>2004</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="15212" citStr="Curran (2004" startWordPosition="2420" endWordPosition="2421">d side of the table, the distribution across collocate positions is visualised. In computational linguistics, collocations play an important role as the term-term co-occurrence matrix underlying distributional semantic models 35 size (GiB) database file no. of rows 0.23 vocabulary 5,787,556 7.24 2-grams 153,634,491 32.81 3-grams 594,453,302 64.32 4-grams 933,385,623 75.09 5-grams 909,734,581 31.73 collocations 494,138,116 211.42 total 3,091,133,669 Table 2: Size of the fully indexed Web1T5 database, including quasi-collocations. (DSM), with association scores used as feature weights (see e.g. Curran (2004, Sec. 4.3)). The Web1T5-Easy quasi-collocations table provides a sparse representation of such a term-term matrix, where only 494 x 106 or 0.0015% of the 5.8 x 106 � 5.8x106 = 33.5x1012 cells of a full co-occurrence matrix are populated with nonzero entries. 4 Technical aspects An essential feature of Web1T5-Easy is the numeric coding of words in the n-gram tables, which allows for compact storage and more efficient indexing of the data than a full character string representation. A separate lexicon table lists every (normalised) word form together with its corpus frequency and an integer ID.</context>
</contexts>
<marker>Curran, 2004</marker>
<rawString>James Richard Curran. 2004. From Distributional to Semantic Similarity. Ph.D. thesis, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Evert</author>
</authors>
<title>Corpora and collocations.</title>
<date>2008</date>
<booktitle>In Anke Lideling and Merja Kyt¨o, editors, Corpus Linguistics. An International Handbook, chapter 58. Mouton de Gruyter,</booktitle>
<location>Berlin.</location>
<contexts>
<context position="10543" citStr="Evert (2008)" startWordPosition="1674" endWordPosition="1675">onsists of 2–5 search terms separated by blanks. Each search term is either a literal word (e.g. sit), a set of words in square brackets (e.g. [sit,sits,sat,sitting]), aprefix (under%) or suffix (%ation) expression, * for an arbitrary word, or ? to skip a word. The difference between the latter two is that positions marked by * are included in the query result, while those marked by ? are not. If a query term cannot match because of normalisation, an informative error message is shown. Matches can be ranked by frequency or by association scores, according to one of the measures recommended by Evert (2008): t-score (t), log-likelihood (G2), chi-squared with Yates’ correction (X2), pointwise MI, or a version of the Dice coefficient. For example, the query web as corpus shows that the trigram Web as Corpus occurs 1,104 times in the Google corpus (case-insensitive). %ly good fun lists ways of having fun such as really good fun (12,223x), jolly good fun (3,730x) and extremely good fun (2,788x). The query [sit,sits,sat,sitting] * ? chair returns the patterns SIT in ... chair (201,084x), SIT on ... chair (61,901x), SIT at ... chair (1,173x), etc. Corpus frequencies are automatically summed over all f</context>
<context position="21029" citStr="Evert (2008)" startWordPosition="3370" endWordPosition="3371">ision-recall graphs, using average precision (AP, corresponding to the area under a precision-recall curve) as a global measure of accuracy. Frequency data from the Web1T5 quasicollocations table was used to calculate association scores and rankings. Since previous studies suggest that no single association measure works equally well for all tasks and data sets, several popular measures were included in the evaluation: t-score (t), chi-squared with Yates’ continuity correction (X2), Dice coefficient (Dice), co-occurrence frequency (f), log-likelihood (G2) and Mutual Information (MI); see e.g. Evert (2008) for full equations and references. The results are compared against rankings obtained from more traditional, linguistically 8http://multiword.sf.net/mwe2008/ annotated corpora of British English: the balanced, 100-million-word British National Corpus (Aston and Burnard, 1998) and the 2-billion-word Web corpus ukWaC (Baroni et al., 2009). For BNC and ukWaC, three different extraction methods were used: (i) adjacent bigrams of verb + particle/preposition; (ii) shallow syntactic patterns based on POS tags (allowing pronouns and simple noun phrases between verb and particle); and (iii) surface co</context>
</contexts>
<marker>Evert, 2008</marker>
<rawString>Stefan Evert. 2008. Corpora and collocations. In Anke Lideling and Merja Kyt¨o, editors, Corpus Linguistics. An International Handbook, chapter 58. Mouton de Gruyter, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tobias Hawker</author>
<author>Mary Gardiner</author>
<author>Andrew Bennetts</author>
</authors>
<title>Practical queries of a massive n-gram database.</title>
<date>2007</date>
<booktitle>In Proceedings of the Australasian Language Technology Workshop</booktitle>
<pages>40--48</pages>
<location>Melbourne, Australia.</location>
<contexts>
<context position="3132" citStr="Hawker et al. (2007)" startWordPosition="478" endWordPosition="481"> can be restricted to a single file containing 50–90 MiB of compressed text – every query requires a linear scan of the full database. This paper presents a simple open-source software solution to the third problem, called Web1T5- Easy. The n-gram data are encoded and indexed in a relational database. Building on convenient open-source tools such as SQLite and Perl, the software aims to strike a good balance between search efficiency and ease of use and implementation. With its focus on interactive, but accurate search it complements the approximate indexing and batch processing approaches of Hawker et al. (2007). Web1T5-Easy can be downloaded from http://webascorpus.sf.net/Web1T5-Easy/.1 1An online demo of the complete Web1T5 database is available at http://cogsci.uos.de/~korpora/ws/Web1T5/. Proceedings of the NAACL HLT 2010 Sixth Web as Corpus Workshop, pages 32–40, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics word 1 word 2 word 3 f supplement depend on 193 supplement depending on 174 supplement depends entirely 94 supplement depends on 338 supplement derived from 2668 supplement des coups 77 supplement described in 200 Table 1: Example of Web1T5 3-gram freque</context>
</contexts>
<marker>Hawker, Gardiner, Bennetts, 2007</marker>
<rawString>Tobias Hawker, Mary Gardiner, and Andrew Bennetts. 2007. Practical queries of a massive n-gram database. In Proceedings of the Australasian Language Technology Workshop 2007, pages 40–48, Melbourne, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom M Mitchell</author>
<author>Svetlana V Shinkareva</author>
<author>Andrew Carlson</author>
<author>Kai-Min Chang</author>
<author>Vicente L Malave</author>
<author>Robert A Mason</author>
<author>Marcel Adam Just</author>
</authors>
<title>Predicting human brain activity associated with the meanings of nouns.</title>
<date>2008</date>
<journal>Science,</journal>
<pages>320--1191</pages>
<contexts>
<context position="1064" citStr="Mitchell et al. (2008)" startWordPosition="157" endWordPosition="160">ic identification of non-compositional VPC. 1 Introduction The Google Web 1T 5-gram (Web1T5) database (Brants and Franz, 2006) consists of frequency counts for bigram, trigrams, 4-grams and 5-grams extracted from 1 trillion words of English Web text, i.e. from a corpus 10,000 times the size of the British National Corpus (Aston and Burnard, 1998). While primarily designed as a resource to build better language models for machine translation and other NLP applications, its public release in 2006 was greeted with great enthusiasm by many researchers in computational linguistics. As one example, Mitchell et al. (2008) used the Web1T5 data successfully to predict fMRI neural activation associated with concrete noun concepts. For linguistic applications, though, the Web1T5 database presents three major obstacles: (i) The lack of linguistic annotation: Google’s tokenisation splits hyphenated compounds (e.g., parttime is split into a three-token sequence part�-Mime) and differs in many other ways from the rules used in liguistic corpora. The n-grams are neither annotated with part-of-speech tags nor lemmatised, and there are separate entries for sentence-initial uppercase and the corresponding lowercase forms.</context>
</contexts>
<marker>Mitchell, Shinkareva, Carlson, Chang, Malave, Mason, Just, 2008</marker>
<rawString>Tom M. Mitchell, Svetlana V. Shinkareva, Andrew Carlson, Kai-Min Chang, Vicente L. Malave, Robert A. Mason, and Marcel Adam Just. 2008. Predicting human brain activity associated with the meanings of nouns. Science, 320:1191–1195.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlos Ramisch</author>
<author>Paulo Schreiner</author>
<author>Marco Idiart</author>
<author>Aline Villavicencio</author>
</authors>
<title>An evaluation of methods for the extraction of multiword expressions.</title>
<date>2008</date>
<booktitle>In Proceedings of the LREC Workshop Towards a Shared Task for Multiword Expressions (MWE</booktitle>
<pages>50--53</pages>
<location>Marrakech, Morocco.</location>
<contexts>
<context position="24674" citStr="Ramisch et al. (2008)" startWordPosition="3970" endWordPosition="3973">on ukWaC and Web1T5. Axes are rescaled logarithmically, preserving sign to indicate positive vs. negative association. In order to determine whether the poor performance of Web1T5 is simply due to the lack of linguistic annotation or whether it points to an intrinsic problem of the n-gram database, co-occurrence data were extracted from an untagged version of the BNC using the same method as for the Web1T5 data. While there is a significant decrease in precision (cf. Figure 3.g and the last row of Table 4), the results are still considerably better than on Web1T5. In the MWE 2008 competition, Ramisch et al. (2008) were also unable to improve on the BNC results using a phrase entropy measure based on search engine data. The direct comparison of X2 association scores on ukWaC and Web1T5 in Figure 2 reveals that the latter are divided into strongly positive and strongly negative association, while scores on ukWaC are spread evenly across the entire range. It is remarkable that many true positives (TP) exhibit negative association in Web1T5, while all but a few show the expected positive association in ukWaC. This unusual pattern, which may well explain the poor VPC evaluation results, can also be observed</context>
</contexts>
<marker>Ramisch, Schreiner, Idiart, Villavicencio, 2008</marker>
<rawString>Carlos Ramisch, Paulo Schreiner, Marco Idiart, and Aline Villavicencio. 2008. An evaluation of methods for the extraction of multiword expressions. In Proceedings of the LREC Workshop Towards a Shared Task for Multiword Expressions (MWE 2008), pages 50–53, Marrakech, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Sinclair</author>
</authors>
<title>Corpus, Concordance, Collocation.</title>
<date>1991</date>
<publisher>Oxford University Press,</publisher>
<location>Oxford.</location>
<contexts>
<context position="11584" citStr="Sinclair (1991)" startWordPosition="1845" endWordPosition="1846">* ? chair returns the patterns SIT in ... chair (201,084x), SIT on ... chair (61,901x), SIT at ... chair (1,173x), etc. Corpus frequencies are automatically summed over all fillers in the third slot. The query implementation is available as a command-line version and as a CGI script that provides a Web-based GUI to the Web1T5-Easy database. The CGI version also offers CSV and XML output formats for use as a Web service. 3 Quasi-collocations and DSM Many corpus linguists and lexicographers will particularly be interested in using the Web1T5 database as a source of collocations (in the sense of Sinclair (1991)). While the British National Corpus at best provides sufficient data for a collocational analysis of some 50,000 words (taking f &gt; 50 to be the minimum corpus frequency necessary), Web1T5 offers comprehensive collocation data for almost 500,000 34 Figure 1: Quasi-collocations for the node word corpus in the Web GUI of Web1T5-Easy. words (which have at least 50 different collocates in the database, and f &gt; 10,000 in the original Google corpus). Unfortunately, the Web1T5 distribution does not include co-occurrence frequencies of word pairs, except for data on immediately adjacent bigrams. It is</context>
</contexts>
<marker>Sinclair, 1991</marker>
<rawString>John Sinclair. 1991. Corpus, Concordance, Collocation. Oxford University Press, Oxford.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>