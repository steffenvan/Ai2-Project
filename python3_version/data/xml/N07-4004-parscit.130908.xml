<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.126821">
<title confidence="0.98176">
POSSLT: A Korean to English Spoken Language Translation System
</title>
<author confidence="0.996865">
Donghyeon Lee, Jonghoon Lee, Gary Geunbae Lee
</author>
<affiliation confidence="0.9999725">
Department of Computer Science and Engineering
Pohang University of Science &amp; Technology (POSTECH)
</affiliation>
<address confidence="0.93807">
San 31, Hyoja-Dong, Pohang, 790-784, Republic of Korea
</address>
<email confidence="0.998459">
{semko, jh21983, gblee}@postech.ac.kr
</email>
<sectionHeader confidence="0.995644" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999260454545454">
The POSSLT 1 is a Korean to English
spoken language translation (SLT) system.
Like most other SLT systems, automatic
speech recognition (ASR), machine trans-
lation (MT), and text-to-speech (TTS) are
coupled in a cascading manner in our
POSSLT. However, several novel tech-
niques are applied to improve overall
translation quality and speed. Models
used in POSSLT are trained on a travel
domain conversational corpus.
</bodyText>
<sectionHeader confidence="0.998994" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9986639375">
Spoken language translation (SLT) has become
more important due to globalization. SLT systems
consist of three major components: automatic
speech recognition (ASR), statistical machine
translation (SMT), text-to-speech (TTS). Currently,
most of SLT systems are developed in a cascading
method. Simple SLT systems translate a single best
recognizer output, but, translation quality can be
improved using the N-best hypotheses or lattice
provided by the ASR (Zhang et. al., 2004; Saleem
et. al., 2004).
In POSSLT, we used an N-best hypothesis re-
ranking based on both ASR and SMT features, and
divided the language model of the ASR according
to the specific domain situation. To improve the
Korean-English SMT quality, several new tech-
</bodyText>
<footnote confidence="0.9637615">
1 POSSLT stands for POSTECH Spoken Language Transla-
tion system
</footnote>
<bodyText confidence="0.981485333333333">
niques can be applied (Lee et. al., 2006-b). The
POSSLT applies most of these techniques using a
preprocessor.
</bodyText>
<sectionHeader confidence="0.974681" genericHeader="introduction">
2 System Description
</sectionHeader>
<bodyText confidence="0.999338666666667">
The POSSLT was developed by integrating ASR,
SMT, and TTS. The system has a pipelined archi-
tecture as shown in Fig. 1. LM loader, preproces-
sor and re-ranking module are newly developed to
improve the translation quality and speed for
POSSLT.
</bodyText>
<figureCaption confidence="0.997602">
Figure 1: Overview of POSSLT
</figureCaption>
<subsectionHeader confidence="0.891874">
2.1 ASR
</subsectionHeader>
<bodyText confidence="0.999933571428571">
The system used HTK-based continuous speech
recognition engine properly trained for Korean.
The acoustic model, lexical model and language
model of Korean are trained for conversational
corpus. The phonetic set for Korean has 48 pho-
neme-like-units, and we used three-state tri-phone
hidden Markov models and trigram language mod-
</bodyText>
<page confidence="0.993706">
7
</page>
<author confidence="0.236924">
NAACL HLT Demonstration Program, pages 7–8,
</author>
<affiliation confidence="0.732343">
Rochester, New York, USA, April 2007. c�2007 Association for Computational Linguistics
</affiliation>
<bodyText confidence="0.997825666666667">
els. Pronunciation lexicons are automatically built
by a Korean grapheme-to-phoneme (G2P) tool
(Lee et. al., 2006-a). We used an eojeol2 as a basic
recognition unit for lexical and language models,
because an eojeol-based recognition unit has the
higher accuracy than the morpheme-based one.
The ASR produces the N-best hypotheses deter-
mined through the decoding process, which are
used as the input of SMT.
</bodyText>
<subsectionHeader confidence="0.977856">
2.2 SMT
</subsectionHeader>
<bodyText confidence="0.999933777777778">
We implemented a Korean-English phrase-based
SMT decoder based on Pharaoh (Koehn, 2004).
The decoder needs a phrase translation model for
the Korean-English pair and a language model for
English. We used the Pharaoh training module and
GIZA++ (Och and Ney, 2000) to construct the
phrase translation table. For language modeling,
SRILM toolkit (Stolcke, 2002) was used to build a
trigram language model.
</bodyText>
<subsectionHeader confidence="0.965709">
2.3 TTS
</subsectionHeader>
<bodyText confidence="0.999261666666667">
We used Microsoft SAPI 5.1 TTS engine for Eng-
lish TTS. The final best translation is pronounced
using the engine.
</bodyText>
<subsectionHeader confidence="0.994558">
2.4 LM Loader
</subsectionHeader>
<bodyText confidence="0.999996">
In cascading SLT systems, SMT coverage depends
on the used ASR. In order to increase the ASR
coverage, our system loads and unloads the ASR
language models dynamically. In our system which
uses a travel corpus, language models are built for
ten domain situation categories such as an airport,
a hotel, a shopping, etc. Besides user utterances,
user selection of the situation is needed as an input
to decide which language model have to be loaded
in advance. By using the divided language models,
many benefits such as fast decoding, higher accu-
racy and more coverage can be obtained.
</bodyText>
<subsectionHeader confidence="0.95855">
2.5 Preprocessor
</subsectionHeader>
<bodyText confidence="0.9940041875">
In the Korean-English SMT task, there have been
developed several techniques for improving the
translation quality such as changing spacing units
into morphemes, adding POS tag information, and
deleting useless words (Lee et. al., 2006-b).
2 Eojeol is a spacing unit in Korean and typically consists of
more than one morpheme.
However, for these techniques, Part-Of-Speech
(POS) tagger is needed. If the final analyzed form
of an eojeol (in the form of a sequence of mor-
phemes plus POS tags) is defined as a word in the
ASR lexicon, the transformed sentences are direct-
ly generated by the ASR only, so POS tagger er-
rors can be removed from the system. Preprocessor
also removes useless words in SMT in the trans-
formed sentences produced by the ASR.
</bodyText>
<subsectionHeader confidence="0.992728">
2.6 Re-ranking Module
</subsectionHeader>
<bodyText confidence="0.999960142857143">
We implemented a re-ranking module to make a
robust SLT system against the speech recognition
errors. The re-ranking module uses several fea-
tures: ASR acoustic model scores, ASR language
model scores, and SMT translation scores. Finally,
the re-ranking module sorts the N-best lists by
comparing the total scores.
</bodyText>
<sectionHeader confidence="0.997018" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.932280333333333">
This research was supported by the MIC (Ministry of
Information and Communication), Korea, under the
ITRC (Information Technology Research Center) sup-
port program supervised by the IITA (Institute of In-
formation Technology Assessment; IITA-2005-C1090-
0501-0018)
</bodyText>
<sectionHeader confidence="0.997909" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998360869565217">
A. Stolcke. 2002. SRILM – An Extensible Language Modeling
Toolkit. Proc. of ICSLP.
F. J. Och and H. Ney. 2000. Improved statistical alignment
models. Proc. of 38th Annual Meeting of the ACL, page
440-447, Hongkong, China, October 2000.
Jinsik Lee, Seungwon Kim, Gary Geunbae Lee. 2006-a. Gra-
pheme-to-Phoneme Conversion Using Automatically Ex-
tracted Associative Rules for Korean TTS System. Proc. of
Interspeech-ICSLP.
Jonghoon Lee, Donghyeon Lee, Gary Geunbae Lee. 2006-b.
Improving Phrase-based Korean-English Statistical Ma-
chine Translation. Proc. of Interspeech-ICSLP.
P. Koehn. 2004. Pharaoh: A Beam Search Decoder for
Phrase-based Statistical Machine Translation Models.
Proc. of AMTA, Washington DC.
R. Zhang, G. Kikui, H. Yamamoto, T. Watanabe, F. Soong,
and W. K. Lo. 2004. A unified approach in speech-to-
speech translation: Integrating features of speech recogni-
tion and machine translation. Proc. of Coling 2004, Geve-
va.
S. Saleem, S. Chen Jou, S. Vogel, and T.Schultz. 2004. Using
word lattice information for a tighter coupling in speech
translation systems. Proc. of ICSLP 2004, Jeju, Korea.
</reference>
<page confidence="0.998486">
8
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.888298">
<title confidence="0.999948">POSSLT: A Korean to English Spoken Language Translation System</title>
<author confidence="0.999027">Donghyeon Lee</author>
<author confidence="0.999027">Jonghoon Lee</author>
<author confidence="0.999027">Gary Geunbae Lee</author>
<affiliation confidence="0.9999375">Department of Computer Science and Pohang University of Science &amp; Technology</affiliation>
<address confidence="0.998129">San 31, Hyoja-Dong, Pohang, 790-784, Republic of</address>
<email confidence="0.915113">semko@postech.ac.kr</email>
<email confidence="0.915113">jh21983@postech.ac.kr</email>
<email confidence="0.915113">gblee@postech.ac.kr</email>
<abstract confidence="0.997679083333333">POSSLT 1is a Korean to English spoken language translation (SLT) system. Like most other SLT systems, automatic speech recognition (ASR), machine translation (MT), and text-to-speech (TTS) are coupled in a cascading manner in our POSSLT. However, several novel techniques are applied to improve overall translation quality and speed. Models used in POSSLT are trained on a travel domain conversational corpus.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Stolcke</author>
</authors>
<title>SRILM – An Extensible Language Modeling Toolkit.</title>
<date>2002</date>
<booktitle>Proc. of ICSLP.</booktitle>
<contexts>
<context position="3181" citStr="Stolcke, 2002" startWordPosition="480" endWordPosition="481">unit for lexical and language models, because an eojeol-based recognition unit has the higher accuracy than the morpheme-based one. The ASR produces the N-best hypotheses determined through the decoding process, which are used as the input of SMT. 2.2 SMT We implemented a Korean-English phrase-based SMT decoder based on Pharaoh (Koehn, 2004). The decoder needs a phrase translation model for the Korean-English pair and a language model for English. We used the Pharaoh training module and GIZA++ (Och and Ney, 2000) to construct the phrase translation table. For language modeling, SRILM toolkit (Stolcke, 2002) was used to build a trigram language model. 2.3 TTS We used Microsoft SAPI 5.1 TTS engine for English TTS. The final best translation is pronounced using the engine. 2.4 LM Loader In cascading SLT systems, SMT coverage depends on the used ASR. In order to increase the ASR coverage, our system loads and unloads the ASR language models dynamically. In our system which uses a travel corpus, language models are built for ten domain situation categories such as an airport, a hotel, a shopping, etc. Besides user utterances, user selection of the situation is needed as an input to decide which langu</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>A. Stolcke. 2002. SRILM – An Extensible Language Modeling Toolkit. Proc. of ICSLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>Improved statistical alignment models.</title>
<date>2000</date>
<booktitle>Proc. of 38th Annual Meeting of the ACL,</booktitle>
<pages>440--447</pages>
<location>Hongkong, China,</location>
<contexts>
<context position="3085" citStr="Och and Ney, 2000" startWordPosition="465" endWordPosition="468">ean grapheme-to-phoneme (G2P) tool (Lee et. al., 2006-a). We used an eojeol2 as a basic recognition unit for lexical and language models, because an eojeol-based recognition unit has the higher accuracy than the morpheme-based one. The ASR produces the N-best hypotheses determined through the decoding process, which are used as the input of SMT. 2.2 SMT We implemented a Korean-English phrase-based SMT decoder based on Pharaoh (Koehn, 2004). The decoder needs a phrase translation model for the Korean-English pair and a language model for English. We used the Pharaoh training module and GIZA++ (Och and Ney, 2000) to construct the phrase translation table. For language modeling, SRILM toolkit (Stolcke, 2002) was used to build a trigram language model. 2.3 TTS We used Microsoft SAPI 5.1 TTS engine for English TTS. The final best translation is pronounced using the engine. 2.4 LM Loader In cascading SLT systems, SMT coverage depends on the used ASR. In order to increase the ASR coverage, our system loads and unloads the ASR language models dynamically. In our system which uses a travel corpus, language models are built for ten domain situation categories such as an airport, a hotel, a shopping, etc. Besi</context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>F. J. Och and H. Ney. 2000. Improved statistical alignment models. Proc. of 38th Annual Meeting of the ACL, page 440-447, Hongkong, China, October 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinsik Lee</author>
<author>Seungwon Kim</author>
<author>Gary Geunbae Lee</author>
</authors>
<title>Grapheme-to-Phoneme Conversion Using Automatically Extracted Associative Rules for Korean TTS System.</title>
<date>2006</date>
<booktitle>Proc. of Interspeech-ICSLP.</booktitle>
<marker>Lee, Kim, Lee, 2006</marker>
<rawString>Jinsik Lee, Seungwon Kim, Gary Geunbae Lee. 2006-a. Grapheme-to-Phoneme Conversion Using Automatically Extracted Associative Rules for Korean TTS System. Proc. of Interspeech-ICSLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonghoon Lee</author>
<author>Donghyeon Lee</author>
<author>Gary Geunbae Lee</author>
</authors>
<title>Improving Phrase-based Korean-English Statistical Machine Translation.</title>
<date>2006</date>
<booktitle>Proc. of Interspeech-ICSLP.</booktitle>
<marker>Lee, Lee, Lee, 2006</marker>
<rawString>Jonghoon Lee, Donghyeon Lee, Gary Geunbae Lee. 2006-b. Improving Phrase-based Korean-English Statistical Machine Translation. Proc. of Interspeech-ICSLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Pharaoh: A Beam Search Decoder for Phrase-based Statistical Machine Translation Models.</title>
<date>2004</date>
<booktitle>Proc. of AMTA,</booktitle>
<location>Washington DC.</location>
<contexts>
<context position="2910" citStr="Koehn, 2004" startWordPosition="438" endWordPosition="439">n Program, pages 7–8, Rochester, New York, USA, April 2007. c�2007 Association for Computational Linguistics els. Pronunciation lexicons are automatically built by a Korean grapheme-to-phoneme (G2P) tool (Lee et. al., 2006-a). We used an eojeol2 as a basic recognition unit for lexical and language models, because an eojeol-based recognition unit has the higher accuracy than the morpheme-based one. The ASR produces the N-best hypotheses determined through the decoding process, which are used as the input of SMT. 2.2 SMT We implemented a Korean-English phrase-based SMT decoder based on Pharaoh (Koehn, 2004). The decoder needs a phrase translation model for the Korean-English pair and a language model for English. We used the Pharaoh training module and GIZA++ (Och and Ney, 2000) to construct the phrase translation table. For language modeling, SRILM toolkit (Stolcke, 2002) was used to build a trigram language model. 2.3 TTS We used Microsoft SAPI 5.1 TTS engine for English TTS. The final best translation is pronounced using the engine. 2.4 LM Loader In cascading SLT systems, SMT coverage depends on the used ASR. In order to increase the ASR coverage, our system loads and unloads the ASR language</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>P. Koehn. 2004. Pharaoh: A Beam Search Decoder for Phrase-based Statistical Machine Translation Models. Proc. of AMTA, Washington DC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Zhang</author>
<author>G Kikui</author>
<author>H Yamamoto</author>
<author>T Watanabe</author>
<author>F Soong</author>
<author>W K Lo</author>
</authors>
<title>A unified approach in speech-tospeech translation: Integrating features of speech recognition and machine translation.</title>
<date>2004</date>
<booktitle>Proc. of Coling</booktitle>
<location>Geveva.</location>
<marker>Zhang, Kikui, Yamamoto, Watanabe, Soong, Lo, 2004</marker>
<rawString>R. Zhang, G. Kikui, H. Yamamoto, T. Watanabe, F. Soong, and W. K. Lo. 2004. A unified approach in speech-tospeech translation: Integrating features of speech recognition and machine translation. Proc. of Coling 2004, Geveva.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Saleem</author>
<author>S Chen Jou</author>
<author>S Vogel</author>
<author>T Schultz</author>
</authors>
<title>Using word lattice information for a tighter coupling in speech translation systems.</title>
<date>2004</date>
<booktitle>Proc. of ICSLP</booktitle>
<location>Jeju,</location>
<marker>Saleem, Jou, Vogel, Schultz, 2004</marker>
<rawString>S. Saleem, S. Chen Jou, S. Vogel, and T.Schultz. 2004. Using word lattice information for a tighter coupling in speech translation systems. Proc. of ICSLP 2004, Jeju, Korea.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>