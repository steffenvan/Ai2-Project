<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000008">
<title confidence="0.9919805">
Unsupervised morphological segmentation and clustering with document
boundaries
</title>
<author confidence="0.999021">
Taesun Moon, Katrin Erk, and Jason Baldridge
</author>
<affiliation confidence="0.993296666666667">
Department of Linguistics
University of Texas at Austin
1 University Station B5100
</affiliation>
<address confidence="0.641679">
Austin, TX 78712-0198 USA
</address>
<email confidence="0.999145">
{tsmoon,katrin.erk,jbaldrid}@mail.utexas.edu
</email>
<sectionHeader confidence="0.993903" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99984795">
Many approaches to unsupervised mor-
phology acquisition incorporate the fre-
quency of character sequences with re-
spect to each other to identify word stems
and affixes. This typically involves heuris-
tic search procedures and calibrating mul-
tiple arbitrary thresholds. We present a
simple approach that uses no thresholds
other than those involved in standard ap-
plication of χ2 significance testing. A
key part of our approach is using docu-
ment boundaries to constrain generation of
candidate stems and affixes and clustering
morphological variants of a given word
stem. We evaluate our model on English
and the Mayan language Uspanteko; it
compares favorably to two benchmark sys-
tems which use considerably more com-
plex strategies and rely more on experi-
mentally chosen threshold values.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999948224137931">
Unsupervised morphology acquisition attempts to
learn from raw corpora one or more of the follow-
ing about the written morphology of a language:
(1) the segmentation of the set of word types in a
corpus (Creutz and Lagus, 2007), (2) the cluster-
ing of word types in a corpus based on some notion
of morphological relatedness (Schone and Juraf-
sky, 2000), (3) the generation of out-of-vocabulary
items which are morphologically related to other
word types in the corpus (Yarowsky et al., 2001).
We take a novel approach to segmenting words
and clustering morphologically related words.
The approach uses no parameters that need to
be tuned on data. The two main ideas of the
approach are (a) the filtering of affixes by sig-
nificant co-occurrence, and (b) the integration of
knowledge of document boundaries when gener-
ating candidate stems and affixes and when clus-
tering morphologically related words. The main
application that we envision for our approach is
to produce interlinearized glossed texts for under-
resourced/endangered languages (Palmer et al.,
2009). Thus, we strive to eliminate hand-tuned
parameters to enable documentary linguists to use
our model as a preprocessing step for their manual
analysis of stems and affixes. To require a docu-
mentary linguist–who is likely to have little to no
knowledge of NLP methods–to tune parameters is
unfeasible. Additionally, data-driven exploration
of parameter settings is unlikely to be reliable in
language documentation since datasets typically
are quite small. To be relevant in this context, a
model needs to produce useful results out of the
box.
Constraining learning by using document
boundaries has been used quite effectively in un-
supervised word sense disambiguation (Yarowsky,
1995). Many applications in information retrieval
are built on the statistical correlation between doc-
uments and terms. However, we are unaware of
cases where knowledge of document boundaries
has been used for unsupervised learning for mor-
phology. The intuition behind our approach is very
simple: if two words in a single document are
very similar in terms of orthography, then the two
words are likely to be related morphologically. We
measure how integrating these assumptions into
our model at different stages affects performance.
We define a simple pipeline model. After gen-
erating candidate stems and affixes (possibly con-
strained by document boundaries), a χ2 test based
on global corpus counts filters out unlikely affixes.
Mutually consistent affix pairs are then clustered
to form affix groups. These in turn are used to
build morphologically related word clusters, pos-
sibly constrained by evidence from co-occurence
of word forms in documents. Following Schone
and Jurafsky (2000), clusters are evaluated for
</bodyText>
<page confidence="0.985766">
668
</page>
<note confidence="0.9966165">
Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 668–677,
Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.9998497">
whether they capture inflectional paradigms using
CELEX (Baayen et al., 1993).
We are unaware of other work on morphology
using χ2 tests despite its wide application across
many disciplines.1 This may be due to the large
degree of noise found in the candidate affix sets
induced through other candidate generation meth-
ods. The χ2 test has two standard thresholds–a
significance threshold and a lower bound on ob-
served counts. These are the only manually set
parameters we require—and we in fact use the
widely accepted standard values for these thresh-
olds without varying them in our experiments.
This is a significant improvement over other ap-
proaches that typically require a number of arbi-
trary thresholds and parameters yet provide little
intuitive justification for them. (We give examples
of these in §3.)
We evaluate our approach on two languages,
English and Uspanteko, and compare its per-
formance to two benchmark systems, Morfessor
(Creutz and Lagus, 2007) and Linguistica (Gold-
smith, 2001). English is commonly used in other
studies and permits the use of CELEX as a gold
standard for evaluation. Uspanteko is an endan-
gered Mayan language for which we have a set of
interlinearized glossed texts (IGT) (Pixabaj et al.,
2007; Palmer et al., 2009). IGT provides word-
by-word morpheme segmenation, which we use
to create a synthetic gold standard. In addition
to evaluation against this standard, Telma Kaan
Pixabaj—a Mayan linguist who helped create the
annotated corpus—reviewed by hand 100 word
clusters produced by our system, Morfessor and
Linguistica. Note that because English is suffixal
and Uspanteko is both prefixal and suffixal, we use
a slightly modified model for Uspanteko.
The approach introduced in this paper compares
favorably to Linguistica and Morfessor, two mod-
els that employ much more complex strategies and
rely on experimentally-tuned language/corpus-
specific parameters. In our evaluation, document
boundary awareness greatly benefits precision for
small datasets, blocking acquisition of spurious af-
fixes. For large datasets, global candidate genera-
tion outperforms document-aware candidate gen-
eration at the task of filtering out spurious stems,
but document-aware clustering improves preci-
sion. These findings are promising for the applica-
tion of this approach to under-resourced languages
</bodyText>
<footnote confidence="0.816577">
1Monson (2004) suggests, but does not actually use, χ2.
</footnote>
<bodyText confidence="0.96936045">
like Uspanteko.
2 Unsupervised morphology acquisition
Unsupervised morphology acquisition aims to
model one or more of three properties of writ-
ten morphology: segmentation, clustering around
a common stem, and generation of new word
forms with productive affixes. Intuitively, there are
straightforward, but non-trivial, challenges that
arise when evaluating a model. One large chal-
lenge is distinguishing derivational from inflec-
tional morphology. Most approaches deal with to-
kens without considering context. Since inflec-
tional morphology is virtually always driven by
syntax and word context, such approaches are un-
able to learn only inflectional morphology or only
derivational morphology. Even approaches which
take context into consideration (Schone and Juraf-
sky, 2000; Baroni et al., 2002; Freitag, 2005) can-
not learn specifically for one or the other.
In addition, the evaluation of both segmentation
and clustering involves arbitrary judgment calls.
Concerning segmentation, should altimeter and
altitude be one morpheme or two? (The sam-
ple English gold standard for MorphoChallenge
2009 provides alti+meter but altitude.) Similar is-
sues arise when evaluating clusters of related word
forms if inflection and derivation are not distin-
guished. Does atheism belong to the same cluster
as theism? Where is the frequency cutoff point be-
tween a productive derivational morpheme and an
unproductive one? Yet, many studies have eval-
uated their segmentations and clusters by going
over their results word by word, cluster by cluster
and judging by sight whether some segmentation
or clustering is good (e.g., Goldsmith (2001)).
Like Schone and Jurafsky (2001), we build clus-
ters that will have both inflectionally and deriva-
tionally related stems and evaluate them with re-
spect to a gold standard of only inflectionally re-
lated stems.
</bodyText>
<sectionHeader confidence="0.999965" genericHeader="introduction">
3 Related work
</sectionHeader>
<bodyText confidence="0.995005714285714">
There is a diverse body of existing work on unsu-
pervised morphology acquisition. We summarize
previous work, emphasizing some of its more ar-
bitrary and ad hoc aspects.
Letter successor variety. Letter successor va-
riety (LSV) models (Hafer and Weiss, 1974;
Gaussier, 1999; Bernhard, 2005; Bordag, 2005;
</bodyText>
<page confidence="0.998108">
669
</page>
<bodyText confidence="0.999913773333334">
Keshava and Pitler, 2005; Hammarstr¨om, 2006;
Dasgupta and Ng, 2007; Demberg, 2007) use the
hypothesis that there is less certainty when pre-
dicting the next character at morpheme bound-
aries. LSV has several issues that require fine pa-
rameter tuning. For example, Hafer and Weiss
(1974) counts how many types of characters ap-
pear after some initial string (the successor count)
and how many types of characters appear before
some final string (the predecessor count). A suc-
cessful criterion for segmenting a word was if the
predecessor count for the second part was greater
than 17 and the successor count for the first part
was greater than 5. Other studies have similar data
specific parameters and restrictions.
MDL and Bayesian models. Minimum descrip-
tion length (MDL) models (Goldsmith, 2001;
Creutz and Lagus, 2002; Creutz and Lagus, 2004;
Goldsmith, 2006; Creutz and Lagus, 2007) try to
segment words by maximizing the probability of
a training corpus subject to a penalty based on
the size of hypothesized morpheme lexicons they
build on the basis of the segmentations. While the-
oretically elegant, a pure implementation on real
data results in descriptions that do not reflect ac-
tual morphology. Creutz and Lagus (2005) re-
port that, “frequent word forms remain unsplit,
whereas rare word forms are excessively split.” In
the end, every MDL approach uses probabilisti-
cally motivated refinements that restrict the ten-
dency of raw MDL to generate descriptions that
do not fit linguistic notions of morphology. De-
spite the sophistication of the models in this group,
there are many parameters that need to be set, and
heuristic search procedures are crucial for their
success (Goldwater, 2007). Snover et al. (2002)
present a Bayesian model that uses a prior distribu-
tion to refine disjoint clusters of morphologically
related words. It disposes with parameter setting
by selecting the highest ranking hypothesis.
Context aware approaches. A word’s mor-
phology is strongly influenced by its syntactic and
semantic context. Schone and Jurafsky (2000) at-
tempts to cluster morphologically related words
starting with an unrefined trie search (but with a
parameter of minimum possible stem length and
an upper bound on potential affix candidates) that
is constrained by semantic similarity in a word
context vector space. Schone and Jurafsky (2001)
builds on this approach, but adds more ad hoc
parameters to handle circumfixation. Baroni et
al. (2002) takes a similar approach but uses edit
distance to cluster words that are similar but do
not necessarily share a long, contiguous substring.
They remove noise by constraining cluster mem-
bership with mutual information derived semantic
similarity. Freitag (2005) uses a mutual informa-
tion derived measure to learn the syntactic simi-
larity between words and clusters them. Then he
derives finite state machines across words in dif-
ferent clusters and refines them through a graph
walk algorithm. This group is the only one to eval-
uate against CELEX (Schone and Jurafsky, 2000;
Schone and Jurafsky, 2001; Freitag, 2005).
Others. Some other models require input such
as POS tables and lexicons and use a wider range
of information about the corpus (Yarowsky and
Wicentowski, 2000; Yarowsky et al., 2001; Chan,
2006). Because of the knowledge dependence of
these models, they are able to properly induce
inflectional morphology, as opposed to the stud-
ies cited above. Snyder and Barzilay (2008) uses
a set of aligned phrases across related languages
to learn how to segment words with a Bayesian
model and is otherwise fully unsupervised.
</bodyText>
<sectionHeader confidence="0.746464" genericHeader="method">
4 Model2
</sectionHeader>
<bodyText confidence="0.995194545454546">
Our goal is to generate conflation sets: sets of
word types that are related through either inflec-
tional or derivational morphology (Schone and Ju-
rafsky, 2000). Solving this task requires learning
how individual types are segmented (though the
segmentation itself is not evaluated). For present
purposes, we assume that the affixal pattern of the
language is known: whether it is prefixal, suffixal,
or both. To simplify presentation, we discuss a
model that captures suffixes only. Our approach is
a four stage process:
</bodyText>
<listItem confidence="0.991299777777778">
1. Candidate Generation: generate candidate
stems and affixes using an orthographically
defined data structure (a trie)
2. Candidate Filtering: filter candidate affixes
using the statistical significance for pairs of
affixes based on their co-occurence counts
with shared stems
3. Affix Clustering: cluster significant affix pairs
into affix groups
</listItem>
<footnote confidence="0.9865745">
2The code implementing the model is available from
http://comp.ling.utexas.edu/earl
</footnote>
<page confidence="0.993465">
670
</page>
<bodyText confidence="0.985513276595745">
4. Word Clustering: form conflation sets based
on affix clusters
The first and last stages are particularly prone to
noise, which has necessitated many of the thresh-
olds and heuristics employed in previous work.
We hypothesize that naturally occuring document
boundaries provide a strong constraint that should
reduce this noise, and we test that hypothesis by
using it in those stages.
Our intuition comes from an observation by
Yarowsky (1995) regarding multiple tokens of
words in documents. He tabulates the applicabil-
ity of using document boundaries to disambiguate
word senses, which measures how often a given
word occurs more than twice in the same docu-
ment. For ten potentially ambiguous words, he
counts how often they occur more than once in
some document and finds that if the words do oc-
cur, they do so multiple times in 50.1% of these
documents, on average. His counts ignored mor-
phological variation, and it is likely the applica-
bility measure would have increased considerably:
if a content word is used more than once in some
text, it is likely to be repeated in different syntactic
contexts, requiring the word to be inflected or to be
derived for a different part-of-speech category. 3
For stage one, we build separate tries for each
document rather than a trie for the entire corpus.
This should reduce the chance that orthographi-
cally similar but morphologically unrelated word
pairs lead to bad candidates by reducing the search
space for words which share a stem to a local doc-
ument. For example, assuage and assume are both
likely to occur in a large corpus and suggest that
there is a stem assu with affixes -age and -me.
They are less likely to occur together in many dif-
ferent documents that form the corpus, whereas
assume, assumed, and assuming are. We refer to
this document constrained candidate generation as
CandGen-D, and to the unconstrained generation
(a single trie for all documents) as CandGen-G.
For stage four, documents are used to constrain
potential membership of words in clusters: all
pairs of words in a cluster must have occured to-
gether in some document. We refer to document-
constrained clustering as Clust-D and the uncon-
strained global clustering as Clust-G.
</bodyText>
<footnote confidence="0.678232333333333">
3For example, in just this one paragraph we have
{document,documents}, {measure, measures}, {occur, oc-
curs, occuring}, and {word, words}.
</footnote>
<subsectionHeader confidence="0.992996">
4.1 Candidate generation
</subsectionHeader>
<bodyText confidence="0.99990975">
Given a document or collection of documents, we
use tries (prefix trees) to identify potential stems
and affixes and collect statistics for co-occurrences
between affixes and between affixes and stems.
A trie G, like the example
on the right, can be iden-
tified with the set of all
words on paths from the
root to any leaf, in the case
of the example figure the
set G = {abd, ab$, ac}.
(We use $ to denote an
empty affix.) Given a trie
G over alphabet L, we de-
fine the set of trunks of G
as all paths from the root to a branching point:
</bodyText>
<equation confidence="0.798293">
Tr(G)={w E L+ |]a,b E L,x1,x2 E L∗ :
a =� b ∧ wax1, wbx2 E G}
</equation>
<bodyText confidence="0.997681">
Also, we define the set of branches of a trunk t E
Tr(G) as the paths from its branching points to the
leaves:
</bodyText>
<equation confidence="0.73045">
Br(t, G) = {x E L+  |tx E G}
</equation>
<bodyText confidence="0.998352842105263">
In our example, {a, ab} are the trunks, with
Br(a, G) = {bd, b$, c} and Br(ab, G) = {d, $}.
When we use a trie to induce stems and affixes,
all induced stems will be trunks, and all induced
affixes will be branches.
From a given trie, we induce a set of stem can-
didates and affix candidates. A simple criterion is
used: if a trunk is longer than all of its branches,
the trunk is a stem candidate and its branches are
affix candidates. So, the set of stem candidates for
a trie G, CStem(G), is the set of trunks t E Tr(G)
such that |t |&gt; |b |for all b E Br(t, G).
Given a stem candidate s E CStem(G), its set of
affix candidates CAff(s, G) is identical to its set of
branches. (To talk about the sets of stem and affix
candidates for a whole trie G or a set of tries, we
write CAff(G), StC(G), CAff, and CStem.) The
count of an affix candidate b E CAff is the number
of stem candidates with which it occurs:
</bodyText>
<equation confidence="0.8966655">
�count(b) = |{s E CStem(G)  |b E CAff(s, G)}|
G
</equation>
<bodyText confidence="0.5628545">
For Fig. 1, the set of stem candidates is {ab} (since
some branches of the trunk a are longer than the
</bodyText>
<figureCaption confidence="0.932977">
Figure 1
</figureCaption>
<page confidence="0.993429">
671
</page>
<bodyText confidence="0.998775666666667">
trunk itself). The matching set of affix candidates
is CAff(ab, G) = {d, $}, each with a count of one.
An affix rule candidate is an unordered pair of
affix candidates {b1, b2}. It states that any stem
occurring with b1 can also occur with b2. Affix
rules implement the assumption that all produc-
tive affixes will cooccur with other productive af-
fixes and that these will form a coherent group.
The rule candidates for a given stem candidate
</bodyText>
<equation confidence="0.6225895">
s E CStem(G) are:
CRule(s, G) = {{b1, b2} C CAff(s, G)  |b1 =� b2}
</equation>
<bodyText confidence="0.971060625">
For example, the single stem candidate ab in
Fig. 1 has one rule candidate, {d, $}. We also use
CRule(G) for the rule candidates of a trie G across
all stems, and CRule for the union of rule candi-
dates in a set of tries.
The count of a rule candidate r={b1, b2} in a
trie is the number of stem candidates it appears
with:
</bodyText>
<equation confidence="0.995535">
�count(r) = |{s E CStem(G)  |r E CRule(s, G)}|
G
</equation>
<bodyText confidence="0.998087161290323">
We also use CAff(s) for the set of affix candidates
of stem s across several tries, and CRule(s) for the
set of rule candidates of a stem s across several
tries.
Document-specific versus global candidate gen-
eration. CandGen-D defines separate tries for
every document in the corpus and induces stem,
affix and rule candidates for each document.
CandGen-G instead induces these candidates for
a global trie over all the words in the corpus.
From the perspective of the formalism laid out
above, the only difference is that CandGen-D
has as many tries GZ as there are documents i
and CandGen-G has only one G. This simple
difference leads to different candidate sets and
counts over their occurrences. For example, say
two documents contain the pair putt/putts and
another contains bogey/bogeys. With CandGen-
D, count($)=3, count(s)=3, and count($, s)=2.
For the same documents, CandGen-G would pro-
duce count($)=2 and count(s)=2 since putt/putts
would have occurred only once in the global trie.
Also, consider a rare pair such as aard-
vark/aardvarks where each word is found in a dif-
ferent document. The pair would be identified
by CandGen-G but not by CandGen-D. The pair
would contribute a count of one to count($, s) in
CandGen-G but not in CandGen-D. So, CandGen-
G can provide better coverage, but it is also more
likely to identify noisy candidates, such as as-
suage/assumed, than CandGen-D.
</bodyText>
<subsectionHeader confidence="0.990098">
4.2 Candidate filtering
</subsectionHeader>
<bodyText confidence="0.999938555555556">
The sets of candidates CStem, CAff, CRule is ex-
pected to be noisy since the only basis for gener-
ating them was strings that share a large portion of
their substrings. One way of filtering candidates is
to find affix candidates whose co-occurence with
other candidates is not statistically significant.
We measure correlation between candidate af-
fixes b1, b2 in a candidate rule with the paired
χ2 test. By using χ2, we only consider pairwise
correlation between affixes, rather than attempting
global inference. Global consistency of affix sets
is not ensured, and as such the approach is sus-
ceptible to the multiple comparisons problem. We
still opt for this approach for its simplicity and be-
cause global inference is problematic due to data
sparseness.
Correlation between b1 and b2 is determined by
the following contingency table:4
</bodyText>
<equation confidence="0.999176">
b1 — b1
b2 O11 O12
— b2 O21 O22
</equation>
<bodyText confidence="0.9984908">
Based on the significance testing, we define the set
of valid rules PairRule as those for which the χ2
test is significant at p &lt; 0.05. Thus, affix can-
didates not significantly correlated with any other
affix in CAff are discarded.
</bodyText>
<subsectionHeader confidence="0.998845">
4.3 Affix clustering
</subsectionHeader>
<bodyText confidence="0.999836714285714">
The previous stage produces a set of pairs of af-
fixes that are significantly correlated. However,
inflectional paradigms rarely contain just two af-
fixes, so we would like to group together affix
pairs into larger affix sets to improve generaliza-
tion. We use a bottom up, minimum distance clus-
tering for valid affix pairs (rules). We do not as-
sume that cluster membership is exclusive. For
example, it would not make sense to determine
that the null affix -$ can belong to only one cluster.
Therefore, we produce non-disjoint affix clusters.
A valid cluster of affixes is a maximal set of af-
fixes forming pairwise valid rules: Aff C CAff is a
valid cluster of affixes iff
</bodyText>
<footnote confidence="0.960383333333333">
4where O11 = count({b1, b2}), O12 = count(b2) −
O11, O21 = count(b1) − O11, O22 = N − O11 − O12 − O21
and N = Pb∈CAff count(b). See table (1) for examples.
</footnote>
<page confidence="0.994241">
672
</page>
<figure confidence="0.85391125">
ed ∼ed le ∼le ed ∼ed le ∼le
ing 10273 21853 s 122 132945 ing 2651 1310 s 20 12073
∼ing 27120 4119332 ∼s 936 4044575 ∼ing 1490 150848 ∼s 198 144008
(a) x2 = 352678 (b) x2 = 239.132 (c) x2 = 65101.6 (d) x2 = 0.631, p = 0.427
</figure>
<tableCaption confidence="0.7808235">
Table 1: Affix counts in contingency tables for the valid pair ed/ing and spurious pair le/s according to
CandGen-D in (a) and (b) and according to CandGen-G in (c) and (d). x2 test values are given under
</tableCaption>
<bodyText confidence="0.87898525">
each table. Data is from NYT. Total affix token counts induced through CandGen-D and CandGen-G
are N=4178578 and N=156299, respectively. A total of 2054 and 3739 affix types were induced for
CandGen-D and CandGen-G, respectively showing that CandGen-G does have better coverage though
it might have more noise.
</bodyText>
<listItem confidence="0.993971333333333">
1. ∀b1, b2 ∈ Aff : {b1, b2} ∈ PairRule, and
2. If b ∈ CAff with ∀b′ ∈ Aff : {b, b′} ∈
PairRule, then b ∈ Aff.
</listItem>
<bodyText confidence="0.99988">
The set of all valid affix clusters is GroupRule.
This formulation does not rule out the existence
of clusters with affixes in common.
</bodyText>
<subsectionHeader confidence="0.998769">
4.4 Word clustering
</subsectionHeader>
<bodyText confidence="0.999995866666667">
We next cluster word forms into morphologically
related groups. Our model assumes two word
forms to be morphologically related iff (1) they oc-
curred in the same trie G, (2) they have a trunk s in
common that is a stem in Stem(G), and (3) their af-
fixes under this stem s are members in a common
valid affix cluster in GroupRule. Hence a single
stem s can be involved in at most |GroupRule |con-
flation sets, one for each valid affix cluster. Again,
the only distinction between clustering with a
global trie (Clust-G) and clustering with several
tries from the documents in a corpus (Clust-D) is
that the former has only one trie.
We define the conflation set for a given stem s ∈
Stem and valid affix cluster Aff ∈ GroupRule as
</bodyText>
<equation confidence="0.9974485">
Wd(s,Aff) = {sb1, sb2  |b1, b2 ∈ Aff ∧
∃G.s ∈ Stem(G) ∧ b1, b2 ∈ CAff(s, G)}
</equation>
<bodyText confidence="0.999857285714286">
One issue that needs clarification is when the
candidate generation and clustering stages use dif-
ferent strategies, i.e. the models CandGen-D
+Clust-G and CandGen-G +Clust-D. This sim-
ply means that the statistics, and thus the valid
GroupRule, are derived from either CandGen-D or
CandGen-G.
</bodyText>
<sectionHeader confidence="0.597993" genericHeader="method">
4.5 Induction for languages that are both
prefixal and affixal
</sectionHeader>
<bodyText confidence="0.99876375">
The above approach would not fit a language that
is prefixal and suffixal. Assuming we have in-
duced separate conflation sets over a prefix trie and
a suffix trie, we merge clusters between the two if
they have at least one word form in common. For-
mally, given a set of prefix conflation sets PCS and
a set of suffix conflation sets SCS, the final set of
conflation sets CS is:
</bodyText>
<equation confidence="0.871151">
CS = {p ∪ s |p ∈ PCS, s ∈ SCS ∧ p ∩ s =6 ∅}
</equation>
<sectionHeader confidence="0.986567" genericHeader="method">
5 Data
</sectionHeader>
<bodyText confidence="0.999911296296296">
We apply our method on English and Uspanteko,
an endangered Mayan language.
Learning corpora. For English, we use two
subsets of the NYTimes portion in the Gigaword
corpus which we will call NYT and MINI-NYT.
NYT in the current study is the complete collec-
tion of articles in the New York Times from June,
2002. NYT has 10K articles, 88K types and 9M
tokens. MINI-NYT is a subset of NYT with 190
articles, 15K types and 187K tokens.
The Uspanteko text, USP has 29 distinct texts,
7K types, and 50K tokens. The texts are from
OKMA (Pixabaj et al., 2007) and the segmenta-
tion and labels of the interlinear glossed text anno-
tations were checked for consistency and cleaned
up (Palmer et al., 2009). All counts are for lower-
cased, punctuation-removed word forms.
CELEX. The CELEX lexical database (Baayen
et al., 1993) has been built for Dutch, English and
German and provides detailed entries that list and
analyze the morphological properties of words,
among other information. Using CELEX, we eval-
uate on types rather than tokens. The performance
of the model is based on how many of the words it
judges to be morphologically related overlap with
the entries in CELEX. Following previous work
(Schone and Jurafsky, 2000; Schone and Jurafsky,
</bodyText>
<page confidence="0.990629">
673
</page>
<bodyText confidence="0.873561">
recall
2001; Freitag, 2005), we evaluate on inflectional
clusters only, using the CELEX file listing clusters
of inflectional variants. 5
</bodyText>
<sectionHeader confidence="0.980179" genericHeader="evaluation">
6 Experiments and evaluation
</sectionHeader>
<bodyText confidence="0.9999595">
We outline our evaluation methodology, baselines,
benchmarks and results, and discuss the results.
</bodyText>
<subsectionHeader confidence="0.993869">
6.1 Evaluation metric
</subsectionHeader>
<bodyText confidence="0.999916454545455">
Schone and Jurafsky (2000) give definitions for
correct (C), inserted (Z), and deleted (D) words
in model-derived conflation sets in relation to a
gold standard. Their formulation does not allow
for multiple cluster membership of words. We ex-
tend the definition to incorporate this fact about the
data. Let w be a word form. We write Xw for the
clusters induced by the model that contain w, and
Yw for gold standard clusters containing w. Xw
and Yw only count words which occurred in both
model and gold standard clusters. Then
</bodyText>
<equation confidence="0.84983075">
(|Xw n Yw|/|Yw|)
(|Xw − (Xw n Yw)|/|Yw|)
(|Yw − (Xw n Yw)|/|Yw|)
w
</equation>
<bodyText confidence="0.99803105882353">
Based on these definitions, we formulate preci-
sion (P), recall (R), and the f-score (F) as: P =
C/(C+Z), R = C/(C+D), F = (2PR)/(P+R).
USP evaluation We use two different means to
evaluate the performance on USP. One is the
f-score derived from the above section with re-
spect to a standard that was automatically gen-
erated from the morpheme segment tiers of the
OKMA IGT. We generated the standard by taking
non-hyphenated segments as the stem and cluster-
ing words with shared stems.
We also had an expert in Uspanteko manually
evaluate a random subset (N = 100) of the model
output to compensate for any failings in the stan-
dard. The evaluator determined a dominant stem
for a cluster and identified words which were not
related to that stem. We measured accuracy and
</bodyText>
<footnote confidence="0.8385922">
5CELEX does have a second file listing words and their
breakup into constituent morphemes for both derivation and
inflection, but its use would have required additional process-
ing that could introduce errors.
precision
</footnote>
<figureCaption confidence="0.722196333333333">
Figure 2: Precision/recall graph for baseline ex-
periments on English, prefix USP (Usp-P) and suf-
fix USP (Usp-S).
</figureCaption>
<bodyText confidence="0.980574">
full cluster accuracy6 for the expert evaluations
(table 4).
We experimented on Uspanteko with three dif-
ferent assumptions: (1) it is only prefixal; (2) it is
only suffixal; (3) it is both prefixal and suffixal.
We applied the assumptions of only prefixal or
only suffixal to LINGUISTICA as well. The rele-
vant results are given row headers in tables with a
corresponding +P(prefix) or +S(suffix).
</bodyText>
<subsectionHeader confidence="0.999713">
6.2 Baselines and benchmarks
</subsectionHeader>
<bodyText confidence="0.943884608695652">
In a set of baselines, we put words which share
the first k characters into the same cluster. We
do this for NYT, MINI-NYT, and USP in a pre-
fix tree, and for USP in suffix tree (using the last k
characters). We set the values of 0 &lt; k &lt; max,
where max is the length of the longest string, and
plot the results in a precision-recall graph (Fig. 2).
Low k corresponds to high recall and low preci-
sion while high k shows the opposite. The contrast
in morphological patterns for each language can
also be seen. Because Uspanteko is morpholog-
ically complex with suffixes and prefixes, a very
simple strategy cannot achieve high recall as op-
posed to English where it is possible to retrieve all
variants with a simple prefix tree.
We use Linguistica (Goldsmith, 2001) and Mor-
fessor (Creutz and Lagus, 2007) as benchmarks.
We used the default settings for these programs.
Note that comparison with these tools is not com-
6Given a model cluster Ci and the “misses” for each clus-
ter Mi, accuracy is measured as 1/N Pi ( |Ci  |−  |Mi |) /( |Ci |)
where N is the sample size. Full cluster accuracy is the num-
ber of clusters that did not have any misses over N.
</bodyText>
<figure confidence="0.973784366666667">
100
90
80
70
60
50
40
0 10 20 30 40 50 60 70 80 90 100
mini−NYT
NYT
Usp−S
Usp−P
X
C =
w
XZ =
w
X
X.
X
Y.
X
X.
X
Y.
XD =
X
X.
X
Y.
</figure>
<page confidence="0.994943">
674
</page>
<table confidence="0.999416125">
MINI-NYT NYT
P R F P R F
LINGUISTICA 64.30 93.34 76.15 47.50 88.33 61.77
MORFESSOR 45.2 87.8 59.7 63.6 69.2 66.3
CandGen-D + Clust-G 69.41 91.42 78.91 46.00 79.81 58.36
CandGen-D + Clust-D 83.47 80.36 81.89 59.02 74.50 65.86
CandGen-G + Clust-G 73.44 88.72 80.36 61.81 82.98 70.85
CandGen-G + Clust-D 88.34 77.95 82.82 77.71 70.24 73.79
</table>
<tableCaption confidence="0.999863">
Table 2: Results on English for all models in precision(P), recall(R), f-score(F) for each data set.
</tableCaption>
<bodyText confidence="0.99940825">
pletely fair. Morfessor only generates segmenta-
tions. We therefore processed Morfessor output
by clustering words by assuming that the longest
segment in any segmentation is the stem and eval-
uated this instead. Linguistica produces stems and
associated suffixes so the clusters naturally follow
from this output. However, Linguistica only infers
either prefix or suffix patterns.
</bodyText>
<subsectionHeader confidence="0.98009">
6.3 Results and discussion
</subsectionHeader>
<bodyText confidence="0.99999353968254">
The results on English are in table 2 with x2 test
criteria of p&lt;0.05 and each cell in the contingency
table &gt;5. CandGen-G +Clust-D had the best f-
score, and easily beats the benchmarks.
This is different from our expectation that
awareness of document boundaries at all stages
(i.e., CandGen-D +Clust-D) would show the best
results. The discrepancy is especially marked for
the larger NYT. One important reason for this is
the affix criterion itself: trunks must be longer than
branches. Consider again the sample contingency
tables in Table 1 that were derived from NYT
through CandGen-D and CandGen-G. We had as-
sumed at the outset that CandGen-D would be bet-
ter able to filter out noise and would be sparser, but
results show the opposite. The reason is that that
short words in a global lexicon are more likely to
share trunks with longer, unrelated words. This
ensures that short word forms rarely generate can-
didate affixes. Longer words which are less likely
to have spurious long branches generate the bulk
of candidate suffixes and stems. This is born out
by the stems that were associated with the spuri-
ous suffix pair le/s: CandGen-G has cliente, cripp,
crumb, daniel, ender, label, mccord, nag, oval,
sear, stubb, whipp. CandGen-D has crumb, hand,
need, sing, tab, trick, trip. The word forms that
are associated with le/s through the CandGen-D
strategy are crumble/crumbs, handle/hands, ....
Compare this with the word forms associated with
the search strategy CandGen-G such as clien-
tele/clientes, cripple/crips, .... The majority of
them are not common English words; they are
most probably proper names such as LaBelle and
Searle. Furthermore, there is no item among the
stems from the CandGen-G search where concate-
nating the stems le and s would result in both word
forms being a common noun or verb as is the
case with the stems from the CandGen-D search
where all concatenated word forms are common
English words. Though CandGen-G finds spuri-
ous stems, the counts for the spurious affix pair are
suppressed (see table 1) because it is a type count
rather than a token count. This results in le/s be-
ing properly excluded as a rule. This explains why
CandGen-D has worse precision in general than
CandGen-G.
The affix criterion has other minor issues. One
is that it ignores the few cases where stems are
shorter than affixes, such as the very common
words be, do, go.7 Assuming that the longest
productive inflectional suffix in English is -ing8,
the criterion would correctly find stem candidates
for -ing only when the stem is longer than 3 or
4 letters. Another is that the criterion, when
combined with CandGen-D, generates candidates
from the/them/then/their/these which cooccur fre-
quently in documents. This is not an issue when
the criterion is applied in CandGen-G.
Nonetheless, results show that when data sizes
are small, as with USP (Table 3) and MINI-NYT,
awareness of document boundaries at the candi-
date generation stage is beneficial to precision.
</bodyText>
<footnote confidence="0.962627833333333">
7The exclusion of such words in a token based evaluation
as opposed to a type based evaluation would heavily penalize
our approach. We are not aware, however, of any prior work
in unsupervised morphology that evaluates over tokens.
8with occasional gemination of final consonant such as
occur → occurring
</footnote>
<page confidence="0.993131">
675
</page>
<table confidence="0.999753857142857">
P R F
Ca-D + Cl-D 70.51 44.35 54.45
Ca-G + Cl-G 70.00 46.87 56.15
Ca-D + Cl-D + S 88.58 45.21 59.86
Ca-D + Cl-G + S 85.03 44.75 58.64
Ca-G + Cl-D + S 90.34 45.48 60.50
Ca-G + Cl-G + S 84.54 46.03 59.60
Ca-D + Cl-D + P 93.84 47.90 63.42
Ca-D + Cl-G + P 89.94 47.38 62.06
Ca-G + Cl-D + P 95.42 47.89 63.78
Ca-G + Cl-G + P 92.03 50.01 64.80
LINGUISTICA + S 81.14 47.60 60.00
LINGUISTICA + P 84.15 52.00 64.28
MORFESSOR 28.12 62.28 38.75
</table>
<tableCaption confidence="0.99731175">
Table 3: Performance of models on automatically
generated USP evaluation set. P: Prefix only, S:
Suffix only. If there is no indication of S or P, it
means model attempted to learn both
</tableCaption>
<table confidence="0.99965">
Acc. FAcc. Avg. Sz.
Ca-G + Cl-G 98.5 79.0 2.94
LINGUISTICA 96.0 85.0 2.64
MORFESSOR 85.3 55.0 4.8
</table>
<tableCaption confidence="0.985447">
Table 4: Human expert evaluated accuracy (Acc.)
</tableCaption>
<bodyText confidence="0.996451333333333">
and full cluster accuracy (FAcc.) of models on
USP and average cluster size in words (Avg. Sz.)
However, it seems that CandGen-G has better cov-
erage no matter the size of the corpus, which
explains why coupling it with Clust-D produces
overall better scores. Clust-D does provide a use-
ful added constraint to mere orthographic similar-
ity (i.e. shared trunks in a trie).
A worrisome aspect of the results is that perfor-
mance degrades for large data sets (this is also true
for Linguistica). However, it also hints that this
method might work well for under-resourced lan-
guages. We surmise that since productive suffixes
do not suffer from sparsity, even a small data set
provides sufficient evidence to reach reliable con-
clusions about the productive morphology of some
language. Increasing the size of the data merely
increases the counts of spurious affixes and poses
problems for a relative simple measure such as
the χ2 test. A similar result was shown in Creutz
and Lagus (2005) where f-score performance of
their segmentation method improved as more data
was provided then decreased as the input exceeded
250K tokens in English. Their method showed
continued improvement with increased data for
Finnish. This hints that more data is beneficial
for morphologically complex languages but not
for morphologically impoverished languages.
Finally, it is also encouraging that the manual
evaluation (Table 4) shows very high accuracy, as
judged by a documentary linguist. Both our model
and Linguistica perform very well under this eval-
uation.
</bodyText>
<sectionHeader confidence="0.998371" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999979407407407">
We have presented a novel approach to unsuper-
vised morphology acquisition that uses a very
simple pipeline and does not use any thresholds
other than standard ones associated with the χ2
test. The model relies on document boundaries
and correlation tests for filtering spurious stems
and affixes. The model compares favorably to
Linguistica and Morfessor, two models that em-
ploy much more complex strategies and rely on
fine-tuned parameters. We found that the use of
document boundaries is especially beneficial with
small datasets, which is promising for the applica-
tion of this model to under-resourced languages.
For large datasets, global candidate generation
outperformed document-aware candidate genera-
tion at the task of filtering out spurious stems,
but document-aware clustering does improve pre-
cision and overall performance.
In this paper we have addressed one aspect of
morphology acquisition, segmentation and clus-
tering. Extending the approach is straightforward,
for example, substituting more sophisticated data
structures or statistical tests for the current ones.
In particular, we will move from the use of doc-
ument boundaries to a flexible notion of textual
distance to estimate likelihood of morphological
relatedness.
</bodyText>
<sectionHeader confidence="0.999016" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.832624333333333">
This work is funded by NSF grant BCS 06651988
“Reducing Annotation Effort in the Documenta-
tion of Languages using Machine Learning and
Active Learning.” Thanks to Alexis Palmer, Telma
Kaan Pixabaj, Elias Ponvert, and the anonymous
reviewers.
</bodyText>
<page confidence="0.999031">
676
</page>
<sectionHeader confidence="0.99588" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999913645833333">
R. H. Baayen, R. Piepenbrock, and H. van Rijn. 1993.
The CELEX lexical database on CD-ROM. Linguis-
tic Data Consortium, Philadelphia, PA.
M. Baroni, J. Matiasek, and H. Trost. 2002. Unsu-
pervised discovery of morphologically related words
based on orthographic and semantic similarity. In
ACL ’02 workshop on Morphological and phonolog-
ical learning, pages 48–57.
D. Bernhard. 2005. Unsupervised morphological seg-
mentation based on segment predictability and word
segments alignment. In Proceedings of Morpho
Challenge 2005, pages 18–27.
S. Bordag. 2005. Two-step approach to unsupervised
morpheme segmentation. In Proceedings ofMorpho
Challenge 2005, pages 23–27.
E. Chan. 2006. Learning Probabilistic Paradigms for
Morphology in a Latent Class Model. In ACL SIG-
PHON ’06, pages 69–78.
M. Creutz and K. Lagus. 2002. Unsupervised dis-
covery of morphemes. In ACL ’02 workshop on
Morphological and phonological learning-Volume
6, pages 21–30.
M. Creutz and K. Lagus. 2004. Induction of a simple
morphology for highly-inflecting languages. In ACL
SIGPHON ’04, pages 43–51.
M. Creutz and K. Lagus. 2005. Inducing the morpho-
logical lexicon of a natural language from unanno-
tated text. In AKRR ’05, pages 106–113.
M. Creutz and K. Lagus. 2007. Unsupervised models
for morpheme segmentation and morphology learn-
ing. ACM Trans. Speech Lang. Process., 4(1):3.
S. Dasgupta and V. Ng. 2007. High-performance,
language-independent morphological segmentation.
In NAACL-HLT, pages 155–163.
V. Demberg. 2007. A language-independent unsu-
pervised model for morphological segmentation. In
ACL ’07, volume 45, page 920.
D. Freitag. 2005. Morphology induction from term
clusters. In CoNLL ’05.
E. Gaussier. 1999. Unsupervised learning of deriva-
tional morphology from inflectional lexicons. In
ACL workshop on Unsupervised Methods in Natu-
ral Language Learning.
J. Goldsmith. 2001. Unsupervised learning of the
morphology of a natural language. Comp. Ling.,
27(2):153–198.
J. Goldsmith. 2006. An algorithm for the unsupervised
learning of morphology. Natural Language Engi-
neering, 12(04):353–371.
S.J. Goldwater. 2007. Nonparametric Bayesian mod-
els of lexical acquisition. Ph.D. thesis, Brown Uni-
versity.
M.A. Hafer and S.F. Weiss. 1974. Word Segmentation
by Letter Successor Varieties. Information Storage
and Retrieval, 10:371–385.
H. Hammarstr¨om. 2006. A naive theory of affixation
and an algorithm for extraction. In ACL SIGPHON
’06, pages 79–88, June.
S. Keshava and E. Pitler. 2005. A simpler, intuitive
approach to morpheme induction. In Proceedings of
Morpho Challenge 2005, pages 28–32.
C. Monson. 2004. A framework for unsupervised nat-
ural language morphology induction. In Proceed-
ings of the Student Workshop at ACL, volume 4.
Alexis Palmer, Taesun Moon, and Jason Baldridge.
2009. Evaluating automation strategies in language
documentation. In Proceedings of the NAACL HLT
2009 Workshop on Active Learningfor Natural Lan-
guage Processing, pages 36–44, Boulder, CO.
T.C. Pixabaj, M.A. Vicente M´endez, M. Vicente
M´endez, and O.A. Dami´an. 2007. Text collections
in Four Mayan Languages. Archived in The Archive
of the Indigenous Languages of Latin America.
P. Schone and D. Jurafsky. 2000. Knowledge-free in-
duction of morphology using latent sematic analysis.
In CoNLL-2000 and LLL-2000.
P. Schone and D. Jurafsky. 2001. Knowledge-free
induction of inflectional morphologies. In NAACL
’01, pages 1–9.
M.G. Snover, G.E. Jarosz, and M.R. Brent. 2002. Un-
supervised learning of morphology using a novel di-
rected search algorithm: taking the first step. In ACL
’02 workshop on Morphological and phonological
learning, pages 11–20.
B. Snyder and R. Barzilay. 2008. Unsupervised multi-
lingual learning for morphological segmentation. In
ACL ’08.
D. Yarowsky and R. Wicentowski. 2000. Minimally
supervised morphological analysis by multimodal
alignment. In ACL ’00, pages 207–216.
D. Yarowsky, G. Ngai, and R. Wicentowski. 2001.
Inducing multilingual text analysis tools via robust
projection across aligned corpora. In HLT ’01.
D. Yarowsky. 1995. Unsupervised word sense disam-
biguation rivaling supervised methods. In ACL ’95,
pages 189–196.
</reference>
<page confidence="0.998159">
677
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.921933">
<title confidence="0.9737645">Unsupervised morphological segmentation and clustering with document boundaries</title>
<author confidence="0.997105">Taesun Moon</author>
<author confidence="0.997105">Katrin Erk</author>
<author confidence="0.997105">Jason</author>
<affiliation confidence="0.999519">Department of University of Texas at 1 University Station</affiliation>
<address confidence="0.984395">Austin, TX 78712-0198</address>
<abstract confidence="0.999176380952381">Many approaches to unsupervised morphology acquisition incorporate the frequency of character sequences with respect to each other to identify word stems and affixes. This typically involves heuristic search procedures and calibrating multiple arbitrary thresholds. We present a simple approach that uses no thresholds other than those involved in standard apof significance testing. A key part of our approach is using document boundaries to constrain generation of candidate stems and affixes and clustering morphological variants of a given word stem. We evaluate our model on English and the Mayan language Uspanteko; it compares favorably to two benchmark systems which use considerably more complex strategies and rely more on experimentally chosen threshold values.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R H Baayen</author>
<author>R Piepenbrock</author>
<author>H van Rijn</author>
</authors>
<date>1993</date>
<booktitle>The CELEX lexical database on CD-ROM. Linguistic Data Consortium,</booktitle>
<location>Philadelphia, PA.</location>
<marker>Baayen, Piepenbrock, van Rijn, 1993</marker>
<rawString>R. H. Baayen, R. Piepenbrock, and H. van Rijn. 1993. The CELEX lexical database on CD-ROM. Linguistic Data Consortium, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Baroni</author>
<author>J Matiasek</author>
<author>H Trost</author>
</authors>
<title>Unsupervised discovery of morphologically related words based on orthographic and semantic similarity.</title>
<date>2002</date>
<booktitle>In ACL ’02 workshop on Morphological and phonological learning,</booktitle>
<pages>48--57</pages>
<contexts>
<context position="7182" citStr="Baroni et al., 2002" startWordPosition="1086" endWordPosition="1089">stering around a common stem, and generation of new word forms with productive affixes. Intuitively, there are straightforward, but non-trivial, challenges that arise when evaluating a model. One large challenge is distinguishing derivational from inflectional morphology. Most approaches deal with tokens without considering context. Since inflectional morphology is virtually always driven by syntax and word context, such approaches are unable to learn only inflectional morphology or only derivational morphology. Even approaches which take context into consideration (Schone and Jurafsky, 2000; Baroni et al., 2002; Freitag, 2005) cannot learn specifically for one or the other. In addition, the evaluation of both segmentation and clustering involves arbitrary judgment calls. Concerning segmentation, should altimeter and altitude be one morpheme or two? (The sample English gold standard for MorphoChallenge 2009 provides alti+meter but altitude.) Similar issues arise when evaluating clusters of related word forms if inflection and derivation are not distinguished. Does atheism belong to the same cluster as theism? Where is the frequency cutoff point between a productive derivational morpheme and an unprod</context>
<context position="10995" citStr="Baroni et al. (2002)" startWordPosition="1689" endWordPosition="1692">words. It disposes with parameter setting by selecting the highest ranking hypothesis. Context aware approaches. A word’s morphology is strongly influenced by its syntactic and semantic context. Schone and Jurafsky (2000) attempts to cluster morphologically related words starting with an unrefined trie search (but with a parameter of minimum possible stem length and an upper bound on potential affix candidates) that is constrained by semantic similarity in a word context vector space. Schone and Jurafsky (2001) builds on this approach, but adds more ad hoc parameters to handle circumfixation. Baroni et al. (2002) takes a similar approach but uses edit distance to cluster words that are similar but do not necessarily share a long, contiguous substring. They remove noise by constraining cluster membership with mutual information derived semantic similarity. Freitag (2005) uses a mutual information derived measure to learn the syntactic similarity between words and clusters them. Then he derives finite state machines across words in different clusters and refines them through a graph walk algorithm. This group is the only one to evaluate against CELEX (Schone and Jurafsky, 2000; Schone and Jurafsky, 2001</context>
</contexts>
<marker>Baroni, Matiasek, Trost, 2002</marker>
<rawString>M. Baroni, J. Matiasek, and H. Trost. 2002. Unsupervised discovery of morphologically related words based on orthographic and semantic similarity. In ACL ’02 workshop on Morphological and phonological learning, pages 48–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Bernhard</author>
</authors>
<title>Unsupervised morphological segmentation based on segment predictability and word segments alignment.</title>
<date>2005</date>
<booktitle>In Proceedings of Morpho Challenge</booktitle>
<pages>18--27</pages>
<contexts>
<context position="8524" citStr="Bernhard, 2005" startWordPosition="1298" endWordPosition="1299">by cluster and judging by sight whether some segmentation or clustering is good (e.g., Goldsmith (2001)). Like Schone and Jurafsky (2001), we build clusters that will have both inflectionally and derivationally related stems and evaluate them with respect to a gold standard of only inflectionally related stems. 3 Related work There is a diverse body of existing work on unsupervised morphology acquisition. We summarize previous work, emphasizing some of its more arbitrary and ad hoc aspects. Letter successor variety. Letter successor variety (LSV) models (Hafer and Weiss, 1974; Gaussier, 1999; Bernhard, 2005; Bordag, 2005; 669 Keshava and Pitler, 2005; Hammarstr¨om, 2006; Dasgupta and Ng, 2007; Demberg, 2007) use the hypothesis that there is less certainty when predicting the next character at morpheme boundaries. LSV has several issues that require fine parameter tuning. For example, Hafer and Weiss (1974) counts how many types of characters appear after some initial string (the successor count) and how many types of characters appear before some final string (the predecessor count). A successful criterion for segmenting a word was if the predecessor count for the second part was greater than 17</context>
</contexts>
<marker>Bernhard, 2005</marker>
<rawString>D. Bernhard. 2005. Unsupervised morphological segmentation based on segment predictability and word segments alignment. In Proceedings of Morpho Challenge 2005, pages 18–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bordag</author>
</authors>
<title>Two-step approach to unsupervised morpheme segmentation.</title>
<date>2005</date>
<booktitle>In Proceedings ofMorpho Challenge</booktitle>
<pages>23--27</pages>
<contexts>
<context position="8538" citStr="Bordag, 2005" startWordPosition="1300" endWordPosition="1301">udging by sight whether some segmentation or clustering is good (e.g., Goldsmith (2001)). Like Schone and Jurafsky (2001), we build clusters that will have both inflectionally and derivationally related stems and evaluate them with respect to a gold standard of only inflectionally related stems. 3 Related work There is a diverse body of existing work on unsupervised morphology acquisition. We summarize previous work, emphasizing some of its more arbitrary and ad hoc aspects. Letter successor variety. Letter successor variety (LSV) models (Hafer and Weiss, 1974; Gaussier, 1999; Bernhard, 2005; Bordag, 2005; 669 Keshava and Pitler, 2005; Hammarstr¨om, 2006; Dasgupta and Ng, 2007; Demberg, 2007) use the hypothesis that there is less certainty when predicting the next character at morpheme boundaries. LSV has several issues that require fine parameter tuning. For example, Hafer and Weiss (1974) counts how many types of characters appear after some initial string (the successor count) and how many types of characters appear before some final string (the predecessor count). A successful criterion for segmenting a word was if the predecessor count for the second part was greater than 17 and the succe</context>
</contexts>
<marker>Bordag, 2005</marker>
<rawString>S. Bordag. 2005. Two-step approach to unsupervised morpheme segmentation. In Proceedings ofMorpho Challenge 2005, pages 23–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Chan</author>
</authors>
<title>Learning Probabilistic Paradigms for Morphology in a Latent Class Model.</title>
<date>2006</date>
<booktitle>In ACL SIGPHON ’06,</booktitle>
<pages>69--78</pages>
<contexts>
<context position="11806" citStr="Chan, 2006" startWordPosition="1821" endWordPosition="1822">mutual information derived semantic similarity. Freitag (2005) uses a mutual information derived measure to learn the syntactic similarity between words and clusters them. Then he derives finite state machines across words in different clusters and refines them through a graph walk algorithm. This group is the only one to evaluate against CELEX (Schone and Jurafsky, 2000; Schone and Jurafsky, 2001; Freitag, 2005). Others. Some other models require input such as POS tables and lexicons and use a wider range of information about the corpus (Yarowsky and Wicentowski, 2000; Yarowsky et al., 2001; Chan, 2006). Because of the knowledge dependence of these models, they are able to properly induce inflectional morphology, as opposed to the studies cited above. Snyder and Barzilay (2008) uses a set of aligned phrases across related languages to learn how to segment words with a Bayesian model and is otherwise fully unsupervised. 4 Model2 Our goal is to generate conflation sets: sets of word types that are related through either inflectional or derivational morphology (Schone and Jurafsky, 2000). Solving this task requires learning how individual types are segmented (though the segmentation itself is n</context>
</contexts>
<marker>Chan, 2006</marker>
<rawString>E. Chan. 2006. Learning Probabilistic Paradigms for Morphology in a Latent Class Model. In ACL SIGPHON ’06, pages 69–78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Creutz</author>
<author>K Lagus</author>
</authors>
<title>Unsupervised discovery of morphemes.</title>
<date>2002</date>
<booktitle>In ACL ’02 workshop on Morphological and phonological learning-Volume 6,</booktitle>
<pages>21--30</pages>
<contexts>
<context position="9363" citStr="Creutz and Lagus, 2002" startWordPosition="1432" endWordPosition="1435">s several issues that require fine parameter tuning. For example, Hafer and Weiss (1974) counts how many types of characters appear after some initial string (the successor count) and how many types of characters appear before some final string (the predecessor count). A successful criterion for segmenting a word was if the predecessor count for the second part was greater than 17 and the successor count for the first part was greater than 5. Other studies have similar data specific parameters and restrictions. MDL and Bayesian models. Minimum description length (MDL) models (Goldsmith, 2001; Creutz and Lagus, 2002; Creutz and Lagus, 2004; Goldsmith, 2006; Creutz and Lagus, 2007) try to segment words by maximizing the probability of a training corpus subject to a penalty based on the size of hypothesized morpheme lexicons they build on the basis of the segmentations. While theoretically elegant, a pure implementation on real data results in descriptions that do not reflect actual morphology. Creutz and Lagus (2005) report that, “frequent word forms remain unsplit, whereas rare word forms are excessively split.” In the end, every MDL approach uses probabilistically motivated refinements that restrict the</context>
</contexts>
<marker>Creutz, Lagus, 2002</marker>
<rawString>M. Creutz and K. Lagus. 2002. Unsupervised discovery of morphemes. In ACL ’02 workshop on Morphological and phonological learning-Volume 6, pages 21–30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Creutz</author>
<author>K Lagus</author>
</authors>
<title>Induction of a simple morphology for highly-inflecting languages.</title>
<date>2004</date>
<booktitle>In ACL SIGPHON ’04,</booktitle>
<pages>43--51</pages>
<contexts>
<context position="9387" citStr="Creutz and Lagus, 2004" startWordPosition="1436" endWordPosition="1439">quire fine parameter tuning. For example, Hafer and Weiss (1974) counts how many types of characters appear after some initial string (the successor count) and how many types of characters appear before some final string (the predecessor count). A successful criterion for segmenting a word was if the predecessor count for the second part was greater than 17 and the successor count for the first part was greater than 5. Other studies have similar data specific parameters and restrictions. MDL and Bayesian models. Minimum description length (MDL) models (Goldsmith, 2001; Creutz and Lagus, 2002; Creutz and Lagus, 2004; Goldsmith, 2006; Creutz and Lagus, 2007) try to segment words by maximizing the probability of a training corpus subject to a penalty based on the size of hypothesized morpheme lexicons they build on the basis of the segmentations. While theoretically elegant, a pure implementation on real data results in descriptions that do not reflect actual morphology. Creutz and Lagus (2005) report that, “frequent word forms remain unsplit, whereas rare word forms are excessively split.” In the end, every MDL approach uses probabilistically motivated refinements that restrict the tendency of raw MDL to </context>
</contexts>
<marker>Creutz, Lagus, 2004</marker>
<rawString>M. Creutz and K. Lagus. 2004. Induction of a simple morphology for highly-inflecting languages. In ACL SIGPHON ’04, pages 43–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Creutz</author>
<author>K Lagus</author>
</authors>
<title>Inducing the morphological lexicon of a natural language from unannotated text.</title>
<date>2005</date>
<booktitle>In AKRR ’05,</booktitle>
<pages>106--113</pages>
<contexts>
<context position="9771" citStr="Creutz and Lagus (2005)" startWordPosition="1498" endWordPosition="1501"> for the first part was greater than 5. Other studies have similar data specific parameters and restrictions. MDL and Bayesian models. Minimum description length (MDL) models (Goldsmith, 2001; Creutz and Lagus, 2002; Creutz and Lagus, 2004; Goldsmith, 2006; Creutz and Lagus, 2007) try to segment words by maximizing the probability of a training corpus subject to a penalty based on the size of hypothesized morpheme lexicons they build on the basis of the segmentations. While theoretically elegant, a pure implementation on real data results in descriptions that do not reflect actual morphology. Creutz and Lagus (2005) report that, “frequent word forms remain unsplit, whereas rare word forms are excessively split.” In the end, every MDL approach uses probabilistically motivated refinements that restrict the tendency of raw MDL to generate descriptions that do not fit linguistic notions of morphology. Despite the sophistication of the models in this group, there are many parameters that need to be set, and heuristic search procedures are crucial for their success (Goldwater, 2007). Snover et al. (2002) present a Bayesian model that uses a prior distribution to refine disjoint clusters of morphologically rela</context>
<context position="34933" citStr="Creutz and Lagus (2005)" startWordPosition="5876" endWordPosition="5879">n a trie). A worrisome aspect of the results is that performance degrades for large data sets (this is also true for Linguistica). However, it also hints that this method might work well for under-resourced languages. We surmise that since productive suffixes do not suffer from sparsity, even a small data set provides sufficient evidence to reach reliable conclusions about the productive morphology of some language. Increasing the size of the data merely increases the counts of spurious affixes and poses problems for a relative simple measure such as the χ2 test. A similar result was shown in Creutz and Lagus (2005) where f-score performance of their segmentation method improved as more data was provided then decreased as the input exceeded 250K tokens in English. Their method showed continued improvement with increased data for Finnish. This hints that more data is beneficial for morphologically complex languages but not for morphologically impoverished languages. Finally, it is also encouraging that the manual evaluation (Table 4) shows very high accuracy, as judged by a documentary linguist. Both our model and Linguistica perform very well under this evaluation. 7 Conclusion We have presented a novel </context>
</contexts>
<marker>Creutz, Lagus, 2005</marker>
<rawString>M. Creutz and K. Lagus. 2005. Inducing the morphological lexicon of a natural language from unannotated text. In AKRR ’05, pages 106–113.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Creutz</author>
<author>K Lagus</author>
</authors>
<title>Unsupervised models for morpheme segmentation and morphology learning.</title>
<date>2007</date>
<journal>ACM Trans. Speech Lang. Process.,</journal>
<volume>4</volume>
<issue>1</issue>
<contexts>
<context position="1315" citStr="Creutz and Lagus, 2007" startWordPosition="193" endWordPosition="196">art of our approach is using document boundaries to constrain generation of candidate stems and affixes and clustering morphological variants of a given word stem. We evaluate our model on English and the Mayan language Uspanteko; it compares favorably to two benchmark systems which use considerably more complex strategies and rely more on experimentally chosen threshold values. 1 Introduction Unsupervised morphology acquisition attempts to learn from raw corpora one or more of the following about the written morphology of a language: (1) the segmentation of the set of word types in a corpus (Creutz and Lagus, 2007), (2) the clustering of word types in a corpus based on some notion of morphological relatedness (Schone and Jurafsky, 2000), (3) the generation of out-of-vocabulary items which are morphologically related to other word types in the corpus (Yarowsky et al., 2001). We take a novel approach to segmenting words and clustering morphologically related words. The approach uses no parameters that need to be tuned on data. The two main ideas of the approach are (a) the filtering of affixes by significant co-occurrence, and (b) the integration of knowledge of document boundaries when generating candida</context>
<context position="4971" citStr="Creutz and Lagus, 2007" startWordPosition="762" endWordPosition="765">standard thresholds–a significance threshold and a lower bound on observed counts. These are the only manually set parameters we require—and we in fact use the widely accepted standard values for these thresholds without varying them in our experiments. This is a significant improvement over other approaches that typically require a number of arbitrary thresholds and parameters yet provide little intuitive justification for them. (We give examples of these in §3.) We evaluate our approach on two languages, English and Uspanteko, and compare its performance to two benchmark systems, Morfessor (Creutz and Lagus, 2007) and Linguistica (Goldsmith, 2001). English is commonly used in other studies and permits the use of CELEX as a gold standard for evaluation. Uspanteko is an endangered Mayan language for which we have a set of interlinearized glossed texts (IGT) (Pixabaj et al., 2007; Palmer et al., 2009). IGT provides wordby-word morpheme segmenation, which we use to create a synthetic gold standard. In addition to evaluation against this standard, Telma Kaan Pixabaj—a Mayan linguist who helped create the annotated corpus—reviewed by hand 100 word clusters produced by our system, Morfessor and Linguistica. N</context>
<context position="9429" citStr="Creutz and Lagus, 2007" startWordPosition="1442" endWordPosition="1445"> Hafer and Weiss (1974) counts how many types of characters appear after some initial string (the successor count) and how many types of characters appear before some final string (the predecessor count). A successful criterion for segmenting a word was if the predecessor count for the second part was greater than 17 and the successor count for the first part was greater than 5. Other studies have similar data specific parameters and restrictions. MDL and Bayesian models. Minimum description length (MDL) models (Goldsmith, 2001; Creutz and Lagus, 2002; Creutz and Lagus, 2004; Goldsmith, 2006; Creutz and Lagus, 2007) try to segment words by maximizing the probability of a training corpus subject to a penalty based on the size of hypothesized morpheme lexicons they build on the basis of the segmentations. While theoretically elegant, a pure implementation on real data results in descriptions that do not reflect actual morphology. Creutz and Lagus (2005) report that, “frequent word forms remain unsplit, whereas rare word forms are excessively split.” In the end, every MDL approach uses probabilistically motivated refinements that restrict the tendency of raw MDL to generate descriptions that do not fit ling</context>
<context position="28569" citStr="Creutz and Lagus, 2007" startWordPosition="4766" endWordPosition="4769">(using the last k characters). We set the values of 0 &lt; k &lt; max, where max is the length of the longest string, and plot the results in a precision-recall graph (Fig. 2). Low k corresponds to high recall and low precision while high k shows the opposite. The contrast in morphological patterns for each language can also be seen. Because Uspanteko is morphologically complex with suffixes and prefixes, a very simple strategy cannot achieve high recall as opposed to English where it is possible to retrieve all variants with a simple prefix tree. We use Linguistica (Goldsmith, 2001) and Morfessor (Creutz and Lagus, 2007) as benchmarks. We used the default settings for these programs. Note that comparison with these tools is not com6Given a model cluster Ci and the “misses” for each cluster Mi, accuracy is measured as 1/N Pi ( |Ci |− |Mi |) /( |Ci |) where N is the sample size. Full cluster accuracy is the number of clusters that did not have any misses over N. 100 90 80 70 60 50 40 0 10 20 30 40 50 60 70 80 90 100 mini−NYT NYT Usp−S Usp−P X C = w XZ = w X X. X Y. X X. X Y. XD = X X. X Y. 674 MINI-NYT NYT P R F P R F LINGUISTICA 64.30 93.34 76.15 47.50 88.33 61.77 MORFESSOR 45.2 87.8 59.7 63.6 69.2 66.3 CandGe</context>
</contexts>
<marker>Creutz, Lagus, 2007</marker>
<rawString>M. Creutz and K. Lagus. 2007. Unsupervised models for morpheme segmentation and morphology learning. ACM Trans. Speech Lang. Process., 4(1):3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Dasgupta</author>
<author>V Ng</author>
</authors>
<title>High-performance, language-independent morphological segmentation.</title>
<date>2007</date>
<booktitle>In NAACL-HLT,</booktitle>
<pages>155--163</pages>
<contexts>
<context position="8611" citStr="Dasgupta and Ng, 2007" startWordPosition="1309" endWordPosition="1312">(e.g., Goldsmith (2001)). Like Schone and Jurafsky (2001), we build clusters that will have both inflectionally and derivationally related stems and evaluate them with respect to a gold standard of only inflectionally related stems. 3 Related work There is a diverse body of existing work on unsupervised morphology acquisition. We summarize previous work, emphasizing some of its more arbitrary and ad hoc aspects. Letter successor variety. Letter successor variety (LSV) models (Hafer and Weiss, 1974; Gaussier, 1999; Bernhard, 2005; Bordag, 2005; 669 Keshava and Pitler, 2005; Hammarstr¨om, 2006; Dasgupta and Ng, 2007; Demberg, 2007) use the hypothesis that there is less certainty when predicting the next character at morpheme boundaries. LSV has several issues that require fine parameter tuning. For example, Hafer and Weiss (1974) counts how many types of characters appear after some initial string (the successor count) and how many types of characters appear before some final string (the predecessor count). A successful criterion for segmenting a word was if the predecessor count for the second part was greater than 17 and the successor count for the first part was greater than 5. Other studies have simi</context>
</contexts>
<marker>Dasgupta, Ng, 2007</marker>
<rawString>S. Dasgupta and V. Ng. 2007. High-performance, language-independent morphological segmentation. In NAACL-HLT, pages 155–163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Demberg</author>
</authors>
<title>A language-independent unsupervised model for morphological segmentation.</title>
<date>2007</date>
<booktitle>In ACL ’07,</booktitle>
<volume>45</volume>
<pages>920</pages>
<contexts>
<context position="8627" citStr="Demberg, 2007" startWordPosition="1313" endWordPosition="1314">). Like Schone and Jurafsky (2001), we build clusters that will have both inflectionally and derivationally related stems and evaluate them with respect to a gold standard of only inflectionally related stems. 3 Related work There is a diverse body of existing work on unsupervised morphology acquisition. We summarize previous work, emphasizing some of its more arbitrary and ad hoc aspects. Letter successor variety. Letter successor variety (LSV) models (Hafer and Weiss, 1974; Gaussier, 1999; Bernhard, 2005; Bordag, 2005; 669 Keshava and Pitler, 2005; Hammarstr¨om, 2006; Dasgupta and Ng, 2007; Demberg, 2007) use the hypothesis that there is less certainty when predicting the next character at morpheme boundaries. LSV has several issues that require fine parameter tuning. For example, Hafer and Weiss (1974) counts how many types of characters appear after some initial string (the successor count) and how many types of characters appear before some final string (the predecessor count). A successful criterion for segmenting a word was if the predecessor count for the second part was greater than 17 and the successor count for the first part was greater than 5. Other studies have similar data specifi</context>
</contexts>
<marker>Demberg, 2007</marker>
<rawString>V. Demberg. 2007. A language-independent unsupervised model for morphological segmentation. In ACL ’07, volume 45, page 920.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Freitag</author>
</authors>
<title>Morphology induction from term clusters.</title>
<date>2005</date>
<journal>In CoNLL</journal>
<volume>05</volume>
<contexts>
<context position="7198" citStr="Freitag, 2005" startWordPosition="1090" endWordPosition="1091">on stem, and generation of new word forms with productive affixes. Intuitively, there are straightforward, but non-trivial, challenges that arise when evaluating a model. One large challenge is distinguishing derivational from inflectional morphology. Most approaches deal with tokens without considering context. Since inflectional morphology is virtually always driven by syntax and word context, such approaches are unable to learn only inflectional morphology or only derivational morphology. Even approaches which take context into consideration (Schone and Jurafsky, 2000; Baroni et al., 2002; Freitag, 2005) cannot learn specifically for one or the other. In addition, the evaluation of both segmentation and clustering involves arbitrary judgment calls. Concerning segmentation, should altimeter and altitude be one morpheme or two? (The sample English gold standard for MorphoChallenge 2009 provides alti+meter but altitude.) Similar issues arise when evaluating clusters of related word forms if inflection and derivation are not distinguished. Does atheism belong to the same cluster as theism? Where is the frequency cutoff point between a productive derivational morpheme and an unproductive one? Yet,</context>
<context position="11257" citStr="Freitag (2005)" startWordPosition="1730" endWordPosition="1731">rds starting with an unrefined trie search (but with a parameter of minimum possible stem length and an upper bound on potential affix candidates) that is constrained by semantic similarity in a word context vector space. Schone and Jurafsky (2001) builds on this approach, but adds more ad hoc parameters to handle circumfixation. Baroni et al. (2002) takes a similar approach but uses edit distance to cluster words that are similar but do not necessarily share a long, contiguous substring. They remove noise by constraining cluster membership with mutual information derived semantic similarity. Freitag (2005) uses a mutual information derived measure to learn the syntactic similarity between words and clusters them. Then he derives finite state machines across words in different clusters and refines them through a graph walk algorithm. This group is the only one to evaluate against CELEX (Schone and Jurafsky, 2000; Schone and Jurafsky, 2001; Freitag, 2005). Others. Some other models require input such as POS tables and lexicons and use a wider range of information about the corpus (Yarowsky and Wicentowski, 2000; Yarowsky et al., 2001; Chan, 2006). Because of the knowledge dependence of these mode</context>
<context position="25386" citStr="Freitag, 2005" startWordPosition="4224" endWordPosition="4225">and cleaned up (Palmer et al., 2009). All counts are for lowercased, punctuation-removed word forms. CELEX. The CELEX lexical database (Baayen et al., 1993) has been built for Dutch, English and German and provides detailed entries that list and analyze the morphological properties of words, among other information. Using CELEX, we evaluate on types rather than tokens. The performance of the model is based on how many of the words it judges to be morphologically related overlap with the entries in CELEX. Following previous work (Schone and Jurafsky, 2000; Schone and Jurafsky, 673 recall 2001; Freitag, 2005), we evaluate on inflectional clusters only, using the CELEX file listing clusters of inflectional variants. 5 6 Experiments and evaluation We outline our evaluation methodology, baselines, benchmarks and results, and discuss the results. 6.1 Evaluation metric Schone and Jurafsky (2000) give definitions for correct (C), inserted (Z), and deleted (D) words in model-derived conflation sets in relation to a gold standard. Their formulation does not allow for multiple cluster membership of words. We extend the definition to incorporate this fact about the data. Let w be a word form. We write Xw fo</context>
</contexts>
<marker>Freitag, 2005</marker>
<rawString>D. Freitag. 2005. Morphology induction from term clusters. In CoNLL ’05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Gaussier</author>
</authors>
<title>Unsupervised learning of derivational morphology from inflectional lexicons.</title>
<date>1999</date>
<booktitle>In ACL workshop on Unsupervised Methods in Natural Language Learning.</booktitle>
<contexts>
<context position="8508" citStr="Gaussier, 1999" startWordPosition="1296" endWordPosition="1297">y word, cluster by cluster and judging by sight whether some segmentation or clustering is good (e.g., Goldsmith (2001)). Like Schone and Jurafsky (2001), we build clusters that will have both inflectionally and derivationally related stems and evaluate them with respect to a gold standard of only inflectionally related stems. 3 Related work There is a diverse body of existing work on unsupervised morphology acquisition. We summarize previous work, emphasizing some of its more arbitrary and ad hoc aspects. Letter successor variety. Letter successor variety (LSV) models (Hafer and Weiss, 1974; Gaussier, 1999; Bernhard, 2005; Bordag, 2005; 669 Keshava and Pitler, 2005; Hammarstr¨om, 2006; Dasgupta and Ng, 2007; Demberg, 2007) use the hypothesis that there is less certainty when predicting the next character at morpheme boundaries. LSV has several issues that require fine parameter tuning. For example, Hafer and Weiss (1974) counts how many types of characters appear after some initial string (the successor count) and how many types of characters appear before some final string (the predecessor count). A successful criterion for segmenting a word was if the predecessor count for the second part was</context>
</contexts>
<marker>Gaussier, 1999</marker>
<rawString>E. Gaussier. 1999. Unsupervised learning of derivational morphology from inflectional lexicons. In ACL workshop on Unsupervised Methods in Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Goldsmith</author>
</authors>
<title>Unsupervised learning of the morphology of a natural language.</title>
<date>2001</date>
<journal>Comp. Ling.,</journal>
<volume>27</volume>
<issue>2</issue>
<contexts>
<context position="5005" citStr="Goldsmith, 2001" startWordPosition="768" endWordPosition="770">old and a lower bound on observed counts. These are the only manually set parameters we require—and we in fact use the widely accepted standard values for these thresholds without varying them in our experiments. This is a significant improvement over other approaches that typically require a number of arbitrary thresholds and parameters yet provide little intuitive justification for them. (We give examples of these in §3.) We evaluate our approach on two languages, English and Uspanteko, and compare its performance to two benchmark systems, Morfessor (Creutz and Lagus, 2007) and Linguistica (Goldsmith, 2001). English is commonly used in other studies and permits the use of CELEX as a gold standard for evaluation. Uspanteko is an endangered Mayan language for which we have a set of interlinearized glossed texts (IGT) (Pixabaj et al., 2007; Palmer et al., 2009). IGT provides wordby-word morpheme segmenation, which we use to create a synthetic gold standard. In addition to evaluation against this standard, Telma Kaan Pixabaj—a Mayan linguist who helped create the annotated corpus—reviewed by hand 100 word clusters produced by our system, Morfessor and Linguistica. Note that because English is suffix</context>
<context position="8013" citStr="Goldsmith (2001)" startWordPosition="1215" endWordPosition="1216">ude be one morpheme or two? (The sample English gold standard for MorphoChallenge 2009 provides alti+meter but altitude.) Similar issues arise when evaluating clusters of related word forms if inflection and derivation are not distinguished. Does atheism belong to the same cluster as theism? Where is the frequency cutoff point between a productive derivational morpheme and an unproductive one? Yet, many studies have evaluated their segmentations and clusters by going over their results word by word, cluster by cluster and judging by sight whether some segmentation or clustering is good (e.g., Goldsmith (2001)). Like Schone and Jurafsky (2001), we build clusters that will have both inflectionally and derivationally related stems and evaluate them with respect to a gold standard of only inflectionally related stems. 3 Related work There is a diverse body of existing work on unsupervised morphology acquisition. We summarize previous work, emphasizing some of its more arbitrary and ad hoc aspects. Letter successor variety. Letter successor variety (LSV) models (Hafer and Weiss, 1974; Gaussier, 1999; Bernhard, 2005; Bordag, 2005; 669 Keshava and Pitler, 2005; Hammarstr¨om, 2006; Dasgupta and Ng, 2007; </context>
<context position="9339" citStr="Goldsmith, 2001" startWordPosition="1430" endWordPosition="1431">oundaries. LSV has several issues that require fine parameter tuning. For example, Hafer and Weiss (1974) counts how many types of characters appear after some initial string (the successor count) and how many types of characters appear before some final string (the predecessor count). A successful criterion for segmenting a word was if the predecessor count for the second part was greater than 17 and the successor count for the first part was greater than 5. Other studies have similar data specific parameters and restrictions. MDL and Bayesian models. Minimum description length (MDL) models (Goldsmith, 2001; Creutz and Lagus, 2002; Creutz and Lagus, 2004; Goldsmith, 2006; Creutz and Lagus, 2007) try to segment words by maximizing the probability of a training corpus subject to a penalty based on the size of hypothesized morpheme lexicons they build on the basis of the segmentations. While theoretically elegant, a pure implementation on real data results in descriptions that do not reflect actual morphology. Creutz and Lagus (2005) report that, “frequent word forms remain unsplit, whereas rare word forms are excessively split.” In the end, every MDL approach uses probabilistically motivated refin</context>
<context position="28530" citStr="Goldsmith, 2001" startWordPosition="4761" endWordPosition="4762">ree, and for USP in suffix tree (using the last k characters). We set the values of 0 &lt; k &lt; max, where max is the length of the longest string, and plot the results in a precision-recall graph (Fig. 2). Low k corresponds to high recall and low precision while high k shows the opposite. The contrast in morphological patterns for each language can also be seen. Because Uspanteko is morphologically complex with suffixes and prefixes, a very simple strategy cannot achieve high recall as opposed to English where it is possible to retrieve all variants with a simple prefix tree. We use Linguistica (Goldsmith, 2001) and Morfessor (Creutz and Lagus, 2007) as benchmarks. We used the default settings for these programs. Note that comparison with these tools is not com6Given a model cluster Ci and the “misses” for each cluster Mi, accuracy is measured as 1/N Pi ( |Ci |− |Mi |) /( |Ci |) where N is the sample size. Full cluster accuracy is the number of clusters that did not have any misses over N. 100 90 80 70 60 50 40 0 10 20 30 40 50 60 70 80 90 100 mini−NYT NYT Usp−S Usp−P X C = w XZ = w X X. X Y. X X. X Y. XD = X X. X Y. 674 MINI-NYT NYT P R F P R F LINGUISTICA 64.30 93.34 76.15 47.50 88.33 61.77 MORFESS</context>
</contexts>
<marker>Goldsmith, 2001</marker>
<rawString>J. Goldsmith. 2001. Unsupervised learning of the morphology of a natural language. Comp. Ling., 27(2):153–198.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Goldsmith</author>
</authors>
<title>An algorithm for the unsupervised learning of morphology.</title>
<date>2006</date>
<journal>Natural Language Engineering,</journal>
<volume>12</volume>
<issue>04</issue>
<contexts>
<context position="9404" citStr="Goldsmith, 2006" startWordPosition="1440" endWordPosition="1441">ing. For example, Hafer and Weiss (1974) counts how many types of characters appear after some initial string (the successor count) and how many types of characters appear before some final string (the predecessor count). A successful criterion for segmenting a word was if the predecessor count for the second part was greater than 17 and the successor count for the first part was greater than 5. Other studies have similar data specific parameters and restrictions. MDL and Bayesian models. Minimum description length (MDL) models (Goldsmith, 2001; Creutz and Lagus, 2002; Creutz and Lagus, 2004; Goldsmith, 2006; Creutz and Lagus, 2007) try to segment words by maximizing the probability of a training corpus subject to a penalty based on the size of hypothesized morpheme lexicons they build on the basis of the segmentations. While theoretically elegant, a pure implementation on real data results in descriptions that do not reflect actual morphology. Creutz and Lagus (2005) report that, “frequent word forms remain unsplit, whereas rare word forms are excessively split.” In the end, every MDL approach uses probabilistically motivated refinements that restrict the tendency of raw MDL to generate descript</context>
</contexts>
<marker>Goldsmith, 2006</marker>
<rawString>J. Goldsmith. 2006. An algorithm for the unsupervised learning of morphology. Natural Language Engineering, 12(04):353–371.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S J Goldwater</author>
</authors>
<title>Nonparametric Bayesian models of lexical acquisition.</title>
<date>2007</date>
<tech>Ph.D. thesis,</tech>
<institution>Brown University.</institution>
<contexts>
<context position="10241" citStr="Goldwater, 2007" startWordPosition="1575" endWordPosition="1576">e theoretically elegant, a pure implementation on real data results in descriptions that do not reflect actual morphology. Creutz and Lagus (2005) report that, “frequent word forms remain unsplit, whereas rare word forms are excessively split.” In the end, every MDL approach uses probabilistically motivated refinements that restrict the tendency of raw MDL to generate descriptions that do not fit linguistic notions of morphology. Despite the sophistication of the models in this group, there are many parameters that need to be set, and heuristic search procedures are crucial for their success (Goldwater, 2007). Snover et al. (2002) present a Bayesian model that uses a prior distribution to refine disjoint clusters of morphologically related words. It disposes with parameter setting by selecting the highest ranking hypothesis. Context aware approaches. A word’s morphology is strongly influenced by its syntactic and semantic context. Schone and Jurafsky (2000) attempts to cluster morphologically related words starting with an unrefined trie search (but with a parameter of minimum possible stem length and an upper bound on potential affix candidates) that is constrained by semantic similarity in a wor</context>
</contexts>
<marker>Goldwater, 2007</marker>
<rawString>S.J. Goldwater. 2007. Nonparametric Bayesian models of lexical acquisition. Ph.D. thesis, Brown University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Hafer</author>
<author>S F Weiss</author>
</authors>
<title>Word Segmentation by Letter Successor Varieties. Information Storage and Retrieval,</title>
<date>1974</date>
<pages>10--371</pages>
<contexts>
<context position="8492" citStr="Hafer and Weiss, 1974" startWordPosition="1292" endWordPosition="1295">er their results word by word, cluster by cluster and judging by sight whether some segmentation or clustering is good (e.g., Goldsmith (2001)). Like Schone and Jurafsky (2001), we build clusters that will have both inflectionally and derivationally related stems and evaluate them with respect to a gold standard of only inflectionally related stems. 3 Related work There is a diverse body of existing work on unsupervised morphology acquisition. We summarize previous work, emphasizing some of its more arbitrary and ad hoc aspects. Letter successor variety. Letter successor variety (LSV) models (Hafer and Weiss, 1974; Gaussier, 1999; Bernhard, 2005; Bordag, 2005; 669 Keshava and Pitler, 2005; Hammarstr¨om, 2006; Dasgupta and Ng, 2007; Demberg, 2007) use the hypothesis that there is less certainty when predicting the next character at morpheme boundaries. LSV has several issues that require fine parameter tuning. For example, Hafer and Weiss (1974) counts how many types of characters appear after some initial string (the successor count) and how many types of characters appear before some final string (the predecessor count). A successful criterion for segmenting a word was if the predecessor count for the</context>
</contexts>
<marker>Hafer, Weiss, 1974</marker>
<rawString>M.A. Hafer and S.F. Weiss. 1974. Word Segmentation by Letter Successor Varieties. Information Storage and Retrieval, 10:371–385.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Hammarstr¨om</author>
</authors>
<title>A naive theory of affixation and an algorithm for extraction.</title>
<date>2006</date>
<booktitle>In ACL SIGPHON ’06,</booktitle>
<pages>79--88</pages>
<marker>Hammarstr¨om, 2006</marker>
<rawString>H. Hammarstr¨om. 2006. A naive theory of affixation and an algorithm for extraction. In ACL SIGPHON ’06, pages 79–88, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Keshava</author>
<author>E Pitler</author>
</authors>
<title>A simpler, intuitive approach to morpheme induction.</title>
<date>2005</date>
<booktitle>In Proceedings of Morpho Challenge</booktitle>
<pages>28--32</pages>
<contexts>
<context position="8568" citStr="Keshava and Pitler, 2005" startWordPosition="1303" endWordPosition="1306">ether some segmentation or clustering is good (e.g., Goldsmith (2001)). Like Schone and Jurafsky (2001), we build clusters that will have both inflectionally and derivationally related stems and evaluate them with respect to a gold standard of only inflectionally related stems. 3 Related work There is a diverse body of existing work on unsupervised morphology acquisition. We summarize previous work, emphasizing some of its more arbitrary and ad hoc aspects. Letter successor variety. Letter successor variety (LSV) models (Hafer and Weiss, 1974; Gaussier, 1999; Bernhard, 2005; Bordag, 2005; 669 Keshava and Pitler, 2005; Hammarstr¨om, 2006; Dasgupta and Ng, 2007; Demberg, 2007) use the hypothesis that there is less certainty when predicting the next character at morpheme boundaries. LSV has several issues that require fine parameter tuning. For example, Hafer and Weiss (1974) counts how many types of characters appear after some initial string (the successor count) and how many types of characters appear before some final string (the predecessor count). A successful criterion for segmenting a word was if the predecessor count for the second part was greater than 17 and the successor count for the first part </context>
</contexts>
<marker>Keshava, Pitler, 2005</marker>
<rawString>S. Keshava and E. Pitler. 2005. A simpler, intuitive approach to morpheme induction. In Proceedings of Morpho Challenge 2005, pages 28–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Monson</author>
</authors>
<title>A framework for unsupervised natural language morphology induction.</title>
<date>2004</date>
<booktitle>In Proceedings of the Student Workshop at ACL,</booktitle>
<volume>4</volume>
<contexts>
<context position="6345" citStr="Monson (2004)" startWordPosition="968" endWordPosition="969"> paper compares favorably to Linguistica and Morfessor, two models that employ much more complex strategies and rely on experimentally-tuned language/corpusspecific parameters. In our evaluation, document boundary awareness greatly benefits precision for small datasets, blocking acquisition of spurious affixes. For large datasets, global candidate generation outperforms document-aware candidate generation at the task of filtering out spurious stems, but document-aware clustering improves precision. These findings are promising for the application of this approach to under-resourced languages 1Monson (2004) suggests, but does not actually use, χ2. like Uspanteko. 2 Unsupervised morphology acquisition Unsupervised morphology acquisition aims to model one or more of three properties of written morphology: segmentation, clustering around a common stem, and generation of new word forms with productive affixes. Intuitively, there are straightforward, but non-trivial, challenges that arise when evaluating a model. One large challenge is distinguishing derivational from inflectional morphology. Most approaches deal with tokens without considering context. Since inflectional morphology is virtually alwa</context>
</contexts>
<marker>Monson, 2004</marker>
<rawString>C. Monson. 2004. A framework for unsupervised natural language morphology induction. In Proceedings of the Student Workshop at ACL, volume 4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexis Palmer</author>
<author>Taesun Moon</author>
<author>Jason Baldridge</author>
</authors>
<title>Evaluating automation strategies in language documentation.</title>
<date>2009</date>
<booktitle>In Proceedings of the NAACL HLT 2009 Workshop on Active Learningfor Natural Language Processing,</booktitle>
<pages>36--44</pages>
<location>Boulder, CO.</location>
<contexts>
<context position="2147" citStr="Palmer et al., 2009" startWordPosition="324" endWordPosition="327">er word types in the corpus (Yarowsky et al., 2001). We take a novel approach to segmenting words and clustering morphologically related words. The approach uses no parameters that need to be tuned on data. The two main ideas of the approach are (a) the filtering of affixes by significant co-occurrence, and (b) the integration of knowledge of document boundaries when generating candidate stems and affixes and when clustering morphologically related words. The main application that we envision for our approach is to produce interlinearized glossed texts for underresourced/endangered languages (Palmer et al., 2009). Thus, we strive to eliminate hand-tuned parameters to enable documentary linguists to use our model as a preprocessing step for their manual analysis of stems and affixes. To require a documentary linguist–who is likely to have little to no knowledge of NLP methods–to tune parameters is unfeasible. Additionally, data-driven exploration of parameter settings is unlikely to be reliable in language documentation since datasets typically are quite small. To be relevant in this context, a model needs to produce useful results out of the box. Constraining learning by using document boundaries has </context>
<context position="5261" citStr="Palmer et al., 2009" startWordPosition="812" endWordPosition="815">other approaches that typically require a number of arbitrary thresholds and parameters yet provide little intuitive justification for them. (We give examples of these in §3.) We evaluate our approach on two languages, English and Uspanteko, and compare its performance to two benchmark systems, Morfessor (Creutz and Lagus, 2007) and Linguistica (Goldsmith, 2001). English is commonly used in other studies and permits the use of CELEX as a gold standard for evaluation. Uspanteko is an endangered Mayan language for which we have a set of interlinearized glossed texts (IGT) (Pixabaj et al., 2007; Palmer et al., 2009). IGT provides wordby-word morpheme segmenation, which we use to create a synthetic gold standard. In addition to evaluation against this standard, Telma Kaan Pixabaj—a Mayan linguist who helped create the annotated corpus—reviewed by hand 100 word clusters produced by our system, Morfessor and Linguistica. Note that because English is suffixal and Uspanteko is both prefixal and suffixal, we use a slightly modified model for Uspanteko. The approach introduced in this paper compares favorably to Linguistica and Morfessor, two models that employ much more complex strategies and rely on experimen</context>
<context position="24808" citStr="Palmer et al., 2009" startWordPosition="4130" endWordPosition="4133">. Learning corpora. For English, we use two subsets of the NYTimes portion in the Gigaword corpus which we will call NYT and MINI-NYT. NYT in the current study is the complete collection of articles in the New York Times from June, 2002. NYT has 10K articles, 88K types and 9M tokens. MINI-NYT is a subset of NYT with 190 articles, 15K types and 187K tokens. The Uspanteko text, USP has 29 distinct texts, 7K types, and 50K tokens. The texts are from OKMA (Pixabaj et al., 2007) and the segmentation and labels of the interlinear glossed text annotations were checked for consistency and cleaned up (Palmer et al., 2009). All counts are for lowercased, punctuation-removed word forms. CELEX. The CELEX lexical database (Baayen et al., 1993) has been built for Dutch, English and German and provides detailed entries that list and analyze the morphological properties of words, among other information. Using CELEX, we evaluate on types rather than tokens. The performance of the model is based on how many of the words it judges to be morphologically related overlap with the entries in CELEX. Following previous work (Schone and Jurafsky, 2000; Schone and Jurafsky, 673 recall 2001; Freitag, 2005), we evaluate on infle</context>
</contexts>
<marker>Palmer, Moon, Baldridge, 2009</marker>
<rawString>Alexis Palmer, Taesun Moon, and Jason Baldridge. 2009. Evaluating automation strategies in language documentation. In Proceedings of the NAACL HLT 2009 Workshop on Active Learningfor Natural Language Processing, pages 36–44, Boulder, CO.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T C Pixabaj</author>
<author>M A Vicente M´endez</author>
<author>M Vicente M´endez</author>
<author>O A Dami´an</author>
</authors>
<date>2007</date>
<booktitle>Text collections in Four Mayan Languages. Archived in The Archive of the Indigenous Languages of Latin</booktitle>
<publisher>America.</publisher>
<marker>Pixabaj, M´endez, M´endez, Dami´an, 2007</marker>
<rawString>T.C. Pixabaj, M.A. Vicente M´endez, M. Vicente M´endez, and O.A. Dami´an. 2007. Text collections in Four Mayan Languages. Archived in The Archive of the Indigenous Languages of Latin America.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Schone</author>
<author>D Jurafsky</author>
</authors>
<title>Knowledge-free induction of morphology using latent sematic analysis.</title>
<date>2000</date>
<booktitle>In CoNLL-2000 and LLL-2000.</booktitle>
<contexts>
<context position="1439" citStr="Schone and Jurafsky, 2000" startWordPosition="214" endWordPosition="218">rphological variants of a given word stem. We evaluate our model on English and the Mayan language Uspanteko; it compares favorably to two benchmark systems which use considerably more complex strategies and rely more on experimentally chosen threshold values. 1 Introduction Unsupervised morphology acquisition attempts to learn from raw corpora one or more of the following about the written morphology of a language: (1) the segmentation of the set of word types in a corpus (Creutz and Lagus, 2007), (2) the clustering of word types in a corpus based on some notion of morphological relatedness (Schone and Jurafsky, 2000), (3) the generation of out-of-vocabulary items which are morphologically related to other word types in the corpus (Yarowsky et al., 2001). We take a novel approach to segmenting words and clustering morphologically related words. The approach uses no parameters that need to be tuned on data. The two main ideas of the approach are (a) the filtering of affixes by significant co-occurrence, and (b) the integration of knowledge of document boundaries when generating candidate stems and affixes and when clustering morphologically related words. The main application that we envision for our approa</context>
<context position="3820" citStr="Schone and Jurafsky (2000)" startWordPosition="580" endWordPosition="583">graphy, then the two words are likely to be related morphologically. We measure how integrating these assumptions into our model at different stages affects performance. We define a simple pipeline model. After generating candidate stems and affixes (possibly constrained by document boundaries), a χ2 test based on global corpus counts filters out unlikely affixes. Mutually consistent affix pairs are then clustered to form affix groups. These in turn are used to build morphologically related word clusters, possibly constrained by evidence from co-occurence of word forms in documents. Following Schone and Jurafsky (2000), clusters are evaluated for 668 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 668–677, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP whether they capture inflectional paradigms using CELEX (Baayen et al., 1993). We are unaware of other work on morphology using χ2 tests despite its wide application across many disciplines.1 This may be due to the large degree of noise found in the candidate affix sets induced through other candidate generation methods. The χ2 test has two standard thresholds–a significance threshold and a lower bound on observ</context>
<context position="7161" citStr="Schone and Jurafsky, 2000" startWordPosition="1081" endWordPosition="1085">rphology: segmentation, clustering around a common stem, and generation of new word forms with productive affixes. Intuitively, there are straightforward, but non-trivial, challenges that arise when evaluating a model. One large challenge is distinguishing derivational from inflectional morphology. Most approaches deal with tokens without considering context. Since inflectional morphology is virtually always driven by syntax and word context, such approaches are unable to learn only inflectional morphology or only derivational morphology. Even approaches which take context into consideration (Schone and Jurafsky, 2000; Baroni et al., 2002; Freitag, 2005) cannot learn specifically for one or the other. In addition, the evaluation of both segmentation and clustering involves arbitrary judgment calls. Concerning segmentation, should altimeter and altitude be one morpheme or two? (The sample English gold standard for MorphoChallenge 2009 provides alti+meter but altitude.) Similar issues arise when evaluating clusters of related word forms if inflection and derivation are not distinguished. Does atheism belong to the same cluster as theism? Where is the frequency cutoff point between a productive derivational m</context>
<context position="10596" citStr="Schone and Jurafsky (2000)" startWordPosition="1626" endWordPosition="1629">cy of raw MDL to generate descriptions that do not fit linguistic notions of morphology. Despite the sophistication of the models in this group, there are many parameters that need to be set, and heuristic search procedures are crucial for their success (Goldwater, 2007). Snover et al. (2002) present a Bayesian model that uses a prior distribution to refine disjoint clusters of morphologically related words. It disposes with parameter setting by selecting the highest ranking hypothesis. Context aware approaches. A word’s morphology is strongly influenced by its syntactic and semantic context. Schone and Jurafsky (2000) attempts to cluster morphologically related words starting with an unrefined trie search (but with a parameter of minimum possible stem length and an upper bound on potential affix candidates) that is constrained by semantic similarity in a word context vector space. Schone and Jurafsky (2001) builds on this approach, but adds more ad hoc parameters to handle circumfixation. Baroni et al. (2002) takes a similar approach but uses edit distance to cluster words that are similar but do not necessarily share a long, contiguous substring. They remove noise by constraining cluster membership with m</context>
<context position="12297" citStr="Schone and Jurafsky, 2000" startWordPosition="1898" endWordPosition="1902"> and lexicons and use a wider range of information about the corpus (Yarowsky and Wicentowski, 2000; Yarowsky et al., 2001; Chan, 2006). Because of the knowledge dependence of these models, they are able to properly induce inflectional morphology, as opposed to the studies cited above. Snyder and Barzilay (2008) uses a set of aligned phrases across related languages to learn how to segment words with a Bayesian model and is otherwise fully unsupervised. 4 Model2 Our goal is to generate conflation sets: sets of word types that are related through either inflectional or derivational morphology (Schone and Jurafsky, 2000). Solving this task requires learning how individual types are segmented (though the segmentation itself is not evaluated). For present purposes, we assume that the affixal pattern of the language is known: whether it is prefixal, suffixal, or both. To simplify presentation, we discuss a model that captures suffixes only. Our approach is a four stage process: 1. Candidate Generation: generate candidate stems and affixes using an orthographically defined data structure (a trie) 2. Candidate Filtering: filter candidate affixes using the statistical significance for pairs of affixes based on thei</context>
<context position="25332" citStr="Schone and Jurafsky, 2000" startWordPosition="4214" endWordPosition="4217">nterlinear glossed text annotations were checked for consistency and cleaned up (Palmer et al., 2009). All counts are for lowercased, punctuation-removed word forms. CELEX. The CELEX lexical database (Baayen et al., 1993) has been built for Dutch, English and German and provides detailed entries that list and analyze the morphological properties of words, among other information. Using CELEX, we evaluate on types rather than tokens. The performance of the model is based on how many of the words it judges to be morphologically related overlap with the entries in CELEX. Following previous work (Schone and Jurafsky, 2000; Schone and Jurafsky, 673 recall 2001; Freitag, 2005), we evaluate on inflectional clusters only, using the CELEX file listing clusters of inflectional variants. 5 6 Experiments and evaluation We outline our evaluation methodology, baselines, benchmarks and results, and discuss the results. 6.1 Evaluation metric Schone and Jurafsky (2000) give definitions for correct (C), inserted (Z), and deleted (D) words in model-derived conflation sets in relation to a gold standard. Their formulation does not allow for multiple cluster membership of words. We extend the definition to incorporate this fac</context>
</contexts>
<marker>Schone, Jurafsky, 2000</marker>
<rawString>P. Schone and D. Jurafsky. 2000. Knowledge-free induction of morphology using latent sematic analysis. In CoNLL-2000 and LLL-2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Schone</author>
<author>D Jurafsky</author>
</authors>
<title>Knowledge-free induction of inflectional morphologies.</title>
<date>2001</date>
<booktitle>In NAACL ’01,</booktitle>
<pages>1--9</pages>
<contexts>
<context position="8047" citStr="Schone and Jurafsky (2001)" startWordPosition="1218" endWordPosition="1221">wo? (The sample English gold standard for MorphoChallenge 2009 provides alti+meter but altitude.) Similar issues arise when evaluating clusters of related word forms if inflection and derivation are not distinguished. Does atheism belong to the same cluster as theism? Where is the frequency cutoff point between a productive derivational morpheme and an unproductive one? Yet, many studies have evaluated their segmentations and clusters by going over their results word by word, cluster by cluster and judging by sight whether some segmentation or clustering is good (e.g., Goldsmith (2001)). Like Schone and Jurafsky (2001), we build clusters that will have both inflectionally and derivationally related stems and evaluate them with respect to a gold standard of only inflectionally related stems. 3 Related work There is a diverse body of existing work on unsupervised morphology acquisition. We summarize previous work, emphasizing some of its more arbitrary and ad hoc aspects. Letter successor variety. Letter successor variety (LSV) models (Hafer and Weiss, 1974; Gaussier, 1999; Bernhard, 2005; Bordag, 2005; 669 Keshava and Pitler, 2005; Hammarstr¨om, 2006; Dasgupta and Ng, 2007; Demberg, 2007) use the hypothesis </context>
<context position="10891" citStr="Schone and Jurafsky (2001)" startWordPosition="1672" endWordPosition="1675">resent a Bayesian model that uses a prior distribution to refine disjoint clusters of morphologically related words. It disposes with parameter setting by selecting the highest ranking hypothesis. Context aware approaches. A word’s morphology is strongly influenced by its syntactic and semantic context. Schone and Jurafsky (2000) attempts to cluster morphologically related words starting with an unrefined trie search (but with a parameter of minimum possible stem length and an upper bound on potential affix candidates) that is constrained by semantic similarity in a word context vector space. Schone and Jurafsky (2001) builds on this approach, but adds more ad hoc parameters to handle circumfixation. Baroni et al. (2002) takes a similar approach but uses edit distance to cluster words that are similar but do not necessarily share a long, contiguous substring. They remove noise by constraining cluster membership with mutual information derived semantic similarity. Freitag (2005) uses a mutual information derived measure to learn the syntactic similarity between words and clusters them. Then he derives finite state machines across words in different clusters and refines them through a graph walk algorithm. Th</context>
</contexts>
<marker>Schone, Jurafsky, 2001</marker>
<rawString>P. Schone and D. Jurafsky. 2001. Knowledge-free induction of inflectional morphologies. In NAACL ’01, pages 1–9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M G Snover</author>
<author>G E Jarosz</author>
<author>M R Brent</author>
</authors>
<title>Unsupervised learning of morphology using a novel directed search algorithm: taking the first step.</title>
<date>2002</date>
<booktitle>In ACL ’02 workshop on Morphological and phonological learning,</booktitle>
<pages>11--20</pages>
<contexts>
<context position="10263" citStr="Snover et al. (2002)" startWordPosition="1577" endWordPosition="1580">egant, a pure implementation on real data results in descriptions that do not reflect actual morphology. Creutz and Lagus (2005) report that, “frequent word forms remain unsplit, whereas rare word forms are excessively split.” In the end, every MDL approach uses probabilistically motivated refinements that restrict the tendency of raw MDL to generate descriptions that do not fit linguistic notions of morphology. Despite the sophistication of the models in this group, there are many parameters that need to be set, and heuristic search procedures are crucial for their success (Goldwater, 2007). Snover et al. (2002) present a Bayesian model that uses a prior distribution to refine disjoint clusters of morphologically related words. It disposes with parameter setting by selecting the highest ranking hypothesis. Context aware approaches. A word’s morphology is strongly influenced by its syntactic and semantic context. Schone and Jurafsky (2000) attempts to cluster morphologically related words starting with an unrefined trie search (but with a parameter of minimum possible stem length and an upper bound on potential affix candidates) that is constrained by semantic similarity in a word context vector space</context>
</contexts>
<marker>Snover, Jarosz, Brent, 2002</marker>
<rawString>M.G. Snover, G.E. Jarosz, and M.R. Brent. 2002. Unsupervised learning of morphology using a novel directed search algorithm: taking the first step. In ACL ’02 workshop on Morphological and phonological learning, pages 11–20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Snyder</author>
<author>R Barzilay</author>
</authors>
<title>Unsupervised multilingual learning for morphological segmentation.</title>
<date>2008</date>
<booktitle>In ACL ’08.</booktitle>
<contexts>
<context position="11984" citStr="Snyder and Barzilay (2008)" startWordPosition="1847" endWordPosition="1850">rs them. Then he derives finite state machines across words in different clusters and refines them through a graph walk algorithm. This group is the only one to evaluate against CELEX (Schone and Jurafsky, 2000; Schone and Jurafsky, 2001; Freitag, 2005). Others. Some other models require input such as POS tables and lexicons and use a wider range of information about the corpus (Yarowsky and Wicentowski, 2000; Yarowsky et al., 2001; Chan, 2006). Because of the knowledge dependence of these models, they are able to properly induce inflectional morphology, as opposed to the studies cited above. Snyder and Barzilay (2008) uses a set of aligned phrases across related languages to learn how to segment words with a Bayesian model and is otherwise fully unsupervised. 4 Model2 Our goal is to generate conflation sets: sets of word types that are related through either inflectional or derivational morphology (Schone and Jurafsky, 2000). Solving this task requires learning how individual types are segmented (though the segmentation itself is not evaluated). For present purposes, we assume that the affixal pattern of the language is known: whether it is prefixal, suffixal, or both. To simplify presentation, we discuss </context>
</contexts>
<marker>Snyder, Barzilay, 2008</marker>
<rawString>B. Snyder and R. Barzilay. 2008. Unsupervised multilingual learning for morphological segmentation. In ACL ’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
<author>R Wicentowski</author>
</authors>
<title>Minimally supervised morphological analysis by multimodal alignment.</title>
<date>2000</date>
<booktitle>In ACL ’00,</booktitle>
<pages>207--216</pages>
<contexts>
<context position="11770" citStr="Yarowsky and Wicentowski, 2000" startWordPosition="1813" endWordPosition="1816">y remove noise by constraining cluster membership with mutual information derived semantic similarity. Freitag (2005) uses a mutual information derived measure to learn the syntactic similarity between words and clusters them. Then he derives finite state machines across words in different clusters and refines them through a graph walk algorithm. This group is the only one to evaluate against CELEX (Schone and Jurafsky, 2000; Schone and Jurafsky, 2001; Freitag, 2005). Others. Some other models require input such as POS tables and lexicons and use a wider range of information about the corpus (Yarowsky and Wicentowski, 2000; Yarowsky et al., 2001; Chan, 2006). Because of the knowledge dependence of these models, they are able to properly induce inflectional morphology, as opposed to the studies cited above. Snyder and Barzilay (2008) uses a set of aligned phrases across related languages to learn how to segment words with a Bayesian model and is otherwise fully unsupervised. 4 Model2 Our goal is to generate conflation sets: sets of word types that are related through either inflectional or derivational morphology (Schone and Jurafsky, 2000). Solving this task requires learning how individual types are segmented </context>
</contexts>
<marker>Yarowsky, Wicentowski, 2000</marker>
<rawString>D. Yarowsky and R. Wicentowski. 2000. Minimally supervised morphological analysis by multimodal alignment. In ACL ’00, pages 207–216.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
<author>G Ngai</author>
<author>R Wicentowski</author>
</authors>
<title>Inducing multilingual text analysis tools via robust projection across aligned corpora. In</title>
<date>2001</date>
<booktitle>HLT ’01.</booktitle>
<contexts>
<context position="1578" citStr="Yarowsky et al., 2001" startWordPosition="236" endWordPosition="239">hmark systems which use considerably more complex strategies and rely more on experimentally chosen threshold values. 1 Introduction Unsupervised morphology acquisition attempts to learn from raw corpora one or more of the following about the written morphology of a language: (1) the segmentation of the set of word types in a corpus (Creutz and Lagus, 2007), (2) the clustering of word types in a corpus based on some notion of morphological relatedness (Schone and Jurafsky, 2000), (3) the generation of out-of-vocabulary items which are morphologically related to other word types in the corpus (Yarowsky et al., 2001). We take a novel approach to segmenting words and clustering morphologically related words. The approach uses no parameters that need to be tuned on data. The two main ideas of the approach are (a) the filtering of affixes by significant co-occurrence, and (b) the integration of knowledge of document boundaries when generating candidate stems and affixes and when clustering morphologically related words. The main application that we envision for our approach is to produce interlinearized glossed texts for underresourced/endangered languages (Palmer et al., 2009). Thus, we strive to eliminate </context>
<context position="11793" citStr="Yarowsky et al., 2001" startWordPosition="1817" endWordPosition="1820">luster membership with mutual information derived semantic similarity. Freitag (2005) uses a mutual information derived measure to learn the syntactic similarity between words and clusters them. Then he derives finite state machines across words in different clusters and refines them through a graph walk algorithm. This group is the only one to evaluate against CELEX (Schone and Jurafsky, 2000; Schone and Jurafsky, 2001; Freitag, 2005). Others. Some other models require input such as POS tables and lexicons and use a wider range of information about the corpus (Yarowsky and Wicentowski, 2000; Yarowsky et al., 2001; Chan, 2006). Because of the knowledge dependence of these models, they are able to properly induce inflectional morphology, as opposed to the studies cited above. Snyder and Barzilay (2008) uses a set of aligned phrases across related languages to learn how to segment words with a Bayesian model and is otherwise fully unsupervised. 4 Model2 Our goal is to generate conflation sets: sets of word types that are related through either inflectional or derivational morphology (Schone and Jurafsky, 2000). Solving this task requires learning how individual types are segmented (though the segmentatio</context>
</contexts>
<marker>Yarowsky, Ngai, Wicentowski, 2001</marker>
<rawString>D. Yarowsky, G. Ngai, and R. Wicentowski. 2001. Inducing multilingual text analysis tools via robust projection across aligned corpora. In HLT ’01.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>Unsupervised word sense disambiguation rivaling supervised methods.</title>
<date>1995</date>
<booktitle>In ACL ’95,</booktitle>
<pages>189--196</pages>
<contexts>
<context position="2833" citStr="Yarowsky, 1995" startWordPosition="430" endWordPosition="431">ary linguists to use our model as a preprocessing step for their manual analysis of stems and affixes. To require a documentary linguist–who is likely to have little to no knowledge of NLP methods–to tune parameters is unfeasible. Additionally, data-driven exploration of parameter settings is unlikely to be reliable in language documentation since datasets typically are quite small. To be relevant in this context, a model needs to produce useful results out of the box. Constraining learning by using document boundaries has been used quite effectively in unsupervised word sense disambiguation (Yarowsky, 1995). Many applications in information retrieval are built on the statistical correlation between documents and terms. However, we are unaware of cases where knowledge of document boundaries has been used for unsupervised learning for morphology. The intuition behind our approach is very simple: if two words in a single document are very similar in terms of orthography, then the two words are likely to be related morphologically. We measure how integrating these assumptions into our model at different stages affects performance. We define a simple pipeline model. After generating candidate stems a</context>
<context position="13541" citStr="Yarowsky (1995)" startWordPosition="2085" endWordPosition="2086">ared stems 3. Affix Clustering: cluster significant affix pairs into affix groups 2The code implementing the model is available from http://comp.ling.utexas.edu/earl 670 4. Word Clustering: form conflation sets based on affix clusters The first and last stages are particularly prone to noise, which has necessitated many of the thresholds and heuristics employed in previous work. We hypothesize that naturally occuring document boundaries provide a strong constraint that should reduce this noise, and we test that hypothesis by using it in those stages. Our intuition comes from an observation by Yarowsky (1995) regarding multiple tokens of words in documents. He tabulates the applicability of using document boundaries to disambiguate word senses, which measures how often a given word occurs more than twice in the same document. For ten potentially ambiguous words, he counts how often they occur more than once in some document and finds that if the words do occur, they do so multiple times in 50.1% of these documents, on average. His counts ignored morphological variation, and it is likely the applicability measure would have increased considerably: if a content word is used more than once in some te</context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>D. Yarowsky. 1995. Unsupervised word sense disambiguation rivaling supervised methods. In ACL ’95, pages 189–196.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>