<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007565">
<title confidence="0.978691">
Multilingual Harvesting of Cross-Cultural Stereotypes
</title>
<author confidence="0.998952">
Tony Veale
</author>
<affiliation confidence="0.9755995">
School of Computer Science
University College Dublin
</affiliation>
<address confidence="0.894912">
Belfield, Dublin 4, Ireland
</address>
<email confidence="0.99702">
tony.veale@ucd.ie
</email>
<author confidence="0.998079">
Yanfen Hao
</author>
<affiliation confidence="0.975585">
School of Computer Science
University College Dublin
</affiliation>
<address confidence="0.895001">
Belfield, Dublin 4, Ireland
</address>
<email confidence="0.99715">
yanfen.hao@ucd.ie
</email>
<author confidence="0.996922">
Guofu Li
</author>
<affiliation confidence="0.97554">
School of Computer Science
University College Dublin
</affiliation>
<address confidence="0.895762">
Belfield, Dublin 4, Ireland
</address>
<email confidence="0.998882">
li.guofu.l@gmail.com
</email>
<sectionHeader confidence="0.995638" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999804464285714">
People rarely articulate explicitly what a na-
tive speaker of a language is already assumed
to know. So to acquire the stereotypical
knowledge that underpins much of what is
said in a given culture, one must look to what
is implied by language rather than what is
overtly stated. Similes are a convenient ve-
hicle for this kind of knowledge, insofar as
they mark out the most salient aspects of the
most frequently evoked concepts. In this pa-
per we perform a multilingual exploration of
the space of common-place similes, by min-
ing a large body of Chinese similes from the
web and comparing these to the English sim-
iles harvested by Veale and Hao (2007). We
demonstrate that while the simile-frame is in-
herently leaky in both languages, a multilin-
gual analysis allows us to filter much of the
noise that otherwise hinders the knowledge
extraction process. In doing so, we can also
identify a core set of stereotypical descrip-
tions that exist in both languages and accu-
rately map these descriptions onto a multilin-
gual lexical ontology like HowNet. Finally,
we demonstrate that conceptual descriptions
that are derived from common-place similes
are extremely compact and predictive of onto-
logical structure.
</bodyText>
<sectionHeader confidence="0.999337" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998927358974359">
Direct perception of our environment is just one
of the ways we can acquire knowledge of the
world. Another, more distinctly human approach,
is through the comprehension of linguistic descrip-
tions of another person’s perceptions and beliefs.
Since computers have limited means of human-like
perception, the latter approach is also very much
suited to the automatic acquisition of world knowl-
edge by a computer (see Hearst, 1992; Charniak and
Berland, 1999; Etzioni et al., 2004; V¨olker et al.,
2005; Almuhareb and Poesio, 2005; Cimiano and
Wenderoth, 2007; Veale and Hao, 2007). Thus, by
using the web as a distributed text corpus (see Keller
et al., 2002), a multitude of facts and beliefs can
be extracted, for purposes ranging from question-
answering to ontology population.
The possible configurations of different concepts
can also be learned from how the words denoting
these concepts are distributed; thus, a computer can
learn that coffee is a beverage that can be served hot
or cold, white or black, strong or weak and sweet
or bitter (see Almuhareb and Poesio, 2005). But it
is difficult to discern from these facts the idealized
or stereotypical states of the world, e.g., that one ex-
pects coffee to be hot and beer to be cold, so that if
one spills coffee, we naturally infer the possibilities
of scalding and staining without having to be told
that the coffee was hot or black; the assumptions
of hotness and blackness are just two stereotypical
facts about coffee that we readily take for granted.
Lenat and Guha (1990) describe these assumed facts
as residing in the white space of a text, in the body
of common-sense assumptions that are rarely articu-
lated as explicit statements. These culturally-shared
common-sense beliefs cannot be harvested directly
from a single web resource or document set, but
must be gleaned indirectly, from telling phrases that
are scattered across the many texts of the web.
Veale and Hao (2007) argue that the most pivotal
</bodyText>
<page confidence="0.98368">
523
</page>
<note confidence="0.696338">
Proceedings ofACL-08: HLT, pages 523–531,
</note>
<page confidence="0.493816">
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</page>
<bodyText confidence="0.999919292307692">
reference points of this world-view can be detected
in common-place similes like “as lazy as a dog”, “as
fat as a hippo” or “as chaste as a nun”. To the extent
that this world-view is ingrained in and influenced
by how we speak, it can differ from culture to cul-
ture and language to language. In English texts, for
example, the concept Tortoise is stereotypically as-
sociated with the properties slowness, patience and
wrinkled, but in Chinese texts, we find that the same
animal is a model of slowness, ugliness, and nutri-
tional value. Likewise, because Chinese “wine” has
a high alcohol content, the dimension of Strength is
much more salient to a Chinese speaker than an En-
glish speaker, as reflected in how the word M is used
in statements such as *M— MJR, which means
“as strong as wine”, or literally, “as wine equally
strong”.
In this paper, we compare the same web-based
approach to acquiring stereotypical concept descrip-
tions from text using two very different languages,
English and Chinese, to determine the extent to
which the same cross-cultural knowledge is un-
earthed for each. In other words, we treat the web as
a large parallel corpus (e.g., see Resnick and Smith,
2003), though not of parallel documents in dif-
ferent languages, but of corresponding translation-
equivalent phrases. By seeking translation equiva-
lence between different pieces of textually-derived
knowledge, this paper addresses the following ques-
tions: if a particular syntagmatic pattern is useful for
mining knowledge in English, can its translated form
be equally useful for Chinese? To what extent does
the knowledge acquired using different source lan-
guages overlap, and to what extent is this knowledge
language- (and culture-) specific? Given that the
syntagmatic patterns used in each language are not
wholly unambiguous or immune to noise, to what
extent should finding the same beliefs expressed in
two different languages increase our confidence in
the acquired knowledge? Finally, what representa-
tional synergies arise from finding these same facts
expressed in two different languages?
Given these goals, the rest of the paper as-
sumes the following structure: in section 2, we
summarize related work on syntagmatic approaches
to knowledge-acquisition; in section 3, we de-
scribe our multilingual efforts in English and Chi-
nese to acquire stereotypical or generic-level facts
from the web, by using corresponding translations
of the commonplace stereotype-establishing pattern
“as ADJ as a NOUN”; and in section 4, we describe
how these English and Chinese data-sets can be uni-
fied using the bilingual ontology HowNet (Dong and
Dong, 2006). This mapping allows us to determine
the meaning overlap in both data sets, the amount
of noise in each data set, and the degree to which
this noise is reduced when parallel translations can
be identified. In section 5 we demonstrate the
overall usefulness of stereotype-based knowledge-
representation by replicating the clustering experi-
ments of Almuhareb and Poesio (2004, 2005) and
showing that stereotype-based representations are
both compact and predictive of ontological classi-
fication. We conclude the paper with some final re-
marks in section 6.
</bodyText>
<sectionHeader confidence="0.999782" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999973464285714">
Text-based approaches to knowledge acquisition
range from the ambitiously comprehensive, in which
an entire text or resource is fully parsed and ana-
lyzed in depth, to the surgically precise, in which
highly-specific text patterns are used to eke out cor-
respondingly specific relationships from a large cor-
pus. Endeavors such as that of Harabagiu et al.
(1999), in which each of the textual glosses in Word-
Net (Fellbaum, 1998) is linguistically analyzed to
yield a sense-tagged logical form, is an example of
the former approach. In contrast, foundational ef-
forts such as that of Hearst (1992) typify the latter
surgical approach, in which one fishes in a large text
for word sequences that strongly suggest a particu-
lar semantic relationship, such as hypernymy or, in
the case of Charniak and Berland (1999), the part-
whole relation. Such efforts offer high precision but
low recall, and extract just a tiny (but very useful)
subset of the semantic content of a text. The Know-
ItAll system of Etzioni et al. (2004) employs the
same generic patterns as Hearst ( e.g., “NPs such
as NP1, NP2, ...”), and more besides, to extract a
whole range of facts that can be exploited for web-
based question-answering. Cimiano and Wenderoth
(2007) also use a range of Hearst-like patterns to
find text sequences in web-text that are indicative
of the lexico-semantic properties of words; in par-
ticular, these authors use phrases like “to * a new
</bodyText>
<page confidence="0.996616">
524
</page>
<bodyText confidence="0.999977156862745">
NOUN” and “the purpose of NOUN is to *” to
identify the agentive and telic roles of given nouns,
thereby fleshing out the noun’s qualia structure as
posited by Pustejovsky’s (1990) theory of the gener-
ative lexicon.
The basic Hearst approach has even proven use-
ful for identifying the meta-properties of concepts
in a formal ontology. V¨olker et al. (2005) show
that patterns like “is no longer a|an NOUN” can
identify, with reasonable accuracy, those concepts
in an ontology that are not rigid, which is to say,
concepts like Teacher and Student whose instances
may at any point stop being instances of these con-
cepts. Almuhareb and Poesio (2005) use patterns
like “a|an|the * C is|was” and “the * of the C is|was”
to find the actual properties of concepts as they are
used in web texts; the former pattern is used to iden-
tify value features like hot, red, large, etc., while
the latter is used to identify the attribute features
that correspond to these values, such as tempera-
ture, color and size. Almuhareb and Poesio go on
to demonstrate that the values and attributes that are
found for word-concepts on the web yield a suffi-
ciently rich representation for these word-concepts
to be automatically clustered into a form resembling
that assigned by WordNet (see Fellbaum, 1998).
Veale and Hao (2007) show that the pattern “as ADJ
as a|an NOUN” can also be used to identify the
value feature associated with a given concept, and
argue that because this pattern corresponds to that
of the simile frame in English, the adjectival fea-
tures that are retrieved are much more likely to be
highly salient of the noun-concept (the simile ve-
hicle) that is used. Whereas Almuhareb and Poe-
sio succeed in identifying the range of potential at-
tributes and values that may be possessed by a par-
ticular concept, Veale and Hao succeed in identi-
fying the generic properties of a concept as it is
conceived in its stereotypical form. As noted by
the latter authors, this results in a much smaller yet
more diagnostic feature set for each concept. How-
ever, because the simile frame is often exploited for
ironic purposes in web texts (e.g., “as meaty as a
skeleton”), and because irony is so hard to detect,
Veale and Hao suggest that the adjective:noun pair-
ings found on the web should be hand-filtered to re-
move such examples. Given this onerous require-
ment for hand-filtering, and the unique, culturally-
loaded nature of the noise involved, we use the work
of Veale and Hao as the basis for the cross-cultural
investigation in this paper.
</bodyText>
<sectionHeader confidence="0.8516455" genericHeader="method">
3 Harvesting Knowledge from Similes:
English and Chinese
</sectionHeader>
<bodyText confidence="0.999988333333333">
Because similes are containers of culturally-
received knowledge, we can reasonably expect the
most commonly used similes to vary significantly
from language to language, especially when those
languages correspond to very different cultures.
These similes form part of the linguistic currency of
a culture which must be learned by a speaker, and
indeed, some remain opaque even to the most edu-
cated native speakers. In “A Christmas Carol”, for
instance, Dickens (1943/1984) questions the mean-
ing of “as dead as a doornail”, and notes: “I might
have been inclined, myself, to regard a coffin-nail as
the deadest piece of ironmongery in the trade. But
the wisdom of our ancestors is in the simile”.
Notwithstanding the opacity of some instances of
the simile form, similes are very revealing about the
concepts one most encounters in everyday language.
In section 5 we demonstrate that concept descrip-
tions which are harvested from similes are both ex-
tremely compact and highly predictive of ontolog-
ical structure. For now, we turn to the process by
which similes can be harvested from the text of the
web. In section 3.1 we summarize the efforts of
Veale and Hao, whose database of English similes
drives part of our current investigation. In section
3.2 we describe how a comparable database of Chi-
nese similes can be harvested from the web.
</bodyText>
<subsectionHeader confidence="0.999897">
3.1 Harvesting English Similes
</subsectionHeader>
<bodyText confidence="0.999974">
Veale and Hao (2007) use the Google API in con-
junction with Princeton WordNet (Fellbaum, 1998)
as the basis of their harvesting system. They first
extracted a list of antonymous adjectives, such as
“hot” or “cold”, from WordNet, the intuition being
that explicit similes will tend to exploit properties
that occupy an exemplary point on a scale. For ev-
ery adjective ADJ on this list, they then sent the
query “as ADJ as *” to Google and scanned the
first 200 snippets returned for different noun val-
ues for the wildcard *. The complete set of nouns
extracted in this way was then used to drive a sec-
</bodyText>
<page confidence="0.990259">
525
</page>
<bodyText confidence="0.999994518518518">
ond harvesting phase, in which the query “as * as
a NOUN” was used to collect similes that employ
different adjectives or which lie beyond the 200-
snippet horizon of the original search. Based on
this wide-ranging series of core samples (of 200 hits
each) from across the web, Veale and Hao report
that both phases together yielded 74,704 simile in-
stances (of 42,618 unique types, or unique adjec-
tive:noun pairings), relating 3769 different adjec-
tives to 9286 different nouns. As often noted by
other authors, such as V¨olker et al. (2005), a pattern-
oriented approach to knowledge mining is prone to
noise, not least because the patterns used are rarely
leak-free (inasmuch as they admit word sequences
that do not exhibit the desired relationship), and be-
cause these patterns look at small text sequences in
isolation from their narrative contexts. Veale and
Hao (2007) report that when the above 42,618 simile
types are hand-annotated by a native speaker, only
12,259 were judged as non-ironic and meaningful
in a null context. In other words, just 29% of the
retrieved pairings conform to what one would con-
sider a well-formed and reusable simile that conveys
some generic aspect of cultural knowledge. Of those
deemed invalid, 2798 unique pairings were tagged
as ironic, insofar as they stated precisely the oppo-
site of what is stereotypically believed to be true.
</bodyText>
<subsectionHeader confidence="0.999801">
3.2 Harvesting Chinese Similes
</subsectionHeader>
<bodyText confidence="0.999988016129033">
To harvest a comparable body of Chinese similes
from the web, we also use the Google API, in con-
junction with both WordNet and HowNet (Dong and
Dong, 2006). HowNet is a bilingual lexical ontol-
ogy that associates English and Chinese word labels
with an underlying set of approximately 100,000
lexical concepts. While each lexical concept is de-
fined using a unique numeric identifier, almost all of
HowNet’s concepts can be uniquely identified by a
pairing of English and Chinese labels. For instance,
the word “王八” can mean both Tortoise and Cuck-
old in Chinese, but the combined label tortoise|王八
uniquely picks out the first sense while cuckold|王
八 uniquely picks out the second. Though Chi-
nese has a large number of figurative expressions,
the yoking of English to Chinese labels still serves
to identify the correct sense in almost every case.
For instance, “绿帽子” is another word for Cuck-
old in Chinese, but it can also translate as “green
hat” and “green scarf”. Nonetheless, green hat|绿
帽子 uniquely identifies the literal sense of “绿帽
子” (a green covering) while green scarf|绿 帽 子
and cuckold|绿帽子 both identify the same human
sense, the former being a distinctly culture-specific
metaphor for cuckolded males (in English, a dispos-
sessed lover “wears the cuckold’s horns”; in Chi-
nese, one apparently “wears a green scarf”).
We employ the same two-phase design as Veale
and Hao: an initial set of Chinese adjectives are
extracted from HowNet, with the stipulation that
their English translations (as given by HowNet) are
also categorized as adjectives in WordNet. We
then use the Chinese equivalent of the English sim-
ile frame “像* 一 样ADJ” (literally, “as-NOUN-
equally-ADJ”) to retrieve a set of noun values that
stereotypically embody these adjectival features.
Again, a set of 200 snippets is analyzed for each
query, and only those values of the Google * wild-
card that HowNet categorizes as nouns are accepted.
In a second phase, these nouns are used to create
new queries of the form “像Noun一样*” and the re-
sulting Google snippets are now scanned for adjec-
tival values of *.
In all, 25,585 unique Chinese similes (i.e., pair-
ings of an adjective to a noun) are harvested, link-
ing 3080 different Chinese adjectives to 4162 Chi-
nese nouns. When hand-annotated by a native Chi-
nese speaker, the Chinese simile frame reveals it-
self to be considerably less leaky than the corre-
sponding English frame. Over 58% of these pairings
(14,867) are tagged as well-formed and meaning-
ful similes that convey some stereotypical element
of world knowledge. The Chinese pattern “像*一
样*” is thus almost twice as reliable as the English
”as * as a *” pattern. In addition, Chinese speak-
ers exploit the simile frame much less frequently for
ironic purposes, since just 185 of the retrieved sim-
iles (or 0.7%) are tagged as ironic, compared with
ten times as many (or 7%) retrieved English similes.
In the next section we consider the extent to which
these English and Chinese similes convey the same
information.
</bodyText>
<sectionHeader confidence="0.90087" genericHeader="method">
4 Tagging and Mapping of Similes
</sectionHeader>
<bodyText confidence="0.9950895">
In each case, the harvesting processes for English
and for Chinese allow us to acquire stereotypi-
</bodyText>
<page confidence="0.991951">
526
</page>
<bodyText confidence="0.999970931034483">
cal associations between words, not word senses.
Nonetheless, the frequent use of synonymous terms
introduces a substantial degree of redundancy in
these associations, and this redundancy can be used
to perform sense discrimination. In the case of En-
glish similes, Veale and Hao (2007) describe how
two English similes “as A as N1” and “as A as
N2” will be mutually disambiguating if N1 and
N2 are synonyms in WordNet, or if some sense
of N1 is a hypernym or hyponym of some sense
of N2 in WordNet. This heuristic allows Veale
and Hao to automatically sense-tag 85%, or 10,378,
of the unique similes that are annotated as valid.
We apply a similar intuition to the disambiguation
of Chinese similes: though HowNet does not sup-
port the notion of a synset, different word-senses
that have the same meaning will be associated with
the same logical definition. Thus, the Chinese
word “著 名” can translate as “celebrated”, “fa-
mous”, “well-known” and “reputable”, but all four
of these possible senses, given by celebrated|著名 ,
famous|著 名, well-known|著 名 and reputable|著
名, are associated with the same logical form in
HowNet, which defines them as a specialization of
ReputationValue|名声值. This allows us to safely
identify “著名” with this logical form. Overall, 69%
of Chinese similes can have both their adjective and
noun assigned to specific HowNet meanings in this
way.
</bodyText>
<subsectionHeader confidence="0.994258">
4.1 Translation Equivalence Among Similes
</subsectionHeader>
<bodyText confidence="0.999654882352941">
Since HowNet represents an integration of English
and Chinese lexicons, it can easily be used to con-
nect the English and Chinese data-sets. For while
the words used in any given simile are likely to
be ambiguous (in the case of one-character Chinese
words, highly so), it would seem unlikely that an
incorrect translation of a web simile would also be
found on the web. This is an intuition that we can
now use the annotated data-sets to evaluate.
For every English simile of the form &lt;Ae as
Ne&gt;, we use HowNet to generate a range of possible
Chinese variations &lt;Ac0 as Nc0&gt;, &lt;Ac1 as Nc0&gt;,
&lt;Ac0 as Nc1&gt;, &lt;Ac1 as Nc1&gt;, ... by using the
HowNet lexical entries Ae|Ac0, Ae|Ac1, ..., Ne|Nc0,
Ne|Nc1, ... as a translation bridge. If the variation
&lt;Aci as Ncj&gt; is found in the Chinese data-set, then
translation equivalence is assumed between &lt;Ae as
</bodyText>
<table confidence="0.998602666666667">
Language Precision Recall F1
English 0.76 0.25 0.38
Chinese 0.82 0.27 0.41
</table>
<tableCaption confidence="0.9767685">
Table 1: Automatic filtering of similes using Translation
Equivalence.
</tableCaption>
<bodyText confidence="0.996533303030303">
Ne&gt; and &lt;Aci as Ncj&gt;; furthermore, Ae|Aci is as-
sumed to be the HowNet sense of the adjectives Ae
and Aci while Ncj is assumed to be the HowNet
sense of the nouns Ne and Ncj. Sense-tagging is
thus a useful side-effect of simile-mapping with a
bilingual lexicon.
We attempt to find Chinese translation equiva-
lences for all 42,618 of the English adjective:noun
pairings harvested by Veale and Hao; this includes
both the 12,259 pairings that were hand-annotated as
valid stereotypical facts, and the remaining 30,359
that were dismissed as noisy or ironic. Using
HowNet, we can establish equivalences from 4177
English similes to 4867 Chinese similes. In those
mapped, we find 3194 English similes and 4019
Chinese similes that were hand-annotated as valid
by their respective native-speaker judges. In other
words, translation equivalence can be used to sep-
arate well-formed stereotypical beliefs from ill-
formed or ironic beliefs with approximately 80%
precision. The precise situation is summarized in
Table 1.
As noted in section 3, just 29% of raw English
similes and 58% of raw Chinese similes that are har-
vested from web-text are judged as valid stereotyp-
ical statements by a native-speaking judge. For the
task of filtering irony and noise from raw data sets,
translation equivalence thus offers good precision
but poor recall, since most English similes appear
not to have a corresponding Chinese variant on the
web. Nonetheless, this heuristic allows us to reliably
identify a sizeable body of cross-cultural stereotypes
that hold in both languages.
</bodyText>
<sectionHeader confidence="0.439151" genericHeader="method">
4.1.1 Error Analysis
</sectionHeader>
<bodyText confidence="0.999717166666667">
Noisy propositions may add little but empty con-
tent to a representation, but ironic propositions will
actively undermine a representation from within,
leading to inferences that are not just unlikely, but
patently false (as is generally the intention of irony).
Since Veale and Hao (2007) annotate their data-
</bodyText>
<page confidence="0.993042">
527
</page>
<bodyText confidence="0.999849333333333">
set for irony, this allows us to measure the number
of egregious mistakes made when using translation
equivalence as a simile filter. Overall, we see that
1% of Chinese similes that are accepted via transla-
tion equivalence are ironic, accounting for 9% of all
errors made when filtering Chinese similes. Like-
wise, 1% of the English similes that are accepted are
ironic, accounting for 5% of all errors made when
filtering English similes.
</bodyText>
<subsectionHeader confidence="0.98934">
4.2 Representational Synergies
</subsectionHeader>
<bodyText confidence="0.999939384615385">
By mapping WordNet-tagged English similes onto
HowNet-tagged Chinese similes, we effectively ob-
tain two representational viewpoints onto the same
shared data set. For instance, though HowNet
has a much shallower hierarchical organization
than WordNet, it compensates by encapsulating the
meaning of different word senses using simple log-
ical formulae of semantic primitives, or sememes,
that are derived from the meaning of common Chi-
nese characters. WordNet and HowNet thus offer
two complementary levels or granularities of gen-
eralization that can be exploited as the context de-
mands.
</bodyText>
<subsectionHeader confidence="0.551641">
4.2.1 Adjective Organization
</subsectionHeader>
<bodyText confidence="0.999895357142857">
Unlike WordNet, HowNet organizes its adjec-
tival senses hierarchically, allowing one to obtain
a weaker form of a given description by climb-
ing the hierarchy, or to obtain a stronger form by
descending the hierarchy from a particular sense.
Thus, one can go up from kaleidoscopic|斑驳陆
离 to colored|彩, or down from colored|彩 to
any of motley|斑驳, dappled|斑驳, prismatic|斑驳
陆 离 and even gorgeous|斑 斓. Once stereotypi-
cal descriptions have been sense-tagged relative to
HowNet, they can easily be further enhanced or
bleached to suit the context of their use. For exam-
ple, by allowing a Chinese adjective to denote any
of the senses above it or below in the HowNet hi-
erarchy, we can extend the mapping of English to
Chinese similes so as to achieve an improved recall
of .36 (though we note that this technique reduces
the precision of the translation-equivalence heuristic
to .75).
As demonstrated by Almuhareb and Poesio
(2004), the best conceptual descriptions combine
adjectival values with the attributes that they fill.
Because adjectival senses hook into HowNet’s up-
per ontology via a series of abstract taxonyms like
TasteValue|美丑值, ReputationValue|名声值 and
AmountValue|多少值, a taxonym of the form At-
tributeValue can be identified for every adjective
sense in HowNet. For example, the English ad-
jective ”beautiful” can denote either beautiful|美,
organized by HowNet under BeautyValue|美
值, or beautiful|婉, organized by HowNet un-
der gracious|雅 which in turn is organized under
GraceValue|典雅值. The adjective “beautiful” can
therefore specify either the Grace or Beauty at-
tributes of a concept. Once similes have been sense-
tagged, we can build up a picture of most salient at-
tributes of our stereotypical concepts. For instance,
“peacock” similes yield the following attributes via
HowNet: Beauty, Appearance, Color, Pride, Be-
havior, Resplendence, Bearing and Grace; likewise
“demon” similes yield the following: Morality, Be-
havior, Temperament, Ability and Competence.
</bodyText>
<subsectionHeader confidence="0.506776">
4.2.2 Orthographic Form
</subsectionHeader>
<bodyText confidence="0.999971384615384">
The Chinese data-set lacks counterparts to many
similes that one would not think of as culturally-
determined, such “as red as a ruby”, “as cruel as
a tyrant” and “as smelly as a skunk”. One signifi-
cant reason for this kind of omission is not cultural
difference, but obviousness: many Chinese words
are multi-character gestalts of different ideas (see
Packard, 2000), so that these ideas form an explicit
part of the orthography of a lexical concept. For in-
stance, using HowNet, we can see that skunk|臭鼬
is actually a gestalt of the concepts smelly|臭 and
weasel|鼬, so the simile “as smelly as a skunk” is
already somewhat redundant in Chinese (somewhat
akin to the English similes “as hot as a hotdog” or
“as hard as a hardhat”).
Such decomposition can allow us to find those
English similes that are already orthographically ex-
plicit in Chinese word-forms. We simply look for
pairs of HowNet senses of the form Noun|XYZ and
Adj|X, where X and XYZ are Chinese words and the
simile “as Adj as a|an Noun” is found in the English
simile set. When we do so, we find that 648 English
similes, from “as meaty as a steak” to “as resonant
as a cello”, are already fossilized in the orthographic
realization of the corresponding Chinese concepts.
When fossilized similes are uncovered in this way,
</bodyText>
<page confidence="0.994596">
528
</page>
<bodyText confidence="0.983011333333333">
the recall of translation equivalence as a noise filter
rises to .29, while its precision rises to .84 (see Table
1)
</bodyText>
<sectionHeader confidence="0.9581045" genericHeader="method">
5 Empirical Evaluation: Simile-derived
Representations
</sectionHeader>
<bodyText confidence="0.99996043902439">
Stereotypes persist in language and culture because
they are, more often than not, cognitively useful:
by emphasizing the most salient aspects of a con-
cept, a stereotype acts as a dense conceptual descrip-
tion that is easily communicated, widely shared,
and which supports rapid inference. To demonstrate
the usefulness of stereotype-based concept descrip-
tions, we replicate here the clustering experiments
of Almuhareb and Poesio (2004, 2005), who in turn
demonstrated that conceptual features that are mined
from specific textual patterns can be used to con-
struct WordNet-like ontological structures. These
authors used different text patterns for mining fea-
ture values (like hot) and attributes (like tempera-
ture), and their experiments evaluated the relative ef-
fectiveness of each as a means of ontological cluster-
ing. Since our focus in this paper is on the harvesting
of feature values, we replicate here only their exper-
iments with values.
Almuhareb and Poesio (2004) used as their ex-
perimental basis a sampling of 214 English nouns
from 13 of WordNet’s upper-level semantic cate-
gories, and proceeded to harvest adjectival features
for these noun-concepts from the web using the tex-
tual pattern “[a I an I the] * C [is I was]”. This pattern
yielded a combined total of 51,045 value features
for these 214 nouns, such as hot, black, etc., which
were then used as the basis of a clustering algorithm
in an attempt to reconstruct the WordNet classifica-
tions for all 214 nouns. Clustering was performed
by the CLUTO-2.1 package (Karypis, 2003), which
partitioned the 214 nouns in 13 categories on the ba-
sis of their 51,045 web-derived features. Compar-
ing these clusters with the original WordNet-based
groupings, Almuhareb and Poesio report a cluster-
ing accuracy of 71.96%. In a second, larger exper-
iment, Almuhareb and Poesio (2005) sampled 402
nouns from 21 different semantic classes in Word-
Net, and harvested 94,989 feature values from the
web using the same textual pattern. They then ap-
plied the repeated bisections clustering algorithm to
</bodyText>
<table confidence="0.890459333333333">
Approach accuracy features
Almuhareb + Poesio 71.96% 51,045
Simile-derived stereotypes 70.2% 2,209
</table>
<tableCaption confidence="0.779188">
Table 2: Results for experiment 1 (214 nouns, 13 WN
categories).
</tableCaption>
<table confidence="0.999916444444445">
Approach Cluster Cluster features
purity entropy
Almu. + Poesio 56.7% 38.4% 94,989
(no filtering)
Almu. + Poesio 62.7% 33.8% 51345
(with filtering)
Simile-derived 64.3% 33% 5,547
stereotypes
(no filtering)
</table>
<tableCaption confidence="0.983639">
Table 3: Results for experiment 2 (402 nouns, 21 WN
categories).
</tableCaption>
<bodyText confidence="0.999149166666667">
this larger data set, and report an initial cluster purity
measure of 56.7%. Suspecting that a noisy feature
set had contributed to the apparent drop in perfor-
mance, these authors then proceed to apply a variety
of noise filters to reduce the set of feature values to
51,345, which in turn leads to an improved cluster
purity measure of 62.7%.
We replicated both of Almuhareb and Poesio’s
experiments on the same experimental data-sets (of
214 and 402 nouns respectively), using instead the
English simile pattern “as * as a NOUN” to harvest
features for these nouns from the web. Note that
in keeping with the original experiments, no hand-
tagging or filtering of these features is performed, so
that every raw match with the simile pattern is used.
Overall, we harvest just 2209 feature values for the
214 nouns of experiment 1, and 5547 features for the
402 nouns of experiment 2. A comparison of both
sets of results for experiment 1 is shown is Table 2,
while a comparison based on experiment 2 is shown
is Table 3.
While Almuhareb and Poesio achieve marginally
higher clustering on the 214 nouns of experiment 1,
they do so by using over 20 times as many features.
</bodyText>
<page confidence="0.994336">
529
</page>
<bodyText confidence="0.9999848125">
In experiment 2, we see a similar ratio of feature
quantities before filtering; after some initial filtering,
Almuhareb and Poesio reduce their feature set to just
under 10 times the size of the simile-derived feature
set.
These experiments demonstrate two key points
about stereotype-based representations. First, the
feature representations do not need to be hand-
filtered and noise-free to be effective; we see from
the above results that the raw values extracted
from the simile pattern prove slightly more effec-
tive than filtered feature sets used by Almuhareb and
Poesio. Secondly, and perhaps more importantly,
stereotype-based representations prove themselves a
much more compact means (by factor of 10 to 20
times) of achieving the same clustering goals.
</bodyText>
<sectionHeader confidence="0.999747" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999982758064516">
Knowledge-acquisition from texts can be a process
fraught with complexity: such texts - especially
web-based texts - are frequently under-determined
and vague; highly ambiguous, both lexically and
structurally; and dense with figures of speech, hy-
perbolae and irony. None of the syntagmatic frames
surveyed in section 2, from the “NP such as NP1,
NP2 ...” pattern of Hearst (1992) and Etzioni et al.
(2004) to the “no longer NOUN” pattern of V¨olker
et al. (2005), are leak-free and immune to noise.
Cimiano and Wenderoth (2007) mitigate this prob-
lem somewhat by performing part-of-speech anal-
ysis on all extracted text sequences, but the prob-
lem remains: the surgical, pattern-based approach
offers an efficient and targeted means of knowledge-
acquisition from corpora because it largely ignores
the context in which these patterns occur; yet one
requires this context to determine if a given text se-
quence really is a good exemplar of the semantic re-
lationship that is sought.
In this paper we have described how stereotyp-
ical associations between adjectival properties and
noun concepts can be mined from similes in web
text. When harvested in both English and Chi-
nese, these associations exhibit two kinds of re-
dundancy that can mitigate the problem of noise.
The first kind, within-language redundancy, allows
us to perform sense-tagging of the adjectives and
nouns that are used in similes, by exploiting the
fact that the same stereotypical association can oc-
cur in a variety of synonymous forms. By recog-
nizing synonymy between the elements of different
similes, we can thus identify the underlying senses
(or WordNet synsets) in these similes. The sec-
ond kind, between-language redundancy, exploits
the fact that the same associations can occur in dif-
ferent languages, allowing us to exploit translation-
equivalence to pin these associations to particular
lexical concepts in a multilingual lexical ontology
like HowNet. While between-language redundancy
is a limited phenomenon, with just 26% of Veale
and Hao’s annotated English similes having Chinese
translations on the web, this phenomenon does allow
us to identify a significant core of shared stereotyp-
ical knowledge across these two very different lan-
guages.
Overall, our analysis suggests that a comparable
number of well-formed Chinese and English similes
can be mined from the web (our exploration finds
approx. 12,000 unique examples of each). This
demonstrates that harvesting stereotypical knowl-
edge from similes is a workable strategy in both lan-
guages. Moreover, Chinese simile usage is charac-
terized by two interesting facts that are of some prac-
tical import: the simile frame “像NOUN 一样ADJ”
is a good deal less leaky and prone to noise than the
equivalent English frame, “as ADJ as a NOUN”; and
Chinese speakers appear less willing to subvert the
stereotypical norms of similes for ironic purposes.
Further research is needed to determine whether
these observations generalize to other knowledge-
mining patterns.
</bodyText>
<sectionHeader confidence="0.999266" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999630230769231">
A. Almuhareb and M. Poesio. 2004. Attribute-Based and
Value-Based Clustering: An Evaluation. In proceed-
ings of EMNLP 2004, pp 158–165. Barcelona, Spain.
A. Almuhareb and M. Poesio. 2005. Concept Learning
and Categorization from the Web. In proceedings of
CogSci 2005, the 27th Annual Conference of the Cog-
nitive Science Society. New Jersey: Lawrence Erl-
baum.
C. Dickens. 1843/1981. A Christmas Carol. Puffin
Books, Middlesex, UK.
C. Fellbaum. 1998. WordNet, an electronic lexical
database. MIT Press.
E. Charniak and M. Berland. 1999. Finding parts in
</reference>
<page confidence="0.96595">
530
</page>
<reference confidence="0.999858666666667">
very large corpora. In proceedings of the 37th Annual
Meeting of the ACL, pp 57-64.
F. Keller, M. Lapata, and O. Ourioupina. 2002. Using
the web to overcome data sparseness. In proceedings
of EMNLP-02, pp 230-237.
F. Keller, M. Lapata, and O. Ourioupina. 1990. Building
large knowledge-based systems: representation and
inference in the Cyc project. Addison-Wesley.
G. Karypis. 2003. CLUTO: A clustering toolkit. Univer-
sity of Minnesota.
J. L. Packard. 2000. The Morphology of Chinese: A
Linguistic and Cognitive Approach. Cambridge Uni-
versity Press, UK.
J. Pustejovsky. 1991. The generative lexicon. Computa-
tional Linguistics 17(4), pp 209-441.
J. V¨olker, D. Vrandecic and Y. Sure. 2005. Automatic
Evaluation of Ontologies (AEON). In Y. Gil, E. Motta,
V. R. Benjamins, M. A. Musen, Proceedings of the 4th
International Semantic Web Conference (ISWC2005),
volume 3729 of LNCS, pp. 716-731. Springer Verlag
Berlin-Heidelberg.
M. Hearst. 1992. Automatic acquisition of hyponyms
from large text corpora. In proceedings of the 14th
intenatinal conference on Computational Linguistics,
pp 539-545.
O. Etzioni, S. Kok, S. Soderland, M. Cafarella, A-M.
Popescu, D. Weld, D. Downey, T. Shaked and A.
Yates. 2004. Web-scale information extraction in
KnowItAll (preliminary results). In proceedings of the
13th WWW Conference, pp 100-109.
P. Cimiano and J. Wenderoth. 2007. Automatic Acqui-
sition of Ranked Qualia Structures from the Web. In
proceedings of the 45th Annual Meeting of the ACL,
pp 888–895.
P. Resnik and N. A. Smith. 2003. The Web as a parallel
corpus. Computational Linguistics, 29(3),pp 349-380.
S. Harabagiu, G. Miller and D. Moldovan. 1999. Word-
Net2 - a morphologically and semantically enhanced
resource. In proceedings of SIGLEX-99, pp 1-8, Uni-
versity of Maryland.
T. Veale and Y. Hao. 2007. Making Lexical Ontologies
Functional and Context-Sensitive. In proceedings of
the 45th Annual Meeting of the ACL, pp 57-64.
Z. Dong and Q. Dong. 2006. HowNet and the Computa-
tion of Meaning. World Scientific: Singapore.
</reference>
<page confidence="0.99796">
531
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.888173">
<title confidence="0.999831">Multilingual Harvesting of Cross-Cultural Stereotypes</title>
<author confidence="0.999997">Tony Veale</author>
<affiliation confidence="0.999516">School of Computer Science University College Dublin</affiliation>
<address confidence="0.999521">Belfield, Dublin 4, Ireland</address>
<email confidence="0.977135">tony.veale@ucd.ie</email>
<author confidence="0.999231">Yanfen Hao</author>
<affiliation confidence="0.9995265">School of Computer Science University College Dublin</affiliation>
<address confidence="0.99937">Belfield, Dublin 4, Ireland</address>
<email confidence="0.981698">yanfen.hao@ucd.ie</email>
<author confidence="0.994483">Guofu Li</author>
<affiliation confidence="0.9995305">School of Computer Science University College Dublin</affiliation>
<address confidence="0.998589">Belfield, Dublin 4, Ireland</address>
<email confidence="0.999923">li.guofu.l@gmail.com</email>
<abstract confidence="0.997819965517241">People rarely articulate explicitly what a native speaker of a language is already assumed to know. So to acquire the stereotypical knowledge that underpins much of what is said in a given culture, one must look to what is implied by language rather than what is overtly stated. Similes are a convenient vehicle for this kind of knowledge, insofar as they mark out the most salient aspects of the most frequently evoked concepts. In this paper we perform a multilingual exploration of the space of common-place similes, by mining a large body of Chinese similes from the web and comparing these to the English similes harvested by Veale and Hao (2007). We demonstrate that while the simile-frame is inherently leaky in both languages, a multilingual analysis allows us to filter much of the noise that otherwise hinders the knowledge extraction process. In doing so, we can also identify a core set of stereotypical descriptions that exist in both languages and accurately map these descriptions onto a multilingual lexical ontology like HowNet. Finally, we demonstrate that conceptual descriptions that are derived from common-place similes are extremely compact and predictive of ontological structure.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Almuhareb</author>
<author>M Poesio</author>
</authors>
<title>Attribute-Based and Value-Based Clustering: An Evaluation.</title>
<date>2004</date>
<booktitle>In proceedings of EMNLP 2004,</booktitle>
<pages>158--165</pages>
<location>Barcelona,</location>
<contexts>
<context position="6717" citStr="Almuhareb and Poesio (2004" startWordPosition="1072" endWordPosition="1075">eb, by using corresponding translations of the commonplace stereotype-establishing pattern “as ADJ as a NOUN”; and in section 4, we describe how these English and Chinese data-sets can be unified using the bilingual ontology HowNet (Dong and Dong, 2006). This mapping allows us to determine the meaning overlap in both data sets, the amount of noise in each data set, and the degree to which this noise is reduced when parallel translations can be identified. In section 5 we demonstrate the overall usefulness of stereotype-based knowledgerepresentation by replicating the clustering experiments of Almuhareb and Poesio (2004, 2005) and showing that stereotype-based representations are both compact and predictive of ontological classification. We conclude the paper with some final remarks in section 6. 2 Related Work Text-based approaches to knowledge acquisition range from the ambitiously comprehensive, in which an entire text or resource is fully parsed and analyzed in depth, to the surgically precise, in which highly-specific text patterns are used to eke out correspondingly specific relationships from a large corpus. Endeavors such as that of Harabagiu et al. (1999), in which each of the textual glosses in Wor</context>
<context position="23720" citStr="Almuhareb and Poesio (2004)" startWordPosition="3904" endWordPosition="3907">d|彩, or down from colored|彩 to any of motley|斑驳, dappled|斑驳, prismatic|斑驳 陆 离 and even gorgeous|斑 斓. Once stereotypical descriptions have been sense-tagged relative to HowNet, they can easily be further enhanced or bleached to suit the context of their use. For example, by allowing a Chinese adjective to denote any of the senses above it or below in the HowNet hierarchy, we can extend the mapping of English to Chinese similes so as to achieve an improved recall of .36 (though we note that this technique reduces the precision of the translation-equivalence heuristic to .75). As demonstrated by Almuhareb and Poesio (2004), the best conceptual descriptions combine adjectival values with the attributes that they fill. Because adjectival senses hook into HowNet’s upper ontology via a series of abstract taxonyms like TasteValue|美丑值, ReputationValue|名声值 and AmountValue|多少值, a taxonym of the form AttributeValue can be identified for every adjective sense in HowNet. For example, the English adjective ”beautiful” can denote either beautiful|美, organized by HowNet under BeautyValue|美 值, or beautiful|婉, organized by HowNet under gracious|雅 which in turn is organized under GraceValue|典雅值. The adjective “beautiful” can th</context>
<context position="26686" citStr="Almuhareb and Poesio (2004" startWordPosition="4374" endWordPosition="4377">d in this way, 528 the recall of translation equivalence as a noise filter rises to .29, while its precision rises to .84 (see Table 1) 5 Empirical Evaluation: Simile-derived Representations Stereotypes persist in language and culture because they are, more often than not, cognitively useful: by emphasizing the most salient aspects of a concept, a stereotype acts as a dense conceptual description that is easily communicated, widely shared, and which supports rapid inference. To demonstrate the usefulness of stereotype-based concept descriptions, we replicate here the clustering experiments of Almuhareb and Poesio (2004, 2005), who in turn demonstrated that conceptual features that are mined from specific textual patterns can be used to construct WordNet-like ontological structures. These authors used different text patterns for mining feature values (like hot) and attributes (like temperature), and their experiments evaluated the relative effectiveness of each as a means of ontological clustering. Since our focus in this paper is on the harvesting of feature values, we replicate here only their experiments with values. Almuhareb and Poesio (2004) used as their experimental basis a sampling of 214 English no</context>
</contexts>
<marker>Almuhareb, Poesio, 2004</marker>
<rawString>A. Almuhareb and M. Poesio. 2004. Attribute-Based and Value-Based Clustering: An Evaluation. In proceedings of EMNLP 2004, pp 158–165. Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Almuhareb</author>
<author>M Poesio</author>
</authors>
<title>Concept Learning and Categorization from the Web. In</title>
<date>2005</date>
<booktitle>proceedings of CogSci 2005, the 27th Annual Conference of the Cognitive Science Society.</booktitle>
<location>New Jersey: Lawrence Erlbaum.</location>
<contexts>
<context position="2141" citStr="Almuhareb and Poesio, 2005" startWordPosition="331" endWordPosition="334">common-place similes are extremely compact and predictive of ontological structure. 1 Introduction Direct perception of our environment is just one of the ways we can acquire knowledge of the world. Another, more distinctly human approach, is through the comprehension of linguistic descriptions of another person’s perceptions and beliefs. Since computers have limited means of human-like perception, the latter approach is also very much suited to the automatic acquisition of world knowledge by a computer (see Hearst, 1992; Charniak and Berland, 1999; Etzioni et al., 2004; V¨olker et al., 2005; Almuhareb and Poesio, 2005; Cimiano and Wenderoth, 2007; Veale and Hao, 2007). Thus, by using the web as a distributed text corpus (see Keller et al., 2002), a multitude of facts and beliefs can be extracted, for purposes ranging from questionanswering to ontology population. The possible configurations of different concepts can also be learned from how the words denoting these concepts are distributed; thus, a computer can learn that coffee is a beverage that can be served hot or cold, white or black, strong or weak and sweet or bitter (see Almuhareb and Poesio, 2005). But it is difficult to discern from these facts t</context>
<context position="8992" citStr="Almuhareb and Poesio (2005)" startWordPosition="1452" endWordPosition="1455">ose of NOUN is to *” to identify the agentive and telic roles of given nouns, thereby fleshing out the noun’s qualia structure as posited by Pustejovsky’s (1990) theory of the generative lexicon. The basic Hearst approach has even proven useful for identifying the meta-properties of concepts in a formal ontology. V¨olker et al. (2005) show that patterns like “is no longer a|an NOUN” can identify, with reasonable accuracy, those concepts in an ontology that are not rigid, which is to say, concepts like Teacher and Student whose instances may at any point stop being instances of these concepts. Almuhareb and Poesio (2005) use patterns like “a|an|the * C is|was” and “the * of the C is|was” to find the actual properties of concepts as they are used in web texts; the former pattern is used to identify value features like hot, red, large, etc., while the latter is used to identify the attribute features that correspond to these values, such as temperature, color and size. Almuhareb and Poesio go on to demonstrate that the values and attributes that are found for word-concepts on the web yield a sufficiently rich representation for these word-concepts to be automatically clustered into a form resembling that assign</context>
<context position="28086" citStr="Almuhareb and Poesio (2005)" startWordPosition="4604" endWordPosition="4607">n I the] * C [is I was]”. This pattern yielded a combined total of 51,045 value features for these 214 nouns, such as hot, black, etc., which were then used as the basis of a clustering algorithm in an attempt to reconstruct the WordNet classifications for all 214 nouns. Clustering was performed by the CLUTO-2.1 package (Karypis, 2003), which partitioned the 214 nouns in 13 categories on the basis of their 51,045 web-derived features. Comparing these clusters with the original WordNet-based groupings, Almuhareb and Poesio report a clustering accuracy of 71.96%. In a second, larger experiment, Almuhareb and Poesio (2005) sampled 402 nouns from 21 different semantic classes in WordNet, and harvested 94,989 feature values from the web using the same textual pattern. They then applied the repeated bisections clustering algorithm to Approach accuracy features Almuhareb + Poesio 71.96% 51,045 Simile-derived stereotypes 70.2% 2,209 Table 2: Results for experiment 1 (214 nouns, 13 WN categories). Approach Cluster Cluster features purity entropy Almu. + Poesio 56.7% 38.4% 94,989 (no filtering) Almu. + Poesio 62.7% 33.8% 51345 (with filtering) Simile-derived 64.3% 33% 5,547 stereotypes (no filtering) Table 3: Results </context>
</contexts>
<marker>Almuhareb, Poesio, 2005</marker>
<rawString>A. Almuhareb and M. Poesio. 2005. Concept Learning and Categorization from the Web. In proceedings of CogSci 2005, the 27th Annual Conference of the Cognitive Science Society. New Jersey: Lawrence Erlbaum.</rawString>
</citation>
<citation valid="false">
<title>A Christmas Carol.</title>
<publisher>Puffin Books,</publisher>
<location>Middlesex, UK.</location>
<marker></marker>
<rawString>C. Dickens. 1843/1981. A Christmas Carol. Puffin Books, Middlesex, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>WordNet, an electronic lexical database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="7338" citStr="Fellbaum, 1998" startWordPosition="1173" endWordPosition="1174">) and showing that stereotype-based representations are both compact and predictive of ontological classification. We conclude the paper with some final remarks in section 6. 2 Related Work Text-based approaches to knowledge acquisition range from the ambitiously comprehensive, in which an entire text or resource is fully parsed and analyzed in depth, to the surgically precise, in which highly-specific text patterns are used to eke out correspondingly specific relationships from a large corpus. Endeavors such as that of Harabagiu et al. (1999), in which each of the textual glosses in WordNet (Fellbaum, 1998) is linguistically analyzed to yield a sense-tagged logical form, is an example of the former approach. In contrast, foundational efforts such as that of Hearst (1992) typify the latter surgical approach, in which one fishes in a large text for word sequences that strongly suggest a particular semantic relationship, such as hypernymy or, in the case of Charniak and Berland (1999), the partwhole relation. Such efforts offer high precision but low recall, and extract just a tiny (but very useful) subset of the semantic content of a text. The KnowItAll system of Etzioni et al. (2004) employs the </context>
<context position="9626" citStr="Fellbaum, 1998" startWordPosition="1563" endWordPosition="1564">“a|an|the * C is|was” and “the * of the C is|was” to find the actual properties of concepts as they are used in web texts; the former pattern is used to identify value features like hot, red, large, etc., while the latter is used to identify the attribute features that correspond to these values, such as temperature, color and size. Almuhareb and Poesio go on to demonstrate that the values and attributes that are found for word-concepts on the web yield a sufficiently rich representation for these word-concepts to be automatically clustered into a form resembling that assigned by WordNet (see Fellbaum, 1998). Veale and Hao (2007) show that the pattern “as ADJ as a|an NOUN” can also be used to identify the value feature associated with a given concept, and argue that because this pattern corresponds to that of the simile frame in English, the adjectival features that are retrieved are much more likely to be highly salient of the noun-concept (the simile vehicle) that is used. Whereas Almuhareb and Poesio succeed in identifying the range of potential attributes and values that may be possessed by a particular concept, Veale and Hao succeed in identifying the generic properties of a concept as it is</context>
<context position="12392" citStr="Fellbaum, 1998" startWordPosition="2031" endWordPosition="2032">n section 5 we demonstrate that concept descriptions which are harvested from similes are both extremely compact and highly predictive of ontological structure. For now, we turn to the process by which similes can be harvested from the text of the web. In section 3.1 we summarize the efforts of Veale and Hao, whose database of English similes drives part of our current investigation. In section 3.2 we describe how a comparable database of Chinese similes can be harvested from the web. 3.1 Harvesting English Similes Veale and Hao (2007) use the Google API in conjunction with Princeton WordNet (Fellbaum, 1998) as the basis of their harvesting system. They first extracted a list of antonymous adjectives, such as “hot” or “cold”, from WordNet, the intuition being that explicit similes will tend to exploit properties that occupy an exemplary point on a scale. For every adjective ADJ on this list, they then sent the query “as ADJ as *” to Google and scanned the first 200 snippets returned for different noun values for the wildcard *. The complete set of nouns extracted in this way was then used to drive a sec525 ond harvesting phase, in which the query “as * as a NOUN” was used to collect similes that </context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>C. Fellbaum. 1998. WordNet, an electronic lexical database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
<author>M Berland</author>
</authors>
<title>Finding parts in very large corpora.</title>
<date>1999</date>
<booktitle>In proceedings of the 37th Annual Meeting of the ACL,</booktitle>
<pages>57--64</pages>
<contexts>
<context position="2069" citStr="Charniak and Berland, 1999" startWordPosition="319" endWordPosition="322">ally, we demonstrate that conceptual descriptions that are derived from common-place similes are extremely compact and predictive of ontological structure. 1 Introduction Direct perception of our environment is just one of the ways we can acquire knowledge of the world. Another, more distinctly human approach, is through the comprehension of linguistic descriptions of another person’s perceptions and beliefs. Since computers have limited means of human-like perception, the latter approach is also very much suited to the automatic acquisition of world knowledge by a computer (see Hearst, 1992; Charniak and Berland, 1999; Etzioni et al., 2004; V¨olker et al., 2005; Almuhareb and Poesio, 2005; Cimiano and Wenderoth, 2007; Veale and Hao, 2007). Thus, by using the web as a distributed text corpus (see Keller et al., 2002), a multitude of facts and beliefs can be extracted, for purposes ranging from questionanswering to ontology population. The possible configurations of different concepts can also be learned from how the words denoting these concepts are distributed; thus, a computer can learn that coffee is a beverage that can be served hot or cold, white or black, strong or weak and sweet or bitter (see Almuha</context>
<context position="7720" citStr="Charniak and Berland (1999)" startWordPosition="1234" endWordPosition="1237">y precise, in which highly-specific text patterns are used to eke out correspondingly specific relationships from a large corpus. Endeavors such as that of Harabagiu et al. (1999), in which each of the textual glosses in WordNet (Fellbaum, 1998) is linguistically analyzed to yield a sense-tagged logical form, is an example of the former approach. In contrast, foundational efforts such as that of Hearst (1992) typify the latter surgical approach, in which one fishes in a large text for word sequences that strongly suggest a particular semantic relationship, such as hypernymy or, in the case of Charniak and Berland (1999), the partwhole relation. Such efforts offer high precision but low recall, and extract just a tiny (but very useful) subset of the semantic content of a text. The KnowItAll system of Etzioni et al. (2004) employs the same generic patterns as Hearst ( e.g., “NPs such as NP1, NP2, ...”), and more besides, to extract a whole range of facts that can be exploited for webbased question-answering. Cimiano and Wenderoth (2007) also use a range of Hearst-like patterns to find text sequences in web-text that are indicative of the lexico-semantic properties of words; in particular, these authors use phr</context>
</contexts>
<marker>Charniak, Berland, 1999</marker>
<rawString>E. Charniak and M. Berland. 1999. Finding parts in very large corpora. In proceedings of the 37th Annual Meeting of the ACL, pp 57-64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Keller</author>
<author>M Lapata</author>
<author>O Ourioupina</author>
</authors>
<title>Using the web to overcome data sparseness.</title>
<date>2002</date>
<booktitle>In proceedings of EMNLP-02,</booktitle>
<pages>230--237</pages>
<contexts>
<context position="2271" citStr="Keller et al., 2002" startWordPosition="354" endWordPosition="357">is just one of the ways we can acquire knowledge of the world. Another, more distinctly human approach, is through the comprehension of linguistic descriptions of another person’s perceptions and beliefs. Since computers have limited means of human-like perception, the latter approach is also very much suited to the automatic acquisition of world knowledge by a computer (see Hearst, 1992; Charniak and Berland, 1999; Etzioni et al., 2004; V¨olker et al., 2005; Almuhareb and Poesio, 2005; Cimiano and Wenderoth, 2007; Veale and Hao, 2007). Thus, by using the web as a distributed text corpus (see Keller et al., 2002), a multitude of facts and beliefs can be extracted, for purposes ranging from questionanswering to ontology population. The possible configurations of different concepts can also be learned from how the words denoting these concepts are distributed; thus, a computer can learn that coffee is a beverage that can be served hot or cold, white or black, strong or weak and sweet or bitter (see Almuhareb and Poesio, 2005). But it is difficult to discern from these facts the idealized or stereotypical states of the world, e.g., that one expects coffee to be hot and beer to be cold, so that if one spi</context>
</contexts>
<marker>Keller, Lapata, Ourioupina, 2002</marker>
<rawString>F. Keller, M. Lapata, and O. Ourioupina. 2002. Using the web to overcome data sparseness. In proceedings of EMNLP-02, pp 230-237.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Keller</author>
<author>M Lapata</author>
<author>O Ourioupina</author>
</authors>
<title>Building large knowledge-based systems: representation and inference in the Cyc project.</title>
<date>1990</date>
<publisher>Addison-Wesley.</publisher>
<marker>Keller, Lapata, Ourioupina, 1990</marker>
<rawString>F. Keller, M. Lapata, and O. Ourioupina. 1990. Building large knowledge-based systems: representation and inference in the Cyc project. Addison-Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Karypis</author>
</authors>
<title>CLUTO: A clustering toolkit.</title>
<date>2003</date>
<institution>University of Minnesota.</institution>
<contexts>
<context position="27796" citStr="Karypis, 2003" startWordPosition="4560" endWordPosition="4561">s with values. Almuhareb and Poesio (2004) used as their experimental basis a sampling of 214 English nouns from 13 of WordNet’s upper-level semantic categories, and proceeded to harvest adjectival features for these noun-concepts from the web using the textual pattern “[a I an I the] * C [is I was]”. This pattern yielded a combined total of 51,045 value features for these 214 nouns, such as hot, black, etc., which were then used as the basis of a clustering algorithm in an attempt to reconstruct the WordNet classifications for all 214 nouns. Clustering was performed by the CLUTO-2.1 package (Karypis, 2003), which partitioned the 214 nouns in 13 categories on the basis of their 51,045 web-derived features. Comparing these clusters with the original WordNet-based groupings, Almuhareb and Poesio report a clustering accuracy of 71.96%. In a second, larger experiment, Almuhareb and Poesio (2005) sampled 402 nouns from 21 different semantic classes in WordNet, and harvested 94,989 feature values from the web using the same textual pattern. They then applied the repeated bisections clustering algorithm to Approach accuracy features Almuhareb + Poesio 71.96% 51,045 Simile-derived stereotypes 70.2% 2,20</context>
</contexts>
<marker>Karypis, 2003</marker>
<rawString>G. Karypis. 2003. CLUTO: A clustering toolkit. University of Minnesota.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J L Packard</author>
</authors>
<title>The Morphology of Chinese: A Linguistic and Cognitive Approach.</title>
<date>2000</date>
<publisher>Cambridge University Press, UK.</publisher>
<contexts>
<context position="25152" citStr="Packard, 2000" startWordPosition="4121" endWordPosition="4122">s yield the following attributes via HowNet: Beauty, Appearance, Color, Pride, Behavior, Resplendence, Bearing and Grace; likewise “demon” similes yield the following: Morality, Behavior, Temperament, Ability and Competence. 4.2.2 Orthographic Form The Chinese data-set lacks counterparts to many similes that one would not think of as culturallydetermined, such “as red as a ruby”, “as cruel as a tyrant” and “as smelly as a skunk”. One significant reason for this kind of omission is not cultural difference, but obviousness: many Chinese words are multi-character gestalts of different ideas (see Packard, 2000), so that these ideas form an explicit part of the orthography of a lexical concept. For instance, using HowNet, we can see that skunk|臭鼬 is actually a gestalt of the concepts smelly|臭 and weasel|鼬, so the simile “as smelly as a skunk” is already somewhat redundant in Chinese (somewhat akin to the English similes “as hot as a hotdog” or “as hard as a hardhat”). Such decomposition can allow us to find those English similes that are already orthographically explicit in Chinese word-forms. We simply look for pairs of HowNet senses of the form Noun|XYZ and Adj|X, where X and XYZ are Chinese words </context>
</contexts>
<marker>Packard, 2000</marker>
<rawString>J. L. Packard. 2000. The Morphology of Chinese: A Linguistic and Cognitive Approach. Cambridge University Press, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pustejovsky</author>
</authors>
<title>The generative lexicon.</title>
<date>1991</date>
<journal>Computational Linguistics</journal>
<volume>17</volume>
<issue>4</issue>
<pages>209--441</pages>
<marker>Pustejovsky, 1991</marker>
<rawString>J. Pustejovsky. 1991. The generative lexicon. Computational Linguistics 17(4), pp 209-441.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J V¨olker</author>
<author>D Vrandecic</author>
<author>Y Sure</author>
</authors>
<title>Automatic Evaluation of Ontologies (AEON). In</title>
<date>2005</date>
<booktitle>Proceedings of the 4th International Semantic Web Conference (ISWC2005),</booktitle>
<volume>3729</volume>
<pages>716--731</pages>
<publisher>Springer Verlag Berlin-Heidelberg.</publisher>
<marker>V¨olker, Vrandecic, Sure, 2005</marker>
<rawString>J. V¨olker, D. Vrandecic and Y. Sure. 2005. Automatic Evaluation of Ontologies (AEON). In Y. Gil, E. Motta, V. R. Benjamins, M. A. Musen, Proceedings of the 4th International Semantic Web Conference (ISWC2005), volume 3729 of LNCS, pp. 716-731. Springer Verlag Berlin-Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<booktitle>In proceedings of the 14th intenatinal conference on Computational Linguistics,</booktitle>
<pages>539--545</pages>
<contexts>
<context position="2041" citStr="Hearst, 1992" startWordPosition="317" endWordPosition="318">ke HowNet. Finally, we demonstrate that conceptual descriptions that are derived from common-place similes are extremely compact and predictive of ontological structure. 1 Introduction Direct perception of our environment is just one of the ways we can acquire knowledge of the world. Another, more distinctly human approach, is through the comprehension of linguistic descriptions of another person’s perceptions and beliefs. Since computers have limited means of human-like perception, the latter approach is also very much suited to the automatic acquisition of world knowledge by a computer (see Hearst, 1992; Charniak and Berland, 1999; Etzioni et al., 2004; V¨olker et al., 2005; Almuhareb and Poesio, 2005; Cimiano and Wenderoth, 2007; Veale and Hao, 2007). Thus, by using the web as a distributed text corpus (see Keller et al., 2002), a multitude of facts and beliefs can be extracted, for purposes ranging from questionanswering to ontology population. The possible configurations of different concepts can also be learned from how the words denoting these concepts are distributed; thus, a computer can learn that coffee is a beverage that can be served hot or cold, white or black, strong or weak and</context>
<context position="7505" citStr="Hearst (1992)" startWordPosition="1200" endWordPosition="1201">on 6. 2 Related Work Text-based approaches to knowledge acquisition range from the ambitiously comprehensive, in which an entire text or resource is fully parsed and analyzed in depth, to the surgically precise, in which highly-specific text patterns are used to eke out correspondingly specific relationships from a large corpus. Endeavors such as that of Harabagiu et al. (1999), in which each of the textual glosses in WordNet (Fellbaum, 1998) is linguistically analyzed to yield a sense-tagged logical form, is an example of the former approach. In contrast, foundational efforts such as that of Hearst (1992) typify the latter surgical approach, in which one fishes in a large text for word sequences that strongly suggest a particular semantic relationship, such as hypernymy or, in the case of Charniak and Berland (1999), the partwhole relation. Such efforts offer high precision but low recall, and extract just a tiny (but very useful) subset of the semantic content of a text. The KnowItAll system of Etzioni et al. (2004) employs the same generic patterns as Hearst ( e.g., “NPs such as NP1, NP2, ...”), and more besides, to extract a whole range of facts that can be exploited for webbased question-a</context>
<context position="31065" citStr="Hearst (1992)" startWordPosition="5087" endWordPosition="5088">ts used by Almuhareb and Poesio. Secondly, and perhaps more importantly, stereotype-based representations prove themselves a much more compact means (by factor of 10 to 20 times) of achieving the same clustering goals. 6 Conclusions Knowledge-acquisition from texts can be a process fraught with complexity: such texts - especially web-based texts - are frequently under-determined and vague; highly ambiguous, both lexically and structurally; and dense with figures of speech, hyperbolae and irony. None of the syntagmatic frames surveyed in section 2, from the “NP such as NP1, NP2 ...” pattern of Hearst (1992) and Etzioni et al. (2004) to the “no longer NOUN” pattern of V¨olker et al. (2005), are leak-free and immune to noise. Cimiano and Wenderoth (2007) mitigate this problem somewhat by performing part-of-speech analysis on all extracted text sequences, but the problem remains: the surgical, pattern-based approach offers an efficient and targeted means of knowledgeacquisition from corpora because it largely ignores the context in which these patterns occur; yet one requires this context to determine if a given text sequence really is a good exemplar of the semantic relationship that is sought. In</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>M. Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In proceedings of the 14th intenatinal conference on Computational Linguistics, pp 539-545.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Etzioni</author>
<author>S Kok</author>
<author>S Soderland</author>
<author>M Cafarella</author>
<author>A-M Popescu</author>
<author>D Weld</author>
<author>D Downey</author>
<author>T Shaked</author>
<author>A Yates</author>
</authors>
<title>Web-scale information extraction in KnowItAll (preliminary results).</title>
<date>2004</date>
<booktitle>In proceedings of the 13th WWW Conference,</booktitle>
<pages>100--109</pages>
<contexts>
<context position="2091" citStr="Etzioni et al., 2004" startWordPosition="323" endWordPosition="326">nceptual descriptions that are derived from common-place similes are extremely compact and predictive of ontological structure. 1 Introduction Direct perception of our environment is just one of the ways we can acquire knowledge of the world. Another, more distinctly human approach, is through the comprehension of linguistic descriptions of another person’s perceptions and beliefs. Since computers have limited means of human-like perception, the latter approach is also very much suited to the automatic acquisition of world knowledge by a computer (see Hearst, 1992; Charniak and Berland, 1999; Etzioni et al., 2004; V¨olker et al., 2005; Almuhareb and Poesio, 2005; Cimiano and Wenderoth, 2007; Veale and Hao, 2007). Thus, by using the web as a distributed text corpus (see Keller et al., 2002), a multitude of facts and beliefs can be extracted, for purposes ranging from questionanswering to ontology population. The possible configurations of different concepts can also be learned from how the words denoting these concepts are distributed; thus, a computer can learn that coffee is a beverage that can be served hot or cold, white or black, strong or weak and sweet or bitter (see Almuhareb and Poesio, 2005).</context>
<context position="7925" citStr="Etzioni et al. (2004)" startWordPosition="1271" endWordPosition="1274">losses in WordNet (Fellbaum, 1998) is linguistically analyzed to yield a sense-tagged logical form, is an example of the former approach. In contrast, foundational efforts such as that of Hearst (1992) typify the latter surgical approach, in which one fishes in a large text for word sequences that strongly suggest a particular semantic relationship, such as hypernymy or, in the case of Charniak and Berland (1999), the partwhole relation. Such efforts offer high precision but low recall, and extract just a tiny (but very useful) subset of the semantic content of a text. The KnowItAll system of Etzioni et al. (2004) employs the same generic patterns as Hearst ( e.g., “NPs such as NP1, NP2, ...”), and more besides, to extract a whole range of facts that can be exploited for webbased question-answering. Cimiano and Wenderoth (2007) also use a range of Hearst-like patterns to find text sequences in web-text that are indicative of the lexico-semantic properties of words; in particular, these authors use phrases like “to * a new 524 NOUN” and “the purpose of NOUN is to *” to identify the agentive and telic roles of given nouns, thereby fleshing out the noun’s qualia structure as posited by Pustejovsky’s (1990</context>
<context position="31091" citStr="Etzioni et al. (2004)" startWordPosition="5090" endWordPosition="5093">eb and Poesio. Secondly, and perhaps more importantly, stereotype-based representations prove themselves a much more compact means (by factor of 10 to 20 times) of achieving the same clustering goals. 6 Conclusions Knowledge-acquisition from texts can be a process fraught with complexity: such texts - especially web-based texts - are frequently under-determined and vague; highly ambiguous, both lexically and structurally; and dense with figures of speech, hyperbolae and irony. None of the syntagmatic frames surveyed in section 2, from the “NP such as NP1, NP2 ...” pattern of Hearst (1992) and Etzioni et al. (2004) to the “no longer NOUN” pattern of V¨olker et al. (2005), are leak-free and immune to noise. Cimiano and Wenderoth (2007) mitigate this problem somewhat by performing part-of-speech analysis on all extracted text sequences, but the problem remains: the surgical, pattern-based approach offers an efficient and targeted means of knowledgeacquisition from corpora because it largely ignores the context in which these patterns occur; yet one requires this context to determine if a given text sequence really is a good exemplar of the semantic relationship that is sought. In this paper we have descri</context>
</contexts>
<marker>Etzioni, Kok, Soderland, Cafarella, Popescu, Weld, Downey, Shaked, Yates, 2004</marker>
<rawString>O. Etzioni, S. Kok, S. Soderland, M. Cafarella, A-M. Popescu, D. Weld, D. Downey, T. Shaked and A. Yates. 2004. Web-scale information extraction in KnowItAll (preliminary results). In proceedings of the 13th WWW Conference, pp 100-109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Cimiano</author>
<author>J Wenderoth</author>
</authors>
<title>Automatic Acquisition of Ranked Qualia Structures from the Web.</title>
<date>2007</date>
<booktitle>In proceedings of the 45th Annual Meeting of the ACL,</booktitle>
<pages>888--895</pages>
<contexts>
<context position="2170" citStr="Cimiano and Wenderoth, 2007" startWordPosition="335" endWordPosition="338">remely compact and predictive of ontological structure. 1 Introduction Direct perception of our environment is just one of the ways we can acquire knowledge of the world. Another, more distinctly human approach, is through the comprehension of linguistic descriptions of another person’s perceptions and beliefs. Since computers have limited means of human-like perception, the latter approach is also very much suited to the automatic acquisition of world knowledge by a computer (see Hearst, 1992; Charniak and Berland, 1999; Etzioni et al., 2004; V¨olker et al., 2005; Almuhareb and Poesio, 2005; Cimiano and Wenderoth, 2007; Veale and Hao, 2007). Thus, by using the web as a distributed text corpus (see Keller et al., 2002), a multitude of facts and beliefs can be extracted, for purposes ranging from questionanswering to ontology population. The possible configurations of different concepts can also be learned from how the words denoting these concepts are distributed; thus, a computer can learn that coffee is a beverage that can be served hot or cold, white or black, strong or weak and sweet or bitter (see Almuhareb and Poesio, 2005). But it is difficult to discern from these facts the idealized or stereotypical</context>
<context position="8143" citStr="Cimiano and Wenderoth (2007)" startWordPosition="1308" endWordPosition="1311">e latter surgical approach, in which one fishes in a large text for word sequences that strongly suggest a particular semantic relationship, such as hypernymy or, in the case of Charniak and Berland (1999), the partwhole relation. Such efforts offer high precision but low recall, and extract just a tiny (but very useful) subset of the semantic content of a text. The KnowItAll system of Etzioni et al. (2004) employs the same generic patterns as Hearst ( e.g., “NPs such as NP1, NP2, ...”), and more besides, to extract a whole range of facts that can be exploited for webbased question-answering. Cimiano and Wenderoth (2007) also use a range of Hearst-like patterns to find text sequences in web-text that are indicative of the lexico-semantic properties of words; in particular, these authors use phrases like “to * a new 524 NOUN” and “the purpose of NOUN is to *” to identify the agentive and telic roles of given nouns, thereby fleshing out the noun’s qualia structure as posited by Pustejovsky’s (1990) theory of the generative lexicon. The basic Hearst approach has even proven useful for identifying the meta-properties of concepts in a formal ontology. V¨olker et al. (2005) show that patterns like “is no longer a|a</context>
<context position="31213" citStr="Cimiano and Wenderoth (2007)" startWordPosition="5111" endWordPosition="5114">e compact means (by factor of 10 to 20 times) of achieving the same clustering goals. 6 Conclusions Knowledge-acquisition from texts can be a process fraught with complexity: such texts - especially web-based texts - are frequently under-determined and vague; highly ambiguous, both lexically and structurally; and dense with figures of speech, hyperbolae and irony. None of the syntagmatic frames surveyed in section 2, from the “NP such as NP1, NP2 ...” pattern of Hearst (1992) and Etzioni et al. (2004) to the “no longer NOUN” pattern of V¨olker et al. (2005), are leak-free and immune to noise. Cimiano and Wenderoth (2007) mitigate this problem somewhat by performing part-of-speech analysis on all extracted text sequences, but the problem remains: the surgical, pattern-based approach offers an efficient and targeted means of knowledgeacquisition from corpora because it largely ignores the context in which these patterns occur; yet one requires this context to determine if a given text sequence really is a good exemplar of the semantic relationship that is sought. In this paper we have described how stereotypical associations between adjectival properties and noun concepts can be mined from similes in web text. </context>
</contexts>
<marker>Cimiano, Wenderoth, 2007</marker>
<rawString>P. Cimiano and J. Wenderoth. 2007. Automatic Acquisition of Ranked Qualia Structures from the Web. In proceedings of the 45th Annual Meeting of the ACL, pp 888–895.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Resnik</author>
<author>N A Smith</author>
</authors>
<title>The Web as a parallel corpus.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>3</issue>
<pages>349--380</pages>
<marker>Resnik, Smith, 2003</marker>
<rawString>P. Resnik and N. A. Smith. 2003. The Web as a parallel corpus. Computational Linguistics, 29(3),pp 349-380.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Harabagiu</author>
<author>G Miller</author>
<author>D Moldovan</author>
</authors>
<title>WordNet2 - a morphologically and semantically enhanced resource.</title>
<date>1999</date>
<booktitle>In proceedings of SIGLEX-99,</booktitle>
<pages>1--8</pages>
<institution>University of Maryland.</institution>
<contexts>
<context position="7272" citStr="Harabagiu et al. (1999)" startWordPosition="1159" endWordPosition="1162">replicating the clustering experiments of Almuhareb and Poesio (2004, 2005) and showing that stereotype-based representations are both compact and predictive of ontological classification. We conclude the paper with some final remarks in section 6. 2 Related Work Text-based approaches to knowledge acquisition range from the ambitiously comprehensive, in which an entire text or resource is fully parsed and analyzed in depth, to the surgically precise, in which highly-specific text patterns are used to eke out correspondingly specific relationships from a large corpus. Endeavors such as that of Harabagiu et al. (1999), in which each of the textual glosses in WordNet (Fellbaum, 1998) is linguistically analyzed to yield a sense-tagged logical form, is an example of the former approach. In contrast, foundational efforts such as that of Hearst (1992) typify the latter surgical approach, in which one fishes in a large text for word sequences that strongly suggest a particular semantic relationship, such as hypernymy or, in the case of Charniak and Berland (1999), the partwhole relation. Such efforts offer high precision but low recall, and extract just a tiny (but very useful) subset of the semantic content of </context>
</contexts>
<marker>Harabagiu, Miller, Moldovan, 1999</marker>
<rawString>S. Harabagiu, G. Miller and D. Moldovan. 1999. WordNet2 - a morphologically and semantically enhanced resource. In proceedings of SIGLEX-99, pp 1-8, University of Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Veale</author>
<author>Y Hao</author>
</authors>
<title>Making Lexical Ontologies Functional and Context-Sensitive.</title>
<date>2007</date>
<booktitle>In proceedings of the 45th Annual Meeting of the ACL,</booktitle>
<pages>57--64</pages>
<contexts>
<context position="1045" citStr="Veale and Hao (2007)" startWordPosition="160" endWordPosition="163">itly what a native speaker of a language is already assumed to know. So to acquire the stereotypical knowledge that underpins much of what is said in a given culture, one must look to what is implied by language rather than what is overtly stated. Similes are a convenient vehicle for this kind of knowledge, insofar as they mark out the most salient aspects of the most frequently evoked concepts. In this paper we perform a multilingual exploration of the space of common-place similes, by mining a large body of Chinese similes from the web and comparing these to the English similes harvested by Veale and Hao (2007). We demonstrate that while the simile-frame is inherently leaky in both languages, a multilingual analysis allows us to filter much of the noise that otherwise hinders the knowledge extraction process. In doing so, we can also identify a core set of stereotypical descriptions that exist in both languages and accurately map these descriptions onto a multilingual lexical ontology like HowNet. Finally, we demonstrate that conceptual descriptions that are derived from common-place similes are extremely compact and predictive of ontological structure. 1 Introduction Direct perception of our enviro</context>
<context position="3555" citStr="Veale and Hao (2007)" startWordPosition="569" endWordPosition="572"> staining without having to be told that the coffee was hot or black; the assumptions of hotness and blackness are just two stereotypical facts about coffee that we readily take for granted. Lenat and Guha (1990) describe these assumed facts as residing in the white space of a text, in the body of common-sense assumptions that are rarely articulated as explicit statements. These culturally-shared common-sense beliefs cannot be harvested directly from a single web resource or document set, but must be gleaned indirectly, from telling phrases that are scattered across the many texts of the web. Veale and Hao (2007) argue that the most pivotal 523 Proceedings ofACL-08: HLT, pages 523–531, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics reference points of this world-view can be detected in common-place similes like “as lazy as a dog”, “as fat as a hippo” or “as chaste as a nun”. To the extent that this world-view is ingrained in and influenced by how we speak, it can differ from culture to culture and language to language. In English texts, for example, the concept Tortoise is stereotypically associated with the properties slowness, patience and wrinkled, but in Chinese t</context>
<context position="9648" citStr="Veale and Hao (2007)" startWordPosition="1565" endWordPosition="1568">was” and “the * of the C is|was” to find the actual properties of concepts as they are used in web texts; the former pattern is used to identify value features like hot, red, large, etc., while the latter is used to identify the attribute features that correspond to these values, such as temperature, color and size. Almuhareb and Poesio go on to demonstrate that the values and attributes that are found for word-concepts on the web yield a sufficiently rich representation for these word-concepts to be automatically clustered into a form resembling that assigned by WordNet (see Fellbaum, 1998). Veale and Hao (2007) show that the pattern “as ADJ as a|an NOUN” can also be used to identify the value feature associated with a given concept, and argue that because this pattern corresponds to that of the simile frame in English, the adjectival features that are retrieved are much more likely to be highly salient of the noun-concept (the simile vehicle) that is used. Whereas Almuhareb and Poesio succeed in identifying the range of potential attributes and values that may be possessed by a particular concept, Veale and Hao succeed in identifying the generic properties of a concept as it is conceived in its ster</context>
<context position="12318" citStr="Veale and Hao (2007)" startWordPosition="2017" endWordPosition="2020">e very revealing about the concepts one most encounters in everyday language. In section 5 we demonstrate that concept descriptions which are harvested from similes are both extremely compact and highly predictive of ontological structure. For now, we turn to the process by which similes can be harvested from the text of the web. In section 3.1 we summarize the efforts of Veale and Hao, whose database of English similes drives part of our current investigation. In section 3.2 we describe how a comparable database of Chinese similes can be harvested from the web. 3.1 Harvesting English Similes Veale and Hao (2007) use the Google API in conjunction with Princeton WordNet (Fellbaum, 1998) as the basis of their harvesting system. They first extracted a list of antonymous adjectives, such as “hot” or “cold”, from WordNet, the intuition being that explicit similes will tend to exploit properties that occupy an exemplary point on a scale. For every adjective ADJ on this list, they then sent the query “as ADJ as *” to Google and scanned the first 200 snippets returned for different noun values for the wildcard *. The complete set of nouns extracted in this way was then used to drive a sec525 ond harvesting ph</context>
<context position="13772" citStr="Veale and Hao (2007)" startWordPosition="2267" endWordPosition="2270">each) from across the web, Veale and Hao report that both phases together yielded 74,704 simile instances (of 42,618 unique types, or unique adjective:noun pairings), relating 3769 different adjectives to 9286 different nouns. As often noted by other authors, such as V¨olker et al. (2005), a patternoriented approach to knowledge mining is prone to noise, not least because the patterns used are rarely leak-free (inasmuch as they admit word sequences that do not exhibit the desired relationship), and because these patterns look at small text sequences in isolation from their narrative contexts. Veale and Hao (2007) report that when the above 42,618 simile types are hand-annotated by a native speaker, only 12,259 were judged as non-ironic and meaningful in a null context. In other words, just 29% of the retrieved pairings conform to what one would consider a well-formed and reusable simile that conveys some generic aspect of cultural knowledge. Of those deemed invalid, 2798 unique pairings were tagged as ironic, insofar as they stated precisely the opposite of what is stereotypically believed to be true. 3.2 Harvesting Chinese Similes To harvest a comparable body of Chinese similes from the web, we also </context>
<context position="17711" citStr="Veale and Hao (2007)" startWordPosition="2924" endWordPosition="2927"> tagged as ironic, compared with ten times as many (or 7%) retrieved English similes. In the next section we consider the extent to which these English and Chinese similes convey the same information. 4 Tagging and Mapping of Similes In each case, the harvesting processes for English and for Chinese allow us to acquire stereotypi526 cal associations between words, not word senses. Nonetheless, the frequent use of synonymous terms introduces a substantial degree of redundancy in these associations, and this redundancy can be used to perform sense discrimination. In the case of English similes, Veale and Hao (2007) describe how two English similes “as A as N1” and “as A as N2” will be mutually disambiguating if N1 and N2 are synonyms in WordNet, or if some sense of N1 is a hypernym or hyponym of some sense of N2 in WordNet. This heuristic allows Veale and Hao to automatically sense-tag 85%, or 10,378, of the unique similes that are annotated as valid. We apply a similar intuition to the disambiguation of Chinese similes: though HowNet does not support the notion of a synset, different word-senses that have the same meaning will be associated with the same logical definition. Thus, the Chinese word “著 名”</context>
<context position="21689" citStr="Veale and Hao (2007)" startWordPosition="3580" endWordPosition="3583">rom raw data sets, translation equivalence thus offers good precision but poor recall, since most English similes appear not to have a corresponding Chinese variant on the web. Nonetheless, this heuristic allows us to reliably identify a sizeable body of cross-cultural stereotypes that hold in both languages. 4.1.1 Error Analysis Noisy propositions may add little but empty content to a representation, but ironic propositions will actively undermine a representation from within, leading to inferences that are not just unlikely, but patently false (as is generally the intention of irony). Since Veale and Hao (2007) annotate their data527 set for irony, this allows us to measure the number of egregious mistakes made when using translation equivalence as a simile filter. Overall, we see that 1% of Chinese similes that are accepted via translation equivalence are ironic, accounting for 9% of all errors made when filtering Chinese similes. Likewise, 1% of the English similes that are accepted are ironic, accounting for 5% of all errors made when filtering English similes. 4.2 Representational Synergies By mapping WordNet-tagged English similes onto HowNet-tagged Chinese similes, we effectively obtain two re</context>
</contexts>
<marker>Veale, Hao, 2007</marker>
<rawString>T. Veale and Y. Hao. 2007. Making Lexical Ontologies Functional and Context-Sensitive. In proceedings of the 45th Annual Meeting of the ACL, pp 57-64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Dong</author>
<author>Q Dong</author>
</authors>
<title>HowNet and the Computation of Meaning. World Scientific:</title>
<date>2006</date>
<contexts>
<context position="6344" citStr="Dong and Dong, 2006" startWordPosition="1013" endWordPosition="1016"> from finding these same facts expressed in two different languages? Given these goals, the rest of the paper assumes the following structure: in section 2, we summarize related work on syntagmatic approaches to knowledge-acquisition; in section 3, we describe our multilingual efforts in English and Chinese to acquire stereotypical or generic-level facts from the web, by using corresponding translations of the commonplace stereotype-establishing pattern “as ADJ as a NOUN”; and in section 4, we describe how these English and Chinese data-sets can be unified using the bilingual ontology HowNet (Dong and Dong, 2006). This mapping allows us to determine the meaning overlap in both data sets, the amount of noise in each data set, and the degree to which this noise is reduced when parallel translations can be identified. In section 5 we demonstrate the overall usefulness of stereotype-based knowledgerepresentation by replicating the clustering experiments of Almuhareb and Poesio (2004, 2005) and showing that stereotype-based representations are both compact and predictive of ontological classification. We conclude the paper with some final remarks in section 6. 2 Related Work Text-based approaches to knowle</context>
<context position="14457" citStr="Dong and Dong, 2006" startWordPosition="2382" endWordPosition="2385">d by a native speaker, only 12,259 were judged as non-ironic and meaningful in a null context. In other words, just 29% of the retrieved pairings conform to what one would consider a well-formed and reusable simile that conveys some generic aspect of cultural knowledge. Of those deemed invalid, 2798 unique pairings were tagged as ironic, insofar as they stated precisely the opposite of what is stereotypically believed to be true. 3.2 Harvesting Chinese Similes To harvest a comparable body of Chinese similes from the web, we also use the Google API, in conjunction with both WordNet and HowNet (Dong and Dong, 2006). HowNet is a bilingual lexical ontology that associates English and Chinese word labels with an underlying set of approximately 100,000 lexical concepts. While each lexical concept is defined using a unique numeric identifier, almost all of HowNet’s concepts can be uniquely identified by a pairing of English and Chinese labels. For instance, the word “王八” can mean both Tortoise and Cuckold in Chinese, but the combined label tortoise|王八 uniquely picks out the first sense while cuckold|王 八 uniquely picks out the second. Though Chinese has a large number of figurative expressions, the yoking of </context>
</contexts>
<marker>Dong, Dong, 2006</marker>
<rawString>Z. Dong and Q. Dong. 2006. HowNet and the Computation of Meaning. World Scientific: Singapore.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>