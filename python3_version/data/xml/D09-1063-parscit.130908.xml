<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.014504">
<title confidence="0.996599">
Generating High-Coverage Semantic Orientation Lexicons
From Overtly Marked Words and a Thesaurus
</title>
<author confidence="0.985851">
Saif Mohammadφt*, Cody Dunne*t, and Bonnie Dorrφtt*
</author>
<affiliation confidence="0.9927042">
Laboratory for Computational Linguistics and Information Processingφ
Human-Computer Interaction Lab*
Institute for Advanced Computer Studiest
Department of Computer Science$, University of Maryland.
Human Language Technology Center of Excellence*
</affiliation>
<email confidence="0.995715">
{saif,bonnie}@umiacs.umd.edu and {cdunne}@cs.umd.edu
</email>
<sectionHeader confidence="0.997189" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99988775">
Sentiment analysis often relies on a se-
mantic orientation lexicon of positive and
negative words. A number of approaches
have been proposed for creating such lex-
icons, but they tend to be computation-
ally expensive, and usually rely on signifi-
cant manual annotation and large corpora.
Most of these methods use WordNet. In
contrast, we propose a simple approach to
generate a high-coverage semantic orien-
tation lexicon, which includes both indi-
vidual words and multi-word expressions,
using only a Roget-like thesaurus and a
handful of affixes. Further, the lexicon
has properties that support the Polyanna
Hypothesis. Using the General Inquirer
as gold standard, we show that our lexi-
con has 14 percentage points more correct
entries than the leading WordNet-based
high-coverage lexicon (SentiWordNet). In
an extrinsic evaluation, we obtain signifi-
cantly higher performance in determining
phrase polarity using our thesaurus-based
lexicon than with any other. Additionally,
we explore the use of visualization tech-
niques to gain insight into the our algo-
rithm beyond the evaluations mentioned
above.
</bodyText>
<sectionHeader confidence="0.99963" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997454930232558">
Sentiment analysis involves determining the opin-
ions and private states (beliefs, emotions, specu-
lations, and so on) of the speaker (Wiebe, 1994).
It has received significant attention in recent years
due to increasing online opinion content and ap-
plications in tasks such as automatic product rec-
ommendation systems (Tatemura, 2000; Terveen
et al., 1997), question answering (Somasundaran
et al., 2007; Lita et al., 2005), and summarizing
multiple view points (Seki et al., 2004) and opin-
ions (Mohammad et al., 2008a).
A crucial sub-problem is to determine whether
positive or negative sentiment is expressed. Auto-
matic methods for this often make use of lexicons
of words tagged with positive and negative seman-
tic orientation (Turney, 2002; Wilson et al., 2005;
Pang and Lee, 2008). A word is said to have a
positive semantic orientation (SO) (or polarity)
if it is often used to convey favorable sentiment
or evaluation of the topic under discussion. Some
example words that have positive semantic orien-
tation are excellent, happy, honest, and so on. Sim-
ilarly, a word is said to have negative semantic ori-
entation if it is often used to convey unfavorable
sentiment or evaluation of the target. Examples
include poor, sad, and dishonest.
Certain semantic orientation lexicons have been
manually compiled for English—the most notable
being the General Inquirer (GI) (Stone et al.,
1966).1 However, the GI lexicon has orientation
labels for only about 3,600 entries. The Pitts-
burgh subjectivity lexicon (PSL) (Wilson et al.,
2005), which draws from the General Inquirer and
other sources, also has semantic orientation labels,
but only for about 8,000 words.
Automatic approaches to creating a seman-
tic orientation lexicon and, more generally, ap-
proaches for word-level sentiment annotation can
be grouped into two kinds: (1) those that rely
on manually created lexical resources—most of
which use WordNet (Strapparava and Valitutti,
2004; Hu and Liu, 2004; Kamps et al., 2004; Taka-
mura et al., 2005; Esuli and Sebastiani, 2006; An-
</bodyText>
<footnote confidence="0.998178">
1http://www.wjh.harvard.edu/ inquirer
</footnote>
<page confidence="0.93328">
599
</page>
<note confidence="0.996793">
Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 599–608,
Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.992036958333333">
dreevskaia and Bergler, 2006; Kanayama and Na-
sukawa, 2006); and (2) those that rely on text cor-
pora (Hatzivassiloglou and McKeown, 1997; Tur-
ney and Littman, 2003; Yu and Hatzivassiloglou,
2003; Grefenstette et al., 2004). Many of these
lexicons, such as SentiWordNet (SWN) (Esuli
and Sebastiani, 2006) were created using super-
vised classifiers and significant manual annota-
tion, whereas others such as the Turney and
Littman lexicon (TLL) (2003) were created from
very large corpora (more than 100 billion words).
In contrast, we propose a computationally
inexpensive method to compile a high-coverage
semantic orientation lexicon without the use of
any text corpora or manually annotated semantic
orientation labels. Both of these resources may
be used, if available, to further improve results.
The lexicon has about twenty times the number
of entries in the GI lexicon, and it includes en-
tries for both individual words and common multi-
word expressions. The method makes use of a
Roget-like thesaurus and a handful of antonym-
generating affix patterns. Whereas thesauri have
long been used to estimate semantic distance (Jar-
masz and Szpakowicz, 2003; Mohammad and
Hirst, 2006), the closest thesaurus-based work on
sentiment analysis is by Aman and Szpakowicz
(2007) on detecting emotions such as happiness,
sadness, and anger. We evaluated our thesaurus-
based algorithm both intrinsically and extrinsi-
cally and show that the semantic orientation lex-
icon it generates has significantly more correct en-
tries than the state-of-the-art high-coverage lexi-
con SentiWordNet, and that it has a significantly
higher coverage than the General Inquirer and
Turney–Littman lexicons.
In Section 2 we examine related work. Section 3
presents our algorithm for creating semantic orien-
tation lexicons. We describe intrinsic and extrin-
sic evaluation experiments in Section 4, followed
by a discussion of the results in Section 5. Ad-
ditionally, in Section 6 we show preliminary vi-
sualizations of how our algorithm forms chains of
positive and negative thesaurus categories. Good
visualizations are not only effective in presenting
information to the user, but also help us better un-
derstand our algorithm. Section 7 has our conclu-
sions.
</bodyText>
<sectionHeader confidence="0.999779" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999534734693878">
Pang and Lee (2008) provide an excellent survey
of the literature on sentiment analysis. Here we
briefly describe the work closest to ours.
Hatzivassiloglou and McKeown (1997) pro-
posed a supervised algorithm to determine the se-
mantic orientation of adjectives. They first gen-
erate a graph that has adjectives as nodes. An
edge between two nodes indicates either that the
two adjectives have the same or opposite seman-
tic orientation. A clustering algorithm partitions
the graph into two subgraphs such that the nodes
in a subgraph have the same semantic orientation.
The subgraph with adjectives that occur more of-
ten in text is marked positive and the other neg-
ative. They used a 21 million word corpus and
evaluated their algorithm on a labeled set of 1336
adjectives (657 positive and 679 negative). Our
approach does not require manually annotated se-
mantic orientation entries to train on and is much
simpler.
Esuli and Sebastiani (2006) used a supervised
algorithm to attach semantic orientation scores to
WordNet glosses. They train a set of ternary clas-
sifiers using different training data and learning
methods. The set of semantic orientation scores
of all WordNet synsets is released by the name
SentiWordNet.2 An evaluation of SentiWordNet
by comparing orientation scores of about 1,000
WordNet glosses to scores assigned by human an-
notators is presented in Esuli (2008). Our ap-
proach uses a Roget-like thesaurus, and it does not
use any supervised classifiers.
Turney and Littman (2003) proposed a mini-
mally supervised algorithm to calculate the se-
mantic orientation of a word by determining if
its tendency to co-occur with a small set of pos-
itive words is greater than its tendency to co-occur
with a small set of negative words. They show
that their approach performs better when it has a
large amount of text at its disposal. They use text
from 350 million web-pages (more than 100 bil-
lion words). Our approach does not make use of
any text corpora, although co-occurrence statistics
could be used to further improve the lexicon. Fur-
thermore, our lexicon has entries for commonly
used multi-word expressions as well.
Mohammad et al. (2008b) developed a method
to determine the degree of antonymy (contrast)
between two words using the Macquarie The-
</bodyText>
<footnote confidence="0.983677">
2http://sentiwordnet.isti.cnr.it/
</footnote>
<page confidence="0.995868">
600
</page>
<bodyText confidence="0.999765666666667">
saurus (Bernard, 1986), co-occurrence statistics,
and a small set of antonym-generating affix pat-
terns such as X–disX. Often, one member of a pair
of contrasting terms is positive and one member is
negative. In this paper, we describe how a subset
of those affix patterns can be used in combination
with a thesaurus and the edicts of marking the-
ory to create a large lexicon of words and phrases
marked with their semantic orientation.
</bodyText>
<sectionHeader confidence="0.9713475" genericHeader="method">
3 Generating the Semantic Orientation
Lexicon
</sectionHeader>
<bodyText confidence="0.9999702">
Our algorithm to generate a semantic orientation
lexicon has two steps: (1) identify a seed set of
positive and negative words; (2) use a Roget-like
thesaurus to mark the words synonymous with the
positive seeds “positive” and words synonymous
with the negative seeds “negative”. The two steps
are described in the subsections below. Our im-
plementation of the algorithm used the Macquarie
Thesaurus (Bernard, 1986). It has about 100,000
unique words and phrases.
</bodyText>
<subsectionHeader confidence="0.993241">
3.1 Seed words
3.1.1 Automatically identifying seed words
</subsectionHeader>
<bodyText confidence="0.999986181818182">
It is known from marking theory that overtly
marked words, such as dishonest, unhappy, and
impure, tend to have negative semantic orienta-
tion, whereas their unmarked counterparts, hon-
est, happy, and pure, tend to have positive seman-
tic orientation (Lehrer, 1974; Battistella, 1990).
Exceptions such as biased–unbiased and partial–
impartial do exist, and in some contexts even a
predominantly negative marked word may be pos-
itive. For example irreverent is negative in most
contexts, but positive in the sentence below:
</bodyText>
<subsubsectionHeader confidence="0.7419975">
Millions offans follow Moulder’s irrev-
erent quest for truth.
</subsubsectionHeader>
<bodyText confidence="0.997133727272727">
However, as we will show through experiments,
the exceptions are far outnumbered by those that
abide by the predictions of marking theory.
We used a set of 11 antonym-generating af-
fix patterns to generate overtly marked words and
their unmarked counterparts (Table 1). Similar
antonyms-generating affix patterns exist for many
languages (Lyons, 1977). The 11 chosen af-
fix patterns generated 2,692 pairs of marked and
unmarked valid English words that are listed in
the Macquarie Thesaurus. The marked words
</bodyText>
<table confidence="0.9878385">
Affix pattern # word
w1 w2 pairs example word pair
X disX 382 honest–dishonest
X imX 196 possible–impossible
X inX 691 consistent–inconsistent
X malX 28 adroit–maladroit
X misX 146 fortune–misfortune
X nonX 73 sense–nonsense
X unX 844 happy–unhappy
X Xless 208 gut–gutless
lX illX 25 legal–illegal
rX irX 48 responsible–irresponsible
Xless Xful 51 harmless–harmful
Total 2692
</table>
<tableCaption confidence="0.88119225">
Table 1: Eleven affix patterns used to generate the
seed set of marked and unmarked words. Here ‘X’
stands for any sequence of letters common to both
words w1 and w2.
</tableCaption>
<bodyText confidence="0.999958476190476">
are deemed negative and the unmarked ones pos-
itive, and these form our seed set of positive
and negative words. We will refer to this set
of orientation-marked words as the affix seeds
lexicon (ASL). Note that some words may have
multiple marked counterparts, for example, trust–
trustless and trust–mistrust. Thus, ASL has more
negative words (2,652) than positive ones (2,379).
Also, the Xless–Xful pattern generates word pairs
that are both overtly marked; words generated
from Xless are deemed negative and words gen-
erated from Xful are deemed positive.
It should be noted that the affix patterns used
here are a subset of those used in Mohammad et
al. (2008b) to generate antonym pairs. The affix
patterns ignored are those that are not expected
to generate pairs of words with opposite seman-
tic orientation. For instance, the pattern imX-exX
generates word pairs such as import–export and
implicit–explicit that are antonymous, but do not
have opposite semantic orientations.
</bodyText>
<subsectionHeader confidence="0.967299">
3.1.2 Using manually annotated seed words
</subsectionHeader>
<bodyText confidence="0.999930285714286">
Since manual semantic orientation labels exist for
some English words (the GI lexicon), we inves-
tigated their usefulness in further improving the
coverage and correctness of the entries in our lex-
icon. We used the GI words as seeds in the same
way as the words generated from the affix patterns
were used (Section 3.1.1).
</bodyText>
<subsectionHeader confidence="0.999299">
3.2 Generalizing from the seeds
</subsectionHeader>
<bodyText confidence="0.999986666666667">
A published thesaurus such as the Roget’s or Mac-
quarie has about 1,000 categories, each consist-
ing of on average 120 words and commonly used
</bodyText>
<page confidence="0.995522">
601
</page>
<table confidence="0.995856461538461">
SO lexicon Mode of Resources used # entries # positives # negatives
creation
ASL automatic 11 affix rules 5,031 2,379 (47.3%) 2,652 (52.7%)
GI manual human SO annotation 3,605 1,617 (44.9%) 1,988 (55.1%)
GI-subset manual human SO annotation 2,761 1,262 (45.7%) 1,499 (54.3%)
MSOL(ASL) automatic thesaurus, 11 affix rules 51,157 34,152 (66.8%) 17,005 (33.2%)
MSOL(GI) automatic GI, thesaurus 69,971 25,995 (37.2%) 43,976 (62.8%)
MSOL(ASL and GI) automatic GI, thesaurus, 11 affix rules 76,400 30,458 (39.9%) 45,942 (60.1%)
PSL mostly manual GI, other sources 6,450 2,298 (35.6%) 4,485 (64.4%)
SWN automatic human SO annotation, 56,200 47,806 (85.1%) 8,394 (14.9%)
WordNet, ternary classifiers
TLL automatic 100 billion word corpus, 3,596 1,625 (45.2%) 1,971 (54.8%)
minimal human SO annotation
</table>
<tableCaption confidence="0.988583">
Table 2: Key details of semantic orientation (SO) lexicons. ASL = affix seeds lexicon, GI = General
</tableCaption>
<bodyText confidence="0.9971509">
Inquirer, MSOL = Macquarie semantic orientation lexicon, PSL = Pitt subjectivity lexicon, SWN =
SentiWordNet, TLL = Turney–Littman lexicon.
multi-word expressions. Terms within a cate-
gory tend to be closely related, and they are fur-
ther grouped into sets of near-synonymous words
and phrases called paragraphs. There are about
10,000 paragraphs in most Roget-like thesauri.
Every thesaurus paragraph is examined to deter-
mine if it has a seed word (by looking up the seed
lexicon described in Section 3.1). If a thesaurus
paragraph has more positive seed words than neg-
ative seed words, then all the words (and multi-
word expressions) in that paragraph are marked as
positive. Otherwise, all its words are marked neg-
ative.
Note that this method assigns semantic orienta-
tion labels to word–thesaurus paragraph pairs.
Thesaurus paragraphs can be thought of as word
senses. A word with multiple meanings is listed
in multiple thesaurus paragraphs, and so will be
assigned semantic orientation labels for each of
these paragraphs. Thus, the method assigns a se-
mantic orientation to a word–sense combination
similar to the SentiWordNet approach and differ-
ing from the General Inquirer and Turney–Littman
lexicons.
However, in most natural language tasks, the in-
tended sense of the target word is not explicitly
marked. So we generate a word-based lexicon by
asking the different senses of a word to vote. If
a word is listed in multiple thesaurus paragraphs,
then the semantic orientation label most common
to them is chosen as the word’s label. We will re-
fer to this set of word–semantic orientation pairs
as the Macquarie Semantic Orientation Lexicon
(MSOL). A set created from only the affix seeds
will be called MSOL(ASL), a set created from
only the GI seeds will be called MSOL(GI), and
the set created using both affix seeds and GI seeds
will be called MSOL(ASL and GI).3 We gener-
ated a similar word-based lexicon for SentiWord-
Net (SWN) by choosing the semantic orientation
label most common to the synsets pertaining to a
target word.
Table 2 summarizes the details of all the lex-
icons. MSOL(ASL and GI) has a much larger
percentage of negatives than MSOL(ASL) be-
cause GI has a much larger percentage of negative
words. These negative seeds generate many more
negative entries in MSOL(ASL and GI). Of the
51,157 entries in MSOL(ASL), 47,514 are single-
word entries and 3,643 are entries for multi-word
expressions. Of the 69,971 entries in MSOL(GI),
45,197 are single-word entries and 24,774 are en-
tries for common multi-word expressions. Of the
76,400 entries in MSOL(ASL and GI), 51,208
are single-word entries and 25,192 are entries for
common multi-word expressions. In our evalua-
tion, we used only the single-word entries to main-
tain a level playing field with other lexicons.
</bodyText>
<sectionHeader confidence="0.99944" genericHeader="method">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.99995325">
We evaluated the semantic orientation lexicons
both intrinsically (by comparing their entries to the
General Inquirer) and extrinsically (by using them
in a phrase polarity annotation task).
</bodyText>
<subsectionHeader confidence="0.548975">
4.1 Intrinsic: Comparison with GI
</subsectionHeader>
<bodyText confidence="0.998142">
Similar to how Turney and Littman (2003) evalu-
ated their lexicon (TLL), we determine if the se-
mantic orientation labels in the automatically gen-
erated lexicons match the semantic orientation la-
</bodyText>
<footnote confidence="0.9927455">
3MSOL is publicly available at: www.umiacs.umd.edu/
∼saif/WebPages/ResearchInterests.html.
</footnote>
<page confidence="0.974704">
602
</page>
<table confidence="0.99993425">
Lexicon All Positives Negatives
MSOL(ASL) 74.3 84.2 65.9
SWN 60.1 86.5 37.9
TLL 83.3 83.8 82.8
</table>
<tableCaption confidence="0.995977">
Table 3: The percentage of GI-subset entries (all,
</tableCaption>
<bodyText confidence="0.984756">
only the positives, only the negatives) that match
those of the automatically generated lexicons.
bels of words in GI. GI, MSOL(ASL), SWN, and
TLL all have 2,761 words in common. We will
call the corresponding 2,761 GI entries the GI-
subset.
Table 3 shows the percentage of GI-subset en-
tries that match those of the three automatically-
generated lexicons (MSOL(ASL), SWN, and
TLL). (The differences in percentages shown in
the table are all statistically significant—p &lt;
0.001.) We do not show results for MSOL(GI),
MSOL(ASL and GI), and the Pittsburgh subjectiv-
ity lexicon (PSL) because these lexicons were cre-
ated using GI entries. TLL most closely matches
the GI-subset, and MSOL matches the GI-subset
more closely than SWN with the GI-subset. How-
ever, the goal of this work is to produce a high-
coverage semantic orientation lexicon and so we
additionally evaluate the lexicons on the extrinsic
task described below.
</bodyText>
<subsectionHeader confidence="0.940521">
4.2 Extrinsic: Identifying phrase polarity
</subsectionHeader>
<bodyText confidence="0.993110619047619">
The MPQA corpus contains news articles man-
ually annotated for opinions and private states.4
Notably, it also has polarity annotations (posi-
tive/negative) at the phrase-level. We conducted
an extrinsic evaluation of the manually-generated
and automatically-generated lexicons by using
them to determine the polarity of phrases in the
MPQA version 1.1 collection of positive and neg-
ative phrases (1,726 positive and 4,485 negative).
We used a simple algorithm to determine the
polarity of a phrase: (1) If any of the words in
the target phrase is listed in the lexicon as having
negative semantic orientation, then the phrase is
marked negative. (2) If none of the words in the
phrase is negative and if there is at least one posi-
tive word in the phrase, then it is marked positive.
(3) In all other instances, the classifier refrains
from assigning a tag. Indeed better accuracies in
phrase semantic orientation annotation can be ob-
tained by using supervised classifiers and more
sophisticated context features (Choi and Cardie,
</bodyText>
<footnote confidence="0.805319">
4http://www.cs.pitt.edu/mpqa
</footnote>
<bodyText confidence="0.999906111111111">
2008). However, our goal here is only to use this
task as a testbed for evaluating different seman-
tic orientation lexicons, and so we use the method
described above to avoid other factors from influ-
encing the results.
Table 4 shows the performance of the algorithm
when using different lexicons. The performance
when using lexicons that additionally make use
of GI entries—MSOL(GI), MSOL(ASL and GI),
PSL, and a combined GI-SWN lexicon—is shown
lower down in the table. GI–SWN has entries
from both GI and SWN. (For entries with oppos-
ing labels, the GI label was chosen since GI en-
tries were created manually.) Observe that the best
F-scores are obtained when using MSOL (in both
categories—individual lexicons and combinations
with GI). The values are significantly better than
those attained by others (p &lt; 0.001).
</bodyText>
<sectionHeader confidence="0.999754" genericHeader="method">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999932352941177">
The extrinsic evaluation shows that our thesaurus-
and affix-based lexicon is significantly more accu-
rate than SentiWordNet. Moreover, it has a much
larger coverage than the GI and Pitt lexicons. Ob-
serve also that the affix seeds set, by itself, attains
only a modest precision and a low recall. This is
expected because it is generated by largely auto-
matic means. However, the significantly higher
MSOL performance suggests that the generaliza-
tion step (described in Section 3.2) helps improve
both precision and recall. Precision is improved
because multiple seed words vote to decide the se-
mantic orientation of a thesaurus paragraph. Re-
call improves simply because non-seed words in
a paragraph are assigned the semantic orientation
that is most prevalent among the seeds in the para-
graph.
</bodyText>
<subsectionHeader confidence="0.86431">
5.1 Support for the Polyanna Hypothesis
</subsectionHeader>
<bodyText confidence="0.999971083333333">
Boucher and Osgood’s (1969) Polyanna Hypoth-
esis states that people have a preference for using
positive words and expressions as opposed to us-
ing negative words and expressions. Studies have
shown that indeed speakers across languages use
positive words much more frequently than nega-
tive words (Kelly, 2000). The distribution of pos-
itive and negative words in MSOL(ASL) further
supports the Polyanna Hypothesis as it shows that
even if we start with an equal number of positive
and negative seed words, the expansion of the pos-
itive set through the thesaurus is much more pro-
</bodyText>
<page confidence="0.998496">
603
</page>
<table confidence="0.999078">
SO lexicon All phrases F Only positives Only negatives
P R P R F P R F
Individual lexicons
ASL 0.451 0.165 0.242 0.451 0.165 0.242 0.192 0.063 0.095
GI 0.797 0.323 0.459 0.871 0.417 0.564 0.763 0.288 0.419
MSOL(ASL) 0.623 0.474 0.539 0.631 0.525 0.573 0.623 0.458 0.528
SWN 0.541 0.408 0.465 0.745 0.624 0.679 0.452 0.328 0.380
TLL 0.769 0.298 0.430 0.761 0.352 0.482 0.775 0.279 0.411
Automatic lexicons + GI information
MSOL(GI) 0.713 0.540 0.615 0.572 0.470 0.516 0.777 0.571 0.658
MSOL(ASL and GI) 0.710 0.546 0.617 0.577 0.481 0.525 0.771 0.574 0.658
PSL 0.823 0.422 0.558 0.860 0.487 0.622 0.810 0.399 0.535
GI-SWN 0.650 0.494 0.561 0.740 0.623 0.677 0.612 0.448 0.517
</table>
<tableCaption confidence="0.938168">
Table 4: Performance in phrase polarity tagging. P = precision, R = recall, F = balanced F-score. The
best F-scores in each category are marked in bold.
</tableCaption>
<bodyText confidence="0.999774125">
nounced than the expansion of the negative set.
(About 66.8% of MSOL(ASL) words are positive,
whereas only 33.2% are negative.) This suggests
that there are many more near-synonyms of pos-
itive words than near-synonyms of negative ones,
and so there are many more forms for expressing
positive sentiments than forms for expressing neg-
ative sentiment.
</bodyText>
<subsectionHeader confidence="0.996514">
5.2 Limitations
</subsectionHeader>
<bodyText confidence="0.999741384615385">
Some of the errors in MSOL were due to non-
antonymous instantiations of the affix patterns.
For example, immigrate is not antonymous to mi-
grate. Other errors occur because occasionally the
words in the same thesaurus paragraph have dif-
fering semantic orientations. For example, one
paragraph has the words slender and slim (which,
many will agree, are positive) as well as the words
wiry and lanky (which many will deem negative).
Both these kinds of errors can be mitigated using a
complementary source of information, such as co-
occurrence with other known positive and negative
words (the Turney–Littman method).
</bodyText>
<subsectionHeader confidence="0.849273">
5.3 Future work
</subsectionHeader>
<bodyText confidence="0.999975764705882">
Theoretically, a much larger Turney–Littman lex-
icon can be created even though it may be com-
putationally intensive when working with 100 bil-
lion words. However, MSOL and TLL are created
from different sources of information—MSOL
from overtly marked words and a thesaurus, and
TLL from co-occurrence information. Therefore,
a combination of the two approaches is expected
to produce an even more accurate semantic orien-
tation lexicon, even with a modest-sized corpus at
its disposal. This is especially attractive for low
resource languages. We are also developing meth-
ods to leverage the information in an English the-
saurus to create semantic orientation lexicons for a
low-resource language through the use of a bilin-
gual lexicon and a translation disambiguation al-
gorithm.
</bodyText>
<sectionHeader confidence="0.956229" genericHeader="method">
6 Visualizing the semantic orientation of
thesaurus categories
</sectionHeader>
<bodyText confidence="0.999890037037037">
In recent years, there have been substantial de-
velopments in the field of information visualiza-
tion, and it is becoming increasingly clear that
good visualizations can not only convey informa-
tion quickly, but are also an important tool for
gaining insight into an algorithm, detecting sys-
tematic errors, and understanding the task. In this
section, we present some preliminary visualiza-
tions that are helping us understand our approach
beyond the evaluations described above.
As discussed in Section 3.1.1, the affix seeds
set connects the thesaurus words with opposite se-
mantic orientation. Usually these pairs of words
occur in different thesaurus categories, but this is
not necessary. We can think of these connections
as relationships of contrast in meaning and seman-
tic orientation, not just between the two words
but also between the two categories. To better
aid our understanding of the automatically deter-
mined category relationships we visualized this
network using the Fruchterman-Reingold force-
directed graph layout algorithm (Fruchterman and
Reingold, 1991) and the NodeXL network analy-
sis tool (Smith et al., 2009) 5.
Our dataset consists of 812 categories from the
Macquarie Thesaurus and 27,155 antonym edges
between them. There can be an edge from a cat-
</bodyText>
<footnote confidence="0.996876">
5Available from http://www.codeplex.com/NodeXL
</footnote>
<page confidence="0.994704">
604
</page>
<figureCaption confidence="0.98319">
Figure 1: After removing edges with low weight we can see the structure the network backbone. Isolate
</figureCaption>
<bodyText confidence="0.989834457142857">
category pairs are drawn in a ring around the main connected component and singletons are staggered
in the corners. Each node is colored by its semantic orientation (red for negative, blue for positive)
and edges are colored by their weight, from red to blue. Node shape also codes semantic orientation,
with triangles positive and circles negative. Size codes the magnitude the semantic orientation, with the
largest nodes representing the extremes. Node labels are shown for nodes in isolates and those in the top
20 for betweenness centrality.
egory to itself called a self-edge, indicating that
a word and its antonym (with opposite seman-
tic orientation) both exist in the same category.
There can be multiple edges between two cate-
gories indicating that one or more words in one
category have one or more antonyms in the other
category. These multiple edges between category
pairs were merged together resulting in 14,597
weighted meta-edges. For example, if there are n
edges between a category pair they were replaced
by a single meta-edge of weight n.
The network is too dense and interconnected
for force-directed placement to generate a useful
publication-size drawing of the entire network. By
removing edges that had a weight less than 6, we
can visualize a smaller and more understandable
540 edge network of the core categories and any
new isolates created. Additionally, we show only
edges between categories with opposite semantic
orientations (Figure 1). Observe that there are
three groups of nodes: those in the core connected
component, the small isolates in the ring surround-
ing it, and the connectionless singletons arranged
in the corners.
Each node c (thesaurus category) is colored on
a red to blue continuous scale according to its se-
mantic orientation SO, which is computed purely
from its graph structure (in-degree ID and out-
degree OD):
</bodyText>
<equation confidence="0.982159666666667">
OD(c) − ID(c)
SO(c) = (1)
OD(c) + ID(c)
</equation>
<bodyText confidence="0.958637">
Blue nodes represent categories with many pos-
itive words; we will call them positive cate-
</bodyText>
<page confidence="0.997929">
605
</page>
<bodyText confidence="0.999944152777778">
gories (p). Red nodes are categories with many
negative words; we will call them negative cate-
gories (n). Shades of purple in between are cat-
egories that have words with both positive and
negative semantic orientation (mixed categories).
Similarly, edges are colored according to their
weight from red (small weight) to blue (large
weight). We also use shape coding for seman-
tic orientation, with triangles being positive and
circles negative, and the size of the node depicts
the magnitude of the semantic orientation. For
example, the pair HEARING(p)–DEAFNESS(n) in
the top left of Figure 1 represent the two size ex-
tremes: HEARING has a semantic orientation of 1
and DEAFNESS has a score of -1. The mixed cat-
egories with near 0 semantic orientation such as
LIKELIHOOD with a score of .07 are the smallest.
Nodes are labeled by the thesaurus-provided
head words—a word or phrase that best represents
the coarse meaning of the category. For read-
ability, we have restricted the labels to nodes in
the isolates and the top 20 nodes in the core con-
nected component that have the highest between-
ness centrality, which means they occur on more
shortest paths between other nodes in the network
(i.e., they are the bridges or gatekeepers).
From the ring of isolates we can see how
many antonymous categories, and their se-
mantic orientations, are correctly recognized.
For example, ASSERTION(p)–DENIAL(n),
HEARING(p)–DEAFNESS(n), GRATEFULNESS(p)–
UNGRATEFULNESS(n), and so on. Some codings
may seem less intuitive, such as those in the core,
but much of this is the effect of abstracting away
the low weight edges, which may have more
clearly identified the relationships.
An alternative approach to removing edges with
low weight is to filter categories in the network
based on graph-theoretic metrics like betweenness
centrality, closeness centrality, and eigenvector
centrality. We discussed betweenness central-
ity before. The closeness centrality of a node is
the average distance along the shortest path be-
tween that node and all other nodes reachable from
it. Eigenvector centrality is another measure of
node importance, assigning node score based on
the idea that connections to high-scoring nodes are
more important than those to low-scoring ones.
We removed nodes with less than 0.1 between-
ness centrality, less than 0.04 eigenvector central-
ity, and above 2.1 closeness centrality, leaving
the key 56 nodes. They have 497 edges between
them, of which we show only those between cat-
egories with opposite semantic orientations (Fig-
ure 2). Node and edge color, size, and shape cod-
ing is as before.
Observe that most of these categories have a
strongly evaluative nature. Also, as our algorithm
makes connections using overt negative markers,
it makes sense that the central categories in our
network have negative orientation (negative cat-
egories have many words with overt markings).
It is interesting, though, how some positive and
mixed categories reside in the core too. Further in-
spection revealed that these categories have a large
number of words within them. For example, it
may be less intuitive as to why the category of MU-
SIC is listed in the core, but this is because it has
about 1,200 words in it (on average, each category
has about 120 words), and because many of these
words, such as harmonious(p), melodious(n), and
lament(n) are evaluative in nature.
</bodyText>
<sectionHeader confidence="0.99901" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999976307692308">
We created a high-coverage semantic orientation
lexicon using only affix rules and a Roget-like
thesaurus. The method does not require terms
with manually annotated semantic orientation la-
bels, though we show that if available they can be
used to further improve both the correctness of its
entries and its coverage. The lexicon has about
twenty times as many entries as in the General In-
quirer and the Turney–Littman lexicons, and in-
cludes entries for both individual words and com-
mon multi-word expressions. Experiments show
that it has significantly more correct entries than
SentiWordNet. The approach is complementary to
that of Turney and Littman (2003) and a combina-
tion of this approach with co-occurrence statistics
(even if drawn from a modest sized corpus) is ex-
pected to yield an even better lexicon.
Visualization of the thesaurus categories as per
the semantic orientations assigned to them by our
algorithm reveals that affix patterns produce a
strongly connected graph and that indeed there are
many long chains of positive and negative cate-
gories. Furthermore, the key categories of this
graph (the ones with high centrality and closeness)
are strongly evaluative in nature, and most of them
tend to have negative semantic orientation.
</bodyText>
<page confidence="0.997602">
606
</page>
<figureCaption confidence="0.988686666666667">
Figure 2: After filtering out nodes based on graph-theoretic metrics, the core of the network becomes
visible. The visualization is colored as in Figure 1, and we can see how the core is dominated by
categories with negative semantic orientation (red). Shape, size, and color coding is as before.
</figureCaption>
<sectionHeader confidence="0.998112" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999971363636364">
We thank Douglas W. Oard, Ben Schneiderman,
Judith Klavans and the anonymous reviewers for
their valuable feedback. This work was supported,
in part, by the National Science Foundation un-
der Grant No. IIS-0705832, in part, by the Human
Language Technology Center of Excellence, and
in part, by Microsoft Research for the NodeXL
project. Any opinions, findings, and conclusions
or recommendations expressed in this material are
those of the authors and do not necessarily reflect
the views of the sponsor.
</bodyText>
<sectionHeader confidence="0.999175" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99759340625">
Saima Aman and Stan Szpakowicz. 2007. Identify-
ing expressions of emotion in text. Text, Speech and
Dialogue, 4629:196–205.
Alina Andreevskaia and Sabine Bergler. 2006. Mining
WordNet for fuzzy sentiment: Sentiment tag extrac-
tion from WordNet glosses. In Proceedings of the
EACL, Trento, Italy.
Edwin Battistella. 1990. Markedness: The Evalua-
tive Superstructure of Language. State University
of New York Press, Albany, New York.
John R. L. Bernard, editor. 1986. The Macquarie The-
saurus. Macquarie Library, Sydney, Australia.
Jerry D. Boucher and Charles E. Osgood. 1969. The
pollyanna hypothesis. Journal of Verbal Learning
and Verbal Behaviour, 8:1–8.
Yejin Choi and Claire Cardie. 2008. Learning with
compositional semantics as structural inference for
subsentential sentiment analysis. In Proceedings of
Empirical Methods in Natural Language Processing
(EMNLP-2008), Waikiki, Hawaii.
Andrea Esuli and Fabrizio Sebastiani. 2006. Senti-
WordNet: A publicly available lexical resource for
opinion mining. In Proceedings of LREC, pages
417–422, Genoa, Italy.
Andrea Esuli. 2008. Automatic Generation of Lexical
Resources for Opinion Mining: Models, Algorithms
and Applications. Ph.D. thesis, Department of Infor-
mation Engineering, University of Pisa, Pisa, Italy.
Thomas M. J. Fruchterman and Edward M. Reingold.
1991. Graph drawing by force-directed placement.
Software: Practice and Experience, 21(11):1129–
1164.
</reference>
<page confidence="0.991257">
607
</page>
<reference confidence="0.978733661016949">
Gregory Grefenstette, Yan Qu, David Evans, and James
Shanahan. 2004. Validating the coverage of lex-
ical resources for affect analysis and automatically
classifying new words along semantic axes. In
James Shanahan Yan Qu and Janyce Wiebe, editors,
Exploring Attitude and Affect in Text: Theories and
Applications, AAAI-2004 Spring Symposium Series,
pages 71–78, San Jose, California.
Vasileios Hatzivassiloglou and Kathleen McKeown.
1997. Predicting the semantic orientation of ad-
jectives. In Proceedings of EACL, pages 174–181,
Madrid, Spain.
Minqing Hu and Bing Liu. 2004. Mining and
summarizing customer reviews. In Proceedings of
ACM SIGKDD International ConferenceDiscovery
and Data Mining (KDD-04), Seattle, WA.
Mario Jarmasz and Stan Szpakowicz. 2003. Ro-
get’s Thesaurus and semantic similarity. In Pro-
ceedings of the International Conference on Recent
Advances in Natural Language Processing (RANLP-
2003), pages 212–219, Borovets, Bulgaria.
Jaap Kamps, Maarten Marx, Robert J. Mokken, and
Maarten de Rijke. 2004. Using WordNet to mea-
sure semantic orientation of adjectives. In LREC.
Hiroshi Kanayama and Tetsuya Nasukawa. 2006.
Fully automatic lexicon expansion for domain-
oriented sentiment analysis. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP), pages 355–363, Syd-
ney, Australia, July. Association for Computational
Linguistics.
Michael H. Kelly. 2000. Naming on the bright side of
life. volume 48, pages 3–26.
Adrienne Lehrer. 1974. Semantic fields and lexical
structure. North-Holland; American Elsevier, Ams-
terdam and New York.
Lucian Vlad Lita, Andrew Hazen Schlaikjer, We-
iChang Hong, and Eric Nyberg. 2005. Qualita-
tive dimensions in question answering: Extending
the definitional QA task. In Proceedings of AAAI,
pages 1616–1617. Student abstract.
John Lyons. 1977. Semantics, volume 1. Cambridge
University Press.
Saif Mohammad and Graeme Hirst. 2006. Distribu-
tional measures of concept-distance: A task-oriented
evaluation. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing
(EMNLP-2006), pages 35–43, Sydney, Australia.
Saif Mohammad, Bonnie Dorr, Melissa Egan, Jimmy
Lin, and David Zajic. 2008a. Multiple alternative
sentence compressions and word-pair antonymy for
automatic text summarization and recognizing tex-
tual entailment. In Proceedings of the Text Analysis
Conference (TAC-2008), Gaithersburg, MD.
Saif Mohammad, Bonnie Dorr, and Graeme Hirst.
2008b. Computing word-pair antonymy. In Pro-
ceedings of the Conference on Empirical Methods
in Natural Language Processing, Waikiki, Hawaii.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Foundations and Trends in In-
formation Retrieval, 2(1–2):1–135.
Yohei Seki, Koji Eguchi, and Noriko Kando. 2004.
Analysis of multi-document viewpoint summariza-
tion using multi-dimensional genres. In Proceed-
ings of the AAAI Spring Symposium on Exploring
Attitude and Affect in Text: Theories and Applica-
tions, pages 142–145.
Marc Smith, Ben Shneiderman, Natasa Milic-Frayling,
Eduarda Mendes Rodrigues, Vladimir Barash, Cody
Dunne, Tony Capone, Adam Perer, and Eric Gleave.
2009. Analyzing (social media) networks with
NodeXL. In C&amp;T ’09: Proc. Fourth International
Conference on Communities and Technologies, Lec-
ture Notes in Computer Science. Springer.
Swapna Somasundaran, Theresa Wilson, Janyce
Wiebe, and Veselin Stoyanov. 2007. QA with atti-
tude: Exploiting opinion type analysis for improving
question answering in on-line discussions and the
news. In Proceedings of the International Confer-
ence on Weblogs and Social Media (ICWSM).
Philip Stone, Dexter Dunphy, Marshall Smith, and
Daniel Ogilvie. 1966. The General Inquirer: A
Computer Approach to Content Analysis. MIT.
Carlo Strapparava and Alessandro Valitutti. 2004.
WordNet-affect: and affective extension of Word-
Net. In Proceedings of LREC, Lisbon, Portugal.
Hiroya Takamura, Takashi Inui, and Manabu Okumura.
2005. Extracting semantic orientation of words us-
ing spin model. In Proceedings of the Association
for Computational Linguistics (ACL), pages 133–
140.
Junichi Tatemura. 2000. Virtual reviewers for collabo-
rative exploration of movie reviews. In Proceedings
of Intelligent User Interfaces (IUI), pages 272–275.
Loren Terveen, Will Hill, Brian Amento, David Mc-
Donald, and Josh Creter. 1997. PHOAKS: A system
for sharing recommendations. Communications of
the Association for Computing Machinery (CACM),
40(3):59–62.
Peter Turney and Michael Littman. 2003. Measuring
praise and criticism: Inference of semantic orienta-
tion from association. ACM Transactions on Infor-
mation Systems (TOIS), 21(4):315–346.
Peter Turney. 2002. Thumbs up or thumbs down? se-
mantic orientation applied to unsupervised classifi-
cation of reviews. In Proceedings of ACL, pages
417–424, Philadelphia, Pennsylvania.
Janyce M. Wiebe. 1994. Tracking point of view in nar-
rative. Computational Linguistics, 20(2):233–287.
Theresa Wilson, Janyce Wiebe, and Paul Hoffman.
2005. Recognizing contextual polarity in phrase-
level sentiment analysis. In Proceedings of HLT-
EMNLP, pages 347–354, Vancouver, Canada.
Hong Yu and Vassileios Hatzivassiloglou. 2003. To-
wards answering opinion questions: Separating facts
from opinions and identifying the polarity of opinion
sentences. In Proceedings of EMNLP, pages 129–
136, Morristown, NJ.
</reference>
<page confidence="0.997221">
608
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.101847">
<title confidence="0.8764556">Generating High-Coverage Semantic Orientation From Overtly Marked Words and a Thesaurus Cody for Computational Linguistics and Information Interaction</title>
<author confidence="0.351712">for Advanced Computer</author>
<affiliation confidence="0.520997666666667">of Computer University of Language Technology Center of and</affiliation>
<abstract confidence="0.995630172413793">Sentiment analysis often relies on a semantic orientation lexicon of positive and negative words. A number of approaches have been proposed for creating such lexicons, but they tend to be computationally expensive, and usually rely on significant manual annotation and large corpora. Most of these methods use WordNet. In contrast, we propose a simple approach to generate a high-coverage semantic orientation lexicon, which includes both individual words and multi-word expressions, using only a Roget-like thesaurus and a handful of affixes. Further, the lexicon has properties that support the Polyanna Hypothesis. Using the General Inquirer as gold standard, we show that our lexicon has 14 percentage points more correct entries than the leading WordNet-based high-coverage lexicon (SentiWordNet). In an extrinsic evaluation, we obtain significantly higher performance in determining phrase polarity using our thesaurus-based lexicon than with any other. Additionally, we explore the use of visualization techniques to gain insight into the our algorithm beyond the evaluations mentioned above.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Saima Aman</author>
<author>Stan Szpakowicz</author>
</authors>
<title>Identifying expressions of emotion</title>
<date>2007</date>
<booktitle>in text. Text, Speech and Dialogue,</booktitle>
<pages>4629--196</pages>
<contexts>
<context position="5068" citStr="Aman and Szpakowicz (2007)" startWordPosition="760" endWordPosition="763">e use of any text corpora or manually annotated semantic orientation labels. Both of these resources may be used, if available, to further improve results. The lexicon has about twenty times the number of entries in the GI lexicon, and it includes entries for both individual words and common multiword expressions. The method makes use of a Roget-like thesaurus and a handful of antonymgenerating affix patterns. Whereas thesauri have long been used to estimate semantic distance (Jarmasz and Szpakowicz, 2003; Mohammad and Hirst, 2006), the closest thesaurus-based work on sentiment analysis is by Aman and Szpakowicz (2007) on detecting emotions such as happiness, sadness, and anger. We evaluated our thesaurusbased algorithm both intrinsically and extrinsically and show that the semantic orientation lexicon it generates has significantly more correct entries than the state-of-the-art high-coverage lexicon SentiWordNet, and that it has a significantly higher coverage than the General Inquirer and Turney–Littman lexicons. In Section 2 we examine related work. Section 3 presents our algorithm for creating semantic orientation lexicons. We describe intrinsic and extrinsic evaluation experiments in Section 4, followe</context>
</contexts>
<marker>Aman, Szpakowicz, 2007</marker>
<rawString>Saima Aman and Stan Szpakowicz. 2007. Identifying expressions of emotion in text. Text, Speech and Dialogue, 4629:196–205.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alina Andreevskaia</author>
<author>Sabine Bergler</author>
</authors>
<title>Mining WordNet for fuzzy sentiment: Sentiment tag extraction from WordNet glosses.</title>
<date>2006</date>
<booktitle>In Proceedings of the EACL,</booktitle>
<location>Trento, Italy.</location>
<marker>Andreevskaia, Bergler, 2006</marker>
<rawString>Alina Andreevskaia and Sabine Bergler. 2006. Mining WordNet for fuzzy sentiment: Sentiment tag extraction from WordNet glosses. In Proceedings of the EACL, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edwin Battistella</author>
</authors>
<title>Markedness: The Evaluative Superstructure of Language.</title>
<date>1990</date>
<publisher>State University of New York Press,</publisher>
<location>Albany, New York.</location>
<contexts>
<context position="9622" citStr="Battistella, 1990" startWordPosition="1489" endWordPosition="1490">ous with the positive seeds “positive” and words synonymous with the negative seeds “negative”. The two steps are described in the subsections below. Our implementation of the algorithm used the Macquarie Thesaurus (Bernard, 1986). It has about 100,000 unique words and phrases. 3.1 Seed words 3.1.1 Automatically identifying seed words It is known from marking theory that overtly marked words, such as dishonest, unhappy, and impure, tend to have negative semantic orientation, whereas their unmarked counterparts, honest, happy, and pure, tend to have positive semantic orientation (Lehrer, 1974; Battistella, 1990). Exceptions such as biased–unbiased and partial– impartial do exist, and in some contexts even a predominantly negative marked word may be positive. For example irreverent is negative in most contexts, but positive in the sentence below: Millions offans follow Moulder’s irreverent quest for truth. However, as we will show through experiments, the exceptions are far outnumbered by those that abide by the predictions of marking theory. We used a set of 11 antonym-generating affix patterns to generate overtly marked words and their unmarked counterparts (Table 1). Similar antonyms-generating aff</context>
</contexts>
<marker>Battistella, 1990</marker>
<rawString>Edwin Battistella. 1990. Markedness: The Evaluative Superstructure of Language. State University of New York Press, Albany, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John R L Bernard</author>
<author>editor</author>
</authors>
<date>1986</date>
<booktitle>The Macquarie Thesaurus. Macquarie Library,</booktitle>
<location>Sydney, Australia.</location>
<marker>Bernard, editor, 1986</marker>
<rawString>John R. L. Bernard, editor. 1986. The Macquarie Thesaurus. Macquarie Library, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry D Boucher</author>
<author>Charles E Osgood</author>
</authors>
<title>The pollyanna hypothesis.</title>
<date>1969</date>
<journal>Journal of Verbal Learning and Verbal Behaviour,</journal>
<volume>8</volume>
<marker>Boucher, Osgood, 1969</marker>
<rawString>Jerry D. Boucher and Charles E. Osgood. 1969. The pollyanna hypothesis. Journal of Verbal Learning and Verbal Behaviour, 8:1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yejin Choi</author>
<author>Claire Cardie</author>
</authors>
<title>Learning with compositional semantics as structural inference for subsentential sentiment analysis.</title>
<date>2008</date>
<booktitle>In Proceedings of Empirical Methods in Natural Language Processing (EMNLP-2008),</booktitle>
<location>Waikiki, Hawaii.</location>
<marker>Choi, Cardie, 2008</marker>
<rawString>Yejin Choi and Claire Cardie. 2008. Learning with compositional semantics as structural inference for subsentential sentiment analysis. In Proceedings of Empirical Methods in Natural Language Processing (EMNLP-2008), Waikiki, Hawaii.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>SentiWordNet: A publicly available lexical resource for opinion mining.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC,</booktitle>
<pages>417--422</pages>
<location>Genoa, Italy.</location>
<contexts>
<context position="3603" citStr="Esuli and Sebastiani, 2006" startWordPosition="537" endWordPosition="540">e GI lexicon has orientation labels for only about 3,600 entries. The Pittsburgh subjectivity lexicon (PSL) (Wilson et al., 2005), which draws from the General Inquirer and other sources, also has semantic orientation labels, but only for about 8,000 words. Automatic approaches to creating a semantic orientation lexicon and, more generally, approaches for word-level sentiment annotation can be grouped into two kinds: (1) those that rely on manually created lexical resources—most of which use WordNet (Strapparava and Valitutti, 2004; Hu and Liu, 2004; Kamps et al., 2004; Takamura et al., 2005; Esuli and Sebastiani, 2006; An1http://www.wjh.harvard.edu/ inquirer 599 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 599–608, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP dreevskaia and Bergler, 2006; Kanayama and Nasukawa, 2006); and (2) those that rely on text corpora (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Yu and Hatzivassiloglou, 2003; Grefenstette et al., 2004). Many of these lexicons, such as SentiWordNet (SWN) (Esuli and Sebastiani, 2006) were created using supervised classifiers and significant manual annotation, whereas others such as </context>
<context position="6977" citStr="Esuli and Sebastiani (2006)" startWordPosition="1064" endWordPosition="1067">des. An edge between two nodes indicates either that the two adjectives have the same or opposite semantic orientation. A clustering algorithm partitions the graph into two subgraphs such that the nodes in a subgraph have the same semantic orientation. The subgraph with adjectives that occur more often in text is marked positive and the other negative. They used a 21 million word corpus and evaluated their algorithm on a labeled set of 1336 adjectives (657 positive and 679 negative). Our approach does not require manually annotated semantic orientation entries to train on and is much simpler. Esuli and Sebastiani (2006) used a supervised algorithm to attach semantic orientation scores to WordNet glosses. They train a set of ternary classifiers using different training data and learning methods. The set of semantic orientation scores of all WordNet synsets is released by the name SentiWordNet.2 An evaluation of SentiWordNet by comparing orientation scores of about 1,000 WordNet glosses to scores assigned by human annotators is presented in Esuli (2008). Our approach uses a Roget-like thesaurus, and it does not use any supervised classifiers. Turney and Littman (2003) proposed a minimally supervised algorithm </context>
</contexts>
<marker>Esuli, Sebastiani, 2006</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2006. SentiWordNet: A publicly available lexical resource for opinion mining. In Proceedings of LREC, pages 417–422, Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
</authors>
<title>Automatic Generation of Lexical Resources for Opinion Mining: Models, Algorithms and Applications.</title>
<date>2008</date>
<tech>Ph.D. thesis,</tech>
<institution>Department of Information Engineering, University of Pisa,</institution>
<location>Pisa, Italy.</location>
<contexts>
<context position="7417" citStr="Esuli (2008)" startWordPosition="1134" endWordPosition="1135"> (657 positive and 679 negative). Our approach does not require manually annotated semantic orientation entries to train on and is much simpler. Esuli and Sebastiani (2006) used a supervised algorithm to attach semantic orientation scores to WordNet glosses. They train a set of ternary classifiers using different training data and learning methods. The set of semantic orientation scores of all WordNet synsets is released by the name SentiWordNet.2 An evaluation of SentiWordNet by comparing orientation scores of about 1,000 WordNet glosses to scores assigned by human annotators is presented in Esuli (2008). Our approach uses a Roget-like thesaurus, and it does not use any supervised classifiers. Turney and Littman (2003) proposed a minimally supervised algorithm to calculate the semantic orientation of a word by determining if its tendency to co-occur with a small set of positive words is greater than its tendency to co-occur with a small set of negative words. They show that their approach performs better when it has a large amount of text at its disposal. They use text from 350 million web-pages (more than 100 billion words). Our approach does not make use of any text corpora, although co-occ</context>
</contexts>
<marker>Esuli, 2008</marker>
<rawString>Andrea Esuli. 2008. Automatic Generation of Lexical Resources for Opinion Mining: Models, Algorithms and Applications. Ph.D. thesis, Department of Information Engineering, University of Pisa, Pisa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas M J Fruchterman</author>
<author>Edward M Reingold</author>
</authors>
<title>Graph drawing by force-directed placement.</title>
<date>1991</date>
<journal>Software: Practice and Experience,</journal>
<volume>21</volume>
<issue>11</issue>
<pages>1164</pages>
<contexts>
<context position="24835" citStr="Fruchterman and Reingold, 1991" startWordPosition="3912" endWordPosition="3915">nd the evaluations described above. As discussed in Section 3.1.1, the affix seeds set connects the thesaurus words with opposite semantic orientation. Usually these pairs of words occur in different thesaurus categories, but this is not necessary. We can think of these connections as relationships of contrast in meaning and semantic orientation, not just between the two words but also between the two categories. To better aid our understanding of the automatically determined category relationships we visualized this network using the Fruchterman-Reingold forcedirected graph layout algorithm (Fruchterman and Reingold, 1991) and the NodeXL network analysis tool (Smith et al., 2009) 5. Our dataset consists of 812 categories from the Macquarie Thesaurus and 27,155 antonym edges between them. There can be an edge from a cat5Available from http://www.codeplex.com/NodeXL 604 Figure 1: After removing edges with low weight we can see the structure the network backbone. Isolate category pairs are drawn in a ring around the main connected component and singletons are staggered in the corners. Each node is colored by its semantic orientation (red for negative, blue for positive) and edges are colored by their weight, from </context>
</contexts>
<marker>Fruchterman, Reingold, 1991</marker>
<rawString>Thomas M. J. Fruchterman and Edward M. Reingold. 1991. Graph drawing by force-directed placement. Software: Practice and Experience, 21(11):1129– 1164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory Grefenstette</author>
<author>Yan Qu</author>
<author>David Evans</author>
<author>James Shanahan</author>
</authors>
<title>Validating the coverage of lexical resources for affect analysis and automatically classifying new words along semantic axes.</title>
<date>2004</date>
<booktitle>In James Shanahan Yan Qu and Janyce Wiebe, editors, Exploring Attitude and Affect in Text: Theories and Applications, AAAI-2004 Spring Symposium Series,</booktitle>
<pages>71--78</pages>
<location>San Jose, California.</location>
<contexts>
<context position="4021" citStr="Grefenstette et al., 2004" startWordPosition="598" endWordPosition="601">s: (1) those that rely on manually created lexical resources—most of which use WordNet (Strapparava and Valitutti, 2004; Hu and Liu, 2004; Kamps et al., 2004; Takamura et al., 2005; Esuli and Sebastiani, 2006; An1http://www.wjh.harvard.edu/ inquirer 599 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 599–608, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP dreevskaia and Bergler, 2006; Kanayama and Nasukawa, 2006); and (2) those that rely on text corpora (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Yu and Hatzivassiloglou, 2003; Grefenstette et al., 2004). Many of these lexicons, such as SentiWordNet (SWN) (Esuli and Sebastiani, 2006) were created using supervised classifiers and significant manual annotation, whereas others such as the Turney and Littman lexicon (TLL) (2003) were created from very large corpora (more than 100 billion words). In contrast, we propose a computationally inexpensive method to compile a high-coverage semantic orientation lexicon without the use of any text corpora or manually annotated semantic orientation labels. Both of these resources may be used, if available, to further improve results. The lexicon has about t</context>
</contexts>
<marker>Grefenstette, Qu, Evans, Shanahan, 2004</marker>
<rawString>Gregory Grefenstette, Yan Qu, David Evans, and James Shanahan. 2004. Validating the coverage of lexical resources for affect analysis and automatically classifying new words along semantic axes. In James Shanahan Yan Qu and Janyce Wiebe, editors, Exploring Attitude and Affect in Text: Theories and Applications, AAAI-2004 Spring Symposium Series, pages 71–78, San Jose, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Hatzivassiloglou</author>
<author>Kathleen McKeown</author>
</authors>
<title>Predicting the semantic orientation of adjectives.</title>
<date>1997</date>
<booktitle>In Proceedings of EACL,</booktitle>
<pages>174--181</pages>
<location>Madrid,</location>
<contexts>
<context position="3936" citStr="Hatzivassiloglou and McKeown, 1997" startWordPosition="585" endWordPosition="588">, more generally, approaches for word-level sentiment annotation can be grouped into two kinds: (1) those that rely on manually created lexical resources—most of which use WordNet (Strapparava and Valitutti, 2004; Hu and Liu, 2004; Kamps et al., 2004; Takamura et al., 2005; Esuli and Sebastiani, 2006; An1http://www.wjh.harvard.edu/ inquirer 599 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 599–608, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP dreevskaia and Bergler, 2006; Kanayama and Nasukawa, 2006); and (2) those that rely on text corpora (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Yu and Hatzivassiloglou, 2003; Grefenstette et al., 2004). Many of these lexicons, such as SentiWordNet (SWN) (Esuli and Sebastiani, 2006) were created using supervised classifiers and significant manual annotation, whereas others such as the Turney and Littman lexicon (TLL) (2003) were created from very large corpora (more than 100 billion words). In contrast, we propose a computationally inexpensive method to compile a high-coverage semantic orientation lexicon without the use of any text corpora or manually annotated semantic orientation labels. Both of these res</context>
<context position="6211" citStr="Hatzivassiloglou and McKeown (1997)" startWordPosition="936" endWordPosition="939">n lexicons. We describe intrinsic and extrinsic evaluation experiments in Section 4, followed by a discussion of the results in Section 5. Additionally, in Section 6 we show preliminary visualizations of how our algorithm forms chains of positive and negative thesaurus categories. Good visualizations are not only effective in presenting information to the user, but also help us better understand our algorithm. Section 7 has our conclusions. 2 Related Work Pang and Lee (2008) provide an excellent survey of the literature on sentiment analysis. Here we briefly describe the work closest to ours. Hatzivassiloglou and McKeown (1997) proposed a supervised algorithm to determine the semantic orientation of adjectives. They first generate a graph that has adjectives as nodes. An edge between two nodes indicates either that the two adjectives have the same or opposite semantic orientation. A clustering algorithm partitions the graph into two subgraphs such that the nodes in a subgraph have the same semantic orientation. The subgraph with adjectives that occur more often in text is marked positive and the other negative. They used a 21 million word corpus and evaluated their algorithm on a labeled set of 1336 adjectives (657 </context>
</contexts>
<marker>Hatzivassiloglou, McKeown, 1997</marker>
<rawString>Vasileios Hatzivassiloglou and Kathleen McKeown. 1997. Predicting the semantic orientation of adjectives. In Proceedings of EACL, pages 174–181, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of ACM SIGKDD International ConferenceDiscovery and Data Mining (KDD-04),</booktitle>
<location>Seattle, WA.</location>
<contexts>
<context position="3532" citStr="Hu and Liu, 2004" startWordPosition="524" endWordPosition="527"> the General Inquirer (GI) (Stone et al., 1966).1 However, the GI lexicon has orientation labels for only about 3,600 entries. The Pittsburgh subjectivity lexicon (PSL) (Wilson et al., 2005), which draws from the General Inquirer and other sources, also has semantic orientation labels, but only for about 8,000 words. Automatic approaches to creating a semantic orientation lexicon and, more generally, approaches for word-level sentiment annotation can be grouped into two kinds: (1) those that rely on manually created lexical resources—most of which use WordNet (Strapparava and Valitutti, 2004; Hu and Liu, 2004; Kamps et al., 2004; Takamura et al., 2005; Esuli and Sebastiani, 2006; An1http://www.wjh.harvard.edu/ inquirer 599 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 599–608, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP dreevskaia and Bergler, 2006; Kanayama and Nasukawa, 2006); and (2) those that rely on text corpora (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Yu and Hatzivassiloglou, 2003; Grefenstette et al., 2004). Many of these lexicons, such as SentiWordNet (SWN) (Esuli and Sebastiani, 2006) were created using supervised</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of ACM SIGKDD International ConferenceDiscovery and Data Mining (KDD-04), Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mario Jarmasz</author>
<author>Stan Szpakowicz</author>
</authors>
<title>Roget’s Thesaurus and semantic similarity.</title>
<date>2003</date>
<booktitle>In Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP2003),</booktitle>
<pages>212--219</pages>
<location>Borovets, Bulgaria.</location>
<contexts>
<context position="4952" citStr="Jarmasz and Szpakowicz, 2003" startWordPosition="742" endWordPosition="746">st, we propose a computationally inexpensive method to compile a high-coverage semantic orientation lexicon without the use of any text corpora or manually annotated semantic orientation labels. Both of these resources may be used, if available, to further improve results. The lexicon has about twenty times the number of entries in the GI lexicon, and it includes entries for both individual words and common multiword expressions. The method makes use of a Roget-like thesaurus and a handful of antonymgenerating affix patterns. Whereas thesauri have long been used to estimate semantic distance (Jarmasz and Szpakowicz, 2003; Mohammad and Hirst, 2006), the closest thesaurus-based work on sentiment analysis is by Aman and Szpakowicz (2007) on detecting emotions such as happiness, sadness, and anger. We evaluated our thesaurusbased algorithm both intrinsically and extrinsically and show that the semantic orientation lexicon it generates has significantly more correct entries than the state-of-the-art high-coverage lexicon SentiWordNet, and that it has a significantly higher coverage than the General Inquirer and Turney–Littman lexicons. In Section 2 we examine related work. Section 3 presents our algorithm for crea</context>
</contexts>
<marker>Jarmasz, Szpakowicz, 2003</marker>
<rawString>Mario Jarmasz and Stan Szpakowicz. 2003. Roget’s Thesaurus and semantic similarity. In Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP2003), pages 212–219, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaap Kamps</author>
<author>Maarten Marx</author>
<author>Robert J Mokken</author>
<author>Maarten de Rijke</author>
</authors>
<title>Using WordNet to measure semantic orientation of adjectives.</title>
<date>2004</date>
<booktitle>In LREC.</booktitle>
<marker>Kamps, Marx, Mokken, de Rijke, 2004</marker>
<rawString>Jaap Kamps, Maarten Marx, Robert J. Mokken, and Maarten de Rijke. 2004. Using WordNet to measure semantic orientation of adjectives. In LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroshi Kanayama</author>
<author>Tetsuya Nasukawa</author>
</authors>
<title>Fully automatic lexicon expansion for domainoriented sentiment analysis.</title>
<date>2006</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>355--363</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="3859" citStr="Kanayama and Nasukawa, 2006" startWordPosition="571" endWordPosition="575">ds. Automatic approaches to creating a semantic orientation lexicon and, more generally, approaches for word-level sentiment annotation can be grouped into two kinds: (1) those that rely on manually created lexical resources—most of which use WordNet (Strapparava and Valitutti, 2004; Hu and Liu, 2004; Kamps et al., 2004; Takamura et al., 2005; Esuli and Sebastiani, 2006; An1http://www.wjh.harvard.edu/ inquirer 599 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 599–608, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP dreevskaia and Bergler, 2006; Kanayama and Nasukawa, 2006); and (2) those that rely on text corpora (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Yu and Hatzivassiloglou, 2003; Grefenstette et al., 2004). Many of these lexicons, such as SentiWordNet (SWN) (Esuli and Sebastiani, 2006) were created using supervised classifiers and significant manual annotation, whereas others such as the Turney and Littman lexicon (TLL) (2003) were created from very large corpora (more than 100 billion words). In contrast, we propose a computationally inexpensive method to compile a high-coverage semantic orientation lexicon without the use of any text</context>
</contexts>
<marker>Kanayama, Nasukawa, 2006</marker>
<rawString>Hiroshi Kanayama and Tetsuya Nasukawa. 2006. Fully automatic lexicon expansion for domainoriented sentiment analysis. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 355–363, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael H Kelly</author>
</authors>
<title>Naming on the bright side of life.</title>
<date>2000</date>
<volume>48</volume>
<pages>3--26</pages>
<contexts>
<context position="20830" citStr="Kelly, 2000" startWordPosition="3273" endWordPosition="3274">n is improved because multiple seed words vote to decide the semantic orientation of a thesaurus paragraph. Recall improves simply because non-seed words in a paragraph are assigned the semantic orientation that is most prevalent among the seeds in the paragraph. 5.1 Support for the Polyanna Hypothesis Boucher and Osgood’s (1969) Polyanna Hypothesis states that people have a preference for using positive words and expressions as opposed to using negative words and expressions. Studies have shown that indeed speakers across languages use positive words much more frequently than negative words (Kelly, 2000). The distribution of positive and negative words in MSOL(ASL) further supports the Polyanna Hypothesis as it shows that even if we start with an equal number of positive and negative seed words, the expansion of the positive set through the thesaurus is much more pro603 SO lexicon All phrases F Only positives Only negatives P R P R F P R F Individual lexicons ASL 0.451 0.165 0.242 0.451 0.165 0.242 0.192 0.063 0.095 GI 0.797 0.323 0.459 0.871 0.417 0.564 0.763 0.288 0.419 MSOL(ASL) 0.623 0.474 0.539 0.631 0.525 0.573 0.623 0.458 0.528 SWN 0.541 0.408 0.465 0.745 0.624 0.679 0.452 0.328 0.380 </context>
</contexts>
<marker>Kelly, 2000</marker>
<rawString>Michael H. Kelly. 2000. Naming on the bright side of life. volume 48, pages 3–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adrienne Lehrer</author>
</authors>
<title>Semantic fields and lexical structure.</title>
<date>1974</date>
<publisher>North-Holland; American Elsevier,</publisher>
<location>Amsterdam and New York.</location>
<contexts>
<context position="9602" citStr="Lehrer, 1974" startWordPosition="1487" endWordPosition="1488"> words synonymous with the positive seeds “positive” and words synonymous with the negative seeds “negative”. The two steps are described in the subsections below. Our implementation of the algorithm used the Macquarie Thesaurus (Bernard, 1986). It has about 100,000 unique words and phrases. 3.1 Seed words 3.1.1 Automatically identifying seed words It is known from marking theory that overtly marked words, such as dishonest, unhappy, and impure, tend to have negative semantic orientation, whereas their unmarked counterparts, honest, happy, and pure, tend to have positive semantic orientation (Lehrer, 1974; Battistella, 1990). Exceptions such as biased–unbiased and partial– impartial do exist, and in some contexts even a predominantly negative marked word may be positive. For example irreverent is negative in most contexts, but positive in the sentence below: Millions offans follow Moulder’s irreverent quest for truth. However, as we will show through experiments, the exceptions are far outnumbered by those that abide by the predictions of marking theory. We used a set of 11 antonym-generating affix patterns to generate overtly marked words and their unmarked counterparts (Table 1). Similar ant</context>
</contexts>
<marker>Lehrer, 1974</marker>
<rawString>Adrienne Lehrer. 1974. Semantic fields and lexical structure. North-Holland; American Elsevier, Amsterdam and New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lucian Vlad Lita</author>
<author>Andrew Hazen Schlaikjer</author>
<author>WeiChang Hong</author>
<author>Eric Nyberg</author>
</authors>
<title>Qualitative dimensions in question answering: Extending the definitional QA task.</title>
<date>2005</date>
<booktitle>In Proceedings of AAAI,</booktitle>
<pages>1616--1617</pages>
<note>Student abstract.</note>
<contexts>
<context position="1995" citStr="Lita et al., 2005" startWordPosition="280" endWordPosition="283">aurus-based lexicon than with any other. Additionally, we explore the use of visualization techniques to gain insight into the our algorithm beyond the evaluations mentioned above. 1 Introduction Sentiment analysis involves determining the opinions and private states (beliefs, emotions, speculations, and so on) of the speaker (Wiebe, 1994). It has received significant attention in recent years due to increasing online opinion content and applications in tasks such as automatic product recommendation systems (Tatemura, 2000; Terveen et al., 1997), question answering (Somasundaran et al., 2007; Lita et al., 2005), and summarizing multiple view points (Seki et al., 2004) and opinions (Mohammad et al., 2008a). A crucial sub-problem is to determine whether positive or negative sentiment is expressed. Automatic methods for this often make use of lexicons of words tagged with positive and negative semantic orientation (Turney, 2002; Wilson et al., 2005; Pang and Lee, 2008). A word is said to have a positive semantic orientation (SO) (or polarity) if it is often used to convey favorable sentiment or evaluation of the topic under discussion. Some example words that have positive semantic orientation are exce</context>
</contexts>
<marker>Lita, Schlaikjer, Hong, Nyberg, 2005</marker>
<rawString>Lucian Vlad Lita, Andrew Hazen Schlaikjer, WeiChang Hong, and Eric Nyberg. 2005. Qualitative dimensions in question answering: Extending the definitional QA task. In Proceedings of AAAI, pages 1616–1617. Student abstract.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lyons</author>
</authors>
<date>1977</date>
<journal>Semantics,</journal>
<volume>1</volume>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="10272" citStr="Lyons, 1977" startWordPosition="1588" endWordPosition="1589">nd partial– impartial do exist, and in some contexts even a predominantly negative marked word may be positive. For example irreverent is negative in most contexts, but positive in the sentence below: Millions offans follow Moulder’s irreverent quest for truth. However, as we will show through experiments, the exceptions are far outnumbered by those that abide by the predictions of marking theory. We used a set of 11 antonym-generating affix patterns to generate overtly marked words and their unmarked counterparts (Table 1). Similar antonyms-generating affix patterns exist for many languages (Lyons, 1977). The 11 chosen affix patterns generated 2,692 pairs of marked and unmarked valid English words that are listed in the Macquarie Thesaurus. The marked words Affix pattern # word w1 w2 pairs example word pair X disX 382 honest–dishonest X imX 196 possible–impossible X inX 691 consistent–inconsistent X malX 28 adroit–maladroit X misX 146 fortune–misfortune X nonX 73 sense–nonsense X unX 844 happy–unhappy X Xless 208 gut–gutless lX illX 25 legal–illegal rX irX 48 responsible–irresponsible Xless Xful 51 harmless–harmful Total 2692 Table 1: Eleven affix patterns used to generate the seed set of mar</context>
</contexts>
<marker>Lyons, 1977</marker>
<rawString>John Lyons. 1977. Semantics, volume 1. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif Mohammad</author>
<author>Graeme Hirst</author>
</authors>
<title>Distributional measures of concept-distance: A task-oriented evaluation.</title>
<date>2006</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2006),</booktitle>
<pages>35--43</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="4979" citStr="Mohammad and Hirst, 2006" startWordPosition="747" endWordPosition="750">ly inexpensive method to compile a high-coverage semantic orientation lexicon without the use of any text corpora or manually annotated semantic orientation labels. Both of these resources may be used, if available, to further improve results. The lexicon has about twenty times the number of entries in the GI lexicon, and it includes entries for both individual words and common multiword expressions. The method makes use of a Roget-like thesaurus and a handful of antonymgenerating affix patterns. Whereas thesauri have long been used to estimate semantic distance (Jarmasz and Szpakowicz, 2003; Mohammad and Hirst, 2006), the closest thesaurus-based work on sentiment analysis is by Aman and Szpakowicz (2007) on detecting emotions such as happiness, sadness, and anger. We evaluated our thesaurusbased algorithm both intrinsically and extrinsically and show that the semantic orientation lexicon it generates has significantly more correct entries than the state-of-the-art high-coverage lexicon SentiWordNet, and that it has a significantly higher coverage than the General Inquirer and Turney–Littman lexicons. In Section 2 we examine related work. Section 3 presents our algorithm for creating semantic orientation l</context>
</contexts>
<marker>Mohammad, Hirst, 2006</marker>
<rawString>Saif Mohammad and Graeme Hirst. 2006. Distributional measures of concept-distance: A task-oriented evaluation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2006), pages 35–43, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif Mohammad</author>
<author>Bonnie Dorr</author>
<author>Melissa Egan</author>
<author>Jimmy Lin</author>
<author>David Zajic</author>
</authors>
<title>Multiple alternative sentence compressions and word-pair antonymy for automatic text summarization and recognizing textual entailment.</title>
<date>2008</date>
<booktitle>In Proceedings of the Text Analysis Conference (TAC-2008),</booktitle>
<location>Gaithersburg, MD.</location>
<contexts>
<context position="2089" citStr="Mohammad et al., 2008" startWordPosition="296" endWordPosition="299">techniques to gain insight into the our algorithm beyond the evaluations mentioned above. 1 Introduction Sentiment analysis involves determining the opinions and private states (beliefs, emotions, speculations, and so on) of the speaker (Wiebe, 1994). It has received significant attention in recent years due to increasing online opinion content and applications in tasks such as automatic product recommendation systems (Tatemura, 2000; Terveen et al., 1997), question answering (Somasundaran et al., 2007; Lita et al., 2005), and summarizing multiple view points (Seki et al., 2004) and opinions (Mohammad et al., 2008a). A crucial sub-problem is to determine whether positive or negative sentiment is expressed. Automatic methods for this often make use of lexicons of words tagged with positive and negative semantic orientation (Turney, 2002; Wilson et al., 2005; Pang and Lee, 2008). A word is said to have a positive semantic orientation (SO) (or polarity) if it is often used to convey favorable sentiment or evaluation of the topic under discussion. Some example words that have positive semantic orientation are excellent, happy, honest, and so on. Similarly, a word is said to have negative semantic orientati</context>
<context position="8190" citStr="Mohammad et al. (2008" startWordPosition="1264" endWordPosition="1267">gorithm to calculate the semantic orientation of a word by determining if its tendency to co-occur with a small set of positive words is greater than its tendency to co-occur with a small set of negative words. They show that their approach performs better when it has a large amount of text at its disposal. They use text from 350 million web-pages (more than 100 billion words). Our approach does not make use of any text corpora, although co-occurrence statistics could be used to further improve the lexicon. Furthermore, our lexicon has entries for commonly used multi-word expressions as well. Mohammad et al. (2008b) developed a method to determine the degree of antonymy (contrast) between two words using the Macquarie The2http://sentiwordnet.isti.cnr.it/ 600 saurus (Bernard, 1986), co-occurrence statistics, and a small set of antonym-generating affix patterns such as X–disX. Often, one member of a pair of contrasting terms is positive and one member is negative. In this paper, we describe how a subset of those affix patterns can be used in combination with a thesaurus and the edicts of marking theory to create a large lexicon of words and phrases marked with their semantic orientation. 3 Generating the</context>
<context position="11634" citStr="Mohammad et al. (2008" startWordPosition="1809" endWordPosition="1812"> positive, and these form our seed set of positive and negative words. We will refer to this set of orientation-marked words as the affix seeds lexicon (ASL). Note that some words may have multiple marked counterparts, for example, trust– trustless and trust–mistrust. Thus, ASL has more negative words (2,652) than positive ones (2,379). Also, the Xless–Xful pattern generates word pairs that are both overtly marked; words generated from Xless are deemed negative and words generated from Xful are deemed positive. It should be noted that the affix patterns used here are a subset of those used in Mohammad et al. (2008b) to generate antonym pairs. The affix patterns ignored are those that are not expected to generate pairs of words with opposite semantic orientation. For instance, the pattern imX-exX generates word pairs such as import–export and implicit–explicit that are antonymous, but do not have opposite semantic orientations. 3.1.2 Using manually annotated seed words Since manual semantic orientation labels exist for some English words (the GI lexicon), we investigated their usefulness in further improving the coverage and correctness of the entries in our lexicon. We used the GI words as seeds in the</context>
</contexts>
<marker>Mohammad, Dorr, Egan, Lin, Zajic, 2008</marker>
<rawString>Saif Mohammad, Bonnie Dorr, Melissa Egan, Jimmy Lin, and David Zajic. 2008a. Multiple alternative sentence compressions and word-pair antonymy for automatic text summarization and recognizing textual entailment. In Proceedings of the Text Analysis Conference (TAC-2008), Gaithersburg, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif Mohammad</author>
<author>Bonnie Dorr</author>
<author>Graeme Hirst</author>
</authors>
<title>Computing word-pair antonymy.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<location>Waikiki, Hawaii.</location>
<contexts>
<context position="2089" citStr="Mohammad et al., 2008" startWordPosition="296" endWordPosition="299">techniques to gain insight into the our algorithm beyond the evaluations mentioned above. 1 Introduction Sentiment analysis involves determining the opinions and private states (beliefs, emotions, speculations, and so on) of the speaker (Wiebe, 1994). It has received significant attention in recent years due to increasing online opinion content and applications in tasks such as automatic product recommendation systems (Tatemura, 2000; Terveen et al., 1997), question answering (Somasundaran et al., 2007; Lita et al., 2005), and summarizing multiple view points (Seki et al., 2004) and opinions (Mohammad et al., 2008a). A crucial sub-problem is to determine whether positive or negative sentiment is expressed. Automatic methods for this often make use of lexicons of words tagged with positive and negative semantic orientation (Turney, 2002; Wilson et al., 2005; Pang and Lee, 2008). A word is said to have a positive semantic orientation (SO) (or polarity) if it is often used to convey favorable sentiment or evaluation of the topic under discussion. Some example words that have positive semantic orientation are excellent, happy, honest, and so on. Similarly, a word is said to have negative semantic orientati</context>
<context position="8190" citStr="Mohammad et al. (2008" startWordPosition="1264" endWordPosition="1267">gorithm to calculate the semantic orientation of a word by determining if its tendency to co-occur with a small set of positive words is greater than its tendency to co-occur with a small set of negative words. They show that their approach performs better when it has a large amount of text at its disposal. They use text from 350 million web-pages (more than 100 billion words). Our approach does not make use of any text corpora, although co-occurrence statistics could be used to further improve the lexicon. Furthermore, our lexicon has entries for commonly used multi-word expressions as well. Mohammad et al. (2008b) developed a method to determine the degree of antonymy (contrast) between two words using the Macquarie The2http://sentiwordnet.isti.cnr.it/ 600 saurus (Bernard, 1986), co-occurrence statistics, and a small set of antonym-generating affix patterns such as X–disX. Often, one member of a pair of contrasting terms is positive and one member is negative. In this paper, we describe how a subset of those affix patterns can be used in combination with a thesaurus and the edicts of marking theory to create a large lexicon of words and phrases marked with their semantic orientation. 3 Generating the</context>
<context position="11634" citStr="Mohammad et al. (2008" startWordPosition="1809" endWordPosition="1812"> positive, and these form our seed set of positive and negative words. We will refer to this set of orientation-marked words as the affix seeds lexicon (ASL). Note that some words may have multiple marked counterparts, for example, trust– trustless and trust–mistrust. Thus, ASL has more negative words (2,652) than positive ones (2,379). Also, the Xless–Xful pattern generates word pairs that are both overtly marked; words generated from Xless are deemed negative and words generated from Xful are deemed positive. It should be noted that the affix patterns used here are a subset of those used in Mohammad et al. (2008b) to generate antonym pairs. The affix patterns ignored are those that are not expected to generate pairs of words with opposite semantic orientation. For instance, the pattern imX-exX generates word pairs such as import–export and implicit–explicit that are antonymous, but do not have opposite semantic orientations. 3.1.2 Using manually annotated seed words Since manual semantic orientation labels exist for some English words (the GI lexicon), we investigated their usefulness in further improving the coverage and correctness of the entries in our lexicon. We used the GI words as seeds in the</context>
</contexts>
<marker>Mohammad, Dorr, Hirst, 2008</marker>
<rawString>Saif Mohammad, Bonnie Dorr, and Graeme Hirst. 2008b. Computing word-pair antonymy. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, Waikiki, Hawaii.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<booktitle>Foundations and Trends in Information Retrieval,</booktitle>
<pages>2--1</pages>
<contexts>
<context position="2357" citStr="Pang and Lee, 2008" startWordPosition="339" endWordPosition="342">gnificant attention in recent years due to increasing online opinion content and applications in tasks such as automatic product recommendation systems (Tatemura, 2000; Terveen et al., 1997), question answering (Somasundaran et al., 2007; Lita et al., 2005), and summarizing multiple view points (Seki et al., 2004) and opinions (Mohammad et al., 2008a). A crucial sub-problem is to determine whether positive or negative sentiment is expressed. Automatic methods for this often make use of lexicons of words tagged with positive and negative semantic orientation (Turney, 2002; Wilson et al., 2005; Pang and Lee, 2008). A word is said to have a positive semantic orientation (SO) (or polarity) if it is often used to convey favorable sentiment or evaluation of the topic under discussion. Some example words that have positive semantic orientation are excellent, happy, honest, and so on. Similarly, a word is said to have negative semantic orientation if it is often used to convey unfavorable sentiment or evaluation of the target. Examples include poor, sad, and dishonest. Certain semantic orientation lexicons have been manually compiled for English—the most notable being the General Inquirer (GI) (Stone et al.,</context>
<context position="6055" citStr="Pang and Lee (2008)" startWordPosition="913" endWordPosition="916">nquirer and Turney–Littman lexicons. In Section 2 we examine related work. Section 3 presents our algorithm for creating semantic orientation lexicons. We describe intrinsic and extrinsic evaluation experiments in Section 4, followed by a discussion of the results in Section 5. Additionally, in Section 6 we show preliminary visualizations of how our algorithm forms chains of positive and negative thesaurus categories. Good visualizations are not only effective in presenting information to the user, but also help us better understand our algorithm. Section 7 has our conclusions. 2 Related Work Pang and Lee (2008) provide an excellent survey of the literature on sentiment analysis. Here we briefly describe the work closest to ours. Hatzivassiloglou and McKeown (1997) proposed a supervised algorithm to determine the semantic orientation of adjectives. They first generate a graph that has adjectives as nodes. An edge between two nodes indicates either that the two adjectives have the same or opposite semantic orientation. A clustering algorithm partitions the graph into two subgraphs such that the nodes in a subgraph have the same semantic orientation. The subgraph with adjectives that occur more often i</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval, 2(1–2):1–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yohei Seki</author>
<author>Koji Eguchi</author>
<author>Noriko Kando</author>
</authors>
<title>Analysis of multi-document viewpoint summarization using multi-dimensional genres.</title>
<date>2004</date>
<booktitle>In Proceedings of the AAAI Spring Symposium on Exploring Attitude and Affect in Text: Theories and Applications,</booktitle>
<pages>142--145</pages>
<contexts>
<context position="2053" citStr="Seki et al., 2004" startWordPosition="289" endWordPosition="292">explore the use of visualization techniques to gain insight into the our algorithm beyond the evaluations mentioned above. 1 Introduction Sentiment analysis involves determining the opinions and private states (beliefs, emotions, speculations, and so on) of the speaker (Wiebe, 1994). It has received significant attention in recent years due to increasing online opinion content and applications in tasks such as automatic product recommendation systems (Tatemura, 2000; Terveen et al., 1997), question answering (Somasundaran et al., 2007; Lita et al., 2005), and summarizing multiple view points (Seki et al., 2004) and opinions (Mohammad et al., 2008a). A crucial sub-problem is to determine whether positive or negative sentiment is expressed. Automatic methods for this often make use of lexicons of words tagged with positive and negative semantic orientation (Turney, 2002; Wilson et al., 2005; Pang and Lee, 2008). A word is said to have a positive semantic orientation (SO) (or polarity) if it is often used to convey favorable sentiment or evaluation of the topic under discussion. Some example words that have positive semantic orientation are excellent, happy, honest, and so on. Similarly, a word is said</context>
</contexts>
<marker>Seki, Eguchi, Kando, 2004</marker>
<rawString>Yohei Seki, Koji Eguchi, and Noriko Kando. 2004. Analysis of multi-document viewpoint summarization using multi-dimensional genres. In Proceedings of the AAAI Spring Symposium on Exploring Attitude and Affect in Text: Theories and Applications, pages 142–145.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Smith</author>
<author>Ben Shneiderman</author>
</authors>
<title>Natasa Milic-Frayling, Eduarda Mendes Rodrigues, Vladimir Barash, Cody Dunne, Tony Capone, Adam Perer, and Eric Gleave.</title>
<date>2009</date>
<booktitle>In C&amp;T ’09: Proc. Fourth International Conference on Communities and Technologies, Lecture Notes in Computer Science.</booktitle>
<publisher>Springer.</publisher>
<marker>Smith, Shneiderman, 2009</marker>
<rawString>Marc Smith, Ben Shneiderman, Natasa Milic-Frayling, Eduarda Mendes Rodrigues, Vladimir Barash, Cody Dunne, Tony Capone, Adam Perer, and Eric Gleave. 2009. Analyzing (social media) networks with NodeXL. In C&amp;T ’09: Proc. Fourth International Conference on Communities and Technologies, Lecture Notes in Computer Science. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Swapna Somasundaran</author>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Veselin Stoyanov</author>
</authors>
<title>QA with attitude: Exploiting opinion type analysis for improving question answering in on-line discussions and the news.</title>
<date>2007</date>
<booktitle>In Proceedings of the International Conference on Weblogs and Social Media (ICWSM).</booktitle>
<contexts>
<context position="1975" citStr="Somasundaran et al., 2007" startWordPosition="276" endWordPosition="279">ase polarity using our thesaurus-based lexicon than with any other. Additionally, we explore the use of visualization techniques to gain insight into the our algorithm beyond the evaluations mentioned above. 1 Introduction Sentiment analysis involves determining the opinions and private states (beliefs, emotions, speculations, and so on) of the speaker (Wiebe, 1994). It has received significant attention in recent years due to increasing online opinion content and applications in tasks such as automatic product recommendation systems (Tatemura, 2000; Terveen et al., 1997), question answering (Somasundaran et al., 2007; Lita et al., 2005), and summarizing multiple view points (Seki et al., 2004) and opinions (Mohammad et al., 2008a). A crucial sub-problem is to determine whether positive or negative sentiment is expressed. Automatic methods for this often make use of lexicons of words tagged with positive and negative semantic orientation (Turney, 2002; Wilson et al., 2005; Pang and Lee, 2008). A word is said to have a positive semantic orientation (SO) (or polarity) if it is often used to convey favorable sentiment or evaluation of the topic under discussion. Some example words that have positive semantic </context>
</contexts>
<marker>Somasundaran, Wilson, Wiebe, Stoyanov, 2007</marker>
<rawString>Swapna Somasundaran, Theresa Wilson, Janyce Wiebe, and Veselin Stoyanov. 2007. QA with attitude: Exploiting opinion type analysis for improving question answering in on-line discussions and the news. In Proceedings of the International Conference on Weblogs and Social Media (ICWSM).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Stone</author>
<author>Dexter Dunphy</author>
<author>Marshall Smith</author>
<author>Daniel Ogilvie</author>
</authors>
<title>The General Inquirer: A Computer Approach to Content Analysis.</title>
<date>1966</date>
<publisher>MIT.</publisher>
<contexts>
<context position="2963" citStr="Stone et al., 1966" startWordPosition="437" endWordPosition="440">nd Lee, 2008). A word is said to have a positive semantic orientation (SO) (or polarity) if it is often used to convey favorable sentiment or evaluation of the topic under discussion. Some example words that have positive semantic orientation are excellent, happy, honest, and so on. Similarly, a word is said to have negative semantic orientation if it is often used to convey unfavorable sentiment or evaluation of the target. Examples include poor, sad, and dishonest. Certain semantic orientation lexicons have been manually compiled for English—the most notable being the General Inquirer (GI) (Stone et al., 1966).1 However, the GI lexicon has orientation labels for only about 3,600 entries. The Pittsburgh subjectivity lexicon (PSL) (Wilson et al., 2005), which draws from the General Inquirer and other sources, also has semantic orientation labels, but only for about 8,000 words. Automatic approaches to creating a semantic orientation lexicon and, more generally, approaches for word-level sentiment annotation can be grouped into two kinds: (1) those that rely on manually created lexical resources—most of which use WordNet (Strapparava and Valitutti, 2004; Hu and Liu, 2004; Kamps et al., 2004; Takamura </context>
</contexts>
<marker>Stone, Dunphy, Smith, Ogilvie, 1966</marker>
<rawString>Philip Stone, Dexter Dunphy, Marshall Smith, and Daniel Ogilvie. 1966. The General Inquirer: A Computer Approach to Content Analysis. MIT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlo Strapparava</author>
<author>Alessandro Valitutti</author>
</authors>
<title>WordNet-affect: and affective extension of WordNet.</title>
<date>2004</date>
<booktitle>In Proceedings of LREC,</booktitle>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="3514" citStr="Strapparava and Valitutti, 2004" startWordPosition="520" endWordPosition="523">or English—the most notable being the General Inquirer (GI) (Stone et al., 1966).1 However, the GI lexicon has orientation labels for only about 3,600 entries. The Pittsburgh subjectivity lexicon (PSL) (Wilson et al., 2005), which draws from the General Inquirer and other sources, also has semantic orientation labels, but only for about 8,000 words. Automatic approaches to creating a semantic orientation lexicon and, more generally, approaches for word-level sentiment annotation can be grouped into two kinds: (1) those that rely on manually created lexical resources—most of which use WordNet (Strapparava and Valitutti, 2004; Hu and Liu, 2004; Kamps et al., 2004; Takamura et al., 2005; Esuli and Sebastiani, 2006; An1http://www.wjh.harvard.edu/ inquirer 599 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 599–608, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP dreevskaia and Bergler, 2006; Kanayama and Nasukawa, 2006); and (2) those that rely on text corpora (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Yu and Hatzivassiloglou, 2003; Grefenstette et al., 2004). Many of these lexicons, such as SentiWordNet (SWN) (Esuli and Sebastiani, 2006) were create</context>
</contexts>
<marker>Strapparava, Valitutti, 2004</marker>
<rawString>Carlo Strapparava and Alessandro Valitutti. 2004. WordNet-affect: and affective extension of WordNet. In Proceedings of LREC, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroya Takamura</author>
<author>Takashi Inui</author>
<author>Manabu Okumura</author>
</authors>
<title>Extracting semantic orientation of words using spin model.</title>
<date>2005</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL),</booktitle>
<pages>133--140</pages>
<contexts>
<context position="3575" citStr="Takamura et al., 2005" startWordPosition="532" endWordPosition="536">l., 1966).1 However, the GI lexicon has orientation labels for only about 3,600 entries. The Pittsburgh subjectivity lexicon (PSL) (Wilson et al., 2005), which draws from the General Inquirer and other sources, also has semantic orientation labels, but only for about 8,000 words. Automatic approaches to creating a semantic orientation lexicon and, more generally, approaches for word-level sentiment annotation can be grouped into two kinds: (1) those that rely on manually created lexical resources—most of which use WordNet (Strapparava and Valitutti, 2004; Hu and Liu, 2004; Kamps et al., 2004; Takamura et al., 2005; Esuli and Sebastiani, 2006; An1http://www.wjh.harvard.edu/ inquirer 599 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 599–608, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP dreevskaia and Bergler, 2006; Kanayama and Nasukawa, 2006); and (2) those that rely on text corpora (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Yu and Hatzivassiloglou, 2003; Grefenstette et al., 2004). Many of these lexicons, such as SentiWordNet (SWN) (Esuli and Sebastiani, 2006) were created using supervised classifiers and significant manual annotat</context>
</contexts>
<marker>Takamura, Inui, Okumura, 2005</marker>
<rawString>Hiroya Takamura, Takashi Inui, and Manabu Okumura. 2005. Extracting semantic orientation of words using spin model. In Proceedings of the Association for Computational Linguistics (ACL), pages 133– 140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Junichi Tatemura</author>
</authors>
<title>Virtual reviewers for collaborative exploration of movie reviews.</title>
<date>2000</date>
<booktitle>In Proceedings of Intelligent User Interfaces (IUI),</booktitle>
<pages>272--275</pages>
<contexts>
<context position="1905" citStr="Tatemura, 2000" startWordPosition="268" endWordPosition="269"> obtain significantly higher performance in determining phrase polarity using our thesaurus-based lexicon than with any other. Additionally, we explore the use of visualization techniques to gain insight into the our algorithm beyond the evaluations mentioned above. 1 Introduction Sentiment analysis involves determining the opinions and private states (beliefs, emotions, speculations, and so on) of the speaker (Wiebe, 1994). It has received significant attention in recent years due to increasing online opinion content and applications in tasks such as automatic product recommendation systems (Tatemura, 2000; Terveen et al., 1997), question answering (Somasundaran et al., 2007; Lita et al., 2005), and summarizing multiple view points (Seki et al., 2004) and opinions (Mohammad et al., 2008a). A crucial sub-problem is to determine whether positive or negative sentiment is expressed. Automatic methods for this often make use of lexicons of words tagged with positive and negative semantic orientation (Turney, 2002; Wilson et al., 2005; Pang and Lee, 2008). A word is said to have a positive semantic orientation (SO) (or polarity) if it is often used to convey favorable sentiment or evaluation of the t</context>
</contexts>
<marker>Tatemura, 2000</marker>
<rawString>Junichi Tatemura. 2000. Virtual reviewers for collaborative exploration of movie reviews. In Proceedings of Intelligent User Interfaces (IUI), pages 272–275.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Loren Terveen</author>
<author>Will Hill</author>
<author>Brian Amento</author>
<author>David McDonald</author>
<author>Josh Creter</author>
</authors>
<title>PHOAKS: A system for sharing recommendations.</title>
<date>1997</date>
<journal>Communications of the Association for Computing Machinery (CACM),</journal>
<volume>40</volume>
<issue>3</issue>
<contexts>
<context position="1928" citStr="Terveen et al., 1997" startWordPosition="270" endWordPosition="273">antly higher performance in determining phrase polarity using our thesaurus-based lexicon than with any other. Additionally, we explore the use of visualization techniques to gain insight into the our algorithm beyond the evaluations mentioned above. 1 Introduction Sentiment analysis involves determining the opinions and private states (beliefs, emotions, speculations, and so on) of the speaker (Wiebe, 1994). It has received significant attention in recent years due to increasing online opinion content and applications in tasks such as automatic product recommendation systems (Tatemura, 2000; Terveen et al., 1997), question answering (Somasundaran et al., 2007; Lita et al., 2005), and summarizing multiple view points (Seki et al., 2004) and opinions (Mohammad et al., 2008a). A crucial sub-problem is to determine whether positive or negative sentiment is expressed. Automatic methods for this often make use of lexicons of words tagged with positive and negative semantic orientation (Turney, 2002; Wilson et al., 2005; Pang and Lee, 2008). A word is said to have a positive semantic orientation (SO) (or polarity) if it is often used to convey favorable sentiment or evaluation of the topic under discussion. </context>
</contexts>
<marker>Terveen, Hill, Amento, McDonald, Creter, 1997</marker>
<rawString>Loren Terveen, Will Hill, Brian Amento, David McDonald, and Josh Creter. 1997. PHOAKS: A system for sharing recommendations. Communications of the Association for Computing Machinery (CACM), 40(3):59–62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Turney</author>
<author>Michael Littman</author>
</authors>
<title>Measuring praise and criticism: Inference of semantic orientation from association.</title>
<date>2003</date>
<journal>ACM Transactions on Information Systems (TOIS),</journal>
<volume>21</volume>
<issue>4</issue>
<contexts>
<context position="3962" citStr="Turney and Littman, 2003" startWordPosition="589" endWordPosition="593">d-level sentiment annotation can be grouped into two kinds: (1) those that rely on manually created lexical resources—most of which use WordNet (Strapparava and Valitutti, 2004; Hu and Liu, 2004; Kamps et al., 2004; Takamura et al., 2005; Esuli and Sebastiani, 2006; An1http://www.wjh.harvard.edu/ inquirer 599 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 599–608, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP dreevskaia and Bergler, 2006; Kanayama and Nasukawa, 2006); and (2) those that rely on text corpora (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Yu and Hatzivassiloglou, 2003; Grefenstette et al., 2004). Many of these lexicons, such as SentiWordNet (SWN) (Esuli and Sebastiani, 2006) were created using supervised classifiers and significant manual annotation, whereas others such as the Turney and Littman lexicon (TLL) (2003) were created from very large corpora (more than 100 billion words). In contrast, we propose a computationally inexpensive method to compile a high-coverage semantic orientation lexicon without the use of any text corpora or manually annotated semantic orientation labels. Both of these resources may be used, if ava</context>
<context position="7534" citStr="Turney and Littman (2003)" startWordPosition="1151" endWordPosition="1154">entries to train on and is much simpler. Esuli and Sebastiani (2006) used a supervised algorithm to attach semantic orientation scores to WordNet glosses. They train a set of ternary classifiers using different training data and learning methods. The set of semantic orientation scores of all WordNet synsets is released by the name SentiWordNet.2 An evaluation of SentiWordNet by comparing orientation scores of about 1,000 WordNet glosses to scores assigned by human annotators is presented in Esuli (2008). Our approach uses a Roget-like thesaurus, and it does not use any supervised classifiers. Turney and Littman (2003) proposed a minimally supervised algorithm to calculate the semantic orientation of a word by determining if its tendency to co-occur with a small set of positive words is greater than its tendency to co-occur with a small set of negative words. They show that their approach performs better when it has a large amount of text at its disposal. They use text from 350 million web-pages (more than 100 billion words). Our approach does not make use of any text corpora, although co-occurrence statistics could be used to further improve the lexicon. Furthermore, our lexicon has entries for commonly us</context>
<context position="16448" citStr="Turney and Littman (2003)" startWordPosition="2577" endWordPosition="2580">s in MSOL(GI), 45,197 are single-word entries and 24,774 are entries for common multi-word expressions. Of the 76,400 entries in MSOL(ASL and GI), 51,208 are single-word entries and 25,192 are entries for common multi-word expressions. In our evaluation, we used only the single-word entries to maintain a level playing field with other lexicons. 4 Evaluation We evaluated the semantic orientation lexicons both intrinsically (by comparing their entries to the General Inquirer) and extrinsically (by using them in a phrase polarity annotation task). 4.1 Intrinsic: Comparison with GI Similar to how Turney and Littman (2003) evaluated their lexicon (TLL), we determine if the semantic orientation labels in the automatically generated lexicons match the semantic orientation la3MSOL is publicly available at: www.umiacs.umd.edu/ ∼saif/WebPages/ResearchInterests.html. 602 Lexicon All Positives Negatives MSOL(ASL) 74.3 84.2 65.9 SWN 60.1 86.5 37.9 TLL 83.3 83.8 82.8 Table 3: The percentage of GI-subset entries (all, only the positives, only the negatives) that match those of the automatically generated lexicons. bels of words in GI. GI, MSOL(ASL), SWN, and TLL all have 2,761 words in common. We will call the correspond</context>
<context position="31230" citStr="Turney and Littman (2003)" startWordPosition="4947" endWordPosition="4950">c orientation lexicon using only affix rules and a Roget-like thesaurus. The method does not require terms with manually annotated semantic orientation labels, though we show that if available they can be used to further improve both the correctness of its entries and its coverage. The lexicon has about twenty times as many entries as in the General Inquirer and the Turney–Littman lexicons, and includes entries for both individual words and common multi-word expressions. Experiments show that it has significantly more correct entries than SentiWordNet. The approach is complementary to that of Turney and Littman (2003) and a combination of this approach with co-occurrence statistics (even if drawn from a modest sized corpus) is expected to yield an even better lexicon. Visualization of the thesaurus categories as per the semantic orientations assigned to them by our algorithm reveals that affix patterns produce a strongly connected graph and that indeed there are many long chains of positive and negative categories. Furthermore, the key categories of this graph (the ones with high centrality and closeness) are strongly evaluative in nature, and most of them tend to have negative semantic orientation. 606 Fi</context>
</contexts>
<marker>Turney, Littman, 2003</marker>
<rawString>Peter Turney and Michael Littman. 2003. Measuring praise and criticism: Inference of semantic orientation from association. ACM Transactions on Information Systems (TOIS), 21(4):315–346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Turney</author>
</authors>
<title>Thumbs up or thumbs down? semantic orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>417--424</pages>
<location>Philadelphia, Pennsylvania.</location>
<contexts>
<context position="2315" citStr="Turney, 2002" startWordPosition="333" endWordPosition="334">r (Wiebe, 1994). It has received significant attention in recent years due to increasing online opinion content and applications in tasks such as automatic product recommendation systems (Tatemura, 2000; Terveen et al., 1997), question answering (Somasundaran et al., 2007; Lita et al., 2005), and summarizing multiple view points (Seki et al., 2004) and opinions (Mohammad et al., 2008a). A crucial sub-problem is to determine whether positive or negative sentiment is expressed. Automatic methods for this often make use of lexicons of words tagged with positive and negative semantic orientation (Turney, 2002; Wilson et al., 2005; Pang and Lee, 2008). A word is said to have a positive semantic orientation (SO) (or polarity) if it is often used to convey favorable sentiment or evaluation of the topic under discussion. Some example words that have positive semantic orientation are excellent, happy, honest, and so on. Similarly, a word is said to have negative semantic orientation if it is often used to convey unfavorable sentiment or evaluation of the target. Examples include poor, sad, and dishonest. Certain semantic orientation lexicons have been manually compiled for English—the most notable bein</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>Peter Turney. 2002. Thumbs up or thumbs down? semantic orientation applied to unsupervised classification of reviews. In Proceedings of ACL, pages 417–424, Philadelphia, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce M Wiebe</author>
</authors>
<title>Tracking point of view in narrative.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>2</issue>
<contexts>
<context position="1718" citStr="Wiebe, 1994" startWordPosition="240" endWordPosition="241">gold standard, we show that our lexicon has 14 percentage points more correct entries than the leading WordNet-based high-coverage lexicon (SentiWordNet). In an extrinsic evaluation, we obtain significantly higher performance in determining phrase polarity using our thesaurus-based lexicon than with any other. Additionally, we explore the use of visualization techniques to gain insight into the our algorithm beyond the evaluations mentioned above. 1 Introduction Sentiment analysis involves determining the opinions and private states (beliefs, emotions, speculations, and so on) of the speaker (Wiebe, 1994). It has received significant attention in recent years due to increasing online opinion content and applications in tasks such as automatic product recommendation systems (Tatemura, 2000; Terveen et al., 1997), question answering (Somasundaran et al., 2007; Lita et al., 2005), and summarizing multiple view points (Seki et al., 2004) and opinions (Mohammad et al., 2008a). A crucial sub-problem is to determine whether positive or negative sentiment is expressed. Automatic methods for this often make use of lexicons of words tagged with positive and negative semantic orientation (Turney, 2002; W</context>
</contexts>
<marker>Wiebe, 1994</marker>
<rawString>Janyce M. Wiebe. 1994. Tracking point of view in narrative. Computational Linguistics, 20(2):233–287.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffman</author>
</authors>
<title>Recognizing contextual polarity in phraselevel sentiment analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of HLTEMNLP,</booktitle>
<pages>347--354</pages>
<location>Vancouver, Canada.</location>
<contexts>
<context position="2336" citStr="Wilson et al., 2005" startWordPosition="335" endWordPosition="338">). It has received significant attention in recent years due to increasing online opinion content and applications in tasks such as automatic product recommendation systems (Tatemura, 2000; Terveen et al., 1997), question answering (Somasundaran et al., 2007; Lita et al., 2005), and summarizing multiple view points (Seki et al., 2004) and opinions (Mohammad et al., 2008a). A crucial sub-problem is to determine whether positive or negative sentiment is expressed. Automatic methods for this often make use of lexicons of words tagged with positive and negative semantic orientation (Turney, 2002; Wilson et al., 2005; Pang and Lee, 2008). A word is said to have a positive semantic orientation (SO) (or polarity) if it is often used to convey favorable sentiment or evaluation of the topic under discussion. Some example words that have positive semantic orientation are excellent, happy, honest, and so on. Similarly, a word is said to have negative semantic orientation if it is often used to convey unfavorable sentiment or evaluation of the target. Examples include poor, sad, and dishonest. Certain semantic orientation lexicons have been manually compiled for English—the most notable being the General Inquire</context>
</contexts>
<marker>Wilson, Wiebe, Hoffman, 2005</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Paul Hoffman. 2005. Recognizing contextual polarity in phraselevel sentiment analysis. In Proceedings of HLTEMNLP, pages 347–354, Vancouver, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hong Yu</author>
<author>Vassileios Hatzivassiloglou</author>
</authors>
<title>Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences.</title>
<date>2003</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>129--136</pages>
<location>Morristown, NJ.</location>
<contexts>
<context position="3993" citStr="Yu and Hatzivassiloglou, 2003" startWordPosition="594" endWordPosition="597">on can be grouped into two kinds: (1) those that rely on manually created lexical resources—most of which use WordNet (Strapparava and Valitutti, 2004; Hu and Liu, 2004; Kamps et al., 2004; Takamura et al., 2005; Esuli and Sebastiani, 2006; An1http://www.wjh.harvard.edu/ inquirer 599 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 599–608, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP dreevskaia and Bergler, 2006; Kanayama and Nasukawa, 2006); and (2) those that rely on text corpora (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Yu and Hatzivassiloglou, 2003; Grefenstette et al., 2004). Many of these lexicons, such as SentiWordNet (SWN) (Esuli and Sebastiani, 2006) were created using supervised classifiers and significant manual annotation, whereas others such as the Turney and Littman lexicon (TLL) (2003) were created from very large corpora (more than 100 billion words). In contrast, we propose a computationally inexpensive method to compile a high-coverage semantic orientation lexicon without the use of any text corpora or manually annotated semantic orientation labels. Both of these resources may be used, if available, to further improve resu</context>
</contexts>
<marker>Yu, Hatzivassiloglou, 2003</marker>
<rawString>Hong Yu and Vassileios Hatzivassiloglou. 2003. Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences. In Proceedings of EMNLP, pages 129– 136, Morristown, NJ.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>