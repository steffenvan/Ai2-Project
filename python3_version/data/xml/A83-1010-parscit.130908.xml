<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.5088585">
PARSING WITH LOGICAL VARIABLES
Timothy W. Finin and Martha Stone Palmer
</note>
<affiliation confidence="0.970787">
Department of Computer and Information Science
University of Pennsylvania
</affiliation>
<address confidence="0.542473">
Philadelphia, PA 19104
</address>
<email confidence="0.456543">
ABSTRACT
</email>
<bodyText confidence="0.999595368421053">
Logic based programming systems have enjoyed
an increasing popularity in applied Al work in the
last few years. One of the contributions to
Computational Linguistics made by the Logic
Programming Paradigm has been the Definite Clause
Grammar. In comparing DCG&apos;s with previous parsing
mechanisms such as ATM&apos;s, certain clear advantages
are seen. We feel that the most important of these
advantages are due to the use of Logical Variables
with Unification as the fundamental operation on
them. To illustrate the power of the Logical
Variable, we have implemented an experimental ATN
system which treats ATN registers as Logical
Variables and provides a unification operation over
them. We would like to simultaneously encourage
the use of the powerful mechanisms available in
DCG&apos;s, and demonstrate that some of these
techniques can be captured without reference to a
resolution theorem prover.
</bodyText>
<sectionHeader confidence="0.967546" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.998739375">
Logic based programming systems have enjoyed
an increasing popularity in applied Al work in the
last few years. One of the contributions to
Computational Linguistics made by the Logic
Programming Paradigm has been the Definite Clause
Grammar. An excellent introduction to this
formalism can be found in [Pereira] in which the
authors present the formalism and make a detailed
comparison to Augmented Transition Networks as a
means of both specifying a language and parsing
sentences in a language.
We feel that the major strengths offered by
the DCG formalism arise from its use of Logical
variables with Unification as the fundamental
operation on them. These techniques can be
abstracted from the theorem proving paradigm and
adapted to other parsing systems (see (Kay] and
[Bossiel ). We have implemented an experimental ATN
system which treats ATN registers as Logic
variables and provides a unification operation over
them.
The DCG formalism provides a powerful
mechanism for parsing based on a context free
grammar. The grammar rule
</bodyText>
<equation confidence="0.656185">
S -&gt; NP VP
</equation>
<bodyText confidence="0.927815">
can be seen as the universally quantified logical
statement,
For all x, y, and z :
</bodyText>
<equation confidence="0.697242">
NP(x) VF(Y) Concatenate(x,y,z) =&gt; S(z).
</equation>
<bodyText confidence="0.98827">
where &amp;quot;x&amp;quot; and &amp;quot;y&amp;quot; represent sequences of words
which can be concatenated together to produce a
sentence, &amp;quot;S.&amp;quot; Prolog, a programming language
based on predicate calculus, allows logical
statements to be input as Horn clauses in the
following (reversed) form:
s(Z) &lt;= np(X),vp(Y),Concatenate(X,Y,Z).
The resolution theorem prover that
&amp;quot;interprets&amp;quot; the Prolog clauses would take the
negation of S as the goal and try and produce the
null clause. Thus the preceding clause can be
interpreted procedurally as, &amp;quot;To establish goal S,
try and establish subgoals, NP, VP and
Concatenate.&amp;quot; DCG&apos;s provide syntactic sugar on top
of Prolog so that the arrow can be reversed and the
&amp;quot;Concatenate&amp;quot; predicate can be dispensed with. The
words in the input string are looked at
sequentially each time a &amp;quot;[Wordl&amp;quot; predicate is
executed which implicitly tests for concatenation
(see figure 1). DCG&apos;s allow grammar rules to be
expressed very cleanly, while still allowing
ATN-type augmentation through the addition of
arbitrary tests on the contents of the variables.
Pereira and Warren argue that the DCG
formalism is well suited for specifying a formal
description of a language and also for use with a
parser. In particular, they assert that it is a
significant advance over an ATN approach on both
philosophical and practical grounds. Their chief
claims are that:
</bodyText>
<listItem confidence="0.998736545454545">
1. DCGs provide a common formalism for
theoretical work in Computational Linguistics
and for writing efficient natural Language
processors.
2. The rule based nature of a DCG result in
systems of greater clarity and modularity.
3. DCG&apos;s provide greater freedom in the range of
structures that can be built in the course of
analyzing a constituent. in particular the DCG
formalism makes it easy to create structures
that do not follow the structure implied by
</listItem>
<page confidence="0.998245">
62
</page>
<bodyText confidence="0.998727368421053">
the rules of a constituent and easy to create
a structure for a constituent that depends on
items not yet encountered in the sentence.
The first two points have been discussed in
the past whenever the ATN formalism is compared
with a rale-based grammar (see [Pratt] , [Heidorn]
, (Coddl , or [Bates] ). The outcome of such
discussions vary. It is safe to say that how one
feels about these points depends quite heavily on
past experience in using the two formalisms.
We find the third point to be well founded,
however. It is clear that the DCG differs most
from previous rule-based parsing systems in its
inclusion of Logical variables. These result in
greater flexibility in building structures to
represent constituents that do not follow the
inherent structure determined by the rules
themselves. They also allow one to create
structures which refer to items that have not yet
been discovered in the course of analysing the
sentence.
We have built an experimental ATN system which
can treat ATN registers as Logical variables and,
we feel, capture these important strengths offered
by the DCG formalism in the otherwise standard ATN
formalism.
The second section gives a more detailed
desciption of DCG&apos;s and presents a simple grammar.
In the third section we show an ATN grammar which
is &amp;quot;equivalent&amp;quot; to the DCG grammar and discuss the
source of its awkwardness. The fourth section then
presents an ATN formalism extended to include
viewing ATN registers as Logical variables which
are subject to the standard unification operation.
The final section concludes this note and suggests
that logical variables might be fruitfully
introduced into other parsing algorithms and
systems.
</bodyText>
<sectionHeader confidence="0.980531" genericHeader="method">
2. Definite Clause Grammars
</sectionHeader>
<bodyText confidence="0.999440428571429">
Figure I shows a simple DCG grammar adapted
from [Pereira] . Figure 2 gives a sentence in the
language recognized by this grammar together with
the associated surface syntactic structure and the
semantic structure built by the grammar.
The way in which unification produces the
appropriate bindings for this example is actually
quite subtle, and requires a detailed analysis of
the parse, as represented by the refutation graph
in Figure 3. For the the refutation graph the
Prolog clauses have been put into clausal normal
form. Some liberties have been taken with the
ordering of the predicates in the interest of
compactness.
In trying to establish the &amp;quot;s(P)&amp;quot; goal, the
&amp;quot;np(X,PI,P)&amp;quot; is first attempted. The &amp;quot;Pl&amp;quot; is an
empty variable that is a &amp;quot;place-holder&amp;quot; for
predicate information that will come from the verb.
It will &amp;quot;hold&amp;quot; a place in the sentence structure
that will be provided by the determiner. &amp;quot;P&amp;quot; is
destined to contain the sentence structure. The
</bodyText>
<construct confidence="0.6882491">
Fig. 1. A Definite Clause Grammar
s(P) -&gt; np(X, PI, P), vp(X, PI).
np(X, PI, P) -&gt; det(X, 22, PI, P),
n(X, P3),
relclause(X, 23, P2).
np(X, P, P) -&gt; name(X).
vp(X, P) -&gt; transv(X, Y, PI), nP(Y, PI, 2).
vp(X, P) -&gt; intransv(X, P).
relclause(X, PI, (And PI P2)) -&gt; [that], vp(X, P2).
relclause(X, P, P) -&gt; [J.
</construct>
<bodyText confidence="0.9164472">
det(X, PI, 22, (ForAll X (.&gt; PI 22))) -&gt; (every!.
det(X, PI, 22, (ForSome X (And PI P2))) -&gt; [a].
n(X, (man X)) -&gt; [man].
n(X, (woman X)) -&gt; [woman].
n(X, (dog X)) -&gt; [dog].
</bodyText>
<equation confidence="0.7780978">
name(john) -&gt; [John]
name(mary) -&gt; [Teary]
name(fido) -&gt; [fido]
transv(X, Y, (loves X Y)) -&gt; [loves].
transv(X, Y, (breathes X Y)) -&gt; [breathes!.
</equation>
<bodyText confidence="0.807196333333333">
intransv(X, (loves X) -&gt; [loves].
intransv(X, (lives X) -&gt; [lives].
intransv(X, (breathes X) -&gt; [breathes].
</bodyText>
<figureCaption confidence="0.736516">
Fig. 2. A Sentence, Structure and Representation
SENTENCE
</figureCaption>
<bodyText confidence="0.4030795">
&amp;quot;John loves every woman who breathes&amp;quot;
SYNTACTIC STRUCTURE
</bodyText>
<equation confidence="0.7537352">
(S (NP (NAME John))
(VP (TRANSV loves)
(NF (DET every)
(NOUN woman)
(REL (VP (INTRANSV breathes)))))))
</equation>
<bodyText confidence="0.612144666666667">
SEMANTIC REPRESENTATION
(ForAll X1 (..&gt; (And (woman X1) (breaches XI))
(loves john KIM
</bodyText>
<page confidence="0.966977">
63
</page>
<figureCaption confidence="0.609459">
Pig. 3. Refutation Graph
</figureCaption>
<equation confidence="0.883815304347826">
[ever‹....:2eryp-det(X,P1,P2,(Fora1
l X (.0P1 P2))) -det Y
-n(Y,P3)\/-relclause(Y,P3,92)
•11 \/
(P is bound to &amp;quot;Foral›..&gt; PI loves( john,Y))&amp;quot;)
[
-Noman]\/-n X woman X \/-relclause(Y,P3,P2)
\/ -np(X,PI,P) \/ -vp(X,PI)
-vp(R,PI)\/-n (X PI P) X P P \/ Ijohnl
\/-transv(X,Y,P1)\/-np(Y,PI,P) inbni (iIhn1
W-Iloves1 (1
ohn
-det(X,122,111,P)\/
-o(X,P3)\/relclause(X,P3,P2)\
-np(Y,PI,P)\/-transv
woman] - woman \/-relclauce(Y.Cwoman Y).P21 -vp(X,P2)\/ -(that]\/
relclause(X.P1.(And P1 132))
(PI is bound to &amp;quot;And (woman Y) P2&amp;quot;)
-intransv(X,P)\I
V. P
/
intransv Y.breathel(X))
(92 is bound to &amp;quot;breathes(Y)&amp;quot;)
</equation>
<page confidence="0.987331">
64
</page>
<bodyText confidence="0.980564578125">
first &amp;quot;np&amp;quot; clause will be matched, but it will
eventually fail since no determiner is present.
The second &amp;quot;np&amp;quot; clause will succeed, having forever
identified the contents of &amp;quot;Pi&amp;quot; with the contents
of &amp;quot;P, &amp;quot; whatever they may be. Since there is no
determiner in the first noun phrase, there is no
quantification information. The quantificational
structure must be supplied by the verb phrase, so
the structure for the sentence will be the same as
the structure for the verb phrase. The variable
&amp;quot;X&amp;quot; will be bound to &amp;quot;John&amp;quot;.
In trying to establish &amp;quot;vp(John,P1), &amp;quot; the
first &amp;quot;vp&amp;quot; clause will succeed, since &amp;quot;loves&amp;quot; is a
transitive verb. It is important not to get the
variables confused. Within the &amp;quot;vp&amp;quot; clause our
original &amp;quot;Pl&amp;quot; has been renamed &amp;quot;P&amp;quot; and and we have
a new &amp;quot;Pl&amp;quot; variable that will be instantiated to
&amp;quot;(loves John Y)&amp;quot; by the success of the &amp;quot;transv&amp;quot;
goal. The &amp;quot;Y&amp;quot; is as yet undetermined, but we can
see that it will be supplied by the next
&amp;quot;np(Y,(loves John Y),P)&amp;quot; goal. It shows great
foresight on &amp;quot;transv&apos;s&amp;quot; part to pass back a
variable in such a way that it will correspond to a
variable that has already been named. This pattern
is repeated throughout the grammar, with powerfull
repurcussions. It is even clearer in the success
of the &amp;quot;np(Y,(loves John Y),P)&amp;quot; goal, where the
presence of the determiner &amp;quot;every&amp;quot; causes &amp;quot;P&amp;quot; to be
bound to
(Forall Y P1 (loves John Y))
This &amp;quot;P&amp;quot; is of course the &amp;quot;P&amp;quot; mentioned above which
has been waiting for the verb phrase to supply it
with a quantificational structure.
As the relative clause for this &amp;quot;np&amp;quot; is
processed, the &amp;quot;Pi&amp;quot; embedded in this structure,
(our second new Pi!), is eventually bound to &amp;quot;(And
(woman Y) (breathes Y))&amp;quot; giving us the full
structure:
(Forall Y (0 (And (woman Y) (breathes Y))
(loves John Y)))
This is what is returned as the binding to the
first &apos;Fl&amp;quot; in the original &amp;quot;vp(X,P1)&amp;quot; goal. Since
our &amp;quot;np(X,P1,P)&amp;quot; goal identified &amp;quot;P&amp;quot; with &amp;quot;FL, &amp;quot;
our &amp;quot;s(P)&amp;quot; goal succeeds with the binding of
(Forall Y (=&gt; (And (woman Y) (breathes Y))
(loves John Y)))
for &amp;quot;P&amp;quot; - the final structure built for the
sentence.
In following the execution of this grammar it
becomes clear that very strong predictions are made
about which parts of the parse will be supplying
particular types of information. Determiners will
provide the quantifiers for the propositional
structure of the sentence, the first noun phrase
and the noun phrase following the verb will he the
two participants in the predicate implied by the
verb, etc. Obviously this is a simple grammar, but
the power of the logical variables can only be made
use of through the encoding of these strong
linguistic assumptions. DCG&apos;s seem to provide. a
mechanism well qualified for expressing such
assumptions and then executing them. Coming up
with the assumptions in the first place is, of
course, something of a major task in itself.
</bodyText>
<listItem confidence="0.478105">
3. Comparing DC and ATN Grammars
</listItem>
<bodyText confidence="0.999709830508475">
Figure 4 shows an ATN grammar which is the
&amp;quot;equivalent&amp;quot; of the DCG grammar given in Figure 1.
The format used to specify the grammar is the one
described in (fininl) and (finin21 . There are
only two minor ways that this particular formalism
differs from the standard ATN formalism described
in [Woods70] or [Bates) . First, the dollar sign
character (i.e. $) followed by the name of a
register stands for the contents of that register.
Second, the function DEFATN defines a set of arcs,
each of which is represented by a list whose first
element is the name of the state and whose
remaining elements are the arcs emanating from the
state.
In addition, this example uses a very simple
lexical manager in which a word has (1) a set of
syntactic categories to which it belongs (2) an
optional set of features and (3) an optional root
form for the word. These attributes are associated
with a word using the function LEX, which supplies
appropriate default values for unspecified
arguments.
In the standard ATN model, a PUSH arc invokes
a sub-computation which takes no arguments and, if
successful, returns a single value. One can
achieve the effect of passing parameters to a
sub-computation by giving a register an initial
value via a SENDR register setting action. There
are two methods by which one can achieve the
effect of returning more than one value from a
sub-computation. The values to be returned can be
packaged into a list or the LIFTR register setting
action can be used to directly set values in the
higher level computation. This grammar makes use
of SENDR and LIFTR to pass parameters into and out
of ATN computations and thus the actions of the DCG
example.
Consider what must happen when looking for a
noun phrase. The representation for a NP will be a
predicate if the noun phrase is indefinite (i.e. &amp;quot;a
man&amp;quot; becomes (man X)) or a constant if the noun
phrase is a name (i.e. &amp;quot;John&amp;quot; becomes John). En
this simple language, a NP is dominated by a either
a sentence (if it is the subject) or by a verb
phrase (if it is the object). In either case, the
NP also determines, or must agree with, the overall
structure used to represent the dominating
constituent. If the NP is a simple name, then it
exerts no additional influence on the
representation of its dominator. If the NP is not
a name, then it is indefinite and will eventually
result in a quantified expression for the
dominating sentence or verb phrase. In this case
we need to tell the dominating computation what the
predicate, quantifier, connective, and variable
name must be. In this ATN grammar, this is done by
having the NP network return a value to represent
the NP predicate and lift values for the
quantifier, connective and variable name.
</bodyText>
<page confidence="0.998134">
65
</page>
<figureCaption confidence="0.915707">
Fig. 4. An Equivalent ATN Grammar
</figureCaption>
<equation confidence="0.902613846153846">
P _
sl
vonlq.
ew,
VP
( iit4f0
(defatn
(s (push np t (setr subj *) (to s/subj)))
(s/subj (push vp t (setr vp *)
(sendr subjvar $var) (to s/end)))
(s/end (pop (list $quanc $var
(list $connect $subj $vp)) $subj)
(pop $vp (null $subj)))
</equation>
<bodyText confidence="0.8964755625">
(np (wrd a t (liftr quant &apos;ForSome)
(liftr connect &apos;And)(to np/det))
(wrd every t (liftr quant &apos;ForAll)
(liftr connect &apos;*&gt;)(to np/det))
(cat name t (setr var *) (to np/np)))
(np/det (cat n t (setr var (gensym))
(setr n (list * $var)) (to np/n)))
(np/n (wrd (who that which) t (to np/n/who))
(jump np/np t))
(np/np (pop $n t (liftr var)))
(np/n/who
(push vp t (sendr subjvar $var)
(setr n (list &apos;And $n *)) (to np/np)))
(vp (cat v t (setr v *) (to vp/v)))
(vp/v (push np (getf trans $v) (setr obj *)
(setr objvar $var) (to vp/vp))
</bodyText>
<equation confidence="0.95884">
(pop (list $v $subjvar) (getf intrans $v)))
(vp/vp (pop (list $quant $objvar
(list $connect $obj
(list $v $subjvar $objvar))).
Sobj)
</equation>
<bodyText confidence="0.957617148148148">
(pop (list $v $subjvar Sobjvar) (null $obj)));
; (Lex &lt;word&gt; &lt;category&gt; &lt;features&gt; &lt;rootform&gt;)
(lex man n)
(lex woman n)
(lex loves v (intrans trans))
(lex breathes v (intrans trans))
(lex lives v (intrans))
(lex john name)
(lex nary name)
(lex fido name)
Similarly, when we are looking for a verb
phrase, we must know what token (i.e. variable name
or constant) represents the subject (if the verb
phrase is dominated by a S) or the head noun (if
the verb phrase acts as a relative clause). This
is done by sending the subjvar register in the
sub—computation the appropriate value via the SENDR
function. The techniques used to quantification
and build an overall sentence structure in this ATN
grammar are similar to those used in the BBN Lunar
Grammar (Woods721 .
This heavy use of SENDR and LIFTR to
communicate between levels in the grammar makes the
ATN grammar cumbersome and difficult to unaerstand.
In the next secton we investigate treating ATN
registers as logic variables and providing a
unification operation on them.
</bodyText>
<sectionHeader confidence="0.558422" genericHeader="method">
4. Replacing ATN Registers with ATN Variables
</sectionHeader>
<bodyText confidence="0.976497658536586">
Although the previous ATN grammar does the
job, it is clearly awkward. We can achieve much of
the elegance of the DCG example by treating the ATN
registers as logical variables and including a
unification operation on them. We will call such
registers ATN Variables.
Since our ATN variables must not be tampered
with between unifications, assignment operations
such as SETA, LIFTR and SENDR are precluded. Thus
the only operations on ATN Registers are access and
unify. It is possible to provide operations similar
to the standard SENDR and LIFTR by defining
unification operations which do the unification in
the another environment, but we have not explored
these possibilities.
The scheduler component of the ATN parser has
been modified to be sensitive to the success or
failure of attempted unifications. If a
unification operation on an arc fails, the arc is
blocked and may not be taken.
Figure 5 shows a grammar in the extended ATN
formalism. A symbol preceded by a &amp;quot;5&amp;quot; represents
an ATN Variable and &amp;quot;*&amp;quot; will again stand for the
current constituent. Thus in the state S in the
grammar:
(S (PUSH NP (UNIFY &amp;quot;(SSUBJVAR $VP $S) A)
(TO S/SUBJ)))
the parser pushes to the state NP to parse a noun
phrase. If one is found, it will pop back with a
value which will then be unified with the
expression (SSUBJVAR SVP $S). If this unification
is successful, the parser will advance to state
S/SUBJ. If it fails, the arc is blocked causing
the parser to backtrack into the NP network.
Although our grammar succeeds in mimicking the
behaviour of the DCG, there are some open questions
involving the use of unification in parsing natural
languages. An examination of this ATN grammar
shows that we are really using unification as a
method of passing parameters. The full power of
unification is not needed in this example since the
</bodyText>
<page confidence="0.881465">
66
</page>
<figureCaption confidence="0.683969">
Fig. 5. An Equivalent ATN Grammar with ATN Variables
</figureCaption>
<figure confidence="0.965182111111111">
NP VP
AMME
Q21511VS .4iPt
(defatn
(s (push np (unify &apos;($subjvar $vp $s) *)
(to s/subj)))
(s/ubj (push vp t (unify &apos;$vp *) (to s/s)))
(s/s (pop $s t))
(np (wrd a t (unify
&apos;$np
&apos;(ForSome $var (And Spred $hole)))
(to np/det))
(wrd every t (unify
&apos;Sap
&apos;(ForAll $var $pred $hole)))
(to np/det))
(cat name t (unify &apos;Sap &apos;Shole)
(unify &apos;$var 41)
</figure>
<bodyText confidence="0.950178756097561">
(to np/np)))
(np/det (cat n t (unify &apos;$var (gensym))
(unify &apos;$pred &apos;(* $var))
(to np/n)))
(np/n (wrd (who that which) t (to np/n/who))
(jump np/np t))
(np/np (pop (list $var &apos;$hole $np) t ))
(np/n/who
(push vp t (unify &apos;$subjvar &apos;$var)
(unify &apos;$pred &apos;(And Spred *))
(to np/np)))
(vp (cat v (getf trans *)
(unify &apos;$v &apos;(* $subjvar Sobjvar))
(to vp/vtrans))
(cat v (getf tntrans *)
(unify &apos;$v &apos;(* $subjvar))
(to vp/vp)))
(vp/vtrans (push np t (unify &apos;($objvar $v $vp) *)
(co vp/vp)))
(vp/vp (pop $vp t))
grammar does not try to find &amp;quot;most-general
unifiers&amp;quot; for complicated sets of terms. Most of
the time it is simply using unification to bind a
variable to the contents of another variable. The
most sophisticated use involves binding a variable
in a term to another copy of that term which also
has a variable to be bound as in the &amp;quot;a man loves a
woman&amp;quot; example in Figure 6. But even this binding
is a simple one-way application of standard
unification. It is not clear to the authors
whether this is due to the simple nature of the
grammars involved or whether it is an inherent
property of the directedness of natural language
parsing.
A situation where full unification might be
required would arise when one is looking for a
constituent matching some partial description. For
example, suppose we were working with a syntactic
grammar and wanted to look for a singular noun
phrase. We might do this with the following PUSH
arc:
</bodyText>
<sectionHeader confidence="0.831118666666667" genericHeader="method">
(PUSH NP T (UNIFY * &apos;(NP (DET $DET)
(NUMBER SINGULAR)
(ADJ $ADJS) ...))
</sectionHeader>
<bodyText confidence="0.999940238095238">
If we follow the usual schedule of interpreting ATM
grammars the unification will not occur until the
NP network has found a noun phrase and popped back
with a value. This would require a fully symmetric
unification operation since there are variables
being bound to values in both arguments. It is also
highly inefficient since we may know right away
that the noun phrase in the input is not singular.
What we would like is to be able to do the
unification just after the push is done, which
would more closely parallel a Prolog-based DCG
parse. Then an attempt to &amp;quot;unify&amp;quot; the number
register with anything other than singular will
fail immediately.
This could be done automatically if we
constrain a network to have only one state which
does a pop and place some additional constraints on
the forms that can be used as values to be popped.
Although we have not explored this idea at any
length, it appears to lead to some interesting
possibilities.
</bodyText>
<sectionHeader confidence="0.999006" genericHeader="conclusions">
5. Conclusions
</sectionHeader>
<bodyText confidence="0.986589222222222">
We have found the use of logical variables and
unification to be a powerful technique in parsing
natural language. It ts one of the main sources of
the strengths of the Definite Clause Grammar
formalism. In attempting to capture this
technique for an ATM grammar we have come to
several interesting conclusions. First, the
strength of the DCG comes as much from the skillful
encoding of linguistic assumptions about the
eventual outcome of the parse as from the powerful
tools it relies on. Second, the notion of logical
variables (with unification) can be adapted to
parsing systems ouside of the theorem proving
paradigm. We have successfully adapted these
techniques to an ATN parser and are beginning to
embed them in an existing parallel bottom-up parser
(finin31 . Third, the full power of unification may
every
</bodyText>
<page confidence="0.997487">
67
</page>
<bodyText confidence="0.7343675">
not be necessary to successfully use lOiiail
variables in natural lanuage parsers.
</bodyText>
<figureCaption confidence="0.781496">
Fig. 6. Example Paiiii With the ATM Grammar
</figureCaption>
<figure confidence="0.947847615384615">
&amp;quot;John loves every woman who breathes&amp;quot;
(ForAll X1 (.0 (And (woman X1) (breathes X1))
(loves John X1)))
&amp;quot;John loves a woman&amp;quot;
(ForSome X1 (And (woman X1) (loves John X1)))
&amp;quot;a man loves a woman&amp;quot;
(ForSome R1
(And (man X1)
(ForSome X2 (And (woman X2)
(loves X1 X2))))
&amp;quot;every man who lives loves&amp;quot;
(ForAll X1 (.&gt; (And (man X1) (lives X1))
(loves X1)))
</figure>
<sectionHeader confidence="0.894728" genericHeader="references">
6. References
</sectionHeader>
<reference confidence="0.928277942857143">
1. Bates, M., Theory and Practice or Augmented
Transition Network Grammars, in Natural Language
Communication with Computers, L. Bolc • ,
Springer-Verlag, 1978.
2. Bossie, S., &amp;quot;A Tactical Component for Text
Generation: Sentence Generation Using a Functional
Grammar&amp;quot;, report MS-GIS-1982-26, Computer and
Information Science, University of Pennsylvania,
1982.
3. Codd, E. F., Arnold, R.S., Cadiou, J-M., Chang,
C. L. and Roussopoulos, N., RENDEZVOUS Version 1:
An Experimental English-Language Query Formulation
System for Casual Users of Relational Data Bases,
Report 1112144, IBM Research Laboratory, San Jose,
January 1978
4. Colmerauer, A., &amp;quot;Metamorphosis Grammars&amp;quot;, in L.
Bolc (Ed.), Natural Language Communication with
Computers, Springer-Verlag, 1978.
5. Finin, T., An Interpreter and Compiler for
Augmented Transition Networks, Coordinated Science
Laboratory technical report T-48, University of
Illinois, 1977.
6. Finin, T., Parsing with ATN Grammars; to appear
in Leonard Bolt (ed.) Data Base Question Answering
Systems, Springer-Verlag, Berlin, 1982. .
&amp;quot;every man who loves mary loves a woman who 7. Finin, T. and B. L. Webber, BUP - A Bottom Up
loves John&amp;quot; Parser, report MS-CIS-1982-27, Computer and
Information Science, University of Pennsylvania,
(ForAll X1 1982.
(.&gt; (And (man X1) (loves X1 mary))
(ForSome X2 (And (And (woman X2) 8. Heidorn, G., Augmented Phrase Structure Grammar,
(loves K2 John)) TINLAP-1, 1975.
(loves X1 X2)))))
&amp;quot;every man who loves a woman who loves every dog
Loves every dog&amp;quot;
</reference>
<figure confidence="0.9587845">
(ForAll X1
(.&gt; (And (man X1)
(ForSome X2
(And (And (woman X2)
(ForAll X)
(.&gt; (dog 1(3)
(loves X2 1(3))))
(loves X1 1(2))))
(ForAll X4
(.&gt; (dog 1(4) (loves 1(1 1(4)))))
</figure>
<reference confidence="0.783195">
13. Woods, W., Transition Network Grammars f
Natural Language Analysis, CACM 13:10, 1970.
14. Woods, W. A., R. M. Kaplan and B. L. Webbe ,
&amp;quot;The Lunar Sciences Natural Language Informatio.1
System: Final Report&amp;quot;, BBN report 2378, 1972.
9. Kay, M., &amp;quot;Functional Grammar&amp;quot;, Proceedings of
the Fifth Annual Meeting of the Berkeley _Linguistic
Society, 1979.
10. Pratt, V. &amp;quot;LINGOL, A Progress Report&amp;quot;, IJCAI 4,
1975.
11. Pereira, F. and D. Warren, &amp;quot;Definite. Clause
Grammars for Language Analysis - A Survey of the
Formalism and a Comparison with Augmented
Transition Networks&amp;quot;., Artificial Intelligence 13
(1980), 231-278.
12. Winograd, T., Language as a Cognitive Proce;-,
Addison-Wesley Publishing Co.,Inc,1983, 349-351.
</reference>
<page confidence="0.999149">
68
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.990223">
<title confidence="0.999819">PARSING WITH LOGICAL VARIABLES</title>
<author confidence="0.99988">Timothy W Finin</author>
<author confidence="0.99988">Martha Stone Palmer</author>
<affiliation confidence="0.9999005">Department of Computer and Information Science University of Pennsylvania</affiliation>
<address confidence="0.999643">Philadelphia, PA 19104</address>
<abstract confidence="0.99950515">Logic based programming systems have enjoyed an increasing popularity in applied Al work in the last few years. One of the contributions to Computational Linguistics made by the Logic Paradigm has been the Clause comparing DCG&apos;s with previous parsing mechanisms such as ATM&apos;s, certain clear advantages are seen. We feel that the most important of these are due to the use of Variables the fundamental operation on them. To illustrate the power of the Logical Variable, we have implemented an experimental ATN system which treats ATN registers as Logical Variables and provides a unification operation over them. We would like to simultaneously encourage the use of the powerful mechanisms available in DCG&apos;s, and demonstrate that some of these techniques can be captured without reference to a resolution theorem prover.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Bates</author>
</authors>
<title>Theory and Practice or Augmented Transition Network Grammars,</title>
<date>1978</date>
<booktitle>in Natural Language Communication with Computers, L. Bolc • ,</booktitle>
<publisher>Springer-Verlag,</publisher>
<contexts>
<context position="12017" citStr="(1)" startWordPosition="1966" endWordPosition="1966">the grammar is the one described in (fininl) and (finin21 . There are only two minor ways that this particular formalism differs from the standard ATN formalism described in [Woods70] or [Bates) . First, the dollar sign character (i.e. $) followed by the name of a register stands for the contents of that register. Second, the function DEFATN defines a set of arcs, each of which is represented by a list whose first element is the name of the state and whose remaining elements are the arcs emanating from the state. In addition, this example uses a very simple lexical manager in which a word has (1) a set of syntactic categories to which it belongs (2) an optional set of features and (3) an optional root form for the word. These attributes are associated with a word using the function LEX, which supplies appropriate default values for unspecified arguments. In the standard ATN model, a PUSH arc invokes a sub-computation which takes no arguments and, if successful, returns a single value. One can achieve the effect of passing parameters to a sub-computation by giving a register an initial value via a SENDR register setting action. There are two methods by which one can achieve the effect </context>
</contexts>
<marker>1.</marker>
<rawString>Bates, M., Theory and Practice or Augmented Transition Network Grammars, in Natural Language Communication with Computers, L. Bolc • , Springer-Verlag, 1978.</rawString>
</citation>
<citation valid="false">
<authors>
<author>S Bossie</author>
</authors>
<title>A Tactical Component for Text Generation: Sentence Generation Using a Functional Grammar&amp;quot;,</title>
<tech>report MS-GIS-1982-26,</tech>
<institution>Computer and Information Science, University of Pennsylvania,</institution>
<contexts>
<context position="12071" citStr="(2)" startWordPosition="1976" endWordPosition="1976">n21 . There are only two minor ways that this particular formalism differs from the standard ATN formalism described in [Woods70] or [Bates) . First, the dollar sign character (i.e. $) followed by the name of a register stands for the contents of that register. Second, the function DEFATN defines a set of arcs, each of which is represented by a list whose first element is the name of the state and whose remaining elements are the arcs emanating from the state. In addition, this example uses a very simple lexical manager in which a word has (1) a set of syntactic categories to which it belongs (2) an optional set of features and (3) an optional root form for the word. These attributes are associated with a word using the function LEX, which supplies appropriate default values for unspecified arguments. In the standard ATN model, a PUSH arc invokes a sub-computation which takes no arguments and, if successful, returns a single value. One can achieve the effect of passing parameters to a sub-computation by giving a register an initial value via a SENDR register setting action. There are two methods by which one can achieve the effect of returning more than one value from a sub-computatio</context>
</contexts>
<marker>2.</marker>
<rawString>Bossie, S., &amp;quot;A Tactical Component for Text Generation: Sentence Generation Using a Functional Grammar&amp;quot;, report MS-GIS-1982-26, Computer and Information Science, University of Pennsylvania,</rawString>
</citation>
<citation valid="true">
<authors>
<author>E F Codd</author>
<author>R S Arnold</author>
<author>J-M Cadiou</author>
<author>C L Chang</author>
<author>N Roussopoulos</author>
</authors>
<title>RENDEZVOUS Version 1: An Experimental English-Language Query Formulation System for Casual Users of Relational Data Bases,</title>
<date>1978</date>
<tech>Report 1112144,</tech>
<institution>IBM Research Laboratory,</institution>
<location>San Jose,</location>
<contexts>
<context position="12107" citStr="(3)" startWordPosition="1983" endWordPosition="1983">that this particular formalism differs from the standard ATN formalism described in [Woods70] or [Bates) . First, the dollar sign character (i.e. $) followed by the name of a register stands for the contents of that register. Second, the function DEFATN defines a set of arcs, each of which is represented by a list whose first element is the name of the state and whose remaining elements are the arcs emanating from the state. In addition, this example uses a very simple lexical manager in which a word has (1) a set of syntactic categories to which it belongs (2) an optional set of features and (3) an optional root form for the word. These attributes are associated with a word using the function LEX, which supplies appropriate default values for unspecified arguments. In the standard ATN model, a PUSH arc invokes a sub-computation which takes no arguments and, if successful, returns a single value. One can achieve the effect of passing parameters to a sub-computation by giving a register an initial value via a SENDR register setting action. There are two methods by which one can achieve the effect of returning more than one value from a sub-computation. The values to be returned can be </context>
</contexts>
<marker>3.</marker>
<rawString>Codd, E. F., Arnold, R.S., Cadiou, J-M., Chang, C. L. and Roussopoulos, N., RENDEZVOUS Version 1: An Experimental English-Language Query Formulation System for Casual Users of Relational Data Bases, Report 1112144, IBM Research Laboratory, San Jose, January 1978</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Colmerauer</author>
</authors>
<title>Metamorphosis Grammars&amp;quot;, in L. Bolc (Ed.), Natural Language Communication with Computers,</title>
<date>1978</date>
<publisher>Springer-Verlag,</publisher>
<marker>4.</marker>
<rawString>Colmerauer, A., &amp;quot;Metamorphosis Grammars&amp;quot;, in L. Bolc (Ed.), Natural Language Communication with Computers, Springer-Verlag, 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Finin</author>
</authors>
<title>An Interpreter and Compiler for Augmented Transition Networks, Coordinated Science Laboratory technical report T-48,</title>
<date>1977</date>
<institution>University of Illinois,</institution>
<marker>5.</marker>
<rawString>Finin, T., An Interpreter and Compiler for Augmented Transition Networks, Coordinated Science Laboratory technical report T-48, University of Illinois, 1977.</rawString>
</citation>
<citation valid="false">
<authors>
<author>T Finin</author>
</authors>
<title>Parsing with ATN Grammars; to appear in Leonard Bolt (ed.) Data Base Question Answering Systems,</title>
<date>1982</date>
<booktitle>ForAll X1 1982. (.&gt; (And (man X1) (loves X1 mary)) (ForSome X2 (And (And (woman X2) 8. Heidorn, G., Augmented Phrase Structure Grammar, (loves K2 John)) TINLAP-1,</booktitle>
<tech>Parser, report MS-CIS-1982-27,</tech>
<editor>Finin, T. and B. L. Webber, BUP</editor>
<publisher>Springer-Verlag,</publisher>
<institution>Computer and Information Science, University of Pennsylvania,</institution>
<location>Berlin,</location>
<marker>6.</marker>
<rawString>Finin, T., Parsing with ATN Grammars; to appear in Leonard Bolt (ed.) Data Base Question Answering Systems, Springer-Verlag, Berlin, 1982. . &amp;quot;every man who loves mary loves a woman who 7. Finin, T. and B. L. Webber, BUP - A Bottom Up loves John&amp;quot; Parser, report MS-CIS-1982-27, Computer and Information Science, University of Pennsylvania, (ForAll X1 1982. (.&gt; (And (man X1) (loves X1 mary)) (ForSome X2 (And (And (woman X2) 8. Heidorn, G., Augmented Phrase Structure Grammar, (loves K2 John)) TINLAP-1, 1975. (loves X1 X2))))) &amp;quot;every man who loves a woman who loves every dog Loves every dog&amp;quot;</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Woods</author>
</authors>
<title>Transition Network Grammars f Natural Language Analysis,</title>
<date>1970</date>
<journal>CACM</journal>
<volume>13</volume>
<marker>13.</marker>
<rawString>Woods, W., Transition Network Grammars f Natural Language Analysis, CACM 13:10, 1970.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Woods</author>
<author>R M Kaplan</author>
<author>B L Webbe</author>
</authors>
<title>The Lunar Sciences Natural Language Informatio.1 System: Final Report&amp;quot;,</title>
<date>1972</date>
<tech>BBN report 2378,</tech>
<marker>14.</marker>
<rawString>Woods, W. A., R. M. Kaplan and B. L. Webbe , &amp;quot;The Lunar Sciences Natural Language Informatio.1 System: Final Report&amp;quot;, BBN report 2378, 1972.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kay</author>
</authors>
<title>Functional Grammar&amp;quot;,</title>
<date>1979</date>
<booktitle>Proceedings of the Fifth Annual Meeting of the Berkeley _Linguistic Society,</booktitle>
<marker>9.</marker>
<rawString>Kay, M., &amp;quot;Functional Grammar&amp;quot;, Proceedings of the Fifth Annual Meeting of the Berkeley _Linguistic Society, 1979.</rawString>
</citation>
<citation valid="false">
<authors>
<author>V Pratt</author>
</authors>
<title>LINGOL, A Progress Report&amp;quot;,</title>
<tech>IJCAI 4,</tech>
<marker>10.</marker>
<rawString>Pratt, V. &amp;quot;LINGOL, A Progress Report&amp;quot;, IJCAI 4,</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Pereira</author>
<author>D Warren</author>
</authors>
<title>Definite. Clause Grammars for Language Analysis - A Survey of the Formalism and a Comparison with Augmented Transition Networks&amp;quot;.,</title>
<date>1980</date>
<journal>Artificial Intelligence</journal>
<volume>13</volume>
<pages>231--278</pages>
<marker>11.</marker>
<rawString>Pereira, F. and D. Warren, &amp;quot;Definite. Clause Grammars for Language Analysis - A Survey of the Formalism and a Comparison with Augmented Transition Networks&amp;quot;., Artificial Intelligence 13 (1980), 231-278.</rawString>
</citation>
<citation valid="false">
<authors>
<author>T Winograd</author>
</authors>
<title>Language as a Cognitive Proce;-,</title>
<booktitle>Co.,Inc,1983,</booktitle>
<pages>349--351</pages>
<publisher>Addison-Wesley Publishing</publisher>
<marker>12.</marker>
<rawString>Winograd, T., Language as a Cognitive Proce;-, Addison-Wesley Publishing Co.,Inc,1983, 349-351.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>