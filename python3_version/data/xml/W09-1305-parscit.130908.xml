<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002106">
<title confidence="0.994253">
How Feasible and Robust is the Automatic Extraction of Gene Regulation
Events ? A Cross-Method Evaluation under Lab and Real-Life Conditions
</title>
<author confidence="0.998517">
Udo Hahn&apos; Katrin Tomanek&apos; Ekaterina Buyko&apos; Jung-jae Kim2 Dietrich Rebholz-Schuhmann2
</author>
<affiliation confidence="0.64469025">
&apos;Jena University Language &amp; Information Engineering (JULIE) Lab
Friedrich-Schiller-Universit¨at Jena, Germany
{udo.hahn|katrin.tomanek|ekaterina.buyko}@uni-jena.de
2EMBL-EBI, Wellcome Trust Genome Campus, Hinxton, Cambridge, UK
</affiliation>
<email confidence="0.994845">
{kim|rebholz}@ebi.ac.uk
</email>
<sectionHeader confidence="0.995554" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998993">
We explore a rule system and a machine learn-
ing (ML) approach to automatically harvest
information on gene regulation events (GREs)
from biological documents in two different
evaluation scenarios – one uses self-supplied
corpora in a clean lab setting, while the other
incorporates a standard reference database of
curated GREs from REGULONDB, real-life
data generated independently from our work.
In the lab condition, we test how feasible
the automatic extraction of GREs really is
and achieve F-scores, under different, not di-
rectly comparable test conditions though, for
the rule and the ML systems which amount
to 34% and 44%, respectively. In the REGU-
LONDB condition, we investigate how robust
both methodologies are by comparing them
with this routinely used database. Here, the
best F-scores for the rule and the ML systems
amount to 34% and 19%, respectively.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999859444444445">
The extraction of binary relations from biomedical
text has caught much attention in the recent years.
Progress on this and other tasks has been monitored
in challenge competitions such as BIOCREATIVE I
and II,1 which dealt with gene/protein names and
and protein-protein interaction.
The BIOCREATIVE challenge and other related
ones have shown at several occasions that partici-
pants continue to use two fundamentally different
</bodyText>
<footnote confidence="0.986432">
1http://biocreative.sourceforge.net/
</footnote>
<page confidence="0.997668">
37
</page>
<bodyText confidence="0.999208689655172">
systems: symbolic pattern-based systems (rule sys-
tems), on the one hand, and feature-based statisti-
cal machine learning (ML) systems, on the other
hand. This has led to some rivalry with regard to the
interpretation of their performance data, the costs
of human efforts still required and their scalability
for the various tasks. While rule systems are of-
ten hand-crafted and fine-tuned to a particular ap-
plication (making a major manual rewrite often nec-
essary when the application area is shifted), ML
systems are trained automatically on manually an-
notated corpora, i.e., without manual intervention,
and thus have the advantage to more easily adapt to
changes in the requested identification tasks. Time
costs (human workload) are thus shifted from rule
design and adaptation to metadata annotation.
Text mining systems as usually delivered by
BioNLP researchers render biologically relevant en-
tities and relations on a limited set of test documents
only. While this might be sufficient for the BioNLP
community, it is certainly insufficient for bioinfor-
maticians and molecular biologists since they re-
quire large-scale data with high coverage and reli-
ability. For our analysis, we have chosen the topic
of gene regulatory events in E. coli, which is a do-
main of very active research and grand challenges.2
Currently the gold standard of the existing body of
knowledge of such events is represented by the fact
database REGULONDB.3 Its content has been man-
</bodyText>
<footnote confidence="0.9411918">
2The field of gene regulation is one of the most prominent
topics of research and often mentioned as one of the core fields
of future research in molecular biology (cf, e.g., the Grand
Challenge I-2 described by Collins et al. (2003)).
3http://regulondb.ccg.unam.mx/
</footnote>
<note confidence="0.922994">
Proceedings of the Workshop on BioNLP, pages 37–45,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.999916409090909">
ually gathered from the scientific literature and de-
scribes the curated computational model of mecha-
nisms of transcriptional regulation in E. coli. Having
this gold standard in mind, we face the challenging
task to automatically reproduce this content from the
available literature, to enhance this content with re-
liable additional information and to update this re-
source as part of a regular automatic routine.
Hence, we first explore the feasibility and per-
formance of a rule-based and an ML-based system
against special, independently created corpora that
were generated to enable measurements under clean
experimental lab conditions. This part, due to dif-
ferent experimental settings, is not meant as a com-
parison between both approaches though. We then
move to the even more demanding real-life scenario
where we evaluate and compare these solutions for
the identification of gene regulatory events against
the REGULONDB data resource. This approach tar-
gets the robustness of the proposed text mining so-
lutions from the perspectives of completeness, cor-
rectness and novelty of the generated results.
</bodyText>
<sectionHeader confidence="0.999692" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999972368421053">
Considering relation extraction (RE) in the biomed-
ical domain, there are only few studies which deal
primarily with gene regulation. Yang et al. (2008)
focus on the detection of sentences that contain
mentions of transcription factors (proteins regulat-
ing gene expression). They aim at the detection
of new transcription factors, while relations are not
taken into account. In contrast, ˇSari´c et al. (2004)
extract gene regulatory networks and achieve in the
RE task an accuracy of up to 90%. They disregard,
however, ambiguous instances, which may have led
to the low recall around 20%. The Genic Interaction
Extraction Challenge (N´edellec, 2005) was orga-
nized to determine the state-of-the-art performance
of systems designed for the detection of gene regula-
tion interactions. The best system achieved a perfor-
mance of about 50% F-score. The results, however,
have to be taken with care as the LLL corpus used in
the challenge is of extremely limited size.
</bodyText>
<sectionHeader confidence="0.5399" genericHeader="method">
3 Extraction of Gene Regulation Events
</sectionHeader>
<bodyText confidence="0.999837076923077">
Gene regulation is a complex cellular process that
controls the expression of genes. These genes are
then transcribed into their RNA representation and
later translated into proteins, which fulfill various
tasks such as maintaining the cell structure, enabling
the generation of energy and interaction with the en-
vironment.
The analysis of the gene regulatory processes is
ongoing research work in molecular biology and af-
fects a large number of research domains. In par-
ticular the interpretation of gene expression profiles
from microarray analyses could be enhanced using
our understanding of gene regulation events (GREs)
from the literature.
We approach the task of the automatic extraction
of GREs from literature from two different method-
ological angles. On the one hand, we provide a set of
hand-crafted rules – both for linguistic analysis and
conceptual inference (cf. Section 3.1), the latter be-
ing particularly helpful in unveiling only implicitly
stated biological knowledge. On the other hand, we
supply a machine learning-based system for event
extraction (cf. Section 3.2). No regularities are spec-
ified a priori by a human although, at least in the su-
pervised scenario we have chosen, this approach re-
lies on training data supplied by human (expert) an-
notators who provide sufficiently many instances of
ground truth decisions from which regularities can
automatically be learnt. At the level of system per-
formance, rules tend to foster precision at the cost
of recall and ML systems tend to produce inverse
figures, while there is no conclusive evidence for or
against any of these two approaches.
The extraction of GREs, independent of the ap-
proach one subscribes to, is a complex problem
composed of a series of subtasks. Abstracting away
from lots of clerical and infrastructure services (e.g.,
sentence splitting, tokenization) at the core of any
GRE extraction lie the following basic steps:
</bodyText>
<listItem confidence="0.9956862">
• the identification of pairs of gene mentions as
the arguments of a relation – the well-known
named entity recognition and normalization
task,
• the decision whether the entity pair really con-
stitutes a relation,
• and the identification of the roles of the argu-
ments in the relation which implicitly amounts
to characterize each argument as either agent or
patient.
</listItem>
<page confidence="0.99723">
38
</page>
<subsectionHeader confidence="0.985727">
3.1 Rule-based Extraction
</subsectionHeader>
<bodyText confidence="0.999746187500001">
The rule-based system extracts GREs from text em-
ploying logical inference. The motivation of using
inference is that the events under scrutiny are often
expressed in text in either a compositional or an in-
complete way. We address this issue by composi-
tionally representing textual semantics and by log-
ically inferring implicit meanings of text over the
compositional representation of textual semantics.
Entity Identification. The system first recognizes
named entities of the types that can be participants of
the target events. We have collected 15,881 E. coli
gene/protein and operon names from REGULONDB
and UNIPROT. Most of the gene/protein names are
associated with UNIPROT identifiers. An operon in
prokaryotes is a DNA sequence with multiple genes
whose expression is controlled by a shared promoter
and which thus express together. We have mapped
the operon names to corresponding gene sets.
Named entity recognition relies on the use of dic-
tionaries. If the system recognizes an operon name,
it then associates the operon with its genes. The
system further recognizes multi-gene object names
(e.g., “acrAB”), divides them into individual gene
names (e.g., “acrA”, “acrB”) and associates the gene
names with the multi-gene object names.
Relation Identification. The system then iden-
tifies syntactic structures of sentences in an in-
put corpus by utilizing the ENJU parser (Sagae et
al., 2007). The ENJU parser generates predicate-
argument structures, and the system converts them
into dependency structures.
The system then analyzes the semantics of the
sentences by matching syntactic-semantic patterns
to the dependency structures. We constructed 1,123
patterns for the event extraction according to the fol-
lowing workflow. We first collected keywords re-
lated to gene regulation, from GENE ONTOLOGY,
INTERPRO, WORDNET, and several papers about
information extraction from biomedical literature
(Hatzivassiloglou and Weng, 2002; Kim and Park,
2004; Huang et al., 2004). Then we collected sub-
categorization frames for each keyword and created
patterns for the frames manually.
Each pattern consists of a syntactic pattern and
a semantic pattern. The syntactic patterns com-
ply with dependency structures. The system tries
to match the syntactic patterns to the dependency
structures of sentences in a bottom-up way, consid-
ering syntactic and semantic restrictions of syntac-
tic patterns. Once a syntactic pattern is successfully
matched to a sub-tree of the available dependency
structure, its corresponding semantic pattern is as-
signed to the sub-tree as one of its semantics. The
semantic patterns are combined according to the de-
pendency structures to form a compositional seman-
tic structure.
The system then performs logical inference over
the semantic structures by using handcrafted infer-
ence rules and extracts target information from the
results of the inference. We have manually created
28 inference rules that reflect the knowledge of the
gene regulation domain. Only relations where the
identified agent is one of those known TFs are kept,
while all others are discarded.
</bodyText>
<subsectionHeader confidence="0.999146">
3.2 Generic, ML-based Extraction
</subsectionHeader>
<bodyText confidence="0.999987761904762">
Apart from the already mentioned clerical pre-
processing steps, the ML-based extraction of GREs
requires several additional syntactic processing
steps including POS-tagging, chunking, and full
dependency- and constituency-based parsing.4
Entity Identification. To identify gene names in
the documents, we applied GENO, a multi-organism
gene name recognizer and normalizer (Wermter
et al., 2009) which achieved a top-rank perfor-
mance of 86.4% on the gene normalization task
of BIOCREATIVE-II. GENO recognizes gene men-
tions by means of an ML-based named entity tag-
ger trained on publicly available corpora. Subse-
quently, it attempts to map all identified mentions to
organism-specific UNIPROT5 identifiers. Mentions
that cannot be mapped are discarded; only success-
fully mapped mentions are kept. We utilized GENO
in its original version, i.e., without special adjust-
ments to the E. coli organism. However, only those
mentions detected to be genes of E. coli were fed
into the relation extraction component.
</bodyText>
<footnote confidence="0.9961082">
4These tasks were performed with the OPENNLP tools
(http://opennlp.sourceforge.net/) and the
MST parser (http://sourceforge.net/projects/
mstparser), both retrained on biomedical corpora.
5http://www.uniprot.de
</footnote>
<page confidence="0.999358">
39
</page>
<bodyText confidence="0.999262125">
Relation Identification. The ML-based approach
to GRE employs Maximum Entropy models and
constitutes and extension of the system proposed by
Buyko et al. (2008) as it also makes use of depen-
dency parse information including dependency tree
level features (Katrenko and Adriaans, 2006) and
shortest dependency path features (Kim et al., 2008).
In short, the feature set consists of:
</bodyText>
<listItem confidence="0.974168882352941">
• word features (covering words before, after and
between both entity mentions);
• entity features (accounting for combinations of
entity types, flags indicating whether mentions
have an overlap, and their mention level);
• chunking and constituency-based parsing fea-
tures (concerned with head words of the
phrases between two entity mentions; this class
of features exploits constituency-based parsing
as well and indicates, e.g., whether mentions
are in the same NP, PP or VP);
• dependency parse features (analyzing both the
dependency levels of the arguments as dis-
cussed by Katrenko and Adriaans (2006) and
dependency path structure between the argu-
ments as described by Kim et al. (2008));
• and relational trigger (key)words (accounting
</listItem>
<bodyText confidence="0.932382777777778">
for the connection of trigger words and men-
tions in a full parse tree).
An advantage of ML-based systems is that they
allow for thresholding. To achieve higher recall
values for our system, we may set the confidence
threshold for the negative class (i.e., a pair of en-
tity mentions does not constitute a relation) to values
&gt; 0.5. Clearly, this is at the cost of precision as the
system more readily assigns the positive class.
</bodyText>
<sectionHeader confidence="0.999355" genericHeader="method">
4 Intrinsic Evaluation of Feasibility
</sectionHeader>
<bodyText confidence="0.999984">
The following two sections aim at evaluating the
rule-based and ML-based GRE extraction systems.
The systems are first “intrinsically” evaluated, i.e.,
in a cross-validation manner on corpora annotated
with respect to GREs. Second, in a more realistic
scenario, both systems were evaluated against REG-
ULONDB, a database collecting knowledge about
gene regulation in E. coli. This scenario tests which
part of manually accumulated knowledge about gene
regulation in E. coli can automatically be identified
by our systems and at what level of quality.
</bodyText>
<subsectionHeader confidence="0.975564">
4.1 Rule-based system
</subsectionHeader>
<bodyText confidence="0.99997995">
Corpus. For the training and evaluation of the
rule-based system, we annotated 209 MEDLINE ab-
stracts with three types of events: specific events
of gene transcription regulation, general events of
gene expression regulation, and physical events of
binding of transcription factors to gene regulatory
regions. Strictly speaking, only the first type is rele-
vant to REGULONDB. However, biologists often re-
port gene transcription regulation events in the sci-
entific literature as if they are gene expression regu-
lation events, which is a generalization of gene tran-
scription regulation, or the binding event, which it-
self is insufficient evidence for gene transcription
regulation. The two latter types may indicate that
the full-texts contain evidence of the first type.
We asked two curators to annotate the abstracts.
Curator A was trained with example annotations and
interactive discussions. Curator B was trained only
with example annotations and guidelines. For cross-
checking of annotations, we asked them to annotate
an unseen corpus of 97 abstracts and found that Cu-
rator A made 10.8% errors, misjudging three event
additions and, in the other 14 errors, mistaking in
annotating event types, event attributes, and pas-
sage boundaries, while Curator B made 32.4% er-
rors as such. This result indicates that the annotation
of GREs requires intensive and interactive training.
The curators have discussed and agreed on the final
release of the corpora.6
Results. The system has successfully extracted 79
biologically meaningful events among them (21.1%
recall) and incorrectly produced 15 events (84.0%
precision) which constitutes an overall F-score of
33.6%. Among the 79 events, the system has cor-
rectly identified event types of 39 events (49.4% pre-
cision), polarity of 46 events (58.2% precision), and
directness of 51 events (64.6% precision). Note that
the system employed a fully automatic module for
named entity recognition. The event type recogni-
tion is impaired, because it often fails to recognize
</bodyText>
<footnote confidence="0.999251">
6The resultant annotated corpora are available at http://
www.ebi.ac.uk/˜kim/eventannotation/.
</footnote>
<page confidence="0.997526">
40
</page>
<bodyText confidence="0.9999285">
the specific event type of transcription regulation,
but only identifies the general event type of gene ex-
pression regulation due to the lack of identified evi-
dence.
</bodyText>
<subsectionHeader confidence="0.981118">
4.2 ML-based system
</subsectionHeader>
<bodyText confidence="0.999958528301887">
GeneReg corpus. The GENEREG corpus (Buyko
et al., 2008) constitutes a selection of 314 MED-
LINE abstracts related to gene regulation in E. coli.
These abstracts were randomly drawn from a set of
32,155 selected by MESH term queries from MED-
LINE using keywords such as Escherichia coli, Gene
Expression and Transcription Factors. These 314
abstracts were manually annotated for named enti-
ties involved in gene regulatory processes (such as
transcription factor, including co-factors and regu-
lators, and genes) and pairwise relations between
transcription factors (TFs) and genes, as well as trig-
gers (e.g., clue verbs) essential for the description of
gene regulation relations. As for the relation types,
the GENEREG corpus distinguishes between (a) un-
specified regulation of gene expression, (b) positive,
and (c) negative regulation of gene expression. Out
of the 314 abstracts a set of 65 were randomly se-
lected and annotated by a second annotator to iden-
tify inter-annotator agreement (IAA) values. For the
task of correct identification of the pair of interacting
named entities in gene regulation processes, an IAA
of 78.4% (R), 77.3% (P ), 77.8% (F) was measured,
while 67% (R), 67.9% (P), 67.4% (F) were achieved
for the identification of interacting pairs plus the 3-
way classification of the interaction relation.
Experimental Setting. The ML-based extraction
system merges all of the above mentioned three
types (unspecific, negative and positive) into one
common type “relation of gene expression”. So, it
either finds that there is a relation of interest be-
tween a pair of gold entity mentions or not. We
evaluated our system by a 5-fold cross-validation on
the GENEREG corpus. The fold splits were done
on the abstract-level to avoid the otherwise unrealis-
tic scenario where a system is trained on sentences
from an abstract and evaluated on other sentences
but from the same abstract (Pyysalo et al., 2008).
As our focus here is only on the performance of the
GRE extraction component, gold entity mentions as
annotated in the respective corpus were used.
Results. For the experimental settings given
above, the system achieved an F-score of 42% with
a precision of 59% and a recall of 33%. Increasing
the confidence threshold for the negative class in-
creases recall as shown for two different thresholds
in Table 1. As expected this is at the cost of preci-
sion. It shows, that using an extremely high thresh-
old of 0.95 results in a dramatically increased recall
of 73% compared to 33% with the default threshold.
Although at the cost of diminished precision of 32%
compared to originally 59%, the lifted threshold in-
creases the overall F-score (44%) by 2 points.
</bodyText>
<table confidence="0.99694275">
threshold R P F
default (0.5) 0.33 0.59 0.42
0.80 0.54 0.43 0.48
0.95 0.73 0.32 0.44
</table>
<tableCaption confidence="0.9943895">
Table 1: Different confidence thresholds for the ML-
based system achieved by intrinsic evaluation
</tableCaption>
<sectionHeader confidence="0.982986" genericHeader="method">
5 Extrinsic Evaluation of Robustness
</sectionHeader>
<bodyText confidence="0.999986730769231">
REGULONDB is the primary and largest reference
database providing manually curated knowledge of
the transcriptional regulatory network of E. coli
K12. On K12, approximately for one-third of K12’s
genes, information about their regulation is avail-
able. REGULONDB is updated with content from
recent research papers on this issue. While REG-
ULONDB contains much more, for this paper our
focus was solely on REGULONDB’s information
about gene regulation events in E. coli. In the fol-
lowing, the term REGULONDB refers to this part of
the REGULONDB database. REGULONDB includes
e.g., the following information for each regulation
event: regulatory gene (the “agent” in such an event,
a transcription factor), the regulated gene (the “pa-
tient”), the regulatory effect on the regulated gene
(activating, suppression, dual, unknown), and evi-
dence that supports the existence of the regulatory
interaction.
Evaluation against REGULONDB constitutes a
real-life scenario. Thus, the complete extraction sys-
tems were run, including gene name recognition and
normalization as well as relation detection. Hence,
the systems’ overall recall values are highly affected
by the gene name identification. REGULONDB is
here taken as a “true” gold standard and thus as-
</bodyText>
<page confidence="0.998727">
41
</page>
<bodyText confidence="0.999742571428571">
sumed to be correct and exhaustive with respect to
the GREs contained. As, however, every manu-
ally curated database is likely to be incomplete and
might contain some errors, we supplement our eval-
uation against REGULONDB with a manual analy-
sis of false positives errors caused by our system (cf.
Section 5.4).
</bodyText>
<subsectionHeader confidence="0.998141">
5.1 Evaluation Scenario and Experimental
Settings
</subsectionHeader>
<bodyText confidence="0.999688896551724">
To evaluate our extraction systems against REG-
ULONDB we first processed a set of input docu-
ments (see below), collected all unique gene reg-
ulation events extracted and compared this set of
events against the full set of known events in REG-
ULONDB. A true positive (TP) hit is obtained, when
an event found automatically corresponds to one in
REGULONDB, i.e., having the same agent and pa-
tient. The type of regulation is not considered. A
false positive (FP) hit is counted, if an event was
found which does not occur in the same way in
REGULONDB, i.e., either patient or agent (or both)
are wrong. False negatives (FN) are those events
covered by REGULONDB but not found by a sys-
tem automatically. From these hit values, standard
precision, recall, and F-score values are calculated.
Of course, the systems’ performance largely depend
on the size of the base corpus collection processed.
Thus, for both systems and all three document sets
we got separate performance scores.
Table 2 gives an overview to the document col-
lections used for evaluating the robustness of our
systems: The “ecoli-tf” variants are documents fil-
tered both with E. coli TF names and with relevance
to E. coli. Abstracts are taken from Medline cita-
tions, while full texts are from a corpus of different
biomedical journals. The third document set, “regu-
lon ra”, is a set containing abstracts from the REG-
ULONDB references.
</bodyText>
<subsectionHeader confidence="0.999191">
5.2 Rule-based-System
</subsectionHeader>
<bodyText confidence="0.9994294">
Table 3 shows the evaluation results of the rule-
based system against REGULONDB. Though the
system distinguishes the three types of events, we
have considered them all as events of gene tran-
scription regulation for the evaluation. For instance,
the system has extracted 718 unique events with
single-unit participants (i.e., excluding operons), not
considering event types and attributes (e.g., polar-
ity), from the “ecoli-tf.fulltext” corpus. Among the
events, 347 events are found in Regulon (9.7% re-
call, 48.3% precision). If we only consider the
events that are specifically identified as gene tran-
scription regulation, the system has extracted 379
unique events among which 201 are also found in
Regulon (5.6% recall, 53.0% precision).
</bodyText>
<figure confidence="0.503590142857143">
participant document set
single-unit ecoli-tf.abstracts
multi-unit ecoli-tf.abstracts
single-unit ecoli-tf.fulltext
multi-unit ecoli-tf.fulltext
single-unit regulon ra
multi-unit regulon ra
</figure>
<tableCaption confidence="0.9898895">
Table 3: Results of evaluation against REGULONDB of
rule-based system.
</tableCaption>
<bodyText confidence="0.999674">
When we split multi-unit participants into individ-
ual genes, the rule-based system shows better per-
formance, as shown in Table 3 with the participant
type “multi-unit”. This may indicate that the gene
regulatory events of E. coli are often described as
interactions of operons. At best, the system shows
34% F-score with the “ecoli-tf.abstracts” corpus.
</bodyText>
<subsectionHeader confidence="0.998743">
5.3 ML-based System
</subsectionHeader>
<bodyText confidence="0.99930475">
The ML-based system was designed to recognize
all types of gene regulation events. REGULONDB,
however, contains only the subtype, i.e., regulation
of transcription. Thus, the ML-based system was
evaluated against REGULONDB in two modes: by
default, all events extracted by the systems are con-
sidered; in the “TF-filtered” mode, only relations
with an agent from the list of all known TFs in E.
coli are considered (as done for the rule-based sys-
tem by default). Thus, comparing to the rule-based
system, only the results obtained in the “TF-filtered”
mode should be considered.
</bodyText>
<table confidence="0.987095083333334">
name type # documents
ecoli-tf.abstracts abstract 4,347
ecoli-tf.fulltext full texts 1,812
regulon ra abstracts 2,704
Table 2: Document sets for REGULONDB evaluation
R P F
0.09 0.60 0.15
0.24 0.61 0.34
0.10 0.48 0.16
0.25 0.49 0.33
0.07 0.73 0.13
0.18 0.70 0.28
</table>
<page confidence="0.988033">
42
</page>
<subsectionHeader confidence="0.748596">
5.3.1 Raw performance scores
</subsectionHeader>
<bodyText confidence="0.950635454545455">
The results for the ML-based system are shown in
Table 4. Recall values here range between 7 and
10%, while precision is between 29 and 78% de-
pending on both the document set as well as the
application of the TF filter. The low recall of the
ML-based system is partially due to the fact that the
system does not recognize multi-gene object names
(e.g., “acrAB”), in this configuration the recall is
similar to the recall of the rule-based system in a
“single-unit modus” (see Table 3).
mode document set R P F
</bodyText>
<table confidence="0.999386666666667">
0.09 0.70 0.16
0.09 0.45 0.15
0.10 0.54 0.17
0.10 0.29 0.15
0.07 0.78 0.13
0.07 0.47 0.12
</table>
<tableCaption confidence="0.992003">
Table 4: Results of evaluation against REGULONDB of
ML-based system
</tableCaption>
<bodyText confidence="0.999979071428571">
As already shown in the intrinsic evaluation,
application of different confidence thresholds in-
creases the recall of the ML-based system. This was
also done for the evaluation against REGULONDB.
Table 5 shows the impact of increased confidence
thresholds for the negative class on the “regulon ra”
set for the “TF-filtered” evaluation mode. Given an
extremely high threshold of 0.95, the recall is in-
creased from 7 to 11% which constitutes a relative
increase of over 60%. Precision obviously drops,
however, the overall F-score has improved from 13
to 19%. These results emphasize that an ML-based
system has an important handle which allows to ad-
just recall according to the application needs.
</bodyText>
<table confidence="0.998496">
threshold R P F
default (0.5) 0.07 0.78 0.13
0.8 0.09 0.70 0.16
0.95 0.11 0.63 0.19
</table>
<tableCaption confidence="0.9963695">
Table 5: Different confidence thresholds for the ML-
based system tested on the “regulon ra” set
</tableCaption>
<subsectionHeader confidence="0.998505">
5.4 Manual analysis of false positives
</subsectionHeader>
<bodyText confidence="0.986251872340426">
REGULONDB was taken as an absolute gold stan-
dard in this evaluation. If a system correctly extracts
an event which is not contained in REGULONDB
for some reason, this constitutes a FP. Moreover, all
kinds of error (e.g., agent and patient mixed up) were
subsumed as FP errors. To analyze the cause and
distribution of FPs in more detail, a manual analysis
of the FP errors was performed and original FP hits
were assigned to one out of four FP error categories:
Cat1: Not a GRE This is really an FP error, as the
extracted relation does not at all constitute a
gene regulation event.
Cat2a: GRE but other than transcription
Unlike REGULONDB which contains only one
subtype of GREs, namely transcriptions, the
ML-based system identifies all kinds of GREs.
Therefore, the ML-based system clearly
identifies events which cannot be contained in
REGULONDB and, therefore, are not really
FPs.
Cat 3: Partially correct transcription event This
category deals with incorrect arguments of
GREs. We distinguish three types of FPs: (a)
the patient and the agent role are interchanged,
(b) the patient is wrong, while the agent is
right, and (c) the agent is wrong, while the
patient is right. In all these three cases, though
errors were committed human curators might
find the partially incorrect information useful
to speed up the curation process.
Cat4: Relation missing in REGULONDB Those
are relations which should be contained in
REGULONDB but are missing for some
reason. The agent is a correctly identified
transcription factor and the sentence contains
a mention of a transcription event. There are
several reasons why this relation was not found
in REGULONDB as we will discuss in the
following.
Table 6 shows the results of the manual FP anal-
ysis of the ML-based system (no TF filter applied)
on the “ecoli-tf-abstracts” and “ecoli-tf-fulltexts”.
It shows that the largest source of error is due
to Cat1, i.e., an identified relation is completely
wrong. As fulltext documents are generally more
complex, the relative amount of this kind of errors
is higher here than on abstracts (54.5 % compared
</bodyText>
<figure confidence="0.962656333333333">
TF-filtered ecoli-tf.abstracts
default ecoli-tf.abstracts
TF-filtered ecoli-relevant.fulltext
default ecoli-relevant.fulltext
TF-filtered regulon ra
default regulon ra
</figure>
<page confidence="0.998661">
43
</page>
<table confidence="0.980337428571429">
category abstracts (%) fulltexts (%)
Cat 1 44.5 54.5
Cat 2 11.2 10.9
Cat 3a 3.8 3.9
Cat 3b 8.5 4.4
Cat 3c 8.2 5.4
Cat 4 23.8 21.0
</table>
<tableCaption confidence="0.993710666666667">
Table 6: Manual analysis of false positive errors (FP).
Percentages of FPs by category are reported on “ecoli-tf-
abstracts” and “ecoli-tf-fulltexts”
</tableCaption>
<bodyText confidence="0.999966958333333">
to 44.5 %). However, on abstracts and fulltexts, a
bit more than 10 % of the FP are because the sys-
tem found too general GREs which, by definition,
are not contained in REGULONDB (Cat2). Iden-
tified GREs that were partially correct constitute
20.5 % (abstracts) or 13.7 % (fulltexts) of the FP er-
rors (Cat3).
Finally, 23.8% and 21.0% of the FPs for abstracts
and fulltext, respectively, are correct transcription
events but could not be found in REGULONDB
(Cat4). This is due to several reasons. For instance,
identified gene names were incorrectly normalized
so that they could not be found in REGULONDB,
REGULONDB curators have not yet added a relation
or simply overlooked it; relations are correctly iden-
tified as such in the narrow context of a paragraph of
a document but were actually of speculative nature
only (this includes relations whose status is unsure,
often indicated by “likely” or “possibly”).
Summarizing, the manual FP analysis shows that
about 50% of all FPs are not completely erroneous.
These numbers must clearly be kept in mind when
interpreting the raw numbers (especially for preci-
sion) reported on in the previous subsection.
</bodyText>
<subsectionHeader confidence="0.991253">
5.5 Integration of text mining results
</subsectionHeader>
<bodyText confidence="0.9999894375">
We have integrated the results of the two different
text mining systems and found that both systems are
complementary to each other such that their result
sets do not heavily overlap. For instance, from the
“ecoli-tf.abstract” corpus, the rule-based system ex-
tracts 992 events, while the ML-based system ex-
tracts 705 events. For the integration, we have con-
sidered only the events whose participants are as-
sociated with UNIPROT identifiers. Among the ex-
tracted events, only 285 events are extracted by both
systems. We might speculate that the overlapping
events are more reliable than the rest of the extracted
events. It also leaves 71.3% of the results from
the rule-based system and 59.6% of results from the
ML-based system as unique contributions from each
of the approaches for the integration.
</bodyText>
<sectionHeader confidence="0.999694" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999976571428571">
We have explored a rule-based and a machine
learning-based approach to the automatic extrac-
tion of gene regulation events. Both approaches
were evaluated under well-defined lab conditions us-
ing self-supplied corpora, and under real-life condi-
tions by comparing our results with REGULONDB,
a well-curated reference data set. While the re-
sults for the first evaluation scenario are state of the
art, performance figures in the real-life scenario are
not so shiny (the best F-scores for the rule-based
and the ML-based system are on the order of 34%
and 19%, respectively). This holds, in particular,
for the comparison with the work of Rodr´ıguez-
Penagos et al. (2007). Still, at least the ML-based
approach is much more general than the very specifi-
cally tuned manual rule set from Rodr´ıguez-Penagos
et al. (2007) and has potential for increases in perfor-
mance. Also, this has been the first extra-mural eval-
uation of automatically generating content for REG-
ULONDB.
Still, the analysis of false positives reveals that
the strict criteria we applied for our evaluation may
appear in another light for human curators. Con-
founded agents and patients (21% on the abstracts,
14% on full texts) and information not contained in
REGULONDB (24% on the abstracts, 21% on full
texts) might be useful from a heuristic perspective to
focus on interesting data during the curation process.
</bodyText>
<sectionHeader confidence="0.997513" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999952">
This work was funded by the EC within the BOOT-
Strep (FP6-028099) and the CALBC (FP7-231727)
projects. We want to thank Tobias Wagner (Centre
for Molecular Biomedicine, FSU Jena) for perform-
ing the manual FP analysis.
</bodyText>
<page confidence="0.998859">
44
</page>
<sectionHeader confidence="0.995885" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999879483333334">
Ekaterina Buyko, Elena Beisswanger, and Udo Hahn.
2008. Testing different ACE-style feature sets for
the extraction of gene regulation relations from MED-
LINE abstracts. In Proceedings of the 3rd Interna-
tional Symposium on Semantic Mining in Biomedicine
(SMBM 2008), pages 21–28.
Francis Collins, Eric Green, Alan Guttmacher, and Mark
Guyer. 2003. A vision for the future of genomics re-
search. Nature, 422(6934 (24 Feb)):835–847.
Vasileios Hatzivassiloglou and Wubin Weng. 2002.
Learning anchor verbs for biological interaction pat-
terns from published text articles. International Jour-
nal of Medical Informatics, 67:19–32.
Minlie Huang, Xiaoyan Zhu, Donald G. Payan, Kun-
bin Qu, and Ming Li. 2004. Discovering patterns
to extract protein-protein interactions from full texts.
Bioinformatics, 20(18):3604–3612.
Sophia Katrenko and P. Adriaans. 2006. Learning rela-
tions from biomedical corpora using dependency trees.
In KDECB 2006 – Knowledge Discovery and Emer-
gent Complexity in Bioinformatics, pages 61–80.
Jung-jae Kim and Jong C. Park. 2004. BioIE: retar-
getable information extraction and ontological anno-
tation of biological interactions from the literature.
Journal of Bioinformatics and Computational Biology,
2(3):551–568.
Seon-Ho Kim, Juntae Yoon, and Jihoon Yang. 2008.
Kernel approaches for genic interaction extraction.
Bioinformatics, 24(1):118–126.
Claire N´edellec. 2005. Learning language in logic -
genic interaction extraction challenge. In Learning
language in logic - genic interaction extraction LLL’
2005, pages 31–37.
Sampo Pyysalo, Antti Airola, Juho Heimonen, Jari
Bj¨orne, Filip Ginter, and Tapio Salakoski. 2008.
Comparative analysis of five protein-protein interac-
tion corpora. BMC Bioinformatics, 9(3), April.
Carlos Rodr´ıguez-Penagos, Heladia Salgado, Irma
Martinez-Flores, and Julio Collado-Vides. 2007. Au-
tomatic reconstruction of a bacterial regulatory net-
work using natural language processing. BMC Bioin-
formatics, 8(293).
Kenji Sagae, Yusuke Miyao, and Junichi Tsujii. 2007.
HPSG parsing with shallow dependency constraints.
In Annual Meeting of Association for Computational
Linguistics, pages 624–631.
Jasmin ˇSari´c, Lars J. Jensen, Rossitza Ouzounova, Isabel
Rojas, and Peer Bork. 2004. Extracting regulatory
gene expression networks from pubmed. In ACL ’04:
Proceedings of the 42nd Annual Meeting on Associa-
tion for Computational Linguistics, page 191, Morris-
town, NJ, USA. Association for Computational Lin-
guistics.
Joachim Wermter, Katrin Tomanek, and Udo Hahn.
2009. High-performance gene name normalization
with GeNo. Bioinformatics, 25(6):815–821.
Hui Yang, Goran Nenadic, and John Keane. 2008. Iden-
tification of transcription factor contexts in literature
using machine learning approaches. BMC Bioinfor-
matics, 9(Supplement 3: S11).
</reference>
<page confidence="0.99939">
45
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.179796">
<title confidence="0.9949825">How Feasible and Robust is the Automatic Extraction of Gene Events ? A Cross-Method Evaluation under Lab and Real-Life Conditions</title>
<author confidence="0.982247">Dietrich</author>
<affiliation confidence="0.997405">University Language &amp; Information Engineering</affiliation>
<address confidence="0.579613">Friedrich-Schiller-Universit¨at Jena, Germany</address>
<author confidence="0.300249">Wellcome Trust Genome Campus</author>
<author confidence="0.300249">Cambridge Hinxton</author>
<abstract confidence="0.99684619047619">We explore a rule system and a machine learning (ML) approach to automatically harvest information on gene regulation events (GREs) from biological documents in two different evaluation scenarios – one uses self-supplied corpora in a clean lab setting, while the other incorporates a standard reference database of GREs from real-life data generated independently from our work. In the lab condition, we test how feasible the automatic extraction of GREs really is and achieve F-scores, under different, not directly comparable test conditions though, for the rule and the ML systems which amount 34% and 44%, respectively. In the condition, we investigate how robust both methodologies are by comparing them with this routinely used database. Here, the best F-scores for the rule and the ML systems amount to 34% and 19%, respectively.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ekaterina Buyko</author>
<author>Elena Beisswanger</author>
<author>Udo Hahn</author>
</authors>
<title>Testing different ACE-style feature sets for the extraction of gene regulation relations from MEDLINE abstracts.</title>
<date>2008</date>
<booktitle>In Proceedings of the 3rd International Symposium on Semantic Mining in Biomedicine (SMBM</booktitle>
<pages>21--28</pages>
<contexts>
<context position="12630" citStr="Buyko et al. (2008)" startWordPosition="1912" endWordPosition="1915">ssfully mapped mentions are kept. We utilized GENO in its original version, i.e., without special adjustments to the E. coli organism. However, only those mentions detected to be genes of E. coli were fed into the relation extraction component. 4These tasks were performed with the OPENNLP tools (http://opennlp.sourceforge.net/) and the MST parser (http://sourceforge.net/projects/ mstparser), both retrained on biomedical corpora. 5http://www.uniprot.de 39 Relation Identification. The ML-based approach to GRE employs Maximum Entropy models and constitutes and extension of the system proposed by Buyko et al. (2008) as it also makes use of dependency parse information including dependency tree level features (Katrenko and Adriaans, 2006) and shortest dependency path features (Kim et al., 2008). In short, the feature set consists of: • word features (covering words before, after and between both entity mentions); • entity features (accounting for combinations of entity types, flags indicating whether mentions have an overlap, and their mention level); • chunking and constituency-based parsing features (concerned with head words of the phrases between two entity mentions; this class of features exploits co</context>
<context position="16984" citStr="Buyko et al., 2008" startWordPosition="2587" endWordPosition="2590">f 39 events (49.4% precision), polarity of 46 events (58.2% precision), and directness of 51 events (64.6% precision). Note that the system employed a fully automatic module for named entity recognition. The event type recognition is impaired, because it often fails to recognize 6The resultant annotated corpora are available at http:// www.ebi.ac.uk/˜kim/eventannotation/. 40 the specific event type of transcription regulation, but only identifies the general event type of gene expression regulation due to the lack of identified evidence. 4.2 ML-based system GeneReg corpus. The GENEREG corpus (Buyko et al., 2008) constitutes a selection of 314 MEDLINE abstracts related to gene regulation in E. coli. These abstracts were randomly drawn from a set of 32,155 selected by MESH term queries from MEDLINE using keywords such as Escherichia coli, Gene Expression and Transcription Factors. These 314 abstracts were manually annotated for named entities involved in gene regulatory processes (such as transcription factor, including co-factors and regulators, and genes) and pairwise relations between transcription factors (TFs) and genes, as well as triggers (e.g., clue verbs) essential for the description of gene </context>
</contexts>
<marker>Buyko, Beisswanger, Hahn, 2008</marker>
<rawString>Ekaterina Buyko, Elena Beisswanger, and Udo Hahn. 2008. Testing different ACE-style feature sets for the extraction of gene regulation relations from MEDLINE abstracts. In Proceedings of the 3rd International Symposium on Semantic Mining in Biomedicine (SMBM 2008), pages 21–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francis Collins</author>
<author>Eric Green</author>
<author>Alan Guttmacher</author>
<author>Mark Guyer</author>
</authors>
<title>A vision for the future of genomics research.</title>
<date>2003</date>
<journal>Nature,</journal>
<volume>422</volume>
<issue>6934</issue>
<pages>835--847</pages>
<contexts>
<context position="3532" citStr="Collins et al. (2003)" startWordPosition="527" endWordPosition="530">molecular biologists since they require large-scale data with high coverage and reliability. For our analysis, we have chosen the topic of gene regulatory events in E. coli, which is a domain of very active research and grand challenges.2 Currently the gold standard of the existing body of knowledge of such events is represented by the fact database REGULONDB.3 Its content has been man2The field of gene regulation is one of the most prominent topics of research and often mentioned as one of the core fields of future research in molecular biology (cf, e.g., the Grand Challenge I-2 described by Collins et al. (2003)). 3http://regulondb.ccg.unam.mx/ Proceedings of the Workshop on BioNLP, pages 37–45, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics ually gathered from the scientific literature and describes the curated computational model of mechanisms of transcriptional regulation in E. coli. Having this gold standard in mind, we face the challenging task to automatically reproduce this content from the available literature, to enhance this content with reliable additional information and to update this resource as part of a regular automatic routine. Hence, we first explore</context>
</contexts>
<marker>Collins, Green, Guttmacher, Guyer, 2003</marker>
<rawString>Francis Collins, Eric Green, Alan Guttmacher, and Mark Guyer. 2003. A vision for the future of genomics research. Nature, 422(6934 (24 Feb)):835–847.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Hatzivassiloglou</author>
<author>Wubin Weng</author>
</authors>
<title>Learning anchor verbs for biological interaction patterns from published text articles.</title>
<date>2002</date>
<journal>International Journal of Medical Informatics,</journal>
<pages>67--19</pages>
<contexts>
<context position="10064" citStr="Hatzivassiloglou and Weng, 2002" startWordPosition="1534" endWordPosition="1537">tic structures of sentences in an input corpus by utilizing the ENJU parser (Sagae et al., 2007). The ENJU parser generates predicateargument structures, and the system converts them into dependency structures. The system then analyzes the semantics of the sentences by matching syntactic-semantic patterns to the dependency structures. We constructed 1,123 patterns for the event extraction according to the following workflow. We first collected keywords related to gene regulation, from GENE ONTOLOGY, INTERPRO, WORDNET, and several papers about information extraction from biomedical literature (Hatzivassiloglou and Weng, 2002; Kim and Park, 2004; Huang et al., 2004). Then we collected subcategorization frames for each keyword and created patterns for the frames manually. Each pattern consists of a syntactic pattern and a semantic pattern. The syntactic patterns comply with dependency structures. The system tries to match the syntactic patterns to the dependency structures of sentences in a bottom-up way, considering syntactic and semantic restrictions of syntactic patterns. Once a syntactic pattern is successfully matched to a sub-tree of the available dependency structure, its corresponding semantic pattern is as</context>
</contexts>
<marker>Hatzivassiloglou, Weng, 2002</marker>
<rawString>Vasileios Hatzivassiloglou and Wubin Weng. 2002. Learning anchor verbs for biological interaction patterns from published text articles. International Journal of Medical Informatics, 67:19–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minlie Huang</author>
<author>Xiaoyan Zhu</author>
<author>Donald G Payan</author>
<author>Kunbin Qu</author>
<author>Ming Li</author>
</authors>
<title>Discovering patterns to extract protein-protein interactions from full texts.</title>
<date>2004</date>
<journal>Bioinformatics,</journal>
<volume>20</volume>
<issue>18</issue>
<contexts>
<context position="10105" citStr="Huang et al., 2004" startWordPosition="1542" endWordPosition="1545">lizing the ENJU parser (Sagae et al., 2007). The ENJU parser generates predicateargument structures, and the system converts them into dependency structures. The system then analyzes the semantics of the sentences by matching syntactic-semantic patterns to the dependency structures. We constructed 1,123 patterns for the event extraction according to the following workflow. We first collected keywords related to gene regulation, from GENE ONTOLOGY, INTERPRO, WORDNET, and several papers about information extraction from biomedical literature (Hatzivassiloglou and Weng, 2002; Kim and Park, 2004; Huang et al., 2004). Then we collected subcategorization frames for each keyword and created patterns for the frames manually. Each pattern consists of a syntactic pattern and a semantic pattern. The syntactic patterns comply with dependency structures. The system tries to match the syntactic patterns to the dependency structures of sentences in a bottom-up way, considering syntactic and semantic restrictions of syntactic patterns. Once a syntactic pattern is successfully matched to a sub-tree of the available dependency structure, its corresponding semantic pattern is assigned to the sub-tree as one of its sema</context>
</contexts>
<marker>Huang, Zhu, Payan, Qu, Li, 2004</marker>
<rawString>Minlie Huang, Xiaoyan Zhu, Donald G. Payan, Kunbin Qu, and Ming Li. 2004. Discovering patterns to extract protein-protein interactions from full texts. Bioinformatics, 20(18):3604–3612.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sophia Katrenko</author>
<author>P Adriaans</author>
</authors>
<title>Learning relations from biomedical corpora using dependency trees.</title>
<date>2006</date>
<booktitle>In KDECB 2006 – Knowledge Discovery and Emergent Complexity in Bioinformatics,</booktitle>
<pages>61--80</pages>
<contexts>
<context position="12754" citStr="Katrenko and Adriaans, 2006" startWordPosition="1931" endWordPosition="1934">e E. coli organism. However, only those mentions detected to be genes of E. coli were fed into the relation extraction component. 4These tasks were performed with the OPENNLP tools (http://opennlp.sourceforge.net/) and the MST parser (http://sourceforge.net/projects/ mstparser), both retrained on biomedical corpora. 5http://www.uniprot.de 39 Relation Identification. The ML-based approach to GRE employs Maximum Entropy models and constitutes and extension of the system proposed by Buyko et al. (2008) as it also makes use of dependency parse information including dependency tree level features (Katrenko and Adriaans, 2006) and shortest dependency path features (Kim et al., 2008). In short, the feature set consists of: • word features (covering words before, after and between both entity mentions); • entity features (accounting for combinations of entity types, flags indicating whether mentions have an overlap, and their mention level); • chunking and constituency-based parsing features (concerned with head words of the phrases between two entity mentions; this class of features exploits constituency-based parsing as well and indicates, e.g., whether mentions are in the same NP, PP or VP); • dependency parse fea</context>
</contexts>
<marker>Katrenko, Adriaans, 2006</marker>
<rawString>Sophia Katrenko and P. Adriaans. 2006. Learning relations from biomedical corpora using dependency trees. In KDECB 2006 – Knowledge Discovery and Emergent Complexity in Bioinformatics, pages 61–80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jung-jae Kim</author>
<author>Jong C Park</author>
</authors>
<title>BioIE: retargetable information extraction and ontological annotation of biological interactions from the literature.</title>
<date>2004</date>
<journal>Journal of Bioinformatics and Computational Biology,</journal>
<volume>2</volume>
<issue>3</issue>
<contexts>
<context position="10084" citStr="Kim and Park, 2004" startWordPosition="1538" endWordPosition="1541"> input corpus by utilizing the ENJU parser (Sagae et al., 2007). The ENJU parser generates predicateargument structures, and the system converts them into dependency structures. The system then analyzes the semantics of the sentences by matching syntactic-semantic patterns to the dependency structures. We constructed 1,123 patterns for the event extraction according to the following workflow. We first collected keywords related to gene regulation, from GENE ONTOLOGY, INTERPRO, WORDNET, and several papers about information extraction from biomedical literature (Hatzivassiloglou and Weng, 2002; Kim and Park, 2004; Huang et al., 2004). Then we collected subcategorization frames for each keyword and created patterns for the frames manually. Each pattern consists of a syntactic pattern and a semantic pattern. The syntactic patterns comply with dependency structures. The system tries to match the syntactic patterns to the dependency structures of sentences in a bottom-up way, considering syntactic and semantic restrictions of syntactic patterns. Once a syntactic pattern is successfully matched to a sub-tree of the available dependency structure, its corresponding semantic pattern is assigned to the sub-tr</context>
</contexts>
<marker>Kim, Park, 2004</marker>
<rawString>Jung-jae Kim and Jong C. Park. 2004. BioIE: retargetable information extraction and ontological annotation of biological interactions from the literature. Journal of Bioinformatics and Computational Biology, 2(3):551–568.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seon-Ho Kim</author>
<author>Juntae Yoon</author>
<author>Jihoon Yang</author>
</authors>
<title>Kernel approaches for genic interaction extraction.</title>
<date>2008</date>
<journal>Bioinformatics,</journal>
<volume>24</volume>
<issue>1</issue>
<contexts>
<context position="12811" citStr="Kim et al., 2008" startWordPosition="1940" endWordPosition="1943">s of E. coli were fed into the relation extraction component. 4These tasks were performed with the OPENNLP tools (http://opennlp.sourceforge.net/) and the MST parser (http://sourceforge.net/projects/ mstparser), both retrained on biomedical corpora. 5http://www.uniprot.de 39 Relation Identification. The ML-based approach to GRE employs Maximum Entropy models and constitutes and extension of the system proposed by Buyko et al. (2008) as it also makes use of dependency parse information including dependency tree level features (Katrenko and Adriaans, 2006) and shortest dependency path features (Kim et al., 2008). In short, the feature set consists of: • word features (covering words before, after and between both entity mentions); • entity features (accounting for combinations of entity types, flags indicating whether mentions have an overlap, and their mention level); • chunking and constituency-based parsing features (concerned with head words of the phrases between two entity mentions; this class of features exploits constituency-based parsing as well and indicates, e.g., whether mentions are in the same NP, PP or VP); • dependency parse features (analyzing both the dependency levels of the argume</context>
</contexts>
<marker>Kim, Yoon, Yang, 2008</marker>
<rawString>Seon-Ho Kim, Juntae Yoon, and Jihoon Yang. 2008. Kernel approaches for genic interaction extraction. Bioinformatics, 24(1):118–126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire N´edellec</author>
</authors>
<title>Learning language in logic -genic interaction extraction challenge. In Learning language in logic - genic interaction extraction LLL’</title>
<date>2005</date>
<pages>31--37</pages>
<marker>N´edellec, 2005</marker>
<rawString>Claire N´edellec. 2005. Learning language in logic -genic interaction extraction challenge. In Learning language in logic - genic interaction extraction LLL’ 2005, pages 31–37.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sampo Pyysalo</author>
<author>Antti Airola</author>
<author>Juho Heimonen</author>
<author>Jari Bj¨orne</author>
<author>Filip Ginter</author>
<author>Tapio Salakoski</author>
</authors>
<title>Comparative analysis of five protein-protein interaction corpora.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<volume>9</volume>
<issue>3</issue>
<marker>Pyysalo, Airola, Heimonen, Bj¨orne, Ginter, Salakoski, 2008</marker>
<rawString>Sampo Pyysalo, Antti Airola, Juho Heimonen, Jari Bj¨orne, Filip Ginter, and Tapio Salakoski. 2008. Comparative analysis of five protein-protein interaction corpora. BMC Bioinformatics, 9(3), April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlos Rodr´ıguez-Penagos</author>
<author>Heladia Salgado</author>
<author>Irma Martinez-Flores</author>
<author>Julio Collado-Vides</author>
</authors>
<title>Automatic reconstruction of a bacterial regulatory network using natural language processing.</title>
<date>2007</date>
<journal>BMC Bioinformatics,</journal>
<volume>8</volume>
<issue>293</issue>
<marker>Rodr´ıguez-Penagos, Salgado, Martinez-Flores, Collado-Vides, 2007</marker>
<rawString>Carlos Rodr´ıguez-Penagos, Heladia Salgado, Irma Martinez-Flores, and Julio Collado-Vides. 2007. Automatic reconstruction of a bacterial regulatory network using natural language processing. BMC Bioinformatics, 8(293).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Sagae</author>
<author>Yusuke Miyao</author>
<author>Junichi Tsujii</author>
</authors>
<title>HPSG parsing with shallow dependency constraints.</title>
<date>2007</date>
<booktitle>In Annual Meeting of Association for Computational Linguistics,</booktitle>
<pages>624--631</pages>
<contexts>
<context position="9529" citStr="Sagae et al., 2007" startWordPosition="1461" endWordPosition="1464">olled by a shared promoter and which thus express together. We have mapped the operon names to corresponding gene sets. Named entity recognition relies on the use of dictionaries. If the system recognizes an operon name, it then associates the operon with its genes. The system further recognizes multi-gene object names (e.g., “acrAB”), divides them into individual gene names (e.g., “acrA”, “acrB”) and associates the gene names with the multi-gene object names. Relation Identification. The system then identifies syntactic structures of sentences in an input corpus by utilizing the ENJU parser (Sagae et al., 2007). The ENJU parser generates predicateargument structures, and the system converts them into dependency structures. The system then analyzes the semantics of the sentences by matching syntactic-semantic patterns to the dependency structures. We constructed 1,123 patterns for the event extraction according to the following workflow. We first collected keywords related to gene regulation, from GENE ONTOLOGY, INTERPRO, WORDNET, and several papers about information extraction from biomedical literature (Hatzivassiloglou and Weng, 2002; Kim and Park, 2004; Huang et al., 2004). Then we collected subc</context>
</contexts>
<marker>Sagae, Miyao, Tsujii, 2007</marker>
<rawString>Kenji Sagae, Yusuke Miyao, and Junichi Tsujii. 2007. HPSG parsing with shallow dependency constraints. In Annual Meeting of Association for Computational Linguistics, pages 624–631.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jasmin ˇSari´c</author>
<author>Lars J Jensen</author>
<author>Rossitza Ouzounova</author>
<author>Isabel Rojas</author>
<author>Peer Bork</author>
</authors>
<title>Extracting regulatory gene expression networks from pubmed.</title>
<date>2004</date>
<booktitle>In ACL ’04: Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>191</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<marker>ˇSari´c, Jensen, Ouzounova, Rojas, Bork, 2004</marker>
<rawString>Jasmin ˇSari´c, Lars J. Jensen, Rossitza Ouzounova, Isabel Rojas, and Peer Bork. 2004. Extracting regulatory gene expression networks from pubmed. In ACL ’04: Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, page 191, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joachim Wermter</author>
<author>Katrin Tomanek</author>
<author>Udo Hahn</author>
</authors>
<title>High-performance gene name normalization with GeNo.</title>
<date>2009</date>
<journal>Bioinformatics,</journal>
<volume>25</volume>
<issue>6</issue>
<contexts>
<context position="11644" citStr="Wermter et al., 2009" startWordPosition="1770" endWordPosition="1773">created 28 inference rules that reflect the knowledge of the gene regulation domain. Only relations where the identified agent is one of those known TFs are kept, while all others are discarded. 3.2 Generic, ML-based Extraction Apart from the already mentioned clerical preprocessing steps, the ML-based extraction of GREs requires several additional syntactic processing steps including POS-tagging, chunking, and full dependency- and constituency-based parsing.4 Entity Identification. To identify gene names in the documents, we applied GENO, a multi-organism gene name recognizer and normalizer (Wermter et al., 2009) which achieved a top-rank performance of 86.4% on the gene normalization task of BIOCREATIVE-II. GENO recognizes gene mentions by means of an ML-based named entity tagger trained on publicly available corpora. Subsequently, it attempts to map all identified mentions to organism-specific UNIPROT5 identifiers. Mentions that cannot be mapped are discarded; only successfully mapped mentions are kept. We utilized GENO in its original version, i.e., without special adjustments to the E. coli organism. However, only those mentions detected to be genes of E. coli were fed into the relation extraction</context>
</contexts>
<marker>Wermter, Tomanek, Hahn, 2009</marker>
<rawString>Joachim Wermter, Katrin Tomanek, and Udo Hahn. 2009. High-performance gene name normalization with GeNo. Bioinformatics, 25(6):815–821.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hui Yang</author>
<author>Goran Nenadic</author>
<author>John Keane</author>
</authors>
<title>Identification of transcription factor contexts in literature using machine learning approaches.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<volume>9</volume>
<pages>11</pages>
<contexts>
<context position="4968" citStr="Yang et al. (2008)" startWordPosition="742" endWordPosition="745">to different experimental settings, is not meant as a comparison between both approaches though. We then move to the even more demanding real-life scenario where we evaluate and compare these solutions for the identification of gene regulatory events against the REGULONDB data resource. This approach targets the robustness of the proposed text mining solutions from the perspectives of completeness, correctness and novelty of the generated results. 2 Related Work Considering relation extraction (RE) in the biomedical domain, there are only few studies which deal primarily with gene regulation. Yang et al. (2008) focus on the detection of sentences that contain mentions of transcription factors (proteins regulating gene expression). They aim at the detection of new transcription factors, while relations are not taken into account. In contrast, ˇSari´c et al. (2004) extract gene regulatory networks and achieve in the RE task an accuracy of up to 90%. They disregard, however, ambiguous instances, which may have led to the low recall around 20%. The Genic Interaction Extraction Challenge (N´edellec, 2005) was organized to determine the state-of-the-art performance of systems designed for the detection of</context>
</contexts>
<marker>Yang, Nenadic, Keane, 2008</marker>
<rawString>Hui Yang, Goran Nenadic, and John Keane. 2008. Identification of transcription factor contexts in literature using machine learning approaches. BMC Bioinformatics, 9(Supplement 3: S11).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>