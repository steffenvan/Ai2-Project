<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001557">
<title confidence="0.994512">
Unsupervised Constraint Driven Learning For Transliteration Discovery
</title>
<author confidence="0.99645">
Ming-Wei Chang Dan Goldwasser Dan Roth Yuancheng Tu
</author>
<affiliation confidence="0.998967">
University of Illinois at Urbana Champaign
</affiliation>
<address confidence="0.79532">
Urbana, IL 61801
</address>
<email confidence="0.998903">
{mchang21,goldwas1,danr,ytu}@uiuc.edu
</email>
<sectionHeader confidence="0.998599" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9996220625">
This paper introduces a novel unsupervised
constraint-driven learning algorithm for iden-
tifying named-entity (NE) transliterations in
bilingual corpora. The proposed method does
not require any annotated data or aligned cor-
pora. Instead, it is bootstrapped using a simple
resource – a romanization table. We show that
this resource, when used in conjunction with
constraints, can efficiently identify translitera-
tion pairs. We evaluate the proposed method
on transliterating English NEs to three differ-
ent languages - Chinese, Russian and Hebrew.
Our experiments show that constraint driven
learning can significantly outperform existing
unsupervised models and achieve competitive
results to existing supervised models.
</bodyText>
<sectionHeader confidence="0.999514" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999794111111111">
Named entity (NE) transliteration is the process of
transcribing a NE from a source language to some
target language while preserving its pronunciation in
the original language. Automatic NE transliteration
is an important component in many cross-language
applications, such as Cross-Lingual Information Re-
trieval (CLIR) and Machine Translation(MT) (Her-
mjakob et al., 2008; Klementiev and Roth, 2006a;
Meng et al., 2001; Knight and Graehl, 1998).
It might initially seem that transliteration is an
easy task, requiring only finding a phonetic mapping
between character sets. However simply matching
every source language character to its target lan-
guage counterpart is not likely to work well as in
practice this mapping depends on the context the
characters appear in and on transliteration conven-
tions which may change across domains. As a result,
current approaches employ machine learning meth-
ods which, given enough labeled training data learn
how to determine whether a pair of words consti-
tute a transliteration pair. These methods typically
require training data and language-specific expertise
which may not exist for many languages. In this pa-
per we try to overcome these difficulties and show
that when the problem is modeled correctly, a sim-
ple character level mapping is a sufficient resource.
In our experiments, English was used as the
source language, allowing us to use romanization ta-
bles, a resource commonly-available for many lan-
guages1. These tables contain an incomplete map-
ping between character sets, mapping every charac-
ter to its most common counterpart.
Our transliteration model takes a discriminative
approach. Given a word pair, the model determines
if one word is a transliteration of the other. The
features used by this model are character n-gram
matches across the two strings. For example, Fig-
ure 1 describes the decomposition of a word pair into
unigram features as a bipartite graph in which each
edge represents an active feature.
We enhance the initial model with constraints, by
framing the feature extraction process as a struc-
tured prediction problem - given a word pair, the set
of possible active features is defined as a set of latent
binary variables. The contextual dependency be-
</bodyText>
<footnote confidence="0.9915785">
1The romanization tables available at the Library of
Congress website (http://www.loc.gov/catdir/cpso/roman.html)
cover more than 150 languages written in various non-Roman
scripts
</footnote>
<page confidence="0.943535">
299
</page>
<note confidence="0.929028">
Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 299–307,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<figureCaption confidence="0.838215333333333">
Figure 1: Top: The space of all possible features that can be
generated given the word pair. Bottom: A pruned features rep-
resentation generated by the inference process.
</figureCaption>
<bodyText confidence="0.999841">
tween features is encoded as a set of constraints over
these variables. Features are extracted by finding
an assignment that maximizes the similarity score
between the two strings and conforms to the con-
straints. The model is bootstrapped using a roman-
ization table and uses a discriminatively self-trained
classifier as a way to improve over several training
iterations. Furthermore, when specific knowledge
about the source and target languages exists, it can
be directly injected into the model as constraints.
We tested our approach on three very differ-
ent languages - Russian, a Slavic language, He-
brew a Semitic language, and Chinese, a Sino-
Tibetan language. In all languages, using this sim-
ple resource in conjunction with constraints pro-
vided us with a robust transliteration system which
significantly outperforms existing unsupervised ap-
proaches and achieves comparable performance to
supervised methods.
The rest of the paper is organized as follows.
Sec. 2 briefly examines more related work. Sec. 3
explains our model and Sec. 4 provide a linguistic
intuition for it. Sec. 5 describes our experiments and
evaluates our results followed by sec. 6 which con-
cludes our paper.
</bodyText>
<sectionHeader confidence="0.999634" genericHeader="introduction">
2 Related Works
</sectionHeader>
<bodyText confidence="0.999931910714286">
Transliteration methods typically fall into two cate-
gories: generative approaches (Li et al., 2004; Jung
et al., 2000; Knight and Graehl, 1998) that try to
produce the target transliteration given a source lan-
guage NE, and discriminative approaches (Gold-
wasser and Roth, 2008b; Bergsma and Kondrak,
2007; Sproat et al., 2006; Klementiev and Roth,
2006a), that try to identify the correct translitera-
tion for a word in the source language given several
candidates in the target language. Generative meth-
ods encounter the Out-Of-Vocabulary (OOV) prob-
lem and require substantial amounts of training data
and knowledge of the source and target languages.
Discriminative approaches, when used to for dis-
covering NE in a bilingual corpora avoid the OOV
problem by choosing the transliteration candidates
from the corpora. These methods typically make
very little assumptions about the source and target
languages and require considerably less data to con-
verge. Training the transliteration model is typi-
cally done under supervised settings (Bergsma and
Kondrak, 2007; Goldwasser and Roth, 2008b), or
weakly supervised settings with additional tempo-
ral information (Sproat et al., 2006; Klementiev and
Roth, 2006a). Our work differs from these works
in that it is completely unsupervised and makes no
assumptions about the training data.
Incorporating knowledge encoded as constraints
into learning problems has attracted a lot of atten-
tion in the NLP community recently. This has been
shown both in supervised settings (Roth and Yih,
2004; Riedel and Clarke, 2006) and unsupervised
settings (Haghighi and Klein, 2006; Chang et al.,
2007) in which constraints are used to bootstrap the
model. (Chang et al., 2007) describes an unsuper-
vised training of a Constrained Conditional Model
(CCM), a general framework for combining statisti-
cal models with declarative constraints. We extend
this work to include constraints over possible assign-
ments to latent variables which, in turn, define the
underlying representation for the learning problem.
In the transliteration community there are sev-
eral works (Ristad and Yianilos, 1998; Bergsma and
Kondrak, 2007; Goldwasser and Roth, 2008b) that
show how the feature representation of a word pair
can be restricted to facilitate learning a string sim-
ilarity model. We follow the approach discussed
in (Goldwasser and Roth, 2008b), which considers
the feature representation as a structured prediction
problem and finds the set of optimal assignments (or
feature activations), under a set of legitimacy con-
straints. This approach stresses the importance of
interaction between learning and inference, as the
model iteratively uses inference to improve the sam-
ple representation for the learning problem and uses
the learned model to improve the accuracy of the in-
</bodyText>
<page confidence="0.994972">
300
</page>
<bodyText confidence="0.997525">
ference process. We adapt this approach to unsu-
pervised settings, where iterating over the data im-
proves the model in both of these dimensions.
</bodyText>
<sectionHeader confidence="0.99731" genericHeader="method">
3 Unsupervised Constraint Driven
</sectionHeader>
<subsectionHeader confidence="0.97109">
Learning
</subsectionHeader>
<bodyText confidence="0.999389754716981">
In this section we present our Unsupervised Con-
straint Driven Learning (UCDL) model for discov-
ering transliteration pairs. Our task is in essence a
ranking task. Given a NE in the source language and
a list of candidate transliterations in the target lan-
guage, the model is supposed to rank the candidates
and output the one with the highest score. The model
is bootstrapped using two linguistic resources: a ro-
manization table and a set of general and linguistic
constraints. We use several iterations of self training
to learn the model. The details of the procedure are
explained in Algorithm 1.
In our model features are character pairs (cs, ct),
where cs E Cs is a source word character and
ct E Ct is a target word character. The feature
representation of a word pair vs, vt is denoted by
F(vs, vt). Each feature (cs, ct) is assigned a weight
W (cs, ct) E R. In step 1 of the algorithm we initial-
ize the weights vector using the romanization table.
Given a pair (vs, vt), a feature extraction process
is used to determine the feature based representation
of the pair. Once features are extracted to represent
a pair, the sum of the weights of the extracted fea-
tures is the score assigned to the target translitera-
tion candidate. Unlike traditional feature extraction
approaches, our feature representation function does
not produce a fixed feature representation. In step
2.1, we formalize the feature extraction process as a
constrained optimization problem that captures the
interdependencies between the features used to rep-
resent the sample. That is, obtaining F(vs, vt) re-
quires solving an optimization problem. The techni-
cal details are described in Sec. 3.1. The constraints
we use are described in Sec. 3.2.
In step 2.2 the different candidates for every
source NE are ranked according to the similarity
score associated with their chosen representation.
This ranking is used to ”label” examples for a dis-
criminative learning process that learns increasingly
better weights, and thus improve the representation
of the pair: each source NE paired with its top
ranked transliteration is labeled as a positive exam-
ples (step 2.3) and the rest of the samples are consid-
ered as negative samples. In order to focus the learn-
ing process, we removed from the training set all
negative examples ruled-out by the constraints (step
2.4). As the learning process progresses, the initial
weights are replaced by weights which are discrimi-
natively learned (step 2.5). This process is repeated
several times until the model converges, and repeats
the same ranking over several iterations.
Input: Romanization table T : Cs → Ct, Constraints
C, Source NEs: Vs, Target words: Vt
</bodyText>
<sectionHeader confidence="0.876627" genericHeader="method">
1. Initialize Model
</sectionHeader>
<bodyText confidence="0.712665">
Let W : Cs x Ct → R be a weight vector.
Initialize W using T by the following procedure
</bodyText>
<equation confidence="0.989186666666667">
V(cs, ct), (cs, ct) E T W(cs, ct) = 0,
V(cs,ct),-((cs,ct) E T) W(cs,ct) = −1,
Vcs, W(cs, ) = −1, Vct, W( , ct) = −1.
</equation>
<listItem confidence="0.983395571428571">
2. Constraints driven unsupervised training
while not converged do
1. Vvs E Vs, vt E Vt, use C and W
to generate a representation F(vs, vt)
2. Vvs E Vs, find the top ranking transliteration
pair (vs, vt ) by solving
vt = arg maxv� score(F(vs, vt)).
3. D = {(+, F(vs, vt*))  |Vvs E Vs}.
4. Vvs E Vs, vt E Vt, if vt =� vt and
score(F(vs, vt)) =� −oo, then
D = D U {(−, F(vs, vt))}.
5. W +— train(D)
end
Algorithm 1: UCDL Transliteration Framework.
</listItem>
<bodyText confidence="0.9998926">
In the rest of this section we explain this process
in detail. We define the feature extraction inference
process in Sec. 3.1, the constraints used in Sec. 3.2
and the inference algorithm in Sec. 3.3. The linguis-
tic intuition for our model is described in Sec. 4.
</bodyText>
<subsectionHeader confidence="0.999124">
3.1 Finding Feature Representation as
Constrained Optimization
</subsectionHeader>
<bodyText confidence="0.999860333333333">
We use the formulation of Constrainted Conditional
Models (CCMs) (Roth and Yih, 2004; Roth and Yih,
2007; Chang et al., 2008). Previous work on CCM
models dependencies between different decisions in
structured prediction problems. Transliteration dis-
covery is a binary classification problem, however,
</bodyText>
<page confidence="0.994032">
301
</page>
<bodyText confidence="0.980057075">
the underlying representation of each sample can be
modeled as a CCM, defined as a set of latent vari-
ables corresponding to the set of all possible features
for a given sample. The dependencies between the
features are captured using constraints.
Given a word pair, the set of all possible features
consists of all character mappings from the source
word to the target word. Since in many cases the
size of the words differ we augment each of the
words with a blank character (denoted as ’ ’). We
model character omission by mapping the character
to the blank character. This process is formally de-
fined as an operator mapping a transliteration can-
didate pair to a set of binary variables, denoted as
All-Features (AF).
AF = {(cs, ct)|cs ∈ vs ∪ { }, ct ∈ vt ∪ { }}
This representation is depicted at the top of Figure 1.
The initial sample representation (AF) gener-
ates features by coupling substrings from the two
terms without considering the dependencies be-
tween the possible combinations. This representa-
tion is clearly noisy and in order to improve it we
select a subset F ⊂ AF of the possible features.
The selection process is formulated as a linear op-
timization problem over binary variables encoding
feature activations in AF. Variables assigned 1 are
selected to be in F, and those assigned 0 are not.
The objective function maximized is a linear func-
tion over the variables in AF, each with its weight as
a coefficient, as in the left part of Equation 1 below.
We seek to maximize this linear sum subject to a set
of constraints. These represent the dependencies be-
tween selections and prior knowledge about possible
legitimate character mappings and correspond to the
right side of Equation 1. In our settings only hard
constraints are used and therefore the penalty (p) for
violating any of the constraints is set to ∞. The spe-
cific constraints used are discussed in Sec. 3.2. The
score of the mapping F(vs, vt) can be written as fol-
lows:
</bodyText>
<equation confidence="0.777249">
1 |vt|(W · F(vs, vt) − ciEC pci(F(vs,vt)) (1)
</equation>
<bodyText confidence="0.999783333333333">
We normalize this score by dividing it by the size of
the target word, since the size of candidates varies,
normalization improved the ranking of candidates.
The result of the optimization process is a set F of
active features, defined in Equation 2. The result of
this process is described at the bottom of Figure 1.
</bodyText>
<equation confidence="0.528651">
F*(vs,vt) = arg maxFCAF(vs,vt)score(F). (2)
</equation>
<bodyText confidence="0.9949444">
The ranking process done by our model can now be
naturally defined - given a source word vs, and a
set of candidates target words v° , ... , vnt , find the
candidate whose optimal representation maximizes
Equation 1. This process is defined in Equation 3.
</bodyText>
<equation confidence="0.549206333333333">
vt = arg max score(F(vs, vit)). (3)
vi
t
</equation>
<subsectionHeader confidence="0.992959">
3.2 Incorporating Mapping Constraints
</subsectionHeader>
<bodyText confidence="0.999960071428571">
We consider two types of constraints: language spe-
cific and general constraints that apply to all lan-
guages. Language specific constraints typically im-
pose a local restriction such as individually forcing
some of the possible character mapping decisions.
The linguistic intuition behind these constraints is
discussed in Section 4. General constraints encode
global restrictions, capturing the dependencies be-
tween different mapping decisions.
General constraints: To facilitate readability we
denote the feature mapping the i-th source word
character to the j-th target word character as a
Boolean variable aij that is 1 if that feature is active
and 0 otherwise.
</bodyText>
<listItem confidence="0.971329833333333">
• Coverage - Every character must be mapped
only to a single character or to the blank char-
acter. We can formulate this as: Ej aij = 1
and Ei aij = 1.
• No Crossing - Every character mapping, except
mapping to blank character, should preserve the
order of appearance in the source and target
words, or formally - ∀i, j s.t. aij = 1 ⇒ ∀l &lt;
i, ∀k &gt; j, alk = 0. Another constraint is ∀i, j
s.t. aij = 1 ⇒ ∀l &gt; i, ∀k &lt; j, alk = 0.
Language specific constraints
• Restricted Mapping: These constraints restrict
the possible local mappings between source
and target language characters. We maintain a
set of possible mappings {cs → Ocs}, where
Ocs ⊆ Ct and {ct → Oct}, where Oct ⊆ Cs.
Any feature (cs, ct) such that cs ∈� Oct or
ct ∈� Ocs is penalized in our model.
</listItem>
<page confidence="0.848694">
302
</page>
<listItem confidence="0.8603662">
• Length restriction: An additional constraint
restricts the size difference between the two
words. We formulate this as follows: bvs E
Vs, bvt E Vt, if -y|vt |&gt; |vs |and -y|vs |&gt; |vt|,
score(F(vs, vt)) _ −oc. Although -y can
</listItem>
<bodyText confidence="0.839763625">
take different values for different languages, we
simply set -y to 2 in this paper.
In addition to biasing the model to choose the
right candidate, the constraints also provide a com-
putational advantage: a given a word pair is elimi-
nated from consideration when the length restriction
is not satisfied or there is no way to satisfy the re-
stricted mapping constraints.
</bodyText>
<subsectionHeader confidence="0.855438">
3.3 Inference
</subsectionHeader>
<bodyText confidence="0.999948235294118">
The optimization problem defined in Equation 2 is
an integer linear program (ILP). However, given
the structure of the problem it is possible to de-
velop an efficient dynamic programming algorithm
for it, based on the algorithm for finding the mini-
mal edit distance of two strings. The complexity of
finding the optimal set of features is only quadratic
in the size of the input pair, a clear improvement
over the ILP exponential time algorithm. The al-
gorithm minimizes the weighted edit distance be-
tween the strings, and produces a character align-
ment that satisfies the general constraints (Sec. 3.2).
Our modifications are only concerned with incorpo-
rating the language-specific constraints into the al-
gorithm. This can be done simply by assigning a
negative infinity score to any alignment decision not
satisfying these constraints.
</bodyText>
<sectionHeader confidence="0.9797055" genericHeader="method">
4 Bootstrapping with Linguistic
Information
</sectionHeader>
<bodyText confidence="0.9997128">
Our model is bootstrapped using two resources - a
romanization table and mapping constraints. Both
resources capture the same information - character
mapping between languages. The distinction be-
tween the two represents the difference in the con-
fidence we have in these resources - the romaniza-
tion table is a noisy mapping covering the character
set and is therefore better suited as a feature. Con-
straints, represented by pervasive, correct character
mapping, indicate the sound mapping tendency be-
tween source and target languages. For example,
certain n-gram phonemic mappings, such as r —* l
from English to Chinese, are language specific and
can be captured by language specific sound change
patterns.
</bodyText>
<table confidence="0.998044181818182">
Phonemes Constraints
Vowel i → y; u → w; a → a
Nasal m ↔ m; m, n ← m
Approximant r → l; l, r ↔ l
l ← l; w → h, w, f
h, o, u, v ← w; y → y
Fricative v → w, b, f
s → s, x, z; s, c ← s
Plosive p → b, p; p ← p
b → b; t ← t
t, d ← d; q → k
</table>
<tableCaption confidence="0.97868375">
Table 1: All language specific constraints used in our English
to Chinese transliteration (see Sec. 3.2 for more details). Con-
straints in boldface apply to all positions, the rest apply only to
characters appearing in initial position.
</tableCaption>
<bodyText confidence="0.999864863636364">
These patterns have been used by other systems
as features or pseudofeatures (Yoon et al., 2007).
However, in our system these language specific rule-
of-thumbs are systematically used as constraints to
exclude impossible alignments and therefore gener-
ate better features for learning. We listed in Table 1
all 20 language specific constraints we used for Chi-
nese. There is a total of 24 constraints for Hebrew
and 17 for Russian.
The constraints in Table 1 indicate a systematic
sound mapping between English and Chinese un-
igram character mappings. Arranged by manners
of articulation each row of the table indicates the
sound change tendency among vowels, nasals, ap-
proximants (retroflex and glides), fricatives and plo-
sives. For example, voiceless plosive sounds such as
p, t in English, tend to map to both voiced (such as b,
d) and voiceless sounds in Chinese. However, if the
sound is voiceless in Chinese, its backtrack English
sound must be voiceless. This voice-voiceless sound
change tendency is captured by our constraints such
as p —* b,p and p +— p; t + —t.
</bodyText>
<sectionHeader confidence="0.997929" genericHeader="evaluation">
5 Experiments and Analysis
</sectionHeader>
<bodyText confidence="0.9998782">
In this section, we demonstrate the effectiveness
of constraint driven learning empirically. We start
by describing the datasets and experimental settings
and then proceed to describe the results. We eval-
uated our method on three very different target lan-
</bodyText>
<page confidence="0.997575">
303
</page>
<figure confidence="0.998947">
0 2 4 6 8 10 12 14 16 18 20
Number of Rounds
</figure>
<figureCaption confidence="0.997487428571429">
Figure 2: Comparison between our models and weakly su-
pervised learning methods (Klementiev and Roth, 2006b).
Note that one of the models proposed in (Klementiev and Roth,
2006b) takes advantage of the temporal information. Our best
model, the unsupervised learning with all constraints, outper-
forms both models in (Klementiev and Roth, 2006b), even
though we do not use any temporal information.
</figureCaption>
<bodyText confidence="0.957763">
guages: Russian, Chinese, and Hebrew, and com-
pared our results to previously published results.
</bodyText>
<subsectionHeader confidence="0.97664">
5.1 Experimental Settings
</subsectionHeader>
<bodyText confidence="0.999864545454546">
In our experiments the system is evaluated on its
ability to correctly identify the gold transliteration
for each source word. We evaluated the system’s
performance using two measures adopted in many
transliteration works. The first one is Mean Recip-
rocal Rank (MRR), used in (Tao et al., 2006; Sproat
et al., 2006), which is the average of the multiplica-
tive inverse of the rank of the correct answer. For-
mally, Let n be the number of source NEs. Let Gol-
dRank(i) be the rank the algorithm assigns to the
correct transliteration. Then, MRR is defined by:
</bodyText>
<equation confidence="0.992054666666667">
1 n 1
MRR =
n Z=1 goldRank(i)
</equation>
<bodyText confidence="0.9975036">
Another measure is Accuracy (ACC) used in (Kle-
mentiev and Roth, 2006a; Goldwasser and Roth,
2008a), which is the percentage of the top rank can-
didates being the gold transliteration. In our im-
plementation we used the support vector machine
(SVM) learning algorithm with linear kernel as our
underlying learning algorithm (mentioned in part
2.5 of Algorithm 1) . We used the package LIB-
LINEAR (Hsieh et al., 2008) in our experiments.
Through all of our experiments, we used the 2-norm
</bodyText>
<figure confidence="0.9899695">
0 2 4 6 8 10 12 14 16 18 20
Number of Rounds
</figure>
<figureCaption confidence="0.951616">
Figure 3: Comparison between our works and supervised
models in (Goldwasser and Roth, 2008b). We show the learn-
ing curves for Hebrew under two different settings: unsuper-
vised learning with general and all constraints. The results of
two supervised models (Goldwasser and Roth, 2008b) are also
included here. Note that our unsupervised model with all con-
straints is competitive to the supervised model with 250 labeled
examples. See the text for more comparisons and details.
</figureCaption>
<bodyText confidence="0.997378">
hinge loss as our loss function and fixed the regular-
ization parameter C to be 0.5.
</bodyText>
<subsectionHeader confidence="0.980395">
5.2 Datasets
</subsectionHeader>
<bodyText confidence="0.999168136363636">
We experimented using three different target lan-
guages Russian, Chinese, and Hebrew. We used En-
glish as the source language in all these experiments.
The Russian data set2, originally introduced in
(Klementiev and Roth, 2006b), is comprised of tem-
porally aligned news articles. The dataset contains
727 single word English NEs with a correspond-
ing set of 50,648 potential Russian candidate words
which include not only name entities, but also other
words appearing in the news articles.
The Chinese dataset is taken directly from an
English-Chinese transliteration dictionary, derived
from LDC Gigaword corpus3. The entire dictionary
consists of 74,396 pairs of English-Chinese NEs,
where Chinese NEs are written in Pinyin, a roman-
ized spelling system of Chinese. In (Tao et al., 2006)
a dataset which contains about 600 English NEs and
700 Chinese candidates is used. Since the dataset
is not publicly available, we created a dataset in a
similar way. We randomly selected approximately
600 NE pairs and then added about 100 candidates
which do not correspond to any of the English NE
</bodyText>
<footnote confidence="0.9994725">
2The corpus is available http://L2R.cs.uiuc.edu/∼cogcomp.
3http://www.ldc.upenn.edu
</footnote>
<figure confidence="0.9848604">
[KR 06] + temporal information
[KR 06]
All Cons. + unsupervsied
learning
0.9
0.8
0.7
0.6
0.5
0.4
1.1
1
4GR 0A250 labeled ex. with cons
GR 0 1 250 labeled ex. w/o cons
General cons + unsupervised learning
All cons. + unsupervised learning
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
M
</figure>
<page confidence="0.996036">
304
</page>
<table confidence="0.999329333333333">
Language UCDL Prev. works
Rus. (ACC) 73 63 (41) (KR’06)
Heb. (MRR) 0.899 0.894 (GR’08)
</table>
<tableCaption confidence="0.9861874">
Table 2: Comparison to previously published results. UCDL
is our method, KR’06 is described in (Klementiev and Roth,
2006b) and GR’08 in (Goldwasser and Roth, 2008b). Note that
our results for Hebrew are comparable with a supervised sys-
tem.
</tableCaption>
<bodyText confidence="0.95691775">
previously selected.
The Hebrew dataset, originally introduced in
(Goldwasser and Roth, 2008a), consists of 300
English-Hebrew pairs extracted from Wikipedia.
</bodyText>
<subsectionHeader confidence="0.727829">
5.3 Results
</subsectionHeader>
<bodyText confidence="0.999872728813559">
We begin by comparing our model to previously
published models tested over the same data, in two
different languages, Russian and Hebrew. For Rus-
sian, we compare to the model presented in (Kle-
mentiev and Roth, 2006b), a weakly supervised al-
gorithm that uses both phonetic information and
temporal information. The model is bootstrapped
using a set of 20 labeled examples. In their setting
the candidates are ranked by combining two scores,
one obtained using the transliteration model and a
second by comparing the relative occurrence fre-
quency of terms over time in both languages. Due
to computational tractability reasons we slightly
changed Algorithm 1 to use only a small subset of
the possible negative examples.
For Hebrew, we compare to the model presented
in (Goldwasser and Roth, 2008b), a supervised
model trained using 250 labeled examples. This
model uses a bigram model to represent the translit-
eration samples (i.e., features are generated by pair-
ing character unigrams and bigrams). The model
also uses constraints to restrict the feature extrac-
tion process, which are equivalent to the coverage
constraint we described in Sec. 3.2.
The results of these experiments are reported us-
ing the evaluation measures used in the original pa-
pers and are summarized in Table 2. The results
show a significant improvement over the Russian
data set and comparable performance to the super-
vised method used for Hebrew.
Figure 2 describes the learning curve of our
method over the Russian dataset. We compared our
algorithm to two models described in (Klementiev
and Roth, 2006b) - one uses only phonetic simi-
larity and the second also considers temporal co-
occurrence similarity when ranking the translitera-
tion candidates. Both models converge after 50 it-
erations. When comparing our model to their mod-
els, we found that even though our model ignores
the temporal information it achieves better results
and converges after fewer iterations. Their results
report a significant improvement when using tempo-
ral information - improving an ACC score of 41%
without temporal information to 63% when using
it. Since the temporal information is orthogonal to
the transliteration model, our model should similarly
benefit from incorporating the temporal information.
Figure 3 compares the learning curve of our
method to an existing supervised method over the
Hebrew data and shows we get comparable results.
Unfortunately, we could not find a published Chi-
nese dataset. However, our system achieved similar
results to other systems, over a different dataset with
similar number of training examples. For example,
(Sproat et al., 2006) presents a supervised system
that achieves a MRR score of 0.89, when evaluated
over a dataset consisting of 400 English NE and 627
Chinese words. Our results for a different dataset of
similar size are reported in Table 3.
</bodyText>
<subsectionHeader confidence="0.975098">
5.4 Analysis
</subsectionHeader>
<bodyText confidence="0.99755515">
The resources used in our framework consist of
- a romanization table, general and language spe-
cific transliteration constraints. To reveal the impact
of each component we experimented with different
combination of the components, resulting in three
different testing configurations.
Romanization Table: We initialized the weight
vector using a romanization table and did not use any
constraints. To generate features we use a modified
version of our AF operator (see Sec. 3), which gen-
erates features by coupling characters in close posi-
tions in the source and target words. This configura-
tion is equivalent to the model used in (Klementiev
and Roth, 2006b).
+General Constraints: This configuration uses the
romanization table for initializing the weight vector
and general transliteration constraints (see Sec. 3.2)
for feature extraction.
+All Constraints: This configuration uses lan-
guage specific constraints in addition to the gen-
</bodyText>
<page confidence="0.995932">
305
</page>
<table confidence="0.998795714285714">
Settings Chinese Russian Hebrew
Romanization table 0.019 (0.5) 0.034 (1.0) 0.046 (1.7)
Romanization table +learning 0.020 (0.3) 0.048 (1.3) 0.028 (0.7)
+Gen Constraints 0.746 (67.1) 0.809 (74.3) 0.533 (45.0)
+Gen Constraints +learning 0.867 (82.2) 0.906 (86.7) 0.834 (76.0)
+All Constraints 0.801 (73.4) 0.849 (79.3) 0.743 (66.0)
+All Constraints +learning 0.889 (84.7) 0.931 (90.0) 0.899 (85.0)
</table>
<tableCaption confidence="0.9801315">
Table 3: Results of an ablation study of unsupervised method for three target languages. Results for ACC are inside parentheses,
and for MRR outside. When the learning algorithm is used, the results after 20 rounds of constraint driven learning are reported.
Note that using linguistic constraints has a significant impact in the English-Hebrew experiments. Our results show that a small
amount of constraints can go a long way, and better constraints lead to better learning performance.
</tableCaption>
<bodyText confidence="0.999085411764706">
eral transliteration constraints to generate the feature
representation. (see Sec. 4).
+Learning: Indicates that after initializing the
weight vector, we update the weight using Algo-
rithm 1. In all of the experiments, we report the
results after 20 training iterations.
The results are summarized in Table 3. Due to the
size of the Russian dataset, we used a subset consist-
ing of 300 English NEs and their matching Russian
transliterations for the analysis presented here. Af-
ter observing the results, we discovered the follow-
ing regularities for all three languages. Using the
romanization table directly without constraints re-
sults in very poor performance, even after learning.
This can be used as an indication of the difficulty of
the transliteration problem and the difficulties ear-
lier works have had when using only romanization
tables, however, when used in conjunction with con-
straints results improve dramatically. For example,
in the English-Chinese data set, we improve MRR
from 0.02 to 0.746 and for the English-Russian data
set we improve 0.03 to 0.8. Interestingly, the results
for the English-Hebrew data set are lower than for
other languages - we achieve 0.53 MRR in this set-
ting. We attribute the difference to the quality of
the mapping in the romanization table for that lan-
guage. Indeed, the weights learned after 20 train-
ing iterations improve the results to 0.83. This im-
provement is consistent across all languages, after
learning we are able to achieve a MRR score of 0.87
for the English-Chinese data set and 0.91 for the
English-Russian data set. These results show that
romanization table contains enough information to
bootstrap the model when used in conjunction with
constraints. We are able to achieve results compa-
rable to supervised methods that use a similar set of
constraints and labeled examples.
Bootstrapping the weight vector using language
specific constraints can further improve the results.
They provide several advantages: a better starting
point, an improved learning rate and a better final
model. This is clear in all three languages, for exam-
ple results for the Russian and Chinese bootstrapped
models improve by 5%, and by over 20% for He-
brew. After training the difference is smaller- only
3% for the first two and 6% for Hebrew. Figure 3 de-
scribes the learning curve for models with and with-
out language specific constraints for the English-
Hebrew data set, it can be observed that using these
constraints the model converges faster and achieves
better results.
</bodyText>
<sectionHeader confidence="0.999543" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9994235">
In this paper we develop a constraints driven ap-
proach to named entity transliteration. In doing it
we show that romanization tables are a very useful
resource for transliteration discovery if proper con-
straints are included. Our framework does not need
labeled data and does not assume that bilingual cor-
pus are temporally aligned. Even without using any
labeled data, our model is competitive to existing
supervised models and outperforms existing weakly
supervised models.
</bodyText>
<sectionHeader confidence="0.999319" genericHeader="acknowledgments">
7 Acknowledgments
</sectionHeader>
<bodyText confidence="0.99868075">
We wish to thank the reviewers for their insightful
comments. This work is partly supported by NSF
grant SoD-HCER-0613885 and DARPA funding un-
der the Bootstrap Learning Program.
</bodyText>
<page confidence="0.998772">
306
</page>
<sectionHeader confidence="0.998346" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999911494736842">
S. Bergsma and G. Kondrak. 2007. Alignment-based
discriminative string similarity. In Proc. of the Annual
Meeting of the Association of Computational Linguis-
tics (ACL), pages 656–663, Prague, Czech Republic,
June. Association for Computational Linguistics.
M. Chang, L. Ratinov, and D. Roth. 2007. Guiding semi-
supervision with constraint-driven learning. In Proc.
of the Annual Meeting of the Association of Compu-
tational Linguistics (ACL), pages 280–287, Prague,
Czech Republic, Jun. Association for Computational
Linguistics.
M. Chang, L. Ratinov, N. Rizzolo, and D. Roth. 2008.
Learning and inference with constraints. In Proc.
of the National Conference on Artificial Intelligence
(AAAI), July.
D. Goldwasser and D. Roth. 2008a. Active sample se-
lection for named entity transliteration. In Proc. of the
Annual Meeting of the Association of Computational
Linguistics (ACL), June.
D. Goldwasser and D. Roth. 2008b. Transliteration as
constrained optimization. In Proc. of the Conference
on Empirical Methods for Natural Language Process-
ing (EMNLP), pages 353–362, Oct.
A. Haghighi and D. Klein. 2006. Prototype-driven learn-
ing for sequence models. In Proc. of the Annual Meet-
ing of the North American Association of Computa-
tional Linguistics (NAACL).
U. Hermjakob, K. Knight, and H. Daum´e III. 2008.
Name translation in statistical machine translation -
learning when to transliterate. In Proc. of the Annual
Meeting of the Association of Computational Linguis-
tics (ACL), pages 389–397, Columbus, Ohio, June.
Cho-Jui Hsieh, Kai-Wei Chang, Chih-Jen Lin, S. Sathiya
Keerthi, and S. Sundararajan. 2008. A dual coordinate
descent method for large-scale linear svm. In ICML
’08: Proceedings of the 25th international conference
on Machine learning, pages 408–415, New York, NY,
USA. ACM.
S. Jung, S. Hong, and E. Paek. 2000. An english to
korean transliteration model of extended markov win-
dow. In Proc. the International Conference on Com-
putational Linguistics (COLING), pages 383–389.
A. Klementiev and D. Roth. 2006a. Named entity
transliteration and discovery from multilingual com-
parable corpora. In Proc. of the Annual Meeting of the
North American Association of Computational Lin-
guistics (NAACL), pages 82–88, June.
A. Klementiev and D. Roth. 2006b. Weakly supervised
named entity transliteration and discovery from mul-
tilingual comparable corpora. In Proc. of the Annual
Meeting of the Association of Computational Linguis-
tics (ACL), pages USS,TL,ADAPT, July.
K. Knight and J. Graehl. 1998. Machine transliteration.
Computational Linguistics, pages 599–612.
H. Li, M. Zhang, and J. Su. 2004. A joint source-channel
model for machine transliteration. In Proc. of the An-
nual Meeting of the Association of Computational Lin-
guistics (ACL), pages 159–166, Barcelona, Spain, July.
H. Meng, W. Lo, B. Chen, and K. Tang. 2001.
Generating phonetic cognates to handle named en-
tities in english-chinese cross-langauge spoken doc-
ument retreival. In Proceedings of the Automatic
Speech Recognition and Understanding Workshop,
pages 389–397.
S. Riedel and J. Clarke. 2006. Incremental integer linear
programming for non-projective dependency parsing.
In Proc. of the Conference on Empirical Methods for
Natural Language Processing (EMNLP), pages 129–
137, Sydney, Australia.
E. S. Ristad and P. N. Yianilos. 1998. Learning string
edit distance. IEEE Transactions on Pattern Recogni-
tion and Machine Intelligence, 20(5):522–532, May.
D. Roth and W. Yih. 2004. A linear programming formu-
lation for global inference in natural language tasks.
pages 1–8. Association for Computational Linguistics.
D. Roth and W. Yih. 2007. Global inference for en-
tity and relation identification via a linear program-
ming formulation. In Lise Getoor and Ben Taskar, ed-
itors, Introduction to Statistical Relational Learning.
MIT Press.
R. Sproat, T. Tao, and C. Zhai. 2006. Named entity
transliteration with comparable corpora. In Proc. of
the Annual Meeting of the Association of Computa-
tional Linguistics (ACL), pages 73–80, Sydney, Aus-
tralia, July.
T. Tao, S. Yoon, A. Fister, R. Sproat, and C. Zhai. 2006.
Unsupervised named entitly transliteration using tem-
poral and phonetic correlation. In Proc. of the Con-
ference on Empirical Methods for Natural Language
Processing (EMNLP), pages 250–257.
S. Yoon, K. Kim, and R. Sproat. 2007. Multilingual
transliteration using feature based phonetic method.
In Proc. of the Annual Meeting of the Association
of Computational Linguistics (ACL), pages 112–119,
Prague, Czech Republic, June.
</reference>
<page confidence="0.998601">
307
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.962652">
<title confidence="0.998746">Unsupervised Constraint Driven Learning For Transliteration Discovery</title>
<author confidence="0.999478">Ming-Wei Chang Dan Goldwasser Dan Roth Yuancheng</author>
<affiliation confidence="0.999687">University of Illinois at Urbana</affiliation>
<address confidence="0.970724">Urbana, IL</address>
<abstract confidence="0.999617764705882">This paper introduces a novel unsupervised algorithm for identifying named-entity (NE) transliterations in bilingual corpora. The proposed method does not require any annotated data or aligned corpora. Instead, it is bootstrapped using a simple resource – a romanization table. We show that this resource, when used in conjunction with constraints, can efficiently identify transliteration pairs. We evaluate the proposed method on transliterating English NEs to three different languages - Chinese, Russian and Hebrew. Our experiments show that constraint driven learning can significantly outperform existing unsupervised models and achieve competitive results to existing supervised models.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Bergsma</author>
<author>G Kondrak</author>
</authors>
<title>Alignment-based discriminative string similarity.</title>
<date>2007</date>
<booktitle>In Proc. of the Annual Meeting of the Association of Computational Linguistics (ACL),</booktitle>
<pages>656--663</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="5244" citStr="Bergsma and Kondrak, 2007" startWordPosition="788" endWordPosition="791">performance to supervised methods. The rest of the paper is organized as follows. Sec. 2 briefly examines more related work. Sec. 3 explains our model and Sec. 4 provide a linguistic intuition for it. Sec. 5 describes our experiments and evaluates our results followed by sec. 6 which concludes our paper. 2 Related Works Transliteration methods typically fall into two categories: generative approaches (Li et al., 2004; Jung et al., 2000; Knight and Graehl, 1998) that try to produce the target transliteration given a source language NE, and discriminative approaches (Goldwasser and Roth, 2008b; Bergsma and Kondrak, 2007; Sproat et al., 2006; Klementiev and Roth, 2006a), that try to identify the correct transliteration for a word in the source language given several candidates in the target language. Generative methods encounter the Out-Of-Vocabulary (OOV) problem and require substantial amounts of training data and knowledge of the source and target languages. Discriminative approaches, when used to for discovering NE in a bilingual corpora avoid the OOV problem by choosing the transliteration candidates from the corpora. These methods typically make very little assumptions about the source and target langua</context>
<context position="7086" citStr="Bergsma and Kondrak, 2007" startWordPosition="1068" endWordPosition="1071">nd Yih, 2004; Riedel and Clarke, 2006) and unsupervised settings (Haghighi and Klein, 2006; Chang et al., 2007) in which constraints are used to bootstrap the model. (Chang et al., 2007) describes an unsupervised training of a Constrained Conditional Model (CCM), a general framework for combining statistical models with declarative constraints. We extend this work to include constraints over possible assignments to latent variables which, in turn, define the underlying representation for the learning problem. In the transliteration community there are several works (Ristad and Yianilos, 1998; Bergsma and Kondrak, 2007; Goldwasser and Roth, 2008b) that show how the feature representation of a word pair can be restricted to facilitate learning a string similarity model. We follow the approach discussed in (Goldwasser and Roth, 2008b), which considers the feature representation as a structured prediction problem and finds the set of optimal assignments (or feature activations), under a set of legitimacy constraints. This approach stresses the importance of interaction between learning and inference, as the model iteratively uses inference to improve the sample representation for the learning problem and uses </context>
</contexts>
<marker>Bergsma, Kondrak, 2007</marker>
<rawString>S. Bergsma and G. Kondrak. 2007. Alignment-based discriminative string similarity. In Proc. of the Annual Meeting of the Association of Computational Linguistics (ACL), pages 656–663, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Chang</author>
<author>L Ratinov</author>
<author>D Roth</author>
</authors>
<title>Guiding semisupervision with constraint-driven learning.</title>
<date>2007</date>
<booktitle>In Proc. of the Annual Meeting of the Association of Computational Linguistics (ACL),</booktitle>
<pages>280--287</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="6572" citStr="Chang et al., 2007" startWordPosition="991" endWordPosition="994">r supervised settings (Bergsma and Kondrak, 2007; Goldwasser and Roth, 2008b), or weakly supervised settings with additional temporal information (Sproat et al., 2006; Klementiev and Roth, 2006a). Our work differs from these works in that it is completely unsupervised and makes no assumptions about the training data. Incorporating knowledge encoded as constraints into learning problems has attracted a lot of attention in the NLP community recently. This has been shown both in supervised settings (Roth and Yih, 2004; Riedel and Clarke, 2006) and unsupervised settings (Haghighi and Klein, 2006; Chang et al., 2007) in which constraints are used to bootstrap the model. (Chang et al., 2007) describes an unsupervised training of a Constrained Conditional Model (CCM), a general framework for combining statistical models with declarative constraints. We extend this work to include constraints over possible assignments to latent variables which, in turn, define the underlying representation for the learning problem. In the transliteration community there are several works (Ristad and Yianilos, 1998; Bergsma and Kondrak, 2007; Goldwasser and Roth, 2008b) that show how the feature representation of a word pair </context>
</contexts>
<marker>Chang, Ratinov, Roth, 2007</marker>
<rawString>M. Chang, L. Ratinov, and D. Roth. 2007. Guiding semisupervision with constraint-driven learning. In Proc. of the Annual Meeting of the Association of Computational Linguistics (ACL), pages 280–287, Prague, Czech Republic, Jun. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Chang</author>
<author>L Ratinov</author>
<author>N Rizzolo</author>
<author>D Roth</author>
</authors>
<title>Learning and inference with constraints.</title>
<date>2008</date>
<booktitle>In Proc. of the National Conference on Artificial Intelligence (AAAI),</booktitle>
<contexts>
<context position="11724" citStr="Chang et al., 2008" startWordPosition="1859" endWordPosition="1862">E Vs}. 4. Vvs E Vs, vt E Vt, if vt =� vt and score(F(vs, vt)) =� −oo, then D = D U {(−, F(vs, vt))}. 5. W +— train(D) end Algorithm 1: UCDL Transliteration Framework. In the rest of this section we explain this process in detail. We define the feature extraction inference process in Sec. 3.1, the constraints used in Sec. 3.2 and the inference algorithm in Sec. 3.3. The linguistic intuition for our model is described in Sec. 4. 3.1 Finding Feature Representation as Constrained Optimization We use the formulation of Constrainted Conditional Models (CCMs) (Roth and Yih, 2004; Roth and Yih, 2007; Chang et al., 2008). Previous work on CCM models dependencies between different decisions in structured prediction problems. Transliteration discovery is a binary classification problem, however, 301 the underlying representation of each sample can be modeled as a CCM, defined as a set of latent variables corresponding to the set of all possible features for a given sample. The dependencies between the features are captured using constraints. Given a word pair, the set of all possible features consists of all character mappings from the source word to the target word. Since in many cases the size of the words di</context>
</contexts>
<marker>Chang, Ratinov, Rizzolo, Roth, 2008</marker>
<rawString>M. Chang, L. Ratinov, N. Rizzolo, and D. Roth. 2008. Learning and inference with constraints. In Proc. of the National Conference on Artificial Intelligence (AAAI), July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Goldwasser</author>
<author>D Roth</author>
</authors>
<title>Active sample selection for named entity transliteration.</title>
<date>2008</date>
<booktitle>In Proc. of the Annual Meeting of the Association of Computational Linguistics (ACL),</booktitle>
<contexts>
<context position="5216" citStr="Goldwasser and Roth, 2008" startWordPosition="783" endWordPosition="787">hes and achieves comparable performance to supervised methods. The rest of the paper is organized as follows. Sec. 2 briefly examines more related work. Sec. 3 explains our model and Sec. 4 provide a linguistic intuition for it. Sec. 5 describes our experiments and evaluates our results followed by sec. 6 which concludes our paper. 2 Related Works Transliteration methods typically fall into two categories: generative approaches (Li et al., 2004; Jung et al., 2000; Knight and Graehl, 1998) that try to produce the target transliteration given a source language NE, and discriminative approaches (Goldwasser and Roth, 2008b; Bergsma and Kondrak, 2007; Sproat et al., 2006; Klementiev and Roth, 2006a), that try to identify the correct transliteration for a word in the source language given several candidates in the target language. Generative methods encounter the Out-Of-Vocabulary (OOV) problem and require substantial amounts of training data and knowledge of the source and target languages. Discriminative approaches, when used to for discovering NE in a bilingual corpora avoid the OOV problem by choosing the transliteration candidates from the corpora. These methods typically make very little assumptions about </context>
<context position="7113" citStr="Goldwasser and Roth, 2008" startWordPosition="1072" endWordPosition="1075">arke, 2006) and unsupervised settings (Haghighi and Klein, 2006; Chang et al., 2007) in which constraints are used to bootstrap the model. (Chang et al., 2007) describes an unsupervised training of a Constrained Conditional Model (CCM), a general framework for combining statistical models with declarative constraints. We extend this work to include constraints over possible assignments to latent variables which, in turn, define the underlying representation for the learning problem. In the transliteration community there are several works (Ristad and Yianilos, 1998; Bergsma and Kondrak, 2007; Goldwasser and Roth, 2008b) that show how the feature representation of a word pair can be restricted to facilitate learning a string similarity model. We follow the approach discussed in (Goldwasser and Roth, 2008b), which considers the feature representation as a structured prediction problem and finds the set of optimal assignments (or feature activations), under a set of legitimacy constraints. This approach stresses the importance of interaction between learning and inference, as the model iteratively uses inference to improve the sample representation for the learning problem and uses the learned model to improv</context>
<context position="21295" citStr="Goldwasser and Roth, 2008" startWordPosition="3517" endWordPosition="3520">y to correctly identify the gold transliteration for each source word. We evaluated the system’s performance using two measures adopted in many transliteration works. The first one is Mean Reciprocal Rank (MRR), used in (Tao et al., 2006; Sproat et al., 2006), which is the average of the multiplicative inverse of the rank of the correct answer. Formally, Let n be the number of source NEs. Let GoldRank(i) be the rank the algorithm assigns to the correct transliteration. Then, MRR is defined by: 1 n 1 MRR = n Z=1 goldRank(i) Another measure is Accuracy (ACC) used in (Klementiev and Roth, 2006a; Goldwasser and Roth, 2008a), which is the percentage of the top rank candidates being the gold transliteration. In our implementation we used the support vector machine (SVM) learning algorithm with linear kernel as our underlying learning algorithm (mentioned in part 2.5 of Algorithm 1) . We used the package LIBLINEAR (Hsieh et al., 2008) in our experiments. Through all of our experiments, we used the 2-norm 0 2 4 6 8 10 12 14 16 18 20 Number of Rounds Figure 3: Comparison between our works and supervised models in (Goldwasser and Roth, 2008b). We show the learning curves for Hebrew under two different settings: unsu</context>
<context position="23995" citStr="Goldwasser and Roth, 2008" startWordPosition="3964" endWordPosition="3967">f the English NE 2The corpus is available http://L2R.cs.uiuc.edu/∼cogcomp. 3http://www.ldc.upenn.edu [KR 06] + temporal information [KR 06] All Cons. + unsupervsied learning 0.9 0.8 0.7 0.6 0.5 0.4 1.1 1 4GR 0A250 labeled ex. with cons GR 0 1 250 labeled ex. w/o cons General cons + unsupervised learning All cons. + unsupervised learning 1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 M 304 Language UCDL Prev. works Rus. (ACC) 73 63 (41) (KR’06) Heb. (MRR) 0.899 0.894 (GR’08) Table 2: Comparison to previously published results. UCDL is our method, KR’06 is described in (Klementiev and Roth, 2006b) and GR’08 in (Goldwasser and Roth, 2008b). Note that our results for Hebrew are comparable with a supervised system. previously selected. The Hebrew dataset, originally introduced in (Goldwasser and Roth, 2008a), consists of 300 English-Hebrew pairs extracted from Wikipedia. 5.3 Results We begin by comparing our model to previously published models tested over the same data, in two different languages, Russian and Hebrew. For Russian, we compare to the model presented in (Klementiev and Roth, 2006b), a weakly supervised algorithm that uses both phonetic information and temporal information. The model is bootstrapped using a set of </context>
</contexts>
<marker>Goldwasser, Roth, 2008</marker>
<rawString>D. Goldwasser and D. Roth. 2008a. Active sample selection for named entity transliteration. In Proc. of the Annual Meeting of the Association of Computational Linguistics (ACL), June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Goldwasser</author>
<author>D Roth</author>
</authors>
<title>Transliteration as constrained optimization.</title>
<date>2008</date>
<booktitle>In Proc. of the Conference on Empirical Methods for Natural Language Processing (EMNLP),</booktitle>
<pages>353--362</pages>
<contexts>
<context position="5216" citStr="Goldwasser and Roth, 2008" startWordPosition="783" endWordPosition="787">hes and achieves comparable performance to supervised methods. The rest of the paper is organized as follows. Sec. 2 briefly examines more related work. Sec. 3 explains our model and Sec. 4 provide a linguistic intuition for it. Sec. 5 describes our experiments and evaluates our results followed by sec. 6 which concludes our paper. 2 Related Works Transliteration methods typically fall into two categories: generative approaches (Li et al., 2004; Jung et al., 2000; Knight and Graehl, 1998) that try to produce the target transliteration given a source language NE, and discriminative approaches (Goldwasser and Roth, 2008b; Bergsma and Kondrak, 2007; Sproat et al., 2006; Klementiev and Roth, 2006a), that try to identify the correct transliteration for a word in the source language given several candidates in the target language. Generative methods encounter the Out-Of-Vocabulary (OOV) problem and require substantial amounts of training data and knowledge of the source and target languages. Discriminative approaches, when used to for discovering NE in a bilingual corpora avoid the OOV problem by choosing the transliteration candidates from the corpora. These methods typically make very little assumptions about </context>
<context position="7113" citStr="Goldwasser and Roth, 2008" startWordPosition="1072" endWordPosition="1075">arke, 2006) and unsupervised settings (Haghighi and Klein, 2006; Chang et al., 2007) in which constraints are used to bootstrap the model. (Chang et al., 2007) describes an unsupervised training of a Constrained Conditional Model (CCM), a general framework for combining statistical models with declarative constraints. We extend this work to include constraints over possible assignments to latent variables which, in turn, define the underlying representation for the learning problem. In the transliteration community there are several works (Ristad and Yianilos, 1998; Bergsma and Kondrak, 2007; Goldwasser and Roth, 2008b) that show how the feature representation of a word pair can be restricted to facilitate learning a string similarity model. We follow the approach discussed in (Goldwasser and Roth, 2008b), which considers the feature representation as a structured prediction problem and finds the set of optimal assignments (or feature activations), under a set of legitimacy constraints. This approach stresses the importance of interaction between learning and inference, as the model iteratively uses inference to improve the sample representation for the learning problem and uses the learned model to improv</context>
<context position="21295" citStr="Goldwasser and Roth, 2008" startWordPosition="3517" endWordPosition="3520">y to correctly identify the gold transliteration for each source word. We evaluated the system’s performance using two measures adopted in many transliteration works. The first one is Mean Reciprocal Rank (MRR), used in (Tao et al., 2006; Sproat et al., 2006), which is the average of the multiplicative inverse of the rank of the correct answer. Formally, Let n be the number of source NEs. Let GoldRank(i) be the rank the algorithm assigns to the correct transliteration. Then, MRR is defined by: 1 n 1 MRR = n Z=1 goldRank(i) Another measure is Accuracy (ACC) used in (Klementiev and Roth, 2006a; Goldwasser and Roth, 2008a), which is the percentage of the top rank candidates being the gold transliteration. In our implementation we used the support vector machine (SVM) learning algorithm with linear kernel as our underlying learning algorithm (mentioned in part 2.5 of Algorithm 1) . We used the package LIBLINEAR (Hsieh et al., 2008) in our experiments. Through all of our experiments, we used the 2-norm 0 2 4 6 8 10 12 14 16 18 20 Number of Rounds Figure 3: Comparison between our works and supervised models in (Goldwasser and Roth, 2008b). We show the learning curves for Hebrew under two different settings: unsu</context>
<context position="23995" citStr="Goldwasser and Roth, 2008" startWordPosition="3964" endWordPosition="3967">f the English NE 2The corpus is available http://L2R.cs.uiuc.edu/∼cogcomp. 3http://www.ldc.upenn.edu [KR 06] + temporal information [KR 06] All Cons. + unsupervsied learning 0.9 0.8 0.7 0.6 0.5 0.4 1.1 1 4GR 0A250 labeled ex. with cons GR 0 1 250 labeled ex. w/o cons General cons + unsupervised learning All cons. + unsupervised learning 1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 M 304 Language UCDL Prev. works Rus. (ACC) 73 63 (41) (KR’06) Heb. (MRR) 0.899 0.894 (GR’08) Table 2: Comparison to previously published results. UCDL is our method, KR’06 is described in (Klementiev and Roth, 2006b) and GR’08 in (Goldwasser and Roth, 2008b). Note that our results for Hebrew are comparable with a supervised system. previously selected. The Hebrew dataset, originally introduced in (Goldwasser and Roth, 2008a), consists of 300 English-Hebrew pairs extracted from Wikipedia. 5.3 Results We begin by comparing our model to previously published models tested over the same data, in two different languages, Russian and Hebrew. For Russian, we compare to the model presented in (Klementiev and Roth, 2006b), a weakly supervised algorithm that uses both phonetic information and temporal information. The model is bootstrapped using a set of </context>
</contexts>
<marker>Goldwasser, Roth, 2008</marker>
<rawString>D. Goldwasser and D. Roth. 2008b. Transliteration as constrained optimization. In Proc. of the Conference on Empirical Methods for Natural Language Processing (EMNLP), pages 353–362, Oct.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Haghighi</author>
<author>D Klein</author>
</authors>
<title>Prototype-driven learning for sequence models.</title>
<date>2006</date>
<booktitle>In Proc. of the Annual Meeting of the North American Association of Computational Linguistics (NAACL).</booktitle>
<contexts>
<context position="6551" citStr="Haghighi and Klein, 2006" startWordPosition="987" endWordPosition="990">del is typically done under supervised settings (Bergsma and Kondrak, 2007; Goldwasser and Roth, 2008b), or weakly supervised settings with additional temporal information (Sproat et al., 2006; Klementiev and Roth, 2006a). Our work differs from these works in that it is completely unsupervised and makes no assumptions about the training data. Incorporating knowledge encoded as constraints into learning problems has attracted a lot of attention in the NLP community recently. This has been shown both in supervised settings (Roth and Yih, 2004; Riedel and Clarke, 2006) and unsupervised settings (Haghighi and Klein, 2006; Chang et al., 2007) in which constraints are used to bootstrap the model. (Chang et al., 2007) describes an unsupervised training of a Constrained Conditional Model (CCM), a general framework for combining statistical models with declarative constraints. We extend this work to include constraints over possible assignments to latent variables which, in turn, define the underlying representation for the learning problem. In the transliteration community there are several works (Ristad and Yianilos, 1998; Bergsma and Kondrak, 2007; Goldwasser and Roth, 2008b) that show how the feature represent</context>
</contexts>
<marker>Haghighi, Klein, 2006</marker>
<rawString>A. Haghighi and D. Klein. 2006. Prototype-driven learning for sequence models. In Proc. of the Annual Meeting of the North American Association of Computational Linguistics (NAACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Hermjakob</author>
<author>K Knight</author>
<author>H Daum´e</author>
</authors>
<title>Name translation in statistical machine translation -learning when to transliterate.</title>
<date>2008</date>
<booktitle>In Proc. of the Annual Meeting of the Association of Computational Linguistics (ACL),</booktitle>
<pages>389--397</pages>
<location>Columbus, Ohio,</location>
<marker>Hermjakob, Knight, Daum´e, 2008</marker>
<rawString>U. Hermjakob, K. Knight, and H. Daum´e III. 2008. Name translation in statistical machine translation -learning when to transliterate. In Proc. of the Annual Meeting of the Association of Computational Linguistics (ACL), pages 389–397, Columbus, Ohio, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cho-Jui Hsieh</author>
<author>Kai-Wei Chang</author>
<author>Chih-Jen Lin</author>
<author>S Sathiya Keerthi</author>
<author>S Sundararajan</author>
</authors>
<title>A dual coordinate descent method for large-scale linear svm.</title>
<date>2008</date>
<booktitle>In ICML ’08: Proceedings of the 25th international conference on Machine learning,</booktitle>
<pages>408--415</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="21611" citStr="Hsieh et al., 2008" startWordPosition="3570" endWordPosition="3573">k of the correct answer. Formally, Let n be the number of source NEs. Let GoldRank(i) be the rank the algorithm assigns to the correct transliteration. Then, MRR is defined by: 1 n 1 MRR = n Z=1 goldRank(i) Another measure is Accuracy (ACC) used in (Klementiev and Roth, 2006a; Goldwasser and Roth, 2008a), which is the percentage of the top rank candidates being the gold transliteration. In our implementation we used the support vector machine (SVM) learning algorithm with linear kernel as our underlying learning algorithm (mentioned in part 2.5 of Algorithm 1) . We used the package LIBLINEAR (Hsieh et al., 2008) in our experiments. Through all of our experiments, we used the 2-norm 0 2 4 6 8 10 12 14 16 18 20 Number of Rounds Figure 3: Comparison between our works and supervised models in (Goldwasser and Roth, 2008b). We show the learning curves for Hebrew under two different settings: unsupervised learning with general and all constraints. The results of two supervised models (Goldwasser and Roth, 2008b) are also included here. Note that our unsupervised model with all constraints is competitive to the supervised model with 250 labeled examples. See the text for more comparisons and details. hinge l</context>
</contexts>
<marker>Hsieh, Chang, Lin, Keerthi, Sundararajan, 2008</marker>
<rawString>Cho-Jui Hsieh, Kai-Wei Chang, Chih-Jen Lin, S. Sathiya Keerthi, and S. Sundararajan. 2008. A dual coordinate descent method for large-scale linear svm. In ICML ’08: Proceedings of the 25th international conference on Machine learning, pages 408–415, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Jung</author>
<author>S Hong</author>
<author>E Paek</author>
</authors>
<title>An english to korean transliteration model of extended markov window.</title>
<date>2000</date>
<booktitle>In Proc. the International Conference on Computational Linguistics (COLING),</booktitle>
<pages>383--389</pages>
<contexts>
<context position="5058" citStr="Jung et al., 2000" startWordPosition="759" endWordPosition="762">esource in conjunction with constraints provided us with a robust transliteration system which significantly outperforms existing unsupervised approaches and achieves comparable performance to supervised methods. The rest of the paper is organized as follows. Sec. 2 briefly examines more related work. Sec. 3 explains our model and Sec. 4 provide a linguistic intuition for it. Sec. 5 describes our experiments and evaluates our results followed by sec. 6 which concludes our paper. 2 Related Works Transliteration methods typically fall into two categories: generative approaches (Li et al., 2004; Jung et al., 2000; Knight and Graehl, 1998) that try to produce the target transliteration given a source language NE, and discriminative approaches (Goldwasser and Roth, 2008b; Bergsma and Kondrak, 2007; Sproat et al., 2006; Klementiev and Roth, 2006a), that try to identify the correct transliteration for a word in the source language given several candidates in the target language. Generative methods encounter the Out-Of-Vocabulary (OOV) problem and require substantial amounts of training data and knowledge of the source and target languages. Discriminative approaches, when used to for discovering NE in a bi</context>
</contexts>
<marker>Jung, Hong, Paek, 2000</marker>
<rawString>S. Jung, S. Hong, and E. Paek. 2000. An english to korean transliteration model of extended markov window. In Proc. the International Conference on Computational Linguistics (COLING), pages 383–389.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Klementiev</author>
<author>D Roth</author>
</authors>
<title>Named entity transliteration and discovery from multilingual comparable corpora.</title>
<date>2006</date>
<booktitle>In Proc. of the Annual Meeting of the North American Association of Computational Linguistics (NAACL),</booktitle>
<pages>82--88</pages>
<contexts>
<context position="1364" citStr="Klementiev and Roth, 2006" startWordPosition="181" endWordPosition="184">uages - Chinese, Russian and Hebrew. Our experiments show that constraint driven learning can significantly outperform existing unsupervised models and achieve competitive results to existing supervised models. 1 Introduction Named entity (NE) transliteration is the process of transcribing a NE from a source language to some target language while preserving its pronunciation in the original language. Automatic NE transliteration is an important component in many cross-language applications, such as Cross-Lingual Information Retrieval (CLIR) and Machine Translation(MT) (Hermjakob et al., 2008; Klementiev and Roth, 2006a; Meng et al., 2001; Knight and Graehl, 1998). It might initially seem that transliteration is an easy task, requiring only finding a phonetic mapping between character sets. However simply matching every source language character to its target language counterpart is not likely to work well as in practice this mapping depends on the context the characters appear in and on transliteration conventions which may change across domains. As a result, current approaches employ machine learning methods which, given enough labeled training data learn how to determine whether a pair of words constitut</context>
<context position="5292" citStr="Klementiev and Roth, 2006" startWordPosition="796" endWordPosition="799">he paper is organized as follows. Sec. 2 briefly examines more related work. Sec. 3 explains our model and Sec. 4 provide a linguistic intuition for it. Sec. 5 describes our experiments and evaluates our results followed by sec. 6 which concludes our paper. 2 Related Works Transliteration methods typically fall into two categories: generative approaches (Li et al., 2004; Jung et al., 2000; Knight and Graehl, 1998) that try to produce the target transliteration given a source language NE, and discriminative approaches (Goldwasser and Roth, 2008b; Bergsma and Kondrak, 2007; Sproat et al., 2006; Klementiev and Roth, 2006a), that try to identify the correct transliteration for a word in the source language given several candidates in the target language. Generative methods encounter the Out-Of-Vocabulary (OOV) problem and require substantial amounts of training data and knowledge of the source and target languages. Discriminative approaches, when used to for discovering NE in a bilingual corpora avoid the OOV problem by choosing the transliteration candidates from the corpora. These methods typically make very little assumptions about the source and target languages and require considerably less data to conver</context>
<context position="20201" citStr="Klementiev and Roth, 2006" startWordPosition="3335" endWordPosition="3338">sound is voiceless in Chinese, its backtrack English sound must be voiceless. This voice-voiceless sound change tendency is captured by our constraints such as p —* b,p and p +— p; t + —t. 5 Experiments and Analysis In this section, we demonstrate the effectiveness of constraint driven learning empirically. We start by describing the datasets and experimental settings and then proceed to describe the results. We evaluated our method on three very different target lan303 0 2 4 6 8 10 12 14 16 18 20 Number of Rounds Figure 2: Comparison between our models and weakly supervised learning methods (Klementiev and Roth, 2006b). Note that one of the models proposed in (Klementiev and Roth, 2006b) takes advantage of the temporal information. Our best model, the unsupervised learning with all constraints, outperforms both models in (Klementiev and Roth, 2006b), even though we do not use any temporal information. guages: Russian, Chinese, and Hebrew, and compared our results to previously published results. 5.1 Experimental Settings In our experiments the system is evaluated on its ability to correctly identify the gold transliteration for each source word. We evaluated the system’s performance using two measures ado</context>
<context position="22525" citStr="Klementiev and Roth, 2006" startWordPosition="3724" endWordPosition="3727">sed learning with general and all constraints. The results of two supervised models (Goldwasser and Roth, 2008b) are also included here. Note that our unsupervised model with all constraints is competitive to the supervised model with 250 labeled examples. See the text for more comparisons and details. hinge loss as our loss function and fixed the regularization parameter C to be 0.5. 5.2 Datasets We experimented using three different target languages Russian, Chinese, and Hebrew. We used English as the source language in all these experiments. The Russian data set2, originally introduced in (Klementiev and Roth, 2006b), is comprised of temporally aligned news articles. The dataset contains 727 single word English NEs with a corresponding set of 50,648 potential Russian candidate words which include not only name entities, but also other words appearing in the news articles. The Chinese dataset is taken directly from an English-Chinese transliteration dictionary, derived from LDC Gigaword corpus3. The entire dictionary consists of 74,396 pairs of English-Chinese NEs, where Chinese NEs are written in Pinyin, a romanized spelling system of Chinese. In (Tao et al., 2006) a dataset which contains about 600 Eng</context>
<context position="23953" citStr="Klementiev and Roth, 2006" startWordPosition="3957" endWordPosition="3960">andidates which do not correspond to any of the English NE 2The corpus is available http://L2R.cs.uiuc.edu/∼cogcomp. 3http://www.ldc.upenn.edu [KR 06] + temporal information [KR 06] All Cons. + unsupervsied learning 0.9 0.8 0.7 0.6 0.5 0.4 1.1 1 4GR 0A250 labeled ex. with cons GR 0 1 250 labeled ex. w/o cons General cons + unsupervised learning All cons. + unsupervised learning 1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 M 304 Language UCDL Prev. works Rus. (ACC) 73 63 (41) (KR’06) Heb. (MRR) 0.899 0.894 (GR’08) Table 2: Comparison to previously published results. UCDL is our method, KR’06 is described in (Klementiev and Roth, 2006b) and GR’08 in (Goldwasser and Roth, 2008b). Note that our results for Hebrew are comparable with a supervised system. previously selected. The Hebrew dataset, originally introduced in (Goldwasser and Roth, 2008a), consists of 300 English-Hebrew pairs extracted from Wikipedia. 5.3 Results We begin by comparing our model to previously published models tested over the same data, in two different languages, Russian and Hebrew. For Russian, we compare to the model presented in (Klementiev and Roth, 2006b), a weakly supervised algorithm that uses both phonetic information and temporal information.</context>
<context position="25823" citStr="Klementiev and Roth, 2006" startWordPosition="4255" endWordPosition="4258"> by pairing character unigrams and bigrams). The model also uses constraints to restrict the feature extraction process, which are equivalent to the coverage constraint we described in Sec. 3.2. The results of these experiments are reported using the evaluation measures used in the original papers and are summarized in Table 2. The results show a significant improvement over the Russian data set and comparable performance to the supervised method used for Hebrew. Figure 2 describes the learning curve of our method over the Russian dataset. We compared our algorithm to two models described in (Klementiev and Roth, 2006b) - one uses only phonetic similarity and the second also considers temporal cooccurrence similarity when ranking the transliteration candidates. Both models converge after 50 iterations. When comparing our model to their models, we found that even though our model ignores the temporal information it achieves better results and converges after fewer iterations. Their results report a significant improvement when using temporal information - improving an ACC score of 41% without temporal information to 63% when using it. Since the temporal information is orthogonal to the transliteration model</context>
<context position="27766" citStr="Klementiev and Roth, 2006" startWordPosition="4561" endWordPosition="4564">work consist of - a romanization table, general and language specific transliteration constraints. To reveal the impact of each component we experimented with different combination of the components, resulting in three different testing configurations. Romanization Table: We initialized the weight vector using a romanization table and did not use any constraints. To generate features we use a modified version of our AF operator (see Sec. 3), which generates features by coupling characters in close positions in the source and target words. This configuration is equivalent to the model used in (Klementiev and Roth, 2006b). +General Constraints: This configuration uses the romanization table for initializing the weight vector and general transliteration constraints (see Sec. 3.2) for feature extraction. +All Constraints: This configuration uses language specific constraints in addition to the gen305 Settings Chinese Russian Hebrew Romanization table 0.019 (0.5) 0.034 (1.0) 0.046 (1.7) Romanization table +learning 0.020 (0.3) 0.048 (1.3) 0.028 (0.7) +Gen Constraints 0.746 (67.1) 0.809 (74.3) 0.533 (45.0) +Gen Constraints +learning 0.867 (82.2) 0.906 (86.7) 0.834 (76.0) +All Constraints 0.801 (73.4) 0.849 (79.3</context>
</contexts>
<marker>Klementiev, Roth, 2006</marker>
<rawString>A. Klementiev and D. Roth. 2006a. Named entity transliteration and discovery from multilingual comparable corpora. In Proc. of the Annual Meeting of the North American Association of Computational Linguistics (NAACL), pages 82–88, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Klementiev</author>
<author>D Roth</author>
</authors>
<title>Weakly supervised named entity transliteration and discovery from multilingual comparable corpora.</title>
<date>2006</date>
<booktitle>In Proc. of the Annual Meeting of the Association of Computational Linguistics (ACL),</booktitle>
<pages>pages USS,TL,ADAPT,</pages>
<contexts>
<context position="1364" citStr="Klementiev and Roth, 2006" startWordPosition="181" endWordPosition="184">uages - Chinese, Russian and Hebrew. Our experiments show that constraint driven learning can significantly outperform existing unsupervised models and achieve competitive results to existing supervised models. 1 Introduction Named entity (NE) transliteration is the process of transcribing a NE from a source language to some target language while preserving its pronunciation in the original language. Automatic NE transliteration is an important component in many cross-language applications, such as Cross-Lingual Information Retrieval (CLIR) and Machine Translation(MT) (Hermjakob et al., 2008; Klementiev and Roth, 2006a; Meng et al., 2001; Knight and Graehl, 1998). It might initially seem that transliteration is an easy task, requiring only finding a phonetic mapping between character sets. However simply matching every source language character to its target language counterpart is not likely to work well as in practice this mapping depends on the context the characters appear in and on transliteration conventions which may change across domains. As a result, current approaches employ machine learning methods which, given enough labeled training data learn how to determine whether a pair of words constitut</context>
<context position="5292" citStr="Klementiev and Roth, 2006" startWordPosition="796" endWordPosition="799">he paper is organized as follows. Sec. 2 briefly examines more related work. Sec. 3 explains our model and Sec. 4 provide a linguistic intuition for it. Sec. 5 describes our experiments and evaluates our results followed by sec. 6 which concludes our paper. 2 Related Works Transliteration methods typically fall into two categories: generative approaches (Li et al., 2004; Jung et al., 2000; Knight and Graehl, 1998) that try to produce the target transliteration given a source language NE, and discriminative approaches (Goldwasser and Roth, 2008b; Bergsma and Kondrak, 2007; Sproat et al., 2006; Klementiev and Roth, 2006a), that try to identify the correct transliteration for a word in the source language given several candidates in the target language. Generative methods encounter the Out-Of-Vocabulary (OOV) problem and require substantial amounts of training data and knowledge of the source and target languages. Discriminative approaches, when used to for discovering NE in a bilingual corpora avoid the OOV problem by choosing the transliteration candidates from the corpora. These methods typically make very little assumptions about the source and target languages and require considerably less data to conver</context>
<context position="20201" citStr="Klementiev and Roth, 2006" startWordPosition="3335" endWordPosition="3338">sound is voiceless in Chinese, its backtrack English sound must be voiceless. This voice-voiceless sound change tendency is captured by our constraints such as p —* b,p and p +— p; t + —t. 5 Experiments and Analysis In this section, we demonstrate the effectiveness of constraint driven learning empirically. We start by describing the datasets and experimental settings and then proceed to describe the results. We evaluated our method on three very different target lan303 0 2 4 6 8 10 12 14 16 18 20 Number of Rounds Figure 2: Comparison between our models and weakly supervised learning methods (Klementiev and Roth, 2006b). Note that one of the models proposed in (Klementiev and Roth, 2006b) takes advantage of the temporal information. Our best model, the unsupervised learning with all constraints, outperforms both models in (Klementiev and Roth, 2006b), even though we do not use any temporal information. guages: Russian, Chinese, and Hebrew, and compared our results to previously published results. 5.1 Experimental Settings In our experiments the system is evaluated on its ability to correctly identify the gold transliteration for each source word. We evaluated the system’s performance using two measures ado</context>
<context position="22525" citStr="Klementiev and Roth, 2006" startWordPosition="3724" endWordPosition="3727">sed learning with general and all constraints. The results of two supervised models (Goldwasser and Roth, 2008b) are also included here. Note that our unsupervised model with all constraints is competitive to the supervised model with 250 labeled examples. See the text for more comparisons and details. hinge loss as our loss function and fixed the regularization parameter C to be 0.5. 5.2 Datasets We experimented using three different target languages Russian, Chinese, and Hebrew. We used English as the source language in all these experiments. The Russian data set2, originally introduced in (Klementiev and Roth, 2006b), is comprised of temporally aligned news articles. The dataset contains 727 single word English NEs with a corresponding set of 50,648 potential Russian candidate words which include not only name entities, but also other words appearing in the news articles. The Chinese dataset is taken directly from an English-Chinese transliteration dictionary, derived from LDC Gigaword corpus3. The entire dictionary consists of 74,396 pairs of English-Chinese NEs, where Chinese NEs are written in Pinyin, a romanized spelling system of Chinese. In (Tao et al., 2006) a dataset which contains about 600 Eng</context>
<context position="23953" citStr="Klementiev and Roth, 2006" startWordPosition="3957" endWordPosition="3960">andidates which do not correspond to any of the English NE 2The corpus is available http://L2R.cs.uiuc.edu/∼cogcomp. 3http://www.ldc.upenn.edu [KR 06] + temporal information [KR 06] All Cons. + unsupervsied learning 0.9 0.8 0.7 0.6 0.5 0.4 1.1 1 4GR 0A250 labeled ex. with cons GR 0 1 250 labeled ex. w/o cons General cons + unsupervised learning All cons. + unsupervised learning 1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 M 304 Language UCDL Prev. works Rus. (ACC) 73 63 (41) (KR’06) Heb. (MRR) 0.899 0.894 (GR’08) Table 2: Comparison to previously published results. UCDL is our method, KR’06 is described in (Klementiev and Roth, 2006b) and GR’08 in (Goldwasser and Roth, 2008b). Note that our results for Hebrew are comparable with a supervised system. previously selected. The Hebrew dataset, originally introduced in (Goldwasser and Roth, 2008a), consists of 300 English-Hebrew pairs extracted from Wikipedia. 5.3 Results We begin by comparing our model to previously published models tested over the same data, in two different languages, Russian and Hebrew. For Russian, we compare to the model presented in (Klementiev and Roth, 2006b), a weakly supervised algorithm that uses both phonetic information and temporal information.</context>
<context position="25823" citStr="Klementiev and Roth, 2006" startWordPosition="4255" endWordPosition="4258"> by pairing character unigrams and bigrams). The model also uses constraints to restrict the feature extraction process, which are equivalent to the coverage constraint we described in Sec. 3.2. The results of these experiments are reported using the evaluation measures used in the original papers and are summarized in Table 2. The results show a significant improvement over the Russian data set and comparable performance to the supervised method used for Hebrew. Figure 2 describes the learning curve of our method over the Russian dataset. We compared our algorithm to two models described in (Klementiev and Roth, 2006b) - one uses only phonetic similarity and the second also considers temporal cooccurrence similarity when ranking the transliteration candidates. Both models converge after 50 iterations. When comparing our model to their models, we found that even though our model ignores the temporal information it achieves better results and converges after fewer iterations. Their results report a significant improvement when using temporal information - improving an ACC score of 41% without temporal information to 63% when using it. Since the temporal information is orthogonal to the transliteration model</context>
<context position="27766" citStr="Klementiev and Roth, 2006" startWordPosition="4561" endWordPosition="4564">work consist of - a romanization table, general and language specific transliteration constraints. To reveal the impact of each component we experimented with different combination of the components, resulting in three different testing configurations. Romanization Table: We initialized the weight vector using a romanization table and did not use any constraints. To generate features we use a modified version of our AF operator (see Sec. 3), which generates features by coupling characters in close positions in the source and target words. This configuration is equivalent to the model used in (Klementiev and Roth, 2006b). +General Constraints: This configuration uses the romanization table for initializing the weight vector and general transliteration constraints (see Sec. 3.2) for feature extraction. +All Constraints: This configuration uses language specific constraints in addition to the gen305 Settings Chinese Russian Hebrew Romanization table 0.019 (0.5) 0.034 (1.0) 0.046 (1.7) Romanization table +learning 0.020 (0.3) 0.048 (1.3) 0.028 (0.7) +Gen Constraints 0.746 (67.1) 0.809 (74.3) 0.533 (45.0) +Gen Constraints +learning 0.867 (82.2) 0.906 (86.7) 0.834 (76.0) +All Constraints 0.801 (73.4) 0.849 (79.3</context>
</contexts>
<marker>Klementiev, Roth, 2006</marker>
<rawString>A. Klementiev and D. Roth. 2006b. Weakly supervised named entity transliteration and discovery from multilingual comparable corpora. In Proc. of the Annual Meeting of the Association of Computational Linguistics (ACL), pages USS,TL,ADAPT, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
<author>J Graehl</author>
</authors>
<date>1998</date>
<booktitle>Machine transliteration. Computational Linguistics,</booktitle>
<pages>599--612</pages>
<contexts>
<context position="1410" citStr="Knight and Graehl, 1998" startWordPosition="189" endWordPosition="192">ments show that constraint driven learning can significantly outperform existing unsupervised models and achieve competitive results to existing supervised models. 1 Introduction Named entity (NE) transliteration is the process of transcribing a NE from a source language to some target language while preserving its pronunciation in the original language. Automatic NE transliteration is an important component in many cross-language applications, such as Cross-Lingual Information Retrieval (CLIR) and Machine Translation(MT) (Hermjakob et al., 2008; Klementiev and Roth, 2006a; Meng et al., 2001; Knight and Graehl, 1998). It might initially seem that transliteration is an easy task, requiring only finding a phonetic mapping between character sets. However simply matching every source language character to its target language counterpart is not likely to work well as in practice this mapping depends on the context the characters appear in and on transliteration conventions which may change across domains. As a result, current approaches employ machine learning methods which, given enough labeled training data learn how to determine whether a pair of words constitute a transliteration pair. These methods typica</context>
<context position="5084" citStr="Knight and Graehl, 1998" startWordPosition="763" endWordPosition="766">ion with constraints provided us with a robust transliteration system which significantly outperforms existing unsupervised approaches and achieves comparable performance to supervised methods. The rest of the paper is organized as follows. Sec. 2 briefly examines more related work. Sec. 3 explains our model and Sec. 4 provide a linguistic intuition for it. Sec. 5 describes our experiments and evaluates our results followed by sec. 6 which concludes our paper. 2 Related Works Transliteration methods typically fall into two categories: generative approaches (Li et al., 2004; Jung et al., 2000; Knight and Graehl, 1998) that try to produce the target transliteration given a source language NE, and discriminative approaches (Goldwasser and Roth, 2008b; Bergsma and Kondrak, 2007; Sproat et al., 2006; Klementiev and Roth, 2006a), that try to identify the correct transliteration for a word in the source language given several candidates in the target language. Generative methods encounter the Out-Of-Vocabulary (OOV) problem and require substantial amounts of training data and knowledge of the source and target languages. Discriminative approaches, when used to for discovering NE in a bilingual corpora avoid the </context>
</contexts>
<marker>Knight, Graehl, 1998</marker>
<rawString>K. Knight and J. Graehl. 1998. Machine transliteration. Computational Linguistics, pages 599–612.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Li</author>
<author>M Zhang</author>
<author>J Su</author>
</authors>
<title>A joint source-channel model for machine transliteration.</title>
<date>2004</date>
<booktitle>In Proc. of the Annual Meeting of the Association of Computational Linguistics (ACL),</booktitle>
<pages>159--166</pages>
<location>Barcelona, Spain,</location>
<contexts>
<context position="5039" citStr="Li et al., 2004" startWordPosition="755" endWordPosition="758">ing this simple resource in conjunction with constraints provided us with a robust transliteration system which significantly outperforms existing unsupervised approaches and achieves comparable performance to supervised methods. The rest of the paper is organized as follows. Sec. 2 briefly examines more related work. Sec. 3 explains our model and Sec. 4 provide a linguistic intuition for it. Sec. 5 describes our experiments and evaluates our results followed by sec. 6 which concludes our paper. 2 Related Works Transliteration methods typically fall into two categories: generative approaches (Li et al., 2004; Jung et al., 2000; Knight and Graehl, 1998) that try to produce the target transliteration given a source language NE, and discriminative approaches (Goldwasser and Roth, 2008b; Bergsma and Kondrak, 2007; Sproat et al., 2006; Klementiev and Roth, 2006a), that try to identify the correct transliteration for a word in the source language given several candidates in the target language. Generative methods encounter the Out-Of-Vocabulary (OOV) problem and require substantial amounts of training data and knowledge of the source and target languages. Discriminative approaches, when used to for dis</context>
</contexts>
<marker>Li, Zhang, Su, 2004</marker>
<rawString>H. Li, M. Zhang, and J. Su. 2004. A joint source-channel model for machine transliteration. In Proc. of the Annual Meeting of the Association of Computational Linguistics (ACL), pages 159–166, Barcelona, Spain, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Meng</author>
<author>W Lo</author>
<author>B Chen</author>
<author>K Tang</author>
</authors>
<title>Generating phonetic cognates to handle named entities in english-chinese cross-langauge spoken document retreival.</title>
<date>2001</date>
<booktitle>In Proceedings of the Automatic Speech Recognition and Understanding Workshop,</booktitle>
<pages>389--397</pages>
<contexts>
<context position="1384" citStr="Meng et al., 2001" startWordPosition="185" endWordPosition="188"> Hebrew. Our experiments show that constraint driven learning can significantly outperform existing unsupervised models and achieve competitive results to existing supervised models. 1 Introduction Named entity (NE) transliteration is the process of transcribing a NE from a source language to some target language while preserving its pronunciation in the original language. Automatic NE transliteration is an important component in many cross-language applications, such as Cross-Lingual Information Retrieval (CLIR) and Machine Translation(MT) (Hermjakob et al., 2008; Klementiev and Roth, 2006a; Meng et al., 2001; Knight and Graehl, 1998). It might initially seem that transliteration is an easy task, requiring only finding a phonetic mapping between character sets. However simply matching every source language character to its target language counterpart is not likely to work well as in practice this mapping depends on the context the characters appear in and on transliteration conventions which may change across domains. As a result, current approaches employ machine learning methods which, given enough labeled training data learn how to determine whether a pair of words constitute a transliteration </context>
</contexts>
<marker>Meng, Lo, Chen, Tang, 2001</marker>
<rawString>H. Meng, W. Lo, B. Chen, and K. Tang. 2001. Generating phonetic cognates to handle named entities in english-chinese cross-langauge spoken document retreival. In Proceedings of the Automatic Speech Recognition and Understanding Workshop, pages 389–397.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Riedel</author>
<author>J Clarke</author>
</authors>
<title>Incremental integer linear programming for non-projective dependency parsing.</title>
<date>2006</date>
<booktitle>In Proc. of the Conference on Empirical Methods for Natural Language Processing (EMNLP),</booktitle>
<pages>129--137</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="6499" citStr="Riedel and Clarke, 2006" startWordPosition="980" endWordPosition="983">ss data to converge. Training the transliteration model is typically done under supervised settings (Bergsma and Kondrak, 2007; Goldwasser and Roth, 2008b), or weakly supervised settings with additional temporal information (Sproat et al., 2006; Klementiev and Roth, 2006a). Our work differs from these works in that it is completely unsupervised and makes no assumptions about the training data. Incorporating knowledge encoded as constraints into learning problems has attracted a lot of attention in the NLP community recently. This has been shown both in supervised settings (Roth and Yih, 2004; Riedel and Clarke, 2006) and unsupervised settings (Haghighi and Klein, 2006; Chang et al., 2007) in which constraints are used to bootstrap the model. (Chang et al., 2007) describes an unsupervised training of a Constrained Conditional Model (CCM), a general framework for combining statistical models with declarative constraints. We extend this work to include constraints over possible assignments to latent variables which, in turn, define the underlying representation for the learning problem. In the transliteration community there are several works (Ristad and Yianilos, 1998; Bergsma and Kondrak, 2007; Goldwasser </context>
</contexts>
<marker>Riedel, Clarke, 2006</marker>
<rawString>S. Riedel and J. Clarke. 2006. Incremental integer linear programming for non-projective dependency parsing. In Proc. of the Conference on Empirical Methods for Natural Language Processing (EMNLP), pages 129– 137, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E S Ristad</author>
<author>P N Yianilos</author>
</authors>
<title>Learning string edit distance.</title>
<date>1998</date>
<journal>IEEE Transactions on Pattern Recognition and Machine Intelligence,</journal>
<volume>20</volume>
<issue>5</issue>
<contexts>
<context position="7059" citStr="Ristad and Yianilos, 1998" startWordPosition="1064" endWordPosition="1067">supervised settings (Roth and Yih, 2004; Riedel and Clarke, 2006) and unsupervised settings (Haghighi and Klein, 2006; Chang et al., 2007) in which constraints are used to bootstrap the model. (Chang et al., 2007) describes an unsupervised training of a Constrained Conditional Model (CCM), a general framework for combining statistical models with declarative constraints. We extend this work to include constraints over possible assignments to latent variables which, in turn, define the underlying representation for the learning problem. In the transliteration community there are several works (Ristad and Yianilos, 1998; Bergsma and Kondrak, 2007; Goldwasser and Roth, 2008b) that show how the feature representation of a word pair can be restricted to facilitate learning a string similarity model. We follow the approach discussed in (Goldwasser and Roth, 2008b), which considers the feature representation as a structured prediction problem and finds the set of optimal assignments (or feature activations), under a set of legitimacy constraints. This approach stresses the importance of interaction between learning and inference, as the model iteratively uses inference to improve the sample representation for the</context>
</contexts>
<marker>Ristad, Yianilos, 1998</marker>
<rawString>E. S. Ristad and P. N. Yianilos. 1998. Learning string edit distance. IEEE Transactions on Pattern Recognition and Machine Intelligence, 20(5):522–532, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roth</author>
<author>W Yih</author>
</authors>
<title>A linear programming formulation for global inference in natural language tasks. pages 1–8. Association for Computational Linguistics.</title>
<date>2004</date>
<contexts>
<context position="6473" citStr="Roth and Yih, 2004" startWordPosition="976" endWordPosition="979">uire considerably less data to converge. Training the transliteration model is typically done under supervised settings (Bergsma and Kondrak, 2007; Goldwasser and Roth, 2008b), or weakly supervised settings with additional temporal information (Sproat et al., 2006; Klementiev and Roth, 2006a). Our work differs from these works in that it is completely unsupervised and makes no assumptions about the training data. Incorporating knowledge encoded as constraints into learning problems has attracted a lot of attention in the NLP community recently. This has been shown both in supervised settings (Roth and Yih, 2004; Riedel and Clarke, 2006) and unsupervised settings (Haghighi and Klein, 2006; Chang et al., 2007) in which constraints are used to bootstrap the model. (Chang et al., 2007) describes an unsupervised training of a Constrained Conditional Model (CCM), a general framework for combining statistical models with declarative constraints. We extend this work to include constraints over possible assignments to latent variables which, in turn, define the underlying representation for the learning problem. In the transliteration community there are several works (Ristad and Yianilos, 1998; Bergsma and </context>
<context position="11683" citStr="Roth and Yih, 2004" startWordPosition="1851" endWordPosition="1854">(vs, vt)). 3. D = {(+, F(vs, vt*)) |Vvs E Vs}. 4. Vvs E Vs, vt E Vt, if vt =� vt and score(F(vs, vt)) =� −oo, then D = D U {(−, F(vs, vt))}. 5. W +— train(D) end Algorithm 1: UCDL Transliteration Framework. In the rest of this section we explain this process in detail. We define the feature extraction inference process in Sec. 3.1, the constraints used in Sec. 3.2 and the inference algorithm in Sec. 3.3. The linguistic intuition for our model is described in Sec. 4. 3.1 Finding Feature Representation as Constrained Optimization We use the formulation of Constrainted Conditional Models (CCMs) (Roth and Yih, 2004; Roth and Yih, 2007; Chang et al., 2008). Previous work on CCM models dependencies between different decisions in structured prediction problems. Transliteration discovery is a binary classification problem, however, 301 the underlying representation of each sample can be modeled as a CCM, defined as a set of latent variables corresponding to the set of all possible features for a given sample. The dependencies between the features are captured using constraints. Given a word pair, the set of all possible features consists of all character mappings from the source word to the target word. Sin</context>
</contexts>
<marker>Roth, Yih, 2004</marker>
<rawString>D. Roth and W. Yih. 2004. A linear programming formulation for global inference in natural language tasks. pages 1–8. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roth</author>
<author>W Yih</author>
</authors>
<title>Global inference for entity and relation identification via a linear programming formulation.</title>
<date>2007</date>
<booktitle>In Lise Getoor and Ben Taskar, editors, Introduction to Statistical Relational Learning.</booktitle>
<publisher>MIT Press.</publisher>
<contexts>
<context position="11703" citStr="Roth and Yih, 2007" startWordPosition="1855" endWordPosition="1858">+, F(vs, vt*)) |Vvs E Vs}. 4. Vvs E Vs, vt E Vt, if vt =� vt and score(F(vs, vt)) =� −oo, then D = D U {(−, F(vs, vt))}. 5. W +— train(D) end Algorithm 1: UCDL Transliteration Framework. In the rest of this section we explain this process in detail. We define the feature extraction inference process in Sec. 3.1, the constraints used in Sec. 3.2 and the inference algorithm in Sec. 3.3. The linguistic intuition for our model is described in Sec. 4. 3.1 Finding Feature Representation as Constrained Optimization We use the formulation of Constrainted Conditional Models (CCMs) (Roth and Yih, 2004; Roth and Yih, 2007; Chang et al., 2008). Previous work on CCM models dependencies between different decisions in structured prediction problems. Transliteration discovery is a binary classification problem, however, 301 the underlying representation of each sample can be modeled as a CCM, defined as a set of latent variables corresponding to the set of all possible features for a given sample. The dependencies between the features are captured using constraints. Given a word pair, the set of all possible features consists of all character mappings from the source word to the target word. Since in many cases the</context>
</contexts>
<marker>Roth, Yih, 2007</marker>
<rawString>D. Roth and W. Yih. 2007. Global inference for entity and relation identification via a linear programming formulation. In Lise Getoor and Ben Taskar, editors, Introduction to Statistical Relational Learning. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Sproat</author>
<author>T Tao</author>
<author>C Zhai</author>
</authors>
<title>Named entity transliteration with comparable corpora.</title>
<date>2006</date>
<booktitle>In Proc. of the Annual Meeting of the Association of Computational Linguistics (ACL),</booktitle>
<pages>73--80</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="5265" citStr="Sproat et al., 2006" startWordPosition="792" endWordPosition="795">ethods. The rest of the paper is organized as follows. Sec. 2 briefly examines more related work. Sec. 3 explains our model and Sec. 4 provide a linguistic intuition for it. Sec. 5 describes our experiments and evaluates our results followed by sec. 6 which concludes our paper. 2 Related Works Transliteration methods typically fall into two categories: generative approaches (Li et al., 2004; Jung et al., 2000; Knight and Graehl, 1998) that try to produce the target transliteration given a source language NE, and discriminative approaches (Goldwasser and Roth, 2008b; Bergsma and Kondrak, 2007; Sproat et al., 2006; Klementiev and Roth, 2006a), that try to identify the correct transliteration for a word in the source language given several candidates in the target language. Generative methods encounter the Out-Of-Vocabulary (OOV) problem and require substantial amounts of training data and knowledge of the source and target languages. Discriminative approaches, when used to for discovering NE in a bilingual corpora avoid the OOV problem by choosing the transliteration candidates from the corpora. These methods typically make very little assumptions about the source and target languages and require consi</context>
<context position="20929" citStr="Sproat et al., 2006" startWordPosition="3449" endWordPosition="3452">ormation. Our best model, the unsupervised learning with all constraints, outperforms both models in (Klementiev and Roth, 2006b), even though we do not use any temporal information. guages: Russian, Chinese, and Hebrew, and compared our results to previously published results. 5.1 Experimental Settings In our experiments the system is evaluated on its ability to correctly identify the gold transliteration for each source word. We evaluated the system’s performance using two measures adopted in many transliteration works. The first one is Mean Reciprocal Rank (MRR), used in (Tao et al., 2006; Sproat et al., 2006), which is the average of the multiplicative inverse of the rank of the correct answer. Formally, Let n be the number of source NEs. Let GoldRank(i) be the rank the algorithm assigns to the correct transliteration. Then, MRR is defined by: 1 n 1 MRR = n Z=1 goldRank(i) Another measure is Accuracy (ACC) used in (Klementiev and Roth, 2006a; Goldwasser and Roth, 2008a), which is the percentage of the top rank candidates being the gold transliteration. In our implementation we used the support vector machine (SVM) learning algorithm with linear kernel as our underlying learning algorithm (mentione</context>
<context position="26873" citStr="Sproat et al., 2006" startWordPosition="4417" endWordPosition="4420">l information - improving an ACC score of 41% without temporal information to 63% when using it. Since the temporal information is orthogonal to the transliteration model, our model should similarly benefit from incorporating the temporal information. Figure 3 compares the learning curve of our method to an existing supervised method over the Hebrew data and shows we get comparable results. Unfortunately, we could not find a published Chinese dataset. However, our system achieved similar results to other systems, over a different dataset with similar number of training examples. For example, (Sproat et al., 2006) presents a supervised system that achieves a MRR score of 0.89, when evaluated over a dataset consisting of 400 English NE and 627 Chinese words. Our results for a different dataset of similar size are reported in Table 3. 5.4 Analysis The resources used in our framework consist of - a romanization table, general and language specific transliteration constraints. To reveal the impact of each component we experimented with different combination of the components, resulting in three different testing configurations. Romanization Table: We initialized the weight vector using a romanization table</context>
</contexts>
<marker>Sproat, Tao, Zhai, 2006</marker>
<rawString>R. Sproat, T. Tao, and C. Zhai. 2006. Named entity transliteration with comparable corpora. In Proc. of the Annual Meeting of the Association of Computational Linguistics (ACL), pages 73–80, Sydney, Australia, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Tao</author>
<author>S Yoon</author>
<author>A Fister</author>
<author>R Sproat</author>
<author>C Zhai</author>
</authors>
<title>Unsupervised named entitly transliteration using temporal and phonetic correlation.</title>
<date>2006</date>
<booktitle>In Proc. of the Conference on Empirical Methods for Natural Language Processing (EMNLP),</booktitle>
<pages>250--257</pages>
<contexts>
<context position="20907" citStr="Tao et al., 2006" startWordPosition="3445" endWordPosition="3448">f the temporal information. Our best model, the unsupervised learning with all constraints, outperforms both models in (Klementiev and Roth, 2006b), even though we do not use any temporal information. guages: Russian, Chinese, and Hebrew, and compared our results to previously published results. 5.1 Experimental Settings In our experiments the system is evaluated on its ability to correctly identify the gold transliteration for each source word. We evaluated the system’s performance using two measures adopted in many transliteration works. The first one is Mean Reciprocal Rank (MRR), used in (Tao et al., 2006; Sproat et al., 2006), which is the average of the multiplicative inverse of the rank of the correct answer. Formally, Let n be the number of source NEs. Let GoldRank(i) be the rank the algorithm assigns to the correct transliteration. Then, MRR is defined by: 1 n 1 MRR = n Z=1 goldRank(i) Another measure is Accuracy (ACC) used in (Klementiev and Roth, 2006a; Goldwasser and Roth, 2008a), which is the percentage of the top rank candidates being the gold transliteration. In our implementation we used the support vector machine (SVM) learning algorithm with linear kernel as our underlying learni</context>
<context position="23086" citStr="Tao et al., 2006" startWordPosition="3811" endWordPosition="3814">et2, originally introduced in (Klementiev and Roth, 2006b), is comprised of temporally aligned news articles. The dataset contains 727 single word English NEs with a corresponding set of 50,648 potential Russian candidate words which include not only name entities, but also other words appearing in the news articles. The Chinese dataset is taken directly from an English-Chinese transliteration dictionary, derived from LDC Gigaword corpus3. The entire dictionary consists of 74,396 pairs of English-Chinese NEs, where Chinese NEs are written in Pinyin, a romanized spelling system of Chinese. In (Tao et al., 2006) a dataset which contains about 600 English NEs and 700 Chinese candidates is used. Since the dataset is not publicly available, we created a dataset in a similar way. We randomly selected approximately 600 NE pairs and then added about 100 candidates which do not correspond to any of the English NE 2The corpus is available http://L2R.cs.uiuc.edu/∼cogcomp. 3http://www.ldc.upenn.edu [KR 06] + temporal information [KR 06] All Cons. + unsupervsied learning 0.9 0.8 0.7 0.6 0.5 0.4 1.1 1 4GR 0A250 labeled ex. with cons GR 0 1 250 labeled ex. w/o cons General cons + unsupervised learning All cons. +</context>
</contexts>
<marker>Tao, Yoon, Fister, Sproat, Zhai, 2006</marker>
<rawString>T. Tao, S. Yoon, A. Fister, R. Sproat, and C. Zhai. 2006. Unsupervised named entitly transliteration using temporal and phonetic correlation. In Proc. of the Conference on Empirical Methods for Natural Language Processing (EMNLP), pages 250–257.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Yoon</author>
<author>K Kim</author>
<author>R Sproat</author>
</authors>
<title>Multilingual transliteration using feature based phonetic method.</title>
<date>2007</date>
<booktitle>In Proc. of the Annual Meeting of the Association of Computational Linguistics (ACL),</booktitle>
<pages>112--119</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="18792" citStr="Yoon et al., 2007" startWordPosition="3099" endWordPosition="3102">ptured by language specific sound change patterns. Phonemes Constraints Vowel i → y; u → w; a → a Nasal m ↔ m; m, n ← m Approximant r → l; l, r ↔ l l ← l; w → h, w, f h, o, u, v ← w; y → y Fricative v → w, b, f s → s, x, z; s, c ← s Plosive p → b, p; p ← p b → b; t ← t t, d ← d; q → k Table 1: All language specific constraints used in our English to Chinese transliteration (see Sec. 3.2 for more details). Constraints in boldface apply to all positions, the rest apply only to characters appearing in initial position. These patterns have been used by other systems as features or pseudofeatures (Yoon et al., 2007). However, in our system these language specific ruleof-thumbs are systematically used as constraints to exclude impossible alignments and therefore generate better features for learning. We listed in Table 1 all 20 language specific constraints we used for Chinese. There is a total of 24 constraints for Hebrew and 17 for Russian. The constraints in Table 1 indicate a systematic sound mapping between English and Chinese unigram character mappings. Arranged by manners of articulation each row of the table indicates the sound change tendency among vowels, nasals, approximants (retroflex and glid</context>
</contexts>
<marker>Yoon, Kim, Sproat, 2007</marker>
<rawString>S. Yoon, K. Kim, and R. Sproat. 2007. Multilingual transliteration using feature based phonetic method. In Proc. of the Annual Meeting of the Association of Computational Linguistics (ACL), pages 112–119, Prague, Czech Republic, June.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>