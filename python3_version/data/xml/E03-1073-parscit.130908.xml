<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003348">
<title confidence="0.781498">
Detecting Novel Compounds: The Role of Distributional Evidence
</title>
<author confidence="0.973714">
Mirella Lapata
</author>
<affiliation confidence="0.997692">
Department of Computer Science
University of Sheffield
</affiliation>
<address confidence="0.923253">
Regent Court, 211 Portobello Street
Sheffield 51 4DP, UK
</address>
<email confidence="0.999108">
mlap@dcs.shef.ac.uk
</email>
<author confidence="0.990648">
Alex Lascarides
</author>
<affiliation confidence="0.9978295">
School of Informatics
The University of Edinburgh
</affiliation>
<address confidence="0.835366">
2 Buccleuch Place
Edinburgh EH8 9LW, UK
</address>
<email confidence="0.999005">
alex@inf.ed.ac.uk
</email>
<sectionHeader confidence="0.987644" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999895166666667">
Research on the discovery of terms from
corpora has focused on word sequences
whose recurrent occurrence in a corpus
is indicative of their terminological sta-
tus, and has not addressed the issue of
discovering terms when data is sparse.
This becomes apparent in the case of
noun compounding, which is extremely
productive: more than half of the candi-
date compounds extracted from a corpus
are attested only once. We show how ev-
idence about established (i.e., frequent)
compounds can be used to estimate fea-
tures that can discriminate rare valid
compounds from rare nonce terms in ad-
dition to a variety of linguistic features
than can be easily gleaned from corpora
without relying on parsed text.
</bodyText>
<sectionHeader confidence="0.995598" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.963081682539683">
The nature and properties of compounds have
been studied at length in the theoretical linguistics
literature. It is a well-known fact that compound
noun formation in English is relatively produc-
tive (see (1)). Although compounds are typically
binary (see (1a,b)), they can be also longer than
two words (see (le)). Compounds are commonly
written as a concatenation of words (see (1a,b)), or
as single words (see (lc)), sometimes a hyphen is
also used (see (le)).
income tax
AT &amp; T headquarters
bathroom
public-relations
income-tax relief
The use of noun compounds is frequent not
only in technical writing and newswire text
(McDonald, 1982) but also in fictional prose
(Leonard, 1984), and spoken language (Liberman
and Sproat, 1992). Novel compounds are used as
a text compression device (Marsh, 1984), i.e., to
pack meaning into a minimal amount of linguistic
structure, as a deictic device, or as a means to clas-
sify an entity which has no specific name (Down-
ing, 1977).
Computational investigations of compound
nouns have concentrated on their automatic ac-
quisition from corpora, syntactic disambiguation
(i.e., determine the structure of compounds like
income tax relief), and semantic interpretation
(i.e., determine the semantic relation between in-
come and tax in income tax). The acquisition of
compound nouns is usually subsumed under the
general discovery of terms from corpora. Terms
are typically acquired by either symbolic or sta-
tistical means. Under a symbolic approach, can-
didate terms are extracted from the corpus us-
ing surface syntactic analysis (Lauer, 1995; Juste-
son and Katz, 1995; Bourigault and Jacquemin,
1999) and sometimes are further submitted to ex-
perts for manual inspection. The approach typi-
cally assumes no prior terminological knowledge,
although Jacquemin (1996) proposed the detection
of terminological variants in a corpus by making
use of lists of existing terms.
The main assumption underlying the statistical
approach to term acquisition is that lexically as-
sociated words tend to appear together more of-
ten than expected on the basis of their individual
occurrence frequencies. Once candidate terms are
detected in the corpus, statistical tests (e.g., mu-
tual information, the log-likelihood ratio) are used
to determine which co-occurrences are valid terms
(see Daille, 1996 and Manning and Schiitze, 1999
for overviews).
Most of the statistical tests proposed in the lit-
erature rely on the fact that candidate terms will
occur frequently in the corpus (Justeson and Katz,
1995) or, when hypothesis testing is applied, on
the assumption that two words form a term when
they co-occur more often than chance (Church and
Hanks, 1990). This means that statistical tests can-
not be applied reliably for candidate compounds
</bodyText>
<page confidence="0.995275">
235
</page>
<note confidence="0.580196">
CoocF BNC Sample Ace
</note>
<table confidence="0.97932325">
&gt;4 52,832 800 93.5
&gt; 1 160,214 800 82.0
&gt; 1 510,673 800 71.0
= 1 350,459 800 57.7
</table>
<tableCaption confidence="0.903322">
Table 1: Relation of noun co-occurrence frequency
with accuracy
</tableCaption>
<bodyText confidence="0.9988065">
with co-occurrence frequency of one and can-
not be used to distinguish rare but valid noun
compounds from rare but nonce noun sequences
(compare (2b) and (2a) which are extracted from
the British National Corpus; both bracketed terms
were found in the corpus once.).
</bodyText>
<listItem confidence="0.8905082">
(2) a. Although no one will doubt their possibilities
for elegance and robustness, sitting on a solid
[woodN seatN1 can test the limits of comfort af-
ter quite a short time and woven seats are little
better.
</listItem>
<bodyText confidence="0.947989">
b. The use of the [termN shilling] derives from a
19th century system of invoicing beer according
to its gravity.
In this paper we present a method that attempts
to distinguish compounds from non-compounds in
cases where very little direct evidence is found in
the corpus and therefore the assumptions under-
lying lexical association scores do not hold. We
restrict our attention to compounds formed by a
concatenation of two nouns (see (1a)) and investi-
gate how surface syntactic and semantic cues can
be used to discriminate valid compounds from rare
nonce terms.
</bodyText>
<sectionHeader confidence="0.979964" genericHeader="method">
2 Compound Noun Extraction
</sectionHeader>
<bodyText confidence="0.999428666666667">
The extraction of two word compounds (as op-
posed to terms) from a corpus has been previously
addressed by Lauer (1995) who proposed a heuris-
tic which simply looks for consecutive pairs of
nouns which are neither preceded nor succeeded
by a noun (see (3)).
</bodyText>
<listItem confidence="0.77512">
(3) C = {(4&apos;2, w3) WI W2 W3 W4; , w40 N; W2, W3 E
</listItem>
<bodyText confidence="0.999970455882353">
Here, wi w2 1423 1424 denotes the occurrence of a se-
quence of four words in the corpus and N is a pre-
defined set of unambiguous nouns. Lauer (1995)
used a corpus derived from the Grolier Multime-
dia Encyclopedia (8M words) for his study and a
predefined list of 90,000 nouns which had no part-
of-speech ambiguity. He reports an accuracy of
97.9% on a sample of 1,068 noun-noun sequences.
Note that the above heuristic incorrectly classifies
(2b) as a valid compound.
We replicated Lauer&apos;s (1995) study on the
British National Corpus (BNC), a 100 million
word collection of samples of written and spo-
ken language from a wide range of sources de-
signed to represent a wide cross-section of cur-
rent British English (Burnard, 1995). An impor-
tant difference, however, between our study and
Lauer&apos;s is that we used a POS-tagged version of
the BNC. Noun sequences were identified using
Gsearch (Corley et al., 2001), a chart parser which
detects syntactic patterns in a tagged corpus by
exploiting a user-specified context free grammar
and a syntactic query. Gsearch was run on a lem-
matised version of the BNC in order to compile
a comprehensive count of all nouns occurring in
a head-modifier relationship. Tokens containing
noun sequences of length two were classified as
candidate compounds unless: (a) the two consecu-
tive nouns were preceded or succeeded by a noun
(e.g., light bulb phobia, see (3)) and (b) either noun
was a number (e.g., flour 100g). This procedure
resulted in a total of 1,624,915 tokens consisting
of 510,673 distinct types of candidate compounds.
We evaluated Lauer&apos;s (1995) heuristic as fol-
lows: 800 tokens were randomly selected from the
noun-noun sequences that were classified as com-
pounds; accordingly, a random sample of 800 to-
kens was selected from the sequences that were
discarded as non-compounds (in order to examine
whether valid compounds are missed). The noun
sequences contained in the samples were manually
inspected within context using the corpus concor-
dance tool Xkwic (Christ, 1995) and classified as
to whether they formed a valid compound or not.
Lauer&apos;s heuristic expectedly achieved a lower ac-
curacy on the POS-tagged corpus. This was 71%
using cLAws4 (Leech et al., 1994), a probabilis-
tic part-of-speech tagger, with error rate rang-
ing from 3% to 4% and 70.3% using Elworthy&apos;s
(1994) HMM part-of-speech tagger, with an error
rate of approximately 4%. The heuristic reached
an accuracy of 98.8% in rejecting noun sequences
as non-compounds.
We further examined how the accuracy of the
heuristic varies when different thresholds are im-
posed on the frequency of the candidate com-
pounds (see Table 1). For example, when we con-
sider noun-noun sequences that appear in the BNC
more than once (CoocF &gt; 1) the heuristic&apos;s accu-
racy is increased by 11.0%. However, the number
of potential compounds is reduced by a factor of
three. The majority of the candidate compounds
extracted from the corpus are hapaxes (i.e., words
that occurred only once). These represent 68.6%
of the noun-noun sequences retrieved from the
BNC; 57.7% of the hapaxes are valid compounds.
Analysis of the misclassifications in the case of
hapaxes revealed that 61.9% are tagging errors
</bodyText>
<page confidence="0.994295">
236
</page>
<table confidence="0.8824504">
f(ni) f (n2) p(K n1 ) P(M112) f (c , (72)
cocaine customer 71 159 1 .18 285.85
baby calf 740 22 .91 .15 35.13
people excitement 1,823 9 .45 1 4.98
may push 0 35 0 .43 76.93
</table>
<tableCaption confidence="0.997993">
Table 2: Feature values for noun-noun sequences (with CoocF = 1)
</tableCaption>
<bodyText confidence="0.9999145">
(i.e., if tagging was perfect these sequences would
have been excluded), 30.6% are due to the absence
of structural information (i.e., they would have
been ruled out if accurate parsing information was
available), 5.30% are acronyms, and 2.20% are
foreign terms or typographical mistakes.
In the next sections we turn to hapaxes and
propose a method that distinguishes valid com-
pounds from nonce noun sequences by modeling
the distributional tendencies observed in lexical-
ized (i.e., frequent) compounds. In Section 3 we
present and motivate these features. Section 4 de-
tails our machine learning experiments and Sec-
tion 5 discusses our results.
</bodyText>
<sectionHeader confidence="0.998541" genericHeader="method">
3 Features for Discovering Compounds
</sectionHeader>
<bodyText confidence="0.99983272972973">
In this section we introduce the features used in the
machine learning experiments described in Sec-
tion 4 and the motivation behind their selection.
In our experiments we make use of numeric fea-
tures (i.e., frequency, probability) as well as cate-
gorical features (i.e., the context surrounding can-
didate noun-noun sequence). All the numeric fea-
tures detailed below were estimated from a corpus
consisting of noun-noun sequences extracted from
the POS-tagged BNC (via Lauer&apos;s 1995 heuristic)
with CoocF greater than four (52,832 in total, see
Table 1). 93.5% of these sequences are valid com-
pounds and can therefore provide reliable infor-
mation about the likelihood of a given noun as a
compound head or modifier.
Noun frequency. Given a noun-noun sequence
ni n2 we look at whether the frequency of the
head n2, f (n2), or the frequency of the modifier
ni, f (ni), are reliable indicators for distinguishing
compounds from non-compounds. Consider for
example the compound cocaine customer which is
attested in the BNC only once. The word cocaine
is attested as a modifier 71 times and the word cus-
tomer is attested as a head 159 (see Table 2). Com-
pare now cocaine customer to people excitement
which is not a valid compound and is also found
in the BNC once (the sequence is attested in the
sentence For some people excitement is only pos-
sible outside marriage.). The modifier frequency
f (people) is 1,823 whereas the head frequency
f (excitement) is nine. Clearly, excitement is less
likely to be a compound head when compared to
customer (see Table 2).
Probability. Given a noun-noun sequence ni n2
we investigate whether it is likely for n2 to be a
head and for fli to be a modifier. We express these
quantities as follows:
</bodyText>
<equation confidence="0.999690571428571">
P(Mln2) = f
(
M
7)
(4)
f (ni,H)
P(1-11n1) = f(no (5)
</equation>
<bodyText confidence="0.99776115625">
Here, f(M,n2) = En, f (ni ,n2) and f(ni ,H) =
f (ni n2). Equation (4) expresses the likeli-
hood of n2 as a head (preceded by any noun mod-
ifier) and equation (5) expresses the likelihood of
ni as a modifier (followed by any noun head). We
estimate f (M, n2) and f (n H) from the reliable
noun-noun sequences attested previously in the
corpus (CoocF &gt; 4). The frequencies f (ni) and
f (n2) are the number of times we see ni and n2 in
our estimation corpus independently of their posi-
tion (i.e., independently of whether they are heads
or modifiers).
Consider the compounds cocaine customer and
baby calf in Table 2. The likelihood of the words
cocaine and baby to be found in a modifier posi-
tion is very high (1 and .91, respectively). Contrast
this with the sequence may push which is the re-
sult of a tagging mistake (i.e., both may and push
are annotated as nouns in the sentence Their dif-
ferent responsibilities in relation to the public may
push them in opposite directions): the likelihood
of the word may to be found in a modifier posi-
tion is zero. Note further that push can be a noun
(denoting the act of pushing) and therefore it is
not entirely unlikely to be found in a head position
(see Table 2). Note also that the fact that may push
is classified as a potential compound indicates that
the preceding word public was mistagged as well.
Concept frequency. Linguistic models of com-
pound noun formation typically involve a hierar-
chical structure of lexical rules, which capture the
regularities of compound noun formation while
</bodyText>
<page confidence="0.990214">
237
</page>
<table confidence="0.997687625">
(c1,c2) f(ci,c2) Examples
(substance, obj ect) 604.7 iron table
(act, social group) 403.0 mining family
(entity, location) 382.4 girls school
(group. relation) 267.6 world language
(communication, act) 231.1 speech treatment
(person, artef act) 162.1 developer&apos;s kit
(institution, person) 38.7 bank spokesman
</table>
<tableCaption confidence="0.999947">
Table 3: Estimated concept pair frequencies
</tableCaption>
<bodyText confidence="0.999923491525424">
also ruling out certain compounds as candidates
(Pustejovsky, 1995; Copestake and Lascarides,
1997). Each lexical rule takes a pair of nouns of
certain semantic type as input, and the output of
the rule is a compound noun whose semantic rep-
resentation stipulates the relation between a mod-
ifier and its head. For example, the compounds
metal tube, leather belt and tin cup are the result
of a lexical rule that combines a noun denoting a
substance and a noun denoting an artefact to yield
a compound denoting the artefact made of the sub-
stance.
The noun frequency and probability features do
not capture meaning regularities concerning the
compounding process. For example, we would ex-
pect the combination of the concepts representing
cocaine and customer to be more likely than the
combination of the concepts representing people
and excitement. A way to obtain such likelihoods
is by substituting the head and modifier by the con-
cepts with which they are represented in a taxon-
omy. The frequency of the concept pair f (c , c2)
could then be estimated by counting the number
of times ci corresponding to n I was observed as
the modifier of c2 corresponding to the head nz.
Concept combination frequencies can be thought
of as potential lexical rules which capture regular-
ities and constraints on noun compound formation.
Counting concept frequencies would be a
straightforward task if each word was always rep-
resented in the taxonomy by a single concept or if
we had a corpus of compounds labeled explicitly
with taxonomic information. Lacking such a cor-
pus we need to take into consideration the fact that
words in a taxonomy may belong to more than one
conceptual class. Nouns in WordNet (Miller et al.,
1990) correspond to an average of 11.5 concepts
(the word return belongs to 104 distinct concep-
tual classes), whereas nouns in Roget&apos;s thesaurus
correspond to an average of 1.7 concepts (the word
point has 18 distinct concepts). Because a head or
a modifier can generally be the realization of one
of several conceptual classes, counts of modifier-
head configurations must be constructed for all po-
tential concept combinations.
To give a concrete example consider again the
compound cocaine customer. The word cocaine
has one sense in WordNet and belongs to six
conceptual classes ((hard drug), (narcotic),
(drug), (artef act), (object), (entity)). The
word customer has also one sense in Word-
Net and belongs to five conceptual classes
((consumer), (person), (life form), (causal
agent), (entity)). Since we do not know which
particular instantiation of these conceptual classes
cocaine and customer are, we will distribute the
attested frequency of cocaine customer over all
pairwise concept combinations. We formally de-
fine the set of concept combinations as follows:
</bodyText>
<equation confidence="0.977596">
c(ni,n2) = {(ci,ci) ci E classes(ni), (6)
ci e class es (n2), cil
</equation>
<bodyText confidence="0.99673348">
Here, c(ni,n2) is the set of distinct concept
pairs a given noun-noun sequence is an in-
stantiation of. Note that we impose a restric-
tion on the type of concept pairs we generate,
namely we disallow pairs with identical concepts
(see (6)). The motivation for this restriction is
twofold: first, we want to avoid overly general
concept pairs that could potentially represent any
noun-noun combination (e.g., (entity, entity),
(artef act, artef act)); second, it is implicitly
assumed in the theoretical linguistics literature
(Levi, 1978) that compounds are derived through
combinations of distinct conceptsl.
For each compound in our corpus we
generate the set of concept pairs it is po-
tentially an instantiation of. The com-
pound cocaine customer generates 29 con-
cept pairs (e.g., (artef act, consumer),
(artef act, person)). We estimate the fre-
quency of a concept pair f(ci , c2) by summing
over all noun-noun sequences ni n2 that are repre-
sentative of the concept combination (c i, c2) . We
divide the contribution of each compound nin2 by
the number of concept combinations it represents
(Resnik, 1993; Lauer, 1995):
</bodyText>
<equation confidence="0.998866">
f(ni,n2)
f(ci,c2) E (7)
c(ni,n2)1
,n2)E ;C2/
</equation>
<bodyText confidence="0.985696">
Here, f(ni,n2) is the number of times a given
noun-noun sequence was observed in the esti-
mation corpus and Ic(ni,n2)1 is the number of
conceptual pairs n n2 has. Assuming that we
want to take the compound cocaine customer
into account for estimating the frequency of the
I Dvanda or appositional compounds (e.g., mother child,
player coach) are a notable exception.
</bodyText>
<page confidence="0.98823">
238
</page>
<bodyText confidence="0.999951984375">
concept pair (art ef act, person), we will in-
crement the observed co-occurrence count of
(artef act, person) by 2+,, since cocaine cus-
tomer is represented by 29 distinct concept pairs.
Table 3 shows a random sample of the derived con-
cept pairs and their estimated frequencies.
Assume now that we want to decide whether the
sequence people excitement is a valid compound
or not. We generate all pairs of conceptual classes
represented by people excitement (see (6)). The
word people has four senses and belongs to 6 con-
ceptual classes; excitement has also four senses
and belongs to 15 classes. This means that people
excitement is potentially represented by 90 con-
cept pairs (people and excitement have no con-
cepts in common), the frequency of which can be
estimated from our corpus of valid compounds us-
ing (7). Since we do not know the actual classes
for the nouns people and excitement in the cor-
pus, we weight the contribution of each class pair
by taking the average of the estimated frequencies
for all 90 class pairs:
As shown in Table 2 people excitement is much
less likely than cocaine customer. Also note that
may push is considered fairly likely (in fact more
likely than baby calf which is a valid compound)
since both May and push can be nouns and are
listed as such in the WordNet taxonomy. The es-
timation of the concept frequencies in (7) relies
on the simplifying assumption that a given noun
is equally likely to be represented by any of its
conceptual classes. As a result, the occurrence fre-
quency of a compound is evenly distributed across
all possible concept combinations representing the
nouns forming the compound, since we cannot as-
sess (without access to a corpus annotated with
class information) which concept combinations
are likely and which are not.
Context. Although the numerical features de-
scribed above encode important information with
respect to modifier-head relations and their prop-
erties, they are blind to contextual information that
could potentially make up for tagging errors or
the lack of structural information. Consider again
the noun-noun sequence may push from Table 2,
which is attested in sentence (9a). In this case, the
context strongly indicates that may push is not a
compound given that push is followed by a per-
sonal pronoun (personal pronouns typically pre-
cede compound nouns but never follow them).
We encode contextual information as the words
preceding and succeeding the noun-noun sequence
in question. In order to capture grammatical and
syntactic dependencies we reduce words to their
parts of speech and encode their positions to the
left or right of the candidate compound. An ex-
ample of this type of feature-encoding is given
in (9b) which represents the context surround-
ing may push in sentence (9a). The feature-vector
in (9b) consists of the candidate compound may
push, represented by its parts of speech (NN1 and
NN1, respectively) and a context of four words to
its right and four words to its left, also reduced to
their parts of speech.2
</bodyText>
<equation confidence="0.88389925">
(9) a. Their different responsibilities in relation to the
public may push them in opposite directions.
b. [NN2, PRP, ATO, AJO, NN1, NN1, PNP, PRP, AJO,
NN2]
</equation>
<bodyText confidence="0.999849333333333">
In the following we explore how the two types
of features (i.e., numerical and categorical) per-
form independently as well as in combination.
</bodyText>
<sectionHeader confidence="0.999736" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.983716">
4.1 Machine Learning
</subsectionHeader>
<bodyText confidence="0.999940076923077">
The different features were combined using the
C4.5 decision tree learner (Quinlan, 1993). Deci-
sion trees are among the most widely used ma-
chine learning algorithms. They perform a general
to specific search of a feature space, adding the
most informative features to a tree structure as the
search proceeds. The objective is to select a min-
imal set of features that efficiently partitions the
feature space into classes of observations and as-
semble them into a tree. For our experiments, the
classification is binary, a noun-noun sequence is
a compound or not. For comparison we also re-
port the performance of the Naive Bayes classifier
(Duda and Hart, 1973). The latter classifier does
not perform a search through the feature space in
order to build a model for classifying future exam-
ples. Instead all features are included in the clas-
sification. The learner is based on the simplifying
assumption that each feature is conditionally inde-
pendent of all other features, given the class of a
given noun-noun sequence. We use the Weka (Wit-
ten and Frank, 2000) implementations of the C4.5
decision tree and Naive Bayes learner.
The classifiers were trained and tested using
10-fold cross-validation on 1,000 noun-sequences
which were attested in the BNC only once. The
</bodyText>
<footnote confidence="0.58113675">
2The part-of-speech NN1 stands for singular common
nouns, NN2 stands for plural common nouns, ATO stands for
determiners, PRP for prepositions, PNP for pronouns, and AJO
for adjectives.
</footnote>
<equation confidence="0.987778">
f(c,,c2)
f(nni2) = Kc1.c2)e c (nt &apos;W2)
i
Ic(nti ,n2&apos; )1
(8)
</equation>
<page confidence="0.995065">
239
</page>
<bodyText confidence="0.999970909090909">
data was annotated by two judges. They were in-
structed to decide whether a noun-noun sequence
is a compound or not and given a page of guide-
lines but had no prior training. The candidate com-
pounds were classified in context: the judges were
given the corpus sentence in which the noun-noun
sequence occurred together with the previous and
following sentence. Using the Kappa coefficient
(Cohen, 1960) the judges&apos; agreement3 on the clas-
sification task was K = .80 (N = 1000,k= 2). This
translates into a percentage agreement of 89%.
</bodyText>
<subsectionHeader confidence="0.98391">
4.2 Experimental Results
</subsectionHeader>
<bodyText confidence="0.997388316326531">
Table 4 shows how accuracy varies when the
learners (decision tree (DT) and Naive Bayes
(NB)) use individual numeric features. For the
concept frequency feature we experimented with
two hierarchies, Roget&apos;s thesaurus and WordNet.
As can be seen in Table 4 the best feature is con-
cept frequency using WordNet (fm,(n1,n2)), with
an accuracy of 66.7% (for DT), a significant im-
provement over the baseline (p &lt; .05) which was
measured as the most frequent class (i.e., com-
pound) in our data set (56.3%). Note that WordNet
outperforms Roget&apos;s thesaurus even though both
dictionaries contain taxonomic information. This
fact may be due to the size of the taxonomies.
WordNet contains twice as many noun entries as
Roget (47,302 versus 20,448). Another explana-
tion might be that Roget&apos;s thesaurus is too coarse-
grained a taxonomy for the task at hand (Ro-
get&apos;s taxonomy contains 1,043 concepts, whereas
WordNet contains 4,795).
We further examined the accuracy on the classi-
fication task when solely contextual features are
used. We evaluated the influence of context by
varying both the position and the size of the win-
dow of words (i.e., parts of speech) surrounding
the candidate compound. The window size param-
eter was varied between one and four words be-
fore and after the candidate compounds. We use
symbols 1 and r for left and right context, respec-
tively and number to denote the window size. For
example, 1 = 2, r = 4 represents a window of two
words to the left and four words to the right of the
candidate noun-noun sequence. Table 5 shows the
performance of the two classifiers for some of the
contextual feature sets we examined.
Good performances are attained by both learn-
ers. For DT, the best accuracy (69.1%) is obtained
with windows of three or four words to the left
of the candidate noun-noun sequence (see / = 4
and 1 = 3 in Table 5). NB performs best (70.8%
3Cases of disagreement were excluded from the data on
which the classifiers were trained and tested.
and 69.8%) with small window sizes (see / = 1,
and 1 = 1, r = un Table 5). All three perfor-
mances are a significant improvement over the
baseline (p &lt; .05). In general, better performance
is achieved when one type of context is used (ei-
ther left or right) instead of their combination
(with the exception of 1 = 1, r = 1 and 1 = 2, r = 1
for NB). Our results suggest that even though con-
text is encoded naively as parts of speech without
preserving any structural or semantic knowledge,
it retains enough information to distinguish com-
pounds from non-compounds. This is an impor-
tant result given that the best numerical predictor
(i.e., f,,(ni,n2)) relies heavily on taxonomic in-
formation. The contextual features are straightfor-
ward to obtain—all we need is a concordance of
the candidate compound annotated with parts of
speech.
Table 6 shows various combinations of numeric
features, but also the interaction between numeric
and contextual features. Again, we report some
(i.e., the most informative) of the feature sets we
examined When only numeric features are used,
the best accuracy for DT is attained with the com-
bination of fwn(ni,n2) with P(1-11n1) (67.3%) or
with f„(ni,n2) (67.4%). Similar accuracies are
obtained when fw, (ni , n2) is combined with two
or three features (see Table 6). For the NB classi-
fier, the best overall accuracy (72.3%) is attained
for the feature set {fivn(ni, n2), P(1-11n1), 1 = 11.
This set of features yields signifiant improvement
over the baseline (p &lt; .05) and outperforms any
other feature combinations including any other
pairings with contextual information.
The DT learner&apos;s performance is consistently
better when numeric features are combined with
contextual ones. For all feature combinations
shown in Table 6 the inclusion of context yields
better results and accuracies around 70%. Gen-
erally, a small context (e.g., 1 = 1 or r = 1)
yields better results (over a larger context) when
combined with numeric features. A smaller con-
text captures local syntactic dependencies such as
the fact that compound nouns are typically pre-
ceded by determiners, verbs, or adjectives and suc-
ceded by verbs, prepositions or function words
(e.g., and, or). On the other hand, widening the
context tends to proliferate global syntactic ambi-
guity making local syntactic dependencies harder
to learn. The DT learner achieves its best per-
formance (72.0%) for the feature sets {f(nt),
f (n2), P(I-11n1), f,„(ni. n2), f„(ni,n2), 1 = 2} and
fP(Mln2), fwn(ni, n2), fro(ni,n2), f (ni), = 11.1t
is worth noting that the second best performance
(71.7%) is attained by the feature set {P
P(Mln2), / = 11. This is an important result given
</bodyText>
<page confidence="0.988904">
240
</page>
<table confidence="0.95984525">
Features DT NB
Baseline 56.3 56.3
f(n1) 60.7 48.9
f (n2) 57.2 55.3
P(4n1) 59.7 59.9
P(mIn2) 61.6 60.0
f. (nt .n2) 66.7 62.3
fro (ni , n2) 58.9 50.2
Table 4: Numeric Features
Features DT NB
Baseline 56.3 56.3
/ = 4 69.1 63.9
1 = 3 69.1 66.2
/ = 2 68.5 67.9
/ = 1 66.7 70.8
r = 4 64.7 65.0
r = 3 63.3 65.7
r = 2 64.3 66.6
r = 1 66.5 69.3
/ = 1, r = 1 63.4 69.8
1 = 2, r= 1 63.5 68.1
/ = 3, r = 1 65.1 66.2
/ = 2, r = 3 63.5 65.9
1 = 3, r = 4 63.5 63.3
1 = 2, r = 3 64.3 66.5
1 = 4, r = 4 65.3 62.8
Table 5: Categorical Features
Features DT NB
Baseline 56.3 56.3
f (n 1 ) ,P (M n2) 62.5 60.4
f (ni),P(M n2), 1 = 1 71.1 71.1
f (ni),P(M n2), r= 1 71.0 68.3
P(H P(H721),P(M n2) 62.1 63.2
P(H ni),P(M n2), 1 = 1 71.7 69.9
ni),P(M n2), r= 1 69.7 70.5
P(H ni ),fwn(ni ,n2) 67.3 63.9
P(H ni),,iwn(ni, n2), 1 = 1 70.8 72.3
P(11 ni),,f1n(111,112), r= 1 70.4 70.8
fivnall ,112),f-o(nl, n2) 67.4 55.0
.f,,,(ni,n2),.f10(ni,n2), 1 = 1 71.5 65.6
,fwn(ni,n2),fro(ni,n2), r = 1 71.4 66.5
f wn(n 1 ,n2),,fro (ni , n2), f(n1) 67.0 53.7
f,,,(ni,n2),fro(ni,n2), f (ni),1 = 1 70.4 65.0
,fwn(ni ,n2),fro(ni ,n2), f (ni),r = 1 70.3 65.5
P(M n2) , ,fwn (n 1 , n2) %fly) (n 1 , n2) 67.3 55.2
P(M n2),.fwn(ni , n2), f „(n 1 ,n2),1 = 1 71.4 63.1
P(M n2) ,lwri(ni, n2),fro(n i ,n2),r = 1 71.4 67.0
P(M P(Kn2),./wn(ni, 67.1 55.2
P(M n2),,t&apos;w, (ni,n2),fro(ni,n2),f (&amp;quot;1) 72.0 60.1
n2),.fwn (n 1 , n2) ,f m(ni,n2),,f (ni), 1 = 1 70.6 65.6
n2),.fro(ni,n2),,f (n2), r = 2
P(H P(Flni),P(Mn2),.flyn(rti, n2),Arn(rti ,n2),.b-o(ni,n2) 66.9 56.0
P(H ni ),P(M n2), f,,,i(n 1 ,n2),fro(ni ,n2), 1 = 1 68.6 68.8
tii ),P(M n2),f,-0(ni .n2), r = 2 69.8 67.1
f (ni),f (n2),P(H ni),,f,n(ro ,n2),fro(ni , n2) 66.9 55.3
f (ni),f (n2),P(H ni),A,i(ni , n2),,f-o(ni . n2), 1 = 2 72.0 61.4
f (ni),f (n2),P(H ni), L., (ni , n2),,fro (ni . n2), r = 2 71.2 62.0
f (ni),f (n2),P(H ni),P(M n2),,fivn(ni ,n2),fro(ni,112) 66.7 54.9
f (ni),f (n2),P(H ni),P(M n2),,fwn(ni , n2), fi-o(ni . n2), 1 = 1 70.5 64.3
f (rli),f (112),P(11 ni),P(M n2),,fwn (ni, 112),f-0 (n 1, n2), r = 1 71.5 64.6
</table>
<tableCaption confidence="0.999676">
Table 6: Combination of numeric and categorical features
</tableCaption>
<bodyText confidence="0.999987222222222">
that these three features can be simply estimated
from the corpus without recourse to taxonomic in-
formation.
When compared, the two learners yield similar
performances. The NB classifier yields better re-
sults with smaller numbers of features, whereas
the DT&apos;s performance remains steadily good, pre-
sumably because the most informative features are
selected during the learning process.
</bodyText>
<sectionHeader confidence="0.999286" genericHeader="conclusions">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999668975609756">
In this paper we focused on noun-noun sequences
for which little evidence is found in the cor-
pus and attempted to distinguish those which are
valid compounds from nonce terms. The auto-
matic acquisition of compound nouns (as opposed
to terms) from unrestricted wide-coverage text
has not received much attention in the literature.
Lauer&apos;s (1995) study was conducted on a cor-
pus exhibiting a uniform register and was further-
more biased in favor of syntactically unambigu-
ous nouns. It cannot therefore be considered rep-
resentative of part-of-speech tagged domain inde-
pendent text.
Our results are encouraging considering the
simplicity of the features we took into account
and the fact that no structural information was
used. Our experiments revealed that surface fea-
tures such as the frequency of the compound
head/modifier, the likelihood of a word as a
head/modifier, or the context surrounding a can-
didate compound perform almost as well as fea-
tures that are estimated on the basis of exist-
ing taxonomies such as WordNet. Our approach
achieved an accuracy of 72% on the compound de-
tection task. Although this performance is a signif-
icant improvement over the baseline (56.3%), it is
16.7% lower than the upper bound of 89% estab-
lished in our agreement study (see Section 4.1).
The task of deciding whether two nouns form a
compound or not crucially depends on a variety of
factors such as world-knowledge, the situation at
hand, and the speaker&apos;s and hearer&apos;s communica-
tive goals, none of which are directly represented
by our features. We demonstrated that a machine
learning approach can overcome the problem of
sparse data which is closely related to the produc-
tivity of compounding. In particular, by exploiting
information about frequent compounds or frequent
contexts (which can be easily retrieved from the
corpus) we can indirectly recreate evidence about
the likelihood of two nouns to form a valid com-
</bodyText>
<page confidence="0.991822">
241
</page>
<bodyText confidence="0.999907814814815">
pound without necessarily relying on parsed text.
Our approach is conceptually close to
Jacquemin (1996): in both cases a list of
terms is used for the acquisition task. The crucial
difference is that our approach does not pre-
suppose the availability of a list of established
terms external to the corpus for the acquisition to
take place. We rely solely on the corpus for the
discovery of reliable compounds (i.e., noun-noun
sequences with CoocF&gt;4) from which our nu-
merical features are estimated. Another difference
is that we discover novel compounds, whereas
Jacquemin&apos;s (1996) method can only discover
variants of already existing terms.
In the future we plan to experiment with bet-
ter estimation schemes for the concept frequency
feature that are appropriate for finding the the
right level of generalisation in a concept hier-
archy (Clark and Weir, 2002) and with smooth-
ing techniques that directly recreate the frequen-
cies of word combinations. We will also investi-
gate in more depth the effect of context (repre-
sented as word-forms and word-lemmas) by tak-
ing into account bigger windows and use learners
that are particularly suited for handling large num-
bers of features (e.g., Support Vector Machines,
AdaBoost).
</bodyText>
<sectionHeader confidence="0.997352" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999772105263158">
Didier Bourigault and Christian Jacquemin. 1999. Term ex-
traction and term clustering: An integrated platform for
computer aided terminology. In Proceedings of the 9th
Conference of the European Chapter of the Association
for Computational Linguistics, pages 15-21, Bergen, Nor-
way.
Lou Burnard, 1995. Users Guide for the British National
Corpus. British National Corpus Consortium, Oxford
University Computing Service.
Oliver Christ, 1995. The XKWIC User Manual. Institute for
Computational Linguistics, University of Stuttgart.
Kenneth W. Church and Patrick Hanks. 1990. Word associ-
ation norms, mutual information, and lexicography. Com-
putational Linguistics, 16(1):22-29.
Stephen Clark and David Weir. 2002. Class-based probabil-
ity estimation using a semantic hierarchy. Computational
Linguistics, 28(2):187-206.
J. Cohen. 1960. A coefficient of agreement for nomi-
nal scales. Educational and Psychological Measurement,
20:37-46.
Ann Copestake and Alex Lascarides. 1997. Integrating sym-
bolic and statistical representations: The lexicon pragmat-
ics interface. In Proceedings of the 35th Annual Meeting
of the Association for Computational Linguistics and 8th
Conference of the European Chapter of the Association
for Computational Linguistics, pages 136-243, Madrid,
Spain.
Steffan Corley, Martin Corley, Frank Keller, Matthew W.
Crocker, and Shari Trewin. 2001. Finding syntactic struc-
ture in unparsed corpora: The Gsearch corpus query sys-
tem. Computers and the Humanities, 35(2):81-94.
Beatrice Daille. 1996. Study and implementation of com-
bined techniques for automatic extraction of terminology.
In Judith Klavans and Philip Resnik, editors, The Balanc-
ing Act: Combining Symbolic and Statistical Approaches
to Language, pages 49-66. The MIT Press, Cambridge,
MA.
Pamela Downing. 1977. On the creation and use of English
compound nouns. Language, 53(4):810-842.
Richard 0. Duda and Peter E. Hart. 1973. Pattern Classifi-
cation and Scene Analysis. Wiley, NY.
David Elworthy. 1994. Does Baum-Welch re-estimation
help taggers? In Proceedings of the 4th Conference
on Applied Natural Language Processing, pages 53-58,
Stuttgart, Germany.
Christian Jacquemin. 1996. A symbolic and surgical acquisi-
tion of terms through variation. In Stefan Wermter, Ellen
Riloff, and Gabriele Scheler, editors, Connectionist, Sta-
tistical and Symbolic Approaches to Learning for Natural
Language, Lecture Notes in Artificial Intelligence, pages
425-438. Springer, Berlin.
John S. Justeson and Slava M. Katz. 1995. Technical ter-
minology: Some linguistic properties and an algorithm
for identification in text. Natural Language Engineering,
1(1):9-27.
Mark Lauer. 1995. Designing Statistical Language Learn-
ers: Experiments on Compound Nouns. Ph.D. thesis,
Macquarie University.
Geoffrey Leech, Roger Garside, and Michael Bryant. 1994.
The tagging of the British national corpus. In Proceedings
of the 15th International Conference on Computational
Linguistics, pages 622-628, Kyoto, Japan.
Rosemary Leonard. 1984. The Interpretation of English
Noun Sequences on the Computer. North-Holland, Am-
sterdam.
Judith N. Levi. 1978. The Syntax and Semantics of Complex
Nominals. New York: Academic Press.
Mark Liberman and Richard Sproat. 1992. The stress and
structure of modified noun phrases in english. In Ivan Sag
and Ann Szabolcsi, editors, Lexical Matters, pages 131-
281. CSLI Publications, Stanford, CA.
Christopher D. Manning and Hinrich Schiitze. 1999. Foun-
dations of Statistical Natural Language Processing. The
MIT Press, Cambridge, MA.
Elaine Marsh. 1984. A computational analysis of complex
noun phrases in navy messages. In Proceedings of the
10th International Conference on Computational Linguis-
tics, pages 505-508, Stanford, CA.
David McDonald. 1982. Understanding Noun Compounds.
Ph.D. thesis, Carnegie Mellon University.
George A. Miller, Richard Beckwith, Christiane Fellbaum,
Derek Gross, and Katherine J. Miller. 1990. Introduction
to WordNet: An on-line lexical database. International
Journal of Lexicography, 3(4):235-244.
James Pustejovsky. 1995. The Generative Lexicon. The MIT
Press, Cambridge, MA.
Ross J. Quinlan. 1993. C4.5: Programs for Machine Learn-
ing. Series in Machine Learning. Morgan Kaufman, San
Mateo, CA.
Philip Stuart Resnik. 1993. Selection and Information: A
Class-Based Approach to Lexical Relationships. Ph.D.
thesis, University of Pennsylvania.
Ian H. Witten and Eibe Frank. 2000. Data Mining: Prac-
tical Machine Learning Tools and Techniques with Java
Implementations. Morgan Kaufman, San Francisco, CA.
</reference>
<page confidence="0.99772">
242
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.770256">
<title confidence="0.988148">Detecting Novel Compounds: The Role of Distributional Evidence</title>
<author confidence="0.999867">Mirella Lapata</author>
<affiliation confidence="0.9999415">Department of Computer Science University of Sheffield</affiliation>
<address confidence="0.9958275">Court, Street Sheffield 51 4DP, UK</address>
<email confidence="0.992856">mlap@dcs.shef.ac.uk</email>
<author confidence="0.997211">Alex Lascarides</author>
<affiliation confidence="0.938993333333333">School of Informatics The University of Edinburgh 2 Buccleuch Place</affiliation>
<address confidence="0.997984">Edinburgh EH8 9LW, UK</address>
<email confidence="0.9967">alex@inf.ed.ac.uk</email>
<abstract confidence="0.998689578947368">Research on the discovery of terms from corpora has focused on word sequences whose recurrent occurrence in a corpus is indicative of their terminological status, and has not addressed the issue of discovering terms when data is sparse. This becomes apparent in the case of noun compounding, which is extremely productive: more than half of the candidate compounds extracted from a corpus are attested only once. We show how evidence about established (i.e., frequent) compounds can be used to estimate features that can discriminate rare valid compounds from rare nonce terms in addition to a variety of linguistic features than can be easily gleaned from corpora without relying on parsed text.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Didier Bourigault</author>
<author>Christian Jacquemin</author>
</authors>
<title>Term extraction and term clustering: An integrated platform for computer aided terminology.</title>
<date>1999</date>
<booktitle>In Proceedings of the 9th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>15--21</pages>
<location>Bergen,</location>
<contexts>
<context position="2690" citStr="Bourigault and Jacquemin, 1999" startWordPosition="415" endWordPosition="418">f compound nouns have concentrated on their automatic acquisition from corpora, syntactic disambiguation (i.e., determine the structure of compounds like income tax relief), and semantic interpretation (i.e., determine the semantic relation between income and tax in income tax). The acquisition of compound nouns is usually subsumed under the general discovery of terms from corpora. Terms are typically acquired by either symbolic or statistical means. Under a symbolic approach, candidate terms are extracted from the corpus using surface syntactic analysis (Lauer, 1995; Justeson and Katz, 1995; Bourigault and Jacquemin, 1999) and sometimes are further submitted to experts for manual inspection. The approach typically assumes no prior terminological knowledge, although Jacquemin (1996) proposed the detection of terminological variants in a corpus by making use of lists of existing terms. The main assumption underlying the statistical approach to term acquisition is that lexically associated words tend to appear together more often than expected on the basis of their individual occurrence frequencies. Once candidate terms are detected in the corpus, statistical tests (e.g., mutual information, the log-likelihood rat</context>
</contexts>
<marker>Bourigault, Jacquemin, 1999</marker>
<rawString>Didier Bourigault and Christian Jacquemin. 1999. Term extraction and term clustering: An integrated platform for computer aided terminology. In Proceedings of the 9th Conference of the European Chapter of the Association for Computational Linguistics, pages 15-21, Bergen, Norway.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lou Burnard</author>
</authors>
<title>Users Guide for the British National Corpus.</title>
<date>1995</date>
<institution>British National Corpus Consortium, Oxford University Computing Service.</institution>
<contexts>
<context position="6079" citStr="Burnard, 1995" startWordPosition="990" endWordPosition="991">et of unambiguous nouns. Lauer (1995) used a corpus derived from the Grolier Multimedia Encyclopedia (8M words) for his study and a predefined list of 90,000 nouns which had no partof-speech ambiguity. He reports an accuracy of 97.9% on a sample of 1,068 noun-noun sequences. Note that the above heuristic incorrectly classifies (2b) as a valid compound. We replicated Lauer&apos;s (1995) study on the British National Corpus (BNC), a 100 million word collection of samples of written and spoken language from a wide range of sources designed to represent a wide cross-section of current British English (Burnard, 1995). An important difference, however, between our study and Lauer&apos;s is that we used a POS-tagged version of the BNC. Noun sequences were identified using Gsearch (Corley et al., 2001), a chart parser which detects syntactic patterns in a tagged corpus by exploiting a user-specified context free grammar and a syntactic query. Gsearch was run on a lemmatised version of the BNC in order to compile a comprehensive count of all nouns occurring in a head-modifier relationship. Tokens containing noun sequences of length two were classified as candidate compounds unless: (a) the two consecutive nouns we</context>
</contexts>
<marker>Burnard, 1995</marker>
<rawString>Lou Burnard, 1995. Users Guide for the British National Corpus. British National Corpus Consortium, Oxford University Computing Service.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oliver Christ</author>
</authors>
<title>The XKWIC User Manual.</title>
<date>1995</date>
<institution>Institute for Computational Linguistics, University of Stuttgart.</institution>
<contexts>
<context position="7373" citStr="Christ, 1995" startWordPosition="1198" endWordPosition="1199">her noun was a number (e.g., flour 100g). This procedure resulted in a total of 1,624,915 tokens consisting of 510,673 distinct types of candidate compounds. We evaluated Lauer&apos;s (1995) heuristic as follows: 800 tokens were randomly selected from the noun-noun sequences that were classified as compounds; accordingly, a random sample of 800 tokens was selected from the sequences that were discarded as non-compounds (in order to examine whether valid compounds are missed). The noun sequences contained in the samples were manually inspected within context using the corpus concordance tool Xkwic (Christ, 1995) and classified as to whether they formed a valid compound or not. Lauer&apos;s heuristic expectedly achieved a lower accuracy on the POS-tagged corpus. This was 71% using cLAws4 (Leech et al., 1994), a probabilistic part-of-speech tagger, with error rate ranging from 3% to 4% and 70.3% using Elworthy&apos;s (1994) HMM part-of-speech tagger, with an error rate of approximately 4%. The heuristic reached an accuracy of 98.8% in rejecting noun sequences as non-compounds. We further examined how the accuracy of the heuristic varies when different thresholds are imposed on the frequency of the candidate comp</context>
</contexts>
<marker>Christ, 1995</marker>
<rawString>Oliver Christ, 1995. The XKWIC User Manual. Institute for Computational Linguistics, University of Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
<author>Patrick Hanks</author>
</authors>
<title>Word association norms, mutual information, and lexicography.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<pages>16--1</pages>
<contexts>
<context position="3726" citStr="Church and Hanks, 1990" startWordPosition="577" endWordPosition="580">than expected on the basis of their individual occurrence frequencies. Once candidate terms are detected in the corpus, statistical tests (e.g., mutual information, the log-likelihood ratio) are used to determine which co-occurrences are valid terms (see Daille, 1996 and Manning and Schiitze, 1999 for overviews). Most of the statistical tests proposed in the literature rely on the fact that candidate terms will occur frequently in the corpus (Justeson and Katz, 1995) or, when hypothesis testing is applied, on the assumption that two words form a term when they co-occur more often than chance (Church and Hanks, 1990). This means that statistical tests cannot be applied reliably for candidate compounds 235 CoocF BNC Sample Ace &gt;4 52,832 800 93.5 &gt; 1 160,214 800 82.0 &gt; 1 510,673 800 71.0 = 1 350,459 800 57.7 Table 1: Relation of noun co-occurrence frequency with accuracy with co-occurrence frequency of one and cannot be used to distinguish rare but valid noun compounds from rare but nonce noun sequences (compare (2b) and (2a) which are extracted from the British National Corpus; both bracketed terms were found in the corpus once.). (2) a. Although no one will doubt their possibilities for elegance and robus</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Kenneth W. Church and Patrick Hanks. 1990. Word association norms, mutual information, and lexicography. Computational Linguistics, 16(1):22-29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>David Weir</author>
</authors>
<title>Class-based probability estimation using a semantic hierarchy.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<pages>28--2</pages>
<marker>Clark, Weir, 2002</marker>
<rawString>Stephen Clark and David Weir. 2002. Class-based probability estimation using a semantic hierarchy. Computational Linguistics, 28(2):187-206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Cohen</author>
</authors>
<title>A coefficient of agreement for nominal scales.</title>
<date>1960</date>
<booktitle>Educational and Psychological Measurement,</booktitle>
<pages>20--37</pages>
<contexts>
<context position="22788" citStr="Cohen, 1960" startWordPosition="3779" endWordPosition="3780">gular common nouns, NN2 stands for plural common nouns, ATO stands for determiners, PRP for prepositions, PNP for pronouns, and AJO for adjectives. f(c,,c2) f(nni2) = Kc1.c2)e c (nt &apos;W2) i Ic(nti ,n2&apos; )1 (8) 239 data was annotated by two judges. They were instructed to decide whether a noun-noun sequence is a compound or not and given a page of guidelines but had no prior training. The candidate compounds were classified in context: the judges were given the corpus sentence in which the noun-noun sequence occurred together with the previous and following sentence. Using the Kappa coefficient (Cohen, 1960) the judges&apos; agreement3 on the classification task was K = .80 (N = 1000,k= 2). This translates into a percentage agreement of 89%. 4.2 Experimental Results Table 4 shows how accuracy varies when the learners (decision tree (DT) and Naive Bayes (NB)) use individual numeric features. For the concept frequency feature we experimented with two hierarchies, Roget&apos;s thesaurus and WordNet. As can be seen in Table 4 the best feature is concept frequency using WordNet (fm,(n1,n2)), with an accuracy of 66.7% (for DT), a significant improvement over the baseline (p &lt; .05) which was measured as the most </context>
</contexts>
<marker>Cohen, 1960</marker>
<rawString>J. Cohen. 1960. A coefficient of agreement for nominal scales. Educational and Psychological Measurement, 20:37-46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
<author>Alex Lascarides</author>
</authors>
<title>Integrating symbolic and statistical representations: The lexicon pragmatics interface.</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics and 8th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>136--243</pages>
<location>Madrid,</location>
<contexts>
<context position="13244" citStr="Copestake and Lascarides, 1997" startWordPosition="2192" endWordPosition="2195">ncy. Linguistic models of compound noun formation typically involve a hierarchical structure of lexical rules, which capture the regularities of compound noun formation while 237 (c1,c2) f(ci,c2) Examples (substance, obj ect) 604.7 iron table (act, social group) 403.0 mining family (entity, location) 382.4 girls school (group. relation) 267.6 world language (communication, act) 231.1 speech treatment (person, artef act) 162.1 developer&apos;s kit (institution, person) 38.7 bank spokesman Table 3: Estimated concept pair frequencies also ruling out certain compounds as candidates (Pustejovsky, 1995; Copestake and Lascarides, 1997). Each lexical rule takes a pair of nouns of certain semantic type as input, and the output of the rule is a compound noun whose semantic representation stipulates the relation between a modifier and its head. For example, the compounds metal tube, leather belt and tin cup are the result of a lexical rule that combines a noun denoting a substance and a noun denoting an artefact to yield a compound denoting the artefact made of the substance. The noun frequency and probability features do not capture meaning regularities concerning the compounding process. For example, we would expect the combi</context>
</contexts>
<marker>Copestake, Lascarides, 1997</marker>
<rawString>Ann Copestake and Alex Lascarides. 1997. Integrating symbolic and statistical representations: The lexicon pragmatics interface. In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics and 8th Conference of the European Chapter of the Association for Computational Linguistics, pages 136-243, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steffan Corley</author>
<author>Martin Corley</author>
<author>Frank Keller</author>
<author>Matthew W Crocker</author>
<author>Shari Trewin</author>
</authors>
<title>Finding syntactic structure in unparsed corpora: The Gsearch corpus query system. Computers and the Humanities,</title>
<date>2001</date>
<pages>35--2</pages>
<contexts>
<context position="6260" citStr="Corley et al., 2001" startWordPosition="1018" endWordPosition="1021">o partof-speech ambiguity. He reports an accuracy of 97.9% on a sample of 1,068 noun-noun sequences. Note that the above heuristic incorrectly classifies (2b) as a valid compound. We replicated Lauer&apos;s (1995) study on the British National Corpus (BNC), a 100 million word collection of samples of written and spoken language from a wide range of sources designed to represent a wide cross-section of current British English (Burnard, 1995). An important difference, however, between our study and Lauer&apos;s is that we used a POS-tagged version of the BNC. Noun sequences were identified using Gsearch (Corley et al., 2001), a chart parser which detects syntactic patterns in a tagged corpus by exploiting a user-specified context free grammar and a syntactic query. Gsearch was run on a lemmatised version of the BNC in order to compile a comprehensive count of all nouns occurring in a head-modifier relationship. Tokens containing noun sequences of length two were classified as candidate compounds unless: (a) the two consecutive nouns were preceded or succeeded by a noun (e.g., light bulb phobia, see (3)) and (b) either noun was a number (e.g., flour 100g). This procedure resulted in a total of 1,624,915 tokens con</context>
</contexts>
<marker>Corley, Corley, Keller, Crocker, Trewin, 2001</marker>
<rawString>Steffan Corley, Martin Corley, Frank Keller, Matthew W. Crocker, and Shari Trewin. 2001. Finding syntactic structure in unparsed corpora: The Gsearch corpus query system. Computers and the Humanities, 35(2):81-94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beatrice Daille</author>
</authors>
<title>Study and implementation of combined techniques for automatic extraction of terminology.</title>
<date>1996</date>
<booktitle>The Balancing Act: Combining Symbolic and Statistical Approaches to Language,</booktitle>
<pages>49--66</pages>
<editor>In Judith Klavans and Philip Resnik, editors,</editor>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="3370" citStr="Daille, 1996" startWordPosition="519" endWordPosition="520">n. The approach typically assumes no prior terminological knowledge, although Jacquemin (1996) proposed the detection of terminological variants in a corpus by making use of lists of existing terms. The main assumption underlying the statistical approach to term acquisition is that lexically associated words tend to appear together more often than expected on the basis of their individual occurrence frequencies. Once candidate terms are detected in the corpus, statistical tests (e.g., mutual information, the log-likelihood ratio) are used to determine which co-occurrences are valid terms (see Daille, 1996 and Manning and Schiitze, 1999 for overviews). Most of the statistical tests proposed in the literature rely on the fact that candidate terms will occur frequently in the corpus (Justeson and Katz, 1995) or, when hypothesis testing is applied, on the assumption that two words form a term when they co-occur more often than chance (Church and Hanks, 1990). This means that statistical tests cannot be applied reliably for candidate compounds 235 CoocF BNC Sample Ace &gt;4 52,832 800 93.5 &gt; 1 160,214 800 82.0 &gt; 1 510,673 800 71.0 = 1 350,459 800 57.7 Table 1: Relation of noun co-occurrence frequency </context>
</contexts>
<marker>Daille, 1996</marker>
<rawString>Beatrice Daille. 1996. Study and implementation of combined techniques for automatic extraction of terminology. In Judith Klavans and Philip Resnik, editors, The Balancing Act: Combining Symbolic and Statistical Approaches to Language, pages 49-66. The MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pamela Downing</author>
</authors>
<title>On the creation and use of English compound nouns.</title>
<date>1977</date>
<journal>Language,</journal>
<pages>53--4</pages>
<contexts>
<context position="2027" citStr="Downing, 1977" startWordPosition="319" endWordPosition="321">nation of words (see (1a,b)), or as single words (see (lc)), sometimes a hyphen is also used (see (le)). income tax AT &amp; T headquarters bathroom public-relations income-tax relief The use of noun compounds is frequent not only in technical writing and newswire text (McDonald, 1982) but also in fictional prose (Leonard, 1984), and spoken language (Liberman and Sproat, 1992). Novel compounds are used as a text compression device (Marsh, 1984), i.e., to pack meaning into a minimal amount of linguistic structure, as a deictic device, or as a means to classify an entity which has no specific name (Downing, 1977). Computational investigations of compound nouns have concentrated on their automatic acquisition from corpora, syntactic disambiguation (i.e., determine the structure of compounds like income tax relief), and semantic interpretation (i.e., determine the semantic relation between income and tax in income tax). The acquisition of compound nouns is usually subsumed under the general discovery of terms from corpora. Terms are typically acquired by either symbolic or statistical means. Under a symbolic approach, candidate terms are extracted from the corpus using surface syntactic analysis (Lauer,</context>
</contexts>
<marker>Downing, 1977</marker>
<rawString>Pamela Downing. 1977. On the creation and use of English compound nouns. Language, 53(4):810-842.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Duda</author>
<author>Peter E Hart</author>
</authors>
<title>Pattern Classification and Scene Analysis.</title>
<date>1973</date>
<publisher>Wiley, NY.</publisher>
<contexts>
<context position="21529" citStr="Duda and Hart, 1973" startWordPosition="3570" endWordPosition="3573">ing the C4.5 decision tree learner (Quinlan, 1993). Decision trees are among the most widely used machine learning algorithms. They perform a general to specific search of a feature space, adding the most informative features to a tree structure as the search proceeds. The objective is to select a minimal set of features that efficiently partitions the feature space into classes of observations and assemble them into a tree. For our experiments, the classification is binary, a noun-noun sequence is a compound or not. For comparison we also report the performance of the Naive Bayes classifier (Duda and Hart, 1973). The latter classifier does not perform a search through the feature space in order to build a model for classifying future examples. Instead all features are included in the classification. The learner is based on the simplifying assumption that each feature is conditionally independent of all other features, given the class of a given noun-noun sequence. We use the Weka (Witten and Frank, 2000) implementations of the C4.5 decision tree and Naive Bayes learner. The classifiers were trained and tested using 10-fold cross-validation on 1,000 noun-sequences which were attested in the BNC only o</context>
</contexts>
<marker>Duda, Hart, 1973</marker>
<rawString>Richard 0. Duda and Peter E. Hart. 1973. Pattern Classification and Scene Analysis. Wiley, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Elworthy</author>
</authors>
<title>Does Baum-Welch re-estimation help taggers?</title>
<date>1994</date>
<booktitle>In Proceedings of the 4th Conference on Applied Natural Language Processing,</booktitle>
<pages>53--58</pages>
<location>Stuttgart, Germany.</location>
<marker>Elworthy, 1994</marker>
<rawString>David Elworthy. 1994. Does Baum-Welch re-estimation help taggers? In Proceedings of the 4th Conference on Applied Natural Language Processing, pages 53-58, Stuttgart, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Jacquemin</author>
</authors>
<title>A symbolic and surgical acquisition of terms through variation.</title>
<date>1996</date>
<booktitle>Connectionist, Statistical and Symbolic Approaches to Learning for Natural Language, Lecture Notes in Artificial Intelligence,</booktitle>
<pages>425--438</pages>
<editor>In Stefan Wermter, Ellen Riloff, and Gabriele Scheler, editors,</editor>
<publisher>Springer,</publisher>
<location>Berlin.</location>
<contexts>
<context position="2852" citStr="Jacquemin (1996)" startWordPosition="440" endWordPosition="441"> semantic interpretation (i.e., determine the semantic relation between income and tax in income tax). The acquisition of compound nouns is usually subsumed under the general discovery of terms from corpora. Terms are typically acquired by either symbolic or statistical means. Under a symbolic approach, candidate terms are extracted from the corpus using surface syntactic analysis (Lauer, 1995; Justeson and Katz, 1995; Bourigault and Jacquemin, 1999) and sometimes are further submitted to experts for manual inspection. The approach typically assumes no prior terminological knowledge, although Jacquemin (1996) proposed the detection of terminological variants in a corpus by making use of lists of existing terms. The main assumption underlying the statistical approach to term acquisition is that lexically associated words tend to appear together more often than expected on the basis of their individual occurrence frequencies. Once candidate terms are detected in the corpus, statistical tests (e.g., mutual information, the log-likelihood ratio) are used to determine which co-occurrences are valid terms (see Daille, 1996 and Manning and Schiitze, 1999 for overviews). Most of the statistical tests prop</context>
<context position="32085" citStr="Jacquemin (1996)" startWordPosition="5408" endWordPosition="5409">e, the situation at hand, and the speaker&apos;s and hearer&apos;s communicative goals, none of which are directly represented by our features. We demonstrated that a machine learning approach can overcome the problem of sparse data which is closely related to the productivity of compounding. In particular, by exploiting information about frequent compounds or frequent contexts (which can be easily retrieved from the corpus) we can indirectly recreate evidence about the likelihood of two nouns to form a valid com241 pound without necessarily relying on parsed text. Our approach is conceptually close to Jacquemin (1996): in both cases a list of terms is used for the acquisition task. The crucial difference is that our approach does not presuppose the availability of a list of established terms external to the corpus for the acquisition to take place. We rely solely on the corpus for the discovery of reliable compounds (i.e., noun-noun sequences with CoocF&gt;4) from which our numerical features are estimated. Another difference is that we discover novel compounds, whereas Jacquemin&apos;s (1996) method can only discover variants of already existing terms. In the future we plan to experiment with better estimation sc</context>
</contexts>
<marker>Jacquemin, 1996</marker>
<rawString>Christian Jacquemin. 1996. A symbolic and surgical acquisition of terms through variation. In Stefan Wermter, Ellen Riloff, and Gabriele Scheler, editors, Connectionist, Statistical and Symbolic Approaches to Learning for Natural Language, Lecture Notes in Artificial Intelligence, pages 425-438. Springer, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John S Justeson</author>
<author>Slava M Katz</author>
</authors>
<title>Technical terminology: Some linguistic properties and an algorithm for identification in text.</title>
<date>1995</date>
<journal>Natural Language Engineering,</journal>
<pages>1--1</pages>
<contexts>
<context position="2657" citStr="Justeson and Katz, 1995" startWordPosition="410" endWordPosition="414">tational investigations of compound nouns have concentrated on their automatic acquisition from corpora, syntactic disambiguation (i.e., determine the structure of compounds like income tax relief), and semantic interpretation (i.e., determine the semantic relation between income and tax in income tax). The acquisition of compound nouns is usually subsumed under the general discovery of terms from corpora. Terms are typically acquired by either symbolic or statistical means. Under a symbolic approach, candidate terms are extracted from the corpus using surface syntactic analysis (Lauer, 1995; Justeson and Katz, 1995; Bourigault and Jacquemin, 1999) and sometimes are further submitted to experts for manual inspection. The approach typically assumes no prior terminological knowledge, although Jacquemin (1996) proposed the detection of terminological variants in a corpus by making use of lists of existing terms. The main assumption underlying the statistical approach to term acquisition is that lexically associated words tend to appear together more often than expected on the basis of their individual occurrence frequencies. Once candidate terms are detected in the corpus, statistical tests (e.g., mutual in</context>
</contexts>
<marker>Justeson, Katz, 1995</marker>
<rawString>John S. Justeson and Slava M. Katz. 1995. Technical terminology: Some linguistic properties and an algorithm for identification in text. Natural Language Engineering, 1(1):9-27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Lauer</author>
</authors>
<title>Designing Statistical Language Learners: Experiments on Compound Nouns.</title>
<date>1995</date>
<tech>Ph.D. thesis,</tech>
<institution>Macquarie University.</institution>
<contexts>
<context position="2632" citStr="Lauer, 1995" startWordPosition="408" endWordPosition="409"> 1977). Computational investigations of compound nouns have concentrated on their automatic acquisition from corpora, syntactic disambiguation (i.e., determine the structure of compounds like income tax relief), and semantic interpretation (i.e., determine the semantic relation between income and tax in income tax). The acquisition of compound nouns is usually subsumed under the general discovery of terms from corpora. Terms are typically acquired by either symbolic or statistical means. Under a symbolic approach, candidate terms are extracted from the corpus using surface syntactic analysis (Lauer, 1995; Justeson and Katz, 1995; Bourigault and Jacquemin, 1999) and sometimes are further submitted to experts for manual inspection. The approach typically assumes no prior terminological knowledge, although Jacquemin (1996) proposed the detection of terminological variants in a corpus by making use of lists of existing terms. The main assumption underlying the statistical approach to term acquisition is that lexically associated words tend to appear together more often than expected on the basis of their individual occurrence frequencies. Once candidate terms are detected in the corpus, statistic</context>
<context position="5167" citStr="Lauer (1995)" startWordPosition="824" endWordPosition="825">to its gravity. In this paper we present a method that attempts to distinguish compounds from non-compounds in cases where very little direct evidence is found in the corpus and therefore the assumptions underlying lexical association scores do not hold. We restrict our attention to compounds formed by a concatenation of two nouns (see (1a)) and investigate how surface syntactic and semantic cues can be used to discriminate valid compounds from rare nonce terms. 2 Compound Noun Extraction The extraction of two word compounds (as opposed to terms) from a corpus has been previously addressed by Lauer (1995) who proposed a heuristic which simply looks for consecutive pairs of nouns which are neither preceded nor succeeded by a noun (see (3)). (3) C = {(4&apos;2, w3) WI W2 W3 W4; , w40 N; W2, W3 E Here, wi w2 1423 1424 denotes the occurrence of a sequence of four words in the corpus and N is a predefined set of unambiguous nouns. Lauer (1995) used a corpus derived from the Grolier Multimedia Encyclopedia (8M words) for his study and a predefined list of 90,000 nouns which had no partof-speech ambiguity. He reports an accuracy of 97.9% on a sample of 1,068 noun-noun sequences. Note that the above heuris</context>
<context position="17104" citStr="Lauer, 1995" startWordPosition="2830" endWordPosition="2831">uistics literature (Levi, 1978) that compounds are derived through combinations of distinct conceptsl. For each compound in our corpus we generate the set of concept pairs it is potentially an instantiation of. The compound cocaine customer generates 29 concept pairs (e.g., (artef act, consumer), (artef act, person)). We estimate the frequency of a concept pair f(ci , c2) by summing over all noun-noun sequences ni n2 that are representative of the concept combination (c i, c2) . We divide the contribution of each compound nin2 by the number of concept combinations it represents (Resnik, 1993; Lauer, 1995): f(ni,n2) f(ci,c2) E (7) c(ni,n2)1 ,n2)E ;C2/ Here, f(ni,n2) is the number of times a given noun-noun sequence was observed in the estimation corpus and Ic(ni,n2)1 is the number of conceptual pairs n n2 has. Assuming that we want to take the compound cocaine customer into account for estimating the frequency of the I Dvanda or appositional compounds (e.g., mother child, player coach) are a notable exception. 238 concept pair (art ef act, person), we will increment the observed co-occurrence count of (artef act, person) by 2+,, since cocaine customer is represented by 29 distinct concept pairs</context>
</contexts>
<marker>Lauer, 1995</marker>
<rawString>Mark Lauer. 1995. Designing Statistical Language Learners: Experiments on Compound Nouns. Ph.D. thesis, Macquarie University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey Leech</author>
<author>Roger Garside</author>
<author>Michael Bryant</author>
</authors>
<title>The tagging of the British national corpus.</title>
<date>1994</date>
<booktitle>In Proceedings of the 15th International Conference on Computational Linguistics,</booktitle>
<pages>622--628</pages>
<location>Kyoto, Japan.</location>
<contexts>
<context position="7567" citStr="Leech et al., 1994" startWordPosition="1229" endWordPosition="1232">uristic as follows: 800 tokens were randomly selected from the noun-noun sequences that were classified as compounds; accordingly, a random sample of 800 tokens was selected from the sequences that were discarded as non-compounds (in order to examine whether valid compounds are missed). The noun sequences contained in the samples were manually inspected within context using the corpus concordance tool Xkwic (Christ, 1995) and classified as to whether they formed a valid compound or not. Lauer&apos;s heuristic expectedly achieved a lower accuracy on the POS-tagged corpus. This was 71% using cLAws4 (Leech et al., 1994), a probabilistic part-of-speech tagger, with error rate ranging from 3% to 4% and 70.3% using Elworthy&apos;s (1994) HMM part-of-speech tagger, with an error rate of approximately 4%. The heuristic reached an accuracy of 98.8% in rejecting noun sequences as non-compounds. We further examined how the accuracy of the heuristic varies when different thresholds are imposed on the frequency of the candidate compounds (see Table 1). For example, when we consider noun-noun sequences that appear in the BNC more than once (CoocF &gt; 1) the heuristic&apos;s accuracy is increased by 11.0%. However, the number of po</context>
</contexts>
<marker>Leech, Garside, Bryant, 1994</marker>
<rawString>Geoffrey Leech, Roger Garside, and Michael Bryant. 1994. The tagging of the British national corpus. In Proceedings of the 15th International Conference on Computational Linguistics, pages 622-628, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rosemary Leonard</author>
</authors>
<date>1984</date>
<booktitle>The Interpretation of English Noun Sequences on the Computer. North-Holland,</booktitle>
<location>Amsterdam.</location>
<contexts>
<context position="1739" citStr="Leonard, 1984" startWordPosition="270" endWordPosition="271">the theoretical linguistics literature. It is a well-known fact that compound noun formation in English is relatively productive (see (1)). Although compounds are typically binary (see (1a,b)), they can be also longer than two words (see (le)). Compounds are commonly written as a concatenation of words (see (1a,b)), or as single words (see (lc)), sometimes a hyphen is also used (see (le)). income tax AT &amp; T headquarters bathroom public-relations income-tax relief The use of noun compounds is frequent not only in technical writing and newswire text (McDonald, 1982) but also in fictional prose (Leonard, 1984), and spoken language (Liberman and Sproat, 1992). Novel compounds are used as a text compression device (Marsh, 1984), i.e., to pack meaning into a minimal amount of linguistic structure, as a deictic device, or as a means to classify an entity which has no specific name (Downing, 1977). Computational investigations of compound nouns have concentrated on their automatic acquisition from corpora, syntactic disambiguation (i.e., determine the structure of compounds like income tax relief), and semantic interpretation (i.e., determine the semantic relation between income and tax in income tax). </context>
</contexts>
<marker>Leonard, 1984</marker>
<rawString>Rosemary Leonard. 1984. The Interpretation of English Noun Sequences on the Computer. North-Holland, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judith N Levi</author>
</authors>
<title>The Syntax and Semantics of Complex Nominals.</title>
<date>1978</date>
<publisher>Academic Press.</publisher>
<location>New York:</location>
<contexts>
<context position="16523" citStr="Levi, 1978" startWordPosition="2732" endWordPosition="2733">follows: c(ni,n2) = {(ci,ci) ci E classes(ni), (6) ci e class es (n2), cil Here, c(ni,n2) is the set of distinct concept pairs a given noun-noun sequence is an instantiation of. Note that we impose a restriction on the type of concept pairs we generate, namely we disallow pairs with identical concepts (see (6)). The motivation for this restriction is twofold: first, we want to avoid overly general concept pairs that could potentially represent any noun-noun combination (e.g., (entity, entity), (artef act, artef act)); second, it is implicitly assumed in the theoretical linguistics literature (Levi, 1978) that compounds are derived through combinations of distinct conceptsl. For each compound in our corpus we generate the set of concept pairs it is potentially an instantiation of. The compound cocaine customer generates 29 concept pairs (e.g., (artef act, consumer), (artef act, person)). We estimate the frequency of a concept pair f(ci , c2) by summing over all noun-noun sequences ni n2 that are representative of the concept combination (c i, c2) . We divide the contribution of each compound nin2 by the number of concept combinations it represents (Resnik, 1993; Lauer, 1995): f(ni,n2) f(ci,c2)</context>
</contexts>
<marker>Levi, 1978</marker>
<rawString>Judith N. Levi. 1978. The Syntax and Semantics of Complex Nominals. New York: Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Liberman</author>
<author>Richard Sproat</author>
</authors>
<title>The stress and structure of modified noun phrases in english.</title>
<date>1992</date>
<booktitle>In Ivan Sag and Ann Szabolcsi, editors, Lexical Matters,</booktitle>
<pages>131--281</pages>
<publisher>CSLI Publications,</publisher>
<location>Stanford, CA.</location>
<contexts>
<context position="1788" citStr="Liberman and Sproat, 1992" startWordPosition="275" endWordPosition="278">e. It is a well-known fact that compound noun formation in English is relatively productive (see (1)). Although compounds are typically binary (see (1a,b)), they can be also longer than two words (see (le)). Compounds are commonly written as a concatenation of words (see (1a,b)), or as single words (see (lc)), sometimes a hyphen is also used (see (le)). income tax AT &amp; T headquarters bathroom public-relations income-tax relief The use of noun compounds is frequent not only in technical writing and newswire text (McDonald, 1982) but also in fictional prose (Leonard, 1984), and spoken language (Liberman and Sproat, 1992). Novel compounds are used as a text compression device (Marsh, 1984), i.e., to pack meaning into a minimal amount of linguistic structure, as a deictic device, or as a means to classify an entity which has no specific name (Downing, 1977). Computational investigations of compound nouns have concentrated on their automatic acquisition from corpora, syntactic disambiguation (i.e., determine the structure of compounds like income tax relief), and semantic interpretation (i.e., determine the semantic relation between income and tax in income tax). The acquisition of compound nouns is usually subs</context>
</contexts>
<marker>Liberman, Sproat, 1992</marker>
<rawString>Mark Liberman and Richard Sproat. 1992. The stress and structure of modified noun phrases in english. In Ivan Sag and Ann Szabolcsi, editors, Lexical Matters, pages 131-281. CSLI Publications, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Hinrich Schiitze</author>
</authors>
<title>Foundations of Statistical Natural Language Processing.</title>
<date>1999</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="3401" citStr="Manning and Schiitze, 1999" startWordPosition="522" endWordPosition="525">ypically assumes no prior terminological knowledge, although Jacquemin (1996) proposed the detection of terminological variants in a corpus by making use of lists of existing terms. The main assumption underlying the statistical approach to term acquisition is that lexically associated words tend to appear together more often than expected on the basis of their individual occurrence frequencies. Once candidate terms are detected in the corpus, statistical tests (e.g., mutual information, the log-likelihood ratio) are used to determine which co-occurrences are valid terms (see Daille, 1996 and Manning and Schiitze, 1999 for overviews). Most of the statistical tests proposed in the literature rely on the fact that candidate terms will occur frequently in the corpus (Justeson and Katz, 1995) or, when hypothesis testing is applied, on the assumption that two words form a term when they co-occur more often than chance (Church and Hanks, 1990). This means that statistical tests cannot be applied reliably for candidate compounds 235 CoocF BNC Sample Ace &gt;4 52,832 800 93.5 &gt; 1 160,214 800 82.0 &gt; 1 510,673 800 71.0 = 1 350,459 800 57.7 Table 1: Relation of noun co-occurrence frequency with accuracy with co-occurrenc</context>
</contexts>
<marker>Manning, Schiitze, 1999</marker>
<rawString>Christopher D. Manning and Hinrich Schiitze. 1999. Foundations of Statistical Natural Language Processing. The MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elaine Marsh</author>
</authors>
<title>A computational analysis of complex noun phrases in navy messages.</title>
<date>1984</date>
<booktitle>In Proceedings of the 10th International Conference on Computational Linguistics,</booktitle>
<pages>505--508</pages>
<location>Stanford, CA.</location>
<contexts>
<context position="1857" citStr="Marsh, 1984" startWordPosition="288" endWordPosition="289">oductive (see (1)). Although compounds are typically binary (see (1a,b)), they can be also longer than two words (see (le)). Compounds are commonly written as a concatenation of words (see (1a,b)), or as single words (see (lc)), sometimes a hyphen is also used (see (le)). income tax AT &amp; T headquarters bathroom public-relations income-tax relief The use of noun compounds is frequent not only in technical writing and newswire text (McDonald, 1982) but also in fictional prose (Leonard, 1984), and spoken language (Liberman and Sproat, 1992). Novel compounds are used as a text compression device (Marsh, 1984), i.e., to pack meaning into a minimal amount of linguistic structure, as a deictic device, or as a means to classify an entity which has no specific name (Downing, 1977). Computational investigations of compound nouns have concentrated on their automatic acquisition from corpora, syntactic disambiguation (i.e., determine the structure of compounds like income tax relief), and semantic interpretation (i.e., determine the semantic relation between income and tax in income tax). The acquisition of compound nouns is usually subsumed under the general discovery of terms from corpora. Terms are typ</context>
</contexts>
<marker>Marsh, 1984</marker>
<rawString>Elaine Marsh. 1984. A computational analysis of complex noun phrases in navy messages. In Proceedings of the 10th International Conference on Computational Linguistics, pages 505-508, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David McDonald</author>
</authors>
<title>Understanding Noun Compounds.</title>
<date>1982</date>
<tech>Ph.D. thesis,</tech>
<institution>Carnegie Mellon University.</institution>
<contexts>
<context position="1695" citStr="McDonald, 1982" startWordPosition="263" endWordPosition="264"> of compounds have been studied at length in the theoretical linguistics literature. It is a well-known fact that compound noun formation in English is relatively productive (see (1)). Although compounds are typically binary (see (1a,b)), they can be also longer than two words (see (le)). Compounds are commonly written as a concatenation of words (see (1a,b)), or as single words (see (lc)), sometimes a hyphen is also used (see (le)). income tax AT &amp; T headquarters bathroom public-relations income-tax relief The use of noun compounds is frequent not only in technical writing and newswire text (McDonald, 1982) but also in fictional prose (Leonard, 1984), and spoken language (Liberman and Sproat, 1992). Novel compounds are used as a text compression device (Marsh, 1984), i.e., to pack meaning into a minimal amount of linguistic structure, as a deictic device, or as a means to classify an entity which has no specific name (Downing, 1977). Computational investigations of compound nouns have concentrated on their automatic acquisition from corpora, syntactic disambiguation (i.e., determine the structure of compounds like income tax relief), and semantic interpretation (i.e., determine the semantic rela</context>
</contexts>
<marker>McDonald, 1982</marker>
<rawString>David McDonald. 1982. Understanding Noun Compounds. Ph.D. thesis, Carnegie Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>Richard Beckwith</author>
<author>Christiane Fellbaum</author>
<author>Derek Gross</author>
<author>Katherine J Miller</author>
</authors>
<title>Introduction to WordNet: An on-line lexical database.</title>
<date>1990</date>
<journal>International Journal of Lexicography,</journal>
<pages>3--4</pages>
<contexts>
<context position="14857" citStr="Miller et al., 1990" startWordPosition="2469" endWordPosition="2472">esponding to n I was observed as the modifier of c2 corresponding to the head nz. Concept combination frequencies can be thought of as potential lexical rules which capture regularities and constraints on noun compound formation. Counting concept frequencies would be a straightforward task if each word was always represented in the taxonomy by a single concept or if we had a corpus of compounds labeled explicitly with taxonomic information. Lacking such a corpus we need to take into consideration the fact that words in a taxonomy may belong to more than one conceptual class. Nouns in WordNet (Miller et al., 1990) correspond to an average of 11.5 concepts (the word return belongs to 104 distinct conceptual classes), whereas nouns in Roget&apos;s thesaurus correspond to an average of 1.7 concepts (the word point has 18 distinct concepts). Because a head or a modifier can generally be the realization of one of several conceptual classes, counts of modifierhead configurations must be constructed for all potential concept combinations. To give a concrete example consider again the compound cocaine customer. The word cocaine has one sense in WordNet and belongs to six conceptual classes ((hard drug), (narcotic),</context>
</contexts>
<marker>Miller, Beckwith, Fellbaum, Gross, Miller, 1990</marker>
<rawString>George A. Miller, Richard Beckwith, Christiane Fellbaum, Derek Gross, and Katherine J. Miller. 1990. Introduction to WordNet: An on-line lexical database. International Journal of Lexicography, 3(4):235-244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
</authors>
<title>The Generative Lexicon.</title>
<date>1995</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="13211" citStr="Pustejovsky, 1995" startWordPosition="2190" endWordPosition="2191">ell. Concept frequency. Linguistic models of compound noun formation typically involve a hierarchical structure of lexical rules, which capture the regularities of compound noun formation while 237 (c1,c2) f(ci,c2) Examples (substance, obj ect) 604.7 iron table (act, social group) 403.0 mining family (entity, location) 382.4 girls school (group. relation) 267.6 world language (communication, act) 231.1 speech treatment (person, artef act) 162.1 developer&apos;s kit (institution, person) 38.7 bank spokesman Table 3: Estimated concept pair frequencies also ruling out certain compounds as candidates (Pustejovsky, 1995; Copestake and Lascarides, 1997). Each lexical rule takes a pair of nouns of certain semantic type as input, and the output of the rule is a compound noun whose semantic representation stipulates the relation between a modifier and its head. For example, the compounds metal tube, leather belt and tin cup are the result of a lexical rule that combines a noun denoting a substance and a noun denoting an artefact to yield a compound denoting the artefact made of the substance. The noun frequency and probability features do not capture meaning regularities concerning the compounding process. For e</context>
</contexts>
<marker>Pustejovsky, 1995</marker>
<rawString>James Pustejovsky. 1995. The Generative Lexicon. The MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ross J Quinlan</author>
</authors>
<date>1993</date>
<booktitle>C4.5: Programs for Machine Learning. Series in Machine Learning.</booktitle>
<publisher>Morgan</publisher>
<location>Kaufman, San Mateo, CA.</location>
<contexts>
<context position="20959" citStr="Quinlan, 1993" startWordPosition="3475" endWordPosition="3476">compound may push, represented by its parts of speech (NN1 and NN1, respectively) and a context of four words to its right and four words to its left, also reduced to their parts of speech.2 (9) a. Their different responsibilities in relation to the public may push them in opposite directions. b. [NN2, PRP, ATO, AJO, NN1, NN1, PNP, PRP, AJO, NN2] In the following we explore how the two types of features (i.e., numerical and categorical) perform independently as well as in combination. 4 Experiments 4.1 Machine Learning The different features were combined using the C4.5 decision tree learner (Quinlan, 1993). Decision trees are among the most widely used machine learning algorithms. They perform a general to specific search of a feature space, adding the most informative features to a tree structure as the search proceeds. The objective is to select a minimal set of features that efficiently partitions the feature space into classes of observations and assemble them into a tree. For our experiments, the classification is binary, a noun-noun sequence is a compound or not. For comparison we also report the performance of the Naive Bayes classifier (Duda and Hart, 1973). The latter classifier does n</context>
</contexts>
<marker>Quinlan, 1993</marker>
<rawString>Ross J. Quinlan. 1993. C4.5: Programs for Machine Learning. Series in Machine Learning. Morgan Kaufman, San Mateo, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Stuart Resnik</author>
</authors>
<title>Selection and Information: A Class-Based Approach to Lexical Relationships.</title>
<date>1993</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="17090" citStr="Resnik, 1993" startWordPosition="2828" endWordPosition="2829">eoretical linguistics literature (Levi, 1978) that compounds are derived through combinations of distinct conceptsl. For each compound in our corpus we generate the set of concept pairs it is potentially an instantiation of. The compound cocaine customer generates 29 concept pairs (e.g., (artef act, consumer), (artef act, person)). We estimate the frequency of a concept pair f(ci , c2) by summing over all noun-noun sequences ni n2 that are representative of the concept combination (c i, c2) . We divide the contribution of each compound nin2 by the number of concept combinations it represents (Resnik, 1993; Lauer, 1995): f(ni,n2) f(ci,c2) E (7) c(ni,n2)1 ,n2)E ;C2/ Here, f(ni,n2) is the number of times a given noun-noun sequence was observed in the estimation corpus and Ic(ni,n2)1 is the number of conceptual pairs n n2 has. Assuming that we want to take the compound cocaine customer into account for estimating the frequency of the I Dvanda or appositional compounds (e.g., mother child, player coach) are a notable exception. 238 concept pair (art ef act, person), we will increment the observed co-occurrence count of (artef act, person) by 2+,, since cocaine customer is represented by 29 distinct</context>
</contexts>
<marker>Resnik, 1993</marker>
<rawString>Philip Stuart Resnik. 1993. Selection and Information: A Class-Based Approach to Lexical Relationships. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian H Witten</author>
<author>Eibe Frank</author>
</authors>
<date>2000</date>
<booktitle>Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations.</booktitle>
<publisher>Morgan</publisher>
<location>Kaufman, San Francisco, CA.</location>
<contexts>
<context position="21929" citStr="Witten and Frank, 2000" startWordPosition="3637" endWordPosition="3641"> and assemble them into a tree. For our experiments, the classification is binary, a noun-noun sequence is a compound or not. For comparison we also report the performance of the Naive Bayes classifier (Duda and Hart, 1973). The latter classifier does not perform a search through the feature space in order to build a model for classifying future examples. Instead all features are included in the classification. The learner is based on the simplifying assumption that each feature is conditionally independent of all other features, given the class of a given noun-noun sequence. We use the Weka (Witten and Frank, 2000) implementations of the C4.5 decision tree and Naive Bayes learner. The classifiers were trained and tested using 10-fold cross-validation on 1,000 noun-sequences which were attested in the BNC only once. The 2The part-of-speech NN1 stands for singular common nouns, NN2 stands for plural common nouns, ATO stands for determiners, PRP for prepositions, PNP for pronouns, and AJO for adjectives. f(c,,c2) f(nni2) = Kc1.c2)e c (nt &apos;W2) i Ic(nti ,n2&apos; )1 (8) 239 data was annotated by two judges. They were instructed to decide whether a noun-noun sequence is a compound or not and given a page of guidel</context>
</contexts>
<marker>Witten, Frank, 2000</marker>
<rawString>Ian H. Witten and Eibe Frank. 2000. Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations. Morgan Kaufman, San Francisco, CA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>