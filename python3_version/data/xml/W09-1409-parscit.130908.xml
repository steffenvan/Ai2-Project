<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003212">
<title confidence="0.985246">
Extraction of biomedical events using case-based reasoning
</title>
<author confidence="0.611773">
Mariana L. Neves José M. Carazo
</author>
<affiliation confidence="0.6259795">
Biocomputing Unit Biocomputing Unit
Centro Nacional de Biotecnología - CSIC Centro Nacional de Biotecnología - CSIC
</affiliation>
<address confidence="0.9366">
C/ Darwin 3, Campus de Cantoblanco, C/ Darwin 3, Campus de Cantoblanco,
28049, Madrid, Spain 28049, Madrid, Spain
</address>
<email confidence="0.993917">
mlara@cnb.csic.es carazo@cnb.csic.es
</email>
<author confidence="0.986882">
Alberto Pascual-Montano
</author>
<affiliation confidence="0.719514">
Departamento de Arquitectura de Computadores
Universidad Complutense de Madrid, Facultad de
Ciencias Físicas
28040, Madrid, Spain
</affiliation>
<email confidence="0.916978">
pascual@fis.ucm.es
</email>
<sectionHeader confidence="0.995206" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997934">
The BioNLP´09 Shared Task on Event Extrac-
tion presented an evaluation on the extraction
of biological events related to genes/proteins
from the literature. We propose a system that
uses the case-based reasoning (CBR) machine
learning approach for the extraction of the enti-
ties (events, sites and location). The mapping
of the proteins in the texts to the previously ex-
tracted entities is carried out by some simple
manually developed rules for each of the argu-
ments under consideration (cause, theme, site
or location). We have achieved an f-measure of
24.15 and 21.15 for Task 1 and 2, respectively.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9997832">
The increasing amount of biological data gener-
ated by the high throughput experiments has
lead to a great demand of computational tools to
process and interpret such amount of informa-
tion. The protein-protein interactions, as well as
molecular events related to one entity only, are
key issues as they take part in many biological
processes, and many efforts have been dedicate
to this matter. For example, databases are avail-
able for the storage of such interaction pairs,
such as the Molecular INTeraction Database
(Chatr-aryamontri et al., 2007) and IntAct
(Kerrien et al., 2007).
In the field of text mining solutions, many ef-
forts have been made. For example, the Bio-
Creative II protein-protein interaction (PPI) task
(Krallinger, Leitner, Rodriguez-Penagos, &amp; Va-
lencia, 2008) consists of four sub-tasks, includ-
ing the extraction of the protein interaction pairs
in full-text documents, achieving an f-measure
of up to 0.30. The initiative of annotation of
both Genia corpus (J. D. Kim, Ohta, &amp; Tsujii,
2008) and BioInfer (Pyysalo et al., 2007) is an-
other good example.
The BioNLP´09 Shared Task on Event Ex-
traction (J.-D. Kim, Ohta, Pyysalo, Kano, &amp;
Tsujii, 2009) proposes a comparative evaluation
for the extraction of biological events related to
one or more gene/protein and even other types
of entities related to the localization of the re-
ferred event in the cell. The types of events that
have been considered in the shared task were
localization, binding, gene expression, transcrip-
tion, protein catabolism, phosphorylation, regu-
lation, positive regulation and negative
regulation. A corpus that consisted of 800, 150
and 260 PubMed documents (title and abstract
text only) was made available for the training,
development test and testing datasets, respec-
tively. For all documents, the proteins that took
part in the events were provided.
The shared task organization proposed three
tasks. Task 1 (Event detection and characteriza-
tion) required the participants to extract the
events from the text and map them to its respec-
</bodyText>
<page confidence="0.99185">
68
</page>
<note confidence="0.9883215">
Proceedings of the Workshop on BioNLP: Shared Task, pages 68–76,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.99996444">
tive theme(s), as an event may be associated to
one or more themes, e.g. binding. Also, some
events may have only a gene/protein as theme,
e.g. protein catabolism, while some other may
be also associated to another event, e.g. regula-
tion events. Task 2 (Event argument recognition)
asked the participants to provide the many ar-
guments that may be related to the extracted
event, such as its cause, that may be an anno-
tated or one of the previously extracted events.
Other arguments include site and localization,
which should be first extracted from the texts by
the system, as they do not come annotated in the
documents. Task 3 (Recognition of negation and
speculations) evaluates the presence of negations
and speculation related to the previously ex-
tracted events.
Our group has participated in this shared task
with a system implemented with the case-based
reasoning (CBR) machine learning technique
as well as some manual rules. We have pre-
sented results for tasks 1 and 2 exclusively. The
system described here is part of the Moara pro-
ject1 and was developed in Java programming
language and use MySQL database.
</bodyText>
<sectionHeader confidence="0.993051" genericHeader="introduction">
2 Methods
</sectionHeader>
<bodyText confidence="0.999651944444444">
Case-based reasoning (CBR) (Aamodt &amp; Plaza,
1994) is the machine learning method that was
used for extracting the terms and events here
proposed and consists of first learning cases
from the training documents, by means of saving
them in a base of case, and further retrieving a
case the most similar to a given problem during
the testing step, from which will be given the
final solution, hereafter called “case-solution”.
One of the advantages of the CBR algorithm is
the possibility of getting an explanation of why
to a given token has been attributed a certain
category, by means of checking the features that
compose the case-solution. Additionally, and
due to the complexity of the tasks, a rule-based
post-processing step was built in order to map
the previously extracted terms and events among
themselves.
</bodyText>
<footnote confidence="0.94808">
1 http://moara.dacya.ucm.es
</footnote>
<subsectionHeader confidence="0.999208">
2.1 Retaining the cases
</subsectionHeader>
<bodyText confidence="0.9999081">
In this first step, documents of the training data-
set are tokenized according to spaces and punc-
tuations. The resulting tokens are represented in
the CBR approach as cases composed of some
predefined features that take into account the
morphology and grammatical function of the
tokens in the text as well as specific features
related to the problem under consideration. The
resulting cases are then stored in a base of case
to be further retrieved (Figure 1).
</bodyText>
<figureCaption confidence="0.997859666666667">
Figure 1: Training step in which cases are repre-
sented by some pre-defined features and further
saved to a base.
</figureCaption>
<bodyText confidence="0.999808105263158">
Regarding the features that compose a case,
these were the ones that were considered during
the training and development phases: the token
itself (token); the token in lower case (lower-
case); the stem of the token (stem); the shape of
the token (shape); the part-of-speech tag
(posTag); the chunk tag (chunkTag); a biomedi-
cal entity tag (entityTag); the type of the term
(termType); the type of the event (eventType);
and the part of the term in the event (eventPart).
The stem of a token was extracted using an
available Java implementation2 of the Porter al-
gorithm (Porter, 1980), while the part-of-speech,
chunk and bio-entity tags were taken from the
GENIA Tagger (Tsuruoka et al., 2005).
The shape of a token is given by a set of char-
acters that represent its morphology: “a” for
lower case letters, “A” for upper case letters, “1”
for numbers, “g” for Greek letters, “p” for stop-
</bodyText>
<footnote confidence="0.973718">
2 http://www.tartarus.org/~martin/PorterStemmer
</footnote>
<page confidence="0.999413">
69
</page>
<bodyText confidence="0.9993859">
words3, “$” for identifying 3-letters prefixes or
suffixes or any other symbol represented by it-
self. Here are some few example for the shape
feature: “Dorsal” would be represented by “Aa”,
“Bmp4” by “Aa1”, “the” by “p”, “cGKI(alpha)”
by “aAAA(g)”, “patterning” by “pat$a” (‘$’
symbol separating the 3-letters prefix) and “ac-
tivity” by “a$vity” (‘$’ symbol separating the 4-
letters suffix). No repetition is allowed in the
case of the “a” symbol for the lower case letters.
</bodyText>
<figureCaption confidence="0.999076">
Figure 2: Example of the termType, eventType and
partEvent features.
</figureCaption>
<bodyText confidence="0.999989928571429">
The last three features listed above are specific
to the event detection task and were extracted
from the annotation files (.a1 and .a2) that are
part of the corpus. The termType feature is used
to identify the type of the term in the event prob-
lem, and it is extracted from the term lines of
both annotation files .a1 and .a2, i.e. the ones
which the identifiers starts with a “T”. The
eventType features represent the event itself and
it is extracted from the event lines of .a2 annota-
tion file, i.e. the ones that starts with an “E”. Fi-
nally, eventPart represents the token according
to its role, i.e. entity, theme, cause, site and loca-
tion. The termType, eventType and eventPart
features are the hereafter called “feature-
problem”, the features that are unknown to the
system in the testing phase and which values are
to be given by the case-solution. Figure 2 illus-
trate one example of these features for an extract
of the annotation of the document “1315834”
from the training dataset.
Usually, one case corresponds for each token
of the documents in the training dataset. How-
ever, more than one case may be created from a
token, as well as none at all, depending on the
predefined features. For example, some tokens
may derive in more than one case due to the
shape feature, as for example, “patterning”
</bodyText>
<page confidence="0.973145">
3
</page>
<bodyText confidence="0.983659304347826">
http://www.dcs.gla.ac.uk/idom/ir_resources/linguistic_utils/
(“pat$a”, “a$ing”, “a”). Also, according to the
retaining strategy, some tokens may be associ-
ated to no case at all, for example, by restricting
the value of a determined feature as the retaining
strategy. In order to reduce the number of re-
tained cases, and consequently reduce the further
retrieving time, only those tokens related to an
event are retained, i.e., tokens with not null
value for the termType feature.
The text of a document may be read in the
forward or backward direction during the train-
ing step, and even combining both of them
(Neves, Chagoyen, Carazo, &amp; Pascual-Montano,
2008). Here, we have considered the forward
direction exclusively. Also, another important
point is the window of tokens under considera-
tion when setting the features of a case, if taking
into account only the token itself or also the sur-
rounding tokens, the ones which come before or
after it. Here we consider a window of (-1,0),
i.e., for each token, we get the feature of the to-
ken itself and of the preceding one, exclusively.
</bodyText>
<table confidence="0.9357959">
Features / Tokens Training Testing
-1 0 -1 0
stem ✓ ✓ ✓ ✓
shape ✓ ✓
posTag ✓ ✓ ✓ ✓
chunkTag
entityTag ✓ ✓ ✓ ✓
termType ✓ ✓ ✓ ✓
eventType ✓ ✓ ✓
partEvent ✓ ✓ ✓
</table>
<tableCaption confidence="0.767139">
Table 1: Selected features in the training and testing
steps for the tokens “0” and “-1”. The last three fea-
tures are the ones to be inferred.
</tableCaption>
<bodyText confidence="0.999872714285714">
Many experiments have been carried out in or-
der to choose the best set of features (Table 1).
The higher the number of features under consid-
eration, the greater is the number of cases to be
retained and the higher is the time needed to
search for the case-solution. He relies therefore
the importance of choosing a small an efficient
set of features. For this reason, the shape fea-
tures has not been considered for the preceding
token (-1) in order to reduce the number of
cases, as this shape usually result in more than
one case per token. The termType feature is at
the same time known and unknown in the testing
step. It is know for the protein terms but is un-
</bodyText>
<page confidence="0.987969">
70
</page>
<bodyText confidence="0.999922">
known for the remaining entities (events, sites
and locations).
By considering these features for the 800
documents in the training set, about 26,788
unique cases were generated. It should be noted
that no repetition of cases with the same values
for the features are allowed, instead a field for
the frequency of the case is incremented to keep
track of the number of times that it has appeared
during the training phase. The frequency range
goes from 1 (more than 22,000 cases) to 238
(one case only).
</bodyText>
<subsectionHeader confidence="0.999874">
2.2 Retrieving a case
</subsectionHeader>
<bodyText confidence="0.999907555555555">
When a new document is presented to the sys-
tem, it is first read in the forward direction and
tokenized according to space and punctuation
and the resulting tokens are mapped to cases of
features, exactly as discussed in the retaining
step. The only difference here is the set of fea-
ture (cf. Table 1), as some of them are unknown
to the system and are the ones to be inferred
from the cases retained during the training step.
</bodyText>
<figureCaption confidence="0.999044666666667">
Figure 3: Retrieval procedure to choose the most
case-solution with higher frequency and based on
MMF and MFC parameters.
</figureCaption>
<bodyText confidence="0.999987355932204">
For each token, the system first creates a case
(hereafter called “case-problem”) based on the
testing features and proceeds to search the base
of cases for the case-solution the most similar to
this case-problem (Figure 3). It should be noted
that a token may have more than one case-
problem, depending of the values of the shape
feature. The best case-solution among the ones
found by the system will be the one with the
higher frequency. The system always tries to
find a case-solution with the higher number of
features that have exactly the same value of the
case-problem’s respective features. The stem is
the only mandatory feature which value must be
always matched between the case-problem and
the case-solution. The value of the two features-
problem (eventType and partEvent) will be
given by the values of the case-solution’s re-
spective features. If no case solution is found,
the token is considered of not being related to
the event domain in none of its parts (entity,
theme, cause, etc.).
Two parameters have been taken into consid-
eration in the retaining strategy: the minimum
matching feature (MMF) and the minimum fre-
quency of the case (MFC). The first one set the
minimum features that should be matched be-
tween the case-problem and the case-solution, as
the higher the number of equal features between
theses cases, the more precise is the decision
inferred from the case-solution.
On the other hand, the MFC parameter re-
stricts the cases that are to be considered by the
search strategy, the ones with frequency higher
than the value specified by this parameter. The
higher the minimum frequency asked for a case,
the lower is the number of cases under consid-
eration and the lower is the time for obtaining
the case-solution. From the 26,788 cases we
have retained during the training phase, about
22,389 of them appeared just once and would
not be considered by the searching procedure if
the MFC parameter was set to 2, for example,
therefore reducing the searching time.
Experiments have been carried out in order to
decide the values for both parameters and it re-
sulted that a better performance is achieved (cf.
3) by setting the MFC to a value higher than 1.
On the other hand, experiments have shown that
the recall may decrease considerably when re-
stricting the MMF parameter.
By repeating this procedure for all the tokens
of the document, the latter may be then consid-
ered as being tagged with the event entities.
However, in order to construct the output file
required by the shared task organization, some
manual rules have been created in order to map
the events mapped to its respective arguments,
as described in the next section.
</bodyText>
<subsectionHeader confidence="0.997317">
2.3 Post-processing rules
</subsectionHeader>
<bodyText confidence="0.999962">
For the tasks 1 and 2, the participants were
asked to output the events present in the pro-
vided texts along with their respective argu-
ments. The events have been already extracted
in the previous step; the tokens that were tagged
as “Entity” for the “partEvent” feature (cf. Fig-
</bodyText>
<page confidence="0.993758">
71
</page>
<bodyText confidence="0.999331666666667">
ure 2), hereafter called “event-entity”. This en-
tity is the start point from which to search for the
arguments which are incrementally extracted
from the text in the following order: theme,
theme 2, cause, site and location. Figure 4 re-
sumes the rules for each of the arguments.
</bodyText>
<figureCaption confidence="0.9990405">
Figure 4: Resume of the post-processing rules for
each type of argument.
</figureCaption>
<bodyText confidence="0.999858444444444">
Themes: The theme-candidates for an event-
entity are the annotated proteins (.a1 file) as well
as the events themselves, in the case of the regu-
lation, positive regulation and negative regula-
tion events. The first step is then to try to map
each event to its theme and in case that no theme
is found, the event is not considered anymore by
the system and it is not printed to the output file.
The theme searching strategy starts from the
event-entity and consists of reading the text in
both directions alternatively, one token in the
forward direction followed by one token in the
backward direction until a theme-candidate is
found (Figure 5). The system halts if the end of
the sentence is found or if the specified number
of tokens in each direction is reached, 20 for the
theme. By analyzing some of the false negatives
returned from the experiments with the devel-
opment dataset, we have learned that few events
are associated to themes present in a different
sentence and although aware these cases, we
have decided to restrict the searching to the sen-
tence boundaries in order to avoid a high num-
ber of false positives.
In the case of a second theme, allowed for
binding events only, a similar searching strategy
is carried out, except that here the system reads
up of 10 tokens in each direction, starting from
the theme entity previously extracted.
Cause: The cause-candidates are also the an-
notated proteins and, starting from the event-
entity, a similar search is carried out, restricted
up to 30 tokens in each direction and to the
boundaries of the same sentence. This procedure
is carried out for the regulation, positive regula-
tion and negative regulation events only and the
only extra restriction is that the candidate should
not be the protein already assigned as theme. If
no candidate is found, the system considers that
there is no cause associated to the event under
consideration.
Site and Location: Here the candidates are
the tokens tagged with the values of “Entity” for
the termType feature, and “Site” and “Location”
for the partEvent feature, respectively. The
search for the site is carried out for the binding
and phosphorylation events and the location
search for the localization event only. The pro-
cedure is restricted to the sentence boundaries
and up to 20 and 30 tokens, respectively, starting
from the event-entity. Once again, if not candi-
date is found, the system consider that there is
no site or location associated to the event under
consideration.
</bodyText>
<figureCaption confidence="0.9806355">
Figure 5: Contribution of each class of error to the
275 false positives analyzed here.
</figureCaption>
<sectionHeader confidence="0.99986" genericHeader="background">
3 Results
</sectionHeader>
<bodyText confidence="0.9999212">
This section presents the results of the experi-
ments carried out with the development and the
blind test datasets as well as an analysis of the
false negatives and false positives. Results here
will be presented for tasks 1 and 2 in terms of
precision, recall and f-measure.
Experiments have been carried out with the
development dataset in order to decide the best
value of the MMF and MFC parameters (cf.
2.2). Figure 6 shows the variation of the F-
measure according to both parameters for the
values of 1, 3, 4, 5, 6, 7 and 8 for MMF; and 1,
2, 5, 10, 15, 20 and 50 for MFC.
Usually, recall is higher for a low value of
MFC, as the searching for the case-solution is
</bodyText>
<page confidence="0.99612">
72
</page>
<bodyText confidence="0.999298166666667">
carried out over a greater number of cases and
the possibility of finding a good case-problem is
higher. On the other hand, precision increases
when few cases are under considered by the
search strategy, as fewer decisions are taken and
the cases-solution have usually a high frequency,
avoiding decision based on “weak” cases of fre-
quency 1, for example.
Figure 6 shows that the best value for MFC
ranges from 2 to 20 and for MMF from 5 to 7
and the best f-measure result is found for the
values of 2 and 6 for these parameters (f2m6),
respectively. As these experiments have been
carried out after the deadline of the test dataset,
the run that was submitted as the final solution
was the one with the values of 2 and 1 for the
MFC and MMF parameters (f2m1), respectively.
Table 3 and 4 resumes the results obtained for
the test dataset with the configuration that was
submitted (f2m1), and the best one (f2m6) after
accomplishing the experiments above described.
Results have slightly improved by only trying to
choose the best values for the parameters here
considered.
</bodyText>
<figureCaption confidence="0.9491195">
Figure 6: F-Measure for the development dataset in
terms of the MFC (curves) and the MMF (x-axis).
</figureCaption>
<bodyText confidence="0.99995984">
An automatic analysis of the false positives and
false negatives has been performed for the de-
velopment dataset and for the results obtained
with the final submission (f2m1), a total of 2502
false positives and 1300 false negatives. We
have found out that the mistakes are related
mainly to the retrieving of the case-solution and
to the mapping of an event to its arguments. The
mistakes have been classified in seven groups
described below and figures 7 and 8 show the
percent contribution of each class for the false
positives and false negatives, respectively.
Events composed of more than one token
(1): this mistake happens when the system is
able to find the event with its correct type and
arguments but with only part of its tokens, such
as “regulation” instead of “up-regulation” and
“reduced” or “levels” instead of “reduced lev-
els”, both in document 10411003. This is mainly
due to our tokenization strategy of separating the
tokens according to all punctuation and symbols
(including hyphens) and also due to the evalua-
tion method that seems not consider alternatives
to the text of an event. This mistake always re-
sults in one false positive and one false negative.
</bodyText>
<table confidence="0.946351666666667">
tasks / recall precision f-measure
results
task 1 (f2m1) 28.63 20.88 24.15
(f2m6) 27.18 23.92 25.45
task 2 (f2m1) 25.02 18.32 21.15
(f2m6) 24.49 21.63 22.97
</table>
<tableCaption confidence="0.945905">
Table 3: Results for the test dataset (tasks 1 and 2).
</tableCaption>
<table confidence="0.99584975">
Results / (f2m1) (f2m6)
Events
p r fm p r fm
prot. catab. 78.6 55.0 64.7 71.4 55.6 65.5
phosphoryl. 49.6 56.1 52.7 46.0 55.2 50.2
transcript. 48.9 19.8 28.1 38.7 29.6 33.5
neg. reg. 9.8 7.9 8.8 7.9 7.7 7.8
pos. reg. 10.0 6.6 7.9 10.2 8.0 9.0
regulation 8.6 4.5 5.9 7.5 5.3 6.3
localizat. 28.2 42.9 34.0 23.3 48.9 33.3
gene expr. 51.8 55.1 53.4 52.6 61.2 56.6
binding 19.5 12.1 14.9 22.4 14.4 17.5
</table>
<tableCaption confidence="0.999911">
Table 4: Results by event for Task 2 on test dataset.
</tableCaption>
<bodyText confidence="0.999571333333333">
Events and arguments in different sentences
of the text (2): as we already discussed in sec-
tion 2.3, our arguments searching strategy is re-
stricted to the boundaries of the sentence. Some
examples of this mistake may be found in
document 10395645 in which two events of the
token “activation [1354-1364]” is mapped to the
themes “caspase-6 [1190-1199]” and “CPP32
[1165-1170]”, both located in a different sen-
tence. This mistake usually affects only the false
negatives but may cause also a false positive if
the system happens to find a valid (wrong) ar-
</bodyText>
<figure confidence="0.980612230769231">
F-Measure
23
21
19
17
15
13
11
9
7
1 3 4 5 6 7 8
Minimum matching features
1 2 5 10 15 20 50
</figure>
<page confidence="0.990089">
73
</page>
<bodyText confidence="0.98112">
gument in the same sentences for the event un-
der consideration.
</bodyText>
<figureCaption confidence="0.99957825">
Figure 7: Percent contribution of each error to the
false positives.
Figure 8: Percent contribution of each error to the
false negatives.
</figureCaption>
<bodyText confidence="0.999873701492538">
Decision for a case (3): this class of error is due
to the selection of a wrong case-solution and we
include in this class mistakes due to two situa-
tions: when the system fails to find any case-
solution for an event token (false negative) or
when a case-solution is found for a non-event
token (false positive). The first situation is only
dependent of the searching strategy and its two
parameters (MMF and MFC) while the second
one is also related to the post-processing step, if
the latter succeeds to find a theme for the incor-
rectly extracted event. An example of a false
negative that falls in this group is “dysregulation
[727-740]” from document 10229231 that failed
to be mapped to a case-solution. Regarding the
false positives, this class of mistake is the major-
ity of them and it is due to the low precision of
the system that frequently is able to find cases-
solution associated to tokens that are not events
at all, such as the token “transcript [392-402]” of
document 10229231. It should be noted that the
incorrect association of a token to a case-
solution does not result in a false positive a pri-
ori, but only if the post-processing step happen
to find a valid theme to it, a mistake further de-
scribed in group 5.
Wrong type of the event (4): this class of
mistake is also due to the wrong selection of a
case-solution, but the difference here is that the
token is really an event, but the case-solution is
of the wrong type, i.e. it has a wrong value for
the eventType feature. The causes of this mis-
take are many, such as, the selection of features
(cf. Table 1) or the value of the MFC parameter
that may lead to the selection of a wrong but
more frequent case. We also include in this
group the few false negatives mistakes in which
a token is associated to more than one type of
event in the gold-standard, such as the token
“Overexpression [475-489]” from document
10229231 that is associated both to a Gene Ex-
pression and to a Positive Regulation event. One
way of overcome it would be to allow the sys-
tem to associated more than one case to a token,
taking the risk of decreasing the precision.
Theme detection (5): in this group falls more
than half of the false negatives and we include
here only those mistakes in which the token was
correctly associated to a case-solution of the cor-
rect type. These mistakes may be due to a vari-
ety of situations related to the theme detection,
such as: the association of the event to another
event when it should have been done to a protein
or vice-versa (for the regulation events); the
mapping of a binding event to one theme only
when it should have been two theme or vice-
versa; the association of the event to the wrong
protein theme, especially when there is more
than one nearby; and even not being able to find
any theme at all. Also, half of theses mistakes
happen when an event is associated to more than
one theme separately, not as a second theme. For
example, the token “associated [278-288]”, from
document 10196286, is associated in the gold
standard to three themes – “tumor necrosis fac-
tor receptor-associated factor (TRAF) 1 [294-
351]”, “2 [353-354]” and “3 [359-360]” – and
</bodyText>
<figure confidence="0.998304025641026">
False Positives
cause
detection
(6); 1,6
theme
detection
(5); 14,6
site/location
detection
(7); 1,6
event type
(4); 2,7
composed
tokens (1);
5,2
case
decision (3);
74,3
site/location
detection
(7); 0,7
cause
detection
(6); 4,2
theme
detection
(5); 56,2
event type
(4); 10,0
different
sentences
(2); 1,4
False Negatives
composed
tokens (1);
10,4
case
decision (3);
17,2
</figure>
<page confidence="0.994154">
74
</page>
<bodyText confidence="0.999994833333333">
we were only able to extract the first of them.
This is due to the fact that we restrict the system
to search only one “first” and one “second”
theme for each event.
Cause detection (6): similar to the previous
class, these mistakes happens when associating a
cause to an event (regulation events only) when
there is no cause related to it or vice-versa. For
example, in document 10092805, the system has
correctly mapped the token “decreases [1230-
1239]” to the theme “4E-BP1 [1240-1246]” but
also associated to it an inexistent cause “4E-BP2
[1315-1321]”. The evaluation of Task 2 does not
allow the partial evaluation of an event and
therefore a false positive and a false negative
would be returned for the example above.
Site/Location detection (7): this error is
similar to the previous one but related only to
binding, phosphorylation and localization
events, when the system fails to associate a site
or a location to an event or vice-versa. For ex-
ample, in document 10395671, the token “phos-
phorylation [1091-1106]” was correctly mapped
to the theme “Janus kinase 3 [1076-1090]” but
was also associated to an inexistent site “DNA
[1200-1203]”. Once again, the evaluation of
Task 2 does not allow the partial evaluation of
the event and a false positive and a false nega-
tive would be returned.
We have also carried out an evaluation of our
own in order to check the performance of our
system only on the extraction the entities (event,
site and location), not taking into account the
association to the arguments. Table 5 resumes
the values of precision, recall and f-measure for
each type of term. The high recall confirm that
most of the entities were successful extracted
although the precision is not always satisfactory,
proving that the tagging of the entities is not as
hard a task as it is the mapping of the arguments.
Additional results and more a detailed analysis
of the errors may be found at Moara page4.
</bodyText>
<sectionHeader confidence="0.99984" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.99465175">
Results show that our system has performed
relatively well using a simple methodology of a
machine learning based extraction of the entities
and manual rules developed for the post-
</bodyText>
<footnote confidence="0.558559">
4 http://moara.dacya.ucm.es/results_shared_task.html
</footnote>
<bodyText confidence="0.95670419047619">
processing step. The analysis of the mistakes
presented here confirms the complexity of the
tasks proposed but not the extraction of the
event terms (cf. Table 5).
We consider that the part of our system that
requires most our attention is the retrieval of the
case-solution and the theme detection of the
post-processing step, in order to increase the
precision and recall, respectively. The decision
of searching for a second theme and of associat-
ing a single event separately to more than one
theme is hard to be accomplished by manual
rules and could better be learned automatically
using a machine learning algorithm.
Events (f2m1) (f2m6)
p r fm p r fm
prot. catab. 70.8 89.5 79.1 69.6 84.2 76.2
phosphoryl. 75.0 94.7 83.7 79.1 89.5 84.0
transcript. 22.7 75.9 34.9 36.4 74.6 48.9
neg. reg. 26.4 56.5 36.0 25.3 43.5 32.0
pos. reg. 24.3 63.7 35.2 26.5 59.1 36.6
</bodyText>
<table confidence="0.6473305">
regulation 20.8 65.9 31.7 22.1 52.5 31.1
localizat. 47.7 79.5 59.6 49.1 66.7 56.5
gene expr. 46.5 83.4 59.7 50.8 80.2 62.2
binding 29.7 71.1 41.9 29.7 64.4 40.7
entity 12.5 55.3 20.4 16.8 50.0 25.1
TOTAL 27.5 69.2 39.4 30.9 62.9 41.4
</table>
<tableCaption confidence="0.8928445">
Table 5: Evaluation of the extraction of the event and
site/location entities for the development dataset.
</tableCaption>
<bodyText confidence="0.9999585">
The automatic analysis of the false positive and
false negative mistakes is a hard task since no
hint is given for the reason of the mistake by the
evaluation system, if due to the event type or to
wrong theme, an incorrectly association to an
event or even a missing cause or site.
</bodyText>
<sectionHeader confidence="0.998361" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999866833333333">
This work has been partially funded by the
Spanish grants BIO2007-67150-C03-02, S-Gen-
0166/2006, PS-010000-2008-1, TIN2005-5619.
APM acknowledges the support of the Spanish
Ramón y Cajal program. The authors acknowl-
edge support from Integromics, S.L.
</bodyText>
<sectionHeader confidence="0.999473" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99981525">
Aamodt, A., &amp; Plaza, E. (1994). Case-Based Reason-
ing: Foundational Issues, Methodological Varia-
tions, and System Approaches. AI
Communications, 7(1), 39-59.
</reference>
<page confidence="0.979293">
75
</page>
<reference confidence="0.999399414634147">
Chatr-aryamontri, A., Ceol, A., Palazzi, L. M.,
Nardelli, G., Schneider, M. V., Castagnoli, L., et
al. (2007). MINT: the Molecular INTeraction da-
tabase. Nucleic Acids Res, 35(Database issue),
D572-574.
Kerrien, S., Alam-Faruque, Y., Aranda, B., Bancarz,
I., Bridge, A., Derow, C., et al. (2007). IntAct--
open source resource for molecular interaction
data. Nucleic Acids Res, 35(Database issue),
D561-565.
Kim, J.-D., Ohta, T., Pyysalo, S., Kano, Y., &amp; Tsujii,
J. i. (2009). Overview of BioNLP&apos;09 Shared Task
on Event Extraction. Paper presented at the Pro-
ceedings of Natural Language Processing in Bio-
medicine (BioNLP) NAACL 2009 Workshop,
Boulder, CO, USA.
Kim, J. D., Ohta, T., &amp; Tsujii, J. (2008). Corpus an-
notation for mining biomedical events from litera-
ture. BMC Bioinformatics, 9, 10.
Krallinger, M., Leitner, F., Rodriguez-Penagos, C., &amp;
Valencia, A. (2008). Overview of the protein-
protein interaction annotation extraction task of
BioCreative II. Genome Biol, 9 Suppl 2, S4.
Neves, M., Chagoyen, M., Carazo, J. M., &amp; Pascual-
Montano, A. (2008). CBR-Tagger: a case-based
reasoning approach to the gene/protein mention
problem. Paper presented at the Proceedings of
the BioNLP 2008 Workshop at ACL 2008, Co-
lumbus, OH, USA.
Porter, M. (1980). An algorithm for suffix stripping.
Program, 14(3), 130-137.
Pyysalo, S., Ginter, F., Heimonen, J., Bjorne, J.,
Boberg, J., Jarvinen, J., et al. (2007). BioInfer: a
corpus for information extraction in the biomedi-
cal domain. BMC Bioinformatics, 8, 50.
Tsuruoka, Y., Tateishi, Y., Kim, J.-D., Ohta, T.,
McNaught, J., Ananiadou, S., et al. (2005). De-
veloping a Robust Part-of-Speech Tagger for
Biomedical Text. Paper presented at the Advances
in Informatics - 10th Panhellenic Conference on
Informatics.
</reference>
<page confidence="0.991579">
76
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.315453">
<title confidence="0.99655">Extraction of biomedical events using case-based reasoning</title>
<author confidence="0.999976">Mariana L Neves José M Carazo</author>
<affiliation confidence="0.910007333333333">Biocomputing Unit Biocomputing Unit Centro Nacional de Biotecnología - CSIC Centro Nacional de Biotecnología - CSIC C/ Darwin 3, Campus de Cantoblanco, C/ Darwin 3, Campus de Cantoblanco,</affiliation>
<address confidence="0.99753">28049, Madrid, Spain 28049, Madrid, Spain</address>
<title confidence="0.621929">mlara@cnb.csic.es carazo@cnb.csic.es</title>
<author confidence="0.996784">Alberto Pascual-Montano</author>
<affiliation confidence="0.897479666666667">Departamento de Arquitectura de Universidad Complutense de Madrid, Facultad Ciencias</affiliation>
<address confidence="0.99388">28040, Madrid,</address>
<email confidence="0.994632">pascual@fis.ucm.es</email>
<abstract confidence="0.993779142857143">The BioNLP´09 Shared Task on Event Extraction presented an evaluation on the extraction of biological events related to genes/proteins from the literature. We propose a system that uses the case-based reasoning (CBR) machine learning approach for the extraction of the entities (events, sites and location). The mapping of the proteins in the texts to the previously extracted entities is carried out by some simple manually developed rules for each of the arguments under consideration (cause, theme, site or location). We have achieved an f-measure of 24.15 and 21.15 for Task 1 and 2, respectively.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Aamodt</author>
<author>E Plaza</author>
</authors>
<title>Case-Based Reasoning: Foundational Issues, Methodological Variations, and System Approaches.</title>
<date>1994</date>
<journal>AI Communications,</journal>
<volume>7</volume>
<issue>1</issue>
<pages>39--59</pages>
<contexts>
<context position="4520" citStr="Aamodt &amp; Plaza, 1994" startWordPosition="704" endWordPosition="707">ts by the system, as they do not come annotated in the documents. Task 3 (Recognition of negation and speculations) evaluates the presence of negations and speculation related to the previously extracted events. Our group has participated in this shared task with a system implemented with the case-based reasoning (CBR) machine learning technique as well as some manual rules. We have presented results for tasks 1 and 2 exclusively. The system described here is part of the Moara project1 and was developed in Java programming language and use MySQL database. 2 Methods Case-based reasoning (CBR) (Aamodt &amp; Plaza, 1994) is the machine learning method that was used for extracting the terms and events here proposed and consists of first learning cases from the training documents, by means of saving them in a base of case, and further retrieving a case the most similar to a given problem during the testing step, from which will be given the final solution, hereafter called “case-solution”. One of the advantages of the CBR algorithm is the possibility of getting an explanation of why to a given token has been attributed a certain category, by means of checking the features that compose the case-solution. Additio</context>
</contexts>
<marker>Aamodt, Plaza, 1994</marker>
<rawString>Aamodt, A., &amp; Plaza, E. (1994). Case-Based Reasoning: Foundational Issues, Methodological Variations, and System Approaches. AI Communications, 7(1), 39-59.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Chatr-aryamontri</author>
<author>A Ceol</author>
<author>L M Palazzi</author>
<author>G Nardelli</author>
<author>M V Schneider</author>
<author>L Castagnoli</author>
</authors>
<title>MINT: the Molecular INTeraction database. Nucleic Acids Res,</title>
<date>2007</date>
<booktitle>35(Database issue),</booktitle>
<pages>572--574</pages>
<contexts>
<context position="1705" citStr="Chatr-aryamontri et al., 2007" startWordPosition="252" endWordPosition="255">ed an f-measure of 24.15 and 21.15 for Task 1 and 2, respectively. 1 Introduction The increasing amount of biological data generated by the high throughput experiments has lead to a great demand of computational tools to process and interpret such amount of information. The protein-protein interactions, as well as molecular events related to one entity only, are key issues as they take part in many biological processes, and many efforts have been dedicate to this matter. For example, databases are available for the storage of such interaction pairs, such as the Molecular INTeraction Database (Chatr-aryamontri et al., 2007) and IntAct (Kerrien et al., 2007). In the field of text mining solutions, many efforts have been made. For example, the BioCreative II protein-protein interaction (PPI) task (Krallinger, Leitner, Rodriguez-Penagos, &amp; Valencia, 2008) consists of four sub-tasks, including the extraction of the protein interaction pairs in full-text documents, achieving an f-measure of up to 0.30. The initiative of annotation of both Genia corpus (J. D. Kim, Ohta, &amp; Tsujii, 2008) and BioInfer (Pyysalo et al., 2007) is another good example. The BioNLP´09 Shared Task on Event Extraction (J.-D. Kim, Ohta, Pyysalo, </context>
</contexts>
<marker>Chatr-aryamontri, Ceol, Palazzi, Nardelli, Schneider, Castagnoli, 2007</marker>
<rawString>Chatr-aryamontri, A., Ceol, A., Palazzi, L. M., Nardelli, G., Schneider, M. V., Castagnoli, L., et al. (2007). MINT: the Molecular INTeraction database. Nucleic Acids Res, 35(Database issue), D572-574.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kerrien</author>
<author>Y Alam-Faruque</author>
<author>B Aranda</author>
<author>I Bancarz</author>
<author>A Bridge</author>
<author>C Derow</author>
</authors>
<title>IntAct--open source resource for molecular interaction data. Nucleic Acids Res,</title>
<date>2007</date>
<booktitle>35(Database issue),</booktitle>
<pages>561--565</pages>
<contexts>
<context position="1739" citStr="Kerrien et al., 2007" startWordPosition="258" endWordPosition="261"> 1 and 2, respectively. 1 Introduction The increasing amount of biological data generated by the high throughput experiments has lead to a great demand of computational tools to process and interpret such amount of information. The protein-protein interactions, as well as molecular events related to one entity only, are key issues as they take part in many biological processes, and many efforts have been dedicate to this matter. For example, databases are available for the storage of such interaction pairs, such as the Molecular INTeraction Database (Chatr-aryamontri et al., 2007) and IntAct (Kerrien et al., 2007). In the field of text mining solutions, many efforts have been made. For example, the BioCreative II protein-protein interaction (PPI) task (Krallinger, Leitner, Rodriguez-Penagos, &amp; Valencia, 2008) consists of four sub-tasks, including the extraction of the protein interaction pairs in full-text documents, achieving an f-measure of up to 0.30. The initiative of annotation of both Genia corpus (J. D. Kim, Ohta, &amp; Tsujii, 2008) and BioInfer (Pyysalo et al., 2007) is another good example. The BioNLP´09 Shared Task on Event Extraction (J.-D. Kim, Ohta, Pyysalo, Kano, &amp; Tsujii, 2009) proposes a c</context>
</contexts>
<marker>Kerrien, Alam-Faruque, Aranda, Bancarz, Bridge, Derow, 2007</marker>
<rawString>Kerrien, S., Alam-Faruque, Y., Aranda, B., Bancarz, I., Bridge, A., Derow, C., et al. (2007). IntAct--open source resource for molecular interaction data. Nucleic Acids Res, 35(Database issue), D561-565.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J-D Kim</author>
<author>T Ohta</author>
<author>S Pyysalo</author>
<author>Y Kano</author>
<author>J i Tsujii</author>
</authors>
<date>2009</date>
<booktitle>Overview of BioNLP&apos;09 Shared Task on Event Extraction. Paper presented at the Proceedings of Natural Language Processing in Biomedicine (BioNLP) NAACL 2009 Workshop,</booktitle>
<location>Boulder, CO, USA.</location>
<contexts>
<context position="2325" citStr="Kim, Ohta, Pyysalo, Kano, &amp; Tsujii, 2009" startWordPosition="350" endWordPosition="356">montri et al., 2007) and IntAct (Kerrien et al., 2007). In the field of text mining solutions, many efforts have been made. For example, the BioCreative II protein-protein interaction (PPI) task (Krallinger, Leitner, Rodriguez-Penagos, &amp; Valencia, 2008) consists of four sub-tasks, including the extraction of the protein interaction pairs in full-text documents, achieving an f-measure of up to 0.30. The initiative of annotation of both Genia corpus (J. D. Kim, Ohta, &amp; Tsujii, 2008) and BioInfer (Pyysalo et al., 2007) is another good example. The BioNLP´09 Shared Task on Event Extraction (J.-D. Kim, Ohta, Pyysalo, Kano, &amp; Tsujii, 2009) proposes a comparative evaluation for the extraction of biological events related to one or more gene/protein and even other types of entities related to the localization of the referred event in the cell. The types of events that have been considered in the shared task were localization, binding, gene expression, transcription, protein catabolism, phosphorylation, regulation, positive regulation and negative regulation. A corpus that consisted of 800, 150 and 260 PubMed documents (title and abstract text only) was made available for the training, development test and testing datasets, respe</context>
</contexts>
<marker>Kim, Ohta, Pyysalo, Kano, Tsujii, 2009</marker>
<rawString>Kim, J.-D., Ohta, T., Pyysalo, S., Kano, Y., &amp; Tsujii, J. i. (2009). Overview of BioNLP&apos;09 Shared Task on Event Extraction. Paper presented at the Proceedings of Natural Language Processing in Biomedicine (BioNLP) NAACL 2009 Workshop, Boulder, CO, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D Kim</author>
<author>T Ohta</author>
<author>J Tsujii</author>
</authors>
<title>Corpus annotation for mining biomedical events from literature.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<volume>9</volume>
<pages>10</pages>
<contexts>
<context position="2169" citStr="Kim, Ohta, &amp; Tsujii, 2008" startWordPosition="325" endWordPosition="329">atter. For example, databases are available for the storage of such interaction pairs, such as the Molecular INTeraction Database (Chatr-aryamontri et al., 2007) and IntAct (Kerrien et al., 2007). In the field of text mining solutions, many efforts have been made. For example, the BioCreative II protein-protein interaction (PPI) task (Krallinger, Leitner, Rodriguez-Penagos, &amp; Valencia, 2008) consists of four sub-tasks, including the extraction of the protein interaction pairs in full-text documents, achieving an f-measure of up to 0.30. The initiative of annotation of both Genia corpus (J. D. Kim, Ohta, &amp; Tsujii, 2008) and BioInfer (Pyysalo et al., 2007) is another good example. The BioNLP´09 Shared Task on Event Extraction (J.-D. Kim, Ohta, Pyysalo, Kano, &amp; Tsujii, 2009) proposes a comparative evaluation for the extraction of biological events related to one or more gene/protein and even other types of entities related to the localization of the referred event in the cell. The types of events that have been considered in the shared task were localization, binding, gene expression, transcription, protein catabolism, phosphorylation, regulation, positive regulation and negative regulation. A corpus that con</context>
</contexts>
<marker>Kim, Ohta, Tsujii, 2008</marker>
<rawString>Kim, J. D., Ohta, T., &amp; Tsujii, J. (2008). Corpus annotation for mining biomedical events from literature. BMC Bioinformatics, 9, 10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Krallinger</author>
<author>F Leitner</author>
<author>C Rodriguez-Penagos</author>
<author>A Valencia</author>
</authors>
<title>Overview of the proteinprotein interaction annotation extraction task of BioCreative II.</title>
<date>2008</date>
<journal>Genome Biol,</journal>
<volume>9</volume>
<pages>4</pages>
<contexts>
<context position="1937" citStr="Krallinger, Leitner, Rodriguez-Penagos, &amp; Valencia, 2008" startWordPosition="285" endWordPosition="291">ional tools to process and interpret such amount of information. The protein-protein interactions, as well as molecular events related to one entity only, are key issues as they take part in many biological processes, and many efforts have been dedicate to this matter. For example, databases are available for the storage of such interaction pairs, such as the Molecular INTeraction Database (Chatr-aryamontri et al., 2007) and IntAct (Kerrien et al., 2007). In the field of text mining solutions, many efforts have been made. For example, the BioCreative II protein-protein interaction (PPI) task (Krallinger, Leitner, Rodriguez-Penagos, &amp; Valencia, 2008) consists of four sub-tasks, including the extraction of the protein interaction pairs in full-text documents, achieving an f-measure of up to 0.30. The initiative of annotation of both Genia corpus (J. D. Kim, Ohta, &amp; Tsujii, 2008) and BioInfer (Pyysalo et al., 2007) is another good example. The BioNLP´09 Shared Task on Event Extraction (J.-D. Kim, Ohta, Pyysalo, Kano, &amp; Tsujii, 2009) proposes a comparative evaluation for the extraction of biological events related to one or more gene/protein and even other types of entities related to the localization of the referred event in the cell. The </context>
</contexts>
<marker>Krallinger, Leitner, Rodriguez-Penagos, Valencia, 2008</marker>
<rawString>Krallinger, M., Leitner, F., Rodriguez-Penagos, C., &amp; Valencia, A. (2008). Overview of the proteinprotein interaction annotation extraction task of BioCreative II. Genome Biol, 9 Suppl 2, S4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Neves</author>
<author>M Chagoyen</author>
<author>J M Carazo</author>
<author>A PascualMontano</author>
</authors>
<title>CBR-Tagger: a case-based reasoning approach to the gene/protein mention problem.</title>
<date>2008</date>
<booktitle>Paper presented at the Proceedings of the BioNLP 2008 Workshop at ACL 2008,</booktitle>
<location>Columbus, OH, USA.</location>
<marker>Neves, Chagoyen, Carazo, PascualMontano, 2008</marker>
<rawString>Neves, M., Chagoyen, M., Carazo, J. M., &amp; PascualMontano, A. (2008). CBR-Tagger: a case-based reasoning approach to the gene/protein mention problem. Paper presented at the Proceedings of the BioNLP 2008 Workshop at ACL 2008, Columbus, OH, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Porter</author>
</authors>
<title>An algorithm for suffix stripping.</title>
<date>1980</date>
<journal>Program,</journal>
<volume>14</volume>
<issue>3</issue>
<pages>130--137</pages>
<contexts>
<context position="6494" citStr="Porter, 1980" startWordPosition="1034" endWordPosition="1035">es and further saved to a base. Regarding the features that compose a case, these were the ones that were considered during the training and development phases: the token itself (token); the token in lower case (lowercase); the stem of the token (stem); the shape of the token (shape); the part-of-speech tag (posTag); the chunk tag (chunkTag); a biomedical entity tag (entityTag); the type of the term (termType); the type of the event (eventType); and the part of the term in the event (eventPart). The stem of a token was extracted using an available Java implementation2 of the Porter algorithm (Porter, 1980), while the part-of-speech, chunk and bio-entity tags were taken from the GENIA Tagger (Tsuruoka et al., 2005). The shape of a token is given by a set of characters that represent its morphology: “a” for lower case letters, “A” for upper case letters, “1” for numbers, “g” for Greek letters, “p” for stop2 http://www.tartarus.org/~martin/PorterStemmer 69 words3, “$” for identifying 3-letters prefixes or suffixes or any other symbol represented by itself. Here are some few example for the shape feature: “Dorsal” would be represented by “Aa”, “Bmp4” by “Aa1”, “the” by “p”, “cGKI(alpha)” by “aAAA(g</context>
</contexts>
<marker>Porter, 1980</marker>
<rawString>Porter, M. (1980). An algorithm for suffix stripping. Program, 14(3), 130-137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pyysalo</author>
<author>F Ginter</author>
<author>J Heimonen</author>
<author>J Bjorne</author>
<author>J Boberg</author>
<author>J Jarvinen</author>
</authors>
<title>BioInfer: a corpus for information extraction in the biomedical domain.</title>
<date>2007</date>
<journal>BMC Bioinformatics,</journal>
<volume>8</volume>
<pages>50</pages>
<contexts>
<context position="2206" citStr="Pyysalo et al., 2007" startWordPosition="332" endWordPosition="335">le for the storage of such interaction pairs, such as the Molecular INTeraction Database (Chatr-aryamontri et al., 2007) and IntAct (Kerrien et al., 2007). In the field of text mining solutions, many efforts have been made. For example, the BioCreative II protein-protein interaction (PPI) task (Krallinger, Leitner, Rodriguez-Penagos, &amp; Valencia, 2008) consists of four sub-tasks, including the extraction of the protein interaction pairs in full-text documents, achieving an f-measure of up to 0.30. The initiative of annotation of both Genia corpus (J. D. Kim, Ohta, &amp; Tsujii, 2008) and BioInfer (Pyysalo et al., 2007) is another good example. The BioNLP´09 Shared Task on Event Extraction (J.-D. Kim, Ohta, Pyysalo, Kano, &amp; Tsujii, 2009) proposes a comparative evaluation for the extraction of biological events related to one or more gene/protein and even other types of entities related to the localization of the referred event in the cell. The types of events that have been considered in the shared task were localization, binding, gene expression, transcription, protein catabolism, phosphorylation, regulation, positive regulation and negative regulation. A corpus that consisted of 800, 150 and 260 PubMed doc</context>
</contexts>
<marker>Pyysalo, Ginter, Heimonen, Bjorne, Boberg, Jarvinen, 2007</marker>
<rawString>Pyysalo, S., Ginter, F., Heimonen, J., Bjorne, J., Boberg, J., Jarvinen, J., et al. (2007). BioInfer: a corpus for information extraction in the biomedical domain. BMC Bioinformatics, 8, 50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Tsuruoka</author>
<author>Y Tateishi</author>
<author>J-D Kim</author>
<author>T Ohta</author>
<author>J McNaught</author>
<author>S Ananiadou</author>
</authors>
<title>Developing a Robust Part-of-Speech Tagger for Biomedical Text.</title>
<date>2005</date>
<booktitle>Paper presented at the Advances in Informatics - 10th Panhellenic Conference on Informatics.</booktitle>
<contexts>
<context position="6604" citStr="Tsuruoka et al., 2005" startWordPosition="1049" endWordPosition="1052">were considered during the training and development phases: the token itself (token); the token in lower case (lowercase); the stem of the token (stem); the shape of the token (shape); the part-of-speech tag (posTag); the chunk tag (chunkTag); a biomedical entity tag (entityTag); the type of the term (termType); the type of the event (eventType); and the part of the term in the event (eventPart). The stem of a token was extracted using an available Java implementation2 of the Porter algorithm (Porter, 1980), while the part-of-speech, chunk and bio-entity tags were taken from the GENIA Tagger (Tsuruoka et al., 2005). The shape of a token is given by a set of characters that represent its morphology: “a” for lower case letters, “A” for upper case letters, “1” for numbers, “g” for Greek letters, “p” for stop2 http://www.tartarus.org/~martin/PorterStemmer 69 words3, “$” for identifying 3-letters prefixes or suffixes or any other symbol represented by itself. Here are some few example for the shape feature: “Dorsal” would be represented by “Aa”, “Bmp4” by “Aa1”, “the” by “p”, “cGKI(alpha)” by “aAAA(g)”, “patterning” by “pat$a” (‘$’ symbol separating the 3-letters prefix) and “activity” by “a$vity” (‘$’ symbo</context>
</contexts>
<marker>Tsuruoka, Tateishi, Kim, Ohta, McNaught, Ananiadou, 2005</marker>
<rawString>Tsuruoka, Y., Tateishi, Y., Kim, J.-D., Ohta, T., McNaught, J., Ananiadou, S., et al. (2005). Developing a Robust Part-of-Speech Tagger for Biomedical Text. Paper presented at the Advances in Informatics - 10th Panhellenic Conference on Informatics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>