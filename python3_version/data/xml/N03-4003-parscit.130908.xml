<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.719384">
<note confidence="0.95989">
Proceedings of HLT-NAACL 2003
Demonstrations , pp. 5-6
Edmonton, May-June 2003
</note>
<title confidence="0.9342895">
DOGHED: A Template-Based Generator for Multimodal Dialog Systems
Targeting Heterogeneous Devices∗
</title>
<author confidence="0.990316">
Songsak Channarukul and Susan W. McRoy and Syed S. Ali
</author>
<affiliation confidence="0.989246333333333">
Natural Language and Knowledge Representation Research Group
Department of Electrical Engineering and Computer Science
University of Wisconsin-Milwaukee
</affiliation>
<email confidence="0.998926">
{songsak,mcroy,syali}@uwm.edu
</email>
<sectionHeader confidence="0.999637" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999971">
This paper describes DOGHED (Dialog Output Gener-
ator for HEterogeneous Devices), a multimodal genera-
tion component which is a part of a dialog system that
supports adaptation of multimodal content based on user
preferences and their current device. Existing dialog sys-
tems focus on generating output for a single device that
might not be suitable when users access the system us-
ing different devices. Multimedia presentation systems
can be built that support several device types. However,
most content presentation and layout is done off-line and
defined at the document level.
Dialog facilitates the process of tailoring the interac-
tion to the dynamically changing needs of the user. With
support for dialog, a computer can regulate the pace at
which users receive content, help focus the user’s atten-
tion, and interleave actions that will help the system mon-
itor (and adjust) to the user’s understanding or satisfac-
tion. Minimally, dialog systems should adapt the interac-
tion to the user’s ability to understand. However, dialog
systems should also be able to adapt to the user’s comput-
ing environment, because people access computers not
only through traditional workstations and terminals, but
also through personal digital assistants and cellular tele-
phones. Each of these devices has a distinct set of phys-
ical capabilities, as well as a distinct set of functions for
which it is typically used.
</bodyText>
<sectionHeader confidence="0.994908" genericHeader="method">
2 DOGHED
</sectionHeader>
<bodyText confidence="0.999191655172414">
DOGHED is a template-based multimodal output gen-
erator for dialog systems that need to support hetero-
geneous devices. It enables dialog systems to create
multimodal presentations for different devices in real-
time. DOGHED extends YAG (Yet Another Generator),
∗We acknowledge the financial support of the National
Science Foundation (under grants IRI-9701617 and DUE-
9952703), Wright State University, and Intel Corporation.
a template-based text realization system (Channarukul et
al., 2000; Channarukul et al., 2001; McRoy et al., 2003)
by providing a pre-defined set of multimodal templates.
It employs JYAG (Channarukul et al., 2002), the Java im-
plementation of YAG, to realize those templates for fur-
ther display by appropriate browsers. It provides output
in the Synchronized Multimedia Integration Language
(SMIL) which can be presented on any SMIL player such
as RealOne Player and X-SMILES (Pihkala et al., 2001);
or any capable web browser.
DOGHED is a generic and domain-independent com-
ponent for generating multimodal presentations in that it
accepts a feature structure as input. These feature struc-
tures can also embed other feature structures to represent
a more complicated input specification. Moreover, an ap-
plication can specify content, user preferences, and de-
vice constraints (e.g., multimedia capabilities, screen size
and resolution, and network bandwidth) using this uni-
form formalism. Natural language can also be inserted
by embedding a feature structure that calls for realization
using one or more YAG’s English syntactic templates.
</bodyText>
<sectionHeader confidence="0.993118" genericHeader="method">
3 Multimodal Templates
</sectionHeader>
<bodyText confidence="0.999967714285714">
There are two types of multimodal templates. The first
type is for generating individual SMIL tags and struc-
tures. The other type is more abstract and captures the
semantics of multimodal presentation. A semantic tem-
plate can be authored so that an application only needs to
specify its selected content, intended presentation style,
and other constraints. Output will then be generated to
best suit the given style and constraints. For example, an
application might want to compare two diagrams or items
that are related. On large display devices, both items can
be displayed side-by-side. However, on smaller display
devices, like PDAs, such presentation is not possible; it
would be better to display one item at a time and switch
between the two items being compared.
</bodyText>
<figureCaption confidence="0.998997">
Figure 1: A Screenshot of IDEY with an Integrated SMIL Player.
</figureCaption>
<sectionHeader confidence="0.962738" genericHeader="method">
4 Template Authoring Tool
</sectionHeader>
<bodyText confidence="0.99999">
In addition to the pre-defined multimodal template set,
application developers can write their own templates to
suit their needs. These new templates can be written from
scratch or built on top of existing ones. We facilitate
the task of template authoring by providing a graphical
development environment. IDEY (Integrated Develop-
ment Environment for YAG) provides support for author-
ing, testing, and managing templates (Channarukul et al.,
2002). Its graphical interface reduces the amount of time
needed for syntax familiarization through direct manip-
ulation and template visualization. It also allows a de-
veloper to test newly constructed templates easily. Mul-
timodal output can be immediately displayed and veri-
fied on an integrated SMIL player (Figure 1). Moreover,
the interface also helps prevent errors by constraining the
way in which templates may be constructed or modified.
For example, values of slots in templates are constrained
by context-sensitive pop-up menu choices.
</bodyText>
<sectionHeader confidence="0.998394" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99961396">
Songsak Channarukul, Susan W. McRoy, and Syed S.
Ali. 2000. Enriching Partially-Specified Representa-
tions for Text Realization using An Attribute Grammar.
In Proceedings of The First International Natural Lan-
guage Generation Conference, pages 163–170, Israel,
June.
Songsak Channarukul, Susan McRoy, and Syed Ali.
2001. YAG: A Template-Based Text Realization Sys-
tem for Dialog. Journal of Uncertainty, Fuzziness, and
Knowledge-Based Systems, 9(6):649–659.
Songsak Channarukul, Susan W. McRoy, and Syed S.
Ali. 2002. JYAG and IDEY: a Template-Based Nat-
ural Language Generator and Its Authoring Tool. In
Companion Volume to the Proceedings of the 40th
Meeting of the Association for Computational Linguis-
tics (ACL), pages 89–90, July.
Susan W. McRoy, Songsak Channarukul, and Syed S.
Ali. 2003. An Augmented Template-Based Approach
to Text Realization. Natural Language Engineering,
9(2):1–40.
Kari Pihkala, Niklas von Knorring, and Petri Vuorimaa.
2001. SMIL for X-SMILES. In Proceedings of the
Seventh International Conference on Distributed Mul-
timedia Systems, Tamkang University, Taipei, Taiwan,
September.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.608933">
<note confidence="0.915261333333333">Proceedings of HLT-NAACL 2003 Demonstrations , pp. 5-6 Edmonton, May-June 2003</note>
<title confidence="0.989167">DOGHED: A Template-Based Generator for Multimodal Dialog Systems Heterogeneous</title>
<author confidence="0.845343">Channarukul W McRoy S</author>
<affiliation confidence="0.975705">Natural Language and Knowledge Representation Research Department of Electrical Engineering and Computer University of Wisconsin-Milwaukee</affiliation>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Songsak Channarukul</author>
<author>Susan W McRoy</author>
<author>Syed S Ali</author>
</authors>
<title>Enriching Partially-Specified Representations for Text Realization using An Attribute Grammar.</title>
<date>2000</date>
<booktitle>In Proceedings of The First International Natural Language Generation Conference,</booktitle>
<pages>163--170</pages>
<contexts>
<context position="2330" citStr="Channarukul et al., 2000" startWordPosition="342" endWordPosition="345">se devices has a distinct set of physical capabilities, as well as a distinct set of functions for which it is typically used. 2 DOGHED DOGHED is a template-based multimodal output generator for dialog systems that need to support heterogeneous devices. It enables dialog systems to create multimodal presentations for different devices in realtime. DOGHED extends YAG (Yet Another Generator), ∗We acknowledge the financial support of the National Science Foundation (under grants IRI-9701617 and DUE9952703), Wright State University, and Intel Corporation. a template-based text realization system (Channarukul et al., 2000; Channarukul et al., 2001; McRoy et al., 2003) by providing a pre-defined set of multimodal templates. It employs JYAG (Channarukul et al., 2002), the Java implementation of YAG, to realize those templates for further display by appropriate browsers. It provides output in the Synchronized Multimedia Integration Language (SMIL) which can be presented on any SMIL player such as RealOne Player and X-SMILES (Pihkala et al., 2001); or any capable web browser. DOGHED is a generic and domain-independent component for generating multimodal presentations in that it accepts a feature structure as input</context>
</contexts>
<marker>Channarukul, McRoy, Ali, 2000</marker>
<rawString>Songsak Channarukul, Susan W. McRoy, and Syed S. Ali. 2000. Enriching Partially-Specified Representations for Text Realization using An Attribute Grammar. In Proceedings of The First International Natural Language Generation Conference, pages 163–170, Israel, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Songsak Channarukul</author>
<author>Susan McRoy</author>
<author>Syed Ali</author>
</authors>
<title>YAG: A Template-Based Text Realization System for Dialog.</title>
<date>2001</date>
<journal>Journal of Uncertainty, Fuzziness, and Knowledge-Based Systems,</journal>
<volume>9</volume>
<issue>6</issue>
<contexts>
<context position="2356" citStr="Channarukul et al., 2001" startWordPosition="346" endWordPosition="349">set of physical capabilities, as well as a distinct set of functions for which it is typically used. 2 DOGHED DOGHED is a template-based multimodal output generator for dialog systems that need to support heterogeneous devices. It enables dialog systems to create multimodal presentations for different devices in realtime. DOGHED extends YAG (Yet Another Generator), ∗We acknowledge the financial support of the National Science Foundation (under grants IRI-9701617 and DUE9952703), Wright State University, and Intel Corporation. a template-based text realization system (Channarukul et al., 2000; Channarukul et al., 2001; McRoy et al., 2003) by providing a pre-defined set of multimodal templates. It employs JYAG (Channarukul et al., 2002), the Java implementation of YAG, to realize those templates for further display by appropriate browsers. It provides output in the Synchronized Multimedia Integration Language (SMIL) which can be presented on any SMIL player such as RealOne Player and X-SMILES (Pihkala et al., 2001); or any capable web browser. DOGHED is a generic and domain-independent component for generating multimodal presentations in that it accepts a feature structure as input. These feature structures</context>
</contexts>
<marker>Channarukul, McRoy, Ali, 2001</marker>
<rawString>Songsak Channarukul, Susan McRoy, and Syed Ali. 2001. YAG: A Template-Based Text Realization System for Dialog. Journal of Uncertainty, Fuzziness, and Knowledge-Based Systems, 9(6):649–659.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Songsak Channarukul</author>
<author>Susan W McRoy</author>
<author>Syed S Ali</author>
</authors>
<title>JYAG and IDEY: a Template-Based Natural Language Generator and Its Authoring Tool.</title>
<date>2002</date>
<booktitle>In Companion Volume to the Proceedings of the 40th Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>89--90</pages>
<contexts>
<context position="2476" citStr="Channarukul et al., 2002" startWordPosition="365" endWordPosition="368"> a template-based multimodal output generator for dialog systems that need to support heterogeneous devices. It enables dialog systems to create multimodal presentations for different devices in realtime. DOGHED extends YAG (Yet Another Generator), ∗We acknowledge the financial support of the National Science Foundation (under grants IRI-9701617 and DUE9952703), Wright State University, and Intel Corporation. a template-based text realization system (Channarukul et al., 2000; Channarukul et al., 2001; McRoy et al., 2003) by providing a pre-defined set of multimodal templates. It employs JYAG (Channarukul et al., 2002), the Java implementation of YAG, to realize those templates for further display by appropriate browsers. It provides output in the Synchronized Multimedia Integration Language (SMIL) which can be presented on any SMIL player such as RealOne Player and X-SMILES (Pihkala et al., 2001); or any capable web browser. DOGHED is a generic and domain-independent component for generating multimodal presentations in that it accepts a feature structure as input. These feature structures can also embed other feature structures to represent a more complicated input specification. Moreover, an application c</context>
</contexts>
<marker>Channarukul, McRoy, Ali, 2002</marker>
<rawString>Songsak Channarukul, Susan W. McRoy, and Syed S. Ali. 2002. JYAG and IDEY: a Template-Based Natural Language Generator and Its Authoring Tool. In Companion Volume to the Proceedings of the 40th Meeting of the Association for Computational Linguistics (ACL), pages 89–90, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan W McRoy</author>
<author>Songsak Channarukul</author>
<author>Syed S Ali</author>
</authors>
<title>An Augmented Template-Based Approach to Text Realization.</title>
<date>2003</date>
<journal>Natural Language Engineering,</journal>
<volume>9</volume>
<issue>2</issue>
<contexts>
<context position="2377" citStr="McRoy et al., 2003" startWordPosition="350" endWordPosition="353">es, as well as a distinct set of functions for which it is typically used. 2 DOGHED DOGHED is a template-based multimodal output generator for dialog systems that need to support heterogeneous devices. It enables dialog systems to create multimodal presentations for different devices in realtime. DOGHED extends YAG (Yet Another Generator), ∗We acknowledge the financial support of the National Science Foundation (under grants IRI-9701617 and DUE9952703), Wright State University, and Intel Corporation. a template-based text realization system (Channarukul et al., 2000; Channarukul et al., 2001; McRoy et al., 2003) by providing a pre-defined set of multimodal templates. It employs JYAG (Channarukul et al., 2002), the Java implementation of YAG, to realize those templates for further display by appropriate browsers. It provides output in the Synchronized Multimedia Integration Language (SMIL) which can be presented on any SMIL player such as RealOne Player and X-SMILES (Pihkala et al., 2001); or any capable web browser. DOGHED is a generic and domain-independent component for generating multimodal presentations in that it accepts a feature structure as input. These feature structures can also embed other</context>
</contexts>
<marker>McRoy, Channarukul, Ali, 2003</marker>
<rawString>Susan W. McRoy, Songsak Channarukul, and Syed S. Ali. 2003. An Augmented Template-Based Approach to Text Realization. Natural Language Engineering, 9(2):1–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kari Pihkala</author>
<author>Niklas von Knorring</author>
<author>Petri Vuorimaa</author>
</authors>
<title>SMIL for X-SMILES.</title>
<date>2001</date>
<booktitle>In Proceedings of the Seventh International Conference on Distributed Multimedia Systems,</booktitle>
<institution>Tamkang University,</institution>
<location>Taipei, Taiwan,</location>
<marker>Pihkala, von Knorring, Vuorimaa, 2001</marker>
<rawString>Kari Pihkala, Niklas von Knorring, and Petri Vuorimaa. 2001. SMIL for X-SMILES. In Proceedings of the Seventh International Conference on Distributed Multimedia Systems, Tamkang University, Taipei, Taiwan, September.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>