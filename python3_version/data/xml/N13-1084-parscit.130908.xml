<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007932">
<title confidence="0.719677">
Distributional semantic models for the evaluation of disordered language
</title>
<author confidence="0.66043">
Masoud Rouhizadeh†, Emily Prud’hommeaux◦, Brian Roark†, Jan van Santen††Center for Spoken Language Understanding, Oregon Health &amp; Science University
</author>
<affiliation confidence="0.605708">
◦Center for Language Sciences, University of Rochester
</affiliation>
<email confidence="0.985703">
{rouhizad,vansantjl@ohsu.edu, {emilypx,roarkbr}@gmail.com
</email>
<sectionHeader confidence="0.984387" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999924352941176">
Atypical semantic and pragmatic expression is
frequently reported in the language of children
with autism. Although this atypicality often
manifests itself in the use of unusual or un-
expected words and phrases, the rate of use
of such unexpected words is rarely directly
measured or quantified. In this paper, we
use distributional semantic models to automat-
ically identify unexpected words in narrative
retellings by children with autism. The classi-
fication of unexpected words is sufficiently ac-
curate to distinguish the retellings of children
with autism from those with typical develop-
ment. These techniques demonstrate the po-
tential of applying automated language anal-
ysis techniques to clinically elicited language
data for diagnostic purposes.
</bodyText>
<sectionHeader confidence="0.992527" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999980520833333">
Autism spectrum disorder (ASD) is a neurodevelop-
mental disorder characterized by impaired commu-
nication and social behavior. Although the symp-
toms of ASD are numerous and varied, atypical
and idiosyncratic language has been one of the
core symptoms observed in verbal individuals with
autism since Kanner first assigned a name to the
disorder (Kanner, 1943). Atypical language cur-
rently serves as a diagnostic criterion in many of the
most widely used diagnostic instruments for ASD
(Lord et al., 2002; Rutter et al., 2003), and the phe-
nomenon is especially marked in the areas of seman-
tics and pragmatics (Tager-Flusberg, 2001; Volden
and Lord, 1991).
Because structured language assessment tools are
not always sensitive to the particular atypical seman-
tic and pragmatic expression associated with ASD,
measures of atypical language are often drawn from
spontaneous language samples. Expert manual an-
notation and analysis of spontaneous language in
young people with ASD has revealed that children
and young adults with autism include significantly
more bizarre and irrelevant content (Loveland et al.,
1990; Losh and Capps, 2003) in their narratives and
more abrupt topic changes (Lam et al., 2012) in
their conversations than their language-matched typ-
ically developing peers. Most normed clinical in-
struments for analyzing children’s spontaneous lan-
guage, however, focus on syntactic measures and
developmental milestones related to the acquisition
of vocabulary and syntactic structures. Measures of
semantic and pragmatic atypicality in spontaneous
language are rarely directly measured. Instead, the
degree of language atypicality is often determined
via subjective parental reports (e.g., asking a par-
ent whether their child has ever used odd phrases
(Rutter et al., 2003)) or general impressions dur-
ing clinical examination (e.g., rating the child’s de-
gree of “stereotyped or idiosyncratic use of words or
phrases” on a four-point scale (Lord et al., 2002)).
This has led to a lack of reliable and objective infor-
mation about the frequency of atypical language use
and its precise nature in ASD.
In this study, we attempt to automatically detect
instances of contextually atypical language in spon-
taneous speech at the lexical level in order to quan-
tify its prevalence in the ASD population. We first
determine manually the off-topic, surprising, or in-
</bodyText>
<equation confidence="0.305019">
709
Proceedings of NAACL-HLT 2013, pages 709–714,
</equation>
<bodyText confidence="0.985931210526316">
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
appropriate words in a set of narrative retellings
elicited in a clinical setting from children with ASD
and typical development. We then apply word rank-
ing methods and distributional semantic modeling to
these narrative retellings in order to automatically
identify these unexpected words. The results indi-
cate not only that children with ASD do in fact pro-
duce more semantically unexpected and inappropri-
ate words in their narratives than typically develop-
ing children but also that our automated methods
for identifying these words are accurate enough to
serve as an adequate substitute for manual annota-
tion. Although unexpected off-topic word use is just
one example of the atypical language observed in
ASD, the work presented here highlights the poten-
tial of computational language evaluation and analy-
sis methods for improving our understanding of the
linguistic deficits associated with ASD.
</bodyText>
<sectionHeader confidence="0.977466" genericHeader="introduction">
2 Data
</sectionHeader>
<bodyText confidence="0.999937">
Participants in this study included 37 children with
typical development (TD) and 21 children with
autism spectrum disorder (ASD). ASD was diag-
nosed via clinical consensus according to the DSM-
IV-TR criteria (American Psychiatric Association,
2000) and the established threshold scores on two
diagnostic instruments: the Autism Diagnostic Ob-
servation Schedule (ADOS) (Lord et al., 2002), a
semi-structured series of activities designed to allow
an examiner to observe behaviors associated with
autism; and the Social Communication Question-
naire (SCQ) (Rutter et al., 2003), a parental ques-
tionnaire. None of the children in this study met
the criteria for a language impairment, and there
were no significant between-group differences in
age (mean=6.4) or full-scale IQ (mean=114).
The narrative retelling task analyzed here is the
Narrative Memory subtest of the NEPSY (Korkman
et al., 1998), a large and comprehensive battery of
tasks that test neurocognitive functioning in chil-
dren. The NEPSY Narrative Memory (NNM) sub-
test is a narrative retelling test in which the subject
listens to a brief narrative, excerpts of which are
shown in Figure 1, and then must retell the narra-
tive to the examiner. The NNM was administered
to each participant in the study, and each partici-
pant’s retelling was recorded and transcribed. Us-
ing Amazon’s Mechanical Turk, we also collected
a large corpus of retellings from neurotypical adults,
who listened to a recording of the story and provided
written retellings. We describe how this corpus was
used in Section 3, below.
Two annotators, blind to the diagnosis of the ex-
perimental subjects, identified every word in each
retelling transcript that was unexpected or inappro-
priate given the larger context of the story. For in-
stance, in the sentence T-rex could smell things, both
T-rex and smell were marked as unexpected, since
there is no mention of either concept in the story. In
a seemingly more appropriate sentence, the boy sat
up off the bridge, the word bridge is considered un-
expected since the boy is trapped up in a tree rather
than on a bridge.
</bodyText>
<sectionHeader confidence="0.99588" genericHeader="method">
3 Methods
</sectionHeader>
<bodyText confidence="0.9998118">
We start with the expectation that different retellings
of the same source narrative will share a common
vocabulary and semantic space. The presence of
words outside of this vocabulary or semantic space
in a retelling may indicate that the speaker has
strayed from the topic of the story. Our approach for
automatically identifying these unexpected words
relies on the ranking of words according to the
strength of their association with the target topic of
the corpus. The word association scores used in the
</bodyText>
<figureCaption confidence="0.995509">
Figure 1: Excerpts from the NNM narrative.
</figureCaption>
<bodyText confidence="0.986464735294117">
Jim was a boy whose best friend was Pepper. Pepper was a big black dog. [...] Near Jim’s house was a
very tall oak tree with branches so high that he couldn’t reach them. Jim always wanted to climb that tree,
so one day he took a ladder from home and carried it to the oak tree. He climbed up [...] When he started
to get down, his foot slipped, his shoe fell off, and the ladder fell to the ground. [...] Pepper sat below the
tree and barked. Suddenly Pepper took Jim’s shoe in his mouth and ran away. [...] Pepper took the shoe to
Anna, Jim’s sister. He barked and barked. Finally, Anna understood that Jim was in trouble. She followed
Pepper to the tree where Jim was stuck. Anna put the ladder up and rescued Jim.
710
ranking are informed by the frequency of a word
in the child’s retelling relative to the frequency of
that word in other retellings in the larger corpus of
retellings. These association measures are similar
to those developed for the information retrieval task
of topic modeling, in which the goal is to identify
topic-specific words – i.e., words that appear fre-
quently in only a subset of documents – in order
to cluster together documents about a similar topic.
Details about how these scores are calculated and in-
terpreted are provided in the following sections.
The pipeline for determining the set of unusual
words in each retelling begins by calculating word
association scores, described below, for each word
in each retelling and ranking the words according to
these scores. A threshold over these scores is de-
termined for each child using leave-one-out cross
validation in order to select a set of potentially un-
expected words. This set of potential unexpected
words is then filtered using two external resources
that allow us to eliminate words that were not used
in other retellings but are likely to be semantically
related to topic of the narrative. This final set of
words is evaluated against the set of manually iden-
tified words in order determine the accuracy of our
unexpected word classification.
</bodyText>
<subsectionHeader confidence="0.99603">
3.1 Word association measures
</subsectionHeader>
<bodyText confidence="0.999992857142857">
Before calculating the word association measures,
we tokenize, downcase, and stem (Porter, 1980) the
transcripts and remove all punctuation. We then use
two association measures to score each word in each
child’s retelling: tf-idf, the term frequency-inverse
document frequency measure (Salton and Buckley,
1988), and the log odds ratio (van Rijsbergen et al.,
1981). We use the following formulation to calcu-
late tf-idf for each child’s retelling i and each word
in that retelling j, where cij is the count of word j
in retelling i; fj is the number of retellings from the
full corpus of child and adult retellings containing
that word j; and D is the total number of retellings
in the full corpus (Manning et al., 2008):
</bodyText>
<equation confidence="0.8536">
�
ad _ (1 + log cij) log f, D if cij &gt; 1
</equation>
<bodyText confidence="0.996948166666667">
tf fzj 0 otherwise
The log odds ratio, another association measure
used in information retrieval and extraction tasks, is
the ratio between the odds of a particular word, j,
appearing in a child’s retelling, i, as estimated us-
ing its relative frequency in that retelling, and the
odds of that word appearing in all other retellings,
again estimated using its relative frequency in all
other retellings. Letting the probability of a word
appearing in a retelling be p1 and the probability of
that word appearing in all other retellings be p2, we
can express the odds ratio as follows:
</bodyText>
<equation confidence="0.992636333333333">
odds(p1)
odds ratio =
odds(p2)
</equation>
<bodyText confidence="0.999955875">
A large tf-idf or log odds score indicates that the
word j is very specific to the retelling i, which in
turn suggests that the word might be unexpected or
inappropriate in the larger context of the NNM nar-
rative. Thus we expect that the words with higher as-
sociation measure scores are likely to be the words
that were manually identified as unexpected in the
context of the NNM narrative.
</bodyText>
<subsectionHeader confidence="0.999513">
3.2 Application of word association measures
</subsectionHeader>
<bodyText confidence="0.999993384615385">
As previously mentioned, both of these word associ-
ation measures are used in information retrieval (IR)
to cluster together documents about a similar target
topic. In IR, words that appear only in a subset of
documents from a large and varied corpus of docu-
ments will have high word association scores, and
the documents containing those words will likely be
focused on the same topic. In our task, however,
we have a single cluster of documents focused on
a single topic: the NNM narrative. Topic-specific
words ought to occur much more frequently than
other words. As a result, words with high tf-idf and
log odds scores are likely to be those unrelated to
the topic of the NNM story. If a child veers away
from the topic of the NNM story and uses words that
do not occur frequently in the retellings produced
by neurotypical speakers, his retellings will contain
more words with high word association scores. We
predict that this set of high-scoring words is likely to
overlap significantly with the set of words identified
by the manual annotators as unexpected or off-topic.
Applying these word association scoring ap-
proaches to each word in each child’s retelling yields
a list of words from each retelling ranked in order of
decreasing tf-idf or log odds score. We use cross-
validation to determine, for each measure, the op-
</bodyText>
<equation confidence="0.911202666666667">
p1/(1 − p1)
p2/(1 − p2)
711
</equation>
<bodyText confidence="0.999969352941177">
erating point that maximizes the unexpected word
identification accuracy in terms of F-measure. For
each child, the threshold is found using the data from
all of the other children. This threshold is then ap-
plied to the ranked word list of the held-out child.
All words above this threshold are potential unex-
pected words, while all words below this threshold
are considered to be expected and appropriate in the
context of the NNM narrative. Table 1 shows the
recall, precision, and F-measure using the two word
association measures discussed here. We see that
these two techniques result in high recall at the ex-
pense of precision. The next stage in the pipeline is
therefore to use external resources to eliminate any
semantically appropriate words from the set of po-
tentially unexpected or inappropriate words gener-
ated via thresholding on the tf-idf or log odds score.
</bodyText>
<subsectionHeader confidence="0.999739">
3.3 Filtering with external resources
</subsectionHeader>
<bodyText confidence="0.999988113636364">
Recall that the corpus of retellings used to gener-
ate the word association measures described above,
is very small. It is therefore quite possible that a
child may have used an entirely appropriate word
that by chance was never used by another child or
one of the neurotypical adults. One way of increas-
ing the lexical coverage of the corpus of retellings
is through semantic expansion using an external re-
source. For each word in the set of potential un-
expected words, we located the WordNet synset for
that word (Fellbaum, 1998). If any of the WordNet
synonyms of the potentially unexpected word was
present in the source narrative or in one of the adult
retellings, that word was removed from the set of
unexpected words.
In the final step, we used the CHILDES corpus
of transcripts of children’s conversational speech
(MacWhinney, 2000) to generate topic estimates for
each remaining potentially unexpected word. For
each of these words, we located every utterance in
the CHILDES corpus containing that potentially un-
expected word. We then measured the association
of that word with every other open-class word that
appeared in an utterance with that word using the
log likelihood ratio (Dunning, 1993). The 20 words
from the CHILDES corpus with the highest log like-
lihood ratio (i.e., the words most strongly associ-
ated with the potentially unexpected word), were as-
sumed to collectively represent a particular topic. If
more than two of the words in the vector of words
representing this topic were also present in the NNM
source narrative or the adult retellings, the word that
generated that topic was eliminated from the set of
unexpected words.
We note that the optimized threshold described
in Section 3.2, above, is determined after filtering.
There is therefore potentially a different threshold
for each condition tested, and hence we do not nec-
essarily expect precision to increase and recall to
decrease after filtering. Rather, since the threshold
is selected in order to optimize F-measure, we ex-
pect that if the filtering is effective, F-measure will
increase with each additional filtering condition ap-
plied.
</bodyText>
<sectionHeader confidence="0.999675" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.9999592">
We evaluated the performance of our two word rank-
ing techniques, both individually and combined by
taking either the maximum of the two measures or
the sum, against the set of manually annotations de-
scribed in Section 2. In addition, we report the re-
sults of applying these word ranking techniques in
combination with the two filtering techniques. We
compare these results with a simple baseline method
in which every word used in a retelling that is never
used in another retelling is considered to be unex-
pected. Table 1 shows the precision, accuracy, and
F-measure of these approaches. We see that all of
the more sophisticated unexpected word identifica-
tion approaches outperform the baseline by a wide
margin, and that tf-idf and log odds perform compa-
rably under the condition without filtering and both
filtering conditions. Filtering improves F-measure
under both word ranking schemes, and combining
the two measures results in further improvements
under both filtering conditions. Although apply-
ing topic-estimate filtering yields the highest preci-
sion, the simple WordNet-based approach results in
the highest F-measure and a reasonable balance be-
tween precision and recall.
Recall that the purpose of identifying these un-
expected words was to determine whether children
with ASD produce unexpected and inappropriate
words at a higher rate than children with typical de-
velopment. This appears to be true in our manu-
ally annotated data. On average, 7.5% of the words
</bodyText>
<page confidence="0.467737">
712
</page>
<table confidence="0.999582642857143">
Unexpected word identification method P R F1
Baseline 46.3 74.0 57.0
TF-IDF 72.1 79.5 75.6
Log-odds 70.5 79.5 74.7
Sum(TF-IDF, Log-odds) 72.2 83.3 77.4
Max(TF-IDF, Log-odds) 69.9 83.3 76.0
TF-IDF+WordNet 83.8 80.5 82.1
Log-odds+WordNet 82.1 83.1 82.6
Sum(TF-IDF, Log-odds)+WordNet 84.2 83.1 83.7
Max(TF-IDF, Log-odds)+WordNet 83.3 84.4 83.9
TF-IDF+WordNet+topic 85.7 77.9 81.7
Log-odds+WordNet+topic 83.8 80.5 82.1
Sum(TF-IDF, Log-odds)+WordNet+topic 86.1 80.5 83.2
Max(TF-IDF, Log-odds)+WordNet+topic 85.1 81.8 83.4
</table>
<tableCaption confidence="0.999922">
Table 1: Accuracy of unexpected word identification.
</tableCaption>
<bodyText confidence="0.999984636363636">
types produced by children with ASD were marked
as unexpected, while only 2.5% of words produced
by children with TD were marked as unexpected, a
significant difference (p &lt; 0.01, using a one-tailed
t-test). This significant between-group difference
in rate of unexpected word use holds even when
using the automated methods of unexpected word
identification, with the best performing unexpected
word identification method estimating a mean of
6.6% in the ASD group and 2.5% in the TD group
(p &lt; 0.01).
</bodyText>
<sectionHeader confidence="0.984414" genericHeader="conclusions">
5 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.999991028571429">
The automated methods presented here for rank-
ing and filtering words according to their distribu-
tions in different corpora, which are adapted from
techniques originally developed for topic modeling
in the context of information retrieval and extrac-
tion tasks, demonstrate the utility of automated ap-
proaches for the analysis of semantics and pragmat-
ics. We were able to use these methods to iden-
tify unexpected or inappropriate words with high
enough accuracy to replicate the patterns of unex-
pected word use manually observed in our two di-
agnostic groups. This work underscores the poten-
tial of automated techniques for improving our un-
derstanding of the prevalence and diagnostic utility
of linguistic features associated with ASD and other
communication and language disorders.
In future work, we plan to use a development set
to determine the optimal number of topical words
to select during the topic estimate filtering stage of
the pipeline in order to maintain improvements in
precision without a loss in recall. We would also
like to investigate using part-of-speech, word sense,
and parse information to improve our approaches
for both semantic expansion and topic estimation.
Although the rate of unexpected word use alone is
unlikely to provide sufficient power to classify the
two diagnostic groups investigated here, we expect
that it can serve as one feature in an array of fea-
tures that capture the broad range of semantic and
pragmatic atypicalities observed in the spoken lan-
guage of children with autism. Finally, we plan to
apply these same methods to identify the confabula-
tions and topic shifts often observed in the narrative
retellings of the elderly with neurodegenerative con-
ditions.
</bodyText>
<sectionHeader confidence="0.995468" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999942166666667">
This work was supported in part by NSF
Grant #BCS-0826654, and NIH NIDCD grant
#1R01DC012033-01. Any opinions, findings, con-
clusions or recommendations expressed in this pub-
lication are those of the authors and do not necessar-
ily reflect the views of the NSF or the NIH.
</bodyText>
<sectionHeader confidence="0.983312" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999536857142857">
American Psychiatric Association. 2000. DSM-IV-TR:
Diagnostic and Statistical Manual of Mental Disor-
ders. American Psychiatric Publishing, Washington,
DC.
Ted Dunning. 1993. Accurate methods for the statistics
of surprise and coincidence. Computational linguis-
tics, 19(1):61–74.
</reference>
<page confidence="0.631793">
713
</page>
<reference confidence="0.99949454">
Christian Fellbaum. 1998. WordNet: An Electronic Lex-
ical Database. MIT Press, Cambridge, MA.
Leo Kanner. 1943. Autistic disturbances of affective
content. Nervous Child, 2:217–250.
Marit Korkman, Ursula Kirk, and Sally Kemp. 1998.
NEPSY: A developmental neuropsychological assess-
ment. The Psychological Corporation, San Antonio.
Yan Grace Lam, Siu Sze, and Susanna Yeung. 2012.
Towards a convergent account of pragmatic language
deficits in children with high-functioning autism: De-
picting the phenotype using the pragmatic rating scale.
Research in Autism Spectrum Disorders, 6:792797.
Catherine Lord, Michael Rutter, Pamela DiLavore, and
Susan Risi. 2002. Autism Diagnostic Observation
Schedule (ADOS). Western Psychological Services,
Los Angeles.
Molly Losh and Lisa Capps. 2003. Narrative ability
in high-functioning children with autism or asperger’s
syndrome. Journal ofAutism and Developmental Dis-
orders, 33(3):239–251.
Katherine Loveland, Robin McEvoy, and Belgin Tunali.
1990. Narrative story telling in autism and down’s
syndrome. British Journal of Developmental Psychol-
ogy, 8(1):9–23.
Brian MacWhinney. 2000. The CHILDES project: Tools
for analyzing talk. Lawrence Erlbaum Associates,
Mahwah, NJ.
Christopher D. Manning, Prabhakar Raghavan, and Hin-
rich Sch¨utze. 2008. Introduction to information re-
trieval. Cambridge University Press.
M.F. Porter. 1980. An algorithm for suffix stripping.
Program, 14(3):130–137.
Michael Rutter, Anthony Bailey, and Catherine Lord.
2003. Social Communication Questionnaire (SCQ).
Western Psychological Services, Los Angeles.
Gerard Salton and Christopher Buckley. 1988. Term-
weighting approaches in automatic text retrieval. In-
formation Processing and Management, 24(5):513–
523.
Helen Tager-Flusberg. 2001. Understanding the lan-
guage and communicative impairments in autism. In-
ternational Review of Research in Mental Retardation,
23:185–205.
C.J. van Rijsbergen, D.J. Harper, and M.F. Porter. 1981.
The selection of good search terms. Information Pro-
cessing and Management, 17(2):77–91.
Joanne Volden and Catherine Lord. 1991. Neologisms
and idiosyncratic language in autistic speakers. Jour-
nal of Autism and Developmental Disorders, 21:109–
130.
</reference>
<page confidence="0.910497">
714
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.538909">
<title confidence="0.974425">Distributional semantic models for the evaluation of disordered language</title>
<author confidence="0.984343">Emily Brian Jan van_for Spoken Language Understanding</author>
<author confidence="0.984343">Oregon Health</author>
<author confidence="0.984343">Science</author>
<affiliation confidence="0.556433">for Language Sciences, University of</affiliation>
<abstract confidence="0.999463888888889">Atypical semantic and pragmatic expression is frequently reported in the language of children with autism. Although this atypicality often manifests itself in the use of unusual or unexpected words and phrases, the rate of use of such unexpected words is rarely directly measured or quantified. In this paper, we use distributional semantic models to automatically identify unexpected words in narrative retellings by children with autism. The classification of unexpected words is sufficiently accurate to distinguish the retellings of children with autism from those with typical development. These techniques demonstrate the potential of applying automated language analysis techniques to clinically elicited language data for diagnostic purposes.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>American Psychiatric Association</author>
</authors>
<title>DSM-IV-TR: Diagnostic and Statistical Manual of Mental Disorders.</title>
<date>2000</date>
<publisher>American Psychiatric Publishing,</publisher>
<location>Washington, DC.</location>
<contexts>
<context position="4760" citStr="Association, 2000" startWordPosition="706" endWordPosition="707">e accurate enough to serve as an adequate substitute for manual annotation. Although unexpected off-topic word use is just one example of the atypical language observed in ASD, the work presented here highlights the potential of computational language evaluation and analysis methods for improving our understanding of the linguistic deficits associated with ASD. 2 Data Participants in this study included 37 children with typical development (TD) and 21 children with autism spectrum disorder (ASD). ASD was diagnosed via clinical consensus according to the DSMIV-TR criteria (American Psychiatric Association, 2000) and the established threshold scores on two diagnostic instruments: the Autism Diagnostic Observation Schedule (ADOS) (Lord et al., 2002), a semi-structured series of activities designed to allow an examiner to observe behaviors associated with autism; and the Social Communication Questionnaire (SCQ) (Rutter et al., 2003), a parental questionnaire. None of the children in this study met the criteria for a language impairment, and there were no significant between-group differences in age (mean=6.4) or full-scale IQ (mean=114). The narrative retelling task analyzed here is the Narrative Memory</context>
</contexts>
<marker>Association, 2000</marker>
<rawString>American Psychiatric Association. 2000. DSM-IV-TR: Diagnostic and Statistical Manual of Mental Disorders. American Psychiatric Publishing, Washington, DC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Dunning</author>
</authors>
<title>Accurate methods for the statistics of surprise and coincidence.</title>
<date>1993</date>
<booktitle>Computational linguistics,</booktitle>
<pages>19--1</pages>
<contexts>
<context position="14531" citStr="Dunning, 1993" startWordPosition="2361" endWordPosition="2362"> word was present in the source narrative or in one of the adult retellings, that word was removed from the set of unexpected words. In the final step, we used the CHILDES corpus of transcripts of children’s conversational speech (MacWhinney, 2000) to generate topic estimates for each remaining potentially unexpected word. For each of these words, we located every utterance in the CHILDES corpus containing that potentially unexpected word. We then measured the association of that word with every other open-class word that appeared in an utterance with that word using the log likelihood ratio (Dunning, 1993). The 20 words from the CHILDES corpus with the highest log likelihood ratio (i.e., the words most strongly associated with the potentially unexpected word), were assumed to collectively represent a particular topic. If more than two of the words in the vector of words representing this topic were also present in the NNM source narrative or the adult retellings, the word that generated that topic was eliminated from the set of unexpected words. We note that the optimized threshold described in Section 3.2, above, is determined after filtering. There is therefore potentially a different thresho</context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>Ted Dunning. 1993. Accurate methods for the statistics of surprise and coincidence. Computational linguistics, 19(1):61–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="13855" citStr="Fellbaum, 1998" startWordPosition="2253" endWordPosition="2254"> thresholding on the tf-idf or log odds score. 3.3 Filtering with external resources Recall that the corpus of retellings used to generate the word association measures described above, is very small. It is therefore quite possible that a child may have used an entirely appropriate word that by chance was never used by another child or one of the neurotypical adults. One way of increasing the lexical coverage of the corpus of retellings is through semantic expansion using an external resource. For each word in the set of potential unexpected words, we located the WordNet synset for that word (Fellbaum, 1998). If any of the WordNet synonyms of the potentially unexpected word was present in the source narrative or in one of the adult retellings, that word was removed from the set of unexpected words. In the final step, we used the CHILDES corpus of transcripts of children’s conversational speech (MacWhinney, 2000) to generate topic estimates for each remaining potentially unexpected word. For each of these words, we located every utterance in the CHILDES corpus containing that potentially unexpected word. We then measured the association of that word with every other open-class word that appeared i</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christian Fellbaum. 1998. WordNet: An Electronic Lexical Database. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leo Kanner</author>
</authors>
<title>Autistic disturbances of affective content.</title>
<date>1943</date>
<journal>Nervous Child,</journal>
<pages>2--217</pages>
<contexts>
<context position="1467" citStr="Kanner, 1943" startWordPosition="204" endWordPosition="205">tinguish the retellings of children with autism from those with typical development. These techniques demonstrate the potential of applying automated language analysis techniques to clinically elicited language data for diagnostic purposes. 1 Introduction Autism spectrum disorder (ASD) is a neurodevelopmental disorder characterized by impaired communication and social behavior. Although the symptoms of ASD are numerous and varied, atypical and idiosyncratic language has been one of the core symptoms observed in verbal individuals with autism since Kanner first assigned a name to the disorder (Kanner, 1943). Atypical language currently serves as a diagnostic criterion in many of the most widely used diagnostic instruments for ASD (Lord et al., 2002; Rutter et al., 2003), and the phenomenon is especially marked in the areas of semantics and pragmatics (Tager-Flusberg, 2001; Volden and Lord, 1991). Because structured language assessment tools are not always sensitive to the particular atypical semantic and pragmatic expression associated with ASD, measures of atypical language are often drawn from spontaneous language samples. Expert manual annotation and analysis of spontaneous language in young </context>
</contexts>
<marker>Kanner, 1943</marker>
<rawString>Leo Kanner. 1943. Autistic disturbances of affective content. Nervous Child, 2:217–250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marit Korkman</author>
<author>Ursula Kirk</author>
<author>Sally Kemp</author>
</authors>
<title>NEPSY: A developmental neuropsychological assessment. The Psychological Corporation,</title>
<date>1998</date>
<location>San Antonio.</location>
<contexts>
<context position="5404" citStr="Korkman et al., 1998" startWordPosition="801" endWordPosition="804">reshold scores on two diagnostic instruments: the Autism Diagnostic Observation Schedule (ADOS) (Lord et al., 2002), a semi-structured series of activities designed to allow an examiner to observe behaviors associated with autism; and the Social Communication Questionnaire (SCQ) (Rutter et al., 2003), a parental questionnaire. None of the children in this study met the criteria for a language impairment, and there were no significant between-group differences in age (mean=6.4) or full-scale IQ (mean=114). The narrative retelling task analyzed here is the Narrative Memory subtest of the NEPSY (Korkman et al., 1998), a large and comprehensive battery of tasks that test neurocognitive functioning in children. The NEPSY Narrative Memory (NNM) subtest is a narrative retelling test in which the subject listens to a brief narrative, excerpts of which are shown in Figure 1, and then must retell the narrative to the examiner. The NNM was administered to each participant in the study, and each participant’s retelling was recorded and transcribed. Using Amazon’s Mechanical Turk, we also collected a large corpus of retellings from neurotypical adults, who listened to a recording of the story and provided written r</context>
</contexts>
<marker>Korkman, Kirk, Kemp, 1998</marker>
<rawString>Marit Korkman, Ursula Kirk, and Sally Kemp. 1998. NEPSY: A developmental neuropsychological assessment. The Psychological Corporation, San Antonio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yan Grace Lam</author>
<author>Siu Sze</author>
<author>Susanna Yeung</author>
</authors>
<title>Towards a convergent account of pragmatic language deficits in children with high-functioning autism: Depicting the phenotype using the pragmatic rating scale. Research in Autism Spectrum Disorders,</title>
<date>2012</date>
<pages>6--792797</pages>
<contexts>
<context position="2311" citStr="Lam et al., 2012" startWordPosition="333" endWordPosition="336">antics and pragmatics (Tager-Flusberg, 2001; Volden and Lord, 1991). Because structured language assessment tools are not always sensitive to the particular atypical semantic and pragmatic expression associated with ASD, measures of atypical language are often drawn from spontaneous language samples. Expert manual annotation and analysis of spontaneous language in young people with ASD has revealed that children and young adults with autism include significantly more bizarre and irrelevant content (Loveland et al., 1990; Losh and Capps, 2003) in their narratives and more abrupt topic changes (Lam et al., 2012) in their conversations than their language-matched typically developing peers. Most normed clinical instruments for analyzing children’s spontaneous language, however, focus on syntactic measures and developmental milestones related to the acquisition of vocabulary and syntactic structures. Measures of semantic and pragmatic atypicality in spontaneous language are rarely directly measured. Instead, the degree of language atypicality is often determined via subjective parental reports (e.g., asking a parent whether their child has ever used odd phrases (Rutter et al., 2003)) or general impress</context>
</contexts>
<marker>Lam, Sze, Yeung, 2012</marker>
<rawString>Yan Grace Lam, Siu Sze, and Susanna Yeung. 2012. Towards a convergent account of pragmatic language deficits in children with high-functioning autism: Depicting the phenotype using the pragmatic rating scale. Research in Autism Spectrum Disorders, 6:792797.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Catherine Lord</author>
<author>Michael Rutter</author>
<author>Pamela DiLavore</author>
<author>Susan Risi</author>
</authors>
<title>Autism Diagnostic Observation Schedule (ADOS). Western Psychological Services,</title>
<date>2002</date>
<location>Los Angeles.</location>
<contexts>
<context position="1611" citStr="Lord et al., 2002" startWordPosition="226" endWordPosition="229">automated language analysis techniques to clinically elicited language data for diagnostic purposes. 1 Introduction Autism spectrum disorder (ASD) is a neurodevelopmental disorder characterized by impaired communication and social behavior. Although the symptoms of ASD are numerous and varied, atypical and idiosyncratic language has been one of the core symptoms observed in verbal individuals with autism since Kanner first assigned a name to the disorder (Kanner, 1943). Atypical language currently serves as a diagnostic criterion in many of the most widely used diagnostic instruments for ASD (Lord et al., 2002; Rutter et al., 2003), and the phenomenon is especially marked in the areas of semantics and pragmatics (Tager-Flusberg, 2001; Volden and Lord, 1991). Because structured language assessment tools are not always sensitive to the particular atypical semantic and pragmatic expression associated with ASD, measures of atypical language are often drawn from spontaneous language samples. Expert manual annotation and analysis of spontaneous language in young people with ASD has revealed that children and young adults with autism include significantly more bizarre and irrelevant content (Loveland et a</context>
<context position="3076" citStr="Lord et al., 2002" startWordPosition="444" endWordPosition="447">us language, however, focus on syntactic measures and developmental milestones related to the acquisition of vocabulary and syntactic structures. Measures of semantic and pragmatic atypicality in spontaneous language are rarely directly measured. Instead, the degree of language atypicality is often determined via subjective parental reports (e.g., asking a parent whether their child has ever used odd phrases (Rutter et al., 2003)) or general impressions during clinical examination (e.g., rating the child’s degree of “stereotyped or idiosyncratic use of words or phrases” on a four-point scale (Lord et al., 2002)). This has led to a lack of reliable and objective information about the frequency of atypical language use and its precise nature in ASD. In this study, we attempt to automatically detect instances of contextually atypical language in spontaneous speech at the lexical level in order to quantify its prevalence in the ASD population. We first determine manually the off-topic, surprising, or in709 Proceedings of NAACL-HLT 2013, pages 709–714, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics appropriate words in a set of narrative retellings elicited in a clinic</context>
<context position="4898" citStr="Lord et al., 2002" startWordPosition="724" endWordPosition="727">the atypical language observed in ASD, the work presented here highlights the potential of computational language evaluation and analysis methods for improving our understanding of the linguistic deficits associated with ASD. 2 Data Participants in this study included 37 children with typical development (TD) and 21 children with autism spectrum disorder (ASD). ASD was diagnosed via clinical consensus according to the DSMIV-TR criteria (American Psychiatric Association, 2000) and the established threshold scores on two diagnostic instruments: the Autism Diagnostic Observation Schedule (ADOS) (Lord et al., 2002), a semi-structured series of activities designed to allow an examiner to observe behaviors associated with autism; and the Social Communication Questionnaire (SCQ) (Rutter et al., 2003), a parental questionnaire. None of the children in this study met the criteria for a language impairment, and there were no significant between-group differences in age (mean=6.4) or full-scale IQ (mean=114). The narrative retelling task analyzed here is the Narrative Memory subtest of the NEPSY (Korkman et al., 1998), a large and comprehensive battery of tasks that test neurocognitive functioning in children.</context>
</contexts>
<marker>Lord, Rutter, DiLavore, Risi, 2002</marker>
<rawString>Catherine Lord, Michael Rutter, Pamela DiLavore, and Susan Risi. 2002. Autism Diagnostic Observation Schedule (ADOS). Western Psychological Services, Los Angeles.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Molly Losh</author>
<author>Lisa Capps</author>
</authors>
<title>Narrative ability in high-functioning children with autism or asperger’s syndrome.</title>
<date>2003</date>
<journal>Journal ofAutism and Developmental Disorders,</journal>
<volume>33</volume>
<issue>3</issue>
<contexts>
<context position="2242" citStr="Losh and Capps, 2003" startWordPosition="321" endWordPosition="324">t al., 2003), and the phenomenon is especially marked in the areas of semantics and pragmatics (Tager-Flusberg, 2001; Volden and Lord, 1991). Because structured language assessment tools are not always sensitive to the particular atypical semantic and pragmatic expression associated with ASD, measures of atypical language are often drawn from spontaneous language samples. Expert manual annotation and analysis of spontaneous language in young people with ASD has revealed that children and young adults with autism include significantly more bizarre and irrelevant content (Loveland et al., 1990; Losh and Capps, 2003) in their narratives and more abrupt topic changes (Lam et al., 2012) in their conversations than their language-matched typically developing peers. Most normed clinical instruments for analyzing children’s spontaneous language, however, focus on syntactic measures and developmental milestones related to the acquisition of vocabulary and syntactic structures. Measures of semantic and pragmatic atypicality in spontaneous language are rarely directly measured. Instead, the degree of language atypicality is often determined via subjective parental reports (e.g., asking a parent whether their chil</context>
</contexts>
<marker>Losh, Capps, 2003</marker>
<rawString>Molly Losh and Lisa Capps. 2003. Narrative ability in high-functioning children with autism or asperger’s syndrome. Journal ofAutism and Developmental Disorders, 33(3):239–251.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katherine Loveland</author>
<author>Robin McEvoy</author>
<author>Belgin Tunali</author>
</authors>
<title>Narrative story telling in autism and down’s syndrome.</title>
<date>1990</date>
<journal>British Journal of Developmental Psychology,</journal>
<volume>8</volume>
<issue>1</issue>
<contexts>
<context position="2219" citStr="Loveland et al., 1990" startWordPosition="317" endWordPosition="320"> et al., 2002; Rutter et al., 2003), and the phenomenon is especially marked in the areas of semantics and pragmatics (Tager-Flusberg, 2001; Volden and Lord, 1991). Because structured language assessment tools are not always sensitive to the particular atypical semantic and pragmatic expression associated with ASD, measures of atypical language are often drawn from spontaneous language samples. Expert manual annotation and analysis of spontaneous language in young people with ASD has revealed that children and young adults with autism include significantly more bizarre and irrelevant content (Loveland et al., 1990; Losh and Capps, 2003) in their narratives and more abrupt topic changes (Lam et al., 2012) in their conversations than their language-matched typically developing peers. Most normed clinical instruments for analyzing children’s spontaneous language, however, focus on syntactic measures and developmental milestones related to the acquisition of vocabulary and syntactic structures. Measures of semantic and pragmatic atypicality in spontaneous language are rarely directly measured. Instead, the degree of language atypicality is often determined via subjective parental reports (e.g., asking a pa</context>
</contexts>
<marker>Loveland, McEvoy, Tunali, 1990</marker>
<rawString>Katherine Loveland, Robin McEvoy, and Belgin Tunali. 1990. Narrative story telling in autism and down’s syndrome. British Journal of Developmental Psychology, 8(1):9–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian MacWhinney</author>
</authors>
<title>The CHILDES project: Tools for analyzing talk. Lawrence Erlbaum Associates,</title>
<date>2000</date>
<location>Mahwah, NJ.</location>
<contexts>
<context position="14165" citStr="MacWhinney, 2000" startWordPosition="2304" endWordPosition="2305">ever used by another child or one of the neurotypical adults. One way of increasing the lexical coverage of the corpus of retellings is through semantic expansion using an external resource. For each word in the set of potential unexpected words, we located the WordNet synset for that word (Fellbaum, 1998). If any of the WordNet synonyms of the potentially unexpected word was present in the source narrative or in one of the adult retellings, that word was removed from the set of unexpected words. In the final step, we used the CHILDES corpus of transcripts of children’s conversational speech (MacWhinney, 2000) to generate topic estimates for each remaining potentially unexpected word. For each of these words, we located every utterance in the CHILDES corpus containing that potentially unexpected word. We then measured the association of that word with every other open-class word that appeared in an utterance with that word using the log likelihood ratio (Dunning, 1993). The 20 words from the CHILDES corpus with the highest log likelihood ratio (i.e., the words most strongly associated with the potentially unexpected word), were assumed to collectively represent a particular topic. If more than two </context>
</contexts>
<marker>MacWhinney, 2000</marker>
<rawString>Brian MacWhinney. 2000. The CHILDES project: Tools for analyzing talk. Lawrence Erlbaum Associates, Mahwah, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Prabhakar Raghavan</author>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Introduction to information retrieval.</title>
<date>2008</date>
<publisher>Cambridge University Press.</publisher>
<marker>Manning, Raghavan, Sch¨utze, 2008</marker>
<rawString>Christopher D. Manning, Prabhakar Raghavan, and Hinrich Sch¨utze. 2008. Introduction to information retrieval. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M F Porter</author>
</authors>
<title>An algorithm for suffix stripping.</title>
<date>1980</date>
<journal>Program,</journal>
<volume>14</volume>
<issue>3</issue>
<contexts>
<context position="9336" citStr="Porter, 1980" startWordPosition="1474" endWordPosition="1475">r each child using leave-one-out cross validation in order to select a set of potentially unexpected words. This set of potential unexpected words is then filtered using two external resources that allow us to eliminate words that were not used in other retellings but are likely to be semantically related to topic of the narrative. This final set of words is evaluated against the set of manually identified words in order determine the accuracy of our unexpected word classification. 3.1 Word association measures Before calculating the word association measures, we tokenize, downcase, and stem (Porter, 1980) the transcripts and remove all punctuation. We then use two association measures to score each word in each child’s retelling: tf-idf, the term frequency-inverse document frequency measure (Salton and Buckley, 1988), and the log odds ratio (van Rijsbergen et al., 1981). We use the following formulation to calculate tf-idf for each child’s retelling i and each word in that retelling j, where cij is the count of word j in retelling i; fj is the number of retellings from the full corpus of child and adult retellings containing that word j; and D is the total number of retellings in the full corp</context>
</contexts>
<marker>Porter, 1980</marker>
<rawString>M.F. Porter. 1980. An algorithm for suffix stripping. Program, 14(3):130–137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Rutter</author>
<author>Anthony Bailey</author>
<author>Catherine Lord</author>
</authors>
<title>Social Communication Questionnaire (SCQ). Western Psychological Services,</title>
<date>2003</date>
<location>Los Angeles.</location>
<contexts>
<context position="1633" citStr="Rutter et al., 2003" startWordPosition="230" endWordPosition="233">analysis techniques to clinically elicited language data for diagnostic purposes. 1 Introduction Autism spectrum disorder (ASD) is a neurodevelopmental disorder characterized by impaired communication and social behavior. Although the symptoms of ASD are numerous and varied, atypical and idiosyncratic language has been one of the core symptoms observed in verbal individuals with autism since Kanner first assigned a name to the disorder (Kanner, 1943). Atypical language currently serves as a diagnostic criterion in many of the most widely used diagnostic instruments for ASD (Lord et al., 2002; Rutter et al., 2003), and the phenomenon is especially marked in the areas of semantics and pragmatics (Tager-Flusberg, 2001; Volden and Lord, 1991). Because structured language assessment tools are not always sensitive to the particular atypical semantic and pragmatic expression associated with ASD, measures of atypical language are often drawn from spontaneous language samples. Expert manual annotation and analysis of spontaneous language in young people with ASD has revealed that children and young adults with autism include significantly more bizarre and irrelevant content (Loveland et al., 1990; Losh and Cap</context>
<context position="2891" citStr="Rutter et al., 2003" startWordPosition="414" endWordPosition="417"> abrupt topic changes (Lam et al., 2012) in their conversations than their language-matched typically developing peers. Most normed clinical instruments for analyzing children’s spontaneous language, however, focus on syntactic measures and developmental milestones related to the acquisition of vocabulary and syntactic structures. Measures of semantic and pragmatic atypicality in spontaneous language are rarely directly measured. Instead, the degree of language atypicality is often determined via subjective parental reports (e.g., asking a parent whether their child has ever used odd phrases (Rutter et al., 2003)) or general impressions during clinical examination (e.g., rating the child’s degree of “stereotyped or idiosyncratic use of words or phrases” on a four-point scale (Lord et al., 2002)). This has led to a lack of reliable and objective information about the frequency of atypical language use and its precise nature in ASD. In this study, we attempt to automatically detect instances of contextually atypical language in spontaneous speech at the lexical level in order to quantify its prevalence in the ASD population. We first determine manually the off-topic, surprising, or in709 Proceedings of </context>
<context position="5084" citStr="Rutter et al., 2003" startWordPosition="751" endWordPosition="754"> linguistic deficits associated with ASD. 2 Data Participants in this study included 37 children with typical development (TD) and 21 children with autism spectrum disorder (ASD). ASD was diagnosed via clinical consensus according to the DSMIV-TR criteria (American Psychiatric Association, 2000) and the established threshold scores on two diagnostic instruments: the Autism Diagnostic Observation Schedule (ADOS) (Lord et al., 2002), a semi-structured series of activities designed to allow an examiner to observe behaviors associated with autism; and the Social Communication Questionnaire (SCQ) (Rutter et al., 2003), a parental questionnaire. None of the children in this study met the criteria for a language impairment, and there were no significant between-group differences in age (mean=6.4) or full-scale IQ (mean=114). The narrative retelling task analyzed here is the Narrative Memory subtest of the NEPSY (Korkman et al., 1998), a large and comprehensive battery of tasks that test neurocognitive functioning in children. The NEPSY Narrative Memory (NNM) subtest is a narrative retelling test in which the subject listens to a brief narrative, excerpts of which are shown in Figure 1, and then must retell t</context>
</contexts>
<marker>Rutter, Bailey, Lord, 2003</marker>
<rawString>Michael Rutter, Anthony Bailey, and Catherine Lord. 2003. Social Communication Questionnaire (SCQ). Western Psychological Services, Los Angeles.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Salton</author>
<author>Christopher Buckley</author>
</authors>
<title>Termweighting approaches in automatic text retrieval.</title>
<date>1988</date>
<booktitle>Information Processing and Management,</booktitle>
<volume>24</volume>
<issue>5</issue>
<pages>523</pages>
<contexts>
<context position="9552" citStr="Salton and Buckley, 1988" startWordPosition="1503" endWordPosition="1506">us to eliminate words that were not used in other retellings but are likely to be semantically related to topic of the narrative. This final set of words is evaluated against the set of manually identified words in order determine the accuracy of our unexpected word classification. 3.1 Word association measures Before calculating the word association measures, we tokenize, downcase, and stem (Porter, 1980) the transcripts and remove all punctuation. We then use two association measures to score each word in each child’s retelling: tf-idf, the term frequency-inverse document frequency measure (Salton and Buckley, 1988), and the log odds ratio (van Rijsbergen et al., 1981). We use the following formulation to calculate tf-idf for each child’s retelling i and each word in that retelling j, where cij is the count of word j in retelling i; fj is the number of retellings from the full corpus of child and adult retellings containing that word j; and D is the total number of retellings in the full corpus (Manning et al., 2008): � ad _ (1 + log cij) log f, D if cij &gt; 1 tf fzj 0 otherwise The log odds ratio, another association measure used in information retrieval and extraction tasks, is the ratio between the odds</context>
</contexts>
<marker>Salton, Buckley, 1988</marker>
<rawString>Gerard Salton and Christopher Buckley. 1988. Termweighting approaches in automatic text retrieval. Information Processing and Management, 24(5):513– 523.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helen Tager-Flusberg</author>
</authors>
<title>Understanding the language and communicative impairments in autism.</title>
<date>2001</date>
<booktitle>International Review of Research in Mental Retardation,</booktitle>
<pages>23--185</pages>
<contexts>
<context position="1737" citStr="Tager-Flusberg, 2001" startWordPosition="249" endWordPosition="250">spectrum disorder (ASD) is a neurodevelopmental disorder characterized by impaired communication and social behavior. Although the symptoms of ASD are numerous and varied, atypical and idiosyncratic language has been one of the core symptoms observed in verbal individuals with autism since Kanner first assigned a name to the disorder (Kanner, 1943). Atypical language currently serves as a diagnostic criterion in many of the most widely used diagnostic instruments for ASD (Lord et al., 2002; Rutter et al., 2003), and the phenomenon is especially marked in the areas of semantics and pragmatics (Tager-Flusberg, 2001; Volden and Lord, 1991). Because structured language assessment tools are not always sensitive to the particular atypical semantic and pragmatic expression associated with ASD, measures of atypical language are often drawn from spontaneous language samples. Expert manual annotation and analysis of spontaneous language in young people with ASD has revealed that children and young adults with autism include significantly more bizarre and irrelevant content (Loveland et al., 1990; Losh and Capps, 2003) in their narratives and more abrupt topic changes (Lam et al., 2012) in their conversations th</context>
</contexts>
<marker>Tager-Flusberg, 2001</marker>
<rawString>Helen Tager-Flusberg. 2001. Understanding the language and communicative impairments in autism. International Review of Research in Mental Retardation, 23:185–205.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J van Rijsbergen</author>
<author>D J Harper</author>
<author>M F Porter</author>
</authors>
<title>The selection of good search terms.</title>
<date>1981</date>
<booktitle>Information Processing and Management,</booktitle>
<volume>17</volume>
<issue>2</issue>
<marker>van Rijsbergen, Harper, Porter, 1981</marker>
<rawString>C.J. van Rijsbergen, D.J. Harper, and M.F. Porter. 1981. The selection of good search terms. Information Processing and Management, 17(2):77–91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joanne Volden</author>
<author>Catherine Lord</author>
</authors>
<title>Neologisms and idiosyncratic language in autistic speakers.</title>
<date>1991</date>
<journal>Journal of Autism and Developmental Disorders,</journal>
<volume>21</volume>
<pages>130</pages>
<contexts>
<context position="1761" citStr="Volden and Lord, 1991" startWordPosition="251" endWordPosition="254">) is a neurodevelopmental disorder characterized by impaired communication and social behavior. Although the symptoms of ASD are numerous and varied, atypical and idiosyncratic language has been one of the core symptoms observed in verbal individuals with autism since Kanner first assigned a name to the disorder (Kanner, 1943). Atypical language currently serves as a diagnostic criterion in many of the most widely used diagnostic instruments for ASD (Lord et al., 2002; Rutter et al., 2003), and the phenomenon is especially marked in the areas of semantics and pragmatics (Tager-Flusberg, 2001; Volden and Lord, 1991). Because structured language assessment tools are not always sensitive to the particular atypical semantic and pragmatic expression associated with ASD, measures of atypical language are often drawn from spontaneous language samples. Expert manual annotation and analysis of spontaneous language in young people with ASD has revealed that children and young adults with autism include significantly more bizarre and irrelevant content (Loveland et al., 1990; Losh and Capps, 2003) in their narratives and more abrupt topic changes (Lam et al., 2012) in their conversations than their language-matche</context>
</contexts>
<marker>Volden, Lord, 1991</marker>
<rawString>Joanne Volden and Catherine Lord. 1991. Neologisms and idiosyncratic language in autistic speakers. Journal of Autism and Developmental Disorders, 21:109– 130.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>