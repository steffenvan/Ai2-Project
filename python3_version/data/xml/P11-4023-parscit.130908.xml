<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.022575">
<title confidence="0.981867">
IMASS: An Intelligent Microblog Analysis and Summarization System
</title>
<author confidence="0.996834">
Jui-Yu Weng Cheng-Lun Yang Bo-Nian Chen Yen-Kai Wang Shou-De Lin
</author>
<affiliation confidence="0.995613">
Department of Computer Science and Information Engineering
National Taiwan University
</affiliation>
<email confidence="0.988548">
{r98922060,r99944042,f92025,b97081,sdlin}@csie.ntu.edu.tw
</email>
<sectionHeader confidence="0.993654" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999967842105263">
This paper presents a system to summarize
a Microblog post and its responses with the
goal to provide readers a more constructive
and concise set of information for efficient
digestion. We introduce a novel two-phase
summarization scheme. In the first phase,
the post plus its responses are classified in-
to four categories based on the intention,
interrogation, sharing, discussion and chat.
For each type of post, in the second phase,
we exploit different strategies, including
opinion analysis, response pair identifica-
tion, and response relevancy detection, to
summarize and highlight critical informa-
tion to display. This system provides an al-
ternative thinking about machine-
summarization: by utilizing AI approaches,
computers are capable of constructing dee-
per and more user-friendly abstraction.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999305828571428">
As Microblog services such as Twitter have be-
come increasingly popular, it is critical to re-
consider the applicability of the existing NLP
technologies on this new media sources. Take
summarization for example, a Microblog user
usually has to browse through tens or even hun-
dreds of posts together with their responses daily,
therefore it can be beneficial if there is an intelli-
gent tool assisting summarizing those information.
Automatic text summarization (ATS) has been
investigated for over fifty years, but the majority of
the existing techniques might not be appropriate
for Microblog write-ups. For instance, a popular
kind of approaches for summarization tries to iden-
tify a subset of information, usually in sentence
form, from longer pieces of writings as summary
(Das and Martins, 2007). Such extraction-based
methods can hardly be applied to Microblog texts
because many posts/responses contain only one
sentence.
Below we first describe some special characte-
ristics that deviates the Microblog summarization
task from general text summarization.
a. The number of sentences is limited, and sen-
tences are usually too short and casual to con-
tain sufficient structural information or cue
phrases. Unlike normal blogs, there is a strict
limitation on the number of characters for each
post (e.g. 140 characters for Twitter and Plurk
maximum). Microblog messages cannot be
treated as complete documents so that we can-
not take advantage of the structural information.
Furthermore, users tend to regard Microblog as
a chatting board. They write casually with
slangs, jargons, and incorrect grammar.
</bodyText>
<listItem confidence="0.927534173913043">
b. Microblog posts can serve several different
purposes. At least three different types of posts
are observed in Microblogs, expressing feeling,
sharing information, and asking questions.
Structured language is not the only means to
achieve those goals. For example, people
sometimes use attachment, as links or files, for
sharing, and utilize emoticons and pre-defined
qualifiers to express their feelings. The diver-
sity of content differ Microblogs from general
news articles. Consequently, using one mold to
fit all types of Microblog posts is not sufficient.
Different summarization schemes for posts
with different purposes are preferred.
c. Posts and responses in Microblogs are more
similar to a multi-persons dialogue corpus. One
of the main purposes of a Microblog is to serve
as the fast but not instant communication
channel among multiple users. Due to the free-
chatting, multi-user characteristics, the topic of
a post/response thread can drift quickly. Some-
times, the topic of discussion at the end of the
thread is totally unrelated to that of the post.
</listItem>
<page confidence="0.980453">
133
</page>
<note confidence="0.314869">
Proceedings of the ACL-HLT 2011 System Demonstrations, pages 133–138,
Portland, Oregon, USA, 21 June 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.999848769230769">
This paper introduces a framework that summariz-
es a post with its responses. Motivated by the ab-
ovementioned characteristics of Microblogs, we
plan to use a two-phase summarization scheme to
develop different summarization strategies for dif-
ferent type of posts (see Figure 1). In the first
phase, a post will be automatically classified into
several categories including interrogation, discus-
sion, sharing and chat based on the intention of the
users. In the second phase, the system chooses dif-
ferent summarization components for different
types of posts.
The novelties of this system are listed below.
</bodyText>
<listItem confidence="0.951392764705882">
1. Strategically, we propose an underlying 2-phase
framework for summarizing Microblog posts.
The system can be accessed online at
http://mslab.csie.ntu.edu.tw/~fishyz/plurk/.
2. Tactically, we argue that it is possible to inte-
grate post-intention classification, opinion anal-
ysis, response relevancy and response-pair
mining to create an intelligent summarization
framework for Microblog posts and responses.
We also found that the content features are not
as useful as the temporal or positional features
for text mining in Microblog.
3. Our work provides an alternative thinking about
ATS. It is possible to go beyond the literal
meaning of summarization to exploit advanced
text mining methods to improve the quality and
usability of a summarization system.
</listItem>
<sectionHeader confidence="0.7472345" genericHeader="method">
2 Summarization Framework and Expe-
riments
</sectionHeader>
<bodyText confidence="0.999340981481482">
Below we discuss our two-phase summarization
framework and the experiment results on each in-
dividual component. Note that our experiments
were tested on the Plurk dataset, which is one of
the most popular micro-blogging platforms in Asia.
Our observation is that Microblog posts can
have different purposes. We divide them into four
categories, Interrogation, Sharing, Discussion, and
Chat.
The Interrogation posts are questions asked in
public with the hope to obtain some useful answers
from friends or other users. However, it is very
common that some repliers do not provide mea-
ningful answers. The responses might serve the
purpose for clarification or, even worse, have noth-
ing to do with the question. Hence we believe the
most appropriate summarization process for this
kind of posts is to find out which replies really re-
spond to the question. We created a response re-
levance detection component to serve as its
summarization mechanism.
The Sharing posts are very frequently observed
in Microblog as Microbloggers like to share inter-
esting websites, pictures, and videos with their
friends. Other people usually write down their
comments or feelings on the shared subjects in the
responses. To summarize such posts, we obtain the
statistics on how many people have positive, neu-
tral, and negative attitude toward the shared sub-
jects. We introduce the opinion analysis
component that provides the analysis on whether
the information shared is recommended by the res-
pondents.
We also observe that some posts contain charac-
teristics of both Interrogation and Sharing. The
users may share a hyperlink and ask for others’
opinions at the same time. We create a category
named Discussion for these posts, and apply both
response ranking and opinion analysis engines on
this type of posts.
Finally, there are posts which simply act as the
solicitation for further chat. For example, one user
writes “so sad...” and another replies “what hap-
pened”. We name this type of posts/responses as
Chat. This kind of posts can sometimes involve
multiple persons and the topic may gradually drift
to a different one. We believe the plausible sum-
marization strategy is to group different messages
based on their topics. Therefore for Chat posts, we
designed a response pair identification system to
accomplish such goal. We group the related res-
ponses together for display, and the number of
groups represents the number of different topics in
this thread.
</bodyText>
<figureCaption confidence="0.923455">
Figure 1 shows the flow of our summarization
Figure 1. System architecture
</figureCaption>
<page confidence="0.992619">
134
</page>
<bodyText confidence="0.9998142">
framework. When an input post with responses
comes in, the system first determines its intention,
based on which the system adopts proper strategies
for summarization. Below we discuss the technical
parts of each sub-system with experiment results.
</bodyText>
<subsectionHeader confidence="0.969176">
2.1 Post Intention Classification
</subsectionHeader>
<bodyText confidence="0.999994666666667">
This stage aims to classify each post into four cat-
egories, Interrogation, Sharing, Discussion, and
Chat. One tricky issue is that the Discussion label
is essentially a combination of interrogation and
sharing labels. Therefore, simply treating it as an
independent label and use a typical multi-label
learning method can hurt the performance. We ob-
tain 76.7% (10-fold cross validation) in accuracy
by training a four-class classifier using the 6-gram
character language model. To improve the perfor-
mance, we design a decision-tree based framework
that utilizes both manually-designed rules and dis-
criminant classification engine (see Figure 2). The
system first checks whether the posts contains
URLs or pointers to files, then uses a binary clas-
sifier to determine whether the post is interrogative.
For the experiment, we manually annotate 6000
posts consisting of 1840 interrogation, 2002 shar-
ing, 1905 chat, and 254 discussion posts. We train
a 6-gram language model as the binary interroga-
tion classifier. Then we integrate the classifier into
our system and test on 6000 posts to obtain a test-
ing accuracy of 82.8%, which is significantly bet-
ter than 76.7% with multi-class classification.
</bodyText>
<subsectionHeader confidence="0.998036">
2.2 Opinion Analysis
</subsectionHeader>
<bodyText confidence="0.999844230769231">
Opinion analysis is used to evaluate public prefe-
rence on the shared subject. The system classifies
responses into 3 categories, positive, negative, and
neutral.
Here we design a two-level classification
framework using Naïve-Bayes classifiers which
takes advantage of the learned 6-gram language
model probabilities as features. First of all, we
train a binary classifier to determine if a post or a
reply is opinionative. This step is called the subjec-
tivity test. If the answer is yes, we then use another
binary classifier to decide if the opinion is positive
or negative. The second step is called the polarity
test.
For subjectivity test, we manually annotate 3244
posts, in which half is subjective and half is objec-
tive. The 10-fold cross validation shows average
accuracy of 70.5%.
For polarity test, we exploit the built-in emoti-
cons in Plurk to automatically extract posts with
positive and negative opinions. We collect 10,000
positive and 10,000 negative posts as training data
to train a language model of Naïve Bayes classifier,
and evaluate on manually annotated data of 3121
posts, with 1624 positive and 1497 negative to ob-
tain accuracy of 0.722.
</bodyText>
<subsectionHeader confidence="0.995036">
2.3 Response Pair Identification
</subsectionHeader>
<bodyText confidence="0.999823357142857">
Conversation in micro-blogs tends to diverge into
multiple topics as the number of responses grows.
Sometimes such divergence may result in res-
ponses that are irrelevant to the original post, thus
creating problems for summarization. Furthermore,
because the messages are usually short, it is diffi-
cult to identify the main topics of these dialogue-
like responses using only keywords in the content
for summarization. Alternatively, we introduce a
subcomponent to identify Response Pairs in micro-
blogs. A Response Pair is a pair of responses that
the latter specifically responds to the former. Based
on those pairs we can then form clusters of mes-
sages to indicate different group of topics and mes-
</bodyText>
<table confidence="0.995472">
Feature Description Weight
Backward Refe- Latter response content 0.055
rencing contains former respond-
er’s display name
Forward Refe- Former response contains 0.018
rencing of user latter response’s author’s
name user name
Response position Number of responses in 0.13
difference between responses
Content similarity Contents’ cosine similari- 0.025
ty using n-gram models.
Response time Time difference between 0.012
difference responses in seconds
</table>
<tableCaption confidence="0.98333">
Table 1. Feature set with their description and weights
</tableCaption>
<figureCaption confidence="0.993607">
Figure 2. The post classification procedure
</figureCaption>
<page confidence="0.995388">
135
</page>
<bodyText confidence="0.99987788372093">
sages.
Looking at the content of micro-blogs, we ob-
serve that related responses are usually adjacent to
each other as users tend to closely follow whether
their messages are responded and reply to the res-
ponses from others quickly. Therefore besides con-
tent features, we decide to add the temporal and
ordering features (See Table 1) to train a classifier
that takes a pair of messages as inputs and return
whether they are related. By identifying the re-
sponse pairs, our summarization system is able to
group the responses into different topic clusters
and display the clusters separately. We believe
such functionality can assist users to digest long
Microblog discussions.
For experiment, the model is trained using
LIBSVM (Chang and Lin, 2001) (RBF kernel)
with 6000 response pairs, half of the training set
positive and half negative. The positive data can be
obtained automatically based on Plurk’s built in
annotation feature. Responses with @user_name
string in the content are matched with earlier res-
ponses by the author, user_name. Based on the
learned weights of the features, we observe that
content feature is not very useful in determining
the response pairs. In a Microblog dialogue, res-
pondents usually do not repeat the question nor
duplicate the keywords. We also have noticed that
there is high correlation between the responses re-
latedness and the number of other responses be-
tween them. For example, users are less likely to
respond to a response if there have been many rep-
lies about this response already. Statistical analy-
sis on positive training data shows that the average
number of responses between related responses is
2.3.
We train the classifier using 6000 automatically-
extracted pairs of both positive and negative in-
stances. We manually annotated 1600 pairs of data
for testing. The experiment result reaches 80.52%
accuracy in identifying response pairs. The base-
line model which uses only content similarity fea-
ture reaches only 45% in accuracy.
</bodyText>
<subsectionHeader confidence="0.994536">
2.4 Response Relevance Detection
</subsectionHeader>
<bodyText confidence="0.999963166666667">
For interrogative posts, we think the best summary
is to find out the relevent responses as potential
answers.
We introduce a response relevancy detection
component for the problem. Similar to previous
components, we exploit a supervised learning ap-
</bodyText>
<table confidence="0.999403857142857">
Feature Weight
Response position 0.170
Response time difference 0.008
Response length 0.003
Occurrence of interrogative 0.023
words
Content similarity 0.023
</table>
<tableCaption confidence="0.999868">
Table 2. Feature set and their weights
</tableCaption>
<bodyText confidence="0.980469333333333">
proach and the features’ weights, learned by
LIBSVM with RBF kernel, are shown in Table 2.
Temporal and Positional Features
A common assertion is that the earlier responses
have higher probability to be the answers of the
question. Based on the learned weights, it is not
surprising that most important feature is the posi-
tion of the response in the response hierarchy.
Another interesting finding by our system is that
meaningful replies do not come right away. Res-
ponses posted within ten seconds are usually for
chatting/clarification or ads from robots.
</bodyText>
<subsectionHeader confidence="0.744483">
Content Features
</subsectionHeader>
<bodyText confidence="0.999932142857143">
We use the length of the message, the cosine simi-
larity of the post and the responses, and the occur-
rence of the interrogative words in response
sentences as content features.
Because the interrogation posts in Plurk are rela-
tively few, we manually find a total of 382 positive
and 403 negative pairs for training and use 10-fold
cross validation for evaluation.
We implement the component using LIBSVM
(RBF Kernel) classifier. The baseline is to always
select the first response as the only relevant answer.
The results show that the accuracy of baseline
reaches 67.4%, far beyond that of our system
73.5%.
</bodyText>
<sectionHeader confidence="0.99719" genericHeader="method">
3 System Demonstration
</sectionHeader>
<bodyText confidence="0.999671333333333">
In this section, we show some snapshots of our
summarization system with real examples using
Plurk dataset. Our demo system is designed as a
</bodyText>
<figureCaption confidence="0.996604">
Figure 3. The IMASS interface
</figureCaption>
<page confidence="0.988697">
136
</page>
<figureCaption confidence="0.998239">
Figure 4. An example of interrogative post.
</figureCaption>
<bodyText confidence="0.999925882352941">
search engine (see Figure 3). Given a query term,
our system first returns several posts containing the
query string under the search bar. When one of the
posts is selected, it will generate a summary ac-
cording to the detected intention and show it in a
pop-up frame. We have recorded a video demon-
strating our system. The video can be viewed at
http://imss-acl11-demo.co.cc/.
For interrogative posts, we perform the response
relevancy detection. The summary contains the
question and relevant answers. Figure 4 is an ex-
ample of summary of an interrogative post. We can
see that responses other than the first and the last
responses are filtered because they are less relevant
to the question.
For sharing posts, the summary consists of two
parts. A pie chart that states the percentage of each
opinion group is displayed. Then the system picks
three responses from the majority group or one re-
sponse from each group if there is no significant
difference. Figure 5 is an example that most
friends of the user dfrag give positive feedback to
the shared video link.
For discussion posts, we combine the response
relevancy detection subsystem and the opinion
analysis sub-system for summarization. The former
first eliminates the responses that are not likely to
be the answer of the post. The latter then generates
a summary for the post and relevant responses. The
result is similar to sharing posts.
For chat posts, we apply the response pair iden-
tification component to generate the summary. In
the example, Figure 6, the original Plurk post is
about one topic while the responses diverge to one
</bodyText>
<figureCaption confidence="0.933697">
Figure 6. An Example of chat post
</figureCaption>
<bodyText confidence="0.999143428571429">
or more unrelated topics. Our system clearly sepa-
rates the responses into multiple groups. This re-
presentation helps the users to quickly catch up
with the discussion flow. The users no longer have
to read interleaving responses from different topics
and guess which topic group a response is referring
to.
</bodyText>
<figureCaption confidence="0.986395">
Figure 5. An example of sharing post.
</figureCaption>
<page confidence="0.992137">
137
</page>
<sectionHeader confidence="0.976462" genericHeader="related work">
4 Related Work ferent strategies are needed to process Microblog
</sectionHeader>
<bodyText confidence="0.995670734693878">
We have not seen many researches focusing on the messages. Our system uses an effective strategy to
issues of Microblog summarization. We found on- summarize the post/response by first determine the
ly one work that discusses about the issues of intention and then perform different analysis de-
summarization for Microblogs (Sharifi et al., 2010). pending on the post types. Conceptually, this work
Their goal, however, is very different from ours as intends to convey an alternative thinking about
they try to summarize multiple posts and do not machine-summarization. By utilizing text mining
consider the responses. They propose the Phrase and analysis techniques, computers are capable of
Reinforcement Algorithm to find the most com- providing more intelligent summarization than in-
monly used phrase that encompasses the topic formation condensation.
phrase, and use these phrases to compose the Acknowledgements
summary. They are essentially trying to solve a This work was supported by National Science
multi-document summarization problem while our Council, National Taiwan University and Intel
problem is more similar to short dialog summariza- Corporation under Grants NSC99-2911-I-002-001,
tion because the dialogue nature of Microblogs is 99R70600, and 10R80800.
one of the most challenging part that we tried to References
overcome. Chih-Chung Chang and Chih-Jen Lin. 2001. LIBSVM :
In dialogue summarization, many researchers a library for support vector machines. Software
have pointed out the importance of detecting re- available at http://www.csie.ntu.edu.tw/~cjlin/libsvm
sponse pairs in a conversation. Zechner (2001) per- Dipanjan Das and André F.T. Martins. 2007. A Survey
forms an in depth analysis and evaluation in the on Automatic Text Summarization. Literature Survey
area of open domain spoken dialogue summariza- for the Language and Statistics II Course. CMU.
tion. He uses decision tree classifier with lexical Chuanhan Liu, Yongcheng Wang, and Fei Zheng. 2006.
features like POS tags to identify questions and Automatic Text Summarization for Dialogue Style.
applies heuristic rules like maximum distance be- In Proceedings of the IEEE International Conference
tween speakers to extract answers. Shrestha and on Information Acquisition. 274-278
McKeown (2004) propose a supervised learning Beaux Sharifi, Mark A. Hutton, and Jugal Kalita. 2010.
method to detect question-answer pairs in Email Summarizing Microblogs Automatically. In Proceed-
conversations. Zhou and Hovy (2005) concen- ings of the Human Language Technologies: The
trates on summarizing dialogue-style technical in- 2010 Annual Conference of the North American
ternet relay chats using supervised learning Chapter of the Association for Computational Lin-
methods. Zhou further clusters chat logs into sev- guistics (NAACL-HLT). 685-688
eral topics and then extract some essential response Lokesh Shrestha and Kathleen McKeown. 2004. Detec-
pairs to form summaries. Liu et al. (2006) propose tion of Question-Answer Pairs in Email Conversa-
to identify question paragraph via analyzing each tions. In Proceedings of the 23rd International
participant’s status, and then use cosine measure to Conference on Computational Linguistics (COLING
select answer paragraphs for online news dataset. 2010).
The major differences between our components Klaus Zechner. 2001. Automatic Generation of Concise
and the systems proposed by others lie in the selec- Summaries of Spoken Dialogues in Unrestricted
tion of features. Due to the intrinsic difference be- Domains. In Proceedings of the 24th ACM-SIGIR
tween the writing styles of Microblog and other International Conference on Research and Develop-
online sources, our experiments show that the con- ment in Information Retrieval. 199-207.
tent feature is not as useful as the position and Liang Zhou and Eduard Hovy. 2005. Digesting virtual
temporal features. geek culture: The summarization of technical internet
5 Conclusion relay chats, in Proceedings of the 43rd Annual Meet-
In terms of length and writing styles, Microblogs ing of the Association for Computational Linguistics
possess very different characteristics than other (ACL 2005). 298-305.
online information sources such as web blogs and
news articles. It is therefore not surprising that dif-
138
</bodyText>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.612153">
<title confidence="0.999515">IMASS: An Intelligent Microblog Analysis and Summarization System</title>
<author confidence="0.999462">Jui-Yu Weng Cheng-Lun Yang Bo-Nian Chen Yen-Kai Wang Shou-De_Lin</author>
<affiliation confidence="0.999643">Department of Computer Science and Information National Taiwan University</affiliation>
<email confidence="0.695773">r98922060@csie.ntu.edu.tw</email>
<email confidence="0.695773">r99944042@csie.ntu.edu.tw</email>
<email confidence="0.695773">f92025@csie.ntu.edu.tw</email>
<email confidence="0.695773">b97081@csie.ntu.edu.tw</email>
<email confidence="0.695773">sdlin@csie.ntu.edu.tw</email>
<abstract confidence="0.993862">This paper presents a system to summarize a Microblog post and its responses with the goal to provide readers a more constructive and concise set of information for efficient digestion. We introduce a novel two-phase summarization scheme. In the first phase, the post plus its responses are classified into four categories based on the intention, interrogation, sharing, discussion and chat. For each type of post, in the second phase, we exploit different strategies, including opinion analysis, response pair identification, and response relevancy detection, to summarize and highlight critical information to display. This system provides an alternative thinking about machinesummarization: by utilizing AI approaches, computers are capable of constructing deeper and more user-friendly abstraction.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>