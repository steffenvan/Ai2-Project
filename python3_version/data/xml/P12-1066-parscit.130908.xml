<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000256">
<title confidence="0.729829">
Selective Sharing for Multilingual Dependency Parsing
</title>
<author confidence="0.358567">
Tahira Naseem Regina Barzilay Amir Globerson
</author>
<affiliation confidence="0.275252">
CSAIL, MIT CSAIL, MIT Hebrew University
</affiliation>
<email confidence="0.994182">
tahira@csail.mit.edu regina@csail.mit.edu gamir@cs.huji.ac.il
</email>
<sectionHeader confidence="0.996571" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997554">
We present a novel algorithm for multilin-
gual dependency parsing that uses annotations
from a diverse set of source languages to parse
a new unannotated language. Our motiva-
tion is to broaden the advantages of multilin-
gual learning to languages that exhibit signif-
icant differences from existing resource-rich
languages. The algorithm learns which as-
pects of the source languages are relevant for
the target language and ties model parame-
ters accordingly. The model factorizes the
process of generating a dependency tree into
two steps: selection of syntactic dependents
and their ordering. Being largely language-
universal, the selection component is learned
in a supervised fashion from all the training
languages. In contrast, the ordering decisions
are only influenced by languages with simi-
lar properties. We systematically model this
cross-lingual sharing using typological fea-
tures. In our experiments, the model con-
sistently outperforms a state-of-the-art multi-
lingual parser. The largest improvement is
achieved on the non Indo-European languages
yielding a gain of 14.4%.1
</bodyText>
<sectionHeader confidence="0.99888" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9998898">
Current top performing parsing algorithms rely on
the availability of annotated data for learning the
syntactic structure of a language. Standard ap-
proaches for extending these techniques to resource-
lean languages either use parallel corpora or rely on
</bodyText>
<footnote confidence="0.999434">
1The source code for the work presented in this paper is
available at http://groups.csail.mit.edu/rbg/code/unidep/
</footnote>
<bodyText confidence="0.999815058823529">
annotated trees from other source languages. These
techniques have been shown to work well for lan-
guage families with many annotated resources (such
as Indo-European languages). Unfortunately, for
many languages there are no available parallel cor-
pora or annotated resources in related languages.
For such languages the only remaining option is to
resort to unsupervised approaches, which are known
to produce highly inaccurate results.
In this paper, we present a new multilingual al-
gorithm for dependency parsing. In contrast to pre-
vious approaches, this algorithm can learn depen-
dency structures using annotations from a diverse
set of source languages, even if this set is not re-
lated to the target language. In our selective shar-
ing approach, the algorithm learns which aspects of
the source languages are relevant for the target lan-
guage and ties model parameters accordingly. This
approach is rooted in linguistic theory that charac-
terizes the connection between languages at various
levels of sharing. Some syntactic properties are uni-
versal across languages. For instance, nouns take ad-
jectives and determiners as dependents, but not ad-
verbs. However, the order of these dependents with
respect to the parent is influenced by the typological
features of each language.
To implement this intuition, we factorize genera-
tion of a dependency tree into two processes: selec-
tion of syntactic dependents and their ordering. The
first component models the distribution of depen-
dents for each part-of-speech tag, abstracting over
their order. Being largely language-universal, this
distribution can be learned in a supervised fashion
from all the training languages. On the other hand,
</bodyText>
<page confidence="0.984796">
629
</page>
<note confidence="0.9857725">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 629–637,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.9999664375">
ordering of dependents varies greatly across lan-
guages and therefore should only be influenced by
languages with similar properties. Furthermore, this
similarity has to be expressed at the level of depen-
dency types – i.e., two languages may share noun-
adposition ordering, but differ in noun-determiner
ordering. To systematically model this cross-lingual
sharing, we rely on typological features that reflect
ordering preferences of a given language. In addi-
tion to the known typological features, our parsing
model embeds latent features that can capture cross-
lingual structural similarities.
While the approach described so far supports a
seamless transfer of shared information, it does not
account for syntactic properties of the target lan-
guage unseen in the training languages. For in-
stance, in the CoNLL data, Arabic is the only lan-
guage with the VSO ordering. To handle such cases,
our approach augments cross-lingual sharing with
unsupervised learning on the target languages.
We evaluated our selective sharing model on 17
languages from 10 language families. On this di-
verse set, our model consistently outperforms state-
of-the-art multilingual dependency parsers. Per-
formance gain, averaged over all the languages, is
5.9% when compared to the highest baseline. Our
model achieves the most significant gains on non-
Indo-European languages, where we see a 14.4%
improvement. We also demonstrate that in the ab-
sence of observed typological information, a set of
automatically induced latent features can effectively
work as a proxy for typology.
</bodyText>
<sectionHeader confidence="0.999765" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999451960784314">
Traditionally, parallel corpora have been a main-
stay of multilingual parsing (Wu, 1997; Kuhn, 2004;
Smith and Smith, 2004; Hwa et al., 2005; Xi and
Hwa, 2005; Burkett and Klein, 2008; Snyder et al.,
2009). However, recent work in multilingual pars-
ing has demonstrated the feasibility of transfer in the
absence of parallel data. As a main source of guid-
ance, these methods rely on the commonalities in de-
pendency structure across languages. For instance,
Naseem et al. (2010) explicitly encode these similar-
ities in the form of universal rules which guide gram-
mar induction in the target language. An alterna-
tive approach is to directly employ a non-lexicalized
parser trained on one language to process a target
language (Zeman and Resnik, 2008; McDonald et
al., 2011; Søgaard, 2011). Since many unlexicalized
dependencies are preserved across languages, these
approaches are shown to be effective for related
languages. For instance, when applied to the lan-
guage pairs within the Indo-European family, such
parsers outperform unsupervised monolingual tech-
niques by a significant margin.
The challenge, however, is to enable dependency
transfer for target languages that exhibit structural
differences from source languages. In such cases,
the extent of multilingual transfer is determined by
the relation between source and target languages.
Berg-Kirkpatrick and Klein (2010) define such a re-
lation in terms of phylogenetic trees, and use this
distance to selectively tie the parameters of mono-
lingual syntactic models. Cohen et al. (2011) do not
use a predefined linguistic hierarchy of language re-
lations, but instead learn the contribution of source
languages to the training mixture based on the like-
lihood of the target language. Søgaard (2011)
proposes a different measure of language related-
ness based on perplexity between POS sequences
of source and target languages. Using this measure,
he selects a subset of training source sentences that
are closer to the target language. While all of the
above techniques demonstrate gains from modeling
language relatedness, they still underperform when
the source and target languages are unrelated.
Our model differs from the above approaches in
its emphasis on the selective information sharing
driven by language relatedness. This is further com-
bined with monolingual unsupervised learning. As
our evaluation demonstrates, this layered approach
broadens the advantages of multilingual learning to
languages that exhibit significant differences from
the languages in the training mix.
</bodyText>
<sectionHeader confidence="0.998878" genericHeader="method">
3 Linguistic Motivation
</sectionHeader>
<subsectionHeader confidence="0.942111">
Language-Independent Dependency Properties
</subsectionHeader>
<bodyText confidence="0.999509666666667">
Despite significant syntactic differences, human lan-
guages exhibit striking similarity in dependency pat-
terns. For a given part-of-speech tag, the set of tags
that can occur as its dependents is largely consistent
across languages. For instance, adverbs and nouns
are likely to be dependents of verbs, while adjectives
</bodyText>
<page confidence="0.995555">
630
</page>
<bodyText confidence="0.999886380952381">
are not. Thus, these patterns can be freely trans-
ferred across languages.
Shared Dependency Properties Unlike dependent
selection, the ordering of dependents in a sentence
differs greatly across languages. In fact, cross-
lingual syntactic variations are primarily expressed
in different ordering of dependents (Harris, 1968;
Greenberg, 1963). Fortunately, the dimensions of
these variations have been extensively studied in lin-
guistics and are documented in the form of typo-
logical features (Comrie, 1989; Haspelmath et al.,
2005). For instance, most languages are either dom-
inantly prepositional like English or post-positional
like Urdu. Moreover, a language may be close to dif-
ferent languages for different dependency types. For
instance, Portuguese is a prepositional language like
English, but the order of its noun-adjective depen-
dency is different from English and matches that of
Arabic. Therefore, we seek a model that can express
parameter sharing at the level of dependency types
and can benefit from known language relations.
</bodyText>
<subsectionHeader confidence="0.746978">
Language-specific Dependency Variations Not
</subsectionHeader>
<bodyText confidence="0.974164428571428">
every aspect of syntactic structure is shared across
languages. This is particularly true given a limited
number of supervised source languages; it is quite
likely that a target language will have previously un-
seen syntactic phenomena. In such a scenario, the
raw text in the target language might be the only
source of information about its unique aspects.
</bodyText>
<sectionHeader confidence="0.991536" genericHeader="method">
4 Model
</sectionHeader>
<bodyText confidence="0.9998260625">
We propose a probabilistic model for generating
dependency trees that facilitates parameter sharing
across languages. We assume a setup where de-
pendency tree annotations are available for a set of
source languages and we want to use these annota-
tions to infer a parser for a target language. Syn-
tactic trees for the target language are not available
during training. We also assume that both source
and target languages are annotated with a coarse
parts-of-speech tagset which is shared across lan-
guages. Such tagsets are commonly used in multilin-
gual parsing (Zeman and Resnik, 2008; McDonald
et al., 2011; Søgaard, 2011; Naseem et al., 2010).
The key feature of our model is a two-tier ap-
proach that separates the selection of dependents
from their ordering:
</bodyText>
<listItem confidence="0.991581666666667">
1. Selection Component: Determines the depen-
dent tags given the parent tag.
2. Ordering Component: Determines the position
</listItem>
<bodyText confidence="0.987997678571429">
of each dependent tag with respect to its parent
(right or left) and the order within the right and
left dependents.
This factorization constitutes a departure from
traditional parsing models where these decisions are
tightly coupled. By separating the two, the model
is able to support different degrees of cross-lingual
sharing on each level.
For the selection component, a reasonable ap-
proximation is to assume that it is the same for all
languages. This is the approach we take here.
As mentioned in Section 3, the ordering of depen-
dents is largely determined by the typological fea-
tures of the language. We assume that we have a
set of such features for every language l, and denote
this feature vector by vl. We also experiment with a
variant of our model where typological features are
not observed. Instead, the model captures structural
variations across languages by means of a small set
of binary latent features. The values of these fea-
tures are language dependent. We denote the set of
latent features for language l by bl.
Finally, based on the well known fact that long
distance dependencies are less likely (Eisner and
Smith, 2010), we bias our model towards short de-
pendencies. This is done by imposing a corpus-level
soft constraint on dependency lengths using the pos-
terior regularization framework (Grac¸a et al., 2007).
</bodyText>
<subsectionHeader confidence="0.741462">
4.1 Generative Process
</subsectionHeader>
<bodyText confidence="0.999980153846154">
Our model generates dependency trees one fragment
at a time. A fragment is defined as a subtree com-
prising the immediate dependents of any node in the
tree. The process recursively generates fragments
in a head outwards manner, where the distribution
over fragments depends on the head tag. If the gen-
erated fragment is not empty then the process con-
tinues for each child tag in the fragment, drawing
new fragments from the distribution associated with
the tag. The process stops when there are no more
non-empty fragments.
A fragment with head node h is generated in lan-
guage l via the following stages:
</bodyText>
<page confidence="0.988635">
631
</page>
<bodyText confidence="0.6484395">
h h h
{ , , , , D} { , , } { ,D} D
</bodyText>
<figure confidence="0.983163">
(a) (b) (c)
</figure>
<figureCaption confidence="0.9747745">
Figure 1: The steps of the generative process for a fragment with head h. In step (a), the unordered set of dependents
is chosen. In step (b) they are partitioned into left and right unordered sets. Finally, each set is ordered in step (c).
</figureCaption>
<listItem confidence="0.988512882352941">
• Generate the set of dependents of h via a distri-
bution Psel(S|h). Here S is an unordered set of
POS tags. Note that this part is universal (i.e.,
it does not depend on the language l).
• For each element in S decide whether it should
go to the right or left of h as follows: for every
a E S, draw its direction from the distribution
Pord(d|a, h, l), where d E {R, L}. This results
in two unordered sets SR, SL, the right and left
dependents of h. This part does depend on the
language l, since the relative ordering of depen-
dents is not likely to be universal.
• Order the sets SR, SL. For simplicity, we as-
sume that the order is drawn uniformly from
all the possible unique permutations over SR
and SL. We denote the number of such unique
permutations of SR by n(SR).2 Thus the prob-
</listItem>
<bodyText confidence="0.890776857142857">
ability of each permutation of SR is 1 3.
n(SR)
Figure 1 illustrates the generative process. The first
step constitutes the selection component and the last
two steps constitute the ordering component. Given
this generation scheme, the probability P(D) of
generating a given fragment D with head h will be:
</bodyText>
<listItem confidence="0.996352333333333">
• {D} is the unordered set of tags in D.
• dD(a) is the position (either R or L) of the de-
pendent a w.r.t. the head of D.
</listItem>
<bodyText confidence="0.993071">
In what follows we discuss the parameterizations
of the different distributions.
</bodyText>
<subsubsectionHeader confidence="0.690794">
4.1.1 Selection Component
</subsubsectionHeader>
<bodyText confidence="0.99988225">
The selection component draws an unordered set
of tags S given the head tag h. We assume that the
process is carried out in two steps. First the number
of dependents n is drawn from a distribution:
</bodyText>
<equation confidence="0.999291">
Psize(n|h) = θsize(n|h) (2)
</equation>
<bodyText confidence="0.9999498">
where θsize(n|h) is a parameter for each value of
n and h. We restrict the maximum value of n to
four, since this is a reasonable bound on the total
number of dependents for a single parent node in
a tree. These parameters are non-negative and sat-
isfy En θsize(n|h) = 1. In other words, the size
is drawn from a categorical distribution that is fully
parameterized.
Next, given the size n, a set S with |S |= n is
drawn according to the following log-linear model:
</bodyText>
<equation confidence="0.9672786">
�
Psel({D}|h)
aED
Pord(dD(a)|a, h,l) 1
n(DR)n(DL)
(1)
Ps S 1 eESiES θ.el(Si|h)
et( Ih n ) Zset(h, n)
�Zset(h, n) = eE Si E S θ.el (Si  |h)
S:|S|=n
</equation>
<bodyText confidence="0.997637">
Where we use the following notations:
</bodyText>
<listItem confidence="0.9950095">
• DR, DL denote the parts of the fragment that
are to the left and right of h.
</listItem>
<footnote confidence="0.868204">
2This number depends on the count of each distinct tag in
SR. For example if SR = {N, N, N} then n(SR) = 1. If
SR = {N, D, V } then n(SR) = K
3We acknowledge that assuming a uniform distribution over
the permutations of the right and left dependents is linguistically
counterintuitive. However, it simplifies the model by greatly
reducing the number of parameters to learn.
</footnote>
<bodyText confidence="0.99954">
In the above, Si is the ith POS tag in the unordered
set S, and θsel(Si|h) are parameters. Thus, large val-
ues of θsel(Si|h) indicate that POS Si is more likely
to appear in the subset with parent POS h.
Combining the above two steps we have the fol-
lowing distribution for selecting a set S of size n:
</bodyText>
<equation confidence="0.997056">
Psel(S|h) = Psize(n|h)Pset(S|h, n) . (3)
</equation>
<page confidence="0.995207">
632
</page>
<note confidence="0.997796571428571">
ID Feature Description Values
81A Order of Subject, Object and Verb SVO, SOV, VSO, VOS, OVS, OSV
85A Order of Adposition and Noun Postpositions, Prepositions, Inpositions
86A Order of Genitive and Noun Genitive-Noun, Noun-Genitive
87A Order of Adjective and Noun Adjective-Noun, Noun-Adjective
88A Order of Demonstrative and Noun Demonstrative-Noun, Noun-Demonstrative
89A Order of Numeral and Noun Numeral-Noun, Noun-Numeral
</note>
<tableCaption confidence="0.991220666666667">
Table 1: The set of typological features that we use in our model. For each feature, the first column gives the ID of
the feature as used in WALS, the second column describes the feature and the last column enumerates the allowable
values for the feature. Besides these values, each feature can also have a value of ‘No dominant order’.
</tableCaption>
<subsectionHeader confidence="0.577254">
4.1.2 Ordering Component
</subsectionHeader>
<bodyText confidence="0.99979725">
The ordering component consists of distributions
Pord(d|a, h, l) that determine whether tag a will be
mapped to the left or right of the head tag h. We
model it using the following log-linear model:
</bodyText>
<equation confidence="0.994755">
1 word&apos;g(d,a,h,vl)
Pord(d|a, h, l) = Zord(a, h, l) e
�Zord(a, h, l) = eword&apos;g(d,a,h,vl)
dE{R,L}
</equation>
<bodyText confidence="0.99941425">
Note that in the above equations the ordering
component depends on the known typological fea-
tures vi. In the setup when typological features are
not known, vi is replaced with the latent ordering
feature set bi.
The feature vector g contains indicator features
for combinations of a, h, d and individual features
vii (i.e., the ith typological features for language l).
</bodyText>
<subsectionHeader confidence="0.979606">
4.2 Typological Features
</subsectionHeader>
<bodyText confidence="0.9999377">
The typological features we use are a subset of
order-related typological features from “The World
Atlas of Language Structure” (Haspelmath et al.,
2005). We include only those features whose val-
ues are available for all the languages in our dataset.
Table 1 summarizes the set of features that we use.
Note that we do not explicitly specify the correspon-
dence between these features and the model param-
eters. Instead, we leave it for the model to learn this
correspondence automatically.
</bodyText>
<subsectionHeader confidence="0.996055">
4.3 Dependency Length Constraint
</subsectionHeader>
<bodyText confidence="0.998190071428572">
To incorporate the intuition that long distance de-
pendencies are less likely, we impose a posterior
constraint on dependency length. In particular, we
use the Posterior Regularization (PR) framework of
Grac¸a et al. (2007). The PR framework incorporates
constraints by adding a penalty term to the standard
likelihood objective. This term penalizes the dis-
tance of the model posterior from a set Q, where
Q contains all the posterior distributions that satisfy
the constraints. In our case the constraint is that the
expected dependency length is less than or equal to
a pre-specified threshold value b. If we denote the
latent dependency trees by z and the observed sen-
tences by x then
</bodyText>
<equation confidence="0.998209">
Q = {q(z|x) : EQ[f(x, z)] G b} (4)
</equation>
<bodyText confidence="0.999981166666667">
where f(x, z) computes the sum of the lengths of all
dependencies in z with respect to the linear order of
x. We measure the length of a dependency relation
by counting the number of tokens between the head
and its modifier. The PR objective penalizes the KL-
divergence of the model posterior from the set Q:
</bodyText>
<equation confidence="0.633039">
Lo(x) − KL (Q II po(z|x))
</equation>
<bodyText confidence="0.99971">
where B denotes the model parameters and the first
term is the log-likelihood of the data. This objective
can be optimized using a modified version of the EM
algorithm (Grac¸a et al., 2007).
</bodyText>
<sectionHeader confidence="0.987337" genericHeader="method">
5 Parameter Learning
</sectionHeader>
<bodyText confidence="0.998410166666667">
Our model is parameterized by the parameters Bsei,
Bsize and word. We learn these by maximizing the
likelihood of the training data. As is standard, we
add f2 regularization on the parameters and tune it
on source languages. The likelihood is marginalized
over all latent variables. These are:
</bodyText>
<listItem confidence="0.57742">
• For sentences in the target language: all pos-
sible derivations that result in the observed
POS tag sequences. The derivations include
the choice of unordered sets size n, the un-
ordered sets themselves S, their left/right al-
</listItem>
<page confidence="0.996024">
633
</page>
<bodyText confidence="0.971440145833333">
locations and the orderings within the left and
right branches.
• For all languages: all possible values of the la-
tent features bl.4
Since we are learning with latent variables, we use
the EM algorithm to monotonically improve the
likelihood. At each E step, the posterior over latent
variables is calculated using the current model. At
the M step this posterior is used to maximize the
likelihood over the fully observed data. To com-
pensate for the differences in the amount of training
data, the counts from each language are normalized
before computing the likelihood.
The M step involves finding maximum likelihood
parameters for log-linear models in Equations 3 and
4. This is done via standard gradient based search;
in particular, we use the method of BFGS.
We now briefly discuss how to calculate the pos-
terior probabilities. For estimating the word param-
eters we require marginals of the type P(bli|Dl; wt)
where Dl are the sentences in language l, bli is the
ith latent feature for the language l and wt are the
parameter values at iteration t. Consider doing this
for a source language l. Since the parses are known,
we only need to marginalize over the other latent
features. This can be done in a straightforward man-
ner by using our probabilistic model. The complex-
ity is exponential in the number of latent features,
since we need to marginalize over all features other
than bli. This is feasible in our case, since we use a
relatively small number of such features.
When performing unsupervised learning for the
target language, we need to marginalize over possi-
ble derivations. Specifically, for the M step, we need
probabilities of the form P(a modifies h|Dl; wt).
These can be calculated using a variant of the inside
outside algorithm. The exact version of this algo-
rithm would be exponential in the number of depen-
dents due to the 1
n(��) term in the permutation factor.
Although it is possible to run this exact algorithm in
our case, where the number of dependents is limited
to 4, we use an approximation that works well in
practice: instead of 1
n(��) we use 1
����!. In this case
the runtime is no longer exponential in the number
of children, so inference is much faster.
</bodyText>
<footnote confidence="0.885572">
4This corresponds to the case when typological features are
not known.
</footnote>
<bodyText confidence="0.999792">
Finally, given the trained parameters we generate
parses in the target language by calculating the max-
imum a posteriori derivation. This is done using a
variant of the CKY algorithm.
</bodyText>
<sectionHeader confidence="0.996802" genericHeader="method">
6 Experimental Setup
</sectionHeader>
<bodyText confidence="0.999357829268293">
Datasets and Evaluation We test the effectiveness
of our approach on 17 languages: Arabic, Basque,
Bulgarian, Catalan, Chinese, Czech, Dutch, English,
German, Greek, Hungarian, Italian, Japanese, Por-
tuguese, Spanish, Swedish and Turkish. We used
datasets distributed for the 2006 and 2007 CoNLL
Shared Tasks (Buchholz and Marsi, 2006; Nivre
et al., 2007). Each dataset provides manually an-
notated dependency trees and POS tags. To en-
able crosslingual sharing, we map the gold part-
of-speech tags in each corpus to a common coarse
tagset (Zeman and Resnik, 2008; Søgaard, 2011;
McDonald et al., 2011; Naseem et al., 2010). The
coarse tagset consists of 11 tags: noun, verb, ad-
jective, adverb, pronoun, determiner, adposition, nu-
meral, conjunction, particle, punctuation mark, and
X (a catch-all tag). Among several available fine-
to-coarse mapping schemes, we employ the one of
Naseem et al. (2010) that yields consistently better
performance for our method and the baselines than
the mapping proposed by Petrov et al. (2011).
As the evaluation metric, we use directed depen-
dency accuracy. Following standard evaluation prac-
tices, we do not evaluate on punctuation. For both
the baselines and our model we evaluate on all sen-
tences of length 50 or less ignoring punctuation.
Training Regime Our model typically converges
quickly and does not require more than 50 iterations
of EM. When the model involves latent typological
variables, the initialization of these variables can im-
pact the final performance. As a selection criterion
for initialization, we consider the performance of the
final model averaged over the supervised source lan-
guages. We perform ten random restarts and select
the best according to this criterion. Likewise, the
threshold value b for the PR constraint on the depen-
dency length is tuned on the source languages, using
average test set accuracy as the selection criterion.
Baselines We compare against the state-of-the-art
multilingual dependency parsers that do not use par-
allel corpora for training. All the systems were eval-
</bodyText>
<page confidence="0.997674">
634
</page>
<bodyText confidence="0.999971666666667">
uated using the same fine-to-coarse tagset mapping.
The first baseline, Transfer, uses direct transfer of a
discriminative parser trained on all the source lan-
guages (McDonald et al., 2011). This simple base-
line achieves surprisingly good results, within less
than 3% difference from a parser trained using par-
allel data. In the second baseline (Mixture), pa-
rameters of the target language are estimated as a
weighted mixture of the parameters learned from an-
notated source languages (Cohen et al., 2011). The
underlying parsing model is the dependency model
with valance (DMV) (Klein and Manning, 2004).
Originally, the baseline methods were evaluated on
different sets of languages using a different tag map-
ping. Therefore, we obtained new results for these
methods in our setup. For the Transfer baseline,
for each target language we trained the model on
all other languages in our dataset. For the Mixture
baseline, we trained the model on the same four lan-
guages used in the original paper — English, Ger-
man, Czech and Italian. When measuring the per-
formance on these languages, we selected another
set of four languages with a similar level of diver-
sity.5
</bodyText>
<sectionHeader confidence="0.999643" genericHeader="evaluation">
7 Results
</sectionHeader>
<bodyText confidence="0.980068626865672">
Table 2 summarizes the performance for different
configurations of our model and the baselines.
Comparison against Baselines On average, the
selective sharing model outperforms both base-
lines, yielding 8.9% gain over the weighted mixture
model (Cohen et al., 2011) and 5.9% gain over the
direct transfer method (McDonald et al., 2011). Our
model outperforms the weighted mixture model on
15 of the 17 languages and the transfer method on
12 of the 17 languages. Most of the gains are ob-
tained on non-Indo-European languages, that have
little similarity with the source languages. For this
set, the average gain over the transfer baseline is
14.4%. With some languages, such as Japanese,
achieving gains of as much as 30%.
On Indo-European languages, the model perfor-
mance is almost equivalent to that of the best per-
forming baseline. To explain this result we con-
5We also experimented with a version of the Cohen et al.
(2011) model trained on all the source languages. This setup
resulted in decreased performance. For this reason, we chose to
train the model on the four languages.
sider the performance of the supervised version of
our model which constitutes an upper bound on the
performance. The average accuracy of our super-
vised model on these languages is 66.8%, compared
to the 76.3% of the unlexicalized MST parser. Since
Indo-European languages are overrepresented in our
dataset, a target language from this family is likely
to exhibit more similarity to the training data. When
such similarity is substantial, the transfer baseline
will benefit from the power of a context-rich dis-
criminative parser.
A similar trait can be seen by comparing the per-
formance of our model to an oracle version of our
model which selects the optimal source language
for a given target language (column 7). Overall,
our method performs similarly to this oracle variant.
However, the gain for non Indo-European languages
is 1.9% vs -1.3% for Indo-European languages.
Analysis of Model Properties We first test our
hypothesis about the universal nature of the depen-
dent selection. We compare the performance of
our model (column 6) against a variant (column 8)
where this component is trained from annotations on
the target language. The performance of the two is
very close – 1.8%, supporting the above hypothesis.
To assess the contribution of other layers of selec-
tive sharing, we first explore the role of typological
features in learning the ordering component. When
the model does not have access to observed typo-
logical features, and does not use latent ones (col-
umn 4), the accuracy drops by 2.6%6. For some
languages (e.g., Turkish) the decrease is very pro-
nounced. Latent typological features (column 5) do
not yield the same gain as observed ones, but they do
improve the performance of the typology-free model
by 1.4%.
Next, we show the importance of using raw tar-
get language data in training the model. When
the model has to make all the ordering decisions
based on meta-linguistic features without account
for unique properties of the target languages, the
performance decreases by 0.9% (see column 3).
To assess the relative difficulty of learning the
ordering and selection components, we consider
model variants where each of these components is
</bodyText>
<footnote confidence="0.997442">
6In this setup, the ordering component is trained in an unsu-
pervised fashion on the target language.
</footnote>
<page confidence="0.992135">
635
</page>
<table confidence="0.99988437037037">
Baselines Selective Sharing Model
Mixture Transfer (D-,To) (D+) (D+,Tl) (D+,To) Best Pair Sup. Sel. Sup. Ord. MLE
Catalan 64.9 69.5 71.9 66.1 66.7 71.8 74.8 70.2 73.2 72.1
Italian
Portuguese
Spanish
61.9 68.3 68.0 65.5 64.2 65.6 68.3 65.1 70.7 72.3
72.9 75.8 76.2 72.3 76.0 73.5 76.4 77.4 77.6 79.6
57.2 65.9 62.3 58.5 59.4 62.1 63.4 61.5 62.6 65.3
Dutch 50.1 53.9 56.2 56.1 55.8 55.9 57.8 56.3 58.6 58.0
English
German
Swedish
45.9 47.0 47.6 48.5 48.1 48.6 44.4 46.3 60.0 62.7
54.5 56.4 54.0 53.5 54.3 53.7 54.8 52.4 56.2 58.0
56.4 63.6 52.0 61.4 60.6 61.5 63.5 67.9 67.1 73.0
Bulgarian 67.7 64.0 67.6 63.5 63.9 66.8 66.1 66.2 69.5 71.0
Czech
39.6 40.3 43.9 44.7 45.4 44.6 47.5 53.2 51.2 58.9
Arabic 44.8 40.7 57.2 58.8 60.3 58.9 57.6 62.9 61.9 64.2
Basque 32.8 32.4 39.7 40.1 39.8 47.6 42.0 46.2 47.9 51.6
Chinese 46.7 49.3 59.9 52.2 52.0 51.2 65.4 62.3 65.5 73.5
Greek 56.8 60.4 61.9 67.5 67.3 67.4 60.6 67.2 69.0 70.5
Hungarian 46.8 54.3 56.9 58.4 58.8 58.5 57.0 57.4 62.0 61.6
Japanese 33.5 34.7 62.3 56.8 61.4 64.0 54.8 63.4 69.7 75.6
Turkish 28.3 34.3 59.1 43.6 57.8 59.2 56.9 66.6 59.5 67.6
Average 50.6 53.6 58.6 56.9 58.3 59.5 59.5 61.3 63.7 66.8
</table>
<tableCaption confidence="0.993967">
Table 2: Directed dependency accuracy of different variants of our selective sharing model and the baselines. The
</tableCaption>
<bodyText confidence="0.995719038461539">
first section of the table (column 1 and 2) shows the accuracy of the weighted mixture baseline (Cohen et al., 2011)
(Mixture) and the multi-source transfer baseline (McDonald et al., 2011) (Transfer). The middle section shows the
performance of our model in different settings. Df indicates the presence/absence of raw target language data during
training. To indicates the use of observed typological features for all languages and Tl indicates the use of latent
typological features for all languages. The last section shows results of our model with different levels of oracle
supervision: a. (Best Pair) Model parameters are borrowed from the best source language based on the accuracy on
the target language b. (Sup. Sel.) Selection component is trained using MLE estimates from target language c. (Sup.
Ord.) Ordering component is trained using MLE estimates from the target language d. (MLE) All model parameters
are trained on the target language in a supervised fashion. The horizontal partitions separate language families. The
first three families are sub-divisions of the Indo-European language family.
trained using annotations in the target language. As
shown in columns 8 and 9, these two variants out-
perform the original model, achieving 61.3% for su-
pervised selection and 63.7% for supervised order-
ing. Comparing these numbers to the accuracy of
the original model (column 6) demonstrates the dif-
ficulty inherent in learning the ordering information.
This finding is expected given that ordering involves
selective sharing from multiple languages.
Overall, the performance gap between the selec-
tive sharing model and its monolingual supervised
counterpart is 7.3%. In contrast, the unsupervised
monolingual variant of our model achieves a mea-
ger 26%.7 This demonstrates that our model can ef-
fectively learn relevant aspects of syntactic structure
from a diverse set of languages.
</bodyText>
<footnote confidence="0.9962185">
7This performance is comparable to other generative models
such as DMV (Klein and Manning, 2004).
</footnote>
<sectionHeader confidence="0.997607" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.999996">
We present a novel algorithm for multilingual de-
pendency parsing that uses annotations from a di-
verse set of source languages to parse a new unan-
notated language. Overall, our model consistently
outperforms the multi-source transfer based depen-
dency parser of McDonald et al. (2011). Our ex-
periments demonstrate that the model is particularly
effective in processing languages that exhibit signif-
icant differences from the training languages.
</bodyText>
<sectionHeader confidence="0.998822" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999839333333333">
The authors acknowledge the support of the NSF
(IIS-0835445), the MURI program (W911NF-10-
1-0533), the DARPA BOLT program, and the ISF
(1789/11). We thank Tommi Jaakkola, Ryan Mc-
Donald and the members of the MIT NLP group for
their comments.
</bodyText>
<page confidence="0.998714">
636
</page>
<sectionHeader confidence="0.99387" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999166473684211">
Taylor Berg-Kirkpatrick and Dan Klein. 2010. Phyloge-
netic grammar induction. In ACL, pages 1288–1297.
Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X
shared task on multilingual dependency parsing. In
Proceedings of CoNLL, pages 149–164.
David Burkett and Dan Klein. 2008. Two languages are
better than one (for syntactic parsing). In Proceedings
of EMNLP, pages 877–886.
Shay B. Cohen, Dipanjan Das, and Noah A. Smith. 2011.
Unsupervised structure prediction with non-parallel
multilingual guidance. In EMNLP, pages 50–61.
Bernard Comrie. 1989. Language Universals and Lin-
guistic Typology: Syntax and Morphology. Oxford:
Blackwell.
Jason Eisner and Noah A. Smith. 2010. Favor short de-
pendencies: Parsing with soft and hard constraints on
dependency length. In Trends in Parsing Technology:
Dependency Parsing, Domain Adaptation, and Deep
Parsing, pages 121–150.
Jo˜ao Grac¸a, Kuzman Ganchev, and Ben Taskar. 2007.
Expectation maximization and posterior constraints.
In Advances in NIPS, pages 569–576.
Joseph H Greenberg. 1963. Some universals of language
with special reference to the order of meaningful ele-
ments. In Joseph H Greenberg, editor, Universals of
Language, pages 73–113. MIT Press.
Z.S. Harris. 1968. Mathematical structures of language.
Wiley.
Martin Haspelmath, Matthew S. Dryer, David Gil, and
Bernard Comrie, editors. 2005. The World Atlas of
Language Structures. Oxford University Press.
R. Hwa, P. Resnik, A. Weinberg, C. Cabezas, and O. Ko-
lak. 2005. Bootstrapping parsers via syntactic projec-
tion across parallel texts. Journal ofNatural Language
Engineering, 11(3):311–325.
Dan Klein and Christopher Manning. 2004. Corpus-
based induction of syntactic structure: Models of de-
pendency and constituency. In Proceedings of ACL,
pages 478–485.
Jonas Kuhn. 2004. Experiments in parallel-text based
grammar induction. In Proceedings of the ACL, pages
470–477.
Ryan T. McDonald, Slav Petrov, and Keith Hall. 2011.
Multi-source transfer of delexicalized dependency
parsers. In EMNLP, pages 62–72.
Tahira Naseem, Harr Chen, Regina Barzilay, and Mark
Johnson. 2010. Using universal linguistic knowledge
to guide grammar induction. In EMNLP, pages 1234–
1244.
Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan McDon-
ald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret.
2007. The CoNLL 2007 shared task on dependency
parsing. In Proceedings of the CoNLL Shared Task
Session of EMNLP-CoNLL 2007, pages 915–932.
Slav Petrov, Dipanjan Das, and Ryan McDonald. 2011.
A universal part-of-speech tagset. In ArXiv, April.
David A. Smith and Noah A. Smith. 2004. Bilingual
parsing with factored estimation: Using English to
parse Korean. In Proceeding of EMNLP, pages 49–
56.
Benjamin Snyder, Tahira Naseem, and Regina Barzilay.
2009. Unsupervised multilingual grammar induction.
In Proceedings ofACL/AFNLP, pages 73–81.
Anders Søgaard. 2011. Data point selection for cross-
language adaptation of dependency parsers. In ACL
(Short Papers), pages 682–686.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3):377–403.
Chenhai Xi and Rebecca Hwa. 2005. A backoff model
for bootstrapping resources for non-english languages.
In Proceedings of EMNLP, pages 851 – 858.
Daniel Zeman and Philip Resnik. 2008. Cross-language
parser adaptation between related languages. In Pro-
ceedings of the IJCNLP-08 Workshop on NLP for Less
Privileged Languages, pages 35–42, January.
</reference>
<page confidence="0.997765">
637
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.589198">
<title confidence="0.999855">Selective Sharing for Multilingual Dependency Parsing</title>
<author confidence="0.99422">Tahira Naseem Regina Barzilay Amir Globerson</author>
<affiliation confidence="0.999456">CSAIL, MIT CSAIL, MIT Hebrew University</affiliation>
<email confidence="0.993673">tahira@csail.mit.eduregina@csail.mit.edugamir@cs.huji.ac.il</email>
<abstract confidence="0.984022153846154">We present a novel algorithm for multilingual dependency parsing that uses annotations from a diverse set of source languages to parse a new unannotated language. Our motivation is to broaden the advantages of multilingual learning to languages that exhibit significant differences from existing resource-rich languages. The algorithm learns which aspects of the source languages are relevant for the target language and ties model parameters accordingly. The model factorizes the process of generating a dependency tree into steps: syntactic dependents their Being largely languageuniversal, the selection component is learned in a supervised fashion from all the training languages. In contrast, the ordering decisions are only influenced by languages with similar properties. We systematically model this cross-lingual sharing using typological features. In our experiments, the model consistently outperforms a state-of-the-art multilingual parser. The largest improvement is achieved on the non Indo-European languages a gain of</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Taylor Berg-Kirkpatrick</author>
<author>Dan Klein</author>
</authors>
<title>Phylogenetic grammar induction.</title>
<date>2010</date>
<booktitle>In ACL,</booktitle>
<pages>1288--1297</pages>
<contexts>
<context position="6505" citStr="Berg-Kirkpatrick and Klein (2010)" startWordPosition="971" endWordPosition="974">8; McDonald et al., 2011; Søgaard, 2011). Since many unlexicalized dependencies are preserved across languages, these approaches are shown to be effective for related languages. For instance, when applied to the language pairs within the Indo-European family, such parsers outperform unsupervised monolingual techniques by a significant margin. The challenge, however, is to enable dependency transfer for target languages that exhibit structural differences from source languages. In such cases, the extent of multilingual transfer is determined by the relation between source and target languages. Berg-Kirkpatrick and Klein (2010) define such a relation in terms of phylogenetic trees, and use this distance to selectively tie the parameters of monolingual syntactic models. Cohen et al. (2011) do not use a predefined linguistic hierarchy of language relations, but instead learn the contribution of source languages to the training mixture based on the likelihood of the target language. Søgaard (2011) proposes a different measure of language relatedness based on perplexity between POS sequences of source and target languages. Using this measure, he selects a subset of training source sentences that are closer to the target</context>
</contexts>
<marker>Berg-Kirkpatrick, Klein, 2010</marker>
<rawString>Taylor Berg-Kirkpatrick and Dan Klein. 2010. Phylogenetic grammar induction. In ACL, pages 1288–1297.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>CoNLL-X shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of CoNLL,</booktitle>
<pages>149--164</pages>
<contexts>
<context position="22242" citStr="Buchholz and Marsi, 2006" startWordPosition="3621" endWordPosition="3624">is much faster. 4This corresponds to the case when typological features are not known. Finally, given the trained parameters we generate parses in the target language by calculating the maximum a posteriori derivation. This is done using a variant of the CKY algorithm. 6 Experimental Setup Datasets and Evaluation We test the effectiveness of our approach on 17 languages: Arabic, Basque, Bulgarian, Catalan, Chinese, Czech, Dutch, English, German, Greek, Hungarian, Italian, Japanese, Portuguese, Spanish, Swedish and Turkish. We used datasets distributed for the 2006 and 2007 CoNLL Shared Tasks (Buchholz and Marsi, 2006; Nivre et al., 2007). Each dataset provides manually annotated dependency trees and POS tags. To enable crosslingual sharing, we map the gold partof-speech tags in each corpus to a common coarse tagset (Zeman and Resnik, 2008; Søgaard, 2011; McDonald et al., 2011; Naseem et al., 2010). The coarse tagset consists of 11 tags: noun, verb, adjective, adverb, pronoun, determiner, adposition, numeral, conjunction, particle, punctuation mark, and X (a catch-all tag). Among several available fineto-coarse mapping schemes, we employ the one of Naseem et al. (2010) that yields consistently better perfo</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X shared task on multilingual dependency parsing. In Proceedings of CoNLL, pages 149–164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Burkett</author>
<author>Dan Klein</author>
</authors>
<title>Two languages are better than one (for syntactic parsing).</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>877--886</pages>
<contexts>
<context position="5310" citStr="Burkett and Klein, 2008" startWordPosition="791" endWordPosition="794">ateof-the-art multilingual dependency parsers. Performance gain, averaged over all the languages, is 5.9% when compared to the highest baseline. Our model achieves the most significant gains on nonIndo-European languages, where we see a 14.4% improvement. We also demonstrate that in the absence of observed typological information, a set of automatically induced latent features can effectively work as a proxy for typology. 2 Related Work Traditionally, parallel corpora have been a mainstay of multilingual parsing (Wu, 1997; Kuhn, 2004; Smith and Smith, 2004; Hwa et al., 2005; Xi and Hwa, 2005; Burkett and Klein, 2008; Snyder et al., 2009). However, recent work in multilingual parsing has demonstrated the feasibility of transfer in the absence of parallel data. As a main source of guidance, these methods rely on the commonalities in dependency structure across languages. For instance, Naseem et al. (2010) explicitly encode these similarities in the form of universal rules which guide grammar induction in the target language. An alternative approach is to directly employ a non-lexicalized parser trained on one language to process a target language (Zeman and Resnik, 2008; McDonald et al., 2011; Søgaard, 201</context>
</contexts>
<marker>Burkett, Klein, 2008</marker>
<rawString>David Burkett and Dan Klein. 2008. Two languages are better than one (for syntactic parsing). In Proceedings of EMNLP, pages 877–886.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shay B Cohen</author>
<author>Dipanjan Das</author>
<author>Noah A Smith</author>
</authors>
<title>Unsupervised structure prediction with non-parallel multilingual guidance.</title>
<date>2011</date>
<booktitle>In EMNLP,</booktitle>
<pages>50--61</pages>
<contexts>
<context position="6669" citStr="Cohen et al. (2011)" startWordPosition="999" endWordPosition="1002">For instance, when applied to the language pairs within the Indo-European family, such parsers outperform unsupervised monolingual techniques by a significant margin. The challenge, however, is to enable dependency transfer for target languages that exhibit structural differences from source languages. In such cases, the extent of multilingual transfer is determined by the relation between source and target languages. Berg-Kirkpatrick and Klein (2010) define such a relation in terms of phylogenetic trees, and use this distance to selectively tie the parameters of monolingual syntactic models. Cohen et al. (2011) do not use a predefined linguistic hierarchy of language relations, but instead learn the contribution of source languages to the training mixture based on the likelihood of the target language. Søgaard (2011) proposes a different measure of language relatedness based on perplexity between POS sequences of source and target languages. Using this measure, he selects a subset of training source sentences that are closer to the target language. While all of the above techniques demonstrate gains from modeling language relatedness, they still underperform when the source and target languages are </context>
<context position="24467" citStr="Cohen et al., 2011" startWordPosition="3975" endWordPosition="3978">he-art multilingual dependency parsers that do not use parallel corpora for training. All the systems were eval634 uated using the same fine-to-coarse tagset mapping. The first baseline, Transfer, uses direct transfer of a discriminative parser trained on all the source languages (McDonald et al., 2011). This simple baseline achieves surprisingly good results, within less than 3% difference from a parser trained using parallel data. In the second baseline (Mixture), parameters of the target language are estimated as a weighted mixture of the parameters learned from annotated source languages (Cohen et al., 2011). The underlying parsing model is the dependency model with valance (DMV) (Klein and Manning, 2004). Originally, the baseline methods were evaluated on different sets of languages using a different tag mapping. Therefore, we obtained new results for these methods in our setup. For the Transfer baseline, for each target language we trained the model on all other languages in our dataset. For the Mixture baseline, we trained the model on the same four languages used in the original paper — English, German, Czech and Italian. When measuring the performance on these languages, we selected another </context>
<context position="26061" citStr="Cohen et al. (2011)" startWordPosition="4240" endWordPosition="4243">hod (McDonald et al., 2011). Our model outperforms the weighted mixture model on 15 of the 17 languages and the transfer method on 12 of the 17 languages. Most of the gains are obtained on non-Indo-European languages, that have little similarity with the source languages. For this set, the average gain over the transfer baseline is 14.4%. With some languages, such as Japanese, achieving gains of as much as 30%. On Indo-European languages, the model performance is almost equivalent to that of the best performing baseline. To explain this result we con5We also experimented with a version of the Cohen et al. (2011) model trained on all the source languages. This setup resulted in decreased performance. For this reason, we chose to train the model on the four languages. sider the performance of the supervised version of our model which constitutes an upper bound on the performance. The average accuracy of our supervised model on these languages is 66.8%, compared to the 76.3% of the unlexicalized MST parser. Since Indo-European languages are overrepresented in our dataset, a target language from this family is likely to exhibit more similarity to the training data. When such similarity is substantial, th</context>
<context position="29883" citStr="Cohen et al., 2011" startWordPosition="4890" endWordPosition="4893">39.7 40.1 39.8 47.6 42.0 46.2 47.9 51.6 Chinese 46.7 49.3 59.9 52.2 52.0 51.2 65.4 62.3 65.5 73.5 Greek 56.8 60.4 61.9 67.5 67.3 67.4 60.6 67.2 69.0 70.5 Hungarian 46.8 54.3 56.9 58.4 58.8 58.5 57.0 57.4 62.0 61.6 Japanese 33.5 34.7 62.3 56.8 61.4 64.0 54.8 63.4 69.7 75.6 Turkish 28.3 34.3 59.1 43.6 57.8 59.2 56.9 66.6 59.5 67.6 Average 50.6 53.6 58.6 56.9 58.3 59.5 59.5 61.3 63.7 66.8 Table 2: Directed dependency accuracy of different variants of our selective sharing model and the baselines. The first section of the table (column 1 and 2) shows the accuracy of the weighted mixture baseline (Cohen et al., 2011) (Mixture) and the multi-source transfer baseline (McDonald et al., 2011) (Transfer). The middle section shows the performance of our model in different settings. Df indicates the presence/absence of raw target language data during training. To indicates the use of observed typological features for all languages and Tl indicates the use of latent typological features for all languages. The last section shows results of our model with different levels of oracle supervision: a. (Best Pair) Model parameters are borrowed from the best source language based on the accuracy on the target language b.</context>
</contexts>
<marker>Cohen, Das, Smith, 2011</marker>
<rawString>Shay B. Cohen, Dipanjan Das, and Noah A. Smith. 2011. Unsupervised structure prediction with non-parallel multilingual guidance. In EMNLP, pages 50–61.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernard Comrie</author>
</authors>
<title>Language Universals and Linguistic Typology: Syntax and Morphology.</title>
<date>1989</date>
<publisher>Blackwell.</publisher>
<location>Oxford:</location>
<contexts>
<context position="8560" citStr="Comrie, 1989" startWordPosition="1276" endWordPosition="1277">across languages. For instance, adverbs and nouns are likely to be dependents of verbs, while adjectives 630 are not. Thus, these patterns can be freely transferred across languages. Shared Dependency Properties Unlike dependent selection, the ordering of dependents in a sentence differs greatly across languages. In fact, crosslingual syntactic variations are primarily expressed in different ordering of dependents (Harris, 1968; Greenberg, 1963). Fortunately, the dimensions of these variations have been extensively studied in linguistics and are documented in the form of typological features (Comrie, 1989; Haspelmath et al., 2005). For instance, most languages are either dominantly prepositional like English or post-positional like Urdu. Moreover, a language may be close to different languages for different dependency types. For instance, Portuguese is a prepositional language like English, but the order of its noun-adjective dependency is different from English and matches that of Arabic. Therefore, we seek a model that can express parameter sharing at the level of dependency types and can benefit from known language relations. Language-specific Dependency Variations Not every aspect of synta</context>
</contexts>
<marker>Comrie, 1989</marker>
<rawString>Bernard Comrie. 1989. Language Universals and Linguistic Typology: Syntax and Morphology. Oxford: Blackwell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Eisner</author>
<author>Noah A Smith</author>
</authors>
<title>Favor short dependencies: Parsing with soft and hard constraints on dependency length.</title>
<date>2010</date>
<booktitle>In Trends in Parsing Technology: Dependency Parsing, Domain Adaptation, and Deep Parsing,</booktitle>
<pages>121--150</pages>
<contexts>
<context position="11536" citStr="Eisner and Smith, 2010" startWordPosition="1757" endWordPosition="1760">ing of dependents is largely determined by the typological features of the language. We assume that we have a set of such features for every language l, and denote this feature vector by vl. We also experiment with a variant of our model where typological features are not observed. Instead, the model captures structural variations across languages by means of a small set of binary latent features. The values of these features are language dependent. We denote the set of latent features for language l by bl. Finally, based on the well known fact that long distance dependencies are less likely (Eisner and Smith, 2010), we bias our model towards short dependencies. This is done by imposing a corpus-level soft constraint on dependency lengths using the posterior regularization framework (Grac¸a et al., 2007). 4.1 Generative Process Our model generates dependency trees one fragment at a time. A fragment is defined as a subtree comprising the immediate dependents of any node in the tree. The process recursively generates fragments in a head outwards manner, where the distribution over fragments depends on the head tag. If the generated fragment is not empty then the process continues for each child tag in the </context>
</contexts>
<marker>Eisner, Smith, 2010</marker>
<rawString>Jason Eisner and Noah A. Smith. 2010. Favor short dependencies: Parsing with soft and hard constraints on dependency length. In Trends in Parsing Technology: Dependency Parsing, Domain Adaptation, and Deep Parsing, pages 121–150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jo˜ao Grac¸a</author>
<author>Kuzman Ganchev</author>
<author>Ben Taskar</author>
</authors>
<title>Expectation maximization and posterior constraints.</title>
<date>2007</date>
<booktitle>In Advances in NIPS,</booktitle>
<pages>569--576</pages>
<marker>Grac¸a, Ganchev, Taskar, 2007</marker>
<rawString>Jo˜ao Grac¸a, Kuzman Ganchev, and Ben Taskar. 2007. Expectation maximization and posterior constraints. In Advances in NIPS, pages 569–576.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph H Greenberg</author>
</authors>
<title>Some universals of language with special reference to the order of meaningful elements.</title>
<date>1963</date>
<booktitle>Universals of Language,</booktitle>
<pages>73--113</pages>
<editor>In Joseph H Greenberg, editor,</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="8397" citStr="Greenberg, 1963" startWordPosition="1251" endWordPosition="1252">n languages exhibit striking similarity in dependency patterns. For a given part-of-speech tag, the set of tags that can occur as its dependents is largely consistent across languages. For instance, adverbs and nouns are likely to be dependents of verbs, while adjectives 630 are not. Thus, these patterns can be freely transferred across languages. Shared Dependency Properties Unlike dependent selection, the ordering of dependents in a sentence differs greatly across languages. In fact, crosslingual syntactic variations are primarily expressed in different ordering of dependents (Harris, 1968; Greenberg, 1963). Fortunately, the dimensions of these variations have been extensively studied in linguistics and are documented in the form of typological features (Comrie, 1989; Haspelmath et al., 2005). For instance, most languages are either dominantly prepositional like English or post-positional like Urdu. Moreover, a language may be close to different languages for different dependency types. For instance, Portuguese is a prepositional language like English, but the order of its noun-adjective dependency is different from English and matches that of Arabic. Therefore, we seek a model that can express </context>
</contexts>
<marker>Greenberg, 1963</marker>
<rawString>Joseph H Greenberg. 1963. Some universals of language with special reference to the order of meaningful elements. In Joseph H Greenberg, editor, Universals of Language, pages 73–113. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z S Harris</author>
</authors>
<title>Mathematical structures of language.</title>
<date>1968</date>
<publisher>Wiley.</publisher>
<contexts>
<context position="8379" citStr="Harris, 1968" startWordPosition="1249" endWordPosition="1250">ferences, human languages exhibit striking similarity in dependency patterns. For a given part-of-speech tag, the set of tags that can occur as its dependents is largely consistent across languages. For instance, adverbs and nouns are likely to be dependents of verbs, while adjectives 630 are not. Thus, these patterns can be freely transferred across languages. Shared Dependency Properties Unlike dependent selection, the ordering of dependents in a sentence differs greatly across languages. In fact, crosslingual syntactic variations are primarily expressed in different ordering of dependents (Harris, 1968; Greenberg, 1963). Fortunately, the dimensions of these variations have been extensively studied in linguistics and are documented in the form of typological features (Comrie, 1989; Haspelmath et al., 2005). For instance, most languages are either dominantly prepositional like English or post-positional like Urdu. Moreover, a language may be close to different languages for different dependency types. For instance, Portuguese is a prepositional language like English, but the order of its noun-adjective dependency is different from English and matches that of Arabic. Therefore, we seek a model</context>
</contexts>
<marker>Harris, 1968</marker>
<rawString>Z.S. Harris. 1968. Mathematical structures of language. Wiley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Haspelmath</author>
<author>Matthew S Dryer</author>
<author>David Gil</author>
<author>Bernard Comrie</author>
<author>editors</author>
</authors>
<title>The World Atlas of Language Structures.</title>
<date>2005</date>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="8586" citStr="Haspelmath et al., 2005" startWordPosition="1278" endWordPosition="1281">es. For instance, adverbs and nouns are likely to be dependents of verbs, while adjectives 630 are not. Thus, these patterns can be freely transferred across languages. Shared Dependency Properties Unlike dependent selection, the ordering of dependents in a sentence differs greatly across languages. In fact, crosslingual syntactic variations are primarily expressed in different ordering of dependents (Harris, 1968; Greenberg, 1963). Fortunately, the dimensions of these variations have been extensively studied in linguistics and are documented in the form of typological features (Comrie, 1989; Haspelmath et al., 2005). For instance, most languages are either dominantly prepositional like English or post-positional like Urdu. Moreover, a language may be close to different languages for different dependency types. For instance, Portuguese is a prepositional language like English, but the order of its noun-adjective dependency is different from English and matches that of Arabic. Therefore, we seek a model that can express parameter sharing at the level of dependency types and can benefit from known language relations. Language-specific Dependency Variations Not every aspect of syntactic structure is shared a</context>
<context position="17276" citStr="Haspelmath et al., 2005" startWordPosition="2780" endWordPosition="2783">ord(d|a, h, l) = Zord(a, h, l) e �Zord(a, h, l) = eword&apos;g(d,a,h,vl) dE{R,L} Note that in the above equations the ordering component depends on the known typological features vi. In the setup when typological features are not known, vi is replaced with the latent ordering feature set bi. The feature vector g contains indicator features for combinations of a, h, d and individual features vii (i.e., the ith typological features for language l). 4.2 Typological Features The typological features we use are a subset of order-related typological features from “The World Atlas of Language Structure” (Haspelmath et al., 2005). We include only those features whose values are available for all the languages in our dataset. Table 1 summarizes the set of features that we use. Note that we do not explicitly specify the correspondence between these features and the model parameters. Instead, we leave it for the model to learn this correspondence automatically. 4.3 Dependency Length Constraint To incorporate the intuition that long distance dependencies are less likely, we impose a posterior constraint on dependency length. In particular, we use the Posterior Regularization (PR) framework of Grac¸a et al. (2007). The PR </context>
</contexts>
<marker>Haspelmath, Dryer, Gil, Comrie, editors, 2005</marker>
<rawString>Martin Haspelmath, Matthew S. Dryer, David Gil, and Bernard Comrie, editors. 2005. The World Atlas of Language Structures. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Hwa</author>
<author>P Resnik</author>
<author>A Weinberg</author>
<author>C Cabezas</author>
<author>O Kolak</author>
</authors>
<title>Bootstrapping parsers via syntactic projection across parallel texts.</title>
<date>2005</date>
<journal>Journal ofNatural Language Engineering,</journal>
<volume>11</volume>
<issue>3</issue>
<contexts>
<context position="5267" citStr="Hwa et al., 2005" startWordPosition="783" endWordPosition="786">ur model consistently outperforms stateof-the-art multilingual dependency parsers. Performance gain, averaged over all the languages, is 5.9% when compared to the highest baseline. Our model achieves the most significant gains on nonIndo-European languages, where we see a 14.4% improvement. We also demonstrate that in the absence of observed typological information, a set of automatically induced latent features can effectively work as a proxy for typology. 2 Related Work Traditionally, parallel corpora have been a mainstay of multilingual parsing (Wu, 1997; Kuhn, 2004; Smith and Smith, 2004; Hwa et al., 2005; Xi and Hwa, 2005; Burkett and Klein, 2008; Snyder et al., 2009). However, recent work in multilingual parsing has demonstrated the feasibility of transfer in the absence of parallel data. As a main source of guidance, these methods rely on the commonalities in dependency structure across languages. For instance, Naseem et al. (2010) explicitly encode these similarities in the form of universal rules which guide grammar induction in the target language. An alternative approach is to directly employ a non-lexicalized parser trained on one language to process a target language (Zeman and Resnik</context>
</contexts>
<marker>Hwa, Resnik, Weinberg, Cabezas, Kolak, 2005</marker>
<rawString>R. Hwa, P. Resnik, A. Weinberg, C. Cabezas, and O. Kolak. 2005. Bootstrapping parsers via syntactic projection across parallel texts. Journal ofNatural Language Engineering, 11(3):311–325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher Manning</author>
</authors>
<title>Corpusbased induction of syntactic structure: Models of dependency and constituency.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>478--485</pages>
<contexts>
<context position="24566" citStr="Klein and Manning, 2004" startWordPosition="3990" endWordPosition="3993">systems were eval634 uated using the same fine-to-coarse tagset mapping. The first baseline, Transfer, uses direct transfer of a discriminative parser trained on all the source languages (McDonald et al., 2011). This simple baseline achieves surprisingly good results, within less than 3% difference from a parser trained using parallel data. In the second baseline (Mixture), parameters of the target language are estimated as a weighted mixture of the parameters learned from annotated source languages (Cohen et al., 2011). The underlying parsing model is the dependency model with valance (DMV) (Klein and Manning, 2004). Originally, the baseline methods were evaluated on different sets of languages using a different tag mapping. Therefore, we obtained new results for these methods in our setup. For the Transfer baseline, for each target language we trained the model on all other languages in our dataset. For the Mixture baseline, we trained the model on the same four languages used in the original paper — English, German, Czech and Italian. When measuring the performance on these languages, we selected another set of four languages with a similar level of diversity.5 7 Results Table 2 summarizes the performa</context>
<context position="31761" citStr="Klein and Manning, 2004" startWordPosition="5175" endWordPosition="5178">iginal model (column 6) demonstrates the difficulty inherent in learning the ordering information. This finding is expected given that ordering involves selective sharing from multiple languages. Overall, the performance gap between the selective sharing model and its monolingual supervised counterpart is 7.3%. In contrast, the unsupervised monolingual variant of our model achieves a meager 26%.7 This demonstrates that our model can effectively learn relevant aspects of syntactic structure from a diverse set of languages. 7This performance is comparable to other generative models such as DMV (Klein and Manning, 2004). 8 Conclusions We present a novel algorithm for multilingual dependency parsing that uses annotations from a diverse set of source languages to parse a new unannotated language. Overall, our model consistently outperforms the multi-source transfer based dependency parser of McDonald et al. (2011). Our experiments demonstrate that the model is particularly effective in processing languages that exhibit significant differences from the training languages. Acknowledgments The authors acknowledge the support of the NSF (IIS-0835445), the MURI program (W911NF-10- 1-0533), the DARPA BOLT program, a</context>
</contexts>
<marker>Klein, Manning, 2004</marker>
<rawString>Dan Klein and Christopher Manning. 2004. Corpusbased induction of syntactic structure: Models of dependency and constituency. In Proceedings of ACL, pages 478–485.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonas Kuhn</author>
</authors>
<title>Experiments in parallel-text based grammar induction.</title>
<date>2004</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>470--477</pages>
<contexts>
<context position="5226" citStr="Kuhn, 2004" startWordPosition="777" endWordPosition="778">ge families. On this diverse set, our model consistently outperforms stateof-the-art multilingual dependency parsers. Performance gain, averaged over all the languages, is 5.9% when compared to the highest baseline. Our model achieves the most significant gains on nonIndo-European languages, where we see a 14.4% improvement. We also demonstrate that in the absence of observed typological information, a set of automatically induced latent features can effectively work as a proxy for typology. 2 Related Work Traditionally, parallel corpora have been a mainstay of multilingual parsing (Wu, 1997; Kuhn, 2004; Smith and Smith, 2004; Hwa et al., 2005; Xi and Hwa, 2005; Burkett and Klein, 2008; Snyder et al., 2009). However, recent work in multilingual parsing has demonstrated the feasibility of transfer in the absence of parallel data. As a main source of guidance, these methods rely on the commonalities in dependency structure across languages. For instance, Naseem et al. (2010) explicitly encode these similarities in the form of universal rules which guide grammar induction in the target language. An alternative approach is to directly employ a non-lexicalized parser trained on one language to pr</context>
</contexts>
<marker>Kuhn, 2004</marker>
<rawString>Jonas Kuhn. 2004. Experiments in parallel-text based grammar induction. In Proceedings of the ACL, pages 470–477.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan T McDonald</author>
<author>Slav Petrov</author>
<author>Keith Hall</author>
</authors>
<title>Multi-source transfer of delexicalized dependency parsers.</title>
<date>2011</date>
<booktitle>In EMNLP,</booktitle>
<pages>62--72</pages>
<contexts>
<context position="5896" citStr="McDonald et al., 2011" startWordPosition="887" endWordPosition="890"> Hwa, 2005; Burkett and Klein, 2008; Snyder et al., 2009). However, recent work in multilingual parsing has demonstrated the feasibility of transfer in the absence of parallel data. As a main source of guidance, these methods rely on the commonalities in dependency structure across languages. For instance, Naseem et al. (2010) explicitly encode these similarities in the form of universal rules which guide grammar induction in the target language. An alternative approach is to directly employ a non-lexicalized parser trained on one language to process a target language (Zeman and Resnik, 2008; McDonald et al., 2011; Søgaard, 2011). Since many unlexicalized dependencies are preserved across languages, these approaches are shown to be effective for related languages. For instance, when applied to the language pairs within the Indo-European family, such parsers outperform unsupervised monolingual techniques by a significant margin. The challenge, however, is to enable dependency transfer for target languages that exhibit structural differences from source languages. In such cases, the extent of multilingual transfer is determined by the relation between source and target languages. Berg-Kirkpatrick and Kle</context>
<context position="10111" citStr="McDonald et al., 2011" startWordPosition="1519" endWordPosition="1522">pects. 4 Model We propose a probabilistic model for generating dependency trees that facilitates parameter sharing across languages. We assume a setup where dependency tree annotations are available for a set of source languages and we want to use these annotations to infer a parser for a target language. Syntactic trees for the target language are not available during training. We also assume that both source and target languages are annotated with a coarse parts-of-speech tagset which is shared across languages. Such tagsets are commonly used in multilingual parsing (Zeman and Resnik, 2008; McDonald et al., 2011; Søgaard, 2011; Naseem et al., 2010). The key feature of our model is a two-tier approach that separates the selection of dependents from their ordering: 1. Selection Component: Determines the dependent tags given the parent tag. 2. Ordering Component: Determines the position of each dependent tag with respect to its parent (right or left) and the order within the right and left dependents. This factorization constitutes a departure from traditional parsing models where these decisions are tightly coupled. By separating the two, the model is able to support different degrees of cross-lingual </context>
<context position="22506" citStr="McDonald et al., 2011" startWordPosition="3666" endWordPosition="3669">m. 6 Experimental Setup Datasets and Evaluation We test the effectiveness of our approach on 17 languages: Arabic, Basque, Bulgarian, Catalan, Chinese, Czech, Dutch, English, German, Greek, Hungarian, Italian, Japanese, Portuguese, Spanish, Swedish and Turkish. We used datasets distributed for the 2006 and 2007 CoNLL Shared Tasks (Buchholz and Marsi, 2006; Nivre et al., 2007). Each dataset provides manually annotated dependency trees and POS tags. To enable crosslingual sharing, we map the gold partof-speech tags in each corpus to a common coarse tagset (Zeman and Resnik, 2008; Søgaard, 2011; McDonald et al., 2011; Naseem et al., 2010). The coarse tagset consists of 11 tags: noun, verb, adjective, adverb, pronoun, determiner, adposition, numeral, conjunction, particle, punctuation mark, and X (a catch-all tag). Among several available fineto-coarse mapping schemes, we employ the one of Naseem et al. (2010) that yields consistently better performance for our method and the baselines than the mapping proposed by Petrov et al. (2011). As the evaluation metric, we use directed dependency accuracy. Following standard evaluation practices, we do not evaluate on punctuation. For both the baselines and our mod</context>
<context position="24152" citStr="McDonald et al., 2011" startWordPosition="3924" endWordPosition="3927">sed source languages. We perform ten random restarts and select the best according to this criterion. Likewise, the threshold value b for the PR constraint on the dependency length is tuned on the source languages, using average test set accuracy as the selection criterion. Baselines We compare against the state-of-the-art multilingual dependency parsers that do not use parallel corpora for training. All the systems were eval634 uated using the same fine-to-coarse tagset mapping. The first baseline, Transfer, uses direct transfer of a discriminative parser trained on all the source languages (McDonald et al., 2011). This simple baseline achieves surprisingly good results, within less than 3% difference from a parser trained using parallel data. In the second baseline (Mixture), parameters of the target language are estimated as a weighted mixture of the parameters learned from annotated source languages (Cohen et al., 2011). The underlying parsing model is the dependency model with valance (DMV) (Klein and Manning, 2004). Originally, the baseline methods were evaluated on different sets of languages using a different tag mapping. Therefore, we obtained new results for these methods in our setup. For the</context>
<context position="25469" citStr="McDonald et al., 2011" startWordPosition="4138" endWordPosition="4141"> dataset. For the Mixture baseline, we trained the model on the same four languages used in the original paper — English, German, Czech and Italian. When measuring the performance on these languages, we selected another set of four languages with a similar level of diversity.5 7 Results Table 2 summarizes the performance for different configurations of our model and the baselines. Comparison against Baselines On average, the selective sharing model outperforms both baselines, yielding 8.9% gain over the weighted mixture model (Cohen et al., 2011) and 5.9% gain over the direct transfer method (McDonald et al., 2011). Our model outperforms the weighted mixture model on 15 of the 17 languages and the transfer method on 12 of the 17 languages. Most of the gains are obtained on non-Indo-European languages, that have little similarity with the source languages. For this set, the average gain over the transfer baseline is 14.4%. With some languages, such as Japanese, achieving gains of as much as 30%. On Indo-European languages, the model performance is almost equivalent to that of the best performing baseline. To explain this result we con5We also experimented with a version of the Cohen et al. (2011) model t</context>
<context position="29956" citStr="McDonald et al., 2011" startWordPosition="4900" endWordPosition="4903">.0 51.2 65.4 62.3 65.5 73.5 Greek 56.8 60.4 61.9 67.5 67.3 67.4 60.6 67.2 69.0 70.5 Hungarian 46.8 54.3 56.9 58.4 58.8 58.5 57.0 57.4 62.0 61.6 Japanese 33.5 34.7 62.3 56.8 61.4 64.0 54.8 63.4 69.7 75.6 Turkish 28.3 34.3 59.1 43.6 57.8 59.2 56.9 66.6 59.5 67.6 Average 50.6 53.6 58.6 56.9 58.3 59.5 59.5 61.3 63.7 66.8 Table 2: Directed dependency accuracy of different variants of our selective sharing model and the baselines. The first section of the table (column 1 and 2) shows the accuracy of the weighted mixture baseline (Cohen et al., 2011) (Mixture) and the multi-source transfer baseline (McDonald et al., 2011) (Transfer). The middle section shows the performance of our model in different settings. Df indicates the presence/absence of raw target language data during training. To indicates the use of observed typological features for all languages and Tl indicates the use of latent typological features for all languages. The last section shows results of our model with different levels of oracle supervision: a. (Best Pair) Model parameters are borrowed from the best source language based on the accuracy on the target language b. (Sup. Sel.) Selection component is trained using MLE estimates from targ</context>
</contexts>
<marker>McDonald, Petrov, Hall, 2011</marker>
<rawString>Ryan T. McDonald, Slav Petrov, and Keith Hall. 2011. Multi-source transfer of delexicalized dependency parsers. In EMNLP, pages 62–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tahira Naseem</author>
<author>Harr Chen</author>
<author>Regina Barzilay</author>
<author>Mark Johnson</author>
</authors>
<title>Using universal linguistic knowledge to guide grammar induction.</title>
<date>2010</date>
<booktitle>In EMNLP,</booktitle>
<pages>1234--1244</pages>
<contexts>
<context position="5603" citStr="Naseem et al. (2010)" startWordPosition="839" endWordPosition="842">of observed typological information, a set of automatically induced latent features can effectively work as a proxy for typology. 2 Related Work Traditionally, parallel corpora have been a mainstay of multilingual parsing (Wu, 1997; Kuhn, 2004; Smith and Smith, 2004; Hwa et al., 2005; Xi and Hwa, 2005; Burkett and Klein, 2008; Snyder et al., 2009). However, recent work in multilingual parsing has demonstrated the feasibility of transfer in the absence of parallel data. As a main source of guidance, these methods rely on the commonalities in dependency structure across languages. For instance, Naseem et al. (2010) explicitly encode these similarities in the form of universal rules which guide grammar induction in the target language. An alternative approach is to directly employ a non-lexicalized parser trained on one language to process a target language (Zeman and Resnik, 2008; McDonald et al., 2011; Søgaard, 2011). Since many unlexicalized dependencies are preserved across languages, these approaches are shown to be effective for related languages. For instance, when applied to the language pairs within the Indo-European family, such parsers outperform unsupervised monolingual techniques by a signif</context>
<context position="10148" citStr="Naseem et al., 2010" startWordPosition="1525" endWordPosition="1528">tic model for generating dependency trees that facilitates parameter sharing across languages. We assume a setup where dependency tree annotations are available for a set of source languages and we want to use these annotations to infer a parser for a target language. Syntactic trees for the target language are not available during training. We also assume that both source and target languages are annotated with a coarse parts-of-speech tagset which is shared across languages. Such tagsets are commonly used in multilingual parsing (Zeman and Resnik, 2008; McDonald et al., 2011; Søgaard, 2011; Naseem et al., 2010). The key feature of our model is a two-tier approach that separates the selection of dependents from their ordering: 1. Selection Component: Determines the dependent tags given the parent tag. 2. Ordering Component: Determines the position of each dependent tag with respect to its parent (right or left) and the order within the right and left dependents. This factorization constitutes a departure from traditional parsing models where these decisions are tightly coupled. By separating the two, the model is able to support different degrees of cross-lingual sharing on each level. For the select</context>
<context position="22528" citStr="Naseem et al., 2010" startWordPosition="3670" endWordPosition="3673"> Datasets and Evaluation We test the effectiveness of our approach on 17 languages: Arabic, Basque, Bulgarian, Catalan, Chinese, Czech, Dutch, English, German, Greek, Hungarian, Italian, Japanese, Portuguese, Spanish, Swedish and Turkish. We used datasets distributed for the 2006 and 2007 CoNLL Shared Tasks (Buchholz and Marsi, 2006; Nivre et al., 2007). Each dataset provides manually annotated dependency trees and POS tags. To enable crosslingual sharing, we map the gold partof-speech tags in each corpus to a common coarse tagset (Zeman and Resnik, 2008; Søgaard, 2011; McDonald et al., 2011; Naseem et al., 2010). The coarse tagset consists of 11 tags: noun, verb, adjective, adverb, pronoun, determiner, adposition, numeral, conjunction, particle, punctuation mark, and X (a catch-all tag). Among several available fineto-coarse mapping schemes, we employ the one of Naseem et al. (2010) that yields consistently better performance for our method and the baselines than the mapping proposed by Petrov et al. (2011). As the evaluation metric, we use directed dependency accuracy. Following standard evaluation practices, we do not evaluate on punctuation. For both the baselines and our model we evaluate on all </context>
</contexts>
<marker>Naseem, Chen, Barzilay, Johnson, 2010</marker>
<rawString>Tahira Naseem, Harr Chen, Regina Barzilay, and Mark Johnson. 2010. Using universal linguistic knowledge to guide grammar induction. In EMNLP, pages 1234– 1244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Sandra K¨ubler</author>
<author>Ryan McDonald</author>
<author>Jens Nilsson</author>
<author>Sebastian Riedel</author>
<author>Deniz Yuret</author>
</authors>
<title>The CoNLL</title>
<date>2007</date>
<booktitle>In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL</booktitle>
<pages>915--932</pages>
<marker>Nivre, Hall, K¨ubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan McDonald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret. 2007. The CoNLL 2007 shared task on dependency parsing. In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pages 915–932.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dipanjan Das</author>
<author>Ryan McDonald</author>
</authors>
<title>A universal part-of-speech tagset.</title>
<date>2011</date>
<booktitle>In ArXiv,</booktitle>
<contexts>
<context position="22931" citStr="Petrov et al. (2011)" startWordPosition="3732" endWordPosition="3735">dency trees and POS tags. To enable crosslingual sharing, we map the gold partof-speech tags in each corpus to a common coarse tagset (Zeman and Resnik, 2008; Søgaard, 2011; McDonald et al., 2011; Naseem et al., 2010). The coarse tagset consists of 11 tags: noun, verb, adjective, adverb, pronoun, determiner, adposition, numeral, conjunction, particle, punctuation mark, and X (a catch-all tag). Among several available fineto-coarse mapping schemes, we employ the one of Naseem et al. (2010) that yields consistently better performance for our method and the baselines than the mapping proposed by Petrov et al. (2011). As the evaluation metric, we use directed dependency accuracy. Following standard evaluation practices, we do not evaluate on punctuation. For both the baselines and our model we evaluate on all sentences of length 50 or less ignoring punctuation. Training Regime Our model typically converges quickly and does not require more than 50 iterations of EM. When the model involves latent typological variables, the initialization of these variables can impact the final performance. As a selection criterion for initialization, we consider the performance of the final model averaged over the supervis</context>
</contexts>
<marker>Petrov, Das, McDonald, 2011</marker>
<rawString>Slav Petrov, Dipanjan Das, and Ryan McDonald. 2011. A universal part-of-speech tagset. In ArXiv, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David A Smith</author>
<author>Noah A Smith</author>
</authors>
<title>Bilingual parsing with factored estimation: Using English to parse Korean.</title>
<date>2004</date>
<booktitle>In Proceeding of EMNLP,</booktitle>
<pages>49--56</pages>
<contexts>
<context position="5249" citStr="Smith and Smith, 2004" startWordPosition="779" endWordPosition="782"> On this diverse set, our model consistently outperforms stateof-the-art multilingual dependency parsers. Performance gain, averaged over all the languages, is 5.9% when compared to the highest baseline. Our model achieves the most significant gains on nonIndo-European languages, where we see a 14.4% improvement. We also demonstrate that in the absence of observed typological information, a set of automatically induced latent features can effectively work as a proxy for typology. 2 Related Work Traditionally, parallel corpora have been a mainstay of multilingual parsing (Wu, 1997; Kuhn, 2004; Smith and Smith, 2004; Hwa et al., 2005; Xi and Hwa, 2005; Burkett and Klein, 2008; Snyder et al., 2009). However, recent work in multilingual parsing has demonstrated the feasibility of transfer in the absence of parallel data. As a main source of guidance, these methods rely on the commonalities in dependency structure across languages. For instance, Naseem et al. (2010) explicitly encode these similarities in the form of universal rules which guide grammar induction in the target language. An alternative approach is to directly employ a non-lexicalized parser trained on one language to process a target language</context>
</contexts>
<marker>Smith, Smith, 2004</marker>
<rawString>David A. Smith and Noah A. Smith. 2004. Bilingual parsing with factored estimation: Using English to parse Korean. In Proceeding of EMNLP, pages 49– 56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Snyder</author>
<author>Tahira Naseem</author>
<author>Regina Barzilay</author>
</authors>
<title>Unsupervised multilingual grammar induction.</title>
<date>2009</date>
<booktitle>In Proceedings ofACL/AFNLP,</booktitle>
<pages>73--81</pages>
<contexts>
<context position="5332" citStr="Snyder et al., 2009" startWordPosition="795" endWordPosition="798">l dependency parsers. Performance gain, averaged over all the languages, is 5.9% when compared to the highest baseline. Our model achieves the most significant gains on nonIndo-European languages, where we see a 14.4% improvement. We also demonstrate that in the absence of observed typological information, a set of automatically induced latent features can effectively work as a proxy for typology. 2 Related Work Traditionally, parallel corpora have been a mainstay of multilingual parsing (Wu, 1997; Kuhn, 2004; Smith and Smith, 2004; Hwa et al., 2005; Xi and Hwa, 2005; Burkett and Klein, 2008; Snyder et al., 2009). However, recent work in multilingual parsing has demonstrated the feasibility of transfer in the absence of parallel data. As a main source of guidance, these methods rely on the commonalities in dependency structure across languages. For instance, Naseem et al. (2010) explicitly encode these similarities in the form of universal rules which guide grammar induction in the target language. An alternative approach is to directly employ a non-lexicalized parser trained on one language to process a target language (Zeman and Resnik, 2008; McDonald et al., 2011; Søgaard, 2011). Since many unlexic</context>
</contexts>
<marker>Snyder, Naseem, Barzilay, 2009</marker>
<rawString>Benjamin Snyder, Tahira Naseem, and Regina Barzilay. 2009. Unsupervised multilingual grammar induction. In Proceedings ofACL/AFNLP, pages 73–81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Søgaard</author>
</authors>
<title>Data point selection for crosslanguage adaptation of dependency parsers.</title>
<date>2011</date>
<booktitle>In ACL (Short Papers),</booktitle>
<pages>682--686</pages>
<contexts>
<context position="5912" citStr="Søgaard, 2011" startWordPosition="891" endWordPosition="892"> Klein, 2008; Snyder et al., 2009). However, recent work in multilingual parsing has demonstrated the feasibility of transfer in the absence of parallel data. As a main source of guidance, these methods rely on the commonalities in dependency structure across languages. For instance, Naseem et al. (2010) explicitly encode these similarities in the form of universal rules which guide grammar induction in the target language. An alternative approach is to directly employ a non-lexicalized parser trained on one language to process a target language (Zeman and Resnik, 2008; McDonald et al., 2011; Søgaard, 2011). Since many unlexicalized dependencies are preserved across languages, these approaches are shown to be effective for related languages. For instance, when applied to the language pairs within the Indo-European family, such parsers outperform unsupervised monolingual techniques by a significant margin. The challenge, however, is to enable dependency transfer for target languages that exhibit structural differences from source languages. In such cases, the extent of multilingual transfer is determined by the relation between source and target languages. Berg-Kirkpatrick and Klein (2010) define</context>
<context position="10126" citStr="Søgaard, 2011" startWordPosition="1523" endWordPosition="1524">se a probabilistic model for generating dependency trees that facilitates parameter sharing across languages. We assume a setup where dependency tree annotations are available for a set of source languages and we want to use these annotations to infer a parser for a target language. Syntactic trees for the target language are not available during training. We also assume that both source and target languages are annotated with a coarse parts-of-speech tagset which is shared across languages. Such tagsets are commonly used in multilingual parsing (Zeman and Resnik, 2008; McDonald et al., 2011; Søgaard, 2011; Naseem et al., 2010). The key feature of our model is a two-tier approach that separates the selection of dependents from their ordering: 1. Selection Component: Determines the dependent tags given the parent tag. 2. Ordering Component: Determines the position of each dependent tag with respect to its parent (right or left) and the order within the right and left dependents. This factorization constitutes a departure from traditional parsing models where these decisions are tightly coupled. By separating the two, the model is able to support different degrees of cross-lingual sharing on each</context>
<context position="22483" citStr="Søgaard, 2011" startWordPosition="3664" endWordPosition="3665">he CKY algorithm. 6 Experimental Setup Datasets and Evaluation We test the effectiveness of our approach on 17 languages: Arabic, Basque, Bulgarian, Catalan, Chinese, Czech, Dutch, English, German, Greek, Hungarian, Italian, Japanese, Portuguese, Spanish, Swedish and Turkish. We used datasets distributed for the 2006 and 2007 CoNLL Shared Tasks (Buchholz and Marsi, 2006; Nivre et al., 2007). Each dataset provides manually annotated dependency trees and POS tags. To enable crosslingual sharing, we map the gold partof-speech tags in each corpus to a common coarse tagset (Zeman and Resnik, 2008; Søgaard, 2011; McDonald et al., 2011; Naseem et al., 2010). The coarse tagset consists of 11 tags: noun, verb, adjective, adverb, pronoun, determiner, adposition, numeral, conjunction, particle, punctuation mark, and X (a catch-all tag). Among several available fineto-coarse mapping schemes, we employ the one of Naseem et al. (2010) that yields consistently better performance for our method and the baselines than the mapping proposed by Petrov et al. (2011). As the evaluation metric, we use directed dependency accuracy. Following standard evaluation practices, we do not evaluate on punctuation. For both th</context>
</contexts>
<marker>Søgaard, 2011</marker>
<rawString>Anders Søgaard. 2011. Data point selection for crosslanguage adaptation of dependency parsers. In ACL (Short Papers), pages 682–686.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>3</issue>
<contexts>
<context position="5214" citStr="Wu, 1997" startWordPosition="775" endWordPosition="776"> 10 language families. On this diverse set, our model consistently outperforms stateof-the-art multilingual dependency parsers. Performance gain, averaged over all the languages, is 5.9% when compared to the highest baseline. Our model achieves the most significant gains on nonIndo-European languages, where we see a 14.4% improvement. We also demonstrate that in the absence of observed typological information, a set of automatically induced latent features can effectively work as a proxy for typology. 2 Related Work Traditionally, parallel corpora have been a mainstay of multilingual parsing (Wu, 1997; Kuhn, 2004; Smith and Smith, 2004; Hwa et al., 2005; Xi and Hwa, 2005; Burkett and Klein, 2008; Snyder et al., 2009). However, recent work in multilingual parsing has demonstrated the feasibility of transfer in the absence of parallel data. As a main source of guidance, these methods rely on the commonalities in dependency structure across languages. For instance, Naseem et al. (2010) explicitly encode these similarities in the form of universal rules which guide grammar induction in the target language. An alternative approach is to directly employ a non-lexicalized parser trained on one la</context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>Dekai Wu. 1997. Stochastic inversion transduction grammars and bilingual parsing of parallel corpora. Computational Linguistics, 23(3):377–403.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chenhai Xi</author>
<author>Rebecca Hwa</author>
</authors>
<title>A backoff model for bootstrapping resources for non-english languages.</title>
<date>2005</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>851--858</pages>
<contexts>
<context position="5285" citStr="Xi and Hwa, 2005" startWordPosition="787" endWordPosition="790">tly outperforms stateof-the-art multilingual dependency parsers. Performance gain, averaged over all the languages, is 5.9% when compared to the highest baseline. Our model achieves the most significant gains on nonIndo-European languages, where we see a 14.4% improvement. We also demonstrate that in the absence of observed typological information, a set of automatically induced latent features can effectively work as a proxy for typology. 2 Related Work Traditionally, parallel corpora have been a mainstay of multilingual parsing (Wu, 1997; Kuhn, 2004; Smith and Smith, 2004; Hwa et al., 2005; Xi and Hwa, 2005; Burkett and Klein, 2008; Snyder et al., 2009). However, recent work in multilingual parsing has demonstrated the feasibility of transfer in the absence of parallel data. As a main source of guidance, these methods rely on the commonalities in dependency structure across languages. For instance, Naseem et al. (2010) explicitly encode these similarities in the form of universal rules which guide grammar induction in the target language. An alternative approach is to directly employ a non-lexicalized parser trained on one language to process a target language (Zeman and Resnik, 2008; McDonald e</context>
</contexts>
<marker>Xi, Hwa, 2005</marker>
<rawString>Chenhai Xi and Rebecca Hwa. 2005. A backoff model for bootstrapping resources for non-english languages. In Proceedings of EMNLP, pages 851 – 858.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Zeman</author>
<author>Philip Resnik</author>
</authors>
<title>Cross-language parser adaptation between related languages.</title>
<date>2008</date>
<booktitle>In Proceedings of the IJCNLP-08 Workshop on NLP for Less Privileged Languages,</booktitle>
<pages>35--42</pages>
<contexts>
<context position="5873" citStr="Zeman and Resnik, 2008" startWordPosition="883" endWordPosition="886">Hwa et al., 2005; Xi and Hwa, 2005; Burkett and Klein, 2008; Snyder et al., 2009). However, recent work in multilingual parsing has demonstrated the feasibility of transfer in the absence of parallel data. As a main source of guidance, these methods rely on the commonalities in dependency structure across languages. For instance, Naseem et al. (2010) explicitly encode these similarities in the form of universal rules which guide grammar induction in the target language. An alternative approach is to directly employ a non-lexicalized parser trained on one language to process a target language (Zeman and Resnik, 2008; McDonald et al., 2011; Søgaard, 2011). Since many unlexicalized dependencies are preserved across languages, these approaches are shown to be effective for related languages. For instance, when applied to the language pairs within the Indo-European family, such parsers outperform unsupervised monolingual techniques by a significant margin. The challenge, however, is to enable dependency transfer for target languages that exhibit structural differences from source languages. In such cases, the extent of multilingual transfer is determined by the relation between source and target languages. B</context>
<context position="10088" citStr="Zeman and Resnik, 2008" startWordPosition="1515" endWordPosition="1518">tion about its unique aspects. 4 Model We propose a probabilistic model for generating dependency trees that facilitates parameter sharing across languages. We assume a setup where dependency tree annotations are available for a set of source languages and we want to use these annotations to infer a parser for a target language. Syntactic trees for the target language are not available during training. We also assume that both source and target languages are annotated with a coarse parts-of-speech tagset which is shared across languages. Such tagsets are commonly used in multilingual parsing (Zeman and Resnik, 2008; McDonald et al., 2011; Søgaard, 2011; Naseem et al., 2010). The key feature of our model is a two-tier approach that separates the selection of dependents from their ordering: 1. Selection Component: Determines the dependent tags given the parent tag. 2. Ordering Component: Determines the position of each dependent tag with respect to its parent (right or left) and the order within the right and left dependents. This factorization constitutes a departure from traditional parsing models where these decisions are tightly coupled. By separating the two, the model is able to support different de</context>
<context position="22468" citStr="Zeman and Resnik, 2008" startWordPosition="3660" endWordPosition="3663">one using a variant of the CKY algorithm. 6 Experimental Setup Datasets and Evaluation We test the effectiveness of our approach on 17 languages: Arabic, Basque, Bulgarian, Catalan, Chinese, Czech, Dutch, English, German, Greek, Hungarian, Italian, Japanese, Portuguese, Spanish, Swedish and Turkish. We used datasets distributed for the 2006 and 2007 CoNLL Shared Tasks (Buchholz and Marsi, 2006; Nivre et al., 2007). Each dataset provides manually annotated dependency trees and POS tags. To enable crosslingual sharing, we map the gold partof-speech tags in each corpus to a common coarse tagset (Zeman and Resnik, 2008; Søgaard, 2011; McDonald et al., 2011; Naseem et al., 2010). The coarse tagset consists of 11 tags: noun, verb, adjective, adverb, pronoun, determiner, adposition, numeral, conjunction, particle, punctuation mark, and X (a catch-all tag). Among several available fineto-coarse mapping schemes, we employ the one of Naseem et al. (2010) that yields consistently better performance for our method and the baselines than the mapping proposed by Petrov et al. (2011). As the evaluation metric, we use directed dependency accuracy. Following standard evaluation practices, we do not evaluate on punctuati</context>
</contexts>
<marker>Zeman, Resnik, 2008</marker>
<rawString>Daniel Zeman and Philip Resnik. 2008. Cross-language parser adaptation between related languages. In Proceedings of the IJCNLP-08 Workshop on NLP for Less Privileged Languages, pages 35–42, January.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>