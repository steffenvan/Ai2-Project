<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000163">
<title confidence="0.9882415">
The Tao of CHI:
Towards Effective Human-Computer Interaction
</title>
<author confidence="0.93058">
Robert Porzel Manja Baudis
</author>
<affiliation confidence="0.89705">
European Media Laboratory, GmbH
</affiliation>
<address confidence="0.8649595">
Schloss-Wolfsbrtnnenweg 33
D-69118 Heidelberg, Germany
</address>
<email confidence="0.875757">
robert.porzel,manja.baudis@eml-d.villa-bosch.de
</email>
<sectionHeader confidence="0.989502" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999542571428571">
End-to-end evaluations of conversational dia-
logue systems with naive users are currently
uncovering severe usability problems that re-
sult in low task completion rates. Preliminary
analyses suggest that these problems are related
to the system’s dialogue management and turn-
taking behavior. We present the results of ex-
periments designed to take a detailed look at
the effects of that behavior. Based on the result-
ing findings, we spell out a set of criteria which
lie orthogonal to dialogue quality, but neverthe-
less constitute an integral part of a more com-
prehensive view on dialogue felicity as a func-
tion of dialogue quality and efficiency.
</bodyText>
<sectionHeader confidence="0.998984" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999898984126985">
Research on dialogue systems in the past has fo-
cused on engineering the various processing stages
involved in dialogical human-computer interaction
(HCI) - e.g., robust automatic speech recognition,
intention recognition, natural language genera-
tion or speech synthesis (cf. Allen et al. (1996),
Cox et al. (2000) or Bailly et al. (2003)). Alongside
these efforts the characteristics of computer-directed
language have also been examined as a general phe-
nomenon (cf. Zoeppritz (1985), Wooffitt et al. (1997)
or Darves and Oviatt (2002)). The flip side, i. e.,
computer-human interaction (CHI), has received very
little attention as a research question by itself. That is
not to say that natural language generation and synthesis
have not made vast improvements, but rather that the
nature and design of the computer as an interlocutor
itself, i. e., the effects of human-directed language, have
not been scrutinized as such.
Looking at broad levels of distinctions for dialogue
systems, e.g., that of Allen et al. (2001) between con-
trolled and conversational dialogue systems, we note the
singular employment of human-based differentiae, i. e.,
the degree of the restriction of the human interactions.
Differentiae stemming from the other communication
partner, i. e., the computer, are not taken into account -
neither on a practical nor on a theoretical level.
In the past controlled and restricted interactions be-
tween the user and the system increased recognition and
understanding accuracies to a level that systems became
reliable enough for deployment in various real world
applications, e. g., transportation or cinema information
systems (Aust et al., 1995; Gorin et al., 1997; Gall-
witz et al., 1998). Today’s more conversational dia-
logue systems, e. g., SMARTKOM (Wahlster et al., 2001)
or MATCH (Johnston et al., 2002), are able to cope
with much less predictable user utterances. Despite the
fact that in these systems recognition and processing
have become extremely difficult, the reliability thereof
has been pushed towards acceptable degrees by employ-
ing an array of highly sophisticated technological ad-
vances - such as dynamic lexica for multi-domain speech
recognition and flexible pronunciation models (Rapp et
al., 2000), robust understanding and discourse modeling
techniques (Johnston, 1998; Engel, 2002; Alexandersson
and Becker, 2001) combined with ontological reasoning
capabilities (Gurevych et al., 2003; Porzel et al., 2003).
However, the usability of such conversational dia-
logue systems is still unsatisfactory, as shown in usabil-
ity experiments with real users (Beringer, 2003) that em-
ployed the PROMISE evaluation framework described
in Beringer et al. (2002), which offers some multimodal
extentions over the PARADISE framework described in
Walker et al. (2000) . The work described herein consti-
tutes a starting point for a scientific examination of the
whys and wherefores of the challenging results stemming
from such end-to-end evaluations of conversational dia-
logue systems. Following a brief description of the state
of the art in examinations of computer-directed language,
we describe a new experimental paradigm, the first two
studies using the paradigm and their corresponding re-
sults. Concluding, we discuss the ensuing implications
for the design of successful and felicitous conversational
dialogue systems.
</bodyText>
<sectionHeader confidence="0.466159" genericHeader="method">
2 Studies on Human-Computer Dialogues
</sectionHeader>
<bodyText confidence="0.997434388888889">
The first studies and descriptions of the particulari-
ties of dialogical human-computer interaction, then la-
beled as computer talk in analogy to baby talk by
Zoeppritz (1985), focused - much like subsequent ones
- on:
proving that a regular register for humans con-
versing with dialogue system exists, e. g., those of
Krause (1992) and Fraser (1993),
describing the regularities and characteristics
of that register, as in Kritzenberger (1992) or
Darves and Oviatt (2002).
The results of these studies clearly show that such a regis-
ter exists and that its regularities can be replicated and ob-
served again and again. In general, this work focuses on
the question: what changes happen to human verbal be-
havior when they talk to computers as opposed to fellow
humans? The questions which are not explicitely asked
or studied are:
how does the computer’s way of communicating af-
fect the human interlocutor,
do the particulars of computer-human interaction
help to explain why today’s conversational dialogue
systems are by and large unusable.
In this paper we claim that this shift of perspective is
of paramount importance, for example, to make sense
of the phenomena observable during end-to-end evalu-
ations of conversational systems. We designed our ex-
periments and started our initial observations using one
of the most advanced conversational dialogue research
prototypes existing today, i. e., the SMARTKOM system
(Wahlster et al., 2001). This system designed for intu-
itive multimodal interaction comprises a symmetric set
of input and output modalities (Wahlster, 2003), together
with an efficient fusion and fission pipeline (Wahlster,
2002). SMARTKOM features speech input with prosodic
analysis, gesture input via infrared camera, recognition
of facial expressions and their emotional states. On the
output side SMARTKOM employs a gesturing and speak-
ing life-like character together with displayed generated
text and multimedia graphical output. It currently com-
prised nearly 50 modules running on a parallel virtual
machine-based integration software called MULTIPLAT-
FORM (Herzog et al., 2003). As such it is certainly
among the most advanced multi-domain conversational
dialogue systems.
To the best of our knowledge, there has not been
a single publication reporting a successful end-to-end
evaluation of a conversational dialogue system with
naive users. We claim that, given the state of the
art of the dialogue management of today’s conversa-
tional dialogue systems, evaluation trials with naive users
will continue to uncover severe usability problems re-
sulting in low task completion rates.&apos; Surprisingly,
this occurs despite acceptable partial evaluation results.
By partial results, we understand evaluations of indi-
vidual components such as concerning the word-error
rate of automatic speech recognition or understanding
rates as conducted by Cox et al. (2000) or reported in
Diaz-Verdejo et al. (2000). As one of the reasons for
the problems thwarting task completion, Beringer (2003)
points at the problem of turn overtaking, which occurs
when users rephrase questions or make a second remark
to the system, while it is still processing the first one. Af-
ter such occurrences a dialogue becomes asynchronous,
meaning that the system responds to the second last user
utterance while in the user’s mind that response concerns
the last. Given the current state of the art regarding the
dialogue handling capabilities of HCI systems, this in-
evitably causes dialogues to fail completely.
We can already conclude from these informal findings
that current state of the art conversational dialogue sys-
tems suffer from
</bodyText>
<listItem confidence="0.63759425">
a) a lack of turn-taking strategies and dialogue han-
dling capabilities as well as
b) a lack of strategies for repairing dialogues once they
become out ofsync.
</listItem>
<bodyText confidence="0.998940567567567">
In human-human interaction (HHI) turn-taking
strategies and their effects have been studied for
decades in unimodal settings from Duncan (1974) and
Sack et al. (1974) to Weinhammer and Rabold (2003)
as well as more recently in multimodal settings as in
Sweetser (2003). Virtually no work exists concerning
the turn-taking strategies that dialogue systems should
pursue and how they effect human-computer interaction,
except in special cases such as in Woodburn et al. (1991)
for the case of conversational computer-mediated com-
munication aids for the speech and hearing impaired or
Shankar et al. (2000) for turn negotiation in text-based
dialogue systems. The overview of classical HCI exper-
iments and their results, given in Wooffitt et al. (1997),
also shows that problems, such as turn-overtaking,
-handling and -repairs , have not been addressed by the
research community.
In the following section we describe a new experimen-
tal paradigm and the first corresponding experiments tai-
lored towards examining the effects of the computer’s
communicative behavior on its human partner. More
specifically, we will analyze the differences in HHI and
&apos;These problems can be diminished, however, ifpeople have
multiple sessions with the system and adapt to the respective
system’s behavior.
HCI/CHI turn-taking and dialogue management strate-
gies, which, in the light of the recent end-to-end eval-
uation results described above, constitutes a promising
starting point for an examination of the effects of the
computer’s communicative behavior. The overall goal of
analyzing these effects is, that future systems become us-
able by exhibiting a more felicitous communicative be-
havior. After reporting on the results of the experiments
in Section 4, we highlight a set of hypotheses that can be
drawn from them and point towards future experiments
that need to be conducted to verify these hypotheses in
Section 6.
</bodyText>
<sectionHeader confidence="0.999197" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.999936702702702">
For conducting the experiments we developed a new
paradigm for collecting telephone-based dialogue data,
called Wizard and Operator Test (WOT), which con-
tains elements of both Wizard-of-Oz (WoZ) experiments
(Francony et al., 1992) as well as Hidden Operator Tests
(Rapp and Strube, 2002). This procedure also represents
a simplification of classical end-to-end experiments, as it
is - much like WoZ experiments - conductible without the
technically very complex use of a real conversational sys-
tem. As post-experimental interviews showed, this did
not limit the feeling of authenticity regarding the simu-
lated conversational system by the human subjects ( ).
The WOT setup consists of two major phases that begin
after subjects have been given a set of tasks to be solved
with the telephone-based dialogue system:
in Phase 1 the human assistant ( ) is acting as a
wizard who is simulating the dialogue system, much
like in WoZ experiments, by operating a speech syn-
thesis interface,
in Phase 2, which starts immediately after a sys-
tem breakdown has been simulated by means of
beeping noises transmitted via the telephone, the hu-
man assistant is acting as a human operator asking
the subject to continue with the tasks.
This setup enables to control for various factors. Most
importantly the technical performance (e. g., latency
times), the pragmatic performance (e. g., understanding
vs. non-understanding of the user utterances) and the
communicative behavior of the simulated systems can be
adjusted to resemble that of state of the art dialogue sys-
tems. These factors can, of course, also be adjusted to
simulate potential future capabilites of dialogue systems
and test their effects. The main point of the experimental
setup, however, is to enable precise analyses of the dif-
ferences in the communicative behaviors of the various
interlocutors, i. e., human-human, human-computer and
computer-human interaction.
</bodyText>
<subsectionHeader confidence="0.999115">
3.1 Technical Setup
</subsectionHeader>
<bodyText confidence="0.999758869565218">
During the experiment and were in separate rooms.
Communication between both was conducted via tele-
phone, i. e., for the user only a telephone was visible
next to a radio microphone for the recording of the sub-
ject’s linguistic expressions. As shown in Figure 1 the
assistant/operator room featured a telephone as well as
two computers - one for the speech synthesis interface
and one for collecting all audio streams; also present
were loudspeakers for feeding the speech synthesis out-
put into the telephone and a microphone for the record-
ing of the synthesis and operator output. With the help
of an audio mixer all linguistic data were recorded time
synchronously and stored in one audio file. The assis-
tant/operator acting as the computer system communi-
cated by selecting fitting answers for the subject’s re-
quest from a prefabricated list covering the scope of the
SMAxTKOM repertoire of answers, which - despite the
more conversational nature of the system, still does not
include any kind of dialogue structuring or feedback par-
ticles. These responses were returned via speech synthe-
sis through the telephone. Beyond that it was possible for
the wizard to communicate over telephone directly with
the subjects when acting as the human operator.
</bodyText>
<figureCaption confidence="0.80562">
Figure 1: Communication in Phase 1 goes from syn-
</figureCaption>
<bodyText confidence="0.698661333333333">
thesized speech out of the loudspeakers into the opera-
tor room (left) phone to the subject room (right) and in
Phase 2 directly via the phone between the humans.
</bodyText>
<subsectionHeader confidence="0.999338">
3.2 The Experiments
</subsectionHeader>
<bodyText confidence="0.999107125">
The experiments were conducted with an English setup,
subjects and assistants in the United States of America
and with a German setup, subjects and assistants in Ger-
many. Both experiments were otherwise identical and in
each 22 sessions were recorded. At the beginning of the
WOT, the test manager told the subjects that they were
testing a novel telephone-based dialogue system that sup-
plies touristic information on the city of Heidelberg. In
order to avoid the usual paraphrases of tasks worded too
specifically, the manager gave the subjects an overall list
of 20 very general touristic activities, such as visit mu-
seum or eat out, from which each subject had to pick
six tasks which had to be solved in the experiment. The
manager then removed the original list, dialed the sys-
tem’s number on the phone and exited from the room
after handing over the telephone receiver. The subject
was always greeted by the system’s standard opening ply:
Welcome to the Heidelberger tourist information system.
How I can help you? After three tasks were finished
(some successful some not) the assistant simulated the
system’s break down and entered the line by saying Ex-
cuse me, something seems to have happened with our sys-
tem, may I assist you from here on and finishing the re-
maining three tasks with the subjects.
</bodyText>
<sectionHeader confidence="0.999969" genericHeader="method">
4 Results
</sectionHeader>
<bodyText confidence="0.991366939393939">
The PARADISE framework (Walker et al., 1997; Walker
et al., 2000) proposes distinct measurements for dia-
logue quality, dialogue efficiency and task success met-
rics. The remaining criterion, i. e., user satisfaction, is
based on questionaries and interviews with the subjects
and cannot be extracted (sub)automatically from log-
files. The analyses of the experiments described herein
focus mainly on dialogue efficency metrics in the sense
of Walker et al. (2000). As we will show below, our find-
ings strongly suggest that a felicitous dialogue is not only
a function of dialogue quality, but critically hinges on
a minimal threshold of efficiency and overall dialogue
management as well. While these criteria lie orthogo-
nal to the Walker et al. (2000) criteria for measuring di-
alogue quality such as recognition rates and the like, we
regard them to constitute an integral part of an aggregate
view on dialogue quality and efficiency, herein referred to
as dialogue felicity. For examining dialogue felicity we
will provide detailed analyses of efficiency metrics per
se as well as additional metrics for examining the num-
ber and effect of pauses, the employment of feedback and
turn-taking signals and the amount of overlaps.
The Data: The length of the dialogues was on aver-
age 5 minutes for the German (G) and 6 minutes for
the English (E) sessions. The subjects featured approx-
imately proportional mixtures of gender (25m,18f), age
(12 71) and computer expertise. Table 1 shows the
duration and turns per phase of the experiment.
Measurements: First of all, we apply the classic
Walker et al. (2000) metric for measuring dialogue effi-
ciency, by calculating the number of turns over dialogue
length. Figure 2 shows the discrepancy between the di-
alogue efficiency in Phase 1 (HCI) versus Phase 2
</bodyText>
<footnote confidence="0.726658">
2The shortest dialogues were 3:18 (E) and 3:30 (G) and the
longest 12:05 (E) and 10:08 (G).
</footnote>
<bodyText confidence="0.668405">
(HHI) of the German experiment and Figure 3 shows that
the same patterns can be observed for English.
</bodyText>
<table confidence="0.99925475">
Phase HHI G HHI E HCI G HCI E
Average 1:52 2:30 2:59 3:23
length min. min. min. min.
Average turns 11.35 21.25 9.2 7.4
</table>
<tableCaption confidence="0.999719">
Table 1: Average length and turns in Phase 1 and 2
</tableCaption>
<figureCaption confidence="0.999977">
Figure 2: Dialogue efficiency (German data)
Figure 3: Dialogue efficiency (English data)
</figureCaption>
<bodyText confidence="0.999968227272727">
As this discrepancy might be accountable by latency
times alone, we calculated the same metric with and with-
out pauses. For these analyses pauses are very conser-
vatively defined as silences during the conversation that
exceeded one second. The German results are shown in
Figure 4 and, as shown in Figure 5 we find the same pat-
terns hold cross-linguistically in the English experiments.
The overall comparison, given in Table 2, shows that - as
one would expect - latency times severely decrease dia-
logue efficiency, but that they alone do not account for
the difference in efficiency between human-human and
human-computer interaction. This means that even if la-
tency times were to vanish completely, yielding actual
real-time performance, we would still observe less effi-
cient dialogues in HCI.
While it is obvious that the existing latency times in-
crease the number and length of pauses of the computer
interactions as compared to the human operator’s interac-
tions, there are no such obvious reasons why the number
and length of pauses in the human subjects’ interactions
should differ in Phase 1 and Phase 2. However, as
shown in Table 3, they do differ substantially.
</bodyText>
<figureCaption confidence="0.99996">
Figure 4: Efficiency w/out latency in German
Figure 5: Efficiency w/out latency in English
</figureCaption>
<table confidence="0.998853666666667">
Efficiency HCI -p HCI +p HHI -p HHI +p
Mean 0.18 0.05 0.25 0.12
German
Standard- 0.04 0.01 0.06 0.03
deviation
Mean 0.16 0.05 0.17 0.17
English
Standard- 0.25 0.02 0.07 0.07
deviation
</table>
<tableCaption confidence="0.97128">
Table 2: Overall dialogue efficiencies with pauses +p and
without pauses -p.
</tableCaption>
<bodyText confidence="0.999541944444445">
Next to this pause-effect, which contributes greatly to
dialogue efficiency metrics by increasing dialogue length,
we have to take a closer look at the individual turns
and their nature. While some turns carry propositional
information and constitute utterances proper, a signif-
icant number solely consists of specific particles used
to exchange signals between the communicative part-
ners or combinations thereof. We differentiate between
dialogue-structuring signals and feedback signals in the
sense of Yngve (1970). Dialogue-structuring signals -
such as hesitations like hmm or ah as well as expressions
like well, yes, so - mark the intent to begin or end an utter-
ances, make corrections or insertions. Feedback signals-
while sometimes phonetically alike - such as right, yes or
hmm - do not express the intent to take over or give up the
speaking role, but rather serve as a means to stay in con-
tact with the speaker, which is why they are sometimes
referred to as contact signals.
</bodyText>
<table confidence="0.999493538461538">
Pauses HCI-G HHI-G HCI-E HHI-E
Number 79 10 94 21
total
Number 3.95 0.5 4.7 1.05
per dialog
Number 0.46 0.05 0.64 0.05
per turn
total 336sec 19sec 467sec 48sec
length
of 9.37 0.84 13.74 1.75
phase
of 5.75 0.3 7.46 0.766
dialogue
</table>
<tableCaption confidence="0.999778">
Table 3: Overall pauses of human subjects:
</tableCaption>
<bodyText confidence="0.974796130434783">
Phase 1 and 2 German (HCI-G/HHI-G) and En-
glish (HCI-G/HCI-E)
In order to be able to differentiate between the two,
for example, between an agreeing feedback yes and a
dialogue-structuring one, all dialogues were annotated
manually. Half of the data were annotated by sepa-
rate annotators, yielding an inter-annotator agreement of
90.61 . The resulting counts for the user utterances in
phase one and two are shown in Table 4. Not shown
in Table 4 are the number of particles employed by the
computer, since it is zero, and of the human operator in
the HHI dialogues, as they are like those of his human
interlocutor.
Again, the findings for both German and English are
comparable. We find that feedback particles almost van-
ish from the human-computer dialogues - a finding that
corresponds to those described in Section 2. This lin-
guistic behavior, in turn, constitutes an adaptation to the
employment of such particles by that of the respective in-
terlocutor. Striking, however, is that the human subjects
still attempted to send dialogue structuring signals to the
computer, which - unfortunately - would have been ig-
nored by today’s “conversational” dialogue systems.3
</bodyText>
<table confidence="0.99936925">
Particles structure particle feedback particle
HCI HHI HCI HHI
Number 112 G 225 G 18 G 135 G
total 90 E 202 E 0 E 43 E
per 5.6 G 11.25 G 0.9 G 6.75 G
dialogue 4.5 E 10.1 E 0 E 2.15 E
per 0.4 G 0.59 G 0.04 G 0.26 G
turn 0.61 E 0.48 E 0 E 0.1 E
</table>
<tableCaption confidence="0.999704">
Table 4: Particles of human subjects: HCI vs. HHI
</tableCaption>
<bodyText confidence="0.999477538461538">
Before turning towards an analysis of this data we will
examine the overlaps that occurred throughout the dia-
logues. Most overlaps in human-human conversation oc-
cur during turn changes with the remainder being feed-
back signals that are uttered during the other interlocu-
tor’s turn (Jefferson, 1983). The results on measuring the
amount of overlap in our experiments are given in Ta-
ble 5. Overall the HHI dialogues featured significantly
more overlap than the HCI ones, which is partly due to
the respective presence and absence of feedback signals
as well as due to the fact that in HCI turn takes are accom-
panied by pauses rather than immediate - overlapping -
hand overs.
</bodyText>
<table confidence="0.99050225">
Overlaps HCI-G HHI-G HCI-E HHI-E
Number total 7 49 4 88
per dialogue 0.35 3.06 0.2 4.4
per turn 0.03 0.18 0.01 0.1
</table>
<tableCaption confidence="0.999737">
Table 5: Overlaps in Phase 1 versus Phase 2
</tableCaption>
<bodyText confidence="0.9999154">
Lastly, our experiments yielded negative findings con-
cerning differences in the type-token ratio (denoting the
lexical variation of forms), speech production errors
(false starts, repetitions etc.) and syntax. This means that
there was no statistically significant difference in the lin-
guistic behavior with respect to these factors. We regard
this finding to strengthen our conclusions (see Section 6),
that to emulate human syntactic and semantic behavior
does not suffice to guarantee effective and therefore fe-
licitous human computer interaction.
</bodyText>
<sectionHeader confidence="0.8455555" genericHeader="method">
5 An Analysis of Ineffective Computer-
Human Interaction
</sectionHeader>
<bodyText confidence="0.9953025">
The results presented above enable a closer look at di-
alogue efficiency as one of the key factors influencing
overall dialogue felicity. As our experiments show, the
difference between the human-human efficiency and that
</bodyText>
<footnote confidence="0.7866395">
3In the English data the subject’s employment of dialogue
structuring particles in HCI even slightly surpassed that of HHI.
</footnote>
<bodyText confidence="0.9999829">
of the human-computer dialogues is not solely due to the
computer’s response times. There is a significant amount
of white noise, for example, as users wait after the com-
puter has finished responding. We see these behaviors as
a result of a mismanaged dialogue. In many cases users
are simple unsure whether the system’s turn has ended or
not and consequently wait much longer than necessary.
The situation is equally bad at the other end of the turn
taking spectrum, i. e., after a user has handed over the turn
to the computer, there is no signal or acknowledgment
that the computer has taken on the baton and is running
along with it - regardless of whether the user’s utterance is
understood or not. Insecurities regarding the main ques-
tion, i. e., whose turn is it anyways, become very notable
when users try to establish contact, e. g., by saying hello
-pause- hello. This kind of behavior certainly does not
happen in HHI, even when we find long silences.
Examining why silences in human-human interaction
are unproblematic, we find that, these silences have been
announced, e. g., by the human operator employing lin-
guistic signals, such as just a moment please or well, I’ll
have to have a look in our database in order to commu-
nicate that he is holding on to the turn and finishing his
round.
To push the relay analogy even further, we can look at
the differences in overlap as another indication of crucial
dialogue inefficiency. Since most overlaps occur at the
turn boundaries and, thusly, ensure a smooth (and fast)
hand over, their absence constitutes another indication
why we are far from having winning systems.
</bodyText>
<sectionHeader confidence="0.983915" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999990611111111">
As the primary effects of the human-directed language
exhibited by today’s conversational dialogue systems, our
experiments show that the human interlocutor:
ceases in the production of feedback signals, which
has been observed before,
still attempts to use his or her turn signals for mark-
ing turn boundaries - which, however, remain ig-
nored by the system - and
increases the amount of pauses, caused by waiting
and uncertainty effects, which also is manifested by
missing overlaps at turn boundaries.
Generally, we can conclude that a felicitous dialogue
needs some amount of extra-propositional exchange be-
tween the interlocutors. The complete absence of such
dialogue controlling mechanisms - by the non-human in-
terlocutors alone - literally causes the dialogical situation
to get out of control, as observable in the turn-taking and
-overtaking phenomena described in Section 2. As wit-
nessable in recent evaluations, this way of behaving does
not serve the intended end, i. e., efficient, intuitive and
felicitous human-computer interaction.
As future work we propose to take the Wizard and Op-
erator Test paradigm introduced herein and to change and
adjust the parameters of the computer-human interaction
- while performing subsequent measurements of the en-
suing effects - until an acceptable degree of dialogue ef-
ficiency is reached. That is, finding out just how much
extra-propositional signaling is needed to guarantee a fe-
licitous dialogue. Such communicative behavior, then has
to be implemented in dialogue systems, to make their way
of communicating more like that of their human partners.
In our minds, achieving dialogue quality remains an im-
portant challenge for the scientific community, but - as
we have shown herein and seen in recent evaluations - di-
alogue efficiency constitutes another necessary condition
for achieving dialogue felicity.
</bodyText>
<sectionHeader confidence="0.992249" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999856375">
This work has been partially funded by the German
Federal Ministry of Research and Technology (BMBF)
and by the Klaus Tschira Foundation as part of the
SMARTKOM, SMARTWEB, and EDU projects. We
would like to thank the International Computer Science
Institute in Berkeley for their help in collecting the data
especially, Lila Finhill, Thilo Pfau, Adam Janin and Fey
Parrill.
</bodyText>
<sectionHeader confidence="0.987824" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.92981417948718">
Jan Alexandersson and Tilman Becker. 2001. Overlay as
the basic operation for discourse processing. In Pro-
ceedings of the IJCAI Workshop on Knowledge and
Reasoning in Practical Dialogue Systems. Springer,
Berlin.
James F. Allen, Bradford Miller, Eric Ringger, and Teresa
Sikorski. 1996. A robust system for natural spoken di-
alogue. In Proceedings of the 34th Annual Meeting of
the Association for Computational Linguistics, Santa
Cruz, USA.
James F. Allen, George Ferguson, and Amanda Stent.
2001. An architecture for more realistic conversational
system. In Proceedings of Intelligent User Interfaces,
Santa Fe, NM.
Harald Aust, Martin Oerder, Frank Seide, and Volker
Steinbiss. 1995. The Philips automatic train timetable
information system. Speech Communication, 17.
Gerard Bailly, Nick Campbell, and Bernd M¨obius. 2003.
Isca special session: Hot topics in speech synthesis.
In Proceedings of the European Conference on Speech
Communication and Technology, Geneva, Switzerland.
Nicole Beringer, Ute Kartal, Katerina Louka, Florian
Schiel, and Uli T¨urk. 2002. PROMISE: A Procedure
for Multimodal Interactive System Evaluation. In Pro-
ceedings of the Workshop ’Multimodal Resources and
Multimodal Systems Evaluation, Las Palmas, Spain.
Nicole Beringer. 2003. The SmartKom Multimodal Cor-
pus - Data Collection and End-to-End Evaluation. In
Colloquium of the Department of Linguistics, Univer-
sity of Nijmwegen, June.
R.V. Cox, C.A. Kamm, L.R. Rabiner, J. Schroeter, and
J.G. Wilpon. 2000. Speech and language process-
ing for next-millenium communications services. Pro-
ceedings of the IEEE, 88(8).
Charles Darves and Shannon Oviatt. 2002. Adapta-
tion of Users’ Spoken Dialogue Patterns in a Conver-
sational Interface. In Proceedings of the 7th Inter-
national Conference on Spoken Language Processing,
Denver, U.S.A.
</reference>
<bodyText confidence="0.881572545454545">
J. Diaz-Verdejo, R. Lopez-Cozar, A. Rubio, and A. De
la Torre. 2000. Evaluation of a dialogue system based
on a generic model that combines robust speech under-
standing and mixed-initiative control. In 2nd Interna-
tional Conference on Language Resources and Evalu-
ation (LREC 2000), Athens, Greece.
Starkey Duncan. 1974. On the structure of speaker-
auditor interaction during speaking turns. Language
in Society, 3.
Ralf Engel. 2002. SPIN: Language understanding for
spoken dialogue systems using a production system ap-
</bodyText>
<reference confidence="0.977893869918699">
proach. In Proceedings of the International Confer-
ence on Speech and Language Processing 2002, Den-
ver, USA.
J.-M. Francony, E. Kuijpers, and Y. Polity. 1992. To-
wards a methodology for wizard of oz experiments. In
Third Conference on Applied Natural Language Pro-
cessing, Trento, Italy, March.
Norman Fraser. 1993. Sublanguage, register and natural
language interfaces. Interacting with Computers, 5.
Florian Gallwitz, Maria Aretoulaki, Manuela Boros,
J¨urgen Haas, Stefan Harbeck, R. Huber, Heinrich Nie-
mann, and Elmar N¨oth. 1998. The Erlangen spoken
dialogue system EVAR: A state-of-the-art information
retrieval system. In Proceedings of 1998 International
Symposium on Spoken Dialogue, Sydney, Australia.
Allen L. Gorin, Guiseppe Riccardi, and Jerry H. Wright.
1997. How may I help you? Speech Communication,
23.
Iryna Gurevych, Robert Porzel, and Stefan Merten.
2003. Less is more: Using a single knowledge rep-
resentation in dialogue systems. In Proceedings of
the HLT/NAACL Text Meaning Workshop, Edmonton,
Canada.
Gerd Herzog, Heinz Kirchmann, Stefan Merten, Alas-
sane Ndiaye, Peter Poller, and Tilman Becker. 2003.
MULTIPLATFORM: An integration platfrom for mul-
timodal dialogue systems. In Proceedings of the
HLT/NAACL SEALTS Workshop, Edmonton, Canada.
G. Jefferson. 1983. Two explorations of the organistion
if overlapping talk in coversation. Tilburg Papers in
Language and Literature, 28.
Michael Johnston, Srinivas Bangalore, Gunaranjan
Vasireddy, Amanda Stent, Patrick Ehlen, Marilyn
Walker, Steve Whittaker, and Preetam Maloor. 2002.
Match: An architecture for multimodal dialogue sys-
tems. In Proceedings of the 40th Annual Meeting ofthe
Association for Computational Linguistics, Philadel-
phia, Germany.
Michael Johnston. 1998. Unification-based multimodal
parsing. In Proceedings of the 17th International Con-
ference on Computational Linguistics and 36th Annual
Meeting of the Association of Computational Linguis-
tics, Montreal, Canada.
J. Krause. 1992. Nat¨urlichsprachliche mensch-
computer-interaktion als technisierte kommunikation:
Die computer talk-hypothese. In J. Krause and
L. Hitzenberger, editors, Computer Talk. Olms,
Hildesheim.
H. Kritzenberger. 1992. Unterschiede zwischen mensch-
computer-interaktion und zwischenmenschlicher kom-
munikation aus der interpretativen analyse der dicos-
protokolle. In J. Krause and L. Hitzenberger, editors,
Computer Talk, pages 122–156. Olms, Hildesheim.
Robert Porzel, Norbert Pfleger, Stefan Merten, Markus
L¨ockelt, Ralf Engel, Iryna Gurevych, and Jan Alexan-
dersson. 2003. More on less: Further applications of
ontologies in multi-modal dialogue systems. In Pro-
ceedings of the 3rd IJCAI 2003 Workshop on Knowl-
edge and Reasoning in Practical Dialogue Systems,
Acapulco, Mexico.
Stefan Rapp and Michael Strube. 2002. An iterative
data collection approach for multimodal dialogue sys-
tems. In Proceedings of the 3rd International Con-
ference on Language Resources and Evaluation, Las
Palmas, Spain.
Stefan Rapp, Sunna Torge, Silke Goronzy, and Ralf
Kompe. 2000. Dynamic speech interfaces. In Pro-
ceedings of the ECAI 2000 Workshop on Artificial In-
telligence in Mobile Systems, Berlin, Germany.
Sadock Sack, E Schegloff, and G Jefferson. 1974. A
simplest systematics for the organization of turn-taking
for conversation. Language, 50.
Tara Rosenberger Shankar, Max VanKleek, Antonio Vi-
cente, and Brian K. Smith. 2000. A computer medi-
ated conversational system that supports turn negotia-
tion. In Proceedings of the Hawai’i International Con-
ference on System Sciences, Maui, Hawaii, January.
Eve Sweetser. 2003. Levels of meaning in speech
and gesture: Real space mapped onto epistemic and
speech-interactional mental spaces. In Proceedings of
the 8th International Conference on Cognitive Linguis-
tics, Logrono, Spain, July.
Wolfgang Wahlster, Norbert Reithinger, and Anselm
Blocher. 2001. Smartkom: Multimodal communica-
tion with a life-like character. In Proceedings of the
7th European Conference on Speech Communication
and Technology.
Wolfgang Wahlster. 2002. SmartKom: Fusion and fis-
sion of speech, gerstures and facial expressions. In
Proceedings of the Firsat International Workshop on
Man-Machine Symbiotic Systems, Kyoto, Japan.
Wolfgang Wahlster. 2003. SmartKom: Symmetric mul-
timodality in an adaptive an reusable dialog shell. In
Proceedings of the Human Computer Interaction Sta-
tus Conference, Berlin, Germany.
Marilyn Walker, Diane Litman, Candace Kamm, and Ali-
cia Abella. 1997. PARADISE: A framework for eval-
uating spoken dialogue agents. In Proceedings of the
35th Annual Meeting of the Association for Computa-
tional Linguistics, Madrid, Spain.
Marilyn A. Walker, Candace A. Kamm, and Diane J. Lit-
man. 2000. Towards developing general model of us-
ability with PARADISE. Natural Language Engeneer-
ing, 6.
Karl Weinhammer and Susan Rabold. 2003. Dura-
tional Aspects in Turn Taking. In Proceedings of In-
ternational Conference Phonetic Sciences, Barcelona,
Spain.
R. Woodburn, R. Procter, J. Arnott, and A. Newell. 1991.
A study of conversational turn-taking in a commu-
nication aid for the disabled. In People and Com-
puters, pages 359–371. Cambridge University Press,
Cambridge.
Robin Wooffitt, Nigel Gilbert, Norman Fraser, and Scott
McGlashan. 1997. Humans, Computers and Wizards:
Conversation Analysis and Human (Simulated) Com-
puter Interaction. Brunner-Routledge, London.
V Yngve. 1970. On getting a word in edgewise. In
Papers from the Sixth Regional Meeting of the Chicago
Linguistic Society, Chicago, Illinois, April.
Magdalena Zoeppritz. 1985. Computer talk? Techni-
cal report, IBM Scientific Center Heidelberg Technical
Report 85.05.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.589682">
<title confidence="0.9987505">The Tao of CHI: Towards Effective Human-Computer Interaction</title>
<author confidence="0.973188">Robert Porzel Manja Baudis</author>
<affiliation confidence="0.815412">European Media Laboratory, Schloss-Wolfsbrtnnenweg</affiliation>
<address confidence="0.994508">D-69118 Heidelberg,</address>
<email confidence="0.999246">robert.porzel,manja.baudis@eml-d.villa-bosch.de</email>
<abstract confidence="0.9977018">End-to-end evaluations of conversational dialogue systems with naive users are currently uncovering severe usability problems that result in low task completion rates. Preliminary analyses suggest that these problems are related to the system’s dialogue management and turntaking behavior. We present the results of experiments designed to take a detailed look at the effects of that behavior. Based on the resulting findings, we spell out a set of criteria which lie orthogonal to dialogue quality, but nevertheless constitute an integral part of a more comview on dialogue a function of dialogue quality and efficiency.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jan Alexandersson</author>
<author>Tilman Becker</author>
</authors>
<title>Overlay as the basic operation for discourse processing.</title>
<date>2001</date>
<booktitle>In Proceedings of the IJCAI Workshop on Knowledge and Reasoning in Practical Dialogue Systems.</booktitle>
<publisher>Springer,</publisher>
<location>Berlin.</location>
<contexts>
<context position="3251" citStr="Alexandersson and Becker, 2001" startWordPosition="483" endWordPosition="486">ersational dialogue systems, e. g., SMARTKOM (Wahlster et al., 2001) or MATCH (Johnston et al., 2002), are able to cope with much less predictable user utterances. Despite the fact that in these systems recognition and processing have become extremely difficult, the reliability thereof has been pushed towards acceptable degrees by employing an array of highly sophisticated technological advances - such as dynamic lexica for multi-domain speech recognition and flexible pronunciation models (Rapp et al., 2000), robust understanding and discourse modeling techniques (Johnston, 1998; Engel, 2002; Alexandersson and Becker, 2001) combined with ontological reasoning capabilities (Gurevych et al., 2003; Porzel et al., 2003). However, the usability of such conversational dialogue systems is still unsatisfactory, as shown in usability experiments with real users (Beringer, 2003) that employed the PROMISE evaluation framework described in Beringer et al. (2002), which offers some multimodal extentions over the PARADISE framework described in Walker et al. (2000) . The work described herein constitutes a starting point for a scientific examination of the whys and wherefores of the challenging results stemming from such end-</context>
</contexts>
<marker>Alexandersson, Becker, 2001</marker>
<rawString>Jan Alexandersson and Tilman Becker. 2001. Overlay as the basic operation for discourse processing. In Proceedings of the IJCAI Workshop on Knowledge and Reasoning in Practical Dialogue Systems. Springer, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James F Allen</author>
<author>Bradford Miller</author>
<author>Eric Ringger</author>
<author>Teresa Sikorski</author>
</authors>
<title>A robust system for natural spoken dialogue.</title>
<date>1996</date>
<booktitle>In Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Santa Cruz, USA.</location>
<contexts>
<context position="1186" citStr="Allen et al. (1996)" startWordPosition="167" endWordPosition="170">d to take a detailed look at the effects of that behavior. Based on the resulting findings, we spell out a set of criteria which lie orthogonal to dialogue quality, but nevertheless constitute an integral part of a more comprehensive view on dialogue felicity as a function of dialogue quality and efficiency. 1 Introduction Research on dialogue systems in the past has focused on engineering the various processing stages involved in dialogical human-computer interaction (HCI) - e.g., robust automatic speech recognition, intention recognition, natural language generation or speech synthesis (cf. Allen et al. (1996), Cox et al. (2000) or Bailly et al. (2003)). Alongside these efforts the characteristics of computer-directed language have also been examined as a general phenomenon (cf. Zoeppritz (1985), Wooffitt et al. (1997) or Darves and Oviatt (2002)). The flip side, i. e., computer-human interaction (CHI), has received very little attention as a research question by itself. That is not to say that natural language generation and synthesis have not made vast improvements, but rather that the nature and design of the computer as an interlocutor itself, i. e., the effects of human-directed language, have</context>
</contexts>
<marker>Allen, Miller, Ringger, Sikorski, 1996</marker>
<rawString>James F. Allen, Bradford Miller, Eric Ringger, and Teresa Sikorski. 1996. A robust system for natural spoken dialogue. In Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics, Santa Cruz, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James F Allen</author>
<author>George Ferguson</author>
<author>Amanda Stent</author>
</authors>
<title>An architecture for more realistic conversational system.</title>
<date>2001</date>
<booktitle>In Proceedings of Intelligent User Interfaces,</booktitle>
<location>Santa Fe, NM.</location>
<contexts>
<context position="1912" citStr="Allen et al. (2001)" startWordPosition="283" endWordPosition="286">ted language have also been examined as a general phenomenon (cf. Zoeppritz (1985), Wooffitt et al. (1997) or Darves and Oviatt (2002)). The flip side, i. e., computer-human interaction (CHI), has received very little attention as a research question by itself. That is not to say that natural language generation and synthesis have not made vast improvements, but rather that the nature and design of the computer as an interlocutor itself, i. e., the effects of human-directed language, have not been scrutinized as such. Looking at broad levels of distinctions for dialogue systems, e.g., that of Allen et al. (2001) between controlled and conversational dialogue systems, we note the singular employment of human-based differentiae, i. e., the degree of the restriction of the human interactions. Differentiae stemming from the other communication partner, i. e., the computer, are not taken into account - neither on a practical nor on a theoretical level. In the past controlled and restricted interactions between the user and the system increased recognition and understanding accuracies to a level that systems became reliable enough for deployment in various real world applications, e. g., transportation or </context>
</contexts>
<marker>Allen, Ferguson, Stent, 2001</marker>
<rawString>James F. Allen, George Ferguson, and Amanda Stent. 2001. An architecture for more realistic conversational system. In Proceedings of Intelligent User Interfaces, Santa Fe, NM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harald Aust</author>
<author>Martin Oerder</author>
<author>Frank Seide</author>
<author>Volker Steinbiss</author>
</authors>
<title>The Philips automatic train timetable information system.</title>
<date>1995</date>
<journal>Speech Communication,</journal>
<volume>17</volume>
<contexts>
<context position="2557" citStr="Aust et al., 1995" startWordPosition="380" endWordPosition="383">ersational dialogue systems, we note the singular employment of human-based differentiae, i. e., the degree of the restriction of the human interactions. Differentiae stemming from the other communication partner, i. e., the computer, are not taken into account - neither on a practical nor on a theoretical level. In the past controlled and restricted interactions between the user and the system increased recognition and understanding accuracies to a level that systems became reliable enough for deployment in various real world applications, e. g., transportation or cinema information systems (Aust et al., 1995; Gorin et al., 1997; Gallwitz et al., 1998). Today’s more conversational dialogue systems, e. g., SMARTKOM (Wahlster et al., 2001) or MATCH (Johnston et al., 2002), are able to cope with much less predictable user utterances. Despite the fact that in these systems recognition and processing have become extremely difficult, the reliability thereof has been pushed towards acceptable degrees by employing an array of highly sophisticated technological advances - such as dynamic lexica for multi-domain speech recognition and flexible pronunciation models (Rapp et al., 2000), robust understanding a</context>
</contexts>
<marker>Aust, Oerder, Seide, Steinbiss, 1995</marker>
<rawString>Harald Aust, Martin Oerder, Frank Seide, and Volker Steinbiss. 1995. The Philips automatic train timetable information system. Speech Communication, 17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Bailly</author>
<author>Nick Campbell</author>
<author>Bernd M¨obius</author>
</authors>
<title>Isca special session: Hot topics in speech synthesis.</title>
<date>2003</date>
<booktitle>In Proceedings of the European Conference on Speech Communication and Technology,</booktitle>
<location>Geneva, Switzerland.</location>
<marker>Bailly, Campbell, M¨obius, 2003</marker>
<rawString>Gerard Bailly, Nick Campbell, and Bernd M¨obius. 2003. Isca special session: Hot topics in speech synthesis. In Proceedings of the European Conference on Speech Communication and Technology, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicole Beringer</author>
<author>Ute Kartal</author>
<author>Katerina Louka</author>
<author>Florian Schiel</author>
<author>Uli T¨urk</author>
</authors>
<title>PROMISE: A Procedure for Multimodal Interactive System Evaluation.</title>
<date>2002</date>
<booktitle>In Proceedings of the Workshop ’Multimodal Resources and Multimodal Systems Evaluation,</booktitle>
<location>Las Palmas,</location>
<marker>Beringer, Kartal, Louka, Schiel, T¨urk, 2002</marker>
<rawString>Nicole Beringer, Ute Kartal, Katerina Louka, Florian Schiel, and Uli T¨urk. 2002. PROMISE: A Procedure for Multimodal Interactive System Evaluation. In Proceedings of the Workshop ’Multimodal Resources and Multimodal Systems Evaluation, Las Palmas, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicole Beringer</author>
</authors>
<title>The SmartKom Multimodal Corpus - Data Collection and End-to-End Evaluation.</title>
<date>2003</date>
<booktitle>In Colloquium of the</booktitle>
<institution>Department of Linguistics, University of Nijmwegen,</institution>
<contexts>
<context position="3501" citStr="Beringer, 2003" startWordPosition="521" endWordPosition="522"> reliability thereof has been pushed towards acceptable degrees by employing an array of highly sophisticated technological advances - such as dynamic lexica for multi-domain speech recognition and flexible pronunciation models (Rapp et al., 2000), robust understanding and discourse modeling techniques (Johnston, 1998; Engel, 2002; Alexandersson and Becker, 2001) combined with ontological reasoning capabilities (Gurevych et al., 2003; Porzel et al., 2003). However, the usability of such conversational dialogue systems is still unsatisfactory, as shown in usability experiments with real users (Beringer, 2003) that employed the PROMISE evaluation framework described in Beringer et al. (2002), which offers some multimodal extentions over the PARADISE framework described in Walker et al. (2000) . The work described herein constitutes a starting point for a scientific examination of the whys and wherefores of the challenging results stemming from such end-to-end evaluations of conversational dialogue systems. Following a brief description of the state of the art in examinations of computer-directed language, we describe a new experimental paradigm, the first two studies using the paradigm and their co</context>
<context position="7285" citStr="Beringer (2003)" startWordPosition="1092" endWordPosition="1093">the state of the art of the dialogue management of today’s conversational dialogue systems, evaluation trials with naive users will continue to uncover severe usability problems resulting in low task completion rates.&apos; Surprisingly, this occurs despite acceptable partial evaluation results. By partial results, we understand evaluations of individual components such as concerning the word-error rate of automatic speech recognition or understanding rates as conducted by Cox et al. (2000) or reported in Diaz-Verdejo et al. (2000). As one of the reasons for the problems thwarting task completion, Beringer (2003) points at the problem of turn overtaking, which occurs when users rephrase questions or make a second remark to the system, while it is still processing the first one. After such occurrences a dialogue becomes asynchronous, meaning that the system responds to the second last user utterance while in the user’s mind that response concerns the last. Given the current state of the art regarding the dialogue handling capabilities of HCI systems, this inevitably causes dialogues to fail completely. We can already conclude from these informal findings that current state of the art conversational dia</context>
</contexts>
<marker>Beringer, 2003</marker>
<rawString>Nicole Beringer. 2003. The SmartKom Multimodal Corpus - Data Collection and End-to-End Evaluation. In Colloquium of the Department of Linguistics, University of Nijmwegen, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R V Cox</author>
<author>C A Kamm</author>
<author>L R Rabiner</author>
<author>J Schroeter</author>
<author>J G Wilpon</author>
</authors>
<title>Speech and language processing for next-millenium communications services.</title>
<date>2000</date>
<booktitle>Proceedings of the IEEE,</booktitle>
<volume>88</volume>
<issue>8</issue>
<contexts>
<context position="1205" citStr="Cox et al. (2000)" startWordPosition="171" endWordPosition="174">look at the effects of that behavior. Based on the resulting findings, we spell out a set of criteria which lie orthogonal to dialogue quality, but nevertheless constitute an integral part of a more comprehensive view on dialogue felicity as a function of dialogue quality and efficiency. 1 Introduction Research on dialogue systems in the past has focused on engineering the various processing stages involved in dialogical human-computer interaction (HCI) - e.g., robust automatic speech recognition, intention recognition, natural language generation or speech synthesis (cf. Allen et al. (1996), Cox et al. (2000) or Bailly et al. (2003)). Alongside these efforts the characteristics of computer-directed language have also been examined as a general phenomenon (cf. Zoeppritz (1985), Wooffitt et al. (1997) or Darves and Oviatt (2002)). The flip side, i. e., computer-human interaction (CHI), has received very little attention as a research question by itself. That is not to say that natural language generation and synthesis have not made vast improvements, but rather that the nature and design of the computer as an interlocutor itself, i. e., the effects of human-directed language, have not been scrutiniz</context>
<context position="7160" citStr="Cox et al. (2000)" startWordPosition="1070" endWordPosition="1073">cation reporting a successful end-to-end evaluation of a conversational dialogue system with naive users. We claim that, given the state of the art of the dialogue management of today’s conversational dialogue systems, evaluation trials with naive users will continue to uncover severe usability problems resulting in low task completion rates.&apos; Surprisingly, this occurs despite acceptable partial evaluation results. By partial results, we understand evaluations of individual components such as concerning the word-error rate of automatic speech recognition or understanding rates as conducted by Cox et al. (2000) or reported in Diaz-Verdejo et al. (2000). As one of the reasons for the problems thwarting task completion, Beringer (2003) points at the problem of turn overtaking, which occurs when users rephrase questions or make a second remark to the system, while it is still processing the first one. After such occurrences a dialogue becomes asynchronous, meaning that the system responds to the second last user utterance while in the user’s mind that response concerns the last. Given the current state of the art regarding the dialogue handling capabilities of HCI systems, this inevitably causes dialog</context>
</contexts>
<marker>Cox, Kamm, Rabiner, Schroeter, Wilpon, 2000</marker>
<rawString>R.V. Cox, C.A. Kamm, L.R. Rabiner, J. Schroeter, and J.G. Wilpon. 2000. Speech and language processing for next-millenium communications services. Proceedings of the IEEE, 88(8).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Darves</author>
<author>Shannon Oviatt</author>
</authors>
<title>Adaptation of Users’ Spoken Dialogue Patterns in a Conversational Interface.</title>
<date>2002</date>
<booktitle>In Proceedings of the 7th International Conference on Spoken Language Processing,</booktitle>
<location>Denver, U.S.A.</location>
<contexts>
<context position="1427" citStr="Darves and Oviatt (2002)" startWordPosition="205" endWordPosition="208">ew on dialogue felicity as a function of dialogue quality and efficiency. 1 Introduction Research on dialogue systems in the past has focused on engineering the various processing stages involved in dialogical human-computer interaction (HCI) - e.g., robust automatic speech recognition, intention recognition, natural language generation or speech synthesis (cf. Allen et al. (1996), Cox et al. (2000) or Bailly et al. (2003)). Alongside these efforts the characteristics of computer-directed language have also been examined as a general phenomenon (cf. Zoeppritz (1985), Wooffitt et al. (1997) or Darves and Oviatt (2002)). The flip side, i. e., computer-human interaction (CHI), has received very little attention as a research question by itself. That is not to say that natural language generation and synthesis have not made vast improvements, but rather that the nature and design of the computer as an interlocutor itself, i. e., the effects of human-directed language, have not been scrutinized as such. Looking at broad levels of distinctions for dialogue systems, e.g., that of Allen et al. (2001) between controlled and conversational dialogue systems, we note the singular employment of human-based differentia</context>
<context position="4754" citStr="Darves and Oviatt (2002)" startWordPosition="708" endWordPosition="711">ng, we discuss the ensuing implications for the design of successful and felicitous conversational dialogue systems. 2 Studies on Human-Computer Dialogues The first studies and descriptions of the particularities of dialogical human-computer interaction, then labeled as computer talk in analogy to baby talk by Zoeppritz (1985), focused - much like subsequent ones - on: proving that a regular register for humans conversing with dialogue system exists, e. g., those of Krause (1992) and Fraser (1993), describing the regularities and characteristics of that register, as in Kritzenberger (1992) or Darves and Oviatt (2002). The results of these studies clearly show that such a register exists and that its regularities can be replicated and observed again and again. In general, this work focuses on the question: what changes happen to human verbal behavior when they talk to computers as opposed to fellow humans? The questions which are not explicitely asked or studied are: how does the computer’s way of communicating affect the human interlocutor, do the particulars of computer-human interaction help to explain why today’s conversational dialogue systems are by and large unusable. In this paper we claim that thi</context>
</contexts>
<marker>Darves, Oviatt, 2002</marker>
<rawString>Charles Darves and Shannon Oviatt. 2002. Adaptation of Users’ Spoken Dialogue Patterns in a Conversational Interface. In Proceedings of the 7th International Conference on Spoken Language Processing, Denver, U.S.A.</rawString>
</citation>
<citation valid="true">
<authors>
<author>proach</author>
</authors>
<date>2002</date>
<booktitle>In Proceedings of the International Conference on Speech and Language Processing</booktitle>
<location>Denver, USA.</location>
<marker>proach, 2002</marker>
<rawString>proach. In Proceedings of the International Conference on Speech and Language Processing 2002, Denver, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J-M Francony</author>
<author>E Kuijpers</author>
<author>Y Polity</author>
</authors>
<title>Towards a methodology for wizard of oz experiments.</title>
<date>1992</date>
<booktitle>In Third Conference on Applied Natural Language Processing,</booktitle>
<location>Trento, Italy,</location>
<contexts>
<context position="10219" citStr="Francony et al., 1992" startWordPosition="1546" endWordPosition="1549"> behavior. The overall goal of analyzing these effects is, that future systems become usable by exhibiting a more felicitous communicative behavior. After reporting on the results of the experiments in Section 4, we highlight a set of hypotheses that can be drawn from them and point towards future experiments that need to be conducted to verify these hypotheses in Section 6. 3 Experiments For conducting the experiments we developed a new paradigm for collecting telephone-based dialogue data, called Wizard and Operator Test (WOT), which contains elements of both Wizard-of-Oz (WoZ) experiments (Francony et al., 1992) as well as Hidden Operator Tests (Rapp and Strube, 2002). This procedure also represents a simplification of classical end-to-end experiments, as it is - much like WoZ experiments - conductible without the technically very complex use of a real conversational system. As post-experimental interviews showed, this did not limit the feeling of authenticity regarding the simulated conversational system by the human subjects ( ). The WOT setup consists of two major phases that begin after subjects have been given a set of tasks to be solved with the telephone-based dialogue system: in Phase 1 the h</context>
</contexts>
<marker>Francony, Kuijpers, Polity, 1992</marker>
<rawString>J.-M. Francony, E. Kuijpers, and Y. Polity. 1992. Towards a methodology for wizard of oz experiments. In Third Conference on Applied Natural Language Processing, Trento, Italy, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Norman Fraser</author>
</authors>
<title>Sublanguage, register and natural language interfaces.</title>
<date>1993</date>
<journal>Interacting with Computers,</journal>
<volume>5</volume>
<contexts>
<context position="4632" citStr="Fraser (1993)" startWordPosition="693" endWordPosition="694">a new experimental paradigm, the first two studies using the paradigm and their corresponding results. Concluding, we discuss the ensuing implications for the design of successful and felicitous conversational dialogue systems. 2 Studies on Human-Computer Dialogues The first studies and descriptions of the particularities of dialogical human-computer interaction, then labeled as computer talk in analogy to baby talk by Zoeppritz (1985), focused - much like subsequent ones - on: proving that a regular register for humans conversing with dialogue system exists, e. g., those of Krause (1992) and Fraser (1993), describing the regularities and characteristics of that register, as in Kritzenberger (1992) or Darves and Oviatt (2002). The results of these studies clearly show that such a register exists and that its regularities can be replicated and observed again and again. In general, this work focuses on the question: what changes happen to human verbal behavior when they talk to computers as opposed to fellow humans? The questions which are not explicitely asked or studied are: how does the computer’s way of communicating affect the human interlocutor, do the particulars of computer-human interact</context>
</contexts>
<marker>Fraser, 1993</marker>
<rawString>Norman Fraser. 1993. Sublanguage, register and natural language interfaces. Interacting with Computers, 5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Florian Gallwitz</author>
<author>Maria Aretoulaki</author>
<author>Manuela Boros</author>
<author>J¨urgen Haas</author>
<author>Stefan Harbeck</author>
<author>R Huber</author>
<author>Heinrich Niemann</author>
<author>Elmar N¨oth</author>
</authors>
<title>The Erlangen spoken dialogue system EVAR: A state-of-the-art information retrieval system.</title>
<date>1998</date>
<booktitle>In Proceedings of 1998 International Symposium on Spoken Dialogue,</booktitle>
<location>Sydney, Australia.</location>
<marker>Gallwitz, Aretoulaki, Boros, Haas, Harbeck, Huber, Niemann, N¨oth, 1998</marker>
<rawString>Florian Gallwitz, Maria Aretoulaki, Manuela Boros, J¨urgen Haas, Stefan Harbeck, R. Huber, Heinrich Niemann, and Elmar N¨oth. 1998. The Erlangen spoken dialogue system EVAR: A state-of-the-art information retrieval system. In Proceedings of 1998 International Symposium on Spoken Dialogue, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Allen L Gorin</author>
<author>Guiseppe Riccardi</author>
<author>Jerry H Wright</author>
</authors>
<title>How may I help you?</title>
<date>1997</date>
<journal>Speech Communication,</journal>
<volume>23</volume>
<contexts>
<context position="2577" citStr="Gorin et al., 1997" startWordPosition="384" endWordPosition="387"> systems, we note the singular employment of human-based differentiae, i. e., the degree of the restriction of the human interactions. Differentiae stemming from the other communication partner, i. e., the computer, are not taken into account - neither on a practical nor on a theoretical level. In the past controlled and restricted interactions between the user and the system increased recognition and understanding accuracies to a level that systems became reliable enough for deployment in various real world applications, e. g., transportation or cinema information systems (Aust et al., 1995; Gorin et al., 1997; Gallwitz et al., 1998). Today’s more conversational dialogue systems, e. g., SMARTKOM (Wahlster et al., 2001) or MATCH (Johnston et al., 2002), are able to cope with much less predictable user utterances. Despite the fact that in these systems recognition and processing have become extremely difficult, the reliability thereof has been pushed towards acceptable degrees by employing an array of highly sophisticated technological advances - such as dynamic lexica for multi-domain speech recognition and flexible pronunciation models (Rapp et al., 2000), robust understanding and discourse modelin</context>
</contexts>
<marker>Gorin, Riccardi, Wright, 1997</marker>
<rawString>Allen L. Gorin, Guiseppe Riccardi, and Jerry H. Wright. 1997. How may I help you? Speech Communication, 23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Iryna Gurevych</author>
<author>Robert Porzel</author>
<author>Stefan Merten</author>
</authors>
<title>Less is more: Using a single knowledge representation in dialogue systems.</title>
<date>2003</date>
<booktitle>In Proceedings of the HLT/NAACL Text Meaning Workshop,</booktitle>
<location>Edmonton, Canada.</location>
<contexts>
<context position="3323" citStr="Gurevych et al., 2003" startWordPosition="492" endWordPosition="495">nston et al., 2002), are able to cope with much less predictable user utterances. Despite the fact that in these systems recognition and processing have become extremely difficult, the reliability thereof has been pushed towards acceptable degrees by employing an array of highly sophisticated technological advances - such as dynamic lexica for multi-domain speech recognition and flexible pronunciation models (Rapp et al., 2000), robust understanding and discourse modeling techniques (Johnston, 1998; Engel, 2002; Alexandersson and Becker, 2001) combined with ontological reasoning capabilities (Gurevych et al., 2003; Porzel et al., 2003). However, the usability of such conversational dialogue systems is still unsatisfactory, as shown in usability experiments with real users (Beringer, 2003) that employed the PROMISE evaluation framework described in Beringer et al. (2002), which offers some multimodal extentions over the PARADISE framework described in Walker et al. (2000) . The work described herein constitutes a starting point for a scientific examination of the whys and wherefores of the challenging results stemming from such end-to-end evaluations of conversational dialogue systems. Following a brief</context>
</contexts>
<marker>Gurevych, Porzel, Merten, 2003</marker>
<rawString>Iryna Gurevych, Robert Porzel, and Stefan Merten. 2003. Less is more: Using a single knowledge representation in dialogue systems. In Proceedings of the HLT/NAACL Text Meaning Workshop, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerd Herzog</author>
<author>Heinz Kirchmann</author>
<author>Stefan Merten</author>
<author>Alassane Ndiaye</author>
<author>Peter Poller</author>
<author>Tilman Becker</author>
</authors>
<title>MULTIPLATFORM: An integration platfrom for multimodal dialogue systems.</title>
<date>2003</date>
<booktitle>In Proceedings of the HLT/NAACL SEALTS Workshop,</booktitle>
<location>Edmonton, Canada.</location>
<contexts>
<context position="6384" citStr="Herzog et al., 2003" startWordPosition="955" endWordPosition="958">imodal interaction comprises a symmetric set of input and output modalities (Wahlster, 2003), together with an efficient fusion and fission pipeline (Wahlster, 2002). SMARTKOM features speech input with prosodic analysis, gesture input via infrared camera, recognition of facial expressions and their emotional states. On the output side SMARTKOM employs a gesturing and speaking life-like character together with displayed generated text and multimedia graphical output. It currently comprised nearly 50 modules running on a parallel virtual machine-based integration software called MULTIPLATFORM (Herzog et al., 2003). As such it is certainly among the most advanced multi-domain conversational dialogue systems. To the best of our knowledge, there has not been a single publication reporting a successful end-to-end evaluation of a conversational dialogue system with naive users. We claim that, given the state of the art of the dialogue management of today’s conversational dialogue systems, evaluation trials with naive users will continue to uncover severe usability problems resulting in low task completion rates.&apos; Surprisingly, this occurs despite acceptable partial evaluation results. By partial results, we</context>
</contexts>
<marker>Herzog, Kirchmann, Merten, Ndiaye, Poller, Becker, 2003</marker>
<rawString>Gerd Herzog, Heinz Kirchmann, Stefan Merten, Alassane Ndiaye, Peter Poller, and Tilman Becker. 2003. MULTIPLATFORM: An integration platfrom for multimodal dialogue systems. In Proceedings of the HLT/NAACL SEALTS Workshop, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Jefferson</author>
</authors>
<title>Two explorations of the organistion if overlapping talk in coversation.</title>
<date>1983</date>
<booktitle>Tilburg Papers in Language and Literature,</booktitle>
<pages>28</pages>
<contexts>
<context position="21523" citStr="Jefferson, 1983" startWordPosition="3438" endWordPosition="3439">onal” dialogue systems.3 Particles structure particle feedback particle HCI HHI HCI HHI Number 112 G 225 G 18 G 135 G total 90 E 202 E 0 E 43 E per 5.6 G 11.25 G 0.9 G 6.75 G dialogue 4.5 E 10.1 E 0 E 2.15 E per 0.4 G 0.59 G 0.04 G 0.26 G turn 0.61 E 0.48 E 0 E 0.1 E Table 4: Particles of human subjects: HCI vs. HHI Before turning towards an analysis of this data we will examine the overlaps that occurred throughout the dialogues. Most overlaps in human-human conversation occur during turn changes with the remainder being feedback signals that are uttered during the other interlocutor’s turn (Jefferson, 1983). The results on measuring the amount of overlap in our experiments are given in Table 5. Overall the HHI dialogues featured significantly more overlap than the HCI ones, which is partly due to the respective presence and absence of feedback signals as well as due to the fact that in HCI turn takes are accompanied by pauses rather than immediate - overlapping - hand overs. Overlaps HCI-G HHI-G HCI-E HHI-E Number total 7 49 4 88 per dialogue 0.35 3.06 0.2 4.4 per turn 0.03 0.18 0.01 0.1 Table 5: Overlaps in Phase 1 versus Phase 2 Lastly, our experiments yielded negative findings concerning diff</context>
</contexts>
<marker>Jefferson, 1983</marker>
<rawString>G. Jefferson. 1983. Two explorations of the organistion if overlapping talk in coversation. Tilburg Papers in Language and Literature, 28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Johnston</author>
<author>Srinivas Bangalore</author>
<author>Gunaranjan Vasireddy</author>
<author>Amanda Stent</author>
<author>Patrick Ehlen</author>
<author>Marilyn Walker</author>
<author>Steve Whittaker</author>
<author>Preetam Maloor</author>
</authors>
<title>Match: An architecture for multimodal dialogue systems.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting ofthe Association for Computational Linguistics,</booktitle>
<location>Philadelphia, Germany.</location>
<contexts>
<context position="2721" citStr="Johnston et al., 2002" startWordPosition="408" endWordPosition="411">rentiae stemming from the other communication partner, i. e., the computer, are not taken into account - neither on a practical nor on a theoretical level. In the past controlled and restricted interactions between the user and the system increased recognition and understanding accuracies to a level that systems became reliable enough for deployment in various real world applications, e. g., transportation or cinema information systems (Aust et al., 1995; Gorin et al., 1997; Gallwitz et al., 1998). Today’s more conversational dialogue systems, e. g., SMARTKOM (Wahlster et al., 2001) or MATCH (Johnston et al., 2002), are able to cope with much less predictable user utterances. Despite the fact that in these systems recognition and processing have become extremely difficult, the reliability thereof has been pushed towards acceptable degrees by employing an array of highly sophisticated technological advances - such as dynamic lexica for multi-domain speech recognition and flexible pronunciation models (Rapp et al., 2000), robust understanding and discourse modeling techniques (Johnston, 1998; Engel, 2002; Alexandersson and Becker, 2001) combined with ontological reasoning capabilities (Gurevych et al., 20</context>
</contexts>
<marker>Johnston, Bangalore, Vasireddy, Stent, Ehlen, Walker, Whittaker, Maloor, 2002</marker>
<rawString>Michael Johnston, Srinivas Bangalore, Gunaranjan Vasireddy, Amanda Stent, Patrick Ehlen, Marilyn Walker, Steve Whittaker, and Preetam Maloor. 2002. Match: An architecture for multimodal dialogue systems. In Proceedings of the 40th Annual Meeting ofthe Association for Computational Linguistics, Philadelphia, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Johnston</author>
</authors>
<title>Unification-based multimodal parsing.</title>
<date>1998</date>
<booktitle>In Proceedings of the 17th International Conference on Computational Linguistics and 36th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="3205" citStr="Johnston, 1998" startWordPosition="479" endWordPosition="480">al., 1998). Today’s more conversational dialogue systems, e. g., SMARTKOM (Wahlster et al., 2001) or MATCH (Johnston et al., 2002), are able to cope with much less predictable user utterances. Despite the fact that in these systems recognition and processing have become extremely difficult, the reliability thereof has been pushed towards acceptable degrees by employing an array of highly sophisticated technological advances - such as dynamic lexica for multi-domain speech recognition and flexible pronunciation models (Rapp et al., 2000), robust understanding and discourse modeling techniques (Johnston, 1998; Engel, 2002; Alexandersson and Becker, 2001) combined with ontological reasoning capabilities (Gurevych et al., 2003; Porzel et al., 2003). However, the usability of such conversational dialogue systems is still unsatisfactory, as shown in usability experiments with real users (Beringer, 2003) that employed the PROMISE evaluation framework described in Beringer et al. (2002), which offers some multimodal extentions over the PARADISE framework described in Walker et al. (2000) . The work described herein constitutes a starting point for a scientific examination of the whys and wherefores of t</context>
</contexts>
<marker>Johnston, 1998</marker>
<rawString>Michael Johnston. 1998. Unification-based multimodal parsing. In Proceedings of the 17th International Conference on Computational Linguistics and 36th Annual Meeting of the Association of Computational Linguistics, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Krause</author>
</authors>
<title>Nat¨urlichsprachliche menschcomputer-interaktion als technisierte kommunikation: Die computer talk-hypothese.</title>
<date>1992</date>
<editor>In J. Krause and L. Hitzenberger, editors, Computer Talk. Olms,</editor>
<location>Hildesheim.</location>
<contexts>
<context position="4614" citStr="Krause (1992)" startWordPosition="690" endWordPosition="691">uage, we describe a new experimental paradigm, the first two studies using the paradigm and their corresponding results. Concluding, we discuss the ensuing implications for the design of successful and felicitous conversational dialogue systems. 2 Studies on Human-Computer Dialogues The first studies and descriptions of the particularities of dialogical human-computer interaction, then labeled as computer talk in analogy to baby talk by Zoeppritz (1985), focused - much like subsequent ones - on: proving that a regular register for humans conversing with dialogue system exists, e. g., those of Krause (1992) and Fraser (1993), describing the regularities and characteristics of that register, as in Kritzenberger (1992) or Darves and Oviatt (2002). The results of these studies clearly show that such a register exists and that its regularities can be replicated and observed again and again. In general, this work focuses on the question: what changes happen to human verbal behavior when they talk to computers as opposed to fellow humans? The questions which are not explicitely asked or studied are: how does the computer’s way of communicating affect the human interlocutor, do the particulars of compu</context>
</contexts>
<marker>Krause, 1992</marker>
<rawString>J. Krause. 1992. Nat¨urlichsprachliche menschcomputer-interaktion als technisierte kommunikation: Die computer talk-hypothese. In J. Krause and L. Hitzenberger, editors, Computer Talk. Olms, Hildesheim.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Kritzenberger</author>
</authors>
<title>Unterschiede zwischen menschcomputer-interaktion und zwischenmenschlicher kommunikation aus der interpretativen analyse der dicosprotokolle.</title>
<date>1992</date>
<pages>122--156</pages>
<editor>In J. Krause and L. Hitzenberger, editors, Computer Talk,</editor>
<publisher>Olms,</publisher>
<location>Hildesheim.</location>
<contexts>
<context position="4726" citStr="Kritzenberger (1992)" startWordPosition="705" endWordPosition="706">onding results. Concluding, we discuss the ensuing implications for the design of successful and felicitous conversational dialogue systems. 2 Studies on Human-Computer Dialogues The first studies and descriptions of the particularities of dialogical human-computer interaction, then labeled as computer talk in analogy to baby talk by Zoeppritz (1985), focused - much like subsequent ones - on: proving that a regular register for humans conversing with dialogue system exists, e. g., those of Krause (1992) and Fraser (1993), describing the regularities and characteristics of that register, as in Kritzenberger (1992) or Darves and Oviatt (2002). The results of these studies clearly show that such a register exists and that its regularities can be replicated and observed again and again. In general, this work focuses on the question: what changes happen to human verbal behavior when they talk to computers as opposed to fellow humans? The questions which are not explicitely asked or studied are: how does the computer’s way of communicating affect the human interlocutor, do the particulars of computer-human interaction help to explain why today’s conversational dialogue systems are by and large unusable. In </context>
</contexts>
<marker>Kritzenberger, 1992</marker>
<rawString>H. Kritzenberger. 1992. Unterschiede zwischen menschcomputer-interaktion und zwischenmenschlicher kommunikation aus der interpretativen analyse der dicosprotokolle. In J. Krause and L. Hitzenberger, editors, Computer Talk, pages 122–156. Olms, Hildesheim.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Porzel</author>
<author>Norbert Pfleger</author>
<author>Stefan Merten</author>
<author>Markus L¨ockelt</author>
<author>Ralf Engel</author>
<author>Iryna Gurevych</author>
<author>Jan Alexandersson</author>
</authors>
<title>More on less: Further applications of ontologies in multi-modal dialogue systems.</title>
<date>2003</date>
<booktitle>In Proceedings of the 3rd IJCAI 2003 Workshop on Knowledge and Reasoning in Practical Dialogue Systems,</booktitle>
<location>Acapulco, Mexico.</location>
<marker>Porzel, Pfleger, Merten, L¨ockelt, Engel, Gurevych, Alexandersson, 2003</marker>
<rawString>Robert Porzel, Norbert Pfleger, Stefan Merten, Markus L¨ockelt, Ralf Engel, Iryna Gurevych, and Jan Alexandersson. 2003. More on less: Further applications of ontologies in multi-modal dialogue systems. In Proceedings of the 3rd IJCAI 2003 Workshop on Knowledge and Reasoning in Practical Dialogue Systems, Acapulco, Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Rapp</author>
<author>Michael Strube</author>
</authors>
<title>An iterative data collection approach for multimodal dialogue systems.</title>
<date>2002</date>
<booktitle>In Proceedings of the 3rd International Conference on Language Resources and Evaluation,</booktitle>
<location>Las Palmas,</location>
<contexts>
<context position="10276" citStr="Rapp and Strube, 2002" startWordPosition="1556" endWordPosition="1559">, that future systems become usable by exhibiting a more felicitous communicative behavior. After reporting on the results of the experiments in Section 4, we highlight a set of hypotheses that can be drawn from them and point towards future experiments that need to be conducted to verify these hypotheses in Section 6. 3 Experiments For conducting the experiments we developed a new paradigm for collecting telephone-based dialogue data, called Wizard and Operator Test (WOT), which contains elements of both Wizard-of-Oz (WoZ) experiments (Francony et al., 1992) as well as Hidden Operator Tests (Rapp and Strube, 2002). This procedure also represents a simplification of classical end-to-end experiments, as it is - much like WoZ experiments - conductible without the technically very complex use of a real conversational system. As post-experimental interviews showed, this did not limit the feeling of authenticity regarding the simulated conversational system by the human subjects ( ). The WOT setup consists of two major phases that begin after subjects have been given a set of tasks to be solved with the telephone-based dialogue system: in Phase 1 the human assistant ( ) is acting as a wizard who is simulatin</context>
</contexts>
<marker>Rapp, Strube, 2002</marker>
<rawString>Stefan Rapp and Michael Strube. 2002. An iterative data collection approach for multimodal dialogue systems. In Proceedings of the 3rd International Conference on Language Resources and Evaluation, Las Palmas, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Rapp</author>
<author>Sunna Torge</author>
<author>Silke Goronzy</author>
<author>Ralf Kompe</author>
</authors>
<title>Dynamic speech interfaces.</title>
<date>2000</date>
<booktitle>In Proceedings of the ECAI 2000 Workshop on Artificial Intelligence in Mobile Systems,</booktitle>
<location>Berlin, Germany.</location>
<contexts>
<context position="3133" citStr="Rapp et al., 2000" startWordPosition="469" endWordPosition="472">ema information systems (Aust et al., 1995; Gorin et al., 1997; Gallwitz et al., 1998). Today’s more conversational dialogue systems, e. g., SMARTKOM (Wahlster et al., 2001) or MATCH (Johnston et al., 2002), are able to cope with much less predictable user utterances. Despite the fact that in these systems recognition and processing have become extremely difficult, the reliability thereof has been pushed towards acceptable degrees by employing an array of highly sophisticated technological advances - such as dynamic lexica for multi-domain speech recognition and flexible pronunciation models (Rapp et al., 2000), robust understanding and discourse modeling techniques (Johnston, 1998; Engel, 2002; Alexandersson and Becker, 2001) combined with ontological reasoning capabilities (Gurevych et al., 2003; Porzel et al., 2003). However, the usability of such conversational dialogue systems is still unsatisfactory, as shown in usability experiments with real users (Beringer, 2003) that employed the PROMISE evaluation framework described in Beringer et al. (2002), which offers some multimodal extentions over the PARADISE framework described in Walker et al. (2000) . The work described herein constitutes a sta</context>
</contexts>
<marker>Rapp, Torge, Goronzy, Kompe, 2000</marker>
<rawString>Stefan Rapp, Sunna Torge, Silke Goronzy, and Ralf Kompe. 2000. Dynamic speech interfaces. In Proceedings of the ECAI 2000 Workshop on Artificial Intelligence in Mobile Systems, Berlin, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sadock Sack</author>
<author>E Schegloff</author>
<author>G Jefferson</author>
</authors>
<title>A simplest systematics for the organization of turn-taking for conversation.</title>
<date>1974</date>
<journal>Language,</journal>
<volume>50</volume>
<contexts>
<context position="8236" citStr="Sack et al. (1974)" startWordPosition="1243" endWordPosition="1246">ncerns the last. Given the current state of the art regarding the dialogue handling capabilities of HCI systems, this inevitably causes dialogues to fail completely. We can already conclude from these informal findings that current state of the art conversational dialogue systems suffer from a) a lack of turn-taking strategies and dialogue handling capabilities as well as b) a lack of strategies for repairing dialogues once they become out ofsync. In human-human interaction (HHI) turn-taking strategies and their effects have been studied for decades in unimodal settings from Duncan (1974) and Sack et al. (1974) to Weinhammer and Rabold (2003) as well as more recently in multimodal settings as in Sweetser (2003). Virtually no work exists concerning the turn-taking strategies that dialogue systems should pursue and how they effect human-computer interaction, except in special cases such as in Woodburn et al. (1991) for the case of conversational computer-mediated communication aids for the speech and hearing impaired or Shankar et al. (2000) for turn negotiation in text-based dialogue systems. The overview of classical HCI experiments and their results, given in Wooffitt et al. (1997), also shows that</context>
</contexts>
<marker>Sack, Schegloff, Jefferson, 1974</marker>
<rawString>Sadock Sack, E Schegloff, and G Jefferson. 1974. A simplest systematics for the organization of turn-taking for conversation. Language, 50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tara Rosenberger Shankar</author>
<author>Max VanKleek</author>
<author>Antonio Vicente</author>
<author>Brian K Smith</author>
</authors>
<title>A computer mediated conversational system that supports turn negotiation.</title>
<date>2000</date>
<booktitle>In Proceedings of the Hawai’i International Conference on System Sciences,</booktitle>
<location>Maui, Hawaii,</location>
<contexts>
<context position="8673" citStr="Shankar et al. (2000)" startWordPosition="1310" endWordPosition="1313">ecome out ofsync. In human-human interaction (HHI) turn-taking strategies and their effects have been studied for decades in unimodal settings from Duncan (1974) and Sack et al. (1974) to Weinhammer and Rabold (2003) as well as more recently in multimodal settings as in Sweetser (2003). Virtually no work exists concerning the turn-taking strategies that dialogue systems should pursue and how they effect human-computer interaction, except in special cases such as in Woodburn et al. (1991) for the case of conversational computer-mediated communication aids for the speech and hearing impaired or Shankar et al. (2000) for turn negotiation in text-based dialogue systems. The overview of classical HCI experiments and their results, given in Wooffitt et al. (1997), also shows that problems, such as turn-overtaking, -handling and -repairs , have not been addressed by the research community. In the following section we describe a new experimental paradigm and the first corresponding experiments tailored towards examining the effects of the computer’s communicative behavior on its human partner. More specifically, we will analyze the differences in HHI and &apos;These problems can be diminished, however, ifpeople hav</context>
</contexts>
<marker>Shankar, VanKleek, Vicente, Smith, 2000</marker>
<rawString>Tara Rosenberger Shankar, Max VanKleek, Antonio Vicente, and Brian K. Smith. 2000. A computer mediated conversational system that supports turn negotiation. In Proceedings of the Hawai’i International Conference on System Sciences, Maui, Hawaii, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eve Sweetser</author>
</authors>
<title>Levels of meaning in speech and gesture: Real space mapped onto epistemic and speech-interactional mental spaces.</title>
<date>2003</date>
<booktitle>In Proceedings of the 8th International Conference on Cognitive Linguistics,</booktitle>
<location>Logrono, Spain,</location>
<contexts>
<context position="8338" citStr="Sweetser (2003)" startWordPosition="1262" endWordPosition="1263">ystems, this inevitably causes dialogues to fail completely. We can already conclude from these informal findings that current state of the art conversational dialogue systems suffer from a) a lack of turn-taking strategies and dialogue handling capabilities as well as b) a lack of strategies for repairing dialogues once they become out ofsync. In human-human interaction (HHI) turn-taking strategies and their effects have been studied for decades in unimodal settings from Duncan (1974) and Sack et al. (1974) to Weinhammer and Rabold (2003) as well as more recently in multimodal settings as in Sweetser (2003). Virtually no work exists concerning the turn-taking strategies that dialogue systems should pursue and how they effect human-computer interaction, except in special cases such as in Woodburn et al. (1991) for the case of conversational computer-mediated communication aids for the speech and hearing impaired or Shankar et al. (2000) for turn negotiation in text-based dialogue systems. The overview of classical HCI experiments and their results, given in Wooffitt et al. (1997), also shows that problems, such as turn-overtaking, -handling and -repairs , have not been addressed by the research c</context>
</contexts>
<marker>Sweetser, 2003</marker>
<rawString>Eve Sweetser. 2003. Levels of meaning in speech and gesture: Real space mapped onto epistemic and speech-interactional mental spaces. In Proceedings of the 8th International Conference on Cognitive Linguistics, Logrono, Spain, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Wahlster</author>
<author>Norbert Reithinger</author>
<author>Anselm Blocher</author>
</authors>
<title>Smartkom: Multimodal communication with a life-like character.</title>
<date>2001</date>
<booktitle>In Proceedings of the 7th European Conference on Speech Communication and Technology.</booktitle>
<contexts>
<context position="2688" citStr="Wahlster et al., 2001" startWordPosition="402" endWordPosition="405"> of the human interactions. Differentiae stemming from the other communication partner, i. e., the computer, are not taken into account - neither on a practical nor on a theoretical level. In the past controlled and restricted interactions between the user and the system increased recognition and understanding accuracies to a level that systems became reliable enough for deployment in various real world applications, e. g., transportation or cinema information systems (Aust et al., 1995; Gorin et al., 1997; Gallwitz et al., 1998). Today’s more conversational dialogue systems, e. g., SMARTKOM (Wahlster et al., 2001) or MATCH (Johnston et al., 2002), are able to cope with much less predictable user utterances. Despite the fact that in these systems recognition and processing have become extremely difficult, the reliability thereof has been pushed towards acceptable degrees by employing an array of highly sophisticated technological advances - such as dynamic lexica for multi-domain speech recognition and flexible pronunciation models (Rapp et al., 2000), robust understanding and discourse modeling techniques (Johnston, 1998; Engel, 2002; Alexandersson and Becker, 2001) combined with ontological reasoning </context>
<context position="5723" citStr="Wahlster et al., 2001" startWordPosition="862" endWordPosition="865">died are: how does the computer’s way of communicating affect the human interlocutor, do the particulars of computer-human interaction help to explain why today’s conversational dialogue systems are by and large unusable. In this paper we claim that this shift of perspective is of paramount importance, for example, to make sense of the phenomena observable during end-to-end evaluations of conversational systems. We designed our experiments and started our initial observations using one of the most advanced conversational dialogue research prototypes existing today, i. e., the SMARTKOM system (Wahlster et al., 2001). This system designed for intuitive multimodal interaction comprises a symmetric set of input and output modalities (Wahlster, 2003), together with an efficient fusion and fission pipeline (Wahlster, 2002). SMARTKOM features speech input with prosodic analysis, gesture input via infrared camera, recognition of facial expressions and their emotional states. On the output side SMARTKOM employs a gesturing and speaking life-like character together with displayed generated text and multimedia graphical output. It currently comprised nearly 50 modules running on a parallel virtual machine-based in</context>
</contexts>
<marker>Wahlster, Reithinger, Blocher, 2001</marker>
<rawString>Wolfgang Wahlster, Norbert Reithinger, and Anselm Blocher. 2001. Smartkom: Multimodal communication with a life-like character. In Proceedings of the 7th European Conference on Speech Communication and Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Wahlster</author>
</authors>
<title>SmartKom: Fusion and fission of speech, gerstures and facial expressions.</title>
<date>2002</date>
<booktitle>In Proceedings of the Firsat International Workshop on Man-Machine Symbiotic Systems,</booktitle>
<location>Kyoto, Japan.</location>
<contexts>
<context position="5929" citStr="Wahlster, 2002" startWordPosition="893" endWordPosition="894">nusable. In this paper we claim that this shift of perspective is of paramount importance, for example, to make sense of the phenomena observable during end-to-end evaluations of conversational systems. We designed our experiments and started our initial observations using one of the most advanced conversational dialogue research prototypes existing today, i. e., the SMARTKOM system (Wahlster et al., 2001). This system designed for intuitive multimodal interaction comprises a symmetric set of input and output modalities (Wahlster, 2003), together with an efficient fusion and fission pipeline (Wahlster, 2002). SMARTKOM features speech input with prosodic analysis, gesture input via infrared camera, recognition of facial expressions and their emotional states. On the output side SMARTKOM employs a gesturing and speaking life-like character together with displayed generated text and multimedia graphical output. It currently comprised nearly 50 modules running on a parallel virtual machine-based integration software called MULTIPLATFORM (Herzog et al., 2003). As such it is certainly among the most advanced multi-domain conversational dialogue systems. To the best of our knowledge, there has not been </context>
</contexts>
<marker>Wahlster, 2002</marker>
<rawString>Wolfgang Wahlster. 2002. SmartKom: Fusion and fission of speech, gerstures and facial expressions. In Proceedings of the Firsat International Workshop on Man-Machine Symbiotic Systems, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Wahlster</author>
</authors>
<title>SmartKom: Symmetric multimodality in an adaptive an reusable dialog shell.</title>
<date>2003</date>
<booktitle>In Proceedings of the Human Computer Interaction Status Conference,</booktitle>
<location>Berlin, Germany.</location>
<contexts>
<context position="5856" citStr="Wahlster, 2003" startWordPosition="883" endWordPosition="884">to explain why today’s conversational dialogue systems are by and large unusable. In this paper we claim that this shift of perspective is of paramount importance, for example, to make sense of the phenomena observable during end-to-end evaluations of conversational systems. We designed our experiments and started our initial observations using one of the most advanced conversational dialogue research prototypes existing today, i. e., the SMARTKOM system (Wahlster et al., 2001). This system designed for intuitive multimodal interaction comprises a symmetric set of input and output modalities (Wahlster, 2003), together with an efficient fusion and fission pipeline (Wahlster, 2002). SMARTKOM features speech input with prosodic analysis, gesture input via infrared camera, recognition of facial expressions and their emotional states. On the output side SMARTKOM employs a gesturing and speaking life-like character together with displayed generated text and multimedia graphical output. It currently comprised nearly 50 modules running on a parallel virtual machine-based integration software called MULTIPLATFORM (Herzog et al., 2003). As such it is certainly among the most advanced multi-domain conversat</context>
</contexts>
<marker>Wahlster, 2003</marker>
<rawString>Wolfgang Wahlster. 2003. SmartKom: Symmetric multimodality in an adaptive an reusable dialog shell. In Proceedings of the Human Computer Interaction Status Conference, Berlin, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn Walker</author>
<author>Diane Litman</author>
<author>Candace Kamm</author>
<author>Alicia Abella</author>
</authors>
<title>PARADISE: A framework for evaluating spoken dialogue agents.</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Madrid,</location>
<contexts>
<context position="14771" citStr="Walker et al., 1997" startWordPosition="2294" endWordPosition="2297">moved the original list, dialed the system’s number on the phone and exited from the room after handing over the telephone receiver. The subject was always greeted by the system’s standard opening ply: Welcome to the Heidelberger tourist information system. How I can help you? After three tasks were finished (some successful some not) the assistant simulated the system’s break down and entered the line by saying Excuse me, something seems to have happened with our system, may I assist you from here on and finishing the remaining three tasks with the subjects. 4 Results The PARADISE framework (Walker et al., 1997; Walker et al., 2000) proposes distinct measurements for dialogue quality, dialogue efficiency and task success metrics. The remaining criterion, i. e., user satisfaction, is based on questionaries and interviews with the subjects and cannot be extracted (sub)automatically from logfiles. The analyses of the experiments described herein focus mainly on dialogue efficency metrics in the sense of Walker et al. (2000). As we will show below, our findings strongly suggest that a felicitous dialogue is not only a function of dialogue quality, but critically hinges on a minimal threshold of efficien</context>
</contexts>
<marker>Walker, Litman, Kamm, Abella, 1997</marker>
<rawString>Marilyn Walker, Diane Litman, Candace Kamm, and Alicia Abella. 1997. PARADISE: A framework for evaluating spoken dialogue agents. In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn A Walker</author>
<author>Candace A Kamm</author>
<author>Diane J Litman</author>
</authors>
<title>Towards developing general model of usability with PARADISE.</title>
<date>2000</date>
<journal>Natural Language Engeneering,</journal>
<volume>6</volume>
<contexts>
<context position="3687" citStr="Walker et al. (2000)" startWordPosition="547" endWordPosition="550"> recognition and flexible pronunciation models (Rapp et al., 2000), robust understanding and discourse modeling techniques (Johnston, 1998; Engel, 2002; Alexandersson and Becker, 2001) combined with ontological reasoning capabilities (Gurevych et al., 2003; Porzel et al., 2003). However, the usability of such conversational dialogue systems is still unsatisfactory, as shown in usability experiments with real users (Beringer, 2003) that employed the PROMISE evaluation framework described in Beringer et al. (2002), which offers some multimodal extentions over the PARADISE framework described in Walker et al. (2000) . The work described herein constitutes a starting point for a scientific examination of the whys and wherefores of the challenging results stemming from such end-to-end evaluations of conversational dialogue systems. Following a brief description of the state of the art in examinations of computer-directed language, we describe a new experimental paradigm, the first two studies using the paradigm and their corresponding results. Concluding, we discuss the ensuing implications for the design of successful and felicitous conversational dialogue systems. 2 Studies on Human-Computer Dialogues Th</context>
<context position="14793" citStr="Walker et al., 2000" startWordPosition="2298" endWordPosition="2301">st, dialed the system’s number on the phone and exited from the room after handing over the telephone receiver. The subject was always greeted by the system’s standard opening ply: Welcome to the Heidelberger tourist information system. How I can help you? After three tasks were finished (some successful some not) the assistant simulated the system’s break down and entered the line by saying Excuse me, something seems to have happened with our system, may I assist you from here on and finishing the remaining three tasks with the subjects. 4 Results The PARADISE framework (Walker et al., 1997; Walker et al., 2000) proposes distinct measurements for dialogue quality, dialogue efficiency and task success metrics. The remaining criterion, i. e., user satisfaction, is based on questionaries and interviews with the subjects and cannot be extracted (sub)automatically from logfiles. The analyses of the experiments described herein focus mainly on dialogue efficency metrics in the sense of Walker et al. (2000). As we will show below, our findings strongly suggest that a felicitous dialogue is not only a function of dialogue quality, but critically hinges on a minimal threshold of efficiency and overall dialogu</context>
<context position="16330" citStr="Walker et al. (2000)" startWordPosition="2547" endWordPosition="2550">mining dialogue felicity we will provide detailed analyses of efficiency metrics per se as well as additional metrics for examining the number and effect of pauses, the employment of feedback and turn-taking signals and the amount of overlaps. The Data: The length of the dialogues was on average 5 minutes for the German (G) and 6 minutes for the English (E) sessions. The subjects featured approximately proportional mixtures of gender (25m,18f), age (12 71) and computer expertise. Table 1 shows the duration and turns per phase of the experiment. Measurements: First of all, we apply the classic Walker et al. (2000) metric for measuring dialogue efficiency, by calculating the number of turns over dialogue length. Figure 2 shows the discrepancy between the dialogue efficiency in Phase 1 (HCI) versus Phase 2 2The shortest dialogues were 3:18 (E) and 3:30 (G) and the longest 12:05 (E) and 10:08 (G). (HHI) of the German experiment and Figure 3 shows that the same patterns can be observed for English. Phase HHI G HHI E HCI G HCI E Average 1:52 2:30 2:59 3:23 length min. min. min. min. Average turns 11.35 21.25 9.2 7.4 Table 1: Average length and turns in Phase 1 and 2 Figure 2: Dialogue efficiency (German dat</context>
</contexts>
<marker>Walker, Kamm, Litman, 2000</marker>
<rawString>Marilyn A. Walker, Candace A. Kamm, and Diane J. Litman. 2000. Towards developing general model of usability with PARADISE. Natural Language Engeneering, 6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karl Weinhammer</author>
<author>Susan Rabold</author>
</authors>
<title>Durational Aspects in Turn Taking.</title>
<date>2003</date>
<booktitle>In Proceedings of International Conference Phonetic Sciences,</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="8268" citStr="Weinhammer and Rabold (2003)" startWordPosition="1248" endWordPosition="1251"> the current state of the art regarding the dialogue handling capabilities of HCI systems, this inevitably causes dialogues to fail completely. We can already conclude from these informal findings that current state of the art conversational dialogue systems suffer from a) a lack of turn-taking strategies and dialogue handling capabilities as well as b) a lack of strategies for repairing dialogues once they become out ofsync. In human-human interaction (HHI) turn-taking strategies and their effects have been studied for decades in unimodal settings from Duncan (1974) and Sack et al. (1974) to Weinhammer and Rabold (2003) as well as more recently in multimodal settings as in Sweetser (2003). Virtually no work exists concerning the turn-taking strategies that dialogue systems should pursue and how they effect human-computer interaction, except in special cases such as in Woodburn et al. (1991) for the case of conversational computer-mediated communication aids for the speech and hearing impaired or Shankar et al. (2000) for turn negotiation in text-based dialogue systems. The overview of classical HCI experiments and their results, given in Wooffitt et al. (1997), also shows that problems, such as turn-overtaki</context>
</contexts>
<marker>Weinhammer, Rabold, 2003</marker>
<rawString>Karl Weinhammer and Susan Rabold. 2003. Durational Aspects in Turn Taking. In Proceedings of International Conference Phonetic Sciences, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Woodburn</author>
<author>R Procter</author>
<author>J Arnott</author>
<author>A Newell</author>
</authors>
<title>A study of conversational turn-taking in a communication aid for the disabled.</title>
<date>1991</date>
<booktitle>In People and Computers,</booktitle>
<pages>359--371</pages>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="8544" citStr="Woodburn et al. (1991)" startWordPosition="1290" endWordPosition="1293">f turn-taking strategies and dialogue handling capabilities as well as b) a lack of strategies for repairing dialogues once they become out ofsync. In human-human interaction (HHI) turn-taking strategies and their effects have been studied for decades in unimodal settings from Duncan (1974) and Sack et al. (1974) to Weinhammer and Rabold (2003) as well as more recently in multimodal settings as in Sweetser (2003). Virtually no work exists concerning the turn-taking strategies that dialogue systems should pursue and how they effect human-computer interaction, except in special cases such as in Woodburn et al. (1991) for the case of conversational computer-mediated communication aids for the speech and hearing impaired or Shankar et al. (2000) for turn negotiation in text-based dialogue systems. The overview of classical HCI experiments and their results, given in Wooffitt et al. (1997), also shows that problems, such as turn-overtaking, -handling and -repairs , have not been addressed by the research community. In the following section we describe a new experimental paradigm and the first corresponding experiments tailored towards examining the effects of the computer’s communicative behavior on its huma</context>
</contexts>
<marker>Woodburn, Procter, Arnott, Newell, 1991</marker>
<rawString>R. Woodburn, R. Procter, J. Arnott, and A. Newell. 1991. A study of conversational turn-taking in a communication aid for the disabled. In People and Computers, pages 359–371. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robin Wooffitt</author>
<author>Nigel Gilbert</author>
<author>Norman Fraser</author>
<author>Scott McGlashan</author>
</authors>
<title>Humans, Computers and Wizards: Conversation Analysis and Human (Simulated) Computer Interaction.</title>
<date>1997</date>
<location>Brunner-Routledge, London.</location>
<contexts>
<context position="1399" citStr="Wooffitt et al. (1997)" startWordPosition="200" endWordPosition="203">of a more comprehensive view on dialogue felicity as a function of dialogue quality and efficiency. 1 Introduction Research on dialogue systems in the past has focused on engineering the various processing stages involved in dialogical human-computer interaction (HCI) - e.g., robust automatic speech recognition, intention recognition, natural language generation or speech synthesis (cf. Allen et al. (1996), Cox et al. (2000) or Bailly et al. (2003)). Alongside these efforts the characteristics of computer-directed language have also been examined as a general phenomenon (cf. Zoeppritz (1985), Wooffitt et al. (1997) or Darves and Oviatt (2002)). The flip side, i. e., computer-human interaction (CHI), has received very little attention as a research question by itself. That is not to say that natural language generation and synthesis have not made vast improvements, but rather that the nature and design of the computer as an interlocutor itself, i. e., the effects of human-directed language, have not been scrutinized as such. Looking at broad levels of distinctions for dialogue systems, e.g., that of Allen et al. (2001) between controlled and conversational dialogue systems, we note the singular employmen</context>
<context position="8819" citStr="Wooffitt et al. (1997)" startWordPosition="1333" endWordPosition="1336">om Duncan (1974) and Sack et al. (1974) to Weinhammer and Rabold (2003) as well as more recently in multimodal settings as in Sweetser (2003). Virtually no work exists concerning the turn-taking strategies that dialogue systems should pursue and how they effect human-computer interaction, except in special cases such as in Woodburn et al. (1991) for the case of conversational computer-mediated communication aids for the speech and hearing impaired or Shankar et al. (2000) for turn negotiation in text-based dialogue systems. The overview of classical HCI experiments and their results, given in Wooffitt et al. (1997), also shows that problems, such as turn-overtaking, -handling and -repairs , have not been addressed by the research community. In the following section we describe a new experimental paradigm and the first corresponding experiments tailored towards examining the effects of the computer’s communicative behavior on its human partner. More specifically, we will analyze the differences in HHI and &apos;These problems can be diminished, however, ifpeople have multiple sessions with the system and adapt to the respective system’s behavior. HCI/CHI turn-taking and dialogue management strategies, which, </context>
</contexts>
<marker>Wooffitt, Gilbert, Fraser, McGlashan, 1997</marker>
<rawString>Robin Wooffitt, Nigel Gilbert, Norman Fraser, and Scott McGlashan. 1997. Humans, Computers and Wizards: Conversation Analysis and Human (Simulated) Computer Interaction. Brunner-Routledge, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Yngve</author>
</authors>
<title>On getting a word in edgewise.</title>
<date>1970</date>
<booktitle>In Papers from the Sixth Regional Meeting of the Chicago Linguistic Society,</booktitle>
<location>Chicago, Illinois,</location>
<contexts>
<context position="19020" citStr="Yngve (1970)" startWordPosition="2991" endWordPosition="2992">07 0.07 deviation Table 2: Overall dialogue efficiencies with pauses +p and without pauses -p. Next to this pause-effect, which contributes greatly to dialogue efficiency metrics by increasing dialogue length, we have to take a closer look at the individual turns and their nature. While some turns carry propositional information and constitute utterances proper, a significant number solely consists of specific particles used to exchange signals between the communicative partners or combinations thereof. We differentiate between dialogue-structuring signals and feedback signals in the sense of Yngve (1970). Dialogue-structuring signals - such as hesitations like hmm or ah as well as expressions like well, yes, so - mark the intent to begin or end an utterances, make corrections or insertions. Feedback signalswhile sometimes phonetically alike - such as right, yes or hmm - do not express the intent to take over or give up the speaking role, but rather serve as a means to stay in contact with the speaker, which is why they are sometimes referred to as contact signals. Pauses HCI-G HHI-G HCI-E HHI-E Number 79 10 94 21 total Number 3.95 0.5 4.7 1.05 per dialog Number 0.46 0.05 0.64 0.05 per turn to</context>
</contexts>
<marker>Yngve, 1970</marker>
<rawString>V Yngve. 1970. On getting a word in edgewise. In Papers from the Sixth Regional Meeting of the Chicago Linguistic Society, Chicago, Illinois, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Magdalena Zoeppritz</author>
</authors>
<title>Computer talk?</title>
<date>1985</date>
<tech>Technical report,</tech>
<institution>IBM Scientific Center Heidelberg</institution>
<contexts>
<context position="1375" citStr="Zoeppritz (1985)" startWordPosition="198" endWordPosition="199"> an integral part of a more comprehensive view on dialogue felicity as a function of dialogue quality and efficiency. 1 Introduction Research on dialogue systems in the past has focused on engineering the various processing stages involved in dialogical human-computer interaction (HCI) - e.g., robust automatic speech recognition, intention recognition, natural language generation or speech synthesis (cf. Allen et al. (1996), Cox et al. (2000) or Bailly et al. (2003)). Alongside these efforts the characteristics of computer-directed language have also been examined as a general phenomenon (cf. Zoeppritz (1985), Wooffitt et al. (1997) or Darves and Oviatt (2002)). The flip side, i. e., computer-human interaction (CHI), has received very little attention as a research question by itself. That is not to say that natural language generation and synthesis have not made vast improvements, but rather that the nature and design of the computer as an interlocutor itself, i. e., the effects of human-directed language, have not been scrutinized as such. Looking at broad levels of distinctions for dialogue systems, e.g., that of Allen et al. (2001) between controlled and conversational dialogue systems, we not</context>
<context position="4458" citStr="Zoeppritz (1985)" startWordPosition="663" endWordPosition="664">such end-to-end evaluations of conversational dialogue systems. Following a brief description of the state of the art in examinations of computer-directed language, we describe a new experimental paradigm, the first two studies using the paradigm and their corresponding results. Concluding, we discuss the ensuing implications for the design of successful and felicitous conversational dialogue systems. 2 Studies on Human-Computer Dialogues The first studies and descriptions of the particularities of dialogical human-computer interaction, then labeled as computer talk in analogy to baby talk by Zoeppritz (1985), focused - much like subsequent ones - on: proving that a regular register for humans conversing with dialogue system exists, e. g., those of Krause (1992) and Fraser (1993), describing the regularities and characteristics of that register, as in Kritzenberger (1992) or Darves and Oviatt (2002). The results of these studies clearly show that such a register exists and that its regularities can be replicated and observed again and again. In general, this work focuses on the question: what changes happen to human verbal behavior when they talk to computers as opposed to fellow humans? The quest</context>
</contexts>
<marker>Zoeppritz, 1985</marker>
<rawString>Magdalena Zoeppritz. 1985. Computer talk? Technical report, IBM Scientific Center Heidelberg Technical Report 85.05.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>