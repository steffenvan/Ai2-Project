<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.013011">
<title confidence="0.985081">
Conciseness through Aggregation in Text Generation
</title>
<author confidence="0.984832">
James Shaw
</author>
<affiliation confidence="0.9963515">
Dept. of Computer Science
Columbia University
</affiliation>
<address confidence="0.985997">
New York, NY 10027, USA
</address>
<email confidence="0.972144">
shawOcs.columbia.edu
</email>
<sectionHeader confidence="0.977016" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999631333333334">
Aggregating different pieces of similar in-
formation is necessary to generate concise
and easy to understand reports in techni-
cal domains. This paper presents a general
algorithm that combines similar messages
in order to generate one or more coherent
sentences for them. The process is not as
trivial as might be expected. Problems en-
countered are briefly described.
</bodyText>
<sectionHeader confidence="0.971048" genericHeader="keywords">
1 Motivation
</sectionHeader>
<bodyText confidence="0.999840172413793">
Aggregation is any syntactic process that allows the
expression of concise and tightly constructed text
such as coordination or subordination. By using the
parallelism of syntactic structure to express similar
information, writers can convey the same amount
of information in a shorter space. Coordination
has been the object of considerable research (for an
overview, see (van Oirsouw87)). In contrast to lin-
guistic approaches, which are generally analytic, the
treatment of coordination in this paper is from a
synthetic point of view — text generation. It raises
issues such as deciding when and how to coordinate.
An algorithm for generating coordinated sentences is
implemented in PLANDoc (Kukich et al.93; McKe-
own et al.94), an automated documentation system.
PLANDoc generates natural language reports
based on the interaction between telephone planning
engineers and LEIS-PLAN&apos;, a knowledge based sys-
tem. Input to PLANDoc is a series of messages, or
semantic functional descriptions (FD, Fig. 1). Each
FD is an atomic decision about telephone equipment
installation chosen by a planning engineer. The do-
main of discourse is currently limited to 31 mes-
sage types, but user interactions include many vari-
ations and combinations of these messages. Instead
of generating four separate messages as in Fig. 2,
PLANDoc combines them and generates the follow-
ing two sentences: &amp;quot;This refinement activated DLC
for CSAs 3122 and 3130 in the first quarter of 1994
</bodyText>
<footnote confidence="0.98672875">
&apos;LEIS is a registered trademark of Bell Communica-
tions Research, Piscataway, NJ.
and ALL-DLC for CSA 3134 in 1994 Q3. It also
activated DSS-DLC for CSA 3208 in 1994 Q3.&amp;quot;
</footnote>
<sectionHeader confidence="0.614234" genericHeader="introduction">
2 System Architecture
</sectionHeader>
<bodyText confidence="0.999275933333333">
Fig. 3 is an overview of PLANDoc&apos;s architecture.
Input to the message generator comes from LEIS-
PLAN tracking files which record user&apos;s actions dur-
ing a planning session. The ontologizer adds hier-
archical structure to messages to facilitate further
processing. The content planner organizes the over-
all narrative and determines the linear order of the
messages. This includes combining atomic messages
into aggregated messages, choosing cue words, and
determining paraphrases that maintain focus and
ensure coherence. Finally the FUF/SURGE pack-
age (Elhadad91; Robin94) lexicalizes the messages
and maps case roles into syntactic roles, builds the
constituent structure of the sentence, ensures agree-
ment, and generates the surface sentences.
</bodyText>
<sectionHeader confidence="0.94477" genericHeader="method">
3 Combining Strategy
</sectionHeader>
<bodyText confidence="0.99942575">
Because PLANDoc can produce many paraphrases
for a single message, aggregation during the syntac-
tic phase of generation would be difficult; semanti-
cally similar messages would already have different
surface forms. As a result, aggregation in PLANDoc
is carried out at the content planning level using se-
mantic FDs. Three main criteria were used to design
the combining strategy:
</bodyText>
<listItem confidence="0.996282">
1. domain independence: the algorithm should
be applicable in other domains.
2. generating the most concise text: it should
avoid repetition of phrases to generate shortest
text.
</listItem>
<figure confidence="0.524144">
((cat message)
(admin ((PLANDoc-message-name RDA)
(runid r-regl)))
(class refinement)
(action activation)
(equipment-type all-d1c)
(csa-site 3134)
(date ((year 1994) (quarter 3))))
</figure>
<figureCaption confidence="0.999254">
Figure 1: Output of the Message Generator
</figureCaption>
<page confidence="0.982202">
329
</page>
<bodyText confidence="0.44664075">
This refinement activated ALL-DLC for CSA 3134 in 1994 Q3. (El 53 D2)
This refinement activated DLC for CSA 3130 in 1994 Qi. (E2 S2 D1)
This refinement activated DSS-DLC for CSA 3208 in 1994 Q3. (E3 S4 D2)
This refinement activated DLC for CSA 3122 in 1994 Qi. (E2 51 D1)
</bodyText>
<figure confidence="0.612301">
Equipment: El= ALL-DLC, E2= DLC, E3= DSS-DLC
Site: S1= CSA 3122, S2= CSA 3130, S3= CSA 3134, S4= CSA 3208
Date: Dl= 1994 Qi, D2= 1994 Q3
</figure>
<figureCaption confidence="0.818012">
Figure 2: Unaggregated Text Output
</figureCaption>
<figure confidence="0.873325">
LEIS- Message Ontologizer Content Lexicalizer Surface PLANDoc
PLAN Generator (FUF) Planner (FUF) Generator Narrative
(C) (C) (Lisp) (SURGE) (text)
■.1.1
</figure>
<figureCaption confidence="0.998927">
Figure 3: PLANDoc System Architecture
</figureCaption>
<bodyText confidence="0.974936166666667">
3. avoidance of overly-complex sentences: it
should not generate sentences that are too com-
plex or ambiguous for readers.
The first aggregation step is to identify semantically
related messages. This is done by grouping messages
with the same action attribute. Then the system at-
tempts to generate concise and unambiguous text
for each action group separately. This reduces the
problem size from tens of messages into much smaller
sizes. Though this heuristic disallows the combina-
tion of messages with different actions, the messages
in each action group already contain enough infor-
mation to produce quite complex sentences.
The system combines the maximum number of re-
lated messages to meet the second design criterion—
generating the most concise text. But such combi-
nation is blocked when a sentence becomes too com-
plex. A bottom-up 4-step algorithm was developed:
</bodyText>
<listItem confidence="0.998768555555556">
1. Sorting: putting similar messages right next to
each other.
2. Merging Same Attribute: combining adja-
cent messages that only have one distinct at-
tribute.
3. Identity Deletion: deletion of identical com-
ponents across messages.
4. Sentence Breaking: determining sentence
breaks.
</listItem>
<subsectionHeader confidence="0.995915">
3.1 Step 1: Sorting
</subsectionHeader>
<bodyText confidence="0.99998725">
The system first ranks the attributes to determine
which are most similar across messages with the
same action. For each potential distinct attribute,
the system calculates its rank using the formula
in — d, where m is the number of messages and d
is the number of distinct attributes for that par-
ticular attribute. The rank is an indicator of how
similar an attribute is across the messages. Com-
bining messages according to the highest ranking
attribute ensures that minimum text will be gen-
erated for these messages. Based on the ranking,
the system reorders the messages by sorting, which
</bodyText>
<equation confidence="0.9022488">
(E2 Si D1) (El S3 D2) (E2 Si D1)
(E2 S2 D1) (E2 Si D1) (E2 S2 D1)
(El S3 D2) --&gt; (E2 S2 D1) --&gt; (El S3 D2)
(E3 S4 D2) (E3 S4 D2) (E3 S4 D2)
by Site by Equipment by Date
</equation>
<figureCaption confidence="0.988984">
Figure 4: Step 1. Sorting
</figureCaption>
<bodyText confidence="0.999946">
puts the messages that have the same attribute right
next to each other. In Fig. 2, equipment has rank
1 because it has 3 distinct equipment values — ALL-
DLC, DLC, and DSS-DLC; date has rank 2 because
it has two distinct date values — 1994 Q1 and 1994
Q3; site has rank 0. Attribute class and action (Fig.
1) are ignored because they are always the same at
this stage. When two attributes have the same rank,
the system breaks the tie based on a priority hierar-
chy determined by the domain experts. Because the
final sorting operation dominates the order of the
resulting messages, PLANDoc sorts the message list
from the lowest rank attribute to the highest. In this
case, the ordering for sorting is site, equipment, and
then date. The resulting message list after sorting
each attribute is shown in Fig. 4.
</bodyText>
<subsectionHeader confidence="0.999514">
3.2 Step 2: Merging Same Attribute
</subsectionHeader>
<bodyText confidence="0.999780058823529">
The list of sorted messages is traversed. When-
ever there is only one distinct attribute between
two adjacent messages, they are merged into one
message with a conjoined attribute, which is a
list of the distinct attributes from both messages.
What about messages with two or more distinct at-
tributes? Merging two messages with two or more
distinct attributes will result in a syntactically valid
sentence but with an undesirable meaning: &amp;quot;*This
refinement activated ALL-DLC and DSS-DLC for
CSAs 3122 and 3130 in the third quarter of 1993.&amp;quot;
By tracking which attribute is compound, a third
message can be merged into the aggregate message
if it also has the same distinct attribute. Continue
from Step 1, (E2 Si D1) and (E2 S2 D1) are merged
because they have only one distinct attribute, site.
A new FD, (E2 (Si S2) D1), is assembled to replace
</bodyText>
<page confidence="0.994519">
330
</page>
<bodyText confidence="0.999891272727273">
those two messages. Note that although (El S3 D2)
and (E3 S4 D2) have the date in common, they are
not combined because they have more than one dis-
tinct attribute, site and equipment.
Step 2 is applied to the message list recursively
to generate possible crossing conjunction, as in the
following output which merges four messages: &amp;quot;This
refinement activated ALL-DLC and DSS-DLC for
CSAs 3122 and 3130 in the third quarter of 1993.&amp;quot;
Though on the outset this phenomenon seems un-
likely, it does happen in our domain.
</bodyText>
<subsectionHeader confidence="0.991784">
3.3 Step 3: Identity Deletion
</subsectionHeader>
<bodyText confidence="0.999945428571429">
After merging at step 2, the message list left in an
action group either has only one message, or it has
more than one message with at least two distinct
attributes between them. Instead of generating two
separate sentences for (E2 (Si S2) D1) and (El S3
D2), the system realizes that both the subject and
verb are the same, thus it uses deletion on identity to
generate &amp;quot;This refinement activated DLC for CSAs
3122 and 3130 in 1994 Q1 and [this refinement ac-
tivated] ALL-DLC for CSA 3134 in 1994 Q3.&amp;quot; For
identical attributes across two messages (as shown
in the bracketed phrase), a &amp;quot;deletion&amp;quot; feature is in-
serted into the semantic FD, so that SURGE will
suppress the output.
</bodyText>
<subsectionHeader confidence="0.985749">
3.4 Step 4: Sentence Break
</subsectionHeader>
<bodyText confidence="0.99998559375">
Applying deletion on identity blindly to the whole
message list might make the generated text incom-
prehensible because readers might have to recover
too much implicit information from the sentence.
As a result, the combining algorithm must have a
way to determine when to break the messages into
separate sentences that are easy to understand and
unambiguous.
How much information to pack into a sentence
does not depend on grammaticality, but on coher-
ence, comprehensibility, and aesthetics which are
hard to formalize. PLANDoc uses a heuristic that
always joins the first and second messages, and con-
tinues to do so for third and more if the distinct
attributes between the messages are the same. This
heuristics results in parallel syntactic structure and
the underlying semantics can be easily recovered.
Once the distinct attributes are different from the
combined messages, the system starts a new sen-
tence. Using the same example, (E2 (51 S2) D1) and
(El S3 D2) have three distinct attributes. They are
combined because they are the first two messages.
Comparing the third message (E3 S4 D2) to (El S3
D2), they have different equipment and site, but not
date, so a sentence break will take place between
them. Aggregating all three messages together will
results in questionable output. Because of the par-
allel structure created between the first 2 messages,
readers are expecting a different date when reading
the third clause. The second occurrence of &amp;quot;1994
Q3&amp;quot; in the same sentence does not agree with read-
ers&apos; expectation thus potentially confusing.
</bodyText>
<sectionHeader confidence="0.998824" genericHeader="method">
4 Future Directions
</sectionHeader>
<bodyText confidence="0.999961461538462">
In this paper, I have described a general algorithm
which not only reduces the amount of the text pro-
duced, but also increases the fluency of the text.
While other systems do generate conjunctions, they
deal with restricted cases such as conjunction of sub-
jects and predicates(Dalianis&amp;Hovy93). There are
other interesting problems in aggregations. Gener-
ating marker words to indicate relationships in con-
joined structures, such as &amp;quot;respectively&amp;quot;, is another
short term goal. Extending the current aggregation
algorithm to be more general is currently being in-
vestigated, such as combining related messages with
different actions.
</bodyText>
<sectionHeader confidence="0.999319" genericHeader="conclusions">
5 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999968333333333">
The author thanks Prof. Kathleen McKeown, and
Dr. Karen Kukich at Bellcore for their advice and
support. This research was conducted while sup-
ported by Bellcore project #CU01403301A1, and
under the auspices of the Columbia University CAT
in High Performance Computing and Communica-
tions in Healthcare, a New York State Center for
Advanced Technology supported by the New York
State Science and Technology Foundation.
</bodyText>
<sectionHeader confidence="0.999075" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99913344">
Dalianis, Hercules, and Hovy, Edward. 1993. Ag-
gregation in Natural Language Generation. In
Proceedings of the Fourth European Workshop on
Natural Language Generation, Pisa, Italy.
Elhadad, Michael. 1991. FUF: The universal unifier
- user manual, version 5.0. Tech Report CUCS-
038-91, Columbia Univ.
Robin, Jacques. 1994. Revision-Based Generation
of Natural Language Summaries Providing Histor-
ical Background: Corpus-based analysis, design,
implementation and evaluation. Ph.D. thesis,
Computer Science Department, Columbia Univ.
Kukich, K., McKeown, K., Morgan, N., Phillips, J.,
Robin, J., Shaw, J., and Lim, J. 1993. User-Needs
Analysis and Design Methodology for an Auto-
mated Documentation Generator. In Proceedings
of the Fourth Bellcore/BCC Symposium on User-
Centered Design, Piscataway, NJ.
McKeown, Kathleen, Kukich, Karen, and Shaw,
James. 1994. Practical Issues in Automatic Doc-
umentation Generation. In Proceedings of the 4th
Conference on Applied Natural Language Process-
ing, Stuttgart, p.7-14.
van Oirsouw, Robert. 1987. The Syntax of Coordi-
nation Beckenham: Croom Helm.
</reference>
<page confidence="0.998807">
331
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000288">
<title confidence="0.999617">Conciseness through Aggregation in Text Generation</title>
<author confidence="0.99998">James Shaw</author>
<affiliation confidence="0.9999005">Dept. of Computer Science Columbia University</affiliation>
<address confidence="0.999833">New York, NY 10027, USA</address>
<email confidence="0.999872">shawOcs.columbia.edu</email>
<abstract confidence="0.942100901234568">Aggregating different pieces of similar information is necessary to generate concise and easy to understand reports in technical domains. This paper presents a general algorithm that combines similar messages in order to generate one or more coherent sentences for them. The process is not as trivial as might be expected. Problems encountered are briefly described. 1 Motivation Aggregation is any syntactic process that allows the expression of concise and tightly constructed text such as coordination or subordination. By using the parallelism of syntactic structure to express similar information, writers can convey the same amount of information in a shorter space. Coordination has been the object of considerable research (for an overview, see (van Oirsouw87)). In contrast to linguistic approaches, which are generally analytic, the treatment of coordination in this paper is from a synthetic point of view — text generation. It raises issues such as deciding when and how to coordinate. An algorithm for generating coordinated sentences is implemented in PLANDoc (Kukich et al.93; McKeown et al.94), an automated documentation system. PLANDoc generates natural language reports based on the interaction between telephone planning engineers and LEIS-PLAN&apos;, a knowledge based system. Input to PLANDoc is a series of messages, or semantic functional descriptions (FD, Fig. 1). Each FD is an atomic decision about telephone equipment installation chosen by a planning engineer. The domain of discourse is currently limited to 31 message types, but user interactions include many variations and combinations of these messages. Instead of generating four separate messages as in Fig. 2, PLANDoc combines them and generates the followtwo sentences: refinement activated DLC for CSAs 3122 and 3130 in the first quarter of 1994 &apos;LEIS is a registered trademark of Bell Communications Research, Piscataway, NJ. and ALL-DLC for CSA 3134 in 1994 Q3. It also DSS-DLC for CSA 3208 in 1994 2 System Architecture Fig. 3 is an overview of PLANDoc&apos;s architecture. Input to the message generator comes from LEIS- PLAN tracking files which record user&apos;s actions during a planning session. The ontologizer adds hierarchical structure to messages to facilitate further processing. The content planner organizes the overall narrative and determines the linear order of the messages. This includes combining atomic messages into aggregated messages, choosing cue words, and determining paraphrases that maintain focus and ensure coherence. Finally the FUF/SURGE package (Elhadad91; Robin94) lexicalizes the messages and maps case roles into syntactic roles, builds the constituent structure of the sentence, ensures agreement, and generates the surface sentences. 3 Combining Strategy Because PLANDoc can produce many paraphrases for a single message, aggregation during the syntactic phase of generation would be difficult; semantically similar messages would already have different surface forms. As a result, aggregation in PLANDoc is carried out at the content planning level using semantic FDs. Three main criteria were used to design the combining strategy: 1. domain independence: the algorithm should be applicable in other domains. 2. generating the most concise text: it should avoid repetition of phrases to generate shortest text. (admin ((PLANDoc-message-name RDA) (runid r-regl))) (class refinement) (action activation) (equipment-type all-d1c) (csa-site 3134) ((year 1994) (quarter</abstract>
<note confidence="0.742598866666667">Figure 1: Output of the Message Generator 329 This refinement activated ALL-DLC for CSA 3134 in 1994 Q3. (El 53 D2) This refinement activated DLC for CSA 3130 in 1994 Qi. (E2 S2 D1) This refinement activated DSS-DLC for CSA 3208 in 1994 Q3. (E3 S4 D2) This refinement activated DLC for CSA 3122 in 1994 Qi. (E2 51 D1) Equipment: El= ALL-DLC, E2= DLC, E3= DSS-DLC S1= CSA 3122, S2= CSA 3130, S3= CSA 3134, CSA 3208 Date: Dl= 1994 Qi, D2= 1994 Q3 Figure 2: Unaggregated Text Output LEIS- Message Ontologizer (FUF) Content Lexicalizer Surface PLANDoc PLAN Generator Planner (FUF) Generator Narrative (C) (C) (Lisp) (SURGE) (text) ■.1.1 Figure 3: PLANDoc System Architecture</note>
<abstract confidence="0.993122558441558">of overly-complex sentences: should not generate sentences that are too complex or ambiguous for readers. The first aggregation step is to identify semantically related messages. This is done by grouping messages with the same action attribute. Then the system attempts to generate concise and unambiguous text for each action group separately. This reduces the problem size from tens of messages into much smaller sizes. Though this heuristic disallows the combination of messages with different actions, the messages in each action group already contain enough information to produce quite complex sentences. The system combines the maximum number of related messages to meet the second design criterion— generating the most concise text. But such combination is blocked when a sentence becomes too complex. A bottom-up 4-step algorithm was developed: Sorting: similar messages right next to each other. Merging Same Attribute: adjacent messages that only have one distinct attribute. Identity Deletion: of identical components across messages. Sentence Breaking: sentence breaks. 3.1 Step 1: Sorting The system first ranks the attributes to determine which are most similar across messages with the same action. For each potential distinct attribute, the system calculates its rank using the formula — m is the number of messages and is the number of distinct attributes for that particular attribute. The rank is an indicator of how similar an attribute is across the messages. Combining messages according to the highest ranking attribute ensures that minimum text will be generated for these messages. Based on the ranking, the system reorders the messages by sorting, which (E2 Si D1) (El S3 D2) (E2 Si D1) (E2 S2 D1) (E2 Si D1) (E2 S2 D1) (El S3 D2) --&gt; (E2 S2 D1) --&gt; (El S3 D2) (E3 S4 D2) (E3 S4 D2) (E3 S4 D2) by Site by Equipment by Date Figure 4: Step 1. Sorting puts the messages that have the same attribute right to each other. In Fig. 2, rank 1 because it has 3 distinct equipment values — ALL- DLC, and DSS-DLC; rank 2 because it has two distinct date values — 1994 Q1 and 1994 rank 0. Attribute 1) are ignored because they are always the same at this stage. When two attributes have the same rank, the system breaks the tie based on a priority hierarchy determined by the domain experts. Because the final sorting operation dominates the order of the resulting messages, PLANDoc sorts the message list from the lowest rank attribute to the highest. In this the ordering for sorting is equipment, resulting message list after sorting each attribute is shown in Fig. 4. 3.2 Step 2: Merging Same Attribute The list of sorted messages is traversed. Whenever there is only one distinct attribute between two adjacent messages, they are merged into one message with a conjoined attribute, which is a list of the distinct attributes from both messages. What about messages with two or more distinct attributes? Merging two messages with two or more distinct attributes will result in a syntactically valid but with an undesirable meaning: refinement activated ALL-DLC and DSS-DLC for CSAs 3122 and 3130 in the third quarter of 1993.&amp;quot; By tracking which attribute is compound, a third message can be merged into the aggregate message if it also has the same distinct attribute. Continue from Step 1, (E2 Si D1) and (E2 S2 D1) are merged they have only one distinct attribute, A new FD, (E2 (Si S2) D1), is assembled to replace 330 those two messages. Note that although (El S3 D2) and (E3 S4 D2) have the date in common, they are not combined because they have more than one disattribute, Step 2 is applied to the message list recursively to generate possible crossing conjunction, as in the output which merges refinement activated ALL-DLC and DSS-DLC for CSAs 3122 and 3130 in the third quarter of 1993.&amp;quot; Though on the outset this phenomenon seems unlikely, it does happen in our domain. 3.3 Step 3: Identity Deletion After merging at step 2, the message list left in an action group either has only one message, or it has more than one message with at least two distinct attributes between them. Instead of generating two separate sentences for (E2 (Si S2) D1) and (El S3 D2), the system realizes that both the subject and verb are the same, thus it uses deletion on identity to refinement activated DLC for CSAs 3122 and 3130 in 1994 Q1 and [this refinement ac- ALL-DLC for CSA 3134 in 1994 Q3.&amp;quot; identical attributes across two messages (as shown in the bracketed phrase), a &amp;quot;deletion&amp;quot; feature is inserted into the semantic FD, so that SURGE will suppress the output. 3.4 Step 4: Sentence Break Applying deletion on identity blindly to the whole message list might make the generated text incomprehensible because readers might have to recover too much implicit information from the sentence. As a result, the combining algorithm must have a way to determine when to break the messages into separate sentences that are easy to understand and unambiguous. How much information to pack into a sentence does not depend on grammaticality, but on coherence, comprehensibility, and aesthetics which are hard to formalize. PLANDoc uses a heuristic that always joins the first and second messages, and continues to do so for third and more if the distinct attributes between the messages are the same. This heuristics results in parallel syntactic structure and the underlying semantics can be easily recovered. Once the distinct attributes are different from the combined messages, the system starts a new sentence. Using the same example, (E2 (51 S2) D1) and (El S3 D2) have three distinct attributes. They are combined because they are the first two messages. Comparing the third message (E3 S4 D2) to (El S3 they have different not a sentence break will take place between them. Aggregating all three messages together will results in questionable output. Because of the parstructure between the first 2 messages, are expecting a different reading the third clause. The second occurrence of &amp;quot;1994 Q3&amp;quot; in the same sentence does not agree with readers&apos; expectation thus potentially confusing. 4 Future Directions In this paper, I have described a general algorithm which not only reduces the amount of the text produced, but also increases the fluency of the text. While other systems do generate conjunctions, they with restricted as conjunction of subjects and predicates(Dalianis&amp;Hovy93). There are other interesting problems in aggregations. Generating marker words to indicate relationships in conjoined structures, such as &amp;quot;respectively&amp;quot;, is another short term goal. Extending the current aggregation algorithm to be more general is currently being investigated, such as combining related messages with different actions.</abstract>
<note confidence="0.734350621621622">5 Acknowledgements The author thanks Prof. Kathleen McKeown, and Dr. Karen Kukich at Bellcore for their advice and support. This research was conducted while supported by Bellcore project #CU01403301A1, and under the auspices of the Columbia University CAT in High Performance Computing and Communications in Healthcare, a New York State Center for Advanced Technology supported by the New York State Science and Technology Foundation. References Dalianis, Hercules, and Hovy, Edward. 1993. Aggregation in Natural Language Generation. In Proceedings of the Fourth European Workshop on Language Generation, Italy. Elhadad, Michael. 1991. FUF: The universal unifier user manual, version 5.0. Report CUCS- Univ. Jacques. 1994. Generation of Natural Language Summaries Providing Historical Background: Corpus-based analysis, design, and evaluation. thesis, Computer Science Department, Columbia Univ. Kukich, K., McKeown, K., Morgan, N., Phillips, J., J., Shaw, Lim, J. 1993. User-Needs Analysis and Design Methodology for an Auto- Documentation Generator. In of the Fourth Bellcore/BCC Symposium on User- Design, NJ. McKeown, Kathleen, Kukich, Karen, and Shaw, James. 1994. Practical Issues in Automatic Doc- Generation. In of the 4th Conference on Applied Natural Language Processp.7-14. Oirsouw, Robert. 1987. Syntax of Coordi- Croom Helm. 331</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Hercules Dalianis</author>
<author>Edward Hovy</author>
</authors>
<title>Aggregation in Natural Language Generation.</title>
<date>1993</date>
<booktitle>In Proceedings of the Fourth European Workshop on Natural Language Generation,</booktitle>
<location>Pisa, Italy.</location>
<marker>Dalianis, Hovy, 1993</marker>
<rawString>Dalianis, Hercules, and Hovy, Edward. 1993. Aggregation in Natural Language Generation. In Proceedings of the Fourth European Workshop on Natural Language Generation, Pisa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Elhadad</author>
</authors>
<title>FUF: The universal unifier - user manual, version 5.0.</title>
<date>1991</date>
<tech>Tech Report CUCS038-91,</tech>
<institution>Columbia Univ.</institution>
<marker>Elhadad, 1991</marker>
<rawString>Elhadad, Michael. 1991. FUF: The universal unifier - user manual, version 5.0. Tech Report CUCS038-91, Columbia Univ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacques Robin</author>
</authors>
<title>Revision-Based Generation of Natural Language Summaries Providing Historical Background: Corpus-based analysis, design, implementation and evaluation.</title>
<date>1994</date>
<tech>Ph.D. thesis,</tech>
<institution>Computer Science Department, Columbia Univ.</institution>
<marker>Robin, 1994</marker>
<rawString>Robin, Jacques. 1994. Revision-Based Generation of Natural Language Summaries Providing Historical Background: Corpus-based analysis, design, implementation and evaluation. Ph.D. thesis, Computer Science Department, Columbia Univ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Kukich</author>
<author>K McKeown</author>
<author>N Morgan</author>
<author>J Phillips</author>
<author>J Robin</author>
<author>J Shaw</author>
<author>J Lim</author>
</authors>
<title>User-Needs Analysis and Design Methodology for an Automated Documentation Generator.</title>
<date>1993</date>
<booktitle>In Proceedings of the Fourth Bellcore/BCC Symposium on UserCentered Design,</booktitle>
<location>Piscataway, NJ.</location>
<marker>Kukich, McKeown, Morgan, Phillips, Robin, Shaw, Lim, 1993</marker>
<rawString>Kukich, K., McKeown, K., Morgan, N., Phillips, J., Robin, J., Shaw, J., and Lim, J. 1993. User-Needs Analysis and Design Methodology for an Automated Documentation Generator. In Proceedings of the Fourth Bellcore/BCC Symposium on UserCentered Design, Piscataway, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathleen McKeown</author>
<author>Karen Kukich</author>
<author>James Shaw</author>
</authors>
<title>Practical Issues in Automatic Documentation Generation.</title>
<date>1994</date>
<booktitle>In Proceedings of the 4th Conference on Applied Natural Language Processing,</booktitle>
<pages>7--14</pages>
<location>Stuttgart,</location>
<marker>McKeown, Kukich, Shaw, 1994</marker>
<rawString>McKeown, Kathleen, Kukich, Karen, and Shaw, James. 1994. Practical Issues in Automatic Documentation Generation. In Proceedings of the 4th Conference on Applied Natural Language Processing, Stuttgart, p.7-14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert van Oirsouw</author>
</authors>
<title>The Syntax of Coordination Beckenham: Croom Helm.</title>
<date>1987</date>
<marker>van Oirsouw, 1987</marker>
<rawString>van Oirsouw, Robert. 1987. The Syntax of Coordination Beckenham: Croom Helm.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>