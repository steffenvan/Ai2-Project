<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.011204">
<title confidence="0.9994055">
A Bayesian Mixture Model for Part-of-Speech Induction
Using Multiple Features
</title>
<author confidence="0.991174">
Christos Christodoulopoulos
</author>
<affiliation confidence="0.998564">
School of Informatics
University of Edinburgh
</affiliation>
<email confidence="0.992266">
christos.c@ed.ac.uk
</email>
<author confidence="0.995567">
Sharon Goldwater
</author>
<affiliation confidence="0.998896">
School of Informatics
University of Edinburgh
</affiliation>
<email confidence="0.993203">
sgwater@inf.ed.ac.uk
</email>
<author confidence="0.99783">
Mark Steedman
</author>
<affiliation confidence="0.9989525">
School of Informatics
University of Edinburgh
</affiliation>
<email confidence="0.996759">
steedman@inf.ed.ac.uk
</email>
<sectionHeader confidence="0.995826" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.995081588235294">
In this paper we present a fully unsupervised
syntactic class induction system formulated as
a Bayesian multinomial mixture model, where
each word type is constrained to belong to a
single class. By using a mixture model rather
than a sequence model (e.g., HMM), we are
able to easily add multiple kinds of features,
including those at both the type level (mor-
phology features) and token level (context and
alignment features, the latter from parallel cor-
pora). Using only context features, our sys-
tem yields results comparable to state-of-the
art, far better than a similar model without the
one-class-per-type constraint. Using the addi-
tional features provides added benefit, and our
final system outperforms the best published
results on most of the 25 corpora tested.
</bodyText>
<sectionHeader confidence="0.998974" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9997175625">
Research on unsupervised learning for NLP has be-
come widespread recently, with part-of-speech in-
duction, or syntactic class induction, being a partic-
ularly popular task.&apos; However, despite a recent pro-
liferation of syntactic class induction systems (Bie-
mann, 2006; Goldwater and Griffiths, 2007; John-
son, 2007; Ravi and Knight, 2009; Berg-Kirkpatrick
et al., 2010; Lee et al., 2010), careful compari-
son indicates that very few systems perform better
than some much simpler and quicker methods dating
back ten or even twenty years (Christodoulopoulos
&apos;The task is more commonly referred to as part-of-speech
induction, but we prefer the term syntactic class induction since
the induced classes may not coincide with part-of-speech tags.
et al., 2010). This fact suggests that we should con-
sider which features of the older systems led to their
success, and attempt to combine these features with
some of the machine learning methods introduced
by the more recent systems. We pursue this strat-
egy here, developing a system based on Bayesian
methods where the probabilistic model incorporates
several insights from previous work.
Perhaps the most important property of our model
is that it is type-based, meaning that all tokens of
a given word type are assigned to the same clus-
ter. This property is not strictly true of linguistic
data, but is a good approximation: as Lee et al.
(2010) note, assigning each word type to its most
frequent part of speech yields an upper bound ac-
curacy of 93% or more for most languages. Since
this is much better than the performance of cur-
rent unsupervised syntactic class induction systems,
constraining the model in this way seems likely to
improve performance by reducing the number of
parameters in the model and incorporating useful
linguistic knowledge. Both of the older systems
discussed by Christodoulopoulos et al. (2010), i.e.,
Clark (2003) and Brown et al. (1992), included this
constraint and achieved very good performance rel-
ative to token-based systems. More recently, Lee et
al. (2010) presented a new type-based model, and
also reported very good results.
A second property of our model, which distin-
guishes it from the type-based Bayesian model of
Lee et al. (2010), is that the underlying probabilistic
model is a clustering model, (specifically, a multino-
mial mixture model) rather than a sequence model
(HMM). In this sense, our model is more closely re-
</bodyText>
<page confidence="0.968436">
638
</page>
<note confidence="0.958059">
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 638–647,
Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.999821976744186">
lated to several non-probabilistic systems that clus-
ter context vectors or lower-dimensional represen-
tations of them (Redington et al., 1998; Sch¨utze,
1995; Lamar et al., 2010). Sequence models are
by far the most common method of supervised part-
of-speech tagging, and have also been widely used
for unsupervised part-of-speech tagging both with
and without a dictionary (Smith and Eisner, 2005;
Haghighi and Klein, 2006; Goldwater and Griffiths,
2007; Johnson, 2007; Ravi and Knight, 2009; Lee et
al., 2010). However, systems based on context vec-
tors have also performed well in these latter scenar-
ios (Sch¨utze, 1995; Lamar et al., 2010; Toutanova
and Johnson, 2007) and present a viable alternative
to sequence models.
One advantage of using a clustering model rather
than a sequence model is that the features used for
clustering need not be restricted to context words.
Additional types of features can easily be incorpo-
rated into the model and inference procedure using
the same general framework as in the basic model
that uses only context word features. In particu-
lar, we present two extensions to the basic model.
The first uses morphological features, which serve
as cues to syntactic class and seemed to partly ex-
plain the success of two best-performing systems
analysed by Christodoulopoulos et al. (2010). The
second extension to our model uses alignment fea-
tures gathered from parallel corpora. Previous work
suggests that using parallel text can improve perfor-
mance on various unsupervised NLP tasks (Naseem
et al., 2009; Snyder and Barzilay, 2008).
We evaluate our model on 25 corpora in 20 lan-
guages that vary substantially in both syntax and
morphology. As in previous work (Lee et al., 2010),
we find that the one-class-per-type restriction boosts
performance considerably over a comparable token-
based model and yields results that are comparable
to state-of-the-art even without the use of morphol-
ogy or alignment features. Including morphology
features yields the best published results on 14 or 15
of our 25 corpora (depending on the measure) and
alignment features can improve results further.
</bodyText>
<sectionHeader confidence="0.987819" genericHeader="introduction">
2 Models
</sectionHeader>
<bodyText confidence="0.9827275">
Our model is a multinomial mixture model with
Bayesian priors over the mixing weights θ and
</bodyText>
<figureCaption confidence="0.95315525">
Figure 1: Plate diagram of the basic model with a single
feature per token (the observed variable f). M, Z, and
nj are the number of word types, syntactic classes z, and
features (= tokens) per word type, respectively.
</figureCaption>
<bodyText confidence="0.999935416666667">
multinomial class output parameters ϕ. The model
is defined so that all observations associated with
a single word type are generated from the same
mixing component (syntactic class). In the basic
model, these observations are token-level features;
the morphology model adds type-level features as
well. We begin by describing the simplest version of
our model, where each word token is associated with
a single feature, for example its left context word
(the word that occurs to its left in the corpus). We
then show how to generalise the model to multiple
token-level features and to type-level features.
</bodyText>
<subsectionHeader confidence="0.989779">
2.1 Basic model
</subsectionHeader>
<bodyText confidence="0.999945307692308">
In the basic model, each word token is represented
by a single feature such as its left context word.
These features are the observed data; the model ex-
plains the data by assuming that it has been gener-
ated from some set of latent syntactic classes. The
ith class is associated with a multinomial parameter
vector ϕZ that defines the distribution over features
generated from that class, and with a mixing weight
θZ that defines the prior probability of that class. θ
and ϕZ are drawn from symmetric Dirichlet distribu-
tions with parameters α and β respectively.
The generative story goes as follows: First, gen-
erate the prior class probabilities θ. Next, for each
</bodyText>
<equation confidence="0.539414">
β
α g
φ
Z
z
f
nj
M
</equation>
<page confidence="0.99294">
639
</page>
<bodyText confidence="0.999419375">
word type j = 1... M, choose a class assignment zj
from the distribution θ. For each class i = 1... Z,
choose an output distribution over features ϕi. Fi-
nally, for each token k = 1... nj of word type j,
generate a feature fjk from ϕzj, the distribution as-
sociated with the class that word type j is assigned
to. The model is illustrated graphically in Figure 1
and is defined formally as follows:
</bodyText>
<equation confidence="0.9984595">
θ  |α — Dirichlet(α)
zj  |θ — Multinomial(θ)
ϕi  |β — Dirichlet(β)
fjk  |ϕzj — Multinomial(ϕzj)
</equation>
<bodyText confidence="0.999991333333333">
In addition to the variables defined above, we will
use F to refer to the number of different possible
values a feature can take on (so that ϕ is a Z x F
matrix). Thus, one way to think of the model is as a
vector-based clustering system, where word type j is
associated with a 1 x F vector of feature counts rep-
resenting the features of all nj tokens of j, and these
vectors are clustered into similar classes. The differ-
ence from other vector-based syntactic class induc-
tion systems is in the method of clustering. Here,
we define a Gibbs sampler that samples from the
posterior distribution of the clusters given the ob-
served features; other systems have used various
standard distance-based vector clustering methods.
Some systems also include dimensionality reduction
(Sch¨utze, 1995; Lamar et al., 2010) to reduce the
size of the context vectors; we simply use the F most
common words as context features.
</bodyText>
<subsectionHeader confidence="0.947013">
2.2 Inference
</subsectionHeader>
<bodyText confidence="0.9978916">
At inference time we want to sample a syntactic
class assignment z from the posterior of the model.
We use a collapsed Gibbs sampler, integrating out
the parameters θ and ϕ and sampling from the fol-
lowing distribution:
</bodyText>
<equation confidence="0.994118">
P(z|f, α, β) a P(z|α)P(f|z, β). (1)
</equation>
<bodyText confidence="0.999783">
Rather than sampling the joint class assignment
P(z|f, α,β) directly, the sampler iterates over each
word type j, resampling its class assignment zj
given the current assignments z−j of all other word
types. The posterior over zj can be computed as
</bodyText>
<equation confidence="0.977538">
P(zj  |z−j, f, α,β)
a P(zj  |z−j, α,β)P(fj  |f−j, z, α,β) (2)
</equation>
<bodyText confidence="0.999987">
where fj are the features associated with word type
j (one feature for each token of j). The first (prior)
factor is easy to compute due to the conjugacy be-
tween the Dirichlet and multinomial distributions,
and is equal to
</bodyText>
<equation confidence="0.998764">
nz + α
P(zj = z  |z−j, α) = (3)
n· + Zα
</equation>
<bodyText confidence="0.999977181818182">
where nz is the number of types in class z and n·
is the total number of word types in all classes. All
counts in this and the following equations are com-
puted with respect to z−j (e.g., n· = M — 1).
Computing the second (likelihood) factor is
slightly more complex due to the dependencies be-
tween the different variables in fj that are induced
by integrating out the ϕ parameters. Consider first a
simple case where word type j occurs exactly twice
in the corpus, so fj contains two features. The prob-
ability of the first feature fj1 is equal to
</bodyText>
<equation confidence="0.986256666666667">
nf,z + β
P(fj1 = f  |zj = z, z−j, f−j, β) = (4)
n·,z + Fβ
</equation>
<bodyText confidence="0.9998791">
where nf,z is the number of times feature f has been
seen in class z, n·,z is the total number of feature
tokens in the class, and F is the number of different
possible features.
The probability of the second feature fj2 can be
calculated similarly, except that it is conditioned on
fj1 in addition to the other variables, so the counts
for previously observed features must include the
counts due to fj1 as well as those due to f−j. Thus,
the probability is
</bodyText>
<equation confidence="0.99969025">
P(fj2 = f  |fj1,zj = z,z−j,f−j,β)
nf,z + δ(fj1, fj2) + β
= n· (5)
,z + 1 + Fβ
</equation>
<bodyText confidence="0.999736625">
where δ is the Kronecker delta function, equal to 1
if its arguments are equal and 0 otherwise.
Extending this example to the general case, the
probability of a sequence of features fj is computed
using the chain rule, where the counts used in each
factor are incremented as necessary for each addi-
tional conditioning feature, yielding the following
expression:
</bodyText>
<equation confidence="0.9115712">
P(fj  |f−j, zj = z, z−j, β)
1r1F njk−1
l k=1 l li=0 (njk,z + i + β)
6
HZ ? 01(n·,z + i + Fβ) ( )
</equation>
<page confidence="0.959766">
640
</page>
<bodyText confidence="0.99988">
where njk is the number of instances of feature k in
word type j.2
</bodyText>
<subsectionHeader confidence="0.998142">
2.3 Extended models
</subsectionHeader>
<bodyText confidence="0.99909995">
We can extend the model above in two different
ways: by adding more features at the word token
level, or by adding features at the type level. To add
more token-level features, we simply assume that
each word token generates multiple features, one
feature from each of several different kinds.3 For
example, the left context word might be one kind of
feature and the right context word another. We as-
sume conditional independence between the gener-
ated features given the syntactic class, so each kind
of feature t has its own output parameters ϕ(t). A
plate diagram of the model with T kinds of features
is shown in Figure 2 (a type-level feature is also in-
cluded in this diagram, as described below).
Due to the independence assumption between the
different kinds of features, the basic Gibbs sampler
is easy to extend to this case by simpling multiplying
in extra factors for the additional kinds of features,
with the prior (Equation 3) unchanged. The likeli-
hood becomes:
</bodyText>
<equation confidence="0.993412">
P(f(1)
j , ... , f(T)
j I f(1...T)
−j ,zj = z, z−j, β)
P(f(t)
j I f(t)
−j, zj = z, z−j, β) (7)
</equation>
<bodyText confidence="0.988331433962264">
where each factor in the product is computed using
Equation 6.
In addition to monolingual context features, we
also explore the use of alignment features for those
languages where we have parallel corpora. These
features are extracted for language ℓ by word-
aligning ℓ to another language ℓ′ (details of the
alignment procedure are described in Section 3.1).
The features used for each token e in ℓ are the left
and right context words of the word token that is
aligned to e (if there is one). As with the mono-
lingual context features, we use only the F most fre-
quent words in ℓ′ as possible features.
2One could approximate this likelihood term by assuming
independence between all nj feature tokens of word type j.
This is the approach taken by Lee et al. (2010).
3We use the word kind here to avoid confusion with type,
which we reserve for the type-token distinction, which can ap-
ply to features as well as words.
Note that this model with multiple context fea-
tures is deficient: it can generate data that are in-
consistent with any actual corpus, because there is
no mechanism to constrain the left context word
of token ei to be the same as the right context
word of token ei−1 (and similarly with alignment
features). However, deficient models have proven
useful in other unsupervised NLP tasks (Klein and
Manning, 2002; Toutanova and Johnson, 2007). In
particular, Toutanova and Johnson (2007) demon-
strate good performance on unsupervised part-of-
speech tagging (using a dictionary) with a Bayesian
model similar to our own. If we remove the part of
their model that relies on the dictionary (the mor-
phological ambiguity classes), their model is equiv-
alent to our own, without the restriction of one class
per type. We use this token-based version of our
model as a baseline in our experiments.
The final extension to our model introduces type-
level features, specifically morphology features.
The model is illustrated in Figure 2. We assume
conditional independence between the morphology
features and other features, so again we can simply
multiply another factor into the likelihood during in-
ference. There is only one morphological feature per
type, so this factor has the form of Equation 4. Since
frequent words will have many token-level features
contributing to the likelihood and only one morphol-
ogy feature, the morphology features will have a
greater effect for infrequent words (as appropriate,
since there is less evidence from context and align-
ments). As with the other kinds of features, we use
only a limited number F,,t of morphology features,
as described below.
</bodyText>
<sectionHeader confidence="0.999941" genericHeader="method">
3 Experiments
</sectionHeader>
<subsectionHeader confidence="0.999283">
3.1 Experimental setup
</subsectionHeader>
<bodyText confidence="0.9991594">
We evaluate our models using an increasing level
of complexity, starting with a model that uses only
monolingual context features. We use the F = 100
most frequent words as features, and consider two
versions of this model: one with two kinds of fea-
tures (one left and one right context word) and one
with four (two context words on each side).
For the model with morphology features we ran
the unsupervised morphological segmentation sys-
tem Morfessor (Creutz and Lagus, 2005) to get a
</bodyText>
<equation confidence="0.849812">
T
H
t=1
</equation>
<page confidence="0.948112">
641
</page>
<figureCaption confidence="0.701572">
Figure 2: Plate diagram of the extended model with T
kinds of token-level features (f(t) variables) and a single
kind of type-level feature (morphology, m).
</figureCaption>
<bodyText confidence="0.999947272727273">
segmentation for each word type in the corpus. We
then extracted the suffix of each word type4 and used
it as a feature type. This process yielded on average
F,,t = 110 morphological feature types5. Each word
type generates at most one of these possible features.
If there are overlapping possibilities (e.g. -ingly and
-y) we take the longest possible match.
We also explore the idea of extending the mor-
phology feature space beyond suffixes, by including
features like capitalisation and punctuation. Specif-
ically we use the features described in Haghighi
and Klein (2006), namely initial-capital, contains-
hyphen, contains-digit and we add an extra feature
contains-punctuation.
For the model with alignment features, we fol-
low (Naseem et al., 2009) in using only bidirectional
alignments: using Giza++ (Och and Ney, 2003),
we get the word alignments in both directions be-
tween all possible language pairs in our parallel cor-
pora (i.e., alternating the source and target languages
within each pair). We then use only those align-
ments that are found in both directions. As discussed
</bodyText>
<footnote confidence="0.927164">
4Since Morfessor yields multiple affixes for each word we
concatenated all the suffixes into a single suffix.
5There was large variance in the number of feature types for
each language ranging from 11 in Chinese to more than 350 in
German and Czech.
</footnote>
<bodyText confidence="0.999965">
above, we use two kinds of alignment features: the
left and right context words of the aligned token in
the other language. The feature space is set to the
F = 100 most frequent words in that language.
Instead of fixing the hyperparameters α and β, we
used the Metropolis-Hastings sampler presented by
Goldwater and Griffiths (2007) to get updated values
based on the likelihood of the data with respect to
those hyperparameters6. In order to improve conver-
gence of the sampler, we used simulated annealing
with a sigmoid-shaped cooling schedule from an ini-
tial temperature of 2 down to 1. Preliminary experi-
ments indicated that we could achieve better results
by cooling even further (approximating the MAP so-
lution rather than a sample from the posterior), so for
all experiments reported here, we ran the sampler for
a total of 2000 iterations, with the last 400 of these
decreasing the temperature from 1 to 0.66.
Finally, we investigated two different initialisa-
tion techniques: First, we use random class as-
signments to word types (referred to as method 1)
and second, we assign each of the Z most frequent
word types to a separate class and then randomly
distribute the rest of the word types to the classes
(method 2).
</bodyText>
<subsectionHeader confidence="0.988943">
3.2 Datasets
</subsectionHeader>
<bodyText confidence="0.988747666666667">
Although unsupervised systems should in principle
be language- and corpus-independent, most part-of-
speech induction systems (especially in the early lit-
erature) have been developed on English. Whether
because English is simply an easier language, or be-
cause of bias introduced during development, these
systems’ performance is considerably worse in other
languages (Christodoulopoulos et al., 2010)
Since we aim to use our system mostly on non-
English corpora, and ones that are significantly
smaller than the large English treebank corpora, we
developed our models using one of the languages of
the MULTEXT-East corpus (Erjavec, 2004), namely
Bulgarian. The other languages in the corpus were
used during development as a source of word align-
ments, but otherwise were only used for testing final
versions of our models. Since none of the authors
speak any of the languages in the MULTEXT col-
6For simplicity, we tied the 0 parameters for the two or four
kinds of context features to the same value, and similarly the �
parameters for the two kinds of alignment features.
</bodyText>
<equation confidence="0.993825538461538">
θ α
z
m f(T) φ(T) β(T)
φ(-) β(-)
Z
. . .
f(1) φ(1) β(1)
nj
nj
M
. . . . . .
Z
Z
</equation>
<page confidence="0.991131">
642
</page>
<bodyText confidence="0.999899727272727">
lection, we also used the Penn Treebank WSJ cor-
pus (Marcus et al., 1993) for development. Fol-
lowing Christodoulopoulos et al. (2010) we created
a smaller version of the WSJ corpus (referred to
as wsj-s) to approximate the size of the corpora in
MULTEXT-East. For comparison to other systems,
we also used the full WSJ at test time.
For further testing, we used the remaining MUL-
TEXT languages, as well as the languages of the
CONNL-X (Buchholz and Marsi, 2006) shared task.
This dataset contains 13 languages, 4 of which
are freely available (Danish, Dutch, Portuguese
and Swedish) and 9 that are used with permission
from the creators of the corpora ( Arabic7, Bul-
garian8, Czech9, German10, Chinese11, Japanese12,
Slovene13, Spanish14, Turkish15 ). Following Lee et
al. (2010) we used only the training sections for each
language.
Finally, to widen the scope of our system, we gen-
erated two more corpora in French16 and Ancient
Greek17, extracting the gold standard parts of speech
from the respective dependency treebanks.
</bodyText>
<subsectionHeader confidence="0.998267">
3.3 Baselines
</subsectionHeader>
<bodyText confidence="0.999917">
We chose three baselines for comparison. The first
is the basic k-means clustering algorithm, which we
applied to the same feature vectors we extracted for
our system (context + extended morphology), using
a Euclidean distance metric. This provides a very
simple vector-based clustering baseline. The second
baseline is a more recent vector-based syntactic class
induction method, the SVD approach of (Lamar et
al., 2010), which extends Sch¨utze (1995)’s original
method and, like ours, enforces a one-class-per-tag
restriction. As a third baseline we use the system of
Clark (2003) since it is a type-level system that mod-
</bodyText>
<footnote confidence="0.939565923076923">
7Part of the Prague Arabic Treebank (Hajiˇc et al., 2003;
Smrˇz and Pajas, 2004)
8Part of the BulTreeBank (Simov et al., 2004).
9Part of the Prague Dep. Treebank (B¨ohmov´a et al., 2001)
10Part of the TIGER Treebank (Brants et al., 2002)
11Part of the Sinica Treebank (Keh-Jiann et al., 2003)
12Part of the T¨ubingen Treebank of Spoken Japanese (for-
merly VERMOBIL Treebank - Kawata and Bartels (2000)).
13Part of the Slovene Dep. Treebank (Dˇzeroski et al., 2006)
14Part of the Cast3LB Treebank (Civit et al., 2006)
15Part of the METU-Sabanci Treebank (Oflazer et al., 2003).
16French Treebank (Abeill´e et al., 2000)
17Greek Dependency Treebank (Bamman et al., 2009)
</footnote>
<bodyText confidence="0.993481">
els morphology and has produced very good results
on multilingual corpora.
</bodyText>
<sectionHeader confidence="0.998206" genericHeader="evaluation">
4 Results and Analysis
</sectionHeader>
<subsectionHeader confidence="0.99549">
4.1 Development results
</subsectionHeader>
<bodyText confidence="0.999987833333334">
Tables 1 and 2 present the results from develop-
ment runs, which were used to decide which fea-
tures to incorporate in the final system. We used V-
Measure (Rosenberg and Hirschberg, 2007) as our
primary evaluation score, but also present many-to-
one matching accuracy (M-1) scores for better com-
parison with previously published results. We chose
V-Measure (VM) as our evaluation score because it
is less sensitive to the number of classes induced by
the model (Christodoulopoulos et al., 2010), allow-
ing us to develop our models without using the num-
ber of classes as a parameter. We fixed the number
of classes in all systems to 45 during development;
note however that the gold standard tag set for Bul-
garian contains only 12 tags, so the results in Ta-
ble 1 (especially the M-1 scores) are not comparable
to previous results. For results using the number of
gold-standard tags refer to Table 4.
The first conclusion that can be drawn from these
results is the large difference between the token-
and type-based versions of our system, which con-
firms that the one-class-per-type restriction is help-
ful for unsupervised syntactic class induction. We
also see that for both languages, the performance of
the model using 4 context words (±2 on each side) is
worse than the 2 context words model. We therefore
used only two context words for all of our additional
test languages (below).
We can clearly see that morphological features
are helpful in both languages; however the extended
features of Haghighi and Klein (2006) seem to help
only on the English data. This could be due to the
fact that Bulgarian has a much richer morphology
and thus the extra features contribute little to the
overall performance of the model.
The contribution of the alignment features on the
Bulgarian corpus (aligned with English) is less sig-
nificant than that of morphology but when com-
bined, the two sets of features yield the best per-
formance. This provides evidence in favor of using
multiple features.
Finally, initialisation method 2 does not yield
</bodyText>
<page confidence="0.99854">
643
</page>
<table confidence="0.999923363636364">
system f1 words f2 words
VM/M-1 VM/M-1
base 58.1 / 70.8 55.4 / 67.6
base(tokens) 48.3 / 62.5 37.0 / 54.4
base(init) 57.6 / 70.1 56.1 / 68.6
+morph 58.3 / 74.9 57.4 / 71.9
+morph(ext) 57.8 / 73.7 57.8 / 70.1
(init)+morph 57.8 / 74.3 57.3 / 69.5
(init)+morph(ext) 58.1 / 74.3 57.2 / 71.3
+aligns(EN) 58.1 / 72.6 56.7 / 71.1
+aligns(EN)+morph 59.0 / 75.4 57.5 / 69.7
</table>
<tableCaption confidence="0.817536">
Table 1: V-measure (VM) and many-to-one (M-1) results
on the MULTEXT-Bulgarian corpus for various mod-
els using either ±1 or ±2 context words as features.
base: context features only; (tokens): token-based model;
(init): Initialisation method 2—other results use method
1; (ext): Extended morphological features.
</tableCaption>
<table confidence="0.999966888888889">
system f1 words f2 words
VM/M-1 VM/M-1
base 63.3 / 64.3 62.4 / 63.3
base(tokens) 48.6 / 57.8 49.3 / 38.3
base(init) 62.7 / 62.9 62.2 / 62.4
+morph 66.4 / 66.7 65.1 / 67.2
+morph(ext) 67.7 / 72.0 65.6 / 67.0
(init)+morph 64.8 / 66.9 64.2 / 66.0
(init)+morph(ext) 67.4 / 71.3 65.7 / 67.1
</table>
<tableCaption confidence="0.997894">
Table 2: V-measure and many-to-one results on the wsj-s
corpus for various models, as described in Table 1.
</tableCaption>
<bodyText confidence="0.9814644">
.
consistent improvements over the standard ran-
dom initialisation—if anything, it seems to perform
worse. We therefore use only method 1 in the re-
maining experiments.
</bodyText>
<subsectionHeader confidence="0.998279">
4.2 Overall results
</subsectionHeader>
<bodyText confidence="0.995478941176471">
Table 3 presents the results on our parallel corpora.
We tested all possible combinations of two lan-
guages to align, and present both the average score
over all alignments, and the score under the best
choice of aligned language.18 Also shown are the
results of adding morphology features to the basic
model (context features only) and to the best align-
ment model for each language. In accord with our
18The choice of language was based on the same test data, so
the ‘best-language’ results should be viewed as oracle scores.
development results, adding morphology to the ba-
sic model is generally useful. The alignment results
are mixed: on the one hand, choosing the best pos-
sible language to align yields improvements, which
can be improved further by adding morphological
features, resulting in the best scores of all models
for most languages. On the other hand, without
knowing which language to choose, alignment fea-
tures do not help on average. We note, however,
that three out of the seven languages have English
as their best-aligned pair (perhaps due to its better
overall scores), which suggests that in the absence
of other knowledge, aligning with English may be a
good choice.
The low average performance of the alignment
features is disappointing, but there are many pos-
sible variations on our method for extracting these
features that we have not yet tested. For example,
we used only bidirectional alignments in an effort to
improve alignment precision, but these alignments
typically cover less than 40% of tokens. It is pos-
sible that a higher-recall set of alignments could be
more useful.
We turn now to our results on all 25 corpora,
shown in Table 4 along with corpus statistics, base-
line results, and the best published results for each
language (when available). Our system, includ-
ing morphology features in all cases, is listed as
BMMM (Bayesian Multinomial Mixture Model).
We do not include alignment features for the MUL-
TEXT languages since these features only yielded
improvements for the oracle case where we know
which aligned language to choose. Nevertheless, our
MULTEXT scores mostly outperform all other sys-
tems. Overall, we acheive the highest published re-
sults on 14 (VM) or 15 (M-1) of the 25 corpora.
One surprising discovery is the high performance
of the k-means clustering system. Despite its sim-
plicity, it is competitive with the other systems and
in a few cases even achieves the best published re-
sults.
</bodyText>
<sectionHeader confidence="0.995846" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.99994">
We have presented a Bayesian model for syntactic
class induction that has two important properties.
First, it is type-based, assigning the same class to
every token of a word type. We have shown by
</bodyText>
<page confidence="0.996895">
644
</page>
<table confidence="0.999002909090909">
BASE ALIGNMENTS
Lang. base +morph Avg. Best +morph
VM/M-1 VM/M-1 VM/M-1 VM/M1 VM/M1
Bulgarian 54.4 / 61.5 54.5 / 64.3 53.1 / 60.5 55.2 / 64.5(EN) 55.7 / 66.0
Czech 54.2 / 58.9 53.9 / 64.2 52.6 / 58.4 53.8 / 59.7(EN) 55.4 / 66.4
English 62.9 / 72.4 63.3 / 73.3 62.5 / 72.0 63.2 / 71.9(HU) 63.5 / 73.7
Estonian 52.8 / 63.5 53.3 / 67.4 52.8 / 63.9 53.5 / 65.0(EN) 54.3 / 66.9
Hungarian 53.3 / 60.4 54.8 / 68.2 53.3 / 60.8 53.9 / 61.1(RO) 55.9 / 67.1
Romanian 53.9 / 62.4 52.3 / 61.1 56.2 / 63.7 57.5 / 64.6(ES) 54.5 / 63.4
Slovene 57.2 / 65.9 56.7 / 67.9 54.7 / 64.1 55.9 / 64.4(HU) 56.7 / 67.9
Serbian 49.1 / 56.6 49.0 / 62.0 47.3 / 55.6 48.9 / 59.4(CZ) 48.3 / 60.8
</table>
<tableCaption confidence="0.9978125">
Table 3: V-measure (VM) and many-to-one (M-1) results on the languages in the MULTEXT-East corpus using
the gold standard number of classes shown in Table 4. BASE results use ±1-word context features alone or with
morphology. ALIGNMENTS adds alignment features, reporting the average score across all possible choices of paired
language and the scores under the best performing paired language (in parens), alone or with morphology features.
</tableCaption>
<table confidence="0.999682807692308">
Language Types Tags k-means SVD2 clark Best Pub. BMMM
WSJ wsj 49,190 45 59.5 / 61.6 58.2 / 64.0 65.6 / 71.2 68.8 / 76.1- 66.1 / 72.8
wsj-s 16,850 45 56.7 / 60.1 54.3 / 60.7 63.8 / 68.8 62.3 / 70.7- 67.7 / 72.0
MULTEXT-East Bulgarian 16,352 12 50.3 / 59.3 41.7 / 51.0 55.6 / 66.5 - 54.5 / 64.4
Czech 19,115 12 48.6 / 56.7 35.5 / 50.9 52.6 / 64.1 - 53.9 / 64.2
English 9,773 12 56.5 / 65.4 52.3 / 65.5 60.5 / 70.6 - 63.3 / 73.3
Estonian 17,845 11 45.3 / 55.6 38.7 / 55.3 44.4 / 58.4 - 53.3 / 64.4
Hungarian 20,321 12 46.7 / 53.9 39.8 / 49.5 48.9 / 61.4 - 54.8 / 68.2
Romanian 15,189 14 45.2 / 55.1 42.1 / 52.6 40.9 / 49.9 - 52.3 / 61.1
Slovene 17,871 12 46.9 / 56.2 39.5 / 54.2 54.9 / 69.4 - 56.7 / 67.9
Serbian 18,095 12 41.4 / 47.0 39.1 / 54.6 51.0 / 64.1 - 49.0 / 62.0
CoNLL06 Shared Task Arabic 12,915 20 43.3 / 60.7 27.6 / 49.0 40.6 / 59.8 - 42.4 / 61.5
Bulgarian 32,439 54 53.6 / 65.6 49.0 / 65.3 59.6 / 70.4 - 58.8 / 68.9
Chinese 40,562 15 32.6 / 61.1 24.5 / 54.6 31.8 / 56.7 - 42.6 / 69.4
Czech 130,208 12 - - 47.1 / 65.5 - 48.4 / 65.7
Danish 18,356 25 51.7 / 61.6 40.8 / 57.6 52.7 / 65.3 - / 66.71 59.0 / 71.1
Dutch 28,393 13 45.3 / 60.5 36.7 / 52.4 52.2 / 67.9 - / 67.31 54.7 / 71.1
German 72,326 54 58.7 / 67.5 54.1 / 64.2 63.0 / 73.9 - / 68.41 61.9 / 74.4
Japanese 3,231 80 76.1 / 76.2 74.4 / 75.5 78.6 / 77.4 - 77.4 / 78.5
Portuguese 28,931 22 51.6 / 64.4 45.9 / 63.1 57.4 / 69.2 - / 75.31 63.9 / 76.8
Slovene 7,128 29 52.6 / 64.2 44.0 / 60.3 53.9 / 63.5 - 49.4 / 56.2
Spanish 16,458 47 59.5 / 69.2 54.8 / 68.2 61.6 / 71.9 - / 73.21 63.2 / 71.7
Swedish 20,057 41 53.2 / 62.2 47.4 / 59.1 58.9 / 68.7 - / 60.61 58.0 / 68.2
Turkish 17,563 30 40.8 / 62.8 27.4 / 52.4 36.8 / 58.1 - 40.2 / 58.7
French 49,964 23 48.2 / 68.6 46.3 / 68.5 57.3 / 77.8 - 55.0 / 76.6
A.Greek 15,194 15 38.6 / 44.8 24.2 / 38.5 33.3 / 45.4 - 40.5 / 45.1
</table>
<tableCaption confidence="0.9420095">
Table 4: Final results on 25 corpora in 20 languages, with the number of induced classes equal to the number of gold
standard tags in all cases. k-means and SVD2 models could not produce a clustering in the Czech CoNLL corpus due
its size. Best published results are from *Christodoulopoulos et al. (2010), tBerg-Kirkpatrick et al. (2010) and tLee
et al. (2010). The latter two papers do not report VM scores. No best published results are shown for the MULTEXT
languages; Christodoulopoulos et al. (2010) report results based on 45 tags suggesting that clark performs best on
these corpora.
</tableCaption>
<page confidence="0.998405">
645
</page>
<bodyText confidence="0.999970166666667">
comparison with a token-based version of the model
that this restriction is very helpful. Second, it is
a clustering model rather than a sequence model.
This property makes it easy to incorporate multi-
ple kinds of features into the model at either the to-
ken or the type level. Here, we experimented with
token-level context features and alignment features
and type-level morphology features, showing that
morphology features are helpful in nearly all cases,
and alignment features can be helpful if the aligned
language is properly chosen. Our results even with-
out these extra features are competitive with state-
of-the-art; with the additional features we achieve
the best published results in the majority of the 25
corpora tested.
Since it is so easy to add extra features to our
model, one direction for future work is to explore
other possible features. For example, it could be
useful to add dependency features from an unsuper-
vised dependency parser. We are also interested in
improving our morphology features, either by con-
sidering other ways to extract features during pre-
processing (for example, including prefixes or not
concatenating together all suffixes), or by develop-
ing a joint model for inducing both morphology and
syntactic classes simultaneously. Finally, our model
could be extended by replacing the standard mixture
model with an infinite mixture model (Rasmussen,
2000) in order to induce the number of syntactic
classes automatically.
</bodyText>
<sectionHeader confidence="0.997639" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99873975">
The authors would like to thank Emily Thomforde,
Ioannis Konstas, Tom Kwiatkowski and the anony-
mous reviewers for their comments and suggestions.
We would also like to thank Kiril Simov, Toni Marti,
Tomaz Erjavec, Jess Lin and Kathrin Beck for pro-
viding us with CoNLL data. This work was sup-
ported by an EPSRC graduate Fellowship, and by
ERC Advanced Fellowship 249520 GRAMPLUS.
</bodyText>
<sectionHeader confidence="0.998898" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998441034482759">
Anne Abeill´e, Lionel Cl´ement, and Alexandra Kinyon.
2000. Building a treebank for French. In In Proceed-
ings of the LREC 2000.
David Bamman, Francesco Mambrini, and Gregory
Crane. 2009. An ownership model of annotation: The
Ancient Greek dependency treebank. In TLT 2009-
Eighth International Workshop on Treebanks and Lin-
guistic Theories.
Taylor Berg-Kirkpatrick, Alexandre B. Cˆot´e, John DeN-
ero, and Dan Klein. 2010. Painless unsupervised
learning with features. In Proceedings of NAACL
2010, pages 582–590, Los Angeles, California, June.
Chris Biemann. 2006. Unsupervised part-of-speech tag-
ging employing efficient graph clustering. In Proceed-
ings of COLING ACL 2006, pages 7–12, Morristown,
NJ, USA.
Alena B¨ohmov´a, Jan Hajiˇc, Eva Hajiˇcov´a, and Barbora
Hladk´a. 2001. The Prague dependency treebank:
Three-level annotation scenario. In Anne Abeill´e, ed-
itor, Treebanks: Building and Using Syntactically An-
notated Corpora, pages 103 – 126. Kluwer Academic
Publishers.
Sabine Brants, Stefanie Dipper, Silvia Hansen, Wolfgang
Lezius, and George Smith. 2002. The TIGER tree-
bank. In Proceedings of the Workshop on Treebanks
and Linguistic Theories, Sozopol.
Peter F. Brown, Vincent J. Della Pietra, Peter V. Desouza,
Jennifer C. Lai, and Robert L. Mercer. 1992. Class-
based n-gram models of natural language. Computa-
tional Linguistics, 18(4):467–479.
Sabine Buchholz and Erwin Marsi. 2006. CoNLL-
X shared task on multilingual dependency parsing.
In Proceedings of the Tenth Conference on Compu-
tational Natural Language Learning, CoNLL-X ’06,
pages 149–164, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Christos Christodoulopoulos, Sharon Goldwater, and
Mark Steedman. 2010. Two decades of unsupervised
POS induction: How far have we come? In Proceed-
ings of the 2010 Conference on Empirical Methods in
Natural Language Processing, pages 575–584, Cam-
bridge, MA, October. Association for Computational
Linguistics.
Montserrat Civit, Ma. Martf, and N´uria Buff. 2006.
Cat3lb and cast3lb: From constituents to dependen-
cies. In Tapio Salakoski, Filip Ginter, Sampo Pyysalo,
and Tapio Pahikkala, editors, Advances in Natural
Language Processing, volume 4139 of Lecture Notes
in Computer Science, pages 141–152. Springer Berlin
/ Heidelberg.
Alexander Clark. 2003. Combining distributional and
morphological information for part of speech induc-
tion. In Proceedings of EACL 2003, pages 59–66,
Morristown, NJ, USA.
Mathias Creutz and Krista Lagus. 2005. Induc-
ing the morphological lexicon of a natural language
from unannotated text. In In Proceedings of the
International and Interdisciplinary Conference on
</reference>
<page confidence="0.988202">
646
</page>
<reference confidence="0.999403990291262">
Adaptive Knowledge Representation and Reasoning
(AKRR’05), volume 5, pages 106–113.
Sa&amp;quot;so D&amp;quot;zeroski, Toma&amp;quot;z Erjavec, Nina Ledinek, Petr Pajas,
Zdenek &amp;quot;Zabokrtsky, and Andreja &amp;quot;Zele. 2006. Towards
a Slovene dependency treebank. In Proceedings Int.
Conf. on Language Resources and Evaluation (LREC).
Toma&amp;quot;z Erjavec. 2004. MULTEXT-East version 3: Mul-
tilingual morphosyntactic specifications, lexicons and
corpora. In Fourth International Conference on Lan-
guage Resources and Evaluation, (LREC’04), pages
1535 – 1538, Paris. ELRA.
Sharon Goldwater and Tom Griffiths. 2007. A fully
bayesian approach to unsupervised part-of-speech tag-
ging. In Proceedings of ACL 2007, pages 744–751,
Prague, Czech Republic, June.
Aria Haghighi and Dan Klein. 2006. Prototype-driven
learning for sequence models. In Proceedings of
NAACL 2006, pages 320–327, Morristown, NJ, USA.
Jan Haji&amp;quot;c, Jarmila Panevov´a, Zde&amp;quot;nka Ure&amp;quot;sov´a, Alevtina
B´emov´a, and Petr Pajas. 2003. PDTVALLEX: cre-
ating a large-coverage valency lexicon for treebank
annotation. In Proceedings of The Second Workshop
on Treebanks and Linguistic Theories, pages 57–68.
Vaxjo University Press.
Mark Johnson. 2007. Why doesn’t EM find good HMM
POS-taggers? In Proceedings of EMNLP-CoNLL
2007, pages 296–305, Prague, Czech Republic, June.
Yasushira Kawata and Julia Bartels. 2000. Stylebook
for the Japanese treebank in VERMOBIL. Technical
report, Universit¨at T¨uubingen.
Chen Keh-Jiann, Chu-Ren Huang, Feng-Yi Chen, Chi-
Ching Luo, Ming-Chung Chang, Chao-Jan Chen, and
Zhao-Ming Gao. 2003. Sinica treebank: Design cri-
teria, representational issues and implementation. In
Anne Abeill´e, editor, Treebanks: Building and Us-
ing Syntactically Annotated Corpora, pages 231–248.
Kluwer Academic Publishers.
Dan Klein and Christopher D. Manning. 2002. A gener-
ative constituent-context model for improved grammar
induction. In Proceedings of ACL 40, pages 128–135.
Michael Lamar, Yariv Maron, Mark Johnson, and Elie
Bienenstock. 2010. SVD and clustering for unsuper-
vised POS tagging. In Proceedings of the ACL 2010
Conference Short Papers, pages 215–219, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Yoong Keok Lee, Aria Haghighi, and Regina Barzilay.
2010. Simple type-level unsupervised POS tagging.
In Proceedings of the 2010 Conference on Empirical
Methods in Natural Language Processing, EMNLP
’10, pages 853–861, Stroudsburg, PA, USA. Associ-
ation for Computational Linguistics.
Mitchell Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a large annotated cor-
pus of English: the Penn Treebank. Computational
Linguistics, 19(2):331–330.
Tahira Naseem, Benjamin Snyder, Jacob Eisenstein, and
Regina Barzilay. 2009. Multilingual Part-of-Speech
tagging: Two unsupervised approaches. Journal ofAr-
tificial Intelligence Research, 36:341–385.
Franz J. Och and Hermann Ney. 2003. A systematic
comparison of various statistical alignment models.
Comput. Linguist., 29(1):19–51.
Kemal Oflazer, Bilge Say, Dilek Z. Hakkani-T¨ur, and
G¨okhan T¨ur, 2003. Building A Turkish Treebank,
chapter 1, pages 1–17. Kluwer Academic Publishers.
Carl Rasmussen. 2000. The infinite Gaussian mixture
model. In Advances in Neural Information Processing
Systems 12.
Sujith Ravi and Kevin Knight. 2009. Minimized mod-
els for unsupervised Part-of-Speech tagging. In Pro-
ceedings of ACL-IJCNLP 2009, pages 504–512, Sun-
tec, Singapore, August.
Martin Redington, Nick Chater, and Steven Finch. 1998.
Distributional information: a powerful cue for acquir-
ing syntactic categories. Cognitive Science, 22:425 –
469.
Andrew Rosenberg and Julia Hirschberg. 2007. V-
measure: A conditional entropy-based external clus-
ter evaluation measure. In Proceedings of EMNLP-
CoNLL 2007, pages 410–420.
Hinrich Sch¨utze. 1995. Distributional part-of-speech
tagging. In Proceedings of EACL 7, pages 141–148,
San Francisco, CA, USA.
Kiril Simov, Petya Osenova, Alexander Simov, and Milen
Kouylekov. 2004. Design and implementation of the
Bulgarian HPSG-based treebank. Research on Lan-
guage &amp; Computation, 2(4):495–522.
Noah A. Smith and Jason Eisner. 2005. Contrastive esti-
mation: training log-linear models on unlabeled data.
In Proceedings of ACL 2005, pages 354–362, Morris-
town, NJ, USA.
Otakar Smrz&amp;quot; and Petr Pajas. 2004. Morphotrees of Ara-
bic and their annotation in the TrEd environment. In
Proceedings of the NEMLAR International Conference
on Arabic Language Resources and Tools, pages 38–
41.
Ben Snyder and Regina Barzilay. 2008. Unsupervised
multilingual learning for morphological segmentation.
In Proceedings of ACL.
Kristina Toutanova and Mark Johnson. 2007. A
Bayesian LDA-based model for semi-supervised part-
of-speech tagging. In Proceedings of NIPS 2007.
</reference>
<page confidence="0.998189">
647
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.821820">
<title confidence="0.999907">A Bayesian Mixture Model for Part-of-Speech Using Multiple Features</title>
<author confidence="0.967883">Christos</author>
<affiliation confidence="0.9980125">School of University of</affiliation>
<email confidence="0.959935">christos.c@ed.ac.uk</email>
<author confidence="0.946548">Sharon</author>
<affiliation confidence="0.9984005">School of University of</affiliation>
<email confidence="0.969065">sgwater@inf.ed.ac.uk</email>
<author confidence="0.995917">Mark</author>
<affiliation confidence="0.999087">School of University of</affiliation>
<email confidence="0.989013">steedman@inf.ed.ac.uk</email>
<abstract confidence="0.999076222222222">In this paper we present a fully unsupervised syntactic class induction system formulated as a Bayesian multinomial mixture model, where each word type is constrained to belong to a single class. By using a mixture model rather than a sequence model (e.g., HMM), we are able to easily add multiple kinds of features, including those at both the type level (morphology features) and token level (context and alignment features, the latter from parallel corpora). Using only context features, our system yields results comparable to state-of-the art, far better than a similar model without the one-class-per-type constraint. Using the additional features provides added benefit, and our final system outperforms the best published results on most of the 25 corpora tested.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anne Abeill´e</author>
<author>Lionel Cl´ement</author>
<author>Alexandra Kinyon</author>
</authors>
<title>Building a treebank for French. In</title>
<date>2000</date>
<booktitle>In Proceedings of the LREC</booktitle>
<marker>Abeill´e, Cl´ement, Kinyon, 2000</marker>
<rawString>Anne Abeill´e, Lionel Cl´ement, and Alexandra Kinyon. 2000. Building a treebank for French. In In Proceedings of the LREC 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Bamman</author>
<author>Francesco Mambrini</author>
<author>Gregory Crane</author>
</authors>
<title>An ownership model of annotation: The Ancient Greek dependency treebank.</title>
<date>2009</date>
<booktitle>In TLT 2009-Eighth International Workshop on Treebanks and Linguistic Theories.</booktitle>
<contexts>
<context position="21822" citStr="Bamman et al., 2009" startWordPosition="3670" endWordPosition="3673">al., 2003; Smrˇz and Pajas, 2004) 8Part of the BulTreeBank (Simov et al., 2004). 9Part of the Prague Dep. Treebank (B¨ohmov´a et al., 2001) 10Part of the TIGER Treebank (Brants et al., 2002) 11Part of the Sinica Treebank (Keh-Jiann et al., 2003) 12Part of the T¨ubingen Treebank of Spoken Japanese (formerly VERMOBIL Treebank - Kawata and Bartels (2000)). 13Part of the Slovene Dep. Treebank (Dˇzeroski et al., 2006) 14Part of the Cast3LB Treebank (Civit et al., 2006) 15Part of the METU-Sabanci Treebank (Oflazer et al., 2003). 16French Treebank (Abeill´e et al., 2000) 17Greek Dependency Treebank (Bamman et al., 2009) els morphology and has produced very good results on multilingual corpora. 4 Results and Analysis 4.1 Development results Tables 1 and 2 present the results from development runs, which were used to decide which features to incorporate in the final system. We used VMeasure (Rosenberg and Hirschberg, 2007) as our primary evaluation score, but also present many-toone matching accuracy (M-1) scores for better comparison with previously published results. We chose V-Measure (VM) as our evaluation score because it is less sensitive to the number of classes induced by the model (Christodoulopoulos </context>
</contexts>
<marker>Bamman, Mambrini, Crane, 2009</marker>
<rawString>David Bamman, Francesco Mambrini, and Gregory Crane. 2009. An ownership model of annotation: The Ancient Greek dependency treebank. In TLT 2009-Eighth International Workshop on Treebanks and Linguistic Theories.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taylor Berg-Kirkpatrick</author>
<author>Alexandre B Cˆot´e</author>
<author>John DeNero</author>
<author>Dan Klein</author>
</authors>
<title>Painless unsupervised learning with features.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL 2010,</booktitle>
<pages>582--590</pages>
<location>Los Angeles, California,</location>
<marker>Berg-Kirkpatrick, Cˆot´e, DeNero, Klein, 2010</marker>
<rawString>Taylor Berg-Kirkpatrick, Alexandre B. Cˆot´e, John DeNero, and Dan Klein. 2010. Painless unsupervised learning with features. In Proceedings of NAACL 2010, pages 582–590, Los Angeles, California, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Biemann</author>
</authors>
<title>Unsupervised part-of-speech tagging employing efficient graph clustering.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING ACL</booktitle>
<pages>7--12</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="1396" citStr="Biemann, 2006" startWordPosition="199" endWordPosition="201">r from parallel corpora). Using only context features, our system yields results comparable to state-of-the art, far better than a similar model without the one-class-per-type constraint. Using the additional features provides added benefit, and our final system outperforms the best published results on most of the 25 corpora tested. 1 Introduction Research on unsupervised learning for NLP has become widespread recently, with part-of-speech induction, or syntactic class induction, being a particularly popular task.&apos; However, despite a recent proliferation of syntactic class induction systems (Biemann, 2006; Goldwater and Griffiths, 2007; Johnson, 2007; Ravi and Knight, 2009; Berg-Kirkpatrick et al., 2010; Lee et al., 2010), careful comparison indicates that very few systems perform better than some much simpler and quicker methods dating back ten or even twenty years (Christodoulopoulos &apos;The task is more commonly referred to as part-of-speech induction, but we prefer the term syntactic class induction since the induced classes may not coincide with part-of-speech tags. et al., 2010). This fact suggests that we should consider which features of the older systems led to their success, and attempt</context>
</contexts>
<marker>Biemann, 2006</marker>
<rawString>Chris Biemann. 2006. Unsupervised part-of-speech tagging employing efficient graph clustering. In Proceedings of COLING ACL 2006, pages 7–12, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alena B¨ohmov´a</author>
<author>Jan Hajiˇc</author>
<author>Eva Hajiˇcov´a</author>
<author>Barbora Hladk´a</author>
</authors>
<title>The Prague dependency treebank: Three-level annotation scenario.</title>
<date>2001</date>
<booktitle>In Anne Abeill´e, editor, Treebanks: Building and Using Syntactically Annotated Corpora,</booktitle>
<pages>103--126</pages>
<publisher>Kluwer Academic Publishers.</publisher>
<marker>B¨ohmov´a, Hajiˇc, Hajiˇcov´a, Hladk´a, 2001</marker>
<rawString>Alena B¨ohmov´a, Jan Hajiˇc, Eva Hajiˇcov´a, and Barbora Hladk´a. 2001. The Prague dependency treebank: Three-level annotation scenario. In Anne Abeill´e, editor, Treebanks: Building and Using Syntactically Annotated Corpora, pages 103 – 126. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Brants</author>
<author>Stefanie Dipper</author>
<author>Silvia Hansen</author>
<author>Wolfgang Lezius</author>
<author>George Smith</author>
</authors>
<title>The TIGER treebank.</title>
<date>2002</date>
<booktitle>In Proceedings of the Workshop on Treebanks and Linguistic Theories,</booktitle>
<location>Sozopol.</location>
<contexts>
<context position="21392" citStr="Brants et al., 2002" startWordPosition="3603" endWordPosition="3606">provides a very simple vector-based clustering baseline. The second baseline is a more recent vector-based syntactic class induction method, the SVD approach of (Lamar et al., 2010), which extends Sch¨utze (1995)’s original method and, like ours, enforces a one-class-per-tag restriction. As a third baseline we use the system of Clark (2003) since it is a type-level system that mod7Part of the Prague Arabic Treebank (Hajiˇc et al., 2003; Smrˇz and Pajas, 2004) 8Part of the BulTreeBank (Simov et al., 2004). 9Part of the Prague Dep. Treebank (B¨ohmov´a et al., 2001) 10Part of the TIGER Treebank (Brants et al., 2002) 11Part of the Sinica Treebank (Keh-Jiann et al., 2003) 12Part of the T¨ubingen Treebank of Spoken Japanese (formerly VERMOBIL Treebank - Kawata and Bartels (2000)). 13Part of the Slovene Dep. Treebank (Dˇzeroski et al., 2006) 14Part of the Cast3LB Treebank (Civit et al., 2006) 15Part of the METU-Sabanci Treebank (Oflazer et al., 2003). 16French Treebank (Abeill´e et al., 2000) 17Greek Dependency Treebank (Bamman et al., 2009) els morphology and has produced very good results on multilingual corpora. 4 Results and Analysis 4.1 Development results Tables 1 and 2 present the results from develop</context>
</contexts>
<marker>Brants, Dipper, Hansen, Lezius, Smith, 2002</marker>
<rawString>Sabine Brants, Stefanie Dipper, Silvia Hansen, Wolfgang Lezius, and George Smith. 2002. The TIGER treebank. In Proceedings of the Workshop on Treebanks and Linguistic Theories, Sozopol.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Vincent J Della Pietra</author>
<author>Peter V Desouza</author>
<author>Jennifer C Lai</author>
<author>Robert L Mercer</author>
</authors>
<title>Classbased n-gram models of natural language.</title>
<date>1992</date>
<journal>Computational Linguistics,</journal>
<volume>18</volume>
<issue>4</issue>
<contexts>
<context position="3041" citStr="Brown et al. (1992)" startWordPosition="466" endWordPosition="469">perty is not strictly true of linguistic data, but is a good approximation: as Lee et al. (2010) note, assigning each word type to its most frequent part of speech yields an upper bound accuracy of 93% or more for most languages. Since this is much better than the performance of current unsupervised syntactic class induction systems, constraining the model in this way seems likely to improve performance by reducing the number of parameters in the model and incorporating useful linguistic knowledge. Both of the older systems discussed by Christodoulopoulos et al. (2010), i.e., Clark (2003) and Brown et al. (1992), included this constraint and achieved very good performance relative to token-based systems. More recently, Lee et al. (2010) presented a new type-based model, and also reported very good results. A second property of our model, which distinguishes it from the type-based Bayesian model of Lee et al. (2010), is that the underlying probabilistic model is a clustering model, (specifically, a multinomial mixture model) rather than a sequence model (HMM). In this sense, our model is more closely re638 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 63</context>
</contexts>
<marker>Brown, Pietra, Desouza, Lai, Mercer, 1992</marker>
<rawString>Peter F. Brown, Vincent J. Della Pietra, Peter V. Desouza, Jennifer C. Lai, and Robert L. Mercer. 1992. Classbased n-gram models of natural language. Computational Linguistics, 18(4):467–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>CoNLLX shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the Tenth Conference on Computational Natural Language Learning, CoNLL-X ’06,</booktitle>
<pages>149--164</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="19953" citStr="Buchholz and Marsi, 2006" startWordPosition="3376" endWordPosition="3379">e value, and similarly the � parameters for the two kinds of alignment features. θ α z m f(T) φ(T) β(T) φ(-) β(-) Z . . . f(1) φ(1) β(1) nj nj M . . . . . . Z Z 642 lection, we also used the Penn Treebank WSJ corpus (Marcus et al., 1993) for development. Following Christodoulopoulos et al. (2010) we created a smaller version of the WSJ corpus (referred to as wsj-s) to approximate the size of the corpora in MULTEXT-East. For comparison to other systems, we also used the full WSJ at test time. For further testing, we used the remaining MULTEXT languages, as well as the languages of the CONNL-X (Buchholz and Marsi, 2006) shared task. This dataset contains 13 languages, 4 of which are freely available (Danish, Dutch, Portuguese and Swedish) and 9 that are used with permission from the creators of the corpora ( Arabic7, Bulgarian8, Czech9, German10, Chinese11, Japanese12, Slovene13, Spanish14, Turkish15 ). Following Lee et al. (2010) we used only the training sections for each language. Finally, to widen the scope of our system, we generated two more corpora in French16 and Ancient Greek17, extracting the gold standard parts of speech from the respective dependency treebanks. 3.3 Baselines We chose three baseli</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Sabine Buchholz and Erwin Marsi. 2006. CoNLLX shared task on multilingual dependency parsing. In Proceedings of the Tenth Conference on Computational Natural Language Learning, CoNLL-X ’06, pages 149–164, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christos Christodoulopoulos</author>
<author>Sharon Goldwater</author>
<author>Mark Steedman</author>
</authors>
<title>Two decades of unsupervised POS induction: How far have we come?</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>575--584</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Cambridge, MA,</location>
<contexts>
<context position="2997" citStr="Christodoulopoulos et al. (2010)" startWordPosition="458" endWordPosition="461">iven word type are assigned to the same cluster. This property is not strictly true of linguistic data, but is a good approximation: as Lee et al. (2010) note, assigning each word type to its most frequent part of speech yields an upper bound accuracy of 93% or more for most languages. Since this is much better than the performance of current unsupervised syntactic class induction systems, constraining the model in this way seems likely to improve performance by reducing the number of parameters in the model and incorporating useful linguistic knowledge. Both of the older systems discussed by Christodoulopoulos et al. (2010), i.e., Clark (2003) and Brown et al. (1992), included this constraint and achieved very good performance relative to token-based systems. More recently, Lee et al. (2010) presented a new type-based model, and also reported very good results. A second property of our model, which distinguishes it from the type-based Bayesian model of Lee et al. (2010), is that the underlying probabilistic model is a clustering model, (specifically, a multinomial mixture model) rather than a sequence model (HMM). In this sense, our model is more closely re638 Proceedings of the 2011 Conference on Empirical Meth</context>
<context position="5059" citStr="Christodoulopoulos et al. (2010)" startWordPosition="783" endWordPosition="786">ble alternative to sequence models. One advantage of using a clustering model rather than a sequence model is that the features used for clustering need not be restricted to context words. Additional types of features can easily be incorporated into the model and inference procedure using the same general framework as in the basic model that uses only context word features. In particular, we present two extensions to the basic model. The first uses morphological features, which serve as cues to syntactic class and seemed to partly explain the success of two best-performing systems analysed by Christodoulopoulos et al. (2010). The second extension to our model uses alignment features gathered from parallel corpora. Previous work suggests that using parallel text can improve performance on various unsupervised NLP tasks (Naseem et al., 2009; Snyder and Barzilay, 2008). We evaluate our model on 25 corpora in 20 languages that vary substantially in both syntax and morphology. As in previous work (Lee et al., 2010), we find that the one-class-per-type restriction boosts performance considerably over a comparable tokenbased model and yields results that are comparable to state-of-the-art even without the use of morphol</context>
<context position="18737" citStr="Christodoulopoulos et al., 2010" startWordPosition="3152" endWordPosition="3155">lass assignments to word types (referred to as method 1) and second, we assign each of the Z most frequent word types to a separate class and then randomly distribute the rest of the word types to the classes (method 2). 3.2 Datasets Although unsupervised systems should in principle be language- and corpus-independent, most part-ofspeech induction systems (especially in the early literature) have been developed on English. Whether because English is simply an easier language, or because of bias introduced during development, these systems’ performance is considerably worse in other languages (Christodoulopoulos et al., 2010) Since we aim to use our system mostly on nonEnglish corpora, and ones that are significantly smaller than the large English treebank corpora, we developed our models using one of the languages of the MULTEXT-East corpus (Erjavec, 2004), namely Bulgarian. The other languages in the corpus were used during development as a source of word alignments, but otherwise were only used for testing final versions of our models. Since none of the authors speak any of the languages in the MULTEXT col6For simplicity, we tied the 0 parameters for the two or four kinds of context features to the same value, </context>
<context position="22435" citStr="Christodoulopoulos et al., 2010" startWordPosition="3769" endWordPosition="3772">amman et al., 2009) els morphology and has produced very good results on multilingual corpora. 4 Results and Analysis 4.1 Development results Tables 1 and 2 present the results from development runs, which were used to decide which features to incorporate in the final system. We used VMeasure (Rosenberg and Hirschberg, 2007) as our primary evaluation score, but also present many-toone matching accuracy (M-1) scores for better comparison with previously published results. We chose V-Measure (VM) as our evaluation score because it is less sensitive to the number of classes induced by the model (Christodoulopoulos et al., 2010), allowing us to develop our models without using the number of classes as a parameter. We fixed the number of classes in all systems to 45 during development; note however that the gold standard tag set for Bulgarian contains only 12 tags, so the results in Table 1 (especially the M-1 scores) are not comparable to previous results. For results using the number of gold-standard tags refer to Table 4. The first conclusion that can be drawn from these results is the large difference between the tokenand type-based versions of our system, which confirms that the one-class-per-type restriction is </context>
<context position="31146" citStr="Christodoulopoulos et al. (2010)" startWordPosition="5381" endWordPosition="5384">2 54.8 / 68.2 61.6 / 71.9 - / 73.21 63.2 / 71.7 Swedish 20,057 41 53.2 / 62.2 47.4 / 59.1 58.9 / 68.7 - / 60.61 58.0 / 68.2 Turkish 17,563 30 40.8 / 62.8 27.4 / 52.4 36.8 / 58.1 - 40.2 / 58.7 French 49,964 23 48.2 / 68.6 46.3 / 68.5 57.3 / 77.8 - 55.0 / 76.6 A.Greek 15,194 15 38.6 / 44.8 24.2 / 38.5 33.3 / 45.4 - 40.5 / 45.1 Table 4: Final results on 25 corpora in 20 languages, with the number of induced classes equal to the number of gold standard tags in all cases. k-means and SVD2 models could not produce a clustering in the Czech CoNLL corpus due its size. Best published results are from *Christodoulopoulos et al. (2010), tBerg-Kirkpatrick et al. (2010) and tLee et al. (2010). The latter two papers do not report VM scores. No best published results are shown for the MULTEXT languages; Christodoulopoulos et al. (2010) report results based on 45 tags suggesting that clark performs best on these corpora. 645 comparison with a token-based version of the model that this restriction is very helpful. Second, it is a clustering model rather than a sequence model. This property makes it easy to incorporate multiple kinds of features into the model at either the token or the type level. Here, we experimented with token</context>
</contexts>
<marker>Christodoulopoulos, Goldwater, Steedman, 2010</marker>
<rawString>Christos Christodoulopoulos, Sharon Goldwater, and Mark Steedman. 2010. Two decades of unsupervised POS induction: How far have we come? In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 575–584, Cambridge, MA, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martf</author>
<author>N´uria Buff</author>
</authors>
<title>Cat3lb and cast3lb: From constituents to dependencies.</title>
<date>2006</date>
<booktitle>Advances in Natural Language Processing,</booktitle>
<volume>4139</volume>
<pages>141--152</pages>
<editor>In Tapio Salakoski, Filip Ginter, Sampo Pyysalo, and Tapio Pahikkala, editors,</editor>
<publisher>Springer</publisher>
<location>Berlin / Heidelberg.</location>
<marker>Martf, Buff, 2006</marker>
<rawString>Montserrat Civit, Ma. Martf, and N´uria Buff. 2006. Cat3lb and cast3lb: From constituents to dependencies. In Tapio Salakoski, Filip Ginter, Sampo Pyysalo, and Tapio Pahikkala, editors, Advances in Natural Language Processing, volume 4139 of Lecture Notes in Computer Science, pages 141–152. Springer Berlin / Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Clark</author>
</authors>
<title>Combining distributional and morphological information for part of speech induction.</title>
<date>2003</date>
<booktitle>In Proceedings of EACL 2003,</booktitle>
<pages>59--66</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="3017" citStr="Clark (2003)" startWordPosition="463" endWordPosition="464">cluster. This property is not strictly true of linguistic data, but is a good approximation: as Lee et al. (2010) note, assigning each word type to its most frequent part of speech yields an upper bound accuracy of 93% or more for most languages. Since this is much better than the performance of current unsupervised syntactic class induction systems, constraining the model in this way seems likely to improve performance by reducing the number of parameters in the model and incorporating useful linguistic knowledge. Both of the older systems discussed by Christodoulopoulos et al. (2010), i.e., Clark (2003) and Brown et al. (1992), included this constraint and achieved very good performance relative to token-based systems. More recently, Lee et al. (2010) presented a new type-based model, and also reported very good results. A second property of our model, which distinguishes it from the type-based Bayesian model of Lee et al. (2010), is that the underlying probabilistic model is a clustering model, (specifically, a multinomial mixture model) rather than a sequence model (HMM). In this sense, our model is more closely re638 Proceedings of the 2011 Conference on Empirical Methods in Natural Langu</context>
<context position="21114" citStr="Clark (2003)" startWordPosition="3556" endWordPosition="3557">ency treebanks. 3.3 Baselines We chose three baselines for comparison. The first is the basic k-means clustering algorithm, which we applied to the same feature vectors we extracted for our system (context + extended morphology), using a Euclidean distance metric. This provides a very simple vector-based clustering baseline. The second baseline is a more recent vector-based syntactic class induction method, the SVD approach of (Lamar et al., 2010), which extends Sch¨utze (1995)’s original method and, like ours, enforces a one-class-per-tag restriction. As a third baseline we use the system of Clark (2003) since it is a type-level system that mod7Part of the Prague Arabic Treebank (Hajiˇc et al., 2003; Smrˇz and Pajas, 2004) 8Part of the BulTreeBank (Simov et al., 2004). 9Part of the Prague Dep. Treebank (B¨ohmov´a et al., 2001) 10Part of the TIGER Treebank (Brants et al., 2002) 11Part of the Sinica Treebank (Keh-Jiann et al., 2003) 12Part of the T¨ubingen Treebank of Spoken Japanese (formerly VERMOBIL Treebank - Kawata and Bartels (2000)). 13Part of the Slovene Dep. Treebank (Dˇzeroski et al., 2006) 14Part of the Cast3LB Treebank (Civit et al., 2006) 15Part of the METU-Sabanci Treebank (Oflaze</context>
</contexts>
<marker>Clark, 2003</marker>
<rawString>Alexander Clark. 2003. Combining distributional and morphological information for part of speech induction. In Proceedings of EACL 2003, pages 59–66, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mathias Creutz</author>
<author>Krista Lagus</author>
</authors>
<title>Inducing the morphological lexicon of a natural language from unannotated text. In</title>
<date>2005</date>
<booktitle>In Proceedings of the International and Interdisciplinary Conference on Adaptive Knowledge Representation and Reasoning (AKRR’05),</booktitle>
<volume>5</volume>
<pages>106--113</pages>
<contexts>
<context position="15586" citStr="Creutz and Lagus, 2005" startWordPosition="2636" endWordPosition="2639">th the other kinds of features, we use only a limited number F,,t of morphology features, as described below. 3 Experiments 3.1 Experimental setup We evaluate our models using an increasing level of complexity, starting with a model that uses only monolingual context features. We use the F = 100 most frequent words as features, and consider two versions of this model: one with two kinds of features (one left and one right context word) and one with four (two context words on each side). For the model with morphology features we ran the unsupervised morphological segmentation system Morfessor (Creutz and Lagus, 2005) to get a T H t=1 641 Figure 2: Plate diagram of the extended model with T kinds of token-level features (f(t) variables) and a single kind of type-level feature (morphology, m). segmentation for each word type in the corpus. We then extracted the suffix of each word type4 and used it as a feature type. This process yielded on average F,,t = 110 morphological feature types5. Each word type generates at most one of these possible features. If there are overlapping possibilities (e.g. -ingly and -y) we take the longest possible match. We also explore the idea of extending the morphology feature </context>
</contexts>
<marker>Creutz, Lagus, 2005</marker>
<rawString>Mathias Creutz and Krista Lagus. 2005. Inducing the morphological lexicon of a natural language from unannotated text. In In Proceedings of the International and Interdisciplinary Conference on Adaptive Knowledge Representation and Reasoning (AKRR’05), volume 5, pages 106–113.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saso Dzeroski</author>
</authors>
<title>Toma&amp;quot;z Erjavec, Nina Ledinek, Petr Pajas, Zdenek &amp;quot;Zabokrtsky, and Andreja &amp;quot;Zele.</title>
<date>2006</date>
<booktitle>In Proceedings Int. Conf. on Language Resources and Evaluation (LREC).</booktitle>
<marker>Dzeroski, 2006</marker>
<rawString>Sa&amp;quot;so D&amp;quot;zeroski, Toma&amp;quot;z Erjavec, Nina Ledinek, Petr Pajas, Zdenek &amp;quot;Zabokrtsky, and Andreja &amp;quot;Zele. 2006. Towards a Slovene dependency treebank. In Proceedings Int. Conf. on Language Resources and Evaluation (LREC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomaz Erjavec</author>
</authors>
<title>MULTEXT-East version 3: Multilingual morphosyntactic specifications, lexicons and corpora.</title>
<date>2004</date>
<booktitle>In Fourth International Conference on Language Resources and Evaluation, (LREC’04),</booktitle>
<pages>1535--1538</pages>
<location>Paris. ELRA.</location>
<contexts>
<context position="18973" citStr="Erjavec, 2004" startWordPosition="3193" endWordPosition="3194">d systems should in principle be language- and corpus-independent, most part-ofspeech induction systems (especially in the early literature) have been developed on English. Whether because English is simply an easier language, or because of bias introduced during development, these systems’ performance is considerably worse in other languages (Christodoulopoulos et al., 2010) Since we aim to use our system mostly on nonEnglish corpora, and ones that are significantly smaller than the large English treebank corpora, we developed our models using one of the languages of the MULTEXT-East corpus (Erjavec, 2004), namely Bulgarian. The other languages in the corpus were used during development as a source of word alignments, but otherwise were only used for testing final versions of our models. Since none of the authors speak any of the languages in the MULTEXT col6For simplicity, we tied the 0 parameters for the two or four kinds of context features to the same value, and similarly the � parameters for the two kinds of alignment features. θ α z m f(T) φ(T) β(T) φ(-) β(-) Z . . . f(1) φ(1) β(1) nj nj M . . . . . . Z Z 642 lection, we also used the Penn Treebank WSJ corpus (Marcus et al., 1993) for dev</context>
</contexts>
<marker>Erjavec, 2004</marker>
<rawString>Toma&amp;quot;z Erjavec. 2004. MULTEXT-East version 3: Multilingual morphosyntactic specifications, lexicons and corpora. In Fourth International Conference on Language Resources and Evaluation, (LREC’04), pages 1535 – 1538, Paris. ELRA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon Goldwater</author>
<author>Tom Griffiths</author>
</authors>
<title>A fully bayesian approach to unsupervised part-of-speech tagging.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL 2007,</booktitle>
<pages>744--751</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="1427" citStr="Goldwater and Griffiths, 2007" startWordPosition="202" endWordPosition="205"> corpora). Using only context features, our system yields results comparable to state-of-the art, far better than a similar model without the one-class-per-type constraint. Using the additional features provides added benefit, and our final system outperforms the best published results on most of the 25 corpora tested. 1 Introduction Research on unsupervised learning for NLP has become widespread recently, with part-of-speech induction, or syntactic class induction, being a particularly popular task.&apos; However, despite a recent proliferation of syntactic class induction systems (Biemann, 2006; Goldwater and Griffiths, 2007; Johnson, 2007; Ravi and Knight, 2009; Berg-Kirkpatrick et al., 2010; Lee et al., 2010), careful comparison indicates that very few systems perform better than some much simpler and quicker methods dating back ten or even twenty years (Christodoulopoulos &apos;The task is more commonly referred to as part-of-speech induction, but we prefer the term syntactic class induction since the induced classes may not coincide with part-of-speech tags. et al., 2010). This fact suggests that we should consider which features of the older systems led to their success, and attempt to combine these features with</context>
<context position="4192" citStr="Goldwater and Griffiths, 2007" startWordPosition="641" endWordPosition="644"> 2011 Conference on Empirical Methods in Natural Language Processing, pages 638–647, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics lated to several non-probabilistic systems that cluster context vectors or lower-dimensional representations of them (Redington et al., 1998; Sch¨utze, 1995; Lamar et al., 2010). Sequence models are by far the most common method of supervised partof-speech tagging, and have also been widely used for unsupervised part-of-speech tagging both with and without a dictionary (Smith and Eisner, 2005; Haghighi and Klein, 2006; Goldwater and Griffiths, 2007; Johnson, 2007; Ravi and Knight, 2009; Lee et al., 2010). However, systems based on context vectors have also performed well in these latter scenarios (Sch¨utze, 1995; Lamar et al., 2010; Toutanova and Johnson, 2007) and present a viable alternative to sequence models. One advantage of using a clustering model rather than a sequence model is that the features used for clustering need not be restricted to context words. Additional types of features can easily be incorporated into the model and inference procedure using the same general framework as in the basic model that uses only context wor</context>
<context position="17431" citStr="Goldwater and Griffiths (2007)" startWordPosition="2942" endWordPosition="2945">that are found in both directions. As discussed 4Since Morfessor yields multiple affixes for each word we concatenated all the suffixes into a single suffix. 5There was large variance in the number of feature types for each language ranging from 11 in Chinese to more than 350 in German and Czech. above, we use two kinds of alignment features: the left and right context words of the aligned token in the other language. The feature space is set to the F = 100 most frequent words in that language. Instead of fixing the hyperparameters α and β, we used the Metropolis-Hastings sampler presented by Goldwater and Griffiths (2007) to get updated values based on the likelihood of the data with respect to those hyperparameters6. In order to improve convergence of the sampler, we used simulated annealing with a sigmoid-shaped cooling schedule from an initial temperature of 2 down to 1. Preliminary experiments indicated that we could achieve better results by cooling even further (approximating the MAP solution rather than a sample from the posterior), so for all experiments reported here, we ran the sampler for a total of 2000 iterations, with the last 400 of these decreasing the temperature from 1 to 0.66. Finally, we in</context>
</contexts>
<marker>Goldwater, Griffiths, 2007</marker>
<rawString>Sharon Goldwater and Tom Griffiths. 2007. A fully bayesian approach to unsupervised part-of-speech tagging. In Proceedings of ACL 2007, pages 744–751, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Dan Klein</author>
</authors>
<title>Prototype-driven learning for sequence models.</title>
<date>2006</date>
<booktitle>In Proceedings of NAACL 2006,</booktitle>
<pages>320--327</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="4161" citStr="Haghighi and Klein, 2006" startWordPosition="637" endWordPosition="640">y re638 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 638–647, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics lated to several non-probabilistic systems that cluster context vectors or lower-dimensional representations of them (Redington et al., 1998; Sch¨utze, 1995; Lamar et al., 2010). Sequence models are by far the most common method of supervised partof-speech tagging, and have also been widely used for unsupervised part-of-speech tagging both with and without a dictionary (Smith and Eisner, 2005; Haghighi and Klein, 2006; Goldwater and Griffiths, 2007; Johnson, 2007; Ravi and Knight, 2009; Lee et al., 2010). However, systems based on context vectors have also performed well in these latter scenarios (Sch¨utze, 1995; Lamar et al., 2010; Toutanova and Johnson, 2007) and present a viable alternative to sequence models. One advantage of using a clustering model rather than a sequence model is that the features used for clustering need not be restricted to context words. Additional types of features can easily be incorporated into the model and inference procedure using the same general framework as in the basic m</context>
<context position="16339" citStr="Haghighi and Klein (2006)" startWordPosition="2762" endWordPosition="2765">single kind of type-level feature (morphology, m). segmentation for each word type in the corpus. We then extracted the suffix of each word type4 and used it as a feature type. This process yielded on average F,,t = 110 morphological feature types5. Each word type generates at most one of these possible features. If there are overlapping possibilities (e.g. -ingly and -y) we take the longest possible match. We also explore the idea of extending the morphology feature space beyond suffixes, by including features like capitalisation and punctuation. Specifically we use the features described in Haghighi and Klein (2006), namely initial-capital, containshyphen, contains-digit and we add an extra feature contains-punctuation. For the model with alignment features, we follow (Naseem et al., 2009) in using only bidirectional alignments: using Giza++ (Och and Ney, 2003), we get the word alignments in both directions between all possible language pairs in our parallel corpora (i.e., alternating the source and target languages within each pair). We then use only those alignments that are found in both directions. As discussed 4Since Morfessor yields multiple affixes for each word we concatenated all the suffixes in</context>
<context position="23461" citStr="Haghighi and Klein (2006)" startWordPosition="3945" endWordPosition="3948">4. The first conclusion that can be drawn from these results is the large difference between the tokenand type-based versions of our system, which confirms that the one-class-per-type restriction is helpful for unsupervised syntactic class induction. We also see that for both languages, the performance of the model using 4 context words (±2 on each side) is worse than the 2 context words model. We therefore used only two context words for all of our additional test languages (below). We can clearly see that morphological features are helpful in both languages; however the extended features of Haghighi and Klein (2006) seem to help only on the English data. This could be due to the fact that Bulgarian has a much richer morphology and thus the extra features contribute little to the overall performance of the model. The contribution of the alignment features on the Bulgarian corpus (aligned with English) is less significant than that of morphology but when combined, the two sets of features yield the best performance. This provides evidence in favor of using multiple features. Finally, initialisation method 2 does not yield 643 system f1 words f2 words VM/M-1 VM/M-1 base 58.1 / 70.8 55.4 / 67.6 base(tokens) </context>
</contexts>
<marker>Haghighi, Klein, 2006</marker>
<rawString>Aria Haghighi and Dan Klein. 2006. Prototype-driven learning for sequence models. In Proceedings of NAACL 2006, pages 320–327, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajic</author>
<author>Jarmila Panevov´a</author>
<author>Zdenka Uresov´a</author>
<author>Alevtina B´emov´a</author>
<author>Petr Pajas</author>
</authors>
<title>PDTVALLEX: creating a large-coverage valency lexicon for treebank annotation.</title>
<date>2003</date>
<booktitle>In Proceedings of The Second Workshop on Treebanks and Linguistic Theories,</booktitle>
<pages>57--68</pages>
<publisher>Vaxjo University Press.</publisher>
<marker>Hajic, Panevov´a, Uresov´a, B´emov´a, Pajas, 2003</marker>
<rawString>Jan Haji&amp;quot;c, Jarmila Panevov´a, Zde&amp;quot;nka Ure&amp;quot;sov´a, Alevtina B´emov´a, and Petr Pajas. 2003. PDTVALLEX: creating a large-coverage valency lexicon for treebank annotation. In Proceedings of The Second Workshop on Treebanks and Linguistic Theories, pages 57–68. Vaxjo University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
</authors>
<title>Why doesn’t EM find good HMM POS-taggers?</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP-CoNLL 2007,</booktitle>
<pages>296--305</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="1442" citStr="Johnson, 2007" startWordPosition="206" endWordPosition="208">eatures, our system yields results comparable to state-of-the art, far better than a similar model without the one-class-per-type constraint. Using the additional features provides added benefit, and our final system outperforms the best published results on most of the 25 corpora tested. 1 Introduction Research on unsupervised learning for NLP has become widespread recently, with part-of-speech induction, or syntactic class induction, being a particularly popular task.&apos; However, despite a recent proliferation of syntactic class induction systems (Biemann, 2006; Goldwater and Griffiths, 2007; Johnson, 2007; Ravi and Knight, 2009; Berg-Kirkpatrick et al., 2010; Lee et al., 2010), careful comparison indicates that very few systems perform better than some much simpler and quicker methods dating back ten or even twenty years (Christodoulopoulos &apos;The task is more commonly referred to as part-of-speech induction, but we prefer the term syntactic class induction since the induced classes may not coincide with part-of-speech tags. et al., 2010). This fact suggests that we should consider which features of the older systems led to their success, and attempt to combine these features with some of the ma</context>
<context position="4207" citStr="Johnson, 2007" startWordPosition="645" endWordPosition="646">ethods in Natural Language Processing, pages 638–647, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics lated to several non-probabilistic systems that cluster context vectors or lower-dimensional representations of them (Redington et al., 1998; Sch¨utze, 1995; Lamar et al., 2010). Sequence models are by far the most common method of supervised partof-speech tagging, and have also been widely used for unsupervised part-of-speech tagging both with and without a dictionary (Smith and Eisner, 2005; Haghighi and Klein, 2006; Goldwater and Griffiths, 2007; Johnson, 2007; Ravi and Knight, 2009; Lee et al., 2010). However, systems based on context vectors have also performed well in these latter scenarios (Sch¨utze, 1995; Lamar et al., 2010; Toutanova and Johnson, 2007) and present a viable alternative to sequence models. One advantage of using a clustering model rather than a sequence model is that the features used for clustering need not be restricted to context words. Additional types of features can easily be incorporated into the model and inference procedure using the same general framework as in the basic model that uses only context word features. In </context>
<context position="13842" citStr="Johnson, 2007" startWordPosition="2355" endWordPosition="2356">en by Lee et al. (2010). 3We use the word kind here to avoid confusion with type, which we reserve for the type-token distinction, which can apply to features as well as words. Note that this model with multiple context features is deficient: it can generate data that are inconsistent with any actual corpus, because there is no mechanism to constrain the left context word of token ei to be the same as the right context word of token ei−1 (and similarly with alignment features). However, deficient models have proven useful in other unsupervised NLP tasks (Klein and Manning, 2002; Toutanova and Johnson, 2007). In particular, Toutanova and Johnson (2007) demonstrate good performance on unsupervised part-ofspeech tagging (using a dictionary) with a Bayesian model similar to our own. If we remove the part of their model that relies on the dictionary (the morphological ambiguity classes), their model is equivalent to our own, without the restriction of one class per type. We use this token-based version of our model as a baseline in our experiments. The final extension to our model introduces typelevel features, specifically morphology features. The model is illustrated in Figure 2. We assume conditio</context>
</contexts>
<marker>Johnson, 2007</marker>
<rawString>Mark Johnson. 2007. Why doesn’t EM find good HMM POS-taggers? In Proceedings of EMNLP-CoNLL 2007, pages 296–305, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yasushira Kawata</author>
<author>Julia Bartels</author>
</authors>
<title>Stylebook for the Japanese treebank in VERMOBIL.</title>
<date>2000</date>
<tech>Technical report, Universit¨at T¨uubingen.</tech>
<contexts>
<context position="21555" citStr="Kawata and Bartels (2000)" startWordPosition="3629" endWordPosition="3632">of (Lamar et al., 2010), which extends Sch¨utze (1995)’s original method and, like ours, enforces a one-class-per-tag restriction. As a third baseline we use the system of Clark (2003) since it is a type-level system that mod7Part of the Prague Arabic Treebank (Hajiˇc et al., 2003; Smrˇz and Pajas, 2004) 8Part of the BulTreeBank (Simov et al., 2004). 9Part of the Prague Dep. Treebank (B¨ohmov´a et al., 2001) 10Part of the TIGER Treebank (Brants et al., 2002) 11Part of the Sinica Treebank (Keh-Jiann et al., 2003) 12Part of the T¨ubingen Treebank of Spoken Japanese (formerly VERMOBIL Treebank - Kawata and Bartels (2000)). 13Part of the Slovene Dep. Treebank (Dˇzeroski et al., 2006) 14Part of the Cast3LB Treebank (Civit et al., 2006) 15Part of the METU-Sabanci Treebank (Oflazer et al., 2003). 16French Treebank (Abeill´e et al., 2000) 17Greek Dependency Treebank (Bamman et al., 2009) els morphology and has produced very good results on multilingual corpora. 4 Results and Analysis 4.1 Development results Tables 1 and 2 present the results from development runs, which were used to decide which features to incorporate in the final system. We used VMeasure (Rosenberg and Hirschberg, 2007) as our primary evaluation</context>
</contexts>
<marker>Kawata, Bartels, 2000</marker>
<rawString>Yasushira Kawata and Julia Bartels. 2000. Stylebook for the Japanese treebank in VERMOBIL. Technical report, Universit¨at T¨uubingen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen Keh-Jiann</author>
</authors>
<title>Chu-Ren Huang, Feng-Yi Chen, ChiChing Luo, Ming-Chung Chang, Chao-Jan Chen, and Zhao-Ming Gao.</title>
<date>2003</date>
<booktitle>Treebanks: Building and Using Syntactically Annotated Corpora,</booktitle>
<pages>231--248</pages>
<editor>In Anne Abeill´e, editor,</editor>
<publisher>Kluwer Academic Publishers.</publisher>
<marker>Keh-Jiann, 2003</marker>
<rawString>Chen Keh-Jiann, Chu-Ren Huang, Feng-Yi Chen, ChiChing Luo, Ming-Chung Chang, Chao-Jan Chen, and Zhao-Ming Gao. 2003. Sinica treebank: Design criteria, representational issues and implementation. In Anne Abeill´e, editor, Treebanks: Building and Using Syntactically Annotated Corpora, pages 231–248. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>A generative constituent-context model for improved grammar induction.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL 40,</booktitle>
<pages>128--135</pages>
<contexts>
<context position="13812" citStr="Klein and Manning, 2002" startWordPosition="2349" endWordPosition="2352">f word type j. This is the approach taken by Lee et al. (2010). 3We use the word kind here to avoid confusion with type, which we reserve for the type-token distinction, which can apply to features as well as words. Note that this model with multiple context features is deficient: it can generate data that are inconsistent with any actual corpus, because there is no mechanism to constrain the left context word of token ei to be the same as the right context word of token ei−1 (and similarly with alignment features). However, deficient models have proven useful in other unsupervised NLP tasks (Klein and Manning, 2002; Toutanova and Johnson, 2007). In particular, Toutanova and Johnson (2007) demonstrate good performance on unsupervised part-ofspeech tagging (using a dictionary) with a Bayesian model similar to our own. If we remove the part of their model that relies on the dictionary (the morphological ambiguity classes), their model is equivalent to our own, without the restriction of one class per type. We use this token-based version of our model as a baseline in our experiments. The final extension to our model introduces typelevel features, specifically morphology features. The model is illustrated i</context>
</contexts>
<marker>Klein, Manning, 2002</marker>
<rawString>Dan Klein and Christopher D. Manning. 2002. A generative constituent-context model for improved grammar induction. In Proceedings of ACL 40, pages 128–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Lamar</author>
<author>Yariv Maron</author>
<author>Mark Johnson</author>
<author>Elie Bienenstock</author>
</authors>
<title>SVD and clustering for unsupervised POS tagging.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL 2010 Conference Short Papers,</booktitle>
<pages>215--219</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="3917" citStr="Lamar et al., 2010" startWordPosition="599" endWordPosition="602">m the type-based Bayesian model of Lee et al. (2010), is that the underlying probabilistic model is a clustering model, (specifically, a multinomial mixture model) rather than a sequence model (HMM). In this sense, our model is more closely re638 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 638–647, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics lated to several non-probabilistic systems that cluster context vectors or lower-dimensional representations of them (Redington et al., 1998; Sch¨utze, 1995; Lamar et al., 2010). Sequence models are by far the most common method of supervised partof-speech tagging, and have also been widely used for unsupervised part-of-speech tagging both with and without a dictionary (Smith and Eisner, 2005; Haghighi and Klein, 2006; Goldwater and Griffiths, 2007; Johnson, 2007; Ravi and Knight, 2009; Lee et al., 2010). However, systems based on context vectors have also performed well in these latter scenarios (Sch¨utze, 1995; Lamar et al., 2010; Toutanova and Johnson, 2007) and present a viable alternative to sequence models. One advantage of using a clustering model rather than </context>
<context position="8787" citStr="Lamar et al., 2010" startWordPosition="1421" endWordPosition="1424">he model is as a vector-based clustering system, where word type j is associated with a 1 x F vector of feature counts representing the features of all nj tokens of j, and these vectors are clustered into similar classes. The difference from other vector-based syntactic class induction systems is in the method of clustering. Here, we define a Gibbs sampler that samples from the posterior distribution of the clusters given the observed features; other systems have used various standard distance-based vector clustering methods. Some systems also include dimensionality reduction (Sch¨utze, 1995; Lamar et al., 2010) to reduce the size of the context vectors; we simply use the F most common words as context features. 2.2 Inference At inference time we want to sample a syntactic class assignment z from the posterior of the model. We use a collapsed Gibbs sampler, integrating out the parameters θ and ϕ and sampling from the following distribution: P(z|f, α, β) a P(z|α)P(f|z, β). (1) Rather than sampling the joint class assignment P(z|f, α,β) directly, the sampler iterates over each word type j, resampling its class assignment zj given the current assignments z−j of all other word types. The posterior over z</context>
<context position="20953" citStr="Lamar et al., 2010" startWordPosition="3530" endWordPosition="3533">to widen the scope of our system, we generated two more corpora in French16 and Ancient Greek17, extracting the gold standard parts of speech from the respective dependency treebanks. 3.3 Baselines We chose three baselines for comparison. The first is the basic k-means clustering algorithm, which we applied to the same feature vectors we extracted for our system (context + extended morphology), using a Euclidean distance metric. This provides a very simple vector-based clustering baseline. The second baseline is a more recent vector-based syntactic class induction method, the SVD approach of (Lamar et al., 2010), which extends Sch¨utze (1995)’s original method and, like ours, enforces a one-class-per-tag restriction. As a third baseline we use the system of Clark (2003) since it is a type-level system that mod7Part of the Prague Arabic Treebank (Hajiˇc et al., 2003; Smrˇz and Pajas, 2004) 8Part of the BulTreeBank (Simov et al., 2004). 9Part of the Prague Dep. Treebank (B¨ohmov´a et al., 2001) 10Part of the TIGER Treebank (Brants et al., 2002) 11Part of the Sinica Treebank (Keh-Jiann et al., 2003) 12Part of the T¨ubingen Treebank of Spoken Japanese (formerly VERMOBIL Treebank - Kawata and Bartels (200</context>
</contexts>
<marker>Lamar, Maron, Johnson, Bienenstock, 2010</marker>
<rawString>Michael Lamar, Yariv Maron, Mark Johnson, and Elie Bienenstock. 2010. SVD and clustering for unsupervised POS tagging. In Proceedings of the ACL 2010 Conference Short Papers, pages 215–219, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoong Keok Lee</author>
<author>Aria Haghighi</author>
<author>Regina Barzilay</author>
</authors>
<title>Simple type-level unsupervised POS tagging.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP ’10,</booktitle>
<pages>853--861</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1515" citStr="Lee et al., 2010" startWordPosition="217" endWordPosition="220">r better than a similar model without the one-class-per-type constraint. Using the additional features provides added benefit, and our final system outperforms the best published results on most of the 25 corpora tested. 1 Introduction Research on unsupervised learning for NLP has become widespread recently, with part-of-speech induction, or syntactic class induction, being a particularly popular task.&apos; However, despite a recent proliferation of syntactic class induction systems (Biemann, 2006; Goldwater and Griffiths, 2007; Johnson, 2007; Ravi and Knight, 2009; Berg-Kirkpatrick et al., 2010; Lee et al., 2010), careful comparison indicates that very few systems perform better than some much simpler and quicker methods dating back ten or even twenty years (Christodoulopoulos &apos;The task is more commonly referred to as part-of-speech induction, but we prefer the term syntactic class induction since the induced classes may not coincide with part-of-speech tags. et al., 2010). This fact suggests that we should consider which features of the older systems led to their success, and attempt to combine these features with some of the machine learning methods introduced by the more recent systems. We pursue t</context>
<context position="3168" citStr="Lee et al. (2010)" startWordPosition="485" endWordPosition="488">o its most frequent part of speech yields an upper bound accuracy of 93% or more for most languages. Since this is much better than the performance of current unsupervised syntactic class induction systems, constraining the model in this way seems likely to improve performance by reducing the number of parameters in the model and incorporating useful linguistic knowledge. Both of the older systems discussed by Christodoulopoulos et al. (2010), i.e., Clark (2003) and Brown et al. (1992), included this constraint and achieved very good performance relative to token-based systems. More recently, Lee et al. (2010) presented a new type-based model, and also reported very good results. A second property of our model, which distinguishes it from the type-based Bayesian model of Lee et al. (2010), is that the underlying probabilistic model is a clustering model, (specifically, a multinomial mixture model) rather than a sequence model (HMM). In this sense, our model is more closely re638 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 638–647, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics lated to several non-probabi</context>
<context position="5452" citStr="Lee et al., 2010" startWordPosition="848" endWordPosition="851">xtensions to the basic model. The first uses morphological features, which serve as cues to syntactic class and seemed to partly explain the success of two best-performing systems analysed by Christodoulopoulos et al. (2010). The second extension to our model uses alignment features gathered from parallel corpora. Previous work suggests that using parallel text can improve performance on various unsupervised NLP tasks (Naseem et al., 2009; Snyder and Barzilay, 2008). We evaluate our model on 25 corpora in 20 languages that vary substantially in both syntax and morphology. As in previous work (Lee et al., 2010), we find that the one-class-per-type restriction boosts performance considerably over a comparable tokenbased model and yields results that are comparable to state-of-the-art even without the use of morphology or alignment features. Including morphology features yields the best published results on 14 or 15 of our 25 corpora (depending on the measure) and alignment features can improve results further. 2 Models Our model is a multinomial mixture model with Bayesian priors over the mixing weights θ and Figure 1: Plate diagram of the basic model with a single feature per token (the observed var</context>
<context position="13251" citStr="Lee et al. (2010)" startWordPosition="2252" endWordPosition="2255">eatures for those languages where we have parallel corpora. These features are extracted for language ℓ by wordaligning ℓ to another language ℓ′ (details of the alignment procedure are described in Section 3.1). The features used for each token e in ℓ are the left and right context words of the word token that is aligned to e (if there is one). As with the monolingual context features, we use only the F most frequent words in ℓ′ as possible features. 2One could approximate this likelihood term by assuming independence between all nj feature tokens of word type j. This is the approach taken by Lee et al. (2010). 3We use the word kind here to avoid confusion with type, which we reserve for the type-token distinction, which can apply to features as well as words. Note that this model with multiple context features is deficient: it can generate data that are inconsistent with any actual corpus, because there is no mechanism to constrain the left context word of token ei to be the same as the right context word of token ei−1 (and similarly with alignment features). However, deficient models have proven useful in other unsupervised NLP tasks (Klein and Manning, 2002; Toutanova and Johnson, 2007). In part</context>
<context position="20270" citStr="Lee et al. (2010)" startWordPosition="3424" endWordPosition="3427">n of the WSJ corpus (referred to as wsj-s) to approximate the size of the corpora in MULTEXT-East. For comparison to other systems, we also used the full WSJ at test time. For further testing, we used the remaining MULTEXT languages, as well as the languages of the CONNL-X (Buchholz and Marsi, 2006) shared task. This dataset contains 13 languages, 4 of which are freely available (Danish, Dutch, Portuguese and Swedish) and 9 that are used with permission from the creators of the corpora ( Arabic7, Bulgarian8, Czech9, German10, Chinese11, Japanese12, Slovene13, Spanish14, Turkish15 ). Following Lee et al. (2010) we used only the training sections for each language. Finally, to widen the scope of our system, we generated two more corpora in French16 and Ancient Greek17, extracting the gold standard parts of speech from the respective dependency treebanks. 3.3 Baselines We chose three baselines for comparison. The first is the basic k-means clustering algorithm, which we applied to the same feature vectors we extracted for our system (context + extended morphology), using a Euclidean distance metric. This provides a very simple vector-based clustering baseline. The second baseline is a more recent vect</context>
<context position="31202" citStr="Lee et al. (2010)" startWordPosition="5390" endWordPosition="5393">/ 62.2 47.4 / 59.1 58.9 / 68.7 - / 60.61 58.0 / 68.2 Turkish 17,563 30 40.8 / 62.8 27.4 / 52.4 36.8 / 58.1 - 40.2 / 58.7 French 49,964 23 48.2 / 68.6 46.3 / 68.5 57.3 / 77.8 - 55.0 / 76.6 A.Greek 15,194 15 38.6 / 44.8 24.2 / 38.5 33.3 / 45.4 - 40.5 / 45.1 Table 4: Final results on 25 corpora in 20 languages, with the number of induced classes equal to the number of gold standard tags in all cases. k-means and SVD2 models could not produce a clustering in the Czech CoNLL corpus due its size. Best published results are from *Christodoulopoulos et al. (2010), tBerg-Kirkpatrick et al. (2010) and tLee et al. (2010). The latter two papers do not report VM scores. No best published results are shown for the MULTEXT languages; Christodoulopoulos et al. (2010) report results based on 45 tags suggesting that clark performs best on these corpora. 645 comparison with a token-based version of the model that this restriction is very helpful. Second, it is a clustering model rather than a sequence model. This property makes it easy to incorporate multiple kinds of features into the model at either the token or the type level. Here, we experimented with token-level context features and alignment features and type-</context>
</contexts>
<marker>Lee, Haghighi, Barzilay, 2010</marker>
<rawString>Yoong Keok Lee, Aria Haghighi, and Regina Barzilay. 2010. Simple type-level unsupervised POS tagging. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP ’10, pages 853–861, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: the Penn Treebank. Computational Linguistics,</title>
<date>1993</date>
<contexts>
<context position="19565" citStr="Marcus et al., 1993" startWordPosition="3310" endWordPosition="3313">-East corpus (Erjavec, 2004), namely Bulgarian. The other languages in the corpus were used during development as a source of word alignments, but otherwise were only used for testing final versions of our models. Since none of the authors speak any of the languages in the MULTEXT col6For simplicity, we tied the 0 parameters for the two or four kinds of context features to the same value, and similarly the � parameters for the two kinds of alignment features. θ α z m f(T) φ(T) β(T) φ(-) β(-) Z . . . f(1) φ(1) β(1) nj nj M . . . . . . Z Z 642 lection, we also used the Penn Treebank WSJ corpus (Marcus et al., 1993) for development. Following Christodoulopoulos et al. (2010) we created a smaller version of the WSJ corpus (referred to as wsj-s) to approximate the size of the corpora in MULTEXT-East. For comparison to other systems, we also used the full WSJ at test time. For further testing, we used the remaining MULTEXT languages, as well as the languages of the CONNL-X (Buchholz and Marsi, 2006) shared task. This dataset contains 13 languages, 4 of which are freely available (Danish, Dutch, Portuguese and Swedish) and 9 that are used with permission from the creators of the corpora ( Arabic7, Bulgarian8</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Mitchell Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of English: the Penn Treebank. Computational Linguistics, 19(2):331–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tahira Naseem</author>
<author>Benjamin Snyder</author>
<author>Jacob Eisenstein</author>
<author>Regina Barzilay</author>
</authors>
<title>Multilingual Part-of-Speech tagging: Two unsupervised approaches.</title>
<date>2009</date>
<journal>Journal ofArtificial Intelligence Research,</journal>
<pages>36--341</pages>
<contexts>
<context position="5277" citStr="Naseem et al., 2009" startWordPosition="817" endWordPosition="820"> incorporated into the model and inference procedure using the same general framework as in the basic model that uses only context word features. In particular, we present two extensions to the basic model. The first uses morphological features, which serve as cues to syntactic class and seemed to partly explain the success of two best-performing systems analysed by Christodoulopoulos et al. (2010). The second extension to our model uses alignment features gathered from parallel corpora. Previous work suggests that using parallel text can improve performance on various unsupervised NLP tasks (Naseem et al., 2009; Snyder and Barzilay, 2008). We evaluate our model on 25 corpora in 20 languages that vary substantially in both syntax and morphology. As in previous work (Lee et al., 2010), we find that the one-class-per-type restriction boosts performance considerably over a comparable tokenbased model and yields results that are comparable to state-of-the-art even without the use of morphology or alignment features. Including morphology features yields the best published results on 14 or 15 of our 25 corpora (depending on the measure) and alignment features can improve results further. 2 Models Our model</context>
<context position="16516" citStr="Naseem et al., 2009" startWordPosition="2787" endWordPosition="2790">process yielded on average F,,t = 110 morphological feature types5. Each word type generates at most one of these possible features. If there are overlapping possibilities (e.g. -ingly and -y) we take the longest possible match. We also explore the idea of extending the morphology feature space beyond suffixes, by including features like capitalisation and punctuation. Specifically we use the features described in Haghighi and Klein (2006), namely initial-capital, containshyphen, contains-digit and we add an extra feature contains-punctuation. For the model with alignment features, we follow (Naseem et al., 2009) in using only bidirectional alignments: using Giza++ (Och and Ney, 2003), we get the word alignments in both directions between all possible language pairs in our parallel corpora (i.e., alternating the source and target languages within each pair). We then use only those alignments that are found in both directions. As discussed 4Since Morfessor yields multiple affixes for each word we concatenated all the suffixes into a single suffix. 5There was large variance in the number of feature types for each language ranging from 11 in Chinese to more than 350 in German and Czech. above, we use two</context>
</contexts>
<marker>Naseem, Snyder, Eisenstein, Barzilay, 2009</marker>
<rawString>Tahira Naseem, Benjamin Snyder, Jacob Eisenstein, and Regina Barzilay. 2009. Multilingual Part-of-Speech tagging: Two unsupervised approaches. Journal ofArtificial Intelligence Research, 36:341–385.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Comput. Linguist.,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="16589" citStr="Och and Ney, 2003" startWordPosition="2798" endWordPosition="2801">rd type generates at most one of these possible features. If there are overlapping possibilities (e.g. -ingly and -y) we take the longest possible match. We also explore the idea of extending the morphology feature space beyond suffixes, by including features like capitalisation and punctuation. Specifically we use the features described in Haghighi and Klein (2006), namely initial-capital, containshyphen, contains-digit and we add an extra feature contains-punctuation. For the model with alignment features, we follow (Naseem et al., 2009) in using only bidirectional alignments: using Giza++ (Och and Ney, 2003), we get the word alignments in both directions between all possible language pairs in our parallel corpora (i.e., alternating the source and target languages within each pair). We then use only those alignments that are found in both directions. As discussed 4Since Morfessor yields multiple affixes for each word we concatenated all the suffixes into a single suffix. 5There was large variance in the number of feature types for each language ranging from 11 in Chinese to more than 350 in German and Czech. above, we use two kinds of alignment features: the left and right context words of the ali</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz J. Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Comput. Linguist., 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kemal Oflazer</author>
<author>Bilge Say</author>
<author>Dilek Z Hakkani-T¨ur</author>
<author>G¨okhan T¨ur</author>
</authors>
<date>2003</date>
<journal>Building A Turkish Treebank, chapter</journal>
<volume>1</volume>
<pages>1--17</pages>
<publisher>Kluwer Academic Publishers.</publisher>
<marker>Oflazer, Say, Hakkani-T¨ur, T¨ur, 2003</marker>
<rawString>Kemal Oflazer, Bilge Say, Dilek Z. Hakkani-T¨ur, and G¨okhan T¨ur, 2003. Building A Turkish Treebank, chapter 1, pages 1–17. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Rasmussen</author>
</authors>
<title>The infinite Gaussian mixture model.</title>
<date>2000</date>
<booktitle>In Advances in Neural Information Processing Systems 12.</booktitle>
<marker>Rasmussen, 2000</marker>
<rawString>Carl Rasmussen. 2000. The infinite Gaussian mixture model. In Advances in Neural Information Processing Systems 12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sujith Ravi</author>
<author>Kevin Knight</author>
</authors>
<title>Minimized models for unsupervised Part-of-Speech tagging.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL-IJCNLP 2009,</booktitle>
<pages>504--512</pages>
<location>Suntec, Singapore,</location>
<contexts>
<context position="1465" citStr="Ravi and Knight, 2009" startWordPosition="209" endWordPosition="212">stem yields results comparable to state-of-the art, far better than a similar model without the one-class-per-type constraint. Using the additional features provides added benefit, and our final system outperforms the best published results on most of the 25 corpora tested. 1 Introduction Research on unsupervised learning for NLP has become widespread recently, with part-of-speech induction, or syntactic class induction, being a particularly popular task.&apos; However, despite a recent proliferation of syntactic class induction systems (Biemann, 2006; Goldwater and Griffiths, 2007; Johnson, 2007; Ravi and Knight, 2009; Berg-Kirkpatrick et al., 2010; Lee et al., 2010), careful comparison indicates that very few systems perform better than some much simpler and quicker methods dating back ten or even twenty years (Christodoulopoulos &apos;The task is more commonly referred to as part-of-speech induction, but we prefer the term syntactic class induction since the induced classes may not coincide with part-of-speech tags. et al., 2010). This fact suggests that we should consider which features of the older systems led to their success, and attempt to combine these features with some of the machine learning methods </context>
<context position="4230" citStr="Ravi and Knight, 2009" startWordPosition="647" endWordPosition="650">al Language Processing, pages 638–647, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics lated to several non-probabilistic systems that cluster context vectors or lower-dimensional representations of them (Redington et al., 1998; Sch¨utze, 1995; Lamar et al., 2010). Sequence models are by far the most common method of supervised partof-speech tagging, and have also been widely used for unsupervised part-of-speech tagging both with and without a dictionary (Smith and Eisner, 2005; Haghighi and Klein, 2006; Goldwater and Griffiths, 2007; Johnson, 2007; Ravi and Knight, 2009; Lee et al., 2010). However, systems based on context vectors have also performed well in these latter scenarios (Sch¨utze, 1995; Lamar et al., 2010; Toutanova and Johnson, 2007) and present a viable alternative to sequence models. One advantage of using a clustering model rather than a sequence model is that the features used for clustering need not be restricted to context words. Additional types of features can easily be incorporated into the model and inference procedure using the same general framework as in the basic model that uses only context word features. In particular, we present </context>
</contexts>
<marker>Ravi, Knight, 2009</marker>
<rawString>Sujith Ravi and Kevin Knight. 2009. Minimized models for unsupervised Part-of-Speech tagging. In Proceedings of ACL-IJCNLP 2009, pages 504–512, Suntec, Singapore, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Redington</author>
<author>Nick Chater</author>
<author>Steven Finch</author>
</authors>
<title>Distributional information: a powerful cue for acquiring syntactic categories.</title>
<date>1998</date>
<journal>Cognitive Science, 22:425 –</journal>
<pages>469</pages>
<contexts>
<context position="3880" citStr="Redington et al., 1998" startWordPosition="593" endWordPosition="596">of our model, which distinguishes it from the type-based Bayesian model of Lee et al. (2010), is that the underlying probabilistic model is a clustering model, (specifically, a multinomial mixture model) rather than a sequence model (HMM). In this sense, our model is more closely re638 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 638–647, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics lated to several non-probabilistic systems that cluster context vectors or lower-dimensional representations of them (Redington et al., 1998; Sch¨utze, 1995; Lamar et al., 2010). Sequence models are by far the most common method of supervised partof-speech tagging, and have also been widely used for unsupervised part-of-speech tagging both with and without a dictionary (Smith and Eisner, 2005; Haghighi and Klein, 2006; Goldwater and Griffiths, 2007; Johnson, 2007; Ravi and Knight, 2009; Lee et al., 2010). However, systems based on context vectors have also performed well in these latter scenarios (Sch¨utze, 1995; Lamar et al., 2010; Toutanova and Johnson, 2007) and present a viable alternative to sequence models. One advantage of </context>
</contexts>
<marker>Redington, Chater, Finch, 1998</marker>
<rawString>Martin Redington, Nick Chater, and Steven Finch. 1998. Distributional information: a powerful cue for acquiring syntactic categories. Cognitive Science, 22:425 – 469.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Rosenberg</author>
<author>Julia Hirschberg</author>
</authors>
<title>Vmeasure: A conditional entropy-based external cluster evaluation measure.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLPCoNLL</booktitle>
<pages>410--420</pages>
<contexts>
<context position="22129" citStr="Rosenberg and Hirschberg, 2007" startWordPosition="3721" endWordPosition="3724">e (formerly VERMOBIL Treebank - Kawata and Bartels (2000)). 13Part of the Slovene Dep. Treebank (Dˇzeroski et al., 2006) 14Part of the Cast3LB Treebank (Civit et al., 2006) 15Part of the METU-Sabanci Treebank (Oflazer et al., 2003). 16French Treebank (Abeill´e et al., 2000) 17Greek Dependency Treebank (Bamman et al., 2009) els morphology and has produced very good results on multilingual corpora. 4 Results and Analysis 4.1 Development results Tables 1 and 2 present the results from development runs, which were used to decide which features to incorporate in the final system. We used VMeasure (Rosenberg and Hirschberg, 2007) as our primary evaluation score, but also present many-toone matching accuracy (M-1) scores for better comparison with previously published results. We chose V-Measure (VM) as our evaluation score because it is less sensitive to the number of classes induced by the model (Christodoulopoulos et al., 2010), allowing us to develop our models without using the number of classes as a parameter. We fixed the number of classes in all systems to 45 during development; note however that the gold standard tag set for Bulgarian contains only 12 tags, so the results in Table 1 (especially the M-1 scores)</context>
</contexts>
<marker>Rosenberg, Hirschberg, 2007</marker>
<rawString>Andrew Rosenberg and Julia Hirschberg. 2007. Vmeasure: A conditional entropy-based external cluster evaluation measure. In Proceedings of EMNLPCoNLL 2007, pages 410–420.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Distributional part-of-speech tagging.</title>
<date>1995</date>
<booktitle>In Proceedings of EACL 7,</booktitle>
<pages>141--148</pages>
<location>San Francisco, CA, USA.</location>
<marker>Sch¨utze, 1995</marker>
<rawString>Hinrich Sch¨utze. 1995. Distributional part-of-speech tagging. In Proceedings of EACL 7, pages 141–148, San Francisco, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kiril Simov</author>
<author>Petya Osenova</author>
<author>Alexander Simov</author>
<author>Milen Kouylekov</author>
</authors>
<title>Design and implementation of the Bulgarian HPSG-based treebank.</title>
<date>2004</date>
<journal>Research on Language &amp;amp; Computation,</journal>
<volume>2</volume>
<issue>4</issue>
<contexts>
<context position="21281" citStr="Simov et al., 2004" startWordPosition="3584" endWordPosition="3587"> vectors we extracted for our system (context + extended morphology), using a Euclidean distance metric. This provides a very simple vector-based clustering baseline. The second baseline is a more recent vector-based syntactic class induction method, the SVD approach of (Lamar et al., 2010), which extends Sch¨utze (1995)’s original method and, like ours, enforces a one-class-per-tag restriction. As a third baseline we use the system of Clark (2003) since it is a type-level system that mod7Part of the Prague Arabic Treebank (Hajiˇc et al., 2003; Smrˇz and Pajas, 2004) 8Part of the BulTreeBank (Simov et al., 2004). 9Part of the Prague Dep. Treebank (B¨ohmov´a et al., 2001) 10Part of the TIGER Treebank (Brants et al., 2002) 11Part of the Sinica Treebank (Keh-Jiann et al., 2003) 12Part of the T¨ubingen Treebank of Spoken Japanese (formerly VERMOBIL Treebank - Kawata and Bartels (2000)). 13Part of the Slovene Dep. Treebank (Dˇzeroski et al., 2006) 14Part of the Cast3LB Treebank (Civit et al., 2006) 15Part of the METU-Sabanci Treebank (Oflazer et al., 2003). 16French Treebank (Abeill´e et al., 2000) 17Greek Dependency Treebank (Bamman et al., 2009) els morphology and has produced very good results on multi</context>
</contexts>
<marker>Simov, Osenova, Simov, Kouylekov, 2004</marker>
<rawString>Kiril Simov, Petya Osenova, Alexander Simov, and Milen Kouylekov. 2004. Design and implementation of the Bulgarian HPSG-based treebank. Research on Language &amp;amp; Computation, 2(4):495–522.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noah A Smith</author>
<author>Jason Eisner</author>
</authors>
<title>Contrastive estimation: training log-linear models on unlabeled data.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL 2005,</booktitle>
<pages>354--362</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="4135" citStr="Smith and Eisner, 2005" startWordPosition="633" endWordPosition="636">our model is more closely re638 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 638–647, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics lated to several non-probabilistic systems that cluster context vectors or lower-dimensional representations of them (Redington et al., 1998; Sch¨utze, 1995; Lamar et al., 2010). Sequence models are by far the most common method of supervised partof-speech tagging, and have also been widely used for unsupervised part-of-speech tagging both with and without a dictionary (Smith and Eisner, 2005; Haghighi and Klein, 2006; Goldwater and Griffiths, 2007; Johnson, 2007; Ravi and Knight, 2009; Lee et al., 2010). However, systems based on context vectors have also performed well in these latter scenarios (Sch¨utze, 1995; Lamar et al., 2010; Toutanova and Johnson, 2007) and present a viable alternative to sequence models. One advantage of using a clustering model rather than a sequence model is that the features used for clustering need not be restricted to context words. Additional types of features can easily be incorporated into the model and inference procedure using the same general f</context>
</contexts>
<marker>Smith, Eisner, 2005</marker>
<rawString>Noah A. Smith and Jason Eisner. 2005. Contrastive estimation: training log-linear models on unlabeled data. In Proceedings of ACL 2005, pages 354–362, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Otakar Smrz</author>
<author>Petr Pajas</author>
</authors>
<title>Morphotrees of Arabic and their annotation in the TrEd environment.</title>
<date>2004</date>
<booktitle>In Proceedings of the NEMLAR International Conference on Arabic Language Resources and Tools,</booktitle>
<pages>38--41</pages>
<marker>Smrz, Pajas, 2004</marker>
<rawString>Otakar Smrz&amp;quot; and Petr Pajas. 2004. Morphotrees of Arabic and their annotation in the TrEd environment. In Proceedings of the NEMLAR International Conference on Arabic Language Resources and Tools, pages 38– 41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Snyder</author>
<author>Regina Barzilay</author>
</authors>
<title>Unsupervised multilingual learning for morphological segmentation.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="5305" citStr="Snyder and Barzilay, 2008" startWordPosition="821" endWordPosition="824">e model and inference procedure using the same general framework as in the basic model that uses only context word features. In particular, we present two extensions to the basic model. The first uses morphological features, which serve as cues to syntactic class and seemed to partly explain the success of two best-performing systems analysed by Christodoulopoulos et al. (2010). The second extension to our model uses alignment features gathered from parallel corpora. Previous work suggests that using parallel text can improve performance on various unsupervised NLP tasks (Naseem et al., 2009; Snyder and Barzilay, 2008). We evaluate our model on 25 corpora in 20 languages that vary substantially in both syntax and morphology. As in previous work (Lee et al., 2010), we find that the one-class-per-type restriction boosts performance considerably over a comparable tokenbased model and yields results that are comparable to state-of-the-art even without the use of morphology or alignment features. Including morphology features yields the best published results on 14 or 15 of our 25 corpora (depending on the measure) and alignment features can improve results further. 2 Models Our model is a multinomial mixture mo</context>
</contexts>
<marker>Snyder, Barzilay, 2008</marker>
<rawString>Ben Snyder and Regina Barzilay. 2008. Unsupervised multilingual learning for morphological segmentation. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Mark Johnson</author>
</authors>
<title>A Bayesian LDA-based model for semi-supervised partof-speech tagging.</title>
<date>2007</date>
<booktitle>In Proceedings of NIPS</booktitle>
<contexts>
<context position="4409" citStr="Toutanova and Johnson, 2007" startWordPosition="677" endWordPosition="680">s that cluster context vectors or lower-dimensional representations of them (Redington et al., 1998; Sch¨utze, 1995; Lamar et al., 2010). Sequence models are by far the most common method of supervised partof-speech tagging, and have also been widely used for unsupervised part-of-speech tagging both with and without a dictionary (Smith and Eisner, 2005; Haghighi and Klein, 2006; Goldwater and Griffiths, 2007; Johnson, 2007; Ravi and Knight, 2009; Lee et al., 2010). However, systems based on context vectors have also performed well in these latter scenarios (Sch¨utze, 1995; Lamar et al., 2010; Toutanova and Johnson, 2007) and present a viable alternative to sequence models. One advantage of using a clustering model rather than a sequence model is that the features used for clustering need not be restricted to context words. Additional types of features can easily be incorporated into the model and inference procedure using the same general framework as in the basic model that uses only context word features. In particular, we present two extensions to the basic model. The first uses morphological features, which serve as cues to syntactic class and seemed to partly explain the success of two best-performing sy</context>
<context position="13842" citStr="Toutanova and Johnson, 2007" startWordPosition="2353" endWordPosition="2356">e approach taken by Lee et al. (2010). 3We use the word kind here to avoid confusion with type, which we reserve for the type-token distinction, which can apply to features as well as words. Note that this model with multiple context features is deficient: it can generate data that are inconsistent with any actual corpus, because there is no mechanism to constrain the left context word of token ei to be the same as the right context word of token ei−1 (and similarly with alignment features). However, deficient models have proven useful in other unsupervised NLP tasks (Klein and Manning, 2002; Toutanova and Johnson, 2007). In particular, Toutanova and Johnson (2007) demonstrate good performance on unsupervised part-ofspeech tagging (using a dictionary) with a Bayesian model similar to our own. If we remove the part of their model that relies on the dictionary (the morphological ambiguity classes), their model is equivalent to our own, without the restriction of one class per type. We use this token-based version of our model as a baseline in our experiments. The final extension to our model introduces typelevel features, specifically morphology features. The model is illustrated in Figure 2. We assume conditio</context>
</contexts>
<marker>Toutanova, Johnson, 2007</marker>
<rawString>Kristina Toutanova and Mark Johnson. 2007. A Bayesian LDA-based model for semi-supervised partof-speech tagging. In Proceedings of NIPS 2007.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>