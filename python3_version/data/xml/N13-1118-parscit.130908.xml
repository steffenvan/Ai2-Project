<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000021">
<title confidence="0.9981225">
Unsupervised Metaphor Identification Using Hierarchical Graph
Factorization Clustering
</title>
<author confidence="0.987442">
Lin Sun
</author>
<affiliation confidence="0.974819">
Computer Laboratory
University of Cambridge
</affiliation>
<email confidence="0.96827">
lin.sun@cl.cam.ac.uk
</email>
<author confidence="0.992058">
Ekaterina Shutova
</author>
<affiliation confidence="0.997347">
International Computer Science Institute and
Institute for Cognitive and Brain Sciences
University of California, Berkeley
</affiliation>
<email confidence="0.997768">
katia@icsi.berkeley.edu
</email>
<sectionHeader confidence="0.993882" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999852166666667">
We present a novel approach to automatic
metaphor identification, that discovers both
metaphorical associations and metaphorical
expressions in unrestricted text. Our sys-
tem first performs hierarchical graph factor-
ization clustering (HGFC) of nouns and then
searches the resulting graph for metaphorical
connections between concepts. It then makes
use of the salient features of the metaphori-
cally connected clusters to identify the actual
metaphorical expressions. In contrast to pre-
vious work, our method is fully unsupervised.
Despite this fact, it operates with an encour-
aging precision (0.69) and recall (0.61). Our
approach is also the first one in NLP to exploit
the cognitive findings on the differences in or-
ganisation of abstract and concrete concepts in
the human brain.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999888490196079">
Metaphor has traditionally been viewed as a form of
linguistic creativity, that gives our expression more
vividness, distinction and artistism. While this is
true on the surface, the mechanisms of metaphor
have a much deeper origin in our reasoning. To-
day metaphor is widely understood as a cognitive
phenomenon operating at the level of mental pro-
cesses, whereby one concept or domain is system-
atically viewed in terms of the properties of another
(Lakoff and Johnson, 1980). Consider the examples
(1) “He shot down all of my arguments” and (2) “He
attacked every weak point in my argument”. They
demonstrate a metaphorical mapping of the concept
of argument to that of war. The argument, which is
the target concept, is viewed in terms of a battle (or
a war), the source concept. The existence of such a
link allows us to systematically describe arguments
using the war terminology, thus leading to a num-
ber of metaphorical expressions. Lakoff and John-
son call such generalisations a source–target domain
mapping, or conceptual metaphor.
The ubiquity of metaphor in language has been
established in a number of corpus studies (Cameron,
2003; Martin, 2006; Steen et al., 2010; Shutova
and Teufel, 2010) and the role it plays in human
reasoning has been confirmed in psychological ex-
periments (Thibodeau and Boroditsky, 2011). This
makes metaphor an important research area for com-
putational and cognitive linguistics, and its auto-
matic processing indispensable for any semantics-
oriented NLP application. The problem of metaphor
modeling is gaining interest within NLP, with a
growing number of approaches exploiting statisti-
cal techniques (Mason, 2004; Gedigian et al., 2006;
Shutova, 2010; Shutova et al., 2010; Turney et al.,
2011; Shutova et al., 2012). Compared to more
traditional approaches based on hand-coded knowl-
edge (Fass, 1991; Martin, 1990; Narayanan, 1997;
Narayanan, 1999; Feldman and Narayanan, 2004;
Barnden and Lee, 2002; Agerri et al., 2007), these
more recent methods tend to have a wider cover-
age, as well as be more efficient, accurate and ro-
bust. However, even the statistical metaphor pro-
cessing approaches so far often focused on a lim-
ited domain or a subset of phenomena (Gedigian
et al., 2006; Krishnakumaran and Zhu, 2007), and
only addressed one of the metaphor processing sub-
tasks: identification of metaphorical mappings (Ma-
son, 2004) or identification of metaphorical expres-
sions (Shutova et al., 2010; Turney et al., 2011). In
this paper, we present the first computational method
</bodyText>
<page confidence="0.97171">
978
</page>
<note confidence="0.471848">
Proceedings of NAACL-HLT 2013, pages 978–988,
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.99989868888889">
that identifies the generalisations that govern the
production of metaphorical expressions, i.e. con-
ceptual metaphors, and then uses these generalisa-
tions to identify metaphorical expressions in unre-
stricted text. As opposed to previous works on sta-
tistical metaphor processing that were supervised or
semi-supervised, and thus required training data, our
method is fully unsupervised. It relies on building a
hierarchical graph of concepts connected by their as-
sociation strength (using hierarchical clustering) and
then searching for metaphorical links in this graph.
Shutova et al. (2010) introduced the hypothesis
of “clustering by association” and claimed that in
the course of distributional noun clustering, abstract
concepts tend to cluster together if they are associ-
ated with the same source domain, while concrete
concepts cluster by meaning similarity. We share
this intuition, but take this idea a significant step
further. Our approach is theoretically grounded in
the cognitive science findings suggesting that ab-
stract and concrete concepts are organised differ-
ently in the human brain (Crutch and Warrington,
2005; Binder et al., 2005; Wiemer-Hastings and
Xu, 2005; Huang et al., 2010; Crutch and Warring-
ton, 2010; Adorni and Proverbio, 2012). Accord-
ing to Crutch and Warrington (2005), these differ-
ences emerge from their general patterns of relation
with other concepts. However, most NLP systems
to date treat abstract and concrete concepts as iden-
tical. In contrast, we incorporate this distinction
into our model by creating a network (or a graph)
of concepts, and automatically learning the differ-
ent patterns of association of abstract and concrete
concepts with other concepts. We expect that, while
concrete concepts would tend to naturally organise
into a tree-like structure (with more specific terms
descending from the more general terms), abstract
concepts would exhibit a more complex pattern of
associations. Consider the example in Figure 1. The
figure schematically shows a small portion of the
graph describing the concepts of mechanism (con-
crete), political system and relationship (abstract)
at two levels of generality. One can see from this
graph that if concrete concepts, such as bike or en-
gine tend to be connected to only one concept at the
higher level in the hierarchy (mechanism), abstract
concepts may have multiple higher-level associates:
the literal ones and the metaphorical ones. For ex-
ample, the abstract concept of democracy is liter-
ally associated with a more general concept of po-
litical system, as well as metaphorically associated
with the concept of mechanism. Such multiple as-
sociations are due to the fact that political systems
are metaphorically viewed as mechanisms, they can
function, break, they can be oiled etc. We often dis-
cuss them using mechanism terminology, and thus a
corpus-based distributional learning approach would
learn that they share features with political systems
(from their literal uses), as well as with mechanisms
(from their metaphorical uses, as shown next to the
respective graph edges in the figure). Our system
discovers such association patterns within the graph
and uses them to identify metaphorical connections
between the concepts.
To the best of our knowledge, our method is the
first one to use a hierarchical clustering model for
the metaphor processing task. The original graph of
concepts is built using hierarchical graph factoriza-
tion clustering (HGFC) (Yu et al., 2006) of nouns,
yielding a network of clusters with different levels
of generality. The weights on the edges of the graph
indicate association between the clusters (concepts).
HGFC has not been previously employed for noun
clustering in NLP, but showed successful results in
the verb clustering task (Sun and Korhonen, 2011).
In summary, our system (1) builds a graph of con-
cepts using HGFC, (2) traverses it to find metaphor-
ical associations between clusters using weights on
the edges of the graph, (3) generates lists of salient
features for the metaphorically connected clusters
and (4) searches the British National Corpus (BNC)
(Burnard, 2007) for metaphorical expressions de-
scribing the target domain concepts using the verbs
from the set of salient features. We evaluated the
performance of the system with the aid of human
judges in precision- and recall-oriented settings. In
addition, we compared its performance to that of two
baselines, an unsupervised baseline using agglom-
erative clustering (AGG) and a supervised baseline
built upon WordNet (Fellbaum, 1998) (WN).
</bodyText>
<sectionHeader confidence="0.993829" genericHeader="introduction">
2 Method
</sectionHeader>
<subsectionHeader confidence="0.996977">
2.1 Dataset and Feature Extraction
</subsectionHeader>
<bodyText confidence="0.992442">
Our noun dataset used for clustering contains 2000
most frequent nouns in the BNC (Burnard, 2007).
</bodyText>
<page confidence="0.99894">
979
</page>
<figureCaption confidence="0.999918">
Figure 1: Organisation of the hierarchical graph of concepts
</figureCaption>
<bodyText confidence="0.999956083333333">
Following previous semantic noun classification ex-
periments (Pantel and Lin, 2002; Bergsma et al.,
2008), we use the grammatical relations (GRs)
as features for clustering. We extracted the fea-
tures from the Gigaword corpus (Graff et al.,
2003), which was first parsed using the RASP
parser (Briscoe et al., 2006). The verb lemmas
in VERB–SUBJECT, VERB–DIRECT OBJECT and
VERB–INDIRECT OBJECT relations with the nouns
in the dataset were then extracted from the GR out-
put of the parser. The feature values were the relative
frequencies of the features.
</bodyText>
<subsectionHeader confidence="0.995801">
2.2 Hierarchical Graph Factorization
Clustering
</subsectionHeader>
<bodyText confidence="0.990003690909091">
The most widely used method for hierarchical word
clustering is AGG (Schulte im Walde and Brew,
2001; Stevenson and Joanis, 2003; Ferrer, 2004;
Devereux and Costello, 2005). The method treats
each word as a singleton cluster and then succes-
sively merges two closest clusters until all the clus-
ters have been merged into one. The cluster simi-
larity is measured using linkage criteria (e.g. Ward
(1963) measures the decrease in variance for the
clusters being merged). As opposed to this, HGFC
derives probabilistic bipartite graphs from the sim-
ilarity matrix (Yu et al., 2006). Since we require a
graph of concepts, our task is rather different from
standard hierarchical word clustering that produces
a tree of concepts. In a tree, each word can only
have a unique parent cluster at each level. Our con-
cept graph does not have this constraint: at any level
a word can be associated with an arbitrary number
of parent clusters. Therefore, not only HGFC out-
performed agglomerative clustering methods in hi-
erarchical clustering tasks (Yu et al., 2006; Sun and
Korhonen, 2011), but its hierarchical graph output
is also a more suitable representation of the concept
graph. In addition, HGFC can detect the number of
levels and the number of clusters on each level of
the hierarchical graph automatically. This is essen-
tial for our task as these settings are difficult to pre-
define for a general-purpose concept graph.
Given a set of nouns, V = {vn}Nn�1, the similar-
ity matrix W for HGFC is constructed using Jensen-
Shannon Divergence. W can be encoded by an undi-
rected graph G (Figure 2(a)), where the nouns are
mapped to vertices and Wij is the edge weight be-
tween vertices i and j. The graph G and the clus-
ter structure can be represented by a bipartite graph
K(V, U). V are the vertices on G. U = {up}mp�1
represent the hidden m clusters. For example, look-
ing at Figure 2(b), V on G can be grouped into three
clusters u1, u2 and u3. The matrix B denotes the
n x m adjacency matrix, with bip being the connec-
tion weight between the vertex vi and the cluster up.
Thus, B represents the connections between clus-
ters at an upper and lower level of clustering. A
flat clustering algorithm can be induced by assign-
ing a lower level node to the parent node that has the
largest connection weight. The number of clusters
at any level can be determined by only counting the
number of non-empty nodes (namely the nodes that
have at least one lower level node associated).
The bipartite graph K also induces a similarity
(W&apos;) between vi and vj: w&apos;i j = EP 1 iabb p =
(BA−1BT)ij where A = diag(A1, ..., am). There-
fore, B can be found by minimizing the divergence
distance (C) between the similarity matrices W and
W&apos;:
</bodyText>
<page confidence="0.822411">
980
</page>
<figure confidence="0.99815482">
V2
V6
V4
V3
V1
V
V9
V7
V
V,
V2
V3
V4
V
V6
V7
V
V9
U,
U2
U3
V6
V2
V4
U,
V3
U3
V,
V
V9
V7
U2
V
U1 U2
U3
v1
v2
v3
v4
v
v6
v7
v
v9
u1
u2
u3
q1
q2
(a) (b) (c) (d) (e)
</figure>
<figureCaption confidence="0.999502">
Figure 2: (a) An undirected graph G representing the similarity matrix; (b) The bipartite graph showing three clusters
on G; (c) The induced clusters U; (d) The new graph G1 over clusters U; (e) The new bipartite graph over G1
</figureCaption>
<bodyText confidence="0.999185555555556">
value of m0 to 800. For the subsequent levels, ml
is set to the number of non-empty clusters (bipartite
graph nodes) on the parent level. The matrices B
and A are initialized randomly. We found that the
actual initialization values have little impact on the
final result. The rows in B are normalized after the
initialization so the values in each row add up to one.
For a word vi, the probability of assigning it to clus-
ter x�l) pE Xl at level l is given by:
</bodyText>
<equation confidence="0.975072333333333">
min ζ(W, HAHT ), s.t. n hip = 1 (1)
H,Λ X
i=1
X xij xij + yij)
H = BA−1;ζ(X,Y ) = (xij log
ij yij
</equation>
<bodyText confidence="0.860405">
Yu et al. (2006) showed that this cost function is
non-increasing under the update rule:
</bodyText>
<equation confidence="0.9688108">
X�hip oc hip
j
wij (HAHT) λphjp s.t. X hip = 1 (2)
ij i
X�λp oc λp
j
X X
hiphjp s.t. �λp = wij (3)
(HAHT )ij
p(x(l)p|vi) = X
X1_1
X... p(x(l) p|x(l−1))...p(x(1)|vi)
x(1)∈X1
wij
p ij
</equation>
<bodyText confidence="0.9997575">
The cost function can thus be optimized by updating
h and λ alternately.
The similarity between clusters p(up, uq) can be
induced from B, as follows:
</bodyText>
<equation confidence="0.9989425">
p(up, uq) = p(up)p(up|uq) = (BT D−1B)pq (4)
D = diag(d1, ..., dn) where di =
</equation>
<bodyText confidence="0.999896727272727">
We can then construct a new graph G1 (Figure
2(d)) with the clusters U as vertices, and the clus-
ter similarity p as the connection weight. The clus-
tering algorithm can now be applied again (Figure
2(e)). This process can go on iteratively, leading to
a hierarchical graph.
The number of levels (L) and the number of
clusters (ml) are detected automatically, using the
method of Sun and Korhonen (2011). Clustering
starts with an initial setting of number of clusters
(m0) for the first level. In our experiment, we set the
</bodyText>
<equation confidence="0.9945715">
= (D(−1)
1 B1D−1
2 B2...D−1
l Bl)ip (5)
</equation>
<bodyText confidence="0.999991722222222">
Due to the random walk property of the graph, ml
is non-increasing for higher levels (Sun and Korho-
nen, 2011). The algorithm can thus terminate when
all nouns are assigned to one cluster. We run 1000
iterations of updates of h and λ (equation 2 and 3)
for each two adjacent levels.
The resulting graph is composed of a set of bipar-
tite graphs defined by Bl, Bl−1,..., B1. A bipartite
graph has a similar structure as in Figure 1. For a
given noun, we can rank the clusters at any level ac-
cording to the soft assignment probability (eq. 5).
The clusters that have no member noun were hidden
from the ranking since they do not explicitly repre-
sent any concept. However, these clusters are still
part of the organisation of conceptual space within
the model and they contribute to the probability for
the clusters on upper levels (eq. 5). We call the view
of the hierarchical graph where these empty clusters
</bodyText>
<equation confidence="0.9352735">
bip
m
X
p=0
</equation>
<page confidence="0.974298">
981
</page>
<bodyText confidence="0.97915">
are hidden an explicit graph. The whole algorithm
can be summarized as follows:
</bodyText>
<figure confidence="0.399706333333333">
Require: N nouns V , initial number of clusters m1
Compute the similarity matrix W0 from V
Build the graph G0 from W0, l +— 1
while ml &gt; 1 do
Factorize Gl_1 to obtain bipartite graph Kl with the
adjacency matrix Bl (eq. 1, 2 and 3)
Build a graph Gl with similarity matrix Wl =
BTl D_1
l Bl according to equation 4
l +— l + 1 ; ml +— No. non-empty clusters (eq. 5)
end while
return Bl, Bl_1...B1
</figure>
<subsectionHeader confidence="0.996621">
2.3 Identification of Metaphorical Associations
</subsectionHeader>
<bodyText confidence="0.999997678571429">
Once we obtained the explicit graph of concepts, we
can now identify metaphorical associations based on
the weights connecting the clusters at different levels
(eq. 5). Taking a single noun (e.g. fire) as input, the
system computes the probability of its cluster mem-
bership for each cluster at each level, using these
weights. We expect the cluster membership prob-
abilities to indicate the level of association of the
input noun with the clusters. The system can then
rank the clusters at each level based on these prob-
abilities. We chose level 3 as the optimal level of
generality for our experiments, based on our qualita-
tive analysis of the graph. The system selects 6 top-
ranked clusters from this level (we expect an average
source concept to have no more than 5 typical tar-
get associates) and excludes the literal cluster con-
taining the input concept (e.g. “fire flame blaze”).
The remaining clusters represent the target concepts
associated with the input source concept. Example
output for the input concepts of fire and disease is
shown in Figure 3. One can see from the Figure
that each of the noun-to-cluster mappings represents
a new conceptual metaphor, e.g. EMOTION is FIRE,
VIOLENCE is FIRE, CRIME is a DISEASE etc. These
mappings are exemplified in language by a number
of metaphorical expressions (e.g. “His anger will
burn him”, “violence flared again”, “it’s time they
found a cure for corruption”).
</bodyText>
<subsectionHeader confidence="0.993128">
2.4 Identification of Salient Features and
Metaphorical Expressions
</subsectionHeader>
<bodyText confidence="0.9810655">
After extracting the source–target domain mappings,
we now move on to the identification of the cor-
</bodyText>
<table confidence="0.945562">
SOURCE: fire
TARGET 1: sense hatred emotion passion enthusiasm
sentiment hope interest feeling resentment optimism
hostility excitement anger
TARGET 2: coup violence fight resistance clash rebel-
lion battle drive fighting riot revolt war confrontation
volcano row revolution struggle
TARGET 3: alien immigrant
TARGET 4: prisoner hostage inmate
SOURCE: disease
TARGET 1: fraud outbreak offense connection leak
count crime violation abuse conspiracy corruption ter-
rorism suicide
TARGET 2: opponent critic rival
TARGET 3: execution destruction signing
TARGET 4: refusal absence fact failure lack delay
</table>
<figureCaption confidence="0.581225416666667">
Figure 3: Discovered metaphorical associations
rage-ncsubj engulf-ncsubj erupt-ncsubj burn-ncsubj
light-dobj consume-ncsubj flare-ncsubj sweep-ncsubj
spark-dobj battle-dobj gut-idobj smolder-ncsubj ig-
nite-dobj destroy-idobj spread-ncsubj damage-idobj
light-ncsubj ravage-ncsubj crackle-ncsubj open-dobj
fuel-dobj spray-idobj roar-ncsubj perish-idobj destroy-
ncsubj wound-idobj start-dobj ignite-ncsubj injure-
idobj fight-dobj rock-ncsubj retaliate-idobj devastate-
idobj blaze-ncsubj ravage-idobj rip-ncsubj burn-idobj
spark-ncsubj warm-idobj suppress-dobj rekindle-dobj
Figure 4: Salient features for fire and the violence cluster
</figureCaption>
<bodyText confidence="0.9996318">
responding metaphorical expressions. The system
does this by harvesting the salient features that lead
to the input noun being strongly associated with the
extracted clusters. The salient features are selected
by ranking the features according to the joint prob-
ability of the feature (f) occurring both with the in-
put noun (w) and the cluster (c). Under a simplified
independence assumption, p(w, c|f) = p(w|f) x
p(c|f). p(w|f) and p(c|f) are calculated as the ra-
tio of the frequency of the feature f to the total
frequency of the input noun and the cluster respec-
tively. The features ranked higher are expected to
represent the source domain vocabulary that can be
used to metaphorically describe the target concepts.
We selected the top 50 features from the ranked list.
Example features (verbs and their grammatical rela-
tions) extracted for the source domain noun fire and
the violence cluster are shown in Figure 4.
We then refined the lists of features by means of
selectional preference (SP) filtering. We use SPs to
</bodyText>
<page confidence="0.985841">
982
</page>
<sectionHeader confidence="0.566943" genericHeader="method">
FEELING IS FIRE
</sectionHeader>
<bodyText confidence="0.595426">
hope lit (Subj), anger blazed (Subj), optimism raged
(Subj), enthusiasm engulfed them (Subj), hatred flared
(Subj), passion flared (Subj), interest lit (Subj), fuel re-
sentment (Dobj), anger crackled (Subj), feelings roared
(Subj), hostility blazed (Subj), light with hope (Iobj)
</bodyText>
<note confidence="0.262666">
CRIME IS A DISEASE
</note>
<figureCaption confidence="0.806550833333333">
cure crime (Dobj), abuse transmitted (Subj), eradicate
terrorism (Dobj), suffer from corruption (Iobj), diag-
nose abuse (Dobj), combat fraud (Dobj), cope with
crime (Iobj), cure abuse (Dobj), eradicate corruption
Figure 5: Identified metaphorical expressions for the
mappings FEELING IS FIRE and CRIME IS A DISEASE
</figureCaption>
<bodyText confidence="0.999727461538462">
quantify how well the extracted features describe the
source domain (e.g. fire). We extracted nominal ar-
gument distributions of the verbs in our feature lists
for VERB–SUBJECT, VERB–DIRECT OBJECT and
VERB–INDIRECT OBJECT relations. We used the al-
gorithm of Sun and Korhonen (2009) to create SP
classes and the measure of Resnik (1993) to quantify
how well a particular argument class fits the verb.
Resnik measures selectional preference strength
5R(v) of a predicate as a Kullback-Leibler distance
between two distributions: the prior probability of
the noun class P(c) and the posterior probability
of the noun class given the verb P(c|v). 5R(v) =
</bodyText>
<equation confidence="0.881980333333333">
D(P(c|v)||P(c)) = Ec P(c|v) log P (c�v)
P (c) . In order
to quantify how well a particular argument class fits
the verb, Resnik defines selectional association as
AR(v, c) = 1
s (v)P(c|v) log p�(C�). We rank the
</equation>
<bodyText confidence="0.999929235294118">
nominal arguments of the verbs in our feature lists
using their selectional association with the verb, and
then only retain the features whose top 5 arguments
contain the source concept. For example, the verb
start, that is a common feature for both fire and the
violence cluster (e.g. “start a war”, “start a fire”),
would be filtered out in this way, whereas the verbs
flare or blaze would be retained as descriptive source
domain vocabulary.
We then search the RASP-parsed BNC for gram-
matical relations, in which the nouns from the target
domain cluster appear with the verbs from the source
domain vocabulary (e.g. “war blazed” (subj), “to
fuel violence” (dobj) for the mapping VIOLENCE is
FIRE). The system thus annotates metaphorical ex-
pressions in text, as well as the corresponding con-
ceptual metaphors, as shown in Figure 5.
</bodyText>
<sectionHeader confidence="0.984471" genericHeader="evaluation">
3 Evaluation and Discussion
</sectionHeader>
<subsectionHeader confidence="0.995036">
3.1 Baselines
</subsectionHeader>
<bodyText confidence="0.999968190476191">
AGG: the agglomerative clustering baseline is
constructed using SciPy implementation (Oliphant,
2007) of Ward’s linkage method (Ward, 1963). The
output tree is cut according to the number of lev-
els and the number of clusters of the explicit graph
detected by HGFC. The resulting tree is converted
into a graph by adding connections from each clus-
ter to all the clusters one level above. The connec-
tion weight (the cluster distance) is measured us-
ing Jensen-Shannon Divergence between the cluster
centroids. This graph is used in place of the HGFC
graph in the metaphor identification experiments.
WN: in the WN baseline, the WordNet hierarchy is
used as the underlying graph of concepts, to which
the metaphor extraction method is applied. Given
a source concept, the system extracts all its sense-
1 hypernyms two levels above and subsequently all
of their sister terms. The hypernyms themselves are
considered to represent the literal sense of the source
noun and are, therefore, removed. The sister terms
are kept as potential target domains.
</bodyText>
<subsectionHeader confidence="0.999871">
3.2 Evaluation of Metaphorical Associations
</subsectionHeader>
<bodyText confidence="0.999929">
To create our dataset, we extracted 10 common
source concepts that map to multiple targets from
the Master Metaphor List (Lakoff et al., 1991) and
linguistic analyses of metaphor (Lakoff and John-
son, 1980; Shutova and Teufel, 2010). These
included FIRE, CHILD, SPEED, WAR, DISEASE,
BREAKDOWN, CONSTRUCTION, VEHICLE, SYS-
TEM, BUSINESS. Each of the three systems identi-
fied 50 source–target domain mappings for the given
source domains, resulting in a set of 150 conceptual
metaphors (each representing a number of submap-
pings since all the target concepts are clusters or
synsets). These were then evaluated against human
judgements in two different experimental settings.
Setting 1: The judges were presented with a set
of conceptual metaphors identified by the three sys-
tems, randomized. They were asked to annotate the
mappings they considered valid. In all our experi-
ments, the judges were encouraged to rely on their
own intuition of metaphor, but they also reviewed
the metaphor annotation guidelines of Shutova and
Teufel (2010). Two independent judges, both na-
</bodyText>
<page confidence="0.998392">
983
</page>
<bodyText confidence="0.998011792682927">
tive speakers of English, participated in this exper-
iment. Their agreement on the task was n = 0.60
(n = 2, N = 150, k = 2) (Siegel and Castel-
lan, 1988). The main differences in the annotators’
judgements stem from the fact that some metaphor-
ical associations are less obvious and common than
others, and thus need more context (or imaginative
effort) to establish. Such examples, where the judges
disagreed included metaphorical mappings such as
INTENSITY is SPEED, GOAL is a CHILD, COLLEC-
TION is a SYSTEM, ILLNESS is a BREAKDOWN.
The system performance was then evaluated
against these judgements in terms of precision (P),
i.e. the proportion of the valid metaphorical map-
pings among those identified. We calculated sys-
tem precision (in all experiments) as an average over
both annotations. HGFC operates with a precision of
P = 0.69, whereas the baselines attain P = 0.36
(AGG) and P = 0.29 (WN). The precision of an-
notator judgements against each other (the human
ceiling) is P = 0.80, suggesting that this is a chal-
lenging task.
Setting 2: To measure recall, R, of the systems we
asked two annotators (both native speakers with a
background in metaphor, different from Setting 1)
to write down up to 5 target concepts they strongly
associated with each of the 10 source concepts.
Their annotations were then aggregated into a sin-
gle metaphor association gold standard, consisting
of 63 mappings in total. The recall of the systems
was measured against this gold standard, resulting in
HGFC R = 0.61, AGG R = 0.11 and WN R = 0.03.
As expected, HGFC outperforms both AGG and
WN baselines in both settings. AGG has been pre-
viously shown to be less accurate than HGFC in the
verb clustering task (Sun and Korhonen, 2011). Our
analysis of the noun clusters indicated that HGFC
tends to produce more pure and complete clusters
than AGG. Another important reason AGG fails is
that it by definition organises all concepts into tree
and optimises its solution locally, taking into ac-
count a small number of clusters at a time. How-
ever, being able to discover connections between
more distant domains and optimising globally over
all concepts is crucial for metaphor identification.
This makes AGG less suitable for the task, as demon-
strated by our results. However, AGG identified a
number of interesting mappings missed by HGFC,
e.g. CAREER IS A CHILD, LANGUAGE IS A SYS-
TEM, CORRUPTION IS A VEHICLE, EMPIRE IS A
CONSTRUCTION, as well as a number of mappings
in common with HGFC, e.g. DEBATE IS A WAR, DE-
STRUCTION IS A DISEASE. The WN system also
identified a few interesting metaphorical mappings
(e.g. COGNITION IS FIRE, EDUCATION IS CON-
STRUCTION), but its output is largely dominated by
the concepts similar to the source noun and contains
some unrelated concepts. The comparison of HGFC
to WN shows that HGFC identifies meaningful prop-
erties and relations of abstract concepts that can not
be captured in a tree-like classification (even an ac-
curate, manually created one). The latter is more ap-
propriate for concrete concepts, and a more flexible
representation is needed to model abstract concepts.
The fact that both baselines identified some valid
metaphorical associations, relying on less suitable
conceptual graphs, suggests that our way of travers-
ing the graph is a viable approach in principle.
HGFC identifies valid metaphorical associations
for a range of source concepts. On of them (CRIME
IS A VIRUS) happened to have been already vali-
dated in psychological experiments (Thibodeau and
Boroditsky, 2011). The most frequent type of error
of HGFC is the presence of target clusters similar or
closely related to the source noun (e.g. the parent
cluster for child). The clusters from the same do-
main can, however, be filtered out if their nouns fre-
quently occur in the same documents with the source
noun (in a large corpus), i.e. by topical similarity.
The latter is less likely for the metaphorically con-
nected nouns. We intend to implement this improve-
ment in the future version of the system.
</bodyText>
<subsectionHeader confidence="0.999942">
3.3 Evaluation of Metaphorical Expressions
</subsectionHeader>
<bodyText confidence="0.999862666666667">
For each of the identified conceptual metaphors, the
three systems extracted a number of metaphorical
expressions from the corpus (average of 430 for
HGFC, 148 for AGG, and 855 for WN). The ex-
pressions were also evaluated against human judge-
ments. The judges were presented with a set of ran-
domly sampled sentences containing metaphorical
expressions as annotated by the system and by the
baselines (200 each), randomized. They were asked
to mark the tagged expressions that were metaphor-
ical in their judgement as correct. Their agreement
on the task was n = 0.56 (n = 2, N = 600, k = 2),
</bodyText>
<page confidence="0.99682">
984
</page>
<bodyText confidence="0.695947909090909">
HLJ 26 [..] ”effective action” was needed to eradicate
terrorism, drug-trafficking and corruption.
EG0 275 In the 1930s the words ”means test” was a
curse, fuelling the resistance against it both among the
unemployed and some of its administrators.
CRX 1054 [..] if the rehabilitative approach were
demonstrably successful in curing crime.
HL3 1206 [..] he would strive to accelerate progress
towards the economic integration of the Caribbean.
HXJ 121 [..] it is likely that some industries will flour-
ish in certain countries as the market widens.
</bodyText>
<figureCaption confidence="0.981394">
Figure 6: Metaphors tagged by the system (in bold)
</figureCaption>
<bodyText confidence="0.999942676470588">
whereby the main source of disagreement was the
presence of lexicalized metaphors, e.g. verbs such
as impose, decline etc. The system performance
against these annotations is P = 0.65 (HGFC), P =
0.47 (AGG) and P = 0.12 (WN). The human ceiling
for this task was measured at P = 0.79. Figure 6
shows example sentences annotated by HGFC. The
performance of our unsupervised approach is close
to the previous supervised systems of Mason (2004)
(accuracy of 0.73) and Shutova et al. (2010) (preci-
sion of 0.79), however, the results are not directly
comparable due to different experimental settings.
The system errors in this task stem from multiple
word senses of the salient features or the source and
target sharing some physical properties (e.g. one can
“die from crime” and “die from a disease”). Some
identified expressions invoke a chain of mappings
(e.g. ABUSE IS A DISEASE, DISEASE IS AN ENEMY
for “combat abuse”), however, such chains are not
yet incorporated into the system. The performance
of AGG is higher than in the mappings identification
task, since it outputs only few expressions for the
incorrect mappings. In contrast, WN tagged a large
number of literal expressions due to the incorrect
prior identification of the underlying associations.
Since there is no large metaphor-annotated corpus
available, it was impossible for us to reliably evalu-
ate the recall of metaphorical expressions. However,
we estimated it as a recall of salient features. We
manually compiled sets of typical features for the
10 source domains, and measured their recall among
the top 50 HGFC features at R = 0.70. However, in
practice the coverage in this task would directly de-
pend on that of the metaphorical associations.
</bodyText>
<sectionHeader confidence="0.999713" genericHeader="related work">
4 Related Work
</sectionHeader>
<bodyText confidence="0.999939652173913">
One of the first attempts to identify and interpret
metaphorical expressions in text is the met* sys-
tem of Fass (1991), that utilizes hand-coded knowl-
edge and detects non-literalness via selectional pref-
erence violation. In case of a violation, the re-
spective phrase is first tested for being metonymic
using hand-coded patterns (e.g. CONTAINER-FOR-
CONTENT). If this fails, the system searches the
knowledge base for a relevant analogy in order to
discriminate metaphorical relations from anomalous
ones. The system of Krishnakumaran and Zhu
(2007) uses WordNet (the hyponymy relation) and
word bigram counts to predict verbal, nominal and
adjectival metaphors at the sentence level. The au-
thors discriminate between conventional metaphors
(included in WordNet) and novel metaphors. Birke
and Sarkar (2006) present a sentence clustering ap-
proach that employs a set of seed sentences an-
notated for literalness and computes similarity be-
tween the new input sentence and all of the seed sen-
tences. The system then tags the sentence as literal
or metaphorical according to the annotation in the
most similar seeds, attaining an f-score of 53.8%.
The first system to discover source–target domain
mappings automatically is CorMet (Mason, 2004).
It does this by searching for systematic variations
in domain-specific verb selectional preferences. For
example, pour is a characteristic verb in both LAB
and FINANCE domains. In the LAB domain it has
a strong preference for liquids and in the FINANCE
domain for money. From this the system infers the
domain mapping FINANCE – LAB and the concept
mapping money – liquid. Gedigian et al. (2006)
trained a maximum entropy classifier to discrimi-
nate between literal and metaphorical use. They
annotated the sentences from PropBank (Kingsbury
and Palmer, 2002) containing the verbs of MOTION
and CURE for metaphoricity. They used PropBank
annotation (arguments and their semantic types) as
features for classification and report an accuracy
of 95.12% (however, against a majority baseline of
92.90%). The metaphor identification system of
Shutova et al. (2010) starts from a small seed set
of metaphorical expressions, learns the analogies in-
volved in their production and extends the set of
analogies by means of verb and noun clustering. As
</bodyText>
<page confidence="0.996528">
985
</page>
<bodyText confidence="0.999869307692308">
a result, the system can recognize new metaphorical
expressions in unrestricted text (e.g. from the seed
“stir excitement” it infers that “swallow anger” is
also a metaphor), achieving a precision of 79%.
Turney et al. (2011) classify verbs and adjectives
as literal or metaphorical based on their level of con-
creteness or abstractness in relation to a noun they
appear with. They learn concreteness rankings for
words automatically (starting from a set of exam-
ples) and then search for expressions where a con-
crete adjective or verb is used with an abstract noun
(e.g. “dark humour” is tagged as a metaphor and
“dark hair” is not). They report an accuracy of 73%.
</bodyText>
<sectionHeader confidence="0.998742" genericHeader="conclusions">
5 Conclusions and Future Directions
</sectionHeader>
<bodyText confidence="0.999943888888889">
Previous research on metaphor addressed a num-
ber of different aspects of the phenomenon, and has
shown that these aspects can be successfully mod-
eled using statistical techniques. However, the meth-
ods often focused on a limited domain and needed
manually-labeled training data. This made them dif-
ficult to apply in a real-world setting with the goal of
improving semantic interpretation in NLP at large.
Our method takes a step towards this direction. It is
fully unsupervised, and thus more robust, and can
perform accurate metaphor identification in unre-
stricted text. It identifies metaphor with a precision
of 69% and a recall of 61%, which is a very encour-
aging result for an unsupervised method. We be-
lieve that this work has important implications for
computational and cognitive modeling of metaphor,
but is also applicable to a range of other seman-
tic tasks within NLP. Integrating different represen-
tations of abstract and concrete concepts into NLP
systems may improve their performance, as well as
make the models more cognitively plausible.
One of our key future research objectives is to in-
vestigate the use and adaptation of the created con-
ceptual graph to perform metaphor interpretation. In
addition, we plan to extend this work to cover nom-
inal and adjectival metaphors, by harvesting salient
nominal and adjectival features.
</bodyText>
<sectionHeader confidence="0.998296" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998279666666667">
This work was funded by the MetaNet project (grant
number W911NF-12-C-0022) and the Dorothy
Hodgkin Postgraduate Award.
</bodyText>
<sectionHeader confidence="0.989901" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.981113">
Roberta Adorni and Alice Mado Proverbio. 2012. The
neural manifestation of the word concreteness effect:
An electrical neuroimaging study. Neuropsychologia,
50(5):880 – 891.
Rodrigo Agerri, John Barnden, Mark Lee, and Alan
Wallington. 2007. Metaphor, inference and domain-
independent mappings. In Proceedings of RANLP-
2007, pages 17–23, Borovets, Bulgaria.
John Barnden and Mark Lee. 2002. An artificial intel-
ligence approach to metaphor understanding. Theoria
etHistoria Scientiarum, 6(1):399–412.
Shane Bergsma, Dekang Lin, and Randy Goebel. 2008.
Discriminative learning of selectional preference from
unlabeled text. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing,
EMNLP ’08, pages 59–68, Honolulu, Hawaii.
Jeffrey R. Binder, Chris F. Westbury, Kristen A. McKier-
nan, Edward T. Possing, and David A. Medler. 2005.
Distinct brain systems for processing concrete and ab-
stract concepts. Journal of Cognitive Neuroscience,
17(6):905–917.
Julia Birke and Anoop Sarkar. 2006. A clustering ap-
proach for the nearly unsupervised recognition of non-
literal language. In In Proceedings of EACL-06, pages
329–336.
Ted Briscoe, John Carroll, and Rebecca Watson. 2006.
The second release of the rasp system. In Proceed-
ings of the COLING/ACL on Interactive presentation
sessions.
Lou Burnard. 2007. Reference Guide for the British Na-
tional Corpus (XML Edition).
Lynne Cameron. 2003. Metaphor in Educational Dis-
course. Continuum, London.
Sebastian J. Crutch and Elizabeth K. Warrington.
2005. Abstract and concrete concepts have struc-
turally different representational frameworks. Brain,
128(3):615–627.
</reference>
<bodyText confidence="0.701495142857143">
Sebastian J Crutch and Elizabeth K Warrington. 2010.
The differential dependence of abstract and concrete
words upon associative and similarity-based informa-
tion: Complementary semantic interference and facil-
itation effects. Cognitive Neuropsychology, 27(1):46–
71.
Barry Devereux and Fintan Costello. 2005. Propane
stoves and gas lamps: How the concept hierarchy in-
fluences the interpretation of noun-noun compounds.
In Proceedings of the Twenty-Seventh Annual Confer-
ence of the Cognitive Science Society.
Dan Fass. 1991. met*: A method for discriminating
metonymy and metaphor by computer. Computational
Linguistics, 17(1):49–90.
</bodyText>
<page confidence="0.994786">
986
</page>
<reference confidence="0.999037105769231">
Jerome Feldman and Srini Narayanan. 2004. Embodied
meaning in a neural theory of language. Brain and
Language, 89(2):385–392.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database (ISBN: 0-262-06197-X). MIT
Press, first edition.
Eva E. Ferrer. 2004. Towards a semantic classification of
spanish verbs based on subcategorisation information.
In Proceedings of the ACL 2004 workshop on Student
research, page 13. Association for Computational Lin-
guistics.
Matt Gedigian, John Bryant, Srini Narayanan, and Bran-
imir Ciric. 2006. Catching metaphors. In In Proceed-
ings of the 3rd Workshop on Scalable Natural Lan-
guage Understanding, pages 41–48, New York.
David Graff, Junbo Kong, Ke Chen, and Kazuaki Maeda.
2003. English gigaword. Linguistic Data Consortium,
Philadelphia.
Hsu-Wen Huang, Chia-Lin Lee, and Kara D. Federmeier.
2010. Imagine that! erps provide evidence for distinct
hemispheric contributions to the processing of con-
crete and abstract concepts. NeuroImage, 49(1):1116
– 1123.
Paul Kingsbury and Martha Palmer. 2002. From
TreeBank to PropBank. In Proceedings of LREC-
2002, pages 1989–1993, Gran Canaria, Canary Is-
lands, Spain.
Saisuresh Krishnakumaran and Xiaojin Zhu. 2007.
Hunting elusive metaphors using lexical resources.
In Proceedings of the Workshop on Computational
Approaches to Figurative Language, pages 13–20,
Rochester, NY.
George Lakoff and Mark Johnson. 1980. Metaphors We
Live By. University of Chicago Press, Chicago.
George Lakoff, Jane Espenson, and Alan Schwartz.
1991. The master metaphor list. Technical report,
University of California at Berkeley.
James Martin. 1990. A Computational Model of
Metaphor Interpretation. Academic Press Profes-
sional, Inc., San Diego, CA, USA.
James Martin. 2006. A corpus-based analysis of con-
text effects on metaphor comprehension. In A. Ste-
fanowitsch and S. T. Gries, editors, Corpus-Based Ap-
proaches to Metaphor and Metonymy, Berlin. Mouton
de Gruyter.
Zachary Mason. 2004. Cormet: a computational,
corpus-based conventional metaphor extraction sys-
tem. Computational Linguistics, 30(1):23–44.
Srini Narayanan. 1997. Knowledge-based Action Repre-
sentations for Metaphor and Aspect (KARMA). Tech-
nical report, PhD thesis, University of California at
Berkeley.
Srini Narayanan. 1999. Moving right along: A compu-
tational model of metaphoric reasoning about events.
In Proceedings of AAAI 99), pages 121–128, Orlando,
Florida.
Travis E. Oliphant. 2007. Python for scientific comput-
ing. Computing in Science and Engineering, 9:10–20.
Patrick Pantel and Dekang Lin. 2002. Discovering word
senses from text. In Proceedings of the eighth ACM
SIGKDD international conference on Knowledge dis-
covery and data mining, pages 613–619. ACM.
Philip Resnik. 1993. Selection and Information: A
Class-based Approach to Lexical Relationships. Ph.D.
thesis, Philadelphia, PA, USA.
Sabine Schulte im Walde and Chris Brew. 2001. Induc-
ing German semantic verb classes from purely syntac-
tic subcategorisation information. In ACL ’02: Pro-
ceedings of the 40th Annual Meeting on Association
for Computational Linguistics, pages 223–230, Mor-
ristown, NJ, USA. Association for Computational Lin-
guistics.
Ekaterina Shutova and Simone Teufel. 2010. Metaphor
corpus annotated for source - target domain map-
pings. In Proceedings of LREC 2010, pages 3255–
3261, Malta.
Ekaterina Shutova, Lin Sun, and Anna Korhonen. 2010.
Metaphor identification using verb and noun cluster-
ing. In Proceedings of Coling 2010, pages 1002–1010,
Beijing, China.
Ekaterina Shutova, Simone Teufel, and Anna Korhonen.
2012. Statistical Metaphor Processing. Computa-
tional Linguistics, 39(2).
Ekaterina Shutova. 2010. Automatic metaphor inter-
pretation as a paraphrasing task. In Proceedings of
NAACL 2010, pages 1029–1037, Los Angeles, USA.
Sidney Siegel and N. John Castellan. 1988. Nonpara-
metric statistics for the behavioral sciences. McGraw-
Hill Book Company, New York, USA.
Gerard J. Steen, Aletta G. Dorst, J. Berenike Herrmann,
Anna A. Kaal, Tina Krennmayr, and Trijntje Pasma.
2010. A method for linguistic metaphor identifica-
tion: From MIP to MIPVU. John Benjamins, Ams-
terdam/Philadelphia.
Suzanne Stevenson and Eric Joanis. 2003. Semi-
supervised verb class discovery using noisy features.
In Proceedings of HLT-NAACL 2003, pages 71–78.
Lin Sun and Anna Korhonen. 2009. Improving
verb clustering with automatically acquired selectional
preferences. In Proceedings of EMNLP 2009, pages
638–647, Singapore, August.
Lin Sun and Anna Korhonen. 2011. Hierarchical verb
clustering using graph factorization. In Proceedings
of EMNLP, pages 1023–1033, Edinburgh, UK.
</reference>
<page confidence="0.980257">
987
</page>
<reference confidence="0.992749210526316">
Paul H. Thibodeau and Lera Boroditsky. 2011.
Metaphors we think with: The role of metaphor in rea-
soning. PLoS ONE, 6(2):e16782, 02.
Peter D. Turney, Yair Neuman, Dan Assaf, and Yohai
Cohen. 2011. Literal and metaphorical sense iden-
tification through concrete and abstract context. In
Proceedings of the Conference on Empirical Meth-
ods in Natural Language Processing, EMNLP ’11,
pages 680–690, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Joe H. Ward. 1963. Hierarchical grouping to optimize an
objective function. Journal of the American statistical
association, 58(301):236–244.
Katja Wiemer-Hastings and Xu Xu. 2005. Content Dif-
ferences for Abstract and Concrete Concepts. Cogni-
tive Science, 29(5):719–736.
Kai Yu, Shipeng Yu, and Volker Tresp. 2006. Soft
clustering on graphs. Advances in Neural Information
Processing Systems, 18.
</reference>
<page confidence="0.997625">
988
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.793473">
<title confidence="0.9991395">Unsupervised Metaphor Identification Using Hierarchical Factorization Clustering</title>
<author confidence="0.999987">Lin Sun</author>
<affiliation confidence="0.9972">Computer University of Cambridge</affiliation>
<email confidence="0.996915">lin.sun@cl.cam.ac.uk</email>
<author confidence="0.823245">Ekaterina</author>
<affiliation confidence="0.996938666666667">International Computer Science Institute Institute for Cognitive and Brain University of California, Berkeley</affiliation>
<email confidence="0.999804">katia@icsi.berkeley.edu</email>
<abstract confidence="0.999038894736842">We present a novel approach to automatic metaphor identification, that discovers both metaphorical associations and metaphorical expressions in unrestricted text. Our system first performs hierarchical graph factorclustering of nouns and then searches the resulting graph for metaphorical connections between concepts. It then makes use of the salient features of the metaphorically connected clusters to identify the actual metaphorical expressions. In contrast to previous work, our method is fully unsupervised. Despite this fact, it operates with an encouraging precision (0.69) and recall (0.61). Our approach is also the first one in NLP to exploit the cognitive findings on the differences in organisation of abstract and concrete concepts in the human brain.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Roberta Adorni</author>
<author>Alice Mado Proverbio</author>
</authors>
<title>The neural manifestation of the word concreteness effect: An electrical neuroimaging study.</title>
<date>2012</date>
<journal>Neuropsychologia,</journal>
<volume>50</volume>
<issue>5</issue>
<pages>891</pages>
<contexts>
<context position="5038" citStr="Adorni and Proverbio, 2012" startWordPosition="758" endWordPosition="761"> by association” and claimed that in the course of distributional noun clustering, abstract concepts tend to cluster together if they are associated with the same source domain, while concrete concepts cluster by meaning similarity. We share this intuition, but take this idea a significant step further. Our approach is theoretically grounded in the cognitive science findings suggesting that abstract and concrete concepts are organised differently in the human brain (Crutch and Warrington, 2005; Binder et al., 2005; Wiemer-Hastings and Xu, 2005; Huang et al., 2010; Crutch and Warrington, 2010; Adorni and Proverbio, 2012). According to Crutch and Warrington (2005), these differences emerge from their general patterns of relation with other concepts. However, most NLP systems to date treat abstract and concrete concepts as identical. In contrast, we incorporate this distinction into our model by creating a network (or a graph) of concepts, and automatically learning the different patterns of association of abstract and concrete concepts with other concepts. We expect that, while concrete concepts would tend to naturally organise into a tree-like structure (with more specific terms descending from the more gener</context>
</contexts>
<marker>Adorni, Proverbio, 2012</marker>
<rawString>Roberta Adorni and Alice Mado Proverbio. 2012. The neural manifestation of the word concreteness effect: An electrical neuroimaging study. Neuropsychologia, 50(5):880 – 891.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rodrigo Agerri</author>
<author>John Barnden</author>
<author>Mark Lee</author>
<author>Alan Wallington</author>
</authors>
<title>Metaphor, inference and domainindependent mappings.</title>
<date>2007</date>
<booktitle>In Proceedings of RANLP2007,</booktitle>
<pages>17--23</pages>
<location>Borovets, Bulgaria.</location>
<contexts>
<context position="3092" citStr="Agerri et al., 2007" startWordPosition="463" endWordPosition="466">aphor an important research area for computational and cognitive linguistics, and its automatic processing indispensable for any semanticsoriented NLP application. The problem of metaphor modeling is gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of phenomena (Gedigian et al., 2006; Krishnakumaran and Zhu, 2007), and only addressed one of the metaphor processing subtasks: identification of metaphorical mappings (Mason, 2004) or identification of metaphorical expressions (Shutova et al., 2010; Turney et al., 2011). In this paper, we present the first computational method 978 Proceedings of NAACL-HLT 2013, pages 978–9</context>
</contexts>
<marker>Agerri, Barnden, Lee, Wallington, 2007</marker>
<rawString>Rodrigo Agerri, John Barnden, Mark Lee, and Alan Wallington. 2007. Metaphor, inference and domainindependent mappings. In Proceedings of RANLP2007, pages 17–23, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Barnden</author>
<author>Mark Lee</author>
</authors>
<title>An artificial intelligence approach to metaphor understanding. Theoria etHistoria</title>
<date>2002</date>
<journal>Scientiarum,</journal>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="3070" citStr="Barnden and Lee, 2002" startWordPosition="459" endWordPosition="462">, 2011). This makes metaphor an important research area for computational and cognitive linguistics, and its automatic processing indispensable for any semanticsoriented NLP application. The problem of metaphor modeling is gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of phenomena (Gedigian et al., 2006; Krishnakumaran and Zhu, 2007), and only addressed one of the metaphor processing subtasks: identification of metaphorical mappings (Mason, 2004) or identification of metaphorical expressions (Shutova et al., 2010; Turney et al., 2011). In this paper, we present the first computational method 978 Proceedings of NAACL</context>
</contexts>
<marker>Barnden, Lee, 2002</marker>
<rawString>John Barnden and Mark Lee. 2002. An artificial intelligence approach to metaphor understanding. Theoria etHistoria Scientiarum, 6(1):399–412.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shane Bergsma</author>
<author>Dekang Lin</author>
<author>Randy Goebel</author>
</authors>
<title>Discriminative learning of selectional preference from unlabeled text.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’08,</booktitle>
<pages>59--68</pages>
<location>Honolulu, Hawaii.</location>
<contexts>
<context position="8642" citStr="Bergsma et al., 2008" startWordPosition="1321" endWordPosition="1324">valuated the performance of the system with the aid of human judges in precision- and recall-oriented settings. In addition, we compared its performance to that of two baselines, an unsupervised baseline using agglomerative clustering (AGG) and a supervised baseline built upon WordNet (Fellbaum, 1998) (WN). 2 Method 2.1 Dataset and Feature Extraction Our noun dataset used for clustering contains 2000 most frequent nouns in the BNC (Burnard, 2007). 979 Figure 1: Organisation of the hierarchical graph of concepts Following previous semantic noun classification experiments (Pantel and Lin, 2002; Bergsma et al., 2008), we use the grammatical relations (GRs) as features for clustering. We extracted the features from the Gigaword corpus (Graff et al., 2003), which was first parsed using the RASP parser (Briscoe et al., 2006). The verb lemmas in VERB–SUBJECT, VERB–DIRECT OBJECT and VERB–INDIRECT OBJECT relations with the nouns in the dataset were then extracted from the GR output of the parser. The feature values were the relative frequencies of the features. 2.2 Hierarchical Graph Factorization Clustering The most widely used method for hierarchical word clustering is AGG (Schulte im Walde and Brew, 2001; St</context>
</contexts>
<marker>Bergsma, Lin, Goebel, 2008</marker>
<rawString>Shane Bergsma, Dekang Lin, and Randy Goebel. 2008. Discriminative learning of selectional preference from unlabeled text. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’08, pages 59–68, Honolulu, Hawaii.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey R Binder</author>
<author>Chris F Westbury</author>
<author>Kristen A McKiernan</author>
<author>Edward T Possing</author>
<author>David A Medler</author>
</authors>
<title>Distinct brain systems for processing concrete and abstract concepts.</title>
<date>2005</date>
<journal>Journal of Cognitive Neuroscience,</journal>
<volume>17</volume>
<issue>6</issue>
<contexts>
<context position="4930" citStr="Binder et al., 2005" startWordPosition="741" endWordPosition="744">for metaphorical links in this graph. Shutova et al. (2010) introduced the hypothesis of “clustering by association” and claimed that in the course of distributional noun clustering, abstract concepts tend to cluster together if they are associated with the same source domain, while concrete concepts cluster by meaning similarity. We share this intuition, but take this idea a significant step further. Our approach is theoretically grounded in the cognitive science findings suggesting that abstract and concrete concepts are organised differently in the human brain (Crutch and Warrington, 2005; Binder et al., 2005; Wiemer-Hastings and Xu, 2005; Huang et al., 2010; Crutch and Warrington, 2010; Adorni and Proverbio, 2012). According to Crutch and Warrington (2005), these differences emerge from their general patterns of relation with other concepts. However, most NLP systems to date treat abstract and concrete concepts as identical. In contrast, we incorporate this distinction into our model by creating a network (or a graph) of concepts, and automatically learning the different patterns of association of abstract and concrete concepts with other concepts. We expect that, while concrete concepts would te</context>
</contexts>
<marker>Binder, Westbury, McKiernan, Possing, Medler, 2005</marker>
<rawString>Jeffrey R. Binder, Chris F. Westbury, Kristen A. McKiernan, Edward T. Possing, and David A. Medler. 2005. Distinct brain systems for processing concrete and abstract concepts. Journal of Cognitive Neuroscience, 17(6):905–917.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Birke</author>
<author>Anoop Sarkar</author>
</authors>
<title>A clustering approach for the nearly unsupervised recognition of nonliteral language. In</title>
<date>2006</date>
<booktitle>In Proceedings of EACL-06,</booktitle>
<pages>329--336</pages>
<contexts>
<context position="31442" citStr="Birke and Sarkar (2006)" startWordPosition="5136" endWordPosition="5139"> via selectional preference violation. In case of a violation, the respective phrase is first tested for being metonymic using hand-coded patterns (e.g. CONTAINER-FORCONTENT). If this fails, the system searches the knowledge base for a relevant analogy in order to discriminate metaphorical relations from anomalous ones. The system of Krishnakumaran and Zhu (2007) uses WordNet (the hyponymy relation) and word bigram counts to predict verbal, nominal and adjectival metaphors at the sentence level. The authors discriminate between conventional metaphors (included in WordNet) and novel metaphors. Birke and Sarkar (2006) present a sentence clustering approach that employs a set of seed sentences annotated for literalness and computes similarity between the new input sentence and all of the seed sentences. The system then tags the sentence as literal or metaphorical according to the annotation in the most similar seeds, attaining an f-score of 53.8%. The first system to discover source–target domain mappings automatically is CorMet (Mason, 2004). It does this by searching for systematic variations in domain-specific verb selectional preferences. For example, pour is a characteristic verb in both LAB and FINANC</context>
</contexts>
<marker>Birke, Sarkar, 2006</marker>
<rawString>Julia Birke and Anoop Sarkar. 2006. A clustering approach for the nearly unsupervised recognition of nonliteral language. In In Proceedings of EACL-06, pages 329–336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
<author>Rebecca Watson</author>
</authors>
<title>The second release of the rasp system.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL on Interactive presentation sessions.</booktitle>
<contexts>
<context position="8851" citStr="Briscoe et al., 2006" startWordPosition="1356" endWordPosition="1359"> agglomerative clustering (AGG) and a supervised baseline built upon WordNet (Fellbaum, 1998) (WN). 2 Method 2.1 Dataset and Feature Extraction Our noun dataset used for clustering contains 2000 most frequent nouns in the BNC (Burnard, 2007). 979 Figure 1: Organisation of the hierarchical graph of concepts Following previous semantic noun classification experiments (Pantel and Lin, 2002; Bergsma et al., 2008), we use the grammatical relations (GRs) as features for clustering. We extracted the features from the Gigaword corpus (Graff et al., 2003), which was first parsed using the RASP parser (Briscoe et al., 2006). The verb lemmas in VERB–SUBJECT, VERB–DIRECT OBJECT and VERB–INDIRECT OBJECT relations with the nouns in the dataset were then extracted from the GR output of the parser. The feature values were the relative frequencies of the features. 2.2 Hierarchical Graph Factorization Clustering The most widely used method for hierarchical word clustering is AGG (Schulte im Walde and Brew, 2001; Stevenson and Joanis, 2003; Ferrer, 2004; Devereux and Costello, 2005). The method treats each word as a singleton cluster and then successively merges two closest clusters until all the clusters have been merge</context>
</contexts>
<marker>Briscoe, Carroll, Watson, 2006</marker>
<rawString>Ted Briscoe, John Carroll, and Rebecca Watson. 2006. The second release of the rasp system. In Proceedings of the COLING/ACL on Interactive presentation sessions.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lou Burnard</author>
</authors>
<date>2007</date>
<booktitle>Reference Guide for the British National Corpus (XML Edition).</booktitle>
<contexts>
<context position="7899" citStr="Burnard, 2007" startWordPosition="1210" endWordPosition="1211">of clusters with different levels of generality. The weights on the edges of the graph indicate association between the clusters (concepts). HGFC has not been previously employed for noun clustering in NLP, but showed successful results in the verb clustering task (Sun and Korhonen, 2011). In summary, our system (1) builds a graph of concepts using HGFC, (2) traverses it to find metaphorical associations between clusters using weights on the edges of the graph, (3) generates lists of salient features for the metaphorically connected clusters and (4) searches the British National Corpus (BNC) (Burnard, 2007) for metaphorical expressions describing the target domain concepts using the verbs from the set of salient features. We evaluated the performance of the system with the aid of human judges in precision- and recall-oriented settings. In addition, we compared its performance to that of two baselines, an unsupervised baseline using agglomerative clustering (AGG) and a supervised baseline built upon WordNet (Fellbaum, 1998) (WN). 2 Method 2.1 Dataset and Feature Extraction Our noun dataset used for clustering contains 2000 most frequent nouns in the BNC (Burnard, 2007). 979 Figure 1: Organisation</context>
</contexts>
<marker>Burnard, 2007</marker>
<rawString>Lou Burnard. 2007. Reference Guide for the British National Corpus (XML Edition).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lynne Cameron</author>
</authors>
<date>2003</date>
<booktitle>Metaphor in Educational Discourse. Continuum,</booktitle>
<location>London.</location>
<contexts>
<context position="2273" citStr="Cameron, 2003" startWordPosition="341" endWordPosition="342">guments” and (2) “He attacked every weak point in my argument”. They demonstrate a metaphorical mapping of the concept of argument to that of war. The argument, which is the target concept, is viewed in terms of a battle (or a war), the source concept. The existence of such a link allows us to systematically describe arguments using the war terminology, thus leading to a number of metaphorical expressions. Lakoff and Johnson call such generalisations a source–target domain mapping, or conceptual metaphor. The ubiquity of metaphor in language has been established in a number of corpus studies (Cameron, 2003; Martin, 2006; Steen et al., 2010; Shutova and Teufel, 2010) and the role it plays in human reasoning has been confirmed in psychological experiments (Thibodeau and Boroditsky, 2011). This makes metaphor an important research area for computational and cognitive linguistics, and its automatic processing indispensable for any semanticsoriented NLP application. The problem of metaphor modeling is gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova</context>
</contexts>
<marker>Cameron, 2003</marker>
<rawString>Lynne Cameron. 2003. Metaphor in Educational Discourse. Continuum, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian J Crutch</author>
<author>Elizabeth K Warrington</author>
</authors>
<title>Abstract and concrete concepts have structurally different representational frameworks.</title>
<date>2005</date>
<journal>Brain,</journal>
<volume>128</volume>
<issue>3</issue>
<contexts>
<context position="4909" citStr="Crutch and Warrington, 2005" startWordPosition="737" endWordPosition="740">ustering) and then searching for metaphorical links in this graph. Shutova et al. (2010) introduced the hypothesis of “clustering by association” and claimed that in the course of distributional noun clustering, abstract concepts tend to cluster together if they are associated with the same source domain, while concrete concepts cluster by meaning similarity. We share this intuition, but take this idea a significant step further. Our approach is theoretically grounded in the cognitive science findings suggesting that abstract and concrete concepts are organised differently in the human brain (Crutch and Warrington, 2005; Binder et al., 2005; Wiemer-Hastings and Xu, 2005; Huang et al., 2010; Crutch and Warrington, 2010; Adorni and Proverbio, 2012). According to Crutch and Warrington (2005), these differences emerge from their general patterns of relation with other concepts. However, most NLP systems to date treat abstract and concrete concepts as identical. In contrast, we incorporate this distinction into our model by creating a network (or a graph) of concepts, and automatically learning the different patterns of association of abstract and concrete concepts with other concepts. We expect that, while concr</context>
</contexts>
<marker>Crutch, Warrington, 2005</marker>
<rawString>Sebastian J. Crutch and Elizabeth K. Warrington. 2005. Abstract and concrete concepts have structurally different representational frameworks. Brain, 128(3):615–627.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerome Feldman</author>
<author>Srini Narayanan</author>
</authors>
<title>Embodied meaning in a neural theory of language.</title>
<date>2004</date>
<journal>Brain and Language,</journal>
<volume>89</volume>
<issue>2</issue>
<contexts>
<context position="3047" citStr="Feldman and Narayanan, 2004" startWordPosition="455" endWordPosition="458">nts (Thibodeau and Boroditsky, 2011). This makes metaphor an important research area for computational and cognitive linguistics, and its automatic processing indispensable for any semanticsoriented NLP application. The problem of metaphor modeling is gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of phenomena (Gedigian et al., 2006; Krishnakumaran and Zhu, 2007), and only addressed one of the metaphor processing subtasks: identification of metaphorical mappings (Mason, 2004) or identification of metaphorical expressions (Shutova et al., 2010; Turney et al., 2011). In this paper, we present the first computational method 9</context>
</contexts>
<marker>Feldman, Narayanan, 2004</marker>
<rawString>Jerome Feldman and Srini Narayanan. 2004. Embodied meaning in a neural theory of language. Brain and Language, 89(2):385–392.</rawString>
</citation>
<citation valid="true">
<date>1998</date>
<booktitle>WordNet: An Electronic Lexical Database (ISBN:</booktitle>
<pages>0--262</pages>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press,</publisher>
<note>first edition.</note>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database (ISBN: 0-262-06197-X). MIT Press, first edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eva E Ferrer</author>
</authors>
<title>Towards a semantic classification of spanish verbs based on subcategorisation information.</title>
<date>2004</date>
<booktitle>In Proceedings of the ACL 2004 workshop on Student research,</booktitle>
<pages>page</pages>
<contexts>
<context position="9280" citStr="Ferrer, 2004" startWordPosition="1424" endWordPosition="1425">elations (GRs) as features for clustering. We extracted the features from the Gigaword corpus (Graff et al., 2003), which was first parsed using the RASP parser (Briscoe et al., 2006). The verb lemmas in VERB–SUBJECT, VERB–DIRECT OBJECT and VERB–INDIRECT OBJECT relations with the nouns in the dataset were then extracted from the GR output of the parser. The feature values were the relative frequencies of the features. 2.2 Hierarchical Graph Factorization Clustering The most widely used method for hierarchical word clustering is AGG (Schulte im Walde and Brew, 2001; Stevenson and Joanis, 2003; Ferrer, 2004; Devereux and Costello, 2005). The method treats each word as a singleton cluster and then successively merges two closest clusters until all the clusters have been merged into one. The cluster similarity is measured using linkage criteria (e.g. Ward (1963) measures the decrease in variance for the clusters being merged). As opposed to this, HGFC derives probabilistic bipartite graphs from the similarity matrix (Yu et al., 2006). Since we require a graph of concepts, our task is rather different from standard hierarchical word clustering that produces a tree of concepts. In a tree, each word </context>
</contexts>
<marker>Ferrer, 2004</marker>
<rawString>Eva E. Ferrer. 2004. Towards a semantic classification of spanish verbs based on subcategorisation information. In Proceedings of the ACL 2004 workshop on Student research, page 13. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matt Gedigian</author>
<author>John Bryant</author>
<author>Srini Narayanan</author>
<author>Branimir Ciric</author>
</authors>
<title>Catching metaphors. In</title>
<date>2006</date>
<booktitle>In Proceedings of the 3rd Workshop on Scalable Natural Language Understanding,</booktitle>
<pages>41--48</pages>
<location>New York.</location>
<contexts>
<context position="2806" citStr="Gedigian et al., 2006" startWordPosition="419" endWordPosition="422">f metaphor in language has been established in a number of corpus studies (Cameron, 2003; Martin, 2006; Steen et al., 2010; Shutova and Teufel, 2010) and the role it plays in human reasoning has been confirmed in psychological experiments (Thibodeau and Boroditsky, 2011). This makes metaphor an important research area for computational and cognitive linguistics, and its automatic processing indispensable for any semanticsoriented NLP application. The problem of metaphor modeling is gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of phenomena (Gedigian et al., 2006; Krishnakumaran and Zhu, 2007), and only addressed one</context>
<context position="32270" citStr="Gedigian et al. (2006)" startWordPosition="5272" endWordPosition="5275">ags the sentence as literal or metaphorical according to the annotation in the most similar seeds, attaining an f-score of 53.8%. The first system to discover source–target domain mappings automatically is CorMet (Mason, 2004). It does this by searching for systematic variations in domain-specific verb selectional preferences. For example, pour is a characteristic verb in both LAB and FINANCE domains. In the LAB domain it has a strong preference for liquids and in the FINANCE domain for money. From this the system infers the domain mapping FINANCE – LAB and the concept mapping money – liquid. Gedigian et al. (2006) trained a maximum entropy classifier to discriminate between literal and metaphorical use. They annotated the sentences from PropBank (Kingsbury and Palmer, 2002) containing the verbs of MOTION and CURE for metaphoricity. They used PropBank annotation (arguments and their semantic types) as features for classification and report an accuracy of 95.12% (however, against a majority baseline of 92.90%). The metaphor identification system of Shutova et al. (2010) starts from a small seed set of metaphorical expressions, learns the analogies involved in their production and extends the set of analo</context>
</contexts>
<marker>Gedigian, Bryant, Narayanan, Ciric, 2006</marker>
<rawString>Matt Gedigian, John Bryant, Srini Narayanan, and Branimir Ciric. 2006. Catching metaphors. In In Proceedings of the 3rd Workshop on Scalable Natural Language Understanding, pages 41–48, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Graff</author>
<author>Junbo Kong</author>
<author>Ke Chen</author>
<author>Kazuaki Maeda</author>
</authors>
<date>2003</date>
<booktitle>English gigaword. Linguistic Data Consortium,</booktitle>
<location>Philadelphia.</location>
<contexts>
<context position="8782" citStr="Graff et al., 2003" startWordPosition="1344" endWordPosition="1347">erformance to that of two baselines, an unsupervised baseline using agglomerative clustering (AGG) and a supervised baseline built upon WordNet (Fellbaum, 1998) (WN). 2 Method 2.1 Dataset and Feature Extraction Our noun dataset used for clustering contains 2000 most frequent nouns in the BNC (Burnard, 2007). 979 Figure 1: Organisation of the hierarchical graph of concepts Following previous semantic noun classification experiments (Pantel and Lin, 2002; Bergsma et al., 2008), we use the grammatical relations (GRs) as features for clustering. We extracted the features from the Gigaword corpus (Graff et al., 2003), which was first parsed using the RASP parser (Briscoe et al., 2006). The verb lemmas in VERB–SUBJECT, VERB–DIRECT OBJECT and VERB–INDIRECT OBJECT relations with the nouns in the dataset were then extracted from the GR output of the parser. The feature values were the relative frequencies of the features. 2.2 Hierarchical Graph Factorization Clustering The most widely used method for hierarchical word clustering is AGG (Schulte im Walde and Brew, 2001; Stevenson and Joanis, 2003; Ferrer, 2004; Devereux and Costello, 2005). The method treats each word as a singleton cluster and then successive</context>
</contexts>
<marker>Graff, Kong, Chen, Maeda, 2003</marker>
<rawString>David Graff, Junbo Kong, Ke Chen, and Kazuaki Maeda. 2003. English gigaword. Linguistic Data Consortium, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hsu-Wen Huang</author>
<author>Chia-Lin Lee</author>
<author>Kara D Federmeier</author>
</authors>
<title>Imagine that! erps provide evidence for distinct hemispheric contributions to the processing of concrete and abstract concepts.</title>
<date>2010</date>
<journal>NeuroImage,</journal>
<volume>49</volume>
<issue>1</issue>
<pages>1123</pages>
<contexts>
<context position="4980" citStr="Huang et al., 2010" startWordPosition="749" endWordPosition="752">. (2010) introduced the hypothesis of “clustering by association” and claimed that in the course of distributional noun clustering, abstract concepts tend to cluster together if they are associated with the same source domain, while concrete concepts cluster by meaning similarity. We share this intuition, but take this idea a significant step further. Our approach is theoretically grounded in the cognitive science findings suggesting that abstract and concrete concepts are organised differently in the human brain (Crutch and Warrington, 2005; Binder et al., 2005; Wiemer-Hastings and Xu, 2005; Huang et al., 2010; Crutch and Warrington, 2010; Adorni and Proverbio, 2012). According to Crutch and Warrington (2005), these differences emerge from their general patterns of relation with other concepts. However, most NLP systems to date treat abstract and concrete concepts as identical. In contrast, we incorporate this distinction into our model by creating a network (or a graph) of concepts, and automatically learning the different patterns of association of abstract and concrete concepts with other concepts. We expect that, while concrete concepts would tend to naturally organise into a tree-like structur</context>
</contexts>
<marker>Huang, Lee, Federmeier, 2010</marker>
<rawString>Hsu-Wen Huang, Chia-Lin Lee, and Kara D. Federmeier. 2010. Imagine that! erps provide evidence for distinct hemispheric contributions to the processing of concrete and abstract concepts. NeuroImage, 49(1):1116 – 1123.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Kingsbury</author>
<author>Martha Palmer</author>
</authors>
<title>From TreeBank to PropBank.</title>
<date>2002</date>
<booktitle>In Proceedings of LREC2002,</booktitle>
<pages>1989--1993</pages>
<location>Gran Canaria, Canary Islands,</location>
<contexts>
<context position="32433" citStr="Kingsbury and Palmer, 2002" startWordPosition="5295" endWordPosition="5298"> source–target domain mappings automatically is CorMet (Mason, 2004). It does this by searching for systematic variations in domain-specific verb selectional preferences. For example, pour is a characteristic verb in both LAB and FINANCE domains. In the LAB domain it has a strong preference for liquids and in the FINANCE domain for money. From this the system infers the domain mapping FINANCE – LAB and the concept mapping money – liquid. Gedigian et al. (2006) trained a maximum entropy classifier to discriminate between literal and metaphorical use. They annotated the sentences from PropBank (Kingsbury and Palmer, 2002) containing the verbs of MOTION and CURE for metaphoricity. They used PropBank annotation (arguments and their semantic types) as features for classification and report an accuracy of 95.12% (however, against a majority baseline of 92.90%). The metaphor identification system of Shutova et al. (2010) starts from a small seed set of metaphorical expressions, learns the analogies involved in their production and extends the set of analogies by means of verb and noun clustering. As 985 a result, the system can recognize new metaphorical expressions in unrestricted text (e.g. from the seed “stir ex</context>
</contexts>
<marker>Kingsbury, Palmer, 2002</marker>
<rawString>Paul Kingsbury and Martha Palmer. 2002. From TreeBank to PropBank. In Proceedings of LREC2002, pages 1989–1993, Gran Canaria, Canary Islands, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saisuresh Krishnakumaran</author>
<author>Xiaojin Zhu</author>
</authors>
<title>Hunting elusive metaphors using lexical resources.</title>
<date>2007</date>
<booktitle>In Proceedings of the Workshop on Computational Approaches to Figurative Language,</booktitle>
<pages>13--20</pages>
<location>Rochester, NY.</location>
<contexts>
<context position="3382" citStr="Krishnakumaran and Zhu, 2007" startWordPosition="514" endWordPosition="517">stical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of phenomena (Gedigian et al., 2006; Krishnakumaran and Zhu, 2007), and only addressed one of the metaphor processing subtasks: identification of metaphorical mappings (Mason, 2004) or identification of metaphorical expressions (Shutova et al., 2010; Turney et al., 2011). In this paper, we present the first computational method 978 Proceedings of NAACL-HLT 2013, pages 978–988, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics that identifies the generalisations that govern the production of metaphorical expressions, i.e. conceptual metaphors, and then uses these generalisations to identify metaphorical expressions in unrestri</context>
<context position="31184" citStr="Krishnakumaran and Zhu (2007)" startWordPosition="5099" endWordPosition="5102">sk would directly depend on that of the metaphorical associations. 4 Related Work One of the first attempts to identify and interpret metaphorical expressions in text is the met* system of Fass (1991), that utilizes hand-coded knowledge and detects non-literalness via selectional preference violation. In case of a violation, the respective phrase is first tested for being metonymic using hand-coded patterns (e.g. CONTAINER-FORCONTENT). If this fails, the system searches the knowledge base for a relevant analogy in order to discriminate metaphorical relations from anomalous ones. The system of Krishnakumaran and Zhu (2007) uses WordNet (the hyponymy relation) and word bigram counts to predict verbal, nominal and adjectival metaphors at the sentence level. The authors discriminate between conventional metaphors (included in WordNet) and novel metaphors. Birke and Sarkar (2006) present a sentence clustering approach that employs a set of seed sentences annotated for literalness and computes similarity between the new input sentence and all of the seed sentences. The system then tags the sentence as literal or metaphorical according to the annotation in the most similar seeds, attaining an f-score of 53.8%. The fi</context>
</contexts>
<marker>Krishnakumaran, Zhu, 2007</marker>
<rawString>Saisuresh Krishnakumaran and Xiaojin Zhu. 2007. Hunting elusive metaphors using lexical resources. In Proceedings of the Workshop on Computational Approaches to Figurative Language, pages 13–20, Rochester, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Lakoff</author>
<author>Mark Johnson</author>
</authors>
<title>Metaphors We Live By.</title>
<date>1980</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago.</location>
<contexts>
<context position="1606" citStr="Lakoff and Johnson, 1980" startWordPosition="228" endWordPosition="231"> one in NLP to exploit the cognitive findings on the differences in organisation of abstract and concrete concepts in the human brain. 1 Introduction Metaphor has traditionally been viewed as a form of linguistic creativity, that gives our expression more vividness, distinction and artistism. While this is true on the surface, the mechanisms of metaphor have a much deeper origin in our reasoning. Today metaphor is widely understood as a cognitive phenomenon operating at the level of mental processes, whereby one concept or domain is systematically viewed in terms of the properties of another (Lakoff and Johnson, 1980). Consider the examples (1) “He shot down all of my arguments” and (2) “He attacked every weak point in my argument”. They demonstrate a metaphorical mapping of the concept of argument to that of war. The argument, which is the target concept, is viewed in terms of a battle (or a war), the source concept. The existence of such a link allows us to systematically describe arguments using the war terminology, thus leading to a number of metaphorical expressions. Lakoff and Johnson call such generalisations a source–target domain mapping, or conceptual metaphor. The ubiquity of metaphor in languag</context>
<context position="22795" citStr="Lakoff and Johnson, 1980" startWordPosition="3713" endWordPosition="3717"> graph of concepts, to which the metaphor extraction method is applied. Given a source concept, the system extracts all its sense1 hypernyms two levels above and subsequently all of their sister terms. The hypernyms themselves are considered to represent the literal sense of the source noun and are, therefore, removed. The sister terms are kept as potential target domains. 3.2 Evaluation of Metaphorical Associations To create our dataset, we extracted 10 common source concepts that map to multiple targets from the Master Metaphor List (Lakoff et al., 1991) and linguistic analyses of metaphor (Lakoff and Johnson, 1980; Shutova and Teufel, 2010). These included FIRE, CHILD, SPEED, WAR, DISEASE, BREAKDOWN, CONSTRUCTION, VEHICLE, SYSTEM, BUSINESS. Each of the three systems identified 50 source–target domain mappings for the given source domains, resulting in a set of 150 conceptual metaphors (each representing a number of submappings since all the target concepts are clusters or synsets). These were then evaluated against human judgements in two different experimental settings. Setting 1: The judges were presented with a set of conceptual metaphors identified by the three systems, randomized. They were asked </context>
</contexts>
<marker>Lakoff, Johnson, 1980</marker>
<rawString>George Lakoff and Mark Johnson. 1980. Metaphors We Live By. University of Chicago Press, Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Lakoff</author>
<author>Jane Espenson</author>
<author>Alan Schwartz</author>
</authors>
<title>The master metaphor list.</title>
<date>1991</date>
<tech>Technical report,</tech>
<institution>University of California at Berkeley.</institution>
<contexts>
<context position="22733" citStr="Lakoff et al., 1991" startWordPosition="3704" endWordPosition="3707"> baseline, the WordNet hierarchy is used as the underlying graph of concepts, to which the metaphor extraction method is applied. Given a source concept, the system extracts all its sense1 hypernyms two levels above and subsequently all of their sister terms. The hypernyms themselves are considered to represent the literal sense of the source noun and are, therefore, removed. The sister terms are kept as potential target domains. 3.2 Evaluation of Metaphorical Associations To create our dataset, we extracted 10 common source concepts that map to multiple targets from the Master Metaphor List (Lakoff et al., 1991) and linguistic analyses of metaphor (Lakoff and Johnson, 1980; Shutova and Teufel, 2010). These included FIRE, CHILD, SPEED, WAR, DISEASE, BREAKDOWN, CONSTRUCTION, VEHICLE, SYSTEM, BUSINESS. Each of the three systems identified 50 source–target domain mappings for the given source domains, resulting in a set of 150 conceptual metaphors (each representing a number of submappings since all the target concepts are clusters or synsets). These were then evaluated against human judgements in two different experimental settings. Setting 1: The judges were presented with a set of conceptual metaphors</context>
</contexts>
<marker>Lakoff, Espenson, Schwartz, 1991</marker>
<rawString>George Lakoff, Jane Espenson, and Alan Schwartz. 1991. The master metaphor list. Technical report, University of California at Berkeley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Martin</author>
</authors>
<title>A Computational Model of Metaphor Interpretation.</title>
<date>1990</date>
<publisher>Academic Press Professional, Inc.,</publisher>
<location>San Diego, CA, USA.</location>
<contexts>
<context position="2984" citStr="Martin, 1990" startWordPosition="449" endWordPosition="450">ing has been confirmed in psychological experiments (Thibodeau and Boroditsky, 2011). This makes metaphor an important research area for computational and cognitive linguistics, and its automatic processing indispensable for any semanticsoriented NLP application. The problem of metaphor modeling is gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of phenomena (Gedigian et al., 2006; Krishnakumaran and Zhu, 2007), and only addressed one of the metaphor processing subtasks: identification of metaphorical mappings (Mason, 2004) or identification of metaphorical expressions (Shutova et al., 2010; Turney et al., 20</context>
</contexts>
<marker>Martin, 1990</marker>
<rawString>James Martin. 1990. A Computational Model of Metaphor Interpretation. Academic Press Professional, Inc., San Diego, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Martin</author>
</authors>
<title>A corpus-based analysis of context effects on metaphor comprehension.</title>
<date>2006</date>
<booktitle>Corpus-Based Approaches to Metaphor and Metonymy,</booktitle>
<editor>In A. Stefanowitsch and S. T. Gries, editors,</editor>
<location>Berlin. Mouton</location>
<note>de Gruyter.</note>
<contexts>
<context position="2287" citStr="Martin, 2006" startWordPosition="343" endWordPosition="344">) “He attacked every weak point in my argument”. They demonstrate a metaphorical mapping of the concept of argument to that of war. The argument, which is the target concept, is viewed in terms of a battle (or a war), the source concept. The existence of such a link allows us to systematically describe arguments using the war terminology, thus leading to a number of metaphorical expressions. Lakoff and Johnson call such generalisations a source–target domain mapping, or conceptual metaphor. The ubiquity of metaphor in language has been established in a number of corpus studies (Cameron, 2003; Martin, 2006; Steen et al., 2010; Shutova and Teufel, 2010) and the role it plays in human reasoning has been confirmed in psychological experiments (Thibodeau and Boroditsky, 2011). This makes metaphor an important research area for computational and cognitive linguistics, and its automatic processing indispensable for any semanticsoriented NLP application. The problem of metaphor modeling is gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012)</context>
</contexts>
<marker>Martin, 2006</marker>
<rawString>James Martin. 2006. A corpus-based analysis of context effects on metaphor comprehension. In A. Stefanowitsch and S. T. Gries, editors, Corpus-Based Approaches to Metaphor and Metonymy, Berlin. Mouton de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zachary Mason</author>
</authors>
<title>Cormet: a computational, corpus-based conventional metaphor extraction system.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>1</issue>
<contexts>
<context position="2783" citStr="Mason, 2004" startWordPosition="417" endWordPosition="418">he ubiquity of metaphor in language has been established in a number of corpus studies (Cameron, 2003; Martin, 2006; Steen et al., 2010; Shutova and Teufel, 2010) and the role it plays in human reasoning has been confirmed in psychological experiments (Thibodeau and Boroditsky, 2011). This makes metaphor an important research area for computational and cognitive linguistics, and its automatic processing indispensable for any semanticsoriented NLP application. The problem of metaphor modeling is gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of phenomena (Gedigian et al., 2006; Krishnakumaran and Zhu, 2007),</context>
<context position="29344" citStr="Mason (2004)" startWordPosition="4807" endWordPosition="4808">f the Caribbean. HXJ 121 [..] it is likely that some industries will flourish in certain countries as the market widens. Figure 6: Metaphors tagged by the system (in bold) whereby the main source of disagreement was the presence of lexicalized metaphors, e.g. verbs such as impose, decline etc. The system performance against these annotations is P = 0.65 (HGFC), P = 0.47 (AGG) and P = 0.12 (WN). The human ceiling for this task was measured at P = 0.79. Figure 6 shows example sentences annotated by HGFC. The performance of our unsupervised approach is close to the previous supervised systems of Mason (2004) (accuracy of 0.73) and Shutova et al. (2010) (precision of 0.79), however, the results are not directly comparable due to different experimental settings. The system errors in this task stem from multiple word senses of the salient features or the source and target sharing some physical properties (e.g. one can “die from crime” and “die from a disease”). Some identified expressions invoke a chain of mappings (e.g. ABUSE IS A DISEASE, DISEASE IS AN ENEMY for “combat abuse”), however, such chains are not yet incorporated into the system. The performance of AGG is higher than in the mappings ide</context>
<context position="31874" citStr="Mason, 2004" startWordPosition="5208" endWordPosition="5209">, nominal and adjectival metaphors at the sentence level. The authors discriminate between conventional metaphors (included in WordNet) and novel metaphors. Birke and Sarkar (2006) present a sentence clustering approach that employs a set of seed sentences annotated for literalness and computes similarity between the new input sentence and all of the seed sentences. The system then tags the sentence as literal or metaphorical according to the annotation in the most similar seeds, attaining an f-score of 53.8%. The first system to discover source–target domain mappings automatically is CorMet (Mason, 2004). It does this by searching for systematic variations in domain-specific verb selectional preferences. For example, pour is a characteristic verb in both LAB and FINANCE domains. In the LAB domain it has a strong preference for liquids and in the FINANCE domain for money. From this the system infers the domain mapping FINANCE – LAB and the concept mapping money – liquid. Gedigian et al. (2006) trained a maximum entropy classifier to discriminate between literal and metaphorical use. They annotated the sentences from PropBank (Kingsbury and Palmer, 2002) containing the verbs of MOTION and CURE </context>
</contexts>
<marker>Mason, 2004</marker>
<rawString>Zachary Mason. 2004. Cormet: a computational, corpus-based conventional metaphor extraction system. Computational Linguistics, 30(1):23–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srini Narayanan</author>
</authors>
<title>Knowledge-based Action Representations for Metaphor and Aspect (KARMA).</title>
<date>1997</date>
<tech>Technical report, PhD thesis,</tech>
<institution>University of California at Berkeley.</institution>
<contexts>
<context position="3001" citStr="Narayanan, 1997" startWordPosition="451" endWordPosition="452">onfirmed in psychological experiments (Thibodeau and Boroditsky, 2011). This makes metaphor an important research area for computational and cognitive linguistics, and its automatic processing indispensable for any semanticsoriented NLP application. The problem of metaphor modeling is gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of phenomena (Gedigian et al., 2006; Krishnakumaran and Zhu, 2007), and only addressed one of the metaphor processing subtasks: identification of metaphorical mappings (Mason, 2004) or identification of metaphorical expressions (Shutova et al., 2010; Turney et al., 2011). In this pape</context>
</contexts>
<marker>Narayanan, 1997</marker>
<rawString>Srini Narayanan. 1997. Knowledge-based Action Representations for Metaphor and Aspect (KARMA). Technical report, PhD thesis, University of California at Berkeley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srini Narayanan</author>
</authors>
<title>Moving right along: A computational model of metaphoric reasoning about events.</title>
<date>1999</date>
<booktitle>In Proceedings of AAAI 99),</booktitle>
<pages>121--128</pages>
<location>Orlando, Florida.</location>
<contexts>
<context position="3018" citStr="Narayanan, 1999" startWordPosition="453" endWordPosition="454">ological experiments (Thibodeau and Boroditsky, 2011). This makes metaphor an important research area for computational and cognitive linguistics, and its automatic processing indispensable for any semanticsoriented NLP application. The problem of metaphor modeling is gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of phenomena (Gedigian et al., 2006; Krishnakumaran and Zhu, 2007), and only addressed one of the metaphor processing subtasks: identification of metaphorical mappings (Mason, 2004) or identification of metaphorical expressions (Shutova et al., 2010; Turney et al., 2011). In this paper, we present the</context>
</contexts>
<marker>Narayanan, 1999</marker>
<rawString>Srini Narayanan. 1999. Moving right along: A computational model of metaphoric reasoning about events. In Proceedings of AAAI 99), pages 121–128, Orlando, Florida.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Travis E Oliphant</author>
</authors>
<title>Python for scientific computing.</title>
<date>2007</date>
<booktitle>Computing in Science and Engineering,</booktitle>
<pages>9--10</pages>
<contexts>
<context position="21604" citStr="Oliphant, 2007" startWordPosition="3520" endWordPosition="3521">he verbs flare or blaze would be retained as descriptive source domain vocabulary. We then search the RASP-parsed BNC for grammatical relations, in which the nouns from the target domain cluster appear with the verbs from the source domain vocabulary (e.g. “war blazed” (subj), “to fuel violence” (dobj) for the mapping VIOLENCE is FIRE). The system thus annotates metaphorical expressions in text, as well as the corresponding conceptual metaphors, as shown in Figure 5. 3 Evaluation and Discussion 3.1 Baselines AGG: the agglomerative clustering baseline is constructed using SciPy implementation (Oliphant, 2007) of Ward’s linkage method (Ward, 1963). The output tree is cut according to the number of levels and the number of clusters of the explicit graph detected by HGFC. The resulting tree is converted into a graph by adding connections from each cluster to all the clusters one level above. The connection weight (the cluster distance) is measured using Jensen-Shannon Divergence between the cluster centroids. This graph is used in place of the HGFC graph in the metaphor identification experiments. WN: in the WN baseline, the WordNet hierarchy is used as the underlying graph of concepts, to which the </context>
</contexts>
<marker>Oliphant, 2007</marker>
<rawString>Travis E. Oliphant. 2007. Python for scientific computing. Computing in Science and Engineering, 9:10–20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Dekang Lin</author>
</authors>
<title>Discovering word senses from text.</title>
<date>2002</date>
<booktitle>In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>613--619</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="8619" citStr="Pantel and Lin, 2002" startWordPosition="1317" endWordPosition="1320">salient features. We evaluated the performance of the system with the aid of human judges in precision- and recall-oriented settings. In addition, we compared its performance to that of two baselines, an unsupervised baseline using agglomerative clustering (AGG) and a supervised baseline built upon WordNet (Fellbaum, 1998) (WN). 2 Method 2.1 Dataset and Feature Extraction Our noun dataset used for clustering contains 2000 most frequent nouns in the BNC (Burnard, 2007). 979 Figure 1: Organisation of the hierarchical graph of concepts Following previous semantic noun classification experiments (Pantel and Lin, 2002; Bergsma et al., 2008), we use the grammatical relations (GRs) as features for clustering. We extracted the features from the Gigaword corpus (Graff et al., 2003), which was first parsed using the RASP parser (Briscoe et al., 2006). The verb lemmas in VERB–SUBJECT, VERB–DIRECT OBJECT and VERB–INDIRECT OBJECT relations with the nouns in the dataset were then extracted from the GR output of the parser. The feature values were the relative frequencies of the features. 2.2 Hierarchical Graph Factorization Clustering The most widely used method for hierarchical word clustering is AGG (Schulte im W</context>
</contexts>
<marker>Pantel, Lin, 2002</marker>
<rawString>Patrick Pantel and Dekang Lin. 2002. Discovering word senses from text. In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 613–619. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Selection and Information: A Class-based Approach to Lexical Relationships.</title>
<date>1993</date>
<tech>Ph.D. thesis,</tech>
<location>Philadelphia, PA, USA.</location>
<contexts>
<context position="20099" citStr="Resnik (1993)" startWordPosition="3275" endWordPosition="3276">d (Subj), eradicate terrorism (Dobj), suffer from corruption (Iobj), diagnose abuse (Dobj), combat fraud (Dobj), cope with crime (Iobj), cure abuse (Dobj), eradicate corruption Figure 5: Identified metaphorical expressions for the mappings FEELING IS FIRE and CRIME IS A DISEASE quantify how well the extracted features describe the source domain (e.g. fire). We extracted nominal argument distributions of the verbs in our feature lists for VERB–SUBJECT, VERB–DIRECT OBJECT and VERB–INDIRECT OBJECT relations. We used the algorithm of Sun and Korhonen (2009) to create SP classes and the measure of Resnik (1993) to quantify how well a particular argument class fits the verb. Resnik measures selectional preference strength 5R(v) of a predicate as a Kullback-Leibler distance between two distributions: the prior probability of the noun class P(c) and the posterior probability of the noun class given the verb P(c|v). 5R(v) = D(P(c|v)||P(c)) = Ec P(c|v) log P (c�v) P (c) . In order to quantify how well a particular argument class fits the verb, Resnik defines selectional association as AR(v, c) = 1 s (v)P(c|v) log p�(C�). We rank the nominal arguments of the verbs in our feature lists using their selectio</context>
</contexts>
<marker>Resnik, 1993</marker>
<rawString>Philip Resnik. 1993. Selection and Information: A Class-based Approach to Lexical Relationships. Ph.D. thesis, Philadelphia, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Schulte im Walde</author>
<author>Chris Brew</author>
</authors>
<title>Inducing German semantic verb classes from purely syntactic subcategorisation information.</title>
<date>2001</date>
<booktitle>In ACL ’02: Proceedings of the 40th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>223--230</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="9238" citStr="Walde and Brew, 2001" startWordPosition="1416" endWordPosition="1419">2; Bergsma et al., 2008), we use the grammatical relations (GRs) as features for clustering. We extracted the features from the Gigaword corpus (Graff et al., 2003), which was first parsed using the RASP parser (Briscoe et al., 2006). The verb lemmas in VERB–SUBJECT, VERB–DIRECT OBJECT and VERB–INDIRECT OBJECT relations with the nouns in the dataset were then extracted from the GR output of the parser. The feature values were the relative frequencies of the features. 2.2 Hierarchical Graph Factorization Clustering The most widely used method for hierarchical word clustering is AGG (Schulte im Walde and Brew, 2001; Stevenson and Joanis, 2003; Ferrer, 2004; Devereux and Costello, 2005). The method treats each word as a singleton cluster and then successively merges two closest clusters until all the clusters have been merged into one. The cluster similarity is measured using linkage criteria (e.g. Ward (1963) measures the decrease in variance for the clusters being merged). As opposed to this, HGFC derives probabilistic bipartite graphs from the similarity matrix (Yu et al., 2006). Since we require a graph of concepts, our task is rather different from standard hierarchical word clustering that produces</context>
</contexts>
<marker>Walde, Brew, 2001</marker>
<rawString>Sabine Schulte im Walde and Chris Brew. 2001. Inducing German semantic verb classes from purely syntactic subcategorisation information. In ACL ’02: Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, pages 223–230, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ekaterina Shutova</author>
<author>Simone Teufel</author>
</authors>
<title>Metaphor corpus annotated for source - target domain mappings.</title>
<date>2010</date>
<booktitle>In Proceedings of LREC 2010,</booktitle>
<pages>3255--3261</pages>
<contexts>
<context position="2334" citStr="Shutova and Teufel, 2010" startWordPosition="349" endWordPosition="352"> my argument”. They demonstrate a metaphorical mapping of the concept of argument to that of war. The argument, which is the target concept, is viewed in terms of a battle (or a war), the source concept. The existence of such a link allows us to systematically describe arguments using the war terminology, thus leading to a number of metaphorical expressions. Lakoff and Johnson call such generalisations a source–target domain mapping, or conceptual metaphor. The ubiquity of metaphor in language has been established in a number of corpus studies (Cameron, 2003; Martin, 2006; Steen et al., 2010; Shutova and Teufel, 2010) and the role it plays in human reasoning has been confirmed in psychological experiments (Thibodeau and Boroditsky, 2011). This makes metaphor an important research area for computational and cognitive linguistics, and its automatic processing indispensable for any semanticsoriented NLP application. The problem of metaphor modeling is gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012). Compared to more traditional approaches based</context>
<context position="22822" citStr="Shutova and Teufel, 2010" startWordPosition="3718" endWordPosition="3721">ch the metaphor extraction method is applied. Given a source concept, the system extracts all its sense1 hypernyms two levels above and subsequently all of their sister terms. The hypernyms themselves are considered to represent the literal sense of the source noun and are, therefore, removed. The sister terms are kept as potential target domains. 3.2 Evaluation of Metaphorical Associations To create our dataset, we extracted 10 common source concepts that map to multiple targets from the Master Metaphor List (Lakoff et al., 1991) and linguistic analyses of metaphor (Lakoff and Johnson, 1980; Shutova and Teufel, 2010). These included FIRE, CHILD, SPEED, WAR, DISEASE, BREAKDOWN, CONSTRUCTION, VEHICLE, SYSTEM, BUSINESS. Each of the three systems identified 50 source–target domain mappings for the given source domains, resulting in a set of 150 conceptual metaphors (each representing a number of submappings since all the target concepts are clusters or synsets). These were then evaluated against human judgements in two different experimental settings. Setting 1: The judges were presented with a set of conceptual metaphors identified by the three systems, randomized. They were asked to annotate the mappings th</context>
</contexts>
<marker>Shutova, Teufel, 2010</marker>
<rawString>Ekaterina Shutova and Simone Teufel. 2010. Metaphor corpus annotated for source - target domain mappings. In Proceedings of LREC 2010, pages 3255– 3261, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ekaterina Shutova</author>
<author>Lin Sun</author>
<author>Anna Korhonen</author>
</authors>
<title>Metaphor identification using verb and noun clustering.</title>
<date>2010</date>
<booktitle>In Proceedings of Coling</booktitle>
<pages>1002--1010</pages>
<location>Beijing, China.</location>
<contexts>
<context position="2843" citStr="Shutova et al., 2010" startWordPosition="425" endWordPosition="428">ished in a number of corpus studies (Cameron, 2003; Martin, 2006; Steen et al., 2010; Shutova and Teufel, 2010) and the role it plays in human reasoning has been confirmed in psychological experiments (Thibodeau and Boroditsky, 2011). This makes metaphor an important research area for computational and cognitive linguistics, and its automatic processing indispensable for any semanticsoriented NLP application. The problem of metaphor modeling is gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of phenomena (Gedigian et al., 2006; Krishnakumaran and Zhu, 2007), and only addressed one of the metaphor processing subtasks:</context>
<context position="4370" citStr="Shutova et al. (2010)" startWordPosition="656" endWordPosition="659">for Computational Linguistics that identifies the generalisations that govern the production of metaphorical expressions, i.e. conceptual metaphors, and then uses these generalisations to identify metaphorical expressions in unrestricted text. As opposed to previous works on statistical metaphor processing that were supervised or semi-supervised, and thus required training data, our method is fully unsupervised. It relies on building a hierarchical graph of concepts connected by their association strength (using hierarchical clustering) and then searching for metaphorical links in this graph. Shutova et al. (2010) introduced the hypothesis of “clustering by association” and claimed that in the course of distributional noun clustering, abstract concepts tend to cluster together if they are associated with the same source domain, while concrete concepts cluster by meaning similarity. We share this intuition, but take this idea a significant step further. Our approach is theoretically grounded in the cognitive science findings suggesting that abstract and concrete concepts are organised differently in the human brain (Crutch and Warrington, 2005; Binder et al., 2005; Wiemer-Hastings and Xu, 2005; Huang et</context>
<context position="29389" citStr="Shutova et al. (2010)" startWordPosition="4813" endWordPosition="4816">likely that some industries will flourish in certain countries as the market widens. Figure 6: Metaphors tagged by the system (in bold) whereby the main source of disagreement was the presence of lexicalized metaphors, e.g. verbs such as impose, decline etc. The system performance against these annotations is P = 0.65 (HGFC), P = 0.47 (AGG) and P = 0.12 (WN). The human ceiling for this task was measured at P = 0.79. Figure 6 shows example sentences annotated by HGFC. The performance of our unsupervised approach is close to the previous supervised systems of Mason (2004) (accuracy of 0.73) and Shutova et al. (2010) (precision of 0.79), however, the results are not directly comparable due to different experimental settings. The system errors in this task stem from multiple word senses of the salient features or the source and target sharing some physical properties (e.g. one can “die from crime” and “die from a disease”). Some identified expressions invoke a chain of mappings (e.g. ABUSE IS A DISEASE, DISEASE IS AN ENEMY for “combat abuse”), however, such chains are not yet incorporated into the system. The performance of AGG is higher than in the mappings identification task, since it outputs only few e</context>
<context position="32733" citStr="Shutova et al. (2010)" startWordPosition="5339" endWordPosition="5342">d in the FINANCE domain for money. From this the system infers the domain mapping FINANCE – LAB and the concept mapping money – liquid. Gedigian et al. (2006) trained a maximum entropy classifier to discriminate between literal and metaphorical use. They annotated the sentences from PropBank (Kingsbury and Palmer, 2002) containing the verbs of MOTION and CURE for metaphoricity. They used PropBank annotation (arguments and their semantic types) as features for classification and report an accuracy of 95.12% (however, against a majority baseline of 92.90%). The metaphor identification system of Shutova et al. (2010) starts from a small seed set of metaphorical expressions, learns the analogies involved in their production and extends the set of analogies by means of verb and noun clustering. As 985 a result, the system can recognize new metaphorical expressions in unrestricted text (e.g. from the seed “stir excitement” it infers that “swallow anger” is also a metaphor), achieving a precision of 79%. Turney et al. (2011) classify verbs and adjectives as literal or metaphorical based on their level of concreteness or abstractness in relation to a noun they appear with. They learn concreteness rankings for </context>
</contexts>
<marker>Shutova, Sun, Korhonen, 2010</marker>
<rawString>Ekaterina Shutova, Lin Sun, and Anna Korhonen. 2010. Metaphor identification using verb and noun clustering. In Proceedings of Coling 2010, pages 1002–1010, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ekaterina Shutova</author>
<author>Simone Teufel</author>
<author>Anna Korhonen</author>
</authors>
<date>2012</date>
<booktitle>Statistical Metaphor Processing. Computational Linguistics,</booktitle>
<volume>39</volume>
<issue>2</issue>
<contexts>
<context position="2887" citStr="Shutova et al., 2012" startWordPosition="433" endWordPosition="436">n, 2003; Martin, 2006; Steen et al., 2010; Shutova and Teufel, 2010) and the role it plays in human reasoning has been confirmed in psychological experiments (Thibodeau and Boroditsky, 2011). This makes metaphor an important research area for computational and cognitive linguistics, and its automatic processing indispensable for any semanticsoriented NLP application. The problem of metaphor modeling is gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of phenomena (Gedigian et al., 2006; Krishnakumaran and Zhu, 2007), and only addressed one of the metaphor processing subtasks: identification of metaphorical mappings (Ma</context>
</contexts>
<marker>Shutova, Teufel, Korhonen, 2012</marker>
<rawString>Ekaterina Shutova, Simone Teufel, and Anna Korhonen. 2012. Statistical Metaphor Processing. Computational Linguistics, 39(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ekaterina Shutova</author>
</authors>
<title>Automatic metaphor interpretation as a paraphrasing task.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL 2010,</booktitle>
<pages>1029--1037</pages>
<location>Los Angeles, USA.</location>
<contexts>
<context position="2821" citStr="Shutova, 2010" startWordPosition="423" endWordPosition="424">has been established in a number of corpus studies (Cameron, 2003; Martin, 2006; Steen et al., 2010; Shutova and Teufel, 2010) and the role it plays in human reasoning has been confirmed in psychological experiments (Thibodeau and Boroditsky, 2011). This makes metaphor an important research area for computational and cognitive linguistics, and its automatic processing indispensable for any semanticsoriented NLP application. The problem of metaphor modeling is gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of phenomena (Gedigian et al., 2006; Krishnakumaran and Zhu, 2007), and only addressed one of the metapho</context>
</contexts>
<marker>Shutova, 2010</marker>
<rawString>Ekaterina Shutova. 2010. Automatic metaphor interpretation as a paraphrasing task. In Proceedings of NAACL 2010, pages 1029–1037, Los Angeles, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sidney Siegel</author>
<author>N John Castellan</author>
</authors>
<title>Nonparametric statistics for the behavioral sciences.</title>
<date>1988</date>
<publisher>McGrawHill Book Company,</publisher>
<location>New York, USA.</location>
<contexts>
<context position="23813" citStr="Siegel and Castellan, 1988" startWordPosition="3879" endWordPosition="3883"> evaluated against human judgements in two different experimental settings. Setting 1: The judges were presented with a set of conceptual metaphors identified by the three systems, randomized. They were asked to annotate the mappings they considered valid. In all our experiments, the judges were encouraged to rely on their own intuition of metaphor, but they also reviewed the metaphor annotation guidelines of Shutova and Teufel (2010). Two independent judges, both na983 tive speakers of English, participated in this experiment. Their agreement on the task was n = 0.60 (n = 2, N = 150, k = 2) (Siegel and Castellan, 1988). The main differences in the annotators’ judgements stem from the fact that some metaphorical associations are less obvious and common than others, and thus need more context (or imaginative effort) to establish. Such examples, where the judges disagreed included metaphorical mappings such as INTENSITY is SPEED, GOAL is a CHILD, COLLECTION is a SYSTEM, ILLNESS is a BREAKDOWN. The system performance was then evaluated against these judgements in terms of precision (P), i.e. the proportion of the valid metaphorical mappings among those identified. We calculated system precision (in all experime</context>
</contexts>
<marker>Siegel, Castellan, 1988</marker>
<rawString>Sidney Siegel and N. John Castellan. 1988. Nonparametric statistics for the behavioral sciences. McGrawHill Book Company, New York, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard J Steen</author>
<author>Aletta G Dorst</author>
<author>J Berenike Herrmann</author>
<author>Anna A Kaal</author>
<author>Tina Krennmayr</author>
<author>Trijntje Pasma</author>
</authors>
<title>A method for linguistic metaphor identification: From MIP to MIPVU.</title>
<date>2010</date>
<publisher>John Benjamins, Amsterdam/Philadelphia.</publisher>
<contexts>
<context position="2307" citStr="Steen et al., 2010" startWordPosition="345" endWordPosition="348"> every weak point in my argument”. They demonstrate a metaphorical mapping of the concept of argument to that of war. The argument, which is the target concept, is viewed in terms of a battle (or a war), the source concept. The existence of such a link allows us to systematically describe arguments using the war terminology, thus leading to a number of metaphorical expressions. Lakoff and Johnson call such generalisations a source–target domain mapping, or conceptual metaphor. The ubiquity of metaphor in language has been established in a number of corpus studies (Cameron, 2003; Martin, 2006; Steen et al., 2010; Shutova and Teufel, 2010) and the role it plays in human reasoning has been confirmed in psychological experiments (Thibodeau and Boroditsky, 2011). This makes metaphor an important research area for computational and cognitive linguistics, and its automatic processing indispensable for any semanticsoriented NLP application. The problem of metaphor modeling is gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012). Compared to more t</context>
</contexts>
<marker>Steen, Dorst, Herrmann, Kaal, Krennmayr, Pasma, 2010</marker>
<rawString>Gerard J. Steen, Aletta G. Dorst, J. Berenike Herrmann, Anna A. Kaal, Tina Krennmayr, and Trijntje Pasma. 2010. A method for linguistic metaphor identification: From MIP to MIPVU. John Benjamins, Amsterdam/Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Suzanne Stevenson</author>
<author>Eric Joanis</author>
</authors>
<title>Semisupervised verb class discovery using noisy features.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL</booktitle>
<pages>71--78</pages>
<contexts>
<context position="9266" citStr="Stevenson and Joanis, 2003" startWordPosition="1420" endWordPosition="1423">8), we use the grammatical relations (GRs) as features for clustering. We extracted the features from the Gigaword corpus (Graff et al., 2003), which was first parsed using the RASP parser (Briscoe et al., 2006). The verb lemmas in VERB–SUBJECT, VERB–DIRECT OBJECT and VERB–INDIRECT OBJECT relations with the nouns in the dataset were then extracted from the GR output of the parser. The feature values were the relative frequencies of the features. 2.2 Hierarchical Graph Factorization Clustering The most widely used method for hierarchical word clustering is AGG (Schulte im Walde and Brew, 2001; Stevenson and Joanis, 2003; Ferrer, 2004; Devereux and Costello, 2005). The method treats each word as a singleton cluster and then successively merges two closest clusters until all the clusters have been merged into one. The cluster similarity is measured using linkage criteria (e.g. Ward (1963) measures the decrease in variance for the clusters being merged). As opposed to this, HGFC derives probabilistic bipartite graphs from the similarity matrix (Yu et al., 2006). Since we require a graph of concepts, our task is rather different from standard hierarchical word clustering that produces a tree of concepts. In a tr</context>
</contexts>
<marker>Stevenson, Joanis, 2003</marker>
<rawString>Suzanne Stevenson and Eric Joanis. 2003. Semisupervised verb class discovery using noisy features. In Proceedings of HLT-NAACL 2003, pages 71–78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lin Sun</author>
<author>Anna Korhonen</author>
</authors>
<title>Improving verb clustering with automatically acquired selectional preferences.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP 2009,</booktitle>
<pages>638--647</pages>
<location>Singapore,</location>
<contexts>
<context position="20045" citStr="Sun and Korhonen (2009)" startWordPosition="3263" endWordPosition="3266">pe (Iobj) CRIME IS A DISEASE cure crime (Dobj), abuse transmitted (Subj), eradicate terrorism (Dobj), suffer from corruption (Iobj), diagnose abuse (Dobj), combat fraud (Dobj), cope with crime (Iobj), cure abuse (Dobj), eradicate corruption Figure 5: Identified metaphorical expressions for the mappings FEELING IS FIRE and CRIME IS A DISEASE quantify how well the extracted features describe the source domain (e.g. fire). We extracted nominal argument distributions of the verbs in our feature lists for VERB–SUBJECT, VERB–DIRECT OBJECT and VERB–INDIRECT OBJECT relations. We used the algorithm of Sun and Korhonen (2009) to create SP classes and the measure of Resnik (1993) to quantify how well a particular argument class fits the verb. Resnik measures selectional preference strength 5R(v) of a predicate as a Kullback-Leibler distance between two distributions: the prior probability of the noun class P(c) and the posterior probability of the noun class given the verb P(c|v). 5R(v) = D(P(c|v)||P(c)) = Ec P(c|v) log P (c�v) P (c) . In order to quantify how well a particular argument class fits the verb, Resnik defines selectional association as AR(v, c) = 1 s (v)P(c|v) log p�(C�). We rank the nominal arguments </context>
</contexts>
<marker>Sun, Korhonen, 2009</marker>
<rawString>Lin Sun and Anna Korhonen. 2009. Improving verb clustering with automatically acquired selectional preferences. In Proceedings of EMNLP 2009, pages 638–647, Singapore, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lin Sun</author>
<author>Anna Korhonen</author>
</authors>
<title>Hierarchical verb clustering using graph factorization.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>1023--1033</pages>
<location>Edinburgh, UK.</location>
<contexts>
<context position="7574" citStr="Sun and Korhonen, 2011" startWordPosition="1156" endWordPosition="1159">to identify metaphorical connections between the concepts. To the best of our knowledge, our method is the first one to use a hierarchical clustering model for the metaphor processing task. The original graph of concepts is built using hierarchical graph factorization clustering (HGFC) (Yu et al., 2006) of nouns, yielding a network of clusters with different levels of generality. The weights on the edges of the graph indicate association between the clusters (concepts). HGFC has not been previously employed for noun clustering in NLP, but showed successful results in the verb clustering task (Sun and Korhonen, 2011). In summary, our system (1) builds a graph of concepts using HGFC, (2) traverses it to find metaphorical associations between clusters using weights on the edges of the graph, (3) generates lists of salient features for the metaphorically connected clusters and (4) searches the British National Corpus (BNC) (Burnard, 2007) for metaphorical expressions describing the target domain concepts using the verbs from the set of salient features. We evaluated the performance of the system with the aid of human judges in precision- and recall-oriented settings. In addition, we compared its performance </context>
<context position="10210" citStr="Sun and Korhonen, 2011" startWordPosition="1577" endWordPosition="1580">rs being merged). As opposed to this, HGFC derives probabilistic bipartite graphs from the similarity matrix (Yu et al., 2006). Since we require a graph of concepts, our task is rather different from standard hierarchical word clustering that produces a tree of concepts. In a tree, each word can only have a unique parent cluster at each level. Our concept graph does not have this constraint: at any level a word can be associated with an arbitrary number of parent clusters. Therefore, not only HGFC outperformed agglomerative clustering methods in hierarchical clustering tasks (Yu et al., 2006; Sun and Korhonen, 2011), but its hierarchical graph output is also a more suitable representation of the concept graph. In addition, HGFC can detect the number of levels and the number of clusters on each level of the hierarchical graph automatically. This is essential for our task as these settings are difficult to predefine for a general-purpose concept graph. Given a set of nouns, V = {vn}Nn�1, the similarity matrix W for HGFC is constructed using JensenShannon Divergence. W can be encoded by an undirected graph G (Figure 2(a)), where the nouns are mapped to vertices and Wij is the edge weight between vertices i </context>
<context position="13692" citStr="Sun and Korhonen (2011)" startWordPosition="2256" endWordPosition="2259">ost function can thus be optimized by updating h and λ alternately. The similarity between clusters p(up, uq) can be induced from B, as follows: p(up, uq) = p(up)p(up|uq) = (BT D−1B)pq (4) D = diag(d1, ..., dn) where di = We can then construct a new graph G1 (Figure 2(d)) with the clusters U as vertices, and the cluster similarity p as the connection weight. The clustering algorithm can now be applied again (Figure 2(e)). This process can go on iteratively, leading to a hierarchical graph. The number of levels (L) and the number of clusters (ml) are detected automatically, using the method of Sun and Korhonen (2011). Clustering starts with an initial setting of number of clusters (m0) for the first level. In our experiment, we set the = (D(−1) 1 B1D−1 2 B2...D−1 l Bl)ip (5) Due to the random walk property of the graph, ml is non-increasing for higher levels (Sun and Korhonen, 2011). The algorithm can thus terminate when all nouns are assigned to one cluster. We run 1000 iterations of updates of h and λ (equation 2 and 3) for each two adjacent levels. The resulting graph is composed of a set of bipartite graphs defined by Bl, Bl−1,..., B1. A bipartite graph has a similar structure as in Figure 1. For a gi</context>
<context position="25383" citStr="Sun and Korhonen, 2011" startWordPosition="4147" endWordPosition="4150">otators (both native speakers with a background in metaphor, different from Setting 1) to write down up to 5 target concepts they strongly associated with each of the 10 source concepts. Their annotations were then aggregated into a single metaphor association gold standard, consisting of 63 mappings in total. The recall of the systems was measured against this gold standard, resulting in HGFC R = 0.61, AGG R = 0.11 and WN R = 0.03. As expected, HGFC outperforms both AGG and WN baselines in both settings. AGG has been previously shown to be less accurate than HGFC in the verb clustering task (Sun and Korhonen, 2011). Our analysis of the noun clusters indicated that HGFC tends to produce more pure and complete clusters than AGG. Another important reason AGG fails is that it by definition organises all concepts into tree and optimises its solution locally, taking into account a small number of clusters at a time. However, being able to discover connections between more distant domains and optimising globally over all concepts is crucial for metaphor identification. This makes AGG less suitable for the task, as demonstrated by our results. However, AGG identified a number of interesting mappings missed by H</context>
</contexts>
<marker>Sun, Korhonen, 2011</marker>
<rawString>Lin Sun and Anna Korhonen. 2011. Hierarchical verb clustering using graph factorization. In Proceedings of EMNLP, pages 1023–1033, Edinburgh, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul H Thibodeau</author>
<author>Lera Boroditsky</author>
</authors>
<title>Metaphors we think with: The role of metaphor in reasoning.</title>
<date>2011</date>
<journal>PLoS ONE,</journal>
<volume>6</volume>
<issue>2</issue>
<pages>02</pages>
<contexts>
<context position="2456" citStr="Thibodeau and Boroditsky, 2011" startWordPosition="368" endWordPosition="371">h is the target concept, is viewed in terms of a battle (or a war), the source concept. The existence of such a link allows us to systematically describe arguments using the war terminology, thus leading to a number of metaphorical expressions. Lakoff and Johnson call such generalisations a source–target domain mapping, or conceptual metaphor. The ubiquity of metaphor in language has been established in a number of corpus studies (Cameron, 2003; Martin, 2006; Steen et al., 2010; Shutova and Teufel, 2010) and the role it plays in human reasoning has been confirmed in psychological experiments (Thibodeau and Boroditsky, 2011). This makes metaphor an important research area for computational and cognitive linguistics, and its automatic processing indispensable for any semanticsoriented NLP application. The problem of metaphor modeling is gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden</context>
<context position="27177" citStr="Thibodeau and Boroditsky, 2011" startWordPosition="4438" endWordPosition="4441">n not be captured in a tree-like classification (even an accurate, manually created one). The latter is more appropriate for concrete concepts, and a more flexible representation is needed to model abstract concepts. The fact that both baselines identified some valid metaphorical associations, relying on less suitable conceptual graphs, suggests that our way of traversing the graph is a viable approach in principle. HGFC identifies valid metaphorical associations for a range of source concepts. On of them (CRIME IS A VIRUS) happened to have been already validated in psychological experiments (Thibodeau and Boroditsky, 2011). The most frequent type of error of HGFC is the presence of target clusters similar or closely related to the source noun (e.g. the parent cluster for child). The clusters from the same domain can, however, be filtered out if their nouns frequently occur in the same documents with the source noun (in a large corpus), i.e. by topical similarity. The latter is less likely for the metaphorically connected nouns. We intend to implement this improvement in the future version of the system. 3.3 Evaluation of Metaphorical Expressions For each of the identified conceptual metaphors, the three systems</context>
</contexts>
<marker>Thibodeau, Boroditsky, 2011</marker>
<rawString>Paul H. Thibodeau and Lera Boroditsky. 2011. Metaphors we think with: The role of metaphor in reasoning. PLoS ONE, 6(2):e16782, 02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
<author>Yair Neuman</author>
<author>Dan Assaf</author>
<author>Yohai Cohen</author>
</authors>
<title>Literal and metaphorical sense identification through concrete and abstract context.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11,</booktitle>
<pages>680--690</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2864" citStr="Turney et al., 2011" startWordPosition="429" endWordPosition="432">orpus studies (Cameron, 2003; Martin, 2006; Steen et al., 2010; Shutova and Teufel, 2010) and the role it plays in human reasoning has been confirmed in psychological experiments (Thibodeau and Boroditsky, 2011). This makes metaphor an important research area for computational and cognitive linguistics, and its automatic processing indispensable for any semanticsoriented NLP application. The problem of metaphor modeling is gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of phenomena (Gedigian et al., 2006; Krishnakumaran and Zhu, 2007), and only addressed one of the metaphor processing subtasks: identification of me</context>
<context position="33145" citStr="Turney et al. (2011)" startWordPosition="5407" endWordPosition="5410">rguments and their semantic types) as features for classification and report an accuracy of 95.12% (however, against a majority baseline of 92.90%). The metaphor identification system of Shutova et al. (2010) starts from a small seed set of metaphorical expressions, learns the analogies involved in their production and extends the set of analogies by means of verb and noun clustering. As 985 a result, the system can recognize new metaphorical expressions in unrestricted text (e.g. from the seed “stir excitement” it infers that “swallow anger” is also a metaphor), achieving a precision of 79%. Turney et al. (2011) classify verbs and adjectives as literal or metaphorical based on their level of concreteness or abstractness in relation to a noun they appear with. They learn concreteness rankings for words automatically (starting from a set of examples) and then search for expressions where a concrete adjective or verb is used with an abstract noun (e.g. “dark humour” is tagged as a metaphor and “dark hair” is not). They report an accuracy of 73%. 5 Conclusions and Future Directions Previous research on metaphor addressed a number of different aspects of the phenomenon, and has shown that these aspects ca</context>
</contexts>
<marker>Turney, Neuman, Assaf, Cohen, 2011</marker>
<rawString>Peter D. Turney, Yair Neuman, Dan Assaf, and Yohai Cohen. 2011. Literal and metaphorical sense identification through concrete and abstract context. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11, pages 680–690, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joe H Ward</author>
</authors>
<title>Hierarchical grouping to optimize an objective function.</title>
<date>1963</date>
<journal>Journal of the American statistical association,</journal>
<pages>58--301</pages>
<contexts>
<context position="9538" citStr="Ward (1963)" startWordPosition="1467" endWordPosition="1468">CT relations with the nouns in the dataset were then extracted from the GR output of the parser. The feature values were the relative frequencies of the features. 2.2 Hierarchical Graph Factorization Clustering The most widely used method for hierarchical word clustering is AGG (Schulte im Walde and Brew, 2001; Stevenson and Joanis, 2003; Ferrer, 2004; Devereux and Costello, 2005). The method treats each word as a singleton cluster and then successively merges two closest clusters until all the clusters have been merged into one. The cluster similarity is measured using linkage criteria (e.g. Ward (1963) measures the decrease in variance for the clusters being merged). As opposed to this, HGFC derives probabilistic bipartite graphs from the similarity matrix (Yu et al., 2006). Since we require a graph of concepts, our task is rather different from standard hierarchical word clustering that produces a tree of concepts. In a tree, each word can only have a unique parent cluster at each level. Our concept graph does not have this constraint: at any level a word can be associated with an arbitrary number of parent clusters. Therefore, not only HGFC outperformed agglomerative clustering methods in</context>
<context position="21642" citStr="Ward, 1963" startWordPosition="3526" endWordPosition="3527">as descriptive source domain vocabulary. We then search the RASP-parsed BNC for grammatical relations, in which the nouns from the target domain cluster appear with the verbs from the source domain vocabulary (e.g. “war blazed” (subj), “to fuel violence” (dobj) for the mapping VIOLENCE is FIRE). The system thus annotates metaphorical expressions in text, as well as the corresponding conceptual metaphors, as shown in Figure 5. 3 Evaluation and Discussion 3.1 Baselines AGG: the agglomerative clustering baseline is constructed using SciPy implementation (Oliphant, 2007) of Ward’s linkage method (Ward, 1963). The output tree is cut according to the number of levels and the number of clusters of the explicit graph detected by HGFC. The resulting tree is converted into a graph by adding connections from each cluster to all the clusters one level above. The connection weight (the cluster distance) is measured using Jensen-Shannon Divergence between the cluster centroids. This graph is used in place of the HGFC graph in the metaphor identification experiments. WN: in the WN baseline, the WordNet hierarchy is used as the underlying graph of concepts, to which the metaphor extraction method is applied.</context>
</contexts>
<marker>Ward, 1963</marker>
<rawString>Joe H. Ward. 1963. Hierarchical grouping to optimize an objective function. Journal of the American statistical association, 58(301):236–244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katja Wiemer-Hastings</author>
<author>Xu Xu</author>
</authors>
<title>Content Differences for Abstract and Concrete Concepts.</title>
<date>2005</date>
<journal>Cognitive Science,</journal>
<volume>29</volume>
<issue>5</issue>
<contexts>
<context position="4960" citStr="Wiemer-Hastings and Xu, 2005" startWordPosition="745" endWordPosition="748">s in this graph. Shutova et al. (2010) introduced the hypothesis of “clustering by association” and claimed that in the course of distributional noun clustering, abstract concepts tend to cluster together if they are associated with the same source domain, while concrete concepts cluster by meaning similarity. We share this intuition, but take this idea a significant step further. Our approach is theoretically grounded in the cognitive science findings suggesting that abstract and concrete concepts are organised differently in the human brain (Crutch and Warrington, 2005; Binder et al., 2005; Wiemer-Hastings and Xu, 2005; Huang et al., 2010; Crutch and Warrington, 2010; Adorni and Proverbio, 2012). According to Crutch and Warrington (2005), these differences emerge from their general patterns of relation with other concepts. However, most NLP systems to date treat abstract and concrete concepts as identical. In contrast, we incorporate this distinction into our model by creating a network (or a graph) of concepts, and automatically learning the different patterns of association of abstract and concrete concepts with other concepts. We expect that, while concrete concepts would tend to naturally organise into </context>
</contexts>
<marker>Wiemer-Hastings, Xu, 2005</marker>
<rawString>Katja Wiemer-Hastings and Xu Xu. 2005. Content Differences for Abstract and Concrete Concepts. Cognitive Science, 29(5):719–736.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kai Yu</author>
<author>Shipeng Yu</author>
<author>Volker Tresp</author>
</authors>
<title>Soft clustering on graphs.</title>
<date>2006</date>
<booktitle>Advances in Neural Information Processing Systems,</booktitle>
<volume>18</volume>
<contexts>
<context position="7255" citStr="Yu et al., 2006" startWordPosition="1106" endWordPosition="1109">ributional learning approach would learn that they share features with political systems (from their literal uses), as well as with mechanisms (from their metaphorical uses, as shown next to the respective graph edges in the figure). Our system discovers such association patterns within the graph and uses them to identify metaphorical connections between the concepts. To the best of our knowledge, our method is the first one to use a hierarchical clustering model for the metaphor processing task. The original graph of concepts is built using hierarchical graph factorization clustering (HGFC) (Yu et al., 2006) of nouns, yielding a network of clusters with different levels of generality. The weights on the edges of the graph indicate association between the clusters (concepts). HGFC has not been previously employed for noun clustering in NLP, but showed successful results in the verb clustering task (Sun and Korhonen, 2011). In summary, our system (1) builds a graph of concepts using HGFC, (2) traverses it to find metaphorical associations between clusters using weights on the edges of the graph, (3) generates lists of salient features for the metaphorically connected clusters and (4) searches the B</context>
<context position="9713" citStr="Yu et al., 2006" startWordPosition="1493" endWordPosition="1496">rarchical Graph Factorization Clustering The most widely used method for hierarchical word clustering is AGG (Schulte im Walde and Brew, 2001; Stevenson and Joanis, 2003; Ferrer, 2004; Devereux and Costello, 2005). The method treats each word as a singleton cluster and then successively merges two closest clusters until all the clusters have been merged into one. The cluster similarity is measured using linkage criteria (e.g. Ward (1963) measures the decrease in variance for the clusters being merged). As opposed to this, HGFC derives probabilistic bipartite graphs from the similarity matrix (Yu et al., 2006). Since we require a graph of concepts, our task is rather different from standard hierarchical word clustering that produces a tree of concepts. In a tree, each word can only have a unique parent cluster at each level. Our concept graph does not have this constraint: at any level a word can be associated with an arbitrary number of parent clusters. Therefore, not only HGFC outperformed agglomerative clustering methods in hierarchical clustering tasks (Yu et al., 2006; Sun and Korhonen, 2011), but its hierarchical graph output is also a more suitable representation of the concept graph. In add</context>
<context position="12809" citStr="Yu et al. (2006)" startWordPosition="2093" endWordPosition="2096">rs U; (e) The new bipartite graph over G1 value of m0 to 800. For the subsequent levels, ml is set to the number of non-empty clusters (bipartite graph nodes) on the parent level. The matrices B and A are initialized randomly. We found that the actual initialization values have little impact on the final result. The rows in B are normalized after the initialization so the values in each row add up to one. For a word vi, the probability of assigning it to cluster x�l) pE Xl at level l is given by: min ζ(W, HAHT ), s.t. n hip = 1 (1) H,Λ X i=1 X xij xij + yij) H = BA−1;ζ(X,Y ) = (xij log ij yij Yu et al. (2006) showed that this cost function is non-increasing under the update rule: X�hip oc hip j wij (HAHT) λphjp s.t. X hip = 1 (2) ij i X�λp oc λp j X X hiphjp s.t. �λp = wij (3) (HAHT )ij p(x(l)p|vi) = X X1_1 X... p(x(l) p|x(l−1))...p(x(1)|vi) x(1)∈X1 wij p ij The cost function can thus be optimized by updating h and λ alternately. The similarity between clusters p(up, uq) can be induced from B, as follows: p(up, uq) = p(up)p(up|uq) = (BT D−1B)pq (4) D = diag(d1, ..., dn) where di = We can then construct a new graph G1 (Figure 2(d)) with the clusters U as vertices, and the cluster similarity p as th</context>
</contexts>
<marker>Yu, Yu, Tresp, 2006</marker>
<rawString>Kai Yu, Shipeng Yu, and Volker Tresp. 2006. Soft clustering on graphs. Advances in Neural Information Processing Systems, 18.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>