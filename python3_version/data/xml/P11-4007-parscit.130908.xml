<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.019747">
<title confidence="0.9994365">
An ERP-based Brain-Computer Interface for text entry
using Rapid Serial Visual Presentation and Language Modeling
</title>
<author confidence="0.976363">
K.E. Hild◦, U. Orhan†, D. Erdogmus†, B. Roark◦, B. Oken◦, S. Purwar†, H. Nezamfar†, M. Fried-Oken◦
</author>
<affiliation confidence="0.935161">
◦Oregon Health and Science University †Cognitive Systems Lab, Northeastern University
</affiliation>
<email confidence="0.997945">
{hildk,roarkb,oken,friedm}@ohsu.edu {orhan,erdogmus,purwar,nezamfar}@ece.neu.edu
</email>
<sectionHeader confidence="0.993865" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999780444444445">
Event related potentials (ERP) corresponding
to stimuli in electroencephalography (EEG)
can be used to detect the intent of a per-
son for brain computer interfaces (BCI). This
paradigm is widely used to build letter-by-
letter text input systems using BCI. Neverthe-
less using a BCI-typewriter depending only on
EEG responses will not be sufficiently accu-
rate for single-trial operation in general, and
existing systems utilize many-trial schemes to
achieve accuracy at the cost of speed. Hence
incorporation of a language model based prior
or additional evidence is vital to improve accu-
racy and speed. In this demonstration we will
present a BCI system for typing that integrates
a stochastic language model with ERP classifi-
cation to achieve speedups, via the rapid serial
visual presentation (RSVP) paradigm.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99998375">
There exist a considerable number of people with se-
vere motor and speech disabilities. Brain computer
interfaces (BCI) are a potential technology to create
a novel communication environment for this popula-
tion, especially persons with completely paralyzed
voluntary muscles (Wolpaw, 2007; Pfurtscheller et
al., 2000). One possible application of BCI is typ-
ing systems; specifically, those BCI systems that
use electroencephalography (EEG) have been in-
creasingly studied in the recent decades to enable
the selection of letters for expressive language gen-
eration (Wolpaw, 2007; Pfurtscheller et al., 2000;
Treder and Blankertz, 2010). However, the use of
noninvasive techniques for letter-by-letter systems
lacks efficiency due to low signal to noise ratio and
variability of background brain activity. Therefore
current BCI-spellers suffer from low symbol rates
and researchers have turned to various hierarchi-
cal symbol trees to achieve system speedups (Serby
et al., 2005; Wolpaw et al., 2002; Treder and
Blankertz, 2010). Slow throughput greatly dimin-
ishes the practical usability of such systems. In-
corporation of a language model, which predicts
the next letter using the previous letters, into the
</bodyText>
<page confidence="0.986831">
38
</page>
<bodyText confidence="0.966732060606061">
decision-making process can greatly affect the per-
formance of these systems by improving the accu-
racy and speed.
As opposed to the matrix layout of the popu-
lar P300-Speller (Wolpaw, 2007), shown in Fig-
ure 1, or the hexagonal two-level hierarchy of the
Berlin BCI (Treder and Blankertz, 2010), we uti-
lize another well-established paradigm: rapid se-
rial visual presentation (RSVP), shown in Figure
2. This paradigm relies on presenting one stimu-
lus at a time at the focal point of the screen. The
sequence of stimuli are presented at relatively high
speeds, each subsequent stimulus replacing the pre-
vious one, while the subject tries to perform men-
tal target matching between the intended symbol and
the presented stimuli. EEG responses corresponding
to the visual stimuli are classified using regularized
discriminant analysis (RDA) applied to stimulus-
locked temporal features from multiple channels.
The RSVP interface is of particular utility for the
most impaired users, including those suffering from
locked-in syndrome (LIS). Locked-in syndrome can
result from traumatic brain injury, such as a brain-
stem stroke1, or from neurodegenerative diseases
such as amyotrophic lateral sclerosis (ALS or Lou
Gehrig’s disease). The condition is characterized by
near total paralysis, though the individuals are cog-
nitively intact. While vision is retained, the motor
control impairments extend to eye movements. Of-
ten the only reliable movement that can be made by
1Brain stem stroke was the cause of LIS for Jean-Dominique
Bauby, who dictated his memoir The Diving Bell and the But-
terfly via eyeblinks (Bauby, 1997).
</bodyText>
<figure confidence="0.989823">
A B C D E F
G H I J K L
M N O P Q R
S T U V W X
Y Z 1 2 3 4
5 6 7 8 9 _
</figure>
<figureCaption confidence="0.9933985">
Figure 1: Spelling grid such as that used for the P300
speller (Farwell and Donchin, 1988). ‘ ’ denotes space.
</figureCaption>
<note confidence="0.295281">
Proceedings of the ACL-HLT 2011 System Demonstrations, pages 38–43,
Portland, Oregon, USA, 21 June 2011. c�2011 Association for Computational Linguistics
</note>
<figureCaption confidence="0.998395">
Figure 2: RSVP scanning interface.
</figureCaption>
<bodyText confidence="0.999982214285714">
an individual is a particular muscle twitch or single
eye blink, if that. Such users have lost the voluntary
motor control sufficient for such an interface. Rely-
ing on extensive visual scanning or complex gestu-
ral feedback from the user renders a typing interface
difficult or impossible to use for the most impaired
users. Simpler interactions via brain-computer in-
terfaces (BCI) hold much promise for effective text
communication for these most impaired users. Yet
these simple interfaces have yet to take full advan-
tage of language models to ease or speed typing.
In this demonstration, we will present a language-
model enabled interface that is appropriate for the
most impaired users.
In addition, the RSVP paradigm provides some
useful interface flexibility relative to the grid-based
paradigm. First, it allows for auditory rather than
visual scanning, for use by the visually impaired
or when visual access is inconvenient, such as in
face-to-face communication. Auditory scanning is
less straightforward when using a grid. Second,
multi-character substrings can be scanned in RSVP,
whereas the kind of dynamic re-organization of a
grid that would be required to support this can be
very confusing. Finally, language model integration
with RSVP is relatively straightforward, as we shall
demonstrate. See Roark et al. (2010) for methods
integrating language modeling into grid scanning.
</bodyText>
<sectionHeader confidence="0.916717" genericHeader="method">
2 RSVP based BCI and ERP Classification
</sectionHeader>
<bodyText confidence="0.999986692307692">
RSVP is an experimental psychophysics technique
in which visual stimulus sequences are displayed
on a screen over time on a fixed focal area and
in rapid succession. The Matrix-P300-Speller used
by Wadsworth and Graz groups (especially g.tec,
Austria) opts for a spatially distributed presentation
of possible symbols, highlighting them in different
orders and combinations to elicit P300 responses.
Berlin BCI’s recent variation utilizes a 2-layer tree
structure where the subject chooses among six units
(symbols or sets of these) where the options are laid
out on the screen while the subject focuses on a cen-
tral focal area that uses an RSVP-like paradigm to
elicit P300 responses. Full screen awareness is re-
quired. In contrast, our approach is to distribute
the stimuli temporally and present one symbol at a
time using RSVP and seek a binary response to find
the desired letter, as shown in Figure 2. The latter
method has the advantage of not requiring the user
to look at different areas of the screen, which can be
an important factor for those with LIS.
Our RSVP paradigm utilizes stimulus sequences
consisting of the 26 letters in the English alphabet
plus symbols for space and backspace, presented in
a randomly ordered sequence. When the user sees
the target symbol, the brain generates an evoked re-
sponse potential (ERP) in the EEG; the most promi-
nent component of this ERP is the P300 wave, which
is a positive deflection in the scalp voltage primar-
ily in frontal areas and that generally occurs with a
latency of approximately 300 ms. This natural nov-
elty response of the brain, occurring when the user
detects a rare, sought-after target, allows us to make
binary decisions about the user’s intent.
The intent detection problem becomes a signal
classification problem when the EEG signals are
windowed in a stimulus-time-locked manner start-
ing at stimulus onset and extending for a sufficient
duration – in this case 500ms. Consider Figure
3, which shows the trial-averaged temporal signals
from various EEG channels corresponding to tar-
get and non-target (distractor) symbols. This graph
shows a clear effect between 300 and 500 ms for the
target symbols that is not present for the distractor
symbols (the latter of which clearly shows a com-
ponent having a periodicity of 400 ms, which is ex-
pected in this case since a new image was presented
every 400 ms). Figure 4, on the other hand, shows
the magnitude of the trial and distractor responses at
channel Cz on a single-trial basis, rather than aver-
aged over all trials. The signals acquired from each
EEG channel are incorporated and classified to de-
termine the class label: ERP or non-ERP.
Our system functions as follows. First, each chan-
nel is band-pass filtered. Second, each channel is
temporally-windowed. Third, a linear dimension
reduction (using principal components analysis) is
learned using training data and is subsequently ap-
plied to the EEG data when the system is being
used. Fourth, the data vectors obtained for each
channel and a given stimulus are concatenated to
create the data matrix corresponding to the speci-
fied stimulus. Fifth, Regularized Discriminant Anal-
ysis (RDA) (Friedman, 1989), which estimates con-
ditional probability densities for each class using
</bodyText>
<page confidence="0.998867">
39
</page>
<figureCaption confidence="0.998035333333333">
Figure 3: Trial-averaged EEG data corresponding to the target
response (top) and distractor response (bottom) for a 1 second
window.
</figureCaption>
<bodyText confidence="0.999911458333333">
Kernel Density Estimation (KDE), is used to deter-
mine a purely EEG-based classification discriminant
score for each stimulus. Sixth, the conditional prob-
ability of each letter given the typed history is ob-
tained from the language model. Seventh, Bayesian
fusion (which assumes the EEG-based information
and the language model information are statistically
independent given the class label) is used to combine
the RDA discriminant score and the language model
score to generate an overall score, from which we
infer whether or not a given stimulus represents an
intended (target) letter.
RDA is a modified quadratic discriminant anal-
ysis (QDA) model. Assuming each class has a
multivariate normal distribution and assuming clas-
sification is made according to the comparison of
posterior distributions of the classes, the optimal
Bayes classifier resides within the QDA model fam-
ily. QDA depends on the inverse of the class co-
variance matrices, which are to be estimated from
training data. Hence, for small sample sizes and
high-dimensional data, singularities of these matri-
ces are problematic. RDA applies regularization and
shrinkage procedures to the class covariance matrix
</bodyText>
<figureCaption confidence="0.999427">
Figure 4: Single-trial EEG data at channel Cz corresponding
to the target response (top) and distractor response (bottom) for
a 1 second window.
</figureCaption>
<bodyText confidence="0.985472666666667">
estimates in an attempt to minimize problems asso-
ciated with singularities. The shrinkage procedure
makes the class covariances closer to the overall data
covariance, and therefore to each other, thus mak-
ing the quadratic boundary more similar to a linear
boundary. Shrinkage is applied as
</bodyText>
<equation confidence="0.976277">
E,(A) = (1 − A)E, + A�Σ, (1)
</equation>
<bodyText confidence="0.999469">
where A is the shrinkage parameter, E, is the class
covariance matrix estimated for class c E t0, 11,
c = 0 corresponds to the non-target class, c = 1 cor-
responds to the target class, and Σ� is the weighted
average of class covariance matrices. Regularization
is administered as
</bodyText>
<equation confidence="0.750283">
�Σ,(A, Y) = (1 − Y) �Σ,(A) + Ydtr[�Σ,(A)]I, (2)
</equation>
<bodyText confidence="0.999719285714286">
where Y is the regularization parameter, tr[·] is the
trace function, and d is the dimension of the data
vector.
After carrying out the regularization and shrink-
age on the estimated covariance matrices, the
Bayesian classification rule (Duda et al., 2001) is
applied by comparing the log-likelihood ratio (using
</bodyText>
<page confidence="0.995468">
40
</page>
<figureCaption confidence="0.999895">
Figure 5: Timing of stimulus sequence presentation
</figureCaption>
<bodyText confidence="0.97756065">
the posterior probability distributions) with a confi-
dence threshold. The confidence threshold can be
chosen so that the system incorporates the relative
risks or costs of making an error for each class. The
corresponding log-likelihood ratio is given by
where µ, and �r, are the estimates of the class means
and priors, respectively, x is the data vector to be
classified, and fN(x; µ, Σ) is the pdf of a multivari-
ate normal distribution.
The set of visual stimuli (letters plus two ex-
tra symbols, in our case) can be shown multiple
times to achieve a higher classification accuracy for
the EEG-based classifier. The information obtained
from showing the visual stimuli multiple times can
easily be combined by assuming the trials are sta-
tistically independent, as is commonly assumed in
EEG-based spellers2. Figure 5 presents a diagram of
the timing of the presentation of stimuli. We define
a sequence to be a randomly-ordered set of all the
letters (and the space and backspace symbols). The
letters are randomly ordered for each sequence be-
cause the magnitude of the ERP, hence the quality of
the EEG-based classification, is commonly thought
to depend on how surprised the user is to find the
intended letter. Our system also has a user-defined
parameter by which we are able to limit the max-
imum number of sequences shown to the user be-
fore our system makes a decision on the (single) in-
tended letter. Thus we are able to operate in single-
trial or multi-trial mode. We use the term epoch to
denote all the sequences that are used by our sys-
tem to make a decision on a single, intended let-
2The typical number of repetitions of visual stimuli is on the
order of 8 or 16, although g.tec claims one subject is able to
achieve reliable operation with 2 trials (verbal communication).
ter. As can be seen in the timing diagram shown
in Figure 5, epoch k contains between 1 and Mk
sequences. This figure shows the onset of each se-
quence, each fixation image (which is shown at the
beginning of each sequence), and each letter using
narrow pulses. After each sequence is shown, the
cumulative (overall) score for all letters is computed.
The cumulative scores are non-negative and sum to
one (summing over the 28 symbols). If the num-
ber of sequences shown is less than the user-defined
limit and if the maximum cumulative score is less
than 0.9, then another randomly-ordered sequence is
shown to the user. Likewise, if either the maximum
number of sequences has already been shown or if
the maximum cumulative score equals or exceeds
0.9, then the associated symbol (for all symbols ex-
cept the backspace) is added to the end of the list
of previously-detected symbols, the user is able to
take a break of indefinite length, and then the system
continues with the next epoch. If the symbol hav-
ing the maximum cumulative score is the backspace
symbol, then the last item in the list of previously-
detected symbols is removed and, like before, the
user can take a break and then the system continues
with the next epoch.
</bodyText>
<sectionHeader confidence="0.990927" genericHeader="method">
3 Language Modeling
</sectionHeader>
<bodyText confidence="0.99994875">
Language modeling is important for many text pro-
cessing applications, e.g., speech recognition or ma-
chine translation, as well as for the kind of typ-
ing application being investigated here (Roark et al.,
2010). Typically, the prefix string (what has al-
ready been typed) is used to predict the next sym-
bol(s) to be typed. The next letters to be typed be-
come highly predictable in certain contexts, partic-
ularly word-internally. In applications where text
generation/typing speed is very slow, the impact
of language modeling can become much more sig-
nificant. BCI-spellers, including the RSVP Key-
board paradigm presented here, can be extremely
low-speed, letter-by-letter writing systems, and thus
can greatly benefit from the incorporation of proba-
bilistic letter predictions from an accurate language
model.
For the current study, all language models were
estimated from a one million sentence (210M char-
acter) sample of the NY Times portion of the English
Gigaword corpus. Models were character n-grams,
estimated via relative frequency estimation. Corpus
normalization and smoothing methods were as de-
scribed in Roark et al. (2010). Most importantly for
</bodyText>
<equation confidence="0.9991462">
, Σ1(A,&apos;Y))�r1 (3)
fN(x; µ0, t0(A,&apos;Y))�r0
fN(x;
1
SRDA (x) = log
</equation>
<page confidence="0.998926">
41
</page>
<figureCaption confidence="0.999364">
Figure 6: Block diagram of system architecture.
</figureCaption>
<bodyText confidence="0.9463305">
this work, the corpus was case normalized, and we
used Witten-Bell smoothing for regularization.
</bodyText>
<sectionHeader confidence="0.974594" genericHeader="method">
4 System Architecture
</sectionHeader>
<bodyText confidence="0.999821032258065">
Figure 6 shows a block diagram of our system. We
use a Quad-core, 2.53 GHz laptop, with system code
written in Labview, Matlab, and C. We also use
the Psychophysics Toolbox3 to preload the images
into the video card and to display the images at
precisely-defined temporal intervals. The type UB
g.USBamp EEG-signal amplifier, which is manufac-
tured by g.tec (Austria), has 24 bits of precision and
has 16 channels. We use a Butterworth bandpass fil-
ter of 0.5 to 60 Hz, a 60 Hz notch filter, a sampling
rate of 256 Hz, and we buffer the EEG data until we
have 8 samples of 16-channel EEG data, at which
point the data are transmitted to the laptop. We
use either g.BUTTERfly or g.LADYbird active elec-
trodes, a g.GAMMA cap, and the g.GAMMAsys ac-
tive electrode system.
The output of the amplifier is fed to the laptop via
a USB connection with a delay that is both highly
variable and unknown a priori. Consequently, we
are unable to rely on the laptop system clock in or-
der to synchronize the EEG data and the onset of
the visual stimuli. Instead, synchronization between
the EEG data and the visual stimuli is provided by
sending a parallel port trigger, via an express card-
to-parallel port adaptor, to one of the digital inputs
of the amplifier, which is then digitized along with
the EEG data. The parallel port to g.tec cable was
custom-built by Cortech Solutions, Inc. (Wilming-
ton, North Carolina, USA). The parallel port trigger
is sent immediately after the laptop monitor sends
the vertical retrace signal. The mean and the stan-
</bodyText>
<footnote confidence="0.751721">
3http://psychtoolbox.org/wikka.php?wakka=HomePage
</footnote>
<bodyText confidence="0.99818025">
dard deviation of the delay needed to trigger the par-
allel port has been measured to be on the order of
tens of microseconds, which should be sufficiently
small for our purposes.
</bodyText>
<sectionHeader confidence="0.999888" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.967206903225806">
Here we report data collected from 2 subjects, one
of whom is a LIS subject with very limited experi-
ence using our BCI system, and the other a healthy
subject with extensive experience using our BCI sys-
tem. The symbol duration was set to 400 ms, the
duty cycle was set to 50%, and the maximum num-
ber of sequences per trial was set to 6. Before test-
ing, the classifier of our system was trained on data
obtained as each subject viewed 50 symbols with 3
sequences per epoch (the classifier was trained once
for the LIS subject and once for the healthy sub-
ject). The healthy subject was specifically instructed
to neither move nor blink their eyes, to the extent
possible, while the symbols are being flashed on the
screen in front of them. Instead, they were to wait
until the rest period, which occurs after each epoch,
to move or to blink. The subjects were free to pro-
duce whatever text they wished. The only require-
ment given to them concerning the chosen text was
that they must not, at any point in the experiment,
change what they are planning to type and they must
correct all mistakes using the backspace symbol.
Figure 7 shows the results for the non-expert,
LIS subject. A total of 10 symbols were correctly
typed by this subject, who had chosen to spell,
“THE STEELERS ARE GOING TO ...”. Notice
that the number of sequences shown exceeds the
maximum value of 6 for 3 of the symbols. This
occurs when the specified letter is mistyped one or
more times. For example, for each mistyped non-
backspace symbol, a backspace is required to delete
</bodyText>
<page confidence="0.998504">
42
</page>
<figureCaption confidence="0.9761775">
Figure 7: Number of sequences to reach the confidence thresh-
old for the non-expert, LIS subject.
Figure 8: Number of sequences to reach the confidence thresh-
old for the expert, healthy subject.
</figureCaption>
<bodyText confidence="0.999458939393939">
the incorrect symbol. Likewise, if a backspace sym-
bol is detected although it was not the symbol that
the subject wished to type, then the correct symbol
must be retyped. As shown in the figure, the mean
number of sequences for each correctly-typed sym-
bol is 14.4 and the mean number of sequences per
symbol is 5.1 (the latter of which has a maximum
value of 6 in this case).
Figure 8 shows the result for the expert, healthy
subject. A total of 20 symbols were cor-
rectly typed by this subject, who had chosen to
spell, “THE LAKERS ARE IN FIRST PLACE”.
The mean number of sequences for each correctly-
typed symbol for this subject is 1.4 and the mean
number of sequences per symbol is also 1.4. Notice
that in 15 out of 20 epochs the classifier was able to
detect the intended symbol on the first epoch, which
corresponds to a single-trial presentation of the sym-
bols, and no mistakes were made for any of the 20
symbols.
There are two obvious explanations as to why the
healthy subject performed better than the LIS sub-
ject. First, it is possible that the healthy subject was
using a non-neural signal, perhaps an electromyo-
graphic (EMG) signal stemming from an unintended
muscle movement occurring synchronously with the
target onset. Second, it is also possible that the LIS
subject needs more training in order to learn how
to control the system. We believe the second ex-
planation is correct and are currently taking steps
to make sure the LIS subject has additional time to
train on our system in hopes of resolving this ques-
tion quickly.
</bodyText>
<sectionHeader confidence="0.997385" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999876666666667">
This work is supported by NSF under grants
ECCS0929576, ECCS0934506, IIS0934509,
IIS0914808, BCS1027724 and by NIH under grant
1R01DC009834-01. The opinions presented here
are those of the authors and do not necessarily
reflect the opinions of the funding agencies.
</bodyText>
<sectionHeader confidence="0.99892" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999467361111111">
J.-D. Bauby. 1997. The Diving Bell and the Butterfly.
Knopf, New York.
R.O. Duda, P.E. Hart, and D.G. Stork. 2001. Pattern
classification. Citeseer.
L.A. Farwell and E. Donchin. 1988. Talking off the
top of your head: toward a mental prosthesis utiliz-
ing event-related brain potentials. Electroenceph Clin.
Neurophysiol., 70:510–523.
J.H. Friedman. 1989. Regularized discriminant analy-
sis. Journal of the American statistical association,
84(405):165–175.
G. Pfurtscheller, C. Neuper, C. Guger, W. Harkam,
H. Ramoser, A. Schlogl, B. Obermaier, and M. Pre-
genzer. 2000. Current trends in Graz brain-computer
interface (BCI) research. IEEE Transactions on Reha-
bilitation Engineering, 8(2):216–219.
B. Roark, J. de Villiers, C. Gibbons, and M. Fried-Oken.
2010. Scanning methods and language modeling for
binary switch typing. In Proceedings of the NAACL
HLT 2010 Workshop on Speech and Language Pro-
cessing for Assistive Technologies, pages 28–36.
H. Serby, E. Yom-Tov, and G.F. Inbar. 2005. An im-
proved P300-based brain-computer interface. Neural
Systems and Rehabilitation Engineering, IEEE Trans-
actions on, 13(1):89–98.
M.S. Treder and B. Blankertz. 2010. (C) overt atten-
tion and visual speller design in an ERP-based brain-
computer interface. Behavioral and Brain Functions,
6(1):28.
J.R. Wolpaw, N. Birbaumer, D.J. McFarland,
G. Pfurtscheller, and T.M. Vaughan. 2002. Brain-
computer interfaces for communication and control.
Clinical neurophysiology, 113(6):767–791.
J.R. Wolpaw. 2007. Brain–computer interfaces as new
brain output pathways. The Journal of Physiology,
579(3):613.
</reference>
<figure confidence="0.9961735">
THE _STEEL E
45
40
25
20
35
30
15
10
5
0
Mean = 144/10 = 14.4 (seq/desired symbol)
Mean = 5.1 (seq/symbol)
THE _LAKERS _ARE _ I N _ F I
No. of sequences to reach confidence threshold
45
40
25
20
35
30
15
10
5
0
Mean = 28/20 = 1.4 (seq/desired symbol)
Mean = 1.4 (seq/symbol)
No. of sequences to reach confidence threshold
</figure>
<page confidence="0.998883">
43
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.888659">
<title confidence="0.9975575">An ERP-based Brain-Computer Interface for text using Rapid Serial Visual Presentation and Language Modeling</title>
<author confidence="0.940289">U D B B S H M</author>
<affiliation confidence="0.955582">Health and Science University Systems Lab, Northeastern University</affiliation>
<abstract confidence="0.998390157894737">Event related potentials (ERP) corresponding to stimuli in electroencephalography (EEG) can be used to detect the intent of a person for brain computer interfaces (BCI). This paradigm is widely used to build letter-byletter text input systems using BCI. Nevertheless using a BCI-typewriter depending only on EEG responses will not be sufficiently accurate for single-trial operation in general, and existing systems utilize many-trial schemes to achieve accuracy at the cost of speed. Hence incorporation of a language model based prior or additional evidence is vital to improve accuracy and speed. In this demonstration we will present a BCI system for typing that integrates a stochastic language model with ERP classification to achieve speedups, via the rapid serial visual presentation (RSVP) paradigm.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J-D Bauby</author>
</authors>
<title>The Diving Bell and the Butterfly.</title>
<date>1997</date>
<publisher>Knopf,</publisher>
<location>New York.</location>
<contexts>
<context position="4031" citStr="Bauby, 1997" startWordPosition="602" endWordPosition="603"> from locked-in syndrome (LIS). Locked-in syndrome can result from traumatic brain injury, such as a brainstem stroke1, or from neurodegenerative diseases such as amyotrophic lateral sclerosis (ALS or Lou Gehrig’s disease). The condition is characterized by near total paralysis, though the individuals are cognitively intact. While vision is retained, the motor control impairments extend to eye movements. Often the only reliable movement that can be made by 1Brain stem stroke was the cause of LIS for Jean-Dominique Bauby, who dictated his memoir The Diving Bell and the Butterfly via eyeblinks (Bauby, 1997). A B C D E F G H I J K L M N O P Q R S T U V W X Y Z 1 2 3 4 5 6 7 8 9 _ Figure 1: Spelling grid such as that used for the P300 speller (Farwell and Donchin, 1988). ‘ ’ denotes space. Proceedings of the ACL-HLT 2011 System Demonstrations, pages 38–43, Portland, Oregon, USA, 21 June 2011. c�2011 Association for Computational Linguistics Figure 2: RSVP scanning interface. an individual is a particular muscle twitch or single eye blink, if that. Such users have lost the voluntary motor control sufficient for such an interface. Relying on extensive visual scanning or complex gestural feedback fro</context>
</contexts>
<marker>Bauby, 1997</marker>
<rawString>J.-D. Bauby. 1997. The Diving Bell and the Butterfly. Knopf, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R O Duda</author>
<author>P E Hart</author>
<author>D G Stork</author>
</authors>
<date>2001</date>
<note>Pattern classification. Citeseer.</note>
<contexts>
<context position="11457" citStr="Duda et al., 2001" startWordPosition="1815" endWordPosition="1818">ied as E,(A) = (1 − A)E, + A�Σ, (1) where A is the shrinkage parameter, E, is the class covariance matrix estimated for class c E t0, 11, c = 0 corresponds to the non-target class, c = 1 corresponds to the target class, and Σ� is the weighted average of class covariance matrices. Regularization is administered as �Σ,(A, Y) = (1 − Y) �Σ,(A) + Ydtr[�Σ,(A)]I, (2) where Y is the regularization parameter, tr[·] is the trace function, and d is the dimension of the data vector. After carrying out the regularization and shrinkage on the estimated covariance matrices, the Bayesian classification rule (Duda et al., 2001) is applied by comparing the log-likelihood ratio (using 40 Figure 5: Timing of stimulus sequence presentation the posterior probability distributions) with a confidence threshold. The confidence threshold can be chosen so that the system incorporates the relative risks or costs of making an error for each class. The corresponding log-likelihood ratio is given by where µ, and �r, are the estimates of the class means and priors, respectively, x is the data vector to be classified, and fN(x; µ, Σ) is the pdf of a multivariate normal distribution. The set of visual stimuli (letters plus two extra</context>
</contexts>
<marker>Duda, Hart, Stork, 2001</marker>
<rawString>R.O. Duda, P.E. Hart, and D.G. Stork. 2001. Pattern classification. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L A Farwell</author>
<author>E Donchin</author>
</authors>
<title>Talking off the top of your head: toward a mental prosthesis utilizing event-related brain potentials.</title>
<date>1988</date>
<journal>Electroenceph Clin. Neurophysiol.,</journal>
<pages>70--510</pages>
<contexts>
<context position="4195" citStr="Farwell and Donchin, 1988" startWordPosition="652" endWordPosition="655">ases such as amyotrophic lateral sclerosis (ALS or Lou Gehrig’s disease). The condition is characterized by near total paralysis, though the individuals are cognitively intact. While vision is retained, the motor control impairments extend to eye movements. Often the only reliable movement that can be made by 1Brain stem stroke was the cause of LIS for Jean-Dominique Bauby, who dictated his memoir The Diving Bell and the Butterfly via eyeblinks (Bauby, 1997). A B C D E F G H I J K L M N O P Q R S T U V W X Y Z 1 2 3 4 5 6 7 8 9 _ Figure 1: Spelling grid such as that used for the P300 speller (Farwell and Donchin, 1988). ‘ ’ denotes space. Proceedings of the ACL-HLT 2011 System Demonstrations, pages 38–43, Portland, Oregon, USA, 21 June 2011. c�2011 Association for Computational Linguistics Figure 2: RSVP scanning interface. an individual is a particular muscle twitch or single eye blink, if that. Such users have lost the voluntary motor control sufficient for such an interface. Relying on extensive visual scanning or complex gestural feedback from the user renders a typing interface difficult or impossible to use for the most impaired users. Simpler interactions via brain-computer interfaces (BCI) hold much</context>
</contexts>
<marker>Farwell, Donchin, 1988</marker>
<rawString>L.A. Farwell and E. Donchin. 1988. Talking off the top of your head: toward a mental prosthesis utilizing event-related brain potentials. Electroenceph Clin. Neurophysiol., 70:510–523.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J H Friedman</author>
</authors>
<title>Regularized discriminant analysis.</title>
<date>1989</date>
<journal>Journal of the American statistical association,</journal>
<volume>84</volume>
<issue>405</issue>
<contexts>
<context position="9023" citStr="Friedman, 1989" startWordPosition="1429" endWordPosition="1430">each EEG channel are incorporated and classified to determine the class label: ERP or non-ERP. Our system functions as follows. First, each channel is band-pass filtered. Second, each channel is temporally-windowed. Third, a linear dimension reduction (using principal components analysis) is learned using training data and is subsequently applied to the EEG data when the system is being used. Fourth, the data vectors obtained for each channel and a given stimulus are concatenated to create the data matrix corresponding to the specified stimulus. Fifth, Regularized Discriminant Analysis (RDA) (Friedman, 1989), which estimates conditional probability densities for each class using 39 Figure 3: Trial-averaged EEG data corresponding to the target response (top) and distractor response (bottom) for a 1 second window. Kernel Density Estimation (KDE), is used to determine a purely EEG-based classification discriminant score for each stimulus. Sixth, the conditional probability of each letter given the typed history is obtained from the language model. Seventh, Bayesian fusion (which assumes the EEG-based information and the language model information are statistically independent given the class label) </context>
</contexts>
<marker>Friedman, 1989</marker>
<rawString>J.H. Friedman. 1989. Regularized discriminant analysis. Journal of the American statistical association, 84(405):165–175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Pfurtscheller</author>
<author>C Neuper</author>
<author>C Guger</author>
<author>W Harkam</author>
<author>H Ramoser</author>
<author>A Schlogl</author>
<author>B Obermaier</author>
<author>M Pregenzer</author>
</authors>
<title>Current trends in Graz brain-computer interface (BCI) research.</title>
<date>2000</date>
<journal>IEEE Transactions on Rehabilitation Engineering,</journal>
<volume>8</volume>
<issue>2</issue>
<contexts>
<context position="1529" citStr="Pfurtscheller et al., 2000" startWordPosition="213" endWordPosition="216">guage model based prior or additional evidence is vital to improve accuracy and speed. In this demonstration we will present a BCI system for typing that integrates a stochastic language model with ERP classification to achieve speedups, via the rapid serial visual presentation (RSVP) paradigm. 1 Introduction There exist a considerable number of people with severe motor and speech disabilities. Brain computer interfaces (BCI) are a potential technology to create a novel communication environment for this population, especially persons with completely paralyzed voluntary muscles (Wolpaw, 2007; Pfurtscheller et al., 2000). One possible application of BCI is typing systems; specifically, those BCI systems that use electroencephalography (EEG) have been increasingly studied in the recent decades to enable the selection of letters for expressive language generation (Wolpaw, 2007; Pfurtscheller et al., 2000; Treder and Blankertz, 2010). However, the use of noninvasive techniques for letter-by-letter systems lacks efficiency due to low signal to noise ratio and variability of background brain activity. Therefore current BCI-spellers suffer from low symbol rates and researchers have turned to various hierarchical sy</context>
</contexts>
<marker>Pfurtscheller, Neuper, Guger, Harkam, Ramoser, Schlogl, Obermaier, Pregenzer, 2000</marker>
<rawString>G. Pfurtscheller, C. Neuper, C. Guger, W. Harkam, H. Ramoser, A. Schlogl, B. Obermaier, and M. Pregenzer. 2000. Current trends in Graz brain-computer interface (BCI) research. IEEE Transactions on Rehabilitation Engineering, 8(2):216–219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Roark</author>
<author>J de Villiers</author>
<author>C Gibbons</author>
<author>M Fried-Oken</author>
</authors>
<title>Scanning methods and language modeling for binary switch typing.</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACL HLT 2010 Workshop on Speech and Language Processing for Assistive Technologies,</booktitle>
<pages>28--36</pages>
<marker>Roark, de Villiers, Gibbons, Fried-Oken, 2010</marker>
<rawString>B. Roark, J. de Villiers, C. Gibbons, and M. Fried-Oken. 2010. Scanning methods and language modeling for binary switch typing. In Proceedings of the NAACL HLT 2010 Workshop on Speech and Language Processing for Assistive Technologies, pages 28–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Serby</author>
<author>E Yom-Tov</author>
<author>G F Inbar</author>
</authors>
<title>An improved P300-based brain-computer interface. Neural Systems and Rehabilitation Engineering,</title>
<date>2005</date>
<journal>IEEE Transactions on,</journal>
<volume>13</volume>
<issue>1</issue>
<contexts>
<context position="2186" citStr="Serby et al., 2005" startWordPosition="310" endWordPosition="313">ping systems; specifically, those BCI systems that use electroencephalography (EEG) have been increasingly studied in the recent decades to enable the selection of letters for expressive language generation (Wolpaw, 2007; Pfurtscheller et al., 2000; Treder and Blankertz, 2010). However, the use of noninvasive techniques for letter-by-letter systems lacks efficiency due to low signal to noise ratio and variability of background brain activity. Therefore current BCI-spellers suffer from low symbol rates and researchers have turned to various hierarchical symbol trees to achieve system speedups (Serby et al., 2005; Wolpaw et al., 2002; Treder and Blankertz, 2010). Slow throughput greatly diminishes the practical usability of such systems. Incorporation of a language model, which predicts the next letter using the previous letters, into the 38 decision-making process can greatly affect the performance of these systems by improving the accuracy and speed. As opposed to the matrix layout of the popular P300-Speller (Wolpaw, 2007), shown in Figure 1, or the hexagonal two-level hierarchy of the Berlin BCI (Treder and Blankertz, 2010), we utilize another well-established paradigm: rapid serial visual present</context>
</contexts>
<marker>Serby, Yom-Tov, Inbar, 2005</marker>
<rawString>H. Serby, E. Yom-Tov, and G.F. Inbar. 2005. An improved P300-based brain-computer interface. Neural Systems and Rehabilitation Engineering, IEEE Transactions on, 13(1):89–98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M S Treder</author>
<author>B Blankertz</author>
</authors>
<title>(C) overt attention and visual speller design in an ERP-based braincomputer interface.</title>
<date>2010</date>
<journal>Behavioral and Brain Functions,</journal>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="1845" citStr="Treder and Blankertz, 2010" startWordPosition="260" endWordPosition="263"> exist a considerable number of people with severe motor and speech disabilities. Brain computer interfaces (BCI) are a potential technology to create a novel communication environment for this population, especially persons with completely paralyzed voluntary muscles (Wolpaw, 2007; Pfurtscheller et al., 2000). One possible application of BCI is typing systems; specifically, those BCI systems that use electroencephalography (EEG) have been increasingly studied in the recent decades to enable the selection of letters for expressive language generation (Wolpaw, 2007; Pfurtscheller et al., 2000; Treder and Blankertz, 2010). However, the use of noninvasive techniques for letter-by-letter systems lacks efficiency due to low signal to noise ratio and variability of background brain activity. Therefore current BCI-spellers suffer from low symbol rates and researchers have turned to various hierarchical symbol trees to achieve system speedups (Serby et al., 2005; Wolpaw et al., 2002; Treder and Blankertz, 2010). Slow throughput greatly diminishes the practical usability of such systems. Incorporation of a language model, which predicts the next letter using the previous letters, into the 38 decision-making process c</context>
</contexts>
<marker>Treder, Blankertz, 2010</marker>
<rawString>M.S. Treder and B. Blankertz. 2010. (C) overt attention and visual speller design in an ERP-based braincomputer interface. Behavioral and Brain Functions, 6(1):28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Wolpaw</author>
<author>N Birbaumer</author>
<author>D J McFarland</author>
<author>G Pfurtscheller</author>
<author>T M Vaughan</author>
</authors>
<title>Braincomputer interfaces for communication and control. Clinical neurophysiology,</title>
<date>2002</date>
<pages>113--6</pages>
<contexts>
<context position="2207" citStr="Wolpaw et al., 2002" startWordPosition="314" endWordPosition="317">ically, those BCI systems that use electroencephalography (EEG) have been increasingly studied in the recent decades to enable the selection of letters for expressive language generation (Wolpaw, 2007; Pfurtscheller et al., 2000; Treder and Blankertz, 2010). However, the use of noninvasive techniques for letter-by-letter systems lacks efficiency due to low signal to noise ratio and variability of background brain activity. Therefore current BCI-spellers suffer from low symbol rates and researchers have turned to various hierarchical symbol trees to achieve system speedups (Serby et al., 2005; Wolpaw et al., 2002; Treder and Blankertz, 2010). Slow throughput greatly diminishes the practical usability of such systems. Incorporation of a language model, which predicts the next letter using the previous letters, into the 38 decision-making process can greatly affect the performance of these systems by improving the accuracy and speed. As opposed to the matrix layout of the popular P300-Speller (Wolpaw, 2007), shown in Figure 1, or the hexagonal two-level hierarchy of the Berlin BCI (Treder and Blankertz, 2010), we utilize another well-established paradigm: rapid serial visual presentation (RSVP), shown i</context>
</contexts>
<marker>Wolpaw, Birbaumer, McFarland, Pfurtscheller, Vaughan, 2002</marker>
<rawString>J.R. Wolpaw, N. Birbaumer, D.J. McFarland, G. Pfurtscheller, and T.M. Vaughan. 2002. Braincomputer interfaces for communication and control. Clinical neurophysiology, 113(6):767–791.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Wolpaw</author>
</authors>
<title>Brain–computer interfaces as new brain output pathways.</title>
<date>2007</date>
<journal>The Journal of Physiology,</journal>
<volume>579</volume>
<issue>3</issue>
<contexts>
<context position="1500" citStr="Wolpaw, 2007" startWordPosition="211" endWordPosition="212">ation of a language model based prior or additional evidence is vital to improve accuracy and speed. In this demonstration we will present a BCI system for typing that integrates a stochastic language model with ERP classification to achieve speedups, via the rapid serial visual presentation (RSVP) paradigm. 1 Introduction There exist a considerable number of people with severe motor and speech disabilities. Brain computer interfaces (BCI) are a potential technology to create a novel communication environment for this population, especially persons with completely paralyzed voluntary muscles (Wolpaw, 2007; Pfurtscheller et al., 2000). One possible application of BCI is typing systems; specifically, those BCI systems that use electroencephalography (EEG) have been increasingly studied in the recent decades to enable the selection of letters for expressive language generation (Wolpaw, 2007; Pfurtscheller et al., 2000; Treder and Blankertz, 2010). However, the use of noninvasive techniques for letter-by-letter systems lacks efficiency due to low signal to noise ratio and variability of background brain activity. Therefore current BCI-spellers suffer from low symbol rates and researchers have turn</context>
</contexts>
<marker>Wolpaw, 2007</marker>
<rawString>J.R. Wolpaw. 2007. Brain–computer interfaces as new brain output pathways. The Journal of Physiology, 579(3):613.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>