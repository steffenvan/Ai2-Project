<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.994721">
Minimally Supervised Morphological Analysis
by Multimodal Alignment
</title>
<author confidence="0.982574">
David Yarowsky and Richard Wicentowski
</author>
<affiliation confidence="0.9255585">
Department of Computer Science
Johns Hopkins University
</affiliation>
<address confidence="0.932146">
Baltimore, MD 21218
</address>
<email confidence="0.83741">
Email:{yarowsky,richardw}@cs . jhu.edu
</email>
<sectionHeader confidence="0.987422" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999913952380952">
This paper presents a corpus-based al-
gorithm capable of inducing inflectional
morphological analyses of both regu-
lar and highly irregular forms (such as
brought—xbring) from distributional pat-
terns in large monolingual text with
no direct supervision. The algorithm
combines four original alignment models
based on relative corpus frequency, con-
textual similarity, weighted string simi-
larity and incrementally retrained inflec-
tional transduction probabilities. Start-
ing with no paired &lt;inflection,root&gt; ex-
amples for training and no prior seeding
of legal morphological transformations,
accuracy of the induced analyses of 3888
past-tense test cases in English exceeds
99.2% for the set, with currently over
80% accuracy on the most highly irreg-
ular forms and 99.7% accuracy on forms
exhibiting non-concatenative suffixation.
</bodyText>
<sectionHeader confidence="0.985191" genericHeader="categories and subject descriptors">
1 Task Definition
</sectionHeader>
<bodyText confidence="0.999657666666666">
This paper presents an original and successful al-
gorithm for the nearly unsupervised induction of
inflectional morphological analyzers, with a focus
on highly irregular forms not typically handled by
other morphology induction algorithms. It is use-
ful to consider this task as three separate steps:
</bodyText>
<listItem confidence="0.8049952">
1) Estimate a probabilistic alignment between
inflected forms and root forms in a given lan-
guage
2) Train a supervised morphological analysis
learner on a weighted subset of these aligned
pairs.
3) Use the result of Step 2 as either a stand-
alone analyzer or a probabilistic scoring com-
ponent to iteratively refine the alignment in
Step 1.
</listItem>
<bodyText confidence="0.9998605">
The target output of Step 1 is an inflection-root
mapping such as shown in Table 1, with optional
columns giving the hypothesized stem change and
suffix analysis as well as part of speech.
</bodyText>
<table confidence="0.9915665">
ROOT STEM INFLECTION POS
CHANGE SUFFIX
take ake —&gt; ook +c took VBD
take e —&gt; c +ing taking VBG
take E —} E -ks takes VBZ
take e —&gt; c +en taken VBN
skip E —} p +ed skipped VBD
defy y —&gt; i +ed defied VBD
defy y —&gt; ie +s defies VBZ
defy E —} E +ing defying VBG
jugar gar —&gt; eg +a juega VPI3S
jugar gar —&gt; eg +an juegan VPI3P
jugar ar —&gt; c +amos jugamos VPI1P
tener ener —&gt; ien +en tienen VPI3P
</table>
<tableCaption confidence="0.999896">
Table 1: Target output (English and Spanish)
</tableCaption>
<bodyText confidence="0.999965266666667">
This suffix-focused transformational model is
not, as given, sufficient for languages with pre-
fixal, infixal and reduplicative morphologies. But
it is remarkably productive across Indo-European
languages in its current form and can be extended
to other affixational schema when appropriate.
For many applications, once the vocabulary list
achieves sufficiently broad coverage, this align-
ment table effectively becomes a morphologi-
cal analyzer simply by table lookup (indepen-
dent of necessary contextual ambiguity resolu-
tion). While the probabilistic analyzer trained
in Step 2 remains useful for previously unseen
words, such words are typically quite regular and
most of the difficult substance of the lemmatiza-
tion problem can often be captured by a large
root+Posinflection mapping table and a sim-
ple transducer to handle residual forms. This is
not the case for agglutinative languages such as
Turkish or Finnish, or for very highly inflected
languages such as Czech, where sparse data be-
comes an issue. But for many languages, and to a
quite practical degree, inflectional morphological
analysis and generation can be viewed primarily
as an alignment task on a broad coverage wordlist.
Thus, while this paper will discuss our imple-
mentation of a stand-alone probabilistic analyzer
and retraining process in Steps 2 and 3, the chal-
lenge of large-coverage inflection-root alignment
expressed in Step 1 is the core of this work.
</bodyText>
<subsectionHeader confidence="0.87832">
1.1 Required and Optional Resources
</subsectionHeader>
<bodyText confidence="0.798568454545455">
In further clarification of the task description, the
morphological induction described in this paper
assumes, and is based on, only the following lim-
ited set of (often optional) available resources:
(a) A table (such as Table 2) of the inflectional
parts of speech of the given language, along
with a list of the canonical suffixes for each
part of speech. These suffixes not only serve
as mnemonic tags for the POS labels, but
they can also be used to obtain a noisy set of
candidate examples for each part of speech.&apos;
</bodyText>
<listItem confidence="0.9991248">
(b) A large unannotated text corpus.
(c) A list of the candidate noun, verb and adjec-
tive roots of the language (typically obtain-
able from a dictionary), and any rough mech-
anism for identifying the candidate parts of
speech of the remaining vocabulary based on
aggregate models of context or tag sequence,
not morphological analysis. Our concurrent
work (Cucerzan and Yarowsky, 2000) focuses
on the problem of bootstrapping approxi-
mate tag probability distributions by mod-
elling relative word-form occurrence proba-
bilities across indicative lexical contexts (e.g.
&amp;quot;the &lt;NOUN&gt; are&amp;quot; and &amp;quot;been &lt;VBG&gt; the&amp;quot;),
among other predictive variables, with the
goal of co-training with the models presented
here. It is not necessary to select the part of
speech of a word in any given context, only
provide an estimate of the candidate tag dis-
tributions across a full corpus. The source of
these candidate tag estimates is unimportant,
however, and the lists can be quite noisy.
Their major function is to partially limit the
potential alignment space from unrestricted
word-to-word alignments across the entire vo-
cabulary.
(d) The current implementation assumes a list of
the consonants and vowels of the language.
(e) While not essential to the execution of the
algorithm, a list of common function words of
</listItem>
<footnote confidence="0.945685666666667">
&apos;The lists need not be exhaustive, and any missing
irregular suffixes (e.g. the English past tense +t) can
be captured via a stem change and null suffix (e.g.
</footnote>
<figureCaption confidence="0.294676">
send: d—&gt;t +c sent), similar to the representation
of take: ake—&gt;ook +c took).
</figureCaption>
<bodyText confidence="0.994971857142857">
the given language is useful to the extraction
of context similarity features.
(f) If available, the various distance/similarity
tables generated by this algorithm on previ-
ously studied languages can be useful as seed
information, especially if these languages are
closely related (e.g. Spanish and Italian).
</bodyText>
<sectionHeader confidence="0.998717" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999886177777778">
There is a rich tradition of supervised and un-
supervised learning in the domain of morphol-
ogy. Rumelhart and McClelland (1986), Egedi
and Sproat (1988), Ling (1994) and Mooney and
Calif (1995) have each investigated the supervised
learning of the English past tense from paired
training data, the first two using phonologically-
based connectionist models and the latter two
performing comparative studies with ID3 decision
trees and first-order decision lists respectively.
Brent (1993, 1999), de Marcken (1995), Kaza-
kov (1997) and Goldsmith (2000) have each fo-
cused on the problem of unsupervised learning of
morphological systems as essentially a segmenta-
tion task, yielding a morphologically plausible and
statistically motivated partition of stems and af-
fixes. Brent and de Marcken both have used a
minimum description length framework, with the
primary goal of inducing lexemes from bound-
aryless speech-like streams. Goldsmith specif-
ically sought to induce suffix paradigm classes
(e.g. NULL . ed. ing vs. e. ed. ing vs. e. ed. es .ing
vs. ted.tion) from raw text. However, handling
of irregular words was largely excluded from this
work, as Goldsmith assumed a strictly concatena-
tive morphology without models for stem changes.
Morphology induction in agglutenative lan-
guages such as Turkish and Finnish presents a
problem similar to parsing or segmenting a sen-
tence, given the long strings of affixations allowed
and the relatively free affix order. Voutilainen
(1995) has approached this problem in a finite-
state framework, and Hakkani-Thr et al. (2000)
have done so using a trigram tagger, with the as-
sumption of a concatenative affixation model.
The two-level model of morphology (Kosken-
niemi, 1983) has been extremely successful in
manually capturing the morphological processes
of the world&apos;s languages. The context sensi-
tive stem-change models used in this current pa-
per have been partially inspired by this frame-
work. For example, a two-level equivalent cap-
turing happy + er = happier is y:i &lt;=&gt; p:p _, quite
similar in spirit and function to our probabilis-
tic model P(y—xil...app, +er). Theron and Cloete
</bodyText>
<equation confidence="0.478928">
English :
Spanish:
</equation>
<table confidence="0.998421166666667">
Part of Speech VB VBD VBZ VBG VBN
Canonical +c +ed +s +ing +en
Suffixes (+t) +ed
+c (+t)
+c
Examples jump jumped jumps jumping jumped
(not used in announce announced announces announcing announced
training) take took takes taking taken
Part of Speech VRoot VPIls VPI2s VPI3s VPIlp VPI2p VPI3p
Canonical +ar +0 +as +a +amos +ads +an
Suffixes +er +es +e +emos +eis +en
+ir +imos +is
</table>
<tableCaption confidence="0.999731">
Table 2: Example parts of speech and their associated canonical suffixes in English and Spanish
</tableCaption>
<bodyText confidence="0.993809708333333">
(1997) sought to learn a 2-level rule set for En-
glish, Xhosa and Afrikaans by supervision from
0(4000) aligned inflection-root pairs extracted
from dictionaries. Single character insertion and
deletions were allowed, and the learned rules sup-
ported both prefixation and suffixation. Their su-
pervised learning approach could be applied di-
rectly to the aligned pairs induced in this paper.
Finally, Oflazer and Nirenburg (1999) have de-
veloped a framework to learn two-level morpho-
logical analyzers from interactive supervision in
a Elicit-Build-Test loop under the Boas project.
Humans provide as-needed feedback regarding er-
rors and omissions. Recently applied to Polish,
the model also assumes concatenative morphol-
ogy and treats non-concatenative irregular forms
through table lookup.
Thus there is a notable gap in the research
literature for induction of analyzers for irregu-
lar morphological processes, including significant
stem changing. The algorithm described below
directly addresses this gap, while successfully in-
ducing more regular analyses without supervision
as well.
</bodyText>
<sectionHeader confidence="0.7268125" genericHeader="method">
3 Lemma Alignment by Frequency
Similarity
</sectionHeader>
<bodyText confidence="0.999400095238095">
The motivating dilemma behind our approach to
morphological alignment is the question of how
one determines that the past tense of sing is sang
and not singed. The pairing sing—x singed requires
only simple concatenation with the canonical suf-
fix, +ed, and singed is indeed a legal word in our
vocabulary (the past tense of singe). And while
few irregular verbs have a true word occupying the
slot that would be generated by a regular mor-
phological rule, a large corpus is filled with many
spelling mistakes or dysfluencies such as taked (ob-
served with a frequency of 1), and such errors can
wreak havoc in naïve alignment-based methods.
How can we overcome this problem? Rel-
ative corpus frequency is one useful evidence
source. Observe in Table 3 that in an 80 mil-
lion word collection of newswire text the relative
frequency distribution of sang/sing is 1427/1204
(or 1.19/1), which indicates a reasonably close
frequency match, while the singed/sing ratio is
0.007/1, a substantial disparity.
</bodyText>
<table confidence="0.991739625">
VBD:VB vvBBD 1 VvB
BD )
0 g (
sang/sing 1427/1204 1.19 0.17
singed/sing 9/1204 0.007 -4.90
singed/singe 9/2 4.5 1.50
sang/singe 1427/9 158.5 5.06
All VBD/VB .85 -0.16
</table>
<tableCaption confidence="0.999792">
Table 3: Example inflection-root frequency ratios
</tableCaption>
<bodyText confidence="0.999890578947369">
However, simply looking for close relative fre-
quencies between an inflection and its candidate
root is inappropriate, given that some inflections
are relatively rare and expected to occur much less
frequently than the root form.
Thus in order to be able to rank the sang/sing
and singed/sing candidates effectively, it is nec-
essary to be able to quantify how well each fits
(or deviates from) expected frequency distribu-
tions. To do so, we use simple non-parametric
statistics to calculate the probability of a particu-
larvBD ratio by examining how frequently other
such ratios in a similar range have been seen in
the corpus. Figure 1 illustrates such a histogram
(based on the log of the ratios to focus more at-
tention on the extrema). The histogram is then
smoothed and normalized as an approximation of
the probability density function for this estimator
( g ( vvBBD ) ) which we can then use to quantify
</bodyText>
<subsubsectionHeader confidence="0.433421">
vvBBD
</subsubsectionHeader>
<bodyText confidence="0.996737666666667">
to what extent a given candidate log( ) such
as /og(sang/sing)=.17, fits our empirically moti-
vated expectations. The relative position of the
candidate pairings on the graph suggests that this
estimator is indeed informative given the task of
ranking potential root-inflection pairings.
However, estimating these distributions
presents a problem given that the true alignments
(and hence frequency ratios) between inflections
</bodyText>
<figure confidence="0.997980710144928">
0.3
0.25
sang/sing (0.17)
singed/singe (1.5)
singed/sing (-4.9)
taked/take(-10.5)
10
-10 -5 0 5
log(VBD/VB)
0.25
took/taking (0.6)
sang/singing (1.0)
0.2
0.15
singed/singeing (2.2)
0.1
0.05
sang/singeing(7.3)
taked/taking (-9.5)
singed/singing (-5)
0
took/take (-0.35)
sang/singe (5.1)
0.2
0.15
0.1
0.05
0
-12 -10 -8 -6 -4 -2 0 2 4 6 8 10
log(VBD/VBG)
0
-6 -4 -2 0 2 4 6 8
log(VBD/VB)
Regular Verbs
Irregular Verbs
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0
-10 -9 -8 -7 -6 -5 -4 -3 -2 -1 0 1
log(VBD|LF-VBD)
0.3
0.25
juegan/jugar (-0.4)
0.2
0.15
0.1
0.05
juegan/juzgar (2.3)
juegan/juntar (3.9)
juegan/jogar(4.8)
0
-8 -6 -4 -2 0 2 4 6
log(VPI3P/VINF)
5 Lemma Alignment by Weighted
Levenshtein Distance
</figure>
<bodyText confidence="0.942669210526316">
The third alignment similarity function considers
overall stem edit distance using a weighted Leven-
shtein measure. In morphological systems world-
wide, vowels and vowel clusters are relatively mu-
table through morphological processes, while con-
sonants generally tend to have a lower probability
of change during inflection. Rather than treating
all string edits as equal, a cost matrix of the form
shown in Table 6 is utilized, with initial distance
costs 61=v-v, 62=v+-v+, 63=c- c and 64=c-v+,
initially set to (0.5, 0.6, 1.0, 0.98), a relatively ar-
bitrary assignment reflecting this tendency. How-
ever, as subsequent algorithm iterations proceed,
this matrix is re-estimated with empirically ob-
served character-to-character stem-change proba-
bilities from the algorithm&apos;s current best weighted
alignments.
a o ue m n ...
a 0 61. 62 64 64 •••
</bodyText>
<table confidence="0.9732086">
o 61 0 62 64 64 ...
ue 62 62 0 64 64 .••
m 64 64 64 0 63 .••
n 64 64 64 63 0 ...
... ••• ••• ••• ••• ••• •••
</table>
<tableCaption confidence="0.995768">
Table 6: Initial Levenshtein cost matrix
</tableCaption>
<bodyText confidence="0.999877888888889">
More optimally, the initial state of this ma-
trix could be seeded with values partially bor-
rowed from previously trained matrices from other
related languages. Alternately, the initial dis-
tances could be set partially sensitive to phonolog-
ical similarities, with dist(/d/,/t/) &lt; dist(/d/,/f/)
for example, although this particular distinction
emerges readily via iterative re-estimation from
the baseline model.
</bodyText>
<sectionHeader confidence="0.658425333333333" genericHeader="method">
6 Lemma Alignment by
Morphological Transformation
Probabilities
</sectionHeader>
<bodyText confidence="0.999826117647059">
The goal of this research is not only to extract an
accurate table of inflection-root alignments, but
also to generalize this mapping function via a gen-
erative probabilistic model. The following section
describes the creation of this model, as well as how
the context-sensitive probability of each morpho-
logical transformation can be used as the fourth
alignment similarity measure.
At each iteration of the algorithm, this prob-
abilistic mapping function is trained on the ta-
ble output of the previous iteration, equivalent to
the information in Table 1 (e.g. &lt;root,inflection&gt;
pairs with optional part-of-speech tags, confidence
scores and stemchange+suffix analysis) .6 From
this output, we cluster the observed stem changes
by the variable-length root context in which they
were applied, as illustrated in Table 7.
</bodyText>
<table confidence="0.99793585">
Root Stem Suffix Count Matching
Context Change Examples
..ray c —&gt; c +ed 5 spray, stray,...
...ay c —&gt; c +ed 13 play, spray,...
...oy c —&gt; c +ed 3 annoy, enjoy,...
...ey c —&gt; c +ed 5 obey, key,...
...fy y —&gt; i +ed 21 beautify,...
...ry y —&gt; i +ed 7 carry,...
...dy y —&gt; i +ed 4 bloody,...
...y y —&gt; i +ed 43 carry,...
...y c —&gt; c +ed 21 spray,...
...y c —&gt; c +ing 83 carry, spray,...
...e e —&gt; c +ed 728 dance,...
...e e —&gt; c +ing 783 dance, take,...
...e c —&gt; c +ing 1 singe
...ke ake —&gt; ook +c 3 take, shake,...
...ke ake —&gt; oke +c 1 wake
...ke ke —&gt; de +c 1 make
...ay y —&gt; id +c 2 lay, pay
...y y —&gt; id +c 2 lay, pay
</table>
<tableCaption confidence="0.998006">
Table 7: Stem change data given root context
</tableCaption>
<bodyText confidence="0.969845833333333">
First note that because the triple of &lt;root&gt;
+ &lt;stemchange&gt; + &lt;suffix&gt; uniquely deter-
mines a resulting inflection, one can effectively
compute P(inflection I root, suffix, POS) by
P(stemchange I root, suffix, POS), i.e. for
any root=-ya, suffix=+o- and inflection=-0a,
</bodyText>
<equation confidence="0.930169">
P(-00-1-Ya,
+o-, POS) = P(ct +o-,POS).
</equation>
<bodyText confidence="0.999943571428571">
Using statistics such as shown in Table 7, it is
thus possible to compute the generation (or align-
ment) probability for an inflection given root and
suffix using the simple interpolated backoff model
in (1) where Ai is a function of the relative sam-
ple size of the conditioning event, and lastk(root)
indicates the final k characters of the root.
</bodyText>
<equation confidence="0.9974355">
P( inflection I root, suffix, POS)
= P( a —&gt; 0 I root, suffix, POS)
AiP( CE —&gt; 0 I tast3(root), suffix, POS)
± (1 — Ai)(A2P( CE —&gt; 0 I last2(root), suffix, POS)
± (1 — A2)(A3P( a —&gt; 0 I lasti (root), suffix, POS)
± (1 — A3)(A4P( a —&gt; 0 I suffix, POS)
+ (I — A4)P( a —&gt; )
(1)
</equation>
<bodyText confidence="0.99762375">
We only backoff to the extent necessary. Fur-
thermore, note that for English (and most inflec-
tions in Spanish), the stem changes observed when
adding suffixes are independent of part of speech
</bodyText>
<footnote confidence="0.744885">
6If only the pairs are given, with no stem-
change+suffix analysis, this analysis can be generated
deterministically by removing the longest matching
canonical suffix from the inflection and generating the
minimal a —&gt; 3 ± a transformation capturing the re-
maining stem difference.
</footnote>
<bodyText confidence="0.99756825">
(i.e. +8 behaves the same on suffixation for both
nouns and verbs), so these probabilities can often
be further simplified by deleting the conditioning
variable POS, as illustrated in (2).
</bodyText>
<equation confidence="0.982745">
P( solidified I solidify, +ed, VBD)
= P( y—&gt;i I solidify, +ed, VBD)
P( I solidify, +ed)
AiP( y—&gt;i I ify, +ed)
± (1 — Ai)(A2P( 3r—&gt;i I fY, +ed)
+ (1 — A2)(A3P( y, +ed)
+ (1 — A3)(A4P( +ed)
+ (1 — A4)P( )
</equation>
<bodyText confidence="0.99780515">
We have further generalized these variable-
length context models via a full hierarchically-
smoothed trie architecture, allowing robust spe-
cialization to very long root contexts if sample
sizes are sufficient.
6.1 Baseline Model for Morphological
Transformation Probabilities
On the first iteration, no inflection/root pairs are
available for estimating the above models. As
prior knowledge is not available regarding a —x
stem-change probabilities, an assumption is made
that the cost of each is proportional to the pre-
viously described Levenshtein distance between a
and /3, with the cost of a change increasing geo-
metrically as the distance from the end of the root
increases. The rate of this cost increase ultimately
depends on the tendency of the language to allow
word-internal spelling changes (as in Spanish or
Arabic), or strongly favor changes at the point of
affixation (as in English).
</bodyText>
<subsectionHeader confidence="0.583857">
6.2 Model Improvement by Iterative
Re-estimation
</subsectionHeader>
<bodyText confidence="0.978128200000001">
The primary goal of iterative retraining is to re-
fine the core morphological transformation model,
which not only serves as one of the four similarity
models, but is also a primary deliverable of the
learning process.
As subsequent iterations proceed, the stem-
change probability models are retrained on the
output of the prior iteration, weighting each train-
ing example with its alignment confidence, and
filtering out a —x /3 changes without a minimum
level of support to help reduce noise. The final
stem-change probabilities then are an interpola-
tion with the trained model Pi and the initial
baseline (P0) model described in Section 6.1:
P( c —x 13 I root, suffix, POS)
= Ai P0( a —x /3 I suffix)
+ (1 — Ai) Pi( a —x /3 I root, suffix, POS)
The Levenshtein distance models are re-
estimated as observed in Section 5, while the con-
text similarity model can be improved through
better self-learned lemmatization of the modelled
context words.
7 Lemma Alignment by Model
Combination and the Pigeonhole
Principle
As shown empirically below, no single model is
sufficiently effective on its own. We applied tradi-
tional classifier combination techniques to merge
the four models&apos; scores, scaling each to achieve
compatible dynamic range. The Frequency, Lev-
enshtein and Context similarity models retain
equal relative weight as training proceeds, while
the Morphological Transformation (MorphTrans)
similarity model increases in relative weight as it
becomes better trained.
Table 8 demonstrates the combined measures in
action, showing the relative rankings of candidate
roots for the inflections took, shook and juegan by
the four similarity models after the first iteration
(in Columns 2-4). The overall consensus similar-
ity measure at the end of Iteration 1 is shown in
Column 1.7
Note that even though only one of the four esti-
mators independently ranked shake as the most
likely root of shook, after only the first itera-
tion the consensus choice is correct. The fi-
nal column of Table 8 shows the retrained Mor-
phTrans similarity measure after convergence.
Based on training evidence from the confidently
aligned pairs took/take, shook/shake and under-
took/undertake from previous iterations, the prob-
ability of ake—xook has increased significantly, fur-
ther increasing the confidence in the overall align-
ments at convergence (not shown), but not chang-
ing the previously correct ranking in these cases.
The final alignment constraint that we pursued
was based on the pigeonhole principle. This prin-
ciple suggests that for a given part of speech, a
root should not have more than one inflection
nor should multiple inflections in the same part
of speech share the same root. There are, of
course, exceptions to this tendency, such as trav-
elled/traveled and dreamed! dreamt, which are ob-
served as variant forms of their respected roots.
71n addition to the consensus similarity score in
subcolumn 2, subcolumn 3 shows the average of the
ranks of the candidate root given the inflection and the
ranks of the candidate inflection given the root. This
bidirectional average ranking score favors cases where
attraction between root and inflection is mutual, and
disfavors cases where higher ranked competition exists
for a root&apos;s attentions, effectively capturing a weak
form of the pigeonhole principle. Thus it was used
as the primary ranking criteria (over raw similarity
score).
</bodyText>
<table confidence="0.859506307692308">
(2)
Candidate Roots for the English inflection TOOK (1st iteration):
Overall Similarity Context Frequency Levenshtein MorphTrans MorphTrans
(Iteration 1) Similarity Similarity Similarity Similarity (1) Similarity (C)
take .00162 3.8 1 take .849 take .072 toot .333 toot .002593 take .465578
turn .00081 8.7 2 turn .546 tell .028 tool .333 tool .002593 toot .001296
tell .00063 15.9 3 tower .332 turn .016 toe .310 tong .000096 tool .001296
test .00041 19.6 4 touch .324 talk .014 take .290 tone .000096 tong .000048
talk .00051 21.0 5 tip .261 test .001 top .236 ... ... tone .000048
tie .00044 26.7 6 tie .260 teach .001 toil .236 take .000006 tout .000048
Candidate Roots for the English inflection SHOOK (1st iteration):
Overall Similarity Context Frequency Levenshtein MorphTrans MorphTrans
(Iteration 1) Similarity Similarity Similarity Similarity (1) Similarity (C)
</table>
<bodyText confidence="0.755576857142857">
shake .00149 5.5 1 shake .854 share .073 shoo .500 shoot .002593 shake .465578
shoot .00126 9.3 2 shave .323 ship .068 shoot .333 shoo .002593 shoot .001296
ship .00104 16.3 3 shape .210 shift .062 shoe .310 shock .000096 shoo .001296
shatter .00061 18.9 4 shore .194 shop .060 shake .290 short .000096 shock .000048
shop .00094 19.8 5 shower .184 shake .058 shop .236 shout .000095 short .000048
shut .00081 20.6 6 shoot .162 shut .052 shout .236 ... ... shove .000048
shun .00039 20.7 7 shock .154 shoot .051 show .236 shake .000003 shore .000048
</bodyText>
<footnote confidence="0.337542">
Candidate Roots for the Spanish inflection JUEGAN (1st iteration)
</footnote>
<table confidence="0.99633175">
jugar .0024 1 jugar .88 jugar .063 jugar .50 jugar .00129
juzgar .0006 2 juntar .38 juzgar .015 juzgar .29 jogar .00129
jurar .0002 4 jurar .26 jogar .009 juntar .25 juntar .00004
jogar .0000 5 justificar .22 juntar .004 jurar .18 juzgar .00004
</table>
<tableCaption confidence="0.999778">
Table 8: Example performance of independent and combined similarity measures
</tableCaption>
<figure confidence="0.991296">
Overall Similarity
(Iteration 1)
Context
Similarity
Frequency
Similarity
Levenshtein
Similarity
MorphTrans
Similarity (1)
</figure>
<bodyText confidence="0.999704266666667">
The extent to which such overlaps should be pe-
nalized depends on the probability of seeing vari-
ant inflections in the morphology, but for Spanish
and English this is relatively low.
We exploited the pigeonhole principle in two
ways simultaneously. The first is a greedy algo-
rithm, in which candidates are aligned in order
of decreasing score, and when the the first-choice
root for a given inflection has already been taken
by another inflection of the same part of speech,
the algorithm continues until a free slot is found.
The exception is when the highest ranking free
form is several orders of magnitude lower than the
first choice; here the first-choice alignment is as-
sumed to be correct, but a variant form.
</bodyText>
<sectionHeader confidence="0.977942" genericHeader="method">
8 Empirical Evaluation
</sectionHeader>
<bodyText confidence="0.999856702702703">
Current empirical evaluation of this work focuses
on its accuracy in analyzing the often highly ir-
regular past tense of English verbs. Consistent
with prior empirical studies in this field, evalua-
tion was performed on a test set of 3888 inflected
words, including 128 highly irregular inflections,
1877 cases where the past tense was formed by
simple concatenative suffixation, and 1883 inflec-
tions exhibiting a non-concatenative stem change
such as gemination or elision.
In execution, for each test inflected form, the
analysis algorithm was free to consider alignment
to any word in the corpus which had been identi-
fied as a potential root verb by the part-of-speech
tagging process or occurrence in a dictionary-
derived rootlist, not just those roots in the test set.
It is thus a more challenging evaluation than test-
ing simple alignment accuracy between two clean
and extraneous-entry-free wordlists.
Table 9 shows the performance of several of the
investigated similarity measures. Frequency simi-
larity (FS), enhanced Levenshtein (LS), and Con-
text similarity (CS) alone achieve only 10%, 31%
and 28% overall accuracy respectively. However,
the hypothesis that these measures model inde-
pendent and complementary evidence sources is
supported by the roughly additive combined ac-
curacy of 71.6%.8
The final performance of the full converged
CS+FS+LS+MS model at 99.2% accuracy on the
full test set, and 99.7% accuracy on inflections re-
quiring analysis beyond simple concatenative suf-
fixation, is quite remarkable given that the algo-
rithm had absolutely no &lt;inflection,root&gt; exam-
ples as training data, and had no prior inventory
of stem changes available, with only a slight sta-
tistical bias in favor of shorter stem changes with
</bodyText>
<footnote confidence="0.99821425">
8In fact, in many cases the consensus ranking
choice is correct when each independent model&apos;s first
choice is wrong, actually yielding a small synergistic
super additivity.
</footnote>
<table confidence="0.9880049">
Combination # of All Highly Simple Non-
of Similarity Iter- Words Irregular Concat. Concat.
Models ations (3888) (128) (1877) (1883)
FS (Frequency Sim) (Iter 1) 9.8 18.6 8.8 10.1
LS (Levenshtein Sim) (Iter 1) 31.3 19.6 20.0 34.4
CS (Context Sim) (Iter 1) 28.0 32.8 30.0 25.8
CS+FS (Iter 1) 32.5 64.8 32.0 30.7
CS+FS+LS (Iter 1) 71.6 76.5 71.1 71.9
CS+FS+LS+MS (Iter 1) 96.5 74.0 97.3 97.4
CS+FS+LS+MS (Convg) 99.2 80.4 99.9 99.7
</table>
<tableCaption confidence="0.999762">
Table 9: Performance of combined alignment models on 4 classes of past-tense English verbs
</tableCaption>
<bodyText confidence="0.977279075471698">
smaller Levenshtein distance, and with the mini-
mal search-simplifying assumption in all the mod-
els that candidate alignments must begin with a
the same VC * prefix.9
Given a starting point where all single charac-
ter X-+17 changes at the point of suffixation are
equally likely, the processes of elison (e-+e), gemi-
nation (e.g. E-xd in the context of d), and y-xi
shift (in the context of a preceding consonant,
not vowel) all emerge by the end of the first it-
eration with high probability in their appropriate
contexts, and low probability elsewhere.
Table 10 shows how each of the models perform
on a randomly-selected 30% of the highly irregu-
lar forms, with correctly selected roots identified
in bold. The residual errors are primarily of three
types: Two inflections, went and ate, were not
alignable with their correct roots due to differ-
ent first character. The largest class of errors are
due to the pigeonhole principle strongly disfavor-
ing two inflections from sharing the same root.10
9To put the Table 9 results in perspective, Mooney
and Calif (1995) achieved 82.5% overall accuracy us-
ing a fully supervised decision list learner trained on
250 paired past-tense/root verb pairs (in plain text
form). Although they don&apos;t breakdown this perfor-
mance by word type, their included FOILDL program
trained from 250 pairs and applied to our evaluation
set achieved 100% accuracy on the pairs with simple
+ed concatenation, 84% accuracy on stem changing
(non-concat) pairs and 5% accuracy on the highly ir-
regular pairs, with 89% overall accuracy. Other avail-
able supervised learning results (e.g. Ling; Rumelhart
and McClelland) are only given for phonological word
representations. While not directly comparable with
our text-based data, their performance is significantly
worse than Mooney and Calif&apos;s FOILDL on common
phonological paired data, suggesting that FOILDL is a
generally competitive reference point for our results.
19This was previously noted in the case of dream
dreamed and dreamt, or burned burned and burnt,
with the higher probability analysis typically occupy-
ing the root slot and the lower probability form typi-
cally forced to seek alignment elsewhere. Indeed, the
pigeonhole principle is the most problematic of all the
The remaining errors typically are due to sparse
statistics for the lower frequency irregular forms.
Mappings such as slew slay are particularly dif-
ficult because, with a corpus frequency of only 4,
there is too little data to estimate a good context
profile or an effectively discriminatory frequency
profile. Enlarging the raw corpus size should im-
prove performance in both of these cases.
</bodyText>
<sectionHeader confidence="0.990746" genericHeader="conclusions">
9 Conclusion
</sectionHeader>
<bodyText confidence="0.998992">
This paper has presented an original algorithm ca-
pable of inducing the accurate morphological anal-
ysis of even highly irregular verbs, starting with
no paired &lt;inflection,root&gt; examples for train-
ing and no prior seeding of legal morphological
transformations. It does so by treating morpho-
logical analysis predominantly as an alignment
task in a large corpus, performing the effective
collaboration of four original similarity measures
based on expected frequency distributions, con-
text, morphologically-weighted Levenshtein simi-
larity and an iteratively bootstrapped model of af-
fixation and stem-change probabilities. This con-
stitutes a significant achievement in that previ-
ous approaches to morphology acquisition have ei-
ther focused on unsupervised induction of quasi-
regular concatenative affixation, or handled irreg-
ular forms with fully supervised training. In con-
trast, this paper&apos;s essentially unsupervised algo-
rithm achieves over 80% accuracy on the most
highly irregular forms, and 99.7% accuracy on
analyses requiring some stem change, outperform-
ing Mooney and Califf&apos;s fully supervised learning
algorithm overall and on both of these measures.
alignment principles used, as it creates nearly as many
problems as it fixes. The overall performance advan-
tage is slightly in its favor (with 59 misalignments
avoided for 50 problems created), but the cost of this
approach is borne heavily by the irregular verbs, and
a probabilistic model of when variant forms should be
expected/allowed is necessary to fix these cases while
preserving the advantages of the principle in down-
weighting clashing analyses in the more regular verbs.
Test True (Convg) CS+FS+LS+MS (Itr 1) CS+FS+LS CS+FS LS only
Word Root Score (Itr 1) (Itr 1) (Itr 1)
got get go 1.30 go go go gut
knew know know 1.35 know know know know
took take take 1.50 take take take toot
blew blow blow 1.80 blow blow blow blow
became become become 2.35 become become become become
made make make 2.40 make make make mate
clung cling cling 2.55 cling cling cling cling
drew draw draw 2.65 draw draw draw draw
swore swear swear 2.80 swear swear swear store
wore wear wear 3.10 wear wear wear wire
came come come 3.55 come come come come
thought think think 3.60 think think think thump
flung fling fling 4.60 fling fling fling fling
brought bring bring 5.35 bring bring bring brighten
strove strive strive 5.85 strive strive straddle strive
stuck stick stick 6.00 stick stick stabilize stock
swept sweep sweep 6.20 sweep sweep sweep swap
shone shine shine 6.55 shine shine shine shine
woke wake wake 6.95 wake wake wind wake
clove cleave cleave 7.35 cleave cleave cleave close
bore bear bear 7.75 bear bar bear bare
meant mean mean 8.20 mean mean manage mount
lent lend lend 9.25 lend lend lend lend
slew slay slit 10.06 slit slight slight slow
struck strike strike 11.60 strike strike strike strut
bought buy buy 12.20 buy buy buy bound
bit bite bite 13.60 bite bite betray bet
dove dive dive 17.25 dive dive dash dive
burnt burn burp 17.30 burp burp burp burn
went go want 18.29 want want want want
caught catch catch 18.35 catch cut catch cough
dealt deal deal 21.45 deal deal disagree deal
</bodyText>
<tableCaption confidence="0.909042">
Table 10: Performance of 4 alignment models on 32 randomly selected highly irregular English verbs
</tableCaption>
<sectionHeader confidence="0.991587" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998334833333334">
M.R. Brent, 1993. Minimal generative models: A
middle ground between neurons and triggers. Pro-
ceedings of the 15th Annual Conference of the Cog-
nitive Science Society, pages 28-36.
M.R. Brent, 1999. An efficient, probabilistically
sound algorithm for segmentation and word discov-
ery. Machine Learning, 34, pages 71-106.
S. Cucerzan and D. Yarowsky, 2000. Language inde-
pendent minimally supervised induction of lexical
probabilities. Proceedings of ACL &apos;00, Hong Kong.
C. de Marcken, 1995. Unsupervised language acqui-
sition. PhD dissertation. MIT.
D. Egedi and R. Sproat, 1988. Connectionist Net-
works and Natural Language Morphology. UMD
Conf on Grammar and Language Processing.
J. Goldsmith, 2000. Unsupervised Learn-
ing of the Morphology of a Natural Language.
http://humanities.uchicago.edu/faculty/goldsmith/
Linguistica2000/Paper/paper.html.
D.Z. Hakkani-Tfir, K. Oflazer, G. Tfir, 2000. Statis-
tical Morphological Disambiguation for Agglutina-
tive Languages. In Proceedings of COLING 2000.
L. Karttunen, 1993. Finite state constraints. In John
Goldsmith (ed.) The Last Phonological Rule, pages
173-194. Chicago: University of Chicago Press.
D. Kazakov, 1997. Unsupervised learning of naive
morphology with genetic algorithms. ECML/Mlnet
Workshop on Empirical Learning of NLP Tasks.
K. Koskenniemi, 1983. A general computation model
for word-form recognition and production. Pub. 11,
Dept. of General Linguistics. Univ. of Helsinki.
C.X. Ling, 1994. Learning the past tense of English
verbs: The symbolic pattern associator vs. connec-
tionist models. J. Art. Intel. Res., 1:209-229.
R. Mooney and M. Califf, 1995. Induction of first-
order decision lists: Results on learning the past
tense of English verbs. J. Art. Intel. Res., 3:1-24.
K. Oflazer and S. Nirenburg, 1999. Practical boot-
strapping of morphological analyzers. Proceedings
of the Conference on Natural Language Learning.
D. Rumelhart and J. McClelland, 1986. On learn-
ing the past tense of English verbs. In J. McClel-
land, D. Rumelhart, and the PDP Research Group,
Parallel distributed processing: Explorations in the
microstructure of cognition, Volume 2. MIT Press.
P. Theron and I. Cloete, 1997. Automatic acquisition
of two-level morphological rules. Proceedings of the
Fifth Conference on Applied Natural Language Pro-
cessing, Washington, pages 103-110.
A. Voutilainen, 1995. Morphological disambiguation.
In F. Karlsson, A. Voutilainen, J. Heikkila, and A.
Anttila (eds.) Constraint grammar - A language
independent system for parsing unrestricted text,
pages 165-284. The Hague: Mouton de Gruyter.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9707045">Minimally Supervised Morphological Analysis by Multimodal Alignment</title>
<author confidence="0.999941">David Yarowsky</author>
<author confidence="0.999941">Richard Wicentowski</author>
<affiliation confidence="0.9995865">Department of Computer Science Johns Hopkins University</affiliation>
<address confidence="0.999917">Baltimore, MD 21218</address>
<email confidence="0.999827">jhu.edu</email>
<abstract confidence="0.998210784946236">This paper presents a corpus-based algorithm capable of inducing inflectional morphological analyses of both regular and highly irregular forms (such as brought—xbring) from distributional patterns in large monolingual text with no direct supervision. The algorithm combines four original alignment models based on relative corpus frequency, contextual similarity, weighted string similarity and incrementally retrained inflectional transduction probabilities. Starting with no paired &lt;inflection,root&gt; examples for training and no prior seeding of legal morphological transformations, accuracy of the induced analyses of 3888 past-tense test cases in English exceeds 99.2% for the set, with currently over 80% accuracy on the most highly irregular forms and 99.7% accuracy on forms exhibiting non-concatenative suffixation. 1 Task Definition This paper presents an original and successful algorithm for the nearly unsupervised induction of inflectional morphological analyzers, with a focus on highly irregular forms not typically handled by other morphology induction algorithms. It is useful to consider this task as three separate steps: 1) Estimate a probabilistic alignment between inflected forms and root forms in a given language 2) Train a supervised morphological analysis learner on a weighted subset of these aligned pairs. 3) Use the result of Step 2 as either a standalone analyzer or a probabilistic scoring component to iteratively refine the alignment in Step 1. The target output of Step 1 is an inflection-root mapping such as shown in Table 1, with optional columns giving the hypothesized stem change and suffix analysis as well as part of speech. ROOT STEM INFLECTION POS CHANGE SUFFIX take ake —&gt; ook +c took VBD take e —&gt; c +ing taking VBG take —} E takes VBZ take e —&gt; c +en taken VBN skip —} +ed skipped VBD defy y —&gt; i +ed defied VBD defy y —&gt; ie +s defies VBZ defy —} E defying VBG jugar gar —&gt; eg +a juega VPI3S jugar gar —&gt; eg +an juegan VPI3P jugar ar —&gt; c +amos jugamos VPI1P tener ener —&gt; ien +en tienen VPI3P Table 1: Target output (English and Spanish) This suffix-focused transformational model is not, as given, sufficient for languages with prefixal, infixal and reduplicative morphologies. But it is remarkably productive across Indo-European languages in its current form and can be extended to other affixational schema when appropriate. For many applications, once the vocabulary list achieves sufficiently broad coverage, this aligntable effectively morphological analyzer simply by table lookup (independent of necessary contextual ambiguity resolution). While the probabilistic analyzer trained in Step 2 remains useful for previously unseen words, such words are typically quite regular and most of the difficult substance of the lemmatization problem can often be captured by a large root+Posinflection mapping table and a simple transducer to handle residual forms. This is not the case for agglutinative languages such as Turkish or Finnish, or for very highly inflected languages such as Czech, where sparse data becomes an issue. But for many languages, and to a quite practical degree, inflectional morphological analysis and generation can be viewed primarily an on a broad coverage wordlist. Thus, while this paper will discuss our implementation of a stand-alone probabilistic analyzer and retraining process in Steps 2 and 3, the challenge of large-coverage inflection-root alignment expressed in Step 1 is the core of this work. 1.1 Required and Optional Resources In further clarification of the task description, the morphological induction described in this paper assumes, and is based on, only the following limited set of (often optional) available resources: (a) A table (such as Table 2) of the inflectional parts of speech of the given language, along with a list of the canonical suffixes for each part of speech. These suffixes not only serve as mnemonic tags for the POS labels, but they can also be used to obtain a noisy set of candidate examples for each part of speech.&apos; (b) A large unannotated text corpus. (c) A list of the candidate noun, verb and adjective roots of the language (typically obtainable from a dictionary), and any rough mechanism for identifying the candidate parts of speech of the remaining vocabulary based on aggregate models of context or tag sequence, not morphological analysis. Our concurrent work (Cucerzan and Yarowsky, 2000) focuses on the problem of bootstrapping approximate tag probability distributions by modelling relative word-form occurrence probabilities across indicative lexical contexts (e.g. among other predictive variables, with the goal of co-training with the models presented here. It is not necessary to select the part of speech of a word in any given context, only provide an estimate of the candidate tag distributions across a full corpus. The source of these candidate tag estimates is unimportant, however, and the lists can be quite noisy. Their major function is to partially limit the potential alignment space from unrestricted word-to-word alignments across the entire vocabulary. (d) The current implementation assumes a list of the consonants and vowels of the language. (e) While not essential to the execution of the algorithm, a list of common function words of &apos;The lists need not be exhaustive, and any missing suffixes (e.g. the English past tense be captured via a stem change and null suffix (e.g. +c similar to the representation take: +c the given language is useful to the extraction of context similarity features. (f) If available, the various distance/similarity tables generated by this algorithm on previously studied languages can be useful as seed information, especially if these languages are closely related (e.g. Spanish and Italian). 2 Related Work There is a rich tradition of supervised and unsupervised learning in the domain of morphology. Rumelhart and McClelland (1986), Egedi and Sproat (1988), Ling (1994) and Mooney and Calif (1995) have each investigated the supervised learning of the English past tense from paired training data, the first two using phonologicallybased connectionist models and the latter two performing comparative studies with ID3 decision trees and first-order decision lists respectively. Brent (1993, 1999), de Marcken (1995), Kazakov (1997) and Goldsmith (2000) have each focused on the problem of unsupervised learning of morphological systems as essentially a segmentation task, yielding a morphologically plausible and statistically motivated partition of stems and affixes. Brent and de Marcken both have used a minimum description length framework, with the primary goal of inducing lexemes from boundaryless speech-like streams. Goldsmith specifically sought to induce suffix paradigm classes . ed. ing vs. e. ed. ing vs. e. ed. es .ing ted.tion) raw text. However, handling of irregular words was largely excluded from this work, as Goldsmith assumed a strictly concatenative morphology without models for stem changes. Morphology induction in agglutenative languages such as Turkish and Finnish presents a problem similar to parsing or segmenting a sentence, given the long strings of affixations allowed and the relatively free affix order. Voutilainen (1995) has approached this problem in a finitestate framework, and Hakkani-Thr et al. (2000) have done so using a trigram tagger, with the assumption of a concatenative affixation model. The two-level model of morphology (Koskenniemi, 1983) has been extremely successful in manually capturing the morphological processes of the world&apos;s languages. The context sensitive stem-change models used in this current paper have been partially inspired by this framework. For example, a two-level equivalent cap- + er = happier is y:i &lt;=&gt; p:p _, similar in spirit and function to our probabilis-</abstract>
<title confidence="0.3409585">model Theron and Cloete English : Spanish: Part of Speech VB VBD VBZ VBG VBN</title>
<abstract confidence="0.969483584">Canonical +c +ed +s +ing +en +ed (+t) +c Suffixes (+t) +c Examples jump jumped jumps jumping jumped in announce announced announces announcing announced training) take took takes taking taken Part of Speech VRoot VPIls VPI2s VPI3s VPIlp VPI2p VPI3p Canonical +ar +0 +as +a +amos +ads +an Suffixes +er +es +e +emos +eis +en +ir +imos +is Table 2: Example parts of speech and their associated canonical suffixes in English and Spanish (1997) sought to learn a 2-level rule set for English, Xhosa and Afrikaans by supervision from 0(4000) aligned inflection-root pairs extracted from dictionaries. Single character insertion and deletions were allowed, and the learned rules supported both prefixation and suffixation. Their supervised learning approach could be applied directly to the aligned pairs induced in this paper. Finally, Oflazer and Nirenburg (1999) have developed a framework to learn two-level morphological analyzers from interactive supervision in a Elicit-Build-Test loop under the Boas project. Humans provide as-needed feedback regarding errors and omissions. Recently applied to Polish, the model also assumes concatenative morphology and treats non-concatenative irregular forms through table lookup. Thus there is a notable gap in the research literature for induction of analyzers for irregular morphological processes, including significant stem changing. The algorithm described below directly addresses this gap, while successfully inducing more regular analyses without supervision as well. 3 Lemma Alignment by Frequency Similarity The motivating dilemma behind our approach to morphological alignment is the question of how determines that the past tense of is sang not pairing singed only simple concatenation with the canonical sufindeed a legal word in our (the past tense of while few irregular verbs have a true word occupying the slot that would be generated by a regular morphological rule, a large corpus is filled with many mistakes or dysfluencies such as (observed with a frequency of 1), and such errors can wreak havoc in naïve alignment-based methods. How can we overcome this problem? Relative corpus frequency is one useful evidence source. Observe in Table 3 that in an 80 million word collection of newswire text the relative distribution of 1427/1204 (or 1.19/1), which indicates a reasonably close match, while the is 0.007/1, a substantial disparity. VBD:VB 1 g( sang/sing 1427/1204 1.19 0.17 singed/sing 9/1204 0.007 -4.90 singed/singe 9/2 4.5 1.50 sang/singe 1427/9 158.5 5.06 All VBD/VB .85 -0.16 Table 3: Example inflection-root frequency ratios However, simply looking for close relative frequencies between an inflection and its candidate root is inappropriate, given that some inflections relatively rare and occur much less frequently than the root form. in order to be able to rank the effectively, it is necessary to be able to quantify how well each fits (or deviates from) expected frequency distributions. To do so, we use simple non-parametric statistics to calculate the probability of a particuratio by examining how frequently other such ratios in a similar range have been seen in the corpus. Figure 1 illustrates such a histogram (based on the log of the ratios to focus more attention on the extrema). The histogram is then smoothed and normalized as an approximation of the probability density function for this estimator g( ) ) which we can then use to quantify what extent a given candidate ) as /og(sang/sing)=.17, fits our empirically motivated expectations. The relative position of the candidate pairings on the graph suggests that this estimator is indeed informative given the task of ranking potential root-inflection pairings. However, estimating these distributions presents a problem given that the true alignments (and hence frequency ratios) between inflections 0.3 0.25 sang/sing (0.17) singed/singe (1.5) singed/sing (-4.9) taked/take(-10.5) 10 -10 -5 0 5 log(VBD/VB) 0.25 took/taking (0.6) sang/singing (1.0) 0.2 0.15 singed/singeing (2.2) 0.1 0.05 sang/singeing(7.3) taked/taking (-9.5) singed/singing (-5) 0 took/take (-0.35) sang/singe (5.1) 0.2 0.15 0.1 0.05 0 -12 -10 -8 -6 -4 -2 0 2 4 6 8 10 log(VBD/VBG) 0</abstract>
<phone confidence="0.778049">6 -4 -2 0 2 4 6 8</phone>
<email confidence="0.741956">log(VBD/VB)</email>
<title confidence="0.741442">Regular Verbs Irregular Verbs</title>
<abstract confidence="0.953636867647059">0.4 0.35 0.3 0.25 0.2 0.15 0.1 0.05 0.4 0.35 0.3 0.25 0.2 0.15 0.1 0.05 0 -10 -9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 log(VBD|LF-VBD) 0.3 0.25 juegan/jugar (-0.4) 0.2 0.15 0.1 0.05 juegan/juzgar (2.3) juegan/juntar (3.9) juegan/jogar(4.8) 0 -8 -6 -4 -2 0 2 4 6 log(VPI3P/VINF) 5 Lemma Alignment by Weighted Levenshtein Distance The third alignment similarity function considers overall stem edit distance using a weighted Levenshtein measure. In morphological systems worldwide, vowels and vowel clusters are relatively mutable through morphological processes, while consonants generally tend to have a lower probability of change during inflection. Rather than treating all string edits as equal, a cost matrix of the form shown in Table 6 is utilized, with initial distance c and initially set to (0.5, 0.6, 1.0, 0.98), a relatively arbitrary assignment reflecting this tendency. However, as subsequent algorithm iterations proceed, this matrix is re-estimated with empirically observed character-to-character stem-change probabilities from the algorithm&apos;s current best weighted alignments. a o ue m n ... a 0 61. 62 64 64 ••• o 61 0 62 64 64 ... ue 62 62 0 64 64 .•• m 64 64 64 0 63 .•• n 64 64 64 63 0 ... ... ••• ••• ••• ••• ••• ••• Table 6: Initial Levenshtein cost matrix More optimally, the initial state of this matrix could be seeded with values partially borrowed from previously trained matrices from other related languages. Alternately, the initial distances could be set partially sensitive to phonological similarities, with dist(/d/,/t/) &lt; dist(/d/,/f/) for example, although this particular distinction emerges readily via iterative re-estimation from the baseline model.</abstract>
<note confidence="0.53071">6 Lemma Alignment by</note>
<title confidence="0.9290565">Morphological Transformation Probabilities</title>
<abstract confidence="0.988931211538461">The goal of this research is not only to extract an accurate table of inflection-root alignments, but also to generalize this mapping function via a generative probabilistic model. The following section describes the creation of this model, as well as how the context-sensitive probability of each morphological transformation can be used as the fourth alignment similarity measure. At each iteration of the algorithm, this probabilistic mapping function is trained on the table output of the previous iteration, equivalent to the information in Table 1 (e.g. &lt;root,inflection&gt; pairs with optional part-of-speech tags, confidence and stemchange+suffix analysis) From this output, we cluster the observed stem changes by the variable-length root context in which they were applied, as illustrated in Table 7. Root Context Stem Suffix Count Matching Examples Change ..ray c —&gt; c +ed 5 spray, stray,... ...ay c —&gt; c +ed 13 play, spray,... ...oy c —&gt; c +ed 3 annoy, enjoy,... ...ey c —&gt; c +ed 5 obey, key,... ...fy y —&gt; i +ed 21 beautify,... ...ry y —&gt; i +ed 7 carry,... ...dy y —&gt; i +ed 4 bloody,... ...y y —&gt; i +ed 43 carry,... ...y c —&gt; c +ed 21 spray,... ...y c —&gt; c +ing 83 carry, spray,... ...e e —&gt; c +ed 728 dance,... ...e e —&gt; c +ing 783 dance, take,... ...e c —&gt; c +ing 1 singe ...ke ake —&gt; ook +c 3 take, shake,... ...ke ake —&gt; oke +c 1 wake ...ke ke —&gt; de +c 1 make ...ay y —&gt; id +c 2 lay, pay ...y y —&gt; id +c 2 lay, pay Table 7: Stem change data given root context First note that because the triple of &lt;root&gt; + &lt;stemchange&gt; + &lt;suffix&gt; uniquely determines a resulting inflection, one can effectively compute P(inflection I root, suffix, POS) by P(stemchange I root, suffix, POS), i.e. for root=-ya, and inflection=-0a, POS) P(ct Using statistics such as shown in Table 7, it is thus possible to compute the generation (or alignment) probability for an inflection given root and suffix using the simple interpolated backoff model (1) where is a function of the relative samsize of the conditioning event, and the final of the root.</abstract>
<note confidence="0.896236571428571">I root, suffix, POS) P( —&gt; 0 I root, suffix, POS) CE 0 tast3(root), suffix, POS) (1 — Ai)(A2P( CE 0 I last2(root), POS) (1 — A2)(A3P( a —&gt; 0 I suffix, POS) ± (1 — A3)(A4P( a —&gt; 0 I suffix, POS) + (I — A4)P( a —&gt; )</note>
<abstract confidence="0.971262357142857">backoff to the extent necessary. Furthermore, note that for English (and most inflections in Spanish), the stem changes observed when adding suffixes are independent of part of speech only the pairs are given, with no stemchange+suffix analysis, this analysis can be generated deterministically by removing the longest matching canonical suffix from the inflection and generating the a —&gt; 3 ± capturing the remaining stem difference. (i.e. +8 behaves the same on suffixation for both nouns and verbs), so these probabilities can often be further simplified by deleting the conditioning variable POS, as illustrated in (2).</abstract>
<note confidence="0.62764075">I solidify, +ed, VBD) I solidify, +ed, VBD) solidify, +ed) I ify, +ed) (1 — Ai)(A2P( I fY, +ed) + (1 — A2)(A3P( y, +ed) + (1 — A3)(A4P( +ed) + (1 — A4)P( )</note>
<abstract confidence="0.958604081300813">further generalized these variablelength context models via a full hierarchicallysmoothed trie architecture, allowing robust specialization to very long root contexts if sample sizes are sufficient. 6.1 Baseline Model for Morphological Transformation Probabilities On the first iteration, no inflection/root pairs are available for estimating the above models. As prior knowledge is not available regarding a —x stem-change probabilities, an assumption is made that the cost of each is proportional to the previously described Levenshtein distance between a with the cost of a change increasing geometrically as the distance from the end of the root increases. The rate of this cost increase ultimately depends on the tendency of the language to allow word-internal spelling changes (as in Spanish or Arabic), or strongly favor changes at the point of affixation (as in English). 6.2 Model Improvement by Iterative Re-estimation primary of iterative retraining is to refine the core morphological transformation model, which not only serves as one of the four similarity models, but is also a primary deliverable of the learning process. As subsequent iterations proceed, the stemchange probability models are retrained on the output of the prior iteration, weighting each training example with its alignment confidence, and out a —x changes without a minimum level of support to help reduce noise. The final stem-change probabilities then are an interpolawith the trained model the initial described in Section 6.1: c —x root, POS) Ai —x I suffix) (1 — Ai) —x I root, suffix, POS) The Levenshtein distance models are reestimated as observed in Section 5, while the context similarity model can be improved through better self-learned lemmatization of the modelled context words. 7 Lemma Alignment by Model Combination and the Pigeonhole Principle empirically below, no single model is sufficiently effective on its own. We applied traditional classifier combination techniques to merge the four models&apos; scores, scaling each to achieve compatible dynamic range. The Frequency, Levenshtein and Context similarity models retain equal relative weight as training proceeds, while the Morphological Transformation (MorphTrans) similarity model increases in relative weight as it becomes better trained. Table 8 demonstrates the combined measures in action, showing the relative rankings of candidate for the inflections shook the four similarity models after the first iteration (in Columns 2-4). The overall consensus similarity measure at the end of Iteration 1 is shown in Note that even though only one of the four estiindependently ranked the most root of only the first iteration the consensus choice is correct. The final column of Table 8 shows the retrained MorphTrans similarity measure after convergence. Based on training evidence from the confidently pairs shook/shake underprevious iterations, the probof increased significantly, further increasing the confidence in the overall alignments at convergence (not shown), but not changing the previously correct ranking in these cases. The final alignment constraint that we pursued was based on the pigeonhole principle. This principle suggests that for a given part of speech, a root should not have more than one inflection nor should multiple inflections in the same part of speech share the same root. There are, of exceptions to this tendency, such as travdreamt, are observed as variant forms of their respected roots. addition to the consensus similarity score in subcolumn 2, subcolumn 3 shows the average of the of the candidate root given the inflection ranks of the candidate inflection given the root. This bidirectional average ranking score favors cases where attraction between root and inflection is mutual, and disfavors cases where higher ranked competition exists for a root&apos;s attentions, effectively capturing a weak form of the pigeonhole principle. Thus it was used as the primary ranking criteria (over raw similarity score). (2) Candidate Roots for the English inflection TOOK (1st iteration): Overall Similarity Context Frequency Levenshtein MorphTrans MorphTrans (Iteration 1) Similarity Similarity Similarity Similarity (1) Similarity (C) take .00162 3.8 1 take .849 take .072 toot .333 toot .002593 take .465578 turn .00081 8.7 2 turn .546 tell .028 tool .333 tool .002593 toot .001296 tell .00063 15.9 3 tower .332 turn .016 toe .310 tong .000096 tool .001296 test .00041 19.6 4 touch .324 talk .014 take .290 tone .000096 tong .000048 talk .00051 21.0 5 tip .261 test .001 top .236 ... ... tone .000048 tie .00044 26.7 6 tie .260 teach .001 toil .236 take .000006 tout .000048 Candidate Roots for the English inflection SHOOK (1st iteration): Overall Similarity Context Frequency Levenshtein Similarity MorphTrans MorphTrans (Iteration 1) Similarity Similarity Similarity (1) Similarity (C) shake .00149 5.5 1 shake .854 share .073 shoo .500 shoot .002593 shake .465578 shoot .00126 9.3 2 shave .323 ship .068 shoot .333 shoo .002593 shoot .001296 ship .00104 16.3 3 shape .210 shift .062 shoe .310 shock .000096 shoo .001296 shatter .00061 18.9 4 shore .194 shop .060 shake .290 short .000096 shock .000048 shop .00094 19.8 5 shower .184 shake .058 shop .236 shout .000095 short .000048 shut .00081 20.6 6 shoot .162 shut .052 shout .236 ... ... shove .000048 shun .00039 20.7 7 shock .154 shoot .051 show .236 shake .000003 shore .000048 Candidate Roots for the Spanish inflection JUEGAN (1st iteration) jugar .0024 1 jugar .88 jugar .063 jugar .50 jugar .00129 juzgar .0006 2 juntar .38 juzgar .015 juzgar .29 jogar .00129 jurar .0002 4 jurar .26 jogar .009 juntar .25 juntar .00004 jogar .0000 5 justificar .22 juntar .004 jurar .18 juzgar .00004 8: performance of independent and combined similarity measures Overall Similarity</abstract>
<note confidence="0.75781">(Iteration 1)</note>
<title confidence="0.902558571428572">Context Similarity Frequency Similarity Levenshtein Similarity MorphTrans</title>
<abstract confidence="0.992854706896552">Similarity (1) The extent to which such overlaps should be penalized depends on the probability of seeing variant inflections in the morphology, but for Spanish and English this is relatively low. We exploited the pigeonhole principle in two ways simultaneously. The first is a greedy algorithm, in which candidates are aligned in order of decreasing score, and when the the first-choice root for a given inflection has already been taken by another inflection of the same part of speech, the algorithm continues until a free slot is found. The exception is when the highest ranking free form is several orders of magnitude lower than the first choice; here the first-choice alignment is assumed to be correct, but a variant form. 8 Empirical Evaluation Current empirical evaluation of this work focuses on its accuracy in analyzing the often highly irregular past tense of English verbs. Consistent with prior empirical studies in this field, evaluation was performed on a test set of 3888 inflected words, including 128 highly irregular inflections, 1877 cases where the past tense was formed by simple concatenative suffixation, and 1883 inflections exhibiting a non-concatenative stem change such as gemination or elision. In execution, for each test inflected form, the analysis algorithm was free to consider alignment to any word in the corpus which had been identified as a potential root verb by the part-of-speech tagging process or occurrence in a dictionaryrootlist, those roots in the test set. It is thus a more challenging evaluation than testing simple alignment accuracy between two clean and extraneous-entry-free wordlists. Table 9 shows the performance of several of the investigated similarity measures. Frequency similarity (FS), enhanced Levenshtein (LS), and Context similarity (CS) alone achieve only 10%, 31% and 28% overall accuracy respectively. However, the hypothesis that these measures model independent and complementary evidence sources is supported by the roughly additive combined acof The final performance of the full converged CS+FS+LS+MS model at 99.2% accuracy on the full test set, and 99.7% accuracy on inflections requiring analysis beyond simple concatenative suffixation, is quite remarkable given that the algorithm had absolutely no &lt;inflection,root&gt; examples as training data, and had no prior inventory of stem changes available, with only a slight statistical bias in favor of shorter stem changes with fact, in many cases the consensus ranking choice is correct when each independent model&apos;s first choice is wrong, actually yielding a small synergistic super additivity.</abstract>
<note confidence="0.822585090909091">Combination of Similarity # of All Highly Irregular Simple Non-Concat. Iter- Words Concat. Models ations (3888) (128) (1877) (1883) Sim) (Iter 1) 9.8 18.6 8.8 10.1 Sim) (Iter 1) 31.3 19.6 20.0 34.4 Sim) (Iter 1) 28.0 32.8 30.0 25.8 CS+FS (Iter 1) 32.5 64.8 32.0 30.7 CS+FS+LS (Iter 1) 71.6 76.5 71.1 71.9 CS+FS+LS+MS (Iter 1) 96.5 74.0 97.3 97.4 CS+FS+LS+MS (Convg) 99.2 80.4 99.9 99.7 Table 9: Performance of combined alignment models on 4 classes of past-tense English verbs</note>
<abstract confidence="0.989610177419355">smaller Levenshtein distance, and with the minimal search-simplifying assumption in all the models that candidate alignments must begin with a same VC * Given a starting point where all single characchanges at the point of suffixation are equally likely, the processes of elison (e-+e), gemi- (e.g. the context of shift (in the context of a preceding consonant, not vowel) all emerge by the end of the first iteration with high probability in their appropriate contexts, and low probability elsewhere. Table 10 shows how each of the models perform on a randomly-selected 30% of the highly irregular forms, with correctly selected roots identified in bold. The residual errors are primarily of three Two inflections, not alignable with their correct roots due to different first character. The largest class of errors are due to the pigeonhole principle strongly disfavortwo inflections from sharing the same put the Table 9 results in perspective, Mooney and Calif (1995) achieved 82.5% overall accuracy using a fully supervised decision list learner trained on 250 paired past-tense/root verb pairs (in plain text form). Although they don&apos;t breakdown this perforby word type, their included trained from 250 pairs and applied to our evaluation set achieved 100% accuracy on the pairs with simple 84% accuracy on stem changing (non-concat) pairs and 5% accuracy on the highly irregular pairs, with 89% overall accuracy. Other available supervised learning results (e.g. Ling; Rumelhart and McClelland) are only given for phonological word representations. While not directly comparable with our text-based data, their performance is significantly than Mooney and Calif&apos;s common paired data, suggesting that a generally competitive reference point for our results. was previously noted in the case of burned burnt, with the higher probability analysis typically occupying the root slot and the lower probability form typically forced to seek alignment elsewhere. Indeed, the pigeonhole principle is the most problematic of all the remaining typically are due to sparse statistics for the lower frequency irregular forms. such as slay particularly difficult because, with a corpus frequency of only 4, there is too little data to estimate a good context profile or an effectively discriminatory frequency profile. Enlarging the raw corpus size should improve performance in both of these cases. 9 Conclusion This paper has presented an original algorithm capable of inducing the accurate morphological analysis of even highly irregular verbs, starting with no paired &lt;inflection,root&gt; examples for training and no prior seeding of legal morphological transformations. It does so by treating morphological analysis predominantly as an alignment task in a large corpus, performing the effective collaboration of four original similarity measures based on expected frequency distributions, context, morphologically-weighted Levenshtein similarity and an iteratively bootstrapped model of affixation and stem-change probabilities. This constitutes a significant achievement in that previous approaches to morphology acquisition have either focused on unsupervised induction of quasiregular concatenative affixation, or handled irregular forms with fully supervised training. In contrast, this paper&apos;s essentially unsupervised algorithm achieves over 80% accuracy on the most highly irregular forms, and 99.7% accuracy on analyses requiring some stem change, outperforming Mooney and Califf&apos;s fully supervised learning algorithm overall and on both of these measures. alignment principles used, as it creates nearly as many problems as it fixes. The overall performance advantage is slightly in its favor (with 59 misalignments avoided for 50 problems created), but the cost of this approach is borne heavily by the irregular verbs, and a probabilistic model of when variant forms should be expected/allowed is necessary to fix these cases while preserving the advantages of the principle in downweighting clashing analyses in the more regular verbs. Test Word True Root (Convg) CS+FS+LS+MS Score (Itr 1) CS+FS+LS (Itr 1) CS+FS (Itr 1) LS only (Itr 1) got get go 1.30 go go go gut knew know know 1.35 know know know know took take take 1.50 take take take toot blew blow blow 1.80 blow blow blow blow became become become 2.35 become become become become made make make 2.40 make make make mate clung cling cling 2.55 cling cling cling cling drew draw draw 2.65 draw draw draw draw swore swear swear 2.80 swear swear swear store wore wear wear 3.10 wear wear wear wire came come come 3.55 come come come come thought think think 3.60 think think think thump flung fling fling 4.60 fling fling fling fling brought bring bring 5.35 bring bring bring brighten strove strive strive 5.85 strive strive straddle strive stuck stick stick 6.00 stick stick stabilize stock swept sweep sweep 6.20 sweep sweep sweep swap shone shine shine 6.55 shine shine shine shine woke wake wake 6.95 wake wake wind wake clove cleave cleave 7.35 cleave cleave cleave close bore bear bear 7.75 bear bar bear bare meant mean mean 8.20 mean mean manage mount lent lend lend 9.25 lend lend lend lend slew slay slit 10.06 slit slight slight slow struck strike strike 11.60 strike strike strike strut bought buy buy 12.20 buy buy buy bound bit bite bite 13.60 bite bite betray bet dove dive dive 17.25 dive dive dash dive burnt burn burp 17.30 burp burp burp burn went go want 18.29 want want want want caught catch catch 18.35 catch cut catch cough dealt deal deal 21.45 deal deal disagree deal Table 10: Performance of 4 alignment models on 32 randomly selected highly irregular English verbs References M.R. Brent, 1993. Minimal generative models: A ground between neurons and triggers. Pro-</abstract>
<note confidence="0.714159">ceedings of the 15th Annual Conference of the Cog- Science Society, 28-36. M.R. Brent, 1999. An efficient, probabilistically sound algorithm for segmentation and word discov- Learning, 34, 71-106. S. Cucerzan and D. Yarowsky, 2000. Language independent minimally supervised induction of lexical of ACL &apos;00, Kong. C. de Marcken, 1995. Unsupervised language acquisition. PhD dissertation. MIT. D. Egedi and R. Sproat, 1988. Connectionist Networks and Natural Language Morphology. UMD Conf on Grammar and Language Processing. Goldsmith, 2000. Unsupervised Learning of the Morphology of a Natural Language.</note>
<web confidence="0.960071">http://humanities.uchicago.edu/faculty/goldsmith/</web>
<note confidence="0.914538125">Linguistica2000/Paper/paper.html. K. Oflazer, G. Tfir, 2000. Statistical Morphological Disambiguation for Agglutina- Languages. In of COLING 2000. L. Karttunen, 1993. Finite state constraints. In John (ed.) Last Phonological Rule, 173-194. Chicago: University of Chicago Press. D. Kazakov, 1997. Unsupervised learning of naive</note>
<abstract confidence="0.949850642857143">with genetic algorithms. Workshop on Empirical Learning of NLP Tasks. K. Koskenniemi, 1983. A general computation model word-form recognition and production. 11, of General Linguistics. of Helsinki. C.X. Ling, 1994. Learning the past tense of English verbs: The symbolic pattern associator vs. connecmodels. Art. Intel. Res., R. Mooney and M. Califf, 1995. Induction of firstorder decision lists: Results on learning the past of English verbs. Art. Intel. Res., K. Oflazer and S. Nirenburg, 1999. Practical bootof morphological analyzers. of the Conference on Natural Language Learning. D. Rumelhart and J. McClelland, 1986. On learning the past tense of English verbs. In J. McClel- D. Rumelhart, and the Group, Parallel distributed processing: Explorations in the of cognition, 2. MIT Press. P. Theron and I. Cloete, 1997. Automatic acquisition two-level morphological rules. of the Fifth Conference on Applied Natural Language Propages 103-110. A. Voutilainen, 1995. Morphological disambiguation. In F. Karlsson, A. Voutilainen, J. Heikkila, and A. (eds.) grammar - A language independent system for parsing unrestricted text, pages 165-284. The Hague: Mouton de Gruyter.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M R Brent</author>
</authors>
<title>Minimal generative models: A middle ground between neurons and triggers.</title>
<date>1993</date>
<booktitle>Proceedings of the 15th Annual Conference of the Cognitive Science Society,</booktitle>
<pages>28--36</pages>
<contexts>
<context position="6667" citStr="Brent (1993" startWordPosition="1061" endWordPosition="1062">an be useful as seed information, especially if these languages are closely related (e.g. Spanish and Italian). 2 Related Work There is a rich tradition of supervised and unsupervised learning in the domain of morphology. Rumelhart and McClelland (1986), Egedi and Sproat (1988), Ling (1994) and Mooney and Calif (1995) have each investigated the supervised learning of the English past tense from paired training data, the first two using phonologicallybased connectionist models and the latter two performing comparative studies with ID3 decision trees and first-order decision lists respectively. Brent (1993, 1999), de Marcken (1995), Kazakov (1997) and Goldsmith (2000) have each focused on the problem of unsupervised learning of morphological systems as essentially a segmentation task, yielding a morphologically plausible and statistically motivated partition of stems and affixes. Brent and de Marcken both have used a minimum description length framework, with the primary goal of inducing lexemes from boundaryless speech-like streams. Goldsmith specifically sought to induce suffix paradigm classes (e.g. NULL . ed. ing vs. e. ed. ing vs. e. ed. es .ing vs. ted.tion) from raw text. However, handli</context>
</contexts>
<marker>Brent, 1993</marker>
<rawString>M.R. Brent, 1993. Minimal generative models: A middle ground between neurons and triggers. Proceedings of the 15th Annual Conference of the Cognitive Science Society, pages 28-36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M R Brent</author>
</authors>
<title>An efficient, probabilistically sound algorithm for segmentation and word discovery.</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<volume>34</volume>
<pages>71--106</pages>
<marker>Brent, 1999</marker>
<rawString>M.R. Brent, 1999. An efficient, probabilistically sound algorithm for segmentation and word discovery. Machine Learning, 34, pages 71-106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Cucerzan</author>
<author>D Yarowsky</author>
</authors>
<title>Language independent minimally supervised induction of lexical probabilities.</title>
<date>2000</date>
<booktitle>Proceedings of ACL &apos;00,</booktitle>
<location>Hong Kong.</location>
<contexts>
<context position="4708" citStr="Cucerzan and Yarowsky, 2000" startWordPosition="752" endWordPosition="755">en language, along with a list of the canonical suffixes for each part of speech. These suffixes not only serve as mnemonic tags for the POS labels, but they can also be used to obtain a noisy set of candidate examples for each part of speech.&apos; (b) A large unannotated text corpus. (c) A list of the candidate noun, verb and adjective roots of the language (typically obtainable from a dictionary), and any rough mechanism for identifying the candidate parts of speech of the remaining vocabulary based on aggregate models of context or tag sequence, not morphological analysis. Our concurrent work (Cucerzan and Yarowsky, 2000) focuses on the problem of bootstrapping approximate tag probability distributions by modelling relative word-form occurrence probabilities across indicative lexical contexts (e.g. &amp;quot;the &lt;NOUN&gt; are&amp;quot; and &amp;quot;been &lt;VBG&gt; the&amp;quot;), among other predictive variables, with the goal of co-training with the models presented here. It is not necessary to select the part of speech of a word in any given context, only provide an estimate of the candidate tag distributions across a full corpus. The source of these candidate tag estimates is unimportant, however, and the lists can be quite noisy. Their major functi</context>
</contexts>
<marker>Cucerzan, Yarowsky, 2000</marker>
<rawString>S. Cucerzan and D. Yarowsky, 2000. Language independent minimally supervised induction of lexical probabilities. Proceedings of ACL &apos;00, Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C de Marcken</author>
</authors>
<title>Unsupervised language acquisition.</title>
<date>1995</date>
<note>PhD dissertation. MIT.</note>
<marker>de Marcken, 1995</marker>
<rawString>C. de Marcken, 1995. Unsupervised language acquisition. PhD dissertation. MIT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Egedi</author>
<author>R Sproat</author>
</authors>
<date>1988</date>
<booktitle>Connectionist Networks and Natural Language Morphology. UMD Conf on Grammar and Language Processing.</booktitle>
<contexts>
<context position="6334" citStr="Egedi and Sproat (1988)" startWordPosition="1011" endWordPosition="1014">st tense +t) can be captured via a stem change and null suffix (e.g. send: d—&gt;t +c sent), similar to the representation of take: ake—&gt;ook +c took). the given language is useful to the extraction of context similarity features. (f) If available, the various distance/similarity tables generated by this algorithm on previously studied languages can be useful as seed information, especially if these languages are closely related (e.g. Spanish and Italian). 2 Related Work There is a rich tradition of supervised and unsupervised learning in the domain of morphology. Rumelhart and McClelland (1986), Egedi and Sproat (1988), Ling (1994) and Mooney and Calif (1995) have each investigated the supervised learning of the English past tense from paired training data, the first two using phonologicallybased connectionist models and the latter two performing comparative studies with ID3 decision trees and first-order decision lists respectively. Brent (1993, 1999), de Marcken (1995), Kazakov (1997) and Goldsmith (2000) have each focused on the problem of unsupervised learning of morphological systems as essentially a segmentation task, yielding a morphologically plausible and statistically motivated partition of stems </context>
</contexts>
<marker>Egedi, Sproat, 1988</marker>
<rawString>D. Egedi and R. Sproat, 1988. Connectionist Networks and Natural Language Morphology. UMD Conf on Grammar and Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Goldsmith</author>
</authors>
<title>Unsupervised Learning of the Morphology of a Natural Language.</title>
<date>2000</date>
<note>http://humanities.uchicago.edu/faculty/goldsmith/ Linguistica2000/Paper/paper.html.</note>
<contexts>
<context position="6730" citStr="Goldsmith (2000)" startWordPosition="1071" endWordPosition="1072">uages are closely related (e.g. Spanish and Italian). 2 Related Work There is a rich tradition of supervised and unsupervised learning in the domain of morphology. Rumelhart and McClelland (1986), Egedi and Sproat (1988), Ling (1994) and Mooney and Calif (1995) have each investigated the supervised learning of the English past tense from paired training data, the first two using phonologicallybased connectionist models and the latter two performing comparative studies with ID3 decision trees and first-order decision lists respectively. Brent (1993, 1999), de Marcken (1995), Kazakov (1997) and Goldsmith (2000) have each focused on the problem of unsupervised learning of morphological systems as essentially a segmentation task, yielding a morphologically plausible and statistically motivated partition of stems and affixes. Brent and de Marcken both have used a minimum description length framework, with the primary goal of inducing lexemes from boundaryless speech-like streams. Goldsmith specifically sought to induce suffix paradigm classes (e.g. NULL . ed. ing vs. e. ed. ing vs. e. ed. es .ing vs. ted.tion) from raw text. However, handling of irregular words was largely excluded from this work, as G</context>
</contexts>
<marker>Goldsmith, 2000</marker>
<rawString>J. Goldsmith, 2000. Unsupervised Learning of the Morphology of a Natural Language. http://humanities.uchicago.edu/faculty/goldsmith/ Linguistica2000/Paper/paper.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Z Hakkani-Tfir</author>
<author>K Oflazer</author>
<author>G Tfir</author>
</authors>
<title>Statistical Morphological Disambiguation for Agglutinative Languages.</title>
<date>2000</date>
<booktitle>In Proceedings of COLING</booktitle>
<marker>Hakkani-Tfir, Oflazer, Tfir, 2000</marker>
<rawString>D.Z. Hakkani-Tfir, K. Oflazer, G. Tfir, 2000. Statistical Morphological Disambiguation for Agglutinative Languages. In Proceedings of COLING 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Karttunen</author>
</authors>
<title>Finite state constraints. In</title>
<date>1993</date>
<booktitle>The Last Phonological Rule,</booktitle>
<pages>173--194</pages>
<editor>John Goldsmith (ed.)</editor>
<publisher>Chicago: University of Chicago Press.</publisher>
<marker>Karttunen, 1993</marker>
<rawString>L. Karttunen, 1993. Finite state constraints. In John Goldsmith (ed.) The Last Phonological Rule, pages 173-194. Chicago: University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Kazakov</author>
</authors>
<title>Unsupervised learning of naive morphology with genetic algorithms. ECML/Mlnet Workshop on Empirical Learning of NLP Tasks.</title>
<date>1997</date>
<contexts>
<context position="6709" citStr="Kazakov (1997)" startWordPosition="1067" endWordPosition="1069">ially if these languages are closely related (e.g. Spanish and Italian). 2 Related Work There is a rich tradition of supervised and unsupervised learning in the domain of morphology. Rumelhart and McClelland (1986), Egedi and Sproat (1988), Ling (1994) and Mooney and Calif (1995) have each investigated the supervised learning of the English past tense from paired training data, the first two using phonologicallybased connectionist models and the latter two performing comparative studies with ID3 decision trees and first-order decision lists respectively. Brent (1993, 1999), de Marcken (1995), Kazakov (1997) and Goldsmith (2000) have each focused on the problem of unsupervised learning of morphological systems as essentially a segmentation task, yielding a morphologically plausible and statistically motivated partition of stems and affixes. Brent and de Marcken both have used a minimum description length framework, with the primary goal of inducing lexemes from boundaryless speech-like streams. Goldsmith specifically sought to induce suffix paradigm classes (e.g. NULL . ed. ing vs. e. ed. ing vs. e. ed. es .ing vs. ted.tion) from raw text. However, handling of irregular words was largely excluded</context>
</contexts>
<marker>Kazakov, 1997</marker>
<rawString>D. Kazakov, 1997. Unsupervised learning of naive morphology with genetic algorithms. ECML/Mlnet Workshop on Empirical Learning of NLP Tasks.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Koskenniemi</author>
</authors>
<title>A general computation model for word-form recognition and production.</title>
<date>1983</date>
<tech>Pub. 11,</tech>
<institution>Dept. of General Linguistics. Univ. of Helsinki.</institution>
<contexts>
<context position="7891" citStr="Koskenniemi, 1983" startWordPosition="1253" endWordPosition="1255">irregular words was largely excluded from this work, as Goldsmith assumed a strictly concatenative morphology without models for stem changes. Morphology induction in agglutenative languages such as Turkish and Finnish presents a problem similar to parsing or segmenting a sentence, given the long strings of affixations allowed and the relatively free affix order. Voutilainen (1995) has approached this problem in a finitestate framework, and Hakkani-Thr et al. (2000) have done so using a trigram tagger, with the assumption of a concatenative affixation model. The two-level model of morphology (Koskenniemi, 1983) has been extremely successful in manually capturing the morphological processes of the world&apos;s languages. The context sensitive stem-change models used in this current paper have been partially inspired by this framework. For example, a two-level equivalent capturing happy + er = happier is y:i &lt;=&gt; p:p _, quite similar in spirit and function to our probabilistic model P(y—xil...app, +er). Theron and Cloete English : Spanish: Part of Speech VB VBD VBZ VBG VBN Canonical +c +ed +s +ing +en Suffixes (+t) +ed +c (+t) +c Examples jump jumped jumps jumping jumped (not used in announce announced anno</context>
</contexts>
<marker>Koskenniemi, 1983</marker>
<rawString>K. Koskenniemi, 1983. A general computation model for word-form recognition and production. Pub. 11, Dept. of General Linguistics. Univ. of Helsinki.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C X Ling</author>
</authors>
<title>Learning the past tense of English verbs: The symbolic pattern associator vs. connectionist models.</title>
<date>1994</date>
<journal>J. Art. Intel. Res.,</journal>
<pages>1--209</pages>
<contexts>
<context position="6347" citStr="Ling (1994)" startWordPosition="1015" endWordPosition="1016">red via a stem change and null suffix (e.g. send: d—&gt;t +c sent), similar to the representation of take: ake—&gt;ook +c took). the given language is useful to the extraction of context similarity features. (f) If available, the various distance/similarity tables generated by this algorithm on previously studied languages can be useful as seed information, especially if these languages are closely related (e.g. Spanish and Italian). 2 Related Work There is a rich tradition of supervised and unsupervised learning in the domain of morphology. Rumelhart and McClelland (1986), Egedi and Sproat (1988), Ling (1994) and Mooney and Calif (1995) have each investigated the supervised learning of the English past tense from paired training data, the first two using phonologicallybased connectionist models and the latter two performing comparative studies with ID3 decision trees and first-order decision lists respectively. Brent (1993, 1999), de Marcken (1995), Kazakov (1997) and Goldsmith (2000) have each focused on the problem of unsupervised learning of morphological systems as essentially a segmentation task, yielding a morphologically plausible and statistically motivated partition of stems and affixes. </context>
</contexts>
<marker>Ling, 1994</marker>
<rawString>C.X. Ling, 1994. Learning the past tense of English verbs: The symbolic pattern associator vs. connectionist models. J. Art. Intel. Res., 1:209-229.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mooney</author>
<author>M Califf</author>
</authors>
<title>Induction of firstorder decision lists: Results on learning the past tense of English verbs.</title>
<date>1995</date>
<journal>J. Art. Intel. Res.,</journal>
<pages>3--1</pages>
<marker>Mooney, Califf, 1995</marker>
<rawString>R. Mooney and M. Califf, 1995. Induction of firstorder decision lists: Results on learning the past tense of English verbs. J. Art. Intel. Res., 3:1-24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Oflazer</author>
<author>S Nirenburg</author>
</authors>
<title>Practical bootstrapping of morphological analyzers.</title>
<date>1999</date>
<booktitle>Proceedings of the Conference on Natural Language Learning.</booktitle>
<contexts>
<context position="9223" citStr="Oflazer and Nirenburg (1999)" startWordPosition="1469" endWordPosition="1472"> VPIlp VPI2p VPI3p Canonical +ar +0 +as +a +amos +ads +an Suffixes +er +es +e +emos +eis +en +ir +imos +is Table 2: Example parts of speech and their associated canonical suffixes in English and Spanish (1997) sought to learn a 2-level rule set for English, Xhosa and Afrikaans by supervision from 0(4000) aligned inflection-root pairs extracted from dictionaries. Single character insertion and deletions were allowed, and the learned rules supported both prefixation and suffixation. Their supervised learning approach could be applied directly to the aligned pairs induced in this paper. Finally, Oflazer and Nirenburg (1999) have developed a framework to learn two-level morphological analyzers from interactive supervision in a Elicit-Build-Test loop under the Boas project. Humans provide as-needed feedback regarding errors and omissions. Recently applied to Polish, the model also assumes concatenative morphology and treats non-concatenative irregular forms through table lookup. Thus there is a notable gap in the research literature for induction of analyzers for irregular morphological processes, including significant stem changing. The algorithm described below directly addresses this gap, while successfully ind</context>
</contexts>
<marker>Oflazer, Nirenburg, 1999</marker>
<rawString>K. Oflazer and S. Nirenburg, 1999. Practical bootstrapping of morphological analyzers. Proceedings of the Conference on Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Rumelhart</author>
<author>J McClelland</author>
</authors>
<title>On learning the past tense of English verbs. In</title>
<date>1986</date>
<booktitle>and the PDP Research Group, Parallel distributed processing: Explorations in the microstructure of cognition,</booktitle>
<volume>2</volume>
<publisher>MIT Press.</publisher>
<contexts>
<context position="6309" citStr="Rumelhart and McClelland (1986)" startWordPosition="1007" endWordPosition="1010">lar suffixes (e.g. the English past tense +t) can be captured via a stem change and null suffix (e.g. send: d—&gt;t +c sent), similar to the representation of take: ake—&gt;ook +c took). the given language is useful to the extraction of context similarity features. (f) If available, the various distance/similarity tables generated by this algorithm on previously studied languages can be useful as seed information, especially if these languages are closely related (e.g. Spanish and Italian). 2 Related Work There is a rich tradition of supervised and unsupervised learning in the domain of morphology. Rumelhart and McClelland (1986), Egedi and Sproat (1988), Ling (1994) and Mooney and Calif (1995) have each investigated the supervised learning of the English past tense from paired training data, the first two using phonologicallybased connectionist models and the latter two performing comparative studies with ID3 decision trees and first-order decision lists respectively. Brent (1993, 1999), de Marcken (1995), Kazakov (1997) and Goldsmith (2000) have each focused on the problem of unsupervised learning of morphological systems as essentially a segmentation task, yielding a morphologically plausible and statistically moti</context>
</contexts>
<marker>Rumelhart, McClelland, 1986</marker>
<rawString>D. Rumelhart and J. McClelland, 1986. On learning the past tense of English verbs. In J. McClelland, D. Rumelhart, and the PDP Research Group, Parallel distributed processing: Explorations in the microstructure of cognition, Volume 2. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Theron</author>
<author>I Cloete</author>
</authors>
<title>Automatic acquisition of two-level morphological rules.</title>
<date>1997</date>
<booktitle>Proceedings of the Fifth Conference on Applied Natural Language Processing,</booktitle>
<pages>103--110</pages>
<location>Washington,</location>
<marker>Theron, Cloete, 1997</marker>
<rawString>P. Theron and I. Cloete, 1997. Automatic acquisition of two-level morphological rules. Proceedings of the Fifth Conference on Applied Natural Language Processing, Washington, pages 103-110.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Voutilainen</author>
</authors>
<title>Morphological disambiguation.</title>
<date>1995</date>
<pages>165--284</pages>
<editor>In F. Karlsson, A. Voutilainen, J. Heikkila, and A. Anttila (eds.)</editor>
<contexts>
<context position="7657" citStr="Voutilainen (1995)" startWordPosition="1216" endWordPosition="1217"> goal of inducing lexemes from boundaryless speech-like streams. Goldsmith specifically sought to induce suffix paradigm classes (e.g. NULL . ed. ing vs. e. ed. ing vs. e. ed. es .ing vs. ted.tion) from raw text. However, handling of irregular words was largely excluded from this work, as Goldsmith assumed a strictly concatenative morphology without models for stem changes. Morphology induction in agglutenative languages such as Turkish and Finnish presents a problem similar to parsing or segmenting a sentence, given the long strings of affixations allowed and the relatively free affix order. Voutilainen (1995) has approached this problem in a finitestate framework, and Hakkani-Thr et al. (2000) have done so using a trigram tagger, with the assumption of a concatenative affixation model. The two-level model of morphology (Koskenniemi, 1983) has been extremely successful in manually capturing the morphological processes of the world&apos;s languages. The context sensitive stem-change models used in this current paper have been partially inspired by this framework. For example, a two-level equivalent capturing happy + er = happier is y:i &lt;=&gt; p:p _, quite similar in spirit and function to our probabilistic </context>
</contexts>
<marker>Voutilainen, 1995</marker>
<rawString>A. Voutilainen, 1995. Morphological disambiguation. In F. Karlsson, A. Voutilainen, J. Heikkila, and A. Anttila (eds.) Constraint grammar - A language independent system for parsing unrestricted text, pages 165-284. The Hague: Mouton de Gruyter.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>