<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.045319">
<title confidence="0.986733">
Social Network Extraction from Texts: A Thesis Proposal
</title>
<author confidence="0.991878">
Apoorv Agarwal
</author>
<affiliation confidence="0.9978565">
Department of Computer Science
Columbia University
</affiliation>
<email confidence="0.998446">
apoorv@cs.columbia.edu
</email>
<sectionHeader confidence="0.99564" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999203125">
In my thesis, I propose to build a system that
would enable extraction of social interactions
from texts. To date I have defined a compre-
hensive set of social events and built a prelim-
inary system that extracts social events from
news articles. I plan to improve the perfor-
mance of my current system by incorporating
semantic information. Using domain adapta-
tion techniques, I propose to apply my sys-
tem to a wide range of genres. By extracting
linguistic constructs relevant to social interac-
tions, I will be able to empirically analyze dif-
ferent kinds of linguistic constructs that peo-
ple use to express social interactions. Lastly, I
will attempt to make convolution kernels more
scalable and interpretable.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999795431372549">
Language is the primary tool that people use for es-
tablishing, maintaining and expressing social rela-
tions. This makes language the real carrier of social
networks. The overall goal of my thesis is to build a
system that automatically extracts a social network
from raw texts such as literary texts, emails, blog
comments and news articles. I take a “social net-
work” to be a network consisting of individual hu-
man beings and groups of human beings who are
connected to each other through various relation-
ships by the virtue of participating in social events.
I define social events to be events that occur be-
tween people where at least one person is aware
of the other and of the event taking place. For ex-
ample, in the sentence John talks to Mary, entities
John and Mary are aware of each other and of the
talking event. In the sentence John thinks Mary is
great, only John is aware of Mary and the event is
the thinking event. My thesis will introduce a novel
way of constructing networks by analyzing text to
capture such interactions or events.
Motivation: Typically researchers construct a so-
cial network from various forms of electronic in-
teraction records like self-declared friendship links,
sender-receiver email links and phone logs etc. They
ignore a vastly rich network present in the content
of such sources. Secondly, many rich sources of
social networks remain untouched simply because
there is no meta-data associated with them (literary
texts, new stories, historical texts). By providing a
methodology for analyzing language to extract in-
teraction links between people, my work will over-
come both these limitations. Moreover, by empiri-
cally analyzing large corpora of text from different
genres, my work will aid in formulating a compre-
hensive linguistic theory about the types of linguistic
constructs people often use to interact and express
their social interactions with others. In the follow-
ing paragraphs I will explicate these impacts.
Impact on current SNA applications: Some
of the current social network analysis (SNA) ap-
plications that utilize interaction meta-data to con-
struct the underlying social network are discussed
by Domingos and Richardson (2003), Kempe et al.
(2003), He et al. (2006), Rowe et al. (2007), Lin-
damood et al. (2009), Zheleva and Getoor (2009).
But meta-data captures only part of all the interac-
tions in which people participate. There is a vastly
rich network present in text such as the content of
emails, comment threads on online social networks,
transcribed phone calls. My work will enrich the
</bodyText>
<page confidence="0.981852">
111
</page>
<subsectionHeader confidence="0.255806">
Proceedings of the ACL-HLT 2011 Student Session, pages 111–116,
</subsectionHeader>
<bodyText confidence="0.995850597938145">
Portland, OR, USA 19-24 June 2011. c�2011 Association for Computational Linguistics
social network that SNA community currently uses
by complementing it with the finer interaction link-
ages present in text. For example, Rowe et al. (2007)
use the sender-receiver email links to connect peo-
ple in the Enron email corpus. Using this network,
they predict the organizational hierarchy of the En-
ron Corporation. Their social network analysis for
calculating centrality measure of people does not
take into account interactions that people talk about
in the content of emails. Such linkages are relevant
to the task for two reasons. First, people talk about
their interactions with other people in the content of
emails. By ignoring these interaction linkages, the
underlying communication network used by Rowe
et al. (2007) to calculate various features is incom-
plete. Second, sender-receiver email links only rep-
resent “who talks to whom”. They do not represent
“who talks about whom to whom.” This later infor-
mation seems to be crucial to the task presumably
because people at the lower organizational hierarchy
are more likely to talk about people higher in the hi-
erarchy. My work will enable extraction of these
missing linkages and hence offers the potential to
improve the performance of currently used SNA al-
gorithms. By capturing alternate forms of commu-
nications, my system will also overcome a known
limitation of the Enron email corpus that a signifi-
cant number of emails were lost at the time of data
creation (Carenini et al., 2005).
Impact on study of literary and journalistic
texts: Sources of social networks that are primar-
ily textual in nature such as literary texts, historical
texts, or news articles are currently under-utilized
for social network analysis. In fact, to the best of
my knowledge, there is no formal comprehensive
categorization of social interactions. An early effort
to illustrate the importance of such linkages is by
Moretti (2005). In his book, Graphs, Maps, Trees:
Abstract Models for a Literary History, Moretti
presents interesting insights into a novel by looking
at its interaction graph. He notes that his models
are incomplete because they neither have a notion
of weight (number of times two characters interact)
nor a notion of direction (mutual or one-directional).
There has been recent work that partially addresses
these concerns (Elson et al., 2010; Celikyilmaz et
al., 2010). They only extract mutual interactions
that are signaled by quoted speech. My thesis will
go beyond quoted speech and will extract interac-
tions signaled by any linguistic means, in particular
verbs of social interaction. Moreover, my research
will not only enable extraction of mutual linkages
(“who talks to whom” ) but also of one-directional
linkages (“who talks about whom”). This will give
rise to new applications such as characterization of
literary texts based on the type of social network that
underlies the narrative. Moreover, analyses of large
amounts of related text such as decades of news ar-
ticles or historical texts will become possible. By
looking at the overall social structure the analyst or
scientist will get a summary of the key players and
their interactions with each other and the rest of net-
work.
Impact on Linguistics: To the best of my knowl-
edge, there is no cognitive or linguistic theory that
explains how people use language to express social
interactions. A system that detects lexical items and
syntactic constructions that realize interactions and
then classifies them into one of the categories, I de-
fine in Section 2, has the potential to provide lin-
guists with empirical data to formulate such a the-
ory. For example, the notion of social interactions
could be added to the FrameNet resource (Baker and
Fillmore, 1998) which is based on frame semantics.
FrameNet records possible semantic frames for lexi-
cal items. Frames describe lexical meaning by speci-
fying a set of frame elements, which are participants
in a typical event or state of affairs expressed by the
frame. It provides lexicographic example annota-
tions that illustrate how frames and frame elements
can be realized by syntactic constructions. My cate-
gorization of social events can be incorporated into
FrameNet by adding new frames for social events
to the frame hierarchy. The data I collect using
the system can provide example sentenctes for these
frames. Linguists can use this data to make gen-
eralizations about linguistic constructions that real-
ize social interactions frames. For example, a pos-
sible generalization could be that transitive verbs in
which both subject and object are people, frequently
express a social event. In addition, it would be in-
teresting to see what kind social interactions occur
in different text genres and if they are realized dif-
ferently. For example, in a news corpus we hardly
found expressions of non-verbal mutual interactions
(like eye-contact) while these are frequent in fiction
</bodyText>
<page confidence="0.921448">
112
</page>
<bodyText confidence="0.999707258064516">
texts like Alice in Wonderland. of using my method to identify separate scenes or
2 Work to date sub-plots in a narrative, which is crucial for a better
So far, I have defined a comprehensive set of social understanding of the text under investigation.
events and have acquired reliable annotations on a Motivated by this pilot test I decided to anno-
well-known news corpus. I have built a preliminary tate social events on the Automatic Content Extrac-
system that extracts social events from news articles. tion (ACE) dataset (Doddington et al., 2004), a well
I will now expand on each of these in the following known news corpus. My annotations extend previ-
paragraphs. ous annotations for entities, relations and events that
Meaning of social events: A text can describe are present in the 2005 version of the corpus. My an-
a social network in two ways: explicitly, by stat- notations revealed that about 80% of the times, en-
ing the type of relationship between two individuals tities mentioned together in the same sentence were
(e.g. Mary is John’s wife), or implicitly, by describ- not linked with any social event. Therefore, a sim-
ing an event which initiates or perpetuates a social ple heuristic of connecting entities that are present
relationship (e.g. John talked to Mary). I call the in the same sentence with a link will not reveal a
later types of events “social events” (Agarwal et al., meaningful network. Hence I saw a need for a more
2010). I defined two broad types of social events: sophisticated analysis.
interaction, in which both parties are aware of each Extraction of social events: To perform such an
other and of the social event, e.g., a conversation, analysis, I built models for two tasks: social event
and observation, in which only one party is aware detection and social event classification (Agarwal
of the other and of the interaction, e.g., thinking of and Rambow, 2010). Both were formulated as bi-
or talking about someone. For example, sentence nary tasks: the first one being about detecting ex-
1, contains two distinct social events: interaction: istence of a social event between a pair of entities
Toujan was informed by the committee, and observa- in a sentence and the second one being about dif-
tion: Toujan is talking about the committee. I have ferentiating between the interaction and observation
also defined sub-categories for each of these broad type events (given there is an event between the en-
categories based on physical proximity, verbal and tities). I used tree kernels on structures derived from
non-verbal interactions. For details and examples of phrase structure trees and dependency trees in con-
these sub-categories please refer to Agarwal et al. junction with Support Vector Machines (SVMs) to
(2010) solve the tasks. For the design of structures and type
(1) [Toujan Faisal], 54, {said} [she] was of kernel, I took motivation from a system proposed
{informed} of the refusal by an [Interior by Nguyen et al. (2009) which is a state-of-the-art
Ministry committee] overseeing election system for relation extraction. I tried all the kernels
preparations. and their combinations proposed by Nguyen et al.
As a pilot test to see if creating a social network (2009). I used syntactic and semantic insights to de-
based on social events can give insight into the so- vise a new structure derived from dependency trees
cial structures of a story, I manually annotated a and showed that this plays a role in achieving the
short version of Alice in Wonderland. On the man- best performance for both social event detection and
ually extracted network, I ran social network anal- classification tasks. The reason for choosing such
ysis algorithms to answer questions like: who are representations is motivated by extensive studies
the most influential characters in the story, which about the regular relation between verb alternations
characters have the same social roles and positions. and meaning components (Levin, 1993; Schuler,
The most influential characters in the story were de- 2005). This regularity provides a useful generaliza-
tected correctly. Another finding was that characters tion that helps to overcome lexical sparseness. How-
appearing in the same scene like Dodo, Lory, Ea- ever, in order to exploit such regularities, there is a
glet, Mouse and Duck were assigned the same social need to have access to a representation which makes
roles and positions. This pointed out the possibility the predicate-argument structure clear. Dependency
113 representations do this. Phrase structure represen-
tations also represent predicate-argument structure,
but in an indirect way through the structural config-
urations. These experiments showed that as a result
of how language expresses the relevant information,
dependency-based structures are best suited for en-
coding this information. Furthermore, because of
the complexity of the task, a combination of phrase-
based structures and dependency-based structures
perform the best. To my surprise, the system per-
formed extremely well on a seemingly hard task of
differentiating between interaction and observation
type social events. This result showed that there are
significant clues in the lexical and syntactic struc-
tures that help in differentiating mutual and one-
directional interactions.
</bodyText>
<sectionHeader confidence="0.999781" genericHeader="introduction">
3 Future Work
</sectionHeader>
<bodyText confidence="0.9996666">
Currently I am working on incorporating semantic
resources to improve the performance of my prelim-
inary system. I will work on making convolution
kernels scalable and interpretable. These two steps
will meet my goal of building a system that will ex-
tract social networks from news articles. My next
step will be to survey and incorporate domain adap-
tation techniques that will allow me port my system
to other genres like literary and historical texts, blog
comments, emails etc. These steps will allow me to
extract social networks from a wide range of textual
data. At the same time I will be able to empirically
analyze the types of linguistic patterns, both lexi-
cal and syntactic, that perpetuate social interactions.
Now I will expand on the aforementioned future di-
rections.
Adding semantic information: Currently I am
exploring linguistically motivated enhancements of
dependency and phrase structure trees to formulate
new kernels. Specifically, I am exploring ways of in-
corporating semantic information from VerbNet and
FrameNet. This will help me reduce data sparse-
ness and thus improve my current system. I am
interested in modeling classes of events which are
characterized by the cognitive states of participants–
who is aware of whom. The predicate-argument
structure of verbs can encode much of this infor-
mation very efficiently, and classes of verbs express
their predicate-argument structure in similar ways.
Levin’s verb classes, and Palmer’s VerbNet (Levin,
1993; Schuler, 2005), are based on syntactic simi-
larity between verbs: two verbs are in the same class
if and only if they can realize their arguments in the
same syntactic patterns. By the Levin Hypothesis,
this is because they share meaning elements, and
meaning and syntactic realizations of arguments are
related. However, this does not mean that verbs in
the same Levin or VerbNet class are synonyms; for
example, to deliberate and to play are both in Verb-
Net class meet-36.3-1. But from a social event per-
spective, I am not interested in exact synonymy, and
in fact it is quite possible that what I am interested
in (awareness of the interaction by the event partici-
pants) is the same among verbs of the same VerbNet
class. In this case, VerbNet will provide a useful ab-
straction. Future work will also explore FrameNet,
which provides a different type of semantic abstrac-
tion and explicit semantic relations that are not di-
rectly based on syntactic realizations.
Scaling convolution kernels: Convolution ker-
nels, first proposed by Haussler (1999), are a con-
venient way of “naturally” combining a variety of
features without having to do fine-grained feature
engineering. Collins and Duffy (2002) presented a
way of successfully using them for NLP tasks such
as parsing and tagging. Since then they have been
used for various NLP tasks such as relation extrac-
tion (Zelenko et al., 2002; Culotta and Jeffrey, 2004;
Nguyen et al., 2009), semantic role labeling (Mos-
chitti et al., 2008), question-answer classification
(Moschitti et al., 2007) etc. Convolution kernels cal-
culate the similarity between two objects, like trees
or strings, by a recursive calculation over the “parts”
(substrings, subtrees) of objects. This calculation
is usually made computationally efficient by using
dynamic programming. But there are two limita-
tions: 1) the computation is still quadratic and hence
slow and 2) the features (or parts) that are given high
weights at the time of learning remain inaccessible
i.e. interpretability of the model becomes difficult.
One direction I will explore to make convolution
kernels more scalable is the following: The deci-
sion function for the classifier (SVM in dual form)
is given in equation 1 (Burges, 1998, Eq 61). In
this equation, yz denotes the class of the ith support
vector (sz), αz denotes the Lagrange multiplier of
sz, K(sz7 x) denotes the kernel similarity between sz
and a test example x, b denotes the bias. The kernel
definition proposed by Collins and Duffy (2002) is
given in equation 2, where hs(T) is the number of
</bodyText>
<page confidence="0.997491">
114
</page>
<bodyText confidence="0.990820166666667">
times the sth subtree appears in tree T. The kernel
function K(T1,T2) therefore calculates the similar-
ity between trees T1 and T2 by counting the common
subtrees in them. By combining equations 1 and 2
I get equation 3 which can be re-written as equation
4.
</bodyText>
<equation confidence="0.999285818181818">
N.
f(x) = αiyiK(si, x) + b (1)
i=1
K(T1,T2) = � hs(T1)hs(T2) (2)
s
N.
f(x) = �αiyi hs(si)hs(x) (3)
i=1 s
N.
f(x) = � αiyihs(si)hs(x) (4)
s i=1
</equation>
<bodyText confidence="0.99989185483871">
The motivation for exchanging these summation
signs is that the contribution of larger subtrees to
the kernel similarity is strictly less than the contri-
bution of the smaller subtrees. I will investigate the
possibility of approximating the decision function of
SVM without having to compare all subtrees, in par-
ticular large subtrees. I will also investigate if this
summation can be calculated in parallel to make the
calculation more scalable. Pelossof and Ying (2010)
have done recent work on speeding up the Percep-
tron by stopping the evaluation of features at an early
stage if they have high confidence that the example
will be classified correctly. Another relevant work to
improve the scalability of linear classifiers is due to
Clarkson et al. (2010). However, to the best of my
knowledge, there is no work that addresses approxi-
mation of kernel evaluation for convolution kernels.
Interpretability of convolution kernels: As
mentioned in the previous paragraph, another dis-
advantage of using convolution kernels is that inter-
pretability of a model is difficult. Recently, Pighin
and Moschitti (2009) proposed an algorithm to lin-
earize convolution kernels. They show that by ef-
ficiently encoding the “relevant” fragments gener-
ated by tree kernels, it is possible to get insight into
the substructures that were given high weights at the
time of learning a model. But their system currently
returns thousands of such fragments. I will inves-
tigate if there is a way of summarizing these frag-
ments into a meaningful set of syntactic and lexical
classes. By doing so I will be able to empirically see
what types of linguistic constructs are used by peo-
ple to express different types of social interactions
thus aiding in formulating a theory of how people
express social interactions.
Domain adaptation: To be able to extract social
networks from literary and historical texts, I will ex-
plore domain adaptation techniques. A notable work
in this direction is by Daum´e III (2007). This work is
especially useful for me because Daum´e III presents
a straightforward kernelized version of his domain
adaptation approach which readily fits the machine
learning paradigm I am using for my problem. I will
explore the literature to see if better domain adap-
tation techniques have been suggested since then.
Domain adaptation will conclude my overall goal of
creating a system that can extract social networks
from a wide variety of texts. I will then attempt to
extract social networks from the increasing amount
of text that is becoming machine readable.
Sentiment Analysis:1 A natural step to try once I
have linkages associated with snippets of text is sen-
timent analysis. I will use my previous work (Agar-
wal et al., 2009) on contextual phrase-level senti-
ment analysis to analyze snippets of text and add
polarity to social event linkages. Sentiment analy-
sis will make the social network representation even
richer by indicating if people are connected with
positive, negative or neutral sentiments. This will
not only give us information about the protagonists
and antagonists in the text but will also affect the
analysis of flow of information through the network.
</bodyText>
<sectionHeader confidence="0.997487" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999941666666667">
This work was funded by NSF grant IIS-0713548. I
would like to thank Dr. Owen Rambow and Daniel
Bauer for useful discussions and feedback.
</bodyText>
<sectionHeader confidence="0.986616" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.65344625">
Apoorv Agarwal and Owen Rambow. 2010. Automatic
detection and classification of social events. In Pro-
ceedings of the 2010 Conference on Empirical Meth-
ods in Natural Language Processing.
</bodyText>
<footnote confidence="0.70190375">
Apoorv Agarwal, Fadi Biadsy, and Kathleen Mckeown.
2009. Contextual phrase-level polarity analysis using
1I do not mention sentiment analysis anywhere else in my
proposal since I will simply use my earlier work.
</footnote>
<page confidence="0.99634">
115
</page>
<reference confidence="0.990925037383178">
lexical affect scoring and syntactic n-grams. Proceed-
ings of the 12th Conference of the European Chapter
of the ACL (EACL 2009), pages 24–32.
Apoorv Agarwal, Owen C. Rambow, and Rebecca J. Pas-
sonneau. 2010. Annotation scheme for social network
extraction from text. In Proceedings of the Fourth Lin-
guistic Annotation Workshop.
C. Baker and C. Fillmore. 1998. The berkeley framenet
project. Proceedings of the 17th international confer-
ence on Computational linguistics, 1.
Chris Burges. 1998. A tutorial on support vector
machines for pattern recognition. Data mining and
knowledge discovery.
G. Carenini, R. T. Ng, and X. Zhou. 2005. Scalable dis-
covery of hidden emails from large folders. Proceed-
ing of the eleventh ACM SIGKDD international con-
ference on Knowledge discovery in data mining, pages
544–549.
Asli Celikyilmaz, Dilek Hakkani-Tur, Hua He, Greg
Kondrak, and Denilson Barbosa. 2010. The actor-
topic model for extracting social networks in literary
narrative. NIPS Workshop: Machine Learning for So-
cial Computing.
K. L. Clarkson, E. Hazan, and D. P. Woodruff. 2010.
Sublinear optimization for machine learning. 51st An-
nual IEEE Symposium on Foundations of Computer
Science, pages 449 –457.
M. Collins and N. Duffy. 2002. Convolution kernels for
natural language. In Advances in neural information
processing systems.
Aron Culotta and Sorensen Jeffrey. 2004. Dependency
tree kernels for relation extraction. In Proceedings of
the 42nd Meeting of the Association for Computational
Linguistics (ACL’04), Main Volume, pages 423–429,
Barcelona, Spain, July.
G. Doddington, A. Mitchell, M. Przybocki, L. Ramshaw,
S. Strassel, and R. Weischedel. 2004. The automatic
content extraction (ace) program–tasks, data, and eval-
uation. LREC, pages 837–840.
P. Domingos and M. Richardson. 2003. Mining the net-
work value of customers. In Proceedings of the 7th In-
ternational Conference on Knowledge Discovery and
Data Mining, pages 57–66.
David K. Elson, Nicholas Dames, and Kathleen R. McK-
eown. 2010. Extracting social networks from literary
fiction. Proceedings of the 48th Annual Meeting of
the Association for Computational Linguistics, pages
138–147.
David Haussler. 1999. Convolution kernels on discrete
structures. Technical report, University of California
at Santa Cruz.
Jianming He, Wesley W. Chu, and Zhenyu (Victor) Liu.
2006. Inferring privacy information from social net-
works. Intelligence and Security Informatics, pages
154–165.
Hal Daume III. 2007. Frustratingly easy domain adapta-
tion. Annual Meeting-Association For Computational
Linguistics.
D. Kempe, J. Kleinberg, and E. Tardos. 2003. Maximiz-
ing the spread of influence through a social network.
Proceedings of the ninth ACM SIGKDD international
conference on Knowledge discovery and data mining,
pages 137–146.
Beth Levin. 1993. English verb classes and alterna-
tions: A preliminary investigation. The University of
Chicago Press.
J. Lindamood, R. Heatherly, M. Kantarcioglu, and
B. Thuraisingham. 2009. Inferring private informa-
tion using social network dataset. WWW.
Franco Moretti. 2005. Graphs, Maps, Trees: Abstract
Models for a Literary History. Verso.
A. Moschitti, S. Quarteroni, and R. Basili. 2007. Ex-
ploiting syntactic and shallow semantic kernels for
question answer classification. Proceedings of the
45th Conference of the Association for Computational
Linguistics (ACL).
A. Moschitti, D. Pighin, and R. Basili. 2008. Tree ker-
nels for semantic role labeling. Computational Lin-
guistics, 34.
Truc-Vien T. Nguyen, Alessandro Moschitti, and
Giuseppe Riccardi. 2009. Convolution kernels on
constituent, dependency and sequential structures for
relation extraction. Conference on Empirical Methods
in Natural Language Processing.
Raphael Pelossof and Zhiliang Ying. 2010. The attentive
perceptron. CoRR, abs/1009.5972.
D. Pighin and A. Moschitti. 2009. Reverse engineering
of tree kernel feature spaces. Proceedings of the Con-
ference on EMNLP, pages 111–120.
Ryan Rowe, German Creamer, Shlomo Hershkop, and
Salvatore J Stolfo. 2007. Automated social hierar-
chy detection through email network analysis. Pro-
ceedings of the 9th WebKDD and 1st SNA-KDD 2007
workshop on Web mining and social network analysis,
pages 109–117.
Karin Kipper Schuler. 2005. Verbnet: a broad-
coverage, comprehensive verb lexicon. Ph.D. thesis,
University of Pennsylvania, Philadelphia, PA, USA.
AAI3179808.
D. Zelenko, C. Aone, and A. Richardella. 2002. Kernel
methods for relation extraction. In Proceedings of the
EMNLP.
Elena Zheleva and Lise Getoor. 2009. To join or not
to join: the illusion of privacy in social networks with
mixed public and private user profiles. Proceedings of
the 18th international conference on World wide web,
pages 531–540.
</reference>
<page confidence="0.999001">
116
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.266052">
<note confidence="0.467668">Social Network Extraction from Texts: A Thesis Proposal Apoorv</note>
<affiliation confidence="0.87507">Department of Computer Columbia</affiliation>
<email confidence="0.999645">apoorv@cs.columbia.edu</email>
<abstract confidence="0.998945176470588">In my thesis, I propose to build a system that would enable extraction of social interactions from texts. To date I have defined a comprehensive set of social events and built a preliminary system that extracts social events from news articles. I plan to improve the performance of my current system by incorporating semantic information. Using domain adaptation techniques, I propose to apply my system to a wide range of genres. By extracting linguistic constructs relevant to social interactions, I will be able to empirically analyze different kinds of linguistic constructs that people use to express social interactions. Lastly, I will attempt to make convolution kernels more scalable and interpretable.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>lexical affect scoring and syntactic n-grams.</title>
<date>2009</date>
<booktitle>Proceedings of the 12th Conference of the European Chapter of the ACL (EACL</booktitle>
<pages>24--32</pages>
<contexts>
<context position="3149" citStr="(2009)" startWordPosition="511" endWordPosition="511">yzing large corpora of text from different genres, my work will aid in formulating a comprehensive linguistic theory about the types of linguistic constructs people often use to interact and express their social interactions with others. In the following paragraphs I will explicate these impacts. Impact on current SNA applications: Some of the current social network analysis (SNA) applications that utilize interaction meta-data to construct the underlying social network are discussed by Domingos and Richardson (2003), Kempe et al. (2003), He et al. (2006), Rowe et al. (2007), Lindamood et al. (2009), Zheleva and Getoor (2009). But meta-data captures only part of all the interactions in which people participate. There is a vastly rich network present in text such as the content of emails, comment threads on online social networks, transcribed phone calls. My work will enrich the 111 Proceedings of the ACL-HLT 2011 Student Session, pages 111–116, Portland, OR, USA 19-24 June 2011. c�2011 Association for Computational Linguistics social network that SNA community currently uses by complementing it with the finer interaction linkages present in text. For example, Rowe et al. (2007) use the s</context>
<context position="11435" citStr="(2009)" startWordPosition="1861" endWordPosition="1861">for each of these broad type events (given there is an event between the encategories based on physical proximity, verbal and tities). I used tree kernels on structures derived from non-verbal interactions. For details and examples of phrase structure trees and dependency trees in conthese sub-categories please refer to Agarwal et al. junction with Support Vector Machines (SVMs) to (2010) solve the tasks. For the design of structures and type (1) [Toujan Faisal], 54, {said} [she] was of kernel, I took motivation from a system proposed {informed} of the refusal by an [Interior by Nguyen et al. (2009) which is a state-of-the-art Ministry committee] overseeing election system for relation extraction. I tried all the kernels preparations. and their combinations proposed by Nguyen et al. As a pilot test to see if creating a social network (2009). I used syntactic and semantic insights to debased on social events can give insight into the so- vise a new structure derived from dependency trees cial structures of a story, I manually annotated a and showed that this plays a role in achieving the short version of Alice in Wonderland. On the man- best performance for both social event detection and</context>
<context position="19327" citStr="(2009)" startWordPosition="3124" endWordPosition="3124">g up the Perceptron by stopping the evaluation of features at an early stage if they have high confidence that the example will be classified correctly. Another relevant work to improve the scalability of linear classifiers is due to Clarkson et al. (2010). However, to the best of my knowledge, there is no work that addresses approximation of kernel evaluation for convolution kernels. Interpretability of convolution kernels: As mentioned in the previous paragraph, another disadvantage of using convolution kernels is that interpretability of a model is difficult. Recently, Pighin and Moschitti (2009) proposed an algorithm to linearize convolution kernels. They show that by efficiently encoding the “relevant” fragments generated by tree kernels, it is possible to get insight into the substructures that were given high weights at the time of learning a model. But their system currently returns thousands of such fragments. I will investigate if there is a way of summarizing these fragments into a meaningful set of syntactic and lexical classes. By doing so I will be able to empirically see what types of linguistic constructs are used by people to express different types of social interaction</context>
</contexts>
<marker>2009</marker>
<rawString>lexical affect scoring and syntactic n-grams. Proceedings of the 12th Conference of the European Chapter of the ACL (EACL 2009), pages 24–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Apoorv Agarwal</author>
<author>Owen C Rambow</author>
<author>Rebecca J Passonneau</author>
</authors>
<title>Annotation scheme for social network extraction from text.</title>
<date>2010</date>
<booktitle>In Proceedings of the Fourth Linguistic Annotation Workshop.</booktitle>
<marker>Agarwal, Rambow, Passonneau, 2010</marker>
<rawString>Apoorv Agarwal, Owen C. Rambow, and Rebecca J. Passonneau. 2010. Annotation scheme for social network extraction from text. In Proceedings of the Fourth Linguistic Annotation Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Baker</author>
<author>C Fillmore</author>
</authors>
<title>The berkeley framenet project.</title>
<date>1998</date>
<booktitle>Proceedings of the 17th international conference on Computational linguistics,</booktitle>
<pages>1</pages>
<contexts>
<context position="7286" citStr="Baker and Fillmore, 1998" startWordPosition="1175" endWordPosition="1178"> a summary of the key players and their interactions with each other and the rest of network. Impact on Linguistics: To the best of my knowledge, there is no cognitive or linguistic theory that explains how people use language to express social interactions. A system that detects lexical items and syntactic constructions that realize interactions and then classifies them into one of the categories, I define in Section 2, has the potential to provide linguists with empirical data to formulate such a theory. For example, the notion of social interactions could be added to the FrameNet resource (Baker and Fillmore, 1998) which is based on frame semantics. FrameNet records possible semantic frames for lexical items. Frames describe lexical meaning by specifying a set of frame elements, which are participants in a typical event or state of affairs expressed by the frame. It provides lexicographic example annotations that illustrate how frames and frame elements can be realized by syntactic constructions. My categorization of social events can be incorporated into FrameNet by adding new frames for social events to the frame hierarchy. The data I collect using the system can provide example sentenctes for these f</context>
</contexts>
<marker>Baker, Fillmore, 1998</marker>
<rawString>C. Baker and C. Fillmore. 1998. The berkeley framenet project. Proceedings of the 17th international conference on Computational linguistics, 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Burges</author>
</authors>
<title>A tutorial on support vector machines for pattern recognition. Data mining and knowledge discovery.</title>
<date>1998</date>
<contexts>
<context position="17485" citStr="Burges, 1998" startWordPosition="2811" endWordPosition="2812">trees or strings, by a recursive calculation over the “parts” (substrings, subtrees) of objects. This calculation is usually made computationally efficient by using dynamic programming. But there are two limitations: 1) the computation is still quadratic and hence slow and 2) the features (or parts) that are given high weights at the time of learning remain inaccessible i.e. interpretability of the model becomes difficult. One direction I will explore to make convolution kernels more scalable is the following: The decision function for the classifier (SVM in dual form) is given in equation 1 (Burges, 1998, Eq 61). In this equation, yz denotes the class of the ith support vector (sz), αz denotes the Lagrange multiplier of sz, K(sz7 x) denotes the kernel similarity between sz and a test example x, b denotes the bias. The kernel definition proposed by Collins and Duffy (2002) is given in equation 2, where hs(T) is the number of 114 times the sth subtree appears in tree T. The kernel function K(T1,T2) therefore calculates the similarity between trees T1 and T2 by counting the common subtrees in them. By combining equations 1 and 2 I get equation 3 which can be re-written as equation 4. N. f(x) = α</context>
</contexts>
<marker>Burges, 1998</marker>
<rawString>Chris Burges. 1998. A tutorial on support vector machines for pattern recognition. Data mining and knowledge discovery.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Carenini</author>
<author>R T Ng</author>
<author>X Zhou</author>
</authors>
<title>Scalable discovery of hidden emails from large folders.</title>
<date>2005</date>
<booktitle>Proceeding of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining,</booktitle>
<pages>544--549</pages>
<contexts>
<context position="5042" citStr="Carenini et al., 2005" startWordPosition="814" endWordPosition="817">o talks to whom”. They do not represent “who talks about whom to whom.” This later information seems to be crucial to the task presumably because people at the lower organizational hierarchy are more likely to talk about people higher in the hierarchy. My work will enable extraction of these missing linkages and hence offers the potential to improve the performance of currently used SNA algorithms. By capturing alternate forms of communications, my system will also overcome a known limitation of the Enron email corpus that a significant number of emails were lost at the time of data creation (Carenini et al., 2005). Impact on study of literary and journalistic texts: Sources of social networks that are primarily textual in nature such as literary texts, historical texts, or news articles are currently under-utilized for social network analysis. In fact, to the best of my knowledge, there is no formal comprehensive categorization of social interactions. An early effort to illustrate the importance of such linkages is by Moretti (2005). In his book, Graphs, Maps, Trees: Abstract Models for a Literary History, Moretti presents interesting insights into a novel by looking at its interaction graph. He notes </context>
</contexts>
<marker>Carenini, Ng, Zhou, 2005</marker>
<rawString>G. Carenini, R. T. Ng, and X. Zhou. 2005. Scalable discovery of hidden emails from large folders. Proceeding of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining, pages 544–549.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Asli Celikyilmaz</author>
<author>Dilek Hakkani-Tur</author>
<author>Hua He</author>
<author>Greg Kondrak</author>
<author>Denilson Barbosa</author>
</authors>
<title>The actortopic model for extracting social networks in literary narrative. NIPS Workshop: Machine Learning for Social Computing.</title>
<date>2010</date>
<contexts>
<context position="5928" citStr="Celikyilmaz et al., 2010" startWordPosition="952" endWordPosition="955"> knowledge, there is no formal comprehensive categorization of social interactions. An early effort to illustrate the importance of such linkages is by Moretti (2005). In his book, Graphs, Maps, Trees: Abstract Models for a Literary History, Moretti presents interesting insights into a novel by looking at its interaction graph. He notes that his models are incomplete because they neither have a notion of weight (number of times two characters interact) nor a notion of direction (mutual or one-directional). There has been recent work that partially addresses these concerns (Elson et al., 2010; Celikyilmaz et al., 2010). They only extract mutual interactions that are signaled by quoted speech. My thesis will go beyond quoted speech and will extract interactions signaled by any linguistic means, in particular verbs of social interaction. Moreover, my research will not only enable extraction of mutual linkages (“who talks to whom” ) but also of one-directional linkages (“who talks about whom”). This will give rise to new applications such as characterization of literary texts based on the type of social network that underlies the narrative. Moreover, analyses of large amounts of related text such as decades of</context>
</contexts>
<marker>Celikyilmaz, Hakkani-Tur, He, Kondrak, Barbosa, 2010</marker>
<rawString>Asli Celikyilmaz, Dilek Hakkani-Tur, Hua He, Greg Kondrak, and Denilson Barbosa. 2010. The actortopic model for extracting social networks in literary narrative. NIPS Workshop: Machine Learning for Social Computing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K L Clarkson</author>
<author>E Hazan</author>
<author>D P Woodruff</author>
</authors>
<title>Sublinear optimization for machine learning.</title>
<date>2010</date>
<booktitle>51st Annual IEEE Symposium on Foundations of Computer Science,</booktitle>
<pages>449--457</pages>
<contexts>
<context position="18977" citStr="Clarkson et al. (2010)" startWordPosition="3069" endWordPosition="3072">than the contribution of the smaller subtrees. I will investigate the possibility of approximating the decision function of SVM without having to compare all subtrees, in particular large subtrees. I will also investigate if this summation can be calculated in parallel to make the calculation more scalable. Pelossof and Ying (2010) have done recent work on speeding up the Perceptron by stopping the evaluation of features at an early stage if they have high confidence that the example will be classified correctly. Another relevant work to improve the scalability of linear classifiers is due to Clarkson et al. (2010). However, to the best of my knowledge, there is no work that addresses approximation of kernel evaluation for convolution kernels. Interpretability of convolution kernels: As mentioned in the previous paragraph, another disadvantage of using convolution kernels is that interpretability of a model is difficult. Recently, Pighin and Moschitti (2009) proposed an algorithm to linearize convolution kernels. They show that by efficiently encoding the “relevant” fragments generated by tree kernels, it is possible to get insight into the substructures that were given high weights at the time of learn</context>
</contexts>
<marker>Clarkson, Hazan, Woodruff, 2010</marker>
<rawString>K. L. Clarkson, E. Hazan, and D. P. Woodruff. 2010. Sublinear optimization for machine learning. 51st Annual IEEE Symposium on Foundations of Computer Science, pages 449 –457.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>N Duffy</author>
</authors>
<title>Convolution kernels for natural language. In Advances in neural information processing systems.</title>
<date>2002</date>
<contexts>
<context position="16452" citStr="Collins and Duffy (2002)" startWordPosition="2645" endWordPosition="2648">quite possible that what I am interested in (awareness of the interaction by the event participants) is the same among verbs of the same VerbNet class. In this case, VerbNet will provide a useful abstraction. Future work will also explore FrameNet, which provides a different type of semantic abstraction and explicit semantic relations that are not directly based on syntactic realizations. Scaling convolution kernels: Convolution kernels, first proposed by Haussler (1999), are a convenient way of “naturally” combining a variety of features without having to do fine-grained feature engineering. Collins and Duffy (2002) presented a way of successfully using them for NLP tasks such as parsing and tagging. Since then they have been used for various NLP tasks such as relation extraction (Zelenko et al., 2002; Culotta and Jeffrey, 2004; Nguyen et al., 2009), semantic role labeling (Moschitti et al., 2008), question-answer classification (Moschitti et al., 2007) etc. Convolution kernels calculate the similarity between two objects, like trees or strings, by a recursive calculation over the “parts” (substrings, subtrees) of objects. This calculation is usually made computationally efficient by using dynamic progra</context>
<context position="17758" citStr="Collins and Duffy (2002)" startWordPosition="2857" endWordPosition="2860">nce slow and 2) the features (or parts) that are given high weights at the time of learning remain inaccessible i.e. interpretability of the model becomes difficult. One direction I will explore to make convolution kernels more scalable is the following: The decision function for the classifier (SVM in dual form) is given in equation 1 (Burges, 1998, Eq 61). In this equation, yz denotes the class of the ith support vector (sz), αz denotes the Lagrange multiplier of sz, K(sz7 x) denotes the kernel similarity between sz and a test example x, b denotes the bias. The kernel definition proposed by Collins and Duffy (2002) is given in equation 2, where hs(T) is the number of 114 times the sth subtree appears in tree T. The kernel function K(T1,T2) therefore calculates the similarity between trees T1 and T2 by counting the common subtrees in them. By combining equations 1 and 2 I get equation 3 which can be re-written as equation 4. N. f(x) = αiyiK(si, x) + b (1) i=1 K(T1,T2) = � hs(T1)hs(T2) (2) s N. f(x) = �αiyi hs(si)hs(x) (3) i=1 s N. f(x) = � αiyihs(si)hs(x) (4) s i=1 The motivation for exchanging these summation signs is that the contribution of larger subtrees to the kernel similarity is strictly less tha</context>
</contexts>
<marker>Collins, Duffy, 2002</marker>
<rawString>M. Collins and N. Duffy. 2002. Convolution kernels for natural language. In Advances in neural information processing systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aron Culotta</author>
<author>Sorensen Jeffrey</author>
</authors>
<title>Dependency tree kernels for relation extraction.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL’04), Main Volume,</booktitle>
<pages>423--429</pages>
<location>Barcelona, Spain,</location>
<contexts>
<context position="16668" citStr="Culotta and Jeffrey, 2004" startWordPosition="2683" endWordPosition="2686"> work will also explore FrameNet, which provides a different type of semantic abstraction and explicit semantic relations that are not directly based on syntactic realizations. Scaling convolution kernels: Convolution kernels, first proposed by Haussler (1999), are a convenient way of “naturally” combining a variety of features without having to do fine-grained feature engineering. Collins and Duffy (2002) presented a way of successfully using them for NLP tasks such as parsing and tagging. Since then they have been used for various NLP tasks such as relation extraction (Zelenko et al., 2002; Culotta and Jeffrey, 2004; Nguyen et al., 2009), semantic role labeling (Moschitti et al., 2008), question-answer classification (Moschitti et al., 2007) etc. Convolution kernels calculate the similarity between two objects, like trees or strings, by a recursive calculation over the “parts” (substrings, subtrees) of objects. This calculation is usually made computationally efficient by using dynamic programming. But there are two limitations: 1) the computation is still quadratic and hence slow and 2) the features (or parts) that are given high weights at the time of learning remain inaccessible i.e. interpretability </context>
</contexts>
<marker>Culotta, Jeffrey, 2004</marker>
<rawString>Aron Culotta and Sorensen Jeffrey. 2004. Dependency tree kernels for relation extraction. In Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL’04), Main Volume, pages 423–429, Barcelona, Spain, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Doddington</author>
<author>A Mitchell</author>
<author>M Przybocki</author>
<author>L Ramshaw</author>
<author>S Strassel</author>
<author>R Weischedel</author>
</authors>
<title>The automatic content extraction (ace) program–tasks, data, and evaluation. LREC,</title>
<date>2004</date>
<pages>837--840</pages>
<contexts>
<context position="9011" citStr="Doddington et al., 2004" startWordPosition="1454" endWordPosition="1457">l interactions (like eye-contact) while these are frequent in fiction 112 texts like Alice in Wonderland. of using my method to identify separate scenes or 2 Work to date sub-plots in a narrative, which is crucial for a better So far, I have defined a comprehensive set of social understanding of the text under investigation. events and have acquired reliable annotations on a Motivated by this pilot test I decided to annowell-known news corpus. I have built a preliminary tate social events on the Automatic Content Extracsystem that extracts social events from news articles. tion (ACE) dataset (Doddington et al., 2004), a well I will now expand on each of these in the following known news corpus. My annotations extend previparagraphs. ous annotations for entities, relations and events that Meaning of social events: A text can describe are present in the 2005 version of the corpus. My ana social network in two ways: explicitly, by stat- notations revealed that about 80% of the times, ening the type of relationship between two individuals tities mentioned together in the same sentence were (e.g. Mary is John’s wife), or implicitly, by describ- not linked with any social event. Therefore, a siming an event whi</context>
</contexts>
<marker>Doddington, Mitchell, Przybocki, Ramshaw, Strassel, Weischedel, 2004</marker>
<rawString>G. Doddington, A. Mitchell, M. Przybocki, L. Ramshaw, S. Strassel, and R. Weischedel. 2004. The automatic content extraction (ace) program–tasks, data, and evaluation. LREC, pages 837–840.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Domingos</author>
<author>M Richardson</author>
</authors>
<title>Mining the network value of customers.</title>
<date>2003</date>
<booktitle>In Proceedings of the 7th International Conference on Knowledge Discovery and Data Mining,</booktitle>
<pages>57--66</pages>
<contexts>
<context position="3065" citStr="Domingos and Richardson (2003)" startWordPosition="491" endWordPosition="494">nteraction links between people, my work will overcome both these limitations. Moreover, by empirically analyzing large corpora of text from different genres, my work will aid in formulating a comprehensive linguistic theory about the types of linguistic constructs people often use to interact and express their social interactions with others. In the following paragraphs I will explicate these impacts. Impact on current SNA applications: Some of the current social network analysis (SNA) applications that utilize interaction meta-data to construct the underlying social network are discussed by Domingos and Richardson (2003), Kempe et al. (2003), He et al. (2006), Rowe et al. (2007), Lindamood et al. (2009), Zheleva and Getoor (2009). But meta-data captures only part of all the interactions in which people participate. There is a vastly rich network present in text such as the content of emails, comment threads on online social networks, transcribed phone calls. My work will enrich the 111 Proceedings of the ACL-HLT 2011 Student Session, pages 111–116, Portland, OR, USA 19-24 June 2011. c�2011 Association for Computational Linguistics social network that SNA community currently uses by complementing it with the f</context>
</contexts>
<marker>Domingos, Richardson, 2003</marker>
<rawString>P. Domingos and M. Richardson. 2003. Mining the network value of customers. In Proceedings of the 7th International Conference on Knowledge Discovery and Data Mining, pages 57–66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David K Elson</author>
<author>Nicholas Dames</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Extracting social networks from literary fiction.</title>
<date>2010</date>
<booktitle>Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>138--147</pages>
<contexts>
<context position="5901" citStr="Elson et al., 2010" startWordPosition="948" endWordPosition="951">t, to the best of my knowledge, there is no formal comprehensive categorization of social interactions. An early effort to illustrate the importance of such linkages is by Moretti (2005). In his book, Graphs, Maps, Trees: Abstract Models for a Literary History, Moretti presents interesting insights into a novel by looking at its interaction graph. He notes that his models are incomplete because they neither have a notion of weight (number of times two characters interact) nor a notion of direction (mutual or one-directional). There has been recent work that partially addresses these concerns (Elson et al., 2010; Celikyilmaz et al., 2010). They only extract mutual interactions that are signaled by quoted speech. My thesis will go beyond quoted speech and will extract interactions signaled by any linguistic means, in particular verbs of social interaction. Moreover, my research will not only enable extraction of mutual linkages (“who talks to whom” ) but also of one-directional linkages (“who talks about whom”). This will give rise to new applications such as characterization of literary texts based on the type of social network that underlies the narrative. Moreover, analyses of large amounts of rela</context>
</contexts>
<marker>Elson, Dames, McKeown, 2010</marker>
<rawString>David K. Elson, Nicholas Dames, and Kathleen R. McKeown. 2010. Extracting social networks from literary fiction. Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 138–147.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Haussler</author>
</authors>
<title>Convolution kernels on discrete structures.</title>
<date>1999</date>
<tech>Technical report,</tech>
<institution>University of California at Santa Cruz.</institution>
<contexts>
<context position="16303" citStr="Haussler (1999)" startWordPosition="2624" endWordPosition="2625">o play are both in VerbNet class meet-36.3-1. But from a social event perspective, I am not interested in exact synonymy, and in fact it is quite possible that what I am interested in (awareness of the interaction by the event participants) is the same among verbs of the same VerbNet class. In this case, VerbNet will provide a useful abstraction. Future work will also explore FrameNet, which provides a different type of semantic abstraction and explicit semantic relations that are not directly based on syntactic realizations. Scaling convolution kernels: Convolution kernels, first proposed by Haussler (1999), are a convenient way of “naturally” combining a variety of features without having to do fine-grained feature engineering. Collins and Duffy (2002) presented a way of successfully using them for NLP tasks such as parsing and tagging. Since then they have been used for various NLP tasks such as relation extraction (Zelenko et al., 2002; Culotta and Jeffrey, 2004; Nguyen et al., 2009), semantic role labeling (Moschitti et al., 2008), question-answer classification (Moschitti et al., 2007) etc. Convolution kernels calculate the similarity between two objects, like trees or strings, by a recursi</context>
</contexts>
<marker>Haussler, 1999</marker>
<rawString>David Haussler. 1999. Convolution kernels on discrete structures. Technical report, University of California at Santa Cruz.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianming He</author>
<author>Wesley W Chu</author>
<author>Zhenyu Liu</author>
</authors>
<title>Inferring privacy information from social networks. Intelligence and Security Informatics,</title>
<date>2006</date>
<pages>154--165</pages>
<contexts>
<context position="3104" citStr="He et al. (2006)" startWordPosition="499" endWordPosition="502">e both these limitations. Moreover, by empirically analyzing large corpora of text from different genres, my work will aid in formulating a comprehensive linguistic theory about the types of linguistic constructs people often use to interact and express their social interactions with others. In the following paragraphs I will explicate these impacts. Impact on current SNA applications: Some of the current social network analysis (SNA) applications that utilize interaction meta-data to construct the underlying social network are discussed by Domingos and Richardson (2003), Kempe et al. (2003), He et al. (2006), Rowe et al. (2007), Lindamood et al. (2009), Zheleva and Getoor (2009). But meta-data captures only part of all the interactions in which people participate. There is a vastly rich network present in text such as the content of emails, comment threads on online social networks, transcribed phone calls. My work will enrich the 111 Proceedings of the ACL-HLT 2011 Student Session, pages 111–116, Portland, OR, USA 19-24 June 2011. c�2011 Association for Computational Linguistics social network that SNA community currently uses by complementing it with the finer interaction linkages present in te</context>
</contexts>
<marker>He, Chu, Liu, 2006</marker>
<rawString>Jianming He, Wesley W. Chu, and Zhenyu (Victor) Liu. 2006. Inferring privacy information from social networks. Intelligence and Security Informatics, pages 154–165.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daume</author>
</authors>
<title>Frustratingly easy domain adaptation. Annual Meeting-Association For Computational Linguistics.</title>
<date>2007</date>
<marker>Daume, 2007</marker>
<rawString>Hal Daume III. 2007. Frustratingly easy domain adaptation. Annual Meeting-Association For Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Kempe</author>
<author>J Kleinberg</author>
<author>E Tardos</author>
</authors>
<title>Maximizing the spread of influence through a social network.</title>
<date>2003</date>
<booktitle>Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>137--146</pages>
<contexts>
<context position="3086" citStr="Kempe et al. (2003)" startWordPosition="495" endWordPosition="498"> my work will overcome both these limitations. Moreover, by empirically analyzing large corpora of text from different genres, my work will aid in formulating a comprehensive linguistic theory about the types of linguistic constructs people often use to interact and express their social interactions with others. In the following paragraphs I will explicate these impacts. Impact on current SNA applications: Some of the current social network analysis (SNA) applications that utilize interaction meta-data to construct the underlying social network are discussed by Domingos and Richardson (2003), Kempe et al. (2003), He et al. (2006), Rowe et al. (2007), Lindamood et al. (2009), Zheleva and Getoor (2009). But meta-data captures only part of all the interactions in which people participate. There is a vastly rich network present in text such as the content of emails, comment threads on online social networks, transcribed phone calls. My work will enrich the 111 Proceedings of the ACL-HLT 2011 Student Session, pages 111–116, Portland, OR, USA 19-24 June 2011. c�2011 Association for Computational Linguistics social network that SNA community currently uses by complementing it with the finer interaction link</context>
</contexts>
<marker>Kempe, Kleinberg, Tardos, 2003</marker>
<rawString>D. Kempe, J. Kleinberg, and E. Tardos. 2003. Maximizing the spread of influence through a social network. Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 137–146.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beth Levin</author>
</authors>
<title>English verb classes and alternations: A preliminary investigation.</title>
<date>1993</date>
<publisher>The University of Chicago Press.</publisher>
<contexts>
<context position="12432" citStr="Levin, 1993" startWordPosition="2017" endWordPosition="2018">ncy trees cial structures of a story, I manually annotated a and showed that this plays a role in achieving the short version of Alice in Wonderland. On the man- best performance for both social event detection and ually extracted network, I ran social network anal- classification tasks. The reason for choosing such ysis algorithms to answer questions like: who are representations is motivated by extensive studies the most influential characters in the story, which about the regular relation between verb alternations characters have the same social roles and positions. and meaning components (Levin, 1993; Schuler, The most influential characters in the story were de- 2005). This regularity provides a useful generalizatected correctly. Another finding was that characters tion that helps to overcome lexical sparseness. Howappearing in the same scene like Dodo, Lory, Ea- ever, in order to exploit such regularities, there is a glet, Mouse and Duck were assigned the same social need to have access to a representation which makes roles and positions. This pointed out the possibility the predicate-argument structure clear. Dependency 113 representations do this. Phrase structure representations also</context>
<context position="15254" citStr="Levin, 1993" startWordPosition="2448" endWordPosition="2449">ts of dependency and phrase structure trees to formulate new kernels. Specifically, I am exploring ways of incorporating semantic information from VerbNet and FrameNet. This will help me reduce data sparseness and thus improve my current system. I am interested in modeling classes of events which are characterized by the cognitive states of participants– who is aware of whom. The predicate-argument structure of verbs can encode much of this information very efficiently, and classes of verbs express their predicate-argument structure in similar ways. Levin’s verb classes, and Palmer’s VerbNet (Levin, 1993; Schuler, 2005), are based on syntactic similarity between verbs: two verbs are in the same class if and only if they can realize their arguments in the same syntactic patterns. By the Levin Hypothesis, this is because they share meaning elements, and meaning and syntactic realizations of arguments are related. However, this does not mean that verbs in the same Levin or VerbNet class are synonyms; for example, to deliberate and to play are both in VerbNet class meet-36.3-1. But from a social event perspective, I am not interested in exact synonymy, and in fact it is quite possible that what I</context>
</contexts>
<marker>Levin, 1993</marker>
<rawString>Beth Levin. 1993. English verb classes and alternations: A preliminary investigation. The University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lindamood</author>
<author>R Heatherly</author>
<author>M Kantarcioglu</author>
<author>B Thuraisingham</author>
</authors>
<title>Inferring private information using social network dataset.</title>
<date>2009</date>
<publisher>WWW.</publisher>
<contexts>
<context position="3149" citStr="Lindamood et al. (2009)" startWordPosition="507" endWordPosition="511"> empirically analyzing large corpora of text from different genres, my work will aid in formulating a comprehensive linguistic theory about the types of linguistic constructs people often use to interact and express their social interactions with others. In the following paragraphs I will explicate these impacts. Impact on current SNA applications: Some of the current social network analysis (SNA) applications that utilize interaction meta-data to construct the underlying social network are discussed by Domingos and Richardson (2003), Kempe et al. (2003), He et al. (2006), Rowe et al. (2007), Lindamood et al. (2009), Zheleva and Getoor (2009). But meta-data captures only part of all the interactions in which people participate. There is a vastly rich network present in text such as the content of emails, comment threads on online social networks, transcribed phone calls. My work will enrich the 111 Proceedings of the ACL-HLT 2011 Student Session, pages 111–116, Portland, OR, USA 19-24 June 2011. c�2011 Association for Computational Linguistics social network that SNA community currently uses by complementing it with the finer interaction linkages present in text. For example, Rowe et al. (2007) use the s</context>
</contexts>
<marker>Lindamood, Heatherly, Kantarcioglu, Thuraisingham, 2009</marker>
<rawString>J. Lindamood, R. Heatherly, M. Kantarcioglu, and B. Thuraisingham. 2009. Inferring private information using social network dataset. WWW.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franco Moretti</author>
</authors>
<title>Graphs, Maps, Trees: Abstract Models for a Literary History.</title>
<date>2005</date>
<publisher>Verso.</publisher>
<contexts>
<context position="5469" citStr="Moretti (2005)" startWordPosition="882" endWordPosition="883">ommunications, my system will also overcome a known limitation of the Enron email corpus that a significant number of emails were lost at the time of data creation (Carenini et al., 2005). Impact on study of literary and journalistic texts: Sources of social networks that are primarily textual in nature such as literary texts, historical texts, or news articles are currently under-utilized for social network analysis. In fact, to the best of my knowledge, there is no formal comprehensive categorization of social interactions. An early effort to illustrate the importance of such linkages is by Moretti (2005). In his book, Graphs, Maps, Trees: Abstract Models for a Literary History, Moretti presents interesting insights into a novel by looking at its interaction graph. He notes that his models are incomplete because they neither have a notion of weight (number of times two characters interact) nor a notion of direction (mutual or one-directional). There has been recent work that partially addresses these concerns (Elson et al., 2010; Celikyilmaz et al., 2010). They only extract mutual interactions that are signaled by quoted speech. My thesis will go beyond quoted speech and will extract interacti</context>
</contexts>
<marker>Moretti, 2005</marker>
<rawString>Franco Moretti. 2005. Graphs, Maps, Trees: Abstract Models for a Literary History. Verso.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Moschitti</author>
<author>S Quarteroni</author>
<author>R Basili</author>
</authors>
<title>Exploiting syntactic and shallow semantic kernels for question answer classification.</title>
<date>2007</date>
<booktitle>Proceedings of the 45th Conference of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="16796" citStr="Moschitti et al., 2007" startWordPosition="2701" endWordPosition="2704"> not directly based on syntactic realizations. Scaling convolution kernels: Convolution kernels, first proposed by Haussler (1999), are a convenient way of “naturally” combining a variety of features without having to do fine-grained feature engineering. Collins and Duffy (2002) presented a way of successfully using them for NLP tasks such as parsing and tagging. Since then they have been used for various NLP tasks such as relation extraction (Zelenko et al., 2002; Culotta and Jeffrey, 2004; Nguyen et al., 2009), semantic role labeling (Moschitti et al., 2008), question-answer classification (Moschitti et al., 2007) etc. Convolution kernels calculate the similarity between two objects, like trees or strings, by a recursive calculation over the “parts” (substrings, subtrees) of objects. This calculation is usually made computationally efficient by using dynamic programming. But there are two limitations: 1) the computation is still quadratic and hence slow and 2) the features (or parts) that are given high weights at the time of learning remain inaccessible i.e. interpretability of the model becomes difficult. One direction I will explore to make convolution kernels more scalable is the following: The dec</context>
</contexts>
<marker>Moschitti, Quarteroni, Basili, 2007</marker>
<rawString>A. Moschitti, S. Quarteroni, and R. Basili. 2007. Exploiting syntactic and shallow semantic kernels for question answer classification. Proceedings of the 45th Conference of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Moschitti</author>
<author>D Pighin</author>
<author>R Basili</author>
</authors>
<title>Tree kernels for semantic role labeling.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<contexts>
<context position="16739" citStr="Moschitti et al., 2008" startWordPosition="2694" endWordPosition="2698">ntic abstraction and explicit semantic relations that are not directly based on syntactic realizations. Scaling convolution kernels: Convolution kernels, first proposed by Haussler (1999), are a convenient way of “naturally” combining a variety of features without having to do fine-grained feature engineering. Collins and Duffy (2002) presented a way of successfully using them for NLP tasks such as parsing and tagging. Since then they have been used for various NLP tasks such as relation extraction (Zelenko et al., 2002; Culotta and Jeffrey, 2004; Nguyen et al., 2009), semantic role labeling (Moschitti et al., 2008), question-answer classification (Moschitti et al., 2007) etc. Convolution kernels calculate the similarity between two objects, like trees or strings, by a recursive calculation over the “parts” (substrings, subtrees) of objects. This calculation is usually made computationally efficient by using dynamic programming. But there are two limitations: 1) the computation is still quadratic and hence slow and 2) the features (or parts) that are given high weights at the time of learning remain inaccessible i.e. interpretability of the model becomes difficult. One direction I will explore to make co</context>
</contexts>
<marker>Moschitti, Pighin, Basili, 2008</marker>
<rawString>A. Moschitti, D. Pighin, and R. Basili. 2008. Tree kernels for semantic role labeling. Computational Linguistics, 34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Truc-Vien T Nguyen</author>
<author>Alessandro Moschitti</author>
<author>Giuseppe Riccardi</author>
</authors>
<title>Convolution kernels on constituent, dependency and sequential structures for relation extraction.</title>
<date>2009</date>
<booktitle>Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="11435" citStr="Nguyen et al. (2009)" startWordPosition="1858" endWordPosition="1861">ub-categories for each of these broad type events (given there is an event between the encategories based on physical proximity, verbal and tities). I used tree kernels on structures derived from non-verbal interactions. For details and examples of phrase structure trees and dependency trees in conthese sub-categories please refer to Agarwal et al. junction with Support Vector Machines (SVMs) to (2010) solve the tasks. For the design of structures and type (1) [Toujan Faisal], 54, {said} [she] was of kernel, I took motivation from a system proposed {informed} of the refusal by an [Interior by Nguyen et al. (2009) which is a state-of-the-art Ministry committee] overseeing election system for relation extraction. I tried all the kernels preparations. and their combinations proposed by Nguyen et al. As a pilot test to see if creating a social network (2009). I used syntactic and semantic insights to debased on social events can give insight into the so- vise a new structure derived from dependency trees cial structures of a story, I manually annotated a and showed that this plays a role in achieving the short version of Alice in Wonderland. On the man- best performance for both social event detection and</context>
<context position="16690" citStr="Nguyen et al., 2009" startWordPosition="2687" endWordPosition="2690">meNet, which provides a different type of semantic abstraction and explicit semantic relations that are not directly based on syntactic realizations. Scaling convolution kernels: Convolution kernels, first proposed by Haussler (1999), are a convenient way of “naturally” combining a variety of features without having to do fine-grained feature engineering. Collins and Duffy (2002) presented a way of successfully using them for NLP tasks such as parsing and tagging. Since then they have been used for various NLP tasks such as relation extraction (Zelenko et al., 2002; Culotta and Jeffrey, 2004; Nguyen et al., 2009), semantic role labeling (Moschitti et al., 2008), question-answer classification (Moschitti et al., 2007) etc. Convolution kernels calculate the similarity between two objects, like trees or strings, by a recursive calculation over the “parts” (substrings, subtrees) of objects. This calculation is usually made computationally efficient by using dynamic programming. But there are two limitations: 1) the computation is still quadratic and hence slow and 2) the features (or parts) that are given high weights at the time of learning remain inaccessible i.e. interpretability of the model becomes d</context>
</contexts>
<marker>Nguyen, Moschitti, Riccardi, 2009</marker>
<rawString>Truc-Vien T. Nguyen, Alessandro Moschitti, and Giuseppe Riccardi. 2009. Convolution kernels on constituent, dependency and sequential structures for relation extraction. Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raphael Pelossof</author>
<author>Zhiliang Ying</author>
</authors>
<title>The attentive perceptron.</title>
<date>2010</date>
<location>CoRR, abs/1009.5972.</location>
<contexts>
<context position="18688" citStr="Pelossof and Ying (2010)" startWordPosition="3020" endWordPosition="3023">uation 4. N. f(x) = αiyiK(si, x) + b (1) i=1 K(T1,T2) = � hs(T1)hs(T2) (2) s N. f(x) = �αiyi hs(si)hs(x) (3) i=1 s N. f(x) = � αiyihs(si)hs(x) (4) s i=1 The motivation for exchanging these summation signs is that the contribution of larger subtrees to the kernel similarity is strictly less than the contribution of the smaller subtrees. I will investigate the possibility of approximating the decision function of SVM without having to compare all subtrees, in particular large subtrees. I will also investigate if this summation can be calculated in parallel to make the calculation more scalable. Pelossof and Ying (2010) have done recent work on speeding up the Perceptron by stopping the evaluation of features at an early stage if they have high confidence that the example will be classified correctly. Another relevant work to improve the scalability of linear classifiers is due to Clarkson et al. (2010). However, to the best of my knowledge, there is no work that addresses approximation of kernel evaluation for convolution kernels. Interpretability of convolution kernels: As mentioned in the previous paragraph, another disadvantage of using convolution kernels is that interpretability of a model is difficult</context>
</contexts>
<marker>Pelossof, Ying, 2010</marker>
<rawString>Raphael Pelossof and Zhiliang Ying. 2010. The attentive perceptron. CoRR, abs/1009.5972.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Pighin</author>
<author>A Moschitti</author>
</authors>
<title>Reverse engineering of tree kernel feature spaces.</title>
<date>2009</date>
<booktitle>Proceedings of the Conference on EMNLP,</booktitle>
<pages>111--120</pages>
<contexts>
<context position="19327" citStr="Pighin and Moschitti (2009)" startWordPosition="3121" endWordPosition="3124">ecent work on speeding up the Perceptron by stopping the evaluation of features at an early stage if they have high confidence that the example will be classified correctly. Another relevant work to improve the scalability of linear classifiers is due to Clarkson et al. (2010). However, to the best of my knowledge, there is no work that addresses approximation of kernel evaluation for convolution kernels. Interpretability of convolution kernels: As mentioned in the previous paragraph, another disadvantage of using convolution kernels is that interpretability of a model is difficult. Recently, Pighin and Moschitti (2009) proposed an algorithm to linearize convolution kernels. They show that by efficiently encoding the “relevant” fragments generated by tree kernels, it is possible to get insight into the substructures that were given high weights at the time of learning a model. But their system currently returns thousands of such fragments. I will investigate if there is a way of summarizing these fragments into a meaningful set of syntactic and lexical classes. By doing so I will be able to empirically see what types of linguistic constructs are used by people to express different types of social interaction</context>
</contexts>
<marker>Pighin, Moschitti, 2009</marker>
<rawString>D. Pighin and A. Moschitti. 2009. Reverse engineering of tree kernel feature spaces. Proceedings of the Conference on EMNLP, pages 111–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan Rowe</author>
<author>German Creamer</author>
<author>Shlomo Hershkop</author>
<author>Salvatore J Stolfo</author>
</authors>
<title>Automated social hierarchy detection through email network analysis.</title>
<date>2007</date>
<booktitle>Proceedings of the 9th WebKDD and 1st SNA-KDD</booktitle>
<pages>109--117</pages>
<contexts>
<context position="3124" citStr="Rowe et al. (2007)" startWordPosition="503" endWordPosition="506">ations. Moreover, by empirically analyzing large corpora of text from different genres, my work will aid in formulating a comprehensive linguistic theory about the types of linguistic constructs people often use to interact and express their social interactions with others. In the following paragraphs I will explicate these impacts. Impact on current SNA applications: Some of the current social network analysis (SNA) applications that utilize interaction meta-data to construct the underlying social network are discussed by Domingos and Richardson (2003), Kempe et al. (2003), He et al. (2006), Rowe et al. (2007), Lindamood et al. (2009), Zheleva and Getoor (2009). But meta-data captures only part of all the interactions in which people participate. There is a vastly rich network present in text such as the content of emails, comment threads on online social networks, transcribed phone calls. My work will enrich the 111 Proceedings of the ACL-HLT 2011 Student Session, pages 111–116, Portland, OR, USA 19-24 June 2011. c�2011 Association for Computational Linguistics social network that SNA community currently uses by complementing it with the finer interaction linkages present in text. For example, Row</context>
</contexts>
<marker>Rowe, Creamer, Hershkop, Stolfo, 2007</marker>
<rawString>Ryan Rowe, German Creamer, Shlomo Hershkop, and Salvatore J Stolfo. 2007. Automated social hierarchy detection through email network analysis. Proceedings of the 9th WebKDD and 1st SNA-KDD 2007 workshop on Web mining and social network analysis, pages 109–117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin Kipper Schuler</author>
</authors>
<title>Verbnet: a broadcoverage, comprehensive verb lexicon.</title>
<date>2005</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania,</institution>
<location>Philadelphia, PA, USA.</location>
<contexts>
<context position="15270" citStr="Schuler, 2005" startWordPosition="2450" endWordPosition="2451">ncy and phrase structure trees to formulate new kernels. Specifically, I am exploring ways of incorporating semantic information from VerbNet and FrameNet. This will help me reduce data sparseness and thus improve my current system. I am interested in modeling classes of events which are characterized by the cognitive states of participants– who is aware of whom. The predicate-argument structure of verbs can encode much of this information very efficiently, and classes of verbs express their predicate-argument structure in similar ways. Levin’s verb classes, and Palmer’s VerbNet (Levin, 1993; Schuler, 2005), are based on syntactic similarity between verbs: two verbs are in the same class if and only if they can realize their arguments in the same syntactic patterns. By the Levin Hypothesis, this is because they share meaning elements, and meaning and syntactic realizations of arguments are related. However, this does not mean that verbs in the same Levin or VerbNet class are synonyms; for example, to deliberate and to play are both in VerbNet class meet-36.3-1. But from a social event perspective, I am not interested in exact synonymy, and in fact it is quite possible that what I am interested i</context>
</contexts>
<marker>Schuler, 2005</marker>
<rawString>Karin Kipper Schuler. 2005. Verbnet: a broadcoverage, comprehensive verb lexicon. Ph.D. thesis, University of Pennsylvania, Philadelphia, PA, USA. AAI3179808.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Zelenko</author>
<author>C Aone</author>
<author>A Richardella</author>
</authors>
<title>Kernel methods for relation extraction.</title>
<date>2002</date>
<booktitle>In Proceedings of the EMNLP.</booktitle>
<contexts>
<context position="16641" citStr="Zelenko et al., 2002" startWordPosition="2679" endWordPosition="2682">ul abstraction. Future work will also explore FrameNet, which provides a different type of semantic abstraction and explicit semantic relations that are not directly based on syntactic realizations. Scaling convolution kernels: Convolution kernels, first proposed by Haussler (1999), are a convenient way of “naturally” combining a variety of features without having to do fine-grained feature engineering. Collins and Duffy (2002) presented a way of successfully using them for NLP tasks such as parsing and tagging. Since then they have been used for various NLP tasks such as relation extraction (Zelenko et al., 2002; Culotta and Jeffrey, 2004; Nguyen et al., 2009), semantic role labeling (Moschitti et al., 2008), question-answer classification (Moschitti et al., 2007) etc. Convolution kernels calculate the similarity between two objects, like trees or strings, by a recursive calculation over the “parts” (substrings, subtrees) of objects. This calculation is usually made computationally efficient by using dynamic programming. But there are two limitations: 1) the computation is still quadratic and hence slow and 2) the features (or parts) that are given high weights at the time of learning remain inaccess</context>
</contexts>
<marker>Zelenko, Aone, Richardella, 2002</marker>
<rawString>D. Zelenko, C. Aone, and A. Richardella. 2002. Kernel methods for relation extraction. In Proceedings of the EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elena Zheleva</author>
<author>Lise Getoor</author>
</authors>
<title>To join or not to join: the illusion of privacy in social networks with mixed public and private user profiles.</title>
<date>2009</date>
<booktitle>Proceedings of the 18th international conference on World wide web,</booktitle>
<pages>531--540</pages>
<contexts>
<context position="3176" citStr="Zheleva and Getoor (2009)" startWordPosition="512" endWordPosition="515">rge corpora of text from different genres, my work will aid in formulating a comprehensive linguistic theory about the types of linguistic constructs people often use to interact and express their social interactions with others. In the following paragraphs I will explicate these impacts. Impact on current SNA applications: Some of the current social network analysis (SNA) applications that utilize interaction meta-data to construct the underlying social network are discussed by Domingos and Richardson (2003), Kempe et al. (2003), He et al. (2006), Rowe et al. (2007), Lindamood et al. (2009), Zheleva and Getoor (2009). But meta-data captures only part of all the interactions in which people participate. There is a vastly rich network present in text such as the content of emails, comment threads on online social networks, transcribed phone calls. My work will enrich the 111 Proceedings of the ACL-HLT 2011 Student Session, pages 111–116, Portland, OR, USA 19-24 June 2011. c�2011 Association for Computational Linguistics social network that SNA community currently uses by complementing it with the finer interaction linkages present in text. For example, Rowe et al. (2007) use the sender-receiver email links </context>
</contexts>
<marker>Zheleva, Getoor, 2009</marker>
<rawString>Elena Zheleva and Lise Getoor. 2009. To join or not to join: the illusion of privacy in social networks with mixed public and private user profiles. Proceedings of the 18th international conference on World wide web, pages 531–540.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>