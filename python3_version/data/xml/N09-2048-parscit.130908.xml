<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.029334">
<title confidence="0.9727465">
Lexical and Syntactic Priming and Their Impact in Deployed Spoken Dialog
Systems
</title>
<author confidence="0.985476">
Svetlana Stoyanchev and Amanda Stent
</author>
<affiliation confidence="0.959925">
Department of Computer Science
Stony Brook University
</affiliation>
<address confidence="0.834244">
Stony Brook, NY 11794-4400, USA
</address>
<email confidence="0.998575">
svetastenchikova@gmail.com, amanda.stent@stonybrook.edu
</email>
<sectionHeader confidence="0.995641" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999728928571429">
In this paper, we examine user adaptation to
the system’s lexical and syntactic choices in
the context of the deployed Let’s Go! dialog
system. We show that in deployed dialog sys-
tems with real users, as in laboratory experi-
ments, users adapt to the system’s lexical and
syntactic choices. We also show that the sys-
tem’s lexical and syntactic choices, and con-
sequent user adaptation, can have an impact
on recognition of task-related concepts. This
means that system prompt formulation, even
in flexible input dialog systems, can be used
to guide users into producing utterances con-
ducive to task success.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999950431818182">
Numerous studies have shown that people adapt
their syntactic and lexical choices in conversation to
those of their conversational partners, both human
(Brennan, 1996; Pickering et al., 2000; Lockridge
and Brennan, 2002; Reitter et al., 2006) and com-
puter (Branigan et al., 2003; Brennan, 1991; Bren-
nan, 1996; Gustafson et al., 1997; Ward and Litman,
2007). User adaptation to the system’s lexical and
syntactic choices can be particularly useful in flexi-
ble input dialog systems. Limited input dialog sys-
tems, including most commercial systems, require
the user to respond to each system prompt using
only the concept and words currently requested by
the system. Flexible input dialog systems allow the
user to respond to system prompts with concepts
and words in addition to or other than the ones cur-
rently requested, and may even allow the user to
take task initiative. Speech recognition (ASR) accu-
racy in limited input systems is better than in flexi-
ble input systems (Danieli and Gerbino, 1995; Smith
and Gordon, 1997). However, task completion rates
and times are better inflexible input systems (Chu-
Carroll and Nickerson, 2000; Smith and Gordon,
1997). With user adaptation, inflexible input dia-
log systems prompts can be formulated to maximize
ASR accuracy and reduce the number of ASR time-
outs (Sheeder and Balogh, 2003).
Previous research on user adaptation to dialog
systems was conducted in laboratory settings. How-
ever, the behavior of recruited subjects in a quiet
laboratory may differ from that of real users in the
noisy world (Ai et al., 2007). Here we present the
first study, to the best of our knowledge, that in-
vestigates the adaptive behavior of real users of a
live dialog system. We analyze dialogs from CMU’s
Let’s Go! dialog system (Raux et al., 2005). We
look at the effects of the system’s lexical and syn-
tactic choices on: 1) lexical and syntactic choices
in user responses; and 2) concept identification rates
for user responses. We confirm prior results showing
that users adapt to the system’s lexical and syntactic
choices. We also show that particular choices for
system prompts can lead to higher concept identifi-
cation rates.
</bodyText>
<sectionHeader confidence="0.99566" genericHeader="method">
2 Experimental Method
</sectionHeader>
<bodyText confidence="0.9999882">
We conducted our experiment using the Let’s Go!
telephone-based spoken dialog system that provides
information about bus routes in Pittsburgh (Raux
et al., 2005). The users are naive callers from the
general population seeking information about bus
</bodyText>
<page confidence="0.986535">
189
</page>
<note confidence="0.372981">
Proceedings of NAACL HLT 2009: Short Papers, pages 189–192,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.9724003">
condition request departure confirm departure request arrival confirm arrival
location location location location
Where are you leav- Leaving from X, is this Where are you going Going to X, is this
ing from? correct? to? correct
Where are you leav- From X, is this cor- Where are you going To X, is this correct
ing from? rect? to?
What is the place of X, is this correct? What is the place of X, is this correct
your departure your arrival?
Where do you want to You want to leave from Where do you want to You want to go to X,
leave from? X, is this correct? go to? is this correct
</bodyText>
<tableCaption confidence="0.999725">
Table 1: Experimental conditions
</tableCaption>
<table confidence="0.997496882352941">
Spkr Task type Utterance
Sys Open Welcome to the CMU Let’s
Usr Go bus information system.
What can I do for you?
61A schedule
Sys Request Where do you wanna leave
Usr Departure from?
Location From downtown
Sys Confirm Leaving from downtown. Is
Usr Departure this correct?
Location Yes
Sys Request Where are you going to?
Usr Arrival Oakland
Location
Sys Confirm Going to Waterfront. Is this
Usr Arrival correct?
Location No, to Oakland
</table>
<figureCaption confidence="0.997857">
Figure 1: Dialog extract from Let’s Go! data
</figureCaption>
<bodyText confidence="0.937402772727273">
schedules. In order to provide the user with route
information, Let’s Go! elicits a departure location,
a destination, a departure time, and optionally a bus
route number. Each concept value provided by the
user is explicitly confirmed by the system. Figure 1
shows an example dialog with the system.
Let’s Go! is a flexible input dialog system. The
user can respond to a system prompt using a single
word or short phrase, e.g. Downtown, or a complete
sentence, e.g. I am leaving from downtown1.
We ran four experimental conditions for two
months. The conditions varied in the lexical choice
and syntax of system prompts for two system re-
quest location tasks and two system confirm loca-
tion tasks (see Table 1). System prompts differed
1The user response can also contain concepts not requested
in the prompt, e.g. specifying departure location and bus num-
ber in one response.
by presence of a verb (to leave, to go) or a preposi-
tion (to, from), and by the syntactic form of the verb.
The request location prompt contained both a verb
and a preposition in the experimental conditions (1,
</bodyText>
<listItem confidence="0.9771955">
3, and 4). The confirm location prompt contained
both a verb and a preposition in conditions 1 and 4,
only a preposition in condition 2, and neither verb
nor preposition in condition 3. In conditions 1 and
4, both request and confirmation prompts differed in
the verb form (leaving/leave, going/go).
</listItem>
<bodyText confidence="0.999923090909091">
2184 dialogs were used for this analysis. For each
experimental condition, we counted the percentages
of verbs, verb forms, prepositions, and locations in
the ASR output for user responses to system request
location and confirm location prompts. Although
the data contains recognition errors, the only differ-
ence in system functionality between the conditions
is the formulation of the system prompt, so any sta-
tistically significant difference in user responses be-
tween different conditions can be attributed to the
formulation of the prompt.
</bodyText>
<sectionHeader confidence="0.994121" genericHeader="method">
3 Syntactic Adaptation
</sectionHeader>
<bodyText confidence="0.997821583333333">
We analyze whether users are more likely to use ac-
tion verbs (leave, leaving, go, or going) and prepo-
sitions (to, from) in response to system prompts that
use a verb or a preposition. This analysis is interest-
ing because ASR partially relies on context words,
words related to a particular concept type such as
place, time or bus route. For example, the likelihood
of correctly recognizing the location Oakland in the
utterance “going to Oakland” is different from the
likelihood of correctly recognizing the single word
utterance “Oakland”.
Table 2 shows the percentages of user responses
</bodyText>
<page confidence="0.966133">
190
</page>
<table confidence="0.9998675">
Cond. Sys uses Sys uses % with % with
verb prep verb prep
Responses to request location prompt
yes yes 2.3% * 5.6%
yes yes 1.9% 4.3%
no no 0.7% 4.5%
yes yes 2.4%* 6.0%
Responses to confirm location prompt
yes yes 15.7% * 41 23.4%
no yes 3.9% 16.9%
no no 6.4% 12.7%
yes yes 10.8% 22.0%
</table>
<tableCaption confidence="0.9115396">
Table 2: Percentages of user utterances containing verbs
and prepositions. * indicates a statistically significant dif-
ference (p&lt;0.01) from the no action verb condition (3).
41 indicates a statistically significant difference from the
no action verb in confirmation condition (2).
</tableCaption>
<bodyText confidence="0.999906965517241">
in each experimental condition that contain a verb
and/or a preposition. We observe adaptation to the
presence of a verb in user responses to request lo-
cation prompts. The prompts in conditions 1, 2 and
4 contain a verb, while those in condition 3 do not.
The differences between conditions 1 and 3, and be-
tween conditions 4 and 3, are statistically significant
(p&lt;0.01)2. The difference between conditions 2 and
3 is not statistically significant, perhaps due to the
absence of a verb in a prior confirm location prompt.
A similar adaptation to the presence of a verb in
the system prompt is seen in user responses to con-
firm location prompts. The prompts in conditions
1 and 4 contain a verb while those in conditions 2
and 3 do not. The differences between conditions
1 and 2, and between conditions 1 and 3, are statis-
tically significant (p&lt;.01), while the difference be-
tween conditions 4 and 2 exhibits a trend. We hy-
pothesize that the lack of the statistically significant
differences between conditions 4 and 2, and condi-
tions 4 and 3, is caused by the low relative frequency
in our data of dialogs in condition 4.
We do not find statistically significant differences
in the use of prepositions. However, we observe a
trend showing higher likelihood of a preposition in
user responses to confirm location in the conditions
where the system uses a preposition. Prepositions
are short closed-class context words that are more
likely to be misrecognized (Goldwater et al., 2008).
</bodyText>
<footnote confidence="0.966375">
2All analyses in this section are t-tests with Bonferroni ad-
justment.
</footnote>
<table confidence="0.9999218">
Condition/ LEAVING LEAVE total
User’s verb (progressive) (simple)
(1) Progressive 74.5% 25.5% 55
(3) Neutral 61.3% 38.7% 31
(4) Simple 43% 57% 42
Condition/ GOING GO total
User’s verb (progressive) (simple)
(1) Progressive 84.4% 15.6% 45
(3) Neutral 66.6% 33.4% 21
(4) Simple 46.5% 53.5% 43
</table>
<tableCaption confidence="0.999919">
Table 3: Usage of verb forms in user utterances
</tableCaption>
<bodyText confidence="0.993755">
Hence, more data (or human transcription) may be
required to see a statistically significant effect.
</bodyText>
<sectionHeader confidence="0.985787" genericHeader="method">
4 Lexical Adaptation
</sectionHeader>
<bodyText confidence="0.999985190476191">
We analyze whether system choice of a particular
verb form affects user choice of verb form. For
this analysis we only consider user utterances in
response to a request location or confirm location
prompt that contain a concept and at least one of the
verb forms leaving, going, leave, or go3.
Table 3 shows the total counts and percentages
of each verb form in the progressive form condition
(condition 1), and the neutral condition (condition
3), and the simple form condition (condition 4)4.
We find that the system’s choice of verb form has
a statistically significant impact on the user’s choice
(x2 test, p&lt;0.01). In the neutral condition, users
are more likely to choose the progressive verb form.
In the progressive form condition, this preference in-
creases by 13.2% for the verb to leave, and by 17.8%
for the verb to go. By contrast, in the simple form
condition, this preference decreases by 18.3% for
the verb to leave and by 20.1% for the verb to go,
making users slightly more likely to choose the sim-
ple verb form than the progressive verb form.
</bodyText>
<sectionHeader confidence="0.7203625" genericHeader="method">
5 Effect of Adaptation on Speech
Recognition Performance
</sectionHeader>
<bodyText confidence="0.999383666666667">
The correct identification and recognition of task-
related concepts in user utterances is an essential
functionality of a dialog system. Table 4 shows
</bodyText>
<footnote confidence="0.999123">
3Such utterances constitute 3% of all user responses to all
request and confirm place prompts in our data.
4We ignore condition 2 where the verb is used only in the
request prompt.
</footnote>
<page confidence="0.987145">
191
</page>
<table confidence="0.999420666666667">
System Arrival Departure
prompt request request
72.2% * 63.8%
77.4% 61.0%
74.5% * 61.5%
82.0% 66.0%
</table>
<tableCaption confidence="0.96713475">
Table 4: Concept identification rates following request
location prompts. * indicates a statistically significant
difference (p&lt;0.01 with Bonferroni adjustment) from
condition 4.
</tableCaption>
<bodyText confidence="0.9998727">
the percentage of user utterances following a re-
quest location prompt that contain an automatically-
recognized location concept. Condition 4, where the
system prompt uses the verb form to leave, achieves
the highest concept identification rates. The differ-
ences in concept identification rates between condi-
tions 1 and 4, and between conditions 3 and 4, are
statistically significant for request arrival location
(t-test, p&lt;.01). Other differences are not statistically
significant, perhaps due to lack of data.
</bodyText>
<sectionHeader confidence="0.998494" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999958533333334">
In this paper, we showed that in deployed dialog sys-
tems with real users, as in laboratory experiments,
users adapt to the lexical and syntactic choices of the
system. We also showed that user adaptation to sys-
tem prompts can have an impact on recognition of
task-related concepts. This means that the formula-
tion of system prompts, even inflexible input dialog
systems, can be used to guide users into producing
utterances conducive to task success.
In future work, we plan to confirm these results
using transcribed data. We also plan additional ex-
periments on adaptation in Let’s Go!, including an
analysis of the time course of adaptation and further
analyses of the impact of adaptation on ASR perfor-
mance.
</bodyText>
<sectionHeader confidence="0.99885" genericHeader="acknowledgments">
7 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999993333333333">
We would like to thank the Let’s Go! researchers at
CMU for making Let’s Go! available. This research
was supported by the NSF under grant no. 0325188.
</bodyText>
<sectionHeader confidence="0.998403" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999668945454546">
H. Ai, A. Raux, D. Bohus, M. Eskenazi, and D. Lit-
man. 2007. Comparing spoken dialog corpora col-
lected with recruited subjects versus real users. In Pro-
ceedings of SIGDial.
H. Branigan, M. Pickering, J. Pearson, J. McLean, and
C. Nass. 2003. Syntactic alignment between comput-
ers and people: the role of belief about mental states.
In Proceedings of CogSci.
S. Brennan. 1991. Conversation with and through com-
puters. User Modeling and User-Adapted Interaction,
1(1):67–86.
S. Brennan. 1996. Lexical entrainment in spontaneous
dialog. In Proceedings ofISSD.
J. Chu-Carroll and J. Nickerson. 2000. Evaluating au-
tomatic dialogue strategy adaptation for a spoken dia-
logue system. In Proceedings ofNAACL.
M. Danieli and E. Gerbino. 1995. Metrics for evaluat-
ing dialogue strategies in a spoken language system.
In Proceedings of the AAAI Spring Symposium on Em-
pirical Methods in Discourse Interpretation and Gen-
eration.
S. Goldwater, D. Jurafsky, and C. Manning. 2008.
Which words are hard to recognize? Lexical, prosodic,
and disfluency factors that increase asr error rates. In
Proceedings ofACL/HLT.
J. Gustafson, A. Larsson, R. Carlson, and K. Hellman.
1997. How do system questions influence lexical
choices in user answers? In Proceedings of Eu-
rospeech.
C. Lockridge and S. Brennan. 2002. Addressees’ needs
influence speakers’ early syntactic choices. Psycho-
nomics Bulletin and Review.
M. Pickering, H. Branigan, A. Cleland, and A. Stew-
art. 2000. Activation of syntactic priming during
language production. Journal of Psycholinguistic Re-
search, 29(2):205–216.
A. Raux, B. Langner, A. Black, and M Eskenazi. 2005.
Let’s Go public! taking a spoken dialog system to the
real world. In Proceedings ofEurospeech.
E. Reitter, J. Moore, and F. Keller. 2006. Priming of syn-
tactic rules in task-oriented dialogue and spontaneous
conversation. In Proceedings of CogSci.
T. Sheeder and J. Balogh. 2003. Say it like you mean
it: priming for structure in caller responses to a spoken
dialog system. International Journal of Speech Tech-
nology, 6(2):103–111.
R. Smith and S. Gordon. 1997. Effects of variable initia-
tive on linguistic behavior in human-computer spoken
natural language dialogue. Computational Linguistics,
23(1):141–168.
A. Ward and D. Litman. 2007. Automatically measuring
lexical and acoustic/prosodic convergence in tutorial
dialog corpora. In Proceedings of the SLaTE Work-
shop on Speech and Language Technology in Educa-
tion.
</reference>
<page confidence="0.998166">
192
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.282519">
<title confidence="0.999217">Lexical and Syntactic Priming and Their Impact in Deployed Spoken Dialog Systems</title>
<author confidence="0.789501">Stoyanchev</author>
<affiliation confidence="0.908871">Department of Computer</affiliation>
<author confidence="0.4850345">Stony Brook Stony Brook</author>
<author confidence="0.4850345">NY</author>
<email confidence="0.999745">svetastenchikova@gmail.com,amanda.stent@stonybrook.edu</email>
<abstract confidence="0.996764266666667">In this paper, we examine user adaptation to the system’s lexical and syntactic choices in context of the deployed Go! system. We show that in deployed dialog systems with real users, as in laboratory experiments, users adapt to the system’s lexical and syntactic choices. We also show that the system’s lexical and syntactic choices, and consequent user adaptation, can have an impact on recognition of task-related concepts. This means that system prompt formulation, even input systems, can be used to guide users into producing utterances conducive to task success.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>H Ai</author>
<author>A Raux</author>
<author>D Bohus</author>
<author>M Eskenazi</author>
<author>D Litman</author>
</authors>
<title>Comparing spoken dialog corpora collected with recruited subjects versus real users.</title>
<date>2007</date>
<booktitle>In Proceedings of SIGDial.</booktitle>
<contexts>
<context position="2453" citStr="Ai et al., 2007" startWordPosition="383" endWordPosition="386"> in flexible input systems (Danieli and Gerbino, 1995; Smith and Gordon, 1997). However, task completion rates and times are better inflexible input systems (ChuCarroll and Nickerson, 2000; Smith and Gordon, 1997). With user adaptation, inflexible input dialog systems prompts can be formulated to maximize ASR accuracy and reduce the number of ASR timeouts (Sheeder and Balogh, 2003). Previous research on user adaptation to dialog systems was conducted in laboratory settings. However, the behavior of recruited subjects in a quiet laboratory may differ from that of real users in the noisy world (Ai et al., 2007). Here we present the first study, to the best of our knowledge, that investigates the adaptive behavior of real users of a live dialog system. We analyze dialogs from CMU’s Let’s Go! dialog system (Raux et al., 2005). We look at the effects of the system’s lexical and syntactic choices on: 1) lexical and syntactic choices in user responses; and 2) concept identification rates for user responses. We confirm prior results showing that users adapt to the system’s lexical and syntactic choices. We also show that particular choices for system prompts can lead to higher concept identification rates</context>
</contexts>
<marker>Ai, Raux, Bohus, Eskenazi, Litman, 2007</marker>
<rawString>H. Ai, A. Raux, D. Bohus, M. Eskenazi, and D. Litman. 2007. Comparing spoken dialog corpora collected with recruited subjects versus real users. In Proceedings of SIGDial.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Branigan</author>
<author>M Pickering</author>
<author>J Pearson</author>
<author>J McLean</author>
<author>C Nass</author>
</authors>
<title>Syntactic alignment between computers and people: the role of belief about mental states.</title>
<date>2003</date>
<booktitle>In Proceedings of CogSci.</booktitle>
<contexts>
<context position="1168" citStr="Branigan et al., 2003" startWordPosition="173" endWordPosition="176">ic choices. We also show that the system’s lexical and syntactic choices, and consequent user adaptation, can have an impact on recognition of task-related concepts. This means that system prompt formulation, even in flexible input dialog systems, can be used to guide users into producing utterances conducive to task success. 1 Introduction Numerous studies have shown that people adapt their syntactic and lexical choices in conversation to those of their conversational partners, both human (Brennan, 1996; Pickering et al., 2000; Lockridge and Brennan, 2002; Reitter et al., 2006) and computer (Branigan et al., 2003; Brennan, 1991; Brennan, 1996; Gustafson et al., 1997; Ward and Litman, 2007). User adaptation to the system’s lexical and syntactic choices can be particularly useful in flexible input dialog systems. Limited input dialog systems, including most commercial systems, require the user to respond to each system prompt using only the concept and words currently requested by the system. Flexible input dialog systems allow the user to respond to system prompts with concepts and words in addition to or other than the ones currently requested, and may even allow the user to take task initiative. Spee</context>
</contexts>
<marker>Branigan, Pickering, Pearson, McLean, Nass, 2003</marker>
<rawString>H. Branigan, M. Pickering, J. Pearson, J. McLean, and C. Nass. 2003. Syntactic alignment between computers and people: the role of belief about mental states. In Proceedings of CogSci.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Brennan</author>
</authors>
<title>Conversation with and through computers. User Modeling and User-Adapted Interaction,</title>
<date>1991</date>
<contexts>
<context position="1183" citStr="Brennan, 1991" startWordPosition="177" endWordPosition="178">w that the system’s lexical and syntactic choices, and consequent user adaptation, can have an impact on recognition of task-related concepts. This means that system prompt formulation, even in flexible input dialog systems, can be used to guide users into producing utterances conducive to task success. 1 Introduction Numerous studies have shown that people adapt their syntactic and lexical choices in conversation to those of their conversational partners, both human (Brennan, 1996; Pickering et al., 2000; Lockridge and Brennan, 2002; Reitter et al., 2006) and computer (Branigan et al., 2003; Brennan, 1991; Brennan, 1996; Gustafson et al., 1997; Ward and Litman, 2007). User adaptation to the system’s lexical and syntactic choices can be particularly useful in flexible input dialog systems. Limited input dialog systems, including most commercial systems, require the user to respond to each system prompt using only the concept and words currently requested by the system. Flexible input dialog systems allow the user to respond to system prompts with concepts and words in addition to or other than the ones currently requested, and may even allow the user to take task initiative. Speech recognition </context>
</contexts>
<marker>Brennan, 1991</marker>
<rawString>S. Brennan. 1991. Conversation with and through computers. User Modeling and User-Adapted Interaction, 1(1):67–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Brennan</author>
</authors>
<title>Lexical entrainment in spontaneous dialog.</title>
<date>1996</date>
<booktitle>In Proceedings ofISSD.</booktitle>
<contexts>
<context position="1056" citStr="Brennan, 1996" startWordPosition="156" endWordPosition="157">g systems with real users, as in laboratory experiments, users adapt to the system’s lexical and syntactic choices. We also show that the system’s lexical and syntactic choices, and consequent user adaptation, can have an impact on recognition of task-related concepts. This means that system prompt formulation, even in flexible input dialog systems, can be used to guide users into producing utterances conducive to task success. 1 Introduction Numerous studies have shown that people adapt their syntactic and lexical choices in conversation to those of their conversational partners, both human (Brennan, 1996; Pickering et al., 2000; Lockridge and Brennan, 2002; Reitter et al., 2006) and computer (Branigan et al., 2003; Brennan, 1991; Brennan, 1996; Gustafson et al., 1997; Ward and Litman, 2007). User adaptation to the system’s lexical and syntactic choices can be particularly useful in flexible input dialog systems. Limited input dialog systems, including most commercial systems, require the user to respond to each system prompt using only the concept and words currently requested by the system. Flexible input dialog systems allow the user to respond to system prompts with concepts and words in a</context>
</contexts>
<marker>Brennan, 1996</marker>
<rawString>S. Brennan. 1996. Lexical entrainment in spontaneous dialog. In Proceedings ofISSD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Chu-Carroll</author>
<author>J Nickerson</author>
</authors>
<title>Evaluating automatic dialogue strategy adaptation for a spoken dialogue system.</title>
<date>2000</date>
<booktitle>In Proceedings ofNAACL.</booktitle>
<marker>Chu-Carroll, Nickerson, 2000</marker>
<rawString>J. Chu-Carroll and J. Nickerson. 2000. Evaluating automatic dialogue strategy adaptation for a spoken dialogue system. In Proceedings ofNAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Danieli</author>
<author>E Gerbino</author>
</authors>
<title>Metrics for evaluating dialogue strategies in a spoken language system.</title>
<date>1995</date>
<booktitle>In Proceedings of the AAAI Spring Symposium on Empirical Methods in Discourse Interpretation and Generation.</booktitle>
<contexts>
<context position="1890" citStr="Danieli and Gerbino, 1995" startWordPosition="292" endWordPosition="295">o the system’s lexical and syntactic choices can be particularly useful in flexible input dialog systems. Limited input dialog systems, including most commercial systems, require the user to respond to each system prompt using only the concept and words currently requested by the system. Flexible input dialog systems allow the user to respond to system prompts with concepts and words in addition to or other than the ones currently requested, and may even allow the user to take task initiative. Speech recognition (ASR) accuracy in limited input systems is better than in flexible input systems (Danieli and Gerbino, 1995; Smith and Gordon, 1997). However, task completion rates and times are better inflexible input systems (ChuCarroll and Nickerson, 2000; Smith and Gordon, 1997). With user adaptation, inflexible input dialog systems prompts can be formulated to maximize ASR accuracy and reduce the number of ASR timeouts (Sheeder and Balogh, 2003). Previous research on user adaptation to dialog systems was conducted in laboratory settings. However, the behavior of recruited subjects in a quiet laboratory may differ from that of real users in the noisy world (Ai et al., 2007). Here we present the first study, to</context>
</contexts>
<marker>Danieli, Gerbino, 1995</marker>
<rawString>M. Danieli and E. Gerbino. 1995. Metrics for evaluating dialogue strategies in a spoken language system. In Proceedings of the AAAI Spring Symposium on Empirical Methods in Discourse Interpretation and Generation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Goldwater</author>
<author>D Jurafsky</author>
<author>C Manning</author>
</authors>
<title>Which words are hard to recognize? Lexical, prosodic, and disfluency factors that increase asr error rates.</title>
<date>2008</date>
<booktitle>In Proceedings ofACL/HLT.</booktitle>
<contexts>
<context position="9163" citStr="Goldwater et al., 2008" startWordPosition="1511" endWordPosition="1514">e difference between conditions 4 and 2 exhibits a trend. We hypothesize that the lack of the statistically significant differences between conditions 4 and 2, and conditions 4 and 3, is caused by the low relative frequency in our data of dialogs in condition 4. We do not find statistically significant differences in the use of prepositions. However, we observe a trend showing higher likelihood of a preposition in user responses to confirm location in the conditions where the system uses a preposition. Prepositions are short closed-class context words that are more likely to be misrecognized (Goldwater et al., 2008). 2All analyses in this section are t-tests with Bonferroni adjustment. Condition/ LEAVING LEAVE total User’s verb (progressive) (simple) (1) Progressive 74.5% 25.5% 55 (3) Neutral 61.3% 38.7% 31 (4) Simple 43% 57% 42 Condition/ GOING GO total User’s verb (progressive) (simple) (1) Progressive 84.4% 15.6% 45 (3) Neutral 66.6% 33.4% 21 (4) Simple 46.5% 53.5% 43 Table 3: Usage of verb forms in user utterances Hence, more data (or human transcription) may be required to see a statistically significant effect. 4 Lexical Adaptation We analyze whether system choice of a particular verb form affects </context>
</contexts>
<marker>Goldwater, Jurafsky, Manning, 2008</marker>
<rawString>S. Goldwater, D. Jurafsky, and C. Manning. 2008. Which words are hard to recognize? Lexical, prosodic, and disfluency factors that increase asr error rates. In Proceedings ofACL/HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Gustafson</author>
<author>A Larsson</author>
<author>R Carlson</author>
<author>K Hellman</author>
</authors>
<title>How do system questions influence lexical choices in user answers?</title>
<date>1997</date>
<booktitle>In Proceedings of Eurospeech.</booktitle>
<contexts>
<context position="1222" citStr="Gustafson et al., 1997" startWordPosition="182" endWordPosition="185">d syntactic choices, and consequent user adaptation, can have an impact on recognition of task-related concepts. This means that system prompt formulation, even in flexible input dialog systems, can be used to guide users into producing utterances conducive to task success. 1 Introduction Numerous studies have shown that people adapt their syntactic and lexical choices in conversation to those of their conversational partners, both human (Brennan, 1996; Pickering et al., 2000; Lockridge and Brennan, 2002; Reitter et al., 2006) and computer (Branigan et al., 2003; Brennan, 1991; Brennan, 1996; Gustafson et al., 1997; Ward and Litman, 2007). User adaptation to the system’s lexical and syntactic choices can be particularly useful in flexible input dialog systems. Limited input dialog systems, including most commercial systems, require the user to respond to each system prompt using only the concept and words currently requested by the system. Flexible input dialog systems allow the user to respond to system prompts with concepts and words in addition to or other than the ones currently requested, and may even allow the user to take task initiative. Speech recognition (ASR) accuracy in limited input systems</context>
</contexts>
<marker>Gustafson, Larsson, Carlson, Hellman, 1997</marker>
<rawString>J. Gustafson, A. Larsson, R. Carlson, and K. Hellman. 1997. How do system questions influence lexical choices in user answers? In Proceedings of Eurospeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Lockridge</author>
<author>S Brennan</author>
</authors>
<title>Addressees’ needs influence speakers’ early syntactic choices. Psychonomics Bulletin and Review.</title>
<date>2002</date>
<contexts>
<context position="1109" citStr="Lockridge and Brennan, 2002" startWordPosition="162" endWordPosition="165">tory experiments, users adapt to the system’s lexical and syntactic choices. We also show that the system’s lexical and syntactic choices, and consequent user adaptation, can have an impact on recognition of task-related concepts. This means that system prompt formulation, even in flexible input dialog systems, can be used to guide users into producing utterances conducive to task success. 1 Introduction Numerous studies have shown that people adapt their syntactic and lexical choices in conversation to those of their conversational partners, both human (Brennan, 1996; Pickering et al., 2000; Lockridge and Brennan, 2002; Reitter et al., 2006) and computer (Branigan et al., 2003; Brennan, 1991; Brennan, 1996; Gustafson et al., 1997; Ward and Litman, 2007). User adaptation to the system’s lexical and syntactic choices can be particularly useful in flexible input dialog systems. Limited input dialog systems, including most commercial systems, require the user to respond to each system prompt using only the concept and words currently requested by the system. Flexible input dialog systems allow the user to respond to system prompts with concepts and words in addition to or other than the ones currently requested</context>
</contexts>
<marker>Lockridge, Brennan, 2002</marker>
<rawString>C. Lockridge and S. Brennan. 2002. Addressees’ needs influence speakers’ early syntactic choices. Psychonomics Bulletin and Review.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pickering</author>
<author>H Branigan</author>
<author>A Cleland</author>
<author>A Stewart</author>
</authors>
<title>Activation of syntactic priming during language production.</title>
<date>2000</date>
<journal>Journal of Psycholinguistic Research,</journal>
<volume>29</volume>
<issue>2</issue>
<contexts>
<context position="1080" citStr="Pickering et al., 2000" startWordPosition="158" endWordPosition="161">real users, as in laboratory experiments, users adapt to the system’s lexical and syntactic choices. We also show that the system’s lexical and syntactic choices, and consequent user adaptation, can have an impact on recognition of task-related concepts. This means that system prompt formulation, even in flexible input dialog systems, can be used to guide users into producing utterances conducive to task success. 1 Introduction Numerous studies have shown that people adapt their syntactic and lexical choices in conversation to those of their conversational partners, both human (Brennan, 1996; Pickering et al., 2000; Lockridge and Brennan, 2002; Reitter et al., 2006) and computer (Branigan et al., 2003; Brennan, 1991; Brennan, 1996; Gustafson et al., 1997; Ward and Litman, 2007). User adaptation to the system’s lexical and syntactic choices can be particularly useful in flexible input dialog systems. Limited input dialog systems, including most commercial systems, require the user to respond to each system prompt using only the concept and words currently requested by the system. Flexible input dialog systems allow the user to respond to system prompts with concepts and words in addition to or other than</context>
</contexts>
<marker>Pickering, Branigan, Cleland, Stewart, 2000</marker>
<rawString>M. Pickering, H. Branigan, A. Cleland, and A. Stewart. 2000. Activation of syntactic priming during language production. Journal of Psycholinguistic Research, 29(2):205–216.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Raux</author>
<author>B Langner</author>
<author>A Black</author>
<author>M Eskenazi</author>
</authors>
<title>Let’s Go public! taking a spoken dialog system to the real world.</title>
<date>2005</date>
<booktitle>In Proceedings ofEurospeech.</booktitle>
<contexts>
<context position="2670" citStr="Raux et al., 2005" startWordPosition="422" endWordPosition="425">With user adaptation, inflexible input dialog systems prompts can be formulated to maximize ASR accuracy and reduce the number of ASR timeouts (Sheeder and Balogh, 2003). Previous research on user adaptation to dialog systems was conducted in laboratory settings. However, the behavior of recruited subjects in a quiet laboratory may differ from that of real users in the noisy world (Ai et al., 2007). Here we present the first study, to the best of our knowledge, that investigates the adaptive behavior of real users of a live dialog system. We analyze dialogs from CMU’s Let’s Go! dialog system (Raux et al., 2005). We look at the effects of the system’s lexical and syntactic choices on: 1) lexical and syntactic choices in user responses; and 2) concept identification rates for user responses. We confirm prior results showing that users adapt to the system’s lexical and syntactic choices. We also show that particular choices for system prompts can lead to higher concept identification rates. 2 Experimental Method We conducted our experiment using the Let’s Go! telephone-based spoken dialog system that provides information about bus routes in Pittsburgh (Raux et al., 2005). The users are naive callers fr</context>
</contexts>
<marker>Raux, Langner, Black, Eskenazi, 2005</marker>
<rawString>A. Raux, B. Langner, A. Black, and M Eskenazi. 2005. Let’s Go public! taking a spoken dialog system to the real world. In Proceedings ofEurospeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Reitter</author>
<author>J Moore</author>
<author>F Keller</author>
</authors>
<title>Priming of syntactic rules in task-oriented dialogue and spontaneous conversation.</title>
<date>2006</date>
<booktitle>In Proceedings of CogSci.</booktitle>
<contexts>
<context position="1132" citStr="Reitter et al., 2006" startWordPosition="166" endWordPosition="169"> to the system’s lexical and syntactic choices. We also show that the system’s lexical and syntactic choices, and consequent user adaptation, can have an impact on recognition of task-related concepts. This means that system prompt formulation, even in flexible input dialog systems, can be used to guide users into producing utterances conducive to task success. 1 Introduction Numerous studies have shown that people adapt their syntactic and lexical choices in conversation to those of their conversational partners, both human (Brennan, 1996; Pickering et al., 2000; Lockridge and Brennan, 2002; Reitter et al., 2006) and computer (Branigan et al., 2003; Brennan, 1991; Brennan, 1996; Gustafson et al., 1997; Ward and Litman, 2007). User adaptation to the system’s lexical and syntactic choices can be particularly useful in flexible input dialog systems. Limited input dialog systems, including most commercial systems, require the user to respond to each system prompt using only the concept and words currently requested by the system. Flexible input dialog systems allow the user to respond to system prompts with concepts and words in addition to or other than the ones currently requested, and may even allow th</context>
</contexts>
<marker>Reitter, Moore, Keller, 2006</marker>
<rawString>E. Reitter, J. Moore, and F. Keller. 2006. Priming of syntactic rules in task-oriented dialogue and spontaneous conversation. In Proceedings of CogSci.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Sheeder</author>
<author>J Balogh</author>
</authors>
<title>Say it like you mean it: priming for structure in caller responses to a spoken dialog system.</title>
<date>2003</date>
<journal>International Journal of Speech Technology,</journal>
<volume>6</volume>
<issue>2</issue>
<contexts>
<context position="2221" citStr="Sheeder and Balogh, 2003" startWordPosition="344" endWordPosition="347">er to respond to system prompts with concepts and words in addition to or other than the ones currently requested, and may even allow the user to take task initiative. Speech recognition (ASR) accuracy in limited input systems is better than in flexible input systems (Danieli and Gerbino, 1995; Smith and Gordon, 1997). However, task completion rates and times are better inflexible input systems (ChuCarroll and Nickerson, 2000; Smith and Gordon, 1997). With user adaptation, inflexible input dialog systems prompts can be formulated to maximize ASR accuracy and reduce the number of ASR timeouts (Sheeder and Balogh, 2003). Previous research on user adaptation to dialog systems was conducted in laboratory settings. However, the behavior of recruited subjects in a quiet laboratory may differ from that of real users in the noisy world (Ai et al., 2007). Here we present the first study, to the best of our knowledge, that investigates the adaptive behavior of real users of a live dialog system. We analyze dialogs from CMU’s Let’s Go! dialog system (Raux et al., 2005). We look at the effects of the system’s lexical and syntactic choices on: 1) lexical and syntactic choices in user responses; and 2) concept identific</context>
</contexts>
<marker>Sheeder, Balogh, 2003</marker>
<rawString>T. Sheeder and J. Balogh. 2003. Say it like you mean it: priming for structure in caller responses to a spoken dialog system. International Journal of Speech Technology, 6(2):103–111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Smith</author>
<author>S Gordon</author>
</authors>
<title>Effects of variable initiative on linguistic behavior in human-computer spoken natural language dialogue.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>1</issue>
<contexts>
<context position="1915" citStr="Smith and Gordon, 1997" startWordPosition="296" endWordPosition="299">syntactic choices can be particularly useful in flexible input dialog systems. Limited input dialog systems, including most commercial systems, require the user to respond to each system prompt using only the concept and words currently requested by the system. Flexible input dialog systems allow the user to respond to system prompts with concepts and words in addition to or other than the ones currently requested, and may even allow the user to take task initiative. Speech recognition (ASR) accuracy in limited input systems is better than in flexible input systems (Danieli and Gerbino, 1995; Smith and Gordon, 1997). However, task completion rates and times are better inflexible input systems (ChuCarroll and Nickerson, 2000; Smith and Gordon, 1997). With user adaptation, inflexible input dialog systems prompts can be formulated to maximize ASR accuracy and reduce the number of ASR timeouts (Sheeder and Balogh, 2003). Previous research on user adaptation to dialog systems was conducted in laboratory settings. However, the behavior of recruited subjects in a quiet laboratory may differ from that of real users in the noisy world (Ai et al., 2007). Here we present the first study, to the best of our knowledg</context>
</contexts>
<marker>Smith, Gordon, 1997</marker>
<rawString>R. Smith and S. Gordon. 1997. Effects of variable initiative on linguistic behavior in human-computer spoken natural language dialogue. Computational Linguistics, 23(1):141–168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ward</author>
<author>D Litman</author>
</authors>
<title>Automatically measuring lexical and acoustic/prosodic convergence in tutorial dialog corpora.</title>
<date>2007</date>
<booktitle>In Proceedings of the SLaTE Workshop on Speech and Language Technology in Education.</booktitle>
<contexts>
<context position="1246" citStr="Ward and Litman, 2007" startWordPosition="186" endWordPosition="189"> consequent user adaptation, can have an impact on recognition of task-related concepts. This means that system prompt formulation, even in flexible input dialog systems, can be used to guide users into producing utterances conducive to task success. 1 Introduction Numerous studies have shown that people adapt their syntactic and lexical choices in conversation to those of their conversational partners, both human (Brennan, 1996; Pickering et al., 2000; Lockridge and Brennan, 2002; Reitter et al., 2006) and computer (Branigan et al., 2003; Brennan, 1991; Brennan, 1996; Gustafson et al., 1997; Ward and Litman, 2007). User adaptation to the system’s lexical and syntactic choices can be particularly useful in flexible input dialog systems. Limited input dialog systems, including most commercial systems, require the user to respond to each system prompt using only the concept and words currently requested by the system. Flexible input dialog systems allow the user to respond to system prompts with concepts and words in addition to or other than the ones currently requested, and may even allow the user to take task initiative. Speech recognition (ASR) accuracy in limited input systems is better than in flexi</context>
</contexts>
<marker>Ward, Litman, 2007</marker>
<rawString>A. Ward and D. Litman. 2007. Automatically measuring lexical and acoustic/prosodic convergence in tutorial dialog corpora. In Proceedings of the SLaTE Workshop on Speech and Language Technology in Education.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>