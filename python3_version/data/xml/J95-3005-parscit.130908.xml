<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9305255">
Squibs and Discussions
Memoization in Top-Down Parsing
</title>
<author confidence="0.995157">
Mark Johnson.
</author>
<affiliation confidence="0.956522">
Brown University
</affiliation>
<sectionHeader confidence="0.989562" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999842729729729">
In a paper published in this journal, Norvig (1991) pointed out that memoization of a
top-down recognizer program produces a program that behaves similiarly to a chart
parser. This is not surprising to anyone familiar with logic-programming approaches to
natural language processing (NLP). For example, the Earley deduction proof procedure
is essentially a memoizing version of the top-down selected literal deletion (SLD) proof
procedure employed by Prolog. Pereira and Warren (1983) showed that the steps of
the Earley Deduction proof procedure proving the well-formedness of a string S from
the standard &apos;top-down&apos; definite clause grammar (DCG) axiomatization of a context-
free grammar (CFG) G correspond directly to those of Earley&apos;s algorithm recognizing
S using G.
Yet as Norvig notes in passing, using his approach the resulting parsers in general
fail to terminate on left-recursive grammars, even with memoization. The goal of
this paper is to discover why this is the case and present a functional formalization
of memoized top-down parsing for which this is not so. Specifically, I show how
to formulate top-down parsers in a &apos;continuation-passing style,&apos; which incrementally
enumerates the right string positions of a category, rather than returning a set of such
positions as a single value. This permits a type of memoization not described to my
knowledge in the context of functional programming before. This kind of memoization
is akin to that used in logic programming, and yields terminating parsers even in the
face of left recursion.
In this paper, algorithms are expressed in the Scheme programming language (Rees
and Clinger 1991). Scheme was chosen because it is a popular, widely known language
that many readers find easy to understand. Scheme&apos;s &apos;first-class&apos; treatment of functions
simplifies the functional abstraction used in this paper, but the basic approach can be
implemented in more conventional languages as well. Admittedly elegance is a matter
of taste, but personally I find the functional specification of CFGs described here as
simple and elegant as the more widely known logical (DCG) formalization, and I hope
that the presentation of working code will encourage readers to experiment with the
ideas described here and in more substantial works such as Leermakers (1993). In
fact, my own observations suggest that with minor modifications (such as the use of
integers rather than lists to indicate string positions, and vectors indexed by string
positions rather than lists in the memoization routines) an extremely efficient chart
parser can be obtained from the code presented here.
Ideas related to the ones discussed here have been presented on numerous occa-
sions. Almost 20 years ago Shiel (1976) noticed the relationship between chart parsing
and top-down parsing. Leermakers (1993) presents a more abstract discussion of the
functional treatment of parsing, and avoids the left-recursion problem for memoized
</bodyText>
<note confidence="0.887745">
* Cognitive Science Department, Brown University, Box 1978, Providence, RI 02912
C) 1995 Association for Computational Linguistics
Computational Linguistics Volume 21, Number 3
</note>
<bodyText confidence="0.9998796">
functional parsers by using a &apos;recursive ascent&apos; or PLR parsing strategy instead of a
top-down strategy. At a more abstract level than that of this paper, Shieber, Schabes,
and Pereira (1994) show that a variety of well-known parsing algorithms can be viewed
as computing the closure of a set of basic parsing operations on a representation of
the input string.
</bodyText>
<sectionHeader confidence="0.988713" genericHeader="method">
2. Formalizing Context-Free Grammars
</sectionHeader>
<bodyText confidence="0.999622142857143">
It is fairly straightforward to implement a top-down parser in a functional program-
ming language. The key insight is that a nonterminal category A in a grammar defines
a function fA that maps a string position 1 in the input string -y to a set of string po-
sitions IA (1) such that r E IA (1) iff A can derive the substring of -y spanning string
positions 1 to r (see e.g., Leermakers [1993] for discussion).
For example, suppose V, NP, and S are already bound to fv, INP and Is, and the
grammar contains the following productions with VP on the left hand side.
</bodyText>
<listItem confidence="0.774036">
(1) VP V NP VP—VS
Then the following Scheme definition binds VP to fvP.
(2) (define (VP p)
</listItem>
<bodyText confidence="0.831048">
(union (reduce union &apos;() (map NP (V p)))
(reduce union &apos;0 (map S (V p))))))
If sets are represented by unordered lists, union can be given the following defini-
tion. The function reduce is defined such that an expression of the form (reduce
f e&apos; (x1 ... x,i)) evaluates to (I (. . . (f e xi) ...)xn).
</bodyText>
<listItem confidence="0.764632">
(3) (define (reduce fn mit args)
</listItem>
<bodyText confidence="0.80330125">
(if (null? args)
mit
(reduce fn (fn mit (car args))
(cdr args))))
</bodyText>
<listItem confidence="0.89034">
(4) (define (union setl set2)
</listItem>
<equation confidence="0.9192395">
(if (null? setl)
set2
(if (member (car setl) set2)
(union (cdr setl) set2)
(cons (car setl)
(union (cdr setl) set2)))))
</equation>
<bodyText confidence="0.999817555555556">
When evaluated using Scheme&apos;s applicative-order reduction rule, such a system be-
haves as a depth-first, top-down recognizer in which nondeterminism is simulated by
backtracking. For example, in (2) the sequence V NP is first investigated as a potential
analysis of VP, and then the sequence V S is investigated.
Rather than defining the functions f by hand as in (2), higher-order functions can
be introduced to automate this task. It is convenient to use suffixes of the input string
to represent the string positions of the input string (as in DCGs).
The expression (terminal x) evaluates to a function that maps a string position 1 to
the singleton set { r iff the terminal x spans from / to r, and the empty set otherwise.
</bodyText>
<page confidence="0.992924">
406
</page>
<figure confidence="0.172983142857143">
Mark Johnson Memoization in Top-Down Parsing
(5) (define (terminal X)
(lambda (p)
(if (and (pair? p)
(eq? (car p) X))
(list (cdr p))
())))
</figure>
<bodyText confidence="0.998784">
The expression (seq fA fB) evaluates to a function that maps a string position 1 to the
set of string positions {r,} such that there exists an m E fA (1), and ri E fB (m). Informally,
the resulting function recognizes substrings that are the concatenation of a substring
recognized by fA and a substring recognized by fs.
</bodyText>
<equation confidence="0.852602222222222">
(6) (define (seq A B)
(lambda (p)
(reduce union &apos;0 (map B (A p)))))
The expression (alt fA fB) evaluates to a function that maps a string position 1 to
fA(I) U fB(/). Informally, the resulting function recognizes the union of the substrings
recognized by fA and fB.
(7) (define (alt A B)
(lambda (p)
(union (A p) (B p))))
</equation>
<bodyText confidence="0.9976968">
While terminal, seq, and alt suffice to define (epsilon-free) context-free grammars,
we can easily define other useful higher-order functions. For example, epsilon recog-
nizes the empty string (i.e., it maps every string position 1 into the singleton set {/}),
(opt fA) recognizes an optional constituent, and (k* fA) recognizes zero or more occur-
rences of the substrings recognized by fA.
</bodyText>
<equation confidence="0.80392">
(8) (define epsilon list)
(9) (define (opt A) (alt epsilon A))
(10) (define (k* A)
(alt epsilon
(seq A (k* A))))
</equation>
<bodyText confidence="0.965554">
These higher-order functions can be used to provide simpler definitions, such as (2a)
or (2b), for the function VP defined in (2) above.
</bodyText>
<listItem confidence="0.9035175">
(2a) (define VP (alt (seq V NP) (seq V S)))
(2b) (define VP (seq V (alt NP S)))
</listItem>
<bodyText confidence="0.960118333333333">
This method of defining the functions corresponding to categories is quite appealing.
Unfortunately, Scheme is deficient in that it does not allow mutually recursive func-
tional definitions of the kind in (2a) or (2b). For example, suppose S is defined as in
</bodyText>
<listItem confidence="0.9886345">
(11) and VP is defined as in (2a).
(11) (define S (seq NP VP))
</listItem>
<page confidence="0.993498">
407
</page>
<note confidence="0.451151">
Computational Linguistics Volume 21, Number 3
</note>
<bodyText confidence="0.898646">
Further, suppose (11) precedes (2a) textually in the program. Then the variable VP in
(11) will be incorrectly interpreted as unbound. Changing the order of the definitions
will not help, as then the variable S will be unbound.1 A work-around is to add a vac-
uous lambda abstraction and application as in (11a), in effect delaying the evaluation
of function definition.
</bodyText>
<equation confidence="0.248543">
(11a) (define S (lambda args (apply (seq NP VP) args)))
</equation>
<bodyText confidence="0.821389">
With a macro definition such as (12) (named to remind us of this deficiency in the
current Scheme specification and perhaps encourage the language designers to do
better in the future), the definition of functions such as (11a) can be written as (11b).
</bodyText>
<equation confidence="0.9615716">
(12) (define—syntax vacuous
(syntax—rules ()
((vacuous fn)
(lambda args (apply fn args)))))
(11b) (define S (vacuous (seq NP VP)))
</equation>
<bodyText confidence="0.868131">
Figure 1 contains a fragment defined in this way. After these definitions have been
loaded, an expression such as the one in (13) can be evaluated. It returns a list of the
input string&apos;s suffixes that correspond to the right string position of an S.
</bodyText>
<equation confidence="0.962061">
(13) &gt; (s &apos;(Kim knows every student likes Sandy))
((likes sandy) 0)
</equation>
<bodyText confidence="0.99949">
In example (13), the list resulting from the evaluation contains two suffixes, corre-
sponding to the fact that both Kim knows every student and Kim knows every student likes
Sandy can be analysed as Ss.
Finally, the re cognize predicate can be defined as follows. The expression (recog-
nize words) is true iff words is a list of words that can be analysed as an S. i.e., if the
empty string is a one of right string positions of an S whose left string position is the
whole string to be recognized.
</bodyText>
<listItem confidence="0.442619">
(14) (define (recognize words)
(member &apos;() (S words)))
3. Memoization and Left Recursion
</listItem>
<bodyText confidence="0.839134">
As noted above, the Scheme functions defined in this way behave as top-down, back-
tracking recognizers. It is well known that such parsing methods suffer from two
major problems.
1 This problem can arise even if syntactic constructions specifically designed to express mutual recursion
are used, such as letre c. Although these variables are closed over, their values are not applied when
the defining expressions are evaluated, so such definitions should not be problematic for an
applicative-order evaluator. Apparently Scheme requires that mutually recursive functional expressions
syntactically contain a lambda expression. Note that this is not a question of reduction strategy (e.g.,
normal-order versus applicative-order), but an issue about the syntactic scope of variables.
</bodyText>
<page confidence="0.992071">
408
</page>
<figure confidence="0.972280333333333">
Mark Johnson Memoization in Top-Down Parsing
(define S (vacuous (seq NP VP))) ; S NP VP
(define VP (vacuous (alt (seq V NP) ; VP V NP
(seq (V 5))))) ; I VS
(define NP (vacuous (alt PN ;NP PN
(seq Det N)) )) ; Det N
</figure>
<figureCaption confidence="0.689096">
(define PN (alt (terminal &apos;Kim) (terminal &apos;Sandy)))
(define V (alt (terminal &apos;likes) (terminal &apos;knows)))
(define Det (alt (terminal &apos;every) (terminal &apos;no)))
(define N (alt (terminal &apos;student) (terminal &apos;professor)))
Figure 1
</figureCaption>
<bodyText confidence="0.996402857142857">
A CFG fragment defined using the higher-order constructors.
First, a top-down parser using a left-recursive grammar typically fails to terminate
on some inputs. This is true for recognizers defined in the manner just described; left-
recursive grammars yield programs that contain ill-founded recursive definitions.&apos;
Second, backtracking parsers typically involve a significant amount of redundant
computation, and parsing time is exponential in the length of the input string in the
worst case. Again, this is also true for the recognizers just described.
Memoization is a standard technique for avoiding redundant computation, and as
Norvig (1991) noted, it can be applied to top-down recognizers to convert exponential-
time recognizers into polynomial-time recognizers.
A general way of doing this is by defining a higher-order procedure memo that takes
a function as an argument and returns a memoized version of it.&apos; This procedure is
essentially the same as the memoize predicate that is extensively discussed in Abelson
and Sussman (1985).
</bodyText>
<equation confidence="0.8410091">
(15) (define (memo fn)
(let ((alist &apos;()))
(lambda args
(let ((entry (assoc args alist)))
(if entry
(cdr entry)
(let ((result (apply fn args)))
(set! alist (cons (cons args result)
alist))
result))))))
</equation>
<bodyText confidence="0.939897833333334">
To memoize the recognizer, the original definitions of the functions should be replaced
with their memoized counterparts; e.g., (11b) should be replaced with (11c). Clearly
these definitions could be further simplified with suitable macro definitions or other
&apos;syntactic sugar.&apos;
2 Specifically, if A is a Scheme variable bound to the function corresponding to a left-recursive category,
then for any string position p the expression (A p) reduces to another expression containing (A p). Thus
the (applicative-order) reduction of such expressions does not terminate.
3 For simplicity, the memo procedure presented in (15) stores the memo table as an association list, in
general resulting in a less than optimal implementation. As Norvig notes, more specialized data
structures, such as hash tables, can improve performance. In the parsing context here, optimal
performance would probably be obtained by encoding string positions with integers, allowing memo
table lookup to be a single array reference.
</bodyText>
<page confidence="0.995674">
409
</page>
<figure confidence="0.475363">
Computational Linguistics Volume 21, Number 3
(11c) (define S (memo (vacuous (seq NP VP) ) ) )
</figure>
<bodyText confidence="0.9997126">
As an aside, it is interesting to note that memoization can be applied selectively in this
approach. For example, because of the overhead of table lookup in complex feature-
based grammars, it might be more efficient not to memoize all categories, but rather
restrict memoization to particular categories such as NP and S.
Now we turn to the problem of left recursion. In a logic programming setting,
memoization (specifically, the use of Earley deduction) avoids the nontermination
problems associated with left recursion, even when used with the DCG axiomati-
zation of a left-recursive grammar. But as Norvig mentions in passing, with parsers
defined in the manner just described, the memoized versions of programs derived
from left-recursive grammars fail to terminate.
It is easy to see why. A memo-ed procedure constructs an entry in a memo table
only after the result of applying the unmemoized function to its arguments has been
computed. Thus in cases of left recursion, memoization does nothing to prevent the
ill-founded recursion that leads to nontermination.
In fact it is not clear how memoization could help in these cases, given that we
require that memo behaves semantically as the identity function; i.e., that (memo f) and
f are the same function. Of course, we could try to weaken this identity requirement
(e.g., by only requiring that (f x) and ( (memo f) x) are identical when the reduction
of the former terminates), but it is not clear how to do this systematically.
Procedurally speaking, it seems as if memoization is applying &apos;too late&apos; in the
left-recursive cases; reasoning by analogy with Earley deduction, we need to construct
an entry in the memo table when such a function is called; not when the result of
its evaluation is known. Of course, in the left recursive cases this seems to lead to
an inconsistency, since these are cases where the value of an expression is required to
compute that very value.
Readers familiar with Abelson and Sussman (1985) will know that in many cases
it is possible to circumvent such apparent circularity by using asynchronous &apos;lazy
streams&apos; in place of the list representations (of string positions) used above. The
continuation-passing style encoding of CFGs discussed in the next section can be
seen as a more functionally oriented instantiation of this kind of approach.
</bodyText>
<sectionHeader confidence="0.931109" genericHeader="method">
4. Formalizing Relations in Continuation-Passing Style
</sectionHeader>
<bodyText confidence="0.9989897">
The apparent circularity in the definition of the functions corresponding to left-recur-
sive categories suggests that it may be worthwhile reformulating the recognition prob-
lem in such a way that the string position results are produced incrementally, rather than
in one fell swoop, as in the formalization just described. The key insight is that each
nonterminal category A in a grammar defines a relation rA such that rA(1,r) iff A can
derive the substring of the input string spanning string positions / to r.4 Informally
speaking, the r can be enumerated one at a time, so the fact that the calculation of
r A (1, r) requires the result r A (1, r&apos;) need not lead to a vicious circularity.
One way to implement this in a functional programming language is to use a
&apos;Continuation-Passing Style&apos; (CPS) of programming.&apos; It turns out that a memoized
</bodyText>
<footnote confidence="0.9524446">
4 The relation rA and the function fA mentioned above satisfy V r V 1 rA(/,r) 4-+ r E f(1)•
5 Several readers of this paper, including a reviewer, suggested that this can be formulated more
succinctly using Scheme&apos;s call/cc continuation-constructing primitive. After this paper was accepted
for publication, Jeff Sisslcind devised an implementation based on call/cc which does not require
continuations to be explicitly passed as arguments to functions.
</footnote>
<page confidence="0.977032">
410
</page>
<note confidence="0.601303">
Mark Johnson Memoization in Top-Down Parsing
</note>
<bodyText confidence="0.999549818181818">
top-down parser written in continuation-passing style will in fact terminate, even
in the face of left recursion. Additionally, the treatment of memoization in a CPS is
instructive because it shows the types of table lookup operations needed in chart
parsing.
Informally, in a CPS program an additional argument, call it c, is added to all
functions and procedures. When these functions and procedures are called c is always
bound to a procedure (called the continuation); the idea is that a result value v is
&apos;returned&apos; by evaluating (c v). For example, the standard definition of the function
square in (16) would be rewritten in CPS as in (17). (18) shows how this definition
could be used to compute and display (using the Scheme builtin display) the square
of the number 3.
</bodyText>
<listItem confidence="0.967299">
(16) (define (square x) (* x x))
(17) (define (square cont x) (cont (* x x)))
(18) &gt; (square display 3)
9
</listItem>
<bodyText confidence="0.998716333333334">
Thus whereas result values in a non-CPS program flow &apos;upwards&apos; in the procedure
call tree, in a CPS program result values flow &apos;downwards&apos; in the procedure call tree.6&apos;7
The CPS style of programming can be used to formalize relations in a pure functional
language as procedures that can be thought of as &apos;returning&apos; multiply valued results
any number of times.
These features of CPS can be used to encode CFGs as follows. Each category A is
associated with a function gA that represents the relation rA, i.e., (gA c 1) reduces (in an
applicative-order reduction) in such a fashion that at some stage in the reduction the
expression (c r) is reduced iff A can derive the substring spanning string positions 1
to r of the input string. (The value of (gA c I) is immaterial and therefore unspecified,
but see footnote 8 below). That is, if (gA c 1) is evaluated with 1 bound to the left string
position of category A, then (c r) will be evaluated zero or more times with r bound
to each of A&apos;s right string positions r corresponding to 1.
For example, a CPS function recognizing the terminal item &apos;will&apos; (arguably a future
auxiliary in a class of its own) could be written as in (19).
</bodyText>
<listItem confidence="0.550806333333333">
(19) (define (future-aux continuation pos)
(if (and (pair? pos) (eq? (car pos) &apos;will))
(continuation (cdr pos))))
</listItem>
<bodyText confidence="0.988468666666667">
For a more complicated example, consider the two rules defining VP in the fragment
above, repeated here as (20). These could be formalized as the CPS function defined
in (21).
</bodyText>
<listItem confidence="0.720152">
(20) VP --+ V NP VP—VS
(21) (define (VP continuation pos)
(begin
</listItem>
<equation confidence="0.524269">
(V (lambda (posi) (NP continuation posi)) pos)
(V (lambda (posi) (S continuation posi)) pos)))
</equation>
<footnote confidence="0.954059">
6 Tail recursion optimization prevents the procedure call stack from growing unboundedly.
7 This CPS formalization of CFGs is closely related to the &apos;downward success passing&apos; method of
translating Prolog into Lisp discussed by Kahn and Carlsson (1984).
</footnote>
<page confidence="0.98984">
411
</page>
<note confidence="0.662875">
Computational Linguistics Volume 21, Number 3
</note>
<bodyText confidence="0.99988875">
In this example V, NP, and S are assumed to have CPS definitions. Informally, the
expression (lambda (pos1) (NP continuation pos1) ) is a continuation that specifies
what to do if a V is found, viz., pass the V&apos;s right string position pos1 to the NP
recognizer as its left-hand string position, and instruct the NP recognizer in turn to
pass its right string positions to continuation.
The recognition process begins by passing the function corresponding to the root
category the string to be recognized, and a continuation (to be evaluated after suc-
cessful recognition) that records the successful analysis.&apos;
</bodyText>
<listItem confidence="0.513448">
(22) (define (recognize words)
</listItem>
<equation confidence="0.9048126">
(let ((recognized #f))
(S (lambda (pos)
(if (null? pos) (set! recognized #t)))
words)
recognized))
</equation>
<bodyText confidence="0.975215411764706">
Thus rather than constructing a set of all the right string positions (as in the previous
encoding), this encoding exploits the ability of the CPS approach to &apos;return&apos; a value
zero, one or more times (corresponding to the number of right string positions). And
although it is not demonstrated in this paper, the ability of a CPS procedure to &apos;return&apos;
more than one value at a time can be used to pass other information besides right string
position, such as additional syntactic features or semantic values.
Again, higher-order functions can be used to simplify the definitions of the CPS
functions corresponding to categories. The CPS versions of the terminal, seq, and alt
functions are given as (23), (25), and (24) respectively.
(23) (define (terminal word)
(lambda (continuation pos)
(if (and (pair? pos) (eq? (car pos) word))
(continuation (cdr pos)))))
8 Thus this formalization makes use of mutability to return final results, and so cannot be expressed in a
purely functional language. However, it is possible to construct a similiar formalization in the purely
functional subset of Scheme by passing around an additional &apos;result&apos; argument (here the last
argument). The examples above would be rewritten as the following under this approach.
</bodyText>
<table confidence="0.863490733333333">
(19&apos;) (define (future-aux continuation pos result)
(if (and (pair? pos) (eq? (car pos) &apos;will))
(continuation (cdr pos) result)))
(21&apos;) (define (VP continuation pos result)
(V (lambda (posl result1)
(NP continuation posl result1))
pos
(V (lambda (posl result1)
(S continuation posl result1))
pos
result)))
(22&apos;) (define (recognize words)
(S (lambda (pos result)
(if (null? pos) #t result))
words))
</table>
<page confidence="0.975776">
412
</page>
<figure confidence="0.956028777777778">
Mark Johnson Memoization in Top-Down Parsing
(24) (define (alt alt1 alt2)
(lambda (continuation pos)
(begin (altl continuation pos)
(alt2 continuation pos))))
(25) (define (seq seq1 seq2)
(lambda (cont pos)
(seql (lambda (pos1) (seq2 cont p051))
pos)))
</figure>
<bodyText confidence="0.999413666666667">
If these three functions definitions replace the earlier definitions given in (5), (6), and
(7), the fragment in Figure 1 defines a CPS recognizer. Note that just as in the first CFG
encoding, the resulting program behaves as a top-down recognizer. Thus in general
these progams fail to terminate when faced with a left-recursive grammar for es-
sentially the same reason: the procedures that correspond to left-recursive categories
involve ill-founded recursion.
</bodyText>
<sectionHeader confidence="0.844096" genericHeader="method">
5. Memoization in Continuation-Passing Style
</sectionHeader>
<bodyText confidence="0.929535526315789">
The memo procedure defined in (15) is not appropriate for CPS programs because it as-
sociates the arguments of the functional expression with the value that the expression
reduces to, but in a CPS program the &apos;results&apos; produced by an expression are the val-
ues it passes on to the continuation, rather than the value that the expression reduces
to. That is, a memoization procedure for a CPS procedure should associate argument
values with the set of values that the unmemoized procedure passes to its continua-
tion. Because an unmemoized CPS procedure can produce multiple result values, its
memoized version must store not only these results, but also the continuations passed
to it by its callers, which must receive any additional results produced by the original
unmemoized procedure.
The cps-memo procedure in (26) achieves this by associating a table entry with
each set of argument values that has two components; a list of caller continuations
and a list of result values. The caller continuation entries are constructed when the
memoized procedure is called, and the result values are entered and propagated back
to callers each time the unmemoized procedure &apos;returns&apos; a new value.&apos;
9 The dolist form used in (26) behaves as the dolist form in CommonLisp. It can be defined in terms
of Scheme primitives as follows:
(define-syntax dolist
(syntax-rules 0
</bodyText>
<footnote confidence="0.6782118">
((dolist (var list) body)
(do ((to-do list))
((null? to-do))
(let ((var (car to-do)))
. body)))))
</footnote>
<page confidence="0.994862">
413
</page>
<figure confidence="0.9556641">
Computational Linguistics Volume 21, Number 3
(26) (define (memo cps-fn)
(let ((table (make-table)))
(lambda (continuation . args)
(let ((entry (table-ref table args)))
(cond ((null? (entry-continuations entry))
; first time memoized procedure has been called with args
(push-continuation! entry continuation)
(apply cps-fn
(lambda result
(when (not (result-subsumed? entry result))
(push-result! entry result)
(dolist (cont (entry-continuations entry))
(apply cont result))) )
args))
(else
; memoized procedure has been called with args before
(push-continuation! entry continuation)
(dolist (result (entry-results entry))
(apply continuation result))))))))
</figure>
<bodyText confidence="0.970105517241379">
Specifically, when the memoized procedure is called, continuation is bound to the
continuation passed by the caller that should receive &apos;return&apos; values, and args is bound
to a list of arguments that index the entry in the memo table and are passed to the
unmemoized procedure cps-fn if evaluation is needed. The memo table table initially
associates every set of arguments with empty caller continuation and empty result
value sets. The local variable entry is bound to the table entry that corresponds to
args; the set of caller continuations stored in entry is null iff the memoized function
has not been called with this particular set of arguments before.
The cond clause determines if the memoized function has been called with args
before by checking if the continuations component of the table entry is nonempty.
In either case, the caller continuation needs to be stored in the continuations compo-
nent of the table entry, so that it can receive any additional results produced by the
unmemoized procedure.
If the memoized procedure has not been called with args before, it is necessary
to call the unmemoized procedure cps-fn to produce the result values for args. The
continuation passed to cps-fn checks to see if each result of this evaluation is sub-
sumed by some other result already produced for this entry; if it is not, it is pushed
onto the results component of this entry, and finally passed to each caller continuation
associated with this entry.
If the memoized procedure has been called with args before, the results associ-
ated with this table entry can be reused. After storing the caller continuation in the
table entry, each result already accumulated in the table entry is passed to the caller
continuation.
Efficient implementations of the table and entry manipulation procedures would
be specialized for the particular types of arguments and results used by the unmem-
oized procedures. Here we give a simple and general, but less than optimal, imple-
mentation using association lists.&apos;
10 This formalization makes use of &apos;impure&apos; features of Scheme, specifically destructive assignment to add
an element to the table list (which is why this list contains the dummy element *head*). Arguably,
</bodyText>
<page confidence="0.994322">
414
</page>
<note confidence="0.598644">
Mark Johnson Memoization in Top-Down Parsing
</note>
<bodyText confidence="0.925864">
A table is a headed association list (27), which is extended as needed by table-ref
(28). In this fragment there are no partially specified arguments or results (such as
would be involved if the fragment used feature structures), so the subsumption relation
is in fact equality.
</bodyText>
<figure confidence="0.989225666666667">
(27) (define (make-table) (list &apos;*head*))
(28) (define (table-ref table key)
(let ((pair (assoc key (cdr table))))
(if pair ; an entry already exists
(cdr pair) ; return it
(let ((new-entry (make-entry)))
(set-cdr! table (cons (cons key new-entry)
(cdr table)))
new-entry))))
</figure>
<bodyText confidence="0.804530333333333">
Entries are manipulated by the following procedures. Again, because this fragment
does not produce partially specified results, the result subsumption check can be per-
formed by the Scheme function member.
</bodyText>
<listItem confidence="0.957522555555556">
(29) (define (make-entry) (cons &apos;0 &apos;0))
(30) (define entry-continuations car)
(31) (define entry-results cdr)
(32) (define (push-continuation! entry continuation)
(set-car! entry (cons continuation (car entry))))
(33) (define (push-result! entry result)
(set-cdr! entry (cons result (cdr entry))))
(34) (define (result-subsumed? entry result)
(member result (entry-results entry)))
</listItem>
<bodyText confidence="0.961">
As claimed above, the memoized version of the CPS top-down parser does terminate,
even if the grammar is left-recursive. Informally, memoized CPS top-down parsers
terminate in the face of left-recursion because they ensure that no unmemoized pro-
cedure is ever called twice with the same arguments. For example, we can replace
the definition of NP in the fragment with the left-recursive one given in (35) with-
out compromising termination, as shown in (36) (where the input string is meant to
approximate Kim&apos;s professor knows every student).
</bodyText>
<figure confidence="0.974825">
(35) (define NP (memo (vacuous
(alt PN ;NP--+.13N
(alt (seq NP N) ; INPN
(seq Det N)))))) ; &apos;ally
</figure>
<page confidence="0.7561255">
(36) &gt; (recognize &apos;(Kim professor knows every student))
#t
</page>
<bodyText confidence="0.46766">
this is a case in which impure features result in a more comprehensible overall program.
</bodyText>
<page confidence="0.992728">
415
</page>
<note confidence="0.720555">
Computational Linguistics Volume 21, Number 3
</note>
<bodyText confidence="0.998914733333333">
Memoized CPS top-down recognizers do in fact correspond fairly closely to chart
parsers. Informally, the memo table for the procedure corresponding to a category A
will have an entry for an argument string position 1 just in case a predictive chart
parser predicts a category A at position 1, and that entry will contain string position
r as a result just in case the corresponding chart contains a complete edge spanning
from 1 to r. Moreover, the evaluation of the procedure PA corresponding to a category
A at string position 1 corresponds to predicting A at position 1, and the evaluation of
the caller continuations corresponds to the completion steps in chart parsing. The CPS
memoization described here caches such evaluations in the same way that the chart
caches predictions, and the termination in the face of left recursive follows from the
fact that no procedure PA is ever called with the same arguments twice. Thus given a
CPS formalization of the parsing problem and an appropriate memoization technique,
it is in fact the case that &amp;quot;the maintenance of well-formed substring tables or charts
can be seen as a special case of a more general technique: memoization&amp;quot; (Norvig 1991),
even if the grammar contains left recursion.
</bodyText>
<sectionHeader confidence="0.982223" genericHeader="conclusions">
6. Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.99998444">
This paper has shown how to generalize Norvig&apos;s application of memoization to
top-down recognizers to yield terminating recognizers for left recursive grammars.
Although not discussed here, the techniques used to construct the CPS recognizers
can be generalized to parsers that construct parse trees, or associate categories with
&amp;quot;semantic values&amp;quot; or &amp;quot;unification-based&amp;quot; feature structures. Specifically, we add extra
arguments to each (caller) continuation whose value is the feature structure, parse tree
and/or the &amp;quot;semantic value&amp;quot; associated with each category. Doing this raises other in-
teresting questions not addressed by this paper. As noted by a CL reviewer, while the
use of memoization described here achieves termination in the face of left recursion
and polynomial recognition times for CFGs, it does not provide packed parse forest
representations of the strings analysed in the way that chart-based systems can (Lang
1991; Tomita 1985). Since the information that would be used to construct such packed
parse forest representations in a chart is encapsulated in the state of the memoized
functions, a straightforward implementation attempt would probably be very compli-
cated, and I suspect ultimately not very informative. I suggest that it might be more
fruitful to try to develop an appropriate higher level of abstraction. For example, the
packed parse forest representation exploits the fact that all that matters about a sub-
tree is its root label and the substring it spans; its other internal details are irrelevant.
This observation might be exploited by performing parse tree construction on streams
of subtrees with the same root labels and string positions (formulated using CPS as
described above) rather than individual subtrees; these operations would be &apos;delayed&apos;
until the stream is actually read, as is standard, so the parse trees would not actually
be constructed during the parsing process. Whether or not this particular approach is
viable is not that important, but it does seem as if a functional perspective provides
useful and insightful ways to think about the parsing process.
</bodyText>
<page confidence="0.997029">
416
</page>
<note confidence="0.491858">
Mark Johnson Memoization in Top-Down Parsing
</note>
<sectionHeader confidence="0.982945" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99981475">
I would like to thank Jeff Sisskind, Edward
Stabler, and the CL reviewers for their
stimulating comments. This paper was
made available via the CMP-LG pre-print
server after it was accepted by Computational
Linguistics, and I thank my colleagues on
the Internet for their numerous suggestions
and technical improvements.
</bodyText>
<sectionHeader confidence="0.992149" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999808413043478">
Abelson, Harold, and Sussman, Gerald Jay
(1985). Structure and Interpretation of
Computer Programs. MIT Press.
Kahn, K. M., and Carlsson, M. (1984). &amp;quot;How
to implement Prolog on a Lisp machine.&amp;quot;
In Implementations of Prolog, edited by J. A.
Campbell, 117-134. Ellis Horwood
Limited.
Lang, Bernard (1991). &amp;quot;Towards a uniform
formal framework for parsing.&amp;quot; In Current
Issues in Parsing Technology, edited by
Masaru Tomita, 153-172. Kluwer
Academic Publishers.
Leermakers, René (1993). The Functional
Treatment of Parsing, Kluwer Academic
Publishers.
Norvig, Peter (1991). &amp;quot;Techniques for
automatic memoization with applications
to context-free parsing.&amp;quot; Computational
Linguistics, 17(1), 91-98.
Pereira, Fernando, and Warren, David H. D.
(1983). &amp;quot;Parsing as deduction.&amp;quot; In
Proceedings, 21st Annual Meeting of the
Association for Computational Linguistics,
137-144.
Rees, Jonathan, and Clinger, William (1991).
&amp;quot;Revised report on the algorithmic
language scheme.&amp;quot; Technical Report 341,
Computer Science Department, Indiana
University.
Sheil, B. A. (1976). &amp;quot;Observations on
context-free parsing.&amp;quot; Technical Report TR
12-76, Center for Research in Computing
Technology, Aiken Computation
Laboratory, Harvard University.
Shieber, Stuart M.; Schabes, Yves; and
Pereira, Fernando C. N. (1994).
&amp;quot;Principles and implementation of
deductive parsing.&amp;quot; Technical Report
TR-11-94, Center for Research in
Computing Technology (also available
from the cmp-lg server), Computer
Science Department, Harvard University.
Tomita, Masaru (1985). Efficient Parsing for
Natural Language, Kluwer Academic
Publishers.
</reference>
<page confidence="0.997423">
417
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.991006">
<title confidence="0.996556">Squibs and Discussions Memoization in Top-Down Parsing</title>
<author confidence="0.999985">Mark Johnson</author>
<affiliation confidence="0.997889">Brown University</affiliation>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Harold Abelson</author>
<author>Gerald Jay Sussman</author>
</authors>
<title>Structure and Interpretation of Computer Programs.</title>
<date>1985</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="11421" citStr="Abelson and Sussman (1985)" startWordPosition="1873" endWordPosition="1876">sing time is exponential in the length of the input string in the worst case. Again, this is also true for the recognizers just described. Memoization is a standard technique for avoiding redundant computation, and as Norvig (1991) noted, it can be applied to top-down recognizers to convert exponentialtime recognizers into polynomial-time recognizers. A general way of doing this is by defining a higher-order procedure memo that takes a function as an argument and returns a memoized version of it.&apos; This procedure is essentially the same as the memoize predicate that is extensively discussed in Abelson and Sussman (1985). (15) (define (memo fn) (let ((alist &apos;())) (lambda args (let ((entry (assoc args alist))) (if entry (cdr entry) (let ((result (apply fn args))) (set! alist (cons (cons args result) alist)) result)))))) To memoize the recognizer, the original definitions of the functions should be replaced with their memoized counterparts; e.g., (11b) should be replaced with (11c). Clearly these definitions could be further simplified with suitable macro definitions or other &apos;syntactic sugar.&apos; 2 Specifically, if A is a Scheme variable bound to the function corresponding to a left-recursive category, then for a</context>
<context position="14710" citStr="Abelson and Sussman (1985)" startWordPosition="2401" endWordPosition="2404"> and ( (memo f) x) are identical when the reduction of the former terminates), but it is not clear how to do this systematically. Procedurally speaking, it seems as if memoization is applying &apos;too late&apos; in the left-recursive cases; reasoning by analogy with Earley deduction, we need to construct an entry in the memo table when such a function is called; not when the result of its evaluation is known. Of course, in the left recursive cases this seems to lead to an inconsistency, since these are cases where the value of an expression is required to compute that very value. Readers familiar with Abelson and Sussman (1985) will know that in many cases it is possible to circumvent such apparent circularity by using asynchronous &apos;lazy streams&apos; in place of the list representations (of string positions) used above. The continuation-passing style encoding of CFGs discussed in the next section can be seen as a more functionally oriented instantiation of this kind of approach. 4. Formalizing Relations in Continuation-Passing Style The apparent circularity in the definition of the functions corresponding to left-recursive categories suggests that it may be worthwhile reformulating the recognition problem in such a way </context>
</contexts>
<marker>Abelson, Sussman, 1985</marker>
<rawString>Abelson, Harold, and Sussman, Gerald Jay (1985). Structure and Interpretation of Computer Programs. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K M Kahn</author>
<author>M Carlsson</author>
</authors>
<title>How to implement Prolog on a Lisp machine.&amp;quot;</title>
<date>1984</date>
<booktitle>In Implementations of Prolog,</booktitle>
<pages>117--134</pages>
<publisher>Ellis Horwood Limited.</publisher>
<note>edited by</note>
<contexts>
<context position="19240" citStr="Kahn and Carlsson (1984)" startWordPosition="3160" endWordPosition="3163"> &apos;will)) (continuation (cdr pos)))) For a more complicated example, consider the two rules defining VP in the fragment above, repeated here as (20). These could be formalized as the CPS function defined in (21). (20) VP --+ V NP VP—VS (21) (define (VP continuation pos) (begin (V (lambda (posi) (NP continuation posi)) pos) (V (lambda (posi) (S continuation posi)) pos))) 6 Tail recursion optimization prevents the procedure call stack from growing unboundedly. 7 This CPS formalization of CFGs is closely related to the &apos;downward success passing&apos; method of translating Prolog into Lisp discussed by Kahn and Carlsson (1984). 411 Computational Linguistics Volume 21, Number 3 In this example V, NP, and S are assumed to have CPS definitions. Informally, the expression (lambda (pos1) (NP continuation pos1) ) is a continuation that specifies what to do if a V is found, viz., pass the V&apos;s right string position pos1 to the NP recognizer as its left-hand string position, and instruct the NP recognizer in turn to pass its right string positions to continuation. The recognition process begins by passing the function corresponding to the root category the string to be recognized, and a continuation (to be evaluated after s</context>
</contexts>
<marker>Kahn, Carlsson, 1984</marker>
<rawString>Kahn, K. M., and Carlsson, M. (1984). &amp;quot;How to implement Prolog on a Lisp machine.&amp;quot; In Implementations of Prolog, edited by J. A. Campbell, 117-134. Ellis Horwood Limited.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernard Lang</author>
</authors>
<title>Towards a uniform formal framework for parsing.&amp;quot;</title>
<date>1991</date>
<booktitle>In Current Issues in Parsing Technology, edited by Masaru Tomita,</booktitle>
<pages>153--172</pages>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="31016" citStr="Lang 1991" startWordPosition="4991" endWordPosition="4992">th &amp;quot;semantic values&amp;quot; or &amp;quot;unification-based&amp;quot; feature structures. Specifically, we add extra arguments to each (caller) continuation whose value is the feature structure, parse tree and/or the &amp;quot;semantic value&amp;quot; associated with each category. Doing this raises other interesting questions not addressed by this paper. As noted by a CL reviewer, while the use of memoization described here achieves termination in the face of left recursion and polynomial recognition times for CFGs, it does not provide packed parse forest representations of the strings analysed in the way that chart-based systems can (Lang 1991; Tomita 1985). Since the information that would be used to construct such packed parse forest representations in a chart is encapsulated in the state of the memoized functions, a straightforward implementation attempt would probably be very complicated, and I suspect ultimately not very informative. I suggest that it might be more fruitful to try to develop an appropriate higher level of abstraction. For example, the packed parse forest representation exploits the fact that all that matters about a subtree is its root label and the substring it spans; its other internal details are irrelevant</context>
</contexts>
<marker>Lang, 1991</marker>
<rawString>Lang, Bernard (1991). &amp;quot;Towards a uniform formal framework for parsing.&amp;quot; In Current Issues in Parsing Technology, edited by Masaru Tomita, 153-172. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>René Leermakers</author>
</authors>
<title>The Functional Treatment of Parsing,</title>
<date>1993</date>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="2412" citStr="Leermakers (1993)" startWordPosition="369" endWordPosition="370">r, widely known language that many readers find easy to understand. Scheme&apos;s &apos;first-class&apos; treatment of functions simplifies the functional abstraction used in this paper, but the basic approach can be implemented in more conventional languages as well. Admittedly elegance is a matter of taste, but personally I find the functional specification of CFGs described here as simple and elegant as the more widely known logical (DCG) formalization, and I hope that the presentation of working code will encourage readers to experiment with the ideas described here and in more substantial works such as Leermakers (1993). In fact, my own observations suggest that with minor modifications (such as the use of integers rather than lists to indicate string positions, and vectors indexed by string positions rather than lists in the memoization routines) an extremely efficient chart parser can be obtained from the code presented here. Ideas related to the ones discussed here have been presented on numerous occasions. Almost 20 years ago Shiel (1976) noticed the relationship between chart parsing and top-down parsing. Leermakers (1993) presents a more abstract discussion of the functional treatment of parsing, and a</context>
</contexts>
<marker>Leermakers, 1993</marker>
<rawString>Leermakers, René (1993). The Functional Treatment of Parsing, Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Norvig</author>
</authors>
<title>Techniques for automatic memoization with applications to context-free parsing.&amp;quot;</title>
<date>1991</date>
<journal>Computational Linguistics,</journal>
<volume>17</volume>
<issue>1</issue>
<pages>91--98</pages>
<contexts>
<context position="11026" citStr="Norvig (1991)" startWordPosition="1813" endWordPosition="1814">igher-order constructors. First, a top-down parser using a left-recursive grammar typically fails to terminate on some inputs. This is true for recognizers defined in the manner just described; leftrecursive grammars yield programs that contain ill-founded recursive definitions.&apos; Second, backtracking parsers typically involve a significant amount of redundant computation, and parsing time is exponential in the length of the input string in the worst case. Again, this is also true for the recognizers just described. Memoization is a standard technique for avoiding redundant computation, and as Norvig (1991) noted, it can be applied to top-down recognizers to convert exponentialtime recognizers into polynomial-time recognizers. A general way of doing this is by defining a higher-order procedure memo that takes a function as an argument and returns a memoized version of it.&apos; This procedure is essentially the same as the memoize predicate that is extensively discussed in Abelson and Sussman (1985). (15) (define (memo fn) (let ((alist &apos;())) (lambda args (let ((entry (assoc args alist))) (if entry (cdr entry) (let ((result (apply fn args))) (set! alist (cons (cons args result) alist)) result)))))) To</context>
<context position="30003" citStr="Norvig 1991" startWordPosition="4841" endWordPosition="4842">e evaluation of the caller continuations corresponds to the completion steps in chart parsing. The CPS memoization described here caches such evaluations in the same way that the chart caches predictions, and the termination in the face of left recursive follows from the fact that no procedure PA is ever called with the same arguments twice. Thus given a CPS formalization of the parsing problem and an appropriate memoization technique, it is in fact the case that &amp;quot;the maintenance of well-formed substring tables or charts can be seen as a special case of a more general technique: memoization&amp;quot; (Norvig 1991), even if the grammar contains left recursion. 6. Conclusion and Future Work This paper has shown how to generalize Norvig&apos;s application of memoization to top-down recognizers to yield terminating recognizers for left recursive grammars. Although not discussed here, the techniques used to construct the CPS recognizers can be generalized to parsers that construct parse trees, or associate categories with &amp;quot;semantic values&amp;quot; or &amp;quot;unification-based&amp;quot; feature structures. Specifically, we add extra arguments to each (caller) continuation whose value is the feature structure, parse tree and/or the &amp;quot;sema</context>
</contexts>
<marker>Norvig, 1991</marker>
<rawString>Norvig, Peter (1991). &amp;quot;Techniques for automatic memoization with applications to context-free parsing.&amp;quot; Computational Linguistics, 17(1), 91-98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando Pereira</author>
<author>David H D Warren</author>
</authors>
<title>Parsing as deduction.&amp;quot;</title>
<date>1983</date>
<booktitle>In Proceedings, 21st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>137--144</pages>
<marker>Pereira, Warren, 1983</marker>
<rawString>Pereira, Fernando, and Warren, David H. D. (1983). &amp;quot;Parsing as deduction.&amp;quot; In Proceedings, 21st Annual Meeting of the Association for Computational Linguistics, 137-144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Rees</author>
<author>William Clinger</author>
</authors>
<title>Revised report on the algorithmic language scheme.&amp;quot;</title>
<date>1991</date>
<tech>Technical Report 341,</tech>
<institution>Computer Science Department, Indiana University.</institution>
<contexts>
<context position="1753" citStr="Rees and Clinger 1991" startWordPosition="265" endWordPosition="268">zed top-down parsing for which this is not so. Specifically, I show how to formulate top-down parsers in a &apos;continuation-passing style,&apos; which incrementally enumerates the right string positions of a category, rather than returning a set of such positions as a single value. This permits a type of memoization not described to my knowledge in the context of functional programming before. This kind of memoization is akin to that used in logic programming, and yields terminating parsers even in the face of left recursion. In this paper, algorithms are expressed in the Scheme programming language (Rees and Clinger 1991). Scheme was chosen because it is a popular, widely known language that many readers find easy to understand. Scheme&apos;s &apos;first-class&apos; treatment of functions simplifies the functional abstraction used in this paper, but the basic approach can be implemented in more conventional languages as well. Admittedly elegance is a matter of taste, but personally I find the functional specification of CFGs described here as simple and elegant as the more widely known logical (DCG) formalization, and I hope that the presentation of working code will encourage readers to experiment with the ideas described h</context>
</contexts>
<marker>Rees, Clinger, 1991</marker>
<rawString>Rees, Jonathan, and Clinger, William (1991). &amp;quot;Revised report on the algorithmic language scheme.&amp;quot; Technical Report 341, Computer Science Department, Indiana University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B A Sheil</author>
</authors>
<title>Observations on context-free parsing.&amp;quot;</title>
<date>1976</date>
<tech>Technical Report TR 12-76,</tech>
<institution>Center for Research in Computing Technology, Aiken Computation Laboratory, Harvard University.</institution>
<marker>Sheil, 1976</marker>
<rawString>Sheil, B. A. (1976). &amp;quot;Observations on context-free parsing.&amp;quot; Technical Report TR 12-76, Center for Research in Computing Technology, Aiken Computation Laboratory, Harvard University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
<author>Yves Schabes</author>
<author>Fernando C N Pereira</author>
</authors>
<date>1994</date>
<marker>Shieber, Schabes, Pereira, 1994</marker>
<rawString>Shieber, Stuart M.; Schabes, Yves; and Pereira, Fernando C. N. (1994).</rawString>
</citation>
<citation valid="false">
<title>Principles and implementation of deductive parsing.&amp;quot;</title>
<tech>Technical Report TR-11-94,</tech>
<institution>Center for</institution>
<note>Research in Computing Technology (also available from the cmp-lg server),</note>
<marker></marker>
<rawString>&amp;quot;Principles and implementation of deductive parsing.&amp;quot; Technical Report TR-11-94, Center for Research in Computing Technology (also available from the cmp-lg server), Computer Science Department, Harvard University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masaru Tomita</author>
</authors>
<title>Efficient Parsing for Natural Language,</title>
<date>1985</date>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="31030" citStr="Tomita 1985" startWordPosition="4993" endWordPosition="4994">c values&amp;quot; or &amp;quot;unification-based&amp;quot; feature structures. Specifically, we add extra arguments to each (caller) continuation whose value is the feature structure, parse tree and/or the &amp;quot;semantic value&amp;quot; associated with each category. Doing this raises other interesting questions not addressed by this paper. As noted by a CL reviewer, while the use of memoization described here achieves termination in the face of left recursion and polynomial recognition times for CFGs, it does not provide packed parse forest representations of the strings analysed in the way that chart-based systems can (Lang 1991; Tomita 1985). Since the information that would be used to construct such packed parse forest representations in a chart is encapsulated in the state of the memoized functions, a straightforward implementation attempt would probably be very complicated, and I suspect ultimately not very informative. I suggest that it might be more fruitful to try to develop an appropriate higher level of abstraction. For example, the packed parse forest representation exploits the fact that all that matters about a subtree is its root label and the substring it spans; its other internal details are irrelevant. This observa</context>
</contexts>
<marker>Tomita, 1985</marker>
<rawString>Tomita, Masaru (1985). Efficient Parsing for Natural Language, Kluwer Academic Publishers.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>