<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.020062">
<title confidence="0.9965535">
Language of Vandalism:
Improving Wikipedia Vandalism Detection via Stylometric Analysis
</title>
<author confidence="0.999535">
Manoj Harpalani, Michael Hart, Sandesh Singh, Rob Johnson, and Yejin Choi
</author>
<affiliation confidence="0.9569525">
Department of Computer Science
Stony Brook University
</affiliation>
<address confidence="0.974535">
NY 11794, USA
</address>
<email confidence="0.992055">
{mharpalani, mhart, sssingh, rob, ychoi}@cs.stonybrook.edu
</email>
<sectionHeader confidence="0.995545" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99905652631579">
Community-based knowledge forums, such as
Wikipedia, are susceptible to vandalism, i.e.,
ill-intentioned contributions that are detrimen-
tal to the quality of collective intelligence.
Most previous work to date relies on shallow
lexico-syntactic patterns and metadata to au-
tomatically detect vandalism in Wikipedia. In
this paper, we explore more linguistically mo-
tivated approaches to vandalism detection. In
particular, we hypothesize that textual vandal-
ism constitutes a unique genre where a group
of people share a similar linguistic behav-
ior. Experimental results suggest that (1) sta-
tistical models give evidence to unique lan-
guage styles in vandalism, and that (2) deep
syntactic patterns based on probabilistic con-
text free grammars (PCFG) discriminate van-
dalism more effectively than shallow lexico-
syntactic patterns based on n-grams.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999970951219512">
Wikipedia, the “free encyclopedia” (Wikipedia,
2011), ranks among the top 200 most visited web-
sites worldwide (Alexa, 2011). This editable ency-
clopedia has amassed over 15 million articles across
hundreds of languages. The English language en-
cyclopedia alone has over 3.5 million articles and
receives over 1.25 million edits (and sometimes up-
wards of 3 million) daily (Wikipedia, 2010). But
allowing anonymous edits is a double-edged sword;
nearly 7% (Potthast, 2010) of edits are vandalism,
i.e. revisions to articles that undermine the quality
and veracity of the content. As Wikipedia contin-
ues to grow, it will become increasingly infeasible
for Wikipedia users and administrators to manually
police articles. This pressing issue has spawned re-
cent research activities to understand and counteract
vandalism (e.g., Geiger and Ribes (2010)). Much of
previous work relies on hand-picked rules such as
lexical cues (e.g., vulgar words) and metadata (e.g.,
anonymity, edit frequency) to automatically detect
vandalism in Wikipedia (e.g., Potthast et al. (2008),
West et al. (2010)). Although some recent work
has started exploring the use of natural language
processing, most work to date is based on shallow
lexico-syntactic patterns (e.g., Wang and McKeown
(2010), Chin et al. (2010), Adler et al. (2011)).
We explore more linguistically motivated ap-
proaches to detect vandalism in this paper. Our
hypothesis is that textual vandalism constitutes a
unique genre where a group of people share simi-
lar linguistic behavior. Some obvious hallmarks of
this style include usage of obscenities, misspellings,
and slang usage, but we aim to automatically un-
cover stylistic cues to effectively discriminate be-
tween vandalizing and normal text. Experimental re-
sults suggest that (1) statistical models give evidence
to unique language styles in vandalism, and that (2)
deep syntactic patterns based on probabilistic con-
text free grammar (PCFG) discriminate vandalism
more effectively than shallow lexico-syntactic pat-
terns based on n-grams.
</bodyText>
<sectionHeader confidence="0.975323" genericHeader="method">
2 Stylometric Features
</sectionHeader>
<bodyText confidence="0.9998125">
Stylometric features attempt to recognize patterns
of style in text. These techniques have been tra-
ditionally applied to attribute authorship (Argamon
et al. (2009), Stamatatos (2009)), opinion mining
</bodyText>
<page confidence="0.988924">
83
</page>
<note confidence="0.5847555">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 83–88,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.998773333333333">
(Panicheva et al., 2010), and forensic linguistics
(Turell, 2010). For our purposes, we hypothesize
that different stylistic features appear in regular and
vandalizing edits. For regular edits, honest editors
will strive to follow the stylistic guidelines set forth
by Wikipedia (e.g. objectivity, neutrality and factu-
ality). For edits that vandalize articles, these users
may converge on common ways of vandalizing arti-
cles.
</bodyText>
<subsectionHeader confidence="0.988205">
2.1 Language Models
</subsectionHeader>
<bodyText confidence="0.9999396">
To differentiate between the styles of normal users
and vandalizers, we employ language models to cap-
ture the stylistic differences between authentic and
vandalizing revisions. We train two trigram lan-
guage model (LM) with Good-Turing discounting
and Katz backoff for smoothing of vandalizing ed-
its (based on the text difference between the vandal-
izing and previous revision) and good edits (based
on the text difference between the new and previous
revision).
</bodyText>
<subsectionHeader confidence="0.926917">
2.2 Probabilistic Context Free Grammar
(PCFG) Models
</subsectionHeader>
<bodyText confidence="0.999267416666667">
Probabilistic context-free grammars (PCFG) capture
deep syntactic regularities beyond shallow lexico-
syntactic patterns. Raghavan et al. (2010) reported
for the first time that PCFG models are effective in
learning stylometric signature of authorship at deep
syntactic levels. In this work, we explore the use of
PCFG models for vandalism detection, by viewing
the task as a genre detection problem, where a group
of authors share similar linguistic behavior. We give
a concise description of the use of PCFG models be-
low, referring to Raghavan et al. (2010) for more de-
tails.
</bodyText>
<listItem confidence="0.902578928571428">
(1) Given a training corpus D for vandalism de-
tection and a generic PCFG parser Co trained
on a manually tree-banked corpus such as WSJ
or Brown, tree-bank each training document
di E D using the generic PCFG parser Co.
(2) Learn vandalism language by training a new
PCFG parser Cvandal using only those tree-
banked documents in D that correspond to van-
dalism. Likewise, learn regular Wikipedia lan-
guage by training a new PCFG parser Cregular
using only those tree-banked documents in D
that correspond to regular Wikipedia edits.
(3) For each test document, compare the proba-
bility of the edit determined by Cvandal and
</listItem>
<bodyText confidence="0.87098625">
Cregular, where the parser with the higher score
determines the class of the edit.
We use the PCFG implementation of Klein and
Manning (2003).
</bodyText>
<sectionHeader confidence="0.987438" genericHeader="method">
3 System Description
</sectionHeader>
<bodyText confidence="0.9998943">
Our system decides if an edit to an article is vandal-
ism by training a classifier based on a set of features
derived from many different aspects of the edit. For
this task, we use an annotated corpus (Potthast et
al., 2010) of Wikipedia edits where revisions are la-
beled as either vandalizing or non-vandalizing. This
section will describe in brief the features used by
our classifier, a more exhaustive description of our
non-linguistically motivated features can be found
in Harpalani et al. (2010).
</bodyText>
<subsectionHeader confidence="0.997348">
3.1 Features Based on Metadata
</subsectionHeader>
<bodyText confidence="0.999998461538462">
Our classifier takes into account metadata generated
by the revision. We generate features based on au-
thor reputation by recording if the edit is submitted
by an anonymous user or a registered user. If the au-
thor is registered, we record how long he has been
registered, how many times he has previously van-
dalized Wikipedia, and how frequent he edits arti-
cles. We also take into account the comment left by
an author. We generate features based on the charac-
teristics of the articles revision history. This includes
how many times the article has been previously van-
dalized, the last time it was edited, how many times
it has been reverted and other related features.
</bodyText>
<subsectionHeader confidence="0.999089">
3.2 Features Based on Lexical Cues
</subsectionHeader>
<bodyText confidence="0.999968333333333">
Our classifier also employs a subset of features that
rely on lexical cues. Simple strategies such as count-
ing the number of vulgarities present in the revision
are effective to capture obvious forms of vandalism.
We measure the edit distance between the old and
new revision, the number of repeated patterns, slang
words, vulgarities and pronouns, the type of edit (in-
sert, modification or delete) and other similar fea-
tures.
</bodyText>
<page confidence="0.996257">
84
</page>
<table confidence="0.9999042">
Features P R F1 AUC
Baseline 72.8 41.1 52.6 91.6
+LM 73.3 42.1 53.5 91.7
+PCFG 73.5 47.7 57.9 92.9
+LM+PCFG 73.2 47.3 57.5 93.0
</table>
<tableCaption confidence="0.999937">
Table 1: Results on naturally unbalanced test data
</tableCaption>
<subsectionHeader confidence="0.996325">
3.3 Features Based on Sentiment
</subsectionHeader>
<bodyText confidence="0.999938">
Wikipedia editors strive to maintain a neutral and
objective voice in articles. Vandals, however, in-
sert subjective and polar statements into articles. We
build two classifiers based on the work of Pang and
Lee (2004) to measure the polarity and objectivity
of article edits. We train the classifier on how many
positive and negative sentences were inserted as well
as the overall change in the sentiment score from the
previous version to the new revision and the num-
ber of inserted or deleted subjective sentences in the
revision.
</bodyText>
<subsectionHeader confidence="0.987262">
3.4 Features Based on Stylometric Measures
</subsectionHeader>
<bodyText confidence="0.999933916666667">
We encode the output of the LM and PCFG in the
following manner for training our classifier. We
take the log-likelihood of the regular edit and van-
dalizing edit LMs. For our PCFG, we take the dif-
ference between the minimum log-likelihood score
(i.e. the sentences with the minimum log-likelihood)
of Cvandal and Cregular, the difference in the max-
imum log-likelihood score, the difference in the
mean log-likelihood score, the difference in the
standard deviation of the mean log-likelihood score
and the difference in the sum of the log-likelihood
scores.
</bodyText>
<subsectionHeader confidence="0.998002">
3.5 Choice of Classifier
</subsectionHeader>
<bodyText confidence="0.999837">
We use Weka’s (Hall et al., 2009) implementation
of LogitBoost (Friedman et al., 2000) to perform the
classification task. We use Decision Stumps (Ai and
Langley, 1992) as the base learner and run Logit-
Boost for 500 iterations. We also discretize the train-
ing data using the Multi-Level Discretization tech-
nique (Perner and Trautzsch, 1998).
</bodyText>
<sectionHeader confidence="0.998785" genericHeader="method">
4 Experimental Results
</sectionHeader>
<bodyText confidence="0.973101571428572">
Data We use the 2010 PAN Wikipedia vandalism
corpus Potthast et al. (2010) to quantify the ben-
Feature Score
Total number of author contributions 0.106
How long the author has been registered 0.098
How frequently the author contributed 0.097
in the training set
If the author is registered 0.0885
Difference in the maximum PCFG scores 0.0437
Difference in the mean PCFG scores 0.0377
How many times the article has been reverted 0.0372
Total contributions of author to Wikipedia 0.0343
Previous vandalism count of the article 0.0325
Difference in the sum of PCFG scores 0.0320
</bodyText>
<tableCaption confidence="0.975136">
Table 2: Top 10 ranked features on the unbalanced test
data by InfoGain
</tableCaption>
<bodyText confidence="0.9999618">
efit of stylometric analysis to vandalism detection.
This corpus comprises of 32452 edits on 28468 ar-
ticles, with 2391 of the edits identified as vandal-
ism by human annotators. The class distribution is
highly skewed, as only 7% of edits corresponds to
vandalism. Among the different types of vandalism
(e.g. deletions, template changes), we focus only on
those edits that inserted or modified text (17145 ed-
its in total) since stylometric features are not relevant
to deletes and template modifications. Note that in-
sertions and modifications are the main source for
vandalism.
We randomly separated 15000 edits for training
of Cvandal and Cregular, and 17444 edits for testing,
preserving the ratio of vandalism to non-vandalism
revisions. We eliminated 7359 of the testing ed-
its to remove revisions that were exclusively tem-
plate modifications (e.g. inserting a link) and main-
tain the observed ratio of vandalism for a total of
10085 edits. For each edit in the test set, we com-
pute the probability of each modified sentence for
Cvandal and Cregular and generate the statistics for
the features described in 3.4. We compare the per-
formance of the language models and stylometric
features against a baseline classifier that is trained
on metadata, lexical and sentiment features using 10
fold stratified cross validation on the test set.
Results Table 1 shows the experimental results.
Because our dataset is highly skewed (97% corre-
sponds to “not vandalism”), we report F-score and
</bodyText>
<page confidence="0.991628">
85
</page>
<bodyText confidence="0.997679454545455">
One day rodrigo was in the school and he saw a
girl and she love her now and they are happy to-
gether
So listen Im going to attack ur family with mighty
powers.
He’s also the best granddaddy ever.
Beatrice Rosen (born 29 November 1985 (Happy
birthday)), also known as Batrice Rosen or Ba-
trice Rosenblatt, is a French-born actress. She is
best known for her role as Faith in the second sea-
son of the TV series “Cuts”.
</bodyText>
<tableCaption confidence="0.9156644">
Table 3: Examples of vandalism detected by base-
line+PCFG features. Baseline features alone could not
detect these vandalism. Notice that several stylistic fea-
tures present in these sentences are unlikely to appear in
normal Wikipedia articles.
</tableCaption>
<bodyText confidence="0.997972555555556">
AUC rather than accuracy.1 The baseline system,
which includes a wide range of features that are
shown to be highly effective in vandalism detection,
achieves F-score 52.6%, and AUC 91.6%. The base-
line features include all features introduced in Sec-
tion 3.
Adding language model features to the baseline
(denoted as +LM in Table 1) increases the F-score
slightly (53.5%), while the AUC score is almost
the same (91.7%). Adding PCFG based features to
the baseline (denoted as +PCFG) brings the most
substantial performance improvement: it increases
recall substantially while also improving precision,
achieving 57.9% F-score and 92.9% AUC. Combin-
ing both PCFG and language model based features
(denoted as +LM+PCFG) only results in a slight
improvement in AUC. From these results, we draw
the following conclusions:
</bodyText>
<listItem confidence="0.995331">
• There are indeed unique language styles in van-
dalism that can be detected with stylometric
analysis.
• Rather unexpectedly, deep syntax oriented fea-
tures based on PCFG bring a much more sub-
stantial improvement than language models
that capture only shallow lexico-syntactic pat-
terns.
</listItem>
<footnote confidence="0.568496">
1A naive rule that always chooses the majority class (“not
vandalism”) will receive zero F-score.
</footnote>
<bodyText confidence="0.998180545454545">
All those partaking in the event get absolutely
“fritzeld” and certain attendees have even been
known to soil themselves
March 10,1876 Alexander Grahm Ball dscovered
th telephone when axcidently spilt battery juice on
his expeiriment.
English remains the most widely spoken language
and New York is the largest city in the English
speaking world. Although massive pockets in
Queens and Brooklyn have 20% or less people
who speak English not so good.
</bodyText>
<tableCaption confidence="0.717007">
Table 4: Examples of vandalism that evaded both our
baseline and baseline+PCFG classifier. Dry wit, for
example, relies on context and may receive a good
score from the parser trained on regular Wikipedia edits
(�regular).
</tableCaption>
<bodyText confidence="0.9999704">
Feature Analysis Table 2 lists the information
gain ranking of our features. Notice that several of
our PCFG features are in the top ten most informa-
tive features. Language model based features were
ranked very low in the list, hence we do not include
them in the list. This finding will be potentially ad-
vantageous to many of the current anti-vandalism
tools such as vulgarisms, which rely only on shal-
low lexico-syntactic patterns.
Examples To provide more insight to the task, Ta-
ble 3 shows several instances where the addition
of the PCFG derived features detected vandalism
that the baseline approach could not. Notice that
the first example contains a lot of conjunctions that
would be hard to characterize using shallow lexico-
syntactic features. The second and third examples
also show sentence structure that are more informal
and vandalism-like. The fourth example is one that
is harder to catch. It looks almost like a benign edit,
however, what makes it a vandalism is the phrase
“(Happy Birthday)” inserted in the middle.
Table 4 shows examples where all of our systems
could not detect the vandalism correctly. Notice that
examples in Table 4 generally manifest more a for-
mal voice than those in Table 3.
</bodyText>
<sectionHeader confidence="0.999891" genericHeader="method">
5 Related Work
</sectionHeader>
<bodyText confidence="0.9860095">
Wang and McKeown (2010) present the first ap-
proach that is linguistically motivated. Their ap-
</bodyText>
<page confidence="0.99232">
86
</page>
<bodyText confidence="0.999974291666667">
proach was based on shallow syntactic patterns,
while ours explores the use of deep syntactic pat-
terns, and performs a comparative evaluation across
different stylometry analysis techniques. It is worth-
while to note that the approach of Wang and McKe-
own (2010) is not as practical and scalable as ours in
that it requires crawling a substantial number (150)
of webpages to detect each vandalism edit. From
our pilot study based on 1600 edits (50% of which
is vandalism), we found that the topic-specific lan-
guage models built from web search do not produce
stronger result than PCFG based features. We do
not have a result directly comparable to theirs how-
ever, as we could not crawl the necessary webpages
required to match the size of corpus.
The standard approach to Wikipedia vandalism
detection is to develop a feature based on either the
content or metadata and train a classifier to recog-
nize it. A comprehensive overview of what types
of features have been employed for this task can be
found in Potthast et al. (2010). WikiTrust, a repu-
tation system for Wikipedia authors, focuses on de-
termining the likely quality of a contribution (Adler
and de Alfaro, 2007).
</bodyText>
<sectionHeader confidence="0.985932" genericHeader="method">
6 Future Work and Conclusion
</sectionHeader>
<bodyText confidence="0.99996955">
This paper presents a vandalism detection system for
Wikipedia that uses stylometric features to aide in
classification. We show that deep syntactic patterns
based on PCFGs more effectively identify vandal-
ism than shallow lexico-syntactic patterns based on
n-grams or contextual language models. PCFGs do
not require the laborious process of performing web
searches to build context language models. Rather,
PCFGs are able to detect differences in language
styles between vandalizing edits and normal edits to
Wikipedia articles. Employing stylometric features
increases the baseline classification rate.
We are currently working to improve this tech-
nique through more effective training of our PCFG
parser. We look to automate the expansion of the
training set of vandalized revisions to include exam-
ples from outside of Wikipedia that reflect similar
language styles. We also are investigating how we
can better utilize the output of our PCFG parsers for
classification.
</bodyText>
<sectionHeader confidence="0.997776" genericHeader="conclusions">
7 Acknowledgments
</sectionHeader>
<bodyText confidence="0.999932">
We express our most sincere gratitude to Dr. Tamara
Berg and Dr. Luis Ortiz for their valuable guid-
ance and suggestions in applying Machine Learning
and Natural Language Processing techniques to the
task of vandalism detection. We also recognize the
hard work of Megha Bassi and Thanadit Phumprao
for assisting us in building our vandalism detection
pipeline that enabled us to perform these experi-
ments.
</bodyText>
<sectionHeader confidence="0.998011" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.995534794871795">
B. Thomas Adler and Luca de Alfaro. 2007. A content-
driven reputation system for the wikipedia. In Pro-
ceedings of the 16th international conference on World
Wide Web, WWW ’07, pages 261–270, New York, NY,
USA. ACM.
B. Thomas Adler, Luca de Alfaro, Santiago M. Mola-
Velasco, Paolo Rosso, and Andrew G. West. 2011.
Wikipedia vandalism detection: Combining natural
language, metadata, and reputation features. In CI-
CLing ’11: Proceedings of the 12th International Con-
ference on Intelligent Text Processing and Computa-
tional Linguistics.
Wayne Iba Ai and Pat Langley. 1992. Induction of one-
level decision trees. In Proceedings of the Ninth In-
ternational Conference on Machine Learning, pages
233–240. Morgan Kaufmann.
Alexa. 2011. Top 500 sites (retrieved April 2011).
http://www.alexa.com/topsites.
Shlomo Argamon, Moshe Koppel, James W. Pennebaker,
and Jonathan Schler. 2009. Automatically profiling
the author of an anonymous text. Commun. ACM,
52:119–123, February.
Si-Chi Chin, W. Nick Street, Padmini Srinivasan, and
David Eichmann. 2010. Detecting wikipedia vandal-
ism with active learning and statistical language mod-
els. In WICOW ’10: Proceedings of the 4rd Workshop
on Information Credibility on the Web.
J. Friedman, T. Hastie, and R. Tibshirani. 2000. Additive
Logistic Regression: a Statistical View of Boosting.
The Annals of Statistics, 38(2).
R. Stuart Geiger and David Ribes. 2010. The work of
sustaining order in wikipedia: the banning of a vandal.
In Proceedings of the 2010 ACM conference on Com-
puter supported cooperative work, CSCW ’10, pages
117–126, New York, NY, USA. ACM.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten.
2009. The weka data mining software: an update.
SIGKDDExplor. Newsl., 11(1):10–18.
</reference>
<page confidence="0.995131">
87
</page>
<reference confidence="0.999031">
Manoj Harpalani, Thanadit Phumprao, Megha Bassi,
Michael Hart, and Rob Johnson. 2010. Wiki
vandalysis- wikipedia vandalism analysis lab report
for pan at clef 2010.
Dan Klein and Christopher D. Manning. 2003. Accurate
unlexicalized parsing. In Proceedings of the 41st An-
nual Meeting on Association for Computational Lin-
guistics, pages 423–430. Association for Computa-
tional Linguistics.
Bo Pang and Lillian Lee. 2004. A sentimental edu-
cation: sentiment analysis using subjectivity summa-
rization based on minimum cuts. In Proceedings of
the 42nd Annual Meeting on Association for Compu-
tational Linguistics, ACL ’04, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Polina Panicheva, John Cardiff, and Paolo Rosso. 2010.
Personal sense and idiolect: Combining authorship at-
tribution and opinion analysis. In Nicoletta Calzo-
lari (Conference Chair), Khalid Choukri, Bente Mae-
gaard, Joseph Mariani, Jan Odijk, Stelios Piperidis,
Mike Rosner, and Daniel Tapias, editors, Proceed-
ings of the Seventh conference on International Lan-
guage Resources and Evaluation (LREC’10), Valletta,
Malta, may. European Language Resources Associa-
tion (ELRA).
Petra Perner and Sascha Trautzsch. 1998. Multi-interval
discretization methods for decision tree learning. In
In: Advances in Pattern Recognition, Joint IAPR In-
ternational Workshops SSPR 98 and SPR 98, pages
475–482.
Martin Potthast, Benno Stein, and Robert Gerling. 2008.
Automatic vandalism detection in wikipedia. In
ECIR’08: Proceedings of the IR research, 30th Euro-
pean conference on Advances in information retrieval,
pages 663–668, Berlin, Heidelberg. Springer-Verlag.
Martin Potthast, Benno Stein, and Teresa Holfeld. 2010.
Overview of the 1st International Competition on
Wikipedia Vandalism Detection. In Martin Braschler
and Donna Harman, editors, Notebook Papers of
CLEF 2010 LABs and Workshops, 22-23 September,
Padua, Italy, September.
Martin Potthast. 2010. Crowdsourcing a wikipedia van-
dalism corpus. In SIGIR’10, pages 789–790.
Sindhu Raghavan, Adriana Kovashka, and Raymond
Mooney. 2010. Authorship attribution using proba-
bilistic context-free grammars. In Proceedings of the
ACL, pages 38–42, Uppsala, Sweden, July. Associa-
tion for Computational Linguistics.
Efstathios Stamatatos. 2009. A survey of modern author-
ship attribution methods. J. Am. Soc. Inf. Sci. Technol.,
60:538–556, March.
M. Teresa Turell. 2010. The use of textual, grammatical
and sociolinguistic evidence in forensic text compari-
son:. International Journal of Speech Language and
the Law, 17(2).
William Yang Wang and Kathleen R. McKeown.
2010. “got you!”: Automatic vandalism detec-
tion in wikipedia with web-based shallow syntactic-
semantic modeling. In 23rd International Conference
on Computational Linguistics (Coling 2010), page
1146?1154.
Andrew G. West, Sampath Kannan, and Insup Lee. 2010.
Detecting wikipedia vandalism via spatio-temporal
analysis of revision metadata. In EUROSEC ’10: Pro-
ceedings of the Third European Workshop on System
Security, pages 22–28, New York, NY, USA. ACM.
Wikipedia. 2010. Daily edit statistics.
http://stats.wikimedia.org/EN/
PlotsPngDatabaseEdits.htm.
Wikipedia. 2011. Wikipedia. http://www.
wikipedia.org.
</reference>
<page confidence="0.999405">
88
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.228200">
<title confidence="0.9962455">Language of Vandalism: Improving Wikipedia Vandalism Detection via Stylometric Analysis</title>
<author confidence="0.963848">Manoj Harpalani</author>
<author confidence="0.963848">Michael Hart</author>
<author confidence="0.963848">Sandesh Singh</author>
<author confidence="0.963848">Rob Johnson</author>
<author confidence="0.963848">Yejin</author>
<affiliation confidence="0.6435555">Department of Computer Stony Brook</affiliation>
<address confidence="0.815607">NY 11794,</address>
<email confidence="0.774344">mhart,sssingh,rob,</email>
<abstract confidence="0.999459">Community-based knowledge forums, such as are susceptible to i.e., ill-intentioned contributions that are detrimental to the quality of collective intelligence. Most previous work to date relies on shallow lexico-syntactic patterns and metadata to automatically detect vandalism in Wikipedia. In this paper, we explore more linguistically motivated approaches to vandalism detection. In particular, we hypothesize that textual vandalconstitutes a unique a group of people share a similar linguistic behavior. Experimental results suggest that (1) statistical models give evidence to unique language styles in vandalism, and that (2) deep syntactic patterns based on probabilistic context free grammars (PCFG) discriminate vandalism more effectively than shallow lexicosyntactic patterns based on n-grams.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B Thomas Adler</author>
<author>Luca de Alfaro</author>
</authors>
<title>A contentdriven reputation system for the wikipedia.</title>
<date>2007</date>
<booktitle>In Proceedings of the 16th international conference on World Wide Web, WWW ’07,</booktitle>
<pages>261--270</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<marker>Adler, de Alfaro, 2007</marker>
<rawString>B. Thomas Adler and Luca de Alfaro. 2007. A contentdriven reputation system for the wikipedia. In Proceedings of the 16th international conference on World Wide Web, WWW ’07, pages 261–270, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Thomas Adler</author>
<author>Luca de Alfaro</author>
<author>Santiago M MolaVelasco</author>
<author>Paolo Rosso</author>
<author>Andrew G West</author>
</authors>
<title>Wikipedia vandalism detection: Combining natural language, metadata, and reputation features.</title>
<date>2011</date>
<booktitle>In CICLing ’11: Proceedings of the 12th International Conference on Intelligent Text Processing and Computational Linguistics.</booktitle>
<marker>Adler, de Alfaro, MolaVelasco, Rosso, West, 2011</marker>
<rawString>B. Thomas Adler, Luca de Alfaro, Santiago M. MolaVelasco, Paolo Rosso, and Andrew G. West. 2011. Wikipedia vandalism detection: Combining natural language, metadata, and reputation features. In CICLing ’11: Proceedings of the 12th International Conference on Intelligent Text Processing and Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wayne Iba Ai</author>
<author>Pat Langley</author>
</authors>
<title>Induction of onelevel decision trees.</title>
<date>1992</date>
<booktitle>In Proceedings of the Ninth International Conference on Machine Learning,</booktitle>
<pages>233--240</pages>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="9140" citStr="Ai and Langley, 1992" startWordPosition="1421" endWordPosition="1424">gular edit and vandalizing edit LMs. For our PCFG, we take the difference between the minimum log-likelihood score (i.e. the sentences with the minimum log-likelihood) of Cvandal and Cregular, the difference in the maximum log-likelihood score, the difference in the mean log-likelihood score, the difference in the standard deviation of the mean log-likelihood score and the difference in the sum of the log-likelihood scores. 3.5 Choice of Classifier We use Weka’s (Hall et al., 2009) implementation of LogitBoost (Friedman et al., 2000) to perform the classification task. We use Decision Stumps (Ai and Langley, 1992) as the base learner and run LogitBoost for 500 iterations. We also discretize the training data using the Multi-Level Discretization technique (Perner and Trautzsch, 1998). 4 Experimental Results Data We use the 2010 PAN Wikipedia vandalism corpus Potthast et al. (2010) to quantify the benFeature Score Total number of author contributions 0.106 How long the author has been registered 0.098 How frequently the author contributed 0.097 in the training set If the author is registered 0.0885 Difference in the maximum PCFG scores 0.0437 Difference in the mean PCFG scores 0.0377 How many times the a</context>
</contexts>
<marker>Ai, Langley, 1992</marker>
<rawString>Wayne Iba Ai and Pat Langley. 1992. Induction of onelevel decision trees. In Proceedings of the Ninth International Conference on Machine Learning, pages 233–240. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexa</author>
</authors>
<title>Top 500 sites (retrieved</title>
<date>2011</date>
<note>http://www.alexa.com/topsites.</note>
<contexts>
<context position="1279" citStr="Alexa, 2011" startWordPosition="177" endWordPosition="178">d approaches to vandalism detection. In particular, we hypothesize that textual vandalism constitutes a unique genre where a group of people share a similar linguistic behavior. Experimental results suggest that (1) statistical models give evidence to unique language styles in vandalism, and that (2) deep syntactic patterns based on probabilistic context free grammars (PCFG) discriminate vandalism more effectively than shallow lexicosyntactic patterns based on n-grams. 1 Introduction Wikipedia, the “free encyclopedia” (Wikipedia, 2011), ranks among the top 200 most visited websites worldwide (Alexa, 2011). This editable encyclopedia has amassed over 15 million articles across hundreds of languages. The English language encyclopedia alone has over 3.5 million articles and receives over 1.25 million edits (and sometimes upwards of 3 million) daily (Wikipedia, 2010). But allowing anonymous edits is a double-edged sword; nearly 7% (Potthast, 2010) of edits are vandalism, i.e. revisions to articles that undermine the quality and veracity of the content. As Wikipedia continues to grow, it will become increasingly infeasible for Wikipedia users and administrators to manually police articles. This pre</context>
</contexts>
<marker>Alexa, 2011</marker>
<rawString>Alexa. 2011. Top 500 sites (retrieved April 2011). http://www.alexa.com/topsites.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shlomo Argamon</author>
<author>Moshe Koppel</author>
<author>James W Pennebaker</author>
<author>Jonathan Schler</author>
</authors>
<title>Automatically profiling the author of an anonymous text.</title>
<date>2009</date>
<journal>Commun. ACM,</journal>
<pages>52--119</pages>
<contexts>
<context position="3377" citStr="Argamon et al. (2009)" startWordPosition="490" endWordPosition="493">ngs, and slang usage, but we aim to automatically uncover stylistic cues to effectively discriminate between vandalizing and normal text. Experimental results suggest that (1) statistical models give evidence to unique language styles in vandalism, and that (2) deep syntactic patterns based on probabilistic context free grammar (PCFG) discriminate vandalism more effectively than shallow lexico-syntactic patterns based on n-grams. 2 Stylometric Features Stylometric features attempt to recognize patterns of style in text. These techniques have been traditionally applied to attribute authorship (Argamon et al. (2009), Stamatatos (2009)), opinion mining 83 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 83–88, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics (Panicheva et al., 2010), and forensic linguistics (Turell, 2010). For our purposes, we hypothesize that different stylistic features appear in regular and vandalizing edits. For regular edits, honest editors will strive to follow the stylistic guidelines set forth by Wikipedia (e.g. objectivity, neutrality and factuality). For edits that vandalize articles, </context>
</contexts>
<marker>Argamon, Koppel, Pennebaker, Schler, 2009</marker>
<rawString>Shlomo Argamon, Moshe Koppel, James W. Pennebaker, and Jonathan Schler. 2009. Automatically profiling the author of an anonymous text. Commun. ACM, 52:119–123, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Si-Chi Chin</author>
<author>W Nick Street</author>
<author>Padmini Srinivasan</author>
<author>David Eichmann</author>
</authors>
<title>Detecting wikipedia vandalism with active learning and statistical language models.</title>
<date>2010</date>
<booktitle>In WICOW ’10: Proceedings of the 4rd Workshop on Information Credibility on the Web.</booktitle>
<contexts>
<context position="2442" citStr="Chin et al. (2010)" startWordPosition="352" endWordPosition="355">nd administrators to manually police articles. This pressing issue has spawned recent research activities to understand and counteract vandalism (e.g., Geiger and Ribes (2010)). Much of previous work relies on hand-picked rules such as lexical cues (e.g., vulgar words) and metadata (e.g., anonymity, edit frequency) to automatically detect vandalism in Wikipedia (e.g., Potthast et al. (2008), West et al. (2010)). Although some recent work has started exploring the use of natural language processing, most work to date is based on shallow lexico-syntactic patterns (e.g., Wang and McKeown (2010), Chin et al. (2010), Adler et al. (2011)). We explore more linguistically motivated approaches to detect vandalism in this paper. Our hypothesis is that textual vandalism constitutes a unique genre where a group of people share similar linguistic behavior. Some obvious hallmarks of this style include usage of obscenities, misspellings, and slang usage, but we aim to automatically uncover stylistic cues to effectively discriminate between vandalizing and normal text. Experimental results suggest that (1) statistical models give evidence to unique language styles in vandalism, and that (2) deep syntactic patterns </context>
</contexts>
<marker>Chin, Street, Srinivasan, Eichmann, 2010</marker>
<rawString>Si-Chi Chin, W. Nick Street, Padmini Srinivasan, and David Eichmann. 2010. Detecting wikipedia vandalism with active learning and statistical language models. In WICOW ’10: Proceedings of the 4rd Workshop on Information Credibility on the Web.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Friedman</author>
<author>T Hastie</author>
<author>R Tibshirani</author>
</authors>
<title>Additive Logistic Regression: a Statistical View of Boosting.</title>
<date>2000</date>
<journal>The Annals of Statistics,</journal>
<volume>38</volume>
<issue>2</issue>
<contexts>
<context position="9058" citStr="Friedman et al., 2000" startWordPosition="1408" endWordPosition="1411"> following manner for training our classifier. We take the log-likelihood of the regular edit and vandalizing edit LMs. For our PCFG, we take the difference between the minimum log-likelihood score (i.e. the sentences with the minimum log-likelihood) of Cvandal and Cregular, the difference in the maximum log-likelihood score, the difference in the mean log-likelihood score, the difference in the standard deviation of the mean log-likelihood score and the difference in the sum of the log-likelihood scores. 3.5 Choice of Classifier We use Weka’s (Hall et al., 2009) implementation of LogitBoost (Friedman et al., 2000) to perform the classification task. We use Decision Stumps (Ai and Langley, 1992) as the base learner and run LogitBoost for 500 iterations. We also discretize the training data using the Multi-Level Discretization technique (Perner and Trautzsch, 1998). 4 Experimental Results Data We use the 2010 PAN Wikipedia vandalism corpus Potthast et al. (2010) to quantify the benFeature Score Total number of author contributions 0.106 How long the author has been registered 0.098 How frequently the author contributed 0.097 in the training set If the author is registered 0.0885 Difference in the maximum</context>
</contexts>
<marker>Friedman, Hastie, Tibshirani, 2000</marker>
<rawString>J. Friedman, T. Hastie, and R. Tibshirani. 2000. Additive Logistic Regression: a Statistical View of Boosting. The Annals of Statistics, 38(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Stuart Geiger</author>
<author>David Ribes</author>
</authors>
<title>The work of sustaining order in wikipedia: the banning of a vandal.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 ACM conference on Computer supported cooperative work, CSCW ’10,</booktitle>
<pages>117--126</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1999" citStr="Geiger and Ribes (2010)" startWordPosition="284" endWordPosition="287">he English language encyclopedia alone has over 3.5 million articles and receives over 1.25 million edits (and sometimes upwards of 3 million) daily (Wikipedia, 2010). But allowing anonymous edits is a double-edged sword; nearly 7% (Potthast, 2010) of edits are vandalism, i.e. revisions to articles that undermine the quality and veracity of the content. As Wikipedia continues to grow, it will become increasingly infeasible for Wikipedia users and administrators to manually police articles. This pressing issue has spawned recent research activities to understand and counteract vandalism (e.g., Geiger and Ribes (2010)). Much of previous work relies on hand-picked rules such as lexical cues (e.g., vulgar words) and metadata (e.g., anonymity, edit frequency) to automatically detect vandalism in Wikipedia (e.g., Potthast et al. (2008), West et al. (2010)). Although some recent work has started exploring the use of natural language processing, most work to date is based on shallow lexico-syntactic patterns (e.g., Wang and McKeown (2010), Chin et al. (2010), Adler et al. (2011)). We explore more linguistically motivated approaches to detect vandalism in this paper. Our hypothesis is that textual vandalism const</context>
</contexts>
<marker>Geiger, Ribes, 2010</marker>
<rawString>R. Stuart Geiger and David Ribes. 2010. The work of sustaining order in wikipedia: the banning of a vandal. In Proceedings of the 2010 ACM conference on Computer supported cooperative work, CSCW ’10, pages 117–126, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hall</author>
<author>Eibe Frank</author>
<author>Geoffrey Holmes</author>
<author>Bernhard Pfahringer</author>
<author>Peter Reutemann</author>
<author>Ian H Witten</author>
</authors>
<title>The weka data mining software: an update.</title>
<date>2009</date>
<journal>SIGKDDExplor. Newsl.,</journal>
<volume>11</volume>
<issue>1</issue>
<contexts>
<context position="9005" citStr="Hall et al., 2009" startWordPosition="1401" endWordPosition="1404">es We encode the output of the LM and PCFG in the following manner for training our classifier. We take the log-likelihood of the regular edit and vandalizing edit LMs. For our PCFG, we take the difference between the minimum log-likelihood score (i.e. the sentences with the minimum log-likelihood) of Cvandal and Cregular, the difference in the maximum log-likelihood score, the difference in the mean log-likelihood score, the difference in the standard deviation of the mean log-likelihood score and the difference in the sum of the log-likelihood scores. 3.5 Choice of Classifier We use Weka’s (Hall et al., 2009) implementation of LogitBoost (Friedman et al., 2000) to perform the classification task. We use Decision Stumps (Ai and Langley, 1992) as the base learner and run LogitBoost for 500 iterations. We also discretize the training data using the Multi-Level Discretization technique (Perner and Trautzsch, 1998). 4 Experimental Results Data We use the 2010 PAN Wikipedia vandalism corpus Potthast et al. (2010) to quantify the benFeature Score Total number of author contributions 0.106 How long the author has been registered 0.098 How frequently the author contributed 0.097 in the training set If the </context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H. Witten. 2009. The weka data mining software: an update. SIGKDDExplor. Newsl., 11(1):10–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manoj Harpalani</author>
<author>Thanadit Phumprao</author>
<author>Megha Bassi</author>
<author>Michael Hart</author>
<author>Rob Johnson</author>
</authors>
<title>Wiki vandalysis- wikipedia vandalism analysis lab report for pan at clef</title>
<date>2010</date>
<contexts>
<context position="6436" citStr="Harpalani et al. (2010)" startWordPosition="970" endWordPosition="973">r score determines the class of the edit. We use the PCFG implementation of Klein and Manning (2003). 3 System Description Our system decides if an edit to an article is vandalism by training a classifier based on a set of features derived from many different aspects of the edit. For this task, we use an annotated corpus (Potthast et al., 2010) of Wikipedia edits where revisions are labeled as either vandalizing or non-vandalizing. This section will describe in brief the features used by our classifier, a more exhaustive description of our non-linguistically motivated features can be found in Harpalani et al. (2010). 3.1 Features Based on Metadata Our classifier takes into account metadata generated by the revision. We generate features based on author reputation by recording if the edit is submitted by an anonymous user or a registered user. If the author is registered, we record how long he has been registered, how many times he has previously vandalized Wikipedia, and how frequent he edits articles. We also take into account the comment left by an author. We generate features based on the characteristics of the articles revision history. This includes how many times the article has been previously van</context>
</contexts>
<marker>Harpalani, Phumprao, Bassi, Hart, Johnson, 2010</marker>
<rawString>Manoj Harpalani, Thanadit Phumprao, Megha Bassi, Michael Hart, and Rob Johnson. 2010. Wiki vandalysis- wikipedia vandalism analysis lab report for pan at clef 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>423--430</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5913" citStr="Klein and Manning (2003)" startWordPosition="883" endWordPosition="886">r Brown, tree-bank each training document di E D using the generic PCFG parser Co. (2) Learn vandalism language by training a new PCFG parser Cvandal using only those treebanked documents in D that correspond to vandalism. Likewise, learn regular Wikipedia language by training a new PCFG parser Cregular using only those tree-banked documents in D that correspond to regular Wikipedia edits. (3) For each test document, compare the probability of the edit determined by Cvandal and Cregular, where the parser with the higher score determines the class of the edit. We use the PCFG implementation of Klein and Manning (2003). 3 System Description Our system decides if an edit to an article is vandalism by training a classifier based on a set of features derived from many different aspects of the edit. For this task, we use an annotated corpus (Potthast et al., 2010) of Wikipedia edits where revisions are labeled as either vandalizing or non-vandalizing. This section will describe in brief the features used by our classifier, a more exhaustive description of our non-linguistically motivated features can be found in Harpalani et al. (2010). 3.1 Features Based on Metadata Our classifier takes into account metadata g</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics, pages 423–430. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>A sentimental education: sentiment analysis using subjectivity summarization based on minimum cuts.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, ACL ’04,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="8031" citStr="Pang and Lee (2004)" startWordPosition="1241" endWordPosition="1244">nce between the old and new revision, the number of repeated patterns, slang words, vulgarities and pronouns, the type of edit (insert, modification or delete) and other similar features. 84 Features P R F1 AUC Baseline 72.8 41.1 52.6 91.6 +LM 73.3 42.1 53.5 91.7 +PCFG 73.5 47.7 57.9 92.9 +LM+PCFG 73.2 47.3 57.5 93.0 Table 1: Results on naturally unbalanced test data 3.3 Features Based on Sentiment Wikipedia editors strive to maintain a neutral and objective voice in articles. Vandals, however, insert subjective and polar statements into articles. We build two classifiers based on the work of Pang and Lee (2004) to measure the polarity and objectivity of article edits. We train the classifier on how many positive and negative sentences were inserted as well as the overall change in the sentiment score from the previous version to the new revision and the number of inserted or deleted subjective sentences in the revision. 3.4 Features Based on Stylometric Measures We encode the output of the LM and PCFG in the following manner for training our classifier. We take the log-likelihood of the regular edit and vandalizing edit LMs. For our PCFG, we take the difference between the minimum log-likelihood sco</context>
</contexts>
<marker>Pang, Lee, 2004</marker>
<rawString>Bo Pang and Lillian Lee. 2004. A sentimental education: sentiment analysis using subjectivity summarization based on minimum cuts. In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, ACL ’04, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Polina Panicheva</author>
<author>John Cardiff</author>
<author>Paolo Rosso</author>
</authors>
<title>Personal sense and idiolect: Combining authorship attribution and opinion analysis.</title>
<date>2010</date>
<booktitle>Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC’10),</booktitle>
<editor>In Nicoletta Calzolari (Conference Chair), Khalid Choukri, Bente Maegaard, Joseph Mariani, Jan Odijk, Stelios Piperidis, Mike Rosner, and Daniel Tapias, editors,</editor>
<location>Valletta, Malta,</location>
<contexts>
<context position="3640" citStr="Panicheva et al., 2010" startWordPosition="523" endWordPosition="526"> deep syntactic patterns based on probabilistic context free grammar (PCFG) discriminate vandalism more effectively than shallow lexico-syntactic patterns based on n-grams. 2 Stylometric Features Stylometric features attempt to recognize patterns of style in text. These techniques have been traditionally applied to attribute authorship (Argamon et al. (2009), Stamatatos (2009)), opinion mining 83 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 83–88, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics (Panicheva et al., 2010), and forensic linguistics (Turell, 2010). For our purposes, we hypothesize that different stylistic features appear in regular and vandalizing edits. For regular edits, honest editors will strive to follow the stylistic guidelines set forth by Wikipedia (e.g. objectivity, neutrality and factuality). For edits that vandalize articles, these users may converge on common ways of vandalizing articles. 2.1 Language Models To differentiate between the styles of normal users and vandalizers, we employ language models to capture the stylistic differences between authentic and vandalizing revisions. W</context>
</contexts>
<marker>Panicheva, Cardiff, Rosso, 2010</marker>
<rawString>Polina Panicheva, John Cardiff, and Paolo Rosso. 2010. Personal sense and idiolect: Combining authorship attribution and opinion analysis. In Nicoletta Calzolari (Conference Chair), Khalid Choukri, Bente Maegaard, Joseph Mariani, Jan Odijk, Stelios Piperidis, Mike Rosner, and Daniel Tapias, editors, Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC’10), Valletta, Malta, may. European Language Resources Association (ELRA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Petra Perner</author>
<author>Sascha Trautzsch</author>
</authors>
<title>Multi-interval discretization methods for decision tree learning. In In:</title>
<date>1998</date>
<booktitle>Advances in Pattern Recognition, Joint IAPR International Workshops SSPR 98 and SPR 98,</booktitle>
<pages>475--482</pages>
<contexts>
<context position="9312" citStr="Perner and Trautzsch, 1998" startWordPosition="1449" endWordPosition="1452">) of Cvandal and Cregular, the difference in the maximum log-likelihood score, the difference in the mean log-likelihood score, the difference in the standard deviation of the mean log-likelihood score and the difference in the sum of the log-likelihood scores. 3.5 Choice of Classifier We use Weka’s (Hall et al., 2009) implementation of LogitBoost (Friedman et al., 2000) to perform the classification task. We use Decision Stumps (Ai and Langley, 1992) as the base learner and run LogitBoost for 500 iterations. We also discretize the training data using the Multi-Level Discretization technique (Perner and Trautzsch, 1998). 4 Experimental Results Data We use the 2010 PAN Wikipedia vandalism corpus Potthast et al. (2010) to quantify the benFeature Score Total number of author contributions 0.106 How long the author has been registered 0.098 How frequently the author contributed 0.097 in the training set If the author is registered 0.0885 Difference in the maximum PCFG scores 0.0437 Difference in the mean PCFG scores 0.0377 How many times the article has been reverted 0.0372 Total contributions of author to Wikipedia 0.0343 Previous vandalism count of the article 0.0325 Difference in the sum of PCFG scores 0.0320</context>
</contexts>
<marker>Perner, Trautzsch, 1998</marker>
<rawString>Petra Perner and Sascha Trautzsch. 1998. Multi-interval discretization methods for decision tree learning. In In: Advances in Pattern Recognition, Joint IAPR International Workshops SSPR 98 and SPR 98, pages 475–482.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Potthast</author>
<author>Benno Stein</author>
<author>Robert Gerling</author>
</authors>
<title>Automatic vandalism detection in wikipedia.</title>
<date>2008</date>
<booktitle>In ECIR’08: Proceedings of the IR research, 30th European conference on Advances in information retrieval,</booktitle>
<pages>663--668</pages>
<publisher>Springer-Verlag.</publisher>
<location>Berlin, Heidelberg.</location>
<contexts>
<context position="2217" citStr="Potthast et al. (2008)" startWordPosition="316" endWordPosition="319">d; nearly 7% (Potthast, 2010) of edits are vandalism, i.e. revisions to articles that undermine the quality and veracity of the content. As Wikipedia continues to grow, it will become increasingly infeasible for Wikipedia users and administrators to manually police articles. This pressing issue has spawned recent research activities to understand and counteract vandalism (e.g., Geiger and Ribes (2010)). Much of previous work relies on hand-picked rules such as lexical cues (e.g., vulgar words) and metadata (e.g., anonymity, edit frequency) to automatically detect vandalism in Wikipedia (e.g., Potthast et al. (2008), West et al. (2010)). Although some recent work has started exploring the use of natural language processing, most work to date is based on shallow lexico-syntactic patterns (e.g., Wang and McKeown (2010), Chin et al. (2010), Adler et al. (2011)). We explore more linguistically motivated approaches to detect vandalism in this paper. Our hypothesis is that textual vandalism constitutes a unique genre where a group of people share similar linguistic behavior. Some obvious hallmarks of this style include usage of obscenities, misspellings, and slang usage, but we aim to automatically uncover sty</context>
</contexts>
<marker>Potthast, Stein, Gerling, 2008</marker>
<rawString>Martin Potthast, Benno Stein, and Robert Gerling. 2008. Automatic vandalism detection in wikipedia. In ECIR’08: Proceedings of the IR research, 30th European conference on Advances in information retrieval, pages 663–668, Berlin, Heidelberg. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Potthast</author>
<author>Benno Stein</author>
<author>Teresa Holfeld</author>
</authors>
<date>2010</date>
<booktitle>Overview of the 1st International Competition on Wikipedia Vandalism Detection. In Martin Braschler and</booktitle>
<pages>22--23</pages>
<editor>Donna Harman, editors,</editor>
<location>Padua, Italy,</location>
<contexts>
<context position="6159" citStr="Potthast et al., 2010" startWordPosition="928" endWordPosition="931">ikipedia language by training a new PCFG parser Cregular using only those tree-banked documents in D that correspond to regular Wikipedia edits. (3) For each test document, compare the probability of the edit determined by Cvandal and Cregular, where the parser with the higher score determines the class of the edit. We use the PCFG implementation of Klein and Manning (2003). 3 System Description Our system decides if an edit to an article is vandalism by training a classifier based on a set of features derived from many different aspects of the edit. For this task, we use an annotated corpus (Potthast et al., 2010) of Wikipedia edits where revisions are labeled as either vandalizing or non-vandalizing. This section will describe in brief the features used by our classifier, a more exhaustive description of our non-linguistically motivated features can be found in Harpalani et al. (2010). 3.1 Features Based on Metadata Our classifier takes into account metadata generated by the revision. We generate features based on author reputation by recording if the edit is submitted by an anonymous user or a registered user. If the author is registered, we record how long he has been registered, how many times he h</context>
<context position="9411" citStr="Potthast et al. (2010)" startWordPosition="1465" endWordPosition="1468">n log-likelihood score, the difference in the standard deviation of the mean log-likelihood score and the difference in the sum of the log-likelihood scores. 3.5 Choice of Classifier We use Weka’s (Hall et al., 2009) implementation of LogitBoost (Friedman et al., 2000) to perform the classification task. We use Decision Stumps (Ai and Langley, 1992) as the base learner and run LogitBoost for 500 iterations. We also discretize the training data using the Multi-Level Discretization technique (Perner and Trautzsch, 1998). 4 Experimental Results Data We use the 2010 PAN Wikipedia vandalism corpus Potthast et al. (2010) to quantify the benFeature Score Total number of author contributions 0.106 How long the author has been registered 0.098 How frequently the author contributed 0.097 in the training set If the author is registered 0.0885 Difference in the maximum PCFG scores 0.0437 Difference in the mean PCFG scores 0.0377 How many times the article has been reverted 0.0372 Total contributions of author to Wikipedia 0.0343 Previous vandalism count of the article 0.0325 Difference in the sum of PCFG scores 0.0320 Table 2: Top 10 ranked features on the unbalanced test data by InfoGain efit of stylometric analys</context>
<context position="16361" citStr="Potthast et al. (2010)" startWordPosition="2608" endWordPosition="2611">m our pilot study based on 1600 edits (50% of which is vandalism), we found that the topic-specific language models built from web search do not produce stronger result than PCFG based features. We do not have a result directly comparable to theirs however, as we could not crawl the necessary webpages required to match the size of corpus. The standard approach to Wikipedia vandalism detection is to develop a feature based on either the content or metadata and train a classifier to recognize it. A comprehensive overview of what types of features have been employed for this task can be found in Potthast et al. (2010). WikiTrust, a reputation system for Wikipedia authors, focuses on determining the likely quality of a contribution (Adler and de Alfaro, 2007). 6 Future Work and Conclusion This paper presents a vandalism detection system for Wikipedia that uses stylometric features to aide in classification. We show that deep syntactic patterns based on PCFGs more effectively identify vandalism than shallow lexico-syntactic patterns based on n-grams or contextual language models. PCFGs do not require the laborious process of performing web searches to build context language models. Rather, PCFGs are able to </context>
</contexts>
<marker>Potthast, Stein, Holfeld, 2010</marker>
<rawString>Martin Potthast, Benno Stein, and Teresa Holfeld. 2010. Overview of the 1st International Competition on Wikipedia Vandalism Detection. In Martin Braschler and Donna Harman, editors, Notebook Papers of CLEF 2010 LABs and Workshops, 22-23 September, Padua, Italy, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Potthast</author>
</authors>
<title>Crowdsourcing a wikipedia vandalism corpus.</title>
<date>2010</date>
<booktitle>In SIGIR’10,</booktitle>
<pages>789--790</pages>
<contexts>
<context position="1624" citStr="Potthast, 2010" startWordPosition="230" endWordPosition="231">listic context free grammars (PCFG) discriminate vandalism more effectively than shallow lexicosyntactic patterns based on n-grams. 1 Introduction Wikipedia, the “free encyclopedia” (Wikipedia, 2011), ranks among the top 200 most visited websites worldwide (Alexa, 2011). This editable encyclopedia has amassed over 15 million articles across hundreds of languages. The English language encyclopedia alone has over 3.5 million articles and receives over 1.25 million edits (and sometimes upwards of 3 million) daily (Wikipedia, 2010). But allowing anonymous edits is a double-edged sword; nearly 7% (Potthast, 2010) of edits are vandalism, i.e. revisions to articles that undermine the quality and veracity of the content. As Wikipedia continues to grow, it will become increasingly infeasible for Wikipedia users and administrators to manually police articles. This pressing issue has spawned recent research activities to understand and counteract vandalism (e.g., Geiger and Ribes (2010)). Much of previous work relies on hand-picked rules such as lexical cues (e.g., vulgar words) and metadata (e.g., anonymity, edit frequency) to automatically detect vandalism in Wikipedia (e.g., Potthast et al. (2008), West </context>
</contexts>
<marker>Potthast, 2010</marker>
<rawString>Martin Potthast. 2010. Crowdsourcing a wikipedia vandalism corpus. In SIGIR’10, pages 789–790.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sindhu Raghavan</author>
<author>Adriana Kovashka</author>
<author>Raymond Mooney</author>
</authors>
<title>Authorship attribution using probabilistic context-free grammars.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>38--42</pages>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="4718" citStr="Raghavan et al. (2010)" startWordPosition="679" endWordPosition="682">s of normal users and vandalizers, we employ language models to capture the stylistic differences between authentic and vandalizing revisions. We train two trigram language model (LM) with Good-Turing discounting and Katz backoff for smoothing of vandalizing edits (based on the text difference between the vandalizing and previous revision) and good edits (based on the text difference between the new and previous revision). 2.2 Probabilistic Context Free Grammar (PCFG) Models Probabilistic context-free grammars (PCFG) capture deep syntactic regularities beyond shallow lexicosyntactic patterns. Raghavan et al. (2010) reported for the first time that PCFG models are effective in learning stylometric signature of authorship at deep syntactic levels. In this work, we explore the use of PCFG models for vandalism detection, by viewing the task as a genre detection problem, where a group of authors share similar linguistic behavior. We give a concise description of the use of PCFG models below, referring to Raghavan et al. (2010) for more details. (1) Given a training corpus D for vandalism detection and a generic PCFG parser Co trained on a manually tree-banked corpus such as WSJ or Brown, tree-bank each train</context>
</contexts>
<marker>Raghavan, Kovashka, Mooney, 2010</marker>
<rawString>Sindhu Raghavan, Adriana Kovashka, and Raymond Mooney. 2010. Authorship attribution using probabilistic context-free grammars. In Proceedings of the ACL, pages 38–42, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Efstathios Stamatatos</author>
</authors>
<title>A survey of modern authorship attribution methods.</title>
<date>2009</date>
<journal>J. Am. Soc. Inf. Sci. Technol.,</journal>
<pages>60--538</pages>
<contexts>
<context position="3396" citStr="Stamatatos (2009)" startWordPosition="494" endWordPosition="495">ut we aim to automatically uncover stylistic cues to effectively discriminate between vandalizing and normal text. Experimental results suggest that (1) statistical models give evidence to unique language styles in vandalism, and that (2) deep syntactic patterns based on probabilistic context free grammar (PCFG) discriminate vandalism more effectively than shallow lexico-syntactic patterns based on n-grams. 2 Stylometric Features Stylometric features attempt to recognize patterns of style in text. These techniques have been traditionally applied to attribute authorship (Argamon et al. (2009), Stamatatos (2009)), opinion mining 83 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 83–88, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics (Panicheva et al., 2010), and forensic linguistics (Turell, 2010). For our purposes, we hypothesize that different stylistic features appear in regular and vandalizing edits. For regular edits, honest editors will strive to follow the stylistic guidelines set forth by Wikipedia (e.g. objectivity, neutrality and factuality). For edits that vandalize articles, these users may con</context>
</contexts>
<marker>Stamatatos, 2009</marker>
<rawString>Efstathios Stamatatos. 2009. A survey of modern authorship attribution methods. J. Am. Soc. Inf. Sci. Technol., 60:538–556, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Teresa Turell</author>
</authors>
<title>The use of textual, grammatical and sociolinguistic evidence in forensic text comparison:.</title>
<date>2010</date>
<journal>International Journal of Speech Language and the Law,</journal>
<volume>17</volume>
<issue>2</issue>
<contexts>
<context position="3681" citStr="Turell, 2010" startWordPosition="530" endWordPosition="531">text free grammar (PCFG) discriminate vandalism more effectively than shallow lexico-syntactic patterns based on n-grams. 2 Stylometric Features Stylometric features attempt to recognize patterns of style in text. These techniques have been traditionally applied to attribute authorship (Argamon et al. (2009), Stamatatos (2009)), opinion mining 83 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 83–88, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics (Panicheva et al., 2010), and forensic linguistics (Turell, 2010). For our purposes, we hypothesize that different stylistic features appear in regular and vandalizing edits. For regular edits, honest editors will strive to follow the stylistic guidelines set forth by Wikipedia (e.g. objectivity, neutrality and factuality). For edits that vandalize articles, these users may converge on common ways of vandalizing articles. 2.1 Language Models To differentiate between the styles of normal users and vandalizers, we employ language models to capture the stylistic differences between authentic and vandalizing revisions. We train two trigram language model (LM) w</context>
</contexts>
<marker>Turell, 2010</marker>
<rawString>M. Teresa Turell. 2010. The use of textual, grammatical and sociolinguistic evidence in forensic text comparison:. International Journal of Speech Language and the Law, 17(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Yang Wang</author>
<author>Kathleen R McKeown</author>
</authors>
<title>got you!”: Automatic vandalism detection in wikipedia with web-based shallow syntacticsemantic modeling.</title>
<date>2010</date>
<booktitle>In 23rd International Conference on Computational Linguistics (Coling 2010),</booktitle>
<pages>1146--1154</pages>
<contexts>
<context position="2422" citStr="Wang and McKeown (2010)" startWordPosition="348" endWordPosition="351">ble for Wikipedia users and administrators to manually police articles. This pressing issue has spawned recent research activities to understand and counteract vandalism (e.g., Geiger and Ribes (2010)). Much of previous work relies on hand-picked rules such as lexical cues (e.g., vulgar words) and metadata (e.g., anonymity, edit frequency) to automatically detect vandalism in Wikipedia (e.g., Potthast et al. (2008), West et al. (2010)). Although some recent work has started exploring the use of natural language processing, most work to date is based on shallow lexico-syntactic patterns (e.g., Wang and McKeown (2010), Chin et al. (2010), Adler et al. (2011)). We explore more linguistically motivated approaches to detect vandalism in this paper. Our hypothesis is that textual vandalism constitutes a unique genre where a group of people share similar linguistic behavior. Some obvious hallmarks of this style include usage of obscenities, misspellings, and slang usage, but we aim to automatically uncover stylistic cues to effectively discriminate between vandalizing and normal text. Experimental results suggest that (1) statistical models give evidence to unique language styles in vandalism, and that (2) deep</context>
<context position="15262" citStr="Wang and McKeown (2010)" startWordPosition="2420" endWordPosition="2423">first example contains a lot of conjunctions that would be hard to characterize using shallow lexicosyntactic features. The second and third examples also show sentence structure that are more informal and vandalism-like. The fourth example is one that is harder to catch. It looks almost like a benign edit, however, what makes it a vandalism is the phrase “(Happy Birthday)” inserted in the middle. Table 4 shows examples where all of our systems could not detect the vandalism correctly. Notice that examples in Table 4 generally manifest more a formal voice than those in Table 3. 5 Related Work Wang and McKeown (2010) present the first approach that is linguistically motivated. Their ap86 proach was based on shallow syntactic patterns, while ours explores the use of deep syntactic patterns, and performs a comparative evaluation across different stylometry analysis techniques. It is worthwhile to note that the approach of Wang and McKeown (2010) is not as practical and scalable as ours in that it requires crawling a substantial number (150) of webpages to detect each vandalism edit. From our pilot study based on 1600 edits (50% of which is vandalism), we found that the topic-specific language models built f</context>
</contexts>
<marker>Wang, McKeown, 2010</marker>
<rawString>William Yang Wang and Kathleen R. McKeown. 2010. “got you!”: Automatic vandalism detection in wikipedia with web-based shallow syntacticsemantic modeling. In 23rd International Conference on Computational Linguistics (Coling 2010), page 1146?1154.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew G West</author>
<author>Sampath Kannan</author>
<author>Insup Lee</author>
</authors>
<title>Detecting wikipedia vandalism via spatio-temporal analysis of revision metadata.</title>
<date>2010</date>
<booktitle>In EUROSEC ’10: Proceedings of the Third European Workshop on System Security,</booktitle>
<pages>22--28</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="2237" citStr="West et al. (2010)" startWordPosition="320" endWordPosition="323">2010) of edits are vandalism, i.e. revisions to articles that undermine the quality and veracity of the content. As Wikipedia continues to grow, it will become increasingly infeasible for Wikipedia users and administrators to manually police articles. This pressing issue has spawned recent research activities to understand and counteract vandalism (e.g., Geiger and Ribes (2010)). Much of previous work relies on hand-picked rules such as lexical cues (e.g., vulgar words) and metadata (e.g., anonymity, edit frequency) to automatically detect vandalism in Wikipedia (e.g., Potthast et al. (2008), West et al. (2010)). Although some recent work has started exploring the use of natural language processing, most work to date is based on shallow lexico-syntactic patterns (e.g., Wang and McKeown (2010), Chin et al. (2010), Adler et al. (2011)). We explore more linguistically motivated approaches to detect vandalism in this paper. Our hypothesis is that textual vandalism constitutes a unique genre where a group of people share similar linguistic behavior. Some obvious hallmarks of this style include usage of obscenities, misspellings, and slang usage, but we aim to automatically uncover stylistic cues to effec</context>
</contexts>
<marker>West, Kannan, Lee, 2010</marker>
<rawString>Andrew G. West, Sampath Kannan, and Insup Lee. 2010. Detecting wikipedia vandalism via spatio-temporal analysis of revision metadata. In EUROSEC ’10: Proceedings of the Third European Workshop on System Security, pages 22–28, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wikipedia</author>
</authors>
<title>Daily edit statistics.</title>
<date>2010</date>
<note>http://stats.wikimedia.org/EN/ PlotsPngDatabaseEdits.htm.</note>
<contexts>
<context position="1542" citStr="Wikipedia, 2010" startWordPosition="218" endWordPosition="219">language styles in vandalism, and that (2) deep syntactic patterns based on probabilistic context free grammars (PCFG) discriminate vandalism more effectively than shallow lexicosyntactic patterns based on n-grams. 1 Introduction Wikipedia, the “free encyclopedia” (Wikipedia, 2011), ranks among the top 200 most visited websites worldwide (Alexa, 2011). This editable encyclopedia has amassed over 15 million articles across hundreds of languages. The English language encyclopedia alone has over 3.5 million articles and receives over 1.25 million edits (and sometimes upwards of 3 million) daily (Wikipedia, 2010). But allowing anonymous edits is a double-edged sword; nearly 7% (Potthast, 2010) of edits are vandalism, i.e. revisions to articles that undermine the quality and veracity of the content. As Wikipedia continues to grow, it will become increasingly infeasible for Wikipedia users and administrators to manually police articles. This pressing issue has spawned recent research activities to understand and counteract vandalism (e.g., Geiger and Ribes (2010)). Much of previous work relies on hand-picked rules such as lexical cues (e.g., vulgar words) and metadata (e.g., anonymity, edit frequency) t</context>
</contexts>
<marker>Wikipedia, 2010</marker>
<rawString>Wikipedia. 2010. Daily edit statistics. http://stats.wikimedia.org/EN/ PlotsPngDatabaseEdits.htm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wikipedia</author>
</authors>
<date>2011</date>
<note>Wikipedia. http://www. wikipedia.org.</note>
<contexts>
<context position="1208" citStr="Wikipedia, 2011" startWordPosition="165" endWordPosition="166">dalism in Wikipedia. In this paper, we explore more linguistically motivated approaches to vandalism detection. In particular, we hypothesize that textual vandalism constitutes a unique genre where a group of people share a similar linguistic behavior. Experimental results suggest that (1) statistical models give evidence to unique language styles in vandalism, and that (2) deep syntactic patterns based on probabilistic context free grammars (PCFG) discriminate vandalism more effectively than shallow lexicosyntactic patterns based on n-grams. 1 Introduction Wikipedia, the “free encyclopedia” (Wikipedia, 2011), ranks among the top 200 most visited websites worldwide (Alexa, 2011). This editable encyclopedia has amassed over 15 million articles across hundreds of languages. The English language encyclopedia alone has over 3.5 million articles and receives over 1.25 million edits (and sometimes upwards of 3 million) daily (Wikipedia, 2010). But allowing anonymous edits is a double-edged sword; nearly 7% (Potthast, 2010) of edits are vandalism, i.e. revisions to articles that undermine the quality and veracity of the content. As Wikipedia continues to grow, it will become increasingly infeasible for W</context>
</contexts>
<marker>Wikipedia, 2011</marker>
<rawString>Wikipedia. 2011. Wikipedia. http://www. wikipedia.org.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>