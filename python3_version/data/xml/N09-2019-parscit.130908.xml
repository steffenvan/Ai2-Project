<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.056678">
<title confidence="0.953954333333333">
Minimum Bayes Risk Combination of Translation Hypotheses from
Alternative Morphological Decompositions
Adri`a de Gispert$ Sami Virpioja*
</title>
<author confidence="0.997027">
Mikko Kurimo* William Byrne$
</author>
<affiliation confidence="0.998422">
$ University of Cambridge. Dept. of Engineering. CB2 1PZ Cambridge, U.K.
</affiliation>
<email confidence="0.967782">
{ad465,wjb31}@eng.cam.ac.uk
</email>
<affiliation confidence="0.861871">
* Helsinki University of Technology. Adaptive Informatics Research Centre
</affiliation>
<address confidence="0.96165">
P.O.Box 5400, 02015 TKK, Finland
</address>
<email confidence="0.999412">
{sami.virpioja,mikko.kurimo}@tkk.fi
</email>
<sectionHeader confidence="0.998603" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999607583333333">
We describe a simple strategy to achieve trans-
lation performance improvements by combin-
ing output from identical statistical machine
translation systems trained on alternative mor-
phological decompositions of the source lan-
guage. Combination is done by means of Min-
imum Bayes Risk decoding over a shared N-
best list. When translating into English from
two highly inflected languages such as Ara-
bic and Finnish we obtain significant improve-
ments over simply selecting the best morpho-
logical decomposition.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998936888888889">
Morphologically rich languages pose significant
challenges for natural language processing. The ex-
tensive use of inflection, derivation, and composi-
tion leads to a huge vocabulary, and sparsity in mod-
els estimated from data. Statistical machine transla-
tion (SMT) systems estimated from parallel text are
affected by this. This is particularly acute when ei-
ther the source or the target language, or both, are
morphologically complex.
Owing to these difficulties and to the natural in-
terest researchers take in complex linguistic phe-
nomena, many approaches to morphological anal-
ysis have been developed and evaluated. We fo-
cus on applications to SMT in Section 1.1, but we
note the recent general survey (Roark and Sproat,
2007) and the Morpho Challenge competitive evalu-
ations1. Prior evaluations of morphological analyz-
ers have focused on determining which analyzer was
</bodyText>
<footnote confidence="0.992531">
1See http://www.cis.hut.fi/morphochallenge2009/ and links
</footnote>
<bodyText confidence="0.998431538461539">
best suited for some particular task. For translation,
we take a different approach and investigate whether
competing analyzers might have complementary in-
formation. Our method is straightforward. We train
two identical SMT systems with two versions of
the same parallel corpus, each with a different mor-
phological decomposition of the source language.
We combine their translation hypotheses perform-
ing Minimum Bayes Risk decoding over merged N-
best lists. Results are reported in the NIST 2008
Arabic-to-English MT task and an European Parlia-
ment Finnish-to-English task, with significant gains
over each individual system.
</bodyText>
<subsectionHeader confidence="0.976714">
1.1 Prior Work
</subsectionHeader>
<bodyText confidence="0.9998980625">
Several earlier works investigate word segmenta-
tion and transformation schemes, which may include
Part-Of-Speech or other information, to alleviate
the effect of morphological variation on translation
models. With different training corpus sizes, they
focus on translation into English from Arabic (Lee,
2004; Habash and Sadat, 2006; Zollmann et al.,
2006), Czech (Goldwater and McClosky, 2005; Tal-
bot and Osborne, 2006), German (Nießen and Ney,
2004) or Catalan, Spanish and Serbian (Popovic
and Ney, 2004). Some address the generation
challenge when translating from English into Span-
ish (Ueffing and Ney, 2003; de Gispert and Mari˜no,
2008). Unsupervised morphology learning is pro-
posed as a language-independent solution to reduce
the problems of rich morphology in (Virpioja et al.,
</bodyText>
<footnote confidence="0.98018">
there to earlier workshops. The combination scheme described
in this paper will be one of the evaluation tracks in the upcoming
workshop.
</footnote>
<page confidence="0.989776">
73
</page>
<subsubsectionHeader confidence="0.396975">
Proceedings of NAACL HLT 2009: Short Papers, pages 73–76,
</subsubsectionHeader>
<note confidence="0.417335">
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<table confidence="0.95298175">
Arabic wqrrt An tn$A ljnp tHDyryp jAmEp lljmEyp AlEAmp fY dwrthA AlvAnyp wAlxmsyn
MADA D2 w+ qrrt &gt;n tn$A ljnp tHDyryp jAmEp l+ AljmEyp AlEAmp fy dwrthA AlvAnyp w+ Alxmsyn
SAKHR w+ qrrt An tn$A ljnp tHDyryp jAmEp l*l+ jmEyp Al+ EAmp fY dwrt +hA Al+ vAnyp w*Al+ xmsyn
English a preparatory committee of the whole of the general assembly is to be established at its fifty-second session
</table>
<tableCaption confidence="0.999909">
Table 1: Example of alternative segmentation schemes for a given Arabic sentence, in Buckwalter transliteration.
</tableCaption>
<bodyText confidence="0.999584344827586">
2007). Factored models are introduced in (Koehn
and Hoang, 2007) for better integration of morpho-
syntactic information.
Gim´enez and M`arquez (2005) merge mul-
tiple word alignments obtained from several
linguistically-tagged versions of a Spanish-English
corpus, but only standard tokens are used in decod-
ing. Dyer et al. (2008) report improvements from
multiple Arabic segmentations in translation to En-
glish translation, but their goal was to demonstrate
the value of lattice-based translation. From a model-
ing perspective their approach is unwieldy: multiple
analyses of the parallel text collections are merged
to create a large, heterogeneous training set; a sin-
gle set of models and alignments is produced; lattice
translation is then performed using a single system
to translate all morphological analyses. We find that
similar gains can be obtained much more easily.
The approach we take is Minimum Bayes Risk
(MBR) System Combination (Sim et al., 2007). N-
best lists from multiple SMT systems are merged;
the posterior distributions over the individual lists
are interpolated to form a new distribution over the
merged list. MBR hypotheses selection is then per-
formed using sentence-level BLEU score (Kumar
and Byrne, 2004). It is very likely that even greater
gains can be achieved by more complicated combi-
nation schemes (Rosti et al., 2007), although signif-
icantly more effort in tuning would be required.
</bodyText>
<sectionHeader confidence="0.984157" genericHeader="method">
2 Arabic-to-English Translation
</sectionHeader>
<bodyText confidence="0.999863254901961">
For Arabic-to-English translation, we consider two
alternative segmentations of the Arabic words. We
first use the MADA toolkit (Habash and Rambow,
2005). After tagging, we split word prefixes and suf-
fixes according to scheme ‘D2’ (Habash and Sadat,
2006). Secondly, we take the segmentation gener-
ated by Sakhr Software in Egypt using their Arabic
Morphological Tagger, as an alternative segmenta-
tion into subword units. This scheme generates more
tokens as it segments all Arabic articles which other-
wise remain attached in the MADA D2 scheme (Ta-
ble 1).
Translation experiments are based on the NIST
MT08 Arabic-to-English translation task, includ-
ing all allowed parallel data as training material
(—150M English words, and 153M or 178M Arabic
words for MADA-segmented and Sakhr-segmented
text, respectively). In addition to the MT08 set itself,
we take the NIST MT02 through MT05 evaluation
sets and divide them into a development set (odd-
numbered sentences) and a test set (even-numbered
sentences), each containing —2k sentences.
The SMT system used is HiFST, a hierarchical
phrase-based system implemented with Weighted
Finite-State Transducers (Iglesias et al., 2009). Two
identical systems are trained from each parallel cor-
pus, i.e. MADA-based and SAKHR-based. Both
systems use the same standard features and share
the first-pass English language model, a 4-gram es-
timated over the parallel text and a 965 million word
subset of monolingual data from the English Giga-
word Third Edition. Minimum Error Training pa-
rameter estimation under IBM BLEU is performed
on the development set (mt02-05-tune), and the out-
put translation lattice is rescored with large language
models estimated using —4.7B words of English
newswire text, in the same fashion as (Iglesias et
al., 2009). Finally, the first 1000-best hypotheses
are rescored with MBR, taking the negative sentence
level BLEU score as the loss function to minimise.
For system combination, we obtain two sets of N-
best lists of depth N=500, one from each system.
Both lists are obtained after large-LM lattice rescor-
ing, i.e. prior to individual MBR. A joint MBR de-
coding is then carried out on the aggregated 1000-
best list with equal weight assigned to the posterior
distribution assigned to the hypotheses by each sys-
tem. Results are shown in Table 2.
As shown, the scores obtained via MBR combi-
nation outperform significantly those achieved via
MBR for the best-performing system (MADA). The
</bodyText>
<page confidence="0.986808">
74
</page>
<table confidence="0.999265857142857">
mt02-05- mt08
-tune -test
MADA-based 53.3 52.7 43.7
+MBR 53.7 53.3 44.0
SAKHR-based 52.7 52.8 43.3
+MBR 53.2 53.2 43.8
MBR-combined 54.6 54.6 45.6
</table>
<tableCaption confidence="0.9851375">
Table 2: Arabic-to-English translation results. Lower-
cased IBM BLEU reported.
</tableCaption>
<bodyText confidence="0.984037">
mixed case BLEU-4 for the MBR-combined system
on mt08 is 44.1. This is directly comparable to the
official MT08 Constrained Training Track evalua-
tion results.2
</bodyText>
<sectionHeader confidence="0.999082" genericHeader="method">
3 Finnish-to-English Translation
</sectionHeader>
<bodyText confidence="0.999960357142857">
Finnish is a highly-inflecting, agglutinative lan-
guage. It has dozens of both inflectional and
derivational suffixes, that are concatenated together
with only moderately small changes in the sur-
face forms. For instance, one can inflect the
word ”kauppa” (shop) into ”kaupa+ssa+mme+kin”
(also in our shop) by glueing the suffixes to the
end. In addition, Finnish has many compound
words, sometimes consisting of several parts, such
as ”ulko+maa+n+kauppa+politiikka” (foreign trade
policy). Due to these properties, the number of dif-
ferent word forms that can be observed is enormous.
Morfessor (Creutz and Lagus, 2007) is a method
for modeling concatenative morphology in an un-
supervised manner. It tries to find morpheme-like
units, morphs, that are segments of the words. In-
spired by the minimum description length principle,
Morfessor tries to find a concise lexicon of morphs
that can effectively code the words in the train-
ing data. Unlike other unsupervised methods (e.g.,
Goldsmith (2001)), there is no restrictions on how
many morphs a word can have. After training the
model, the most likely segmentation of new words
to morphs can be found using the Viterbi algorithm.
There exist a few different versions of Morfessor.
The baseline algorithm has been found to be very
useful in automatic speech recognition of agglutina-
tive languages (Kurimo et al., 2006). However, it
</bodyText>
<footnote confidence="0.972341">
2Full MT08 results are available at http://www.nist.gov/
speech/tests/mt/2008/doc/mt08 official results v0.html
</footnote>
<bodyText confidence="0.999747108108108">
often oversegments morphemes that are rare or not
seen at all in the training data. Following the ap-
proach in (Virpioja et al., 2007), we use the Morfes-
sor Categories-MAP algorithm (Creutz and Lagus,
2005). It applies a hierarchical model with three sur-
face categories (prefix, stem and suffix), that allow
the algorithm to treat out-of-vocabulary words in a
convenient manner. For instance, if we encounter a
new name with a known suffix, it can usually sepa-
rate the suffix and leave the actual name intact.
Similarly to the Arabic-to-English task, we train
two identical HiFST systems. In this case, whereas
one is trained on Finnish morphs decomposed by
Morfessor (morph-based), the other is trained on
standard, unprocessed Finnish (word-based). For
this task we use the EuParl parallel corpus . Portions
from Q4/2000 was reserved for testing and Septem-
ber 2000 for development, both containing around
3,000 sentences. The training data comprised 23M
English words, and 17M or 27M Finnish tokens for
word-based or morph-based text, respectively.
The training set was also used to train the mor-
phological segmentation. The quality of the seg-
mentation is evaluated in (Virpioja et al., 2007). A
precision of 78.72% and recall of 52.29% was mea-
sured for the segmentation boundaries with respect
to a linguistic reference segmentation. As the recall
is not very high, the segmentation is more conserva-
tive than the linguistic reference. Table 4 shows an
example for a phrase in the training data.
Results are shown in Table 3, where again signifi-
cant gains are achieved when simply combining out-
put N-best lists via MBR. Only one reference was
available for scoring. In this case we did not ap-
ply large-LM rescoring, as no large additional par-
liamentary data was available. Individual MBR did
not yield gains for each of the systems.
</bodyText>
<table confidence="0.96991175">
devel test
Word-based 30.2 27.9
Morph-based 29.4 27.4
MBR-combined 30.5 28.9
</table>
<tableCaption confidence="0.9846755">
Table 3: Finnish-to-English translation results. Lower-
cased IBM BLEU reported.
</tableCaption>
<page confidence="0.945655">
75
</page>
<table confidence="0.9992115">
Finnish vaarallisten aineiden kuljetusten turvallisuusneuvonantaja
Morfessor vaaraSTM llistenSTM aineSTM idenSUF kuljetusPRE tenSTM turvallisuusPRE neuvoSTM nSUF antajaSTM
Linguistic vaara llis t en aine i den kuljet us t en turva llis uus neuvo n anta ja
English safety adviser for the transport of dangerous goods
</table>
<tableCaption confidence="0.9815745">
Table 4: Example of Morfessor Categories-MAP segmentation and linguistic segmentation for a Finnish phrase. Sub-
scripts show the morph categories given by Morfessor: stem (STM), prefix (PRE) and suffix (SUF).
</tableCaption>
<sectionHeader confidence="0.995631" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.969855764705882">
We demonstrated that multiple morphological anal-
yses can be the basis for SMT system combination.
These results will be of interest to researchers devel-
oping morphological analyzers, as it provides a new,
and potentially profitable way to evaluate compet-
ing analysers. The results should also interest SMT
researchers. SMT system combination is an active
area of research, but good gains from combination
usually require very different system architectures;
this can be a barrier to developing competitive sys-
tems. We find that the same architecture trained on
two different analyses is adequate to generate the di-
verse hypotheses needed for system combination.
Acknowledgments. This work was supported by the GALE
program of DARPA (HR0011-06-C-0022), the GSLT and AIRC
in the Academy of Finland, and the EMIME project and PAS-
CAL2 NoE in the EC’s FP7.
</bodyText>
<sectionHeader confidence="0.999032" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999373044117647">
M. Creutz and K. Lagus. 2005. Inducing the morpho-
logical lexicon of a natural language from unannotated
text. In Conf. on Adaptive Knowledge Representation
and Reasoning (AKRR).
M. Creutz and K. Lagus. 2007. Unsupervised models
for morpheme segmentation and morphology learning.
ACM Trans. Speech and Language Processing, 4(1).
A. de Gispert and J.B. Mari˜no. 2008. On the impact
of morphology in English to Spanish statistical MT.
Speech Communication, 50.
C. Dyer, S. Muresan, and P. Resnik. 2008. Generalizing
word lattice translation. In ACL-HLT.
J. Gim´enez and Ll. M`arquez. 2005. Combining linguis-
tic data views for phrase-based SMT. In ACL Work-
shop on Building and Using Parallel Texts.
J. Goldsmith. 2001. Unsupervised learning of the mor-
phology of a natural language. Computational Lin-
guistics, 27(2).
S. Goldwater and D. McClosky. 2005. Improving sta-
tistical MT through morphological analysis. In HLT-
EMNLP.
N. Habash and O. Rambow. 2005. Arabic tokeniza-
tion, part-of-speech tagging and morphological disam-
biguation in one fell swoop. In ACL.
N. Habash and F. Sadat. 2006. Arabic preprocessing
schemes for statistical machine translation. In HLT-
NAACL: Short Papers.
G. Iglesias, A. de Gispert, E.R. Banga, and W. Byrne.
2009. Hierarchical phrase-based translation with
weighted finite state transducers. In HLT-NAACL.
P. Koehn and H. Hoang. 2007. Factored translation mod-
els. In EMNLP.
S. Kumar and W. Byrne. 2004. Minimum Bayes-risk
decoding for statistical machine translation. In HLT-
NAACL.
M. Kurimo, A. Puurula, E. Arisoy, V. Siivola, T. Hir-
sim¨aki, J. Pylkk¨onen, T. Alum¨ae, and M. Saraclar.
2006. Unlimited vocabulary speech recognition for
agglutinative languages. In HLT-NAACL.
Y.-S. Lee. 2004. Morphological analysis for statistical
machine translation. In HLT-NAACL: Short Papers.
S. Nießen and H. Ney. 2004. Statistical machine transla-
tion with scarce resources using morpho-syntactic in-
formation. Computational Linguistics, 30(2).
M. Popovic and H. Ney. 2004. Towards the use of word
stems and suffixes for statistical machine translation.
In LREC.
B. Roark and R. Sproat. 2007. Computational Ap-
proaches to Morphology and Syntax. Oxford Univer-
sity Press.
A.V. Rosti, S. Matsoukas, and R. Schwartz. 2007. Im-
proved word-level system combination for machine
translation. In ACL.
K.C. Sim, W. Byrne, M. Gales, H. Sahbi, and P. C. Wood-
land. 2007. Consensus network decoding for sta-
tistical machine translation system combination. In
ICASSP, volume 4.
D. Talbot and M. Osborne. 2006. Modelling lexical re-
dundancy for machine translation. In ACL.
N. Ueffing and H. Ney. 2003. Using POS information for
SMT into morphologically rich languages. In EACL.
S. Virpioja, J.J. V¨ayrynen, M. Creutz, and M. Sadeniemi.
2007. Morphology-aware statistical machine transla-
tion based on morphs induced in an unsupervised man-
ner. In MT Summit XI.
A. Zollmann, A. Venugopal, and S. Vogel. 2006. Bridg-
ing the inflection morphology gap for Arabic statistical
machine translation. In HLT-NAACL: Short Papers.
</reference>
<page confidence="0.99176">
76
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.244027">
<title confidence="0.820714333333333">Minimum Bayes Risk Combination of Translation Hypotheses Alternative Morphological Decompositions de</title>
<author confidence="0.951849">William</author>
<affiliation confidence="0.873054">of Cambridge. Dept. of Engineering. CB2 1PZ Cambridge, University of Technology. Adaptive Informatics Research</affiliation>
<address confidence="0.692995">P.O.Box 5400, 02015 TKK,</address>
<abstract confidence="0.989194076923077">We describe a simple strategy to achieve translation performance improvements by combining output from identical statistical machine translation systems trained on alternative morphological decompositions of the source language. Combination is done by means of Minimum Bayes Risk decoding over a shared Nbest list. When translating into English from two highly inflected languages such as Arabic and Finnish we obtain significant improvements over simply selecting the best morphological decomposition.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Creutz</author>
<author>K Lagus</author>
</authors>
<title>Inducing the morphological lexicon of a natural language from unannotated text.</title>
<date>2005</date>
<booktitle>In Conf. on Adaptive Knowledge Representation and Reasoning (AKRR).</booktitle>
<contexts>
<context position="10090" citStr="Creutz and Lagus, 2005" startWordPosition="1530" endWordPosition="1533">the model, the most likely segmentation of new words to morphs can be found using the Viterbi algorithm. There exist a few different versions of Morfessor. The baseline algorithm has been found to be very useful in automatic speech recognition of agglutinative languages (Kurimo et al., 2006). However, it 2Full MT08 results are available at http://www.nist.gov/ speech/tests/mt/2008/doc/mt08 official results v0.html often oversegments morphemes that are rare or not seen at all in the training data. Following the approach in (Virpioja et al., 2007), we use the Morfessor Categories-MAP algorithm (Creutz and Lagus, 2005). It applies a hierarchical model with three surface categories (prefix, stem and suffix), that allow the algorithm to treat out-of-vocabulary words in a convenient manner. For instance, if we encounter a new name with a known suffix, it can usually separate the suffix and leave the actual name intact. Similarly to the Arabic-to-English task, we train two identical HiFST systems. In this case, whereas one is trained on Finnish morphs decomposed by Morfessor (morph-based), the other is trained on standard, unprocessed Finnish (word-based). For this task we use the EuParl parallel corpus . Porti</context>
</contexts>
<marker>Creutz, Lagus, 2005</marker>
<rawString>M. Creutz and K. Lagus. 2005. Inducing the morphological lexicon of a natural language from unannotated text. In Conf. on Adaptive Knowledge Representation and Reasoning (AKRR).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Creutz</author>
<author>K Lagus</author>
</authors>
<title>Unsupervised models for morpheme segmentation and morphology learning.</title>
<date>2007</date>
<journal>ACM Trans. Speech and Language Processing,</journal>
<volume>4</volume>
<issue>1</issue>
<contexts>
<context position="9011" citStr="Creutz and Lagus, 2007" startWordPosition="1360" endWordPosition="1363">ation Finnish is a highly-inflecting, agglutinative language. It has dozens of both inflectional and derivational suffixes, that are concatenated together with only moderately small changes in the surface forms. For instance, one can inflect the word ”kauppa” (shop) into ”kaupa+ssa+mme+kin” (also in our shop) by glueing the suffixes to the end. In addition, Finnish has many compound words, sometimes consisting of several parts, such as ”ulko+maa+n+kauppa+politiikka” (foreign trade policy). Due to these properties, the number of different word forms that can be observed is enormous. Morfessor (Creutz and Lagus, 2007) is a method for modeling concatenative morphology in an unsupervised manner. It tries to find morpheme-like units, morphs, that are segments of the words. Inspired by the minimum description length principle, Morfessor tries to find a concise lexicon of morphs that can effectively code the words in the training data. Unlike other unsupervised methods (e.g., Goldsmith (2001)), there is no restrictions on how many morphs a word can have. After training the model, the most likely segmentation of new words to morphs can be found using the Viterbi algorithm. There exist a few different versions of</context>
</contexts>
<marker>Creutz, Lagus, 2007</marker>
<rawString>M. Creutz and K. Lagus. 2007. Unsupervised models for morpheme segmentation and morphology learning. ACM Trans. Speech and Language Processing, 4(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A de Gispert</author>
<author>J B Mari˜no</author>
</authors>
<title>On the impact of morphology in English to Spanish statistical MT.</title>
<date>2008</date>
<journal>Speech Communication,</journal>
<volume>50</volume>
<marker>de Gispert, Mari˜no, 2008</marker>
<rawString>A. de Gispert and J.B. Mari˜no. 2008. On the impact of morphology in English to Spanish statistical MT. Speech Communication, 50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Dyer</author>
<author>S Muresan</author>
<author>P Resnik</author>
</authors>
<title>Generalizing word lattice translation.</title>
<date>2008</date>
<booktitle>In ACL-HLT.</booktitle>
<contexts>
<context position="4397" citStr="Dyer et al. (2008)" startWordPosition="644" endWordPosition="647">jAmEp l*l+ jmEyp Al+ EAmp fY dwrt +hA Al+ vAnyp w*Al+ xmsyn English a preparatory committee of the whole of the general assembly is to be established at its fifty-second session Table 1: Example of alternative segmentation schemes for a given Arabic sentence, in Buckwalter transliteration. 2007). Factored models are introduced in (Koehn and Hoang, 2007) for better integration of morphosyntactic information. Gim´enez and M`arquez (2005) merge multiple word alignments obtained from several linguistically-tagged versions of a Spanish-English corpus, but only standard tokens are used in decoding. Dyer et al. (2008) report improvements from multiple Arabic segmentations in translation to English translation, but their goal was to demonstrate the value of lattice-based translation. From a modeling perspective their approach is unwieldy: multiple analyses of the parallel text collections are merged to create a large, heterogeneous training set; a single set of models and alignments is produced; lattice translation is then performed using a single system to translate all morphological analyses. We find that similar gains can be obtained much more easily. The approach we take is Minimum Bayes Risk (MBR) Syst</context>
</contexts>
<marker>Dyer, Muresan, Resnik, 2008</marker>
<rawString>C. Dyer, S. Muresan, and P. Resnik. 2008. Generalizing word lattice translation. In ACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M`arquez</author>
</authors>
<title>Combining linguistic data views for phrase-based SMT.</title>
<date>2005</date>
<booktitle>In ACL Workshop on Building and Using Parallel Texts.</booktitle>
<marker>M`arquez, 2005</marker>
<rawString>J. Gim´enez and Ll. M`arquez. 2005. Combining linguistic data views for phrase-based SMT. In ACL Workshop on Building and Using Parallel Texts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Goldsmith</author>
</authors>
<title>Unsupervised learning of the morphology of a natural language.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>2</issue>
<contexts>
<context position="9388" citStr="Goldsmith (2001)" startWordPosition="1422" endWordPosition="1423">d words, sometimes consisting of several parts, such as ”ulko+maa+n+kauppa+politiikka” (foreign trade policy). Due to these properties, the number of different word forms that can be observed is enormous. Morfessor (Creutz and Lagus, 2007) is a method for modeling concatenative morphology in an unsupervised manner. It tries to find morpheme-like units, morphs, that are segments of the words. Inspired by the minimum description length principle, Morfessor tries to find a concise lexicon of morphs that can effectively code the words in the training data. Unlike other unsupervised methods (e.g., Goldsmith (2001)), there is no restrictions on how many morphs a word can have. After training the model, the most likely segmentation of new words to morphs can be found using the Viterbi algorithm. There exist a few different versions of Morfessor. The baseline algorithm has been found to be very useful in automatic speech recognition of agglutinative languages (Kurimo et al., 2006). However, it 2Full MT08 results are available at http://www.nist.gov/ speech/tests/mt/2008/doc/mt08 official results v0.html often oversegments morphemes that are rare or not seen at all in the training data. Following the appro</context>
</contexts>
<marker>Goldsmith, 2001</marker>
<rawString>J. Goldsmith. 2001. Unsupervised learning of the morphology of a natural language. Computational Linguistics, 27(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Goldwater</author>
<author>D McClosky</author>
</authors>
<title>Improving statistical MT through morphological analysis.</title>
<date>2005</date>
<booktitle>In HLTEMNLP.</booktitle>
<contexts>
<context position="2899" citStr="Goldwater and McClosky, 2005" startWordPosition="411" endWordPosition="414">inimum Bayes Risk decoding over merged Nbest lists. Results are reported in the NIST 2008 Arabic-to-English MT task and an European Parliament Finnish-to-English task, with significant gains over each individual system. 1.1 Prior Work Several earlier works investigate word segmentation and transformation schemes, which may include Part-Of-Speech or other information, to alleviate the effect of morphological variation on translation models. With different training corpus sizes, they focus on translation into English from Arabic (Lee, 2004; Habash and Sadat, 2006; Zollmann et al., 2006), Czech (Goldwater and McClosky, 2005; Talbot and Osborne, 2006), German (Nießen and Ney, 2004) or Catalan, Spanish and Serbian (Popovic and Ney, 2004). Some address the generation challenge when translating from English into Spanish (Ueffing and Ney, 2003; de Gispert and Mari˜no, 2008). Unsupervised morphology learning is proposed as a language-independent solution to reduce the problems of rich morphology in (Virpioja et al., there to earlier workshops. The combination scheme described in this paper will be one of the evaluation tracks in the upcoming workshop. 73 Proceedings of NAACL HLT 2009: Short Papers, pages 73–76, Boulde</context>
</contexts>
<marker>Goldwater, McClosky, 2005</marker>
<rawString>S. Goldwater and D. McClosky. 2005. Improving statistical MT through morphological analysis. In HLTEMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Habash</author>
<author>O Rambow</author>
</authors>
<title>Arabic tokenization, part-of-speech tagging and morphological disambiguation in one fell swoop.</title>
<date>2005</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="5671" citStr="Habash and Rambow, 2005" startWordPosition="840" endWordPosition="843">m multiple SMT systems are merged; the posterior distributions over the individual lists are interpolated to form a new distribution over the merged list. MBR hypotheses selection is then performed using sentence-level BLEU score (Kumar and Byrne, 2004). It is very likely that even greater gains can be achieved by more complicated combination schemes (Rosti et al., 2007), although significantly more effort in tuning would be required. 2 Arabic-to-English Translation For Arabic-to-English translation, we consider two alternative segmentations of the Arabic words. We first use the MADA toolkit (Habash and Rambow, 2005). After tagging, we split word prefixes and suffixes according to scheme ‘D2’ (Habash and Sadat, 2006). Secondly, we take the segmentation generated by Sakhr Software in Egypt using their Arabic Morphological Tagger, as an alternative segmentation into subword units. This scheme generates more tokens as it segments all Arabic articles which otherwise remain attached in the MADA D2 scheme (Table 1). Translation experiments are based on the NIST MT08 Arabic-to-English translation task, including all allowed parallel data as training material (—150M English words, and 153M or 178M Arabic words fo</context>
</contexts>
<marker>Habash, Rambow, 2005</marker>
<rawString>N. Habash and O. Rambow. 2005. Arabic tokenization, part-of-speech tagging and morphological disambiguation in one fell swoop. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Habash</author>
<author>F Sadat</author>
</authors>
<title>Arabic preprocessing schemes for statistical machine translation. In HLTNAACL: Short Papers.</title>
<date>2006</date>
<contexts>
<context position="2838" citStr="Habash and Sadat, 2006" startWordPosition="402" endWordPosition="405">e. We combine their translation hypotheses performing Minimum Bayes Risk decoding over merged Nbest lists. Results are reported in the NIST 2008 Arabic-to-English MT task and an European Parliament Finnish-to-English task, with significant gains over each individual system. 1.1 Prior Work Several earlier works investigate word segmentation and transformation schemes, which may include Part-Of-Speech or other information, to alleviate the effect of morphological variation on translation models. With different training corpus sizes, they focus on translation into English from Arabic (Lee, 2004; Habash and Sadat, 2006; Zollmann et al., 2006), Czech (Goldwater and McClosky, 2005; Talbot and Osborne, 2006), German (Nießen and Ney, 2004) or Catalan, Spanish and Serbian (Popovic and Ney, 2004). Some address the generation challenge when translating from English into Spanish (Ueffing and Ney, 2003; de Gispert and Mari˜no, 2008). Unsupervised morphology learning is proposed as a language-independent solution to reduce the problems of rich morphology in (Virpioja et al., there to earlier workshops. The combination scheme described in this paper will be one of the evaluation tracks in the upcoming workshop. 73 Pro</context>
<context position="5773" citStr="Habash and Sadat, 2006" startWordPosition="857" endWordPosition="860">ed to form a new distribution over the merged list. MBR hypotheses selection is then performed using sentence-level BLEU score (Kumar and Byrne, 2004). It is very likely that even greater gains can be achieved by more complicated combination schemes (Rosti et al., 2007), although significantly more effort in tuning would be required. 2 Arabic-to-English Translation For Arabic-to-English translation, we consider two alternative segmentations of the Arabic words. We first use the MADA toolkit (Habash and Rambow, 2005). After tagging, we split word prefixes and suffixes according to scheme ‘D2’ (Habash and Sadat, 2006). Secondly, we take the segmentation generated by Sakhr Software in Egypt using their Arabic Morphological Tagger, as an alternative segmentation into subword units. This scheme generates more tokens as it segments all Arabic articles which otherwise remain attached in the MADA D2 scheme (Table 1). Translation experiments are based on the NIST MT08 Arabic-to-English translation task, including all allowed parallel data as training material (—150M English words, and 153M or 178M Arabic words for MADA-segmented and Sakhr-segmented text, respectively). In addition to the MT08 set itself, we take </context>
</contexts>
<marker>Habash, Sadat, 2006</marker>
<rawString>N. Habash and F. Sadat. 2006. Arabic preprocessing schemes for statistical machine translation. In HLTNAACL: Short Papers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Iglesias</author>
<author>A de Gispert</author>
<author>E R Banga</author>
<author>W Byrne</author>
</authors>
<title>Hierarchical phrase-based translation with weighted finite state transducers.</title>
<date>2009</date>
<booktitle>In HLT-NAACL.</booktitle>
<marker>Iglesias, de Gispert, Banga, Byrne, 2009</marker>
<rawString>G. Iglesias, A. de Gispert, E.R. Banga, and W. Byrne. 2009. Hierarchical phrase-based translation with weighted finite state transducers. In HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>H Hoang</author>
</authors>
<title>Factored translation models.</title>
<date>2007</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="4134" citStr="Koehn and Hoang, 2007" startWordPosition="606" endWordPosition="609">June 2009. c�2009 Association for Computational Linguistics Arabic wqrrt An tn$A ljnp tHDyryp jAmEp lljmEyp AlEAmp fY dwrthA AlvAnyp wAlxmsyn MADA D2 w+ qrrt &gt;n tn$A ljnp tHDyryp jAmEp l+ AljmEyp AlEAmp fy dwrthA AlvAnyp w+ Alxmsyn SAKHR w+ qrrt An tn$A ljnp tHDyryp jAmEp l*l+ jmEyp Al+ EAmp fY dwrt +hA Al+ vAnyp w*Al+ xmsyn English a preparatory committee of the whole of the general assembly is to be established at its fifty-second session Table 1: Example of alternative segmentation schemes for a given Arabic sentence, in Buckwalter transliteration. 2007). Factored models are introduced in (Koehn and Hoang, 2007) for better integration of morphosyntactic information. Gim´enez and M`arquez (2005) merge multiple word alignments obtained from several linguistically-tagged versions of a Spanish-English corpus, but only standard tokens are used in decoding. Dyer et al. (2008) report improvements from multiple Arabic segmentations in translation to English translation, but their goal was to demonstrate the value of lattice-based translation. From a modeling perspective their approach is unwieldy: multiple analyses of the parallel text collections are merged to create a large, heterogeneous training set; a s</context>
</contexts>
<marker>Koehn, Hoang, 2007</marker>
<rawString>P. Koehn and H. Hoang. 2007. Factored translation models. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kumar</author>
<author>W Byrne</author>
</authors>
<title>Minimum Bayes-risk decoding for statistical machine translation.</title>
<date>2004</date>
<booktitle>In HLTNAACL.</booktitle>
<contexts>
<context position="5300" citStr="Kumar and Byrne, 2004" startWordPosition="784" endWordPosition="787">erged to create a large, heterogeneous training set; a single set of models and alignments is produced; lattice translation is then performed using a single system to translate all morphological analyses. We find that similar gains can be obtained much more easily. The approach we take is Minimum Bayes Risk (MBR) System Combination (Sim et al., 2007). Nbest lists from multiple SMT systems are merged; the posterior distributions over the individual lists are interpolated to form a new distribution over the merged list. MBR hypotheses selection is then performed using sentence-level BLEU score (Kumar and Byrne, 2004). It is very likely that even greater gains can be achieved by more complicated combination schemes (Rosti et al., 2007), although significantly more effort in tuning would be required. 2 Arabic-to-English Translation For Arabic-to-English translation, we consider two alternative segmentations of the Arabic words. We first use the MADA toolkit (Habash and Rambow, 2005). After tagging, we split word prefixes and suffixes according to scheme ‘D2’ (Habash and Sadat, 2006). Secondly, we take the segmentation generated by Sakhr Software in Egypt using their Arabic Morphological Tagger, as an altern</context>
</contexts>
<marker>Kumar, Byrne, 2004</marker>
<rawString>S. Kumar and W. Byrne. 2004. Minimum Bayes-risk decoding for statistical machine translation. In HLTNAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kurimo</author>
<author>A Puurula</author>
<author>E Arisoy</author>
<author>V Siivola</author>
<author>T Hirsim¨aki</author>
<author>J Pylkk¨onen</author>
<author>T Alum¨ae</author>
<author>M Saraclar</author>
</authors>
<title>Unlimited vocabulary speech recognition for agglutinative languages. In HLT-NAACL.</title>
<date>2006</date>
<marker>Kurimo, Puurula, Arisoy, Siivola, Hirsim¨aki, Pylkk¨onen, Alum¨ae, Saraclar, 2006</marker>
<rawString>M. Kurimo, A. Puurula, E. Arisoy, V. Siivola, T. Hirsim¨aki, J. Pylkk¨onen, T. Alum¨ae, and M. Saraclar. 2006. Unlimited vocabulary speech recognition for agglutinative languages. In HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y-S Lee</author>
</authors>
<title>Morphological analysis for statistical machine translation. In HLT-NAACL: Short Papers.</title>
<date>2004</date>
<contexts>
<context position="2814" citStr="Lee, 2004" startWordPosition="400" endWordPosition="401">rce language. We combine their translation hypotheses performing Minimum Bayes Risk decoding over merged Nbest lists. Results are reported in the NIST 2008 Arabic-to-English MT task and an European Parliament Finnish-to-English task, with significant gains over each individual system. 1.1 Prior Work Several earlier works investigate word segmentation and transformation schemes, which may include Part-Of-Speech or other information, to alleviate the effect of morphological variation on translation models. With different training corpus sizes, they focus on translation into English from Arabic (Lee, 2004; Habash and Sadat, 2006; Zollmann et al., 2006), Czech (Goldwater and McClosky, 2005; Talbot and Osborne, 2006), German (Nießen and Ney, 2004) or Catalan, Spanish and Serbian (Popovic and Ney, 2004). Some address the generation challenge when translating from English into Spanish (Ueffing and Ney, 2003; de Gispert and Mari˜no, 2008). Unsupervised morphology learning is proposed as a language-independent solution to reduce the problems of rich morphology in (Virpioja et al., there to earlier workshops. The combination scheme described in this paper will be one of the evaluation tracks in the u</context>
</contexts>
<marker>Lee, 2004</marker>
<rawString>Y.-S. Lee. 2004. Morphological analysis for statistical machine translation. In HLT-NAACL: Short Papers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Nießen</author>
<author>H Ney</author>
</authors>
<title>Statistical machine translation with scarce resources using morpho-syntactic information.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>2</issue>
<contexts>
<context position="2957" citStr="Nießen and Ney, 2004" startWordPosition="421" endWordPosition="424">eported in the NIST 2008 Arabic-to-English MT task and an European Parliament Finnish-to-English task, with significant gains over each individual system. 1.1 Prior Work Several earlier works investigate word segmentation and transformation schemes, which may include Part-Of-Speech or other information, to alleviate the effect of morphological variation on translation models. With different training corpus sizes, they focus on translation into English from Arabic (Lee, 2004; Habash and Sadat, 2006; Zollmann et al., 2006), Czech (Goldwater and McClosky, 2005; Talbot and Osborne, 2006), German (Nießen and Ney, 2004) or Catalan, Spanish and Serbian (Popovic and Ney, 2004). Some address the generation challenge when translating from English into Spanish (Ueffing and Ney, 2003; de Gispert and Mari˜no, 2008). Unsupervised morphology learning is proposed as a language-independent solution to reduce the problems of rich morphology in (Virpioja et al., there to earlier workshops. The combination scheme described in this paper will be one of the evaluation tracks in the upcoming workshop. 73 Proceedings of NAACL HLT 2009: Short Papers, pages 73–76, Boulder, Colorado, June 2009. c�2009 Association for Computation</context>
</contexts>
<marker>Nießen, Ney, 2004</marker>
<rawString>S. Nießen and H. Ney. 2004. Statistical machine translation with scarce resources using morpho-syntactic information. Computational Linguistics, 30(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Popovic</author>
<author>H Ney</author>
</authors>
<title>Towards the use of word stems and suffixes for statistical machine translation.</title>
<date>2004</date>
<booktitle>In LREC.</booktitle>
<contexts>
<context position="3013" citStr="Popovic and Ney, 2004" startWordPosition="430" endWordPosition="433">an European Parliament Finnish-to-English task, with significant gains over each individual system. 1.1 Prior Work Several earlier works investigate word segmentation and transformation schemes, which may include Part-Of-Speech or other information, to alleviate the effect of morphological variation on translation models. With different training corpus sizes, they focus on translation into English from Arabic (Lee, 2004; Habash and Sadat, 2006; Zollmann et al., 2006), Czech (Goldwater and McClosky, 2005; Talbot and Osborne, 2006), German (Nießen and Ney, 2004) or Catalan, Spanish and Serbian (Popovic and Ney, 2004). Some address the generation challenge when translating from English into Spanish (Ueffing and Ney, 2003; de Gispert and Mari˜no, 2008). Unsupervised morphology learning is proposed as a language-independent solution to reduce the problems of rich morphology in (Virpioja et al., there to earlier workshops. The combination scheme described in this paper will be one of the evaluation tracks in the upcoming workshop. 73 Proceedings of NAACL HLT 2009: Short Papers, pages 73–76, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics Arabic wqrrt An tn$A ljnp tHDyryp jAmEp l</context>
</contexts>
<marker>Popovic, Ney, 2004</marker>
<rawString>M. Popovic and H. Ney. 2004. Towards the use of word stems and suffixes for statistical machine translation. In LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Roark</author>
<author>R Sproat</author>
</authors>
<title>Computational Approaches to Morphology and Syntax.</title>
<date>2007</date>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="1664" citStr="Roark and Sproat, 2007" startWordPosition="237" endWordPosition="240">e use of inflection, derivation, and composition leads to a huge vocabulary, and sparsity in models estimated from data. Statistical machine translation (SMT) systems estimated from parallel text are affected by this. This is particularly acute when either the source or the target language, or both, are morphologically complex. Owing to these difficulties and to the natural interest researchers take in complex linguistic phenomena, many approaches to morphological analysis have been developed and evaluated. We focus on applications to SMT in Section 1.1, but we note the recent general survey (Roark and Sproat, 2007) and the Morpho Challenge competitive evaluations1. Prior evaluations of morphological analyzers have focused on determining which analyzer was 1See http://www.cis.hut.fi/morphochallenge2009/ and links best suited for some particular task. For translation, we take a different approach and investigate whether competing analyzers might have complementary information. Our method is straightforward. We train two identical SMT systems with two versions of the same parallel corpus, each with a different morphological decomposition of the source language. We combine their translation hypotheses perfo</context>
</contexts>
<marker>Roark, Sproat, 2007</marker>
<rawString>B. Roark and R. Sproat. 2007. Computational Approaches to Morphology and Syntax. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A V Rosti</author>
<author>S Matsoukas</author>
<author>R Schwartz</author>
</authors>
<title>Improved word-level system combination for machine translation.</title>
<date>2007</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="5420" citStr="Rosti et al., 2007" startWordPosition="805" endWordPosition="808"> is then performed using a single system to translate all morphological analyses. We find that similar gains can be obtained much more easily. The approach we take is Minimum Bayes Risk (MBR) System Combination (Sim et al., 2007). Nbest lists from multiple SMT systems are merged; the posterior distributions over the individual lists are interpolated to form a new distribution over the merged list. MBR hypotheses selection is then performed using sentence-level BLEU score (Kumar and Byrne, 2004). It is very likely that even greater gains can be achieved by more complicated combination schemes (Rosti et al., 2007), although significantly more effort in tuning would be required. 2 Arabic-to-English Translation For Arabic-to-English translation, we consider two alternative segmentations of the Arabic words. We first use the MADA toolkit (Habash and Rambow, 2005). After tagging, we split word prefixes and suffixes according to scheme ‘D2’ (Habash and Sadat, 2006). Secondly, we take the segmentation generated by Sakhr Software in Egypt using their Arabic Morphological Tagger, as an alternative segmentation into subword units. This scheme generates more tokens as it segments all Arabic articles which otherw</context>
</contexts>
<marker>Rosti, Matsoukas, Schwartz, 2007</marker>
<rawString>A.V. Rosti, S. Matsoukas, and R. Schwartz. 2007. Improved word-level system combination for machine translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K C Sim</author>
<author>W Byrne</author>
<author>M Gales</author>
<author>H Sahbi</author>
<author>P C Woodland</author>
</authors>
<title>Consensus network decoding for statistical machine translation system combination.</title>
<date>2007</date>
<booktitle>In ICASSP,</booktitle>
<volume>4</volume>
<contexts>
<context position="5030" citStr="Sim et al., 2007" startWordPosition="742" endWordPosition="745">ents from multiple Arabic segmentations in translation to English translation, but their goal was to demonstrate the value of lattice-based translation. From a modeling perspective their approach is unwieldy: multiple analyses of the parallel text collections are merged to create a large, heterogeneous training set; a single set of models and alignments is produced; lattice translation is then performed using a single system to translate all morphological analyses. We find that similar gains can be obtained much more easily. The approach we take is Minimum Bayes Risk (MBR) System Combination (Sim et al., 2007). Nbest lists from multiple SMT systems are merged; the posterior distributions over the individual lists are interpolated to form a new distribution over the merged list. MBR hypotheses selection is then performed using sentence-level BLEU score (Kumar and Byrne, 2004). It is very likely that even greater gains can be achieved by more complicated combination schemes (Rosti et al., 2007), although significantly more effort in tuning would be required. 2 Arabic-to-English Translation For Arabic-to-English translation, we consider two alternative segmentations of the Arabic words. We first use t</context>
</contexts>
<marker>Sim, Byrne, Gales, Sahbi, Woodland, 2007</marker>
<rawString>K.C. Sim, W. Byrne, M. Gales, H. Sahbi, and P. C. Woodland. 2007. Consensus network decoding for statistical machine translation system combination. In ICASSP, volume 4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Talbot</author>
<author>M Osborne</author>
</authors>
<title>Modelling lexical redundancy for machine translation.</title>
<date>2006</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="2926" citStr="Talbot and Osborne, 2006" startWordPosition="415" endWordPosition="419">r merged Nbest lists. Results are reported in the NIST 2008 Arabic-to-English MT task and an European Parliament Finnish-to-English task, with significant gains over each individual system. 1.1 Prior Work Several earlier works investigate word segmentation and transformation schemes, which may include Part-Of-Speech or other information, to alleviate the effect of morphological variation on translation models. With different training corpus sizes, they focus on translation into English from Arabic (Lee, 2004; Habash and Sadat, 2006; Zollmann et al., 2006), Czech (Goldwater and McClosky, 2005; Talbot and Osborne, 2006), German (Nießen and Ney, 2004) or Catalan, Spanish and Serbian (Popovic and Ney, 2004). Some address the generation challenge when translating from English into Spanish (Ueffing and Ney, 2003; de Gispert and Mari˜no, 2008). Unsupervised morphology learning is proposed as a language-independent solution to reduce the problems of rich morphology in (Virpioja et al., there to earlier workshops. The combination scheme described in this paper will be one of the evaluation tracks in the upcoming workshop. 73 Proceedings of NAACL HLT 2009: Short Papers, pages 73–76, Boulder, Colorado, June 2009. c�2</context>
</contexts>
<marker>Talbot, Osborne, 2006</marker>
<rawString>D. Talbot and M. Osborne. 2006. Modelling lexical redundancy for machine translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ueffing</author>
<author>H Ney</author>
</authors>
<title>Using POS information for SMT into morphologically rich languages.</title>
<date>2003</date>
<booktitle>In EACL.</booktitle>
<contexts>
<context position="3118" citStr="Ueffing and Ney, 2003" startWordPosition="446" endWordPosition="449">ior Work Several earlier works investigate word segmentation and transformation schemes, which may include Part-Of-Speech or other information, to alleviate the effect of morphological variation on translation models. With different training corpus sizes, they focus on translation into English from Arabic (Lee, 2004; Habash and Sadat, 2006; Zollmann et al., 2006), Czech (Goldwater and McClosky, 2005; Talbot and Osborne, 2006), German (Nießen and Ney, 2004) or Catalan, Spanish and Serbian (Popovic and Ney, 2004). Some address the generation challenge when translating from English into Spanish (Ueffing and Ney, 2003; de Gispert and Mari˜no, 2008). Unsupervised morphology learning is proposed as a language-independent solution to reduce the problems of rich morphology in (Virpioja et al., there to earlier workshops. The combination scheme described in this paper will be one of the evaluation tracks in the upcoming workshop. 73 Proceedings of NAACL HLT 2009: Short Papers, pages 73–76, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics Arabic wqrrt An tn$A ljnp tHDyryp jAmEp lljmEyp AlEAmp fY dwrthA AlvAnyp wAlxmsyn MADA D2 w+ qrrt &gt;n tn$A ljnp tHDyryp jAmEp l+ AljmEyp AlEAmp fy </context>
</contexts>
<marker>Ueffing, Ney, 2003</marker>
<rawString>N. Ueffing and H. Ney. 2003. Using POS information for SMT into morphologically rich languages. In EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Virpioja</author>
<author>J J V¨ayrynen</author>
<author>M Creutz</author>
<author>M Sadeniemi</author>
</authors>
<title>Morphology-aware statistical machine translation based on morphs induced in an unsupervised manner.</title>
<date>2007</date>
<booktitle>In MT Summit XI.</booktitle>
<marker>Virpioja, V¨ayrynen, Creutz, Sadeniemi, 2007</marker>
<rawString>S. Virpioja, J.J. V¨ayrynen, M. Creutz, and M. Sadeniemi. 2007. Morphology-aware statistical machine translation based on morphs induced in an unsupervised manner. In MT Summit XI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Zollmann</author>
<author>A Venugopal</author>
<author>S Vogel</author>
</authors>
<title>Bridging the inflection morphology gap for Arabic statistical machine translation. In HLT-NAACL: Short Papers.</title>
<date>2006</date>
<contexts>
<context position="2862" citStr="Zollmann et al., 2006" startWordPosition="406" endWordPosition="409">slation hypotheses performing Minimum Bayes Risk decoding over merged Nbest lists. Results are reported in the NIST 2008 Arabic-to-English MT task and an European Parliament Finnish-to-English task, with significant gains over each individual system. 1.1 Prior Work Several earlier works investigate word segmentation and transformation schemes, which may include Part-Of-Speech or other information, to alleviate the effect of morphological variation on translation models. With different training corpus sizes, they focus on translation into English from Arabic (Lee, 2004; Habash and Sadat, 2006; Zollmann et al., 2006), Czech (Goldwater and McClosky, 2005; Talbot and Osborne, 2006), German (Nießen and Ney, 2004) or Catalan, Spanish and Serbian (Popovic and Ney, 2004). Some address the generation challenge when translating from English into Spanish (Ueffing and Ney, 2003; de Gispert and Mari˜no, 2008). Unsupervised morphology learning is proposed as a language-independent solution to reduce the problems of rich morphology in (Virpioja et al., there to earlier workshops. The combination scheme described in this paper will be one of the evaluation tracks in the upcoming workshop. 73 Proceedings of NAACL HLT 20</context>
</contexts>
<marker>Zollmann, Venugopal, Vogel, 2006</marker>
<rawString>A. Zollmann, A. Venugopal, and S. Vogel. 2006. Bridging the inflection morphology gap for Arabic statistical machine translation. In HLT-NAACL: Short Papers.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>