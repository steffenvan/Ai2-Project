<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000327">
<title confidence="0.980547">
Minimally-Supervised Extraction of Entities from Text Advertisements
</title>
<author confidence="0.995781">
Sameer Singh
</author>
<affiliation confidence="0.9984165">
Dept. of Computer Science
University of Massachusetts
</affiliation>
<address confidence="0.730562">
Amherst, MA 01003
</address>
<email confidence="0.99808">
sameer@cs.umass.edu
</email>
<author confidence="0.731443">
Dustin Hillard
</author>
<affiliation confidence="0.558485">
Advertising Sciences
Yahoo! Labs Silicon Valley
</affiliation>
<address confidence="0.857279">
Santa Clara, CA 95054
</address>
<email confidence="0.831057">
dhillard@yahoo-inc.com
</email>
<author confidence="0.622427">
Chris Leggetter
</author>
<affiliation confidence="0.51935">
Advertising Sciences
Yahoo! Labs Silicon Valley
</affiliation>
<address confidence="0.872258">
Santa Clara, CA 95054
</address>
<email confidence="0.921443">
cjl@yahoo-inc.com
</email>
<sectionHeader confidence="0.991297" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999735045454546">
Extraction of entities from ad creatives is an
important problem that can benefit many com-
putational advertising tasks. Supervised and
semi-supervised solutions rely on labeled data
which is expensive, time consuming, and dif-
ficult to procure for ad creatives. A small
set of manually derived constraints on fea-
ture expectations over unlabeled data can be
used to partially and probabilistically label
large amounts of data. Utilizing recent work
in constraint-based semi-supervised learning,
this paper injects light weight supervision
specified as these “constraints” into a semi-
Markov conditional random field model of en-
tity extraction in ad creatives. Relying solely
on the constraints, the model is trained on a set
of unlabeled ads using an online learning al-
gorithm. We demonstrate significant accuracy
improvements on a manually labeled test set
as compared to a baseline dictionary approach.
We also achieve accuracy that approaches a
fully supervised classifier.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999345">
Growth and competition in web search in recent
years has created an increasing need for improve-
ments in organic and sponsored search. While foun-
dational approaches still focus on matching the exact
words of a search to potential results, there is emerg-
ing need to better understand the underlying intent in
queries and documents. The implicit intent is partic-
ularly important when little text is available, such as
for user queries and advertiser creatives.
This work specifically explores the extraction of
named-entities, i.e. discovering and labeling phrases
in ad creatives. For example, for an ad “Move to
</bodyText>
<page confidence="0.982829">
73
</page>
<bodyText confidence="0.999807583333333">
San Francisco!”, we would like to extract the entity
san francisco and label it a CITY. Similarly, for an
ad “Find DVD players at Amazon”, we would ex-
tract dvd players as a PRODUCT and amazon as a
ORGNAME. The named-entities provide important
features to downstream tasks about what words and
phrases are important, as well as information on the
intent. Much recent research has focused on extract-
ing useful information from text advertisement cre-
atives that can be used for better retrieval and rank-
ing of ads. Semantic annotation of queries and ad
creatives allows for more powerful retrieval models.
Structured representations of semantics, like the one
studied in our task, can be directly framed as infor-
mation extraction tasks, such as segmentation and
named-entity recognition.
Information extraction methods commonly rely
on labeled data for training the models. The hu-
man labeling of ad creatives would have to pro-
vide the complete segmentation and entity labels for
the ads, which the information extraction algorithm
would then rely on as the truth. For entity extraction
from advertisements this involves familiarity with
a large number of different domains, such as elec-
tronics, transportation, apparel, lodging, sports, din-
ing, services, etc. This leads to an arduous and time
consuming labeling process that can result in noisy
and error-prone data. The problem is further com-
pounded by the inherent ambiguity of the task, lead-
ing to the human editors often presenting conflicting
and incorrect labeling.
Similar problems, to a certain degree, are also
faced by a number of other machine learning tasks
where completely relying on the labeled data leads
to unsatisfactory results. To counter the noisy
and sparse labels, semi-supervised learning meth-
</bodyText>
<note confidence="0.637861">
Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 73–81,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999685016949152">
ods utilize unlabeled data to improve the model
(see (Chapelle et al., 2006) for an overview). Fur-
thermore, recent work on constraint-based semi-
supervised learning allows domain experts to eas-
ily provide additional light supervision, enabling the
learning algorithm to learn using the prior domain
knowledge, labeled and unlabeled data (Chang et
al., 2007; Mann and McCallum, 2008; Bellare et al.,
2009; Singh et al., 2010).
Prior domain knowledge, if it can be easily ex-
pressed and incorporated into the learning algo-
rithm, can often be a high-quality and cheap sub-
stitute for labeled data. For example, previous
work has often used dictionaries or lexicons (lists
of phrases of a particular label) to bootstrap the
model (Agichtein and Ganti, 2004; Canisius and
Sporleder, 2007), leading to a partial labeling of the
data. Domain knowledge can also be more proba-
bilistic in nature, representing the probability of cer-
tain token taking on a certain label. For most tasks,
labeled data is a convenient representation of the do-
main knowledge, but for complex domains such as
structured information extraction from ads, these al-
ternative easily expressible representations may be
as effective as labeled data.
Our approach to solving the the named entity ex-
traction problem for ads relies completely on do-
main knowledge not expressed as labeled data, an
approach that is termed minimally supervised. Each
ad creative is represented as a semi-Markov condi-
tional random field that probabilistically represents
the segmentation and labeling of the creative. Exter-
nal domain knowledge is expressed as a set of targets
for the expectations of a small subset of the features
of the model. We use alternating projections (Bel-
lare et al., 2009) to train our model using this knowl-
edge, relying on the rest of the features of the model
to “dissipate” the knowledge. Topic model and co-
occurrence based features help this propagation by
generalizing the supervision to a large number of
similar ads.
This method is applied to a large dataset of text
advertisements sampled from a variety of different
domains. The minimally supervised model performs
significantly better than a model that incorporates
the domain knowledge as hard constraints. Our
model also performs competitively when compared
to a supervised model trained on labeled data from a
similar domain (web search queries).
Background material on semi-CRFs and con-
straint based semi-supervised learning is summa-
rized in Section 2. In Section 3, we describe the
problem of named entity recognition in ad creatives
as a semi-CRF, and describe the features in Sec-
tion 4. The constraints that we use to inject super-
vision into our model are listed in Section 5. We
demonstrate the success of our approach in Sec-
tion 6. This work is compared with related literature
in Section 7.
</bodyText>
<sectionHeader confidence="0.974486" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.9997682">
This section covers introductory material on
the probabilistic representation of our model
(semi-Markov conditional random fields) and the
constraint-driven semi-supervised method that we
use to inject supervision into the model.
</bodyText>
<subsectionHeader confidence="0.992272">
2.1 Semi-Markov Conditional Random Fields
</subsectionHeader>
<bodyText confidence="0.966640214285714">
Conditional Random Fields (CRFs) (Lafferty et
al., 2001) use a Markov random field to model the
conditional probability P(y|x). CRFs are com-
monly used to learn sequential models, where the
Markov field is a linear-chain, and y is a linear se-
quence of labels and each label yi E Y. Let f be a
vector of local feature functions f = (f1, ... , fK),
each of which maps a pair (x, y) and an index i to
a measurement fk(i, x, y) E R. Let f(i, x, y) be
the vector of these measurements, and let F(x, y) =
�|x|
i f(i, x, y). CRFs use these feature functions in
conjunction with the parameters 0 to represent the
conditional probability as follows:
</bodyText>
<equation confidence="0.998509">
P x, 1 eθ·F(x,Y)
(Y�B ) = Z(x)
</equation>
<bodyText confidence="0.99954225">
where Z(x) = EY, eθ·F(x,Y&apos;).
For sequential models where the same labels ap-
pear within a sequence as contiguous blocks (e.g.,
named entity recognition) it is more convenient to
represent these blocks directly as segments. This
representation was formulated as semi-Markov con-
ditional random fields (Semi-CRFs) in (Sarawagi
and Cohen, 2004). The segmentation of a sequence
is represented by s = (s1, ... , sp) where each seg-
ment sj = (tj, uj, yj) consists of a start position
tj, an end position uj, and a label yj E Y. Similar
to the CRF, let g be the vector of segment feature
</bodyText>
<page confidence="0.955042">
74
</page>
<equation confidence="0.830336">
functions g = hg1, ... , gKi, each of which maps
the pair (x, s) and an index j to a measurement
gk(j, x, s) ∈ &lt;, and G(x, s) = P|s|
j g(j, x, s). The
conditional probability is represented as:
P(s|x,B) = Z(x)eθ·G(x,s)
1
</equation>
<bodyText confidence="0.999753666666667">
where Z(x) = Ps0 eθ·G(x,s0). To assert the Marko-
vian assumption, each gk(j, x, s) only computes
features based on x, sj, and yj−11.
An exact inference algorithm was described in
(Sarawagi and Cohen, 2004), and was later im-
proved to be more efficient (Sarawagi, 2006).
</bodyText>
<subsectionHeader confidence="0.97597">
2.2 Constraint Driven Learning Using
Alternating Projections
</subsectionHeader>
<bodyText confidence="0.99957052">
Recent work in semi-supervised learning uses
constraints as external supervision (Chang et al.,
2007; Mann and McCallum, 2008; Bellare et al.,
2009; Singh et al., 2010). These external constraints
are specified as constraints on the expectations of a
set of auxiliary features g0 = {g01, ... , g0k} over the
unlabeled data. In particular, given the targets u =
{u1, ... , uk} corresponding to the auxiliary features
g0, the constraints can take different forms, for ex-
ample L2 penalty ( 1 2β kui−Pj Ep[g0i(xj, s)]k22 = 0),
L1 box constraints (|ui − P j Ep[g0i(xj, s)] |≤ �)
and Affine constraints2 (Ep[g0i(x, s)] ≤ ui). In this
work, we only use the affine form of the constraints.
For an example, using domain knowledge, we
may know that token “arizona” should get the label
STATE in at least half of the occurrences in our data.
To capture this, we introduce an auxiliary feature g0 :
[[Label=STATE given Token=“arizona”]]. The
affine constraint is written as Ep[g0(x, y)] ≥ 0.5.
These constraints have been incorporated into
learning using Alternating Projections (Bellare et
al., 2009). Instead of directly optimizing an ob-
jective function that includes the constraints, this
method considers two distributions, pλ and qλ,µ,
where pλ(s|x) = 1
</bodyText>
<equation confidence="0.924287666666667">
Z(x)eλ·G(x,s) is the usual semi-
Markov model, and1 e(λ·G(x,s)+µ·G0(x,s))
qλ,µ = Z(x)
</equation>
<bodyText confidence="0.9811525">
is an auxiliary distribution that satisfies the con-
straints and has low divergence with the model pλ.
</bodyText>
<footnote confidence="0.973102333333333">
1i.e. gk(j, x, s) can be written as gk(yj−1, x, 8j)
2where E,[g] represents the expectation of g over the unla-
beled data using the model p.
</footnote>
<bodyText confidence="0.999823666666667">
In the batch setting, parameters A and µ are
learned using an EM-like algorithm, where µ is fixed
while optimizing A and vice versa. Each of the up-
dates in these steps decomposes according to the in-
stances, leading to a stochastic gradient based online
algorithm, as follows:
</bodyText>
<listItem confidence="0.926243">
1. Fort = 1, ... , T, let q = 1
</listItem>
<bodyText confidence="0.9602185">
t+t0 where t0 =
1/q0, q0 the initial learning rate. Let labeled
and unlabeled data set sizes be m and n − m
respectively. Let the initial parameters be A0
and µ0, and α be the weight of L2 regulariza-
tion on A.
</bodyText>
<listItem confidence="0.792929">
2. For a new labeled instance xt with segmen-
tation st, set µt = µt−1 and At = At−1 +
q hg(xt, st) − Ep,,t−1 [g(xt, s)] − αλn−1 i
</listItem>
<sectionHeader confidence="0.98198" genericHeader="method">
3 Model
</sectionHeader>
<bodyText confidence="0.999965846153846">
Most text ads consist of a brief title and an ac-
companying abstract that provides additional infor-
mation. The objective of our paper is to extract
the named-entity phrases within these titles and ab-
stracts, then label them with a type from a pre-
determined taxonomy. An example of such an ex-
traction is shown in Fig 1.
We represent the ad creatives as a sequence of
individual tokens, with a special token inserted be-
tween the title and the abstract of the ad. The dis-
tribution over possible phrases and labels of the ad
is expressed as a semi-Markov conditional random
field, as described earlier in Section 2.1.
</bodyText>
<subsectionHeader confidence="0.999694">
3.1 Label Taxonomy
</subsectionHeader>
<bodyText confidence="0.999795">
In most applications of CRFs and semi-CRFs, the
domain of labels is a fixed set Y, where each label
indexes into one value. Instead, in our approach, we
represent our set of labels as a taxonomy (tree). The
labels higher in the taxonomy are more generic (for
</bodyText>
<listItem confidence="0.489452">
3. For a new unlabeled instance xt, µt =
</listItem>
<equation confidence="0.6906904">
h u i
µt−1 + q (n−m) − Eq�t−1,µt−1 [g0(xt, s)]
and At ( = (At−1 + l
hEqat−1,µt−1 [g(xt, s)] − Ep,,t−1 [g(xt, s)] − αλt−1 J .
n
</equation>
<bodyText confidence="0.88028175">
Online training enables scaling the approach to
large data sets, as is the case with ads. In our ap-
proach we rely only on unlabeled data (m = 0, and
step 2 of the above algorithm does not apply).
</bodyText>
<page confidence="0.996398">
75
</page>
<table confidence="0.99147925">
Ad Title: Bradley International Airport Hotel
Ad Abstract: Marriott Hartford, CT Airport hotel - free shuttle service &amp; parking.
Output: Bradley International Airport Hotel
Marriott Hartford, CT Airport hotel free shuttle service &amp; parking.
Label Segment
PLACE: AIRPORT Bradley International
BUSINESS: TRAVEL Hotel
ORGNAME: LODGING Marriott
PLACE: CITY Hartford
PLACE: STATE CT
BUSINESS: TRAVEL hotel
PRODUCT: TRAVEL shuttle service &amp; parking.
</table>
<figureCaption confidence="0.998880333333333">
Figure 1: Example Prediction: An example of an ad creative (title and abstract), along with a set of probable ex-
tracted entities. Note that even in this relatively simple example, there is some ambiguity about what is the correct
segmentation and labeling.
</figureCaption>
<bodyText confidence="0.99997236">
instance, PLACE) and the labels lower in the taxon-
omy are more specific (for instance, STATE may be
a child of PLACE). The taxonomy of labels that we
use for tagging phrases is shown in Figure 2.
When the model predicts a label for a segment,
it can be from any of the levels in the tree. The
benefits of this is multi-fold. First, this allows the
model to be flexible in predicting labels at a lower
(or higher) level based on its confidence. For ex-
ample, the model may have enough evidence to la-
bel “san francisco” a CITY, however, for “georgia”
it may not have enough context to discriminate be-
tween STATE or COUNTRY, but could confidently
label it a PLACE. Secondly, this also allows us to
design the features over multiple levels of label gran-
ularity, which leads to a more expressive model. Ex-
pectation constraints can be specified over this ex-
panded set of features, at any level of the taxonomy.
In order to incorporate the nested labels into our
model, we observe that every feature that fires for
a non-leaf label should also fire for all descendants
of that label, e.g. every feature that is active for la-
bel PLACE should also be active for a label CITY,
COUNTRY, etc 3. Following the observation, for ev-
ery feature gk(x, (tj, uj, yj)) that is active, we also
</bodyText>
<footnote confidence="0.89053875">
3Note that this argument works similarly for the taxonomy
represented as a DAG, where the descendants are of a node are
all nodes reachable from it. We do not explore this structure of
the taxonomy in this paper.
</footnote>
<bodyText confidence="0.5728905">
fire by&apos; E desc(yj), gk(x, (tj, uj, y&apos;))4. The same
procedure is applied to the constraints.
</bodyText>
<sectionHeader confidence="0.999318" genericHeader="method">
4 Features
</sectionHeader>
<bodyText confidence="0.999953461538462">
Our learning algorithm relies on constraints g&apos; as
supervision to extract entities, but even though con-
straints are designed to be generic they do not cover
the whole dataset. The learning algorithm needs
to propagate the supervision to instances where the
constraints are not applicable, guided by the set
of feature functions g. More expressive and rele-
vant features will provide better propagation. Even
though these feature functions represent the “unsu-
pervised” part of the model (in that they are only
dependent on the unlabeled sequences), they play
an important role in propagating the supervision
throughout the dataset.
</bodyText>
<subsectionHeader confidence="0.995028">
4.1 Sequence and Segment Features
</subsectionHeader>
<bodyText confidence="0.999977142857143">
Our first set of features are the commonly used
features employed in linear-chain sequence models
such as CRFs and HMMs. These consist of factors
between each token and its corresponding label, and
neighboring labels. They also include transition fac-
tors between the labels. These are local feature func-
tions that are defined only over pairs of token-wise
</bodyText>
<footnote confidence="0.978031333333333">
4This example describes when gk(yj_1, x, sj) ignores
yj_1. For the usual case gk(yj_1, x, sj), features between all
pairs of descendants of yj_1 and yj are enabled.
</footnote>
<page confidence="0.818124">
76
</page>
<table confidence="0.998905375">
Proper Nouns Common Nouns
PERSON
PRODUCT and BUSINESS
FINANCE MEDIA
EDUCATION APPAREL
TRAVEL AUTO
TECHNOLOGY RESTAURANT
CITY PLACE MANUFACTURER
COUNTRY STATE PRODUCTNAME
AIRPORT CONTINENT MEDIATITLE
ZIPCODE EVENT
OCCASION
AIRLINE ORGNAME APPAREL AUTO
MEDIA SPORTSLEAGUE FINANCE LODGING
EDUCATION TECHNOLOGY RESTAURANT
SPORTSTEAM
</table>
<figureCaption confidence="0.966847333333333">
Figure 2: Label Taxonomy: The set of labels that are used are shown grouped by the parent label. PRODUCT and
BUSINESS labels have been merged for brevity, i.e. there are two labels of each child label shown (e.g. PRODUCT:
AUTO and BUSINESS: AUTO). An additional label OTHER is used for the tokens that do not belong to any entities.
</figureCaption>
<bodyText confidence="0.99929525">
labels yj and yj_I. To utilize the semi-Markov rep-
resentation that allows features over the predicted
segmentation, we add the segment length and pre-
fix/suffix tokens of the segment as features.
</bodyText>
<subsectionHeader confidence="0.993183">
4.2 Segment Clusters
</subsectionHeader>
<bodyText confidence="0.99997125">
Although the sequence and segment features cap-
ture a lot of useful information, they are not suffi-
cient for propagation. For example, if we have a
constraint about the token “london” being a CITY,
but not about “boston”, the model can only rely on
similar contexts between ‘london” and ‘boston” to
propagate the information. To allow more compli-
cated propagation to occur, we use features based
on a clustering of segments.
The segment cluster features are based on simi-
larity between segments from English sentences. A
large corpus of English documents were taken from
web, from which 5.1 billion unique sentences were
extracted. Using the co-occurrence of segments in
the sentences as a distance measure, K-Means is
used to identify clusters of segments as described in
(Pantel et al., 2009). The cluster identity of each seg-
ment is added as a feature to the model, capturing
the intuition that segments that appear in the same
cluster should get the same label.
</bodyText>
<subsectionHeader confidence="0.931595">
4.3 Topic Model
</subsectionHeader>
<bodyText confidence="0.9999915">
Most of the ads lie in separate domains with
very little overlap, for example travel and electron-
ics. Additional information about the domain can
be very useful for identifying entities in the ad. For
example, consider the token “amazon”. It may be
difficult to discern whether the token refers to the
geographical region or the website from just the fea-
tures in the model, however given that the domain
of the ad is travel (or conversely, electronics), the
choice becomes easier.
The problem of domain identification is often
posed as a document classification task, which re-
quires labeled data to train and thus is not applica-
ble for our task. Additionally, we are not concerned
with accurately specifying the exact domain of each
ad, instead any information about similarity between
ads according to their domains is helpful. This kind
of representation can be obtained in an unsupervised
fashion by using topic cluster models (Steyvers and
Griffiths, 2007; Blei et al., 2003). Given a large
set of unlabeled documents, topic models define a
distribution of topics over each document, such that
documents that are similar to each other have similar
topic distributions.
The LDA (Blei et al., 2003) implementation of
topic models in the Mallet toolkit (McCallum, 2002)
was used to construct a model with 1000 topics for
a dataset containing 3 million ads. For each ad, the
discrete distribution over the topics, in conjunction
with each possible label, was added as a feature.
This captures a potential for each label given an ap-
proximation of the ad’s domain captured as topics.
</bodyText>
<page confidence="0.998857">
77
</page>
<sectionHeader confidence="0.996419" genericHeader="method">
5 Constraints
</sectionHeader>
<bodyText confidence="0.99997815">
Constraints are used to inject light supervision
into the learning algorithm and are defined as tar-
gets u for expectations of features G&apos; over the data.
Any feature that can be included in the model can be
used as a constraint. This allows us to capture a va-
riety of different forms of domain knowledge, some
of which we shall explore in this section.
Labeled data xl, sl can be incorporated as a spe-
cial case when constraints have a target expectation
of 1.0 for the features that are defined only for the
sequence xl and with segmentation sl. This allows
us to easily use labeled data in form of constraints,
but in this work we do not include any labeled data.
A more interesting case is that of partial labeling,
where the domain expert may have prior knowledge
about the probability that certain tokens and/or con-
texts result in a specific label. These constraints
can cover more instances than labeled data, however
they only provide partial and stochastic labels. All
of the constraints described in this section are also
included as simple features.
Many different methods have been suggested in
recent work for finding the correct target values for
the feature expectations. First, if ample labeled data
is available, features expectations can be calculated,
and assumptions can be made that the same expec-
tations hold for the unlabeled data. This method
cannot be applied to our work due to lack of la-
beled data. Second, for certain constraints, the prior
knowledge can be used directly to specify these val-
ues. Third, if the constraints are an output of a
previous machine learning model, we can use that
model’s confidence in the prediction as the target
expectation of the constraint. Finally, a search for
the ideal values of the target expectations can be
performed by evaluating on small evaluation data.
Our target values for feature expectations were set
based on domain knowledge, then adjusted manu-
ally based on minimal manual examination of ex-
amples on a small held-out data set.
</bodyText>
<subsectionHeader confidence="0.990909">
5.1 Dictionary-Based
</subsectionHeader>
<bodyText confidence="0.999719628571428">
Dictionary constraints are the form of constraints
that apply to the feature between an individual token
and its label. For a set of tokens in the dictionary, the
constraints specify which label they are likely to be.
Dictionaries can be easily constructed using various
sources, for example product databases, lexicons,
manual collections, or predictions from other mod-
els. These dictionary constraints are often used to
bootstrap models (Agichtein and Ganti, 2004; Cani-
sius and Sporleder, 2007) and have also been used in
the ads domain (Li et al., 2009). For our application,
we rely on dictionary constraints from two sources.
First, the predictions of a previous model are used
to construct a dictionary. A model for entity extrac-
tion is trained on a large amount of labeled search
query data. The domain and style of web queries
differs from advertisements, but the set of labels is
essentially the same. The supervised query entity
extraction model is used to infer segments and la-
bels for the ads domain, and each of the predicted
segments are added to the dictionary of the corre-
sponding predicted label. Even though the predic-
tions of the model are not perfect (see Section 6.1)
the predictions of some of the labels are of high pre-
cision, and thus can be used for supervision in form
of noisy dictionary constraints.
The second source of prior information for dictio-
nary constraints are external databases. Lists of vari-
ous types of places can be obtained easily, for exam-
ple CITY, COUNTRY, STATE, AIRPORT, etc. Ad-
ditionally, product databases available internally to
our research group are used for MANUFACTURERS,
BRANDS, PRODUCTS, MEDIATITLE, etc. Some of
these databases are noisy, and the constraints based
on them are given lower target expectations.
</bodyText>
<subsectionHeader confidence="0.999654">
5.2 Pattern-Based
</subsectionHeader>
<bodyText confidence="0.999984533333333">
Prior knowledge can often be easily expressed as
patterns that appear for a specific domain. Pattern
based matching has been used to express supervision
for information extraction tasks (Califf and Mooney,
1999; Muslea, 1999). The usual use case involves
a domain expert specifying a number of “prototyp-
ical” patterns, while additional patterns are discov-
ered based on these initial patterns.
We incorporate noisy forms of patterns as con-
straints. Simple regular expression based patterns
were used to identify and label segments for a few
domains (e.g. “flights to {PLACE}” and “looking
for {PRODUCT}?”). We do not employ a pattern-
discovery algorithm for finding other contexts; the
model propagates these labels, as before, using the
</bodyText>
<page confidence="0.995616">
78
</page>
<bodyText confidence="0.99960875">
features of the rest of the model. However if the
output of a pattern-discovery algorithm is available,
it can be directly incorporated into the model as ad-
ditional constraints.
</bodyText>
<subsectionHeader confidence="0.999149">
5.3 Domain-Based
</subsectionHeader>
<bodyText confidence="0.999556454545454">
A number of label-independent constraints are
also added to avoid unrealistic segmentation predic-
tions. For example, an expectation over segment
lengths was included, which denotes that the seg-
ment length is usually 1 or 2, and almost never more
than 6. A constraint is also added to avoid segments
that overlap the separator token between title and
abstract by ensuring that the segment that includes
the separator token is always of length 1 and of la-
bel OTHER. Finally, an additional constraint ensures
that the label OTHER is the most common label.
</bodyText>
<sectionHeader confidence="0.999905" genericHeader="evaluation">
6 Results
</sectionHeader>
<bodyText confidence="0.9999766875">
The feature expectations of the model are cal-
culated with modifications to an open source
semi-CRF package5. We collect two datasets of
ad creatives randomly sampled from Yahoo!’s ads
database: a smaller dataset contains 14k ads and a
larger dataset of 42k ads. The ads were not restricted
to any particular domain (such as travel, electronics,
etc.). The average length of the complete ad text
was —14 tokens. Preprocessing of the text involved
lower-casing, basic cleaning, and stemming.
The training time for each iteration through the
data was —90 minutes for the smaller dataset and
—360 minutes for the larger dataset. Inference over
the dataset, using Viterbi decoding for semi-CRFs,
took a total of —8 and —32 minutes. The initial
learning rate q is set to 10.0.
</bodyText>
<subsectionHeader confidence="0.990776">
6.1 Discussion
</subsectionHeader>
<bodyText confidence="0.9998231">
We compare our approach to a baseline “Dictio-
nary” system that deterministically selects a label
based on the dictionaries described in Section 5.1.
A segment is given a label corresponding to the dic-
tionary it appears in, or OTHER if it does not ap-
pear in any dictionary. In addition, we compare to
an external supervised system that has been trained
on tens-of-thousands of manually-annotated search
queries that use the same taxonomy (the same sys-
tem as used in Section 5.1 to derive dictionaries).
</bodyText>
<footnote confidence="0.983669">
5Available on http://crf.sourceforge.net/
</footnote>
<bodyText confidence="0.999938181818182">
This CRF-based model contains mostly the same
features as our unsupervised system, and approxi-
mates what a fully supervised system might achieve,
although it is trained on search queries. Results for
our approach and these two systems are presented
in Table 1. Our evaluation data consists of 2,157
randomly sampled ads that were manually labeled
by professional editors. This labeled data size was
too small to sufficiently train a supervised semi-CRF
model that out-performed the dictionary baseline for
our task (which consists of 45 potential labels).
We measure the token-wise accuracy and macro
F-score over the manually labeled dataset. Typi-
cally, these metrics measure only exact matches be-
tween the true and the predicted label, but this leads
to cases where the model may predict PLACE for a
true CITY. To allow a “partial credit” for these cases,
we introduce “weighted” version of these measures,
where a predicted label is given 0.5 credit if the true
label is its direct child or parent, and 0.25 credit if
the true label is a sibling. Our F-score measures the
recall of all true labels except OTHER and similarly
the precision of all predicted labels except OTHER.
We focus on these labels because the OTHER la-
bel is mostly uninformative for downstream tasks.
The token-wise accuracy over all labels (including
OTHER) is included as “Overall Accuracy”.
Our method significantly outperforms the base-
line dictionary method while approaching the results
obtained with the sophisticated supervised model.
Overall accuracy is 50% greater than the dictionary
baseline, and comes within 10% of the supervised
model6. Increasing unlabeled data from 14k to 42k
ads provides an increase in overall accuracy and
non-OTHER precision, but somewhat reduces recall
for the remaining labels. We also include the F2-
score which gives more weight to recall, because
we are interested in extracting informative labels for
downstream models (which may be able to com-
pensate for a lower precision in label prediction).
Our model trained on 14k samples out-performs the
query-based supervised model in terms of F2, which
is promising for future work that will incorporate
predicted labels in ad retrieval and ranking systems.
</bodyText>
<footnote confidence="0.9838315">
6Comparisons and trends for normal and weighted measures
are consistent throughout the results.
</footnote>
<page confidence="0.998448">
79
</page>
<tableCaption confidence="0.999765">
Table 1: Evaluation: Token-wise accuracy and F-score for the methods evaluated on labeled data (Normal / Weighted)
</tableCaption>
<table confidence="0.999295833333333">
Metric Dictionary Our Method (14k) Our Method (42k) Query-based Sup. Model
Overall Accuracy 0.454 / 0.466 0.596 / 0.627 0.629 / 0.649 0.665 / 0.685
non-OTHER Recall 0.170 / 0.205 0.329 / 0.412 0.271 / 0.325 0.286 / 0.342
non-OTHER Precision 0.136 / 0.163 0.265 / 0.333 0.297 / 0.357 0.392 / 0.469
F1-score 0.151 / 0.182 0.293 / 0.368 0.283 / 0.340 0.331 / 0.395
F2-score 0.162 / 0.195 0.313 / 0.393 0.276 / 0.331 0.303 / 0.361
</table>
<sectionHeader confidence="0.999769" genericHeader="related work">
7 Related Work
</sectionHeader>
<bodyText confidence="0.999960782608696">
Extraction of structured information from text is
of interest to a large number of communities. How-
ever, in the ads domain, the task has usually been
simplified to that of classification or ranking. Pre-
vious work has focused on retrieval (Raghavan and
Iyer, 2008), user click prediction (Shaparenko et
al., 2009; Richardson et al., 2007; Ciaramita et al.,
2008), ad relevance (Hillard et al., 2010) and bounce
rate prediction (Sculley et al., 2009). As far we
know, our method is the only one that aims to solve a
much more complex task of segmentation and entity
extraction from ad creatives. Supervised methods
are a poor choice to solve this task as they require
large amounts of labeled ads, which is expensive,
time-consuming and noisy. Most semi-supervised
methods also rely on some labeled data, and scale
badly with the size of unlabeled data, which is in-
tractable for most ad databases.
Considerable research has been undertaken to ex-
ploit forms of domain knowledge other than la-
beled data to efficiently train a model while utiliz-
ing the unlabeled data. These include methods that
express domain knowledge as constraints on fea-
tures, which have shown to provide high accuracy
on natural language datasets (Chang et al., 2007;
Chang et al., 2008; Mann and McCallum, 2008;
Bellare et al., 2009; Singh et al., 2010). We use
the method of alternating projections for constraint-
driven learning (Bellare et al., 2009) since it spec-
ifies constraints on feature expectations instead of
less intuitive constraints on feature parameters (as
in (Chang et al., 2008)). Additionally, the alternat-
ing projection method is computationally more effi-
cient than Generalized Expectation (Mann and Mc-
Callum, 2008) and can be applied in an online fash-
ion using stochastic gradient.
Our approach is most similar to (Li et al., 2009),
which uses semi-supervised learning for CRFs to ex-
tract structured information from user queries. They
also use a constraint-driven method that utilizes an
external data source. Their method, however, relies
on labeled data for part of the supervision while our
method uses only unlabeled data. Also, evaluation
was only shown for a small domain of user queries,
while our work does not restrict itself to any specific
domain of ads for evaluation.
</bodyText>
<sectionHeader confidence="0.998945" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.99994804">
Although important for a number of tasks in spon-
sored search, extraction of structured information
from text advertisements is not a well-studied prob-
lem. The difficulty of the problem lies in the expen-
sive, time-consuming and error-prone labeling pro-
cess. In this work, the aim was to explore machine
learning methods that do not use labeled data, re-
lying instead on light supervision specified as con-
straints on feature expectations. The results clearly
show this minimally-supervised method performs
significantly better than a dictionary based baseline.
Our method also approaches the performance of a
supervised model trained to extract entities from
web search queries. These findings strongly suggest
that domain knowledge expressed in forms other
than directly labeled data may be preferable in do-
mains for which labeling data is unsuitable.
The most important limitation lies in the fact
that specifying the target expectations of constraints
is an ad-hoc process, and robustness of the semi-
supervised learning method to noise in these target
values needs to be investigated. Further research
will also explore using the extracted entities from
advertisements to improve downstream sponsored
search tasks.
</bodyText>
<page confidence="0.996008">
80
</page>
<sectionHeader confidence="0.990106" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99953587">
Eugene Agichtein and Venkatesh Ganti. 2004. Min-
ing reference tables for automatic text segmentation.
In KDD: ACM SIGKDD International Conference on
Knowledge Discovery and Data mining, pages 20–29,
New York, NY, USA.
Kedar Bellare, Gregory Druck, and Andrew McCallum.
2009. Alternating projections for learning with expec-
tation constraints. In UAI: Conference on Uncertainty
in Artificial Intelligence.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent dirichlet allocation. Journal on Machine
Learning Research, 3:993–1022.
Mary Elaine Califf and Raymond J. Mooney. 1999. Re-
lational learning of pattern-match rules for information
extraction. In AAAI / IAAI ’99: National conference
on Artificial intelligence and the Innovative Applica-
tions of Artificial Intelligence conference, pages 328–
334.
Sander Canisius and Caroline Sporleder. 2007. Boot-
strapping information extraction from field books.
In EMNLP-CoNLL: Joint Conference on Empirical
Methods in Natural Language Processing and Compu-
tational Natural Language Learning, pages 827–836.
Ming-Wei Chang, Lev Ratinov, and Dan Roth.
2007. Guiding semi-supervision with constraint-
driven learning. In ACL: Annual meeting of the Asso-
ciation for Computational Linguistics, pages 280–287.
Ming-Wei Chang, Lev Ratinov, Nicholas Rizzolo, and
Dan Roth. 2008. Learning and inference with con-
straints. In AAAI: National Conference on Artificial
Intelligence, pages 1513–1518.
O. Chapelle, B. Sch¨olkopf, and A. Zien, editors.
2006. Semi-Supervised Learning (Adaptive Computa-
tion and Machine Learning). The MIT Press, Septem-
ber.
Massimiliano Ciaramita, Vanessa Murdock, and Vassilis
Plachouras. 2008. Online learning from click data for
sponsored search. In WWW: International World Wide
Web Conference.
Dustin Hillard, Stefan Schroedl, Eren Manavoglu, Hema
Raghavan, and Chris Leggetter. 2010. Improving
ad relevance in sponsored search. In WSDM: Inter-
national conference on Web search and data mining,
pages 361–370.
John Lafferty, Andrew Mccallum, and Fernando Pereira.
2001. Conditional random fields: Probabilistic models
for segmenting and labeling sequence data. In ICML:
International Conference on Machine Learning, pages
282–289.
Xiao Li, Ye-Yi Wang, and Alex Acero. 2009. Extracting
structured information from user queries with semi-
supervised conditional random fields. In SIGIR: In-
ternational Conference on research and development
in information retrieval, pages 572–579. ACM.
Gideon S. Mann and Andrew McCallum. 2008. General-
ized expectation criteria for semi-supervised learning
of conditional random fields. In ACL: Annual meet-
ing of the Association for Computational Linguistics,
pages 870–878.
Andrew McCallum. 2002. Mallet: A machine learning
for language toolkit. http://mallet.cs.umass.edu.
Ion Muslea. 1999. Extraction patterns for information
extraction tasks: A survey. In AAAI: Workshop on Ma-
chine Learning for Information Extraction, pages 1–6.
Patrick Pantel, Eric Crestan, Arkady Borkovsky, Ana-
Maria Popescu, and Vishnu Vyas. 2009. Web-scale
distributional similarity and entity set expansion. In
EMNLP: Conference on Empirical Methods in Natu-
ral Language Processing, pages 938–947.
Hema Raghavan and Rukmini Iyer. 2008. Evaluating
vector-space and probabilistic models for query to ad
matching. In SIGIR Workshop on Information Re-
trieval in Advertising (IRA).
Matthew Richardson, Ewa Dominowska, and Robert
Ragno. 2007. Predicting clicks: estimating the click-
through rate for new ads. In WWW: International
World Wide Web Conference.
Sunita Sarawagi and William W. Cohen. 2004. Semi-
markov conditional random fields for information ex-
traction. In NIPS: Neural Information Processing Sys-
tems.
Sunita Sarawagi. 2006. Efficient inference on sequence
segmentation models. In ICML: International Confer-
ence on Machine Learning, pages 793–800.
D. Sculley, Robert G. Malkin, Sugato Basu, and
Roberto J. Bayardo. 2009. Predicting bounce
rates in sponsored search advertisements. In KDD:
ACM SIGKDD International Conference on Knowl-
edge Discovery and Data mining, pages 1325–1334.
Benyah Shaparenko, Ozgur Cetin, and Rukmini Iyer.
2009. Data driven text features for sponsored search
click prediction. In AdKDD: Workshop on Data min-
ing and audience intelligence for advertising.
Sameer Singh, Limin Yao, Sebastian Riedel, and Andrew
McCallum. 2010. Constraint-driven rank-based learn-
ing for information extraction. In North American
Chapter of the Association for Computational Linguis-
tics - Human Language Technologies (NAACL HLT).
Mark Steyvers and Tom Griffiths. 2007. Probabilistic
Topic Models. Lawrence Erlbaum Associates.
</reference>
<page confidence="0.999257">
81
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.017226">
<title confidence="0.999742">Minimally-Supervised Extraction of Entities from Text Advertisements</title>
<author confidence="0.998929">Sameer Singh</author>
<affiliation confidence="0.999832">Dept. of Computer University of</affiliation>
<address confidence="0.975881">Amherst, MA</address>
<email confidence="0.998502">sameer@cs.umass.edu</email>
<title confidence="0.5846775">Dustin Advertising</title>
<author confidence="0.45255">Yahoo Labs Silicon</author>
<address confidence="0.835715">Santa Clara, CA</address>
<email confidence="0.995882">dhillard@yahoo-inc.com</email>
<title confidence="0.4693825">Chris Advertising</title>
<author confidence="0.456731">Yahoo Labs Silicon</author>
<address confidence="0.765862">Santa Clara, CA</address>
<email confidence="0.998998">cjl@yahoo-inc.com</email>
<abstract confidence="0.998479608695652">Extraction of entities from ad creatives is an important problem that can benefit many computational advertising tasks. Supervised and semi-supervised solutions rely on labeled data which is expensive, time consuming, and difficult to procure for ad creatives. A small set of manually derived constraints on feature expectations over unlabeled data can be to large amounts of data. Utilizing recent work in constraint-based semi-supervised learning, this paper injects light weight supervision specified as these “constraints” into a semi- Markov conditional random field model of entity extraction in ad creatives. Relying solely on the constraints, the model is trained on a set of unlabeled ads using an online learning algorithm. We demonstrate significant accuracy improvements on a manually labeled test set as compared to a baseline dictionary approach. We also achieve accuracy that approaches a fully supervised classifier.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eugene Agichtein</author>
<author>Venkatesh Ganti</author>
</authors>
<title>Mining reference tables for automatic text segmentation.</title>
<date>2004</date>
<booktitle>In KDD: ACM SIGKDD International Conference on Knowledge Discovery and Data mining,</booktitle>
<pages>20--29</pages>
<location>New York, NY, USA.</location>
<contexts>
<context position="4708" citStr="Agichtein and Ganti, 2004" startWordPosition="716" endWordPosition="719">onstraint-based semisupervised learning allows domain experts to easily provide additional light supervision, enabling the learning algorithm to learn using the prior domain knowledge, labeled and unlabeled data (Chang et al., 2007; Mann and McCallum, 2008; Bellare et al., 2009; Singh et al., 2010). Prior domain knowledge, if it can be easily expressed and incorporated into the learning algorithm, can often be a high-quality and cheap substitute for labeled data. For example, previous work has often used dictionaries or lexicons (lists of phrases of a particular label) to bootstrap the model (Agichtein and Ganti, 2004; Canisius and Sporleder, 2007), leading to a partial labeling of the data. Domain knowledge can also be more probabilistic in nature, representing the probability of certain token taking on a certain label. For most tasks, labeled data is a convenient representation of the domain knowledge, but for complex domains such as structured information extraction from ads, these alternative easily expressible representations may be as effective as labeled data. Our approach to solving the the named entity extraction problem for ads relies completely on domain knowledge not expressed as labeled data, </context>
<context position="21778" citStr="Agichtein and Ganti, 2004" startWordPosition="3612" endWordPosition="3615">s were set based on domain knowledge, then adjusted manually based on minimal manual examination of examples on a small held-out data set. 5.1 Dictionary-Based Dictionary constraints are the form of constraints that apply to the feature between an individual token and its label. For a set of tokens in the dictionary, the constraints specify which label they are likely to be. Dictionaries can be easily constructed using various sources, for example product databases, lexicons, manual collections, or predictions from other models. These dictionary constraints are often used to bootstrap models (Agichtein and Ganti, 2004; Canisius and Sporleder, 2007) and have also been used in the ads domain (Li et al., 2009). For our application, we rely on dictionary constraints from two sources. First, the predictions of a previous model are used to construct a dictionary. A model for entity extraction is trained on a large amount of labeled search query data. The domain and style of web queries differs from advertisements, but the set of labels is essentially the same. The supervised query entity extraction model is used to infer segments and labels for the ads domain, and each of the predicted segments are added to the </context>
</contexts>
<marker>Agichtein, Ganti, 2004</marker>
<rawString>Eugene Agichtein and Venkatesh Ganti. 2004. Mining reference tables for automatic text segmentation. In KDD: ACM SIGKDD International Conference on Knowledge Discovery and Data mining, pages 20–29, New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kedar Bellare</author>
<author>Gregory Druck</author>
<author>Andrew McCallum</author>
</authors>
<title>Alternating projections for learning with expectation constraints.</title>
<date>2009</date>
<booktitle>In UAI: Conference on Uncertainty in Artificial Intelligence.</booktitle>
<contexts>
<context position="4361" citStr="Bellare et al., 2009" startWordPosition="658" endWordPosition="661">pervised learning methHuman Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 73–81, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics ods utilize unlabeled data to improve the model (see (Chapelle et al., 2006) for an overview). Furthermore, recent work on constraint-based semisupervised learning allows domain experts to easily provide additional light supervision, enabling the learning algorithm to learn using the prior domain knowledge, labeled and unlabeled data (Chang et al., 2007; Mann and McCallum, 2008; Bellare et al., 2009; Singh et al., 2010). Prior domain knowledge, if it can be easily expressed and incorporated into the learning algorithm, can often be a high-quality and cheap substitute for labeled data. For example, previous work has often used dictionaries or lexicons (lists of phrases of a particular label) to bootstrap the model (Agichtein and Ganti, 2004; Canisius and Sporleder, 2007), leading to a partial labeling of the data. Domain knowledge can also be more probabilistic in nature, representing the probability of certain token taking on a certain label. For most tasks, labeled data is a convenient </context>
<context position="5693" citStr="Bellare et al., 2009" startWordPosition="873" endWordPosition="877">ads, these alternative easily expressible representations may be as effective as labeled data. Our approach to solving the the named entity extraction problem for ads relies completely on domain knowledge not expressed as labeled data, an approach that is termed minimally supervised. Each ad creative is represented as a semi-Markov conditional random field that probabilistically represents the segmentation and labeling of the creative. External domain knowledge is expressed as a set of targets for the expectations of a small subset of the features of the model. We use alternating projections (Bellare et al., 2009) to train our model using this knowledge, relying on the rest of the features of the model to “dissipate” the knowledge. Topic model and cooccurrence based features help this propagation by generalizing the supervision to a large number of similar ads. This method is applied to a large dataset of text advertisements sampled from a variety of different domains. The minimally supervised model performs significantly better than a model that incorporates the domain knowledge as hard constraints. Our model also performs competitively when compared to a supervised model trained on labeled data from </context>
<context position="9017" citStr="Bellare et al., 2009" startWordPosition="1446" endWordPosition="1449"> j to a measurement gk(j, x, s) ∈ &lt;, and G(x, s) = P|s| j g(j, x, s). The conditional probability is represented as: P(s|x,B) = Z(x)eθ·G(x,s) 1 where Z(x) = Ps0 eθ·G(x,s0). To assert the Markovian assumption, each gk(j, x, s) only computes features based on x, sj, and yj−11. An exact inference algorithm was described in (Sarawagi and Cohen, 2004), and was later improved to be more efficient (Sarawagi, 2006). 2.2 Constraint Driven Learning Using Alternating Projections Recent work in semi-supervised learning uses constraints as external supervision (Chang et al., 2007; Mann and McCallum, 2008; Bellare et al., 2009; Singh et al., 2010). These external constraints are specified as constraints on the expectations of a set of auxiliary features g0 = {g01, ... , g0k} over the unlabeled data. In particular, given the targets u = {u1, ... , uk} corresponding to the auxiliary features g0, the constraints can take different forms, for example L2 penalty ( 1 2β kui−Pj Ep[g0i(xj, s)]k22 = 0), L1 box constraints (|ui − P j Ep[g0i(xj, s)] |≤ �) and Affine constraints2 (Ep[g0i(x, s)] ≤ ui). In this work, we only use the affine form of the constraints. For an example, using domain knowledge, we may know that token “a</context>
<context position="30102" citStr="Bellare et al., 2009" startWordPosition="4972" endWordPosition="4975">f labeled ads, which is expensive, time-consuming and noisy. Most semi-supervised methods also rely on some labeled data, and scale badly with the size of unlabeled data, which is intractable for most ad databases. Considerable research has been undertaken to exploit forms of domain knowledge other than labeled data to efficiently train a model while utilizing the unlabeled data. These include methods that express domain knowledge as constraints on features, which have shown to provide high accuracy on natural language datasets (Chang et al., 2007; Chang et al., 2008; Mann and McCallum, 2008; Bellare et al., 2009; Singh et al., 2010). We use the method of alternating projections for constraintdriven learning (Bellare et al., 2009) since it specifies constraints on feature expectations instead of less intuitive constraints on feature parameters (as in (Chang et al., 2008)). Additionally, the alternating projection method is computationally more efficient than Generalized Expectation (Mann and McCallum, 2008) and can be applied in an online fashion using stochastic gradient. Our approach is most similar to (Li et al., 2009), which uses semi-supervised learning for CRFs to extract structured information </context>
</contexts>
<marker>Bellare, Druck, McCallum, 2009</marker>
<rawString>Kedar Bellare, Gregory Druck, and Andrew McCallum. 2009. Alternating projections for learning with expectation constraints. In UAI: Conference on Uncertainty in Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>Journal on Machine Learning Research,</journal>
<pages>3--993</pages>
<contexts>
<context position="18671" citStr="Blei et al., 2003" startWordPosition="3096" endWordPosition="3099">n the model, however given that the domain of the ad is travel (or conversely, electronics), the choice becomes easier. The problem of domain identification is often posed as a document classification task, which requires labeled data to train and thus is not applicable for our task. Additionally, we are not concerned with accurately specifying the exact domain of each ad, instead any information about similarity between ads according to their domains is helpful. This kind of representation can be obtained in an unsupervised fashion by using topic cluster models (Steyvers and Griffiths, 2007; Blei et al., 2003). Given a large set of unlabeled documents, topic models define a distribution of topics over each document, such that documents that are similar to each other have similar topic distributions. The LDA (Blei et al., 2003) implementation of topic models in the Mallet toolkit (McCallum, 2002) was used to construct a model with 1000 topics for a dataset containing 3 million ads. For each ad, the discrete distribution over the topics, in conjunction with each possible label, was added as a feature. This captures a potential for each label given an approximation of the ad’s domain captured as topic</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent dirichlet allocation. Journal on Machine Learning Research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mary Elaine Califf</author>
<author>Raymond J Mooney</author>
</authors>
<title>Relational learning of pattern-match rules for information extraction.</title>
<date>1999</date>
<booktitle>In AAAI / IAAI ’99: National conference on Artificial intelligence and the Innovative Applications of Artificial Intelligence conference,</booktitle>
<pages>328--334</pages>
<contexts>
<context position="23308" citStr="Califf and Mooney, 1999" startWordPosition="3865" endWordPosition="3868">ictionary constraints are external databases. Lists of various types of places can be obtained easily, for example CITY, COUNTRY, STATE, AIRPORT, etc. Additionally, product databases available internally to our research group are used for MANUFACTURERS, BRANDS, PRODUCTS, MEDIATITLE, etc. Some of these databases are noisy, and the constraints based on them are given lower target expectations. 5.2 Pattern-Based Prior knowledge can often be easily expressed as patterns that appear for a specific domain. Pattern based matching has been used to express supervision for information extraction tasks (Califf and Mooney, 1999; Muslea, 1999). The usual use case involves a domain expert specifying a number of “prototypical” patterns, while additional patterns are discovered based on these initial patterns. We incorporate noisy forms of patterns as constraints. Simple regular expression based patterns were used to identify and label segments for a few domains (e.g. “flights to {PLACE}” and “looking for {PRODUCT}?”). We do not employ a patterndiscovery algorithm for finding other contexts; the model propagates these labels, as before, using the 78 features of the rest of the model. However if the output of a pattern-d</context>
</contexts>
<marker>Califf, Mooney, 1999</marker>
<rawString>Mary Elaine Califf and Raymond J. Mooney. 1999. Relational learning of pattern-match rules for information extraction. In AAAI / IAAI ’99: National conference on Artificial intelligence and the Innovative Applications of Artificial Intelligence conference, pages 328– 334.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sander Canisius</author>
<author>Caroline Sporleder</author>
</authors>
<title>Bootstrapping information extraction from field books.</title>
<date>2007</date>
<booktitle>In EMNLP-CoNLL: Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>827--836</pages>
<contexts>
<context position="4739" citStr="Canisius and Sporleder, 2007" startWordPosition="720" endWordPosition="723">sed learning allows domain experts to easily provide additional light supervision, enabling the learning algorithm to learn using the prior domain knowledge, labeled and unlabeled data (Chang et al., 2007; Mann and McCallum, 2008; Bellare et al., 2009; Singh et al., 2010). Prior domain knowledge, if it can be easily expressed and incorporated into the learning algorithm, can often be a high-quality and cheap substitute for labeled data. For example, previous work has often used dictionaries or lexicons (lists of phrases of a particular label) to bootstrap the model (Agichtein and Ganti, 2004; Canisius and Sporleder, 2007), leading to a partial labeling of the data. Domain knowledge can also be more probabilistic in nature, representing the probability of certain token taking on a certain label. For most tasks, labeled data is a convenient representation of the domain knowledge, but for complex domains such as structured information extraction from ads, these alternative easily expressible representations may be as effective as labeled data. Our approach to solving the the named entity extraction problem for ads relies completely on domain knowledge not expressed as labeled data, an approach that is termed mini</context>
<context position="21809" citStr="Canisius and Sporleder, 2007" startWordPosition="3616" endWordPosition="3620">knowledge, then adjusted manually based on minimal manual examination of examples on a small held-out data set. 5.1 Dictionary-Based Dictionary constraints are the form of constraints that apply to the feature between an individual token and its label. For a set of tokens in the dictionary, the constraints specify which label they are likely to be. Dictionaries can be easily constructed using various sources, for example product databases, lexicons, manual collections, or predictions from other models. These dictionary constraints are often used to bootstrap models (Agichtein and Ganti, 2004; Canisius and Sporleder, 2007) and have also been used in the ads domain (Li et al., 2009). For our application, we rely on dictionary constraints from two sources. First, the predictions of a previous model are used to construct a dictionary. A model for entity extraction is trained on a large amount of labeled search query data. The domain and style of web queries differs from advertisements, but the set of labels is essentially the same. The supervised query entity extraction model is used to infer segments and labels for the ads domain, and each of the predicted segments are added to the dictionary of the corresponding</context>
</contexts>
<marker>Canisius, Sporleder, 2007</marker>
<rawString>Sander Canisius and Caroline Sporleder. 2007. Bootstrapping information extraction from field books. In EMNLP-CoNLL: Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 827–836.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ming-Wei Chang</author>
<author>Lev Ratinov</author>
<author>Dan Roth</author>
</authors>
<title>Guiding semi-supervision with constraintdriven learning.</title>
<date>2007</date>
<booktitle>In ACL: Annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>280--287</pages>
<contexts>
<context position="4314" citStr="Chang et al., 2007" startWordPosition="650" endWordPosition="653"> counter the noisy and sparse labels, semi-supervised learning methHuman Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 73–81, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics ods utilize unlabeled data to improve the model (see (Chapelle et al., 2006) for an overview). Furthermore, recent work on constraint-based semisupervised learning allows domain experts to easily provide additional light supervision, enabling the learning algorithm to learn using the prior domain knowledge, labeled and unlabeled data (Chang et al., 2007; Mann and McCallum, 2008; Bellare et al., 2009; Singh et al., 2010). Prior domain knowledge, if it can be easily expressed and incorporated into the learning algorithm, can often be a high-quality and cheap substitute for labeled data. For example, previous work has often used dictionaries or lexicons (lists of phrases of a particular label) to bootstrap the model (Agichtein and Ganti, 2004; Canisius and Sporleder, 2007), leading to a partial labeling of the data. Domain knowledge can also be more probabilistic in nature, representing the probability of certain token taking on a certain label</context>
<context position="8970" citStr="Chang et al., 2007" startWordPosition="1438" endWordPosition="1441">ch of which maps the pair (x, s) and an index j to a measurement gk(j, x, s) ∈ &lt;, and G(x, s) = P|s| j g(j, x, s). The conditional probability is represented as: P(s|x,B) = Z(x)eθ·G(x,s) 1 where Z(x) = Ps0 eθ·G(x,s0). To assert the Markovian assumption, each gk(j, x, s) only computes features based on x, sj, and yj−11. An exact inference algorithm was described in (Sarawagi and Cohen, 2004), and was later improved to be more efficient (Sarawagi, 2006). 2.2 Constraint Driven Learning Using Alternating Projections Recent work in semi-supervised learning uses constraints as external supervision (Chang et al., 2007; Mann and McCallum, 2008; Bellare et al., 2009; Singh et al., 2010). These external constraints are specified as constraints on the expectations of a set of auxiliary features g0 = {g01, ... , g0k} over the unlabeled data. In particular, given the targets u = {u1, ... , uk} corresponding to the auxiliary features g0, the constraints can take different forms, for example L2 penalty ( 1 2β kui−Pj Ep[g0i(xj, s)]k22 = 0), L1 box constraints (|ui − P j Ep[g0i(xj, s)] |≤ �) and Affine constraints2 (Ep[g0i(x, s)] ≤ ui). In this work, we only use the affine form of the constraints. For an example, us</context>
<context position="30035" citStr="Chang et al., 2007" startWordPosition="4960" endWordPosition="4963"> a poor choice to solve this task as they require large amounts of labeled ads, which is expensive, time-consuming and noisy. Most semi-supervised methods also rely on some labeled data, and scale badly with the size of unlabeled data, which is intractable for most ad databases. Considerable research has been undertaken to exploit forms of domain knowledge other than labeled data to efficiently train a model while utilizing the unlabeled data. These include methods that express domain knowledge as constraints on features, which have shown to provide high accuracy on natural language datasets (Chang et al., 2007; Chang et al., 2008; Mann and McCallum, 2008; Bellare et al., 2009; Singh et al., 2010). We use the method of alternating projections for constraintdriven learning (Bellare et al., 2009) since it specifies constraints on feature expectations instead of less intuitive constraints on feature parameters (as in (Chang et al., 2008)). Additionally, the alternating projection method is computationally more efficient than Generalized Expectation (Mann and McCallum, 2008) and can be applied in an online fashion using stochastic gradient. Our approach is most similar to (Li et al., 2009), which uses s</context>
</contexts>
<marker>Chang, Ratinov, Roth, 2007</marker>
<rawString>Ming-Wei Chang, Lev Ratinov, and Dan Roth. 2007. Guiding semi-supervision with constraintdriven learning. In ACL: Annual meeting of the Association for Computational Linguistics, pages 280–287.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ming-Wei Chang</author>
<author>Lev Ratinov</author>
<author>Nicholas Rizzolo</author>
<author>Dan Roth</author>
</authors>
<title>Learning and inference with constraints.</title>
<date>2008</date>
<booktitle>In AAAI: National Conference on Artificial Intelligence,</booktitle>
<pages>1513--1518</pages>
<contexts>
<context position="30055" citStr="Chang et al., 2008" startWordPosition="4964" endWordPosition="4967">lve this task as they require large amounts of labeled ads, which is expensive, time-consuming and noisy. Most semi-supervised methods also rely on some labeled data, and scale badly with the size of unlabeled data, which is intractable for most ad databases. Considerable research has been undertaken to exploit forms of domain knowledge other than labeled data to efficiently train a model while utilizing the unlabeled data. These include methods that express domain knowledge as constraints on features, which have shown to provide high accuracy on natural language datasets (Chang et al., 2007; Chang et al., 2008; Mann and McCallum, 2008; Bellare et al., 2009; Singh et al., 2010). We use the method of alternating projections for constraintdriven learning (Bellare et al., 2009) since it specifies constraints on feature expectations instead of less intuitive constraints on feature parameters (as in (Chang et al., 2008)). Additionally, the alternating projection method is computationally more efficient than Generalized Expectation (Mann and McCallum, 2008) and can be applied in an online fashion using stochastic gradient. Our approach is most similar to (Li et al., 2009), which uses semi-supervised learn</context>
</contexts>
<marker>Chang, Ratinov, Rizzolo, Roth, 2008</marker>
<rawString>Ming-Wei Chang, Lev Ratinov, Nicholas Rizzolo, and Dan Roth. 2008. Learning and inference with constraints. In AAAI: National Conference on Artificial Intelligence, pages 1513–1518.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Chapelle</author>
<author>B Sch¨olkopf</author>
<author>A Zien</author>
<author>editors</author>
</authors>
<date>2006</date>
<booktitle>Semi-Supervised Learning (Adaptive Computation and Machine Learning). The</booktitle>
<publisher>MIT Press,</publisher>
<marker>Chapelle, Sch¨olkopf, Zien, editors, 2006</marker>
<rawString>O. Chapelle, B. Sch¨olkopf, and A. Zien, editors. 2006. Semi-Supervised Learning (Adaptive Computation and Machine Learning). The MIT Press, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimiliano Ciaramita</author>
<author>Vanessa Murdock</author>
<author>Vassilis Plachouras</author>
</authors>
<title>Online learning from click data for sponsored search.</title>
<date>2008</date>
<booktitle>In WWW: International World Wide Web Conference.</booktitle>
<contexts>
<context position="29162" citStr="Ciaramita et al., 2008" startWordPosition="4814" endWordPosition="4817">.329 / 0.412 0.271 / 0.325 0.286 / 0.342 non-OTHER Precision 0.136 / 0.163 0.265 / 0.333 0.297 / 0.357 0.392 / 0.469 F1-score 0.151 / 0.182 0.293 / 0.368 0.283 / 0.340 0.331 / 0.395 F2-score 0.162 / 0.195 0.313 / 0.393 0.276 / 0.331 0.303 / 0.361 7 Related Work Extraction of structured information from text is of interest to a large number of communities. However, in the ads domain, the task has usually been simplified to that of classification or ranking. Previous work has focused on retrieval (Raghavan and Iyer, 2008), user click prediction (Shaparenko et al., 2009; Richardson et al., 2007; Ciaramita et al., 2008), ad relevance (Hillard et al., 2010) and bounce rate prediction (Sculley et al., 2009). As far we know, our method is the only one that aims to solve a much more complex task of segmentation and entity extraction from ad creatives. Supervised methods are a poor choice to solve this task as they require large amounts of labeled ads, which is expensive, time-consuming and noisy. Most semi-supervised methods also rely on some labeled data, and scale badly with the size of unlabeled data, which is intractable for most ad databases. Considerable research has been undertaken to exploit forms of dom</context>
</contexts>
<marker>Ciaramita, Murdock, Plachouras, 2008</marker>
<rawString>Massimiliano Ciaramita, Vanessa Murdock, and Vassilis Plachouras. 2008. Online learning from click data for sponsored search. In WWW: International World Wide Web Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dustin Hillard</author>
<author>Stefan Schroedl</author>
<author>Eren Manavoglu</author>
<author>Hema Raghavan</author>
<author>Chris Leggetter</author>
</authors>
<title>Improving ad relevance in sponsored search.</title>
<date>2010</date>
<booktitle>In WSDM: International conference on Web search and data mining,</booktitle>
<pages>361--370</pages>
<contexts>
<context position="29199" citStr="Hillard et al., 2010" startWordPosition="4820" endWordPosition="4823">2 non-OTHER Precision 0.136 / 0.163 0.265 / 0.333 0.297 / 0.357 0.392 / 0.469 F1-score 0.151 / 0.182 0.293 / 0.368 0.283 / 0.340 0.331 / 0.395 F2-score 0.162 / 0.195 0.313 / 0.393 0.276 / 0.331 0.303 / 0.361 7 Related Work Extraction of structured information from text is of interest to a large number of communities. However, in the ads domain, the task has usually been simplified to that of classification or ranking. Previous work has focused on retrieval (Raghavan and Iyer, 2008), user click prediction (Shaparenko et al., 2009; Richardson et al., 2007; Ciaramita et al., 2008), ad relevance (Hillard et al., 2010) and bounce rate prediction (Sculley et al., 2009). As far we know, our method is the only one that aims to solve a much more complex task of segmentation and entity extraction from ad creatives. Supervised methods are a poor choice to solve this task as they require large amounts of labeled ads, which is expensive, time-consuming and noisy. Most semi-supervised methods also rely on some labeled data, and scale badly with the size of unlabeled data, which is intractable for most ad databases. Considerable research has been undertaken to exploit forms of domain knowledge other than labeled data</context>
</contexts>
<marker>Hillard, Schroedl, Manavoglu, Raghavan, Leggetter, 2010</marker>
<rawString>Dustin Hillard, Stefan Schroedl, Eren Manavoglu, Hema Raghavan, and Chris Leggetter. 2010. Improving ad relevance in sponsored search. In WSDM: International conference on Web search and data mining, pages 361–370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew Mccallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In</title>
<date>2001</date>
<booktitle>ICML: International Conference on Machine Learning,</booktitle>
<pages>282--289</pages>
<contexts>
<context position="7124" citStr="Lafferty et al., 2001" startWordPosition="1099" endWordPosition="1102">on in ad creatives as a semi-CRF, and describe the features in Section 4. The constraints that we use to inject supervision into our model are listed in Section 5. We demonstrate the success of our approach in Section 6. This work is compared with related literature in Section 7. 2 Background This section covers introductory material on the probabilistic representation of our model (semi-Markov conditional random fields) and the constraint-driven semi-supervised method that we use to inject supervision into the model. 2.1 Semi-Markov Conditional Random Fields Conditional Random Fields (CRFs) (Lafferty et al., 2001) use a Markov random field to model the conditional probability P(y|x). CRFs are commonly used to learn sequential models, where the Markov field is a linear-chain, and y is a linear sequence of labels and each label yi E Y. Let f be a vector of local feature functions f = (f1, ... , fK), each of which maps a pair (x, y) and an index i to a measurement fk(i, x, y) E R. Let f(i, x, y) be the vector of these measurements, and let F(x, y) = �|x| i f(i, x, y). CRFs use these feature functions in conjunction with the parameters 0 to represent the conditional probability as follows: P x, 1 eθ·F(x,Y)</context>
</contexts>
<marker>Lafferty, Mccallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew Mccallum, and Fernando Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In ICML: International Conference on Machine Learning, pages 282–289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiao Li</author>
<author>Ye-Yi Wang</author>
<author>Alex Acero</author>
</authors>
<title>Extracting structured information from user queries with semisupervised conditional random fields.</title>
<date>2009</date>
<booktitle>In SIGIR: International Conference on research and development in information retrieval,</booktitle>
<pages>572--579</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="21869" citStr="Li et al., 2009" startWordPosition="3630" endWordPosition="3633">examples on a small held-out data set. 5.1 Dictionary-Based Dictionary constraints are the form of constraints that apply to the feature between an individual token and its label. For a set of tokens in the dictionary, the constraints specify which label they are likely to be. Dictionaries can be easily constructed using various sources, for example product databases, lexicons, manual collections, or predictions from other models. These dictionary constraints are often used to bootstrap models (Agichtein and Ganti, 2004; Canisius and Sporleder, 2007) and have also been used in the ads domain (Li et al., 2009). For our application, we rely on dictionary constraints from two sources. First, the predictions of a previous model are used to construct a dictionary. A model for entity extraction is trained on a large amount of labeled search query data. The domain and style of web queries differs from advertisements, but the set of labels is essentially the same. The supervised query entity extraction model is used to infer segments and labels for the ads domain, and each of the predicted segments are added to the dictionary of the corresponding predicted label. Even though the predictions of the model a</context>
<context position="30621" citStr="Li et al., 2009" startWordPosition="5054" endWordPosition="5057">e datasets (Chang et al., 2007; Chang et al., 2008; Mann and McCallum, 2008; Bellare et al., 2009; Singh et al., 2010). We use the method of alternating projections for constraintdriven learning (Bellare et al., 2009) since it specifies constraints on feature expectations instead of less intuitive constraints on feature parameters (as in (Chang et al., 2008)). Additionally, the alternating projection method is computationally more efficient than Generalized Expectation (Mann and McCallum, 2008) and can be applied in an online fashion using stochastic gradient. Our approach is most similar to (Li et al., 2009), which uses semi-supervised learning for CRFs to extract structured information from user queries. They also use a constraint-driven method that utilizes an external data source. Their method, however, relies on labeled data for part of the supervision while our method uses only unlabeled data. Also, evaluation was only shown for a small domain of user queries, while our work does not restrict itself to any specific domain of ads for evaluation. 8 Conclusions Although important for a number of tasks in sponsored search, extraction of structured information from text advertisements is not a we</context>
</contexts>
<marker>Li, Wang, Acero, 2009</marker>
<rawString>Xiao Li, Ye-Yi Wang, and Alex Acero. 2009. Extracting structured information from user queries with semisupervised conditional random fields. In SIGIR: International Conference on research and development in information retrieval, pages 572–579. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gideon S Mann</author>
<author>Andrew McCallum</author>
</authors>
<title>Generalized expectation criteria for semi-supervised learning of conditional random fields.</title>
<date>2008</date>
<booktitle>In ACL: Annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>870--878</pages>
<contexts>
<context position="4339" citStr="Mann and McCallum, 2008" startWordPosition="654" endWordPosition="657">nd sparse labels, semi-supervised learning methHuman Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 73–81, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics ods utilize unlabeled data to improve the model (see (Chapelle et al., 2006) for an overview). Furthermore, recent work on constraint-based semisupervised learning allows domain experts to easily provide additional light supervision, enabling the learning algorithm to learn using the prior domain knowledge, labeled and unlabeled data (Chang et al., 2007; Mann and McCallum, 2008; Bellare et al., 2009; Singh et al., 2010). Prior domain knowledge, if it can be easily expressed and incorporated into the learning algorithm, can often be a high-quality and cheap substitute for labeled data. For example, previous work has often used dictionaries or lexicons (lists of phrases of a particular label) to bootstrap the model (Agichtein and Ganti, 2004; Canisius and Sporleder, 2007), leading to a partial labeling of the data. Domain knowledge can also be more probabilistic in nature, representing the probability of certain token taking on a certain label. For most tasks, labeled</context>
<context position="8995" citStr="Mann and McCallum, 2008" startWordPosition="1442" endWordPosition="1445"> pair (x, s) and an index j to a measurement gk(j, x, s) ∈ &lt;, and G(x, s) = P|s| j g(j, x, s). The conditional probability is represented as: P(s|x,B) = Z(x)eθ·G(x,s) 1 where Z(x) = Ps0 eθ·G(x,s0). To assert the Markovian assumption, each gk(j, x, s) only computes features based on x, sj, and yj−11. An exact inference algorithm was described in (Sarawagi and Cohen, 2004), and was later improved to be more efficient (Sarawagi, 2006). 2.2 Constraint Driven Learning Using Alternating Projections Recent work in semi-supervised learning uses constraints as external supervision (Chang et al., 2007; Mann and McCallum, 2008; Bellare et al., 2009; Singh et al., 2010). These external constraints are specified as constraints on the expectations of a set of auxiliary features g0 = {g01, ... , g0k} over the unlabeled data. In particular, given the targets u = {u1, ... , uk} corresponding to the auxiliary features g0, the constraints can take different forms, for example L2 penalty ( 1 2β kui−Pj Ep[g0i(xj, s)]k22 = 0), L1 box constraints (|ui − P j Ep[g0i(xj, s)] |≤ �) and Affine constraints2 (Ep[g0i(x, s)] ≤ ui). In this work, we only use the affine form of the constraints. For an example, using domain knowledge, we </context>
<context position="30080" citStr="Mann and McCallum, 2008" startWordPosition="4968" endWordPosition="4971">y require large amounts of labeled ads, which is expensive, time-consuming and noisy. Most semi-supervised methods also rely on some labeled data, and scale badly with the size of unlabeled data, which is intractable for most ad databases. Considerable research has been undertaken to exploit forms of domain knowledge other than labeled data to efficiently train a model while utilizing the unlabeled data. These include methods that express domain knowledge as constraints on features, which have shown to provide high accuracy on natural language datasets (Chang et al., 2007; Chang et al., 2008; Mann and McCallum, 2008; Bellare et al., 2009; Singh et al., 2010). We use the method of alternating projections for constraintdriven learning (Bellare et al., 2009) since it specifies constraints on feature expectations instead of less intuitive constraints on feature parameters (as in (Chang et al., 2008)). Additionally, the alternating projection method is computationally more efficient than Generalized Expectation (Mann and McCallum, 2008) and can be applied in an online fashion using stochastic gradient. Our approach is most similar to (Li et al., 2009), which uses semi-supervised learning for CRFs to extract s</context>
</contexts>
<marker>Mann, McCallum, 2008</marker>
<rawString>Gideon S. Mann and Andrew McCallum. 2008. Generalized expectation criteria for semi-supervised learning of conditional random fields. In ACL: Annual meeting of the Association for Computational Linguistics, pages 870–878.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew McCallum</author>
</authors>
<title>Mallet: A machine learning for language toolkit.</title>
<date>2002</date>
<note>http://mallet.cs.umass.edu.</note>
<contexts>
<context position="18962" citStr="McCallum, 2002" startWordPosition="3144" endWordPosition="3145">lly, we are not concerned with accurately specifying the exact domain of each ad, instead any information about similarity between ads according to their domains is helpful. This kind of representation can be obtained in an unsupervised fashion by using topic cluster models (Steyvers and Griffiths, 2007; Blei et al., 2003). Given a large set of unlabeled documents, topic models define a distribution of topics over each document, such that documents that are similar to each other have similar topic distributions. The LDA (Blei et al., 2003) implementation of topic models in the Mallet toolkit (McCallum, 2002) was used to construct a model with 1000 topics for a dataset containing 3 million ads. For each ad, the discrete distribution over the topics, in conjunction with each possible label, was added as a feature. This captures a potential for each label given an approximation of the ad’s domain captured as topics. 77 5 Constraints Constraints are used to inject light supervision into the learning algorithm and are defined as targets u for expectations of features G&apos; over the data. Any feature that can be included in the model can be used as a constraint. This allows us to capture a variety of diff</context>
</contexts>
<marker>McCallum, 2002</marker>
<rawString>Andrew McCallum. 2002. Mallet: A machine learning for language toolkit. http://mallet.cs.umass.edu.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ion Muslea</author>
</authors>
<title>Extraction patterns for information extraction tasks: A survey.</title>
<date>1999</date>
<booktitle>In AAAI: Workshop on Machine Learning for Information Extraction,</booktitle>
<pages>1--6</pages>
<contexts>
<context position="23323" citStr="Muslea, 1999" startWordPosition="3869" endWordPosition="3870"> external databases. Lists of various types of places can be obtained easily, for example CITY, COUNTRY, STATE, AIRPORT, etc. Additionally, product databases available internally to our research group are used for MANUFACTURERS, BRANDS, PRODUCTS, MEDIATITLE, etc. Some of these databases are noisy, and the constraints based on them are given lower target expectations. 5.2 Pattern-Based Prior knowledge can often be easily expressed as patterns that appear for a specific domain. Pattern based matching has been used to express supervision for information extraction tasks (Califf and Mooney, 1999; Muslea, 1999). The usual use case involves a domain expert specifying a number of “prototypical” patterns, while additional patterns are discovered based on these initial patterns. We incorporate noisy forms of patterns as constraints. Simple regular expression based patterns were used to identify and label segments for a few domains (e.g. “flights to {PLACE}” and “looking for {PRODUCT}?”). We do not employ a patterndiscovery algorithm for finding other contexts; the model propagates these labels, as before, using the 78 features of the rest of the model. However if the output of a pattern-discovery algori</context>
</contexts>
<marker>Muslea, 1999</marker>
<rawString>Ion Muslea. 1999. Extraction patterns for information extraction tasks: A survey. In AAAI: Workshop on Machine Learning for Information Extraction, pages 1–6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
</authors>
<title>Eric Crestan, Arkady Borkovsky, AnaMaria Popescu, and Vishnu Vyas.</title>
<date>2009</date>
<booktitle>In EMNLP: Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>938--947</pages>
<marker>Pantel, 2009</marker>
<rawString>Patrick Pantel, Eric Crestan, Arkady Borkovsky, AnaMaria Popescu, and Vishnu Vyas. 2009. Web-scale distributional similarity and entity set expansion. In EMNLP: Conference on Empirical Methods in Natural Language Processing, pages 938–947.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hema Raghavan</author>
<author>Rukmini Iyer</author>
</authors>
<title>Evaluating vector-space and probabilistic models for query to ad matching.</title>
<date>2008</date>
<booktitle>In SIGIR Workshop on Information Retrieval in Advertising (IRA).</booktitle>
<contexts>
<context position="29064" citStr="Raghavan and Iyer, 2008" startWordPosition="4799" endWordPosition="4802">l Accuracy 0.454 / 0.466 0.596 / 0.627 0.629 / 0.649 0.665 / 0.685 non-OTHER Recall 0.170 / 0.205 0.329 / 0.412 0.271 / 0.325 0.286 / 0.342 non-OTHER Precision 0.136 / 0.163 0.265 / 0.333 0.297 / 0.357 0.392 / 0.469 F1-score 0.151 / 0.182 0.293 / 0.368 0.283 / 0.340 0.331 / 0.395 F2-score 0.162 / 0.195 0.313 / 0.393 0.276 / 0.331 0.303 / 0.361 7 Related Work Extraction of structured information from text is of interest to a large number of communities. However, in the ads domain, the task has usually been simplified to that of classification or ranking. Previous work has focused on retrieval (Raghavan and Iyer, 2008), user click prediction (Shaparenko et al., 2009; Richardson et al., 2007; Ciaramita et al., 2008), ad relevance (Hillard et al., 2010) and bounce rate prediction (Sculley et al., 2009). As far we know, our method is the only one that aims to solve a much more complex task of segmentation and entity extraction from ad creatives. Supervised methods are a poor choice to solve this task as they require large amounts of labeled ads, which is expensive, time-consuming and noisy. Most semi-supervised methods also rely on some labeled data, and scale badly with the size of unlabeled data, which is in</context>
</contexts>
<marker>Raghavan, Iyer, 2008</marker>
<rawString>Hema Raghavan and Rukmini Iyer. 2008. Evaluating vector-space and probabilistic models for query to ad matching. In SIGIR Workshop on Information Retrieval in Advertising (IRA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Richardson</author>
<author>Ewa Dominowska</author>
<author>Robert Ragno</author>
</authors>
<title>Predicting clicks: estimating the clickthrough rate for new ads.</title>
<date>2007</date>
<booktitle>In WWW: International World Wide Web Conference.</booktitle>
<contexts>
<context position="29137" citStr="Richardson et al., 2007" startWordPosition="4810" endWordPosition="4813">ER Recall 0.170 / 0.205 0.329 / 0.412 0.271 / 0.325 0.286 / 0.342 non-OTHER Precision 0.136 / 0.163 0.265 / 0.333 0.297 / 0.357 0.392 / 0.469 F1-score 0.151 / 0.182 0.293 / 0.368 0.283 / 0.340 0.331 / 0.395 F2-score 0.162 / 0.195 0.313 / 0.393 0.276 / 0.331 0.303 / 0.361 7 Related Work Extraction of structured information from text is of interest to a large number of communities. However, in the ads domain, the task has usually been simplified to that of classification or ranking. Previous work has focused on retrieval (Raghavan and Iyer, 2008), user click prediction (Shaparenko et al., 2009; Richardson et al., 2007; Ciaramita et al., 2008), ad relevance (Hillard et al., 2010) and bounce rate prediction (Sculley et al., 2009). As far we know, our method is the only one that aims to solve a much more complex task of segmentation and entity extraction from ad creatives. Supervised methods are a poor choice to solve this task as they require large amounts of labeled ads, which is expensive, time-consuming and noisy. Most semi-supervised methods also rely on some labeled data, and scale badly with the size of unlabeled data, which is intractable for most ad databases. Considerable research has been undertake</context>
</contexts>
<marker>Richardson, Dominowska, Ragno, 2007</marker>
<rawString>Matthew Richardson, Ewa Dominowska, and Robert Ragno. 2007. Predicting clicks: estimating the clickthrough rate for new ads. In WWW: International World Wide Web Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sunita Sarawagi</author>
<author>William W Cohen</author>
</authors>
<title>Semimarkov conditional random fields for information extraction.</title>
<date>2004</date>
<booktitle>In NIPS: Neural Information Processing Systems.</booktitle>
<contexts>
<context position="8078" citStr="Sarawagi and Cohen, 2004" startWordPosition="1273" endWordPosition="1276"> index i to a measurement fk(i, x, y) E R. Let f(i, x, y) be the vector of these measurements, and let F(x, y) = �|x| i f(i, x, y). CRFs use these feature functions in conjunction with the parameters 0 to represent the conditional probability as follows: P x, 1 eθ·F(x,Y) (Y�B ) = Z(x) where Z(x) = EY, eθ·F(x,Y&apos;). For sequential models where the same labels appear within a sequence as contiguous blocks (e.g., named entity recognition) it is more convenient to represent these blocks directly as segments. This representation was formulated as semi-Markov conditional random fields (Semi-CRFs) in (Sarawagi and Cohen, 2004). The segmentation of a sequence is represented by s = (s1, ... , sp) where each segment sj = (tj, uj, yj) consists of a start position tj, an end position uj, and a label yj E Y. Similar to the CRF, let g be the vector of segment feature 74 functions g = hg1, ... , gKi, each of which maps the pair (x, s) and an index j to a measurement gk(j, x, s) ∈ &lt;, and G(x, s) = P|s| j g(j, x, s). The conditional probability is represented as: P(s|x,B) = Z(x)eθ·G(x,s) 1 where Z(x) = Ps0 eθ·G(x,s0). To assert the Markovian assumption, each gk(j, x, s) only computes features based on x, sj, and yj−11. An ex</context>
</contexts>
<marker>Sarawagi, Cohen, 2004</marker>
<rawString>Sunita Sarawagi and William W. Cohen. 2004. Semimarkov conditional random fields for information extraction. In NIPS: Neural Information Processing Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sunita Sarawagi</author>
</authors>
<title>Efficient inference on sequence segmentation models.</title>
<date>2006</date>
<booktitle>In ICML: International Conference on Machine Learning,</booktitle>
<pages>793--800</pages>
<contexts>
<context position="8807" citStr="Sarawagi, 2006" startWordPosition="1419" endWordPosition="1420">s of a start position tj, an end position uj, and a label yj E Y. Similar to the CRF, let g be the vector of segment feature 74 functions g = hg1, ... , gKi, each of which maps the pair (x, s) and an index j to a measurement gk(j, x, s) ∈ &lt;, and G(x, s) = P|s| j g(j, x, s). The conditional probability is represented as: P(s|x,B) = Z(x)eθ·G(x,s) 1 where Z(x) = Ps0 eθ·G(x,s0). To assert the Markovian assumption, each gk(j, x, s) only computes features based on x, sj, and yj−11. An exact inference algorithm was described in (Sarawagi and Cohen, 2004), and was later improved to be more efficient (Sarawagi, 2006). 2.2 Constraint Driven Learning Using Alternating Projections Recent work in semi-supervised learning uses constraints as external supervision (Chang et al., 2007; Mann and McCallum, 2008; Bellare et al., 2009; Singh et al., 2010). These external constraints are specified as constraints on the expectations of a set of auxiliary features g0 = {g01, ... , g0k} over the unlabeled data. In particular, given the targets u = {u1, ... , uk} corresponding to the auxiliary features g0, the constraints can take different forms, for example L2 penalty ( 1 2β kui−Pj Ep[g0i(xj, s)]k22 = 0), L1 box constra</context>
</contexts>
<marker>Sarawagi, 2006</marker>
<rawString>Sunita Sarawagi. 2006. Efficient inference on sequence segmentation models. In ICML: International Conference on Machine Learning, pages 793–800.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Sculley</author>
<author>Robert G Malkin</author>
<author>Sugato Basu</author>
<author>Roberto J Bayardo</author>
</authors>
<title>Predicting bounce rates in sponsored search advertisements.</title>
<date>2009</date>
<booktitle>In KDD: ACM SIGKDD International Conference on Knowledge Discovery and Data mining,</booktitle>
<pages>1325--1334</pages>
<contexts>
<context position="29249" citStr="Sculley et al., 2009" startWordPosition="4828" endWordPosition="4831">0.297 / 0.357 0.392 / 0.469 F1-score 0.151 / 0.182 0.293 / 0.368 0.283 / 0.340 0.331 / 0.395 F2-score 0.162 / 0.195 0.313 / 0.393 0.276 / 0.331 0.303 / 0.361 7 Related Work Extraction of structured information from text is of interest to a large number of communities. However, in the ads domain, the task has usually been simplified to that of classification or ranking. Previous work has focused on retrieval (Raghavan and Iyer, 2008), user click prediction (Shaparenko et al., 2009; Richardson et al., 2007; Ciaramita et al., 2008), ad relevance (Hillard et al., 2010) and bounce rate prediction (Sculley et al., 2009). As far we know, our method is the only one that aims to solve a much more complex task of segmentation and entity extraction from ad creatives. Supervised methods are a poor choice to solve this task as they require large amounts of labeled ads, which is expensive, time-consuming and noisy. Most semi-supervised methods also rely on some labeled data, and scale badly with the size of unlabeled data, which is intractable for most ad databases. Considerable research has been undertaken to exploit forms of domain knowledge other than labeled data to efficiently train a model while utilizing the </context>
</contexts>
<marker>Sculley, Malkin, Basu, Bayardo, 2009</marker>
<rawString>D. Sculley, Robert G. Malkin, Sugato Basu, and Roberto J. Bayardo. 2009. Predicting bounce rates in sponsored search advertisements. In KDD: ACM SIGKDD International Conference on Knowledge Discovery and Data mining, pages 1325–1334.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benyah Shaparenko</author>
<author>Ozgur Cetin</author>
<author>Rukmini Iyer</author>
</authors>
<title>Data driven text features for sponsored search click prediction. In AdKDD: Workshop on Data mining and audience intelligence for advertising.</title>
<date>2009</date>
<contexts>
<context position="29112" citStr="Shaparenko et al., 2009" startWordPosition="4806" endWordPosition="4809">649 0.665 / 0.685 non-OTHER Recall 0.170 / 0.205 0.329 / 0.412 0.271 / 0.325 0.286 / 0.342 non-OTHER Precision 0.136 / 0.163 0.265 / 0.333 0.297 / 0.357 0.392 / 0.469 F1-score 0.151 / 0.182 0.293 / 0.368 0.283 / 0.340 0.331 / 0.395 F2-score 0.162 / 0.195 0.313 / 0.393 0.276 / 0.331 0.303 / 0.361 7 Related Work Extraction of structured information from text is of interest to a large number of communities. However, in the ads domain, the task has usually been simplified to that of classification or ranking. Previous work has focused on retrieval (Raghavan and Iyer, 2008), user click prediction (Shaparenko et al., 2009; Richardson et al., 2007; Ciaramita et al., 2008), ad relevance (Hillard et al., 2010) and bounce rate prediction (Sculley et al., 2009). As far we know, our method is the only one that aims to solve a much more complex task of segmentation and entity extraction from ad creatives. Supervised methods are a poor choice to solve this task as they require large amounts of labeled ads, which is expensive, time-consuming and noisy. Most semi-supervised methods also rely on some labeled data, and scale badly with the size of unlabeled data, which is intractable for most ad databases. Considerable re</context>
</contexts>
<marker>Shaparenko, Cetin, Iyer, 2009</marker>
<rawString>Benyah Shaparenko, Ozgur Cetin, and Rukmini Iyer. 2009. Data driven text features for sponsored search click prediction. In AdKDD: Workshop on Data mining and audience intelligence for advertising.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Singh</author>
<author>Limin Yao</author>
<author>Sebastian Riedel</author>
<author>Andrew McCallum</author>
</authors>
<title>Constraint-driven rank-based learning for information extraction.</title>
<date>2010</date>
<booktitle>In North American Chapter of the Association for Computational Linguistics - Human Language Technologies (NAACL HLT).</booktitle>
<contexts>
<context position="4382" citStr="Singh et al., 2010" startWordPosition="662" endWordPosition="665">Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 73–81, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics ods utilize unlabeled data to improve the model (see (Chapelle et al., 2006) for an overview). Furthermore, recent work on constraint-based semisupervised learning allows domain experts to easily provide additional light supervision, enabling the learning algorithm to learn using the prior domain knowledge, labeled and unlabeled data (Chang et al., 2007; Mann and McCallum, 2008; Bellare et al., 2009; Singh et al., 2010). Prior domain knowledge, if it can be easily expressed and incorporated into the learning algorithm, can often be a high-quality and cheap substitute for labeled data. For example, previous work has often used dictionaries or lexicons (lists of phrases of a particular label) to bootstrap the model (Agichtein and Ganti, 2004; Canisius and Sporleder, 2007), leading to a partial labeling of the data. Domain knowledge can also be more probabilistic in nature, representing the probability of certain token taking on a certain label. For most tasks, labeled data is a convenient representation of the</context>
<context position="9038" citStr="Singh et al., 2010" startWordPosition="1450" endWordPosition="1453">(j, x, s) ∈ &lt;, and G(x, s) = P|s| j g(j, x, s). The conditional probability is represented as: P(s|x,B) = Z(x)eθ·G(x,s) 1 where Z(x) = Ps0 eθ·G(x,s0). To assert the Markovian assumption, each gk(j, x, s) only computes features based on x, sj, and yj−11. An exact inference algorithm was described in (Sarawagi and Cohen, 2004), and was later improved to be more efficient (Sarawagi, 2006). 2.2 Constraint Driven Learning Using Alternating Projections Recent work in semi-supervised learning uses constraints as external supervision (Chang et al., 2007; Mann and McCallum, 2008; Bellare et al., 2009; Singh et al., 2010). These external constraints are specified as constraints on the expectations of a set of auxiliary features g0 = {g01, ... , g0k} over the unlabeled data. In particular, given the targets u = {u1, ... , uk} corresponding to the auxiliary features g0, the constraints can take different forms, for example L2 penalty ( 1 2β kui−Pj Ep[g0i(xj, s)]k22 = 0), L1 box constraints (|ui − P j Ep[g0i(xj, s)] |≤ �) and Affine constraints2 (Ep[g0i(x, s)] ≤ ui). In this work, we only use the affine form of the constraints. For an example, using domain knowledge, we may know that token “arizona” should get th</context>
<context position="30123" citStr="Singh et al., 2010" startWordPosition="4976" endWordPosition="4979">s expensive, time-consuming and noisy. Most semi-supervised methods also rely on some labeled data, and scale badly with the size of unlabeled data, which is intractable for most ad databases. Considerable research has been undertaken to exploit forms of domain knowledge other than labeled data to efficiently train a model while utilizing the unlabeled data. These include methods that express domain knowledge as constraints on features, which have shown to provide high accuracy on natural language datasets (Chang et al., 2007; Chang et al., 2008; Mann and McCallum, 2008; Bellare et al., 2009; Singh et al., 2010). We use the method of alternating projections for constraintdriven learning (Bellare et al., 2009) since it specifies constraints on feature expectations instead of less intuitive constraints on feature parameters (as in (Chang et al., 2008)). Additionally, the alternating projection method is computationally more efficient than Generalized Expectation (Mann and McCallum, 2008) and can be applied in an online fashion using stochastic gradient. Our approach is most similar to (Li et al., 2009), which uses semi-supervised learning for CRFs to extract structured information from user queries. Th</context>
</contexts>
<marker>Singh, Yao, Riedel, McCallum, 2010</marker>
<rawString>Sameer Singh, Limin Yao, Sebastian Riedel, and Andrew McCallum. 2010. Constraint-driven rank-based learning for information extraction. In North American Chapter of the Association for Computational Linguistics - Human Language Technologies (NAACL HLT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steyvers</author>
<author>Tom Griffiths</author>
</authors>
<title>Probabilistic Topic Models. Lawrence Erlbaum Associates.</title>
<date>2007</date>
<contexts>
<context position="18651" citStr="Steyvers and Griffiths, 2007" startWordPosition="3092" endWordPosition="3095">bsite from just the features in the model, however given that the domain of the ad is travel (or conversely, electronics), the choice becomes easier. The problem of domain identification is often posed as a document classification task, which requires labeled data to train and thus is not applicable for our task. Additionally, we are not concerned with accurately specifying the exact domain of each ad, instead any information about similarity between ads according to their domains is helpful. This kind of representation can be obtained in an unsupervised fashion by using topic cluster models (Steyvers and Griffiths, 2007; Blei et al., 2003). Given a large set of unlabeled documents, topic models define a distribution of topics over each document, such that documents that are similar to each other have similar topic distributions. The LDA (Blei et al., 2003) implementation of topic models in the Mallet toolkit (McCallum, 2002) was used to construct a model with 1000 topics for a dataset containing 3 million ads. For each ad, the discrete distribution over the topics, in conjunction with each possible label, was added as a feature. This captures a potential for each label given an approximation of the ad’s doma</context>
</contexts>
<marker>Steyvers, Griffiths, 2007</marker>
<rawString>Mark Steyvers and Tom Griffiths. 2007. Probabilistic Topic Models. Lawrence Erlbaum Associates.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>