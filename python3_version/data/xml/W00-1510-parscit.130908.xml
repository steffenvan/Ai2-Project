<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000230">
<title confidence="0.457014">
Diamod - a Tool for Modeling Dialogue Applications
Anke Kolzer
Speech Understanding Systems (FT3/AV)
DaimlerChrysler AG — Research and Technology
</title>
<address confidence="0.831627">
P.O.Box 2360
D-89013 Ulm (Germany)
</address>
<email confidence="0.987617">
e—mail: anke.koelzerAdaimlerchryslencom
</email>
<sectionHeader confidence="0.995412" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.970030486486486">
Speech dialogue systems are currently becom-
ing state—of—the—art for different kinds of ap-
plications, but they are still weak in the sup-
port of spontaneous speech and correct inter-
pretation of what was said. One reason for
the lack of good interactive dialogue systems is
their complexity. To develop a system which is
able to handle more than simple commands and
phrases requires a lot of experience and time.
To be able to accelerate and improve this pro-
cess we are currently working on methods and
tools which support this development. A new
method called Dialogue Statecharts was defined
for the graphical specification of complex dia-
logues. It is capable of representing parallel di-
alogue steps which is e.g. necessary for mixed—
initiative dialogues. Our tool system named
Diamod provides editors for different dialogue
concepts, such as dialogue structures, grammars
and parameters. The modeling is supported by
graphical editors for Dialogue Statecharts and
Task Hierarchies. Diamod is able to check
for the completeness and consistency of dia-
logue models. One goal when developing Di-
amod was to provide specification models which
are universal enough to be interpreted within
different dialogue systems, i.e. different imple-
mentations of generic conversational systems.&apos;
With the help of a uniform representation of
data a transformation between different mod-
els and different dialogue description languages
(DDL) such as VoiceXML (AT&amp;T et al., 2000)
and some in—house—DDLs, such as Temic—DDL
and Dialogue-Prolog, will be possible.
1-By this we mean systems which are implemented
application independently and are easily adapted to dif-
ferent applications.
</bodyText>
<sectionHeader confidence="0.994673" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999802380952381">
You find different dialogue system approaches
on the market place and in research. One has
been developed by the DaimlerChrysler research
and is able to understand spontaneous speech
speaker—independently and carry on dialogues
on special topics. The structure and algorithms
used are based on concepts developed in the
Sundial project (Peckham, 1993). Most applica-
tions are made for telephony domains. Thus, up
to now we gathered experience in applications
like train time—table information, call centers
for insurances and telematic systems for traf-
fic data (see (Brietzmann et al., 1994), (Heis-
terkamp and McGlashan, 1996), (Ehrlich et al.,
1997), (Boros et al., 1998) for further informa-
tion).
We made the experience that developing new
applications is very expensive concerning time
and staff and needed tools to accelerate the
process. Another goal was to make dialogue
application modeling possible even for non—
experts and help the expert to achieve consis-
tent reusable applications. As there are dif-
ferent dialogue systems all over the world and
many steps of application development are sim-
ilar or even the same for all of them we de-
cided to create tools which are system indepen-
dent resp. easily adaptable to different needs
and different dialogue systems. Our focus was
on modeling dialogue structure for information—
extracting resp. —processing systems of the slot—
filling kind (Bilange, 1991).
In order to find out what functionality a tool
must provide to be helpful we analyzed the way
we construct dialogue applications and the dif-
ferent knowledge bases that are needed. Similar
operation steps have to be executed for every
new application in order to obtain a structured
and maintainable dialogue. Typical tasks are:
modeling of the dialogue structure: i.e. di-
vide the dialogue into subdialogues to han-
dle a special part of the interaction like the
identification of a caller
definition of the application parameters,
i.e. the parameters necessary to give infor-
mation to the caller or access a database
like the name of the caller
attachment of system prompts to dialogue
situations like what the system has to say
when asking the name of the caller
definition of the appropriate vocabulary
(pronunciation) and training of the lan-
guage models
definition of linguistic structures (lexicon,
grammar, semantics)
definition of the interface to the application
system (e.g. an SQL—interface to a data
base)
Diamod supports the specification of all of
these dialogue application concepts (some are
still under construction) and generates code
which is interpreted by the target dialogue sys-
tem.
</bodyText>
<sectionHeader confidence="0.969438" genericHeader="introduction">
2 Requirements
</sectionHeader>
<bodyText confidence="0.998685891891892">
Dialogue systems which allow for spontaneous
speech are much more difficult to handle than
those which are only capable of processing sin-
gle commands. Diamod has to support dif-
ferent ways of modeling dialogue structure and
to transform one into another regarding special
consistency requirements.
Thus the knowledge — i.e. the dialogue con-
cepts — has to be represented in a universal way
so that different aspects of dialogue can be mod-
eled and code for different dialogue systems can
be generated. A transformation from a sponta-
neous speech dialogue model to a rather restric-
tive command—and—control one and vice versa
should be possible or a transformation from a
state—based dialogue flow model to a rule—based
one which is organized in tasks (as will be de-
scribed in section 3.1). The approach must be
extensible with little effort for specifying the ad-
ditional knowledge bases, necessary for conver-
sational systems, such as grammar models.
All the concepts necessary for dialogue flow
modeling are to be integrated in the dialogue
flow tool. Thus the dialogue flow tool must pro-
vide concepts such as application parameters,
system prompts, state and task modeling. The
state logic has to be described in a rather ab-
stract way so that an automatic transformation
for different dialogue systems is possible. There-
fore it is not sufficient to use the widely em-
ployed state machines with which the specialties
of spontaneous speech cannot be described ade-
quately. Instead we use a design method based
on Hare&apos;s statecharts (Hard, 1987) which are
capable of describing concurrency and provide
special event mechanisms and called it Dialogue
Statecharts.
</bodyText>
<subsectionHeader confidence="0.986161">
2.1 Properties of Diamod
</subsectionHeader>
<bodyText confidence="0.999693125">
Diamod is a CASE—tool (Computer Aided Soft-
ware Engineering) specialized for language en-
gineering which provides the concepts necessary
for dialogue specification. To be able to develop
new and modify old knowledge bases easily, the
tool supports the language engineer with the
following functionality:
Graphical editors for visual languages such
as Dialogue Statecharts for the specifica-
tion of structured dialogue data. The
graphical interface shall enable the user to
specify his models in a rather easy and in-
tuitive way.
Data representation of all relevant informa-
tion and the dependences between them.
Consistency checking by a formalism for
defining constraints on the models and in-
forming the user of violations of these con-
straints.
Code—generation (Prolog, VoiceXML, stan-
dardized speech API—code, ... ) that can
be interpreted by the currently preferred
generic dialogue system.
Reuse support of formerly developed appli-
cation models.
Two-phase modeling in order to be able to
specify generic data independently of ap-
plication specific data.
Easy adaptability to further dialogue sys-
tems and needs.
The principles of working with Diamod are
described in the following sections.
</bodyText>
<sectionHeader confidence="0.91076" genericHeader="method">
3 The Tool System Diamod
</sectionHeader>
<bodyText confidence="0.999819058823529">
Figure 1 shows the workflow in Diamod. The
central unit is the tool system which provides
methods for specifying knowledge, keeps the
data and models, and does consistency checks.
The user modifies the models with the help of a
graphical user interface. A second possibility in
future editions will be a textual interface for off—
line specification where the user can model the
dialogue with the help of a dialogue description
language. The tool system represents data in
a uniform graph representation and is able to
generate code in different dialogue description
languages such as Prolog2 or VoiceXML depen-
dent on the generic dialogue system currently
in use. This code output (commonly spoken
textual files) is read and interpreted by the cor-
responding generic dialogue system at runtime.
</bodyText>
<subsectionHeader confidence="0.983259">
3.1 Dialogue flow models
</subsectionHeader>
<bodyText confidence="0.98704276">
With Diamod the application developer models
what the system has to do in a given situation.
As this must work for different generic dialogue
systems, Diamod must also consider the generic
features of the system (because they can be dif-
ferent for different dialogue systems). Therefore
a two—phase approach is supported where in the
first phase a dialogue expert (usually the devel-
oper of the generic dialogue system) models ap-
plication independent data. In a second phase
an application developer models application de-
pendent data using the data which was modeled
by the expert (Kolzer, 1999).
Another feature of Diamod is the support
of different dialogue structure models. Our re-
search system is a rule—based system (Ehrlich,
1999) which can be modeled in Diamod using
tasks and task—hierarchy—diagrams. A rather
state—based system can be modeled using the
Dialogue—Statecharts—editor.
The following listing sums up the most impor-
tant steps which have to be done by the appli-
cation developer in order to specify the dialogue
flow of a new application:
— definition of the components of the dia-
logue; e.g. a subdialogue for handling the
2A predefined sublanguage of Prolog is used to model
applications for the DaimlerChrysler research system.
identification of the caller and finding out
why he calls, a subdialogue for reservation
of a ticket, and one for callers who only
want information.
definition of the dialogue structure i.e.
what the system has to handle first and
what comes next. This is done by defin-
ing a start dialogue and the successors of
each dialogue.
attachment of application parameters to
the dialogues; e.g. in the identification dia-
logue the system must request the caller&apos;s
name and password.
attachment of system prompts to the states
where the system has to say something such
as confirm the parameter &amp;quot;Source&amp;quot; in the
reservation dialogue.
The following sections describe how Diamod
supports the modeling for different approaches.
With Diamod the user can model every concept
by entering a name, a comment and information
on the specific structure of the concept.
</bodyText>
<subsubsectionHeader confidence="0.565917">
3.1.1 Task—Based Approach
</subsubsectionHeader>
<bodyText confidence="0.99997896">
The DaimlerChrysler research system is orga-
nized in tasks. Every task represents a sub-
dialogue, e.g. a caller identification or a hotel
reservation. The task structure is organized in
a task hierarchy as shown in figure 2, which
can be modeled with Diamod using the task—
hierarchy—editor. At runtime the dialogue sys-
tem can only activate the direct daughter— or
mother—task of a currently active task in this
hierarchy. This is used to make dialogue han-
dling easier and more consistent. It is not nec-
essary to model exactly the system states and
their sequence as it often has to be done for
other dialogue systems. The dialogue system
uses a set of dialogue acts (Gazdar, 1981), (Heis-
terkamp et al., 1992) such as confirm, request
and inform in order to distinguish between dif-
ferent dialogue situations. Every task has differ-
ent application concepts attached to it. Among
others these are:
Task (application) parameters: These are
the concepts which model what values must
be found out in order to reach the goals
of the task, e.g. to be able to make a
database access. This is usually what you
</bodyText>
<figure confidence="0.997569">
Dialogue
User Interface
Representation
GUI
Textual
off-line
interface
Task 1
Identify
Task 2
Topic
Start
Tool System
Uniform
graph
representation
Consistency
checks
Methods
Models
.....
Code
Generation
Language
1
Language
n
Generic
Dialogue
System
System 1
System n
Task 3
Reservation
Task 4
Information
</figure>
<bodyText confidence="0.998740734693877">
prompt is an example for confirming (dia-
logue act confirm) a task parameter name.
Diamod is able to check if a used param-
eter value reference is feasible. This is the
case when the appropriate task parameter
was declared for this task. Prompts can be
entered for different languages and Diamod
can check if there is a prompt for every sit-
uation in every language. Figure 4 shows
the prompt table mask of Diamod.
The prompt table can be calculated auto-
matically. I.e. all combinations of dialogue
acts and application parameter values are
generated in order to gain all those system
states, where a system prompt is needed.
The result of such a generation is shown in
figure 4. The user only has to fill in the
prompts or delete table entries which are
not needed.
Language models, grammars and lexicons:
They can be declared for a task in order to
switch between different ones and improve
speech recognition this way. This is still
under development (see section 4.1).
Actions: The application developer can model
typed actions which should be performed
on entering, resp. exiting the task. They
can be related to task parameters using Di-
amod—masks which offer the user a list of
accessable parameters and functions.
The transitions between tasks are realized us-
ing rules and conditions which are generic. This
means that they are implemented in the dia-
logue system and do not have to be modeled
by the application developer. Such a rule is
for example that a task can only be exited suc-
cessfully if all obligatory task parameters are
known. In order to determine the next task to
be activated the user&apos;s utterance is interpreted,
like if he wants a hotel reservation. This to-
gether with preconditions for entering possible
successor tasks is considered to control the dia-
logue flow.
When the developer has finished the specifi-
cation he or she starts the code generation. The
code produced can then be interpreted by the
dialogue system. For our research system this
is Prolog—code specifying the application knowl-
edge bases.
</bodyText>
<figureCaption confidence="0.582859">
Figure 3: A mask for the description of a di-
</figureCaption>
<bodyText confidence="0.989976222222222">
alogue for the DaimlerChrysler research sys-
tem. In some dialogue systems parameters can
have attributes like if they are obligatory or op-
tional. Therefore the masks have to be con-
figured for the dialogue system. Clicking the
button Generate Prompt Table will generate
the possible prompts. Clicking the button Edit
Prompt Table will open the mask shown in fig-
ure 4.
</bodyText>
<subsubsectionHeader confidence="0.595326">
3.1.2 State—Based Approach
</subsubsectionHeader>
<bodyText confidence="0.999948470588235">
Many dialogue systems use a state based ap-
proach where dialogue flow is described in
detail using state—transition—models combined
with events (Failenschmid and Thornton, 1998),
(Cole, 1999). Simple state—transition—models
are adequate for very simple dialogue systems
such as command—and—control systems.3 As
conversational systems have a high complexity
of states, the expressiveness of state—transition—
models is too small to be a good means for di-
alogue flow modeling. The number of states is
usually too big to be handled by a human.
A good alternative for complex state model-
ing are statecharts as described by Harel (1987).
They provide different means of abstraction
such as concurrent states, state refinement, spe-
cial event handling and action triggers.
</bodyText>
<footnote confidence="0.727881666666667">
3These are systems where a speaker may only say spe-
cial commands like &amp;quot;radio louder&amp;quot; and not speak spon-
taneously.
</footnote>
<figure confidence="0.99945805">
Edit Task
Related steer
parameters:
I Identify&apos;
General data
Name:
System ID: 120
Documentation:
Expert
Task—specific data
Parameter&apos; Optional Secret Inform&amp;quot; In..
Related tas password Optional Not secret Inform Infer 11H
parameters name Optional Not secret Inform Inter
Parameter
Generate Prompt Table Edit Prompt Table
OK
Apply el
DoDialogue
Identify
[not successful]
[continuation]
[successful]
PossibleTopics
[topic=reservation]
Topic
[topic=information]
Reservation
Information
[no continuation]
End
exit action:
close_down
HandleParams
HandleDepart
[contains(Utter,
DepartCity)]
[contains(Utter,
DepartTime)]
[contains(Utter,
DestCity)]
RequestDepart
entry action:
prompt(&amp;quot;Where do you
want to start?&amp;quot;)
HandleTime
HandleDest
HandleDepart
[no valid source found]
[valid source found]
exit action:
get_user_utterance()
HandleProblem
ConfirmDepart
entry action:
prompt(&amp;quot;You want to
start from &lt;source_par&gt;?&amp;quot;)
exit action:
get_user_utterance()
[confirmation negative]
[confirmation positive]
</figure>
<footnote confidence="0.338596">
3.1.3 Rule—based approach
</footnote>
<bodyText confidence="0.99868765">
Advanced dialogue systems are often not mod-
eled using states and transitions but rules and
conditions. Diamod can support this, too, as
states can be used as abstract dialogue units.
Thus states can represent subdialogues and di-
alogue steps. Every state can be modeled by
a set of preconditions which indicate when the
state may be entered and postconditions which
represent when the state can be exited success-
fully. Rules can be specified to model how the
next state to be activated has to be selected.
There is a default order on the states which sup-
ports this selection. Some of these concepts are
used for the application modeling of the Daim-
lerChrysler research dialogue system.
The benefits of Diamod in this context has
not been investigated yet as one needs a well de-
fined dialogue description language as interface
to such a rule—based dialogue system.5 Thus
this is work for the future.
</bodyText>
<subsubsectionHeader confidence="0.594854">
3.1.4 Concistency checking
</subsubsectionHeader>
<bodyText confidence="0.999650952380953">
An important point is that the tool is capable
of checking the completeness of the models and
their consistency. This is done using an object—
oriented graph structure which represents all re-
quired concepts and the dependences between
them. Consistency checks can be executed by
formulating constraints on the graph using path
expressions and having them examined by a spe-
cial path interpreter (Ebert et al., 1996). Thus,
it is possible to guarantee that for example
— there are no problematic cycles in the
model
there is a system prompt defined for every
system initiative state (i.e. states where
the system has to speak an utterance) and
every parameter, so that the system never
runs in a situation where it is &apos;speechless&apos;.
— domains are defined properly for all param-
eters
— there is a following state in every situation
(or the end of the dialogue)
</bodyText>
<sectionHeader confidence="0.937637" genericHeader="method">
4 Summary
</sectionHeader>
<bodyText confidence="0.955521590909091">
The paper introduces the tool system Diamod
which implements a universal approach for the
5This would be a quite interesting project and we
would be grateful for suggestions of collaboration here.
specification of dialogue applications with a fo-
cus on task—oriented dialogue systems of the
slot—filling kind. The tool system supports dia-
logue flow modeling in terms of tasks and states
which can be specified in detail by describing
parameters, actions, prompts and other typical
concepts of dialogue models. The most impor-
tant features of Diamod are
a uniform knowledge representation which
allows for automatic transformation of data
for different generic dialogue systems
the possibility of modeling different aspects
of dialogue with different views on the data
the capability of checking the consistency
of the models automatically
the support of the reuse of models
the easy adaptability to additional knowl-
edge bases and different dialogue systems.
</bodyText>
<subsectionHeader confidence="0.994931">
4.1 State of work — technical realization
</subsectionHeader>
<bodyText confidence="0.998748340425532">
The task and statechart modeling are com-
pletely implemented as described in section 3.
The following summary gives an overview over
what Diamod contains up to now:
task structure modeling as shown in figure
2
Dialogue Statecharts modeling as shown
in figure 5; this includes relating prompts,
conditions, actions and events etc. to the
dialogues. These are described in masks as
shown in figure 3
automatic prompt table generation
system parameters and application depen-
dent application parameters which repre-
sent the dialogue state
mapping from application parameters to
data base parameters; e.g. if the caller talks
about &amp;quot;tomorrow&amp;quot; this has to be mapped
into the actual date in a form that can be
handled by the database such as 03.02.99
attaching multilingual system prompts to
the modeled dialogues.
The system is implemented in C++ using
graphs and one set of constraints per dialogue
system, which represents the consistency rules
for this system.
We are currently working on adapting the
system to the needs of Temic—DDL (a dialogue
description language developed by Temic) and
VoiceXML (AT&amp;T et al., 2000) and on the au-
tomatic transformation of models. The inte-
gration of a grammar specification tool (work
in progress) is planned for the end of the year.
This module will provide different grammar for-
malisms such as UCG (Zeevat, 1988), PSG
(Boros, 1997) and Java Speech API (Sun mi-
crosystems, 2000). The conversion between
these grammar types will be supported.
The implementation of the system has just
been finished so far that it can be used by appli-
cation developers. But as it is completely new
and the graphical user interface is still being
improved in order to make it more intuitive, we
have not made any experience yet how much the
win of using Diamod will be for realistic dia-
logues. We are currently starting the evaluation
and we are optimistic after the first tests.
</bodyText>
<subsectionHeader confidence="0.593472">
4.2 Outlook
</subsectionHeader>
<bodyText confidence="0.999965736842106">
The dialogue systems we aimed at when we de-
veloped Diamod were mainly task—oriented sys-
tems, i.e. systems giving information on special
topics or modifying databases. The benefits of
Diamod in another context like translation sys-
tems (e.g. Verbmobil (Wahlster et al., 2000))
has not been investigated so far, but this is one
of our goals in the future.
Another interesting topic would be the adap-
tation of Diamod to dialogue systems using
dialogue grammars (Reichman, 1981) or plan—
based systems (Cohen and Levesque, 1980).
Further plans include the integration of a pro-
totyper into the tool system to be able to im-
mediately check the consequences of the mod-
ifications made. With these different means it
will be possible even for an untrained user to
specify new applications for his or her own re-
quirements.
</bodyText>
<sectionHeader confidence="0.997971" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999349794392523">
AT&amp;T et al. 2000. VoiceXML. World Wide
Web, http://www.voicexml.org/.
Eric Bilange. 1991. A task independent oral
dialogue model. In Proceedings of the Fifth
Conference of the European Chapter of the
Association for Computational Linguistics,
pages 83-88, Congress Hall, Alexanderplatz,
Berlin, Germany.
Manuela Boros, Ute Ehrlich, Paul Heisterkamp,
and Heinrich Niemann. 1998. An evaluation
framework for spoken language processing.
In Proceedings of the International Work-
shop Speech and Computer 1998, Russian
Academy of Sciences, St.Petersburg, Russia,
October.
Manuela Boros. 1997. Gepard - dokumenta-
tion des parsers f&apos;ur phrasenstrukturgram-
matiken. Projektbericht, FORWISS, Juni.
Astrid Brietzmann, Fritz Class, Ute Ehrlich,
Paul Heisterkamp, Alfred Kaltenmeier, Klaus
Mecklenburg, Peter Regel-Brietzmann, Ger-
hard Hanrieder, and Waltraud Hiltl. 1994.
Robust speech understanding. In Interna-
tional Conference on Spoken Language Pro-
cessing, pages 967-970, Yokohama.
Philip R. Cohen and Hector J. Levesque. 1980.
Speech acts and the recognition of shared
plans. In Proceedings of the Third Biennial
Conference of the Canadian Society for Com-
putational Studies of Intelligence, pages 263-
271.
Ron Cole. 1999. Tools for research and edu-
cation in speech science. In Proceedings of
the International Conference of Phonetic Sci-
ences, San Francisco, USA, August.
Jurgen Ebert, Angelika Franzke, Peter Dahm,
Andreas Winter, and Roger Sttenbach. 1996.
Graph based modeling and implementation
with eer/gral. In B. Thalheim, editor,
15th International Conference on Conceptual
Modeling (ER &apos;96), Proceedings, number 1157
in LNCS, pages 163-178, Berlin. Springer.
Ute Ehrlich, Gerhard Hanrieder, Ludwig
Hitzenberger, Paul Heisterkamp, Klaus
Mecklenburg, and Peter Regel-Brietzmann.
1997. ACCeSS - automated call center
through speech understanding system. In
Proc. Eurospeech &apos;97, pages 1819-1822,
Rhodes, Greece, September.
Ute Ehrlich. 1999. Task hierarchies - represent-
ing sub-dialogs in speech dialog systems. In
6th European Conference on Speech Commu-
nication and Technology (EUROSPEECH),
Budapest, Hungary, September.
Klaus Failenschmid and J.H. Simon Thornton.
1998. End-user driven dialogue system de-
sign: The reward experience. In Proceedings
of the International Conference on Spoken
Language Processing (ICSLP) 1998, Sydney,
Australia, November.
Gerald Gazdar. 1981. Speech act assignment.
In Aravind K. Joshi, Bonnie Lynn Webber,
and Ivan Sag, editors, Elements of Discourse
Understanding, pages 63-83. Cambridge Uni-
versity Press, Cambridge.
David Hard. 1987. Statecharts: A visual for-
malism for complex systems. Science of Com-
puter Programming, 8:231-274.
Paul Heisterkamp and Scott McGlashan. 1996.
Units of dialogue management: An example.
In Proc. ICSLP &apos;96, volume 1, pages 200-203,
Philadelphia, PA, October.
Paul Heisterkamp, Scott McGlashan, and
N. Youd. 1992. Dialogue semantics for an
oral dialogue system. In International Con-
ference on Spoken Language Processing (IC-
SLP), Volumel, pages 643-646, Banff, Al-
berta, Canada.
Anke Kolzer. 1999. Universal dialogue specifi-
cation for conversational systems. In Proceed-
ings of the International Workshop: Knowl-
edge and Reasoning in Practical Dialogue
Systems, IJCAI 1999, pages 65-72, Stock-
holm, Sweden, August.
Jeremy Peckham. 1993. A new generation
of spoken dialogue systems: Results and
lessons from the sundial project. In 3rd Eu-
ropean Conference on Speech Communication
and Technology (EUROSPEECH&apos;93); Vol.1,
pages 33-40, Berlin, September.
Rachel Reichman. 1981. Plain-speaking: A the-
ory and grammar of spontaneous discourse.
Ph.D. thesis, Department of Computer Sci-
ence, Harvard University, Cambridge, Mas-
sachusetts.
Sun microsystems. 2000. Java
Speech API. World Wide Web,
http://java.sun.com/products/java-
media/speech/index.html.
Wahlster et al. 2000. Project Verbmo-
bil. World Wide Web, http://www.coli.uni-
sb.de/—,vm/.
Henk Zeevat. 1988. Combining categorial
grammar and unification. In Reyle, Rohrer:
Natural Language Parsing and Linguistic
Theories, pages 202-229, Dordrecht. D. Rei-
del Publishing Company.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.213499">
<title confidence="0.824355">Tool for Modeling Dialogue Applications Anke Kolzer Speech Understanding Systems</title>
<author confidence="0.516375">DaimlerChrysler AG</author>
<email confidence="0.426251">P.O.Box</email>
<address confidence="0.980022">D-89013 Ulm (Germany)</address>
<email confidence="0.999823">e—mail:anke.koelzerAdaimlerchryslencom</email>
<abstract confidence="0.987922">Speech dialogue systems are currently becoming state—of—the—art for different kinds of applications, but they are still weak in the support of spontaneous speech and correct interpretation of what was said. One reason for the lack of good interactive dialogue systems is their complexity. To develop a system which is able to handle more than simple commands and phrases requires a lot of experience and time. To be able to accelerate and improve this process we are currently working on methods and tools which support this development. A new called Statecharts defined for the graphical specification of complex dialogues. It is capable of representing parallel dialogue steps which is e.g. necessary for mixed— initiative dialogues. Our tool system named editors for different dialogue concepts, such as dialogue structures, grammars and parameters. The modeling is supported by editors for Statecharts Hierarchies. Diamod able to check for the completeness and consistency of diamodels. One goal when developing Dito provide specification models which are universal enough to be interpreted within different dialogue systems, i.e. different implementations of generic conversational systems.&apos; With the help of a uniform representation of data a transformation between different models and different dialogue description languages (DDL) such as VoiceXML (AT&amp;T et al., 2000) and some in—house—DDLs, such as Temic—DDL and Dialogue-Prolog, will be possible. this we mean systems which are implemented application independently and are easily adapted to different applications.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>AT&amp;T</author>
</authors>
<date>2000</date>
<publisher>VoiceXML. World</publisher>
<location>Wide Web, http://www.voicexml.org/.</location>
<marker>AT&amp;T, 2000</marker>
<rawString>AT&amp;T et al. 2000. VoiceXML. World Wide Web, http://www.voicexml.org/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Bilange</author>
</authors>
<title>A task independent oral dialogue model.</title>
<date>1991</date>
<booktitle>In Proceedings of the Fifth Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>83--88</pages>
<location>Congress Hall, Alexanderplatz, Berlin, Germany.</location>
<contexts>
<context position="3318" citStr="Bilange, 1991" startWordPosition="504" endWordPosition="505">ff and needed tools to accelerate the process. Another goal was to make dialogue application modeling possible even for non— experts and help the expert to achieve consistent reusable applications. As there are different dialogue systems all over the world and many steps of application development are similar or even the same for all of them we decided to create tools which are system independent resp. easily adaptable to different needs and different dialogue systems. Our focus was on modeling dialogue structure for information— extracting resp. —processing systems of the slot— filling kind (Bilange, 1991). In order to find out what functionality a tool must provide to be helpful we analyzed the way we construct dialogue applications and the different knowledge bases that are needed. Similar operation steps have to be executed for every new application in order to obtain a structured and maintainable dialogue. Typical tasks are: modeling of the dialogue structure: i.e. divide the dialogue into subdialogues to handle a special part of the interaction like the identification of a caller definition of the application parameters, i.e. the parameters necessary to give information to the caller or ac</context>
</contexts>
<marker>Bilange, 1991</marker>
<rawString>Eric Bilange. 1991. A task independent oral dialogue model. In Proceedings of the Fifth Conference of the European Chapter of the Association for Computational Linguistics, pages 83-88, Congress Hall, Alexanderplatz, Berlin, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manuela Boros</author>
<author>Ute Ehrlich</author>
<author>Paul Heisterkamp</author>
<author>Heinrich Niemann</author>
</authors>
<title>An evaluation framework for spoken language processing.</title>
<date>1998</date>
<booktitle>In Proceedings of the International Workshop Speech and Computer 1998, Russian Academy of Sciences,</booktitle>
<location>St.Petersburg, Russia,</location>
<contexts>
<context position="2580" citStr="Boros et al., 1998" startWordPosition="384" endWordPosition="387"> market place and in research. One has been developed by the DaimlerChrysler research and is able to understand spontaneous speech speaker—independently and carry on dialogues on special topics. The structure and algorithms used are based on concepts developed in the Sundial project (Peckham, 1993). Most applications are made for telephony domains. Thus, up to now we gathered experience in applications like train time—table information, call centers for insurances and telematic systems for traffic data (see (Brietzmann et al., 1994), (Heisterkamp and McGlashan, 1996), (Ehrlich et al., 1997), (Boros et al., 1998) for further information). We made the experience that developing new applications is very expensive concerning time and staff and needed tools to accelerate the process. Another goal was to make dialogue application modeling possible even for non— experts and help the expert to achieve consistent reusable applications. As there are different dialogue systems all over the world and many steps of application development are similar or even the same for all of them we decided to create tools which are system independent resp. easily adaptable to different needs and different dialogue systems. Ou</context>
</contexts>
<marker>Boros, Ehrlich, Heisterkamp, Niemann, 1998</marker>
<rawString>Manuela Boros, Ute Ehrlich, Paul Heisterkamp, and Heinrich Niemann. 1998. An evaluation framework for spoken language processing. In Proceedings of the International Workshop Speech and Computer 1998, Russian Academy of Sciences, St.Petersburg, Russia, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manuela Boros</author>
</authors>
<title>Gepard - dokumentation des parsers f&apos;ur phrasenstrukturgrammatiken.</title>
<date>1997</date>
<tech>Projektbericht, FORWISS, Juni.</tech>
<contexts>
<context position="20283" citStr="Boros, 1997" startWordPosition="3207" endWordPosition="3208">ultilingual system prompts to the modeled dialogues. The system is implemented in C++ using graphs and one set of constraints per dialogue system, which represents the consistency rules for this system. We are currently working on adapting the system to the needs of Temic—DDL (a dialogue description language developed by Temic) and VoiceXML (AT&amp;T et al., 2000) and on the automatic transformation of models. The integration of a grammar specification tool (work in progress) is planned for the end of the year. This module will provide different grammar formalisms such as UCG (Zeevat, 1988), PSG (Boros, 1997) and Java Speech API (Sun microsystems, 2000). The conversion between these grammar types will be supported. The implementation of the system has just been finished so far that it can be used by application developers. But as it is completely new and the graphical user interface is still being improved in order to make it more intuitive, we have not made any experience yet how much the win of using Diamod will be for realistic dialogues. We are currently starting the evaluation and we are optimistic after the first tests. 4.2 Outlook The dialogue systems we aimed at when we developed Diamod we</context>
</contexts>
<marker>Boros, 1997</marker>
<rawString>Manuela Boros. 1997. Gepard - dokumentation des parsers f&apos;ur phrasenstrukturgrammatiken. Projektbericht, FORWISS, Juni.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Astrid Brietzmann</author>
<author>Fritz Class</author>
<author>Ute Ehrlich</author>
<author>Paul Heisterkamp</author>
<author>Alfred Kaltenmeier</author>
<author>Klaus Mecklenburg</author>
<author>Peter Regel-Brietzmann</author>
<author>Gerhard Hanrieder</author>
<author>Waltraud Hiltl</author>
</authors>
<title>Robust speech understanding.</title>
<date>1994</date>
<booktitle>In International Conference on Spoken Language Processing,</booktitle>
<pages>967--970</pages>
<location>Yokohama.</location>
<contexts>
<context position="2499" citStr="Brietzmann et al., 1994" startWordPosition="371" endWordPosition="374">rent applications. 1 Introduction You find different dialogue system approaches on the market place and in research. One has been developed by the DaimlerChrysler research and is able to understand spontaneous speech speaker—independently and carry on dialogues on special topics. The structure and algorithms used are based on concepts developed in the Sundial project (Peckham, 1993). Most applications are made for telephony domains. Thus, up to now we gathered experience in applications like train time—table information, call centers for insurances and telematic systems for traffic data (see (Brietzmann et al., 1994), (Heisterkamp and McGlashan, 1996), (Ehrlich et al., 1997), (Boros et al., 1998) for further information). We made the experience that developing new applications is very expensive concerning time and staff and needed tools to accelerate the process. Another goal was to make dialogue application modeling possible even for non— experts and help the expert to achieve consistent reusable applications. As there are different dialogue systems all over the world and many steps of application development are similar or even the same for all of them we decided to create tools which are system indepen</context>
</contexts>
<marker>Brietzmann, Class, Ehrlich, Heisterkamp, Kaltenmeier, Mecklenburg, Regel-Brietzmann, Hanrieder, Hiltl, 1994</marker>
<rawString>Astrid Brietzmann, Fritz Class, Ute Ehrlich, Paul Heisterkamp, Alfred Kaltenmeier, Klaus Mecklenburg, Peter Regel-Brietzmann, Gerhard Hanrieder, and Waltraud Hiltl. 1994. Robust speech understanding. In International Conference on Spoken Language Processing, pages 967-970, Yokohama.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip R Cohen</author>
<author>Hector J Levesque</author>
</authors>
<title>Speech acts and the recognition of shared plans.</title>
<date>1980</date>
<booktitle>In Proceedings of the Third Biennial Conference of the Canadian Society for Computational Studies of Intelligence,</booktitle>
<pages>263--271</pages>
<marker>Cohen, Levesque, 1980</marker>
<rawString>Philip R. Cohen and Hector J. Levesque. 1980. Speech acts and the recognition of shared plans. In Proceedings of the Third Biennial Conference of the Canadian Society for Computational Studies of Intelligence, pages 263-271.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ron Cole</author>
</authors>
<title>Tools for research and education in speech science.</title>
<date>1999</date>
<booktitle>In Proceedings of the International Conference of Phonetic Sciences,</booktitle>
<location>San Francisco, USA,</location>
<contexts>
<context position="14420" citStr="Cole, 1999" startWordPosition="2305" endWordPosition="2306"> for the description of a dialogue for the DaimlerChrysler research system. In some dialogue systems parameters can have attributes like if they are obligatory or optional. Therefore the masks have to be configured for the dialogue system. Clicking the button Generate Prompt Table will generate the possible prompts. Clicking the button Edit Prompt Table will open the mask shown in figure 4. 3.1.2 State—Based Approach Many dialogue systems use a state based approach where dialogue flow is described in detail using state—transition—models combined with events (Failenschmid and Thornton, 1998), (Cole, 1999). Simple state—transition—models are adequate for very simple dialogue systems such as command—and—control systems.3 As conversational systems have a high complexity of states, the expressiveness of state—transition— models is too small to be a good means for dialogue flow modeling. The number of states is usually too big to be handled by a human. A good alternative for complex state modeling are statecharts as described by Harel (1987). They provide different means of abstraction such as concurrent states, state refinement, special event handling and action triggers. 3These are systems where </context>
</contexts>
<marker>Cole, 1999</marker>
<rawString>Ron Cole. 1999. Tools for research and education in speech science. In Proceedings of the International Conference of Phonetic Sciences, San Francisco, USA, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jurgen Ebert</author>
<author>Angelika Franzke</author>
<author>Peter Dahm</author>
<author>Andreas Winter</author>
<author>Roger Sttenbach</author>
</authors>
<title>Graph based modeling and implementation with eer/gral.</title>
<date>1996</date>
<booktitle>15th International Conference on Conceptual Modeling (ER &apos;96), Proceedings, number 1157 in LNCS,</booktitle>
<pages>163--178</pages>
<editor>In B. Thalheim, editor,</editor>
<publisher>Springer.</publisher>
<location>Berlin.</location>
<contexts>
<context position="17467" citStr="Ebert et al., 1996" startWordPosition="2750" endWordPosition="2753">ext has not been investigated yet as one needs a well defined dialogue description language as interface to such a rule—based dialogue system.5 Thus this is work for the future. 3.1.4 Concistency checking An important point is that the tool is capable of checking the completeness of the models and their consistency. This is done using an object— oriented graph structure which represents all required concepts and the dependences between them. Consistency checks can be executed by formulating constraints on the graph using path expressions and having them examined by a special path interpreter (Ebert et al., 1996). Thus, it is possible to guarantee that for example — there are no problematic cycles in the model there is a system prompt defined for every system initiative state (i.e. states where the system has to speak an utterance) and every parameter, so that the system never runs in a situation where it is &apos;speechless&apos;. — domains are defined properly for all parameters — there is a following state in every situation (or the end of the dialogue) 4 Summary The paper introduces the tool system Diamod which implements a universal approach for the 5This would be a quite interesting project and we would b</context>
</contexts>
<marker>Ebert, Franzke, Dahm, Winter, Sttenbach, 1996</marker>
<rawString>Jurgen Ebert, Angelika Franzke, Peter Dahm, Andreas Winter, and Roger Sttenbach. 1996. Graph based modeling and implementation with eer/gral. In B. Thalheim, editor, 15th International Conference on Conceptual Modeling (ER &apos;96), Proceedings, number 1157 in LNCS, pages 163-178, Berlin. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ute Ehrlich</author>
<author>Gerhard Hanrieder</author>
<author>Ludwig Hitzenberger</author>
<author>Paul Heisterkamp</author>
<author>Klaus Mecklenburg</author>
<author>Peter Regel-Brietzmann</author>
</authors>
<title>ACCeSS - automated call center through speech understanding system.</title>
<date>1997</date>
<booktitle>In Proc. Eurospeech &apos;97,</booktitle>
<pages>1819--1822</pages>
<location>Rhodes, Greece,</location>
<contexts>
<context position="2558" citStr="Ehrlich et al., 1997" startWordPosition="380" endWordPosition="383">system approaches on the market place and in research. One has been developed by the DaimlerChrysler research and is able to understand spontaneous speech speaker—independently and carry on dialogues on special topics. The structure and algorithms used are based on concepts developed in the Sundial project (Peckham, 1993). Most applications are made for telephony domains. Thus, up to now we gathered experience in applications like train time—table information, call centers for insurances and telematic systems for traffic data (see (Brietzmann et al., 1994), (Heisterkamp and McGlashan, 1996), (Ehrlich et al., 1997), (Boros et al., 1998) for further information). We made the experience that developing new applications is very expensive concerning time and staff and needed tools to accelerate the process. Another goal was to make dialogue application modeling possible even for non— experts and help the expert to achieve consistent reusable applications. As there are different dialogue systems all over the world and many steps of application development are similar or even the same for all of them we decided to create tools which are system independent resp. easily adaptable to different needs and differen</context>
</contexts>
<marker>Ehrlich, Hanrieder, Hitzenberger, Heisterkamp, Mecklenburg, Regel-Brietzmann, 1997</marker>
<rawString>Ute Ehrlich, Gerhard Hanrieder, Ludwig Hitzenberger, Paul Heisterkamp, Klaus Mecklenburg, and Peter Regel-Brietzmann. 1997. ACCeSS - automated call center through speech understanding system. In Proc. Eurospeech &apos;97, pages 1819-1822, Rhodes, Greece, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ute Ehrlich</author>
</authors>
<title>Task hierarchies - representing sub-dialogs in speech dialog systems.</title>
<date>1999</date>
<booktitle>In 6th European Conference on Speech Communication and Technology (EUROSPEECH),</booktitle>
<location>Budapest, Hungary,</location>
<contexts>
<context position="8979" citStr="Ehrlich, 1999" startWordPosition="1404" endWordPosition="1405">rent generic dialogue systems, Diamod must also consider the generic features of the system (because they can be different for different dialogue systems). Therefore a two—phase approach is supported where in the first phase a dialogue expert (usually the developer of the generic dialogue system) models application independent data. In a second phase an application developer models application dependent data using the data which was modeled by the expert (Kolzer, 1999). Another feature of Diamod is the support of different dialogue structure models. Our research system is a rule—based system (Ehrlich, 1999) which can be modeled in Diamod using tasks and task—hierarchy—diagrams. A rather state—based system can be modeled using the Dialogue—Statecharts—editor. The following listing sums up the most important steps which have to be done by the application developer in order to specify the dialogue flow of a new application: — definition of the components of the dialogue; e.g. a subdialogue for handling the 2A predefined sublanguage of Prolog is used to model applications for the DaimlerChrysler research system. identification of the caller and finding out why he calls, a subdialogue for reservation</context>
</contexts>
<marker>Ehrlich, 1999</marker>
<rawString>Ute Ehrlich. 1999. Task hierarchies - representing sub-dialogs in speech dialog systems. In 6th European Conference on Speech Communication and Technology (EUROSPEECH), Budapest, Hungary, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Klaus Failenschmid</author>
<author>J H Simon Thornton</author>
</authors>
<title>End-user driven dialogue system design: The reward experience.</title>
<date>1998</date>
<booktitle>In Proceedings of the International Conference on Spoken Language Processing (ICSLP)</booktitle>
<location>Sydney, Australia,</location>
<contexts>
<context position="14406" citStr="Failenschmid and Thornton, 1998" startWordPosition="2301" endWordPosition="2304">n knowledge bases. Figure 3: A mask for the description of a dialogue for the DaimlerChrysler research system. In some dialogue systems parameters can have attributes like if they are obligatory or optional. Therefore the masks have to be configured for the dialogue system. Clicking the button Generate Prompt Table will generate the possible prompts. Clicking the button Edit Prompt Table will open the mask shown in figure 4. 3.1.2 State—Based Approach Many dialogue systems use a state based approach where dialogue flow is described in detail using state—transition—models combined with events (Failenschmid and Thornton, 1998), (Cole, 1999). Simple state—transition—models are adequate for very simple dialogue systems such as command—and—control systems.3 As conversational systems have a high complexity of states, the expressiveness of state—transition— models is too small to be a good means for dialogue flow modeling. The number of states is usually too big to be handled by a human. A good alternative for complex state modeling are statecharts as described by Harel (1987). They provide different means of abstraction such as concurrent states, state refinement, special event handling and action triggers. 3These are </context>
</contexts>
<marker>Failenschmid, Thornton, 1998</marker>
<rawString>Klaus Failenschmid and J.H. Simon Thornton. 1998. End-user driven dialogue system design: The reward experience. In Proceedings of the International Conference on Spoken Language Processing (ICSLP) 1998, Sydney, Australia, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerald Gazdar</author>
</authors>
<title>Speech act assignment. In Aravind</title>
<date>1981</date>
<booktitle>Elements of Discourse Understanding,</booktitle>
<pages>63--83</pages>
<editor>K. Joshi, Bonnie Lynn Webber, and Ivan Sag, editors,</editor>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="11043" citStr="Gazdar, 1981" startWordPosition="1743" endWordPosition="1744">ask represents a subdialogue, e.g. a caller identification or a hotel reservation. The task structure is organized in a task hierarchy as shown in figure 2, which can be modeled with Diamod using the task— hierarchy—editor. At runtime the dialogue system can only activate the direct daughter— or mother—task of a currently active task in this hierarchy. This is used to make dialogue handling easier and more consistent. It is not necessary to model exactly the system states and their sequence as it often has to be done for other dialogue systems. The dialogue system uses a set of dialogue acts (Gazdar, 1981), (Heisterkamp et al., 1992) such as confirm, request and inform in order to distinguish between different dialogue situations. Every task has different application concepts attached to it. Among others these are: Task (application) parameters: These are the concepts which model what values must be found out in order to reach the goals of the task, e.g. to be able to make a database access. This is usually what you Dialogue User Interface Representation GUI Textual off-line interface Task 1 Identify Task 2 Topic Start Tool System Uniform graph representation Consistency checks Methods Models .</context>
</contexts>
<marker>Gazdar, 1981</marker>
<rawString>Gerald Gazdar. 1981. Speech act assignment. In Aravind K. Joshi, Bonnie Lynn Webber, and Ivan Sag, editors, Elements of Discourse Understanding, pages 63-83. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Hard</author>
</authors>
<title>Statecharts: A visual formalism for complex systems.</title>
<date>1987</date>
<journal>Science of Computer Programming,</journal>
<pages>8--231</pages>
<contexts>
<context position="6071" citStr="Hard, 1987" startWordPosition="949" endWordPosition="950"> as grammar models. All the concepts necessary for dialogue flow modeling are to be integrated in the dialogue flow tool. Thus the dialogue flow tool must provide concepts such as application parameters, system prompts, state and task modeling. The state logic has to be described in a rather abstract way so that an automatic transformation for different dialogue systems is possible. Therefore it is not sufficient to use the widely employed state machines with which the specialties of spontaneous speech cannot be described adequately. Instead we use a design method based on Hare&apos;s statecharts (Hard, 1987) which are capable of describing concurrency and provide special event mechanisms and called it Dialogue Statecharts. 2.1 Properties of Diamod Diamod is a CASE—tool (Computer Aided Software Engineering) specialized for language engineering which provides the concepts necessary for dialogue specification. To be able to develop new and modify old knowledge bases easily, the tool supports the language engineer with the following functionality: Graphical editors for visual languages such as Dialogue Statecharts for the specification of structured dialogue data. The graphical interface shall enable</context>
</contexts>
<marker>Hard, 1987</marker>
<rawString>David Hard. 1987. Statecharts: A visual formalism for complex systems. Science of Computer Programming, 8:231-274.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Heisterkamp</author>
<author>Scott McGlashan</author>
</authors>
<title>Units of dialogue management: An example.</title>
<date>1996</date>
<booktitle>In Proc. ICSLP &apos;96,</booktitle>
<volume>1</volume>
<pages>200--203</pages>
<location>Philadelphia, PA,</location>
<contexts>
<context position="2534" citStr="Heisterkamp and McGlashan, 1996" startWordPosition="375" endWordPosition="379">uction You find different dialogue system approaches on the market place and in research. One has been developed by the DaimlerChrysler research and is able to understand spontaneous speech speaker—independently and carry on dialogues on special topics. The structure and algorithms used are based on concepts developed in the Sundial project (Peckham, 1993). Most applications are made for telephony domains. Thus, up to now we gathered experience in applications like train time—table information, call centers for insurances and telematic systems for traffic data (see (Brietzmann et al., 1994), (Heisterkamp and McGlashan, 1996), (Ehrlich et al., 1997), (Boros et al., 1998) for further information). We made the experience that developing new applications is very expensive concerning time and staff and needed tools to accelerate the process. Another goal was to make dialogue application modeling possible even for non— experts and help the expert to achieve consistent reusable applications. As there are different dialogue systems all over the world and many steps of application development are similar or even the same for all of them we decided to create tools which are system independent resp. easily adaptable to diff</context>
</contexts>
<marker>Heisterkamp, McGlashan, 1996</marker>
<rawString>Paul Heisterkamp and Scott McGlashan. 1996. Units of dialogue management: An example. In Proc. ICSLP &apos;96, volume 1, pages 200-203, Philadelphia, PA, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Heisterkamp</author>
<author>Scott McGlashan</author>
<author>N Youd</author>
</authors>
<title>Dialogue semantics for an oral dialogue system.</title>
<date>1992</date>
<booktitle>In International Conference on Spoken Language Processing (ICSLP), Volumel,</booktitle>
<pages>643--646</pages>
<location>Banff, Alberta, Canada.</location>
<contexts>
<context position="11071" citStr="Heisterkamp et al., 1992" startWordPosition="1745" endWordPosition="1749"> subdialogue, e.g. a caller identification or a hotel reservation. The task structure is organized in a task hierarchy as shown in figure 2, which can be modeled with Diamod using the task— hierarchy—editor. At runtime the dialogue system can only activate the direct daughter— or mother—task of a currently active task in this hierarchy. This is used to make dialogue handling easier and more consistent. It is not necessary to model exactly the system states and their sequence as it often has to be done for other dialogue systems. The dialogue system uses a set of dialogue acts (Gazdar, 1981), (Heisterkamp et al., 1992) such as confirm, request and inform in order to distinguish between different dialogue situations. Every task has different application concepts attached to it. Among others these are: Task (application) parameters: These are the concepts which model what values must be found out in order to reach the goals of the task, e.g. to be able to make a database access. This is usually what you Dialogue User Interface Representation GUI Textual off-line interface Task 1 Identify Task 2 Topic Start Tool System Uniform graph representation Consistency checks Methods Models ..... Code Generation Languag</context>
</contexts>
<marker>Heisterkamp, McGlashan, Youd, 1992</marker>
<rawString>Paul Heisterkamp, Scott McGlashan, and N. Youd. 1992. Dialogue semantics for an oral dialogue system. In International Conference on Spoken Language Processing (ICSLP), Volumel, pages 643-646, Banff, Alberta, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anke Kolzer</author>
</authors>
<title>Universal dialogue specification for conversational systems.</title>
<date>1999</date>
<booktitle>In Proceedings of the International Workshop: Knowledge and Reasoning in Practical Dialogue Systems, IJCAI</booktitle>
<pages>65--72</pages>
<location>Stockholm, Sweden,</location>
<contexts>
<context position="8838" citStr="Kolzer, 1999" startWordPosition="1382" endWordPosition="1383">ialogue flow models With Diamod the application developer models what the system has to do in a given situation. As this must work for different generic dialogue systems, Diamod must also consider the generic features of the system (because they can be different for different dialogue systems). Therefore a two—phase approach is supported where in the first phase a dialogue expert (usually the developer of the generic dialogue system) models application independent data. In a second phase an application developer models application dependent data using the data which was modeled by the expert (Kolzer, 1999). Another feature of Diamod is the support of different dialogue structure models. Our research system is a rule—based system (Ehrlich, 1999) which can be modeled in Diamod using tasks and task—hierarchy—diagrams. A rather state—based system can be modeled using the Dialogue—Statecharts—editor. The following listing sums up the most important steps which have to be done by the application developer in order to specify the dialogue flow of a new application: — definition of the components of the dialogue; e.g. a subdialogue for handling the 2A predefined sublanguage of Prolog is used to model a</context>
</contexts>
<marker>Kolzer, 1999</marker>
<rawString>Anke Kolzer. 1999. Universal dialogue specification for conversational systems. In Proceedings of the International Workshop: Knowledge and Reasoning in Practical Dialogue Systems, IJCAI 1999, pages 65-72, Stockholm, Sweden, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeremy Peckham</author>
</authors>
<title>A new generation of spoken dialogue systems: Results and lessons from the sundial project.</title>
<date>1993</date>
<booktitle>In 3rd European Conference on Speech Communication and Technology (EUROSPEECH&apos;93); Vol.1,</booktitle>
<pages>33--40</pages>
<location>Berlin,</location>
<contexts>
<context position="2260" citStr="Peckham, 1993" startWordPosition="336" endWordPosition="337">(DDL) such as VoiceXML (AT&amp;T et al., 2000) and some in—house—DDLs, such as Temic—DDL and Dialogue-Prolog, will be possible. 1-By this we mean systems which are implemented application independently and are easily adapted to different applications. 1 Introduction You find different dialogue system approaches on the market place and in research. One has been developed by the DaimlerChrysler research and is able to understand spontaneous speech speaker—independently and carry on dialogues on special topics. The structure and algorithms used are based on concepts developed in the Sundial project (Peckham, 1993). Most applications are made for telephony domains. Thus, up to now we gathered experience in applications like train time—table information, call centers for insurances and telematic systems for traffic data (see (Brietzmann et al., 1994), (Heisterkamp and McGlashan, 1996), (Ehrlich et al., 1997), (Boros et al., 1998) for further information). We made the experience that developing new applications is very expensive concerning time and staff and needed tools to accelerate the process. Another goal was to make dialogue application modeling possible even for non— experts and help the expert to </context>
</contexts>
<marker>Peckham, 1993</marker>
<rawString>Jeremy Peckham. 1993. A new generation of spoken dialogue systems: Results and lessons from the sundial project. In 3rd European Conference on Speech Communication and Technology (EUROSPEECH&apos;93); Vol.1, pages 33-40, Berlin, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rachel Reichman</author>
</authors>
<title>Plain-speaking: A theory and grammar of spontaneous discourse.</title>
<date>1981</date>
<tech>Ph.D. thesis,</tech>
<institution>Department of Computer Science, Harvard University,</institution>
<location>Cambridge, Massachusetts.</location>
<marker>Reichman, 1981</marker>
<rawString>Rachel Reichman. 1981. Plain-speaking: A theory and grammar of spontaneous discourse. Ph.D. thesis, Department of Computer Science, Harvard University, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sun microsystems</author>
</authors>
<title>Java Speech API.</title>
<date>2000</date>
<publisher>World Wide</publisher>
<note>Web, http://java.sun.com/products/javamedia/speech/index.html.</note>
<contexts>
<context position="20328" citStr="microsystems, 2000" startWordPosition="3214" endWordPosition="3216">led dialogues. The system is implemented in C++ using graphs and one set of constraints per dialogue system, which represents the consistency rules for this system. We are currently working on adapting the system to the needs of Temic—DDL (a dialogue description language developed by Temic) and VoiceXML (AT&amp;T et al., 2000) and on the automatic transformation of models. The integration of a grammar specification tool (work in progress) is planned for the end of the year. This module will provide different grammar formalisms such as UCG (Zeevat, 1988), PSG (Boros, 1997) and Java Speech API (Sun microsystems, 2000). The conversion between these grammar types will be supported. The implementation of the system has just been finished so far that it can be used by application developers. But as it is completely new and the graphical user interface is still being improved in order to make it more intuitive, we have not made any experience yet how much the win of using Diamod will be for realistic dialogues. We are currently starting the evaluation and we are optimistic after the first tests. 4.2 Outlook The dialogue systems we aimed at when we developed Diamod were mainly task—oriented systems, i.e. systems</context>
</contexts>
<marker>microsystems, 2000</marker>
<rawString>Sun microsystems. 2000. Java Speech API. World Wide Web, http://java.sun.com/products/javamedia/speech/index.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wahlster</author>
</authors>
<title>Project Verbmobil. World Wide Web,</title>
<date>2000</date>
<location>http://www.coli.unisb.de/—,vm/.</location>
<marker>Wahlster, 2000</marker>
<rawString>Wahlster et al. 2000. Project Verbmobil. World Wide Web, http://www.coli.unisb.de/—,vm/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Henk Zeevat</author>
</authors>
<title>Combining categorial grammar and unification. In Reyle, Rohrer: Natural Language Parsing and Linguistic Theories,</title>
<date>1988</date>
<pages>202--229</pages>
<publisher>Reidel Publishing Company.</publisher>
<location>Dordrecht. D.</location>
<contexts>
<context position="20264" citStr="Zeevat, 1988" startWordPosition="3204" endWordPosition="3205">03.02.99 attaching multilingual system prompts to the modeled dialogues. The system is implemented in C++ using graphs and one set of constraints per dialogue system, which represents the consistency rules for this system. We are currently working on adapting the system to the needs of Temic—DDL (a dialogue description language developed by Temic) and VoiceXML (AT&amp;T et al., 2000) and on the automatic transformation of models. The integration of a grammar specification tool (work in progress) is planned for the end of the year. This module will provide different grammar formalisms such as UCG (Zeevat, 1988), PSG (Boros, 1997) and Java Speech API (Sun microsystems, 2000). The conversion between these grammar types will be supported. The implementation of the system has just been finished so far that it can be used by application developers. But as it is completely new and the graphical user interface is still being improved in order to make it more intuitive, we have not made any experience yet how much the win of using Diamod will be for realistic dialogues. We are currently starting the evaluation and we are optimistic after the first tests. 4.2 Outlook The dialogue systems we aimed at when we </context>
</contexts>
<marker>Zeevat, 1988</marker>
<rawString>Henk Zeevat. 1988. Combining categorial grammar and unification. In Reyle, Rohrer: Natural Language Parsing and Linguistic Theories, pages 202-229, Dordrecht. D. Reidel Publishing Company.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>