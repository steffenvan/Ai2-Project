<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9986625">
Completeness Conditions for Mixed
Strategy Bidirectional Parsing
</title>
<author confidence="0.996375">
Graeme Ritchie*
</author>
<affiliation confidence="0.981693">
University of Edinburgh
</affiliation>
<bodyText confidence="0.999471642857143">
It has been suggested that, in certain circumstances, it might be useful for a grammar writer
to annotate which rules are to be used bottom-up and which are to be used top-down within a
parser, using a bidirectional variant of the active chart parsing technique. The formal properties
of such systems have not been fully explored. One limitation of this mixed strategy technique is
that certain annotations of rules can lead to incompleteness; that is, there may be valid analyses of
the input string that cannot be found by the parser. We formalize a fairly natural notion of mixed
strategy bidirectional parsing for context-free grammars, in which one or more symbols within a
rule may be annotated as &amp;quot;triggers,&amp;quot; so that the rule is either top-down (triggered from its left-
hand side), or bottom-up (triggered from element(s) of its right-hand side). We define a decidable
property of annotated grammars, such that any grammar with this property is provably complete.
There are, however, some complete annotations of grammars that fall outside this decidable class.
We show that membership of this wider class is undecidable. These results suggest that the mixed
strategy approach is of rather limited usefulness, regardless of whether it is empirically efficient
or not.
</bodyText>
<sectionHeader confidence="0.77332" genericHeader="abstract">
1. Overview
</sectionHeader>
<bodyText confidence="0.99991505">
Many methods have been explored for parsing context-free grammars; some of these
methods are loosely categorized as &amp;quot;top-down&amp;quot; (e.g., recursive descent), some as
&amp;quot;bottom-up&amp;quot; (e.g., shift-reduce), and some could be seen as a mixture of these two
varieties (e.g., left-corner). All of the well-explored methods assume that the rules in
the grammar are handled in a fairly uniform way. In particular, it is not usual for the
rules to be separated into two classes—those to be used bottom-up and those to be
used top-down. Steel and de Roeck (1987) argue (giving credit to Henry Thompson
for some of the ideas) that the performance of a parser could be improved by allowing
the grammar writer to do exactly this. The motivation comes from linguistic phenom-
ena where it is intuitively clear that one symbol (linguistic category) in the rule is
noticeably more distinctive than others, so that a parser should not waste time trying
to match the rule unless that distinctive element is there. For example, a rule such as
NP —&gt; NP CONJ NP (where CONJ indicates a conjunction, such as and) should not be
invoked simply because a noun phrase (NP), or the start of a noun phrase, has been
found. The proposal is that if the linguist is allowed to mark the CONJ element as a
&amp;quot;trigger,&amp;quot; and the parser introduces the rule, bottom-up, only if the trigger has been
matched, then parsing would proceed more efficiently.
Steel and de Roeck describe semi-formally a system they have implemented, which
they claim benefits from this labeling of rules. The current paper does not take a
position on the wisdom or effectiveness of such labeling. Instead, we explore the
</bodyText>
<note confidence="0.872003">
* Division of Informatics, 80 South Bridge, Edinburgh EHI IHN, Scotland.
© 1999 Association for Computational Linguistics
Computational Linguistics Volume 25, Number 4
</note>
<bodyText confidence="0.9998796">
formal consequences of this proposal. We show that, although the idea may seem
superficially plausible, it still has certain formal limitations in the area of completeness
and decidability. The proofs may be of some theoretical interest from a formal language
viewpoint.
The central ideas are as follows: A conventional context-free grammar is &amp;quot;anno-
tated&amp;quot; by marking at least one symbol in each rule as a trigger. Marking the left-hand-
side (LHS) symbol as a trigger indicates that the rule can be used top-down; marking
a right-hand-side (RHS) symbol as a trigger means that the rule can be used bottom-
up whenever a constituent labeled with that symbol is found by the parser.&apos; Using a
method of parsing known as active chart parsing, it is straightforward to give a precise
meaning to this labeling of rules, since a chart parser can operate either bottom-up or
top-down. The scheme examined here is similar to, but different in important ways
from, head-driven parsing (see Section 7.2).
It is simple to construct an annotated grammar in which there are some analyses
that are valid according to the original (unannotated) grammar but that would not
be parsed by a chart parser following the annotations. This establishes that not all
annotated grammars allow complete parsing.
The main substance of this paper is as follows: A property of annotated grammars
(direct analyzability) is defined, which is decidable, and it is proven that any annotated
grammar with this property will also allow the parser to produce all the valid analyses
licensed by the original grammar. However, some annotated grammars are not directly
analyzable, but nevertheless lead to complete parsing. A characteristic of (a subset of)
this wider class of annotated grammars (indirect analyzability) is defined, and it is
proven that any annotated grammar with this property will allow complete parsing.
However, indirect analyzability can be shown to be undecidable.
</bodyText>
<sectionHeader confidence="0.995256" genericHeader="method">
2. The problems
</sectionHeader>
<subsectionHeader confidence="0.997613">
2.1 Losing Completeness
</subsectionHeader>
<bodyText confidence="0.9094327">
Before presenting a formal definition of the mechanisms, and proceeding to prove their
various properties, it is useful to consider informally a very simple example that shows
how this approach can lead to loss of analyses by the parser. As outlined above, the
central idea is to allow different rules to be marked as either top-down (LHS trigger
symbol) or bottom-up (RHS trigger symbol(s)), or both. Top-down means that the rule
can be invoked only if some other rule has established a need for its LHS symbol (or
if the LHS symbol is the initial symbol of the grammar). Bottom-up means that the
rule can be invoked only if one of the symbols marked as triggers on its RHS has
been completely parsed. We shall assume that rules of the form A —&gt; w where w is a
terminal symbol are never annotated, and can be used whenever needed in the parser
(all this is made precise in our formalization in Section 3.3 below).
For this informal presentation, and occasionally elsewhere, we shall mark a trigger
symbol A by overlining it, thus: A. In the illustrative examples, the distinguished
(initial) symbol of the grammar will always be S and terminal symbols will be in
lower case.
1 The term &amp;quot;bottom-up&amp;quot; is adopted here for compatibiity with some other literature on chart parsing, and
for lack of a better simple phrase. In fact, there are various possible parsing regimes that are in some
sense &amp;quot;bottom-up,&amp;quot; and it is arguable that some are &amp;quot;more bottom-up&amp;quot; than those outlined here. Where
right-hand-side triggers are restricted to the leftmost symbol (as in Section 5 below), parsing is more
like &amp;quot;left-corner&amp;quot; parsing, but this would be a misleading term when triggers are allowed elsewhere.
</bodyText>
<page confidence="0.994294">
458
</page>
<figure confidence="0.760713571428571">
Ritchie Completeness Conditions for Mixed Strategy Bidirectional Parsing
Consider the annotated grammar (see Section 3 for a definition of grammar):
S NP VP
NP Art N
VP —&gt; runs
Art —&gt; the
N —&gt; dog
</figure>
<bodyText confidence="0.999907571428571">
It should be intuitively clear that although this grammar generates exactly one sen-
tence, that string cannot be parsed by a parser that follows the annotations as de-
scribed. The rule S NP VP cannot be used until an initial NP is recognized, and the
rule that might do that, NP —&gt; Art N, cannot be used until an initial need for an NP
is established (which could happen only using S NP VP). There is a form of dead-
lock, resulting in incompleteness. It should also be intuitively clear that the presence
or absence of such combinations of annotations may not be as obvious as it is here.
In a grammar with hundreds of rules, the presence of a combination that blocks an
otherwise valid analysis could take some detailed checking. This is a serious flaw, as
the annotation method was supposed to alter the efficiency of the parser, but not to
eliminate strings from its language.
It would be very easy to ensure that annotation does not lose analyses, by stipu-
lating that all rules are marked as top-down, or that all rules are marked as bottom-up
with the leftmost symbol as a trigger. The parser would then behave as a conventional
top-down (or bottom-up) chart parser, which is known to be complete. However, since
the aim is to allow the grammar writer to make a nontrivial annotation of the grammar
(in an attempt to allow linguistic knowledge to influence the efficiency of the parsing),
we need to be able to check the completeness of arbitrarily annotated grammars. In
Section 4 below, we define formally a nontrivial characteristic of annotated grammars
that guarantees that they do not lose analyses in this way, and show that this property
of grammars is decidable.
</bodyText>
<subsectionHeader confidence="0.999732">
2.2 Completeness through Interactions
</subsectionHeader>
<bodyText confidence="0.999894333333333">
The situation is even more complicated than Section 2.1 above indicates. One of the
crucial aspects of chart parsing (which is central to its simplicity and its efficiency)
is that any entry in a chart can be used to combine with any other compatible entry,
regardless of whether there is a single coherent tree that will result from it. In particular,
an entry that has been inserted in the chart as the result of some rule interaction that
does not itself produce a complete sentential tree (i.e., a partial fragment of an analysis)
can contribute to some other analysis that happens to require it.
This is best demonstrated by a simple artificial example. Consider the strategy-
marked grammar, notation as before:
</bodyText>
<figure confidence="0.720645142857143">
3—&gt;EH
H—BF
13—&gt;PQ
E j
P 1
m
F k
</figure>
<bodyText confidence="0.796031">
The un-strategy-marked version of this grammar would generate the string jlmk, with
</bodyText>
<page confidence="0.99297">
459
</page>
<figure confidence="0.469252">
Computational Linguistics Volume 25, Number 4
a derivation as follows (see Section 3 for a definition of the relation &amp;quot;&amp;quot;):
S EH jH jBF = jPQF j1QF = jlmF = jlmk
</figure>
<bodyText confidence="0.998918">
The tree described by this derivation cannot be found by a parser following the
strategy-marked grammar, for reasons similar to those outlined in Section 2.1 above.
Suppose we now add the following rules to the grammar:
</bodyText>
<figure confidence="0.987805">
S C D
D—&gt;EA
A —&gt; B C
C x
</figure>
<bodyText confidence="0.999532904761905">
This larger grammar will also generate the string xj/mx, but this is not relevant to the
argument. What is more interesting is that the extended grammar does now allow the
parsing of jlmk, with an associated syntax tree that corresponds to the derivation given
above (i.e., a tree that makes no direct use of the rules that have been added to the
grammar). The way in which the added rules act as a &amp;quot;catalyst&amp;quot; to allow the hitherto
blocked analysis is an example of a general phenomenon. Informally, what happens is
the following: (A chart parser is assumed here; formal details are given in Section 3.3
below.) With just the smaller grammar, the nonterminal H cannot be expanded as
required, since it is on the LHS of a bottom-up rule, and its first symbol B cannot be
recognized because it requires a top-down rule. In both the original grammar and the
larger grammar, H is introduced only by the rule S E H, i.e., with E on its immediate
left. So the only strings where H can participate in an analysis are those where E occurs
at the start. Consider the parsing, with the larger grammar, of the string jlmk (which
does indeed start with an E). As E is preterminal, it can be recognized directly (with no
effect from annotations). In the larger grammar, the bottom-up rule D E A is then
introduced to the parsing, which creates a predictive entry in the parser&apos;s structures
seeking an A, after the recognized E. The top-down rule A C is then introduced,
which leads to an entry, at that same point, seeking a B. This causes the top-down
rule B P Q (from the original grammar) to be introduced; this is a crucial step. This
allows the sequence /m to be parsed as a B, thereby causing the introduction of the
bottom-up rule H B F, and the subsequent success of the parse.
</bodyText>
<subsectionHeader confidence="0.99964">
2.3 What Are the Problems?
</subsectionHeader>
<bodyText confidence="0.999948222222222">
The grammars discussed above (Sections 2.1 and 2.2) are examples of various aspects
of the problem. We shall show that there is a simple, decidable property of annotated
grammars that guarantees completeness, and that could be used to detect the sim-
ple blocking illustrated in Section 2.1. However, this property is merely a sufficient
condition for completeness, as the larger grammar of Section 2.2 above does not pos-
sess it, despite being complete. We shall show that the larger grammar of Section 2.2
has a more general property, which also guarantees completeness. However, the more
general property of annotated grammars is undecidable.
First, we have to set up the basic formal mechanisms for our definitions.
</bodyText>
<sectionHeader confidence="0.463458" genericHeader="method">
3. Trees, Grammars, and Charts
</sectionHeader>
<subsectionHeader confidence="0.999875">
3.1 Basic Concepts and Terms
</subsectionHeader>
<bodyText confidence="0.806930666666667">
We adopt the standard concepts for syntax trees (see Aho and Ullman [1972, Sect. 0.51
or Partee, ter Meulen, and Wall [1990, Chap. 16] for possible approaches to formaliza-
tion). A syntax tree is a rooted, ordered, labeled tree. Each node apart from the root
</bodyText>
<page confidence="0.995261">
460
</page>
<subsectionHeader confidence="0.185633">
Ritchie Completeness Conditions for Mixed Strategy Bidirectional Parsing
</subsectionHeader>
<bodyText confidence="0.99976875">
has exactly one mother node, and each nonterminal node has one or more daughter
nodes. A tree is said to span the sequence of labels associated with the sequence of
its terminal nodes (in left-to-right order), and we shall also say that the root node of
a (sub)tree spans its sequence of terminal nodes.
</bodyText>
<subsectionHeader confidence="0.913267">
Definition 1
</subsectionHeader>
<bodyText confidence="0.9998845">
The height of a node in a tree is defined as follows. A terminal node has height 0; a
nonterminal node has height = (1 + maximum height of its daughter nodes).
</bodyText>
<subsectionHeader confidence="0.918263">
Definition 2
</subsectionHeader>
<bodyText confidence="0.999984222222222">
The depth of a node in a tree is defined as follows. A root node has depth 0; a nonroot
node has depth = (1 + depth of its parent node).
Following the usual conventions (e.g., Aho and Ullman 1972), we will take a
context-free grammar (CFG) to be a quadruple (VN, VT, P. S), consisting of a set VN
of nonterminal symbols, a set VT of terminal symbols, a set P of rules (productions),
and a single distinguished symbol S E VN. Set theoretically, rules can be regarded as
being ordered pairs where the first element is a nonterminal symbol and the second
is a tuple of symbols, i.e., of the form (A0, (A1,. , Ak)) where k &gt; 0, but for ease of
exposition they will be written as
</bodyText>
<equation confidence="0.763651">
Ao —&gt; Al • • • Ak
</equation>
<bodyText confidence="0.9241715">
We will make the following simplifying assumptions (which do not lose general-
ity):
</bodyText>
<listItem confidence="0.8620734">
1. Each rule in P is either of the form Ao A1A2 Ak with k&gt; 0, where
all the symbols A, E VN, or of the form A —÷ w where w E VT.
2. The grammar has no redundant symbols, in the sense that no symbols
are &amp;quot;useless&amp;quot; or &amp;quot;inaccessible&amp;quot; as defined by Aho and Ullman (1972,
Sect. 2.4.2).
</listItem>
<bodyText confidence="0.9912976">
Rules of the form A —&gt; w where W E VT will be referred to as lexical rules, and other
rules as nonlexical. A nonterminal A that appears in a lexical rule will be called
preterminal, or lexical.
Given a CFG G, a syntax tree based on G is a rooted, ordered tree whose nonter-
minal nodes are labeled with elements of VN and whose terminal nodes are labeled
with elements of VT. Those nodes immediately dominating terminal nodes will be
referred to as preterminal; other nonterminal nodes will be referred to as nonlexical.
Where a tree T spans a terminal string al . an, and M is a node within T that spans
a1. ak, the start of M is the index i — 1, and the end of M is the index k.
A syntax tree based on (VN, VT, P. S) is said to be well-formed with respect to
(VN, VT, P, S) if for every nonterminal node with label Ao and daughter nodes labeled
A1,. , Ak, there is a rule in P of the form Ao —&gt; Ai . Ak; this rule is said to license
the node labeled Ao. For convenience, we shall distinguish between a tree that is
compatible with the rules of the grammar, and a tree that also spans a sentence. A
syntax tree is said to be generated by a grammar G iff:
</bodyText>
<listItem confidence="0.63154">
1. The root node is labeled with S (the distinguished symbol).
2. The tree is well-formed w.r.t. G.
</listItem>
<page confidence="0.996988">
461
</page>
<note confidence="0.43425">
Computational Linguistics Volume 25, Number 4
</note>
<bodyText confidence="0.9918477">
We will write trees (G) for the set of all trees generated by G.
The conventional &amp;quot;rewrite&amp;quot; interpretation of CFGs will also be used in some sit-
uations (Section 5 below). Given two strings col, w2 from (VN U Vr)*, then wi directly
derives w2, written &amp;quot;w1 w2,&amp;quot; if col = SA&apos;-y, co2 = 6a-y and A a is a rule in G. Sim-
ilarly, col derives w2, written &amp;quot;wl 4 co2,&amp;quot; is the reflexive transitive closure of directly
derives. A derivation is a sequence of symbol strings wl, ,w„ such that wi cowl
for all 1 &lt; i &lt; n. A rightmost derivation is one in which each step from w, to co,+1 is
made by replacing the furthest right nonterminal symbol in wi using some rule (i.e.,
-y in the above definition of directly derives is entirely made up of terminal symbols)
(cf. Aho and Ullman 1972).
</bodyText>
<subsectionHeader confidence="0.999967">
3.2 Annotated Grammars
</subsectionHeader>
<bodyText confidence="0.9997946">
Since we are allowing trigger elements of a rule to occur anywhere on the RHS of a rule,
it is necessary to allow the parser to explore outwards in either direction (leftwards
or rightwards) from a constituent that has been parsed. Hence the parsing schemes
defined below are referred to as bidirectional, to reflect this fact. This does not allude
to the two &amp;quot;directions” of top-down or bottom-up.
</bodyText>
<equation confidence="0.870563">
Definition 3
Let G be a context-free grammar (VN,VT,P, 5). A bidirectional strategy marking of
G is a (total) function tr from the nonlexical rules in P to P(N) (the set of sets of
nonnegative integers) such that for any rule r of the form Ao Ai • • • Ak:
1. tr(r) 0
2. 0 &lt; i &lt; k for every i E tr(r)
</equation>
<bodyText confidence="0.9932494">
Informally, tr indicates which element(s) of the rule can trigger it. If 0 E tr(r), the
LHS of the rule is a trigger; that is, it can be used top-down. If j E tr(r), where j&gt; 0,
then element j of the RHS can act as a trigger, bottom-up. The value of tr(r) is a set of
integers in order to allow a rule to have more than one possible trigger; in particular,
it is allowable for a rule to be used either top-down or bottom-up.
</bodyText>
<subsectionHeader confidence="0.924584">
Definition 4
</subsectionHeader>
<bodyText confidence="0.9997525">
A bidirectionally strategy-marked context free-grammar (BSCFG) is a pair (G, tr)
where G is a CFG and tr is a bidirectional strategy marking of G.
</bodyText>
<subsectionHeader confidence="0.905744">
Definition 5
</subsectionHeader>
<bodyText confidence="0.977407">
Let ((VN, VT, P. S), tr) be a bidirectionally strategy-marked context-free grammar. Then
a rule r E P is said to be:
</bodyText>
<listItem confidence="0.99646925">
1. top-down, if 0 E tr(r).
2. bottom-up, if there is an i&gt; 0 such that i E tr(r).
3. purely bottom-up, if 0 tr(r).
4. purely top-down, if tr(r) = {0}.
</listItem>
<subsectionHeader confidence="0.999652">
3.3 Active Charts
</subsectionHeader>
<bodyText confidence="0.982775">
The techniques and structures known as active charts have been in use for parsing
(at least in the area of natural language processing) since the early 1970s. The method
</bodyText>
<page confidence="0.997448">
462
</page>
<subsectionHeader confidence="0.185366">
Ritchie Completeness Conditions for Mixed Strategy Bidirectional Parsing
</subsectionHeader>
<bodyText confidence="0.9991114">
is a generalization of Earley&apos;s algorithm (Earley 1970), and tutorial expositions of the
ideas can be found in Thompson and Ritchie (1984) or Winograd (1983). In keeping
with more recent presentations (e.g., Shieber, Schabes, and Pereira 1995; Sikkel and op
den Akker 1996) we define the parsing principles as well-formedness conditions on
complete charts, abstracting away from the sequence of steps used to build them.
</bodyText>
<subsectionHeader confidence="0.838684">
Definition 6
</subsectionHeader>
<bodyText confidence="0.886189">
Given a CFG G of the form (VN, VT, P. S) a double-dotted rule based on G is a triple
</bodyText>
<equation confidence="0.954668">
(p,1,r) where p is a rule in P of the form Ao —&gt; k and 1,r are integers such that
0 &lt;1 &lt; r &lt; k.
Such a rule will be written as:
Ao A1 ...AI. Ai±i • • • Ar • Ard-i • • • Ak
</equation>
<bodyText confidence="0.998798">
for ease of exposition and similarity to previous literature. Where either 1 = 0 or r = k,
the empty portions will be omitted from the expression.
</bodyText>
<subsectionHeader confidence="0.883245">
Definition 7
</subsectionHeader>
<bodyText confidence="0.995832111111111">
Given a CFG G = (VN, VT, P, S), an edge based on G is a triple (i, j, d) where i and j
are nonnegative integers with i &lt; j, and d is a double-dotted rule based on G.
An edge is said to be lexical or nonlexical according to whether or not the rule is
lexical. An edge of the form (i,j, A0 —&gt; A1 • Aq. Ap • Ap±i Ak) where either
q &gt; 1 or p &lt; k (i.e., with a nonempty component at either end) is referred to as
an active edge, and an edge of the form (i,j,A0 —&gt; eA1 ...At.) is an inactive edge.
An active edge (i, i,A0 --4 • • A1 ...Ak) or (i, A0 -4 Ai ... k • .) is referred to as an
empty active edge. (Sometimes it will be referred to as &amp;quot;an empty active edge for
Ao --&gt; Ai . • • Aro&amp;quot;)
</bodyText>
<subsectionHeader confidence="0.901919">
Definition 8
</subsectionHeader>
<bodyText confidence="0.997327333333333">
Given a CFG G = (VN, VT, P. S) and a string a1,. ,a„ from V;-`, a chart based on
al, , an and using G is a set C of edges based on G that meets the following condi-
tions:
</bodyText>
<listItem confidence="0.9993375">
1. for every (i,j, r) tiC, i E {0, ... ,n} and j c {0, ...,
2. for ai c VT, (i - 1,i, L —&gt; •ai.) E C iff a, E .,a} and L ai ti P.
</listItem>
<bodyText confidence="0.980226">
The terminology of the last three definitions will also be used for a BSCFG (G, tr).
</bodyText>
<subsectionHeader confidence="0.916618">
Definition 9
</subsectionHeader>
<bodyText confidence="0.9970815">
Let G be a CFG, and let C be a chart based on a string a and using G. C is said to be
bidirectionally resolved iff both the following conditions hold:
</bodyText>
<listItem confidence="0.541049">
1. Left Extension: For every pair of edges:
Ao —&gt; 0,41 .Am.)
k, Bo Bq • B 0_1 Bp • Bp±i
</listItem>
<bodyText confidence="0.973186">
where p &lt; v,q &gt; 0 and Ao = Bq, there is also an edge:
</bodyText>
<equation confidence="0.453664">
(i, k, Bo —&gt; Bi Bq_i • Bq . Bp • Bp+1 • • • BV)
</equation>
<page confidence="0.998353">
463
</page>
<figure confidence="0.1219295">
Computational Linguistics Volume 25, Number 4
2. Right Extension: For every pair of edges:
(i, j, Bo . • • Bq • Bq+1 • • • Bp • Bp+i • • • Bv)
k, Ao -4 *Ai Am.)
</figure>
<bodyText confidence="0.904676">
where p &lt; v,q &gt; 0 and Ao = Bp+i, there is also an edge:
</bodyText>
<equation confidence="0.900225571428571">
(i, k, Bo -4 Bi • • . Bq • B0-1 . Bp+i • Bp+2 • • • Bv)
Lemma 1
Let C be a bidirectionally resolved chart based on a string a and using a CFG G, and
suppose that C contains an edge of the form:
(i, j, Bo Bi Bq • Bq+1 Bp • Bp+i Bv)
(i) (Rightwards) If C contains edges of the form:
(ip+Dip+1, Bp+1 111Wp+141)
(iP+t p-Ft Bp+t OWp _t•)
where (p + t) &lt; v, ik±i = jk where (p + 1) &lt; k &lt; (p + t) and ip+1 =j, then C
also contains an edge of the form:
jp+t, Bo B1 • • • Bq • Bil-1-1 • • • Bp+t • Bp+t+1 • • • Bv)
(ii) (Leftwards) If C contains edges of the form:
(i(q-t), (q-t), B(q-t)
(iq, jq, Bq *wq•)
</equation>
<bodyText confidence="0.9969275">
where 0 &lt; t &lt; q, ik-f -1 = jk where (q t) &lt; k &lt; q and jg = i, then C also
contains an edge of the form:
</bodyText>
<equation confidence="0.956155285714286">
BO —&gt; B1 • • B(q-t-i) • B(q_t) . Bp • Bp+1 • • • By)
Proof
Both the cases (i) and (ii) proceed by induction on the number of inactive edges.
Corollary
If C is as described, and it contains a full set of edges as given at both sides (i.e.,
t = (q — 1), so that there are q inactive edges to the left, and (p + t) = v so that there
are (v — p) inactive edges to the right, all with labels matching the rule), then there is
</equation>
<bodyText confidence="0.9899008">
a complete (inactive) edge of the form (ii,fv, Bo •Bi B„. )
A chart parser is driven by two principles: one is that of edge combination, as given
in the above definition of bidirectionally resolved, and the other is the introduction of
rules into the chart. For a strategy-marked grammar, the rule-introduction principle is
sensitive to the annotation of the rules.
</bodyText>
<page confidence="0.998098">
464
</page>
<figure confidence="0.5925482">
Ritchie Completeness Conditions for Mixed Strategy Bidirectional Parsing
Definition 10
Let (G,tr) be a BSCFG, and let C be a chart based on a string a and using G. C is said
to be bidirectionally mixed strategy explored iff all the following conditions hold:
1. (Bottom-up activation) For every edge:
Ao —&gt; •Al A,ne)
there is an edge in C:
Bo B1 • . .Bq_i • Bq • Bq.4..1 • • • By)
for every rule r in G of the form Bo —&gt; B1 . . By such that q E tr(r) and
Bq = Ao,
</figure>
<listItem confidence="0.816572">
2. (Top-down initialization) For every rule r in G of the form S —&gt; B1 . • • Bk,
where S is the distinguished symbol of G and 0 E tr(r), there is an edge
in C of the form:
(0, 0, S —&gt; • • Bi • • • Bk)
3. (Top-down activation, right) For every edge:
</listItem>
<equation confidence="0.491578">
(i, j, Bo —+ Bi Bq • Bq+1 Bp • Bp±i . By)
</equation>
<bodyText confidence="0.9980865">
where 0 &lt;p &lt;v, and every rule r in G of the form Ao Ai Ak for
which Bp+i = Ao and 0 E tr(r), there is also an edge in C of the form:
</bodyText>
<equation confidence="0.920434666666667">
(j, j,A0 • • Ai • • • Ak)
4. (Top-down activation, left) For every edge:
(i, j, Bo —&gt; Bi Bn • Bq+1. Bp • Bp+1...Bn)
</equation>
<bodyText confidence="0.956465125">
where 0 &lt; q &lt; v, and every rule r in G of the form Ao ---&gt; A Ak for
which Bq = Ao and 0 E tr(r), there is also an edge in C of the form:
(i, Ao —&gt; Ai . • • Ak • 46)
For brevity, the term fully bidirectional will be used for a chart that is both
bidirectionally resolved and bidirectionally mixed strategy explored.
To explore the issue of completeness (i.e., whether a parsing mechanism finds all
valid analyses) we need to define how the edges in a chart correspond to those in a
syntax tree.
</bodyText>
<subsectionHeader confidence="0.899335">
Definition 11
</subsectionHeader>
<bodyText confidence="0.978541">
A chart C based on a1a2... an is said to contain a representation of a syntax tree T, iff:
</bodyText>
<listItem confidence="0.85815625">
1. T spans a substring (not necessarily proper) of a1a2 ... an; and
2. for every nonterminal node N in T, spanning ai±i ...ay labeled Ao, with
k daughters labeled A1,.. .,Ak in order, C contains an edge
(i, j, A0 —&gt; •A1 . Ake)
</listItem>
<bodyText confidence="0.881451">
(This includes the case where k = 1 and A1 c VT.)
</bodyText>
<page confidence="0.995993">
465
</page>
<note confidence="0.429556">
Computational Linguistics Volume 25, Number 4
</note>
<bodyText confidence="0.9989816">
Notice that for any chart C based on a string a, C will contain an edge for each
preterminal node of any tree that spans a, by virtue of the definition of a chart being
&amp;quot;based on&amp;quot; a string. Hence later discussions of parsing and completeness can assume
the presence of these edges in the relevant charts, with only the presence of edges for
other nonterminal nodes being subject to verification.
</bodyText>
<subsectionHeader confidence="0.934665">
Definition 12
</subsectionHeader>
<bodyText confidence="0.999059333333333">
Given a CFG G, a bidirectional strategy-marking tr of G is said to be complete iff for
every tree T E trees(G) that spans a string a, any fully bidirectional chart C based on
a and using (G,tr) contains a representation of T.
</bodyText>
<sectionHeader confidence="0.779955" genericHeader="method">
4. A Decidable Class of Complete Annotations
</sectionHeader>
<bodyText confidence="0.999867428571429">
In this section we define a decidable property of annotated grammars that guar-
antees that a parser following the annotations will not miss analyses in the man-
ner outlined in Section 2.1. There is also a weaker (more general) sufficient con-
dition for completeness, which is defined in Section 5 below, but which is unde-
cidable. The fact that the stronger condition is decidable makes it worth defining,
and some of the proofs in Section 5 make use of some concepts from the current
section.
</bodyText>
<subsectionHeader confidence="0.998657">
4.1 Reachability
</subsectionHeader>
<bodyText confidence="0.9999295">
Another notion that has to be formalized is the way in which a syntax tree can be
parsed from a string of terminal symbols in a purely bottom-up manner.
</bodyText>
<subsectionHeader confidence="0.91248">
Definition 13
</subsectionHeader>
<bodyText confidence="0.9635195">
Let (G,tr) be a BSCFG. In a syntax tree T generated by G, a nonlexical node Mo,
with daughters Ml,.. . , Mk, is said to be reachable from below iff Mo is licensed by a
bottom-up rule r and there is a j, 1 &lt; j &lt; k, such that] e tr(r) and one of the following
is true:
</bodyText>
<listItem confidence="0.8932025">
1. M is a preterminal node of T;
2. M is reachable from below.
</listItem>
<subsectionHeader confidence="0.87903">
Definition 14
</subsectionHeader>
<bodyText confidence="0.999338333333333">
Let (G,tr) be a BSCFG. A syntax tree T generated by G, is said to be fully reachable
iff every nonlexical node M in T licensed by a purely bottom-up rule is reachable from
below.
</bodyText>
<subsectionHeader confidence="0.999064">
4.2 Direct Analyzability
</subsectionHeader>
<bodyText confidence="0.996937571428571">
Now we need to define a property of grammars that will guarantee that generated
trees are fully reachable in the above sense. This can be done in three stages: first,
define a property of nonterminal symbols; then, use that to define a property of gram-
mars; lastly, prove that any grammar with this property generates only fully reachable
trees.
A first approximation to the definition for the property of nonterminals would be
the following:
</bodyText>
<page confidence="0.997588">
466
</page>
<figure confidence="0.395656">
Ritchie Completeness Conditions for Mixed Strategy Bidirectional Parsing
</figure>
<subsectionHeader confidence="0.643538">
Draft Definition:
</subsectionHeader>
<bodyText confidence="0.97922">
Given a BSCFG (G, tr), a nonterminal symbol Ao is directly analyzable iff every rule
r of the form Ao ... is either lexical, or of the form Ao —&gt; A1 Ak with at least one
i E tr(r), i&gt; 0, for which A, is directly analyzable.
The subsequent definition for grammars is then:
</bodyText>
<subsectionHeader confidence="0.933428">
Definition 15
</subsectionHeader>
<bodyText confidence="0.9977046">
A BSCFG (G, tr) is directly analyzable iff it meets the following condition: for every
purely bottom-up rule r of the form Ao —&gt; A1 .. Ak, there is at least one i E tr(r), i&gt; 0,
for which A, is directly analyzable.
The draft definition captures the essential idea in a fairly natural and clear way,
but it has a slight technical problem. Consider the toy grammar given below:
</bodyText>
<equation confidence="0.9953174">
S—&gt;AB
A —&gt; CA
C —&gt; x
B &gt; y
A — z
</equation>
<bodyText confidence="0.99988125">
In this grammar, the nonterminal A is not classed as directly analyzable. This is be-
cause there is a cycle from A to itself via trigger symbols in bottom-up rules.&apos; It would
be equally consistent with the draft definition to state that A is directly analyzable, or
to stipulate that it is not directly analyzable. There is a sense in which the draft defi-
nition is underspecified, and gives only partial coverage of the items being classified
(nonterminals). To extend this definition to total coverage, a more elaborate construc-
tion is needed (borrowed from theoretical computer science; cf. Stoy [1981, Chap. 6]).3
First, for any BSCFG (G, tr) we define an analyzability predicate as any function g
from nonterminal symbols to the set {true, false} that assigns true to a category Ao
iff every rule r of the form Ao ... is either lexical, or of the form Ao —&gt; Ai . • • Alo
with at least one i E tr(r), i &gt; 0, for which g(A) = true. Call the set of all such func-
tions A&apos;P(G, tr). For any two g,h E A&apos;P(G, tr), define the relation &amp;quot;E&amp;quot; by h g iff
h(A) = true D g(A) = true. This relation is easily shown to be reflexive, transitive, and
antisymmetric, and hence (AP (G, tr), E) forms a partially ordered set (Maclane and
Birkhoff 1967, 59; Stoy 1981, 82). Then for any set gi,• • • , gn of elements of A&apos;P(G, tr),
the function g&apos; (in AP (G, tr)) given by
</bodyText>
<equation confidence="0.3285075">
g&apos; (A) = true iff either gi (A) = true or ... (A) = true
is at least upper bound (Maclane and Birkhoff 1967; Stoy 1981) for • • • ,gt, with
</equation>
<construct confidence="0.9255306">
respect to E. Since AP (G, tr) is finite, the presence of a 1.u.b. for any subset means it has
a maximum element, which we will call APMAX(G,tr). This predicate APMAX(Gm.) will
assign true to a symbol A if there is some analyzability predicate (for (G, tr)) that makes
this assignment.&apos; Then define a nonterminal A (from G) to be directly analyzable iff
APMAX(G,to (A) = true. Intuitively, any nonterminal that the draft definition might
</construct>
<footnote confidence="0.94246275">
2 Thanks to Alistair Willis for pointing out this problem.
3 `Thanks to Suresh Manandhar for suggesting this approach.
4 Stoy (1981, 79-80) illustrates the use of a minimum element from an ordered set of possible functions,
but here we have chosen to use the maximum.
</footnote>
<page confidence="0.994476">
467
</page>
<note confidence="0.42898">
Computational Linguistics Volume 25, Number 4
</note>
<bodyText confidence="0.999857333333333">
leave as undefined with respect to being directly analyzable is classed by this new
definition as being directly analyzable. Instead of the draft definition, we can now
have the following complete definition:
</bodyText>
<subsectionHeader confidence="0.837524">
Definition 16
</subsectionHeader>
<bodyText confidence="0.9864635">
Given a BSCFG (G, tr), a nonterminal symbol Ao is directly analyzable iff
APMAX(G,tr)(A0) = true, where APMAX(G,tr) is as constructed above.
Notice that it follows from the construction of APMAX(GA) that Ao is directly ana-
lyzable iff every rule r of the form Ao ... is either lexical, or of the form Ao —&gt; A1 • • • Ak
with at least one i c tr(r), i &gt; 0, for which A, is directly analyzable. That is, the draft
definition, which was not sufficiently self-contained to be a definition, is now deriv-
able as a theorem from the more rigorous definition. This means that we can use the
logical equivalence stated in the draft definition in subsequent proofs.
</bodyText>
<subsectionHeader confidence="0.538543">
Lemma 2
</subsectionHeader>
<bodyText confidence="0.9943115">
Let (G, tr) be a BSCFG that is directly analyzable. Let T be a tree in trees(G). Then T
is fully reachable.
</bodyText>
<subsectionHeader confidence="0.838979">
Proof
</subsectionHeader>
<bodyText confidence="0.9769576">
It is straightforward to prove the following preliminary result, using induction on the
height of nodes and the logical equivalence stated in the draft definition above:
Any node in T that has a directly analyzable label is reachable from below.
It is then easy to show that any node in T that is licensed by a purely bottom-up rule
is reachable from below. 0
</bodyText>
<subsectionHeader confidence="0.811091">
4.3 Parsing
Lemma 3
</subsectionHeader>
<bodyText confidence="0.838722333333333">
Let (G, tr) be a BSCFG. Let T be a fully reachable tree in trees(G), spanning the string
a. Let C be a fully bidirectional chart based on a and using (G, tr). Then for any node
M in T, labeled A:
</bodyText>
<listItem confidence="0.81645425">
1. If M is licensed by a purely bottom-up rule, then C contains a
representation of the subtree rooted at M.
2. If M is licensed by a top-down rule, and there is in C an active edge
(t, g, Bo Bp_i • Bp .13q_i • Bq
</listItem>
<bodyText confidence="0.999775">
where either Bp_1 = A and t is the end of M, or Bq = A and g is the start
of M, then C contains a representation of the subtree rooted at M.
</bodyText>
<subsectionHeader confidence="0.84599">
Proof
</subsectionHeader>
<bodyText confidence="0.6125748">
By induction on the height of nodes.
Inductive Hypothesis: For any 0 &lt; d&apos; &lt; d, if node M in T is of height d&apos;, the
conditions listed in the lemma hold.
Base Case: Suppose M is of height 1 (i.e., preterminal). Then C contains a repre-
sentation of the subtree rooted at M, regardless of the antecedent conditions.
</bodyText>
<page confidence="0.991719">
468
</page>
<table confidence="0.4425455">
Ritchie Completeness Conditions for Mixed Strategy Bidirectional Parsing
Inductive Step: Suppose M is of height d, where d&gt; 1, and is labeled A.
</table>
<listItem confidence="0.840778">
(a) Suppose M, with daughter nodes M1,. Mk, is licensed by a purely
bottom-up rule A —&gt; A1 Ak. Then, since T is fully reachable, there is a
j, 1 &lt;j &lt; k such that Mj is reachable from below; that is, Mi is either
lexical or licensed by a bottom-up rule. Therefore, by the Inductive
Hypothesis, C contains a representation of the subtree rooted at Mi. Since
C is fully bidirectional, it contains an edge spanning M1 of the form:
</listItem>
<bodyText confidence="0.931628125">
(I,h, A —&gt; A1.. .A1_1 .A • 4,±1 . • .A)
Now consider the nodes A, for j + 1 &lt; i &lt; k. The Inductive Hypothesis
applies to each of these nodes. Hence it can be proved by induction on i
that there is a representation in C of the subtree rooted at A for all
j + 1 &lt; i &lt; k (cf. Lemma 1). Similarly, it can be proved that there are
representations in C for the subtrees rooted at M1, ...,Mj_i. By the
corollary to Lemma 1, there is a representation for the tree rooted at M
in C.
</bodyText>
<listItem confidence="0.795835">
(b) Suppose M is licensed by a top-down rule. Suppose there is an edge
</listItem>
<equation confidence="0.468231">
(t, g, Bo --&gt; 131 Bp_i • Bp . .Bq-i • Bq •Bv)
</equation>
<bodyText confidence="0.999695666666667">
where Bq = A and g is the start of M (a similar argument holds in the
case where Bp_1 = A and t is the end of M). Since the chart is fully
bidirectional, there must also be an empty active edge
</bodyText>
<equation confidence="0.452091">
(g, g, A • • Al • • • AO
</equation>
<bodyText confidence="0.998877">
By a similar argument to that in case (a) above, it follows that there are
representations in C for all the nodes Ml,. . . , Mk and thence for M.
This establishes the main induction. 0
</bodyText>
<subsectionHeader confidence="0.655165">
Lemma 4
</subsectionHeader>
<bodyText confidence="0.924967">
Let (G, tr) be a BSCFG that is directly analyzable. Let T be a tree in trees(G), spanning
the string a. Let C be a fully bidirectional chart based on a and using (G, tr). Then for
any node M in T, labeled A:
</bodyText>
<listItem confidence="0.999371333333333">
1. If M is licensed by a purely bottom-up rule, then C contains a
representation of the subtree rooted at M.
2. If M is licensed by a top-down rule, and there is in C an active edge
</listItem>
<equation confidence="0.432623">
(t, g, Bo —&gt; Bi Bp_i • Bp Bq_i • Bq 13„)
</equation>
<bodyText confidence="0.9997525">
where either Bp_1 = A and t is the end of M, or Bq = A and g is the start
of M, then C contains a representation of the subtree rooted at M.
</bodyText>
<subsectionHeader confidence="0.66413">
Proof
</subsectionHeader>
<bodyText confidence="0.936408">
Follows from Lemmas 2 and 3. 0
</bodyText>
<page confidence="0.997182">
469
</page>
<note confidence="0.635284">
Computational Linguistics Volume 25, Number 4
</note>
<bodyText confidence="0.999190133333334">
Being reachable from below can be seen as a condition on nodes that can be built
bottom-up. Surprisingly, we do not need a corresponding condition for nodes that
are built top-down. It is possible to formulate the appropriate condition, but it turns
out that any tree that meets the condition of being fully reachable will also meet the
appropriate condition for top-down nodes. It is hard to give an informal, intuitive
explanation for this, but roughly speaking, the reason is as follows. For a top-down
rule to be invoked, it must be used in a position at which some prediction of its LHS
symbol A will be introduced (by some other rule). This can happen either as a cascade
of predictions from above, using a sequence of top-down rules, or because a rule has
been introduced and has caused a sequence of predictions to be made, either left-
to-right or right-to-left, as its RHS symbols are parsed. For either of these to happen,
either there must be a clear path of daughter categories from some other prediction, or
A must be on the RHS of a rule that is somehow introduced. The daughter condition
of &amp;quot;reachable from below&amp;quot; simultaneously imposes these conditions on the top-down
rules.
</bodyText>
<subsectionHeader confidence="0.997378">
4.4 Completeness
</subsectionHeader>
<bodyText confidence="0.993038">
The final step in proving completeness is now simple.
</bodyText>
<subsectionHeader confidence="0.480472">
Theorem 1
</subsectionHeader>
<bodyText confidence="0.905212">
If a BSCFG (G, tr) is directly analyzable, then tr is complete.
</bodyText>
<subsectionHeader confidence="0.817304">
Proof
</subsectionHeader>
<bodyText confidence="0.996626333333333">
Let T be a tree in trees(G), spanning the string a, with root node Mo labeled S (the
distinguished symbol of G). Let C be a fully bidirectional chart based on o- and using
(G, tr).
</bodyText>
<listItem confidence="0.8407308">
(a) If Mo is licensed by a bottom-up rule, then by Lemma 4, C contains a
representation of the tree rooted at Mo•
(b) If Mo is licensed by a top-down rule S —&gt; A1,. , Ak, then C must contain
an empty active edge of the form:
(0, 0, S ---&gt; • • Ai . • • Ak)
</listItem>
<bodyText confidence="0.999091">
It follows from repeated applications of Lemma 4 and Lemma 1 (similar
to part (b) of the Inductive Step of Lemma 3) that C contains a
representation of the subtrees rooted at the daughters of Mo, and thence
of the subtree rooted at Mo• 0
Thus we have proved that all BSCFGs that meet the condition of being directly
analyzable can be bidirectionally parsed without any valid trees being omitted.
</bodyText>
<subsectionHeader confidence="0.604426">
Theorem 2
</subsectionHeader>
<bodyText confidence="0.97391">
It is decidable whether a given BSCFG is directly analyzable.
</bodyText>
<subsectionHeader confidence="0.446103">
Proof
</subsectionHeader>
<bodyText confidence="0.4216095">
This is straightforward to verify from the definition of directly analyzable (see Ap-
pendix A for an algorithm).
</bodyText>
<page confidence="0.974585">
470
</page>
<figure confidence="0.260867">
Ritchie Completeness Conditions for Mixed Strategy Bidirectional Parsing
5. An Undecidable Class of Complete Annotations
</figure>
<subsectionHeader confidence="0.984823">
5.1 Informal Outline
</subsectionHeader>
<bodyText confidence="0.999666222222222">
Before proceeding to formalize the mechanisms underlying the problem presented in
Section 2.2, it is useful to set out informally the relevant factors in that example. A
strategy-marked grammar (G,tr) causes problems only if there is some purely bottom-
up rule of the form Ao A1 . Ak such that every trigger symbol At requires a purely
top-down rule somewhere in its expansion (see Section 4.2 above). Such a rule leads to
the possibility of there being a tree T E trees(G) that contains a nonterminal node that
can only be built by a bottom-up rule, and whose trigger daughter can only be built
using a top-down rule. This would give rise to a tree that was not fully reachable. In
the example in Section 2.2 above, the rules
</bodyText>
<equation confidence="0.898215">
H B F
B--413Q
</equation>
<bodyText confidence="0.999976208333333">
create this situation. The &amp;quot;upper&amp;quot; symbol H cannot be parsed because the &amp;quot;lower&amp;quot;
symbol B cannot be parsed. What salvages this difficulty is the fact that the &amp;quot;upper&amp;quot;
nonterminal (H in this example) always occurs in a left context, (i.e., a string of sym-
bols to its left) with the following property: Every possible terminal expansion of the
left context contains a substring that will, via bottom-up rules, introduce rules that are
bound to result in the introduction of an active edge, which starts at the point where
the &amp;quot;upper&amp;quot; symbol (H) is needed and which is seeking the &amp;quot;lower&amp;quot; symbol (B).
The illustrative grammars in Sections 2.1 and 2.2 are of a particular subclass of
grammars—those where tr(r) = {0} or tr(r) = {1} for any (nonlexical) rule r. This is
equivalent to partitioning the rules into two subgroups—top-down and bottom-up—
where the bottom-up rules are always triggered in a left-corner manner, much as in
conventional &amp;quot;bottom-up&amp;quot; chart parsers (such as those in Thompson and Ritchie [1984]
or Winograd [1983]). That is, there is a natural subclass of annotated grammars that
do not rely on the bidirectional exploration of the chart, but allow this limited form
of mixed strategy left-to-right exploration.
The definitions and proofs of the earlier sections apply to this subclass. It is also
clear, from Section 2.2, that the issue of &amp;quot;completeness by interaction&amp;quot; can be illustrated
within this limited subclass. In the remainder of Section 5 below, it is proved that
detecting the possibility of such rule interactions is undecidable even for this limited
subclass of grammars. It follows that it must be undecidable for the more general
class, where any annotation is permitted. The advantages of focusing on this more
limited subclass are twofold: it shows that restricting the annotations in this way
would not ease the undecidability problem, and it simplifies the proofs (which are
already tediously complex).
</bodyText>
<subsectionHeader confidence="0.821084">
Definition 17
</subsectionHeader>
<bodyText confidence="0.999654857142857">
A left-corner strategy-marked context-free grammar (LCSCFG) is a BSCFG (G,tr) such
that tr(r) c {0, 1} for every rule r in G.
This definition allows a rule to be both bottom-up and top-down marked, rather
than enforcing a strict partitioning. In the following proofs, we will define constructs
for BSCFGs where possible, simply for generality, but where it matters we shall confine
attention to LCSCFGs, thereby narrowing the range of contexts relevant to parsing a
particular symbol.
</bodyText>
<page confidence="0.992587">
471
</page>
<note confidence="0.597496">
Computational Linguistics Volume 25, Number 4
</note>
<subsectionHeader confidence="0.997123">
5.2 Left Contexts
</subsectionHeader>
<bodyText confidence="0.999504333333333">
Following from the informal discussion in Section 5.1 above, we need to define more
precisely the notion of a left context of a symbol. What we want is a way of charac-
terizing, for a given nonterminal A, exactly those strings of symbols that must appear
immediately to the left of A in any valid derivation in which A appears. These need
not be all that is to the left of A in a derivation, but it must be the case that A cannot
appear without having one of these left context strings immediately adjacent to it.
In the following definitions, the derivation relationship &amp;quot; is the conventional
one, and is independent of any strategy marking; the relationship &amp;quot;i&amp;quot; indicates a
rightmost derivation (see Section 3.1 earlier).
</bodyText>
<subsectionHeader confidence="0.770285">
Definition 18
</subsectionHeader>
<bodyText confidence="0.8867975">
Suppose we have a context-free grammar (VN,VT,P, S), and a sequence of symbols
B1, . . . , Bt in VN, where there are rules B, -4 pi--03,-10,-1 for 2 &lt; i &lt; t E 11k).
Suppose we have a rightmost derivation of the form:
Bt
</bodyText>
<listItem confidence="0.9815783">
• Pt-lPt-2Bt-2Wt-2
• Pt-lPt-2 • • -B2W2
• Pt-lPt-2 • • • piBiwi
(all the wi E Vi). This derivation is said to be:
1. nonrepeating if B, Bi whenever i j.
2. rooted if Bt = S.
3. localized if there is a longer sequence of nonterminal symbols B1, ,B„,
and a rooted rightmost derivation Bm 14 Pm-I • .. piBico; such that Br = Bk
for some t &lt; k &lt; m.
4. essential if it is nonrepeating and either rooted or localized.
</listItem>
<bodyText confidence="0.897248">
Also, the derivation is said to be for B1 from Bt, and the string pt_i p1 is said to be
the left context sequence of this derivation.
</bodyText>
<subsectionHeader confidence="0.903534">
Definition 19
</subsectionHeader>
<bodyText confidence="0.946669444444444">
For any nonterminal A, the set of essential left contexts of A is
{a c 17.1,` 3 an essential rightmost derivation D for A and &apos;;/) is the left
context sequence of D and 04 a}
The following lemma proves that essential left contexts have just the required
property.
Lemma 5
Let G be a CFG. Let T be a tree in trees(G). Let M be a nonterminal node in T. Let a
be the terminal string spanned by T, and 5 the portion of a spanned by M. Then a is
of the form 01-y802 for some -y in the essential left contexts of the label of M.
</bodyText>
<page confidence="0.993895">
472
</page>
<figure confidence="0.996371">
Ritchie Completeness Conditions for Mixed Strategy Bidirectional Parsing
Pk-1 P1
8
0
</figure>
<figureCaption confidence="0.99629">
Figure 1
</figureCaption>
<bodyText confidence="0.539181">
Situation described in Lemma 5.
</bodyText>
<subsectionHeader confidence="0.891047">
Proof
</subsectionHeader>
<bodyText confidence="0.999083428571429">
(See Figure 1 for an intuitive picture.) Since T is a tree, there is a path of nonterminal
nodes (N1,. , Nt) where Ni is labeled B„ for 1 &lt; i &lt; t, N1 = M,Nt is the root of
T, and Nt is the mother of N,_1 for 2 &lt; i &lt; t . Since T e trees(G), there must be a
sequence of rules Bi -&gt; Pi-iBI-1131-1 (PA E 171v`) such that the node N, is licensed by
B, -&gt; pi-031-01-1 for 2 &lt; i &lt; t. Hence there is a rooted rightmost derivation for Bi
from B. From this it is trivial to form an essential rightmost derivation for B1 from
some symbol Bk (where k
</bodyText>
<equation confidence="0.789636333333333">
Bk 4 pk_1• • • piBicoi
where wi E V and
Pk-1 • • • P1B1Wi 4 0
</equation>
<bodyText confidence="0.9974568">
where 0 is the substring of a spanned by Nk-
This means that 0 is of the form -y6coi where pk_i p1 r -y and B1 6 (since B1 is
the label of M, and 6 is the terminal string spanned by M). Then 7 is an essential left
context of B1, by virtue of the way Pt-i p1 was constructed. Since 0 is a substring
of o-, this establishes the result.
</bodyText>
<page confidence="0.998484">
473
</page>
<note confidence="0.584248">
Computational Linguistics Volume 25, Number 4
</note>
<subsectionHeader confidence="0.9066">
5.3 Bottom-up Derivations
Definition 20
</subsectionHeader>
<bodyText confidence="0.984011666666667">
In a BSCFG (G, tr), suppose A is a nonterminal symbol, and o- is a string of terminal
symbols. Then o- can be coherently derived from A (with tree T) iff T is a syntax tree
generated by G such that:
</bodyText>
<listItem confidence="0.995219666666667">
1. T spans o-
2. the root of T is labeled A
3. T is fully reachable.
</listItem>
<bodyText confidence="0.97528">
The next definition requires that the derivation can occur without need for top-
down initiation.
</bodyText>
<subsectionHeader confidence="0.719454">
Definition 21
</subsectionHeader>
<bodyText confidence="0.959270666666666">
Let (G, tr) be a BSCFG. Suppose A is a nonterminal symbol, and o- is a string of terminal
symbols, from G . Then o- can be up-derived from A (written &amp;quot;A ft* a&amp;quot;) using (G, tr)
iff:
</bodyText>
<listItem confidence="0.9942155">
1. a- can be coherently derived from A with tree T;
2. the root of T is reachable from below.
</listItem>
<bodyText confidence="0.9885135">
It is clear that all nodes of such trees will appear in a chart, as formalized in
Lemma 6.
</bodyText>
<subsectionHeader confidence="0.679571">
Lemma 6
</subsectionHeader>
<bodyText confidence="0.999721">
Let (G, tr) be a BSCFG. If A -11* a using (G, tr), and C is a fully bidirectional chart based
on a string -y10--y2, and using (G, tr), then C contains a representation of a tree T such
that T spans o- and the root of T is labeled A.
</bodyText>
<subsectionHeader confidence="0.90906">
Proof
</subsectionHeader>
<bodyText confidence="0.986069">
Follows from Lemma 3. 0
</bodyText>
<subsectionHeader confidence="0.998262">
5.4 Left-Introducible Rules
</subsectionHeader>
<bodyText confidence="0.9999945">
In characterizing formally the situation outlined informally in Section 5.1 above, the
following definition allows a more succinct statement.
</bodyText>
<subsectionHeader confidence="0.768565">
Definition 22
</subsectionHeader>
<bodyText confidence="0.879577">
Let A, B be two nonterminal symbols from a LCSCFG. A introduces B from above
(written &amp;quot;A ,,,+ B&amp;quot;) if either A = B, or there is a sequence of top-down rules
</bodyText>
<equation confidence="0.952616666666667">
A —&gt; A0 . . .
Ao —&gt; A1 . . .
At B . . .
</equation>
<page confidence="0.995229">
474
</page>
<figure confidence="0.977771">
Ritchie Completeness Conditions for Mixed Strategy Bidirectional Parsing
X pl
</figure>
<figureCaption confidence="0.715368">
Figure 2
</figureCaption>
<equation confidence="0.3120105">
Left-introducibility.
Lemma 7
</equation>
<bodyText confidence="0.93530625">
Let A,B be two nonterminal symbols from a LCSCFG (G,tr). If A B, then in
any bidirectionally mixed strategy explored chart C using (G,tr) that contains an ac-
tive edge (i, j, A&apos; —&gt; *al • A/31), there will also be an active edge in C of the form
(1, j,A&amp;quot; .a2 B02), where either / = i or 1 = j.
</bodyText>
<subsectionHeader confidence="0.727931">
Proof
</subsectionHeader>
<bodyText confidence="0.9984954">
Straightforward. The case 1 = i allows for A = B (and A&apos; = A&amp;quot;), and 1 = j is the more
general case where there is a sequence of top-down-invoked active edges linking A
to B.
Next we have a definition of the condition on rules that allows them to enter into
the parsing process despite the difficulties outlined in Section 2.1 above.
</bodyText>
<subsectionHeader confidence="0.825189">
Definition 23
</subsectionHeader>
<bodyText confidence="0.987388">
In a LCSCFG (G,tr), a rule Bo —&gt; Bi a is said to be left-introducible iff for every -y that
is an essential left context of Bo, there is a bottom-up rule Ao Ai ... k such that
</bodyText>
<listItem confidence="0.813576125">
1. -y = xpi p, for some i &lt; k
2. Ai 1r Pi
3. pi can be coherently derived from A, for all 1 &lt;j &lt; i
4. 11,±1 Bo
Scrutiny of this definition should reveal its relationship to the informal outlines in
Sections 2.2 and 5.1 earlier (see also Figure 2). Notice that for any nonterminal A, if
S 4 A... then the empty string is an essential left context of A and hence any rule of
the form A —&gt; ... cannot be left-introducible.
</listItem>
<subsectionHeader confidence="0.663374">
Lemma 8
</subsectionHeader>
<bodyText confidence="0.9948645">
Let (G,tr) be a LCSCFG. Let T be an annotated tree generated by G, and Mo a nonlexical
node in T whose leftmost daughter is Mi, with Mo labeled Bo, Mi labeled Bi, and where
</bodyText>
<page confidence="0.997512">
475
</page>
<note confidence="0.635176">
Computational Linguistics Volume 25, Number 4
</note>
<bodyText confidence="0.962955666666667">
the start of both Mo and M1 is m. Suppose that the rule Bo Bi ... licensing Mo in T
is left-introducible. Then in any fully bidirectional chart based on the terminal string
spanned by T and using (G, tr), there is an active edge of the form
</bodyText>
<equation confidence="0.598969">
(1, m, A —&gt; •ct • BO)
</equation>
<bodyText confidence="0.878828">
(i.e., an edge at the start of Mo,Mi, seeking Bo).
</bodyText>
<subsectionHeader confidence="0.863951">
Proof
</subsectionHeader>
<bodyText confidence="0.999874">
Let the string spanned by T be a, with a = a16a2, where S is spanned by Mo. Let C be
a fully bidirectional chart based on a and using (G, tr). By Lemma 5, an is of the form
q5ry where -y is in the essential left contexts of Bo. Since Bo —&gt; B1 ... is left-introducible,
every such -y has the property that there is a bottom-up rule Ao —&gt; A1 Ak such that
</bodyText>
<listItem confidence="0.99921925">
• = XPi • • • pi
• Ai -11-* Pi
• pi can be coherently derived from Aj, 1 &lt;j &lt; i
• A,+i &apos;‘-&amp;quot;› BO
</listItem>
<bodyText confidence="0.776529">
It follows from Lemma 6 that, since Ai &apos;ft* pi, there are inactive edges in C for all
nodes of a tree with root label A1 spanning pi. Since Ao —&gt; A1 Ak is bottom-up, this
means there is an active edge in C
</bodyText>
<equation confidence="0.736643">
AO 0A1 • A2 • • • Ak)
</equation>
<bodyText confidence="0.831485">
where j is the start of the inactive edge for the root of this tree (i.e., the node labeled
A1), and j&apos; is its end. By Lemma 1 and Lemma 4, there are inactive edges in C labeled
A2, , Ai, corresponding to nodes spanning p2 p,. By Lemma 1, there is an edge
(i, Ao —&gt; •Ai . • Ai • Ai±i • • • Ak)
where m is the start of S. Since Awl Bo, by Lemma 7 there is an active edge
(/, m, A —+ ea • B00)
</bodyText>
<subsectionHeader confidence="0.993925">
5.5 Indirect Analyzability
</subsectionHeader>
<bodyText confidence="0.999821333333333">
In Section 4 we defined direct analyzability as a condition on grammars that would
lead to complete parsing. Now we establish a more general property that also leads
to completeness.
</bodyText>
<subsectionHeader confidence="0.846268">
Definition 24
</subsectionHeader>
<bodyText confidence="0.7751345">
Let (G, tr) be a LCSCFG. A nonterminal symbol Ao in G is said to be indirectly an-
alyzable iff every rule Ao —&gt; w is either lexical, or top-down and left-introducible, or
bottom-up of the form Ao -.4 Ala where A1 is indirectly analyzable.&apos;
5 Like the definition of directly analyzable in Section 4, this strictly needs a more detailed definition to
allow for cycles. This is straightforward to provide, in exactly the manner used in that earlier section,
and then the &amp;quot;definition&amp;quot; given here becomes a theorem about indirect analyzability.
</bodyText>
<page confidence="0.994458">
476
</page>
<table confidence="0.2700825">
Ritchie Completeness Conditions for Mixed Strategy Bidirectional Parsing
Definition 25
</table>
<bodyText confidence="0.98755225">
A LCSCFG (G, tr) is indirectly analyzable iff for every purely bottom-up rule Ao Ala,
the nonterminal symbol A1 is indirectly analyzable.
The next two lemmas ensure that a grammar with the property of indirect ana-
lyzability leads to complete parses. The first is just a generalization of Lemma 4.
</bodyText>
<subsectionHeader confidence="0.927484">
Lemma 9
</subsectionHeader>
<bodyText confidence="0.990630333333333">
Let (G, tr) be a BSCFG that is indirectly analyzable. Let T be a tree in trees(G), spanning
the string a. Let C be a fully bidirectional chart based on a and using (G, tr). Then for
any node M labeled A in T:
</bodyText>
<listItem confidence="0.998704">
1. If M is licensed by a purely bottom-up rule, then C contains a
representation of the subtree rooted at M.
2. If M is licensed by a top-down rule, and there is in C an active edge
</listItem>
<equation confidence="0.606084">
(t, g, Bo —&gt; Bp_i • Bp Bq _1 • Bq An)
</equation>
<bodyText confidence="0.9998365">
where either Bp_i = A and t is the end of M, or Bq = A and g is the start
of M, then C contains a representation of the subtree rooted at M.
</bodyText>
<subsectionHeader confidence="0.941308">
Proof
</subsectionHeader>
<bodyText confidence="0.998219384615385">
By induction on the height of nodes, in a manner very similar to Lemma 3, except
that part (a) of the Inductive Step is as follows:
Inductive Step(a): Suppose Mo, with daughter nodes Mi, ,Mk, is
licensed by a purely bottom-up rule Ao —&gt; Ai A. Then, since (G, tr) is
indirectly analyzable, this means that Ai is indirectly analyzable. Hence
whatever rule licenses Mi, it must be either lexical, or top-down and
left-introducible, or bottom-up with an indirectly analyzable symbol at
the start of its RHS. In the lexical and bottom-up cases, the Base Case and
Inductive Hypothesis establish that C contains a representation of the
tree rooted at Mi. If the rule is top-down and left-introducible, there is an
edge seeking its LHS symbol at the start of Mi, and so, by the Inductive
Hypothesis, there is a representation of the tree rooted at Mi in C. Since
C is fully bidirectional, it contains an edge spanning M1 of the form:
</bodyText>
<equation confidence="0.815432">
(1, h, Ao —&gt; •Ai • A2 Ak)
</equation>
<bodyText confidence="0.990085">
Repeated applications of the Inductive Hypothesis and Lemma 1
(Corollary) establish that there is a representation of the tree rooted at
Mo in C (i.e., the Inductive Step).
</bodyText>
<subsectionHeader confidence="0.905238">
Lemma 10
</subsectionHeader>
<bodyText confidence="0.9993608">
Suppose (G, tr) is an indirectly analyzable LCSCFG. Suppose T E trees(G), and C is
a fully bidirectional chart based on the string spanned by T and using (G, tr). Then
for any nonroot node M in T, if M is licensed by a top-down rule A —&gt; w, then C
contains an active edge at the start of M of the form (ti, t2, Bo —&gt; a • • A...) (i.e.,
seeking A).
</bodyText>
<page confidence="0.994595">
477
</page>
<note confidence="0.656566">
Computational Linguistics Volume 25, Number 4
</note>
<subsectionHeader confidence="0.613443">
Proof
</subsectionHeader>
<bodyText confidence="0.87543">
By induction on the depth of nodes.
</bodyText>
<listItem confidence="0.91946390625">
Inductive Hypothesis: Assume that for any node M of depth d&apos;, where 0 &lt; d&apos; &lt;d,
the lemma holds.
Base Case: Suppose M is of depth 1 (i.e., a daughter of the root node). Suppose
the root is licensed by a rule S -4 A1 Ak, where M, is the ith daughter of the root
(1 &lt;1 &lt; k) and M =
(a) Assume this rule is purely bottom-up. Since (G, tr) is indirectly
analyzable, A1 is indirectly analyzable. Consider the rule that licenses
Mi. It cannot be left-introducible, as S 4 A1 ... (see earlier remark about
empty essential left contexts); hence it must be either lexical or
bottom-up. By Lemma 9, C contains a representation of the subtree
rooted at Mi. Since the rule S -&gt; A1 k is bottom-up, C contains an
active edge of the form (0,0,S •A1 • A2 • • At).
(b) Assume this rule is top-down. Then there must be an empty active edge
(0,0, S -&gt; • • Ai . • • Ak)•
By repeated applications of Lemma 9 and Lemma 1, there are edges of the form
(0 , ti, S .A1 . . . Ai • Ai+i • • Ak)
1 &lt;i &lt; (j - 1). The last of these fulfils the condition.
Inductive Step: Let M be a node labeled A of depth d&gt; 1, licensed by a top-down
rule r. Let its mother node be N, of depth (d - 1), and the leftmost daughter of N be
Mi. Consider the rule r&apos; (of the form Ao -› A1 • • • Ak), which licenses N.
(a) Suppose r&apos; is purely bottom-up. Then M1 is labeled with an indirectly
analyzable symbol, Al. Hence for the rule licensing M1, three cases must
be considered:
1. It is lexical. In this case, C contains a representation for A41.
2. It is top-down and left-introducible. By Lemma 8, there is an
edge at the start of M1 seeking its label. If M = M1, this
establishes the Inductive Step in this situation. Otherwise, by
Lemma 9, there is a representation in C for the subtree rooted at
Mi.
3. It is bottom-up of the form A1 B1 ... where Bi is indirectly
analyzable. By Lemma 9, there is a representation in C for the
subtree rooted at Mi.
</listItem>
<bodyText confidence="0.954484571428571">
Since there is a representation in C for the subtree rooted at Mi, there is
an (inactive) edge in C of the form (i,j, Ai -+ • where i is the start
of M1 (and hence of N). Since r&apos; is bottom-up and A1 is the leftmost
(trigger) symbol of its RHS, this leads to an active edge of the form
(i, i, A0 -&gt; • • Ai Ak) for r&apos; at the start of M1 and N. By repeated
applications of Lemma 1 and Lemma 9, there is an active edge seeking A
at the start of M.
</bodyText>
<page confidence="0.996064">
478
</page>
<figure confidence="0.436562">
Ritchie Completeness Conditions for Mixed Strategy Bidirectional Parsing
(b) Suppose r&apos; is top-down. By the Inductive Hypothesis, there is an edge at
</figure>
<bodyText confidence="0.9996642">
the start of N seeking the label of N. Since r&apos; is top-down, there is also
an empty active edge for r&apos; at that point. If M = M1, this establishes the
Inductive Step in this situation. Otherwise, by repeated applications of
Lemma 1 and Lemma 9, there is an active edge seeking A at the start
of M.
</bodyText>
<subsectionHeader confidence="0.767632">
Theorem 3
</subsectionHeader>
<bodyText confidence="0.922272">
If a LCSCFG (G, tr) is indirectly analyzable, then tr is complete.
</bodyText>
<subsectionHeader confidence="0.942281">
Proof
</subsectionHeader>
<bodyText confidence="0.980428">
Follows from Lemma 9 and Lemma 10.
</bodyText>
<subsectionHeader confidence="0.997955">
5.6 Undecidability
</subsectionHeader>
<bodyText confidence="0.999994">
We have established that the condition of indirect analyzability suffices to ensure com-
pleteness. Unfortunately, indirect analyzability is not a decidable property of annotated
grammars, as we now show.
</bodyText>
<subsectionHeader confidence="0.69801">
Theorem 4
</subsectionHeader>
<bodyText confidence="0.98761">
It is undecidable whether an arbitrary LCSCFG is indirectly analyzable.
</bodyText>
<subsectionHeader confidence="0.940182">
Proof
</subsectionHeader>
<bodyText confidence="0.9999772">
Suppose that there were a decision procedure for indirect analyzability. This could
then be used to construct a decision procedure that determines for any two CFGs G1,
G2 whether every member of L(G1) ends in a substrirtg that is a member of L(G2).
This is an undecidable problem (see Appendix B); hence, the indirect analyzability
question is also undecidable. The construction proceeds as outlined below.
Suppose we have the two arbitrary CFGs G1 and G2 over the same alphabet VT, and
assume that their nonterminal alphabets VI, 17,2„ do not intersect. Construct a LCSCFG
as follows. The distinguished symbol S&apos; is distinct from all symbols in 17/1v U -177v. Use
symbols B1, B2, . . , B6 also not in Vk, U17k. The purely bottom-up rules are all the rules
of G2, together with
</bodyText>
<equation confidence="0.9958055">
B1 —&gt; B2B3
B6 —&gt; 52B2
</equation>
<bodyText confidence="0.8586675">
where each S, is the distinguished symbol of G1. The purely top-down rules are all the
rules of G1 together with
</bodyText>
<equation confidence="0.9068835">
S&apos; —&gt; S1B1
B2 —&gt; BB5
Also we include lexical rules:
B3 —&gt; a
B4 b
B5 —&gt; C
</equation>
<bodyText confidence="0.958115857142857">
for some terminal symbols a, b, c.
This LCSCFG is indirectly analyzable iff (by definition) every purely bottom-up
rule has an indirectly analyzable symbol at the start of its RHS (the trigger position).
All the rules taken directly from G2 meet this condition, since all are bottom-up. So,
therefore, does the rule B6 —&gt; S2B2. All the rules taken directly from G1, and the rule
S&apos; SiBi, do not affect the condition, since all are top-down. Hence the grammar
is indirectly analyzable iff in the rule B1 B2B3, the trigger symbol B2 is indirectly
</bodyText>
<page confidence="0.996505">
479
</page>
<note confidence="0.737405">
Computational Linguistics Volume 25, Number 4
</note>
<bodyText confidence="0.98756625">
analyzable. This depends on whether the only rule expanding B2, B2 -&gt; B4B5 is left-
introducible. The essential left contexts of B2 is the set 0 E V; 1 Si r 71. The only
symbol X for which X ,* B2 is B2 itself. Hence the only rule that meets the schema
for left-introducibility is B6 -4 S2B2. SO B2 -&gt; B4B5 is left-introducible iff every 7 such
that S1 4-y is of the form Op with S2 coherently derived from p. Since all G2 rules are
bottom-up, S2 is coherently derived from p iff S2 r- p. Hence the left-introducibility of
the rule in question is logically equivalent to L(G1) C V&apos;7&apos;,+L(G2) (where + indicates
concatenation). O
</bodyText>
<subsectionHeader confidence="0.74434">
6. Some Further Complications
</subsectionHeader>
<bodyText confidence="0.999787714285714">
So far, the proofs have shown that direct analyzability is a sufficient condition for com-
pleteness, and that indirect analyzability (a more general condition) is also sufficient.
The question might be posed—is indirect analyzability necessary for completeness? In
fact, it is not, as there is at least one other sufficient condition for completeness, not
covered by indirect analyzability.
It is not worthwhile formalizing and analyzing these possibilities in detail, but a
brief informal outline of one such condition may be helpful. This occurs where a set of
rules that is not directly analyzable, and might seem to cause &amp;quot;blocking&amp;quot; as discussed
in Section 2.1 earlier, is redeemed by interaction with other rules in the grammar. This
is similar to the phenomenon analyzed in Section 5 above, but whereas the analysis
above dealt with a configuration of rules that can be parsed bottom-up to the left of
the problematic rule, there is an analogous condition on subtrees to the left that can
be parsed top-down.
The following grammar illustrates this phenomenon.
</bodyText>
<equation confidence="0.587561307692308">
S -›- r- I K
3----+ZB
H --+ E F
E--413R
QTV
2-&gt;HQ
K-&gt;QD
P -&gt; p
R-+r
F -4 f
D -&gt; d
T - &gt; t
V -› v
</equation>
<bodyText confidence="0.9686462">
Here, the grammar is not indirectly analyzable, as the purely bottom-up rule K -pQ D
has a trigger category Q that is not indirectly analyzable. (The rule S -&gt; H K is also
problematic.) However, the only situation in which K ---&gt; Q D would be needed would
be to parse a string prftvd. Since S -,-&gt; H, there will be an empty active edge introduced
for H -&gt; E F at the start of the string. This will parse prf (top-down) as an H, and
this will combine with the active edge already introduced for Z -&gt; H Q, leading to the
introduction of an empty active edge for Q T V at the start of the correct substring,
tvd.
Intuitively, this is similar to the phenomenon defined earlier as left-introducible,
but with the catalytic sequence of rules being triggered top-down from the distin-
</bodyText>
<page confidence="0.984188">
480
</page>
<note confidence="0.1714">
Ritchie Completeness Conditions for Mixed Strategy Bidirectional Parsing
</note>
<bodyText confidence="0.999673">
guished symbol of the grammar. It is likely that some generalization could be made
to cover this pattern of rules and those described in Section 5, but the undecidability
result in Theorem 4 suggests that this would not improve matters—the more general
property would also be undecidable.
</bodyText>
<sectionHeader confidence="0.994083" genericHeader="method">
7. Discussion
</sectionHeader>
<subsectionHeader confidence="0.999896">
7.1 Other Bidirectional Schemes
</subsectionHeader>
<bodyText confidence="0.999995681818182">
As mentioned in Section 1 above, the ideas here were developed from a semi-formal
proposal by Steel and de Roeck (1987). The formalization given here is a slight gen-
eralization, as it allows multiple possible triggers on the RHS of a rule, which Steel
and de Roeck did not consider. Steel and de Roeck did not formalize their proposal
in detail, and did not show how to check if such annotations could lead to the parser
missing possible analyses (i.e., becoming incomplete), although they concede that this
is an important issue.
Satta and Stock (1989, 1991, 1994) have developed various detailed and rigorous
systems of chart-based parsing, including one (Satta and Stock 1989) that allows a
form of purely bottom-up bidirectional parsing, but they do not explore the question of
mixed strategy invocation of rules. Most of the mechanisms in their bottom-up method
are aimed at avoiding redundant edges in the chart, a problem that has been ignored
here by working at a more abstract, set-theoretic level. Satta and Stock provide a more
algorithmic approach in which such issues are of concern. A practical implementation
of the definitions given above might have to consider whether their system could be
adopted to achieve greater efficiency. However, Willis (1996) points out that in some
situations the scheme given in Satta and Stock (1989) can be less efficient (in terms of
edges introduced to the chart) than a fairly naive implementation of a mixed strategy
chart parser whose grammar is annotated to run bottom-up (essential for comparison
with the Satta and Stock algorithm). This seems to be because the Satta and Stock
method involves the introduction, when a constituent is found, of an edge for every
rule with that type of constituent on its RHS.
</bodyText>
<subsectionHeader confidence="0.999086">
7.2 Head Parsing
</subsectionHeader>
<bodyText confidence="0.999982210526316">
There has been a growth in interest over the past decade or so in head-driven parsing
(e.g., Kay 1989). In these approaches, the parsing is guided by the fact that exactly
one item on the right-hand side of a grammar rule is the head of the construction, in
the sense that it is a linguistically important part of the rule. Some of these proposals
have been formalized using chart parsing, and their properties explored.
Although some of the head-driven strategies are said to act &amp;quot;top-down,&amp;quot; this refers
to the parser exploring from a prediction of a specific nonterminal symbol in some
region of the input, but not to rules being introduced because the grammar writer
has indicated that it is to be introduced top-down in the sense used here. The head
markings are always on the right-hand side of the rule, never the left-hand side (since
that would not make sense for a linguistic head). Hence, head-driven parsing is, in
terms of the approach defined here, a form of bottom-up parsing, and the issues
of incompleteness resulting from a mixed strategy algorithm do not arise. The mixed
strategy approach here (which was developed independently of the head-driven work)
could be seen as a possible generalization of a very simple head-driven parser.
There are similarities between the bidirectional scheme here and the head-corner
parser of Sikkel and op den Akker 1996, in which top-down predictions can arise
either from the distinguished symbol (predicted to span the whole input) or by work-
ing outwards from the specified head constituent (as in the left and right extension
</bodyText>
<page confidence="0.994942">
481
</page>
<note confidence="0.70493">
Computational Linguistics Volume 25, Number 4
</note>
<bodyText confidence="0.999238090909091">
principles of Definition 9 in Section 3.3). They define a transitive reflexive relationship
&amp;quot;&gt;&amp;quot;, which roughly means that A&gt;B if there is a chain of rules from A to B such
that the left-hand side of each one is the head of the previous rule in the sequence.
Sikkel and op den Akker&apos;s chart handling principles all have the precondition that the
introduction of the new edge can happen only if the region of the input in question
is spanned by a predictive edge seeking a symbol A such that A&gt;B, where B is the
label of the constituent or prediction being introduced. This is, as they make clear,
comparable to using a left-corner oracle to avoid unnecessary edges in a more tradi-
tional parser. A similar optimization might be possible for a mixed strategy parser of
the sort discussed here, by using the triggers in bottom-up rules in the same way that
heads are used by Sikkel and op den Akker.
</bodyText>
<subsectionHeader confidence="0.998441">
7.3 Extended Generalized Left-Corner Parsing
</subsectionHeader>
<bodyText confidence="0.9999944">
Stabler (1994) outlines a very general approach to top-down and bottom-up parsing
of context-free grammars, in a somewhat different formal framework. Although his
theoretical mechanisms are in some ways a generalization of the left-corner strategy-
marked grammars discussed in Section 5 above, there is one respect in which they are
slightly less general, and which places the chart-based proofs given above outside the
scope of his results. Stabler defines a class of extended generalized left-corner (XGLC)
parsers, by attaching an (extended) trigger function to a CFG. This function maps each
pair consisting of a stack configuration and a rule to a prefix of the RHS of that rule.
Intuitively, the rule indicates how much of the RHS of the rule has to be recognized
before that rule is to be introduced into the parsing process; making this dependent on
the parser&apos;s stack (which can hold both recognized symbols and predictions of symbols
needed) allows some sensitivity to the parsing context. Stabler cites a proof that all such
parsers are complete with respect to the original CFG. This may seem to conflict with
the proofs offered above, but it is crucial that Stabler&apos;s trigger functions are defined to
be total functions—for any stack configuration, there must be some prefix of the rule&apos;s
RHS. To faithfully reproduce the notion of a top-down rule used in the mixed strategy
chart system, the trigger function would have to be partial, indicating no prefix at
all in those cases where the stack did not have the right prediction. It is reasonable
to assume that Stabler&apos;s completeness proofs rely on the total nature of the trigger
function, and thus do not cover the notion of mixed strategy parsing defined here.
</bodyText>
<subsectionHeader confidence="0.999293">
7.4 Possible Uses
</subsectionHeader>
<bodyText confidence="0.99998625">
As mentioned in Section 1 above, the original Steel and de Roeck proposal was put
forward as a way of improving the efficiency of parsers for natural languages, such
as English. Although they did not have any real statistical evidence that this guidance
leads to more efficient parsing, they claimed that it did appear to help, judging by
the performance of the parser they had implemented for use in an English-language
query interface. That approach is dependent on the grammar writer having some
linguistic intuitions about which constituents are best parsed bottom-up and which
are best parsed top-down. Alternatively, the rule annotations could be developed from
statistics about rule usage in parsing suitably large corpora.
Some preliminary results (Willis 1996) suggest that on small grammars, gains of up
to 35% can be made in efficiency (measured in terms of chart entries) by using certain
combinations of the mechanisms formalized here. These gains are not great, and it is
unclear whether similar improvements could be achieved in realistically large natural
language grammars. The formal results in Sections 4 and 5 above suggest that it may
not be worthwhile carrying out such experiments, unless grammars are restricted to
those that are directly analyzable.
</bodyText>
<page confidence="0.989392">
482
</page>
<note confidence="0.170829">
Ritchie Completeness Conditions for Mixed Strategy Bidirectional Parsing
</note>
<bodyText confidence="0.9988864">
Context-free grammar has been used as the basis here, both to simplify the for-
malization, to achieve some degree of generality, and in order to relate the work to
existing formal language theory. Steel and de Roeck also use a CFG base as an ex-
pository device for their ideas. However, it is extremely rare within computational
linguistics for a pure CFG to be used in actual systems that parse natural language.
Usually, some much more complex grammatical formalizm is used, such as unification
grammar (Shieber 1986). Many of the methods for parsing unification grammars are
closely based on traditional CFG parsing techniques, with enhancements. This means
that an obvious extension of the theoretical definitions and results in this paper would
be the application of mixed strategy bidirectional parsing to unification grammars.
Most of the framework could be retained, since the main difference between a simple
unification grammar formalism and CFG is in the way that nonterminal symbols are
compared or combined with each other. It is highly improbable that the undecidability
result would be overturned, and it is even conceivable that the appropriate counterpart
of direct analyzability might turn out to be less tractable.
</bodyText>
<sectionHeader confidence="0.954528" genericHeader="method">
8. Conclusions
</sectionHeader>
<bodyText confidence="0.999961333333333">
Although the idea of allowing the grammar writer to specify the strategy to be used
for each rule in a grammar may seem superficially appealing, the formal evidence
presented here is that it is severely limited. In general, grammar annotation may lead
to incompleteness. Although there is a decidable property—direct analyzability—that
guarantees completeness, it is overrestrictive, in the sense that there are complete
annotations that are not directly analyzable. There is also a wider class of complete
annotations—indirectly analyzable—that cannot be decidably detected.
There is also some question over the practical effectiveness of the mixed strategy
technique, although that issue has not been explored here.
</bodyText>
<sectionHeader confidence="0.716133" genericHeader="method">
Appendix A: Computing Direct Analyzability
</sectionHeader>
<bodyText confidence="0.907278888888889">
The algorithm is a simple variant of the use of an AND-OR graph in problem solving,
as in Nilsson (1971). The graph will contain a node for each nonterminal symbol A in
the grammar, and an OR node for each bottom-up rule. Each node has a label, which
is either a nonterminal symbol or OR, and may, optionally, have a marking, which is
either SOLVED or FAILED.
1. For each symbol A E VN, create a node NA, and insert arcs and markings as follows:
if there is a purely TD rule of the form A —&gt; a
then mark NA as FAILED
else if all rules of the form A a are lexical
then mark NA as SOLVED
else
for each bottom-up rule of the form A —› A1 . • • Ak:
- create a node N labeled oR;
- create an arc from NA to N;
- create an arc from N to NA, for every i e tr(A —&gt; A1 • • • Ak)
such that i&gt; 0.
At this point, each non—terminally labeled node has outgoing arcs for every bottom-up rule
that might expand it, and each of these arcs connects to an OR node, which in turn connects to
</bodyText>
<page confidence="0.994751">
483
</page>
<note confidence="0.478534">
Computational Linguistics Volume 25, Number 4
</note>
<bodyText confidence="0.987325125">
every possible trigger category for that rule. Nodes marked FAILED correspond to categories that
are not directly analyzable; nodes marked SOLVED correspond to those that are directly analyzable.
Initially, any node marked SOLVED or FAILED has no outgoing arcs.
2. Repeat until no changes occur in the graph:
for each node N in the graph:
if N is marked FAILED
then delete any arc into N from a node M;
if N is labeled OR, or there are no other outgoing
arcs from M;
then - mark M as FAILED;
- remove any outgoing arcs from M;
if N is marked SOLVED
then if there is an arc into N from an OR-node M
then - mark M as SOLVED;
- remove any outgoing arcs from M.
else if there is an arc into N from a node MA
then delete this arc from MA to N
if this leaves no outgoing arcs from MA
then mark MA as SOLVED.
if N is an OR node with no incoming arcs
then delete N and all its outgoing arcs.
The properties remarked above remain invariant during this iteration. The iteration termi-
nates as the graph is finite. On termination, the only arcs left must be in cycles. The categories
associated with any nodes in cycles should be taken as directly analyzable.
</bodyText>
<listItem confidence="0.807194">
3. For every node NA that has an arc (incoming or outgoing) attached to it, mark NA
</listItem>
<bodyText confidence="0.787471166666667">
as SOLVED.
4. If for every purely bottom-up rule A A1 Ak, there is an i E tr(A A1 . • • Ak)
such that NA, is marked SOLVED, then the grammar is directly analyzable.
The above statement is not intended to be maximally efficient. No formal proof
of its correctness is given here, but there is a fairly straightforward relationship to the
property of direct analyzability, which is stated as the draft definition in Section 4.2.
</bodyText>
<sectionHeader confidence="0.95314" genericHeader="method">
Appendix B: Undecidability Proof
</sectionHeader>
<subsectionHeader confidence="0.61866">
Lemma
</subsectionHeader>
<bodyText confidence="0.999476">
For any two context-free grammars G1, G2, it is undecidable whether every member
of L(G1) ends in a substring that is a member of L(G2).
</bodyText>
<subsectionHeader confidence="0.762214">
Proof
</subsectionHeader>
<bodyText confidence="0.835186">
Let G1 and G2 be two CFGs over the same alphabet V. with languages L(Gi) and L(G2)
respectively. Let # be a symbol that is not a member of V. Consider the language
given by:
filx I X E L(GOI
</bodyText>
<page confidence="0.98801">
484
</page>
<bodyText confidence="0.9214159375">
Ritchie Completeness Conditions for Mixed Strategy Bidirectional Parsing
and L&apos;2 given by:
{lty y G L(G2)}
These are both context-free languages; assume that grammars di, G; generate them.
Suppose we have a procedure that would decide, for any two context-free grammars,
whether every member of the language of one ends in a substring that is a member
of the language of the other. Consider the question whether every member of L(G)
(i.e., L&apos;2) ends in a substring that is a member of L(G) (i.e., LI). This is true iff every
string of the form #y in L&apos;2 has a final substring that is in {#x I x E L(G1)}. Since # is
not in V. this can be true iff y E L(G1). This will be true for every such string in L&apos;2, iff
y E L(G1) for every y E L(G2); i.e., L(G2) C L(G1)
That is, a decision procedure for the final substring question would allow the
construction of a decision procedure for the subset question for the languages gener-
ated by two arbitrary context-free grammars, which in turn would provide a decision
procedure for the equivalence of the languages, and that is known to be undecidable
(Aho and Ullman 1972, Sect. 2.6.3).
</bodyText>
<sectionHeader confidence="0.99148" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999220142857143">
I would like to thank Anne de Roeck,
Alistair Willis, and Suresh Manandhar for
useful discussions, and Nicolas Nicolov for
comments on an earlier draft. The incisive
and thorough comments of various
anonymous reviewers have greatly
improved this paper.
</bodyText>
<sectionHeader confidence="0.99544" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.994510380952381">
Aho, Alfred V. and Jeffrey D. Ullman. 1972.
The Theory of Parsing, Translation, and
Compiling. Volume Ti: Parsing. Prentice-Hall,
Englewood Cliffs, NJ.
Earley, Jay. 1970. An efficient context-free
parsing algorithm. Communications of the
ACM, 13(2):94-102.
Kay, Martin. 1989. Head-driven parsing. In
Proceedings of the International Workshop on
Parsing Technologies, pages 52-62, Carnegie
Mellon University, Pittsburgh, PA,
August.
Maclane, Saunders and Garrett Birkhoff.
1967. Algebra. Macmillan, London.
Nilsson, Nils J. 1971. Problem-solving methods
in artificial intelligence. McGraw-Hill, New
York.
Partee, Barbara H., Alice ter Meulen, and
Robert E. Wall. 1990. Mathematical Methods
in Linguistics. Kluwer Academic,
Dordrecht.
Satta, Giorgio and Oliviero Stock. 1989.
Formal properties and implementation of
bidirectional charts. In Proceedings of the
Eleventh International Joint Conference on
Artificial Intelligence (IJCAI-89),
pages 1480-1485.
Satta, Giorgio and Oliviero Stock. 1991. A
tabular method for island-driven
context-free grammar parsing. In
Proceedings of the Eighth National Conference
on Artificial Intelligence (AAAI-91),
pages 143-148.
Satta, Giorgio and Oliviero Stock. 1994.
Bidirectional context-free grammar
parsing for natural language processing.
Artificial Intelligence, 69:123-164.
Shieber, Stuart. 1986. An Introduction to
Unification Approaches to Grammar. CSLI
Lecture Notes Number 4. Center for the
Study of Language and Information.
Shieber, Stuart M., Yves Schabes, and
Fernando C. N. Pereira. 1995. Principles
and Implementation of Deductive
Parsing. Journal of Logic Programming,
24(1 &amp; 2):3-36.
Sikkel, Klaas and Rieks op den Akker. 1996.
Predictive head-corner chart parsing. In
Harry Bunt and Masaru Tomita, editors,
Recent Advances in Parsing Technology.
Kluwer Academic, Netherlands,
chapter 9, pages 169-182.
Stabler, Edward P. 1994. Parsing for
incremental interpretation. Unpublished
paper, UCLA, Los Angeles, CA.
Steel, Sam and Anne de Roeck. 1987.
Bidirectional chart parsing. In J. Hallam
and C. Mellish, editors, Advances in
Artificial Intelligence. John Wiley,
pages 223-235.
Stoy, Joseph E. 1981. Denotational Semantics:
the Scott-Strachey approach to programming
language theory. MIT Press, Cambridge,
</reference>
<page confidence="0.981475">
485
</page>
<note confidence="0.305603">
Computational Linguistics Volume 25, Number 4
</note>
<reference confidence="0.984886733333333">
MA.
Thompson, Henry and Graeme Ritchie.
1984. Implementing natural language
parsers. In T. O&apos;Shea and M. Eisenstadt,
editors, Artificial Intelligence: Tools,
Techniques and Applications. Harper and
Row, New York, Chapter 9, pages
245-300.
Willis, Alistair. 1996. Exploring Chart Parsing
Mechanisms. Master&apos;s thesis, Department
of Artificial Intelligence, University of
Edinburgh, Edinburgh, Scotland.
Winograd, Terry. 1983. Language as a
Cognitive Process. Volume I: Syntax.
Addison-Wesley, Reading, MA.
</reference>
<page confidence="0.999042">
486
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.014545">
<title confidence="0.9965305">Completeness Conditions for Mixed Strategy Bidirectional Parsing</title>
<author confidence="0.993328">Graeme Ritchie</author>
<affiliation confidence="0.998406">University of Edinburgh</affiliation>
<abstract confidence="0.998766714285714">It has been suggested that, in certain circumstances, it might be useful for a grammar writer to annotate which rules are to be used bottom-up and which are to be used top-down within a parser, using a bidirectional variant of the active chart parsing technique. The formal properties of such systems have not been fully explored. One limitation of this mixed strategy technique is that certain annotations of rules can lead to incompleteness; that is, there may be valid analyses of the input string that cannot be found by the parser. We formalize a fairly natural notion of mixed strategy bidirectional parsing for context-free grammars, in which one or more symbols within a rule may be annotated as &amp;quot;triggers,&amp;quot; so that the rule is either top-down (triggered from its lefthand side), or bottom-up (triggered from element(s) of its right-hand side). We define a decidable property of annotated grammars, such that any grammar with this property is provably complete. There are, however, some complete annotations of grammars that fall outside this decidable class. We show that membership of this wider class is undecidable. These results suggest that the mixed strategy approach is of rather limited usefulness, regardless of whether it is empirically efficient or not. 1. Overview Many methods have been explored for parsing context-free grammars; some of these methods are loosely categorized as &amp;quot;top-down&amp;quot; (e.g., recursive descent), some as &amp;quot;bottom-up&amp;quot; (e.g., shift-reduce), and some could be seen as a mixture of these two varieties (e.g., left-corner). All of the well-explored methods assume that the rules in the grammar are handled in a fairly uniform way. In particular, it is not usual for the rules to be separated into two classes—those to be used bottom-up and those to be used top-down. Steel and de Roeck (1987) argue (giving credit to Henry Thompson for some of the ideas) that the performance of a parser could be improved by allowing the grammar writer to do exactly this. The motivation comes from linguistic phenomena where it is intuitively clear that one symbol (linguistic category) in the rule is noticeably more distinctive than others, so that a parser should not waste time trying to match the rule unless that distinctive element is there. For example, a rule such as —&gt; NP CONJ NP a conjunction, such as not be simply because a noun phrase the start of a noun phrase, has been The proposal is that if the linguist is allowed to mark the as a &amp;quot;trigger,&amp;quot; and the parser introduces the rule, bottom-up, only if the trigger has been matched, then parsing would proceed more efficiently. Steel and de Roeck describe semi-formally a system they have implemented, which they claim benefits from this labeling of rules. The current paper does not take a position on the wisdom or effectiveness of such labeling. Instead, we explore the</abstract>
<note confidence="0.757684">Division of Informatics, 80 South Bridge, Edinburgh EHI IHN, Scotland. © 1999 Association for Computational Linguistics Computational Linguistics Volume 25, Number 4</note>
<abstract confidence="0.99190885106383">formal consequences of this proposal. We show that, although the idea may seem superficially plausible, it still has certain formal limitations in the area of completeness and decidability. The proofs may be of some theoretical interest from a formal language viewpoint. The central ideas are as follows: A conventional context-free grammar is &amp;quot;annotated&amp;quot; by marking at least one symbol in each rule as a trigger. Marking the left-handside (LHS) symbol as a trigger indicates that the rule can be used top-down; marking a right-hand-side (RHS) symbol as a trigger means that the rule can be used bottomup whenever a constituent labeled with that symbol is found by the parser.&apos; Using a method of parsing known as active chart parsing, it is straightforward to give a precise meaning to this labeling of rules, since a chart parser can operate either bottom-up or top-down. The scheme examined here is similar to, but different in important ways parsing Section 7.2). It is simple to construct an annotated grammar in which there are some analyses that are valid according to the original (unannotated) grammar but that would not be parsed by a chart parser following the annotations. This establishes that not all annotated grammars allow complete parsing. The main substance of this paper is as follows: A property of annotated grammars (direct analyzability) is defined, which is decidable, and it is proven that any annotated grammar with this property will also allow the parser to produce all the valid analyses licensed by the original grammar. However, some annotated grammars are not directly analyzable, but nevertheless lead to complete parsing. A characteristic of (a subset of) this wider class of annotated grammars (indirect analyzability) is defined, and it is proven that any annotated grammar with this property will allow complete parsing. However, indirect analyzability can be shown to be undecidable. 2. The problems 2.1 Losing Completeness Before presenting a formal definition of the mechanisms, and proceeding to prove their various properties, it is useful to consider informally a very simple example that shows how this approach can lead to loss of analyses by the parser. As outlined above, the central idea is to allow different rules to be marked as either top-down (LHS trigger symbol) or bottom-up (RHS trigger symbol(s)), or both. Top-down means that the rule can be invoked only if some other rule has established a need for its LHS symbol (or if the LHS symbol is the initial symbol of the grammar). Bottom-up means that the rule can be invoked only if one of the symbols marked as triggers on its RHS has completely parsed. We shall assume that rules of the form —&gt; where w is a terminal symbol are never annotated, and can be used whenever needed in the parser (all this is made precise in our formalization in Section 3.3 below). For this informal presentation, and occasionally elsewhere, we shall mark a trigger overlining it, thus: the illustrative examples, the distinguished symbol of the grammar will always be terminal symbols will be in lower case. 1 The term &amp;quot;bottom-up&amp;quot; is adopted here for compatibiity with some other literature on chart parsing, and for lack of a better simple phrase. In fact, there are various possible parsing regimes that are in some sense &amp;quot;bottom-up,&amp;quot; and it is arguable that some are &amp;quot;more bottom-up&amp;quot; than those outlined here. Where right-hand-side triggers are restricted to the leftmost symbol (as in Section 5 below), parsing is more like &amp;quot;left-corner&amp;quot; parsing, but this would be a misleading term when triggers are allowed elsewhere.</abstract>
<note confidence="0.365395">458</note>
<title confidence="0.8783802">Ritchie Completeness Conditions for Mixed Strategy Bidirectional Parsing Consider the annotated grammar (see Section 3 for a definition of grammar): S NP VP NP Art N VP —&gt; runs</title>
<author confidence="0.805878">Art</author>
<abstract confidence="0.989331347826087">N —&gt; dog It should be intuitively clear that although this grammar generates exactly one sentence, that string cannot be parsed by a parser that follows the annotations as de- The rule S VP be used until an initial recognized, and the that might do that, Art N, be used until an initial need for an established (which could happen only using S VP). is a form of deadlock, resulting in incompleteness. It should also be intuitively clear that the presence or absence of such combinations of annotations may not be as obvious as it is here. In a grammar with hundreds of rules, the presence of a combination that blocks an otherwise valid analysis could take some detailed checking. This is a serious flaw, as annotation method was supposed to alter the the parser, but not to eliminate strings from its language. It would be very easy to ensure that annotation does not lose analyses, by stipulating that all rules are marked as top-down, or that all rules are marked as bottom-up with the leftmost symbol as a trigger. The parser would then behave as a conventional (or bottom-up) chart parser, which is be complete. However, since the aim is to allow the grammar writer to make a nontrivial annotation of the grammar (in an attempt to allow linguistic knowledge to influence the efficiency of the parsing), we need to be able to check the completeness of arbitrarily annotated grammars. In Section 4 below, we define formally a nontrivial characteristic of annotated grammars that guarantees that they do not lose analyses in this way, and show that this property of grammars is decidable. 2.2 Completeness through Interactions The situation is even more complicated than Section 2.1 above indicates. One of the crucial aspects of chart parsing (which is central to its simplicity and its efficiency) is that any entry in a chart can be used to combine with any other compatible entry, regardless of whether there is a single coherent tree that will result from it. In particular, an entry that has been inserted in the chart as the result of some rule interaction that does not itself produce a complete sentential tree (i.e., a partial fragment of an analysis) can contribute to some other analysis that happens to require it. This is best demonstrated by a simple artificial example. Consider the strategymarked grammar, notation as before: 3—&gt;EH H—BF 13—&gt;PQ E j P 1 m F k un-strategy-marked version of this grammar would generate the string 459 Computational Linguistics Volume 25, Number 4 a derivation as follows (see Section 3 for a definition of the relation &amp;quot;&amp;quot;): jH jBF = jPQF j1QF = jlmF = jlmk The tree described by this derivation cannot be found by a parser following the strategy-marked grammar, for reasons similar to those outlined in Section 2.1 above.</abstract>
<title confidence="0.89981075">Suppose we now add the following rules to the grammar: S C D D—&gt;EA A —&gt; B C</title>
<author confidence="0.561468">C x</author>
<abstract confidence="0.997282277777778">larger grammar will also generate the string this is not relevant to the argument. What is more interesting is that the extended grammar does now allow the of an associated syntax tree that corresponds to the derivation given above (i.e., a tree that makes no direct use of the rules that have been added to the grammar). The way in which the added rules act as a &amp;quot;catalyst&amp;quot; to allow the hitherto blocked analysis is an example of a general phenomenon. Informally, what happens is the following: (A chart parser is assumed here; formal details are given in Section 3.3 With just the smaller grammar, the nonterminal be expanded as since it is on the LHS of a bottom-up rule, and its first symbol be recognized because it requires a top-down rule. In both the original grammar and the grammar, introduced only by the rule H, with its immediate So the only strings where participate in an analysis are those where E occurs the start. Consider the parsing, with the larger grammar, of the string indeed start with an preterminal, it can be recognized directly (with no from annotations). In the larger grammar, the bottom-up rule A is then introduced to the parsing, which creates a predictive entry in the parser&apos;s structures an the recognized top-down rule C then leads to an entry, at that same point, seeking a causes the top-down</abstract>
<intro confidence="0.71931">P (from the original grammar) to be introduced; this is a crucial step. This</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alfred V Aho</author>
<author>Jeffrey D Ullman</author>
</authors>
<date>1972</date>
<booktitle>The Theory of Parsing, Translation, and Compiling. Volume Ti: Parsing. Prentice-Hall,</booktitle>
<location>Englewood Cliffs, NJ.</location>
<contexts>
<context position="13638" citStr="Aho and Ullman 1972" startWordPosition="2313" endWordPosition="2316">more daughter nodes. A tree is said to span the sequence of labels associated with the sequence of its terminal nodes (in left-to-right order), and we shall also say that the root node of a (sub)tree spans its sequence of terminal nodes. Definition 1 The height of a node in a tree is defined as follows. A terminal node has height 0; a nonterminal node has height = (1 + maximum height of its daughter nodes). Definition 2 The depth of a node in a tree is defined as follows. A root node has depth 0; a nonroot node has depth = (1 + depth of its parent node). Following the usual conventions (e.g., Aho and Ullman 1972), we will take a context-free grammar (CFG) to be a quadruple (VN, VT, P. S), consisting of a set VN of nonterminal symbols, a set VT of terminal symbols, a set P of rules (productions), and a single distinguished symbol S E VN. Set theoretically, rules can be regarded as being ordered pairs where the first element is a nonterminal symbol and the second is a tuple of symbols, i.e., of the form (A0, (A1,. , Ak)) where k &gt; 0, but for ease of exposition they will be written as Ao —&gt; Al • • • Ak We will make the following simplifying assumptions (which do not lose generality): 1. Each rule in P is</context>
<context position="16575" citStr="Aho and Ullman 1972" startWordPosition="2891" endWordPosition="2894">(Section 5 below). Given two strings col, w2 from (VN U Vr)*, then wi directly derives w2, written &amp;quot;w1 w2,&amp;quot; if col = SA&apos;-y, co2 = 6a-y and A a is a rule in G. Similarly, col derives w2, written &amp;quot;wl 4 co2,&amp;quot; is the reflexive transitive closure of directly derives. A derivation is a sequence of symbol strings wl, ,w„ such that wi cowl for all 1 &lt; i &lt; n. A rightmost derivation is one in which each step from w, to co,+1 is made by replacing the furthest right nonterminal symbol in wi using some rule (i.e., -y in the above definition of directly derives is entirely made up of terminal symbols) (cf. Aho and Ullman 1972). 3.2 Annotated Grammars Since we are allowing trigger elements of a rule to occur anywhere on the RHS of a rule, it is necessary to allow the parser to explore outwards in either direction (leftwards or rightwards) from a constituent that has been parsed. Hence the parsing schemes defined below are referred to as bidirectional, to reflect this fact. This does not allude to the two &amp;quot;directions” of top-down or bottom-up. Definition 3 Let G be a context-free grammar (VN,VT,P, 5). A bidirectional strategy marking of G is a (total) function tr from the nonlexical rules in P to P(N) (the set of set</context>
</contexts>
<marker>Aho, Ullman, 1972</marker>
<rawString>Aho, Alfred V. and Jeffrey D. Ullman. 1972. The Theory of Parsing, Translation, and Compiling. Volume Ti: Parsing. Prentice-Hall, Englewood Cliffs, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jay Earley</author>
</authors>
<title>An efficient context-free parsing algorithm.</title>
<date>1970</date>
<journal>Communications of the ACM,</journal>
<pages>13--2</pages>
<contexts>
<context position="18485" citStr="Earley 1970" startWordPosition="3247" endWordPosition="3248">king of G. Definition 5 Let ((VN, VT, P. S), tr) be a bidirectionally strategy-marked context-free grammar. Then a rule r E P is said to be: 1. top-down, if 0 E tr(r). 2. bottom-up, if there is an i&gt; 0 such that i E tr(r). 3. purely bottom-up, if 0 tr(r). 4. purely top-down, if tr(r) = {0}. 3.3 Active Charts The techniques and structures known as active charts have been in use for parsing (at least in the area of natural language processing) since the early 1970s. The method 462 Ritchie Completeness Conditions for Mixed Strategy Bidirectional Parsing is a generalization of Earley&apos;s algorithm (Earley 1970), and tutorial expositions of the ideas can be found in Thompson and Ritchie (1984) or Winograd (1983). In keeping with more recent presentations (e.g., Shieber, Schabes, and Pereira 1995; Sikkel and op den Akker 1996) we define the parsing principles as well-formedness conditions on complete charts, abstracting away from the sequence of steps used to build them. Definition 6 Given a CFG G of the form (VN, VT, P. S) a double-dotted rule based on G is a triple (p,1,r) where p is a rule in P of the form Ao —&gt; k and 1,r are integers such that 0 &lt;1 &lt; r &lt; k. Such a rule will be written as: Ao A1 ..</context>
</contexts>
<marker>Earley, 1970</marker>
<rawString>Earley, Jay. 1970. An efficient context-free parsing algorithm. Communications of the ACM, 13(2):94-102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Kay</author>
</authors>
<title>Head-driven parsing.</title>
<date>1989</date>
<booktitle>In Proceedings of the International Workshop on Parsing Technologies,</booktitle>
<pages>52--62</pages>
<institution>Carnegie Mellon University,</institution>
<location>Pittsburgh, PA,</location>
<contexts>
<context position="60570" citStr="Kay 1989" startWordPosition="11337" endWordPosition="11338">s out that in some situations the scheme given in Satta and Stock (1989) can be less efficient (in terms of edges introduced to the chart) than a fairly naive implementation of a mixed strategy chart parser whose grammar is annotated to run bottom-up (essential for comparison with the Satta and Stock algorithm). This seems to be because the Satta and Stock method involves the introduction, when a constituent is found, of an edge for every rule with that type of constituent on its RHS. 7.2 Head Parsing There has been a growth in interest over the past decade or so in head-driven parsing (e.g., Kay 1989). In these approaches, the parsing is guided by the fact that exactly one item on the right-hand side of a grammar rule is the head of the construction, in the sense that it is a linguistically important part of the rule. Some of these proposals have been formalized using chart parsing, and their properties explored. Although some of the head-driven strategies are said to act &amp;quot;top-down,&amp;quot; this refers to the parser exploring from a prediction of a specific nonterminal symbol in some region of the input, but not to rules being introduced because the grammar writer has indicated that it is to be i</context>
</contexts>
<marker>Kay, 1989</marker>
<rawString>Kay, Martin. 1989. Head-driven parsing. In Proceedings of the International Workshop on Parsing Technologies, pages 52-62, Carnegie Mellon University, Pittsburgh, PA, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saunders Maclane</author>
<author>Garrett Birkhoff</author>
</authors>
<date>1967</date>
<publisher>Algebra. Macmillan,</publisher>
<location>London.</location>
<contexts>
<context position="28730" citStr="Maclane and Birkhoff 1967" startWordPosition="5346" endWordPosition="5349">p. 6]).3 First, for any BSCFG (G, tr) we define an analyzability predicate as any function g from nonterminal symbols to the set {true, false} that assigns true to a category Ao iff every rule r of the form Ao ... is either lexical, or of the form Ao —&gt; Ai . • • Alo with at least one i E tr(r), i &gt; 0, for which g(A) = true. Call the set of all such functions A&apos;P(G, tr). For any two g,h E A&apos;P(G, tr), define the relation &amp;quot;E&amp;quot; by h g iff h(A) = true D g(A) = true. This relation is easily shown to be reflexive, transitive, and antisymmetric, and hence (AP (G, tr), E) forms a partially ordered set (Maclane and Birkhoff 1967, 59; Stoy 1981, 82). Then for any set gi,• • • , gn of elements of A&apos;P(G, tr), the function g&apos; (in AP (G, tr)) given by g&apos; (A) = true iff either gi (A) = true or ... (A) = true is at least upper bound (Maclane and Birkhoff 1967; Stoy 1981) for • • • ,gt, with respect to E. Since AP (G, tr) is finite, the presence of a 1.u.b. for any subset means it has a maximum element, which we will call APMAX(G,tr). This predicate APMAX(Gm.) will assign true to a symbol A if there is some analyzability predicate (for (G, tr)) that makes this assignment.&apos; Then define a nonterminal A (from G) to be directly </context>
</contexts>
<marker>Maclane, Birkhoff, 1967</marker>
<rawString>Maclane, Saunders and Garrett Birkhoff. 1967. Algebra. Macmillan, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nils J Nilsson</author>
</authors>
<title>Problem-solving methods in artificial intelligence.</title>
<date>1971</date>
<publisher>McGraw-Hill,</publisher>
<location>New York.</location>
<contexts>
<context position="68250" citStr="Nilsson (1971)" startWordPosition="12580" endWordPosition="12581"> to incompleteness. Although there is a decidable property—direct analyzability—that guarantees completeness, it is overrestrictive, in the sense that there are complete annotations that are not directly analyzable. There is also a wider class of complete annotations—indirectly analyzable—that cannot be decidably detected. There is also some question over the practical effectiveness of the mixed strategy technique, although that issue has not been explored here. Appendix A: Computing Direct Analyzability The algorithm is a simple variant of the use of an AND-OR graph in problem solving, as in Nilsson (1971). The graph will contain a node for each nonterminal symbol A in the grammar, and an OR node for each bottom-up rule. Each node has a label, which is either a nonterminal symbol or OR, and may, optionally, have a marking, which is either SOLVED or FAILED. 1. For each symbol A E VN, create a node NA, and insert arcs and markings as follows: if there is a purely TD rule of the form A —&gt; a then mark NA as FAILED else if all rules of the form A a are lexical then mark NA as SOLVED else for each bottom-up rule of the form A —› A1 . • • Ak: - create a node N labeled oR; - create an arc from NA to N;</context>
</contexts>
<marker>Nilsson, 1971</marker>
<rawString>Nilsson, Nils J. 1971. Problem-solving methods in artificial intelligence. McGraw-Hill, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara H Partee</author>
<author>Alice ter Meulen</author>
<author>Robert E Wall</author>
</authors>
<date>1990</date>
<booktitle>Mathematical Methods in Linguistics.</booktitle>
<publisher>Kluwer Academic,</publisher>
<location>Dordrecht.</location>
<marker>Partee, Meulen, Wall, 1990</marker>
<rawString>Partee, Barbara H., Alice ter Meulen, and Robert E. Wall. 1990. Mathematical Methods in Linguistics. Kluwer Academic, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giorgio Satta</author>
<author>Oliviero Stock</author>
</authors>
<title>Formal properties and implementation of bidirectional charts.</title>
<date>1989</date>
<booktitle>In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (IJCAI-89),</booktitle>
<pages>1480--1485</pages>
<contexts>
<context position="59238" citStr="Satta and Stock (1989" startWordPosition="11116" endWordPosition="11119">d also be undecidable. 7. Discussion 7.1 Other Bidirectional Schemes As mentioned in Section 1 above, the ideas here were developed from a semi-formal proposal by Steel and de Roeck (1987). The formalization given here is a slight generalization, as it allows multiple possible triggers on the RHS of a rule, which Steel and de Roeck did not consider. Steel and de Roeck did not formalize their proposal in detail, and did not show how to check if such annotations could lead to the parser missing possible analyses (i.e., becoming incomplete), although they concede that this is an important issue. Satta and Stock (1989, 1991, 1994) have developed various detailed and rigorous systems of chart-based parsing, including one (Satta and Stock 1989) that allows a form of purely bottom-up bidirectional parsing, but they do not explore the question of mixed strategy invocation of rules. Most of the mechanisms in their bottom-up method are aimed at avoiding redundant edges in the chart, a problem that has been ignored here by working at a more abstract, set-theoretic level. Satta and Stock provide a more algorithmic approach in which such issues are of concern. A practical implementation of the definitions given abo</context>
</contexts>
<marker>Satta, Stock, 1989</marker>
<rawString>Satta, Giorgio and Oliviero Stock. 1989. Formal properties and implementation of bidirectional charts. In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (IJCAI-89), pages 1480-1485.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giorgio Satta</author>
<author>Oliviero Stock</author>
</authors>
<title>A tabular method for island-driven context-free grammar parsing.</title>
<date>1991</date>
<booktitle>In Proceedings of the Eighth National Conference on Artificial Intelligence (AAAI-91),</booktitle>
<pages>143--148</pages>
<marker>Satta, Stock, 1991</marker>
<rawString>Satta, Giorgio and Oliviero Stock. 1991. A tabular method for island-driven context-free grammar parsing. In Proceedings of the Eighth National Conference on Artificial Intelligence (AAAI-91), pages 143-148.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giorgio Satta</author>
<author>Oliviero Stock</author>
</authors>
<title>Bidirectional context-free grammar parsing for natural language processing.</title>
<date>1994</date>
<journal>Artificial Intelligence,</journal>
<pages>69--123</pages>
<marker>Satta, Stock, 1994</marker>
<rawString>Satta, Giorgio and Oliviero Stock. 1994. Bidirectional context-free grammar parsing for natural language processing. Artificial Intelligence, 69:123-164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Shieber</author>
</authors>
<title>An Introduction to Unification Approaches to Grammar. CSLI Lecture Notes Number 4. Center for the Study of Language and Information.</title>
<date>1986</date>
<contexts>
<context position="66655" citStr="Shieber 1986" startWordPosition="12340" endWordPosition="12341">rectly analyzable. 482 Ritchie Completeness Conditions for Mixed Strategy Bidirectional Parsing Context-free grammar has been used as the basis here, both to simplify the formalization, to achieve some degree of generality, and in order to relate the work to existing formal language theory. Steel and de Roeck also use a CFG base as an expository device for their ideas. However, it is extremely rare within computational linguistics for a pure CFG to be used in actual systems that parse natural language. Usually, some much more complex grammatical formalizm is used, such as unification grammar (Shieber 1986). Many of the methods for parsing unification grammars are closely based on traditional CFG parsing techniques, with enhancements. This means that an obvious extension of the theoretical definitions and results in this paper would be the application of mixed strategy bidirectional parsing to unification grammars. Most of the framework could be retained, since the main difference between a simple unification grammar formalism and CFG is in the way that nonterminal symbols are compared or combined with each other. It is highly improbable that the undecidability result would be overturned, and it</context>
</contexts>
<marker>Shieber, 1986</marker>
<rawString>Shieber, Stuart. 1986. An Introduction to Unification Approaches to Grammar. CSLI Lecture Notes Number 4. Center for the Study of Language and Information.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
<author>Yves Schabes</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Principles and Implementation of Deductive Parsing.</title>
<date>1995</date>
<journal>Journal of Logic Programming,</journal>
<volume>24</volume>
<issue>1</issue>
<pages>2--3</pages>
<marker>Shieber, Schabes, Pereira, 1995</marker>
<rawString>Shieber, Stuart M., Yves Schabes, and Fernando C. N. Pereira. 1995. Principles and Implementation of Deductive Parsing. Journal of Logic Programming, 24(1 &amp; 2):3-36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Klaas Sikkel</author>
<author>Rieks op den Akker</author>
</authors>
<title>Predictive head-corner chart parsing.</title>
<date>1996</date>
<booktitle>In Harry Bunt and Masaru Tomita, editors, Recent Advances in Parsing Technology. Kluwer Academic, Netherlands, chapter 9,</booktitle>
<pages>169--182</pages>
<marker>Sikkel, den Akker, 1996</marker>
<rawString>Sikkel, Klaas and Rieks op den Akker. 1996. Predictive head-corner chart parsing. In Harry Bunt and Masaru Tomita, editors, Recent Advances in Parsing Technology. Kluwer Academic, Netherlands, chapter 9, pages 169-182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward P Stabler</author>
</authors>
<title>Parsing for incremental interpretation. Unpublished paper,</title>
<date>1994</date>
<location>UCLA, Los Angeles, CA.</location>
<contexts>
<context position="63055" citStr="Stabler (1994)" startWordPosition="11758" endWordPosition="11759">the introduction of the new edge can happen only if the region of the input in question is spanned by a predictive edge seeking a symbol A such that A&gt;B, where B is the label of the constituent or prediction being introduced. This is, as they make clear, comparable to using a left-corner oracle to avoid unnecessary edges in a more traditional parser. A similar optimization might be possible for a mixed strategy parser of the sort discussed here, by using the triggers in bottom-up rules in the same way that heads are used by Sikkel and op den Akker. 7.3 Extended Generalized Left-Corner Parsing Stabler (1994) outlines a very general approach to top-down and bottom-up parsing of context-free grammars, in a somewhat different formal framework. Although his theoretical mechanisms are in some ways a generalization of the left-corner strategymarked grammars discussed in Section 5 above, there is one respect in which they are slightly less general, and which places the chart-based proofs given above outside the scope of his results. Stabler defines a class of extended generalized left-corner (XGLC) parsers, by attaching an (extended) trigger function to a CFG. This function maps each pair consisting of </context>
</contexts>
<marker>Stabler, 1994</marker>
<rawString>Stabler, Edward P. 1994. Parsing for incremental interpretation. Unpublished paper, UCLA, Los Angeles, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sam Steel</author>
<author>Anne de Roeck</author>
</authors>
<title>Bidirectional chart parsing.</title>
<date>1987</date>
<booktitle>Advances in Artificial Intelligence.</booktitle>
<pages>223--235</pages>
<editor>In J. Hallam and C. Mellish, editors,</editor>
<publisher>John Wiley,</publisher>
<marker>Steel, de Roeck, 1987</marker>
<rawString>Steel, Sam and Anne de Roeck. 1987. Bidirectional chart parsing. In J. Hallam and C. Mellish, editors, Advances in Artificial Intelligence. John Wiley, pages 223-235.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph E Stoy</author>
</authors>
<title>Denotational Semantics: the Scott-Strachey approach to programming language theory.</title>
<date>1981</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="28745" citStr="Stoy 1981" startWordPosition="5351" endWordPosition="5352">G, tr) we define an analyzability predicate as any function g from nonterminal symbols to the set {true, false} that assigns true to a category Ao iff every rule r of the form Ao ... is either lexical, or of the form Ao —&gt; Ai . • • Alo with at least one i E tr(r), i &gt; 0, for which g(A) = true. Call the set of all such functions A&apos;P(G, tr). For any two g,h E A&apos;P(G, tr), define the relation &amp;quot;E&amp;quot; by h g iff h(A) = true D g(A) = true. This relation is easily shown to be reflexive, transitive, and antisymmetric, and hence (AP (G, tr), E) forms a partially ordered set (Maclane and Birkhoff 1967, 59; Stoy 1981, 82). Then for any set gi,• • • , gn of elements of A&apos;P(G, tr), the function g&apos; (in AP (G, tr)) given by g&apos; (A) = true iff either gi (A) = true or ... (A) = true is at least upper bound (Maclane and Birkhoff 1967; Stoy 1981) for • • • ,gt, with respect to E. Since AP (G, tr) is finite, the presence of a 1.u.b. for any subset means it has a maximum element, which we will call APMAX(G,tr). This predicate APMAX(Gm.) will assign true to a symbol A if there is some analyzability predicate (for (G, tr)) that makes this assignment.&apos; Then define a nonterminal A (from G) to be directly analyzable iff </context>
</contexts>
<marker>Stoy, 1981</marker>
<rawString>Stoy, Joseph E. 1981. Denotational Semantics: the Scott-Strachey approach to programming language theory. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Henry Thompson</author>
<author>Graeme Ritchie</author>
</authors>
<title>Implementing natural language parsers.</title>
<date>1984</date>
<booktitle>Artificial Intelligence: Tools, Techniques and Applications. Harper and Row,</booktitle>
<volume>9</volume>
<pages>245--300</pages>
<editor>In T. O&apos;Shea and M. Eisenstadt, editors,</editor>
<location>New York, Chapter</location>
<contexts>
<context position="18568" citStr="Thompson and Ritchie (1984)" startWordPosition="3259" endWordPosition="3262">y strategy-marked context-free grammar. Then a rule r E P is said to be: 1. top-down, if 0 E tr(r). 2. bottom-up, if there is an i&gt; 0 such that i E tr(r). 3. purely bottom-up, if 0 tr(r). 4. purely top-down, if tr(r) = {0}. 3.3 Active Charts The techniques and structures known as active charts have been in use for parsing (at least in the area of natural language processing) since the early 1970s. The method 462 Ritchie Completeness Conditions for Mixed Strategy Bidirectional Parsing is a generalization of Earley&apos;s algorithm (Earley 1970), and tutorial expositions of the ideas can be found in Thompson and Ritchie (1984) or Winograd (1983). In keeping with more recent presentations (e.g., Shieber, Schabes, and Pereira 1995; Sikkel and op den Akker 1996) we define the parsing principles as well-formedness conditions on complete charts, abstracting away from the sequence of steps used to build them. Definition 6 Given a CFG G of the form (VN, VT, P. S) a double-dotted rule based on G is a triple (p,1,r) where p is a rule in P of the form Ao —&gt; k and 1,r are integers such that 0 &lt;1 &lt; r &lt; k. Such a rule will be written as: Ao A1 ...AI. Ai±i • • • Ar • Ard-i • • • Ak for ease of exposition and similarity to previo</context>
</contexts>
<marker>Thompson, Ritchie, 1984</marker>
<rawString>Thompson, Henry and Graeme Ritchie. 1984. Implementing natural language parsers. In T. O&apos;Shea and M. Eisenstadt, editors, Artificial Intelligence: Tools, Techniques and Applications. Harper and Row, New York, Chapter 9, pages 245-300.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alistair Willis</author>
</authors>
<title>Exploring Chart Parsing Mechanisms.</title>
<date>1996</date>
<tech>Master&apos;s thesis,</tech>
<institution>Department of Artificial Intelligence, University of Edinburgh,</institution>
<location>Edinburgh, Scotland.</location>
<contexts>
<context position="59955" citStr="Willis (1996)" startWordPosition="11230" endWordPosition="11231"> (Satta and Stock 1989) that allows a form of purely bottom-up bidirectional parsing, but they do not explore the question of mixed strategy invocation of rules. Most of the mechanisms in their bottom-up method are aimed at avoiding redundant edges in the chart, a problem that has been ignored here by working at a more abstract, set-theoretic level. Satta and Stock provide a more algorithmic approach in which such issues are of concern. A practical implementation of the definitions given above might have to consider whether their system could be adopted to achieve greater efficiency. However, Willis (1996) points out that in some situations the scheme given in Satta and Stock (1989) can be less efficient (in terms of edges introduced to the chart) than a fairly naive implementation of a mixed strategy chart parser whose grammar is annotated to run bottom-up (essential for comparison with the Satta and Stock algorithm). This seems to be because the Satta and Stock method involves the introduction, when a constituent is found, of an edge for every rule with that type of constituent on its RHS. 7.2 Head Parsing There has been a growth in interest over the past decade or so in head-driven parsing (</context>
<context position="65555" citStr="Willis 1996" startWordPosition="12163" endWordPosition="12164">es, such as English. Although they did not have any real statistical evidence that this guidance leads to more efficient parsing, they claimed that it did appear to help, judging by the performance of the parser they had implemented for use in an English-language query interface. That approach is dependent on the grammar writer having some linguistic intuitions about which constituents are best parsed bottom-up and which are best parsed top-down. Alternatively, the rule annotations could be developed from statistics about rule usage in parsing suitably large corpora. Some preliminary results (Willis 1996) suggest that on small grammars, gains of up to 35% can be made in efficiency (measured in terms of chart entries) by using certain combinations of the mechanisms formalized here. These gains are not great, and it is unclear whether similar improvements could be achieved in realistically large natural language grammars. The formal results in Sections 4 and 5 above suggest that it may not be worthwhile carrying out such experiments, unless grammars are restricted to those that are directly analyzable. 482 Ritchie Completeness Conditions for Mixed Strategy Bidirectional Parsing Context-free gram</context>
</contexts>
<marker>Willis, 1996</marker>
<rawString>Willis, Alistair. 1996. Exploring Chart Parsing Mechanisms. Master&apos;s thesis, Department of Artificial Intelligence, University of Edinburgh, Edinburgh, Scotland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Winograd</author>
</authors>
<title>Language as a Cognitive Process. Volume I: Syntax.</title>
<date>1983</date>
<publisher>Addison-Wesley,</publisher>
<location>Reading, MA.</location>
<contexts>
<context position="18587" citStr="Winograd (1983)" startWordPosition="3264" endWordPosition="3265">grammar. Then a rule r E P is said to be: 1. top-down, if 0 E tr(r). 2. bottom-up, if there is an i&gt; 0 such that i E tr(r). 3. purely bottom-up, if 0 tr(r). 4. purely top-down, if tr(r) = {0}. 3.3 Active Charts The techniques and structures known as active charts have been in use for parsing (at least in the area of natural language processing) since the early 1970s. The method 462 Ritchie Completeness Conditions for Mixed Strategy Bidirectional Parsing is a generalization of Earley&apos;s algorithm (Earley 1970), and tutorial expositions of the ideas can be found in Thompson and Ritchie (1984) or Winograd (1983). In keeping with more recent presentations (e.g., Shieber, Schabes, and Pereira 1995; Sikkel and op den Akker 1996) we define the parsing principles as well-formedness conditions on complete charts, abstracting away from the sequence of steps used to build them. Definition 6 Given a CFG G of the form (VN, VT, P. S) a double-dotted rule based on G is a triple (p,1,r) where p is a rule in P of the form Ao —&gt; k and 1,r are integers such that 0 &lt;1 &lt; r &lt; k. Such a rule will be written as: Ao A1 ...AI. Ai±i • • • Ar • Ard-i • • • Ak for ease of exposition and similarity to previous literature. Wher</context>
</contexts>
<marker>Winograd, 1983</marker>
<rawString>Winograd, Terry. 1983. Language as a Cognitive Process. Volume I: Syntax. Addison-Wesley, Reading, MA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>