<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.82488">
American Journal of Computational Linguistics Microfiche 32
</note>
<sectionHeader confidence="0.9305775" genericHeader="method">
PROCEED NGS
13TH ANNUAL MEETING
ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
1 : LANGUAGE UNDERSTANDING SYSTEMS
</sectionHeader>
<author confidence="0.496653">
Timothy C. Diller, Editor
</author>
<affiliation confidence="0.279807">
Sperry-Univac
</affiliation>
<note confidence="0.639942">
St. Paul, Minnesota 55101
</note>
<bodyText confidence="0.912155923076923">
Copyright 01975 by the Association for computational Linguistics
2
PREFACE
The 13th annual ACL meeting was held at Boston, Massa-
chusetts, October 30 - November 1, 1975, in conjunction with
the 38th meeting of the American Society for Information
Science. The ACL thanks the ASIS for its assistance in pub-
licizing the conference and in handling registration.
This and the following four microfiches contain 27 of
the 30 papers presented at the meeting. The breadth of the
conference is evident in (a) the modes of communication in-
vestigated (speech, sign language, and written text), (b) the
styles of communication (monologues, dialogues, and note
making), and (c) the uses envisioned for the processing of
language data (e.g., theoretical modeling, data collection and
retrieval, game playing, story generation, idiolect charac-
terization, and automatic indexing).
Topics considered include the development of language
understanding systems, the integration and utilization of
specific components of language, specifically syntax and
semantics, the representation and use of discourse structure
and general world knowledge, and the construction of text
processing systems.
The program committee was solely responsible for select-
ing the talks to be given, and hence the papers to be pub-
lished herein. (Regretfully, nearly half of those submitted
</bodyText>
<sectionHeader confidence="0.233831" genericHeader="method">
3
</sectionHeader>
<bodyText confidence="0.959306222222222">
could not be accepted for lack of program time.) Members of
the program committee were Jonathan Allen, Joyce Friedman,
Bonnie Nash-Webber, and Chuck Rieger. A special word of ap-
preciation is due Jonathan Allen, who also served as Local
Arrangements Chairman. Working with him were Betty Brociner
and Skip McAfee of the ASIS. Aravind Joshi, president of
ACL, provided guidance in all areas of preparation.
The AJCL kindly provided advance publication of the
accepted abstracts and now makes possible the publication of
the entire proceedings. David Hays, editor of AJCL, provided
guidance in publication format and each author provided final
copy in accordance with requested specifications. The Center
for Applied Linguistics (in particular, David Hoffman and
Nancy Jokovich with guidance from Hood Roberts) contributed
In a variety of ways, most notably in the preparation of
meeting handbooks.
This microfiche contains the papers as submitted by
their authors for five of the six talkt touching on Language
</bodyText>
<note confidence="0.638338125">
Understanding Systems. The paper detailing &amp;quot;Conceptual
Grammar&amp;quot; by William Martin was too long for inclusion in
this microfiche and will appear elsewhere. My thanks to
Yorick Wilke for chairing the session.
-Timothy C. Diller
Program Committee Chairman
4
TABLE (), CONTENTS
</note>
<title confidence="0.309791666666667">
Program Schedule . • • • • • • . • • • • • 5
SESSION 1: LANGUAGE UNDERSTANDING SYSTEMS
PEDAGLOT and Understanding Natural Language Processing
</title>
<author confidence="0.575531">
William Fabens . . • • • • • • • 0 • • • 9
</author>
<title confidence="0.92485475">
A General System for Semantic Analysis of English And
its Use in Drawing Maps from Directions Jerry .R. Halts • 21
An Adaptive Natural Language Parser Perry L. Miller . . 42
Conceptual Grammar (abstract only) William A. Martin . . 57
</title>
<author confidence="0.582301">
Semantic-based Parsing and a Natural-language Interface
</author>
<affiliation confidence="0.569763">
for Iftteractive Data Management Jo&apos;inF, Burger, Antonio
</affiliation>
<note confidence="0.932182142857143">
Lead, and Axle Shoshani • • • •• • • • • • . 58
•
PHLIQA 1: Multilevel Semantics in Question Answering
P. Medema, W. J. Bronnenberg, H. C. Bunt, S. P. J. Landsbergen,
R. J. H. Scha, W. J. Schoenmakers, and E. P. C. van Utteren . 72
THIRTEENTH ANNUAL MEETING
THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
</note>
<address confidence="0.449772">
Sheraton Boston Hotel
Boston, Massachusetts
October GO-November 1, 1975
Thursday, October 30, 1975
SESSION 1: LANGUAGE UNDERSTANDING SYSTEMS
Session Chairman: Yorick Mks - University of Edinburgh
</address>
<note confidence="0.5955942">
9:00 A.M. Greetings and Introductory Remarks
9:15 A.M. PEDAGLOT and Understanding Natural Lang-uage Processing
William Fabens - Rutgers University
9:40 A.M. /1 System for General Semanitic Analysis And Its Use
In Drawing Maps from Directions
Jerry R. Hobbs - The City College of CUNY
10:05 A.M. an Adaptive Natural Language Parser
Perry L. Miller M 1 T.
[0:30 A.tvi. COFFEE &amp; DONUTS
L100 A.M. Conceptual Grammar
</note>
<author confidence="0.730144">
William A. Martin - MIT
</author>
<affiliation confidence="0.7250365">
11:30 A.M. Semantic-Based Parsing And A Natural-Language Interface
For interactive Data Afanagernent
John F. Burger, Antonio Leal, and Arie Shoshani -
System Development Corporation
</affiliation>
<note confidence="0.704453428571429">
12:00 NOON PIILIQA 1: Multilevel Semantics in Question Answering
P. Iviedema, el. al - Philips Research Laboratories,
The Netherlands
() P.M. LUNCHEON BREAK
5
2
SESSION 2: LANGUAGE GENERATION SYSTEMS
</note>
<author confidence="0.608822">
Session Chairman: Martin Kay - Xerox Corporation
</author>
<figure confidence="0.680891333333333">
6
2:00 P.M.
2:30 P.M.
3:00 P.M.
3:30 P.M.
4:00 P.M.
</figure>
<title confidence="0.984686">
A Framework for Writing Generation Grammars
for Interactive Computer Programs
</title>
<author confidence="0.963707">
David McDonald - M I T.
</author>
<affiliation confidence="0.587975">
Incremental Sentence Processing
</affiliation>
<author confidence="0.890846">
Rodger Knaus - Bureau of the Census
</author>
<title confidence="0.552418">
A Lexical Process Model of Nominal Compounding
</title>
<author confidence="0.903586">
In English
</author>
<affiliation confidence="0.9446">
J.R. Rhyne - University of Houston
</affiliation>
<address confidence="0.309988">
COFFEE &amp; DONUTS
</address>
<title confidence="0.644475">
Generation as Parsing from /1 Network into a
</title>
<author confidence="0.735663">
Linear String
</author>
<affiliation confidence="0.492929">
Stuart C Shapiro - Indiana University
</affiliation>
<subsubsectionHeader confidence="0.359842">
4:30 P.M. Speech Generation from Semantic Nets
</subsubsectionHeader>
<author confidence="0.584801">
Jonathan Slocum - Stanford Research Institute
</author>
<subsubsectionHeader confidence="0.488719">
5:00 P.M. Using Planning Structures to Generate Stories
</subsubsectionHeader>
<author confidence="0.660238">
Jim Meehan - Yale University
</author>
<note confidence="0.748742222222222">
5:30 P.M. DINNER BREAK
8:00 RM. WINE, CHEESE &amp; COMPUTER DEMONSTRATIONS
Friday, October 31, 1975
SESSION .3: PARSING, SYNTAX, /IND SEMANTICS
Session Chairman: Joyce Friedman - Stanford Research Institute
9:00 A.M. Syntactic Processing in the BBN Speech Understanding
9:30 A.M. System
Madeline Bates,- Bolt, Beranek &amp; Newman, Inc
System Integration and Control for Speech Understanding
Wilkam H. Paxton and Ann E. Robinson
Stanford Research Institute
10:00 A.M. A Tuneable Performance Grammar
Jane J. Pobinson - Stanford Research Institute
3
10:30 AM. COFFEE &amp; DONUTS
11:00 A.M. Semantic Processing for Speech Understanding
Gary G. I4endrix - Stanford Research Institute
11:30 A.M. SPS: II Formalism for Semantic Interpretation&apos; and
</note>
<title confidence="0.849517">
Its Use in Processing Prepositions that Reference Spare
</title>
<author confidence="0.946428">
Norman K Sondheimer - Ohio State University
</author>
<affiliation confidence="0.812340333333333">
12:00 -NOON The Nature and Computational Use of a Meaning
Representation for Word Concepts
Nick Cercone - University of Alberta
</affiliation>
<address confidence="0.57903325">
12:30 P.M. LUNCHEON BREAK
SESSION 4: MODELING DISCOURSE AND WORLD KNOWLEDGE I
Session Chairman: Carl Hewitt - MIT
200 P.M. Establishing Contewt in Task-Oriented Dialog.s
</address>
<note confidence="0.617918">
Barbara G. Deutsch - Stanford Research Institute
2:30 P.M. Discourse Models and Language Comprehension
</note>
<author confidence="0.494047">
Bertram C Bruce - Bolt, Beranek &amp; Newman, Inc
</author>
<subsubsectionHeader confidence="0.8493505">
3:00 P.M. judging the Coherency of Discourse (and Some
Observations /Thou: Frames/Scripts)
</subsubsectionHeader>
<affiliation confidence="0.810743">
Brian Phillips - University of Illinois at
Chicago Circle
</affiliation>
<note confidence="0.802844">
3:30 P.M. COFFEE &amp; DONUTS
400 P.M. iTh lipproach to the Organization of Mundane World
Knowledge: the Generation and Management of Scripts
</note>
<author confidence="0.729693">
R.E. Cullingford - Yale University
</author>
<affiliation confidence="0.6717385">
430 P.M. The Conceptual Description of Physical lirtivities
Norman Sadler - University of Pennsylvania
</affiliation>
<note confidence="0.5803327">
5:00 P.M. A Frame Analysis of American Sign Language
JUdy Kegi (MIT) and Nancy Chinchor (U. of Mass)
5:30 P.M. ACL BUSINESS MEETING AND ELECTION OF OFFICERS
7
DINNER: ACL BANQUET
4 8
Saturday, November 1, 1975
SESSION 5/1: MODELING DISCOURSE Sa WORLD KNOWLEDGE II
Session Chairman: Georgette Silva - System Development Corporation
9:00 A.M. Cross-Sentential Reference Resolution
</note>
<author confidence="0.676642">
David Klappholz and Abe Lockman - Columbia University
</author>
<affiliation confidence="0.4521195">
9:30 A.M. How Does a System Know When to Stop Inferencine
Stan Rosenschein - University of Pennsylvania
</affiliation>
<address confidence="0.175674714285714">
10:00 A.M. COFFEE &amp; DONUTS
SESSION 513: TEXT ANALYSIS
10:30 A.M. Developing a Computer System for Handling Inherently
Variable Linguistic Data
David Beckles, Lawrence Carrington, and
Gemma Warner - The University of thc West Indies
11:00 A.M. /1 Natural Language Processing Package
</address>
<affiliation confidence="0.747919">
David Brill and Beatrice T Oshika -
Speech Communications Research Laboratory
</affiliation>
<subsubsectionHeader confidence="0.6416425">
11:30 A.M. On the, Role of Words and Phrases in Automatic Text
Analysis and Computation
</subsubsectionHeader>
<author confidence="0.899728">
Gerard Salton - Cornell University
</author>
<affiliation confidence="0.822428666666667">
12:00 NOON Grammatical Compression in Notes and Records:
analysis and Computation
Barbara Anderson (University of New Brunswick),
Irwin Bross (Roswell Park Memorial Institute),
and Naomi Sager (New York University)
American Journal of Computational Linguistics Microfiche 32 : 9
</affiliation>
<sectionHeader confidence="0.7225575" genericHeader="method">
PEDAGLOT AND UNDERSTANDING NATURAL LANGUAGE PROCESSING
WILLIAM FABENS
</sectionHeader>
<affiliation confidence="0.869654">
COmputer Science Department
Rutgers University
</affiliation>
<address confidence="0.454162">
New Brunswick, New Jersey 08903
</address>
<email confidence="0.33804">
ABSTRACT
</email>
<bodyText confidence="0.918881454545454">
PEDAGLOT is a programmable parser, a &apos;meta-parser.&apos; To program it, one
describes not just syntax and some semantics, but also--independently--its
modes of behavior. The PEDAGLOT formulation of such modes of behavior follows
a categorization of parsing processes into attention-control, discovery, pre-
diction and construction. Within these overall types of-activities, control
can be specified covering a number of syntax-processing and semantics-process-
ing operations. While it is not the only possible way of programming a meta-
parser, the PEDAGLOT mode-specification technique is suggestive in itself of
various new approaches to modeling and understanding some language processing
activities besides parsing, such as generation and inference.
This work was sponsored by through NIH Grant #RR643.
</bodyText>
<equation confidence="0.373007">
10
Introduction
</equation>
<bodyText confidence="0.978757846153846">
It is well known that to process natural langUage, one needs both a
syntactic description of possible sentences, blended in some way with a semantic
description of a certain domain of discourse, and a rather detailed description
of the actual processes used in hearing or producing sentences.
An augmented transition network (Woods, 1970) is An example of the blending
of syntactic and quasi-semantic descriptions. Here registers would be reposi-
tories of, or pointers to, semantics. When used in conjunction with a semantic
fleAwork, an ATN can be used to parse or to generate (Simmons and Slocum, 19,72)
sentences. The issue of changing the description of the actual processes used
in such systems has been touched on by Woods (in using a &apos;generation mode&apos;), to
some extent by Simmons and Slocum (using decision functions to control style of
generation), and to a larger extent by Kaplat (1973), in his General Syntactic
Processor, GSP. GSP indeed is one example of a system in which syntax, semantics
and to some extent processes can each be usefully defined.
If we look At syntax, semantics and processes as three describable components,
these systems just mentioned illustrate how thoroughly intertwined they can become--
to the extent that theorists from time to time deny the existence or at least the
importance of some one of them. Ignoring that dispute, I would like to concentrate
on the question of being able to comprehensively describe one&apos;s theory of language
in terms of its syntax, semantics and processes in a way that allows for their
necessary and extensive intertwining connections, but at the same time allows one
to describe them independently.
I tame to the need for doing this while designing a &apos;relaxation parser,&apos; a
parser which can make grammatical relaxations if it is given an ill-formed string,
so as to arrive at a &apos;closest&apos; possible parse for the string. This problem involved
describing a &apos;correct&apos; grammar and then (in some way) describing a space of deviations
</bodyText>
<page confidence="0.489482">
11
</page>
<bodyText confidence="0.996998576923077">
that might be allowed by the parser. Thus the syntax would be fixed and the way
the parser uses it would separately have to be described. It was soon noticed
that efficiency could be greatly enhanced if some rudimentary notion of semantic
plausibility could also be used. It would have to be described in a way related
to the correct syntax but still be usable by the parser. Thus, for my purposes,
the descriptions had to be independent of one another.
One feature of a relaxation parser is that it can &apos;fill in the gaps&apos; of a
string that is missing various words. If one could, which my relaxation parser
did not, specify the semantic context of a sentence, the generated sentence might
be semantically rather plausible. In any case, the relaxation parser operates in
various respects like an actual parser or like a generator, and it was this rela-
tionship between parsing and generating that became of interest.
Out of the design of the relaxation parser, the notation (independent of syn-
tax) which to some extent describes various processes and choices of alternate ways
of processing was developed. Thus, one may take a set of syntax and semantic de-
scriptions and then through describing the processing &apos;modes&apos; involved, define a
processor which uses the particular algorithm that the individual processes together
define. One may call the parser that is programmable in its processes a meta-parser,
of which various existing _parsers and generators appear to be special casesi
A closer examination of the parser I have developed (called PEDAGLOT*) may show
some such aspects of meta-parsing, especially as regards the relationship between
parsing and generating. I will describe the syntactic and semantic parts of the
parser first by noting its resemblances to the parser of J. Earley (1970) and the
ATN system of Woods. Then I will describe the process-type specifications that are
available, and the use of meta-parsers as a basis for defining general language be-
haviors. Further detail can be found in the PEDAGLOT manual (Fabens, 1972 and 1973).
</bodyText>
<footnote confidence="0.373942">
*for pedagogic poliglot
</footnote>
<page confidence="0.427888">
12
</page>
<sectionHeader confidence="0.472137" genericHeader="method">
1. The Core of the Parser
</sectionHeader>
<subsectionHeader confidence="0.626417">
The fundamental operation of the parser is very similar to the operation
</subsectionHeader>
<bodyText confidence="0.7351835">
of Barley&apos;s parser, with augmentations for recording the results of parses
(e.g., their tre structure, and various of their attributes, which I call
&apos;tags&apos;). It is given a grammar as a set of context-free rules with various
extensions, most important of which are that LISP functions may be used as
</bodyText>
<subsectionHeader confidence="0.50906">
predicates instead of terminals, and thap each rule may be followed by opera-
</subsectionHeader>
<bodyText confidence="0.743405">
tions that are defined in tbrms of the syntactic elements of the rule in question.
</bodyText>
<subsectionHeader confidence="0.578256">
An example of this notation is as follows:
</subsectionHeader>
<table confidence="0.931109">
S NP VP
=&gt; [AGREE [REF NP][VB VP]]
[SUBJ = [REF NP]][OBJ . [REF VF] [VB = [VB VP]]
S NP [BE] VPASS] BY NP
=&gt; [AGREE [REF NP][VB[BE]]]
[SUBJ = [REF NPM[OBJ = REF NP]][VB = [VB[VPASS]]]
NP [DET][N]
=&gt; [REF = [N]]
VP ÷ [V]NP
=&gt; [VB = [V]][REF = [REF NP]]
</table>
<subsectionHeader confidence="0.559757">
Here, each bracketed symbol is the name of a recognition predicate (e.g.,
</subsectionHeader>
<bodyText confidence="0.741263571428571">
[N] recognizes nouns, [BE] recognizes forms of qo be&apos;). Following the =&gt; are
the post-recognition functions. Fox instance [AGREE [REF NP][VB VP]] specifies
a call to the AGREE function which is given, as arguMents, the REF attribute (tag)
of the sub-parse involved in that rule and the VB attribute of the VP part of
the rule.
Following is a parse tree for &apos;The Man Bites the&amp;quot; Dog&apos; and values of tags
after the parse.
</bodyText>
<equation confidence="0.7662595">
S = (SUBJ.Man, OBJ.Dog, REF.{Man,Dog),VB=Bites)
NP= (REF.Mah) VP= (REF=Dog , VB..Bites)
</equation>
<page confidence="0.549974">
13
</page>
<figure confidence="0.988447142857143">
/////N
[DET] [N]
The Man
[V] NP
Bites
[DET] [N]
The Dog
</figure>
<subsectionHeader confidence="0.517089">
The general flow of the parser is from top-down, and as the lowest compo-
</subsectionHeader>
<bodyText confidence="0.986781111111111">
nents (symbols in the string) are found, the post-recognition functions that are
associated with the rule that recognized them are applied. Tags become associated
with sub-parses when the post-recognition operation uses the form [x = y] (in which
the value referenced by y is stored as the x tag of the sub-parse). In the example,
[DET] and [N] recognize &apos;The Man&apos; and &apos;Man&apos; is used as the REF attribute of the
first NP. In the second S rule, the operation of [SUBJ [REF NP&apos;]] would be to
retrieve the REF tag of the second NP (thus the prime), and to store that as the
SUM tag of the final parse.
As in most top-down parses, this parser begins with S and its two rules,
</bodyText>
<footnote confidence="0.93892675">
since S is non-terminal. S is expanded into the two sequences of matches it should
perform. This expansion results in various (in this cast, two) predictions of what
to find next. When the initial symbol in some rule is a terminal or a predicate,
a discovery is called for (in which a match is performed, possibly involving the
known values of the tags). When some complete sequence of elements is found (here,
for instance, when NP [DETUN] has matched the [N]). Construction invokes the
post-recognition operations and then usually completes some earlier part of a rule
(here, the &apos;NP&apos; Df S NP VP) go further predictions (involving VP) or discoveries
</footnote>
<page confidence="0.762913">
14
</page>
<bodyText confidence="0.9378715">
are then specified.
have broken up the parsing process into these three parts so as to similarly
catalog the &apos;parsing modes,&apos; turning this parser into a meta-parser. Before doing
so, I should note that this parser suites each result under construction in a
&apos;chart&apos; as is done by Kaplan in his GSP, so that, for instance, the NP &apos;test&apos;
will only have to be evaluated once for each place one is wanted in the string.
</bodyText>
<subsectionHeader confidence="0.97181225">
Illustration of PEDAGLOT&apos;s Parsing Chart
Simple Arrows indicate &apos;Predictions.&apos;
Double Head ATTOWS indicate &apos;Discoveries.&apos;
Dotted Arrows indicate &amp;quot;Construction.&apos;
</subsectionHeader>
<bodyText confidence="0.667686">
Also, for various well known reasons of efficiency, Earley&apos;s concept of
</bodyText>
<subsectionHeader confidence="0.572028">
independent processing of syntactic events is used (combined conmptually with
</subsectionHeader>
<bodyText confidence="0.938894666666667">
the chart), so that a main controller can evaluate the individual syntactic &apos;tests&apos;
in almost any order, and not just in a backtracking sense (cf. Woods, 1975). The
efficiency is realized here since many &apos;partial parses&apos; (partially recognized forms)
</bodyText>
<figure confidence="0.992362909090909">
VP -+ [V] NP
NP [DET][N]
[BE]
Bites
(i[DET]
The
&amp;quot;NP [DET] [N]
S NP [BE] [VPASS] BY NP
■
[V]-
15
</figure>
<tableCaption confidence="0.6281745">
are effectively abandoned if other results can complete the parse, or a sub-
parse, first.
</tableCaption>
<sectionHeader confidence="0.921012" genericHeader="method">
2. Meta-Parsing Modes
</sectionHeader>
<bodyText confidence="0.953876567567568">
One can see that, except for the notational inefficiencies of the context
free formalism (as opposed to the augmented transition network form), this parser
is very much like other standard parsers (especially ATN&apos;s). It differs in that
there is a way,of specifying how to proceed.- Currently, this system has approxi-
mately a dozen &amp;quot;modes&apos; and I will present some of them here. Each mode specifies
how to handle a certain part of the parsing process. They can be classified into
four categories: attention control, prediction, discovery and construction.
a. Attention Control Modes:
Since the parser operates on a chart of independent events (&apos;parsing
queItions&apos;), one must give the parser a method of sequencing through them.
Thus, one may specify &apos;breadth-first&apos; or &apos;depth-first&apos; and the appropriate
mechanism will be invoked (this merely involves the way the processor stacks
its jobs). A &apos;best-first&apos; option is -under development, which, when given an
evaluation function to be applied to the set of currently active partial
parses, allows the system to operate on the &apos;best&apos; problem next. Experi-
ments with this mode have so far been inconclusive.
One also can specify when to stop (i.e., at the first complete parse,
or to wait until all other ambiguous parses have been discovered). The dis-
ambiguation routine (which is described as a part of the construction modes)
defines which parse is &apos;best&apos;. Further, one may specify a left-to-right or
right-to-left mode of how to progress along the string.
b. Discovery Modes:
The starting point of building a relaxation parser is to specify what
to do when an exact match is not made. If the parser is expecting one word
and finds another it can look around the indicated place in the string to find
16
what it is looking for, or it can in certain other circumstances simply
insert the expected word into the string. Thus, under discovery modes,
there are various options: either the parser is allowed to attempt matches
in out-of-sequence parts of the string, or not. And if not, or if no such
match is found, the parser may or may not be allowed to make an insertion.
So in PEDAGLOT, there is an INSERT mode (and various restricted versions
of it) and a &apos;where to look&apos; mode which is used to control the degree to which
the parser can try to find out-of-place matches. There are tags associated
with these two specifications, the INSERT tag and the OMIT tag, which are
associated with the parses involving insertions and omissions that contain
the number of insertions made and the number of input symbols omitted in
building the parse.
There is also a rearrangement mode. Thus, given certain constraints,
the parser could be givep &apos;The Bites Man Dog&apos; and produce a parse for &apos;The
Man Bites the Dog&apos; since it would have found &apos;Man,&apos; by temporarily omitting
&apos;Bites,&apos; but then it looks for and finds &apos;Bites&apos; and finally, finding no se-
cond ethe,,the,&apos; inserts one (or some other determiner because of the [DET] func-
tion]) and finds &apos;Dog. In a similar way it would try to produce a passive
form (i.e., the Man Is Bitten By the Dog) but since this involves more inser-
tions, etc. it would not be chosen.
These heuristics are controlled by recording numerical summary tags
with each sub-parse that participate in, and are &apos;judged&apos; by the disambiguaticla
routines. Similar ideas are used by Lyon (1974).
c. Prediction Modes:
As Woods (1975) has pointed out, the extent to which a parser&apos;s prediction
increases efficiency varies with the quality of the expected input. This fact
affects greatly our discovOry procedures, since, if insertions are to be made,
one ought to be rather suite of one&apos;s predictions, or risk a combinatorial ex-
17
plosion. In PEDAGLOT, there is a programmable &apos;choice&apos; function that&apos;con-
trols predictions. Specifically, when the parser encounters a non-terminal
symbol, that symbol is the left-hand side of various rules. An uncontrolled
prediction (used by a canonical top-down parser) is to select each such rule
as the expansion. Intuitively, however, people do not seem to do this. In-
stead, as in an ATN, they try one and only if that fails, go into the next.
In PEDAGLOT, the choice of which rule to try can be defined as the result of
the call to a &apos;choose&apos; function (or it can be left uncontrolled). We have
designed various approaches to such predictions (e.g., a limited key-word
scan of the incoming string, and the use of &apos;language statistics&apos; such as the
set of rules which can generate the next symbol in the string as their left
most symbol).
The prediction is currently made once for any giVen choice point; its
outcomes are expected to be an ordered set of rules to try next.
d. Construction Modes:
The phase of parsing in which the parts of the parse tree and associated
t‘g values are formed, is a place where most of the non-syntactic information
(tags) about the string being parsed can come into play.
In the first place, new tags can be formed as functions of lower level
parse tags through a process called melding. Thus, &apos;nonsense&apos; can be discovered
and pronoun references can sometimes be tied down. In the second place, it is
a result of construction that ambiguity is discovered and dealt with.
Since these features of parsing deal primarily with semantics (and since,
if anywhere, semantic representations of the string reside in the tags), most
of the PEDAGLOT construction modes involve tags.
One may explicitly meld tag values by using post-recognition operators, or
one may define an &apos;implicit&apos; melding routine that is associated with the tag
18
names themselves instead of with individual rules. In our example we use
this device to implicitly form a simple list of the two REF tags that be-
come associated with the S rule. This implicit melding operation can also
include a blocking function, or some reference to a data base. The tags
that contain INSERT and OMIT information are used in this way to keep running
totals of, and to minimize the number of such heuristics in the relaxation
parsing modes. One may also associate a LIFT function which, when the par-
tial parse becomes complete, specifies a transformation of that tag to be
msed as the tag of the next higher level parse.
Ambiguity is discovered when two parses from the same symbol, covering
the same string segment are found. For this case, an AMBIG function is asso-
ciated with tag names, and it makes a &apos;value judgement&apos; of which tag is &apos;better,
hence which interpretation to use. (Other types of criteria can also come into
play here such as user interaction, (cf. Kay, 1973).
3. The Uses of Meta-Parsers
I have just catalogued some of the parsing modes available in PEDAGLOT. Others,
such as Bottom-Up (instead of Top-Down) or Inside-Out (instead of Left-to-Right, etc.),
are envisionecabut not implemented. Since PEDAGLOT is an interactive program, the
user can change modes at will, just as he can change syntax or introduce new tags.
Thus, the obvious first use of meta-parsers is that one may use them to design
language processors without having to tie oneself down from the start to say, a
depth-first parser.
Meta-parsers also have a certain amount of tractibility that parsers that
blend all activities into one huge network may not. One may see at a rather high level
what is going to be happening (i.e., all tags of a certain name will meld together
in a certain way, unless the grammar specifies otherwise). If one, however, wants
certain forms of local behavior, one may use predicates or functions on individual
rules. Further, if one wants to change the order in which predictions are evaluated,
</bodyText>
<page confidence="0.448466">
19
</page>
<bodyText confidence="0.958011730769231">
one can program a &apos;choose&apos; function which will make that global change. To a
large extent, the language designer may specify much of the processor in broad
terms and still be able to control local events where necessary.
In a more general sense, a meta-parser allows one to understand and build
higher order theories about how people might represent and process language.
For instance, while it may be true that generating is the inverse of parsing,
there is more than one way to do such inverting. One could start from a semantic
network, using the choose function along with the INSERT mode to restrict means of
expression consistent with the intended message, and using AMBIG functions to weed
out all but reasonable messages from among the many the parser may produce or one
might simply take from the semantic network a simple string of meaningful words,
and then use a less tightly programmed &apos;relaxation parser&apos; to rearrange these words
to be syntactically correct. We are now considering using a crude &apos;backwards&apos; mode
which begins with the operation part of a rule and, by using predicates (e.g., AGREE)
to yield inverses, specifies what the context-free pattern must produce. Thus there
are many variations of how to generate using a meta-parser.
In the area of language inference, to take another example of language processing,
PEDAGLOT suggests various differing ways of approaching the problem. First, ohe may
use it as a &apos;relaxation-parser,&apos; the &apos;parse tree&apos; can be pattern-matched against
the new sentence, and hypotheses can be formed. Or, one could place a more rudimentary
inference system on the &apos;prediction&apos; part of the processor itself, and using other
controls, the predictions that are successful could be rewritten as a new grammar.
These two learning paradigms could each be strengthened by way of the use of tags
to contain (in a sense) the meaning of the sentences to be learned. Each of these
paradigms can be modeled using a meta-parser like PEDAGLOT. Thus, a meta-parser can
raise (and be prepared to answer) a number of interesting questions.
</bodyText>
<figure confidence="0.969873">
20
References
</figure>
<figureCaption confidence="0.8770635">
Earley, J. (1970), &amp;quot;An Efficient Context-Free Parsing Algorithm,&amp;quot; Comm. ACM 13,
number 2, (February 1970), pp. 94-102.
Fabens, W. (1972), PEDAGLOT Users Manual, Rutgers University CBM-TR-12,
Oct. 1972.
Fabens, W. (1973), PEDAGLOT Users Manual: Part II, Rutgers University CBM-TR-23,
Nov. 1973.
</figureCaption>
<bodyText confidence="0.488937923076923">
Kaplan, R.M. (1973), &amp;quot;A General Syntactic Processor,&amp;quot; in R. Rustin (ed.)
Natural Language Processing, New York: Algorithmics Press, (1973), pp. 193-242.
Kay, M. (1973), &amp;quot;The MIND System,&amp;quot; in R. Rustin (ed.) Natural Language Processing,
New York: Algorithmics Press, (1973), pp. /55-188.
Lyon, G. (1974), &amp;quot;Syntax-Directed Least-Errors Analysis for Context-Free
Languages: A Practical Approach.&amp;quot; Comm. ACM 17, number 1, (January 1974),
PP. 3-13.
Simmons, R. and Slocum, J. (1972), &amp;quot;Generating English Discourse from Semantic
Networks:&amp;quot; Comm. ACM 15, number 10, (October 1972), pp. 891-905.
Woods, W.A. (1970), &amp;quot;Transition Network Grammars for Natural Language Analysis.&amp;quot;
Comm. ACM 13, number 10, (October 1970), pp. 591-606.
Woods, W.A., (1975), Syntax, Semantics, and Speech, BBN Report No. 3067, A.I.
Report No. 27. Bolt Beranek and Newman Inc., to appear in D.R. Reddy (ed.)
</bodyText>
<subsectionHeader confidence="0.58117">
Speech Recognition, Academic Press (1975).
</subsectionHeader>
<bodyText confidence="0.513828">
American bum! of Computational Linguistics Microfiche 32 :21
</bodyText>
<sectionHeader confidence="0.705392" genericHeader="method">
A GENERAL SYSTEM FOR SEMANTIC ANALYSIS OF ENGLISH AND ITS USE
IN DRAWING MAPS FROM DIRECTIONS
JERRY R. HoBBs
</sectionHeader>
<affiliation confidence="0.7466158">
Department of Computer Science
The City College of the
City University of New York
Convent Avenue at 140th Street
New York, New York 10031
</affiliation>
<sectionHeader confidence="0.910618" genericHeader="method">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.958926368421053">
We describe a semantic processor we are constructing which is
intended to be of general applicability. It is designed around
semantic operations which work on a structured data base of world
knowledge to draw the appropriate inferences and to identify the
same entities in different parts of the text. The semantic oper-
ations capitalize QA the high degree of redundancy exhibited by
all texts. Described are the operations far interpreting higher
predicates, for detecting some intersentential,relations, and in
particular detail, for finding the antecedents of definite noun
phrases. The processor is applied to the problem of drawing maps
from directions. We describe a lattice-like representation
intermediate between the linguistic representation of directions
and the visual representation of maps.
OVERVIEW1&apos;2
We are trying to construct a semantic processor of some
This research was supported by the Research Foundation of the
2 City University of New York under Faculty Grant No. 11233.
The author would like to express his indebtedness to Harry Elam
for many insights into the problems discussed here.
</bodyText>
<page confidence="0.6440745">
1
22
</page>
<bodyText confidence="0.987438230769231">
generality. We are using as our data base a set of facts involv-
ing spatial terms in English. To test the processor and to study
the interfacing of semantic and task components, we are building
a system which takes as input directions in English of how to get
from one place to another and outputs a map, a map such as one
might sketch for an unfamiliar region, hearing the directions
over the phone.
A typical input might be the text
&amp;quot;Upon leaving this building, turn right and follow
Washington Street three blocks. Make a left. The (1)
library is on the right side of the street before
the text corner.&amp;quot;
The output would be the map
</bodyText>
<sectionHeader confidence="0.493871" genericHeader="method">
-1,410 Library
</sectionHeader>
<subsectionHeader confidence="0.547073">
Washington Street
</subsectionHeader>
<bodyText confidence="0.963554916666667">
This Building
To bypass syntactic problems, we are using as our input the
output of the Linguistic String Project&apos;s transformational pro-
gram (Grishman et al. 1973, Hobbs &amp; Grishman), which is very
close to a predicate-like notation. The semantic component is
designed around general semantic operations which work on a
structured data base of world knowledge to draw the appropriate
inferences and to identify phrases in different part d of the text
which refer to the same entity. The text, augmented and inter-
related in this way, is then passed over to the task component,
which makes arbitrary decisions when the map requires information
not given by the directions and produces the map.
</bodyText>
<page confidence="0.422307">
23
</page>
<sectionHeader confidence="0.642751" genericHeader="method">
ORGANIZATION OF TEXT AND WORLD KNOWLEDGE
</sectionHeader>
<bodyText confidence="0.995216">
The two problems of semantic analysis are to find, out of a
potentially enormous collection of inferences, the appropriate
inferences, and to find them quickly. Our solution to the first
is in our semantic operations described below. Our approach to
the second problem is in the organization of the data base.
The data in the semantic component is of two sorts:
</bodyText>
<listItem confidence="0.9986065">
1. The Text: the information which is explicitly in the
text. In the course of semantic processing this is augmented by
information which is only implicit in the text. The text con-
sists of the set of entities X1 IX2 ... explicitly and implicitly
referred to in the text, and structures of the form p(X11X2) rep-
resenting the statements made or implied about these entities, e.g.
</listItem>
<equation confidence="0.939011">
walk(X1) = X1 walks,
building(X2) = X2 is a building,
door(X3,X2) = X3 is a door of X2.
</equation>
<listItem confidence="0.52829175">
2. The World Knowledge or the Lexicon: the system&apos;s knowl-
edge of words and the world. Words are the boundary between the
Text and the Lexicon. A word is viewed as a key indexing a large
bodf of facts (Holzman, 1971).
</listItem>
<bodyText confidence="0.99285275">
Associated with each word are a number of facts or inferences
which can be drawn from the occurrence of p(X11...1Xn) in the
Text. The facts are expressed in terms of p&apos;s set of parameters
and a set of other lexical variables
standing for entities whose existence is also implied. A fact
consists of enabling conditions and conclusions. When
occurs in the Text and the semantic operations determine a
24
particular inference appropriate, its enabling conditions are
checked. If they hold, the conclusions are instantiated by
creating a copy of them in the Text with the lexical variables
replaced by Text entities.
Clusters. One way tO state the &amp;quot;frames&amp;quot; problem (Minsky
1974) is &amp;quot;How should the data base be organized to guide, confine,
and make efficient the searches which the semantic operations
require?&amp;quot; We approach this by dividing the sets of inferences
into clusters according to topic and salience in the particular
application. In the searches, the clusters are probed in order
of their
concerns
example,
salience. In our application, the top-level cluster
the one-dimensional aspects of objects and actions. For
the fact about a block that it is the distance between
is in the cluster. If &amp;quot;around the block&amp;quot; is
salient clusters will have to be accessed to
two intersections
encountered, less
find informatioa about the two-dimensional nature of blocks. The
most important fact about an apartment building is that it is a
building, to be represented by a square on the map. But if the
directions take us inside the building, up the elevator, and
along the hallway, the cluster of facts about the interiors of
buildings must be accessed.
A self-organizing list (Knuth 1973) of the clusters is main-
tained--when a fact in a cluster is used, it becomes the top-
level cluster--on the assumption that the text will continue to
talk about the same thing.
The &amp;quot;Truth Status&amp;quot; of Inferences. In natural language,
unlike mathematics, one is not always free to draw certain
</bodyText>
<page confidence="0.489849">
25
</page>
<bodyText confidence="0.995176580645161">
inferehces. We tag our inferences always, normally, or sometimes.
These notions are defined operationally. An always inference is
one we are always free to draw, such as that a street is a path
through space. A normally inference is one we can draw if it is
not explicitly contradicted elsewhere, such as that buildings
have windows. A sometimes inference may be drawn if reinforced
elsewhere, such as the fact used below that a building is by a
street. This classification of inferencescuts across the cluster
structure of the Lexicon.
Lattices. A large number of statements in any natural lan-
guage text, especially the texts this system analyzes, involve a
transitive relation, or equivalently, say something about an
underlying scale. For example, the word &amp;quot;walk&amp;quot; indicates a
change of location along a path through space, or a distance
scale; &amp;quot;turn&amp;quot; indicates a change along a scale of anguLar orien-
tation.
In any particular type of text there are scales or transitive
relations which are important enough to deserve a more economical
representation than predicate notation. In this particular task,
the important scales are a distance scale, a subscale of this
indicating the path &amp;quot;you&amp;quot; All travel, and a scale representing
angular orientation. This is the principal information used in
constructing the map. For these scales we translate into a
directed graph or lattice-like representation (Hobbs 1974).
Some of the things which can be said about the structure of
a scale are that some point is on the scale, that of two points
on the scale one is closer to the positive end than the other,
26
and that a scale is a part of another scale. If a point B is
Closer to the positive end of the scale than point A, this Tact
is represented by
</bodyText>
<figure confidence="0.865897666666667">
A • B
If point C lies in the interval from A to B the representation is
A
The diagram
C D
A
</figure>
<bodyText confidence="0.995955">
mean the scale from C to D is part of the &apos;scale from A to B. It
is possible to represent incompleteness of information. For exam-
ple, if it is known that points A and B both lie in a region R
of a scale but their relative positions are not known and if it
is known about C only that it precedes B this is represented by
The lattice for the distance scale for text (1) is as follows:
</bodyText>
<table confidence="0.538810625">
Washington St.
The Second St.
the
first
cross
St.
This
Bldg. &amp;quot;
</table>
<bodyText confidence="0.898342">
Library
The lattices are intermediate between the linguistic repre-
sentation of the directions and the visual representation of the
maps. They are used at several points in the semantic and task
</bodyText>
<page confidence="0.488908">
27
</page>
<bodyText confidence="0.9954605">
processes. They can be constructed for any transitive relation,
and could be very useful, for example, in representing causal and
enabling relations in a system translating descriptions of algo-
rithms into flowcharts or programs.
</bodyText>
<sectionHeader confidence="0.990303" genericHeader="method">
SEMANTIC OPERATIONS
</sectionHeader>
<subsectionHeader confidence="0.640831">
Basic Principle of Semantic Analysis. We believe the key to
</subsectionHeader>
<bodyText confidence="0.999456142857143">
the first problem of semantic analysis, that of finding which
inferences are appropriate, is Joos&apos; Semantic Axiom Number One
(Joos 1972), or what I will call the Principle of *Knitting.
Restated, this is, &amp;quot;The important facts in a text will be repeat-
ed, explicitly or implicity.&amp;quot; That is, we capitalize on the very
high degree of redundancy that characterizes an texts. Consider,
for example, the simple sentencer, &amp;quot;Walk out the door of this
building.&amp;quot; &amp;quot;Walk&amp;quot; implies motion from one place to another.
&amp;quot;Out&amp;quot; implies motion from inside something to the outside. &amp;quot;Door&amp;quot;
is something which permits motion from inside something to the
outside or from the outside to the inside, or if closed, prevents
this motion. &amp;quot;Building&amp;quot; is something whose purpose is for people
to be in. Thus, all four content words of the sentence repeated-
ly key the same facts. Those inferences which should be drawn
are those which are keyed by more than one element in the text.
This principle is used both formally and informally by the
semantic operations. It is used formally in the interpretation.
of higher predicates and in finding antecedents. It is used more
informally for deciding among competing plausible antecedents,
resolving ambiguities, detecting intersentential relations, and
knitting the text together in some minimal way. Here it is,
</bodyText>
<page confidence="0.271916">
28
</page>
<bodyText confidence="0.997053333333333">
primarily the formal uses that will be described.
interpretation,of Higher Predicates. In &amp;quot;walk out&amp;quot;, &amp;quot;walk
slwoly&amp;quot;, and &amp;quot;pleasant walk&amp;quot;, the higher predicates &amp;quot;out&amp;quot;, &amp;quot;slow&amp;quot;
and &amp;quot;pleasant&amp;quot; all apply to &amp;quot;walk&amp;quot;, but they narrow in on differ-
ent aspects of walking. That is, each demands that a different
inference be drawn from the statement that &amp;quot;X walks&amp;quot;. &amp;quot;Out&amp;quot; and
&amp;quot;slow&amp;quot; demand their arguments be motion from one place to
another, forcing us to infer from &amp;quot;X walks&amp;quot; that &amp;quot;X goes from A
to B&amp;quot;. &amp;quot;Out&amp;quot; then adds information about the locations of A and
B, while &amp;quot;slow&amp;quot; says something about the speed of this motion.
&amp;quot;Pleasant&amp;quot;, on the other hand, requires its argument to be an
awareness, so we must infer from &amp;quot;X walks&amp;quot; that &amp;quot;X engages in a
bodily activity he is aware of&amp;quot;.
Stored in the Lexicon with each higher predicate is the
inference which must be drawn from its argument and the informa-
tion it adds to this inference. For example, &amp;quot;go(z11z2,z3)&amp;quot; must
be inferred from the argument of &amp;quot;out&amp;quot;. When the statement
&amp;quot;out(walk(X1))&amp;quot; is encountered in the Text, the higher predicate
operation makes efforts to find a proof of &amp;quot;go(z11z2,z3)&amp;quot; from
&amp;quot;walk(X1)&amp;quot;. The search for this inference is similar to the
search procedure described below for finding antecedents. The
facts in the resulting chain of inference are instantiated
together with the information added by the higher predicate, and
they are subsequently treated as thOugh part of. the explicit Text.
It is usual for them to be useful in further processing, unless
the modifier is simply gratuitous information.
Note that this operation allows considerable compression in
</bodyText>
<page confidence="0.743176">
29
</page>
<bodyText confidence="0.961074434782609">
the number of senses that must be stored for each word. It
allows us, for example, to define &amp;quot;slow&amp;quot; as something like &amp;quot;Find
the most salient associated motion. Find the most specific Speed
Scale for the object X of this motion. X&apos;s speed is on the lower
end of this scale&amp;quot;. This definition is adequate for such phrases
as &amp;quot;walk slowly&amp;quot; (the most salient motion is the forward motion
of the walking), &amp;quot;slow race&amp;quot; (the forward motion of the competi-
tors), &amp;quot;slow horse&amp;quot; (its running at full speed, usually in a
race), and &amp;quot;slow person&amp;quot;. This last case is highly dependent on
context, and could mean the person&apos;s physical acts in general,
his mental processes, or the act he is engaged in at the moment.
This operation has a default feature. If a proof of the
required inference can&apos;t be found, it is assumed anyway. This
allows a text to be understood even if all the words aren&apos;t
known. Suppose, for example, &amp;quot;veer right&amp;quot; is encountered, and
the word &amp;quot;veer&amp;quot; isn&apos;t known, i.e. no inferences can be drawn from
it. Since &amp;quot;right&amp;quot; requires a change in angular orientation as
its argument, it is assumed this is what &amp;quot;veer&amp;quot; &apos;means Only the
information that the change is small is lost.
FIND ANTECEDENTS OF DEFINITE NOUN PHRASES
Entities referred to in a text may be arranged in a hierarchy
according to their degree of specification:
I. proper names, including &amp;quot;you&amp;quot; and &amp;quot;I&apos;
</bodyText>
<listItem confidence="0.9924595">
2. other noun phrases, including those with definite,
indefinite, and demonstrative articles
3. third person pronouns
4. zeroed arguments and implied entities.
</listItem>
<page confidence="0.402942">
30
</page>
<bodyText confidence="0.992265185185185">
So far our work has concerned primarily definite noun phrases,
but it is expected that many features of the definite noun phrase
algorithm will carry over to other cases.
The definite noun phrase algorithm consists of four steps.
First, &amp;quot;uniqueness conditions&amp;quot; are checked to determine whether
an antecedent is required. If so, the Text and Lexicon are
searched for plausible antecedents. Third, consistency checks
are made on these. Finally if more than one plausible antecedent
remains the Principle of Knitting is applied to decide between
them.
Uniqueness Conditions, In the phrase &amp;quot;the end of the block&amp;quot;,
we know we must look back in the text for an explicitly or impli-
citly mentioned &amp;quot;block&amp;quot; (the search case), but we do not neqes-
sarily look for a previously mentioned &amp;quot;end&amp;quot; (the no-search case).
Given a definite noun phrase the algorithm first tries to deter-
mine whether it belongs to the search or no-search case. This is
done by checking two broad criteria. (These criteria were moti-
vated by a large number of examples not only from sets of direc-
tions but also from technical and news articles.)
These criteria are checked by searching the Lexicon for
certain features. However these searches are generally very
shallow, in contrast to the potentially much deeper searches in
the text step of the algorithm. Since, by far the majority of
definite noun phrases are in the no-search case, checking unique-
ness conditions can result in great savings.
A caveat is in ordr. We state the criteria at a very high
level of abstraction. We feel in fact that the algorithm can
</bodyText>
<page confidence="0.965164">
31
</page>
<bodyText confidence="0.9982504">
work at that level of abstraction if the Lexicon is properly
constructed. But how to construct a large Lexicon properly is
a problem we have not yet tackled in detail. In any event, we
give examples for each case, and the examples themselves form a
reasonably exhaustive classification.
</bodyText>
<listItem confidence="0.9451168">
1. A definite entity is in the no-search case if it can be
located precisely with respect to some framework. This includes
the following conditions.
a. Objects which are located with respect to some identi-
fied point in space: &amp;quot;the building on the corner&amp;quot;.
b. Plurals and mass nouns which are restricted to some
identified region of space: &amp;quot;the trees in the park&amp;quot;, &amp;quot;the water
in the swimming pool&amp;quot;. Here &amp;quot;the&amp;quot; indicates all such objects or
substance.
c. Points and intervals in time tahich are fixed with
respect to some identified event: &amp;quot;the minute you arrive&amp;quot;, &amp;quot;the
hour since you left&amp;quot;.
d. Events in which at least some of the participants are
identified and which can be recognized as occurring at a specific
time: &amp;quot;the ride you took through the park yesterday&amp;quot;;
</listItem>
<bodyText confidence="0.904272857142857">
e. Points or intervals on more abstract scales: &amp;quot;the end
of the block&amp;quot;, &amp;quot;the size of the building&amp;quot;. The end is a specific
point on the distance scale defined by the block. The size of
the building is a specific point on the general size scale for
objects, i.e. the volume scale.
f. Superlatives, ordinals, and related terms: &amp;quot;the largest
house on the block&amp;quot;, &amp;quot;the second house on the block&amp;quot;, &amp;quot;the only
</bodyText>
<page confidence="0.464191">
32
</page>
<bodyText confidence="0.997788074074074">
house on the block&amp;quot;. If the set of comparison is identified,
the superlative or ordinal indicates the scale of comparison and
the place on that scale of the entity it describes. This is a
subcase of (e).
All of these conditions can be checked in one operation if
the facts in the Lexicon are expressed in terms of suitably
abstract operators relating entities to scales. We simply ask if
the definite entity is on or part of a scale or at a point on or
along an .interval of a scale, where the scale can be identified.
However this requires that we take very seriously my suggestion
in Hobbs (1974) that the lexicon for the entire language be built,
insofar as possible, along the lines of a spatial metaphor. We
have not yet had to face these problems since our only scales are
physical -- our &amp;quot;at&amp;quot; and &amp;quot;on&amp;quot; are the locative &amp;quot;at&amp;quot; and &amp;quot;on&amp;quot;.
Also checking this criterion presupposes a very sophisticated
syntactic and semantic analysis. For example, (d) assumes that
the times of events mentioned in tenseless constructions can be
recovered.
2. A definite entity is in the no-search case if it is the
dominant entity of that description. This divides into two sub-
criteria:
a. Those entities which are unique or dominant by virtue
of the properties which describe them: &amp;quot;the sun&amp;quot;, &amp;quot;the wind&amp;quot;. If
the properties p1(X),p2(X),..., are known about the definite
entity X, the definitions of p11p2,..., are probed for the fact
that the entity does not normally occur in the plural. Included
under this heading are proper names beginning with &amp;quot;the&amp;quot;, like
</bodyText>
<page confidence="0.794702">
33
</page>
<bodyText confidence="0.910217074074074">
&amp;quot;the Empire State Building&amp;quot;, and appositives, like &amp;quot;the city of
Boston&amp;quot;.
b. Those entities which are unique by virtue of the prop-
erties of an entity with which they are grammatically related:
&amp;quot;the door of the building&amp;quot;, &amp;quot;the Hudson River valley&amp;quot;. &amp;quot;The door
of the building&amp;quot; is represented in the Text as &amp;quot;X1Idoor(X1&apos;X2I
building(X2))&amp;quot; i.e. &amp;quot;the Xi such that Xi is the door of X2 which
is a building&amp;quot;. The uniqueness or dominance of Xi is not a prop-
erty of &amp;quot;door&amp;quot; but of &amp;quot;building&amp;quot;. Stored with &amp;quot;building&amp;quot; is the
fact that a building has in its front surface a main door which
does not normally occur in the plural. &amp;quot;The door of the building&amp;quot;
is interpreted as this dominant door.
If the uniqueness conditions succeed, a pointer is set from
the dominant lexical variable to the corresponding entity. If
subsequently the same definite noun phrase occurs, the uniqueness
check will discover this pointer and correctly identify the ante-
cedent. Thus, we can handle the example
&amp;quot;Walk up to the door of the building. Go through
the door of the building.&amp;quot;
Here the uniqueness check gives us a shortcut around the next
step in the algorithm.
The Search for Plausible Antecedents. To illustrate the
search for an antecedent, consider
&amp;quot;Walk out the door of this building. Turn right.
Walk to the end of the block.&amp;quot;
What block? From &amp;quot;block&amp;quot; we follow a back pointer to the fact
stored with &amp;quot;street&amp;quot; that &amp;quot;streets consist of blocks&amp;quot;, and from
</bodyText>
<page confidence="0.813068">
34
</page>
<bodyText confidence="0.99916637037037">
&amp;quot;street&amp;quot; the fact with &amp;quot;building&amp;quot; that &amp;quot;Buildings are by streets&amp;quot;
Since a building is mentioned, we assume it is &amp;quot;the block of the
street the building is on&amp;quot;. The facts in the chain of inference
leading to this are instantiated. An entity is introduced into
the text for the &amp;quot;street&amp;quot; and the Text is augmented by the state-
ments that &amp;quot;the building is on the street&amp;quot; and &amp;quot;the block is part
of the street&amp;quot;. This information turns out to be required for
the map. Note that the fact that a building is on a street is a
sometimes fact and that we are free to draw it only because &amp;quot;the
block&amp;quot; occurs.
To conduct the search of the Lexicon, ideally we would like
to send out a pulse from the word &amp;quot;block&amp;quot; which travels faster
over more salient paths, and look for the first entity which the
pUlse reaches. The saliency is simulated by the cluster
structure described above. The parallel process of the spreading
signal is simulated by interleafing deeper probes from salient
clusters with shallower probes from less salient clusters. For
example, if &amp;quot;streets consist of blocks&amp;quot; is a cluster I fact, then
we might probe for a cluster 1 fact involving streets and a
cluster 2 fact involving blocks at roughly the same time. After
one plausible antecedent is found in this way, the search is
continued for possible antecedents which are nearly as plausible.
If after a time no plausible antecedents are found, the search
is discontinued.
Searches for antecedents are conducted not only for entities
but also for definite noun phrases that the nominalization trans-
formations of the syntactic component have turned into statements
</bodyText>
<page confidence="0.541315">
35
</page>
<bodyText confidence="0.997588888888889">
--e.g. &amp;quot;The walk was tiring&amp;quot;. Here we look back for a statement
whose predicate is &amp;quot;walk&amp;quot; or from which a statement involving
&amp;quot;walk&amp;quot; can he inferred. There are cases in which the required
inference is in fact a summary of an ntire paragraph--e.g.
&amp;quot;These actions surprised...&amp;quot;--although of course we cannot
handle these cases.
Consistency. Each of the plausible antecedents is checked
for consistency. Suppose X1 is the definite entity which prompt-
ed the search and its properties are
</bodyText>
<equation confidence="0.713405666666667">
p(X1),q1(X1),...,qm(X1)
and X2 is the proposed antecedent with properties
p(X2) fri(X2),...,rn(X2)
</equation>
<bodyText confidence="0.9806768">
We must cycle through the q&apos;s and the r&apos;s to ensure they are con-
sistent properties. Of course, to prove two properties q(X) and
r(X) inconsistent can be an indefinitely long process with no
assurance of termination. One admittedly ad hoc way we get
around this is by placing into a special cluster those facts we
feel are likely to lead quickly to a contradiction. The second
tool we use for deriving inconsistencies may turn out to be
quite significant.
In the course of processing, the lattice described abwve is
constructed for several predicates. They contain information
which can be useful in deriving an inconsistency. Suppose we
have a text in which &amp;quot;the block&amp;quot; occurs explicitly several times.
Toward the end of it, we encounter
&amp;quot;Turn right onto Adams Street. The library
is at the end of the block&amp;quot;.
</bodyText>
<subsectionHeader confidence="0.521598">
36
</subsectionHeader>
<bodyText confidence="0.998195777777778">
The search algorithm looks first for explicit mentions of &amp;quot;block,&amp;quot;
and finds them. Yet none of these entities is the one we want.
Intuitively, the reason we know this is our almost visual feeling
that we are already beyond those points.
The lattice consistency check corresponds precisely to this
feeling. If a definite entity X1 is a point or interval in a
lattice or at a point or along an interval, we ask if the propos-
ed antecedent X2 is or can be related to a portion of the lattice.
If so, then since the lattice represents a transitive relation,
we need only ask if there is a path in the lattice from X2 to Xl.
If there is, they cannot be the same entity.
Many cases which pass for applications of the supposed
recency principle--&amp;quot;Pick the most recent plausible antecedent&amp;quot;--
are in reality examples of this consistency check. The earlier
plausible antecedent is rejected because of lattice considera-
tions.
As the text is processed, the whole structure of the
discourse is built up. When a definite noun phrase is encounter-
ed, this discourse structure is known and it is this knowledge
that is used to determine the antecedent rather than the linear
ordering of the words an the page.
Competition amou Remaining Plausible Antecedents. Even
after the consistency checks, several plausible antecedents may
remain, forcing us to decide among them on less certain criteria.
To do this, we appeal to the Principle of Knitting again and make
the choice that will maximize the redundancy in the simplest
possible way.
</bodyText>
<subsectionHeader confidence="0.453538">
37
</subsectionHeader>
<bodyText confidence="0.995370966666667">
A probe is sent out from the definite entity and from each
plausible antecedent. Each plausible antecedent is searched for
properties it has in common with the definite entity. Common
properties Count most if they are already in the Text, and with-
in the Lexicon, common properties count more if they are within
more salient clusters or they result from shorter chains of
inference.
Default. Like the higher predicate algorithm, the definite
noun phrase algorithm has a default feature. If the uniqueness
conditions fail and the search turas up no antecedent, we simply
introduce a new entity. In fact, in the directions texts there
are a disproportionately large number of default cases, for &amp;quot;the
object&amp;quot; may simply be the object you will see when you reach
that point in following the directions.
Other Anaphora. We have not yet implemented routines for
handling other anaphora. However, we believe they are very
similar to the definite noun phrase routine, with certain differ-
ences. For entities tagged with demonstrative articles, we do
not check
since the
occurring
tions are
plausible
be placed
uniqueness conditions, and the search will be narrower
antecedent must be an entity or statement actually
in the text. For pronouns also, no uniqueness condi-
checked. The search will turn up more consistent
antecedents, and a correspondingly greater burden will
on the competition routine.
</bodyText>
<sectionHeader confidence="0.948117" genericHeader="method">
INTERSENTENTIAL CONNECTIVES
</sectionHeader>
<bodyText confidence="0.9801222">
We detect unstated inter-sentence connectives by matching two
successive sentences S1 S2 with a small number of common
38
patterns. In the directions texts the patterns are usually few
and simple. The most common are
</bodyText>
<listItem confidence="0.964807">
1. S1 asserts a change whose final state is asserted or
presupposed by S2.
2. S1 asserts or presupposes a state which is the initial
state of a change asserted by S2.
</listItem>
<bodyText confidence="0.998652368421053">
(These are likely very common patterns in all narratives.) For
example, in the text
&amp;quot;Walk out the door of this building. Turn right.
Walk to the end of the block&amp;quot;.
pattern(1) joins the first two sentences, where the state is
&amp;quot;You at X&amp;quot;. Pattern(2) joins the last two sentences, where
again the state is &amp;quot;You at X_&amp;quot;. Note moreover that the sentences
are interlocked by a second application of the two patterns: The
first sentence assumes an angular orientation which is the
initial state of the change asserted in the second sentence.
The final state of this change is assumed by the third sentence.
In addition to providing the discourse with structure, this
operation is one of the principal means by which implied entities
in one sentence, like X above, are identified with those in
another.
When pattern (2) is applied, we delete the independent occur-
rence of the state in the Text, so that subsequently it exists
only as one intermediate state ih a larger event. Changes across
time are handled in this way.
</bodyText>
<sectionHeader confidence="0.6123005" genericHeader="method">
TASK PERFORMANCE COMPONENT
Arbitrary Decisions. The semantic operations are quite
</sectionHeader>
<subsectionHeader confidence="0.514509">
39
</subsectionHeader>
<bodyText confidence="0.998552958333333">
general and can be used for any application. The augmented and
interrelated Text is then handed over to the task performance
component, which of course is specific to the application.
Our task component first makes arbitrary decisions required
by the map but not given in the text. Both natural language
directions and sketched maps allow information to be incomplete
and imprecise, but in different ways. For example, in
&amp;quot;Turn right at the third street or the second stoplight&amp;quot;.
we must decide whether to put the first stoplight at the first
or second street.
The lattice representing the path &amp;quot;you&amp;quot; take must be complete
in the sense that it is continuous, begins at the initial loca-
tion, and ends at the desired goal, and that the relative loca-
tions of all points on the path are known. The lattide is
complete if and only if there is a directed path passing through
every point in the lattice at least once. If it is not complete,
it is completed by supplying the fewest possible new links.
Geometrizing the Lattices. The second task operation is to
convert the topological lattice representation into the geometric
representation required by the maps. First we assign directions
to all the points in the angular orientation lattice. In the
simplest case we may have something like
where &amp;quot;a b&amp;quot; means direction b results from a clockwise
rotation of direction a. If no explicit directional information
</bodyText>
<subsectionHeader confidence="0.688074">
4,0
</subsectionHeader>
<bodyText confidence="0.999878888888889">
is present, we simply assume a, c, and e are the same direction,
and b and d are the same, and then assume the two directions are
at right angles. Then in tha distance lattice, contiguous or
overlapping paths which share the same orientation are assumed
to be parts of the same path and are mapped into a straight line.
Information about names is accessed and assigned to the streets
and buildings and the map is drawn.
Specific Systems with a General Semantic Component. We are
aiming not so much at the construction of a general natural
language processing system, which still seems reasonably far off
but at an easier way of constructing specific systems. The case
of syntax is instructive. It would be foolish for one who is
building a natural language processing system to build his
syntactic component from scratch. Large general grammars and
parsers for them exist (e.g. Grishman et al. 1973, Sager &amp;
Grishman 1975). It is easier by several orders of magnitude to
begin with a general grammar and specialize it, by weeding out
the rules for constructions that don&apos;t occur in the texts one is
dealing with, and by adding a few rules for constructions and
constraints peculiar to one&apos;s application.
We are trying to make a similar facility available for the
most common kinds of semantic processing. Specializing the
general semantic component would consist of several relatively
easy steps. First the Lexicon would be organized into a
cluster structure appropriate to the task. At worst, this would
mean specifying the necessary knowledge in a fairly simple format.
If a very large Lexicon were available, this could mean no more
</bodyText>
<page confidence="0.459177">
41
</page>
<bodyText confidence="0.968911125">
than designating for each fact the cluster it should appear in.
Certain inferences could be made obligatory while others which
are irrelevant to the task could be left out of the special Lexi-
con altogether. Second a Task Component would be built which
would take, as ours does, the semantically processed Text, and
use it to perform the task. We are demonstrating the usefulness
of this approach in performing a task involving a visual repre-
sentation. It is likely to be useful in other sorts of tasks also.
</bodyText>
<sectionHeader confidence="0.95934" genericHeader="method">
BIBLIOGRAPHY
</sectionHeader>
<reference confidence="0.9563698">
Grishman, R., Sager, N., Raze, C., &amp; Bookchin,B.,&amp;quot;The Linguistic
String Parser,&amp;quot; Proc. NCC, AFIPS Press, Montvale, N.J. 1973.
Hobbs, J.I &amp;quot;A Model for Natural Language Semantics, Part I: The
Model,&amp;quot; Yale Univ. Dept. Comp. Sci. Res. Rep. 36, Nov. 1974.
Hobbs, J., and Grishman, R., &amp;quot;The Automatic Transformational
Analysis of EngUsh Sentences: An Implementation,&amp;quot;
Submitted to International Journal of Computer Mathematics.
Holzman, M., &amp;quot;Ellipsis in Discourse: Implications for Linguistic
Analysis by Computer, The Child&apos;s Acquisition of Language, and
Semantic Theory, Ir Language and Speech (1971, 86-98.
Joos, M., &amp;quot;Semantic Axiom Number One,&amp;quot; Language (1972) 257-265.
Knuth, D. The Art of Computer Programming, 3, Addison-Wesley,
Reading, Mass., 1973.
Minsky, M., &amp;quot;A Framework for Representing Knowledge,&amp;quot; MIT Al Memo
306, June 1974.
</reference>
<note confidence="0.43597625">
Sager, N., and Grishman-, R., &amp;quot;The Restriction Language for Compu-
ter Grammars of Natural Language,&amp;quot; CACM 18, 7 (7/75) 390-400.
American Journal of Computational Linguistics Microfiche 32: 42
AN ADAPTIVE NATURAL LANGUAGE PARSER
</note>
<author confidence="0.690502">
PERRY L. MILLER
</author>
<affiliation confidence="0.7210105">
Massachusetts Institute of Technology
Cambridge, Massachusetts 02139
</affiliation>
<sectionHeader confidence="0.814834" genericHeader="method">
ABSTRACT
</sectionHeader>
<subsectionHeader confidence="0.475946">
Wheh a user interacts with a natural language system, he may well
</subsectionHeader>
<bodyText confidence="0.99344175">
use words and expressions which were not anticipated by the system
designers. This paper describes a system which can play TIC-TAC-TOE, and
discuss the game while it is in progress. If the system encounters new
words, new expressions, or inadvertent ungrammaticalities, it attempts to
understand what was meant, through contextual inference, and by asking
ihteliigent clarifying questions of the user. The system then records
the meaning of any nw4 words or expressions, thus augmenting its
linguistic knowledge in the course of user interaction.
</bodyText>
<sectionHeader confidence="0.998324" genericHeader="method">
1. INTRODUCTION
</sectionHeader>
<bodyText confidence="0.849263355555555">
A number of systems are being developed which communicate with
users in a natural language such as English. The ultimate purpose of
such systems is to provide easy computer access to a technically
Unsophisticated person. When such a person interacts with a natural
language system, however, he is quite likely to use words and expressions
which were not anticipated. To provide truly natural interaction, the
system should be able to respond intelligently when this happens.
Most current systems, such as those of Winograd [10] and Woods
[11], are not designed to cope with such &amp;quot;linguistic input uncertainty.&amp;quot;
Their parsers fail completely if an input sentence does not use a
specific, built-in syntax and vocabulary. At the other extreme, systems
like ELIZA [9] and PARRY [2] allow the user to type anything, but make no
attempt to fully understand the sentence. The present work explores the
middle ground between these extremes: developing a system which has a
great deal of knowledge about a particular subject area, and which can
use this knowledge to make language interaction a flexible, adaptive,
learning medium.
In pursuing this goal, the present work is most closely related
to work being done in the various speech recognition efforts [5, 7, 8,
12] which are studying how linguistic and semantic constraints can help
deal with the ACOUSTIC error gnd uncertainty of speech. The adaptive
system, however, is designed to deal with a much more LINGUISTIC type of
uncertainty.
When people use unfamiliar words or expressions in conversation,
we can usually deduce from context what is meant, and if not, we can at
least ask intelligent clarifying questions. To allow the machine to do
the same, there must be a very flexible interaction of syntax and
Semantics in the parsing/understanding process. There must be a
different parser organization, and a more flexible use of linguistic and
semantic constraints, than is present in current natural language
systems.
The adaptive system is a step towards this goal The current
implementation is a prototype, designed to illustrate many of these
ideas, and to tie them together in a restricted system that is complete
but not too complex. The system&apos;s domain of discourse is TIC-TAC-TOE: it
plays a game and discusses the game in progress. It has a (currently
limited) set of semantic concepts, and attempts to interpret the user&apos;s
sentences in terms of these. The set of semantic concepts is FIXED. The
system does not attempt to learn new concepts, merely new ways of
describing concepts that are already familiar.
When the system encounters a new word or a new phrasing, it uses
contextual information to determine the possible meaning, and to ask
clarifying questions which are as intelligent as possible. It then
remembers the meaning of the new egpression, and will use it itself when
it talks.
</bodyText>
<sectionHeader confidence="0.981131" genericHeader="method">
2. SAMPLE SESSION
</sectionHeader>
<bodyText confidence="0.9573725">
The best way to introduce the system is to show it in operation.
In the sample session that follows, user input is preceded by wll:&amp;quot;,
machine output by &amp;quot;M:&amp;quot;, and comments added by the author are in small
type, enclosed in brackets.
</bodyText>
<table confidence="0.637444935483871">
(MACHINE: I PLACE AN X IN THE TOP LEFT SQUARE)
[The machine makes its opening move.
(USER: PLAY A ZERO IN THE CENTER SQUARE)
(M: IS ZERO A NOUN MEANING 0)
(U: YES)
(M: OK)
[The new word &amp;quot;zero&amp;quot; is added to the chine&apos;s vocabulary.]
43
(M: I PLACE AN X IN THE BOTTOM RIGHT SQUARE)
(U: SLAP AN 0 IN THE BOTTOM LEFT CORNER)
(M: IS (TO SLAP SOMETHING SOMEWHERE) A WAY OF SAYING (IC) PLACE SOMETHING
SOMEWHERE))
(U: YES)
(M: OK)
(X--)
(- 0 -)
(0 - X)
[A new surface frame (as described in section 4) is added to the set of
surface frames which express the concept of making a move.]
(M: I SLAP AN X IN THE TOP RIGHT SQUARE)
(X - X)
(- 0 -)
(0 X)
[In this sample session, the machine uses its newly acquired vocabulary
at every opportunity.]
(U: HOW COME YOU PLACED AN X IN THE TOP RIGHT SQUARE)
(M: IS (HOW COME SOMEONE DOES SOMETHING) AN EXPRESSION MEANING (WHY PiES
SOMEONE DO SOMETHING))
(U.: YES)
(M: OK)
(N: TO BEAT YOU)
</table>
<tableCaption confidence="0.814412">
[A new surface frame is added to those expressing the concept &apos;WHY&apos;.
Syntactic features are associated with each such frame indicatirg such
things as Whether subject-verb inversion is to be performed.]
</tableCaption>
<table confidence="0.920628">
44
(U: CAN YOU CURRENTLY BEAT ME)
(M: IS CURRENTLY AN ADVERB REFERRING TO THE TIME OF A MOVE)
[These are the only adverbs the system knows about. In fact, at present,
the system ignores adverbs in its semantic processing. It asks the
question because it wants to account far all the words in the sentence.]
(U: YES)
N. OK)
(M: YES)
(U: AFTER YOU PLAYED AN X IN THE TOP WEST SQUARE COULD I BEAT YOU IF I
ELAM ANO IN THE BOTTOM RIGHT SQUARE)
(M: IS WEST AN ADJECTIVE MEANING)
EITHER
(1: CORNER)
(2: LEFT)
(U: 2)
(M: OK)
(M: NO)
</table>
<bodyText confidence="0.947971">
[Notice that two top squares contain an x. However, only the left one
was played while the bottom right square was free. Therefore the system
concluded that the top left square was being described. This example
illustrates how contextual information can be used to ask as intelligent
a clarifying question as possible.]
(U: now COME YOU PLACED AN X IN THE TOP EAST SQUARE)
</bodyText>
<sectionHeader confidence="0.7005274" genericHeader="method">
(M: IS EAST AN ADJECTIVE MEANING)
EITHER
(1: RIGHT)
(2: WEST)
(U:
</sectionHeader>
<figure confidence="0.977913317460318">
(U: OK)
45
0.44 o••• ••••••■ .•-•• .•-••• •••••• rT1 .0••■ .•••■ •••••
• • 40 40 (i01 IN) M •• S.
0 0 ■-•0 V. 04 ••• 0
74; --1 en 0.4 PI
00 0
&gt;
0 r- 7:s
re- re,
cel 0 &lt;
rn rn
—1
00
rn
30
Z Z
rn 0
0-4 0-4 rri
(TO KEEP SOMEONE FROM DOING
•••■• ••■•••
•••.••
0 ON THE RIGHT SIDE SQUARE HOW CAN YOU POLISH ME OFF)
IS CELL A NOUN MEANING SQUARE)
two sentences each contain two problems for the system to
X IN THE TOP RIGHT CELL COULD I KEEP YOU FROM
• •
rn
5■4
S 1A31 W01108 3H1 NI 0 NV
(aw 1V32 noA moo
top square might have been referred to
.0. i-9 ..-.. ...........
0 = .• • 0 • 4 tin • •
C13
0 rt• -4 0&lt; 1=4
lal V ri 74 SI Ca CA
9 M Cli N-0 CA 0
CD..... ....
9 0 cll
i
O.
M a = rTI
Ai CU I■1 Z
3 P&amp;quot;.
0
0
rn
8
rrl
C/3
C/3
0
rri
OMNI oiJouv. pue olaym.
9NINV3W NOISS3&apos;dX3
3NO3WOS H314V
(M: IS (TO LAY SOMETHING SOMEWHERE) A WAY OF SAYING (TO SLAP SOMETHING
SOMEWHERE))
(U: YES)
(M: OK)
(M: IS (TO POLISH SOMEONE OFF) A WAY OF SAYING)
EITHER
</figure>
<reference confidence="0.5945685">
(1: (TO BEAT SOMEONE))
(2: (TO LOSE TO SOMEONE))
(3: (TO TIE SOMEONE))
(U: 1)
(PI: OK)
(M: BY LAYING AN X ON THE TOP CENTER CELL)
</reference>
<bodyText confidence="0.6838695">
[If this same session were subsequently repeated, of course, the system
would not need to ask any questions of the user.]
</bodyText>
<subsectionHeader confidence="0.966544">
2.1 Comments on Current Limitations
</subsectionHeader>
<bodyText confidence="0.8822075">
There are a number of limitations to the adaptive system as it
now stands. Some of these may be apparent in the sample session, but an
introduction to the system is not complete without discussing them
explicitly.
</bodyText>
<reference confidence="0.775811294117647">
(I) The number of concepts available to the system at present is very
small. This, in fact, is why the system&apos;s first guess is usually the
correct one. If the sentence is at all within the system&apos;s
comprehension, the options as to its meaning are currently quite limited.
(2) The range of expressive devices presently recognized is quite
limited as well. For instance, the system does not recognize relative
clauses, conjunctions, or pronouns (except for I and you).
(3) The system currently deals only with TOTALLY UNFAMILIAR words and
expressions in this adaptive fashion. It will not correctly handle
familiar words which are used in new ways (such as a noun used as a verb,
as in &amp;quot;zero the center square&amp;quot;).
(4) The system tries to map the meaning of new words and expressions
into its specified set of underlying concepts. It then displays its
hypotheses to the user, giving him only the option of saying yes or no.
The user cannot say &amp;quot;no, not quite, it means ...&amp;quot;. (Thus concepts like
&amp;quot;the &apos;northeast&apos; square&amp;quot; or &amp;quot;the &apos;topmost&apos; square&amp;quot; would be confusing and
not correctly understood.)
</reference>
<page confidence="0.972372">
47
</page>
<bodyText confidence="0.791865">
The present simple system has been developed with two goals in
mind: (1) to explore the techniques required to achieve adaptive
behavior, and (2) to help formulate the issues which will have to be
faced when incorporating these techniques into a much broader natural
language system.
</bodyText>
<sectionHeader confidence="0.985541" genericHeader="acknowledgments">
3. OVERVIEW
</sectionHeader>
<reference confidence="0.972660837837838">
Fig. 1 shows the various stages that the Adaptive System goes
through in understanding a sentence. In this section, we shall watch
while the system processes the sentence &amp;quot;How come you placed an x in the
top right square.&amp;quot;
(1) Local Syntactic Processing:
In this first stage, the system scans the entire sentence looking for
local constituents. These include &amp;quot;simple&amp;quot; noun phrases (NPs) and
prepositional phrases (PPs), (&amp;quot;simple&amp;quot; meaning &amp;quot;up to the head noun but
not including any modifying clauses or phrases&amp;quot;), and verb groups (VGs)
consisting of verbs together with any adjoining modals, auxilliaries, and
adverbs. In this instance, the system finds the two NPs, &amp;quot;you&amp;quot; and &amp;quot;an
x&amp;quot;, the PP &amp;quot;in the top right square&amp;quot;, and the VG &amp;quot;placed&amp;quot;.
(2) Semantic Clustering:
At this stage, the clause-level processing starts. Unlike most systems,
this clause-level processing is driven by SEMANTIC relationships, rather
than by syntactic form. It uses a semantics-first &amp;quot;clustering&amp;quot;, with a
secondary use of syntax for comments and confirmation. In this example,
all the local constituents found can be clustered into a description of a
single concept: that of making a move. Section 4 describes the mechanics
of this stage in more detail.
(3) Cluster Expansion and Connection:
During this stage an attempt is made to account for each word in the
sentence by expanding the concept clusters, and if there is more than
one, by joining them together to form an entire multiclausal sentence.
In this case, the concept cluster might be expanded in two ways.
a) One possibility might be that it is a &amp;quot;HOW&amp;quot; type question, and that
&amp;quot;come&amp;quot; is some sort of adverb. However this possibility violates a
semantic constraint, since the system is not set up to answer how a move
Is made; only how to win, how to prevent someone from winning, etc.
Therefore this possibility is ignored.
b) The other possibility is that &amp;quot;how come&amp;quot; is a new way of describing
some other clause funrction.
(4) Contextual Inference; Clarification; and Response:
During this final stage, any contextual information available is brought
to bear on areas of uncertainty, any necessary clarifying questions are
asked, and the system responds to the sentence. In this example, the
only uncertainty is the meaning of &amp;quot;how come&amp;quot;. Since this is the main
</reference>
<page confidence="0.629836">
48
</page>
<figure confidence="0.96538356">
sentence
Ut—AL SYNTACTIC
,y ROCESSING
1
local constituents
SYNTAX:
comments &amp;
!confirmation
1SEMANTIC
CLUSTERING
49
concept
clusters
FUSTER EXPANSION
&amp; CONNECTION
complete
sentence
hypothesis
USER is asked
for clarification
EXTUAL INFERENCE;
CLARIFICATION;
&amp; RESPONSE
system responds
to sentence
</figure>
<figureCaption confidence="0.985553">
Fig. I: Adaptive System Overview
</figureCaption>
<bodyText confidence="0.979333">
clause of the sentence, the possibility of its being an &amp;quot;if&amp;quot; or &amp;quot;after&amp;quot;
clause are discarded. The remaining possibilities are &amp;quot;imperative&amp;quot;,
&amp;quot;how&amp;quot;, &amp;quot;why&amp;quot;, and &amp;quot;can&amp;quot;. The system does not answer &amp;quot;how&amp;quot; and &amp;quot;can&amp;quot;
questions in relation to making moves. Similarly, &amp;quot;imperative&amp;quot; does not
make sense since the action described is a previously made move.
Therefore the system asks if &amp;quot;How come someone does something&amp;quot; means &amp;quot;Why
does someone do something&amp;quot;. The user answers &amp;quot;yes&amp;quot;, so the system stores
this new way of asking &amp;quot;why&amp;quot;, and proceeds to answer the question.
</bodyText>
<sectionHeader confidence="0.997273" genericHeader="references">
4. SEMANTICS-FIRST CLAUSE-LEVEL PROCESSING
</sectionHeader>
<bodyText confidence="0.98536975">
One of the major differences between this approach to parsing and
that of a top-down, syntax-driven system such as Woods&apos; or Winograd&apos;s)
is the order in which syntactic and semantic processing is done at the
clause level.
</bodyText>
<subsectionHeader confidence="0.594501">
In a top-down system, a sentence must exactly match the built-in
</subsectionHeader>
<bodyText confidence="0.90323147826087">
syntax before semantics can even be called and given the various
constituents of a clause. This is clearly undesirable when one is
dealing with input uncertainty, since one cannot be sure exactly how the
user will phrase his sentence. One would prefer to let semantics operate
first on any local consituents present, so that it can make a reasonable
gtess as to what is being discussed.
As semantically-related clusters of local constituents are found,
syntax can be consulted and asked to comment on the relative
grammaticality of the various clusters. If there are two competing
semahtic interpretations of one part of a sentence, and syntax likes one
much better than the other, then the &amp;quot;syntactically pleasing&amp;quot;
Interpretation can be pursued first. Later, if this does not pan out,
the syntactically irregular possibility can be looked at as well. In
this way, syntax can help guide the system, but is not placed in a
totally controlling position.
A by-product advantage of this semantics-first approach is that
the system can handle mildly ungrammatical input without any extra work.
In addition, the semantics-first clustering approach lends itself quite
naturally to handling sentence fragments.
In the remainder of this section, we describe how the adaptive
system organizes its linguistic knowledge to implement this semantics-
first approach. As we shall see, there are three components of this
knowledge.
</bodyText>
<reference confidence="0.985720625">
(a) The local recognizers which initially find local constituents. These
recognizers are represented in Augmented Transition Network [11] form,
are quite simple, and are not described further in this paper.
(b) Clause-level knowledge of how actions and clause-functions are
described. This knowledge is expressed in a descriptive fashion which
makes it easily manipulable, and easy to add to.
(c) Clause-level syntactic knowledge which is expressed in a domain-
independent form.
</reference>
<page confidence="0.874185">
50
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.616393666666667">Journal of Computational Linguistics 32 PROCEED NGS 13TH ANNUAL</note>
<title confidence="0.834201">ASSOCIATION FOR COMPUTATIONAL LINGUISTICS 1 : LANGUAGE UNDERSTANDING SYSTEMS</title>
<author confidence="0.943971">Timothy C Diller</author>
<author confidence="0.943971">Editor</author>
<note confidence="0.7070315">Sperry-Univac Paul, Minnesota for computational Linguistics 2 PREFACE The 13th annual ACL meeting was held at Boston, Massa-</note>
<abstract confidence="0.971611377777778">October - November 1, 1975, in conjunction with the 38th meeting of the American Society for Information Science. The ACL thanks the ASIS for its assistance in publicizing the conference and in handling registration. and following four contain 27 of the 30 papers presented at the meeting. The breadth of the conference is evident in (a) the modes of communication investigated (speech, sign language, and written text), (b) the of communication dialogues, note making), and (c) the uses envisioned for the processing of (e.g., theoretical modeling, data collection and game playing, story generation, idiolect characterization, and automatic indexing). Topics considered include the development of language systems, the and utilization of specific components of language, specifically syntax and semantics, the representation and use of discourse structure and general world knowledge, and the construction of text processing systems. program committee was solely responsible for selectto be given, the papers to be pubherein. (Regretfully, half of those submitted 3 could not be accepted for lack of program time.) Members of the program committee were Jonathan Allen, Joyce Friedman, Bonnie Nash-Webber, and Chuck Rieger. A special word of appreciation is due Jonathan Allen, who also served as Local Arrangements Chairman. Working with him were Betty Brociner and Skip McAfee of the ASIS. Aravind Joshi, president of ACL, provided guidance in all areas of preparation. The AJCL kindly provided advance publication of the accepted abstracts and now makes possible the publication of the entire proceedings. David Hays, editor of AJCL, provided guidance in publication format and each author provided final copy in accordance with requested specifications. The Center Applied Linguistics (in David Hoffman and Nancy Jokovich with guidance from Hood Roberts) contributed In a variety of ways, most notably in the preparation of meeting handbooks. This microfiche contains the papers as submitted by their authors for five of the six talkt touching on Language Understanding Systems. The paper detailing &amp;quot;Conceptual Grammar&amp;quot; by William Martin was too long for inclusion in this microfiche and will appear elsewhere. My thanks to Yorick Wilke for chairing the session.</abstract>
<author confidence="0.922299">-Timothy C Diller</author>
<affiliation confidence="0.837819">Program Committee Chairman</affiliation>
<address confidence="0.586462">4</address>
<note confidence="0.608856">TABLE (), CONTENTS Program Schedule . • • • • • • . • • • • • 5</note>
<title confidence="0.58022525">SESSION 1: LANGUAGE UNDERSTANDING SYSTEMS PEDAGLOT and Understanding Natural Language Processing Fabens . . • • • • • • 0 • • • A General System for Semantic Analysis of English And Use in Drawing Maps from Directions .R. Halts • Adaptive Natural Language Parser L. Miller . . Grammar (abstract only) A. Martin . . Semantic-based Parsing and a Natural-language Interface Iftteractive Data Management Burger, Axle Shoshani • • • • • • • . • PHLIQA 1: Multilevel Semantics in Question Answering</title>
<author confidence="0.9960475">P Medema</author>
<author confidence="0.9960475">W J Bronnenberg</author>
<author confidence="0.9960475">H C Bunt</author>
<author confidence="0.9960475">S P J Landsbergen</author>
<author confidence="0.9960475">R J H Scha</author>
<author confidence="0.9960475">W J Schoenmakers</author>
<author confidence="0.9960475">E P C van_Utteren</author>
<affiliation confidence="0.533998">THIRTEENTH ANNUAL MEETING THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS Sheraton Boston Hotel</affiliation>
<address confidence="0.666013">Boston, Massachusetts</address>
<date confidence="0.8883685">October GO-November 1, 1975 Thursday, October 30, 1975</date>
<note confidence="0.535619">SESSION 1: LANGUAGE UNDERSTANDING SYSTEMS Session Chairman: Yorick Mks - University of Edinburgh</note>
<address confidence="0.80103375">9:00 A.M. Introductory Remarks 9:15 A.M. and Understanding Natural Lang-uage Processing William Fabens - Rutgers University 9:40 A.M. for General Semanitic Analysis And Its Use</address>
<title confidence="0.774737">In Drawing Maps from Directions</title>
<author confidence="0.806637">The City College of CUNY</author>
<note confidence="0.4129315">10:05 A.M. Adaptive Natural Language Parser Perry L. Miller M 1 T. [0:30 A.tvi. COFFEE &amp; DONUTS L100 William A. Martin - MIT 11:30 Parsing And A Natural-Language Interface</note>
<title confidence="0.922492">interactive Afanagernent</title>
<author confidence="0.922816">John F Burger</author>
<author confidence="0.922816">Antonio Leal</author>
<author confidence="0.922816">Arie Shoshani</author>
<affiliation confidence="0.788946">System Development Corporation</affiliation>
<address confidence="0.644797">NOON 1: Semantics in Question Answering</address>
<affiliation confidence="0.867616">P. Iviedema, el. al - Philips Research Laboratories,</affiliation>
<address confidence="0.924318">The Netherlands</address>
<email confidence="0.214067">()BREAK</email>
<note confidence="0.8712999">5 2 SESSION 2: LANGUAGE GENERATION SYSTEMS Chairman: Martin Kay - 6 2:00 P.M. 2:30 P.M. 3:00 P.M. 3:30 P.M. 4:00 P.M.</note>
<title confidence="0.9872065">A Framework for Writing Generation Grammars for Interactive Computer Programs</title>
<author confidence="0.957013">M I T</author>
<title confidence="0.796424666666667">Sentence Rodger Knaus - Bureau of the Census A Lexical Process Model of Nominal Compounding</title>
<author confidence="0.853133">In English</author>
<affiliation confidence="0.93358675">J.R. Rhyne - University of Houston COFFEE &amp; DONUTS as Parsing from into a Stuart C Shapiro - Indiana University</affiliation>
<title confidence="0.619393333333333">P.M. Generation from Semantic Nets Jonathan Slocum - Stanford Research Institute P.M. Planning Structures to Generate Stories</title>
<author confidence="0.482146">Jim Meehan</author>
<address confidence="0.9818705">5:30 P.M. DINNER BREAK 8:00 RM. WINE, CHEESE &amp; COMPUTER DEMONSTRATIONS</address>
<date confidence="0.965382">October 31,</date>
<affiliation confidence="0.8313365">SYNTAX, Session Chairman: Joyce Friedman - Stanford Research Institute</affiliation>
<address confidence="0.814406333333333">9:00 A.M. Syntactic Processing in the BBN Speech Understanding 9:30 A.M. System Bolt, Beranek &amp; Newman, Inc</address>
<affiliation confidence="0.782258666666667">and Control for Speech Understanding Wilkam H. Paxton and Ann E. Robinson Stanford Research Institute A.M. Tuneable Performance Grammar Jane J. Pobinson - Stanford Research Institute</affiliation>
<address confidence="0.872427">3 10:30 AM. COFFEE &amp; DONUTS</address>
<affiliation confidence="0.909347333333333">A.M. for Speech Understanding Gary G. I4endrix - Stanford Research Institute II Formalism for Semantic Interpretation&apos; and</affiliation>
<title confidence="0.77559">Use in Processing Prepositions Spare Norman K Sondheimer - Ohio State University -NOON and Computational of Representation for Word Concepts</title>
<affiliation confidence="0.99742">University of Alberta</affiliation>
<address confidence="0.994465">12:30 P.M. LUNCHEON BREAK</address>
<title confidence="0.736809">4: MODELING DISCOURSE WORLD KNOWLEDGE I Session Chairman: Carl Hewitt - MIT P.M. Contewt in Task-Oriented Dialog.s Barbara G. Deutsch - Stanford Research Institute Discourse Models and Language Comprehension Bertram C Bruce - Bolt, Beranek &amp; Newman, Inc P.M. Coherency of Discourse (and Some Observations /Thou: Frames/Scripts)</title>
<author confidence="0.639947">University of Illinois at Chicago Circle</author>
<affiliation confidence="0.3636555">P.M. &amp; DONUTS P.M. lipproach to the Organization of Mundane World</affiliation>
<title confidence="0.780611666666667">the Scripts R.E. Cullingford - Yale University P.M. Conceptual Description of Physical lirtivities</title>
<author confidence="0.741463">University of Pennsylvania P M Frame Analysis of American Language</author>
<affiliation confidence="0.740307">JUdy Kegi (MIT) and Nancy Chinchor (U. of Mass)</affiliation>
<address confidence="0.862117">5:30 P.M. ACL BUSINESS MEETING AND ELECTION OF OFFICERS</address>
<note confidence="0.576343333333333">7 BANQUET Saturday, November 1, 1975</note>
<title confidence="0.900065666666667">SESSION 5/1: MODELING DISCOURSE Sa WORLD KNOWLEDGE Session Chairman: Georgette Silva - System Development Corporation A.M. Reference Resolution</title>
<author confidence="0.6619105">Columbia University A M Does a System Know When to Stop Inferencine</author>
<affiliation confidence="0.804125">Stan Rosenschein - University of Pennsylvania</affiliation>
<address confidence="0.664036">10:00 A.M. COFFEE &amp; DONUTS SESSION 513: TEXT ANALYSIS</address>
<title confidence="0.933791">A.M. a Computer System for Handling Inherently Linguistic</title>
<author confidence="0.970119">David Beckles</author>
<author confidence="0.970119">Lawrence Carrington</author>
<title confidence="0.9602855">Gemma Warner - The University of thc West Indies A.M. Language Processing Package</title>
<author confidence="0.981352">David Brill</author>
<author confidence="0.981352">Beatrice T Oshika</author>
<affiliation confidence="0.468404">Speech Communications Research Laboratory A.M. the, Role of Words and Phrases in Automatic Text Analysis and Computation Gerard Salton - Cornell University</affiliation>
<title confidence="0.9198705">Grammatical Compression in Notes and Records: Computation</title>
<author confidence="0.944106">Barbara Anderson</author>
<affiliation confidence="0.868216714285714">Irwin Bross (Roswell Park Memorial Institute), and Naomi Sager (New York University) Journal of Computational Linguistics 32 UNDERSTANDING NATURAL LANGUAGE PROCESSING WILLIAM FABENS COmputer Science Department Rutgers University</affiliation>
<address confidence="0.999159">New Brunswick, New Jersey 08903</address>
<abstract confidence="0.999787454545455">a programmable parser, a &apos;meta-parser.&apos; To program it, one describes not just syntax and some semantics, but also--independently--its modes of behavior. The PEDAGLOT formulation of such modes of behavior follows a categorization of parsing processes into attention-control, discovery, preand construction. types can be specified covering a number of syntax-processing and semantics-processoperations. it is not only possible of programming a metaparser, the PEDAGLOT mode-specification technique is suggestive in itself of various new approaches to modeling and understanding some language processing activities besides parsing, such as generation and inference.</abstract>
<note confidence="0.892521">work was sponsored by through Grant #RR643.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Grishman</author>
<author>N Sager</author>
<author>C Raze</author>
</authors>
<title>Bookchin,B.,&amp;quot;The Linguistic String Parser,&amp;quot;</title>
<date>1973</date>
<booktitle>Proc. NCC,</booktitle>
<publisher>AFIPS Press,</publisher>
<location>Montvale, N.J.</location>
<contexts>
<context position="30640" citStr="Grishman et al. 1973" startWordPosition="4970" endWordPosition="4973">akes as input directions in English of how to get from one place to another and outputs a map, a map such as one might sketch for an unfamiliar region, hearing the directions over the phone. A typical input might be the text &amp;quot;Upon leaving this building, turn right and follow Washington Street three blocks. Make a left. The (1) library is on the right side of the street before the text corner.&amp;quot; The output would be the map -1,410 Library Washington Street This Building To bypass syntactic problems, we are using as our input the output of the Linguistic String Project&apos;s transformational program (Grishman et al. 1973, Hobbs &amp; Grishman), which is very close to a predicate-like notation. The semantic component is designed around general semantic operations which work on a structured data base of world knowledge to draw the appropriate inferences and to identify phrases in different part d of the text which refer to the same entity. The text, augmented and interrelated in this way, is then passed over to the task component, which makes arbitrary decisions when the map requires information not given by the directions and produces the map. 23 ORGANIZATION OF TEXT AND WORLD KNOWLEDGE The two problems of semanti</context>
<context position="57273" citStr="Grishman et al. 1973" startWordPosition="9490" endWordPosition="9493">path and are mapped into a straight line. Information about names is accessed and assigned to the streets and buildings and the map is drawn. Specific Systems with a General Semantic Component. We are aiming not so much at the construction of a general natural language processing system, which still seems reasonably far off but at an easier way of constructing specific systems. The case of syntax is instructive. It would be foolish for one who is building a natural language processing system to build his syntactic component from scratch. Large general grammars and parsers for them exist (e.g. Grishman et al. 1973, Sager &amp; Grishman 1975). It is easier by several orders of magnitude to begin with a general grammar and specialize it, by weeding out the rules for constructions that don&apos;t occur in the texts one is dealing with, and by adding a few rules for constructions and constraints peculiar to one&apos;s application. We are trying to make a similar facility available for the most common kinds of semantic processing. Specializing the general semantic component would consist of several relatively easy steps. First the Lexicon would be organized into a cluster structure appropriate to the task. At worst, this</context>
</contexts>
<marker>Grishman, Sager, Raze, 1973</marker>
<rawString>Grishman, R., Sager, N., Raze, C., &amp; Bookchin,B.,&amp;quot;The Linguistic String Parser,&amp;quot; Proc. NCC, AFIPS Press, Montvale, N.J. 1973.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J I Hobbs</author>
</authors>
<title>A Model for Natural Language Semantics, Part I: The Model,&amp;quot; Yale Univ.</title>
<date>1974</date>
<journal>Dept. Comp. Sci. Res. Rep.</journal>
<volume>36</volume>
<contexts>
<context position="35641" citStr="Hobbs 1974" startWordPosition="5804" endWordPosition="5805">along a path through space, or a distance scale; &amp;quot;turn&amp;quot; indicates a change along a scale of anguLar orientation. In any particular type of text there are scales or transitive relations which are important enough to deserve a more economical representation than predicate notation. In this particular task, the important scales are a distance scale, a subscale of this indicating the path &amp;quot;you&amp;quot; All travel, and a scale representing angular orientation. This is the principal information used in constructing the map. For these scales we translate into a directed graph or lattice-like representation (Hobbs 1974). Some of the things which can be said about the structure of a scale are that some point is on the scale, that of two points on the scale one is closer to the positive end than the other, 26 and that a scale is a part of another scale. If a point B is Closer to the positive end of the scale than point A, this Tact is represented by A • B If point C lies in the interval from A to B the representation is A The diagram C D A mean the scale from C to D is part of the &apos;scale from A to B. It is possible to represent incompleteness of information. For example, if it is known that points A and B both</context>
<context position="45146" citStr="Hobbs (1974)" startWordPosition="7444" endWordPosition="7445"> &amp;quot;the only 32 house on the block&amp;quot;. If the set of comparison is identified, the superlative or ordinal indicates the scale of comparison and the place on that scale of the entity it describes. This is a subcase of (e). All of these conditions can be checked in one operation if the facts in the Lexicon are expressed in terms of suitably abstract operators relating entities to scales. We simply ask if the definite entity is on or part of a scale or at a point on or along an .interval of a scale, where the scale can be identified. However this requires that we take very seriously my suggestion in Hobbs (1974) that the lexicon for the entire language be built, insofar as possible, along the lines of a spatial metaphor. We have not yet had to face these problems since our only scales are physical -- our &amp;quot;at&amp;quot; and &amp;quot;on&amp;quot; are the locative &amp;quot;at&amp;quot; and &amp;quot;on&amp;quot;. Also checking this criterion presupposes a very sophisticated syntactic and semantic analysis. For example, (d) assumes that the times of events mentioned in tenseless constructions can be recovered. 2. A definite entity is in the no-search case if it is the dominant entity of that description. This divides into two subcriteria: a. Those entities which ar</context>
</contexts>
<marker>Hobbs, 1974</marker>
<rawString>Hobbs, J.I &amp;quot;A Model for Natural Language Semantics, Part I: The Model,&amp;quot; Yale Univ. Dept. Comp. Sci. Res. Rep. 36, Nov. 1974.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hobbs</author>
<author>R Grishman</author>
</authors>
<title>The Automatic Transformational Analysis of EngUsh Sentences: An Implementation,&amp;quot; Submitted to</title>
<date>1971</date>
<journal>International Journal of Computer</journal>
<pages>86--98</pages>
<marker>Hobbs, Grishman, 1971</marker>
<rawString>Hobbs, J., and Grishman, R., &amp;quot;The Automatic Transformational Analysis of EngUsh Sentences: An Implementation,&amp;quot; Submitted to International Journal of Computer Mathematics. Holzman, M., &amp;quot;Ellipsis in Discourse: Implications for Linguistic Analysis by Computer, The Child&apos;s Acquisition of Language, and Semantic Theory, Ir Language and Speech (1971, 86-98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Joos</author>
</authors>
<title>Semantic Axiom Number One,&amp;quot; Language</title>
<date>1972</date>
<journal>Knuth, D. The Art of Computer Programming,</journal>
<volume>3</volume>
<pages>257--265</pages>
<publisher>Addison-Wesley,</publisher>
<location>Reading, Mass.,</location>
<contexts>
<context position="37156" citStr="Joos 1972" startWordPosition="6089" endWordPosition="6090">diate between the linguistic representation of the directions and the visual representation of the maps. They are used at several points in the semantic and task 27 processes. They can be constructed for any transitive relation, and could be very useful, for example, in representing causal and enabling relations in a system translating descriptions of algorithms into flowcharts or programs. SEMANTIC OPERATIONS Basic Principle of Semantic Analysis. We believe the key to the first problem of semantic analysis, that of finding which inferences are appropriate, is Joos&apos; Semantic Axiom Number One (Joos 1972), or what I will call the Principle of *Knitting. Restated, this is, &amp;quot;The important facts in a text will be repeated, explicitly or implicity.&amp;quot; That is, we capitalize on the very high degree of redundancy that characterizes an texts. Consider, for example, the simple sentencer, &amp;quot;Walk out the door of this building.&amp;quot; &amp;quot;Walk&amp;quot; implies motion from one place to another. &amp;quot;Out&amp;quot; implies motion from inside something to the outside. &amp;quot;Door&amp;quot; is something which permits motion from inside something to the outside or from the outside to the inside, or if closed, prevents this motion. &amp;quot;Building&amp;quot; is something wh</context>
</contexts>
<marker>Joos, 1972</marker>
<rawString>Joos, M., &amp;quot;Semantic Axiom Number One,&amp;quot; Language (1972) 257-265. Knuth, D. The Art of Computer Programming, 3, Addison-Wesley, Reading, Mass., 1973.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Minsky</author>
</authors>
<title>A Framework for Representing Knowledge,&amp;quot;</title>
<date>1974</date>
<journal>MIT Al Memo</journal>
<volume>306</volume>
<contexts>
<context position="32933" citStr="Minsky 1974" startWordPosition="5363" endWordPosition="5364">hich can be drawn from the occurrence of p(X11...1Xn) in the Text. The facts are expressed in terms of p&apos;s set of parameters and a set of other lexical variables standing for entities whose existence is also implied. A fact consists of enabling conditions and conclusions. When occurs in the Text and the semantic operations determine a 24 particular inference appropriate, its enabling conditions are checked. If they hold, the conclusions are instantiated by creating a copy of them in the Text with the lexical variables replaced by Text entities. Clusters. One way tO state the &amp;quot;frames&amp;quot; problem (Minsky 1974) is &amp;quot;How should the data base be organized to guide, confine, and make efficient the searches which the semantic operations require?&amp;quot; We approach this by dividing the sets of inferences into clusters according to topic and salience in the particular application. In the searches, the clusters are probed in order of their concerns example, salience. In our application, the top-level cluster the one-dimensional aspects of objects and actions. For the fact about a block that it is the distance between is in the cluster. If &amp;quot;around the block&amp;quot; is salient clusters will have to be accessed to two inte</context>
</contexts>
<marker>Minsky, 1974</marker>
<rawString>Minsky, M., &amp;quot;A Framework for Representing Knowledge,&amp;quot; MIT Al Memo 306, June 1974.</rawString>
</citation>
<citation valid="false">
<title>2: (TO LOSE TO SOMEONE)) (3: (TO TIE SOMEONE)) (U: 1) (PI: OK) (M: BY LAYING AN X ON THE TOP CENTER CELL) (I) The number of concepts available to the system at present is very small. This, in fact, is why the system&apos;s first guess is usually the correct one. If the sentence is at all within the system&apos;s comprehension, the options as to its meaning are currently quite limited. (2) The range of expressive devices presently recognized is quite limited as well. For instance, the system does not recognize relative clauses, conjunctions, or pronouns (except for I and you). (3) The system currently deals only with TOTALLY UNFAMILIAR words and expressions in this adaptive fashion. It will not correctly handle familiar words which are used in new ways (such as a noun used as a verb, as in &amp;quot;zero the center square&amp;quot;).</title>
<marker></marker>
<rawString>(1: (TO BEAT SOMEONE)) (2: (TO LOSE TO SOMEONE)) (3: (TO TIE SOMEONE)) (U: 1) (PI: OK) (M: BY LAYING AN X ON THE TOP CENTER CELL) (I) The number of concepts available to the system at present is very small. This, in fact, is why the system&apos;s first guess is usually the correct one. If the sentence is at all within the system&apos;s comprehension, the options as to its meaning are currently quite limited. (2) The range of expressive devices presently recognized is quite limited as well. For instance, the system does not recognize relative clauses, conjunctions, or pronouns (except for I and you). (3) The system currently deals only with TOTALLY UNFAMILIAR words and expressions in this adaptive fashion. It will not correctly handle familiar words which are used in new ways (such as a noun used as a verb, as in &amp;quot;zero the center square&amp;quot;).</rawString>
</citation>
<citation valid="false">
<title>(4) The system tries to map the meaning of new words and expressions into its specified set of underlying concepts. It then displays its hypotheses to the user, giving him only the option of saying yes or no. The user cannot say &amp;quot;no, not quite, it means ...&amp;quot;. (Thus concepts like &amp;quot;the &apos;northeast&apos; square&amp;quot; or &amp;quot;the &apos;topmost&apos; square&amp;quot; would be confusing and not correctly understood.) Fig. 1 shows the various stages that the Adaptive System goes through in understanding a sentence. In this section, we shall watch while the system processes the sentence &amp;quot;How come you placed an x in the top right square.&amp;quot; (1) Local Syntactic Processing: In this first stage, the system scans the entire sentence looking for local constituents. These include &amp;quot;simple&amp;quot; noun phrases (NPs) and prepositional phrases (PPs), (&amp;quot;simple&amp;quot; meaning &amp;quot;up to the head noun but not including any modifying clauses or phrases&amp;quot;), and verb groups (VGs) consisting of verbs together with any adjoining modals, auxilliaries, and adverbs. In this instance, the system finds the two NPs, &amp;quot;you&amp;quot; and &amp;quot;an x&amp;quot;, the PP &amp;quot;in the top right square&amp;quot;, and the VG &amp;quot;placed&amp;quot;. (2) Semantic Clustering: At this stage, the clause-level processing starts. Unlike most systems, this clause-level processing is driven by SEMANTIC relationships, rather than by syntactic form. It uses a semantics-first &amp;quot;clustering&amp;quot;, with a secondary use of syntax for comments and confirmation. In this example, all the local constituents found can be clustered into a description of a single concept: that of making a move. Section 4 describes the mechanics of this stage in more detail.</title>
<marker></marker>
<rawString>(4) The system tries to map the meaning of new words and expressions into its specified set of underlying concepts. It then displays its hypotheses to the user, giving him only the option of saying yes or no. The user cannot say &amp;quot;no, not quite, it means ...&amp;quot;. (Thus concepts like &amp;quot;the &apos;northeast&apos; square&amp;quot; or &amp;quot;the &apos;topmost&apos; square&amp;quot; would be confusing and not correctly understood.) Fig. 1 shows the various stages that the Adaptive System goes through in understanding a sentence. In this section, we shall watch while the system processes the sentence &amp;quot;How come you placed an x in the top right square.&amp;quot; (1) Local Syntactic Processing: In this first stage, the system scans the entire sentence looking for local constituents. These include &amp;quot;simple&amp;quot; noun phrases (NPs) and prepositional phrases (PPs), (&amp;quot;simple&amp;quot; meaning &amp;quot;up to the head noun but not including any modifying clauses or phrases&amp;quot;), and verb groups (VGs) consisting of verbs together with any adjoining modals, auxilliaries, and adverbs. In this instance, the system finds the two NPs, &amp;quot;you&amp;quot; and &amp;quot;an x&amp;quot;, the PP &amp;quot;in the top right square&amp;quot;, and the VG &amp;quot;placed&amp;quot;. (2) Semantic Clustering: At this stage, the clause-level processing starts. Unlike most systems, this clause-level processing is driven by SEMANTIC relationships, rather than by syntactic form. It uses a semantics-first &amp;quot;clustering&amp;quot;, with a secondary use of syntax for comments and confirmation. In this example, all the local constituents found can be clustered into a description of a single concept: that of making a move. Section 4 describes the mechanics of this stage in more detail.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Cluster</author>
</authors>
<title>Expansion and Connection: During this stage an attempt is made to account for each word in the sentence by expanding the concept clusters, and if there is more than one, by joining them together to form an entire multiclausal sentence. In this case, the concept cluster might be expanded in two ways.</title>
<marker>Cluster, </marker>
<rawString>(3) Cluster Expansion and Connection: During this stage an attempt is made to account for each word in the sentence by expanding the concept clusters, and if there is more than one, by joining them together to form an entire multiclausal sentence. In this case, the concept cluster might be expanded in two ways.</rawString>
</citation>
<citation valid="false">
<title>a) One possibility might be that it is a &amp;quot;HOW&amp;quot; type question, and that &amp;quot;come&amp;quot; is some sort of adverb. However this possibility violates a semantic constraint, since the system is not set up to answer how a move Is made; only how to win, how to prevent someone from winning, etc. Therefore this possibility is ignored.</title>
<marker></marker>
<rawString>a) One possibility might be that it is a &amp;quot;HOW&amp;quot; type question, and that &amp;quot;come&amp;quot; is some sort of adverb. However this possibility violates a semantic constraint, since the system is not set up to answer how a move Is made; only how to win, how to prevent someone from winning, etc. Therefore this possibility is ignored.</rawString>
</citation>
<citation valid="false">
<title>b) The other possibility is that &amp;quot;how come&amp;quot; is a new way of describing some other clause funrction. (4) Contextual Inference; Clarification; and Response: During this final stage, any contextual information available is brought to bear on areas of uncertainty, any necessary clarifying questions are asked, and the system responds to the sentence. In this example, the only uncertainty is the meaning of &amp;quot;how come&amp;quot;. Since this is the main (a) The local recognizers which initially find local constituents. These recognizers are represented in Augmented Transition Network [11] form, are quite simple, and are not described further in this paper.</title>
<marker></marker>
<rawString>b) The other possibility is that &amp;quot;how come&amp;quot; is a new way of describing some other clause funrction. (4) Contextual Inference; Clarification; and Response: During this final stage, any contextual information available is brought to bear on areas of uncertainty, any necessary clarifying questions are asked, and the system responds to the sentence. In this example, the only uncertainty is the meaning of &amp;quot;how come&amp;quot;. Since this is the main (a) The local recognizers which initially find local constituents. These recognizers are represented in Augmented Transition Network [11] form, are quite simple, and are not described further in this paper.</rawString>
</citation>
<citation valid="false">
<title>(b) Clause-level knowledge of how actions and clause-functions are described. This knowledge is expressed in a descriptive fashion which makes it easily manipulable, and easy to add to. (c) Clause-level syntactic knowledge which is expressed in a domainindependent form.</title>
<marker></marker>
<rawString>(b) Clause-level knowledge of how actions and clause-functions are described. This knowledge is expressed in a descriptive fashion which makes it easily manipulable, and easy to add to. (c) Clause-level syntactic knowledge which is expressed in a domainindependent form.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>