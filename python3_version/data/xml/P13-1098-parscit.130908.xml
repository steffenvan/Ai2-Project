<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000014">
<title confidence="0.928834">
A user-centric model of voting intention from Social Media
</title>
<author confidence="0.981898">
Vasileios Lampos, Daniel Preot¸iuc-Pietro and Trevor Cohn
</author>
<affiliation confidence="0.98225">
Computer Science Department
University of Sheffield, UK
</affiliation>
<email confidence="0.991528">
{v.lampos,d.preotiuc,t.cohn}@dcs.shef.ac.uk
</email>
<sectionHeader confidence="0.994644" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99975132">
Social Media contain a multitude of user
opinions which can be used to predict real-
world phenomena in many domains in-
cluding politics, finance and health. Most
existing methods treat these problems as
linear regression, learning to relate word
frequencies and other simple features to
a known response variable (e.g., voting
intention polls or financial indicators).
These techniques require very careful fil-
tering of the input texts, as most Social
Media posts are irrelevant to the task. In
this paper, we present a novel approach
which performs high quality filtering au-
tomatically, through modelling not just
words but also users, framed as a bilin-
ear model with a sparse regulariser. We
also consider the problem of modelling
groups of related output variables, us-
ing a structured multi-task regularisation
method. Our experiments on voting inten-
tion prediction demonstrate strong perfor-
mance over large-scale input from Twitter
on two distinct case studies, outperform-
ing competitive baselines.
</bodyText>
<sectionHeader confidence="0.99885" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999697943396227">
Web Social Media platforms have ushered a new
era in human interaction and communication. The
main by-product of this activity is vast amounts of
user-generated content, a type of information that
has already attracted the interest of both marke-
teers and scientists because it offers – for the first
time at a large-scale – unmediated access to peo-
ples’ observations and opinions.
One exciting avenue of research concentrates
on mining interesting signals automatically from
this stream of text input. For example, by exploit-
ing Twitter posts, it is possible to infer time series
that correlate with financial indicators (Bollen et
al., 2011), track infectious diseases (Lampos and
Cristianini, 2010; Lampos et al., 2010; Paul and
Dredze, 2011) and, in general, nowcast the magni-
tude of events emerging in real-life (Sakaki et al.,
2010; Lampos and Cristianini, 2012). Other stud-
ies suggest ways for modelling opinions encap-
sulated in this content in order to forge branding
strategies (Jansen et al., 2009) or understand vari-
ous socio-political trends (Tumasjan et al., 2010;
O’Connor et al., 2010; Lansdall-Welfare et al.,
2012). The main theme of the aforementioned
works is linear regression between word frequen-
cies and a real-world quantity. They also tend to
incorporate hand-crafted lists of search terms to
filter irrelevant content and use sentiment analy-
sis lexicons for extracting opinion bias. Conse-
quently, they are quite often restricted to a specific
application and therefore, generalise poorly to new
data sets (Gayo-Avello et al., 2011).
In this paper, we propose a generic method that
aims to be independent of the characteristics de-
scribed above (use of search terms or sentiment
analysis tools). Our approach is able to explore
not only word frequencies, but also the space of
users by introducing a bilinear formulation for
this learning task. Regularised regression on both
spaces allows for an automatic selection of the
most important terms and users, performing at the
same time an improved noise filtering. In addi-
tion, more advanced regularisation functions en-
able multi-task learning schemes that can exploit
shared structure in the feature space. The latter
property becomes very useful in multi-output re-
gression scenarios, where selected features are ex-
pected to have correlated as well as anti-correlated
impact on each output (e.g., when inferring voting
intentions for competing political parties).
We evaluate our methods on the domain of
politics using data from the microblogging ser-
vice of Twitter to infer voting trends. Our pro-
</bodyText>
<page confidence="0.982236">
993
</page>
<note confidence="0.914163">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 993–1003,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.9995975">
posed framework is able to successfully predict
voting intentions for the top-3 and top-4 parties
in the United Kingdom (UK) and Austria respec-
tively. In both case studies – bound by differ-
ent characteristics (including language, time-span
and number of users) – the average prediction er-
ror is smaller than 1.5% for our best model using
multi-task learning. Finally, our qualitative analy-
sis shows that the models uncover interesting and
semantically interpretable insights from the data.
</bodyText>
<sectionHeader confidence="0.994778" genericHeader="introduction">
2 Data
</sectionHeader>
<bodyText confidence="0.99901475">
For the evaluation of the proposed methodologies
we have created two data sets of Social Media con-
tent with different characteristics based in the UK
and Austria respectively. They are used for per-
forming regression aiming to infer voting intention
polls in those countries. Data processing is per-
formed using the TrendMiner architecture for So-
cial Media analysis (Preot¸iuc-Pietro et al., 2012).
</bodyText>
<subsectionHeader confidence="0.980525">
2.1 Tweets from users in the UK
</subsectionHeader>
<bodyText confidence="0.9997815">
The first data set (we refer to it as Cuk) used in
our experimental process consists of approx. 60
million tweets produced by approx. 42K UK Twit-
ter users from 30/04/2010 to 13/02/2012. We as-
sumed each user to be from the UK, if the location
field in their profile matched with a list of com-
mon UK locations and their time zone was set to
G.M.T. In this way, we were able to extract hun-
dreds of thousands of UK users, from which we
sub-sampled 42K users to be distributed across the
UK geographical regions proportionally to their
population figures.1
</bodyText>
<subsectionHeader confidence="0.941863">
2.2 Tweets for Austria
</subsectionHeader>
<bodyText confidence="0.99999575">
The second data set (Cau) is shorter in terms of
the number of users involved (1.1K), its time span
(25/01 to 01/12/2012) and, consequently, of the
total number of tweets considered (800K). How-
ever, this time the selection of users has been made
by Austrian political experts who decided which
accounts to monitor by subjectively assessing the
value of information they may provide towards
political-oriented topics. Still, we assume that the
different users will produce information of varying
quality, and some should be eliminated entirely.
However, we emphasise that there may be smaller
</bodyText>
<footnote confidence="0.947272666666667">
1Data collection was performed using Twitter API,
http://dev.twitter.com/, to extract all posts for our
target users.
</footnote>
<figure confidence="0.980890333333333">
Time
(a) 240 voting intention polls for the 3 major parties
in the UK (April 2010 to February 2012)
Time
(b) 98 voting intention polls for the 4 major parties in
Austria (January to December 2012)
</figure>
<figureCaption confidence="0.969709">
Figure 1: Voting intention polls for the UK and
Austria.
</figureCaption>
<bodyText confidence="0.938697">
potential gains from user modelling compared to
the UK case study. Another important distinction
is language, which for this data set is primarily
German with some English.
</bodyText>
<subsectionHeader confidence="0.999397">
2.3 Ground Truth
</subsectionHeader>
<bodyText confidence="0.9788251875">
The ground truth for training and evaluating our
regression models is formed by voting intention
polls from YouGov (UK) and a collection of Aus-
trian pollsters2 – as none performed high fre-
quency polling – for the Austrian case study.
We focused on the three major parties in the
UK, namely Conservatives (CON), Labour (LAB)
and Liberal Democrats (LBD) and the four ma-
jor parties in Austria, namely the Social Demo-
cratic Party (SP ¨O), People’s Party ( ¨OVP), Free-
dom Party (FP ¨O) and the Green Alternative Party
(GR ¨U). Matching with the time spans of the data
sets described in the previous sections, we have
acquired 240 unique polls for the UK and 65 polls
for Austria. The latter have been expanded to
98 polls by replicating the poll of day i for day
</bodyText>
<footnote confidence="0.986753">
2Wikipedia, http://de.wikipedia.org/wiki/
Nationalratswahl—in—\%D6sterreich—2013.
</footnote>
<page confidence="0.808692">
45
</page>
<figure confidence="0.989078296296296">
40
35
30
25
20
15
10
5
0
5 30 55 80 105 130 155 180 205 230
CON
LAB
LIB
5 20 35 50 65 80 95
Voting Intention %
30
25
20
15
10
5
0
SPÖ
ÖVP
FPÖ
GRÜ
Voting Intention %
</figure>
<page confidence="0.997626">
994
</page>
<bodyText confidence="0.9998064">
i − 1 where possible.3 There exists some inter-
esting variability towards the end for the UK polls
(Fig. 1a), whereas for the Austrian case, the main
changing point is between the second and the third
party (Fig. 1b).
</bodyText>
<sectionHeader confidence="0.996288" genericHeader="method">
3 Methods
</sectionHeader>
<bodyText confidence="0.999962111111111">
The textual content posted on Social Media plat-
forms unarguably contains valuable information,
but quite often it is hidden under vast amounts of
unstructured user generated input. In this section,
we propose a set of methods that build on one an-
other, which aim to filter the non desirable noise
and extract the most informative features not only
based on word frequencies, but also by incorporat-
ing users in this process.
</bodyText>
<subsectionHeader confidence="0.997415">
3.1 The bilinear model
</subsectionHeader>
<bodyText confidence="0.999829761904762">
There exist a number of different possibilities for
incorporating user information into a regression
model. A simple approach is to expand the fea-
ture set, such that each user’s effect on the re-
sponse variable can be modelled separately. Al-
though flexible, this approach would be doomed
to failure due to the sheer size of the resulting fea-
ture set, and the propensity to overfit all but the
largest of training sets. One solution is to group
users into different types, such as journalist, politi-
cian, activist, etc., but this presupposes a method
for classification or clustering of users which is a
non-trivial undertaking. Besides, these naive ap-
proaches fail to account for the fact that most users
use similar words to express their opinions, by
separately parameterising the model for different
users or user groups.
We propose to account for individual users
while restricting all users to share the same vocab-
ulary. This is formulated as a bilinear predictive
model,
</bodyText>
<equation confidence="0.999579">
f(X) = uTXw + β , (1)
</equation>
<bodyText confidence="0.950699133333333">
where X is an m x p matrix of user-word fre-
quencies and u and w are the model parameters.
Let Q E Rnxmxp be a tensor which captures our
training inputs, where n, m and p denote the con-
sidered number of samples (each sample usually
refers to a day), terms and users respectively; Q
can simply be interpreted as n versions of X (de-
noted by Qi in the remainder of the script), a dif-
ferent one for each day, put together. Each element
3This has been carried out to ensure an adequate number
of training points in the experimental process.
Qijk holds the frequency of term j for user k dur-
ing the day i in our sample. If a user k has posted
ci·k tweets during day i, and cijk G ci·k of them
contain a term j, then the frequency of j for this
</bodyText>
<subsectionHeader confidence="0.465889">
jk
</subsectionHeader>
<bodyText confidence="0.9375608">
day and user is defined as Qijk = ci .
Aiming to learn sparse sets of users and terms
that are representative of the voting intention sig-
nal, we formulate our optimisation task as follows:
n
</bodyText>
<equation confidence="0.984784">
{w*,u*, β*} = argmin (uTQiw + β − yi)2
w,u,β i=1
+ ψ(w,ρ1) + ψ(u,ρ2),
(2)
</equation>
<bodyText confidence="0.999342826086957">
where y E Rn is the response variable (voting in-
tention), w E Rm and u E Rp denote the term
and user weights respectively, uTQiw expresses
the bilinear term, β E R is a bias term and ψ(·)
is a regularisation function with parameters ρ1 or
ρ2. The first term in Eq. 2 is the standard regulari-
sation loss function, namely the sum squared error
over the training instances.4
In the main formulation of our bilinear model,
as the regularisation function ψ(·) we use the elas-
tic net (Zou and Hastie, 2005), an extension of
the well-studied `1-norm regulariser, known as the
LASSO (Tibshirani, 1996). The `1-norm regu-
larisation has found many applications in several
scientific fields as it encourages sparse solutions
which reduce the possibility of overfitting and en-
hance the interpretability of the inferred model
(Hastie et al., 2009). The elastic net applies an
extra penalty on the `2-norm of the weight vector,
and can resolve instability issues of LASSO which
arise when correlated predictors exist in the input
data (Zhao and Yu, 2006). Its regularisation func-
tion ψel(·) is defined by:
</bodyText>
<equation confidence="0.995727">
C1 − α /
ψel (w,λ,α) = λ 2 �w�2 2 + α�w�1 , (3)
</equation>
<bodyText confidence="0.999921777777778">
where λ &gt; 0 and α E [0, 1); setting parameter
α to its extremes transforms elastic net to ridge
regression (α = 0) or vanilla LASSO (α = 1).
Eq. 2 can be treated as a biconvex learning task
(Al-Khayyal and Falk, 1983), by observing that
for a fixed w, learning u is a convex problem and
vice versa. Biconvex functions and possible ap-
plications have been well studied in the optimi-
sation literature (Quesada and Grossmann, 1995;
</bodyText>
<footnote confidence="0.822808">
4Note that other loss functions could be used here, such
as logistic loss for classification, or more generally bilinear
variations of Generalised Linear Models (Nelder and Wed-
derburn, 1972).
</footnote>
<page confidence="0.996852">
995
</page>
<bodyText confidence="0.999429416666667">
Pirsiavash et al., 2009). Their main advantage is
the ability to solve efficiently non-convex prob-
lems by a repeated application of two convex pro-
cesses, i.e., a form of coordinate ascent. In our
case, the bilinear technique makes it possible to
explore both word and user spaces, while main-
taining a modest training complexity.
Therefore, in our bilinear approach we divide
learning in two phases, where we learn word and
user weights respectively. For the first phase we
produce the term-scores matrix V ∈ Rn×m with
elements given by:
</bodyText>
<equation confidence="0.9239">
uzQijz. (4)
</equation>
<bodyText confidence="0.997259222222222">
V contains weighted sums of term frequencies
over all users for the considered set of days. The
weights are held in u and are representative of
each user. The initial optimisation task is formu-
lated as:
where we aim to learn a sparse but consistent set
of weights w∗ for the terms of our vocabulary.
In the second phase, we are using w∗ to form
the user-scores matrix D ∈ Rn×p:
</bodyText>
<equation confidence="0.59913">
w∗zQizk , (6)
</equation>
<bodyText confidence="0.998988333333333">
which now contains weighted sums over all terms
for the same set of days. The optimisation task
becomes:
</bodyText>
<equation confidence="0.993825666666667">
{u∗, β∗} = argmin kDu + β − yk22
u,β (7)
+ ψel (u, λ2, α2) .
</equation>
<bodyText confidence="0.999954">
This process continues iteratively by inserting
the weights of the second phase back to phase one,
and so on until convergence. We cannot claim that
a global optimum will be reached, but biconvexity
guarantees that our global objective (Eq. 2) will
decrease in each step of this iterative process. In
the remainder of this paper, we refer to the method
described above as Bilinear Elastic Net (BEN).
</bodyText>
<subsectionHeader confidence="0.936173">
3.2 Exploiting term-target or user-target
relationships
</subsectionHeader>
<bodyText confidence="0.990976894736842">
The previous model assumes that the response
variable y holds information about a single infer-
ence target. However, the task that we are ad-
dressing in this paper usually implies the exis-
tence of several targets, i.e., different political par-
ties or politicians. An important property, there-
fore, is the ability to perform multiple output re-
gression. A simple way of adapting the model to
the multiple output scenario is by framing a sep-
arate learning problem for each output, but tying
together some of the parameters. Here we con-
sider tying together the user weights u, to enforce
that the same set of users are relevant to all tasks,
while learning different term weights. Note that
the converse situation, where w’s are tied and u’s
are independent, can be formulated in an equiva-
lent manner.
Suppose that our target variable y ∈ Rτn refers
now to τ political entities, y = �yT ~T; in
</bodyText>
<equation confidence="0.850581">
1yT 2...yT τ
</equation>
<bodyText confidence="0.9962">
this formation the top n elements of y match to
the first political entity, the next n elements to the
second and so on. In the first phase of the bilin-
ear model, we would have to solve the following
optimisation task:
</bodyText>
<equation confidence="0.9947608">
{w∗, β∗} =argmin
w,β
+
Xτ ψel (wi, λ1, α1) , (8)
i=1
</equation>
<bodyText confidence="0.9760735">
where V is given by Eq. 4 and w∗ ∈ Rτm de-
notes the vector of weights which can be sliced
into τ sub-vectors {w∗1, ...,w∗τ} each one repre-
senting a political entity. In the second phase,
sub-vectors w∗i are used to form the input matrices
Di, i ∈ {1, ..., τ} with elements given by Eq. 6.
The input matrix D0 is formed by the vertical
concatenation of all Di user score matrices, i.e.,
D0 = [D1 ... DT ~T, and the optimisation target is
τ
equivalent to the one expressed in Eq. 7. Since
D0 ∈ Rτn×p, the user weight vector u∗ ∈ Rp and
thus, we are learning a single weight per user and
not one per political party as in the previous step.
The method described above allows learning
different term weights per response variable and
then binds them under a shared set of user weights.
As mentioned before, one could also try the oppo-
site (i.e., start by expanding the user space); both
those models can also be optimised in an itera-
tive process. However, our experiments revealed
that those approaches did not improve on the
performance of BEN. Still, this behaviour could
be problem-specific, i.e., learning different words
</bodyText>
<equation confidence="0.994894909090909">
Xp
z=1
Vij =
{w∗, β∗} =argmin kVw + β − yk22 (5)
w,β + ψel (w, λ1, α1) ,
m
X
z=1
Dik =
Xτ kVwi + βi − yik22
i=1
</equation>
<page confidence="0.983861">
996
</page>
<bodyText confidence="0.998984142857143">
from a shared set of users (and the opposite) may
not be a good modelling practice for the domain of
politics. Nevertheless, this observation served as
a motivation for the method described in the next
section, where we extract a consistent set of words
and users that are weighted differently among the
considered political entities.
</bodyText>
<subsectionHeader confidence="0.6262215">
3.3 Multi-task learning with the `1/`2
regulariser
</subsectionHeader>
<bodyText confidence="0.99990675">
All previous models – even when combining all
inference targets – were not able to explore rela-
tionships across the different task domains; in our
case, a task domain is defined by a specific politi-
cal label or party. Ideally, we would like to make a
sparse selection of words and users but with a reg-
ulariser that promotes inter-task sharing of struc-
ture, so that many features may have a positive
influence towards one or more parties, but nega-
tive towards the remaining one(s). It is possible to
achieve this multi-task learning property by intro-
ducing a different set of regularisation constraints
in the optimisation function.
We perform multi-task learning using an exten-
sion of group LASSO (Yuan and Lin, 2006), a
method known as `1/`2 regularisation (Argyriou et
al., 2008; Liu et al., 2009). Group LASSO exploits
a predefined group structure on the feature space
and tries to achieve sparsity in the group-level, i.e.,
it does not perform feature selection (unlike the
elastic net), but group selection. The `1/`2 regu-
lariser extends this notion for a τ-dimensional re-
sponse variable. The global optimisation target is
now formulated as:
</bodyText>
<equation confidence="0.8939018">
{W*, U*,β*1 =
argmin �τ n (ut 2iwt + βt − yti 2 (9)
W,U,β t=1 i=1 )
+ λ1 �m lWjl2 + λ2 � p lUkl2,
j=1 k=1
</equation>
<bodyText confidence="0.999990620689655">
where the input matrix 2i is defined in the same
way as earlier, W = [w1 ... wτ] is the term weight
matrix (each wt refers to the t-th political entity
or task), equivalently U = [u1 ... uτ], Wj and Uj
denote the j-th rows of weight matrices W and
U respectively, and vector β E ][8τ holds the bias
terms per task. In this optimisation process, we
aim to enforce sparsity in the feature space but in
a structured manner. Notice that we are now regu-
larising the `2,1 mixed norm of W and U, which is
defined as the sum of the row `2-norms for those
matrices. As a result, we expect to encourage the
activation of a sparse set of features (correspond-
ing to the rows of W and U), but with nonzero
weights across the τ tasks (Argyriou et al., 2008).
Consequently, we are performing filtering (many
users and words will have zero weights) and, at the
same time, assign weights of different magnitude
and sign on the selected features, something that
suits a political opinion mining application, where
pro-A often means anti-B.
Eq. 9 can be broken into two convex tasks (fol-
lowing the same notion as in Eqs. 5 and 7), where
we individually learn {W,β1 and then {U,β1;
each step of the process is a standard linear regres-
sion problem with an `1/`2 regulariser. Again, we
are able iterate this bilinear process and in each
step convexity is guaranteed. We refer to this
method as Bilinear Group `1/`2 (BGL).
</bodyText>
<sectionHeader confidence="0.999743" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.9999675">
The proposed models are evaluated on Cuk and
Cau which have been introduced in Section 2. We
measure predictive performance, compare it to the
performance of several competitive baselines, and
provide a qualitative analysis of the parameters
learned by the models.
</bodyText>
<subsectionHeader confidence="0.99629">
4.1 Data preprocessing
</subsectionHeader>
<bodyText confidence="0.999980066666667">
Basic preprocessing has been applied on the vo-
cabulary index of Cuk and Cau aiming to filter out
some of the word features and partially reduce
the dimensionality of the problem. Stop words
and web links were removed in both sets, together
with character sequences of length &lt;4 and &lt;3
for Cuk and Cau respectively.5 As the vocabulary
size of Cuk was significantly larger, for this data
set we have additionally merged Twitter hashtags
(i.e., words starting with ‘#’) with their exact non
topic word match, where possible (by dropping the
‘#’ when the word existed in the index). After
performing the preprocessing routines described
above, the vocabulary sizes for Cuk and Cau were
set to 80,976 and 22,917 respectively.
</bodyText>
<subsectionHeader confidence="0.991658">
4.2 Predictive accuracy
</subsectionHeader>
<bodyText confidence="0.999893">
To evaluate the predictive accuracy of our meth-
ods, we have chosen to emulate a real-life scenario
</bodyText>
<footnote confidence="0.52180725">
5Most of the times those character sequences were not
valid words. This pattern was different in each language and
thus, a different filtering threshold was applied in each data
set.
</footnote>
<page confidence="0.973519">
997
</page>
<figure confidence="0.661943">
Step
</figure>
<figureCaption confidence="0.950144666666667">
Figure 2: Global objective function and RMSE on
a validation set for BEN in 15 iterations (30 steps)
of the model.
</figureCaption>
<bodyText confidence="0.9996045">
of voting intention prediction. The evaluation pro-
cess starts by using a fixed set of polls matching
to consecutive time points in the past for training
and validating the parameters of each model. Test-
ing is performed on the following 6 (unseen) polls
of the data set. In the next step of the evaluation
process, the training/validation set is increased by
merging it with the previously used test set (6
polls), and testing is now performed on the next
6 unseen polls. In our experiments, the number of
steps in this evaluation process is set to 10 and in
each step the size of the test set is set to 6 = 5
polls. Hence, each model is tested on 50 unseen
and consecutive in time samples. The loss func-
tion in our evaluation is the standard Mean Square
Error (MSE), but to allow a better interpretation
of the results, we display its root (RMSE) in ta-
bles and figures.6
The parameters of each model (αi for BEN and
λi for BEN and BGL, i ∈ {1, 2}) are optimised
using a held-out validation set by performing grid
search. Note that it may be tempting to adapt the
regularisation parameters in each phase of the it-
erative training loop, however this would change
the global objective (see Eqs. 2 and 9) and thus
convergence will not be guaranteed. A key ques-
tion is how many iterations of training are required
to reach convergence. Figure 2 illustrates how the
BEN global objective function (Eq. 2) converges
during this iterative process and the model’s per-
formance on an unseen validation set. Notice that
there is a large performance improvement after the
first step (which alone is a linear solver), but over-
fitting occurs after step 11. Based on this result,
for subsequent experiments we run the training
process for two iterations (4 steps), and take the
</bodyText>
<footnote confidence="0.892909">
6RMSE has the same metric units as the response variable.
</footnote>
<table confidence="0.999592833333333">
CON LAB LBD µ
Bµ 2.272 1.663 1.136 1.69
Blast 2 2.074 1.095 1.723
LEN 3.845 2.912 2.445 3.067
BEN 1.939 1.644 1.136 1.573
BGL 1.785 1.595 1.054 1.478
</table>
<tableCaption confidence="0.6733646">
Table 1: UK case study — Average RMSEs rep-
resenting the error of the inferred voting intention
percentage for the 10-step validation process; µ
denotes the mean RMSE across the three political
parties for each baseline or inference method.
</tableCaption>
<table confidence="0.999812">
SPO¨ ¨OVP FPO¨ GRU¨ µ
Bµ 1.535 1.373 3.3 1.197 1.851
Blast 1.148 1.556 1.639 1.536 1.47
LEN 1.291 1.286 2.039 1.152 1.442
BEN 1.392 1.31 2.89 1.205 1.699
BGL 1.619 1.005 1.757 1.374 1.439
</table>
<tableCaption confidence="0.8114605">
Table 2: Austrian case study — Average RMSEs
for the 10-step validation process.
</tableCaption>
<bodyText confidence="0.999169115384615">
best performing model on the held-out validation
set.
We compare the performance of our methods
with three baselines. The first makes a constant
prediction of the mean value of the response vari-
able y in the training set (Bµ); the second predicts
the last value of y (Blast); and the third baseline
(LEN) is a linear regression over the terms using
elastic net regularisation. Recalling that each test
set is made of 5 polls, Blast should be considered
as a hard baseline to beat7 given that voting inten-
tions tend to have a smooth behaviour. Moreover,
improving on LEN partly justifies the usefulness
of a bilinear approach compared to a linear one.
Performance results comparing inferred voting
intention percentages and polls for Cuk and Cau are
presented in Tables 1 and 2 respectively. For the
UK case study, both BEN and BGL are able to beat
all baselines in average performance across all par-
ties. However in the Austrian case study, LEN
performs better that BEN, something that could be
justified by the fact that the users in Cau were se-
lected by domain experts, and consequently there
was not much gain to be had by filtering them fur-
ther. Nevertheless, the difference in performance
was rather small (approx. 0.26% error) and the in-
</bodyText>
<footnote confidence="0.725695">
7The last response value could be easily included as a fea-
ture in the model, and would likely improve predictive perfor-
mance.
</footnote>
<figure confidence="0.9933276">
2 4 6 8 10 12 14 16 18 20 22 24 26 28 30
2.4
0.8
0.4
1.6
1.2
2
0
Global Objective
RMSE
</figure>
<page confidence="0.9430825">
998
999
</page>
<figure confidence="0.999634445652174">
CON
LAB
LIB
5 10 15 20 25 30 35 40 45
Time
(a) Ground Truth (polls)
CON
LAB
LIB
5 10 15 20 25 30 35 40 45
Time
(b) BEN
CON
LAB
LIB
5 10 15 20 25 30 35 40 45
Time
30
25
20
15
10
5
0
5 10 15 20 25 30 35 40 45
SPÖ
ÖVP
FPÖ
GRÜ
Time
(a) Ground Truth (polls)
5 10 15 20 25 30 35 40 45
Voting Intention %
30
25
20
15
10
5
0
SPÖ
ÖVP
FPÖ
GRÜ
Time
(b) BEN
5 10 15 20 25 30 35 40 45
Time
Voting Intention %
SPÖ
ÖVP
FPÖ
GRÜ
40
35
30
25
20
15
10
Voting Intention %
5
0
40
35
30
25
20
15
10
Voting Intention %
5
0
40
35
30
25
20
15
10
Voting Intention %
5
0
30
25
20
15
10
Voting Intention %
5
0
(c) BGL
</figure>
<figureCaption confidence="0.7334515">
Figure 3: UK case study — Voting intention infer-
ence results (50 polls, 3 parties). Sub-figure 3a is
a plot of ground truth as presented in voting inten-
tion polls (Fig. 1a).
</figureCaption>
<bodyText confidence="0.972579">
ferences of LEN and BEN followed a very similar
pattern (¯ρ = .94 with p &lt; 10−10).8 Multi-task
learning (BGL) delivered the best inference per-
formance in both case studies, which was on aver-
age smaller than 1.48% (RMSE).
Inferences for both BEN and BGL have been
plotted on Figures 3 and 4. They are presented as
continuous lines of 50 inferred points (per party)
which are created by concatenating the inferences
8Pearson’s linear correlation averaged across the four
Austrian parties.
</bodyText>
<figure confidence="0.849304">
(c) BGL
</figure>
<figureCaption confidence="0.9412415">
Figure 4: Austrian case study — Voting intention
inference results (50 polls, 4 parties). Sub-figure
4a is a plot of ground truth as presented in voting
intention polls (Fig. 1b).
</figureCaption>
<bodyText confidence="0.986873888888889">
on all test sets.9 For the UK case study, one may
observe that BEN (Fig. 3b) cannot register any
change – with the exception of one test point – in
the leading party fight (CON versus LAB); BGL
(Fig. 3c) performs much better in that aspect. In
the Austrian case study this characteristic becomes
more obvious. BEN (Fig. 4b) consistently predicts
the wrong ranking of ¨OVP and FP ¨O, whereas BGL
(Fig. 4c) does much better. Most importantly, a
</bodyText>
<footnote confidence="0.532921">
9Voting intention polls were plotted separately to allow a
better presentation.
</footnote>
<table confidence="0.99990415">
Party Tweet Score Author
CON PM in friendly chat with top EU mate, Sweden’s Fredrik Reinfeldt, before family photo 1.334 Journalist
Have Liberal Democrats broken electoral rules? Blog on Labour complaint to cabinet −0.991 Journalist
secretary
LAB Blog Post Liverpool: City of Radicals Website now Live &lt;link&gt; #liverpool #art 1.954 Art Fanzine
I am so pleased to hear Paul Savage who worked for the Labour group has been Ap- −0.552 Politician
pointed the Marketing manager for the baths hall GREAT NEWS (Labour)
LBD RT @user: Must be awful for TV bosses to keep getting knocked back by all the 0.874 LibDem MP
women they ask to host election night (via @user)
Blog Post Liverpool: City of Radicals 2011 – More Details Announced #liverpool −0.521 Art Fanzine
#art
SPO¨ Inflationsrate in ¨O. im Juli leicht gesunken: von 2,2 auf 2,1%. Teurer wurde Wohnen, 0.745 Journalist
Wasser, Energie.
Translation: Inflation rate in Austria slightly down in July from 2,2 to 2,1%. Accom-
modation, Water, Energy more expensive.
Hans Rauscher zu Felix #Baumgartner “A klaner Hitler” &lt;link&gt; −1.711 Journalist
Translation: Hans Rauscher on Felix #Baumgartner “A little Hitler” &lt;link&gt;
¨OVP #IchPirat setze mich daf¨ur ein, dass eine große Koalition mathematisch verhindert 4.953 User
wird! 1.Geige: #Gruene + #FPOe + #OeVP
Translation: #IPirate am committed to prevent a grand coalition mathematically!
Calling the tune: #Greens + #FPO + #OVP
kann das buch “res publica” von johannes #voggenhuber wirklich empfehlen! so zum −2.323 User
nachdenken und so... #europa #demokratie
Translation: can really recommend the book “res publica” by johannes
#voggenhuber! Food for thought and so on #europe #democracy
FPO¨ Neue Kampagne der #Krone zur #Wehrpflicht: “GIB BELLO EINE STIMME!” 7.44 Political satire
Translation: New campaign by the #Krone on #Conscription: “GIVE WOOFY A
VOICE!”
Kampagne der Wiener SPO¨ “zum Zusammenleben” spielt Rechtspopulisten in die −3.44 Human Rights
H¨ande &lt;link&gt;
Translation: Campaign of the Viennese SP O¨ on “Living together” plays right into the
hands of right-wing populists &lt;link&gt;
GRU¨ Protestsong gegen die Abschaffung des Bachelor-Studiums Internationale Entwick- 1.45 Student Union
lung: &lt;link&gt; #IEbleibt #unibrennt #uniwut
Translation: Protest songs against the closing-down of the bachelor course of Inter-
national Development: &lt;link&gt; #IDremains #uniburns #unirage
Pilz “ich will in dieser Republik weder kriminelle Asylwerber, noch kriminelle orange −2.172 User
Politiker” - BZ ¨O-Abschiebung ok, aber wohin? #amPunkt
Translation: Pilz “i want neither criminal asylum-seekers, nor criminal orange politi-
cians in this republic” - BZ¨O-Deportation OK, but where? #amPunkt
</table>
<tableCaption confidence="0.996114">
Table 3: Examples of tweets amongst the ones with top positive and negative scores per party for both
</tableCaption>
<bodyText confidence="0.967337769230769">
Cuk and Cau data sets (tweets in Austrian have been translated in English as well). Notice that weight
magnitude may differ per case study and party as they are based on the range of the response variable
and the total number of selected features.
general observation is that BEN’s predictions are
smooth and do not vary significantly with time.
This might be a result of overfitting the model
to a single response variable which usually has
a smooth behaviour. On the contrary, the multi-
task learning property of BGL reduces this type of
overfitting providing more statistical evidence for
the terms and users and thus, yielding not only a
better inference performance, but also a more ac-
curate model.
</bodyText>
<subsectionHeader confidence="0.99659">
4.3 Qualitative Analysis
</subsectionHeader>
<bodyText confidence="0.9999444375">
In this section, we refer to features that have been
selected and weighted as significant by our bi-
linear learning functions. Based on the weights
for the word and the user spaces that we re-
trieve after the application of BGL in the last step
of the evaluation process (see the previous sec-
tion), we compute a score (weighted sum) for each
tweet in our training data sets for both Cuk and
Cau. Table 3 shows examples of interesting tweets
amongst the top weighted ones (positively as well
as negatively) per party. Together with their text
(anonymised for privacy reasons) and scores, we
also provide an attribute for the author (if present).
In the displayed tweets for the UK study, the only
possible outlier is the ‘Art Fanzine’; still, it seems
to register a consistent behaviour (positive towards
</bodyText>
<page confidence="0.950923">
1000
</page>
<bodyText confidence="0.9985745">
LAB, negative towards LBD) and, of course, hid-
den, indirect relationships may exist between po-
litical opinion and art. The Austrian case study
revealed even more interesting tweets since train-
ing was conducted on data from a very active pre-
election period (we made an effort to translate
those tweets in English language as well). For
a better interpretation of the presented tweets, it
may be useful to know that ‘Johannes Voggen-
huber’ (who receives a positive comment for his
book) and ‘Peter Pilz’ (whose comment is ques-
tioned) are members of GR ¨U, ‘Krone’ (or Kro-
nen Zeitung) is the major newspaper in Austria10
and that FP O¨ is labelled as a far right party, some-
thing that may cause various reactions from ‘Hu-
man Rights’ organisations.
</bodyText>
<sectionHeader confidence="0.999953" genericHeader="evaluation">
5 Related Work
</sectionHeader>
<bodyText confidence="0.994827260869565">
The topic of political opinion mining from So-
cial Media has been the focus of various recent
research works. Several papers have presented
methods that aim to predict the result of an elec-
tion (Tumasjan et al., 2010; Bermingham and
Smeaton, 2011) or to model voting intention and
other kinds of socio-political polls (O’Connor et
al., 2010; Lampos, 2012). Their common fea-
ture is a methodology based on a meta-analysis
of word frequencies using off-the-shelf sentiment
tools such as LIWC (Pennebaker et al., 2007)
or Senti-WordNet (Esuli and Sebastiani, 2006).
Moreover, the proposed techniques tend to incor-
porate posting volume figures as well as hand-
crafted lists of words relevant to the task (e.g.,
names of politicians or parties) in order to filter
the content successfully.
Such papers have been criticised as their meth-
ods do not generalise when applied on different
data sets. According to the work in (Gayo-Avello
et al., 2011), the methods presented in (Tumasjan
et al., 2010) and (O’Connor et al., 2010) failed to
predict the result of US congressional elections in
2009. We disagree with the arguments support-
ing the statement “you cannot predict elections
with Twitter” (Gayo-Avello, 2012), as many times
in the past actual voting intention polls have also
failed to predict election outcomes, but we agree
that most methods that have been proposed so far
were not entirely generic. It is a fact that the
10“Accused of abusing its near monopoly to manipulate
public opinion in Austria”, Wikipedia, 19/02/2013, http:
//en.wikipedia.org/wiki/Kronen_Zeitung.
majority of sentiment analysis tools are English-
specific (or even American English) and, most
importantly, political word lists (or ontologies)
change in time, per country and per party; hence,
generalisable methods should make an effort to
limit reliance from such tools.
Furthermore, our work – indirectly – meets the
guidelines proposed in (Metaxas et al., 2011) as
we have developed a framework of “well-defined”
algorithms that are “Social Web aware” (since the
bilinear approach aims to improve noise filtering)
and that have been tested on two evaluation sce-
narios with distinct characteristics.
</bodyText>
<sectionHeader confidence="0.998687" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999942409090909">
We have presented a novel method for text regres-
sion that exploits both word and user spaces by
solving a bilinear optimisation task, and an ex-
tension that applies multi-task learning for multi-
output inference. Our approach performs feature
selection – hence, noise filtering – on large-scale
user-generated inputs automatically, generalises
across two languages without manual adaptations
and delivers some significant improvements over
strong performance baselines (&lt; 1.5% error when
predicting polls). The application domain in this
paper was politics, though the presented methods
are generic and could be easily applied on various
other domains, such as health or finance.
Future work may investigate further modelling
improvements achieved by applying different reg-
ularisation functions as well as the adaptation of
the presented models to classification problems.
Finally, in the application level, we aim at an in-
depth analysis of patterns and characteristics in the
extracted sets of features by collaborating with do-
main experts (e.g., political analysts).
</bodyText>
<sectionHeader confidence="0.996979" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9981344">
This work was funded by the TrendMiner project
(EU-FP7-ICT n.287863). All authors would like
to thank the political analysts (and especially Paul
Ringler) from SORA11 for their useful insights on
politics in Austria.
</bodyText>
<footnote confidence="0.861727">
11SORA – Institute for Social Research and Consulting,
http://www.sora.at.
</footnote>
<page confidence="0.991854">
1001
</page>
<sectionHeader confidence="0.993646" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999620224299065">
Faiz A Al-Khayyal and James E Falk. 1983. Jointly
Constrained Biconvex Programming. Mathematics
of Operations Research, 8(2):273–286.
Andreas Argyriou, Theodoros Evgeniou, and Massi-
miliano Pontil. 2008. Convex multi-task feature
learning. Machine Learning, 73(3):243–272, Jan-
uary.
Adam Bermingham and Alan F Smeaton. 2011. On
using Twitter to monitor political sentiment and pre-
dict election results. In Proceedings of the Workshop
on Sentiment Analysis where AI meets Psychology
(SAAIP 2011), pages 2–10, November.
Johan Bollen, Huina Mao, and Xiaojun Zeng. 2011.
Twitter mood predicts the stock market. Journal of
Computational Science, 2(1):1–8, March.
Andrea Esuli and Fabrizio Sebastiani. 2006. Sen-
tiWordNet: A publicly available lexical resource
for opinion mining. In Proceeding of the 5th
Conference on Language Resources and Evaluation
(LREC), pages 417–422.
Daniel Gayo-Avello, Panagiotis T Metaxas, and Eni
Mustafaraj. 2011. Limits of Electoral Predictions
using Twitter. In Proceedings of the Fifth Interna-
tional AAAI Conference on Weblogs and Social Me-
dia (ICWSM), pages 490–493.
Daniel Gayo-Avello. 2012. No, You Cannot Predict
Elections with Twitter. IEEE Internet Computing,
16(6):91–94, November.
Trevor Hastie, Robert Tibshirani, and Jerome Fried-
man. 2009. The Elements of Statistical Learning.
Springer Series in Statistics. Springer.
Bernard J Jansen, Mimi Zhang, Kate Sobel, and Ab-
dur Chowdury. 2009. Twitter power: Tweets as
electronic word of mouth. Journal of the Ameri-
can Society for Information Science and Technology,
60(11):2169–2188.
Vasileios Lampos and Nello Cristianini. 2010. Track-
ing the flu pandemic by monitoring the Social Web.
In 2nd IAPR Workshop on Cognitive Information
Processing, pages 411–416. IEEE Press.
Vasileios Lampos and Nello Cristianini. 2012. Now-
casting Events from the Social Web with Statistical
Learning. ACM Transactions on Intelligent Systems
and Technology, 3(4):1–22, September.
Vasileios Lampos, Tijl De Bie, and Nello Cristianini.
2010. Flu Detector - Tracking Epidemics on Twitter.
In Proceedings of European Conference on Machine
Learning and Principles and Practice of Knowledge
Discovery in Databases (ECML PKDD), pages 599–
602. Springer.
Vasileios Lampos. 2012. On voting intentions infer-
ence from Twitter content: a case study on UK 2010
General Election. CoRR, April.
Thomas Lansdall-Welfare, Vasileios Lampos, and
Nello Cristianini. 2012. Effects of the recession
on public mood in the UK. In Proceedings of the
21st international conference companion on World
Wide Web, WWW ’12 Companion, pages 1221–
1226. ACM.
Jun Liu, Shuiwang Ji, and Jieping Ye. 2009. Multi-
task feature learning via efficient l2,1-norm mini-
mization. pages 339–348, June.
Panagiotis T Metaxas, Eni Mustafaraj, and Daniel
Gayo-Avello. 2011. How (Not) To Predict Elec-
tions. In IEEE 3rd International Conference on So-
cial Computing (SocialCom), pages 165 – 171. IEEE
Press.
John A Nelder and Robert W M Wedderburn. 1972.
Generalized Linear Models. Journal of the Royal
Statistical Society - Series A (General), 135(3):370.
Brendan O’Connor, Ramnath Balasubramanyan,
Bryan R Routledge, and Noah A Smith. 2010.
From Tweets to Polls: Linking Text Sentiment to
Public Opinion Time Series. In Proceedings of the
International AAAI Conference on Weblogs and
Social Media, pages 122–129. AAAI Press.
Michael J Paul and Mark Dredze. 2011. You Are What
You Tweet: Analyzing Twitter for Public Health.
Proceedings of the 5th International AAAI Confer-
ence on Weblogs and Social Media, pages 265–272.
James W Pennebaker, Cindy K Chung, Molly Ire-
land, Amy Gonzales, and Roger J Booth. 2007.
The Development and Psychometric Properties of
LIWC2007. Technical report, Universities of Texas
at Austin &amp; University of Auckland, New Zealand.
Hamed Pirsiavash, Deva Ramanan, and Charless
Fowlkes. 2009. Bilinear classifiers for visual recog-
nition. In Advances in Neural Information Process-
ing Systems, volume 22, pages 1482–1490.
Daniel Preot¸iuc-Pietro, Sina Samangooei, Trevor
Cohn, Nicholas Gibbins, and Mahesan Niranjan.
2012. Trendminer: An Architecture for Real Time
Analysis of Social Media Text. In Sixth Interna-
tional AAAI Conference on Weblogs and Social Me-
dia, pages 38–42. AAAI Press, July.
Ignacio Quesada and Ignacio E Grossmann. 1995. A
global optimization algorithm for linear fractional
and bilinear programs. Journal of Global Optimiza-
tion, 6(1):39–76, January.
Takeshi Sakaki, Makoto Okazaki, and Yutaka Matsuo.
2010. Earthquake shakes Twitter users: real-time
event detection by social sensors. In Proceedings
of the 19th international conference on World Wide
Web (WWW), pages 851–860. ACM.
Robert Tibshirani. 1996. Regression shrinkage and se-
lection via the lasso. Journal of the Royal Statistical
Society - Series B (Methodological), 58(1):267–288.
</reference>
<page confidence="0.863103">
1002
</page>
<reference confidence="0.999573411764706">
Andranik Tumasjan, Timm O Sprenger, Philipp G
Sandner, and Isabell M Welpe. 2010. Predicting
elections with Twitter: What 140 characters reveal
about political sentiment. In Proceedings of the 4th
International AAAI Conference on Weblogs and So-
cial Media, pages 178–185. AAAI.
Ming Yuan and Yi Lin. 2006. Model selection and es-
timation in regression with grouped variables. Jour-
nal of the Royal Statistical Society - Series B: Statis-
tical Methodology, 68(1):49–67.
Peng Zhao and Bin Yu. 2006. On model selection
consistency of Lasso. Journal of Machine Learning
Research, 7(11):2541–2563.
Hui Zou and Trevor Hastie. 2005. Regularization
and variable selection via the elastic net. Journal
of the Royal Statistical Society: Series B (Statistical
Methodology), 67(2):301–320, April.
</reference>
<page confidence="0.966669">
1003
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.812851">
<title confidence="0.913136">A user-centric model of voting intention from Social Media</title>
<author confidence="0.842565">Daniel Lampos</author>
<affiliation confidence="0.999879">Computer Science University of Sheffield,</affiliation>
<abstract confidence="0.9994005">Social Media contain a multitude of user opinions which can be used to predict realworld phenomena in many domains including politics, finance and health. Most existing methods treat these problems as linear regression, learning to relate word frequencies and other simple features to known response variable voting intention polls or financial indicators). These techniques require very careful filtering of the input texts, as most Social Media posts are irrelevant to the task. In this paper, we present a novel approach which performs high quality filtering automatically, through modelling not just words but also users, framed as a bilinear model with a sparse regulariser. We also consider the problem of modelling groups of related output variables, using a structured multi-task regularisation method. Our experiments on voting intention prediction demonstrate strong performance over large-scale input from Twitter on two distinct case studies, outperforming competitive baselines.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Faiz A Al-Khayyal</author>
<author>James E Falk</author>
</authors>
<date>1983</date>
<journal>Jointly Constrained Biconvex Programming. Mathematics of Operations Research,</journal>
<volume>8</volume>
<issue>2</issue>
<contexts>
<context position="11703" citStr="Al-Khayyal and Falk, 1983" startWordPosition="1959" endWordPosition="1962">possibility of overfitting and enhance the interpretability of the inferred model (Hastie et al., 2009). The elastic net applies an extra penalty on the `2-norm of the weight vector, and can resolve instability issues of LASSO which arise when correlated predictors exist in the input data (Zhao and Yu, 2006). Its regularisation function ψel(·) is defined by: C1 − α / ψel (w,λ,α) = λ 2 �w�2 2 + α�w�1 , (3) where λ &gt; 0 and α E [0, 1); setting parameter α to its extremes transforms elastic net to ridge regression (α = 0) or vanilla LASSO (α = 1). Eq. 2 can be treated as a biconvex learning task (Al-Khayyal and Falk, 1983), by observing that for a fixed w, learning u is a convex problem and vice versa. Biconvex functions and possible applications have been well studied in the optimisation literature (Quesada and Grossmann, 1995; 4Note that other loss functions could be used here, such as logistic loss for classification, or more generally bilinear variations of Generalised Linear Models (Nelder and Wedderburn, 1972). 995 Pirsiavash et al., 2009). Their main advantage is the ability to solve efficiently non-convex problems by a repeated application of two convex processes, i.e., a form of coordinate ascent. In o</context>
</contexts>
<marker>Al-Khayyal, Falk, 1983</marker>
<rawString>Faiz A Al-Khayyal and James E Falk. 1983. Jointly Constrained Biconvex Programming. Mathematics of Operations Research, 8(2):273–286.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Argyriou</author>
<author>Theodoros Evgeniou</author>
<author>Massimiliano Pontil</author>
</authors>
<title>Convex multi-task feature learning.</title>
<date>2008</date>
<booktitle>Machine Learning,</booktitle>
<volume>73</volume>
<issue>3</issue>
<contexts>
<context position="17249" citStr="Argyriou et al., 2008" startWordPosition="2941" endWordPosition="2944"> domain is defined by a specific political label or party. Ideally, we would like to make a sparse selection of words and users but with a regulariser that promotes inter-task sharing of structure, so that many features may have a positive influence towards one or more parties, but negative towards the remaining one(s). It is possible to achieve this multi-task learning property by introducing a different set of regularisation constraints in the optimisation function. We perform multi-task learning using an extension of group LASSO (Yuan and Lin, 2006), a method known as `1/`2 regularisation (Argyriou et al., 2008; Liu et al., 2009). Group LASSO exploits a predefined group structure on the feature space and tries to achieve sparsity in the group-level, i.e., it does not perform feature selection (unlike the elastic net), but group selection. The `1/`2 regulariser extends this notion for a τ-dimensional response variable. The global optimisation target is now formulated as: {W*, U*,β*1 = argmin �τ n (ut 2iwt + βt − yti 2 (9) W,U,β t=1 i=1 ) + λ1 �m lWjl2 + λ2 � p lUkl2, j=1 k=1 where the input matrix 2i is defined in the same way as earlier, W = [w1 ... wτ] is the term weight matrix (each wt refers to t</context>
</contexts>
<marker>Argyriou, Evgeniou, Pontil, 2008</marker>
<rawString>Andreas Argyriou, Theodoros Evgeniou, and Massimiliano Pontil. 2008. Convex multi-task feature learning. Machine Learning, 73(3):243–272, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Bermingham</author>
<author>Alan F Smeaton</author>
</authors>
<title>On using Twitter to monitor political sentiment and predict election results.</title>
<date>2011</date>
<booktitle>In Proceedings of the Workshop on Sentiment Analysis where AI meets Psychology (SAAIP 2011),</booktitle>
<pages>2--10</pages>
<contexts>
<context position="31807" citStr="Bermingham and Smeaton, 2011" startWordPosition="5476" endWordPosition="5479">tweets, it may be useful to know that ‘Johannes Voggenhuber’ (who receives a positive comment for his book) and ‘Peter Pilz’ (whose comment is questioned) are members of GR ¨U, ‘Krone’ (or Kronen Zeitung) is the major newspaper in Austria10 and that FP O¨ is labelled as a far right party, something that may cause various reactions from ‘Human Rights’ organisations. 5 Related Work The topic of political opinion mining from Social Media has been the focus of various recent research works. Several papers have presented methods that aim to predict the result of an election (Tumasjan et al., 2010; Bermingham and Smeaton, 2011) or to model voting intention and other kinds of socio-political polls (O’Connor et al., 2010; Lampos, 2012). Their common feature is a methodology based on a meta-analysis of word frequencies using off-the-shelf sentiment tools such as LIWC (Pennebaker et al., 2007) or Senti-WordNet (Esuli and Sebastiani, 2006). Moreover, the proposed techniques tend to incorporate posting volume figures as well as handcrafted lists of words relevant to the task (e.g., names of politicians or parties) in order to filter the content successfully. Such papers have been criticised as their methods do not general</context>
</contexts>
<marker>Bermingham, Smeaton, 2011</marker>
<rawString>Adam Bermingham and Alan F Smeaton. 2011. On using Twitter to monitor political sentiment and predict election results. In Proceedings of the Workshop on Sentiment Analysis where AI meets Psychology (SAAIP 2011), pages 2–10, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bollen</author>
<author>Huina Mao</author>
<author>Xiaojun Zeng</author>
</authors>
<title>Twitter mood predicts the stock market.</title>
<date>2011</date>
<journal>Journal of Computational Science,</journal>
<volume>2</volume>
<issue>1</issue>
<contexts>
<context position="1884" citStr="Bollen et al., 2011" startWordPosition="279" endWordPosition="282">orms have ushered a new era in human interaction and communication. The main by-product of this activity is vast amounts of user-generated content, a type of information that has already attracted the interest of both marketeers and scientists because it offers – for the first time at a large-scale – unmediated access to peoples’ observations and opinions. One exciting avenue of research concentrates on mining interesting signals automatically from this stream of text input. For example, by exploiting Twitter posts, it is possible to infer time series that correlate with financial indicators (Bollen et al., 2011), track infectious diseases (Lampos and Cristianini, 2010; Lampos et al., 2010; Paul and Dredze, 2011) and, in general, nowcast the magnitude of events emerging in real-life (Sakaki et al., 2010; Lampos and Cristianini, 2012). Other studies suggest ways for modelling opinions encapsulated in this content in order to forge branding strategies (Jansen et al., 2009) or understand various socio-political trends (Tumasjan et al., 2010; O’Connor et al., 2010; Lansdall-Welfare et al., 2012). The main theme of the aforementioned works is linear regression between word frequencies and a real-world quan</context>
</contexts>
<marker>Bollen, Mao, Zeng, 2011</marker>
<rawString>Johan Bollen, Huina Mao, and Xiaojun Zeng. 2011. Twitter mood predicts the stock market. Journal of Computational Science, 2(1):1–8, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>SentiWordNet: A publicly available lexical resource for opinion mining.</title>
<date>2006</date>
<booktitle>In Proceeding of the 5th Conference on Language Resources and Evaluation (LREC),</booktitle>
<pages>417--422</pages>
<contexts>
<context position="32120" citStr="Esuli and Sebastiani, 2006" startWordPosition="5524" endWordPosition="5527">various reactions from ‘Human Rights’ organisations. 5 Related Work The topic of political opinion mining from Social Media has been the focus of various recent research works. Several papers have presented methods that aim to predict the result of an election (Tumasjan et al., 2010; Bermingham and Smeaton, 2011) or to model voting intention and other kinds of socio-political polls (O’Connor et al., 2010; Lampos, 2012). Their common feature is a methodology based on a meta-analysis of word frequencies using off-the-shelf sentiment tools such as LIWC (Pennebaker et al., 2007) or Senti-WordNet (Esuli and Sebastiani, 2006). Moreover, the proposed techniques tend to incorporate posting volume figures as well as handcrafted lists of words relevant to the task (e.g., names of politicians or parties) in order to filter the content successfully. Such papers have been criticised as their methods do not generalise when applied on different data sets. According to the work in (Gayo-Avello et al., 2011), the methods presented in (Tumasjan et al., 2010) and (O’Connor et al., 2010) failed to predict the result of US congressional elections in 2009. We disagree with the arguments supporting the statement “you cannot predic</context>
</contexts>
<marker>Esuli, Sebastiani, 2006</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2006. SentiWordNet: A publicly available lexical resource for opinion mining. In Proceeding of the 5th Conference on Language Resources and Evaluation (LREC), pages 417–422.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gayo-Avello</author>
<author>Panagiotis T Metaxas</author>
<author>Eni Mustafaraj</author>
</authors>
<title>Limits of Electoral Predictions using Twitter.</title>
<date>2011</date>
<booktitle>In Proceedings of the Fifth International AAAI Conference on Weblogs and Social Media (ICWSM),</booktitle>
<pages>490--493</pages>
<contexts>
<context position="2797" citStr="Gayo-Avello et al., 2011" startWordPosition="420" endWordPosition="423">d in this content in order to forge branding strategies (Jansen et al., 2009) or understand various socio-political trends (Tumasjan et al., 2010; O’Connor et al., 2010; Lansdall-Welfare et al., 2012). The main theme of the aforementioned works is linear regression between word frequencies and a real-world quantity. They also tend to incorporate hand-crafted lists of search terms to filter irrelevant content and use sentiment analysis lexicons for extracting opinion bias. Consequently, they are quite often restricted to a specific application and therefore, generalise poorly to new data sets (Gayo-Avello et al., 2011). In this paper, we propose a generic method that aims to be independent of the characteristics described above (use of search terms or sentiment analysis tools). Our approach is able to explore not only word frequencies, but also the space of users by introducing a bilinear formulation for this learning task. Regularised regression on both spaces allows for an automatic selection of the most important terms and users, performing at the same time an improved noise filtering. In addition, more advanced regularisation functions enable multi-task learning schemes that can exploit shared structure</context>
<context position="32499" citStr="Gayo-Avello et al., 2011" startWordPosition="5587" endWordPosition="5590">lls (O’Connor et al., 2010; Lampos, 2012). Their common feature is a methodology based on a meta-analysis of word frequencies using off-the-shelf sentiment tools such as LIWC (Pennebaker et al., 2007) or Senti-WordNet (Esuli and Sebastiani, 2006). Moreover, the proposed techniques tend to incorporate posting volume figures as well as handcrafted lists of words relevant to the task (e.g., names of politicians or parties) in order to filter the content successfully. Such papers have been criticised as their methods do not generalise when applied on different data sets. According to the work in (Gayo-Avello et al., 2011), the methods presented in (Tumasjan et al., 2010) and (O’Connor et al., 2010) failed to predict the result of US congressional elections in 2009. We disagree with the arguments supporting the statement “you cannot predict elections with Twitter” (Gayo-Avello, 2012), as many times in the past actual voting intention polls have also failed to predict election outcomes, but we agree that most methods that have been proposed so far were not entirely generic. It is a fact that the 10“Accused of abusing its near monopoly to manipulate public opinion in Austria”, Wikipedia, 19/02/2013, http: //en.wi</context>
</contexts>
<marker>Gayo-Avello, Metaxas, Mustafaraj, 2011</marker>
<rawString>Daniel Gayo-Avello, Panagiotis T Metaxas, and Eni Mustafaraj. 2011. Limits of Electoral Predictions using Twitter. In Proceedings of the Fifth International AAAI Conference on Weblogs and Social Media (ICWSM), pages 490–493.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gayo-Avello</author>
</authors>
<title>No, You Cannot Predict Elections with Twitter.</title>
<date>2012</date>
<journal>IEEE Internet Computing,</journal>
<volume>16</volume>
<issue>6</issue>
<contexts>
<context position="32765" citStr="Gayo-Avello, 2012" startWordPosition="5630" endWordPosition="5631">chniques tend to incorporate posting volume figures as well as handcrafted lists of words relevant to the task (e.g., names of politicians or parties) in order to filter the content successfully. Such papers have been criticised as their methods do not generalise when applied on different data sets. According to the work in (Gayo-Avello et al., 2011), the methods presented in (Tumasjan et al., 2010) and (O’Connor et al., 2010) failed to predict the result of US congressional elections in 2009. We disagree with the arguments supporting the statement “you cannot predict elections with Twitter” (Gayo-Avello, 2012), as many times in the past actual voting intention polls have also failed to predict election outcomes, but we agree that most methods that have been proposed so far were not entirely generic. It is a fact that the 10“Accused of abusing its near monopoly to manipulate public opinion in Austria”, Wikipedia, 19/02/2013, http: //en.wikipedia.org/wiki/Kronen_Zeitung. majority of sentiment analysis tools are Englishspecific (or even American English) and, most importantly, political word lists (or ontologies) change in time, per country and per party; hence, generalisable methods should make an ef</context>
</contexts>
<marker>Gayo-Avello, 2012</marker>
<rawString>Daniel Gayo-Avello. 2012. No, You Cannot Predict Elections with Twitter. IEEE Internet Computing, 16(6):91–94, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trevor Hastie</author>
<author>Robert Tibshirani</author>
<author>Jerome Friedman</author>
</authors>
<date>2009</date>
<booktitle>The Elements of Statistical Learning. Springer Series in Statistics.</booktitle>
<publisher>Springer.</publisher>
<contexts>
<context position="11180" citStr="Hastie et al., 2009" startWordPosition="1857" endWordPosition="1860">ion with parameters ρ1 or ρ2. The first term in Eq. 2 is the standard regularisation loss function, namely the sum squared error over the training instances.4 In the main formulation of our bilinear model, as the regularisation function ψ(·) we use the elastic net (Zou and Hastie, 2005), an extension of the well-studied `1-norm regulariser, known as the LASSO (Tibshirani, 1996). The `1-norm regularisation has found many applications in several scientific fields as it encourages sparse solutions which reduce the possibility of overfitting and enhance the interpretability of the inferred model (Hastie et al., 2009). The elastic net applies an extra penalty on the `2-norm of the weight vector, and can resolve instability issues of LASSO which arise when correlated predictors exist in the input data (Zhao and Yu, 2006). Its regularisation function ψel(·) is defined by: C1 − α / ψel (w,λ,α) = λ 2 �w�2 2 + α�w�1 , (3) where λ &gt; 0 and α E [0, 1); setting parameter α to its extremes transforms elastic net to ridge regression (α = 0) or vanilla LASSO (α = 1). Eq. 2 can be treated as a biconvex learning task (Al-Khayyal and Falk, 1983), by observing that for a fixed w, learning u is a convex problem and vice ve</context>
</contexts>
<marker>Hastie, Tibshirani, Friedman, 2009</marker>
<rawString>Trevor Hastie, Robert Tibshirani, and Jerome Friedman. 2009. The Elements of Statistical Learning. Springer Series in Statistics. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernard J Jansen</author>
<author>Mimi Zhang</author>
<author>Kate Sobel</author>
<author>Abdur Chowdury</author>
</authors>
<title>Twitter power: Tweets as electronic word of mouth.</title>
<date>2009</date>
<journal>Journal of the American Society for Information Science and Technology,</journal>
<volume>60</volume>
<issue>11</issue>
<contexts>
<context position="2249" citStr="Jansen et al., 2009" startWordPosition="337" endWordPosition="340">citing avenue of research concentrates on mining interesting signals automatically from this stream of text input. For example, by exploiting Twitter posts, it is possible to infer time series that correlate with financial indicators (Bollen et al., 2011), track infectious diseases (Lampos and Cristianini, 2010; Lampos et al., 2010; Paul and Dredze, 2011) and, in general, nowcast the magnitude of events emerging in real-life (Sakaki et al., 2010; Lampos and Cristianini, 2012). Other studies suggest ways for modelling opinions encapsulated in this content in order to forge branding strategies (Jansen et al., 2009) or understand various socio-political trends (Tumasjan et al., 2010; O’Connor et al., 2010; Lansdall-Welfare et al., 2012). The main theme of the aforementioned works is linear regression between word frequencies and a real-world quantity. They also tend to incorporate hand-crafted lists of search terms to filter irrelevant content and use sentiment analysis lexicons for extracting opinion bias. Consequently, they are quite often restricted to a specific application and therefore, generalise poorly to new data sets (Gayo-Avello et al., 2011). In this paper, we propose a generic method that ai</context>
</contexts>
<marker>Jansen, Zhang, Sobel, Chowdury, 2009</marker>
<rawString>Bernard J Jansen, Mimi Zhang, Kate Sobel, and Abdur Chowdury. 2009. Twitter power: Tweets as electronic word of mouth. Journal of the American Society for Information Science and Technology, 60(11):2169–2188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Lampos</author>
<author>Nello Cristianini</author>
</authors>
<title>Tracking the flu pandemic by monitoring the Social Web.</title>
<date>2010</date>
<booktitle>In 2nd IAPR Workshop on Cognitive Information Processing,</booktitle>
<pages>411--416</pages>
<publisher>IEEE Press.</publisher>
<contexts>
<context position="1941" citStr="Lampos and Cristianini, 2010" startWordPosition="286" endWordPosition="289">and communication. The main by-product of this activity is vast amounts of user-generated content, a type of information that has already attracted the interest of both marketeers and scientists because it offers – for the first time at a large-scale – unmediated access to peoples’ observations and opinions. One exciting avenue of research concentrates on mining interesting signals automatically from this stream of text input. For example, by exploiting Twitter posts, it is possible to infer time series that correlate with financial indicators (Bollen et al., 2011), track infectious diseases (Lampos and Cristianini, 2010; Lampos et al., 2010; Paul and Dredze, 2011) and, in general, nowcast the magnitude of events emerging in real-life (Sakaki et al., 2010; Lampos and Cristianini, 2012). Other studies suggest ways for modelling opinions encapsulated in this content in order to forge branding strategies (Jansen et al., 2009) or understand various socio-political trends (Tumasjan et al., 2010; O’Connor et al., 2010; Lansdall-Welfare et al., 2012). The main theme of the aforementioned works is linear regression between word frequencies and a real-world quantity. They also tend to incorporate hand-crafted lists of</context>
</contexts>
<marker>Lampos, Cristianini, 2010</marker>
<rawString>Vasileios Lampos and Nello Cristianini. 2010. Tracking the flu pandemic by monitoring the Social Web. In 2nd IAPR Workshop on Cognitive Information Processing, pages 411–416. IEEE Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Lampos</author>
<author>Nello Cristianini</author>
</authors>
<title>Nowcasting Events from the Social Web with Statistical Learning.</title>
<date>2012</date>
<journal>ACM Transactions on Intelligent Systems and Technology,</journal>
<volume>3</volume>
<issue>4</issue>
<contexts>
<context position="2109" citStr="Lampos and Cristianini, 2012" startWordPosition="314" endWordPosition="317">h marketeers and scientists because it offers – for the first time at a large-scale – unmediated access to peoples’ observations and opinions. One exciting avenue of research concentrates on mining interesting signals automatically from this stream of text input. For example, by exploiting Twitter posts, it is possible to infer time series that correlate with financial indicators (Bollen et al., 2011), track infectious diseases (Lampos and Cristianini, 2010; Lampos et al., 2010; Paul and Dredze, 2011) and, in general, nowcast the magnitude of events emerging in real-life (Sakaki et al., 2010; Lampos and Cristianini, 2012). Other studies suggest ways for modelling opinions encapsulated in this content in order to forge branding strategies (Jansen et al., 2009) or understand various socio-political trends (Tumasjan et al., 2010; O’Connor et al., 2010; Lansdall-Welfare et al., 2012). The main theme of the aforementioned works is linear regression between word frequencies and a real-world quantity. They also tend to incorporate hand-crafted lists of search terms to filter irrelevant content and use sentiment analysis lexicons for extracting opinion bias. Consequently, they are quite often restricted to a specific </context>
</contexts>
<marker>Lampos, Cristianini, 2012</marker>
<rawString>Vasileios Lampos and Nello Cristianini. 2012. Nowcasting Events from the Social Web with Statistical Learning. ACM Transactions on Intelligent Systems and Technology, 3(4):1–22, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Lampos</author>
<author>Tijl De Bie</author>
<author>Nello Cristianini</author>
</authors>
<title>Flu Detector - Tracking Epidemics on Twitter.</title>
<date>2010</date>
<booktitle>In Proceedings of European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD),</booktitle>
<pages>599--602</pages>
<publisher>Springer.</publisher>
<marker>Lampos, De Bie, Cristianini, 2010</marker>
<rawString>Vasileios Lampos, Tijl De Bie, and Nello Cristianini. 2010. Flu Detector - Tracking Epidemics on Twitter. In Proceedings of European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD), pages 599– 602. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Lampos</author>
</authors>
<title>On voting intentions inference from Twitter content: a case study on UK</title>
<date>2012</date>
<location>CoRR,</location>
<contexts>
<context position="31915" citStr="Lampos, 2012" startWordPosition="5495" endWordPosition="5496"> (whose comment is questioned) are members of GR ¨U, ‘Krone’ (or Kronen Zeitung) is the major newspaper in Austria10 and that FP O¨ is labelled as a far right party, something that may cause various reactions from ‘Human Rights’ organisations. 5 Related Work The topic of political opinion mining from Social Media has been the focus of various recent research works. Several papers have presented methods that aim to predict the result of an election (Tumasjan et al., 2010; Bermingham and Smeaton, 2011) or to model voting intention and other kinds of socio-political polls (O’Connor et al., 2010; Lampos, 2012). Their common feature is a methodology based on a meta-analysis of word frequencies using off-the-shelf sentiment tools such as LIWC (Pennebaker et al., 2007) or Senti-WordNet (Esuli and Sebastiani, 2006). Moreover, the proposed techniques tend to incorporate posting volume figures as well as handcrafted lists of words relevant to the task (e.g., names of politicians or parties) in order to filter the content successfully. Such papers have been criticised as their methods do not generalise when applied on different data sets. According to the work in (Gayo-Avello et al., 2011), the methods pr</context>
</contexts>
<marker>Lampos, 2012</marker>
<rawString>Vasileios Lampos. 2012. On voting intentions inference from Twitter content: a case study on UK 2010 General Election. CoRR, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Lansdall-Welfare</author>
<author>Vasileios Lampos</author>
<author>Nello Cristianini</author>
</authors>
<title>Effects of the recession on public mood in the UK.</title>
<date>2012</date>
<booktitle>In Proceedings of the 21st international conference companion on World Wide Web, WWW ’12 Companion,</booktitle>
<pages>1221--1226</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2372" citStr="Lansdall-Welfare et al., 2012" startWordPosition="355" endWordPosition="358">. For example, by exploiting Twitter posts, it is possible to infer time series that correlate with financial indicators (Bollen et al., 2011), track infectious diseases (Lampos and Cristianini, 2010; Lampos et al., 2010; Paul and Dredze, 2011) and, in general, nowcast the magnitude of events emerging in real-life (Sakaki et al., 2010; Lampos and Cristianini, 2012). Other studies suggest ways for modelling opinions encapsulated in this content in order to forge branding strategies (Jansen et al., 2009) or understand various socio-political trends (Tumasjan et al., 2010; O’Connor et al., 2010; Lansdall-Welfare et al., 2012). The main theme of the aforementioned works is linear regression between word frequencies and a real-world quantity. They also tend to incorporate hand-crafted lists of search terms to filter irrelevant content and use sentiment analysis lexicons for extracting opinion bias. Consequently, they are quite often restricted to a specific application and therefore, generalise poorly to new data sets (Gayo-Avello et al., 2011). In this paper, we propose a generic method that aims to be independent of the characteristics described above (use of search terms or sentiment analysis tools). Our approach</context>
</contexts>
<marker>Lansdall-Welfare, Lampos, Cristianini, 2012</marker>
<rawString>Thomas Lansdall-Welfare, Vasileios Lampos, and Nello Cristianini. 2012. Effects of the recession on public mood in the UK. In Proceedings of the 21st international conference companion on World Wide Web, WWW ’12 Companion, pages 1221– 1226. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Liu</author>
<author>Shuiwang Ji</author>
<author>Jieping Ye</author>
</authors>
<title>Multitask feature learning via efficient l2,1-norm minimization.</title>
<date>2009</date>
<pages>339--348</pages>
<contexts>
<context position="17268" citStr="Liu et al., 2009" startWordPosition="2945" endWordPosition="2948"> specific political label or party. Ideally, we would like to make a sparse selection of words and users but with a regulariser that promotes inter-task sharing of structure, so that many features may have a positive influence towards one or more parties, but negative towards the remaining one(s). It is possible to achieve this multi-task learning property by introducing a different set of regularisation constraints in the optimisation function. We perform multi-task learning using an extension of group LASSO (Yuan and Lin, 2006), a method known as `1/`2 regularisation (Argyriou et al., 2008; Liu et al., 2009). Group LASSO exploits a predefined group structure on the feature space and tries to achieve sparsity in the group-level, i.e., it does not perform feature selection (unlike the elastic net), but group selection. The `1/`2 regulariser extends this notion for a τ-dimensional response variable. The global optimisation target is now formulated as: {W*, U*,β*1 = argmin �τ n (ut 2iwt + βt − yti 2 (9) W,U,β t=1 i=1 ) + λ1 �m lWjl2 + λ2 � p lUkl2, j=1 k=1 where the input matrix 2i is defined in the same way as earlier, W = [w1 ... wτ] is the term weight matrix (each wt refers to the t-th political e</context>
</contexts>
<marker>Liu, Ji, Ye, 2009</marker>
<rawString>Jun Liu, Shuiwang Ji, and Jieping Ye. 2009. Multitask feature learning via efficient l2,1-norm minimization. pages 339–348, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Panagiotis T Metaxas</author>
<author>Eni Mustafaraj</author>
<author>Daniel Gayo-Avello</author>
</authors>
<title>How (Not) To Predict Elections.</title>
<date>2011</date>
<booktitle>In IEEE 3rd International Conference on Social Computing (SocialCom),</booktitle>
<pages>165--171</pages>
<publisher>IEEE Press.</publisher>
<contexts>
<context position="33497" citStr="Metaxas et al., 2011" startWordPosition="5739" endWordPosition="5742"> agree that most methods that have been proposed so far were not entirely generic. It is a fact that the 10“Accused of abusing its near monopoly to manipulate public opinion in Austria”, Wikipedia, 19/02/2013, http: //en.wikipedia.org/wiki/Kronen_Zeitung. majority of sentiment analysis tools are Englishspecific (or even American English) and, most importantly, political word lists (or ontologies) change in time, per country and per party; hence, generalisable methods should make an effort to limit reliance from such tools. Furthermore, our work – indirectly – meets the guidelines proposed in (Metaxas et al., 2011) as we have developed a framework of “well-defined” algorithms that are “Social Web aware” (since the bilinear approach aims to improve noise filtering) and that have been tested on two evaluation scenarios with distinct characteristics. 6 Conclusions and Future Work We have presented a novel method for text regression that exploits both word and user spaces by solving a bilinear optimisation task, and an extension that applies multi-task learning for multioutput inference. Our approach performs feature selection – hence, noise filtering – on large-scale user-generated inputs automatically, ge</context>
</contexts>
<marker>Metaxas, Mustafaraj, Gayo-Avello, 2011</marker>
<rawString>Panagiotis T Metaxas, Eni Mustafaraj, and Daniel Gayo-Avello. 2011. How (Not) To Predict Elections. In IEEE 3rd International Conference on Social Computing (SocialCom), pages 165 – 171. IEEE Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John A Nelder</author>
<author>Robert W M Wedderburn</author>
</authors>
<title>Generalized Linear Models.</title>
<date>1972</date>
<journal>Journal of the Royal Statistical Society - Series A (General),</journal>
<volume>135</volume>
<issue>3</issue>
<contexts>
<context position="12104" citStr="Nelder and Wedderburn, 1972" startWordPosition="2022" endWordPosition="2026">w�1 , (3) where λ &gt; 0 and α E [0, 1); setting parameter α to its extremes transforms elastic net to ridge regression (α = 0) or vanilla LASSO (α = 1). Eq. 2 can be treated as a biconvex learning task (Al-Khayyal and Falk, 1983), by observing that for a fixed w, learning u is a convex problem and vice versa. Biconvex functions and possible applications have been well studied in the optimisation literature (Quesada and Grossmann, 1995; 4Note that other loss functions could be used here, such as logistic loss for classification, or more generally bilinear variations of Generalised Linear Models (Nelder and Wedderburn, 1972). 995 Pirsiavash et al., 2009). Their main advantage is the ability to solve efficiently non-convex problems by a repeated application of two convex processes, i.e., a form of coordinate ascent. In our case, the bilinear technique makes it possible to explore both word and user spaces, while maintaining a modest training complexity. Therefore, in our bilinear approach we divide learning in two phases, where we learn word and user weights respectively. For the first phase we produce the term-scores matrix V ∈ Rn×m with elements given by: uzQijz. (4) V contains weighted sums of term frequencies </context>
</contexts>
<marker>Nelder, Wedderburn, 1972</marker>
<rawString>John A Nelder and Robert W M Wedderburn. 1972. Generalized Linear Models. Journal of the Royal Statistical Society - Series A (General), 135(3):370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brendan O’Connor</author>
<author>Ramnath Balasubramanyan</author>
<author>Bryan R Routledge</author>
<author>Noah A Smith</author>
</authors>
<title>From Tweets to Polls: Linking Text Sentiment to Public Opinion Time Series.</title>
<date>2010</date>
<booktitle>In Proceedings of the International AAAI Conference on Weblogs and Social Media,</booktitle>
<pages>122--129</pages>
<publisher>AAAI Press.</publisher>
<marker>O’Connor, Balasubramanyan, Routledge, Smith, 2010</marker>
<rawString>Brendan O’Connor, Ramnath Balasubramanyan, Bryan R Routledge, and Noah A Smith. 2010. From Tweets to Polls: Linking Text Sentiment to Public Opinion Time Series. In Proceedings of the International AAAI Conference on Weblogs and Social Media, pages 122–129. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael J Paul</author>
<author>Mark Dredze</author>
</authors>
<title>You Are What You Tweet: Analyzing Twitter for Public Health.</title>
<date>2011</date>
<booktitle>Proceedings of the 5th International AAAI Conference on Weblogs and Social Media,</booktitle>
<pages>265--272</pages>
<contexts>
<context position="1986" citStr="Paul and Dredze, 2011" startWordPosition="294" endWordPosition="297">vity is vast amounts of user-generated content, a type of information that has already attracted the interest of both marketeers and scientists because it offers – for the first time at a large-scale – unmediated access to peoples’ observations and opinions. One exciting avenue of research concentrates on mining interesting signals automatically from this stream of text input. For example, by exploiting Twitter posts, it is possible to infer time series that correlate with financial indicators (Bollen et al., 2011), track infectious diseases (Lampos and Cristianini, 2010; Lampos et al., 2010; Paul and Dredze, 2011) and, in general, nowcast the magnitude of events emerging in real-life (Sakaki et al., 2010; Lampos and Cristianini, 2012). Other studies suggest ways for modelling opinions encapsulated in this content in order to forge branding strategies (Jansen et al., 2009) or understand various socio-political trends (Tumasjan et al., 2010; O’Connor et al., 2010; Lansdall-Welfare et al., 2012). The main theme of the aforementioned works is linear regression between word frequencies and a real-world quantity. They also tend to incorporate hand-crafted lists of search terms to filter irrelevant content an</context>
</contexts>
<marker>Paul, Dredze, 2011</marker>
<rawString>Michael J Paul and Mark Dredze. 2011. You Are What You Tweet: Analyzing Twitter for Public Health. Proceedings of the 5th International AAAI Conference on Weblogs and Social Media, pages 265–272.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James W Pennebaker</author>
<author>Cindy K Chung</author>
<author>Molly Ireland</author>
<author>Amy Gonzales</author>
<author>Roger J Booth</author>
</authors>
<title>The Development and Psychometric Properties of LIWC2007.</title>
<date>2007</date>
<tech>Technical report,</tech>
<institution>Universities of Texas at Austin &amp; University of Auckland,</institution>
<location>New Zealand.</location>
<contexts>
<context position="32074" citStr="Pennebaker et al., 2007" startWordPosition="5518" endWordPosition="5521"> far right party, something that may cause various reactions from ‘Human Rights’ organisations. 5 Related Work The topic of political opinion mining from Social Media has been the focus of various recent research works. Several papers have presented methods that aim to predict the result of an election (Tumasjan et al., 2010; Bermingham and Smeaton, 2011) or to model voting intention and other kinds of socio-political polls (O’Connor et al., 2010; Lampos, 2012). Their common feature is a methodology based on a meta-analysis of word frequencies using off-the-shelf sentiment tools such as LIWC (Pennebaker et al., 2007) or Senti-WordNet (Esuli and Sebastiani, 2006). Moreover, the proposed techniques tend to incorporate posting volume figures as well as handcrafted lists of words relevant to the task (e.g., names of politicians or parties) in order to filter the content successfully. Such papers have been criticised as their methods do not generalise when applied on different data sets. According to the work in (Gayo-Avello et al., 2011), the methods presented in (Tumasjan et al., 2010) and (O’Connor et al., 2010) failed to predict the result of US congressional elections in 2009. We disagree with the argumen</context>
</contexts>
<marker>Pennebaker, Chung, Ireland, Gonzales, Booth, 2007</marker>
<rawString>James W Pennebaker, Cindy K Chung, Molly Ireland, Amy Gonzales, and Roger J Booth. 2007. The Development and Psychometric Properties of LIWC2007. Technical report, Universities of Texas at Austin &amp; University of Auckland, New Zealand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hamed Pirsiavash</author>
<author>Deva Ramanan</author>
<author>Charless Fowlkes</author>
</authors>
<title>Bilinear classifiers for visual recognition.</title>
<date>2009</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<volume>22</volume>
<pages>1482--1490</pages>
<contexts>
<context position="12134" citStr="Pirsiavash et al., 2009" startWordPosition="2028" endWordPosition="2031">1); setting parameter α to its extremes transforms elastic net to ridge regression (α = 0) or vanilla LASSO (α = 1). Eq. 2 can be treated as a biconvex learning task (Al-Khayyal and Falk, 1983), by observing that for a fixed w, learning u is a convex problem and vice versa. Biconvex functions and possible applications have been well studied in the optimisation literature (Quesada and Grossmann, 1995; 4Note that other loss functions could be used here, such as logistic loss for classification, or more generally bilinear variations of Generalised Linear Models (Nelder and Wedderburn, 1972). 995 Pirsiavash et al., 2009). Their main advantage is the ability to solve efficiently non-convex problems by a repeated application of two convex processes, i.e., a form of coordinate ascent. In our case, the bilinear technique makes it possible to explore both word and user spaces, while maintaining a modest training complexity. Therefore, in our bilinear approach we divide learning in two phases, where we learn word and user weights respectively. For the first phase we produce the term-scores matrix V ∈ Rn×m with elements given by: uzQijz. (4) V contains weighted sums of term frequencies over all users for the conside</context>
</contexts>
<marker>Pirsiavash, Ramanan, Fowlkes, 2009</marker>
<rawString>Hamed Pirsiavash, Deva Ramanan, and Charless Fowlkes. 2009. Bilinear classifiers for visual recognition. In Advances in Neural Information Processing Systems, volume 22, pages 1482–1490.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Preot¸iuc-Pietro</author>
<author>Sina Samangooei</author>
<author>Trevor Cohn</author>
<author>Nicholas Gibbins</author>
<author>Mahesan Niranjan</author>
</authors>
<title>Trendminer: An Architecture for Real Time Analysis of Social Media Text.</title>
<date>2012</date>
<booktitle>In Sixth International AAAI Conference on Weblogs and Social Media,</booktitle>
<pages>38--42</pages>
<publisher>AAAI Press,</publisher>
<marker>Preot¸iuc-Pietro, Samangooei, Cohn, Gibbins, Niranjan, 2012</marker>
<rawString>Daniel Preot¸iuc-Pietro, Sina Samangooei, Trevor Cohn, Nicholas Gibbins, and Mahesan Niranjan. 2012. Trendminer: An Architecture for Real Time Analysis of Social Media Text. In Sixth International AAAI Conference on Weblogs and Social Media, pages 38–42. AAAI Press, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ignacio Quesada</author>
<author>Ignacio E Grossmann</author>
</authors>
<title>A global optimization algorithm for linear fractional and bilinear programs.</title>
<date>1995</date>
<journal>Journal of Global Optimization,</journal>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="11912" citStr="Quesada and Grossmann, 1995" startWordPosition="1994" endWordPosition="1997">ty issues of LASSO which arise when correlated predictors exist in the input data (Zhao and Yu, 2006). Its regularisation function ψel(·) is defined by: C1 − α / ψel (w,λ,α) = λ 2 �w�2 2 + α�w�1 , (3) where λ &gt; 0 and α E [0, 1); setting parameter α to its extremes transforms elastic net to ridge regression (α = 0) or vanilla LASSO (α = 1). Eq. 2 can be treated as a biconvex learning task (Al-Khayyal and Falk, 1983), by observing that for a fixed w, learning u is a convex problem and vice versa. Biconvex functions and possible applications have been well studied in the optimisation literature (Quesada and Grossmann, 1995; 4Note that other loss functions could be used here, such as logistic loss for classification, or more generally bilinear variations of Generalised Linear Models (Nelder and Wedderburn, 1972). 995 Pirsiavash et al., 2009). Their main advantage is the ability to solve efficiently non-convex problems by a repeated application of two convex processes, i.e., a form of coordinate ascent. In our case, the bilinear technique makes it possible to explore both word and user spaces, while maintaining a modest training complexity. Therefore, in our bilinear approach we divide learning in two phases, whe</context>
</contexts>
<marker>Quesada, Grossmann, 1995</marker>
<rawString>Ignacio Quesada and Ignacio E Grossmann. 1995. A global optimization algorithm for linear fractional and bilinear programs. Journal of Global Optimization, 6(1):39–76, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takeshi Sakaki</author>
<author>Makoto Okazaki</author>
<author>Yutaka Matsuo</author>
</authors>
<title>Earthquake shakes Twitter users: real-time event detection by social sensors.</title>
<date>2010</date>
<booktitle>In Proceedings of the 19th international conference on World Wide Web (WWW),</booktitle>
<pages>851--860</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2078" citStr="Sakaki et al., 2010" startWordPosition="310" endWordPosition="313">d the interest of both marketeers and scientists because it offers – for the first time at a large-scale – unmediated access to peoples’ observations and opinions. One exciting avenue of research concentrates on mining interesting signals automatically from this stream of text input. For example, by exploiting Twitter posts, it is possible to infer time series that correlate with financial indicators (Bollen et al., 2011), track infectious diseases (Lampos and Cristianini, 2010; Lampos et al., 2010; Paul and Dredze, 2011) and, in general, nowcast the magnitude of events emerging in real-life (Sakaki et al., 2010; Lampos and Cristianini, 2012). Other studies suggest ways for modelling opinions encapsulated in this content in order to forge branding strategies (Jansen et al., 2009) or understand various socio-political trends (Tumasjan et al., 2010; O’Connor et al., 2010; Lansdall-Welfare et al., 2012). The main theme of the aforementioned works is linear regression between word frequencies and a real-world quantity. They also tend to incorporate hand-crafted lists of search terms to filter irrelevant content and use sentiment analysis lexicons for extracting opinion bias. Consequently, they are quite </context>
</contexts>
<marker>Sakaki, Okazaki, Matsuo, 2010</marker>
<rawString>Takeshi Sakaki, Makoto Okazaki, and Yutaka Matsuo. 2010. Earthquake shakes Twitter users: real-time event detection by social sensors. In Proceedings of the 19th international conference on World Wide Web (WWW), pages 851–860. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Tibshirani</author>
</authors>
<title>Regression shrinkage and selection via the lasso.</title>
<date>1996</date>
<journal>Journal of the Royal Statistical Society - Series B (Methodological),</journal>
<volume>58</volume>
<issue>1</issue>
<contexts>
<context position="10940" citStr="Tibshirani, 1996" startWordPosition="1823" endWordPosition="1824"> ψ(w,ρ1) + ψ(u,ρ2), (2) where y E Rn is the response variable (voting intention), w E Rm and u E Rp denote the term and user weights respectively, uTQiw expresses the bilinear term, β E R is a bias term and ψ(·) is a regularisation function with parameters ρ1 or ρ2. The first term in Eq. 2 is the standard regularisation loss function, namely the sum squared error over the training instances.4 In the main formulation of our bilinear model, as the regularisation function ψ(·) we use the elastic net (Zou and Hastie, 2005), an extension of the well-studied `1-norm regulariser, known as the LASSO (Tibshirani, 1996). The `1-norm regularisation has found many applications in several scientific fields as it encourages sparse solutions which reduce the possibility of overfitting and enhance the interpretability of the inferred model (Hastie et al., 2009). The elastic net applies an extra penalty on the `2-norm of the weight vector, and can resolve instability issues of LASSO which arise when correlated predictors exist in the input data (Zhao and Yu, 2006). Its regularisation function ψel(·) is defined by: C1 − α / ψel (w,λ,α) = λ 2 �w�2 2 + α�w�1 , (3) where λ &gt; 0 and α E [0, 1); setting parameter α to its</context>
</contexts>
<marker>Tibshirani, 1996</marker>
<rawString>Robert Tibshirani. 1996. Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society - Series B (Methodological), 58(1):267–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andranik Tumasjan</author>
<author>Timm O Sprenger</author>
<author>Philipp G Sandner</author>
<author>Isabell M Welpe</author>
</authors>
<title>Predicting elections with Twitter: What 140 characters reveal about political sentiment.</title>
<date>2010</date>
<booktitle>In Proceedings of the 4th International AAAI Conference on Weblogs and Social Media,</booktitle>
<pages>178--185</pages>
<publisher>AAAI.</publisher>
<contexts>
<context position="2317" citStr="Tumasjan et al., 2010" startWordPosition="347" endWordPosition="350">s automatically from this stream of text input. For example, by exploiting Twitter posts, it is possible to infer time series that correlate with financial indicators (Bollen et al., 2011), track infectious diseases (Lampos and Cristianini, 2010; Lampos et al., 2010; Paul and Dredze, 2011) and, in general, nowcast the magnitude of events emerging in real-life (Sakaki et al., 2010; Lampos and Cristianini, 2012). Other studies suggest ways for modelling opinions encapsulated in this content in order to forge branding strategies (Jansen et al., 2009) or understand various socio-political trends (Tumasjan et al., 2010; O’Connor et al., 2010; Lansdall-Welfare et al., 2012). The main theme of the aforementioned works is linear regression between word frequencies and a real-world quantity. They also tend to incorporate hand-crafted lists of search terms to filter irrelevant content and use sentiment analysis lexicons for extracting opinion bias. Consequently, they are quite often restricted to a specific application and therefore, generalise poorly to new data sets (Gayo-Avello et al., 2011). In this paper, we propose a generic method that aims to be independent of the characteristics described above (use of </context>
<context position="31776" citStr="Tumasjan et al., 2010" startWordPosition="5472" endWordPosition="5475">ation of the presented tweets, it may be useful to know that ‘Johannes Voggenhuber’ (who receives a positive comment for his book) and ‘Peter Pilz’ (whose comment is questioned) are members of GR ¨U, ‘Krone’ (or Kronen Zeitung) is the major newspaper in Austria10 and that FP O¨ is labelled as a far right party, something that may cause various reactions from ‘Human Rights’ organisations. 5 Related Work The topic of political opinion mining from Social Media has been the focus of various recent research works. Several papers have presented methods that aim to predict the result of an election (Tumasjan et al., 2010; Bermingham and Smeaton, 2011) or to model voting intention and other kinds of socio-political polls (O’Connor et al., 2010; Lampos, 2012). Their common feature is a methodology based on a meta-analysis of word frequencies using off-the-shelf sentiment tools such as LIWC (Pennebaker et al., 2007) or Senti-WordNet (Esuli and Sebastiani, 2006). Moreover, the proposed techniques tend to incorporate posting volume figures as well as handcrafted lists of words relevant to the task (e.g., names of politicians or parties) in order to filter the content successfully. Such papers have been criticised </context>
</contexts>
<marker>Tumasjan, Sprenger, Sandner, Welpe, 2010</marker>
<rawString>Andranik Tumasjan, Timm O Sprenger, Philipp G Sandner, and Isabell M Welpe. 2010. Predicting elections with Twitter: What 140 characters reveal about political sentiment. In Proceedings of the 4th International AAAI Conference on Weblogs and Social Media, pages 178–185. AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ming Yuan</author>
<author>Yi Lin</author>
</authors>
<title>Model selection and estimation in regression with grouped variables.</title>
<date>2006</date>
<journal>Journal of the Royal Statistical Society - Series B: Statistical Methodology,</journal>
<volume>68</volume>
<issue>1</issue>
<contexts>
<context position="17186" citStr="Yuan and Lin, 2006" startWordPosition="2931" endWordPosition="2934">nships across the different task domains; in our case, a task domain is defined by a specific political label or party. Ideally, we would like to make a sparse selection of words and users but with a regulariser that promotes inter-task sharing of structure, so that many features may have a positive influence towards one or more parties, but negative towards the remaining one(s). It is possible to achieve this multi-task learning property by introducing a different set of regularisation constraints in the optimisation function. We perform multi-task learning using an extension of group LASSO (Yuan and Lin, 2006), a method known as `1/`2 regularisation (Argyriou et al., 2008; Liu et al., 2009). Group LASSO exploits a predefined group structure on the feature space and tries to achieve sparsity in the group-level, i.e., it does not perform feature selection (unlike the elastic net), but group selection. The `1/`2 regulariser extends this notion for a τ-dimensional response variable. The global optimisation target is now formulated as: {W*, U*,β*1 = argmin �τ n (ut 2iwt + βt − yti 2 (9) W,U,β t=1 i=1 ) + λ1 �m lWjl2 + λ2 � p lUkl2, j=1 k=1 where the input matrix 2i is defined in the same way as earlier,</context>
</contexts>
<marker>Yuan, Lin, 2006</marker>
<rawString>Ming Yuan and Yi Lin. 2006. Model selection and estimation in regression with grouped variables. Journal of the Royal Statistical Society - Series B: Statistical Methodology, 68(1):49–67.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peng Zhao</author>
<author>Bin Yu</author>
</authors>
<title>On model selection consistency of Lasso.</title>
<date>2006</date>
<journal>Journal of Machine Learning Research,</journal>
<volume>7</volume>
<issue>11</issue>
<contexts>
<context position="11386" citStr="Zhao and Yu, 2006" startWordPosition="1892" endWordPosition="1895"> the regularisation function ψ(·) we use the elastic net (Zou and Hastie, 2005), an extension of the well-studied `1-norm regulariser, known as the LASSO (Tibshirani, 1996). The `1-norm regularisation has found many applications in several scientific fields as it encourages sparse solutions which reduce the possibility of overfitting and enhance the interpretability of the inferred model (Hastie et al., 2009). The elastic net applies an extra penalty on the `2-norm of the weight vector, and can resolve instability issues of LASSO which arise when correlated predictors exist in the input data (Zhao and Yu, 2006). Its regularisation function ψel(·) is defined by: C1 − α / ψel (w,λ,α) = λ 2 �w�2 2 + α�w�1 , (3) where λ &gt; 0 and α E [0, 1); setting parameter α to its extremes transforms elastic net to ridge regression (α = 0) or vanilla LASSO (α = 1). Eq. 2 can be treated as a biconvex learning task (Al-Khayyal and Falk, 1983), by observing that for a fixed w, learning u is a convex problem and vice versa. Biconvex functions and possible applications have been well studied in the optimisation literature (Quesada and Grossmann, 1995; 4Note that other loss functions could be used here, such as logistic los</context>
</contexts>
<marker>Zhao, Yu, 2006</marker>
<rawString>Peng Zhao and Bin Yu. 2006. On model selection consistency of Lasso. Journal of Machine Learning Research, 7(11):2541–2563.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hui Zou</author>
<author>Trevor Hastie</author>
</authors>
<title>Regularization and variable selection via the elastic net.</title>
<date>2005</date>
<journal>Journal of the Royal Statistical Society: Series B (Statistical Methodology),</journal>
<volume>67</volume>
<issue>2</issue>
<contexts>
<context position="10847" citStr="Zou and Hastie, 2005" startWordPosition="1808" endWordPosition="1811"> formulate our optimisation task as follows: n {w*,u*, β*} = argmin (uTQiw + β − yi)2 w,u,β i=1 + ψ(w,ρ1) + ψ(u,ρ2), (2) where y E Rn is the response variable (voting intention), w E Rm and u E Rp denote the term and user weights respectively, uTQiw expresses the bilinear term, β E R is a bias term and ψ(·) is a regularisation function with parameters ρ1 or ρ2. The first term in Eq. 2 is the standard regularisation loss function, namely the sum squared error over the training instances.4 In the main formulation of our bilinear model, as the regularisation function ψ(·) we use the elastic net (Zou and Hastie, 2005), an extension of the well-studied `1-norm regulariser, known as the LASSO (Tibshirani, 1996). The `1-norm regularisation has found many applications in several scientific fields as it encourages sparse solutions which reduce the possibility of overfitting and enhance the interpretability of the inferred model (Hastie et al., 2009). The elastic net applies an extra penalty on the `2-norm of the weight vector, and can resolve instability issues of LASSO which arise when correlated predictors exist in the input data (Zhao and Yu, 2006). Its regularisation function ψel(·) is defined by: C1 − α / </context>
</contexts>
<marker>Zou, Hastie, 2005</marker>
<rawString>Hui Zou and Trevor Hastie. 2005. Regularization and variable selection via the elastic net. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 67(2):301–320, April.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>