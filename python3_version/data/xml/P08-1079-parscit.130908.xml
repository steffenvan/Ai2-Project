<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.011939">
<title confidence="0.996888">
Unsupervised Discovery of Generic Relationships Using Pattern Clusters
and its Evaluation by Automatically Generated SAT Analogy Questions
</title>
<author confidence="0.992126">
Dmitry Davidov Ari Rappoport
</author>
<affiliation confidence="0.999632">
ICNC Institute of Computer Science
Hebrew University of Jerusalem Hebrew University of Jerusalem
</affiliation>
<email confidence="0.99068">
dmitry@alice.nc.huji.ac.il arir@cs.huji.ac.il
</email>
<sectionHeader confidence="0.995508" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99997615">
We present a novel framework for the dis-
covery and representation of general semantic
relationships that hold between lexical items.
We propose that each such relationship can be
identified with a cluster of patterns that cap-
tures this relationship. We give a fully unsu-
pervised algorithm for pattern cluster discov-
ery, which searches, clusters and merges high-
frequency words-based patterns around ran-
domly selected hook words. Pattern clusters
can be used to extract instances of the corre-
sponding relationships. To assess the quality
of discovered relationships, we use the pattern
clusters to automatically generate SAT anal-
ogy questions. We also compare to a set of
known relationships, achieving very good re-
sults in both methods. The evaluation (done
in both English and Russian) substantiates the
premise that our pattern clusters indeed reflect
relationships perceived by humans.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99994197826087">
Semantic resources can be very useful in many NLP
tasks. Manual construction of such resources is la-
bor intensive and susceptible to arbitrary human de-
cisions. In addition, manually constructed semantic
databases are not easily portable across text domains
or languages. Hence, there is a need for developing
semantic acquisition algorithms that are as unsuper-
vised and language independent as possible.
A fundamental type of semantic resource is that
of concepts (represented by sets of lexical items)
and their inter-relationships. While there is rel-
atively good agreement as to what concepts are
and which concepts should exist in a lexical re-
source, identifying types of important lexical rela-
tionships is a rather difficult task. Most established
resources (e.g., WordNet) represent only the main
and widely accepted relationships such as hyper-
nymy and meronymy. However, there are many
other useful relationships between concepts, such as
noun-modifier and inter-verb relationships. Identi-
fying and representing these explicitly can greatly
assist various tasks and applications. There are al-
ready applications that utilize such knowledge (e.g.,
(Tatu and Moldovan, 2005) for textual entailment).
One of the leading methods in semantics acqui-
sition is based on patterns (see e.g., (Hearst, 1992;
Pantel and Pennacchiotti, 2006)). The standard pro-
cess for pattern-based relation extraction is to start
with hand-selected patterns or word pairs express-
ing a particular relationship, and iteratively scan
the corpus for co-appearances of word pairs in pat-
terns and for patterns that contain known word pairs.
This methodology is semi-supervised, requiring pre-
specification of the desired relationship or hand-
coding initial seed words or patterns. The method
is quite successful, and examining its results in de-
tail shows that concept relationships are often being
manifested by several different patterns.
In this paper, unlike the majority of studies that
use patterns in order to find instances of given rela-
tionships, we use sets of patterns as the definitions
of lexical relationships. We introduce pattern clus-
ters, a novel framework in which each cluster cor-
responds to a relationship that can hold between the
lexical items that fill its patterns’ slots. We present
a fully unsupervised algorithm to compute pat-
</bodyText>
<page confidence="0.970421">
692
</page>
<note confidence="0.715722">
Proceedings of ACL-08: HLT, pages 692–700,
</note>
<page confidence="0.537942">
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</page>
<bodyText confidence="0.978250957446808">
tern clusters, not requiring any, even implicit, pre-
specification of relationship types or word/pattern
seeds. Our algorithm does not utilize preprocess-
ing such as POS tagging and parsing. Some patterns
may be present in several clusters, thus indirectly ad-
dressing pattern ambiguity.
The algorithm is comprised of the following
stages. First, we randomly select hook words and
create a context corpus (hook corpus) for each hook
word. Second, we define a meta-pattern using high
frequency words and punctuation. Third, in each
hook corpus, we use the meta-pattern to discover
concrete patterns and target words co-appearing
with the hook word. Fourth, we cluster the patterns
in each corpus according to co-appearance of the tar-
get words. Finally, we merge clusters from different
hook corpora to produce the final structure. We also
propose a way to label each cluster by word pairs
that represent it best.
Since we are dealing with relationships that are
unspecified in advance, assessing the quality of the
resulting pattern clusters is non-trivial. Our evalu-
ation uses two methods: SAT tests, and compari-
son to known relationships. We used instances of
the discovered relationships to automatically gener-
ate analogy SAT tests in two languages, English and
Russian1. Human subjects answered these and real
SAT tests. English grades were 80% for our test and
71% for the real test (83% and 79% for Russian),
showing that our relationship definitions indeed re-
flect human notions of relationship similarity. In ad-
dition, we show that among our pattern clusters there
are clusters that cover major known noun-compound
and verb-verb relationships.
In the present paper we focus on the pattern clus-
ter resource itself and how to evaluate its intrinsic
quality. In (Davidov and Rappoport, 2008) we show
how to use the resource for a known task of a to-
tally different nature, classification of relationships
between nominals (based on annotated data), obtain-
ing superior results over previous work.
Section 2 discusses related work, and Section 3
presents the pattern clustering and labeling algo-
rithm. Section 4 describes the corpora we used and
the algorithm’s parameters in detail. Sections 5 and
1Turney and Littman (2005) automatically answers SAT
tests, while our focus is on generating them.
</bodyText>
<sectionHeader confidence="0.7612205" genericHeader="introduction">
6 present SAT and comparison evaluation results.
2 Related Work
</sectionHeader>
<bodyText confidence="0.999838833333333">
Extraction of relation information from text is a
large sub-field in NLP. Major differences between
pattern approaches include the relationship types
sought (including domain restrictions), the degrees
of supervision and required preprocessing, and eval-
uation method.
</bodyText>
<subsectionHeader confidence="0.980513">
2.1 Relationship Types
</subsectionHeader>
<bodyText confidence="0.999844214285714">
There is a large body of related work that deals with
discovery of basic relationship types represented in
useful resources such as WordNet, including hyper-
nymy (Hearst, 1992; Pantel et al., 2004; Snow
et al., 2006), synonymy (Davidov and Rappoport,
2006; Widdows and Dorow, 2002) and meronymy
(Berland and Charniak, 1999; Girju et al., 2006).
Since named entities are very important in NLP,
many studies define and discover relations between
named entities (Hasegawa et al., 2004; Hassan et
al., 2006). Work was also done on relations be-
tween verbs (Chklovski and Pantel, 2004). There
is growing research on relations between nominals
(Moldovan et al., 2004; Girju et al., 2007).
</bodyText>
<subsectionHeader confidence="0.999866">
2.2 Degree of Supervision and Preprocessing
</subsectionHeader>
<bodyText confidence="0.999030761904762">
While numerous studies attempt to discover one or
more pre-specified relationship types, very little pre-
vious work has directly attempted the discovery of
which main types of generic relationships actually
exist in an unrestricted domain. Turney (2006) pro-
vided a pattern distance measure that allows a fully
unsupervised measurement of relational similarity
between two pairs of words; such a measure could
in principle be used by a clustering algorithm in or-
der to deduce relationship types, but this was not
discussed. Unlike (Turney, 2006), we do not per-
form any pattern ranking. Instead we produce (pos-
sibly overlapping) hard clusters, where each pattern
cluster represents a relationship discovered in the
domain. Banko et al. (2007) and Rosenfeld and
Feldman (2007) find relationship instances where
the relationships are not specified in advance. They
aim to find relationship instances rather than iden-
tify generic semantic relationships. Thus, their rep-
resentation is very different from ours. In addition,
(Banko et al., 2007) utilize supervised tools such
</bodyText>
<page confidence="0.998739">
693
</page>
<bodyText confidence="0.9998560625">
as a POS tagger and a shallow parser. Davidov et
al. (2007) proposed a method for unsupervised dis-
covery of concept-specific relations. That work, like
ours, relies on pattern clusters. However, it requires
initial word seeds and targets the discovery of rela-
tionships specific for some given concept, while we
attempt to discover and define generic relationships
that exist in the entire domain.
Studying relationships between tagged named en-
tities, (Hasegawa et al., 2004; Hassan et al., 2006)
proposed unsupervised clustering methods that as-
sign given sets of pairs into several clusters, where
each cluster corresponds to one of a known set of re-
lationship types. Their classification setting is thus
very different from our unsupervised discovery one.
Several recent papers discovered relations on the
web using seed patterns (Pantel et al., 2004), rules
(Etzioni et al., 2004), and word pairs (Pasca et al.,
2006; Alfonseca et al., 2006). The latter used the
notion of hook which we also use in this paper.
Several studies utilize some preprocessing, includ-
ing parsing (Hasegawa et al., 2004; Hassan et al.,
2006) and usage of syntactic (Suchanek et al., 2006)
and morphological (Pantel et al., 2004) informa-
tion in patterns. Several algorithms use manually-
prepared resources, including WordNet (Moldovan
et al., 2004; Costello et al., 2006) and Wikipedia
(Strube and Ponzetto, 2006). In this paper, we
do not utilize any language-specific preprocessing
or any other resources, which makes our algorithm
relatively easily portable between languages, as we
demonstrate in our bilingual evaluation.
</bodyText>
<subsectionHeader confidence="0.998151">
2.3 Evaluation Method
</subsectionHeader>
<bodyText confidence="0.999922785714286">
Evaluation for hypernymy and synonymy usually
uses WordNet (Lin and Pantel, 2002; Widdows and
Dorow, 2002; Davidov and Rappoport, 2006). For
more specific lexical relationships like relationships
between verbs (Chklovski and Pantel, 2004), nom-
inals (Girju et al., 2004; Girju et al., 2007) or
meronymy subtypes (Berland and Charniak, 1999)
there is still little agreement which important rela-
tionships should be defined. Thus, there are more
than a dozen different type hierarchies and tasks pro-
posed for noun compounds (and nominals in gen-
eral), including (Nastase and Szpakowicz, 2003;
Girju et al., 2005; Girju et al., 2007).
There are thus two possible ways for a fair eval-
uation. A study can develop its own relationship
definitions and dataset, like (Nastase and Szpakow-
icz, 2003), thus introducing a possible bias; or it
can accept the definition and dataset prepared by
another work, like (Turney, 2006). However, this
makes it impossible to work on new relationship
types. Hence, when exploring very specific relation-
ship types or very generic, but not widely accepted,
types (like verb strength), many researchers resort
to manual human-based evaluation (Chklovski and
Pantel, 2004). In our case, where relationship types
are not specified in advance, creating an unbiased
benchmark is very problematic, so we rely on hu-
man subjects for relationship evaluation.
</bodyText>
<sectionHeader confidence="0.992116" genericHeader="method">
3 Pattern Clustering Algorithm
</sectionHeader>
<bodyText confidence="0.999981555555556">
Our algorithm first discovers and clusters patterns in
which a single (‘hook’) word participates, and then
merges the resulting clusters to form the final struc-
ture. In this section we detail the algorithm. The
algorithm utilizes several parameters, whose selec-
tion is detailed in Section 4. We refer to a pattern
contained in our clusters (a pattern type) as a ‘pat-
tern’ and to an occurrence of a pattern in the corpus
(a pattern token) as a ‘pattern instance’.
</bodyText>
<subsectionHeader confidence="0.999855">
3.1 Hook Words and Hook Corpora
</subsectionHeader>
<bodyText confidence="0.9999019">
As a first step, we randomly select a set of hook
words. Hook words were used in e.g. (Alfonseca
et al., 2006) for extracting general relations starting
from given seed word pairs. Unlike most previous
work, our hook words are not provided in advance
but selected randomly; the goal in those papers is
to discover relationships between given word pairs,
while we use hook words in order to discover rela-
tionships that generally occur in the corpus.
Only patterns in which a hook word actually par-
ticipates will eventually be discovered. Hence, in
principle we should select as many hook words as
possible. However, words whose frequency is very
high are usually ambiguous and are likely to produce
patterns that are too noisy, so we do not select words
with frequency higher than a parameter FC. In ad-
dition, we do not select words whose frequency is
below a threshold FB, to avoid selection of typos
and other noise that frequently appear on the web.
We also limit the total number N of hook words.
</bodyText>
<page confidence="0.99472">
694
</page>
<bodyText confidence="0.999815551724138">
Our algorithm merges clusters originating from dif-
ferent hook words. Using too many hook words in-
creases the chance that some of them belong to a
noisy part in the corpus and thus lowers the quality
of our resulting clusters.
For each hook word, we now create a hook cor-
pus, the set of the contexts in which the word ap-
pears. Each context is a window containing W
words or punctuation characters before and after the
hook word. We avoid extracting text from clearly
unformatted sentences and our contexts do not cross
paragraph boundaries.
The size of each hook corpus is much smaller than
that of the whole corpus, easily fitting into main
memory; the corpus of a hook word occurring h
times in the corpus contains at most 2hW words.
Since most operations are done on each hook corpus
separately, computation is very efficient.
Note that such context corpora can in principle be
extracted by focused querying on the web, making
the system dynamically scalable. It is also possi-
ble to restrict selection of hook words to a specific
domain or word type, if we want to discover only
a desired subset of existing relationships. Thus we
could sample hook words from nouns, verbs, proper
names, or names of chemical compounds if we are
only interested in discovering relationships between
these. Selecting hook words randomly allows us to
avoid using any language-specific data at this step.
</bodyText>
<subsectionHeader confidence="0.999567">
3.2 Pattern Specification
</subsectionHeader>
<bodyText confidence="0.991331857142857">
In order to reduce noise and to make the computa-
tion more efficient, we did not consider all contexts
of a hook word as pattern candidates, only contexts
that are instances of a specified meta-pattern type.
Following (Davidov and Rappoport, 2006), we clas-
sified words into high-frequency words (HFWs) and
content words (CWs). A word whose frequency is
more (less) than FH (FC) is considered to be a HFW
(CW). Unlike (Davidov and Rappoport, 2006), we
consider all punctuation characters as HFWs. Our
patterns have the general form
[Prefix] CW1 [Infix] CW2 [Postfix]
where Prefix, Infix and Postfix contain only HFWs.
To reduce the chance of catching CWZ’s that are
parts of a multiword expression, we require Prefix
and Postfix to have at least one word (HFW), while
Infix is allowed to contain any number of HFWs (but
recall that the total length of a pattern is limited by
window size). A pattern example is ‘such X as Y
and’. During this stage we only allow single words
to be in CW slots2.
</bodyText>
<subsectionHeader confidence="0.998489">
3.3 Discovery of Target Words
</subsectionHeader>
<bodyText confidence="0.999968">
For each of the hook corpora, we now extract all
pattern instances where one CW slot contains the
hook word and the other CW slot contains some
other (‘target’) word. To avoid the selection of com-
mon words as target words, and to avoid targets ap-
pearing in pattern instances that are relatively fixed
multiword expressions, we sort all target words in
a given hook corpus by pointwise mutual informa-
tion between hook and target, and drop patterns ob-
tained from pattern instances containing the lowest
and highest L percent of target words.
</bodyText>
<subsectionHeader confidence="0.93492">
3.4 Local Pattern Clustering
</subsectionHeader>
<bodyText confidence="0.999930583333333">
We now have for each hook corpus a set of patterns.
All of the corresponding pattern instances share the
hook word, and some of them also share a target
word. We cluster patterns in a two-stage process.
First, we group in clusters all patterns whose in-
stances share the same target word, and ignore the
rest. For each target word we have a single pattern
cluster. Second, we merge clusters that share more
than 5 percent of their patterns. A pattern can ap-
pear in more than a single cluster. Note that clusters
contain pattern types, obtained through examining
pattern instances.
</bodyText>
<subsectionHeader confidence="0.928461">
3.5 Global Cluster Merging
</subsectionHeader>
<bodyText confidence="0.99945">
The purpose of this stage is to create clusters of pat-
terns that express generic relationships rather than
ones specific to a single hook word. In addition,
the technique used in this stage reduces noise. For
each created cluster we will define core patterns and
unconfirmed patterns, which are weighed differently
during cluster labeling (see Section 3.6). We merge
clusters from different hook corpora using the fol-
lowing algorithm:
</bodyText>
<footnote confidence="0.9368164">
1. Remove all patterns originating from a single hook
corpus.
2While for pattern clusters creation we use only single words
as CWs, later during evaluation we allow multiword expressions
in CW slots of previously acquired patterns.
</footnote>
<page confidence="0.994269">
695
</page>
<figure confidence="0.995056857142857">
2. Mark all patterns of all present clusters as uncon-
firmed.
3. While there exists some cluster C1 from corpus DX
containing only unconfirmed patterns:
(a) Select a cluster with a minimal number of pat-
terns.
(b) For each corpus D different from DX:
</figure>
<figureCaption confidence="0.793256777777778">
i. Scan D for clusters C2 that share at least
S percent of their patterns, and all of their
core patterns, with C1.
ii. Add all patterns of C2 to C1, setting all
shared patterns as core and all others as
unconfirmed.
iii. Remove cluster C2.
(c) If all of C1’s patterns remain unconfirmed re-
move C1.
</figureCaption>
<bodyText confidence="0.971351444444444">
4. If several clusters have the same set of core patterns
merge them according to rules (i,ii).
We start from the smallest clusters because we ex-
pect these to be more precise; the best patterns for
semantic acquisition are those that belong to small
clusters, and appear in many different clusters. At
the end of this algorithm, we have a set of pattern
clusters where for each cluster there are two subsets,
core patterns and unconfirmed patterns.
</bodyText>
<subsectionHeader confidence="0.999795">
3.6 Labeling of Pattern Clusters
</subsectionHeader>
<bodyText confidence="0.9992636">
To label pattern clusters we define a HITS measure
that reflects the affinity of a given word pair to a
given cluster. For a given word pair (w1, w2) and
cluster C with n core patterns Pcore and m uncon-
firmed patterns Punconf,
</bodyText>
<equation confidence="0.978157333333333">
Hits(C, (w1, w2)) _
|{p; (w1, w2) appears in p E Pcore} |/n+
α x |{p; (w1, w2) appears in p E Punconf} |/m.
</equation>
<bodyText confidence="0.999978">
In this formula, ‘appears in’ means that the word
pair appears in instances of this pattern extracted
from the original corpus or retrieved from the web
during evaluation (see Section 5.2). Thus if some
pair appears in most of patterns of some cluster it
receives a high HITS value for this cluster. The top
5 pairs for each cluster are selected as its labels.
α E (0..1) is a parameter that lets us modify the
relative weight of core and unconfirmed patterns.
</bodyText>
<sectionHeader confidence="0.98451" genericHeader="method">
4 Corpora and Parameters
</sectionHeader>
<bodyText confidence="0.996354333333333">
In this section we describe our experimental setup,
and discuss in detail the effect of each of the algo-
rithms’ parameters.
</bodyText>
<subsectionHeader confidence="0.990927">
4.1 Languages and Corpora
</subsectionHeader>
<bodyText confidence="0.999936833333333">
The evaluation was done using corpora in English
and Russian. The English corpus (Gabrilovich and
Markovitch, 2005) was obtained through crawling
the URLs in the Open Directory Project (dmoz.org).
It contains about 8.2G words and its size is about
68GB of untagged plain text. The Russian corpus
was collected over the web, comprising a variety of
domains, including news, web pages, forums, nov-
els and scientific papers. It contains 7.5G words of
size 55GB untagged plain text. Aside from remov-
ing noise and sentence duplicates, we did not apply
any text preprocessing or tagging.
</bodyText>
<subsectionHeader confidence="0.952714">
4.2 Parameters
</subsectionHeader>
<bodyText confidence="0.99999215625">
Our algorithm uses the following parameters: FC,
FH, FB, W, N, L, S and α. We used part of the
Russian corpus as a development set for determin-
ing the parameters. On our development set we have
tested various parameter settings. A detailed analy-
sis of the involved parameters is beyond the scope
of this paper; below we briefly discuss the observed
qualitative effects of parameter selection. Naturally,
the parameters are not mutually independent.
FC (upper bound for content word frequency in
patterns) influences which words are considered as
hook and target words. More ambiguous words gen-
erally have higher frequency. Since content words
determine the joining of patterns into clusters, the
more ambiguous a word is, the noisier the result-
ing clusters. Thus, higher values of FC allow more
ambiguous words, increasing cluster recall but also
increasing cluster noise, while lower ones increase
cluster precision at the expense of recall.
FH (lower bound for HFW frequency in patterns)
influences the specificity of patterns. Higher val-
ues restrict our patterns to be based upon the few
most common HFWs (like ‘the’, ‘of’, ‘and’) and
thus yield patterns that are very generic. Lowering
the values, we obtain increasing amounts of pattern
clusters for more specific relationships. The value
we use for FH is lower than that used for FC, in or-
der to allow as HFWs function words of relatively
low frequency (e.g., ‘through’), while allowing as
content words some frequent words that participate
in meaningful relationships (e.g., ‘game’). However,
this way we may also introduce more noise.
</bodyText>
<page confidence="0.998123">
696
</page>
<bodyText confidence="0.998327325">
FB (lower bound for hook words) filters hook
words that do not appear enough times in the cor-
pus. We have found that this parameter is essential
for removing typos and other words that do not qual-
ify as hook words.
N (number of hook words) influences relation-
ship coverage. With higher N values we discover
more relationships roughly of the same specificity
level, but computation becomes less efficient and
more noise is introduced.
W (window size) determines the length of the dis-
covered patterns. Lower values are more efficient
computationally, but values that are too low result in
drastic decrease in coverage. Higher values would
be more useful when we allow our algorithm to sup-
port multiword expressions as hooks and targets.
L (target word mutual information filter) helps in
avoiding using as targets common words that are
unrelated to hooks, while still catching as targets
frequent words that are related. Low L values de-
crease pattern precision, allowing patterns like ‘give
Xplease Y more’, where X is the hook (e.g., ‘Alex’)
and Y the target (e.g., ‘some’). High values increase
pattern precision at the expense of recall.
5 (minimal overlap for cluster merging) is a clus-
ters merge filter. Higher values cause more strict
merging, producing smaller but more precise clus-
ters, while lower values start introducing noise. In
extreme cases, low values can start a chain reaction
of total merging.
α (core vs. unconfirmed weight for HITS labeling)
allows lower quality patterns to complement higher
quality ones during labeling. Higher values increase
label noise, while lower ones effectively ignore un-
confirmed patterns during labeling.
In our experiments we have used the following
values (again, determined using a development set)
for these parameters: FC: 1, 000 words per mil-
lion (wpm); FH: 100 wpm; FB: 1.2 wpm; N: 500
words; W: 5 words; L: 30%; 5: 2/3; α: 0.1.
</bodyText>
<sectionHeader confidence="0.997579" genericHeader="method">
5 SAT-based Evaluation
</sectionHeader>
<bodyText confidence="0.999971684210526">
As discussed in Section 2, the evaluation of semantic
relationship structures is non-trivial. The goal of our
evaluation was to assess whether pattern clusters in-
deed represent meaningful, precise and different re-
lationships. There are two complementary perspec-
tives that a pattern clusters quality assessment needs
to address. The first is the quality (precision/recall)
of individual pattern clusters: does each pattern clus-
ter capture lexical item pairs of the same semantic
relationship? does it recognize many pairs of the
same semantic relationship? The second is the qual-
ity of the cluster set as whole: does the pattern clus-
ters set allow identification of important known se-
mantic relationships? do several pattern clusters de-
scribe the same relationship?
Manually examining the resulting pattern clus-
ters, we saw that the majority of sampled clusters in-
deed clearly express an interesting specific relation-
ship. Examples include familiar hypernymy clusters
such as3 {‘such X as Y’, ‘X such as Y’, ‘Y and other
X’,} with label (pets, dogs), and much more specific
clusters like { ‘buy Y accessory for X!’, ‘shipping Y
for X’, ‘Y is available for X’, ‘Y are available for X’,
‘Y are available for X systems’, ‘Yfor X’ }, labeled
by (phone, charger). Some clusters contain overlap-
ping patterns, like ‘Y for X’, but represent different
relationships when examined as a whole.
We addressed the evaluation questions above us-
ing a SAT-like analogy test automatically generated
from word pairs captured by our clusters (see below
in this section). In addition, we tested coverage and
overlap of pattern clusters with a set of 35 known re-
lationships, and we compared our patterns to those
found useful by other algorithms (the next section).
Quantitatively, the final number of clusters is 508
(470) for English (Russian), and the average cluster
size is 5.5 (6.1) pattern types. 55% of the clusters
had no overlap with other clusters.
</bodyText>
<subsectionHeader confidence="0.99756">
5.1 SAT Analogy Choice Test
</subsectionHeader>
<bodyText confidence="0.999990454545455">
Our main evaluation method, which is also a use-
ful application by itself, uses our pattern clusters to
automatically generate SAT analogy questions. The
questions were answered by human subjects.
We randomly selected 15 clusters. This allowed
us to assess the precision of the whole cluster set as
well as of the internal coherence of separate clus-
ters (see below). For each cluster, we constructed
a SAT analogy question in the following manner.
The header of the question is a word pair that is one
of the label pairs of the cluster. The five multiple
</bodyText>
<footnote confidence="0.980533">
3For readability, we omit punctuations in Prefix and Postfix.
</footnote>
<page confidence="0.996106">
697
</page>
<bodyText confidence="0.999962866666667">
choice items include: (1) another label of the clus-
ter (the ‘correct’ answer); (2) three labels of other
clusters among the 15; and (3) a pair constructed by
randomly selecting words from those making up the
various cluster labels.
In our sample there were no word pairs assigned
as labels to more than one cluster4. As a baseline for
comparison, we have mixed these questions with 15
real SAT questions taken from English and Russian
SAT analogy tests. In addition, we have also asked
our subjects to write down one example pair of the
same relationship for each question in the test.
As an example, from one of the 15 clusters we
have randomly selected the label (glass, water). The
correct answer selected from the same cluster was
(schoolbag, book). The three pairs randomly se-
lected from the other 14 clusters were (war, death),
(request, license) and (mouse, cat). The pair ran-
domly selected from a cluster not among the 15 clus-
ters was (milk, drink). Among the subjects’ propos-
als for this question were (closet, clothes) and (wal-
let, money).
We computed accuracy of SAT answers, and the
correlation between answers for our questions and
the real ones (Table 1). Three things are demon-
strated about our system when humans are capable
of selecting the correct answer. First, our clusters
are internally coherent in the sense of expressing a
certain relationship, because people identified that
the pairs in the question header and in the correct
answer exhibit the same relationship. Second, our
clusters distinguish between different relationships,
because the three pairs not expressing the same rela-
tionship as the header were not selected by the evalu-
ators. Third, our cluster labeling algorithm produces
results that are usable by people.
The test was performed in both English and Rus-
sian, with 10 (6) subjects for English (Russian).
The subjects (biology and CS students) were not in-
volved with the research, did not see the clusters,
and did not receive any special training as prepara-
tion. Inter-subject agreement and Kappa were 0.82,
0.72 (0.9, 0.78) for English (Russian). As reported
in (Turney, 2005), an average high-school SAT
grade is 57. Table 1 shows the final English and Rus-
</bodyText>
<footnote confidence="0.9467205">
4But note that a pair can certainly obtain a positive HITS
value for several clusters.
</footnote>
<table confidence="0.875174">
Our method Real SAT Correlation
English 80% 71% 0.85
Russian 83% 79% 0.88
</table>
<tableCaption confidence="0.985904">
Table 1: Pattern cluster evaluation using automatically
generated SAT analogy choice questions.
</tableCaption>
<bodyText confidence="0.999198142857143">
sian grade average for ours and real SAT questions.
We can see that for both languages, around 80%
of the choices were correct (the random choice base-
line is 20%). Our subjects are university students,
so results higher than 57 are expected, as we can
see from real SAT performance. The difference
in grades between the two languages might be at-
tributed to the presence of relatively hard and un-
common words. It also may result from the Russian
test being easier because there is less verb-noun am-
biguity in Russian.
We have observed a high correlation between true
grades and ours, suggesting that our automatically
generated test reflects the ability to recognize analo-
gies and can be potentially used for automated gen-
eration of SAT-like tests.
The results show that our pattern clusters indeed
mirror a human notion of relationship similarity and
represent meaningful relationships. They also show
that as intended, different clusters describe different
relationships.
</bodyText>
<subsectionHeader confidence="0.998241">
5.2 Analogy Invention Test
</subsectionHeader>
<bodyText confidence="0.999948888888889">
To assess recall of separate pattern clusters, we have
asked subjects to provide (if possible) an additional
pair for each SAT question. On each such pair
we have automatically extracted a set of pattern in-
stances that capture this pair by using automated
web queries. Then we calculated the HITS value for
each of the selected pairs and assigned them to clus-
ters with highest HITS value. The numbers of pairs
provided were 81 for English and 43 for Russian.
We have estimated precision for this task as
macro-average of percentage of correctly assigned
pairs, obtaining 87% for English and 82% for Rus-
sian (the random baseline of this 15-class classifi-
cation task is 6.7%). It should be noted however
that the human-provided additional relationship ex-
amples in this test are not random so it may intro-
duce bias. Nevertheless, these results confirm that
our pattern clusters are able to recognize new in-
</bodyText>
<page confidence="0.994789">
698
</page>
<table confidence="0.99893375">
30 Noun Compound Relationships
Avg. num Overlap
of clusters
Russian 1.8 0.046
English 1.7 0.059
5 Verb Verb Relationships
Russian 1.4 0.01
English 1.2 0
</table>
<tableCaption confidence="0.9883135">
Table 2: Patterns clusters discovery of known relation-
ships.
</tableCaption>
<bodyText confidence="0.727975">
stances of relationships of the same type.
</bodyText>
<sectionHeader confidence="0.995218" genericHeader="evaluation">
6 Evaluation Using Known Information
</sectionHeader>
<bodyText confidence="0.999711">
We also evaluated our pattern clusters using relevant
information reported in related work.
</bodyText>
<subsectionHeader confidence="0.996648">
6.1 Discovery of Known Relationships
</subsectionHeader>
<bodyText confidence="0.999985620689655">
To estimate recall of our pattern cluster set, we
attempted to estimate whether (at least) a subset
of known relationships have corresponding pattern
clusters. As a testing subset, we have used 35 re-
lationships for both English and Russian. 30 rela-
tions are noun compound relationships as proposed
in the (Nastase and Szpakowicz, 2003) classifica-
tion scheme, and 5 relations are verb-verb relations
proposed by (Chklovski and Pantel, 2004). We
have manually created sets of 5 unambiguous sam-
ple pairs for each of these 35 relationships. For each
such pair we have assigned the pattern cluster with
best HITS value.
The middle column of Table 2 shows the average
number of clusters per relationship. Ideally, if for
each relationship all 5 pairs are assigned to the same
cluster, the average would be 1. In the worst case,
when each pair is assigned to a different cluster, the
average would be 5. We can see that most of the
pairs indeed fall into one or two clusters, success-
fully recognizing that similarly related pairs belong
to the same cluster. The column on the right shows
the overlap between different clusters, measured as
the average number of shared pairs in two randomly
selected clusters. The baseline in this case is essen-
tially 5, since there are more than 400 clusters for 5
word pairs. We see a very low overlap between as-
signed clusters, which shows that these clusters in-
deed separate well between defined relations.
</bodyText>
<subsectionHeader confidence="0.997921">
6.2 Discovery of Known Pattern Sets
</subsectionHeader>
<bodyText confidence="0.999960583333333">
We compared our clusters to lists of patterns re-
ported as useful by previous papers. These lists
included patterns expressing hypernymy (Hearst,
1992; Pantel et al., 2004), meronymy (Berland and
Charniak, 1999; Girju et al., 2006), synonymy
(Widdows and Dorow, 2002; Davidov and Rap-
poport, 2006), and verb strength + verb happens-
before (Chklovski and Pantel, 2004). In all cases,
we discovered clusters containing all of the reported
patterns (including their refinements with domain-
specific prefix or postfix) and not containing patterns
of competing relationships.
</bodyText>
<sectionHeader confidence="0.999046" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.9998525">
We have proposed a novel way to define and identify
generic lexical relationships as clusters of patterns.
Each such cluster is set of patterns that can be used
to identify, classify or capture new instances of some
unspecified semantic relationship. We showed how
such pattern clusters can be obtained automatically
from text corpora without any seeds and without re-
lying on manually created databases or language-
specific text preprocessing. In an evaluation based
on an automatically created analogy SAT test we
showed on two languages that pairs produced by our
clusters indeed strongly reflect human notions of re-
lation similarity. We also showed that the obtained
pattern clusters can be used to recognize new ex-
amples of the same relationships. In an additional
test where we assign labeled pairs to pattern clus-
ters, we showed that they provide good coverage for
known noun-noun and verb-verb relationships for
both tested languages.
While our algorithm shows good performance,
there is still room for improvement. It utilizes a set
of constants that affect precision, recall and the gran-
ularity of the extracted cluster set. It would be ben-
eficial to obtain such parameters automatically and
to create a multilevel relationship hierarchy instead
of a flat one, thus combining different granularity
levels. In this study we applied our algorithm to a
generic domain, while the same method can be used
for more restricted domains, potentially discovering
useful domain-specific relationships.
</bodyText>
<page confidence="0.998802">
699
</page>
<sectionHeader confidence="0.99589" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999920736842105">
Alfonseca, E., Ruiz-Casado, M., Okumura, M., Castells,
P., 2006. Towards large-scale non-taxonomic relation
extraction: estimating the precision of rote extractors.
COLING-ACL ’06 Ontology Learning &amp; Population
Workshop.
Banko, M., Cafarella, M. J. , Soderland, S., Broadhead,
M., and Etzioni, O., 2007. Open information extrac-
tion from the Web. IJCAI ’07.
Berland, M., Charniak, E., 1999. Finding parts in very
large corpora. ACL ’99.
Chklovski, T., Pantel, P., 2004. VerbOcean: mining the
web for fine-grained semantic verb relations. EMNLP
’04.
Costello, F., Veale, T. Dunne, S., 2006. Using Word-
Net to automatically deduce relations between words
in noun-noun compounds. COLING-ACL ’06.
Davidov, D., Rappoport, A., 2006. Efficient unsuper-
vised discovery of word categories using symmetric
patterns and high frequency words. COLING-ACL
’06.
Davidov, D., Rappoport, A. and Koppel, M., 2007. Fully
unsupervised discovery of concept-specific relation-
ships by Web mining. ACL ’07.
Davidov, D., Rappoport, A., 2008. Classification of re-
lationships between nominals using pattern clusters.
ACL ’08.
Etzioni, O., Cafarella, M., Downey, D., Popescu, A.,
Shaked, T., Soderland, S., Weld, D., and Yates, A.,
2004. Methods for domain-independent information
extraction from the web: An experimental compari-
son. AAAI 04
Gabrilovich, E., Markovitch, S., 2005. Feature gener-
ation for text categorization using world knowledge.
IJCAI 2005.
Gir u, R., Giuglea, A., Olteanu, M., Fortu, O., Bolohan,
O., and Moldovan, D., 2004. Support vector machines
applied to the classification of semantic relations in
nominalized noun phrases. HLT/NAACL Workshop on
Computational Lexical Semantics.
Gir u, R., Moldovan, D., Tatu, M., and Antohe, D., 2005.
On the semantics of noun compounds. Computer
Speech and Language, 19(4):479-496.
Gir u, R., Badulescu, A., and Moldovan, D., 2006. Au-
tomatic discovery of part-whole relations. Computa-
tional Linguistics, 32(1).
Gir u, R., Hearst, M., Nakov, P., Nastase, V., Szpakow-
icz, S., Turney, P., and Yuret, D., 2007. Task 04:
Classification of semantic relations between nominal
at SemEval 2007. ACL ’07 SemEval Workshop.
Hasegawa, T., Sekine, S., and Grishman, R., 2004. Dis-
covering relations among named entities from large
corpora. ACL ’04.
Hassan, H., Hassan, A. and Emam, O., 2006. Unsu-
pervised information extraction approach using graph
mutual reinforcement. EMNLP ’06.
Hearst, M., 1992. Automatic acquisition of hyponyms
from large text corpora. COLING ’92
Lin, D., Pantel, P., 2002. Concept discovery from text.
COLING 02.
Moldovan, D., Badulescu, A., Tatu, M., Antohe, D.,Gir u,
R., 2004. Models for the semantic classification of
noun phrases. HLT-NAACL ’04 Workshop on Compu-
tational Lexical Semantics.
Nastase, V., Szpakowicz, S., 2003. Exploring noun mod-
ifier semantic relations. IWCS-5.
Pantel, P., Pennacchiotti, M., 2006. Espresso: leveraging
generic patterns for automatically harvesting semantic
relations. COLING-ACL 2006.
Pantel, P., Ravichandran, D. and Hovy, E.H., 2004. To-
wards terascale knowledge acquisition. COLING ’04.
Pasca, M., Lin, D., Bigham, J., Lifchits A., Jain, A.,
2006. Names and similarities on the web: fact extrac-
tion in the fast lane. COLING-ACL ’06.
Rosenfeld, B., Feldman, R., 2007. Clustering for unsu-
pervised relation identification. CIKM ’07.
Snow, R., Jurafsky, D., Ng, A.Y., 2006. Seman-
tic taxonomy induction from heterogeneous evidence.
COLING-ACL ’06.
Strube, M., Ponzetto, S., 2006. WikiRelate! computing
semantic relatedness using Wikipedia. AAAI ’06.
Suchanek, F., Ifrim, G., and Weikum, G., 2006. LEILA:
learning to extract information by linguistic analysis.
COLING-ACL ’06 Ontology Learning &amp; Population
Workshop.
Tatu, M., Moldovan, D., 2005. A semantic approach to
recognizing textual entailment. HLT/EMNLP 2005.
Turney, P., 2005. Measuring semantic similarity by la-
tent relational analysis. IJCAI ’05.
Turney, P., Littman, M., 2005. Corpus-based learn-
ing of analogies and semantic selations. Machine
Learning(60):1–3:251–278.
Turney, P., 2006. Expressing implicit semantic relations
without supervision. COLING-ACL ’06.
Widdows, D., Dorow, B., 2002. A graph model for un-
supervised lexical acquisition. COLING ’02.
</reference>
<page confidence="0.9964">
700
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.956274">
<title confidence="0.9947875">Unsupervised Discovery of Generic Relationships Using Pattern Clusters and its Evaluation by Automatically Generated SAT Analogy Questions</title>
<author confidence="0.997891">Dmitry Davidov Ari Rappoport</author>
<affiliation confidence="0.999738">ICNC Institute of Computer Science Hebrew University of Jerusalem Hebrew University of Jerusalem</affiliation>
<email confidence="0.976894">dmitry@alice.nc.huji.ac.ilarir@cs.huji.ac.il</email>
<abstract confidence="0.999595523809524">We present a novel framework for the discovery and representation of general semantic relationships that hold between lexical items. We propose that each such relationship can be identified with a cluster of patterns that captures this relationship. We give a fully unsupervised algorithm for pattern cluster discovery, which searches, clusters and merges highfrequency words-based patterns around randomly selected hook words. Pattern clusters can be used to extract instances of the corresponding relationships. To assess the quality of discovered relationships, we use the pattern clusters to automatically generate SAT analogy questions. We also compare to a set of known relationships, achieving very good results in both methods. The evaluation (done in both English and Russian) substantiates the premise that our pattern clusters indeed reflect relationships perceived by humans.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Alfonseca</author>
<author>M Ruiz-Casado</author>
<author>M Okumura</author>
<author>P Castells</author>
</authors>
<title>Towards large-scale non-taxonomic relation extraction: estimating the precision of rote extractors.</title>
<date>2006</date>
<booktitle>COLING-ACL ’06 Ontology Learning &amp; Population Workshop.</booktitle>
<contexts>
<context position="9063" citStr="Alfonseca et al., 2006" startWordPosition="1383" endWordPosition="1386">o discover and define generic relationships that exist in the entire domain. Studying relationships between tagged named entities, (Hasegawa et al., 2004; Hassan et al., 2006) proposed unsupervised clustering methods that assign given sets of pairs into several clusters, where each cluster corresponds to one of a known set of relationship types. Their classification setting is thus very different from our unsupervised discovery one. Several recent papers discovered relations on the web using seed patterns (Pantel et al., 2004), rules (Etzioni et al., 2004), and word pairs (Pasca et al., 2006; Alfonseca et al., 2006). The latter used the notion of hook which we also use in this paper. Several studies utilize some preprocessing, including parsing (Hasegawa et al., 2004; Hassan et al., 2006) and usage of syntactic (Suchanek et al., 2006) and morphological (Pantel et al., 2004) information in patterns. Several algorithms use manuallyprepared resources, including WordNet (Moldovan et al., 2004; Costello et al., 2006) and Wikipedia (Strube and Ponzetto, 2006). In this paper, we do not utilize any language-specific preprocessing or any other resources, which makes our algorithm relatively easily portable betwee</context>
<context position="11753" citStr="Alfonseca et al., 2006" startWordPosition="1810" endWordPosition="1813">stering Algorithm Our algorithm first discovers and clusters patterns in which a single (‘hook’) word participates, and then merges the resulting clusters to form the final structure. In this section we detail the algorithm. The algorithm utilizes several parameters, whose selection is detailed in Section 4. We refer to a pattern contained in our clusters (a pattern type) as a ‘pattern’ and to an occurrence of a pattern in the corpus (a pattern token) as a ‘pattern instance’. 3.1 Hook Words and Hook Corpora As a first step, we randomly select a set of hook words. Hook words were used in e.g. (Alfonseca et al., 2006) for extracting general relations starting from given seed word pairs. Unlike most previous work, our hook words are not provided in advance but selected randomly; the goal in those papers is to discover relationships between given word pairs, while we use hook words in order to discover relationships that generally occur in the corpus. Only patterns in which a hook word actually participates will eventually be discovered. Hence, in principle we should select as many hook words as possible. However, words whose frequency is very high are usually ambiguous and are likely to produce patterns tha</context>
</contexts>
<marker>Alfonseca, Ruiz-Casado, Okumura, Castells, 2006</marker>
<rawString>Alfonseca, E., Ruiz-Casado, M., Okumura, M., Castells, P., 2006. Towards large-scale non-taxonomic relation extraction: estimating the precision of rote extractors. COLING-ACL ’06 Ontology Learning &amp; Population Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Soderland</author>
<author>M Broadhead</author>
<author>O Etzioni</author>
</authors>
<date>2007</date>
<booktitle>Open information extraction from the Web. IJCAI ’07.</booktitle>
<marker>Soderland, Broadhead, Etzioni, 2007</marker>
<rawString>Banko, M., Cafarella, M. J. , Soderland, S., Broadhead, M., and Etzioni, O., 2007. Open information extraction from the Web. IJCAI ’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Berland</author>
<author>E Charniak</author>
</authors>
<title>Finding parts in very large corpora.</title>
<date>1999</date>
<journal>ACL</journal>
<volume>99</volume>
<contexts>
<context position="6644" citStr="Berland and Charniak, 1999" startWordPosition="1006" endWordPosition="1009"> Related Work Extraction of relation information from text is a large sub-field in NLP. Major differences between pattern approaches include the relationship types sought (including domain restrictions), the degrees of supervision and required preprocessing, and evaluation method. 2.1 Relationship Types There is a large body of related work that deals with discovery of basic relationship types represented in useful resources such as WordNet, including hypernymy (Hearst, 1992; Pantel et al., 2004; Snow et al., 2006), synonymy (Davidov and Rappoport, 2006; Widdows and Dorow, 2002) and meronymy (Berland and Charniak, 1999; Girju et al., 2006). Since named entities are very important in NLP, many studies define and discover relations between named entities (Hasegawa et al., 2004; Hassan et al., 2006). Work was also done on relations between verbs (Chklovski and Pantel, 2004). There is growing research on relations between nominals (Moldovan et al., 2004; Girju et al., 2007). 2.2 Degree of Supervision and Preprocessing While numerous studies attempt to discover one or more pre-specified relationship types, very little previous work has directly attempted the discovery of which main types of generic relationships</context>
<context position="10084" citStr="Berland and Charniak, 1999" startWordPosition="1536" endWordPosition="1539">al., 2006) and Wikipedia (Strube and Ponzetto, 2006). In this paper, we do not utilize any language-specific preprocessing or any other resources, which makes our algorithm relatively easily portable between languages, as we demonstrate in our bilingual evaluation. 2.3 Evaluation Method Evaluation for hypernymy and synonymy usually uses WordNet (Lin and Pantel, 2002; Widdows and Dorow, 2002; Davidov and Rappoport, 2006). For more specific lexical relationships like relationships between verbs (Chklovski and Pantel, 2004), nominals (Girju et al., 2004; Girju et al., 2007) or meronymy subtypes (Berland and Charniak, 1999) there is still little agreement which important relationships should be defined. Thus, there are more than a dozen different type hierarchies and tasks proposed for noun compounds (and nominals in general), including (Nastase and Szpakowicz, 2003; Girju et al., 2005; Girju et al., 2007). There are thus two possible ways for a fair evaluation. A study can develop its own relationship definitions and dataset, like (Nastase and Szpakowicz, 2003), thus introducing a possible bias; or it can accept the definition and dataset prepared by another work, like (Turney, 2006). However, this makes it imp</context>
<context position="32085" citStr="Berland and Charniak, 1999" startWordPosition="5211" endWordPosition="5214">olumn on the right shows the overlap between different clusters, measured as the average number of shared pairs in two randomly selected clusters. The baseline in this case is essentially 5, since there are more than 400 clusters for 5 word pairs. We see a very low overlap between assigned clusters, which shows that these clusters indeed separate well between defined relations. 6.2 Discovery of Known Pattern Sets We compared our clusters to lists of patterns reported as useful by previous papers. These lists included patterns expressing hypernymy (Hearst, 1992; Pantel et al., 2004), meronymy (Berland and Charniak, 1999; Girju et al., 2006), synonymy (Widdows and Dorow, 2002; Davidov and Rappoport, 2006), and verb strength + verb happensbefore (Chklovski and Pantel, 2004). In all cases, we discovered clusters containing all of the reported patterns (including their refinements with domainspecific prefix or postfix) and not containing patterns of competing relationships. 7 Conclusion We have proposed a novel way to define and identify generic lexical relationships as clusters of patterns. Each such cluster is set of patterns that can be used to identify, classify or capture new instances of some unspecified s</context>
</contexts>
<marker>Berland, Charniak, 1999</marker>
<rawString>Berland, M., Charniak, E., 1999. Finding parts in very large corpora. ACL ’99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Chklovski</author>
<author>P Pantel</author>
</authors>
<title>VerbOcean: mining the web for fine-grained semantic verb relations.</title>
<date>2004</date>
<journal>EMNLP</journal>
<volume>04</volume>
<contexts>
<context position="6901" citStr="Chklovski and Pantel, 2004" startWordPosition="1048" endWordPosition="1051">g, and evaluation method. 2.1 Relationship Types There is a large body of related work that deals with discovery of basic relationship types represented in useful resources such as WordNet, including hypernymy (Hearst, 1992; Pantel et al., 2004; Snow et al., 2006), synonymy (Davidov and Rappoport, 2006; Widdows and Dorow, 2002) and meronymy (Berland and Charniak, 1999; Girju et al., 2006). Since named entities are very important in NLP, many studies define and discover relations between named entities (Hasegawa et al., 2004; Hassan et al., 2006). Work was also done on relations between verbs (Chklovski and Pantel, 2004). There is growing research on relations between nominals (Moldovan et al., 2004; Girju et al., 2007). 2.2 Degree of Supervision and Preprocessing While numerous studies attempt to discover one or more pre-specified relationship types, very little previous work has directly attempted the discovery of which main types of generic relationships actually exist in an unrestricted domain. Turney (2006) provided a pattern distance measure that allows a fully unsupervised measurement of relational similarity between two pairs of words; such a measure could in principle be used by a clustering algorith</context>
<context position="9983" citStr="Chklovski and Pantel, 2004" startWordPosition="1519" endWordPosition="1522">ral algorithms use manuallyprepared resources, including WordNet (Moldovan et al., 2004; Costello et al., 2006) and Wikipedia (Strube and Ponzetto, 2006). In this paper, we do not utilize any language-specific preprocessing or any other resources, which makes our algorithm relatively easily portable between languages, as we demonstrate in our bilingual evaluation. 2.3 Evaluation Method Evaluation for hypernymy and synonymy usually uses WordNet (Lin and Pantel, 2002; Widdows and Dorow, 2002; Davidov and Rappoport, 2006). For more specific lexical relationships like relationships between verbs (Chklovski and Pantel, 2004), nominals (Girju et al., 2004; Girju et al., 2007) or meronymy subtypes (Berland and Charniak, 1999) there is still little agreement which important relationships should be defined. Thus, there are more than a dozen different type hierarchies and tasks proposed for noun compounds (and nominals in general), including (Nastase and Szpakowicz, 2003; Girju et al., 2005; Girju et al., 2007). There are thus two possible ways for a fair evaluation. A study can develop its own relationship definitions and dataset, like (Nastase and Szpakowicz, 2003), thus introducing a possible bias; or it can accept</context>
<context position="30842" citStr="Chklovski and Pantel, 2004" startWordPosition="4998" endWordPosition="5001">ips of the same type. 6 Evaluation Using Known Information We also evaluated our pattern clusters using relevant information reported in related work. 6.1 Discovery of Known Relationships To estimate recall of our pattern cluster set, we attempted to estimate whether (at least) a subset of known relationships have corresponding pattern clusters. As a testing subset, we have used 35 relationships for both English and Russian. 30 relations are noun compound relationships as proposed in the (Nastase and Szpakowicz, 2003) classification scheme, and 5 relations are verb-verb relations proposed by (Chklovski and Pantel, 2004). We have manually created sets of 5 unambiguous sample pairs for each of these 35 relationships. For each such pair we have assigned the pattern cluster with best HITS value. The middle column of Table 2 shows the average number of clusters per relationship. Ideally, if for each relationship all 5 pairs are assigned to the same cluster, the average would be 1. In the worst case, when each pair is assigned to a different cluster, the average would be 5. We can see that most of the pairs indeed fall into one or two clusters, successfully recognizing that similarly related pairs belong to the sa</context>
<context position="32240" citStr="Chklovski and Pantel, 2004" startWordPosition="5236" endWordPosition="5239">eline in this case is essentially 5, since there are more than 400 clusters for 5 word pairs. We see a very low overlap between assigned clusters, which shows that these clusters indeed separate well between defined relations. 6.2 Discovery of Known Pattern Sets We compared our clusters to lists of patterns reported as useful by previous papers. These lists included patterns expressing hypernymy (Hearst, 1992; Pantel et al., 2004), meronymy (Berland and Charniak, 1999; Girju et al., 2006), synonymy (Widdows and Dorow, 2002; Davidov and Rappoport, 2006), and verb strength + verb happensbefore (Chklovski and Pantel, 2004). In all cases, we discovered clusters containing all of the reported patterns (including their refinements with domainspecific prefix or postfix) and not containing patterns of competing relationships. 7 Conclusion We have proposed a novel way to define and identify generic lexical relationships as clusters of patterns. Each such cluster is set of patterns that can be used to identify, classify or capture new instances of some unspecified semantic relationship. We showed how such pattern clusters can be obtained automatically from text corpora without any seeds and without relying on manually</context>
</contexts>
<marker>Chklovski, Pantel, 2004</marker>
<rawString>Chklovski, T., Pantel, P., 2004. VerbOcean: mining the web for fine-grained semantic verb relations. EMNLP ’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Costello</author>
<author>T Dunne Veale</author>
<author>S</author>
</authors>
<title>Using WordNet to automatically deduce relations between words in noun-noun compounds.</title>
<date>2006</date>
<journal>COLING-ACL</journal>
<volume>06</volume>
<contexts>
<context position="9467" citStr="Costello et al., 2006" startWordPosition="1447" endWordPosition="1450">our unsupervised discovery one. Several recent papers discovered relations on the web using seed patterns (Pantel et al., 2004), rules (Etzioni et al., 2004), and word pairs (Pasca et al., 2006; Alfonseca et al., 2006). The latter used the notion of hook which we also use in this paper. Several studies utilize some preprocessing, including parsing (Hasegawa et al., 2004; Hassan et al., 2006) and usage of syntactic (Suchanek et al., 2006) and morphological (Pantel et al., 2004) information in patterns. Several algorithms use manuallyprepared resources, including WordNet (Moldovan et al., 2004; Costello et al., 2006) and Wikipedia (Strube and Ponzetto, 2006). In this paper, we do not utilize any language-specific preprocessing or any other resources, which makes our algorithm relatively easily portable between languages, as we demonstrate in our bilingual evaluation. 2.3 Evaluation Method Evaluation for hypernymy and synonymy usually uses WordNet (Lin and Pantel, 2002; Widdows and Dorow, 2002; Davidov and Rappoport, 2006). For more specific lexical relationships like relationships between verbs (Chklovski and Pantel, 2004), nominals (Girju et al., 2004; Girju et al., 2007) or meronymy subtypes (Berland an</context>
</contexts>
<marker>Costello, Veale, S, 2006</marker>
<rawString>Costello, F., Veale, T. Dunne, S., 2006. Using WordNet to automatically deduce relations between words in noun-noun compounds. COLING-ACL ’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Davidov</author>
<author>A Rappoport</author>
</authors>
<title>Efficient unsupervised discovery of word categories using symmetric patterns and high frequency words.</title>
<date>2006</date>
<journal>COLING-ACL</journal>
<volume>06</volume>
<contexts>
<context position="6577" citStr="Davidov and Rappoport, 2006" startWordPosition="996" endWordPosition="999"> generating them. 6 present SAT and comparison evaluation results. 2 Related Work Extraction of relation information from text is a large sub-field in NLP. Major differences between pattern approaches include the relationship types sought (including domain restrictions), the degrees of supervision and required preprocessing, and evaluation method. 2.1 Relationship Types There is a large body of related work that deals with discovery of basic relationship types represented in useful resources such as WordNet, including hypernymy (Hearst, 1992; Pantel et al., 2004; Snow et al., 2006), synonymy (Davidov and Rappoport, 2006; Widdows and Dorow, 2002) and meronymy (Berland and Charniak, 1999; Girju et al., 2006). Since named entities are very important in NLP, many studies define and discover relations between named entities (Hasegawa et al., 2004; Hassan et al., 2006). Work was also done on relations between verbs (Chklovski and Pantel, 2004). There is growing research on relations between nominals (Moldovan et al., 2004; Girju et al., 2007). 2.2 Degree of Supervision and Preprocessing While numerous studies attempt to discover one or more pre-specified relationship types, very little previous work has directly a</context>
<context position="9880" citStr="Davidov and Rappoport, 2006" startWordPosition="1506" endWordPosition="1509"> syntactic (Suchanek et al., 2006) and morphological (Pantel et al., 2004) information in patterns. Several algorithms use manuallyprepared resources, including WordNet (Moldovan et al., 2004; Costello et al., 2006) and Wikipedia (Strube and Ponzetto, 2006). In this paper, we do not utilize any language-specific preprocessing or any other resources, which makes our algorithm relatively easily portable between languages, as we demonstrate in our bilingual evaluation. 2.3 Evaluation Method Evaluation for hypernymy and synonymy usually uses WordNet (Lin and Pantel, 2002; Widdows and Dorow, 2002; Davidov and Rappoport, 2006). For more specific lexical relationships like relationships between verbs (Chklovski and Pantel, 2004), nominals (Girju et al., 2004; Girju et al., 2007) or meronymy subtypes (Berland and Charniak, 1999) there is still little agreement which important relationships should be defined. Thus, there are more than a dozen different type hierarchies and tasks proposed for noun compounds (and nominals in general), including (Nastase and Szpakowicz, 2003; Girju et al., 2005; Girju et al., 2007). There are thus two possible ways for a fair evaluation. A study can develop its own relationship definitio</context>
<context position="14306" citStr="Davidov and Rappoport, 2006" startWordPosition="2246" endWordPosition="2249"> domain or word type, if we want to discover only a desired subset of existing relationships. Thus we could sample hook words from nouns, verbs, proper names, or names of chemical compounds if we are only interested in discovering relationships between these. Selecting hook words randomly allows us to avoid using any language-specific data at this step. 3.2 Pattern Specification In order to reduce noise and to make the computation more efficient, we did not consider all contexts of a hook word as pattern candidates, only contexts that are instances of a specified meta-pattern type. Following (Davidov and Rappoport, 2006), we classified words into high-frequency words (HFWs) and content words (CWs). A word whose frequency is more (less) than FH (FC) is considered to be a HFW (CW). Unlike (Davidov and Rappoport, 2006), we consider all punctuation characters as HFWs. Our patterns have the general form [Prefix] CW1 [Infix] CW2 [Postfix] where Prefix, Infix and Postfix contain only HFWs. To reduce the chance of catching CWZ’s that are parts of a multiword expression, we require Prefix and Postfix to have at least one word (HFW), while Infix is allowed to contain any number of HFWs (but recall that the total length</context>
<context position="32171" citStr="Davidov and Rappoport, 2006" startWordPosition="5224" endWordPosition="5228">rage number of shared pairs in two randomly selected clusters. The baseline in this case is essentially 5, since there are more than 400 clusters for 5 word pairs. We see a very low overlap between assigned clusters, which shows that these clusters indeed separate well between defined relations. 6.2 Discovery of Known Pattern Sets We compared our clusters to lists of patterns reported as useful by previous papers. These lists included patterns expressing hypernymy (Hearst, 1992; Pantel et al., 2004), meronymy (Berland and Charniak, 1999; Girju et al., 2006), synonymy (Widdows and Dorow, 2002; Davidov and Rappoport, 2006), and verb strength + verb happensbefore (Chklovski and Pantel, 2004). In all cases, we discovered clusters containing all of the reported patterns (including their refinements with domainspecific prefix or postfix) and not containing patterns of competing relationships. 7 Conclusion We have proposed a novel way to define and identify generic lexical relationships as clusters of patterns. Each such cluster is set of patterns that can be used to identify, classify or capture new instances of some unspecified semantic relationship. We showed how such pattern clusters can be obtained automaticall</context>
</contexts>
<marker>Davidov, Rappoport, 2006</marker>
<rawString>Davidov, D., Rappoport, A., 2006. Efficient unsupervised discovery of word categories using symmetric patterns and high frequency words. COLING-ACL ’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Davidov</author>
<author>A Rappoport</author>
<author>M Koppel</author>
</authors>
<title>Fully unsupervised discovery of concept-specific relationships by Web mining.</title>
<date>2007</date>
<journal>ACL</journal>
<volume>07</volume>
<contexts>
<context position="8179" citStr="Davidov et al. (2007)" startWordPosition="1246" endWordPosition="1249"> discussed. Unlike (Turney, 2006), we do not perform any pattern ranking. Instead we produce (possibly overlapping) hard clusters, where each pattern cluster represents a relationship discovered in the domain. Banko et al. (2007) and Rosenfeld and Feldman (2007) find relationship instances where the relationships are not specified in advance. They aim to find relationship instances rather than identify generic semantic relationships. Thus, their representation is very different from ours. In addition, (Banko et al., 2007) utilize supervised tools such 693 as a POS tagger and a shallow parser. Davidov et al. (2007) proposed a method for unsupervised discovery of concept-specific relations. That work, like ours, relies on pattern clusters. However, it requires initial word seeds and targets the discovery of relationships specific for some given concept, while we attempt to discover and define generic relationships that exist in the entire domain. Studying relationships between tagged named entities, (Hasegawa et al., 2004; Hassan et al., 2006) proposed unsupervised clustering methods that assign given sets of pairs into several clusters, where each cluster corresponds to one of a known set of relationshi</context>
</contexts>
<marker>Davidov, Rappoport, Koppel, 2007</marker>
<rawString>Davidov, D., Rappoport, A. and Koppel, M., 2007. Fully unsupervised discovery of concept-specific relationships by Web mining. ACL ’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Davidov</author>
<author>A Rappoport</author>
</authors>
<title>Classification of relationships between nominals using pattern clusters.</title>
<date>2008</date>
<journal>ACL</journal>
<volume>08</volume>
<contexts>
<context position="5464" citStr="Davidov and Rappoport, 2008" startWordPosition="826" endWordPosition="829">scovered relationships to automatically generate analogy SAT tests in two languages, English and Russian1. Human subjects answered these and real SAT tests. English grades were 80% for our test and 71% for the real test (83% and 79% for Russian), showing that our relationship definitions indeed reflect human notions of relationship similarity. In addition, we show that among our pattern clusters there are clusters that cover major known noun-compound and verb-verb relationships. In the present paper we focus on the pattern cluster resource itself and how to evaluate its intrinsic quality. In (Davidov and Rappoport, 2008) we show how to use the resource for a known task of a totally different nature, classification of relationships between nominals (based on annotated data), obtaining superior results over previous work. Section 2 discusses related work, and Section 3 presents the pattern clustering and labeling algorithm. Section 4 describes the corpora we used and the algorithm’s parameters in detail. Sections 5 and 1Turney and Littman (2005) automatically answers SAT tests, while our focus is on generating them. 6 present SAT and comparison evaluation results. 2 Related Work Extraction of relation informati</context>
</contexts>
<marker>Davidov, Rappoport, 2008</marker>
<rawString>Davidov, D., Rappoport, A., 2008. Classification of relationships between nominals using pattern clusters. ACL ’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Etzioni</author>
<author>M Cafarella</author>
<author>D Downey</author>
<author>A Popescu</author>
<author>T Shaked</author>
<author>S Soderland</author>
<author>D Weld</author>
<author>A Yates</author>
</authors>
<title>Methods for domain-independent information extraction from the web: An experimental comparison.</title>
<date>2004</date>
<journal>AAAI</journal>
<volume>04</volume>
<contexts>
<context position="9002" citStr="Etzioni et al., 2004" startWordPosition="1372" endWordPosition="1375">onships specific for some given concept, while we attempt to discover and define generic relationships that exist in the entire domain. Studying relationships between tagged named entities, (Hasegawa et al., 2004; Hassan et al., 2006) proposed unsupervised clustering methods that assign given sets of pairs into several clusters, where each cluster corresponds to one of a known set of relationship types. Their classification setting is thus very different from our unsupervised discovery one. Several recent papers discovered relations on the web using seed patterns (Pantel et al., 2004), rules (Etzioni et al., 2004), and word pairs (Pasca et al., 2006; Alfonseca et al., 2006). The latter used the notion of hook which we also use in this paper. Several studies utilize some preprocessing, including parsing (Hasegawa et al., 2004; Hassan et al., 2006) and usage of syntactic (Suchanek et al., 2006) and morphological (Pantel et al., 2004) information in patterns. Several algorithms use manuallyprepared resources, including WordNet (Moldovan et al., 2004; Costello et al., 2006) and Wikipedia (Strube and Ponzetto, 2006). In this paper, we do not utilize any language-specific preprocessing or any other resources</context>
</contexts>
<marker>Etzioni, Cafarella, Downey, Popescu, Shaked, Soderland, Weld, Yates, 2004</marker>
<rawString>Etzioni, O., Cafarella, M., Downey, D., Popescu, A., Shaked, T., Soderland, S., Weld, D., and Yates, A., 2004. Methods for domain-independent information extraction from the web: An experimental comparison. AAAI 04</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Gabrilovich</author>
<author>S Markovitch</author>
</authors>
<title>Feature generation for text categorization using world knowledge. IJCAI</title>
<date>2005</date>
<contexts>
<context position="19046" citStr="Gabrilovich and Markovitch, 2005" startWordPosition="3069" endWordPosition="3072">l corpus or retrieved from the web during evaluation (see Section 5.2). Thus if some pair appears in most of patterns of some cluster it receives a high HITS value for this cluster. The top 5 pairs for each cluster are selected as its labels. α E (0..1) is a parameter that lets us modify the relative weight of core and unconfirmed patterns. 4 Corpora and Parameters In this section we describe our experimental setup, and discuss in detail the effect of each of the algorithms’ parameters. 4.1 Languages and Corpora The evaluation was done using corpora in English and Russian. The English corpus (Gabrilovich and Markovitch, 2005) was obtained through crawling the URLs in the Open Directory Project (dmoz.org). It contains about 8.2G words and its size is about 68GB of untagged plain text. The Russian corpus was collected over the web, comprising a variety of domains, including news, web pages, forums, novels and scientific papers. It contains 7.5G words of size 55GB untagged plain text. Aside from removing noise and sentence duplicates, we did not apply any text preprocessing or tagging. 4.2 Parameters Our algorithm uses the following parameters: FC, FH, FB, W, N, L, S and α. We used part of the Russian corpus as a dev</context>
</contexts>
<marker>Gabrilovich, Markovitch, 2005</marker>
<rawString>Gabrilovich, E., Markovitch, S., 2005. Feature generation for text categorization using world knowledge. IJCAI 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>u Gir</author>
<author>R Giuglea</author>
<author>A Olteanu</author>
<author>M Fortu</author>
<author>O Bolohan</author>
<author>O</author>
<author>D Moldovan</author>
</authors>
<title>Support vector machines applied to the classification of semantic relations in nominalized noun phrases.</title>
<date>2004</date>
<booktitle>HLT/NAACL Workshop on Computational Lexical Semantics.</booktitle>
<marker>Gir, Giuglea, Olteanu, Fortu, Bolohan, O, Moldovan, 2004</marker>
<rawString>Gir u, R., Giuglea, A., Olteanu, M., Fortu, O., Bolohan, O., and Moldovan, D., 2004. Support vector machines applied to the classification of semantic relations in nominalized noun phrases. HLT/NAACL Workshop on Computational Lexical Semantics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>u Gir</author>
<author>R Moldovan</author>
<author>D Tatu</author>
<author>M</author>
<author>D Antohe</author>
</authors>
<title>On the semantics of noun compounds.</title>
<date>2005</date>
<journal>Computer Speech and Language,</journal>
<pages>19--4</pages>
<marker>Gir, Moldovan, Tatu, M, Antohe, 2005</marker>
<rawString>Gir u, R., Moldovan, D., Tatu, M., and Antohe, D., 2005. On the semantics of noun compounds. Computer Speech and Language, 19(4):479-496.</rawString>
</citation>
<citation valid="true">
<authors>
<author>u Gir</author>
<author>R Badulescu</author>
<author>A</author>
<author>D Moldovan</author>
</authors>
<title>Automatic discovery of part-whole relations.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<volume>32</volume>
<issue>1</issue>
<marker>Gir, Badulescu, A, Moldovan, 2006</marker>
<rawString>Gir u, R., Badulescu, A., and Moldovan, D., 2006. Automatic discovery of part-whole relations. Computational Linguistics, 32(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>u Gir</author>
<author>R Hearst</author>
<author>M Nakov</author>
<author>P Nastase</author>
<author>V Szpakowicz</author>
<author>S Turney</author>
<author>P</author>
<author>D Yuret</author>
</authors>
<title>Task 04: Classification of semantic relations between nominal at SemEval</title>
<date>2007</date>
<booktitle>ACL ’07 SemEval Workshop.</booktitle>
<marker>Gir, Hearst, Nakov, Nastase, Szpakowicz, Turney, P, Yuret, 2007</marker>
<rawString>Gir u, R., Hearst, M., Nakov, P., Nastase, V., Szpakowicz, S., Turney, P., and Yuret, D., 2007. Task 04: Classification of semantic relations between nominal at SemEval 2007. ACL ’07 SemEval Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Hasegawa</author>
<author>S Sekine</author>
<author>R Grishman</author>
</authors>
<title>Discovering relations among named entities from large corpora.</title>
<date>2004</date>
<journal>ACL</journal>
<volume>04</volume>
<contexts>
<context position="6803" citStr="Hasegawa et al., 2004" startWordPosition="1031" endWordPosition="1034">sought (including domain restrictions), the degrees of supervision and required preprocessing, and evaluation method. 2.1 Relationship Types There is a large body of related work that deals with discovery of basic relationship types represented in useful resources such as WordNet, including hypernymy (Hearst, 1992; Pantel et al., 2004; Snow et al., 2006), synonymy (Davidov and Rappoport, 2006; Widdows and Dorow, 2002) and meronymy (Berland and Charniak, 1999; Girju et al., 2006). Since named entities are very important in NLP, many studies define and discover relations between named entities (Hasegawa et al., 2004; Hassan et al., 2006). Work was also done on relations between verbs (Chklovski and Pantel, 2004). There is growing research on relations between nominals (Moldovan et al., 2004; Girju et al., 2007). 2.2 Degree of Supervision and Preprocessing While numerous studies attempt to discover one or more pre-specified relationship types, very little previous work has directly attempted the discovery of which main types of generic relationships actually exist in an unrestricted domain. Turney (2006) provided a pattern distance measure that allows a fully unsupervised measurement of relational similar</context>
<context position="8593" citStr="Hasegawa et al., 2004" startWordPosition="1308" endWordPosition="1311">semantic relationships. Thus, their representation is very different from ours. In addition, (Banko et al., 2007) utilize supervised tools such 693 as a POS tagger and a shallow parser. Davidov et al. (2007) proposed a method for unsupervised discovery of concept-specific relations. That work, like ours, relies on pattern clusters. However, it requires initial word seeds and targets the discovery of relationships specific for some given concept, while we attempt to discover and define generic relationships that exist in the entire domain. Studying relationships between tagged named entities, (Hasegawa et al., 2004; Hassan et al., 2006) proposed unsupervised clustering methods that assign given sets of pairs into several clusters, where each cluster corresponds to one of a known set of relationship types. Their classification setting is thus very different from our unsupervised discovery one. Several recent papers discovered relations on the web using seed patterns (Pantel et al., 2004), rules (Etzioni et al., 2004), and word pairs (Pasca et al., 2006; Alfonseca et al., 2006). The latter used the notion of hook which we also use in this paper. Several studies utilize some preprocessing, including parsin</context>
</contexts>
<marker>Hasegawa, Sekine, Grishman, 2004</marker>
<rawString>Hasegawa, T., Sekine, S., and Grishman, R., 2004. Discovering relations among named entities from large corpora. ACL ’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Hassan</author>
<author>A Hassan</author>
<author>O Emam</author>
</authors>
<title>Unsupervised information extraction approach using graph mutual reinforcement.</title>
<date>2006</date>
<journal>EMNLP</journal>
<volume>06</volume>
<contexts>
<context position="6825" citStr="Hassan et al., 2006" startWordPosition="1035" endWordPosition="1038">n restrictions), the degrees of supervision and required preprocessing, and evaluation method. 2.1 Relationship Types There is a large body of related work that deals with discovery of basic relationship types represented in useful resources such as WordNet, including hypernymy (Hearst, 1992; Pantel et al., 2004; Snow et al., 2006), synonymy (Davidov and Rappoport, 2006; Widdows and Dorow, 2002) and meronymy (Berland and Charniak, 1999; Girju et al., 2006). Since named entities are very important in NLP, many studies define and discover relations between named entities (Hasegawa et al., 2004; Hassan et al., 2006). Work was also done on relations between verbs (Chklovski and Pantel, 2004). There is growing research on relations between nominals (Moldovan et al., 2004; Girju et al., 2007). 2.2 Degree of Supervision and Preprocessing While numerous studies attempt to discover one or more pre-specified relationship types, very little previous work has directly attempted the discovery of which main types of generic relationships actually exist in an unrestricted domain. Turney (2006) provided a pattern distance measure that allows a fully unsupervised measurement of relational similarity between two pairs </context>
<context position="8615" citStr="Hassan et al., 2006" startWordPosition="1312" endWordPosition="1315"> Thus, their representation is very different from ours. In addition, (Banko et al., 2007) utilize supervised tools such 693 as a POS tagger and a shallow parser. Davidov et al. (2007) proposed a method for unsupervised discovery of concept-specific relations. That work, like ours, relies on pattern clusters. However, it requires initial word seeds and targets the discovery of relationships specific for some given concept, while we attempt to discover and define generic relationships that exist in the entire domain. Studying relationships between tagged named entities, (Hasegawa et al., 2004; Hassan et al., 2006) proposed unsupervised clustering methods that assign given sets of pairs into several clusters, where each cluster corresponds to one of a known set of relationship types. Their classification setting is thus very different from our unsupervised discovery one. Several recent papers discovered relations on the web using seed patterns (Pantel et al., 2004), rules (Etzioni et al., 2004), and word pairs (Pasca et al., 2006; Alfonseca et al., 2006). The latter used the notion of hook which we also use in this paper. Several studies utilize some preprocessing, including parsing (Hasegawa et al., 20</context>
</contexts>
<marker>Hassan, Hassan, Emam, 2006</marker>
<rawString>Hassan, H., Hassan, A. and Emam, O., 2006. Unsupervised information extraction approach using graph mutual reinforcement. EMNLP ’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<journal>COLING</journal>
<volume>92</volume>
<contexts>
<context position="2523" citStr="Hearst, 1992" startWordPosition="368" endWordPosition="369">ical relationships is a rather difficult task. Most established resources (e.g., WordNet) represent only the main and widely accepted relationships such as hypernymy and meronymy. However, there are many other useful relationships between concepts, such as noun-modifier and inter-verb relationships. Identifying and representing these explicitly can greatly assist various tasks and applications. There are already applications that utilize such knowledge (e.g., (Tatu and Moldovan, 2005) for textual entailment). One of the leading methods in semantics acquisition is based on patterns (see e.g., (Hearst, 1992; Pantel and Pennacchiotti, 2006)). The standard process for pattern-based relation extraction is to start with hand-selected patterns or word pairs expressing a particular relationship, and iteratively scan the corpus for co-appearances of word pairs in patterns and for patterns that contain known word pairs. This methodology is semi-supervised, requiring prespecification of the desired relationship or handcoding initial seed words or patterns. The method is quite successful, and examining its results in detail shows that concept relationships are often being manifested by several different p</context>
<context position="6497" citStr="Hearst, 1992" startWordPosition="985" endWordPosition="986">man (2005) automatically answers SAT tests, while our focus is on generating them. 6 present SAT and comparison evaluation results. 2 Related Work Extraction of relation information from text is a large sub-field in NLP. Major differences between pattern approaches include the relationship types sought (including domain restrictions), the degrees of supervision and required preprocessing, and evaluation method. 2.1 Relationship Types There is a large body of related work that deals with discovery of basic relationship types represented in useful resources such as WordNet, including hypernymy (Hearst, 1992; Pantel et al., 2004; Snow et al., 2006), synonymy (Davidov and Rappoport, 2006; Widdows and Dorow, 2002) and meronymy (Berland and Charniak, 1999; Girju et al., 2006). Since named entities are very important in NLP, many studies define and discover relations between named entities (Hasegawa et al., 2004; Hassan et al., 2006). Work was also done on relations between verbs (Chklovski and Pantel, 2004). There is growing research on relations between nominals (Moldovan et al., 2004; Girju et al., 2007). 2.2 Degree of Supervision and Preprocessing While numerous studies attempt to discover one or</context>
<context position="32025" citStr="Hearst, 1992" startWordPosition="5204" endWordPosition="5205">elated pairs belong to the same cluster. The column on the right shows the overlap between different clusters, measured as the average number of shared pairs in two randomly selected clusters. The baseline in this case is essentially 5, since there are more than 400 clusters for 5 word pairs. We see a very low overlap between assigned clusters, which shows that these clusters indeed separate well between defined relations. 6.2 Discovery of Known Pattern Sets We compared our clusters to lists of patterns reported as useful by previous papers. These lists included patterns expressing hypernymy (Hearst, 1992; Pantel et al., 2004), meronymy (Berland and Charniak, 1999; Girju et al., 2006), synonymy (Widdows and Dorow, 2002; Davidov and Rappoport, 2006), and verb strength + verb happensbefore (Chklovski and Pantel, 2004). In all cases, we discovered clusters containing all of the reported patterns (including their refinements with domainspecific prefix or postfix) and not containing patterns of competing relationships. 7 Conclusion We have proposed a novel way to define and identify generic lexical relationships as clusters of patterns. Each such cluster is set of patterns that can be used to ident</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Hearst, M., 1992. Automatic acquisition of hyponyms from large text corpora. COLING ’92</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
<author>P Pantel</author>
</authors>
<title>Concept discovery from text.</title>
<date>2002</date>
<journal>COLING</journal>
<volume>02</volume>
<contexts>
<context position="9825" citStr="Lin and Pantel, 2002" startWordPosition="1498" endWordPosition="1501">et al., 2004; Hassan et al., 2006) and usage of syntactic (Suchanek et al., 2006) and morphological (Pantel et al., 2004) information in patterns. Several algorithms use manuallyprepared resources, including WordNet (Moldovan et al., 2004; Costello et al., 2006) and Wikipedia (Strube and Ponzetto, 2006). In this paper, we do not utilize any language-specific preprocessing or any other resources, which makes our algorithm relatively easily portable between languages, as we demonstrate in our bilingual evaluation. 2.3 Evaluation Method Evaluation for hypernymy and synonymy usually uses WordNet (Lin and Pantel, 2002; Widdows and Dorow, 2002; Davidov and Rappoport, 2006). For more specific lexical relationships like relationships between verbs (Chklovski and Pantel, 2004), nominals (Girju et al., 2004; Girju et al., 2007) or meronymy subtypes (Berland and Charniak, 1999) there is still little agreement which important relationships should be defined. Thus, there are more than a dozen different type hierarchies and tasks proposed for noun compounds (and nominals in general), including (Nastase and Szpakowicz, 2003; Girju et al., 2005; Girju et al., 2007). There are thus two possible ways for a fair evaluat</context>
</contexts>
<marker>Lin, Pantel, 2002</marker>
<rawString>Lin, D., Pantel, P., 2002. Concept discovery from text. COLING 02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Moldovan</author>
<author>A Badulescu</author>
<author>M Tatu</author>
<author>D Antohe</author>
<author>u Gir</author>
<author>R</author>
</authors>
<title>Models for the semantic classification of noun phrases.</title>
<date>2004</date>
<booktitle>HLT-NAACL ’04 Workshop on Computational Lexical Semantics.</booktitle>
<contexts>
<context position="6981" citStr="Moldovan et al., 2004" startWordPosition="1060" endWordPosition="1063"> that deals with discovery of basic relationship types represented in useful resources such as WordNet, including hypernymy (Hearst, 1992; Pantel et al., 2004; Snow et al., 2006), synonymy (Davidov and Rappoport, 2006; Widdows and Dorow, 2002) and meronymy (Berland and Charniak, 1999; Girju et al., 2006). Since named entities are very important in NLP, many studies define and discover relations between named entities (Hasegawa et al., 2004; Hassan et al., 2006). Work was also done on relations between verbs (Chklovski and Pantel, 2004). There is growing research on relations between nominals (Moldovan et al., 2004; Girju et al., 2007). 2.2 Degree of Supervision and Preprocessing While numerous studies attempt to discover one or more pre-specified relationship types, very little previous work has directly attempted the discovery of which main types of generic relationships actually exist in an unrestricted domain. Turney (2006) provided a pattern distance measure that allows a fully unsupervised measurement of relational similarity between two pairs of words; such a measure could in principle be used by a clustering algorithm in order to deduce relationship types, but this was not discussed. Unlike (Tur</context>
<context position="9443" citStr="Moldovan et al., 2004" startWordPosition="1443" endWordPosition="1446">us very different from our unsupervised discovery one. Several recent papers discovered relations on the web using seed patterns (Pantel et al., 2004), rules (Etzioni et al., 2004), and word pairs (Pasca et al., 2006; Alfonseca et al., 2006). The latter used the notion of hook which we also use in this paper. Several studies utilize some preprocessing, including parsing (Hasegawa et al., 2004; Hassan et al., 2006) and usage of syntactic (Suchanek et al., 2006) and morphological (Pantel et al., 2004) information in patterns. Several algorithms use manuallyprepared resources, including WordNet (Moldovan et al., 2004; Costello et al., 2006) and Wikipedia (Strube and Ponzetto, 2006). In this paper, we do not utilize any language-specific preprocessing or any other resources, which makes our algorithm relatively easily portable between languages, as we demonstrate in our bilingual evaluation. 2.3 Evaluation Method Evaluation for hypernymy and synonymy usually uses WordNet (Lin and Pantel, 2002; Widdows and Dorow, 2002; Davidov and Rappoport, 2006). For more specific lexical relationships like relationships between verbs (Chklovski and Pantel, 2004), nominals (Girju et al., 2004; Girju et al., 2007) or meron</context>
</contexts>
<marker>Moldovan, Badulescu, Tatu, Antohe, Gir, R, 2004</marker>
<rawString>Moldovan, D., Badulescu, A., Tatu, M., Antohe, D.,Gir u, R., 2004. Models for the semantic classification of noun phrases. HLT-NAACL ’04 Workshop on Computational Lexical Semantics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Nastase</author>
<author>S Szpakowicz</author>
</authors>
<title>Exploring noun modifier semantic relations.</title>
<date>2003</date>
<pages>5</pages>
<contexts>
<context position="10331" citStr="Nastase and Szpakowicz, 2003" startWordPosition="1575" endWordPosition="1578">lingual evaluation. 2.3 Evaluation Method Evaluation for hypernymy and synonymy usually uses WordNet (Lin and Pantel, 2002; Widdows and Dorow, 2002; Davidov and Rappoport, 2006). For more specific lexical relationships like relationships between verbs (Chklovski and Pantel, 2004), nominals (Girju et al., 2004; Girju et al., 2007) or meronymy subtypes (Berland and Charniak, 1999) there is still little agreement which important relationships should be defined. Thus, there are more than a dozen different type hierarchies and tasks proposed for noun compounds (and nominals in general), including (Nastase and Szpakowicz, 2003; Girju et al., 2005; Girju et al., 2007). There are thus two possible ways for a fair evaluation. A study can develop its own relationship definitions and dataset, like (Nastase and Szpakowicz, 2003), thus introducing a possible bias; or it can accept the definition and dataset prepared by another work, like (Turney, 2006). However, this makes it impossible to work on new relationship types. Hence, when exploring very specific relationship types or very generic, but not widely accepted, types (like verb strength), many researchers resort to manual human-based evaluation (Chklovski and Pantel,</context>
<context position="30738" citStr="Nastase and Szpakowicz, 2003" startWordPosition="4983" endWordPosition="4986"> 1.4 0.01 English 1.2 0 Table 2: Patterns clusters discovery of known relationships. stances of relationships of the same type. 6 Evaluation Using Known Information We also evaluated our pattern clusters using relevant information reported in related work. 6.1 Discovery of Known Relationships To estimate recall of our pattern cluster set, we attempted to estimate whether (at least) a subset of known relationships have corresponding pattern clusters. As a testing subset, we have used 35 relationships for both English and Russian. 30 relations are noun compound relationships as proposed in the (Nastase and Szpakowicz, 2003) classification scheme, and 5 relations are verb-verb relations proposed by (Chklovski and Pantel, 2004). We have manually created sets of 5 unambiguous sample pairs for each of these 35 relationships. For each such pair we have assigned the pattern cluster with best HITS value. The middle column of Table 2 shows the average number of clusters per relationship. Ideally, if for each relationship all 5 pairs are assigned to the same cluster, the average would be 1. In the worst case, when each pair is assigned to a different cluster, the average would be 5. We can see that most of the pairs inde</context>
</contexts>
<marker>Nastase, Szpakowicz, 2003</marker>
<rawString>Nastase, V., Szpakowicz, S., 2003. Exploring noun modifier semantic relations. IWCS-5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Pantel</author>
<author>M Pennacchiotti</author>
</authors>
<title>Espresso: leveraging generic patterns for automatically harvesting semantic relations. COLING-ACL</title>
<date>2006</date>
<contexts>
<context position="2556" citStr="Pantel and Pennacchiotti, 2006" startWordPosition="370" endWordPosition="373">hips is a rather difficult task. Most established resources (e.g., WordNet) represent only the main and widely accepted relationships such as hypernymy and meronymy. However, there are many other useful relationships between concepts, such as noun-modifier and inter-verb relationships. Identifying and representing these explicitly can greatly assist various tasks and applications. There are already applications that utilize such knowledge (e.g., (Tatu and Moldovan, 2005) for textual entailment). One of the leading methods in semantics acquisition is based on patterns (see e.g., (Hearst, 1992; Pantel and Pennacchiotti, 2006)). The standard process for pattern-based relation extraction is to start with hand-selected patterns or word pairs expressing a particular relationship, and iteratively scan the corpus for co-appearances of word pairs in patterns and for patterns that contain known word pairs. This methodology is semi-supervised, requiring prespecification of the desired relationship or handcoding initial seed words or patterns. The method is quite successful, and examining its results in detail shows that concept relationships are often being manifested by several different patterns. In this paper, unlike th</context>
</contexts>
<marker>Pantel, Pennacchiotti, 2006</marker>
<rawString>Pantel, P., Pennacchiotti, M., 2006. Espresso: leveraging generic patterns for automatically harvesting semantic relations. COLING-ACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Pantel</author>
<author>D Ravichandran</author>
<author>E H Hovy</author>
</authors>
<title>Towards terascale knowledge acquisition.</title>
<date>2004</date>
<journal>COLING</journal>
<volume>04</volume>
<contexts>
<context position="6518" citStr="Pantel et al., 2004" startWordPosition="987" endWordPosition="990">omatically answers SAT tests, while our focus is on generating them. 6 present SAT and comparison evaluation results. 2 Related Work Extraction of relation information from text is a large sub-field in NLP. Major differences between pattern approaches include the relationship types sought (including domain restrictions), the degrees of supervision and required preprocessing, and evaluation method. 2.1 Relationship Types There is a large body of related work that deals with discovery of basic relationship types represented in useful resources such as WordNet, including hypernymy (Hearst, 1992; Pantel et al., 2004; Snow et al., 2006), synonymy (Davidov and Rappoport, 2006; Widdows and Dorow, 2002) and meronymy (Berland and Charniak, 1999; Girju et al., 2006). Since named entities are very important in NLP, many studies define and discover relations between named entities (Hasegawa et al., 2004; Hassan et al., 2006). Work was also done on relations between verbs (Chklovski and Pantel, 2004). There is growing research on relations between nominals (Moldovan et al., 2004; Girju et al., 2007). 2.2 Degree of Supervision and Preprocessing While numerous studies attempt to discover one or more pre-specified r</context>
<context position="8972" citStr="Pantel et al., 2004" startWordPosition="1367" endWordPosition="1370">rgets the discovery of relationships specific for some given concept, while we attempt to discover and define generic relationships that exist in the entire domain. Studying relationships between tagged named entities, (Hasegawa et al., 2004; Hassan et al., 2006) proposed unsupervised clustering methods that assign given sets of pairs into several clusters, where each cluster corresponds to one of a known set of relationship types. Their classification setting is thus very different from our unsupervised discovery one. Several recent papers discovered relations on the web using seed patterns (Pantel et al., 2004), rules (Etzioni et al., 2004), and word pairs (Pasca et al., 2006; Alfonseca et al., 2006). The latter used the notion of hook which we also use in this paper. Several studies utilize some preprocessing, including parsing (Hasegawa et al., 2004; Hassan et al., 2006) and usage of syntactic (Suchanek et al., 2006) and morphological (Pantel et al., 2004) information in patterns. Several algorithms use manuallyprepared resources, including WordNet (Moldovan et al., 2004; Costello et al., 2006) and Wikipedia (Strube and Ponzetto, 2006). In this paper, we do not utilize any language-specific prepro</context>
<context position="32047" citStr="Pantel et al., 2004" startWordPosition="5206" endWordPosition="5209">elong to the same cluster. The column on the right shows the overlap between different clusters, measured as the average number of shared pairs in two randomly selected clusters. The baseline in this case is essentially 5, since there are more than 400 clusters for 5 word pairs. We see a very low overlap between assigned clusters, which shows that these clusters indeed separate well between defined relations. 6.2 Discovery of Known Pattern Sets We compared our clusters to lists of patterns reported as useful by previous papers. These lists included patterns expressing hypernymy (Hearst, 1992; Pantel et al., 2004), meronymy (Berland and Charniak, 1999; Girju et al., 2006), synonymy (Widdows and Dorow, 2002; Davidov and Rappoport, 2006), and verb strength + verb happensbefore (Chklovski and Pantel, 2004). In all cases, we discovered clusters containing all of the reported patterns (including their refinements with domainspecific prefix or postfix) and not containing patterns of competing relationships. 7 Conclusion We have proposed a novel way to define and identify generic lexical relationships as clusters of patterns. Each such cluster is set of patterns that can be used to identify, classify or captu</context>
</contexts>
<marker>Pantel, Ravichandran, Hovy, 2004</marker>
<rawString>Pantel, P., Ravichandran, D. and Hovy, E.H., 2004. Towards terascale knowledge acquisition. COLING ’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pasca</author>
<author>D Lin</author>
<author>J Bigham</author>
<author>A Lifchits</author>
<author>A Jain</author>
</authors>
<title>Names and similarities on the web: fact extraction in the fast lane.</title>
<date>2006</date>
<journal>COLING-ACL</journal>
<volume>06</volume>
<contexts>
<context position="9038" citStr="Pasca et al., 2006" startWordPosition="1379" endWordPosition="1382">, while we attempt to discover and define generic relationships that exist in the entire domain. Studying relationships between tagged named entities, (Hasegawa et al., 2004; Hassan et al., 2006) proposed unsupervised clustering methods that assign given sets of pairs into several clusters, where each cluster corresponds to one of a known set of relationship types. Their classification setting is thus very different from our unsupervised discovery one. Several recent papers discovered relations on the web using seed patterns (Pantel et al., 2004), rules (Etzioni et al., 2004), and word pairs (Pasca et al., 2006; Alfonseca et al., 2006). The latter used the notion of hook which we also use in this paper. Several studies utilize some preprocessing, including parsing (Hasegawa et al., 2004; Hassan et al., 2006) and usage of syntactic (Suchanek et al., 2006) and morphological (Pantel et al., 2004) information in patterns. Several algorithms use manuallyprepared resources, including WordNet (Moldovan et al., 2004; Costello et al., 2006) and Wikipedia (Strube and Ponzetto, 2006). In this paper, we do not utilize any language-specific preprocessing or any other resources, which makes our algorithm relative</context>
</contexts>
<marker>Pasca, Lin, Bigham, Lifchits, Jain, 2006</marker>
<rawString>Pasca, M., Lin, D., Bigham, J., Lifchits A., Jain, A., 2006. Names and similarities on the web: fact extraction in the fast lane. COLING-ACL ’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Rosenfeld</author>
<author>R Feldman</author>
</authors>
<title>Clustering for unsupervised relation identification.</title>
<date>2007</date>
<journal>CIKM</journal>
<volume>07</volume>
<contexts>
<context position="7820" citStr="Rosenfeld and Feldman (2007)" startWordPosition="1190" endWordPosition="1193">scovery of which main types of generic relationships actually exist in an unrestricted domain. Turney (2006) provided a pattern distance measure that allows a fully unsupervised measurement of relational similarity between two pairs of words; such a measure could in principle be used by a clustering algorithm in order to deduce relationship types, but this was not discussed. Unlike (Turney, 2006), we do not perform any pattern ranking. Instead we produce (possibly overlapping) hard clusters, where each pattern cluster represents a relationship discovered in the domain. Banko et al. (2007) and Rosenfeld and Feldman (2007) find relationship instances where the relationships are not specified in advance. They aim to find relationship instances rather than identify generic semantic relationships. Thus, their representation is very different from ours. In addition, (Banko et al., 2007) utilize supervised tools such 693 as a POS tagger and a shallow parser. Davidov et al. (2007) proposed a method for unsupervised discovery of concept-specific relations. That work, like ours, relies on pattern clusters. However, it requires initial word seeds and targets the discovery of relationships specific for some given concept</context>
</contexts>
<marker>Rosenfeld, Feldman, 2007</marker>
<rawString>Rosenfeld, B., Feldman, R., 2007. Clustering for unsupervised relation identification. CIKM ’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Snow</author>
<author>D Jurafsky</author>
<author>A Y Ng</author>
</authors>
<title>Semantic taxonomy induction from heterogeneous evidence.</title>
<date>2006</date>
<journal>COLING-ACL</journal>
<volume>06</volume>
<contexts>
<context position="6538" citStr="Snow et al., 2006" startWordPosition="991" endWordPosition="994">T tests, while our focus is on generating them. 6 present SAT and comparison evaluation results. 2 Related Work Extraction of relation information from text is a large sub-field in NLP. Major differences between pattern approaches include the relationship types sought (including domain restrictions), the degrees of supervision and required preprocessing, and evaluation method. 2.1 Relationship Types There is a large body of related work that deals with discovery of basic relationship types represented in useful resources such as WordNet, including hypernymy (Hearst, 1992; Pantel et al., 2004; Snow et al., 2006), synonymy (Davidov and Rappoport, 2006; Widdows and Dorow, 2002) and meronymy (Berland and Charniak, 1999; Girju et al., 2006). Since named entities are very important in NLP, many studies define and discover relations between named entities (Hasegawa et al., 2004; Hassan et al., 2006). Work was also done on relations between verbs (Chklovski and Pantel, 2004). There is growing research on relations between nominals (Moldovan et al., 2004; Girju et al., 2007). 2.2 Degree of Supervision and Preprocessing While numerous studies attempt to discover one or more pre-specified relationship types, v</context>
</contexts>
<marker>Snow, Jurafsky, Ng, 2006</marker>
<rawString>Snow, R., Jurafsky, D., Ng, A.Y., 2006. Semantic taxonomy induction from heterogeneous evidence. COLING-ACL ’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Strube</author>
<author>S Ponzetto</author>
</authors>
<title>WikiRelate! computing semantic relatedness using Wikipedia.</title>
<date>2006</date>
<journal>AAAI</journal>
<volume>06</volume>
<contexts>
<context position="9509" citStr="Strube and Ponzetto, 2006" startWordPosition="1453" endWordPosition="1456">l recent papers discovered relations on the web using seed patterns (Pantel et al., 2004), rules (Etzioni et al., 2004), and word pairs (Pasca et al., 2006; Alfonseca et al., 2006). The latter used the notion of hook which we also use in this paper. Several studies utilize some preprocessing, including parsing (Hasegawa et al., 2004; Hassan et al., 2006) and usage of syntactic (Suchanek et al., 2006) and morphological (Pantel et al., 2004) information in patterns. Several algorithms use manuallyprepared resources, including WordNet (Moldovan et al., 2004; Costello et al., 2006) and Wikipedia (Strube and Ponzetto, 2006). In this paper, we do not utilize any language-specific preprocessing or any other resources, which makes our algorithm relatively easily portable between languages, as we demonstrate in our bilingual evaluation. 2.3 Evaluation Method Evaluation for hypernymy and synonymy usually uses WordNet (Lin and Pantel, 2002; Widdows and Dorow, 2002; Davidov and Rappoport, 2006). For more specific lexical relationships like relationships between verbs (Chklovski and Pantel, 2004), nominals (Girju et al., 2004; Girju et al., 2007) or meronymy subtypes (Berland and Charniak, 1999) there is still little ag</context>
</contexts>
<marker>Strube, Ponzetto, 2006</marker>
<rawString>Strube, M., Ponzetto, S., 2006. WikiRelate! computing semantic relatedness using Wikipedia. AAAI ’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Suchanek</author>
<author>G Ifrim</author>
<author>G Weikum</author>
</authors>
<title>LEILA: learning to extract information by linguistic analysis.</title>
<date>2006</date>
<booktitle>COLING-ACL ’06 Ontology Learning &amp; Population Workshop.</booktitle>
<contexts>
<context position="9286" citStr="Suchanek et al., 2006" startWordPosition="1421" endWordPosition="1424">sign given sets of pairs into several clusters, where each cluster corresponds to one of a known set of relationship types. Their classification setting is thus very different from our unsupervised discovery one. Several recent papers discovered relations on the web using seed patterns (Pantel et al., 2004), rules (Etzioni et al., 2004), and word pairs (Pasca et al., 2006; Alfonseca et al., 2006). The latter used the notion of hook which we also use in this paper. Several studies utilize some preprocessing, including parsing (Hasegawa et al., 2004; Hassan et al., 2006) and usage of syntactic (Suchanek et al., 2006) and morphological (Pantel et al., 2004) information in patterns. Several algorithms use manuallyprepared resources, including WordNet (Moldovan et al., 2004; Costello et al., 2006) and Wikipedia (Strube and Ponzetto, 2006). In this paper, we do not utilize any language-specific preprocessing or any other resources, which makes our algorithm relatively easily portable between languages, as we demonstrate in our bilingual evaluation. 2.3 Evaluation Method Evaluation for hypernymy and synonymy usually uses WordNet (Lin and Pantel, 2002; Widdows and Dorow, 2002; Davidov and Rappoport, 2006). For </context>
</contexts>
<marker>Suchanek, Ifrim, Weikum, 2006</marker>
<rawString>Suchanek, F., Ifrim, G., and Weikum, G., 2006. LEILA: learning to extract information by linguistic analysis. COLING-ACL ’06 Ontology Learning &amp; Population Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Tatu</author>
<author>D Moldovan</author>
</authors>
<title>A semantic approach to recognizing textual entailment. HLT/EMNLP</title>
<date>2005</date>
<contexts>
<context position="2400" citStr="Tatu and Moldovan, 2005" startWordPosition="346" endWordPosition="349">tively good agreement as to what concepts are and which concepts should exist in a lexical resource, identifying types of important lexical relationships is a rather difficult task. Most established resources (e.g., WordNet) represent only the main and widely accepted relationships such as hypernymy and meronymy. However, there are many other useful relationships between concepts, such as noun-modifier and inter-verb relationships. Identifying and representing these explicitly can greatly assist various tasks and applications. There are already applications that utilize such knowledge (e.g., (Tatu and Moldovan, 2005) for textual entailment). One of the leading methods in semantics acquisition is based on patterns (see e.g., (Hearst, 1992; Pantel and Pennacchiotti, 2006)). The standard process for pattern-based relation extraction is to start with hand-selected patterns or word pairs expressing a particular relationship, and iteratively scan the corpus for co-appearances of word pairs in patterns and for patterns that contain known word pairs. This methodology is semi-supervised, requiring prespecification of the desired relationship or handcoding initial seed words or patterns. The method is quite success</context>
</contexts>
<marker>Tatu, Moldovan, 2005</marker>
<rawString>Tatu, M., Moldovan, D., 2005. A semantic approach to recognizing textual entailment. HLT/EMNLP 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Turney</author>
</authors>
<title>Measuring semantic similarity by latent relational analysis.</title>
<date>2005</date>
<journal>IJCAI</journal>
<volume>05</volume>
<contexts>
<context position="27735" citStr="Turney, 2005" startWordPosition="4497" endWordPosition="4498">ters distinguish between different relationships, because the three pairs not expressing the same relationship as the header were not selected by the evaluators. Third, our cluster labeling algorithm produces results that are usable by people. The test was performed in both English and Russian, with 10 (6) subjects for English (Russian). The subjects (biology and CS students) were not involved with the research, did not see the clusters, and did not receive any special training as preparation. Inter-subject agreement and Kappa were 0.82, 0.72 (0.9, 0.78) for English (Russian). As reported in (Turney, 2005), an average high-school SAT grade is 57. Table 1 shows the final English and Rus4But note that a pair can certainly obtain a positive HITS value for several clusters. Our method Real SAT Correlation English 80% 71% 0.85 Russian 83% 79% 0.88 Table 1: Pattern cluster evaluation using automatically generated SAT analogy choice questions. sian grade average for ours and real SAT questions. We can see that for both languages, around 80% of the choices were correct (the random choice baseline is 20%). Our subjects are university students, so results higher than 57 are expected, as we can see from r</context>
</contexts>
<marker>Turney, 2005</marker>
<rawString>Turney, P., 2005. Measuring semantic similarity by latent relational analysis. IJCAI ’05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Turney</author>
<author>M Littman</author>
</authors>
<title>Corpus-based learning of analogies and semantic selations.</title>
<date>2005</date>
<booktitle>Machine Learning(60):1–3:251–278.</booktitle>
<contexts>
<context position="5895" citStr="Turney and Littman (2005)" startWordPosition="895" endWordPosition="898"> known noun-compound and verb-verb relationships. In the present paper we focus on the pattern cluster resource itself and how to evaluate its intrinsic quality. In (Davidov and Rappoport, 2008) we show how to use the resource for a known task of a totally different nature, classification of relationships between nominals (based on annotated data), obtaining superior results over previous work. Section 2 discusses related work, and Section 3 presents the pattern clustering and labeling algorithm. Section 4 describes the corpora we used and the algorithm’s parameters in detail. Sections 5 and 1Turney and Littman (2005) automatically answers SAT tests, while our focus is on generating them. 6 present SAT and comparison evaluation results. 2 Related Work Extraction of relation information from text is a large sub-field in NLP. Major differences between pattern approaches include the relationship types sought (including domain restrictions), the degrees of supervision and required preprocessing, and evaluation method. 2.1 Relationship Types There is a large body of related work that deals with discovery of basic relationship types represented in useful resources such as WordNet, including hypernymy (Hearst, 19</context>
</contexts>
<marker>Turney, Littman, 2005</marker>
<rawString>Turney, P., Littman, M., 2005. Corpus-based learning of analogies and semantic selations. Machine Learning(60):1–3:251–278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Turney</author>
</authors>
<title>Expressing implicit semantic relations without supervision.</title>
<date>2006</date>
<journal>COLING-ACL</journal>
<volume>06</volume>
<contexts>
<context position="7300" citStr="Turney (2006)" startWordPosition="1109" endWordPosition="1110"> are very important in NLP, many studies define and discover relations between named entities (Hasegawa et al., 2004; Hassan et al., 2006). Work was also done on relations between verbs (Chklovski and Pantel, 2004). There is growing research on relations between nominals (Moldovan et al., 2004; Girju et al., 2007). 2.2 Degree of Supervision and Preprocessing While numerous studies attempt to discover one or more pre-specified relationship types, very little previous work has directly attempted the discovery of which main types of generic relationships actually exist in an unrestricted domain. Turney (2006) provided a pattern distance measure that allows a fully unsupervised measurement of relational similarity between two pairs of words; such a measure could in principle be used by a clustering algorithm in order to deduce relationship types, but this was not discussed. Unlike (Turney, 2006), we do not perform any pattern ranking. Instead we produce (possibly overlapping) hard clusters, where each pattern cluster represents a relationship discovered in the domain. Banko et al. (2007) and Rosenfeld and Feldman (2007) find relationship instances where the relationships are not specified in advanc</context>
<context position="10656" citStr="Turney, 2006" startWordPosition="1632" endWordPosition="1633">ymy subtypes (Berland and Charniak, 1999) there is still little agreement which important relationships should be defined. Thus, there are more than a dozen different type hierarchies and tasks proposed for noun compounds (and nominals in general), including (Nastase and Szpakowicz, 2003; Girju et al., 2005; Girju et al., 2007). There are thus two possible ways for a fair evaluation. A study can develop its own relationship definitions and dataset, like (Nastase and Szpakowicz, 2003), thus introducing a possible bias; or it can accept the definition and dataset prepared by another work, like (Turney, 2006). However, this makes it impossible to work on new relationship types. Hence, when exploring very specific relationship types or very generic, but not widely accepted, types (like verb strength), many researchers resort to manual human-based evaluation (Chklovski and Pantel, 2004). In our case, where relationship types are not specified in advance, creating an unbiased benchmark is very problematic, so we rely on human subjects for relationship evaluation. 3 Pattern Clustering Algorithm Our algorithm first discovers and clusters patterns in which a single (‘hook’) word participates, and then m</context>
</contexts>
<marker>Turney, 2006</marker>
<rawString>Turney, P., 2006. Expressing implicit semantic relations without supervision. COLING-ACL ’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Widdows</author>
<author>B Dorow</author>
</authors>
<title>A graph model for unsupervised lexical acquisition.</title>
<date>2002</date>
<journal>COLING</journal>
<volume>02</volume>
<contexts>
<context position="6603" citStr="Widdows and Dorow, 2002" startWordPosition="1000" endWordPosition="1003">AT and comparison evaluation results. 2 Related Work Extraction of relation information from text is a large sub-field in NLP. Major differences between pattern approaches include the relationship types sought (including domain restrictions), the degrees of supervision and required preprocessing, and evaluation method. 2.1 Relationship Types There is a large body of related work that deals with discovery of basic relationship types represented in useful resources such as WordNet, including hypernymy (Hearst, 1992; Pantel et al., 2004; Snow et al., 2006), synonymy (Davidov and Rappoport, 2006; Widdows and Dorow, 2002) and meronymy (Berland and Charniak, 1999; Girju et al., 2006). Since named entities are very important in NLP, many studies define and discover relations between named entities (Hasegawa et al., 2004; Hassan et al., 2006). Work was also done on relations between verbs (Chklovski and Pantel, 2004). There is growing research on relations between nominals (Moldovan et al., 2004; Girju et al., 2007). 2.2 Degree of Supervision and Preprocessing While numerous studies attempt to discover one or more pre-specified relationship types, very little previous work has directly attempted the discovery of </context>
<context position="9850" citStr="Widdows and Dorow, 2002" startWordPosition="1502" endWordPosition="1505">t al., 2006) and usage of syntactic (Suchanek et al., 2006) and morphological (Pantel et al., 2004) information in patterns. Several algorithms use manuallyprepared resources, including WordNet (Moldovan et al., 2004; Costello et al., 2006) and Wikipedia (Strube and Ponzetto, 2006). In this paper, we do not utilize any language-specific preprocessing or any other resources, which makes our algorithm relatively easily portable between languages, as we demonstrate in our bilingual evaluation. 2.3 Evaluation Method Evaluation for hypernymy and synonymy usually uses WordNet (Lin and Pantel, 2002; Widdows and Dorow, 2002; Davidov and Rappoport, 2006). For more specific lexical relationships like relationships between verbs (Chklovski and Pantel, 2004), nominals (Girju et al., 2004; Girju et al., 2007) or meronymy subtypes (Berland and Charniak, 1999) there is still little agreement which important relationships should be defined. Thus, there are more than a dozen different type hierarchies and tasks proposed for noun compounds (and nominals in general), including (Nastase and Szpakowicz, 2003; Girju et al., 2005; Girju et al., 2007). There are thus two possible ways for a fair evaluation. A study can develop </context>
<context position="32141" citStr="Widdows and Dorow, 2002" startWordPosition="5220" endWordPosition="5223">ters, measured as the average number of shared pairs in two randomly selected clusters. The baseline in this case is essentially 5, since there are more than 400 clusters for 5 word pairs. We see a very low overlap between assigned clusters, which shows that these clusters indeed separate well between defined relations. 6.2 Discovery of Known Pattern Sets We compared our clusters to lists of patterns reported as useful by previous papers. These lists included patterns expressing hypernymy (Hearst, 1992; Pantel et al., 2004), meronymy (Berland and Charniak, 1999; Girju et al., 2006), synonymy (Widdows and Dorow, 2002; Davidov and Rappoport, 2006), and verb strength + verb happensbefore (Chklovski and Pantel, 2004). In all cases, we discovered clusters containing all of the reported patterns (including their refinements with domainspecific prefix or postfix) and not containing patterns of competing relationships. 7 Conclusion We have proposed a novel way to define and identify generic lexical relationships as clusters of patterns. Each such cluster is set of patterns that can be used to identify, classify or capture new instances of some unspecified semantic relationship. We showed how such pattern cluster</context>
</contexts>
<marker>Widdows, Dorow, 2002</marker>
<rawString>Widdows, D., Dorow, B., 2002. A graph model for unsupervised lexical acquisition. COLING ’02.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>