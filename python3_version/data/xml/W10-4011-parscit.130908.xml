<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000011">
<title confidence="0.9864855">
More Languages, More MAP?: A Study of Multiple Assisting Languages
in Multilingual PRF
</title>
<author confidence="0.992481">
Vishal Vachhani Manoj K. Chinnakotla Mitesh M. Khapra Pushpak Bhattacharyya
</author>
<affiliation confidence="0.999184">
Department of Computer Science and Engineering,
Indian Institute of Technology Bombay
</affiliation>
<email confidence="0.992861">
{vishalv,manoj,miteshk,pb}@cse.iitb.ac.in
</email>
<sectionHeader confidence="0.99738" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.995321333333334">
Multilingual Pseudo-Relevance Feedback
(MultiPRF) is a framework to improve
the PRF of a source language by taking
the help of another language called as-
sisting language. In this paper, we ex-
tend the MultiPRF framework to include
multiple assisting languages. We consider
three different configurations to incorpo-
rate multiple assisting languages - a) Par-
allel - all assisting languages combined
simultaneously b) Serial - assisting lan-
guages combined in sequence one after
another and c) Selective - dynamically se-
lecting the best feedback model for each
query. We study their effect on MultiPRF
performance. Results using multiple as-
sisting languages are mixed and it helps in
boosting MultiPRF accuracy only in some
cases. We also observe that MultiPRF be-
comes more robust with increase in num-
ber of assisting languages.
</bodyText>
<sectionHeader confidence="0.999466" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999646185185185">
Pseudo-Relevance Feedback (PRF) (Buckley et
al., 1994; Xu and Croft, 2000; Mitra et al., 1998)
is known to be an effective technique to im-
prove the effectiveness of Information Retrieval
(IR) systems. In PRF, the top ‘k’ documents
from the ranked list retrieved using the initial key-
word query are assumed to be relevant. Later,
these documents are used to refine the user query
and the final ranked list is obtained using the
above refined query. Although PRF has been
shown to improve retrieval, it suffers from the
following drawbacks: (a) Lexical and Semantic
Non-Inclusion: the type of term associations ob-
tained for query expansion is restricted to only
co-occurrence based relationships in the feedback
documents and (b) Lack of Robustness: due to
the inherent assumption in PRF, i.e., relevance
of top k documents, performance is sensitive to
that of the initial retrieval algorithm and as a re-
sult is not robust. Typically, larger coverage en-
sures higher proportion of relevant documents in
the top k retrieval (Hawking et al., 1999). How-
ever, some resource-constrained languages do not
have adequate information coverage in their own
language. For example, languages like Hungarian
and Finnish have meager online content in their
own languages.
</bodyText>
<subsubsectionHeader confidence="0.511368">
Multilingual Pseudo-Relevance Feedback
</subsubsectionHeader>
<bodyText confidence="0.999327521739131">
(MultiPRF) (Chinnakotla et al., 2010a) is a
novel framework for PRF to overcome the above
limitations of PRF. It does so by taking the help of
a different language called the assisting language.
Thus, the performance of a resource-constrained
language could be improved by harnessing the
good coverage of another language. MulitiPRF
showed significant improvements on standard
CLEF collections (Braschler and Peters, 2004)
over state-of-art PRF system. On the web, each
language has its own exclusive topical coverage
besides sharing a large number of common topics
with other languages. For example, information
about Saudi Arabia government policies and
regulations is more likely to be found in Arabic
language web and also information about a local
event in Spain is more likely to be covered in
Spanish web than in English. Hence, using
multiple languages in conjunction is more likely
to ensure satisfaction of the user information need
and hence will be more robust.
In this paper, we extend the MultiPRF frame-
work to multiple assisting languages. We study
</bodyText>
<page confidence="0.977968">
70
</page>
<note confidence="0.6853205">
Proceedings of the 4th International Workshop on Cross Lingual Information Access at COLING 2010, pages 70–78,
Beijing, August 2010
</note>
<bodyText confidence="0.999900925925926">
the various possible ways of combining the mod-
els learned from multiple assisting languages. We
propose three different configurations for includ-
ing multiple assisting languages in MultiPRF - a)
Parallel b) Serial and c) Selective. In Parallel com-
bination, all the assisting languages are combined
simultaneously using interpolation. In Serial con-
figuration, the assisting languages are applied in
sequence one after another and finally, in Selec-
tive configuration, the best feedback model is dy-
namically chosen for each query. We experiment
with each of the above configurations and present
both quantitative and qualitative analysis of the re-
sults. Results using multiple assisting languages
are mixed and it helps in boosting MultiPRF ac-
curacy only in some cases. We also observe that
MultiPRF becomes more robust with increase in
number of assisting languages. Besides, we also
study the relation between number of assisting
languages, coverage and the MultiPRF accuracy.
The paper is organized as follows: Section 2,
explains the Language Modeling (LM) based PRF
approach. Section 3, describes the MultiPRF ap-
proach. Section 4 explains the various configu-
rations to extend MultiPRF for multiple assisting
languages. Section 6 presents the results and dis-
cussions. Finally, Section 7 concludes the paper.
</bodyText>
<sectionHeader confidence="0.741693" genericHeader="introduction">
2 PRF in the LM Framework
</sectionHeader>
<bodyText confidence="0.999619444444444">
The Language Modeling (LM) Framework allows
PRF to be modeled in a principled manner. In the
LM approach, documents and queries are mod-
eled using multinomial distribution over words
called document language model P(w|D) and
query language model P(w|ΘQ) respectively. For
a given query, the document language models are
ranked based on their proximity to the query lan-
guage model, measured using KL-Divergence.
</bodyText>
<equation confidence="0.998956">
P (w|ΘQ)
P(w|ΘQ) · log P (w|D)
</equation>
<bodyText confidence="0.999694857142857">
Since the query length is short, it is difficult to es-
timate ΘQ accurately using the query alone. In
PRF, the top k documents obtained through the
initial ranking algorithm are assumed to be rele-
vant and used as feedback for improving the es-
timation of ΘQ. The feedback documents con-
tain both relevant and noisy terms from which
</bodyText>
<figure confidence="0.4815525">
Symbol Description
®Q Query Language Model
®� Feedback Language Model obtained from PRF in L1
L1
®� Feedback Language Model obtained from PRF in L2
L2
®� �698 Feedback Model Translated from L2 to L1
L1
t(f|e) Probabilistic Bi-Lingual Dictionary from L2 to L1
β, ry Interpolation coefficients coefficients used in MultiPRF
</figure>
<tableCaption confidence="0.995863">
Table 1: Glossary of Symbols used in explaining MultiPRF
</tableCaption>
<bodyText confidence="0.997698666666667">
the feedback language model is inferred based on
a Generative Mixture Model (Zhai and Lafferty,
2001).
Let DF = {d1, d2, ... , dk} be the top k doc-
uments retrieved using the initial ranking algo-
rithm. Zhai and Lafferty (Zhai and Lafferty, 2001)
model the feedback document set DF as a mixture
of two distributions: (a) the feedback language
model and (b) the collection model P(w|C). The
feedback language model is inferred using the EM
Algorithm (Dempster et al., 1977), which itera-
tively accumulates probability mass on the most
distinguishing terms, i.e. terms which are more
frequent in the feedback document set than in the
entire collection. To maintain query focus the fi-
nal converged feedback model, ΘF is interpolated
with the initial query model ΘQ to obtain the final
query model ΘFinal.
</bodyText>
<equation confidence="0.890862">
ΘFinal = (1 − α) · ΘQ + α · ΘF
</equation>
<bodyText confidence="0.9998208">
ΘFinal is used to re-rank the corpus using the
KL-Divergence ranking function to obtain the fi-
nal ranked list of documents. Henceforth, we refer
to the above technique as Model Based Feedback
(MBF).
</bodyText>
<sectionHeader confidence="0.842299" genericHeader="method">
3 Multilingual Pseudo-Relevance
Feedback (MultiPRF)
</sectionHeader>
<bodyText confidence="0.999793923076923">
Chinnakotla et al. (Chinnakotla et al., 2010a;
Chinnakotla et al., 2010b) propose the MultiPRF
approach which overcomes the fundamental limi-
tations of PRF with the help of an assisting collec-
tion in a different language. Given a query Q in
the source language L1, it is automatically trans-
lated into the assisting language L2. The docu-
ments in the L2 collection are ranked using the
query likelihood ranking function (John Lafferty
and Chengxiang Zhai, 2003). Using the top k doc-
uments, they estimate the feedback model using
MBF as described in the previous section. Simi-
larly, they also estimate a feedback model using
</bodyText>
<equation confidence="0.978606666666667">
�
KL(ΘQ||D) =
w
</equation>
<page confidence="0.978863">
71
</page>
<bodyText confidence="0.999904833333333">
The probabilistic bi-lingual dictionary t(f|e) is
learned from a parallel sentence-aligned corpora
in L1 − L2 based on word level alignments. The
probabilistic bi-lingual dictionary acts as a rich
source of morphologically and semantically re-
lated feedback terms. Thus, the translation model
adds related terms in L1 which have their source
as the term from feedback model ΘFL2. The final
MultiPRF model is obtained by interpolating the
above translated feedback model with the original
query model and the feedback model of language
L1 as given below:
</bodyText>
<equation confidence="0.994059333333333">
ΘMulti
L1 = (1 − β − γ) · ΘQ + β · ΘF L1 + γ · ΘTrans
L1 (2)
</equation>
<bodyText confidence="0.9898934">
In order to retain the query focus during back
translation, the feedback model in L2 is interpo-
lated with the translated query before translation
of the L2 feedback model. The parameters β and
γ control the relative importance of the original
query model, feedback model of L1 and the trans-
lated feedback model obtained from L1 and are
tuned based on the choice of L1 and L2.
the original query and the top k documents re-
trieved from the initial ranking in L1. Let the re-
sultant feedback models be ΘF L2 and ΘFL1 respec-
tively. The feedback model estimated in the as-
sisting language ΘF L2 is translated back into lan-
guage L1 using a probabilistic bi-lingual dictio-
nary t(f|e) from L2 → L1 as follows:
</bodyText>
<equation confidence="0.96077325">
�
P (f|ΘT rans
L1 ) =
∀ e in L2
</equation>
<sectionHeader confidence="0.881187" genericHeader="method">
4 Extending MultiPRF to Multiple
Assisting Languages
</sectionHeader>
<bodyText confidence="0.999703909090909">
In this section, we extend the MultiPRF model
described earlier to multiple assisting languages.
Since each language produces a different feed-
back model, there could be different ways of com-
bining these models as suggested below.
Parallel: One way is to include the new assist-
ing language model using one more interpo-
lation coefficient which gives the effect of us-
ing multiple assisting languages in parallel.
Serial: Alternately, we can have a serial combi-
nation wherein language L2 is first assisted
</bodyText>
<figureCaption confidence="0.998496">
Figure 1: Schematic of the Multilingual PRF Approach Us-
ing Parallel Assistance
Figure 2: Schematic of the Multilingual PRF Approach Us-
ing Serial Assistance
</figureCaption>
<bodyText confidence="0.999597285714286">
by language L3 and then this MultiPRF sys-
tem is used to assist the source language L1.
Selective: Finally, we can have selective assis-
tance wherein we dynamically select which
assisting language to use based on the input
query.
Below we describe each of these systems in detail.
</bodyText>
<subsectionHeader confidence="0.995034">
4.1 Parallel Combination
</subsectionHeader>
<bodyText confidence="0.999984142857143">
The MultiPRF model as explained in section 3 in-
terpolates the query model of L1 with the MBF
of L1 and the translated feedback model of the
assisting language L2. The most natural exten-
sion to this approach is to translate the query into
multiple languages instead of a single language
and collect the feedback terms from the initial re-
</bodyText>
<figure confidence="0.989210991304348">
Relevance Model
Translation
Final Ranked List
Of Documents in L
Query in L Translated Query
to L1
Relevance Model
Translation
Initial Retrieval
(LM Based Query
Likelihood)
Initial Retrieval
(LM Based Query Likelihood)
Initial
Retrieval
Translated Query
to Ln
L Index
Top ‘k’
Results
Top ‘k’
Results
L1 Index
Top ‘k’
Results
Ln
Index
PRF
(Model Based
Feedback)
PRF
(Model Based
Feedback)
PRF
(Model Based
Feedback)
Feedback Model θL
Feedback Model θL1
Feedback Model θLn
Query
Model
θQ
KL-Divergence
Ranking Function
Feedback
Model
Interpolation
Probabilistic
Dictionary
L1 → L
Probabilistic
Dictionary
Ln→ L
Query
Model
θQ
L Index
Feedback Model θL
KL-Divergence
Ranking
Function
Initial Retrieval
Algorithm
(LM Based Query
Likelihood)
Feedback
Model
Interpolation
PRF
(Model Based
Feedback)
Top &amp;quot;�’
Results
L1 Index
PRF
(Model Based Feedback)
Relevance Model
Translation
Feedback Model θL1
Query in L1
Initial Retrieval
lgorithm
(LM ABased
Qu
ery
Likelihood)
Top &amp;quot;�’ Results
Feedback
Model
Interpolation
PRF
(Model Based
Feedback)
Probabilistic
Dictionary
L1 → L
Top &amp;quot; esults
Feedback Model θL2
Query in L2
PRF
(Model Based Feedback)
Relevance Model
Translation
Initial Retrieval
Algorithm
(LM Based Query
Likelihood)
Top &amp;quot;�’ Results
KL Divergence
Ranking
Probabilistic
Dictionary
L2 → L1
L2 Index
t(f|e) · P(e|ΘFL2) (1)
</figure>
<page confidence="0.98359">
72
</page>
<table confidence="0.9994351">
Language CLEF Collection Description No. of No. of Unique CLEF Topics (No. of Topics)
Identifier Documents Terms
English EN-02+03 LA Times 94, Glasgow Herald 95 169477 234083 91-200 (67)
French FR-02+03 Le Monde 94, French SDA 94-95 129806 182214 91-200 (67)
German DE-02+03 294809 867072 91-200 (67)
Frankfurter Rundschau 94, Der Spiegel 94-95,
German SDA 94-95
Finnish FI-02+03 Aamulehti 94-95 55344 531160 91-200 (67)
Dutch NL-02+03 NRC Handelsblad 94-95, Algemeen Dagblad 94-95 190604 575582 91-200 (67)
Spanish ES-02+03 EFE 94, EFE 95 454045 340250 91-200 (67)
</table>
<tableCaption confidence="0.997525">
Table 2: Details of the CLEF Datasets used for Evaluating the MultiPRF approach. The number shown in brackets of the final
column CLEF Topics indicate the actual number of topics used during evaluation.
</tableCaption>
<bodyText confidence="0.99961125">
trieval of each of these languages. The translated
feedback models resulting from each of these re-
trievals can then be interpolated to get the final
parallel MultiPRF model. Specifically, if L1 is the
source language and L2, L3,... Ln are assisting
languages then final parallel MultiPRF model can
be obtained by generalizing Equation 2 as shown
below:
</bodyText>
<equation confidence="0.98878475">
X
ΘMultiAssist = (1 − β −
L1
i
</equation>
<bodyText confidence="0.9992">
The schematic representation of parallel combina-
tion is shown in Figure 1.
</bodyText>
<subsectionHeader confidence="0.991979">
4.2 Serial Combination
</subsectionHeader>
<bodyText confidence="0.999945">
Let L1 be the source language and let L2 and L3
be two assisting languages. A serial combination
can then be achieved by cascading two MultiPRF
systems as described below:
</bodyText>
<listItem confidence="0.923002857142857">
1. Construct a MultiPRF system with L2 as
the source language and L3 as the assist-
ing language. We call this system as L2L3-
MultiPRF system.
2. Next, construct a MultiPRF system with L1
as the source language and L2L3-MultiPRF
as the assisting system.
</listItem>
<bodyText confidence="0.9999709">
As compared to a single assistance system where
only L2 is used as the assisting language for
L1, here the performance of language L2 is first
boosted using L3 as the assisting language. This
boosted system is then used for assisting L1. Also
note that unlike parallel assistance here we do
not introduce an extra interpolation co-efficient in
the original MultiPRF model given in Equation 2.
The schematic representation of serial combina-
tion is shown in Figure 2.
</bodyText>
<subsectionHeader confidence="0.99867">
4.3 Selective Assistance
</subsectionHeader>
<bodyText confidence="0.999984933333333">
We motivate selective assistance by posing the
following question: “Given a source language
L1 and two assisting languages L2 and L3, is
it possible that L2 is ideal for assisting some
queries whereas L3 is ideal for assisting some
other queries?” For example, suppose L2 has a
rich collection of TOURISM documents whereas
L3 has a rich collection of HEALTH documents.
Now, given a query pertaining to TOURISM do-
main one might expect L2 to serve as a better as-
sisting language whereas given a query pertaining
to the HEALTH domain one might expect L3 to
serve as a better assisting language. This intuition
can be captured by suitably changing the interpo-
lation model as shown below:
</bodyText>
<equation confidence="0.998477">
ΘBest = SelectBestModel(ΘF L, ΘT rans
L1 , ΘT rans
L2 , ΘT rans
L L12 )
ΘMulti = (1 − α) · ΘQ + α · ΘBest (4)
L1 L
</equation>
<bodyText confidence="0.999177">
where, SelectBestModel() gives the best
model for a particular query using the algorithm
mentioned below which is based on minimizing
the query drift as described in (?):
</bodyText>
<listItem confidence="0.936128285714286">
1. Obtain the four feedback models, viz.,
OF OTransOTransOTrans
L, L1 , L2 , L12
2. Build a language model (say, LM) using
query Q and top-100 documents of initial re-
trieval in language L.
3. Find the KL-Divergence between LM and
the four models obtained during step 1.
4. Select the model which has minimum KL-
Divergence score from LM. Call this model
OBest
L .
5. Get the final model by interpolating the
query model, OQ, with O
</listItem>
<equation confidence="0.8724648">
Xαi) · ΘQ + β · ΘF + αi · ΘT rans Li
i
(3)
Best
L .
</equation>
<page confidence="0.995743">
73
</page>
<sectionHeader confidence="0.998495" genericHeader="method">
5 Experimental Setup
</sectionHeader>
<bodyText confidence="0.999870680851064">
We evaluate the performance of our system us-
ing the standard CLEF evaluation data in six lan-
guages, widely varying in their familial relation-
ships - Dutch, German, English, French, Spanish
and Finnish. The details of the collections and
their corresponding topics used for MultiPRF are
given in Table 2. Note that, in each experiment,
we choose assisting collections such that the top-
ics in the source language are covered in the as-
sisting collection so as to get meaningful feedback
terms. In all the topics, we only use the title field.
We ignore the topics which have no relevant docu-
ments as the true performance on those topics can-
not be evaluated.
We use the Terrier IR platform (Ounis et al.,
2005) for indexing the documents. We perform
standard tokenization, stop word removal and
stemming. We use the Porter Stemmer for English
and the stemmers available through the Snowball
package for other languages. Other than these,
we do not perform any language-specific process-
ing on the languages. In case of French, since
some function words like l’, d’ etc., occur as pre-
fixes to a word, we strip them off during index-
ing and query processing, since it significantly im-
proves the baseline performance. We use standard
evaluation measures like MAP, P@S and P@10
for evaluation. Additionally, for assessing robust-
ness, we use the Geometric Mean Average Preci-
sion (GMAP) metric (Robertson, 2006) which is
also used in the TREC Robust Track (Voorhees,
2006). The probabilistic bi-lingual dictionary
used in MultiPRF was learnt automatically by run-
ning GIZA++: a word alignment tool (Och and
Ney, 2003) on a parallel sentence aligned corpora.
For all the above language pairs we used the Eu-
roparl Corpus (Philipp, 2005). We use Google
Translate as the query translation system as it has
been shown to perform well for the task (Wu et
al., 2008). We use two-stage Dirichlet smooth-
ing with the optimal parameters tuned based on
the collection (Zhai and Lafferty, 2004). We tune
the parameters of MBF, specifically A and α, and
choose the values which give the optimal perfor-
mance on a given collection. We observe that the
optimal parameters γ and β are uniform across
collections and vary in the range 0.4-0.48. We
</bodyText>
<table confidence="0.999897295454546">
Source Assist. MBF MultiPRF MultiPRF MultiPRF
Langs Langs (L1) (L2) (L1,L2)
MAP 0.4495 0.4464 0.4471 0.4885(4.8)†
DE-NL P@5 0.4955 0.4925 0.5045 0.5164(2.4)
P@10 0.4328 0.4343 0.4373 0.4463(2.1)
MAP 0.4495 0.4464 0.4545 0.4713(3.7)†
DE-FI P@5 0.4955 0.4925 0.5194 0.5224(1.2)
P@10 0.4328 0.4343 0.4373 0.4507(3.1)
MAP 0.4495 0.4471 0.4566 0.4757(4.2)†
NL-ES P@5 0.4955 0.5045 0.5164 0.5224(0.6)
EN P@10 0.4328 0.4373 0.4537 0.4448(2.4)
MAP 0.4495 0.4566 0.4563 0.48(5.1)†
ES-FR P@5 0.4955 0.5164 0.5075 0.5224(1.2)
P@10 0.4328 0.4537 0.4343 0.4388(-3.3)
MAP 0.4495 0.4566 0.4545 0.48(5.1)†
ES-FI P@5 0.4955 0.5164 0.5194 0.5254(1.7)
P@10 0.4328 0.4537 0.4373 0.4403(-3.0)
MAP 0.4495 0.4563 0.4545 0.4774(4.6)
FR-FI P@5 0.4955 0.5075 0.5194 0.5284(4.1)†
P@10 0.4328 0.4343 0.4373 0.4373(0.7)
MAP 0.3578 0.3411 0.3553 0.3688(3.8)
EN-FR P@5 0.3821 0.394 0.397 0.4149(4.5)†
P@10 0.3105 0.3463 0.3433 0.3433(0.1)
MAP 0.3578 0.3722 0.3796 0.3929(3.5)
NL-DE P@5 0.3821 0.406 0.403 0.4149(3.0)
P@10 0.3105 0.3478 0.3582 0.3597(0.4)
MAP 0.3578 0.369 0.3796 0.4058(6.9)†
ES-DE P@5 0.3821 0.4119 0.403 0.4239(5.2)
P@10 0.3105 0.3448 0.3582 0.3612(0.8)
MAP 0.3578 0.3553 0.3796 0.3988(5.1)†
FI FR-DE P@5 0.3821 0.397 0.403 0.406(0.7)
P@10 0.3105 0.3433 0.3582 0.3507(-2.1)
MAP 0.3578 0.3722 0.369 0.3875(4.1)†
NL-ES P@5 0.3821 0.406 0.4119 0.4060.0)
P@10 0.3105 0.3478 0.3448 0.3537(1.7)
MAP 0.3578 0.3722 0.3553 0.3875(4.1)†
NL-FR P@5 0.3821 0.406 0.397 0.409(0.7)
P@10 0.3105 0.3478 0.3433 0.3463(-0.4)
MAP 0.3578 0.369 0.3553 0.3823(3.6)
ES-FR P@5 0.3821 0.4119 0.397 0.4119(0.0)
P@10 0.3105 0.3448 0.3433 0.3418(-0.9)
MAP 0.4356 0.4658 0.4634 0.4803(3.1)
FR EN-ES P@5 0.4776 0.4925 0.4925 0.4985(1.2)
P@10 0.4194 0.4358 0.4388 0.4493(3.1)†
</table>
<tableCaption confidence="0.8857">
Table 3: Comparison of MultiPRF Multiple Assisting Lan-
guages using parallel assistance framework with MultiPRF
</tableCaption>
<bodyText confidence="0.716689375">
with single assisting language. Only language pairs where
positive improvements were obtained are reported here. Re-
sults marked as ‡ indicate that the improvement was sta-
tistically significant over baseline (Maximum of MultiPRF
with single assisting language) at 90% confidence level (α =
0.01) when tested using a paired two-tailed t-test.
uniformly choose the top ten documents for feed-
back.
</bodyText>
<sectionHeader confidence="0.999541" genericHeader="evaluation">
6 Results and Discussion
</sectionHeader>
<bodyText confidence="0.9999273">
Tables ?? and ?? present the results for Multi-
PRF with two assisting languages using paral-
lel assistance and selective assistance framework.
Out of the total 60 possible combinations, in Ta-
ble ??, we only report the combinations where
we have obtained positive improvements greater
than 3%. We observe most improvements in En-
glish, Finnish and French. We did not observe any
improvements using the serial assistance frame-
work over MultiPRF with single assisting lan-
</bodyText>
<page confidence="0.996798">
74
</page>
<table confidence="0.999819875">
Source Assist. Parallel Model Selective Model
Langs Langs
EN DE-NL MAP 0.4651 0.4848
P@5 0.5254 0.5224
P@10 0.4493 0.4522
MAP 0.4387 0.4502
NL-FI P@5 0.5015 0.5164
P@10 0.4284 0.4358
MAP 0.4097 0.4302
EN-FR P@5 0.594 0.5851
DE P@10 0.5149 0.5179
MAP 0.4215 0.4333
FR-ES P@5 0.591 0.591
P@10 0.5239 0.5209
MAP 0.4139 0.4236
FR-NL P@5 0.5701 0.5701
P@10 0.5075 0.5134
MAP 0.3925 0.4055
FR-FI P@5 0.5101 0.5642
P@10 0.4851 0.5
MAP 0.3974 0.4192
NL-FI P@5 0.5731 0.5612
P@10 0.497 0.503
MAP 0.4436 0.4501
ES EN-FI P@5 0.6179 0.6269
P@10 0.5567 0.5657
MAP 0.4542 0.465
DE-FI P@5 0.6269 0.6179
P@10 0.5627 0.5582
MAP 0.4531 0.4611
NL-FI P@5 0.6269 0.6299
P@10 0.5627 0.5627
</table>
<tableCaption confidence="0.991241666666667">
Table 4: Results showing the positive improvements of Mul-
tiPRF with selective assistance framework over MultiPRF
with parallel assistance framework.
</tableCaption>
<bodyText confidence="0.999832875">
guage. Hence, we do not report their results as
the results were almost equivalent to single as-
sisting language. As shown in Table ??, selec-
tive assistance does give decent improvements in
some language pairs. An interesting point to note
in selective assistance is that it helps languages
like Spanish whose monolingual performance and
document coverage are both high.
</bodyText>
<subsectionHeader confidence="0.9982755">
6.1 Qualitative Comparison of Feedback
Terms using Multiple Languages
</subsectionHeader>
<bodyText confidence="0.999939733333334">
In this section, we qualitatively compare the re-
sults of MultiPRF with two assisting languages
with that of MultiPRF with single assisting lan-
guage, based on the top feedback terms obtained
by each model. Specifically, in Table 5 we com-
pare the terms obtained by MultiPRF using (i)
Only L1 as assisting language, (ii) Only L2 as as-
sisting language and (iii) Both L1 and L2 as as-
sisting languages in a parallel combination. For
example, the first row in the above table shows
the terms obtained by each model for the En-
glish query “Golden Globes 1994”. Here, L1 is
French and L2 is Spanish. Terms like “Gold”
and “Prize” appearing in the translated feedback
model of L1 cause a drift in the topic towards
“Gold Prize” resulting in a lower MAP score
(0.33). Similarly, the terms like “forrest” and
“spielberg” appearing in the translated feedback
model of L2 cause a drift in topic towards For-
rest Gump and Spielberg Oscars resulting in a
MAP score (0.5). However, when the models
from two languages are combined, terms which
cause a topic drift get ranked lower and as a result
the focus of the query is wrenched back. A sim-
ilar observation was made for the English query
“Damages in Ozone Layer” using French (L1)
and Spanish (L2) as assisting languages. Here,
terms from the translated feedback model of L1
cause a drift in topic towards “militri bacteria”
whereas the terms from the translated feedback
model of L2 cause a drift in topic towards “iraq
war”. However, in the combined model these
terms get lower rank there by bringing back the
focus of the query. For the Finnish query “Lasten
oikeudet” (Children’s Rights), in German (L1),
the topic drift is introduced by terms like “las,
gram, yhteis”. In case of Dutch (L2), the query
drift is caused by “mandy, richard, slovakia” (L2)
and in the case of combined model, these terms
get less weightage and the relevant terms like
“laps, oikeuks, vanhemp” which are common in
both models, receive higher weightage causing an
improvement in query performance.
Next, we look at a few negative examples where
the parallel combination actually performs poorer
than the individual models. This happens when
some drift-terms (i.e., terms which can cause
topic drift) get mutually reinforced by both the
models. For example, for the German query
“Konkurs der Baring-Bank” (Bankruptcy of Bar-
ing Bank) the term “share market” which was ac-
tually ranked lower in the individual models gets
boosted in the combined model resulting in a drift
in topic. Similarly, for the German query “Ehren-
Oscar f¨ur italienische Regisseure” (Honorary Os-
car for Italian directors) the term “head office”
which was actually ranked lower in the individual
models gets ranked higher in the combined model
due to mutual reinforcement resulting in a topic
drift.
</bodyText>
<page confidence="0.999391">
75
</page>
<tableCaption confidence="0.997331">
Table 5: Qualitative Comparison of MultiPRF Results using two assisting languages with single assisting language.
</tableCaption>
<figure confidence="0.996676641025641">
L1
MAP
L2
MAP
L1-L2
MAP
TRANSLATED ENGLISH
QUERIES
(Assisting Lang.)
QUERIES
TOPIC NO. (Meaning in
Eng.)
Representative Terms with L2 as
Single Assisting Language (With
Meaning)
Representative Terms with L1 as
Single Assisting Language (With
Meaning)
Representative Terms with L1&amp; L2 as
Assisting Langs. (With Meaning)
English ‘03
TOPIC 165 Globes 1994
Golden Globes 1994 (FR)
Globos de Oro 1994 (ES) 0.33 0.5 1
Finnish &apos;03
TOPIC 152
Lasten oikeudet
(Children’s
Rights)
Rechte des Kindes (DE) 0.2 0.25 0.37
Kinderrechten (NL)
English ’03
TOPIC 148
Damages in
Ozone Layer
Dommages à la couche
d&apos;ozone (FR)
Destrucción de la capa de
ozono (ES)
</figure>
<figureCaption confidence="0.828748666666667">
damag, weather, atmospher, earth, problem,
report, research, harm, iraq, war, scandal,
illigel, latin, hair
</figureCaption>
<bodyText confidence="0.620252">
damag, uv, layer,weather, atmospher, earth,
problem, report, research , utraviolet, chemic
</bodyText>
<figure confidence="0.771904857142857">
0.08 0.07 0.2 damag, militri, uv, layer, condition, chemic,
bacteria, ban, radiat, ultraviolet
Honorary Oscar for Italian
Directors (EN)
Kunnia-Oscar italialaisille
elokuvaohjaajille (FI)
0.5 0.35 0.2
</figure>
<bodyText confidence="0.994084708333333">
Gold, prize, oscar, nomin, best award,
hollywood, actor, director ,actress, world,
won ,list, winner, televi, foreign ,year, press
laps (child), oikeuks (rights), oikeud (rights),
kind, oikeus (right), isä (father), oikeut
(justify), vanhemp (parent), vanhem
(parents), las, gram, yhteis, unicef, sunt,
äiti(mother), yleissopimnks(conventions)
world, nomin, film, award, delici, planet,
earth, actress, list, drama, director, actor,
spielberg, music, movie, forrest, hank
oikeuks (rights), laps (child), oikeud (right),
mandy, richard, slovakia, tähänast (to date),
tuomar (judge), tyto, kid, , nuor (young
people), nuort (young), sano(said) ,
perustam(establishing)
oscar, nomin, best, award, hollywood actor,
director, cinema, televi, music, actress,
drama, role, hank, foreign, gold
laps (child), oikeuks (rights), oikeud (rights),
oikeus (right), isä (father, parent), vanhemp
(parent), vanhem (parents), oikeut (justify),
las, mandy, nuort (young), richard, nuor
(young people), slovakia, tähänast (to date),
</bodyText>
<figure confidence="0.962647818181818">
Konkurs der
Baring-Bank
(Bankruptcy of
Baring Bank)
Ehren-Oscar für
italienische
Regisseure
(Honorary Oscar
for Italian
directors)
zentralbank(central bank),bankrott(bank
</figure>
<figureCaption confidence="0.611677">
cruptcy), investitionsbank, sigapur, london ,
britisch, index, tokio, england,
werbung(advertising), japan
</figureCaption>
<bodyText confidence="0.888211875">
Direktor(director), film, regierungschef(prime)
, best antonionis, antonionins, lieb,
geschicht(history) , paris, preis, berlin,
monitor, kamera
fall, konkurs, bankrott(Bankruptcy),
warnsignal(warning), ignoriert,
zusammenbruch(collepse), london, singapur,
britisch(british), dollar, tokio, druck(pressur),
handel(trade)
Generaldirektion(General director), film,
ehrenmitglied, regisseur, direktor, verleih ,
itali, oscar, award, antonionins
aktienmarkt(share market), investitionsbank,
bankrott, zentralbank(central bank), federal,
singapur, london, britisch, index, tokio, dollar,
druck, england, dokument(document)
</bodyText>
<figure confidence="0.749667833333333">
generaldirektion(head office),
ehrenmitglied(honorable member),
regierungschef(prime), regisseur(director
),oscar, genossenschaftsbank (corporate
bank)
German &apos;03
TOPIC 180
German &apos;03
TOPIC 198
Bankruptcy of Barings (EN)
Baringsin 0.55 0.51 0.33
Konkurssi (FI)
</figure>
<subsectionHeader confidence="0.955279">
6.2 Effect of Coverage on MultiPRF
Accuracy
</subsectionHeader>
<bodyText confidence="0.999983608695652">
A study of the results obtained for MultiPRF using
single assisting language and multiple assisting
languages with different source languages showed
that certain languages are more suited to be ben-
efited by assisting languages. In particular, lan-
guages having smaller collections are more likely
to be benefited if assisted by a language having a
larger collection size. For example, Finnish which
has the smallest collection (55344 documents)
showed maximum improvement when supported
by assisting language(s). Based on this observa-
tion, we plotted a graph of the collection size of a
source language v/s the average improvement ob-
tained by using two assisting languages to see if
their exists a correlation between these two fac-
tors. As shown in Figure 3, there indeed exists a
high correlation between these two entities. At
one extreme, we have a language like Spanish
which has the largest collection (454045 docu-
ments) and is not benefited much by assisting lan-
guages. On the other extreme, we have Finnish
which has the smallest collection size and is ben-
efited most by assisting languages.
</bodyText>
<table confidence="0.941656375">
454.045 (Spanish)
294.809 (German)
190.604 (Dutch)
169.477 (English)
129.806 (French)
55.344 (Finnish
0 1 2 3 4 5 6 7
Avg. Improvement in MAP of MultiPRF using two Assisting Languages (%)
</table>
<figureCaption confidence="0.9967015">
Figure 3: Effect of Coverage on Average MultiPRF MAP
using Two Assisting Languages.
</figureCaption>
<subsectionHeader confidence="0.9836285">
6.3 Effect of Number of Assisting Languages
on MultiPRF Accuracy
</subsectionHeader>
<bodyText confidence="0.999871071428571">
Another interesting question which needs to be
addressed is “Whether it helps to use more than
two assisting languages?” and if so “Is there an
optimum number of assisting languages beyond
which there will be no improvement?”. To an-
swer these questions, we performed experiments
using 1-4 assisting languages with each source
language. As seen in Figure 4, in general as the
number of assisting languages increases the per-
formance saturates (typically after 3 languages).
Thus, for 5 out of the 6 source languages, the per-
formance saturates after 3 languages which is in
line with what we would intuitively expect. How-
ever, in the case of German, on an average, the
</bodyText>
<figure confidence="0.982168928571428">
500
450
400
350
Coverage 300
(No.of Docs 250
in
Thousands) 200
150
100
50
0
)
76
</figure>
<figureCaption confidence="0.999067">
Figure 4: Effect of Number of Assisting Languages on Avg. MultiPRF Performance with Multiple Assistance.
</figureCaption>
<figure confidence="0.999836968421052">
English
French
Finnish
0 2 4 6
No. of. Assisting Langs.
German
0 2 4 6
No. of Assisting Langs.
Dutch
0 2 4 6
No. of Assisting Langs.
Spanish
0.47
0.45
0.43
0.41
0.39
0.37
0.35
0.45
0.43
0.41
0.39
0.37
0.35
0.49
0.47
0.45
0.43
0.41
0.39
0.37
0.35
MAP
MAP
Avg. MAP
MBF
Avg. MAP
MBF
Avg. MAP
MBF
0 2 4 6
No. of Assisting Langs.
0 2 4 6
No. of Assisting Langs.
0 2 4 6
No. of Assisting Langs.
0.49
0.45
MAP
Avg. MAP
MBF
0.47
0.47
0.45
0.43
0.41
0.39
0.37
0.35
0.45
0.43
0.41
0.39
0.37
0.35
0.43
0.41
0.39
0.37
0.35
MAP
Avg. MAP
MBF
Avg. MAP
MBF
MAP
MAP
Avg. GMAP
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0
MB
1
2
3
4
English French German Spanish Dutch Finnish
Source Language
</figure>
<figureCaption confidence="0.9990685">
Figure 5: Effect of Number of Assisting Languages on Ro-
bustness measured through GMAP.
</figureCaption>
<bodyText confidence="0.95307">
performance drops as the number of assisting lan-
guages is increased. This drop is counter intuitive
and needs further investigation.
</bodyText>
<subsectionHeader confidence="0.981156">
6.4 Effect of Number of Assisting Languages
on Robustness
</subsectionHeader>
<bodyText confidence="0.9997444">
One of the primary motivations for including mul-
tiple assisting languages in MultiPRF was to in-
crease the robustness of retrieval through better
coverage. We varied the number of assisting lan-
guages for each source and studied the average
GMAP. The results are shown in Figure 5. We
observe that in almost all the source languages,
the GMAP value increases with number of assist-
ing languages and then reaches a saturation after
reaching three languages.
</bodyText>
<sectionHeader confidence="0.999673" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999985117647059">
In this paper, we extended the MultiPRF frame-
work to multiple assisting languages. We pre-
Fsented three different configurations for including
multiple assisting languages - a) Parallel b) Serial
and c) Selective. We observe that the results are
mixed with parallel and selective assistance show-
ing improvements in some cases. We also observe
that the robustness of MultiPRF increases with
number of assisting languages. We analyzed the
influence of coverage of MultiPRF accuracy and
observed that it is inversely correlated. Finally,
increasing the number of assisting languages in-
creases the MultiPRF accuracy to some extent and
then it saturates beyond that limit. Many of the
above results (negative results of serial, selective
configurations etc.) require deeper investigation
which we plan to take up in future.
</bodyText>
<sectionHeader confidence="0.999459" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999416666666667">
Braschler, Martin and Carol Peters. 2004. Cross-
language evaluation forum: Objectives, results,
achievements. Inf. Retr., 7(1-2):7–31.
Buckley, Chris, Gerald Salton, James Allan, and Amit
Singhal. 1994. Automatic query expansion using
smart : Trec 3. In Proceedings of The Third Text
REtrieval Conference (TREC-3, pages 69–80.
Chinnakotla, Manoj K., Karthik Raman, and Push-
pak Bhattacharyya. 2010a. Multilingual pseudo-
</reference>
<page confidence="0.979421">
77
</page>
<reference confidence="0.999860584615385">
relevance feedback: English lends a helping hand.
In ACM SIGIR 2010, Geneva, Switzerland, July.
ACM.
Chinnakotla, Manoj K., Karthik Raman, and Push-
pak Bhattacharyya. 2010b. Multilingual pseudo-
relevance feedback: Performance study of assisting
languages. In ACL 2010, Uppsala, Sweeden, July.
ACL.
Dempster, A., N. Laird, and D. Rubin. 1977. Maxi-
mum Likelihood from Incomplete Data via the EM
Algorithm. Journal of the Royal Statistical Society,
39:1–38.
Hawking, David, Paul Thistlewaite, and Donna Har-
man. 1999. Scaling up the trec collection. Inf. Retr.,
1(1-2):115–137.
John Lafferty and Chengxiang Zhai. 2003. Proba-
bilistic Relevance Models Based on Document and
Query Generation. In Language Modeling for Infor-
mation Retrieval, volume 13, pages 1–10. Kluwer
International Series on IR.
Mitra, Mandar, Amit Singhal, and Chris Buckley.
1998. Improving automatic query expansion. In
SIGIR ’98: Proceedings of the 21st annual interna-
tional ACM SIGIR conference on Research and de-
velopment in information retrieval, pages 206–214,
New York, NY, USA. ACM.
Och, Franz Josef and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29(1):19–51.
Ounis, I., G. Amati, Plachouras V., B. He, C. Macdon-
ald, and Johnson. 2005. Terrier Information Re-
trieval Platform. In Proceedings of the 27th Euro-
pean Conference on IR Research (ECIR 2005), vol-
ume 3408 of Lecture Notes in Computer Science,
pages 517–519. Springer.
Philipp, Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In MT Summit.
Robertson, Stephen. 2006. On gmap: and other trans-
formations. In CIKM ’06: Proceedings of the 15th
ACM international conference on Information and
knowledge management, pages 78–83, New York,
NY, USA. ACM.
Voorhees, Ellen. 2006. Overview of the trec 2005
robust retrieval track. In E. M. Voorhees and L.
P. Buckland, editors, The Fourteenth Text REtrieval
Conference, TREC 2005, Gaithersburg, MD. NIST.
Wu, Dan, Daqing He, Heng Ji, and Ralph Grishman.
2008. A study of using an out-of-box commercial
mt system for query translation in clir. In iNEWS
’08: Proceeding of the 2nd ACM workshop on Im-
proving non english web searching, pages 71–76,
New York, NY, USA. ACM.
Xu, Jinxi and W. Bruce Croft. 2000. Improving the ef-
fectiveness of information retrieval with local con-
text analysis. ACM Trans. Inf. Syst., 18(1):79–112.
Zhai, Chengxiang and John Lafferty. 2001. Model-
based Feedback in the Language Modeling ap-
proach to Information Retrieval. In CIKM ’01: Pro-
ceedings of the tenth international conference on In-
formation and knowledge management, pages 403–
410, New York, NY, USA. ACM Press.
Zhai, Chengxiang and John Lafferty. 2004. A Study of
Smoothing Methods for Language Models applied
to Information Retrieval. ACM Transactions on In-
formation Systems, 22(2):179–214.
</reference>
<page confidence="0.998827">
78
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.971668">
<title confidence="0.995062">More Languages, More MAP?: A Study of Multiple Assisting in Multilingual PRF</title>
<author confidence="0.998577">Vishal Vachhani Manoj K Chinnakotla Mitesh M Khapra Pushpak</author>
<affiliation confidence="0.9974625">Department of Computer Science and Indian Institute of Technology Bombay</affiliation>
<abstract confidence="0.999413363636364">Multilingual Pseudo-Relevance Feedback (MultiPRF) is a framework to improve PRF of a language taking help of another language called as- In this paper, we extend the MultiPRF framework to include multiple assisting languages. We consider three different configurations to incorporate multiple assisting languages a) Parallel all assisting languages combined simultaneously b) Serial assisting languages combined in sequence one after another and c) Selective dynamically selecting the best feedback model for each query. We study their effect on MultiPRF performance. Results using multiple assisting languages are mixed and it helps in boosting MultiPRF accuracy only in some cases. We also observe that MultiPRF becomes more robust with increase in number of assisting languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Martin Braschler</author>
<author>Carol Peters</author>
</authors>
<title>Crosslanguage evaluation forum: Objectives, results, achievements.</title>
<date>2004</date>
<journal>Inf. Retr.,</journal>
<pages>7--1</pages>
<contexts>
<context position="2855" citStr="Braschler and Peters, 2004" startWordPosition="431" endWordPosition="434">do not have adequate information coverage in their own language. For example, languages like Hungarian and Finnish have meager online content in their own languages. Multilingual Pseudo-Relevance Feedback (MultiPRF) (Chinnakotla et al., 2010a) is a novel framework for PRF to overcome the above limitations of PRF. It does so by taking the help of a different language called the assisting language. Thus, the performance of a resource-constrained language could be improved by harnessing the good coverage of another language. MulitiPRF showed significant improvements on standard CLEF collections (Braschler and Peters, 2004) over state-of-art PRF system. On the web, each language has its own exclusive topical coverage besides sharing a large number of common topics with other languages. For example, information about Saudi Arabia government policies and regulations is more likely to be found in Arabic language web and also information about a local event in Spain is more likely to be covered in Spanish web than in English. Hence, using multiple languages in conjunction is more likely to ensure satisfaction of the user information need and hence will be more robust. In this paper, we extend the MultiPRF framework </context>
</contexts>
<marker>Braschler, Peters, 2004</marker>
<rawString>Braschler, Martin and Carol Peters. 2004. Crosslanguage evaluation forum: Objectives, results, achievements. Inf. Retr., 7(1-2):7–31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Buckley</author>
<author>Gerald Salton</author>
<author>James Allan</author>
<author>Amit Singhal</author>
</authors>
<title>Automatic query expansion using smart : Trec 3.</title>
<date>1994</date>
<booktitle>In Proceedings of The Third Text REtrieval Conference (TREC-3,</booktitle>
<pages>69--80</pages>
<contexts>
<context position="1192" citStr="Buckley et al., 1994" startWordPosition="171" endWordPosition="174">three different configurations to incorporate multiple assisting languages - a) Parallel - all assisting languages combined simultaneously b) Serial - assisting languages combined in sequence one after another and c) Selective - dynamically selecting the best feedback model for each query. We study their effect on MultiPRF performance. Results using multiple assisting languages are mixed and it helps in boosting MultiPRF accuracy only in some cases. We also observe that MultiPRF becomes more robust with increase in number of assisting languages. 1 Introduction Pseudo-Relevance Feedback (PRF) (Buckley et al., 1994; Xu and Croft, 2000; Mitra et al., 1998) is known to be an effective technique to improve the effectiveness of Information Retrieval (IR) systems. In PRF, the top ‘k’ documents from the ranked list retrieved using the initial keyword query are assumed to be relevant. Later, these documents are used to refine the user query and the final ranked list is obtained using the above refined query. Although PRF has been shown to improve retrieval, it suffers from the following drawbacks: (a) Lexical and Semantic Non-Inclusion: the type of term associations obtained for query expansion is restricted t</context>
</contexts>
<marker>Buckley, Salton, Allan, Singhal, 1994</marker>
<rawString>Buckley, Chris, Gerald Salton, James Allan, and Amit Singhal. 1994. Automatic query expansion using smart : Trec 3. In Proceedings of The Third Text REtrieval Conference (TREC-3, pages 69–80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manoj K Chinnakotla</author>
<author>Karthik Raman</author>
<author>Pushpak Bhattacharyya</author>
</authors>
<title>Multilingual pseudorelevance feedback: English lends a helping hand.</title>
<date>2010</date>
<booktitle>In ACM SIGIR 2010,</booktitle>
<publisher>ACM.</publisher>
<location>Geneva, Switzerland,</location>
<contexts>
<context position="2469" citStr="Chinnakotla et al., 2010" startWordPosition="373" endWordPosition="376">ack documents and (b) Lack of Robustness: due to the inherent assumption in PRF, i.e., relevance of top k documents, performance is sensitive to that of the initial retrieval algorithm and as a result is not robust. Typically, larger coverage ensures higher proportion of relevant documents in the top k retrieval (Hawking et al., 1999). However, some resource-constrained languages do not have adequate information coverage in their own language. For example, languages like Hungarian and Finnish have meager online content in their own languages. Multilingual Pseudo-Relevance Feedback (MultiPRF) (Chinnakotla et al., 2010a) is a novel framework for PRF to overcome the above limitations of PRF. It does so by taking the help of a different language called the assisting language. Thus, the performance of a resource-constrained language could be improved by harnessing the good coverage of another language. MulitiPRF showed significant improvements on standard CLEF collections (Braschler and Peters, 2004) over state-of-art PRF system. On the web, each language has its own exclusive topical coverage besides sharing a large number of common topics with other languages. For example, information about Saudi Arabia gove</context>
<context position="7241" citStr="Chinnakotla et al., 2010" startWordPosition="1141" endWordPosition="1144"> probability mass on the most distinguishing terms, i.e. terms which are more frequent in the feedback document set than in the entire collection. To maintain query focus the final converged feedback model, ΘF is interpolated with the initial query model ΘQ to obtain the final query model ΘFinal. ΘFinal = (1 − α) · ΘQ + α · ΘF ΘFinal is used to re-rank the corpus using the KL-Divergence ranking function to obtain the final ranked list of documents. Henceforth, we refer to the above technique as Model Based Feedback (MBF). 3 Multilingual Pseudo-Relevance Feedback (MultiPRF) Chinnakotla et al. (Chinnakotla et al., 2010a; Chinnakotla et al., 2010b) propose the MultiPRF approach which overcomes the fundamental limitations of PRF with the help of an assisting collection in a different language. Given a query Q in the source language L1, it is automatically translated into the assisting language L2. The documents in the L2 collection are ranked using the query likelihood ranking function (John Lafferty and Chengxiang Zhai, 2003). Using the top k documents, they estimate the feedback model using MBF as described in the previous section. Similarly, they also estimate a feedback model using � KL(ΘQ||D) = w 71 The </context>
</contexts>
<marker>Chinnakotla, Raman, Bhattacharyya, 2010</marker>
<rawString>Chinnakotla, Manoj K., Karthik Raman, and Pushpak Bhattacharyya. 2010a. Multilingual pseudorelevance feedback: English lends a helping hand. In ACM SIGIR 2010, Geneva, Switzerland, July. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manoj K Chinnakotla</author>
<author>Karthik Raman</author>
<author>Pushpak Bhattacharyya</author>
</authors>
<title>Multilingual pseudorelevance feedback: Performance study of assisting languages.</title>
<date>2010</date>
<booktitle>In ACL 2010,</booktitle>
<publisher>ACL.</publisher>
<location>Uppsala, Sweeden,</location>
<contexts>
<context position="2469" citStr="Chinnakotla et al., 2010" startWordPosition="373" endWordPosition="376">ack documents and (b) Lack of Robustness: due to the inherent assumption in PRF, i.e., relevance of top k documents, performance is sensitive to that of the initial retrieval algorithm and as a result is not robust. Typically, larger coverage ensures higher proportion of relevant documents in the top k retrieval (Hawking et al., 1999). However, some resource-constrained languages do not have adequate information coverage in their own language. For example, languages like Hungarian and Finnish have meager online content in their own languages. Multilingual Pseudo-Relevance Feedback (MultiPRF) (Chinnakotla et al., 2010a) is a novel framework for PRF to overcome the above limitations of PRF. It does so by taking the help of a different language called the assisting language. Thus, the performance of a resource-constrained language could be improved by harnessing the good coverage of another language. MulitiPRF showed significant improvements on standard CLEF collections (Braschler and Peters, 2004) over state-of-art PRF system. On the web, each language has its own exclusive topical coverage besides sharing a large number of common topics with other languages. For example, information about Saudi Arabia gove</context>
<context position="7241" citStr="Chinnakotla et al., 2010" startWordPosition="1141" endWordPosition="1144"> probability mass on the most distinguishing terms, i.e. terms which are more frequent in the feedback document set than in the entire collection. To maintain query focus the final converged feedback model, ΘF is interpolated with the initial query model ΘQ to obtain the final query model ΘFinal. ΘFinal = (1 − α) · ΘQ + α · ΘF ΘFinal is used to re-rank the corpus using the KL-Divergence ranking function to obtain the final ranked list of documents. Henceforth, we refer to the above technique as Model Based Feedback (MBF). 3 Multilingual Pseudo-Relevance Feedback (MultiPRF) Chinnakotla et al. (Chinnakotla et al., 2010a; Chinnakotla et al., 2010b) propose the MultiPRF approach which overcomes the fundamental limitations of PRF with the help of an assisting collection in a different language. Given a query Q in the source language L1, it is automatically translated into the assisting language L2. The documents in the L2 collection are ranked using the query likelihood ranking function (John Lafferty and Chengxiang Zhai, 2003). Using the top k documents, they estimate the feedback model using MBF as described in the previous section. Similarly, they also estimate a feedback model using � KL(ΘQ||D) = w 71 The </context>
</contexts>
<marker>Chinnakotla, Raman, Bhattacharyya, 2010</marker>
<rawString>Chinnakotla, Manoj K., Karthik Raman, and Pushpak Bhattacharyya. 2010b. Multilingual pseudorelevance feedback: Performance study of assisting languages. In ACL 2010, Uppsala, Sweeden, July. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Dempster</author>
<author>N Laird</author>
<author>D Rubin</author>
</authors>
<title>Maximum Likelihood from Incomplete Data via the EM Algorithm.</title>
<date>1977</date>
<journal>Journal of the Royal Statistical Society,</journal>
<pages>39--1</pages>
<contexts>
<context position="6586" citStr="Dempster et al., 1977" startWordPosition="1032" endWordPosition="1035">ingual Dictionary from L2 to L1 β, ry Interpolation coefficients coefficients used in MultiPRF Table 1: Glossary of Symbols used in explaining MultiPRF the feedback language model is inferred based on a Generative Mixture Model (Zhai and Lafferty, 2001). Let DF = {d1, d2, ... , dk} be the top k documents retrieved using the initial ranking algorithm. Zhai and Lafferty (Zhai and Lafferty, 2001) model the feedback document set DF as a mixture of two distributions: (a) the feedback language model and (b) the collection model P(w|C). The feedback language model is inferred using the EM Algorithm (Dempster et al., 1977), which iteratively accumulates probability mass on the most distinguishing terms, i.e. terms which are more frequent in the feedback document set than in the entire collection. To maintain query focus the final converged feedback model, ΘF is interpolated with the initial query model ΘQ to obtain the final query model ΘFinal. ΘFinal = (1 − α) · ΘQ + α · ΘF ΘFinal is used to re-rank the corpus using the KL-Divergence ranking function to obtain the final ranked list of documents. Henceforth, we refer to the above technique as Model Based Feedback (MBF). 3 Multilingual Pseudo-Relevance Feedback </context>
</contexts>
<marker>Dempster, Laird, Rubin, 1977</marker>
<rawString>Dempster, A., N. Laird, and D. Rubin. 1977. Maximum Likelihood from Incomplete Data via the EM Algorithm. Journal of the Royal Statistical Society, 39:1–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Hawking</author>
<author>Paul Thistlewaite</author>
<author>Donna Harman</author>
</authors>
<title>Scaling up the trec collection.</title>
<date>1999</date>
<journal>Inf. Retr.,</journal>
<pages>1--1</pages>
<contexts>
<context position="2181" citStr="Hawking et al., 1999" startWordPosition="335" endWordPosition="338">g the above refined query. Although PRF has been shown to improve retrieval, it suffers from the following drawbacks: (a) Lexical and Semantic Non-Inclusion: the type of term associations obtained for query expansion is restricted to only co-occurrence based relationships in the feedback documents and (b) Lack of Robustness: due to the inherent assumption in PRF, i.e., relevance of top k documents, performance is sensitive to that of the initial retrieval algorithm and as a result is not robust. Typically, larger coverage ensures higher proportion of relevant documents in the top k retrieval (Hawking et al., 1999). However, some resource-constrained languages do not have adequate information coverage in their own language. For example, languages like Hungarian and Finnish have meager online content in their own languages. Multilingual Pseudo-Relevance Feedback (MultiPRF) (Chinnakotla et al., 2010a) is a novel framework for PRF to overcome the above limitations of PRF. It does so by taking the help of a different language called the assisting language. Thus, the performance of a resource-constrained language could be improved by harnessing the good coverage of another language. MulitiPRF showed signific</context>
</contexts>
<marker>Hawking, Thistlewaite, Harman, 1999</marker>
<rawString>Hawking, David, Paul Thistlewaite, and Donna Harman. 1999. Scaling up the trec collection. Inf. Retr., 1(1-2):115–137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Chengxiang Zhai</author>
</authors>
<title>Probabilistic Relevance Models Based on Document and Query Generation. In Language Modeling for Information Retrieval,</title>
<date>2003</date>
<booktitle>International Series on IR.</booktitle>
<volume>13</volume>
<pages>1--10</pages>
<publisher>Kluwer</publisher>
<marker>Lafferty, Zhai, 2003</marker>
<rawString>John Lafferty and Chengxiang Zhai. 2003. Probabilistic Relevance Models Based on Document and Query Generation. In Language Modeling for Information Retrieval, volume 13, pages 1–10. Kluwer International Series on IR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mandar Mitra</author>
<author>Amit Singhal</author>
<author>Chris Buckley</author>
</authors>
<title>Improving automatic query expansion.</title>
<date>1998</date>
<booktitle>In SIGIR ’98: Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>206--214</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1233" citStr="Mitra et al., 1998" startWordPosition="179" endWordPosition="182">ate multiple assisting languages - a) Parallel - all assisting languages combined simultaneously b) Serial - assisting languages combined in sequence one after another and c) Selective - dynamically selecting the best feedback model for each query. We study their effect on MultiPRF performance. Results using multiple assisting languages are mixed and it helps in boosting MultiPRF accuracy only in some cases. We also observe that MultiPRF becomes more robust with increase in number of assisting languages. 1 Introduction Pseudo-Relevance Feedback (PRF) (Buckley et al., 1994; Xu and Croft, 2000; Mitra et al., 1998) is known to be an effective technique to improve the effectiveness of Information Retrieval (IR) systems. In PRF, the top ‘k’ documents from the ranked list retrieved using the initial keyword query are assumed to be relevant. Later, these documents are used to refine the user query and the final ranked list is obtained using the above refined query. Although PRF has been shown to improve retrieval, it suffers from the following drawbacks: (a) Lexical and Semantic Non-Inclusion: the type of term associations obtained for query expansion is restricted to only co-occurrence based relationships </context>
</contexts>
<marker>Mitra, Singhal, Buckley, 1998</marker>
<rawString>Mitra, Mandar, Amit Singhal, and Chris Buckley. 1998. Improving automatic query expansion. In SIGIR ’98: Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval, pages 206–214, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="17105" citStr="Och and Ney, 2003" startWordPosition="2808" endWordPosition="2811">n the languages. In case of French, since some function words like l’, d’ etc., occur as prefixes to a word, we strip them off during indexing and query processing, since it significantly improves the baseline performance. We use standard evaluation measures like MAP, P@S and P@10 for evaluation. Additionally, for assessing robustness, we use the Geometric Mean Average Precision (GMAP) metric (Robertson, 2006) which is also used in the TREC Robust Track (Voorhees, 2006). The probabilistic bi-lingual dictionary used in MultiPRF was learnt automatically by running GIZA++: a word alignment tool (Och and Ney, 2003) on a parallel sentence aligned corpora. For all the above language pairs we used the Europarl Corpus (Philipp, 2005). We use Google Translate as the query translation system as it has been shown to perform well for the task (Wu et al., 2008). We use two-stage Dirichlet smoothing with the optimal parameters tuned based on the collection (Zhai and Lafferty, 2004). We tune the parameters of MBF, specifically A and α, and choose the values which give the optimal performance on a given collection. We observe that the optimal parameters γ and β are uniform across collections and vary in the range 0</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Och, Franz Josef and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Ounis</author>
<author>G Amati</author>
<author>V Plachouras</author>
<author>B He</author>
<author>C Macdonald</author>
<author>Johnson</author>
</authors>
<title>Terrier Information Retrieval Platform.</title>
<date>2005</date>
<booktitle>In Proceedings of the 27th European Conference on IR Research (ECIR</booktitle>
<volume>3408</volume>
<pages>517--519</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="16207" citStr="Ounis et al., 2005" startWordPosition="2664" endWordPosition="2667">ix languages, widely varying in their familial relationships - Dutch, German, English, French, Spanish and Finnish. The details of the collections and their corresponding topics used for MultiPRF are given in Table 2. Note that, in each experiment, we choose assisting collections such that the topics in the source language are covered in the assisting collection so as to get meaningful feedback terms. In all the topics, we only use the title field. We ignore the topics which have no relevant documents as the true performance on those topics cannot be evaluated. We use the Terrier IR platform (Ounis et al., 2005) for indexing the documents. We perform standard tokenization, stop word removal and stemming. We use the Porter Stemmer for English and the stemmers available through the Snowball package for other languages. Other than these, we do not perform any language-specific processing on the languages. In case of French, since some function words like l’, d’ etc., occur as prefixes to a word, we strip them off during indexing and query processing, since it significantly improves the baseline performance. We use standard evaluation measures like MAP, P@S and P@10 for evaluation. Additionally, for asse</context>
</contexts>
<marker>Ounis, Amati, Plachouras, He, Macdonald, Johnson, 2005</marker>
<rawString>Ounis, I., G. Amati, Plachouras V., B. He, C. Macdonald, and Johnson. 2005. Terrier Information Retrieval Platform. In Proceedings of the 27th European Conference on IR Research (ECIR 2005), volume 3408 of Lecture Notes in Computer Science, pages 517–519. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koehn Philipp</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In MT Summit.</booktitle>
<contexts>
<context position="17222" citStr="Philipp, 2005" startWordPosition="2830" endWordPosition="2831">m off during indexing and query processing, since it significantly improves the baseline performance. We use standard evaluation measures like MAP, P@S and P@10 for evaluation. Additionally, for assessing robustness, we use the Geometric Mean Average Precision (GMAP) metric (Robertson, 2006) which is also used in the TREC Robust Track (Voorhees, 2006). The probabilistic bi-lingual dictionary used in MultiPRF was learnt automatically by running GIZA++: a word alignment tool (Och and Ney, 2003) on a parallel sentence aligned corpora. For all the above language pairs we used the Europarl Corpus (Philipp, 2005). We use Google Translate as the query translation system as it has been shown to perform well for the task (Wu et al., 2008). We use two-stage Dirichlet smoothing with the optimal parameters tuned based on the collection (Zhai and Lafferty, 2004). We tune the parameters of MBF, specifically A and α, and choose the values which give the optimal performance on a given collection. We observe that the optimal parameters γ and β are uniform across collections and vary in the range 0.4-0.48. We Source Assist. MBF MultiPRF MultiPRF MultiPRF Langs Langs (L1) (L2) (L1,L2) MAP 0.4495 0.4464 0.4471 0.48</context>
</contexts>
<marker>Philipp, 2005</marker>
<rawString>Philipp, Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In MT Summit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Robertson</author>
</authors>
<title>On gmap: and other transformations.</title>
<date>2006</date>
<booktitle>In CIKM ’06: Proceedings of the 15th ACM international conference on Information and knowledge management,</booktitle>
<pages>78--83</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="16900" citStr="Robertson, 2006" startWordPosition="2777" endWordPosition="2778">val and stemming. We use the Porter Stemmer for English and the stemmers available through the Snowball package for other languages. Other than these, we do not perform any language-specific processing on the languages. In case of French, since some function words like l’, d’ etc., occur as prefixes to a word, we strip them off during indexing and query processing, since it significantly improves the baseline performance. We use standard evaluation measures like MAP, P@S and P@10 for evaluation. Additionally, for assessing robustness, we use the Geometric Mean Average Precision (GMAP) metric (Robertson, 2006) which is also used in the TREC Robust Track (Voorhees, 2006). The probabilistic bi-lingual dictionary used in MultiPRF was learnt automatically by running GIZA++: a word alignment tool (Och and Ney, 2003) on a parallel sentence aligned corpora. For all the above language pairs we used the Europarl Corpus (Philipp, 2005). We use Google Translate as the query translation system as it has been shown to perform well for the task (Wu et al., 2008). We use two-stage Dirichlet smoothing with the optimal parameters tuned based on the collection (Zhai and Lafferty, 2004). We tune the parameters of MBF</context>
</contexts>
<marker>Robertson, 2006</marker>
<rawString>Robertson, Stephen. 2006. On gmap: and other transformations. In CIKM ’06: Proceedings of the 15th ACM international conference on Information and knowledge management, pages 78–83, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Voorhees</author>
</authors>
<title>Overview of the trec 2005 robust retrieval track.</title>
<date>2006</date>
<booktitle>The Fourteenth Text REtrieval Conference, TREC 2005,</booktitle>
<editor>In E. M. Voorhees and L. P. Buckland, editors,</editor>
<publisher>NIST.</publisher>
<location>Gaithersburg, MD.</location>
<contexts>
<context position="16961" citStr="Voorhees, 2006" startWordPosition="2788" endWordPosition="2789">e stemmers available through the Snowball package for other languages. Other than these, we do not perform any language-specific processing on the languages. In case of French, since some function words like l’, d’ etc., occur as prefixes to a word, we strip them off during indexing and query processing, since it significantly improves the baseline performance. We use standard evaluation measures like MAP, P@S and P@10 for evaluation. Additionally, for assessing robustness, we use the Geometric Mean Average Precision (GMAP) metric (Robertson, 2006) which is also used in the TREC Robust Track (Voorhees, 2006). The probabilistic bi-lingual dictionary used in MultiPRF was learnt automatically by running GIZA++: a word alignment tool (Och and Ney, 2003) on a parallel sentence aligned corpora. For all the above language pairs we used the Europarl Corpus (Philipp, 2005). We use Google Translate as the query translation system as it has been shown to perform well for the task (Wu et al., 2008). We use two-stage Dirichlet smoothing with the optimal parameters tuned based on the collection (Zhai and Lafferty, 2004). We tune the parameters of MBF, specifically A and α, and choose the values which give the </context>
</contexts>
<marker>Voorhees, 2006</marker>
<rawString>Voorhees, Ellen. 2006. Overview of the trec 2005 robust retrieval track. In E. M. Voorhees and L. P. Buckland, editors, The Fourteenth Text REtrieval Conference, TREC 2005, Gaithersburg, MD. NIST.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Wu</author>
<author>Daqing He</author>
<author>Heng Ji</author>
<author>Ralph Grishman</author>
</authors>
<title>A study of using an out-of-box commercial mt system for query translation in clir.</title>
<date>2008</date>
<booktitle>In iNEWS ’08: Proceeding of the 2nd ACM workshop on Improving non english web searching,</booktitle>
<pages>71--76</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="17347" citStr="Wu et al., 2008" startWordPosition="2852" endWordPosition="2855">ation measures like MAP, P@S and P@10 for evaluation. Additionally, for assessing robustness, we use the Geometric Mean Average Precision (GMAP) metric (Robertson, 2006) which is also used in the TREC Robust Track (Voorhees, 2006). The probabilistic bi-lingual dictionary used in MultiPRF was learnt automatically by running GIZA++: a word alignment tool (Och and Ney, 2003) on a parallel sentence aligned corpora. For all the above language pairs we used the Europarl Corpus (Philipp, 2005). We use Google Translate as the query translation system as it has been shown to perform well for the task (Wu et al., 2008). We use two-stage Dirichlet smoothing with the optimal parameters tuned based on the collection (Zhai and Lafferty, 2004). We tune the parameters of MBF, specifically A and α, and choose the values which give the optimal performance on a given collection. We observe that the optimal parameters γ and β are uniform across collections and vary in the range 0.4-0.48. We Source Assist. MBF MultiPRF MultiPRF MultiPRF Langs Langs (L1) (L2) (L1,L2) MAP 0.4495 0.4464 0.4471 0.4885(4.8)† DE-NL P@5 0.4955 0.4925 0.5045 0.5164(2.4) P@10 0.4328 0.4343 0.4373 0.4463(2.1) MAP 0.4495 0.4464 0.4545 0.4713(3.7</context>
</contexts>
<marker>Wu, He, Ji, Grishman, 2008</marker>
<rawString>Wu, Dan, Daqing He, Heng Ji, and Ralph Grishman. 2008. A study of using an out-of-box commercial mt system for query translation in clir. In iNEWS ’08: Proceeding of the 2nd ACM workshop on Improving non english web searching, pages 71–76, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinxi Xu</author>
<author>W Bruce Croft</author>
</authors>
<title>Improving the effectiveness of information retrieval with local context analysis.</title>
<date>2000</date>
<journal>ACM Trans. Inf. Syst.,</journal>
<volume>18</volume>
<issue>1</issue>
<contexts>
<context position="1212" citStr="Xu and Croft, 2000" startWordPosition="175" endWordPosition="178">urations to incorporate multiple assisting languages - a) Parallel - all assisting languages combined simultaneously b) Serial - assisting languages combined in sequence one after another and c) Selective - dynamically selecting the best feedback model for each query. We study their effect on MultiPRF performance. Results using multiple assisting languages are mixed and it helps in boosting MultiPRF accuracy only in some cases. We also observe that MultiPRF becomes more robust with increase in number of assisting languages. 1 Introduction Pseudo-Relevance Feedback (PRF) (Buckley et al., 1994; Xu and Croft, 2000; Mitra et al., 1998) is known to be an effective technique to improve the effectiveness of Information Retrieval (IR) systems. In PRF, the top ‘k’ documents from the ranked list retrieved using the initial keyword query are assumed to be relevant. Later, these documents are used to refine the user query and the final ranked list is obtained using the above refined query. Although PRF has been shown to improve retrieval, it suffers from the following drawbacks: (a) Lexical and Semantic Non-Inclusion: the type of term associations obtained for query expansion is restricted to only co-occurrence</context>
</contexts>
<marker>Xu, Croft, 2000</marker>
<rawString>Xu, Jinxi and W. Bruce Croft. 2000. Improving the effectiveness of information retrieval with local context analysis. ACM Trans. Inf. Syst., 18(1):79–112.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chengxiang Zhai</author>
<author>John Lafferty</author>
</authors>
<title>Modelbased Feedback in the Language Modeling approach to Information Retrieval.</title>
<date>2001</date>
<booktitle>In CIKM ’01: Proceedings of the tenth international conference on Information and knowledge management,</booktitle>
<pages>403--410</pages>
<publisher>ACM Press.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="6217" citStr="Zhai and Lafferty, 2001" startWordPosition="967" endWordPosition="970">to be relevant and used as feedback for improving the estimation of ΘQ. The feedback documents contain both relevant and noisy terms from which Symbol Description ®Q Query Language Model ®� Feedback Language Model obtained from PRF in L1 L1 ®� Feedback Language Model obtained from PRF in L2 L2 ®� �698 Feedback Model Translated from L2 to L1 L1 t(f|e) Probabilistic Bi-Lingual Dictionary from L2 to L1 β, ry Interpolation coefficients coefficients used in MultiPRF Table 1: Glossary of Symbols used in explaining MultiPRF the feedback language model is inferred based on a Generative Mixture Model (Zhai and Lafferty, 2001). Let DF = {d1, d2, ... , dk} be the top k documents retrieved using the initial ranking algorithm. Zhai and Lafferty (Zhai and Lafferty, 2001) model the feedback document set DF as a mixture of two distributions: (a) the feedback language model and (b) the collection model P(w|C). The feedback language model is inferred using the EM Algorithm (Dempster et al., 1977), which iteratively accumulates probability mass on the most distinguishing terms, i.e. terms which are more frequent in the feedback document set than in the entire collection. To maintain query focus the final converged feedback </context>
</contexts>
<marker>Zhai, Lafferty, 2001</marker>
<rawString>Zhai, Chengxiang and John Lafferty. 2001. Modelbased Feedback in the Language Modeling approach to Information Retrieval. In CIKM ’01: Proceedings of the tenth international conference on Information and knowledge management, pages 403– 410, New York, NY, USA. ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chengxiang Zhai</author>
<author>John Lafferty</author>
</authors>
<title>A Study of Smoothing Methods for Language Models applied to Information Retrieval.</title>
<date>2004</date>
<journal>ACM Transactions on Information Systems,</journal>
<volume>22</volume>
<issue>2</issue>
<contexts>
<context position="17469" citStr="Zhai and Lafferty, 2004" startWordPosition="2871" endWordPosition="2874"> Mean Average Precision (GMAP) metric (Robertson, 2006) which is also used in the TREC Robust Track (Voorhees, 2006). The probabilistic bi-lingual dictionary used in MultiPRF was learnt automatically by running GIZA++: a word alignment tool (Och and Ney, 2003) on a parallel sentence aligned corpora. For all the above language pairs we used the Europarl Corpus (Philipp, 2005). We use Google Translate as the query translation system as it has been shown to perform well for the task (Wu et al., 2008). We use two-stage Dirichlet smoothing with the optimal parameters tuned based on the collection (Zhai and Lafferty, 2004). We tune the parameters of MBF, specifically A and α, and choose the values which give the optimal performance on a given collection. We observe that the optimal parameters γ and β are uniform across collections and vary in the range 0.4-0.48. We Source Assist. MBF MultiPRF MultiPRF MultiPRF Langs Langs (L1) (L2) (L1,L2) MAP 0.4495 0.4464 0.4471 0.4885(4.8)† DE-NL P@5 0.4955 0.4925 0.5045 0.5164(2.4) P@10 0.4328 0.4343 0.4373 0.4463(2.1) MAP 0.4495 0.4464 0.4545 0.4713(3.7)† DE-FI P@5 0.4955 0.4925 0.5194 0.5224(1.2) P@10 0.4328 0.4343 0.4373 0.4507(3.1) MAP 0.4495 0.4471 0.4566 0.4757(4.2)† </context>
</contexts>
<marker>Zhai, Lafferty, 2004</marker>
<rawString>Zhai, Chengxiang and John Lafferty. 2004. A Study of Smoothing Methods for Language Models applied to Information Retrieval. ACM Transactions on Information Systems, 22(2):179–214.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>