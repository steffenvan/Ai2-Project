<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.846925">
Aligning Features with Sense Distinction Dimensions
</title>
<author confidence="0.350223">
1 Nianwen Xue, 2 Anying Chen, 3 Martha Palmer
</author>
<affiliation confidence="0.526861">
1CSLR and 3Department of Linguistics
University of Colorado
</affiliation>
<address confidence="0.679922">
Boulder, CO, 80309
</address>
<email confidence="0.940665">
{Nianwen.Xue,Martha.Palmer}@colorado.edu
</email>
<affiliation confidence="0.996545">
2 Department of Computer and Information Science
University of Pennsylvania
</affiliation>
<address confidence="0.95456">
Philadelphia, PA, 19104
</address>
<email confidence="0.99962">
jinying@cis.upenn.edu
</email>
<sectionHeader confidence="0.996683" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999710222222222">
In this paper we present word sense
disambiguation (WSD) experiments on
ten highly polysemous verbs in Chinese,
where significant performance
improvements are achieved using rich
linguistic features. Our system performs
significantly better, and in some cases
substantially better, than the baseline on
all ten verbs. Our results also
demonstrate that features extracted from
the output of an automatic Chinese
semantic role labeling system in general
benefited the WSD system, even though
the amount of improvement was not
consistent across the verbs. For a few
verbs, semantic role information actually
hurt WSD performance. The
inconsistency of feature performance is a
general characteristic of the WSD task, as
has been observed by others. We argue
that this result can be explained by the
fact that word senses are partitioned
along different dimensions for different
verbs and the features therefore need to
be tailored to particular verbs in order to
achieve adequate accuracy on verb sense
disambiguation.
</bodyText>
<sectionHeader confidence="0.999164" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999963693877551">
Word sense disambiguation, the determination of
the correct sense of a polysemous word from a
number of possible senses based on the context
in which it occurs, is a continuing obstacle to
high performance natural language processing
applications. There are several well-documented
factors that make accurate WSD particularly
challenging. The first has to do with how senses
are defined. The English data used for the
SENSEVAL exercises, arguably the most widely
used data to train and test WSD systems, are
annotated based on very fine-grained distinctions
defined in WordNet (Fellbaum, 1998), with
human inter-annotator agreement at a little over
seventy percent and the top-ranked systems&apos;
performances falling between 60%-70%
(Palmer, et al., 2001; Mihalcea et al., 2004). The
second source of difficulty for accurate WSD
comes from how senses are distributed. It is
often the case that a polysemous word has a
dominant sense or several dominant senses that
occur with high frequency and not enough
instances can be found for its low frequency
senses in the currently publicly available data.
There are on-going efforts to address these
issues. For example, the sense annotation
component of the OntoNotes project (Novy, et
al., 2006) attempts to create a large-scale coarse-
grained sense-annotated corpus with senses
defined based on explicit linguistic criteria.
These problems will be alleviated when
resources like this are available to the general
NLP community. There have already been
experiments that show such coarse-grained
senses lead to substantial improvement in system
performance (Palmer et al, 2006).
The goal of our experiments is to explore the
implications of a related and yet separate
problem, specifically the extent to which the
linguistic criteria used to define senses are
related to what features need to be used in
machine-learning systems. There are already
published results that show WSD for different
syntactic categories may need different types of
features. For example, Yarowsky and Florian
(2002), in their experiments on SENSEVAL2
English data, showed that sense distinctions of
verbs relied more on linguistically motivated
features than other parts-of-speech. In this paper,
</bodyText>
<page confidence="0.962378">
921
</page>
<note confidence="0.725273">
Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 921–928,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999770366666667">
we will go one step further and show that even
for words of the same syntactic category senses
are often defined along different dimensions
based on different criteria. One direct implication
of this observation for supervised machine-
learning approaches to WSD is that the features
have to be customized for different word
categories, or even for different words of the
same category. This supports previous arguments
for word-specific feature design and parametric
modeling for WSD tasks (Chen and Palmer,
2005; Hoste et al. 2002). We report experiments
on ten highly polysemous Chinese verbs and
show that features are not uniformly useful for
all words.
The rest of the paper is organized as follows.
In Section 2, we describe our WSD system,
focusing on the features we used. We also briefly
compare the features we use for Chinese with
those used in a similar English WSD system. In
Section 3, we present our experimental results
and show that although rich linguistic features
and features derived from a Chinese Semantic
Role Labeling improve the WSD accuracy, the
improvement is not uniform across all verbs. We
show that this lack of consistency is due to the
different dimensions along which the features are
defined. In Section 4, we discuss related work.
Finally Section 5 concludes this paper and
describes future directions.
</bodyText>
<sectionHeader confidence="0.836234" genericHeader="method">
2 WSD System for Chinese Verbs
</sectionHeader>
<bodyText confidence="0.999271133333334">
Our WSD system uses a smoothed maximum
entropy (MaxEnt) model with a Gaussian prior
(McCallum, 2002) for learning Chinese verb
senses. The primary reason is that the MaxEnt
model provides a natural way for combining
different features without the assumption of
feature independence. Furthermore, smoothing
the MaxEnt model with a Gaussian prior is better
than other smoothing methods at alleviating the
overfitting problem caused by low frequency
features (Chen et al., 1999). This model has been
applied successfully for English WSD (Dang,
2004; Chen and Palmer, 2005).
The features used by our Chinese WSD
system include:
</bodyText>
<subsectionHeader confidence="0.598659">
Collocation Features
</subsectionHeader>
<bodyText confidence="0.756872">
- Previous and next word (relative to the target
verb), w_1 and w1 and their parts-of-speech p_1
and p1
</bodyText>
<subsectionHeader confidence="0.829621">
Syntactic Features
</subsectionHeader>
<bodyText confidence="0.953655571428571">
- Whether the target verb takes a direct object
(i.e., in a transitive use)
- Whether the verb takes a sentential
complement
- Whether the verb, if it consists of a single
character, occurs at the last position of a
compound verb
</bodyText>
<subsectionHeader confidence="0.575875">
Semantic Features
</subsectionHeader>
<bodyText confidence="0.993541342857143">
- The semantic role information about the verbs
- The semantic categories for the verb&apos;s NP
arguments from a general Chinese noun
Taxonomy
All of these features require some level of
preprocessing of the Chinese raw text, which
comes without word boundaries. To extract the
collocation features the raw text needs to be
segmented and POS-tagged; to extract the
syntactic and semantic features, the Chinese text
needs to be parsed. We use an integrated parser
that does segmentation, POS-tagging and parsing
in one step. Since part of the sense-tagged data
comes from the Chinese Treebank that the parser
is trained on, we divide the Chinese Treebank
into nine equal-sized portions and parse each
portion with a parsing model trained on the other
eight portions so that the parser has not seen any
of the data it parses. The data that is not from the
Chinese Treebank is parsed with a parsing model
trained on the entire Chinese Treebank. The
parser produces a segmented, POS-tagged and
parsed version of the same text to facilitate the
extraction of the different types of features. The
extraction of the semantic role labels as features
requires the use of a semantic role tagger, which
we describe in greater detail in Section 2.2.
In addition to using the semantic role labeling
information, we also extract another type of
semantic features from the verb&apos;s NP arguments.
These features are top-level semantic categories
from a three-level general taxonomy for Chinese
nouns, which was created semi-automatically
based on two Chinese semantic dictionaries
(Chen and Palmer, 2004).
</bodyText>
<subsectionHeader confidence="0.968048">
2.1 A Comparison with Our English WSD
System
</subsectionHeader>
<bodyText confidence="0.999070333333333">
Similar to our English WSD system, which
achieved the best published results on
SENSEVAL2 English verbs for both fine-
grained and coarse-grained senses (Chen and
Palmer, 2005), our Chinese WSD system uses
the same smoothed MaxEnt machine learning
model and linguistically motivated features for
Chinese verb sense disambiguation. However,
the features used in the two systems differ
</bodyText>
<page confidence="0.995722">
922
</page>
<bodyText confidence="0.999937666666667">
somewhat due to the different properties of the
two languages .
For example, our English system uses the
inflected form and the part-of-speech tag of the
target verb as feature. For Chinese we no longer
use such features since Chinese words, unlike
English ones, do not contain morphology that
marks tense.
The collocation features used by our English
system include bi-grams and tri-grams of the
words that occur within two positions before or
after the target verb and their part-of-speech tags.
In contrast, our Chinese system extracts
collocation features from a narrower, three-word
window, with one word immediately before and
after the target verb. This decision was made
based on two observations about the Chinese
language. First, certain single-character Hi
Chinese
verbs, such as the verbs &amp;quot; Ichu&amp;quot;, &amp;quot;ffIkai&amp;quot; and
&amp;quot;Alcheng&amp;quot; in our experiments, often form a
compound with a verb to its immediate left. That
verb is often a good indicator of the sense of this
verb. An example is given in (1):
</bodyText>
<equation confidence="0.806890666666667">
(1) �� � _ )Q ffl
Liaoning already show completion
411:Tuft a# im_§ �
</equation>
<bodyText confidence="0.975207692307692">
multidimensional development trend
&amp;quot;Liaoning Province has shown the trend of
multidimensional development.&amp;quot;
Being the last word of a verb compound is a
strong indicator for Sense 8 of the verb &amp;quot; ffl
Ichu1&amp;quot; (used after a verb to indicate direction or
aspect), as in &amp;quot;_ )QJcheng2xian4 ffllchu1&amp;quot;.
Second, unlike English common nouns that
often require determiners such as the, a or an,
Chinese common nouns can stand alone.
Therefore, the direct object of a verb often
occurs right after the verb in Chinese, as shown
in (2).
</bodyText>
<figure confidence="0.38071675">
(2)4_6i NA a.10 9 �r �
mobilize people tighten waistband collect
1� ff kV (direct object)
funds build highway
</figure>
<bodyText confidence="0.941735777777778">
&amp;quot;Mobilize people to tighten their waistbands (i.e.,
save money) in order to collect funds to build
highways.&amp;quot;
Based on these observations, we use words
surrounding the target verb and their part-of-
speech tags as collocation features. A further
investigation on the different sizes of the context
window (3,5,7,9,11) showed that increasing the
window size decreased our system&apos;s accuracy.
</bodyText>
<subsectionHeader confidence="0.9954335">
2.2 Features Based on Automatic Semantic
Role Tagging
</subsectionHeader>
<bodyText confidence="0.999898564102564">
In a recent paper on the WSD of English verbs,
Dang and Palmer (2005) showed that semantic
role information significantly improves the WSD
accuracy of English verbs for both fine-grained
and coarse-grained senses. However, this result
assumes the human annotation of the Penn
English Propbank (Palmer et al, 2005). It seems
worthwhile to investigate whether the semantic
role information produced by a fully automatic
Semantic Role tagger can improve the WSD
accuracy on verbs, and test the hypothesis that
the senses of a verb have a high correlation to
the arguments it takes. To that end, we assigned
semantic role labels to the arguments of the
target verb with a fully automatic semantic role
tagger (Xue and Palmer, 2005) trained on the
Chinese Propbank (CPB) (Xue and Palmer,
2003), a corpus annotated with semantic role
labels that are similiar in style to the Penn
English Propbank. In this annotation, core
arguments such as agent or theme are labeled
with numbered arguments such as Arg0 and Argl,
up to Argy while adjunct-like elements are
assigned functional tags such as TMP (for
temporal), MNR, prefixed by ArgM. The
Semantic Role tagger takes as input syntactic
parses produced by the parser described above as
input and produces a list of arguments for each
of the sense-tagged target verbs and assigns
argument labels to them. Features are extracted
from both the core arguments and adjuncts of the
target verb. In addition to providing the sematnic
role labels (e.g., Arg0 and Argl) of the extracted
core arguments, the Semantic Role tagger also
provides Hownet (Dong and Dong, 1991)
semantic categories associated with these
arguments. (3) shows the arguments for the
target verb &amp;quot;#T&amp;quot; identified by the Semantic Role
tagger:
</bodyText>
<listItem confidence="0.666163">
(3) [ArgM-MNR 4-�Dp;-A � � X T] ,
</listItem>
<bodyText confidence="0.501522">
through three year hard work,
</bodyText>
<equation confidence="0.856842333333333">
[arg0 4_t, �] [rel #T] A
whole county dig finish
[Arg1 X 7K#] � NV �
</equation>
<bodyText confidence="0.91141">
deep well three classifier
</bodyText>
<page confidence="0.993561">
923
</page>
<bodyText confidence="0.991652625">
each verb in the data. The fourth column shows
the sense entropy for each verb in its test data, as
calculated in Equation 1.
&amp;quot;The whole county finished digging three deep
wells through 3 years of hard work.&amp;quot;
Based on the output of the Semantic Role tagger
and the Chinese noun taxonomy (as described in
Section 2.1), the following features are extracted:
</bodyText>
<equation confidence="0.55805625">
SRL+lex SRL+HowNet SRL+Taxonomy
ARG1-水井 ARG1-设施 ARG1_location
ARG0-乡 ARG0-地方 ARG0_location
ARGM|MNR-经过 ARGM|MNR-经受 ARGM|MNR
</equation>
<bodyText confidence="0.9997036">
In this example, semantic role related features
include: (1) the head word of the core arguments
(ARG1-水井 and ARG0-乡) and the adjunct
(ARGM|MNR-经过); (2) the HowNet semantic
category for the head word (ARG1-设施, ARG0-
地方, ARGM|MNR-经受); (3) the semantic role
label of the adjunct (ARGM|MNR); and (4) the
top level semantic category from the taxonomy
of Chinese nouns for the head word of the NP
arguments (ARG1_location and ARG0_location).
</bodyText>
<sectionHeader confidence="0.997405" genericHeader="method">
3 Experimental Results
</sectionHeader>
<bodyText confidence="0.999919178571429">
The data we used for our experiments are
developed as part of the OntoNotes project
(Hovy et al., 2006) and they come from a variety
of sources. Part of the data is from the Chinese
Treebank (Xue et al, 2005), which has a
combination of Xinhua news and Sinorama
News Magazine. Since some verbs have an
insufficient number of instances for any
meaningful experiments, we also annotated
portions of the People&apos;s Daily corpus, developed
by Peking University. We chose not to use the
Chinese WSD dataset used in Senseval 3 1
because we are mainly interested in investigating
how the features used in WSD are related to the
criteria used to define the senses of Chinese
verbs. The Chinese Senseval dataset includes
both nouns and verbs. In addition, the criteria
used to define their senses are not made explicit
and therefore are not clear to us.
Table 1 summarizes the corpus statistics and
the experimental results for the 10 highly
polysemous Chinese verbs used in our
experiments. The results were obtained by using
5-fold cross validation. The top five verbs are
verbs that were identified as difficult verbs in
Dang et al&apos;s (2002) experiments. The first three
columns show the verbs (and their pinyin), the
number of instances and the number of senses for
</bodyText>
<equation confidence="0.957994">
1 http://www.senseval.org/senseval3
n
−E P(sensei) log P(sensei) (1)
i=1
</equation>
<bodyText confidence="0.9675566875">
Where n is the number of senses of a verb in our
data; P(sensei) is the probability of the ith sense
of the verb, which is estimated based on the
frequency count of the verb&apos;s senses in the data.
Sense entropy generally reflects the frequency
distribution of senses in the corpus. A verb with
an evenly distributed sense distribution tends to
have a high entropy value. However, a verb can
also have a high sense entropy simply because it
is highly polysemous (say, has 20 or more senses)
even though the sense distribution may be
skewed, with one or two dominant senses. To
separate the effects of the number of senses, we
also use a normalized sense entropy metric (the
sixth column in Table 1), as calculated in
Equation 2.
</bodyText>
<equation confidence="0.97587725">
n
E ( i
P sense
(2)
</equation>
<bodyText confidence="0.9912365">
Here a large sense number n corresponds to a
high value for the normalization factor
</bodyText>
<equation confidence="0.740729">
n− E 1 logP(1) . Therefore, normalized sense
</equation>
<bodyText confidence="0.996666777777778">
entropy can indicate sense frequency distribution
more precisely than sense entropy.
Table 1 (Columns 7 to 10) also shows the
experimental results. As we can see, on average,
our system achieved about 19% improvement
(absolute gain) in accuracy compared to the most
frequent sense baseline. Its performance is
consistently better than the baseline for all 10
verbs.
</bodyText>
<subsectionHeader confidence="0.9406435">
3.1 Corpus Statistics and Disambiguation
Accuracy
</subsectionHeader>
<bodyText confidence="0.9999618">
The data in Table 1 shows that verbs with a high
normalized sense entropy have the low frequency
baselines. Furthermore, this relation is stronger
than that between un-normalized sense entropy
and the baseline. However, sense entropy is a
better predictor for system performance than
normalized sense entropy. The reason is intuitive:
unlike the baseline, the automatic WSD system,
trained on the training data, does not only rely on
sense frequency information to predict senses.
</bodyText>
<equation confidence="0.999423347826087">
−
) log
P(sense)
i
i
=
1
1
n
1
P
−
)
log
(
E
i
n
n
=
1
n n
i =1
</equation>
<page confidence="0.996741">
924
</page>
<table confidence="0.999868933333333">
# of # of sense norm. baseline all feat all-SRL
instance sense entropy sense
entropy
出|chu 271 11 1.12 0.47 74.54 79.70 78.59
恢复|huifu 113 3 0.93 0.84 50.44 69.91 72.57
见|jian 167 7 1.01 0.52 72.46 82.63 82.03
想|xiang 231 6 1.00 0.56 65.80 76.19 77.49
要|yao 254 9 1.56 0.71 33.46 46.46 49.21
成|cheng 161 8 1.38 0.67 43.48 73.29 72.67
打|da 313 21 2.29 0.75 20.77 45.05 32.59
开|kai 382 18 2.31 0.80 19.37 50.00 39.27
通过|tongguo 384 4 0.97 0.70 55.73 81.51 79.17
发展|fazhan 1141 7 0.88 0.45 74.76 79.58 77.56
average 9.4 51.08 70.18 67.13
total 3417
</table>
<tableCaption confidence="0.998228">
Table 1 Corpus Statistics and Experimental Results for the 10 Chinese Verbs
</tableCaption>
<bodyText confidence="0.999661166666667">
The number of senses has a direct impact on how
many training instances exist for each verb sense.
As a consequence, it is more difficult for the
system to make good generalizations from the
limited training data that is available for highly
polysemous verbs. Therefore, sense entropy,
which is based on both sense frequency
distribution and polysemy is more appropriate
for predicting system accuracy. A related
observation is that the system gain (compared
with the baseline) is bigger for verbs with a high
normalized sense entropy, such as &amp;quot;恢复|huifu&amp;quot;,
&amp;quot;打|da&amp;quot;, &amp;quot;开|kai&amp;quot;, and &amp;quot;通过|tongguo&amp;quot;, than for
other verbs; and the system gain is very small for
verbs with low normalized sense entropy and a
relatively large number of senses, such as &amp;quot;出
|chu&amp;quot; and &amp;quot;发展|fazhan&amp;quot;, since they already have
high baselines.
</bodyText>
<subsectionHeader confidence="0.999041">
3.2 The Effect of Semantic Role Features
</subsectionHeader>
<bodyText confidence="0.999698909090909">
When Semantic Role information is used in
features, the system&apos;s performance on average
improves 3.05%, from 67.13% to 70.18%
compared with when the features derived from
the Semantic Role information is not used. If we
look at the system&apos;s performance on individual
verbs, the results show that adding Semantic
Role information as features improves the
accuracy of 7 of the 10 verbs. For the remaining
3 verbs, adding semantic role information
actually hurts the system&apos;s performance. We
believe this apparent inconsistency can be
explained by looking at how senses are defined
for the different verbs. The two verbs that
present the most challenge to the system, are
&amp;quot;打|da&amp;quot; and &amp;quot;要|yao&amp;quot; While Semantic Role
features substantially improve the accuracy of
&amp;quot;打|da&amp;quot;, they actually hurt the accuracy of &amp;quot;要
|yao&amp;quot;. For &amp;quot;要|yao&amp;quot;, its three most frequent
senses account for 86% of its total instances (232
out of 270) and they are the &amp;quot;intend to&amp;quot;, &amp;quot;must,
should&amp;quot; and &amp;quot;need&amp;quot; senses:
</bodyText>
<figure confidence="0.79902225">
(4) Three most frequent senses of &amp;quot;要|yao&amp;quot;
(a) 双方 表表 要 进一步 合合 。
two sides indicate intend further cooperation
&amp;quot;The two sides indicated that they intended to step up
their cooperation.&amp;quot;
(b) 公 很 滑 , 大大 要 小小 。
road very slippery, everybody should careful
&amp;quot;The road is slippery. Everybody should be careful.&amp;quot;
(c) 苏苏 每 年 要 靠
Suzhou Steel Works every year need depend
大大大 大运 原原 。
the Great Canal transport raw material
</figure>
<figureCaption confidence="0.3290475">
&amp;quot;Suzhou Steel Works needs to depend on the Great
Canal to transport raw material.&amp;quot;
</figureCaption>
<bodyText confidence="0.999968333333333">
Two of the senses, &amp;quot;must&amp;quot; and &amp;quot;need&amp;quot;, are
used as auxiliary verbs. As such, they do not take
arguments in the same way non-auxiliary verbs
do. For example, they do not take noun phrases
as arguments. As a result, the Semantic Role
tagger, which assigns argument labels to head
words of noun phrases or clauses, cannot
produce a meaningful argument for an auxiliary
verb. For the &amp;quot;intend to&amp;quot; sense, even if it is not
</bodyText>
<page confidence="0.996813">
925
</page>
<bodyText confidence="0.99975025">
an auxiliary verb, it still does not take a noun
phrase as an object. Instead, its object is a verb
phrase or a clause, depending on the analysis.
The correct head word of its argument should be
the lower verb, which apparently is not a useful
discriminative feature either.
In contrast, the senses of &amp;quot;47lda&amp;quot; are generally
defined based on their arguments. The three most
frequent senses of &amp;quot; 47 Ida&amp;quot; are &amp;quot;call by
telephone&amp;quot;, &amp;quot;play&amp;quot; and &amp;quot;fight&amp;quot; and they account
for 40% of the &amp;quot;47lda&amp;quot; instances. Some examples
are provided in (5)
</bodyText>
<figure confidence="0.950952181818182">
(5) Top three senses of &amp;quot;47lda&amp;quot;
(a) *, ;qA 4f-r-, 47
you have queue in long line call
� Al r,it N 4-9-;1% [[1 ?
public phone DE experience ma
&amp;quot;Do you have the experience of queuing in a line
and waiting to make a call with a public phone?&amp;quot;
(b) Il.^ T1* A161 HIM
a few on duty personnel sit
� 0 47 *A �
one circle play poker
</figure>
<figureCaption confidence="0.4845645">
&amp;quot;A few of the personnel on duty were sitting in a
circle and playing poker.&amp;quot;
</figureCaption>
<listItem confidence="0.665613">
(c) 4161 � #� k- tilt 470
mobilize whole society power fight
</listItem>
<equation confidence="0.747843">
RR YA4� iW �
</equation>
<bodyText confidence="0.998606816666667">
helping the poor crucial battle
&amp;quot;...mobilize the power of the whole society and
fight the crucial battle of helping the poor.&amp;quot;
The senses of &amp;quot;47�da&amp;quot; are to a large extent
determined by its PATIENT (or Argl) argument,
which is generally realized in the object position.
The Argl argument usually forms highly
coherent lexical classes. For example, the Argl
of the &amp;quot;call&amp;quot; sense can be &amp;quot; r, it
Idianghua/phone, &amp;quot;-T- #L |shouji/cellphone&amp;quot;,
etc. its Arg] argument can be &amp;quot; I f*
Ilangqiu/basketball&amp;quot;, &amp;quot; * 9 lqiaopai/bridge&amp;quot;,
&amp;quot;eAIyouxi/game&amp;quot;, etc for the &amp;quot;play&amp;quot; sense,
Finally , for its sense &amp;quot;fight&amp;quot;, the Arg] argument
can be &amp;quot;YAMIgongjian/crucial iW1zhan/battle&amp;quot;,
&amp;quot;8iWIxiangzhang/street warfare&amp;quot;, &amp;quot;eariWI
youjizhan/guerilla warfare&amp;quot;, etc.. It&apos;s not
surprising that recognizing the arguments of
&amp;quot;47lda&amp;quot; is crucial in determining its sense.
The accuracy for both verbs is still very low,
but for very different reasons. In the case of
&amp;quot;_51yao4&amp;quot;, the challenge is identifying
discriminative features that may not be found in
the narrow local context. These could for
instance include discourse features. In the case of
&amp;quot;471da&apos;, one important reason why the accuracy
is still low is because &amp;quot;47Ida&amp;quot; is highly
polysemous and has over forty senses. Given its
large number of senses, the majority of its senses
do not have enough instances to train a
reasonable model. We believe that more data will
improve its WSD accuracy.
There are other dimensions along which verb
senses are defined in addition to whether or not a
verb is an auxiliary verb and what type of
auxiliary verb it is, and what types of arguments
it takes. One sense of &amp;quot;,&apos;f{Ichu&amp;quot; is a verb particle
that indicates the direction or aspect of the main
verb that generally immediately precedes it. In
this case the most important feature for
identifying this sense is the collocation feature.
Our experimental results seem to lend support
to a WSD approach where features are tailored to
each target word, or at least each class of words,
based on a careful analysis of the dimensions
along which senses are defined. Automatic
feature selection (Blum and Langley, 1997)
could also prove useful in providing this type of
tailoring. An issue that immediately arises is the
feasibility of this approach. At least for Chinese,
the task is not too daunting, as the number of
highly polysemous verbs is small. Our estimation
based on a 250K-word chunk of the Chinese
Treebank and a large electronic dictionary in our
possession shows only 6% or 384 verb types
having four or more definitions in the dictionary.
Even for these verbs, the majority of them are
not difficult to disambiguate, based on work by
Dang et al. (2002). Only a small number of these
verbs truly need customized features.
</bodyText>
<sectionHeader confidence="0.999904" genericHeader="method">
4 Related work
</sectionHeader>
<bodyText confidence="0.999508">
There is a large body of literature on WSD and
here we only discuss a few that are most relevant
to our work. Dang and Palmer (2005) also use
predicate-argument information as features in
their work on English verbs, but their argument
labels are not produced by an automatic SRL
system. Rather, their semantic role labels are
directly extracted from a human annotated
</bodyText>
<page confidence="0.996059">
926
</page>
<bodyText confidence="0.98764431884058">
corpus, the English Proposition Bank (Palmer et
al, 2005), citing the inadequate accuracy of
automatic semantic role labeling systems. In
contrast, we used a fully antomated SRL system
trained on the Chinese Propbank. Nevertheless,
their results show, as ours do, that the use of
semantic role labels as features improves the
WSD accuracy of verbs.
There are relatively few attempts to use
linguistically motivated features for Chinese
word sense disambiguation. Niu et al (2004)
applied a Naive Bayesian model to Chinese
WSD and experimented with different window
sizes for extracting local and topical features and
different types of local features (e.g., bigram
templates, local words with position or parts-of-
speech information). One basic finding of their
experiments is that simply increasing the window
size for extracting local features or enriching the
set of local features does not improve
disambiguation performance. This is consistent
with our usage of a small size window for
extracting bigram collocation features. Li et al.
(2005) used sense-tagged true bigram
collocations 2 as features. These features were
obtained from a collocation extraction system
that used lexical co-occurrence statistics to
extract candidate collocations and then selected
true collocations by using syntactic dependencies
(Xu et al., 2003). In their experiments on
Chinese nouns and verbs extracted from the
People&apos;s Daily News and the SENSEVAL3 data
set, the Naive Bayesian classifier using true
collocation features generally performed better
than that using simple bigram collocation
features (i.e., bigram co-occurence features). It is
worth noting that the true collocations overlap to
a large degree with rich syntactic information
used here such as the subject and direct object of
a target verb. Therefore, their experiments show
evidence that rich linguistic information benefits
WSD on Chinese, consistent with our results.
Our work is more closely related to the work
of Dang et al (2002), who conducted
experiments on 28 verbs and achieved an
accuracy of 94.2%. However the high accuarcy is
largely due to the fact that their verbs are
randomly chosen from the Chinese Treebank and
some of them are not even polysemous (having a
single sense). Extracting features from the gold
2 In their definition, a collocation is a recurrent and
conventional fixed expression of words that holds
syntactic and semantic relations.
standard parses also contributed to the high
accuracy, although not by much. For 5 of their 28
verbs, their initial experimental results did not
break the most frequent sense baseline. They
annotated additional data on those five verbs and
their system trained on this new data did
outperfom the baseline. However, they
concluded that the contribution of linguistic
motivated features, such as features extracted
from a syntactic parse, is insignificant, a finding
they attributed to unique properties of Chinese
given that the same syntactic features
significantly improves the WSD accuracy. Our
experimental results show that this conclusion is
premature, without a detailed analysis of the
senses for the individual verbs.
</bodyText>
<sectionHeader confidence="0.978998" genericHeader="conclusions">
5 Conclusion and future work
</sectionHeader>
<bodyText confidence="0.999996458333334">
We presented experiments with ten highly
polysemous Chinese verbs and showed that a
previous conclusion that rich linguistic features
are not useful for the WSD of Chinese verbs is
premature. We demonstrated that rich linguistic
features, specifically features based on syntactic
and semantic role information, are useful for the
WSD of Chinese verbs. We believe that the
WSD systems can benefit even more from rich
linguistic features as the performance of other
NLP tools such as parsers and Semantic Role
Taggers improves. Our experimental results also
lend support to the position that feature design
for WSD should be linked tightly to the study of
the criteria that sense distinctions are based on.
This position calls for the customization of
features for individual verbs based on
understanding of the dimensions along which
sense distinctions are made and a closer marriage
between machine learning and linguistics. We
believe this represents a rich area of exploration
and we intend to experiment with more verbs
with further customization of features, including
experimenting with automatic feature selection.
</bodyText>
<sectionHeader confidence="0.936513" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.9997275">
This work was supported by National Science
Foundation Grant NSF-0415923, Word Sense
Disambiguation, the DTO-AQUAINT NBCHC-
040036 grant under the University of Illinois
subcontract to University of Pennsylvania 2003-
07911-01 and the GALE program of the Defense
Advanced Research Projects Agency, Contract
No. HR0011-06-C-0022. Any opinions, findings,
and conclusions or recommendations expressed
in this material are those of the authors and do
</bodyText>
<page confidence="0.989648">
927
</page>
<bodyText confidence="0.989193">
not necessarily reflect the views of the National
Science Foundation, the DTO, or DARPA.
</bodyText>
<sectionHeader confidence="0.993959" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999868828282829">
Avrim L. Blum and Pat Langley. 1997. Selection of
relevant features and examples in machine learning.
Artificial Intelligence, 97:245-271, 1997.
Jinying Chen and Martha Palmer. 2004. Chinese Verb
Sense Discrimination Using an EM Clustering
Model with Rich Linguistic Features, In Proc. of
the 42nd Annual meeting of the Assoication for
Computational Linguistics, ACL-04. July 21-24,
Barcelona, Spain
Jinying Chen and Martha Palmer. 2005. Towards
Robust High Performance Word Sense
Disambiguation of English Verbs Using Rich
Linguistic Features. In Proc. of the 2nd
International Joint Conference on Natural
Language Processing. Jeju Island, Korea, in press.
Stanley. F. Chen and Ronald Rosenfeld. 1999. A
Gaussian Prior for Smoothing Maximum Entropy
Modals. Technical Report CMU-CS-99-108, CMU.
Hoa T. Dang, Ching-yi Chia, Martha Palmer and Fu-
Dong Chiou. 2002. Simple Features for Chinese
Word Sense Disambiguation. In Proceedings of
COLING-2002, the Nineteenth Int. Conference on
Computational Linguistics, Taipei, Aug.24-Sept.1.
Hoa T. Dang. 2004. Investigations into the role of
lexical semantics in word sense disambiguation.
PhD Thesis. University of Pennsylvania.
Hoa Dang and Martha Palmer. 2005. The role of
semantic roles in disambiguating verb senses. In
Proceedings of ACL-05, Ann Arbor, Michigan.
Zhendong Dong and Qiang Dong, HowNet. 1991.
http://www.keenage.com.
Christiane Fellbaum, ed. 1998. WordNet: An
Electronic Lexical Database. Cambridge, MA:
MIT Press.
Veronique Hoste, Iris Hendrickx, Walter Daelemans,
and Antal van den Bosch. 2002. Parameter
optimization for machine-learning of word sense
disambiguation. NLE, Special Issue on Word Sense
Disambiguation Systems, 8(4):311-325.
Eduard Hovy, Mtchchell Marcus, Martha Palmer,
Lance Ramshaw and Ralph Weischedel. 2006.
OntoNotes: the 90% solution. In Proceedings of the
HLT-NAACL 2006, New York City.
Wanyin Li, Qin Lu and Wenjie Li. 2005. Integrating
Collocation Features in Chinese Word Sense
Disambiguation. In Proceedings of the Fourth
Sighan Workshop on Chinese Language Processing.
pp: 87-94. Jeju, Korea.
Andrew K. McCallum: MALLET: A Machine
Learning for Language Toolkit. http://www.cs.
umass.edu/~mccallum/mallet (2002).
Rada Mihalcea, Timothy Chklovski and Adam
Kilgarriff. 2004. The Senseval-3 English lexical
sample task. In Proceedings of Senseval-3: The
Third International Workshop on the Evaluation of
Systems for the Semantic Analysis of Text.
Barcelona, Spain. July.
Zheng-Yu Niu, Dong-Hong Ji and Chew Lim Tan,
Optimizing Feature Set for Chinese Word Sense
Disambiguation. 2004. In Proceedings of the 3rd
International Workshop on the Evaluation of
Systems for the Semantic Analysis of Text
(SENSEVAL-3). Barcelona, Spain.
Martha Palmer, Christiane Fellbaum, Scott Cotton,
Lauren Delfs, and Hoa Trang Dang. 2001. English
tasks: All-words and verb lexical sample.
Proceedings of Senseval-2: Second International
Workshop on Evaluating Word Sense
Disambiguation Systems, Toulouse, France, 21-24.
Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005. The Proposition Bank: An Annotated Corpus
of Semantic Roles, Computational Linguistics,
31(1): 71106.
Martha Palmer, Christiane Fellbaum and Hoa Trang
Dang. (to appear, 2006). Making fine-grained and
coarse-grained sense distinctions, both manually
and automatically. Natural Language Engineering.
Ruifeng Xu , Qin Lu, and Yin Li. 2003. An automatic
Chinese Collocation Extraction Algorithm Based
On Lexical Statistics. In Proceedings of the
NLPKE Workshop. Beijing, China.
Nianwen Xue, Fei Xia, Fu-Dong Chiou and Martha
Palmer. 2005. The Penn Chinese Treebank: Phrase
Structure Annotation of a Large Corpus. Natural
Language Engineering, 11(2):207-238.
Nianwen Xue and Martha Palmer. 2003. Annotating
Propositions in the Penn Chinese Treebank, In
Proceedings of the 2nd SIGHAN Workshop on
Chinese Language Processing, in conjunction with
ACL&apos;03. Sapporo, Japan.
Nianwen Xue and Martha Palmer. 2005. Automatic
Semantic Role Labeling for Chinese Verbs. In
Proceedings of the 19th International Joint
Conference on Artificial Intelligence. Edinburgh,
Scotland.
David Yarowsky and Radu Florian. 2002. Evaluating
sense disambiguation across diverse parameter
spaces. Journal of Natural Language Engineering,
8(4): 293310.
</reference>
<page confidence="0.996971">
928
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.822724">
<title confidence="0.996744">Aligning Features with Sense Distinction Dimensions</title>
<author confidence="0.961586">Nianwen Xue</author>
<author confidence="0.961586">Anying Chen</author>
<author confidence="0.961586">Martha Palmer</author>
<affiliation confidence="0.9998815">and of Linguistics University of Colorado</affiliation>
<address confidence="0.999945">Boulder, CO, 80309</address>
<email confidence="0.94931">Nianwen.Xue@colorado.edu</email>
<email confidence="0.94931">Martha.Palmer@colorado.edu</email>
<affiliation confidence="0.9978925">of Computer and Information Science University of Pennsylvania</affiliation>
<address confidence="0.999816">Philadelphia, PA, 19104</address>
<email confidence="0.999649">jinying@cis.upenn.edu</email>
<abstract confidence="0.996631428571429">In this paper we present word sense disambiguation (WSD) experiments on ten highly polysemous verbs in Chinese, where significant performance improvements are achieved using rich linguistic features. Our system performs significantly better, and in some cases substantially better, than the baseline on all ten verbs. Our results also demonstrate that features extracted from the output of an automatic Chinese semantic role labeling system in general benefited the WSD system, even though the amount of improvement was not consistent across the verbs. For a few verbs, semantic role information actually hurt WSD performance. The inconsistency of feature performance is a general characteristic of the WSD task, as has been observed by others. We argue that this result can be explained by the fact that word senses are partitioned along different dimensions for different verbs and the features therefore need to be tailored to particular verbs in order to achieve adequate accuracy on verb sense disambiguation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Avrim L Blum</author>
<author>Pat Langley</author>
</authors>
<title>Selection of relevant features and examples in machine learning.</title>
<date>1997</date>
<journal>Artificial Intelligence,</journal>
<pages>97--245</pages>
<contexts>
<context position="22803" citStr="Blum and Langley, 1997" startWordPosition="3735" endWordPosition="3738"> or not a verb is an auxiliary verb and what type of auxiliary verb it is, and what types of arguments it takes. One sense of &amp;quot;,&apos;f{Ichu&amp;quot; is a verb particle that indicates the direction or aspect of the main verb that generally immediately precedes it. In this case the most important feature for identifying this sense is the collocation feature. Our experimental results seem to lend support to a WSD approach where features are tailored to each target word, or at least each class of words, based on a careful analysis of the dimensions along which senses are defined. Automatic feature selection (Blum and Langley, 1997) could also prove useful in providing this type of tailoring. An issue that immediately arises is the feasibility of this approach. At least for Chinese, the task is not too daunting, as the number of highly polysemous verbs is small. Our estimation based on a 250K-word chunk of the Chinese Treebank and a large electronic dictionary in our possession shows only 6% or 384 verb types having four or more definitions in the dictionary. Even for these verbs, the majority of them are not difficult to disambiguate, based on work by Dang et al. (2002). Only a small number of these verbs truly need cus</context>
</contexts>
<marker>Blum, Langley, 1997</marker>
<rawString>Avrim L. Blum and Pat Langley. 1997. Selection of relevant features and examples in machine learning. Artificial Intelligence, 97:245-271, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinying Chen</author>
<author>Martha Palmer</author>
</authors>
<title>Chinese Verb Sense Discrimination Using an EM Clustering Model with Rich Linguistic Features,</title>
<date>2004</date>
<booktitle>In Proc. of the 42nd Annual meeting of the Assoication for Computational Linguistics, ACL-04.</booktitle>
<location>Barcelona, Spain</location>
<contexts>
<context position="7718" citStr="Chen and Palmer, 2004" startWordPosition="1195" endWordPosition="1198">segmented, POS-tagged and parsed version of the same text to facilitate the extraction of the different types of features. The extraction of the semantic role labels as features requires the use of a semantic role tagger, which we describe in greater detail in Section 2.2. In addition to using the semantic role labeling information, we also extract another type of semantic features from the verb&apos;s NP arguments. These features are top-level semantic categories from a three-level general taxonomy for Chinese nouns, which was created semi-automatically based on two Chinese semantic dictionaries (Chen and Palmer, 2004). 2.1 A Comparison with Our English WSD System Similar to our English WSD system, which achieved the best published results on SENSEVAL2 English verbs for both finegrained and coarse-grained senses (Chen and Palmer, 2005), our Chinese WSD system uses the same smoothed MaxEnt machine learning model and linguistically motivated features for Chinese verb sense disambiguation. However, the features used in the two systems differ 922 somewhat due to the different properties of the two languages . For example, our English system uses the inflected form and the part-of-speech tag of the target verb a</context>
</contexts>
<marker>Chen, Palmer, 2004</marker>
<rawString>Jinying Chen and Martha Palmer. 2004. Chinese Verb Sense Discrimination Using an EM Clustering Model with Rich Linguistic Features, In Proc. of the 42nd Annual meeting of the Assoication for Computational Linguistics, ACL-04. July 21-24, Barcelona, Spain</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinying Chen</author>
<author>Martha Palmer</author>
</authors>
<title>Towards Robust High Performance Word Sense Disambiguation of English Verbs Using Rich Linguistic Features.</title>
<date>2005</date>
<booktitle>In Proc. of the 2nd International Joint Conference on Natural Language Processing. Jeju Island,</booktitle>
<note>in press.</note>
<contexts>
<context position="4261" citStr="Chen and Palmer, 2005" startWordPosition="631" endWordPosition="634">onference Poster Sessions, pages 921–928, Sydney, July 2006. c�2006 Association for Computational Linguistics we will go one step further and show that even for words of the same syntactic category senses are often defined along different dimensions based on different criteria. One direct implication of this observation for supervised machinelearning approaches to WSD is that the features have to be customized for different word categories, or even for different words of the same category. This supports previous arguments for word-specific feature design and parametric modeling for WSD tasks (Chen and Palmer, 2005; Hoste et al. 2002). We report experiments on ten highly polysemous Chinese verbs and show that features are not uniformly useful for all words. The rest of the paper is organized as follows. In Section 2, we describe our WSD system, focusing on the features we used. We also briefly compare the features we use for Chinese with those used in a similar English WSD system. In Section 3, we present our experimental results and show that although rich linguistic features and features derived from a Chinese Semantic Role Labeling improve the WSD accuracy, the improvement is not uniform across all v</context>
<context position="5689" citStr="Chen and Palmer, 2005" startWordPosition="862" endWordPosition="865">es future directions. 2 WSD System for Chinese Verbs Our WSD system uses a smoothed maximum entropy (MaxEnt) model with a Gaussian prior (McCallum, 2002) for learning Chinese verb senses. The primary reason is that the MaxEnt model provides a natural way for combining different features without the assumption of feature independence. Furthermore, smoothing the MaxEnt model with a Gaussian prior is better than other smoothing methods at alleviating the overfitting problem caused by low frequency features (Chen et al., 1999). This model has been applied successfully for English WSD (Dang, 2004; Chen and Palmer, 2005). The features used by our Chinese WSD system include: Collocation Features - Previous and next word (relative to the target verb), w_1 and w1 and their parts-of-speech p_1 and p1 Syntactic Features - Whether the target verb takes a direct object (i.e., in a transitive use) - Whether the verb takes a sentential complement - Whether the verb, if it consists of a single character, occurs at the last position of a compound verb Semantic Features - The semantic role information about the verbs - The semantic categories for the verb&apos;s NP arguments from a general Chinese noun Taxonomy All of these f</context>
<context position="7939" citStr="Chen and Palmer, 2005" startWordPosition="1230" endWordPosition="1233"> which we describe in greater detail in Section 2.2. In addition to using the semantic role labeling information, we also extract another type of semantic features from the verb&apos;s NP arguments. These features are top-level semantic categories from a three-level general taxonomy for Chinese nouns, which was created semi-automatically based on two Chinese semantic dictionaries (Chen and Palmer, 2004). 2.1 A Comparison with Our English WSD System Similar to our English WSD system, which achieved the best published results on SENSEVAL2 English verbs for both finegrained and coarse-grained senses (Chen and Palmer, 2005), our Chinese WSD system uses the same smoothed MaxEnt machine learning model and linguistically motivated features for Chinese verb sense disambiguation. However, the features used in the two systems differ 922 somewhat due to the different properties of the two languages . For example, our English system uses the inflected form and the part-of-speech tag of the target verb as feature. For Chinese we no longer use such features since Chinese words, unlike English ones, do not contain morphology that marks tense. The collocation features used by our English system include bi-grams and tri-gram</context>
</contexts>
<marker>Chen, Palmer, 2005</marker>
<rawString>Jinying Chen and Martha Palmer. 2005. Towards Robust High Performance Word Sense Disambiguation of English Verbs Using Rich Linguistic Features. In Proc. of the 2nd International Joint Conference on Natural Language Processing. Jeju Island, Korea, in press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Chen</author>
<author>Ronald Rosenfeld</author>
</authors>
<title>A Gaussian Prior for Smoothing Maximum Entropy Modals.</title>
<date>1999</date>
<tech>Technical Report CMU-CS-99-108, CMU.</tech>
<marker>Chen, Rosenfeld, 1999</marker>
<rawString>Stanley. F. Chen and Ronald Rosenfeld. 1999. A Gaussian Prior for Smoothing Maximum Entropy Modals. Technical Report CMU-CS-99-108, CMU.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoa T Dang</author>
<author>Ching-yi Chia</author>
<author>Martha Palmer</author>
<author>FuDong Chiou</author>
</authors>
<title>Simple Features for Chinese Word Sense Disambiguation.</title>
<date>2002</date>
<booktitle>In Proceedings of COLING-2002, the Nineteenth Int. Conference on Computational Linguistics,</booktitle>
<location>Taipei, Aug.24-Sept.1.</location>
<contexts>
<context position="23352" citStr="Dang et al. (2002)" startWordPosition="3830" endWordPosition="3833">ses are defined. Automatic feature selection (Blum and Langley, 1997) could also prove useful in providing this type of tailoring. An issue that immediately arises is the feasibility of this approach. At least for Chinese, the task is not too daunting, as the number of highly polysemous verbs is small. Our estimation based on a 250K-word chunk of the Chinese Treebank and a large electronic dictionary in our possession shows only 6% or 384 verb types having four or more definitions in the dictionary. Even for these verbs, the majority of them are not difficult to disambiguate, based on work by Dang et al. (2002). Only a small number of these verbs truly need customized features. 4 Related work There is a large body of literature on WSD and here we only discuss a few that are most relevant to our work. Dang and Palmer (2005) also use predicate-argument information as features in their work on English verbs, but their argument labels are not produced by an automatic SRL system. Rather, their semantic role labels are directly extracted from a human annotated 926 corpus, the English Proposition Bank (Palmer et al, 2005), citing the inadequate accuracy of automatic semantic role labeling systems. In contr</context>
<context position="25802" citStr="Dang et al (2002)" startWordPosition="4209" endWordPosition="4212"> verbs extracted from the People&apos;s Daily News and the SENSEVAL3 data set, the Naive Bayesian classifier using true collocation features generally performed better than that using simple bigram collocation features (i.e., bigram co-occurence features). It is worth noting that the true collocations overlap to a large degree with rich syntactic information used here such as the subject and direct object of a target verb. Therefore, their experiments show evidence that rich linguistic information benefits WSD on Chinese, consistent with our results. Our work is more closely related to the work of Dang et al (2002), who conducted experiments on 28 verbs and achieved an accuracy of 94.2%. However the high accuarcy is largely due to the fact that their verbs are randomly chosen from the Chinese Treebank and some of them are not even polysemous (having a single sense). Extracting features from the gold 2 In their definition, a collocation is a recurrent and conventional fixed expression of words that holds syntactic and semantic relations. standard parses also contributed to the high accuracy, although not by much. For 5 of their 28 verbs, their initial experimental results did not break the most frequent </context>
</contexts>
<marker>Dang, Chia, Palmer, Chiou, 2002</marker>
<rawString>Hoa T. Dang, Ching-yi Chia, Martha Palmer and FuDong Chiou. 2002. Simple Features for Chinese Word Sense Disambiguation. In Proceedings of COLING-2002, the Nineteenth Int. Conference on Computational Linguistics, Taipei, Aug.24-Sept.1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoa T Dang</author>
</authors>
<title>Investigations into the role of lexical semantics in word sense disambiguation. PhD Thesis.</title>
<date>2004</date>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="5665" citStr="Dang, 2004" startWordPosition="860" endWordPosition="861"> and describes future directions. 2 WSD System for Chinese Verbs Our WSD system uses a smoothed maximum entropy (MaxEnt) model with a Gaussian prior (McCallum, 2002) for learning Chinese verb senses. The primary reason is that the MaxEnt model provides a natural way for combining different features without the assumption of feature independence. Furthermore, smoothing the MaxEnt model with a Gaussian prior is better than other smoothing methods at alleviating the overfitting problem caused by low frequency features (Chen et al., 1999). This model has been applied successfully for English WSD (Dang, 2004; Chen and Palmer, 2005). The features used by our Chinese WSD system include: Collocation Features - Previous and next word (relative to the target verb), w_1 and w1 and their parts-of-speech p_1 and p1 Syntactic Features - Whether the target verb takes a direct object (i.e., in a transitive use) - Whether the verb takes a sentential complement - Whether the verb, if it consists of a single character, occurs at the last position of a compound verb Semantic Features - The semantic role information about the verbs - The semantic categories for the verb&apos;s NP arguments from a general Chinese noun</context>
</contexts>
<marker>Dang, 2004</marker>
<rawString>Hoa T. Dang. 2004. Investigations into the role of lexical semantics in word sense disambiguation. PhD Thesis. University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoa Dang</author>
<author>Martha Palmer</author>
</authors>
<title>The role of semantic roles in disambiguating verb senses.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL-05,</booktitle>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="10366" citStr="Dang and Palmer (2005)" startWordPosition="1625" endWordPosition="1628"> (2)4_6i NA a.10 9 �r � mobilize people tighten waistband collect 1� ff kV (direct object) funds build highway &amp;quot;Mobilize people to tighten their waistbands (i.e., save money) in order to collect funds to build highways.&amp;quot; Based on these observations, we use words surrounding the target verb and their part-ofspeech tags as collocation features. A further investigation on the different sizes of the context window (3,5,7,9,11) showed that increasing the window size decreased our system&apos;s accuracy. 2.2 Features Based on Automatic Semantic Role Tagging In a recent paper on the WSD of English verbs, Dang and Palmer (2005) showed that semantic role information significantly improves the WSD accuracy of English verbs for both fine-grained and coarse-grained senses. However, this result assumes the human annotation of the Penn English Propbank (Palmer et al, 2005). It seems worthwhile to investigate whether the semantic role information produced by a fully automatic Semantic Role tagger can improve the WSD accuracy on verbs, and test the hypothesis that the senses of a verb have a high correlation to the arguments it takes. To that end, we assigned semantic role labels to the arguments of the target verb with a f</context>
<context position="23568" citStr="Dang and Palmer (2005)" startWordPosition="3871" endWordPosition="3874">r Chinese, the task is not too daunting, as the number of highly polysemous verbs is small. Our estimation based on a 250K-word chunk of the Chinese Treebank and a large electronic dictionary in our possession shows only 6% or 384 verb types having four or more definitions in the dictionary. Even for these verbs, the majority of them are not difficult to disambiguate, based on work by Dang et al. (2002). Only a small number of these verbs truly need customized features. 4 Related work There is a large body of literature on WSD and here we only discuss a few that are most relevant to our work. Dang and Palmer (2005) also use predicate-argument information as features in their work on English verbs, but their argument labels are not produced by an automatic SRL system. Rather, their semantic role labels are directly extracted from a human annotated 926 corpus, the English Proposition Bank (Palmer et al, 2005), citing the inadequate accuracy of automatic semantic role labeling systems. In contrast, we used a fully antomated SRL system trained on the Chinese Propbank. Nevertheless, their results show, as ours do, that the use of semantic role labels as features improves the WSD accuracy of verbs. There are </context>
</contexts>
<marker>Dang, Palmer, 2005</marker>
<rawString>Hoa Dang and Martha Palmer. 2005. The role of semantic roles in disambiguating verb senses. In Proceedings of ACL-05, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhendong Dong</author>
<author>Qiang Dong</author>
<author>HowNet</author>
</authors>
<date>1991</date>
<note>http://www.keenage.com.</note>
<marker>Dong, Dong, HowNet, 1991</marker>
<rawString>Zhendong Dong and Qiang Dong, HowNet. 1991. http://www.keenage.com.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
<author>ed</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA:</location>
<marker>Fellbaum, ed, 1998</marker>
<rawString>Christiane Fellbaum, ed. 1998. WordNet: An Electronic Lexical Database. Cambridge, MA: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veronique Hoste</author>
<author>Iris Hendrickx</author>
<author>Walter Daelemans</author>
<author>Antal van den Bosch</author>
</authors>
<title>Parameter optimization for machine-learning of word sense disambiguation.</title>
<date>2002</date>
<journal>NLE, Special Issue on Word Sense Disambiguation Systems,</journal>
<pages>8--4</pages>
<marker>Hoste, Hendrickx, Daelemans, van den Bosch, 2002</marker>
<rawString>Veronique Hoste, Iris Hendrickx, Walter Daelemans, and Antal van den Bosch. 2002. Parameter optimization for machine-learning of word sense disambiguation. NLE, Special Issue on Word Sense Disambiguation Systems, 8(4):311-325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard Hovy</author>
<author>Mtchchell Marcus</author>
<author>Martha Palmer</author>
<author>Lance Ramshaw</author>
<author>Ralph Weischedel</author>
</authors>
<title>OntoNotes: the 90% solution.</title>
<date>2006</date>
<booktitle>In Proceedings of the HLT-NAACL 2006,</booktitle>
<location>New York City.</location>
<contexts>
<context position="13249" citStr="Hovy et al., 2006" startWordPosition="2094" endWordPosition="2097">ARG0-地方 ARG0_location ARGM|MNR-经过 ARGM|MNR-经受 ARGM|MNR In this example, semantic role related features include: (1) the head word of the core arguments (ARG1-水井 and ARG0-乡) and the adjunct (ARGM|MNR-经过); (2) the HowNet semantic category for the head word (ARG1-设施, ARG0- 地方, ARGM|MNR-经受); (3) the semantic role label of the adjunct (ARGM|MNR); and (4) the top level semantic category from the taxonomy of Chinese nouns for the head word of the NP arguments (ARG1_location and ARG0_location). 3 Experimental Results The data we used for our experiments are developed as part of the OntoNotes project (Hovy et al., 2006) and they come from a variety of sources. Part of the data is from the Chinese Treebank (Xue et al, 2005), which has a combination of Xinhua news and Sinorama News Magazine. Since some verbs have an insufficient number of instances for any meaningful experiments, we also annotated portions of the People&apos;s Daily corpus, developed by Peking University. We chose not to use the Chinese WSD dataset used in Senseval 3 1 because we are mainly interested in investigating how the features used in WSD are related to the criteria used to define the senses of Chinese verbs. The Chinese Senseval dataset in</context>
</contexts>
<marker>Hovy, Marcus, Palmer, Ramshaw, Weischedel, 2006</marker>
<rawString>Eduard Hovy, Mtchchell Marcus, Martha Palmer, Lance Ramshaw and Ralph Weischedel. 2006. OntoNotes: the 90% solution. In Proceedings of the HLT-NAACL 2006, New York City.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wanyin Li</author>
<author>Qin Lu</author>
<author>Wenjie Li</author>
</authors>
<title>Integrating Collocation Features in Chinese Word Sense Disambiguation.</title>
<date>2005</date>
<booktitle>In Proceedings of the Fourth Sighan Workshop on Chinese Language Processing.</booktitle>
<pages>87--94</pages>
<location>Jeju,</location>
<contexts>
<context position="24855" citStr="Li et al. (2005)" startWordPosition="4068" endWordPosition="4071">inese word sense disambiguation. Niu et al (2004) applied a Naive Bayesian model to Chinese WSD and experimented with different window sizes for extracting local and topical features and different types of local features (e.g., bigram templates, local words with position or parts-ofspeech information). One basic finding of their experiments is that simply increasing the window size for extracting local features or enriching the set of local features does not improve disambiguation performance. This is consistent with our usage of a small size window for extracting bigram collocation features. Li et al. (2005) used sense-tagged true bigram collocations 2 as features. These features were obtained from a collocation extraction system that used lexical co-occurrence statistics to extract candidate collocations and then selected true collocations by using syntactic dependencies (Xu et al., 2003). In their experiments on Chinese nouns and verbs extracted from the People&apos;s Daily News and the SENSEVAL3 data set, the Naive Bayesian classifier using true collocation features generally performed better than that using simple bigram collocation features (i.e., bigram co-occurence features). It is worth noting</context>
</contexts>
<marker>Li, Lu, Li, 2005</marker>
<rawString>Wanyin Li, Qin Lu and Wenjie Li. 2005. Integrating Collocation Features in Chinese Word Sense Disambiguation. In Proceedings of the Fourth Sighan Workshop on Chinese Language Processing. pp: 87-94. Jeju, Korea.</rawString>
</citation>
<citation valid="false">
<authors>
<author>K Andrew</author>
</authors>
<title>McCallum: MALLET: A Machine Learning for Language Toolkit.</title>
<marker>Andrew, </marker>
<rawString>Andrew K. McCallum: MALLET: A Machine Learning for Language Toolkit. http://www.cs. umass.edu/~mccallum/mallet (2002).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Timothy Chklovski</author>
<author>Adam Kilgarriff</author>
</authors>
<title>The Senseval-3 English lexical sample task.</title>
<date>2004</date>
<booktitle>In Proceedings of Senseval-3: The Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text.</booktitle>
<location>Barcelona, Spain.</location>
<contexts>
<context position="2154" citStr="Mihalcea et al., 2004" startWordPosition="311" endWordPosition="314">occurs, is a continuing obstacle to high performance natural language processing applications. There are several well-documented factors that make accurate WSD particularly challenging. The first has to do with how senses are defined. The English data used for the SENSEVAL exercises, arguably the most widely used data to train and test WSD systems, are annotated based on very fine-grained distinctions defined in WordNet (Fellbaum, 1998), with human inter-annotator agreement at a little over seventy percent and the top-ranked systems&apos; performances falling between 60%-70% (Palmer, et al., 2001; Mihalcea et al., 2004). The second source of difficulty for accurate WSD comes from how senses are distributed. It is often the case that a polysemous word has a dominant sense or several dominant senses that occur with high frequency and not enough instances can be found for its low frequency senses in the currently publicly available data. There are on-going efforts to address these issues. For example, the sense annotation component of the OntoNotes project (Novy, et al., 2006) attempts to create a large-scale coarsegrained sense-annotated corpus with senses defined based on explicit linguistic criteria. These p</context>
</contexts>
<marker>Mihalcea, Chklovski, Kilgarriff, 2004</marker>
<rawString>Rada Mihalcea, Timothy Chklovski and Adam Kilgarriff. 2004. The Senseval-3 English lexical sample task. In Proceedings of Senseval-3: The Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text. Barcelona, Spain. July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zheng-Yu Niu</author>
<author>Dong-Hong Ji</author>
<author>Chew Lim Tan</author>
</authors>
<title>Optimizing Feature Set for Chinese Word Sense Disambiguation.</title>
<date>2004</date>
<booktitle>In Proceedings of the 3rd International Workshop on the Evaluation of Systems for the Semantic Analysis of Text (SENSEVAL-3).</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="24288" citStr="Niu et al (2004)" startWordPosition="3982" endWordPosition="3985">labels are not produced by an automatic SRL system. Rather, their semantic role labels are directly extracted from a human annotated 926 corpus, the English Proposition Bank (Palmer et al, 2005), citing the inadequate accuracy of automatic semantic role labeling systems. In contrast, we used a fully antomated SRL system trained on the Chinese Propbank. Nevertheless, their results show, as ours do, that the use of semantic role labels as features improves the WSD accuracy of verbs. There are relatively few attempts to use linguistically motivated features for Chinese word sense disambiguation. Niu et al (2004) applied a Naive Bayesian model to Chinese WSD and experimented with different window sizes for extracting local and topical features and different types of local features (e.g., bigram templates, local words with position or parts-ofspeech information). One basic finding of their experiments is that simply increasing the window size for extracting local features or enriching the set of local features does not improve disambiguation performance. This is consistent with our usage of a small size window for extracting bigram collocation features. Li et al. (2005) used sense-tagged true bigram co</context>
</contexts>
<marker>Niu, Ji, Tan, 2004</marker>
<rawString>Zheng-Yu Niu, Dong-Hong Ji and Chew Lim Tan, Optimizing Feature Set for Chinese Word Sense Disambiguation. 2004. In Proceedings of the 3rd International Workshop on the Evaluation of Systems for the Semantic Analysis of Text (SENSEVAL-3). Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Christiane Fellbaum</author>
<author>Scott Cotton</author>
<author>Lauren Delfs</author>
<author>Hoa Trang Dang</author>
</authors>
<title>English tasks: All-words and verb lexical sample.</title>
<date>2001</date>
<booktitle>Proceedings of Senseval-2: Second International Workshop on Evaluating Word Sense Disambiguation Systems,</booktitle>
<pages>21--24</pages>
<location>Toulouse, France,</location>
<contexts>
<context position="2130" citStr="Palmer, et al., 2001" startWordPosition="307" endWordPosition="310">e context in which it occurs, is a continuing obstacle to high performance natural language processing applications. There are several well-documented factors that make accurate WSD particularly challenging. The first has to do with how senses are defined. The English data used for the SENSEVAL exercises, arguably the most widely used data to train and test WSD systems, are annotated based on very fine-grained distinctions defined in WordNet (Fellbaum, 1998), with human inter-annotator agreement at a little over seventy percent and the top-ranked systems&apos; performances falling between 60%-70% (Palmer, et al., 2001; Mihalcea et al., 2004). The second source of difficulty for accurate WSD comes from how senses are distributed. It is often the case that a polysemous word has a dominant sense or several dominant senses that occur with high frequency and not enough instances can be found for its low frequency senses in the currently publicly available data. There are on-going efforts to address these issues. For example, the sense annotation component of the OntoNotes project (Novy, et al., 2006) attempts to create a large-scale coarsegrained sense-annotated corpus with senses defined based on explicit ling</context>
</contexts>
<marker>Palmer, Fellbaum, Cotton, Delfs, Dang, 2001</marker>
<rawString>Martha Palmer, Christiane Fellbaum, Scott Cotton, Lauren Delfs, and Hoa Trang Dang. 2001. English tasks: All-words and verb lexical sample. Proceedings of Senseval-2: Second International Workshop on Evaluating Word Sense Disambiguation Systems, Toulouse, France, 21-24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Daniel Gildea</author>
<author>Paul Kingsbury</author>
</authors>
<title>The Proposition Bank: An Annotated Corpus of Semantic Roles,</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<pages>71--106</pages>
<contexts>
<context position="10610" citStr="Palmer et al, 2005" startWordPosition="1660" endWordPosition="1663">s, we use words surrounding the target verb and their part-ofspeech tags as collocation features. A further investigation on the different sizes of the context window (3,5,7,9,11) showed that increasing the window size decreased our system&apos;s accuracy. 2.2 Features Based on Automatic Semantic Role Tagging In a recent paper on the WSD of English verbs, Dang and Palmer (2005) showed that semantic role information significantly improves the WSD accuracy of English verbs for both fine-grained and coarse-grained senses. However, this result assumes the human annotation of the Penn English Propbank (Palmer et al, 2005). It seems worthwhile to investigate whether the semantic role information produced by a fully automatic Semantic Role tagger can improve the WSD accuracy on verbs, and test the hypothesis that the senses of a verb have a high correlation to the arguments it takes. To that end, we assigned semantic role labels to the arguments of the target verb with a fully automatic semantic role tagger (Xue and Palmer, 2005) trained on the Chinese Propbank (CPB) (Xue and Palmer, 2003), a corpus annotated with semantic role labels that are similiar in style to the Penn English Propbank. In this annotation, c</context>
<context position="23866" citStr="Palmer et al, 2005" startWordPosition="3917" endWordPosition="3920"> these verbs, the majority of them are not difficult to disambiguate, based on work by Dang et al. (2002). Only a small number of these verbs truly need customized features. 4 Related work There is a large body of literature on WSD and here we only discuss a few that are most relevant to our work. Dang and Palmer (2005) also use predicate-argument information as features in their work on English verbs, but their argument labels are not produced by an automatic SRL system. Rather, their semantic role labels are directly extracted from a human annotated 926 corpus, the English Proposition Bank (Palmer et al, 2005), citing the inadequate accuracy of automatic semantic role labeling systems. In contrast, we used a fully antomated SRL system trained on the Chinese Propbank. Nevertheless, their results show, as ours do, that the use of semantic role labels as features improves the WSD accuracy of verbs. There are relatively few attempts to use linguistically motivated features for Chinese word sense disambiguation. Niu et al (2004) applied a Naive Bayesian model to Chinese WSD and experimented with different window sizes for extracting local and topical features and different types of local features (e.g.,</context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>Martha Palmer, Daniel Gildea, and Paul Kingsbury. 2005. The Proposition Bank: An Annotated Corpus of Semantic Roles, Computational Linguistics, 31(1): 71106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
</authors>
<title>Christiane Fellbaum and Hoa Trang Dang. (to appear,</title>
<date>2006</date>
<marker>Palmer, 2006</marker>
<rawString>Martha Palmer, Christiane Fellbaum and Hoa Trang Dang. (to appear, 2006). Making fine-grained and coarse-grained sense distinctions, both manually and automatically. Natural Language Engineering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qin Lu</author>
<author>Yin Li</author>
</authors>
<title>An automatic Chinese Collocation Extraction Algorithm Based On Lexical Statistics.</title>
<date>2003</date>
<booktitle>In Proceedings of the NLPKE Workshop.</booktitle>
<location>Beijing, China.</location>
<marker>Lu, Li, 2003</marker>
<rawString>Ruifeng Xu , Qin Lu, and Yin Li. 2003. An automatic Chinese Collocation Extraction Algorithm Based On Lexical Statistics. In Proceedings of the NLPKE Workshop. Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Fei Xia</author>
<author>Fu-Dong Chiou</author>
<author>Martha Palmer</author>
</authors>
<title>The Penn Chinese Treebank: Phrase Structure Annotation of a Large Corpus. Natural Language Engineering,</title>
<date>2005</date>
<pages>11--2</pages>
<contexts>
<context position="13354" citStr="Xue et al, 2005" startWordPosition="2115" endWordPosition="2118">ude: (1) the head word of the core arguments (ARG1-水井 and ARG0-乡) and the adjunct (ARGM|MNR-经过); (2) the HowNet semantic category for the head word (ARG1-设施, ARG0- 地方, ARGM|MNR-经受); (3) the semantic role label of the adjunct (ARGM|MNR); and (4) the top level semantic category from the taxonomy of Chinese nouns for the head word of the NP arguments (ARG1_location and ARG0_location). 3 Experimental Results The data we used for our experiments are developed as part of the OntoNotes project (Hovy et al., 2006) and they come from a variety of sources. Part of the data is from the Chinese Treebank (Xue et al, 2005), which has a combination of Xinhua news and Sinorama News Magazine. Since some verbs have an insufficient number of instances for any meaningful experiments, we also annotated portions of the People&apos;s Daily corpus, developed by Peking University. We chose not to use the Chinese WSD dataset used in Senseval 3 1 because we are mainly interested in investigating how the features used in WSD are related to the criteria used to define the senses of Chinese verbs. The Chinese Senseval dataset includes both nouns and verbs. In addition, the criteria used to define their senses are not made explicit </context>
</contexts>
<marker>Xue, Xia, Chiou, Palmer, 2005</marker>
<rawString>Nianwen Xue, Fei Xia, Fu-Dong Chiou and Martha Palmer. 2005. The Penn Chinese Treebank: Phrase Structure Annotation of a Large Corpus. Natural Language Engineering, 11(2):207-238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Martha Palmer</author>
</authors>
<title>Annotating Propositions in the Penn Chinese Treebank,</title>
<date>2003</date>
<booktitle>In Proceedings of the 2nd SIGHAN Workshop on Chinese Language Processing, in conjunction with ACL&apos;03.</booktitle>
<location>Sapporo, Japan.</location>
<contexts>
<context position="11085" citStr="Xue and Palmer, 2003" startWordPosition="1740" endWordPosition="1743">r both fine-grained and coarse-grained senses. However, this result assumes the human annotation of the Penn English Propbank (Palmer et al, 2005). It seems worthwhile to investigate whether the semantic role information produced by a fully automatic Semantic Role tagger can improve the WSD accuracy on verbs, and test the hypothesis that the senses of a verb have a high correlation to the arguments it takes. To that end, we assigned semantic role labels to the arguments of the target verb with a fully automatic semantic role tagger (Xue and Palmer, 2005) trained on the Chinese Propbank (CPB) (Xue and Palmer, 2003), a corpus annotated with semantic role labels that are similiar in style to the Penn English Propbank. In this annotation, core arguments such as agent or theme are labeled with numbered arguments such as Arg0 and Argl, up to Argy while adjunct-like elements are assigned functional tags such as TMP (for temporal), MNR, prefixed by ArgM. The Semantic Role tagger takes as input syntactic parses produced by the parser described above as input and produces a list of arguments for each of the sense-tagged target verbs and assigns argument labels to them. Features are extracted from both the core a</context>
</contexts>
<marker>Xue, Palmer, 2003</marker>
<rawString>Nianwen Xue and Martha Palmer. 2003. Annotating Propositions in the Penn Chinese Treebank, In Proceedings of the 2nd SIGHAN Workshop on Chinese Language Processing, in conjunction with ACL&apos;03. Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Martha Palmer</author>
</authors>
<title>Automatic Semantic Role Labeling for Chinese Verbs.</title>
<date>2005</date>
<booktitle>In Proceedings of the 19th International Joint Conference on Artificial Intelligence.</booktitle>
<location>Edinburgh, Scotland.</location>
<contexts>
<context position="11024" citStr="Xue and Palmer, 2005" startWordPosition="1730" endWordPosition="1733">n significantly improves the WSD accuracy of English verbs for both fine-grained and coarse-grained senses. However, this result assumes the human annotation of the Penn English Propbank (Palmer et al, 2005). It seems worthwhile to investigate whether the semantic role information produced by a fully automatic Semantic Role tagger can improve the WSD accuracy on verbs, and test the hypothesis that the senses of a verb have a high correlation to the arguments it takes. To that end, we assigned semantic role labels to the arguments of the target verb with a fully automatic semantic role tagger (Xue and Palmer, 2005) trained on the Chinese Propbank (CPB) (Xue and Palmer, 2003), a corpus annotated with semantic role labels that are similiar in style to the Penn English Propbank. In this annotation, core arguments such as agent or theme are labeled with numbered arguments such as Arg0 and Argl, up to Argy while adjunct-like elements are assigned functional tags such as TMP (for temporal), MNR, prefixed by ArgM. The Semantic Role tagger takes as input syntactic parses produced by the parser described above as input and produces a list of arguments for each of the sense-tagged target verbs and assigns argumen</context>
</contexts>
<marker>Xue, Palmer, 2005</marker>
<rawString>Nianwen Xue and Martha Palmer. 2005. Automatic Semantic Role Labeling for Chinese Verbs. In Proceedings of the 19th International Joint Conference on Artificial Intelligence. Edinburgh, Scotland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
<author>Radu Florian</author>
</authors>
<title>Evaluating sense disambiguation across diverse parameter spaces.</title>
<date>2002</date>
<journal>Journal of Natural Language Engineering,</journal>
<volume>8</volume>
<issue>4</issue>
<pages>293--310</pages>
<contexts>
<context position="3413" citStr="Yarowsky and Florian (2002)" startWordPosition="506" endWordPosition="509">resources like this are available to the general NLP community. There have already been experiments that show such coarse-grained senses lead to substantial improvement in system performance (Palmer et al, 2006). The goal of our experiments is to explore the implications of a related and yet separate problem, specifically the extent to which the linguistic criteria used to define senses are related to what features need to be used in machine-learning systems. There are already published results that show WSD for different syntactic categories may need different types of features. For example, Yarowsky and Florian (2002), in their experiments on SENSEVAL2 English data, showed that sense distinctions of verbs relied more on linguistically motivated features than other parts-of-speech. In this paper, 921 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 921–928, Sydney, July 2006. c�2006 Association for Computational Linguistics we will go one step further and show that even for words of the same syntactic category senses are often defined along different dimensions based on different criteria. One direct implication of this observation for supervised machinelearning approaches to WSD is</context>
</contexts>
<marker>Yarowsky, Florian, 2002</marker>
<rawString>David Yarowsky and Radu Florian. 2002. Evaluating sense disambiguation across diverse parameter spaces. Journal of Natural Language Engineering, 8(4): 293310.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>