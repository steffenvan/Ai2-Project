<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.006776">
<title confidence="0.841522">
CL Research’s Knowledge Management System
</title>
<author confidence="0.711609">
Kenneth C. Litkowski
</author>
<note confidence="0.457670666666667">
CL Research
9208 Gue Road
Damascus, MD 20872
</note>
<email confidence="0.9520315">
ken@clres.com
http://www.clres.com
</email>
<sectionHeader confidence="0.991677" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999572578947369">
CL Research began experimenting with
massive XML tagging of texts to answer
questions in TREC 2002. In DUC 2003, the
experiments were extended into text
summarization. Based on these experiments,
The Knowledge Management System (KMS)
was developed to combine these two
capabilities and to serve as a unified basis for
other types of document exploration. KMS has
been extended to include web question
answering, both general and topic-based
summarization, information extraction, and
document exploration. The document
exploration functionality includes identification
of semantically similar concepts and dynamic
ontology creation. As development of KMS has
continued, user modeling has become a key
research issue: how will different users want to
use the information they identify.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999973152173913">
In participating the TREC question-answering track,
CL Research began by parsing full documents and
developing databases consisting of semantic relation
triples (Litkowski, 1999). The database approach
proved to be quite confining, with time requirements
expanding exponentially trying to maintain larger sets
of documents and increasingly complex procedures to
answer questions. A suggestion was made to tag text
with the type of questions they could answer (e.g.,
tagging time phrases as answering when questions
and person names as answering who questions). This
led to the general approach of analyzing parse trees to
construct an XML representation of texts (i.e.,
attaching metadata to the text) and examining these
representations with XPath expressions to answer
questions.
Litkowski (2003a) demonstrated the viability of
this approach by showing that XPath expressions
could be used to answer questions at a level above the
highest performing team. Many issues and problems
were identified: (1) The necessary level of analysis to
meet the needs of particular applications; (2) tagging
alternatives; and (3) the viability of the using the
XML representation for text summarization,
information extraction, novelty detection, and text
mining. Subsequent efforts showed that XML
representations could be effectively used in
summarization (Litkowski, 2003b) and novelty
detection (Litkowski, 2005).
Initially, CL Research developed an interface for
examining question-answering performance. This
interface has since evolved into a Knowledge
Management System (KMS) that provides a single
platform for examining English documents (e.g.,
newswire and research papers) and for generating
different types of output (e.g., answers to questions,
summaries, and document ontologies), also in XML
representations. In this demonstration, CL Research
will describe many parts of KMS, particularly the
approaches used for analyzing texts.1 The
demonstration will particularly focus on the value of
XML in providing a flexible and extensible
mechanism for implementing the various NLP
functionalities. In addition, the demonstration will
identify the emerging issue of user modeling to
determine exactly how knowledge will be used, since
</bodyText>
<footnote confidence="0.993038666666667">
1Screen shots of KMS in performing the
functions as described below are can be seen at
http://www.clres.com/kmsscreen.html.
</footnote>
<page confidence="0.987755">
13
</page>
<note confidence="0.363662">
Proceedings of the ACL Interactive Poster and Demonstration Sessions,
pages 13–16, Ann Arbor, June 2005. c�2005 Association for Computational Linguistics
</note>
<bodyText confidence="0.9961858">
the primary purpose of KMS is to serve as a tool that
will enable users (such as scientists and intelligence
analysts) to accumulate and manage knowledge
(including facts, such as described in Fiszman et al.,
2003) about topics of interest.2
</bodyText>
<sectionHeader confidence="0.521919" genericHeader="introduction">
2 Parsing and Creation of XML Tagging
</sectionHeader>
<bodyText confidence="0.985417035714286">
KMS and each of its application areas is based on
parsing text and then transforming parse trees into an
XML representation. CL Research uses the Proximity
Parser, developed by an inventor of top-down syntax-
directed parsing (Irons, 1961).3 The parser output
consists of bracketed parse trees, with leaf nodes
describing the part of speech and lexical entry for
each sentence word. Annotations, such as number and
tense information, may be included at any node.
(Litkowski (2002) and references therein provide
more details on the parser.)
After each sentence is parsed, its parse tree is
traversed in a depth-first recursive function. During
this traversal, each non-terminal and terminal node is
analyzed to identify discourse segments (sentences
and clauses), noun phrases, verbs, adjectives, and
prepositional phrases. These items are maintained in
lists; the growing lists constitute a document’s
discourse structure and are used, e.g., in resolving
anaphora and establishing coreferents (implementing
techniques inspired by Marcu (2000) and Tetreault
(2001)). As these items are identified, they are
subjected to a considerable amount of analysis to
characterize them syntactically and semantically. The
analysis includes word-sense disambiguation of
nouns, verbs (including subcategorization
identification), and adjectives and semantic analysis
of prepositions to establish their semantic roles (such
as described in Gildea &amp; Jurafsky, 2002).
When all sentences of a document have been
2The overall design of KMS is based on
requirements enunciated by intelligence analysts and
question-answering researchers in a workshop on
Scenario-Based Question Answering sponsored by the
Advanced Research and Development Agency in 2003.
3An online demonstration of the parser is
available at http://www.zzcad.com/parse.htm. A demo
version of the parser is available for download at
http://www.clres.com/demos.html.
parsed and components identified and analyzed, the
various lists are used to generate the XML
representation. Most of the properties of the
components are used as the basis for establishing
XML attributes and values in the final representation.
(Litkowski 2003a provides further details on this
process.) This representation then becomes the basis
for question answering, summarization, information
extraction, and document exploration.
The utility of the XML representation does not
stem from an ability to use XML manipulation
technologies, such as XSLT and XQuery. In fact,
these technologies seem to involve too much
overhead. Instead, the utility arises within a
Windows-based C++ development environment with
a set of XML functions that facilitate working with
node sets from a document’s XML tree.
</bodyText>
<sectionHeader confidence="0.99061" genericHeader="method">
3 Question Answering
</sectionHeader>
<bodyText confidence="0.99993456">
As indicated above, the initial implementation of the
question-answering component of KMS was designed
primarily to determine if suitable XPath expressions
could be created for answering questions. CL
Research’s XML Analyzer was developed for this
purpose.4 XML Analyzer is constructed in a C++
Windows development environment to which a
capability for examining XML nodes has been added.
With this capability, a document can be loaded with
one instruction and an XPath expression can be
applied against this document in one more instruction
to obtain a set of nodes which can be examined in
more detail. Crucially, this enables low-level control
over subsequent analysis steps (e.g., examining the
text of a node with Perl regular expressions).
XML Analyzer first loads an XML file (which
can include many documents, such as the “top 50”
used in TREC). The user then presents an XPath
expression and discourse components (typically, noun
phrases) satisfying that expression are returned. XML
Analyzer includes the document number, the sentence
number, and the full sentence for each noun phrase.
Several other features were added to XML Analyzer
to examine characteristics of the documents and
sentences (particularly to identify why an answer
</bodyText>
<footnote confidence="0.9820085">
4A demo version of XML Analyzer is available
for download at http://www.clres.com/demos.html.
</footnote>
<page confidence="0.998561">
14
</page>
<bodyText confidence="0.999962558139535">
wasn’t retrieved by an XPath expression).
XML Analyzer does not include the automatic
creation of an XPath expression. KMS was created
for TREC 2003 as the initial implementation of a
complete question-answering system. In KMS, the
question itself is parsed and transformed into an
XML representation (using the same underlying
functionality for processing documents) and then used
to construct an XPath expression.
An XPath expression consists of two parts. The
first part is a “passage retrieval” component, designed
to retrieve sentences likely to contain the answer. This
basic XPath is then extended for each question type
with additional specifications, e.g., to ask for noun
phrases that have time, location, or other semantic
attributes. Experiments have shown that there is a
tradeoff involved in these specifications. If they are
very exacting, few possible answers are returned.
Backoff strategies are used to return a larger set of
potential answers and to analyze the context of these
potential answers in more detail. The development of
routines for automatic creation of XPath expressions
is an ongoing process, but has begun to yield more
consistent results (Litkowski, 2005).
In preparation for TREC 2004, KMS was further
extended to incorporate a web-based component.
With a check box to indicate whether the web or a
document repository should be used, additional
functionality was used to pose questions to Google. In
web mode, an XML representation of a question is
still developed, but then it is analyzed to present an
optimal query to Google, typically, a pattern that will
provide an answer. This involves the use of an
integrated dictionary, particularly for creating
appropriate inflected forms in the search query. KMS
only uses the first page of Google results, without
going into the source documents, extracting sentences
from the Google results and using these as the
documents. (A user can create a new “document
repository” consisting of the documents from which
answers have been obtained.) Many additional
possibilities have emerged from initial explorations in
using web-based question answering.
</bodyText>
<sectionHeader confidence="0.997581" genericHeader="method">
4 Summarization
</sectionHeader>
<bodyText confidence="0.99995734883721">
Litkowski (2003a) indicated the possibility that the
XML representation of documents could be used for
summarization. To investigate this possibility, XML
Analyzer was extended to include summarization
capabilities for both general and topic-based
summaries, including headline and keyword
generation. Summarization techniques crucially take
into account anaphora, coreferent, and definite noun
phrase resolutions. As intimated in the analysis of the
parse output, the XML representation for a referring
expression is tagged with antecedent information,
including both an identifying number and the full text
of the antecedent. As a result, in examining a
sentence, it is possible to consider the import of all its
antecedents, instead of simply the surface form.
At the present time, only extractive
summarization is performed in KMS. The basis for
identifying important sentences is simply a frequency
count of its words, but using antecedents instead of
referring expressions. Stopwords and some other
items are eliminated from this count.
In KMS, the user has the option for creating
several kinds of summaries. The user specifies the
type of summary (general, topic-based, headline, or
keyword), which documents to summarize (one or
many), and the length. Topic-based summaries
require the user to enter search terms. The search
terms can be as simple as a person’s name or a few
keywords or can be several sentences in length.
Topic-based summaries use the search terms to give
extra weight to sentences containing the search terms.
Sentences are also evaluated for their novelty, with
redundancy and overlap measures based on
examining their noun phrases. KMS summarization
procedures are described in more detail in Litkowski
(2003b); novelty techniques are described in
Litkowski (2005).
In KMS, summaries are saved in XML files as
sets of sentences, each characterized by its source and
sentence number. Each summary uses XML
attributes containing the user’s specifications and the
documents included in the search. generated quickly
but in whole form.
</bodyText>
<sectionHeader confidence="0.981887" genericHeader="method">
5 Document Exploration
</sectionHeader>
<bodyText confidence="0.9999545">
KMS includes two major components for
exploring the contents of a document. The first is
based on the semantic types attached to nouns and
verbs. The second is based on analyzing noun phrases
to construct a document hierarchy or ontology.
As noted above, each noun phrase and each verb
</bodyText>
<page confidence="0.994909">
15
</page>
<bodyText confidence="0.999972458333333">
is tagged with its semantic class, based on WordNet.
A user can explore one or more documents in three
stages. First, a semantic category is specified.
Second, the user pushes a button to obtain all the
instances in the documents in that category. The
phraseology in the documents is examined so that
similar words (e.g., plurals and singulars and/or
synonyms) are grouped together and then presented in
a drop-down box by frequency. Finally, the user can
select any term set and obtain all the sentences in the
documents containing any of the terms.
KMS provides the capability for viewing a
“dynamic” noun ontology of a document set. All noun
phrases are analyzed into groups in a tree structure
that portrays the ontology that is instantiated by these
phrases. Noun phrases are reduced to their base
forms (in cases of plurals) and grouped together first
on the basis of their heads. Synonym sets are then
generated and a further grouping is made. Algorithms
from Navigli &amp; Velardi (2004) are being modified
and implemented in KMS. The user can then select a
node in the ontology hierarchy and create a summary
based on sentences containing any of its terms or
children.
</bodyText>
<sectionHeader confidence="0.983676" genericHeader="evaluation">
6 Dictionaries and Thesauruses in KMS
</sectionHeader>
<bodyText confidence="0.999960230769231">
KMS makes extensive use of integrated dictionaries
and thesauruses, in addition to a comprehensive
dictionary used in parsing (which makes use of about
30 subcategorization patterns for verbs). This
dictionary is supplemented with other dictionaries that
are first used in dynamically extending the parser’s
dictionary for parsing, but then more extensively in
semantic analysis. WordNet is used for many
functions, as is a Roget-style thesaurus. KMS also
uses a full machine-readable dictionary, dictionaries
and semantic networks from the Unified Medical
Language System, and a specially constructed
dictionary of prepositions for semantic role analysis.
</bodyText>
<sectionHeader confidence="0.998594" genericHeader="conclusions">
7 Summary
</sectionHeader>
<bodyText confidence="0.9999755">
The preceding sections have focused on particular
prominent functionalities (question-answering,
summarization, and document exploration) in KMS.
Each of these components is part of the whole, in
which the main objective is to allow a user to explore
documents in a variety of ways to identify salient
portions of one or more documents. KMS is designed
to identify relevant documents, to build a repository
of these documents, to explore the documents, and to
extract relevant pieces of information.
</bodyText>
<sectionHeader confidence="0.990336" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999944613636364">
Fiszman, M., Rindflesch, T., &amp; Kilicoglu, H. (2003).
Integrating a Hypernymic Proposition Interpreter
into a Semantic Processor for Biomedical Texts.
Proceedings of the AMIA Annual Symposium on
Medical Informatics.
Gildea, Daniel, and Daniel Jurafsky. (2002) Automatic
Labeling of Semantic Roles. Computational
Linguistics, 28 (3), 245-288.
Irons, E. T. (1961) A Syntax Directed Compiler for
ALGOL-60. Communications of the ACM, 4, 51-
55.
Litkowski, K. C. (1999). Question Answering Using
Semantic Relation Triples. In E. M. Voorhees &amp;
D. K. Harman (eds.), The Eighth Text Retrieval
Conference (TREC-8). NIST Special Publication
500-246. Gaithersburg, MD., 349-56.
Litkowski, K. C. (2002). CL Research Experiments in
TREC-10 Question-Answering. In E. M. Voorhees
&amp; D. K. Harman (eds.), The Tenth Text Retrieval
Conference (TREC 2001). NIST Special
Publication 500-250. Gaithersburg, MD., 122-131.
Litkowski, K. C. (2003a). Question Answering Using
XML-Tagged Documents. In E. M. Voorhees &amp; L.
P. Buckland (eds.), The Eleventh Text Retrieval
Conference (TREC 2002). NIST Special
Publication 500-251. Gaithersburg, MD., 122-131.
Litkowski, K. C. (2003b). Text Summarization Using
XML-Tagged Documents. Available:
http://nlpir.nist.gov/projects/duc/pubs.html.
Litkowski, K. C. (2005). Evolving XML and Dictionary
Strategies for Question Answering and Novelty
Tasks. Available:
http://trec.nist.gov/pubs/trec13/t13proceedings.ht
ml.
Marcu, Daniel. (2000) The Rhetorical Parsing of
Unrestricted Texts: A Surface-based Approach.
Computational Linguistics, 26 (3), 395-448.
Navigli, R. &amp; P. Velardi (2004) Learning Domain
Ontologies from Document Warehouses and
Dedicated Web Sites. Computational Linguistics
30, 151-180.
Tetreault, Joel. (2001) A Corpus-Based Evaluation of
Centering and Pronoun Resolution. Computational
Linguistics, 27 (4), 507-520.
</reference>
<page confidence="0.9987">
16
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.908372">
<title confidence="0.999761">CL Research’s Knowledge Management System</title>
<author confidence="0.999958">Kenneth C Litkowski</author>
<affiliation confidence="0.999034">CL Research</affiliation>
<address confidence="0.9992455">9208 Gue Road Damascus, MD 20872</address>
<email confidence="0.999799">ken@clres.com</email>
<web confidence="0.916363">http://www.clres.com</web>
<abstract confidence="0.9996827">CL Research began experimenting with massive XML tagging of texts to answer questions in TREC 2002. In DUC 2003, the experiments were extended into text summarization. Based on these experiments, The Knowledge Management System (KMS) was developed to combine these two capabilities and to serve as a unified basis for other types of document exploration. KMS has been extended to include web question answering, both general and topic-based summarization, information extraction, and document exploration. The document exploration functionality includes identification of semantically similar concepts and dynamic ontology creation. As development of KMS has continued, user modeling has become a key research issue: how will different users want to use the information they identify.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Fiszman</author>
<author>T Rindflesch</author>
<author>H Kilicoglu</author>
</authors>
<title>Integrating a Hypernymic Proposition Interpreter into a Semantic Processor for Biomedical Texts.</title>
<date>2003</date>
<booktitle>Proceedings of the AMIA Annual Symposium on Medical Informatics.</booktitle>
<contexts>
<context position="3678" citStr="Fiszman et al., 2003" startWordPosition="521" endWordPosition="524">n, the demonstration will identify the emerging issue of user modeling to determine exactly how knowledge will be used, since 1Screen shots of KMS in performing the functions as described below are can be seen at http://www.clres.com/kmsscreen.html. 13 Proceedings of the ACL Interactive Poster and Demonstration Sessions, pages 13–16, Ann Arbor, June 2005. c�2005 Association for Computational Linguistics the primary purpose of KMS is to serve as a tool that will enable users (such as scientists and intelligence analysts) to accumulate and manage knowledge (including facts, such as described in Fiszman et al., 2003) about topics of interest.2 2 Parsing and Creation of XML Tagging KMS and each of its application areas is based on parsing text and then transforming parse trees into an XML representation. CL Research uses the Proximity Parser, developed by an inventor of top-down syntaxdirected parsing (Irons, 1961).3 The parser output consists of bracketed parse trees, with leaf nodes describing the part of speech and lexical entry for each sentence word. Annotations, such as number and tense information, may be included at any node. (Litkowski (2002) and references therein provide more details on the pars</context>
</contexts>
<marker>Fiszman, Rindflesch, Kilicoglu, 2003</marker>
<rawString>Fiszman, M., Rindflesch, T., &amp; Kilicoglu, H. (2003). Integrating a Hypernymic Proposition Interpreter into a Semantic Processor for Biomedical Texts. Proceedings of the AMIA Annual Symposium on Medical Informatics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic Labeling of Semantic Roles.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>3</issue>
<pages>245--288</pages>
<contexts>
<context position="5192" citStr="Gildea &amp; Jurafsky, 2002" startWordPosition="740" endWordPosition="743">ese items are maintained in lists; the growing lists constitute a document’s discourse structure and are used, e.g., in resolving anaphora and establishing coreferents (implementing techniques inspired by Marcu (2000) and Tetreault (2001)). As these items are identified, they are subjected to a considerable amount of analysis to characterize them syntactically and semantically. The analysis includes word-sense disambiguation of nouns, verbs (including subcategorization identification), and adjectives and semantic analysis of prepositions to establish their semantic roles (such as described in Gildea &amp; Jurafsky, 2002). When all sentences of a document have been 2The overall design of KMS is based on requirements enunciated by intelligence analysts and question-answering researchers in a workshop on Scenario-Based Question Answering sponsored by the Advanced Research and Development Agency in 2003. 3An online demonstration of the parser is available at http://www.zzcad.com/parse.htm. A demo version of the parser is available for download at http://www.clres.com/demos.html. parsed and components identified and analyzed, the various lists are used to generate the XML representation. Most of the properties of </context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>Gildea, Daniel, and Daniel Jurafsky. (2002) Automatic Labeling of Semantic Roles. Computational Linguistics, 28 (3), 245-288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E T Irons</author>
</authors>
<title>A Syntax Directed Compiler for ALGOL-60.</title>
<date>1961</date>
<journal>Communications of the ACM,</journal>
<volume>4</volume>
<pages>51--55</pages>
<contexts>
<context position="3981" citStr="Irons, 1961" startWordPosition="572" endWordPosition="573"> Sessions, pages 13–16, Ann Arbor, June 2005. c�2005 Association for Computational Linguistics the primary purpose of KMS is to serve as a tool that will enable users (such as scientists and intelligence analysts) to accumulate and manage knowledge (including facts, such as described in Fiszman et al., 2003) about topics of interest.2 2 Parsing and Creation of XML Tagging KMS and each of its application areas is based on parsing text and then transforming parse trees into an XML representation. CL Research uses the Proximity Parser, developed by an inventor of top-down syntaxdirected parsing (Irons, 1961).3 The parser output consists of bracketed parse trees, with leaf nodes describing the part of speech and lexical entry for each sentence word. Annotations, such as number and tense information, may be included at any node. (Litkowski (2002) and references therein provide more details on the parser.) After each sentence is parsed, its parse tree is traversed in a depth-first recursive function. During this traversal, each non-terminal and terminal node is analyzed to identify discourse segments (sentences and clauses), noun phrases, verbs, adjectives, and prepositional phrases. These items are</context>
</contexts>
<marker>Irons, 1961</marker>
<rawString>Irons, E. T. (1961) A Syntax Directed Compiler for ALGOL-60. Communications of the ACM, 4, 51-55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K C Litkowski</author>
</authors>
<title>Question Answering Using Semantic Relation Triples.</title>
<date>1999</date>
<booktitle>The Eighth Text Retrieval Conference (TREC-8). NIST Special Publication 500-246.</booktitle>
<pages>349--56</pages>
<editor>In E. M. Voorhees &amp; D. K. Harman (eds.),</editor>
<location>Gaithersburg, MD.,</location>
<contexts>
<context position="1130" citStr="Litkowski, 1999" startWordPosition="155" endWordPosition="156"> been extended to include web question answering, both general and topic-based summarization, information extraction, and document exploration. The document exploration functionality includes identification of semantically similar concepts and dynamic ontology creation. As development of KMS has continued, user modeling has become a key research issue: how will different users want to use the information they identify. 1 Introduction In participating the TREC question-answering track, CL Research began by parsing full documents and developing databases consisting of semantic relation triples (Litkowski, 1999). The database approach proved to be quite confining, with time requirements expanding exponentially trying to maintain larger sets of documents and increasingly complex procedures to answer questions. A suggestion was made to tag text with the type of questions they could answer (e.g., tagging time phrases as answering when questions and person names as answering who questions). This led to the general approach of analyzing parse trees to construct an XML representation of texts (i.e., attaching metadata to the text) and examining these representations with XPath expressions to answer questio</context>
</contexts>
<marker>Litkowski, 1999</marker>
<rawString>Litkowski, K. C. (1999). Question Answering Using Semantic Relation Triples. In E. M. Voorhees &amp; D. K. Harman (eds.), The Eighth Text Retrieval Conference (TREC-8). NIST Special Publication 500-246. Gaithersburg, MD., 349-56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K C Litkowski</author>
</authors>
<title>CL Research Experiments in TREC-10 Question-Answering.</title>
<date>2002</date>
<booktitle>The Tenth Text Retrieval Conference (TREC 2001). NIST Special Publication 500-250.</booktitle>
<pages>122--131</pages>
<editor>In E. M. Voorhees &amp; D. K. Harman (eds.),</editor>
<location>Gaithersburg, MD.,</location>
<contexts>
<context position="4222" citStr="Litkowski (2002)" startWordPosition="610" endWordPosition="611">e knowledge (including facts, such as described in Fiszman et al., 2003) about topics of interest.2 2 Parsing and Creation of XML Tagging KMS and each of its application areas is based on parsing text and then transforming parse trees into an XML representation. CL Research uses the Proximity Parser, developed by an inventor of top-down syntaxdirected parsing (Irons, 1961).3 The parser output consists of bracketed parse trees, with leaf nodes describing the part of speech and lexical entry for each sentence word. Annotations, such as number and tense information, may be included at any node. (Litkowski (2002) and references therein provide more details on the parser.) After each sentence is parsed, its parse tree is traversed in a depth-first recursive function. During this traversal, each non-terminal and terminal node is analyzed to identify discourse segments (sentences and clauses), noun phrases, verbs, adjectives, and prepositional phrases. These items are maintained in lists; the growing lists constitute a document’s discourse structure and are used, e.g., in resolving anaphora and establishing coreferents (implementing techniques inspired by Marcu (2000) and Tetreault (2001)). As these item</context>
</contexts>
<marker>Litkowski, 2002</marker>
<rawString>Litkowski, K. C. (2002). CL Research Experiments in TREC-10 Question-Answering. In E. M. Voorhees &amp; D. K. Harman (eds.), The Tenth Text Retrieval Conference (TREC 2001). NIST Special Publication 500-250. Gaithersburg, MD., 122-131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K C Litkowski</author>
</authors>
<title>Question Answering Using XML-Tagged Documents.</title>
<date>2003</date>
<booktitle>The Eleventh Text Retrieval Conference (TREC 2002). NIST Special Publication 500-251.</booktitle>
<pages>122--131</pages>
<editor>In E. M. Voorhees &amp; L. P. Buckland (eds.),</editor>
<location>Gaithersburg, MD.,</location>
<contexts>
<context position="1749" citStr="Litkowski (2003" startWordPosition="247" endWordPosition="248">e database approach proved to be quite confining, with time requirements expanding exponentially trying to maintain larger sets of documents and increasingly complex procedures to answer questions. A suggestion was made to tag text with the type of questions they could answer (e.g., tagging time phrases as answering when questions and person names as answering who questions). This led to the general approach of analyzing parse trees to construct an XML representation of texts (i.e., attaching metadata to the text) and examining these representations with XPath expressions to answer questions. Litkowski (2003a) demonstrated the viability of this approach by showing that XPath expressions could be used to answer questions at a level above the highest performing team. Many issues and problems were identified: (1) The necessary level of analysis to meet the needs of particular applications; (2) tagging alternatives; and (3) the viability of the using the XML representation for text summarization, information extraction, novelty detection, and text mining. Subsequent efforts showed that XML representations could be effectively used in summarization (Litkowski, 2003b) and novelty detection (Litkowski, </context>
<context position="5916" citStr="Litkowski 2003" startWordPosition="845" endWordPosition="846"> intelligence analysts and question-answering researchers in a workshop on Scenario-Based Question Answering sponsored by the Advanced Research and Development Agency in 2003. 3An online demonstration of the parser is available at http://www.zzcad.com/parse.htm. A demo version of the parser is available for download at http://www.clres.com/demos.html. parsed and components identified and analyzed, the various lists are used to generate the XML representation. Most of the properties of the components are used as the basis for establishing XML attributes and values in the final representation. (Litkowski 2003a provides further details on this process.) This representation then becomes the basis for question answering, summarization, information extraction, and document exploration. The utility of the XML representation does not stem from an ability to use XML manipulation technologies, such as XSLT and XQuery. In fact, these technologies seem to involve too much overhead. Instead, the utility arises within a Windows-based C++ development environment with a set of XML functions that facilitate working with node sets from a document’s XML tree. 3 Question Answering As indicated above, the initial im</context>
<context position="9989" citStr="Litkowski (2003" startWordPosition="1467" endWordPosition="1468">query to Google, typically, a pattern that will provide an answer. This involves the use of an integrated dictionary, particularly for creating appropriate inflected forms in the search query. KMS only uses the first page of Google results, without going into the source documents, extracting sentences from the Google results and using these as the documents. (A user can create a new “document repository” consisting of the documents from which answers have been obtained.) Many additional possibilities have emerged from initial explorations in using web-based question answering. 4 Summarization Litkowski (2003a) indicated the possibility that the XML representation of documents could be used for summarization. To investigate this possibility, XML Analyzer was extended to include summarization capabilities for both general and topic-based summaries, including headline and keyword generation. Summarization techniques crucially take into account anaphora, coreferent, and definite noun phrase resolutions. As intimated in the analysis of the parse output, the XML representation for a referring expression is tagged with antecedent information, including both an identifying number and the full text of the</context>
<context position="11713" citStr="Litkowski (2003" startWordPosition="1727" endWordPosition="1728"> specifies the type of summary (general, topic-based, headline, or keyword), which documents to summarize (one or many), and the length. Topic-based summaries require the user to enter search terms. The search terms can be as simple as a person’s name or a few keywords or can be several sentences in length. Topic-based summaries use the search terms to give extra weight to sentences containing the search terms. Sentences are also evaluated for their novelty, with redundancy and overlap measures based on examining their noun phrases. KMS summarization procedures are described in more detail in Litkowski (2003b); novelty techniques are described in Litkowski (2005). In KMS, summaries are saved in XML files as sets of sentences, each characterized by its source and sentence number. Each summary uses XML attributes containing the user’s specifications and the documents included in the search. generated quickly but in whole form. 5 Document Exploration KMS includes two major components for exploring the contents of a document. The first is based on the semantic types attached to nouns and verbs. The second is based on analyzing noun phrases to construct a document hierarchy or ontology. As noted above</context>
</contexts>
<marker>Litkowski, 2003</marker>
<rawString>Litkowski, K. C. (2003a). Question Answering Using XML-Tagged Documents. In E. M. Voorhees &amp; L. P. Buckland (eds.), The Eleventh Text Retrieval Conference (TREC 2002). NIST Special Publication 500-251. Gaithersburg, MD., 122-131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K C Litkowski</author>
</authors>
<title>Text Summarization Using XML-Tagged Documents.</title>
<date>2003</date>
<note>Available: http://nlpir.nist.gov/projects/duc/pubs.html.</note>
<contexts>
<context position="1749" citStr="Litkowski (2003" startWordPosition="247" endWordPosition="248">e database approach proved to be quite confining, with time requirements expanding exponentially trying to maintain larger sets of documents and increasingly complex procedures to answer questions. A suggestion was made to tag text with the type of questions they could answer (e.g., tagging time phrases as answering when questions and person names as answering who questions). This led to the general approach of analyzing parse trees to construct an XML representation of texts (i.e., attaching metadata to the text) and examining these representations with XPath expressions to answer questions. Litkowski (2003a) demonstrated the viability of this approach by showing that XPath expressions could be used to answer questions at a level above the highest performing team. Many issues and problems were identified: (1) The necessary level of analysis to meet the needs of particular applications; (2) tagging alternatives; and (3) the viability of the using the XML representation for text summarization, information extraction, novelty detection, and text mining. Subsequent efforts showed that XML representations could be effectively used in summarization (Litkowski, 2003b) and novelty detection (Litkowski, </context>
<context position="5916" citStr="Litkowski 2003" startWordPosition="845" endWordPosition="846"> intelligence analysts and question-answering researchers in a workshop on Scenario-Based Question Answering sponsored by the Advanced Research and Development Agency in 2003. 3An online demonstration of the parser is available at http://www.zzcad.com/parse.htm. A demo version of the parser is available for download at http://www.clres.com/demos.html. parsed and components identified and analyzed, the various lists are used to generate the XML representation. Most of the properties of the components are used as the basis for establishing XML attributes and values in the final representation. (Litkowski 2003a provides further details on this process.) This representation then becomes the basis for question answering, summarization, information extraction, and document exploration. The utility of the XML representation does not stem from an ability to use XML manipulation technologies, such as XSLT and XQuery. In fact, these technologies seem to involve too much overhead. Instead, the utility arises within a Windows-based C++ development environment with a set of XML functions that facilitate working with node sets from a document’s XML tree. 3 Question Answering As indicated above, the initial im</context>
<context position="9989" citStr="Litkowski (2003" startWordPosition="1467" endWordPosition="1468">query to Google, typically, a pattern that will provide an answer. This involves the use of an integrated dictionary, particularly for creating appropriate inflected forms in the search query. KMS only uses the first page of Google results, without going into the source documents, extracting sentences from the Google results and using these as the documents. (A user can create a new “document repository” consisting of the documents from which answers have been obtained.) Many additional possibilities have emerged from initial explorations in using web-based question answering. 4 Summarization Litkowski (2003a) indicated the possibility that the XML representation of documents could be used for summarization. To investigate this possibility, XML Analyzer was extended to include summarization capabilities for both general and topic-based summaries, including headline and keyword generation. Summarization techniques crucially take into account anaphora, coreferent, and definite noun phrase resolutions. As intimated in the analysis of the parse output, the XML representation for a referring expression is tagged with antecedent information, including both an identifying number and the full text of the</context>
<context position="11713" citStr="Litkowski (2003" startWordPosition="1727" endWordPosition="1728"> specifies the type of summary (general, topic-based, headline, or keyword), which documents to summarize (one or many), and the length. Topic-based summaries require the user to enter search terms. The search terms can be as simple as a person’s name or a few keywords or can be several sentences in length. Topic-based summaries use the search terms to give extra weight to sentences containing the search terms. Sentences are also evaluated for their novelty, with redundancy and overlap measures based on examining their noun phrases. KMS summarization procedures are described in more detail in Litkowski (2003b); novelty techniques are described in Litkowski (2005). In KMS, summaries are saved in XML files as sets of sentences, each characterized by its source and sentence number. Each summary uses XML attributes containing the user’s specifications and the documents included in the search. generated quickly but in whole form. 5 Document Exploration KMS includes two major components for exploring the contents of a document. The first is based on the semantic types attached to nouns and verbs. The second is based on analyzing noun phrases to construct a document hierarchy or ontology. As noted above</context>
</contexts>
<marker>Litkowski, 2003</marker>
<rawString>Litkowski, K. C. (2003b). Text Summarization Using XML-Tagged Documents. Available: http://nlpir.nist.gov/projects/duc/pubs.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K C Litkowski</author>
</authors>
<title>Evolving XML and Dictionary Strategies for Question Answering and Novelty Tasks. Available: http://trec.nist.gov/pubs/trec13/t13proceedings.ht ml.</title>
<date>2005</date>
<contexts>
<context position="2354" citStr="Litkowski, 2005" startWordPosition="333" endWordPosition="334">owski (2003a) demonstrated the viability of this approach by showing that XPath expressions could be used to answer questions at a level above the highest performing team. Many issues and problems were identified: (1) The necessary level of analysis to meet the needs of particular applications; (2) tagging alternatives; and (3) the viability of the using the XML representation for text summarization, information extraction, novelty detection, and text mining. Subsequent efforts showed that XML representations could be effectively used in summarization (Litkowski, 2003b) and novelty detection (Litkowski, 2005). Initially, CL Research developed an interface for examining question-answering performance. This interface has since evolved into a Knowledge Management System (KMS) that provides a single platform for examining English documents (e.g., newswire and research papers) and for generating different types of output (e.g., answers to questions, summaries, and document ontologies), also in XML representations. In this demonstration, CL Research will describe many parts of KMS, particularly the approaches used for analyzing texts.1 The demonstration will particularly focus on the value of XML in pro</context>
<context position="9015" citStr="Litkowski, 2005" startWordPosition="1316" endWordPosition="1317"> basic XPath is then extended for each question type with additional specifications, e.g., to ask for noun phrases that have time, location, or other semantic attributes. Experiments have shown that there is a tradeoff involved in these specifications. If they are very exacting, few possible answers are returned. Backoff strategies are used to return a larger set of potential answers and to analyze the context of these potential answers in more detail. The development of routines for automatic creation of XPath expressions is an ongoing process, but has begun to yield more consistent results (Litkowski, 2005). In preparation for TREC 2004, KMS was further extended to incorporate a web-based component. With a check box to indicate whether the web or a document repository should be used, additional functionality was used to pose questions to Google. In web mode, an XML representation of a question is still developed, but then it is analyzed to present an optimal query to Google, typically, a pattern that will provide an answer. This involves the use of an integrated dictionary, particularly for creating appropriate inflected forms in the search query. KMS only uses the first page of Google results, </context>
<context position="11769" citStr="Litkowski (2005)" startWordPosition="1734" endWordPosition="1735">eadline, or keyword), which documents to summarize (one or many), and the length. Topic-based summaries require the user to enter search terms. The search terms can be as simple as a person’s name or a few keywords or can be several sentences in length. Topic-based summaries use the search terms to give extra weight to sentences containing the search terms. Sentences are also evaluated for their novelty, with redundancy and overlap measures based on examining their noun phrases. KMS summarization procedures are described in more detail in Litkowski (2003b); novelty techniques are described in Litkowski (2005). In KMS, summaries are saved in XML files as sets of sentences, each characterized by its source and sentence number. Each summary uses XML attributes containing the user’s specifications and the documents included in the search. generated quickly but in whole form. 5 Document Exploration KMS includes two major components for exploring the contents of a document. The first is based on the semantic types attached to nouns and verbs. The second is based on analyzing noun phrases to construct a document hierarchy or ontology. As noted above, each noun phrase and each verb 15 is tagged with its s</context>
</contexts>
<marker>Litkowski, 2005</marker>
<rawString>Litkowski, K. C. (2005). Evolving XML and Dictionary Strategies for Question Answering and Novelty Tasks. Available: http://trec.nist.gov/pubs/trec13/t13proceedings.ht ml.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
</authors>
<title>The Rhetorical Parsing of Unrestricted Texts: A Surface-based Approach.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>26</volume>
<issue>3</issue>
<pages>395--448</pages>
<contexts>
<context position="4785" citStr="Marcu (2000)" startWordPosition="688" endWordPosition="689">n, may be included at any node. (Litkowski (2002) and references therein provide more details on the parser.) After each sentence is parsed, its parse tree is traversed in a depth-first recursive function. During this traversal, each non-terminal and terminal node is analyzed to identify discourse segments (sentences and clauses), noun phrases, verbs, adjectives, and prepositional phrases. These items are maintained in lists; the growing lists constitute a document’s discourse structure and are used, e.g., in resolving anaphora and establishing coreferents (implementing techniques inspired by Marcu (2000) and Tetreault (2001)). As these items are identified, they are subjected to a considerable amount of analysis to characterize them syntactically and semantically. The analysis includes word-sense disambiguation of nouns, verbs (including subcategorization identification), and adjectives and semantic analysis of prepositions to establish their semantic roles (such as described in Gildea &amp; Jurafsky, 2002). When all sentences of a document have been 2The overall design of KMS is based on requirements enunciated by intelligence analysts and question-answering researchers in a workshop on Scenario</context>
</contexts>
<marker>Marcu, 2000</marker>
<rawString>Marcu, Daniel. (2000) The Rhetorical Parsing of Unrestricted Texts: A Surface-based Approach. Computational Linguistics, 26 (3), 395-448.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Navigli</author>
<author>P Velardi</author>
</authors>
<title>Learning Domain Ontologies from Document Warehouses and Dedicated Web Sites.</title>
<date>2004</date>
<journal>Computational Linguistics</journal>
<volume>30</volume>
<pages>151--180</pages>
<contexts>
<context position="13340" citStr="Navigli &amp; Velardi (2004)" startWordPosition="1994" endWordPosition="1997">ouped together and then presented in a drop-down box by frequency. Finally, the user can select any term set and obtain all the sentences in the documents containing any of the terms. KMS provides the capability for viewing a “dynamic” noun ontology of a document set. All noun phrases are analyzed into groups in a tree structure that portrays the ontology that is instantiated by these phrases. Noun phrases are reduced to their base forms (in cases of plurals) and grouped together first on the basis of their heads. Synonym sets are then generated and a further grouping is made. Algorithms from Navigli &amp; Velardi (2004) are being modified and implemented in KMS. The user can then select a node in the ontology hierarchy and create a summary based on sentences containing any of its terms or children. 6 Dictionaries and Thesauruses in KMS KMS makes extensive use of integrated dictionaries and thesauruses, in addition to a comprehensive dictionary used in parsing (which makes use of about 30 subcategorization patterns for verbs). This dictionary is supplemented with other dictionaries that are first used in dynamically extending the parser’s dictionary for parsing, but then more extensively in semantic analysis.</context>
</contexts>
<marker>Navigli, Velardi, 2004</marker>
<rawString>Navigli, R. &amp; P. Velardi (2004) Learning Domain Ontologies from Document Warehouses and Dedicated Web Sites. Computational Linguistics 30, 151-180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joel Tetreault</author>
</authors>
<title>A Corpus-Based Evaluation of Centering and Pronoun Resolution.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>4</issue>
<pages>507--520</pages>
<contexts>
<context position="4806" citStr="Tetreault (2001)" startWordPosition="691" endWordPosition="692">d at any node. (Litkowski (2002) and references therein provide more details on the parser.) After each sentence is parsed, its parse tree is traversed in a depth-first recursive function. During this traversal, each non-terminal and terminal node is analyzed to identify discourse segments (sentences and clauses), noun phrases, verbs, adjectives, and prepositional phrases. These items are maintained in lists; the growing lists constitute a document’s discourse structure and are used, e.g., in resolving anaphora and establishing coreferents (implementing techniques inspired by Marcu (2000) and Tetreault (2001)). As these items are identified, they are subjected to a considerable amount of analysis to characterize them syntactically and semantically. The analysis includes word-sense disambiguation of nouns, verbs (including subcategorization identification), and adjectives and semantic analysis of prepositions to establish their semantic roles (such as described in Gildea &amp; Jurafsky, 2002). When all sentences of a document have been 2The overall design of KMS is based on requirements enunciated by intelligence analysts and question-answering researchers in a workshop on Scenario-Based Question Answe</context>
</contexts>
<marker>Tetreault, 2001</marker>
<rawString>Tetreault, Joel. (2001) A Corpus-Based Evaluation of Centering and Pronoun Resolution. Computational Linguistics, 27 (4), 507-520.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>