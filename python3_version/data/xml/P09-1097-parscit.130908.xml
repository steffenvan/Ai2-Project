<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.956968">
Semantic Tagging of Web Search Queries
</title>
<author confidence="0.99786">
Mehdi Manshadi Xiao Li
</author>
<affiliation confidence="0.998403">
University of Rochester Microsoft Research
</affiliation>
<address confidence="0.665311">
Rochester, NY Redmond, WA
</address>
<email confidence="0.9969">
mehdih@cs.rochester.edu xiaol@microsoft.com
</email>
<sectionHeader confidence="0.997368" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9995485">
We present a novel approach to parse web
search queries for the purpose of automatic
tagging of the queries. We will define a set
of probabilistic context-free rules, which
generates bags (i.e. multi-sets) of words. Us-
ing this new type of rule in combination
with the traditional probabilistic phrase
structure rules, we define a hybrid grammar,
which treats each search query as a bag of
chunks (i.e. phrases). A hybrid probabilistic
parser is used to parse the queries. In order
to take contextual information into account,
a discriminative model is used on top of the
parser to re-rank the n-best parse trees gen-
erated by the parser. Experiments show that
our approach outperforms a basic model,
which is based on Conditional Random
Fields.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.983276411764706">
Understanding users’ intent from web search
queries is an important step in designing an intel-
ligent search engine. While it remains a chal-
lenge to have a scientific definition of &amp;quot;intent&amp;quot;,
many efforts have been devoted to automatically
mapping queries into different domains i.e. topi-
cal classes such as product, job and travel
(Broder et al. 2007; Li et al. 2008). This work
goes beyond query-level classification. We as-
sume that the queries are already classified into
the correct domain and investigate the problem of
semantic tagging at the word level, which is to
assign a label from a set of pre-defined semantic
labels (specific to the domain) to every word in
the query. For example, a search query in the
product domain can be tagged as:
cheap garmin streetpilot c340 gps
</bodyText>
<equation confidence="0.674653">
     ||
</equation>
<subsubsectionHeader confidence="0.193171">
SortOrder Brand Model Model Type
</subsubsectionHeader>
<bodyText confidence="0.999896317073171">
Many specialized search engines build their in-
dexes directly from relational databases, which
contain highly structured information. Given a
query tagged with the semantic labels, a search
engine is able to compare the values of semantic
labels in the query (e.g., Brand = Ògarmin”) with
its counterpart values in documents, thereby pro-
viding users with more relevant search results.
Despite this importance, there has been rela-
tively little published work on semantic tagging
of web search queries. Allan and Raghavan
(2002) and Barr et al. (2008) study the linguistic
structure of queries by performing part-of-speech
tagging. Pasca et al. (2007) use queries as a
source of knowledge for extracting prominent
attributes for semantic concepts.
On the other hand, there has been much work
on extracting structured information from larger
text segments, such as addresses (Kushmerick
2001), bibliographic citations (McCallum et al.
1999), and classified advertisements (Grenager
et al. 2005), among many others. The most
widely used approaches to these problems have
been sequential models including hidden Markov
models (HMMs), maximum entropy Markov mod-
els (MEMMs) (Mccallum 2000), and conditional
random fields (CRFs) (Lafferty et al. 2001)
These sequential models, however, are not op-
timal for processing web search queries for the
following reasons.. The first problem is that the
global constraints and long distance dependencies
on state variables are difficult to capture using
sequential models. Because of this limitation,
Viola and Narasimhand (2007) use a discrimina-
tive context-free (phrase structure) grammar for
extracting information from semi-structured data
and report higher performances over CRFs.
Secondly, sequential models treat the input text
as an ordered sequence of words. A web search
query, however, is often formulated by a user as a
bag of keywords. For example, if a user is look-
</bodyText>
<page confidence="0.974146">
861
</page>
<note confidence="0.999611">
Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 861–869,
Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.998586218181818">
ing for cheap garmin gps, it is possible that the
query comes in any ordering of these three
words. We are looking for a model that, once it
observes this query, assumes that the other per-
mutations of the words in this query are also
likely. This model should also be able to handle
cases where some local orderings have to be
fixed as in the query buses from New York City to
Boston, where the words in the phrases from New
York city and to Boston have to come in the exact
order.
The third limitation is that the sequential mod-
els treat queries as unstructured (linear) se-
quences of words. The study by Barr et al. (2008)
on Yahoo! query logs suggests that web search
queries, to some degree, carry an underlying lin-
guistic structure. As an example, consider a query
about finding a local business near some location
such as:
seattle wa drugstore 24/7 98109
This query has two constituents: the Business that
the user is looking for (24/7 drugstore) and the
Neighborhood (seattle wa 98109). The model
should not only be able to recognize the two con-
stituents but it also needs to understand the struc-
ture of each constituent. Note that the arbitrary
ordering of the words in the query is a big chal-
lenge to understanding the structure of the query.
The problem is not only that the two constituents
can come in either order, but also that a sub-
constituent such as 98109 can also be far from
the other words belonging to the same constitu-
ent. We are looking for a model that is able to
generate a hierarchical structure for this query as
shown in figure (1).
The last problem that we discuss here is that
the two powerful sequential models i.e. MEMM
and CRF are discriminative models; hence they
are highly dependent on the training data. Prepar-
ing labeled data, however, is very expensive.
Therefore in cases where there is no or a small
amount of labeled data available, these models do
a poor job.
In this paper, we define a hybrid, generative
grammar model (section 3) that generates bags of
phrases (also called chunks in this paper). The
chunks are generated by a set of phrase structure
(PS) rules. At a higher level, a bag of chunks is
generated from individual chunks by a second
type of rule, which we call context-free multiset
generating rules. We define a probabilistic ver-
sion of this grammar in which every rule has a
probability associated with it. Our grammar
model eliminates the local dependency assump-
tion made by sequential models and the ordering
</bodyText>
<figureCaption confidence="0.999183">
Figure 1. A simple grammar for product domain
</figureCaption>
<bodyText confidence="0.999851545454545">
constraints imposed by phrase structure gram-
mars (PSG). This model better reflects the under-
lying linguistic structure of web search queries.
The model’s power, however, comes at the cost
of increased time complexity, which is exponen-
tial in the length of the query. This, is less of an
issue for parsing web search queries, as they are
usually very short (2.8 words/query in average
(Xue et al., 2004)).
Yet another drawback of our approach is due
to the context-free nature of the proposed gram-
mar model. Contextual information often plays a
big role in resolving tagging ambiguities and is
one of the key benefits of discriminative models
such as CRFs. But such information is not
straightforward to incorporate in our grammar
model. To overcome this limitation, we further
present a discriminative re-ranking module on top
of the parser to re-rank the n-best parse trees gen-
erated by the parser using contextual features. As
seen later, in the case where there is not a large
amount of labeled data available, the parser part
is the dominant part of the module and performs
reasonably well. In cases where there is a large
amount of labeled data available, the discrimina-
tive re-ranking incorporates into the system and
enhances the performance. We evaluate this
model on the task of tagging search queries in the
product domain. As seen later, preliminary ex-
periments show that this hybrid genera-
tive/discriminative model performs significantly
better than a CRF-based module in both absence
and presence of the labeled data.
The structure of the paper is as follows. Sec-
tion 2 introduces a linguistic grammar formalism
that motivates our grammar model. In section 3,
we define our grammar model. In section 4 we
address the design and implementation of a
parser for this kind of grammar. Section 5 gives
an example of such a grammar designed for the
purpose of automatic tagging of queries. Section
6 discusses motivations for and benefits of run-
ning a discriminative re-ranker on top of the
parser. In section 7, we explain the evaluations
</bodyText>
<page confidence="0.995793">
862
</page>
<bodyText confidence="0.999921">
and discuss the results. Section 8 summarizes this
work and discusses future work.
</bodyText>
<sectionHeader confidence="0.997768" genericHeader="introduction">
2 ID/LP Grammar
</sectionHeader>
<bodyText confidence="0.995161111111111">
Context-free phrase structure grammars are
widely used for parsing natural language. The
adequate power of this type of grammar plus the
efficient parsing algorithms available for it has
made it very popular. PSGs treat a sentence as an
ordered sequence of words. There are however
natural languages that are free word order. For
example, a three-word sentence consisting of a
subject, an object and a verb in Russian, can
occur in all six possible orderings. PSGs are not
a well-suited model for this type of language,
since six different PS-rules must be defined in
order to cover such a simple structure. To address
this issue, Gazdar (1985) introduced the concept
of ID/LP rules within the framework of
Generalized Phrase Structure Grammar (GPSG).
In this framework, Immediate Dominance or ID
rules are of the form:
</bodyText>
<listItem confidence="0.803554818181818">
(1) A→ B, C
This rule specifies that a non-terminal A can be
rewritten as B and C, but it does not specify the
order. Therefore A can be rewritten as both BC
and CB. In other words the rule in (1) is
equivalent to two PS-rules:
(2) A → BC
A → CB
Similarly one ID rule will suffice to cover the
simple subject-object-verb structure in Russian:
(3) S 4 Sub, Obj, Vrb
</listItem>
<bodyText confidence="0.999718285714286">
However even in free-word-order languages,
there are some ordering restrictions on some of
the constituents. For example in Russian an
adjective always comes before the noun that it
modifies. To cover these ordering restrictions,
Gazdar defined Linear Precedence (LP) rules. (4)
gives an example of a linear precedence rule:
</bodyText>
<listItem confidence="0.834221">
(4) ADJ &lt; N
</listItem>
<bodyText confidence="0.999267434782609">
This specifies that ADJ always comes before N
when both occur on the right-hand side of a
single rule.
Although very intuitive, ID/LP rules are not
widely used in the area of natural language
processing. The main reason is the time-
complexity issue of ID/LP grammar. It has been
shown that parsing ID/LP rules is an NP-
complete problem (Barton 1985). Since the
length of a natural language sentence can easily
reach 30-40 (and sometimes even up to 100)
words, ID/LP grammar is not a practical model
for natural language syntax. In our case, however,
the time-complexity is not a bottleneck as web
search queries are usually very short (2.8 words
per query in average). Moreover, the nature of ID
rules can be deceptive as it might appear that ID
rules allow any reordering of the words in a valid
sentence to occur as another vaild sentence of the
language. But in general this is not the case. For
example consider a grammar with only two ID
rules given in (5) and consider S as the start
symbol:
</bodyText>
<equation confidence="0.8279825">
(5) S → B, c
B → d, e
</equation>
<bodyText confidence="0.999452916666667">
It can be easily verified that dec is a sentence of
the language but dce is not. In fact, although the
permutation of subconstituents of a constituent is
allowed, a subconstituent can not be pulled out
from its mother consitutent and freely move
within the other constituents. This kind of
movement however is a common behaviour in
web search queries as shown in figure (1). It
means that even ID rules are not powerful enough
to model the free-word-order nature of web
search queries. This leads us to define to a new
type of grammar model.
</bodyText>
<sectionHeader confidence="0.99931" genericHeader="method">
3 Our Grammar Model
</sectionHeader>
<subsectionHeader confidence="0.999755">
3.1 The basic model
</subsectionHeader>
<bodyText confidence="0.998699">
We propose a set of rules in the form:
</bodyText>
<equation confidence="0.89110525">
(6) S → {B, c)
B → {D, E)
D → {d)
E → {e)
</equation>
<bodyText confidence="0.836102357142857">
which can be used to generate multisets of words.
For the notation convenience and consistancy,
throughout this paper, we show terminals and
non-terminals by lowercase and uppercase letters,
respectively and sets and multisets by bold font
uppercase letters. Using the rules in (6) a
sentence of the language (which is a multiset in
this model) can be derived as follows:
(7) S ⇒ {B, c) ⇒ {D, E, c) ⇒ {D, e, c)⇒ {d, e, c)
Once the set is generated, it can be realized as
any of the six permutation of d, e, and c.
Therefore a single sequence of derivations can
lead to six different strings of words. As another
example consider the grammar in (8).
</bodyText>
<construct confidence="0.944716">
(8) Query → {Business, Location)
Business → {Attribute, Business)
Location → {City, State)
Business → {drugstore)  |{Resturant)
Attribute→ {Chinese)  |{24/7)
City→ {Seattle)  |{Portland)
State→ {WA)  |{OR)
</construct>
<page confidence="0.998823">
863
</page>
<figureCaption confidence="0.999796">
Figure 2. A CFSG parse tree
</figureCaption>
<bodyText confidence="0.999028210526316">
where Query is the start symbol and by A — B|C
we mean two differnet rules A — B and A — C.
Figures (2) and (3) show the tree structures for
the queries Restaurant Rochester Chinese MN,
and Rochester MN Chinese Restaurant,
respectively. As seen in these figures, no matter
what the order of the words in the query is, the
grammar always groups the words Resturant and
Chinese together as the Business and the words
Rochester and MN together as the Location. It is
important to notice that the above grammars are
context-free as every non-terminal A, which
occurs on the left-hand side of a rule r, can be
replaced with the set of terminals and non-
terminals on the right-hand side of r, no matter
what the context in which A occurs is.
More formally we define a Context-Free
multiSet generating Grammar (CFSG) as a 4-
tuple G=(N, T, S, R) where
</bodyText>
<listItem confidence="0.986317428571429">
• N is a set of non-terminals;
• T is a set of terminals;
• S E N is a special non-terminal called
start symbol,
• R is a set of rules {Ai— X&apos;} where Ai is a
non-terminal and X&apos; is a set of terminals
and non-terminals.
</listItem>
<bodyText confidence="0.960779333333333">
Given two multisets Y and Z over the set N U T,
we say Y dervies Z (shown as Y ==&gt; Z) iff there
exists A, W, and X such that:
</bodyText>
<equation confidence="0.999882333333333">
Y = W + {A}1
Z = W + X
A— X E R
</equation>
<bodyText confidence="0.99858475">
Here ==&gt;* is defined as the reflexive transitive
closure of ==&gt;. Finally we define the language of
multisets generated by the grammar G (shown as
L(G)) as
</bodyText>
<equation confidence="0.532666">
L = { X  |X is a multiset over NUT and S ==&gt;*X}
</equation>
<bodyText confidence="0.983154">
The sequence of =&gt; used to derive X from S is
called a derivation of X. Given the above
</bodyText>
<footnote confidence="0.549529666666667">
1 If X and Y are two multisets, X+Y simply means append-
ing X to Y. For example {a, b, a} + {b, c, d} = {a, b, a, b, c,
d}.
</footnote>
<figureCaption confidence="0.99911">
Figure 3. A CFSG parse tree
</figureCaption>
<bodyText confidence="0.9992005">
definitions, parsing a multiset X means to find all
(if any) the derivations of X from S. 2
</bodyText>
<subsectionHeader confidence="0.997296">
3.2 Probabilisic CFSG
</subsectionHeader>
<bodyText confidence="0.999438">
Very often a sentence in the language has more
than one derivation, that is the sentence is
syntactically ambiguous. One natural way of
resolving the ambiguity is using a probabilistic
grammar. Analogous to PCFG (Manning and
Schütze 1999), we define the probabilistic
version of a CFSG, in which every rule Ai—X&apos; has
a probability P(Ai—X&apos;) and for every non-
terminal Ai, we have:
</bodyText>
<equation confidence="0.669209">
(9) E&apos; P(Ai— X&apos;) = 1
</equation>
<bodyText confidence="0.948833">
Consider a sentence w1w2...wn, a parse tree T of
this sentence, and an interior node v in T labeled
with Av and assume that v1, v2, ...vk are the
children of the node v in T. We define:
</bodyText>
<listItem confidence="0.7363105">
(10) α(v) = P(Av— {Av1... Avk})α(v1) ... α(vk)
with the initial conditions α(wi)=1. If u is the root
of the tree T we have:
(11) P(w1w2...wn , T) = α(u)
</listItem>
<bodyText confidence="0.9706835">
The parse tree that the probabilistic model
assigns to the sentence is defined as:
</bodyText>
<equation confidence="0.421889">
(12) Tmax = argmaxT (P(w1w2...wn , T))
</equation>
<bodyText confidence="0.998811">
where T ranges over all possible parse trees of the
sentence.
</bodyText>
<sectionHeader confidence="0.998521" genericHeader="method">
4 Parsing Algorithm
</sectionHeader>
<subsectionHeader confidence="0.999624">
4.1 Deterministic parser
</subsectionHeader>
<bodyText confidence="0.823904230769231">
The parsing algorithm for the CFSG is straight-
forward. We used a modified version of the Bot-
tom-Up Chart Parser for the phrase structure
grammars (Allen 1995, see 3.4). Given the
grammar G=(N,T,S,R) and the query
q=w1w2...wn, the algorithm in figure (4) is used to
parse q. The algorithm is based on the concept of
an active arc. An active arc is defined as a 3–
2 Every sentence of a language corresponds to a vector of |T|
integers where the kth element represents how many times
the kth terminal occurs in the multi-set. In fact, the languages
defined by grammars are not interesting but the derivations
are.
</bodyText>
<page confidence="0.993557">
864
</page>
<bodyText confidence="0.999379069767442">
tuple (r, U, I) where r is a rule A → X in R, U is a
subset of X, and I is a subset of {1, 2 ...n} (where
n is the number of words in the query). This ac-
tive arc tries to find a match to the right-hand side
of r (i.e. X) and suggests to replace it with the
non-terminal A. U contains the part of the right-
hand side that has not been matched yet. There-
fore when an arc is newly created U=X. Equiva-
lently, X\U3 is the part of the right hand side that
has so far been matched with a subset of words in
the query, where I stores the positions of these
words in q.
An active arc is completed when U=¯. Every
completed active arc can be reduced to a tuple (A,
I), which we call a constituent. A constituent (A,
I) shows that the non-terminal A matches the
words in the query that are positioned at the
numbers in I. Every constituent that is built by
the parser is stored in a data structure called chart
and remains there throughout the whole process.
Agenda is another data structure that temporarily
stores the constituents. At initialization step, the
constituents (w1, {1}), ... (wn, {n}) are added to
both chart and agenda. At each iteration, we pull
out a constituent from the agenda and try to find a
match to this constituent from the remaining list
of terminals and non-terminals on the right-hand
side of an active arc. More precisely, given a
constituent c=(A, I) and an active arc γ =
(r:B4X, U, J), we check if A E U and I ∩ J =
¯; if so, γ is extendable by c, therefore we extend
γ by removing A from U and appending I to J.
Note that the extension process keeps a copy of
every active arc before it extends it. In practice
every active arc and every constituent keep a set
of pointers to its children constituents (stored in
chart). This information is necessary for the ter-
mination step in order to print the parse trees. The
algorithm succeeds if there is a constituent in the
chart that corresponds to the start symbol and
covers all the words in the query, i.e. there is a
constituent of the form (S, {1,2,....n}) in the
chart.
</bodyText>
<subsectionHeader confidence="0.994314">
4.2 Probabilistic Parser
</subsectionHeader>
<bodyText confidence="0.999707857142857">
The algorithm given in figure (4) works for a de-
terministic grammar. As mentioned before, we
use a probabilistic version of the grammar.
Therefore the algorithm is modified for the prob-
abilistic case. The probabilistic parser keeps a
probability p for every active arc and every con-
stituent:
</bodyText>
<equation confidence="0.727057571428572">
γ = (r, U, J, pγ )
3 A\B is defined as {x  |x ∈ A &amp; x ∉ B}
c =(A, I, pc )
When extending γ using c, we have:
(13) py F py pc
When creating c from the completed active arc γ :
(14) pc F py p(r)
</equation>
<bodyText confidence="0.999908285714286">
Although search queries are usually short, the
running time is still an issue when the length of
the query exceeds 7 or 8. Therefore a couple of
techniques have been used to make the naïve al-
gorithm more efficient. For example we have
used pruning techniques to filter out structures
with very low probability. Also, a dynamic pro-
gramming version of the algorithm has been
used, where for every subset I of the word posi-
tions and every non-terminal A only the highest-
ranking constituent c=(A, I, p) is kept and the rest
are ignored. Note that although more efficient,
the dynamic programming version is still expo-
nential in the length of the query.
</bodyText>
<sectionHeader confidence="0.962976" genericHeader="method">
5 A grammar for semantic tagging
</sectionHeader>
<bodyText confidence="0.999982">
As mentioned before, in our system queries are
already classified into different domains like
movies, books, products, etc. using an automatic
query classifier. For every domain we have a
schema, which is a set of pre-defined tags. For
example figure (5) shows an example of a
schema for the product domain. The task defined
for this system is to automatically tag the words
in the query with the tags defined in the schema:
</bodyText>
<figure confidence="0.753752">
cheap garmin streetpilot c340 gps
     ||
SortOrder Brand Model Model Type
</figure>
<figureCaption confidence="0.98702">
Figure 4. An algorithm for parsing deterministic
</figureCaption>
<figure confidence="0.98061925">
CFSG
Initialization:
For each word wi in q add (wi, {i}) to Chart and
to Agenda
For all r: A→X in R, create an active arc (r, X,
{}) and add it to the list of active arcs.
Iteration
Repeat
Pull a constituent c = (A, I) from Agenda
For every active arc γ =(r:B4X, U, I)
Extend γ using c if extendable
If U=¯ add (B, I) to Chart and to Agenda
Until Agenda is empty
Termination
For every item c=(S, {1..n}) in Chart, return the
tree rooted at c.
</figure>
<page confidence="0.995341">
865
</page>
<bodyText confidence="0.999992252873563">
We mentioned that one of the motivations of
parsing search queries is to have a deeper under-
standing of the structure of the query. The
evaluation of such a deep model, however, is not
an easy task. There is no Treebank available for
web search queries. Furthermore, the definition
of the tree structure for a query is quite arbitrary.
Therefore even when human resources are avail-
able, building such a Treebank is not a trivial
task. For these reasons, we evaluate our grammar
model on the task of automatic tagging of queries
for which we have labeled data available. The
other advantage of this evaluation is that there
exists a CRF-based module in our system used
for the task of automatic tagging. The perform-
ance of this module can be considered as the
baseline for our evaluation.
We have manually designed a grammar for
the purpose of automatic tagging. The resources
available for training and testing were a set of
search queries from the product domain. There-
fore a set of CFSG rules were written for the
product domain. We defined very simple and
intuitive rules (shown in figure 6) that could eas-
ily be generalized to the other domains
Note that Type, Brand, Model, É could be
either pre-terminals generating word tokens, or
non-terminals forming the left-hand side of the
phrase structure rules. For the product domain,
Type and Attribute are generated by a phrase
structure grammar. Model and Attribute may also
be generated by a set of manually designed regu-
lar expressions. The rest of the tags are simply
pre-terminals generating word tokens. Note that
we have a lexicon, e.g.., a Brand lexicon, for all
the tags except Type and Attribute. The model,
however, extends the lexicon by including words
discovered from labeled data (if available). The
gray color for a non-terminal on the right-hand
side (RHS) of some rule means that the non-
terminal is optional (see Query rule in figure (6)).
We used the optional non-terminals to make the
task of defining the grammar easier. For example
if we consider a rule with n optional non-
terminals on its RHS, without optional non-
terminals we have to define 2n different rules to
have an equivalent grammar. The parser can treat
the optional non-terminals in different ways such
as pre-compiling the rules to the equivalent set of
rules with no optional non-terminal, or directly
handling optional non-terminals during the pars-
ing. The first approach results in exponentially
many rules in the system, which causes sparsity
issues when learning the probability of the rules.
Therefore in our system the parser handles op-
tional non-terminals directly. In fact, every non-
terminal has its own probability for not occurring
on the RHS of a rule, therefore the model learns
n+1 probabilities for a rule with n optional non-
terminals on its RHS: one for the rule itself and
one for every non-terminal on its RHS. It means
that instead of learning 2n probabilities for 2n dif-
ferent rules, the model only learns n+1 probabili-
ties. That solves the sparsity problem, but causes
another issue which we call short length prefer-
ence. This occurs because we have assumed that
the probability of a non-terminal being optional is
independent of other optional non-terminals.
Since for almost all non-terminals on the RHS of
the query rule, the probability that the non-
terminal does not exist in an instance of a query
is higher than 0.5, a null query is the most likely
query that the model generates! We solve this
problem by conditioning the probabilities on the
length of queries. This brings a trade-off between
the two other alternatives: ignoring sparsity prob-
lem to prevent making many independence as-
sumptions and making a lot of independence
assumptions to address the sparsity issue.
Unlike sequential models, the grammar
model is able to capture critical global con-
straints. For example, it is very unlikely for a
query to have more than one Type, Brand, etc.
This is an important property of the product que-
ries that can help to resolve the ambiguity in
many cases. In practice, the probability that the
model learns for a rule like:
</bodyText>
<note confidence="0.994820375">
Type: Camera, Shoe, Cell phone, ...
Brand: Canon, Nike, At&amp;t, ...
Model: dc1700, powershot, ipod nano
Attribute: 1GB, 7mpixel, 3X, ...
BuyingIntenet: Sale, deal, ...
ResearchIntent: Review, compare, ...
SortOrder: Best, Cheap, ...
Merchant: Walmart, Target, ...
</note>
<figureCaption confidence="0.999734">
Figure 5. Example of schema for product domain
</figureCaption>
<equation confidence="0.996075142857143">
Query — {Brand*, Product*, Model*, ...}
Brand* — {Brand}
Brand* — {Brand*, Brand}
Type* — {Type}
Type* — {Type*, Type}
Model* — {Model}
Model* — {Model*, Model}
</equation>
<page confidence="0.463858">
...
</page>
<figureCaption confidence="0.982668">
Figure 6. A simple grammar for product domain
</figureCaption>
<page confidence="0.987945">
866
</page>
<figureCaption confidence="0.999185">
Figure 7. Two equivalent CFSG parse trees
</figureCaption>
<bodyText confidence="0.561428">
Type* 4 {Type*, Type}
compared to the rule:
</bodyText>
<subsubsectionHeader confidence="0.509507">
Type* 4 Type
</subsubsectionHeader>
<bodyText confidence="0.99994124">
is very small; the model penalizes the occurrence
of more than one Type in a query. Figure (7a)
shows an example of a parse tree generated for
the query “Canon vs Sony Camera” in which B,
Q, and T are abbreviations for Brand, Query, and
Type, and U is a special tag for the words that
does not fall into any other tag categories and
have been left unlabeled in our corpus such as a,
the, for, etc. Therefore the parser assigns the tag
sequence B U B T to this query. It is true that the
word “vs” plays a critical role in this query, rep-
resenting that the user’s intention is to compare
the two brands; but as mentioned above in our
labeled data such words has left unlabeled. The
general model, however, is able to easily capture
these sorts of phenomena.
A more careful look at the grammar shows
that there is another parse tree for this query as
shown in figure (7b). These two trees basically
represent the same structure and generate the
same sequence of tags. The number of trees gen-
erated for the same structure increases exponen-
tially with the number of equal tags in the tree.
To prevent this over-generation we used rules
analogous to GPSG’s LP rules such as:
</bodyText>
<subsectionHeader confidence="0.624909">
B* &lt; B
</subsectionHeader>
<bodyText confidence="0.9992415">
which allows only a unique way of generating a
bag of the Brand tags. Using this LP rule, the
only valid tree for the above query is the one in
figure (7a).
</bodyText>
<sectionHeader confidence="0.999644" genericHeader="method">
6 Discriminative re-ranking
</sectionHeader>
<bodyText confidence="0.999973821428571">
By using a context-free grammar, we are missing
a great source of clues that can help to resolve
ambiguity. Discriminative models, on the other
hand, allow us to define numerous features,
which can cooperate to resolve the ambiguities.
Similar studies in parsing natural language sen-
tences (Collins and Koo 2005) have shown that
if, instead of taking the most likely tree structure
generated by a parser, the n-best parse trees are
passed through a discriminative re-ranking mod-
ule, the accuracy of the model will increase sig-
nificantly. We use the same idea to improve the
performance of our model. We run a Support
Vector Machine (SVM) based re-ranking module
on top of the parser. Several contextual features
(such as bigrams) are defined to help in disam-
biguation. This combination provides a frame-
work that benefits from the advantages of both
generative and discriminative models. In particu-
lar, when there is no or a very small amount of
labeled data, a parser could still work by using
unsupervised learning approaches to learn the
rules, or by simply using a set of hand-built rules
(as we did above for the task of semantic tag-
ging). When there is enough labeled data, then a
discriminative model can be trained on the la-
beled data to learn contextual information and to
further enhance the tagging performance.
</bodyText>
<sectionHeader confidence="0.999222" genericHeader="evaluation">
7 Evaluation
</sectionHeader>
<bodyText confidence="0.918898266666667">
Our resources are a set of 21000 manually la-
beled queries, a manually designed grammar, a
lexicon for every tag (except Type and Attribute),
and a set of regular expressions defined for Mod-
els and Attributes. Note that with a grammar
similar to the one in figure (6), generating a parse
tree from a labeled query is straightforward. Then
the parser is trained on the trees to learn the pa-
rameters of the model (probabilities in this case).
We randomly extracted 3000, out of 21000,
queries as the test set and used the remaining
18000 for training. We created training sets with
different sizes to evaluate the impact of training
data size on tagging performance.
Three modules were used in the evaluation:
the CRF-based model4, the parser, and the parser
plus the SVM-based re-ranking. Figure (8) shows
the learning curve of the word-level F-score for
all the three modules. As seen in this plot, when
there is a small amount of training data, the
parser performs better than the CRF module and
parser+SVM module performs better than the
other two. With a large amount of training data,
the CRF and parser almost have the same per-
formance. Once again the parser+SVM module
4 The CRF module also uses the lexical resources and regu-
lar expressions. In fact, it applies a deterministic context free
grammar to the query to find all the possible groupings of
words into chunks and uses this information as a set of fea-
tures in the system.
</bodyText>
<page confidence="0.990611">
867
</page>
<figureCaption confidence="0.999798">
Figure 8. The learning curve for the three modules
</figureCaption>
<bodyText confidence="0.999946785714286">
outperforms the other two. These results show
that, as expected, the CRF-based model is more
dependent on the training data than the parser.
Parser+SVM always performs at least as well as
the parser-only module even with a very small
set of training data. This is because the rank
given to every parse tree by the parser is used as
a feature in the SVM module. When there is a
very small amount of training data, this feature is
dominant and the output of the re-reranking
module is basically the same as the parser’s
highest-rank output. Table (1) shows the per-
formance of all three modules when the whole
training set was used to train the system. The first
three columns in the table show the word-level
precision, recall, and F-score; and the last column
represents the query level accuracy (a query is
considered correct if all the words in the query
have been labeled correctly). There are two rows
for the parser+SVM in the table: one for n=2 (i.e.
re-ranking the 2-Best trees) and one for n=10. It
is interesting to see that even with the re-ranking
of only the first two trees generated by the
parser, the difference between the accuracy of
the parser+SVM module and the parser-only
module is quite significant. Re-ranking with a
larger number of trees (n&gt;10) did not increase
performance significantly.
</bodyText>
<sectionHeader confidence="0.998126" genericHeader="conclusions">
8 Summary
</sectionHeader>
<bodyText confidence="0.99993525">
We introduced a novel approach for deep parsing
of web search queries. Our approach uses a
grammar for generating multisets called a con-
text-free multiset generating grammar (CFSG).
We used a probabilistic version of this grammar.
A parser was designed for parsing this type of
grammar. Also a discriminative re-ranking mod-
ule based on a support vector machine was used
</bodyText>
<table confidence="0.997271">
Train No = 18000 P R F Q
Test No = 3000
CRF 0.815 0.812 0.813 0.509
Parser 0.808 0.814 0.811 0.494
Parser+SVM (n = 2) 0.823 0.827 0.825 0.531
Parser+SVM (n = 10) 0.832 0.835 0.833 0.555
</table>
<tableCaption confidence="0.999739">
Table 1. The results of evaluating the three modules
</tableCaption>
<bodyText confidence="0.99999084375">
to take contextual information into account. We
have used this system for automatic tagging of
web search queries and have compared it with a
CRF-based model designed for the same task.
The parser performs much better when there is
a small amount of training data, but an adequate
lexicon for every tag. This is a big advantage of
the parser model, because in practice providing
labeled data is very expensive but very often the
lexicons can be easily extracted from the struc-
tured data on the web (for example extracting
movie titles from imdb or book titles from Ama-
zon).
Our hybrid model (parser plus discriminative
re-ranking), on the other hand, outperforms the
other two modules regardless of the size of the
training data.
The main drawback with our approach is to
completely ignore the ordering. Note that al-
though strict ordering constraints such as those
imposed by PSG is not appropriate for modeling
query structure, it might be helpful to take order-
ing information into account when resolving am-
biguity. We leave this for future work. Another
interesting and practically useful problem that we
have left for future work is to design an unsuper-
vised learning algorithm for CFSG similar to its
phrase structure counterpart: inside-outside algo-
rithm (Baker 1979). Having such a capability, we
are able to automatically learn the underlying
structure of queries by processing the huge
amount of available unlabeled queries.
</bodyText>
<sectionHeader confidence="0.983723" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.999973">
We need to thank Ye-Yi Wang for his helpful
advices. We also thank William de Beaumont for
his great comments on the paper.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999464461538462">
Allan, J. and Raghavan, H. (2002) Using Part-of-
speech Patterns to Reduce Query Ambiguity, Pro-
ceedings of SIGIR 2002, pp. 307-314.
Allen, J. F. (1995) Natural Language Understanding,
Benjamin Cummings.
Baker, J. K. (1979) Trainable grammars for speech
recognition. In Jared J. Wolf and Dennis H. Klatt,
editors, Speech communication papers presented at
the 97th Meeting of the Acoustical Society of
America, MIT, Cambridge, MA.
Barton, E. (1985) On the complexity of ID/LP rules,
Computational Linguistics, Volume 11, Pages 205-
218.
</reference>
<page confidence="0.981621">
868
</page>
<reference confidence="0.999861041666667">
Barr, C., Jones, R., Regelson, M., (2008) The Linguis-
tic Structure of English Web-Search Queries, In
Proceedings of EMNLP-08: conference on Empiri-
cal Methods in Natural Language Processing.
Broder, A., Fontoura, M., Gabrilovich, E., Joshi, A.,
Josifovski, V., and Zhang, T. (2007) Robust classi-
fication of rare queries using web knowledge. In
Proceedings of SIGIR’07
Collins, M., Koo, T., (2005) Discriminative Reranking
for Natural Language Parsing, Computational Lin-
guistics, v.31 p.25-70.
Gazdar, G., Klein, E., Sag, I., Pullum, G., (1985) Gen-
eralized Phrase Structure Grammar, Harvard Uni-
versity Press.
Grenager, T., Klein, D., and Manning, C. (2005) Un-
supervised learning of field segmentation models
for information extraction, In Proceedings of ACL-
05.
Kushmerick, N., Johnston, E., and McGuinness, S.
(2001). Information extraction by text classifica-
tion, In Proceedings of the IJCAI-01 Workshopon
Adaptive Text Extraction and Mining.
Li, X., Wang, Y., and Acero, A. (2008) Learning
query intent from regularized click graphs. In Pro-
ceedings of SIGIR’08
Manning, C., Schütze, H. (1999) Foundations of Sta-
tistical Natural Language Processing, The MIT
Press, Cambridge, MA.
McCallum, A., Freitag, D., Pereira, F. (2000) Maxi-
mum entropy markov models for information ex-
traction and segmentation, Proceedings of the
Seventeenth International Conference on Machine
Learning, Pages: 591 - 598
McCallum, A., Nigam, K., Rennie, J., and Seymore,
K. (1999) A machine learning approach to building
domain-specific search engines, In IJCAI-1999.
Pasca, M., Van Durme, B., and Garera, N. (2007) The
Role of Documents vs. Queries in Extracting Class
Attributes from Text, ACM Sixteenth Conference
on Information and Knowledge Management
(CIKM 2007). Lisboa, Portugal.
Viola, P., Narasimhan, M., Learning to extract infor-
mation from semi-structured text using a discrimi-
native context free grammar SIGIR 2005: 330-337.
Xue, GR, HJ Zeng, Z Chen, Y Yu, WY Ma, WS Xi,
WG Fan, (2004), Optimizing web search using web
click-through data, Proceedings of the thirteenth
ACM international conference.
</reference>
<page confidence="0.998922">
869
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.294762">
<title confidence="0.999643">Semantic Tagging of Web Search Queries</title>
<author confidence="0.999518">Mehdi Manshadi Xiao Li</author>
<affiliation confidence="0.946497">of Rochester Research</affiliation>
<address confidence="0.919854">Rochester, NY Redmond, WA</address>
<email confidence="0.999189">mehdih@cs.rochester.eduxiaol@microsoft.com</email>
<abstract confidence="0.949099315789474">We present a novel approach to parse web search queries for the purpose of automatic tagging of the queries. We will define a set of probabilistic context-free rules, which generates bags (i.e. multi-sets) of words. Using this new type of rule in combination with the traditional probabilistic phrase structure rules, we define a hybrid grammar, which treats each search query as a bag of chunks (i.e. phrases). A hybrid probabilistic parser is used to parse the queries. In order to take contextual information into account, a discriminative model is used on top of the parser to re-rank the n-best parse trees generated by the parser. Experiments show that our approach outperforms a basic model, which is based on Conditional Random Fields.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Allan</author>
<author>H Raghavan</author>
</authors>
<title>Using Part-ofspeech Patterns to Reduce Query Ambiguity,</title>
<date>2002</date>
<booktitle>Proceedings of SIGIR</booktitle>
<pages>307--314</pages>
<contexts>
<context position="2287" citStr="Allan and Raghavan (2002)" startWordPosition="362" endWordPosition="365">duct domain can be tagged as: cheap garmin streetpilot c340 gps || SortOrder Brand Model Model Type Many specialized search engines build their indexes directly from relational databases, which contain highly structured information. Given a query tagged with the semantic labels, a search engine is able to compare the values of semantic labels in the query (e.g., Brand = Ògarmin”) with its counterpart values in documents, thereby providing users with more relevant search results. Despite this importance, there has been relatively little published work on semantic tagging of web search queries. Allan and Raghavan (2002) and Barr et al. (2008) study the linguistic structure of queries by performing part-of-speech tagging. Pasca et al. (2007) use queries as a source of knowledge for extracting prominent attributes for semantic concepts. On the other hand, there has been much work on extracting structured information from larger text segments, such as addresses (Kushmerick 2001), bibliographic citations (McCallum et al. 1999), and classified advertisements (Grenager et al. 2005), among many others. The most widely used approaches to these problems have been sequential models including hidden Markov models (HMMs</context>
</contexts>
<marker>Allan, Raghavan, 2002</marker>
<rawString>Allan, J. and Raghavan, H. (2002) Using Part-ofspeech Patterns to Reduce Query Ambiguity, Proceedings of SIGIR 2002, pp. 307-314.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J F Allen</author>
</authors>
<title>Natural Language Understanding,</title>
<date>1995</date>
<location>Benjamin Cummings.</location>
<contexts>
<context position="15484" citStr="Allen 1995" startWordPosition="2701" endWordPosition="2702">ume that v1, v2, ...vk are the children of the node v in T. We define: (10) α(v) = P(Av— {Av1... Avk})α(v1) ... α(vk) with the initial conditions α(wi)=1. If u is the root of the tree T we have: (11) P(w1w2...wn , T) = α(u) The parse tree that the probabilistic model assigns to the sentence is defined as: (12) Tmax = argmaxT (P(w1w2...wn , T)) where T ranges over all possible parse trees of the sentence. 4 Parsing Algorithm 4.1 Deterministic parser The parsing algorithm for the CFSG is straightforward. We used a modified version of the Bottom-Up Chart Parser for the phrase structure grammars (Allen 1995, see 3.4). Given the grammar G=(N,T,S,R) and the query q=w1w2...wn, the algorithm in figure (4) is used to parse q. The algorithm is based on the concept of an active arc. An active arc is defined as a 3– 2 Every sentence of a language corresponds to a vector of |T| integers where the kth element represents how many times the kth terminal occurs in the multi-set. In fact, the languages defined by grammars are not interesting but the derivations are. 864 tuple (r, U, I) where r is a rule A → X in R, U is a subset of X, and I is a subset of {1, 2 ...n} (where n is the number of words in the que</context>
</contexts>
<marker>Allen, 1995</marker>
<rawString>Allen, J. F. (1995) Natural Language Understanding, Benjamin Cummings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J K Baker</author>
</authors>
<title>Trainable grammars for speech recognition.</title>
<date>1979</date>
<booktitle>Speech communication papers presented at the 97th Meeting of the Acoustical Society of America, MIT,</booktitle>
<editor>In Jared J. Wolf and Dennis H. Klatt, editors,</editor>
<location>Cambridge, MA.</location>
<marker>Baker, 1979</marker>
<rawString>Baker, J. K. (1979) Trainable grammars for speech recognition. In Jared J. Wolf and Dennis H. Klatt, editors, Speech communication papers presented at the 97th Meeting of the Acoustical Society of America, MIT, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Barton</author>
</authors>
<title>On the complexity of ID/LP rules,</title>
<date>1985</date>
<journal>Computational Linguistics, Volume</journal>
<volume>11</volume>
<pages>205--218</pages>
<contexts>
<context position="10366" citStr="Barton 1985" startWordPosition="1728" endWordPosition="1729">ictions on some of the constituents. For example in Russian an adjective always comes before the noun that it modifies. To cover these ordering restrictions, Gazdar defined Linear Precedence (LP) rules. (4) gives an example of a linear precedence rule: (4) ADJ &lt; N This specifies that ADJ always comes before N when both occur on the right-hand side of a single rule. Although very intuitive, ID/LP rules are not widely used in the area of natural language processing. The main reason is the timecomplexity issue of ID/LP grammar. It has been shown that parsing ID/LP rules is an NPcomplete problem (Barton 1985). Since the length of a natural language sentence can easily reach 30-40 (and sometimes even up to 100) words, ID/LP grammar is not a practical model for natural language syntax. In our case, however, the time-complexity is not a bottleneck as web search queries are usually very short (2.8 words per query in average). Moreover, the nature of ID rules can be deceptive as it might appear that ID rules allow any reordering of the words in a valid sentence to occur as another vaild sentence of the language. But in general this is not the case. For example consider a grammar with only two ID rules </context>
</contexts>
<marker>Barton, 1985</marker>
<rawString>Barton, E. (1985) On the complexity of ID/LP rules, Computational Linguistics, Volume 11, Pages 205-218.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Barr</author>
<author>R Jones</author>
<author>M Regelson</author>
</authors>
<title>The Linguistic Structure of English Web-Search Queries,</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP-08: conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="2310" citStr="Barr et al. (2008)" startWordPosition="367" endWordPosition="370">cheap garmin streetpilot c340 gps || SortOrder Brand Model Model Type Many specialized search engines build their indexes directly from relational databases, which contain highly structured information. Given a query tagged with the semantic labels, a search engine is able to compare the values of semantic labels in the query (e.g., Brand = Ògarmin”) with its counterpart values in documents, thereby providing users with more relevant search results. Despite this importance, there has been relatively little published work on semantic tagging of web search queries. Allan and Raghavan (2002) and Barr et al. (2008) study the linguistic structure of queries by performing part-of-speech tagging. Pasca et al. (2007) use queries as a source of knowledge for extracting prominent attributes for semantic concepts. On the other hand, there has been much work on extracting structured information from larger text segments, such as addresses (Kushmerick 2001), bibliographic citations (McCallum et al. 1999), and classified advertisements (Grenager et al. 2005), among many others. The most widely used approaches to these problems have been sequential models including hidden Markov models (HMMs), maximum entropy Mark</context>
<context position="4454" citStr="Barr et al. (2008)" startWordPosition="717" endWordPosition="720">or cheap garmin gps, it is possible that the query comes in any ordering of these three words. We are looking for a model that, once it observes this query, assumes that the other permutations of the words in this query are also likely. This model should also be able to handle cases where some local orderings have to be fixed as in the query buses from New York City to Boston, where the words in the phrases from New York city and to Boston have to come in the exact order. The third limitation is that the sequential models treat queries as unstructured (linear) sequences of words. The study by Barr et al. (2008) on Yahoo! query logs suggests that web search queries, to some degree, carry an underlying linguistic structure. As an example, consider a query about finding a local business near some location such as: seattle wa drugstore 24/7 98109 This query has two constituents: the Business that the user is looking for (24/7 drugstore) and the Neighborhood (seattle wa 98109). The model should not only be able to recognize the two constituents but it also needs to understand the structure of each constituent. Note that the arbitrary ordering of the words in the query is a big challenge to understanding </context>
</contexts>
<marker>Barr, Jones, Regelson, 2008</marker>
<rawString>Barr, C., Jones, R., Regelson, M., (2008) The Linguistic Structure of English Web-Search Queries, In Proceedings of EMNLP-08: conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Broder</author>
<author>M Fontoura</author>
<author>E Gabrilovich</author>
<author>A Joshi</author>
<author>V Josifovski</author>
<author>T Zhang</author>
</authors>
<title>Robust classification of rare queries using web knowledge.</title>
<date>2007</date>
<booktitle>In Proceedings of SIGIR’07</booktitle>
<contexts>
<context position="1292" citStr="Broder et al. 2007" startWordPosition="200" endWordPosition="203">ontextual information into account, a discriminative model is used on top of the parser to re-rank the n-best parse trees generated by the parser. Experiments show that our approach outperforms a basic model, which is based on Conditional Random Fields. 1 Introduction Understanding users’ intent from web search queries is an important step in designing an intelligent search engine. While it remains a challenge to have a scientific definition of &amp;quot;intent&amp;quot;, many efforts have been devoted to automatically mapping queries into different domains i.e. topical classes such as product, job and travel (Broder et al. 2007; Li et al. 2008). This work goes beyond query-level classification. We assume that the queries are already classified into the correct domain and investigate the problem of semantic tagging at the word level, which is to assign a label from a set of pre-defined semantic labels (specific to the domain) to every word in the query. For example, a search query in the product domain can be tagged as: cheap garmin streetpilot c340 gps || SortOrder Brand Model Model Type Many specialized search engines build their indexes directly from relational databases, which contain highly structured informatio</context>
</contexts>
<marker>Broder, Fontoura, Gabrilovich, Joshi, Josifovski, Zhang, 2007</marker>
<rawString>Broder, A., Fontoura, M., Gabrilovich, E., Joshi, A., Josifovski, V., and Zhang, T. (2007) Robust classification of rare queries using web knowledge. In Proceedings of SIGIR’07</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>T Koo</author>
</authors>
<title>Discriminative Reranking for Natural Language Parsing, Computational Linguistics,</title>
<date>2005</date>
<volume>31</volume>
<pages>25--70</pages>
<contexts>
<context position="26551" citStr="Collins and Koo 2005" startWordPosition="4680" endWordPosition="4683">umber of equal tags in the tree. To prevent this over-generation we used rules analogous to GPSG’s LP rules such as: B* &lt; B which allows only a unique way of generating a bag of the Brand tags. Using this LP rule, the only valid tree for the above query is the one in figure (7a). 6 Discriminative re-ranking By using a context-free grammar, we are missing a great source of clues that can help to resolve ambiguity. Discriminative models, on the other hand, allow us to define numerous features, which can cooperate to resolve the ambiguities. Similar studies in parsing natural language sentences (Collins and Koo 2005) have shown that if, instead of taking the most likely tree structure generated by a parser, the n-best parse trees are passed through a discriminative re-ranking module, the accuracy of the model will increase significantly. We use the same idea to improve the performance of our model. We run a Support Vector Machine (SVM) based re-ranking module on top of the parser. Several contextual features (such as bigrams) are defined to help in disambiguation. This combination provides a framework that benefits from the advantages of both generative and discriminative models. In particular, when there</context>
</contexts>
<marker>Collins, Koo, 2005</marker>
<rawString>Collins, M., Koo, T., (2005) Discriminative Reranking for Natural Language Parsing, Computational Linguistics, v.31 p.25-70.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Gazdar</author>
<author>E Klein</author>
<author>I Sag</author>
<author>G Pullum</author>
</authors>
<title>Generalized Phrase Structure Grammar,</title>
<date>1985</date>
<publisher>Harvard University Press.</publisher>
<marker>Gazdar, Klein, Sag, Pullum, 1985</marker>
<rawString>Gazdar, G., Klein, E., Sag, I., Pullum, G., (1985) Generalized Phrase Structure Grammar, Harvard University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Grenager</author>
<author>D Klein</author>
<author>C Manning</author>
</authors>
<title>Unsupervised learning of field segmentation models for information extraction,</title>
<date>2005</date>
<booktitle>In Proceedings of ACL05.</booktitle>
<contexts>
<context position="2752" citStr="Grenager et al. 2005" startWordPosition="430" endWordPosition="433">earch results. Despite this importance, there has been relatively little published work on semantic tagging of web search queries. Allan and Raghavan (2002) and Barr et al. (2008) study the linguistic structure of queries by performing part-of-speech tagging. Pasca et al. (2007) use queries as a source of knowledge for extracting prominent attributes for semantic concepts. On the other hand, there has been much work on extracting structured information from larger text segments, such as addresses (Kushmerick 2001), bibliographic citations (McCallum et al. 1999), and classified advertisements (Grenager et al. 2005), among many others. The most widely used approaches to these problems have been sequential models including hidden Markov models (HMMs), maximum entropy Markov models (MEMMs) (Mccallum 2000), and conditional random fields (CRFs) (Lafferty et al. 2001) These sequential models, however, are not optimal for processing web search queries for the following reasons.. The first problem is that the global constraints and long distance dependencies on state variables are difficult to capture using sequential models. Because of this limitation, Viola and Narasimhand (2007) use a discriminative context-</context>
</contexts>
<marker>Grenager, Klein, Manning, 2005</marker>
<rawString>Grenager, T., Klein, D., and Manning, C. (2005) Unsupervised learning of field segmentation models for information extraction, In Proceedings of ACL05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Kushmerick</author>
<author>E Johnston</author>
<author>S McGuinness</author>
</authors>
<title>Information extraction by text classification,</title>
<date>2001</date>
<booktitle>In Proceedings of the IJCAI-01 Workshopon Adaptive Text Extraction and Mining.</booktitle>
<marker>Kushmerick, Johnston, McGuinness, 2001</marker>
<rawString>Kushmerick, N., Johnston, E., and McGuinness, S. (2001). Information extraction by text classification, In Proceedings of the IJCAI-01 Workshopon Adaptive Text Extraction and Mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Li</author>
<author>Y Wang</author>
<author>A Acero</author>
</authors>
<title>Learning query intent from regularized click graphs.</title>
<date>2008</date>
<booktitle>In Proceedings of SIGIR’08</booktitle>
<contexts>
<context position="1309" citStr="Li et al. 2008" startWordPosition="204" endWordPosition="207">n into account, a discriminative model is used on top of the parser to re-rank the n-best parse trees generated by the parser. Experiments show that our approach outperforms a basic model, which is based on Conditional Random Fields. 1 Introduction Understanding users’ intent from web search queries is an important step in designing an intelligent search engine. While it remains a challenge to have a scientific definition of &amp;quot;intent&amp;quot;, many efforts have been devoted to automatically mapping queries into different domains i.e. topical classes such as product, job and travel (Broder et al. 2007; Li et al. 2008). This work goes beyond query-level classification. We assume that the queries are already classified into the correct domain and investigate the problem of semantic tagging at the word level, which is to assign a label from a set of pre-defined semantic labels (specific to the domain) to every word in the query. For example, a search query in the product domain can be tagged as: cheap garmin streetpilot c340 gps || SortOrder Brand Model Model Type Many specialized search engines build their indexes directly from relational databases, which contain highly structured information. Given a query </context>
</contexts>
<marker>Li, Wang, Acero, 2008</marker>
<rawString>Li, X., Wang, Y., and Acero, A. (2008) Learning query intent from regularized click graphs. In Proceedings of SIGIR’08</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Manning</author>
<author>H Schütze</author>
</authors>
<title>Foundations of Statistical Natural Language Processing,</title>
<date>1999</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="14597" citStr="Manning and Schütze 1999" startWordPosition="2535" endWordPosition="2538"> a multiset over NUT and S ==&gt;*X} The sequence of =&gt; used to derive X from S is called a derivation of X. Given the above 1 If X and Y are two multisets, X+Y simply means appending X to Y. For example {a, b, a} + {b, c, d} = {a, b, a, b, c, d}. Figure 3. A CFSG parse tree definitions, parsing a multiset X means to find all (if any) the derivations of X from S. 2 3.2 Probabilisic CFSG Very often a sentence in the language has more than one derivation, that is the sentence is syntactically ambiguous. One natural way of resolving the ambiguity is using a probabilistic grammar. Analogous to PCFG (Manning and Schütze 1999), we define the probabilistic version of a CFSG, in which every rule Ai—X&apos; has a probability P(Ai—X&apos;) and for every nonterminal Ai, we have: (9) E&apos; P(Ai— X&apos;) = 1 Consider a sentence w1w2...wn, a parse tree T of this sentence, and an interior node v in T labeled with Av and assume that v1, v2, ...vk are the children of the node v in T. We define: (10) α(v) = P(Av— {Av1... Avk})α(v1) ... α(vk) with the initial conditions α(wi)=1. If u is the root of the tree T we have: (11) P(w1w2...wn , T) = α(u) The parse tree that the probabilistic model assigns to the sentence is defined as: (12) Tmax = argm</context>
</contexts>
<marker>Manning, Schütze, 1999</marker>
<rawString>Manning, C., Schütze, H. (1999) Foundations of Statistical Natural Language Processing, The MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A McCallum</author>
<author>D Freitag</author>
<author>F Pereira</author>
</authors>
<title>Maximum entropy markov models for information extraction and segmentation,</title>
<date>2000</date>
<booktitle>Proceedings of the Seventeenth International Conference on Machine Learning,</booktitle>
<pages>591--598</pages>
<marker>McCallum, Freitag, Pereira, 2000</marker>
<rawString>McCallum, A., Freitag, D., Pereira, F. (2000) Maximum entropy markov models for information extraction and segmentation, Proceedings of the Seventeenth International Conference on Machine Learning, Pages: 591 - 598</rawString>
</citation>
<citation valid="true">
<authors>
<author>A McCallum</author>
<author>K Nigam</author>
<author>J Rennie</author>
<author>K Seymore</author>
</authors>
<title>A machine learning approach to building domain-specific search engines,</title>
<date>1999</date>
<booktitle>In IJCAI-1999.</booktitle>
<contexts>
<context position="2698" citStr="McCallum et al. 1999" startWordPosition="423" endWordPosition="426">ocuments, thereby providing users with more relevant search results. Despite this importance, there has been relatively little published work on semantic tagging of web search queries. Allan and Raghavan (2002) and Barr et al. (2008) study the linguistic structure of queries by performing part-of-speech tagging. Pasca et al. (2007) use queries as a source of knowledge for extracting prominent attributes for semantic concepts. On the other hand, there has been much work on extracting structured information from larger text segments, such as addresses (Kushmerick 2001), bibliographic citations (McCallum et al. 1999), and classified advertisements (Grenager et al. 2005), among many others. The most widely used approaches to these problems have been sequential models including hidden Markov models (HMMs), maximum entropy Markov models (MEMMs) (Mccallum 2000), and conditional random fields (CRFs) (Lafferty et al. 2001) These sequential models, however, are not optimal for processing web search queries for the following reasons.. The first problem is that the global constraints and long distance dependencies on state variables are difficult to capture using sequential models. Because of this limitation, Viol</context>
</contexts>
<marker>McCallum, Nigam, Rennie, Seymore, 1999</marker>
<rawString>McCallum, A., Nigam, K., Rennie, J., and Seymore, K. (1999) A machine learning approach to building domain-specific search engines, In IJCAI-1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pasca</author>
<author>B Van Durme</author>
<author>N Garera</author>
</authors>
<title>The Role of Documents vs.</title>
<date>2007</date>
<booktitle>Queries in Extracting Class Attributes from Text, ACM Sixteenth Conference on Information and Knowledge Management (CIKM</booktitle>
<location>Lisboa, Portugal.</location>
<marker>Pasca, Van Durme, Garera, 2007</marker>
<rawString>Pasca, M., Van Durme, B., and Garera, N. (2007) The Role of Documents vs. Queries in Extracting Class Attributes from Text, ACM Sixteenth Conference on Information and Knowledge Management (CIKM 2007). Lisboa, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Viola</author>
<author>M Narasimhan</author>
</authors>
<title>Learning to extract information from semi-structured text using a discriminative context free grammar SIGIR</title>
<date>2005</date>
<pages>330--337</pages>
<marker>Viola, Narasimhan, 2005</marker>
<rawString>Viola, P., Narasimhan, M., Learning to extract information from semi-structured text using a discriminative context free grammar SIGIR 2005: 330-337.</rawString>
</citation>
<citation valid="true">
<authors>
<author>GR Xue</author>
<author>HJ Zeng</author>
<author>Z Chen</author>
<author>Y Yu</author>
<author>WY Ma</author>
<author>WS Xi</author>
<author>WG Fan</author>
</authors>
<title>Optimizing web search using web click-through data,</title>
<date>2004</date>
<booktitle>Proceedings of the thirteenth ACM international conference.</booktitle>
<contexts>
<context position="6749" citStr="Xue et al., 2004" startWordPosition="1115" endWordPosition="1118">rammar in which every rule has a probability associated with it. Our grammar model eliminates the local dependency assumption made by sequential models and the ordering Figure 1. A simple grammar for product domain constraints imposed by phrase structure grammars (PSG). This model better reflects the underlying linguistic structure of web search queries. The model’s power, however, comes at the cost of increased time complexity, which is exponential in the length of the query. This, is less of an issue for parsing web search queries, as they are usually very short (2.8 words/query in average (Xue et al., 2004)). Yet another drawback of our approach is due to the context-free nature of the proposed grammar model. Contextual information often plays a big role in resolving tagging ambiguities and is one of the key benefits of discriminative models such as CRFs. But such information is not straightforward to incorporate in our grammar model. To overcome this limitation, we further present a discriminative re-ranking module on top of the parser to re-rank the n-best parse trees generated by the parser using contextual features. As seen later, in the case where there is not a large amount of labeled data</context>
</contexts>
<marker>Xue, Zeng, Chen, Yu, Ma, Xi, Fan, 2004</marker>
<rawString>Xue, GR, HJ Zeng, Z Chen, Y Yu, WY Ma, WS Xi, WG Fan, (2004), Optimizing web search using web click-through data, Proceedings of the thirteenth ACM international conference.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>