<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.006909">
<title confidence="0.996626">
Towards Unsupervised Recognition of Dialogue Acts
</title>
<author confidence="0.99827">
Nicole Novielli
</author>
<affiliation confidence="0.999809">
Dept. of Informatics, University of Bari
</affiliation>
<address confidence="0.928401">
via Orabona 4
I-70125 Bari, Italy
</address>
<email confidence="0.997396">
novielli@di.uniba.it
</email>
<author confidence="0.730843">
Carlo Strapparava
</author>
<affiliation confidence="0.516987">
FBK-irst
</affiliation>
<address confidence="0.5158795">
via Sommarive, Povo
I-38050 Trento, Italy
</address>
<email confidence="0.997819">
strappa@fbk.eu
</email>
<sectionHeader confidence="0.995617" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9988909375">
When engaged in dialogues, people per-
form communicative actions to pursue specific
communicative goals. Speech acts recogni-
tion attracted computational linguistics since
long time and could impact considerably a
huge variety of application domains. We study
the task of automatic labeling dialogues with
the proper dialogue acts, relying on empiri-
cal methods and simply exploiting lexical se-
mantics of the utterances. In particular, we
present some experiments in supervised and
unsupervised framework on both an English
and an Italian corpus of dialogue transcrip-
tions. The evaluation displays encouraging re-
sults in both languages, especially in the unsu-
pervised version of the methodology.
</bodyText>
<sectionHeader confidence="0.998986" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999891625">
People proceed in their conversations through a se-
quence of dialogue acts to yield some specific com-
municative goal. They can ask for information,
agree or disagree with their partner, state some facts
and express opinions.
Dialogue Acts (DA) attracted linguistics (Austin,
1962; Searle, 1969) and computational linguistics
research (Core and Allen, 1997; Traum, 2000) since
long time. With the advent of the Web, a large
amount of material about natural language inter-
actions (e.g. blogs, chats, conversation transcripts)
has become available, raising the attractiveness of
empirical methods analyses on this field. There is
a large number of application domains that could
benefit from automatically labeling DAs: e.g. con-
versational agents for monitoring and supporting
</bodyText>
<page confidence="0.973397">
84
</page>
<bodyText confidence="0.999961575757576">
human-human remote conversations, blogs, forums
and chat logs analysis for opinion mining, interper-
sonal stances modeling by mean of conversational
analysis, automatic meeting summarizations and so
on. These applications require a deep understanding
of the conversational structure and the ability of the
system to understand who is telling what to whom.
This study defines a method for automatically la-
beling dialogues with the proper speech acts by re-
lying on empirical methods. Even if prosody and
intonation surely play a role (e.g. (Stolcke et al.,
2000; Warnke et al., 1997)), nonetheless language
and words are what the speaker uses to convey the
communicative message and are just what we have
at disposal when we consider texts found on the
Web. Hence, we decided to simply exploit lexical
semantics of the sentences. We performed some ex-
periments in a supervised and unsupervised frame-
work on both an English and an Italian corpora of
dialogue transcriptions, achieving good results in all
settings. Unsupervised performance is particularly
encouraging, independently from the used language.
The paper is organized as follows. Section 2 gives
a brief sketch of the NLP background on Dialogue
Acts recognition. In Section 3 we introduce the En-
glish and Italian corpora of dialogues, their charac-
teristics and DA labeling. In Section 4 we describe
the preprocessing of the data sets. Then Section 5
explains the supervised and unsupervised settings,
showing the experimental results obtained on the
two corpora and providing an error analysis. Finally,
in Section 6 we conclude the paper with a brief dis-
cussion and some directions for future work.
</bodyText>
<note confidence="0.8473885">
Proceedings of the NAACL HLT Student Research Workshop and Doctoral Consortium, pages 84–89,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<figure confidence="0.948159222222222">
Speaker Dialogue Act Utterance
A OPENING Hello Ann.
B OPENING Hello Chuck.
A STATEMENT Uh, the other day, I attended a conference here at Utah State University on recycling
A STATEMENT and, uh, I was kind of interested to hear cause they had some people from the EPA and
lots of different places, and, uh, there is going to be a real problem on solid waste.
B OPINION Uh, I didn’t think that was a new revelation.
A AGREE /ACCEPT Well, it’s not too new.
B INFO-REQUEST So what is the EPA recommending now?
</figure>
<tableCaption confidence="0.999038">
Table 1: An excerpt from the Switchboard corpus
</tableCaption>
<sectionHeader confidence="0.963633" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.999978">
A DA can be identified with the communicative goal
of a given utterance (Austin, 1962). Researchers use
different labels and definitions to address this con-
cept: speech act (Searle, 1969), adjacency pair part
(Schegloff, 1968) (Sacks et al., 1974), game move
(Power, 1979)
Traditionally, the NLP community has employed
DA definitions with the drawback of being do-
main or application oriented. Recently some efforts
have been made towards unifying the DA annotation
(Traum, 2000). In the present study we refer to a
domain-independent framework for DA annotation,
the DAMSL architecture (Dialogue Act Markup in
Several Layers) by (Core and Allen, 1997).
Recently, the problem of DA recognition has
been addressed with promising results: Poesio and
Mikheev (1998) combine expectations about the
next likely dialogue ‘move’ with information de-
rived from the speech signal features; Stolcke et
al. (2000) employ a discourse grammar, formal-
ized in terms of Hidden Markov Models, combining
also evidences about lexicon and prosody; Keizer et
al. (2002) make use of Bayesian networks for DA
recognition in dutch dialogues; Grau et al. (2004)
consider naive Bayes classifiers as a suitable ap-
proach to the DA classification problem; a partially
supervised framework has also been explored by
Venkataraman et al. (2005)
Regardless of the model they use (discourse
grammars, models based on word sequences or on
the acoustic features or a combination of all these)
the mentioned studies are developed in a supervised
framework. In this paper, one goal is to explore also
the use of a fully unsupervised methodology.
</bodyText>
<sectionHeader confidence="0.981084" genericHeader="method">
3 Data Sets
</sectionHeader>
<bodyText confidence="0.999957357142857">
In the experiments of the present paper we exploit
two corpora, both annotated with DAs labels. We
aim at developing a recognition methodology as
general as possible, so we selected corpora which
are different in content and language: the Switch-
board corpus (Godfrey et al., 1992), a collection
of transcriptions of spoken English telephone con-
versations about general interest topics, and an Ital-
ian corpus of dialogues in the healthy-eating domain
(Clarizio et al., 2006).
In this section we describe the two corpora, their
features, the set of labels used for annotating the di-
alogue acts with their distributions and the data pre-
processing.
</bodyText>
<subsectionHeader confidence="0.994542">
3.1 Description
</subsectionHeader>
<bodyText confidence="0.999804705882353">
The Switchboard corpus is a collection of English
human-human telephone conversations (Godfrey et
al., 1992) between couples of randomly selected
strangers. They were asked to choose one general
interest topic and to talk informally about it. Full
transcripts of these dialogues are distributed by the
Linguistic Data Consortium. A part of this cor-
pus is annotated (Jurafsky et al., 1997) with DA
labels (overall 1155 conversations, for a total of
205,000 utterances and 1.4 million words)1. Table
1 shows a short sample fragments of dialogues from
the Switchboard corpus.
The Italian corpus had been collected in the scope
of some previous research about Human-ECA inter-
action. A Wizard of Oz tool was employed (Clarizio
et al., 2006) and during the interaction, a conver-
sational agent (i.e. the ‘wizard’) played the role of
</bodyText>
<footnote confidence="0.8179535">
1ftp.ldc.upenn.edu/pub/ldc/public\_data/
swb1\_dialogact\_annot.tar.gz
</footnote>
<page confidence="0.997006">
85
</page>
<table confidence="0.999281333333334">
Label Description Example Italian English
INFO-REQUEST Utterances that are pragmatically, semantically, ‘What did you do when your kids 34% 7%
and syntactically questions were growing up?’
STATEMENT Descriptive, narrative, personal statements ‘I usually eat a lot offruit’ 37% 57%
S-OPINION Directed opinion statements ‘I think he deserves it.’ 6% 20%
AGREE-ACCEPT Acceptance of a proposal, plan or opinion ‘That’s right’ 5% 9%
REJECT Disagreement with a proposal, plan, or opinion ‘I’m sorry no’ 7% .3%
OPENING Dialogue opening or self-introduction ‘Hello, my name is Imma’ 2% .2%
CLOSING Dialogue closing (e.g. farewell and wishes) ‘It’s been nice talking to you.’ 2% 2%
KIND-ATT Kind attitude (e.g. thanking and apology) ‘Thank you very much.’ 9% .1%
GEN-ANS Generic answers to an Info-Request ‘Yes’, ‘No’, ‘I don’t know’ 4% 4%
total cases 1448 131,265
</table>
<tableCaption confidence="0.999903">
Table 2: The set of labels employed for Dialogue Acts annotation and their distribution in the two corpora
</tableCaption>
<bodyText confidence="0.9997862">
an artificial therapist. The users were free to inter-
act with it in natural language, without any partic-
ular constraint. This corpus is about healthy eating
and contains (overall 60 dialogues, 1448 users’ ut-
terances and 15,500 words).
</bodyText>
<subsectionHeader confidence="0.999256">
3.2 Labelling
</subsectionHeader>
<bodyText confidence="0.999956571428572">
Both corpora are annotated following the Dialogue
Act Markup in Several Layers (DAMSL) annotation
scheme (Core and Allen, 1997). In particular the
Switchboard corpus employs a revision (Jurafsky et
al., 1997).2
Table 2 shows the set of labels employed with
their definitions, examples and distributions in the
two data sets. The categories maintain the DAMSL
main characteristic of being domain-independent
and can be easily mapped back into SWBD-DAMSL
ones, and maintain their original semantics. Thus,
the original SWBD-DAMSL annotation had been
automatically converted into the categories included
in our markup language.3
</bodyText>
<sectionHeader confidence="0.948149" genericHeader="method">
4 Data preprocessing
</sectionHeader>
<bodyText confidence="0.999942833333333">
To reduce the data sparseness, we used a POS-tagger
and morphological analyzer (Pianta et al., 2008) for
preprocessing both corpora. So we considered lem-
mata instead of tokens in the format lemma#POS. In
addition, we augment the features of each sentence
with a set of linguistic markers, defined according to
</bodyText>
<footnote confidence="0.996235">
2The SWBD-DAMSL modifies the original DAMSL frame-
work by further specifying some categories or by adding extra
features (mainly prosodic) which were not originally included
in the scheme.
3Also we did not consider the utterances formed only by
non-verbal material (e.g. laughter).
</footnote>
<bodyText confidence="0.997132714285714">
the semantic of the DA categories. We hypothesize,
in fact, these features could play an important role
in defining the linguistic profile of each DA. The ad-
dition of these markers is performed automatically,
by just exploiting the output of the POS-tagger and
of the morphological analyzer, according to the fol-
lowing rules:
</bodyText>
<listItem confidence="0.995963086956522">
• WH-QTN, used whenever an interrogative de-
terminer (e.g. ‘what’) is found, according to the
output of the POS-tagger;
• ASK-IF, used whenever an utterance presents
the pattern of a ‘Yes/No’ question. ASK-IF and
WH-QTN markers are supposed to be relevant
for the INFO-REQUEST category;
• I-PERS, used for all declarative utterances
whenever a verb is in the first person form, sin-
gular or plural (relevant for the STATEMENT);
• COND, used for conditional form is detected.
• SUPER, used for superlative adjectives.
• AGR-EX, used whenever an agreement ex-
pression (e.g.‘You’re right’, ‘I agree’) is de-
tected (relevant for AGREE-ACCEPT);
• NAME, used whenever a proper name follows
a self-introduction expression (e.g. ‘My name
is’) (relevant for the OPENING);
• OR-CLAUSE, used for or-clauses, that is ut-
terance starting by ‘or’ (should be helpful for
the characterization of the INFO-REQUEST);
• VB, used only for the Italian, when a dialectal
form of agreement expression is detected.
</listItem>
<sectionHeader confidence="0.975703" genericHeader="method">
5 Dialogue Acts Recognition
</sectionHeader>
<bodyText confidence="0.995727">
We conducted some experiments both in a super-
vised and unsupervised settings.
</bodyText>
<page confidence="0.984253">
86
</page>
<subsectionHeader confidence="0.830377">
5.1 Supervised
</subsectionHeader>
<bodyText confidence="0.99998225">
Regarding the supervised experiments, we used
Support Vector Machines (Vapnik, 1995), in partic-
ular SVM-light package (Joachims, 1998) under its
default configuration. We randomly split the two
corpora into 80/20 training/test partitions. SVMs
have been used in a large range of problems, in-
cluding text classification, image recognition tasks,
bioinformatics and medical applications, and they
are regarded as the state-of-the-art in supervised
learning. We got .71 and .77 of F1 measures respec-
tively for the Italian and English corpus. Table 4
reports the performance for each direct act.
</bodyText>
<subsectionHeader confidence="0.969728">
5.2 Unsupervised
</subsectionHeader>
<bodyText confidence="0.998326577777778">
It is not always easy to collect large training, partly
because of manual labeling effort and moreover be-
cause often it is not possible to find it.
Schematically, our unsupervised methodology is:
(i) building a semantic similarity space in which
words, set of words, text fragments can be repre-
sented homogeneously, (ii) finding seeds that prop-
erly represent dialogue acts and considering their
representations in the similarity space, and (iii)
checking the similarity of the utterances.
To get a similarity space with the required charac-
teristics, we used Latent Semantic Analysis (LSA),
a corpus-based measure of semantic similarity pro-
posed by Landauer (Landauer et al., 1998). In LSA,
term co-occurrences in a corpus are captured by
means of a dimensionality reduction operated by a
singular value decomposition (SVD) on the term-by-
document matrix T representing the corpus.
SVD decomposes the term-by-document matrix
T into three matrices T = UEkVT where Ek is
the diagonal k x k matrix containing the k singu-
lar values of T, Q1 &gt; Q2 &gt; ... &gt; Qk, and U
and V are column-orthogonal matrices. When the
three matrices are multiplied together the original
term-by-document matrix is re-composed. Typically
we can choose k&apos; « k obtaining the approximation
T ^_ UEk&apos;VT.
LSA can be viewed as a way to overcome some
of the drawbacks of the standard vector space model
(sparseness and high dimensionality). In fact, the
LSA similarity is computed in a lower dimensional
space, in which second-order relations among terms
and texts are exploited. The similarity in the result-
ing vector space is then measured with the standard
cosine similarity. Note also that LSA yields a vec-
tor space model that allows for a homogeneous rep-
resentation (and hence comparison) of words, sen-
tences, and texts. For representing a word set or
a sentence in the LSA space we use the pseudo-
document representation technique, as described by
Berry (1992). In practice, each text segment is repre-
sented in the LSA space by summing up the normal-
ized LSA vectors of all the constituent words, using
also a tf.idf weighting scheme (Gliozzo and Strappa-
rava, 2005).
</bodyText>
<subsectionHeader confidence="0.659782">
Seeds
</subsectionHeader>
<bodyText confidence="0.870050142857143">
WH-QTN, Question Mark, ASK-IF, huh
I-PERS, I
Verbs which directly express opinion or
evaluation (guess, think, suppose, affect)
AGR-EX, yep, yeah, absolutely, correct
Verbs which directly express disagreement
(disagree, refute)
</bodyText>
<figureCaption confidence="0.730064888888889">
Greetings (hi, hello), words and markers re-
lated to self-introduction (name, NAME)
Interjections/exclamations ending dis-
course (alright, okeydoke), Expressions
of thanking (thank) and farewell (bye,
bye-bye, goodnight, goodbye)
Wishes (wish), apologies (apologize),
thanking (thank) and sorry-for (sorry,
excuse)
</figureCaption>
<table confidence="0.265957">
no, yes, uh-huh, nope
</table>
<tableCaption confidence="0.996927">
Table 3: The seeds for the unsupervised experiment
</tableCaption>
<bodyText confidence="0.9999293125">
The methodology is completely unsupervised.
We run the LSA using 400 dimensions (i.e. k&apos;, as
suggested by (Landauer et al., 1998)) respectively
on the English and Italian corpus, without any DA
label information. Starting from a set of seeds
(words) representing the communicative acts (see
the complete sets in Table 3), we build the corre-
sponding vectors in the LSA space and then we com-
pare the utterances to find the communicative act
with higher similarity. To compare with SVM, the
performance is measured on the same test set parti-
tion used in the supervised experiment (Table 4).
We defined seeds by only considering the commu-
nicative goal and the specific semantic of every sin-
gle DA, just avoiding as much as possible the over-
lapping between seeds groups. We wanted to design
</bodyText>
<figure confidence="0.9975556">
Label
INFO-REQ
STATEMENT
S-OPINION
AGREE-ACC
REJECT
OPENING
CLOSING
KIND-ATT
GEN-ANS
</figure>
<page confidence="0.994327">
87
</page>
<table confidence="0.999457583333333">
SVM Italian LSA SVM English LSA
Label prec rec f1 prec rec f1 prec rec f1 prec rec f1
INFO-REQ .92 .99 .95 .96 .88 .92 .92 .84 .88 .93 .70 .80
STATEMENT .85 .68 .69 .76 .66 .71 .79 .92 .85 .70 .95 .81
S-OPINION .28 .42 .33 .24 .42 .30 .66 .44 .53 .41 .07 .12
AGREE-ACC .50 .80 .62 .56 .50 .53 .69 .74 .71 .68 .63 .65
REJECT - - - .09 .25 .13 - - - .01 .01 .01
OPENING .60 1.00 .75 .55 1.00 .71 .96 .55 .70 .20 .43 .27
CLOSING .67 .40 .50 .25 .40 .31 .83 .59 .69 .76 .34 .47
KIND-ATT .82 .53 .64 .43 .18 .25 .85 .34 .49 .09 .47 .15
GEN-ANS .20 .63 .30 .27 .38 .32 .56 .25 .35 .54 .33 .41
micro .71 .71 .71 .66 .66 .66 .77 .77 .77 .69 .69 .69
</table>
<tableCaption confidence="0.99993">
Table 4: Evaluation of the two methods on both corpora
</tableCaption>
<bodyText confidence="0.99998025">
an approach which is as general as possible, so we
did not consider domain words. The seeds are the
same for both languages, which is coherent with our
goal of defining a language-independent method.
</bodyText>
<subsectionHeader confidence="0.99958">
5.3 Experimental Results and Discussion
</subsectionHeader>
<bodyText confidence="0.999990551020408">
We evaluate the performance of our method in terms
of precision, recall and f1-measure (see Table 4) ac-
cording to the DA labels given by annotators in the
datasets. As baselines we consider (i) most-frequent
label assignment (respectively 37% for Italian, 57%
for English) for the supervised setting, and (ii) ran-
dom DA selection (11%) for the unsupervised one.
Results are quite satisfying (Table 4). In particu-
lar, the unsupervised technique is largely above the
baselines, for both the Italian and the English exper-
iments. The methodology is independent from the
language and the domain: the Italian corpus is a col-
lection of dialogue about a very restricted domain
while the Switchboard conversations are essentially
task-free. Moreover, in the unsupervised setting we
use in practice the same seed definitions. Secondly,
it is independent on the differences in the linguis-
tic style due to the specific interaction scenario and
input modality. Finally, the performance is not af-
fected by the difference in size of the two data sets.
Error analysis. After conducting an error analy-
sis, we noted that many utterances are misclassi-
fied as STATEMENT. One possible reason is that
statements usually are quite long and there is a high
chance that some linguistic markers that character-
ize other dialogue acts are present in those sen-
tences. On the other hand, looking at the corpora we
observed that many utterances which appear to be
linguistically consistent with the typical structure of
statements have been annotated differently, accord-
ing to the actual communicative role they play. For
similar reasons, we observed some misclassifica-
tion of S-OPINION as STATEMENT. The only sig-
nificative difference between the two labels seems
to be the wider usage of ‘slanted’ and affectively
loaded lexicon when conveying an opinion. Another
cause of confounding is the confusion among the
backchannel labels (GEN-ANS, AGREE-ACC and
REJECT) due to the inherent ambiguity of common
words like yes, no, yeah, ok.
Recognition of such cases could be improved (i)
by enabling the classifiers to consider not only the
lexical semantics of the given utterance (local con-
text) but also the knowledge about a wider context
window (e.g. the previous n utterances), (ii) by en-
riching the data preprocessing (e.g. by exploiting in-
formation about lexicon polarity and subjectivity pa-
rameters). We intend to follow both these directions
in our future research.
</bodyText>
<sectionHeader confidence="0.998619" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999877111111111">
This study aims at defining a method for Dialogue
Acts recognition by simply exploiting the lexical se-
mantics of dialogue turns. The technique had to
be independent from some important features of the
corpus being used such as domain, language, size,
interaction scenario. In a long-term perspective, we
will employ the technique in conversational analysis
for user attitude classification (Martalo et al., 2008).
The methodology starts with automatically en-
</bodyText>
<page confidence="0.996114">
88
</page>
<bodyText confidence="0.99988285">
riching the corpus with additional features, such as
linguistic markers. Then the unsupervised case con-
sists of defining a very simple and intuitive set of
seeds that profiles the specific dialogue acts, and
subsequently performing a similarity analysis in a
latent semantic space. The performance of the unsu-
pervised experiment has been compared with a su-
pervised state-of-art technique such as Support Vec-
tor Machines, and the results are quite encouraging.
Regarding future developments, we will investi-
gate how to include in the framework a wider con-
text (e.g. the previous n utterances), and the intro-
duction of new linguistic markers by enriching the
preprocessing techniques. In particular, it would be
interesting to exploit the role of slanted or affective-
loaded lexicon to deal with the misclassification of
opinions as statements. Along this perspective, DA
recognition could serve also as a basis for conver-
sational analysis aimed at improving a fine-grained
opinion mining in dialogues.
</bodyText>
<sectionHeader confidence="0.998159" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999906086419754">
J. Austin. 1962. How to do Things with Words. Oxford
University Press, New York.
M. Berry. 1992. Large-scale sparse singular value com-
putations. International Journal of Supercomputer
Applications, 6(1).
G. Clarizio, I. Mazzotta, N. Novielli, and F. deRosis.
2006. Social attitude towards a conversational char-
acter. In Proceedings of the 15th IEEE International
Symposium on Robot and Human Interactive Commu-
nication, pages 2–7, Hatfield, UK, September.
M. Core and J. Allen. 1997. Coding dialogs with the
DAMSL annotation scheme. In Working Notes of the
AAAI Fall Symposium on Communicative Action in
Humans and Machines, Cambridge, MA.
A. Gliozzo and C. Strapparava. 2005. Domains kernels
for text categorization. In Proceedengs of (CoNLL-
2005), University of Michigan, Ann Arbor, June.
J. Godfrey, E. Holliman, and J. McDaniel. 1992.
SWITCHBOARD: Telephone speech corpus for re-
search and development. In Proceedings of ICASSP-
92, pages 517–520, San Francisco, CA. IEEE.
S. Grau, E. Sanchis, M. J. Castro, and D. Vilar. 2004. Di-
alogue act classification using a bayesian approach. In
Proceedings of SPECOM-04, pages 495–499, Saint-
Petersburg, Russia, September.
T. Joachims. 1998. Text categorization with Support
Vector Machines: learning with many relevant fea-
tures. In Proceedings of the European Conference on
Machine Learning.
D. Jurafsky, E. Shriberg, and D. Biasca. 1997. Switch-
board SWBD-DAMSL shallow-discourse-function an-
notation coders manual, draft 13. Technical Report
97-01, University of Colorado.
S. Keizer, R. op den Akker, and A. Nijholt. 2002. Dia-
logue act recognition with bayesian networks for dutch
dialogues. In K. Jokinen and S. McRoy, editors, Pro-
ceedings 3rd SIGdial Workshop on Discourse and Di-
alogue, pages 88–94, Philadelphia, PA, July.
T. K. Landauer, P. Foltz, and D. Laham. 1998. Introduc-
tion to latent semantic analysis. Discourse Processes,
25.
A. Martalo, N. Novielli, and F. deRosis. 2008. Attitude
display in dialogue patterns. In AISB 2008 Conven-
tion on Communication, Interaction and Social Intel-
ligence, Aberdeen, Scotland, April.
E. Pianta, C. Girardi, and R. Zanoli. 2008. The TextPro
tool suite. In Proceedings of LREC, Marrakech (Mo-
rocco), May.
M. Poesio and A. Mikheev. 1998. The predictive power
of game structure in dialogue act recognition: Experi-
mental results using maximum entropy estimation. In
Proceedings ofICSLP-98, Sydney, December.
R. Power. 1979. The organisation of purposeful dia-
logues. Linguistics, 17:107–152.
H. Sacks, E. Schegloff, and G. Jefferson. 1974. A sim-
plest systematics for the organization of turn-taking for
conversation. Language, 50(4):696–735.
E. Schegloff. 1968. Sequencing in conversational open-
ings. American Anthropologist, 70:1075–1095.
J. Searle. 1969. Speech Acts: An Essay in the Philoso-
phy of Language. Cambridge University Press, Cam-
bridge, London.
A. Stolcke, N. Coccaro, R. Bates, P. Taylor, C. Van Ess-
Dykema, K. Ries, E. Shriberg, D. Jurafsky, R. Mar-
tin, and M. Meteer. 2000. Dialogue act modeling for
automatic tagging and recognition of conversational
speech. Computational Linguistics, 26(3):339–373.
D. Traum. 2000. 20 questions for dialogue act tax-
onomies. Journal of Semantics, 17(1):7–30.
V. Vapnik. 1995. The Nature of Statistical Learning The-
ory. Springer-Verlag.
A. Venkataraman, Y. Liu, E. Shriberg, and A. Stol-
cke. 2005. Does active learning help automatic dia-
log act tagging in meeting data? In Proceedings of
EUROSPEECH-05, Lisbon, Portugal.
V. Warnke, R. Kompe, H. Niemann, and E. N¨oth. 1997.
Integrated dialog act segmentation and classification
using prosodic features and language models. In Pro-
ceedings of 5th European Conference on Speech Com-
munication and Technology, volume 1, pages 207–
210, Rhodes, Greece.
</reference>
<page confidence="0.999753">
89
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.185664">
<title confidence="0.998947">Towards Unsupervised Recognition of Dialogue Acts</title>
<author confidence="0.989739">Nicole</author>
<affiliation confidence="0.887916">Dept. of Informatics, University of via Orabona</affiliation>
<address confidence="0.903452">I-70125 Bari,</address>
<email confidence="0.996511">novielli@di.uniba.it</email>
<author confidence="0.998661">Carlo Strapparava</author>
<email confidence="0.866786">FBK-irst</email>
<author confidence="0.300639">via Sommarive</author>
<author confidence="0.300639">Povo</author>
<address confidence="0.980554">I-38050 Trento, Italy</address>
<email confidence="0.997645">strappa@fbk.eu</email>
<abstract confidence="0.997100411764706">When engaged in dialogues, people perform communicative actions to pursue specific communicative goals. Speech acts recognition attracted computational linguistics since long time and could impact considerably a huge variety of application domains. We study the task of automatic labeling dialogues with the proper dialogue acts, relying on empirical methods and simply exploiting lexical semantics of the utterances. In particular, we present some experiments in supervised and unsupervised framework on both an English and an Italian corpus of dialogue transcriptions. The evaluation displays encouraging results in both languages, especially in the unsupervised version of the methodology.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Austin</author>
</authors>
<title>How to do Things with Words.</title>
<date>1962</date>
<publisher>Oxford University Press,</publisher>
<location>New York.</location>
<contexts>
<context position="1241" citStr="Austin, 1962" startWordPosition="177" endWordPosition="178">oiting lexical semantics of the utterances. In particular, we present some experiments in supervised and unsupervised framework on both an English and an Italian corpus of dialogue transcriptions. The evaluation displays encouraging results in both languages, especially in the unsupervised version of the methodology. 1 Introduction People proceed in their conversations through a sequence of dialogue acts to yield some specific communicative goal. They can ask for information, agree or disagree with their partner, state some facts and express opinions. Dialogue Acts (DA) attracted linguistics (Austin, 1962; Searle, 1969) and computational linguistics research (Core and Allen, 1997; Traum, 2000) since long time. With the advent of the Web, a large amount of material about natural language interactions (e.g. blogs, chats, conversation transcripts) has become available, raising the attractiveness of empirical methods analyses on this field. There is a large number of application domains that could benefit from automatically labeling DAs: e.g. conversational agents for monitoring and supporting 84 human-human remote conversations, blogs, forums and chat logs analysis for opinion mining, interperson</context>
<context position="4221" citStr="Austin, 1962" startWordPosition="653" endWordPosition="654"> Hello Ann. B OPENING Hello Chuck. A STATEMENT Uh, the other day, I attended a conference here at Utah State University on recycling A STATEMENT and, uh, I was kind of interested to hear cause they had some people from the EPA and lots of different places, and, uh, there is going to be a real problem on solid waste. B OPINION Uh, I didn’t think that was a new revelation. A AGREE /ACCEPT Well, it’s not too new. B INFO-REQUEST So what is the EPA recommending now? Table 1: An excerpt from the Switchboard corpus 2 Background A DA can be identified with the communicative goal of a given utterance (Austin, 1962). Researchers use different labels and definitions to address this concept: speech act (Searle, 1969), adjacency pair part (Schegloff, 1968) (Sacks et al., 1974), game move (Power, 1979) Traditionally, the NLP community has employed DA definitions with the drawback of being domain or application oriented. Recently some efforts have been made towards unifying the DA annotation (Traum, 2000). In the present study we refer to a domain-independent framework for DA annotation, the DAMSL architecture (Dialogue Act Markup in Several Layers) by (Core and Allen, 1997). Recently, the problem of DA recog</context>
</contexts>
<marker>Austin, 1962</marker>
<rawString>J. Austin. 1962. How to do Things with Words. Oxford University Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Berry</author>
</authors>
<title>Large-scale sparse singular value computations.</title>
<date>1992</date>
<journal>International Journal of Supercomputer Applications,</journal>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="13736" citStr="Berry (1992)" startWordPosition="2146" endWordPosition="2147"> the drawbacks of the standard vector space model (sparseness and high dimensionality). In fact, the LSA similarity is computed in a lower dimensional space, in which second-order relations among terms and texts are exploited. The similarity in the resulting vector space is then measured with the standard cosine similarity. Note also that LSA yields a vector space model that allows for a homogeneous representation (and hence comparison) of words, sentences, and texts. For representing a word set or a sentence in the LSA space we use the pseudodocument representation technique, as described by Berry (1992). In practice, each text segment is represented in the LSA space by summing up the normalized LSA vectors of all the constituent words, using also a tf.idf weighting scheme (Gliozzo and Strapparava, 2005). Seeds WH-QTN, Question Mark, ASK-IF, huh I-PERS, I Verbs which directly express opinion or evaluation (guess, think, suppose, affect) AGR-EX, yep, yeah, absolutely, correct Verbs which directly express disagreement (disagree, refute) Greetings (hi, hello), words and markers related to self-introduction (name, NAME) Interjections/exclamations ending discourse (alright, okeydoke), Expressions </context>
</contexts>
<marker>Berry, 1992</marker>
<rawString>M. Berry. 1992. Large-scale sparse singular value computations. International Journal of Supercomputer Applications, 6(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Clarizio</author>
<author>I Mazzotta</author>
<author>N Novielli</author>
<author>F deRosis</author>
</authors>
<title>Social attitude towards a conversational character.</title>
<date>2006</date>
<booktitle>In Proceedings of the 15th IEEE International Symposium on Robot and Human Interactive Communication,</booktitle>
<pages>2--7</pages>
<location>Hatfield, UK,</location>
<contexts>
<context position="6226" citStr="Clarizio et al., 2006" startWordPosition="966" endWordPosition="969">studies are developed in a supervised framework. In this paper, one goal is to explore also the use of a fully unsupervised methodology. 3 Data Sets In the experiments of the present paper we exploit two corpora, both annotated with DAs labels. We aim at developing a recognition methodology as general as possible, so we selected corpora which are different in content and language: the Switchboard corpus (Godfrey et al., 1992), a collection of transcriptions of spoken English telephone conversations about general interest topics, and an Italian corpus of dialogues in the healthy-eating domain (Clarizio et al., 2006). In this section we describe the two corpora, their features, the set of labels used for annotating the dialogue acts with their distributions and the data preprocessing. 3.1 Description The Switchboard corpus is a collection of English human-human telephone conversations (Godfrey et al., 1992) between couples of randomly selected strangers. They were asked to choose one general interest topic and to talk informally about it. Full transcripts of these dialogues are distributed by the Linguistic Data Consortium. A part of this corpus is annotated (Jurafsky et al., 1997) with DA labels (overall</context>
</contexts>
<marker>Clarizio, Mazzotta, Novielli, deRosis, 2006</marker>
<rawString>G. Clarizio, I. Mazzotta, N. Novielli, and F. deRosis. 2006. Social attitude towards a conversational character. In Proceedings of the 15th IEEE International Symposium on Robot and Human Interactive Communication, pages 2–7, Hatfield, UK, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Core</author>
<author>J Allen</author>
</authors>
<title>Coding dialogs with the DAMSL annotation scheme.</title>
<date>1997</date>
<booktitle>In Working Notes of the AAAI Fall Symposium on Communicative Action in Humans and Machines,</booktitle>
<location>Cambridge, MA.</location>
<contexts>
<context position="1317" citStr="Core and Allen, 1997" startWordPosition="185" endWordPosition="188">t some experiments in supervised and unsupervised framework on both an English and an Italian corpus of dialogue transcriptions. The evaluation displays encouraging results in both languages, especially in the unsupervised version of the methodology. 1 Introduction People proceed in their conversations through a sequence of dialogue acts to yield some specific communicative goal. They can ask for information, agree or disagree with their partner, state some facts and express opinions. Dialogue Acts (DA) attracted linguistics (Austin, 1962; Searle, 1969) and computational linguistics research (Core and Allen, 1997; Traum, 2000) since long time. With the advent of the Web, a large amount of material about natural language interactions (e.g. blogs, chats, conversation transcripts) has become available, raising the attractiveness of empirical methods analyses on this field. There is a large number of application domains that could benefit from automatically labeling DAs: e.g. conversational agents for monitoring and supporting 84 human-human remote conversations, blogs, forums and chat logs analysis for opinion mining, interpersonal stances modeling by mean of conversational analysis, automatic meeting su</context>
<context position="4786" citStr="Core and Allen, 1997" startWordPosition="737" endWordPosition="740">e communicative goal of a given utterance (Austin, 1962). Researchers use different labels and definitions to address this concept: speech act (Searle, 1969), adjacency pair part (Schegloff, 1968) (Sacks et al., 1974), game move (Power, 1979) Traditionally, the NLP community has employed DA definitions with the drawback of being domain or application oriented. Recently some efforts have been made towards unifying the DA annotation (Traum, 2000). In the present study we refer to a domain-independent framework for DA annotation, the DAMSL architecture (Dialogue Act Markup in Several Layers) by (Core and Allen, 1997). Recently, the problem of DA recognition has been addressed with promising results: Poesio and Mikheev (1998) combine expectations about the next likely dialogue ‘move’ with information derived from the speech signal features; Stolcke et al. (2000) employ a discourse grammar, formalized in terms of Hidden Markov Models, combining also evidences about lexicon and prosody; Keizer et al. (2002) make use of Bayesian networks for DA recognition in dutch dialogues; Grau et al. (2004) consider naive Bayes classifiers as a suitable approach to the DA classification problem; a partially supervised fra</context>
<context position="8653" citStr="Core and Allen, 1997" startWordPosition="1341" endWordPosition="1344">logy) ‘Thank you very much.’ 9% .1% GEN-ANS Generic answers to an Info-Request ‘Yes’, ‘No’, ‘I don’t know’ 4% 4% total cases 1448 131,265 Table 2: The set of labels employed for Dialogue Acts annotation and their distribution in the two corpora an artificial therapist. The users were free to interact with it in natural language, without any particular constraint. This corpus is about healthy eating and contains (overall 60 dialogues, 1448 users’ utterances and 15,500 words). 3.2 Labelling Both corpora are annotated following the Dialogue Act Markup in Several Layers (DAMSL) annotation scheme (Core and Allen, 1997). In particular the Switchboard corpus employs a revision (Jurafsky et al., 1997).2 Table 2 shows the set of labels employed with their definitions, examples and distributions in the two data sets. The categories maintain the DAMSL main characteristic of being domain-independent and can be easily mapped back into SWBD-DAMSL ones, and maintain their original semantics. Thus, the original SWBD-DAMSL annotation had been automatically converted into the categories included in our markup language.3 4 Data preprocessing To reduce the data sparseness, we used a POS-tagger and morphological analyzer (</context>
</contexts>
<marker>Core, Allen, 1997</marker>
<rawString>M. Core and J. Allen. 1997. Coding dialogs with the DAMSL annotation scheme. In Working Notes of the AAAI Fall Symposium on Communicative Action in Humans and Machines, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Gliozzo</author>
<author>C Strapparava</author>
</authors>
<title>Domains kernels for text categorization.</title>
<date>2005</date>
<booktitle>In Proceedengs of (CoNLL2005),</booktitle>
<institution>University of Michigan,</institution>
<location>Ann Arbor,</location>
<contexts>
<context position="13940" citStr="Gliozzo and Strapparava, 2005" startWordPosition="2179" endWordPosition="2183">ons among terms and texts are exploited. The similarity in the resulting vector space is then measured with the standard cosine similarity. Note also that LSA yields a vector space model that allows for a homogeneous representation (and hence comparison) of words, sentences, and texts. For representing a word set or a sentence in the LSA space we use the pseudodocument representation technique, as described by Berry (1992). In practice, each text segment is represented in the LSA space by summing up the normalized LSA vectors of all the constituent words, using also a tf.idf weighting scheme (Gliozzo and Strapparava, 2005). Seeds WH-QTN, Question Mark, ASK-IF, huh I-PERS, I Verbs which directly express opinion or evaluation (guess, think, suppose, affect) AGR-EX, yep, yeah, absolutely, correct Verbs which directly express disagreement (disagree, refute) Greetings (hi, hello), words and markers related to self-introduction (name, NAME) Interjections/exclamations ending discourse (alright, okeydoke), Expressions of thanking (thank) and farewell (bye, bye-bye, goodnight, goodbye) Wishes (wish), apologies (apologize), thanking (thank) and sorry-for (sorry, excuse) no, yes, uh-huh, nope Table 3: The seeds for the un</context>
</contexts>
<marker>Gliozzo, Strapparava, 2005</marker>
<rawString>A. Gliozzo and C. Strapparava. 2005. Domains kernels for text categorization. In Proceedengs of (CoNLL2005), University of Michigan, Ann Arbor, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Godfrey</author>
<author>E Holliman</author>
<author>J McDaniel</author>
</authors>
<title>SWITCHBOARD: Telephone speech corpus for research and development.</title>
<date>1992</date>
<booktitle>In Proceedings of ICASSP92,</booktitle>
<pages>517--520</pages>
<publisher>IEEE.</publisher>
<location>San Francisco, CA.</location>
<contexts>
<context position="6033" citStr="Godfrey et al., 1992" startWordPosition="937" endWordPosition="940">red by Venkataraman et al. (2005) Regardless of the model they use (discourse grammars, models based on word sequences or on the acoustic features or a combination of all these) the mentioned studies are developed in a supervised framework. In this paper, one goal is to explore also the use of a fully unsupervised methodology. 3 Data Sets In the experiments of the present paper we exploit two corpora, both annotated with DAs labels. We aim at developing a recognition methodology as general as possible, so we selected corpora which are different in content and language: the Switchboard corpus (Godfrey et al., 1992), a collection of transcriptions of spoken English telephone conversations about general interest topics, and an Italian corpus of dialogues in the healthy-eating domain (Clarizio et al., 2006). In this section we describe the two corpora, their features, the set of labels used for annotating the dialogue acts with their distributions and the data preprocessing. 3.1 Description The Switchboard corpus is a collection of English human-human telephone conversations (Godfrey et al., 1992) between couples of randomly selected strangers. They were asked to choose one general interest topic and to ta</context>
</contexts>
<marker>Godfrey, Holliman, McDaniel, 1992</marker>
<rawString>J. Godfrey, E. Holliman, and J. McDaniel. 1992. SWITCHBOARD: Telephone speech corpus for research and development. In Proceedings of ICASSP92, pages 517–520, San Francisco, CA. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Grau</author>
<author>E Sanchis</author>
<author>M J Castro</author>
<author>D Vilar</author>
</authors>
<title>Dialogue act classification using a bayesian approach.</title>
<date>2004</date>
<booktitle>In Proceedings of SPECOM-04,</booktitle>
<pages>495--499</pages>
<location>SaintPetersburg, Russia,</location>
<contexts>
<context position="5269" citStr="Grau et al. (2004)" startWordPosition="812" endWordPosition="815">omain-independent framework for DA annotation, the DAMSL architecture (Dialogue Act Markup in Several Layers) by (Core and Allen, 1997). Recently, the problem of DA recognition has been addressed with promising results: Poesio and Mikheev (1998) combine expectations about the next likely dialogue ‘move’ with information derived from the speech signal features; Stolcke et al. (2000) employ a discourse grammar, formalized in terms of Hidden Markov Models, combining also evidences about lexicon and prosody; Keizer et al. (2002) make use of Bayesian networks for DA recognition in dutch dialogues; Grau et al. (2004) consider naive Bayes classifiers as a suitable approach to the DA classification problem; a partially supervised framework has also been explored by Venkataraman et al. (2005) Regardless of the model they use (discourse grammars, models based on word sequences or on the acoustic features or a combination of all these) the mentioned studies are developed in a supervised framework. In this paper, one goal is to explore also the use of a fully unsupervised methodology. 3 Data Sets In the experiments of the present paper we exploit two corpora, both annotated with DAs labels. We aim at developing</context>
</contexts>
<marker>Grau, Sanchis, Castro, Vilar, 2004</marker>
<rawString>S. Grau, E. Sanchis, M. J. Castro, and D. Vilar. 2004. Dialogue act classification using a bayesian approach. In Proceedings of SPECOM-04, pages 495–499, SaintPetersburg, Russia, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Text categorization with Support Vector Machines: learning with many relevant features.</title>
<date>1998</date>
<booktitle>In Proceedings of the European Conference on Machine Learning.</booktitle>
<contexts>
<context position="11334" citStr="Joachims, 1998" startWordPosition="1757" endWordPosition="1758">CEPT); • NAME, used whenever a proper name follows a self-introduction expression (e.g. ‘My name is’) (relevant for the OPENING); • OR-CLAUSE, used for or-clauses, that is utterance starting by ‘or’ (should be helpful for the characterization of the INFO-REQUEST); • VB, used only for the Italian, when a dialectal form of agreement expression is detected. 5 Dialogue Acts Recognition We conducted some experiments both in a supervised and unsupervised settings. 86 5.1 Supervised Regarding the supervised experiments, we used Support Vector Machines (Vapnik, 1995), in particular SVM-light package (Joachims, 1998) under its default configuration. We randomly split the two corpora into 80/20 training/test partitions. SVMs have been used in a large range of problems, including text classification, image recognition tasks, bioinformatics and medical applications, and they are regarded as the state-of-the-art in supervised learning. We got .71 and .77 of F1 measures respectively for the Italian and English corpus. Table 4 reports the performance for each direct act. 5.2 Unsupervised It is not always easy to collect large training, partly because of manual labeling effort and moreover because often it is no</context>
</contexts>
<marker>Joachims, 1998</marker>
<rawString>T. Joachims. 1998. Text categorization with Support Vector Machines: learning with many relevant features. In Proceedings of the European Conference on Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Jurafsky</author>
<author>E Shriberg</author>
<author>D Biasca</author>
</authors>
<title>Switchboard SWBD-DAMSL shallow-discourse-function annotation coders manual, draft 13.</title>
<date>1997</date>
<tech>Technical Report 97-01,</tech>
<institution>University of Colorado.</institution>
<contexts>
<context position="6802" citStr="Jurafsky et al., 1997" startWordPosition="1057" endWordPosition="1060"> healthy-eating domain (Clarizio et al., 2006). In this section we describe the two corpora, their features, the set of labels used for annotating the dialogue acts with their distributions and the data preprocessing. 3.1 Description The Switchboard corpus is a collection of English human-human telephone conversations (Godfrey et al., 1992) between couples of randomly selected strangers. They were asked to choose one general interest topic and to talk informally about it. Full transcripts of these dialogues are distributed by the Linguistic Data Consortium. A part of this corpus is annotated (Jurafsky et al., 1997) with DA labels (overall 1155 conversations, for a total of 205,000 utterances and 1.4 million words)1. Table 1 shows a short sample fragments of dialogues from the Switchboard corpus. The Italian corpus had been collected in the scope of some previous research about Human-ECA interaction. A Wizard of Oz tool was employed (Clarizio et al., 2006) and during the interaction, a conversational agent (i.e. the ‘wizard’) played the role of 1ftp.ldc.upenn.edu/pub/ldc/public\_data/ swb1\_dialogact\_annot.tar.gz 85 Label Description Example Italian English INFO-REQUEST Utterances that are pragmatically</context>
<context position="8734" citStr="Jurafsky et al., 1997" startWordPosition="1353" endWordPosition="1356">Yes’, ‘No’, ‘I don’t know’ 4% 4% total cases 1448 131,265 Table 2: The set of labels employed for Dialogue Acts annotation and their distribution in the two corpora an artificial therapist. The users were free to interact with it in natural language, without any particular constraint. This corpus is about healthy eating and contains (overall 60 dialogues, 1448 users’ utterances and 15,500 words). 3.2 Labelling Both corpora are annotated following the Dialogue Act Markup in Several Layers (DAMSL) annotation scheme (Core and Allen, 1997). In particular the Switchboard corpus employs a revision (Jurafsky et al., 1997).2 Table 2 shows the set of labels employed with their definitions, examples and distributions in the two data sets. The categories maintain the DAMSL main characteristic of being domain-independent and can be easily mapped back into SWBD-DAMSL ones, and maintain their original semantics. Thus, the original SWBD-DAMSL annotation had been automatically converted into the categories included in our markup language.3 4 Data preprocessing To reduce the data sparseness, we used a POS-tagger and morphological analyzer (Pianta et al., 2008) for preprocessing both corpora. So we considered lemmata ins</context>
</contexts>
<marker>Jurafsky, Shriberg, Biasca, 1997</marker>
<rawString>D. Jurafsky, E. Shriberg, and D. Biasca. 1997. Switchboard SWBD-DAMSL shallow-discourse-function annotation coders manual, draft 13. Technical Report 97-01, University of Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Keizer</author>
<author>R op den Akker</author>
<author>A Nijholt</author>
</authors>
<title>Dialogue act recognition with bayesian networks for dutch dialogues. In</title>
<date>2002</date>
<booktitle>Proceedings 3rd SIGdial Workshop on Discourse and Dialogue,</booktitle>
<pages>88--94</pages>
<editor>K. Jokinen and S. McRoy, editors,</editor>
<location>Philadelphia, PA,</location>
<marker>Keizer, den Akker, Nijholt, 2002</marker>
<rawString>S. Keizer, R. op den Akker, and A. Nijholt. 2002. Dialogue act recognition with bayesian networks for dutch dialogues. In K. Jokinen and S. McRoy, editors, Proceedings 3rd SIGdial Workshop on Discourse and Dialogue, pages 88–94, Philadelphia, PA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T K Landauer</author>
<author>P Foltz</author>
<author>D Laham</author>
</authors>
<title>Introduction to latent semantic analysis.</title>
<date>1998</date>
<booktitle>Discourse Processes,</booktitle>
<volume>25</volume>
<contexts>
<context position="12489" citStr="Landauer et al., 1998" startWordPosition="1933" endWordPosition="1936">cause of manual labeling effort and moreover because often it is not possible to find it. Schematically, our unsupervised methodology is: (i) building a semantic similarity space in which words, set of words, text fragments can be represented homogeneously, (ii) finding seeds that properly represent dialogue acts and considering their representations in the similarity space, and (iii) checking the similarity of the utterances. To get a similarity space with the required characteristics, we used Latent Semantic Analysis (LSA), a corpus-based measure of semantic similarity proposed by Landauer (Landauer et al., 1998). In LSA, term co-occurrences in a corpus are captured by means of a dimensionality reduction operated by a singular value decomposition (SVD) on the term-bydocument matrix T representing the corpus. SVD decomposes the term-by-document matrix T into three matrices T = UEkVT where Ek is the diagonal k x k matrix containing the k singular values of T, Q1 &gt; Q2 &gt; ... &gt; Qk, and U and V are column-orthogonal matrices. When the three matrices are multiplied together the original term-by-document matrix is re-composed. Typically we can choose k&apos; « k obtaining the approximation T ^_ UEk&apos;VT. LSA can be </context>
<context position="14691" citStr="Landauer et al., 1998" startWordPosition="2282" endWordPosition="2285">ffect) AGR-EX, yep, yeah, absolutely, correct Verbs which directly express disagreement (disagree, refute) Greetings (hi, hello), words and markers related to self-introduction (name, NAME) Interjections/exclamations ending discourse (alright, okeydoke), Expressions of thanking (thank) and farewell (bye, bye-bye, goodnight, goodbye) Wishes (wish), apologies (apologize), thanking (thank) and sorry-for (sorry, excuse) no, yes, uh-huh, nope Table 3: The seeds for the unsupervised experiment The methodology is completely unsupervised. We run the LSA using 400 dimensions (i.e. k&apos;, as suggested by (Landauer et al., 1998)) respectively on the English and Italian corpus, without any DA label information. Starting from a set of seeds (words) representing the communicative acts (see the complete sets in Table 3), we build the corresponding vectors in the LSA space and then we compare the utterances to find the communicative act with higher similarity. To compare with SVM, the performance is measured on the same test set partition used in the supervised experiment (Table 4). We defined seeds by only considering the communicative goal and the specific semantic of every single DA, just avoiding as much as possible t</context>
</contexts>
<marker>Landauer, Foltz, Laham, 1998</marker>
<rawString>T. K. Landauer, P. Foltz, and D. Laham. 1998. Introduction to latent semantic analysis. Discourse Processes, 25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Martalo</author>
<author>N Novielli</author>
<author>F deRosis</author>
</authors>
<title>Attitude display in dialogue patterns.</title>
<date>2008</date>
<booktitle>In AISB 2008 Convention on Communication, Interaction and Social Intelligence,</booktitle>
<location>Aberdeen, Scotland,</location>
<contexts>
<context position="19253" citStr="Martalo et al., 2008" startWordPosition="3061" endWordPosition="3064">hing the data preprocessing (e.g. by exploiting information about lexicon polarity and subjectivity parameters). We intend to follow both these directions in our future research. 6 Conclusions and Future Work This study aims at defining a method for Dialogue Acts recognition by simply exploiting the lexical semantics of dialogue turns. The technique had to be independent from some important features of the corpus being used such as domain, language, size, interaction scenario. In a long-term perspective, we will employ the technique in conversational analysis for user attitude classification (Martalo et al., 2008). The methodology starts with automatically en88 riching the corpus with additional features, such as linguistic markers. Then the unsupervised case consists of defining a very simple and intuitive set of seeds that profiles the specific dialogue acts, and subsequently performing a similarity analysis in a latent semantic space. The performance of the unsupervised experiment has been compared with a supervised state-of-art technique such as Support Vector Machines, and the results are quite encouraging. Regarding future developments, we will investigate how to include in the framework a wider </context>
</contexts>
<marker>Martalo, Novielli, deRosis, 2008</marker>
<rawString>A. Martalo, N. Novielli, and F. deRosis. 2008. Attitude display in dialogue patterns. In AISB 2008 Convention on Communication, Interaction and Social Intelligence, Aberdeen, Scotland, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Pianta</author>
<author>C Girardi</author>
<author>R Zanoli</author>
</authors>
<title>The TextPro tool suite.</title>
<date>2008</date>
<booktitle>In Proceedings of LREC,</booktitle>
<location>Marrakech</location>
<contexts>
<context position="9273" citStr="Pianta et al., 2008" startWordPosition="1432" endWordPosition="1435">. In particular the Switchboard corpus employs a revision (Jurafsky et al., 1997).2 Table 2 shows the set of labels employed with their definitions, examples and distributions in the two data sets. The categories maintain the DAMSL main characteristic of being domain-independent and can be easily mapped back into SWBD-DAMSL ones, and maintain their original semantics. Thus, the original SWBD-DAMSL annotation had been automatically converted into the categories included in our markup language.3 4 Data preprocessing To reduce the data sparseness, we used a POS-tagger and morphological analyzer (Pianta et al., 2008) for preprocessing both corpora. So we considered lemmata instead of tokens in the format lemma#POS. In addition, we augment the features of each sentence with a set of linguistic markers, defined according to 2The SWBD-DAMSL modifies the original DAMSL framework by further specifying some categories or by adding extra features (mainly prosodic) which were not originally included in the scheme. 3Also we did not consider the utterances formed only by non-verbal material (e.g. laughter). the semantic of the DA categories. We hypothesize, in fact, these features could play an important role in de</context>
</contexts>
<marker>Pianta, Girardi, Zanoli, 2008</marker>
<rawString>E. Pianta, C. Girardi, and R. Zanoli. 2008. The TextPro tool suite. In Proceedings of LREC, Marrakech (Morocco), May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
<author>A Mikheev</author>
</authors>
<title>The predictive power of game structure in dialogue act recognition: Experimental results using maximum entropy estimation.</title>
<date>1998</date>
<booktitle>In Proceedings ofICSLP-98,</booktitle>
<location>Sydney,</location>
<contexts>
<context position="4896" citStr="Poesio and Mikheev (1998)" startWordPosition="753" endWordPosition="756"> to address this concept: speech act (Searle, 1969), adjacency pair part (Schegloff, 1968) (Sacks et al., 1974), game move (Power, 1979) Traditionally, the NLP community has employed DA definitions with the drawback of being domain or application oriented. Recently some efforts have been made towards unifying the DA annotation (Traum, 2000). In the present study we refer to a domain-independent framework for DA annotation, the DAMSL architecture (Dialogue Act Markup in Several Layers) by (Core and Allen, 1997). Recently, the problem of DA recognition has been addressed with promising results: Poesio and Mikheev (1998) combine expectations about the next likely dialogue ‘move’ with information derived from the speech signal features; Stolcke et al. (2000) employ a discourse grammar, formalized in terms of Hidden Markov Models, combining also evidences about lexicon and prosody; Keizer et al. (2002) make use of Bayesian networks for DA recognition in dutch dialogues; Grau et al. (2004) consider naive Bayes classifiers as a suitable approach to the DA classification problem; a partially supervised framework has also been explored by Venkataraman et al. (2005) Regardless of the model they use (discourse gramma</context>
</contexts>
<marker>Poesio, Mikheev, 1998</marker>
<rawString>M. Poesio and A. Mikheev. 1998. The predictive power of game structure in dialogue act recognition: Experimental results using maximum entropy estimation. In Proceedings ofICSLP-98, Sydney, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Power</author>
</authors>
<title>The organisation of purposeful dialogues.</title>
<date>1979</date>
<journal>Linguistics,</journal>
<pages>17--107</pages>
<contexts>
<context position="4407" citStr="Power, 1979" startWordPosition="681" endWordPosition="682">cause they had some people from the EPA and lots of different places, and, uh, there is going to be a real problem on solid waste. B OPINION Uh, I didn’t think that was a new revelation. A AGREE /ACCEPT Well, it’s not too new. B INFO-REQUEST So what is the EPA recommending now? Table 1: An excerpt from the Switchboard corpus 2 Background A DA can be identified with the communicative goal of a given utterance (Austin, 1962). Researchers use different labels and definitions to address this concept: speech act (Searle, 1969), adjacency pair part (Schegloff, 1968) (Sacks et al., 1974), game move (Power, 1979) Traditionally, the NLP community has employed DA definitions with the drawback of being domain or application oriented. Recently some efforts have been made towards unifying the DA annotation (Traum, 2000). In the present study we refer to a domain-independent framework for DA annotation, the DAMSL architecture (Dialogue Act Markup in Several Layers) by (Core and Allen, 1997). Recently, the problem of DA recognition has been addressed with promising results: Poesio and Mikheev (1998) combine expectations about the next likely dialogue ‘move’ with information derived from the speech signal fea</context>
</contexts>
<marker>Power, 1979</marker>
<rawString>R. Power. 1979. The organisation of purposeful dialogues. Linguistics, 17:107–152.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Sacks</author>
<author>E Schegloff</author>
<author>G Jefferson</author>
</authors>
<title>A simplest systematics for the organization of turn-taking for conversation.</title>
<date>1974</date>
<journal>Language,</journal>
<volume>50</volume>
<issue>4</issue>
<contexts>
<context position="4382" citStr="Sacks et al., 1974" startWordPosition="675" endWordPosition="678"> was kind of interested to hear cause they had some people from the EPA and lots of different places, and, uh, there is going to be a real problem on solid waste. B OPINION Uh, I didn’t think that was a new revelation. A AGREE /ACCEPT Well, it’s not too new. B INFO-REQUEST So what is the EPA recommending now? Table 1: An excerpt from the Switchboard corpus 2 Background A DA can be identified with the communicative goal of a given utterance (Austin, 1962). Researchers use different labels and definitions to address this concept: speech act (Searle, 1969), adjacency pair part (Schegloff, 1968) (Sacks et al., 1974), game move (Power, 1979) Traditionally, the NLP community has employed DA definitions with the drawback of being domain or application oriented. Recently some efforts have been made towards unifying the DA annotation (Traum, 2000). In the present study we refer to a domain-independent framework for DA annotation, the DAMSL architecture (Dialogue Act Markup in Several Layers) by (Core and Allen, 1997). Recently, the problem of DA recognition has been addressed with promising results: Poesio and Mikheev (1998) combine expectations about the next likely dialogue ‘move’ with information derived f</context>
</contexts>
<marker>Sacks, Schegloff, Jefferson, 1974</marker>
<rawString>H. Sacks, E. Schegloff, and G. Jefferson. 1974. A simplest systematics for the organization of turn-taking for conversation. Language, 50(4):696–735.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Schegloff</author>
</authors>
<title>Sequencing in conversational openings.</title>
<date>1968</date>
<journal>American Anthropologist,</journal>
<pages>70--1075</pages>
<contexts>
<context position="4361" citStr="Schegloff, 1968" startWordPosition="673" endWordPosition="674">ATEMENT and, uh, I was kind of interested to hear cause they had some people from the EPA and lots of different places, and, uh, there is going to be a real problem on solid waste. B OPINION Uh, I didn’t think that was a new revelation. A AGREE /ACCEPT Well, it’s not too new. B INFO-REQUEST So what is the EPA recommending now? Table 1: An excerpt from the Switchboard corpus 2 Background A DA can be identified with the communicative goal of a given utterance (Austin, 1962). Researchers use different labels and definitions to address this concept: speech act (Searle, 1969), adjacency pair part (Schegloff, 1968) (Sacks et al., 1974), game move (Power, 1979) Traditionally, the NLP community has employed DA definitions with the drawback of being domain or application oriented. Recently some efforts have been made towards unifying the DA annotation (Traum, 2000). In the present study we refer to a domain-independent framework for DA annotation, the DAMSL architecture (Dialogue Act Markup in Several Layers) by (Core and Allen, 1997). Recently, the problem of DA recognition has been addressed with promising results: Poesio and Mikheev (1998) combine expectations about the next likely dialogue ‘move’ with </context>
</contexts>
<marker>Schegloff, 1968</marker>
<rawString>E. Schegloff. 1968. Sequencing in conversational openings. American Anthropologist, 70:1075–1095.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Searle</author>
</authors>
<title>Speech Acts: An Essay in the Philosophy of Language.</title>
<date>1969</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, London.</location>
<contexts>
<context position="1256" citStr="Searle, 1969" startWordPosition="179" endWordPosition="180"> semantics of the utterances. In particular, we present some experiments in supervised and unsupervised framework on both an English and an Italian corpus of dialogue transcriptions. The evaluation displays encouraging results in both languages, especially in the unsupervised version of the methodology. 1 Introduction People proceed in their conversations through a sequence of dialogue acts to yield some specific communicative goal. They can ask for information, agree or disagree with their partner, state some facts and express opinions. Dialogue Acts (DA) attracted linguistics (Austin, 1962; Searle, 1969) and computational linguistics research (Core and Allen, 1997; Traum, 2000) since long time. With the advent of the Web, a large amount of material about natural language interactions (e.g. blogs, chats, conversation transcripts) has become available, raising the attractiveness of empirical methods analyses on this field. There is a large number of application domains that could benefit from automatically labeling DAs: e.g. conversational agents for monitoring and supporting 84 human-human remote conversations, blogs, forums and chat logs analysis for opinion mining, interpersonal stances mode</context>
<context position="4322" citStr="Searle, 1969" startWordPosition="668" endWordPosition="669">h State University on recycling A STATEMENT and, uh, I was kind of interested to hear cause they had some people from the EPA and lots of different places, and, uh, there is going to be a real problem on solid waste. B OPINION Uh, I didn’t think that was a new revelation. A AGREE /ACCEPT Well, it’s not too new. B INFO-REQUEST So what is the EPA recommending now? Table 1: An excerpt from the Switchboard corpus 2 Background A DA can be identified with the communicative goal of a given utterance (Austin, 1962). Researchers use different labels and definitions to address this concept: speech act (Searle, 1969), adjacency pair part (Schegloff, 1968) (Sacks et al., 1974), game move (Power, 1979) Traditionally, the NLP community has employed DA definitions with the drawback of being domain or application oriented. Recently some efforts have been made towards unifying the DA annotation (Traum, 2000). In the present study we refer to a domain-independent framework for DA annotation, the DAMSL architecture (Dialogue Act Markup in Several Layers) by (Core and Allen, 1997). Recently, the problem of DA recognition has been addressed with promising results: Poesio and Mikheev (1998) combine expectations abou</context>
</contexts>
<marker>Searle, 1969</marker>
<rawString>J. Searle. 1969. Speech Acts: An Essay in the Philosophy of Language. Cambridge University Press, Cambridge, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
<author>N Coccaro</author>
<author>R Bates</author>
<author>P Taylor</author>
<author>C Van EssDykema</author>
<author>K Ries</author>
<author>E Shriberg</author>
<author>D Jurafsky</author>
<author>R Martin</author>
<author>M Meteer</author>
</authors>
<title>Dialogue act modeling for automatic tagging and recognition of conversational speech.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>26</volume>
<issue>3</issue>
<marker>Stolcke, Coccaro, Bates, Taylor, Van EssDykema, Ries, Shriberg, Jurafsky, Martin, Meteer, 2000</marker>
<rawString>A. Stolcke, N. Coccaro, R. Bates, P. Taylor, C. Van EssDykema, K. Ries, E. Shriberg, D. Jurafsky, R. Martin, and M. Meteer. 2000. Dialogue act modeling for automatic tagging and recognition of conversational speech. Computational Linguistics, 26(3):339–373.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Traum</author>
</authors>
<title>20 questions for dialogue act taxonomies.</title>
<date>2000</date>
<journal>Journal of Semantics,</journal>
<volume>17</volume>
<issue>1</issue>
<contexts>
<context position="1331" citStr="Traum, 2000" startWordPosition="189" endWordPosition="190">supervised and unsupervised framework on both an English and an Italian corpus of dialogue transcriptions. The evaluation displays encouraging results in both languages, especially in the unsupervised version of the methodology. 1 Introduction People proceed in their conversations through a sequence of dialogue acts to yield some specific communicative goal. They can ask for information, agree or disagree with their partner, state some facts and express opinions. Dialogue Acts (DA) attracted linguistics (Austin, 1962; Searle, 1969) and computational linguistics research (Core and Allen, 1997; Traum, 2000) since long time. With the advent of the Web, a large amount of material about natural language interactions (e.g. blogs, chats, conversation transcripts) has become available, raising the attractiveness of empirical methods analyses on this field. There is a large number of application domains that could benefit from automatically labeling DAs: e.g. conversational agents for monitoring and supporting 84 human-human remote conversations, blogs, forums and chat logs analysis for opinion mining, interpersonal stances modeling by mean of conversational analysis, automatic meeting summarizations a</context>
<context position="4613" citStr="Traum, 2000" startWordPosition="712" endWordPosition="713">l, it’s not too new. B INFO-REQUEST So what is the EPA recommending now? Table 1: An excerpt from the Switchboard corpus 2 Background A DA can be identified with the communicative goal of a given utterance (Austin, 1962). Researchers use different labels and definitions to address this concept: speech act (Searle, 1969), adjacency pair part (Schegloff, 1968) (Sacks et al., 1974), game move (Power, 1979) Traditionally, the NLP community has employed DA definitions with the drawback of being domain or application oriented. Recently some efforts have been made towards unifying the DA annotation (Traum, 2000). In the present study we refer to a domain-independent framework for DA annotation, the DAMSL architecture (Dialogue Act Markup in Several Layers) by (Core and Allen, 1997). Recently, the problem of DA recognition has been addressed with promising results: Poesio and Mikheev (1998) combine expectations about the next likely dialogue ‘move’ with information derived from the speech signal features; Stolcke et al. (2000) employ a discourse grammar, formalized in terms of Hidden Markov Models, combining also evidences about lexicon and prosody; Keizer et al. (2002) make use of Bayesian networks f</context>
</contexts>
<marker>Traum, 2000</marker>
<rawString>D. Traum. 2000. 20 questions for dialogue act taxonomies. Journal of Semantics, 17(1):7–30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Vapnik</author>
</authors>
<title>The Nature of Statistical Learning Theory.</title>
<date>1995</date>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="11284" citStr="Vapnik, 1995" startWordPosition="1750" endWordPosition="1751">’, ‘I agree’) is detected (relevant for AGREE-ACCEPT); • NAME, used whenever a proper name follows a self-introduction expression (e.g. ‘My name is’) (relevant for the OPENING); • OR-CLAUSE, used for or-clauses, that is utterance starting by ‘or’ (should be helpful for the characterization of the INFO-REQUEST); • VB, used only for the Italian, when a dialectal form of agreement expression is detected. 5 Dialogue Acts Recognition We conducted some experiments both in a supervised and unsupervised settings. 86 5.1 Supervised Regarding the supervised experiments, we used Support Vector Machines (Vapnik, 1995), in particular SVM-light package (Joachims, 1998) under its default configuration. We randomly split the two corpora into 80/20 training/test partitions. SVMs have been used in a large range of problems, including text classification, image recognition tasks, bioinformatics and medical applications, and they are regarded as the state-of-the-art in supervised learning. We got .71 and .77 of F1 measures respectively for the Italian and English corpus. Table 4 reports the performance for each direct act. 5.2 Unsupervised It is not always easy to collect large training, partly because of manual l</context>
</contexts>
<marker>Vapnik, 1995</marker>
<rawString>V. Vapnik. 1995. The Nature of Statistical Learning Theory. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Venkataraman</author>
<author>Y Liu</author>
<author>E Shriberg</author>
<author>A Stolcke</author>
</authors>
<title>Does active learning help automatic dialog act tagging in meeting data?</title>
<date>2005</date>
<booktitle>In Proceedings of EUROSPEECH-05,</booktitle>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="5445" citStr="Venkataraman et al. (2005)" startWordPosition="839" endWordPosition="842">ognition has been addressed with promising results: Poesio and Mikheev (1998) combine expectations about the next likely dialogue ‘move’ with information derived from the speech signal features; Stolcke et al. (2000) employ a discourse grammar, formalized in terms of Hidden Markov Models, combining also evidences about lexicon and prosody; Keizer et al. (2002) make use of Bayesian networks for DA recognition in dutch dialogues; Grau et al. (2004) consider naive Bayes classifiers as a suitable approach to the DA classification problem; a partially supervised framework has also been explored by Venkataraman et al. (2005) Regardless of the model they use (discourse grammars, models based on word sequences or on the acoustic features or a combination of all these) the mentioned studies are developed in a supervised framework. In this paper, one goal is to explore also the use of a fully unsupervised methodology. 3 Data Sets In the experiments of the present paper we exploit two corpora, both annotated with DAs labels. We aim at developing a recognition methodology as general as possible, so we selected corpora which are different in content and language: the Switchboard corpus (Godfrey et al., 1992), a collecti</context>
</contexts>
<marker>Venkataraman, Liu, Shriberg, Stolcke, 2005</marker>
<rawString>A. Venkataraman, Y. Liu, E. Shriberg, and A. Stolcke. 2005. Does active learning help automatic dialog act tagging in meeting data? In Proceedings of EUROSPEECH-05, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Warnke</author>
<author>R Kompe</author>
<author>H Niemann</author>
<author>E N¨oth</author>
</authors>
<title>Integrated dialog act segmentation and classification using prosodic features and language models.</title>
<date>1997</date>
<booktitle>In Proceedings of 5th European Conference on Speech Communication and Technology,</booktitle>
<volume>1</volume>
<pages>207--210</pages>
<location>Rhodes, Greece.</location>
<marker>Warnke, Kompe, Niemann, N¨oth, 1997</marker>
<rawString>V. Warnke, R. Kompe, H. Niemann, and E. N¨oth. 1997. Integrated dialog act segmentation and classification using prosodic features and language models. In Proceedings of 5th European Conference on Speech Communication and Technology, volume 1, pages 207– 210, Rhodes, Greece.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>