<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.988459">
Characterizing Indirect Speech Act&amp;
</title>
<author confidence="0.863845">
Gretchen P. Brown
</author>
<subsectionHeader confidence="0.424783666666667">
Computer Corporation of America
575 Technology Square
Cambridge, Massachusetts 02139
</subsectionHeader>
<bodyText confidence="0.993754666666667">
This paper presents the core of a descriptive theory of indirect speech acts, i.e.
utterances in which one speech act form is used to realize another, different, speech act.
The proposed characterization of indirect speech acts is based on principles of goal
formation, viewed in the context of a general structural model of action. The model of
action is used to develop rules that characterize a large number of indirect speech act
forms. Computational implications of the theory are discussed.
</bodyText>
<sectionHeader confidence="0.994297" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999793428571429">
In recent years, a considerable amount of attention
has been devoted to the topic of indirect speech acts,
i.e. utterances in which one speech act form is used to
realize another, different, speech act. A simple exam-
ple of an indirect speech act is the question form 1.1
uttered with the intent to convey a request to close the
door.
</bodyText>
<subsectionHeader confidence="0.944444">
1.1 Can you close the door?
</subsectionHeader>
<bodyText confidence="0.995779428571429">
Despite the volume of work that has been done on
indirect speech acts, fundamental questions remain
unanswered. We still lack a complete answer to even
the basic question of what forms can realize a given
speech act. Two properties of the problem have made
the search for a complete theory of indirect forms
particularly difficult:
</bodyText>
<listItem confidence="0.9992981">
1. .Sheer numbers: There are a considerable
number of different speech acts, and many
have a wide selection of possible indirect re-
alizations. A theory must be quite general to
take these into account.
2. Variety: Indirect speech act forms range from
highly conventionalized to apparently free
forms. It appears that no single, simple set
of generalizations can adequately capture the
complexity of indirect speech acts.
</listItem>
<bodyText confidence="0.967856583333333">
1 The research for this paper was carried out while the author
was on the staff of the Laboratory for Computer Science at the
Massachusetts Institute of Technology. The research was supported
by the Advanced Research Projects Agency of the Department of
Defense and was monitored by the Office of Naval Research under
Contract Number N00014-75-C-0661.
It is the claim of this paper that previous investigations
of indirect speech acts (abbreviated ISA52) have been
hampered by inadequate semantic theories. This study
takes as primary the central tenet of speech act theory
that language is action (Austin [2]) and brings to bear
some of the perspectives on the representation of ac-
tions developed in the course of Artificial Intelligence
research. Accordingly, principles of goal formation
are discussed in the context of a general structural
model of action. The model of action is used to devel-
op rules that characterize a large number of indirect
speech act forms.
The focus of this investigation is on the develop-
ment of a descriptive theory of ISAs. Accounting for
the diversity of ISAs is an important goal, but I see
the formulation of a solid and complete descriptive
theory as a necessary prerequisite to an explanatory
theory. This is not to say that explanation can be
totally decoupled from description, and, in fact, the
use of the general model of actions to derive ISA
forms has significant explanatory potential. To fully
account for differences in ISA forms, however, we
must have a good characterization of what these dif-
ferences are.
While the claims that will be made in this paper
stop at a (partial) descriptive theory of ISAs, the un-
derlying motivations do not. Computational consider-
ations have played a significant role in the develop-
ment of the ISA categorization. The work presented
here grew out of the implementation effort reported in
</bodyText>
<footnote confidence="0.604450666666667">
2 It is helpful to pronounce ISA as initials to avoid confusion
with IS-A, the name used commonly in the Artificial Intelligence
literature for a hierarchical semantic relationship.
Copyright 1980 by the Association for Computational Linguistics. Permission to copy without fee all or part of this material is granted
provided that the copies are not made for direct commercial advantage and the Journal reference and this copyright notice are included on
the first page. To copy otherwise, or to republish, requires a fee and/or specific permission.
</footnote>
<page confidence="0.524227">
0362-613X/80/030150-17$01.00
150 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980
</page>
<note confidence="0.365909">
Gretchen P. Brown Characterizing Indirect Speech Acts
</note>
<bodyText confidence="0.999855258064516">
[3]. The actual behavior of the system was limited
(internal manipulations for a twenty turn sample dia-
logue), but the process model implemented was rela-
tively sophisticated. A further expanded and refined
version of this model is presented in [4].
In viewing the characterization of ISAs as a compu-
tational problem, the central premise has been that the
phenomenon of ISAs is too complex to admit to a
single uniform computational treatment. The two
stumbling blocks to a descriptive theory -- the number
and variety of ISA forms -- are doubly troubling when
the theory is to have a computational application.
Some means must be found to divide the class of ISAs
into subclasses which have their own specialized repre-
sentations and processing strategies. The development
of the descriptive theory of ISAs presented has been
affected in various ways, subtle and not so subtle, by
this computational hypothesis. The proper level of
representation of ISA rules has been of primary con-
cern, as has the identification of classes of ISAs ac-
cording to the complexity of their derivations.
Section 2 introduces some of the issues that have
been raised about ISAs and Section 3 lays the ground-
work for the approach taken here. Section 4 then
presents a set of general rules that handle a large num-
ber of ISA forms. The rules in that section are pro-
posed as the core of a descriptive theory of ISAs. Is-
sues surrounding the application of the rules are ad-
dressed in Section 5. Finally, Section 6 discusses some
of the implications of the theory, with comparison to
recent computational work.
</bodyText>
<sectionHeader confidence="0.933728" genericHeader="keywords">
2. Previous Approaches
</sectionHeader>
<bodyText confidence="0.976071793650794">
Two approaches to the characterization of indirect
speech acts have been particularly influential for both
computational and traditional linguists: the views pro-
posed by Gordon and Lakoff and by Searle. Since the
rules presented in this paper combine properties of
each approach, we start with a brief description of
each.
We consider first the approach taken by Gordon
and Lakoff [12]. Concentrating primarily on request,
Gordon and Lakoff propose a set of what they call
sincerity conditions and then give a single powerful
rule to account for the different ways that a request
can be framed. They say that to make a sincere
request a speaker must, first, want the action done,
second, believe that the hearer can do the action,
third, believe that the hearer wants to do the action,
and, fourth, believe that the hearer would not do the
action unless asked to. The first of these sincerity
conditions is called speaker-based and the remaining
three are called hearer-based. The rule given is:
One can convey a request by
(a) asserting a speaker-based sincerity condition or
(b) questioning a hearer-based sincerity condition.
This formulation is attractive because it is so elegant
and simple, but it is also, as the authors are the first to
observe, only a preliminary answer. The conditions
associated with request are incomplete, since they lack
any mention of obligation relationships; these are dis-
cussed below in Section 3.3. More problematic is the
lack of detailed guidelines for extending the theory
beyond requests.
A second major approach to ISA regularities is that
of Searle. Searle presents a more complete account of
ISAs, proposing generalizations associated with the
five major classes of speech act defined in [26]. In
[25] he lists four generalizations for directives and five
others for commissives. The generalizations are differ-
entiated according to the parts of the speech act iden-
tified in [24], i.e. propositional content conditions,
sincerity conditions, and preparatory conditions.
(Gordon and Lakoff&apos;s sincerity conditions, in contrast,
seem to be an amalgam of Searle&apos;s sincerity and pre-
paratory conditions.)
Searle&apos;s contribution is a valuable one, in that he
has succeeded in accounting for a broad range of
speech acts. At the same time, Searle&apos;s generalizations
can be questioned on the count that they are too spe-
cific. Generalizations are stated in terms of types of
preparatory conditions, rather than in terms of prepar-
atory conditions as a whole. A more serious problem
is the relegation of the notion of speaker- and hearer-
based conditions to an informal role, as opposed to
giving it an explicit place in the theory.
The theory proposed in this paper is both a synthe-
sis and a generalization of the two approaches. Rather
than derive ISA forms from a single set of conditions
associated with the speech act, as do Gordon iftd La-
koff, I follow Searle in looking for important classes of
ISA forms based on different parts of the speech act.
The theory presented goes a step further, however,
looking beyond the structure of individual speech acts
to derive ISA forms from very general principles of
goal formation.
</bodyText>
<sectionHeader confidence="0.977864" genericHeader="introduction">
3. Preliminaries
</sectionHeader>
<bodyText confidence="0.9999762">
We first introduce the model of actions on which
the ISA rules will be based, and Section 3.2 looks at
speech acts from the perspective of this model. Sec-
tion 3.3 then discusses the request speech act as a basis
for examples used throughout the paper.
</bodyText>
<subsectionHeader confidence="0.99658">
3.1. An Outline of the Structure of Actions
</subsectionHeader>
<bodyText confidence="0.976239052631579">
If we are to follow Austin and Searle in the belief
that language is, fundamentally, action, then linguistic
models must include a model of the structure of ac-
tions. Such a model of actions can be a unifying force
American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 151
Gretchen P. Brown Characterizing Indirect Speech Acts
within the larger model, since structural information
can be used in a number of different ways. This sub-
section gives a very general treatment of actions, just
enough to support the ISA rules proposed. The ac-
count of actions is taken from the OWL-I representa-
tion scheme (Szolovits et al. [27] and Brown [3,6]),3
and it has counterparts in work by Bruce [7], Schank
and Abelson [23], Grosz [14], and Moore, Levin, and
Mann [18,19]. Some of these approaches differ in the
type of action modelled, and all of them differ in the
details, but each of the approaches is open to the
treatment of action representations as general knowl-
edge. Thus, action representations are not merely
programs for doing something, they are also knowledge
structures that may be used by other processes.
We start with the notion of a method, a representa-
tion of an action. Methods have three main parts: a
header, argument specifications, and a procedural
body. The header is the method&apos;s unique name. Argu-
ment specifications, organized by semantic cases, are
used for type checking of inputs to the method (input
cases) or to specify the form of results (output cases).
The procedural body is divided into two parts:
(optional) prerequisites and procedure steps.
Note that input cases are associated with methods,
not surface English verbs. Input case specifications
give constraints on the participants in the method, the
materials used, objects manipulated, etc. (A suggested
set of semantic input cases derived by William A. Mar-
tin can be found in [4].) An important type of input
case constraint, the precondition, is discussed in the
next subsection.
Besides input case specifications, we said that me-
thods may have associated output case specifications,
i.e. specifications of results. One important notion
here is that of principal result, which is the main result
of the method and, typically, the reason that the me-
thod is undertaken. For example, the action conveyed
in &amp;quot;Paint the block red&amp;quot; has as principal result that the
block is red. The paint brush may also end up red,
but this is not the principal result.
Turning to the method&apos;s procedural body, we need
to know that procedure steps may correspond to sub-
actions, i.e. they may be used as calls to other me-
thods. Beyond this, procedure steps have a good deal
of interesting structure, discussion of which is not
necessary for the purposes of this paper.
As for prerequisites, the ones that are of interest
here are states. A stative prerequisite of an action is a
condition that must obtain before that action is carried
out. If the condition does not hold, then one must
</bodyText>
<footnote confidence="0.9780535">
3 OWL-I was developed by William A. Martin, Lowell Haw-
kinson, William Long, Alexander Sunguroff, William Swartout,
Peter Szolovits, and the author. OWL has continued to develop
since that time.
</footnote>
<bodyText confidence="0.94781525">
bring it about before carrying out the action. An ex-
ample of a prerequisite is the requirement that an ele-
mentary course of study be completed before a more
advanced one is undertaken.
</bodyText>
<subsectionHeader confidence="0.99178">
3.2. The Model of Actions Applied to Speech Acts
</subsectionHeader>
<bodyText confidence="0.99805766">
Speech acts, because they are actions, can be repre-
sented by methods. Speech act representations there-
fore have semantic input cases, which typically include
cases for the participants in the conversation and a
case for what Searle calls the propositional content
condition of the speech act (very roughly, what the
speech act is &amp;quot;about&amp;quot;) [24]. Among the constraints
on these input cases are preconditions. Preconditions
are constraints on the beliefs, desires, or other inten-
tions of the agent of the method (the participant re-
sponsible for the action) that should be satisfied be-
fore the speech act gets underway. Preconditions
differ from prerequisites in that a failure to satisfy
preconditions typically means that a method is elimi-
nated from consideration as a possible plan; a prere-
quisite that is not satisfied merely adds extra steps to
be performed. Preconditions will play an important
role in the framing of ISAs; a sample set is given in
the next subsection.
A concept that will be useful in talking about ISAs
is the intended effect. The intended effects of speech
acts are those effects that P1 (the agent of the speech
act) intends to have on P2. The most important of
these effects will be called the principal intended effect.
For request, the principal intended effect is that P2
take responsibility for carrying out some action. For
offer, it is that P2 accept the offer. &amp;quot;Accept&amp;quot; here
includes not only a verbal acceptance, but also that P2
perform some action that complements P 1 &apos;s offer, e.g.,
P2 takes food that is offered. The notion of intended
effect comes from Verschueren [28], but it has been
adapted somewhat. In particular, for uniformity, in-
tended effects will be restricted to be actions only, not
states. For example, the principal intended effect for
state is that P2 come to know (as opposed to just know)
that P1 believes something to be a fact.
Intended effects and principal intended effects can
be related in a straightforward way to methods. In-
tended effects are actions precipitating certain method
results (i.e. intended effects are the direct causes);
principal intended effects are actions precipitating
certain principal results. The results and principal
results are not necessarily associated with the speech
act method but are instead associated with higher level
methods that include both the speech act and its pro-
totypical linguistic and nonlinguistic responses.
Once speech acts have been set within the action
representation, we can define ISAs more closely to
delimit the phenomena of interest. Speech acts con-
veyed by ISA forms are derivable from parts of, or
</bodyText>
<page confidence="0.759287">
152 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980
</page>
<bodyText confidence="0.965048058823529">
Gretchen P. Brown Characterizing Indirect Speech Acts
conditions associated with, the conveyed speech act(s).
Other implications of an utterance may arise from a
particular co-occurrence of steps within larger patterns
of dialogue, but these implications will not be consid-
ered to be conveyed speech acts. A very simple exam-
ple of such an implication comes from a computer
console session environment, where some users type
&amp;quot;Thank you&amp;quot; in a place where others type &amp;quot;Thank
you&amp;quot; followed by &amp;quot;Good-bye&amp;quot;. When &amp;quot;Thank you&amp;quot;
occurs alone in such a situation, it will not be consid-
ered to be an indirect closing. Instead, the closing is
seen as an optional step, which may be omitted in the
presence of utterances that uniquely identify the place
in the dialogue. Utterances that imply omitted steps
do so based on relationships at a higher level of dia-
logue structure than individual speech acts.
</bodyText>
<subsectionHeader confidence="0.990898">
3.3. Preconditions for Requests
</subsectionHeader>
<bodyText confidence="0.9993350625">
Although the rules presented in the next section are
intended to apply to speech acts in general, examples
will be drawn primarily from request forms. Since the
ISA rules depend in part on the preconditions of a
speech act, the preconditions of the speech act request
are discussed here; preconditions for ask, state, offer,
and suggest appear in the Appendix.4 In these precon-
ditions and throughout the paper, P1 is the originator
of the utterance (or written message) and P2 is the
receiver. If subsequent related utterances are dis-
cussed, then P1 and P2 continue to refer to the same
participants. Consider, then, the following precondi-
tions for request:
I. P1 wants P2 to take responsibility for car-
rying out the action.
II. P1 believes that P2 can take responsibility
for carrying out the action.
III. P1 believes that P2 is willing to take respon-
sibility for carrying out the action.
IV. P1 believes that P2 is obligated to P1 (and
possibly to others) to take responsibility for
carrying out the action.
To clarify the terms used in the preconditions, I
will outline some of the relationships that should be
captured in a semantic network representation of
them.
The internal semantic node believe has a superclass
relationship to semantic nodes for idea-holding con-
cepts, e.g., thinking, knowing, assuming, and hypothes-
izing. The different specializations (i.e. subclasses) of
believe differ according to the strength of commitment
to the belief. In addition, they differ according to
</bodyText>
<footnote confidence="0.990818">
4 In the interests of readability, preconditions and ISA rules
are presented in this paper informally. The model of actions and
rules have been represented in OWL-I, which implies a number of
commitments, many shared by other representation schemes of the
late seventies. These commitments are discussed further in Sect. 5.
</footnote>
<bodyText confidence="0.993332358024691">
whether the belief is open to confirmation against
some external reality (i.e., facts), will eventually be
open to confirmation (i.e., guesses and predictions), or
is generally considered to be a matter of taste (i.e.,
opinions). The link between the various specializa-
tions of believe is the fact that beliefs can be partially
supported by evidence, whether or not complete con-
firmation of the beliefs is ultimately possible. This
excludes idea-holding actions such as dreaming.
In precondition I, the internal node want has a su-
perclass relationship to semantic nodes for all goal-
holding concepts, e.g., desiring and hoping. &amp;quot;Take
responsibility&amp;quot; is used in the preconditions to permit
subcontracting. Whether P2 does all the action steps
or not, P2 still remains responsible to P1 for the re-
sults.
In precondition II, &amp;quot;can&amp;quot; is meant to convey the
general notion of enablement for actions. One spe-
cialization of the semantic node can is may, enable-
ment through permission. The internal representation
for &amp;quot;can&amp;quot; is discussed further in Section 5.
In the third precondition, the internal node for &amp;quot;be
willing&amp;quot; has a superclass in common with want
(perhaps called &amp;quot;be inclined&amp;quot;) but it differs in that if
P2 is willing to do action Al, he or she is not disin-
clined to do it. That is to say, P2 does not necessarily
have Al as a goal, but P2 has no conflicting goals
which, when weighed against Al, result in a decision
against adopting Al as a goal. Precondition III is
worded &amp;quot;P2 is willing to&amp;quot; rather than &amp;quot;P2 wants to,&amp;quot;
because P2 will not necessarily already have the action
requested as a goal at the time that P1 makes the
request.
Finally, we come to the notion of obligation in
precondition IV. The concept of obligation assumed is
a more specific version of the generalized obligation
that Labov and Fanshel use for requests in [16]. Obli-
gation to other people is seen here as coming in three
types: role obligation, authority obligation, and the
general obligation to be cooperative. Role obligations
are associated with roles, which can be seen as pat-
terns of behavior that can be assumed by individuals
for varying periods of time. An example of a role
obligation would be the requirement that a bank teller
fulfill a request to make change. Authority obligations
are slightly more difficult to identify, since, especially
in contemporary American society, most authority
arises from roles. Authority obligations based on age
differences are probably the most prevalent examples.
The third type of obligation, the general obligation to
be cooperative, seems to arise simply from a need,
often in the form of a temporary inequality between
individuals. The obligation applies in a range of situa-
tions. A typically mundane version of the obligation is
that questions should be answered, i.e. that inequali-
ties of knowledge should be corrected. A more serious
American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 153
Gretchen P. Brown Characterizing Indirect Speech Acts
version is the injunction to help someone in an emer-
gency. Note that this obligation is not absolute (nor
are role or authority obligations), and it may be over-
ridden by other obligations. A point worth mentioning
is that my notion of obligation includes the notion of
Pt&apos;s right to invoke the obligation. (See [16], p. 78.)
An obligation is seen as a three-place relationship
between P1, P2, and the thing that P2 is obliged to do.
Note that the specific persons P1 and P2 need not be
named explicitly in the obligation. For example, the
obligation to drive carefully may be an obligation to
society in general, and hence to any individual P1 by
inclusion in the larger set. Given this formulation, P1
has the right to invoke the obligation to drive carefully
because P1 is one of the parties to the obligation, even
if P1 is not named explicitly.5
Philosophical controversy surrounds several of
these terms, and a complete and detailed definition for
any of them is a research project in itself. The com-
ments on the terms used in the preconditions are
sketchy, but the intent of the comments is to give the
reader enough information to evaluate the approach to
ISA characterization proposed in this paper.
</bodyText>
<sectionHeader confidence="0.582634" genericHeader="method">
4. A Set of General Rules for Indirect Speech Acts
</sectionHeader>
<bodyText confidence="0.999671666666667">
If one looks carefully at a varied group of indirect
speech acts, an outline of a common sense view of
rational behavior begins to emerge. This common
sense view can be used as a conceptual organization of
ISA forms, an approach taken here in the presentation
of a set of general rules for ISAs.
</bodyText>
<subsectionHeader confidence="0.999471">
4.1. Some Basic Observations
</subsectionHeader>
<bodyText confidence="0.998547257142857">
We start with some very basic observations, none
of which should seem particularly remarkable since the
phenomena involved lie just below the surface, and
sometimes right at the surface, of English (and other
languages as well).
Strategy I. If you believe that a proposition
holds, you can tell someone.
Strategy 2. If you want to know whether a
proposition holds, you can ask someone if it
holds.
Strategy 3. If you want to know whether a
proposition holds, you can ask someone if it
does not hold.
These three communication strategies are extensions
of the observations made by Searle and built into Gor-
don and Lakoff&apos;s rule for requests. &amp;quot;Can&amp;quot; is used
above to indicate that other options do, of course,
exist; these are merely the options of interest for ISAs.
5 Reminders are one class of utterance in which P1 does have
the right to invoke an obligation without being a party to it. This is
not necessarily a problem for requests, however, because reminders
can be treated as separate speech acts.
The three strategies can be augmented by what will be
called here the better-knowledge principle: if both you
and a conversational partner have a degree of knowl-
edge about a proposition, the decision whether to tell
what you know (or think) or ask what the other per-
son knows (or thinks) can be made based on which
participant has the better knowledge of the proposi-
tion.
Moving from information exchanges to actions in
general, we can identify some basic factors in the
process of undertaking an action (i.e. adopting the
action as a goal, not necessarily with the intent of
being the agent yourself).
</bodyText>
<listItem confidence="0.977396857142857">
1. One should only undertake actions that are
necessary.
2. One should only undertake actions for which
some desirable result or results can be ex-
pected.
3. One should only undertake actions that one
expects to be possible.
</listItem>
<bodyText confidence="0.999022057142857">
These three maxims, which will be referred to as the
maxims of Necessity, Desirability, and Possibility,
summarize factors that should be weighed in goal for-
mation, the process of deciding to adopt some action
as a goal. Necessity, desirability, and possibility of
actions are not necessarily, of course, evaluated inde-
pendently, but the maxims abstract away from the
actual weighing procedure. Interpretation of these
maxims is intended to be quite broad. &amp;quot;Necessity&amp;quot; is
assumed here to include obligations, and &amp;quot;possibility&amp;quot;
is assumed to include having permission.
Readers familiar with the classic work of Grice on
conversational implicature [13] will recognize the ap-
proach that is being taken. Grice suggests four cate-
gories of maxims that are applicable to linguistic ac-
tions but which have analogues in other types of ac-
tions. The maxims given here are applicable to actions
in general but apply to speech acts as a special case.
The Maxim of Necessity above has a partial counter-
part in Grice&apos;s category of Quantity. The other two
maxims have no direct counterparts, and they suggest
extensions to Grice&apos;s framework.
Given these basic observations about communica-
tion and action in general, the question is how they
should be incorporated into a theory. One possible
approach is to represent the observations at essentially
the level of generality given, then derive ISA forms by
a uniform inference process. Here, in contrast, the
observations will be used as a conceptual organization
and as a guide to rule specification. The resulting
rules will be more specialized, but they will be at a
level closer to the ISA forms that they describe.
The motivation for the choice of this approach can
better be described after the rules have been present-
ed. Accordingly, the rest of this section discusses
</bodyText>
<page confidence="0.834156">
154 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980
</page>
<bodyText confidence="0.856809666666667">
Gretchen P. Brown Characterizing Indirect Speech Acts
rules associated with the maxims of Necessity, Desira-
bility, and Possibility.
</bodyText>
<subsectionHeader confidence="0.991599">
4.2. Rules Related to the Maxim of Necessity
</subsectionHeader>
<bodyText confidence="0.99986425">
The Maxim of Necessity says that one should act
only when necessary, avoiding extraneous actions.
The following rules account for speech act forms relat-
ed to this maxim:
</bodyText>
<equation confidence="0.7545265">
PI can convey a speech act indirectly by --
Rule NECESSARY-ASSERT
</equation>
<bodyText confidence="0.996438">
-- asserting that the intended speech act is neces-
sary
e.g., the request &amp;quot;I have to ask you to shut the
door.&amp;quot;
</bodyText>
<sectionHeader confidence="0.511481" genericHeader="method">
Rule NECESSARY-ASK
</sectionHeader>
<bodyText confidence="0.9897545">
-- asking whether the intended speech act is neces-
sary
e.g., the request &amp;quot;Do I need to ask you to shut
the door?&amp;quot;
</bodyText>
<sectionHeader confidence="0.550807" genericHeader="method">
Rule EQUI-ASK
</sectionHeader>
<bodyText confidence="0.995400380000001">
-- asking whether an equivalent speech act (i.e.,
one with the same principal intended effect) has
already been performed
e.g., the request &amp;quot;Did anyone ask you to take
out the garbage?&amp;quot;
Rule FUTURE-EFFECT-ASK
-- asking whether the principal intended effect can
be expected to occur without the speech act
e.g., the requests:
&amp;quot;Are you planning to take out the garbage?&amp;quot;
&amp;quot;Are you going to take out the garbage?&amp;quot;
Rule PAST-EFFECT-ASK
-- asking whether the principal intended effect of
the speech act has already occurred
e.g., the requests:
&amp;quot;Did you take out the garbage?&amp;quot;
&amp;quot;Have you taken out the garbage?&amp;quot;
and, using additional rules (see Section 5),
&amp;quot;Is the garbage out?&amp;quot;
&amp;quot;Assert&amp;quot; is used in these and subsequent rules to in-
clude the speech acts of stating a fact and giving an
opinion, i.e., those speech acts that Searle calls repre-
sentatives [26].
The &amp;quot;necessity&amp;quot; rules exemplify the three commu-
nication strategies listed at the beginning of this sec-
tion. NECESSARY-ASSERT exemplifies the first
strategy, in which P1 tells what he or she knows about
the necessity of the speech act. In NECESSARY-
ASK, P1 asks whether the speech act is necessary
(strategy 2), and in the last three rules, P1 asks
whether the speech act is unnecessary (strategy 3).
Note that there is no rule for the explicit version of
the third strategy, e.g. for the form &amp;quot;Is it unnecessary
for me to &lt;speech act&gt;?&amp;quot; This form is practically
incomprehensible as a way to carry out the speech act,
even though the reasoning involved is comparable to
that for the EQUI-ASK form. Perhaps this gap re-
flects a preference for more specialized forms. The
three strategy-3 rules for necessity, which are more
specific, supersede the explicit &amp;quot;Is it unnecessary...&amp;quot;
form.
Gordon and Lakoff use a condition analogous to
the FUTURE-EFFECT-ASK rule to account for the
&amp;quot;Will you &lt;action&gt;?&amp;quot; request form. In this interpre-
tation, the form asks if the request is unnecessary be-
cause P2 was going to perform the desired action any-
way. While this approach is plausible on the face of
it, some uses of the &amp;quot;will&amp;quot; form are not motivated by
questions of the necessity of the action. Consider, for
example, 4.1:
</bodyText>
<subsectionHeader confidence="0.923018">
4.1 Will you accept a ride to the airport?
</subsectionHeader>
<bodyText confidence="0.999968294117647">
One can view example 4.1 as P1 asking P2 whether
the outcome of an offer by P1 will be successful (i.e.,
acceptance). This example can therefore be accounted
for by the Maxim of Possibility; &amp;quot;will&amp;quot; forms are dis-
cussed further in Section 4.4.
Finally, note that P1 is permitted to use an ISA
only when P1 can reasonably expect P2 to decipher
P l&apos;s intent, i.e., to recognize the indirection. Neither
the &amp;quot;necessity&amp;quot; rules nor any of the other rules to be
presented here, however, include this information. It
appears that this constraint is part of a more general
constraint that P1 avoid ambiguity. That is, P1 is
obligated -- to the best of his or her ability -- to frame
any utterance (ISA or not) in such a way that P2 can
understand the message that P1 intended to convey.
See Grice [13] for discussion of an &amp;quot;avoid ambiguity&amp;quot;
maxim.
</bodyText>
<subsectionHeader confidence="0.998594">
4.3. Rules Related to the Maxim of Desirability
</subsectionHeader>
<bodyText confidence="0.999862666666667">
Next we come to the Maxim of Desirability, which
says that one should initiate actions for which some
desirable result or results can be expected and avoid
actions for which an undesirable result or results can
be expected. Related to this maxim, we have the fol-
lowing ISA rules:
</bodyText>
<equation confidence="0.4691905">
PI can convey a speech act indirectly by --
Rule DESIRABLE-ASSERT
</equation>
<bodyText confidence="0.975873595238095">
-- asserting that some desirable result or results can
be expected or some undesirable result or results
can be avoided for some intended effect of the
speech act.
e.g., the request &amp;quot;I&apos;ll be happier when you sub-
stantiate those figures.&amp;quot;
Here, the desirable result is the happiness of P1,
and the intended effect of the request is that P2
substantiate the figures.
American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 155
Gretchen P. Brown Characterizing Indirect Speech Acts
Rule DESIRABLE-ASK
-- asking whether some desirable result or results
can be expected or whether some undesirable result
or results can be avoided for some intended effect
of the speech act.
e.g., the request &amp;quot;Will more light come in if you
move it a little to the right?&amp;quot;
Rule UNDESIRABLE-ASK
-- asking whether some undesirable result or results
can be expected from the intended speech act.
e.g., the request &amp;quot;Will you be offended if I ask
you to loan me some money?&amp;quot;
For the first two rules, note that the intended ef-
fect need not be an immediate result of the speech act;
it may be several times removed in the causal chain.
Similarly, the desirable result need not be an immedi-
ate result of the intended effect.
The &amp;quot;desirability&amp;quot; rules exemplify the three linguis-
tic strategies listed at the beginning of this section.
Again, as for the strategy-3 &amp;quot;necessity&amp;quot; rules,
DESIRABLE-ASSERT and DESIRABLE-ASK do not
include the most general possible forms. For example,
no rule has been given to permit example 4.2 to be
interpreted as an indirect request that P2 be quiet.
4.2 I will be happier if I ask you to be quiet.
Whereas DESIRABLE-ASSERT is framed in terms of
an intended effect of the speech act, example 4.2 ref-
ers to the speech act explicitly. The same hypothesis
applies for this gap: the more specialized
DESIRABLE-ASSERT has displaced the explicit, and
more general, form exemplified by 4.2.
</bodyText>
<subsectionHeader confidence="0.996738">
4.4. Rules Related to the Maxim of Possibility
</subsectionHeader>
<bodyText confidence="0.9922365">
The third maxim proposed was the Maxim of Possi-
bility: one should only initiate actions that one expects
to be possible. This means that a speech act should
only be initiated when:
</bodyText>
<listItem confidence="0.8063762">
1. P1 has the appropriate authority or permis-
sion for the speech act; and
2. it appears likely that the specific precondi-
tions associated with the action&apos;s method
can be satisfied.
</listItem>
<bodyText confidence="0.999343833333333">
Only the second case, preconditions, will be consid-
ered here. The ISA forms derived from the first case
all seem to belong to a class that Fraser has called
hedged performatives, and which are well accounted for
in [11].
The approach taken for ISAs based on precondi-
tions will be to distinguish three classes of precondi-
tion and formulate six rules using the classes distin-
guished. The classes will be based on the better-
knowledge principle from the beginning of this section,
specialized in terms of preconditions. The classes of
precondition are as follows:
</bodyText>
<listItem confidence="0.876662">
1. P1-based preconditions
</listItem>
<bodyText confidence="0.999947666666667">
Here P1 has inherently better knowledge of
whether or not the topic of the precondition
holds. The topic of preconditions that begin
here with &amp;quot;P1 believes that P2&amp;quot; is considered to
be the direct object of the initial &amp;quot;believe,&amp;quot; i.e.,
the rest of the precondition. For other precon-
ditions, the topic is the entire pattern. Precondi-
tions that are P1-based represent intentional
states of P1, i.e., beliefs, intentions, wants, de-
sires, and degrees of willingness. An example is
request I, P1 wants P2 to take responsibility for
carrying out the action.
</bodyText>
<sectionHeader confidence="0.761505" genericHeader="method">
2. P2-based preconditions
</sectionHeader>
<bodyText confidence="0.999751428571429">
Here P2 has inherently better knowledge of
whether or not the topic of the precondition
holds. Preconditions that fit this category in-
clude P l&apos;s beliefs about P2&apos;s intentional states.6
An example of a P2-based precondition is
request III, P1 believes that P2 is willing to take
responsibility for carrying out the action.
</bodyText>
<listItem confidence="0.516112">
3. Unmarked preconditions
</listItem>
<bodyText confidence="0.999794">
For these preconditions, determination of which
participant has better knowledge of the precon-
dition depends on properties of the context or
its particular speech act. Examples are request
II and IV.
Using these precondition types, we can construct
the following six rules for ISA forms.
</bodyText>
<equation confidence="0.944484">
PI can convey a speech act indirectly by --
Rule P1-ASSERT:
</equation>
<bodyText confidence="0.989674333333333">
-- asserting a P1-based precondition of the
speech act; e.g.,
&amp;quot;I want you to water the plants.&amp;quot; (request I)
</bodyText>
<equation confidence="0.788479333333333">
&amp;quot;I hope you will use common sense.&amp;quot;
(request I)
Rule P2-ASK:
</equation>
<bodyText confidence="0.9967435">
-- an ask of the topic of a P2-based precondi-
tion of the speech act.
e.g., &amp;quot;Do you want to shut the door?&amp;quot;
(request III)
</bodyText>
<sectionHeader confidence="0.498628" genericHeader="method">
Rule UNMARKED-ASK:
</sectionHeader>
<bodyText confidence="0.9992826">
-- an ask of the topic of an unmarked precondi-
tion of the speech act.
This rule applies in a context where P1 believes
P2 has better knowledge of the condition in the
precondition topic.
</bodyText>
<footnote confidence="0.811962857142857">
e.g., &amp;quot;Is it your turn to do the dishes?&amp;quot;
(request IV)
6 An exception is the degree of knowledge of facts, which will
be classified as an Unmarked condition. There are cases in which
PI is assumed to have better knowledge about what P2 knows or
does not know than P2. Such an assumption underlies the use of
the form &amp;quot;You don&apos;t know &lt;fact&gt;&amp;quot; as a way to state the fact.
</footnote>
<page confidence="0.419654">
156 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980
</page>
<table confidence="0.4780455">
Gretchen P. Brown Characterizing Indirect Speech Acts
Rule UNMARKED-ASSERT:
</table>
<bodyText confidence="0.931309214285714">
-- asserting the topic of an unmarked precondi-
tion of the speech act.
This rule applies in a context where P1 believes
P1 has better knowledge of the condition in the
precondition topic.
e.g., &amp;quot;It&apos;s your turn to do the dishes.&amp;quot;
(request IV)
Rule COMPOSITE-REQUEST:
-- a request form of an action that is a goal of
P1
This rule is applicable only when the speech act
has preconditions that are exact matches or spe-
cializations of the four preconditions of request.
e.g., &amp;quot;Take a cookie.&amp;quot; (offer IV-VII, in Ap-
</bodyText>
<equation confidence="0.851826">
pendix)
Rule COMPOSITE-ASK:
</equation>
<bodyText confidence="0.986187285714286">
-- an ask about whether P2 will take responsi-
bility for carrying out an action that is a goal of
P1.
This rule is applicable only when the speech act
has preconditions that are exact matches or spe-
cializations of the four preconditions of request.
e.g., &amp;quot;Will you accept a ride to the airport?&amp;quot;
</bodyText>
<equation confidence="0.636062">
(offer IV-VII, in Appendix)
</equation>
<bodyText confidence="0.941776">
The rules as written do not account for differences
in tense and mood. That is, the UNMARKED-ASK
rule accounts for example 4.3 but not 4.4 and 4.5.
4.3 Are you able to drive Sarah to school?
4.4 Will you be able to drive Sarah to school?
4.5 Would you be able to drive Sarah to school?
Examples 4.4 and 4.5 can be handled as legitimate
requests if we extend the rules to account for a wider
range of tense and mood behavior. See [4] for sugges-
tions.
The &amp;quot;possibility&amp;quot; rules given also do not derive
&amp;quot;not&amp;quot; forms, i.e. strategy-3 rules related to whether an
action is impossible.
</bodyText>
<listItem confidence="0.634343428571429">
4.6 Shouldn&apos;t you shut the door?
4.7 Can&apos;t you shut the door?
Note, however, that the rules given can be used as
patterns for producing rules that account for examples
4.6 and 4.7. Any of the rules above that involve an
ask have rule counterparts with not inserted after the
ask.&apos;
</listItem>
<bodyText confidence="0.985691181818182">
In terms of specific rules, UNMARKED-ASSERT
may seem odd when applied to preconditions involving
7 This is a change from [4], where the &apos;&apos;not&apos;&apos; forms were seen
as realizations of a different speech act, with different precondi-
tions. The &amp;quot;not&amp;quot; forms are now seen as requests with a particular
set of connotations. The motive for the change is to make the
&amp;quot;possibility&amp;quot; rules consistent with the rules for the maxims of Ne-
cessity and Desirability by allowing the strategy of questioning
whether a condition does not hold.
capability, producing indirect requests such as example
4.8.
</bodyText>
<subsectionHeader confidence="0.792152">
4.8 You can open the door.
</subsectionHeader>
<bodyText confidence="0.998740297297297">
Such forms do occur, however, particularly in requests
to children where there may be some question of the
child&apos;s capability to perform the action requested.
COMPOSITE-REQUEST and COMPOSITE-ASK
differ most from rules in previous theories because
they are based on groups of preconditions. The
COMPOSITE-ASK rule is of special interest. In
Searle&apos;s scheme, the very common &amp;quot;Will you
&lt;action&gt;?&amp;quot; form is derived from the propositional
content condition of directives (the class that includes
request). This approach seems to produce the correct
forms, but it is basically a structural account, without
strong semantic motivation. Instead, the approach
taken here is to appeal to the Maxim of Possibility.
The appearance of the four request preconditions in a
set of preconditions indicates an action that P1 wants
done. We can think of a speech act with this precon-
dition subset as an act with a component request. By
using a &amp;quot;will&amp;quot; form to perform the speech act, e.g. the
offer example 4.1, P1 is asking a question about how
P2 will respond to the offer, i.e., whether the compo-
nent request will have a satisfactory response. When
the speech act is itself a request, then the question in
the &amp;quot;will&amp;quot; form is whether the speech act as a whole
will have a satisfactory response.
The distinction between P1-based, P2-based, and
Unmarked preconditions is probably uncontroversial;
the question is whether the categories should be given
a primary place in the theory. The reason that the
better-knowledge split has been given a central place
is that there is then a distinction between knowledge
about a precondition that is independent of context
(P1- and P2-based) and that which is not (Unmarked).
Instead of deriving the invariant knowledge from first
principles each time, it is &amp;quot;precompiled&amp;quot; into the rules.
This choice reflects an approach that will be discussed
in Section 6.
</bodyText>
<subsectionHeader confidence="0.996956">
4.5. The Scope of the Rules
</subsectionHeader>
<bodyText confidence="0.9898056">
Starting with a general evaluation of the scope of
the rules, note that they do not account for such phe-
nomena as sarcasm, jokes, or failure to make standard
choices (e.g., P1 makes an utterance and has not de-
cided whether it is a question or a request for a non-
verbal action). Another phenomenon specific to
speech acts that complicates theory building is what
can be called force shift. This occurs when one speech
act form is used to &amp;quot;masquerade&amp;quot; as another. For
example, one may use a suggestion form such as &amp;quot;How
about picking up the blocks now?&amp;quot; in an environment
where authority and role relationships make it clear
that the utterance is functioning as a command. In
American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 157
Gretchen P. Brown Characterizing Indirect Speech Acts
general, force shift seems to be used to give P1 the
appearance of greater benevolence or to save face for
P2.
What these phenomena have in common, I think, is
their &amp;quot;second order&amp;quot; nature. All can be seen as pre-
supposing a set of rules and then deviating from them.
I expect these phenomena to be modelled by the
mechanisms for rule application, not accounted for by
individual rules alone. Since such mechanisms could
be expected to build on, and interact with, the &amp;quot;first
order&amp;quot; rule application mechanism, these phenomena
have been considered beyond the scope of the current
investigation.
The rules in this section are proposed to hold for
speech acts in general. ISAs are not grounded solely
in individual speech acts, as for Gordon and Lakoff, or
even in types of speech acts as for Searle. Instead,
they are related to a broader view of rational action
analogous to that expounded by Grice. Speech acts,
because they are actions, do have structural compo-
nents that play an important part in the derivation of
ISAs. The driving force behind ISAs, however, is the
process of goal formation, i.e. the process of deciding
whether to adopt a speech act as a goal. This process
is reflected in the three maxims that were used as a
conceptual organization for the presentation. This
emphasis on the goal formation process is closely rela-
ted to the work of Allen, Cohen, and Perrault
[1,8,21]. The similarities and differences between the
two approaches are discussed in Section 6.
</bodyText>
<sectionHeader confidence="0.903784" genericHeader="method">
5. Relating Utterances to the General Rules
</sectionHeader>
<bodyText confidence="0.9999562">
The general ISA rules in the last section were illus-
trated with English sentences, but nothing has as yet
been said about the correspondence between particular
utterances and rules. This section discusses in broad
terms the nature of the correspondence, focusing on
differences in complexity. Because the topic is diffi-
cult to present in a neutral way, it will be approached
from the point of view of language recognition, i.e.,
matching utterances against rules. Much of what is
said, however, is relevant for generation as well. Note
that discussion in this section is restricted to the issue
of proposing correct matches; issues related to choos-
ing between alternative interpretations of an utterance
(i.e., alternative matches) are deliberately avoided.
(See, however, [41).
</bodyText>
<subsectionHeader confidence="0.999435">
5.1. Levels of Matching Complexity
</subsectionHeader>
<bodyText confidence="0.999755428571429">
Any discussion of matching rests on a set of as-
sumptions about the representations involved. We
briefly outline some of the assumptions made here,
starting with a distinction between two levels of repre-
sentation: surface and internal.
Each utterance is expected to have (at least) a
surface representation and an internal representation.
Internal representations are also used for action struc-
tures, including preconditions, and for ISA rules and
patterns. Internal representations are organized in a
knowledge base according to a semantic network for-
malism. Surface representations closely reflect the
surface form of an utterance, and only those distinc-
tions forced by the parsing process are made. Thus,
noun group references not needed by the parser may
remain unresolved (e.g., &amp;quot;I saw him&amp;quot;). Choices
among systematically ambiguous relationships of con-
stituents and choices among ambiguous word senses
also need not be made unless they are forced. ISA
forms are preserved; e.g., &amp;quot;Can you close the door?&amp;quot;
would have a surface representation that records its
interrogative nature and that contains a surface item
corresponding to &amp;quot;can.&amp;quot;
An important implication of these attributes is that
surface representation draws from a different vocabu-
lary of semantic items than internal representation.
For example, the surface item &amp;quot;believe&amp;quot; used in repre-
senting &amp;quot;I believe you&apos;re right&amp;quot; is related to, but is not
the same as, the internal item &amp;quot;believe&amp;quot; that corre-
sponds to the general idea-holding concept from Sec-
tion 3.3. Surface items do, however, have associated
internal level definitions which specify the ways that
they can be translated into internal level representa-
tions. These definitions include various potential
translations; context is typically called on in each indi-
vidual case to choose among alternatives and to speci-
fy details.
The problem for ISA matching, then, is to relate
the definitions of items in the surface representation of
an ISA to ISA patterns. The ISA patterns are pro-
duced by applying the general rules from the last sec-
tion to the method representations of particular speech
acts. Matching will be discussed using as an example
the pattern produced by applying rule UNMARKED-
ASK to request precondition II:
P1 asks whether P2 can take responsibility
for carrying out action A.
Consider, then, the following examples interpreted as
indirect requests.
</bodyText>
<footnote confidence="0.884992444444445">
5.1 Can you close the door?
5.2 Are you able to close the door?
5.3 Are you permitted to close the door?
5.4 Can you please close the door?
5.5 Will you be home in time to walk the dog?
5.6 Have you got a hammer to put up that hook?
5.7 Must you smoke?
5.8 Can you reach the salt?
5.9 It&apos;s cold in here.
</footnote>
<page confidence="0.715859">
158 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980
</page>
<bodyText confidence="0.99121086440678">
Gretchen P. Brown Characterizing Indirect Speech Acts
Examples 5.1 to 5.3 can be handled by a set of
general purpose matching rules that reflect hierarchical
relationships in the knowledge base. The &amp;quot;can&amp;quot; in
example 5.1 matches can in the above ISA pattern,
since we can expect surface &amp;quot;can&amp;quot; to have internal can
as a major part of its associated definition. (Other
components in the definition might include the conno-
tations of the lexical item.) Similarly, &amp;quot;are you able&amp;quot;
in example 5.2 is an exact match, since we can also
expect its associated definition to contain can as a
component. In example 5.3, &amp;quot;permitted&amp;quot; has may as a
component in its definition, and in the knowledge base
may is a specialization (i.e., subclass) of can.
The important point in these matches is that ele-
ments of internal level definitions of surface items are
related to elements of ISA patterns via the hierarchical
relationships of the knowledge base, i.e., via prede-
fined classification links. Thus, proposing the request
interpretation for examples 5.1 to 5.3 involves rela-
tively well understood knowledge base manipulations.
Example 5.4 is a typical utterance that is not ac-
counted for by the ISA patterns given. The problem is
that example 5.4, a question according to its interroga-
tive form, contains &amp;quot;please&amp;quot;, a construct reserved for
request and related speech acts. Utterances of this
form have been much-discussed in the literature (e.g.
Sadock [22], Searle [25], and Morgan [20]). The
question is whether this form has evolved to the point
that it is &amp;quot;really&amp;quot; a request only, no longer also a ques-
tion. The interest is fueled by questions of the nature
of meaning that are involved. Because I am interested
in focusing on generalizations possible about ISAs,
these issues will be omitted from discussion here. It is
worth noting, however, that, whatever the ultimate
theoretical disposition of these forms may be, they will
probably have to be handled in a computational sys-
tem by specialized patterns, to represent their unique
properties. One such representation scheme, closely
related to Morgan&apos;s notion of short-circuited
entailment, is given in [4].
The rest of the examples above, 5.5 through 5.9,
can be related to the &amp;quot;can&amp;quot; request pattern in a regular
fashion, but they require a richer set of matching rela-
tionships. Example 5.5 is typical of examples for
which proposing a match may turn out to involve arbi-
trarily complex inference. To begin to account for
example 5.5, we can posit some link between can in
the ISA pattern and a representation for being in the
appropriate spatial proximity to do an action. This
link may be hierarchical, or part of a definition related
to the internal node can, or both.
This treatment does not, however, fully solve the
problem exemplified by example 5.5. There is still a
good distance between the relationship of being at
home with a dog and the idea of being in the right
range to perform the action of taking it for a walk.
The level of detail in the utterance is so much more
specific than the level of detail in the pattern that we
cannot expect a match by merely traversing precom-
puted links in a knowledge base. Another difference
between 5.5 and the previous examples is that the
knowledge needed to propose the match may go be-
yond information conveyed by the utterance to infor-
mation from the surrounding context. Either of these
two factors has the potential to turn the process of
proposing interpretations for utterances such as exam-
ple 5.5 into a full-blown inference process, with all the
attendant difficulties in controlling the inference.
The rest of the examples can be expected to be
more tractable, because we can take advantage of
specialized links in the model of actions introduced in
Section 3. Example 5.6 makes a &amp;quot;can you&amp;quot; request by
asking whether P2 has an assignment (the hammer)
for the instrument semantic case of the action (putting
up a hook). Several different types of semantic cases
can be queried in this way (see [4]); the structural
model of actions supplies links between actions and
their cases that can be traversed in this match.
For examples 5.7 to 5.9, we can again exploit the
model of actions to propose matches. The three ex-
amples may have request interpretations where the
actions intended are, respectively, that P2 stop smok-
ing, pass the salt, and close the window. Note that
none of the three examples describes these actions
explicitly, and for that reason I have called utterances
of this class implicit-action ISAs. These three exam-
ples represent three classes of implicit-action ISAs,
which differ in the complexity of the search needed to
propose a match. For example 5.7 there is essentially
no search; the implicit action is merely that P2 stop or
avoid the action named. Example 5.8 names a prere-
quisite of the implicit salt passing action. Recall from
Section 3.1 that prerequisites are among the basic
parts of methods. Other components of actions, in-
cluding semantic input cases, steps, and principal re-
sults, may also be used in implicit-action ISAs. All of
these are related to the action by the explicit links of
the method representation. Finally, example 5.9 al-
ludes to the intended action by stating a basis for the
action, i.e., a condition seen as sufficient to warrant
the action. &amp;quot;Basis for action&amp;quot; can be related to the
structural links of methods (see [4]), but the relation-
ship between the condition named in the utterance and
the implicit action is relatively complex. Implicit-
action ISAs are discussed in more detail in [5].
We have, then, classes of utterances that obey rela-
tively constrained matching relationships and classes
that could involve an arbitrary inference process to
propose interpretations. In between is a set of utter-
ances for which proposal of interpretations can utilize
structural links within action representations. Difficult
problems of search and knowledge structuring remain
American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 159
Gretchen P. Brown Characterizing Indirect Speech Acts
unsolved, but the links identified at least specify the
types of paths that we can expect to see in matches of
ISA patterns.
</bodyText>
<subsectionHeader confidence="0.99146">
5.2. Embedded ISAs
</subsectionHeader>
<bodyText confidence="0.999968666666667">
In the discussion of matching, the initial assumption
was that matching of surface representations occurred
against patterns produced by single applications of
rules to speech act methods. This assumption makes
no provision for embedded forms. Some evidence
does exist for this approach. For example, Sadock
[22], in another context, observes that 5.10 is not a
request for the hearer to move over, even though the
similar form 5.11 is.
</bodyText>
<listItem confidence="0.716606">
5.10 Tell me if you can move over.
5.11 Can you move over?
</listItem>
<bodyText confidence="0.964514555555556">
In terms of the rules presented in Section 4, a request
interpretation for 5.10 could only come from an em-
bedded rule application: the UNMARKED-ASK rule
applied to request II, resulting in ask, then the
COMPOSITE-REQUEST rule applied to four of the
preconditions of ask (see the Appendix). Forbidding
such a double application effectively blocks a request
interpretation, leaving only the information-seeking
alternative.
This straightforward solution, augmented by vari-
ous classes of exceptions, was adopted in [4]. The
embedded examples that have accumulated since, how-
ever, are too numerous to be accounted for simply as
exceptions. Consider the following indirect requests:
5.12 I wonder if you can move over.
5.13 I believe it&apos;s your turn to do the dishes.
For 5.12, the internal level definition of wonder would
include the following information:
</bodyText>
<listItem confidence="0.914035">
P1 wonder if &lt;action or state&gt;
1. P1 wants to know if &lt;action or state&gt;
2. P1 is speculating if &lt;action or state&gt;
</listItem>
<bodyText confidence="0.988521278688525">
Example 5.12 is characterizable by applying rule P 1-
ASSERT to ask I (P1 wants to know the answer to the
question) after applying rule UNMARKED-ASK to
request II. Example 5.13 is characterizable by apply-
ing rule P1-ASSERT to state I (P1 believes X is a
fact) after applying rule UNMARKED-ASSERT to
request IV.
These examples, and others like them, seem to be
best accounted for by politeness conditions.8 In partic-
ular, I suggest the following hypothesis: embedding of
general ISA rules is permitted when it furthers the
politeness intentions of P1, either to heighten polite-
8 &amp;quot;Politeness&apos;&apos; is used here quite broadly to include not only
observation of the conventions of etiquette, but also the expression
of respect for the other participant and the expression only of
emotions harmonious with the social expectations associated with
the conversational environment.
ness or to lessen it. These processes are referred to
here as mitigation and aggravation, respectively. (The
terms are borrowed from Labov and Fanshel [16] but
apply to a somewhat broader range of phenomena
here.) Embeddings within rules that are unmarked for
politeness are forbidden, as are embeddings where the
rules involved have conflicting politeness markings.
Evidence for this hypothesis is found in comparing
example 5.12 to 5.14:
5.14 I want to know if you can move over.
Example 5.14 is derivable from the same set of rules
as 5.12, but 5.12 conveys a request force while 5.14
does not. The reason for this, I suggest, is that the
UNMARKED-ASK rule is a mitigator: questions, in
general, promote politeness by giving P2 an opportuni-
ty to answer, allowing P2 to refuse to accept P l&apos;s
goals in uttering the speech act. &amp;quot;I wonder&amp;quot; is similar-
ly undemanding: the emphasis is more on the specula-
tion process P1 is involved in than the &amp;quot;wanting to
know&amp;quot; aspect. In contrast, the &amp;quot;I want to know&amp;quot; in
5.14 works in the direction of aggravation. A goal
stated explicitly leaves P2 very little room to refuse P1
without doing so explicitly. In narrowing P2&apos;s options,
P1 has lowered the level of politeness. Example 5.12,
then, with both rule applications working in the direc-
tion of mitigation, is a permitted embedding. Example
5.14, with one rule application producing mitigation
and one aggravation, is blocked as an indirect request.
This approach can also be used to explain the block
on embedding in example 5.10. The COMPOSITE-
REQUEST rule realized with an imperative is not a
mitigator, while the UNMARKED-ASK rule realized
with a question is. Thus, the indirect request interpre-
tation is blocked.
The examples presented make a case for the use of
politeness conditions to govern ISA rule embedding,
but it must be emphasized that more work is needed.
Despite the work on politeness conditions, much of
this area is not well understood. (For three different
perspectives on the implications of ISA choices, see
Lakoff [17], Davison [9], and Ervin-Tripp [10].) Con-
clusive proof or disproof of the hypothesis awaits an
analysis of the implications of ISA choices at a level of
detail and completeness that is not yet available.
</bodyText>
<sectionHeader confidence="0.892274" genericHeader="method">
6. Computational Implications
</sectionHeader>
<bodyText confidence="0.983585987878788">
This paper has characterized a significant number
of ISA forms, with attention to representational issues.
As noted in the introduction, these are the only claims
made, although the ultimate motivation of the work
was not only computational but was directed by a
particular computational philosophy of language recog-
nition. This philosophy will be described briefly here,
with emphasis on the way that the theory presented
fits into it. Due to the number of issues involved, I
160 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980
Gretchen P. Brown Characterizing Indirect Speech Acts
will again consider only ISA pattern identification, i.e.
proposing the candidate matches for a particular utter-
ance form. Issues related to choosing between alter-
natives are discussed in [4], along with a framework
for using dialogue context to aid in this choice. The
approach to ISA pattern identification suggested will
be contrasted with two other computational ap-
proaches, that of Moore, Levin, and Mann [18,19] and
Allen, Cohen, and Perrault [1,8,21]. We start with a
summary of each approach.
The central structure in the process model of dia-
logue developed by Moore, Levin, and Mann is called
the dialogue game. Dialogue games are procedures
that include steps for speech acts and their standard
range of responses. Indirect speech act forms are
related to these larger structures according to the gen-
eral principle that any utterance that can establish the
parameters of a dialogue game can serve as an ISA.
For recognition, the correspondence between particu-
lar ISAs and parameters is done by applying rule-like
transformations using partial match and plausible in-
ference techniques. Representations of utterances are
placed in a pool of facts about the dialogue where
correspondences are drawn by highly parallel
&amp;quot;anarchic&amp;quot; control structures.
The second computational approach to ISAs, that
of Allen et al., focuses on the speech act planning
process. Allen&apos;s work is most relevant here, because it
deals in detail with ISA recognition. Allen introduces
the notion of an obstacle, a type of condition in the
speech act planning process that provides the subject
matter for many varieties of ISAs. This approach
appears to generate a more constrained set of possible
ISA forms than the approach of Moore et al. and gives
more basis for an explanation of the variety of forms.
To draw the correspondence between ISAs and speech
act plans, Allen et al. propose a general inference
process guided by heuristics such as the principle that
inference stops when a non-obvious condition is pro-
posed as the topic of the ISA.
These approaches and the one advocated here have
in common the reliance on representation of actions to
characterize indirect speech acts. Allen, Cohen, and
Perrault view the speech act as an independent unit;
Moore, Levin and Mann relate ISAs to larger units of
activity that have speech act components and that are
defined according to the goals achieved by the speech
acts. This difference between the approaches of Allen
et al. and Moore et al. is, I think, primarily one of
presentation rather than substance. The approach
advocated here is a combination of the two perspec-
tives. A complete system would need both the ability
to handle the prototype speech act plus response se-
quences (called core dialogue methods in [4]) and the
ability to treat speech acts as basic building blocks
within other sequences. By focusing on independent
speech acts in this paper, I do not intend to rule out
their incorporation within larger actions.
A more substantive difference among the ap-
proaches is the mechanism envisioned for drawing
correspondences between individual ISAs and ISA
patterns. Both of the approaches summarized above
are theoretical in a traditional sense, in that they posit
one mechanism powerful enough to account for any
utterance, i.e., a mechanism powerful enough to han-
dle the most difficult case. Coupled with the interest
in maximizing power is the interest in maximizing sim-
plicity; redundancy in the representation structure is
not expected or exploited.
In contrast, the proposals in this paper are motivat-
ed by an &amp;quot;appropriate technology&amp;quot; view of ISA pat-
tern identification. From this perspective, ISA pat-
terns are assumed to be particularly adapted to com-
munication, so that identifying candidate ISA patterns
is not typically a general problem solving process. (I
emphasize here pattern identification; choosing be-
tween the alternative candidates identified appears to
be a more open-ended process.) Given these assump-
tions, the search is for a way to identify the most fre-
quently used ISA forms simply, short of full-blown
problem solving. The solution could include a hier-
archy of processing strategies, differentiated to handle
different levels of complexity.
The descriptive model presented in the preceding
sections relates to this philosophy on two counts:
matching processes and the choice of levels of repre-
sentation. Each is considered in turn.
Section 5 described several different types of match
between particular ISA representations and patterns:
first, those matches using only predefined classification
links in the knowledge base; second, those requiring
evaluation of representations, possibly augmented by
contextual information, to establish classification links;
and, third, those using definition and method compo-
nent links, again with or without the use of additional
contextual information. While these distinctions can
be used to guide a general inference mechanism, they
could also be used in the development of specialized
matching strategies, to take advantage of properties of
the representations and links involved.
Along with the use of specialized processors for
ISA pattern identification can come the use of special-
ized, and to an extent redundant, representations.
This is most evident in the preceding pages in the dis-
tinction between using the goal formation process as a
conceptual organization of ISAs (and, hence, to an
extent as an explanation) versus its use as a direct
basis for drawing correspondences with individual
ISAs. The ISA patterns assumed are at least three
levels removed from any actual goal formation proce-
dure: the use of maxims is an abstraction of the proce-
American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 161
Gretchen P. Brown Characterizing Indirect Speech Acts
dure; generalized rules are based on maxims; and then
ISA patterns are produced by applying rules to indi-
vidual speech acts. This is in contrast to plan deduc-
tion of Allen et al., which uses only very general rules
coupled with the representations of the plan deduction
process. Similarly, what was called the better-
knowledge principle was &amp;quot;precompiled&amp;quot; into rules,
rather than combined with more general rules by infer-
ence. The thrust of the effort is to push ISA patterns
to a level as close as possible to the representations of
particular ISAs; in fact, in many cases this paper has
not gone as far as possible, and I think, as ultimately
desirable, in producing highly specific ISA patterns.
This representational style is expected to have three
effects. First, for many cases, it avoids problems in-
herent in general inference processes of controlling the
direction of inference toward the &amp;quot;interesting&amp;quot; cases.
Second, the more specialized the patterns, the simpler
the individual match processes, and the more forms
can be handled by cheaper processes. Third, the vari-
ous ISA patterns give a natural place to associate in-
formation about idiomaticity and specialized informa-
tion about implications of ISA choice.
Note that these various mechanisms and represent-
ations cannot be introduced arbitrarily. To be effec-
tive, they must be chosen based on an understanding
of the structure of indirect speech act classes, i.e. on
an appropriate descriptive theory. This brings us back
to the original claims of the paper; it is hoped that the
proposals made are a step toward such a theory.
Finally, it should be emphasized that the computa-
tional apparatus sketched here complements, rather
than seeks to replace, a generalized problem solving
mechanism for ISA pattern identification. The hy-
pothesis is that only a relatively small proportion of
ISAs require the more general (and more expensive)
mechanism. It is possible that the use of redundant
mechanisms and representations can lead to good com-
putational solutions to the problem of modelling a
large body of indirect speech acts.
Appendix. Indirect Forms for Sample Speech Acts
</bodyText>
<listItem confidence="0.8151866">
• ask
propositional content: some question
performative: I ask you ...
other direct form:
&lt;interrogative&gt; e.g., Where&apos;s the mustard?
</listItem>
<bodyText confidence="0.701453">
principal intended effect: that P2 tell P1 the answer to
the question in the propositional content
</bodyText>
<footnote confidence="0.57583225">
Rule NECESSARY-ASSERT:
I have to ask you where the mustard is.
Rule NECESSARY-ASK:
Do I need to ask you where the mustard is?
</footnote>
<table confidence="0.903632714285714">
Rule EQUI-ASK:
Did I ask you where the mustard is?
Rule FUTURE-EFFECT-ASK:
Do you intend to tell me where the mustard is?
Rule PAST-EFFECT-ASK:
Did you tell me where the mustard is?
Rule DESIRABLE-ASSERT:
</table>
<bodyText confidence="0.937436625">
I&apos;ll be able to finish these sandwiches if you tell
me where the mustard is.
Rule DESIRABLE-ASK:
Will you feel better if you tell me where the mus-
tard is?
Rule UNDESIRABLE-ASK:
Will you be angry if I ask you where the mustard
is?
</bodyText>
<subsubsectionHeader confidence="0.444564">
Precondition-Based Examples
</subsubsectionHeader>
<bodyText confidence="0.9678148">
I. P1 wants to know the answer to the question.
(Want here and in IV implies that P1 does not al-
ready know the answer. The case where P1 does
know and merely wants to know if P2 knows -- and
where P2 knows that Pl. knows -- is classed as an-
other speech act. Know is considered to be a re-
stricted form of believe; while anything can be be-
lieved, only facts can be known. For ask, the
&amp;quot;fact&amp;quot; is that some proposition is the answer to the
question.)
</bodyText>
<equation confidence="0.366037">
Rule P1-ASSERT:
</equation>
<bodyText confidence="0.9879126">
I want to know where the mustard is.
II. P1 believes that P2 can tell the answer to the ques-
tion.
(Tell is used here and below to mean &amp;quot;utter a repre-
sentative&amp;quot;; see Searle [261.)
</bodyText>
<sectionHeader confidence="0.503521" genericHeader="method">
Rule UNMARKED-ASK:
</sectionHeader>
<bodyText confidence="0.845723">
Can you tell me where the mustard is?
</bodyText>
<sectionHeader confidence="0.608286" genericHeader="method">
Rule UNMARKED-ASSERT:
</sectionHeader>
<bodyText confidence="0.931216230769231">
You can tell me where the mustard is.
III. P1 believes that P2 is willing to tell the answer to
the question.
Rule P2-ASK:
Would you be willing to tell me where the mus-
tard is?
IV. P1 wants P2 to tell P1 the answer to the question.
Rule P1-ASSERT:
I&apos;d like you to tell me where the mustard is.
V. P1 believes that P2 has some obligation (a role
obligation, authority obligation, or general obligation
to be cooperative) to P1 to tell P1 the answer to the
question.
</bodyText>
<sectionHeader confidence="0.563617" genericHeader="method">
Rule UNMARKED-ASK:
</sectionHeader>
<bodyText confidence="0.920995611111111">
? Should you tell me where the mustard is?
(Although it is possible to construct contexts in
which this form can be used, it seems to be
only marginal. Forms such as &amp;quot;Shouldn&apos;t you
162 American Journal of Comp utational Linguistics, Volume 6, Number 3-4, July-December 1980
Gretchen P. Brown Characterizing Indirect Speech Acts
tell me ...?&amp;quot; and &amp;quot;Don&apos;t you think you should
tell me...?&amp;quot; are far more common. Perhaps this
is because the &amp;quot;should&amp;quot; form is too neutral
with respect to the obligation. To the extent
that the obligation is motivated by Pl&apos;s wants
or needs, then P1 defines the obligation. Even
for other obligations, situations are scarce in
which 131 can reasonably be presented as neu-
tral about the existence of the obligation. In
most cases, to successfully carry out the speech
act, P1 must use a form that conveys P 1 &apos;s be-
lief that the obligation exists.)
</bodyText>
<figure confidence="0.836298375">
Rule UNMARKED-ASSERT:
You ought to tell me where the mustard is.
II-V together:
Rule COMPOSITE-REQUEST:
Tell me where the mustard is.
Rule COMPOSITE-ASK:
Will you tell me where the mustard is?
• state
</figure>
<figureCaption confidence="0.370964666666667">
propositional content: some proposition that P1 be-
lieves to be open to confirmation against what P1
believes is commonly held to be reality
</figureCaption>
<bodyText confidence="0.931769">
(This is contrasted with opinions, e.g., judgments
about tastes, which are assumed to be conveyed
by a different type of speech act.)
performative: I state that ...
other direct form: &lt;declarative&gt; e.g., Your candidate
is a convicted felon.
principal intended effect: that P2 come to know the
proposition at the same level of detail and certainty as
P1
</bodyText>
<sectionHeader confidence="0.681308" genericHeader="method">
Rule NECESSARY-ASSERT:
</sectionHeader>
<bodyText confidence="0.992235">
I have to tell you that your candidate is a convict-
ed felon.
</bodyText>
<sectionHeader confidence="0.723999" genericHeader="method">
Rule NECESSARY-ASK:
</sectionHeader>
<bodyText confidence="0.9544505">
Do I need to tell you that your candidate is a
convicted felon?
</bodyText>
<sectionHeader confidence="0.75087" genericHeader="method">
Rule EQUI-ASK:
</sectionHeader>
<bodyText confidence="0.958018">
Has anybody told you that your candidate is a
convicted felon?
</bodyText>
<sectionHeader confidence="0.489738" genericHeader="method">
Rule FUTURE-EFFECT-ASK: GAP
</sectionHeader>
<bodyText confidence="0.98055125">
(Once a fact is mentioned, inquiry about future
knowledge of that fact is irrelevant. This rules
out forms such as &amp;quot;Will you hear that...?&amp;quot; and
&amp;quot;Will you know that ...?&apos;&amp;quot;)
</bodyText>
<figure confidence="0.571248444444444">
Rule PAST-EFFECT-ASK:
Did you hear that your candidate is a convicted
felon?
Rule DESIRABLE-ASSERT:
It&apos;s important that you hear that your candidate is
a convicted felon.
Rule DESIRABLE-ASK:
? Is it helpful for you to hear that your candidate
is a convicted felon?
</figure>
<bodyText confidence="0.9920958">
(The stative form &amp;quot;Is it helpful for you to know
that...?&amp;quot; is much more acceptable. This form
would be derived using DESIRABLE-ASK and an
implicit-action rule. See Section 5 for general
discussion.)
</bodyText>
<figure confidence="0.502275857142857">
Rule UNDESIRABLE-ASK:
Will you be angry if I tell you that your candidate
is a convicted felon?
Precondition-Based Examples
I. P1 believes that some proposition is a fact.
Rule P1-ASSERT:
I think that your candidate is a convicted felon.
</figure>
<bodyText confidence="0.882618580645161">
II. P1 believes that P2 does not know the proposition
at the same level of detail and certainty that P1 does.
(The mention of &amp;quot;level of detail&amp;quot; here is motivated
by an interest in including statements which could
otherwise be mistakenly classed as redundant. For
example, if P2 knows that it is raining, then the
statement &amp;quot;It&apos;s raining&amp;quot; should be a violation of
precondition II; a statement such as &amp;quot;It&apos;s pouring,&amp;quot;
however, should not.)
Rule UNMARKED-ASK:
Are you unaware that your candidate is a con-
victed felon?
Rule UNMARKED-ASSERT:
You don&apos;t know that your candidate is a con-
victed felon.
III. P1 wants P2 to know the proposition at the same
level of detail and certainty that P1 does.
Rule P1-ASSERT:
I want you to know that your candidate is a
convicted felon.
IV. P1 believes that it is in P 1 &apos;s, P2&apos;s, or someone
else&apos;s interest that P2 know the proposition at the
same level of detail and certainty that P1 does.
Rule UNMARKED-ASK:
Should you know that your candidate is a con-
victed felon?
Rule UNMARKED-ASSERT:
You should know that your candidate is a con-
victed felon.
American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 163
Gretchen P. Brown Characterizing Indirect Speech Acts
</bodyText>
<listItem confidence="0.657243">
• offer
</listItem>
<bodyText confidence="0.954685428571429">
propositional content: some action that P1 believes
will be of benefit to P2
performative: I offer you ...
other direct form: none
principal intended effect: that P2 accept Pl&apos;s commit-
ment to take responsibility for the action in the propo-
sitional content
</bodyText>
<sectionHeader confidence="0.66964" genericHeader="method">
Rule NECESSARY-ASSERT:
? I must offer you a ride to the airport.
</sectionHeader>
<bodyText confidence="0.912469366666667">
(In general, necessity alone is not considered to
be enough to motivate an offer, although in prac-
tice, of course, it may be the sole motivation.
The propositional content specification of offer
includes the notion of benefit to P2, so P1 is ex-
pected to have the well-being of P2 in mind. The
statement of necessity alone clashes with this ex-
pected benevolence. The only way that this ex-
ample form could be used for a sincere offer is if
must is used in the same way as in the polite offer
cited by R.Lakoff, &amp;quot;You must have some cake.&amp;quot;)
Rule NECESSARY-ASK:
?Do I need to offer you a ride to the airport?
(Beyond the considerations noted for the
NECESSARY-ASSERT example, this form seems
to be marginal due to the conflict between its
angry connotations and the level of politeness
involved in an offer.)
Rule EQUI-ASK:
Has anybody offered you a ride to the airport?
Rule FUTURE-EFFECT-ASK: GAP
(This gap is explained by the fact that the princi-
pal intended effect for offer can be brought about
only by the speech act; there is no independent
means of achieving it.)
Rule PAST-EFFECT-ASK:
Have you already accepted a ride to the airport?
Rule DESIRABLE-ASSERT:
I&apos;d feel a lot better if you&apos;d accept a ride to the
airport.
</bodyText>
<sectionHeader confidence="0.802313" genericHeader="method">
Rule DESIRABLE-ASK:
</sectionHeader>
<bodyText confidence="0.999724333333333">
? Will you stop worrying if you accept a ride to
the airport?
(An elaboration of this rule may be warranted,
since a form that explicitly names the speech act
is much more acceptable, e.g., &amp;quot;Will you stop
worrying if I offer you a ride to the airport?&amp;quot; It is
not clear, however, exactly how to proceed, since
comparable &amp;quot;explicit speech act&amp;quot; forms for request
and suggest do not seem to exist.)
</bodyText>
<sectionHeader confidence="0.570188" genericHeader="method">
Rule UNDESIRABLE-ASK:
</sectionHeader>
<bodyText confidence="0.9075145">
Will you be offended if I offer to loan you some
money?
</bodyText>
<figure confidence="0.9385348">
Precondition-Based Examples
I. P1 wants to take responsibility for the action.
Rule P1-ASSERT:
I want to drive you to the airport.
II. P1 believes that P1 can take responsibility for Pl&apos;s
part of the action.
Rule UNMARKED-ASK:
Can I drive you to the airport?
Rule UNMARKED-ASSERT:
I can drive you to the airport.
</figure>
<figureCaption confidence="0.5759665">
III. P1 is willing to take responsibility for Pl&apos;s part of
the action.
</figureCaption>
<bodyText confidence="0.92253975">
Rule P1-ASSERT:
I&apos;m more than willing to drive you to the air-
port.
IV. P1 wants P2 to perform some action that comple-
ments Pl&apos;s part of the action.
(Examples of complementary actions would be
physically taking food offered by a hostess or get-
ting into a car and sitting in response to an offer of
a ride from a friend. A general way to refer to P2&apos;s
performance of a complementary action in response
to an offered action is to say that P2 accepted, e.g.,
&amp;quot;Jane thanked Paula and accepted the gift.&amp;quot;)
Rule P1-ASSERT:
I want you to accept a ride to the airport.
V. P1 believes P2 can perform some action that com-
plements Pl&apos;s part of the action.
</bodyText>
<sectionHeader confidence="0.484031" genericHeader="method">
Rule UNMARKED-ASK:
</sectionHeader>
<bodyText confidence="0.817978">
Can you accept a ride to the airport?
</bodyText>
<sectionHeader confidence="0.495834" genericHeader="method">
Rule UNMARKED-ASSERT:
</sectionHeader>
<bodyText confidence="0.974671105263158">
You can accept a ride to the airport.
VI. P1 believes that P2 would be willing to perform
some action that complements Pl&apos;s part of the action.
Rule P2-ASK:
Would you be willing to accept a ride to the
airport?
VII. P1 believes that P2 has an obligation (to &amp;quot;be
cooperative&amp;quot;) to P1 to perform some action that com-
plements Pl&apos;s part of the action.
(It is generally in P2&apos;s interest to accept an offer,
and so one of the obligations involved in accepting
an offer is P2&apos;s obligation to further his or her own
self interest. Beyond, this, however, P2 has an obli-
gation to help further Fl &apos;s goals by virtue of a gen-
eral social obligation to be cooperative. In accept-
ing an offer, P2 is enhancing Pl&apos;s image as a benev-
olent person, Pl&apos;s satisfaction in giving, etc. By
accepting, then, P2 is furthering Pl&apos;s goals and be-
ing &amp;quot;cooperative.&amp;quot;)
</bodyText>
<sectionHeader confidence="0.589322" genericHeader="method">
Rule UNMARKED-ASK:
</sectionHeader>
<bodyText confidence="0.762719125">
? Should you accept a ride to the airport?
(See discussion for ask V.)
Rule UNMARKED-ASSERT:
You must accept a ride to the airport.
164 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980
Gretchen P. Brown Characterizing Indirect Speech Acts
VIII. P1 believes that P2 has an obligation to P2 (by
virtue of P2&apos;s own self-interest) to perform some ac-
tion that complements P 1 &apos;s part of the action.
Rule UNMARKED-ASK:
? That suitcase is heavy. Should you let me
drive you to the airport?
(See discussion for ask V.)
Rule UNMARKED-ASSERT:
That suitcase is heavy. You should let me drive
you to the airport.
</bodyText>
<figure confidence="0.411558333333333">
IV-VII together:
Rule COMPOSITE-REQUEST:
Please accept a ride to the airport.
Rule COMPOSITE-ASK:
Will you accept a ride to the airport?
• suggest
</figure>
<figureCaption confidence="0.232886">
propositional content: an action
</figureCaption>
<bodyText confidence="0.723994833333333">
except for: actions in which P1 and P2 share com-
mon agency
(In excluding actions where P1 and P2 share com-
mon agency, I am merely arguing for a separate
type of speech act, e.g., suggest-common-action, to
cover such cases.)
</bodyText>
<reference confidence="0.972498818181818">
performative: I suggest ...
other direct forms:
1. What about &lt;action&gt;? e.g., What about join-
ing the Marines?
2. How about &lt;action&gt;? e.g., How about joining
the Marines?
principal intended effect: that P2 consider taking
responsibility for the action in the propositional
content.
Rule NECESSARY-ASSERT:
I must suggest that you join the Marines.
Rule NECESSARY-ASK:
Need I suggest that you join the Marines?
Rule EQUI-ASK:
Has anyone suggested that you join the M
rines?
Rule FUTURE-EFFECT-ASK:
Are you thinking about joining the Marines?
Rule PAST-EFFECT-ASK:
Have you considered joining the Marines?
Rule DESIRABLE-ASSERT:
I&apos;d be pleased if you&apos;d consider joining the Ma-
rines.
Rule DESIRABLE-ASK:
Would your parents be happy if you considered
joining the Marines?
Rule UNDESIRABLE-ASK:
Would you be offended if I suggested that you
join the Marines?
Precondition-Based Examples
I. P1 wants P2 to consider taking responsibility for
the action.
Rule P 1 -ASSERT :
I want you to think about joining the Ma-
rines.
II. P1 believes that P2 can consider taking responsi-
bility for the action.
Rule UNMARKED-ASK:
Could you think about joining the Marines?
Rule UNMARKED-ASSERT:
You could think about joining the Marines.
III. P1 believes that P2 is willing to consider taking
responsibility for the action.
Rule P2-ASK:
</reference>
<bodyText confidence="0.8350915">
Are you willing to consider joining the Ma-
rines?
IV. P1 believes that P2 has an obligation (to &amp;quot;be
cooperative&amp;quot;) to P1 to consider the action.
(The &amp;quot;be cooperative&amp;quot; obligation is similar to that
for offer VII. The obligation arises from the fact
that a goal of P1 is involved in a suggest, via pre-
condition I.)
</bodyText>
<sectionHeader confidence="0.469197" genericHeader="conclusions">
Rule UNMARKED-ASK:
</sectionHeader>
<reference confidence="0.905956461538462">
? Should you think about joining the Ma-
rines?
(See discussion for ask V.)
Rule UNMARKED-ASSERT:
You must think about joining the Marines.
V. P1 believes that P2 can take responsibility for
the action.
Rule UNMARKED-ASK:
Can you join the Marines?
Rule UNMARKED-ASSERT:
You can join the Marines.
VI. P1 believes that P2 is willing to take responsibil-
ity for the action.
Rule P2-ASK:
Are you willing to join the Marines?
VII. P1 believes that there are some reasons why
the action is desirable.
Rule UNMARKED-ASK:
Would it be good for you to join the Ma-
rines?
Rule UNMARKED-ASSERT:
You&apos;d be a credit to your sorority if you
joined the Marines.
American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 165
Gretchen P. Brown Characterizing Indirect Speech Acts
VIII. P1 believes that P2 has an obligation to P2
(by virtue of P2&apos;s own self-interest) to consider
taking responsibility for the action.
Rule UNMARKED-ASK:
You need a new experience. Should you join
the Marines?
Rule UNMARKED-ASSERT:
You need a new experience. You should join
the Marines.
I-IV together:
Rule COMPOSITE-REQUEST:
Think about joining the Marines.
Rule COMPOSITE-ASK:
Will you consider joining the Marines?
</reference>
<sectionHeader confidence="0.985611" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.998919777777778">
This paper builds on work in knowledge repre-
sentation done by William A. Martin and members
of the Knowledge Based Systems Group at the
M.I.T. Laboratory for Computer Science. I am also
grateful to William Mark, Candace Sidner, Peter
Szolovits, James Weiner, and the referees for many
helpful comments. Special thanks to Michael
McCord and George Heidorn for substantial con-
tributions to the presentation.
</bodyText>
<sectionHeader confidence="0.995523" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999803840425532">
1. Allen, J. &amp;quot;A Plan-Based Approach to Speech Act Recogni-
tion,&amp;quot; Technical Report No. 131/79 (February 1979), Depart-
ment of Computer Science, University of Toronto, Toronto,
Canada.
2. Austin, J.L. How to Do Things with Words, Oxford University
Press, New York, 1962.
3. Brown, G.P. &amp;quot;A Framework for Processing Dialogue,&amp;quot; LCS
TR-182 (June 1977), Laboratory for Computer Science,
M.I.T., Cambridge, MA.
4. Brown, G.P. &amp;quot;Toward a Computational Theory of Indirect
Speech Acts,&amp;quot; LCS TR-223 (September 1979), Laboratory for
Computer Science, M.I.T. Cambridge, MA.
5. Brown, G.P. &amp;quot;Action Descriptions in Indirect Speech Acts,&amp;quot;
Cognition and Brain Theory, Vol. 3, No. 3, Spring 1980.
6. Brown, G.P. &amp;quot;Linguistic and Situational Context in a Model
of Task-Oriented Dialogue,&amp;quot; to appear in Vaina and Hintikka
(eds.): Cognitive Constraints on Communication Representations
and Processes, D. Reidel, Dortrecht, Holland.
7. Bruce, B.C. &amp;quot;Belief Systems and Language Understanding,&amp;quot;
BBN Report No. 2973 (January 1975), Bolt, Beranek and
Newman, Inc., Cambridge, MA.
8. Cohen, P.R. &amp;quot;On Knowing What to Say: Planning Speech
Acts,&amp;quot; Technical Report No. 118 (January 1978), Department
of Computer Science, University of Toronto, Toronto, Cana-
da.
9. Davison A. &amp;quot;Indirect Speech Acts and What to Do With
Them,&amp;quot; in: Cole and Morgan (eds.) Syntax and Semantics, vol.
3, Academic Press, New York, 1975.
10. Ervin-Tripp, S. &amp;quot;Wait for Me, Roller Skate,&amp;quot; in: Ervin-Tripp
and Mitchell-Kernan (eds.) Child Discourse, Academic Press,
New York, 1977.
11. Fraser, B. &amp;quot;Hedged Performatives,&amp;quot; in: Cole and Morgan
(eds.) Syntax and Semantics, vol. 3, Academic Press, New
York, 1975.
12. Gordon, D. and Lakoff, G. &amp;quot;Conversational Postulates,&amp;quot; in:
Cole and Morgan (eds.) Syntax and Semantics, vol. 3, Academ-
ic Press, New York, 1975.
13. Grice, H.P. &amp;quot;Logic and Conversation,&amp;quot; in: Cole and Morgan
(eds.) Syntax and Semantics, vol. 3, Academic Press, New
York, 1975.
14. Grosz, B. &amp;quot;The Representation and Use of Focus in a System
for Understanding Dialogs,&amp;quot; Proceedings of the Fifth Interna-
tional Joint Conference on Artificial Intelligence, Cambridge,
Mass. (August 1977).
15. Hawkinson, L. &amp;quot;The Representation of Concepts in OWL,&amp;quot;
Advance Papers of the Fourth International Joint Conference on
Artificial Intelligence, Tbilisi, Georgia, USSR (September
1975).
16. Labov, W. and Fanshel, D. Therapeutic Discourse, Academic
Press, New York, 1977.
17. Lakoff, R. &amp;quot;The Logic of Politeness; of, Minding Your p&apos;s
and q&apos;s,&amp;quot; Papers from the Ninth Regional Meeting of the Chicago
Linguistic Society, Department of Linguistics, University of
Chicago, Chicago IL.
18. Levin, J.A. and Moore, J.A. &amp;quot;Dialogue Games: Meta-
communication Structures for Natural Language Interaction,&amp;quot;
Cognitive Science, Vol. 1, No. 4, October 1977.
19. Moore, J.A., Levin, J.A., and Mann, W.C. &amp;quot;A Goal-Oriented
Model of Human Dialogue,&amp;quot; American Journal of Computation-
al Linguistics, Microfiche 67 (1977).
20. Morgan, J.L. &amp;quot;Two Types of Convention in Indirect Speech
Acts,&amp;quot; in: Cole (ed.) Syntax and Semantics, vol. 9, Academic
Press, New York, 1978.
21. Perrault, C.R., Allen, J.F., and Cohen P.R. &amp;quot;Speech Acts as a
Basis for Understanding Dialogue Coherence,&amp;quot; Theoretical
Issues in Natural Language Processing-2, University of Illinois at
Urbana-Champaign, (July 1978).
22. Sadock, J.M. Toward a Linguistic Theory of Speech Acts, Aca-
demic Press, New York, 1974.
23. Schank, R. and Abelson, R. Scripts, Plans, Goals, and
Understanding, Lawrence Erlbaum Associates, Hillsdale, NJ
1977. .
24. Searle, J.R. Speech Acts, University Press, Cambridge, 1969.
25. Searle, J.R. &amp;quot;Indirect Speech Acts,&amp;quot; in: Cole and Morgan
(eds.) Syntax and Semantics, vol. 3, Academic Press, New
York, 1975.
26. Searle, J.R. &amp;quot;A Taxonomy of Illocutionary Acts,&amp;quot; in: Gunder-
son (ed.), Language, Mind, and Knowledge, University of Min-
nesota Press, 1976.
27. Szolovits, P., Hawkinson, L., and Martin, W.A. &amp;quot;An Overview
of OWL, a Language for Knowledge Representation,&amp;quot; Proceed-
ings of the Workshop on Natural Language for Interaction with
Data Bases, International Institute for Applied Systems Analy-
sis, Laxenburg, Austria; also available as LCS-TM-86, (June
1977), Laboratory for Computer Science, M.I.T., Cambridge,
MA.
28. Verschueren, J. &amp;quot;The Analysis of Speech Act Verbs: Theoret-
ical Preliminaries,&amp;quot; (August 1977) Indiana University Linguis-
tics Club, Bloomington, IN.
Gretchen P. Brown is a Computer Scientist in the
Sponsored Research Division of the Computer Corpora-
tion of America. She received the Electrical Engineer
degree in computer science from the Massachusetts Insti-
tute of Technology in 1974.
</reference>
<page confidence="0.914806">
166 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.942576">
<title confidence="0.998202">Characterizing Indirect Speech Act&amp;</title>
<author confidence="0.999994">Gretchen P Brown</author>
<affiliation confidence="0.996382">Computer Corporation of</affiliation>
<address confidence="0.9946">575 Technology Square Cambridge, Massachusetts 02139</address>
<abstract confidence="0.9882775">This paper presents the core of a descriptive theory of indirect speech acts, i.e. utterances in which one speech act form is used to realize another, different, speech act. The proposed characterization of indirect speech acts is based on principles of goal formation, viewed in the context of a general structural model of action. The model of action is used to develop rules that characterize a large number of indirect speech act forms. Computational implications of the theory are discussed.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>performative: I suggest ... other direct forms:</title>
<marker></marker>
<rawString> performative: I suggest ... other direct forms:</rawString>
</citation>
<citation valid="false">
<title>What about e.g., What about joining the Marines?</title>
<contexts>
<context position="42384" citStr="[1,8,21]" startWordPosition="7077" endWordPosition="7077">s for Searle. Instead, they are related to a broader view of rational action analogous to that expounded by Grice. Speech acts, because they are actions, do have structural components that play an important part in the derivation of ISAs. The driving force behind ISAs, however, is the process of goal formation, i.e. the process of deciding whether to adopt a speech act as a goal. This process is reflected in the three maxims that were used as a conceptual organization for the presentation. This emphasis on the goal formation process is closely related to the work of Allen, Cohen, and Perrault [1,8,21]. The similarities and differences between the two approaches are discussed in Section 6. 5. Relating Utterances to the General Rules The general ISA rules in the last section were illustrated with English sentences, but nothing has as yet been said about the correspondence between particular utterances and rules. This section discusses in broad terms the nature of the correspondence, focusing on differences in complexity. Because the topic is difficult to present in a neutral way, it will be approached from the point of view of language recognition, i.e., matching utterances against rules. Mu</context>
<context position="58002" citStr="[1,8,21]" startWordPosition="9623" endWordPosition="9623">d, I 160 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 Gretchen P. Brown Characterizing Indirect Speech Acts will again consider only ISA pattern identification, i.e. proposing the candidate matches for a particular utterance form. Issues related to choosing between alternatives are discussed in [4], along with a framework for using dialogue context to aid in this choice. The approach to ISA pattern identification suggested will be contrasted with two other computational approaches, that of Moore, Levin, and Mann [18,19] and Allen, Cohen, and Perrault [1,8,21]. We start with a summary of each approach. The central structure in the process model of dialogue developed by Moore, Levin, and Mann is called the dialogue game. Dialogue games are procedures that include steps for speech acts and their standard range of responses. Indirect speech act forms are related to these larger structures according to the general principle that any utterance that can establish the parameters of a dialogue game can serve as an ISA. For recognition, the correspondence between particular ISAs and parameters is done by applying rule-like transformations using partial matc</context>
</contexts>
<marker>1.</marker>
<rawString>What about &lt;action&gt;? e.g., What about joining the Marines?</rawString>
</citation>
<citation valid="false">
<authors>
<author>P Gretchen</author>
</authors>
<title>How about e.g., How about joining the Marines? principal intended effect: that P2 consider taking responsibility for the action in the propositional content. Rule NECESSARY-ASSERT: I must suggest that you join the Marines. Rule NECESSARY-ASK: Need I suggest that you join the Marines? Rule EQUI-ASK: Has anyone suggested that you join the M rines? Rule FUTURE-EFFECT-ASK: Are you thinking about joining the Marines? Rule PAST-EFFECT-ASK: Have you considered joining the Marines? Rule DESIRABLE-ASSERT: I&apos;d be pleased if you&apos;d consider joining the Marines. Rule DESIRABLE-ASK: Would your parents be happy if you considered joining the Marines? Rule UNDESIRABLE-ASK: Would you be offended if I suggested that you join the Marines? Precondition-Based Examples I. P1 wants P2 to consider taking responsibility for the action. Rule P 1 -ASSERT : I want you to think about joining the Marines. II. P1 believes that P2 can consider taking responsibility for the action. Rule UNMARKED-ASK: Could you think about joining the Marines? Rule UNMARKED-ASSERT: You could think about joining the Marines. III. P1 believes that P2 is willing to consider taking responsibility for the action. Rule P2-ASK: ? Should you think about joining the Marines? (See discussion for ask V.) Rule UNMARKED-ASSERT: You must think about joining the Marines. V. P1 believes that P2 can take responsibility for the action. Rule UNMARKED-ASK: Can you join the Marines? Rule UNMARKED-ASSERT: You can join the Marines. VI. P1 believes that P2 is willing to take responsibility for the action. Rule P2-ASK: Are you willing to join the Marines? VII. P1 believes that there are some reasons why the action is desirable. Rule UNMARKED-ASK: Would it be good for you to join the Marines? Rule UNMARKED-ASSERT: You&apos;d be a credit to your sorority if you joined the Marines.</title>
<date>1980</date>
<journal>American Journal of Computational Linguistics,</journal>
<volume>6</volume>
<pages>165</pages>
<contexts>
<context position="2376" citStr="[2]" startWordPosition="382" endWordPosition="382">research for this paper was carried out while the author was on the staff of the Laboratory for Computer Science at the Massachusetts Institute of Technology. The research was supported by the Advanced Research Projects Agency of the Department of Defense and was monitored by the Office of Naval Research under Contract Number N00014-75-C-0661. It is the claim of this paper that previous investigations of indirect speech acts (abbreviated ISA52) have been hampered by inadequate semantic theories. This study takes as primary the central tenet of speech act theory that language is action (Austin [2]) and brings to bear some of the perspectives on the representation of actions developed in the course of Artificial Intelligence research. Accordingly, principles of goal formation are discussed in the context of a general structural model of action. The model of action is used to develop rules that characterize a large number of indirect speech act forms. The focus of this investigation is on the development of a descriptive theory of ISAs. Accounting for the diversity of ISAs is an important goal, but I see the formulation of a solid and complete descriptive theory as a necessary prerequisi</context>
</contexts>
<marker>2.</marker>
<rawString>How about &lt;action&gt;? e.g., How about joining the Marines? principal intended effect: that P2 consider taking responsibility for the action in the propositional content. Rule NECESSARY-ASSERT: I must suggest that you join the Marines. Rule NECESSARY-ASK: Need I suggest that you join the Marines? Rule EQUI-ASK: Has anyone suggested that you join the M rines? Rule FUTURE-EFFECT-ASK: Are you thinking about joining the Marines? Rule PAST-EFFECT-ASK: Have you considered joining the Marines? Rule DESIRABLE-ASSERT: I&apos;d be pleased if you&apos;d consider joining the Marines. Rule DESIRABLE-ASK: Would your parents be happy if you considered joining the Marines? Rule UNDESIRABLE-ASK: Would you be offended if I suggested that you join the Marines? Precondition-Based Examples I. P1 wants P2 to consider taking responsibility for the action. Rule P 1 -ASSERT : I want you to think about joining the Marines. II. P1 believes that P2 can consider taking responsibility for the action. Rule UNMARKED-ASK: Could you think about joining the Marines? Rule UNMARKED-ASSERT: You could think about joining the Marines. III. P1 believes that P2 is willing to consider taking responsibility for the action. Rule P2-ASK: ? Should you think about joining the Marines? (See discussion for ask V.) Rule UNMARKED-ASSERT: You must think about joining the Marines. V. P1 believes that P2 can take responsibility for the action. Rule UNMARKED-ASK: Can you join the Marines? Rule UNMARKED-ASSERT: You can join the Marines. VI. P1 believes that P2 is willing to take responsibility for the action. Rule P2-ASK: Are you willing to join the Marines? VII. P1 believes that there are some reasons why the action is desirable. Rule UNMARKED-ASK: Would it be good for you to join the Marines? Rule UNMARKED-ASSERT: You&apos;d be a credit to your sorority if you joined the Marines. American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 165 Gretchen P. Brown Characterizing Indirect Speech Acts VIII. P1 believes that P2 has an obligation to P2 (by virtue of P2&apos;s own self-interest) to consider taking responsibility for the action. Rule UNMARKED-ASK: You need a new experience. Should you join the Marines? Rule UNMARKED-ASSERT: You need a new experience. You should join the Marines. I-IV together: Rule COMPOSITE-REQUEST: Think about joining the Marines. Rule COMPOSITE-ASK: Will you consider joining the Marines?</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Allen</author>
</authors>
<title>A Plan-Based Approach to Speech Act Recognition,&amp;quot;</title>
<date>1979</date>
<tech>Technical Report No. 131/79</tech>
<institution>Department of Computer Science, University of Toronto,</institution>
<location>Toronto, Canada.</location>
<contexts>
<context position="42384" citStr="[1,8,21]" startWordPosition="7077" endWordPosition="7077">s for Searle. Instead, they are related to a broader view of rational action analogous to that expounded by Grice. Speech acts, because they are actions, do have structural components that play an important part in the derivation of ISAs. The driving force behind ISAs, however, is the process of goal formation, i.e. the process of deciding whether to adopt a speech act as a goal. This process is reflected in the three maxims that were used as a conceptual organization for the presentation. This emphasis on the goal formation process is closely related to the work of Allen, Cohen, and Perrault [1,8,21]. The similarities and differences between the two approaches are discussed in Section 6. 5. Relating Utterances to the General Rules The general ISA rules in the last section were illustrated with English sentences, but nothing has as yet been said about the correspondence between particular utterances and rules. This section discusses in broad terms the nature of the correspondence, focusing on differences in complexity. Because the topic is difficult to present in a neutral way, it will be approached from the point of view of language recognition, i.e., matching utterances against rules. Mu</context>
<context position="58002" citStr="[1,8,21]" startWordPosition="9623" endWordPosition="9623">d, I 160 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 Gretchen P. Brown Characterizing Indirect Speech Acts will again consider only ISA pattern identification, i.e. proposing the candidate matches for a particular utterance form. Issues related to choosing between alternatives are discussed in [4], along with a framework for using dialogue context to aid in this choice. The approach to ISA pattern identification suggested will be contrasted with two other computational approaches, that of Moore, Levin, and Mann [18,19] and Allen, Cohen, and Perrault [1,8,21]. We start with a summary of each approach. The central structure in the process model of dialogue developed by Moore, Levin, and Mann is called the dialogue game. Dialogue games are procedures that include steps for speech acts and their standard range of responses. Indirect speech act forms are related to these larger structures according to the general principle that any utterance that can establish the parameters of a dialogue game can serve as an ISA. For recognition, the correspondence between particular ISAs and parameters is done by applying rule-like transformations using partial matc</context>
</contexts>
<marker>1.</marker>
<rawString>Allen, J. &amp;quot;A Plan-Based Approach to Speech Act Recognition,&amp;quot; Technical Report No. 131/79 (February 1979), Department of Computer Science, University of Toronto, Toronto, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J L Austin</author>
</authors>
<title>How to Do Things with Words,</title>
<date>1962</date>
<publisher>University Press,</publisher>
<location>Oxford</location>
<contexts>
<context position="2376" citStr="[2]" startWordPosition="382" endWordPosition="382">research for this paper was carried out while the author was on the staff of the Laboratory for Computer Science at the Massachusetts Institute of Technology. The research was supported by the Advanced Research Projects Agency of the Department of Defense and was monitored by the Office of Naval Research under Contract Number N00014-75-C-0661. It is the claim of this paper that previous investigations of indirect speech acts (abbreviated ISA52) have been hampered by inadequate semantic theories. This study takes as primary the central tenet of speech act theory that language is action (Austin [2]) and brings to bear some of the perspectives on the representation of actions developed in the course of Artificial Intelligence research. Accordingly, principles of goal formation are discussed in the context of a general structural model of action. The model of action is used to develop rules that characterize a large number of indirect speech act forms. The focus of this investigation is on the development of a descriptive theory of ISAs. Accounting for the diversity of ISAs is an important goal, but I see the formulation of a solid and complete descriptive theory as a necessary prerequisi</context>
</contexts>
<marker>2.</marker>
<rawString>Austin, J.L. How to Do Things with Words, Oxford University Press, New York, 1962.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G P Brown</author>
</authors>
<title>A Framework for Processing Dialogue,&amp;quot;</title>
<date>1977</date>
<tech>LCS TR-182</tech>
<institution>Laboratory for Computer Science, M.I.T.,</institution>
<location>Cambridge, MA.</location>
<contexts>
<context position="4362" citStr="[3]" startWordPosition="699" endWordPosition="699">ce literature for a hierarchical semantic relationship. Copyright 1980 by the Association for Computational Linguistics. Permission to copy without fee all or part of this material is granted provided that the copies are not made for direct commercial advantage and the Journal reference and this copyright notice are included on the first page. To copy otherwise, or to republish, requires a fee and/or specific permission. 0362-613X/80/030150-17$01.00 150 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 Gretchen P. Brown Characterizing Indirect Speech Acts [3]. The actual behavior of the system was limited (internal manipulations for a twenty turn sample dialogue), but the process model implemented was relatively sophisticated. A further expanded and refined version of this model is presented in [4]. In viewing the characterization of ISAs as a computational problem, the central premise has been that the phenomenon of ISAs is too complex to admit to a single uniform computational treatment. The two stumbling blocks to a descriptive theory -- the number and variety of ISA forms -- are doubly troubling when the theory is to have a computational appli</context>
<context position="10104" citStr="[3,6]" startWordPosition="1653" endWordPosition="1653"> is, fundamentally, action, then linguistic models must include a model of the structure of actions. Such a model of actions can be a unifying force American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 151 Gretchen P. Brown Characterizing Indirect Speech Acts within the larger model, since structural information can be used in a number of different ways. This subsection gives a very general treatment of actions, just enough to support the ISA rules proposed. The account of actions is taken from the OWL-I representation scheme (Szolovits et al. [27] and Brown [3,6]),3 and it has counterparts in work by Bruce [7], Schank and Abelson [23], Grosz [14], and Moore, Levin, and Mann [18,19]. Some of these approaches differ in the type of action modelled, and all of them differ in the details, but each of the approaches is open to the treatment of action representations as general knowledge. Thus, action representations are not merely programs for doing something, they are also knowledge structures that may be used by other processes. We start with the notion of a method, a representation of an action. Methods have three main parts: a header, argument specifica</context>
</contexts>
<marker>3.</marker>
<rawString>Brown, G.P. &amp;quot;A Framework for Processing Dialogue,&amp;quot; LCS TR-182 (June 1977), Laboratory for Computer Science, M.I.T., Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G P Brown</author>
</authors>
<title>Toward a Computational Theory of Indirect Speech Acts,&amp;quot;</title>
<date>1979</date>
<tech>LCS TR-223</tech>
<institution>Laboratory for Computer Science, M.I.T.</institution>
<location>Cambridge, MA.</location>
<contexts>
<context position="4606" citStr="[4]" startWordPosition="738" endWordPosition="738">mercial advantage and the Journal reference and this copyright notice are included on the first page. To copy otherwise, or to republish, requires a fee and/or specific permission. 0362-613X/80/030150-17$01.00 150 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 Gretchen P. Brown Characterizing Indirect Speech Acts [3]. The actual behavior of the system was limited (internal manipulations for a twenty turn sample dialogue), but the process model implemented was relatively sophisticated. A further expanded and refined version of this model is presented in [4]. In viewing the characterization of ISAs as a computational problem, the central premise has been that the phenomenon of ISAs is too complex to admit to a single uniform computational treatment. The two stumbling blocks to a descriptive theory -- the number and variety of ISA forms -- are doubly troubling when the theory is to have a computational application. Some means must be found to divide the class of ISAs into subclasses which have their own specialized representations and processing strategies. The development of the descriptive theory of ISAs presented has been affected in various wa</context>
<context position="11327" citStr="[4]" startWordPosition="1854" endWordPosition="1854">ral body. The header is the method&apos;s unique name. Argument specifications, organized by semantic cases, are used for type checking of inputs to the method (input cases) or to specify the form of results (output cases). The procedural body is divided into two parts: (optional) prerequisites and procedure steps. Note that input cases are associated with methods, not surface English verbs. Input case specifications give constraints on the participants in the method, the materials used, objects manipulated, etc. (A suggested set of semantic input cases derived by William A. Martin can be found in [4].) An important type of input case constraint, the precondition, is discussed in the next subsection. Besides input case specifications, we said that methods may have associated output case specifications, i.e. specifications of results. One important notion here is that of principal result, which is the main result of the method and, typically, the reason that the method is undertaken. For example, the action conveyed in &amp;quot;Paint the block red&amp;quot; has as principal result that the block is red. The paint brush may also end up red, but this is not the principal result. Turning to the method&apos;s proced</context>
<context position="37232" citStr="[4]" startWordPosition="6213" endWordPosition="6213">s preconditions that are exact matches or specializations of the four preconditions of request. e.g., &amp;quot;Will you accept a ride to the airport?&amp;quot; (offer IV-VII, in Appendix) The rules as written do not account for differences in tense and mood. That is, the UNMARKED-ASK rule accounts for example 4.3 but not 4.4 and 4.5. 4.3 Are you able to drive Sarah to school? 4.4 Will you be able to drive Sarah to school? 4.5 Would you be able to drive Sarah to school? Examples 4.4 and 4.5 can be handled as legitimate requests if we extend the rules to account for a wider range of tense and mood behavior. See [4] for suggestions. The &amp;quot;possibility&amp;quot; rules given also do not derive &amp;quot;not&amp;quot; forms, i.e. strategy-3 rules related to whether an action is impossible. 4.6 Shouldn&apos;t you shut the door? 4.7 Can&apos;t you shut the door? Note, however, that the rules given can be used as patterns for producing rules that account for examples 4.6 and 4.7. Any of the rules above that involve an ask have rule counterparts with not inserted after the ask.&apos; In terms of specific rules, UNMARKED-ASSERT may seem odd when applied to preconditions involving 7 This is a change from [4], where the &apos;&apos;not&apos;&apos; forms were seen as realizatio</context>
<context position="48258" citStr="[4]" startWordPosition="8021" endWordPosition="8021">&amp;quot;really&amp;quot; a request only, no longer also a question. The interest is fueled by questions of the nature of meaning that are involved. Because I am interested in focusing on generalizations possible about ISAs, these issues will be omitted from discussion here. It is worth noting, however, that, whatever the ultimate theoretical disposition of these forms may be, they will probably have to be handled in a computational system by specialized patterns, to represent their unique properties. One such representation scheme, closely related to Morgan&apos;s notion of short-circuited entailment, is given in [4]. The rest of the examples above, 5.5 through 5.9, can be related to the &amp;quot;can&amp;quot; request pattern in a regular fashion, but they require a richer set of matching relationships. Example 5.5 is typical of examples for which proposing a match may turn out to involve arbitrarily complex inference. To begin to account for example 5.5, we can posit some link between can in the ISA pattern and a representation for being in the appropriate spatial proximity to do an action. This link may be hierarchical, or part of a definition related to the internal node can, or both. This treatment does not, however, </context>
<context position="50109" citStr="[4]" startWordPosition="8346" endWordPosition="8346">has the potential to turn the process of proposing interpretations for utterances such as example 5.5 into a full-blown inference process, with all the attendant difficulties in controlling the inference. The rest of the examples can be expected to be more tractable, because we can take advantage of specialized links in the model of actions introduced in Section 3. Example 5.6 makes a &amp;quot;can you&amp;quot; request by asking whether P2 has an assignment (the hammer) for the instrument semantic case of the action (putting up a hook). Several different types of semantic cases can be queried in this way (see [4]); the structural model of actions supplies links between actions and their cases that can be traversed in this match. For examples 5.7 to 5.9, we can again exploit the model of actions to propose matches. The three examples may have request interpretations where the actions intended are, respectively, that P2 stop smoking, pass the salt, and close the window. Note that none of the three examples describes these actions explicitly, and for that reason I have called utterances of this class implicit-action ISAs. These three examples represent three classes of implicit-action ISAs, which differ </context>
<context position="51485" citStr="[4]" startWordPosition="8577" endWordPosition="8577">ed. Example 5.8 names a prerequisite of the implicit salt passing action. Recall from Section 3.1 that prerequisites are among the basic parts of methods. Other components of actions, including semantic input cases, steps, and principal results, may also be used in implicit-action ISAs. All of these are related to the action by the explicit links of the method representation. Finally, example 5.9 alludes to the intended action by stating a basis for the action, i.e., a condition seen as sufficient to warrant the action. &amp;quot;Basis for action&amp;quot; can be related to the structural links of methods (see [4]), but the relationship between the condition named in the utterance and the implicit action is relatively complex. Implicitaction ISAs are discussed in more detail in [5]. We have, then, classes of utterances that obey relatively constrained matching relationships and classes that could involve an arbitrary inference process to propose interpretations. In between is a set of utterances for which proposal of interpretations can utilize structural links within action representations. Difficult problems of search and knowledge structuring remain American Journal of Computational Linguistics, Vol</context>
<context position="53336" citStr="[4]" startWordPosition="8862" endWordPosition="8862">gh the similar form 5.11 is. 5.10 Tell me if you can move over. 5.11 Can you move over? In terms of the rules presented in Section 4, a request interpretation for 5.10 could only come from an embedded rule application: the UNMARKED-ASK rule applied to request II, resulting in ask, then the COMPOSITE-REQUEST rule applied to four of the preconditions of ask (see the Appendix). Forbidding such a double application effectively blocks a request interpretation, leaving only the information-seeking alternative. This straightforward solution, augmented by various classes of exceptions, was adopted in [4]. The embedded examples that have accumulated since, however, are too numerous to be accounted for simply as exceptions. Consider the following indirect requests: 5.12 I wonder if you can move over. 5.13 I believe it&apos;s your turn to do the dishes. For 5.12, the internal level definition of wonder would include the following information: P1 wonder if &lt;action or state&gt; 1. P1 wants to know if &lt;action or state&gt; 2. P1 is speculating if &lt;action or state&gt; Example 5.12 is characterizable by applying rule P 1- ASSERT to ask I (P1 wants to know the answer to the question) after applying rule UNMARKED-ASK</context>
<context position="57736" citStr="[4]" startWordPosition="9581" endWordPosition="9581">rk was not only computational but was directed by a particular computational philosophy of language recognition. This philosophy will be described briefly here, with emphasis on the way that the theory presented fits into it. Due to the number of issues involved, I 160 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 Gretchen P. Brown Characterizing Indirect Speech Acts will again consider only ISA pattern identification, i.e. proposing the candidate matches for a particular utterance form. Issues related to choosing between alternatives are discussed in [4], along with a framework for using dialogue context to aid in this choice. The approach to ISA pattern identification suggested will be contrasted with two other computational approaches, that of Moore, Levin, and Mann [18,19] and Allen, Cohen, and Perrault [1,8,21]. We start with a summary of each approach. The central structure in the process model of dialogue developed by Moore, Levin, and Mann is called the dialogue game. Dialogue games are procedures that include steps for speech acts and their standard range of responses. Indirect speech act forms are related to these larger structures a</context>
<context position="60300" citStr="[4]" startWordPosition="10001" endWordPosition="10001">ct speech acts. Allen, Cohen, and Perrault view the speech act as an independent unit; Moore, Levin and Mann relate ISAs to larger units of activity that have speech act components and that are defined according to the goals achieved by the speech acts. This difference between the approaches of Allen et al. and Moore et al. is, I think, primarily one of presentation rather than substance. The approach advocated here is a combination of the two perspectives. A complete system would need both the ability to handle the prototype speech act plus response sequences (called core dialogue methods in [4]) and the ability to treat speech acts as basic building blocks within other sequences. By focusing on independent speech acts in this paper, I do not intend to rule out their incorporation within larger actions. A more substantive difference among the approaches is the mechanism envisioned for drawing correspondences between individual ISAs and ISA patterns. Both of the approaches summarized above are theoretical in a traditional sense, in that they posit one mechanism powerful enough to account for any utterance, i.e., a mechanism powerful enough to handle the most difficult case. Coupled wi</context>
</contexts>
<marker>4.</marker>
<rawString>Brown, G.P. &amp;quot;Toward a Computational Theory of Indirect Speech Acts,&amp;quot; LCS TR-223 (September 1979), Laboratory for Computer Science, M.I.T. Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G P Brown</author>
</authors>
<title>Action Descriptions in Indirect Speech Acts,&amp;quot;</title>
<date>1980</date>
<journal>Cognition and Brain Theory,</journal>
<volume>3</volume>
<contexts>
<context position="51656" citStr="[5]" startWordPosition="8605" endWordPosition="8605"> of actions, including semantic input cases, steps, and principal results, may also be used in implicit-action ISAs. All of these are related to the action by the explicit links of the method representation. Finally, example 5.9 alludes to the intended action by stating a basis for the action, i.e., a condition seen as sufficient to warrant the action. &amp;quot;Basis for action&amp;quot; can be related to the structural links of methods (see [4]), but the relationship between the condition named in the utterance and the implicit action is relatively complex. Implicitaction ISAs are discussed in more detail in [5]. We have, then, classes of utterances that obey relatively constrained matching relationships and classes that could involve an arbitrary inference process to propose interpretations. In between is a set of utterances for which proposal of interpretations can utilize structural links within action representations. Difficult problems of search and knowledge structuring remain American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 159 Gretchen P. Brown Characterizing Indirect Speech Acts unsolved, but the links identified at least specify the types of paths that</context>
</contexts>
<marker>5.</marker>
<rawString>Brown, G.P. &amp;quot;Action Descriptions in Indirect Speech Acts,&amp;quot; Cognition and Brain Theory, Vol. 3, No. 3, Spring 1980.</rawString>
</citation>
<citation valid="false">
<authors>
<author>G P Brown</author>
</authors>
<title>Linguistic and Situational Context in a Model of Task-Oriented Dialogue,&amp;quot; to appear in</title>
<booktitle>Vaina and Hintikka (eds.): Cognitive Constraints on Communication Representations and Processes,</booktitle>
<editor>D. Reidel, Dortrecht,</editor>
<location>Holland.</location>
<contexts>
<context position="10104" citStr="[3,6]" startWordPosition="1653" endWordPosition="1653"> is, fundamentally, action, then linguistic models must include a model of the structure of actions. Such a model of actions can be a unifying force American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 151 Gretchen P. Brown Characterizing Indirect Speech Acts within the larger model, since structural information can be used in a number of different ways. This subsection gives a very general treatment of actions, just enough to support the ISA rules proposed. The account of actions is taken from the OWL-I representation scheme (Szolovits et al. [27] and Brown [3,6]),3 and it has counterparts in work by Bruce [7], Schank and Abelson [23], Grosz [14], and Moore, Levin, and Mann [18,19]. Some of these approaches differ in the type of action modelled, and all of them differ in the details, but each of the approaches is open to the treatment of action representations as general knowledge. Thus, action representations are not merely programs for doing something, they are also knowledge structures that may be used by other processes. We start with the notion of a method, a representation of an action. Methods have three main parts: a header, argument specifica</context>
</contexts>
<marker>6.</marker>
<rawString>Brown, G.P. &amp;quot;Linguistic and Situational Context in a Model of Task-Oriented Dialogue,&amp;quot; to appear in Vaina and Hintikka (eds.): Cognitive Constraints on Communication Representations and Processes, D. Reidel, Dortrecht, Holland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B C Bruce</author>
</authors>
<title>Belief Systems and Language Understanding,&amp;quot;</title>
<date>1975</date>
<tech>BBN Report No. 2973</tech>
<location>Bolt, Beranek and Newman, Inc., Cambridge, MA.</location>
<contexts>
<context position="10152" citStr="[7]" startWordPosition="1662" endWordPosition="1662"> must include a model of the structure of actions. Such a model of actions can be a unifying force American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 151 Gretchen P. Brown Characterizing Indirect Speech Acts within the larger model, since structural information can be used in a number of different ways. This subsection gives a very general treatment of actions, just enough to support the ISA rules proposed. The account of actions is taken from the OWL-I representation scheme (Szolovits et al. [27] and Brown [3,6]),3 and it has counterparts in work by Bruce [7], Schank and Abelson [23], Grosz [14], and Moore, Levin, and Mann [18,19]. Some of these approaches differ in the type of action modelled, and all of them differ in the details, but each of the approaches is open to the treatment of action representations as general knowledge. Thus, action representations are not merely programs for doing something, they are also knowledge structures that may be used by other processes. We start with the notion of a method, a representation of an action. Methods have three main parts: a header, argument specifications, and a procedural body. The header is the </context>
</contexts>
<marker>7.</marker>
<rawString>Bruce, B.C. &amp;quot;Belief Systems and Language Understanding,&amp;quot; BBN Report No. 2973 (January 1975), Bolt, Beranek and Newman, Inc., Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P R Cohen</author>
</authors>
<title>On Knowing What to Say: Planning Speech Acts,&amp;quot;</title>
<date>1978</date>
<tech>Technical Report No. 118</tech>
<institution>Department of Computer Science, University of Toronto,</institution>
<location>Toronto, Canada.</location>
<contexts>
<context position="42384" citStr="[1,8,21]" startWordPosition="7077" endWordPosition="7077">s for Searle. Instead, they are related to a broader view of rational action analogous to that expounded by Grice. Speech acts, because they are actions, do have structural components that play an important part in the derivation of ISAs. The driving force behind ISAs, however, is the process of goal formation, i.e. the process of deciding whether to adopt a speech act as a goal. This process is reflected in the three maxims that were used as a conceptual organization for the presentation. This emphasis on the goal formation process is closely related to the work of Allen, Cohen, and Perrault [1,8,21]. The similarities and differences between the two approaches are discussed in Section 6. 5. Relating Utterances to the General Rules The general ISA rules in the last section were illustrated with English sentences, but nothing has as yet been said about the correspondence between particular utterances and rules. This section discusses in broad terms the nature of the correspondence, focusing on differences in complexity. Because the topic is difficult to present in a neutral way, it will be approached from the point of view of language recognition, i.e., matching utterances against rules. Mu</context>
<context position="58002" citStr="[1,8,21]" startWordPosition="9623" endWordPosition="9623">d, I 160 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 Gretchen P. Brown Characterizing Indirect Speech Acts will again consider only ISA pattern identification, i.e. proposing the candidate matches for a particular utterance form. Issues related to choosing between alternatives are discussed in [4], along with a framework for using dialogue context to aid in this choice. The approach to ISA pattern identification suggested will be contrasted with two other computational approaches, that of Moore, Levin, and Mann [18,19] and Allen, Cohen, and Perrault [1,8,21]. We start with a summary of each approach. The central structure in the process model of dialogue developed by Moore, Levin, and Mann is called the dialogue game. Dialogue games are procedures that include steps for speech acts and their standard range of responses. Indirect speech act forms are related to these larger structures according to the general principle that any utterance that can establish the parameters of a dialogue game can serve as an ISA. For recognition, the correspondence between particular ISAs and parameters is done by applying rule-like transformations using partial matc</context>
</contexts>
<marker>8.</marker>
<rawString>Cohen, P.R. &amp;quot;On Knowing What to Say: Planning Speech Acts,&amp;quot; Technical Report No. 118 (January 1978), Department of Computer Science, University of Toronto, Toronto, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Davison</author>
</authors>
<title>Indirect Speech Acts and What to Do With Them,&amp;quot; in:</title>
<date>1975</date>
<booktitle>Cole and Morgan (eds.) Syntax and Semantics,</booktitle>
<volume>3</volume>
<publisher>Academic Press,</publisher>
<location>New York,</location>
<contexts>
<context position="56701" citStr="[9]" startWordPosition="9422" endWordPosition="9422">his approach can also be used to explain the block on embedding in example 5.10. The COMPOSITEREQUEST rule realized with an imperative is not a mitigator, while the UNMARKED-ASK rule realized with a question is. Thus, the indirect request interpretation is blocked. The examples presented make a case for the use of politeness conditions to govern ISA rule embedding, but it must be emphasized that more work is needed. Despite the work on politeness conditions, much of this area is not well understood. (For three different perspectives on the implications of ISA choices, see Lakoff [17], Davison [9], and Ervin-Tripp [10].) Conclusive proof or disproof of the hypothesis awaits an analysis of the implications of ISA choices at a level of detail and completeness that is not yet available. 6. Computational Implications This paper has characterized a significant number of ISA forms, with attention to representational issues. As noted in the introduction, these are the only claims made, although the ultimate motivation of the work was not only computational but was directed by a particular computational philosophy of language recognition. This philosophy will be described briefly here, with em</context>
</contexts>
<marker>9.</marker>
<rawString>Davison A. &amp;quot;Indirect Speech Acts and What to Do With Them,&amp;quot; in: Cole and Morgan (eds.) Syntax and Semantics, vol. 3, Academic Press, New York, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Ervin-Tripp</author>
</authors>
<title>Wait for Me, Roller Skate,&amp;quot;</title>
<date>1977</date>
<editor>in: Ervin-Tripp and Mitchell-Kernan (eds.) Child Discourse,</editor>
<publisher>Academic Press,</publisher>
<location>New York,</location>
<contexts>
<context position="56723" citStr="[10]" startWordPosition="9425" endWordPosition="9425"> be used to explain the block on embedding in example 5.10. The COMPOSITEREQUEST rule realized with an imperative is not a mitigator, while the UNMARKED-ASK rule realized with a question is. Thus, the indirect request interpretation is blocked. The examples presented make a case for the use of politeness conditions to govern ISA rule embedding, but it must be emphasized that more work is needed. Despite the work on politeness conditions, much of this area is not well understood. (For three different perspectives on the implications of ISA choices, see Lakoff [17], Davison [9], and Ervin-Tripp [10].) Conclusive proof or disproof of the hypothesis awaits an analysis of the implications of ISA choices at a level of detail and completeness that is not yet available. 6. Computational Implications This paper has characterized a significant number of ISA forms, with attention to representational issues. As noted in the introduction, these are the only claims made, although the ultimate motivation of the work was not only computational but was directed by a particular computational philosophy of language recognition. This philosophy will be described briefly here, with emphasis on the way that</context>
</contexts>
<marker>10.</marker>
<rawString>Ervin-Tripp, S. &amp;quot;Wait for Me, Roller Skate,&amp;quot; in: Ervin-Tripp and Mitchell-Kernan (eds.) Child Discourse, Academic Press, New York, 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Fraser</author>
</authors>
<title>Hedged Performatives,&amp;quot;</title>
<date>1975</date>
<booktitle>Syntax and Semantics,</booktitle>
<volume>3</volume>
<editor>in: Cole and Morgan (eds.)</editor>
<publisher>Academic Press,</publisher>
<location>New York,</location>
<contexts>
<context position="33268" citStr="[11]" startWordPosition="5530" endWordPosition="5530">e Maxim of Possibility The third maxim proposed was the Maxim of Possibility: one should only initiate actions that one expects to be possible. This means that a speech act should only be initiated when: 1. P1 has the appropriate authority or permission for the speech act; and 2. it appears likely that the specific preconditions associated with the action&apos;s method can be satisfied. Only the second case, preconditions, will be considered here. The ISA forms derived from the first case all seem to belong to a class that Fraser has called hedged performatives, and which are well accounted for in [11]. The approach taken for ISAs based on preconditions will be to distinguish three classes of precondition and formulate six rules using the classes distinguished. The classes will be based on the betterknowledge principle from the beginning of this section, specialized in terms of preconditions. The classes of precondition are as follows: 1. P1-based preconditions Here P1 has inherently better knowledge of whether or not the topic of the precondition holds. The topic of preconditions that begin here with &amp;quot;P1 believes that P2&amp;quot; is considered to be the direct object of the initial &amp;quot;believe,&amp;quot; i.e.</context>
</contexts>
<marker>11.</marker>
<rawString>Fraser, B. &amp;quot;Hedged Performatives,&amp;quot; in: Cole and Morgan (eds.) Syntax and Semantics, vol. 3, Academic Press, New York, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gordon</author>
<author>G Lakoff</author>
</authors>
<title>Conversational Postulates,&amp;quot; in:</title>
<date>1975</date>
<booktitle>Cole and Morgan (eds.) Syntax and Semantics,</booktitle>
<volume>3</volume>
<publisher>Academic Press,</publisher>
<location>New York,</location>
<contexts>
<context position="6349" citStr="[12]" startWordPosition="1031" endWordPosition="1031">SAs. Issues surrounding the application of the rules are addressed in Section 5. Finally, Section 6 discusses some of the implications of the theory, with comparison to recent computational work. 2. Previous Approaches Two approaches to the characterization of indirect speech acts have been particularly influential for both computational and traditional linguists: the views proposed by Gordon and Lakoff and by Searle. Since the rules presented in this paper combine properties of each approach, we start with a brief description of each. We consider first the approach taken by Gordon and Lakoff [12]. Concentrating primarily on request, Gordon and Lakoff propose a set of what they call sincerity conditions and then give a single powerful rule to account for the different ways that a request can be framed. They say that to make a sincere request a speaker must, first, want the action done, second, believe that the hearer can do the action, third, believe that the hearer wants to do the action, and, fourth, believe that the hearer would not do the action unless asked to. The first of these sincerity conditions is called speaker-based and the remaining three are called hearer-based. The rule</context>
</contexts>
<marker>12.</marker>
<rawString>Gordon, D. and Lakoff, G. &amp;quot;Conversational Postulates,&amp;quot; in: Cole and Morgan (eds.) Syntax and Semantics, vol. 3, Academic Press, New York, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H P Grice</author>
</authors>
<title>Logic and Conversation,&amp;quot;</title>
<date>1975</date>
<booktitle>Syntax and Semantics,</booktitle>
<volume>3</volume>
<editor>in: Cole and Morgan (eds.)</editor>
<publisher>Academic Press,</publisher>
<location>New York,</location>
<contexts>
<context position="25369" citStr="[13]" startWordPosition="4184" endWordPosition="4184">as the maxims of Necessity, Desirability, and Possibility, summarize factors that should be weighed in goal formation, the process of deciding to adopt some action as a goal. Necessity, desirability, and possibility of actions are not necessarily, of course, evaluated independently, but the maxims abstract away from the actual weighing procedure. Interpretation of these maxims is intended to be quite broad. &amp;quot;Necessity&amp;quot; is assumed here to include obligations, and &amp;quot;possibility&amp;quot; is assumed to include having permission. Readers familiar with the classic work of Grice on conversational implicature [13] will recognize the approach that is being taken. Grice suggests four categories of maxims that are applicable to linguistic actions but which have analogues in other types of actions. The maxims given here are applicable to actions in general but apply to speech acts as a special case. The Maxim of Necessity above has a partial counterpart in Grice&apos;s category of Quantity. The other two maxims have no direct counterparts, and they suggest extensions to Grice&apos;s framework. Given these basic observations about communication and action in general, the question is how they should be incorporated in</context>
<context position="30283" citStr="[13]" startWordPosition="5023" endWordPosition="5023">ty; &amp;quot;will&amp;quot; forms are discussed further in Section 4.4. Finally, note that P1 is permitted to use an ISA only when P1 can reasonably expect P2 to decipher P l&apos;s intent, i.e., to recognize the indirection. Neither the &amp;quot;necessity&amp;quot; rules nor any of the other rules to be presented here, however, include this information. It appears that this constraint is part of a more general constraint that P1 avoid ambiguity. That is, P1 is obligated -- to the best of his or her ability -- to frame any utterance (ISA or not) in such a way that P2 can understand the message that P1 intended to convey. See Grice [13] for discussion of an &amp;quot;avoid ambiguity&amp;quot; maxim. 4.3. Rules Related to the Maxim of Desirability Next we come to the Maxim of Desirability, which says that one should initiate actions for which some desirable result or results can be expected and avoid actions for which an undesirable result or results can be expected. Related to this maxim, we have the following ISA rules: PI can convey a speech act indirectly by -- Rule DESIRABLE-ASSERT -- asserting that some desirable result or results can be expected or some undesirable result or results can be avoided for some intended effect of the speech </context>
</contexts>
<marker>13.</marker>
<rawString>Grice, H.P. &amp;quot;Logic and Conversation,&amp;quot; in: Cole and Morgan (eds.) Syntax and Semantics, vol. 3, Academic Press, New York, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Grosz</author>
</authors>
<title>The Representation and Use of Focus in a System for Understanding Dialogs,&amp;quot;</title>
<date>1977</date>
<booktitle>Proceedings of the Fifth International Joint Conference on Artificial Intelligence,</booktitle>
<location>Cambridge, Mass.</location>
<contexts>
<context position="10189" citStr="[14]" startWordPosition="1668" endWordPosition="1668">re of actions. Such a model of actions can be a unifying force American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 151 Gretchen P. Brown Characterizing Indirect Speech Acts within the larger model, since structural information can be used in a number of different ways. This subsection gives a very general treatment of actions, just enough to support the ISA rules proposed. The account of actions is taken from the OWL-I representation scheme (Szolovits et al. [27] and Brown [3,6]),3 and it has counterparts in work by Bruce [7], Schank and Abelson [23], Grosz [14], and Moore, Levin, and Mann [18,19]. Some of these approaches differ in the type of action modelled, and all of them differ in the details, but each of the approaches is open to the treatment of action representations as general knowledge. Thus, action representations are not merely programs for doing something, they are also knowledge structures that may be used by other processes. We start with the notion of a method, a representation of an action. Methods have three main parts: a header, argument specifications, and a procedural body. The header is the method&apos;s unique name. Argument specif</context>
</contexts>
<marker>14.</marker>
<rawString>Grosz, B. &amp;quot;The Representation and Use of Focus in a System for Understanding Dialogs,&amp;quot; Proceedings of the Fifth International Joint Conference on Artificial Intelligence, Cambridge, Mass. (August 1977).</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Hawkinson</author>
</authors>
<title>The Representation of Concepts in OWL,&amp;quot;</title>
<date>1975</date>
<booktitle>Advance Papers of the Fourth International Joint Conference on Artificial Intelligence,</booktitle>
<location>Tbilisi, Georgia, USSR</location>
<marker>15.</marker>
<rawString>Hawkinson, L. &amp;quot;The Representation of Concepts in OWL,&amp;quot; Advance Papers of the Fourth International Joint Conference on Artificial Intelligence, Tbilisi, Georgia, USSR (September 1975).</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Labov</author>
<author>D Fanshel</author>
</authors>
<title>Therapeutic Discourse,</title>
<date>1977</date>
<publisher>Academic Press,</publisher>
<location>New York,</location>
<contexts>
<context position="20130" citStr="[16]" startWordPosition="3311" endWordPosition="3311">e or she is not disinclined to do it. That is to say, P2 does not necessarily have Al as a goal, but P2 has no conflicting goals which, when weighed against Al, result in a decision against adopting Al as a goal. Precondition III is worded &amp;quot;P2 is willing to&amp;quot; rather than &amp;quot;P2 wants to,&amp;quot; because P2 will not necessarily already have the action requested as a goal at the time that P1 makes the request. Finally, we come to the notion of obligation in precondition IV. The concept of obligation assumed is a more specific version of the generalized obligation that Labov and Fanshel use for requests in [16]. Obligation to other people is seen here as coming in three types: role obligation, authority obligation, and the general obligation to be cooperative. Role obligations are associated with roles, which can be seen as patterns of behavior that can be assumed by individuals for varying periods of time. An example of a role obligation would be the requirement that a bank teller fulfill a request to make change. Authority obligations are slightly more difficult to identify, since, especially in contemporary American society, most authority arises from roles. Authority obligations based on age dif</context>
<context position="21619" citStr="[16]" startWordPosition="3548" endWordPosition="3548">undane version of the obligation is that questions should be answered, i.e. that inequalities of knowledge should be corrected. A more serious American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 153 Gretchen P. Brown Characterizing Indirect Speech Acts version is the injunction to help someone in an emergency. Note that this obligation is not absolute (nor are role or authority obligations), and it may be overridden by other obligations. A point worth mentioning is that my notion of obligation includes the notion of Pt&apos;s right to invoke the obligation. (See [16], p. 78.) An obligation is seen as a three-place relationship between P1, P2, and the thing that P2 is obliged to do. Note that the specific persons P1 and P2 need not be named explicitly in the obligation. For example, the obligation to drive carefully may be an obligation to society in general, and hence to any individual P1 by inclusion in the larger set. Given this formulation, P1 has the right to invoke the obligation to drive carefully because P1 is one of the parties to the obligation, even if P1 is not named explicitly.5 Philosophical controversy surrounds several of these terms, and a</context>
<context position="54812" citStr="[16]" startWordPosition="9104" endWordPosition="9104"> I suggest the following hypothesis: embedding of general ISA rules is permitted when it furthers the politeness intentions of P1, either to heighten polite8 &amp;quot;Politeness&apos;&apos; is used here quite broadly to include not only observation of the conventions of etiquette, but also the expression of respect for the other participant and the expression only of emotions harmonious with the social expectations associated with the conversational environment. ness or to lessen it. These processes are referred to here as mitigation and aggravation, respectively. (The terms are borrowed from Labov and Fanshel [16] but apply to a somewhat broader range of phenomena here.) Embeddings within rules that are unmarked for politeness are forbidden, as are embeddings where the rules involved have conflicting politeness markings. Evidence for this hypothesis is found in comparing example 5.12 to 5.14: 5.14 I want to know if you can move over. Example 5.14 is derivable from the same set of rules as 5.12, but 5.12 conveys a request force while 5.14 does not. The reason for this, I suggest, is that the UNMARKED-ASK rule is a mitigator: questions, in general, promote politeness by giving P2 an opportunity to answer</context>
</contexts>
<marker>16.</marker>
<rawString>Labov, W. and Fanshel, D. Therapeutic Discourse, Academic Press, New York, 1977.</rawString>
</citation>
<citation valid="false">
<authors>
<author>R Lakoff</author>
</authors>
<title>The Logic of Politeness; of, Minding Your p&apos;s and q&apos;s,&amp;quot; Papers from the Ninth Regional Meeting of the Chicago Linguistic Society,</title>
<institution>Department of Linguistics, University of Chicago, Chicago IL.</institution>
<contexts>
<context position="56688" citStr="[17]" startWordPosition="9420" endWordPosition="9420">ect request. This approach can also be used to explain the block on embedding in example 5.10. The COMPOSITEREQUEST rule realized with an imperative is not a mitigator, while the UNMARKED-ASK rule realized with a question is. Thus, the indirect request interpretation is blocked. The examples presented make a case for the use of politeness conditions to govern ISA rule embedding, but it must be emphasized that more work is needed. Despite the work on politeness conditions, much of this area is not well understood. (For three different perspectives on the implications of ISA choices, see Lakoff [17], Davison [9], and Ervin-Tripp [10].) Conclusive proof or disproof of the hypothesis awaits an analysis of the implications of ISA choices at a level of detail and completeness that is not yet available. 6. Computational Implications This paper has characterized a significant number of ISA forms, with attention to representational issues. As noted in the introduction, these are the only claims made, although the ultimate motivation of the work was not only computational but was directed by a particular computational philosophy of language recognition. This philosophy will be described briefly </context>
</contexts>
<marker>17.</marker>
<rawString>Lakoff, R. &amp;quot;The Logic of Politeness; of, Minding Your p&apos;s and q&apos;s,&amp;quot; Papers from the Ninth Regional Meeting of the Chicago Linguistic Society, Department of Linguistics, University of Chicago, Chicago IL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Levin</author>
<author>J A Moore</author>
</authors>
<title>Dialogue Games: Metacommunication Structures for Natural Language Interaction,&amp;quot;</title>
<date>1977</date>
<journal>Cognitive Science,</journal>
<volume>1</volume>
<contexts>
<context position="10225" citStr="[18,19]" startWordPosition="1674" endWordPosition="1674">tions can be a unifying force American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 151 Gretchen P. Brown Characterizing Indirect Speech Acts within the larger model, since structural information can be used in a number of different ways. This subsection gives a very general treatment of actions, just enough to support the ISA rules proposed. The account of actions is taken from the OWL-I representation scheme (Szolovits et al. [27] and Brown [3,6]),3 and it has counterparts in work by Bruce [7], Schank and Abelson [23], Grosz [14], and Moore, Levin, and Mann [18,19]. Some of these approaches differ in the type of action modelled, and all of them differ in the details, but each of the approaches is open to the treatment of action representations as general knowledge. Thus, action representations are not merely programs for doing something, they are also knowledge structures that may be used by other processes. We start with the notion of a method, a representation of an action. Methods have three main parts: a header, argument specifications, and a procedural body. The header is the method&apos;s unique name. Argument specifications, organized by semantic case</context>
<context position="57962" citStr="[18,19]" startWordPosition="9617" endWordPosition="9617">it. Due to the number of issues involved, I 160 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 Gretchen P. Brown Characterizing Indirect Speech Acts will again consider only ISA pattern identification, i.e. proposing the candidate matches for a particular utterance form. Issues related to choosing between alternatives are discussed in [4], along with a framework for using dialogue context to aid in this choice. The approach to ISA pattern identification suggested will be contrasted with two other computational approaches, that of Moore, Levin, and Mann [18,19] and Allen, Cohen, and Perrault [1,8,21]. We start with a summary of each approach. The central structure in the process model of dialogue developed by Moore, Levin, and Mann is called the dialogue game. Dialogue games are procedures that include steps for speech acts and their standard range of responses. Indirect speech act forms are related to these larger structures according to the general principle that any utterance that can establish the parameters of a dialogue game can serve as an ISA. For recognition, the correspondence between particular ISAs and parameters is done by applying rule</context>
</contexts>
<marker>18.</marker>
<rawString>Levin, J.A. and Moore, J.A. &amp;quot;Dialogue Games: Metacommunication Structures for Natural Language Interaction,&amp;quot; Cognitive Science, Vol. 1, No. 4, October 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Moore</author>
<author>J A Levin</author>
<author>W C Mann</author>
</authors>
<title>A Goal-Oriented Model of Human Dialogue,&amp;quot;</title>
<date>1977</date>
<journal>American Journal of Computational Linguistics, Microfiche</journal>
<volume>67</volume>
<contexts>
<context position="10225" citStr="[18,19]" startWordPosition="1674" endWordPosition="1674">tions can be a unifying force American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 151 Gretchen P. Brown Characterizing Indirect Speech Acts within the larger model, since structural information can be used in a number of different ways. This subsection gives a very general treatment of actions, just enough to support the ISA rules proposed. The account of actions is taken from the OWL-I representation scheme (Szolovits et al. [27] and Brown [3,6]),3 and it has counterparts in work by Bruce [7], Schank and Abelson [23], Grosz [14], and Moore, Levin, and Mann [18,19]. Some of these approaches differ in the type of action modelled, and all of them differ in the details, but each of the approaches is open to the treatment of action representations as general knowledge. Thus, action representations are not merely programs for doing something, they are also knowledge structures that may be used by other processes. We start with the notion of a method, a representation of an action. Methods have three main parts: a header, argument specifications, and a procedural body. The header is the method&apos;s unique name. Argument specifications, organized by semantic case</context>
<context position="57962" citStr="[18,19]" startWordPosition="9617" endWordPosition="9617">it. Due to the number of issues involved, I 160 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 Gretchen P. Brown Characterizing Indirect Speech Acts will again consider only ISA pattern identification, i.e. proposing the candidate matches for a particular utterance form. Issues related to choosing between alternatives are discussed in [4], along with a framework for using dialogue context to aid in this choice. The approach to ISA pattern identification suggested will be contrasted with two other computational approaches, that of Moore, Levin, and Mann [18,19] and Allen, Cohen, and Perrault [1,8,21]. We start with a summary of each approach. The central structure in the process model of dialogue developed by Moore, Levin, and Mann is called the dialogue game. Dialogue games are procedures that include steps for speech acts and their standard range of responses. Indirect speech act forms are related to these larger structures according to the general principle that any utterance that can establish the parameters of a dialogue game can serve as an ISA. For recognition, the correspondence between particular ISAs and parameters is done by applying rule</context>
</contexts>
<marker>19.</marker>
<rawString>Moore, J.A., Levin, J.A., and Mann, W.C. &amp;quot;A Goal-Oriented Model of Human Dialogue,&amp;quot; American Journal of Computational Linguistics, Microfiche 67 (1977).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J L Morgan</author>
</authors>
<title>Two Types of Convention in Indirect Speech Acts,&amp;quot;</title>
<date>1978</date>
<booktitle>Syntax and Semantics,</booktitle>
<volume>9</volume>
<editor>in: Cole (ed.)</editor>
<publisher>Academic Press,</publisher>
<location>New York,</location>
<contexts>
<context position="47582" citStr="[20]" startWordPosition="7912" endWordPosition="7912"> patterns via the hierarchical relationships of the knowledge base, i.e., via predefined classification links. Thus, proposing the request interpretation for examples 5.1 to 5.3 involves relatively well understood knowledge base manipulations. Example 5.4 is a typical utterance that is not accounted for by the ISA patterns given. The problem is that example 5.4, a question according to its interrogative form, contains &amp;quot;please&amp;quot;, a construct reserved for request and related speech acts. Utterances of this form have been much-discussed in the literature (e.g. Sadock [22], Searle [25], and Morgan [20]). The question is whether this form has evolved to the point that it is &amp;quot;really&amp;quot; a request only, no longer also a question. The interest is fueled by questions of the nature of meaning that are involved. Because I am interested in focusing on generalizations possible about ISAs, these issues will be omitted from discussion here. It is worth noting, however, that, whatever the ultimate theoretical disposition of these forms may be, they will probably have to be handled in a computational system by specialized patterns, to represent their unique properties. One such representation scheme, close</context>
</contexts>
<marker>20.</marker>
<rawString>Morgan, J.L. &amp;quot;Two Types of Convention in Indirect Speech Acts,&amp;quot; in: Cole (ed.) Syntax and Semantics, vol. 9, Academic Press, New York, 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C R Perrault</author>
<author>J F Allen</author>
<author>P R Cohen</author>
</authors>
<title>Speech Acts as a Basis for Understanding Dialogue Coherence,&amp;quot; Theoretical Issues</title>
<date>1978</date>
<booktitle>in Natural Language Processing-2,</booktitle>
<institution>University of Illinois at Urbana-Champaign,</institution>
<contexts>
<context position="42384" citStr="[1,8,21]" startWordPosition="7077" endWordPosition="7077">s for Searle. Instead, they are related to a broader view of rational action analogous to that expounded by Grice. Speech acts, because they are actions, do have structural components that play an important part in the derivation of ISAs. The driving force behind ISAs, however, is the process of goal formation, i.e. the process of deciding whether to adopt a speech act as a goal. This process is reflected in the three maxims that were used as a conceptual organization for the presentation. This emphasis on the goal formation process is closely related to the work of Allen, Cohen, and Perrault [1,8,21]. The similarities and differences between the two approaches are discussed in Section 6. 5. Relating Utterances to the General Rules The general ISA rules in the last section were illustrated with English sentences, but nothing has as yet been said about the correspondence between particular utterances and rules. This section discusses in broad terms the nature of the correspondence, focusing on differences in complexity. Because the topic is difficult to present in a neutral way, it will be approached from the point of view of language recognition, i.e., matching utterances against rules. Mu</context>
<context position="58002" citStr="[1,8,21]" startWordPosition="9623" endWordPosition="9623">d, I 160 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 Gretchen P. Brown Characterizing Indirect Speech Acts will again consider only ISA pattern identification, i.e. proposing the candidate matches for a particular utterance form. Issues related to choosing between alternatives are discussed in [4], along with a framework for using dialogue context to aid in this choice. The approach to ISA pattern identification suggested will be contrasted with two other computational approaches, that of Moore, Levin, and Mann [18,19] and Allen, Cohen, and Perrault [1,8,21]. We start with a summary of each approach. The central structure in the process model of dialogue developed by Moore, Levin, and Mann is called the dialogue game. Dialogue games are procedures that include steps for speech acts and their standard range of responses. Indirect speech act forms are related to these larger structures according to the general principle that any utterance that can establish the parameters of a dialogue game can serve as an ISA. For recognition, the correspondence between particular ISAs and parameters is done by applying rule-like transformations using partial matc</context>
</contexts>
<marker>21.</marker>
<rawString>Perrault, C.R., Allen, J.F., and Cohen P.R. &amp;quot;Speech Acts as a Basis for Understanding Dialogue Coherence,&amp;quot; Theoretical Issues in Natural Language Processing-2, University of Illinois at Urbana-Champaign, (July 1978).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Sadock</author>
</authors>
<title>Toward a Linguistic Theory of Speech Acts,</title>
<date>1974</date>
<publisher>Academic Press,</publisher>
<location>New York,</location>
<contexts>
<context position="47552" citStr="[22]" startWordPosition="7907" endWordPosition="7907">are related to elements of ISA patterns via the hierarchical relationships of the knowledge base, i.e., via predefined classification links. Thus, proposing the request interpretation for examples 5.1 to 5.3 involves relatively well understood knowledge base manipulations. Example 5.4 is a typical utterance that is not accounted for by the ISA patterns given. The problem is that example 5.4, a question according to its interrogative form, contains &amp;quot;please&amp;quot;, a construct reserved for request and related speech acts. Utterances of this form have been much-discussed in the literature (e.g. Sadock [22], Searle [25], and Morgan [20]). The question is whether this form has evolved to the point that it is &amp;quot;really&amp;quot; a request only, no longer also a question. The interest is fueled by questions of the nature of meaning that are involved. Because I am interested in focusing on generalizations possible about ISAs, these issues will be omitted from discussion here. It is worth noting, however, that, whatever the ultimate theoretical disposition of these forms may be, they will probably have to be handled in a computational system by specialized patterns, to represent their unique properties. One suc</context>
<context position="52637" citStr="[22]" startWordPosition="8749" endWordPosition="8749">n American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 159 Gretchen P. Brown Characterizing Indirect Speech Acts unsolved, but the links identified at least specify the types of paths that we can expect to see in matches of ISA patterns. 5.2. Embedded ISAs In the discussion of matching, the initial assumption was that matching of surface representations occurred against patterns produced by single applications of rules to speech act methods. This assumption makes no provision for embedded forms. Some evidence does exist for this approach. For example, Sadock [22], in another context, observes that 5.10 is not a request for the hearer to move over, even though the similar form 5.11 is. 5.10 Tell me if you can move over. 5.11 Can you move over? In terms of the rules presented in Section 4, a request interpretation for 5.10 could only come from an embedded rule application: the UNMARKED-ASK rule applied to request II, resulting in ask, then the COMPOSITE-REQUEST rule applied to four of the preconditions of ask (see the Appendix). Forbidding such a double application effectively blocks a request interpretation, leaving only the information-seeking alterna</context>
</contexts>
<marker>22.</marker>
<rawString>Sadock, J.M. Toward a Linguistic Theory of Speech Acts, Academic Press, New York, 1974.</rawString>
</citation>
<citation valid="false">
<authors>
<author>R Schank</author>
<author>R Scripts Abelson</author>
</authors>
<title>Plans, Goals, and Understanding, Lawrence Erlbaum Associates,</title>
<location>Hillsdale, NJ</location>
<contexts>
<context position="10177" citStr="[23]" startWordPosition="1666" endWordPosition="1666"> the structure of actions. Such a model of actions can be a unifying force American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 151 Gretchen P. Brown Characterizing Indirect Speech Acts within the larger model, since structural information can be used in a number of different ways. This subsection gives a very general treatment of actions, just enough to support the ISA rules proposed. The account of actions is taken from the OWL-I representation scheme (Szolovits et al. [27] and Brown [3,6]),3 and it has counterparts in work by Bruce [7], Schank and Abelson [23], Grosz [14], and Moore, Levin, and Mann [18,19]. Some of these approaches differ in the type of action modelled, and all of them differ in the details, but each of the approaches is open to the treatment of action representations as general knowledge. Thus, action representations are not merely programs for doing something, they are also knowledge structures that may be used by other processes. We start with the notion of a method, a representation of an action. Methods have three main parts: a header, argument specifications, and a procedural body. The header is the method&apos;s unique name. Arg</context>
</contexts>
<marker>23.</marker>
<rawString>Schank, R. and Abelson, R. Scripts, Plans, Goals, and Understanding, Lawrence Erlbaum Associates, Hillsdale, NJ</rawString>
</citation>
<citation valid="false">
<marker>1977.</marker>
<rawString>.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Searle</author>
</authors>
<title>Speech Acts,</title>
<date>1969</date>
<publisher>University Press,</publisher>
<location>Cambridge,</location>
<contexts>
<context position="7885" citStr="[24]" startWordPosition="1281" endWordPosition="1281">st are incomplete, since they lack any mention of obligation relationships; these are discussed below in Section 3.3. More problematic is the lack of detailed guidelines for extending the theory beyond requests. A second major approach to ISA regularities is that of Searle. Searle presents a more complete account of ISAs, proposing generalizations associated with the five major classes of speech act defined in [26]. In [25] he lists four generalizations for directives and five others for commissives. The generalizations are differentiated according to the parts of the speech act identified in [24], i.e. propositional content conditions, sincerity conditions, and preparatory conditions. (Gordon and Lakoff&apos;s sincerity conditions, in contrast, seem to be an amalgam of Searle&apos;s sincerity and preparatory conditions.) Searle&apos;s contribution is a valuable one, in that he has succeeded in accounting for a broad range of speech acts. At the same time, Searle&apos;s generalizations can be questioned on the count that they are too specific. Generalizations are stated in terms of types of preparatory conditions, rather than in terms of preparatory conditions as a whole. A more serious problem is the rel</context>
<context position="13184" citStr="[24]" startWordPosition="2167" endWordPosition="2167">o develop since that time. bring it about before carrying out the action. An example of a prerequisite is the requirement that an elementary course of study be completed before a more advanced one is undertaken. 3.2. The Model of Actions Applied to Speech Acts Speech acts, because they are actions, can be represented by methods. Speech act representations therefore have semantic input cases, which typically include cases for the participants in the conversation and a case for what Searle calls the propositional content condition of the speech act (very roughly, what the speech act is &amp;quot;about&amp;quot;) [24]. Among the constraints on these input cases are preconditions. Preconditions are constraints on the beliefs, desires, or other intentions of the agent of the method (the participant responsible for the action) that should be satisfied before the speech act gets underway. Preconditions differ from prerequisites in that a failure to satisfy preconditions typically means that a method is eliminated from consideration as a possible plan; a prerequisite that is not satisfied merely adds extra steps to be performed. Preconditions will play an important role in the framing of ISAs; a sample set is g</context>
</contexts>
<marker>24.</marker>
<rawString>Searle, J.R. Speech Acts, University Press, Cambridge, 1969.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Searle</author>
</authors>
<title>Indirect Speech Acts,&amp;quot; in:</title>
<date>1975</date>
<booktitle>Cole and Morgan (eds.) Syntax and Semantics,</booktitle>
<volume>3</volume>
<publisher>Academic Press,</publisher>
<location>New York,</location>
<contexts>
<context position="7708" citStr="[25]" startWordPosition="1253" endWordPosition="1253">ation is attractive because it is so elegant and simple, but it is also, as the authors are the first to observe, only a preliminary answer. The conditions associated with request are incomplete, since they lack any mention of obligation relationships; these are discussed below in Section 3.3. More problematic is the lack of detailed guidelines for extending the theory beyond requests. A second major approach to ISA regularities is that of Searle. Searle presents a more complete account of ISAs, proposing generalizations associated with the five major classes of speech act defined in [26]. In [25] he lists four generalizations for directives and five others for commissives. The generalizations are differentiated according to the parts of the speech act identified in [24], i.e. propositional content conditions, sincerity conditions, and preparatory conditions. (Gordon and Lakoff&apos;s sincerity conditions, in contrast, seem to be an amalgam of Searle&apos;s sincerity and preparatory conditions.) Searle&apos;s contribution is a valuable one, in that he has succeeded in accounting for a broad range of speech acts. At the same time, Searle&apos;s generalizations can be questioned on the count that they are t</context>
<context position="47565" citStr="[25]" startWordPosition="7909" endWordPosition="7909">o elements of ISA patterns via the hierarchical relationships of the knowledge base, i.e., via predefined classification links. Thus, proposing the request interpretation for examples 5.1 to 5.3 involves relatively well understood knowledge base manipulations. Example 5.4 is a typical utterance that is not accounted for by the ISA patterns given. The problem is that example 5.4, a question according to its interrogative form, contains &amp;quot;please&amp;quot;, a construct reserved for request and related speech acts. Utterances of this form have been much-discussed in the literature (e.g. Sadock [22], Searle [25], and Morgan [20]). The question is whether this form has evolved to the point that it is &amp;quot;really&amp;quot; a request only, no longer also a question. The interest is fueled by questions of the nature of meaning that are involved. Because I am interested in focusing on generalizations possible about ISAs, these issues will be omitted from discussion here. It is worth noting, however, that, whatever the ultimate theoretical disposition of these forms may be, they will probably have to be handled in a computational system by specialized patterns, to represent their unique properties. One such representat</context>
</contexts>
<marker>25.</marker>
<rawString>Searle, J.R. &amp;quot;Indirect Speech Acts,&amp;quot; in: Cole and Morgan (eds.) Syntax and Semantics, vol. 3, Academic Press, New York, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Searle</author>
</authors>
<title>A Taxonomy of Illocutionary Acts,&amp;quot;</title>
<date>1976</date>
<editor>in: Gunderson (ed.), Language, Mind, and</editor>
<publisher>Press,</publisher>
<institution>Knowledge, University of Minnesota</institution>
<contexts>
<context position="7699" citStr="[26]" startWordPosition="1251" endWordPosition="1251">is formulation is attractive because it is so elegant and simple, but it is also, as the authors are the first to observe, only a preliminary answer. The conditions associated with request are incomplete, since they lack any mention of obligation relationships; these are discussed below in Section 3.3. More problematic is the lack of detailed guidelines for extending the theory beyond requests. A second major approach to ISA regularities is that of Searle. Searle presents a more complete account of ISAs, proposing generalizations associated with the five major classes of speech act defined in [26]. In [25] he lists four generalizations for directives and five others for commissives. The generalizations are differentiated according to the parts of the speech act identified in [24], i.e. propositional content conditions, sincerity conditions, and preparatory conditions. (Gordon and Lakoff&apos;s sincerity conditions, in contrast, seem to be an amalgam of Searle&apos;s sincerity and preparatory conditions.) Searle&apos;s contribution is a valuable one, in that he has succeeded in accounting for a broad range of speech acts. At the same time, Searle&apos;s generalizations can be questioned on the count that t</context>
<context position="28138" citStr="[26]" startWordPosition="4647" endWordPosition="4647">ended effect can be expected to occur without the speech act e.g., the requests: &amp;quot;Are you planning to take out the garbage?&amp;quot; &amp;quot;Are you going to take out the garbage?&amp;quot; Rule PAST-EFFECT-ASK -- asking whether the principal intended effect of the speech act has already occurred e.g., the requests: &amp;quot;Did you take out the garbage?&amp;quot; &amp;quot;Have you taken out the garbage?&amp;quot; and, using additional rules (see Section 5), &amp;quot;Is the garbage out?&amp;quot; &amp;quot;Assert&amp;quot; is used in these and subsequent rules to include the speech acts of stating a fact and giving an opinion, i.e., those speech acts that Searle calls representatives [26]. The &amp;quot;necessity&amp;quot; rules exemplify the three communication strategies listed at the beginning of this section. NECESSARY-ASSERT exemplifies the first strategy, in which P1 tells what he or she knows about the necessity of the speech act. In NECESSARYASK, P1 asks whether the speech act is necessary (strategy 2), and in the last three rules, P1 asks whether the speech act is unnecessary (strategy 3). Note that there is no rule for the explicit version of the third strategy, e.g. for the form &amp;quot;Is it unnecessary for me to &lt;speech act&gt;?&amp;quot; This form is practically incomprehensible as a way to carry ou</context>
</contexts>
<marker>26.</marker>
<rawString>Searle, J.R. &amp;quot;A Taxonomy of Illocutionary Acts,&amp;quot; in: Gunderson (ed.), Language, Mind, and Knowledge, University of Minnesota Press, 1976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Szolovits</author>
<author>L Hawkinson</author>
<author>W A Martin</author>
</authors>
<title>An Overview of OWL, a Language for Knowledge Representation,&amp;quot;</title>
<date>1977</date>
<booktitle>Proceedings of the Workshop on Natural Language for Interaction with Data Bases, International Institute for Applied Systems Analysis, Laxenburg, Austria; also available as LCS-TM-86,</booktitle>
<institution>Laboratory for Computer Science, M.I.T.,</institution>
<location>Cambridge, MA.</location>
<contexts>
<context position="10088" citStr="[27]" startWordPosition="1650" endWordPosition="1650">f that language is, fundamentally, action, then linguistic models must include a model of the structure of actions. Such a model of actions can be a unifying force American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 151 Gretchen P. Brown Characterizing Indirect Speech Acts within the larger model, since structural information can be used in a number of different ways. This subsection gives a very general treatment of actions, just enough to support the ISA rules proposed. The account of actions is taken from the OWL-I representation scheme (Szolovits et al. [27] and Brown [3,6]),3 and it has counterparts in work by Bruce [7], Schank and Abelson [23], Grosz [14], and Moore, Levin, and Mann [18,19]. Some of these approaches differ in the type of action modelled, and all of them differ in the details, but each of the approaches is open to the treatment of action representations as general knowledge. Thus, action representations are not merely programs for doing something, they are also knowledge structures that may be used by other processes. We start with the notion of a method, a representation of an action. Methods have three main parts: a header, ar</context>
</contexts>
<marker>27.</marker>
<rawString>Szolovits, P., Hawkinson, L., and Martin, W.A. &amp;quot;An Overview of OWL, a Language for Knowledge Representation,&amp;quot; Proceedings of the Workshop on Natural Language for Interaction with Data Bases, International Institute for Applied Systems Analysis, Laxenburg, Austria; also available as LCS-TM-86, (June 1977), Laboratory for Computer Science, M.I.T., Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Verschueren</author>
</authors>
<title>The Analysis of Speech Act Verbs: Theoretical Preliminaries,&amp;quot;</title>
<date>1977</date>
<booktitle>Gretchen P. Brown is a Computer Scientist in the Sponsored Research Division of the Computer Corporation of America. She received the Electrical Engineer degree in computer science from the Massachusetts Institute of Technology in</booktitle>
<institution>Indiana University Linguistics Club,</institution>
<location>Bloomington, IN.</location>
<contexts>
<context position="14448" citStr="[28]" startWordPosition="2381" endWordPosition="2381">n talking about ISAs is the intended effect. The intended effects of speech acts are those effects that P1 (the agent of the speech act) intends to have on P2. The most important of these effects will be called the principal intended effect. For request, the principal intended effect is that P2 take responsibility for carrying out some action. For offer, it is that P2 accept the offer. &amp;quot;Accept&amp;quot; here includes not only a verbal acceptance, but also that P2 perform some action that complements P 1 &apos;s offer, e.g., P2 takes food that is offered. The notion of intended effect comes from Verschueren [28], but it has been adapted somewhat. In particular, for uniformity, intended effects will be restricted to be actions only, not states. For example, the principal intended effect for state is that P2 come to know (as opposed to just know) that P1 believes something to be a fact. Intended effects and principal intended effects can be related in a straightforward way to methods. Intended effects are actions precipitating certain method results (i.e. intended effects are the direct causes); principal intended effects are actions precipitating certain principal results. The results and principal re</context>
</contexts>
<marker>28.</marker>
<rawString>Verschueren, J. &amp;quot;The Analysis of Speech Act Verbs: Theoretical Preliminaries,&amp;quot; (August 1977) Indiana University Linguistics Club, Bloomington, IN. Gretchen P. Brown is a Computer Scientist in the Sponsored Research Division of the Computer Corporation of America. She received the Electrical Engineer degree in computer science from the Massachusetts Institute of Technology in 1974.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>