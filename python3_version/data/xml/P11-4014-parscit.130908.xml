<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.136460">
<title confidence="0.997485">
A Speech-based Just-in-Time Retrieval System using Semantic Search
</title>
<author confidence="0.998705">
Andrei Popescu-Belis, Majid Yazdani, Alexandre Nanchen, and Philip N. Garner
</author>
<affiliation confidence="0.994508">
Idiap Research Institute
</affiliation>
<address confidence="0.93186">
Rue Marconi 19, CP 592
1920 Martigny, Switzerland
</address>
<email confidence="0.999482">
{apbelis,myazdani,ananchen,pgarner}@idiap.ch
</email>
<sectionHeader confidence="0.998574" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.996185461538462">
The Automatic Content Linking Device is a
just-in-time document retrieval system which
monitors an ongoing conversation or a mono-
logue and enriches it with potentially related
documents, including multimedia ones, from
local repositories or from the Internet. The
documents are found using keyword-based
search or using a semantic similarity measure
between documents and the words obtained
from automatic speech recognition. Results
are displayed in real time to meeting partici-
pants, or to users watching a recorded lecture
or conversation.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999436176470588">
Enriching a monologue or a conversation with re-
lated content, such as textual or audio-visual docu-
ments on the same topic, is a task with multiple ap-
plications in the field of computer-mediated human-
human communication. In this paper, we describe
the Automatic Content Linking Device (ACLD), a
system that analyzes spoken input from one or more
speakers using automatic speech recognition (ASR),
in order to retrieve related content, in real-time, from
a variety of repositories. These include local doc-
ument databases or archives of multimedia record-
ings, as well as websites. Local repositories are
queried using a keyword-based search engine, or us-
ing a semantic similarity measure, while websites
are queried using commercial search engines.
We will first describe the scenarios of use of the
ACLD in Section 2, and review previous systems for
</bodyText>
<page confidence="0.954524">
80
</page>
<bodyText confidence="0.99920975">
just-in-time retrieval in Section 3. The ACLD com-
ponents will be outlined in Sections 4.1 to 4.5. Four
types of evaluation results obtained with our system
will finally be summarized in Sections 5.1 to 5.4.
</bodyText>
<sectionHeader confidence="0.977648" genericHeader="method">
2 Content Linking: Scenarios of Use
</sectionHeader>
<bodyText confidence="0.964270114285714">
Just-in-time information retrieval, i.e. finding useful
documents without the need for a user to initiate a di-
rect search for them, is one of the ways in which the
large quantity of knowledge that is available in net-
worked environments can be efficiently put to use.
To perform this task, a system must consider ex-
plicit and implicit input from users, mainly speech
or typed input, and attempt to model their context,
in order to provide recommendations, which users
are free to consult if they feel the need for additional
information.
One of the main scenarios of use for the ACLD
involves people taking part in meetings, who often
mention documents containing facts under discus-
sion, but do not have the time to search for them
without interrupting the discussion flow. The ACLD
performs this search for them. Moreover, as the
ACLD was developed on meetings from the AMI
Corpus, it can also perform the same operations on
a replayed meeting, as a complement to a meet-
ing browser, for development or demonstration pur-
poses.
In a second scenario, content linking is performed
over live or recorded lectures, for instance in a
computer-assisted learning environment for individ-
ual students. The ACLD enriches the lectures with
related material drawn from various repositories,
through a search process that can be guided in real
Proceedings of the ACL-HLT 2011 System Demonstrations, pages 80–85,
Portland, Oregon, USA, 21 June 2011. c�2011 Association for Computational Linguistics
time by its user. The advantage of real-time con-
tent linking over a more static enrichment, such as
the Feynman lectures at Microsoft Research,1 is that
users can tune search parameters at will while view-
ing the lecture.
</bodyText>
<sectionHeader confidence="0.900739" genericHeader="method">
3 Just-in-Time Retrieval Systems
</sectionHeader>
<bodyText confidence="0.999897789473684">
The first precursors to the ACLD were the Fixit
query-free search system (Hart and Graham, 1997),
the Remembrance Agent for just-in-time retrieval
(Rhodes and Maes, 2000), and the Implicit Queries
(IQ) system (Dumais et al., 2004). Fixit monitored
the state of a user’s interaction with a diagnostic
system, and excerpts from maintenance manuals de-
pending on the interaction state. The Remembrance
Agent was integrated to the Emacs text editor, and
ran searches over emails or notes at regular time in-
tervals (every few seconds) using the latest 20–500
words typed by the user. The IQ system generated
context-sensitive searches based on a user’s ongoing
activities on their computer, such as writing email.
A version of the Remembrance Agent called Jim-
miny was conceived as a wearable assistant for tak-
ing notes, but ASR was only simulated for evalua-
tion (Rhodes, 1997).
The Watson system (Budzik and Hammond,
2000) monitored the user’s operations in a text ed-
itor, but proposed a more complex mechanism than
the Remembrance Agent for selecting terms for
queries, which were directed to a web search engine.
Another assistant for an authoring environment was
developed in the A-Propos project (Puerta Melguizo
et al., 2008). A query-free system was designed for
enriching television news with articles from the Web
(Henziker et al., 2005).
The FAME interactive space (Metze and al.,
2006), which provides multi-modal access to record-
ings of lectures via a table top interface, bears many
similarities to the ACLD. However, it requires the
use of specific voice commands by one user only,
and does not spontaneously follow a conversation.
More recently, several speech-based search en-
gines have become available, including as smart
phone applications. Conversely, many systems al-
low searching of spoken document archives.2 Inspi-
</bodyText>
<footnote confidence="0.9999555">
1See http://research.microsoft.com/apps/tools/tuva/.
2See workshops at http://www.searchingspeech.org.
</footnote>
<bodyText confidence="0.999892727272727">
ration from these approaches, which are not query-
free, can nevertheless be useful to just-in-time re-
trieval. Other related systems are the Speech Spot-
ter (Goto et al., 2004) and a personal assistant using
dual-purpose speech (Lyons et al., 2004), which en-
able users to search for information using commands
that are identified in the speech flow.
The ACLD improves over numerous past ones by
giving access to indexed multimedia recordings as
well as websites, with fully operational ASR and se-
mantic search, as we now explain.
</bodyText>
<sectionHeader confidence="0.878666" genericHeader="method">
4 Description of the ACLD
</sectionHeader>
<bodyText confidence="0.9997524">
The architecture of the ACLD comprises the follow-
ing functions: document preparation, text extraction
and indexing; input sensing and query preparation;
search and integration of results; user interface to
display the results.
</bodyText>
<subsectionHeader confidence="0.998507">
4.1 Document Preparation and Indexing
</subsectionHeader>
<bodyText confidence="0.999970777777778">
The preparation of the local database of documents
for content linking involves mainly the extraction of
text, and then the indexing of the documents, which
is done using Apache Lucene software. Text can be
extracted from a large variety of formats (includ-
ing MS Office, PDF, and HTML) and hierarchies
of directories are recursively scanned. The docu-
ment repository is generally prepared before using
the ACLD, but users can also add files at will. Be-
cause past discussions are relevant to subsequent
ones, they are passed through offline ASR and then
chunked into smaller units (e.g. of fixed length, or
based on a homogeneous topic). The resulting texts
are indexed along with the other documents.
The ACLD uses external search engines to search
in external repositories, for instance the Google Web
search API or the Google Desktop application to
search the user’s local drives.
</bodyText>
<subsectionHeader confidence="0.999608">
4.2 Sensing the User’s Information Needs
</subsectionHeader>
<bodyText confidence="0.999849375">
We believe that the most useful cues about the in-
formation needs of participants in a conversation,
or of people viewing a lecture, are the words that
are spoken during the conversation or the lecture.
For the ACLD, we use the AMI real-time ASR sys-
tem (Garner et al., 2009). One of its main features
is the use of a pre-compiled grammar, which al-
lows it to retain accuracy even when running in real-
</bodyText>
<page confidence="0.991717">
81
</page>
<bodyText confidence="0.99998464516129">
time on a low resource machine. Of course, when
content linking is done over past meetings, or for
text extraction from past recordings, the ASR sys-
tem runs slower than real-time to maximize accuracy
of recognition. However, the accuracy of real-time
ASR is only about 1% lower than the unconstrained
mode which takes several times real-time.
For the RT07 meeting data, when using signals
from individual headset microphones, the AMI ASR
system reaches about 38% word error rate. With
a microphone array, this increases to about 41%.
These values indicate that enough correct words are
sensed by the real-time ASR to make it applicable
to the ACLD, and that a robust search mechanism
could help avoiding retrieval errors due to spurious
words.
The words obtained from the ASR are filtered for
stopwords, so that only content words are used for
search; our list has about 80 words. Furthermore,
we believe that existing knowledge about the impor-
tant terminology of a domain or project can be used
to increase the impact of specific words on search. A
list of pre-specified keywords can be defined based
on such knowledge and can be modified while run-
ning the ACLD. For instance, for remote control de-
sign as in the AMI Corpus scenario, this list includes
about 30 words such as ‘chip’, ‘button’, or ‘mate-
rial’. If any of them is detected in the ASR output,
then their importance is increased for searching, but
otherwise all the other words from the ASR (minus
the stopwords) are used for constructing the query.
</bodyText>
<subsectionHeader confidence="0.996639">
4.3 Querying the Document Database
</subsectionHeader>
<bodyText confidence="0.99995268">
The Query Aggregator (QA) uses the ASR words
to retrieve the most relevant documents from one or
more databases. The current version of the ACLD
makes use of semantic search (see next subsection),
while previous versions used word-based search
from Apache Lucene for local documents, or from
the Google Web or Google Desktop APIs. ASR
words from the latest time frame are put together
(minus the stopwords) to form queries, and recog-
nized keywords are boosted in the Lucene query.
Queries are formulated at regular time intervals, typ-
ically every 15-30 seconds, or on demand. This du-
ration is a compromise between the need to gather
enough words for search, and the need to refresh the
search results reasonably often.
The results are integrated with those from the
previous time frame, using a persistence model to
smooth variations over time. The model keeps track
of the salience of each result, initialized from their
ranking among the search results, then decreasing
in time unless the document is again retrieved. The
rate of decrease (or its inverse, persistence) can be
tuned by the user, but in any case, all past results are
saved by the user interface and can be consulted at
any time.
</bodyText>
<subsectionHeader confidence="0.992305">
4.4 Semantic Search over Wikipedia
</subsectionHeader>
<bodyText confidence="0.99998225">
The goal of our method for semantic search is to
improve the relevance of the retrieved documents,
and to make the mechanism more robust to noise
from the ASR. We have applied to document re-
trieval the graph-based model of semantic rela-
tedness that we recently developed (Yazdani and
Popescu-Belis, 2010), which is also related to other
proposals (Strube and Ponzetto, 2006; Gabrilovich
and Markovitch, 2007; Yeh et al., 2009).
The model is grounded in a measure of seman-
tic relatedness between text fragments, which is
computed using random walk over the network of
Wikipedia articles – about 1.2 million articles from
the WEX data set (Metaweb Technologies, 2010).
The articles are linked through hyperlinks, and also
through lexical similarity links that are constructed
upon initialization. The random walk model allows
the computation of a visiting probability (VP) from
one article to another, and then a VP between sets of
articles, which has been shown to function as a mea-
sure of semantic relatedness, and has been applied
to various NLP problems. To compute relatedness
between two text fragments, these are first projected
represented into the network by the ten closest arti-
cles in terms of lexical similarity.
For the ACLD, the use of semantic relatedness for
document retrieval amounts to searching, in a very
large collection, the documents that are the most
closely related to the words from the ASR in a given
timeframe. Here, the document collection is (again)
the set of Wikipedia articles from WEX, and the goal
is to return the eight most related articles. Such a
search is hard to perform in real time; hence, the so-
lution that was found makes use of several approx-
imations to compute average VP between the ASR
fragment and all articles in the Wikipedia network.
</bodyText>
<page confidence="0.998338">
82
</page>
<figureCaption confidence="0.99860125">
Figure 1: Unobtrusive UI displaying document results.
Hovering the mouse over a result (here, the most relevant
one) displays a pop-up window with more information
about it.
</figureCaption>
<subsectionHeader confidence="0.997227">
4.5 The User Interface (UI)
</subsectionHeader>
<bodyText confidence="0.9995548">
The main goal of the UI is to make available all
information produced by the system, in a config-
urable way, allowing users to see a larger or smaller
amount of information according to their needs. A
modular architecture with a flexible layout has been
implemented, maximizing the accessibility but also
the understandability of the results, and displaying
also intermediary data such as ASR words and found
keywords. The UI displays up to five widgets, which
can be arranged at will:
</bodyText>
<listItem confidence="0.996195625">
1. ASR results with highlighted keywords.
2. Tag-cloud of keywords, coding for recency and
frequency of keywords.
3. Names of documents and past meeting snippets
found by the QA.
4. Names of web pages found via the Google API.
5. Names of local files found via the Google
Desktop API.
</listItem>
<bodyText confidence="0.996343666666667">
Two main arrangements are intended, though
many others are possible: an informative full-screen
UI, shown in Figure 2 with widgets 1–4; and an un-
obtrusive widget UI, with superposed tabs, shown in
Figure 1 with widget 3.
The document names displayed in widgets 3–5
function as hyperlinks to the documents, launching
appropriate external viewers when the user clicks on
them. Moreover, when hovering over a document
name, a pop-up window displays metadata and doc-
ument excerpts that match words from the query, as
an explanation of why the document was retrieved.
</bodyText>
<sectionHeader confidence="0.994244" genericHeader="evaluation">
5 Evaluation Experiments
</sectionHeader>
<bodyText confidence="0.9977">
Four types of evidence for the relevance and utility
of the ACLD are summarized in this section.
</bodyText>
<subsectionHeader confidence="0.987797">
5.1 Feedback from Potential Users
</subsectionHeader>
<bodyText confidence="0.9999816">
The ACLD was demonstrated to about 50 potential
users (industrial partners, focus groups, etc.) in a
series of sessions of about 30 minutes, starting with
a presentation of the ACLD and continuing with a
discussion and elicitation of feedback. The overall
concept was generally found useful, with positive
verbal evaluations. Feedback for smaller and larger
improvements was collected: e.g. the importance of
matching context, linking on demand, and the UI un-
obtrusive mode.
</bodyText>
<subsectionHeader confidence="0.999657">
5.2 Pilot Task-based Experiments
</subsectionHeader>
<bodyText confidence="0.99999775">
A pilot experiment was conducted by a team at the
University of Edinburgh with an earlier version of
the unobtrusive UI. Four subjects had to complete a
task that was started in previous meetings (ES2008a-
b-c from the AMI Corpus). The goal was to compare
two conditions, with vs. without the ACLD, in terms
of satisfied constraints, overall efficiency, and satis-
faction. Two pilot runs have shown that the ACLD
was being consulted about five times per meeting.
Therefore, many more runs are required to reach sta-
tistical significance of observations, and remain to
be executed depending on future resources.
</bodyText>
<subsectionHeader confidence="0.998427">
5.3 Usability Evaluation of the UI
</subsectionHeader>
<bodyText confidence="0.9999181875">
The UI was submitted to a usability evaluation ex-
periment with nine non-technical subjects. The
subjects used the ACLD over a replayed meeting
recording, and were asked to perform several tasks
with it, such as adding a keyword to monitor, search-
ing for a word, or changing the layout. The subjects
then rated usability-related statements, leading to an
assessment on the System Usability Scale (Brooke,
1996).
The overall usability score was 68% (SD: 10),
which is considered as ‘acceptable usability’ for the
SUS. The average task-completion time was 45–
75 seconds. In free-form feedback, subjects found
the system helpful to review meetings but also lec-
tures, appreciated the availability of documents, but
also noted that search results (with keyword-based
</bodyText>
<page confidence="0.998917">
83
</page>
<figureCaption confidence="0.999136">
Figure 2: Full screen UI with four widgets: ASR, keywords, document and website results.
</figureCaption>
<bodyText confidence="0.99990725">
search) were often irrelevant. They also suggested
simplifying the UI (menus, layout) and embedding
a media player for use in the meeting or lecture re-
play scenario.
</bodyText>
<subsectionHeader confidence="0.99688">
5.4 Comparing the Relevance of
Keyword-based vs. Semantic Search
</subsectionHeader>
<bodyText confidence="0.999816352941177">
We compared the output of semantic search with
that of keyword-based search. The ASR transcript
of one AMI meeting (ES2008d) was passed to both
search methods, and ‘evaluation snippets’ contain-
ing the manual transcript for one-minute excerpts,
accompanied by the 8-best Wikipedia articles found
by each method were produced. Overall, 36 snip-
pets were generated. The manual transcript shown to
subjects was enriched with punctuation and speak-
ers’ names, and the names of the Wikipedia pages
were placed on each side of the transcript frame.
Subjects were then asked to read each snippet,
and decide which of the two document sets was the
most relevant to the discussion taking place, i.e. the
most useful as a suggestion to the participants. They
could also answer ‘none’, and could consult the re-
sult if necessary.
Results were obtained from 8 subjects, each see-
ing 9 snippets out of 36. Every snippet was thus
seen by two subjects. The subjects agreed on 23
(64%) snippets and disagreed on 13 (36%). In fact,
the number of true disagreements not including the
answer ‘none’ was only 7 out of 36.
Over the 23 snippets on which subjects agreed,
the result of semantic search was judged more rel-
evant than that of keyword search for 19 snippets
(53% of the total), and the reverse for 4 snippets
only (11%). Alternatively, if one counts the votes
cast by subjects in favor of each system, regardless
of agreement, then semantic search received 72%
of the votes and keyword-based only 28%. These
numbers show that semantic search quite clearly im-
proves relevance in comparison to keyword-based
one, but there is still room for improvement.
</bodyText>
<sectionHeader confidence="0.999596" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999301166666667">
The ACLD is, to the best of our knowledge, the
first just-in-time retrieval system to use spontaneous
speech and to support access to multimedia docu-
ments and web pages, using a robust semantic search
method. Future work will aim at improving the rel-
evance of semantic search, at modeling context to
</bodyText>
<page confidence="0.993858">
84
</page>
<bodyText confidence="0.999949">
improve timing of results, and at inferring relevance
feedback from users. The ACLD should also be ap-
plied to specific use cases, and an experiment with
group work in a learning environment is under way.
</bodyText>
<sectionHeader confidence="0.997713" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999338">
The authors gratefully acknowledge the support
of the EU AMI and AMIDA Integrated Projects
(http://www.amiproject.org) and of the Swiss IM2
NCCR on Interactive Multimodal Information Man-
agement (http://www.im2.ch).
</bodyText>
<sectionHeader confidence="0.998969" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997686935064935">
John Brooke. 1996. SUS: A ‘quick and dirty’ us-
ability scale. In Patrick W. Jordan, Bruce Thomas,
Bernard A. Weerdmeester, and Ian L. McClelland, ed-
itors, Usability evaluation in industry, pages 189–194.
Taylor and Francis, London, UK.
Jay Budzik and Kristian J. Hammond. 2000. User inter-
actions with everyday applications as context for just-
in-time information access. In IUI 2000 (5th Interna-
tional Conference on Intelligent User Interfaces), New
Orleans, LA.
Susan Dumais, Edward Cutrell, Raman Sarin, and Eric
Horvitz. 2004. Implicit Queries (IQ) for contextual-
ized search. In SIGIR 2004 (27th ACM SIGIR Confer-
ence) Demonstrations, page 534, Sheffield, UK.
Evgeniy Gabrilovich and Shaul Markovitch. 2007. Com-
puting semantic relatedness using Wikipedia-based
explicit semantic analysis. In IJCAI 2007 (20th Inter-
national Joint Conference on Artificial Intelligence),
pages 6–12, Hyderabad, India.
Philip N. Garner, John Dines, Thomas Hain, Asmaa
El Hannani, Martin Karafiat, Danil Korchagin, Mike
Lincoln, Vincent Wan, and Le Zhang. 2009. Real-
time ASR from meetings. In Interspeech 2009 (10th
Annual Conference of the Intl. Speech Communication
Association), pages 2119–2122, Brighton, UK.
Masataka Goto, Koji Kitayama, Katsunobu Itou, and Tet-
sunori Kobayashi. 2004. Speech Spotter: On-demand
speech recognition in human-human conversation on
the telephone or in face-to-face situations. In ICSLP
2004 (8th International Conference on Spoken Lan-
guage Processing), pages 1533–1536, Jeju Island.
Peter E. Hart and Jamey Graham. 1997. Query-free in-
formation retrieval. IEEE Expert: Intelligent Systems
and Their Applications, 12(5):32–37.
Monika Henziker, Bay-Wei Chang, Brian Milch, and
Sergey Brin. 2005. Query-free news search. World
Wide Web: Internet and Web Information Systems,
8:101–126.
Kent Lyons, Christopher Skeels, Thad Starner, Cor-
nelis M. Snoeck, Benjamin A. Wong, and Daniel Ash-
brook. 2004. Augmenting conversations using dual-
purpose speech. In UIST 2004 (17th Annual ACM
Symposium on User Interface Software and Technol-
ogy), pages 237–246, Santa Fe, NM.
Metaweb Technologies. 2010. Freebase Wikipedia Ex-
traction (WEX). http://download.freebase.com/wex/.
Florian Metze and al. 2006. The ‘Fame’ interactive
space. In Machine Learning for Multimodal Interac-
tion II, LNCS 3869, pages 126–137. Springer, Berlin.
Maria Carmen Puerta Melguizo, Olga Monoz Ramos,
Lou Boves, Toine Bogers, and Antal van den Bosch.
2008. A personalized recommender system for writ-
ing in the Internet age. In LREC 2008 Workshop on
NLP Resources, Algorithms, and Tools for Authoring
Aids, pages 21–26, Marrakech, Morocco.
Bradley J. Rhodes and Pattie Maes. 2000. Just-in-time
information retrieval agents. IBM Systems Journal,
39(3-4):685–704.
Bradley J. Rhodes. 1997. The Wearable Remembrance
Agent: A system for augmented memory. Personal
Technologies: Special Issue on Wearable Computing,
1:218–224.
Michael Strube and Simone Paolo Ponzetto. 2006.
Wikirelate! Computing semantic relatedness using
Wikipedia. In AAAI 2006 (21st National Conference
on Artificial Intelligence), pages 1419–1424, Boston,
MA.
Majid Yazdani and Andrei Popescu-Belis. 2010. A ran-
dom walk framework to compute textual semantic sim-
ilarity: A unified model for three benchmark tasks. In
ICSC 2010 (4th IEEE International Conference on Se-
mantic Computing), pages 424–429, Pittsburgh, PA.
Eric Yeh, Daniel Ramage, Christopher D. Manning,
Eneko Agirre, and Aitor Soroa. 2009. WikiWalk: ran-
dom walks on Wikipedia for semantic relatedness. In
TextGraphs-4 (4th Workshop on Graph-based Methods
for NLP), pages 41–49, Singapore.
</reference>
<page confidence="0.999674">
85
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.791207">
<title confidence="0.996138">A Speech-based Just-in-Time Retrieval System using Semantic Search</title>
<author confidence="0.969977">Andrei Popescu-Belis</author>
<author confidence="0.969977">Majid Yazdani</author>
<author confidence="0.969977">Alexandre Nanchen</author>
<author confidence="0.969977">N Philip</author>
<affiliation confidence="0.980762">Idiap Research</affiliation>
<address confidence="0.9190995">Rue Marconi 19, CP 1920 Martigny,</address>
<abstract confidence="0.993522785714286">The Automatic Content Linking Device is a just-in-time document retrieval system which monitors an ongoing conversation or a monologue and enriches it with potentially related documents, including multimedia ones, from local repositories or from the Internet. The documents are found using keyword-based search or using a semantic similarity measure between documents and the words obtained from automatic speech recognition. Results are displayed in real time to meeting participants, or to users watching a recorded lecture or conversation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>John Brooke</author>
</authors>
<title>SUS: A ‘quick and dirty’ usability scale.</title>
<date>1996</date>
<booktitle>Usability evaluation in industry,</booktitle>
<pages>189--194</pages>
<editor>In Patrick W. Jordan, Bruce Thomas, Bernard A. Weerdmeester, and Ian L. McClelland, editors,</editor>
<publisher>Taylor and Francis,</publisher>
<location>London, UK.</location>
<contexts>
<context position="15553" citStr="Brooke, 1996" startWordPosition="2514" endWordPosition="2515">ve times per meeting. Therefore, many more runs are required to reach statistical significance of observations, and remain to be executed depending on future resources. 5.3 Usability Evaluation of the UI The UI was submitted to a usability evaluation experiment with nine non-technical subjects. The subjects used the ACLD over a replayed meeting recording, and were asked to perform several tasks with it, such as adding a keyword to monitor, searching for a word, or changing the layout. The subjects then rated usability-related statements, leading to an assessment on the System Usability Scale (Brooke, 1996). The overall usability score was 68% (SD: 10), which is considered as ‘acceptable usability’ for the SUS. The average task-completion time was 45– 75 seconds. In free-form feedback, subjects found the system helpful to review meetings but also lectures, appreciated the availability of documents, but also noted that search results (with keyword-based 83 Figure 2: Full screen UI with four widgets: ASR, keywords, document and website results. search) were often irrelevant. They also suggested simplifying the UI (menus, layout) and embedding a media player for use in the meeting or lecture replay</context>
</contexts>
<marker>Brooke, 1996</marker>
<rawString>John Brooke. 1996. SUS: A ‘quick and dirty’ usability scale. In Patrick W. Jordan, Bruce Thomas, Bernard A. Weerdmeester, and Ian L. McClelland, editors, Usability evaluation in industry, pages 189–194. Taylor and Francis, London, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jay Budzik</author>
<author>Kristian J Hammond</author>
</authors>
<title>User interactions with everyday applications as context for justin-time information access.</title>
<date>2000</date>
<booktitle>In IUI 2000 (5th International Conference on Intelligent User Interfaces),</booktitle>
<location>New Orleans, LA.</location>
<contexts>
<context position="4578" citStr="Budzik and Hammond, 2000" startWordPosition="716" endWordPosition="719">agnostic system, and excerpts from maintenance manuals depending on the interaction state. The Remembrance Agent was integrated to the Emacs text editor, and ran searches over emails or notes at regular time intervals (every few seconds) using the latest 20–500 words typed by the user. The IQ system generated context-sensitive searches based on a user’s ongoing activities on their computer, such as writing email. A version of the Remembrance Agent called Jimminy was conceived as a wearable assistant for taking notes, but ASR was only simulated for evaluation (Rhodes, 1997). The Watson system (Budzik and Hammond, 2000) monitored the user’s operations in a text editor, but proposed a more complex mechanism than the Remembrance Agent for selecting terms for queries, which were directed to a web search engine. Another assistant for an authoring environment was developed in the A-Propos project (Puerta Melguizo et al., 2008). A query-free system was designed for enriching television news with articles from the Web (Henziker et al., 2005). The FAME interactive space (Metze and al., 2006), which provides multi-modal access to recordings of lectures via a table top interface, bears many similarities to the ACLD. H</context>
</contexts>
<marker>Budzik, Hammond, 2000</marker>
<rawString>Jay Budzik and Kristian J. Hammond. 2000. User interactions with everyday applications as context for justin-time information access. In IUI 2000 (5th International Conference on Intelligent User Interfaces), New Orleans, LA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan Dumais</author>
<author>Edward Cutrell</author>
<author>Raman Sarin</author>
<author>Eric Horvitz</author>
</authors>
<title>Implicit Queries (IQ) for contextualized search.</title>
<date>2004</date>
<booktitle>In SIGIR 2004 (27th ACM SIGIR Conference) Demonstrations,</booktitle>
<pages>534</pages>
<location>Sheffield, UK.</location>
<contexts>
<context position="3892" citStr="Dumais et al., 2004" startWordPosition="604" endWordPosition="607"> ACL-HLT 2011 System Demonstrations, pages 80–85, Portland, Oregon, USA, 21 June 2011. c�2011 Association for Computational Linguistics time by its user. The advantage of real-time content linking over a more static enrichment, such as the Feynman lectures at Microsoft Research,1 is that users can tune search parameters at will while viewing the lecture. 3 Just-in-Time Retrieval Systems The first precursors to the ACLD were the Fixit query-free search system (Hart and Graham, 1997), the Remembrance Agent for just-in-time retrieval (Rhodes and Maes, 2000), and the Implicit Queries (IQ) system (Dumais et al., 2004). Fixit monitored the state of a user’s interaction with a diagnostic system, and excerpts from maintenance manuals depending on the interaction state. The Remembrance Agent was integrated to the Emacs text editor, and ran searches over emails or notes at regular time intervals (every few seconds) using the latest 20–500 words typed by the user. The IQ system generated context-sensitive searches based on a user’s ongoing activities on their computer, such as writing email. A version of the Remembrance Agent called Jimminy was conceived as a wearable assistant for taking notes, but ASR was only</context>
</contexts>
<marker>Dumais, Cutrell, Sarin, Horvitz, 2004</marker>
<rawString>Susan Dumais, Edward Cutrell, Raman Sarin, and Eric Horvitz. 2004. Implicit Queries (IQ) for contextualized search. In SIGIR 2004 (27th ACM SIGIR Conference) Demonstrations, page 534, Sheffield, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeniy Gabrilovich</author>
<author>Shaul Markovitch</author>
</authors>
<title>Computing semantic relatedness using Wikipedia-based explicit semantic analysis.</title>
<date>2007</date>
<booktitle>In IJCAI 2007 (20th International Joint Conference on Artificial Intelligence),</booktitle>
<pages>6--12</pages>
<location>Hyderabad, India.</location>
<contexts>
<context position="10921" citStr="Gabrilovich and Markovitch, 2007" startWordPosition="1752" endWordPosition="1755">n retrieved. The rate of decrease (or its inverse, persistence) can be tuned by the user, but in any case, all past results are saved by the user interface and can be consulted at any time. 4.4 Semantic Search over Wikipedia The goal of our method for semantic search is to improve the relevance of the retrieved documents, and to make the mechanism more robust to noise from the ASR. We have applied to document retrieval the graph-based model of semantic relatedness that we recently developed (Yazdani and Popescu-Belis, 2010), which is also related to other proposals (Strube and Ponzetto, 2006; Gabrilovich and Markovitch, 2007; Yeh et al., 2009). The model is grounded in a measure of semantic relatedness between text fragments, which is computed using random walk over the network of Wikipedia articles – about 1.2 million articles from the WEX data set (Metaweb Technologies, 2010). The articles are linked through hyperlinks, and also through lexical similarity links that are constructed upon initialization. The random walk model allows the computation of a visiting probability (VP) from one article to another, and then a VP between sets of articles, which has been shown to function as a measure of semantic relatedne</context>
</contexts>
<marker>Gabrilovich, Markovitch, 2007</marker>
<rawString>Evgeniy Gabrilovich and Shaul Markovitch. 2007. Computing semantic relatedness using Wikipedia-based explicit semantic analysis. In IJCAI 2007 (20th International Joint Conference on Artificial Intelligence), pages 6–12, Hyderabad, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip N Garner</author>
<author>John Dines</author>
<author>Thomas Hain</author>
<author>Asmaa El Hannani</author>
<author>Martin Karafiat</author>
<author>Danil Korchagin</author>
<author>Mike Lincoln</author>
<author>Vincent Wan</author>
<author>Le Zhang</author>
</authors>
<title>Realtime ASR from meetings.</title>
<date>2009</date>
<booktitle>In Interspeech 2009 (10th Annual Conference of the Intl. Speech Communication Association),</booktitle>
<pages>2119--2122</pages>
<location>Brighton, UK.</location>
<marker>Garner, Dines, Hain, El Hannani, Karafiat, Korchagin, Lincoln, Wan, Le Zhang, 2009</marker>
<rawString>Philip N. Garner, John Dines, Thomas Hain, Asmaa El Hannani, Martin Karafiat, Danil Korchagin, Mike Lincoln, Vincent Wan, and Le Zhang. 2009. Realtime ASR from meetings. In Interspeech 2009 (10th Annual Conference of the Intl. Speech Communication Association), pages 2119–2122, Brighton, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masataka Goto</author>
<author>Koji Kitayama</author>
<author>Katsunobu Itou</author>
<author>Tetsunori Kobayashi</author>
</authors>
<title>Speech Spotter: On-demand speech recognition in human-human conversation on the telephone or in face-to-face situations.</title>
<date>2004</date>
<booktitle>In ICSLP 2004 (8th International Conference on Spoken Language Processing),</booktitle>
<pages>1533--1536</pages>
<location>Jeju Island.</location>
<contexts>
<context position="5766" citStr="Goto et al., 2004" startWordPosition="892" endWordPosition="895">ny similarities to the ACLD. However, it requires the use of specific voice commands by one user only, and does not spontaneously follow a conversation. More recently, several speech-based search engines have become available, including as smart phone applications. Conversely, many systems allow searching of spoken document archives.2 Inspi1See http://research.microsoft.com/apps/tools/tuva/. 2See workshops at http://www.searchingspeech.org. ration from these approaches, which are not queryfree, can nevertheless be useful to just-in-time retrieval. Other related systems are the Speech Spotter (Goto et al., 2004) and a personal assistant using dual-purpose speech (Lyons et al., 2004), which enable users to search for information using commands that are identified in the speech flow. The ACLD improves over numerous past ones by giving access to indexed multimedia recordings as well as websites, with fully operational ASR and semantic search, as we now explain. 4 Description of the ACLD The architecture of the ACLD comprises the following functions: document preparation, text extraction and indexing; input sensing and query preparation; search and integration of results; user interface to display the re</context>
</contexts>
<marker>Goto, Kitayama, Itou, Kobayashi, 2004</marker>
<rawString>Masataka Goto, Koji Kitayama, Katsunobu Itou, and Tetsunori Kobayashi. 2004. Speech Spotter: On-demand speech recognition in human-human conversation on the telephone or in face-to-face situations. In ICSLP 2004 (8th International Conference on Spoken Language Processing), pages 1533–1536, Jeju Island.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter E Hart</author>
<author>Jamey Graham</author>
</authors>
<title>Query-free information retrieval.</title>
<date>1997</date>
<journal>IEEE Expert: Intelligent Systems and Their Applications,</journal>
<volume>12</volume>
<issue>5</issue>
<contexts>
<context position="3758" citStr="Hart and Graham, 1997" startWordPosition="584" endWordPosition="587">e lectures with related material drawn from various repositories, through a search process that can be guided in real Proceedings of the ACL-HLT 2011 System Demonstrations, pages 80–85, Portland, Oregon, USA, 21 June 2011. c�2011 Association for Computational Linguistics time by its user. The advantage of real-time content linking over a more static enrichment, such as the Feynman lectures at Microsoft Research,1 is that users can tune search parameters at will while viewing the lecture. 3 Just-in-Time Retrieval Systems The first precursors to the ACLD were the Fixit query-free search system (Hart and Graham, 1997), the Remembrance Agent for just-in-time retrieval (Rhodes and Maes, 2000), and the Implicit Queries (IQ) system (Dumais et al., 2004). Fixit monitored the state of a user’s interaction with a diagnostic system, and excerpts from maintenance manuals depending on the interaction state. The Remembrance Agent was integrated to the Emacs text editor, and ran searches over emails or notes at regular time intervals (every few seconds) using the latest 20–500 words typed by the user. The IQ system generated context-sensitive searches based on a user’s ongoing activities on their computer, such as wri</context>
</contexts>
<marker>Hart, Graham, 1997</marker>
<rawString>Peter E. Hart and Jamey Graham. 1997. Query-free information retrieval. IEEE Expert: Intelligent Systems and Their Applications, 12(5):32–37.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Monika Henziker</author>
<author>Bay-Wei Chang</author>
<author>Brian Milch</author>
<author>Sergey Brin</author>
</authors>
<title>Query-free news search. World Wide Web: Internet and Web Information Systems,</title>
<date>2005</date>
<pages>8--101</pages>
<contexts>
<context position="5001" citStr="Henziker et al., 2005" startWordPosition="783" endWordPosition="786"> of the Remembrance Agent called Jimminy was conceived as a wearable assistant for taking notes, but ASR was only simulated for evaluation (Rhodes, 1997). The Watson system (Budzik and Hammond, 2000) monitored the user’s operations in a text editor, but proposed a more complex mechanism than the Remembrance Agent for selecting terms for queries, which were directed to a web search engine. Another assistant for an authoring environment was developed in the A-Propos project (Puerta Melguizo et al., 2008). A query-free system was designed for enriching television news with articles from the Web (Henziker et al., 2005). The FAME interactive space (Metze and al., 2006), which provides multi-modal access to recordings of lectures via a table top interface, bears many similarities to the ACLD. However, it requires the use of specific voice commands by one user only, and does not spontaneously follow a conversation. More recently, several speech-based search engines have become available, including as smart phone applications. Conversely, many systems allow searching of spoken document archives.2 Inspi1See http://research.microsoft.com/apps/tools/tuva/. 2See workshops at http://www.searchingspeech.org. ration f</context>
</contexts>
<marker>Henziker, Chang, Milch, Brin, 2005</marker>
<rawString>Monika Henziker, Bay-Wei Chang, Brian Milch, and Sergey Brin. 2005. Query-free news search. World Wide Web: Internet and Web Information Systems, 8:101–126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kent Lyons</author>
<author>Christopher Skeels</author>
<author>Thad Starner</author>
<author>Cornelis M Snoeck</author>
<author>Benjamin A Wong</author>
<author>Daniel Ashbrook</author>
</authors>
<title>Augmenting conversations using dualpurpose speech.</title>
<date>2004</date>
<booktitle>In UIST 2004 (17th Annual ACM Symposium on User Interface Software and Technology),</booktitle>
<pages>237--246</pages>
<location>Santa Fe, NM.</location>
<contexts>
<context position="5838" citStr="Lyons et al., 2004" startWordPosition="903" endWordPosition="906">oice commands by one user only, and does not spontaneously follow a conversation. More recently, several speech-based search engines have become available, including as smart phone applications. Conversely, many systems allow searching of spoken document archives.2 Inspi1See http://research.microsoft.com/apps/tools/tuva/. 2See workshops at http://www.searchingspeech.org. ration from these approaches, which are not queryfree, can nevertheless be useful to just-in-time retrieval. Other related systems are the Speech Spotter (Goto et al., 2004) and a personal assistant using dual-purpose speech (Lyons et al., 2004), which enable users to search for information using commands that are identified in the speech flow. The ACLD improves over numerous past ones by giving access to indexed multimedia recordings as well as websites, with fully operational ASR and semantic search, as we now explain. 4 Description of the ACLD The architecture of the ACLD comprises the following functions: document preparation, text extraction and indexing; input sensing and query preparation; search and integration of results; user interface to display the results. 4.1 Document Preparation and Indexing The preparation of the loca</context>
</contexts>
<marker>Lyons, Skeels, Starner, Snoeck, Wong, Ashbrook, 2004</marker>
<rawString>Kent Lyons, Christopher Skeels, Thad Starner, Cornelis M. Snoeck, Benjamin A. Wong, and Daniel Ashbrook. 2004. Augmenting conversations using dualpurpose speech. In UIST 2004 (17th Annual ACM Symposium on User Interface Software and Technology), pages 237–246, Santa Fe, NM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Metaweb Technologies</author>
</authors>
<title>Freebase Wikipedia Extraction</title>
<date>2010</date>
<contexts>
<context position="11179" citStr="Technologies, 2010" startWordPosition="1797" endWordPosition="1798">to improve the relevance of the retrieved documents, and to make the mechanism more robust to noise from the ASR. We have applied to document retrieval the graph-based model of semantic relatedness that we recently developed (Yazdani and Popescu-Belis, 2010), which is also related to other proposals (Strube and Ponzetto, 2006; Gabrilovich and Markovitch, 2007; Yeh et al., 2009). The model is grounded in a measure of semantic relatedness between text fragments, which is computed using random walk over the network of Wikipedia articles – about 1.2 million articles from the WEX data set (Metaweb Technologies, 2010). The articles are linked through hyperlinks, and also through lexical similarity links that are constructed upon initialization. The random walk model allows the computation of a visiting probability (VP) from one article to another, and then a VP between sets of articles, which has been shown to function as a measure of semantic relatedness, and has been applied to various NLP problems. To compute relatedness between two text fragments, these are first projected represented into the network by the ten closest articles in terms of lexical similarity. For the ACLD, the use of semantic relatedn</context>
</contexts>
<marker>Technologies, 2010</marker>
<rawString>Metaweb Technologies. 2010. Freebase Wikipedia Extraction (WEX). http://download.freebase.com/wex/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Florian Metze</author>
<author>al</author>
</authors>
<title>The ‘Fame’ interactive space.</title>
<date>2006</date>
<booktitle>In Machine Learning for Multimodal Interaction II, LNCS 3869,</booktitle>
<pages>126--137</pages>
<publisher>Springer,</publisher>
<location>Berlin.</location>
<marker>Metze, al, 2006</marker>
<rawString>Florian Metze and al. 2006. The ‘Fame’ interactive space. In Machine Learning for Multimodal Interaction II, LNCS 3869, pages 126–137. Springer, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Carmen Puerta Melguizo</author>
<author>Olga Monoz Ramos</author>
<author>Lou Boves</author>
<author>Toine Bogers</author>
<author>Antal van den Bosch</author>
</authors>
<title>A personalized recommender system for writing in the Internet age.</title>
<date>2008</date>
<booktitle>In LREC 2008 Workshop on NLP Resources, Algorithms, and Tools for Authoring Aids,</booktitle>
<pages>21--26</pages>
<location>Marrakech, Morocco.</location>
<marker>Melguizo, Ramos, Boves, Bogers, van den Bosch, 2008</marker>
<rawString>Maria Carmen Puerta Melguizo, Olga Monoz Ramos, Lou Boves, Toine Bogers, and Antal van den Bosch. 2008. A personalized recommender system for writing in the Internet age. In LREC 2008 Workshop on NLP Resources, Algorithms, and Tools for Authoring Aids, pages 21–26, Marrakech, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bradley J Rhodes</author>
<author>Pattie Maes</author>
</authors>
<title>Just-in-time information retrieval agents.</title>
<date>2000</date>
<journal>IBM Systems Journal,</journal>
<pages>39--3</pages>
<contexts>
<context position="3832" citStr="Rhodes and Maes, 2000" startWordPosition="594" endWordPosition="597">a search process that can be guided in real Proceedings of the ACL-HLT 2011 System Demonstrations, pages 80–85, Portland, Oregon, USA, 21 June 2011. c�2011 Association for Computational Linguistics time by its user. The advantage of real-time content linking over a more static enrichment, such as the Feynman lectures at Microsoft Research,1 is that users can tune search parameters at will while viewing the lecture. 3 Just-in-Time Retrieval Systems The first precursors to the ACLD were the Fixit query-free search system (Hart and Graham, 1997), the Remembrance Agent for just-in-time retrieval (Rhodes and Maes, 2000), and the Implicit Queries (IQ) system (Dumais et al., 2004). Fixit monitored the state of a user’s interaction with a diagnostic system, and excerpts from maintenance manuals depending on the interaction state. The Remembrance Agent was integrated to the Emacs text editor, and ran searches over emails or notes at regular time intervals (every few seconds) using the latest 20–500 words typed by the user. The IQ system generated context-sensitive searches based on a user’s ongoing activities on their computer, such as writing email. A version of the Remembrance Agent called Jimminy was conceive</context>
</contexts>
<marker>Rhodes, Maes, 2000</marker>
<rawString>Bradley J. Rhodes and Pattie Maes. 2000. Just-in-time information retrieval agents. IBM Systems Journal, 39(3-4):685–704.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bradley J Rhodes</author>
</authors>
<title>The Wearable Remembrance Agent: A system for augmented memory.</title>
<date>1997</date>
<journal>Personal Technologies: Special Issue on Wearable Computing,</journal>
<pages>1--218</pages>
<contexts>
<context position="4532" citStr="Rhodes, 1997" startWordPosition="711" endWordPosition="712"> of a user’s interaction with a diagnostic system, and excerpts from maintenance manuals depending on the interaction state. The Remembrance Agent was integrated to the Emacs text editor, and ran searches over emails or notes at regular time intervals (every few seconds) using the latest 20–500 words typed by the user. The IQ system generated context-sensitive searches based on a user’s ongoing activities on their computer, such as writing email. A version of the Remembrance Agent called Jimminy was conceived as a wearable assistant for taking notes, but ASR was only simulated for evaluation (Rhodes, 1997). The Watson system (Budzik and Hammond, 2000) monitored the user’s operations in a text editor, but proposed a more complex mechanism than the Remembrance Agent for selecting terms for queries, which were directed to a web search engine. Another assistant for an authoring environment was developed in the A-Propos project (Puerta Melguizo et al., 2008). A query-free system was designed for enriching television news with articles from the Web (Henziker et al., 2005). The FAME interactive space (Metze and al., 2006), which provides multi-modal access to recordings of lectures via a table top int</context>
</contexts>
<marker>Rhodes, 1997</marker>
<rawString>Bradley J. Rhodes. 1997. The Wearable Remembrance Agent: A system for augmented memory. Personal Technologies: Special Issue on Wearable Computing, 1:218–224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Strube</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>Wikirelate! Computing semantic relatedness using Wikipedia.</title>
<date>2006</date>
<booktitle>In AAAI 2006 (21st National Conference on Artificial Intelligence),</booktitle>
<pages>1419--1424</pages>
<location>Boston, MA.</location>
<contexts>
<context position="10887" citStr="Strube and Ponzetto, 2006" startWordPosition="1748" endWordPosition="1751">unless the document is again retrieved. The rate of decrease (or its inverse, persistence) can be tuned by the user, but in any case, all past results are saved by the user interface and can be consulted at any time. 4.4 Semantic Search over Wikipedia The goal of our method for semantic search is to improve the relevance of the retrieved documents, and to make the mechanism more robust to noise from the ASR. We have applied to document retrieval the graph-based model of semantic relatedness that we recently developed (Yazdani and Popescu-Belis, 2010), which is also related to other proposals (Strube and Ponzetto, 2006; Gabrilovich and Markovitch, 2007; Yeh et al., 2009). The model is grounded in a measure of semantic relatedness between text fragments, which is computed using random walk over the network of Wikipedia articles – about 1.2 million articles from the WEX data set (Metaweb Technologies, 2010). The articles are linked through hyperlinks, and also through lexical similarity links that are constructed upon initialization. The random walk model allows the computation of a visiting probability (VP) from one article to another, and then a VP between sets of articles, which has been shown to function </context>
</contexts>
<marker>Strube, Ponzetto, 2006</marker>
<rawString>Michael Strube and Simone Paolo Ponzetto. 2006. Wikirelate! Computing semantic relatedness using Wikipedia. In AAAI 2006 (21st National Conference on Artificial Intelligence), pages 1419–1424, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Majid Yazdani</author>
<author>Andrei Popescu-Belis</author>
</authors>
<title>A random walk framework to compute textual semantic similarity: A unified model for three benchmark tasks.</title>
<date>2010</date>
<booktitle>In ICSC 2010 (4th IEEE International Conference on Semantic Computing),</booktitle>
<pages>424--429</pages>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="10818" citStr="Yazdani and Popescu-Belis, 2010" startWordPosition="1737" endWordPosition="1740">alized from their ranking among the search results, then decreasing in time unless the document is again retrieved. The rate of decrease (or its inverse, persistence) can be tuned by the user, but in any case, all past results are saved by the user interface and can be consulted at any time. 4.4 Semantic Search over Wikipedia The goal of our method for semantic search is to improve the relevance of the retrieved documents, and to make the mechanism more robust to noise from the ASR. We have applied to document retrieval the graph-based model of semantic relatedness that we recently developed (Yazdani and Popescu-Belis, 2010), which is also related to other proposals (Strube and Ponzetto, 2006; Gabrilovich and Markovitch, 2007; Yeh et al., 2009). The model is grounded in a measure of semantic relatedness between text fragments, which is computed using random walk over the network of Wikipedia articles – about 1.2 million articles from the WEX data set (Metaweb Technologies, 2010). The articles are linked through hyperlinks, and also through lexical similarity links that are constructed upon initialization. The random walk model allows the computation of a visiting probability (VP) from one article to another, and </context>
</contexts>
<marker>Yazdani, Popescu-Belis, 2010</marker>
<rawString>Majid Yazdani and Andrei Popescu-Belis. 2010. A random walk framework to compute textual semantic similarity: A unified model for three benchmark tasks. In ICSC 2010 (4th IEEE International Conference on Semantic Computing), pages 424–429, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Yeh</author>
<author>Daniel Ramage</author>
<author>Christopher D Manning</author>
<author>Eneko Agirre</author>
<author>Aitor Soroa</author>
</authors>
<title>WikiWalk: random walks on Wikipedia for semantic relatedness.</title>
<date>2009</date>
<booktitle>In TextGraphs-4 (4th Workshop on Graph-based Methods for NLP),</booktitle>
<pages>41--49</pages>
<contexts>
<context position="10940" citStr="Yeh et al., 2009" startWordPosition="1756" endWordPosition="1759">(or its inverse, persistence) can be tuned by the user, but in any case, all past results are saved by the user interface and can be consulted at any time. 4.4 Semantic Search over Wikipedia The goal of our method for semantic search is to improve the relevance of the retrieved documents, and to make the mechanism more robust to noise from the ASR. We have applied to document retrieval the graph-based model of semantic relatedness that we recently developed (Yazdani and Popescu-Belis, 2010), which is also related to other proposals (Strube and Ponzetto, 2006; Gabrilovich and Markovitch, 2007; Yeh et al., 2009). The model is grounded in a measure of semantic relatedness between text fragments, which is computed using random walk over the network of Wikipedia articles – about 1.2 million articles from the WEX data set (Metaweb Technologies, 2010). The articles are linked through hyperlinks, and also through lexical similarity links that are constructed upon initialization. The random walk model allows the computation of a visiting probability (VP) from one article to another, and then a VP between sets of articles, which has been shown to function as a measure of semantic relatedness, and has been ap</context>
</contexts>
<marker>Yeh, Ramage, Manning, Agirre, Soroa, 2009</marker>
<rawString>Eric Yeh, Daniel Ramage, Christopher D. Manning, Eneko Agirre, and Aitor Soroa. 2009. WikiWalk: random walks on Wikipedia for semantic relatedness. In TextGraphs-4 (4th Workshop on Graph-based Methods for NLP), pages 41–49, Singapore.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>