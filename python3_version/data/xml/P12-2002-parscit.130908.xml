<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.018206">
<title confidence="0.7199515">
Joint Evaluation of Morphological Segmentation and Syntactic Parsing
Reut Tsarfaty Joakim Nivre Evelina Andersson
</title>
<address confidence="0.445775">
Box 635, 751 26, Uppsala University, Uppsala, Sweden
</address>
<email confidence="0.977573">
tsarfaty@stp.lingfil.uu.se, Uoakim.nivre, evelina.andersson}@lingfil.uu.se
</email>
<sectionHeader confidence="0.998547" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999956571428571">
We present novel metrics for parse evalua-
tion in joint segmentation and parsing sce-
narios where the gold sequence of terminals
is not known in advance. The protocol uses
distance-based metrics defined for the space
of trees over lattices. Our metrics allow us
to precisely quantify the performance gap be-
tween non-realistic parsing scenarios (assum-
ing gold segmented and tagged input) and re-
alistic ones (not assuming gold segmentation
and tags). Our evaluation of segmentation and
parsing for Modern Hebrew sheds new light
on the performance of the best parsing systems
to date in the different scenarios.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99983975">
A parser takes a sentence in natural language as in-
put and returns a syntactic parse tree representing
the sentence’s human-perceived interpretation. Cur-
rent state-of-the-art parsers assume that the space-
delimited words in the input are the basic units of
syntactic analysis. Standard evaluation procedures
and metrics (Black et al., 1991; Buchholz and Marsi,
2006) accordingly assume that the yield of the parse
tree is known in advance. This assumption breaks
down when parsing morphologically rich languages
(Tsarfaty et al., 2010), where every space-delimited
word may be effectively composed of multiple mor-
phemes, each of which having a distinct role in the
syntactic parse tree. In order to parse such input the
text needs to undergo morphological segmentation,
that is, identifying the morphological segments of
each word and assigning the corresponding part-of-
speech (PoS) tags to them.
Morphologically complex words may be highly
ambiguous and in order to segment them correctly
their analysis has to be disambiguated. The multiple
morphological analyses of input words may be rep-
resented via a lattice that encodes the different seg-
mentation possibilities of the entire word sequence.
One can either select a segmentation path prior to
parsing, or, as has been recently argued, one can let
the parser pick a segmentation jointly with decoding
(Tsarfaty, 2006; Cohen and Smith, 2007; Goldberg
and Tsarfaty, 2008; Green and Manning, 2010). If
the selected segmentation is different from the gold
segmentation, the gold and parse trees are rendered
incomparable and standard evaluation metrics break
down. Evaluation scenarios restricted to gold input
are often used to bypass this problem, but, as shall be
seen shortly, they present an overly optimistic upper-
bound on parser performance.
This paper presents a full treatment of evaluation
in different parsing scenarios, using distance-based
measures defined for trees over a shared common
denominator defined in terms of a lattice structure.
We demonstrate the informativeness of our metrics
by evaluating joint segmentation and parsing perfor-
mance for the Semitic language Modern Hebrew, us-
ing the best performing systems, both constituency-
based and dependency-based (Tsarfaty, 2010; Gold-
berg, 2011a). Our experiments demonstrate that, for
all parsers, significant performance gaps between re-
alistic and non-realistic scenarios crucially depend
on the kind of information initially provided to the
parser. The tool and metrics that we provide are
completely general and can straightforwardly apply
to other languages, treebanks and different tasks.
</bodyText>
<page confidence="0.989788">
6
</page>
<note confidence="0.8117985">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 6–10,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<figure confidence="0.997568239130435">
(tree1) TOP (tree2) TOP
PP PP
NP
IN
0B1
“in”
NP
IN
0B1
“in”
NP
ADJP
PRN
4HM5
“them”
POSS
3FL4
of
PP
NP
DEF
1H2
“the”
DEF
5H6
“the”
NN
2CL3
“shadow”
JJ
6NEIM7
“pleasant”
NN
1CL2
“shadow”
NP
PP
POSS
2FL3
“of”
PRN
3HM4
“them”
VB
4HNEIM5
“made-pleasant”
</figure>
<figureCaption confidence="0.971141">
Figure 1: A correct tree (tree1) and an incorrect tree (tree2) for “BCLM HNEIM”, indexed by terminal boundaries.
Erroneous nodes in the parse hypothesis are marked in italics. Missing nodes from the hypothesis are marked in bold.
</figureCaption>
<sectionHeader confidence="0.939133" genericHeader="method">
2 The Challenge: Evaluation for MRLs
</sectionHeader>
<bodyText confidence="0.999979615384615">
In morphologically rich languages (MRLs) substan-
tial information about the grammatical relations be-
tween entities is expressed at word level using in-
flectional affixes. In particular, in MRLs such as He-
brew, Arabic, Turkish or Maltese, elements such as
determiners, definite articles and conjunction mark-
ers appear as affixes that are appended to an open-
class word. Take, for example the Hebrew word-
token BCLM,1 which means “in their shadow”. This
word corresponds to five distinctly tagged elements:
B (“in”/IN), H (“the”/DEF), CL (“shadow”/NN), FL
(”of”/POSS), HM (”they”/PRN). Note that morpho-
logical segmentation is not the inverse of concatena-
tion. For instance, the overt definite article H and
the possessor FL show up only in the analysis.
The correct parse for the Hebrew phrase “BCLM
HNEIM” is shown in Figure 1 (tree1), and it pre-
supposes that these segments can be identified and
assigned the correct PoS tags. However, morpholog-
ical segmentation is non-trivial due to massive word-
level ambiguity. The word BCLM, for instance, can
be segmented into the noun BCL (“onion”) and M (a
genitive suffix, “of them”), or into the prefix B (“in”)
followed by the noun CLM (“image”).2 The multi-
tude of morphological analyses may be encoded in a
lattice structure, as illustrated in Figure 2.
</bodyText>
<footnote confidence="0.87475475">
1We use the Hebrew transliteration in Sima’an et al. (2001).
2The complete set of analyses for this word is provided in
Goldberg and Tsarfaty (2008). Examples for similar phenom-
ena in Arabic may be found in Green and Manning (2010).
</footnote>
<figureCaption confidence="0.988072">
Figure 2: The morphological segmentation possibilities
of BCLM HNEIM. Double-circles are word boundaries.
</figureCaption>
<bodyText confidence="0.999971608695652">
In practice, a statistical component is required to
decide on the correct morphological segmentation,
that is, to pick out the correct path through the lat-
tice. This may be done based on linear local context
(Adler and Elhadad, 2006; Shacham and Wintner,
2007; Bar-haim et al., 2008; Habash and Rambow,
2005), or jointly with parsing (Tsarfaty, 2006; Gold-
berg and Tsarfaty, 2008; Green and Manning, 2010).
Either way, an incorrect morphological segmenta-
tion hypothesis introduces errors into the parse hy-
pothesis, ultimately providing a parse tree which
spans a different yield than the gold terminals. In
such cases, existing evaluation metrics break down.
To understand why, consider the trees in Figure 1.
Metrics like PARSEVAL (Black et al., 1991) cal-
culate the harmonic means of precision and recall
on labeled spans (i, label, j) where i, j are termi-
nal boundaries. Now, the NP dominating “shadow
of them” has been identified and labeled correctly
in tree2, but in tree1 it spans (2, NP, 5) and in tree2
it spans (1, NP, 4). This node will then be counted
as an error for tree2, along with its dominated and
dominating structure, and PARSEVAL will score 0.
</bodyText>
<page confidence="0.997222">
7
</page>
<bodyText confidence="0.999854066666667">
A generalized version of PARSEVAL which con-
siders i, j character-based indices instead of termi-
nal boundaries (Tsarfaty, 2006) will fail here too,
since the missing overt definite article H will cause
similar misalignments. Metrics for dependency-
based evaluation such as ATTACHMENT SCORES
(Buchholz and Marsi, 2006) suffer from similar
problems, since they assume that both trees have the
same nodes — an assumption that breaks down in
the case of incorrect morphological segmentation.
Although great advances have been made in pars-
ing MRLs in recent years, this evaluation challenge
remained unsolved.3 In this paper we present a solu-
tion to this challenge by extending TEDEVAL (Tsar-
faty et al., 2011) for handling trees over lattices.
</bodyText>
<sectionHeader confidence="0.999211" genericHeader="method">
3 The Proposal: Distance-Based Metrics
</sectionHeader>
<bodyText confidence="0.99394368">
Input and Output Spaces We view the joint task
as a structured prediction function h : X → Y from
input space X onto output space Y. Each element
x ∈ X is a sequence x = w1, ... , wn of space-
delimited words from a set W. We assume a lexicon
LEX, distinct from W, containing pairs of segments
drawn from a set T of terminals and PoS categories
drawn from a set N of nonterminals.
LEX = {hs, pi|s ∈ T , p ∈ N}
Each word wi in the input may admit multiple
morphological analyses, constrained by a language-
specific morphological analyzer MA. The morpho-
logical analysis of an input word MA(wi) can be
represented as a lattice Li in which every arc cor-
responds to a lexicon entry hs, pi. The morpholog-
ical analysis of an input sentence x is then a lattice
L obtained through the concatenation of the lattices
L1, ... , Ln where MA(w1) = L1, ... , MA(wn) =
Ln. Now, let x = w1, ... , wn be a sentence with
a morphological analysis lattice MA(x) = L. We
define the output space YMA(x)=L for h (abbreviated
YL), as the set of linearly-ordered labeled trees such
that the yield of LEX entries hs1, p1i,...,hsk,pki in
each tree (where si ∈ T and pi ∈ N, and possibly
k =6 n) corresponds to a path through the lattice L.
</bodyText>
<footnote confidence="0.544831">
3A tool that could potentially apply here is SParseval (Roark
et al., 2006). But since it does not respect word-boundaries, it
fails to apply to such lattices. Cohen and Smith (2007) aimed to
fix this, but in their implementation syntactic nodes internal to
word boundaries may be lost without scoring.
</footnote>
<bodyText confidence="0.989713470588235">
Edit Scripts and Edit Costs We assume a
set A={ADD(c, i, j),DEL(c, i, j),ADD(hs, pi, i, j),
DEL(hs, pi, i, j)} of edit operations which can add
or delete a labeled node c ∈ N or an entry hs, pi ∈
LEX which spans the states i, j in the lattice L. The
operations in A are properly constrained by the lat-
tice, that is, we can only add and delete lexemes that
belong to LEX, and we can only add and delete them
where they can occur in the lattice. We assume a
function C(a) = 1 assigning a unit cost to every op-
eration a ∈ A, and define the cost of a sequence
ha1, ... , ami as the sum of the costs of all opera-
tions in the sequence C(ha1, ..., ami) = Emi=1 C(ai).
An edit script ES(y1, y2) = ha1, ... , ami is a se-
quence of operations that turns y1 into y2. The tree-
edit distance is the minimum cost of any edit script
that turns y1 into y2 (Bille, 2005).
</bodyText>
<equation confidence="0.9984305">
TED(y1, y2) = min
ES(y1,y2)
</equation>
<bodyText confidence="0.99927775">
Distance-Based Metrics The error of a predicted
structure p with respect to a gold structure g is now
taken to be the TED cost, and we can turn it into a
score by normalizing it and subtracting from a unity:
</bodyText>
<equation confidence="0.855088">
TEDEVAL(p, g) = 1 |p |+ |g |− 2
</equation>
<bodyText confidence="0.97987">
The term |p |+ |g |− 2 is a normalization factor de-
fined in terms of the worst-case scenario, in which
the parser has only made incorrect decisions. We
would need to delete all lexemes and nodes in p and
add all the lexemes and nodes of g, except for roots.
An Example Both trees in Figure 1 are contained
in YL for the lattice L in Figure 2. If we re-
place terminal boundaries with lattice indices from
Figure 2, we need 6 edit operations to turn tree2
into tree1 (deleting the nodes in italic, adding the
nodes in bold) and the evaluation score will be
</bodyText>
<equation confidence="0.9914625">
TEDEVAL(tree2,tree1) = 1 − 6
14+10−2 = 0.7273.
</equation>
<sectionHeader confidence="0.999443" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.947292833333333">
We aim to evaluate state-of-the-art parsing architec-
tures on the morphosyntactic disambiguation of He-
brew texts in three different parsing scenarios: (i)
Gold: assuming gold segmentation and PoS-tags,
(ii) Predicted: assuming only gold segmentation,
and (iii) Raw: assuming unanalyzed input text.
</bodyText>
<equation confidence="0.9841735">
C(ES(y1, y2))
TED(p, g)
</equation>
<page confidence="0.991874">
8
</page>
<table confidence="0.999531461538462">
SEGEVAL PARSEVAL TEDEVAL
Gold PS U: 100.00 U: 94.35
L: 100.00 L: 88.75 L: 93.39
Predicted PS U: 100.00 U: 92.92
L: 90.85 L: 82.30 L: 86:26
Raw PS U: 96.42 U: 88.47
L: 84.54 N/A L: 80.67
Gold RR U: 100.00 U: 94.34
L: 100.00 L: 83.93 L: 92.45
Predicted RR U: 100.00 U: 92.82
L: 91.69 L: 78.93 L: 85.83
Raw RR U: 96.03 U: 87.96
L: 86.10 N/A L: 79.46
</table>
<tableCaption confidence="0.973724">
Table 1: Phrase-Structure based results for the Berke-
ley Parser trained on bare-bone trees (PS) and relational-
realizational trees (RR). We parse all sentences in the dev
set. RR extra decoration is removed prior to evaluation.
</tableCaption>
<table confidence="0.999061285714286">
SEGEVAL ATTSCORES TEDEVAL
Gold MP 100.00 U: 83.59 U: 91.76
Predicted MP 100.00 U: 82.00 U: 91.20
Raw MP 95.07 N/A U: 87.03
Gold EF 100.00 U: 84.68 U: 92.25
Predicted EF 100.00 U: 83.97 U: 92:02
Raw EF 95.07 N/A U: 87.75
</table>
<tableCaption confidence="0.938778666666667">
Table 2: Dependency parsing results by MaltParser (MP)
and EasyFirst (EF), trained on the treebank converted into
unlabeled dependencies, and parsing the entire dev-set.
</tableCaption>
<bodyText confidence="0.999958730769231">
For constituency-based parsing we use two mod-
els trained by the Berkeley parser (Petrov et al.,
2006) one on phrase-structure (PS) trees and one
on relational-realizational (RR) trees (Tsarfaty and
Sima’an, 2008). In the raw scenario we let a lattice-
based parser choose its own segmentation and tags
(Goldberg, 2011b). For dependency parsing we use
MaltParser (Nivre et al., 2007b) optimized for He-
brew by Ballesteros and Nivre (2012), and the Easy-
First parser of Goldberg and Elhadad (2010) with the
features therein. Since these parsers cannot choose
their own tags, automatically predicted segments
and tags are provided by Adler and Elhadad (2006).
We use the standard split of the Hebrew tree-
bank (Sima’an et al., 2001) and its conversion into
unlabeled dependencies (Goldberg, 2011a). We
use PARSEVAL for evaluating phrase-structure trees,
ATTACHSCORES for evaluating dependency trees,
and TEDEVAL for evaluating all trees in all scenar-
ios. We implement SEGEVAL for evaluating seg-
mentation based on our TEDEVAL implementation,
replacing the tree distance and size with string terms.
Table 1 shows the constituency-based parsing re-
sults for all scenarios. All of our results confirm
that gold information leads to much higher scores.
TEDEVAL allows us to precisely quantify the drop
in accuracy from gold to predicted (as in PARSE-
VAL) and than from predicted to raw on a single
scale. TEDEVAL further allows us to scrutinize the
contribution of different sorts of information. Unla-
beled TEDEVAL shows a greater drop when moving
from predicted to raw than from gold to predicted,
and for labeled TEDEVAL it is the other way round.
This demonstrates the great importance of gold tags
which provide morphologically disambiguated in-
formation for identifying phrase content.
Table 2 shows that dependency parsing results
confirm the same trends, but we see a much smaller
drop when moving from gold to predicted. This is
due to the fact that we train the parsers for predicted
on a treebank containing predicted tags. There is
however a great drop when moving from predicted
to raw, which confirms that evaluation benchmarks
on gold input as in Nivre et al. (2007a) do not pro-
vide a realistic indication of parser performance.
For all tables, TEDEVAL results are on a simi-
lar scale. However, results are not yet comparable
across parsers. RR trees are flatter than bare-bone
PS trees. PS and DEP trees have different label
sets. Cross-framework evaluation may be conducted
by combining this metric with the cross-framework
protocol of Tsarfaty et al. (2012).
</bodyText>
<sectionHeader confidence="0.999449" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999990444444445">
We presented distance-based metrics defined for
trees over lattices and applied them to evaluating
parsers on joint morphological and syntactic dis-
ambiguation. Our contribution is both technical,
providing an evaluation tool that can be straight-
forwardly applied for parsing scenarios involving
trees over lattices,4 and methodological, suggesting
to evaluate parsers in all possible scenarios in order
to get a realistic indication of parser performance.
</bodyText>
<sectionHeader confidence="0.997751" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999912333333333">
We thank Shay Cohen, Yoav Goldberg and Spence
Green for discussion of this challenge. This work
was supported by the Swedish Science Council.
</bodyText>
<footnote confidence="0.986248">
4The tool can be downloaded http://stp.ling.uu.
se/˜tsarfaty/unipar/index.html
</footnote>
<page confidence="0.995982">
9
</page>
<sectionHeader confidence="0.995801" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998655697916667">
Meni Adler and Michael Elhadad. 2006. An unsuper-
vised morpheme-based HMM for Hebrew morpholog-
ical disambiguation. In Proceedings of COLING-ACL.
Miguel Ballesteros and Joakim Nivre. 2012. MaltOpti-
mizer: A system for MaltParser optimization. Istan-
bul.
Roy Bar-haim, Khalil Sima’an, and Yoad Winter. 2008.
Part-of-speech tagging of Modern Hebrew text. Natu-
ral Language Engineering, 14(2):223–251.
Philip Bille. 2005. A survey on tree-edit distance
and related. problems. Theoretical Computer Science,
337:217–239.
Ezra Black, Steven P. Abney, D. Flickenger, Claudia
Gdaniec, Ralph Grishman, P. Harrison, Donald Hin-
dle, Robert Ingria, Frederick Jelinek, Judith L. Kla-
vans, Mark Liberman, Mitchell P. Marcus, Salim
Roukos, Beatrice Santorini, and Tomek Strzalkowski.
1991. A procedure for quantitatively comparing the
syntactic coverage of English grammars. In Proceed-
ings of the DARPA Workshop on Speech and Natural
Language.
Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X
shared task on multilingual dependency parsing. In
Proceedings of CoNLL-X, pages 149–164.
Shay B. Cohen and Noah A. Smith. 2007. Joint morpho-
logical and syntactic disambiguation. In Proceedings
of EMNLP-CoNLL, pages 208–217.
Yoav Goldberg and Michael Elhadad. 2010. Easy-first
dependency parsing of Modern Hebrew. In Proceed-
ings of NAACL/HLT workshop on Statistical Parsing
of Morphologically Rich Languages.
Yoav Goldberg and Reut Tsarfaty. 2008. A single frame-
work for joint morphological segmentation and syn-
tactic parsing. In Proceedings of ACL.
Yoav Goldberg. 2011a. Automatic Syntactic Processing
of Modern Hebrew. Ph.D. thesis, Ben-Gurion Univer-
sity of the Negev.
Yoav Goldberg. 2011b. Joint morphological segmen-
tation and syntactic parsing using a PCFGLA lattice
parser. In Proceedings of ACL.
Spence Green and Christopher D. Manning. 2010. Better
Arabic parsing: Baselines, evaluations, and analysis.
In Proceedings of COLING.
Nizar Habash and Owen Rambow. 2005. Arabic tok-
enization, part-of-speech tagging and morphological
disambiguation in one fell swoop. In Proceedings of
ACL.
Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan McDon-
ald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret.
2007a. The CoNLL 2007 shared task on dependency
parsing. In Proceedings of the CoNLL Shared Task
Session of EMNLP-CoNLL 2007, pages 915–932.
Joakim Nivre, Jens Nilsson, Johan Hall, Atanas Chanev,
G¨ulsen Eryigit, Sandra K¨ubler, Svetoslav Marinov,
and Erwin Marsi. 2007b. MaltParser: A language-
independent system for data-driven dependency pars-
ing. Natural Language Engineering, 13(1):1–41.
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan
Klein. 2006. Learning accurate, compact, and inter-
pretable tree annotation. In Proceedings ofACL.
Brian Roark, Mary Harper, Eugene Charniak, Bon-
nie Dorr C, Mark Johnson D, Jeremy G. Kahn
E, Yang Liu F, Mari Ostendorf E, John Hale
H, Anna Krasnyanskaya I, Matthew Lease D,
Izhak Shafran J, Matthew Snover C, Robin Stewart K,
and Lisa Yung J. 2006. Sparseval: Evaluation metrics
for parsing speech. In Proceesings of LREC.
Danny Shacham and Shuly Wintner. 2007. Morpholog-
ical disambiguation of Hebrew: A case study in clas-
sifier combination. In Proceedings of the 2007 Joint
Conference of EMNLP-CoNLL, pages pages 439–447.
Khalil Sima’an, Alon Itai, Yoad Winter, Alon Altman,
and Noa Nativ. 2001. Building a Tree-Bank for
Modern Hebrew Text. In Traitement Automatique des
Langues.
Reut Tsarfaty and Khalil Sima’an. 2008. Relational-
Realizational parsing. In Proceedings of CoLing.
Reut Tsarfaty, Djame Seddah, Yoav Goldberg, San-
dra Kuebler, Marie Candito, Jennifer Foster, Yan-
nick Versley, Ines Rehbein, and Lamia Tounsi. 2010.
Statistical parsing for morphologically rich language
(SPMRL): What, how and whither. In Proceedings of
the first workshop on Statistical Parsing of Morpho-
logically Rich Languages (SPMRL) at NA-ACL.
Reut Tsarfaty, Joakim Nivre, and Evelina Andersson.
2011. Evaluating dependency parsing: Robust and
heuristics-free cross-framework evaluation. In Pro-
ceedings of EMNLP.
Reut Tsarfaty, Joakim Nivre, and Evelina Andersson.
2012. Cross-framework evaluation for statistical pars-
ing. In Proceedings of EACL.
Reut Tsarfaty. 2006. Integrated morphological and syn-
tactic disambiguation for Modern Hebrew. In Pro-
ceeding of ACL-SRW.
Reut Tsarfaty. 2010. Relational-Realizational Parsing.
Ph.D. thesis, University of Amsterdam.
</reference>
<page confidence="0.997789">
10
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.690618">
<title confidence="0.997926">Joint Evaluation of Morphological Segmentation and Syntactic Parsing</title>
<author confidence="0.749358">Reut Tsarfaty Joakim Nivre Evelina Andersson</author>
<address confidence="0.921875">Box 635, 751 26, Uppsala University, Uppsala, Sweden</address>
<abstract confidence="0.999618333333333">We present novel metrics for parse evaluation in joint segmentation and parsing scenarios where the gold sequence of terminals is not known in advance. The protocol uses distance-based metrics defined for the space of trees over lattices. Our metrics allow us to precisely quantify the performance gap between non-realistic parsing scenarios (assuming gold segmented and tagged input) and realistic ones (not assuming gold segmentation and tags). Our evaluation of segmentation and parsing for Modern Hebrew sheds new light on the performance of the best parsing systems to date in the different scenarios.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Meni Adler</author>
<author>Michael Elhadad</author>
</authors>
<title>An unsupervised morpheme-based HMM for Hebrew morphological disambiguation.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING-ACL.</booktitle>
<contexts>
<context position="6059" citStr="Adler and Elhadad, 2006" startWordPosition="936" endWordPosition="939">in a lattice structure, as illustrated in Figure 2. 1We use the Hebrew transliteration in Sima’an et al. (2001). 2The complete set of analyses for this word is provided in Goldberg and Tsarfaty (2008). Examples for similar phenomena in Arabic may be found in Green and Manning (2010). Figure 2: The morphological segmentation possibilities of BCLM HNEIM. Double-circles are word boundaries. In practice, a statistical component is required to decide on the correct morphological segmentation, that is, to pick out the correct path through the lattice. This may be done based on linear local context (Adler and Elhadad, 2006; Shacham and Wintner, 2007; Bar-haim et al., 2008; Habash and Rambow, 2005), or jointly with parsing (Tsarfaty, 2006; Goldberg and Tsarfaty, 2008; Green and Manning, 2010). Either way, an incorrect morphological segmentation hypothesis introduces errors into the parse hypothesis, ultimately providing a parse tree which spans a different yield than the gold terminals. In such cases, existing evaluation metrics break down. To understand why, consider the trees in Figure 1. Metrics like PARSEVAL (Black et al., 1991) calculate the harmonic means of precision and recall on labeled spans (i, label,</context>
<context position="12954" citStr="Adler and Elhadad (2006)" startWordPosition="2177" endWordPosition="2180">ing we use two models trained by the Berkeley parser (Petrov et al., 2006) one on phrase-structure (PS) trees and one on relational-realizational (RR) trees (Tsarfaty and Sima’an, 2008). In the raw scenario we let a latticebased parser choose its own segmentation and tags (Goldberg, 2011b). For dependency parsing we use MaltParser (Nivre et al., 2007b) optimized for Hebrew by Ballesteros and Nivre (2012), and the EasyFirst parser of Goldberg and Elhadad (2010) with the features therein. Since these parsers cannot choose their own tags, automatically predicted segments and tags are provided by Adler and Elhadad (2006). We use the standard split of the Hebrew treebank (Sima’an et al., 2001) and its conversion into unlabeled dependencies (Goldberg, 2011a). We use PARSEVAL for evaluating phrase-structure trees, ATTACHSCORES for evaluating dependency trees, and TEDEVAL for evaluating all trees in all scenarios. We implement SEGEVAL for evaluating segmentation based on our TEDEVAL implementation, replacing the tree distance and size with string terms. Table 1 shows the constituency-based parsing results for all scenarios. All of our results confirm that gold information leads to much higher scores. TEDEVAL allo</context>
</contexts>
<marker>Adler, Elhadad, 2006</marker>
<rawString>Meni Adler and Michael Elhadad. 2006. An unsupervised morpheme-based HMM for Hebrew morphological disambiguation. In Proceedings of COLING-ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miguel Ballesteros</author>
<author>Joakim Nivre</author>
</authors>
<title>MaltOptimizer: A system for MaltParser optimization.</title>
<date>2012</date>
<location>Istanbul.</location>
<contexts>
<context position="12737" citStr="Ballesteros and Nivre (2012)" startWordPosition="2143" endWordPosition="2146">w EF 95.07 N/A U: 87.75 Table 2: Dependency parsing results by MaltParser (MP) and EasyFirst (EF), trained on the treebank converted into unlabeled dependencies, and parsing the entire dev-set. For constituency-based parsing we use two models trained by the Berkeley parser (Petrov et al., 2006) one on phrase-structure (PS) trees and one on relational-realizational (RR) trees (Tsarfaty and Sima’an, 2008). In the raw scenario we let a latticebased parser choose its own segmentation and tags (Goldberg, 2011b). For dependency parsing we use MaltParser (Nivre et al., 2007b) optimized for Hebrew by Ballesteros and Nivre (2012), and the EasyFirst parser of Goldberg and Elhadad (2010) with the features therein. Since these parsers cannot choose their own tags, automatically predicted segments and tags are provided by Adler and Elhadad (2006). We use the standard split of the Hebrew treebank (Sima’an et al., 2001) and its conversion into unlabeled dependencies (Goldberg, 2011a). We use PARSEVAL for evaluating phrase-structure trees, ATTACHSCORES for evaluating dependency trees, and TEDEVAL for evaluating all trees in all scenarios. We implement SEGEVAL for evaluating segmentation based on our TEDEVAL implementation, r</context>
</contexts>
<marker>Ballesteros, Nivre, 2012</marker>
<rawString>Miguel Ballesteros and Joakim Nivre. 2012. MaltOptimizer: A system for MaltParser optimization. Istanbul.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roy Bar-haim</author>
<author>Khalil Sima’an</author>
<author>Yoad Winter</author>
</authors>
<title>Part-of-speech tagging of Modern Hebrew text.</title>
<date>2008</date>
<journal>Natural Language Engineering,</journal>
<volume>14</volume>
<issue>2</issue>
<marker>Bar-haim, Sima’an, Winter, 2008</marker>
<rawString>Roy Bar-haim, Khalil Sima’an, and Yoad Winter. 2008. Part-of-speech tagging of Modern Hebrew text. Natural Language Engineering, 14(2):223–251.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Bille</author>
</authors>
<title>A survey on tree-edit distance and related. problems.</title>
<date>2005</date>
<journal>Theoretical Computer Science,</journal>
<pages>337--217</pages>
<contexts>
<context position="10131" citStr="Bille, 2005" startWordPosition="1683" endWordPosition="1684">ice L. The operations in A are properly constrained by the lattice, that is, we can only add and delete lexemes that belong to LEX, and we can only add and delete them where they can occur in the lattice. We assume a function C(a) = 1 assigning a unit cost to every operation a ∈ A, and define the cost of a sequence ha1, ... , ami as the sum of the costs of all operations in the sequence C(ha1, ..., ami) = Emi=1 C(ai). An edit script ES(y1, y2) = ha1, ... , ami is a sequence of operations that turns y1 into y2. The treeedit distance is the minimum cost of any edit script that turns y1 into y2 (Bille, 2005). TED(y1, y2) = min ES(y1,y2) Distance-Based Metrics The error of a predicted structure p with respect to a gold structure g is now taken to be the TED cost, and we can turn it into a score by normalizing it and subtracting from a unity: TEDEVAL(p, g) = 1 |p |+ |g |− 2 The term |p |+ |g |− 2 is a normalization factor defined in terms of the worst-case scenario, in which the parser has only made incorrect decisions. We would need to delete all lexemes and nodes in p and add all the lexemes and nodes of g, except for roots. An Example Both trees in Figure 1 are contained in YL for the lattice L </context>
</contexts>
<marker>Bille, 2005</marker>
<rawString>Philip Bille. 2005. A survey on tree-edit distance and related. problems. Theoretical Computer Science, 337:217–239.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Ezra Black</author>
<author>Steven P Abney</author>
<author>D Flickenger</author>
<author>Claudia Gdaniec</author>
<author>Ralph Grishman</author>
<author>P Harrison</author>
<author>Donald Hindle</author>
<author>Robert Ingria</author>
<author>Frederick Jelinek</author>
<author>Judith L Klavans</author>
<author>Mark Liberman</author>
<author>Mitchell P Marcus</author>
<author>Salim Roukos</author>
<author>Beatrice Santorini</author>
<author>Tomek Strzalkowski</author>
</authors>
<title>A procedure for quantitatively comparing the syntactic coverage of English grammars.</title>
<date>1991</date>
<booktitle>In Proceedings of the DARPA Workshop on Speech and Natural Language.</booktitle>
<contexts>
<context position="1211" citStr="Black et al., 1991" startWordPosition="172" endWordPosition="175">(assuming gold segmented and tagged input) and realistic ones (not assuming gold segmentation and tags). Our evaluation of segmentation and parsing for Modern Hebrew sheds new light on the performance of the best parsing systems to date in the different scenarios. 1 Introduction A parser takes a sentence in natural language as input and returns a syntactic parse tree representing the sentence’s human-perceived interpretation. Current state-of-the-art parsers assume that the spacedelimited words in the input are the basic units of syntactic analysis. Standard evaluation procedures and metrics (Black et al., 1991; Buchholz and Marsi, 2006) accordingly assume that the yield of the parse tree is known in advance. This assumption breaks down when parsing morphologically rich languages (Tsarfaty et al., 2010), where every space-delimited word may be effectively composed of multiple morphemes, each of which having a distinct role in the syntactic parse tree. In order to parse such input the text needs to undergo morphological segmentation, that is, identifying the morphological segments of each word and assigning the corresponding part-ofspeech (PoS) tags to them. Morphologically complex words may be highl</context>
<context position="6578" citStr="Black et al., 1991" startWordPosition="1016" endWordPosition="1019">ct path through the lattice. This may be done based on linear local context (Adler and Elhadad, 2006; Shacham and Wintner, 2007; Bar-haim et al., 2008; Habash and Rambow, 2005), or jointly with parsing (Tsarfaty, 2006; Goldberg and Tsarfaty, 2008; Green and Manning, 2010). Either way, an incorrect morphological segmentation hypothesis introduces errors into the parse hypothesis, ultimately providing a parse tree which spans a different yield than the gold terminals. In such cases, existing evaluation metrics break down. To understand why, consider the trees in Figure 1. Metrics like PARSEVAL (Black et al., 1991) calculate the harmonic means of precision and recall on labeled spans (i, label, j) where i, j are terminal boundaries. Now, the NP dominating “shadow of them” has been identified and labeled correctly in tree2, but in tree1 it spans (2, NP, 5) and in tree2 it spans (1, NP, 4). This node will then be counted as an error for tree2, along with its dominated and dominating structure, and PARSEVAL will score 0. 7 A generalized version of PARSEVAL which considers i, j character-based indices instead of terminal boundaries (Tsarfaty, 2006) will fail here too, since the missing overt definite articl</context>
</contexts>
<marker>Black, Abney, Flickenger, Gdaniec, Grishman, Harrison, Hindle, Ingria, Jelinek, Klavans, Liberman, Marcus, Roukos, Santorini, Strzalkowski, 1991</marker>
<rawString>Ezra Black, Steven P. Abney, D. Flickenger, Claudia Gdaniec, Ralph Grishman, P. Harrison, Donald Hindle, Robert Ingria, Frederick Jelinek, Judith L. Klavans, Mark Liberman, Mitchell P. Marcus, Salim Roukos, Beatrice Santorini, and Tomek Strzalkowski. 1991. A procedure for quantitatively comparing the syntactic coverage of English grammars. In Proceedings of the DARPA Workshop on Speech and Natural Language.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>CoNLL-X shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of CoNLL-X,</booktitle>
<pages>149--164</pages>
<contexts>
<context position="1238" citStr="Buchholz and Marsi, 2006" startWordPosition="176" endWordPosition="179">nted and tagged input) and realistic ones (not assuming gold segmentation and tags). Our evaluation of segmentation and parsing for Modern Hebrew sheds new light on the performance of the best parsing systems to date in the different scenarios. 1 Introduction A parser takes a sentence in natural language as input and returns a syntactic parse tree representing the sentence’s human-perceived interpretation. Current state-of-the-art parsers assume that the spacedelimited words in the input are the basic units of syntactic analysis. Standard evaluation procedures and metrics (Black et al., 1991; Buchholz and Marsi, 2006) accordingly assume that the yield of the parse tree is known in advance. This assumption breaks down when parsing morphologically rich languages (Tsarfaty et al., 2010), where every space-delimited word may be effectively composed of multiple morphemes, each of which having a distinct role in the syntactic parse tree. In order to parse such input the text needs to undergo morphological segmentation, that is, identifying the morphological segments of each word and assigning the corresponding part-ofspeech (PoS) tags to them. Morphologically complex words may be highly ambiguous and in order to</context>
<context position="7307" citStr="Buchholz and Marsi, 2006" startWordPosition="1140" endWordPosition="1143">inal boundaries. Now, the NP dominating “shadow of them” has been identified and labeled correctly in tree2, but in tree1 it spans (2, NP, 5) and in tree2 it spans (1, NP, 4). This node will then be counted as an error for tree2, along with its dominated and dominating structure, and PARSEVAL will score 0. 7 A generalized version of PARSEVAL which considers i, j character-based indices instead of terminal boundaries (Tsarfaty, 2006) will fail here too, since the missing overt definite article H will cause similar misalignments. Metrics for dependencybased evaluation such as ATTACHMENT SCORES (Buchholz and Marsi, 2006) suffer from similar problems, since they assume that both trees have the same nodes — an assumption that breaks down in the case of incorrect morphological segmentation. Although great advances have been made in parsing MRLs in recent years, this evaluation challenge remained unsolved.3 In this paper we present a solution to this challenge by extending TEDEVAL (Tsarfaty et al., 2011) for handling trees over lattices. 3 The Proposal: Distance-Based Metrics Input and Output Spaces We view the joint task as a structured prediction function h : X → Y from input space X onto output space Y. Each e</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X shared task on multilingual dependency parsing. In Proceedings of CoNLL-X, pages 149–164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shay B Cohen</author>
<author>Noah A Smith</author>
</authors>
<title>Joint morphological and syntactic disambiguation.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP-CoNLL,</booktitle>
<pages>208--217</pages>
<contexts>
<context position="2265" citStr="Cohen and Smith, 2007" startWordPosition="337" endWordPosition="340">at is, identifying the morphological segments of each word and assigning the corresponding part-ofspeech (PoS) tags to them. Morphologically complex words may be highly ambiguous and in order to segment them correctly their analysis has to be disambiguated. The multiple morphological analyses of input words may be represented via a lattice that encodes the different segmentation possibilities of the entire word sequence. One can either select a segmentation path prior to parsing, or, as has been recently argued, one can let the parser pick a segmentation jointly with decoding (Tsarfaty, 2006; Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008; Green and Manning, 2010). If the selected segmentation is different from the gold segmentation, the gold and parse trees are rendered incomparable and standard evaluation metrics break down. Evaluation scenarios restricted to gold input are often used to bypass this problem, but, as shall be seen shortly, they present an overly optimistic upperbound on parser performance. This paper presents a full treatment of evaluation in different parsing scenarios, using distance-based measures defined for trees over a shared common denominator defined in terms of a lattice </context>
<context position="9159" citStr="Cohen and Smith (2007)" startWordPosition="1483" endWordPosition="1486">the concatenation of the lattices L1, ... , Ln where MA(w1) = L1, ... , MA(wn) = Ln. Now, let x = w1, ... , wn be a sentence with a morphological analysis lattice MA(x) = L. We define the output space YMA(x)=L for h (abbreviated YL), as the set of linearly-ordered labeled trees such that the yield of LEX entries hs1, p1i,...,hsk,pki in each tree (where si ∈ T and pi ∈ N, and possibly k =6 n) corresponds to a path through the lattice L. 3A tool that could potentially apply here is SParseval (Roark et al., 2006). But since it does not respect word-boundaries, it fails to apply to such lattices. Cohen and Smith (2007) aimed to fix this, but in their implementation syntactic nodes internal to word boundaries may be lost without scoring. Edit Scripts and Edit Costs We assume a set A={ADD(c, i, j),DEL(c, i, j),ADD(hs, pi, i, j), DEL(hs, pi, i, j)} of edit operations which can add or delete a labeled node c ∈ N or an entry hs, pi ∈ LEX which spans the states i, j in the lattice L. The operations in A are properly constrained by the lattice, that is, we can only add and delete lexemes that belong to LEX, and we can only add and delete them where they can occur in the lattice. We assume a function C(a) = 1 assig</context>
</contexts>
<marker>Cohen, Smith, 2007</marker>
<rawString>Shay B. Cohen and Noah A. Smith. 2007. Joint morphological and syntactic disambiguation. In Proceedings of EMNLP-CoNLL, pages 208–217.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Goldberg</author>
<author>Michael Elhadad</author>
</authors>
<title>Easy-first dependency parsing of Modern Hebrew.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL/HLT workshop on Statistical Parsing of Morphologically Rich Languages.</booktitle>
<contexts>
<context position="12794" citStr="Goldberg and Elhadad (2010)" startWordPosition="2153" endWordPosition="2156">s by MaltParser (MP) and EasyFirst (EF), trained on the treebank converted into unlabeled dependencies, and parsing the entire dev-set. For constituency-based parsing we use two models trained by the Berkeley parser (Petrov et al., 2006) one on phrase-structure (PS) trees and one on relational-realizational (RR) trees (Tsarfaty and Sima’an, 2008). In the raw scenario we let a latticebased parser choose its own segmentation and tags (Goldberg, 2011b). For dependency parsing we use MaltParser (Nivre et al., 2007b) optimized for Hebrew by Ballesteros and Nivre (2012), and the EasyFirst parser of Goldberg and Elhadad (2010) with the features therein. Since these parsers cannot choose their own tags, automatically predicted segments and tags are provided by Adler and Elhadad (2006). We use the standard split of the Hebrew treebank (Sima’an et al., 2001) and its conversion into unlabeled dependencies (Goldberg, 2011a). We use PARSEVAL for evaluating phrase-structure trees, ATTACHSCORES for evaluating dependency trees, and TEDEVAL for evaluating all trees in all scenarios. We implement SEGEVAL for evaluating segmentation based on our TEDEVAL implementation, replacing the tree distance and size with string terms. Ta</context>
</contexts>
<marker>Goldberg, Elhadad, 2010</marker>
<rawString>Yoav Goldberg and Michael Elhadad. 2010. Easy-first dependency parsing of Modern Hebrew. In Proceedings of NAACL/HLT workshop on Statistical Parsing of Morphologically Rich Languages.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Goldberg</author>
<author>Reut Tsarfaty</author>
</authors>
<title>A single framework for joint morphological segmentation and syntactic parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="2294" citStr="Goldberg and Tsarfaty, 2008" startWordPosition="341" endWordPosition="344">morphological segments of each word and assigning the corresponding part-ofspeech (PoS) tags to them. Morphologically complex words may be highly ambiguous and in order to segment them correctly their analysis has to be disambiguated. The multiple morphological analyses of input words may be represented via a lattice that encodes the different segmentation possibilities of the entire word sequence. One can either select a segmentation path prior to parsing, or, as has been recently argued, one can let the parser pick a segmentation jointly with decoding (Tsarfaty, 2006; Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008; Green and Manning, 2010). If the selected segmentation is different from the gold segmentation, the gold and parse trees are rendered incomparable and standard evaluation metrics break down. Evaluation scenarios restricted to gold input are often used to bypass this problem, but, as shall be seen shortly, they present an overly optimistic upperbound on parser performance. This paper presents a full treatment of evaluation in different parsing scenarios, using distance-based measures defined for trees over a shared common denominator defined in terms of a lattice structure. We demonstrate the</context>
<context position="5636" citStr="Goldberg and Tsarfaty (2008)" startWordPosition="869" endWordPosition="872">igure 1 (tree1), and it presupposes that these segments can be identified and assigned the correct PoS tags. However, morphological segmentation is non-trivial due to massive wordlevel ambiguity. The word BCLM, for instance, can be segmented into the noun BCL (“onion”) and M (a genitive suffix, “of them”), or into the prefix B (“in”) followed by the noun CLM (“image”).2 The multitude of morphological analyses may be encoded in a lattice structure, as illustrated in Figure 2. 1We use the Hebrew transliteration in Sima’an et al. (2001). 2The complete set of analyses for this word is provided in Goldberg and Tsarfaty (2008). Examples for similar phenomena in Arabic may be found in Green and Manning (2010). Figure 2: The morphological segmentation possibilities of BCLM HNEIM. Double-circles are word boundaries. In practice, a statistical component is required to decide on the correct morphological segmentation, that is, to pick out the correct path through the lattice. This may be done based on linear local context (Adler and Elhadad, 2006; Shacham and Wintner, 2007; Bar-haim et al., 2008; Habash and Rambow, 2005), or jointly with parsing (Tsarfaty, 2006; Goldberg and Tsarfaty, 2008; Green and Manning, 2010). Eit</context>
</contexts>
<marker>Goldberg, Tsarfaty, 2008</marker>
<rawString>Yoav Goldberg and Reut Tsarfaty. 2008. A single framework for joint morphological segmentation and syntactic parsing. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Goldberg</author>
</authors>
<title>Automatic Syntactic Processing of Modern Hebrew.</title>
<date>2011</date>
<tech>Ph.D. thesis,</tech>
<institution>Ben-Gurion University of the Negev.</institution>
<contexts>
<context position="3133" citStr="Goldberg, 2011" startWordPosition="466" endWordPosition="468">to gold input are often used to bypass this problem, but, as shall be seen shortly, they present an overly optimistic upperbound on parser performance. This paper presents a full treatment of evaluation in different parsing scenarios, using distance-based measures defined for trees over a shared common denominator defined in terms of a lattice structure. We demonstrate the informativeness of our metrics by evaluating joint segmentation and parsing performance for the Semitic language Modern Hebrew, using the best performing systems, both constituencybased and dependency-based (Tsarfaty, 2010; Goldberg, 2011a). Our experiments demonstrate that, for all parsers, significant performance gaps between realistic and non-realistic scenarios crucially depend on the kind of information initially provided to the parser. The tool and metrics that we provide are completely general and can straightforwardly apply to other languages, treebanks and different tasks. 6 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 6–10, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics (tree1) TOP (tree2) TOP PP PP NP IN 0B1 “in” NP IN 0B1 “</context>
<context position="12618" citStr="Goldberg, 2011" startWordPosition="2126" endWordPosition="2127">91.20 Raw MP 95.07 N/A U: 87.03 Gold EF 100.00 U: 84.68 U: 92.25 Predicted EF 100.00 U: 83.97 U: 92:02 Raw EF 95.07 N/A U: 87.75 Table 2: Dependency parsing results by MaltParser (MP) and EasyFirst (EF), trained on the treebank converted into unlabeled dependencies, and parsing the entire dev-set. For constituency-based parsing we use two models trained by the Berkeley parser (Petrov et al., 2006) one on phrase-structure (PS) trees and one on relational-realizational (RR) trees (Tsarfaty and Sima’an, 2008). In the raw scenario we let a latticebased parser choose its own segmentation and tags (Goldberg, 2011b). For dependency parsing we use MaltParser (Nivre et al., 2007b) optimized for Hebrew by Ballesteros and Nivre (2012), and the EasyFirst parser of Goldberg and Elhadad (2010) with the features therein. Since these parsers cannot choose their own tags, automatically predicted segments and tags are provided by Adler and Elhadad (2006). We use the standard split of the Hebrew treebank (Sima’an et al., 2001) and its conversion into unlabeled dependencies (Goldberg, 2011a). We use PARSEVAL for evaluating phrase-structure trees, ATTACHSCORES for evaluating dependency trees, and TEDEVAL for evaluat</context>
</contexts>
<marker>Goldberg, 2011</marker>
<rawString>Yoav Goldberg. 2011a. Automatic Syntactic Processing of Modern Hebrew. Ph.D. thesis, Ben-Gurion University of the Negev.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Goldberg</author>
</authors>
<title>Joint morphological segmentation and syntactic parsing using a PCFGLA lattice parser.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="3133" citStr="Goldberg, 2011" startWordPosition="466" endWordPosition="468">to gold input are often used to bypass this problem, but, as shall be seen shortly, they present an overly optimistic upperbound on parser performance. This paper presents a full treatment of evaluation in different parsing scenarios, using distance-based measures defined for trees over a shared common denominator defined in terms of a lattice structure. We demonstrate the informativeness of our metrics by evaluating joint segmentation and parsing performance for the Semitic language Modern Hebrew, using the best performing systems, both constituencybased and dependency-based (Tsarfaty, 2010; Goldberg, 2011a). Our experiments demonstrate that, for all parsers, significant performance gaps between realistic and non-realistic scenarios crucially depend on the kind of information initially provided to the parser. The tool and metrics that we provide are completely general and can straightforwardly apply to other languages, treebanks and different tasks. 6 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 6–10, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics (tree1) TOP (tree2) TOP PP PP NP IN 0B1 “in” NP IN 0B1 “</context>
<context position="12618" citStr="Goldberg, 2011" startWordPosition="2126" endWordPosition="2127">91.20 Raw MP 95.07 N/A U: 87.03 Gold EF 100.00 U: 84.68 U: 92.25 Predicted EF 100.00 U: 83.97 U: 92:02 Raw EF 95.07 N/A U: 87.75 Table 2: Dependency parsing results by MaltParser (MP) and EasyFirst (EF), trained on the treebank converted into unlabeled dependencies, and parsing the entire dev-set. For constituency-based parsing we use two models trained by the Berkeley parser (Petrov et al., 2006) one on phrase-structure (PS) trees and one on relational-realizational (RR) trees (Tsarfaty and Sima’an, 2008). In the raw scenario we let a latticebased parser choose its own segmentation and tags (Goldberg, 2011b). For dependency parsing we use MaltParser (Nivre et al., 2007b) optimized for Hebrew by Ballesteros and Nivre (2012), and the EasyFirst parser of Goldberg and Elhadad (2010) with the features therein. Since these parsers cannot choose their own tags, automatically predicted segments and tags are provided by Adler and Elhadad (2006). We use the standard split of the Hebrew treebank (Sima’an et al., 2001) and its conversion into unlabeled dependencies (Goldberg, 2011a). We use PARSEVAL for evaluating phrase-structure trees, ATTACHSCORES for evaluating dependency trees, and TEDEVAL for evaluat</context>
</contexts>
<marker>Goldberg, 2011</marker>
<rawString>Yoav Goldberg. 2011b. Joint morphological segmentation and syntactic parsing using a PCFGLA lattice parser. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Spence Green</author>
<author>Christopher D Manning</author>
</authors>
<title>Better Arabic parsing: Baselines, evaluations, and analysis.</title>
<date>2010</date>
<booktitle>In Proceedings of COLING.</booktitle>
<contexts>
<context position="2320" citStr="Green and Manning, 2010" startWordPosition="345" endWordPosition="348">h word and assigning the corresponding part-ofspeech (PoS) tags to them. Morphologically complex words may be highly ambiguous and in order to segment them correctly their analysis has to be disambiguated. The multiple morphological analyses of input words may be represented via a lattice that encodes the different segmentation possibilities of the entire word sequence. One can either select a segmentation path prior to parsing, or, as has been recently argued, one can let the parser pick a segmentation jointly with decoding (Tsarfaty, 2006; Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008; Green and Manning, 2010). If the selected segmentation is different from the gold segmentation, the gold and parse trees are rendered incomparable and standard evaluation metrics break down. Evaluation scenarios restricted to gold input are often used to bypass this problem, but, as shall be seen shortly, they present an overly optimistic upperbound on parser performance. This paper presents a full treatment of evaluation in different parsing scenarios, using distance-based measures defined for trees over a shared common denominator defined in terms of a lattice structure. We demonstrate the informativeness of our me</context>
<context position="5719" citStr="Green and Manning (2010)" startWordPosition="884" endWordPosition="887">the correct PoS tags. However, morphological segmentation is non-trivial due to massive wordlevel ambiguity. The word BCLM, for instance, can be segmented into the noun BCL (“onion”) and M (a genitive suffix, “of them”), or into the prefix B (“in”) followed by the noun CLM (“image”).2 The multitude of morphological analyses may be encoded in a lattice structure, as illustrated in Figure 2. 1We use the Hebrew transliteration in Sima’an et al. (2001). 2The complete set of analyses for this word is provided in Goldberg and Tsarfaty (2008). Examples for similar phenomena in Arabic may be found in Green and Manning (2010). Figure 2: The morphological segmentation possibilities of BCLM HNEIM. Double-circles are word boundaries. In practice, a statistical component is required to decide on the correct morphological segmentation, that is, to pick out the correct path through the lattice. This may be done based on linear local context (Adler and Elhadad, 2006; Shacham and Wintner, 2007; Bar-haim et al., 2008; Habash and Rambow, 2005), or jointly with parsing (Tsarfaty, 2006; Goldberg and Tsarfaty, 2008; Green and Manning, 2010). Either way, an incorrect morphological segmentation hypothesis introduces errors into </context>
</contexts>
<marker>Green, Manning, 2010</marker>
<rawString>Spence Green and Christopher D. Manning. 2010. Better Arabic parsing: Baselines, evaluations, and analysis. In Proceedings of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
</authors>
<title>Arabic tokenization, part-of-speech tagging and morphological disambiguation in one fell swoop.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="6135" citStr="Habash and Rambow, 2005" startWordPosition="948" endWordPosition="951">sliteration in Sima’an et al. (2001). 2The complete set of analyses for this word is provided in Goldberg and Tsarfaty (2008). Examples for similar phenomena in Arabic may be found in Green and Manning (2010). Figure 2: The morphological segmentation possibilities of BCLM HNEIM. Double-circles are word boundaries. In practice, a statistical component is required to decide on the correct morphological segmentation, that is, to pick out the correct path through the lattice. This may be done based on linear local context (Adler and Elhadad, 2006; Shacham and Wintner, 2007; Bar-haim et al., 2008; Habash and Rambow, 2005), or jointly with parsing (Tsarfaty, 2006; Goldberg and Tsarfaty, 2008; Green and Manning, 2010). Either way, an incorrect morphological segmentation hypothesis introduces errors into the parse hypothesis, ultimately providing a parse tree which spans a different yield than the gold terminals. In such cases, existing evaluation metrics break down. To understand why, consider the trees in Figure 1. Metrics like PARSEVAL (Black et al., 1991) calculate the harmonic means of precision and recall on labeled spans (i, label, j) where i, j are terminal boundaries. Now, the NP dominating “shadow of th</context>
</contexts>
<marker>Habash, Rambow, 2005</marker>
<rawString>Nizar Habash and Owen Rambow. 2005. Arabic tokenization, part-of-speech tagging and morphological disambiguation in one fell swoop. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Sandra K¨ubler</author>
<author>Ryan McDonald</author>
<author>Jens Nilsson</author>
<author>Sebastian Riedel</author>
<author>Deniz Yuret</author>
</authors>
<title>The CoNLL</title>
<date>2007</date>
<booktitle>In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL</booktitle>
<pages>915--932</pages>
<marker>Nivre, Hall, K¨ubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan McDonald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret. 2007a. The CoNLL 2007 shared task on dependency parsing. In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pages 915–932.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Jens Nilsson</author>
<author>Johan Hall</author>
</authors>
<title>Atanas Chanev, G¨ulsen Eryigit, Sandra K¨ubler, Svetoslav Marinov, and Erwin Marsi.</title>
<date>2007</date>
<journal>Natural Language Engineering,</journal>
<volume>13</volume>
<issue>1</issue>
<contexts>
<context position="12682" citStr="Nivre et al., 2007" startWordPosition="2134" endWordPosition="2137">2.25 Predicted EF 100.00 U: 83.97 U: 92:02 Raw EF 95.07 N/A U: 87.75 Table 2: Dependency parsing results by MaltParser (MP) and EasyFirst (EF), trained on the treebank converted into unlabeled dependencies, and parsing the entire dev-set. For constituency-based parsing we use two models trained by the Berkeley parser (Petrov et al., 2006) one on phrase-structure (PS) trees and one on relational-realizational (RR) trees (Tsarfaty and Sima’an, 2008). In the raw scenario we let a latticebased parser choose its own segmentation and tags (Goldberg, 2011b). For dependency parsing we use MaltParser (Nivre et al., 2007b) optimized for Hebrew by Ballesteros and Nivre (2012), and the EasyFirst parser of Goldberg and Elhadad (2010) with the features therein. Since these parsers cannot choose their own tags, automatically predicted segments and tags are provided by Adler and Elhadad (2006). We use the standard split of the Hebrew treebank (Sima’an et al., 2001) and its conversion into unlabeled dependencies (Goldberg, 2011a). We use PARSEVAL for evaluating phrase-structure trees, ATTACHSCORES for evaluating dependency trees, and TEDEVAL for evaluating all trees in all scenarios. We implement SEGEVAL for evaluat</context>
<context position="14466" citStr="Nivre et al. (2007" startWordPosition="2422" endWordPosition="2425">ed to raw than from gold to predicted, and for labeled TEDEVAL it is the other way round. This demonstrates the great importance of gold tags which provide morphologically disambiguated information for identifying phrase content. Table 2 shows that dependency parsing results confirm the same trends, but we see a much smaller drop when moving from gold to predicted. This is due to the fact that we train the parsers for predicted on a treebank containing predicted tags. There is however a great drop when moving from predicted to raw, which confirms that evaluation benchmarks on gold input as in Nivre et al. (2007a) do not provide a realistic indication of parser performance. For all tables, TEDEVAL results are on a similar scale. However, results are not yet comparable across parsers. RR trees are flatter than bare-bone PS trees. PS and DEP trees have different label sets. Cross-framework evaluation may be conducted by combining this metric with the cross-framework protocol of Tsarfaty et al. (2012). 5 Conclusion We presented distance-based metrics defined for trees over lattices and applied them to evaluating parsers on joint morphological and syntactic disambiguation. Our contribution is both techni</context>
</contexts>
<marker>Nivre, Nilsson, Hall, 2007</marker>
<rawString>Joakim Nivre, Jens Nilsson, Johan Hall, Atanas Chanev, G¨ulsen Eryigit, Sandra K¨ubler, Svetoslav Marinov, and Erwin Marsi. 2007b. MaltParser: A languageindependent system for data-driven dependency parsing. Natural Language Engineering, 13(1):1–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Leon Barrett</author>
<author>Romain Thibaux</author>
<author>Dan Klein</author>
</authors>
<title>Learning accurate, compact, and interpretable tree annotation.</title>
<date>2006</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="12404" citStr="Petrov et al., 2006" startWordPosition="2091" endWordPosition="2094">d relationalrealizational trees (RR). We parse all sentences in the dev set. RR extra decoration is removed prior to evaluation. SEGEVAL ATTSCORES TEDEVAL Gold MP 100.00 U: 83.59 U: 91.76 Predicted MP 100.00 U: 82.00 U: 91.20 Raw MP 95.07 N/A U: 87.03 Gold EF 100.00 U: 84.68 U: 92.25 Predicted EF 100.00 U: 83.97 U: 92:02 Raw EF 95.07 N/A U: 87.75 Table 2: Dependency parsing results by MaltParser (MP) and EasyFirst (EF), trained on the treebank converted into unlabeled dependencies, and parsing the entire dev-set. For constituency-based parsing we use two models trained by the Berkeley parser (Petrov et al., 2006) one on phrase-structure (PS) trees and one on relational-realizational (RR) trees (Tsarfaty and Sima’an, 2008). In the raw scenario we let a latticebased parser choose its own segmentation and tags (Goldberg, 2011b). For dependency parsing we use MaltParser (Nivre et al., 2007b) optimized for Hebrew by Ballesteros and Nivre (2012), and the EasyFirst parser of Goldberg and Elhadad (2010) with the features therein. Since these parsers cannot choose their own tags, automatically predicted segments and tags are provided by Adler and Elhadad (2006). We use the standard split of the Hebrew treebank</context>
</contexts>
<marker>Petrov, Barrett, Thibaux, Klein, 2006</marker>
<rawString>Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. 2006. Learning accurate, compact, and interpretable tree annotation. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Roark</author>
<author>Mary Harper</author>
<author>Eugene Charniak</author>
<author>Bonnie Dorr C</author>
<author>Mark Johnson D</author>
<author>Jeremy G Kahn E</author>
<author>Yang Liu F</author>
<author>Mari Ostendorf E</author>
<author>John Hale H</author>
<author>Anna Krasnyanskaya I</author>
<author>Matthew Lease D</author>
<author>Izhak Shafran J</author>
<author>Matthew Snover C</author>
<author>Robin Stewart K</author>
<author>Lisa Yung J</author>
</authors>
<title>Sparseval: Evaluation metrics for parsing speech.</title>
<date>2006</date>
<booktitle>In Proceesings of LREC.</booktitle>
<contexts>
<context position="9052" citStr="Roark et al., 2006" startWordPosition="1465" endWordPosition="1468">on entry hs, pi. The morphological analysis of an input sentence x is then a lattice L obtained through the concatenation of the lattices L1, ... , Ln where MA(w1) = L1, ... , MA(wn) = Ln. Now, let x = w1, ... , wn be a sentence with a morphological analysis lattice MA(x) = L. We define the output space YMA(x)=L for h (abbreviated YL), as the set of linearly-ordered labeled trees such that the yield of LEX entries hs1, p1i,...,hsk,pki in each tree (where si ∈ T and pi ∈ N, and possibly k =6 n) corresponds to a path through the lattice L. 3A tool that could potentially apply here is SParseval (Roark et al., 2006). But since it does not respect word-boundaries, it fails to apply to such lattices. Cohen and Smith (2007) aimed to fix this, but in their implementation syntactic nodes internal to word boundaries may be lost without scoring. Edit Scripts and Edit Costs We assume a set A={ADD(c, i, j),DEL(c, i, j),ADD(hs, pi, i, j), DEL(hs, pi, i, j)} of edit operations which can add or delete a labeled node c ∈ N or an entry hs, pi ∈ LEX which spans the states i, j in the lattice L. The operations in A are properly constrained by the lattice, that is, we can only add and delete lexemes that belong to LEX, a</context>
</contexts>
<marker>Roark, Harper, Charniak, C, D, E, F, E, H, I, D, J, C, K, J, 2006</marker>
<rawString>Brian Roark, Mary Harper, Eugene Charniak, Bonnie Dorr C, Mark Johnson D, Jeremy G. Kahn E, Yang Liu F, Mari Ostendorf E, John Hale H, Anna Krasnyanskaya I, Matthew Lease D, Izhak Shafran J, Matthew Snover C, Robin Stewart K, and Lisa Yung J. 2006. Sparseval: Evaluation metrics for parsing speech. In Proceesings of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danny Shacham</author>
<author>Shuly Wintner</author>
</authors>
<title>Morphological disambiguation of Hebrew: A case study in classifier combination.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference of EMNLP-CoNLL,</booktitle>
<pages>439--447</pages>
<contexts>
<context position="6086" citStr="Shacham and Wintner, 2007" startWordPosition="940" endWordPosition="943">s illustrated in Figure 2. 1We use the Hebrew transliteration in Sima’an et al. (2001). 2The complete set of analyses for this word is provided in Goldberg and Tsarfaty (2008). Examples for similar phenomena in Arabic may be found in Green and Manning (2010). Figure 2: The morphological segmentation possibilities of BCLM HNEIM. Double-circles are word boundaries. In practice, a statistical component is required to decide on the correct morphological segmentation, that is, to pick out the correct path through the lattice. This may be done based on linear local context (Adler and Elhadad, 2006; Shacham and Wintner, 2007; Bar-haim et al., 2008; Habash and Rambow, 2005), or jointly with parsing (Tsarfaty, 2006; Goldberg and Tsarfaty, 2008; Green and Manning, 2010). Either way, an incorrect morphological segmentation hypothesis introduces errors into the parse hypothesis, ultimately providing a parse tree which spans a different yield than the gold terminals. In such cases, existing evaluation metrics break down. To understand why, consider the trees in Figure 1. Metrics like PARSEVAL (Black et al., 1991) calculate the harmonic means of precision and recall on labeled spans (i, label, j) where i, j are terminal</context>
</contexts>
<marker>Shacham, Wintner, 2007</marker>
<rawString>Danny Shacham and Shuly Wintner. 2007. Morphological disambiguation of Hebrew: A case study in classifier combination. In Proceedings of the 2007 Joint Conference of EMNLP-CoNLL, pages pages 439–447.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Khalil Sima’an</author>
<author>Alon Itai</author>
<author>Yoad Winter</author>
<author>Alon Altman</author>
<author>Noa Nativ</author>
</authors>
<title>Building a Tree-Bank for Modern Hebrew Text. In Traitement Automatique des Langues.</title>
<date>2001</date>
<marker>Sima’an, Itai, Winter, Altman, Nativ, 2001</marker>
<rawString>Khalil Sima’an, Alon Itai, Yoad Winter, Alon Altman, and Noa Nativ. 2001. Building a Tree-Bank for Modern Hebrew Text. In Traitement Automatique des Langues.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reut Tsarfaty</author>
<author>Khalil Sima’an</author>
</authors>
<title>RelationalRealizational parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of CoLing.</booktitle>
<marker>Tsarfaty, Sima’an, 2008</marker>
<rawString>Reut Tsarfaty and Khalil Sima’an. 2008. RelationalRealizational parsing. In Proceedings of CoLing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reut Tsarfaty</author>
<author>Djame Seddah</author>
<author>Yoav Goldberg</author>
<author>Sandra Kuebler</author>
<author>Marie Candito</author>
<author>Jennifer Foster</author>
<author>Yannick Versley</author>
<author>Ines Rehbein</author>
<author>Lamia Tounsi</author>
</authors>
<title>Statistical parsing for morphologically rich language (SPMRL): What, how and whither.</title>
<date>2010</date>
<booktitle>In Proceedings of the first workshop on Statistical Parsing of Morphologically Rich Languages (SPMRL) at NA-ACL.</booktitle>
<contexts>
<context position="1407" citStr="Tsarfaty et al., 2010" startWordPosition="202" endWordPosition="205">formance of the best parsing systems to date in the different scenarios. 1 Introduction A parser takes a sentence in natural language as input and returns a syntactic parse tree representing the sentence’s human-perceived interpretation. Current state-of-the-art parsers assume that the spacedelimited words in the input are the basic units of syntactic analysis. Standard evaluation procedures and metrics (Black et al., 1991; Buchholz and Marsi, 2006) accordingly assume that the yield of the parse tree is known in advance. This assumption breaks down when parsing morphologically rich languages (Tsarfaty et al., 2010), where every space-delimited word may be effectively composed of multiple morphemes, each of which having a distinct role in the syntactic parse tree. In order to parse such input the text needs to undergo morphological segmentation, that is, identifying the morphological segments of each word and assigning the corresponding part-ofspeech (PoS) tags to them. Morphologically complex words may be highly ambiguous and in order to segment them correctly their analysis has to be disambiguated. The multiple morphological analyses of input words may be represented via a lattice that encodes the diff</context>
</contexts>
<marker>Tsarfaty, Seddah, Goldberg, Kuebler, Candito, Foster, Versley, Rehbein, Tounsi, 2010</marker>
<rawString>Reut Tsarfaty, Djame Seddah, Yoav Goldberg, Sandra Kuebler, Marie Candito, Jennifer Foster, Yannick Versley, Ines Rehbein, and Lamia Tounsi. 2010. Statistical parsing for morphologically rich language (SPMRL): What, how and whither. In Proceedings of the first workshop on Statistical Parsing of Morphologically Rich Languages (SPMRL) at NA-ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reut Tsarfaty</author>
<author>Joakim Nivre</author>
<author>Evelina Andersson</author>
</authors>
<title>Evaluating dependency parsing: Robust and heuristics-free cross-framework evaluation.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="7694" citStr="Tsarfaty et al., 2011" startWordPosition="1203" endWordPosition="1207">nstead of terminal boundaries (Tsarfaty, 2006) will fail here too, since the missing overt definite article H will cause similar misalignments. Metrics for dependencybased evaluation such as ATTACHMENT SCORES (Buchholz and Marsi, 2006) suffer from similar problems, since they assume that both trees have the same nodes — an assumption that breaks down in the case of incorrect morphological segmentation. Although great advances have been made in parsing MRLs in recent years, this evaluation challenge remained unsolved.3 In this paper we present a solution to this challenge by extending TEDEVAL (Tsarfaty et al., 2011) for handling trees over lattices. 3 The Proposal: Distance-Based Metrics Input and Output Spaces We view the joint task as a structured prediction function h : X → Y from input space X onto output space Y. Each element x ∈ X is a sequence x = w1, ... , wn of spacedelimited words from a set W. We assume a lexicon LEX, distinct from W, containing pairs of segments drawn from a set T of terminals and PoS categories drawn from a set N of nonterminals. LEX = {hs, pi|s ∈ T , p ∈ N} Each word wi in the input may admit multiple morphological analyses, constrained by a languagespecific morphological a</context>
</contexts>
<marker>Tsarfaty, Nivre, Andersson, 2011</marker>
<rawString>Reut Tsarfaty, Joakim Nivre, and Evelina Andersson. 2011. Evaluating dependency parsing: Robust and heuristics-free cross-framework evaluation. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reut Tsarfaty</author>
<author>Joakim Nivre</author>
<author>Evelina Andersson</author>
</authors>
<title>Cross-framework evaluation for statistical parsing.</title>
<date>2012</date>
<booktitle>In Proceedings of EACL.</booktitle>
<contexts>
<context position="14860" citStr="Tsarfaty et al. (2012)" startWordPosition="2485" endWordPosition="2488">t that we train the parsers for predicted on a treebank containing predicted tags. There is however a great drop when moving from predicted to raw, which confirms that evaluation benchmarks on gold input as in Nivre et al. (2007a) do not provide a realistic indication of parser performance. For all tables, TEDEVAL results are on a similar scale. However, results are not yet comparable across parsers. RR trees are flatter than bare-bone PS trees. PS and DEP trees have different label sets. Cross-framework evaluation may be conducted by combining this metric with the cross-framework protocol of Tsarfaty et al. (2012). 5 Conclusion We presented distance-based metrics defined for trees over lattices and applied them to evaluating parsers on joint morphological and syntactic disambiguation. Our contribution is both technical, providing an evaluation tool that can be straightforwardly applied for parsing scenarios involving trees over lattices,4 and methodological, suggesting to evaluate parsers in all possible scenarios in order to get a realistic indication of parser performance. Acknowledgements We thank Shay Cohen, Yoav Goldberg and Spence Green for discussion of this challenge. This work was supported by</context>
</contexts>
<marker>Tsarfaty, Nivre, Andersson, 2012</marker>
<rawString>Reut Tsarfaty, Joakim Nivre, and Evelina Andersson. 2012. Cross-framework evaluation for statistical parsing. In Proceedings of EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reut Tsarfaty</author>
</authors>
<title>Integrated morphological and syntactic disambiguation for Modern Hebrew.</title>
<date>2006</date>
<booktitle>In Proceeding of ACL-SRW.</booktitle>
<contexts>
<context position="2242" citStr="Tsarfaty, 2006" startWordPosition="335" endWordPosition="336">segmentation, that is, identifying the morphological segments of each word and assigning the corresponding part-ofspeech (PoS) tags to them. Morphologically complex words may be highly ambiguous and in order to segment them correctly their analysis has to be disambiguated. The multiple morphological analyses of input words may be represented via a lattice that encodes the different segmentation possibilities of the entire word sequence. One can either select a segmentation path prior to parsing, or, as has been recently argued, one can let the parser pick a segmentation jointly with decoding (Tsarfaty, 2006; Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008; Green and Manning, 2010). If the selected segmentation is different from the gold segmentation, the gold and parse trees are rendered incomparable and standard evaluation metrics break down. Evaluation scenarios restricted to gold input are often used to bypass this problem, but, as shall be seen shortly, they present an overly optimistic upperbound on parser performance. This paper presents a full treatment of evaluation in different parsing scenarios, using distance-based measures defined for trees over a shared common denominator defined</context>
<context position="6176" citStr="Tsarfaty, 2006" startWordPosition="956" endWordPosition="957"> set of analyses for this word is provided in Goldberg and Tsarfaty (2008). Examples for similar phenomena in Arabic may be found in Green and Manning (2010). Figure 2: The morphological segmentation possibilities of BCLM HNEIM. Double-circles are word boundaries. In practice, a statistical component is required to decide on the correct morphological segmentation, that is, to pick out the correct path through the lattice. This may be done based on linear local context (Adler and Elhadad, 2006; Shacham and Wintner, 2007; Bar-haim et al., 2008; Habash and Rambow, 2005), or jointly with parsing (Tsarfaty, 2006; Goldberg and Tsarfaty, 2008; Green and Manning, 2010). Either way, an incorrect morphological segmentation hypothesis introduces errors into the parse hypothesis, ultimately providing a parse tree which spans a different yield than the gold terminals. In such cases, existing evaluation metrics break down. To understand why, consider the trees in Figure 1. Metrics like PARSEVAL (Black et al., 1991) calculate the harmonic means of precision and recall on labeled spans (i, label, j) where i, j are terminal boundaries. Now, the NP dominating “shadow of them” has been identified and labeled corre</context>
</contexts>
<marker>Tsarfaty, 2006</marker>
<rawString>Reut Tsarfaty. 2006. Integrated morphological and syntactic disambiguation for Modern Hebrew. In Proceeding of ACL-SRW.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reut Tsarfaty</author>
</authors>
<title>Relational-Realizational Parsing.</title>
<date>2010</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Amsterdam.</institution>
<contexts>
<context position="3117" citStr="Tsarfaty, 2010" startWordPosition="464" endWordPosition="465">rios restricted to gold input are often used to bypass this problem, but, as shall be seen shortly, they present an overly optimistic upperbound on parser performance. This paper presents a full treatment of evaluation in different parsing scenarios, using distance-based measures defined for trees over a shared common denominator defined in terms of a lattice structure. We demonstrate the informativeness of our metrics by evaluating joint segmentation and parsing performance for the Semitic language Modern Hebrew, using the best performing systems, both constituencybased and dependency-based (Tsarfaty, 2010; Goldberg, 2011a). Our experiments demonstrate that, for all parsers, significant performance gaps between realistic and non-realistic scenarios crucially depend on the kind of information initially provided to the parser. The tool and metrics that we provide are completely general and can straightforwardly apply to other languages, treebanks and different tasks. 6 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 6–10, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics (tree1) TOP (tree2) TOP PP PP NP IN 0B1 </context>
</contexts>
<marker>Tsarfaty, 2010</marker>
<rawString>Reut Tsarfaty. 2010. Relational-Realizational Parsing. Ph.D. thesis, University of Amsterdam.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>