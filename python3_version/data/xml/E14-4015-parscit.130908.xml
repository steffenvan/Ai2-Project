<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.014631">
<title confidence="0.875994">
Accelerated Estimation of Conditional Random Fields using a
Pseudo-Likelihood-inspired Perceptron Variant
Teemu Ruokolainena Miikka Silfverbergb Mikko Kurimoa Krister Lindénb
a Department of Signal Processing and Acoustics, Aalto University, firstname.lastname@aalto.fi
b Department of Modern Languages, University of Helsinki, firstname.lastname@helsinki.fi
</title>
<sectionHeader confidence="0.961207" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999864666666667">
We discuss a simple estimation approach
for conditional random fields (CRFs). The
approach is derived heuristically by defin-
ing a variant of the classic perceptron al-
gorithm in spirit of pseudo-likelihood for
maximum likelihood estimation. The re-
sulting approximative algorithm has a lin-
ear time complexity in the size of the la-
bel set and contains a minimal amount of
tunable hyper-parameters. Consequently,
the algorithm is suitable for learning CRF-
based part-of-speech (POS) taggers in
presence of large POS label sets. We
present experiments on five languages.
Despite its heuristic nature, the algorithm
provides surprisingly competetive accura-
cies and running times against reference
methods.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999969462962963">
The conditional random field (CRF) model (Laf-
ferty et al., 2001) has been successfully applied
to several sequence labeling tasks in natural lan-
guage processing, including part-of-speech (POS)
tagging. In this work, we discuss accelerating the
CRF model estimation in presence of a large num-
ber of labels, say, hundreds or thousands. Large la-
bel sets occur in POS tagging of morphologically
rich languages (Erjavec, 2010; Haverinen et al.,
2013).
CRF training is most commonly associated with
the (conditional) maximum likelihood (ML) crite-
rion employed in the original work of Lafferty et
al. (2001). In this work, we focus on an alternative
training approach using the averaged perceptron
algorithm of Collins (2002). While yielding com-
petitive accuracy (Collins, 2002; Zhang and Clark,
2011), the perceptron algorithm avoids extensive
tuning of hyper-parameters and regularization re-
quired by the stochastic gradient descent algo-
rithm employed in ML estimation (Vishwanathan
et al., 2006). Additionally, while ML and percep-
tron training share an identical time complexity,
the perceptron is in practice faster due to sparser
parameter updates.
Despite its simplicity, running the perceptron al-
gorithm can be tedious in case the data contains
a large number of labels. Previously, this prob-
lem has been addressed using, for example, k-best
beam search (Collins and Roark, 2004; Zhang and
Clark, 2011; Huang et al., 2012) and paralleliza-
tion (McDonald et al., 2010). In this work, we
explore an alternative strategy, in which we mod-
ify the perceptron algorithm in spirit of the classic
pseudo-likelihood approximation for ML estima-
tion (Besag, 1975). The resulting novel algorithm
has linear complexity w.r.t. the label set size and
contains only a single hyper-parameter, namely,
the number of passes taken over the training data
set.
We evaluate the algorithm, referred to as the
pseudo-perceptron, empirically in POS tagging
on five languages. The results suggest that the
approach can yield competitive accuracy com-
pared to perceptron training accelerated using a
violation-fixed 1-best beam search (Collins and
Roark, 2004; Huang et al., 2012) which also pro-
vides a linear time complexity in label set size.
The rest of the paper is as follows. In Section 2,
we describe the pseudo-perceptron algorithm and
discuss related work. In Sections 3 and 4, we
describe our experiment setup and the results, re-
spectively. Conclusions on the work are presented
in Section 5.
</bodyText>
<sectionHeader confidence="0.999077" genericHeader="introduction">
2 Methods
</sectionHeader>
<subsectionHeader confidence="0.983747">
2.1 Pseudo-Perceptron Algorithm
</subsectionHeader>
<bodyText confidence="0.998816">
The (unnormalized) CRF model for input and
output sequences x = (x1, x2,... , xjx) and
</bodyText>
<page confidence="0.987263">
74
</page>
<note confidence="0.728469">
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 74–78,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<equation confidence="0.987697833333333">
y = (y1, y2, ... , y|x|), respectively, is written as
( )
p (y  |x; w) ∝ exp w · Φ(y, x)
( )
exp w · φ(yi−n, . . . , yi, x, i) ,
(1)
</equation>
<bodyText confidence="0.999594">
where w denotes the model parameter vector, Φ
the vector-valued global feature extracting func-
tion, φ the vector-valued local feature extracting
function, and n the model order. We denote the
tag set as Y. The model parameters w are esti-
mated based on training data, and test instances
are decoded using the Viterbi search (Lafferty et
al., 2001).
Given the model definition (1), the param-
eters w can be estimated in a straightforward
manner using the structured perceptron algo-
rithm (Collins, 2002). The algorithm iterates
over the training set a single instance (x, y) at
a time and updates the parameters according
</bodyText>
<equation confidence="0.920804333333333">
to the rule w(i) = w(i−1) + ΔΦ(x, y, z), where
ΔΦ(x, y, z) for the ith iteration is written as
ΔΦ(x, y, z) = Φ(x, y) − Φ(x, z). The predic-
tion z is obtained as
z = arg max w · Φ(x, u) (2)
u∈Y(x)
</equation>
<bodyText confidence="0.9990839">
by performing the Viterbi search over
Y(x) = Y × ··· × Y, a product of |x |copies
of Y. In case the perceptron algorithm yields
a small number of incorrect predictions on the
training data set, the parameters generalize well
to test instances with a high probability (Collins,
2002).
The time complexity of the Viterbi search is
O(|x |× |Y|n+1). Consequently, running the per-
ceptron algorithm can become tedious if the la-
bel set cardinality |Y |and/or the model order n
is large. In order to speed up learning, we define
a variant of the algorithm in the spirit of pseudo-
likelihood (PL) learning (Besag, 1975). In anal-
ogy to PL, the key idea of the pseudo-perceptron
(PP) algorithm is to obtain the required predictions
over single variables yi while fixing the remaining
variables to their true values. In other words, in-
stead of using the Viterbi search to find the z as in
(2), we find a z0 for each position i ∈ 1..|x |as
</bodyText>
<equation confidence="0.97576225">
z0 = arg max w · Φ(x, u) , (3)
u∈Y,i(x)
with Y0i(x) = {y1}×···×{yi−1}×Y ×{yi+1}×
· · · × {y|x|}. Subsequent to training, test instances
</equation>
<bodyText confidence="0.99891340625">
are decoded in a standard manner using the Viterbi
search.
The appeal of PP is that the time complexity
of search is reduced to O(|x |× |Y|), i.e., linear
in the number of labels in the label set. On the
other hand, we no longer expect the obtained pa-
rameters to necessarily generalize well to test in-
stances.1 Consequently, we consider PP a heuris-
tic estimation approach motivated by the rather
well-established success of PL (Korˇc and Förstner,
2008; Sutton and McCallum, 2009).2
Next, we study yet another heuristic pseudo-
variant of the perceptron algorithm referred to as
the piecewise-pseudo-perceptron (PW-PP). This
algorithm is analogous to the piecewise-pseudo-
likelihood (PW-PL) approximation presented by
Sutton and McCallum (2009). In this variant, the
original graph is first split into smaller, possibly
overlapping subgraphs (pieces). Subsequently, we
apply the PP approximation to the pieces. We em-
ploy the approach coined factor-as-piece by Sut-
ton and McCallum (2009), in which each piece
contains n + 1 consecutive variables, where n is
the CRF model order.
The PW-PP approach is motivated by the results
of Sutton and McCallum (2009) who found PW-
PL to increase stability w.r.t. accuracy compared
to plain PL across tasks. Note that the piecewise
approximation in itself is not interesting in chain-
structured CRFs, as it results in same time com-
plexity as standard estimation. Meanwhile, the
PW-PP algorithm has same time complexity as PP.
</bodyText>
<sectionHeader confidence="0.620551" genericHeader="method">
2.2 Related work
</sectionHeader>
<bodyText confidence="0.9997592">
Previously, impractical running times of percep-
tron learning have been addressed most notably
using the k-best beam search method (Collins and
Roark, 2004; Zhang and Clark, 2011; Huang et
al., 2012). Here, we consider the ”greedy” 1-best
beam search variant most relevant as it shares the
time complexity of the pseudo search. Therefore,
in the experimental section of this work, we com-
pare the PP and 1-best beam search.
We are aware of at least two other learning ap-
proaches inspired by PL, namely, the pseudo-max
and piecewise algorithms of Sontag et al. (2010)
and Alahari et al. (2010), respectively. Com-
pared to these approaches, the PP algorithm pro-
vides a simpler estimation tool as it avoids the
</bodyText>
<footnote confidence="0.980062">
1We leave formal treatment to future work.
2Meanwhile, note that pseudo-likelihood is a consistent
estimator (Gidas, 1988; Hyvärinen, 2006).
</footnote>
<equation confidence="0.761804">
|x|
= H
i=n
</equation>
<page confidence="0.968703">
75
</page>
<bodyText confidence="0.9997305">
hyper-parameters involved in the stochastic gradi-
ent descent algorithms as well as the regularization
and margin functions inherent to the approaches of
Alahari et al. (2010) and Sontag et al. (2010). On
the other hand, Sontag et al. (2010) show that the
pseudo-max approach achieves consistency given
certain assumptions on the data generating func-
tion. Meanwhile, as discussed in previous section,
we consider PP a heuristic and do not provide any
generalization guarantees. To our understanding,
Alahari et al. (2010) do not provide generalization
guarantees for their algorithm.
</bodyText>
<sectionHeader confidence="0.999825" genericHeader="method">
3 Experimental Setup
</sectionHeader>
<subsectionHeader confidence="0.996092">
3.1 Data
</subsectionHeader>
<bodyText confidence="0.99908536">
For a quick overview of the data sets, see Table 1.
Penn Treebank. The first data set we consider
is the classic Penn Treebank. The complete tree-
bank is divided into 25 sections of newswire text
extracted from the Wall Street Journal. We split
the data into training, development, and test sets
using the sections 0-18, 19-21, and 22-24, accord-
ing to the standardly applied division introduced
by Collins (2002).
Multext-East. The second data we consider is
the multilingual Multext-East (Erjavec, 2010) cor-
pus. The corpus contains the novel 1984 by
George Orwell. From the available seven lan-
guages, we utilize the Czech, Estonian and Ro-
manian sections. Since the data does not have a
standard division to training and test sets, we as-
sign the 9th and 10th from each 10 consecutive
sentences to the development and test sets, respec-
tively. The remaining sentences are assigned to the
training sets.
Turku Dependency Treebank. The third data
we consider is the Finnish Turku Dependency
Treebank (Haverinen et al., 2013). The treebank
contains text from 10 different domains. We use
the same data split strategy as for Multext East.
</bodyText>
<subsectionHeader confidence="0.844136">
3.2 Reference Methods
</subsectionHeader>
<bodyText confidence="0.999599714285714">
We compare the PP and PW-PP algorithms with
perceptron learning accelerated using 1-best beam
search modified using the early update rule
(Huang et al., 2012). While Huang et al. (2012)
experimented with several violation-fixing meth-
ods (early, latest, maximum, hybrid), they ap-
peared to reach termination at the same rate in
</bodyText>
<table confidence="0.761145">
lang. train. dev. test tags train. tags
eng 38,219 5,527 5,462 45 45
rom 5,216 652 652 405 391
est 5,183 648 647 413 408
cze 5,402 675 675 955 908
fin 5,043 630 630 2,355 2,141
</table>
<tableCaption confidence="0.9324">
Table 1: Overview on data. The training (train.),
</tableCaption>
<bodyText confidence="0.962450363636364">
development (dev.) and test set sizes are given in
sentences. The columns titled tags and train. tags
correspond to total number of tags in the data set
and number of tags in the training set, respectively.
POS tagging. Our preliminary experiments using
the latest violation updates supported this. Conse-
quently, we employ the early updates.
We also provide results using the CRFsuite
toolkit (Okazaki, 2007), which implements a 1st-
order CRF model. To best of our knowledge,
CRFsuite is currently the fastest freely available
CRF implementation.3 In addition to the averaged
perceptron algorithm (Collins, 2002), the toolkit
implements several training procedures (Nocedal,
1980; Crammer et al., 2006; Andrew and Gao,
2007; Mejer and Crammer, 2010; Shalev-Shwartz
et al., 2011). We run CRFsuite using these algo-
rithms employing their default parameters and the
feature extraction scheme and stopping criterion
described in Section 3.3. We then report results
provided by the most accurate algorithm on each
language.
</bodyText>
<subsectionHeader confidence="0.998763">
3.3 Details on CRF Training and Decoding
</subsectionHeader>
<bodyText confidence="0.999967823529412">
While the methods discussed in this work are ap-
plicable for nth-order CRFs, we employ 1st-order
CRFs in order to avoid overfitting the relatively
small training sets.
We employ a simple feature set including word
forms at position t − 2, ... , t + 2, suffixes of word
at position t up to four letters, and three ortho-
graphic features indicating if the word at position
t contains a hyphen, capital letter, or a digit.
All the perceptron variants (PP, PW-PP, 1-best
beam search) initialize the model parameters with
zero vectors and process the training instances in
the order they appear in the corpus. At the end
of each pass, we apply the CRFs using the latest
averaged parameters (Collins, 2002) to the devel-
opment set. We assume the algorithms have con-
verged when the model accuracy on development
</bodyText>
<footnote confidence="0.982868">
3See benchmark results at http://www.chokkan.
org/software/crfsuite/benchmark.html
</footnote>
<page confidence="0.992154">
76
</page>
<bodyText confidence="0.999986636363636">
has not increased during last three iterations. Af-
ter termination, we apply the averaged parameters
yielding highest performance on the development
set to test instances.
Test and development instances are decoded us-
ing a combination of Viterbi search and the tag
dictionary approach of Ratnaparkhi (1996). In this
approach, candidate tags for known word forms
are limited to those observed in the training data.
Meanwhile, word forms that were unseen during
training consider the full label set.
</bodyText>
<subsectionHeader confidence="0.988234">
3.4 Software and Hardware
</subsectionHeader>
<bodyText confidence="0.999990666666667">
The experiments are run on a standard desktop
computer. We use our own C++-based implemen-
tation of the methods discussed in Section 2.
</bodyText>
<sectionHeader confidence="0.999964" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.999977958333333">
The obtained training times and test set accuracies
(measured using accuracy and out-of-vocabulary
(OOV) accuracy) are presented in Table 2. The
training CPU times include the time (in minutes)
consumed by running the perceptron algorithm
variants as well as evaluation of the development
set accuracy. The column labeled it. corresponds
to the number of passes over training set made by
the algorithms before termination.
We summarize the results as follows. First, PW-
PP provided higher accuracies compared to PP on
Romanian, Czech, and Finnish. The differences
were statistically significant4 on Czech. Second,
while yielding similar running times compared
to 1-best beam search, PW-PP provided higher
accuracies on all languages apart from Finnish.
The differences were significant on Estonian and
Czech. Third, while fastest on the Penn Treebank,
the CRFsuite toolkit became substantially slower
compared to PW-PP when the number of labels
were increased (see Czech and Finnish). The dif-
ferences in accuracies between the best perform-
ing CRFsuite algorithm and PP and PW-PP were
significant on Czech.
</bodyText>
<sectionHeader confidence="0.997492" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.998318">
We presented a heuristic perceptron variant for
estimation of CRFs in the spirit of the classic
</bodyText>
<footnote confidence="0.87598525">
4We establish significance (with confidence level 0.95)
using the standard 1-sided Wilcoxon signed-rank test per-
formed on 10 randomly divided, non-overlapping subsets of
the complete test sets.
</footnote>
<table confidence="0.999507923076923">
method it. time (min) acc. OOV
English
PP 9 6 96.99 87.97
PW-PP 10 7 96.98 88.11
1-best beam 17 8 96.91 88.33
Pas.-Agg. 9 1 97.01 88.68
Romanian
PP 9 8 96.81 83.66
PW-PP 8 7 96.91 84.38
1-best beam 17 10 96.88 85.32
Pas.-Agg. 13 9 97.06 84.69
Estonian
PP 10 8 93.39 78.10
PW-PP 8 6 93.35 78.66
1-best beam 23 15 92.95 75.65
Pas.-Agg. 15 12 93.27 77.63
Czech
PP 11 26 89.37 70.67
PW-PP 16 41 89.84 72.52
1-best beam 14 19 88.95 70.90
Pegasos 15 341 90.42 72.59
Finnish
PP 11 58 87.09 58.58
PW-PP 11 56 87.16 58.50
1-best beam 21 94 87.38 59.29
Pas.-Agg. 16 693 87.17 57.58
</table>
<tableCaption confidence="0.98674">
Table 2: Results. We report CRFsuite results pro-
</tableCaption>
<bodyText confidence="0.991848384615385">
vided by most accurate algorithm on each lan-
guage: the Pas.-Agg. and Pegasos refer to the al-
gorithms of Crammer et al. (2006) and Shalev-
Shwartz et al. (2011), respectively.
pseudo-likelihood estimator. The resulting ap-
proximative algorithm has a linear time complex-
ity in the label set cardinality and contains only
a single hyper-parameter, namely, the number of
passes taken over the training data set. We eval-
uated the algorithm in POS tagging on five lan-
guages. Despite its heuristic nature, the algo-
rithm provided competetive accuracies and run-
ning times against reference methods.
</bodyText>
<sectionHeader confidence="0.99495" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999865285714286">
This work was financially supported by Langnet
(Finnish doctoral programme in language stud-
ies) and the Academy of Finland under the grant
no 251170 (Finnish Centre of Excellence Pro-
gram (2012-2017)). We would like to thank Dr.
Onur Dikmen for the helpful discussions during
the work.
</bodyText>
<page confidence="0.998081">
77
</page>
<sectionHeader confidence="0.990235" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999688732673268">
Karteek Alahari, Chris Russell, and Philip H.S. Torr.
2010. Efficient piecewise learning for conditional
random fields. In Computer Vision and Pattern
Recognition (CVPR), 2010 IEEE Conference on,
pages 895–901.
Galen Andrew and Jianfeng Gao. 2007. Scalable train-
ing of Ll-regularized log-linear models. In Proceed-
ings of the 24th international conference on Ma-
chine learning, pages 33–40.
Julian Besag. 1975. Statistical analysis of non-lattice
data. The statistician, pages 179–195.
Michael Collins and Brian Roark. 2004. Incremental
parsing with the perceptron algorithm. In Proceed-
ings of the 42nd Annual Meeting on Association for
Computational Linguistics, page 111.
Michael Collins. 2002. Discriminative training meth-
ods for hidden Markov models: Theory and exper-
iments with perceptron algorithms. In Proceedings
of the ACL-02 conference on Empirical methods in
natural language processing, volume 10, pages 1–8.
Koby Crammer, Ofer Dekel, Joseph Keshet, Shai
Shalev-Shwartz, and Yoram Singer. 2006. Online
passive-aggressive algorithms. The Journal of Ma-
chine Learning Research, 7:551–585.
Tomaž Erjavec. 2010. Multext-east version 4: Multi-
lingual morphosyntactic specifications, lexicons and
corpora. In Proceedings of the Seventh International
Conference on Language Resources and Evaluation
(LREC’10).
Basilis Gidas. 1988. Consistency of maximum like-
lihood and pseudo-likelihood estimators for Gibbs
distributions. In Stochastic differential systems,
stochastic control theory and applications, pages
129–145.
Katri Haverinen, Jenna Nyblom, Timo Viljanen,
Veronika Laippala, Samuel Kohonen, Anna Missilä,
Stina Ojala, Tapio Salakoski, and Filip Ginter. 2013.
Building the essential resources for Finnish: the
Turku Dependency Treebank. Language Resources
and Evaluation.
Liang Huang, Suphan Fayong, and Yang Guo. 2012.
Structured perceptron with inexact search. In Pro-
ceedings of the 2012 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies, pages
142–151.
Aapo Hyvärinen. 2006. Consistency of pseudolike-
lihood estimation of fully visible Boltzmann ma-
chines. Neural Computation, 18(10):2283–2292.
Filip Korˇc and Wolfgang Förstner. 2008. Approximate
parameter learning in conditional random fields: An
empirical investigation. Pattern Recognition, pages
11–20.
John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data. In Proceedings of the Eighteenth In-
ternational Conference on Machine Learning, pages
282–289.
Ryan McDonald, Keith Hall, and Gideon Mann. 2010.
Distributed training strategies for the structured per-
ceptron. In Human Language Technologies: The
2010 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics, pages 456–464.
Avihai Mejer and Koby Crammer. 2010. Confidence
in structured-prediction using confidence-weighted
models. In Proceedings of the 2010 conference on
empirical methods in natural language processing,
pages 971–981.
Jorge Nocedal. 1980. Updating quasi-Newton matri-
ces with limited storage. Mathematics of computa-
tion, 35(151):773–782.
Naoaki Okazaki. 2007. CRFsuite: a fast implemen-
tation of conditional random fields (CRFs). URL
http://www.chokkan.org/software/crfsuite.
Adwait Ratnaparkhi. 1996. A maximum entropy
model for part-of-speech tagging. In Proceedings
of the conference on empirical methods in natural
language processing, volume 1, pages 133–142.
Shai Shalev-Shwartz, Yoram Singer, Nathan Srebro,
and Andrew Cotter. 2011. Pegasos: Primal esti-
mated sub-gradient solver for SVM. Mathematical
Programming, 127(1):3–30.
David Sontag, Ofer Meshi, Tommi Jaakkola, and Amir
Globerson. 2010. More data means less inference:
A pseudo-max approach to structured learning. In
Advances in Neural Information Processing Systems
23, pages 2181–2189.
Charles Sutton and Andrew McCallum. 2009. Piece-
wise training for structured prediction. Machine
learning, 77(2):165–194.
S.V.N. Vishwanathan, Nicol Schraudolph, Mark
Schmidt, and Kevin Murphy. 2006. Accelerated
training of conditional random fields with stochas-
tic gradient methods. In Proceedings of the 23rd in-
ternational conference on Machine learning, pages
969–976.
Yue Zhang and Stephen Clark. 2011. Syntactic pro-
cessing using the generalized perceptron and beam
search. Computational Linguistics, 37(1):105–151.
</reference>
<page confidence="0.998825">
78
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.494408">
<title confidence="0.992146">Accelerated Estimation of Conditional Random Fields using</title>
<author confidence="0.97831">Pseudo-Likelihood-inspired Perceptron Variant</author>
<affiliation confidence="0.98748">of Signal Processing and Acoustics, Aalto University,</affiliation>
<address confidence="0.524611">of Modern Languages, University of Helsinki, firstname.lastname@helsinki.fi</address>
<abstract confidence="0.998118473684211">We discuss a simple estimation approach for conditional random fields (CRFs). The approach is derived heuristically by defining a variant of the classic perceptron algorithm in spirit of pseudo-likelihood for maximum likelihood estimation. The resulting approximative algorithm has a linear time complexity in the size of the label set and contains a minimal amount of tunable hyper-parameters. Consequently, the algorithm is suitable for learning CRFbased part-of-speech (POS) taggers in presence of large POS label sets. We present experiments on five languages. Despite its heuristic nature, the algorithm provides surprisingly competetive accuracies and running times against reference methods.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Karteek Alahari</author>
<author>Chris Russell</author>
<author>Philip H S Torr</author>
</authors>
<title>Efficient piecewise learning for conditional random fields.</title>
<date>2010</date>
<booktitle>In Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on,</booktitle>
<pages>895--901</pages>
<contexts>
<context position="7966" citStr="Alahari et al. (2010)" startWordPosition="1292" endWordPosition="1295">lexity as PP. 2.2 Related work Previously, impractical running times of perceptron learning have been addressed most notably using the k-best beam search method (Collins and Roark, 2004; Zhang and Clark, 2011; Huang et al., 2012). Here, we consider the ”greedy” 1-best beam search variant most relevant as it shares the time complexity of the pseudo search. Therefore, in the experimental section of this work, we compare the PP and 1-best beam search. We are aware of at least two other learning approaches inspired by PL, namely, the pseudo-max and piecewise algorithms of Sontag et al. (2010) and Alahari et al. (2010), respectively. Compared to these approaches, the PP algorithm provides a simpler estimation tool as it avoids the 1We leave formal treatment to future work. 2Meanwhile, note that pseudo-likelihood is a consistent estimator (Gidas, 1988; Hyvärinen, 2006). |x| = H i=n 75 hyper-parameters involved in the stochastic gradient descent algorithms as well as the regularization and margin functions inherent to the approaches of Alahari et al. (2010) and Sontag et al. (2010). On the other hand, Sontag et al. (2010) show that the pseudo-max approach achieves consistency given certain assumptions on the </context>
</contexts>
<marker>Alahari, Russell, Torr, 2010</marker>
<rawString>Karteek Alahari, Chris Russell, and Philip H.S. Torr. 2010. Efficient piecewise learning for conditional random fields. In Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, pages 895–901.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Galen Andrew</author>
<author>Jianfeng Gao</author>
</authors>
<title>Scalable training of Ll-regularized log-linear models.</title>
<date>2007</date>
<booktitle>In Proceedings of the 24th international conference on Machine learning,</booktitle>
<pages>33--40</pages>
<contexts>
<context position="11279" citStr="Andrew and Gao, 2007" startWordPosition="1826" endWordPosition="1829">correspond to total number of tags in the data set and number of tags in the training set, respectively. POS tagging. Our preliminary experiments using the latest violation updates supported this. Consequently, we employ the early updates. We also provide results using the CRFsuite toolkit (Okazaki, 2007), which implements a 1storder CRF model. To best of our knowledge, CRFsuite is currently the fastest freely available CRF implementation.3 In addition to the averaged perceptron algorithm (Collins, 2002), the toolkit implements several training procedures (Nocedal, 1980; Crammer et al., 2006; Andrew and Gao, 2007; Mejer and Crammer, 2010; Shalev-Shwartz et al., 2011). We run CRFsuite using these algorithms employing their default parameters and the feature extraction scheme and stopping criterion described in Section 3.3. We then report results provided by the most accurate algorithm on each language. 3.3 Details on CRF Training and Decoding While the methods discussed in this work are applicable for nth-order CRFs, we employ 1st-order CRFs in order to avoid overfitting the relatively small training sets. We employ a simple feature set including word forms at position t − 2, ... , t + 2, suffixes of w</context>
</contexts>
<marker>Andrew, Gao, 2007</marker>
<rawString>Galen Andrew and Jianfeng Gao. 2007. Scalable training of Ll-regularized log-linear models. In Proceedings of the 24th international conference on Machine learning, pages 33–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julian Besag</author>
</authors>
<title>Statistical analysis of non-lattice data. The statistician,</title>
<date>1975</date>
<pages>179--195</pages>
<contexts>
<context position="2732" citStr="Besag, 1975" startWordPosition="398" endWordPosition="399">g share an identical time complexity, the perceptron is in practice faster due to sparser parameter updates. Despite its simplicity, running the perceptron algorithm can be tedious in case the data contains a large number of labels. Previously, this problem has been addressed using, for example, k-best beam search (Collins and Roark, 2004; Zhang and Clark, 2011; Huang et al., 2012) and parallelization (McDonald et al., 2010). In this work, we explore an alternative strategy, in which we modify the perceptron algorithm in spirit of the classic pseudo-likelihood approximation for ML estimation (Besag, 1975). The resulting novel algorithm has linear complexity w.r.t. the label set size and contains only a single hyper-parameter, namely, the number of passes taken over the training data set. We evaluate the algorithm, referred to as the pseudo-perceptron, empirically in POS tagging on five languages. The results suggest that the approach can yield competitive accuracy compared to perceptron training accelerated using a violation-fixed 1-best beam search (Collins and Roark, 2004; Huang et al., 2012) which also provides a linear time complexity in label set size. The rest of the paper is as follows.</context>
<context position="5449" citStr="Besag, 1975" startWordPosition="872" endWordPosition="873">x) by performing the Viterbi search over Y(x) = Y × ··· × Y, a product of |x |copies of Y. In case the perceptron algorithm yields a small number of incorrect predictions on the training data set, the parameters generalize well to test instances with a high probability (Collins, 2002). The time complexity of the Viterbi search is O(|x |× |Y|n+1). Consequently, running the perceptron algorithm can become tedious if the label set cardinality |Y |and/or the model order n is large. In order to speed up learning, we define a variant of the algorithm in the spirit of pseudolikelihood (PL) learning (Besag, 1975). In analogy to PL, the key idea of the pseudo-perceptron (PP) algorithm is to obtain the required predictions over single variables yi while fixing the remaining variables to their true values. In other words, instead of using the Viterbi search to find the z as in (2), we find a z0 for each position i ∈ 1..|x |as z0 = arg max w · Φ(x, u) , (3) u∈Y,i(x) with Y0i(x) = {y1}×···×{yi−1}×Y ×{yi+1}× · · · × {y|x|}. Subsequent to training, test instances are decoded in a standard manner using the Viterbi search. The appeal of PP is that the time complexity of search is reduced to O(|x |× |Y|), i.e.,</context>
</contexts>
<marker>Besag, 1975</marker>
<rawString>Julian Besag. 1975. Statistical analysis of non-lattice data. The statistician, pages 179–195.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Brian Roark</author>
</authors>
<title>Incremental parsing with the perceptron algorithm.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>111</pages>
<contexts>
<context position="2460" citStr="Collins and Roark, 2004" startWordPosition="352" endWordPosition="355"> (Collins, 2002; Zhang and Clark, 2011), the perceptron algorithm avoids extensive tuning of hyper-parameters and regularization required by the stochastic gradient descent algorithm employed in ML estimation (Vishwanathan et al., 2006). Additionally, while ML and perceptron training share an identical time complexity, the perceptron is in practice faster due to sparser parameter updates. Despite its simplicity, running the perceptron algorithm can be tedious in case the data contains a large number of labels. Previously, this problem has been addressed using, for example, k-best beam search (Collins and Roark, 2004; Zhang and Clark, 2011; Huang et al., 2012) and parallelization (McDonald et al., 2010). In this work, we explore an alternative strategy, in which we modify the perceptron algorithm in spirit of the classic pseudo-likelihood approximation for ML estimation (Besag, 1975). The resulting novel algorithm has linear complexity w.r.t. the label set size and contains only a single hyper-parameter, namely, the number of passes taken over the training data set. We evaluate the algorithm, referred to as the pseudo-perceptron, empirically in POS tagging on five languages. The results suggest that the a</context>
<context position="7530" citStr="Collins and Roark, 2004" startWordPosition="1216" endWordPosition="1219">contains n + 1 consecutive variables, where n is the CRF model order. The PW-PP approach is motivated by the results of Sutton and McCallum (2009) who found PWPL to increase stability w.r.t. accuracy compared to plain PL across tasks. Note that the piecewise approximation in itself is not interesting in chainstructured CRFs, as it results in same time complexity as standard estimation. Meanwhile, the PW-PP algorithm has same time complexity as PP. 2.2 Related work Previously, impractical running times of perceptron learning have been addressed most notably using the k-best beam search method (Collins and Roark, 2004; Zhang and Clark, 2011; Huang et al., 2012). Here, we consider the ”greedy” 1-best beam search variant most relevant as it shares the time complexity of the pseudo search. Therefore, in the experimental section of this work, we compare the PP and 1-best beam search. We are aware of at least two other learning approaches inspired by PL, namely, the pseudo-max and piecewise algorithms of Sontag et al. (2010) and Alahari et al. (2010), respectively. Compared to these approaches, the PP algorithm provides a simpler estimation tool as it avoids the 1We leave formal treatment to future work. 2Meanw</context>
</contexts>
<marker>Collins, Roark, 2004</marker>
<rawString>Michael Collins and Brian Roark. 2004. Incremental parsing with the perceptron algorithm. In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, page 111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 conference on Empirical methods in natural language processing,</booktitle>
<volume>10</volume>
<pages>1--8</pages>
<contexts>
<context position="1800" citStr="Collins (2002)" startWordPosition="255" endWordPosition="256">l sequence labeling tasks in natural language processing, including part-of-speech (POS) tagging. In this work, we discuss accelerating the CRF model estimation in presence of a large number of labels, say, hundreds or thousands. Large label sets occur in POS tagging of morphologically rich languages (Erjavec, 2010; Haverinen et al., 2013). CRF training is most commonly associated with the (conditional) maximum likelihood (ML) criterion employed in the original work of Lafferty et al. (2001). In this work, we focus on an alternative training approach using the averaged perceptron algorithm of Collins (2002). While yielding competitive accuracy (Collins, 2002; Zhang and Clark, 2011), the perceptron algorithm avoids extensive tuning of hyper-parameters and regularization required by the stochastic gradient descent algorithm employed in ML estimation (Vishwanathan et al., 2006). Additionally, while ML and perceptron training share an identical time complexity, the perceptron is in practice faster due to sparser parameter updates. Despite its simplicity, running the perceptron algorithm can be tedious in case the data contains a large number of labels. Previously, this problem has been addressed usi</context>
<context position="4526" citStr="Collins, 2002" startWordPosition="698" endWordPosition="699">, y|x|), respectively, is written as ( ) p (y |x; w) ∝ exp w · Φ(y, x) ( ) exp w · φ(yi−n, . . . , yi, x, i) , (1) where w denotes the model parameter vector, Φ the vector-valued global feature extracting function, φ the vector-valued local feature extracting function, and n the model order. We denote the tag set as Y. The model parameters w are estimated based on training data, and test instances are decoded using the Viterbi search (Lafferty et al., 2001). Given the model definition (1), the parameters w can be estimated in a straightforward manner using the structured perceptron algorithm (Collins, 2002). The algorithm iterates over the training set a single instance (x, y) at a time and updates the parameters according to the rule w(i) = w(i−1) + ΔΦ(x, y, z), where ΔΦ(x, y, z) for the ith iteration is written as ΔΦ(x, y, z) = Φ(x, y) − Φ(x, z). The prediction z is obtained as z = arg max w · Φ(x, u) (2) u∈Y(x) by performing the Viterbi search over Y(x) = Y × ··· × Y, a product of |x |copies of Y. In case the perceptron algorithm yields a small number of incorrect predictions on the training data set, the parameters generalize well to test instances with a high probability (Collins, 2002). Th</context>
<context position="9261" citStr="Collins (2002)" startWordPosition="1500" endWordPosition="1501">r PP a heuristic and do not provide any generalization guarantees. To our understanding, Alahari et al. (2010) do not provide generalization guarantees for their algorithm. 3 Experimental Setup 3.1 Data For a quick overview of the data sets, see Table 1. Penn Treebank. The first data set we consider is the classic Penn Treebank. The complete treebank is divided into 25 sections of newswire text extracted from the Wall Street Journal. We split the data into training, development, and test sets using the sections 0-18, 19-21, and 22-24, according to the standardly applied division introduced by Collins (2002). Multext-East. The second data we consider is the multilingual Multext-East (Erjavec, 2010) corpus. The corpus contains the novel 1984 by George Orwell. From the available seven languages, we utilize the Czech, Estonian and Romanian sections. Since the data does not have a standard division to training and test sets, we assign the 9th and 10th from each 10 consecutive sentences to the development and test sets, respectively. The remaining sentences are assigned to the training sets. Turku Dependency Treebank. The third data we consider is the Finnish Turku Dependency Treebank (Haverinen et al</context>
<context position="11168" citStr="Collins, 2002" startWordPosition="1812" endWordPosition="1813">), development (dev.) and test set sizes are given in sentences. The columns titled tags and train. tags correspond to total number of tags in the data set and number of tags in the training set, respectively. POS tagging. Our preliminary experiments using the latest violation updates supported this. Consequently, we employ the early updates. We also provide results using the CRFsuite toolkit (Okazaki, 2007), which implements a 1storder CRF model. To best of our knowledge, CRFsuite is currently the fastest freely available CRF implementation.3 In addition to the averaged perceptron algorithm (Collins, 2002), the toolkit implements several training procedures (Nocedal, 1980; Crammer et al., 2006; Andrew and Gao, 2007; Mejer and Crammer, 2010; Shalev-Shwartz et al., 2011). We run CRFsuite using these algorithms employing their default parameters and the feature extraction scheme and stopping criterion described in Section 3.3. We then report results provided by the most accurate algorithm on each language. 3.3 Details on CRF Training and Decoding While the methods discussed in this work are applicable for nth-order CRFs, we employ 1st-order CRFs in order to avoid overfitting the relatively small t</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms. In Proceedings of the ACL-02 conference on Empirical methods in natural language processing, volume 10, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Ofer Dekel</author>
<author>Joseph Keshet</author>
<author>Shai Shalev-Shwartz</author>
<author>Yoram Singer</author>
</authors>
<title>Online passive-aggressive algorithms.</title>
<date>2006</date>
<journal>The Journal of Machine Learning Research,</journal>
<pages>7--551</pages>
<contexts>
<context position="11257" citStr="Crammer et al., 2006" startWordPosition="1822" endWordPosition="1825"> tags and train. tags correspond to total number of tags in the data set and number of tags in the training set, respectively. POS tagging. Our preliminary experiments using the latest violation updates supported this. Consequently, we employ the early updates. We also provide results using the CRFsuite toolkit (Okazaki, 2007), which implements a 1storder CRF model. To best of our knowledge, CRFsuite is currently the fastest freely available CRF implementation.3 In addition to the averaged perceptron algorithm (Collins, 2002), the toolkit implements several training procedures (Nocedal, 1980; Crammer et al., 2006; Andrew and Gao, 2007; Mejer and Crammer, 2010; Shalev-Shwartz et al., 2011). We run CRFsuite using these algorithms employing their default parameters and the feature extraction scheme and stopping criterion described in Section 3.3. We then report results provided by the most accurate algorithm on each language. 3.3 Details on CRF Training and Decoding While the methods discussed in this work are applicable for nth-order CRFs, we employ 1st-order CRFs in order to avoid overfitting the relatively small training sets. We employ a simple feature set including word forms at position t − 2, ... </context>
<context position="15325" citStr="Crammer et al. (2006)" startWordPosition="2489" endWordPosition="2492">97.01 88.68 Romanian PP 9 8 96.81 83.66 PW-PP 8 7 96.91 84.38 1-best beam 17 10 96.88 85.32 Pas.-Agg. 13 9 97.06 84.69 Estonian PP 10 8 93.39 78.10 PW-PP 8 6 93.35 78.66 1-best beam 23 15 92.95 75.65 Pas.-Agg. 15 12 93.27 77.63 Czech PP 11 26 89.37 70.67 PW-PP 16 41 89.84 72.52 1-best beam 14 19 88.95 70.90 Pegasos 15 341 90.42 72.59 Finnish PP 11 58 87.09 58.58 PW-PP 11 56 87.16 58.50 1-best beam 21 94 87.38 59.29 Pas.-Agg. 16 693 87.17 57.58 Table 2: Results. We report CRFsuite results provided by most accurate algorithm on each language: the Pas.-Agg. and Pegasos refer to the algorithms of Crammer et al. (2006) and ShalevShwartz et al. (2011), respectively. pseudo-likelihood estimator. The resulting approximative algorithm has a linear time complexity in the label set cardinality and contains only a single hyper-parameter, namely, the number of passes taken over the training data set. We evaluated the algorithm in POS tagging on five languages. Despite its heuristic nature, the algorithm provided competetive accuracies and running times against reference methods. Acknowledgements This work was financially supported by Langnet (Finnish doctoral programme in language studies) and the Academy of Finlan</context>
</contexts>
<marker>Crammer, Dekel, Keshet, Shalev-Shwartz, Singer, 2006</marker>
<rawString>Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-Shwartz, and Yoram Singer. 2006. Online passive-aggressive algorithms. The Journal of Machine Learning Research, 7:551–585.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomaž Erjavec</author>
</authors>
<title>Multext-east version 4: Multilingual morphosyntactic specifications, lexicons and corpora.</title>
<date>2010</date>
<booktitle>In Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC’10).</booktitle>
<contexts>
<context position="1502" citStr="Erjavec, 2010" startWordPosition="209" endWordPosition="210">. We present experiments on five languages. Despite its heuristic nature, the algorithm provides surprisingly competetive accuracies and running times against reference methods. 1 Introduction The conditional random field (CRF) model (Lafferty et al., 2001) has been successfully applied to several sequence labeling tasks in natural language processing, including part-of-speech (POS) tagging. In this work, we discuss accelerating the CRF model estimation in presence of a large number of labels, say, hundreds or thousands. Large label sets occur in POS tagging of morphologically rich languages (Erjavec, 2010; Haverinen et al., 2013). CRF training is most commonly associated with the (conditional) maximum likelihood (ML) criterion employed in the original work of Lafferty et al. (2001). In this work, we focus on an alternative training approach using the averaged perceptron algorithm of Collins (2002). While yielding competitive accuracy (Collins, 2002; Zhang and Clark, 2011), the perceptron algorithm avoids extensive tuning of hyper-parameters and regularization required by the stochastic gradient descent algorithm employed in ML estimation (Vishwanathan et al., 2006). Additionally, while ML and </context>
<context position="9353" citStr="Erjavec, 2010" startWordPosition="1512" endWordPosition="1513">hari et al. (2010) do not provide generalization guarantees for their algorithm. 3 Experimental Setup 3.1 Data For a quick overview of the data sets, see Table 1. Penn Treebank. The first data set we consider is the classic Penn Treebank. The complete treebank is divided into 25 sections of newswire text extracted from the Wall Street Journal. We split the data into training, development, and test sets using the sections 0-18, 19-21, and 22-24, according to the standardly applied division introduced by Collins (2002). Multext-East. The second data we consider is the multilingual Multext-East (Erjavec, 2010) corpus. The corpus contains the novel 1984 by George Orwell. From the available seven languages, we utilize the Czech, Estonian and Romanian sections. Since the data does not have a standard division to training and test sets, we assign the 9th and 10th from each 10 consecutive sentences to the development and test sets, respectively. The remaining sentences are assigned to the training sets. Turku Dependency Treebank. The third data we consider is the Finnish Turku Dependency Treebank (Haverinen et al., 2013). The treebank contains text from 10 different domains. We use the same data split s</context>
</contexts>
<marker>Erjavec, 2010</marker>
<rawString>Tomaž Erjavec. 2010. Multext-east version 4: Multilingual morphosyntactic specifications, lexicons and corpora. In Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC’10).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Basilis Gidas</author>
</authors>
<title>Consistency of maximum likelihood and pseudo-likelihood estimators for Gibbs distributions. In Stochastic differential systems, stochastic control theory and applications,</title>
<date>1988</date>
<pages>129--145</pages>
<contexts>
<context position="8202" citStr="Gidas, 1988" startWordPosition="1330" endWordPosition="1331">er the ”greedy” 1-best beam search variant most relevant as it shares the time complexity of the pseudo search. Therefore, in the experimental section of this work, we compare the PP and 1-best beam search. We are aware of at least two other learning approaches inspired by PL, namely, the pseudo-max and piecewise algorithms of Sontag et al. (2010) and Alahari et al. (2010), respectively. Compared to these approaches, the PP algorithm provides a simpler estimation tool as it avoids the 1We leave formal treatment to future work. 2Meanwhile, note that pseudo-likelihood is a consistent estimator (Gidas, 1988; Hyvärinen, 2006). |x| = H i=n 75 hyper-parameters involved in the stochastic gradient descent algorithms as well as the regularization and margin functions inherent to the approaches of Alahari et al. (2010) and Sontag et al. (2010). On the other hand, Sontag et al. (2010) show that the pseudo-max approach achieves consistency given certain assumptions on the data generating function. Meanwhile, as discussed in previous section, we consider PP a heuristic and do not provide any generalization guarantees. To our understanding, Alahari et al. (2010) do not provide generalization guarantees for</context>
</contexts>
<marker>Gidas, 1988</marker>
<rawString>Basilis Gidas. 1988. Consistency of maximum likelihood and pseudo-likelihood estimators for Gibbs distributions. In Stochastic differential systems, stochastic control theory and applications, pages 129–145.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katri Haverinen</author>
<author>Jenna Nyblom</author>
</authors>
<title>Timo Viljanen, Veronika Laippala, Samuel Kohonen,</title>
<date>2013</date>
<location>Anna Missilä, Stina Ojala, Tapio</location>
<marker>Haverinen, Nyblom, 2013</marker>
<rawString>Katri Haverinen, Jenna Nyblom, Timo Viljanen, Veronika Laippala, Samuel Kohonen, Anna Missilä, Stina Ojala, Tapio Salakoski, and Filip Ginter. 2013. Building the essential resources for Finnish: the Turku Dependency Treebank. Language Resources and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Suphan Fayong</author>
<author>Yang Guo</author>
</authors>
<title>Structured perceptron with inexact search.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>142--151</pages>
<contexts>
<context position="2504" citStr="Huang et al., 2012" startWordPosition="360" endWordPosition="363">ceptron algorithm avoids extensive tuning of hyper-parameters and regularization required by the stochastic gradient descent algorithm employed in ML estimation (Vishwanathan et al., 2006). Additionally, while ML and perceptron training share an identical time complexity, the perceptron is in practice faster due to sparser parameter updates. Despite its simplicity, running the perceptron algorithm can be tedious in case the data contains a large number of labels. Previously, this problem has been addressed using, for example, k-best beam search (Collins and Roark, 2004; Zhang and Clark, 2011; Huang et al., 2012) and parallelization (McDonald et al., 2010). In this work, we explore an alternative strategy, in which we modify the perceptron algorithm in spirit of the classic pseudo-likelihood approximation for ML estimation (Besag, 1975). The resulting novel algorithm has linear complexity w.r.t. the label set size and contains only a single hyper-parameter, namely, the number of passes taken over the training data set. We evaluate the algorithm, referred to as the pseudo-perceptron, empirically in POS tagging on five languages. The results suggest that the approach can yield competitive accuracy compa</context>
<context position="7574" citStr="Huang et al., 2012" startWordPosition="1224" endWordPosition="1227"> the CRF model order. The PW-PP approach is motivated by the results of Sutton and McCallum (2009) who found PWPL to increase stability w.r.t. accuracy compared to plain PL across tasks. Note that the piecewise approximation in itself is not interesting in chainstructured CRFs, as it results in same time complexity as standard estimation. Meanwhile, the PW-PP algorithm has same time complexity as PP. 2.2 Related work Previously, impractical running times of perceptron learning have been addressed most notably using the k-best beam search method (Collins and Roark, 2004; Zhang and Clark, 2011; Huang et al., 2012). Here, we consider the ”greedy” 1-best beam search variant most relevant as it shares the time complexity of the pseudo search. Therefore, in the experimental section of this work, we compare the PP and 1-best beam search. We are aware of at least two other learning approaches inspired by PL, namely, the pseudo-max and piecewise algorithms of Sontag et al. (2010) and Alahari et al. (2010), respectively. Compared to these approaches, the PP algorithm provides a simpler estimation tool as it avoids the 1We leave formal treatment to future work. 2Meanwhile, note that pseudo-likelihood is a consi</context>
<context position="10162" citStr="Huang et al., 2012" startWordPosition="1644" endWordPosition="1647">d division to training and test sets, we assign the 9th and 10th from each 10 consecutive sentences to the development and test sets, respectively. The remaining sentences are assigned to the training sets. Turku Dependency Treebank. The third data we consider is the Finnish Turku Dependency Treebank (Haverinen et al., 2013). The treebank contains text from 10 different domains. We use the same data split strategy as for Multext East. 3.2 Reference Methods We compare the PP and PW-PP algorithms with perceptron learning accelerated using 1-best beam search modified using the early update rule (Huang et al., 2012). While Huang et al. (2012) experimented with several violation-fixing methods (early, latest, maximum, hybrid), they appeared to reach termination at the same rate in lang. train. dev. test tags train. tags eng 38,219 5,527 5,462 45 45 rom 5,216 652 652 405 391 est 5,183 648 647 413 408 cze 5,402 675 675 955 908 fin 5,043 630 630 2,355 2,141 Table 1: Overview on data. The training (train.), development (dev.) and test set sizes are given in sentences. The columns titled tags and train. tags correspond to total number of tags in the data set and number of tags in the training set, respectively</context>
</contexts>
<marker>Huang, Fayong, Guo, 2012</marker>
<rawString>Liang Huang, Suphan Fayong, and Yang Guo. 2012. Structured perceptron with inexact search. In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 142–151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aapo Hyvärinen</author>
</authors>
<title>Consistency of pseudolikelihood estimation of fully visible Boltzmann machines.</title>
<date>2006</date>
<journal>Neural Computation,</journal>
<volume>18</volume>
<issue>10</issue>
<contexts>
<context position="8220" citStr="Hyvärinen, 2006" startWordPosition="1332" endWordPosition="1333">y” 1-best beam search variant most relevant as it shares the time complexity of the pseudo search. Therefore, in the experimental section of this work, we compare the PP and 1-best beam search. We are aware of at least two other learning approaches inspired by PL, namely, the pseudo-max and piecewise algorithms of Sontag et al. (2010) and Alahari et al. (2010), respectively. Compared to these approaches, the PP algorithm provides a simpler estimation tool as it avoids the 1We leave formal treatment to future work. 2Meanwhile, note that pseudo-likelihood is a consistent estimator (Gidas, 1988; Hyvärinen, 2006). |x| = H i=n 75 hyper-parameters involved in the stochastic gradient descent algorithms as well as the regularization and margin functions inherent to the approaches of Alahari et al. (2010) and Sontag et al. (2010). On the other hand, Sontag et al. (2010) show that the pseudo-max approach achieves consistency given certain assumptions on the data generating function. Meanwhile, as discussed in previous section, we consider PP a heuristic and do not provide any generalization guarantees. To our understanding, Alahari et al. (2010) do not provide generalization guarantees for their algorithm. </context>
</contexts>
<marker>Hyvärinen, 2006</marker>
<rawString>Aapo Hyvärinen. 2006. Consistency of pseudolikelihood estimation of fully visible Boltzmann machines. Neural Computation, 18(10):2283–2292.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Filip Korˇc</author>
<author>Wolfgang Förstner</author>
</authors>
<title>Approximate parameter learning in conditional random fields: An empirical investigation. Pattern Recognition,</title>
<date>2008</date>
<pages>11--20</pages>
<marker>Korˇc, Förstner, 2008</marker>
<rawString>Filip Korˇc and Wolfgang Förstner. 2008. Approximate parameter learning in conditional random fields: An empirical investigation. Pattern Recognition, pages 11–20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of the Eighteenth International Conference on Machine Learning,</booktitle>
<pages>282--289</pages>
<contexts>
<context position="1146" citStr="Lafferty et al., 2001" startWordPosition="151" endWordPosition="155">ceptron algorithm in spirit of pseudo-likelihood for maximum likelihood estimation. The resulting approximative algorithm has a linear time complexity in the size of the label set and contains a minimal amount of tunable hyper-parameters. Consequently, the algorithm is suitable for learning CRFbased part-of-speech (POS) taggers in presence of large POS label sets. We present experiments on five languages. Despite its heuristic nature, the algorithm provides surprisingly competetive accuracies and running times against reference methods. 1 Introduction The conditional random field (CRF) model (Lafferty et al., 2001) has been successfully applied to several sequence labeling tasks in natural language processing, including part-of-speech (POS) tagging. In this work, we discuss accelerating the CRF model estimation in presence of a large number of labels, say, hundreds or thousands. Large label sets occur in POS tagging of morphologically rich languages (Erjavec, 2010; Haverinen et al., 2013). CRF training is most commonly associated with the (conditional) maximum likelihood (ML) criterion employed in the original work of Lafferty et al. (2001). In this work, we focus on an alternative training approach usi</context>
<context position="4373" citStr="Lafferty et al., 2001" startWordPosition="672" endWordPosition="675"> Association for Computational Linguistics, pages 74–78, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics y = (y1, y2, ... , y|x|), respectively, is written as ( ) p (y |x; w) ∝ exp w · Φ(y, x) ( ) exp w · φ(yi−n, . . . , yi, x, i) , (1) where w denotes the model parameter vector, Φ the vector-valued global feature extracting function, φ the vector-valued local feature extracting function, and n the model order. We denote the tag set as Y. The model parameters w are estimated based on training data, and test instances are decoded using the Viterbi search (Lafferty et al., 2001). Given the model definition (1), the parameters w can be estimated in a straightforward manner using the structured perceptron algorithm (Collins, 2002). The algorithm iterates over the training set a single instance (x, y) at a time and updates the parameters according to the rule w(i) = w(i−1) + ΔΦ(x, y, z), where ΔΦ(x, y, z) for the ith iteration is written as ΔΦ(x, y, z) = Φ(x, y) − Φ(x, z). The prediction z is obtained as z = arg max w · Φ(x, u) (2) u∈Y(x) by performing the Viterbi search over Y(x) = Y × ··· × Y, a product of |x |copies of Y. In case the perceptron algorithm yields a sma</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the Eighteenth International Conference on Machine Learning, pages 282–289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Keith Hall</author>
<author>Gideon Mann</author>
</authors>
<title>Distributed training strategies for the structured perceptron.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>456--464</pages>
<contexts>
<context position="2548" citStr="McDonald et al., 2010" startWordPosition="367" endWordPosition="370"> of hyper-parameters and regularization required by the stochastic gradient descent algorithm employed in ML estimation (Vishwanathan et al., 2006). Additionally, while ML and perceptron training share an identical time complexity, the perceptron is in practice faster due to sparser parameter updates. Despite its simplicity, running the perceptron algorithm can be tedious in case the data contains a large number of labels. Previously, this problem has been addressed using, for example, k-best beam search (Collins and Roark, 2004; Zhang and Clark, 2011; Huang et al., 2012) and parallelization (McDonald et al., 2010). In this work, we explore an alternative strategy, in which we modify the perceptron algorithm in spirit of the classic pseudo-likelihood approximation for ML estimation (Besag, 1975). The resulting novel algorithm has linear complexity w.r.t. the label set size and contains only a single hyper-parameter, namely, the number of passes taken over the training data set. We evaluate the algorithm, referred to as the pseudo-perceptron, empirically in POS tagging on five languages. The results suggest that the approach can yield competitive accuracy compared to perceptron training accelerated using</context>
</contexts>
<marker>McDonald, Hall, Mann, 2010</marker>
<rawString>Ryan McDonald, Keith Hall, and Gideon Mann. 2010. Distributed training strategies for the structured perceptron. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 456–464.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Avihai Mejer</author>
<author>Koby Crammer</author>
</authors>
<title>Confidence in structured-prediction using confidence-weighted models.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 conference on empirical methods in natural language processing,</booktitle>
<pages>971--981</pages>
<contexts>
<context position="11304" citStr="Mejer and Crammer, 2010" startWordPosition="1830" endWordPosition="1833">mber of tags in the data set and number of tags in the training set, respectively. POS tagging. Our preliminary experiments using the latest violation updates supported this. Consequently, we employ the early updates. We also provide results using the CRFsuite toolkit (Okazaki, 2007), which implements a 1storder CRF model. To best of our knowledge, CRFsuite is currently the fastest freely available CRF implementation.3 In addition to the averaged perceptron algorithm (Collins, 2002), the toolkit implements several training procedures (Nocedal, 1980; Crammer et al., 2006; Andrew and Gao, 2007; Mejer and Crammer, 2010; Shalev-Shwartz et al., 2011). We run CRFsuite using these algorithms employing their default parameters and the feature extraction scheme and stopping criterion described in Section 3.3. We then report results provided by the most accurate algorithm on each language. 3.3 Details on CRF Training and Decoding While the methods discussed in this work are applicable for nth-order CRFs, we employ 1st-order CRFs in order to avoid overfitting the relatively small training sets. We employ a simple feature set including word forms at position t − 2, ... , t + 2, suffixes of word at position t up to f</context>
</contexts>
<marker>Mejer, Crammer, 2010</marker>
<rawString>Avihai Mejer and Koby Crammer. 2010. Confidence in structured-prediction using confidence-weighted models. In Proceedings of the 2010 conference on empirical methods in natural language processing, pages 971–981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jorge Nocedal</author>
</authors>
<title>Updating quasi-Newton matrices with limited storage.</title>
<date>1980</date>
<journal>Mathematics of computation,</journal>
<pages>35--151</pages>
<contexts>
<context position="11235" citStr="Nocedal, 1980" startWordPosition="1820" endWordPosition="1821"> columns titled tags and train. tags correspond to total number of tags in the data set and number of tags in the training set, respectively. POS tagging. Our preliminary experiments using the latest violation updates supported this. Consequently, we employ the early updates. We also provide results using the CRFsuite toolkit (Okazaki, 2007), which implements a 1storder CRF model. To best of our knowledge, CRFsuite is currently the fastest freely available CRF implementation.3 In addition to the averaged perceptron algorithm (Collins, 2002), the toolkit implements several training procedures (Nocedal, 1980; Crammer et al., 2006; Andrew and Gao, 2007; Mejer and Crammer, 2010; Shalev-Shwartz et al., 2011). We run CRFsuite using these algorithms employing their default parameters and the feature extraction scheme and stopping criterion described in Section 3.3. We then report results provided by the most accurate algorithm on each language. 3.3 Details on CRF Training and Decoding While the methods discussed in this work are applicable for nth-order CRFs, we employ 1st-order CRFs in order to avoid overfitting the relatively small training sets. We employ a simple feature set including word forms a</context>
</contexts>
<marker>Nocedal, 1980</marker>
<rawString>Jorge Nocedal. 1980. Updating quasi-Newton matrices with limited storage. Mathematics of computation, 35(151):773–782.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Naoaki Okazaki</author>
</authors>
<title>CRFsuite: a fast implementation of conditional random fields (CRFs).</title>
<date>2007</date>
<note>URL http://www.chokkan.org/software/crfsuite.</note>
<contexts>
<context position="10965" citStr="Okazaki, 2007" startWordPosition="1782" endWordPosition="1783">t tags train. tags eng 38,219 5,527 5,462 45 45 rom 5,216 652 652 405 391 est 5,183 648 647 413 408 cze 5,402 675 675 955 908 fin 5,043 630 630 2,355 2,141 Table 1: Overview on data. The training (train.), development (dev.) and test set sizes are given in sentences. The columns titled tags and train. tags correspond to total number of tags in the data set and number of tags in the training set, respectively. POS tagging. Our preliminary experiments using the latest violation updates supported this. Consequently, we employ the early updates. We also provide results using the CRFsuite toolkit (Okazaki, 2007), which implements a 1storder CRF model. To best of our knowledge, CRFsuite is currently the fastest freely available CRF implementation.3 In addition to the averaged perceptron algorithm (Collins, 2002), the toolkit implements several training procedures (Nocedal, 1980; Crammer et al., 2006; Andrew and Gao, 2007; Mejer and Crammer, 2010; Shalev-Shwartz et al., 2011). We run CRFsuite using these algorithms employing their default parameters and the feature extraction scheme and stopping criterion described in Section 3.3. We then report results provided by the most accurate algorithm on each l</context>
</contexts>
<marker>Okazaki, 2007</marker>
<rawString>Naoaki Okazaki. 2007. CRFsuite: a fast implementation of conditional random fields (CRFs). URL http://www.chokkan.org/software/crfsuite.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait Ratnaparkhi</author>
</authors>
<title>A maximum entropy model for part-of-speech tagging.</title>
<date>1996</date>
<booktitle>In Proceedings of the conference on empirical methods in natural language processing,</booktitle>
<volume>1</volume>
<pages>133--142</pages>
<contexts>
<context position="12808" citStr="Ratnaparkhi (1996)" startWordPosition="2072" endWordPosition="2073"> they appear in the corpus. At the end of each pass, we apply the CRFs using the latest averaged parameters (Collins, 2002) to the development set. We assume the algorithms have converged when the model accuracy on development 3See benchmark results at http://www.chokkan. org/software/crfsuite/benchmark.html 76 has not increased during last three iterations. After termination, we apply the averaged parameters yielding highest performance on the development set to test instances. Test and development instances are decoded using a combination of Viterbi search and the tag dictionary approach of Ratnaparkhi (1996). In this approach, candidate tags for known word forms are limited to those observed in the training data. Meanwhile, word forms that were unseen during training consider the full label set. 3.4 Software and Hardware The experiments are run on a standard desktop computer. We use our own C++-based implementation of the methods discussed in Section 2. 4 Results The obtained training times and test set accuracies (measured using accuracy and out-of-vocabulary (OOV) accuracy) are presented in Table 2. The training CPU times include the time (in minutes) consumed by running the perceptron algorith</context>
</contexts>
<marker>Ratnaparkhi, 1996</marker>
<rawString>Adwait Ratnaparkhi. 1996. A maximum entropy model for part-of-speech tagging. In Proceedings of the conference on empirical methods in natural language processing, volume 1, pages 133–142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shai Shalev-Shwartz</author>
<author>Yoram Singer</author>
<author>Nathan Srebro</author>
<author>Andrew Cotter</author>
</authors>
<title>Pegasos: Primal estimated sub-gradient solver for SVM.</title>
<date>2011</date>
<booktitle>Mathematical Programming,</booktitle>
<volume>127</volume>
<issue>1</issue>
<contexts>
<context position="11334" citStr="Shalev-Shwartz et al., 2011" startWordPosition="1834" endWordPosition="1837">set and number of tags in the training set, respectively. POS tagging. Our preliminary experiments using the latest violation updates supported this. Consequently, we employ the early updates. We also provide results using the CRFsuite toolkit (Okazaki, 2007), which implements a 1storder CRF model. To best of our knowledge, CRFsuite is currently the fastest freely available CRF implementation.3 In addition to the averaged perceptron algorithm (Collins, 2002), the toolkit implements several training procedures (Nocedal, 1980; Crammer et al., 2006; Andrew and Gao, 2007; Mejer and Crammer, 2010; Shalev-Shwartz et al., 2011). We run CRFsuite using these algorithms employing their default parameters and the feature extraction scheme and stopping criterion described in Section 3.3. We then report results provided by the most accurate algorithm on each language. 3.3 Details on CRF Training and Decoding While the methods discussed in this work are applicable for nth-order CRFs, we employ 1st-order CRFs in order to avoid overfitting the relatively small training sets. We employ a simple feature set including word forms at position t − 2, ... , t + 2, suffixes of word at position t up to four letters, and three orthogr</context>
</contexts>
<marker>Shalev-Shwartz, Singer, Srebro, Cotter, 2011</marker>
<rawString>Shai Shalev-Shwartz, Yoram Singer, Nathan Srebro, and Andrew Cotter. 2011. Pegasos: Primal estimated sub-gradient solver for SVM. Mathematical Programming, 127(1):3–30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Sontag</author>
<author>Ofer Meshi</author>
<author>Tommi Jaakkola</author>
<author>Amir Globerson</author>
</authors>
<title>More data means less inference: A pseudo-max approach to structured learning.</title>
<date>2010</date>
<booktitle>In Advances in Neural Information Processing Systems 23,</booktitle>
<pages>2181--2189</pages>
<contexts>
<context position="7940" citStr="Sontag et al. (2010)" startWordPosition="1287" endWordPosition="1290">orithm has same time complexity as PP. 2.2 Related work Previously, impractical running times of perceptron learning have been addressed most notably using the k-best beam search method (Collins and Roark, 2004; Zhang and Clark, 2011; Huang et al., 2012). Here, we consider the ”greedy” 1-best beam search variant most relevant as it shares the time complexity of the pseudo search. Therefore, in the experimental section of this work, we compare the PP and 1-best beam search. We are aware of at least two other learning approaches inspired by PL, namely, the pseudo-max and piecewise algorithms of Sontag et al. (2010) and Alahari et al. (2010), respectively. Compared to these approaches, the PP algorithm provides a simpler estimation tool as it avoids the 1We leave formal treatment to future work. 2Meanwhile, note that pseudo-likelihood is a consistent estimator (Gidas, 1988; Hyvärinen, 2006). |x| = H i=n 75 hyper-parameters involved in the stochastic gradient descent algorithms as well as the regularization and margin functions inherent to the approaches of Alahari et al. (2010) and Sontag et al. (2010). On the other hand, Sontag et al. (2010) show that the pseudo-max approach achieves consistency given c</context>
</contexts>
<marker>Sontag, Meshi, Jaakkola, Globerson, 2010</marker>
<rawString>David Sontag, Ofer Meshi, Tommi Jaakkola, and Amir Globerson. 2010. More data means less inference: A pseudo-max approach to structured learning. In Advances in Neural Information Processing Systems 23, pages 2181–2189.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Sutton</author>
<author>Andrew McCallum</author>
</authors>
<title>Piecewise training for structured prediction.</title>
<date>2009</date>
<booktitle>Machine learning,</booktitle>
<pages>77--2</pages>
<contexts>
<context position="6382" citStr="Sutton and McCallum, 2009" startWordPosition="1039" endWordPosition="1042">1..|x |as z0 = arg max w · Φ(x, u) , (3) u∈Y,i(x) with Y0i(x) = {y1}×···×{yi−1}×Y ×{yi+1}× · · · × {y|x|}. Subsequent to training, test instances are decoded in a standard manner using the Viterbi search. The appeal of PP is that the time complexity of search is reduced to O(|x |× |Y|), i.e., linear in the number of labels in the label set. On the other hand, we no longer expect the obtained parameters to necessarily generalize well to test instances.1 Consequently, we consider PP a heuristic estimation approach motivated by the rather well-established success of PL (Korˇc and Förstner, 2008; Sutton and McCallum, 2009).2 Next, we study yet another heuristic pseudovariant of the perceptron algorithm referred to as the piecewise-pseudo-perceptron (PW-PP). This algorithm is analogous to the piecewise-pseudolikelihood (PW-PL) approximation presented by Sutton and McCallum (2009). In this variant, the original graph is first split into smaller, possibly overlapping subgraphs (pieces). Subsequently, we apply the PP approximation to the pieces. We employ the approach coined factor-as-piece by Sutton and McCallum (2009), in which each piece contains n + 1 consecutive variables, where n is the CRF model order. The P</context>
</contexts>
<marker>Sutton, McCallum, 2009</marker>
<rawString>Charles Sutton and Andrew McCallum. 2009. Piecewise training for structured prediction. Machine learning, 77(2):165–194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S V N Vishwanathan</author>
<author>Nicol Schraudolph</author>
<author>Mark Schmidt</author>
<author>Kevin Murphy</author>
</authors>
<title>Accelerated training of conditional random fields with stochastic gradient methods.</title>
<date>2006</date>
<booktitle>In Proceedings of the 23rd international conference on Machine learning,</booktitle>
<pages>969--976</pages>
<contexts>
<context position="2073" citStr="Vishwanathan et al., 2006" startWordPosition="291" endWordPosition="294">agging of morphologically rich languages (Erjavec, 2010; Haverinen et al., 2013). CRF training is most commonly associated with the (conditional) maximum likelihood (ML) criterion employed in the original work of Lafferty et al. (2001). In this work, we focus on an alternative training approach using the averaged perceptron algorithm of Collins (2002). While yielding competitive accuracy (Collins, 2002; Zhang and Clark, 2011), the perceptron algorithm avoids extensive tuning of hyper-parameters and regularization required by the stochastic gradient descent algorithm employed in ML estimation (Vishwanathan et al., 2006). Additionally, while ML and perceptron training share an identical time complexity, the perceptron is in practice faster due to sparser parameter updates. Despite its simplicity, running the perceptron algorithm can be tedious in case the data contains a large number of labels. Previously, this problem has been addressed using, for example, k-best beam search (Collins and Roark, 2004; Zhang and Clark, 2011; Huang et al., 2012) and parallelization (McDonald et al., 2010). In this work, we explore an alternative strategy, in which we modify the perceptron algorithm in spirit of the classic pseu</context>
</contexts>
<marker>Vishwanathan, Schraudolph, Schmidt, Murphy, 2006</marker>
<rawString>S.V.N. Vishwanathan, Nicol Schraudolph, Mark Schmidt, and Kevin Murphy. 2006. Accelerated training of conditional random fields with stochastic gradient methods. In Proceedings of the 23rd international conference on Machine learning, pages 969–976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Stephen Clark</author>
</authors>
<title>Syntactic processing using the generalized perceptron and beam search.</title>
<date>2011</date>
<journal>Computational Linguistics,</journal>
<volume>37</volume>
<issue>1</issue>
<contexts>
<context position="1876" citStr="Zhang and Clark, 2011" startWordPosition="264" endWordPosition="267">part-of-speech (POS) tagging. In this work, we discuss accelerating the CRF model estimation in presence of a large number of labels, say, hundreds or thousands. Large label sets occur in POS tagging of morphologically rich languages (Erjavec, 2010; Haverinen et al., 2013). CRF training is most commonly associated with the (conditional) maximum likelihood (ML) criterion employed in the original work of Lafferty et al. (2001). In this work, we focus on an alternative training approach using the averaged perceptron algorithm of Collins (2002). While yielding competitive accuracy (Collins, 2002; Zhang and Clark, 2011), the perceptron algorithm avoids extensive tuning of hyper-parameters and regularization required by the stochastic gradient descent algorithm employed in ML estimation (Vishwanathan et al., 2006). Additionally, while ML and perceptron training share an identical time complexity, the perceptron is in practice faster due to sparser parameter updates. Despite its simplicity, running the perceptron algorithm can be tedious in case the data contains a large number of labels. Previously, this problem has been addressed using, for example, k-best beam search (Collins and Roark, 2004; Zhang and Clar</context>
<context position="7553" citStr="Zhang and Clark, 2011" startWordPosition="1220" endWordPosition="1223">e variables, where n is the CRF model order. The PW-PP approach is motivated by the results of Sutton and McCallum (2009) who found PWPL to increase stability w.r.t. accuracy compared to plain PL across tasks. Note that the piecewise approximation in itself is not interesting in chainstructured CRFs, as it results in same time complexity as standard estimation. Meanwhile, the PW-PP algorithm has same time complexity as PP. 2.2 Related work Previously, impractical running times of perceptron learning have been addressed most notably using the k-best beam search method (Collins and Roark, 2004; Zhang and Clark, 2011; Huang et al., 2012). Here, we consider the ”greedy” 1-best beam search variant most relevant as it shares the time complexity of the pseudo search. Therefore, in the experimental section of this work, we compare the PP and 1-best beam search. We are aware of at least two other learning approaches inspired by PL, namely, the pseudo-max and piecewise algorithms of Sontag et al. (2010) and Alahari et al. (2010), respectively. Compared to these approaches, the PP algorithm provides a simpler estimation tool as it avoids the 1We leave formal treatment to future work. 2Meanwhile, note that pseudo-</context>
</contexts>
<marker>Zhang, Clark, 2011</marker>
<rawString>Yue Zhang and Stephen Clark. 2011. Syntactic processing using the generalized perceptron and beam search. Computational Linguistics, 37(1):105–151.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>