<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000069">
<note confidence="0.713453">
Proceedings of EACL &apos;99
</note>
<title confidence="0.997612">
New Models for Improving Supertag Disambiguation
</title>
<author confidence="0.999628">
John Chen*
</author>
<affiliation confidence="0.995171666666667">
Department of Computer
and Information Sciences
University of Delaware
</affiliation>
<address confidence="0.879972">
Newark, DE 19716
</address>
<email confidence="0.997616">
jchen@cis.udel.edu
</email>
<author confidence="0.933644">
Srinivas Bangalore
</author>
<affiliation confidence="0.95868">
AT&amp;T Labs Research
</affiliation>
<address confidence="0.975305666666667">
180 Park Avenue
P.O. Box 971
Florham Park, NJ 07932
</address>
<email confidence="0.99777">
srini@research.att.com
</email>
<author confidence="0.987585">
K. Vijay-Shanker
</author>
<affiliation confidence="0.995011">
Department of Computer
and Information Sciences
University of Delaware
</affiliation>
<address confidence="0.880292">
Newark, DE 19716
</address>
<email confidence="0.9987">
vijay@cis.udel.edu
</email>
<sectionHeader confidence="0.995638" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999689">
In previous work, supertag disambigua-
tion has been presented as a robust par-
tial parsing technique. In this paper
we present two approaches: contextual
models, which exploit a variety of fea-
tures in order to improve supertag per-
formance, and class-based models, which
assign sets of supertags to words in order
to substantially improve accuracy with
only a slight increase in ambiguity.
</bodyText>
<sectionHeader confidence="0.998801" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9993032">
Many natural language applications are beginning
to exploit some underlying structure of the lan-
guage. Roukos (1996) and Jurafsky et al. (1995)
use structure-based language models in the
context of speech applications. Grishman (1995)
and Hobbs et al. (1995) use phrasal information
in information extraction. Alshawi (1996) uses
dependency information in a machine translation
system. The need to impose structure leads to
the need to have robust parsers. There have
been two main robust parsing paradigms: Fi-
nite State Grammar-based approaches (such
as Abney (1990), Grishman (1995), and
Hobbs et al. (1997)) and Statistical Parsing
(such as Charniak (1996), Magerman (1995), and
Collins (1996)).
Srinivas (1997a) has presented a different ap-
proach called supertagging that integrates linguis-
tically motivated lexical descriptions with the ro-
bustness of statistical techniques. The idea un-
derlying the approach is that the computation
of linguistic structure can be localized if lexical
items are associated with rich descriptions (Su-
pertags) that impose complex constraints in a lo-
cal context. Supertag disambiguation is resolved
</bodyText>
<listItem confidence="0.499452">
• Supported by NSF grants #SBR-9710411 and
</listItem>
<page confidence="0.96201">
#GER-9354869
</page>
<bodyText confidence="0.999593452380952">
by using statistical distributions of supertag co-
occurrences collected from a corpus of parses. It
results in a representation that is effectively a
parse (almost parse).
Supertagging has been found useful for a num-
ber of applications. For instance, it can be
used to speed up conventional chart parsers be-
cause it reduces the ambiguity which a parser
must face, as described in Srinivas (19974
Chandrasekhar and Srinivas (1997) has shown
that supertagging may be employed in informa-
tion retrieval. Furthermore, given a sentence
aligned parallel corpus of two languages and al-
most parse information for the sentences of one
of the languages, one can rapidly develop a gram-
mar for the other language using supertagging, as
suggested by Bangalore (1998).
In contrast to the aforementioned work in su-
pertag disambiguation, where the objective was
to provide a direct comparison between trigram
models for part-of-speech tagging and supertag-
ging, in this paper our goal is to improve the per-
formance of supertagging using local techniques
which avoid full parsing. These supertag disam-
biguation models can be grouped into contextual
models and class based models. Contextual mod-
els use different features in frameworks that ex-
ploit the information those features provide in
order to achieve higher accuracies in supertag-
ging. For class based models, supertags are first
grouped into clusters and words are tagged with
clusters of supertags. We develop several auto-
mated clustering techniques. We then demon-
strate that with a slight increase in supertag ambi-
guity that supertagging accuracy can be substan-
tially improved.
The layout of the paper is as follows. In Sec-
tion 2, we briefly review the task of supertagging
and the results from previous work. In Section 3,
we explore contextual models. In Section 4, we
outline various class based approaches. Ideas for
future work are presented in Section 5. Lastly, we
</bodyText>
<page confidence="0.995615">
188
</page>
<bodyText confidence="0.7580405">
Proceedings of EACL &apos;99
present our conclusions in Section 6.
</bodyText>
<sectionHeader confidence="0.857195" genericHeader="introduction">
2 Supertagging
</sectionHeader>
<bodyText confidence="0.999966428571429">
Supertags, the primary elements of the LTAG
formalism, attempt to localize dependencies, in-
cluding long distance dependencies. This is ac-
complished by grouping syntactically or semanti-
cally dependent elements to be within the same
structure. Thus, as seen in Figure 1, supertags
contain more information than standard part-of-
speech tags, and there are many more supertags
per word than part-of-speech tags. In fact, su-
pertag disambiguation may be characterized as
providing an almost parse, as shown in the bottom
part of Figure 1.
Local statistical information, in the form of a
trigram model based on the distribution of su-
pertags in an LTAG parsed corpus, can be used
to choose the most appropriate supertag for any
given word. Joshi and Srinivas (1994) define su-
pertagging as the process of assigning the best
supertag to each word. Srinivas (1997b) and
Srinivas (1997a) have tested the performance of a
trigram model, typically used for part-of-speech
tagging on supertagging, on restricted domains
such as ATIS and less restricted domains such as
Wall Street Journal (WSJ).
In this work, we explore a variety of local
techniques in order to improve the performance
of supertagging. All of the models presented
here perform smoothing using a Good-Turing dis-
counting technique with Katz&apos;s backoff model.
With exceptions where noted, our models were
trained on one million words of Wall Street Jour-
nal data and tested on 48K words. The data
and evaluation procedure are similar to that used
in Srinivas (1997b). The data was derived by
mapping structural information from the Penn
Treebank WSJ corpus into supertags from the
XTAG grammar (The XTAG-Group (1995)) us-
ing heuristics (Srinivas (1997a)). Using this data,
the trigram model for supertagging achieves an
accuracy of 91.37%, meaning that 91.37% of the
words in the test corpus were assigned the correct
supertag.&apos;
</bodyText>
<sectionHeader confidence="0.997857" genericHeader="method">
3 Contextual Models
</sectionHeader>
<bodyText confidence="0.986911">
As noted in Srinivas (1997b), a trigram model of-
ten fails to capture the cooccurrence dependencies
&apos;The supertagging accuracy of 92.2% reported
in Srinivas (1997b) was based on a different supertag
tagset; specifically, the supertag corpus was reanno-
tated with detailed supertags for punctuation and
with a different analysis for subordinating conjunc-
tions.
between a head and its dependents—dependents
which might not appear within a trigram&apos;s window
size. For example, in the sentence &amp;quot;Many Indians
feared their country might split again&amp;quot; the pres-
ence of might influences the choice of the supertag
for feared, an influence that is not accounted for by
the trigram model. As described below, we show
that the introduction of features which take into
account aspects of head-dependency relationships
improves the accuracy of supertagging.
</bodyText>
<subsectionHeader confidence="0.998">
3.1 One Pass Head Trigram Model
</subsectionHeader>
<bodyText confidence="0.999592">
In a head model, the prediction of the current su-
pertag is conditioned not on the immediately pre-
ceding two supertags, but on the supertags for the
two previous head words. This model may thus
be considered to be using a context of variable
length.2 The sentence &amp;quot;Many Indians feared their
country might split again&amp;quot; shows a head model&apos;s
strengths over the trigram model. There are at
least two frequently assigned supertags for the
word feared: a more frequent one corresponding
to a subcategorization of NP object (as an of
Figure 1) and a less frequent one to a S comple-
ment. The supertag for the word might, highly
probable to be modeled as an auxiliary verb in
this case, provides strong evidence for the latter.
Notice that might and feared appear within a head
model&apos;s two head window, but not within the tri-
gram model&apos;s two word window. We may there-
fore expect that a head model would make a more
accurate prediction.
Srinivas (1997b) presents a two pass head tri-
gram model. In the first pass, it tags words as
either head words or non-head words. Training
data for this pass is obtained using a head percola-
tion table (Magerman (1995)) on bracketed Penn
Treebank sentences. After training, head tagging
is performed according to Equation 1, where /3 is
the estimated probability and H (i) is a charac-
teristic function which is true if word i is a head
word.
</bodyText>
<equation confidence="0.977343">
H argmax H HioilH(05(H(i)1H(i-1)H(i-2))
(1)
</equation>
<bodyText confidence="0.99904">
The second pass then takes the words with this
head information and supertags them according
to Equation 2, where tH(z,,) is the supertag of the
</bodyText>
<footnote confidence="0.8022924">
2Part of speech tagging models have not used heads
in this manner to achieve variable length contexts.
Variable length n-gram models, one of which is de-
scribed in Niesler and Woodland (1996), have been
used instead.
</footnote>
<page confidence="0.993306">
189
</page>
<figure confidence="0.560854">
Proceedings of EACL &apos;99
</figure>
<figureCaption confidence="0.994242">
Figure 1: A selection of the supertags associated with each word of the sentence: the purchase price
</figureCaption>
<figure confidence="0.979543558823529">
includes two ancillary companies
NP NIP / \ NP VP NP
NP* S price NP S /N. companies
NP VP ./^&amp;quot;. V AP CC5
VN NP VP i I
V NP /N E A
I / V NP ancillary
PUIChaSeE 1 1 aLl
al includes E
03
NP VN NP VP NP NP S
NP S I /N. NP VP
NP VP VN
VN V NP
V NP i I
I I
D N N. E N V NP D NP. A N. C N
the purchase price includes two ancillary companies
131 132 06 07 133 134 08
NiP N NP VP NP S NP VP
purchase price VN / \ V NP
N° V NP NP VP companies
includes - V AP
I
E A
ancillary
• 09 1310 l 012 al3
NP NP VP NP N NIP
V.\ /N
D NP. N N. V NP DNP&apos; A N. 71
i
the purchase price includes two ancillary companies
131 02 al 1 133 134 05
the purchase price includes two ancillary companies
</figure>
<bodyText confidence="0.767017">
jth head from word i.
</bodyText>
<equation confidence="0.588798">
T argmaxT 1113(wilti)ictiltmi,_1&gt;tmi,-2))
</equation>
<bodyText confidence="0.997236076923077">
(2)
This model achieves an accuracy of 87%, lower
than the trigram model&apos;s accuracy.
Our current approach differs significantly. In-
stead of having heads be defined through the use
of the head percolation table on the Penn Tree-
bank, we define headedness in terms of the su-
pertags themselves. The set of supertags can nat-
urally be partitioned into head and non-head su-
pertags. Head supertags correspond to those that
represent a predicate and its arguments, such as
a3 and a7. Conversely, non-head supertags corre-
spond to those supertags that represent modifiers
or adjuncts, such as )31 and /32.
Now, the tree that is assigned to a word during
supertagging determines whether or not it is to
be a head word. Thus, a simple adaptation of the
Viterbi algorithm suffices to compute Equation 2
in a single pass, yielding a one pass head trigram
model. Using the same training and test data, the
one pass head model achieved 90.75% accuracy,
constituting a 28.8% reduction in error over the
two pass head trigram model. This improvement
may come from a reduction in error propagation
or the richer context that is being used to predict
heads.
</bodyText>
<subsectionHeader confidence="0.999947">
3.2 Mixed Head and Trigram Models
</subsectionHeader>
<bodyText confidence="0.99999">
The head model skips words that it does not con-
sider to be head words and hence may lose valu-
able information. The lack of immediate local con-
text hurts the head model in many cases, such as
selection between head noun and noun modifier,
and is a reason for its lower performance relative
to the trigram model. Consider the phrase &amp;quot;... ,
or $ 2.48 a share.&amp;quot; The word 2.48 may either be
associated with a determiner phrase supertag (01)
or a noun phrase supertag (a9). Notice that 2.48
is immediately preceded by $ which is extremely
likely to be supertagged as a determiner phrase
(01). This is strong evidence that 2.48 should be
supertagged as 09. A pure head model cannot
consider this particular fact, however, because 01
is not a head supertag. Thus, local context and
long distance head dependency relationships are
both important for accurate supertagging.
A 5-gram mixed model that includes both the
trigram and the head trigram context is one ap-
proach to this problem. This model achieves a
performance of 91.50%, an improvement over both
</bodyText>
<page confidence="0.992577">
190
</page>
<table confidence="0.583936222222222">
Proceedings of EACL &apos;99
Previous Current Next
Context Supertag Context
tx(i,_,) tx(,,_1) tH(i,o) tH(_ ) tx(i,o)
tH(._2)tx(i,_1) ttavt(.0) tx(i,_,) tLm( ,o)
tx(„)tti(,_1) tRitt(,o) trio ._2) tx(i,_1)
tH(,_,) tL, m(,,_ 1) tH(,,0) tH(,_,)tx(i,o)
tH(i....ntLitit(,_,) qm(,o) tH(,)qm(.,o)
4/0_0 tt,m(i,_i) tRA/(..0) tH(._,)tRm(1,o)
</table>
<tableCaption confidence="0.599642">
Table 1: In the 3-gram mixed model, previous con-
</tableCaption>
<bodyText confidence="0.999681878787879">
ditioning context and the current supertag deter-
ministically establish the next conditioning con-
text. H, LM, and RM denote the entities head,
left modifier, and right modifier, respectively.
the trigram model and the head trigram model.
We hypothesize that the improvement is limited
because of a large increase in the number of pa-
rameters to be estimated.
As an alternative, we explore a 3-gram mixed
model that incorporates nearly all of the relevant
information. This mixed model may be described
as follows. Recall that we partition the set of
all supertags into heads and modifiers. Modifiers
have been defined so as to share the characteristic
that each one either modifies exactly one item to
the right or one item to the left. Consequently,
we further divide modifiers into left modifiers (04)
and right modifiers. Now, instead of fixing the
conditioning context to be either the two previous
tags (as in the trigram model) or the two pre-
vious head tags (as in the head trigram model)
we allow it to vary according to the identity of
the current tag and the previous conditioning con-
text, as shown in Table 1. Intuitively, the mixed
model is like the trigram model except that a mod-
ifier tag is discarded from the conditioning context
when it has found an object of modification. The
mixed model achieves an accuracy of 91.79%, a
significant improvement over both the head tri-
gram model&apos;s and the trigram model&apos;s accuracies,
p &lt; 0.05. Furthermore, this mixed model is com-
putationally more efficient as well as more accu-
rate than the 5-gram model.
</bodyText>
<subsectionHeader confidence="0.996597">
3.3 Head Word Models
</subsectionHeader>
<bodyText confidence="0.999869428571429">
Rather than head supertags, head words often
seem to be more predictive of dependency rela-
tions. Based upon this reflection, we have imple-
mented models where head words have been used
as features. The head word model predicts the cur-
rent supertag based on two previous head words
(backing off to their supertags) as shown in Equa-
</bodyText>
<table confidence="0.999345333333333">
Model Context Accuracy
Trigram t2_1t2-2 91.37
Head tH(i,_ 1 )tx(i,--2) 90.75
Trigram
5-gram 4_14-2 91.50
Mix tigi,-1)tH(i,-2)
3-gram tcntzt(i,-1)tcntxt(i,-2) 91.79
Mix
Head w(i,_ 1 ) w( i , -2) 88.16
Word
Mix t.1 t_2 89.46
Word W H(i,-1)W H(i,-2)
</table>
<tableCaption confidence="0.947294">
Table 2: Single classifier contextual models that
have been explored along with the contexts they
consider and their accuracies
</tableCaption>
<equation confidence="0.94226225">
tion 3.
T argmaxTrigwiiti)13(tiiwmi,-1)w
i.1
(3)
</equation>
<bodyText confidence="0.999884066666667">
The mixed trigram and head word model takes into
account local (supertag) context and long distance
(head word) context. Both of these models ap-
pear to suffer from severe sparse data problems.
It is not surprising, then, that the head word
model achieves an accuracy of only 88.16%, and
the mixed trigram and head word model achieves
an accuracy of 89.46%. We were only able to
train the latter model with 250K of training data
because of memory problems that were caused
by computing the large parameter space of that
model.
The salient characteristics of models that have
been discussed in this subsection are summarized
in Table 2.
</bodyText>
<subsectionHeader confidence="0.919582">
3.4 Classifier Combination
</subsectionHeader>
<bodyText confidence="0.9999654375">
While the features that our new models have con-
sidered are useful, an n-gram model that considers
all of them would run into severe sparse data prob-
lems. This difficulty may be surmounted through
the use of more elaborate backoff techniques. On
the other hand, we could consider using decision
trees at choice points in order to decide which fea-
tures are most relevant at each point. However, we
have currently experimented with classifier combi-
nation as a means of ameliorating the sparse data
problem while making use of the feature combina-
tions that we have introduced.
In this approach, a selection of the discussed
models is treated as a different classifier and is
trained on the same data. Subsequently, each clas-
sifier supertags the test corpus separately. Finally,
</bodyText>
<page confidence="0.991634">
191
</page>
<table confidence="0.995930142857143">
Proceedings of EACL &apos;99
Trigram Head Trigram Head Word 3-gram Mix Mix Word
Trigram 91.37 91.87* 91.65 91.96 91.55
Head Trigram 90.75 90.96 91.95 91.35*
Head Word 88.16 91.88 90.51*
3-gram Mix 91.79 91.87
Mix Word 89.46
</table>
<tableCaption confidence="0.999935">
Table 3: Accuracies of Single Classifiers and Pairwise Combination of Classifiers.
</tableCaption>
<bodyText confidence="0.973069754716981">
their predictions are combined using various vot-
ing strategies.
The same 1000K word test corpus is used in
models of classifier combination as is used in pre-
vious models. We created three distinct partitions
of this 1000K word corpus, each partition consist-
ing of a 900K word training corpus and a 100K
word tune corpus. In this manner, we ended up
with a total of 300K word tuning data.
We consider three voting strategies suggested
by van Halteren et al. (1998): equal vote, where
each classifier&apos;s vote is weighted equally, overall
accuracy, where the weight depends on the over-
all accuracy of a classifier, and pairwise voting.
Pairwise voting works as follows. First, for each
pair of classifiers a and b, the empirical prob-
ability pl(tcorrectitclassifier—atclassifier—b) is Com-
puted from tuning data, where t
..classif ier—a and
tclassifier..b are classifier a&apos;s and classifier b&apos;s su-
pertag assignment for a particular word respec-
tively, and tcorrect is the correct supertag. Sub-
sequently, on the test data, each classifier pair
votes, weighted by overall accuracy, for the su-
pertag with the highest empirical probability as
determined in the previous step, given each indi-
vidual classifier&apos;s guess.
The results from these voting strategies are pos-
itive. Equal vote yields an accuracy of 91.89%.
Overall accuracy vote has an accuracy of 91.93%.
Pairwise voting yields an accuracy of 92.19%,
the highest supertagging accuracy that has been
achieved, a 9.5% reduction in error over the tri-
gram model.
The table of accuracy of combinations of pairs
of classifiers is shown in Table 3.3 The effi-
cacy of pairwise combination (which has signifi-
cantly fewer parameters to estimate) in ameliorat-
ing the sparse data problem can be seen clearly.
For example, the accuracy of pairwise combina-
tion of head classifier and trigram classifier ex-
ceeds that of the 5-gram mixed model. It is also
3Entries marked with an asterisk ( &amp;quot;*&amp;quot; ) correspond
to cases where the pairwise combination of classifiers
was significantly better than either of their component
classifiers, p &lt; 0.05.
marginally, but not significantly, higher than the
3-gram mixed model. It is also notable that the
pairwise combination of the head word classifier
and the mix word classifier yields a significant im-
provement over either classifier, p &lt; 0.05, consid-
ering the disparity between the accuracies of its
component classifiers.
</bodyText>
<subsectionHeader confidence="0.862053">
3.5 Further Evaluation
</subsectionHeader>
<bodyText confidence="0.999985805555556">
We also compare various models&apos; performance
on base-NP detection and PP attachment disam-
biguation. The results will underscore the adroit-
ness of the classifier combination model in using
both local and long distance features. They will
also show that, depending on the ultimate appli-
cation, one model may be more appropriate than
another model.
A base-NP is a non-recursive NP structure
whose detection is useful in many applications,
such as information extraction. We extend our su-
pertagging models to perform this task in a fash-
ion similar to that described in Srinivas (1997b).
Selected models have been trained on 200K words.
Subsequently, after a model has supertagged the
test corpus, a procedure detects base-NPs by scan-
ning for appropriate sequences of supertags. Re-
sults for base-NP detection are shown in Table 4.
Note that the mixed model performs nearly as well
as the trigram model. Note also that the head
trigram model is outperformed by the other mod-
els. We suspect that unlike the trigram model, the
head model does not perform the accurate mod-
eling of local context which is important for base-
NP detection.
In contrast, information about long distance de-
pendencies are more important for the the PP at-
tachment task. In this task, a model must de-
cide whether a PP attaches at the NP or the VP
level. This corresponds to a choice between two
PP supertags: one associated with NP attach-
ment, and another associated with VP attach-
ment. The trigram model, head trigram model,
3-gram mixed model, and classifier combination
model perform at accuracies of 78.53%, 79.56%,
80.16%, and 82.10%, respectively, on the PP at-
</bodyText>
<page confidence="0.996607">
192
</page>
<table confidence="0.991395666666667">
Proceedings of EACL &apos;99
Recall Precision
Trigram 93.75 93.00
3-gram Mix 93.65 92.63
Head Trigram 91.17 89.72
Classifier Combination 94.00 93.17
</table>
<tableCaption confidence="0.973674">
Table 4: Some contextual models&apos; results on base-
NP chunking
</tableCaption>
<bodyText confidence="0.9750245">
tachment task. As may be expected, the trigram
model performs the worst on this task, presum-
ably because it is restricted to considering purely
local information.
</bodyText>
<sectionHeader confidence="0.971643" genericHeader="method">
4 Class Based Models
</sectionHeader>
<bodyText confidence="0.999968739130435">
Contextual models tag each word with the sin-
gle most appropriate supertag. In many applica-
tions, however, it is sufficient to reduce ambiguity
to a small number of supertags per word. For
example, using traditional TAG parsing methods,
such are described in Schabes (1990), it is ineffi-
cient to parse with a large LTAG grammar for En-
glish such as XTAG (The XTAG-Group (1995)).
In these circumstances, a single word may be as-
sociated with hundreds of supertags. Reducing
ambiguity to some small number k, say k &lt; 5 su-
pertags per word&apos; would accelerate parsing con-
siderably.5 As an alternative, once such a reduc-
tion in ambiguity has been achieved, partial pars-
ing or other techniques could be employed to iden-
tify the best single supertag. These are the aims
of class based models, which assign a small set of
supertags to each word. It is related to work by
Brown et al. (1992) where mutual information is
used to cluster words into classes for language
modeling. In our work with class based models,
we have considered only trigram based approaches
so far.
</bodyText>
<subsectionHeader confidence="0.972429">
4.1 Context Class Model
</subsectionHeader>
<bodyText confidence="0.999981428571429">
One reason why the trigram model of supertag-
ging is limited in its accuracy is because it con-
siders only a small contextual window around
the word to be supertagged when making its
tagging decision. Instead of using this limited
context to pinpoint the exact supertag, we pos-
tulate that it may be used to predict certain
</bodyText>
<footnote confidence="0.986876125">
4For example, the n-best model, described below,
achieves 98.4% accuracy with on average 4.8 supertags
per word.
5An alternate approach to TAG parsing that ef-
fectively shares the computation associated with each
lexicalized elementary tree (supertag) is described in
Evans and Weir (1998). It would be worth comparing
both approaches.
</footnote>
<bodyText confidence="0.99990908">
structural characteristics of the correct supertag
with much higher accuracy. In the context class
model, supertags that share the same character-
istics are grouped into classes and these classes,
rather than individual supertags, are predicted
by a trigram model. This is reminiscent of
Samuelsson and Reich (1999) where some part of
speech tags have been compounded so that each
word is deterministically in one class.
The grouping procedure may be described as
follows. Recall that each supertag corresponds to
a lexicalized tree t E G, where G is a particu-
lar LTAG. Using standard FIRST and FOLLOW
techniques, we may associate t with FOLLOW
and PRECEDE sets, FOLLOW(t) being the set
of supertags that can immediately follow t and
PRECEDE(t) being those supertags that can im-
mediately precede t. For example, an NP tree such
as (31 would be in the FOLLOW set of a supertag
of a verb that subcategorizes for an NP comple-
ment. We partition the set of all supertags into
classes such that all of the supertags in a particu-
lar class are associated with lexicalized trees with
the same PRECEDE and FOLLOW sets. For in-
stance, the supertags ti and t2 corresponding re-
spectively to the NP and S subcategorizations of
a verb feared would be associated with the same
class. (Note that a head NP tree would be a mem-
ber of both FOLLOW(h) and FOLLOW(t2)-)
The context class model predicts sets of su-
pertags for words as follows. First, the trigram
model supertags each word wi with supertag ti
that belongs to class C2.6 Furthermore, using the
training corpus, we obtain set Di which contains
all supertags t such that p(w, It) &gt; 0. The word
w, is relabeled with the set of supertags C2 n Di.
The context class model trades off an increased
ambiguity of 1.65 supertags per word on average,
for a higher 92.51% accuracy. For the purpose of
comparison, we may compare this model against
a baseline model that partitions the set of all su-
pertags into classes so that all of the supertags in
one class share the same preterminal symbol, i.e.,
they are anchored by words which share the same
part of speech. With classes defined in this man-
ner, call the set of supertags that belong to
the class which is associated with word w, in the
test corpus. We may then associate with word wi
the set of supertags n Di, where Di is defined
as above. This baseline procedure yields an aver-
</bodyText>
<footnote confidence="0.999586833333333">
6For class models, we have also exper-
imented with a variant where the classes
are assigned to words through the model
C argmaxc 117_113(Wi ICt )P(Ci 1C1-2)• In
general, we have found this procedure to give slightly
worse results.
</footnote>
<page confidence="0.997187">
193
</page>
<bodyText confidence="0.889668">
Proceedings of EACL &apos;99
age ambiguity of 5.64 supertags per word with an
accuracy of 97.96%.
</bodyText>
<subsectionHeader confidence="0.813503">
4.2 Confusion Class Model
</subsectionHeader>
<bodyText confidence="0.999866717391304">
The confusion class model partitions supertags
into classes according to an alternate procedure.
Here, classes are derived from a confusion matrix
analysis of errors which the trigram model makes
while supertagging. First, the trigram model su-
pertags a tune set. A confusion matrix is con-
structed, recording the number of times supertag
t, was confused for supertag ti, or vice versa,
in the tune set. Based on the top k pairs of
supertags that are most confused, we construct
classes of supertags that are confused with one
another. For example, let t1 and t2 be two PP
supertags which modify an NP and VP respec-
tively. The most common kind of mistake that
the trigram model made on the tune data was to
mistag t1 as t2, and vice versa. Hence, t1 and t2
are clustered by our method into the same con-
fusion class. The second most common mistake
was to confuse supertags that represent verb mod-
ifier PPs and those that represent verb argument
PPs, while the third most common mistake was to
confuse supertags that represent head nouns and
noun modifiers. These, too, would form their own
classes.
The confusion class model predicts sets of su-
pertags for words in a manner similar to the con-
text class model. Unlike the context class model,
however, in this model we have to choose k, the
number of pairs of supertags which are extracted
from the confusion matrix over which confusion
classes are formed. In our experiments, we have
found that with k = 10, k = 20, and k = 40,
the resulting models attain 94.61% accuracy and
1.86 tags per word, 95.76% accurate and 2.23 tags
per word, and 97.03% accurate and 3.38 tags per
word, respectively.&apos;
Results of these, as well as other models dis-
cussed below, are plotted in Figure 2. The n-best
model is a modification of the trigram model in
which the n most probable supertags per word are
chosen. The classifier union result is obtained by
assigning a word w, a set of supertags tzi, -,tik
where to t2, is the jth classifier&apos;s supertag assign-
ment for word wi, the classifiers being the models
discussed in Section 3. It achieves an accuracy of
95.21% with 1.26 supertags per word.
</bodyText>
<footnote confidence="0.560556333333333">
7Again, for the class C assign to a given word w„
we consider only those tags t, E C for which f(w„ lt,) &gt;
0.
</footnote>
<figure confidence="0.998215555555556">
0 Context
CUss
-Pr Confusion
Class
0 Classifier
Limon
-X• N-Best
2 3
Ambiguity (Tags Per Word)
</figure>
<figureCaption confidence="0.9306015">
Figure 2: Ambiguity versus Accuracy for Various
Class Models
</figureCaption>
<sectionHeader confidence="0.996187" genericHeader="method">
5 Future Work
</sectionHeader>
<bodyText confidence="0.999758454545455">
We are considering extending our work in sev-
eral directions. Srinivas (1997b) discussed a
lightweight dependency analyzer which assigns de-
pendencies assuming that each word has been as-
signed a unique supertag. We are extending this
algorithm to work with class based models which
narrows down the number of supertags per word
with much higher accuracy. Aside from the n-
gram modeling that was a focus of this paper,
we would also like to explore using other kinds
of models, such as maximum entropy.
</bodyText>
<sectionHeader confidence="0.999453" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999991157894737">
We have introduced two different kinds of models
for the task of supertagging. Contextual mod-
els show that features for accurate supertagging
only produce improvements when they are appro-
priately combined. Among these models were: a
one pass head model that reduces propagation of
head detection errors of previous models by using
supertags themselves to identify heads; a mixed
model that combines use of local and long distance
information; and a classifier combination model
that ameliorates the sparse data problem that is
worsened by the introduction of many new fea-
tures. These models achieve better supertagging
accuracies than previously obtained. We have also
introduced class based models which trade a slight
increase in ambiguity for significantly higher accu-
racy. Different class based methods are discussed,
and the tradeoff between accuracy and ambiguity
is demonstrated.
</bodyText>
<sectionHeader confidence="0.990488" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.513995">
Steven Abney. 1990. Rapid Incremental parsing
</reference>
<page confidence="0.996227">
194
</page>
<reference confidence="0.998134245283019">
Proceedings of EACL &apos;99
with repair. In Proceedings of the 6th New OED
Conference: Electronic Text Research, pages 1-
9, University of Waterloo, Waterloo, Canada.
Hiyan Alshawi. 1996. Head automata and bilin-
gual tiling: translation with minimal represen-
tations. In Proceedings of the 34th Annual
Meeting Association for Computational Lin-
guistics, Santa Cruz, California.
Srinivas Bangalore. 1998. Transplanting Su-
pertags from English to Spanish. In Proceedings
of the TAG+4 Workshop, Philadelphia, USA.
Peter F. Brown, Vincent J. Della Pietra, Peter V.
deSouza, Jennifer Lai, and Robert L. Mercer.
1992. Class-based n-gram models of natural
language Computational Linguistics, 18.4:467-
479.
R. Chandrasekhar and B. Srinivas. 1997. Using
supertags in document filtering: the effect of
increased context on information retrieval In
Proceedings of Recent Advances in NLP &apos;97.
Eugene Charniak. 1996. Tree-bank Grammars.
Technical Report CS-96-02, Brown University,
Providence, RI.
Michael Collins. 1996. A New Statistical Parser
Based on Bigram Lexical Dependencies. In Pro-
ceedings of the 34th Annual Meeting of the As-
sociation for Computational Linguistics, Santa
Cruz.
Roger Evans and David Weir. 1998. A Structure-
sharing Parser for Lexicalized Grammars. In
Proceedings of the 17th International Confer-
ence on Computational Linguistics and the 36th
Annual Meeting of the Association for Compu-
tational Linguistics, Montreal.
Ralph Grishman. 1995. Where&apos;s the Syntax?
The New York University MUC-6 System. In
Proceedings of the Sixth Message Understand-
ing Conference, Columbia, Maryland.
H. van Halteren, J. Zavrel, and W. Daelmans.
1998. Improving Data Driven Wordclass Tag-
ging by System Combination. In Proceedings of
COLING-ACL 98, Montreal.
Jerry R. Hobbs, Douglas E. Appelt, John
Bear, David Israel, Andy Kehler, Megumi Ka-
mayama, David Martin, Karen Myers, and
Marby Tyson. 1995. SRI International FAS-
TUS system MUC-6 test results and analy-
sis. In Proceedings of the Sixth Message Un-
derstanding Conference, Columbia, Maryland.
Jerry R. Hobbs, Douglas Appelt, John Bear,
David Israel, Megumi Kameyama, Mark Stickel,
and Mabry Tyson. 1997. FASTUS: A Cas-
caded Finite-State Transducer for Extracting
Information from Natural-Language Text. In
E. Roche and Schabes Y., editors, Finite State
Devices for Natural Language Processing. MIT
Press, Cambridge, Massachusetts.
Aravind K. Joshi and B. Srinivas. 1994. Dis-
ambiguation of Super Parts of Speech (or Su-
pertags): Almost Parsing. In Proceedings of
the 17th International Conference on Com-
putational Linguistics (COLING &apos;94), Kyoto,
Japan, August.
D. Jurafsky, Chuck Wooters, Jonathan Segal, An-
dreas Stolcke, Eric Fosler, Gary Tajchman, and
Nelson Morgan. 1995. Using a Stochastic CFG
as a Language Model for Speech Recognition.
In Proceedings, IEEE ICASSP, Detroit, Michi-
gan.
David M. Magerman. 1995. Statistical Decision-
Tree Models for Parsing. In Proceedings of
the 33rd Annual Meeting of the Association for
Computational Linguistics.
T.R. Niesler and P.C. Woodland. 1996. A
variable-length category-based N-gram lan-
guage model. In Proceedings, IEEE ICASSP.
S. Roukos. 1996. Phrase structure language mod-
els. In Proc. ICSLP &apos;96, volume supplement,
Philadelphia, PA, October.
Christer Samuelsson and Wolfgang Reich. 1999.
A Class-based Language Model for Large Vo-
cabulary Speech Recognition Extracted from
Part-of-Speech Statistics. In Proceedings, IEEE
ICASSP.
Yves Schabes. 1990. Mathematical and Computa-
tional Aspects of Lexicalized Grammars. Ph.D.
thesis, University of Pennsylvania, Philadel-
phia, PA.
B. Srinivas. 1997a. Complexity of Lexical De-
scriptions and its Relevance to Partial Pars-
ing. Ph.D. thesis, University of Pennsylvania,
Philadelphia, PA, August.
B. Srinivas. 1997b. Performance Evaluation of
Supertagging for Partial Parsing. In Proceed-
ings of Fifth International Workshop on Pars-
ing Technology, Boston, USA, September.
R. Weischedel., R. Schwartz, J. Palmucci, M.
Meteer, and L. Ramshaw. 1993. Coping with
ambiguity and unknown words through prob-
abilistic models. Computational Linguistics,
19.2:359-382.
The XTAG-Group. 1995. A Lexicalized Tree Ad-
joining Grammar for English. Technical Re-
port IRCS 95-03, University of Pennsylvania,
Philadelphia, PA.
</reference>
<page confidence="0.99893">
195
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.498171">
<note confidence="0.637905">Proceedings of EACL &apos;99</note>
<title confidence="0.99755">New Models for Improving Supertag Disambiguation</title>
<author confidence="0.999534">John Chen</author>
<affiliation confidence="0.999895666666667">Department of Computer and Information Sciences University of Delaware</affiliation>
<address confidence="0.966221">Newark, DE 19716</address>
<email confidence="0.999419">jchen@cis.udel.edu</email>
<author confidence="0.879912">Srinivas Bangalore</author>
<affiliation confidence="0.98589">AT&amp;T Labs Research</affiliation>
<address confidence="0.999014333333333">180 Park Avenue P.O. Box 971 Florham Park, NJ 07932</address>
<email confidence="0.999648">srini@research.att.com</email>
<author confidence="0.999011">K Vijay-Shanker</author>
<affiliation confidence="0.999885666666667">Department of Computer and Information Sciences University of Delaware</affiliation>
<address confidence="0.941248">Newark, DE 19716</address>
<email confidence="0.999149">vijay@cis.udel.edu</email>
<abstract confidence="0.999730272727273">In previous work, supertag disambiguation has been presented as a robust partial parsing technique. In this paper we present two approaches: contextual models, which exploit a variety of features in order to improve supertag performance, and class-based models, which assign sets of supertags to words in order to substantially improve accuracy with only a slight increase in ambiguity.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven Abney</author>
</authors>
<title>Rapid Incremental parsing Proceedings of EACL &apos;99 with repair.</title>
<date>1990</date>
<booktitle>In Proceedings of the 6th New OED Conference: Electronic Text Research,</booktitle>
<pages>1--9</pages>
<institution>University of Waterloo,</institution>
<location>Waterloo, Canada.</location>
<contexts>
<context position="1406" citStr="Abney (1990)" startWordPosition="204" endWordPosition="205">slight increase in ambiguity. 1 Introduction Many natural language applications are beginning to exploit some underlying structure of the language. Roukos (1996) and Jurafsky et al. (1995) use structure-based language models in the context of speech applications. Grishman (1995) and Hobbs et al. (1995) use phrasal information in information extraction. Alshawi (1996) uses dependency information in a machine translation system. The need to impose structure leads to the need to have robust parsers. There have been two main robust parsing paradigms: Finite State Grammar-based approaches (such as Abney (1990), Grishman (1995), and Hobbs et al. (1997)) and Statistical Parsing (such as Charniak (1996), Magerman (1995), and Collins (1996)). Srinivas (1997a) has presented a different approach called supertagging that integrates linguistically motivated lexical descriptions with the robustness of statistical techniques. The idea underlying the approach is that the computation of linguistic structure can be localized if lexical items are associated with rich descriptions (Supertags) that impose complex constraints in a local context. Supertag disambiguation is resolved • Supported by NSF grants #SBR-971</context>
</contexts>
<marker>Abney, 1990</marker>
<rawString>Steven Abney. 1990. Rapid Incremental parsing Proceedings of EACL &apos;99 with repair. In Proceedings of the 6th New OED Conference: Electronic Text Research, pages 1-9, University of Waterloo, Waterloo, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiyan Alshawi</author>
</authors>
<title>Head automata and bilingual tiling: translation with minimal representations.</title>
<date>1996</date>
<booktitle>In Proceedings of the 34th Annual Meeting Association for Computational Linguistics,</booktitle>
<location>Santa Cruz, California.</location>
<contexts>
<context position="1163" citStr="Alshawi (1996)" startWordPosition="166" endWordPosition="167">r we present two approaches: contextual models, which exploit a variety of features in order to improve supertag performance, and class-based models, which assign sets of supertags to words in order to substantially improve accuracy with only a slight increase in ambiguity. 1 Introduction Many natural language applications are beginning to exploit some underlying structure of the language. Roukos (1996) and Jurafsky et al. (1995) use structure-based language models in the context of speech applications. Grishman (1995) and Hobbs et al. (1995) use phrasal information in information extraction. Alshawi (1996) uses dependency information in a machine translation system. The need to impose structure leads to the need to have robust parsers. There have been two main robust parsing paradigms: Finite State Grammar-based approaches (such as Abney (1990), Grishman (1995), and Hobbs et al. (1997)) and Statistical Parsing (such as Charniak (1996), Magerman (1995), and Collins (1996)). Srinivas (1997a) has presented a different approach called supertagging that integrates linguistically motivated lexical descriptions with the robustness of statistical techniques. The idea underlying the approach is that the</context>
</contexts>
<marker>Alshawi, 1996</marker>
<rawString>Hiyan Alshawi. 1996. Head automata and bilingual tiling: translation with minimal representations. In Proceedings of the 34th Annual Meeting Association for Computational Linguistics, Santa Cruz, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srinivas Bangalore</author>
</authors>
<title>Transplanting Supertags from English to Spanish.</title>
<date>1998</date>
<booktitle>In Proceedings of the TAG+4 Workshop,</booktitle>
<location>Philadelphia, USA.</location>
<contexts>
<context position="2779" citStr="Bangalore (1998)" startWordPosition="415" endWordPosition="416">effectively a parse (almost parse). Supertagging has been found useful for a number of applications. For instance, it can be used to speed up conventional chart parsers because it reduces the ambiguity which a parser must face, as described in Srinivas (19974 Chandrasekhar and Srinivas (1997) has shown that supertagging may be employed in information retrieval. Furthermore, given a sentence aligned parallel corpus of two languages and almost parse information for the sentences of one of the languages, one can rapidly develop a grammar for the other language using supertagging, as suggested by Bangalore (1998). In contrast to the aforementioned work in supertag disambiguation, where the objective was to provide a direct comparison between trigram models for part-of-speech tagging and supertagging, in this paper our goal is to improve the performance of supertagging using local techniques which avoid full parsing. These supertag disambiguation models can be grouped into contextual models and class based models. Contextual models use different features in frameworks that exploit the information those features provide in order to achieve higher accuracies in supertagging. For class based models, super</context>
</contexts>
<marker>Bangalore, 1998</marker>
<rawString>Srinivas Bangalore. 1998. Transplanting Supertags from English to Spanish. In Proceedings of the TAG+4 Workshop, Philadelphia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Vincent J Della Pietra</author>
<author>Peter V deSouza</author>
<author>Jennifer Lai</author>
<author>Robert L Mercer</author>
</authors>
<date>1992</date>
<booktitle>Class-based n-gram models of natural language Computational Linguistics,</booktitle>
<pages>18--4</pages>
<contexts>
<context position="21404" citStr="Brown et al. (1992)" startWordPosition="3549" endWordPosition="3552">Schabes (1990), it is inefficient to parse with a large LTAG grammar for English such as XTAG (The XTAG-Group (1995)). In these circumstances, a single word may be associated with hundreds of supertags. Reducing ambiguity to some small number k, say k &lt; 5 supertags per word&apos; would accelerate parsing considerably.5 As an alternative, once such a reduction in ambiguity has been achieved, partial parsing or other techniques could be employed to identify the best single supertag. These are the aims of class based models, which assign a small set of supertags to each word. It is related to work by Brown et al. (1992) where mutual information is used to cluster words into classes for language modeling. In our work with class based models, we have considered only trigram based approaches so far. 4.1 Context Class Model One reason why the trigram model of supertagging is limited in its accuracy is because it considers only a small contextual window around the word to be supertagged when making its tagging decision. Instead of using this limited context to pinpoint the exact supertag, we postulate that it may be used to predict certain 4For example, the n-best model, described below, achieves 98.4% accuracy w</context>
</contexts>
<marker>Brown, Pietra, deSouza, Lai, Mercer, 1992</marker>
<rawString>Peter F. Brown, Vincent J. Della Pietra, Peter V. deSouza, Jennifer Lai, and Robert L. Mercer. 1992. Class-based n-gram models of natural language Computational Linguistics, 18.4:467-479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Chandrasekhar</author>
<author>B Srinivas</author>
</authors>
<title>Using supertags in document filtering: the effect of increased context on information retrieval</title>
<date>1997</date>
<booktitle>In Proceedings of Recent Advances in NLP &apos;97.</booktitle>
<contexts>
<context position="2456" citStr="Chandrasekhar and Srinivas (1997)" startWordPosition="361" endWordPosition="364">ical items are associated with rich descriptions (Supertags) that impose complex constraints in a local context. Supertag disambiguation is resolved • Supported by NSF grants #SBR-9710411 and #GER-9354869 by using statistical distributions of supertag cooccurrences collected from a corpus of parses. It results in a representation that is effectively a parse (almost parse). Supertagging has been found useful for a number of applications. For instance, it can be used to speed up conventional chart parsers because it reduces the ambiguity which a parser must face, as described in Srinivas (19974 Chandrasekhar and Srinivas (1997) has shown that supertagging may be employed in information retrieval. Furthermore, given a sentence aligned parallel corpus of two languages and almost parse information for the sentences of one of the languages, one can rapidly develop a grammar for the other language using supertagging, as suggested by Bangalore (1998). In contrast to the aforementioned work in supertag disambiguation, where the objective was to provide a direct comparison between trigram models for part-of-speech tagging and supertagging, in this paper our goal is to improve the performance of supertagging using local tech</context>
</contexts>
<marker>Chandrasekhar, Srinivas, 1997</marker>
<rawString>R. Chandrasekhar and B. Srinivas. 1997. Using supertags in document filtering: the effect of increased context on information retrieval In Proceedings of Recent Advances in NLP &apos;97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>Tree-bank Grammars.</title>
<date>1996</date>
<tech>Technical Report CS-96-02,</tech>
<institution>Brown University,</institution>
<location>Providence, RI.</location>
<contexts>
<context position="1498" citStr="Charniak (1996)" startWordPosition="218" endWordPosition="219">ning to exploit some underlying structure of the language. Roukos (1996) and Jurafsky et al. (1995) use structure-based language models in the context of speech applications. Grishman (1995) and Hobbs et al. (1995) use phrasal information in information extraction. Alshawi (1996) uses dependency information in a machine translation system. The need to impose structure leads to the need to have robust parsers. There have been two main robust parsing paradigms: Finite State Grammar-based approaches (such as Abney (1990), Grishman (1995), and Hobbs et al. (1997)) and Statistical Parsing (such as Charniak (1996), Magerman (1995), and Collins (1996)). Srinivas (1997a) has presented a different approach called supertagging that integrates linguistically motivated lexical descriptions with the robustness of statistical techniques. The idea underlying the approach is that the computation of linguistic structure can be localized if lexical items are associated with rich descriptions (Supertags) that impose complex constraints in a local context. Supertag disambiguation is resolved • Supported by NSF grants #SBR-9710411 and #GER-9354869 by using statistical distributions of supertag cooccurrences collected</context>
</contexts>
<marker>Charniak, 1996</marker>
<rawString>Eugene Charniak. 1996. Tree-bank Grammars. Technical Report CS-96-02, Brown University, Providence, RI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>A New Statistical Parser Based on Bigram Lexical Dependencies.</title>
<date>1996</date>
<booktitle>In Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Santa Cruz.</location>
<contexts>
<context position="1535" citStr="Collins (1996)" startWordPosition="223" endWordPosition="224">ure of the language. Roukos (1996) and Jurafsky et al. (1995) use structure-based language models in the context of speech applications. Grishman (1995) and Hobbs et al. (1995) use phrasal information in information extraction. Alshawi (1996) uses dependency information in a machine translation system. The need to impose structure leads to the need to have robust parsers. There have been two main robust parsing paradigms: Finite State Grammar-based approaches (such as Abney (1990), Grishman (1995), and Hobbs et al. (1997)) and Statistical Parsing (such as Charniak (1996), Magerman (1995), and Collins (1996)). Srinivas (1997a) has presented a different approach called supertagging that integrates linguistically motivated lexical descriptions with the robustness of statistical techniques. The idea underlying the approach is that the computation of linguistic structure can be localized if lexical items are associated with rich descriptions (Supertags) that impose complex constraints in a local context. Supertag disambiguation is resolved • Supported by NSF grants #SBR-9710411 and #GER-9354869 by using statistical distributions of supertag cooccurrences collected from a corpus of parses. It results </context>
</contexts>
<marker>Collins, 1996</marker>
<rawString>Michael Collins. 1996. A New Statistical Parser Based on Bigram Lexical Dependencies. In Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics, Santa Cruz.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Evans</author>
<author>David Weir</author>
</authors>
<title>A Structuresharing Parser for Lexicalized Grammars.</title>
<date>1998</date>
<booktitle>In Proceedings of the 17th International Conference on Computational Linguistics and the 36th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Montreal.</location>
<contexts>
<context position="22218" citStr="Evans and Weir (1998)" startWordPosition="3682" endWordPosition="3685">Class Model One reason why the trigram model of supertagging is limited in its accuracy is because it considers only a small contextual window around the word to be supertagged when making its tagging decision. Instead of using this limited context to pinpoint the exact supertag, we postulate that it may be used to predict certain 4For example, the n-best model, described below, achieves 98.4% accuracy with on average 4.8 supertags per word. 5An alternate approach to TAG parsing that effectively shares the computation associated with each lexicalized elementary tree (supertag) is described in Evans and Weir (1998). It would be worth comparing both approaches. structural characteristics of the correct supertag with much higher accuracy. In the context class model, supertags that share the same characteristics are grouped into classes and these classes, rather than individual supertags, are predicted by a trigram model. This is reminiscent of Samuelsson and Reich (1999) where some part of speech tags have been compounded so that each word is deterministically in one class. The grouping procedure may be described as follows. Recall that each supertag corresponds to a lexicalized tree t E G, where G is a p</context>
</contexts>
<marker>Evans, Weir, 1998</marker>
<rawString>Roger Evans and David Weir. 1998. A Structuresharing Parser for Lexicalized Grammars. In Proceedings of the 17th International Conference on Computational Linguistics and the 36th Annual Meeting of the Association for Computational Linguistics, Montreal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph Grishman</author>
</authors>
<title>Where&apos;s the Syntax? The New York University MUC-6 System.</title>
<date>1995</date>
<booktitle>In Proceedings of the Sixth Message Understanding Conference,</booktitle>
<location>Columbia, Maryland.</location>
<contexts>
<context position="1073" citStr="Grishman (1995)" startWordPosition="153" endWordPosition="154">ertag disambiguation has been presented as a robust partial parsing technique. In this paper we present two approaches: contextual models, which exploit a variety of features in order to improve supertag performance, and class-based models, which assign sets of supertags to words in order to substantially improve accuracy with only a slight increase in ambiguity. 1 Introduction Many natural language applications are beginning to exploit some underlying structure of the language. Roukos (1996) and Jurafsky et al. (1995) use structure-based language models in the context of speech applications. Grishman (1995) and Hobbs et al. (1995) use phrasal information in information extraction. Alshawi (1996) uses dependency information in a machine translation system. The need to impose structure leads to the need to have robust parsers. There have been two main robust parsing paradigms: Finite State Grammar-based approaches (such as Abney (1990), Grishman (1995), and Hobbs et al. (1997)) and Statistical Parsing (such as Charniak (1996), Magerman (1995), and Collins (1996)). Srinivas (1997a) has presented a different approach called supertagging that integrates linguistically motivated lexical descriptions w</context>
</contexts>
<marker>Grishman, 1995</marker>
<rawString>Ralph Grishman. 1995. Where&apos;s the Syntax? The New York University MUC-6 System. In Proceedings of the Sixth Message Understanding Conference, Columbia, Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H van Halteren</author>
<author>J Zavrel</author>
<author>W Daelmans</author>
</authors>
<title>Improving Data Driven Wordclass Tagging by System Combination.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING-ACL 98,</booktitle>
<location>Montreal.</location>
<marker>van Halteren, Zavrel, Daelmans, 1998</marker>
<rawString>H. van Halteren, J. Zavrel, and W. Daelmans. 1998. Improving Data Driven Wordclass Tagging by System Combination. In Proceedings of COLING-ACL 98, Montreal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
<author>Douglas E Appelt</author>
<author>John Bear</author>
<author>David Israel</author>
<author>Andy Kehler</author>
<author>Megumi Kamayama</author>
<author>David Martin</author>
<author>Karen Myers</author>
<author>Marby Tyson</author>
</authors>
<title>results and analysis.</title>
<date>1995</date>
<booktitle>SRI International FASTUS system MUC-6 test</booktitle>
<location>Columbia, Maryland.</location>
<contexts>
<context position="1097" citStr="Hobbs et al. (1995)" startWordPosition="156" endWordPosition="159"> has been presented as a robust partial parsing technique. In this paper we present two approaches: contextual models, which exploit a variety of features in order to improve supertag performance, and class-based models, which assign sets of supertags to words in order to substantially improve accuracy with only a slight increase in ambiguity. 1 Introduction Many natural language applications are beginning to exploit some underlying structure of the language. Roukos (1996) and Jurafsky et al. (1995) use structure-based language models in the context of speech applications. Grishman (1995) and Hobbs et al. (1995) use phrasal information in information extraction. Alshawi (1996) uses dependency information in a machine translation system. The need to impose structure leads to the need to have robust parsers. There have been two main robust parsing paradigms: Finite State Grammar-based approaches (such as Abney (1990), Grishman (1995), and Hobbs et al. (1997)) and Statistical Parsing (such as Charniak (1996), Magerman (1995), and Collins (1996)). Srinivas (1997a) has presented a different approach called supertagging that integrates linguistically motivated lexical descriptions with the robustness of st</context>
</contexts>
<marker>Hobbs, Appelt, Bear, Israel, Kehler, Kamayama, Martin, Myers, Tyson, 1995</marker>
<rawString>Jerry R. Hobbs, Douglas E. Appelt, John Bear, David Israel, Andy Kehler, Megumi Kamayama, David Martin, Karen Myers, and Marby Tyson. 1995. SRI International FASTUS system MUC-6 test results and analysis. In Proceedings of the Sixth Message Understanding Conference, Columbia, Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
<author>Douglas Appelt</author>
<author>John Bear</author>
<author>David Israel</author>
<author>Megumi Kameyama</author>
<author>Mark Stickel</author>
<author>Mabry Tyson</author>
</authors>
<title>FASTUS: A Cascaded Finite-State Transducer for Extracting Information from Natural-Language Text.</title>
<date>1997</date>
<booktitle>Finite State Devices for Natural Language Processing.</booktitle>
<editor>In E. Roche and Schabes Y., editors,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="1448" citStr="Hobbs et al. (1997)" startWordPosition="209" endWordPosition="212">roduction Many natural language applications are beginning to exploit some underlying structure of the language. Roukos (1996) and Jurafsky et al. (1995) use structure-based language models in the context of speech applications. Grishman (1995) and Hobbs et al. (1995) use phrasal information in information extraction. Alshawi (1996) uses dependency information in a machine translation system. The need to impose structure leads to the need to have robust parsers. There have been two main robust parsing paradigms: Finite State Grammar-based approaches (such as Abney (1990), Grishman (1995), and Hobbs et al. (1997)) and Statistical Parsing (such as Charniak (1996), Magerman (1995), and Collins (1996)). Srinivas (1997a) has presented a different approach called supertagging that integrates linguistically motivated lexical descriptions with the robustness of statistical techniques. The idea underlying the approach is that the computation of linguistic structure can be localized if lexical items are associated with rich descriptions (Supertags) that impose complex constraints in a local context. Supertag disambiguation is resolved • Supported by NSF grants #SBR-9710411 and #GER-9354869 by using statistical</context>
</contexts>
<marker>Hobbs, Appelt, Bear, Israel, Kameyama, Stickel, Tyson, 1997</marker>
<rawString>Jerry R. Hobbs, Douglas Appelt, John Bear, David Israel, Megumi Kameyama, Mark Stickel, and Mabry Tyson. 1997. FASTUS: A Cascaded Finite-State Transducer for Extracting Information from Natural-Language Text. In E. Roche and Schabes Y., editors, Finite State Devices for Natural Language Processing. MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind K Joshi</author>
<author>B Srinivas</author>
</authors>
<title>Disambiguation of Super Parts of Speech (or Supertags): Almost Parsing.</title>
<date>1994</date>
<booktitle>In Proceedings of the 17th International Conference on Computational Linguistics (COLING &apos;94),</booktitle>
<location>Kyoto, Japan,</location>
<contexts>
<context position="4776" citStr="Joshi and Srinivas (1994)" startWordPosition="734" endWordPosition="737"> is accomplished by grouping syntactically or semantically dependent elements to be within the same structure. Thus, as seen in Figure 1, supertags contain more information than standard part-ofspeech tags, and there are many more supertags per word than part-of-speech tags. In fact, supertag disambiguation may be characterized as providing an almost parse, as shown in the bottom part of Figure 1. Local statistical information, in the form of a trigram model based on the distribution of supertags in an LTAG parsed corpus, can be used to choose the most appropriate supertag for any given word. Joshi and Srinivas (1994) define supertagging as the process of assigning the best supertag to each word. Srinivas (1997b) and Srinivas (1997a) have tested the performance of a trigram model, typically used for part-of-speech tagging on supertagging, on restricted domains such as ATIS and less restricted domains such as Wall Street Journal (WSJ). In this work, we explore a variety of local techniques in order to improve the performance of supertagging. All of the models presented here perform smoothing using a Good-Turing discounting technique with Katz&apos;s backoff model. With exceptions where noted, our models were tra</context>
</contexts>
<marker>Joshi, Srinivas, 1994</marker>
<rawString>Aravind K. Joshi and B. Srinivas. 1994. Disambiguation of Super Parts of Speech (or Supertags): Almost Parsing. In Proceedings of the 17th International Conference on Computational Linguistics (COLING &apos;94), Kyoto, Japan, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Jurafsky</author>
<author>Chuck Wooters</author>
<author>Jonathan Segal</author>
<author>Andreas Stolcke</author>
<author>Eric Fosler</author>
<author>Gary Tajchman</author>
<author>Nelson Morgan</author>
</authors>
<title>Using a Stochastic CFG as a Language Model for Speech Recognition.</title>
<date>1995</date>
<booktitle>In Proceedings, IEEE ICASSP,</booktitle>
<location>Detroit, Michigan.</location>
<contexts>
<context position="982" citStr="Jurafsky et al. (1995)" startWordPosition="139" endWordPosition="142">Sciences University of Delaware Newark, DE 19716 vijay@cis.udel.edu Abstract In previous work, supertag disambiguation has been presented as a robust partial parsing technique. In this paper we present two approaches: contextual models, which exploit a variety of features in order to improve supertag performance, and class-based models, which assign sets of supertags to words in order to substantially improve accuracy with only a slight increase in ambiguity. 1 Introduction Many natural language applications are beginning to exploit some underlying structure of the language. Roukos (1996) and Jurafsky et al. (1995) use structure-based language models in the context of speech applications. Grishman (1995) and Hobbs et al. (1995) use phrasal information in information extraction. Alshawi (1996) uses dependency information in a machine translation system. The need to impose structure leads to the need to have robust parsers. There have been two main robust parsing paradigms: Finite State Grammar-based approaches (such as Abney (1990), Grishman (1995), and Hobbs et al. (1997)) and Statistical Parsing (such as Charniak (1996), Magerman (1995), and Collins (1996)). Srinivas (1997a) has presented a different a</context>
</contexts>
<marker>Jurafsky, Wooters, Segal, Stolcke, Fosler, Tajchman, Morgan, 1995</marker>
<rawString>D. Jurafsky, Chuck Wooters, Jonathan Segal, Andreas Stolcke, Eric Fosler, Gary Tajchman, and Nelson Morgan. 1995. Using a Stochastic CFG as a Language Model for Speech Recognition. In Proceedings, IEEE ICASSP, Detroit, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Magerman</author>
</authors>
<title>Statistical DecisionTree Models for Parsing.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1515" citStr="Magerman (1995)" startWordPosition="220" endWordPosition="221">ome underlying structure of the language. Roukos (1996) and Jurafsky et al. (1995) use structure-based language models in the context of speech applications. Grishman (1995) and Hobbs et al. (1995) use phrasal information in information extraction. Alshawi (1996) uses dependency information in a machine translation system. The need to impose structure leads to the need to have robust parsers. There have been two main robust parsing paradigms: Finite State Grammar-based approaches (such as Abney (1990), Grishman (1995), and Hobbs et al. (1997)) and Statistical Parsing (such as Charniak (1996), Magerman (1995), and Collins (1996)). Srinivas (1997a) has presented a different approach called supertagging that integrates linguistically motivated lexical descriptions with the robustness of statistical techniques. The idea underlying the approach is that the computation of linguistic structure can be localized if lexical items are associated with rich descriptions (Supertags) that impose complex constraints in a local context. Supertag disambiguation is resolved • Supported by NSF grants #SBR-9710411 and #GER-9354869 by using statistical distributions of supertag cooccurrences collected from a corpus of</context>
<context position="7930" citStr="Magerman (1995)" startWordPosition="1254" endWordPosition="1255">gure 1) and a less frequent one to a S complement. The supertag for the word might, highly probable to be modeled as an auxiliary verb in this case, provides strong evidence for the latter. Notice that might and feared appear within a head model&apos;s two head window, but not within the trigram model&apos;s two word window. We may therefore expect that a head model would make a more accurate prediction. Srinivas (1997b) presents a two pass head trigram model. In the first pass, it tags words as either head words or non-head words. Training data for this pass is obtained using a head percolation table (Magerman (1995)) on bracketed Penn Treebank sentences. After training, head tagging is performed according to Equation 1, where /3 is the estimated probability and H (i) is a characteristic function which is true if word i is a head word. H argmax H HioilH(05(H(i)1H(i-1)H(i-2)) (1) The second pass then takes the words with this head information and supertags them according to Equation 2, where tH(z,,) is the supertag of the 2Part of speech tagging models have not used heads in this manner to achieve variable length contexts. Variable length n-gram models, one of which is described in Niesler and Woodland (19</context>
</contexts>
<marker>Magerman, 1995</marker>
<rawString>David M. Magerman. 1995. Statistical DecisionTree Models for Parsing. In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T R Niesler</author>
<author>P C Woodland</author>
</authors>
<title>A variable-length category-based N-gram language model.</title>
<date>1996</date>
<booktitle>In Proceedings, IEEE ICASSP.</booktitle>
<contexts>
<context position="8533" citStr="Niesler and Woodland (1996)" startWordPosition="1353" endWordPosition="1356">n table (Magerman (1995)) on bracketed Penn Treebank sentences. After training, head tagging is performed according to Equation 1, where /3 is the estimated probability and H (i) is a characteristic function which is true if word i is a head word. H argmax H HioilH(05(H(i)1H(i-1)H(i-2)) (1) The second pass then takes the words with this head information and supertags them according to Equation 2, where tH(z,,) is the supertag of the 2Part of speech tagging models have not used heads in this manner to achieve variable length contexts. Variable length n-gram models, one of which is described in Niesler and Woodland (1996), have been used instead. 189 Proceedings of EACL &apos;99 Figure 1: A selection of the supertags associated with each word of the sentence: the purchase price includes two ancillary companies NP NIP / \ NP VP NP NP* S price NP S /N. companies NP VP ./^&amp;quot;. V AP CC5 VN NP VP i I V NP /N E A I / V NP ancillary PUIChaSeE 1 1 aLl al includes E 03 NP VN NP VP NP NP S NP S I /N. NP VP NP VP VN VN V NP V NP i I I I D N N. E N V NP D NP. A N. C N the purchase price includes two ancillary companies 131 132 06 07 133 134 08 NiP N NP VP NP S NP VP purchase price VN / \ V NP N° V NP NP VP companies includes - V</context>
</contexts>
<marker>Niesler, Woodland, 1996</marker>
<rawString>T.R. Niesler and P.C. Woodland. 1996. A variable-length category-based N-gram language model. In Proceedings, IEEE ICASSP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Roukos</author>
</authors>
<title>Phrase structure language models.</title>
<date>1996</date>
<booktitle>In Proc. ICSLP &apos;96,</booktitle>
<volume>volume</volume>
<location>Philadelphia, PA,</location>
<contexts>
<context position="955" citStr="Roukos (1996)" startWordPosition="136" endWordPosition="137">r and Information Sciences University of Delaware Newark, DE 19716 vijay@cis.udel.edu Abstract In previous work, supertag disambiguation has been presented as a robust partial parsing technique. In this paper we present two approaches: contextual models, which exploit a variety of features in order to improve supertag performance, and class-based models, which assign sets of supertags to words in order to substantially improve accuracy with only a slight increase in ambiguity. 1 Introduction Many natural language applications are beginning to exploit some underlying structure of the language. Roukos (1996) and Jurafsky et al. (1995) use structure-based language models in the context of speech applications. Grishman (1995) and Hobbs et al. (1995) use phrasal information in information extraction. Alshawi (1996) uses dependency information in a machine translation system. The need to impose structure leads to the need to have robust parsers. There have been two main robust parsing paradigms: Finite State Grammar-based approaches (such as Abney (1990), Grishman (1995), and Hobbs et al. (1997)) and Statistical Parsing (such as Charniak (1996), Magerman (1995), and Collins (1996)). Srinivas (1997a) </context>
</contexts>
<marker>Roukos, 1996</marker>
<rawString>S. Roukos. 1996. Phrase structure language models. In Proc. ICSLP &apos;96, volume supplement, Philadelphia, PA, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christer Samuelsson</author>
<author>Wolfgang Reich</author>
</authors>
<title>A Class-based Language Model for Large Vocabulary Speech Recognition Extracted from Part-of-Speech Statistics.</title>
<date>1999</date>
<booktitle>In Proceedings, IEEE ICASSP.</booktitle>
<contexts>
<context position="22579" citStr="Samuelsson and Reich (1999)" startWordPosition="3736" endWordPosition="3739">st model, described below, achieves 98.4% accuracy with on average 4.8 supertags per word. 5An alternate approach to TAG parsing that effectively shares the computation associated with each lexicalized elementary tree (supertag) is described in Evans and Weir (1998). It would be worth comparing both approaches. structural characteristics of the correct supertag with much higher accuracy. In the context class model, supertags that share the same characteristics are grouped into classes and these classes, rather than individual supertags, are predicted by a trigram model. This is reminiscent of Samuelsson and Reich (1999) where some part of speech tags have been compounded so that each word is deterministically in one class. The grouping procedure may be described as follows. Recall that each supertag corresponds to a lexicalized tree t E G, where G is a particular LTAG. Using standard FIRST and FOLLOW techniques, we may associate t with FOLLOW and PRECEDE sets, FOLLOW(t) being the set of supertags that can immediately follow t and PRECEDE(t) being those supertags that can immediately precede t. For example, an NP tree such as (31 would be in the FOLLOW set of a supertag of a verb that subcategorizes for an NP</context>
</contexts>
<marker>Samuelsson, Reich, 1999</marker>
<rawString>Christer Samuelsson and Wolfgang Reich. 1999. A Class-based Language Model for Large Vocabulary Speech Recognition Extracted from Part-of-Speech Statistics. In Proceedings, IEEE ICASSP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Schabes</author>
</authors>
<title>Mathematical and Computational Aspects of Lexicalized Grammars.</title>
<date>1990</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania,</institution>
<location>Philadelphia, PA.</location>
<contexts>
<context position="20799" citStr="Schabes (1990)" startWordPosition="3440" endWordPosition="3441">am 93.75 93.00 3-gram Mix 93.65 92.63 Head Trigram 91.17 89.72 Classifier Combination 94.00 93.17 Table 4: Some contextual models&apos; results on baseNP chunking tachment task. As may be expected, the trigram model performs the worst on this task, presumably because it is restricted to considering purely local information. 4 Class Based Models Contextual models tag each word with the single most appropriate supertag. In many applications, however, it is sufficient to reduce ambiguity to a small number of supertags per word. For example, using traditional TAG parsing methods, such are described in Schabes (1990), it is inefficient to parse with a large LTAG grammar for English such as XTAG (The XTAG-Group (1995)). In these circumstances, a single word may be associated with hundreds of supertags. Reducing ambiguity to some small number k, say k &lt; 5 supertags per word&apos; would accelerate parsing considerably.5 As an alternative, once such a reduction in ambiguity has been achieved, partial parsing or other techniques could be employed to identify the best single supertag. These are the aims of class based models, which assign a small set of supertags to each word. It is related to work by Brown et al. (</context>
</contexts>
<marker>Schabes, 1990</marker>
<rawString>Yves Schabes. 1990. Mathematical and Computational Aspects of Lexicalized Grammars. Ph.D. thesis, University of Pennsylvania, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Srinivas</author>
</authors>
<title>Complexity of Lexical Descriptions and its Relevance to Partial Parsing.</title>
<date>1997</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania,</institution>
<location>Philadelphia, PA,</location>
<contexts>
<context position="1552" citStr="Srinivas (1997" startWordPosition="225" endWordPosition="226">ge. Roukos (1996) and Jurafsky et al. (1995) use structure-based language models in the context of speech applications. Grishman (1995) and Hobbs et al. (1995) use phrasal information in information extraction. Alshawi (1996) uses dependency information in a machine translation system. The need to impose structure leads to the need to have robust parsers. There have been two main robust parsing paradigms: Finite State Grammar-based approaches (such as Abney (1990), Grishman (1995), and Hobbs et al. (1997)) and Statistical Parsing (such as Charniak (1996), Magerman (1995), and Collins (1996)). Srinivas (1997a) has presented a different approach called supertagging that integrates linguistically motivated lexical descriptions with the robustness of statistical techniques. The idea underlying the approach is that the computation of linguistic structure can be localized if lexical items are associated with rich descriptions (Supertags) that impose complex constraints in a local context. Supertag disambiguation is resolved • Supported by NSF grants #SBR-9710411 and #GER-9354869 by using statistical distributions of supertag cooccurrences collected from a corpus of parses. It results in a representati</context>
<context position="4871" citStr="Srinivas (1997" startWordPosition="752" endWordPosition="753">ure. Thus, as seen in Figure 1, supertags contain more information than standard part-ofspeech tags, and there are many more supertags per word than part-of-speech tags. In fact, supertag disambiguation may be characterized as providing an almost parse, as shown in the bottom part of Figure 1. Local statistical information, in the form of a trigram model based on the distribution of supertags in an LTAG parsed corpus, can be used to choose the most appropriate supertag for any given word. Joshi and Srinivas (1994) define supertagging as the process of assigning the best supertag to each word. Srinivas (1997b) and Srinivas (1997a) have tested the performance of a trigram model, typically used for part-of-speech tagging on supertagging, on restricted domains such as ATIS and less restricted domains such as Wall Street Journal (WSJ). In this work, we explore a variety of local techniques in order to improve the performance of supertagging. All of the models presented here perform smoothing using a Good-Turing discounting technique with Katz&apos;s backoff model. With exceptions where noted, our models were trained on one million words of Wall Street Journal data and tested on 48K words. The data and eva</context>
<context position="7727" citStr="Srinivas (1997" startWordPosition="1217" endWordPosition="1218">ead model&apos;s strengths over the trigram model. There are at least two frequently assigned supertags for the word feared: a more frequent one corresponding to a subcategorization of NP object (as an of Figure 1) and a less frequent one to a S complement. The supertag for the word might, highly probable to be modeled as an auxiliary verb in this case, provides strong evidence for the latter. Notice that might and feared appear within a head model&apos;s two head window, but not within the trigram model&apos;s two word window. We may therefore expect that a head model would make a more accurate prediction. Srinivas (1997b) presents a two pass head trigram model. In the first pass, it tags words as either head words or non-head words. Training data for this pass is obtained using a head percolation table (Magerman (1995)) on bracketed Penn Treebank sentences. After training, head tagging is performed according to Equation 1, where /3 is the estimated probability and H (i) is a characteristic function which is true if word i is a head word. H argmax H HioilH(05(H(i)1H(i-1)H(i-2)) (1) The second pass then takes the words with this head information and supertags them according to Equation 2, where tH(z,,) is the </context>
<context position="19083" citStr="Srinivas (1997" startWordPosition="3155" endWordPosition="3156">classifiers. 3.5 Further Evaluation We also compare various models&apos; performance on base-NP detection and PP attachment disambiguation. The results will underscore the adroitness of the classifier combination model in using both local and long distance features. They will also show that, depending on the ultimate application, one model may be more appropriate than another model. A base-NP is a non-recursive NP structure whose detection is useful in many applications, such as information extraction. We extend our supertagging models to perform this task in a fashion similar to that described in Srinivas (1997b). Selected models have been trained on 200K words. Subsequently, after a model has supertagged the test corpus, a procedure detects base-NPs by scanning for appropriate sequences of supertags. Results for base-NP detection are shown in Table 4. Note that the mixed model performs nearly as well as the trigram model. Note also that the head trigram model is outperformed by the other models. We suspect that unlike the trigram model, the head model does not perform the accurate modeling of local context which is important for baseNP detection. In contrast, information about long distance depende</context>
<context position="27462" citStr="Srinivas (1997" startWordPosition="4612" endWordPosition="4613">lt is obtained by assigning a word w, a set of supertags tzi, -,tik where to t2, is the jth classifier&apos;s supertag assignment for word wi, the classifiers being the models discussed in Section 3. It achieves an accuracy of 95.21% with 1.26 supertags per word. 7Again, for the class C assign to a given word w„ we consider only those tags t, E C for which f(w„ lt,) &gt; 0. 0 Context CUss -Pr Confusion Class 0 Classifier Limon -X• N-Best 2 3 Ambiguity (Tags Per Word) Figure 2: Ambiguity versus Accuracy for Various Class Models 5 Future Work We are considering extending our work in several directions. Srinivas (1997b) discussed a lightweight dependency analyzer which assigns dependencies assuming that each word has been assigned a unique supertag. We are extending this algorithm to work with class based models which narrows down the number of supertags per word with much higher accuracy. Aside from the ngram modeling that was a focus of this paper, we would also like to explore using other kinds of models, such as maximum entropy. 6 Conclusions We have introduced two different kinds of models for the task of supertagging. Contextual models show that features for accurate supertagging only produce improve</context>
</contexts>
<marker>Srinivas, 1997</marker>
<rawString>B. Srinivas. 1997a. Complexity of Lexical Descriptions and its Relevance to Partial Parsing. Ph.D. thesis, University of Pennsylvania, Philadelphia, PA, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Srinivas</author>
</authors>
<title>Performance Evaluation of Supertagging for Partial Parsing.</title>
<date>1997</date>
<booktitle>In Proceedings of Fifth International Workshop on Parsing Technology,</booktitle>
<location>Boston, USA,</location>
<contexts>
<context position="1552" citStr="Srinivas (1997" startWordPosition="225" endWordPosition="226">ge. Roukos (1996) and Jurafsky et al. (1995) use structure-based language models in the context of speech applications. Grishman (1995) and Hobbs et al. (1995) use phrasal information in information extraction. Alshawi (1996) uses dependency information in a machine translation system. The need to impose structure leads to the need to have robust parsers. There have been two main robust parsing paradigms: Finite State Grammar-based approaches (such as Abney (1990), Grishman (1995), and Hobbs et al. (1997)) and Statistical Parsing (such as Charniak (1996), Magerman (1995), and Collins (1996)). Srinivas (1997a) has presented a different approach called supertagging that integrates linguistically motivated lexical descriptions with the robustness of statistical techniques. The idea underlying the approach is that the computation of linguistic structure can be localized if lexical items are associated with rich descriptions (Supertags) that impose complex constraints in a local context. Supertag disambiguation is resolved • Supported by NSF grants #SBR-9710411 and #GER-9354869 by using statistical distributions of supertag cooccurrences collected from a corpus of parses. It results in a representati</context>
<context position="4871" citStr="Srinivas (1997" startWordPosition="752" endWordPosition="753">ure. Thus, as seen in Figure 1, supertags contain more information than standard part-ofspeech tags, and there are many more supertags per word than part-of-speech tags. In fact, supertag disambiguation may be characterized as providing an almost parse, as shown in the bottom part of Figure 1. Local statistical information, in the form of a trigram model based on the distribution of supertags in an LTAG parsed corpus, can be used to choose the most appropriate supertag for any given word. Joshi and Srinivas (1994) define supertagging as the process of assigning the best supertag to each word. Srinivas (1997b) and Srinivas (1997a) have tested the performance of a trigram model, typically used for part-of-speech tagging on supertagging, on restricted domains such as ATIS and less restricted domains such as Wall Street Journal (WSJ). In this work, we explore a variety of local techniques in order to improve the performance of supertagging. All of the models presented here perform smoothing using a Good-Turing discounting technique with Katz&apos;s backoff model. With exceptions where noted, our models were trained on one million words of Wall Street Journal data and tested on 48K words. The data and eva</context>
<context position="7727" citStr="Srinivas (1997" startWordPosition="1217" endWordPosition="1218">ead model&apos;s strengths over the trigram model. There are at least two frequently assigned supertags for the word feared: a more frequent one corresponding to a subcategorization of NP object (as an of Figure 1) and a less frequent one to a S complement. The supertag for the word might, highly probable to be modeled as an auxiliary verb in this case, provides strong evidence for the latter. Notice that might and feared appear within a head model&apos;s two head window, but not within the trigram model&apos;s two word window. We may therefore expect that a head model would make a more accurate prediction. Srinivas (1997b) presents a two pass head trigram model. In the first pass, it tags words as either head words or non-head words. Training data for this pass is obtained using a head percolation table (Magerman (1995)) on bracketed Penn Treebank sentences. After training, head tagging is performed according to Equation 1, where /3 is the estimated probability and H (i) is a characteristic function which is true if word i is a head word. H argmax H HioilH(05(H(i)1H(i-1)H(i-2)) (1) The second pass then takes the words with this head information and supertags them according to Equation 2, where tH(z,,) is the </context>
<context position="19083" citStr="Srinivas (1997" startWordPosition="3155" endWordPosition="3156">classifiers. 3.5 Further Evaluation We also compare various models&apos; performance on base-NP detection and PP attachment disambiguation. The results will underscore the adroitness of the classifier combination model in using both local and long distance features. They will also show that, depending on the ultimate application, one model may be more appropriate than another model. A base-NP is a non-recursive NP structure whose detection is useful in many applications, such as information extraction. We extend our supertagging models to perform this task in a fashion similar to that described in Srinivas (1997b). Selected models have been trained on 200K words. Subsequently, after a model has supertagged the test corpus, a procedure detects base-NPs by scanning for appropriate sequences of supertags. Results for base-NP detection are shown in Table 4. Note that the mixed model performs nearly as well as the trigram model. Note also that the head trigram model is outperformed by the other models. We suspect that unlike the trigram model, the head model does not perform the accurate modeling of local context which is important for baseNP detection. In contrast, information about long distance depende</context>
<context position="27462" citStr="Srinivas (1997" startWordPosition="4612" endWordPosition="4613">lt is obtained by assigning a word w, a set of supertags tzi, -,tik where to t2, is the jth classifier&apos;s supertag assignment for word wi, the classifiers being the models discussed in Section 3. It achieves an accuracy of 95.21% with 1.26 supertags per word. 7Again, for the class C assign to a given word w„ we consider only those tags t, E C for which f(w„ lt,) &gt; 0. 0 Context CUss -Pr Confusion Class 0 Classifier Limon -X• N-Best 2 3 Ambiguity (Tags Per Word) Figure 2: Ambiguity versus Accuracy for Various Class Models 5 Future Work We are considering extending our work in several directions. Srinivas (1997b) discussed a lightweight dependency analyzer which assigns dependencies assuming that each word has been assigned a unique supertag. We are extending this algorithm to work with class based models which narrows down the number of supertags per word with much higher accuracy. Aside from the ngram modeling that was a focus of this paper, we would also like to explore using other kinds of models, such as maximum entropy. 6 Conclusions We have introduced two different kinds of models for the task of supertagging. Contextual models show that features for accurate supertagging only produce improve</context>
</contexts>
<marker>Srinivas, 1997</marker>
<rawString>B. Srinivas. 1997b. Performance Evaluation of Supertagging for Partial Parsing. In Proceedings of Fifth International Workshop on Parsing Technology, Boston, USA, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Weischedel</author>
<author>R Schwartz</author>
<author>J Palmucci</author>
<author>M Meteer</author>
<author>L Ramshaw</author>
</authors>
<title>Coping with ambiguity and unknown words through probabilistic models.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--2</pages>
<marker>Weischedel, Schwartz, Palmucci, Meteer, Ramshaw, 1993</marker>
<rawString>R. Weischedel., R. Schwartz, J. Palmucci, M. Meteer, and L. Ramshaw. 1993. Coping with ambiguity and unknown words through probabilistic models. Computational Linguistics, 19.2:359-382.</rawString>
</citation>
<citation valid="true">
<authors>
<author>The XTAG-Group</author>
</authors>
<title>A Lexicalized Tree Adjoining Grammar for English.</title>
<date>1995</date>
<tech>Technical Report IRCS 95-03,</tech>
<institution>University of Pennsylvania,</institution>
<location>Philadelphia, PA.</location>
<contexts>
<context position="5683" citStr="XTAG-Group (1995)" startWordPosition="881" endWordPosition="882">uch as Wall Street Journal (WSJ). In this work, we explore a variety of local techniques in order to improve the performance of supertagging. All of the models presented here perform smoothing using a Good-Turing discounting technique with Katz&apos;s backoff model. With exceptions where noted, our models were trained on one million words of Wall Street Journal data and tested on 48K words. The data and evaluation procedure are similar to that used in Srinivas (1997b). The data was derived by mapping structural information from the Penn Treebank WSJ corpus into supertags from the XTAG grammar (The XTAG-Group (1995)) using heuristics (Srinivas (1997a)). Using this data, the trigram model for supertagging achieves an accuracy of 91.37%, meaning that 91.37% of the words in the test corpus were assigned the correct supertag.&apos; 3 Contextual Models As noted in Srinivas (1997b), a trigram model often fails to capture the cooccurrence dependencies &apos;The supertagging accuracy of 92.2% reported in Srinivas (1997b) was based on a different supertag tagset; specifically, the supertag corpus was reannotated with detailed supertags for punctuation and with a different analysis for subordinating conjunctions. between a </context>
<context position="20901" citStr="XTAG-Group (1995)" startWordPosition="3460" endWordPosition="3461">able 4: Some contextual models&apos; results on baseNP chunking tachment task. As may be expected, the trigram model performs the worst on this task, presumably because it is restricted to considering purely local information. 4 Class Based Models Contextual models tag each word with the single most appropriate supertag. In many applications, however, it is sufficient to reduce ambiguity to a small number of supertags per word. For example, using traditional TAG parsing methods, such are described in Schabes (1990), it is inefficient to parse with a large LTAG grammar for English such as XTAG (The XTAG-Group (1995)). In these circumstances, a single word may be associated with hundreds of supertags. Reducing ambiguity to some small number k, say k &lt; 5 supertags per word&apos; would accelerate parsing considerably.5 As an alternative, once such a reduction in ambiguity has been achieved, partial parsing or other techniques could be employed to identify the best single supertag. These are the aims of class based models, which assign a small set of supertags to each word. It is related to work by Brown et al. (1992) where mutual information is used to cluster words into classes for language modeling. In our wor</context>
</contexts>
<marker>XTAG-Group, 1995</marker>
<rawString>The XTAG-Group. 1995. A Lexicalized Tree Adjoining Grammar for English. Technical Report IRCS 95-03, University of Pennsylvania, Philadelphia, PA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>