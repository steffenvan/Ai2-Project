<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.011771">
<title confidence="0.99513">
Active Learning-Based Elicitation for Semi-Supervised Word Alignment
</title>
<author confidence="0.897915">
Vamshi Ambati, Stephan Vogel and Jaime Carbonell
</author>
<email confidence="0.824308">
{vamshi,vogel,jgc}@cs.cmu.edu
</email>
<affiliation confidence="0.888723">
Language Technologies Institute, Carnegie Mellon University
5000 Forbes Avenue, Pittsburgh, PA 15213, USA
</affiliation>
<sectionHeader confidence="0.986566" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999346">
Semi-supervised word alignment aims to
improve the accuracy of automatic word
alignment by incorporating full or par-
tial manual alignments. Motivated by
standard active learning query sampling
frameworks like uncertainty-, margin- and
query-by-committee sampling we propose
multiple query strategies for the alignment
link selection task. Our experiments show
that by active selection of uncertain and
informative links, we reduce the overall
manual effort involved in elicitation of
alignment link data for training a semi-
supervised word aligner.
</bodyText>
<sectionHeader confidence="0.999518" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99994768627451">
Corpus-based approaches to machine translation
have become predominant, with phrase-based sta-
tistical machine translation (PB-SMT) (Koehn et
al., 2003) being the most actively progressing area.
The success of statistical approaches to MT can
be attributed to the IBM models (Brown et al.,
1993) that characterize word-level alignments in
parallel corpora. Parameters of these alignment
models are learnt in an unsupervised manner us-
ing the EM algorithm over sentence-level aligned
parallel corpora. While the ease of automati-
cally aligning sentences at the word-level with
tools like GIZA++ (Och and Ney, 2003) has en-
abled fast development of SMT systems for vari-
ous language pairs, the quality of alignment is typ-
ically quite low for language pairs like Chinese-
English, Arabic-English that diverge from the in-
dependence assumptions made by the generative
models. Increased parallel data enables better es-
timation of the model parameters, but a large num-
ber of language pairs still lack such resources.
Two directions of research have been pursued
for improving generative word alignment. The
first is to relax or update the independence as-
sumptions based on more information, usually
syntactic, from the language pairs (Cherry and
Lin, 2006; Fraser and Marcu, 2007a). The sec-
ond is to use extra annotation, typically word-level
human alignment for some sentence pairs, in con-
junction with the parallel data to learn alignment
in a semi-supervised manner. Our research is in
the direction of the latter, and aims to reduce the
effort involved in hand-generation of word align-
ments by using active learning strategies for care-
ful selection of word pairs to seek alignment.
Active learning for MT has not yet been ex-
plored to its full potential. Much of the litera-
ture has explored one task – selecting sentences
to translate and add to the training corpus (Haf-
fari and Sarkar, 2009). In this paper we explore
active learning for word alignment, where the in-
put to the active learner is a sentence pair (5, T)
and the annotation elicited from human is a set of
links {aij, bsi E 5, tj E T}. Unlike previous ap-
proaches, our work does not require elicitation of
full alignment for the sentence pair, which could
be effort-intensive. We propose active learning
query strategies to selectively elicit partial align-
ment information. Experiments in Section 5 show
that our selection strategies reduce alignment error
rates significantly over baseline.
</bodyText>
<sectionHeader confidence="0.999906" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9961145">
Researchers have begun to explore models that
use both labeled and unlabeled data to build
word-alignment models for MT. Fraser and Marcu
(2006) pose the problem of alignment as a search
problem in log-linear space with features com-
ing from the IBM alignment models. The log-
</bodyText>
<page confidence="0.987803">
365
</page>
<note confidence="0.507884">
Proceedings of the ACL 2010 Conference Short Papers, pages 365–370,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999676476190476">
linear model is trained on available labeled data
to improve performance. They propose a semi-
supervised training algorithm which alternates be-
tween discriminative error training on the la-
beled data to learn the weighting parameters and
maximum-likelihood EM training on unlabeled
data to estimate the parameters. Callison-Burch
et al. (2004) also improve alignment by interpolat-
ing human alignments with automatic alignments.
They observe that while working with such data
sets, alignments of higher quality should be given
a much higher weight than the lower-quality align-
ments. Wu et al. (2006) learn separate models
from labeled and unlabeled data using the standard
EM algorithm. The two models are then interpo-
lated to use as a learner in the semi-supervised
algorithm to improve word alignment. To our
knowledge, there is no prior work that has looked
at reducing human effort by selective elicitation of
partial word alignment using active learning tech-
niques.
</bodyText>
<sectionHeader confidence="0.973017" genericHeader="method">
3 Active Learning for Word Alignment
</sectionHeader>
<bodyText confidence="0.999954533333333">
Active learning attempts to optimize performance
by selecting the most informative instances to la-
bel where ‘informativeness’ is defined as maximal
expected improvement in accuracy. The objective
is to select optimal instance for an external expert
to label and then run the learning method on the
newly-labeled and previously-labeled instances to
minimize prediction or translation error, repeat-
ing until either the maximal number of external
queries is reached or a desired accuracy level is
achieved. Several studies (Tong and Koller, 2002;
Nguyen and Smeulders, 2004; Donmez and Car-
bonell, 2008) show that active learning greatly
helps to reduce the labeling effort in various clas-
sification tasks.
</bodyText>
<subsectionHeader confidence="0.999399">
3.1 Active Learning Setup
</subsectionHeader>
<bodyText confidence="0.974736347826087">
We discuss our active learning setup for word
alignment in Algorithm 1. We start with an un-
labeled dataset U = {(5k, Tk)}, indexed by k,
and a seed pool of partial alignment links A0 =
{ak ij,Vsi E 5k, tj E Tk}. This is usually an empty
set at iteration t = 0. We iterate for T itera-
tions. We take a pool-based active learning strat-
egy, where we have access to all the automatically
aligned links and we can score the links based
on our active learning query strategy. The query
strategy uses the automatically trained alignment
model Mt from current iteration t for scoring the
links. Re-training and re-tuning an SMT system
for each link at a time is computationally infeasi-
ble. We therefore perform batch learning by se-
lecting a set of N links scored high by our query
strategy. We seek manual corrections for the se-
lected links and add the alignment data to the
current labeled data set. The word-level aligned
labeled data is provided to our semi-supervised
word alignment algorithm for training an align-
ment model Mt+1 over U.
Algorithm 1 AL FOR WORD ALIGNMENT
</bodyText>
<listItem confidence="0.987874461538462">
1: Unlabeled Data Set: U = {(5k, Tk)}
2: Manual Alignment Set : A0 = {akij,Vsi E
5k, tj E Tk}
3: Train Semi-supervised Word Alignment using
(U, A0) — M0
4: N: batch size
5: fort = 0 to T do
6: Lt = LinkSelection(U,At,Mt,N)
7: Request Human Alignment for Lt
8: At+1 = At + Lt
9: Re-train Semi-Supervised Word Align-
ment on (U, At+1) — Mt+1
10: end for
</listItem>
<bodyText confidence="0.999931">
We can iteratively perform the algorithm for a
defined number of iterations T or until a certain
desired performance is reached, which is mea-
sured by alignment error rate (AER) (Fraser and
Marcu, 2007b) in the case of word alignment. In
a more typical scenario, since reducing human ef-
fort or cost of elicitation is the objective, we iterate
until the available budget is exhausted.
</bodyText>
<subsectionHeader confidence="0.999603">
3.2 Semi-Supervised Word Alignment
</subsectionHeader>
<bodyText confidence="0.9999976">
We use an extended version of MGIZA++ (Gao
and Vogel, 2008) to perform the constrained semi-
supervised word alignment. Manual alignments
are incorporated in the EM training phase of these
models as constraints that restrict the summation
over all possible alignment paths. Typically in the
EM procedure for IBM models, the training pro-
cedure requires for each source sentence position,
the summation over all positions in the target sen-
tence. The manual alignments allow for one-to-
many alignments and many-to-many alignments
in both directions. For each position i in the source
sentence, there can be more than one manually
aligned target word. The restricted training will
allow only those paths, which are consistent with
</bodyText>
<page confidence="0.994878">
366
</page>
<bodyText confidence="0.998766">
the manual alignments. Therefore, the restriction
of the alignment paths reduces to restricting the
summation in EM.
</bodyText>
<sectionHeader confidence="0.900288" genericHeader="method">
4 Query Strategies for Link Selection
</sectionHeader>
<bodyText confidence="0.99999375">
We propose multiple query selection strategies for
our active learning setup. The scoring criteria is
designed to select alignment links across sentence
pairs that are highly uncertain under current au-
tomatic translation models. These links are diffi-
cult to align correctly by automatic alignment and
will cause incorrect phrase pairs to be extracted in
the translation model, in turn hurting the transla-
tion quality of the SMT system. Manual correc-
tion of such links produces the maximal benefit to
the model. We would ideally like to elicit the least
number of manual corrections possible in order to
reduce the cost of data acquisition. In this section
we discuss our link selection strategies based on
the standard active learning paradigm of ‘uncer-
tainty sampling’(Lewis and Catlett, 1994). We use
the automatically trained translation model Bt for
scoring each link for uncertainty, which consists of
bidirectional translation lexicon tables computed
from the bidirectional alignments.
</bodyText>
<subsectionHeader confidence="0.983873">
4.1 Uncertainty Sampling: Bidirectional
Alignment Scores
</subsectionHeader>
<bodyText confidence="0.998111090909091">
The automatic Viterbi alignment produced by
the alignment models is used to obtain transla-
tion lexicons. These lexicons capture the condi-
tional distributions of source-given-target P(s/t)
and target-given-source P(t/s) probabilities at the
word level where si E S and tj E T. We de-
fine certainty of a link as the harmonic mean of the
bidirectional probabilities. The selection strategy
selects the least scoring links according to the for-
mula below which corresponds to links with max-
imum uncertainty:
</bodyText>
<equation confidence="0.9659895">
Score(aij/sI1, t1J) = 2 � P (tj/si) � P (si/tj)
P(tj/si) + P(si/tj) (1)
</equation>
<subsectionHeader confidence="0.9046065">
4.2 Confidence Sampling: Posterior
Alignment probabilities
</subsectionHeader>
<bodyText confidence="0.99953">
Confidence estimation for MT output is an in-
teresting area with meaningful initial exploration
(Blatz et al., 2004; Ueffing and Ney, 2007). Given
a sentence pair (sI1, tJ1) and its word alignment,
we compute two confidence metrics at alignment
link level – based on the posterior link probability
as seen in Equation 5. We select the alignment
links that the initial word aligner is least confi-
dent according to our metric and seek manual cor-
rection of the links. We use t2s to denote com-
putation using higher order (IBM4) target-given-
source models and s2t to denote source-given-
target models. Targeting some of the uncertain
parts of word alignment has already been shown
to improve translation quality in SMT (Huang,
2009). We use confidence metrics as an active
learning sampling strategy to obtain most informa-
tive links. We also experimented with other con-
fidence metrics as discussed in (Ueffing and Ney,
2007), especially the IBM 1 model score metric,
but it did not show significant improvement in this
task.
</bodyText>
<equation confidence="0.986229625">
Pt2s(aij,tJ1/sI1) = pt2s(tj/si,aijEA) (2)
EMi pt2s(tj/si)
ilti) = Ps2t(si/tj,aijEA)
Ps2t(aij, s (3)
EiN ps2t (si/tj )
Conf1(aij/S, T) = 2*t2s*Ps2t (4)
Pt2s+Ps2t
(5)
</equation>
<subsectionHeader confidence="0.981139">
4.3 Query by Committee
</subsectionHeader>
<bodyText confidence="0.999996111111111">
The generative alignments produced differ based
on the choice of direction of the language pair. We
use As2t to denote alignment in the source to target
direction and At2s to denote the target to source
direction. We consider these alignments to be two
experts that have two different views of the align-
ment process. We formulate our query strategy
to select links where the agreement differs across
these two alignments. In general query by com-
mittee is a standard sampling strategy in active
learning(Freund et al., 1997), where the commit-
tee consists of any number of experts, in this case
alignments, with varying opinions. We formulate
a query by committee sampling strategy for word
alignment as shown in Equation 6. In order to
break ties, we extend this approach to select the
link with higher average frequency of occurrence
of words involved in the link.
</bodyText>
<equation confidence="0.87007575">
Score(aij) = α (6)
{ 2 aij E As2t n At2s
1 aij E As2t U At2s
0 otherwise
</equation>
<subsectionHeader confidence="0.994684">
4.4 Margin Sampling
</subsectionHeader>
<bodyText confidence="0.997089">
The strategy for confidence based sampling only
considers information about the best scoring link
where α =
</bodyText>
<page confidence="0.971116">
367
</page>
<bodyText confidence="0.999184105263158">
conf(aij/S, T). However we could benefit from
information about the second best scoring link as
well. In typical multi-class classification prob-
lems, earlier work shows success using such a
‘margin based’ approach (Scheffer et al., 2001),
where the difference between the probabilities as-
signed by the underlying model to the first best
and second best labels is used as a sampling cri-
teria. We adapt such a margin-based approach to
link-selection using the Conf1 scoring function
discussed in the earlier sub-section. Our margin
technique is formulated below, where a1ij and
a2ij are potential first best and second best scor-
ing alignment links for a word at position i in the
source sentence S with translation T. The word
with minimum margin value is chosen for human
alignment. Intuitively such a word is a possible
candidate for mis-alignment due to the inherent
confusion in its target translation.
</bodyText>
<equation confidence="0.9881405">
Margin(i) _
Conf1( a1ij/S,T) −Conf1( a2ij/S,T)
</equation>
<sectionHeader confidence="0.998384" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.988835">
5.1 Data Setup
</subsectionHeader>
<bodyText confidence="0.999993857142857">
Our aim in this paper is to show that active learn-
ing can help select the most informative alignment
links that have high uncertainty according to a
given automatically trained model. We also show
that fixing such alignments leads to the maximum
reduction of error in word alignment, as measured
by AER. We compare this with a baseline where
links are selected at random for manual correction.
To run our experiments iteratively, we automate
the setup by using a parallel corpus for which the
gold-standard human alignment is already avail-
able. We select the Chinese-English language pair,
where we have access to 21,863 sentence pairs
along with complete manual alignment.
</bodyText>
<subsectionHeader confidence="0.882552">
5.2 Results
</subsectionHeader>
<bodyText confidence="0.9998751">
We first automatically align the Cn-En corpus us-
ing GIZA++ (Och and Ney, 2003). We then
use the learned model in running our link selec-
tion algorithm over the entire corpus to determine
the most uncertain links according to each active
learning strategy. The links are then looked up in
the gold-standard human alignment database and
corrected. In case a link is not present in the
gold-standard data, we introduce a NULL align-
ment, else we propose the alignment as given in
</bodyText>
<figureCaption confidence="0.990768">
Figure 1: Performance of active sampling strate-
gies for link selection
</figureCaption>
<bodyText confidence="0.99972990625">
the gold standard. We select the partial align-
ment as a set of alignment links and provide it to
our semi-supervised word aligner. We plot per-
formance curves as number of links used in each
iteration vs. the overall reduction of AER on the
corpus.
Query by committee performs worse than ran-
dom indicating that two alignments differing in
direction are not sufficient in deciding for uncer-
tainty. We will be exploring alternative formula-
tions to this strategy. We observe that confidence
based metrics perform significantly better than the
baseline. From the scatter plots in Figure 1 1 we
can say that using our best selection strategy one
achieves similar performance to the baseline, but
at a much lower cost of elicitation assuming cost
per link is uniform.
We also perform end-to-end machine transla-
tion experiments to show that our improvement
of alignment quality leads to an improvement of
translation scores. For this experiment, we train
a standard phrase-based SMT system (Koehn et
al., 2007) over the entire parallel corpus. We tune
on the MT-Eval 2004 dataset and test on a subset
of MT-Eval 2004 dataset consisting of 631 sen-
tences. We first obtain the baseline score where
no manual alignment was used. We also train a
configuration using gold standard manual align-
ment data for the parallel corpus. This is the max-
imum translation accuracy that we can achieve by
any link selection algorithm. We now take the
best link selection criteria, which is the confidence
</bodyText>
<footnote confidence="0.994105">
1X axis has number of links elicited on a log-scale
</footnote>
<page confidence="0.988816">
368
</page>
<table confidence="0.9994905">
System BLEU METEOR
Baseline 18.82 42.70
Human Alignment 19.96 44.22
Active Selection 20% 19.34 43.25
</table>
<tableCaption confidence="0.999851">
Table 1: Alignment and Translation Quality
</tableCaption>
<bodyText confidence="0.996569444444444">
based method and train a system by only selecting
20% of all the links. We observe that at this point
we have reduced the AER from 37.09 AER to
26.57 AER. The translation accuracy as measured
by BLEU (Papineni et al., 2002) and METEOR
(Lavie and Agarwal, 2007) also shows improve-
ment over baseline and approaches gold standard
quality. Therefore we achieve 45% of the possible
improvement by only using 20% elicitation effort.
</bodyText>
<subsectionHeader confidence="0.999108">
5.3 Batch Selection
</subsectionHeader>
<bodyText confidence="0.9738843125">
Re-training the word alignment models after elic-
iting every individual alignment link is infeasible.
In our data set of 21,863 sentences with 588,075
links, it would be computationally intensive to re-
train after eliciting even 100 links in a batch. We
therefore sample links as a discrete batch, and train
alignment models to report performance at fixed
points. Such a batch selection is only going to be
sub-optimal as the underlying model changes with
every alignment link and therefore becomes ‘stale’
for future selections. We observe that in some sce-
narios while fixing one alignment link could po-
tentially fix all the mis-alignments in a sentence
pair, our batch selection mechanism still samples
from the rest of the links in the sentence pair. We
experimented with an exponential decay function
over the number of links previously selected, in
order to discourage repeated sampling from the
same sentence pair. We performed an experiment
by selecting one of our best performing selection
strategies (conf) and ran it in both configurations
- one with the decay parameter (batchdecay) and
one without it (batch). As seen in Figure 2, the
decay function has an effect in the initial part of
the curve where sampling is sparse but the effect
gradually fades away as we observe more samples.
In the reported results we do not use batch decay,
but an optimal estimation of ‘staleness’ could lead
to better gains in batch link selection using active
learning.
Figure 2: Batch decay effects on Conf-posterior
sampling strategy
</bodyText>
<sectionHeader confidence="0.997901" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999900818181818">
Word-Alignment is a particularly challenging
problem and has been addressed in a completely
unsupervised manner thus far (Brown et al., 1993).
While generative alignment models have been suc-
cessful, lack of sufficient data, model assump-
tions and local optimum during training are well
known problems. Semi-supervised techniques use
partial manual alignment data to address some of
these issues. We have shown that active learning
strategies can reduce the effort involved in elicit-
ing human alignment data. The reduction in ef-
fort is due to careful selection of maximally un-
certain links that provide the most benefit to the
alignment model when used in a semi-supervised
training fashion. Experiments on Chinese-English
have shown considerable improvements. In future
we wish to work with word alignments for other
language pairs like Arabic and English. We have
tested out the feasibility of obtaining human word
alignment data using Amazon Mechanical Turk
and plan to obtain more data reduce the cost of
annotation.
</bodyText>
<sectionHeader confidence="0.998812" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999912">
This research was partially supported by DARPA
under grant NBCHC080097. Any opinions, find-
ings, and conclusions expressed in this paper are
those of the authors and do not necessarily reflect
the views of the DARPA. The first author would
like to thank Qin Gao for the semi-supervised
word alignment software and help with running
experiments.
</bodyText>
<page confidence="0.998535">
369
</page>
<sectionHeader confidence="0.996359" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9997146">
John Blatz, Erin Fitzgerald, George Foster, Simona Gan-
drabur, Cyril Goutte, Alex Kulesza, Alberto Sanchis, and
Nicola Ueffing. 2004. Confidence estimation for machine
translation. In Proceedings of Coling 2004, pages 315–
321, Geneva, Switzerland, Aug 23–Aug 27. COLING.
Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della
Pietra, and Robert L. Mercer. 1993. The mathematics
of statistical machine translation: parameter estimation.
Computational Linguistics, 19(2):263–311.
Chris Callison-Burch, David Talbot, and Miles Osborne.
2004. Statistical machine translation with word- and
sentence-aligned parallel corpora. In ACL 2004, page
175, Morristown, NJ, USA. Association for Computa-
tional Linguistics.
Colin Cherry and Dekang Lin. 2006. Soft syntactic con-
straints for word alignment through discriminative train-
ing. In Proceedings of the COLING/ACL on Main con-
ference poster sessions, pages 105–112, Morristown, NJ,
USA.
Pinar Donmez and Jaime G. Carbonell. 2008. Optimizing es-
timated loss reduction for active sampling in rank learning.
In ICML ’08: Proceedings of the 25th international con-
ference on Machine learning, pages 248–255, New York,
NY, USA. ACM.
Alexander Fraser and Daniel Marcu. 2006. Semi-supervised
training for statistical word alignment. In ACL-44: Pro-
ceedings of the 21st International Conference on Compu-
tational Linguistics and the 44th annual meeting of the
Association for Computational Linguistics, pages 769–
776, Morristown, NJ, USA. Association for Computa-
tional Linguistics.
Alexander Fraser and Daniel Marcu. 2007a. Getting the
structure right for word alignment: LEAF. In Proceedings
of the 2007 Joint Conference on EMNLP-CoNLL, pages
51–60.
Alexander Fraser and Daniel Marcu. 2007b. Measuring word
alignment quality for statistical machine translation. Com-
put. Linguist., 33(3):293–303.
Yoav Freund, Sebastian H. Seung, Eli Shamir, and Naftali
Tishby. 1997. Selective sampling using the query by com-
mittee algorithm. Machine. Learning., 28(2-3):133–168.
Qin Gao and Stephan Vogel. 2008. Parallel implementa-
tions of word alignment tool. In Software Engineering,
Testing, and Quality Assurance for Natural Language Pro-
cessing, pages 49–57, Columbus, Ohio, June. Association
for Computational Linguistics.
Gholamreza Haffari and Anoop Sarkar. 2009. Active learn-
ing for multilingual statistical machine translation. In
Proceedings of the Joint Conference of the 47th Annual
Meeting of the ACL and the 4th International Joint Con-
ference on Natural Language Processing of the AFNLP,
pages 181–189, Suntec, Singapore, August. Association
for Computational Linguistics.
Fei Huang. 2009. Confidence measure for word alignment.
In Proceedings of the Joint ACL and IJCNLP, pages 932–
940, Suntec, Singapore, August. Association for Compu-
tational Linguistics.
Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In Proc. of the
HLT/NAACL, Edomonton, Canada.
Philipp Koehn, Hieu Hoang, Alexandra Birch Mayne,
Christopher Callison-Burch, Marcello Federico, Nicola
Bertoldi, Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: Open source
toolkit for statistical machine translation. In ACL Demon-
stration Session.
Alon Lavie and Abhaya Agarwal. 2007. Meteor: an auto-
matic metric for mt evaluation with high levels of corre-
lation with human judgments. In WMT 2007, pages 228–
231, Morristown, NJ, USA.
David D. Lewis and Jason Catlett. 1994. Heterogeneous un-
certainty sampling for supervised learning. In In Proceed-
ings of the Eleventh International Conference on Machine
Learning, pages 148–156. Morgan Kaufmann.
Hieu T. Nguyen and Arnold Smeulders. 2004. Active learn-
ing using pre-clustering. In ICML.
Franz Josef Och and Hermann Ney. 2003. A systematic com-
parison of various statistical alignment models. Computa-
tional Linguistics, pages 19–51.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing
Zhu. 2002. Bleu: a method for automatic evaluation of
machine translation. In ACL 2002, pages 311–318, Mor-
ristown, NJ, USA.
Tobias Scheffer, Christian Decomain, and Stefan Wrobel.
2001. Active hidden markov models for information ex-
traction. In IDA ’01: Proceedings of the 4th Interna-
tional Conference on Advances in Intelligent Data Anal-
ysis, pages 309–318, London, UK. Springer-Verlag.
Simon Tong and Daphne Koller. 2002. Support vector ma-
chine active learning with applications to text classifica-
tion. Journal of Machine Learning, pages 45–66.
Nicola Ueffing and Hermann Ney. 2007. Word-level con-
fidence estimation for machine translation. Comput. Lin-
guist., 33(1):9–40.
Hua Wu, Haifeng Wang, and Zhanyi Liu. 2006. Boost-
ing statistical word alignment using labeled and unlabeled
data. In Proceedings of the COLING/ACL on Main con-
ference poster sessions, pages 913–920, Morristown, NJ,
USA. Association for Computational Linguistics.
</reference>
<page confidence="0.998269">
370
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.843674">
<title confidence="0.999644">Active Learning-Based Elicitation for Semi-Supervised Word Alignment</title>
<author confidence="0.999192">Vamshi Ambati</author>
<author confidence="0.999192">Stephan Vogel</author>
<author confidence="0.999192">Jaime Carbonell</author>
<email confidence="0.998431">vamshi@cs.cmu.edu</email>
<email confidence="0.998431">vogel@cs.cmu.edu</email>
<email confidence="0.998431">jgc@cs.cmu.edu</email>
<affiliation confidence="0.99556">Language Technologies Institute, Carnegie Mellon University</affiliation>
<address confidence="0.999896">5000 Forbes Avenue, Pittsburgh, PA 15213, USA</address>
<abstract confidence="0.9899448">Semi-supervised word alignment aims to improve the accuracy of automatic word alignment by incorporating full or partial manual alignments. Motivated by standard active learning query sampling frameworks like uncertainty-, marginand query-by-committee sampling we propose multiple query strategies for the alignment link selection task. Our experiments show that by active selection of uncertain and informative links, we reduce the overall manual effort involved in elicitation of alignment link data for training a semisupervised word aligner.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>John Blatz</author>
<author>Erin Fitzgerald</author>
<author>George Foster</author>
<author>Simona Gandrabur</author>
<author>Cyril Goutte</author>
<author>Alex Kulesza</author>
<author>Alberto Sanchis</author>
<author>Nicola Ueffing</author>
</authors>
<title>Confidence estimation for machine translation.</title>
<date>2004</date>
<booktitle>In Proceedings of Coling</booktitle>
<pages>315--321</pages>
<publisher>COLING.</publisher>
<location>Geneva, Switzerland,</location>
<contexts>
<context position="9962" citStr="Blatz et al., 2004" startWordPosition="1579" endWordPosition="1582">he conditional distributions of source-given-target P(s/t) and target-given-source P(t/s) probabilities at the word level where si E S and tj E T. We define certainty of a link as the harmonic mean of the bidirectional probabilities. The selection strategy selects the least scoring links according to the formula below which corresponds to links with maximum uncertainty: Score(aij/sI1, t1J) = 2 � P (tj/si) � P (si/tj) P(tj/si) + P(si/tj) (1) 4.2 Confidence Sampling: Posterior Alignment probabilities Confidence estimation for MT output is an interesting area with meaningful initial exploration (Blatz et al., 2004; Ueffing and Ney, 2007). Given a sentence pair (sI1, tJ1) and its word alignment, we compute two confidence metrics at alignment link level – based on the posterior link probability as seen in Equation 5. We select the alignment links that the initial word aligner is least confident according to our metric and seek manual correction of the links. We use t2s to denote computation using higher order (IBM4) target-givensource models and s2t to denote source-giventarget models. Targeting some of the uncertain parts of word alignment has already been shown to improve translation quality in SMT (Hu</context>
</contexts>
<marker>Blatz, Fitzgerald, Foster, Gandrabur, Goutte, Kulesza, Sanchis, Ueffing, 2004</marker>
<rawString>John Blatz, Erin Fitzgerald, George Foster, Simona Gandrabur, Cyril Goutte, Alex Kulesza, Alberto Sanchis, and Nicola Ueffing. 2004. Confidence estimation for machine translation. In Proceedings of Coling 2004, pages 315– 321, Geneva, Switzerland, Aug 23–Aug 27. COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Vincent J Della Pietra</author>
<author>Stephen A Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="1120" citStr="Brown et al., 1993" startWordPosition="147" endWordPosition="150">ry-by-committee sampling we propose multiple query strategies for the alignment link selection task. Our experiments show that by active selection of uncertain and informative links, we reduce the overall manual effort involved in elicitation of alignment link data for training a semisupervised word aligner. 1 Introduction Corpus-based approaches to machine translation have become predominant, with phrase-based statistical machine translation (PB-SMT) (Koehn et al., 2003) being the most actively progressing area. The success of statistical approaches to MT can be attributed to the IBM models (Brown et al., 1993) that characterize word-level alignments in parallel corpora. Parameters of these alignment models are learnt in an unsupervised manner using the EM algorithm over sentence-level aligned parallel corpora. While the ease of automatically aligning sentences at the word-level with tools like GIZA++ (Och and Ney, 2003) has enabled fast development of SMT systems for various language pairs, the quality of alignment is typically quite low for language pairs like ChineseEnglish, Arabic-English that diverge from the independence assumptions made by the generative models. Increased parallel data enable</context>
<context position="18159" citStr="Brown et al., 1993" startWordPosition="2935" endWordPosition="2938">(batchdecay) and one without it (batch). As seen in Figure 2, the decay function has an effect in the initial part of the curve where sampling is sparse but the effect gradually fades away as we observe more samples. In the reported results we do not use batch decay, but an optimal estimation of ‘staleness’ could lead to better gains in batch link selection using active learning. Figure 2: Batch decay effects on Conf-posterior sampling strategy 6 Conclusion and Future Work Word-Alignment is a particularly challenging problem and has been addressed in a completely unsupervised manner thus far (Brown et al., 1993). While generative alignment models have been successful, lack of sufficient data, model assumptions and local optimum during training are well known problems. Semi-supervised techniques use partial manual alignment data to address some of these issues. We have shown that active learning strategies can reduce the effort involved in eliciting human alignment data. The reduction in effort is due to careful selection of maximally uncertain links that provide the most benefit to the alignment model when used in a semi-supervised training fashion. Experiments on Chinese-English have shown considera</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: parameter estimation. Computational Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>David Talbot</author>
<author>Miles Osborne</author>
</authors>
<title>Statistical machine translation with word- and sentence-aligned parallel corpora.</title>
<date>2004</date>
<booktitle>In ACL 2004,</booktitle>
<pages>175</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="4055" citStr="Callison-Burch et al. (2004)" startWordPosition="617" endWordPosition="620">6) pose the problem of alignment as a search problem in log-linear space with features coming from the IBM alignment models. The log365 Proceedings of the ACL 2010 Conference Short Papers, pages 365–370, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics linear model is trained on available labeled data to improve performance. They propose a semisupervised training algorithm which alternates between discriminative error training on the labeled data to learn the weighting parameters and maximum-likelihood EM training on unlabeled data to estimate the parameters. Callison-Burch et al. (2004) also improve alignment by interpolating human alignments with automatic alignments. They observe that while working with such data sets, alignments of higher quality should be given a much higher weight than the lower-quality alignments. Wu et al. (2006) learn separate models from labeled and unlabeled data using the standard EM algorithm. The two models are then interpolated to use as a learner in the semi-supervised algorithm to improve word alignment. To our knowledge, there is no prior work that has looked at reducing human effort by selective elicitation of partial word alignment using a</context>
</contexts>
<marker>Callison-Burch, Talbot, Osborne, 2004</marker>
<rawString>Chris Callison-Burch, David Talbot, and Miles Osborne. 2004. Statistical machine translation with word- and sentence-aligned parallel corpora. In ACL 2004, page 175, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Cherry</author>
<author>Dekang Lin</author>
</authors>
<title>Soft syntactic constraints for word alignment through discriminative training.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL on Main conference poster sessions,</booktitle>
<pages>105--112</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="2067" citStr="Cherry and Lin, 2006" startWordPosition="295" endWordPosition="298">d fast development of SMT systems for various language pairs, the quality of alignment is typically quite low for language pairs like ChineseEnglish, Arabic-English that diverge from the independence assumptions made by the generative models. Increased parallel data enables better estimation of the model parameters, but a large number of language pairs still lack such resources. Two directions of research have been pursued for improving generative word alignment. The first is to relax or update the independence assumptions based on more information, usually syntactic, from the language pairs (Cherry and Lin, 2006; Fraser and Marcu, 2007a). The second is to use extra annotation, typically word-level human alignment for some sentence pairs, in conjunction with the parallel data to learn alignment in a semi-supervised manner. Our research is in the direction of the latter, and aims to reduce the effort involved in hand-generation of word alignments by using active learning strategies for careful selection of word pairs to seek alignment. Active learning for MT has not yet been explored to its full potential. Much of the literature has explored one task – selecting sentences to translate and add to the tr</context>
</contexts>
<marker>Cherry, Lin, 2006</marker>
<rawString>Colin Cherry and Dekang Lin. 2006. Soft syntactic constraints for word alignment through discriminative training. In Proceedings of the COLING/ACL on Main conference poster sessions, pages 105–112, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pinar Donmez</author>
<author>Jaime G Carbonell</author>
</authors>
<title>Optimizing estimated loss reduction for active sampling in rank learning.</title>
<date>2008</date>
<booktitle>In ICML ’08: Proceedings of the 25th international conference on Machine learning,</booktitle>
<pages>248--255</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="5318" citStr="Donmez and Carbonell, 2008" startWordPosition="812" endWordPosition="816">Learning for Word Alignment Active learning attempts to optimize performance by selecting the most informative instances to label where ‘informativeness’ is defined as maximal expected improvement in accuracy. The objective is to select optimal instance for an external expert to label and then run the learning method on the newly-labeled and previously-labeled instances to minimize prediction or translation error, repeating until either the maximal number of external queries is reached or a desired accuracy level is achieved. Several studies (Tong and Koller, 2002; Nguyen and Smeulders, 2004; Donmez and Carbonell, 2008) show that active learning greatly helps to reduce the labeling effort in various classification tasks. 3.1 Active Learning Setup We discuss our active learning setup for word alignment in Algorithm 1. We start with an unlabeled dataset U = {(5k, Tk)}, indexed by k, and a seed pool of partial alignment links A0 = {ak ij,Vsi E 5k, tj E Tk}. This is usually an empty set at iteration t = 0. We iterate for T iterations. We take a pool-based active learning strategy, where we have access to all the automatically aligned links and we can score the links based on our active learning query strategy. T</context>
</contexts>
<marker>Donmez, Carbonell, 2008</marker>
<rawString>Pinar Donmez and Jaime G. Carbonell. 2008. Optimizing estimated loss reduction for active sampling in rank learning. In ICML ’08: Proceedings of the 25th international conference on Machine learning, pages 248–255, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Fraser</author>
<author>Daniel Marcu</author>
</authors>
<title>Semi-supervised training for statistical word alignment.</title>
<date>2006</date>
<booktitle>In ACL-44: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>769--776</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="3429" citStr="Fraser and Marcu (2006)" startWordPosition="523" endWordPosition="526">r is a sentence pair (5, T) and the annotation elicited from human is a set of links {aij, bsi E 5, tj E T}. Unlike previous approaches, our work does not require elicitation of full alignment for the sentence pair, which could be effort-intensive. We propose active learning query strategies to selectively elicit partial alignment information. Experiments in Section 5 show that our selection strategies reduce alignment error rates significantly over baseline. 2 Related Work Researchers have begun to explore models that use both labeled and unlabeled data to build word-alignment models for MT. Fraser and Marcu (2006) pose the problem of alignment as a search problem in log-linear space with features coming from the IBM alignment models. The log365 Proceedings of the ACL 2010 Conference Short Papers, pages 365–370, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics linear model is trained on available labeled data to improve performance. They propose a semisupervised training algorithm which alternates between discriminative error training on the labeled data to learn the weighting parameters and maximum-likelihood EM training on unlabeled data to estimate the parameters. Ca</context>
</contexts>
<marker>Fraser, Marcu, 2006</marker>
<rawString>Alexander Fraser and Daniel Marcu. 2006. Semi-supervised training for statistical word alignment. In ACL-44: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 769– 776, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Fraser</author>
<author>Daniel Marcu</author>
</authors>
<title>Getting the structure right for word alignment: LEAF.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on EMNLP-CoNLL,</booktitle>
<pages>51--60</pages>
<contexts>
<context position="2091" citStr="Fraser and Marcu, 2007" startWordPosition="299" endWordPosition="302">SMT systems for various language pairs, the quality of alignment is typically quite low for language pairs like ChineseEnglish, Arabic-English that diverge from the independence assumptions made by the generative models. Increased parallel data enables better estimation of the model parameters, but a large number of language pairs still lack such resources. Two directions of research have been pursued for improving generative word alignment. The first is to relax or update the independence assumptions based on more information, usually syntactic, from the language pairs (Cherry and Lin, 2006; Fraser and Marcu, 2007a). The second is to use extra annotation, typically word-level human alignment for some sentence pairs, in conjunction with the parallel data to learn alignment in a semi-supervised manner. Our research is in the direction of the latter, and aims to reduce the effort involved in hand-generation of word alignments by using active learning strategies for careful selection of word pairs to seek alignment. Active learning for MT has not yet been explored to its full potential. Much of the literature has explored one task – selecting sentences to translate and add to the training corpus (Haffari a</context>
<context position="7065" citStr="Fraser and Marcu, 2007" startWordPosition="1131" endWordPosition="1134">ining an alignment model Mt+1 over U. Algorithm 1 AL FOR WORD ALIGNMENT 1: Unlabeled Data Set: U = {(5k, Tk)} 2: Manual Alignment Set : A0 = {akij,Vsi E 5k, tj E Tk} 3: Train Semi-supervised Word Alignment using (U, A0) — M0 4: N: batch size 5: fort = 0 to T do 6: Lt = LinkSelection(U,At,Mt,N) 7: Request Human Alignment for Lt 8: At+1 = At + Lt 9: Re-train Semi-Supervised Word Alignment on (U, At+1) — Mt+1 10: end for We can iteratively perform the algorithm for a defined number of iterations T or until a certain desired performance is reached, which is measured by alignment error rate (AER) (Fraser and Marcu, 2007b) in the case of word alignment. In a more typical scenario, since reducing human effort or cost of elicitation is the objective, we iterate until the available budget is exhausted. 3.2 Semi-Supervised Word Alignment We use an extended version of MGIZA++ (Gao and Vogel, 2008) to perform the constrained semisupervised word alignment. Manual alignments are incorporated in the EM training phase of these models as constraints that restrict the summation over all possible alignment paths. Typically in the EM procedure for IBM models, the training procedure requires for each source sentence positio</context>
</contexts>
<marker>Fraser, Marcu, 2007</marker>
<rawString>Alexander Fraser and Daniel Marcu. 2007a. Getting the structure right for word alignment: LEAF. In Proceedings of the 2007 Joint Conference on EMNLP-CoNLL, pages 51–60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Fraser</author>
<author>Daniel Marcu</author>
</authors>
<title>Measuring word alignment quality for statistical machine translation.</title>
<date>2007</date>
<journal>Comput. Linguist.,</journal>
<volume>33</volume>
<issue>3</issue>
<contexts>
<context position="2091" citStr="Fraser and Marcu, 2007" startWordPosition="299" endWordPosition="302">SMT systems for various language pairs, the quality of alignment is typically quite low for language pairs like ChineseEnglish, Arabic-English that diverge from the independence assumptions made by the generative models. Increased parallel data enables better estimation of the model parameters, but a large number of language pairs still lack such resources. Two directions of research have been pursued for improving generative word alignment. The first is to relax or update the independence assumptions based on more information, usually syntactic, from the language pairs (Cherry and Lin, 2006; Fraser and Marcu, 2007a). The second is to use extra annotation, typically word-level human alignment for some sentence pairs, in conjunction with the parallel data to learn alignment in a semi-supervised manner. Our research is in the direction of the latter, and aims to reduce the effort involved in hand-generation of word alignments by using active learning strategies for careful selection of word pairs to seek alignment. Active learning for MT has not yet been explored to its full potential. Much of the literature has explored one task – selecting sentences to translate and add to the training corpus (Haffari a</context>
<context position="7065" citStr="Fraser and Marcu, 2007" startWordPosition="1131" endWordPosition="1134">ining an alignment model Mt+1 over U. Algorithm 1 AL FOR WORD ALIGNMENT 1: Unlabeled Data Set: U = {(5k, Tk)} 2: Manual Alignment Set : A0 = {akij,Vsi E 5k, tj E Tk} 3: Train Semi-supervised Word Alignment using (U, A0) — M0 4: N: batch size 5: fort = 0 to T do 6: Lt = LinkSelection(U,At,Mt,N) 7: Request Human Alignment for Lt 8: At+1 = At + Lt 9: Re-train Semi-Supervised Word Alignment on (U, At+1) — Mt+1 10: end for We can iteratively perform the algorithm for a defined number of iterations T or until a certain desired performance is reached, which is measured by alignment error rate (AER) (Fraser and Marcu, 2007b) in the case of word alignment. In a more typical scenario, since reducing human effort or cost of elicitation is the objective, we iterate until the available budget is exhausted. 3.2 Semi-Supervised Word Alignment We use an extended version of MGIZA++ (Gao and Vogel, 2008) to perform the constrained semisupervised word alignment. Manual alignments are incorporated in the EM training phase of these models as constraints that restrict the summation over all possible alignment paths. Typically in the EM procedure for IBM models, the training procedure requires for each source sentence positio</context>
</contexts>
<marker>Fraser, Marcu, 2007</marker>
<rawString>Alexander Fraser and Daniel Marcu. 2007b. Measuring word alignment quality for statistical machine translation. Comput. Linguist., 33(3):293–303.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Freund</author>
<author>Sebastian H Seung</author>
<author>Eli Shamir</author>
<author>Naftali Tishby</author>
</authors>
<title>Selective sampling using the query by committee algorithm.</title>
<date>1997</date>
<journal>Machine. Learning.,</journal>
<pages>28--2</pages>
<contexts>
<context position="11576" citStr="Freund et al., 1997" startWordPosition="1844" endWordPosition="1847">j, s (3) EiN ps2t (si/tj ) Conf1(aij/S, T) = 2*t2s*Ps2t (4) Pt2s+Ps2t (5) 4.3 Query by Committee The generative alignments produced differ based on the choice of direction of the language pair. We use As2t to denote alignment in the source to target direction and At2s to denote the target to source direction. We consider these alignments to be two experts that have two different views of the alignment process. We formulate our query strategy to select links where the agreement differs across these two alignments. In general query by committee is a standard sampling strategy in active learning(Freund et al., 1997), where the committee consists of any number of experts, in this case alignments, with varying opinions. We formulate a query by committee sampling strategy for word alignment as shown in Equation 6. In order to break ties, we extend this approach to select the link with higher average frequency of occurrence of words involved in the link. Score(aij) = α (6) { 2 aij E As2t n At2s 1 aij E As2t U At2s 0 otherwise 4.4 Margin Sampling The strategy for confidence based sampling only considers information about the best scoring link where α = 367 conf(aij/S, T). However we could benefit from informa</context>
</contexts>
<marker>Freund, Seung, Shamir, Tishby, 1997</marker>
<rawString>Yoav Freund, Sebastian H. Seung, Eli Shamir, and Naftali Tishby. 1997. Selective sampling using the query by committee algorithm. Machine. Learning., 28(2-3):133–168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qin Gao</author>
<author>Stephan Vogel</author>
</authors>
<title>Parallel implementations of word alignment tool.</title>
<date>2008</date>
<booktitle>In Software Engineering, Testing, and Quality Assurance for Natural Language Processing,</booktitle>
<pages>49--57</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<contexts>
<context position="7342" citStr="Gao and Vogel, 2008" startWordPosition="1177" endWordPosition="1180">tion(U,At,Mt,N) 7: Request Human Alignment for Lt 8: At+1 = At + Lt 9: Re-train Semi-Supervised Word Alignment on (U, At+1) — Mt+1 10: end for We can iteratively perform the algorithm for a defined number of iterations T or until a certain desired performance is reached, which is measured by alignment error rate (AER) (Fraser and Marcu, 2007b) in the case of word alignment. In a more typical scenario, since reducing human effort or cost of elicitation is the objective, we iterate until the available budget is exhausted. 3.2 Semi-Supervised Word Alignment We use an extended version of MGIZA++ (Gao and Vogel, 2008) to perform the constrained semisupervised word alignment. Manual alignments are incorporated in the EM training phase of these models as constraints that restrict the summation over all possible alignment paths. Typically in the EM procedure for IBM models, the training procedure requires for each source sentence position, the summation over all positions in the target sentence. The manual alignments allow for one-tomany alignments and many-to-many alignments in both directions. For each position i in the source sentence, there can be more than one manually aligned target word. The restricted</context>
</contexts>
<marker>Gao, Vogel, 2008</marker>
<rawString>Qin Gao and Stephan Vogel. 2008. Parallel implementations of word alignment tool. In Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 49–57, Columbus, Ohio, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gholamreza Haffari</author>
<author>Anoop Sarkar</author>
</authors>
<title>Active learning for multilingual statistical machine translation.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</booktitle>
<pages>181--189</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Suntec, Singapore,</location>
<contexts>
<context position="2707" citStr="Haffari and Sarkar, 2009" startWordPosition="404" endWordPosition="408">rcu, 2007a). The second is to use extra annotation, typically word-level human alignment for some sentence pairs, in conjunction with the parallel data to learn alignment in a semi-supervised manner. Our research is in the direction of the latter, and aims to reduce the effort involved in hand-generation of word alignments by using active learning strategies for careful selection of word pairs to seek alignment. Active learning for MT has not yet been explored to its full potential. Much of the literature has explored one task – selecting sentences to translate and add to the training corpus (Haffari and Sarkar, 2009). In this paper we explore active learning for word alignment, where the input to the active learner is a sentence pair (5, T) and the annotation elicited from human is a set of links {aij, bsi E 5, tj E T}. Unlike previous approaches, our work does not require elicitation of full alignment for the sentence pair, which could be effort-intensive. We propose active learning query strategies to selectively elicit partial alignment information. Experiments in Section 5 show that our selection strategies reduce alignment error rates significantly over baseline. 2 Related Work Researchers have begun</context>
</contexts>
<marker>Haffari, Sarkar, 2009</marker>
<rawString>Gholamreza Haffari and Anoop Sarkar. 2009. Active learning for multilingual statistical machine translation. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 181–189, Suntec, Singapore, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Huang</author>
</authors>
<title>Confidence measure for word alignment.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint ACL and IJCNLP,</booktitle>
<pages>932--940</pages>
<institution>Suntec, Singapore, August. Association for Computational Linguistics.</institution>
<contexts>
<context position="10572" citStr="Huang, 2009" startWordPosition="1684" endWordPosition="1685">04; Ueffing and Ney, 2007). Given a sentence pair (sI1, tJ1) and its word alignment, we compute two confidence metrics at alignment link level – based on the posterior link probability as seen in Equation 5. We select the alignment links that the initial word aligner is least confident according to our metric and seek manual correction of the links. We use t2s to denote computation using higher order (IBM4) target-givensource models and s2t to denote source-giventarget models. Targeting some of the uncertain parts of word alignment has already been shown to improve translation quality in SMT (Huang, 2009). We use confidence metrics as an active learning sampling strategy to obtain most informative links. We also experimented with other confidence metrics as discussed in (Ueffing and Ney, 2007), especially the IBM 1 model score metric, but it did not show significant improvement in this task. Pt2s(aij,tJ1/sI1) = pt2s(tj/si,aijEA) (2) EMi pt2s(tj/si) ilti) = Ps2t(si/tj,aijEA) Ps2t(aij, s (3) EiN ps2t (si/tj ) Conf1(aij/S, T) = 2*t2s*Ps2t (4) Pt2s+Ps2t (5) 4.3 Query by Committee The generative alignments produced differ based on the choice of direction of the language pair. We use As2t to denote </context>
</contexts>
<marker>Huang, 2009</marker>
<rawString>Fei Huang. 2009. Confidence measure for word alignment. In Proceedings of the Joint ACL and IJCNLP, pages 932– 940, Suntec, Singapore, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proc. of the HLT/NAACL,</booktitle>
<location>Edomonton, Canada.</location>
<contexts>
<context position="977" citStr="Koehn et al., 2003" startWordPosition="123" endWordPosition="126">rporating full or partial manual alignments. Motivated by standard active learning query sampling frameworks like uncertainty-, margin- and query-by-committee sampling we propose multiple query strategies for the alignment link selection task. Our experiments show that by active selection of uncertain and informative links, we reduce the overall manual effort involved in elicitation of alignment link data for training a semisupervised word aligner. 1 Introduction Corpus-based approaches to machine translation have become predominant, with phrase-based statistical machine translation (PB-SMT) (Koehn et al., 2003) being the most actively progressing area. The success of statistical approaches to MT can be attributed to the IBM models (Brown et al., 1993) that characterize word-level alignments in parallel corpora. Parameters of these alignment models are learnt in an unsupervised manner using the EM algorithm over sentence-level aligned parallel corpora. While the ease of automatically aligning sentences at the word-level with tools like GIZA++ (Och and Ney, 2003) has enabled fast development of SMT systems for various language pairs, the quality of alignment is typically quite low for language pairs l</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proc. of the HLT/NAACL, Edomonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch Mayne</author>
<author>Christopher Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In ACL Demonstration Session.</booktitle>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra</location>
<contexts>
<context position="15338" citStr="Koehn et al., 2007" startWordPosition="2469" endWordPosition="2472">uncertainty. We will be exploring alternative formulations to this strategy. We observe that confidence based metrics perform significantly better than the baseline. From the scatter plots in Figure 1 1 we can say that using our best selection strategy one achieves similar performance to the baseline, but at a much lower cost of elicitation assuming cost per link is uniform. We also perform end-to-end machine translation experiments to show that our improvement of alignment quality leads to an improvement of translation scores. For this experiment, we train a standard phrase-based SMT system (Koehn et al., 2007) over the entire parallel corpus. We tune on the MT-Eval 2004 dataset and test on a subset of MT-Eval 2004 dataset consisting of 631 sentences. We first obtain the baseline score where no manual alignment was used. We also train a configuration using gold standard manual alignment data for the parallel corpus. This is the maximum translation accuracy that we can achieve by any link selection algorithm. We now take the best link selection criteria, which is the confidence 1X axis has number of links elicited on a log-scale 368 System BLEU METEOR Baseline 18.82 42.70 Human Alignment 19.96 44.22 </context>
</contexts>
<marker>Koehn, Hoang, Mayne, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch Mayne, Christopher Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In ACL Demonstration Session.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alon Lavie</author>
<author>Abhaya Agarwal</author>
</authors>
<title>Meteor: an automatic metric for mt evaluation with high levels of correlation with human judgments.</title>
<date>2007</date>
<booktitle>In WMT 2007,</booktitle>
<pages>228--231</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="16274" citStr="Lavie and Agarwal, 2007" startWordPosition="2631" endWordPosition="2634">This is the maximum translation accuracy that we can achieve by any link selection algorithm. We now take the best link selection criteria, which is the confidence 1X axis has number of links elicited on a log-scale 368 System BLEU METEOR Baseline 18.82 42.70 Human Alignment 19.96 44.22 Active Selection 20% 19.34 43.25 Table 1: Alignment and Translation Quality based method and train a system by only selecting 20% of all the links. We observe that at this point we have reduced the AER from 37.09 AER to 26.57 AER. The translation accuracy as measured by BLEU (Papineni et al., 2002) and METEOR (Lavie and Agarwal, 2007) also shows improvement over baseline and approaches gold standard quality. Therefore we achieve 45% of the possible improvement by only using 20% elicitation effort. 5.3 Batch Selection Re-training the word alignment models after eliciting every individual alignment link is infeasible. In our data set of 21,863 sentences with 588,075 links, it would be computationally intensive to retrain after eliciting even 100 links in a batch. We therefore sample links as a discrete batch, and train alignment models to report performance at fixed points. Such a batch selection is only going to be sub-opti</context>
</contexts>
<marker>Lavie, Agarwal, 2007</marker>
<rawString>Alon Lavie and Abhaya Agarwal. 2007. Meteor: an automatic metric for mt evaluation with high levels of correlation with human judgments. In WMT 2007, pages 228– 231, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David D Lewis</author>
<author>Jason Catlett</author>
</authors>
<title>Heterogeneous uncertainty sampling for supervised learning. In</title>
<date>1994</date>
<booktitle>In Proceedings of the Eleventh International Conference on Machine Learning,</booktitle>
<pages>148--156</pages>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="8960" citStr="Lewis and Catlett, 1994" startWordPosition="1430" endWordPosition="1433">ghly uncertain under current automatic translation models. These links are difficult to align correctly by automatic alignment and will cause incorrect phrase pairs to be extracted in the translation model, in turn hurting the translation quality of the SMT system. Manual correction of such links produces the maximal benefit to the model. We would ideally like to elicit the least number of manual corrections possible in order to reduce the cost of data acquisition. In this section we discuss our link selection strategies based on the standard active learning paradigm of ‘uncertainty sampling’(Lewis and Catlett, 1994). We use the automatically trained translation model Bt for scoring each link for uncertainty, which consists of bidirectional translation lexicon tables computed from the bidirectional alignments. 4.1 Uncertainty Sampling: Bidirectional Alignment Scores The automatic Viterbi alignment produced by the alignment models is used to obtain translation lexicons. These lexicons capture the conditional distributions of source-given-target P(s/t) and target-given-source P(t/s) probabilities at the word level where si E S and tj E T. We define certainty of a link as the harmonic mean of the bidirection</context>
</contexts>
<marker>Lewis, Catlett, 1994</marker>
<rawString>David D. Lewis and Jason Catlett. 1994. Heterogeneous uncertainty sampling for supervised learning. In In Proceedings of the Eleventh International Conference on Machine Learning, pages 148–156. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hieu T Nguyen</author>
<author>Arnold Smeulders</author>
</authors>
<title>Active learning using pre-clustering.</title>
<date>2004</date>
<booktitle>In ICML.</booktitle>
<contexts>
<context position="5289" citStr="Nguyen and Smeulders, 2004" startWordPosition="808" endWordPosition="811">arning techniques. 3 Active Learning for Word Alignment Active learning attempts to optimize performance by selecting the most informative instances to label where ‘informativeness’ is defined as maximal expected improvement in accuracy. The objective is to select optimal instance for an external expert to label and then run the learning method on the newly-labeled and previously-labeled instances to minimize prediction or translation error, repeating until either the maximal number of external queries is reached or a desired accuracy level is achieved. Several studies (Tong and Koller, 2002; Nguyen and Smeulders, 2004; Donmez and Carbonell, 2008) show that active learning greatly helps to reduce the labeling effort in various classification tasks. 3.1 Active Learning Setup We discuss our active learning setup for word alignment in Algorithm 1. We start with an unlabeled dataset U = {(5k, Tk)}, indexed by k, and a seed pool of partial alignment links A0 = {ak ij,Vsi E 5k, tj E Tk}. This is usually an empty set at iteration t = 0. We iterate for T iterations. We take a pool-based active learning strategy, where we have access to all the automatically aligned links and we can score the links based on our acti</context>
</contexts>
<marker>Nguyen, Smeulders, 2004</marker>
<rawString>Hieu T. Nguyen and Arnold Smeulders. 2004. Active learning using pre-clustering. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models. Computational Linguistics,</title>
<date>2003</date>
<pages>pages</pages>
<contexts>
<context position="1436" citStr="Och and Ney, 2003" startWordPosition="194" endWordPosition="197">duction Corpus-based approaches to machine translation have become predominant, with phrase-based statistical machine translation (PB-SMT) (Koehn et al., 2003) being the most actively progressing area. The success of statistical approaches to MT can be attributed to the IBM models (Brown et al., 1993) that characterize word-level alignments in parallel corpora. Parameters of these alignment models are learnt in an unsupervised manner using the EM algorithm over sentence-level aligned parallel corpora. While the ease of automatically aligning sentences at the word-level with tools like GIZA++ (Och and Ney, 2003) has enabled fast development of SMT systems for various language pairs, the quality of alignment is typically quite low for language pairs like ChineseEnglish, Arabic-English that diverge from the independence assumptions made by the generative models. Increased parallel data enables better estimation of the model parameters, but a large number of language pairs still lack such resources. Two directions of research have been pursued for improving generative word alignment. The first is to relax or update the independence assumptions based on more information, usually syntactic, from the langu</context>
<context position="13868" citStr="Och and Ney, 2003" startWordPosition="2225" endWordPosition="2228"> a given automatically trained model. We also show that fixing such alignments leads to the maximum reduction of error in word alignment, as measured by AER. We compare this with a baseline where links are selected at random for manual correction. To run our experiments iteratively, we automate the setup by using a parallel corpus for which the gold-standard human alignment is already available. We select the Chinese-English language pair, where we have access to 21,863 sentence pairs along with complete manual alignment. 5.2 Results We first automatically align the Cn-En corpus using GIZA++ (Och and Ney, 2003). We then use the learned model in running our link selection algorithm over the entire corpus to determine the most uncertain links according to each active learning strategy. The links are then looked up in the gold-standard human alignment database and corrected. In case a link is not present in the gold-standard data, we introduce a NULL alignment, else we propose the alignment as given in Figure 1: Performance of active sampling strategies for link selection the gold standard. We select the partial alignment as a set of alignment links and provide it to our semi-supervised word aligner. W</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, pages 19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei-Jing Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In ACL 2002,</booktitle>
<pages>311--318</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="16237" citStr="Papineni et al., 2002" startWordPosition="2625" endWordPosition="2628">ment data for the parallel corpus. This is the maximum translation accuracy that we can achieve by any link selection algorithm. We now take the best link selection criteria, which is the confidence 1X axis has number of links elicited on a log-scale 368 System BLEU METEOR Baseline 18.82 42.70 Human Alignment 19.96 44.22 Active Selection 20% 19.34 43.25 Table 1: Alignment and Translation Quality based method and train a system by only selecting 20% of all the links. We observe that at this point we have reduced the AER from 37.09 AER to 26.57 AER. The translation accuracy as measured by BLEU (Papineni et al., 2002) and METEOR (Lavie and Agarwal, 2007) also shows improvement over baseline and approaches gold standard quality. Therefore we achieve 45% of the possible improvement by only using 20% elicitation effort. 5.3 Batch Selection Re-training the word alignment models after eliciting every individual alignment link is infeasible. In our data set of 21,863 sentences with 588,075 links, it would be computationally intensive to retrain after eliciting even 100 links in a batch. We therefore sample links as a discrete batch, and train alignment models to report performance at fixed points. Such a batch s</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In ACL 2002, pages 311–318, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tobias Scheffer</author>
<author>Christian Decomain</author>
<author>Stefan Wrobel</author>
</authors>
<title>Active hidden markov models for information extraction.</title>
<date>2001</date>
<booktitle>In IDA ’01: Proceedings of the 4th International Conference on Advances in Intelligent Data Analysis,</booktitle>
<pages>309--318</pages>
<publisher>Springer-Verlag.</publisher>
<location>London, UK.</location>
<contexts>
<context position="12360" citStr="Scheffer et al., 2001" startWordPosition="1978" endWordPosition="1981">ord alignment as shown in Equation 6. In order to break ties, we extend this approach to select the link with higher average frequency of occurrence of words involved in the link. Score(aij) = α (6) { 2 aij E As2t n At2s 1 aij E As2t U At2s 0 otherwise 4.4 Margin Sampling The strategy for confidence based sampling only considers information about the best scoring link where α = 367 conf(aij/S, T). However we could benefit from information about the second best scoring link as well. In typical multi-class classification problems, earlier work shows success using such a ‘margin based’ approach (Scheffer et al., 2001), where the difference between the probabilities assigned by the underlying model to the first best and second best labels is used as a sampling criteria. We adapt such a margin-based approach to link-selection using the Conf1 scoring function discussed in the earlier sub-section. Our margin technique is formulated below, where a1ij and a2ij are potential first best and second best scoring alignment links for a word at position i in the source sentence S with translation T. The word with minimum margin value is chosen for human alignment. Intuitively such a word is a possible candidate for mis</context>
</contexts>
<marker>Scheffer, Decomain, Wrobel, 2001</marker>
<rawString>Tobias Scheffer, Christian Decomain, and Stefan Wrobel. 2001. Active hidden markov models for information extraction. In IDA ’01: Proceedings of the 4th International Conference on Advances in Intelligent Data Analysis, pages 309–318, London, UK. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simon Tong</author>
<author>Daphne Koller</author>
</authors>
<title>Support vector machine active learning with applications to text classification.</title>
<date>2002</date>
<journal>Journal of Machine Learning,</journal>
<pages>45--66</pages>
<contexts>
<context position="5261" citStr="Tong and Koller, 2002" startWordPosition="804" endWordPosition="807">ignment using active learning techniques. 3 Active Learning for Word Alignment Active learning attempts to optimize performance by selecting the most informative instances to label where ‘informativeness’ is defined as maximal expected improvement in accuracy. The objective is to select optimal instance for an external expert to label and then run the learning method on the newly-labeled and previously-labeled instances to minimize prediction or translation error, repeating until either the maximal number of external queries is reached or a desired accuracy level is achieved. Several studies (Tong and Koller, 2002; Nguyen and Smeulders, 2004; Donmez and Carbonell, 2008) show that active learning greatly helps to reduce the labeling effort in various classification tasks. 3.1 Active Learning Setup We discuss our active learning setup for word alignment in Algorithm 1. We start with an unlabeled dataset U = {(5k, Tk)}, indexed by k, and a seed pool of partial alignment links A0 = {ak ij,Vsi E 5k, tj E Tk}. This is usually an empty set at iteration t = 0. We iterate for T iterations. We take a pool-based active learning strategy, where we have access to all the automatically aligned links and we can score</context>
</contexts>
<marker>Tong, Koller, 2002</marker>
<rawString>Simon Tong and Daphne Koller. 2002. Support vector machine active learning with applications to text classification. Journal of Machine Learning, pages 45–66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicola Ueffing</author>
<author>Hermann Ney</author>
</authors>
<title>Word-level confidence estimation for machine translation.</title>
<date>2007</date>
<journal>Comput. Linguist.,</journal>
<volume>33</volume>
<issue>1</issue>
<contexts>
<context position="9986" citStr="Ueffing and Ney, 2007" startWordPosition="1583" endWordPosition="1586">ibutions of source-given-target P(s/t) and target-given-source P(t/s) probabilities at the word level where si E S and tj E T. We define certainty of a link as the harmonic mean of the bidirectional probabilities. The selection strategy selects the least scoring links according to the formula below which corresponds to links with maximum uncertainty: Score(aij/sI1, t1J) = 2 � P (tj/si) � P (si/tj) P(tj/si) + P(si/tj) (1) 4.2 Confidence Sampling: Posterior Alignment probabilities Confidence estimation for MT output is an interesting area with meaningful initial exploration (Blatz et al., 2004; Ueffing and Ney, 2007). Given a sentence pair (sI1, tJ1) and its word alignment, we compute two confidence metrics at alignment link level – based on the posterior link probability as seen in Equation 5. We select the alignment links that the initial word aligner is least confident according to our metric and seek manual correction of the links. We use t2s to denote computation using higher order (IBM4) target-givensource models and s2t to denote source-giventarget models. Targeting some of the uncertain parts of word alignment has already been shown to improve translation quality in SMT (Huang, 2009). We use confi</context>
</contexts>
<marker>Ueffing, Ney, 2007</marker>
<rawString>Nicola Ueffing and Hermann Ney. 2007. Word-level confidence estimation for machine translation. Comput. Linguist., 33(1):9–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hua Wu</author>
<author>Haifeng Wang</author>
<author>Zhanyi Liu</author>
</authors>
<title>Boosting statistical word alignment using labeled and unlabeled data.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL on Main conference poster sessions,</booktitle>
<pages>913--920</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="4310" citStr="Wu et al. (2006)" startWordPosition="657" endWordPosition="660">ational Linguistics linear model is trained on available labeled data to improve performance. They propose a semisupervised training algorithm which alternates between discriminative error training on the labeled data to learn the weighting parameters and maximum-likelihood EM training on unlabeled data to estimate the parameters. Callison-Burch et al. (2004) also improve alignment by interpolating human alignments with automatic alignments. They observe that while working with such data sets, alignments of higher quality should be given a much higher weight than the lower-quality alignments. Wu et al. (2006) learn separate models from labeled and unlabeled data using the standard EM algorithm. The two models are then interpolated to use as a learner in the semi-supervised algorithm to improve word alignment. To our knowledge, there is no prior work that has looked at reducing human effort by selective elicitation of partial word alignment using active learning techniques. 3 Active Learning for Word Alignment Active learning attempts to optimize performance by selecting the most informative instances to label where ‘informativeness’ is defined as maximal expected improvement in accuracy. The objec</context>
</contexts>
<marker>Wu, Wang, Liu, 2006</marker>
<rawString>Hua Wu, Haifeng Wang, and Zhanyi Liu. 2006. Boosting statistical word alignment using labeled and unlabeled data. In Proceedings of the COLING/ACL on Main conference poster sessions, pages 913–920, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>