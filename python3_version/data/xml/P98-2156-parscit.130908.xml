<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000005">
<title confidence="0.923192">
An alternative LR algorithm for TAGs
</title>
<author confidence="0.39567">
Mark-Jan Nederhof
</author>
<note confidence="0.891774">
DFKI
Stuhlsatzenhausweg 3
D-66123 Saarbri_icken, Germany
</note>
<email confidence="0.967339">
E-mail: nederhoffidfki.de
</email>
<sectionHeader confidence="0.997063" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99963975">
We present a new LR algorithm for tree-
adjoining grammars. It is an alternative to an
existing algorithm that is shown to be incorrect.
Furthermore, the new algorithm is much sim-
pler, being very close to traditional LR parsing
for context-free grammars. The construction of
derived trees and the computation of features
also become straightforward.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999983369565218">
The efficiency of LR(k) parsing techniques
(Sippu and Soisalon-Soininen, 1990) appears
to be very attractive from the perspective of
natural language processing. This has stim-
ulated the computational linguistics commu-
nity to develop extensions of these techniques
to general context-free grammar parsing. The
best-known example is generalized LR parsing
(Tomita, 1986).
A first attempt to adapt LR parsing to tree-
adjoining grammars (TAGs) was made by Scha-
bes and Vijay-Shanker (1990). The description
was very complicated however, and not surpris-
ingly, no implementation of the algorithm seems
to have been made up to now. Apart from pre-
sentational difficulties, the algorithm as it was
published is also incorrect. Brief indications of
the nature of the incorrectness have been given
before by Kinyon (1997). There seems to be no
straightforward way to correct the algorithm.
We therefore developed an alternative to
the algorithm from Schabes and Vijay-Shanker
(1990). This alternative is novel in presenta-
tional aspects, and is fundamentally different in
that it incorporates reductions of subtrees.
The new algorithm has the benefit that many
theoretically and practically useful properties
carry over from the context-free case. For ex-
ample, by making a straightforward translation
from TAGs to linear indexed grammars, one
may identify computations of the parser with
rightmost derivations in reverse. Also the ex-
tensions needed for construction of parse trees
(or &amp;quot;derived trees&amp;quot; as they are often called for
TAGs) and the computation of features are al-
most identical to the corresponding extensions
for context-free LR parsing.
Section 2 discusses our notation. The algo-
rithm for constructing the LR table is given in
Section 3, and the automaton that operates on
these tables is given in Section 4. Section 5
first explains why the algorithm from Schabes
and Vijay-Shanker (1990) is incorrect, and then
provides an example of how our new algorithm
works. Some extensions are discussed in Sec-
tion 6, and the implementation in Section 7.
</bodyText>
<sectionHeader confidence="0.992813" genericHeader="introduction">
2 Notation
</sectionHeader>
<bodyText confidence="0.999867238095238">
For a good introduction to TAGs, the reader
is referred to Joshi (1987). In this section we
merely summarize our notation.
A tree-adjoining grammar is a 4-tuple
(Z, NT, I, A), where E is a finite set of termi-
nals, I is a finite set of initial trees and A is
a finite set of auxiliary trees. We refer to the
trees in I U A as elementary trees. The set NT,
a finite set of nonterminals, does not play any
role in this paper.
Each auxiliary tree has a distinguished leaf,
call the foot. We refer to the foot of an aux-
iliary tree t as F. We refer to the root of an
elementary tree t as R. The set of all nodes
of an elementary tree t is denoted by .A( (t), and
we define the set of all nodes in the grammar by
= UtENA
For each non-leaf node N we define
children(N) as the list of children nodes. For
other nodes, the function children is undefined.
The dominance relation ‹* is the reflexive and
</bodyText>
<page confidence="0.998055">
946
</page>
<bodyText confidence="0.999481">
transitive closure of the parent relation i de-
fined by N i M if and only if children(N) =
aM13, for some a, E Ar*.
Each leaf N in an elementary tree, except
when it is a foot, is labelled by either a termi-
nal from Z or the empty string E. We identify
such a node N labelled by a terminal with that
terminal. Thus, we consider E to be a subset
of N.1
For now, we will disallow labels to be E, since
this causes a slight technical problem. We will
return to this issue in Section 6.
For each node N that is not a leaf or that
is a foot, we define Adjunct(N) as the set of
auxiliary trees that can be adjoined at N. This
set may contain the element nil to indicate that
adjunction at that node is not obligatory.
An example of a TAG is given in Figure 1.
There are two initial trees, ai and a2, and one
auxiliary tree 0. For each node N, Adjunct(N)
has been indicated to the right of that node,
unless Adjunct(N) = {nil} , in which case that
information is omitted from the picture.
</bodyText>
<sectionHeader confidence="0.317913" genericHeader="method">
3 Construction of the LR table
</sectionHeader>
<bodyText confidence="0.998359125">
For technical reasons, we assume an additional
node for each elementary tree t, which we de-
note by T. This node has only one child, viz.
the actual root node R. We also assume an
additional node for each auxiliary tree t, which
we denote by I. This is the unique child of the
actual foot node F. The domain of the func-
tion children is extended to include foot nodes,
by defining children(Ft) = 1, for each t E A.
For the algorithm, two kinds of tree need to
be distinguished: elementary trees and subtrees
of elementary trees. A subtree can be identified
by a pair (t, N), where t is an elementary tree
and N is a node in that tree; the pair indicates
the subtree of t rooted at N. The set of all trees
needed by our algorithm is given by:
</bodyText>
<equation confidence="0.996082">
T = ./UAUf(t,N) I tE/UA,NEN(t)}
</equation>
<bodyText confidence="0.986229">
From here on, we will use the symbol t exclu-
sively to range over I U A, and T to range over
T in general.
</bodyText>
<footnote confidence="0.9917078">
1With this convention, we can no longer distinguish
between different leaves in the grammar with the same
terminal label. This merging of leaves with identical la-
bels is not an inherent part of our algorithm, but it sim-
plifies the notation considerably.
</footnote>
<bodyText confidence="0.997062">
For each r E T, we may consider a part of the
tree consisting of a node N in T and the list of its
children nodes -y. Analogously to the notation
for context-free parsing, we separate the list of
children nodes into two lists, separated by a dot,
and write N -4 a • [3, where al3 = 7, to indicate
that the children nodes in a have already been
matched against a part of the input string, and
those in have as yet not been processed.
The set of such objects for an elementary tree
t is given by:
</bodyText>
<equation confidence="0.9916574">
Pt = {(r a • 0) I a/3 = Rt}
1(N a • 13) I N E N(t), children(N) = afil
For subtrees (t, M) we define:
=
l(N -4 a • /3) I M &lt;3* N, children(N) = a01
</equation>
<bodyText confidence="0.964038">
Such objects are attached to the trees T E T to
which they pertain, to form the set of items:
</bodyText>
<equation confidence="0.8817905">
Items =
{[r , N --+ a • 0] j T E T, (N a • [3) E }
</equation>
<bodyText confidence="0.999371846153846">
A completed item is an item that indicates a
completely recognized elementary tree or sub-
tree. Formally, items are completed if they
are of the form [t, T Rt .] or of the form
Rt, N), N —+a .1.
The main concept needed for the construction
of the LR table is that of LR states. These
are particular elements from 2/tems to be defined
shortly.
First, we introduce the function closure from
2it&apos; to 2items and the functions goto and gotow
from 2/terns x AI to 2items. For any q C Items,
closure(q) is the smallest set such that:
</bodyText>
<listItem confidence="0.895031363636363">
1. q C closure(q);
2. [7-, N -4 a • M E closure(q), nil E
Adjunct(M) and children (M) = 7 implies
[T, M -* • 7] E closure(q);
3. [T, N a • M E closure(q) and
t E Adjunct(M) implies [t, T • Rd E
closure(q);
4. [T, Ft -4 • 1] E closure(q), t E Adjunct(N),
N E ./01) and children(N) = 7 implies
[(t&apos;, N), N • 7] E closure(q); and
5. [7-, M -+ .] E closure(q) and [r, N -+ aM •
</listItem>
<bodyText confidence="0.890054666666667">
E Items implies [r, N -4 aM • E
closure(q).
The clauses 1 thru 4 are reminiscent of the clo-
</bodyText>
<page confidence="0.951064">
947
</page>
<figureCaption confidence="0.894518">
b&apos;
Figure 2: An incorrect
&amp;quot;parse tree&amp;quot; (Section 5).
Figure 1: A tree-adjoining grammar.
</figureCaption>
<bodyText confidence="0.9991301">
sure function for traditional LR parsing. Note
that in clause 4 we set out to recognize a sub-
tree (t&apos;, N) of elementary tree t&apos;. Clause 5 is
unconventional: we traverse the tree T upwards
when the dot indicates that all children nodes
of M have been recognized.
Next we define the function goto, for any
q C Items, and any M E E or M E Ar such
that Adjunct(M) includes at least one auxiliary
tree.
</bodyText>
<equation confidence="0.8916615">
goto(q, M) = fir, N aM • 01 I
, N -4 a • Md] E closure(q)}
</equation>
<bodyText confidence="0.999984833333333">
The function gotoj_ is similar in that it shifts
the dot over a node, in this case the imaginary
node 1 which is the unique child of an actual
foot node F. However, it only does this if t is a
tree which can be adjoined at the node that is
given as the second argument.
</bodyText>
<equation confidence="0.49780575">
goto±(q, M) = fir, Ft -4 J•] I
[T, Ft • 1] E closure(q) A t e Adjunct(M)}
The initial LR state is the set
gin = fit, T -4 • lit] I t E /1
</equation>
<bodyText confidence="0.991309666666667">
We construct the set Q of all LR states as the
smallest collection of sets satisfying the condi-
tions:
</bodyText>
<listItem confidence="0.9988724">
1. qj E Q;
2. q E Q, M E .A./. and q&apos; = goto(q,M) 0
imply q&apos; E Q; and
3. q E Q, M E Ar and q&apos; = goto±(q,M) 0 0
imply q&apos; E Q.
</listItem>
<bodyText confidence="0.9000225">
An LR state is final if its closure includes a
completed item corresponding to an initial tree:
</bodyText>
<equation confidence="0.6835415">
Qfin = {q E Q I
closure(q) fl {[t, T --+ Rt •1 I t E I} 0 0}
</equation>
<bodyText confidence="0.999434">
Final LR states indicate recognition of the in-
put. Other completed items give rise to a re-
duction, a type of stack manipulation by the
LR automaton to be defined in the next sec-
tion. As defined below, reductions are uniquely
identified by either auxiliary trees t or by nodes
N obtained from the corresponding completed
items.
</bodyText>
<equation confidence="0.996245333333333">
reductions (q) =
ft E A I [t, T Rt lb] E closure(q)} U
{N E [(t, N), N -4 a .1 E closure(q)}
</equation>
<bodyText confidence="0.999374727272727">
For each node N in a tree, we consider the
set CS(N) of strings that represent horizontal
cross-sections through the subtree rooted at N.
If we do not want to include the cross-section
through N itself, we write CS(N)+. A cross-
section can also be seen as the yield of the sub-
tree after removal of a certain number of its sub-
trees.
For convenience, each node of an auxiliary
tree (or subtree thereof) that dominates a foot
node is paired with a stack of nodes. The intu-
ition behind such a stack of nodes [N1, , Arn]
is that it indicates a path, the so called spine,
through the derived tree in the direction of the
foot nodes, where each N, with 1 &lt; i &lt; m,
is a node at which adjunction has taken place.
Such stacks correspond to the stacks of linear
indexed grammars.
The set of all stacks of nodes is denoted by
Ar*. The empty stack is denoted by [1, and
stacks consisting of head H and tail T are de-
noted by [HIT]. We define:
</bodyText>
<equation confidence="0.637499">
A4 =
</equation>
<bodyText confidence="0.8351855">
and we simultaneously define the functions CS
and cs+ from Al to 2A4* as the least functions
</bodyText>
<page confidence="0.986168">
948
</page>
<listItem confidence="0.923059285714286">
satisfying:
• CS (N)+ C CS (N), for each N;
• (N, L) E CS (N), for each N such that N .4*
1, and each L E .Ai*;
• N E CS (N), for each N such that --,(N•i*1);
and
• for each N, children(N) = Mi • • • Mm and
</listItem>
<equation confidence="0.86209">
xi E CS(Mi), xm E CS(Mm) implies
X1 • • • xm E CS( N).
</equation>
<sectionHeader confidence="0.978798" genericHeader="method">
4 The recognizer
</sectionHeader>
<bodyText confidence="0.999956636363636">
Relying on the functions defined in the previous
section, we now explore the steps of the LR au-
tomaton, which as usual reads input from left
to right and manipulates a stack.
We can divide the stack elements into two
classes. One class contains the LR states from
Q, the other contains elements of M. A stack
consists of an alternation of elements from these
two classes. More precisely, each stack is an
element from the following set of strings, given
by a regular expression:
</bodyText>
<equation confidence="0.916536">
S = qin(A4 Q)*
</equation>
<bodyText confidence="0.999945333333333">
Note that the bottom element of the stack is
always qm. We will use the symbol A to range
over stacks and substrings of stacks, and the
symbol X to range over elements from .M.
A configuration (A, w) of the automaton con-
sists of a stack A E S and a remaining input w.
The steps of the automaton are given by the bi-
nary relation I- on pairs of configurations. There
are three kinds of step:
</bodyText>
<equation confidence="0.975442666666667">
shift (Aq, aw) (Aqaq&apos; ,w), provided q&apos; =
goto(q, a) 0 0.
reduce subtree (AqoXiqiX2q2 • • • Xmqm,w) I-
( Aqo (1, [NIL])q&apos; , w), provided N E
reductions(qm), X1 • • • Xm E CSI N) and q&apos; =
got° 1(T), N) 0, where L is determined by the
</equation>
<bodyText confidence="0.989210571428571">
following. If for some j (1 &lt; j &lt; m) Xi is of
the form (M, L) then this provides the value of
L, otherwise we set L = [1.2
reduce aux tree (AqoX1qiX2q2 • • • Xmqm,w)
(AqoXq&apos; , w), provided t E reductions(qm),
Xi • • • Xm E CS(Rt) and q&apos; = goto(q0,N) 0 0,
where we obtain node N from the (unique) Xi
</bodyText>
<equation confidence="0.59719">
(1 &lt; j &lt; m) which is of the form (M, [NIL]),
</equation>
<bodyText confidence="0.968723274509804">
2 Exactly in the case that N dominates a footnote will
(exactly) one of the Xj be of the form (M, L), some M.
and set X = N if L = H and X = (N, L)
otherwise.3
The shift step is identical to that for context-
free LR parsing. There are two reduce steps
that must be distinguished. The first takes
place when a subtree of an elementary tree
t has been recognized. We then remove the
stack symbols corresponding to a cross-section
through that subtree, together with the associ-
ated LR states. We replace these by 2 other
symbols, the first of which corresponds to the
foot of an auxiliary tree, and the second is the
associated LR state. In the case that some node
M of the cross-section dominates the foot of t,
then we must copy the associated list L to the
first of the new stack elements, after pushing N
onto that list to reflect that the spine has grown
one segment upwards.
The second type of reduction deals with
recognition of an auxiliary tree. Here, the head
of the list [NIL], which indicates the node at
which the auxiliary tree t has been adjoined
according to previous bottom-up calculations,
must match a node that occurs directly above
the root node of the auxiliary tree; this is
checked by the test q&apos; = goto(q0,N) 0 0.
Input v is recognized if (qi„, v) 1-* (qm.Aq, c)
for some A and q E Qfin. Then A will be of the
form X1qiX2q2 • • • qm_iX,„ where Xi • • E
CS(Rt), for some t E I.
Up to now, it has been tacitly assumed that
the recognizer has some mechanism to its dis-
posal to find the strings Xi • • • Xm E CS(Rt)
and X1 • • Xm E CS( N) in the stack. We will
now explain how this is done.
For each N, we construct a deterministic fi-
nite automaton that recognizes the strings from
CS(N) from right to left. There is only one
final state, which has no outgoing transitions.
This is related to the fact that CS( N) is suffix-
closed. A consequence is that, given any stack
that may occur and any N, there is at most one
string X1 • • Xm E CS(N) that can be found
from the top of the stack downwards, and this
string is found in linear time. For each t E /U A
we also construct a deterministic finite automa-
ton for CS(Rt). The procedure for t E I is given
in Figure 3, and an example of its application
is given in Figure 4. The procedure for t E A is
</bodyText>
<footnote confidence="0.83314">
3Exactly in the case that N dominates a footnote will
L [1.
</footnote>
<page confidence="0.90408">
949
</page>
<equation confidence="0.975266333333333">
let K = 0, T = 0;
lets = fresh_state, f = fresh_state;
make_fa(f,Rt,.$).
procedure make_fa(qi, M, q0):
let T= T U {(q0, M,q1)};
if children(M) is defined
then rnake_fa_list(qi, children (M), q0)
endproc.
procedure make_fa_list(qi, Ma, go):
if a = E
then make_fa(qi, M, q0)
else let q = fresh_state;
make_fa_list(q, a, go); make_fa(qi, M, q)
endproc.
procedure fresh_state0:
create some fresh object q;
let K = K U {q}; return q
endproc.
</equation>
<figureCaption confidence="0.8759178">
Figure 3: Producing a finite automaton
(K,N,T,s,{f}) that recognizes CS(R), given
some t E I. K is the set of states, N acts as
alphabet here, T is the set of transitions, s is
the initial state and f is the (only) final state.
</figureCaption>
<bodyText confidence="0.999743444444445">
similar except that it also has to introduce tran-
sitions labelled with pairs (N, L), where N dom-
inates a foot and L is a stack in Al..; it is obvious
that we should not actually construct different
transitions for different L E Alt, but rather one
single transition (N,_), with the placeholder &amp;quot;2
representing all possible L E .A.I.*.
The procedure for CS(N) can easily be ex-
pressed in terms of those for CS(R).
</bodyText>
<sectionHeader confidence="0.927179" genericHeader="method">
5 Extended example
</sectionHeader>
<bodyText confidence="0.999730916666667">
For the TAG presented in Figure 1, the algo-
rithm from Schabes and Vijay-Shanker (1990)
does not work correctly. The language de-
scribed by the grammar contains exactly the
strings abc, a&apos; b&apos; c&apos;, adbec, and a&apos; db&apos; ec&apos; . The al-
gorithm from Schabes and Vijay-Shanker (1990)
however also accepts adb&apos; ec&apos; and a&apos; dbec. In the
former string, it acts as if it were recognizing
the (ill-formed) tree in Figure 2: it correctly
matches the part to the &amp;quot;south&amp;quot; of the adjunc-
tion to the part to the &amp;quot;north-east&amp;quot;. Then, after
reading c&apos;, the information that would indicate
</bodyText>
<figureCaption confidence="0.688965333333333">
Figure 4: Example of the construction for
CS(R1), where R1 is the root node of al (Fig-
ure 1).
</figureCaption>
<bodyText confidence="0.99885605">
whether a or a&apos; was read is retrieved from the
stack, but this information is merely popped
without investigation. Thereby, the algorithm
fails to perform the necessary matching of the
elementary tree with regard to the part to the
&amp;quot;north-west&amp;quot; of the adjunction.
Our new algorithm recognizes exactly the
strings in the language. For the running ex-
ample, the set of LR states and some opera-
tions on them are shown in Figure 5. Arrows
labelled with nodes N represent the goto func-
tion and those labelled with _L(N) represent the
gotol function. The initial state is 0. The thin
lines separate the items resulting from the goto
and goto± functions from those induced by the
closure function. (This corresponds with the
distinction between kernel and nonkernel items
as known from context-free LR parsing.)
That correct input is recognized is illustrated
by the following:
</bodyText>
<table confidence="0.939107333333333">
Stack Input Step
0 adbec shift a
0 a 1 dbec shift d
0 a 1 d 5 bec shift b
0 a 1 d 5 b 7 ec reduce Ni
0 a 1 d 5 (1, ENID 9 ec shift e
0 a 1 d 5 (±, [Nd) 9 e 10 c reduce /3
0 a 1 Ni 3 c shift c
0 a 1 NI. 3 c 6 accept
</table>
<bodyText confidence="0.996624125">
Note that as soon as all the terminals in the aux-
iliary tree have been read, the &amp;quot;south&amp;quot; section of
the initial tree is matched to the &amp;quot;north-west&amp;quot;
section through the goto function. Through
subsequent shifts this is then matched to the
&amp;quot;north-east&amp;quot; section.
This is in contrast to the situation when in-
correct input, such as adb&apos; ec&apos; , is provided to the
</bodyText>
<page confidence="0.800762">
950
2
</page>
<figureCaption confidence="0.999245">
Figure 5: The set of LR states.
</figureCaption>
<equation confidence="0.945450181818182">
[ai , Ri —&gt; a • Aric]
[a2, R2 --) a&apos; • N2c
[c2, N2 —&gt; • b&apos;]
[/3,T —&gt; • Rs]
[13, Rs -+ • dFe]
b&apos;
12
[al, T -4 • R1]
[a2, T —&gt; • R2]
[al , Ri —&gt; • aNic]
[a2, R2 —. • a&apos;N2cl]
</equation>
<figure confidence="0.959579549019608">
a
--...
.4-....,
5
/
[al , NI —&gt; • b]
[0, T -4 • Rs]
[/3,Rs —&gt; • dFe]
b
4
N2
[/3,Ro -4 d • Fe]
[al , Ni -4 b.]
[al, RI --&gt; aNi c
[az, N2 -4 b&apos;.]
[012, R2 —&gt; al N2 •
11
[0, F --4 • 1]
Rai , NI), Ni -4 • b]
Raz, N2), N2 -4 • WI
1(N1)
3
FraTRI -4 aNi • c] I
y
a2, R2 -÷ a&apos;N2 • c
I
9
1(N2)
N1
13
[a2, R2 -4 al N2C1 0]
[CE2, T —&gt; R2.]
8
Raz,N2), N2 -4 b&apos; s]
[0, F —&gt; 1 .1
{3,Rs -4 dF • e
10
[0, Rs dFe.]
[13,T -4 Ro .1
b
[al, R1 -4 aNic •
[ai , T -4 R1 •]
6
automaton:
Stack Input Step
0 adb&apos; ec&apos; shift a
0 a 1 db&apos; ec&apos; shift d
0 a 1 d 5 b&apos; ec&apos; shift b&apos;
0 a 1 d 5 b&apos; 8 ec&apos; reduce N2
Oa 1 d5 (1,{N2]) 9 ec&apos; shift e
0 a 1 d 5 (I, [N2]) 9 e 10 c&apos;
</figure>
<bodyText confidence="0.917777333333333">
Here, the computation is stuck. In particular, a
reduction with auxiliary tree f3 fails due to the
fact that goto(1, N2) = 0.
</bodyText>
<sectionHeader confidence="0.998733" genericHeader="method">
6 Extensions
</sectionHeader>
<bodyText confidence="0.979560928571428">
The recognizer can be turned into a parser
by attaching information to the stack elements
from M. At reductions, such information is
gathered and combined, and the resulting data
is attached to the new element from M that
is pushed onto the stack. This can be used
for computation of derived trees or derivation
trees, and for computation of features. Since
this technique is almost identical to that for the
context-free case, it suffices to refer to existing
literature, e.g. Aho et al. (1986, Section 5.3).
We have treated a classical type of TAG,
which has adjunction as the only operation for
composing trees. Many modern types of TAG
also allow tree substitution next to adjunc-
tion. Our algorithm can be straightforwardly
extended to handle tree substitution. The main
changes that are required lie in the closure
function, which needs an extra case (much like
the corresponding operation in context-free LR
parsing), in adding a third type of goto func-
tion, and in adding a fourth step, consisting of
reduction of initial trees, which is almost iden-
tical to the reduction of auxiliary trees. The
main difference is that all Xj are elements from
N.; the X that is pushed can be a substitution
node or a nonterminal (see also Section 7).
Up to now we have assumed that the gram-
mar does not assign the empty string as label
to any of the leaves of the elementary trees.
The problem introduced by allowing the empty
string is that it does not leave any trace on
the stack, and therefore CS (Rt) and CS( N)
are no longer suffix-closed. We have solved this
by extending items with a third component E,
which is a set of nodes labelled with e that have
been traversed by the closure function. Upon
encountering a completed item [7-, N -4 a •, E],
a reduction is performed according to the sets
CS (Rt, E) or CS+ (N,E), which are subsets of
CS (Re) and CS + (N), respectively, containing
only those cross-sections in which the nodes la-
</bodyText>
<page confidence="0.994791">
951
</page>
<bodyText confidence="0.930829333333333">
belled with E are exactly those in E. An au-
tomaton for such a set is deterministic and has
one final state, without outgoing transitions.
</bodyText>
<sectionHeader confidence="0.987289" genericHeader="conclusions">
7 Implementation
</sectionHeader>
<bodyText confidence="0.999972044444445">
We have implemented the parser generator,
with the extensions from the previous section.
We have assumed that each set Adjunct(N), if
it is not {nil}, depends only on the nonterminal
label of N. This allows more compact storage
of the entries goto±(q, M): for a fixed state q
and nonterminal B, several such entries where
M has B as label can be collapsed into a single
entry gotol(q, B). The goto function for tree
substitution is represented similarly.
We have constructed the LR table for the En-
glish grammar developed by the XTAG project
at the University of Pennsylvania. This gram-
mar contains 286 initial trees and 316 auxiliary
trees, which together have 5950 nodes. There
are 9 nonterminals that allow adjunction, and
10 that allow substitution. There are 21 sym-
bols that function as terminals.
Our findings are that for a grammar of this
size, the size of the LR table is prohibitively
large. The table represented as a collection of
unit clauses in Prolog takes over 46 MB for stor-
age. The majority of this is needed to represent
the three goto functions, which together require
over 2.5 million entries, almost 99% of which is
consumed by goto, and the remainder by goto±
and the goto function for tree substitution. The
reduction functions require almost 80 thousand
entries. There are 5610 LR states. The size of
the automata for recognizing the sets CS (Rt, E)
and CS + (N, E) is negligible: together they con-
tain just over 15 thousand transitions.
The time requirements for generation of the
table were acceptable: approximately 25 min-
utes were needed on a standard main frame with
moderate load.
Another obstacle to practical use is the equiv-
alent of hidden left recursion known from tradi-
tional LR parsing (Nederhof and Sarbo, 1996),
which we have shown to be present in the
grammar for English. This phenomenon pre-
cludes realization of nondeterminism by means
of backtracking. Tabular realization was inves-
tigated by Nederhof (1998) and will be the sub-
ject of further research.
</bodyText>
<sectionHeader confidence="0.988101" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998855461538461">
Anoop Sarkar provided generous help with mak-
ing the XTAG available for testing purposes.
Parts of this research were carried out within
the framework of the Priority Programme Lan-
guage and Speech Technology (TST), while
the author was employed at the University of
Groningen. The TST-Programme is sponsored
by NWO (Dutch Organization for Scientific Re-
search). This work was further funded by the
German Federal Ministry of Education, Science,
Research and Technology (BMBF) in the frame-
work of the VERBMOBIL Project under Grant 01
IV 701 VO.
</bodyText>
<sectionHeader confidence="0.998353" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999797628571429">
A.V. Aho, R. Sethi, and J.D. Ullman. 1986.
Compilers: Principles, Techniques, and
Tools. Addison-Wesley.
A.K. Joshi. 1987. An introduction to tree ad-
joining grammars. In A. Manaster-Ramer,
editor, Mathematics of Language, pages 87-
114. John Benjamins Publishing Company.
A. Kinyon. 1997. Un algorithme d&apos;analyse
LR(0) pour les grammaires d&apos;arbres adjoints
lexicalisees. In D. Genthial, editor, Qua-
Henze conference annuelle sur Le Traitement
Automatique du Langage Naturel, Actes,
pages 93-102, Grenoble, June.
M.-J. Nederhof and J.J. Sarbo. 1996. In-
creasing the applicability of LR parsing. In
H. Bunt and M. Tomita, editors, Recent
Advances in Parsing Technology, chapter 3,
pages 35-57. Kluwer Academic Publishers.
M.-J. Nederhof. 1998. Linear indexed automata
and tabulation of TAG parsing. In Actes des
premieres journees sur la Tabulation en Ana-
lyse Syntaxique et Deduction (Tabulation in
Parsing and Deduction), pages 1-9, Paris,
France, April.
Y. Schabes and K. Vijay-Shanker. 1990. Deter-
ministic left to right parsing of tree adjoin-
ing languages. In 28th Annual Meeting of the
ACL, pages 276-283.
S. Sippu and E. Soisalon-Soininen. 1990.
Parsing Theory, Vol. II: LR(k) and LL(k)
Parsing, volume 20 of EATCS Monographs
on Theoretical Computer Science. Springer-
Verlag.
M. Tomita. 1986. Efficient Parsing for Natural
Language. Kluwer Academic Publishers.
</reference>
<page confidence="0.997575">
952
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.814322">
<title confidence="0.999472">An alternative LR algorithm for TAGs</title>
<author confidence="0.960496">Mark-Jan Nederhof</author>
<affiliation confidence="0.886816">DFKI</affiliation>
<address confidence="0.95128">Stuhlsatzenhausweg 3 D-66123 Saarbri_icken, Germany</address>
<email confidence="0.999619">E-mail:nederhoffidfki.de</email>
<abstract confidence="0.998869">We present a new LR algorithm for treeadjoining grammars. It is an alternative to an existing algorithm that is shown to be incorrect. Furthermore, the new algorithm is much simpler, being very close to traditional LR parsing for context-free grammars. The construction of derived trees and the computation of features also become straightforward.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A V Aho</author>
<author>R Sethi</author>
<author>J D Ullman</author>
</authors>
<date>1986</date>
<booktitle>Compilers: Principles, Techniques, and Tools.</booktitle>
<publisher>Addison-Wesley.</publisher>
<contexts>
<context position="18913" citStr="Aho et al. (1986" startWordPosition="3737" endWordPosition="3740">tion is stuck. In particular, a reduction with auxiliary tree f3 fails due to the fact that goto(1, N2) = 0. 6 Extensions The recognizer can be turned into a parser by attaching information to the stack elements from M. At reductions, such information is gathered and combined, and the resulting data is attached to the new element from M that is pushed onto the stack. This can be used for computation of derived trees or derivation trees, and for computation of features. Since this technique is almost identical to that for the context-free case, it suffices to refer to existing literature, e.g. Aho et al. (1986, Section 5.3). We have treated a classical type of TAG, which has adjunction as the only operation for composing trees. Many modern types of TAG also allow tree substitution next to adjunction. Our algorithm can be straightforwardly extended to handle tree substitution. The main changes that are required lie in the closure function, which needs an extra case (much like the corresponding operation in context-free LR parsing), in adding a third type of goto function, and in adding a fourth step, consisting of reduction of initial trees, which is almost identical to the reduction of auxiliary tr</context>
</contexts>
<marker>Aho, Sethi, Ullman, 1986</marker>
<rawString>A.V. Aho, R. Sethi, and J.D. Ullman. 1986. Compilers: Principles, Techniques, and Tools. Addison-Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Joshi</author>
</authors>
<title>An introduction to tree adjoining grammars.</title>
<date>1987</date>
<booktitle>Mathematics of Language,</booktitle>
<pages>87--114</pages>
<editor>In A. Manaster-Ramer, editor,</editor>
<publisher>John Benjamins Publishing Company.</publisher>
<contexts>
<context position="2637" citStr="Joshi (1987)" startWordPosition="405" endWordPosition="406"> TAGs) and the computation of features are almost identical to the corresponding extensions for context-free LR parsing. Section 2 discusses our notation. The algorithm for constructing the LR table is given in Section 3, and the automaton that operates on these tables is given in Section 4. Section 5 first explains why the algorithm from Schabes and Vijay-Shanker (1990) is incorrect, and then provides an example of how our new algorithm works. Some extensions are discussed in Section 6, and the implementation in Section 7. 2 Notation For a good introduction to TAGs, the reader is referred to Joshi (1987). In this section we merely summarize our notation. A tree-adjoining grammar is a 4-tuple (Z, NT, I, A), where E is a finite set of terminals, I is a finite set of initial trees and A is a finite set of auxiliary trees. We refer to the trees in I U A as elementary trees. The set NT, a finite set of nonterminals, does not play any role in this paper. Each auxiliary tree has a distinguished leaf, call the foot. We refer to the foot of an auxiliary tree t as F. We refer to the root of an elementary tree t as R. The set of all nodes of an elementary tree t is denoted by .A( (t), and we define the </context>
</contexts>
<marker>Joshi, 1987</marker>
<rawString>A.K. Joshi. 1987. An introduction to tree adjoining grammars. In A. Manaster-Ramer, editor, Mathematics of Language, pages 87-114. John Benjamins Publishing Company.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kinyon</author>
</authors>
<title>Un algorithme d&apos;analyse LR(0) pour les grammaires d&apos;arbres adjoints lexicalisees. In</title>
<date>1997</date>
<booktitle>QuaHenze conference annuelle sur Le Traitement Automatique du Langage Naturel, Actes,</booktitle>
<pages>93--102</pages>
<editor>D. Genthial, editor,</editor>
<location>Grenoble,</location>
<contexts>
<context position="1318" citStr="Kinyon (1997)" startWordPosition="195" endWordPosition="196">onal linguistics community to develop extensions of these techniques to general context-free grammar parsing. The best-known example is generalized LR parsing (Tomita, 1986). A first attempt to adapt LR parsing to treeadjoining grammars (TAGs) was made by Schabes and Vijay-Shanker (1990). The description was very complicated however, and not surprisingly, no implementation of the algorithm seems to have been made up to now. Apart from presentational difficulties, the algorithm as it was published is also incorrect. Brief indications of the nature of the incorrectness have been given before by Kinyon (1997). There seems to be no straightforward way to correct the algorithm. We therefore developed an alternative to the algorithm from Schabes and Vijay-Shanker (1990). This alternative is novel in presentational aspects, and is fundamentally different in that it incorporates reductions of subtrees. The new algorithm has the benefit that many theoretically and practically useful properties carry over from the context-free case. For example, by making a straightforward translation from TAGs to linear indexed grammars, one may identify computations of the parser with rightmost derivations in reverse. </context>
</contexts>
<marker>Kinyon, 1997</marker>
<rawString>A. Kinyon. 1997. Un algorithme d&apos;analyse LR(0) pour les grammaires d&apos;arbres adjoints lexicalisees. In D. Genthial, editor, QuaHenze conference annuelle sur Le Traitement Automatique du Langage Naturel, Actes, pages 93-102, Grenoble, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M-J Nederhof</author>
<author>J J Sarbo</author>
</authors>
<title>Increasing the applicability of LR parsing.</title>
<date>1996</date>
<booktitle>Recent Advances in Parsing Technology, chapter 3,</booktitle>
<pages>35--57</pages>
<editor>In H. Bunt and M. Tomita, editors,</editor>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="22261" citStr="Nederhof and Sarbo, 1996" startWordPosition="4324" endWordPosition="4327">% of which is consumed by goto, and the remainder by goto± and the goto function for tree substitution. The reduction functions require almost 80 thousand entries. There are 5610 LR states. The size of the automata for recognizing the sets CS (Rt, E) and CS + (N, E) is negligible: together they contain just over 15 thousand transitions. The time requirements for generation of the table were acceptable: approximately 25 minutes were needed on a standard main frame with moderate load. Another obstacle to practical use is the equivalent of hidden left recursion known from traditional LR parsing (Nederhof and Sarbo, 1996), which we have shown to be present in the grammar for English. This phenomenon precludes realization of nondeterminism by means of backtracking. Tabular realization was investigated by Nederhof (1998) and will be the subject of further research. Acknowledgments Anoop Sarkar provided generous help with making the XTAG available for testing purposes. Parts of this research were carried out within the framework of the Priority Programme Language and Speech Technology (TST), while the author was employed at the University of Groningen. The TST-Programme is sponsored by NWO (Dutch Organization for</context>
</contexts>
<marker>Nederhof, Sarbo, 1996</marker>
<rawString>M.-J. Nederhof and J.J. Sarbo. 1996. Increasing the applicability of LR parsing. In H. Bunt and M. Tomita, editors, Recent Advances in Parsing Technology, chapter 3, pages 35-57. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M-J Nederhof</author>
</authors>
<title>Linear indexed automata and tabulation of TAG parsing.</title>
<date>1998</date>
<booktitle>In Actes des premieres journees sur la Tabulation en Analyse Syntaxique et Deduction (Tabulation in Parsing and Deduction),</booktitle>
<pages>1--9</pages>
<location>Paris, France,</location>
<contexts>
<context position="22462" citStr="Nederhof (1998)" startWordPosition="4357" endWordPosition="4358">ata for recognizing the sets CS (Rt, E) and CS + (N, E) is negligible: together they contain just over 15 thousand transitions. The time requirements for generation of the table were acceptable: approximately 25 minutes were needed on a standard main frame with moderate load. Another obstacle to practical use is the equivalent of hidden left recursion known from traditional LR parsing (Nederhof and Sarbo, 1996), which we have shown to be present in the grammar for English. This phenomenon precludes realization of nondeterminism by means of backtracking. Tabular realization was investigated by Nederhof (1998) and will be the subject of further research. Acknowledgments Anoop Sarkar provided generous help with making the XTAG available for testing purposes. Parts of this research were carried out within the framework of the Priority Programme Language and Speech Technology (TST), while the author was employed at the University of Groningen. The TST-Programme is sponsored by NWO (Dutch Organization for Scientific Research). This work was further funded by the German Federal Ministry of Education, Science, Research and Technology (BMBF) in the framework of the VERBMOBIL Project under Grant 01 IV 701 </context>
</contexts>
<marker>Nederhof, 1998</marker>
<rawString>M.-J. Nederhof. 1998. Linear indexed automata and tabulation of TAG parsing. In Actes des premieres journees sur la Tabulation en Analyse Syntaxique et Deduction (Tabulation in Parsing and Deduction), pages 1-9, Paris, France, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Schabes</author>
<author>K Vijay-Shanker</author>
</authors>
<title>Deterministic left to right parsing of tree adjoining languages.</title>
<date>1990</date>
<booktitle>In 28th Annual Meeting of the ACL,</booktitle>
<pages>276--283</pages>
<contexts>
<context position="993" citStr="Schabes and Vijay-Shanker (1990)" startWordPosition="140" endWordPosition="144"> LR parsing for context-free grammars. The construction of derived trees and the computation of features also become straightforward. 1 Introduction The efficiency of LR(k) parsing techniques (Sippu and Soisalon-Soininen, 1990) appears to be very attractive from the perspective of natural language processing. This has stimulated the computational linguistics community to develop extensions of these techniques to general context-free grammar parsing. The best-known example is generalized LR parsing (Tomita, 1986). A first attempt to adapt LR parsing to treeadjoining grammars (TAGs) was made by Schabes and Vijay-Shanker (1990). The description was very complicated however, and not surprisingly, no implementation of the algorithm seems to have been made up to now. Apart from presentational difficulties, the algorithm as it was published is also incorrect. Brief indications of the nature of the incorrectness have been given before by Kinyon (1997). There seems to be no straightforward way to correct the algorithm. We therefore developed an alternative to the algorithm from Schabes and Vijay-Shanker (1990). This alternative is novel in presentational aspects, and is fundamentally different in that it incorporates redu</context>
<context position="2398" citStr="Schabes and Vijay-Shanker (1990)" startWordPosition="361" endWordPosition="364"> a straightforward translation from TAGs to linear indexed grammars, one may identify computations of the parser with rightmost derivations in reverse. Also the extensions needed for construction of parse trees (or &amp;quot;derived trees&amp;quot; as they are often called for TAGs) and the computation of features are almost identical to the corresponding extensions for context-free LR parsing. Section 2 discusses our notation. The algorithm for constructing the LR table is given in Section 3, and the automaton that operates on these tables is given in Section 4. Section 5 first explains why the algorithm from Schabes and Vijay-Shanker (1990) is incorrect, and then provides an example of how our new algorithm works. Some extensions are discussed in Section 6, and the implementation in Section 7. 2 Notation For a good introduction to TAGs, the reader is referred to Joshi (1987). In this section we merely summarize our notation. A tree-adjoining grammar is a 4-tuple (Z, NT, I, A), where E is a finite set of terminals, I is a finite set of initial trees and A is a finite set of auxiliary trees. We refer to the trees in I U A as elementary trees. The set NT, a finite set of nonterminals, does not play any role in this paper. Each auxi</context>
<context position="15423" citStr="Schabes and Vijay-Shanker (1990)" startWordPosition="2998" endWordPosition="3001">tes, N acts as alphabet here, T is the set of transitions, s is the initial state and f is the (only) final state. similar except that it also has to introduce transitions labelled with pairs (N, L), where N dominates a foot and L is a stack in Al..; it is obvious that we should not actually construct different transitions for different L E Alt, but rather one single transition (N,_), with the placeholder &amp;quot;2 representing all possible L E .A.I.*. The procedure for CS(N) can easily be expressed in terms of those for CS(R). 5 Extended example For the TAG presented in Figure 1, the algorithm from Schabes and Vijay-Shanker (1990) does not work correctly. The language described by the grammar contains exactly the strings abc, a&apos; b&apos; c&apos;, adbec, and a&apos; db&apos; ec&apos; . The algorithm from Schabes and Vijay-Shanker (1990) however also accepts adb&apos; ec&apos; and a&apos; dbec. In the former string, it acts as if it were recognizing the (ill-formed) tree in Figure 2: it correctly matches the part to the &amp;quot;south&amp;quot; of the adjunction to the part to the &amp;quot;north-east&amp;quot;. Then, after reading c&apos;, the information that would indicate Figure 4: Example of the construction for CS(R1), where R1 is the root node of al (Figure 1). whether a or a&apos; was read is retr</context>
</contexts>
<marker>Schabes, Vijay-Shanker, 1990</marker>
<rawString>Y. Schabes and K. Vijay-Shanker. 1990. Deterministic left to right parsing of tree adjoining languages. In 28th Annual Meeting of the ACL, pages 276-283.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Sippu</author>
<author>E Soisalon-Soininen</author>
</authors>
<title>Parsing Theory, Vol. II: LR(k) and LL(k) Parsing,</title>
<date>1990</date>
<journal>of EATCS Monographs on Theoretical Computer Science.</journal>
<volume>20</volume>
<publisher>SpringerVerlag.</publisher>
<marker>Sippu, Soisalon-Soininen, 1990</marker>
<rawString>S. Sippu and E. Soisalon-Soininen. 1990. Parsing Theory, Vol. II: LR(k) and LL(k) Parsing, volume 20 of EATCS Monographs on Theoretical Computer Science. SpringerVerlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Tomita</author>
</authors>
<title>Efficient Parsing for Natural Language.</title>
<date>1986</date>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="878" citStr="Tomita, 1986" startWordPosition="123" endWordPosition="124">to be incorrect. Furthermore, the new algorithm is much simpler, being very close to traditional LR parsing for context-free grammars. The construction of derived trees and the computation of features also become straightforward. 1 Introduction The efficiency of LR(k) parsing techniques (Sippu and Soisalon-Soininen, 1990) appears to be very attractive from the perspective of natural language processing. This has stimulated the computational linguistics community to develop extensions of these techniques to general context-free grammar parsing. The best-known example is generalized LR parsing (Tomita, 1986). A first attempt to adapt LR parsing to treeadjoining grammars (TAGs) was made by Schabes and Vijay-Shanker (1990). The description was very complicated however, and not surprisingly, no implementation of the algorithm seems to have been made up to now. Apart from presentational difficulties, the algorithm as it was published is also incorrect. Brief indications of the nature of the incorrectness have been given before by Kinyon (1997). There seems to be no straightforward way to correct the algorithm. We therefore developed an alternative to the algorithm from Schabes and Vijay-Shanker (1990</context>
</contexts>
<marker>Tomita, 1986</marker>
<rawString>M. Tomita. 1986. Efficient Parsing for Natural Language. Kluwer Academic Publishers.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>