<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.573228">
The FINITE STRING Newsletter
</title>
<subsectionHeader confidence="0.840589">
New Editor&apos;s Note
</subsectionHeader>
<bodyText confidence="0.9982018">
It&apos;s a pleasure to assume the editorship of The FINITE
STRING, since it is such an important resource for our
discipline and its community of researchers.
The success of The FINITE STRING depends on two
factors:
</bodyText>
<listItem confidence="0.969459">
• individual members supplying items of general inter-
est to the readership, including announcements of
meetings, summaries of research in progress, and
abstracts
• timely publishing of that information by the AWL
staff.
</listItem>
<bodyText confidence="0.998257238095238">
That means you are a critical part of The FINITE
STRING; I seek your help as an information source.
For our part, we will make every effort to publish
what you submit in the next issue after receipt.
The section on abstracts of current literature is a
particularly important part of The FINITE STRING. We
would like it to be a major reference tool, but that
requires your contributions. Please send abstracts of
papers, books, and technical reports, and call my at-
tention to relevant work in out-of-the-way journals
and proceedings that you think I might not see.
I would particularly like to solicit brief summaries
of research in progress at a given site. These descrip-
tions should cover 4-12 double-spaced pages, depend-
ing on the number of participants. Providing a contin-
uing perspective on the field in this way would provide
an invaluable service to all; please take advantage of
it. A report on the new Center for Study of Language
and Information inaugurates this new feature.
How can The FINITE STRING best serve the read-
ers? Please let me know.
</bodyText>
<keyword confidence="0.155369">
Ralph Weischedel, Editor
</keyword>
<sectionHeader confidence="0.255278" genericHeader="method">
The FINITE STRING Newsletter
</sectionHeader>
<subsectionHeader confidence="0.679886666666667">
Center for the Study of Language
and Information
Research Program on Situated Language
</subsectionHeader>
<bodyText confidence="0.999876020833333">
Founded early in 1983, the Center for the Study of
Language and Information (CSLI) at Stanford Univer-
sity grew out of a long-standing collaboration between
scientists at research laboratories in the Palo Alto area
and the faculty and students of several Stanford Uni-
versity departments and out of a need for an institu-
tional focus for this work on natural and computer
languages. At present, CSLI has 17 senior members,
or &amp;quot;principals&amp;quot; (listed in the Appendix), and about as
many associate members, from SRI International, Xe-
rox PARC, Fairchild, and the Departments of Comput-
er Science, Linguistics, and Philosophy at Stanford.
Since the Center&apos;s research will overlap with the work
of other researchers around the world, an important
goal of CSLI will be to initiate a major outreact,
whereby members of CSLI both inform themselves of
work done elsewhere and share their own results with
others.
As its first major research program, CSLI is under-
taking a study of situated language, Program SL, that
is based on three insights: (1) Language use is funda-
mentally computational in that it is used by finite
agents with limited resources to process, store, and
communicate information; (2) computational practice
is fundamentally linguistic in that computers are used
by humans under the assumption that the symbols and
processes of computers are about entities in the world;
and (3) understanding linguistic activity in any real
situation requires theories based on solid semantic
foundations, connecting computation and language
with information about the world.
The major goals of the program, dictated by the
current state of affairs in research on languages, are:
(1) to extend the study of natural language to include
the active, situated agent; (2) to extend the study of
computer languages to consider information content
and the embedding world; and (3) to merge the in-
sights and theories of these two traditions into an inte-
grated whole, based on solid philosophical and mathe-
matical foundations.
Program SL, outlined here, comprises 16 projects in
four areas: (A) the evaluation and development of
syntax, morphology, and phonology, as well as the
study of their computational aspects and their relation
to language use; (B) the development of theories of
natural-language use from the perspective of language
users as finite processors of information derived from
the world; (C) the understanding of computing lan-
</bodyText>
<page confidence="0.695479">
30 American Journal of Computational Linguistics, Volume 9, Number 1, January-March 1983
</page>
<note confidence="0.388884">
The FINITE STRING Newsletter Center for the Study of Language and Information
</note>
<bodyText confidence="0.975708666666667">
guages and architectures supporting the thesis of com-
putation as linguistic activity; and (D) the develop-
ment of the philosophical and mathematical founda-
tions needed to support the theories on situated lan-
guage use.
Questions about CSLI or Program SL should be
addressed to Dr. Elizabeth Macken, Assistant Direc-
tor, CSLI, Ventura Hall, Stanford University, Stanford,
CA 94305.
</bodyText>
<subsectionHeader confidence="0.992193">
A. Traditional Linguistics and Situated Language
</subsectionHeader>
<bodyText confidence="0.98475">
This collection of projects will evaluate and further
develop areas of traditional linguistics — syntax, pho-
nology, and morphology — in the light of our commit-
ment to computation, semantics, and language use.
Stanley Peters has responsibility for the overall guid-
ance of Area A.
</bodyText>
<listItem confidence="0.484932">
A.1. Phonology, morphology, and syntax
Project Manager: Lauri Karttunen (Ronald Kaplan
during fall 1983)
</listItem>
<bodyText confidence="0.988040363636364">
New theories of lexical phonology and morphology
have stressed the natural decomposition of sound-
mapping rules into word-internal and phrasal types,
each having distinctive properties. Independently of
this, new syntactic theories have given evidence that
many processes previously thought to be syntactic are
morphological. To explore further the relation be-
tween phonology and morphosyntax, and their contrib-
ution to meaning, this project will study word forma-
tion and syntax in a representative sample of morpho-
logically varying language types. The results of these
studies will be integrated with the current theory of
morphologically governed sound structure. We will
also look into whether there is a natural computational
interpretation for the theoretically motivated rules and
representations and whether the natural phonological
and morphological algorithms interact properly with
higher level syntactic and functional computations.
We will investigate syntactic structure as it relates
to semantic interpretation and sentence generation.
The study of syntax is particularly relevant in the con-
text of topics such as the extensions of semantic theo-
ries (B.1). To develop adequate semantic treatments
for many of the constructions listed there, we need
better descriptions of their syntactic composition. We
will try to integrate the insights of current theoretical
approaches to syntax, such as lexical-functional gram-
mar, generalized phrase structure grammar, and gov-
ernment binding theory. Another topic with close
connections to syntax is the computational properties
of parsing algorithms (A.4).
A.2. The effect of syntax and phonology on dis-
course structure
</bodyText>
<subsectionHeader confidence="0.697498">
Project Manager: Joan Bresnan
</subsectionHeader>
<bodyText confidence="0.94773435">
Our current theories of phonology and syntax are
largely restricted to the phrase and sentence levels,
respectively. Theories of discourse are largely uncon-
nected with the phonological and syntactic levels, yet
several cases are known where theoretical accounts at
one of these levels depend on factors at another.
Phrase-level phonological grammars have advanced our
knowledge of sound variation and intonation, yet they
do not show how these phenomena depend on syntac-
tic and discourse boundaries. Conversely, intonation
influences illocutionary force, as does the discourse
situation. Certain sentence forms (e.g., clefts and
topicalization) influence focusing and centering and
thus constrain the referents of pronouns. This project
will investigate the relation between the phonological,
syntactic, and discourse levels and the computational
problems involved in doing recognition and generation
across them.
A.3. Strategies and tactics in the processing of
utterances
</bodyText>
<subsectionHeader confidence="0.572445">
Project Manager: Ronald Kaplan
</subsectionHeader>
<bodyText confidence="0.999921909090909">
Many sentences have multiple meanings, though in any
given context one is typically preferred. To model
effective communication, we need to develop algor-
ithms that produce the preferred reading. Semantic
and pragmatic factors strongly influence preferences,
but there is also evidence for independent lexical and
syntactic effects. Explicit computational models of
how lexical and syntactic properties interact during the
comprehension process have also been developed.
To simplify the development of the theory of lexi-
cosyntactic interactions, possible semantic and prag-
matic influences were treated as constant boundary
conditions that could be ignored, at least temporarily.
As our computational theories of discourse and seman-
tics improve to the point at which coherent characteri-
zations of the situational context can be given, we
expect to be able to extend our theory of ambiguity
resolution to account for the interacting influence of
factors at all levels of analysis. The result of this pro-
ject, then, will be a full-fledged model of sentence
interpretation that is sensitive to both structural and
contextual factors.
</bodyText>
<listItem confidence="0.9205395">
A.4. Computational properties of parsing algorithms
Project Manager: Stanley Peters
</listItem>
<bodyText confidence="0.98262376">
Principals of CSLI have developed and are currently
investigating several formalisms for encoding syntactic
descriptions of natural languages: the generalized
phrase structure grammar (GPSG), the lexical-
functional grammar (LFG), the phrase-linking gram-
mar, and PATR-2. These theories are noteworthy in
that they all admit simple and direct recognition and
generation algorithms and thus can be incorporated
naturally into realistic models of a finite agent&apos;s lan-
guage processing. Some parsing models have already
American Journal of Computational Linguistics, Volume 9, Number 1, January-March 1983 31
The FINITE STRING Newsletter Center for the Study of Language and Information
been constructed, and it seems that despite their su-
perficial differences, all of the theories depend on a
combination of algorithms for context-free analysis
and unification.
This project will study and implement alternative
ways of performing the mappings that the syntactic
theories describe, by extending current parsing tech-
nology and also by constructing new strategies for
language generation. We will also strive to understand
the computational consequences of various descriptive
devices that our formalisms include and perhaps devel-
op a computational rationale for choosing among
them.
</bodyText>
<subsectionHeader confidence="0.975938">
B. Theories of Situated Human Language
</subsectionHeader>
<bodyText confidence="0.9999662">
This collection of projects aims at developing scientific
theories of natural-language use consonant with our
basic perspective on language users as finite informa-
tion processors. Barbara Grosz has responsibility for
the overall guidance of Area B.
</bodyText>
<subsectionHeader confidence="0.9886785">
B.1. Extensions of semantic theories
Project Manager: Stanley Peters
</subsectionHeader>
<bodyText confidence="0.999962534883721">
Human languages contain a variety of expressive de-
vices whose meaning is poorly understood because
existing semantic theories are inadequately developed
in crucial respects. Some of these constructions are
well understood at the syntactic level, but either no
semantical analysis of them exists or the semantical
analyses that have been provided give no insight as to
how a finite agent with bounded computational re-
sources can understand them. Many key constructions
are related to our understanding of foundational is-
sues; the treatment of conditionals, for example, turns
on the treatment of constraints, a key notion in the
new theory of information emerging from situation
semantics.
Of particular interest is how the interpretation of
an utterance is related to its syntactic form. The prin-
ciple of compositionality is the claim that the meaning
of an expression is a function of the meanings of its
constituent parts. This principle has served as a guide
in Montague grammar and in most truth-conditional
accounts of meaning. However, such accounts have
usually ignored the difference between the meaning of
an expression and its interpretation in a given dis-
course, so the principle has become very confused.
Also, it is virtually a theorem that one can always
make meanings compositional if one makes them com-
plicated enough. The problem is to capture the intui-
tion behind the principle while keeping the theory
computationally tractable. Another aspect of the
problem is the application of the principle to languages
with freer word order than English, such as German,
Hebrew, and Walpiri.
We aim to develop computationally tractable se-
mantical analyses for a range of natural-language con-
structs not currently well understood. These will in-
clude tense, aspect, and time adverbials; comparatives;
reflexive pronouns and reciprocal noun phrases; mass
terms, plurals, and other forms of collective reference;
modal verbs and conditional sentences; locative prepo-
sitions and adverbials; and verbal modifiers in general.
Cases testing the principle of compositionality include
wide-scope phenomena, extraposition, and topicaliza-
tion.
</bodyText>
<listItem confidence="0.492772">
B.2. Semantics of sentences about mental states
Project Manager: John Perry
</listItem>
<bodyText confidence="0.986059413793104">
Of all types of expressions in natural language, sen-
tences about mental states, such as belief, desire, and
intention, play a uniquely important role in the devel-
opment of semantical theories. The reason for this is
that sentences about mental states typically involve
embedding a sentence or sentencelike expression in a
way that depends critically on the information content
of the embedded sentence. It has proved to be ex-
tremely difficult to develop a theory of natural-
language semantics that systematically assigns mean-
ings to sentences in such a way that the facts come out
right when those sentences are embedded in contexts
like John thinks that .... Many semantical theories
have foundered on exactly this issue.
Furthermore, understanding the semantics of sen-
tences about mental states provides essential support
for understanding the nature of mental states them-
selves, which is of critical importance to a comprehen-
sive theory of language use. New semantical theories
have cast all of these problems into a new light, in
ways that emphasize the informational focus of sen-
tences about mental states. These theories need to be
developed and tested by their ability to guide the de-
velopment of overall theories of natural-language se-
mantics and computational theories of mental states as
part of a comprehensive theory of linguistic communi-
cation.
B.3. Integrated syntactic and semantic accounts of
discourse
</bodyText>
<subsectionHeader confidence="0.261163">
Project Manager: Ivan Sag
</subsectionHeader>
<bodyText confidence="0.999926083333333">
Everyday language is rife with ellipses, sentence frag-
ments, and other anaphoric devices. At present, we
only partially understand these phenomena and hence
are unable to explain a central facet of situated lan-
guage. Work in linguistics has developed taxonomies
of anaphoric devices, isolating distinctive properties of
various types. Research in artificial intelligence has
isolated extralinguistic factors that influence the inter-
pretation of anaphoric elements, ellipses, and frag-
ments. And some psycholinguistic research has sug-
gested specific hypotheses about the way incomplete
sentences of various kinds are processed. We will
</bodyText>
<page confidence="0.575114">
32 American Journal of Computational Linguistics, Volume 9, Number 1, January-March 1983
</page>
<note confidence="0.642644">
The FINITE STRING Newsletter Center for the Study of Language and Information
</note>
<bodyText confidence="0.9997394">
attempt to isolate the levels of linguistic structure that
serve as the basis for the interpretation of elliptical,
fragmentary, and anaphoric sentences, and the compu-
tational processes by which these structures are manip-
ulated in language use.
</bodyText>
<subsectionHeader confidence="0.658575333333333">
B.4. Integration of semantical and computational
accounts of discourse
Project Manager: Barbara Grosz
</subsectionHeader>
<bodyText confidence="0.9987075">
Research in new semantic formalisms (e.g., by Barwise
and Perry) and semantical theories of discourse (e.g.,
by Kamp) have provided formal foundations and no-
tions such as &amp;quot;role&amp;quot; and &amp;quot;value loading&amp;quot; that are es-
sential for the explanation of the use of pronouns and
other referring expressions within a theory of dis-
course. However, this work so far has not considered
extended sequences of utterances and deals with dis-
course only statically. Research in artificial intelli-
gence (e.g., by Grosz and Sidner) has led to computa-
tional mechanisms such as focusing and centering to
address the same issues. This work has dealt with
extended sequences of utterances and with the dynam-
ics of discourse but has been based on inadequate
semantics. This project aims to integrate these two
treatments to provide a firm foundation for the com-
putational work and to extend the semantic work be-
yond a static view of discourse.
</bodyText>
<sectionHeader confidence="0.453794" genericHeader="method">
B.5. Communication
</sectionHeader>
<subsectionHeader confidence="0.734551">
Project Manager: Raymond Perrault
</subsectionHeader>
<bodyText confidence="0.999993892857143">
The study of language, not just as an abstract struc-
ture but as a medium through which agents exchange,
store, and process information, should place linguistic
behavior within the larger framework of a language-
independent theory of reasoning and action. A theory
of discourse, and of linguistic actions in general,
should tie actions to mental states, identify the effects
of utterances, and specify how mental states constrain
what acts can be performed. Starting from work in
artificial intelligence that extends plan construction
and recognition systems to include linguistic actions,
we shall attempt to provide a semantics for linguistic
actions inspired by semantic theories of programming
languages. In conjunction with the project on reason-
ing and planning (D.2), this should lead to algorithms
for the planning and recognition of complex actions,
including both linguistic and nonlinguistic subparts.
An important test for this theory will be to provide
a uniform account of questions, imperatives and decla-
ratives that shows, for example, relations between
questions and requests to assert. Making use of devel-
opments in the project on integrating semantical and
computational accounts of discourse (B.4), we will
extend the treatment of communicative acts to the
discourse level, including pronouns and referring ex-
pressions, and then study discourse elements that func-
tion as indications of how various parts of the dis-
course are to be related.
</bodyText>
<subsectionHeader confidence="0.587423">
C. Theories of Situated Computer Languages
</subsectionHeader>
<bodyText confidence="0.9995515">
The object of the projects of this section is to under-
stand current theories and practices of computing
within the perspective of computation as linguistic
activity. Area C is guided by Brian Smith.
</bodyText>
<subsectionHeader confidence="0.995825">
Cl. Semantics of computer languages
</subsectionHeader>
<bodyText confidence="0.999073">
Acting Project Manager: Jon Barwise (until a principal
in this area is found)
The aim of this project is to develop a semantic ac-
count of computation, rich enough to account for cur-
rent computational practice, that can lead into the
kind of theory developed in Area D dealing with the
foundations underlying a unified view of language. In
particular, we plan to develop a semantic account that
encompasses both natural and programming languages.
Because of the similarities between the information
systems in domain theory and the informational rela-
tions in situation semantics, one of our first aims will
be to connect with the substantial body of work that
has been done on programming languages by Dana
Scott and others working with Scott&apos;s domain theory.
To construct a theory that is adequate to deal with the
structures of current computation theory, we will try
to clarify the interrelation of three things: (1) the
higher order formalisms of computation theory; (2)
the formalisms normally used in programming lan-
guages, specification languages, verification systems,
and analysis systems; and (3) the new structures being
developed in situation semantics. Also, we will inves-
tigate the semantics of the reflective lambda calculus,
leading into the semantics of 3-LISP, and the seman-
tics of computational and reflective logics. Finally, we
will attempt to develop a general theory of the syntac-
tic and structural operations on which all formal sys-
tems are based (procedure calls, structural unifications,
schema instantiation, etc.).
</bodyText>
<subsectionHeader confidence="0.940076">
C.2. The analysis and design of linguistically coher-
ent computer languages
Project Manager: Terry Winograd
</subsectionHeader>
<bodyText confidence="0.96425784">
Traditional programming languages have been restrict-
ed primarily to commands; their syntax was essentially
trivial, although not their semantics. Now they are
becoming extremely complex — far more so, for exam-
ple, than the artificial languages typically studied in
mathematics. There are linguistic structures that deal
especially with temporality (sequencing, including the
interweaving of concurrent sequences), plurality (sets
and other such collections), metadescription
(constructs that refer to the program text or some
aspect of its interpretation, rather than to the compu-
tation it describes), and information grouping
American Journal of Computational Linguistics, Volume 9, Number 1, January-March 1983 33
The FINITE STRING Newsletter Center for the Study of Language and Information
(grouping into modules whose contents are in some
sense isolated from those of other modules). The aim
of this project is to put some theoretical order into this
rather diverse set of practices, partly to develop even
more powerful structural protocols and partly to un-
derstand a level of information complexity intermedi-
ate between natural and traditional formal languages.
We will concentrate on languages with declarative
structures (e.g., ALEPH and 4-LISP), on the relation
between description and control, and on the relation
between input/output and communication.
</bodyText>
<subsectionHeader confidence="0.739692">
C.3. Computational architectures for reasoning
Project Manager: Brian Smith
</subsectionHeader>
<bodyText confidence="0.99991525">
Under the assumption that computational processes
are radically idealized language users, it is natural to
develop specific architectures that use and reason with
language in just the ways that our theories describe.
The idea is to design a simple calculus that explicitly
reveals the important aspects of the emerging theory, a
role played by the first-order predicate calculus in the
development of logic and model theory. We will de-
velop a computational architecture, called MANTIQ,
that serves this role in our developing theories of lan-
guage in use.
MANTIQ will be based on essential insights from
both computational and natural languages. From the
computational side, it will draw on both procedural
languages (like LISP) and descriptive languages (such
as specification languages and knowledge-representa-
tion languages in artificial intelligence). It will also be
based on the theories of inference and reasoning that
grow out of our studies of natural language and out of
our foundational studies on information. Technically,
it rests on two important developments: a full theory
of what we call reflection and an internal notion of
structure based on information content. By reflection,
very briefly, we mean the ability of an agent to reason
effectively about its own operations, structures, and
behavior. Structurally, MANTIQ will be based directly
on the theories of intensional identity developed in the
foundational semantic parts of our overall program. A
goal of the MANTIQ design is to have internal struc-
tural identity directly encode semantic identity, which
will make it possible to describe the architecture en-
tirely in terms of content, in line with the information-
al orientation of our entire research program.
MANTIQ holds out the promise of modeling the
intentional aspects of human language use, which are
an essential part of a theory of action. It will also
serve both as a test bed and as a forcing function on
theories of belief, planning, and so forth. Formally, it
will rest on semantic accounts of concurrent architec-
tures and on theories of procedure (both mentioned in
project C.1 on the semantics of computer language);
its implementation may rely on the unification proce-
dures described in project A.4 on the computational
properties of parsing algorithms.
</bodyText>
<subsectionHeader confidence="0.824538">
D. Foundations Underlying a Unified View of
Language
</subsectionHeader>
<bodyText confidence="0.989962666666667">
This area aims at developing the philosophical and
mathematical foundations needed to support the theo-
ries on situated language. It is guided by John Perry.
</bodyText>
<reference confidence="0.535711">
D.1. Computation, information, and logic
Project Manager: Jon Barwise
</reference>
<bodyText confidence="0.999784882352941">
This project is intended to contribute to the mathe-
matical development of those parts of logic relevant to
our overall program on language, computation, and
information. In particular, we plan to study the math-
ematical properties of (semantic) information, relating
it to work in model theory and generalized recursion
theory as well as to the measure of information used in
Shannon&apos;s communication theory. Long-term goals of
this project include (a) providing theoretical concepts
with which to analyze the interaction of computation
and information in situated language users, both hu-
man and computer; (b) providing useful measures of
the semantic content of a message relative to certain
background information and constraints; (c) providing
more semantically relevant notions of computational
tractability; and (d) contributing to the logic of both
human and computing languages.
</bodyText>
<subsectionHeader confidence="0.433142">
D.2. Reasoning and planning
Project Manager: Stanley Rosenschein
</subsectionHeader>
<bodyText confidence="0.99996732">
This project will investigate the computational process-
es necessary to perform the reasoning required by the
use of language. It will be divided into three interre-
lated parts: reasoning about the external world, rea-
soning about mental states and actions, and planning.
In its first part, we will develop a formal, computa-
tional theory of commonsense reasoning precise
enough to permit a direct, efficient implementation.
We will limit ourselves to those aspects of the world
studied in the project on the commonsense world
(D.4). The second part on reasoning about mental
states is the computational complement of the project
on mind and action (D.3) and an extension of the
work already done by Moore, Appelt, and Konolige to
include desires and intentions. Finally, &amp;quot;planning,&amp;quot;
which denotes the mental processes by which inten-
tions are established and revised, is a form of reason-
ing that differs from general reasoning in that it has a
concrete aim: finding (executable descriptions of)
actions that achieve the agent&apos;s desires. While several
computational models of the planning process have
been suggested, there are still considerable difficulties
in handling more subtle notions of desire (e.g., graded
preferences), in smoothly integrating the monitoring
and replanning processes, and in reasoning about corn-
</bodyText>
<note confidence="0.5636605">
34 American Journal of Computational Linguistics, Volume 9, Number 1, January-March 1983
The FINITE STRING Newsletter Center for the Study of Language and Information
</note>
<bodyText confidence="0.994291625">
plex future actions that cannot easily be thought of as
sequences of abstract operations.
We also intend to explore whether an integrated
view of planning and reasoning was abandoned prema-
turely. One possible end result of our research would
be the disappearance of planning as a separate subject
of study altogether, subsumed in a more inclusive and
deeper theory of general reasoning.
</bodyText>
<listItem confidence="0.4477415">
D.3. Mind and action
Project Manager: John Perry
</listItem>
<bodyText confidence="0.9993794">
This project will attempt to bridge the gap between
computational theory and practice, on the one hand,
and philosophical insight, on the other, by using for-
mal methods to bring intuitive theories of mind and
action into a computational frame of reference. This
will involve building a common technical vocabulary,
possibly based on work in theoretical computer science
on formalizing the relation between levels of abstrac-
tion in the description of complex computational proc-
esses (e.g., work on abstract data structures and the
semantics of high-level languages). The ultimate goal
is either a computationally meaningful reinterpretation
of much of the intuitive terminology from the philoso-
phy of mind and practical reasoning or a more radical
revision of our ideas on how to describe mental struc-
ture and process. One important question we will try
to answer is whether our model should include as a
separate component each of the many attitudes that
our language names (e.g., believe, want, intend, fear).
If not, what criteria should be used to collapse them?
We will look at the relationship between an objective
&amp;quot;observer&apos;s&amp;quot; theory of mind and action and the com-
monsense &amp;quot;participants&apos;s&amp;quot; theory that we apply to
each other in everyday life. Further, we will examine
whether there is a systematic method for abstracting
the latter type of theory from the semantics of propo-
sitional attitudes, how we can account computationally
for how rational deliberation results in the causation
of action, and what mechanism lead to &amp;quot;changes of
mind.&amp;quot;
</bodyText>
<reference confidence="0.8403735">
D.4. The commonsense world
Project Manager: Robert C. Moore
</reference>
<bodyText confidence="0.998208368421053">
Generating and interpreting fluent natural language
requires considerable abilities to do commonsense
reasoning, which in turn presupposes an explicit elabo-
ration of our commonsense theories of the world.
Such theories are also needed for extending semantical
theories of natural language, since the semantics of our
language and our commonsense view of the world are
inextricably intertwined. We will focus on a handful
of commonsense theories that are so basic to our view
of the world that they arise in some form in almost
any domain of discourse, for example, the common-
sense theory of space and motion. We will also
choose areas in which natural language has evolved
special mechanisms for expressing information, so that
a commonsense theory in such an area is almost essen-
tial to carrying out the semantical analysis of that part
of language. The commonsense theory of time, for
instance, must be understood in order to explicate
adequately the semantics of tense and aspect.
</bodyText>
<sectionHeader confidence="0.960051" genericHeader="method">
Appendix: The Principals of CSLI
</sectionHeader>
<reference confidence="0.994552444444445">
Jon Barwise, Director of CSLI, Stanford University
Joan Bresnan, Stanford University and Xerox PARC
Barbara J. Grosz, SRI International
Ronald Kaplan, Xerox PARC
Lauri Karttunen, SRI International
Martin Kay, Xerox PARC
John McCarthy, Stanford University
Robert C. Moore, SRI International
C. Raymond Perrault, SRI International
John Perry, Stanford University
Stanley Peters, Associate Director of CSLI, Stanford
University
Stanley J. Rosenschein, SRI International
Ivan Sag, Stanford University
Patrick Suppes, Stanford University
Brian Cantwell Smith, Xerox PARC
Thomas Wasow, Stanford University
Terry Winograd, Stanford University
</reference>
<bodyText confidence="0.990236785714286">
Program for the 21st Annual Meeting of
the ACL
The 21st Annual Meeting of the Association for Com-
putational Linguistics will be held 15-17 June 1983 at
Massachusetts Institute of Technology, Cambridge,
Massachusetts, USA. In addition to refereed papers, it
will contain several new features. As a reflection of
continuing growth and specialization within computa-
tional linguistics, the program committee felt that se-
veral intellectual developments of potentially wide
interest required some introduction for non-specialists.
Accordingly, the authors of submitted papers in two of
these areas have been invited to give instead more
extensive presentations with more tutorial content.
David Israel will talk on computational implications of
Barwise and Perry&apos;s newly emergent theory of situa-
tion semantics and Mark Liberman will present a tuto-
rial overview on the new round of applications of
techniques from artificial intelligence and computa-
tional linguistics to low-level speech analysis and
phonetically-based speech recognition.
The sole panel discussion at the meeting is closely
linked to a set of papers which are part of a new wave
of work focusing on the computational complexity of
various grammatical formalisms and on the relevance
of such analyses. The program committee felt the
differing views expressed in these papers strongly in-
vited wider discussion. Ray Perrault has organized a
</bodyText>
<note confidence="0.366298">
American Journal of Computational Linguistics, Volume 9, Number 1, January-March 1983 35
</note>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000007">
<title confidence="0.8231595">The FINITE STRING Newsletter New Editor&apos;s Note</title>
<abstract confidence="0.99773290625">a pleasure to assume the editorship of FINITE it is such an important resource for our discipline and its community of researchers. success of FINITE STRING on two factors: • individual members supplying items of general interest to the readership, including announcements of meetings, summaries of research in progress, and abstracts timely publishing of that information by the staff. means you are a critical part of FINITE seek your help as an information source. For our part, we will make every effort to publish what you submit in the next issue after receipt. The section on abstracts of current literature is a important part of FINITE STRING. would like it to be a major reference tool, but that requires your contributions. Please send abstracts of papers, books, and technical reports, and call my attention to relevant work in out-of-the-way journals and proceedings that you think I might not see. I would particularly like to solicit brief summaries of research in progress at a given site. These descriptions should cover 4-12 double-spaced pages, depending on the number of participants. Providing a continuing perspective on the field in this way would provide an invaluable service to all; please take advantage of it. A report on the new Center for Study of Language and Information inaugurates this new feature. can FINITE STRING serve the readers? Please let me know.</abstract>
<author confidence="0.870067">Ralph Weischedel</author>
<author confidence="0.870067">Editor</author>
<affiliation confidence="0.761725333333333">The FINITE STRING Newsletter Center for the Study of Language and Information</affiliation>
<note confidence="0.687812">Research Program on Situated Language Founded early in 1983, the Center for the Study of Language and Information (CSLI) at Stanford Univer-</note>
<abstract confidence="0.991532418181818">sity grew out of a long-standing collaboration between scientists at research laboratories in the Palo Alto area and the faculty and students of several Stanford University departments and out of a need for an institutional focus for this work on natural and computer languages. At present, CSLI has 17 senior members, or &amp;quot;principals&amp;quot; (listed in the Appendix), and about as associate members, from Xerox PARC, Fairchild, and the Departments of Computer Science, Linguistics, and Philosophy at Stanford. Since the Center&apos;s research will overlap with the work of other researchers around the world, an important goal of CSLI will be to initiate a major outreact, whereby members of CSLI both inform themselves of work done elsewhere and share their own results with others. As its first major research program, CSLI is undera study of situated language, SL, is based on three insights: (1) Language use is fundamentally computational in that it is used by finite agents with limited resources to process, store, and communicate information; (2) computational practice is fundamentally linguistic in that computers are used by humans under the assumption that the symbols and processes of computers are about entities in the world; and (3) understanding linguistic activity in any real situation requires theories based on solid semantic foundations, connecting computation and language with information about the world. The major goals of the program, dictated by the current state of affairs in research on languages, are: (1) to extend the study of natural language to include the active, situated agent; (2) to extend the study of computer languages to consider information content and the embedding world; and (3) to merge the insights and theories of these two traditions into an integrated whole, based on solid philosophical and mathematical foundations. Program SL, outlined here, comprises 16 projects in four areas: (A) the evaluation and development of syntax, morphology, and phonology, as well as the study of their computational aspects and their relation language use; development of theories of natural-language use from the perspective of language users as finite processors of information derived from world; (C) the understanding of computing lan- Journal of Computational Linguistics, Volume 9, Number 1, January-March 1983 The FINITE STRING Newsletter Center for the Study of Language and Information guages and architectures supporting the thesis of computation as linguistic activity; and (D) the development of the philosophical and mathematical foundations needed to support the theories on situated language use. Questions about CSLI or Program SL should be addressed to Dr. Elizabeth Macken, Assistant Direc-</abstract>
<address confidence="0.761735">tor, CSLI, Ventura Hall, Stanford University, Stanford, CA 94305.</address>
<abstract confidence="0.993792018329939">A. Traditional Linguistics and Situated Language This collection of projects will evaluate and further develop areas of traditional linguistics — syntax, phonology, and morphology — in the light of our commitment to computation, semantics, and language use. Stanley Peters has responsibility for the overall guidance of Area A. A.1. Phonology, morphology, and syntax Manager: Karttunen (Ronald Kaplan during fall 1983) New theories of lexical phonology and morphology have stressed the natural decomposition of soundmapping rules into word-internal and phrasal types, each having distinctive properties. Independently of this, new syntactic theories have given evidence that many processes previously thought to be syntactic are morphological. To explore further the relation between phonology and morphosyntax, and their contribution to meaning, this project will study word formation and syntax in a representative sample of morphologically varying language types. The results of these studies will be integrated with the current theory of morphologically governed sound structure. We will also look into whether there is a natural computational interpretation for the theoretically motivated rules and representations and whether the natural phonological and morphological algorithms interact properly with higher level syntactic and functional computations. We will investigate syntactic structure as it relates to semantic interpretation and sentence generation. The study of syntax is particularly relevant in the context of topics such as the extensions of semantic theories (B.1). To develop adequate semantic treatments for many of the constructions listed there, we need better descriptions of their syntactic composition. We will try to integrate the insights of current theoretical approaches to syntax, such as lexical-functional grammar, generalized phrase structure grammar, and government binding theory. Another topic with close connections to syntax is the computational properties of parsing algorithms (A.4). A.2. The effect of syntax and phonology on discourse structure Manager: Bresnan Our current theories of phonology and syntax are largely restricted to the phrase and sentence levels, respectively. Theories of discourse are largely unconnected with the phonological and syntactic levels, yet several cases are known where theoretical accounts at one of these levels depend on factors at another. Phrase-level phonological grammars have advanced our knowledge of sound variation and intonation, yet they do not show how these phenomena depend on syntactic and discourse boundaries. Conversely, intonation influences illocutionary force, as does the discourse situation. Certain sentence forms (e.g., clefts and topicalization) influence focusing and centering and thus constrain the referents of pronouns. This project will investigate the relation between the phonological, syntactic, and discourse levels and the computational problems involved in doing recognition and generation across them. A.3. Strategies and tactics in the processing of utterances Manager: Kaplan Many sentences have multiple meanings, though in any given context one is typically preferred. To model effective communication, we need to develop algorithms that produce the preferred reading. Semantic and pragmatic factors strongly influence preferences, but there is also evidence for independent lexical and syntactic effects. Explicit computational models of how lexical and syntactic properties interact during the comprehension process have also been developed. To simplify the development of the theory of lexicosyntactic interactions, possible semantic and pragmatic influences were treated as constant boundary conditions that could be ignored, at least temporarily. As our computational theories of discourse and semantics improve to the point at which coherent characterizations of the situational context can be given, we expect to be able to extend our theory of ambiguity resolution to account for the interacting influence of factors at all levels of analysis. The result of this project, then, will be a full-fledged model of sentence interpretation that is sensitive to both structural and contextual factors. A.4. Computational properties of parsing algorithms Manager: Peters Principals of CSLI have developed and are currently investigating several formalisms for encoding syntactic descriptions of natural languages: the generalized phrase structure grammar (GPSG), the lexicalfunctional grammar (LFG), the phrase-linking gramand theories are noteworthy in that they all admit simple and direct recognition and generation algorithms and thus can be incorporated naturally into realistic models of a finite agent&apos;s language processing. Some parsing models have already Journal of Computational Linguistics, Volume 9, Number 1, January-March 1983 The FINITE STRING Newsletter Center for the Study of Language and Information been constructed, and it seems that despite their superficial differences, all of the theories depend on a combination of algorithms for context-free analysis and unification. This project will study and implement alternative ways of performing the mappings that the syntactic theories describe, by extending current parsing technology and also by constructing new strategies for language generation. We will also strive to understand the computational consequences of various descriptive devices that our formalisms include and perhaps develop a computational rationale for choosing among them. B. Theories of Situated Human Language This collection of projects aims at developing scientific theories of natural-language use consonant with our basic perspective on language users as finite information processors. Barbara Grosz has responsibility for the overall guidance of Area B. B.1. Extensions of semantic theories Manager: Peters Human languages contain a variety of expressive devices whose meaning is poorly understood because existing semantic theories are inadequately developed in crucial respects. Some of these constructions are well understood at the syntactic level, but either no semantical analysis of them exists or the semantical analyses that have been provided give no insight as to how a finite agent with bounded computational resources can understand them. Many key constructions are related to our understanding of foundational issues; the treatment of conditionals, for example, turns on the treatment of constraints, a key notion in the new theory of information emerging from situation semantics. Of particular interest is how the interpretation of an utterance is related to its syntactic form. The principle of compositionality is the claim that the meaning of an expression is a function of the meanings of its constituent parts. This principle has served as a guide in Montague grammar and in most truth-conditional accounts of meaning. However, such accounts have usually ignored the difference between the meaning of an expression and its interpretation in a given discourse, so the principle has become very confused. Also, it is virtually a theorem that one can always make meanings compositional if one makes them complicated enough. The problem is to capture the intuition behind the principle while keeping the theory computationally tractable. Another aspect of the problem is the application of the principle to languages with freer word order than English, such as German, Hebrew, and Walpiri. We aim to develop computationally tractable semantical analyses for a range of natural-language constructs not currently well understood. These will include tense, aspect, and time adverbials; comparatives; reflexive pronouns and reciprocal noun phrases; mass terms, plurals, and other forms of collective reference; modal verbs and conditional sentences; locative prepositions and adverbials; and verbal modifiers in general. Cases testing the principle of compositionality include wide-scope phenomena, extraposition, and topicalization. B.2. Semantics of sentences about mental states Manager: Perry Of all types of expressions in natural language, sentences about mental states, such as belief, desire, and intention, play a uniquely important role in the development of semantical theories. The reason for this is that sentences about mental states typically involve embedding a sentence or sentencelike expression in a that depends critically on the content of the embedded sentence. It has proved to be extremely difficult to develop a theory of naturallanguage semantics that systematically assigns meanings to sentences in such a way that the facts come out right when those sentences are embedded in contexts thinks that .... semantical theories have foundered on exactly this issue. Furthermore, understanding the semantics of sentences about mental states provides essential support for understanding the nature of mental states themselves, which is of critical importance to a comprehensive theory of language use. New semantical theories have cast all of these problems into a new light, in ways that emphasize the informational focus of sentences about mental states. These theories need to be developed and tested by their ability to guide the development of overall theories of natural-language semantics and computational theories of mental states as part of a comprehensive theory of linguistic communication. B.3. Integrated syntactic and semantic accounts of discourse Manager: Sag Everyday language is rife with ellipses, sentence fragments, and other anaphoric devices. At present, we only partially understand these phenomena and hence unable to explain a central facet of situated lanin linguistics has developed taxonomies of anaphoric devices, isolating distinctive properties of various types. Research in artificial intelligence has isolated extralinguistic factors that influence the interpretation of anaphoric elements, ellipses, and fragpsycholinguistic research has suggested specific hypotheses about the way incomplete sentences of various kinds are processed. We will 32 American Journal of Computational Linguistics, Volume 9, Number 1, January-March 1983 The FINITE STRING Newsletter Center for the Study of Language and Information attempt to isolate the levels of linguistic structure that serve as the basis for the interpretation of elliptical, fragmentary, and anaphoric sentences, and the computational processes by which these structures are manipulated in language use. B.4. Integration of semantical and computational accounts of discourse Manager: Grosz Research in new semantic formalisms (e.g., by Barwise and Perry) and semantical theories of discourse (e.g., by Kamp) have provided formal foundations and notions such as &amp;quot;role&amp;quot; and &amp;quot;value loading&amp;quot; that are essential for the explanation of the use of pronouns and other referring expressions within a theory of discourse. However, this work so far has not considered extended sequences of utterances and deals with discourse only statically. Research in artificial intelligence (e.g., by Grosz and Sidner) has led to computational mechanisms such as focusing and centering to address the same issues. This work has dealt with extended sequences of utterances and with the dynamics of discourse but has been based on inadequate semantics. This project aims to integrate these two treatments to provide a firm foundation for the computational work and to extend the semantic work beyond a static view of discourse. B.5. Communication Manager: Perrault The study of language, not just as an abstract structure but as a medium through which agents exchange, store, and process information, should place linguistic behavior within the larger framework of a languageindependent theory of reasoning and action. A theory of discourse, and of linguistic actions in general, should tie actions to mental states, identify the effects of utterances, and specify how mental states constrain what acts can be performed. Starting from work in artificial intelligence that extends plan construction and recognition systems to include linguistic actions, we shall attempt to provide a semantics for linguistic actions inspired by semantic theories of programming languages. In conjunction with the project on reasoning and planning (D.2), this should lead to algorithms for the planning and recognition of complex actions, including both linguistic and nonlinguistic subparts. An important test for this theory will be to provide a uniform account of questions, imperatives and declaratives that shows, for example, relations between questions and requests to assert. Making use of developments in the project on integrating semantical and computational accounts of discourse (B.4), we will extend the treatment of communicative acts to the discourse level, including pronouns and referring expressions, and then study discourse elements that function as indications of how various parts of the discourse are to be related. C. Theories of Situated Computer Languages The object of the projects of this section is to understand current theories and practices of computing within the perspective of computation as linguistic activity. Area C is guided by Brian Smith. Cl. Semantics of computer languages Project Manager: Barwise (until a principal in this area is found) The aim of this project is to develop a semantic account of computation, rich enough to account for current computational practice, that can lead into the kind of theory developed in Area D dealing with the foundations underlying a unified view of language. In particular, we plan to develop a semantic account that encompasses both natural and programming languages. Because of the similarities between the information systems in domain theory and the informational relations in situation semantics, one of our first aims will be to connect with the substantial body of work that has been done on programming languages by Dana Scott and others working with Scott&apos;s domain theory. To construct a theory that is adequate to deal with the structures of current computation theory, we will try to clarify the interrelation of three things: (1) the higher order formalisms of computation theory; (2) the formalisms normally used in programming languages, specification languages, verification systems, and analysis systems; and (3) the new structures being developed in situation semantics. Also, we will investigate the semantics of the reflective lambda calculus, leading into the semantics of 3-LISP, and the semantics of computational and reflective logics. Finally, we will attempt to develop a general theory of the syntactic and structural operations on which all formal systems are based (procedure calls, structural unifications, schema instantiation, etc.). C.2. The analysis and design of linguistically coherent computer languages Manager: Winograd Traditional programming languages have been restricted primarily to commands; their syntax was essentially trivial, although not their semantics. Now they are becoming extremely complex — far more so, for example, than the artificial languages typically studied in mathematics. There are linguistic structures that deal especially with temporality (sequencing, including the interweaving of concurrent sequences), plurality (sets and other such collections), metadescription (constructs that refer to the program text or some aspect of its interpretation, rather than to the computation it describes), and information grouping Journal of Computational Linguistics, Volume 9, Number 1, January-March 1983 The FINITE STRING Newsletter Center for the Study of Language and Information (grouping into modules whose contents are in some sense isolated from those of other modules). The aim of this project is to put some theoretical order into this rather diverse set of practices, partly to develop even more powerful structural protocols and partly to understand a level of information complexity intermediate between natural and traditional formal languages. We will concentrate on languages with declarative (e.g., the relation between description and control, and on the relation between input/output and communication. C.3. Computational architectures for reasoning Manager: Smith Under the assumption that computational processes are radically idealized language users, it is natural to develop specific architectures that use and reason with language in just the ways that our theories describe. The idea is to design a simple calculus that explicitly reveals the important aspects of the emerging theory, a role played by the first-order predicate calculus in the development of logic and model theory. We will develop a computational architecture, called MANTIQ, that serves this role in our developing theories of language in use. be based on essential insights from both computational and natural languages. From the computational side, it will draw on both procedural languages (like LISP) and descriptive languages (such as specification languages and knowledge-representation languages in artificial intelligence). It will also be based on the theories of inference and reasoning that grow out of our studies of natural language and out of our foundational studies on information. Technically, it rests on two important developments: a full theory of what we call reflection and an internal notion of structure based on information content. By reflection, very briefly, we mean the ability of an agent to reason effectively about its own operations, structures, and behavior. Structurally, MANTIQ will be based directly on the theories of intensional identity developed in the foundational semantic parts of our overall program. A goal of the MANTIQ design is to have internal structural identity directly encode semantic identity, which will make it possible to describe the architecture entirely in terms of content, in line with the informational orientation of our entire research program. out the promise of modeling the intentional aspects of human language use, which are an essential part of a theory of action. It will also serve both as a test bed and as a forcing function on theories of belief, planning, and so forth. Formally, it will rest on semantic accounts of concurrent architectures and on theories of procedure (both mentioned in project C.1 on the semantics of computer language); its implementation may rely on the unification procedures described in project A.4 on the computational properties of parsing algorithms. D. Foundations Underlying a Unified View of Language This area aims at developing the philosophical and mathematical foundations needed to support the theories on situated language. It is guided by John Perry. D.1. Computation, information, and logic Manager: Barwise This project is intended to contribute to the mathematical development of those parts of logic relevant to our overall program on language, computation, and information. In particular, we plan to study the mathematical properties of (semantic) information, relating it to work in model theory and generalized recursion theory as well as to the measure of information used in Shannon&apos;s communication theory. Long-term goals of this project include (a) providing theoretical concepts with which to analyze the interaction of computation and information in situated language users, both human and computer; (b) providing useful measures of the semantic content of a message relative to certain background information and constraints; (c) providing more semantically relevant notions of computational tractability; and (d) contributing to the logic of both human and computing languages. D.2. Reasoning and planning Manager: Rosenschein This project will investigate the computational processes necessary to perform the reasoning required by the use of language. It will be divided into three interrelated parts: reasoning about the external world, reasoning about mental states and actions, and planning. In its first part, we will develop a formal, computational theory of commonsense reasoning precise enough to permit a direct, efficient implementation. We will limit ourselves to those aspects of the world studied in the project on the commonsense world (D.4). The second part on reasoning about mental states is the computational complement of the project on mind and action (D.3) and an extension of the work already done by Moore, Appelt, and Konolige to include desires and intentions. Finally, &amp;quot;planning,&amp;quot; which denotes the mental processes by which intentions are established and revised, is a form of reasoning that differs from general reasoning in that it has a concrete aim: finding (executable descriptions of) actions that achieve the agent&apos;s desires. While several computational models of the planning process have been suggested, there are still considerable difficulties in handling more subtle notions of desire (e.g., graded preferences), in smoothly integrating the monitoring replanning processes, and in reasoning about corn- 34 American Journal of Computational Linguistics, Volume 9, Number 1, January-March 1983 The FINITE STRING Newsletter Center for the Study of Language and Information plex future actions that cannot easily be thought of as sequences of abstract operations. We also intend to explore whether an integrated view of planning and reasoning was abandoned prematurely. One possible end result of our research would be the disappearance of planning as a separate subject of study altogether, subsumed in a more inclusive and deeper theory of general reasoning. D.3. Mind and action Manager: Perry This project will attempt to bridge the gap between computational theory and practice, on the one hand, and philosophical insight, on the other, by using formal methods to bring intuitive theories of mind and action into a computational frame of reference. This will involve building a common technical vocabulary, possibly based on work in theoretical computer science on formalizing the relation between levels of abstraction in the description of complex computational processes (e.g., work on abstract data structures and the semantics of high-level languages). The ultimate goal is either a computationally meaningful reinterpretation of much of the intuitive terminology from the philosophy of mind and practical reasoning or a more radical revision of our ideas on how to describe mental structure and process. One important question we will try to answer is whether our model should include as a separate component each of the many attitudes that language names (e.g., want, intend, fear). If not, what criteria should be used to collapse them? We will look at the relationship between an objective &amp;quot;observer&apos;s&amp;quot; theory of mind and action and the commonsense &amp;quot;participants&apos;s&amp;quot; theory that we apply to each other in everyday life. Further, we will examine whether there is a systematic method for abstracting the latter type of theory from the semantics of propositional attitudes, how we can account computationally for how rational deliberation results in the causation of action, and what mechanism lead to &amp;quot;changes of mind.&amp;quot; D.4. The commonsense world Manager: C. Moore Generating and interpreting fluent natural language requires considerable abilities to do commonsense reasoning, which in turn presupposes an explicit elaboration of our commonsense theories of the world. Such theories are also needed for extending semantical theories of natural language, since the semantics of our language and our commonsense view of the world are inextricably intertwined. We will focus on a handful of commonsense theories that are so basic to our view of the world that they arise in some form in almost any domain of discourse, for example, the commonsense theory of space and motion. We will also choose areas in which natural language has evolved special mechanisms for expressing information, so that a commonsense theory in such an area is almost essential to carrying out the semantical analysis of that part of language. The commonsense theory of time, for instance, must be understood in order to explicate adequately the semantics of tense and aspect.</abstract>
<note confidence="0.3328215">Appendix: The Principals of CSLI Jon Barwise, Director of CSLI, Stanford University</note>
<author confidence="0.806338">Joan Bresnan</author>
<author confidence="0.806338">Stanford University</author>
<author confidence="0.806338">Xerox PARC Barbara J Grosz</author>
<author confidence="0.806338">SRI International Ronald Kaplan</author>
<author confidence="0.806338">Xerox PARC</author>
<affiliation confidence="0.604950666666667">Lauri Karttunen, SRI International Martin Kay, Xerox PARC John McCarthy, Stanford University</affiliation>
<author confidence="0.593751">C Moore</author>
<affiliation confidence="0.864135">C. Raymond Perrault, SRI International John Perry, Stanford University</affiliation>
<address confidence="0.896815">Stanley Peters, Associate Director of CSLI, Stanford</address>
<affiliation confidence="0.828687">University Stanley J. Rosenschein, SRI International Ivan Sag, Stanford University Patrick Suppes, Stanford University</affiliation>
<author confidence="0.724192">Brian Cantwell Smith</author>
<author confidence="0.724192">Xerox PARC</author>
<note confidence="0.831805666666667">Thomas Wasow, Stanford University Terry Winograd, Stanford University Program for the 21st Annual Meeting of the ACL The 21st Annual Meeting of the Association for Computational Linguistics will be held 15-17 June 1983 at</note>
<affiliation confidence="0.987011">Massachusetts Institute of Technology, Cambridge,</affiliation>
<address confidence="0.742685">Massachusetts, USA. In addition to refereed papers, it</address>
<abstract confidence="0.997035">will contain several new features. As a reflection of continuing growth and specialization within computational linguistics, the program committee felt that se-</abstract>
<intro confidence="0.540687">veral intellectual developments of potentially wide</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>D 1 Computation</author>
</authors>
<title>information, and logic Project Manager: Jon Barwise D.4. The commonsense world Project Manager: Robert C.</title>
<institution>Moore Jon Barwise, Director of CSLI, Stanford University Joan Bresnan, Stanford University and Xerox PARC</institution>
<marker>Computation, </marker>
<rawString>D.1. Computation, information, and logic Project Manager: Jon Barwise D.4. The commonsense world Project Manager: Robert C. Moore Jon Barwise, Director of CSLI, Stanford University Joan Bresnan, Stanford University and Xerox PARC</rawString>
</citation>
<citation valid="false">
<authors>
<author>Barbara J Grosz</author>
</authors>
<institution>SRI International Ronald Kaplan, Xerox PARC Lauri Karttunen, SRI International</institution>
<marker>Grosz, </marker>
<rawString>Barbara J. Grosz, SRI International Ronald Kaplan, Xerox PARC Lauri Karttunen, SRI International</rawString>
</citation>
<citation valid="false">
<authors>
<author>Martin Kay</author>
</authors>
<institution>Xerox PARC John McCarthy, Stanford University</institution>
<marker>Kay, </marker>
<rawString>Martin Kay, Xerox PARC John McCarthy, Stanford University</rawString>
</citation>
<citation valid="false">
<authors>
<author>Robert C Moore</author>
<author>SRI International C Raymond Perrault</author>
</authors>
<institution>SRI International John Perry, Stanford University</institution>
<marker>Moore, Perrault, </marker>
<rawString>Robert C. Moore, SRI International C. Raymond Perrault, SRI International John Perry, Stanford University</rawString>
</citation>
<citation valid="false">
<authors>
<author>Stanley Peters</author>
</authors>
<title>Associate Director of CSLI,</title>
<publisher>Stanford University</publisher>
<marker>Peters, </marker>
<rawString>Stanley Peters, Associate Director of CSLI, Stanford University</rawString>
</citation>
<citation valid="false">
<authors>
<author>Stanley J Rosenschein</author>
</authors>
<institution>SRI International Ivan Sag, Stanford University Patrick Suppes, Stanford University</institution>
<marker>Rosenschein, </marker>
<rawString>Stanley J. Rosenschein, SRI International Ivan Sag, Stanford University Patrick Suppes, Stanford University</rawString>
</citation>
<citation valid="false">
<authors>
<author>Brian Cantwell Smith</author>
</authors>
<institution>Xerox PARC Thomas Wasow, Stanford University</institution>
<marker>Smith, </marker>
<rawString>Brian Cantwell Smith, Xerox PARC Thomas Wasow, Stanford University</rawString>
</citation>
<citation valid="false">
<authors>
<author>Terry Winograd</author>
</authors>
<institution>Stanford University</institution>
<marker>Winograd, </marker>
<rawString>Terry Winograd, Stanford University</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>