<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.014955">
<title confidence="0.9465435">
UAlacant: Using Online Machine Translation for
Cross-Lingual Textual Entailment
</title>
<author confidence="0.88957">
Miquel Espl`a-Gomis and Felipe S´anchez-Martinez and Mikel L. Forcada
</author>
<affiliation confidence="0.857308">
Departament de Llenguatges i Sistemes Inform`atics
</affiliation>
<address confidence="0.88126">
Universitat d’Alacant, E-03071 Alacant, Spain
</address>
<email confidence="0.998953">
{mespla,fsanchez,mlf}@dlsi.ua.es
</email>
<sectionHeader confidence="0.997386" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999884923076923">
This paper describes a new method for cross-
lingual textual entailment (CLTE) detection
based on machine translation (MT). We use
sub-segment translations from different MT
systems available online as a source of cross-
lingual knowledge. In this work we describe
and evaluate different features derived from
these sub-segment translations, which are used
by a support vector machine classifier to detect
CLTEs. We presented this system to the Se-
mEval 2012 task 8 obtaining an accuracy up to
59.8% on the English–Spanish test set, the sec-
ond best performing approach in the contest.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999911678571429">
Cross-lingual textual entailment (CLTE) detec-
tion (Mehdad et al., 2010) is an extension of the
textual entailment (TE) detection (Dagan et al., 2006)
problem. TE detection consists of finding out, for
two text fragments T and H in the same language,
whether T entails H from a semantic point of view
or not. CLTE presents a similar problem, but with T
and H written in different languages.
During the last years, many authors have focused
on resolving TE detection, as solutions to this prob-
lem have proved to be useful in many natural lan-
guage processing tasks, such as question answer-
ing (Harabagiu and Hickl, 2006) or machine trans-
lation (MT) (Mirkin et al., 2009; Pad´o et al., 2009).
Therefore, CLTE may also be useful for related tasks
in which more than one language is involved, such
as cross-lingual question answering or cross-lingual
information retrieval. Although CLTE detection is
a relatively new problem, it has already been tack-
led. Mehdad et al. (2010) propose to use machine
translation (MT) to translate H from LH, the lan-
guage of H, into LT, the language of T, and then use
any of the state-of-the-art TE approaches. In a later
work (Mehdad et al., 2011), the authors use MT, but
in a more elaborate way. They train a phrase-based
statistical MT (PBSMT) system (Koehn et al., 2003)
translating from LH to LT, and use the translation
table obtained as a by-product of the training process
to extract a set of features which are processed by a
support vector machine classifier (Theodoridis and
Koutroumbas, 2009, Sect. 3.7) to decide whether T
entails H or not. Castillo (2011) discusses another
machine learning approach in which the features are
obtained from semantic similarity measures based on
WordNet (Miller, 1995).
In this work we present a new approach to tackle
the problem of CLTE detection using a machine learn-
ing approach, partly inspired by that of Mehdad et
al. (2011). Our method uses MT as a source of infor-
mation to detect semantic relationships between T
and H. To do so, we firstly split both T and H into
all the possible sub-segments with lengths between 1
and L, the maximum length, measured in words. We
then translate the set of sub-segments from T into
LH, and vice versa, and collect all the sub-segment
pairs in a single set. We claim that when T-side
sub-segments match T and their corresponding H-
side sub-segments match H, this reveals a semantic
relationship between them, which can be used to de-
termine whether T entails H or not. Note that MT
is used as a black box, i.e. sub-segment translations
may be collected from any MT system, and that our
approach could even use any other sources of bilin-
gual sub-sentential information. It is even possible
to combine different MT systems as we do in our
experiments. This is a key point of our work, since
</bodyText>
<page confidence="0.980792">
472
</page>
<note confidence="0.5294215">
First Joint Conference on Lexical and Computational Semantics (*SEM), pages 472–476,
Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.996869727272727">
it uses MT in a more elaborate way than Mehdad et
al. (2010), and it does not depend on a specific MT
approach. Another important difference between this
work and that of Mehdad et al. (2011) is the set of
features used for classification.
The paper is organized as follows: Section 2 de-
scribes the method used to collect the MT informa-
tion and obtain the features; Section 3 explains the
experimental framework; Section 4 shows the results
obtained for the different features combination pro-
posed; the paper ends with concluding remarks.
</bodyText>
<sectionHeader confidence="0.990807" genericHeader="method">
2 Features from machine translation
</sectionHeader>
<bodyText confidence="0.999953666666667">
Our approach uses MT as a black box to detect par-
allelisms between the text fragments T and H by
following these steps:
</bodyText>
<equation confidence="0.985275777777778">
1. T is segmented in all possible sub-segments
t�+p−1 of length p with 1 ≤ p ≤ L and 1 ≤
�
M ≤ |T  |− p + 1, where L is the maximum
sub-segment length allowed. Analogously, H is
segmented to get all the possible sub-segments
hn+q−1 of length q, with 1 ≤ q ≤ L and 1 ≤
n
n ≤ |T |− q + 1.
</equation>
<listItem confidence="0.88511675">
2. The sub-segments obtained from T are trans-
lated using all the available MT systems into
LH. Analogously, the sub-segments from H
are translated into LT, to generate a set of sub-
segment pairs (t, h).
3. Those pairs of sub-segments (t, h) such that t is
a sub-string of T and h is a sub-string of H are
annotated as sub-segment links.
</listItem>
<bodyText confidence="0.998618888888889">
Note that it could be possible to use statistical MT to
translate both T and H and then use word alignments
to obtain the sub-segment links. However, we use this
methodology to ensure that any kind of MT system
can be used by our approach. As a result of this
process, a sub-segment in T may be linked to more
than one sub-segment in H, and vice versa. Based
on these sub-segment links we have designed a set of
features which may be used by a classifier for CLTE.
</bodyText>
<subsectionHeader confidence="0.995316">
2.1 Basic features [Bas]
</subsectionHeader>
<bodyText confidence="0.993472833333333">
We used a set of basic features to represent the infor-
mation from the sub-segment links between T and H,
which are computed as the fraction of words in each
of them covered by linked sub-segments of length
l ∈ [1, L]. We define the feature function Fl(S),
applied on a text fragment S (either T or H) as:
</bodyText>
<equation confidence="0.98761">
Fl(S) = Cov(S, l)/|S|
</equation>
<bodyText confidence="0.9999666">
where Cov(S, l) is a function which obtains the num-
ber of words in S covered by at least one sub-segment
of length l which is part of a sub-segment link. An
additional feature is computed to represent the total
proportion of words in each text fragment:
</bodyText>
<equation confidence="0.963883">
Ftotal(S) = Cov(S, ∗)/|S|
</equation>
<bodyText confidence="0.9999897">
where Cov(S, ∗) is the same as Cov(S, l) but using
sub-segments of any length up to L. Ftotal(S) pro-
vide information about overlapping that Fl(S) can-
not grasp. For instance, if we have F1(T) = 0.5 and
F2(T) = 0.5, we cannot know if the sub-segments
of l = 1 and l = 2 are covering the same or different
words, so Ftotal(S) represents the actual proportion
of words covered in a text fragment S. These fea-
ture functions are applied both on T and H, thus
obtaining a set of 2 ∗ L + 2 features, henceforth Bas.
</bodyText>
<subsectionHeader confidence="0.997952">
2.2 Extensions to the basic features
</subsectionHeader>
<bodyText confidence="0.990515888888889">
Some extensions can be made to the basic features
defined above by using additional external resources.
In this section we propose two extensions.
Separate analysis of function words and content
words [Spl]. In this case, features represent, sepa-
rately, function words, with poor lexical information,
and content words, with richer lexical and seman-
tic information. In this way, Fl(S) is divided into
FFl(S) and CFl(S) defined as:
</bodyText>
<equation confidence="0.905238">
FFl(S) = CovF(S,l)/|FW(S)|
and
CFl(S) = CovC(S, l)/|CW(S)|
</equation>
<bodyText confidence="0.9998961">
where FW(S) is a function that returns the func-
tion words in text fragment S and CW(S) per-
forms the same task for content words. Analogously,
CovF(S, l) and CovC(S, l) are versions of Cov(S, l)
which only consider function and content words, re-
spectively. This extension can be also be applied to
Ftotal(T) and Ftotal(H). The set of 4L + 4 features
obtained in this way (henceforth Spl) allows the clas-
sifier to use the information from the most relevant
words in T and H to detect entailment.
</bodyText>
<page confidence="0.997109">
473
</page>
<bodyText confidence="0.999898714285714">
Stemming [Stm and SplStm]. Stemming can also
be used when detecting the sub-segment links. Both
the table of sub-segment pairs and the text fragment
pair (T,H) are stemmed before matching. In this
way, conflicts of number or gender disagreement in
the translations can be overcome in order to detect
more sub-segment links. This new extension can
be applied both to Bas, obtaining the set of features
Stm, and to Spl, obtaining the set of features SplStm.
Although lemmatization could have been used, stem-
ming was preferred because it does not require the
part-of-speech ambiguity to be solved, which may
be difficult to solve when dealing with very short
sub-segments.
</bodyText>
<subsectionHeader confidence="0.996889">
2.3 Additional features
</subsectionHeader>
<bodyText confidence="0.999833833333333">
Two additional features were defined unrelated with
the basic features proposed. The first one, called here
R, is the length ratio |T|/|H|. Intuitively we can
guess that if H is much longer than T it is unlikely
that T entails H.
The second additional set of features is the one
defined by Mehdad et al. (2011), so we will refer to
it as M. The corresponding feature function com-
putes, for the total number of sub-segments of a given
length l E [1, L] obtained from a text fragment S, the
fraction of them which appear in a sub-segment link.
It is applied both to H and T and is defined as:
</bodyText>
<equation confidence="0.983609">
Fl0 (S) = Linkedl(S)/(|S |− l + 1)
</equation>
<bodyText confidence="0.9931935">
where Linkedl is the number of sub-segments from
S with length l which appear in a sub-segment link.
</bodyText>
<sectionHeader confidence="0.998007" genericHeader="method">
3 Experimental settings
</sectionHeader>
<bodyText confidence="0.992608173913044">
The experiments designed for this task are aimed
at evaluating the features proposed in Section 2.
We evaluate our CLTE approach using the English–
Spanish data sets provided in the task 8 of SemEval
2012 (Negri et al., 2012).
Datasets. Two datasets were provided by the or-
ganization of SemEval 2012 (Negri et al., 2011): a
training set and a test set, both composed by a set
of 500 pairs of sentences. CLTE detection is evalu-
ated in both directions, so instances belong to one of
these four classes: forward (the sentence in Spanish
entails the one in English); backward (the sentence
in English entails the one in Spanish); bidirectional
(both sentences entail each other); and no entailment
(neither of the sentences entails each other).
For the whole data set, both sentences in each in-
stance were tokenized using the scripts1 included in
the Moses MT system (Koehn et al., 2007). Each sen-
tence was segmented to get all possible sub-segments
which were then translated into the other language.
External resources. We used three different MT
systems to translate the sub-segments from English
to Spanish, and vice versa:
</bodyText>
<listItem confidence="0.996685444444445">
• Apertium:2 a free/open-source platform for the
development of rule-based MT systems (For-
cada et al., 2011). We used the English–Spanish
MT system from the project’s repository3 (revi-
sion 34706).
• Google Translate:4 an online MT system by
Google Inc.
• Microsoft Translator:5 an online MT system by
Microsoft.
</listItem>
<bodyText confidence="0.999482">
External resources were also used for the extended
features described in Section 2.2. We used the stem-
mer6 and the stopwords list provided by the SnowBall
project for Spanish7 and English.8
Classifier. We used the implementation of support
vector machine included in the WEKA v.3.6.6 data
mining software package (Hall et al., 2009) for multi-
class classification, and a polynomial kernel.
</bodyText>
<sectionHeader confidence="0.999725" genericHeader="evaluation">
4 Results and discussion
</sectionHeader>
<bodyText confidence="0.9999556">
We tried the different features proposed in Section 2
in isolation, and also different combinations of them.
Table 1 reports the accuracy for the different fea-
tures described in Section 2 on the test set using
sub-segments with lengths up to L = 6.9
</bodyText>
<footnote confidence="0.999931111111111">
1http://bit.ly/H4LNux
2http://www.apertium.org
3http://bit.ly/HCbnBa
4http://translate.google.com
5http://www.microsofttranslator.com
6http://bit.ly/H2HU97
7http://bit.ly/JMybmL
8http://bit.ly/Iwg9Vm
9All the results in this section are computed with L = 6,
</footnote>
<bodyText confidence="0.5190165">
which proved to be the value providing the best accuracy for the
dataset available after trying different values of L.
</bodyText>
<page confidence="0.996589">
474
</page>
<table confidence="0.998953875">
Bas U Spl U Stm U SplStm U M U R Bas U Spl U M U R
Apertium Ap.+Go.+Mi. Apertium Ap.+Go.+Mi.
P R P R P R P R
Backward 64.3% 64.8% 64.5% 72.8% 59.1% 64.8% 57.3% 60.0%
Forward 65.5% 57.6% 68.9 % 56.8% 59.8% 56.0% 58.7% 59.2%
Bidirectional 57.7% 56.8% 56.6% 55.2% 43.7% 41.6% 42.5% 40.8%
No-entailment 47.5% 53.6% 50.7% 54.4% 42.5% 43.2% 44.7% 44.0%
Accuracy 58.2% 59.8% 51.4% 51.0%
</table>
<tableCaption confidence="0.954927333333333">
Table 2: Precision (P) and recall (R) obtained by our approach for each of the four entailment classes and total accuracy
on the English–Spanish test set using different feature combinations and different MT systems: Apertium, and a
combination of Apertium, Google Translate, and Microsoft Translator (Ap.+Go.+Mi.).
</tableCaption>
<table confidence="0.999954153846154">
Feature set Nf Accuracy
Bas 14 50.0%
Spl 28 56.0%
Stm 14 49.6%
SplStm 28 56.8%
R 1 45.8%
M 12 47.0%
Bas U Spl 42 56.6%
Bas U Stm 28 51.0%
Bas U Spl U Stm U SplStm 84 57.4%
Bas U Spl U M U R 41 58.2%
Bas U Spl U Stm U 97 59.8%
U SplStm U M U R
</table>
<tableCaption confidence="0.787948666666667">
Table 1: Accuracy obtained by the system using the dif-
ferent feature sets proposed in Section 2 for the test set.
Nf is the number of features.
</tableCaption>
<bodyText confidence="0.999895323529412">
As can be seen, the features providing the best
results on accuracy are the SplStm features. In ad-
dition, results show that all versions of the basic
features (Bas, Spl, Stm, and SplStm) provide better
results than the M feature alone. Some combinations
of features are also reported in Table 1. Although
many combinations were tried, we only report the
results of the combinations of features performing
best because of lack of space.
As can be seen, both feature combinations Bas U
Spl and Bas U Stm obtain higher accuracy than the
separated features. Combining all these features
Bas U Spl U Stm U SplStm provide even better re-
sults, thus confirming some degree of orthogonality
between them. Combination Bas U Spl U M U R
obtains one of the best results, since it produces
an improvement of almost 1% over combination
Bas U Spl U Stm U SplStm but using less than a
half of features. Combining all the features provides
the best accuracy as expected, so this seems to be the
best combination for the task.
Table 2 reports the results sent for the SemEval
2012 task 8. We chose feature combinations Bas U
Spl U M U R and Bas U Spl U Stm U SplStm U M U
R since they are the best performing combinations.
We sent two runs of our method using all three MT
systems described in Section 3 and two more runs
using only sub-segment translations from Apertium.
From the ten teams presenting systems for the con-
test, only one overcomes our best result. Even the
results obtained using Apertium as the only MT sys-
tem overcome seven of the ten approaches presented.
This result confirms that state-of-the-art MT is a rich
source of information for CLTE detection.
</bodyText>
<sectionHeader confidence="0.919171" genericHeader="conclusions">
5 Concluding remarks
</sectionHeader>
<bodyText confidence="0.988653833333334">
In this paper we have described a new method for
CLTE detection which uses MT as a black-box source
of bilingual information. We experimented with dif-
ferent features which were evaluated with the datasets
for task 8 of SemEval 2012. We obtained up to 59.8%
of accuracy on the Spanish–English test set provided,
becoming the second best performing approach of
the contest. As future works, we are now preparing
experiments for other pairs of languages and we plan
to use weights to promote those translations coming
from more-reliable MT systems.
Acknowledgements: Work supported by the Span-
ish government through project TIN2009-14009-
C02-01 and by Universitat d’Alacant through project
GRE11-20. Google Translate service provided by the
University Research Program for Google Translate.
We thank M. Negri, Y. Mehdad, and M. Federico for
encouraging us to participate in SemEval 2012.
</bodyText>
<page confidence="0.998853">
475
</page>
<sectionHeader confidence="0.985726" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99821273255814">
Julio J. Castillo. 2011. A WordNet-based semantic ap-
proach to textual entailment and cross-lingual textual
entailment. International Journal of Machine Learning
and Cybernetics, 2(3):177–189.
Ido Dagan, Oren Glickman, and Bernardo Magnini. 2006.
The PASCAL recognising textual entailment chal-
lenge. In Machine Learning Challenges. Evaluating
Predictive Uncertainty, Visual Object Classification,
and Recognising Tectual Entailment, volume 3944 of
Lecture Notes in Computer Science, pages 177–190.
Springer Berlin / Heidelberg.
Mikel Forcada, Mireia Ginestf-Rosell, Jacob Nordfalk,
Jim O’Regan, Sergio Ortiz-Rojas, Juan P´erez-Ortiz,
Felipe S´anchez-Martfnez, Gema Ramfrez-S´anchez, and
Francis Tyers. 2011. Apertium: a free/open-source
platform for rule-based machine translation. Machine
Translation, 25(2):127–144.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten. 2009.
The WEKA data mining software: an update. SIGKDD
Explorations Newsletter, 11(1):10–18.
Sanda Harabagiu and Andrew Hickl. 2006. Methods
for using textual entailment in open-domain question
answering. In Proceedings of the 21st International
Conference on Computational Linguistics and the 44th
Annual Meeting of the Association for Computational
Linguistics, pages 905–912, Sydney, Australia.
Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In Proceedings of
the 2003 Conference of the North American Chapter
of the Association for Computational Linguistics on
Human Language Technology, pages 48–54, Edmonton,
Canada.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondˇrej Bojar, Alexandra Constantin,
and Evan Herbst. 2007. Moses: open source toolkit
for statistical machine translation. In Proceedings of
the 45th Annual Meeting of the ACL, pages 177–180,
Prague, Czech Republic.
Yashar Mehdad, Matteo Negri, and Marcello Federico.
2010. Towards cross-lingual textual entailment. In
Human Language Technologies: The 11th Annual Con-
ference of the North American Chapter of the Associ-
ation for Computational Linguistics, pages 321–324,
Los Angeles, USA.
Yashar Mehdad, Matteo Negri, and Marcello Federico.
2011. Using bilingual parallel corpora for cross-lingual
textual entailment. In Proceedings of the 49th Annual
Meeting of the Association for Computational Linguis-
tics: Human Language Technologies, pages 1336–1345,
Portland, Oregon.
George A. Miller. 1995. WordNet: a lexical database for
english. Communications of the ACM, 38(11):39–41.
Shachar Mirkin, Lucia Specia, Nicola Cancedda, Ido
Dagan, Marc Dymetman, and Idan Szpektor. 2009.
Source-language entailment modeling for translating
unknown terms. In Proceedings of the Joint Confer-
ence of the 47th Annual Meeting of the ACL and the 4th
International Joint Conference on Natural Language
Processing of the Asian Federation of Natural Lan-
guage Processing, pages 791–799, Suntec, Singapore.
Matteo Negri, Luisa Bentivogli, Yashar Mehdad, Danilo
Giampiccolo, and Alessandro Marchetti. 2011. Di-
vide and conquer: crowdsourcing the creation of cross-
lingual textual entailment corpora. In Proceedings of
the Conference on Empirical Methods in Natural Lan-
guage Processing, pages 670–679, Edinburgh, United
Kingdom.
Matteo Negri, Alessandro Marchetti, Yashar Mehdad,
Luisa Bentivogli, and D. Giampiccolo. 2012. Semeval-
2012 Task 8: Cross-lingual Textual Entailment for Con-
tent Synchronization. In Proceedings of the 6th Inter-
national Workshop on Semantic Evaluation (SemEval
2012).
Sebastian Pad´o, Michel Galley, Dan Jurafsky, and Chris
Manning. 2009. Robust machine translation evalua-
tion with entailment features. In Proceedings of the
Joint Conference of the 47th Annual Meeting of the
ACL and the 4th International Joint Conference on Nat-
ural Language Processing of the Asian Federation of
Natural Language Processing, pages 297–305, Suntec,
Singapore.
Sergios Theodoridis and Konstantinos Koutroumbas.
2009. Pattern Recognition. Elsevier, 4th edition.
</reference>
<page confidence="0.999107">
476
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.603064">
<title confidence="0.9550945">UAlacant: Using Online Machine Translation Cross-Lingual Textual Entailment</title>
<author confidence="0.718439">Espl`a-Gomis S´anchez-Martinez L</author>
<affiliation confidence="0.938385">Departament de Llenguatges i Sistemes Universitat d’Alacant, E-03071 Alacant,</affiliation>
<abstract confidence="0.992765714285714">This paper describes a new method for crosslingual textual entailment (CLTE) detection based on machine translation (MT). We use sub-segment translations from different MT systems available online as a source of crosslingual knowledge. In this work we describe and evaluate different features derived from these sub-segment translations, which are used by a support vector machine classifier to detect CLTEs. We presented this system to the SemEval 2012 task 8 obtaining an accuracy up to 59.8% on the English–Spanish test set, the second best performing approach in the contest.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Julio J Castillo</author>
</authors>
<title>A WordNet-based semantic approach to textual entailment and cross-lingual textual entailment.</title>
<date>2011</date>
<journal>International Journal of Machine Learning and Cybernetics,</journal>
<volume>2</volume>
<issue>3</issue>
<contexts>
<context position="2481" citStr="Castillo (2011)" startWordPosition="396" endWordPosition="397">use machine translation (MT) to translate H from LH, the language of H, into LT, the language of T, and then use any of the state-of-the-art TE approaches. In a later work (Mehdad et al., 2011), the authors use MT, but in a more elaborate way. They train a phrase-based statistical MT (PBSMT) system (Koehn et al., 2003) translating from LH to LT, and use the translation table obtained as a by-product of the training process to extract a set of features which are processed by a support vector machine classifier (Theodoridis and Koutroumbas, 2009, Sect. 3.7) to decide whether T entails H or not. Castillo (2011) discusses another machine learning approach in which the features are obtained from semantic similarity measures based on WordNet (Miller, 1995). In this work we present a new approach to tackle the problem of CLTE detection using a machine learning approach, partly inspired by that of Mehdad et al. (2011). Our method uses MT as a source of information to detect semantic relationships between T and H. To do so, we firstly split both T and H into all the possible sub-segments with lengths between 1 and L, the maximum length, measured in words. We then translate the set of sub-segments from T i</context>
</contexts>
<marker>Castillo, 2011</marker>
<rawString>Julio J. Castillo. 2011. A WordNet-based semantic approach to textual entailment and cross-lingual textual entailment. International Journal of Machine Learning and Cybernetics, 2(3):177–189.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Oren Glickman</author>
<author>Bernardo Magnini</author>
</authors>
<title>The PASCAL recognising textual entailment challenge. In Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification, and Recognising Tectual Entailment,</title>
<date>2006</date>
<booktitle>of Lecture Notes in Computer Science,</booktitle>
<volume>3944</volume>
<pages>177--190</pages>
<publisher>Springer</publisher>
<location>Berlin / Heidelberg.</location>
<contexts>
<context position="1033" citStr="Dagan et al., 2006" startWordPosition="144" endWordPosition="147">use sub-segment translations from different MT systems available online as a source of crosslingual knowledge. In this work we describe and evaluate different features derived from these sub-segment translations, which are used by a support vector machine classifier to detect CLTEs. We presented this system to the SemEval 2012 task 8 obtaining an accuracy up to 59.8% on the English–Spanish test set, the second best performing approach in the contest. 1 Introduction Cross-lingual textual entailment (CLTE) detection (Mehdad et al., 2010) is an extension of the textual entailment (TE) detection (Dagan et al., 2006) problem. TE detection consists of finding out, for two text fragments T and H in the same language, whether T entails H from a semantic point of view or not. CLTE presents a similar problem, but with T and H written in different languages. During the last years, many authors have focused on resolving TE detection, as solutions to this problem have proved to be useful in many natural language processing tasks, such as question answering (Harabagiu and Hickl, 2006) or machine translation (MT) (Mirkin et al., 2009; Pad´o et al., 2009). Therefore, CLTE may also be useful for related tasks in whic</context>
</contexts>
<marker>Dagan, Glickman, Magnini, 2006</marker>
<rawString>Ido Dagan, Oren Glickman, and Bernardo Magnini. 2006. The PASCAL recognising textual entailment challenge. In Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification, and Recognising Tectual Entailment, volume 3944 of Lecture Notes in Computer Science, pages 177–190. Springer Berlin / Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mikel Forcada</author>
<author>Mireia Ginestf-Rosell</author>
<author>Jacob Nordfalk</author>
<author>Jim O’Regan</author>
<author>Sergio Ortiz-Rojas</author>
<author>Juan P´erez-Ortiz</author>
</authors>
<title>Felipe S´anchez-Martfnez, Gema Ramfrez-S´anchez, and Francis Tyers.</title>
<date>2011</date>
<journal>Machine Translation,</journal>
<volume>25</volume>
<issue>2</issue>
<marker>Forcada, Ginestf-Rosell, Nordfalk, O’Regan, Ortiz-Rojas, P´erez-Ortiz, 2011</marker>
<rawString>Mikel Forcada, Mireia Ginestf-Rosell, Jacob Nordfalk, Jim O’Regan, Sergio Ortiz-Rojas, Juan P´erez-Ortiz, Felipe S´anchez-Martfnez, Gema Ramfrez-S´anchez, and Francis Tyers. 2011. Apertium: a free/open-source platform for rule-based machine translation. Machine Translation, 25(2):127–144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hall</author>
<author>Eibe Frank</author>
<author>Geoffrey Holmes</author>
<author>Bernhard Pfahringer</author>
<author>Peter Reutemann</author>
<author>Ian H Witten</author>
</authors>
<title>The WEKA data mining software: an update.</title>
<date>2009</date>
<journal>SIGKDD Explorations Newsletter,</journal>
<volume>11</volume>
<issue>1</issue>
<contexts>
<context position="11022" citStr="Hall et al., 2009" startWordPosition="1901" endWordPosition="1904">ource platform for the development of rule-based MT systems (Forcada et al., 2011). We used the English–Spanish MT system from the project’s repository3 (revision 34706). • Google Translate:4 an online MT system by Google Inc. • Microsoft Translator:5 an online MT system by Microsoft. External resources were also used for the extended features described in Section 2.2. We used the stemmer6 and the stopwords list provided by the SnowBall project for Spanish7 and English.8 Classifier. We used the implementation of support vector machine included in the WEKA v.3.6.6 data mining software package (Hall et al., 2009) for multiclass classification, and a polynomial kernel. 4 Results and discussion We tried the different features proposed in Section 2 in isolation, and also different combinations of them. Table 1 reports the accuracy for the different features described in Section 2 on the test set using sub-segments with lengths up to L = 6.9 1http://bit.ly/H4LNux 2http://www.apertium.org 3http://bit.ly/HCbnBa 4http://translate.google.com 5http://www.microsofttranslator.com 6http://bit.ly/H2HU97 7http://bit.ly/JMybmL 8http://bit.ly/Iwg9Vm 9All the results in this section are computed with L = 6, which prov</context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H. Witten. 2009. The WEKA data mining software: an update. SIGKDD Explorations Newsletter, 11(1):10–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanda Harabagiu</author>
<author>Andrew Hickl</author>
</authors>
<title>Methods for using textual entailment in open-domain question answering.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>905--912</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="1501" citStr="Harabagiu and Hickl, 2006" startWordPosition="227" endWordPosition="230">oduction Cross-lingual textual entailment (CLTE) detection (Mehdad et al., 2010) is an extension of the textual entailment (TE) detection (Dagan et al., 2006) problem. TE detection consists of finding out, for two text fragments T and H in the same language, whether T entails H from a semantic point of view or not. CLTE presents a similar problem, but with T and H written in different languages. During the last years, many authors have focused on resolving TE detection, as solutions to this problem have proved to be useful in many natural language processing tasks, such as question answering (Harabagiu and Hickl, 2006) or machine translation (MT) (Mirkin et al., 2009; Pad´o et al., 2009). Therefore, CLTE may also be useful for related tasks in which more than one language is involved, such as cross-lingual question answering or cross-lingual information retrieval. Although CLTE detection is a relatively new problem, it has already been tackled. Mehdad et al. (2010) propose to use machine translation (MT) to translate H from LH, the language of H, into LT, the language of T, and then use any of the state-of-the-art TE approaches. In a later work (Mehdad et al., 2011), the authors use MT, but in a more elabor</context>
</contexts>
<marker>Harabagiu, Hickl, 2006</marker>
<rawString>Sanda Harabagiu and Andrew Hickl. 2006. Methods for using textual entailment in open-domain question answering. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics, pages 905–912, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz J Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology,</booktitle>
<pages>48--54</pages>
<location>Edmonton, Canada.</location>
<contexts>
<context position="2186" citStr="Koehn et al., 2003" startWordPosition="345" endWordPosition="348">009). Therefore, CLTE may also be useful for related tasks in which more than one language is involved, such as cross-lingual question answering or cross-lingual information retrieval. Although CLTE detection is a relatively new problem, it has already been tackled. Mehdad et al. (2010) propose to use machine translation (MT) to translate H from LH, the language of H, into LT, the language of T, and then use any of the state-of-the-art TE approaches. In a later work (Mehdad et al., 2011), the authors use MT, but in a more elaborate way. They train a phrase-based statistical MT (PBSMT) system (Koehn et al., 2003) translating from LH to LT, and use the translation table obtained as a by-product of the training process to extract a set of features which are processed by a support vector machine classifier (Theodoridis and Koutroumbas, 2009, Sect. 3.7) to decide whether T entails H or not. Castillo (2011) discusses another machine learning approach in which the features are obtained from semantic similarity measures based on WordNet (Miller, 1995). In this work we present a new approach to tackle the problem of CLTE detection using a machine learning approach, partly inspired by that of Mehdad et al. (20</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology, pages 48–54, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the ACL,</booktitle>
<pages>177--180</pages>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra</location>
<contexts>
<context position="10137" citStr="Koehn et al., 2007" startWordPosition="1762" endWordPosition="1765">by the organization of SemEval 2012 (Negri et al., 2011): a training set and a test set, both composed by a set of 500 pairs of sentences. CLTE detection is evaluated in both directions, so instances belong to one of these four classes: forward (the sentence in Spanish entails the one in English); backward (the sentence in English entails the one in Spanish); bidirectional (both sentences entail each other); and no entailment (neither of the sentences entails each other). For the whole data set, both sentences in each instance were tokenized using the scripts1 included in the Moses MT system (Koehn et al., 2007). Each sentence was segmented to get all possible sub-segments which were then translated into the other language. External resources. We used three different MT systems to translate the sub-segments from English to Spanish, and vice versa: • Apertium:2 a free/open-source platform for the development of rule-based MT systems (Forcada et al., 2011). We used the English–Spanish MT system from the project’s repository3 (revision 34706). • Google Translate:4 an online MT system by Google Inc. • Microsoft Translator:5 an online MT system by Microsoft. External resources were also used for the exten</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the ACL, pages 177–180, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yashar Mehdad</author>
<author>Matteo Negri</author>
<author>Marcello Federico</author>
</authors>
<title>Towards cross-lingual textual entailment.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>321--324</pages>
<location>Los Angeles, USA.</location>
<contexts>
<context position="955" citStr="Mehdad et al., 2010" startWordPosition="131" endWordPosition="134">gual textual entailment (CLTE) detection based on machine translation (MT). We use sub-segment translations from different MT systems available online as a source of crosslingual knowledge. In this work we describe and evaluate different features derived from these sub-segment translations, which are used by a support vector machine classifier to detect CLTEs. We presented this system to the SemEval 2012 task 8 obtaining an accuracy up to 59.8% on the English–Spanish test set, the second best performing approach in the contest. 1 Introduction Cross-lingual textual entailment (CLTE) detection (Mehdad et al., 2010) is an extension of the textual entailment (TE) detection (Dagan et al., 2006) problem. TE detection consists of finding out, for two text fragments T and H in the same language, whether T entails H from a semantic point of view or not. CLTE presents a similar problem, but with T and H written in different languages. During the last years, many authors have focused on resolving TE detection, as solutions to this problem have proved to be useful in many natural language processing tasks, such as question answering (Harabagiu and Hickl, 2006) or machine translation (MT) (Mirkin et al., 2009; Pad</context>
<context position="3922" citStr="Mehdad et al. (2010)" startWordPosition="642" endWordPosition="645">n them, which can be used to determine whether T entails H or not. Note that MT is used as a black box, i.e. sub-segment translations may be collected from any MT system, and that our approach could even use any other sources of bilingual sub-sentential information. It is even possible to combine different MT systems as we do in our experiments. This is a key point of our work, since 472 First Joint Conference on Lexical and Computational Semantics (*SEM), pages 472–476, Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics it uses MT in a more elaborate way than Mehdad et al. (2010), and it does not depend on a specific MT approach. Another important difference between this work and that of Mehdad et al. (2011) is the set of features used for classification. The paper is organized as follows: Section 2 describes the method used to collect the MT information and obtain the features; Section 3 explains the experimental framework; Section 4 shows the results obtained for the different features combination proposed; the paper ends with concluding remarks. 2 Features from machine translation Our approach uses MT as a black box to detect parallelisms between the text fragments</context>
</contexts>
<marker>Mehdad, Negri, Federico, 2010</marker>
<rawString>Yashar Mehdad, Matteo Negri, and Marcello Federico. 2010. Towards cross-lingual textual entailment. In Human Language Technologies: The 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 321–324, Los Angeles, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yashar Mehdad</author>
<author>Matteo Negri</author>
<author>Marcello Federico</author>
</authors>
<title>Using bilingual parallel corpora for cross-lingual textual entailment.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>1336--1345</pages>
<location>Portland, Oregon.</location>
<contexts>
<context position="2059" citStr="Mehdad et al., 2011" startWordPosition="323" endWordPosition="326"> tasks, such as question answering (Harabagiu and Hickl, 2006) or machine translation (MT) (Mirkin et al., 2009; Pad´o et al., 2009). Therefore, CLTE may also be useful for related tasks in which more than one language is involved, such as cross-lingual question answering or cross-lingual information retrieval. Although CLTE detection is a relatively new problem, it has already been tackled. Mehdad et al. (2010) propose to use machine translation (MT) to translate H from LH, the language of H, into LT, the language of T, and then use any of the state-of-the-art TE approaches. In a later work (Mehdad et al., 2011), the authors use MT, but in a more elaborate way. They train a phrase-based statistical MT (PBSMT) system (Koehn et al., 2003) translating from LH to LT, and use the translation table obtained as a by-product of the training process to extract a set of features which are processed by a support vector machine classifier (Theodoridis and Koutroumbas, 2009, Sect. 3.7) to decide whether T entails H or not. Castillo (2011) discusses another machine learning approach in which the features are obtained from semantic similarity measures based on WordNet (Miller, 1995). In this work we present a new a</context>
<context position="4053" citStr="Mehdad et al. (2011)" startWordPosition="665" endWordPosition="668">ns may be collected from any MT system, and that our approach could even use any other sources of bilingual sub-sentential information. It is even possible to combine different MT systems as we do in our experiments. This is a key point of our work, since 472 First Joint Conference on Lexical and Computational Semantics (*SEM), pages 472–476, Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics it uses MT in a more elaborate way than Mehdad et al. (2010), and it does not depend on a specific MT approach. Another important difference between this work and that of Mehdad et al. (2011) is the set of features used for classification. The paper is organized as follows: Section 2 describes the method used to collect the MT information and obtain the features; Section 3 explains the experimental framework; Section 4 shows the results obtained for the different features combination proposed; the paper ends with concluding remarks. 2 Features from machine translation Our approach uses MT as a black box to detect parallelisms between the text fragments T and H by following these steps: 1. T is segmented in all possible sub-segments t�+p−1 of length p with 1 ≤ p ≤ L and 1 ≤ � M ≤ |</context>
<context position="8813" citStr="Mehdad et al. (2011)" startWordPosition="1526" endWordPosition="1529"> set of features Stm, and to Spl, obtaining the set of features SplStm. Although lemmatization could have been used, stemming was preferred because it does not require the part-of-speech ambiguity to be solved, which may be difficult to solve when dealing with very short sub-segments. 2.3 Additional features Two additional features were defined unrelated with the basic features proposed. The first one, called here R, is the length ratio |T|/|H|. Intuitively we can guess that if H is much longer than T it is unlikely that T entails H. The second additional set of features is the one defined by Mehdad et al. (2011), so we will refer to it as M. The corresponding feature function computes, for the total number of sub-segments of a given length l E [1, L] obtained from a text fragment S, the fraction of them which appear in a sub-segment link. It is applied both to H and T and is defined as: Fl0 (S) = Linkedl(S)/(|S |− l + 1) where Linkedl is the number of sub-segments from S with length l which appear in a sub-segment link. 3 Experimental settings The experiments designed for this task are aimed at evaluating the features proposed in Section 2. We evaluate our CLTE approach using the English– Spanish dat</context>
</contexts>
<marker>Mehdad, Negri, Federico, 2011</marker>
<rawString>Yashar Mehdad, Matteo Negri, and Marcello Federico. 2011. Using bilingual parallel corpora for cross-lingual textual entailment. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 1336–1345, Portland, Oregon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>WordNet: a lexical database for english.</title>
<date>1995</date>
<journal>Communications of the ACM,</journal>
<volume>38</volume>
<issue>11</issue>
<contexts>
<context position="2626" citStr="Miller, 1995" startWordPosition="416" endWordPosition="417">roaches. In a later work (Mehdad et al., 2011), the authors use MT, but in a more elaborate way. They train a phrase-based statistical MT (PBSMT) system (Koehn et al., 2003) translating from LH to LT, and use the translation table obtained as a by-product of the training process to extract a set of features which are processed by a support vector machine classifier (Theodoridis and Koutroumbas, 2009, Sect. 3.7) to decide whether T entails H or not. Castillo (2011) discusses another machine learning approach in which the features are obtained from semantic similarity measures based on WordNet (Miller, 1995). In this work we present a new approach to tackle the problem of CLTE detection using a machine learning approach, partly inspired by that of Mehdad et al. (2011). Our method uses MT as a source of information to detect semantic relationships between T and H. To do so, we firstly split both T and H into all the possible sub-segments with lengths between 1 and L, the maximum length, measured in words. We then translate the set of sub-segments from T into LH, and vice versa, and collect all the sub-segment pairs in a single set. We claim that when T-side sub-segments match T and their correspon</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>George A. Miller. 1995. WordNet: a lexical database for english. Communications of the ACM, 38(11):39–41.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Shachar Mirkin</author>
<author>Lucia Specia</author>
<author>Nicola Cancedda</author>
<author>Ido Dagan</author>
<author>Marc Dymetman</author>
<author>Idan Szpektor</author>
</authors>
<title>Source-language entailment modeling for translating unknown terms.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing,</booktitle>
<pages>791--799</pages>
<location>Suntec, Singapore.</location>
<contexts>
<context position="1550" citStr="Mirkin et al., 2009" startWordPosition="236" endWordPosition="239">on (Mehdad et al., 2010) is an extension of the textual entailment (TE) detection (Dagan et al., 2006) problem. TE detection consists of finding out, for two text fragments T and H in the same language, whether T entails H from a semantic point of view or not. CLTE presents a similar problem, but with T and H written in different languages. During the last years, many authors have focused on resolving TE detection, as solutions to this problem have proved to be useful in many natural language processing tasks, such as question answering (Harabagiu and Hickl, 2006) or machine translation (MT) (Mirkin et al., 2009; Pad´o et al., 2009). Therefore, CLTE may also be useful for related tasks in which more than one language is involved, such as cross-lingual question answering or cross-lingual information retrieval. Although CLTE detection is a relatively new problem, it has already been tackled. Mehdad et al. (2010) propose to use machine translation (MT) to translate H from LH, the language of H, into LT, the language of T, and then use any of the state-of-the-art TE approaches. In a later work (Mehdad et al., 2011), the authors use MT, but in a more elaborate way. They train a phrase-based statistical MT</context>
</contexts>
<marker>Mirkin, Specia, Cancedda, Dagan, Dymetman, Szpektor, 2009</marker>
<rawString>Shachar Mirkin, Lucia Specia, Nicola Cancedda, Ido Dagan, Marc Dymetman, and Idan Szpektor. 2009. Source-language entailment modeling for translating unknown terms. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, pages 791–799, Suntec, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matteo Negri</author>
<author>Luisa Bentivogli</author>
<author>Yashar Mehdad</author>
<author>Danilo Giampiccolo</author>
<author>Alessandro Marchetti</author>
</authors>
<title>Divide and conquer: crowdsourcing the creation of crosslingual textual entailment corpora.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>670--679</pages>
<location>Edinburgh, United Kingdom.</location>
<contexts>
<context position="9574" citStr="Negri et al., 2011" startWordPosition="1666" endWordPosition="1669">obtained from a text fragment S, the fraction of them which appear in a sub-segment link. It is applied both to H and T and is defined as: Fl0 (S) = Linkedl(S)/(|S |− l + 1) where Linkedl is the number of sub-segments from S with length l which appear in a sub-segment link. 3 Experimental settings The experiments designed for this task are aimed at evaluating the features proposed in Section 2. We evaluate our CLTE approach using the English– Spanish data sets provided in the task 8 of SemEval 2012 (Negri et al., 2012). Datasets. Two datasets were provided by the organization of SemEval 2012 (Negri et al., 2011): a training set and a test set, both composed by a set of 500 pairs of sentences. CLTE detection is evaluated in both directions, so instances belong to one of these four classes: forward (the sentence in Spanish entails the one in English); backward (the sentence in English entails the one in Spanish); bidirectional (both sentences entail each other); and no entailment (neither of the sentences entails each other). For the whole data set, both sentences in each instance were tokenized using the scripts1 included in the Moses MT system (Koehn et al., 2007). Each sentence was segmented to get </context>
</contexts>
<marker>Negri, Bentivogli, Mehdad, Giampiccolo, Marchetti, 2011</marker>
<rawString>Matteo Negri, Luisa Bentivogli, Yashar Mehdad, Danilo Giampiccolo, and Alessandro Marchetti. 2011. Divide and conquer: crowdsourcing the creation of crosslingual textual entailment corpora. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 670–679, Edinburgh, United Kingdom.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matteo Negri</author>
<author>Alessandro Marchetti</author>
<author>Yashar Mehdad</author>
<author>Luisa Bentivogli</author>
<author>D Giampiccolo</author>
</authors>
<title>Semeval2012 Task 8: Cross-lingual Textual Entailment for Content Synchronization.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval</booktitle>
<contexts>
<context position="9479" citStr="Negri et al., 2012" startWordPosition="1650" endWordPosition="1653">g feature function computes, for the total number of sub-segments of a given length l E [1, L] obtained from a text fragment S, the fraction of them which appear in a sub-segment link. It is applied both to H and T and is defined as: Fl0 (S) = Linkedl(S)/(|S |− l + 1) where Linkedl is the number of sub-segments from S with length l which appear in a sub-segment link. 3 Experimental settings The experiments designed for this task are aimed at evaluating the features proposed in Section 2. We evaluate our CLTE approach using the English– Spanish data sets provided in the task 8 of SemEval 2012 (Negri et al., 2012). Datasets. Two datasets were provided by the organization of SemEval 2012 (Negri et al., 2011): a training set and a test set, both composed by a set of 500 pairs of sentences. CLTE detection is evaluated in both directions, so instances belong to one of these four classes: forward (the sentence in Spanish entails the one in English); backward (the sentence in English entails the one in Spanish); bidirectional (both sentences entail each other); and no entailment (neither of the sentences entails each other). For the whole data set, both sentences in each instance were tokenized using the scr</context>
</contexts>
<marker>Negri, Marchetti, Mehdad, Bentivogli, Giampiccolo, 2012</marker>
<rawString>Matteo Negri, Alessandro Marchetti, Yashar Mehdad, Luisa Bentivogli, and D. Giampiccolo. 2012. Semeval2012 Task 8: Cross-lingual Textual Entailment for Content Synchronization. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Pad´o</author>
<author>Michel Galley</author>
<author>Dan Jurafsky</author>
<author>Chris Manning</author>
</authors>
<title>Robust machine translation evaluation with entailment features.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing,</booktitle>
<pages>297--305</pages>
<location>Suntec, Singapore.</location>
<marker>Pad´o, Galley, Jurafsky, Manning, 2009</marker>
<rawString>Sebastian Pad´o, Michel Galley, Dan Jurafsky, and Chris Manning. 2009. Robust machine translation evaluation with entailment features. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, pages 297–305, Suntec, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergios Theodoridis</author>
<author>Konstantinos Koutroumbas</author>
</authors>
<date>2009</date>
<booktitle>Pattern Recognition. Elsevier, 4th edition.</booktitle>
<contexts>
<context position="2415" citStr="Theodoridis and Koutroumbas, 2009" startWordPosition="382" endWordPosition="385">elatively new problem, it has already been tackled. Mehdad et al. (2010) propose to use machine translation (MT) to translate H from LH, the language of H, into LT, the language of T, and then use any of the state-of-the-art TE approaches. In a later work (Mehdad et al., 2011), the authors use MT, but in a more elaborate way. They train a phrase-based statistical MT (PBSMT) system (Koehn et al., 2003) translating from LH to LT, and use the translation table obtained as a by-product of the training process to extract a set of features which are processed by a support vector machine classifier (Theodoridis and Koutroumbas, 2009, Sect. 3.7) to decide whether T entails H or not. Castillo (2011) discusses another machine learning approach in which the features are obtained from semantic similarity measures based on WordNet (Miller, 1995). In this work we present a new approach to tackle the problem of CLTE detection using a machine learning approach, partly inspired by that of Mehdad et al. (2011). Our method uses MT as a source of information to detect semantic relationships between T and H. To do so, we firstly split both T and H into all the possible sub-segments with lengths between 1 and L, the maximum length, mea</context>
</contexts>
<marker>Theodoridis, Koutroumbas, 2009</marker>
<rawString>Sergios Theodoridis and Konstantinos Koutroumbas. 2009. Pattern Recognition. Elsevier, 4th edition.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>