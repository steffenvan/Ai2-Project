<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005653">
<title confidence="0.999369">
A Feature Based Approach to Leveraging Context for Classifying
Newsgroup Style Discussion Segments
</title>
<author confidence="0.8331">
Yi-Chia Wang, Mahesh Joshi
</author>
<affiliation confidence="0.714484">
Language Technologies Institute
Carnegie Mellon University
</affiliation>
<address confidence="0.601551">
Pittsburgh, PA 15213
</address>
<email confidence="0.996652">
{yichiaw,maheshj}@cs.cmu.edu
</email>
<title confidence="0.7647676">
Carolyn Penstein Rosé
Language Technologies Institute/
Human-Computer Interaction Institute
Carnegie Mellon University
Pittsburgh, PA 15213
</title>
<email confidence="0.997798">
cprose@cs.cmu.edu
</email>
<sectionHeader confidence="0.998601" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998958090909091">
On a multi-dimensional text categorization
task, we compare the effectiveness of a fea-
ture based approach with the use of a state-
of-the-art sequential learning technique that
has proven successful for tasks such as
“email act classification”. Our evaluation
demonstrates for the three separate dimen-
sions of a well established annotation
scheme that novel thread based features
have a greater and more consistent impact
on classification performance.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99997895">
The problem of information overload in personal
communication media such as email, instant mes-
saging, and on-line discussion boards is a well
documented phenomenon (Bellotti, 2005). Be-
cause of this, conversation summarization is an
area with a great potential impact (Zechner, 2001).
What is strikingly different about this form of
summarization from summarization of expository
text is that the summary may include more than
just the content, such as the style and structure of
the conversation (Roman et al., 2006). In this pa-
per we focus on a classification task that will even-
tually be used to enable this form of conversation
summarization by providing indicators of the qual-
ity of group functioning and argumentation.
Lacson and colleagues (2006) describe a form of
conversation summarization where a classification
approach is first applied to segments of a conversa-
tion in order to identify regions of the conversation
related to different types of information. This aids
</bodyText>
<page confidence="0.981965">
73
</page>
<bodyText confidence="0.990586489795919">
in structuring a useful summary. In this paper, we
describe work in progress towards a different form
of conversation summarization that similarly lev-
erages a text classification approach. We focus on
newsgroup style interactions. The goal of assess-
ing the quality of interactions in that context is to
enable the quality and nature of discussions that
occur within an on-line discussion board to be
communicated in a summary to a potential new-
comer or group moderators.
We propose to adopt an approach developed in
the computer supported collaborative learning
(CSCL) community for measuring the quality of
interactions in a threaded, online discussion forum
using a multi-dimensional annotation scheme
(Weinberger &amp; Fischer, 2006). Using this annota-
tion scheme, messages are segmented into idea
units and then coded with several independent di-
mensions, three of which are relevant for our work,
namely micro-argumentation, macro-
argumentation, and social modes of co-
construction, which categorizes spans of text as
belonging to one of five consensus building cate-
gories. By coding segments with this annotation
scheme, it is possible to measure the extent to
which group members’ arguments are well formed
or the extent to which they are engaging in func-
tional or dysfunctional consensus building behav-
ior.
This work can be seen as analogous to work on
“email act classification” (Carvalho &amp; Cohen,
2005). However, while in some ways the structure
of newsgroup style interaction is more straightfor-
ward than email based interaction because of the
unambiguous thread structure (Carvalho &amp; Cohen,
2005), what makes this particularly challenging
Proceedings of the ACL 2007 Demo and Poster Sessions, pages 73–76,
Prague, June 2007. c�2007 Association for Computational Linguistics
from a technical standpoint is that the structure of
this type of conversation is multi-leveled, as we
describe in greater depth below.
We investigate the use of state-of-the-art se-
quential learning techniques that have proven suc-
cessful for email act classification in comparison
with a feature based approach. Our evaluation
demonstrates for the three separate dimensions of a
context oriented annotation scheme that novel
thread based features have a greater and more con-
sistent impact on classification performance.
</bodyText>
<sectionHeader confidence="0.784269" genericHeader="introduction">
2 Data and Coding
</sectionHeader>
<bodyText confidence="0.999991952380953">
We make use of an available annotated corpus of
discussion data where groups of three students dis-
cuss case studies in an on-line, newsgroup style
discussion environment (Weinberger &amp; Fischer,
2006). This corpus is structurally more complex
than the data sets used previously to demonstrate
the advantages of using sequential learning tech-
niques for identifying email acts (Carvalho &amp;
Cohen, 2005). In the email act corpus, each mes-
sage as a whole is assigned one or more codes.
Thus, the history of a span of text is defined in
terms of the thread structure of an email conversa-
tion. However, in the Weinberger and Fischer cor-
pus, each message is segmented into idea units.
Thus, a span of text has a context within a message,
defined by the sequence of text spans within that
message, as well as a context from the larger
thread structure.
The Weinberger and Fischer annotation scheme
has seven dimensions, three of which are relevant
for our work.
</bodyText>
<listItem confidence="0.696174">
1. Micro-level of argumentation [4 categories]
How an individual argument consists of a
claim which can be supported by a ground
with warrant and/or specified by a qualifier
2. Macro-level of argumentation [6 categories]
</listItem>
<bodyText confidence="0.8859234">
Argumentation sequences are examined in
terms of how learners connect individual ar-
guments to create a more complex argument
(for example, consisting of an argument, a
counter-argument, and integration)
</bodyText>
<listItem confidence="0.8356265">
3. Social Modes of Co-Construction [6 catego-
ries] To what degree or in what ways learn-
</listItem>
<bodyText confidence="0.96587045">
ers refer to the contributions of their learn-
ing partners, including externalizations,
elicitations, quick consensus building, inte-
gration oriented consensus building, or con-
flict oriented consensus building, or other.
For the two argumentation dimensions, the most
natural application of sequential learning tech-
niques is by defining the history of a span of text in
terms of the sequence of spans of text within a
message, since although arguments may build on
previous messages, there is also a structure to the
argument within a single message. For the Social
Modes of Co-construction dimension, it is less
clear. However, we have experimented with both
ways of defining the history and have not observed
any benefit of sequential learning techniques by
defining the history for sequential learning in terms
of previous messages. Thus, for all three dimen-
sions, we report results for histories defined within
a single message in our evaluation below.
</bodyText>
<sectionHeader confidence="0.99689" genericHeader="method">
3 Feature Based Approach
</sectionHeader>
<bodyText confidence="0.995911533333333">
In previous text classification research, more atten-
tion to the selection of predictive features has been
done for text classification problems where very
subtle distinctions must be made or where the size
of spans of text being classified is relatively small.
Both of these are true of our work. For the base
features, we began with typical text features ex-
tracted from the raw text, including unstemmed uni-
grams and punctuation. We did not remove stop
words, although we did remove features that occured
less than 5 times in the corpus. We also included a
feature that indicated the number of words in the
segment.
Thread Structure Features. The simplest context-
oriented feature we can add based on the threaded
structure is a number indicating the depth in the
thread where a message appears. We refer to this
feature as deep. This is expected to improve per-
formance to the extent that thread initial messages
may be rhetorically distinct from messages that
occur further down in the thread. The other con-
text oriented feature related to the thread structure
is derived from relationships between spans of text
appearing in the parent and child messages. This
feature is meant to indicate how semantically re-
lated a span of text is to the spans of text in the
parent message. This is computed using the mini-
mum of all cosine distance measures between the
vector representation of the span of text and that of
each of the spans of text in all parent messages,
</bodyText>
<page confidence="0.996966">
74
</page>
<bodyText confidence="0.999837833333333">
which is a typical shallow measure of semantic with a subset of this data, using altogether 1250
similarity. The smallest such distance measure is annotated text segments. Trained coders catego-
included as a feature indicating how related the rized each segment using this multi-dimensional
current span of text is to a parent message. annotation scheme, in each case achieving a level
of agreement exceeding .7 Kappa both for segmen-
Sequence-Oriented Features. We hypothesized that tation and coding of all dimensions as previously
the sequence of codes within a message follows a published (Weinberger &amp; Fischer, 2006).
semi-regular structure. In particular, the discussion For each dimension, we first evaluate alternative
environment used to collect the Weinberger and combinations of features using SMO, Weka’s im-
Fischer corpus inserts prompts into the message plementation of Support Vector Machines (Witten
buffers before messages are composed in order to &amp; Frank, 2005). For a sequential learning algo-
structure the interaction. Users fill in text under- rithm, we make use of the Collins Perceptron
neath these prompts. Sometimes they quote mate- Learner (Collins, 2002). When using the Collins
rial from a previous message before inserting their Perceptron Learner, in all cases we evaluate com-
own comments. We hypothesized that whether or binations of alternative history sizes (0 and 1) and
not a piece of quoted material appears before a alternative feature sets (base and base+AllContext).
span of text might influence which code is appro- In our experimentation we have evaluated larger
priate. Thus, we constructed the fsm feature, history sizes as well, but the performance was con-
which indicates the state of a simple finite-state sistently worse as the history size grew larger than
automaton that only has two states. The automaton 1. Thus, we only report results for history sizes of
is set to initial state (q0) at the top of a message. It 0 and 1.
makes a transition to state (q1) when it encounters a Our evaluation demonstrates that we achieve a
quoted span of text. Once in state (q1), the automa- much greater impact on performance with carefully
ton remains in this state until it encounters a designed, automatically extractable context ori-
prompt. On encountering a prompt it makes a tran- ented features. In all cases we are able to achieve a
sition back to the initial state (q0). The purpose is statistically significant improvement by adding
to indicate places where users are likely to make a context oriented features, and only achieve a statis-
comment in reference to something another par- tically significant improvement using sequential
ticipant in the conversation has already contributed. learning for one dimension, and only in the ab-
sence of context oriented features.
</bodyText>
<sectionHeader confidence="0.999734" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.999378">
4.1 Feature Based Approach
</subsectionHeader>
<bodyText confidence="0.999728894736842">
The purpose of our evaluation is to contrast our
proposed feature based approach with a state-of-
the-art sequential learning technique (Collins,
2002). Both approaches are designed to leverage
context for the purpose of increasing classification
accuracy on a classification task where the codes
refer to the role a span of text plays in context.
We evaluate these two approaches alone and in
combination over the same data but with three dif-
ferent sets of codes, namely the three relevant di-
mensions of the Weinberger and Fischer annota-
tion scheme. In all cases, we employ a 10-fold
cross-validation methodology, where we apply a
feature selection wrapper in such as way as to se-
lect the 100 best features over the training set on
each fold, and then to apply this feature space and
the trained model to the test set. The complete
corpus comprises about 250 discussions of the par-
ticipants. From this we have run our experiments
</bodyText>
<figureCaption confidence="0.9669375">
Figure 1. Results with alternative features
sets
</figureCaption>
<figure confidence="0.997231833333333">
Kappa from 10-fold CV
0.75
0.70
0.65
0.60
0.55
0.50
0.45
0.40
0.52
0.67
0.66
0.69
0.71
0.73
0.70
0.73
0.61
0.62
0.61
0.61
Social Macro Micro
Dimension
Base Base+Thread Base+Seq Base+AllContext
</figure>
<page confidence="0.996053">
75
</page>
<bodyText confidence="0.999921916666667">
We first evaluated the feature based approach
across all three dimensions and demonstrate that
statistically significant improvements are achieved
on all dimensions by adding context oriented fea-
tures. The most dramatic results are achieved on
the Social Modes of Co-Construction dimension
(See Figure 1). All pairwise contrasts between al-
ternative feature sets within this dimension are sta-
tistically significant. In the other dimensions,
while Base+Thread is a significant improvement
over Base, there is no significant difference be-
tween Base+Thread and Base+AllContext.
</bodyText>
<subsectionHeader confidence="0.968715">
4.2 Sequential Learning
</subsectionHeader>
<figureCaption confidence="0.993384">
Figure 2. Results with Sequential Learning
</figureCaption>
<bodyText confidence="0.999954227272727">
The results for sequential learning are weaker than
for the feature based (See Figure 2). While the
Collins Perceptron learner possesses the capability
of modeling sequential dependencies between
codes, which SMO does not possess, it is not nec-
essarily a more powerful learner. On this data set,
the Collins Perceptron learner consistently per-
forms worse that SMO. Even restricting our
evaluation of sequential learning to a comparison
between the Collins Perceptron learner with a his-
tory of 0 (i.e., no history) with the same learner
using a history of 1, we only see a statistically sig-
nificant improvement on the Social Modes of Co-
Construction dimension. This is when only using
base features, although the trend was consistently
in favor of a history of 1 over 0. Note that the stan-
dard deviation in the performance across folds was
much higher with the Collins Perceptron learner,
so that a much greater difference in average would
be required in order to achieve statistical signifi-
cance. Performance over a validation set was al-
ways worse with larger history sizes than 1.
</bodyText>
<sectionHeader confidence="0.999192" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.934066333333333">
We have described work towards an approach to
conversation summarization where an assessment
of conversational quality along multiple process
dimensions is reported. We make use of a well-
established annotation scheme developed in the
CSCL community. Our evaluation demonstrates
that thread based features have a greater and more
consistent impact on performance with this data.
This work was supported by the National Sci-
ence Foundation grant number SBE0354420, and
Office of Naval Research, Cognitive and Neural Sci-
ences Division Grant N00014-05-1-0043.
</bodyText>
<sectionHeader confidence="0.99623" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999453866666667">
Bellotti, V., Ducheneaut, N., Howard, M. Smith, I.,
Grinter, R. (2005). Quality versus Quantity: Email-
centric task management and its relation with over-
load. Human-Computer Interaction, 2005, vol. 20
Carvalho, V. &amp; Cohen, W. (2005). On the Collective
Classification of Email “Speech Acts”, Proceedings
of SIGIR ‘2005.
Collins, M (2002). Discriminative Training Methods for
Hidden Markov Models: Theory and Experiments
with Perceptron Algorithms. In Proceedings of
EMNLP 2002.
Lacson, R., Barzilay, R., &amp; Long, W. (2006). Automatic
analysis of medical dialogue in the homehemodialy-
sis domain: structure induction and summarization,
Journal of Biomedical Informatics 39(5), pp541-555.
Roman, N., Piwek, P., &amp; Carvalho, A. (2006). Polite-
ness and Bias in Dialogue Summarization : Two Ex-
ploratory Studies, in J. Shanahan, Y. Qu, &amp; J. Wiebe
(Eds.) Computing Attitude and Affect in Text: Theory
and Applications, the Information Retrieval Series.
Weinberger, A., &amp; Fischer, F. (2006). A framework to
analyze argumentative knowledge construction in
computer-supported collaborative learning. Com-
puters &amp; Education, 46, 71-95.
Witten, I. H. &amp; Frank, E. (2005). Data Mining: Practi-
cal Machine Learning Tools and Techniques, sec-
ond edition, Elsevier: San Francisco.
Zechner, K. (2001). Automatic Generation of Concise
Summaries of Spoken Dialogues in Unrestricted
Domains. Proceedings of ACM SIG-IR 2001.
</reference>
<figure confidence="0.993667882352941">
Social Macro Micro
Dimension
Base / 0 Base / 1 Base+AllContext / 0 Base+AllContext / 1
0.65
0.61 0.63 0.64 0.63
0.59
0.56 0.56 0.56
0.52 0.54
0.43
Kappa from 10-fold CV 0.75
0.70
0.65
0.60
0.55
0.50
0.45
0.40
</figure>
<page confidence="0.675441">
76
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.917460">
<title confidence="0.997479">A Feature Based Approach to Leveraging Context for Classifying Newsgroup Style Discussion Segments</title>
<author confidence="0.999743">Yi-Chia Wang</author>
<author confidence="0.999743">Mahesh Joshi</author>
<affiliation confidence="0.999108">Language Technologies Institute Carnegie Mellon University</affiliation>
<address confidence="0.999809">Pittsburgh, PA 15213</address>
<email confidence="0.996685">yichiaw@cs.cmu.edu</email>
<email confidence="0.996685">maheshj@cs.cmu.edu</email>
<author confidence="0.943586">Carolyn Penstein Rosé</author>
<affiliation confidence="0.998759">Language Technologies Institute/ Human-Computer Interaction Institute Carnegie Mellon University</affiliation>
<address confidence="0.999816">Pittsburgh, PA 15213</address>
<email confidence="0.997255">cprose@cs.cmu.edu</email>
<abstract confidence="0.99905725">On a multi-dimensional text categorization task, we compare the effectiveness of a feature based approach with the use of a stateof-the-art sequential learning technique that has proven successful for tasks such as “email act classification”. Our evaluation demonstrates for the three separate dimensions of a well established annotation scheme that novel thread based features have a greater and more consistent impact on classification performance.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>V Bellotti</author>
<author>N Ducheneaut</author>
<author>M Smith Howard</author>
<author>I Grinter</author>
<author>R</author>
</authors>
<title>Quality versus Quantity: Emailcentric task management and its relation with overload. Human-Computer Interaction,</title>
<date>2005</date>
<volume>20</volume>
<marker>Bellotti, Ducheneaut, Howard, Grinter, R, 2005</marker>
<rawString>Bellotti, V., Ducheneaut, N., Howard, M. Smith, I., Grinter, R. (2005). Quality versus Quantity: Emailcentric task management and its relation with overload. Human-Computer Interaction, 2005, vol. 20</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Carvalho</author>
<author>W Cohen</author>
</authors>
<title>On the Collective Classification of Email “Speech Acts”,</title>
<date>2005</date>
<booktitle>Proceedings of SIGIR</booktitle>
<contexts>
<context position="3256" citStr="Carvalho &amp; Cohen, 2005" startWordPosition="484" endWordPosition="487">nted into idea units and then coded with several independent dimensions, three of which are relevant for our work, namely micro-argumentation, macroargumentation, and social modes of coconstruction, which categorizes spans of text as belonging to one of five consensus building categories. By coding segments with this annotation scheme, it is possible to measure the extent to which group members’ arguments are well formed or the extent to which they are engaging in functional or dysfunctional consensus building behavior. This work can be seen as analogous to work on “email act classification” (Carvalho &amp; Cohen, 2005). However, while in some ways the structure of newsgroup style interaction is more straightforward than email based interaction because of the unambiguous thread structure (Carvalho &amp; Cohen, 2005), what makes this particularly challenging Proceedings of the ACL 2007 Demo and Poster Sessions, pages 73–76, Prague, June 2007. c�2007 Association for Computational Linguistics from a technical standpoint is that the structure of this type of conversation is multi-leveled, as we describe in greater depth below. We investigate the use of state-of-the-art sequential learning techniques that have proven</context>
<context position="4565" citStr="Carvalho &amp; Cohen, 2005" startWordPosition="680" endWordPosition="683">Our evaluation demonstrates for the three separate dimensions of a context oriented annotation scheme that novel thread based features have a greater and more consistent impact on classification performance. 2 Data and Coding We make use of an available annotated corpus of discussion data where groups of three students discuss case studies in an on-line, newsgroup style discussion environment (Weinberger &amp; Fischer, 2006). This corpus is structurally more complex than the data sets used previously to demonstrate the advantages of using sequential learning techniques for identifying email acts (Carvalho &amp; Cohen, 2005). In the email act corpus, each message as a whole is assigned one or more codes. Thus, the history of a span of text is defined in terms of the thread structure of an email conversation. However, in the Weinberger and Fischer corpus, each message is segmented into idea units. Thus, a span of text has a context within a message, defined by the sequence of text spans within that message, as well as a context from the larger thread structure. The Weinberger and Fischer annotation scheme has seven dimensions, three of which are relevant for our work. 1. Micro-level of argumentation [4 categories]</context>
</contexts>
<marker>Carvalho, Cohen, 2005</marker>
<rawString>Carvalho, V. &amp; Cohen, W. (2005). On the Collective Classification of Email “Speech Acts”, Proceedings of SIGIR ‘2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
</authors>
<title>Discriminative Training Methods for Hidden Markov Models: Theory and Experiments with Perceptron Algorithms.</title>
<date>2002</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context position="9250" citStr="Collins, 2002" startWordPosition="1446" endWordPosition="1447">message follows a published (Weinberger &amp; Fischer, 2006). semi-regular structure. In particular, the discussion For each dimension, we first evaluate alternative environment used to collect the Weinberger and combinations of features using SMO, Weka’s imFischer corpus inserts prompts into the message plementation of Support Vector Machines (Witten buffers before messages are composed in order to &amp; Frank, 2005). For a sequential learning algostructure the interaction. Users fill in text under- rithm, we make use of the Collins Perceptron neath these prompts. Sometimes they quote mate- Learner (Collins, 2002). When using the Collins rial from a previous message before inserting their Perceptron Learner, in all cases we evaluate comown comments. We hypothesized that whether or binations of alternative history sizes (0 and 1) and not a piece of quoted material appears before a alternative feature sets (base and base+AllContext). span of text might influence which code is appro- In our experimentation we have evaluated larger priate. Thus, we constructed the fsm feature, history sizes as well, but the performance was conwhich indicates the state of a simple finite-state sistently worse as the history</context>
<context position="11071" citStr="Collins, 2002" startWordPosition="1742" endWordPosition="1743">o the initial state (q0). The purpose is statistically significant improvement by adding to indicate places where users are likely to make a context oriented features, and only achieve a statiscomment in reference to something another par- tically significant improvement using sequential ticipant in the conversation has already contributed. learning for one dimension, and only in the absence of context oriented features. 4 Evaluation 4.1 Feature Based Approach The purpose of our evaluation is to contrast our proposed feature based approach with a state-ofthe-art sequential learning technique (Collins, 2002). Both approaches are designed to leverage context for the purpose of increasing classification accuracy on a classification task where the codes refer to the role a span of text plays in context. We evaluate these two approaches alone and in combination over the same data but with three different sets of codes, namely the three relevant dimensions of the Weinberger and Fischer annotation scheme. In all cases, we employ a 10-fold cross-validation methodology, where we apply a feature selection wrapper in such as way as to select the 100 best features over the training set on each fold, and the</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Collins, M (2002). Discriminative Training Methods for Hidden Markov Models: Theory and Experiments with Perceptron Algorithms. In Proceedings of EMNLP 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Lacson</author>
<author>R Barzilay</author>
<author>W Long</author>
</authors>
<title>Automatic analysis of medical dialogue in the homehemodialysis domain: structure induction and summarization,</title>
<date>2006</date>
<journal>Journal of Biomedical Informatics</journal>
<volume>39</volume>
<issue>5</issue>
<pages>541--555</pages>
<marker>Lacson, Barzilay, Long, 2006</marker>
<rawString>Lacson, R., Barzilay, R., &amp; Long, W. (2006). Automatic analysis of medical dialogue in the homehemodialysis domain: structure induction and summarization, Journal of Biomedical Informatics 39(5), pp541-555.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Roman</author>
<author>P Piwek</author>
<author>A Carvalho</author>
</authors>
<title>Politeness and Bias in Dialogue Summarization : Two Exploratory Studies,</title>
<date>2006</date>
<note>in</note>
<contexts>
<context position="1384" citStr="Roman et al., 2006" startWordPosition="189" endWordPosition="192">based features have a greater and more consistent impact on classification performance. 1 Introduction The problem of information overload in personal communication media such as email, instant messaging, and on-line discussion boards is a well documented phenomenon (Bellotti, 2005). Because of this, conversation summarization is an area with a great potential impact (Zechner, 2001). What is strikingly different about this form of summarization from summarization of expository text is that the summary may include more than just the content, such as the style and structure of the conversation (Roman et al., 2006). In this paper we focus on a classification task that will eventually be used to enable this form of conversation summarization by providing indicators of the quality of group functioning and argumentation. Lacson and colleagues (2006) describe a form of conversation summarization where a classification approach is first applied to segments of a conversation in order to identify regions of the conversation related to different types of information. This aids 73 in structuring a useful summary. In this paper, we describe work in progress towards a different form of conversation summarization t</context>
</contexts>
<marker>Roman, Piwek, Carvalho, 2006</marker>
<rawString>Roman, N., Piwek, P., &amp; Carvalho, A. (2006). Politeness and Bias in Dialogue Summarization : Two Exploratory Studies, in J. Shanahan, Y. Qu, &amp; J. Wiebe (Eds.) Computing Attitude and Affect in Text: Theory and Applications, the Information Retrieval Series.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Weinberger</author>
<author>F Fischer</author>
</authors>
<title>A framework to analyze argumentative knowledge construction in computer-supported collaborative learning.</title>
<date>2006</date>
<journal>Computers &amp; Education,</journal>
<volume>46</volume>
<pages>71--95</pages>
<contexts>
<context position="2583" citStr="Weinberger &amp; Fischer, 2006" startWordPosition="376" endWordPosition="379">conversation summarization that similarly leverages a text classification approach. We focus on newsgroup style interactions. The goal of assessing the quality of interactions in that context is to enable the quality and nature of discussions that occur within an on-line discussion board to be communicated in a summary to a potential newcomer or group moderators. We propose to adopt an approach developed in the computer supported collaborative learning (CSCL) community for measuring the quality of interactions in a threaded, online discussion forum using a multi-dimensional annotation scheme (Weinberger &amp; Fischer, 2006). Using this annotation scheme, messages are segmented into idea units and then coded with several independent dimensions, three of which are relevant for our work, namely micro-argumentation, macroargumentation, and social modes of coconstruction, which categorizes spans of text as belonging to one of five consensus building categories. By coding segments with this annotation scheme, it is possible to measure the extent to which group members’ arguments are well formed or the extent to which they are engaging in functional or dysfunctional consensus building behavior. This work can be seen as</context>
<context position="4366" citStr="Weinberger &amp; Fischer, 2006" startWordPosition="650" endWordPosition="653">be in greater depth below. We investigate the use of state-of-the-art sequential learning techniques that have proven successful for email act classification in comparison with a feature based approach. Our evaluation demonstrates for the three separate dimensions of a context oriented annotation scheme that novel thread based features have a greater and more consistent impact on classification performance. 2 Data and Coding We make use of an available annotated corpus of discussion data where groups of three students discuss case studies in an on-line, newsgroup style discussion environment (Weinberger &amp; Fischer, 2006). This corpus is structurally more complex than the data sets used previously to demonstrate the advantages of using sequential learning techniques for identifying email acts (Carvalho &amp; Cohen, 2005). In the email act corpus, each message as a whole is assigned one or more codes. Thus, the history of a span of text is defined in terms of the thread structure of an email conversation. However, in the Weinberger and Fischer corpus, each message is segmented into idea units. Thus, a span of text has a context within a message, defined by the sequence of text spans within that message, as well as </context>
<context position="8692" citStr="Weinberger &amp; Fischer, 2006" startWordPosition="1362" endWordPosition="1365">ages, 74 which is a typical shallow measure of semantic with a subset of this data, using altogether 1250 similarity. The smallest such distance measure is annotated text segments. Trained coders categoincluded as a feature indicating how related the rized each segment using this multi-dimensional current span of text is to a parent message. annotation scheme, in each case achieving a level of agreement exceeding .7 Kappa both for segmenSequence-Oriented Features. We hypothesized that tation and coding of all dimensions as previously the sequence of codes within a message follows a published (Weinberger &amp; Fischer, 2006). semi-regular structure. In particular, the discussion For each dimension, we first evaluate alternative environment used to collect the Weinberger and combinations of features using SMO, Weka’s imFischer corpus inserts prompts into the message plementation of Support Vector Machines (Witten buffers before messages are composed in order to &amp; Frank, 2005). For a sequential learning algostructure the interaction. Users fill in text under- rithm, we make use of the Collins Perceptron neath these prompts. Sometimes they quote mate- Learner (Collins, 2002). When using the Collins rial from a previ</context>
</contexts>
<marker>Weinberger, Fischer, 2006</marker>
<rawString>Weinberger, A., &amp; Fischer, F. (2006). A framework to analyze argumentative knowledge construction in computer-supported collaborative learning. Computers &amp; Education, 46, 71-95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I H Witten</author>
<author>E Frank</author>
</authors>
<date>2005</date>
<booktitle>Data Mining: Practical Machine Learning Tools and Techniques, second edition, Elsevier:</booktitle>
<location>San Francisco.</location>
<marker>Witten, Frank, 2005</marker>
<rawString>Witten, I. H. &amp; Frank, E. (2005). Data Mining: Practical Machine Learning Tools and Techniques, second edition, Elsevier: San Francisco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Zechner</author>
</authors>
<title>Automatic Generation of Concise Summaries of Spoken Dialogues in Unrestricted Domains.</title>
<date>2001</date>
<booktitle>Proceedings of ACM SIG-IR</booktitle>
<contexts>
<context position="1150" citStr="Zechner, 2001" startWordPosition="153" endWordPosition="154">e-art sequential learning technique that has proven successful for tasks such as “email act classification”. Our evaluation demonstrates for the three separate dimensions of a well established annotation scheme that novel thread based features have a greater and more consistent impact on classification performance. 1 Introduction The problem of information overload in personal communication media such as email, instant messaging, and on-line discussion boards is a well documented phenomenon (Bellotti, 2005). Because of this, conversation summarization is an area with a great potential impact (Zechner, 2001). What is strikingly different about this form of summarization from summarization of expository text is that the summary may include more than just the content, such as the style and structure of the conversation (Roman et al., 2006). In this paper we focus on a classification task that will eventually be used to enable this form of conversation summarization by providing indicators of the quality of group functioning and argumentation. Lacson and colleagues (2006) describe a form of conversation summarization where a classification approach is first applied to segments of a conversation in o</context>
</contexts>
<marker>Zechner, 2001</marker>
<rawString>Zechner, K. (2001). Automatic Generation of Concise Summaries of Spoken Dialogues in Unrestricted Domains. Proceedings of ACM SIG-IR 2001.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>