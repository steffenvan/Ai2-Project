<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.018216">
<title confidence="0.992736">
Word Alignment with Cohesion Constraint
</title>
<author confidence="0.998012">
Dekang Lin and Colin Cherry
</author>
<affiliation confidence="0.998768">
Department of Computing Science
University of Alberta
</affiliation>
<address confidence="0.631473">
Edmonton, Alberta, Canada, T6G 2E8
</address>
<email confidence="0.997826">
{lindek,colinc}@cs.ualberta.ca
</email>
<sectionHeader confidence="0.993869" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997755">
We present a syntax-based constraint for word
alignment, known as the cohesion constraint. It
requires disjoint English phrases to be mapped
to non-overlapping intervals in the French sen-
tence. We evaluate the utility of this constraint
in two different algorithms. The results show
that it can provide a significant improvement in
alignment quality.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99468384375">
The IBM statistical machine translation (SMT) models
have been extremely influential in computational linguis-
tics in the past decade. The (arguably) most striking char-
acteristic of the IBM-style SMT models is their total lack
of linguistic knowledge. The IBM models demonstrated
how much one can do with pure statistical techniques,
which have inspired a whole new generation of NLP re-
search and systems.
More recently, there have been many proposals to
introduce syntactic knowledge into SMT models (Wu,
1997; Alshawi et al., 2000; Yamada and Knight, 2001;
Lopez et al., 2002). A common theme among these
approaches is the assumption that the syntactic struc-
tures of a pair of source-target sentences are isomor-
phic (or nearly isomorphic). This assumption seems too
strong. Human translators often use non-literal transla-
tions, which result in differences in syntactic structures.
According to a study in (Dorr et al., 2002), such transla-
tional divergences are quite common, involving 11-31%
of the sentences.
We introduce a constraint that uses the dependency tree
of the English sentence to maintain phrasal cohesion in
the French sentence. In other words, if two phrases are
disjoint in the English sentence, the alignment must not
map them to overlapping intervals in the French sentence.
For example, in Figure 1, the cohesion constraint will rule
out the possibility of aligning to with `a. The phrases the
reboot and the host to discover all the devices are dis-
joint, but the partial alignment in Figure 1 maps them to
overlapping intervals. This constraint is weaker than iso-
morphism. However, we will show that it can produce a
significant increase in alignment quality.
</bodyText>
<equation confidence="0.5954864">
The[teboot@auses[Hhe[host[to[discoverCall[Hhe[devices❑
1❑ 20 3 E 40 50 60 70 80 90 100
10 20 30 40 5[$❑ 7❑ 80 90 100 11El
Suite❑à laijiéinitialisation ,d&apos; hôte[}epère❑tousIles4�ériphériques❑
after❑ toE the❑ reboot❑ the®ost❑ locate❑ all❑ the❑ peripherals❑
</equation>
<figureCaption confidence="0.999499">
Figure 1: A cohesion constraint violation
</figureCaption>
<sectionHeader confidence="0.956247" genericHeader="method">
2 Cohesion Constraint
</sectionHeader>
<bodyText confidence="0.99980525">
Given an English sentence E = e1e2 ... el and a French
sentence F = f1f2 ... fm, an alignment is a set of links
between the words in E and F. An alignment can be
represented as a binary relation A in [1, l] × [1, m]. A
pair (i, j) is in A if ei and fj are a translation (or part
of a translation) of each other. We call such pairs links.
In Figure 2, the links in the alignment are represented by
dashed lines.
</bodyText>
<equation confidence="0.890606285714286">
compe
pre
subj�
det� subj� det� aux� detE]
The[tebootCdauses[Hhe[host[to[discoverCall[Hhe[devices❑
Suite❑à laijiéinitialisation ,d&apos; hôte[}epère❑tousIles4�ériphériques❑
after❑ toE the❑ reboot❑ the®ost❑ locate❑ all❑ the❑ peripherals❑
</equation>
<figureCaption confidence="0.994869">
Figure 2: An example pair of aligned sentence
</figureCaption>
<bodyText confidence="0.983253">
The cohesion constraint (Fox, 2002) uses the depen-
dency tree TE (Mel’ˇcuk, 1987) of the English sentence
</bodyText>
<figure confidence="0.980784">
mode
obj❑
preO.detE] subjl7 detf] ubjc detE]
aux1.
1❑ 20 3 E 40 50 60 70 80 90 100
10 20 30 40 5❑6❑7❑ 80 90 100
11El
obj11
</figure>
<bodyText confidence="0.978166">
to restrict possible link combinations. Let TE(ei) be
the subtree of TE rooted at ei. The phrase span of ei,
spanP (ei, TE, A), is the image of the English phrase
headed by ei in F given a (partial) alignment A. More
precisely, spanP (ei, TE, A) = [k1, k2], where
</bodyText>
<equation confidence="0.945479333333333">
k1 = min{j|(u, j) E A, eu E TE(ei)}
k2 = max{j|(u, j) E A, eu E TE(ei)}
The head span is the image of ei itself. We define
spanH(ei, TE, A) = [k1, k2], where
k1 = min{j|(i, j) E A}
k2 = max{j|(i, j) E A}
</equation>
<bodyText confidence="0.972695846153846">
In Figure 2, the phrase span of the node discover is
[6, 11] and the head span is [8, 8]; the phrase span of the
node reboot is [3, 4] and the head span is [4, 4]. The word
cause has a phrase span of [3,11] and its head span is the
empty set 0.
With these definitions of phrase and head spans, we de-
fine two notions of overlap, originally introduced in (Fox,
2002) as crossings. Given a head node eh and its modi-
fier em, a head-modifier overlap occurs when:
spanH(eh, TE, A) n spanP (em, TE, A) =� 0
Given two nodes em1 and em2 which both modify the
same head node, a modifier-modifier overlap occurs
when:
</bodyText>
<equation confidence="0.676352">
spanP (em1, TE, A) n spanP (em2, TE, A) =� 0
</equation>
<bodyText confidence="0.993259363636364">
Following (Fox, 2002), we say an alignment is cohe-
sive with respect to TE if it does not introduce any head-
modifier or modifier-modifier overlaps. For example, the
alignment A in Figure 1 is not cohesive because there
is an overlap between spanP (reboot, TE, A)=[4, 4] and
spanP (discover, TE, A)=[2,11].
If an alignment A&apos; violates the cohesion constraint, any
alignment A that is a superset of A&apos; will also violate the
cohesion constraint. This is because any pair of nodes
that have overlapping spans in A&apos; will still have overlap-
ping spans in A.
</bodyText>
<sectionHeader confidence="0.682727" genericHeader="method">
Cohesion Checking Algorithm:
</sectionHeader>
<bodyText confidence="0.9278312">
We now present an algorithm that checks whether an
individual link (ei, fj) causes a cohesion constraint vi-
olation when it is added to a partial alignment. Let
ep0, ep1, ep2, ... be a sequence of nodes in TE such that
ep0=ei and epk=parentOf(epk−1) (k = 1, 2, ...)
</bodyText>
<listItem confidence="0.999382363636364">
1. For all k ≥ 0, update the spanP and the spanH of
epk to include j.
2. For each epk (k &gt; 0), check for a modifier-modifier
overlap between the updated the phrase span of
epk−1 and the the phrase span of each of the other
children of epk.
3. For each epk (k &gt; 0), check for a head-modifier
overlap between the updated phrase span of epk−1
and the head span of epk.
4. If an overlap is found, return true (the constraint is
violated). Otherwise, return false.
</listItem>
<sectionHeader confidence="0.997097" genericHeader="method">
3 Evaluation
</sectionHeader>
<bodyText confidence="0.998749681818182">
To determine the utility of the cohesion constraint, we
incorporated it into two alignment algorithms. The algo-
rithms take as input an English-French sentence pair and
the dependency tree of the English sentence. Both algo-
rithms build an alignment by adding one link at a time.
We implement two versions of each algorithm: one with
the cohesion constraint and one without. We will describe
the versions without cohesion constraint below. For the
versions with cohesion constraint, it is understood that
each new link must also pass the test described in Sec-
tion 2.
The first algorithm is similar to Competitive Linking
(Melamed, 1997). We use a sentence-aligned corpus
to compute the 02 correlation metric (Gale and Church,
1991) between all English-French word pairs. For a given
sentence pair, we begin with an empty alignment. We
then add links in the order of their 02 scores so that each
word participates in at most one link. We will refer to this
as the 02 method.
The second algorithm uses a best-first search (with
fixed beam width and agenda size) to find an alignment
that maximizes P(A|E, F). A state in this search space
is a partial alignment. A transition is defined as the ad-
dition of a single link to the current state. The algorithm
computes P(A|E, F) based on statistics obtained from a
word-aligned corpus. We construct the initial corpus with
a system that is similar to the 02 method. The algorithm
then re-aligns the corpus and trains again for three iter-
ations. We will refer to this as the P(A|E, F) method.
The details of this algorithm are described in (Cherry and
Lin, 2003).
We trained our alignment programs with the same 50K
pairs of sentences as (Och and Ney, 2000) and tested it on
the same 500 manually aligned sentences. Both the train-
ing and testing sentences are from the Hansard corpus.
We parsed the training and testing corpora with Minipar.l
We adopted the evaluation methodology in (Och and Ney,
2000), which defines three metrics: precision, recall and
alignment error rate (AER).
Table 1 shows the results of our experiments. The first
four rows correspond to the methods described above. As
a reference point, we also provide the results reported in
(Och and Ney, 2000). They implemented IBM Model 4
by bootstrapping from an HMM model. The rows F→E
</bodyText>
<footnote confidence="0.713362">
&apos;available at http://www.cs.ualberta.ca/˜lindek/minipar.htm
</footnote>
<tableCaption confidence="0.997765">
Table 1: Evaluation Results
</tableCaption>
<table confidence="0.9996875">
Method Prec Rec AER
02 w/o cohesion 82.7 84.6 16.5
w/ cohesion 89.2 82.7 13.8
P(A|E, F) w/o cohesion 87.3 85.3 13.6
w/ cohesion 95.7 86.4 8.7
F→E 80.5 91.2 15.6
Och&amp;Ney E→F 80.0 90.8 16.0
Refined 85.9 92.3 11.7
</table>
<bodyText confidence="0.999720538461539">
and E→F are the results obtained by this model when
treating French as the source and English as the target
or vice versa. The row Refined shows results obtained
by taking the intersection of E→F and F→E and then
refining this intersection to increase recall.
From Table 1, we can see that the addition of the cohe-
sion constraint leads to significant improvements in per-
formance with both algorithms. The relative reduction in
error rate is 16% with the 02 method and 36% with the
P(A|E, F) method. The improvement comes primarily
from increased precision. With the P(A|E, F) method,
this increase in precision does not come at the expense of
recall.
</bodyText>
<sectionHeader confidence="0.99989" genericHeader="evaluation">
4 Related Work
</sectionHeader>
<bodyText confidence="0.999959588235294">
There has been a growing trend in the SMT community
to attempt to leverage syntactic data in word alignment.
Methods such as (Wu, 1997), (Alshawi et al., 2000) and
(Lopez et al., 2002) employ a synchronous parsing proce-
dure to constrain a statistical alignment. The work done
in (Yamada and Knight, 2001) measures statistics on op-
erations that transform a parse tree from one language
into another.
The syntactic knowledge that is leveraged in these
methods is tightly coupled with the alignment method it-
self. We have presented a modular constraint that can be
plugged into different alignment algorithms. This has al-
lowed us to test the contribution of the constraint directly.
(Fox, 2002) studied the extent to which the cohesion
constraint holds in a parallel corpus and the reasons for
the violations, but did not apply the constraint to an align-
ment algorithm.
</bodyText>
<sectionHeader confidence="0.999259" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999964166666667">
We have presented a syntax-based constraint for word
alignment, known as the cohesion constraint. It requires
disjoint English phrases to be mapped to non-overlapping
intervals in the French sentence. Our experiments have
shown that the use of this constraint can provide a rela-
tive reduction in alignment error rate of 36%.
</bodyText>
<sectionHeader confidence="0.995491" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999556">
We wish to thank Franz Och for providing us with manu-
ally aligned evaluation data. This project is funded by and
jointly undertaken with Sun Microsystems, Inc. We wish
to thank Finola Brady, Bob Kuhns and Michael McHugh
for their help.
</bodyText>
<sectionHeader confidence="0.998122" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998290121951219">
Hiyan Alshawi, Srinivas Bangalore, and Shona Douglas.
2000. Learning dependency translation models as col-
lections of finite state head transducers. Computa-
tional Linguistics, 26(1):45–60.
Colin Cherry and Dekang Lin. 2003. A probability
model to improve word alignment. Submitted.
Bonnie J. Dorr, Lisa Pearl, Rebecca Hwa, and Nizar
Habash. 2002. Duster: A method for unraveling
cross-language divergences for statistical word-level
alignment. In Stephen D. Richardson, editor, Proceed-
ings ofAMTA-02, pages 31–43, Tiburon, CA, October.
Springer.
Heidi J. Fox. 2002. Phrasal cohesion and statistical ma-
chine translation. In Proceedings ofEMNLP-02, pages
304–311.
W.A. Gale and K.W. Church. 1991. Identifying word
correspondences in parallel texts. In Proceedings of
the 4th Speech and Natural Language Workshop, pages
152–157. DARPA, Morgan Kaufmann.
Adam Lopez, Michael Nossal, Rebecca Hwa, and Philip
Resnik. 2002. Word-level alignment for multilingual
resource acquisition. In Proceedings of the Workshop
on Linguistic Knowledge Acquisition and Representa-
tion: Bootstrapping Annotated Language Data.
I. Dan Melamed. 1997. A word-to-word model of trans-
lational equivalence. In Proceedings of the ACL-97,
pages 490–497. Association for Computational Lin-
guistics.
Igor A. Mel’ˇcuk. 1987. Dependency syntax: theory and
practice. State University of New York Press, Albany.
Franz J. Och and Hermann Ney. 2000. Improved sta-
tistical alignment models. In Proceedings of the 38th
Annual Meeting of the Association for Computational
Linguistics, pages 440–447, Hong Kong, China, Octo-
ber.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3):374–403.
Kenji Yamada and Kevin Knight. 2001. A syntax-based
statistical translation model. In Meeting of the Associ-
ation for Computational Linguistics, pages 523–530.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.932848">
<title confidence="0.998863">Word Alignment with Cohesion Constraint</title>
<author confidence="0.998861">Lin</author>
<affiliation confidence="0.9990315">Department of Computing University of</affiliation>
<address confidence="0.958283">Edmonton, Alberta, Canada, T6G</address>
<abstract confidence="0.997309111111111">We present a syntax-based constraint for word alignment, known as the cohesion constraint. It requires disjoint English phrases to be mapped to non-overlapping intervals in the French sentence. We evaluate the utility of this constraint in two different algorithms. The results show that it can provide a significant improvement in alignment quality.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Hiyan Alshawi</author>
<author>Srinivas Bangalore</author>
<author>Shona Douglas</author>
</authors>
<title>Learning dependency translation models as collections of finite state head transducers.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>26</volume>
<issue>1</issue>
<contexts>
<context position="1094" citStr="Alshawi et al., 2000" startWordPosition="158" endWordPosition="161"> show that it can provide a significant improvement in alignment quality. 1 Introduction The IBM statistical machine translation (SMT) models have been extremely influential in computational linguistics in the past decade. The (arguably) most striking characteristic of the IBM-style SMT models is their total lack of linguistic knowledge. The IBM models demonstrated how much one can do with pure statistical techniques, which have inspired a whole new generation of NLP research and systems. More recently, there have been many proposals to introduce syntactic knowledge into SMT models (Wu, 1997; Alshawi et al., 2000; Yamada and Knight, 2001; Lopez et al., 2002). A common theme among these approaches is the assumption that the syntactic structures of a pair of source-target sentences are isomorphic (or nearly isomorphic). This assumption seems too strong. Human translators often use non-literal translations, which result in differences in syntactic structures. According to a study in (Dorr et al., 2002), such translational divergences are quite common, involving 11-31% of the sentences. We introduce a constraint that uses the dependency tree of the English sentence to maintain phrasal cohesion in the Fren</context>
<context position="9335" citStr="Alshawi et al., 2000" startWordPosition="1603" endWordPosition="1606">and then refining this intersection to increase recall. From Table 1, we can see that the addition of the cohesion constraint leads to significant improvements in performance with both algorithms. The relative reduction in error rate is 16% with the 02 method and 36% with the P(A|E, F) method. The improvement comes primarily from increased precision. With the P(A|E, F) method, this increase in precision does not come at the expense of recall. 4 Related Work There has been a growing trend in the SMT community to attempt to leverage syntactic data in word alignment. Methods such as (Wu, 1997), (Alshawi et al., 2000) and (Lopez et al., 2002) employ a synchronous parsing procedure to constrain a statistical alignment. The work done in (Yamada and Knight, 2001) measures statistics on operations that transform a parse tree from one language into another. The syntactic knowledge that is leveraged in these methods is tightly coupled with the alignment method itself. We have presented a modular constraint that can be plugged into different alignment algorithms. This has allowed us to test the contribution of the constraint directly. (Fox, 2002) studied the extent to which the cohesion constraint holds in a para</context>
</contexts>
<marker>Alshawi, Bangalore, Douglas, 2000</marker>
<rawString>Hiyan Alshawi, Srinivas Bangalore, and Shona Douglas. 2000. Learning dependency translation models as collections of finite state head transducers. Computational Linguistics, 26(1):45–60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Cherry</author>
<author>Dekang Lin</author>
</authors>
<title>A probability model to improve word alignment.</title>
<date>2003</date>
<note>Submitted.</note>
<contexts>
<context position="7519" citStr="Cherry and Lin, 2003" startWordPosition="1297" endWordPosition="1300">d algorithm uses a best-first search (with fixed beam width and agenda size) to find an alignment that maximizes P(A|E, F). A state in this search space is a partial alignment. A transition is defined as the addition of a single link to the current state. The algorithm computes P(A|E, F) based on statistics obtained from a word-aligned corpus. We construct the initial corpus with a system that is similar to the 02 method. The algorithm then re-aligns the corpus and trains again for three iterations. We will refer to this as the P(A|E, F) method. The details of this algorithm are described in (Cherry and Lin, 2003). We trained our alignment programs with the same 50K pairs of sentences as (Och and Ney, 2000) and tested it on the same 500 manually aligned sentences. Both the training and testing sentences are from the Hansard corpus. We parsed the training and testing corpora with Minipar.l We adopted the evaluation methodology in (Och and Ney, 2000), which defines three metrics: precision, recall and alignment error rate (AER). Table 1 shows the results of our experiments. The first four rows correspond to the methods described above. As a reference point, we also provide the results reported in (Och an</context>
</contexts>
<marker>Cherry, Lin, 2003</marker>
<rawString>Colin Cherry and Dekang Lin. 2003. A probability model to improve word alignment. Submitted.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie J Dorr</author>
<author>Lisa Pearl</author>
<author>Rebecca Hwa</author>
<author>Nizar Habash</author>
</authors>
<title>Duster: A method for unraveling cross-language divergences for statistical word-level alignment.</title>
<date>2002</date>
<booktitle>Proceedings ofAMTA-02,</booktitle>
<pages>31--43</pages>
<editor>In Stephen D. Richardson, editor,</editor>
<publisher>October. Springer.</publisher>
<location>Tiburon, CA,</location>
<contexts>
<context position="1488" citStr="Dorr et al., 2002" startWordPosition="220" endWordPosition="223">e statistical techniques, which have inspired a whole new generation of NLP research and systems. More recently, there have been many proposals to introduce syntactic knowledge into SMT models (Wu, 1997; Alshawi et al., 2000; Yamada and Knight, 2001; Lopez et al., 2002). A common theme among these approaches is the assumption that the syntactic structures of a pair of source-target sentences are isomorphic (or nearly isomorphic). This assumption seems too strong. Human translators often use non-literal translations, which result in differences in syntactic structures. According to a study in (Dorr et al., 2002), such translational divergences are quite common, involving 11-31% of the sentences. We introduce a constraint that uses the dependency tree of the English sentence to maintain phrasal cohesion in the French sentence. In other words, if two phrases are disjoint in the English sentence, the alignment must not map them to overlapping intervals in the French sentence. For example, in Figure 1, the cohesion constraint will rule out the possibility of aligning to with `a. The phrases the reboot and the host to discover all the devices are disjoint, but the partial alignment in Figure 1 maps them t</context>
</contexts>
<marker>Dorr, Pearl, Hwa, Habash, 2002</marker>
<rawString>Bonnie J. Dorr, Lisa Pearl, Rebecca Hwa, and Nizar Habash. 2002. Duster: A method for unraveling cross-language divergences for statistical word-level alignment. In Stephen D. Richardson, editor, Proceedings ofAMTA-02, pages 31–43, Tiburon, CA, October. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heidi J Fox</author>
</authors>
<title>Phrasal cohesion and statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings ofEMNLP-02,</booktitle>
<pages>304--311</pages>
<contexts>
<context position="3287" citStr="Fox, 2002" startWordPosition="513" endWordPosition="514">tween the words in E and F. An alignment can be represented as a binary relation A in [1, l] × [1, m]. A pair (i, j) is in A if ei and fj are a translation (or part of a translation) of each other. We call such pairs links. In Figure 2, the links in the alignment are represented by dashed lines. compe pre subj� det� subj� det� aux� detE] The[tebootCdauses[Hhe[host[to[discoverCall[Hhe[devices❑ Suite❑à laijiéinitialisation ,d&apos; hôte[}epère❑tousIles4�ériphériques❑ after❑ toE the❑ reboot❑ the®ost❑ locate❑ all❑ the❑ peripherals❑ Figure 2: An example pair of aligned sentence The cohesion constraint (Fox, 2002) uses the dependency tree TE (Mel’ˇcuk, 1987) of the English sentence mode obj❑ preO.detE] subjl7 detf] ubjc detE] aux1. 1❑ 20 3 E 40 50 60 70 80 90 100 10 20 30 40 5❑6❑7❑ 80 90 100 11El obj11 to restrict possible link combinations. Let TE(ei) be the subtree of TE rooted at ei. The phrase span of ei, spanP (ei, TE, A), is the image of the English phrase headed by ei in F given a (partial) alignment A. More precisely, spanP (ei, TE, A) = [k1, k2], where k1 = min{j|(u, j) E A, eu E TE(ei)} k2 = max{j|(u, j) E A, eu E TE(ei)} The head span is the image of ei itself. We define spanH(ei, TE, A) = [</context>
<context position="4621" citStr="Fox, 2002" startWordPosition="787" endWordPosition="788">d the head span is [8, 8]; the phrase span of the node reboot is [3, 4] and the head span is [4, 4]. The word cause has a phrase span of [3,11] and its head span is the empty set 0. With these definitions of phrase and head spans, we define two notions of overlap, originally introduced in (Fox, 2002) as crossings. Given a head node eh and its modifier em, a head-modifier overlap occurs when: spanH(eh, TE, A) n spanP (em, TE, A) =� 0 Given two nodes em1 and em2 which both modify the same head node, a modifier-modifier overlap occurs when: spanP (em1, TE, A) n spanP (em2, TE, A) =� 0 Following (Fox, 2002), we say an alignment is cohesive with respect to TE if it does not introduce any headmodifier or modifier-modifier overlaps. For example, the alignment A in Figure 1 is not cohesive because there is an overlap between spanP (reboot, TE, A)=[4, 4] and spanP (discover, TE, A)=[2,11]. If an alignment A&apos; violates the cohesion constraint, any alignment A that is a superset of A&apos; will also violate the cohesion constraint. This is because any pair of nodes that have overlapping spans in A&apos; will still have overlapping spans in A. Cohesion Checking Algorithm: We now present an algorithm that checks wh</context>
<context position="9867" citStr="Fox, 2002" startWordPosition="1691" endWordPosition="1692">tic data in word alignment. Methods such as (Wu, 1997), (Alshawi et al., 2000) and (Lopez et al., 2002) employ a synchronous parsing procedure to constrain a statistical alignment. The work done in (Yamada and Knight, 2001) measures statistics on operations that transform a parse tree from one language into another. The syntactic knowledge that is leveraged in these methods is tightly coupled with the alignment method itself. We have presented a modular constraint that can be plugged into different alignment algorithms. This has allowed us to test the contribution of the constraint directly. (Fox, 2002) studied the extent to which the cohesion constraint holds in a parallel corpus and the reasons for the violations, but did not apply the constraint to an alignment algorithm. 5 Conclusion We have presented a syntax-based constraint for word alignment, known as the cohesion constraint. It requires disjoint English phrases to be mapped to non-overlapping intervals in the French sentence. Our experiments have shown that the use of this constraint can provide a relative reduction in alignment error rate of 36%. Acknowledgments We wish to thank Franz Och for providing us with manually aligned eval</context>
</contexts>
<marker>Fox, 2002</marker>
<rawString>Heidi J. Fox. 2002. Phrasal cohesion and statistical machine translation. In Proceedings ofEMNLP-02, pages 304–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Gale</author>
<author>K W Church</author>
</authors>
<title>Identifying word correspondences in parallel texts.</title>
<date>1991</date>
<booktitle>In Proceedings of the 4th Speech and Natural Language Workshop,</booktitle>
<pages>152--157</pages>
<publisher>DARPA, Morgan Kaufmann.</publisher>
<contexts>
<context position="6646" citStr="Gale and Church, 1991" startWordPosition="1140" endWordPosition="1143">algorithms take as input an English-French sentence pair and the dependency tree of the English sentence. Both algorithms build an alignment by adding one link at a time. We implement two versions of each algorithm: one with the cohesion constraint and one without. We will describe the versions without cohesion constraint below. For the versions with cohesion constraint, it is understood that each new link must also pass the test described in Section 2. The first algorithm is similar to Competitive Linking (Melamed, 1997). We use a sentence-aligned corpus to compute the 02 correlation metric (Gale and Church, 1991) between all English-French word pairs. For a given sentence pair, we begin with an empty alignment. We then add links in the order of their 02 scores so that each word participates in at most one link. We will refer to this as the 02 method. The second algorithm uses a best-first search (with fixed beam width and agenda size) to find an alignment that maximizes P(A|E, F). A state in this search space is a partial alignment. A transition is defined as the addition of a single link to the current state. The algorithm computes P(A|E, F) based on statistics obtained from a word-aligned corpus. We</context>
</contexts>
<marker>Gale, Church, 1991</marker>
<rawString>W.A. Gale and K.W. Church. 1991. Identifying word correspondences in parallel texts. In Proceedings of the 4th Speech and Natural Language Workshop, pages 152–157. DARPA, Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Lopez</author>
<author>Michael Nossal</author>
<author>Rebecca Hwa</author>
<author>Philip Resnik</author>
</authors>
<title>Word-level alignment for multilingual resource acquisition.</title>
<date>2002</date>
<booktitle>In Proceedings of the Workshop on Linguistic Knowledge Acquisition and Representation: Bootstrapping Annotated Language Data.</booktitle>
<contexts>
<context position="1140" citStr="Lopez et al., 2002" startWordPosition="166" endWordPosition="169">ment in alignment quality. 1 Introduction The IBM statistical machine translation (SMT) models have been extremely influential in computational linguistics in the past decade. The (arguably) most striking characteristic of the IBM-style SMT models is their total lack of linguistic knowledge. The IBM models demonstrated how much one can do with pure statistical techniques, which have inspired a whole new generation of NLP research and systems. More recently, there have been many proposals to introduce syntactic knowledge into SMT models (Wu, 1997; Alshawi et al., 2000; Yamada and Knight, 2001; Lopez et al., 2002). A common theme among these approaches is the assumption that the syntactic structures of a pair of source-target sentences are isomorphic (or nearly isomorphic). This assumption seems too strong. Human translators often use non-literal translations, which result in differences in syntactic structures. According to a study in (Dorr et al., 2002), such translational divergences are quite common, involving 11-31% of the sentences. We introduce a constraint that uses the dependency tree of the English sentence to maintain phrasal cohesion in the French sentence. In other words, if two phrases ar</context>
<context position="9360" citStr="Lopez et al., 2002" startWordPosition="1608" endWordPosition="1611">rsection to increase recall. From Table 1, we can see that the addition of the cohesion constraint leads to significant improvements in performance with both algorithms. The relative reduction in error rate is 16% with the 02 method and 36% with the P(A|E, F) method. The improvement comes primarily from increased precision. With the P(A|E, F) method, this increase in precision does not come at the expense of recall. 4 Related Work There has been a growing trend in the SMT community to attempt to leverage syntactic data in word alignment. Methods such as (Wu, 1997), (Alshawi et al., 2000) and (Lopez et al., 2002) employ a synchronous parsing procedure to constrain a statistical alignment. The work done in (Yamada and Knight, 2001) measures statistics on operations that transform a parse tree from one language into another. The syntactic knowledge that is leveraged in these methods is tightly coupled with the alignment method itself. We have presented a modular constraint that can be plugged into different alignment algorithms. This has allowed us to test the contribution of the constraint directly. (Fox, 2002) studied the extent to which the cohesion constraint holds in a parallel corpus and the reaso</context>
</contexts>
<marker>Lopez, Nossal, Hwa, Resnik, 2002</marker>
<rawString>Adam Lopez, Michael Nossal, Rebecca Hwa, and Philip Resnik. 2002. Word-level alignment for multilingual resource acquisition. In Proceedings of the Workshop on Linguistic Knowledge Acquisition and Representation: Bootstrapping Annotated Language Data.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>A word-to-word model of translational equivalence.</title>
<date>1997</date>
<booktitle>In Proceedings of the ACL-97,</booktitle>
<pages>490--497</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6551" citStr="Melamed, 1997" startWordPosition="1127" endWordPosition="1128">lity of the cohesion constraint, we incorporated it into two alignment algorithms. The algorithms take as input an English-French sentence pair and the dependency tree of the English sentence. Both algorithms build an alignment by adding one link at a time. We implement two versions of each algorithm: one with the cohesion constraint and one without. We will describe the versions without cohesion constraint below. For the versions with cohesion constraint, it is understood that each new link must also pass the test described in Section 2. The first algorithm is similar to Competitive Linking (Melamed, 1997). We use a sentence-aligned corpus to compute the 02 correlation metric (Gale and Church, 1991) between all English-French word pairs. For a given sentence pair, we begin with an empty alignment. We then add links in the order of their 02 scores so that each word participates in at most one link. We will refer to this as the 02 method. The second algorithm uses a best-first search (with fixed beam width and agenda size) to find an alignment that maximizes P(A|E, F). A state in this search space is a partial alignment. A transition is defined as the addition of a single link to the current stat</context>
</contexts>
<marker>Melamed, 1997</marker>
<rawString>I. Dan Melamed. 1997. A word-to-word model of translational equivalence. In Proceedings of the ACL-97, pages 490–497. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Igor A Mel’ˇcuk</author>
</authors>
<title>Dependency syntax: theory and practice.</title>
<date>1987</date>
<publisher>State University of New York Press,</publisher>
<location>Albany.</location>
<marker>Mel’ˇcuk, 1987</marker>
<rawString>Igor A. Mel’ˇcuk. 1987. Dependency syntax: theory and practice. State University of New York Press, Albany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
<author>Hermann Ney</author>
</authors>
<title>Improved statistical alignment models.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>440--447</pages>
<location>Hong Kong, China,</location>
<contexts>
<context position="7614" citStr="Och and Ney, 2000" startWordPosition="1314" endWordPosition="1317">that maximizes P(A|E, F). A state in this search space is a partial alignment. A transition is defined as the addition of a single link to the current state. The algorithm computes P(A|E, F) based on statistics obtained from a word-aligned corpus. We construct the initial corpus with a system that is similar to the 02 method. The algorithm then re-aligns the corpus and trains again for three iterations. We will refer to this as the P(A|E, F) method. The details of this algorithm are described in (Cherry and Lin, 2003). We trained our alignment programs with the same 50K pairs of sentences as (Och and Ney, 2000) and tested it on the same 500 manually aligned sentences. Both the training and testing sentences are from the Hansard corpus. We parsed the training and testing corpora with Minipar.l We adopted the evaluation methodology in (Och and Ney, 2000), which defines three metrics: precision, recall and alignment error rate (AER). Table 1 shows the results of our experiments. The first four rows correspond to the methods described above. As a reference point, we also provide the results reported in (Och and Ney, 2000). They implemented IBM Model 4 by bootstrapping from an HMM model. The rows F→E &apos;av</context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>Franz J. Och and Hermann Ney. 2000. Improved statistical alignment models. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics, pages 440–447, Hong Kong, China, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>3</issue>
<contexts>
<context position="1072" citStr="Wu, 1997" startWordPosition="156" endWordPosition="157">he results show that it can provide a significant improvement in alignment quality. 1 Introduction The IBM statistical machine translation (SMT) models have been extremely influential in computational linguistics in the past decade. The (arguably) most striking characteristic of the IBM-style SMT models is their total lack of linguistic knowledge. The IBM models demonstrated how much one can do with pure statistical techniques, which have inspired a whole new generation of NLP research and systems. More recently, there have been many proposals to introduce syntactic knowledge into SMT models (Wu, 1997; Alshawi et al., 2000; Yamada and Knight, 2001; Lopez et al., 2002). A common theme among these approaches is the assumption that the syntactic structures of a pair of source-target sentences are isomorphic (or nearly isomorphic). This assumption seems too strong. Human translators often use non-literal translations, which result in differences in syntactic structures. According to a study in (Dorr et al., 2002), such translational divergences are quite common, involving 11-31% of the sentences. We introduce a constraint that uses the dependency tree of the English sentence to maintain phrasa</context>
<context position="9311" citStr="Wu, 1997" startWordPosition="1601" endWordPosition="1602">E→F and F→E and then refining this intersection to increase recall. From Table 1, we can see that the addition of the cohesion constraint leads to significant improvements in performance with both algorithms. The relative reduction in error rate is 16% with the 02 method and 36% with the P(A|E, F) method. The improvement comes primarily from increased precision. With the P(A|E, F) method, this increase in precision does not come at the expense of recall. 4 Related Work There has been a growing trend in the SMT community to attempt to leverage syntactic data in word alignment. Methods such as (Wu, 1997), (Alshawi et al., 2000) and (Lopez et al., 2002) employ a synchronous parsing procedure to constrain a statistical alignment. The work done in (Yamada and Knight, 2001) measures statistics on operations that transform a parse tree from one language into another. The syntactic knowledge that is leveraged in these methods is tightly coupled with the alignment method itself. We have presented a modular constraint that can be plugged into different alignment algorithms. This has allowed us to test the contribution of the constraint directly. (Fox, 2002) studied the extent to which the cohesion co</context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>Dekai Wu. 1997. Stochastic inversion transduction grammars and bilingual parsing of parallel corpora. Computational Linguistics, 23(3):374–403.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Yamada</author>
<author>Kevin Knight</author>
</authors>
<title>A syntax-based statistical translation model.</title>
<date>2001</date>
<booktitle>In Meeting of the Association for Computational Linguistics,</booktitle>
<pages>523--530</pages>
<contexts>
<context position="1119" citStr="Yamada and Knight, 2001" startWordPosition="162" endWordPosition="165">ide a significant improvement in alignment quality. 1 Introduction The IBM statistical machine translation (SMT) models have been extremely influential in computational linguistics in the past decade. The (arguably) most striking characteristic of the IBM-style SMT models is their total lack of linguistic knowledge. The IBM models demonstrated how much one can do with pure statistical techniques, which have inspired a whole new generation of NLP research and systems. More recently, there have been many proposals to introduce syntactic knowledge into SMT models (Wu, 1997; Alshawi et al., 2000; Yamada and Knight, 2001; Lopez et al., 2002). A common theme among these approaches is the assumption that the syntactic structures of a pair of source-target sentences are isomorphic (or nearly isomorphic). This assumption seems too strong. Human translators often use non-literal translations, which result in differences in syntactic structures. According to a study in (Dorr et al., 2002), such translational divergences are quite common, involving 11-31% of the sentences. We introduce a constraint that uses the dependency tree of the English sentence to maintain phrasal cohesion in the French sentence. In other wor</context>
<context position="9480" citStr="Yamada and Knight, 2001" startWordPosition="1627" endWordPosition="1630">cant improvements in performance with both algorithms. The relative reduction in error rate is 16% with the 02 method and 36% with the P(A|E, F) method. The improvement comes primarily from increased precision. With the P(A|E, F) method, this increase in precision does not come at the expense of recall. 4 Related Work There has been a growing trend in the SMT community to attempt to leverage syntactic data in word alignment. Methods such as (Wu, 1997), (Alshawi et al., 2000) and (Lopez et al., 2002) employ a synchronous parsing procedure to constrain a statistical alignment. The work done in (Yamada and Knight, 2001) measures statistics on operations that transform a parse tree from one language into another. The syntactic knowledge that is leveraged in these methods is tightly coupled with the alignment method itself. We have presented a modular constraint that can be plugged into different alignment algorithms. This has allowed us to test the contribution of the constraint directly. (Fox, 2002) studied the extent to which the cohesion constraint holds in a parallel corpus and the reasons for the violations, but did not apply the constraint to an alignment algorithm. 5 Conclusion We have presented a synt</context>
</contexts>
<marker>Yamada, Knight, 2001</marker>
<rawString>Kenji Yamada and Kevin Knight. 2001. A syntax-based statistical translation model. In Meeting of the Association for Computational Linguistics, pages 523–530.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>