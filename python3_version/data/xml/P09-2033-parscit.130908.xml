<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000959">
<title confidence="0.9982675">
English-Chinese Bi-Directional OOV Translation
based on Web Mining and Supervised Learning
</title>
<author confidence="0.999575">
Yuejie Zhang, Yang Wang and Xiangyang Xue
</author>
<affiliation confidence="0.958809">
School of Computer Science
Shanghai Key Laboratory of Intelligent Information Processing
Fudan University, Shanghai 200433, P.R. China
</affiliation>
<email confidence="0.995879">
{yjzhang,072021176,xyxue}@fudan.edu.cn
</email>
<sectionHeader confidence="0.993692" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.996930357142857">
In Cross-Language Information Retrieval
(CLIR), Out-of-Vocabulary (OOV) detection
and translation pair relevance evaluation still
remain as key problems. In this paper, an Eng-
lish-Chinese Bi-Directional OOV translation
model is presented, which utilizes Web mining
as the corpus source to collect translation pairs
and combines supervised learning to evaluate
their association degree. The experimental re-
sults show that the proposed model can suc-
cessfully filter the most possible translation
candidate with the lower computational cost,
and improve the OOV translation ranking ef-
fect, especially for popular new words.
</bodyText>
<sectionHeader confidence="0.998755" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99960556">
In Cross-Language Information Retrieval (CLIR),
most of queries are generally composed of short
terms, in which there are many Out-of-
Vocabulary (OOV) terms like named entities,
new words, terminologies and so on. The transla-
tion quality of OOVs directly influences the pre-
cision of querying relevant multilingual informa-
tion. Therefore, OOV translation has become a
very important and challenging issue in CLIR.
The translation of OOVs can either be ac-
quired from parallel or comparable corpus (Lee,
2006) or mining from Web (Lu, 2004). However,
how to evaluate the degree of association be-
tween source query term and its target translation
is quite important. In this paper, an OOV transla-
tion model is established based on the combina-
tion pattern of Web mining and translation rank-
ing. Given an OOV, its related information are
gotten from search results by search engine, from
which the possible translation terms in target
language can be extracted and then ranked
through supervised learning such as Support
Vector Machine (SVM) and Ranking-SVM (Cao,
2006). The basic framework of the translation
model is shown in Figure 1.
</bodyText>
<figureCaption confidence="0.9054465">
Figure 1. The basic framework of English-
Chinese Bi-Directional OOV translation model.
</figureCaption>
<sectionHeader confidence="0.989938" genericHeader="introduction">
2 Related Research Work
</sectionHeader>
<bodyText confidence="0.999943411764706">
With the rapid growth of Web information, in-
creasing new terms and terminologies cannot be
found in bilingual dictionaries. The state-of-art
OOV translation strategies tend to use Web itself
as a big corpus (Wang, 2004; Zhang, 2004). The
quick and direct way of getting required informa-
tion from Web pages is to use search engines,
such as Google, Altavista or Yahoo. Therefore,
many OOV translation models based on Web
mining are proposed by researchers (Fang, 2006;
Wu, 2007).
By introducing supervised learning mechan-
ism, the relevance between original OOV term
and extracted candidate translation can be accu-
rately evaluated. Meanwhile, the model proposed
exhibits better applicability and can also be ap-
plied in processing OOVs with different classes.
</bodyText>
<sectionHeader confidence="0.7423675" genericHeader="method">
3 Chinese OOV Extraction based on
PAT-Tree
</sectionHeader>
<bodyText confidence="0.999810285714286">
For a language that has no words boundary like
Chinese, PAT-Tree data structure is adopted to
extract OOV terms (Chien, 1997). The most out-
standing property of this structure is its Semi
Infinite String, which can store all the semi-
strings of whole corpus in a binary tree. In this
tree, branch nodes indicate direction of search
</bodyText>
<page confidence="0.986536">
129
</page>
<note confidence="0.925972">
Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 129–132,
Suntec, Singapore, 4 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999411818181818">
and child nodes store information about index
and frequency of semi infinite strings. With
common strings being extracted, large amounts
of noisy terms and fragments are also extracted.
For example, when searching for the translation
of English abbreviation term “FDA”, some noisy
Chinese terms are extracted, such as “国食品”
(17 times), “美国食品” (16 times), “美国食品
药” (9 times). In order to filter noisy fragments,
the simplified Local-Maxima algorithm is used
(Wang, 2004).
</bodyText>
<sectionHeader confidence="0.8874795" genericHeader="method">
4 Translation Ranking based on Super-
vised Learning
</sectionHeader>
<subsectionHeader confidence="0.932288">
4.1 Ranking by Classification and Ordinal
</subsectionHeader>
<sectionHeader confidence="0.732441" genericHeader="method">
Regression
</sectionHeader>
<bodyText confidence="0.999979636363636">
Based on the extracted terms, the correct transla-
tion can be chosen further. A direct option is to
rank them by their frequency or length. It works
well when the OOV term has a unique meaning
and all the Web snippets are about the same topic.
However, in much more cases only the highly
related fragments of OOV terms can be found,
rather than their correct translations. To evaluate
the relevance of translation pair precisely, SVM
and Ranking-SVM are employed as classifier
and ordinal regression model respectively.
</bodyText>
<subsectionHeader confidence="0.994244">
4.2 Feature Representation
</subsectionHeader>
<bodyText confidence="0.9995365">
The same feature set is utilized by SVM and
Ranking-SVM.
</bodyText>
<listItem confidence="0.999095692307692">
(1) Term frequency: fq denotes the frequency of
OOV to be translated in all the Web snippets
of search results. tfi indicates the number of
the translation candidate in all the snippets.
dfi represents the number of Web snippets
that contains the candidate. dft means the
number of snippets that contains both OOV
to be translated and the candidate.
(2) Term length: Len( ) is the length of the can-
didate.
(3) Cooccurrence Distance: C-Dist is the aver-
age distance between the OOV query and the
translation candidate, computed as follows.
</listItem>
<equation confidence="0.9080715">
(Dist) (1)
dft
</equation>
<bodyText confidence="0.995209">
where Sum(Dist) is the sum of distance in
each translation pair of every snippet.
</bodyText>
<listItem confidence="0.743119">
(4) Length Ratio: This is the ratio of OOV query
length and translation candidate length.
(5) Rank Value:
i. Top Rank (T-Rank): The rank of snippet
that first contains the candidate. This
value indicates the rank given by search
engine.
ii. Average_Rank (A-Rank): It is the aver-
age position of candidate in snippets of
search results, shown as follows.
</listItem>
<equation confidence="0.962874333333333">
Sum(Rank)
A −Rank = (2)
dfi
</equation>
<bodyText confidence="0.999147333333333">
where Sum(Rank) denotes the sum of
every single rank value of snippets that
contains the candidate.
</bodyText>
<listItem confidence="0.98699">
iii. Simple_Rank (S-Rank): It is computed
based on Rank(i)=tfi*Len(i), which aims
at investigating the impact of these two
features on ranking translation.
iv. R-Rank: This rank method is utilized as a
comparison basis, computed as follows.
</listItem>
<equation confidence="0.947205666666667">
Sn
R Rank
− =αx L +(1−α)x
</equation>
<bodyText confidence="0.99967">
where α is set as 0.25 empirically, |Sn|
represents the length of candidate term,
L is the largest length of candidate terms,
fn is tfi, and foov is fq in Feature (1).
</bodyText>
<listItem confidence="0.9879815">
v. Df_Rank (D-Rank): It is similar to S-
Rank and computed based on Rank(i)=
dfi *Len(i).
(6) Mark feature: Within a certain distance
</listItem>
<bodyText confidence="0.986844916666667">
(usually less than 10 characters) between the
original OOV and candidate, if there is such
a term like “全称”, “中文叫”, “中文译为”
“中文名称”, “中文称为”, “或称为”, “又称
为”, “英文叫”, “英文名为”, this feature will
be labeled as “+1”, else “-1” instead.
Among these features above, some features
come from search engine like (1) and (5) and
some ones from heuristic rules like (3) and (6).
Through the establishment of feature set, the
translation candidate can be optimized efficiently
and the noisy information can also be filtered.
</bodyText>
<sectionHeader confidence="0.989034" genericHeader="evaluation">
5 Experiment and Analysis
</sectionHeader>
<subsectionHeader confidence="0.985463">
5.1 Data Set
</subsectionHeader>
<bodyText confidence="0.999961166666667">
For the performance evaluation of Chinese-
English OOV translation, the corpus of NER task
in SIGHAN 2008 provided by Peking University
is used. The whole corpus contains 19,866 per-
son names, 22,212 location names and 7,837 or-
ganization names, from which 100 person names,
100 location names and 100 organization names
are selected for testing. Meanwhile, 300 English
named entities are chosen randomly from the
terms of 9 categories, which include movie name,
book title, organization name, brand name, ter-
minology, idiom, rare animal name, person name
</bodyText>
<figure confidence="0.8810315">
Sum
=
C-Dist
fn (3)
fOOV
,
</figure>
<page confidence="0.930294">
130
</page>
<bodyText confidence="0.973863">
=
and so on. These new terms are used as the test-
ing data for English-Chinese OOV translation.
</bodyText>
<subsectionHeader confidence="0.990658">
5.2 Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.9932735">
Three parameters are used for the evaluation of
translation and ranking candidates.
</bodyText>
<figure confidence="0.938028">
N Inclusion Rate
− −
number of correct translation in top N translations
total number of OOV terms to be translated
R − Precision(termi )
R translations
=
T
ecision(termi )
</figure>
<figureCaption confidence="0.445686">
total number of OOV terms to be translated
</figureCaption>
<bodyText confidence="0.999971666666667">
where T denotes the number of testing entities.
The first one is a measurement for translation
and the others are used for ranking measurement.
</bodyText>
<subsectionHeader confidence="0.995772">
5.3 Experiment on Parameter Setting
</subsectionHeader>
<bodyText confidence="0.994644">
Frequency and length are two crucial features for
translation candidates. To get the most related
terms into top 10 before the final ranking, a pre-
rank testing is performed based on S-Rank, R-
Rank and D-Rank. It can be seen from Figure 2
that the pre-rank by D-Rank exhibits better per-
formance in translation experiment.
</bodyText>
<figureCaption confidence="0.9890955">
Figure 2. The impact of different Pre-Rank man-
ners on English-Chinese OOV translation.
</figureCaption>
<bodyText confidence="0.99528575">
In search results, for some English OOV terms
such as “BYOB(自RX水)”, there are few candi-
dates with better quality in top 20 snippets.
Therefore, in order to find how many snippets
are suitable in translation, the experiment on
snippet number is performed. It can be observed
from Figure 3 that the best performance can be
obtained by utilizing 200 snippets.
</bodyText>
<figureCaption confidence="0.940474">
Figure 3. The impact of different snippet number
on English-Chinese OOV translation.
</figureCaption>
<subsectionHeader confidence="0.7886905">
5.4 Experiment On English-Chinese Bi-
Directional OOV Translation
</subsectionHeader>
<bodyText confidence="0.9480545">
The experimental results on 300 English new
terms are shown in Table 1.
</bodyText>
<table confidence="0.994635857142857">
N-Inclusion-Rate English-Chinese OOV
Translation
Top-1 0.313
Top-3 0.587
Top-5 0.627
Top-7 0.707
Top-9 0.763
</table>
<tableCaption confidence="0.995171">
Table 1. The experimental results on English-
Chinese OOV translation.
</tableCaption>
<bodyText confidence="0.9244185">
The experimental results on 300 Chinese
named entities are shown in Table 2.
</bodyText>
<table confidence="0.999602857142857">
N-Inclusion- Person Location Organization
Rate Name Name Name
Top-1 0.210 0.510 0.110
Top-3 0.390 0.800 0.280
Top-5 0.490 0.900 0.400
Top-7 0.530 0.920 0.480
Top-9 0.540 0.930 0.630
</table>
<tableCaption confidence="0.971418">
Table 2. The experimental results on Chinese-
English OOV translation.
</tableCaption>
<bodyText confidence="0.999838714285714">
It can be observed from Table 2 that the per-
formance of Chinese location name translation is
much higher than the other two categories. This
is because most of the location names are famous
cities or countries. The experimental results
above demonstrate that the proposed model can
be applicable in all kinds of OOV terms.
</bodyText>
<subsectionHeader confidence="0.995445">
5.5 Experiment on Ranking
</subsectionHeader>
<bodyText confidence="0.877232857142857">
In SVM-based and Ranking-SVM-based ranking
experiment, the statistics on training data are
shown in Table 3. For SVM training data, the
“Related” candidates are neglected. The experi-
mental results on ranking in English-Chinese and
Chinese-English OOV translation are shown in
Table 4 and 5 respectively.
</bodyText>
<table confidence="0.998762666666667">
Number of Correct Related Indifferent
Candidates
English- 234 141 250
Chinese
Chinese- 240 144 373
English
</table>
<tableCaption confidence="0.992969">
Table 3. Statistics of training data for ranking.
</tableCaption>
<table confidence="0.999809166666667">
English- Top-1 Top-3 R-
Chinese Inclusion Inclusion Precision
D-Rank 0.313 0.587 0.417
T-Rank 0.217 0.430 0.217
SVM 0.530 0.687 0.533
Ranking-SVM 0.550 0.687 0.547
</table>
<tableCaption confidence="0.9695535">
Table 4. The experimental results on ranking in
English-Chinese OOV translation.
</tableCaption>
<figure confidence="0.869773222222222">
R
=
number of correct translations for term to be translated
i
− Precision
number of correct transaltion in top
Pr
Y=R−
i1
</figure>
<page confidence="0.897008">
131
</page>
<table confidence="0.999702">
Chinese- Top-1 Top-3 R-
English Inclusion Inclusion Precision
TF-Rank 0.277 0.490 0.287
T-Rank 0.197 0.387 0.207
SVM 0.347 0.587 0.347
Ranking-SVM 0.357 0.613 0.387
</table>
<tableCaption confidence="0.9868245">
Table 5. The experimental results on ranking in
Chinese-English OOV translation.
</tableCaption>
<bodyText confidence="0.999656666666667">
From the experiments above, it can be con-
cluded that the supervised learning significantly
outperform the conventional ranking strategies.
</bodyText>
<subsectionHeader confidence="0.994263">
5.6 Analysis and Discussion
</subsectionHeader>
<bodyText confidence="0.980878382352941">
Through analysis about the experimental results
in extraction and ranking, it can be observed that
the OOV translation quality is highly related to
the following aspects.
(1) The translation results are related to the
search engine used, especially for some spe-
cific OOV terms. For example, given a query
OOV term “两岸三通”, the mining result
based on Google in China is “three direct
links”, while some meaningless information
is mined by the other engines like Live Trans.
(2) Some terms are conventional terminologies
and cannot be translated literally. For exam-
ple, “woman pace-setter”, a proper name with
the particular Chinese characteristic, should
be translated into “三八红旗手”, rather than
“女子的步伐” or “制定”.
(3) The proposed model is sensitive to the nota-
bility degree of OOV term. For famous per-
son name and book title, the translation per-
formance is very promising. However, for
other OOV terms with lower notability, such
as “YA尔曼来” and “兰红光”, the correct
translation cannot even be retrieved by
search engine.
(4) Word Sense Disambiguation (WSD) should
be added to improve the whole translation
performance. Although most of OOVs have
unique semantic definition, there are still a
few OOVs with ambiguity. For example,
“Rice” can either be a person name or a kind
of food. Another example is “AARP”, which
also has two kinds of meaning, that is, “美Q
退休者协会” and “地址解析协议”.
</bodyText>
<sectionHeader confidence="0.998963" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999963153846154">
In this paper, the proposed model improves the
acquirement ability for OOV translation through
Web mining and solves the translation pair eval-
uation problem in a novel way by introducing
supervised learning in translation ranking. In ad-
dition, it is very significant to apply the key
techniques in traditional machine translation into
OOV translation, such as OOV recognition, sta-
tistical machine learning, alignment of sentence
and phoneme, and WSD. The merits of these
techniques should be integrated. All these as-
pects above will become the research focus in
our future work.
</bodyText>
<sectionHeader confidence="0.998762" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.609744833333333">
This paper is supported by National Natural
Science Foundation of China (No. 60773124),
National Science and Technology Pillar Program
of China (No. 2007BAH09B03) and Shanghai
Municipal R&amp;D Foundation (No. 08dz1500109).
Yang Wang is the corresponding author.
</bodyText>
<sectionHeader confidence="0.965353" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999757972222222">
Chun-Jen Lee, Jason S. Chang, and Jyh-Shing R. Jang.
2006. Alignment of Bilingual Named Entities in
Parallel Corpora Using Statistical Models and
Multiple Knowledge Sources. ACM Transactions
on Asian Language Processing, 5(2):121-145.
Gaolin Fang, Hao Yu, and Fumihito Nishino. 2006.
Chinese-English Term Translation Mining Based
on Semantic Prediction. In Proceedings of the
COLING/ACL on Main Conference Poster Ses-
sions, pp.199-206.
Jenq-Haur Wang, Jei-Wen Teng, Pu-Jen Cheng, Wen-
Hsiang Lu, and Lee-Feng Chien. 2004. Translating
Unknown Cross-Lingual Queries in Digital Libra-
ries Using a Web-based Approach. In Proceedings
of the 4th ACM/IEEE-CS Joint Conference on Dig-
ital Libraries, pp.108-116.
Jian-Cheng Wu and Jason S. Chang. 2007. Learning
to Find English to Chinese Transliterations on the
Web. In Proceedings of the 2007 Joint Conference
on Empirical Methods in Natural Language
Processing and Computational Natural Language
Learning, pp.996-1004.
L. F. Chien. 1997. PAT-Tree-Based Keyword Extrac-
tion for Chinese Information Retrieval. In Proceed-
ings of SIGIR’97, pp.50-58.
Wen-Hsiang Lu and Lee-Feng Chien. 2004. Anchor
Text Mining for Translation of Web Queries: A
Transitive Translation Approach. ACM Transac-
tions on Information Systems, 22(2): 242-269.
Ying Zhang and Phil Vines. 2004. Detection and
Translation of OOV Terms Prior to Query Time. In
Proceedings of SIGIR’04, pp.524-525.
Yunbo Cao, Jun Xu, Tie-Yan LIU, Hang Li, Yalou
HUANG, and Hsiao-Wuen HON. 2006. Adapting
Ranking SVM to Document Retrieval. In Proceed-
ings of SIGIR’06, pp.186-193.
</reference>
<page confidence="0.997726">
132
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.595633">
<title confidence="0.9993425">English-Chinese Bi-Directional OOV Translation based on Web Mining and Supervised Learning</title>
<author confidence="0.990953">Yuejie Zhang</author>
<author confidence="0.990953">Yang Wang</author>
<author confidence="0.990953">Xiangyang Xue</author>
<affiliation confidence="0.936948">School of Computer Science Shanghai Key Laboratory of Intelligent Information Processing</affiliation>
<address confidence="0.807688">Fudan University, Shanghai 200433, P.R. China</address>
<email confidence="0.905144">yjzhang@fudan.edu.cn</email>
<email confidence="0.905144">072021176@fudan.edu.cn</email>
<email confidence="0.905144">xyxue@fudan.edu.cn</email>
<abstract confidence="0.9952366">In Cross-Language Information Retrieval (CLIR), Out-of-Vocabulary (OOV) detection and translation pair relevance evaluation still remain as key problems. In this paper, an English-Chinese Bi-Directional OOV translation model is presented, which utilizes Web mining as the corpus source to collect translation pairs and combines supervised learning to evaluate their association degree. The experimental results show that the proposed model can successfully filter the most possible translation candidate with the lower computational cost, and improve the OOV translation ranking effect, especially for popular new words.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Chun-Jen Lee</author>
<author>Jason S Chang</author>
<author>Jyh-Shing R Jang</author>
</authors>
<title>Alignment of Bilingual Named Entities in Parallel Corpora Using Statistical Models and Multiple Knowledge Sources.</title>
<date>2006</date>
<journal>ACM Transactions on Asian Language Processing,</journal>
<pages>5--2</pages>
<marker>Lee, Chang, Jang, 2006</marker>
<rawString>Chun-Jen Lee, Jason S. Chang, and Jyh-Shing R. Jang. 2006. Alignment of Bilingual Named Entities in Parallel Corpora Using Statistical Models and Multiple Knowledge Sources. ACM Transactions on Asian Language Processing, 5(2):121-145.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gaolin Fang</author>
<author>Hao Yu</author>
<author>Fumihito Nishino</author>
</authors>
<title>Chinese-English Term Translation Mining Based on Semantic Prediction.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL on Main Conference Poster Sessions,</booktitle>
<pages>199--206</pages>
<marker>Fang, Yu, Nishino, 2006</marker>
<rawString>Gaolin Fang, Hao Yu, and Fumihito Nishino. 2006. Chinese-English Term Translation Mining Based on Semantic Prediction. In Proceedings of the COLING/ACL on Main Conference Poster Sessions, pp.199-206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenq-Haur Wang</author>
<author>Jei-Wen Teng</author>
<author>Pu-Jen Cheng</author>
<author>WenHsiang Lu</author>
<author>Lee-Feng Chien</author>
</authors>
<title>Translating Unknown Cross-Lingual Queries in Digital Libraries Using a Web-based Approach.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th ACM/IEEE-CS Joint Conference on Digital Libraries,</booktitle>
<pages>108--116</pages>
<marker>Wang, Teng, Cheng, Lu, Chien, 2004</marker>
<rawString>Jenq-Haur Wang, Jei-Wen Teng, Pu-Jen Cheng, WenHsiang Lu, and Lee-Feng Chien. 2004. Translating Unknown Cross-Lingual Queries in Digital Libraries Using a Web-based Approach. In Proceedings of the 4th ACM/IEEE-CS Joint Conference on Digital Libraries, pp.108-116.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jian-Cheng Wu</author>
<author>Jason S Chang</author>
</authors>
<title>Learning to Find English to Chinese Transliterations on the Web.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>996--1004</pages>
<marker>Wu, Chang, 2007</marker>
<rawString>Jian-Cheng Wu and Jason S. Chang. 2007. Learning to Find English to Chinese Transliterations on the Web. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pp.996-1004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L F Chien</author>
</authors>
<title>PAT-Tree-Based Keyword Extraction for Chinese Information Retrieval.</title>
<date>1997</date>
<booktitle>In Proceedings of SIGIR’97,</booktitle>
<pages>50--58</pages>
<contexts>
<context position="3117" citStr="Chien, 1997" startWordPosition="467" endWordPosition="468">se search engines, such as Google, Altavista or Yahoo. Therefore, many OOV translation models based on Web mining are proposed by researchers (Fang, 2006; Wu, 2007). By introducing supervised learning mechanism, the relevance between original OOV term and extracted candidate translation can be accurately evaluated. Meanwhile, the model proposed exhibits better applicability and can also be applied in processing OOVs with different classes. 3 Chinese OOV Extraction based on PAT-Tree For a language that has no words boundary like Chinese, PAT-Tree data structure is adopted to extract OOV terms (Chien, 1997). The most outstanding property of this structure is its Semi Infinite String, which can store all the semistrings of whole corpus in a binary tree. In this tree, branch nodes indicate direction of search 129 Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 129–132, Suntec, Singapore, 4 August 2009. c�2009 ACL and AFNLP and child nodes store information about index and frequency of semi infinite strings. With common strings being extracted, large amounts of noisy terms and fragments are also extracted. For example, when searching for the translation of English abbreviation ter</context>
</contexts>
<marker>Chien, 1997</marker>
<rawString>L. F. Chien. 1997. PAT-Tree-Based Keyword Extraction for Chinese Information Retrieval. In Proceedings of SIGIR’97, pp.50-58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wen-Hsiang Lu</author>
<author>Lee-Feng Chien</author>
</authors>
<title>Anchor Text Mining for Translation of Web Queries: A Transitive Translation Approach.</title>
<date>2004</date>
<journal>ACM Transactions on Information Systems,</journal>
<volume>22</volume>
<issue>2</issue>
<pages>242--269</pages>
<marker>Lu, Chien, 2004</marker>
<rawString>Wen-Hsiang Lu and Lee-Feng Chien. 2004. Anchor Text Mining for Translation of Web Queries: A Transitive Translation Approach. ACM Transactions on Information Systems, 22(2): 242-269.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ying Zhang</author>
<author>Phil Vines</author>
</authors>
<title>Detection and Translation of OOV Terms Prior to Query Time.</title>
<date>2004</date>
<booktitle>In Proceedings of SIGIR’04,</booktitle>
<pages>524--525</pages>
<marker>Zhang, Vines, 2004</marker>
<rawString>Ying Zhang and Phil Vines. 2004. Detection and Translation of OOV Terms Prior to Query Time. In Proceedings of SIGIR’04, pp.524-525.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yunbo Cao</author>
<author>Jun Xu</author>
<author>Tie-Yan LIU</author>
<author>Hang Li</author>
<author>Yalou HUANG</author>
<author>Hsiao-Wuen HON</author>
</authors>
<title>Adapting Ranking SVM to Document Retrieval.</title>
<date>2006</date>
<booktitle>In Proceedings of SIGIR’06,</booktitle>
<pages>186--193</pages>
<marker>Cao, Xu, LIU, Li, HUANG, HON, 2006</marker>
<rawString>Yunbo Cao, Jun Xu, Tie-Yan LIU, Hang Li, Yalou HUANG, and Hsiao-Wuen HON. 2006. Adapting Ranking SVM to Document Retrieval. In Proceedings of SIGIR’06, pp.186-193.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>