<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000151">
<title confidence="0.990072">
Multimodal Menu-based Dialogue with Speech Cursor in DICO II+
</title>
<author confidence="0.99399">
Staffan Larsson
</author>
<affiliation confidence="0.8918125">
University of Gothenburg
Sweden
</affiliation>
<email confidence="0.9841">
sl@ling.gu.se
</email>
<author confidence="0.768897">
Alexander Berman
</author>
<affiliation confidence="0.541004">
Talkamatic AB
Sweden
</affiliation>
<email confidence="0.976836">
alex@talkamatic.se
</email>
<author confidence="0.993235">
Jessica Villing
</author>
<affiliation confidence="0.891126">
University of Gothenburg
Sweden
</affiliation>
<email confidence="0.990173">
jessica@ling.gu.se
</email>
<sectionHeader confidence="0.993639" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9995495">
This paper describes Dico II+, an in-vehicle
dialogue system demonstrating a novel com-
bination of flexible multimodal menu-based
dialogueand a “speech cursor” which enables
menu navigation as well as browsing long list
using haptic input and spoken output.
</bodyText>
<sectionHeader confidence="0.998798" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99997512">
Dico is a multimodal in-car dialogue system appli-
cation, originally developed in the DICO (with cap-
ital letters) project by Volvo Technology AB and
the University of Gothenburg. Dico is built on top
of the GoDiS dialogue system platform (Larsson,
2002), which in turn is implemented using TrindiKit
(Traum and Larsson, 2003).
The main goal of the original Dico application
(Olsson and Villing, 2005), (Villing and Larsson,
2006) was to develop an interface that is less dis-
tracting for the driver, and thus both safer and easier
to use than existing interfaces. (Larsson and Villing,
2009) described the Dico II system resulting from
work in the DICO project. Since then, the Dico
demonstrator has been further developed.
In this paper, we describe the Dico II+ demon-
strator which introduces a novel combination of
flexible Multimodal Menu-Based Dialogue and a
Speech Cursor which together enable flexible multi-
modal interaction without the need for looking at the
screen. In the following, we will first argue for the
usefulness of in-vehicle dialogue systems. We will
then briefly present the GoDiS platform which Dico
II+ is based on, as well as some aspects of flexible
dialogue enabled by the GoDiS dialogue manager.
</bodyText>
<sectionHeader confidence="0.931373" genericHeader="introduction">
2 In-vehicle dialogue systems
</sectionHeader>
<bodyText confidence="0.9998354">
Voice interaction is a very natural means of com-
munication for humans, and enabling spoken inter-
action with technologies may thus make it easier
and less cognitively demanding for people to in-
teract with machines. However, this requires that
the spoken interaction is similar to ordinary spoken
human-human dialogue. A problem with available
in-vehicle voice control technologies is that they are
not flexible enough in terms of the interaction strate-
gies and modalities offered to the user.
</bodyText>
<sectionHeader confidence="0.99372" genericHeader="method">
3 GoDiS features in Dico
</sectionHeader>
<bodyText confidence="0.9998753">
GoDiS (Larsson, 2002) is an experimental di-
alogue system implementing a theory of Issue-
Based Dialogue Management based on Ginzburg’s
concept of Questions Under Discussion (QUD).
GoDiS is implemented using the TrindiKit, a toolkit
for implementing dialogue move engines and dia-
logue systems based on the Information State ap-
proach (Traum and Larsson, 2003). GoDiS has
been adapted to several different dialogue types, do-
mains, and languages, including menu-based mul-
timodal dialogue when acting as an interface to an
mp3 player (Hjelm et al., 2005).
The GoDiS dialogue manager allows the user
to interact more flexibly and naturally with menu-
based interfaces to devices. General dialogue man-
agement issues such as accommodation, task switch-
ing and grounding are handled by the application-
independent dialogue manager. Re-using these tech-
nologies in new applications enables rapid prototyp-
ing of advanced dialogue applications.
</bodyText>
<page confidence="0.953955">
92
</page>
<note confidence="0.361654">
Proceedings of the ACL-HLT 2011 System Demonstrations, pages 92–96,
Portland, Oregon, USA, 21 June 2011. c�2011 Association for Computational Linguistics
</note>
<subsectionHeader confidence="0.998591">
3.1 Accommodation
</subsectionHeader>
<bodyText confidence="0.999938777777778">
The applications in Dico II+ are based on exist-
ing menu interfaces, using a method for converting
menus into dialogue plans (see below). While it is
possible for the novice user to let the system take
initiative and guide the user through the menus step-
by-step, expert users might prefer to use accommo-
dation strategies enabling the user to skip through
the menus and getting right to the point. Two exam-
ples are shown below.
</bodyText>
<sectionHeader confidence="0.685251" genericHeader="method">
Ex. 1:
</sectionHeader>
<bodyText confidence="0.73744175">
S: “What do you want to do? Go to the
phonebook, manage settings, or...”
U: “Call Lisa’s home number”
S: “OK. Calling Lisa’s home number.”
</bodyText>
<sectionHeader confidence="0.673189" genericHeader="method">
Ex. 2:
</sectionHeader>
<bodyText confidence="0.900016">
U: “Lisa’s home number”
S: “OK. Do you want to change the num-
ber or make a call?”
U: “Make a call.”
S: “OK. Calling Lisa’s home number.”
</bodyText>
<subsectionHeader confidence="0.992901">
3.2 Multiple simultaneous tasks and task
switching
</subsectionHeader>
<bodyText confidence="0.999636142857143">
GoDiS enables arbitrarily nested subdialogues. It
is possible to start one dialogue to perform a task,
and then start a subdialogue before the first task is
completed. When the second task is completed the
system automatically returns to the first task, and ex-
plicitly signals this. This gives the user freedom to
switch task at any time:
</bodyText>
<sectionHeader confidence="0.556464" genericHeader="method">
Ex. 3:
</sectionHeader>
<bodyText confidence="0.951488357142857">
U: “Change Lisa’s home number.”
S: “Okay. Let’s see. What phone number
do you want instead?”
U: “Check my messages.”
S: “You have got this message. Hi!
I have got a new home number, it is
(031)234567. Best regards, Lisa.”
S: “Returning to change an entry. What
phone number do you want instead?”
U: “oh three one twentythree fourtyfive
sixtyseven.”
U: “Okay. Changing Lisa’s home num-
ber to oh three one two three four five six
seven.”
</bodyText>
<subsectionHeader confidence="0.998918">
3.3 Feedback and grounding
</subsectionHeader>
<bodyText confidence="0.999804266666667">
The GoDiS dialogue manager provides general feed-
back strategies to make sure that the dialogue part-
ners have contact, that the system can can hear what
the user says, understands the words that are spoken
(semantic understanding), understands the meaning
of the utterance (pragmatic understanding) and ac-
cepts the dialogue moves performed in utterances.
As an example, the single user utterance “Lisa”
may result in positive feedback on the semantic level
but negative on the pragmatic, resulting in a system
utterance consisting of two feedback moves and a
clarification question: “Lisa. I don’t quite under-
stand. Do you want to make a call, change an entry
in the phonebook, or delete an entry from the phone-
book?”
</bodyText>
<sectionHeader confidence="0.991238" genericHeader="method">
4 Multimodal menu-based dialogue
</sectionHeader>
<bodyText confidence="0.999929782608696">
Dico II+ implemented a concept of Multimodal
Menu-based Dialogue (MMD). Technologies for
MMD in menu-based applications have already been
developed for other GoDiS applications (Hjelm et
al., 2005) and the ideas behind these solutions were
re-implemented and significantly improved in Dico.
A common argument for using spoken interaction
in a car context is that the driver should be able to
use a system without looking at a screen. However,
there are many situations where current technology
requires the user to look at a screen at some point
in the interaction. The idea behind MMD is that the
user should be able to switch between and combine
modalities freely across and within utterances. This
makes it possible to use the system using speech
only, using traditional GUI interaction only, or us-
ing a combination of the two.
MMD enables integrated multimodality for user
input, meaning that a single contribution can use
several input modalities, e.g. “Call this contact
[click]” where the [click] symbolises haptic input
(e.g. a mouse click) which in this case selects a spe-
cific contact. For output, MMD uses parallel mul-
</bodyText>
<page confidence="0.99456">
93
</page>
<bodyText confidence="0.999951047619048">
timodality, i.e., output is generally rendered both
as speech and as GUI output. To use speech only,
the user can merely ignore the graphical output and
not use the haptic input device. To enable interac-
tion using GUI only, speech input and output can be
turned on or off using a button which toggles be-
tween “speech on” and “speech off” mode.
The GUI used in Dico II+ is a generic graphi-
cal interface for the GoDiS system, developed by
Talkamatic AB with graphical adaptations for Dico.
It represents GoDiS dialogue moves graphically as
menus using a refined version of the conversion
schema presented in (Larsson et al., 2001) . For
example, alternative questions are represented as
multiple choice menus, and wh-questions are rep-
resented as scrollable lists. Conversely, haptic user
input from the GUI is interpreted as dialogue moves.
Selecting an action in a multiple-choice menu cor-
responds to making a request move, and selecting
an item in a scrollable list corresponds to an answer
move.
</bodyText>
<sectionHeader confidence="0.980517" genericHeader="method">
5 Speech Cursor
</sectionHeader>
<bodyText confidence="0.99999225">
This section describes an important addition to the
GoDiS dialogue manager and Dico demonstrator,
which enables the user to use spoken interaction in
combination with haptic input to access all func-
tionality (including browsing long lists) without ever
having to look at the screen. In combination with
the flexible dialogue capabilities of the GoDiS dia-
logue manager, and the concept of MMD, we believe
that a Speech Cursor provides a powerful and user-
friendly way of interacting with menu-based inter-
faces in cognitively demanding environments such
as the in-vehicle environment.
</bodyText>
<subsectionHeader confidence="0.996536">
5.1 The problem
</subsectionHeader>
<bodyText confidence="0.999985844444445">
A common argument for using spoken interaction
in a car context is that the driver should be able to
use a system without looking at a screen. However,
there are many situations where current technology
requires the user to look at a screen at some point
in the interaction. This was true also for Dico II
in the case of browsing lists; for example, to find
out which contacts were listed in the phonebook, the
user would at some point have to look at the screen.
Imagine that the user wants to select a song from
a song database, and that the user has made restric-
tions filtering out 30 songs from the database. The
dialogue system asks the user which of the songs she
wants to hear displaying them in a list on the screen.
The user must now either look at the screen and
use a scroll-wheel or similar to select a song, or look
at the screen to see which songs are available, and
then speak the proper song title. This means that
part of the point of using spoken interaction in the
car is lost. The example discusses car use, but is
applicable any time when the user cannot or does
not want to look at a screen, for instance when using
a cellphone walking in a city, or when using a web
application on a portable device.
An existing interaction strategy for addressing the
problems of browsing lists is to allow a kind of meta-
dialogue, where the system verbally presents a num-
ber of items (for instance 5) from the list, then asking
the user if she or he would like to hear the subse-
quent 5 items, until the list has been read in its en-
tirety or until the users responds negatively. While
this strategy in principle solves the problem, it is
rather time-consuming compared to browsing the
list using a screen and a haptic input device (such
as a scroll-wheel); this may decrease the perceived
usability of the voice interface in comparison with
traditional GUI-based interaction.
Some existing voice interaction systems use a
technology to establish understanding which con-
sists of displaying the top N best recognition hy-
potheses to the user, each one associated with a num-
ber, together with a verbal request to the user to
say the number corresponding to the desired result.
This situation, however, requires the user to look at
a screen, and is arguably quite unnatural.
</bodyText>
<subsectionHeader confidence="0.999526">
5.2 The solution: Speech Cursor
</subsectionHeader>
<bodyText confidence="0.999840909090909">
Dico II+ requires a haptic menu navigation de-
vice, such as a mouse (trackball, touch pad,
TrackPointTM) with buttons, pointers and drivers,
keyboard with arrow keys, or jog dial/shuttle wheel.
A typical in-vehicle menu navigation device consists
of three or four buttons (UP, DOWN, OK and possi-
ble BACK).
Every time a new item gets focus, the system
reads out a voice icon - a spoken representation of
the item. This representation can be textual, in-
tended to be realised using a TTS, or in the form
</bodyText>
<page confidence="0.998526">
94
</page>
<bodyText confidence="0.99995775">
of audio data, to be played directly. Every time a
new element gets focus, all any ongoing voice out-
put is interrupted by the voice icon for the element
in focus.
</bodyText>
<sectionHeader confidence="0.8273235" genericHeader="method">
6 Combining flexible dialogue and Speech
Cursor
</sectionHeader>
<bodyText confidence="0.999932857142857">
Combining flexible dialogue processing with the
Speech Cursor concept1 enables interaction where
the user may freely choose between using domain-
level spoken utterances (requests, confirmations,
questions, answers etc.) and using the Speech Cur-
sor. This is an improvement over existing technol-
ogy in that it offers a greater variety of interaction
styles which can be freely chosen and combined by
the user, as well as offering flexible dialogue inter-
action. Specifically, it provides flexible spoken dia-
logue interaction in combination with user-friendly
browsing of long lists without the need for looking
at the screen.
Here is a walk-through of a sample interaction:
</bodyText>
<sectionHeader confidence="0.803962" genericHeader="method">
Ex. 4:
</sectionHeader>
<bodyText confidence="0.896623285714286">
U: “I want to listen to Madonna”(This ut-
terance uses accommodation to allow the
user to supply unrequested information)
S: “There are 3 songs by Madonna. What
song do you want?” (Showing list of all
songs by Madonna: ’Like a Prayer’, ’La
Isla Bonita’, ’Music’, ...)
</bodyText>
<figure confidence="0.896194636363636">
U: [DOWN]
S: “Like a Prayer from the album Like a
Prayer” (“Like a Prayer” is highlighted)
U: [DOWN]
S: “La Isla Bonita from the album True
Blue” (“La Isla Bonita” is highlighted)
U: [DOWN]
S: “Music from the alb+” (“Music” is
highlighted)
U: [UP]
S: “Like a Prayer”
</figure>
<footnote confidence="0.8453525">
1The combination of a (simple or flexible) spoken dialogue
system and the voice cursor technology is patent pending.
</footnote>
<bodyText confidence="0.930346">
U: [OK]
S: “OK, playing Like a Prayer.”
Here is a further example:
</bodyText>
<sectionHeader confidence="0.763869" genericHeader="conclusions">
Ex. 5:
</sectionHeader>
<bodyText confidence="0.918136357142857">
U: “I want to add an ABBA song”
S: “What album?” (Shows ”Waterloo”
and ”Arrival)
U: [DOWN]
S: “Wat...”
U: [DOWN]
S: “Arrival”
U: [OK]
S: “what song?” (Shows “Mamma Mia”
and “Money Money Money”)
U: “Mamma Mia”
A promotional demo film showing interactions
similar to the above is available2, courtesy of Talka-
matic AB.
</bodyText>
<sectionHeader confidence="0.997639" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9995143">
The work reported here was funded DICO, Vinnova
project P28536-1. Additional funding was provided
by Talkamatic AB, and by CLT, the Centre of Lan-
guage Technology at the University of Gothenburg.
Dico II+ was implemented by the authors, Fredrik
Kronlid, Peter Ljungl¨of and Andreas Wiberg. The
authors gratefully acknowledge the assistance of
Volvo Technology AB and the DICO project group.
The GoDiS system is the property of Talkamatic
AB.
</bodyText>
<sectionHeader confidence="0.999458" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999196333333333">
David Hjelm, Ann-Charlotte Forslund, Staffan Larsson,
and Andreas Wallentin. 2005. DJ GoDiS: Multimodal
menu-based dialogue in an asychronous isu system. In
Claire Gardent and Bertrand Gaiffe, editors, Proceed-
ings of the ninth workshop on the semantics and prag-
matics of dialogue.
</reference>
<footnote confidence="0.688171">
2www.youtube.com/watch?v=yvLcQOeBAJE
</footnote>
<page confidence="0.992881">
95
</page>
<reference confidence="0.99889748">
Staffan Larsson and Jessica Villing. 2009. Multimodal
menu-based dialogue in dico ii. In Jens Edlund,
Joakim Gustafson, Anna Hjalmarsson, and Gabriel
Skantze, editors, Proceedings of DiaHolmia, 2009
Workshop on the Semantics and Pragmatics of Dia-
logue.
Staffan Larsson, Robin Cooper, and Stina Ericsson.
2001. menu2dialog. In Proceedings of the 2nd IJCAI
Workshop on Knowledge and Reasoning in Practical
Dialogue Systems, pages 41–45.
Staffan Larsson. 2002. Issue-based Dialogue Manage-
ment. Ph.D. thesis, G¨oteborg University.
Anna Olsson and Jessica Villing. 2005. Dico - a dialogue
system for a cell phone. Master’s thesis, Department
of Linguistics, Goteborg University.
David Traum and Staffan Larsson. 2003. The informa-
tion state approach to dialogue management. In Ron-
nie Smith and Jan Kuppevelt, editors, Current and New
Directions in Discourse &amp; Dialogue. Kluwer Aca-
demic Publishers.
Jessica Villing and Staffan Larsson. 2006. Dico - a mul-
timodal in-vehicle dialogue system. In D. Schlangen
and R. Fernandez, editors, Proceedings of the 10th
workshop on the semantics and pragmatics of dia-
logue.
</reference>
<page confidence="0.998359">
96
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.168385">
<title confidence="0.993978">Multimodal Menu-based Dialogue with Speech Cursor in DICO II+</title>
<author confidence="0.954029">Staffan</author>
<affiliation confidence="0.979876">University of</affiliation>
<abstract confidence="0.34641425">sl@ling.gu.se Alexander Talkamatic alex@talkamatic.se</abstract>
<author confidence="0.89234">Jessica</author>
<affiliation confidence="0.979102">University of</affiliation>
<email confidence="0.884197">jessica@ling.gu.se</email>
<abstract confidence="0.999399571428571">This paper describes Dico II+, an in-vehicle dialogue system demonstrating a novel combination of flexible multimodal menu-based dialogueand a “speech cursor” which enables menu navigation as well as browsing long list using haptic input and spoken output.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David Hjelm</author>
<author>Ann-Charlotte Forslund</author>
<author>Staffan Larsson</author>
<author>Andreas Wallentin</author>
</authors>
<title>DJ GoDiS: Multimodal menu-based dialogue in an asychronous isu system.</title>
<date>2005</date>
<booktitle>In Claire Gardent and Bertrand Gaiffe, editors, Proceedings of the ninth workshop on the</booktitle>
<contexts>
<context position="2845" citStr="Hjelm et al., 2005" startWordPosition="435" endWordPosition="438">strategies and modalities offered to the user. 3 GoDiS features in Dico GoDiS (Larsson, 2002) is an experimental dialogue system implementing a theory of IssueBased Dialogue Management based on Ginzburg’s concept of Questions Under Discussion (QUD). GoDiS is implemented using the TrindiKit, a toolkit for implementing dialogue move engines and dialogue systems based on the Information State approach (Traum and Larsson, 2003). GoDiS has been adapted to several different dialogue types, domains, and languages, including menu-based multimodal dialogue when acting as an interface to an mp3 player (Hjelm et al., 2005). The GoDiS dialogue manager allows the user to interact more flexibly and naturally with menubased interfaces to devices. General dialogue management issues such as accommodation, task switching and grounding are handled by the applicationindependent dialogue manager. Re-using these technologies in new applications enables rapid prototyping of advanced dialogue applications. 92 Proceedings of the ACL-HLT 2011 System Demonstrations, pages 92–96, Portland, Oregon, USA, 21 June 2011. c�2011 Association for Computational Linguistics 3.1 Accommodation The applications in Dico II+ are based on exis</context>
<context position="5921" citStr="Hjelm et al., 2005" startWordPosition="941" endWordPosition="944"> performed in utterances. As an example, the single user utterance “Lisa” may result in positive feedback on the semantic level but negative on the pragmatic, resulting in a system utterance consisting of two feedback moves and a clarification question: “Lisa. I don’t quite understand. Do you want to make a call, change an entry in the phonebook, or delete an entry from the phonebook?” 4 Multimodal menu-based dialogue Dico II+ implemented a concept of Multimodal Menu-based Dialogue (MMD). Technologies for MMD in menu-based applications have already been developed for other GoDiS applications (Hjelm et al., 2005) and the ideas behind these solutions were re-implemented and significantly improved in Dico. A common argument for using spoken interaction in a car context is that the driver should be able to use a system without looking at a screen. However, there are many situations where current technology requires the user to look at a screen at some point in the interaction. The idea behind MMD is that the user should be able to switch between and combine modalities freely across and within utterances. This makes it possible to use the system using speech only, using traditional GUI interaction only, o</context>
</contexts>
<marker>Hjelm, Forslund, Larsson, Wallentin, 2005</marker>
<rawString>David Hjelm, Ann-Charlotte Forslund, Staffan Larsson, and Andreas Wallentin. 2005. DJ GoDiS: Multimodal menu-based dialogue in an asychronous isu system. In Claire Gardent and Bertrand Gaiffe, editors, Proceedings of the ninth workshop on the semantics and pragmatics of dialogue.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Staffan Larsson</author>
<author>Jessica Villing</author>
</authors>
<title>Multimodal menu-based dialogue in dico ii.</title>
<date>2009</date>
<booktitle>Proceedings of DiaHolmia, 2009 Workshop on the Semantics and Pragmatics of Dialogue.</booktitle>
<editor>In Jens Edlund, Joakim Gustafson, Anna Hjalmarsson, and Gabriel Skantze, editors,</editor>
<contexts>
<context position="1118" citStr="Larsson and Villing, 2009" startWordPosition="162" endWordPosition="165">ut and spoken output. 1 Introduction Dico is a multimodal in-car dialogue system application, originally developed in the DICO (with capital letters) project by Volvo Technology AB and the University of Gothenburg. Dico is built on top of the GoDiS dialogue system platform (Larsson, 2002), which in turn is implemented using TrindiKit (Traum and Larsson, 2003). The main goal of the original Dico application (Olsson and Villing, 2005), (Villing and Larsson, 2006) was to develop an interface that is less distracting for the driver, and thus both safer and easier to use than existing interfaces. (Larsson and Villing, 2009) described the Dico II system resulting from work in the DICO project. Since then, the Dico demonstrator has been further developed. In this paper, we describe the Dico II+ demonstrator which introduces a novel combination of flexible Multimodal Menu-Based Dialogue and a Speech Cursor which together enable flexible multimodal interaction without the need for looking at the screen. In the following, we will first argue for the usefulness of in-vehicle dialogue systems. We will then briefly present the GoDiS platform which Dico II+ is based on, as well as some aspects of flexible dialogue enable</context>
</contexts>
<marker>Larsson, Villing, 2009</marker>
<rawString>Staffan Larsson and Jessica Villing. 2009. Multimodal menu-based dialogue in dico ii. In Jens Edlund, Joakim Gustafson, Anna Hjalmarsson, and Gabriel Skantze, editors, Proceedings of DiaHolmia, 2009 Workshop on the Semantics and Pragmatics of Dialogue.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Staffan Larsson</author>
<author>Robin Cooper</author>
<author>Stina Ericsson</author>
</authors>
<date>2001</date>
<booktitle>menu2dialog. In Proceedings of the 2nd IJCAI Workshop on Knowledge and Reasoning in Practical Dialogue Systems,</booktitle>
<pages>41--45</pages>
<contexts>
<context position="7484" citStr="Larsson et al., 2001" startWordPosition="1206" endWordPosition="1209">ity, i.e., output is generally rendered both as speech and as GUI output. To use speech only, the user can merely ignore the graphical output and not use the haptic input device. To enable interaction using GUI only, speech input and output can be turned on or off using a button which toggles between “speech on” and “speech off” mode. The GUI used in Dico II+ is a generic graphical interface for the GoDiS system, developed by Talkamatic AB with graphical adaptations for Dico. It represents GoDiS dialogue moves graphically as menus using a refined version of the conversion schema presented in (Larsson et al., 2001) . For example, alternative questions are represented as multiple choice menus, and wh-questions are represented as scrollable lists. Conversely, haptic user input from the GUI is interpreted as dialogue moves. Selecting an action in a multiple-choice menu corresponds to making a request move, and selecting an item in a scrollable list corresponds to an answer move. 5 Speech Cursor This section describes an important addition to the GoDiS dialogue manager and Dico demonstrator, which enables the user to use spoken interaction in combination with haptic input to access all functionality (includ</context>
</contexts>
<marker>Larsson, Cooper, Ericsson, 2001</marker>
<rawString>Staffan Larsson, Robin Cooper, and Stina Ericsson. 2001. menu2dialog. In Proceedings of the 2nd IJCAI Workshop on Knowledge and Reasoning in Practical Dialogue Systems, pages 41–45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Staffan Larsson</author>
</authors>
<title>Issue-based Dialogue Management.</title>
<date>2002</date>
<tech>Ph.D. thesis,</tech>
<institution>G¨oteborg University.</institution>
<contexts>
<context position="781" citStr="Larsson, 2002" startWordPosition="109" endWordPosition="110">talkamatic.se Jessica Villing University of Gothenburg Sweden jessica@ling.gu.se Abstract This paper describes Dico II+, an in-vehicle dialogue system demonstrating a novel combination of flexible multimodal menu-based dialogueand a “speech cursor” which enables menu navigation as well as browsing long list using haptic input and spoken output. 1 Introduction Dico is a multimodal in-car dialogue system application, originally developed in the DICO (with capital letters) project by Volvo Technology AB and the University of Gothenburg. Dico is built on top of the GoDiS dialogue system platform (Larsson, 2002), which in turn is implemented using TrindiKit (Traum and Larsson, 2003). The main goal of the original Dico application (Olsson and Villing, 2005), (Villing and Larsson, 2006) was to develop an interface that is less distracting for the driver, and thus both safer and easier to use than existing interfaces. (Larsson and Villing, 2009) described the Dico II system resulting from work in the DICO project. Since then, the Dico demonstrator has been further developed. In this paper, we describe the Dico II+ demonstrator which introduces a novel combination of flexible Multimodal Menu-Based Dialog</context>
<context position="2319" citStr="Larsson, 2002" startWordPosition="355" endWordPosition="356">alogue enabled by the GoDiS dialogue manager. 2 In-vehicle dialogue systems Voice interaction is a very natural means of communication for humans, and enabling spoken interaction with technologies may thus make it easier and less cognitively demanding for people to interact with machines. However, this requires that the spoken interaction is similar to ordinary spoken human-human dialogue. A problem with available in-vehicle voice control technologies is that they are not flexible enough in terms of the interaction strategies and modalities offered to the user. 3 GoDiS features in Dico GoDiS (Larsson, 2002) is an experimental dialogue system implementing a theory of IssueBased Dialogue Management based on Ginzburg’s concept of Questions Under Discussion (QUD). GoDiS is implemented using the TrindiKit, a toolkit for implementing dialogue move engines and dialogue systems based on the Information State approach (Traum and Larsson, 2003). GoDiS has been adapted to several different dialogue types, domains, and languages, including menu-based multimodal dialogue when acting as an interface to an mp3 player (Hjelm et al., 2005). The GoDiS dialogue manager allows the user to interact more flexibly and</context>
</contexts>
<marker>Larsson, 2002</marker>
<rawString>Staffan Larsson. 2002. Issue-based Dialogue Management. Ph.D. thesis, G¨oteborg University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna Olsson</author>
<author>Jessica Villing</author>
</authors>
<title>Dico - a dialogue system for a cell phone.</title>
<date>2005</date>
<tech>Master’s thesis,</tech>
<institution>Department of Linguistics, Goteborg University.</institution>
<contexts>
<context position="928" citStr="Olsson and Villing, 2005" startWordPosition="130" endWordPosition="133">ialogue system demonstrating a novel combination of flexible multimodal menu-based dialogueand a “speech cursor” which enables menu navigation as well as browsing long list using haptic input and spoken output. 1 Introduction Dico is a multimodal in-car dialogue system application, originally developed in the DICO (with capital letters) project by Volvo Technology AB and the University of Gothenburg. Dico is built on top of the GoDiS dialogue system platform (Larsson, 2002), which in turn is implemented using TrindiKit (Traum and Larsson, 2003). The main goal of the original Dico application (Olsson and Villing, 2005), (Villing and Larsson, 2006) was to develop an interface that is less distracting for the driver, and thus both safer and easier to use than existing interfaces. (Larsson and Villing, 2009) described the Dico II system resulting from work in the DICO project. Since then, the Dico demonstrator has been further developed. In this paper, we describe the Dico II+ demonstrator which introduces a novel combination of flexible Multimodal Menu-Based Dialogue and a Speech Cursor which together enable flexible multimodal interaction without the need for looking at the screen. In the following, we will </context>
</contexts>
<marker>Olsson, Villing, 2005</marker>
<rawString>Anna Olsson and Jessica Villing. 2005. Dico - a dialogue system for a cell phone. Master’s thesis, Department of Linguistics, Goteborg University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Traum</author>
<author>Staffan Larsson</author>
</authors>
<title>The information state approach to dialogue management.</title>
<date>2003</date>
<booktitle>Current and New Directions in Discourse &amp; Dialogue.</booktitle>
<editor>In Ronnie Smith and Jan Kuppevelt, editors,</editor>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="853" citStr="Traum and Larsson, 2003" startWordPosition="118" endWordPosition="121">jessica@ling.gu.se Abstract This paper describes Dico II+, an in-vehicle dialogue system demonstrating a novel combination of flexible multimodal menu-based dialogueand a “speech cursor” which enables menu navigation as well as browsing long list using haptic input and spoken output. 1 Introduction Dico is a multimodal in-car dialogue system application, originally developed in the DICO (with capital letters) project by Volvo Technology AB and the University of Gothenburg. Dico is built on top of the GoDiS dialogue system platform (Larsson, 2002), which in turn is implemented using TrindiKit (Traum and Larsson, 2003). The main goal of the original Dico application (Olsson and Villing, 2005), (Villing and Larsson, 2006) was to develop an interface that is less distracting for the driver, and thus both safer and easier to use than existing interfaces. (Larsson and Villing, 2009) described the Dico II system resulting from work in the DICO project. Since then, the Dico demonstrator has been further developed. In this paper, we describe the Dico II+ demonstrator which introduces a novel combination of flexible Multimodal Menu-Based Dialogue and a Speech Cursor which together enable flexible multimodal interac</context>
<context position="2653" citStr="Traum and Larsson, 2003" startWordPosition="404" endWordPosition="407">oken interaction is similar to ordinary spoken human-human dialogue. A problem with available in-vehicle voice control technologies is that they are not flexible enough in terms of the interaction strategies and modalities offered to the user. 3 GoDiS features in Dico GoDiS (Larsson, 2002) is an experimental dialogue system implementing a theory of IssueBased Dialogue Management based on Ginzburg’s concept of Questions Under Discussion (QUD). GoDiS is implemented using the TrindiKit, a toolkit for implementing dialogue move engines and dialogue systems based on the Information State approach (Traum and Larsson, 2003). GoDiS has been adapted to several different dialogue types, domains, and languages, including menu-based multimodal dialogue when acting as an interface to an mp3 player (Hjelm et al., 2005). The GoDiS dialogue manager allows the user to interact more flexibly and naturally with menubased interfaces to devices. General dialogue management issues such as accommodation, task switching and grounding are handled by the applicationindependent dialogue manager. Re-using these technologies in new applications enables rapid prototyping of advanced dialogue applications. 92 Proceedings of the ACL-HLT</context>
</contexts>
<marker>Traum, Larsson, 2003</marker>
<rawString>David Traum and Staffan Larsson. 2003. The information state approach to dialogue management. In Ronnie Smith and Jan Kuppevelt, editors, Current and New Directions in Discourse &amp; Dialogue. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jessica Villing</author>
<author>Staffan Larsson</author>
</authors>
<title>Dico - a multimodal in-vehicle dialogue system.</title>
<date>2006</date>
<booktitle>Proceedings of the 10th workshop on the semantics and pragmatics of dialogue.</booktitle>
<editor>In D. Schlangen and R. Fernandez, editors,</editor>
<contexts>
<context position="957" citStr="Villing and Larsson, 2006" startWordPosition="134" endWordPosition="137"> a novel combination of flexible multimodal menu-based dialogueand a “speech cursor” which enables menu navigation as well as browsing long list using haptic input and spoken output. 1 Introduction Dico is a multimodal in-car dialogue system application, originally developed in the DICO (with capital letters) project by Volvo Technology AB and the University of Gothenburg. Dico is built on top of the GoDiS dialogue system platform (Larsson, 2002), which in turn is implemented using TrindiKit (Traum and Larsson, 2003). The main goal of the original Dico application (Olsson and Villing, 2005), (Villing and Larsson, 2006) was to develop an interface that is less distracting for the driver, and thus both safer and easier to use than existing interfaces. (Larsson and Villing, 2009) described the Dico II system resulting from work in the DICO project. Since then, the Dico demonstrator has been further developed. In this paper, we describe the Dico II+ demonstrator which introduces a novel combination of flexible Multimodal Menu-Based Dialogue and a Speech Cursor which together enable flexible multimodal interaction without the need for looking at the screen. In the following, we will first argue for the usefulnes</context>
</contexts>
<marker>Villing, Larsson, 2006</marker>
<rawString>Jessica Villing and Staffan Larsson. 2006. Dico - a multimodal in-vehicle dialogue system. In D. Schlangen and R. Fernandez, editors, Proceedings of the 10th workshop on the semantics and pragmatics of dialogue.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>