<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.045503">
<title confidence="0.996338">
You Can’t Beat Frequency (Unless You Use Linguistic Knowledge) –
A Qualitative Evaluation of Association Measures for
Collocation and Term Extraction
</title>
<author confidence="0.998753">
Joachim Wermter Udo Hahn
</author>
<affiliation confidence="0.997">
Jena University Language &amp; Information Engineering (JULIE) Lab
</affiliation>
<address confidence="0.647981">
D-07743 Jena, Germany
</address>
<email confidence="0.762848">
{wermter|hahn}@coling-uni-jena.de
</email>
<sectionHeader confidence="0.987153" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999976375">
In the past years, a number of lexical
association measures have been studied
to help extract new scientific terminol-
ogy or general-language collocations. The
implicit assumption of this research was
that newly designed term measures involv-
ing more sophisticated statistical criteria
would outperform simple counts of co-
occurrence frequencies. We here explic-
itly test this assumption. By way of four
qualitative criteria, we show that purely
statistics-based measures reveal virtually
no difference compared with frequency
of occurrence counts, while linguistically
more informed metrics do reveal such a
marked difference.
</bodyText>
<sectionHeader confidence="0.998987" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999943736842106">
Research on domain-specific automatic term
recognition (ATR) and on general-language collo-
cation extraction (CE) has gone mostly separate
ways in the last decade although their underlying
procedures and goals turn out to be rather simi-
lar. In both cases, linguistic filters (POS taggers,
phrase chunkers, (shallow) parsers) initially col-
lect candidates from large text corpora and then
frequency- or statistics-based evidence or associa-
tion measures yield scores indicating to what de-
gree a candidate qualifies as a term or a colloca-
tion. While term mining and collocation mining,
as a whole, involve almost the same analytical pro-
cessing steps, such as orthographic and morpho-
logical normalization, normalization of term or
collocation variation etc., it is exactly the measure
which grades termhood or collocativity of a can-
didate on which alternative approaches diverge.
Still, the output of such mining algorithms look
similar. It is typically constituted by a ranked list
on which, ideally, the true terms or collocations
are placed in the top portion of the list, while the
non-terms / non-collocations occur in its bottom
portion.
While there have been lots of approaches to
come up with a fully adequate ATR/CE metric
(cf. Section 2), we have made observations in our
experiments that seem to indicate that simplicity
rules, i.e., frequency of occurrence is the dominat-
ing factor for the ranking in the result lists even
when much smarter statistical machinery is em-
ployed. In this paper, we will discuss data which
reveals that purely statistics-based measures ex-
hibit virtually no difference compared with fre-
quency of occurrence counts, while linguistically
more informed measures do reveal such a marked
difference – for the problem of term and colloca-
tion mining at least.
</bodyText>
<sectionHeader confidence="0.999833" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999890066666667">
Although there has been a fair amount of work
employing linguistically sophisticated analysis of
candidate items (e.g., on CE by Lin (1998) and
Lin (1999) as well as on ATR by Daille (1996),
Jacquemin (1999), and Jacquemin (2001)), these
approaches are limited by the difficulty to port
grammatical specifications to other domains (in
the case of ATR) or by the error-proneness of
full general-language parsers (in the case of CE).
Therefore, most recent approaches in both areas
have backed off to more shallow linguistic filter-
ing techniques, such as POS tagging and phrase
chunking (e.g., Frantzi et al. (2000), Krenn and
Evert (2001), Nenadi´c et al. (2004), Wermter and
Hahn (2005)).
</bodyText>
<page confidence="0.974807">
785
</page>
<bodyText confidence="0.997765428571429">
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 785–792,
Sydney, July 2006. c�2006 Association for Computational Linguistics
After linguistic filtering, various measures
are employed in the literature for grading the
termhood / collocativity of collected candidates.
Among the most widespread ones, both for ATR
and CE, are statistical and information-theoretic
measures, such as t-test, log-likelihood, entropy,
and mutual information. Their prominence is
also reflected by the fact that a whole chapter of
a widely used textbook on statistical NLP (viz.
Chapter 5 (Collocations) in Manning and Sch¨utze
(1999)) is devoted to them. In addition, the C-
value (Frantzi et al., 2000) – basically a frequency-
based approach – has been another widely used
measure for multi-word ATR. Recently, more lin-
guistically informed algorithms have been intro-
duced both for CE (Wermter and Hahn, 2004) and
for ATR (Wermter and Hahn, 2005), which have
been shown to outperform several of the statistics-
only metrics.
</bodyText>
<sectionHeader confidence="0.991068" genericHeader="method">
3 Methods and Experiments
</sectionHeader>
<subsectionHeader confidence="0.997436">
3.1 Qualitative Criteria
</subsectionHeader>
<bodyText confidence="0.9999324">
Because various metrics assign a score to the can-
didates indicating as to what degree they qualify
as a collocation or term (or not), these candidates
should ideally be ranked in such a way that the
following two conditions are met:
</bodyText>
<listItem confidence="0.998648166666667">
• true collocations or terms (i.e., the true pos-
itives) are ranked in the upper portion of the
output list.
• non-collocations or non-terms (i.e., the true
negatives) are ranked in the lower part of the
output list.1
</listItem>
<bodyText confidence="0.988553926470588">
While a trivial solution to the problem might
be to simply count the number of occurrences of
candidates in the data, employing more sophis-
ticated statistics-based / information-theoretic or
even linguistically-motivated algorithms for grad-
ing term and collocation candidates is guided by
the assumption that this additional level of sophis-
tication yields more adequate rankings relative to
these two conditions.
Several studies (e.g., Evert and Krenn (2001),
Krenn and Evert (2001), Frantzi et al. (2000),
Wermter and Hahn (2004)), however, have al-
ready observed that ranking the candidates merely
by their frequency of occurrence fares quite well
1Obviously, this goal is similar to ranking documents ac-
cording to their relevance for information retrieval.
compared with various more sophisticated as-
sociation measures (AMs such as t-test, log-
likelihood, etc.). In particular, the precision/recall
value comparison between the various AMs ex-
hibits a rather inconclusive picture in Evert and
Krenn (2001) and Krenn and Evert (2001) as to
whether sophisticated statistical AMs are actually
more viable than frequency counting.
Commonly used statistical significance testing
(e.g., the McNemar or the Wilcoxon sign rank
tests; see (Sachs, 1984)) does not seem to provide
an appropriate evaluation ground either. Although
Evert and Krenn (2001) and Wermter and Hahn
(2004) provide significance testing of some AMs
with respect to mere frequency counting for collo-
cation extraction, they do not differentiate whether
this is due to differences in the ranking of true pos-
itives or true negatives or a combination thereof.2
As for studies on ATR (e.g., Wermter and Hahn
(2005) or Nenadi´c et al. (2004)), no statistical test-
ing of the term extraction algorithms to mere fre-
quency counting was performed.
But after all, these kinds of commonly used sta-
tistical significance tests may not provide the right
machinery in the first place. By design, they are
rather limited (or focused) in their scope in that
they just check whether a null hypothesis can be
rejected or not. In such a sense, they do not pro-
vide a way to determine, e.g., to which degree of
magnitude some differences pertain and thus do
not offer the facilities to devise qualitative criteria
to test whether an AM is superior to co-occurrence
frequency counting.
The purpose of this study is therefore to postu-
late a set of criteria for the qualitative testing of
differences among the various CE and ATR met-
rics. We do this by taking up the two conditions
above which state that a good CE or ATR algo-
rithm would rank most of the true positives in a
candidate set in the upper portion and most of
the true negatives in the lower portion of the out-
put. Thus, compared to co-occurrence frequency
counting, a superior CE/ATR algorithm should
achieve the following four objectives:
2In particular Evert and Krenn (2001) use the chi-square
test which assumes independent samples and is thus not re-
ally suitable for testing the significance of differences of two
or more measures which are typically run on the same set
of candidates (i.e., a dependent sample). Wermter and Hahn
(2004) use the McNemar test for dependent samples, which
only examines the differences in which two metrics do not
coincide.
</bodyText>
<page confidence="0.971203">
786
</page>
<listItem confidence="0.963533">
1. keep the true positives in the upper portion
2. keep the true negatives in the lower portion
3. demote true negatives from the upper portion
4. promote true positives from the lower por-
tion.
</listItem>
<bodyText confidence="0.999509333333333">
We take these to be four qualitative criteria by
which the merit of a certain AM against mere oc-
currence frequency counting can be determined.
</bodyText>
<subsectionHeader confidence="0.999698">
3.2 Data Sets
</subsectionHeader>
<bodyText confidence="0.999991210526316">
For collocation extraction (CE), we used the data
set provided by Wermter and Hahn (2004) which
consists of a 114-million-word German newspa-
per corpus. After shallow syntactic analysis, the
authors extracted Preposition-Noun-Verb (PNV)
combinations occurring at least ten times and had
them classified by human judges as to whether
they constituted a valid collocation or not, re-
sulting in 8644 PNV-combinations with 13.7%
true positives. As for domain-specific automatic
term recognition (ATR), we used a biomedical
term candidate set put forth by Wermter and Hahn
(2005), who, after shallow syntactic analysis, ex-
tracted 31,017 trigram term candidates occurring
at least eight times out of a 104-million-word
MEDLINE corpus. Checking these term candi-
dates against the 2004 edition UMLS Metathe-
saurus (UMLS, 2004)3 resulted in 11.6% true pos-
itives. This information is summarized in Table 1.
</bodyText>
<table confidence="0.9916305">
Collocations Terms
domain newspaper biomedicine
language German English
linguistic type PP-Verb noun phrases
combinations (trigrams)
corpus size 114 million 104 million
cutoff 10 8
# candidates 8,644 31,017
# true positives 1,180 (13.7%) 3,590 (11.6%)
# true negatives 7,464 (86.3%) 27,427 (88.4%)
</table>
<tableCaption confidence="0.959003">
Table 1: Data sets for Collocation Extraction (CE) and Au-
tomatic Term Dioscovery (ATR)
</tableCaption>
<footnote confidence="0.9797905">
3The UMLS Metathesaurus is an extensive and carefully
curated terminological resource for the biomedical domain.
</footnote>
<subsectionHeader confidence="0.982861">
3.3 The Association Measures
</subsectionHeader>
<bodyText confidence="0.99995996969697">
We examined both standard statistics-based and
more recent linguistically rooted association mea-
sures against mere frequency of occurrence count-
ing (henceforth referred to as Frequency). As the
standard statistical AM, we selected the t-test (see
also Manning and Sch¨utze (1999) for a descrip-
tion on its use in CE and ATR) because it has
been shown to be the best-performing statistics-
only measure for CE (cf. Evert and Krenn (2001)
and Krenn and Evert (2001)) and also for ATR (see
Wermter and Hahn (2005)).
Concerning more recent linguistically grounded
AMs, we looked at limited syntagmatic modifia-
bility (LSM) for CE (Wermter and Hahn, 2004)
and limited paradigmatic modifiability (LPM) for
ATR (Wermter and Hahn, 2005). LSM exploits
the well-known linguistic property that colloca-
tions are much less modifiable with additional lex-
ical material (supplements) than non-collocations.
For each collocation candidate, LSM determines
the lexical supplement with the highest probabil-
ity, which results in a higher collocativity score for
those candidates with a particularly characteristic
lexical supplement. LPM assumes that domain-
specific terms are linguistically more fixed and
show less distributional variation than common
noun phrases. Taking n-gram term candidates, it
determines the likelihood of precluding the ap-
pearance of alternative tokens in various token slot
combinations, which results in higher scores for
more constrained candidates. All measures assign
a score to the candidates and thus produce a ranked
output list.
</bodyText>
<subsectionHeader confidence="0.895924">
3.4 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.9999455">
In order to determine any potential merit of the
above measures, we use the four criteria described
in Section 3.1 and qualitatively compare the differ-
ent rankings given to true positives and true neg-
atives by an AM and by Frequency. For this pur-
pose, we chose the middle rank as a mark to di-
vide a ranked output list into an upper portion and
a lower portion. Then we looked at the true pos-
itives (TPs) and true negatives (TNs) assigned to
these portions by Frequency and quantified, ac-
cording to the criteria postulated in Section 3.1,
to what degree the other AMs changed these rank-
ings (or not). In order to better quantify the de-
grees of movement, we partitioned both the upper
and the lower portions into three further subpor-
tions.
</bodyText>
<page confidence="0.975915">
787
</page>
<table confidence="0.999957578947369">
Association upper portion (ranks 1 - 4322) lower portion (ranks 4323 - 8644)
Measure
0% - 16.7% 16.7% - 33.3% 33.3% - 50% 50% - 66.7% 66.7% - 83.3% 83.3% - 100%
Criterion 1 Freq 545 (60.2%) 216 (23.9%) 144 (15.9%) 0 0 0
(905 TPs)
t-test 540 (59.7%) 198 (21.9%) 115 (12.7%) 9 (1.0%) 12 (1.3%) 12 (1.3%)
LSM 606 (67.0%) 237 (26.2%) 35 (3.9%) 10 (1.1%) 12 (1.3%) 5 (0.6%)
Criterion 2 Freq 0 0 0 1361 (33.6%) 1357 (33.5%) 1329 (32.8%)
(4047 TNs)
t-test 0 34 (0.8%) 613 (15.2%) 1121 (27.7%) 1100 (27.2%) 1179 (29.1%)
LSM 118 (2.9%) 506 (12.5%) 726 (17.9%) 808 (20.0%) 800 (19.8%) 1089 (26.9%)
Criterion 3 Freq 896 (26.2%) 1225 (35.9%) 1296 (37.9%) 0 0 0
(3417 TNs)
t-test 901 (26.4%) 1243 (36.4%) 932 (27.3%) 95 (2.8%) 47 (1.4%) 199 (5.8%)
LSM 835 (24.4%) 1150 (33.7%) 342 (10.0%) 218 (6.4%) 378 (11.1%) 494 (14.5%)
Criterion 4 Freq 0 0 0 113 (41.1%) 85 (30.9%) 77 (28.0%)
(275 TPs)
t-test 0 0 31 (11.3%) 88 (32.6%) 59 (21.5%) 95 (34.5%)
LSM 0 10 (3.6%) 144 (52.4%) 85 (30.9%) 27 (9.8%) 9 (3.3%)
</table>
<tableCaption confidence="0.995894">
Table 2: Results on the four qualitative criteria for Collocation Extraction (CE)
</tableCaption>
<table confidence="0.999857578947369">
Association upper portion (ranks 1 - 15508) lower portion (ranks 15509 - 31017)
Measure
0% - 16.7% 16.7% - 33.3% 33.3% - 50% 50% - 66.7% 66.7% - 83.3% 83.3% - 100%
Criterion 1 Freq 1252 (50.7%) 702 (28.4%) 515 (20.9%) 0 0 0
(2469 TPs)
t-test 1283 (52.0%) 709 (28.7%) 446 (18.1%) 13 (0.5%) 2 (0.1%) 16 (0.6%)
LPM 1346 (54.5%) 513 (20.8%) 301 (12.2%) 163 (6.6%) 95 (3.8%) 51 (2.1%)
Criterion 2 Freq 0 0 0 4732 (32.9%) 4822 (33.5%) 4833 (33.6%))
(14387 TNs)
t-test 0 0 580 (4.0%) 4407 (30.6%) 4743 (33.0%) 4657 (32.4%)
LPM 1009 (7.0%) 1698 (11.8%) 2190 (15.2%) 2628 (18.3%) 3029 (21.1%) 3834 (26.6%)
Criterion 3 Freq 3917 (30.0%) 4467 (34.3%) 4656 (35.7%) 0 0 0
(13040 TNs)
t-test 3885 (29.8%) 4460 (34.2%) 4048 (31.0%) 315 (2.4%) 76 (0.6%) 256 (2.0%)
LPM 2545 (19.5%) 2712 (20.8%) 2492 (19.1%) 2200 (16.9%) 1908 (14.6%) 1182 (9.1%)
Criterion 4 Freq 0 0 0 438 (39.1%) 347 (31.0%) 336 (30.0%)
(1121 TPs)
t-test 0 0 97 (8.7%) 436 (38.9%) 348 (31.0%) 240 (21.4%)
LPM 268 (23.9%) 246 (21.9%) 188 (16.8%) 180 (16.1%) 137 (12.2%) 102 (9.1%)
</table>
<tableCaption confidence="0.999899">
Table 3: Results on the four qualitative criteria for Automatic Term Discovery (ATR)
</tableCaption>
<sectionHeader confidence="0.998915" genericHeader="evaluation">
4 Results and Discussion
</sectionHeader>
<bodyText confidence="0.999957276595745">
The first two criteria examine how conservative an
association measure is with respect to Frequency,
i.e., a superior AM at least should keep the status-
quo (or even improve it) by keeping the true pos-
itives in the upper portion and the true negatives
in the lower one. In meeting criteria 1 for CE,
Table 2 shows that t-test behaves very similar to
Frequency in keeping roughly the same amount of
TPs in each of the upper three subportions. LSM
even promotes its TPs from the third into the first
two upper subportion (i.e., by a 7- and 2-point in-
crease in the first and in the second subportion as
well as a 12-point decrease in the third subportion,
compared to Frequency).
With respect to the same criterion for ATR (see
Table 3), Frequency and t-test again show quite
similar distributions of TPs in the top three sub-
portions. LPM, on the other hand, demonstrates a
modest increase (by 4 points) in the top upper sub-
portion, but decreases in the second and third one
so that a small fraction of TPs gets demoted to the
lower three subportions (6.6%, 3.8% and 2.1%).
Regarding criterion 2 for CE (see Table 2), t-
test’s share of TNs in the lower three subportions
is slightly less than that of Frequency, leading
to a 15-point increase in the adjacent third up-
per subportion. This local ”spilling over” to the
upper portion is comparatively small considering
the change that occurs with respect to LSM. Here,
TNs appear in the second (12.5%) and the third
(17.9%) upper subportions. For ATR, t-test once
more shows a very similar distribution compared
to Frequency, whereas LPM again promotes some
of its lower TNs into the upper subportions (7%,
11.8% and 15.2%).
Criteria 3 and 4 examine the kinds of re-
rankings (i.e., demoting upper portion TNs and
promoting lower portion TPs) which an AM needs
to perform in order to qualify as being superior to
Frequency. These criteria look at how well an AM
is able to undo the unfavorable ranking of TPs and
TNs by Frequency. As for criterion 3 (the demo-
tion of TNs from the upper portion) in CE, Table 2
shows that t-test is only marginally able to undo
the unfavorable rankings in its third upper sub-
portion (11 percentage points less of TNs). This
causes a small fraction of TNs getting demoted to
</bodyText>
<page confidence="0.979602">
788
</page>
<figure confidence="0.986276666666667">
Rank in LSM
Rank in LPM
Rank in Frequency
</figure>
<figureCaption confidence="0.9964245">
Figure 1: Collocations: True negatives moved from upper
to lower portion (LSM rank compared to Frequency rank)
</figureCaption>
<figure confidence="0.58512">
Rank in Frequency
</figure>
<figureCaption confidence="0.985698">
Figure 3: Terms: True negatives moved from upper to
lower portion (LPM rank compared to Frequency rank)
</figureCaption>
<table confidence="0.997253666666667">
0% 16.7% 33.3% 50%
100% 83.3% 66.7% 50% 33.3% 16.7 0%
0% 16.7% 33.3% 50%
100% 83.3% 66.7% 50% 33.3% 16.7 0%
Rank in Frequency
Rank in Frequency
0% 16.7% 33.3% 50%
Rank in t−test
100% 83.3% 66.7% 50% 33.3% 16.7 0%
0% 16.7% 33.3% 50%
Rank in t−test
100% 83.3% 66.7% 50% 33.3% 16.7 0%
</table>
<figureCaption confidence="0.99786575">
Figure 2: Collocations: True negatives moved from upper
to lower portion (t-test rank compared to Frequency rank)
Figure 4: Terms: True negatives moved from upper to
lower portion (t-test rank compared to Frequency rank)
</figureCaption>
<bodyText confidence="0.9998357">
the lower three subportions (viz. 2.8%, 1.4%, and
5.8%).
A view from another angle on this rather slight
re-ranking is offered by the scatterplot in Figure
2, in which the rankings of the upper portion TNs
of Frequency are plotted against their ranking in
t-test. Here it can be seen that, in terms of the rank
subportions considered, the t-test TNs are concen-
trated along the same line as the Frequency TNs,
with only a few being able to break this line and
</bodyText>
<page confidence="0.990121">
789
</page>
<figure confidence="0.962935666666667">
Rank in LSM
Rank in LPM
Rank in Frequency
</figure>
<figureCaption confidence="0.9932135">
Figure 5: Collocations: True positives moved from lower
to upper portion (LSM rank compared to Frequency rank)
</figureCaption>
<figure confidence="0.574873">
Rank in Frequency
</figure>
<figureCaption confidence="0.87565">
Figure 7: Terms: True positives moved from lower to upper
portion (LPM rank compared to Frequency rank)
</figureCaption>
<table confidence="0.99825625">
50% 66.7% 83.3% 100%
100% 83.3% 66.7% 50% 33.3% 16.7 0%
50% 66.7% 83.3% 100%
100% 83.3% 66.7% 50% 33.3% 16.7 0%
Rank in Frequency
Rank in Frequency
50% 66.7% 83.3% 100%
Rank in t−test
100% 83.3% 66.7% 50% 33.3% 16.7 0%
50% 66.7% 83.3% 100%
Rank in t−test
100% 83.3% 66.7% 50% 33.3% 16.7 0%
</table>
<figureCaption confidence="0.9966835">
Figure 6: Collocations: True positives moved from lower
to upper portion (t-test rank compared to Frequency rank)
Figure 8: Terms: True positives moved from lower to upper
portion (t-test rank compared to Frequency rank)
</figureCaption>
<bodyText confidence="0.9996045">
get demoted to a lower subportion.
A strikingly similar picture holds for this cri-
terion in ATR: as can be witnessed from Figure
4, the vast majority of upper portion t-test TNs is
stuck on the same line as in Frequency. The sim-
ilarity of t-test in both CE and ATR is even more
remarkable given the fact in the actual number of
upper portion TNs is more than four times higher
in ATR (13040) than in CE (3076). A look at the
actual figures in Table 3 indicates that t-test is even
</bodyText>
<page confidence="0.988515">
790
</page>
<bodyText confidence="0.999985333333334">
less able to deviate from Frequency’s TN distribu-
tion (i.e., the third upper subportion is only occu-
pied by 4.7 points less TNs, with the other two
subportions essentially remaining the same as in
Frequency).
The two linguistically rooted measures, LSM
for CE and LPM for ATR, offer quite a different
picture regarding this criterion. With LSM, almost
one third (32%) of the upper portion TNs get de-
moted to the three lower portions (see Table 2);
with LPM, this proportion even amounts to 40.6%
(see Table 3). The scatterplots in Figure 1 and
Figure 3 visualize this from another perspective:
in particular, LPM completely breaks the original
Frequency ranking pattern and scatters the upper
portion TNs in almost all possible directions, with
the vast majority of them thus getting demoted to
a lower rank than in Frequency. Although LSM
stays more in line, still substantially more upper
portion TNs get demoted than with t-test.
With regard to Criterion 4 (the promotion of
TPs from the lower portion) in CE, t-test manages
to promote 11.3% of its lower portion TPs to the
adjacent third upper subportion, but at the same
time demotes more TPs to the third lower subpor-
tion (34.5% compared to 28% in Frequency; see
Table 2). Figure 6 thus shows the t-test TPs to
be a bit more dispersed in the lower portion. For
ATR, the t-test distribution of TPs differs even less
from Frequency. Table 3 reveals that only 8.7% of
the lower portion TPs get promoted to the adjacent
third upper portion. The staggered groupinlpr g of
lower portion t-test TPs (visualized in the respec-
tive scatterplot in Figure 8) actually indicates that
there are certain plateaus beyond which the TPs
cannot get promoted.
The two non-standard measures, LSM and
LPM, once more present a very different picture.
Regarding LSM, 56% of all lower portion TPs get
promoted to the upper three subportions. The ma-
jority of these (52.4%) gets placed the third upper
subportion. This can also be seen in the respective
scatterplot in Figure 5 which shows a marked con-
centration of lower portion TPs in the third upper
subportion. With respect to LPM, even 62.6% of
all lower portion TPs make it to the upper portions
– with the majority (23.9%) even getting promoted
to the first upper subportion. The respective scat-
terplot in Figure 7 additionally shows that this up-
ward movement of TPs, like the downward move-
ment of TNs in Figure 3, is quite dispersed.
</bodyText>
<sectionHeader confidence="0.999192" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.99998408">
For lexical processing, the automatic identifica-
tion of terms and collocations constitutes a re-
search theme that has been dealt with by employ-
ing increasingly complex probabilistic criteria (t-
test, mutual information, log-likelihood etc.). This
trend is also reflected by their prominent status in
standard textbooks on statistical NLP. The implicit
justification in using these statistics-only metrics
was that they would markedly outperform fre-
quency of co-occurrence counting. We devised
four qualitative criteria for explicitly testing this
assumption. Using the best performing standard
association measure (t-test) as a pars pro toto, our
study indicates that the statistical sophistication
does not pay off when compared with simple fre-
quency of co-occurrence counting.
This pattern changes, however, when proba-
bilistic measures incorporate additional linguistic
knowledge about the distributional properties of
terms and the modifiability properties of colloca-
tions. Our results show that these augmented met-
rics reveal a marked difference compared to fre-
quency of occurrence counts – to a larger degree
with respect to automatic term recognition, to a
slightly lesser degree for collocation extraction.
</bodyText>
<sectionHeader confidence="0.997673" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99475856">
B´eatrice Daille. 1996. Study and implementation of
combined techniques for automatic extraction of ter-
minology. In Judith L. Klavans and Philip Resnik,
editors, The Balancing Act: Combining Statistical
and Symbolic Approaches to Language, pages 49–
66. Cambridge, MA: MIT Press.
Stefan Evert and Brigitte Krenn. 2001. Methods for
the qualitative evaluation of lexical association mea-
sures. In ACL’01/EACL’01 – Proceedings of the
39th Annual Meeting of the Association for Com-
putational Linguistics and the 10th Conference of
the European Chapter of the Association for Com-
putational Linguistics, pages 188–195. Toulouse,
France, July 9-11, 2001. San Francisco, CA: Mor-
gan Kaufmann.
Katerina T. Frantzi, Sophia Ananiadou, and Hideki
Mima. 2000. Automatic recognition of multi-word
terms: The C-value/NC-value method. Interna-
tional Journal on Digital Libraries, 3(2):115–130.
Christian Jacquemin. 1999. Syntagmatic and paradig-
matic representations of term variation. In Proceed-
ings of the 37rd Annual Meeting of the Association
for Computational Linguistics, pages 341–348. Col-
lege Park, MD, USA, 20-26 June 1999. San Fran-
cisco, CA: Morgan Kaufmann.
</reference>
<page confidence="0.971564">
791
</page>
<reference confidence="0.99991536">
Christian Jacquemin. 2001. Spotting and Discovering
Terms through NLP. Mass.: MIT Press.
Brigitte Krenn and Stefan Evert. 2001. Can we do bet-
ter than frequency? A case study on extracting pp-
verb collocations. In Proceedings of the ACL Work-
shop on Collocations. Toulouse, France.
Dekang Lin. 1998. Automatic retrieval and cluster-
ing of similar words. In COLING/ACL’98 – Pro-
ceedings of the 36th Annual Meeting of the Asso-
ciation for Computational Linguistics &amp; 17th In-
ternational Conference on Computational Linguis-
tics, volume 2, pages 768–774. Montr´eal, Quebec,
Canada, August 10-14, 1998. San Francisco, CA:
Morgan Kaufmann.
Dekang Lin. 1999. Automatic identification of non-
compositional phrases. In Proceedings of the 37th
Annual Meeting of the Association for Computa-
tional Linguistics, pages 317–324. College Park,
MD, USA, 20-26 June 1999. San Francisco, CA:
Morgan Kaufmann.
Christopher D. Manning and Hinrich Sch¨utze. 1999.
Foundations of Statistical Natural Language Pro-
cessing. Cambridge, MA; London, U.K.: Bradford
Book &amp; MIT Press.
Goran Nenadi´c, Sophia Ananiadou, and John Mc-
Naught. 2004. Enhancing automatic term recog-
nition through recognition of variation. In COL-
ING Geneva 2004 – Proceedings of the 20th Inter-
national Conference on Computational Linguistics,
pages 604–610. Geneva, Switzerland, August 23-27,
2004. Association for Computational Linguistics.
Lothar Sachs. 1984. Applied Statistics: A Handbook
of Techniques. New York: Springer, 2nd edition.
UMLS. 2004. Unified Medical Language System.
Bethesda, MD: National Library of Medicine.
Joachim Wermter and Udo Hahn. 2004. Collocation
extraction based on modifiability statistics. In COL-
ING Geneva 2004 – Proceedings of the 20th Inter-
national Conference on Computational Linguistics,
volume 2, pages 980–986. Geneva, Switzerland, Au-
gust 23-27, 2004. Association for Computational
Linguistics.
Joachim Wermter and Udo Hahn. 2005. Paradig-
matic modifiability statistics for the extraction of of
complex multi-word terms. In HLT-EMNLP’05 –
Proceedings of the 5th Human Language Technol-
ogy Conference and 2005 Conference on Empiri-
cal Methods in Natural Language Processing, pages
843–850. Vancouver, Canada, October 6-8, 2005.
Association for Computational Linguistics.
</reference>
<page confidence="0.997414">
792
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.971856">
<title confidence="0.997439666666667">You Can’t Beat Frequency (Unless You Use Linguistic Knowledge) – A Qualitative Evaluation of Association Measures for Collocation and Term Extraction</title>
<author confidence="0.999816">Joachim Wermter Udo Hahn</author>
<affiliation confidence="0.999135">Jena University Language &amp; Information Engineering (JULIE) Lab</affiliation>
<address confidence="0.99857">D-07743 Jena, Germany</address>
<abstract confidence="0.998905235294118">In the past years, a number of lexical association measures have been studied to help extract new scientific terminology or general-language collocations. The implicit assumption of this research was that newly designed term measures involving more sophisticated statistical criteria would outperform simple counts of cooccurrence frequencies. We here explicitly test this assumption. By way of four qualitative criteria, we show that purely statistics-based measures reveal virtually no difference compared with frequency of occurrence counts, while linguistically more informed metrics do reveal such a marked difference.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B´eatrice Daille</author>
</authors>
<title>Study and implementation of combined techniques for automatic extraction of terminology.</title>
<date>1996</date>
<booktitle>The Balancing Act: Combining Statistical and Symbolic Approaches to Language,</booktitle>
<pages>49--66</pages>
<editor>In Judith L. Klavans and Philip Resnik, editors,</editor>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA:</location>
<contexts>
<context position="2932" citStr="Daille (1996)" startWordPosition="445" endWordPosition="446">ing factor for the ranking in the result lists even when much smarter statistical machinery is employed. In this paper, we will discuss data which reveals that purely statistics-based measures exhibit virtually no difference compared with frequency of occurrence counts, while linguistically more informed measures do reveal such a marked difference – for the problem of term and collocation mining at least. 2 Related Work Although there has been a fair amount of work employing linguistically sophisticated analysis of candidate items (e.g., on CE by Lin (1998) and Lin (1999) as well as on ATR by Daille (1996), Jacquemin (1999), and Jacquemin (2001)), these approaches are limited by the difficulty to port grammatical specifications to other domains (in the case of ATR) or by the error-proneness of full general-language parsers (in the case of CE). Therefore, most recent approaches in both areas have backed off to more shallow linguistic filtering techniques, such as POS tagging and phrase chunking (e.g., Frantzi et al. (2000), Krenn and Evert (2001), Nenadi´c et al. (2004), Wermter and Hahn (2005)). 785 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Me</context>
</contexts>
<marker>Daille, 1996</marker>
<rawString>B´eatrice Daille. 1996. Study and implementation of combined techniques for automatic extraction of terminology. In Judith L. Klavans and Philip Resnik, editors, The Balancing Act: Combining Statistical and Symbolic Approaches to Language, pages 49– 66. Cambridge, MA: MIT Press.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Stefan Evert</author>
<author>Brigitte Krenn</author>
</authors>
<title>Methods for the qualitative evaluation of lexical association measures.</title>
<date>2001</date>
<booktitle>In ACL’01/EACL’01 – Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics and the 10th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>188--195</pages>
<publisher>Morgan Kaufmann.</publisher>
<location>Toulouse, France,</location>
<contexts>
<context position="5465" citStr="Evert and Krenn (2001)" startWordPosition="837" endWordPosition="840">s) are ranked in the upper portion of the output list. • non-collocations or non-terms (i.e., the true negatives) are ranked in the lower part of the output list.1 While a trivial solution to the problem might be to simply count the number of occurrences of candidates in the data, employing more sophisticated statistics-based / information-theoretic or even linguistically-motivated algorithms for grading term and collocation candidates is guided by the assumption that this additional level of sophistication yields more adequate rankings relative to these two conditions. Several studies (e.g., Evert and Krenn (2001), Krenn and Evert (2001), Frantzi et al. (2000), Wermter and Hahn (2004)), however, have already observed that ranking the candidates merely by their frequency of occurrence fares quite well 1Obviously, this goal is similar to ranking documents according to their relevance for information retrieval. compared with various more sophisticated association measures (AMs such as t-test, loglikelihood, etc.). In particular, the precision/recall value comparison between the various AMs exhibits a rather inconclusive picture in Evert and Krenn (2001) and Krenn and Evert (2001) as to whether sophisticat</context>
<context position="7882" citStr="Evert and Krenn (2001)" startWordPosition="1235" endWordPosition="1238">o test whether an AM is superior to co-occurrence frequency counting. The purpose of this study is therefore to postulate a set of criteria for the qualitative testing of differences among the various CE and ATR metrics. We do this by taking up the two conditions above which state that a good CE or ATR algorithm would rank most of the true positives in a candidate set in the upper portion and most of the true negatives in the lower portion of the output. Thus, compared to co-occurrence frequency counting, a superior CE/ATR algorithm should achieve the following four objectives: 2In particular Evert and Krenn (2001) use the chi-square test which assumes independent samples and is thus not really suitable for testing the significance of differences of two or more measures which are typically run on the same set of candidates (i.e., a dependent sample). Wermter and Hahn (2004) use the McNemar test for dependent samples, which only examines the differences in which two metrics do not coincide. 786 1. keep the true positives in the upper portion 2. keep the true negatives in the lower portion 3. demote true negatives from the upper portion 4. promote true positives from the lower portion. We take these to be</context>
<context position="10473" citStr="Evert and Krenn (2001)" startWordPosition="1642" endWordPosition="1645">ction (CE) and Automatic Term Dioscovery (ATR) 3The UMLS Metathesaurus is an extensive and carefully curated terminological resource for the biomedical domain. 3.3 The Association Measures We examined both standard statistics-based and more recent linguistically rooted association measures against mere frequency of occurrence counting (henceforth referred to as Frequency). As the standard statistical AM, we selected the t-test (see also Manning and Sch¨utze (1999) for a description on its use in CE and ATR) because it has been shown to be the best-performing statisticsonly measure for CE (cf. Evert and Krenn (2001) and Krenn and Evert (2001)) and also for ATR (see Wermter and Hahn (2005)). Concerning more recent linguistically grounded AMs, we looked at limited syntagmatic modifiability (LSM) for CE (Wermter and Hahn, 2004) and limited paradigmatic modifiability (LPM) for ATR (Wermter and Hahn, 2005). LSM exploits the well-known linguistic property that collocations are much less modifiable with additional lexical material (supplements) than non-collocations. For each collocation candidate, LSM determines the lexical supplement with the highest probability, which results in a higher collocativity score </context>
</contexts>
<marker>Evert, Krenn, 2001</marker>
<rawString>Stefan Evert and Brigitte Krenn. 2001. Methods for the qualitative evaluation of lexical association measures. In ACL’01/EACL’01 – Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics and the 10th Conference of the European Chapter of the Association for Computational Linguistics, pages 188–195. Toulouse, France, July 9-11, 2001. San Francisco, CA: Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katerina T Frantzi</author>
<author>Sophia Ananiadou</author>
<author>Hideki Mima</author>
</authors>
<title>Automatic recognition of multi-word terms: The C-value/NC-value method.</title>
<date>2000</date>
<booktitle>International Journal on Digital Libraries,</booktitle>
<pages>3--2</pages>
<contexts>
<context position="3356" citStr="Frantzi et al. (2000)" startWordPosition="509" endWordPosition="512">ed Work Although there has been a fair amount of work employing linguistically sophisticated analysis of candidate items (e.g., on CE by Lin (1998) and Lin (1999) as well as on ATR by Daille (1996), Jacquemin (1999), and Jacquemin (2001)), these approaches are limited by the difficulty to port grammatical specifications to other domains (in the case of ATR) or by the error-proneness of full general-language parsers (in the case of CE). Therefore, most recent approaches in both areas have backed off to more shallow linguistic filtering techniques, such as POS tagging and phrase chunking (e.g., Frantzi et al. (2000), Krenn and Evert (2001), Nenadi´c et al. (2004), Wermter and Hahn (2005)). 785 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 785–792, Sydney, July 2006. c�2006 Association for Computational Linguistics After linguistic filtering, various measures are employed in the literature for grading the termhood / collocativity of collected candidates. Among the most widespread ones, both for ATR and CE, are statistical and information-theoretic measures, such as t-test, log-likelihood, entropy, and mutual information. Their promi</context>
<context position="5512" citStr="Frantzi et al. (2000)" startWordPosition="845" endWordPosition="848"> list. • non-collocations or non-terms (i.e., the true negatives) are ranked in the lower part of the output list.1 While a trivial solution to the problem might be to simply count the number of occurrences of candidates in the data, employing more sophisticated statistics-based / information-theoretic or even linguistically-motivated algorithms for grading term and collocation candidates is guided by the assumption that this additional level of sophistication yields more adequate rankings relative to these two conditions. Several studies (e.g., Evert and Krenn (2001), Krenn and Evert (2001), Frantzi et al. (2000), Wermter and Hahn (2004)), however, have already observed that ranking the candidates merely by their frequency of occurrence fares quite well 1Obviously, this goal is similar to ranking documents according to their relevance for information retrieval. compared with various more sophisticated association measures (AMs such as t-test, loglikelihood, etc.). In particular, the precision/recall value comparison between the various AMs exhibits a rather inconclusive picture in Evert and Krenn (2001) and Krenn and Evert (2001) as to whether sophisticated statistical AMs are actually more viable tha</context>
</contexts>
<marker>Frantzi, Ananiadou, Mima, 2000</marker>
<rawString>Katerina T. Frantzi, Sophia Ananiadou, and Hideki Mima. 2000. Automatic recognition of multi-word terms: The C-value/NC-value method. International Journal on Digital Libraries, 3(2):115–130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Jacquemin</author>
</authors>
<title>Syntagmatic and paradigmatic representations of term variation.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>341--348</pages>
<publisher>Morgan Kaufmann.</publisher>
<location>College Park, MD, USA,</location>
<contexts>
<context position="2950" citStr="Jacquemin (1999)" startWordPosition="447" endWordPosition="448">the ranking in the result lists even when much smarter statistical machinery is employed. In this paper, we will discuss data which reveals that purely statistics-based measures exhibit virtually no difference compared with frequency of occurrence counts, while linguistically more informed measures do reveal such a marked difference – for the problem of term and collocation mining at least. 2 Related Work Although there has been a fair amount of work employing linguistically sophisticated analysis of candidate items (e.g., on CE by Lin (1998) and Lin (1999) as well as on ATR by Daille (1996), Jacquemin (1999), and Jacquemin (2001)), these approaches are limited by the difficulty to port grammatical specifications to other domains (in the case of ATR) or by the error-proneness of full general-language parsers (in the case of CE). Therefore, most recent approaches in both areas have backed off to more shallow linguistic filtering techniques, such as POS tagging and phrase chunking (e.g., Frantzi et al. (2000), Krenn and Evert (2001), Nenadi´c et al. (2004), Wermter and Hahn (2005)). 785 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, </context>
</contexts>
<marker>Jacquemin, 1999</marker>
<rawString>Christian Jacquemin. 1999. Syntagmatic and paradigmatic representations of term variation. In Proceedings of the 37rd Annual Meeting of the Association for Computational Linguistics, pages 341–348. College Park, MD, USA, 20-26 June 1999. San Francisco, CA: Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Jacquemin</author>
</authors>
<title>Spotting and Discovering Terms through NLP.</title>
<date>2001</date>
<publisher>MIT Press.</publisher>
<location>Mass.:</location>
<contexts>
<context position="2972" citStr="Jacquemin (2001)" startWordPosition="450" endWordPosition="451">ult lists even when much smarter statistical machinery is employed. In this paper, we will discuss data which reveals that purely statistics-based measures exhibit virtually no difference compared with frequency of occurrence counts, while linguistically more informed measures do reveal such a marked difference – for the problem of term and collocation mining at least. 2 Related Work Although there has been a fair amount of work employing linguistically sophisticated analysis of candidate items (e.g., on CE by Lin (1998) and Lin (1999) as well as on ATR by Daille (1996), Jacquemin (1999), and Jacquemin (2001)), these approaches are limited by the difficulty to port grammatical specifications to other domains (in the case of ATR) or by the error-proneness of full general-language parsers (in the case of CE). Therefore, most recent approaches in both areas have backed off to more shallow linguistic filtering techniques, such as POS tagging and phrase chunking (e.g., Frantzi et al. (2000), Krenn and Evert (2001), Nenadi´c et al. (2004), Wermter and Hahn (2005)). 785 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 785–792, Sydney,</context>
</contexts>
<marker>Jacquemin, 2001</marker>
<rawString>Christian Jacquemin. 2001. Spotting and Discovering Terms through NLP. Mass.: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brigitte Krenn</author>
<author>Stefan Evert</author>
</authors>
<title>Can we do better than frequency? A case study on extracting ppverb collocations.</title>
<date>2001</date>
<booktitle>In Proceedings of the ACL Workshop on Collocations.</booktitle>
<location>Toulouse, France.</location>
<contexts>
<context position="3380" citStr="Krenn and Evert (2001)" startWordPosition="513" endWordPosition="516">has been a fair amount of work employing linguistically sophisticated analysis of candidate items (e.g., on CE by Lin (1998) and Lin (1999) as well as on ATR by Daille (1996), Jacquemin (1999), and Jacquemin (2001)), these approaches are limited by the difficulty to port grammatical specifications to other domains (in the case of ATR) or by the error-proneness of full general-language parsers (in the case of CE). Therefore, most recent approaches in both areas have backed off to more shallow linguistic filtering techniques, such as POS tagging and phrase chunking (e.g., Frantzi et al. (2000), Krenn and Evert (2001), Nenadi´c et al. (2004), Wermter and Hahn (2005)). 785 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 785–792, Sydney, July 2006. c�2006 Association for Computational Linguistics After linguistic filtering, various measures are employed in the literature for grading the termhood / collocativity of collected candidates. Among the most widespread ones, both for ATR and CE, are statistical and information-theoretic measures, such as t-test, log-likelihood, entropy, and mutual information. Their prominence is also reflected </context>
<context position="5489" citStr="Krenn and Evert (2001)" startWordPosition="841" endWordPosition="844">er portion of the output list. • non-collocations or non-terms (i.e., the true negatives) are ranked in the lower part of the output list.1 While a trivial solution to the problem might be to simply count the number of occurrences of candidates in the data, employing more sophisticated statistics-based / information-theoretic or even linguistically-motivated algorithms for grading term and collocation candidates is guided by the assumption that this additional level of sophistication yields more adequate rankings relative to these two conditions. Several studies (e.g., Evert and Krenn (2001), Krenn and Evert (2001), Frantzi et al. (2000), Wermter and Hahn (2004)), however, have already observed that ranking the candidates merely by their frequency of occurrence fares quite well 1Obviously, this goal is similar to ranking documents according to their relevance for information retrieval. compared with various more sophisticated association measures (AMs such as t-test, loglikelihood, etc.). In particular, the precision/recall value comparison between the various AMs exhibits a rather inconclusive picture in Evert and Krenn (2001) and Krenn and Evert (2001) as to whether sophisticated statistical AMs are a</context>
<context position="10500" citStr="Krenn and Evert (2001)" startWordPosition="1647" endWordPosition="1650">rm Dioscovery (ATR) 3The UMLS Metathesaurus is an extensive and carefully curated terminological resource for the biomedical domain. 3.3 The Association Measures We examined both standard statistics-based and more recent linguistically rooted association measures against mere frequency of occurrence counting (henceforth referred to as Frequency). As the standard statistical AM, we selected the t-test (see also Manning and Sch¨utze (1999) for a description on its use in CE and ATR) because it has been shown to be the best-performing statisticsonly measure for CE (cf. Evert and Krenn (2001) and Krenn and Evert (2001)) and also for ATR (see Wermter and Hahn (2005)). Concerning more recent linguistically grounded AMs, we looked at limited syntagmatic modifiability (LSM) for CE (Wermter and Hahn, 2004) and limited paradigmatic modifiability (LPM) for ATR (Wermter and Hahn, 2005). LSM exploits the well-known linguistic property that collocations are much less modifiable with additional lexical material (supplements) than non-collocations. For each collocation candidate, LSM determines the lexical supplement with the highest probability, which results in a higher collocativity score for those candidates with a</context>
</contexts>
<marker>Krenn, Evert, 2001</marker>
<rawString>Brigitte Krenn and Stefan Evert. 2001. Can we do better than frequency? A case study on extracting ppverb collocations. In Proceedings of the ACL Workshop on Collocations. Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar words.</title>
<date>1998</date>
<booktitle>In COLING/ACL’98 – Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics &amp; 17th International Conference on Computational Linguistics,</booktitle>
<volume>2</volume>
<pages>768--774</pages>
<publisher>Morgan Kaufmann.</publisher>
<location>Montr´eal, Quebec, Canada,</location>
<contexts>
<context position="2882" citStr="Lin (1998)" startWordPosition="434" endWordPosition="435">s, i.e., frequency of occurrence is the dominating factor for the ranking in the result lists even when much smarter statistical machinery is employed. In this paper, we will discuss data which reveals that purely statistics-based measures exhibit virtually no difference compared with frequency of occurrence counts, while linguistically more informed measures do reveal such a marked difference – for the problem of term and collocation mining at least. 2 Related Work Although there has been a fair amount of work employing linguistically sophisticated analysis of candidate items (e.g., on CE by Lin (1998) and Lin (1999) as well as on ATR by Daille (1996), Jacquemin (1999), and Jacquemin (2001)), these approaches are limited by the difficulty to port grammatical specifications to other domains (in the case of ATR) or by the error-proneness of full general-language parsers (in the case of CE). Therefore, most recent approaches in both areas have backed off to more shallow linguistic filtering techniques, such as POS tagging and phrase chunking (e.g., Frantzi et al. (2000), Krenn and Evert (2001), Nenadi´c et al. (2004), Wermter and Hahn (2005)). 785 Proceedings of the 21st International Conferen</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Automatic retrieval and clustering of similar words. In COLING/ACL’98 – Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics &amp; 17th International Conference on Computational Linguistics, volume 2, pages 768–774. Montr´eal, Quebec, Canada, August 10-14, 1998. San Francisco, CA: Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic identification of noncompositional phrases.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>317--324</pages>
<publisher>Morgan Kaufmann.</publisher>
<location>College Park, MD, USA,</location>
<contexts>
<context position="2897" citStr="Lin (1999)" startWordPosition="437" endWordPosition="438">ncy of occurrence is the dominating factor for the ranking in the result lists even when much smarter statistical machinery is employed. In this paper, we will discuss data which reveals that purely statistics-based measures exhibit virtually no difference compared with frequency of occurrence counts, while linguistically more informed measures do reveal such a marked difference – for the problem of term and collocation mining at least. 2 Related Work Although there has been a fair amount of work employing linguistically sophisticated analysis of candidate items (e.g., on CE by Lin (1998) and Lin (1999) as well as on ATR by Daille (1996), Jacquemin (1999), and Jacquemin (2001)), these approaches are limited by the difficulty to port grammatical specifications to other domains (in the case of ATR) or by the error-proneness of full general-language parsers (in the case of CE). Therefore, most recent approaches in both areas have backed off to more shallow linguistic filtering techniques, such as POS tagging and phrase chunking (e.g., Frantzi et al. (2000), Krenn and Evert (2001), Nenadi´c et al. (2004), Wermter and Hahn (2005)). 785 Proceedings of the 21st International Conference on Computati</context>
</contexts>
<marker>Lin, 1999</marker>
<rawString>Dekang Lin. 1999. Automatic identification of noncompositional phrases. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics, pages 317–324. College Park, MD, USA, 20-26 June 1999. San Francisco, CA: Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Hinrich Sch¨utze</author>
</authors>
<date>1999</date>
<booktitle>Foundations of Statistical Natural Language Processing.</booktitle>
<publisher>Bradford Book &amp; MIT Press.</publisher>
<location>Cambridge, MA; London, U.K.:</location>
<marker>Manning, Sch¨utze, 1999</marker>
<rawString>Christopher D. Manning and Hinrich Sch¨utze. 1999. Foundations of Statistical Natural Language Processing. Cambridge, MA; London, U.K.: Bradford Book &amp; MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Goran Nenadi´c</author>
<author>Sophia Ananiadou</author>
<author>John McNaught</author>
</authors>
<title>Enhancing automatic term recognition through recognition of variation.</title>
<date>2004</date>
<booktitle>In COLING Geneva 2004 – Proceedings of the 20th International Conference on Computational Linguistics,</booktitle>
<pages>604--610</pages>
<location>Geneva, Switzerland,</location>
<marker>Nenadi´c, Ananiadou, McNaught, 2004</marker>
<rawString>Goran Nenadi´c, Sophia Ananiadou, and John McNaught. 2004. Enhancing automatic term recognition through recognition of variation. In COLING Geneva 2004 – Proceedings of the 20th International Conference on Computational Linguistics, pages 604–610. Geneva, Switzerland, August 23-27, 2004. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lothar Sachs</author>
</authors>
<title>Applied Statistics: A Handbook of Techniques.</title>
<date>1984</date>
<publisher>Springer,</publisher>
<location>New York:</location>
<note>2nd edition.</note>
<contexts>
<context position="6250" citStr="Sachs, 1984" startWordPosition="956" endWordPosition="957"> fares quite well 1Obviously, this goal is similar to ranking documents according to their relevance for information retrieval. compared with various more sophisticated association measures (AMs such as t-test, loglikelihood, etc.). In particular, the precision/recall value comparison between the various AMs exhibits a rather inconclusive picture in Evert and Krenn (2001) and Krenn and Evert (2001) as to whether sophisticated statistical AMs are actually more viable than frequency counting. Commonly used statistical significance testing (e.g., the McNemar or the Wilcoxon sign rank tests; see (Sachs, 1984)) does not seem to provide an appropriate evaluation ground either. Although Evert and Krenn (2001) and Wermter and Hahn (2004) provide significance testing of some AMs with respect to mere frequency counting for collocation extraction, they do not differentiate whether this is due to differences in the ranking of true positives or true negatives or a combination thereof.2 As for studies on ATR (e.g., Wermter and Hahn (2005) or Nenadi´c et al. (2004)), no statistical testing of the term extraction algorithms to mere frequency counting was performed. But after all, these kinds of commonly used </context>
</contexts>
<marker>Sachs, 1984</marker>
<rawString>Lothar Sachs. 1984. Applied Statistics: A Handbook of Techniques. New York: Springer, 2nd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>UMLS</author>
</authors>
<title>Unified Medical Language System.</title>
<date>2004</date>
<institution>National Library of Medicine.</institution>
<location>Bethesda, MD:</location>
<contexts>
<context position="9434" citStr="UMLS, 2004" startWordPosition="1486" endWordPosition="1487">cted Preposition-Noun-Verb (PNV) combinations occurring at least ten times and had them classified by human judges as to whether they constituted a valid collocation or not, resulting in 8644 PNV-combinations with 13.7% true positives. As for domain-specific automatic term recognition (ATR), we used a biomedical term candidate set put forth by Wermter and Hahn (2005), who, after shallow syntactic analysis, extracted 31,017 trigram term candidates occurring at least eight times out of a 104-million-word MEDLINE corpus. Checking these term candidates against the 2004 edition UMLS Metathesaurus (UMLS, 2004)3 resulted in 11.6% true positives. This information is summarized in Table 1. Collocations Terms domain newspaper biomedicine language German English linguistic type PP-Verb noun phrases combinations (trigrams) corpus size 114 million 104 million cutoff 10 8 # candidates 8,644 31,017 # true positives 1,180 (13.7%) 3,590 (11.6%) # true negatives 7,464 (86.3%) 27,427 (88.4%) Table 1: Data sets for Collocation Extraction (CE) and Automatic Term Dioscovery (ATR) 3The UMLS Metathesaurus is an extensive and carefully curated terminological resource for the biomedical domain. 3.3 The Association Mea</context>
</contexts>
<marker>UMLS, 2004</marker>
<rawString>UMLS. 2004. Unified Medical Language System. Bethesda, MD: National Library of Medicine.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joachim Wermter</author>
<author>Udo Hahn</author>
</authors>
<title>Collocation extraction based on modifiability statistics.</title>
<date>2004</date>
<booktitle>In COLING Geneva 2004 – Proceedings of the 20th International Conference on Computational Linguistics,</booktitle>
<volume>2</volume>
<pages>980--986</pages>
<location>Geneva, Switzerland,</location>
<contexts>
<context position="4392" citStr="Wermter and Hahn, 2004" startWordPosition="665" endWordPosition="668">ates. Among the most widespread ones, both for ATR and CE, are statistical and information-theoretic measures, such as t-test, log-likelihood, entropy, and mutual information. Their prominence is also reflected by the fact that a whole chapter of a widely used textbook on statistical NLP (viz. Chapter 5 (Collocations) in Manning and Sch¨utze (1999)) is devoted to them. In addition, the Cvalue (Frantzi et al., 2000) – basically a frequencybased approach – has been another widely used measure for multi-word ATR. Recently, more linguistically informed algorithms have been introduced both for CE (Wermter and Hahn, 2004) and for ATR (Wermter and Hahn, 2005), which have been shown to outperform several of the statisticsonly metrics. 3 Methods and Experiments 3.1 Qualitative Criteria Because various metrics assign a score to the candidates indicating as to what degree they qualify as a collocation or term (or not), these candidates should ideally be ranked in such a way that the following two conditions are met: • true collocations or terms (i.e., the true positives) are ranked in the upper portion of the output list. • non-collocations or non-terms (i.e., the true negatives) are ranked in the lower part of the</context>
<context position="6377" citStr="Wermter and Hahn (2004)" startWordPosition="974" endWordPosition="977"> retrieval. compared with various more sophisticated association measures (AMs such as t-test, loglikelihood, etc.). In particular, the precision/recall value comparison between the various AMs exhibits a rather inconclusive picture in Evert and Krenn (2001) and Krenn and Evert (2001) as to whether sophisticated statistical AMs are actually more viable than frequency counting. Commonly used statistical significance testing (e.g., the McNemar or the Wilcoxon sign rank tests; see (Sachs, 1984)) does not seem to provide an appropriate evaluation ground either. Although Evert and Krenn (2001) and Wermter and Hahn (2004) provide significance testing of some AMs with respect to mere frequency counting for collocation extraction, they do not differentiate whether this is due to differences in the ranking of true positives or true negatives or a combination thereof.2 As for studies on ATR (e.g., Wermter and Hahn (2005) or Nenadi´c et al. (2004)), no statistical testing of the term extraction algorithms to mere frequency counting was performed. But after all, these kinds of commonly used statistical significance tests may not provide the right machinery in the first place. By design, they are rather limited (or f</context>
<context position="8146" citStr="Wermter and Hahn (2004)" startWordPosition="1279" endWordPosition="1282"> above which state that a good CE or ATR algorithm would rank most of the true positives in a candidate set in the upper portion and most of the true negatives in the lower portion of the output. Thus, compared to co-occurrence frequency counting, a superior CE/ATR algorithm should achieve the following four objectives: 2In particular Evert and Krenn (2001) use the chi-square test which assumes independent samples and is thus not really suitable for testing the significance of differences of two or more measures which are typically run on the same set of candidates (i.e., a dependent sample). Wermter and Hahn (2004) use the McNemar test for dependent samples, which only examines the differences in which two metrics do not coincide. 786 1. keep the true positives in the upper portion 2. keep the true negatives in the lower portion 3. demote true negatives from the upper portion 4. promote true positives from the lower portion. We take these to be four qualitative criteria by which the merit of a certain AM against mere occurrence frequency counting can be determined. 3.2 Data Sets For collocation extraction (CE), we used the data set provided by Wermter and Hahn (2004) which consists of a 114-million-word</context>
<context position="10686" citStr="Wermter and Hahn, 2004" startWordPosition="1676" endWordPosition="1679">rd statistics-based and more recent linguistically rooted association measures against mere frequency of occurrence counting (henceforth referred to as Frequency). As the standard statistical AM, we selected the t-test (see also Manning and Sch¨utze (1999) for a description on its use in CE and ATR) because it has been shown to be the best-performing statisticsonly measure for CE (cf. Evert and Krenn (2001) and Krenn and Evert (2001)) and also for ATR (see Wermter and Hahn (2005)). Concerning more recent linguistically grounded AMs, we looked at limited syntagmatic modifiability (LSM) for CE (Wermter and Hahn, 2004) and limited paradigmatic modifiability (LPM) for ATR (Wermter and Hahn, 2005). LSM exploits the well-known linguistic property that collocations are much less modifiable with additional lexical material (supplements) than non-collocations. For each collocation candidate, LSM determines the lexical supplement with the highest probability, which results in a higher collocativity score for those candidates with a particularly characteristic lexical supplement. LPM assumes that domainspecific terms are linguistically more fixed and show less distributional variation than common noun phrases. Taki</context>
</contexts>
<marker>Wermter, Hahn, 2004</marker>
<rawString>Joachim Wermter and Udo Hahn. 2004. Collocation extraction based on modifiability statistics. In COLING Geneva 2004 – Proceedings of the 20th International Conference on Computational Linguistics, volume 2, pages 980–986. Geneva, Switzerland, August 23-27, 2004. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joachim Wermter</author>
<author>Udo Hahn</author>
</authors>
<title>Paradigmatic modifiability statistics for the extraction of of complex multi-word terms.</title>
<date>2005</date>
<booktitle>In HLT-EMNLP’05 – Proceedings of the 5th Human Language Technology Conference and 2005 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>843--850</pages>
<location>Vancouver, Canada,</location>
<contexts>
<context position="3429" citStr="Wermter and Hahn (2005)" startWordPosition="521" endWordPosition="524">tically sophisticated analysis of candidate items (e.g., on CE by Lin (1998) and Lin (1999) as well as on ATR by Daille (1996), Jacquemin (1999), and Jacquemin (2001)), these approaches are limited by the difficulty to port grammatical specifications to other domains (in the case of ATR) or by the error-proneness of full general-language parsers (in the case of CE). Therefore, most recent approaches in both areas have backed off to more shallow linguistic filtering techniques, such as POS tagging and phrase chunking (e.g., Frantzi et al. (2000), Krenn and Evert (2001), Nenadi´c et al. (2004), Wermter and Hahn (2005)). 785 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 785–792, Sydney, July 2006. c�2006 Association for Computational Linguistics After linguistic filtering, various measures are employed in the literature for grading the termhood / collocativity of collected candidates. Among the most widespread ones, both for ATR and CE, are statistical and information-theoretic measures, such as t-test, log-likelihood, entropy, and mutual information. Their prominence is also reflected by the fact that a whole chapter of a widely used</context>
<context position="6678" citStr="Wermter and Hahn (2005)" startWordPosition="1024" endWordPosition="1027">ophisticated statistical AMs are actually more viable than frequency counting. Commonly used statistical significance testing (e.g., the McNemar or the Wilcoxon sign rank tests; see (Sachs, 1984)) does not seem to provide an appropriate evaluation ground either. Although Evert and Krenn (2001) and Wermter and Hahn (2004) provide significance testing of some AMs with respect to mere frequency counting for collocation extraction, they do not differentiate whether this is due to differences in the ranking of true positives or true negatives or a combination thereof.2 As for studies on ATR (e.g., Wermter and Hahn (2005) or Nenadi´c et al. (2004)), no statistical testing of the term extraction algorithms to mere frequency counting was performed. But after all, these kinds of commonly used statistical significance tests may not provide the right machinery in the first place. By design, they are rather limited (or focused) in their scope in that they just check whether a null hypothesis can be rejected or not. In such a sense, they do not provide a way to determine, e.g., to which degree of magnitude some differences pertain and thus do not offer the facilities to devise qualitative criteria to test whether an </context>
<context position="9192" citStr="Wermter and Hahn (2005)" startWordPosition="1448" endWordPosition="1451">requency counting can be determined. 3.2 Data Sets For collocation extraction (CE), we used the data set provided by Wermter and Hahn (2004) which consists of a 114-million-word German newspaper corpus. After shallow syntactic analysis, the authors extracted Preposition-Noun-Verb (PNV) combinations occurring at least ten times and had them classified by human judges as to whether they constituted a valid collocation or not, resulting in 8644 PNV-combinations with 13.7% true positives. As for domain-specific automatic term recognition (ATR), we used a biomedical term candidate set put forth by Wermter and Hahn (2005), who, after shallow syntactic analysis, extracted 31,017 trigram term candidates occurring at least eight times out of a 104-million-word MEDLINE corpus. Checking these term candidates against the 2004 edition UMLS Metathesaurus (UMLS, 2004)3 resulted in 11.6% true positives. This information is summarized in Table 1. Collocations Terms domain newspaper biomedicine language German English linguistic type PP-Verb noun phrases combinations (trigrams) corpus size 114 million 104 million cutoff 10 8 # candidates 8,644 31,017 # true positives 1,180 (13.7%) 3,590 (11.6%) # true negatives 7,464 (86.</context>
<context position="10547" citStr="Wermter and Hahn (2005)" startWordPosition="1656" endWordPosition="1659"> an extensive and carefully curated terminological resource for the biomedical domain. 3.3 The Association Measures We examined both standard statistics-based and more recent linguistically rooted association measures against mere frequency of occurrence counting (henceforth referred to as Frequency). As the standard statistical AM, we selected the t-test (see also Manning and Sch¨utze (1999) for a description on its use in CE and ATR) because it has been shown to be the best-performing statisticsonly measure for CE (cf. Evert and Krenn (2001) and Krenn and Evert (2001)) and also for ATR (see Wermter and Hahn (2005)). Concerning more recent linguistically grounded AMs, we looked at limited syntagmatic modifiability (LSM) for CE (Wermter and Hahn, 2004) and limited paradigmatic modifiability (LPM) for ATR (Wermter and Hahn, 2005). LSM exploits the well-known linguistic property that collocations are much less modifiable with additional lexical material (supplements) than non-collocations. For each collocation candidate, LSM determines the lexical supplement with the highest probability, which results in a higher collocativity score for those candidates with a particularly characteristic lexical supplement</context>
</contexts>
<marker>Wermter, Hahn, 2005</marker>
<rawString>Joachim Wermter and Udo Hahn. 2005. Paradigmatic modifiability statistics for the extraction of of complex multi-word terms. In HLT-EMNLP’05 – Proceedings of the 5th Human Language Technology Conference and 2005 Conference on Empirical Methods in Natural Language Processing, pages 843–850. Vancouver, Canada, October 6-8, 2005. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>