<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<sectionHeader confidence="0.579286" genericHeader="abstract">
ABSTRACTS OF CURRENT LITERATURE
</sectionHeader>
<bodyText confidence="0.4180175">
Correction: In Issue 14-2, the title of Kathleen Finn&apos;s thesis was incorrect. It should read &amp;quot;An Investigation of
Visible Lip Information to be Used in Automated Speech Recognition.&amp;quot;
</bodyText>
<subsectionHeader confidence="0.483542">
Selected Dissertation Abstracts
</subsectionHeader>
<author confidence="0.6205265">
Compiled by:
Susanne M. Humphrey, National Library of Medicine, Bethesda, MD 20209
</author>
<affiliation confidence="0.649578">
Bob Krovetz, University of Massachusetts, Amherst, MA 01002
</affiliation>
<bodyText confidence="0.924311315789474">
The following are citations selected by title and abstract as being related to computational linguistics or knowledge
representation, resulting from a computer search, using the BRS Information Technologies retrieval service, of the
Dissertation Abstracts International (DAI) data base produced by University Microfilms International.
Included are the UM order number and year-month of entry into the data base; author; university, degree, and,
if available, number of pages; title; DAI subject category chosen by the author of the dissertation; and abstract.
References are sorted first by DAI subject category and second by author. Citations denoted by an MAI reference
do not yet have abstracts in the data base and refer to abstracts in the published Masters Abstracts International.
Unless otherwise specified, paper or microform copies of dissertations may be ordered from:
University Microfilms International
Dissertation Copies
Post Office Box 1764
Ann Arbor, MI 48106
telephone for U.S. (except Michigan, Hawaii, Alaska): 1-800-521-3042,
for Canada: 1-800-268-6090.
Price lists and other ordering and shipping information are in the introduction to the published DAI. An alternate
source for copies is sometimes provided at the end of the abstract.
The dissertation titles and abstracts contained here are published with permission of University Microfilms
International, publishers of Dissertation Abstracts International (copyright by University Microfilms International),
and may not be reproduced without their prior permission.
</bodyText>
<figure confidence="0.656863">
Logic-Based Knowledge Representation
Languages Can Represent Complex
Objects and Hierarchical Structure in
a Natural Manner
Jeffrey Alan Jackson
The University of Wisconsin - Madison
Ph.D 1987, 391 pages
Computer Science
University Microfilms International
ADG87-20464
</figure>
<bodyText confidence="0.997739333333333">
KORAL is a syntactic extension of traditional predicate calculus
for knowledge representation (KR). It has expressive power
comparable to higher-order logic, is more concise and
perspicuous than traditional logic, and represents important
aspects of the meaning of descriptive English statements.
KORAL features include numerical quantification, structured
variables, new rules of variable scoping, pointers, and typing of
predicate places. An algorithm for translating KORAL to
traditional logic is given, thus demonstrating the reducibility of
KORAL semantics to the semantics of the ordinary predicate
calculus.
The KORAL interpreter evaluates detection and individuation
&amp;quot;meaning postulates&amp;quot; against a finite relational data base to
automatically identify and name complex objects. The new
names are constants used during subsequent computation.
The overall effect of this automatic identification and naming
of complex individuals is that, in addition to having the
capacity of the ordinary predicate calculus to handle hierarchies
of atomic and compound formulas and of primitive and defined
predicates, KORAL and its interpreter also have the capability
to handle the &amp;quot;structural&amp;quot; hierarchy of complex individuals
composed of other individuals, possibly themselves complex.
Thus the frequent criticism that logic is &amp;quot;too flat&amp;quot; for effective
KR is shown to be groundless and, further, logic is seen to
</bodyText>
<page confidence="0.964778">
108 Computational Linguistics, Volume 14, Number 4, December 1988
</page>
<subsectionHeader confidence="0.340458">
Abstracts of Current Literature
</subsectionHeader>
<bodyText confidence="0.9991605">
provide a helpful explication of the semantics of KR schemes
that focus on hierarchies of complex objects.
A second frequent criticism of logic-based KR is that its
associated inference too often blows up combinatorially. We
argue that this criticism applied to all KR formalisms, and that
the solution lies not in how knowledge is represented but in
what knowledge is represented. In particular, hierarchical
planning is required to control deductive combinatorial
explosion. KORAL promises to be suitable for representing the
control knowledge on which such planning must be based.
</bodyText>
<figure confidence="0.938831083333333">
A Knowledge System Using Hybrid
Reasoning Schemes and Exploiting a
Relational Data-Base as a Frame-Like
Knowledge Base
Wei-Si Jiang
University of Cincinnati Ph.D 1987, 178
pages
Computer Science
University Microfilms International
ADG87-22093
A Formal Theory of Plan Recognition
Henry Alexander Kautz
</figure>
<affiliation confidence="0.7009185">
The University of Rochester Ph.D 1987,
226 pages
Computer Science
University Microfilms International
</affiliation>
<page confidence="0.816261">
ADG87-I8947
</page>
<bodyText confidence="0.988243063829787">
This dissertation describes an expert system shell, PAIS-I, and
several prototype systems developed using this shell. The PAIS-
I system has a couple of special facilities to support hybrid
reasoning schemes, and is capable of exploiting a relational data
base as a framelike knowledge base.
First-generation expert systems reason from rules of thumb,
or use heuristic reasoning. They have limited problem-solving
ability and a fragile behavior at the boundary of the field
domain. Model-based reasoning employs a different approach. In
this approach, we first build a model of the system&apos;s structure,
function and causality, and then reason about this model.
With a specific problem domain-electronic trouble shooting,
three small prototype expert systems were developed using the
PAIS-I shell. Each of them employs a different reasoning
scheme: the first one uses heuristic reasoning only; the second
one uses model-based reasoning only; and the third one
combines the first two approaches and uses a hybrid reasoning
scheme. The comparative study shows that the heuristic
approach is of high efficiency, but the problem-solving ability is
limited. The model-based approach has powerful problem-solving
ability, but is inefficient. The combined approach supported by
the PAIS-I shell can achieve high efficiency as well as powerful
problem-solving ability. The special facilities of the PAIS-I shell
enable the implementation of this hybrid reasoning scheme
easier and more convenient than the existing shells.
The PAIS-I shell has a direct access to an external database
management system (DBMS) for fetching the information from
the data base. It also has a DBMS frame interpreter to
transform the information into executable Prolog clauses
representing a frame.
With the support of these facilities, the system is capable of
exploiting passive data in the data base as active knowledge for
making useful inferences. With the help of the PAIS-I system
facilities, a hardware verification prototype was developed using
a novel approach. An implementation of commonsense reasoning
was also studied, which is able to solve well-known Whether
Birds Can Fly and Temporal Projection problems.
Research in discourse analysis, story understanding, and user
modeling for expert systems has shown great interest in plan
recognition problems. In a plan recognition problem, one is
given a fragmented description of actions performed by one or
more agents, and expected to infer the overall plan or scenario
that explains those actions. This thesis develops the first formal
description of the plan recognition process.
Beginning with a reified logic of events, the thesis presents a
scheme for hierarchically structuring a library of event types. A
Computational Linguistics, Volume 14, Number 4, December 1988 109
</bodyText>
<subsectionHeader confidence="0.968337">
Abstracts of Current Literature
</subsectionHeader>
<bodyText confidence="0.999976692307692">
semantic basis for non-deductive inference, called minimum
covering entailment, justifies the conclusions that one may draw
from a set of observed actions. Minimum covering entailment is
defined by delineating the class of models in which the library
is complete and the set of unrelated observations is minimized.
An equivalent proof theory forms a preliminary basis for
mechanizing the theory. Equivalence theorems between the
proof and model theories are presented. Minimum covering
entailment is related to a formalism for non-monotonic inference
known as circumscription. Finally, the thesis describes a
number of algorithms that correctly implement the theory,
together with a discussion of their complexity.
The theory is applied to a number of examples of plan
recognition, in domains ranging from an operating system
advisor to the theory of speech acts. The thesis shows how
problems of medical diagnosis, a similar kind of non-deductive
reasoning, can be cast in the framework, and an example
previously solved by a medical expert system is worked out in
detail.
The analyses provides a firm theoretical foundation for much
of what is loosely called &amp;quot;frame-based inference&amp;quot;, and directly
accounts for problems of ambiguity, abstraction, and complex
temporal interactions, which were ignored by previous work.
The framework can be extended to handle difficult phenomena
such as errors, and can also be restricted in order to improve
its computational properties in specialized domains.
</bodyText>
<figure confidence="0.9703965">
A Unified Theory of Inference for
Text Understanding
Peter Norvig
University of California, Berkeley Ph.D
1986, 290 pages
Computer Science
University Microfilms International
ADG87-I8104
</figure>
<bodyText confidence="0.999034129032258">
Natural languages, like English, are difficult to understand not
only because of the variety of forms that can be expressed, but
also because of what is not explicitly expressed. The problem
of deciding what was implied by a text—of &amp;quot;reading between
the lines&amp;quot;—is the problem of inference. For a reader to extract
the proper set of inferences from a text (the set that was
intended by the text&apos;s author) requires a great deal of general
knowledge on the part of reader, as well as a capability to
reason with this knowledge.
Past approaches to the problem of inference have often
concentrated on a particular type of knowledge structure (such
as a script) and postulated an algorithm tuned to process just
that type of structure. The problem with this approach is that it
is difficult to modify the algorithm when it comes time to add a
new type of knowledge structure.
An alternative, unified approach is proposed. This approach
is formalized in a computer program named FAUSTUS. The
algorithm recognizes six very general classes of inference,
classes that are not dependent on individual knowledge
structures. Rather, the classes describe very general kinds of
connections between concepts. New kinds of knowledge can be
added without modifying the algorithm. Thus the complexity has
been shifted from the algorithm to the knowledge base. To
accommodate this, a powerful knowledge representation
language named KODIAK is employed.
The resulting system is capable of drawing proper inferences
(and avoiding improper ones) from a variety of texts, in some
cases duplicating the efforts of other systems, and in other
cases improving on them. In each case, the same unified
algorithm is used, without tuning the program specifically for
the text eat hand.
</bodyText>
<page confidence="0.973944">
110 Computational Linguistics, Volume 14, Number 4, December 1988
</page>
<figure confidence="0.984401933333333">
Abstracts of Current Literature
Toward a Mathematical Theory of
Plan Synthesis
Edwin Peter Dawson Pednault
Stanford University Ph.D 1987, 258 pages
Computer Science
University Microfilms International
ADG87-20423
Derived Relations with Exceptions
Gonzalo Ramirez-Ruiz
Texas A&amp;M University Ph.D 1987, 200
pages
Computer Science
University Microfilms International
ADG87-20937
</figure>
<bodyText confidence="0.999444979591837">
Planning problems generally have the following form: given a
set of goals, a set of allowable actions, and a descriptive of the
current state of affairs, find a sequence of allowable actions
that will bring about a state of affairs in which all of the
desired goals are satisfied. This dissertation examines the
question of how to solve planning problems efficiently. This
question is addressed from a rigorous, mathematical standpoint,
in contrast to the informal and highly experimental treatments
found in most previous works. By introducing mathematical
rigor, it has been possible to develop techniques that are
capable of solving a much broader class of problems than has
been considered in the past. For example, problems that
involve time and context-dependent actions can be solved using
the techniques that are presented. It has also been possible to
unify and generalize many existing ideas in automatic planning,
showing how they arise from first principles and how they may
be applied to solve this broader class of problems. These ideas
include means-ends analysis, opportunistic planning, goal
protection, goal regression, constraint posting/propagation, and
formal objects.
Generalization rules are a powerful and versatile tool to
represent knowledge at a high level of abstraction—as opposed
to conventional database systems, which use data to represent
specific facts. A generalization rule used in conjunction with a
relational database system serves two purposes: first, it
represents knowledge of a general nature; and second, it defines
the subset of a population of tuples that satisfy the conditions
defined in the rule. As a generalization, the knowledge being
represented does not depend on any specific facts, but rather it
describes information of a general nature about an organization
or a phenomenon; as a subset of a population, it describes all
those individuals that fall into the generalization given by the
rule. A major issue that had not been fully addressed in the
literature is the problem of exceptions to generalizations.
Exceptions arise naturally in the real world because, by
definition, a generalization implies a loss of detail, and because
even if it were feasible, it is probably not desirable nor
convenient to define every possible case in a generalization
rule.
This dissertation has identified the problems in dealing with
exceptions, characterized the types of exceptions, analyzed the
issues in storing generalization rules and exceptions, studied the
possible conflicts in stored data, and proposed definite
solutions. These solutions are given in a mathematical,
axiomatic form. A mathematical entity called DRE-algebra has
been defined that allows the formal specification of
generalization rules, exceptions, and database operations on
exceptions. In addition, an implementation has been given as an
extension to the SQL database language.
</bodyText>
<figure confidence="0.938100105263158">
Computational Linguistics, Volume 14, Number 4, December 1988 111
Abstracts of Current Literature
Concept Acquisition Through
Representational Adjustment
Jeffrey Curtis Schlimmer
University of California, Irvine Ph.D
1987, 354 pages
Computer Science
University Microfilms International
ADG87-24747
A Theory of Stratified Meaning
Representation for Natural Language
Tomasz Strzalkowski
Simon Fraser University (Canada) Ph.D
1986
Computer Science
(This item is not available from
University Microfilms International.)
ADG05-61235
</figure>
<bodyText confidence="0.999578877192983">
Though the experiences of life exhibit unceasing variety, people
are able to find constancy and deal with their world in a
regular and predictable manner. This thesis promotes the
hypothesis that the necessary abstractions can be learned. The
specific task studied is inducing a concept description from
examples. A model is presented that relies on a weighted,
symbolic description of concepts. Though the description is
distributed, novel examples are classified holistically by
combining each portion&apos;s contribution. Each new example also
refines the concept description: internal weights are updated and
new symbolic structures are introduced. These actions improve
description quality as measured by classification accuracy over
novel examples.
Initially the concept description is highly distributed, being
composed of many simple components. As learning progresses,
sophisticated descriptive structures are added, and eventually
the description is coalesced into a few highly predictive
components. This qualitative change in the representation of the
concept is a unique feature of the model.
The model extends previous work by allowing for noisy
examples, unknown values, and concept change over time. To
bolster claims of robustness, several experiments illustrating the
model&apos;s behavior are reported. Key results illustrate that the
model should scale-up to larger tasks than those studied and
have a number of potential applications.
We introduce a computationally oriented theory of natural
language understanding that integrates various levels of language
processing with methods of modeling the language denotational
base. This theory attempts to bridge the gap between the
formal theories of language and meaning, such as possible
worlds theory and the theory of situations, and artificial
intelligence practice. We develop the concept of the Stratified
Model as a major processing medium that provides an interface
between linguistic input, the &amp;quot;real&amp;quot; universe, and the
knowledge base of some hypothetic, intelligent individual.
The major work reported in this dissertation focuses on
selected aspects of the Stratified Model which have been
identified with the domains of three language transformations
and the meaning representation levels they produce. The first of
these transformations represents the syntactic analysis of
morphologically disambiguated utterances with the categorial
grammar CAT. As a result, a set of possible discourses is
generated in which each sentence is considered independently of
the rest of discourse. Possible discourses are subject to another
transformation which integrates them into partially connected
and locally coherent discourse prototypes. At this stage, various
intersentential dependencies are evaluated, including anaphoric
in-text relations. A small number of possible discourse
representations that display global coherence are selected from
among discourse prototypes and delivered onto the ultimate
meaning representation level by the final transformation. From
this level a mapping is attempted onto a corresponding universe
model. A sequence of further transformations would then extend
this mapping to a real-world interpretation of discourse.
The problems of modeling the language denotational base are
addressed within the Theory of Names and Descriptions, which
constitutes a part of our framework. A layered model of the
</bodyText>
<page confidence="0.89698">
112 Computational Linguistics, Volume 14, Number 4, December 1988
</page>
<table confidence="0.878296">
Abstracts of Current Literature
Language and Definiteness
Nirmalangshu Mukherji
University of Waterloo (Canada) Ph.D
1987
Education, Philosophy of
(This item is not available from
University Microfilms International.)
ADG05-60643
</table>
<bodyText confidence="0.99070284">
universe is proposed to capture non-singular interpretations of
certain linguistic entities often referred to as functional, generic,
mass, or intensional. The uniformity and elegance of our
approach is contrasted with the partial and incomplete
explanation of this phenomenon given in other relevant
research.
This study is an attempt to confront a received view of
language with a single linguistic phenomenon. At issue is the
computational view of language according to which a sequence
of sounds is processed through computational components, each
of which is distinguished by its own set of rules. The linguistic
phenomenon at issue is the definite article the. Hence the title.
I show first that, given the nature of the linguistic
phenomenon at issue, just two components of the computational
view are relevant here. The components are: grammar
(Chomsky) and logic (Montague).
Next, I argue that there is some reason to believe that the,
unlike other &amp;quot;logical particles&amp;quot; of English, seems to escape
computational processing. This problem has never quite surfaced
in the recent literature in philosophy, linguistics, and logic
because most authors still believe that Russell&apos;s Theory of
Descriptions—despite Strawson&apos;s objections—at least partially
accounts for the. I show that Russell&apos;s theory has been simply
assumed, rather than examined, in much current discussion of
de re modalities, rigid designators, etc. I examine Russell&apos;s
theory from various angles to conclude that it fails even as a
partial account of the-phrases. Thus the problem raised above
remains open.
Finally, an evaluation of a variety of data leads to the
conclusion that the is best viewed as a blind device for an
expected convergence, from the speaker&apos;s point of view, of
speaker-hearer—GROUP—reference. This leads to three
consequences. First, the only rule that plausibly could be
applied to the turns out not to be syntactic, in the Chomskyan
sense, despite the being a blind device. Second, the cannot be
cast in any logic since it does not simulate any logical
operation. Third, given that definite descriptions supply the
clearest model for singular reference, some problems in this
area (e.g., Frege&apos;s Puzzles) seem to escape a computational
solution.
Production systems&apos; static and dynamic characteristics are
modeled with the use of graph grammar in order to create
means to increase the processing efficiency and the use of
parallel computation through compile time analysis. The model
is used to explicate rule interaction, so that proofs of
equivalence between knowledge bases can be attempted. Solely
relying on program static characteristics shown by the model, a
series of observations are made to determine the system
dynamic characteristics, and modifications to the original
The following dissertation is available from
</bodyText>
<table confidence="0.90179475">
Micrographics Department
Doheny Library
University of Southern California
Los Angeles, CA 90089-0182
Parallel Processing Techniques for
Production Systems
Manuel Fernando Da Mota Tenorio
University of Southern California Ph.D
</table>
<page confidence="0.667921">
1987
</page>
<figure confidence="0.81023152">
Engineering, Electronics and Electrical
(This item is not available from
University Microfilms International.)
ADG05-61010
Computational Linguistics, Volume 14, Number 4, December 1988 113
Abstracts of Current Literature
Quantitative and Qualitative
Assessments of the Impact of
Linguistic Theory on Information
Science
Amy Warner
University of Illinois at
Urbana-Champaign Ph.D 1987, 240 pages
Information Science
University Microfilms International
ADG87-21782
What&apos;s a Bunch? Integrating and
Applying Syntactic, Semantic, and
Sociolinguistic Analyses to Explain the
Partitive Construction in English
Thomas Anthony Angelo
Harvard University Ed.D 1987, 360 pages
Language, Linguistics
University Microfilms International
ADG87-22667
</figure>
<bodyText confidence="0.999756339622642">
knowledge base are suggested as a means of increasing
efficiency and decreasing overall search and computational
effort. Dependences between the rules are analyzed and
different approaches for automatic detection are presented.
From rule dependences, tools for programming environments,
logical evaluation of search spaces, and Petri net models of
production systems are shown. An algorithm for the allocation
and partitioning of a production system into a multiprocessor
system is also shown, and addresses the problems of
communication and execution of these systems in parallel.
Finally, the results of a simulator constructed to test several
strategies, networks, and algorithms are presented.
A citation analysis was performed on a subset of the
information science literature to determine the impact of
linguistic theory on information science. Both quantitative and
qualitative measures were employed to show the relationship
between the two fields. The overall findings indicate that this
portion of the information science literature has made almost no
use of linguistic theory. The small number of citations on
linguistic theory did show some patterns, indicating that small
numbers of citing and cited authors account for most of the
activity; that syntax and semantics have occupied more
attention from information scientists than other branches of
linguistic theory; that information scientists have cited older
works over time; and that most of the citations to linguistic
theory belong to qualitative &amp;quot;non-use&amp;quot; categories.
This dissertation explains the structure, meanings, and uses of
the partitive construction in English. Partitive constructions are
phrases such as &amp;quot;bunch of&apos;, &amp;quot;herd of&amp;quot;, &amp;quot;gallon of&apos;, or
&amp;quot;boatload of&apos;. Partitives premodify and specify nouns and noun
phrases. Partitives are shown to be of two syntactic classes:
nominal and quantifier. The syntactic structure of each class of
partitives is analyzed and illustrated in some detail. Next, the
lexical semantic meanings of partitives are discussed. Partitive
meanings are shown to be systematically interrelated and
categorizable according to a limited number of dimensions.
Third, a subset of the English nominal partitives is shown to be
a nominal classifier system—a language-specific instance of a
language universal feature. Fourth, results are presented from a
study of partitive acquisition in five English-speaking children.
The data base used in the present study consists of transcripts
of extensive audiotaping of these five preschool children and
their caregivers. These transcripts were accessed and analyzed
through the Child Language Data Exchange System
(CHILDES). The development of partitive use in children is
then considered in light of overall development of classification
and categorization during childhood. Results from surveys on
adult use and understanding of partitives are presented and
analyzed in terms of the pragmatic functions of partitives in
English. Finally, the relevance of this dissertation to applied
linguistics, English lexicography, and English language teaching
and related research is commented on, and suggestions are
made for more focused future research on partitives.
</bodyText>
<page confidence="0.975058">
114 Computational Linguistics, Volume 14, Number 4, December 1988
</page>
<figure confidence="0.421622588235294">
Abstracts of Current Literature
Morphological Structure and Parsing
in the Lexicon
Karen Denise Emmorey
University of California, Los Angeles
Ph.D 1987, 183 pages
Language, Linguistics
University Microfilms International
ADG87-25038
Topic, Focus, and the Grammar of
Spoken French
Knud P. Lambrecht
University of California, Berkeley Ph.D
1986, 365 pages
Language, Linguistics
University Microfilms International
ADG87-1805I
</figure>
<bodyText confidence="0.987759241379311">
This study explores the relation between formal grammars and
psychological parsing models and is concerned with how
morphological structure is represented and accessed in the
lexicon. A series of auditory lexical decision experiments were
conducted with English. The results indicate that morphological
structure is analyzed on-line during lexical access. I propose
that English prefixed words are stored in the lexicon with their
morphological structure marked and that only the roots of
suffixed words are contained in the cohort set used for
recognition. There was no evidence that parsing is misled by
pseudoaffixation. Some evidence suggests that derived suffixed
words take longer to recognize than inflected and
monomorphemic words. I propose that this delay is due to the
category-changing nature of the derivational suffixes.
Morphologically complex words and nonwords were also
presented visually. The results indicate that auditory and visual
lexical access procedures are subject to different constraints that
affect morphological analysis. For auditory processing
recognition of a suffix is tied to the identification of a root. For
visual processing, however, recognition of the root and suffix
can occur in parallel. Auditory word recognition is constrained
by temporal order, whereas visual word recognition can operate
more holistically.
Three auditory priming experiments were also conducted. One
experiment showed that morphological relationships are
represented independently of semantic relatedness. A large
priming effect was found for morphologically related words that
were not semantically related (e.g., submit, permit). Significant
priming was not found for words that were simply
phonologically related (e.g., balloon, saloon). The second and
third priming experiments indicated that suffixes do not have
lexical representations that can be primed during lexical access;
morphological priming was not found between words that share
a suffix (e.g., blackness, shortness). Formal models that propose
separate lexical entries for affixes are not supported. Lastly,
phonological priming was observed when the words shared a
final syllable but not when they shared final segments. Word-
final phonological priming presents problems for the cohort
model, which predicts that only word-initial priming can occur.
This study is an attempt to explain a number of recurring
structural patterns in the spoken French sentence in terms of
the communicative functions these patterns serve in spontaneous
speech. It is based on the assumption that the relationship
between the form of sentences and the linguistic and
extralinguistic contexts in which sentences are used as units of
propositional information is governed by rules of grammar at a
grammatical level called information structure. The fundamental
argument is that the structure of the French sentence reflects
the semantic-pragmatic relations topic and focus. These correlate
in turn indirectly with the representations of referents of
syntactic constituents in the mind of the speaker/hearer at the
time of an utterance. Thus a link is established between the
pragmatics of the speech situation and the formal structure of
the sentence.
Part 1 discusses the grammatical domain of information
structure and defines three sets of discourse-pragmatic notions:
1. the propositional notion of information, subdivided into
Computational Linguistics, Volume 14, Number 4, December 1988 115
</bodyText>
<subsectionHeader confidence="0.951112">
Abstracts of Current Literature
</subsectionHeader>
<bodyText confidence="0.999895714285715">
assertion and pragmatic presupposition; 2. the cognitive notions
of activation and identifiability, which reflect the status of
mental representations of referents in a discourse; 3. the
relational notions of topic and focus, which determine the
respective scope of the assertion and the presupposition.
Part 2 is an analysis of the structure of the spoken French
clause based on the framework elaborated in Part 1. The
analysis builds on two fundamental observations concerning the
relationship between syntax and discourse in spoken French.
The first is that the canonical SV(0) sentence type, with lexical
arguments in subject (and object) position, is pragmatically
severely constrained and is superseded by a preferred clause
type of the form V(X). The second observation concerns the
existence of a number of ready-made grammatical constructions
that allow speakers to preserve the preferred V(X) clause type
in discourse. These grammatical constructions are of two major
structural types: clefts and detachments. In both types, lexical
NP constituents appear in positions other than within the clause
in which they are semantic arguments, resulting in a separation
of the lexical naming function of the NP from the relational
role it plays as an argument in a proposition.
</bodyText>
<figure confidence="0.572076571428571">
Computer Synthesis of English
Causative Verbs
Roberta H. Merchant
Georgetown University Ph.D 1986, 248
pages
Language, Linguistics
University Microfilms International
ADG87-20561
Control Verbs in English
Elizabeth Minassian Pellegrino
Georgetown University Ph.D 1986, 170
pages
Language, Linguistics
University Microfilms International
</figure>
<page confidence="0.971058">
ADG87-20562
</page>
<bodyText confidence="0.999979235294117">
Machine translation systems require word level analysis in order
to identify lexical items used in the processing. The question of
whether to go beyond word level analysis to morphological
analysis depends on whether coherent and productive
morphological rules, either inflectional or derivational, exist in
the language studied. English inflectional morphology is
productive and is used in most machine translation systems, but
derivational morphological analysis is required for synthesis of
English causative verbs from translation of other languages.
To evaluate the effectiveness of derivational morphological
analysis in English, word formation rules based on principles of
X-bar morphology were developed. After the rules were
formulated, a computer program was written to carry out these
morphological operations. A large data base representing the
possible categories of morphological variation between
non-causative and causative pairs in English was selected and
tested to verify the rules used in the program.
The program and data base show that there is a large
number of non-causative/causative pairs in English showing
coherent and productive morphological relationships which can
be stated in word formation rules designed for computational
analysis. Application of morphological rules to computer
synthesis of English causative verbs is a practical and efficient
method of building the lexical synthesis component of a
computational system.
This thesis deals with control verbs in English within an
interpretive framework, proposing lexical features for these
verbs and rules in LF which account for their behavior. It is
argued that control features, applicable to LF, should be based
on thematic relations instead of grammatical relations. The
proposed thematic control features, (+AG) and (AG), are shown
to best account for the data. The projection of these features
into the syntax including any structures, such as a nonull
COMP, which may affect the choice of controller, is addressed.
</bodyText>
<page confidence="0.957004">
116 Computational Linguistics, Volume 14, Number 4, December 1988
</page>
<subsectionHeader confidence="0.827849">
Abstracts of Current Literature
</subsectionHeader>
<bodyText confidence="0.99994944">
In the course of this examination of control verbs, an
explanation is provided for an apparent enigmatic pair: the
ungrammatical, *John was promised to leave, where the
obligatory controller is unavailable, and the grammatical, John
was promised to be allowed to leave, where the obligatory
controller appears to be unavailable. It is shown that a
passivized complement triggers a reversal of lexical control
properties. Consequently, the control properties of promise in
the above pair reverse with an embedded passive, allowing
subsequent matrix passivization in the latter of the two.
Furthermore, this study reveals a dichotomy among control
verbs with two matrix NPs, hence two possible controllers:
those that take a passivized complement and exhibit a reversal
of control properties and those that neither take a passivized
complement nor exhibit a reversal of control properties. This
same dichotomy emerges in the study of the influence of
pragmatic factors; the former group is subject to their influence,
whereas the latter group is not.
The basic theme of this study is that control properties
correlate with the meaning of the verb. The features (+/—AG)
represent a component of the meaning of the verb. It is
illustrated that various senses of a control verb correspond to
various control features. It is further suggested that
subcategorization properties correlate with the sense of the
lexical item rather than with the lexical item alone.
</bodyText>
<table confidence="0.548690375">
Aspects of Coherence in English and
Japanese Expository Prose
Thomas Kenneth Ricento
University of California, Los Angeles
Ph.D 1987, 218 pages
Language, Linguistics
University Microfilms International
ADG87-23190
</table>
<bodyText confidence="0.98795640625">
The primary goals of this dissertation are to compare certain
structural aspects of comparable English and Japanese
expository texts which are thought to be coherence markers,
and to ascertain the degree to which native speakers of both
languages are able to access appropriate formal schemata in
reordering scrambled paragraphs of these texts.
The data consist of 10 Japanese texts and the English
translations of these same texts, and five English texts. The
coherence features measured or described are: thematic
continuity, paragraph linking, rhetorical patterns, literary
conventions, reader/writer responsibility, and cultural values/
attitudes. In the experimental portion of the study, 30 bilingual
native Japanese speakers and 23 monolingual native English
speakers ordered the scrambled paragraphs of the texts and also
provided titles and summaries. Rank order correlations (rho)
and interrater reliability scores (r) were calculated, and between-
group comparisons of means were made.
Analysis of the texts revealed cross-linguistic similarities in
the relative frequency of cohesion (lexical, referential,
conjunctive) markers, and differences in the relative use of
paragraph linking devices, transition statements, and topical
focus markers. Differences were noted in the relative use of
various rhetorical types (Meyer 1985); certain rhetorical patterns
were identified which are particular to Japanese, and other
patterns were identified which occur in both languages.
Results from the paragraph reordering experiment provide
evidence that certain rhetorical patterns are familiar to both
native English speakers and native Japanese speakers, while
other patterns are familiar only to native Japanese speakers. It
was also found that bilingual native Japanese speakers
apparently access formal schemata appropriate for English
Computational Linguistics, Volume 14, Number 4, December 1988 117
</bodyText>
<subsectionHeader confidence="0.880664">
Abstracts of Current Literature
</subsectionHeader>
<bodyText confidence="0.9997545">
expository prose when reading English translations of Japanese
texts.
Analysis of titles and summaries provided by consultants
revealed no correlation between consultants&apos; ability to correctly
reorder the scrambled paragraphs and their understanding of the
main point of the text.
</bodyText>
<figure confidence="0.991343428571429">
Indeterminacy of Translation: Theory
and Practice
Dorit Bar-On
University of California, Los Angeles
Ph.D 1987, 439 pages
Philosophy
University Microfilms International
ADG87-23145
The Elicitation of Units of Knowledge
and Relations: Enhancing Empirically
Derived Semantic Networks
Nancy Marie Cooke
Psychology, Experimental
University Microfilms International
</figure>
<page confidence="0.854417">
ADG87-20055
</page>
<bodyText confidence="0.99987988">
To an ordinary translator, the idea that there are too many
perfect translation schemes between any two languages would
come as a surprise. Quine&apos;s thesis of the indeterminacy of
translation expresses just this idea. It implies that most of the
implicit canons actual translators use in their assessment of
translations lack objective status. My dissertation is an attempt
to present a systematic challenge to Quine&apos;s view of language
(and mind) and to support the idea that one could develop an
objective theory of translation that is also faithful to actual
translation practices.
I expose a non-superficial similarity between external-world
skepticism and Quine&apos;s meaning-scepticism, and deploy against
Quine an objection that closely resembles his own objection to
external-world skepticism. I then develop a new interpretation
of Quine&apos;s reasoning, according to which denying objective
status to intuitive meanings is Quine&apos;s way of avoiding a
sceptical problem about what other people &amp;quot;really&amp;quot; mean.
I argue that the intelligibility of Quine&apos;s meaning-scepticism
turns on an implicit contrast between the perspective of the
theorist of language and the perspective of the user of language.
Quine&apos;s defense of his skepticism features a theorist-language
trying to probe an alien language—a &amp;quot;radical translator&amp;quot;—who
reasons that her own judgments as a language user lack
objective status.
I take issue with the use Quine makes of the above contrast.
I first argue that understanding the goal of radical translators
requires knowing what is to be expected of an adequate
translation scheme. Since this is something we learn from
experience with existing translation schemes, I offer a
pretheoretic description of the practice of translation between
known languages. I show how ordinary translators&apos; assessments
of the quality of given translations derive from systematic
judgments they make as language users. It is these sorts of
judgments that guide actual radical translators in ruling out
bizarre alternative translations of the kind Quine entertains in
defending his scepticism. A proper theoretical account of radical
translation, I conclude, must begin with—and include—the
perspective of the radical translator as a language user.
The notion that associations of units of knowledge underlie
memory has been pervasive throughout many psychological
paradigms and is especially prevalent in current semantic
network theories. Units of knowledge have been represented in
semantic networks as nodes and associations between units
have been represented as links between nodes. Unlike previous
associational theories, semantic network theories have attributed
meaning to associations through the use of links labeled with
particular relations. Unfortunately, there have been as many
different types of units and relations proposed as semantic
network models. Attempts to address these variations have been
made through the development of semantic network formalisms.
</bodyText>
<page confidence="0.942637">
118 Computational Linguistics, Volume 14, Number 4, December 1988
</page>
<bodyText confidence="0.981456941176471">
Abstracts of Current Literature
An alternate approach is through the empirical generation of
networks using algorithms such as Pathfinder. Semantic
networks derived from human judgments can be used to verify
the psychological meaningfulness of intuitively derived networks.
In addition, the networks have some useful applications as
knowledge elicitation tools. However, there are limitations
inherent in the Pathfinder methodology that must be overcome
before it can be successfully applied. The research discussed in
this paper addressed two limitations that are also particularly
relevant to the historical issues of units of knowledge and
associations. More specifically, the problems of identifying the
critical units of domain knowledge to be represented by nodes
and of interpreting or labeling links in the resulting networks
were investigated.
In the first two studies units of knowledge were elicited from
experts in the domains of driving and flight maneuvers. The
elicitation tasks that were used included the listing of concepts,
steps, or chapter headings, and the extraction of main ideas
from an interview. The elicitation techniques differed in terms
of the quantity of ideas elicited, as well as the type of
knowledge that was elicited. A second series of studies
addressed the link interpretation issue using relations in a set of
common concepts and a set of programming concepts. Subjects
either sorted linked pairs into groups having the same meaning
or labeled links with the appropriate relation. Links were
ultimately classified using cluster analysis techniques. Results
indicated that the clusters were meaningful and that the link
types represented by each cluster corresponded to an
independently derived taxonomy of link types. In general, the
techniques investigated in this paper represent steps toward the
formalization of aspects of the Pathfinder methodology that are
critical to its application as a knowledge elicitation tool and as
a tool for validating intuitively derived semantic networks.
</bodyText>
<page confidence="0.286981">
Computational Linguistics, Volume 14, Number 4, December 1988 119
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.103663">
<note confidence="0.789121733333333">ABSTRACTS OF CURRENT LITERATURE Correction: In Issue 14-2, the title of Kathleen Finn&apos;s thesis was incorrect. It should read &amp;quot;An Investigation of Visible Lip Information to be Used in Automated Speech Recognition.&amp;quot; Selected Dissertation Abstracts Compiled by: Susanne M. Humphrey, National Library of Medicine, Bethesda, MD 20209 Bob Krovetz, University of Massachusetts, Amherst, MA 01002 The following are citations selected by title and abstract as being related to computational linguistics or knowledge representation, resulting from a computer search, using the BRS Information Technologies retrieval service, of the Dissertation Abstracts International (DAI) data base produced by University Microfilms International. Included are the UM order number and year-month of entry into the data base; author; university, degree, and, if available, number of pages; title; DAI subject category chosen by the author of the dissertation; and abstract. References are sorted first by DAI subject category and second by author. Citations denoted by an MAI reference do not yet have abstracts in the data base and refer to abstracts in the published Masters Abstracts International. Unless otherwise specified, paper or microform copies of dissertations may be ordered from:</note>
<affiliation confidence="0.6951585">University Microfilms International Dissertation Copies</affiliation>
<address confidence="0.702373">Post Office Box 1764 Ann Arbor, MI 48106</address>
<note confidence="0.8970065">telephone for U.S. (except Michigan, Hawaii, Alaska): 1-800-521-3042, for Canada: 1-800-268-6090.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>