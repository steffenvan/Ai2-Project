<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.063680">
<title confidence="0.9992195">
Discriminative Alignment Training without Annotated Data
for Machine Translation
</title>
<author confidence="0.946153">
Patrik Lambert, Rafael E. Banchs and Josep M. Crego
</author>
<affiliation confidence="0.908213">
TALP Research Center
</affiliation>
<address confidence="0.9098425">
Jordi Girona Salgado 1–3
08034 Barcelona, Spain
</address>
<email confidence="0.995536">
{lambert, rbanchs, jmcrego}@gps.tsc.upc.edu
</email>
<sectionHeader confidence="0.995636" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999143125">
In present Statistical Machine Translation
(SMT) systems, alignment is trained in a
previous stage as the translation model.
Consequently, alignment model parame-
ters are not tuned in function of the trans-
lation task, but only indirectly. In this
paper, we propose a novel framework for
discriminative training of alignment mod-
els with automated translation metrics as
maximization criterion. In this approach,
alignments are optimized for the transla-
tion task. In addition, no link labels at the
word level are needed. This framework
is evaluated in terms of automatic trans-
lation evaluation metrics, and an improve-
ment of translation quality is observed.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.986147153846154">
In the first SMT systems (Brown et al., 1993), word
alignment was introduced as a hidden variable of
the translation model. When word-based translation
models have been replaced by phrase-based mod-
els (Zens et al., 2002), alignment1 and translation
model training have become two separated tasks.
The system of Brown et al. was based on the
noisy channel approach. Present SMT systems use a
more general maximum entropy approach in which a
log-linear combination of multiple feature functions
is implemented (Och and Ney, 2002). Within this
1Hereinafter, alignment will refer to word alignment, unless
otherwise stated.
</bodyText>
<page confidence="0.99656">
85
</page>
<bodyText confidence="0.999752617647059">
new framework translation quality can be tuned by
adjusting the weight of each feature function in the
log-linear combination. In order to improve transla-
tion quality, this tuning can be effectively performed
by minimizing translation error over a development
corpus for which manually translated references are
available (Och, 2003). As a separate first stage of the
process, alignment is not in practice directly tuned in
function of the machine translation task.
Tuning alignment for an MT system is subject to
practical difficulties. Unsupervised systems (Och
and Ney, 2003; Liang et al., 2006) are based on gen-
erative models trained with the EM algorithm. They
require large computational resources, and incorpo-
rating new features is difficult. In contrast, adding
new features to some supervised systems (Liu et al.,
2005; Moore, 2005; Ittycheriah and Roukos, 2005)
is easy, but the need of annotated data is a problem.
A more general difficulty, however, is that of find-
ing an alignment evaluation metric favoring align-
ments which benefit Machine Translation. The fact
that the required alignment characteristics depend
on each particular system makes it even more dif-
ficult. It seems that high precision alignments are
better for phrase-based SMT (Chen and Federico,
2006; Ayan and Dorr, 2006), whereas high recall
alignments are more suited to N-gram SMT (Mari˜no
et al., 2006). In this context, alignment quality im-
provements does not necessarily imply translation
quality improvements. This is in agreement with
the observation of a poor correlation between word
alignment error rate (AER (Och and Ney, 2000)) and
automatic translation evaluation metrics (Ittycheriah
and Roukos, 2005; Vilar et al., 2006).
</bodyText>
<note confidence="0.3947615">
Proceedings of NAACL HLT 2007, Companion Volume, pages 85–88,
Rochester, NY, April 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.999553055555556">
Recently some alignment evaluation metrics have
been proposed which are more informative when
the alignments are used to extract translation
units (Fraser and Marcu, 2006; Ayan and Dorr,
2006). However, these metrics assess translation
quality very indirectly.
In this paper, we propose a novel framework for
discriminative training of alignment models with au-
tomated translation metrics as maximization crite-
rion. Thus we just need a reference aligned at the
sentence level instead of link labels at the word level.
The paper is structured as follows. Section 2 ex-
plains the models used in our word aligner, focusing
on the features designed to account for the specifici-
ties of the SMT system. In section 3, our minimum
error training procedure is described and experimen-
tal results are shown. Finally, some concluding re-
marks and lines of further research are given.
</bodyText>
<sectionHeader confidence="0.877464" genericHeader="introduction">
2 Bilingual Word Aligner
</sectionHeader>
<bodyText confidence="0.9999770625">
For versatility and efficiency requirements, we im-
plemented BIA, a BIlingual word Aligner similar
to that of Moore (2005). BIA consists in a beam-
search decoder searching, for each sentence pair, the
alignment which minimizes the cost of a linear com-
bination of various models. The differences with
the system of Moore lie in the features, which we
specially designed to suit our translation system (N-
gram SMT (Mari˜no et al., 2006)). Its particularity
is the translation model, which is based on a 4-gram
language model of bilingual units referred to as tu-
ples. Two issues regarding this translation model can
be dealt with at the alignment stage.
Firstly, in order to estimate the bilingual n-gram
model, only one monotonic segmentation of each
sentence pair is performed. Thus long reorderings
cause long and sparse tuples to be extracted. For ex-
ample, if the first source word is linked to the last
target word, only one tuple can be extracted, which
contains the whole sentence pair. This kind of tuple
is not reusable, and the data between its two extreme
words are lost.
Secondly, it occurs very often that unlinked words
(i.e. linked to NULL) end up producing tuples with
NULL source sides. This cannot be allowed since
no NULL is expected to occur in a translation input.
This problem is solved by preprocessing alignments
before tuple extraction such that any unlinked target
word is attached to either its precedent or its follow-
ing word.
Taking theses issues into account, we imple-
mented the following features:
</bodyText>
<listItem confidence="0.943774">
• distinct source and target unlinked word penal-
ties: since unlinked words have a different im-
pact whether they appear in the source or target
language, we introduced an unlinked word fea-
ture for each side of the sentence pair.
• link bonus: in order to accommodate the N-
gram model preference for higher recall align-
ment, we introduced a feature which adds a
bonus for each link in the alignment.
• embedded word position penalty: this feature
penalizes situations like the one depicted in fig-
ure 1. In this example, the bilingual units s2-t2
and s3-t3 cannot be extracted because word po-
sitions s2 and s3 are embedded between links
s1-t1 and s4-t1. Thus the link s4-t1 may intro-
duces data sparseness in the translation model,
although it may be a correct link. So we want
to have a feature which counts the number of
embedded word positions in an alignment.
</listItem>
<figureCaption confidence="0.999036">
Figure 1: Word positions embedded in a tuple.
</figureCaption>
<bodyText confidence="0.999987857142857">
In addition to the embedded word position feature,
we used the same two distortion features as Moore
to penalize reorderings in the alignment (one sums
the number of crossing links, and the other one sums
the amplitude of crossing links). We also used the 02
score (Gale and Church, 1991) as a word association
model, and as a POS-tags association model.
</bodyText>
<sectionHeader confidence="0.999873" genericHeader="related work">
3 Experimental Work
</sectionHeader>
<bodyText confidence="0.999547">
For these experiments we used the Chinese-
English data provided for IWSLT’06 evaluation
campaign (Paul, 2006). The training set contains
46000 sentences (of 6.7 and 7.0 average length). Pa-
rameters were tuned over the development set (dev4)
provided, consisting of 489 sentences of 11.2 words
in average, with 7 references. Our test set was a se-
lection of 500 sentences (of 6 words in average, with
16 references) among dev1, dev2 and dev3 sets.
</bodyText>
<page confidence="0.982397">
86
</page>
<subsectionHeader confidence="0.988061">
3.1 Optimization Procedure
</subsectionHeader>
<bodyText confidence="0.999441333333333">
Once the alignment models were computed, a set of
optimal log-linear coefficients was estimated via the
optimization procedure depicted in Figure 2.
</bodyText>
<figureCaption confidence="0.999143">
Figure 2: Optimization loop.
</figureCaption>
<bodyText confidence="0.999939137931034">
The training corpus was aligned with a set of ini-
tial parameters A,, ... , A7. This alignment was used
to extract tuples and build a bilingual N-gram trans-
lation model (TM). A baseline SMT system, consist-
ing of MARIE decoder and this translation model as
unique feature2, was used to produce a translation
(OUT) of the development source set. Then, trans-
lation quality over the development set is maximized
by iteratively varying the set of coefficients.
The optimization procedure was performed by us-
ing the SPSA algorithm (Spall, 1992). SPSA is a
stochastic implementation of the conjugate gradient
method which requires only two evaluations of the
objective function. It was observed to be more ro-
bust than the Downhill Simplex method when tuning
SMT coefficients (Lambert and Banchs, 2006).
Each function evaluation required to align the
training corpus and build a new translation model.
The algorithm converged after about 80 evaluations,
lasting each 17 minutes with a 3 GHz processor.
Alignment decoding was performed with a beam of
10 (it took 50 seconds and required 8 MB memory).
Finally, the corpus was aligned with the opti-
mum set of coefficients, and a full SMT system was
build, with a target language model (trained on the
provided training data), a word bonus model and
two lexical models. SMT models weights were op-
timized with a standard Minimum Error Training
(MET) strategy3 and the test corpus was translated
</bodyText>
<footnote confidence="0.995451">
2An N-gram SMT system can produce good translations
without additional target language model since the target lan-
guage is modeled inside the bilingual N-gram model.
3SMT parameters are not optimized together with alignment
</footnote>
<bodyText confidence="0.999817625">
with the full system. To contrast the results, full
translation systems were also build extracting tuples
from various combinations of GIZA++ alignments
(trained with 50 classes and respectively 4,5 and 4
iterations of models 1,HMM and 4). In order to limit
the error introduced by MET, we translated the test
corpus with three sets of SMT model weights, and
took the average and standard deviation.
</bodyText>
<subsectionHeader confidence="0.959266">
3.2 Results
</subsectionHeader>
<bodyText confidence="0.999924454545455">
Table 1 shows results obtained with the full SMT
system on the test corpus, with GIZA++ alignments,
and BIA alignments optimized in function of three
metrics: BLEU, NIST, and BLEU+4*NIST. The
standard deviation is indicated in parentheses. Al-
though results for systems trained with different BIA
alignments present more variability than systems
trained with GIZA++ alignments, they achieve bet-
ter average scores, and one of them obtains much
higher scores. Unexpectedly, BIA alignments tuned
with NIST yield the system with worse NIST score.
</bodyText>
<sectionHeader confidence="0.973361" genericHeader="conclusions">
4 Conclusions and further work
</sectionHeader>
<bodyText confidence="0.95997572">
We proposed a novel framework for discriminative
training of alignment models with automated trans-
lation metrics as maximization criterion. Accord-
ing to this type of metrics, the translation systems
trained from the optimized alignments clearly per-
formed better than the ones trained from Giza++
alignment combinations.
In addition, this first version of the alignment
system has very basic models and could be im-
proved. We could certainly improve the association
score model, for example adding discount factors or
adding more association score types, or dictionaries.
During the alignment coefficient optimization de-
picted in Figure 2, only the baseline SMT system
is used. In future work, we could consider using
various SMT features (as would be required for a
phrase-based SMT system).
Our approach, as it is, cannot be applied to a large
corpus, since it requires to align the whole training
corpus at each iteration. Thus an interesting further
research would consist in determining whether the
parameters for two main reasons. Firstly, translation is more
sensitive to variations of SMT parameters. Secondly, alignment
is optimized over the full training set, whereas SMT is tuned
over the development set.
</bodyText>
<page confidence="0.9966">
87
</page>
<table confidence="0.999633142857143">
System BLEU NIST PER WER
GIZA++ union 42.7 (1.1) 8.82 (0.07) 34.7 (0.2) 43.7 (0.4)
GIZA++ intersection 42.4 (0.9) 8.53 (0.07) 37.0 (0.9) 45.0 (1.3)
GIZA++ Zh-*En 43.7 (0.9) 8.90 (0.2) 37.2 (1.4) 45.5 (2.0)
BIA (BLEU) 44.8 (0.4) 9.00 (0.04) 35.7 (0.07) 43.8 (0.09)
BIA (BLEU+4*NIST) 47.0 (1.5) 8.83 (0.4) 32.9 (0.8) 40.9 (0.5)
BIA (NIST) 44.8 (0.1) 8.55 (0.14) 33.0 (0.2) 41.4 (0.5)
</table>
<tableCaption confidence="0.999882">
Table 1: Automatic translation evaluation results.
</tableCaption>
<bodyText confidence="0.94656825">
alignment parameters trained on a part of the corpus
are valid for the whole corpus.
Finally, some Giza++ parameters may also be
tuned, in the same way as for BIA parameters.
</bodyText>
<sectionHeader confidence="0.99951" genericHeader="acknowledgments">
5 Acknowledgments
</sectionHeader>
<bodyText confidence="0.999370166666667">
This work has been partially funded by the Euro-
pean Union under the integrated project TC-STAR
- Technology and Corpora for Speech to Speech
Translation -(IST-2002-FP6-506738, http://www.tc-
star.org) and by the Spanish Government under grant
TEC2006-13964-C03 (AVIVAVOZ project).
</bodyText>
<sectionHeader confidence="0.99802" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999687575757576">
Necip F. Ayan and Bonnie J. Dorr. 2006. Going Beyond
AER: An Extensive Analysis of Word Alignments and
Their Impact on MT. In Proc. COLING-ACL, pages
9–16, Sydney, Australia.
Peter F. Brown, Stephen A. Della Pietra, Vincent J.
Della Pietra, and Robert L. Mercer. 1993. The mathe-
matics of statistical machine translation: Parameter es-
timation. Computational Linguistics, 19(2):263–311.
Boxing Chen and Marcello Federico. 2006. Improving
phrase-based statistical translation through combina-
tion of word alignment. In Proc. FinTAL, Turku, Fin-
land.
Alexander Fraser and Daniel Marcu. 2006. Semi-
supervised training for statistical word alignment. In
Proc. COLING-ACL, pages 769–776, Sydney, Aus-
tralia.
W. Gale and K. W. Church. 1991. Identifying word cor-
respondences in parallel texts. In DARPA Speech and
Natural Language Workshop, Asilomar, CA.
Abraham Ittycheriah and Salim Roukos. 2005. A maxi-
mum entropy word aligner for arabic-english machine
translation. In Proc. HLT-EMNLP, pages 89–96, Van-
couver, Canada.
Patrik Lambert and Rafael E. Banchs. 2006. Tuning
Machine Translation Parameters with SPSA. In Proc.
IWSLT, pages 190–196, Kyoto, Japan.
Percy Liang, Ben Taskar, and Dan Klein. 2006. Align-
ment by agreement. In Proc. the HLT-NAACL, pages
104–111, New York City, USA.
Yang Liu, Qun Liu, and Shouxun Lin. 2005. Log-linear
models for word alignment. In Proc. ACL, pages 459–
466, Ann Arbor, Michigan.
Jos´e B. Mari˜no, Rafael E. Banchs, Josep M. Crego, Adri`a
de Gispert, Patrik Lambert, Jos´e A.R. Fonollosa, and
Marta R. Costa-juss`a. 2006. N-gram based machine
translation. Computational Linguistics, 32(4):527–
549.
Robert C. Moore. 2005. A discriminative framework
for bilingual word alignment. In Proc. HLT-EMNLP,
pages 81–88, Vancouver, Canada.
Franz Josef Och and Hermann Ney. 2000. A compari-
son of alignment models for statistical machine trans-
lation. In Proc. COLING, pages 1086–1090, Saar-
brucken,Germany.
F.J. Och and H. Ney. 2002. Dicriminative training
and maximum entropy models for statistical machine
translation. In Proc. ACL, pages 295–302, Philadel-
phia, PA.
F.J. Och and H. Ney. 2003. A systematic comparison of
various statistical alignment models. Computational
Linguistics, 29(1):19–51, March.
F.J. Och. 2003. Minimum error rate training in statistical
machine translation. In Proc. ACL, pages 160–167.
Michael Paul. 2006. Overview of the IWSLT 2006 Eval-
uation Campaign. In Proc. IWSLT, pages 1–15, Kyoto,
Japan.
James C. Spall. 1992. Multivariate stochastic approxi-
mation using a simultaneous perturbation gradient ap-
proximation. IEEE Trans. Automat. Control, 37:332–
341.
David Vilar, Maja Popovic, and Hermann Ney. 2006.
AER: Do we need to ”improve” our alignments? In
Proc. IWSLT, pages 205–212, Kyoto, Japan.
R. Zens, F.J. Och, and H. Ney. 2002. Phrase-based sta-
tistical machine translation. In Springer Verlag, editor,
Proc. German Conf. on Artificial Intelligence (KI).
</reference>
<page confidence="0.999408">
88
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.815126">
<title confidence="0.9983645">Discriminative Alignment Training without Annotated for Machine Translation</title>
<author confidence="0.971772">Patrik Lambert</author>
<author confidence="0.971772">Rafael E Banchs</author>
<author confidence="0.971772">M Josep</author>
<affiliation confidence="0.923155">TALP Research Jordi Girona Salgado</affiliation>
<address confidence="0.999166">08034 Barcelona,</address>
<email confidence="0.996204">rbanchs,</email>
<abstract confidence="0.997579823529412">In present Statistical Machine Translation (SMT) systems, alignment is trained in a previous stage as the translation model. Consequently, alignment model parameters are not tuned in function of the translation task, but only indirectly. In this paper, we propose a novel framework for discriminative training of alignment models with automated translation metrics as maximization criterion. In this approach, alignments are optimized for the translation task. In addition, no link labels at the word level are needed. This framework is evaluated in terms of automatic translation evaluation metrics, and an improvement of translation quality is observed.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Necip F Ayan</author>
<author>Bonnie J Dorr</author>
</authors>
<title>Going Beyond AER: An Extensive Analysis of Word Alignments and Their Impact on MT.</title>
<date>2006</date>
<booktitle>In Proc. COLING-ACL,</booktitle>
<pages>9--16</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="2850" citStr="Ayan and Dorr, 2006" startWordPosition="431" endWordPosition="434">omputational resources, and incorporating new features is difficult. In contrast, adding new features to some supervised systems (Liu et al., 2005; Moore, 2005; Ittycheriah and Roukos, 2005) is easy, but the need of annotated data is a problem. A more general difficulty, however, is that of finding an alignment evaluation metric favoring alignments which benefit Machine Translation. The fact that the required alignment characteristics depend on each particular system makes it even more difficult. It seems that high precision alignments are better for phrase-based SMT (Chen and Federico, 2006; Ayan and Dorr, 2006), whereas high recall alignments are more suited to N-gram SMT (Mari˜no et al., 2006). In this context, alignment quality improvements does not necessarily imply translation quality improvements. This is in agreement with the observation of a poor correlation between word alignment error rate (AER (Och and Ney, 2000)) and automatic translation evaluation metrics (Ittycheriah and Roukos, 2005; Vilar et al., 2006). Proceedings of NAACL HLT 2007, Companion Volume, pages 85–88, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics Recently some alignment evaluation metrics ha</context>
</contexts>
<marker>Ayan, Dorr, 2006</marker>
<rawString>Necip F. Ayan and Bonnie J. Dorr. 2006. Going Beyond AER: An Extensive Analysis of Word Alignments and Their Impact on MT. In Proc. COLING-ACL, pages 9–16, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="971" citStr="Brown et al., 1993" startWordPosition="140" endWordPosition="143">e as the translation model. Consequently, alignment model parameters are not tuned in function of the translation task, but only indirectly. In this paper, we propose a novel framework for discriminative training of alignment models with automated translation metrics as maximization criterion. In this approach, alignments are optimized for the translation task. In addition, no link labels at the word level are needed. This framework is evaluated in terms of automatic translation evaluation metrics, and an improvement of translation quality is observed. 1 Introduction In the first SMT systems (Brown et al., 1993), word alignment was introduced as a hidden variable of the translation model. When word-based translation models have been replaced by phrase-based models (Zens et al., 2002), alignment1 and translation model training have become two separated tasks. The system of Brown et al. was based on the noisy channel approach. Present SMT systems use a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented (Och and Ney, 2002). Within this 1Hereinafter, alignment will refer to word alignment, unless otherwise stated. 85 new framework translat</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Boxing Chen</author>
<author>Marcello Federico</author>
</authors>
<title>Improving phrase-based statistical translation through combination of word alignment.</title>
<date>2006</date>
<booktitle>In Proc. FinTAL,</booktitle>
<location>Turku, Finland.</location>
<contexts>
<context position="2828" citStr="Chen and Federico, 2006" startWordPosition="427" endWordPosition="430">thm. They require large computational resources, and incorporating new features is difficult. In contrast, adding new features to some supervised systems (Liu et al., 2005; Moore, 2005; Ittycheriah and Roukos, 2005) is easy, but the need of annotated data is a problem. A more general difficulty, however, is that of finding an alignment evaluation metric favoring alignments which benefit Machine Translation. The fact that the required alignment characteristics depend on each particular system makes it even more difficult. It seems that high precision alignments are better for phrase-based SMT (Chen and Federico, 2006; Ayan and Dorr, 2006), whereas high recall alignments are more suited to N-gram SMT (Mari˜no et al., 2006). In this context, alignment quality improvements does not necessarily imply translation quality improvements. This is in agreement with the observation of a poor correlation between word alignment error rate (AER (Och and Ney, 2000)) and automatic translation evaluation metrics (Ittycheriah and Roukos, 2005; Vilar et al., 2006). Proceedings of NAACL HLT 2007, Companion Volume, pages 85–88, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics Recently some alignment</context>
</contexts>
<marker>Chen, Federico, 2006</marker>
<rawString>Boxing Chen and Marcello Federico. 2006. Improving phrase-based statistical translation through combination of word alignment. In Proc. FinTAL, Turku, Finland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Fraser</author>
<author>Daniel Marcu</author>
</authors>
<title>Semisupervised training for statistical word alignment.</title>
<date>2006</date>
<booktitle>In Proc. COLING-ACL,</booktitle>
<pages>769--776</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="3575" citStr="Fraser and Marcu, 2006" startWordPosition="536" endWordPosition="539"> alignment quality improvements does not necessarily imply translation quality improvements. This is in agreement with the observation of a poor correlation between word alignment error rate (AER (Och and Ney, 2000)) and automatic translation evaluation metrics (Ittycheriah and Roukos, 2005; Vilar et al., 2006). Proceedings of NAACL HLT 2007, Companion Volume, pages 85–88, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics Recently some alignment evaluation metrics have been proposed which are more informative when the alignments are used to extract translation units (Fraser and Marcu, 2006; Ayan and Dorr, 2006). However, these metrics assess translation quality very indirectly. In this paper, we propose a novel framework for discriminative training of alignment models with automated translation metrics as maximization criterion. Thus we just need a reference aligned at the sentence level instead of link labels at the word level. The paper is structured as follows. Section 2 explains the models used in our word aligner, focusing on the features designed to account for the specificities of the SMT system. In section 3, our minimum error training procedure is described and experim</context>
</contexts>
<marker>Fraser, Marcu, 2006</marker>
<rawString>Alexander Fraser and Daniel Marcu. 2006. Semisupervised training for statistical word alignment. In Proc. COLING-ACL, pages 769–776, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Gale</author>
<author>K W Church</author>
</authors>
<title>Identifying word correspondences in parallel texts.</title>
<date>1991</date>
<booktitle>In DARPA Speech and Natural Language Workshop,</booktitle>
<location>Asilomar, CA.</location>
<contexts>
<context position="7015" citStr="Gale and Church, 1991" startWordPosition="1119" endWordPosition="1122">d because word positions s2 and s3 are embedded between links s1-t1 and s4-t1. Thus the link s4-t1 may introduces data sparseness in the translation model, although it may be a correct link. So we want to have a feature which counts the number of embedded word positions in an alignment. Figure 1: Word positions embedded in a tuple. In addition to the embedded word position feature, we used the same two distortion features as Moore to penalize reorderings in the alignment (one sums the number of crossing links, and the other one sums the amplitude of crossing links). We also used the 02 score (Gale and Church, 1991) as a word association model, and as a POS-tags association model. 3 Experimental Work For these experiments we used the ChineseEnglish data provided for IWSLT’06 evaluation campaign (Paul, 2006). The training set contains 46000 sentences (of 6.7 and 7.0 average length). Parameters were tuned over the development set (dev4) provided, consisting of 489 sentences of 11.2 words in average, with 7 references. Our test set was a selection of 500 sentences (of 6 words in average, with 16 references) among dev1, dev2 and dev3 sets. 86 3.1 Optimization Procedure Once the alignment models were computed</context>
</contexts>
<marker>Gale, Church, 1991</marker>
<rawString>W. Gale and K. W. Church. 1991. Identifying word correspondences in parallel texts. In DARPA Speech and Natural Language Workshop, Asilomar, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Abraham Ittycheriah</author>
<author>Salim Roukos</author>
</authors>
<title>A maximum entropy word aligner for arabic-english machine translation.</title>
<date>2005</date>
<booktitle>In Proc. HLT-EMNLP,</booktitle>
<pages>89--96</pages>
<location>Vancouver, Canada.</location>
<contexts>
<context position="2420" citStr="Ittycheriah and Roukos, 2005" startWordPosition="362" endWordPosition="365">ver a development corpus for which manually translated references are available (Och, 2003). As a separate first stage of the process, alignment is not in practice directly tuned in function of the machine translation task. Tuning alignment for an MT system is subject to practical difficulties. Unsupervised systems (Och and Ney, 2003; Liang et al., 2006) are based on generative models trained with the EM algorithm. They require large computational resources, and incorporating new features is difficult. In contrast, adding new features to some supervised systems (Liu et al., 2005; Moore, 2005; Ittycheriah and Roukos, 2005) is easy, but the need of annotated data is a problem. A more general difficulty, however, is that of finding an alignment evaluation metric favoring alignments which benefit Machine Translation. The fact that the required alignment characteristics depend on each particular system makes it even more difficult. It seems that high precision alignments are better for phrase-based SMT (Chen and Federico, 2006; Ayan and Dorr, 2006), whereas high recall alignments are more suited to N-gram SMT (Mari˜no et al., 2006). In this context, alignment quality improvements does not necessarily imply translat</context>
</contexts>
<marker>Ittycheriah, Roukos, 2005</marker>
<rawString>Abraham Ittycheriah and Salim Roukos. 2005. A maximum entropy word aligner for arabic-english machine translation. In Proc. HLT-EMNLP, pages 89–96, Vancouver, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrik Lambert</author>
<author>Rafael E Banchs</author>
</authors>
<title>Tuning Machine Translation Parameters with SPSA.</title>
<date>2006</date>
<booktitle>In Proc. IWSLT,</booktitle>
<pages>190--196</pages>
<location>Kyoto, Japan.</location>
<contexts>
<context position="8547" citStr="Lambert and Banchs, 2006" startWordPosition="1367" endWordPosition="1370">(TM). A baseline SMT system, consisting of MARIE decoder and this translation model as unique feature2, was used to produce a translation (OUT) of the development source set. Then, translation quality over the development set is maximized by iteratively varying the set of coefficients. The optimization procedure was performed by using the SPSA algorithm (Spall, 1992). SPSA is a stochastic implementation of the conjugate gradient method which requires only two evaluations of the objective function. It was observed to be more robust than the Downhill Simplex method when tuning SMT coefficients (Lambert and Banchs, 2006). Each function evaluation required to align the training corpus and build a new translation model. The algorithm converged after about 80 evaluations, lasting each 17 minutes with a 3 GHz processor. Alignment decoding was performed with a beam of 10 (it took 50 seconds and required 8 MB memory). Finally, the corpus was aligned with the optimum set of coefficients, and a full SMT system was build, with a target language model (trained on the provided training data), a word bonus model and two lexical models. SMT models weights were optimized with a standard Minimum Error Training (MET) strateg</context>
</contexts>
<marker>Lambert, Banchs, 2006</marker>
<rawString>Patrik Lambert and Rafael E. Banchs. 2006. Tuning Machine Translation Parameters with SPSA. In Proc. IWSLT, pages 190–196, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Ben Taskar</author>
<author>Dan Klein</author>
</authors>
<title>Alignment by agreement.</title>
<date>2006</date>
<booktitle>In Proc. the HLT-NAACL,</booktitle>
<pages>104--111</pages>
<location>New York City, USA.</location>
<contexts>
<context position="2147" citStr="Liang et al., 2006" startWordPosition="320" endWordPosition="323">otherwise stated. 85 new framework translation quality can be tuned by adjusting the weight of each feature function in the log-linear combination. In order to improve translation quality, this tuning can be effectively performed by minimizing translation error over a development corpus for which manually translated references are available (Och, 2003). As a separate first stage of the process, alignment is not in practice directly tuned in function of the machine translation task. Tuning alignment for an MT system is subject to practical difficulties. Unsupervised systems (Och and Ney, 2003; Liang et al., 2006) are based on generative models trained with the EM algorithm. They require large computational resources, and incorporating new features is difficult. In contrast, adding new features to some supervised systems (Liu et al., 2005; Moore, 2005; Ittycheriah and Roukos, 2005) is easy, but the need of annotated data is a problem. A more general difficulty, however, is that of finding an alignment evaluation metric favoring alignments which benefit Machine Translation. The fact that the required alignment characteristics depend on each particular system makes it even more difficult. It seems that h</context>
</contexts>
<marker>Liang, Taskar, Klein, 2006</marker>
<rawString>Percy Liang, Ben Taskar, and Dan Klein. 2006. Alignment by agreement. In Proc. the HLT-NAACL, pages 104–111, New York City, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Liu</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Log-linear models for word alignment.</title>
<date>2005</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>459--466</pages>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="2376" citStr="Liu et al., 2005" startWordPosition="356" endWordPosition="359"> minimizing translation error over a development corpus for which manually translated references are available (Och, 2003). As a separate first stage of the process, alignment is not in practice directly tuned in function of the machine translation task. Tuning alignment for an MT system is subject to practical difficulties. Unsupervised systems (Och and Ney, 2003; Liang et al., 2006) are based on generative models trained with the EM algorithm. They require large computational resources, and incorporating new features is difficult. In contrast, adding new features to some supervised systems (Liu et al., 2005; Moore, 2005; Ittycheriah and Roukos, 2005) is easy, but the need of annotated data is a problem. A more general difficulty, however, is that of finding an alignment evaluation metric favoring alignments which benefit Machine Translation. The fact that the required alignment characteristics depend on each particular system makes it even more difficult. It seems that high precision alignments are better for phrase-based SMT (Chen and Federico, 2006; Ayan and Dorr, 2006), whereas high recall alignments are more suited to N-gram SMT (Mari˜no et al., 2006). In this context, alignment quality impr</context>
</contexts>
<marker>Liu, Liu, Lin, 2005</marker>
<rawString>Yang Liu, Qun Liu, and Shouxun Lin. 2005. Log-linear models for word alignment. In Proc. ACL, pages 459– 466, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jos´e B Mari˜no</author>
<author>Rafael E Banchs</author>
<author>Josep M Crego</author>
<author>Adri`a de Gispert</author>
<author>Patrik Lambert</author>
<author>Jos´e A R Fonollosa</author>
<author>Marta R Costa-juss`a</author>
</authors>
<title>N-gram based machine translation.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<volume>32</volume>
<issue>4</issue>
<pages>549</pages>
<marker>Mari˜no, Banchs, Crego, de Gispert, Lambert, Fonollosa, Costa-juss`a, 2006</marker>
<rawString>Jos´e B. Mari˜no, Rafael E. Banchs, Josep M. Crego, Adri`a de Gispert, Patrik Lambert, Jos´e A.R. Fonollosa, and Marta R. Costa-juss`a. 2006. N-gram based machine translation. Computational Linguistics, 32(4):527– 549.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C Moore</author>
</authors>
<title>A discriminative framework for bilingual word alignment.</title>
<date>2005</date>
<booktitle>In Proc. HLT-EMNLP,</booktitle>
<pages>81--88</pages>
<location>Vancouver, Canada.</location>
<contexts>
<context position="2389" citStr="Moore, 2005" startWordPosition="360" endWordPosition="361">ation error over a development corpus for which manually translated references are available (Och, 2003). As a separate first stage of the process, alignment is not in practice directly tuned in function of the machine translation task. Tuning alignment for an MT system is subject to practical difficulties. Unsupervised systems (Och and Ney, 2003; Liang et al., 2006) are based on generative models trained with the EM algorithm. They require large computational resources, and incorporating new features is difficult. In contrast, adding new features to some supervised systems (Liu et al., 2005; Moore, 2005; Ittycheriah and Roukos, 2005) is easy, but the need of annotated data is a problem. A more general difficulty, however, is that of finding an alignment evaluation metric favoring alignments which benefit Machine Translation. The fact that the required alignment characteristics depend on each particular system makes it even more difficult. It seems that high precision alignments are better for phrase-based SMT (Chen and Federico, 2006; Ayan and Dorr, 2006), whereas high recall alignments are more suited to N-gram SMT (Mari˜no et al., 2006). In this context, alignment quality improvements does</context>
<context position="4420" citStr="Moore (2005)" startWordPosition="675" endWordPosition="676"> criterion. Thus we just need a reference aligned at the sentence level instead of link labels at the word level. The paper is structured as follows. Section 2 explains the models used in our word aligner, focusing on the features designed to account for the specificities of the SMT system. In section 3, our minimum error training procedure is described and experimental results are shown. Finally, some concluding remarks and lines of further research are given. 2 Bilingual Word Aligner For versatility and efficiency requirements, we implemented BIA, a BIlingual word Aligner similar to that of Moore (2005). BIA consists in a beamsearch decoder searching, for each sentence pair, the alignment which minimizes the cost of a linear combination of various models. The differences with the system of Moore lie in the features, which we specially designed to suit our translation system (Ngram SMT (Mari˜no et al., 2006)). Its particularity is the translation model, which is based on a 4-gram language model of bilingual units referred to as tuples. Two issues regarding this translation model can be dealt with at the alignment stage. Firstly, in order to estimate the bilingual n-gram model, only one monoto</context>
</contexts>
<marker>Moore, 2005</marker>
<rawString>Robert C. Moore. 2005. A discriminative framework for bilingual word alignment. In Proc. HLT-EMNLP, pages 81–88, Vancouver, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A comparison of alignment models for statistical machine translation.</title>
<date>2000</date>
<booktitle>In Proc. COLING,</booktitle>
<pages>1086--1090</pages>
<contexts>
<context position="3168" citStr="Och and Ney, 2000" startWordPosition="480" endWordPosition="483">ion metric favoring alignments which benefit Machine Translation. The fact that the required alignment characteristics depend on each particular system makes it even more difficult. It seems that high precision alignments are better for phrase-based SMT (Chen and Federico, 2006; Ayan and Dorr, 2006), whereas high recall alignments are more suited to N-gram SMT (Mari˜no et al., 2006). In this context, alignment quality improvements does not necessarily imply translation quality improvements. This is in agreement with the observation of a poor correlation between word alignment error rate (AER (Och and Ney, 2000)) and automatic translation evaluation metrics (Ittycheriah and Roukos, 2005; Vilar et al., 2006). Proceedings of NAACL HLT 2007, Companion Volume, pages 85–88, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics Recently some alignment evaluation metrics have been proposed which are more informative when the alignments are used to extract translation units (Fraser and Marcu, 2006; Ayan and Dorr, 2006). However, these metrics assess translation quality very indirectly. In this paper, we propose a novel framework for discriminative training of alignment models with autom</context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>Franz Josef Och and Hermann Ney. 2000. A comparison of alignment models for statistical machine translation. In Proc. COLING, pages 1086–1090, Saarbrucken,Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>Dicriminative training and maximum entropy models for statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>295--302</pages>
<location>Philadelphia, PA.</location>
<contexts>
<context position="1453" citStr="Och and Ney, 2002" startWordPosition="215" endWordPosition="218"> evaluation metrics, and an improvement of translation quality is observed. 1 Introduction In the first SMT systems (Brown et al., 1993), word alignment was introduced as a hidden variable of the translation model. When word-based translation models have been replaced by phrase-based models (Zens et al., 2002), alignment1 and translation model training have become two separated tasks. The system of Brown et al. was based on the noisy channel approach. Present SMT systems use a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented (Och and Ney, 2002). Within this 1Hereinafter, alignment will refer to word alignment, unless otherwise stated. 85 new framework translation quality can be tuned by adjusting the weight of each feature function in the log-linear combination. In order to improve translation quality, this tuning can be effectively performed by minimizing translation error over a development corpus for which manually translated references are available (Och, 2003). As a separate first stage of the process, alignment is not in practice directly tuned in function of the machine translation task. Tuning alignment for an MT system is s</context>
</contexts>
<marker>Och, Ney, 2002</marker>
<rawString>F.J. Och and H. Ney. 2002. Dicriminative training and maximum entropy models for statistical machine translation. In Proc. ACL, pages 295–302, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="2126" citStr="Och and Ney, 2003" startWordPosition="316" endWordPosition="319"> alignment, unless otherwise stated. 85 new framework translation quality can be tuned by adjusting the weight of each feature function in the log-linear combination. In order to improve translation quality, this tuning can be effectively performed by minimizing translation error over a development corpus for which manually translated references are available (Och, 2003). As a separate first stage of the process, alignment is not in practice directly tuned in function of the machine translation task. Tuning alignment for an MT system is subject to practical difficulties. Unsupervised systems (Och and Ney, 2003; Liang et al., 2006) are based on generative models trained with the EM algorithm. They require large computational resources, and incorporating new features is difficult. In contrast, adding new features to some supervised systems (Liu et al., 2005; Moore, 2005; Ittycheriah and Roukos, 2005) is easy, but the need of annotated data is a problem. A more general difficulty, however, is that of finding an alignment evaluation metric favoring alignments which benefit Machine Translation. The fact that the required alignment characteristics depend on each particular system makes it even more diffi</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>F.J. Och and H. Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>160--167</pages>
<contexts>
<context position="1882" citStr="Och, 2003" startWordPosition="279" endWordPosition="280"> channel approach. Present SMT systems use a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented (Och and Ney, 2002). Within this 1Hereinafter, alignment will refer to word alignment, unless otherwise stated. 85 new framework translation quality can be tuned by adjusting the weight of each feature function in the log-linear combination. In order to improve translation quality, this tuning can be effectively performed by minimizing translation error over a development corpus for which manually translated references are available (Och, 2003). As a separate first stage of the process, alignment is not in practice directly tuned in function of the machine translation task. Tuning alignment for an MT system is subject to practical difficulties. Unsupervised systems (Och and Ney, 2003; Liang et al., 2006) are based on generative models trained with the EM algorithm. They require large computational resources, and incorporating new features is difficult. In contrast, adding new features to some supervised systems (Liu et al., 2005; Moore, 2005; Ittycheriah and Roukos, 2005) is easy, but the need of annotated data is a problem. A more </context>
</contexts>
<marker>Och, 2003</marker>
<rawString>F.J. Och. 2003. Minimum error rate training in statistical machine translation. In Proc. ACL, pages 160–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Paul</author>
</authors>
<title>Overview of the IWSLT</title>
<date>2006</date>
<booktitle>In Proc. IWSLT,</booktitle>
<pages>1--15</pages>
<location>Kyoto, Japan.</location>
<contexts>
<context position="7210" citStr="Paul, 2006" startWordPosition="1151" endWordPosition="1152">ave a feature which counts the number of embedded word positions in an alignment. Figure 1: Word positions embedded in a tuple. In addition to the embedded word position feature, we used the same two distortion features as Moore to penalize reorderings in the alignment (one sums the number of crossing links, and the other one sums the amplitude of crossing links). We also used the 02 score (Gale and Church, 1991) as a word association model, and as a POS-tags association model. 3 Experimental Work For these experiments we used the ChineseEnglish data provided for IWSLT’06 evaluation campaign (Paul, 2006). The training set contains 46000 sentences (of 6.7 and 7.0 average length). Parameters were tuned over the development set (dev4) provided, consisting of 489 sentences of 11.2 words in average, with 7 references. Our test set was a selection of 500 sentences (of 6 words in average, with 16 references) among dev1, dev2 and dev3 sets. 86 3.1 Optimization Procedure Once the alignment models were computed, a set of optimal log-linear coefficients was estimated via the optimization procedure depicted in Figure 2. Figure 2: Optimization loop. The training corpus was aligned with a set of initial pa</context>
</contexts>
<marker>Paul, 2006</marker>
<rawString>Michael Paul. 2006. Overview of the IWSLT 2006 Evaluation Campaign. In Proc. IWSLT, pages 1–15, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James C Spall</author>
</authors>
<title>Multivariate stochastic approximation using a simultaneous perturbation gradient approximation.</title>
<date>1992</date>
<journal>IEEE Trans. Automat. Control,</journal>
<volume>37</volume>
<pages>341</pages>
<contexts>
<context position="8291" citStr="Spall, 1992" startWordPosition="1329" endWordPosition="1330"> optimization procedure depicted in Figure 2. Figure 2: Optimization loop. The training corpus was aligned with a set of initial parameters A,, ... , A7. This alignment was used to extract tuples and build a bilingual N-gram translation model (TM). A baseline SMT system, consisting of MARIE decoder and this translation model as unique feature2, was used to produce a translation (OUT) of the development source set. Then, translation quality over the development set is maximized by iteratively varying the set of coefficients. The optimization procedure was performed by using the SPSA algorithm (Spall, 1992). SPSA is a stochastic implementation of the conjugate gradient method which requires only two evaluations of the objective function. It was observed to be more robust than the Downhill Simplex method when tuning SMT coefficients (Lambert and Banchs, 2006). Each function evaluation required to align the training corpus and build a new translation model. The algorithm converged after about 80 evaluations, lasting each 17 minutes with a 3 GHz processor. Alignment decoding was performed with a beam of 10 (it took 50 seconds and required 8 MB memory). Finally, the corpus was aligned with the optim</context>
</contexts>
<marker>Spall, 1992</marker>
<rawString>James C. Spall. 1992. Multivariate stochastic approximation using a simultaneous perturbation gradient approximation. IEEE Trans. Automat. Control, 37:332– 341.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Vilar</author>
<author>Maja Popovic</author>
<author>Hermann Ney</author>
</authors>
<title>AER: Do we need to ”improve” our alignments?</title>
<date>2006</date>
<booktitle>In Proc. IWSLT,</booktitle>
<pages>205--212</pages>
<location>Kyoto, Japan.</location>
<contexts>
<context position="3265" citStr="Vilar et al., 2006" startWordPosition="493" endWordPosition="496">gnment characteristics depend on each particular system makes it even more difficult. It seems that high precision alignments are better for phrase-based SMT (Chen and Federico, 2006; Ayan and Dorr, 2006), whereas high recall alignments are more suited to N-gram SMT (Mari˜no et al., 2006). In this context, alignment quality improvements does not necessarily imply translation quality improvements. This is in agreement with the observation of a poor correlation between word alignment error rate (AER (Och and Ney, 2000)) and automatic translation evaluation metrics (Ittycheriah and Roukos, 2005; Vilar et al., 2006). Proceedings of NAACL HLT 2007, Companion Volume, pages 85–88, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics Recently some alignment evaluation metrics have been proposed which are more informative when the alignments are used to extract translation units (Fraser and Marcu, 2006; Ayan and Dorr, 2006). However, these metrics assess translation quality very indirectly. In this paper, we propose a novel framework for discriminative training of alignment models with automated translation metrics as maximization criterion. Thus we just need a reference aligned at the </context>
</contexts>
<marker>Vilar, Popovic, Ney, 2006</marker>
<rawString>David Vilar, Maja Popovic, and Hermann Ney. 2006. AER: Do we need to ”improve” our alignments? In Proc. IWSLT, pages 205–212, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Zens</author>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>Phrase-based statistical machine translation.</title>
<date>2002</date>
<booktitle>Proc. German Conf. on Artificial Intelligence (KI).</booktitle>
<editor>editor,</editor>
<publisher>In Springer Verlag,</publisher>
<contexts>
<context position="1146" citStr="Zens et al., 2002" startWordPosition="167" endWordPosition="170">ramework for discriminative training of alignment models with automated translation metrics as maximization criterion. In this approach, alignments are optimized for the translation task. In addition, no link labels at the word level are needed. This framework is evaluated in terms of automatic translation evaluation metrics, and an improvement of translation quality is observed. 1 Introduction In the first SMT systems (Brown et al., 1993), word alignment was introduced as a hidden variable of the translation model. When word-based translation models have been replaced by phrase-based models (Zens et al., 2002), alignment1 and translation model training have become two separated tasks. The system of Brown et al. was based on the noisy channel approach. Present SMT systems use a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented (Och and Ney, 2002). Within this 1Hereinafter, alignment will refer to word alignment, unless otherwise stated. 85 new framework translation quality can be tuned by adjusting the weight of each feature function in the log-linear combination. In order to improve translation quality, this tuning can be effectivel</context>
</contexts>
<marker>Zens, Och, Ney, 2002</marker>
<rawString>R. Zens, F.J. Och, and H. Ney. 2002. Phrase-based statistical machine translation. In Springer Verlag, editor, Proc. German Conf. on Artificial Intelligence (KI).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>