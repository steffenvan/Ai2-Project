<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.903238">
A Lazy Way to Chart-Parse with Categorial Grammars
</title>
<note confidence="0.96731975">
•
Remo Pareschi and Mark Steedmant
Dept. of Al and Centre for Cognitive Science, Univ. of Edinburgh,*t
and Dept. of Computer and Information Science, Univ. of Pennsylvaniat
</note>
<sectionHeader confidence="0.926299" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999687772727273">
There has recently been a revival of interest in Categorial
Grammars (CG) among computational linguists. The various
versions noted below which extend pure CG by including
operations such as functional composition have been claimed
to offer simple and uniform accounts of a wide range of natural
language (NL) constructions involving bounded and
unbounded &amp;quot;movement&amp;quot; and coordination &amp;quot;reduction&amp;quot; in a
number of languages. Such grammars have obvious advan-
tages for computational applications, provided that they can be
parsed efficiently. However, many of the proposed extensions
engender proliferating semantically equivalent surface syntac-
tic analyses. These &amp;quot;spurious analyses&amp;quot; have been claimed to
compromise their efficient parseability.
The present paper describes a simple parsing algorithm for our
own &amp;quot;combinatory&amp;quot; extension of CG. This algorithm offers a
uniform treatment for &amp;quot;spurious&amp;quot; syntactic ambiguities and the
&amp;quot;genuine&amp;quot; structural ambiguities which any processor must
cope with, by exploiting the associativity of functional compo-
sition and the procedural neutrality of the combinatory rules
of grammar in a bottom-up, left-to-right parser which delivers
all semantically distinct analyses via a novel unification-based
extension of chart-parsing.
</bodyText>
<sectionHeader confidence="0.909308" genericHeader="keywords">
1. Combinatory Categorial Grammars
</sectionHeader>
<bodyText confidence="0.9997556875">
&amp;quot;Pure&amp;quot; categorial grammar (CC) is a grammatical notation,
equivalent in power to context-free grammars, which puts all
syntactic information in the lexicon, via the specification of all
grammatical entities as either functions or arguments. For
example, such a grammar might capture the obvious intuitions
concerning constituency in a sentence like John must leave by
identifying the VP leave and the NP John as the arguments of
the tensed verb must, and the verb itself as a function combin-
ing to its right with a VP, to yield a predicate -- that is, a
leftward-combining function-from-NPs-into-sentences. One
common &amp;quot;slash&amp;quot; notation for the types of such functions
expresses them as triples of the form &lt;result, direction, argu-
ment&gt;, where result and argument are themselves syntactic
types, and direction is indicated by &amp;quot;I&amp;quot; (for rightward-
combining functions) or &apos;V (for leftward). Must then gets the
following type-assignment
</bodyText>
<listItem confidence="0.573654">
(1) must:— (S\NP) /VP
</listItem>
<bodyText confidence="0.997883">
In pure categorial grammar, the only other element is a single
&amp;quot;combinatory&amp;quot; rule of Functional Application, which gives
rise to the following two instances:1
</bodyText>
<listItem confidence="0.481487">
(2) a. Rightward Application:
</listItem>
<sectionHeader confidence="0.951290666666667" genericHeader="introduction">
X X/Y Y
b. Leftward Application:
X Y X\Y
</sectionHeader>
<bodyText confidence="0.999817">
These rules allow functions to combine with immediately adja-
cent arguments in the obvious way, to yield the obvious sur-
face structures and interpretations, as in:
</bodyText>
<listItem confidence="0.579464">
(3) John must leave
NP (S \ NP ) /VP VP
</listItem>
<bodyText confidence="0.944635090909091">
&gt;apply
S\NP
&lt;apply
Combinatory Categorial Grammar (CCG) (Ades and Steedman
1982, Steedman 1985, Steedman 1986) adds a number of
further elementary operations on functions and arguments to
the combinatory component. These operations correspond to
certain of the primitive combinators used by Curry and Feys
(1958) to define the foundations of the .-calculus, notably
including functional composition and &amp;quot;type raising&amp;quot;. For
example:
</bodyText>
<listItem confidence="0.7682995">
(4) a. Subject Type Raising:
S/(S\NP) --&gt; NP
b. Rightward Composition:
X/Z ==&gt; X/Y Y/Z
</listItem>
<bodyText confidence="0.9990744">
These combinatory operations allow additional, non-standard
&amp;quot;surface structures&amp;quot; like the following, which arises from the
type-raising of the subject John into a function over predicates,
which composes with the verb, which is of course a function
into predicates:
</bodyText>
<figure confidence="0.721919571428572">
(5) John must leave
NP (S\NP) /VP VP
&gt;raise
S/ (S\NP)
&gt;compose
S /VP
&gt;apply
</figure>
<bodyText confidence="0.998439">
In general, wherever orthodox surface structure posits a right
branching structure like (a) below, these new operations will
allow not only the left branching structure (b), but every mix-
ture of right- and left- branching in between:
</bodyText>
<footnote confidence="0.4378482">
(6) a.
1 All combinatory rules are written as productions in the
present paper, in contrast with the reduction rule notation used in the
earlier papers. The change is intended to aid comparison with other
unification-based grammars, and has no theoretical significance.
</footnote>
<page confidence="0.991493">
81
</page>
<figure confidence="0.87871875">
b. /S
X&apos;
Y &apos;#
A&apos; . . . C
</figure>
<bodyText confidence="0.99943138961039">
The linguistic motivation for including such operations, (and
the grounds for contesting the standard linguists&apos; view of sur-
face constituency), for details of which the reader is referred to
the bibliography, stems from the possibility of extracting over,
and also coordinating, a wide range of such non-standard com-
posed structures. A crucial feature of this theory of grammar is
that the novel operation of functional composition is associa-
tive so that all the novel analyses like (5) are semantically
equivalent to the relevant canonical analysis, like (3). On the
other hand, rules of type raising simply map arguments into
functions over the functions of which they are argument, pro-
ducing the same result, and thus are by themselves responsible
for no change in generative capacity; indeed, they can simply
be regarded as tools which enable functional composition to
operate in circumstances where one or both the constituents
which need to be combined initially are not associated with a
functional type, as when combining a subject NP with the verb
which follows it.
Grammars of this kind, and the related variety proposed by
Kartunnen (1986), achieve simplicity in the grammar of move-
ment and coordination at the expense of multiplying the
number of derivations according to which an unambiguous
string such as the sentence above can be parsed. While we
have suggested in earlier papers (Ades and Steedman 1982,
Pareschi 1986) that this property can be exploited for incre-
mental semantic interpretation and evaluation, a suggestion
which has been explored further by Haddock (1987) and Hin-
richs and Polanyi (1986), two potentially serious problems
arise from these spurious ambiguities. The first is the possibil-
ity of producing a whole set of semantically equivalent ana-
lyses for each reading of a given string. The second more
serious problem is that of efficiently coping with non-
determinism in the face of such proliferating ambiguity in sur-
face analyses.
The problem of avoiding equivalent derivations is common to
parsers of all grammars, even context-free phrase-structure
grammars. Since all the spurious derivations are by definition
semantically equivalent, the solution seems obvious: just find
one of them, say via a &amp;quot;reduce first&amp;quot; strategy of the kind pro-
posed by Ades and Steedman (1982). The problem with this
proposal arises from the fact that, assuming left-to-right pro-
cessing, Rightward Composition may preempt the construction
of constituents which are needed as arguments by leftward
combining functional types.2 Such a depth-first processor can-
not take advantage of standard techniques for eliminating
backtracking, such as chart-parsing (Kay, 1980), because the
subconstituents for the alternative analysis will not in general
have been built. For example, if we have produced a left-
branching analysis like (b) above, and then find that we need
the constituent X in analysis (a) (say to attach a modifier), we
will be forced to redo the entire analysis, since not one of the
subconstituents of X (such as Y) was a constituent under the
previous analysis. Nor of course can we afford a standard
breadth-first strategy. Karttunen (1986a) has pointed out that a
parser which associates a canonical interpretation structure
2 If we had chosen to process right-to-left, then an identical
problem would arise from the involvement of Leftward Composition.
with substrings in a chart can always distinguish a spurious
new analysis of the same string from a genuinely different
analysis: spurious analyses produce results that are the same
as one already installed on the chart. However, the spurious
ambiguity problem remains acute. In order to produce only the
genuinely distinct readings, it seems that all of the spurious
analyses must be explored, even if they can be discarded again.
Even for short strings, this can lead to an unmanageable
enlargement of the search space of the processor. Similarly,
the problem of reanalysis under backtracking still threatens to
overwhelm the parser. In the face of this problem Wittenburg
(1986) has recently argued that massive heuristic guidance by
strategies quite problematically related to the grammar itself
may be required to parse at all with acceptable costs in the face
of spurious ambiguities (see also Wittenburg, this conference.)
The present paper concerns an alternative unification-based
chart-parsing solution which is grammatically transparent, and
which we claim to be generally applicable to parsing &amp;quot;genuine&amp;quot;
attachment ambiguities, under extensions to CO which involve
associative operations.
</bodyText>
<sectionHeader confidence="0.977994" genericHeader="method">
2. Unification-based Combinatory Categorial Grammars
</sectionHeader>
<bodyText confidence="0.999864555555555">
As Karttunen (1986), Uszkoreit (1986), Wittenburg (1986),
and Zeevat et al. (1986) have noted, unification-based compu-
tational environments (Shieber 1986) offer a natural choice for
implementing the categories and combination rules of CGs,
because of their rigorously defined declarative semantics. We
describe below a unification-based realisation of CCG which is
both transparent to the linguistically motivated properties of
the theory of grammar and can be directly coupled to the pars-
ing methodology we offer further on.
</bodyText>
<subsectionHeader confidence="0.995425">
2.1. A Restricted Version of Graph-unification
</subsectionHeader>
<bodyText confidence="0.999934">
We assume, like all unification formalisms, that grammatical
constituents can be represented as feature-structures, which we
encode as directed acyclic graphs (dags). A dag can be either:
</bodyText>
<listItem confidence="0.7408945">
(i) a constant
(ii) a variable
</listItem>
<bodyText confidence="0.916814631578947">
(iii) a finite set of label-value pairs (features), where any
value is itself a dag, and each label is associated with
one and only one value
We use round brackets to define sets, and we notate features as
(label value]. We refer to variables with symbols starting with
capital letters, and to labels and constants with symbols start-
ing with lower-case letters. The following is an example of a
dag:
(7) ((a el
((c XJ
d f ) 1 )
Like other unification based grammars, we adopt dags as the
data-structures encoding categorial feature information
because of the conceptual perspicuity of their set-theoretic
definition. However, the variety of unification between dags
that we adopt is more restrictive than the one used in standard
graph-unification formalisms like PATR-2 (Shieber 1986), and
closely resembles term-unification as adopted in logic-
programming languages.
</bodyText>
<page confidence="0.99755">
82
</page>
<bodyText confidence="0.918737823529412">
We define unification by first defining a partial ordering of
subsumption over dags in a similar (albeit more restricted) way
to previous work discussed in Shieber (1986). A dag D1 sub-
sumes a dag D2 if the information contained in DI is a (not
necessarily proper) subset of the information contained in D2.
Thus, variables subsume all other dags, as they contain no
information at all. Conversely, a constant subsumes, and is
subsumed by, itself alone. Finally, subsumption between dags
which are feature-sets is defined as follows. We refer to two
feature-sets D1 and 1)2 as variants of each other if there is an
isomorphism a mapping each feature in DI onto a feature with
the same label in D,. Then a feature-set D1 subsumes a
feature-set D2 if and oMy if
(i) DI and D2 are variants; and
if cr(f, f ), where f is a feature in Di and f is a feanwe in
D2&apos; then the value off subsumes the value off&apos;.
The uniftcation of two dags DI and D2 is then defined as the
most general dag D which is subsumed by both DI and D2.
Like most other unification-based approaches, we assume that
from a procedural point of view, the process of obtaining the
unification of two dags D1 and D2 requires that they be des-
tructively modified to become the same dag D. (We also use
the term unification to refer to this process.)
For example let D1 and D2 be the two following dags:
(8) ((a ab c])] ((a Y
[ d g [ d Z
[ e X) ) [e Z])
Then the following din is the unification of DI and D2:
(9) ((a ((b c])]
(d g
[e gl)
However, under the present definition of unification, as
opposed to the more general PATR-2 definition, the above is
not the unification of the following pair of dags:
</bodyText>
<listItem confidence="0.633742">
(10) ((a ((b c) ) ) ( [ d Z
(d g]) (e Z])
</listItem>
<bodyText confidence="0.999988428571428">
These two dags are not unifiable in present terms, because
under the above definition of subsumption, unification of two
feature sets can only succeed if they are variants. It follows
that a dag resulting from unification must have the same
feature population as the two feature structures that it unifies.
The present definition of unification thus resembles term unifi-
cation in invariably yielding a feature-set with exactly the
same structure as both of the input feature-sets, via the instan-
tiation of variables. The only difference from standard term
unification is that it is defined over dags, rather than standard
terms. By contrast, standard graph-unification can yield a
feature-set containing features initially entirely missing from
one or other of the unified feature-sets. The significance of this
point will emerge later on, in the discussions of the procedural
neutrality of combinatory rules in section 2.4, and of the
related transparency property of functional categories in sec-
tion /3. Since the properties in question inhere to the gram-
mar itself, to which unification is merely transparent, there is
nothing in our approach that is incompatible with the more
general definition of graph unification offered by PATR-2.
However, in order to establish the correctness of our proposal
for efficient parsing of extended categorial grammars using the
more general definition, we would have had to neutralise its
greater power with more laborious constraints on the encoding
of entries in the categorial lexicon as dags than those we actu-
ally require below. The more restricted version we propose
preserves most of the advantages of graph over term data-
structures pointed out in Shieber (1986).&apos;
</bodyText>
<subsectionHeader confidence="0.826593">
2.2. Categories as Features Structures
</subsectionHeader>
<bodyText confidence="0.9999895">
We encode constituents corresponding to non-functional
categories, such as the noun-phrases below, as feature-sets
defining the three major attributes syntax, phonology and
semantics, abbreviated for reasons of space to syn, pho, and
sem (the examples of feature-based categories given below are
of course simplified for the purposes of concise exposition --
for instance, we omit any specification of agreement informa-
tion in the value associated with the syn(tax) label):
</bodyText>
<listItem confidence="0.932733833333333">
(11) John ([syn np]
[pho John]
[sem john&apos;])
(12) Mary : — ((syn np]
[pho miry]
[sem mary&apos;l)
</listItem>
<bodyText confidence="0.941145147058824">
Constituents corresponding to functional categories are
feature-sets characterized by a triple of attributes, result, direc-
tion, and argiunent, abbreviated to res, dir, and arg. The value
associated with dir(ection) can be instantiated to one of the
constants / and \ and the values associated with res(ult) and
arg(ument) can be associated with any functional or non-
functional category. (Thus our functions are &amp;quot;curried&amp;quot;, and
may be higher order.)
We impose the simple but crucial requirement of transparency
over the well-fonnedness of functional categories in feature-
based CCG. Intuitively, this requirement corresponds to the
idea that any change to the structure of the value of arg(ument)
caused by unification must be reflected in the value of res( ult).
Given the definition of unification in the section above, this
requirement can be simply stated as follows:
(13) Functional categories must be transparent, in the sense
that every uninstantiated feature in the value of a
function&apos;s arg(ument) feature — that is, every feature
whose value is a variable -- must share that variable
value with some feature in the value of the function&apos;s
res(ult) feature.
Thus, whenever a feature in a function&apos;s arg(ument) is instan-
tiated by unification, some other feature in its res( ult) will be
instantiated identically, as a side-effect of the destructive
replacement of structures imposed by unification. Variables in
the value of the arg(ument) of a functional category therefore
have the sole effect of increasing the specificity of the informa-
tion contained in the value of its res(ult). As the combinatory
rules of CCG build new constituents exclusively in terms of
information already contained in the categories that they com-
bine, a requirement that all the functional categories in the lex-
icon be transparent in turn guarantees the transparency of any
functional category assigned to complex constituents generated
by the grammar.
</bodyText>
<page confidence="0.879021">
3
</page>
<bodyText confidence="0.7251385">
Calder (1987) and Thompson (1987) have independently
motivated similar approaches to constraining unification in encoding
</bodyText>
<page confidence="0.993932">
83
</page>
<bodyText confidence="0.995377666666667">
The following feature-based functional category for a lexical
transitive tensed verb obeys the transparency requirement (the
operator * indicates string concatenation):
</bodyText>
<figure confidence="0.950294928571429">
(14) loves :
([res ((res ( [syn 5]
[pho P1*loves*22]
[sem ([act loving]
[agent Si]
[patient S2] /])]
[dir \]
[arg ([syn np]
[pho Pl]
[sem Si])]
[dir I]
[arg ([syn np]
[pho P2]
[sem S2])]
</figure>
<bodyText confidence="0.988060846153846">
When two adjacent feature-structures corresponding to a func-
tion category X1 and an argument X2 are combined by func-
tional application, a new feature-structure X0 is constructed by
unifying the argument feature-structure X2 with the value of
the arg( ument) in the function feature structure X1. The result
X0 is then unified with the res(ult) of the function. For exam-
ple, Rightward Application can be expressed in a notation
adapted from PATR-2 as follows. We use the notation
1&gt; for a path of feature labels of length n, and we identify as
In&gt;) the value associated with the feature identified
by the path &lt;li ... In&gt; in the dag corresponding to a category
X. We indicate unification with the equality sign, =. Right-
ward Application can then be written as:
</bodyText>
<listItem confidence="0.788702">
(15) Rightward Application:
</listItem>
<equation confidence="0.93728325">
Xo --&gt; X1 X2
X1(&lt;direction&gt;) ■ /
X1 (&lt;arg&gt;) X2
X1 (&lt;result&gt;) XO
</equation>
<bodyText confidence="0.996952">
Application of this rule to the functional feature-set (14) for the
transitive verb loves and the feature-set (12) for the noun-
phrase Mary yields the following structure for the verb-phrase
</bodyText>
<figure confidence="0.759848727272727">
loves Mary
(16) loves Mary:-.
([res ([syn s]
[pho Pl*loves*mary]
[sem ([act loving]
[agent Si]
[patient mary&apos;] )])]
[dir \]
[arg ((syn np]
[pho P1]
[sem Sl] ) ]
</figure>
<bodyText confidence="0.9063696">
To rightward-compose two functional categories according to
rule (4b), we similarly unify the appropriate arg(iunent) and
res( ult) features of the input functions according to the follow-
ing rule:
linguistic theories.
</bodyText>
<listItem confidence="0.562941">
(17) Rightward Composition:
</listItem>
<equation confidence="0.989332285714286">
Xo X1 X2
(&lt;direction&gt;) ■ /
(&lt;direction&gt;) = /
(&lt;arg&gt;) X2 (&lt;result&gt;)
(&lt;direction&gt;) X0 (&lt;direction&gt;)
(&lt;result&gt;) X0 (&lt;result&gt;)
(&lt;arg&gt;) = X0 (&lt;arg&gt;)
</equation>
<bodyText confidence="0.980291">
For example, suppose that the non-functional feature-set
(11) for the noun-phrase John is type-raised into the following
functional feature-set, according to rule (4a), whose
unification-based version we omit here:
</bodyText>
<figure confidence="0.93320548">
(18) John
Urea ( (syn a]
[pho P]
[sem S] ) ]
[(lir I]
[arg (Cres ([syn a]
[pho P]
[sem S])]
[dir \]
[arg ([syn np]
[pho john]
[sem john&apos;])])])
Then (18) can be combined by Rightward Composition with
(14) to obtain the following feature structure for the functional
category corresponding to John loves:
(19) John loves:=
( [res [(syn s]
[pho john*loves*P2]
[sem ([act loving]
[agent john&apos;]
[patient S2])3)]
[dir I]
[arg IsYn n13]
[pho P2]
[sem S2])])
</figure>
<bodyText confidence="0.883722">
Leftward-combining rules are defined analogously to the
rightward-combining rules above.
</bodyText>
<subsectionHeader confidence="0.858095">
2.3. Derivational Equivalence Modulo Composition
</subsectionHeader>
<bodyText confidence="0.995028666666667">
Let us denote the operations of applying and composing
categories by writing apply(X, Y) and comp(X. Y) respec-
tively. Then by the definition of the operations themselves,
and in particular because of the associativity of functional
composition, the following equivalences hold across type-
derivations:
</bodyText>
<figure confidence="0.508001166666667">
(20) apply (comp (X1,
— apply (Xi , X2&apos; ) X )
apply (X2, X3) )
3
(21) comp (comp (X4, X5&apos; ) X6)
comp (X4 , comp (X5, X6) )
</figure>
<bodyText confidence="0.9687045">
More formally, the left-hand side and right-hand side of both
equations define equivalent terms in the combinatory logic of
</bodyText>
<figure confidence="0.661427333333333">
Xix
X2
X2
X2
x1
2
</figure>
<page confidence="0.98354">
84
</page>
<bodyText confidence="0.9998684375">
Curry and Feys (1958).4 It follows that all alternative deriva-
tions of an arbitrary sequence of functions and arguments that
are allowed by different orders of application and composition
in which a composition is merely traded for andapplication also
define equivalent terms of Combinatory Logic.&amp;quot;
So, for instance, a type for the sentence John loves Mary can
be assigned either by rightward-composing the type-raised
function John, (18), with loves, (14), to obtain the feature-
structure (19) for John loves, and then rightward applying
(19) to Mary, (12), to obtain a feature-structure for the whole
sentence; or, conversely, it can be assigned by rightward-
applying loves, (14), to Mary, (12), to obtain the feature-
structure (16) for loves Mary, and then rightward-applying
John, (18), to (16) to obtain the final feature-structure. In both
cases, as the reader may care to verify, the type-assignment we
get is the following:
</bodyText>
<figure confidence="0.962791">
(22) John loves Mary: —
((syn s]
[pho john*loves*mary]
[sem ([act loving]
[agent john&apos;]
[patient mary&apos;])])
</figure>
<bodyText confidence="0.999554722222222">
An important property of CCG is that it unites syntactic and
semantic combination in uniform operations of application and
composition. Unification-based CCG makes this identification
explicit by uniting the syntactic type of a constituent and its
interpretation in a single feature-based type. It follows that all
derivations for a given string induced by functional composi-
tion correspond to the same unique feature-based type, whicb
cannot be assigned to any other constituent in the grammar.°
This property, which we characterize formally elsewhere, is a
direct consequence of the fact that unification is itself an asso-
ciative operation.
It follows in turn that a feature-based category like (22) associ-
ated with a given constituent not only contains all the informa-
tion necessary for its grammatical interpretation, but also
determines an equivalence class of derivations for that consti-
tuent, a point which is related to Kartnmen&apos;s (1986) proposal
for the spurious ambiguity problem (cf. secn. 1 above), but
which we exploit differently, as follows.
</bodyText>
<subsectionHeader confidence="0.986811">
2.4. Procedural Neutrality of Combinatory Rules
</subsectionHeader>
<bodyText confidence="0.9165486">
The rules of combinatory categorial grammar are purely
declarative, and unification preserves this property, so that, as
with other unification-based grammatical formalisms (cf.
Shieber 1986), there is no procedural constraint on their use.
So far, we have only considered examples in which such rules
are applied &amp;quot;bottom-up&amp;quot;, as in example (16), in which the rule
of application (15) is used to define the feature structure X0 on
the left-hand side of the rule in terms of the feature structures
4 The terms are equivalent in the technical sense that they
reduce to an identical normal form.
</bodyText>
<sectionHeader confidence="0.851278" genericHeader="method">
5
</sectionHeader>
<subsectionHeader confidence="0.976059">
The inclusion of certain higher-order function categories in
</subsectionHeader>
<bodyText confidence="0.9997976">
the lexicon (of which &amp;quot;modifiers of modifiers&amp;quot; like formerly would be
an example in English) means that composition may affect the argu-
ment structure itself, thereby changing meaning and giving rise to
non-equivalent terms. This possibility does not affect the present pro-
posal, and can be ignored.
</bodyText>
<page confidence="0.956982">
6
</page>
<bodyText confidence="0.973127959183674">
If there is genuine ambiguity, a constituent will of course be
assigned more than one type.
X1 and X2 on the right, respectively instantiated as the func-
tion loves (14) and its argument Mary 02). However, other
procedural realizations are equally viable.&apos; In particular, it is a
property of rules (15) and (17), (and of all the combinatory
rules permitted in the theory -- cf. Steedman 1986) that if any
two out of the three elements that they relate are specified, then
the third is entirely and uniquely determined. This property,
which we call procedural neutrality follows from the form of
the rules themselves and from the transparency property
(13) of functional categories, tinder the definition of unifica-
tion given in section 2.1 above.
This property of the grammar offers a way to short-circuit the
entire problem of non-determinism in a chart-based parser for
grammars characterised by spurious analyses engendered by
associative rules such as composition. The procedural neutral-
ity of the combinatory rules allows a processor to recover con-
stituents which are &amp;quot;implicit&amp;quot; in analysed constituents in the
sense that they would have been built if some other equivalent
analysis had happened to have been the one followed by the
processor. For example, consider the situation where, faced
with the string John loves Mary dealt with in the last section,
the processor has avoided multiple analyses by composing
John, (18), with loves, (14), to obtain John loves, (19), and has
then applied that to Mary, (12), to obtain John loves Mary
(22), ignoring the other analysis. If the parser turns out to
need the constituent loves Mary, (16), (as it will if it is to find a
sensible analysis when the sentence turns out to be John loves
Mary madly), then it can recover that constituent by defining it
via the rule of Rightward Application in terms of the feature
structures for John loves Mary, (22), and John, (18). These two
feature structures can be used to respectively instantiate X0
and X in the rule as stated at (15). The reader may verify that
1
instantiating the rule in this way determines the required con-
stituent to be exactly the same category as (16).
This particular procedural alternative to the bottom-up invoca-
tion of combinatory rules will be central to the parsing algo-
rithm which we present in the following section, so it will be
convenient to give it a name. Since it is the &amp;quot;parent&amp;quot; category
X and the &amp;quot;left-constituent&amp;quot; category X1 that are instantiated,
. 0
it seems natural to call this alternative left-branch instantia-
tion of a combinatory rule, a term which we contrast with the
bottom-up instantiation invoked in earlier examples.
The significance of this point is as follows. Let us suppose
that we can guarantee that a parser will always make available,
say in a chart, the constituent that could have combined under
</bodyText>
<page confidence="0.478348">
7
</page>
<bodyText confidence="0.971017176470588">
There is an obvious analogy here with the fact that
unification-based programming languages like Prolog do not have any
predefined distinction between the input and the output parameters of a
given procedure.
8 From a formal point of view, procedural neutrality is a conse-
quence of the fact that unification-based combinatory rules, as charac-
terised above, are extensional. Thus, we follow Pereira and Shieber
(1984) in claiming that the &amp;quot;bottom-up&amp;quot; realization of a unification-
based rule r corresponds to the unification of a structure Er encoding
the equational constraints of r, and a structure Dr corresponding to the
merging of the structures instantiating the elements of the right-hand
side of r. A structure N,is consequently assigned as the instantiation of
the left-hand side of r by individuating a relevant substructure of the
unification of the pair &lt;Dr, E,&gt;. If r is a rule of unification-based
CCG, then the fact that Nr th instantiation of the left-hand side of,
both in terms of &lt;Dr, Er&gt; and &lt;D &apos; , E,&gt; guarantees that Dr and Dr&apos;
are identical (in the sense that they subsume each other).
</bodyText>
<page confidence="0.999453">
85
</page>
<bodyText confidence="0.999858285714286">
bottom-up instantiation as a left-constituent with an implicit
right-constituent to yield the same result as the analysis that
was actually followed. In that case, the processor will be able
to recover the implicit right-constituent by left-branch instan-
tiation of a single combinatory rule, without restarting syntac-
tic analysis and without backtracking or search of any kind.
The following algorithm does just that.
</bodyText>
<sectionHeader confidence="0.713855" genericHeader="method">
3. A Lazy Chart Parsing Methodology
</sectionHeader>
<bodyText confidence="0.999273363636364">
Derivational equivalence modulo composition, together with
the procedural neutrality of unification-based combinatory
rules, allows us to define a novel generalisation of the classic
chart parsing technique for extended CGs, which is &amp;quot;lazy&amp;quot; in
the sense that:
a) only edges corresponding to one of the set of semanti-
cally equivalent analyses are installed on the chart;
b) surface constituents of already parsed parts of the input
which are not on the chart are directly generated from
the structures which are, rather than being built from
scratch via syntactic reanalysis.
</bodyText>
<subsectionHeader confidence="0.997817">
3.1. A Bottom-up Left-to-Right Algorithm
</subsectionHeader>
<bodyText confidence="0.982732195652174">
The algorithm we decribe here implements a bottom-up, left-
to-right parser which delivers all semantically distinct ana-
lyses. Other algorithms based on alternative control strategies
are equally feasible. In this specific algorithm, the distinction
between active and inactive edges is drawn in a rather different
way from the standard one. For an edge E to be active does not
meanthat it is associated with an incomplete constituent
(indeed, the distinction between complete and incomplete con-
stituents is eliminated in CCG); it simply means that E can
trigger new actions of the parser to install other edges, after
which E itself becomes inactive. By contrast, inactive edges
cannot initiate modifications to the state of the parser.
Active edges can be added to the chart according to the three
following actions:
Scanning: if a is a word in the input string then, for
each lexical entry X associated with a, add an active
edge labeled X spanning the vertices corresponding to
the position of a on the chart.
Lifting: if E1 is an active edge labeled X1, then for
every unary rule of type raising which can be instan-
tiated as X X add an active edge E0 labeled X0
.0 1 .
and spanning the same vertices of El.
Reducing: if an edge E2 labeled X2 has a left-adjacent
edge E1 labeled Xi and there is a combinatory rule
which can be instantiated as X =---&gt; X X- then add
0 . 1 —2
an active edge E0 labeled X0 spanning the starting ver-
tex of E and the ending vertex E2.
1
The operational meaning of Scanning and Lifting should be
clear enough. The Reducing action is the workhorse of the
parser, building new constituents by invoking combinatory
rules via bottom-up instantiation. Whenever Reducing is
effected over two edges El and E2 to obtain a new edge E0 we
ensure that:
El is marked as a left-generator of E0. If the rule in the
grammar which was used is Rightward Composition,
then E2 is marked as a right-generator of E0.
The intuition behind this move is that right-generators are
rightward functional categories which have been composed
into, and will therefore give rise to spurious analyses if they
take part in further rightward combinations, as a consequence
of the property of derivational equivalence modulo composi-
tion, discussed in section 2.3. Left-generators correspond
instead to choice points from where it would have been possi-
ble to obtain a derivationally different but semantically
equivalent constituent analysis of some part of the input string.
They thus constitute suitable constituents for use in recovering
implicit right-constituents of other constituents in the chart via
the invocation of combinatory rules under the procedure of
left-branch instantiation discussed in the last section.
In order to state exactly how this is done, we need to introduce
the left-starter relation, corresponding to the transitive closure
of the left-generator relation:
(i) A left-generator L of an edge E is a left-starter of E.
(ii) If L is a left-starter of E, then any left-starter of L is a
left-starter of E.
The parser can now add inactive edges corresponding to impli-
cit right-constituents according to the following action:
Revealing: if an edge E is labeled by a leftward-looking
functional type X and there is a combinatory rule which
can be instantiated as X&apos; =&gt;X2 X then if
(i) there is an edge E0 labeled Xn left-adjacent to E
E0 has a left-starter El labelea X1
(iii) there is a combinatory rule which can be instantiated
as X0 XI X2
then add to the chart an inactive edge E2 labeled X2
spanning the ending vertex of Ei and the starting vertex
of E, unless there is already an sage labelled in the same
way and spanning the same vertices. Mark El as a
right-generator of Eo if the rule used in (iii) was-Right-
ward Composition.
To summarise the section so fan if the parser is devised so as
to avoid putting on the chart subconstituents which would lead
to redundant equivalent derivations, non-determinism in the
grammar will always give rise to cases which require some of
the excluded constituents. In a left-to-right processor this typi-
cally happens when the argument required by a leftward-
looking functional type has been mistakenly combined in the
analysis of a substring left-adjacent to that leftward-looking
type. However, such an implicit or hidden constituent could
have only been obtained through an equivalent derivation path
for the left-adjacent substring. It follows that we can &amp;quot;reveal&amp;quot;
it on the chart by invoking a combinatory rule in terms of left-
branch instantiation.
We can now informally characterize the algorithm itself as fol-
lows:
the parser does Scanning for each word in the input
string going left-to-right
moreover, whenever an active edge A is added to the
chart, then the following actions are taken in order
</bodyText>
<listItem confidence="0.946269">
(i) the parser does Lifting over A
(ii) if A is labeled by a leftward-looking type, then
for every edge E left-adjacent to A the parser does
Revealing over E with respect to A
</listItem>
<page confidence="0.994611">
86
</page>
<bodyText confidence="0.907608285714286">
(iii) for every edge E left-adjacent to A the parser does
Reducing over E and A, with the constraint that
if A is not labeled by a leftward-looking type then
E must not be a right-generator of any edge E&apos;
the parser returns the set of categories associated with
edges spanning the whole input, if such a set is not
empty; it fails otherwise.
</bodyText>
<subsectionHeader confidence="0.996151">
3.2. An Example
</subsectionHeader>
<bodyText confidence="0.999976846153846">
In the interests of brevity and simplicity, we eschew all details
to do with unification itself in the following examples of the
workings of the parser, reverting to the original categorial
notation for CCG of section 1, bearing in mind that the
categories are now to be read strictly as a shorthand for the
fuller notation of unification-based CCG. For similar reasons
of simplicity in exposition, we assume for the present purpose
that the only type-raising rule in the grammar is the subject
rule (4a).
The algorithm analyses the sentence John loves Mary madly as
follows. First, the parser Scans the rust word John, adding to
the chart an active NP edge corresponding to its sole lexical
entry, and spanning the word in question, thus:
</bodyText>
<sectionHeader confidence="0.915849" genericHeader="method">
(23) . John
NP
</sectionHeader>
<bodyText confidence="0.913381625">
(We adopt the convention that active edges are indicated by
upper-case categories, while inactive edges will be indicated
with lower-case categories.) Since the edge in question is
active, it falls under the second clause of the algorithm. The
Lifting condition (i) of this clause applies, since there is a rule
which type raises over NP, so a new active edge of type
S/(S\NP) is added, spanning the same word, John (no other
conditions apply to the NP active edge, and it becomes inac-
tive):
(24) S/ (S \NP)
_John
rip
Neither Lifting, Revealing, nor Reducing yield any new edges,
so the new active edge merely becomes inactive. The next
word is Scanned to add a new lexical active edge of type
(S\NP)/NP spanning loves:
</bodyText>
<sectionHeader confidence="0.495968" genericHeader="method">
(25) s/ (s\np)
oyes .
(SNP
</sectionHeader>
<bodyText confidence="0.943736741935484">
•
The new lexical edge Reduces with the type-raised subject to
yield a new active edge of type S/NP. The subject category is
marked as the new edge&apos;s left-generator, and (because the
combinatory rule was Rightward Composition) the verb
category is marked as its right-generator. Nothing more
results from loves, and neither Lifting, Revealing nor Reducing
yield anything from the new edge, so it too becomes inactive,
and the next word is Scanned to add a new lexical active NP
edge corresponding to Mary:
1 ove s
np (s np np NP
This edge yields two new active edges before becoming inac-
tive, one of type S/(S\NP) via Lifting and the subject rule, and
one of type S. via Reducing with the s/np edge to its left by the
Forward application rule (we omit the former from the illustra-
tion, because nothing further happens to it, but it is there
nonetheless):
(27) (s\np)
7212j:`.. loves
np (s\np)/np np
The s/np edge is in addition marked as the left generator of the
S. Note that Reducing would potentially have allowed a third
new active edge corresponding to loves Mary to be added by
Reducing the new active NP edge corresponding to Mary with
the left-adjacent (Anp)/np edge, loves. However, this edge has
been marked as a right generator, and is therefore not allowed
to Reduce by the algorithm.
Nothing new results from the new active S edge, so it becomes
inactive and the next word madly is scanned to add a new
active edge, thus.
</bodyText>
<figure confidence="0.841079666666667">
(28) / (s\np) s/np
loves . Mary
np (a \npUnp np (S \NTT\ (S \NP)
</figure>
<bodyText confidence="0.879728461538462">
This active edge, being a leftward-looking functional type, pre-
cipitates Revealing. Since there is a rule (Backward Applica-
tion, 2a) which would allow madly, (S\NP)\(S\NP) to combine
with a left-adjacent Anp, and there is a rule (Forwards Appli-
cation, 2a) which would allow a left-starter Johnsi(ftv) to
combine with such an Atm to yield the s which is lett-adjacent
to madly, (and since there is no left-adjacent Anp there
already), the rule of Forward Application can be invoked via
Left-branch Instantiation to Reveal the inactive edge loves
Mary, Anp:
(29) s/(s\np) &apos;-.(/np
madly_,-...
npiii)/np n (s \NP) \ (S \NP)
</bodyText>
<subsectionHeader confidence="0.735253">
S n
</subsectionHeader>
<bodyText confidence="0.99775025">
The (still) active backward modier madly can now Reduce
with the newly introduced Arm, to yield a new active edge
S\NP corresponding to loves Mary madly, before becoming
inactive:
</bodyText>
<figure confidence="0.45145725">
(30) s/ (s\np) /np
.77or-N-in . Ma
--
np WW-1P)/np n
</figure>
<bodyText confidence="0.987424285714286">
The new active edge potent&apos; y gives rise to two semantically
equivalent Reductions with the subject John to yield S -- one
with its ground np type, and one with its raised type, s/(Anp).
Only one of these is effected, because of a detail dealt with in
the next section, and the algorithm terminates with a single S
edge spanning the s
(31)-(s\npr---......s/n
</bodyText>
<sectionHeader confidence="0.433432" genericHeader="method">
.&apos;i&apos;-. love
</sectionHeader>
<bodyText confidence="0.875549833333333">
In an attachment-ambiguous sentence like the following, which
we leave as an exercise, two predicates, believes John loves
Mary and loves Mary, are revealed in the penultimate stage of
the analysis, and two semantically distinct analyses result
(32) Fred believes John loves Mary passionately
Space permits us no more than to note that this procedure will
</bodyText>
<figure confidence="0.9829194">
. .
(s \np) \ (s \np
S \ NP
np /np na,..01(s\np) \ (s\np
sAnp s \ np
</figure>
<page confidence="0.995716">
87
</page>
<bodyText confidence="0.9991436">
also cope with another class of constructions which constitute
a major source of non-determinism in natural language pars-
ing, namely the diverse coordinate constructions whose
categorial analysis is discussed by Dowty (1985) and Steed-
man (1985, 1987).
</bodyText>
<sectionHeader confidence="0.666383" genericHeader="method">
4. Type Raising and Spurious Ambiguity
</sectionHeader>
<bodyText confidence="0.999988928571429">
As noted at example (30) above, type raising rules introduce a
second kind of spurious ambiguity connected to the interac-
tions of such rules with functional application rather than func-
tional composition. If the processor can Reduce via a rule of
application on a type-raised category, then it can also always
invoke the opposite rule of application to the surmised version
of the same category to yield the same result. Spurious ambi-
guity of this kind is trivially easy to avoided, as (unlike the
kind associated with composition), it can always be detected
locally by the following redundancy check on attachment of
new edges to the chart in Reducing: when Reducing creates an
edge via functional application, then it is only added to the
chart if there is no edge associated with the same feature
structure and spanning the same vertices already on the chart.
</bodyText>
<sectionHeader confidence="0.9739335" genericHeader="method">
S. Alternative Control Strategies and Grammatical For-
malisms
</sectionHeader>
<bodyText confidence="0.999926857142857">
The algorithm described above is a pure bottom-up parsing
procedure which has a close relative in the Cocke-Kasami-
Younger algorithm for context-free phrase-structure grammars.
However, our chart-parsing methodology is completely open to
alternative control options. In particular, Pareschi (forthcom-
ing) describes an adaptation of the Earley algorithm, which, in
virtue of its top-down prediction stage, allows for efficient
application of more general type-raising rules than are con-
sidered here. Formal proofs of the correctness of both these
algorithms will be presented in the same reference.
The possibility of exploiting this methodology for improving
processing of other unification-based extensions of CG involv-
ing spurious ambiguity, like the one reported in Karttunen
(1986a), is also under exploration.
</bodyText>
<sectionHeader confidence="0.998952" genericHeader="conclusions">
6. Conclusion
</sectionHeader>
<bodyText confidence="0.999954571428571">
The above approach to chart-parsing with extensions to CGs
characterised by spurious ambiguities allows us to define algo-
rithms which do not build significantly more edges than chart
parsers for more standard theories of grammar. Our technique
is fully transparent with respect to our grammatical formalism,
since it is based on properties of associativity and procedural
neutrality inherent in the grammar itself.9
</bodyText>
<sectionHeader confidence="0.999769" genericHeader="acknowledgments">
ACKNOWLEDGEMENTS
</sectionHeader>
<reference confidence="0.9955239">
We thank Inge Bethke, Kit Fine, Ellen Hays, Aravind Joshi, Dale
Miller, Henry Thompson, Bonnie Lynn Webber, and Kent Wittenburg
for help and advice. Parts of the research were supported by: an Edin-
burgh University Research Studentship: an ESPRIT grant (project 393)
to CCS, Univ. Edinburgh; a Sloan Foundation grant to the Cognitive
Science Program, Univ. Pennsylvania; and NSF grant IRI-10413 A02,
ARO grant DAA6-29- 84K-0061 and DARPA grant N0014-85-K0018
to CIS, Univ. Pennsylvania.
9 Chmt parsers based on the methodology described here and
written in Quintus Prolog have been developed on a Sun workstation.
</reference>
<sectionHeader confidence="0.775111" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.999837050847458">
Ades, A. and Steedman, M. J. (1982) On the Order of Words.
Linguistics and Philosophy, 44,517-518.
Calder, J. (1987) Typed Unification for Natural Language
Processing. Ms, Univ. of Edinburgh
Curry, H. B. and Feys, R. (1958) Combinatory Logic,
Volume I. Amsterdam: North Holland.
Dowty, D. (1985). Type raising, functional composition and
non-constituent coordination. In R. Oehrle et al, (eds.),
Categorial Grammars and Natural Language Structures,
Dordrecht, Reidel. (In press).
Haddock. N. J. (1987) Incremental Interpretation and
Combinatory Categorial Grammar. In Proceedings of
the Tenth International Joint Conference on Artifi-
cial Intelligence, Milan, Italy, August, 1987.
Hinrichs, E. and Polariyi, L (1986) Pointing the Way. Papers
from the Parasession on Pragmatics and Grammatical
Theory at the Twenty-Second Regional Meeting of the
Chicago Linguistic Society, pp.298-314.
Karttunen. L. (1986) Radical Lexicalism. Paper presented at
the Conference on Alternative Conceptions of Phrase
Structure, July 1986, New York.
Kay, M. (1980) Algorithm Schemata and Data Structures in
Syntactic Processing. Technical Report No. CSL-80- 12,
XEROX Palo Alto Research Centre.
Pareschi. Remo. 1986. Combinatory Categorial Grammar,
Logic Programming, and the Parsing of Natural
Language. DAI Working Paper, University of Edinburgh.
Pareschi, R. (forthcoming) PhD Thesis, Univ. Edinburgh.
Pereira, F. C. N. and Shieber, S. M. (1984) The Semantics of
Grammar Formalisms Seen as Computer Languages. In
Proceedings of the 22nd Annual Meeting of the ACL,
Stanford, July 1984, pp.123-129.
Shieber, S. M. (1986) An Introduction to Unification-based
Approaches to Grammar, Chicago: Univ. Chicago Press.
Steadman, M. (1985) Dependency and Coordination in the
Grammar of Dutch and English. Language; 61, 523-568.
Steedman,M. (1986) Combinatory Grammars and Parasitic
Gaps. Natural Language and Linguistic Theory, to
appear.
Steedman, M. (1987) Coordination and Constituency in a
Combinatory Grammar. In Mark Baltin and Tony Kroch,
(eds.), Alternative Conceptions of Phrase Structure,
University of Chicago Press: Chicago. (To appear.)
Thompson, H. (1987) FBF - An Alternative to PATR as a
Grammatical Assembly Language. Research Paper,
Department of AI, Univ. Edinburgh.
Usikoreit, H. (1986) Categorial Unification Grammars. In
Proceedings of the 11th International Conference on
Computational Linguistics, Bonn, August, 1986, pp187-
194.
Wittenburg, K. W. (1986) Natural Language Parsing with
Combinatory Categorial Grammar in a Graph-
Unification-Based Formalism. PhD Thesis, Department
of Linguistics, University of Texas.
Zeevat, H., Klein. E. and Calder, J. (1987) An Introduction to
Unification Categorial Grammar. In N. Haddock et al.
(eds.), Edinburgh Working Papers in Cognitive Science,
1: Categorial Grammar, Unification Grammar, and Pars-
ing.
</reference>
<page confidence="0.999408">
88
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.016122">
<title confidence="0.92568">A Lazy Way to Chart-Parse with Categorial Grammars •</title>
<author confidence="0.518815">Pareschi</author>
<author confidence="0.518815">Mark</author>
<abstract confidence="0.997716885225887">of Al and Centre for Cognitive Science, Univ. of and Dept. of Computer and Information Science, Univ. of Pennsylvaniat ABSTRACT There has recently been a revival of interest in Categorial Grammars (CG) among computational linguists. The various versions noted below which extend pure CG by including operations such as functional composition have been claimed to offer simple and uniform accounts of a wide range of natural language (NL) constructions involving bounded and unbounded &amp;quot;movement&amp;quot; and coordination &amp;quot;reduction&amp;quot; in a number of languages. Such grammars have obvious advantages for computational applications, provided that they can be parsed efficiently. However, many of the proposed extensions engender proliferating semantically equivalent surface syntactic analyses. These &amp;quot;spurious analyses&amp;quot; have been claimed to compromise their efficient parseability. The present paper describes a simple parsing algorithm for our own &amp;quot;combinatory&amp;quot; extension of CG. This algorithm offers a uniform treatment for &amp;quot;spurious&amp;quot; syntactic ambiguities and the &amp;quot;genuine&amp;quot; structural ambiguities which any processor must cope with, by exploiting the associativity of functional composition and the procedural neutrality of the combinatory rules of grammar in a bottom-up, left-to-right parser which delivers all semantically distinct analyses via a novel unification-based extension of chart-parsing. 1. Combinatory Categorial Grammars &amp;quot;Pure&amp;quot; categorial grammar (CC) is a grammatical notation, equivalent in power to context-free grammars, which puts all syntactic information in the lexicon, via the specification of all grammatical entities as either functions or arguments. For example, such a grammar might capture the obvious intuitions constituency in a sentence like must leave the VP the NP as arguments of tensed verb the verb itself as a function combining to its right with a VP, to yield a predicate -that is, a leftward-combining function-from-NPs-into-sentences. One common &amp;quot;slash&amp;quot; notation for the types of such functions them as triples of the form direction, arguthemselves syntactic and is by &amp;quot;I&amp;quot; (for rightwardfunctions) or &apos;V (for leftward). gets the following type-assignment categorial grammar, the only other element is a single &amp;quot;combinatory&amp;quot; rule of Functional Application, which gives to the following two a. Application: X X/Y Y b. Leftward Application: X Y X\Y These rules allow functions to combine with immediately adjacent arguments in the obvious way, to yield the obvious surstructures and interpretations, as (3) John must leave NP (S \ NP ) /VP VP &gt;apply S\NP &lt;apply Combinatory Categorial Grammar (CCG) (Ades and Steedman 1982, Steedman 1985, Steedman 1986) adds a number of further elementary operations on functions and arguments to the combinatory component. These operations correspond to certain of the primitive combinators used by Curry and Feys (1958) to define the foundations of the .-calculus, notably including functional composition and &amp;quot;type raising&amp;quot;. For example: (4) a. Subject Type Raising: S/(S\NP) --&gt; NP b. Rightward Composition: X/Z ==&gt; X/Y Y/Z These combinatory operations allow additional, non-standard &amp;quot;surface structures&amp;quot; like the following, which arises from the of the subject into function over predicates, which composes with the verb, which is of course a function (5) John must leave (S\NP) VP &gt;raise &gt;compose S /VP &gt;apply In general, wherever orthodox surface structure posits a right branching structure like (a) below, these new operations will allow not only the left branching structure (b), but every mixrightand leftbranching in between: 1All combinatory rules are written as the paper, in contrast with the notation used in the earlier papers. The change is intended to aid comparison with other unification-based grammars, and has no theoretical significance. 81 b. /S X&apos; Y &apos;# A&apos; . . . C The linguistic motivation for including such operations, (and the grounds for contesting the standard linguists&apos; view of surface constituency), for details of which the reader is referred to bibliography, the possibility of extracting over, and also coordinating, a wide range of such non-standard composed structures. A crucial feature of this theory of grammar is the novel operation of functional composition is associathat all the novel analyses like (5) are semantically equivalent to the relevant canonical analysis, like (3). On the other hand, rules of type raising simply map arguments into functions over the functions of which they are argument, producing the same result, and thus are by themselves responsible for no change in generative capacity; indeed, they can simply be regarded as tools which enable functional composition to operate in circumstances where one or both the constituents which need to be combined initially are not associated with a functional type, as when combining a subject NP with the verb which follows it. Grammars of this kind, and the related variety proposed by Kartunnen (1986), achieve simplicity in the grammar of movement and coordination at the expense of multiplying the number of derivations according to which an unambiguous string such as the sentence above can be parsed. While we have suggested in earlier papers (Ades and Steedman 1982, 1986) that can be exploited for incremental semantic interpretation and evaluation, a suggestion which has been explored further by Haddock (1987) and Hinrichs and Polanyi (1986), two potentially serious problems arise from these spurious ambiguities. The first is the possibility of producing a whole set of semantically equivalent analyses for each reading of a given string. The second more serious problem is that of efficiently coping with nondeterminism in the face of such proliferating ambiguity in surface analyses. The problem of avoiding equivalent derivations is common to parsers of all grammars, even context-free phrase-structure grammars. Since all the spurious derivations are by definition equivalent, the solution just find one of them, say via a &amp;quot;reduce first&amp;quot; strategy of the kind proposed by Ades and Steedman (1982). The problem with this proposal arises from the fact that, assuming left-to-right pro- Composition may preempt the construction of constituents which are needed as arguments by leftward functional Such a depth-first processor cannot take advantage of standard techniques for eliminating backtracking, such as chart-parsing (Kay, 1980), because the subconstituents for the alternative analysis will not in general have been built. For example, if we have produced a leftbranching analysis like (b) above, and then find that we need the constituent X in analysis (a) (say to attach a modifier), we will be forced to redo the entire analysis, since not one of the of X (such as a constituent under the previous analysis. Nor of course can we afford a standard breadth-first strategy. Karttunen (1986a) has pointed out that a parser which associates a canonical interpretation structure If we chosen to process right-to-left, then an identical would arise from the involvement of with substrings in a chart can always distinguish a spurious new analysis of the same string from a genuinely different analysis: spurious analyses produce results that are the same as one already installed on the chart. However, the spurious ambiguity problem remains acute. In order to produce only the distinct readings, it seems that the spurious analyses must be explored, even if they can be discarded again. Even for short strings, this can lead to an unmanageable enlargement of the search space of the processor. Similarly, the problem of reanalysis under backtracking still threatens to overwhelm the parser. In the face of this problem Wittenburg (1986) has recently argued that massive heuristic guidance by strategies quite problematically related to the grammar itself may be required to parse at all with acceptable costs in the face of spurious ambiguities (see also Wittenburg, this conference.) The present paper concerns an alternative unification-based chart-parsing solution which is grammatically transparent, and which we claim to be generally applicable to parsing &amp;quot;genuine&amp;quot; attachment ambiguities, under extensions to CO which involve associative operations. 2. Unification-based Combinatory Categorial Grammars As Karttunen (1986), Uszkoreit (1986), Wittenburg (1986), and Zeevat et al. (1986) have noted, unification-based computational environments (Shieber 1986) offer a natural choice for implementing the categories and combination rules of CGs, because of their rigorously defined declarative semantics. We describe below a unification-based realisation of CCG which is both transparent to the linguistically motivated properties of the theory of grammar and can be directly coupled to the parsing methodology we offer further on. 2.1. A Restricted Version of Graph-unification We assume, like all unification formalisms, that grammatical constituents can be represented as feature-structures, which we as acyclic graphs A dag can be either: (i) a constant (ii) a variable (iii) a finite set of label-value pairs (features), where any value is itself a dag, and each label is associated with one and only one value We use round brackets to define sets, and we notate features as value]. refer to variables with symbols starting with capital letters, and to labels and constants with symbols starting with lower-case letters. The following is an example of a dag: (7) ((a el ((c XJ f ) ) Like other unification based grammars, we adopt dags as the data-structures encoding categorial feature information because of the conceptual perspicuity of their set-theoretic definition. However, the variety of unification between dags that we adopt is more restrictive than the one used in standard graph-unification formalisms like PATR-2 (Shieber 1986), and closely resembles term-unification as adopted in logicprogramming languages. 82 We define unification by first defining a partial ordering of dags in a similar (albeit more restricted) way previous work discussed in Shieber (1986). A dag suba dag if the information contained in is a (not proper) subset of the information contained in Thus, variables subsume all other dags, as they contain no information at all. Conversely, a constant subsumes, and is subsumed by, itself alone. Finally, subsumption between dags which are feature-sets is defined as follows. We refer to two and 1)2as each other if there is an a mapping each feature in onto a feature with same label in D,. Then a feature-set a and oMy if variants; and f ), is feature in and is feanwe in the value the value off&apos;. two dags and is then defined as the general dag D which is subsumed by both and Like most other unification-based approaches, we assume that from a procedural point of view, the process of obtaining the of two dags and requires that they be desmodified to become the D. (We also use the term unification to refer to this process.) example let and be the two following dags: (8) ((a ab c])] ((a Y [ d g [ d Z [ e X) ) [e Z]) the following din is the unification of and (9) ((a ((b c])] (d g [e gl) However, under the present definition of unification, as opposed to the more general PATR-2 definition, the above is unification of the following pair of dags: (10) ((a ((b c) ) ) ( [ d Z (d g]) (e Z]) These two dags are not unifiable in present terms, because under the above definition of subsumption, unification of two feature sets can only succeed if they are variants. It follows that a dag resulting from unification must have the same feature population as the two feature structures that it unifies. The present definition of unification thus resembles term unification in invariably yielding a feature-set with exactly the same structure as both of the input feature-sets, via the instantiation of variables. The only difference from standard term unification is that it is defined over dags, rather than standard terms. By contrast, standard graph-unification can yield a feature-set containing features initially entirely missing from one or other of the unified feature-sets. The significance of this will emerge later on, in the discussions of the combinatory rules in section 2.4, and of the property functional categories in section /3. Since the properties in question inhere to the grammar itself, to which unification is merely transparent, there is in our approach that is the more general definition of graph unification offered by PATR-2. However, in order to establish the correctness of our proposal for efficient parsing of extended categorial grammars using the more general definition, we would have had to neutralise its greater power with more laborious constraints on the encoding of entries in the categorial lexicon as dags than those we actually require below. The more restricted version we propose preserves most of the advantages of graph over term datastructures pointed out in Shieber (1986).&apos; 2.2. Categories as Features Structures We encode constituents corresponding to non-functional categories, such as the noun-phrases below, as feature-sets the three major attributes for reasons of space to pho, examples of feature-based categories given below are of course simplified for the purposes of concise exposition -for instance, we omit any specification of agreement informain the value associated with the John np] [pho John] [sem john&apos;]) Mary : — np] [pho miry] [sem mary&apos;l) Constituents corresponding to functional categories are characterized by a triple of attributes, directo value with be instantiated to one of the / and \ and the values associated with be associated with any functional or nonfunctional category. (Thus our functions are &amp;quot;curried&amp;quot;, and may be higher order.) impose the simple but crucial requirement of over the well-fonnedness of functional categories in featurebased CCG. Intuitively, this requirement corresponds to the that any change to the structure of the value of by unification must be reflected in the value of ult). Given the definition of unification in the section above, this requirement can be simply stated as follows: Functional categories must be in sense that every uninstantiated feature in the value of a — that is, every feature whose value is a variable -must share that variable value with some feature in the value of the function&apos;s whenever a feature in a function&apos;s instanby unification, some other feature in its ult) be instantiated identically, as a side-effect of the destructive replacement of structures imposed by unification. Variables in value of the a functional category therefore have the sole effect of increasing the specificity of the informacontained in the value of its the combinatory rules of CCG build new constituents exclusively in terms of information already contained in the categories that they combine, a requirement that all the functional categories in the lexicon be transparent in turn guarantees the transparency of any functional category assigned to complex constituents generated by the grammar. 3 Calder (1987) and Thompson (1987) have independently motivated similar approaches to constraining unification in encoding 83 The following feature-based functional category for a lexical transitive tensed verb obeys the transparency requirement (the operator * indicates string concatenation): (14) loves : ([res ((res ( [syn 5] [pho P1*loves*22] [sem ([act loving] [agent Si] [patient S2] /])] [dir \] np] [pho Pl] [sem Si])] [dir I] [arg ([syn np] [pho P2] [sem S2])] When two adjacent feature-structures corresponding to a funccategory and an argument are combined by funcapplication, a new feature-structure is constructed by the argument feature-structure with the value of ument) in function feature structure The result is then unified with the the function. For example, Rightward Application can be expressed in a notation adapted from PATR-2 as follows. We use the notation 1&gt; for a path of feature labels of length n, and we identify as the value associated with the feature identified the path ... in the dag corresponding to a category X. We indicate unification with the equality sign, =. Rightward Application can then be written as: (15) Rightward Application: ■ / Application of this rule to the functional feature-set (14) for the verb the feature-set (12) for the nounthe following structure for the verb-phrase loves Mary (16) loves Mary:-. ([res ([syn s] [pho Pl*loves*mary] [sem ([act loving] [agent Si] [patient mary&apos;] )])] [dir \] ((syn ) ] To rightward-compose two functional categories according to (4b), we similarly unify the appropriate ult) of the input functions according to the following rule: linguistic theories. (17) Rightward Composition: (&lt;direction&gt;) ■ / (&lt;direction&gt;) = / (&lt;direction&gt;) (&lt;result&gt;) = (&lt;arg&gt;) example, suppose that the feature-set the noun-phrase type-raised into the following functional feature-set, according to rule (4a), whose unification-based version we omit here: (18) John ( (syn [sem S] ) ] (Cres a] [pho P] [sem S])] [dir \] ([syn [sem john&apos;])])]) Then (18) can be combined by Rightward Composition with (14) to obtain the following feature structure for the functional corresponding to loves: (19) John loves:= [res loving] [agent john&apos;] [patient S2])3)] IsYn [pho P2] [sem S2])]) Leftward-combining rules are defined analogously to the rightward-combining rules above. 2.3. Derivational Equivalence Modulo Composition Let us denote the operations of applying and composing by writing Y) respectively. Then by the definition of the operations themselves, and in particular because of the associativity of functional composition, the following equivalences hold across typederivations: apply (comp apply , X2&apos; ) X ) ) 3 comp (comp X5&apos; ) , comp ) More formally, the left-hand side and right-hand side of both equations define equivalent terms in the combinatory logic of 2 84 and Feys It follows that derivations of an arbitrary sequence of functions and arguments that are allowed by different orders of application and composition which a composition is merely traded for also define equivalent terms of Combinatory Logic.&amp;quot; for instance, a type for the sentence loves Mary be assigned either by rightward-composing the type-raised John, (18), with to obtain the feature- (19) for loves, then rightward applying to to obtain a feature-structure for the whole sentence; or, conversely, it can be assigned by rightwardto to obtain the feature- (16) for Mary, then rightward-applying to (16) to obtain the final feature-structure. In both cases, as the reader may care to verify, the type-assignment we get is the following: Mary: — ((syn s] [pho john*loves*mary] [sem ([act loving] [agent john&apos;] [patient mary&apos;])]) An important property of CCG is that it unites syntactic and semantic combination in uniform operations of application and composition. Unification-based CCG makes this identification explicit by uniting the syntactic type of a constituent and its interpretation in a single feature-based type. It follows that all derivations for a given string induced by functional composition correspond to the same unique feature-based type, whicb be assigned to any other constituent in the This property, which we characterize formally elsewhere, is a direct consequence of the fact that unification is itself an associative operation. It follows in turn that a feature-based category like (22) associated with a given constituent not only contains all the information necessary for its grammatical interpretation, but also determines an equivalence class of derivations for that constituent, a point which is related to Kartnmen&apos;s (1986) proposal for the spurious ambiguity problem (cf. secn. 1 above), but which we exploit differently, as follows. 2.4. Procedural Neutrality of Combinatory Rules The rules of combinatory categorial grammar are purely declarative, and unification preserves this property, so that, as with other unification-based grammatical formalisms (cf. Shieber 1986), there is no procedural constraint on their use. So far, we have only considered examples in which such rules are applied &amp;quot;bottom-up&amp;quot;, as in example (16), in which the rule application (15) is used to define the feature structure on the left-hand side of the rule in terms of the feature structures 4 The terms are equivalent in the technical sense that they reduce to an identical normal form. 5 The inclusion of certain higher-order function categories in lexicon (of which &amp;quot;modifiers of modifiers&amp;quot; like an example in English) means that composition may affect the argument structure itself, thereby changing meaning and giving rise to non-equivalent terms. This possibility does not affect the present proposal, and can be ignored. 6 If there is genuine ambiguity, a constituent will of course be assigned more than one type. and on the right, respectively instantiated as the funcand its argument However, other procedural realizations are equally viable.&apos; In particular, it is a property of rules (15) and (17), (and of all the combinatory rules permitted in the theory -cf. Steedman 1986) that if any two out of the three elements that they relate are specified, then the third is entirely and uniquely determined. This property, we call neutrality from the form of the rules themselves and from the transparency property of functional categories, definition of unification given in section 2.1 above. This property of the grammar offers a way to short-circuit the entire problem of non-determinism in a chart-based parser for grammars characterised by spurious analyses engendered by associative rules such as composition. The procedural neutrality of the combinatory rules allows a processor to recover constituents which are &amp;quot;implicit&amp;quot; in analysed constituents in the that they would have been built if some analysis had happened to have been the one followed by the processor. For example, consider the situation where, faced the string loves Mary with in the last section, the processor has avoided multiple analyses by composing with to obtain loves, and has applied that to to obtain loves Mary (22), ignoring the other analysis. If the parser turns out to the constituent Mary, (as it will if it is to find a analysis when the sentence turns out to be loves madly), it can recover that constituent by defining it via the rule of Rightward Application in terms of the feature for loves Mary, and These two structures can be used to respectively instantiate and X in the rule as stated at (15). The reader may verify that 1 the rule in this way determines the required constituent to be exactly the same category as (16). This particular procedural alternative to the bottom-up invocation of combinatory rules will be central to the parsing algorithm which we present in the following section, so it will be convenient to give it a name. Since it is the &amp;quot;parent&amp;quot; category and the &amp;quot;left-constituent&amp;quot; category that are instantiated, . 0 seems natural to call this alternative left-branch instantiation of a combinatory rule, a term which we contrast with the bottom-up instantiation invoked in earlier examples. The significance of this point is as follows. Let us suppose that we can guarantee that a parser will always make available, in a chart, the constituent that combined under 7 There is an obvious analogy here with the fact that unification-based programming languages like Prolog do not have any predefined distinction between the input and the output parameters of a given procedure. 8 From a formal point of view, procedural neutrality is a consequence of the fact that unification-based combinatory rules, as characabove, are we follow Pereira and Shieber (1984) in claiming that the &amp;quot;bottom-up&amp;quot; realization of a unificationrule to the unification of a structure encoding equational constraints of r, and a structure corresponding to the merging of the structures instantiating the elements of the right-hand of structure consequently assigned as the instantiation of left-hand side of individuating a relevant substructure of the of the pair a rule of unification-based then the fact that th instantiation of the left-hand side in terms of &apos; , that are identical (in the sense that they subsume each other). 85 bottom-up instantiation as a left-constituent with an implicit right-constituent to yield the same result as the analysis that was actually followed. In that case, the processor will be able to recover the implicit right-constituent by left-branch instanof a rule, without restarting syntactic analysis and without backtracking or search of any kind. The following algorithm does just that. 3. A Lazy Chart Parsing Methodology Derivational equivalence modulo composition, together with the procedural neutrality of unification-based combinatory rules, allows us to define a novel generalisation of the classic chart parsing technique for extended CGs, which is &amp;quot;lazy&amp;quot; in the sense that: only edges corresponding to the set of cally equivalent analyses are installed on the chart; b) surface constituents of already parsed parts of the input which are not on the chart are directly generated from the structures which are, rather than being built from scratch via syntactic reanalysis. 3.1. A Bottom-up Left-to-Right Algorithm The algorithm we decribe here implements a bottom-up, leftto-right parser which delivers all semantically distinct analyses. Other algorithms based on alternative control strategies are equally feasible. In this specific algorithm, the distinction is drawn in a rather different from the standard one. For an edge be active does not meanthat it is associated with an incomplete constituent (indeed, the distinction between complete and incomplete conis eliminated in CCG); it simply means that trigger new actions of the parser to install other edges, after becomes inactive. By contrast, inactive edges cannot initiate modifications to the state of the parser. Active edges can be added to the chart according to the three following actions: Scanning: if a is a word in the input string then, for each lexical entry X associated with a, add an active edge labeled X spanning the vertices corresponding to the position of a on the chart. if is an active edge labeled then for unary rule of type raising which can be instanas X X add an active edge labeled .0 1 . spanning the same vertices of if an edge labeled has a left-adjacent labeled and there is a combinatory rule which can be instantiated as X =---&gt; X Xthen add . 1 active edge labeled spanning the starting verof E and the ending vertex 1 The operational meaning of Scanning and Lifting should be clear enough. The Reducing action is the workhorse of the parser, building new constituents by invoking combinatory rules via bottom-up instantiation. Whenever Reducing is over two edges and to obtain a new edge we ensure that: marked as a left-generator of If the rule in the grammar which was used is Rightward Composition, marked as a right-generator of intuition behind this move is that rightward functional categories which have been composed into, and will therefore give rise to spurious analyses if they take part in further rightward combinations, as a consequence of the property of derivational equivalence modulo composidiscussed in section 2.3. instead to choice points from where it would have been possible to obtain a derivationally different but semantically equivalent constituent analysis of some part of the input string. They thus constitute suitable constituents for use in recovering of other constituents in the chart via the invocation of combinatory rules under the procedure of left-branch instantiation discussed in the last section. In order to state exactly how this is done, we need to introduce the left-starter relation, corresponding to the transitive closure of the left-generator relation: (i) A left-generator L of an edge E is a left-starter of E. (ii) If L is a left-starter of E, then any left-starter of L is a left-starter of E. parser can now add corresponding to impliaccording to the following action: Revealing: if an edge E is labeled by a leftward-looking functional type X and there is a combinatory rule which be instantiated as X&apos; X then if there is an edge labeled left-adjacent to E has a left-starter labelea (iii) there is a combinatory rule which can be instantiated add to the chart an inactive edge labeled the ending vertex of and the starting vertex of E, unless there is already an sage labelled in the same and spanning the same vertices. Mark as a of if the rule used in (iii) ward Composition. To summarise the section so fan if the parser is devised so as to avoid putting on the chart subconstituents which would lead to redundant equivalent derivations, non-determinism in the grammar will always give rise to cases which require some of the excluded constituents. In a left-to-right processor this typically happens when the argument required by a leftwardlooking functional type has been mistakenly combined in the analysis of a substring left-adjacent to that leftward-looking type. However, such an implicit or hidden constituent could have only been obtained through an equivalent derivation path for the left-adjacent substring. It follows that we can &amp;quot;reveal&amp;quot; it on the chart by invoking a combinatory rule in terms of leftbranch instantiation. We can now informally characterize the algorithm itself as follows: the parser does Scanning for each word in the input string going left-to-right moreover, whenever an active edge A is added to the chart, then the following actions are taken in order (i) the parser does Lifting over A (ii) if A is labeled by a leftward-looking type, then for every edge E left-adjacent to A the parser does Revealing over E with respect to A 86 (iii) for every edge E left-adjacent to A the parser does Reducing over E and A, with the constraint that if A is not labeled by a leftward-looking type then E must not be a right-generator of any edge E&apos; the parser returns the set of categories associated with edges spanning the whole input, if such a set is not empty; it fails otherwise. 3.2. An Example In the interests of brevity and simplicity, we eschew all details to do with unification itself in the following examples of the workings of the parser, reverting to the original categorial notation for CCG of section 1, bearing in mind that the categories are now to be read strictly as a shorthand for the fuller notation of unification-based CCG. For similar reasons of simplicity in exposition, we assume for the present purpose that the only type-raising rule in the grammar is the subject rule (4a). algorithm analyses the sentence loves Mary madly First, the parser Scans the to the chart an active NP edge corresponding to its sole lexical entry, and spanning the word in question, thus: (23) . John NP (We adopt the convention that active edges are indicated by upper-case categories, while inactive edges will be indicated with lower-case categories.) Since the edge in question is active, it falls under the second clause of the algorithm. The condition this clause applies, since there is a rule which type raises over NP, so a new active edge of type is added, spanning the same word, other conditions apply to the NP active edge, and it becomes inactive): (24) S/ (S \NP) _John rip Neither Lifting, Revealing, nor Reducing yield any new edges, so the new active edge merely becomes inactive. The next word is Scanned to add a new lexical active edge of type spanning s/ oyes . (SNP • The new lexical edge Reduces with the type-raised subject to a new active edge of type S/NP. The subject category marked as the new edge&apos;s left-generator, and (because the combinatory rule was Rightward Composition) the verb category is marked as its right-generator. Nothing more from neither Lifting, Revealing nor Reducing yield anything from the new edge, so it too becomes inactive, and the next word is Scanned to add a new lexical active NP corresponding to (26) 1 ove s np NP edge yields active edges before becoming inactive, one of type S/(S\NP) via Lifting and the subject rule, and one of type S. via Reducing with the s/np edge to its left by the Forward application rule (we omit the former from the illustrabecause nothingfurtherhappens to it, but it is there nonetheless): (27) (s\np) loves np (s\np)/np np The s/np edge is in addition marked as the left generator of the S. Note that Reducing would potentially have allowed a third active edge corresponding to Mary be added by the new active NP edge corresponding to left-adjacent (Anp)/np edge, this edge has been marked as a right generator, and is therefore not allowed to Reduce by the algorithm. Nothing new results from the new active S edge, so it becomes and the next word scanned to add a new active edge, thus. (28) / (s\np) s/np loves . Mary np (a \npUnp np (S \NTT\ (S \NP) This active edge, being a leftward-looking functional type, precipitates Revealing. Since there is a rule (Backward Applica- 2a) which would allow to combine a left-adjacent Anp, is a rule (Forwards Appli- 2a) which would allow a left-starter combine with such an Atm to yield the s which is lett-adjacent since there is no left-adjacent Anp there already), the rule of Forward Application can be invoked via InstantiationtoReveal the inactive edge s/(s\np) madly_,-... npiii)/np n (s \NP) \ (S \NP) (still) active backward modier now Reduce with the newly introduced Arm, to yield a new active edge corresponding to Mary madly, becoming inactive: (30) s/ (s\np) /np . -n new active edge potent&apos; y gives to semantically Reductions with the subject yield S -one with its ground np type, and one with its raised type, s/(Anp). Only one of these is effected, because of a detail dealt with in the next section, and the algorithm terminates with a single S edge spanning the s In an attachment-ambiguous sentence like the following, which leave as an exercise, John loves Mary, revealed in the penultimate stage of analysis, and distinct analyses result (32) Fred believes John loves Mary passionately Space permits us no more than to note that this procedure will . . (s \np) \ (s \np S \ NP /np \ (s\np sAnp s \ np 87 also cope with another class of constructions which constitute a major source of non-determinism in natural language parsing, namely the diverse coordinate constructions whose categorial analysis is discussed by Dowty (1985) and Steedman (1985, 1987). 4. Type Raising and Spurious Ambiguity As noted at example (30) above, type raising rules introduce a second kind of spurious ambiguity connected to the interactions of such rules with functional application rather than functional composition. If the processor can Reduce via a rule of application on a type-raised category, then it can also always invoke the opposite rule of application to the surmised version of the same category to yield the same result. Spurious ambiguity of this kind is trivially easy to avoided, as (unlike the kind associated with composition), it can always be detected the following redundancy check on attachment of edges to the chart in Reducing: Reducing creates an edge via functional application, then it is only added to the chart if there is no edge associated with the same feature structure and spanning the same vertices already on the chart. S. Alternative Control Strategies and Grammatical Formalisms The algorithm described above is a pure bottom-up parsing procedure which has a close relative in the Cocke-Kasami- Younger algorithm for context-free phrase-structure grammars. However, our chart-parsing methodology is completely open to alternative control options. In particular, Pareschi (forthcoming) describes an adaptation of the Earley algorithm, which, in virtue of its top-down prediction stage, allows for efficient of more general type-raising rules than con- Formal proofs of the correctness of both these algorithms will be presented in the same reference. The possibility of exploiting this methodology for improving processing of other unification-based extensions of CG involving spurious ambiguity, like the one reported in Karttunen (1986a), is also under exploration. 6. Conclusion The above approach to chart-parsing with extensions to CGs characterised by spurious ambiguities allows us to define algorithms which do not build significantly more edges than chart parsers for more standard theories of grammar. Our technique is fully transparent with respect to our grammatical formalism, since it is based on properties of associativity and procedural inherent in the grammar ACKNOWLEDGEMENTS</abstract>
<author confidence="0.7265995">We thank Inge Bethke</author>
<author confidence="0.7265995">Kit Fine</author>
<author confidence="0.7265995">Ellen Hays</author>
<author confidence="0.7265995">Aravind Joshi</author>
<author confidence="0.7265995">Dale Miller</author>
<author confidence="0.7265995">Henry Thompson</author>
<author confidence="0.7265995">Bonnie Lynn Webber</author>
<author confidence="0.7265995">Kent Wittenburg</author>
<note confidence="0.922364878048781">for help and advice. Parts of the research were supported by: an Edinburgh University Research Studentship: an ESPRIT grant (project 393) to CCS, Univ. Edinburgh; a Sloan Foundation grant to the Cognitive Science Program, Univ. Pennsylvania; and NSF grant IRI-10413 A02, ARO grant DAA6-29- 84K-0061 and DARPA grant N0014-85-K0018 to CIS, Univ. Pennsylvania. 9 Chmt parsers based on the methodology described here and written in Quintus Prolog have been developed on a Sun workstation. REFERENCES A. and Steedman, M. J. (1982) On the Order of Linguistics and Philosophy, 44,517-518. Calder, J. (1987) Typed Unification for Natural Language Processing. Ms, Univ. of Edinburgh Curry, H. B. and Feys, R. (1958) Combinatory Logic, Volume I. Amsterdam: North Holland. Dowty, D. (1985). Type raising, functional composition and non-constituent coordination. In R. Oehrle et al, (eds.), Categorial Grammars and Natural Language Structures, Dordrecht, Reidel. (In press). Haddock. N. J. (1987) Incremental Interpretation and Combinatory Categorial Grammar. In Proceedings of the Tenth International Joint Conference on Artificial Intelligence, Milan, Italy, August, 1987. Hinrichs, E. and Polariyi, L (1986) Pointing the Way. Papers from the Parasession on Pragmatics and Grammatical Theory at the Twenty-Second Regional Meeting of the Chicago Linguistic Society, pp.298-314. Karttunen. L. (1986) Radical Lexicalism. Paper presented at the Conference on Alternative Conceptions of Phrase Structure, July 1986, New York. Kay, M. (1980) Algorithm Schemata and Data Structures in Syntactic Processing. Technical Report No. CSL-80- 12, XEROX Palo Alto Research Centre. Pareschi. Remo. 1986. Combinatory Categorial Grammar, Logic Programming, and the Parsing of Natural Language. DAI Working Paper, University of Edinburgh. Pareschi, R. (forthcoming) PhD Thesis, Univ. Edinburgh. Pereira, F. C. N. and Shieber, S. M. (1984) The Semantics of Grammar Formalisms Seen as Computer Languages. In Proceedings of the 22nd Annual Meeting of the ACL, Stanford, July 1984, pp.123-129.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>We thank Inge Bethke</author>
<author>Kit Fine</author>
<author>Ellen Hays</author>
<author>Aravind Joshi</author>
<author>Dale Miller</author>
<author>Henry Thompson</author>
<author>Bonnie Lynn Webber</author>
</authors>
<title>and Kent Wittenburg for help and advice. Parts of the research were supported by: an Edinburgh University Research Studentship: an ESPRIT grant (project 393) to CCS, Univ. Edinburgh; a Sloan Foundation grant to the Cognitive Science Program, Univ. Pennsylvania; and NSF grant IRI-10413 A02, ARO grant DAA6-29- 84K-0061 and DARPA grant N0014-85-K0018 to CIS,</title>
<location>Univ. Pennsylvania.</location>
<marker>Bethke, Fine, Hays, Joshi, Miller, Thompson, Webber, </marker>
<rawString>We thank Inge Bethke, Kit Fine, Ellen Hays, Aravind Joshi, Dale Miller, Henry Thompson, Bonnie Lynn Webber, and Kent Wittenburg for help and advice. Parts of the research were supported by: an Edinburgh University Research Studentship: an ESPRIT grant (project 393) to CCS, Univ. Edinburgh; a Sloan Foundation grant to the Cognitive Science Program, Univ. Pennsylvania; and NSF grant IRI-10413 A02, ARO grant DAA6-29- 84K-0061 and DARPA grant N0014-85-K0018 to CIS, Univ. Pennsylvania.</rawString>
</citation>
<citation valid="false">
<title>9 Chmt parsers based on the methodology described here and written in Quintus Prolog have been developed on a Sun workstation.</title>
<marker></marker>
<rawString>9 Chmt parsers based on the methodology described here and written in Quintus Prolog have been developed on a Sun workstation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ades</author>
<author>M J Steedman</author>
</authors>
<title>On the Order of Words. Linguistics and Philosophy,</title>
<date>1982</date>
<pages>44--517</pages>
<contexts>
<context position="2997" citStr="Ades and Steedman 1982" startWordPosition="444" endWordPosition="447">combining functions) or &apos;V (for leftward). Must then gets the following type-assignment (1) must:— (S\NP) /VP In pure categorial grammar, the only other element is a single &amp;quot;combinatory&amp;quot; rule of Functional Application, which gives rise to the following two instances:1 (2) a. Rightward Application: X X/Y Y b. Leftward Application: X Y X\Y These rules allow functions to combine with immediately adjacent arguments in the obvious way, to yield the obvious surface structures and interpretations, as in: (3) John must leave NP (S \ NP ) /VP VP &gt;apply S\NP &lt;apply Combinatory Categorial Grammar (CCG) (Ades and Steedman 1982, Steedman 1985, Steedman 1986) adds a number of further elementary operations on functions and arguments to the combinatory component. These operations correspond to certain of the primitive combinators used by Curry and Feys (1958) to define the foundations of the .-calculus, notably including functional composition and &amp;quot;type raising&amp;quot;. For example: (4) a. Subject Type Raising: S/(S\NP) --&gt; NP b. Rightward Composition: X/Z ==&gt; X/Y Y/Z These combinatory operations allow additional, non-standard &amp;quot;surface structures&amp;quot; like the following, which arises from the type-raising of the subject John into</context>
<context position="5730" citStr="Ades and Steedman 1982" startWordPosition="880" endWordPosition="883">they can simply be regarded as tools which enable functional composition to operate in circumstances where one or both the constituents which need to be combined initially are not associated with a functional type, as when combining a subject NP with the verb which follows it. Grammars of this kind, and the related variety proposed by Kartunnen (1986), achieve simplicity in the grammar of movement and coordination at the expense of multiplying the number of derivations according to which an unambiguous string such as the sentence above can be parsed. While we have suggested in earlier papers (Ades and Steedman 1982, Pareschi 1986) that this property can be exploited for incremental semantic interpretation and evaluation, a suggestion which has been explored further by Haddock (1987) and Hinrichs and Polanyi (1986), two potentially serious problems arise from these spurious ambiguities. The first is the possibility of producing a whole set of semantically equivalent analyses for each reading of a given string. The second more serious problem is that of efficiently coping with nondeterminism in the face of such proliferating ambiguity in surface analyses. The problem of avoiding equivalent derivations is </context>
</contexts>
<marker>Ades, Steedman, 1982</marker>
<rawString>Ades, A. and Steedman, M. J. (1982) On the Order of Words. Linguistics and Philosophy, 44,517-518.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Calder</author>
</authors>
<title>Typed Unification for Natural Language Processing.</title>
<date>1987</date>
<journal>Ms, Univ. of Edinburgh</journal>
<contexts>
<context position="16583" citStr="Calder (1987)" startWordPosition="2621" endWordPosition="2622">he destructive replacement of structures imposed by unification. Variables in the value of the arg(ument) of a functional category therefore have the sole effect of increasing the specificity of the information contained in the value of its res(ult). As the combinatory rules of CCG build new constituents exclusively in terms of information already contained in the categories that they combine, a requirement that all the functional categories in the lexicon be transparent in turn guarantees the transparency of any functional category assigned to complex constituents generated by the grammar. 3 Calder (1987) and Thompson (1987) have independently motivated similar approaches to constraining unification in encoding 83 The following feature-based functional category for a lexical transitive tensed verb obeys the transparency requirement (the operator * indicates string concatenation): (14) loves : ([res ((res ( [syn 5] [pho P1*loves*22] [sem ([act loving] [agent Si] [patient S2] /])] [dir \] [arg ([syn np] [pho Pl] [sem Si])] [dir I] [arg ([syn np] [pho P2] [sem S2])] When two adjacent feature-structures corresponding to a function category X1 and an argument X2 are combined by functional applicati</context>
</contexts>
<marker>Calder, 1987</marker>
<rawString>Calder, J. (1987) Typed Unification for Natural Language Processing. Ms, Univ. of Edinburgh</rawString>
</citation>
<citation valid="true">
<authors>
<author>H B Curry</author>
<author>R Feys</author>
</authors>
<title>Combinatory Logic, Volume I.</title>
<date>1958</date>
<location>Amsterdam: North Holland.</location>
<contexts>
<context position="3230" citStr="Curry and Feys (1958)" startWordPosition="478" endWordPosition="481">e to the following two instances:1 (2) a. Rightward Application: X X/Y Y b. Leftward Application: X Y X\Y These rules allow functions to combine with immediately adjacent arguments in the obvious way, to yield the obvious surface structures and interpretations, as in: (3) John must leave NP (S \ NP ) /VP VP &gt;apply S\NP &lt;apply Combinatory Categorial Grammar (CCG) (Ades and Steedman 1982, Steedman 1985, Steedman 1986) adds a number of further elementary operations on functions and arguments to the combinatory component. These operations correspond to certain of the primitive combinators used by Curry and Feys (1958) to define the foundations of the .-calculus, notably including functional composition and &amp;quot;type raising&amp;quot;. For example: (4) a. Subject Type Raising: S/(S\NP) --&gt; NP b. Rightward Composition: X/Z ==&gt; X/Y Y/Z These combinatory operations allow additional, non-standard &amp;quot;surface structures&amp;quot; like the following, which arises from the type-raising of the subject John into a function over predicates, which composes with the verb, which is of course a function into predicates: (5) John must leave NP (S\NP) /VP VP &gt;raise S/ (S\NP) &gt;compose S /VP &gt;apply In general, wherever orthodox surface structure pos</context>
<context position="20038" citStr="Curry and Feys (1958)" startWordPosition="3180" endWordPosition="3183">Equivalence Modulo Composition Let us denote the operations of applying and composing categories by writing apply(X, Y) and comp(X. Y) respectively. Then by the definition of the operations themselves, and in particular because of the associativity of functional composition, the following equivalences hold across typederivations: (20) apply (comp (X1, — apply (Xi , X2&apos; ) X ) apply (X2, X3) ) 3 (21) comp (comp (X4, X5&apos; ) X6) comp (X4 , comp (X5, X6) ) More formally, the left-hand side and right-hand side of both equations define equivalent terms in the combinatory logic of Xix X2 X2 X2 x1 2 84 Curry and Feys (1958).4 It follows that all alternative derivations of an arbitrary sequence of functions and arguments that are allowed by different orders of application and composition in which a composition is merely traded for andapplication also define equivalent terms of Combinatory Logic.&amp;quot; So, for instance, a type for the sentence John loves Mary can be assigned either by rightward-composing the type-raised function John, (18), with loves, (14), to obtain the featurestructure (19) for John loves, and then rightward applying (19) to Mary, (12), to obtain a feature-structure for the whole sentence; or, conve</context>
</contexts>
<marker>Curry, Feys, 1958</marker>
<rawString>Curry, H. B. and Feys, R. (1958) Combinatory Logic, Volume I. Amsterdam: North Holland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Dowty</author>
</authors>
<title>Type raising, functional composition and non-constituent coordination. In</title>
<date>1985</date>
<booktitle>Categorial Grammars and Natural Language Structures,</booktitle>
<editor>R. Oehrle et al, (eds.),</editor>
<publisher>(In press).</publisher>
<location>Dordrecht, Reidel.</location>
<contexts>
<context position="38334" citStr="Dowty (1985)" startWordPosition="6237" endWordPosition="6238"> the following, which we leave as an exercise, two predicates, believes John loves Mary and loves Mary, are revealed in the penultimate stage of the analysis, and two semantically distinct analyses result (32) Fred believes John loves Mary passionately Space permits us no more than to note that this procedure will . . (s \np) \ (s \np S \ NP np /np na,..01(s\np) \ (s\np sAnp s \ np 87 also cope with another class of constructions which constitute a major source of non-determinism in natural language parsing, namely the diverse coordinate constructions whose categorial analysis is discussed by Dowty (1985) and Steedman (1985, 1987). 4. Type Raising and Spurious Ambiguity As noted at example (30) above, type raising rules introduce a second kind of spurious ambiguity connected to the interactions of such rules with functional application rather than functional composition. If the processor can Reduce via a rule of application on a type-raised category, then it can also always invoke the opposite rule of application to the surmised version of the same category to yield the same result. Spurious ambiguity of this kind is trivially easy to avoided, as (unlike the kind associated with composition), </context>
</contexts>
<marker>Dowty, 1985</marker>
<rawString>Dowty, D. (1985). Type raising, functional composition and non-constituent coordination. In R. Oehrle et al, (eds.), Categorial Grammars and Natural Language Structures, Dordrecht, Reidel. (In press).</rawString>
</citation>
<citation valid="true">
<authors>
<author>N J</author>
</authors>
<title>Incremental Interpretation and Combinatory Categorial Grammar.</title>
<date>1987</date>
<booktitle>In Proceedings of the Tenth International Joint Conference on Artificial Intelligence,</booktitle>
<location>Milan, Italy,</location>
<marker>J, 1987</marker>
<rawString>Haddock. N. J. (1987) Incremental Interpretation and Combinatory Categorial Grammar. In Proceedings of the Tenth International Joint Conference on Artificial Intelligence, Milan, Italy, August, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Hinrichs</author>
<author>L Polariyi</author>
</authors>
<title>Pointing the Way. Papers from the Parasession on Pragmatics and Grammatical Theory at the Twenty-Second Regional Meeting of the Chicago Linguistic Society,</title>
<date>1986</date>
<pages>298--314</pages>
<marker>Hinrichs, Polariyi, 1986</marker>
<rawString>Hinrichs, E. and Polariyi, L (1986) Pointing the Way. Papers from the Parasession on Pragmatics and Grammatical Theory at the Twenty-Second Regional Meeting of the Chicago Linguistic Society, pp.298-314.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L</author>
</authors>
<title>Radical Lexicalism.</title>
<date>1986</date>
<booktitle>Paper presented at the Conference on Alternative Conceptions of Phrase Structure,</booktitle>
<location>New York.</location>
<marker>L, 1986</marker>
<rawString>Karttunen. L. (1986) Radical Lexicalism. Paper presented at the Conference on Alternative Conceptions of Phrase Structure, July 1986, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kay</author>
</authors>
<title>Algorithm Schemata and Data Structures in Syntactic Processing.</title>
<date>1980</date>
<tech>Technical Report No. CSL-80- 12,</tech>
<institution>XEROX Palo Alto Research Centre.</institution>
<contexts>
<context position="6991" citStr="Kay, 1980" startWordPosition="1072" endWordPosition="1073">e phrase-structure grammars. Since all the spurious derivations are by definition semantically equivalent, the solution seems obvious: just find one of them, say via a &amp;quot;reduce first&amp;quot; strategy of the kind proposed by Ades and Steedman (1982). The problem with this proposal arises from the fact that, assuming left-to-right processing, Rightward Composition may preempt the construction of constituents which are needed as arguments by leftward combining functional types.2 Such a depth-first processor cannot take advantage of standard techniques for eliminating backtracking, such as chart-parsing (Kay, 1980), because the subconstituents for the alternative analysis will not in general have been built. For example, if we have produced a leftbranching analysis like (b) above, and then find that we need the constituent X in analysis (a) (say to attach a modifier), we will be forced to redo the entire analysis, since not one of the subconstituents of X (such as Y) was a constituent under the previous analysis. Nor of course can we afford a standard breadth-first strategy. Karttunen (1986a) has pointed out that a parser which associates a canonical interpretation structure 2 If we had chosen to proces</context>
</contexts>
<marker>Kay, 1980</marker>
<rawString>Kay, M. (1980) Algorithm Schemata and Data Structures in Syntactic Processing. Technical Report No. CSL-80- 12, XEROX Palo Alto Research Centre.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Remo</author>
</authors>
<title>Combinatory Categorial Grammar, Logic Programming, and the Parsing of Natural Language.</title>
<date>1986</date>
<tech>Pareschi, R. (forthcoming) PhD Thesis,</tech>
<institution>DAI Working Paper, University of Edinburgh.</institution>
<marker>Remo, 1986</marker>
<rawString>Pareschi. Remo. 1986. Combinatory Categorial Grammar, Logic Programming, and the Parsing of Natural Language. DAI Working Paper, University of Edinburgh. Pareschi, R. (forthcoming) PhD Thesis, Univ. Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F C N Pereira</author>
<author>S M Shieber</author>
</authors>
<title>The Semantics of Grammar Formalisms Seen as Computer Languages.</title>
<date>1984</date>
<booktitle>In Proceedings of the 22nd Annual Meeting of the ACL,</booktitle>
<pages>123--129</pages>
<location>Stanford,</location>
<contexts>
<context position="26386" citStr="Pereira and Shieber (1984)" startWordPosition="4204" endWordPosition="4207">n earlier examples. The significance of this point is as follows. Let us suppose that we can guarantee that a parser will always make available, say in a chart, the constituent that could have combined under 7 There is an obvious analogy here with the fact that unification-based programming languages like Prolog do not have any predefined distinction between the input and the output parameters of a given procedure. 8 From a formal point of view, procedural neutrality is a consequence of the fact that unification-based combinatory rules, as characterised above, are extensional. Thus, we follow Pereira and Shieber (1984) in claiming that the &amp;quot;bottom-up&amp;quot; realization of a unificationbased rule r corresponds to the unification of a structure Er encoding the equational constraints of r, and a structure Dr corresponding to the merging of the structures instantiating the elements of the right-hand side of r. A structure N,is consequently assigned as the instantiation of the left-hand side of r by individuating a relevant substructure of the unification of the pair &lt;Dr, E,&gt;. If r is a rule of unification-based CCG, then the fact that Nr th instantiation of the left-hand side of, both in terms of &lt;Dr, Er&gt; and &lt;D &apos; , </context>
</contexts>
<marker>Pereira, Shieber, 1984</marker>
<rawString>Pereira, F. C. N. and Shieber, S. M. (1984) The Semantics of Grammar Formalisms Seen as Computer Languages. In Proceedings of the 22nd Annual Meeting of the ACL, Stanford, July 1984, pp.123-129.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shieber</author>
</authors>
<title>An Introduction to Unification-based Approaches to Grammar,</title>
<date>1986</date>
<publisher>Univ. Chicago Press.</publisher>
<location>Chicago:</location>
<contexts>
<context position="9100" citStr="Shieber 1986" startWordPosition="1392" endWordPosition="1393">self may be required to parse at all with acceptable costs in the face of spurious ambiguities (see also Wittenburg, this conference.) The present paper concerns an alternative unification-based chart-parsing solution which is grammatically transparent, and which we claim to be generally applicable to parsing &amp;quot;genuine&amp;quot; attachment ambiguities, under extensions to CO which involve associative operations. 2. Unification-based Combinatory Categorial Grammars As Karttunen (1986), Uszkoreit (1986), Wittenburg (1986), and Zeevat et al. (1986) have noted, unification-based computational environments (Shieber 1986) offer a natural choice for implementing the categories and combination rules of CGs, because of their rigorously defined declarative semantics. We describe below a unification-based realisation of CCG which is both transparent to the linguistically motivated properties of the theory of grammar and can be directly coupled to the parsing methodology we offer further on. 2.1. A Restricted Version of Graph-unification We assume, like all unification formalisms, that grammatical constituents can be represented as feature-structures, which we encode as directed acyclic graphs (dags). A dag can be e</context>
<context position="10523" citStr="Shieber 1986" startWordPosition="1616" endWordPosition="1617">e sets, and we notate features as (label value]. We refer to variables with symbols starting with capital letters, and to labels and constants with symbols starting with lower-case letters. The following is an example of a dag: (7) ((a el ((c XJ d f ) 1 ) Like other unification based grammars, we adopt dags as the data-structures encoding categorial feature information because of the conceptual perspicuity of their set-theoretic definition. However, the variety of unification between dags that we adopt is more restrictive than the one used in standard graph-unification formalisms like PATR-2 (Shieber 1986), and closely resembles term-unification as adopted in logicprogramming languages. 82 We define unification by first defining a partial ordering of subsumption over dags in a similar (albeit more restricted) way to previous work discussed in Shieber (1986). A dag D1 subsumes a dag D2 if the information contained in DI is a (not necessarily proper) subset of the information contained in D2. Thus, variables subsume all other dags, as they contain no information at all. Conversely, a constant subsumes, and is subsumed by, itself alone. Finally, subsumption between dags which are feature-sets is d</context>
<context position="14022" citStr="Shieber (1986)" startWordPosition="2224" endWordPosition="2225">erely transparent, there is nothing in our approach that is incompatible with the more general definition of graph unification offered by PATR-2. However, in order to establish the correctness of our proposal for efficient parsing of extended categorial grammars using the more general definition, we would have had to neutralise its greater power with more laborious constraints on the encoding of entries in the categorial lexicon as dags than those we actually require below. The more restricted version we propose preserves most of the advantages of graph over term datastructures pointed out in Shieber (1986).&apos; 2.2. Categories as Features Structures We encode constituents corresponding to non-functional categories, such as the noun-phrases below, as feature-sets defining the three major attributes syntax, phonology and semantics, abbreviated for reasons of space to syn, pho, and sem (the examples of feature-based categories given below are of course simplified for the purposes of concise exposition -- for instance, we omit any specification of agreement information in the value associated with the syn(tax) label): (11) John ([syn np] [pho John] [sem john&apos;]) (12) Mary : — ((syn np] [pho miry] [sem </context>
<context position="22349" citStr="Shieber 1986" startWordPosition="3533" endWordPosition="3534">category like (22) associated with a given constituent not only contains all the information necessary for its grammatical interpretation, but also determines an equivalence class of derivations for that constituent, a point which is related to Kartnmen&apos;s (1986) proposal for the spurious ambiguity problem (cf. secn. 1 above), but which we exploit differently, as follows. 2.4. Procedural Neutrality of Combinatory Rules The rules of combinatory categorial grammar are purely declarative, and unification preserves this property, so that, as with other unification-based grammatical formalisms (cf. Shieber 1986), there is no procedural constraint on their use. So far, we have only considered examples in which such rules are applied &amp;quot;bottom-up&amp;quot;, as in example (16), in which the rule of application (15) is used to define the feature structure X0 on the left-hand side of the rule in terms of the feature structures 4 The terms are equivalent in the technical sense that they reduce to an identical normal form. 5 The inclusion of certain higher-order function categories in the lexicon (of which &amp;quot;modifiers of modifiers&amp;quot; like formerly would be an example in English) means that composition may affect the argu</context>
</contexts>
<marker>Shieber, 1986</marker>
<rawString>Shieber, S. M. (1986) An Introduction to Unification-based Approaches to Grammar, Chicago: Univ. Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Steadman</author>
</authors>
<title>Dependency and Coordination in the</title>
<date>1985</date>
<journal>Grammar of Dutch and English. Language;</journal>
<volume>61</volume>
<pages>523--568</pages>
<marker>Steadman, 1985</marker>
<rawString>Steadman, M. (1985) Dependency and Coordination in the Grammar of Dutch and English. Language; 61, 523-568.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Steedman</author>
</authors>
<title>Combinatory Grammars and Parasitic Gaps. Natural Language and Linguistic Theory,</title>
<date>1986</date>
<note>to appear.</note>
<contexts>
<context position="3028" citStr="Steedman 1986" startWordPosition="450" endWordPosition="451">d). Must then gets the following type-assignment (1) must:— (S\NP) /VP In pure categorial grammar, the only other element is a single &amp;quot;combinatory&amp;quot; rule of Functional Application, which gives rise to the following two instances:1 (2) a. Rightward Application: X X/Y Y b. Leftward Application: X Y X\Y These rules allow functions to combine with immediately adjacent arguments in the obvious way, to yield the obvious surface structures and interpretations, as in: (3) John must leave NP (S \ NP ) /VP VP &gt;apply S\NP &lt;apply Combinatory Categorial Grammar (CCG) (Ades and Steedman 1982, Steedman 1985, Steedman 1986) adds a number of further elementary operations on functions and arguments to the combinatory component. These operations correspond to certain of the primitive combinators used by Curry and Feys (1958) to define the foundations of the .-calculus, notably including functional composition and &amp;quot;type raising&amp;quot;. For example: (4) a. Subject Type Raising: S/(S\NP) --&gt; NP b. Rightward Composition: X/Z ==&gt; X/Y Y/Z These combinatory operations allow additional, non-standard &amp;quot;surface structures&amp;quot; like the following, which arises from the type-raising of the subject John into a function over predicates, wh</context>
<context position="23506" citStr="Steedman 1986" startWordPosition="3728" endWordPosition="3729">le in English) means that composition may affect the argument structure itself, thereby changing meaning and giving rise to non-equivalent terms. This possibility does not affect the present proposal, and can be ignored. 6 If there is genuine ambiguity, a constituent will of course be assigned more than one type. X1 and X2 on the right, respectively instantiated as the function loves (14) and its argument Mary 02). However, other procedural realizations are equally viable.&apos; In particular, it is a property of rules (15) and (17), (and of all the combinatory rules permitted in the theory -- cf. Steedman 1986) that if any two out of the three elements that they relate are specified, then the third is entirely and uniquely determined. This property, which we call procedural neutrality follows from the form of the rules themselves and from the transparency property (13) of functional categories, tinder the definition of unification given in section 2.1 above. This property of the grammar offers a way to short-circuit the entire problem of non-determinism in a chart-based parser for grammars characterised by spurious analyses engendered by associative rules such as composition. The procedural neutrali</context>
</contexts>
<marker>Steedman, 1986</marker>
<rawString>Steedman,M. (1986) Combinatory Grammars and Parasitic Gaps. Natural Language and Linguistic Theory, to appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Steedman</author>
</authors>
<title>Coordination and Constituency in a Combinatory Grammar.</title>
<date>1987</date>
<booktitle>Alternative Conceptions of Phrase Structure, University of</booktitle>
<editor>In Mark Baltin and Tony Kroch, (eds.),</editor>
<publisher>Chicago Press: Chicago. (To appear.)</publisher>
<marker>Steedman, 1987</marker>
<rawString>Steedman, M. (1987) Coordination and Constituency in a Combinatory Grammar. In Mark Baltin and Tony Kroch, (eds.), Alternative Conceptions of Phrase Structure, University of Chicago Press: Chicago. (To appear.)</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Thompson</author>
</authors>
<title>FBF - An Alternative to PATR as a Grammatical Assembly Language.</title>
<date>1987</date>
<tech>Research Paper,</tech>
<institution>Department of AI, Univ.</institution>
<location>Edinburgh.</location>
<contexts>
<context position="16603" citStr="Thompson (1987)" startWordPosition="2624" endWordPosition="2625">lacement of structures imposed by unification. Variables in the value of the arg(ument) of a functional category therefore have the sole effect of increasing the specificity of the information contained in the value of its res(ult). As the combinatory rules of CCG build new constituents exclusively in terms of information already contained in the categories that they combine, a requirement that all the functional categories in the lexicon be transparent in turn guarantees the transparency of any functional category assigned to complex constituents generated by the grammar. 3 Calder (1987) and Thompson (1987) have independently motivated similar approaches to constraining unification in encoding 83 The following feature-based functional category for a lexical transitive tensed verb obeys the transparency requirement (the operator * indicates string concatenation): (14) loves : ([res ((res ( [syn 5] [pho P1*loves*22] [sem ([act loving] [agent Si] [patient S2] /])] [dir \] [arg ([syn np] [pho Pl] [sem Si])] [dir I] [arg ([syn np] [pho P2] [sem S2])] When two adjacent feature-structures corresponding to a function category X1 and an argument X2 are combined by functional application, a new feature-st</context>
</contexts>
<marker>Thompson, 1987</marker>
<rawString>Thompson, H. (1987) FBF - An Alternative to PATR as a Grammatical Assembly Language. Research Paper, Department of AI, Univ. Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Usikoreit</author>
</authors>
<title>Categorial Unification Grammars.</title>
<date>1986</date>
<booktitle>In Proceedings of the 11th International Conference on Computational Linguistics,</booktitle>
<pages>187--194</pages>
<location>Bonn,</location>
<marker>Usikoreit, 1986</marker>
<rawString>Usikoreit, H. (1986) Categorial Unification Grammars. In Proceedings of the 11th International Conference on Computational Linguistics, Bonn, August, 1986, pp187-194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K W Wittenburg</author>
</authors>
<title>Natural Language Parsing with Combinatory Categorial Grammar in a GraphUnification-Based Formalism.</title>
<date>1986</date>
<tech>PhD Thesis,</tech>
<institution>Department of Linguistics, University of Texas.</institution>
<contexts>
<context position="8373" citStr="Wittenburg (1986)" startWordPosition="1296" endWordPosition="1297"> analysis of the same string from a genuinely different analysis: spurious analyses produce results that are the same as one already installed on the chart. However, the spurious ambiguity problem remains acute. In order to produce only the genuinely distinct readings, it seems that all of the spurious analyses must be explored, even if they can be discarded again. Even for short strings, this can lead to an unmanageable enlargement of the search space of the processor. Similarly, the problem of reanalysis under backtracking still threatens to overwhelm the parser. In the face of this problem Wittenburg (1986) has recently argued that massive heuristic guidance by strategies quite problematically related to the grammar itself may be required to parse at all with acceptable costs in the face of spurious ambiguities (see also Wittenburg, this conference.) The present paper concerns an alternative unification-based chart-parsing solution which is grammatically transparent, and which we claim to be generally applicable to parsing &amp;quot;genuine&amp;quot; attachment ambiguities, under extensions to CO which involve associative operations. 2. Unification-based Combinatory Categorial Grammars As Karttunen (1986), Uszkor</context>
</contexts>
<marker>Wittenburg, 1986</marker>
<rawString>Wittenburg, K. W. (1986) Natural Language Parsing with Combinatory Categorial Grammar in a GraphUnification-Based Formalism. PhD Thesis, Department of Linguistics, University of Texas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E</author>
<author>J Calder</author>
</authors>
<title>An Introduction to Unification Categorial Grammar. In</title>
<date>1987</date>
<booktitle>Edinburgh Working Papers in Cognitive Science, 1: Categorial Grammar, Unification Grammar, and Parsing.</booktitle>
<editor>N. Haddock et al. (eds.),</editor>
<marker>E, Calder, 1987</marker>
<rawString>Zeevat, H., Klein. E. and Calder, J. (1987) An Introduction to Unification Categorial Grammar. In N. Haddock et al. (eds.), Edinburgh Working Papers in Cognitive Science, 1: Categorial Grammar, Unification Grammar, and Parsing.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>