<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002021">
<title confidence="0.996962">
Efficient Search for Interactive Statistical Machine Translation
</title>
<author confidence="0.984538">
Franz Josef Ochl and Richard Zens and Hermann Ney
</author>
<affiliation confidence="0.9885525">
Chair of Computer Science VI
RWTH Aachen - University of Technology
</affiliation>
<email confidence="0.983074">
foch,zens,neyl@cs.rwth-aachen.de
</email>
<sectionHeader confidence="0.998529" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999982">
The goal of interactive machine transla-
tion is to improve the productivity of hu-
man translators. An interactive machine
translation system operates as follows:
the automatic system proposes a transla-
tion. Now, the human user has two op-
tions: to accept the suggestion or to cor-
rect it. During the post-editing process,
the human user is assisted by the inter-
active system in the following way: the
system suggests an extension of the cur-
rent translation prefix. Then, the user ei-
ther accepts this extension (completely
or partially) or ignores it. The two most
important factors of such an interactive
system are the quality of the proposed
extensions and the response time. Here,
we will use a fully fledged translation
system to ensure the quality of the pro-
posed extensions. To achieve fast re-
sponse times, we will use word hypothe-
ses graphs as an efficient search space
representation. We will show results of
our approach on the Verbmobil task and
on the Canadian Hansards task.
</bodyText>
<sectionHeader confidence="0.999622" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.996203">
Current machine translation technology is not able
to guarantee high quality translations for large do-
mains. Hence, in many applications, post-editing
</bodyText>
<footnote confidence="0.435732">
&apos;The author is now affiliated with the Information Science
Institute, University of Southern California, och@isi.edu.
</footnote>
<bodyText confidence="0.999838147058823">
of the machine translation output is necessary. In
such an environment, the main goal of the ma-
chine translation system is not to produce transla-
tions that are understandable for an inexperienced
recipient but to support a professional human post-
editor.
Typically, a better quality of the produced ma-
chine translation text yields a reduced post-editing
effort. From an application point of view, many
additional aspects have to be considered: the
user interface, the used formats and the addi-
tional support tools such as lexicons, terminologi-
cal databases or translation memories.
The concept of interactive machine translation,
first suggested by (Foster et al., 1996), finds a very
natural implementation in the framework of statis-
tical machine translation. In interactive machine
translation, the basic idea is to provide an environ-
ment to a human translator that interactively reacts
upon the input as the user writes or corrects the
translation. In such an approach, the system sug-
gests an extension of a sentence that the human
user either accepts or ignores. An implementation
of such a tool was performed in the TransType
project (Foster et al., 1996; Foster et al., 1997;
Langlais et al., 2000).
The user interface of the TransType system
combines a machine translation system and a text
editor into a single application. The human trans-
lator types the translation of a given source text.
For each prefix of a word, the machine translation
system computes the most probable extension of
this word and presents this to the user. The human
translator either accepts this translation by press-
</bodyText>
<page confidence="0.995985">
387
</page>
<bodyText confidence="0.9981365">
ing a certain key or ignores the suggestion and
continues typing.
Rather than single-word predictions, as in the
TransType approach, it is preferable that the sug-
gested extension consists of multiple words or
whole phrases. Ideally, the whole sentence should
be suggested completely and the human translator
should have the freedom to accept any prefix of
the suggested translation.
In the following, we will first describe the prob-
lem from a statistical point of view. For the re-
sulting decision rule, we will describe efficient ap-
proximations based on word hypotheses graphs.
Afterwards, we will present some results. Finally,
we will describe the implemented prototype sys-
tem.
</bodyText>
<sectionHeader confidence="0.982757" genericHeader="introduction">
2 Statistical Machine Translation
</sectionHeader>
<bodyText confidence="0.943277666666667">
We are given a source language (&apos;French&apos;) sen-
tence = f3 . . . ff, which is to be trans-
lated into a target language ( &apos;English&apos;) sentence
ef = el ... 6, ... el-. Among all possible target
language sentences, we will choose the sentence
of unknown length / with the highest probability:
</bodyText>
<equation confidence="0.9854645">
ei = argmax {Pr (ei f )} (1)
argmax {Pr (ef ) • Pr (fil lef )1 (2)
</equation>
<bodyText confidence="0.999989615384615">
The decomposition into two knowledge sources
in Eq. 2 is the so-called source-channel approach
to statistical machine translation (Brown et al.,
1990). It allows an independent modeling of tar-
get language model Pr (ef ) and translation model
Pr(filef)- The target language model describes
the well-formedness of the target language sen-
tence. The translation model links the source lan-
guage sentence to the target language sentence.
The argmax operation denotes the search problem,
i.e. the generation of the output sentence in the tar-
get language. Here, we maximize over all possible
target language sentences.
</bodyText>
<sectionHeader confidence="0.999351" genericHeader="method">
3 Interactive Machine Translation
</sectionHeader>
<bodyText confidence="0.9984026">
In a statistical approach, the problem of finding
an extension ef+1 of a given prefix 61 can be de-
scribed by constraining the search to those sen-
tences ef that contain ej as prefix. So, we max-
imize over all possible extensions
</bodyText>
<equation confidence="0.974833">
= argmax {Pr(el) • Pr(fillef)} (3)
</equation>
<bodyText confidence="0.999945652173913">
For simplicity, we formulated this equation on the
level of whole words, but of course, the same
method can also be applied at the character level.
In an interactive machine translation environ-
ment, we have to evaluate this quantity after ev-
ery key-stroke of the human user and compute the
corresponding extension. For the practicability of
this approach, an efficient maximization in Eq. 3
is very important. For the human user, a response
time larger than a fraction of a second is not ac-
ceptable. The search algorithms developed so far
are not able to achieve this efficiency without an
unacceptable amount of search errors. The one we
will use usually takes a few seconds per sentence.
Hence, we have to perform certain simplifications
making the search problem feasible.
Our solution is to precompute a subset of pos-
sible word sequences. The search in Eq. 3 is
then constrained to this set of hypotheses. As
data structure for efficiently representing the set
of possible word sequences, we use word hypothe-
ses graphs (Ney and Aubert, 1994; Ueffing et al.,
2002) .
</bodyText>
<sectionHeader confidence="0.979302" genericHeader="method">
4 Alignment Templates
</sectionHeader>
<bodyText confidence="0.999964142857143">
As specific machine translation method, we use
the alignment template approach (Och et al.,
1999). The key elements of this approach are the
alignment templates, which are pairs of source and
target language phrases together with an alignment
between the words within the phrases. The advan-
tage of the alignment template approach compared
to single word-based statistical translation models
is that word context and local changes in word or-
der are explicitly considered.
The alignment template model refines the trans-
lation probability Pr (fil ef)by introducing two
hidden variables z and a fc for the K alignment
templates and the alignment of the alignment tem-
</bodyText>
<page confidence="0.942046">
388
</page>
<equation confidence="0.87613">
plates:
Pr(g I ef) = E pr(afc ef) .
z1 a1
Pr(Z11 ef) • Pr ( f z1 a1 afc, ef)
</equation>
<bodyText confidence="0.999967166666667">
Hence, we obtain three different probability
distributions: Pr (at&apos; ef ), Pr (zic afc ef) and
Pr(fjfz. 01( , ef). Here, we omit a detailed de-
scription of modeling and training as this is not
relevant for the subsequent exposition. For further
details, see (Och et al., 1999).
</bodyText>
<sectionHeader confidence="0.990442" genericHeader="method">
5 Word Hypotheses Graphs
</sectionHeader>
<bodyText confidence="0.999869272727272">
A word hypotheses graph is a directed acyclic
graph G = (V, E). It is a subset of the search
graph and is computed as a byproduct of the search
algorithm. Each node n E V corresponds to a par-
tial translation hypothesis. Each edge (n, n&apos;)
E is annotated with both a target language word
e(n,n&apos;) and the associated extension probability
p(n n&apos;) of language and translation model. The
word hypotheses graph is constructed in such a
way that the extension probabilities only depend
on the two adjacent nodes. So, these probabilities
are independent of the considered path through the
graph. For simplicity, we assume that there exists
exactly one goal and one start node. For a more de-
tailed description of word hypotheses graphs, see
(Ueffing et al., 2002). An example of a simplified
word hypotheses graph is shown in Fig. 1 for the
German source sentence &amp;quot;was hast du gesagt?&amp;quot;.
The English reference translation is &amp;quot;what did you
say?&amp;quot;.
For each node in the word hypotheses graph, the
maximum probability path to reach the goal node
is computed. This probability can be decomposed
into the so-called forward probability p(n), which
is the maximum probability to reach the node n
from the start node and the so-called backward
probability h (n), which is the maximum proba-
bility to reach the node n backwards from the goal
node.
The backward probability h(n) is an optimal
heuristic function in the spirit of A* search. Hav-
ing this information, we can compute efficiently
for each node n in the graph the best successor
</bodyText>
<equation confidence="0.941535">
node S (n):
S(n) = argmax {p(n) • p(n, n&apos;) • h(771)} (4)
n&apos;:(n,n1)EE
</equation>
<bodyText confidence="0.931093333333333">
As each node n corresponds to a partial translation
hypothesis el, the optimal extension of this prefix
is obtained by:
</bodyText>
<equation confidence="0.997375333333333">
= e(n. S (n)) (5)
ei+2 = (6)
ei+k — e(sk-1(n), sk (n)) (7)
</equation>
<bodyText confidence="0.999985157894737">
Hence, the function S provides the optimal word
sequence in a time complexity linear to the number
of words in the extension.
Yet, as the word hypotheses graph contains only
a subset of the possible word sequences, we might
face the problem that the prefix path is not part of
the word hypotheses graph. To avoid this prob-
lem, we perform a tolerant search in the word hy-
potheses graph. We select the set of nodes that
correspond to word sequences with minimum Lev-
enshtein distance (edit distance) to the given pre-
fix. This can be computed by a straightforward
extension of the normal Levenshtein algorithm for
word hypotheses graphs. From this set of nodes,
we choose the one with maximum probability and
compute the extension according to Eq. 4. Be-
cause of this approximation, the suggested trans-
lation extension might contain words that are al-
ready part of the translation prefix.
</bodyText>
<sectionHeader confidence="0.998025" genericHeader="method">
6 Evaluation Criterion
</sectionHeader>
<bodyText confidence="0.999985285714286">
As evaluation criterion, we use the key-stroke ra-
tio (KSR), which is the ratio of the number of
key-strokes needed to produce the single reference
translation using the interactive translation system
divided by the number of key-strokes needed to
simply type the reference translation. We make the
simplifying assumption that the user can accept an
arbitrary length of the proposed extension using a
single key-stroke. Hence, a key-stroke ratio of 1
means that the system was never able to suggest
a correct extension. A very small key-stroke ratio
means that the suggested extensions are often cor-
rect. This value gives an indication about the pos-
sible effective gain that can be achieved if this in-
</bodyText>
<page confidence="0.997224">
389
</page>
<figureCaption confidence="0.9838805">
Figure 1: Example of a word hypotheses graph for the German source sentence &amp;quot;was hast du gesagt?&amp;quot;
(English reference translation: &amp;quot;what did you say?&amp;quot;).
</figureCaption>
<bodyText confidence="0.999719769230769">
teractive translation system is used in a real trans-
lation task. On the one hand, the key-stroke ratio is
very optimistic with respect to the efficiency gain
of the user. On the other hand, it is a well-defined
objective criterion that we expect to be well corre-
lated to a more user-centered evaluation criterion.
A simplified example is shown in Tab. 1. We
manually selected paths in the word hypotheses
graph (Fig. 1) to illustrate the interaction with the
system. In practice, the system should translate
this short sentence correctly without any user in-
teraction. The reference translation is &amp;quot;what did
you say ?&amp;quot; and the first suggestion of the sys-
tem is &amp;quot;what do you say ?&amp;quot;. So, the user accepts
the prefix &amp;quot;what d&amp;quot; with one key-stroke (denoted
with a &amp;quot;#&amp;quot;) and then enters the correct character
&amp;quot;i&amp;quot;. The next suggestion of the system is &amp;quot;what
did you said ?&amp;quot;. Now, the user accepts the prefix
&amp;quot;what did you sa&amp;quot; and then types the character &amp;quot;y&amp;quot;.
Finally, the system suggests the correct translation
the user simply accepts. Overall, the user needed
5 key-strokes to produce the reference translation
with the interactive translation system. Simply
typing the reference translation would take 19 key-
strokes (including blanks and a return at the end).
So, the key-stroke ratio is 5/19 = 26.3%.
</bodyText>
<tableCaption confidence="0.999493">
Table 1: Example of the post-editing process.
</tableCaption>
<table confidence="0.998911833333334">
step source was hast du gesagt ?
no.
reference what did you say ?
1 prefix what do you say ?
extension # i
user
2 prefix what di ?
extension d you said
user # y
3 prefix what did you say
extension ?
user #
</table>
<sectionHeader confidence="0.998899" genericHeader="method">
7 Results
</sectionHeader>
<subsectionHeader confidence="0.791789">
7.1 Verbmobil
</subsectionHeader>
<bodyText confidence="0.999945285714286">
The first task, we present results on, is the VERB-
MOBIL task (Wahlster, 2000). The domain of this
corpus is appointment scheduling, travel planning,
and hotel reservation. It consists of transcriptions
of spontaneous speech. Table 2 shows the corpus
statistics of this corpus.
Table 3 shows the resulting key-stroke ratio and
the average extension time for various word hy-
potheses graph densities (i.e. the number of edges
per source word). The table shows the effect of
both single-word extensions and whole-sentence
extensions.
We see a strong correlation between the word
hypotheses graph density and the response time.
</bodyText>
<page confidence="0.999195">
390
</page>
<tableCaption confidence="0.8444715">
Table 2: Statistics of training and test corpus for Table 4: Statistics of training and test corpus for
Verbmobil (PP=perplexity). the Canadian Hansards task (PP=perplexity).
</tableCaption>
<table confidence="0.999929625">
German English
Train Sentences 58 073
Words 519 523 549 921
Vocabulary 7 939 4 672
Singletons 3 453 1 698
Test Sentences 251
Words 2 628 2 871
Tri gram PP - 30.5
French English
Train Sentences 1.5M
Words 24M 22M
Vocabulary 100 269 78 332
Singletons 40 199 31 319
Test Sentences 200
Words 2 124 2 246
Trigram PP - 180.5
</table>
<tableCaption confidence="0.978">
Table 3: Verbmobil: key-stroke ratio (KSR) and
</tableCaption>
<table confidence="0.944019764705882">
average extension time for various word hypothe-
ses graph densities (WGD).
extension type
WGD single-word full sentence
time KSR time KSR
[s] [%] [s] [go]
5 0.003 54.3 0.003 41.7
14 0.008 47.6 0.008 32.3
32 0.014 45.7 0.015 29.6
77 0.022 44.6 0.025 28.1
188 0.034 43.8 0.038 27.0
453 0.050 43.0 0.058 25.7
1030 0.071 42.3 0.091 25.7
2107 0.106 42.0 0.143 25.0
3892 0.161 41.9 0.226 25.1
6513 0.235 41.7 0.345 24.7
10064 0.333 41.6 0.505 24.5
</table>
<bodyText confidence="0.999549181818182">
When using a larger word hypotheses graph, a
considerably larger amount of time is needed to
search for the optimal extension. On the other
hand, there is a reduction of the KSR: in the
case of single-word extensions, the KSR improves
from 54.3% and 0.003 seconds per extension to
41.6% and 0.333 seconds per extension. Signif-
icantly better results are obtained by performing
whole-sentence extensions. Here, the KSR im-
proves from 41.7% and 0.003 seconds per exten-
sion to 24.5% and 0.505 seconds per extension.
</bodyText>
<subsectionHeader confidence="0.993854">
7.2 Canadian Hansards
</subsectionHeader>
<bodyText confidence="0.999923588235294">
Additional experiments were carried out on the
Canadian Hansards task. This task contains the
proceedings of the Canadian parliament, which are
kept by law in both French and English. About
3 million parallel sentences of this bilingual data
have been made available by the Linguistic Data
Consortium (LDC). Here, we use a subset of the
data containing only sentences with a maximum
length of 30 words. Table 4 shows the training
and test corpus statistics.
Table 5 shows the resulting key-stroke ratio and
the average extension time for various word hy-
potheses graph densities. Again, we show the ef-
fect of both single-word extensions and whole-
sentence extensions.
The results are similar to the Verbmobil task: by
using a larger word hypotheses graph, a consid-
erably larger amount of time is needed to search
the word hypotheses graph, but on the other hand
there is an improvement of the KSR: in the case of
single-word extensions, the KSR improves from
62.9% and 0.003 seconds per extension to 50.3%
and 0.436 seconds per extension. As for the Verb-
mobil task, significantly better results are obtained
by performing whole-sentence extensions. Here,
the KSR improves from 46.3% and 0.002 seconds
per extension to 33.1% and 0.556 seconds per ex-
tension.
Regarding the experiments carried out on both
tasks, we conclude that the set of possible can-
didate translations can be indeed represented by
word hypotheses graphs. In addition, we conclude
that whole-sentence extensions give significantly
better results than single-word extensions.
</bodyText>
<page confidence="0.998961">
391
</page>
<tableCaption confidence="0.98076">
Table 5: Hansards: key-stroke ratio (KSR) and av-
</tableCaption>
<table confidence="0.949681142857143">
erage extension time for various word hypotheses
graph densities (WGD).
extension type
WGD single-word full sentence
time KSR time KSR
[s] re] [s] [%]
11 0.003 62.9 0.002 46.3
22 0.009 58.0 0.009 40.9
83 0.028 54.2 0.028 36.6
363 0.059 52.9 0.061 35.8
1306 0.104 52.0 0.113 34.9
3673 0.172 51.3 0.194 34.0
8592 0.274 50.8 0.329 33.5
17301 0.436 50.3 0.556 33.1
</table>
<sectionHeader confidence="0.599286" genericHeader="method">
8 Prototype System
</sectionHeader>
<bodyText confidence="0.999469625">
In the following, we describe how the presented
method has been used to build an operational
prototype for interactive translation. This pro-
totype has been build as part of the EU project
TransType 2 (IST-2001-32091). It allows an effec-
tive interaction between the human translator and
the machine translation system. The prototype has
the following key properties:
</bodyText>
<listItem confidence="0.805902615384615">
• The system uses the alignment template ap-
proach described in section 4 as translation
engine.
• It allows the machine translation output to
be interactively post-edited. The system sug-
gests a full-sentence extension of the current
translation prefix. The user either accepts the
complete suggestion or a certain prefix.
• The human translator is able to obtain a list
of alternative words at a specific position in
the sentence. This helps the human translator
to find alternative translations.
• Since the system is based on the statistical
approach, it can learn from existing sample
translations. Therefore, it adapts to very spe-
cific domains without much human interven-
tion. Unlike systems based on translation
memories, the system is able to provide sug-
gestions also for sentences that have not been
seen in the bilingual translation examples.
• The system can also learn interactively from
those sentences that have been corrected or
accepted by the user. The user may request
that a specific set of sentences be added to the
knowledge base. A major aim of this feature
is an improved user acceptability as the ma-
</listItem>
<bodyText confidence="0.995631052631579">
chine translation environment is able to adapt
rapidly and easily to a new vocabulary.
The developed system seems to have advan-
tages over currently used machine translation or
translation memory environments as it combines
important concepts from these areas into a sin-
gle application. The two major advantages are the
ability to suggest full-sentence extensions and the
ability to learn interactively from user corrections.
The system is implemented as a client—server
application. The server performs the actual trans-
lations as well as all time-consuming operations
such as computing the extensions. The client in-
cludes only the user interface and can therefore
run on a small computer. Client and server are
connected via Internet or Intranet.
There is ongoing research to experimentally
study the productivity gain of such a system for
professional human translators.
</bodyText>
<sectionHeader confidence="0.999549" genericHeader="related work">
9 Related Work
</sectionHeader>
<bodyText confidence="0.999935588235294">
As already mentioned, previous work towards in-
teractive machine translation has been carried out
in the TransType project (Foster et al., 1996; Fos-
ter et al., 1997; Langlais et al., 2000).
In (Foster et al., 2002) a so-called &amp;quot;user model&amp;quot;
has been introduced to maximize the expected
benefit of the human translator. This user model
consists of two components. The first component
models the benefit of a certain extension. The sec-
ond component models the acceptance probability
of this extension. The user model is used to de-
termine the length of the proposed extension mea-
sured in characters.
The resulting decision rule is more centered on
the human user than the one in Eq. 3. It takes into
account, e.g., the time the user needs to read the
extension (at least approximatively).
</bodyText>
<page confidence="0.994136">
392
</page>
<bodyText confidence="0.9999695625">
In principle, the decision rule in Eq. 3 can be
extended by such a user model. In (Foster et al.,
2002) the assumption is made that &amp;quot;the user ed-
its only by erasing wrong character from the end
of a proposal&amp;quot;. The approach in this paper is dif-
ferent in that the user works from left to right by
either accepting or correcting the proposed trans-
lation. Therefore, in our approach, we would have
to modify the details of the user model.
An additional difference is the used translation
engine: in (Foster et al., 2002) a simple translation
model is chosen for efficiency reasons, namely a
maximum entropy version of IBM2. Here, we
use a fully fledged translation model and deal with
the efficiency problem by using word hypotheses
graphs.
</bodyText>
<sectionHeader confidence="0.998075" genericHeader="conclusions">
10 Conclusions
</sectionHeader>
<bodyText confidence="0.9999874">
We have suggested an interactive machine trans-
lation environment for computer assisted transla-
tion. It assists the human user by interactively
reacting upon his/her input. The system suggests
full-sentence extensions of the current translation
prefix. The human user can accept any prefix of
this extension.
We have used a fully fledged translation sys-
tem, namely the alignment template approach, to
produce high quality extensions. Word hypotheses
graphs have been used to allow an efficient search
for the optimal extension. Using this method, the
amount of key-strokes needed to produce the ref-
erence translation reduces significantly.
Additional optimizations of the word hypothe-
ses graphs might improve the efficiency of the
search. E.g., forward-backward pruning (Sixtus
and Ortmanns, 1999) could be used to reduce the
word hypotheses graph density. Further improve-
ments could be achieved by incorporating a more
user-centered cost function like the user model in
(Foster et al., 2002). To answer the question of
how long the extension should be, a good con-
fidence measure could be useful (Wessel et al.,
2001).
</bodyText>
<sectionHeader confidence="0.985836" genericHeader="acknowledgments">
11 Acknowledgement
</sectionHeader>
<bodyText confidence="0.966156">
This work has been partially funded by the EU
project TransType 2, IST-2001-32091.
</bodyText>
<sectionHeader confidence="0.978241" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99979542">
P. F. Brown, J. Cocke, S. A. Della Pietra, V. J. Della
Pietra, F. Jelinek, J. D. Lafferty, R. L. Mercer,
and P. S. Roossin. 1990. A statistical approach
to machine translation. Computational Linguistics,
16(2):79-85, June.
G. Foster, P. Isabelle, and P. Plamondon. 1996. Word
completion: A first step toward target-text mediated
IMT. In COLING &apos;96: The 16th Int. Conf on Com-
putational Linguistics, pages 394-399, Copenhagen,
Denmark, August.
G. Foster, P. Isabelle, and P. Plamondon. 1997. Target-
text mediated interactive machine translation. Ma-
chine Translation, 12(1):175-194.
G. Foster, P. Langlais, and G. Lapalme. 2002. User-
friendly text prediction for translators. In Proceed-
ings of the 2002 Conference on Empirical Methods
in Natural Language Processing (EMNLP 2002),
pages 46-51, Philadelphia, July.
P. Langlais, G. Foster, and G. Lapalme. 2000.
TransType: a computer-aided translation typing sys-
tem. In Workshop on Embedded Machine Transla-
tion Systems, pages 46-51, Seattle, Wash., May.
H. Ney and X. Aubert. 1994. A word graph algorithm
for large vocabulary continuous speech recognition.
In Proc. Mt. Conf on Spoken Language Processing,
pages 1355-1358, Yokohama, Japan, September.
F. J. Och, C. Tillmann, and H. Ney. 1999. Improved
alignment models for statistical machine translation.
In Proc. of the Joint SIGDAT Conf on Empirical
Methods in Natural Language Processing and Very
Large Corpora, pages 20-28, University of Mary-
land, College Park, MD, June.
A. Sixtus and S. Ortmanns. 1999. High quality word
graphs using forward-backward pruning. In Proc.
Mt. Conf on Acoustics, Speech, and Signal Process-
ing, volume 2, pages 593-596, Phoenix, AZ, USA,
March.
N. Ueffing, F. J. Och, and H. Ney. 2002. Generation
of word graphs in statistical machine translation. In
Proc. Conf on Empirical Methods for Natural Lan-
guage Processing, pages 156-163, Philadelphia, PA,
July.
W. Wahlster, editor. 2000. Verbmobil: Foundations
of speech-to-speech translations. Springer Verlag,
Berlin, Germany, July.
F. Wessel, R. Schltiter, K. Macherey, and H. Ney.
2001. Confidence measures for large vocabulary
continuous speech recognition. IEEE Transactions
on Speech and Audio Processing, 9(3):288-298,
March.
</reference>
<page confidence="0.999571">
393
394
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.981259">
<title confidence="0.999667">Efficient Search for Interactive Statistical Machine Translation</title>
<author confidence="0.998637">Josef</author>
<author confidence="0.998637">Zens Ney</author>
<affiliation confidence="0.998644">of Computer Science VI - University of Technology</affiliation>
<abstract confidence="0.999437423076923">The goal of interactive machine translation is to improve the productivity of human translators. An interactive machine translation system operates as follows: the automatic system proposes a translation. Now, the human user has two options: to accept the suggestion or to correct it. During the post-editing process, the human user is assisted by the interactive system in the following way: the system suggests an extension of the current translation prefix. Then, the user either accepts this extension (completely or partially) or ignores it. The two most important factors of such an interactive system are the quality of the proposed extensions and the response time. Here, we will use a fully fledged translation system to ensure the quality of the proposed extensions. To achieve fast response times, we will use word hypotheses graphs as an efficient search space representation. We will show results of our approach on the Verbmobil task and on the Canadian Hansards task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>J Cocke</author>
<author>S A Della Pietra</author>
<author>V J Della Pietra</author>
<author>F Jelinek</author>
<author>J D Lafferty</author>
<author>R L Mercer</author>
<author>P S Roossin</author>
</authors>
<title>A statistical approach to machine translation.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<pages>16--2</pages>
<contexts>
<context position="4310" citStr="Brown et al., 1990" startWordPosition="693" endWordPosition="696"> present some results. Finally, we will describe the implemented prototype system. 2 Statistical Machine Translation We are given a source language (&apos;French&apos;) sentence = f3 . . . ff, which is to be translated into a target language ( &apos;English&apos;) sentence ef = el ... 6, ... el-. Among all possible target language sentences, we will choose the sentence of unknown length / with the highest probability: ei = argmax {Pr (ei f )} (1) argmax {Pr (ef ) • Pr (fil lef )1 (2) The decomposition into two knowledge sources in Eq. 2 is the so-called source-channel approach to statistical machine translation (Brown et al., 1990). It allows an independent modeling of target language model Pr (ef ) and translation model Pr(filef)- The target language model describes the well-formedness of the target language sentence. The translation model links the source language sentence to the target language sentence. The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language. Here, we maximize over all possible target language sentences. 3 Interactive Machine Translation In a statistical approach, the problem of finding an extension ef+1 of a given prefix 61 can be described</context>
</contexts>
<marker>Brown, Cocke, Pietra, Pietra, Jelinek, Lafferty, Mercer, Roossin, 1990</marker>
<rawString>P. F. Brown, J. Cocke, S. A. Della Pietra, V. J. Della Pietra, F. Jelinek, J. D. Lafferty, R. L. Mercer, and P. S. Roossin. 1990. A statistical approach to machine translation. Computational Linguistics, 16(2):79-85, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Foster</author>
<author>P Isabelle</author>
<author>P Plamondon</author>
</authors>
<title>Word completion: A first step toward target-text mediated IMT.</title>
<date>1996</date>
<booktitle>In COLING &apos;96: The 16th Int. Conf on Computational Linguistics,</booktitle>
<pages>394--399</pages>
<location>Copenhagen, Denmark,</location>
<contexts>
<context position="2161" citStr="Foster et al., 1996" startWordPosition="333" endWordPosition="336">n such an environment, the main goal of the machine translation system is not to produce translations that are understandable for an inexperienced recipient but to support a professional human posteditor. Typically, a better quality of the produced machine translation text yields a reduced post-editing effort. From an application point of view, many additional aspects have to be considered: the user interface, the used formats and the additional support tools such as lexicons, terminological databases or translation memories. The concept of interactive machine translation, first suggested by (Foster et al., 1996), finds a very natural implementation in the framework of statistical machine translation. In interactive machine translation, the basic idea is to provide an environment to a human translator that interactively reacts upon the input as the user writes or corrects the translation. In such an approach, the system suggests an extension of a sentence that the human user either accepts or ignores. An implementation of such a tool was performed in the TransType project (Foster et al., 1996; Foster et al., 1997; Langlais et al., 2000). The user interface of the TransType system combines a machine tr</context>
<context position="18933" citStr="Foster et al., 1996" startWordPosition="3149" endWordPosition="3152">r corrections. The system is implemented as a client—server application. The server performs the actual translations as well as all time-consuming operations such as computing the extensions. The client includes only the user interface and can therefore run on a small computer. Client and server are connected via Internet or Intranet. There is ongoing research to experimentally study the productivity gain of such a system for professional human translators. 9 Related Work As already mentioned, previous work towards interactive machine translation has been carried out in the TransType project (Foster et al., 1996; Foster et al., 1997; Langlais et al., 2000). In (Foster et al., 2002) a so-called &amp;quot;user model&amp;quot; has been introduced to maximize the expected benefit of the human translator. This user model consists of two components. The first component models the benefit of a certain extension. The second component models the acceptance probability of this extension. The user model is used to determine the length of the proposed extension measured in characters. The resulting decision rule is more centered on the human user than the one in Eq. 3. It takes into account, e.g., the time the user needs to read </context>
</contexts>
<marker>Foster, Isabelle, Plamondon, 1996</marker>
<rawString>G. Foster, P. Isabelle, and P. Plamondon. 1996. Word completion: A first step toward target-text mediated IMT. In COLING &apos;96: The 16th Int. Conf on Computational Linguistics, pages 394-399, Copenhagen, Denmark, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Foster</author>
<author>P Isabelle</author>
<author>P Plamondon</author>
</authors>
<title>Targettext mediated interactive machine translation.</title>
<date>1997</date>
<journal>Machine Translation,</journal>
<pages>12--1</pages>
<contexts>
<context position="2671" citStr="Foster et al., 1997" startWordPosition="418" endWordPosition="421">ranslation memories. The concept of interactive machine translation, first suggested by (Foster et al., 1996), finds a very natural implementation in the framework of statistical machine translation. In interactive machine translation, the basic idea is to provide an environment to a human translator that interactively reacts upon the input as the user writes or corrects the translation. In such an approach, the system suggests an extension of a sentence that the human user either accepts or ignores. An implementation of such a tool was performed in the TransType project (Foster et al., 1996; Foster et al., 1997; Langlais et al., 2000). The user interface of the TransType system combines a machine translation system and a text editor into a single application. The human translator types the translation of a given source text. For each prefix of a word, the machine translation system computes the most probable extension of this word and presents this to the user. The human translator either accepts this translation by press387 ing a certain key or ignores the suggestion and continues typing. Rather than single-word predictions, as in the TransType approach, it is preferable that the suggested extensio</context>
<context position="18954" citStr="Foster et al., 1997" startWordPosition="3153" endWordPosition="3157">stem is implemented as a client—server application. The server performs the actual translations as well as all time-consuming operations such as computing the extensions. The client includes only the user interface and can therefore run on a small computer. Client and server are connected via Internet or Intranet. There is ongoing research to experimentally study the productivity gain of such a system for professional human translators. 9 Related Work As already mentioned, previous work towards interactive machine translation has been carried out in the TransType project (Foster et al., 1996; Foster et al., 1997; Langlais et al., 2000). In (Foster et al., 2002) a so-called &amp;quot;user model&amp;quot; has been introduced to maximize the expected benefit of the human translator. This user model consists of two components. The first component models the benefit of a certain extension. The second component models the acceptance probability of this extension. The user model is used to determine the length of the proposed extension measured in characters. The resulting decision rule is more centered on the human user than the one in Eq. 3. It takes into account, e.g., the time the user needs to read the extension (at lea</context>
</contexts>
<marker>Foster, Isabelle, Plamondon, 1997</marker>
<rawString>G. Foster, P. Isabelle, and P. Plamondon. 1997. Targettext mediated interactive machine translation. Machine Translation, 12(1):175-194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Foster</author>
<author>P Langlais</author>
<author>G Lapalme</author>
</authors>
<title>Userfriendly text prediction for translators.</title>
<date>2002</date>
<booktitle>In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<pages>46--51</pages>
<location>Philadelphia,</location>
<contexts>
<context position="19004" citStr="Foster et al., 2002" startWordPosition="3163" endWordPosition="3166">n. The server performs the actual translations as well as all time-consuming operations such as computing the extensions. The client includes only the user interface and can therefore run on a small computer. Client and server are connected via Internet or Intranet. There is ongoing research to experimentally study the productivity gain of such a system for professional human translators. 9 Related Work As already mentioned, previous work towards interactive machine translation has been carried out in the TransType project (Foster et al., 1996; Foster et al., 1997; Langlais et al., 2000). In (Foster et al., 2002) a so-called &amp;quot;user model&amp;quot; has been introduced to maximize the expected benefit of the human translator. This user model consists of two components. The first component models the benefit of a certain extension. The second component models the acceptance probability of this extension. The user model is used to determine the length of the proposed extension measured in characters. The resulting decision rule is more centered on the human user than the one in Eq. 3. It takes into account, e.g., the time the user needs to read the extension (at least approximatively). 392 In principle, the decisio</context>
</contexts>
<marker>Foster, Langlais, Lapalme, 2002</marker>
<rawString>G. Foster, P. Langlais, and G. Lapalme. 2002. Userfriendly text prediction for translators. In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing (EMNLP 2002), pages 46-51, Philadelphia, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Langlais</author>
<author>G Foster</author>
<author>G Lapalme</author>
</authors>
<title>TransType: a computer-aided translation typing system.</title>
<date>2000</date>
<booktitle>In Workshop on Embedded Machine Translation Systems,</booktitle>
<pages>46--51</pages>
<location>Seattle, Wash.,</location>
<contexts>
<context position="2695" citStr="Langlais et al., 2000" startWordPosition="422" endWordPosition="425">The concept of interactive machine translation, first suggested by (Foster et al., 1996), finds a very natural implementation in the framework of statistical machine translation. In interactive machine translation, the basic idea is to provide an environment to a human translator that interactively reacts upon the input as the user writes or corrects the translation. In such an approach, the system suggests an extension of a sentence that the human user either accepts or ignores. An implementation of such a tool was performed in the TransType project (Foster et al., 1996; Foster et al., 1997; Langlais et al., 2000). The user interface of the TransType system combines a machine translation system and a text editor into a single application. The human translator types the translation of a given source text. For each prefix of a word, the machine translation system computes the most probable extension of this word and presents this to the user. The human translator either accepts this translation by press387 ing a certain key or ignores the suggestion and continues typing. Rather than single-word predictions, as in the TransType approach, it is preferable that the suggested extension consists of multiple w</context>
<context position="18978" citStr="Langlais et al., 2000" startWordPosition="3158" endWordPosition="3161">s a client—server application. The server performs the actual translations as well as all time-consuming operations such as computing the extensions. The client includes only the user interface and can therefore run on a small computer. Client and server are connected via Internet or Intranet. There is ongoing research to experimentally study the productivity gain of such a system for professional human translators. 9 Related Work As already mentioned, previous work towards interactive machine translation has been carried out in the TransType project (Foster et al., 1996; Foster et al., 1997; Langlais et al., 2000). In (Foster et al., 2002) a so-called &amp;quot;user model&amp;quot; has been introduced to maximize the expected benefit of the human translator. This user model consists of two components. The first component models the benefit of a certain extension. The second component models the acceptance probability of this extension. The user model is used to determine the length of the proposed extension measured in characters. The resulting decision rule is more centered on the human user than the one in Eq. 3. It takes into account, e.g., the time the user needs to read the extension (at least approximatively). 392</context>
</contexts>
<marker>Langlais, Foster, Lapalme, 2000</marker>
<rawString>P. Langlais, G. Foster, and G. Lapalme. 2000. TransType: a computer-aided translation typing system. In Workshop on Embedded Machine Translation Systems, pages 46-51, Seattle, Wash., May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Ney</author>
<author>X Aubert</author>
</authors>
<title>A word graph algorithm for large vocabulary continuous speech recognition.</title>
<date>1994</date>
<booktitle>In Proc. Mt. Conf on Spoken Language Processing,</booktitle>
<pages>1355--1358</pages>
<location>Yokohama, Japan,</location>
<contexts>
<context position="6111" citStr="Ney and Aubert, 1994" startWordPosition="993" endWordPosition="996">user, a response time larger than a fraction of a second is not acceptable. The search algorithms developed so far are not able to achieve this efficiency without an unacceptable amount of search errors. The one we will use usually takes a few seconds per sentence. Hence, we have to perform certain simplifications making the search problem feasible. Our solution is to precompute a subset of possible word sequences. The search in Eq. 3 is then constrained to this set of hypotheses. As data structure for efficiently representing the set of possible word sequences, we use word hypotheses graphs (Ney and Aubert, 1994; Ueffing et al., 2002) . 4 Alignment Templates As specific machine translation method, we use the alignment template approach (Och et al., 1999). The key elements of this approach are the alignment templates, which are pairs of source and target language phrases together with an alignment between the words within the phrases. The advantage of the alignment template approach compared to single word-based statistical translation models is that word context and local changes in word order are explicitly considered. The alignment template model refines the translation probability Pr (fil ef)by in</context>
</contexts>
<marker>Ney, Aubert, 1994</marker>
<rawString>H. Ney and X. Aubert. 1994. A word graph algorithm for large vocabulary continuous speech recognition. In Proc. Mt. Conf on Spoken Language Processing, pages 1355-1358, Yokohama, Japan, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>C Tillmann</author>
<author>H Ney</author>
</authors>
<title>Improved alignment models for statistical machine translation.</title>
<date>1999</date>
<booktitle>In Proc. of the Joint SIGDAT Conf on Empirical Methods in Natural Language Processing and Very Large Corpora,</booktitle>
<pages>20--28</pages>
<institution>University of Maryland,</institution>
<location>College Park, MD,</location>
<contexts>
<context position="6256" citStr="Och et al., 1999" startWordPosition="1016" endWordPosition="1019">ciency without an unacceptable amount of search errors. The one we will use usually takes a few seconds per sentence. Hence, we have to perform certain simplifications making the search problem feasible. Our solution is to precompute a subset of possible word sequences. The search in Eq. 3 is then constrained to this set of hypotheses. As data structure for efficiently representing the set of possible word sequences, we use word hypotheses graphs (Ney and Aubert, 1994; Ueffing et al., 2002) . 4 Alignment Templates As specific machine translation method, we use the alignment template approach (Och et al., 1999). The key elements of this approach are the alignment templates, which are pairs of source and target language phrases together with an alignment between the words within the phrases. The advantage of the alignment template approach compared to single word-based statistical translation models is that word context and local changes in word order are explicitly considered. The alignment template model refines the translation probability Pr (fil ef)by introducing two hidden variables z and a fc for the K alignment templates and the alignment of the alignment tem388 plates: Pr(g I ef) = E pr(afc e</context>
</contexts>
<marker>Och, Tillmann, Ney, 1999</marker>
<rawString>F. J. Och, C. Tillmann, and H. Ney. 1999. Improved alignment models for statistical machine translation. In Proc. of the Joint SIGDAT Conf on Empirical Methods in Natural Language Processing and Very Large Corpora, pages 20-28, University of Maryland, College Park, MD, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Sixtus</author>
<author>S Ortmanns</author>
</authors>
<title>High quality word graphs using forward-backward pruning.</title>
<date>1999</date>
<booktitle>In Proc. Mt. Conf on Acoustics, Speech, and Signal Processing,</booktitle>
<volume>2</volume>
<pages>593--596</pages>
<location>Phoenix, AZ, USA,</location>
<marker>Sixtus, Ortmanns, 1999</marker>
<rawString>A. Sixtus and S. Ortmanns. 1999. High quality word graphs using forward-backward pruning. In Proc. Mt. Conf on Acoustics, Speech, and Signal Processing, volume 2, pages 593-596, Phoenix, AZ, USA, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ueffing</author>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>Generation of word graphs in statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proc. Conf on Empirical Methods for Natural Language Processing,</booktitle>
<pages>156--163</pages>
<location>Philadelphia, PA,</location>
<contexts>
<context position="6134" citStr="Ueffing et al., 2002" startWordPosition="997" endWordPosition="1000">larger than a fraction of a second is not acceptable. The search algorithms developed so far are not able to achieve this efficiency without an unacceptable amount of search errors. The one we will use usually takes a few seconds per sentence. Hence, we have to perform certain simplifications making the search problem feasible. Our solution is to precompute a subset of possible word sequences. The search in Eq. 3 is then constrained to this set of hypotheses. As data structure for efficiently representing the set of possible word sequences, we use word hypotheses graphs (Ney and Aubert, 1994; Ueffing et al., 2002) . 4 Alignment Templates As specific machine translation method, we use the alignment template approach (Och et al., 1999). The key elements of this approach are the alignment templates, which are pairs of source and target language phrases together with an alignment between the words within the phrases. The advantage of the alignment template approach compared to single word-based statistical translation models is that word context and local changes in word order are explicitly considered. The alignment template model refines the translation probability Pr (fil ef)by introducing two hidden va</context>
<context position="7956" citStr="Ueffing et al., 2002" startWordPosition="1311" endWordPosition="1314"> the search algorithm. Each node n E V corresponds to a partial translation hypothesis. Each edge (n, n&apos;) E is annotated with both a target language word e(n,n&apos;) and the associated extension probability p(n n&apos;) of language and translation model. The word hypotheses graph is constructed in such a way that the extension probabilities only depend on the two adjacent nodes. So, these probabilities are independent of the considered path through the graph. For simplicity, we assume that there exists exactly one goal and one start node. For a more detailed description of word hypotheses graphs, see (Ueffing et al., 2002). An example of a simplified word hypotheses graph is shown in Fig. 1 for the German source sentence &amp;quot;was hast du gesagt?&amp;quot;. The English reference translation is &amp;quot;what did you say?&amp;quot;. For each node in the word hypotheses graph, the maximum probability path to reach the goal node is computed. This probability can be decomposed into the so-called forward probability p(n), which is the maximum probability to reach the node n from the start node and the so-called backward probability h (n), which is the maximum probability to reach the node n backwards from the goal node. The backward probability h(</context>
</contexts>
<marker>Ueffing, Och, Ney, 2002</marker>
<rawString>N. Ueffing, F. J. Och, and H. Ney. 2002. Generation of word graphs in statistical machine translation. In Proc. Conf on Empirical Methods for Natural Language Processing, pages 156-163, Philadelphia, PA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wahlster</author>
<author>editor</author>
</authors>
<title>Verbmobil: Foundations of speech-to-speech translations.</title>
<date>2000</date>
<publisher>Springer Verlag,</publisher>
<location>Berlin, Germany,</location>
<marker>Wahlster, editor, 2000</marker>
<rawString>W. Wahlster, editor. 2000. Verbmobil: Foundations of speech-to-speech translations. Springer Verlag, Berlin, Germany, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Wessel</author>
<author>R Schltiter</author>
<author>K Macherey</author>
<author>H Ney</author>
</authors>
<title>Confidence measures for large vocabulary continuous speech recognition.</title>
<date>2001</date>
<booktitle>IEEE Transactions on Speech and Audio Processing,</booktitle>
<pages>9--3</pages>
<marker>Wessel, Schltiter, Macherey, Ney, 2001</marker>
<rawString>F. Wessel, R. Schltiter, K. Macherey, and H. Ney. 2001. Confidence measures for large vocabulary continuous speech recognition. IEEE Transactions on Speech and Audio Processing, 9(3):288-298, March.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>