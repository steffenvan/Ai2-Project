<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.829083">
American Journal of Computational Linguistics Microfiche 53
</note>
<sectionHeader confidence="0.996248" genericHeader="method">
COMPUTER UNDERSTANDING OF
PHYSICS PROBLEMS
STATED IN NATURAL LANGUAGE
</sectionHeader>
<author confidence="0.921016">
GORDON S. NOVAK JR.
</author>
<affiliation confidence="0.997537">
Computer Science Department
University of Texas
</affiliation>
<author confidence="0.203033">
Austin 78712
</author>
<affiliation confidence="0.309672">
Copyright C) 1976&apos;
Association for Computational Linguistics
</affiliation>
<sectionHeader confidence="0.487938" genericHeader="method">
SUMMARY
</sectionHeader>
<bodyText confidence="0.989554794117647">
This paper describes a computer program, called ISAAC, which can read,
understand, solve, and draw pictures of physics problems stated in English. The
program has solved twenty problems, most of which were taken unedited from high
school and college physics texts. These problems involve . rigid bodies in static
equilibrium, and include such objects ,as levers, pivots, weights, ropes, and springs in
various configurations. An example of the class of problems solved is the following
(from Sehaum&apos;s Outline of College Physics):
The foot of a ladder rests against a &apos;c&apos;ertical wall and on a horizontal
floor. The top of the ladder is supporvi4 from the wall by a horizontal
rope 30 ft long. The laddei is 50 ft long, weighs 100 lb W ith its center of
gravity 20 ft from the foot, and a 150 lb man is 10 ft from the top.
Determine the tension in the rope.
In order to understand and solve such a problem, it is necessary to build an internal
model of the problem in which the various objects and then interrelationships are
adequately represented. Many of the relationships and features of the objects are not
specified explicitly in the problem statement but must be inferred by using common
sense knowledge of what is usual. In the abow example, we 14,:stime that the mato is
standing on the ladder, although this is not explicitly stated. Thus, the understanding of
a physics problem is an active process in Which the :=:entences of the problem statement
are used to guide the construction of a model which represents the relationships and
features of objects with much greater detail and specificity rhan, they are specified in the
original problem statement.
In this paper, we investigate ways in which the meanings of phrases and
sentences may be understood and related to a developing model of the problem, using
common sense knowledge (represented by computer programs) to aid the understanding
process. Was of representing objects and their relationships are developed. These
representations, which are originally created in response to the sentences in the problem
statement, are further elaborated by processes which construct.a geometric model of the
problem, associate canonical objects (such as.a point mass) with physical objects t.su(h
as a person), write and solve equations which describe the interactions of the objects
and construct a diagram of the problem.
This paper is a slightly edited version of the author.s Ph.D. dissertation. I
am grateful to my committee membeis, Professors John Loehlin, Woodrow Bledsoe,
and Norman Martin, and especially to my supervising pcofeswi., liobext F. Simmons.
</bodyText>
<sectionHeader confidence="0.535881" genericHeader="method">
TABLE OF CONTENTS
</sectionHeader>
<keyword confidence="0.312482">
Page
</keyword>
<sectionHeader confidence="0.900357" genericHeader="method">
SUMMARY 2
LIST OF FIGURES 5
1. INTRODUCTION AND OVERVIEW 6
</sectionHeader>
<address confidence="0.815322266666667">
1.1 Introduction 6
1.2 Overview of the Program 6
2. REVIEW OF PREVIOUS WORK 10
2.1 Natural Language Problem Solvers 4.0
2.1.1 Bobrow&apos;s STUDENT 10
Chamiak&apos;s CARPS 11
2.1.3 Gelb&apos;s HAPPINESS 11
2.1.4 Heidorn&apos;s Simulation Programming System 11
2.2 Natural Language Processing 12.
2.2.1 Woods&apos; Augmented Transition Networks
2.2.2 Winograd&apos;s SHRDLU
2.2.3 Wilks&apos; Preferential Semantics 13
2.2;4 Simmons&apos; Semantic Networks 14
2.2.5 Schank&apos;s Conceptual Dependency 14
2.3 Minsky&apos;s Frame System Theory 15
</address>
<sectionHeader confidence="0.760773" genericHeader="method">
3. PARSING 16
</sectionHeader>
<subsectionHeader confidence="0.79659925">
3.1 Introduction 16
3.2 Control Structure of the Parser 17
3.3 Data Structures Produced During Parsing 19
3.4 Noun Phrase Parsing 20
</subsectionHeader>
<footnote confidence="0.763616857142857">
:3.4.1 Basic Noun Phrase 90
3.4.2 Noun Phrase Compadrids and Modifiers 95
3.4.3 Noun Phrase Variants 26
3.5 Verb Phrase Parsing 26
3.5.1 Basic Verb Group 26
3.5.2 Verb Phrase 28
3.6 Prepositional Phrase Parsing 28
</footnote>
<page confidence="0.52826">
4
</page>
<address confidence="0.657483971428571">
3.7 Clause Parsing 30
3,8 Conclusion 31
4. SEMANTICS :33
4.1 Introduction :33
4.2 Preliminary Modifier Processing 34
4.3 Preposition Semantics :34
4.3:1 Semantics of the Preposition &amp;quot;OF&amp;quot; 35
4.3.2 Semantics of Other Prepositions 36
4.3.3 Definition and Translation of Prepositions 38
4.4 Referent Identification &apos;39
4.4.1 Identifying Physical Entity Referents :39
4.4.2 Identifying Location Referents 4:3
4.4.3 Attachment Identification 49
4.5 Modifier Semantics 49
4.6 Verb Semantics 51
4.6.1 Semantics of the Verb &amp;quot;BE&amp;quot; 51
4.6.2 Semantics of the Verb &amp;quot;SUPPORT&amp;quot; 52
4.6.3 Semantics of Other Verbs 53
4.7 Question Semantics 54
5. CONSTRUCTION OF OBJECT FRAMES AND THE GEOMETRIC MODEL
5A Introduction 56
5.2 Making Canonical Object Frames 57
5.3 Geometric Model Construction 59
5.4 Frame Completion 62
5.5 Conclusion 6:3
6. PROBLEM SOLVING 64
6.1 Generation of Equations 64
6.2 Equation Solving e5
6.3 Answer Generation 67
7. PICTURE CONSTRUCTION 69
7.1 Constructing the Pieture Model 69
7.2 Drawing the Diagram 73
8. CONCLUSION 74
8.1 Methodology 7 I
8.2 Directions for Future Research 75
</address>
<equation confidence="0.496344">
U•— X 0) r—f Csq Cn C&apos;c:;) LCD N. Cf:) X
r— X X IX X X or: -^ X -IL CC &apos;&amp;quot;&amp;quot;:. r..N/ .7t4 C.0
</equation>
<figure confidence="0.9245208125">
,—,
z
3 -c z
C.) a.) t....
4-4 &apos;4.c&apos; 0
a)
- ---)
0 &apos; 0
. --.
al
Ce
CD S-4 44 4-)
P-4 CI
,—.
a)
:67:J. 0
&gt; a)
.&gt; CZ
o
0) hp td) tag) &gt;
Z Z Z Z
.4., ... .,... &apos;CI
bl) cZ -4-) Z CO
Z. ,-. F.
-•-•
7:1 0) 01
E E —
z r•■I
CZ 0 0 a)
Cr)
Cbnstant or Variable Represent Lion
LIST OF FIGURES
Verb Phrase Parsing Program
Flowchart of LOCNP
Flowchart of PHYSNP
4.) = ;4. ccl r.i: r...) 0
.-. s. 4-4 Z M s. cci E
0 0 0
ezt
44441
•--&amp;quot;&apos; &gt;a
Ce
r•-■
7; ,-. MI cZ
• o4 &apos;&amp;quot;... ...* P
-.-, • .4 ,...0 .--.
7..., ...., e-, ,-,
-I•-• • — --, CZS
-•-) .....• 47..) :-.
CI: &lt; ,.... (.7
Ce tx -.&apos;&apos;
0-•
e•■•
-
F.C)
X X) CO
P:1 PC) P4 R4
GNI CO .11 CN Cf) f--4 *--4 CV
ce) cf&amp;quot; .14 -14 in If) r•••.. N.
Potential Applications
BIBLIOGRAPHY
APPENDIX C: GENERATED STRUCTURES FOR A SAMPLE PROBLEM
Commonts on Individual Problems
World Knowledge
</figure>
<sectionHeader confidence="0.595320666666667" genericHeader="method">
APPENDIX B. OBJECT FRAME REPRESENTATION&apos;S
APPENDIX A: SAMPLE PROBLEM SOLUTIONS
1. Introduction alid Overview
</sectionHeader>
<subsectionHeader confidence="0.952555">
1.1 Introduction
</subsectionHeader>
<bodyText confidence="0.999503473684211">
This paper describes a computer program, called ISAAC, which is able to
read and understand physics problems stated in English, write equations for the
problems and solve them, and draw diagrams showing the objects in the problems and
their spatial relationships. The program has solved twenty problems, which were taken
essentially unedited from physics textbooks; some sample problems are shown, with the
drawings and answers generated by the program, in Appendix A.
While the diagram and answer to a problem are the most easily observable
outputs of the program, another significant output is its robust internal model of the
objects in the problem and their relationships. It is this mod.el which makes possible the
generation of the diagram and the answer to the problem. The internal model is robust
in the sense that it represents, in an explicit and readily accessible form, most of the
information which a competent human reader might be expected to derive from the
English problem statement. In addition to the ways in which it is currently used, the
model could be used for answering questions about the objects and their relationships,
or fbr generating a description of the problem in English or in another language, or for
generating other types of diagrams (such as a force diagram). Since it makes all of the
features and relationships of the objects explicit, the internal model is many times
larger than the original problem statement, which specifies only the major features and
leaves many details to be filled in by the? reader.
</bodyText>
<subsectionHeader confidence="0.809596">
1.2 Overview of the Program
</subsectionHeader>
<bodyText confidence="0.946936363636364">
The overall organization of the program and its data elements is shown in
Figure 1.1; programs are represented by boxes with double lines, and data structures by
plain boxes. In this section, we present an overview of the functions performed by each
group of programs and an overview of the types of information represented in the data
structures.
The process of understanding and solving a physics problem occurs in
several distinct steps. First, the problem statement is translated from English into a
structured parsing of the sentences, which is interpreted semantically to construct an
initial internal model. This model is interpreted to form a model in terms of canonical
physical obje :ts (such as a point mass). A geometric model which repreents the spatial
position and orientation of each object is constructed. Equations which describe the
</bodyText>
<figure confidence="0.988422097560975">
6
7
English
Problem
Statement
Parsing
Programs
_
Semantic
Programs
.14
Internal
Model
EUCLID
Geometric
Model
Picture
Model
Programs
Picture
Model
Picture
Generate=
Diagram
•
Canonical
Object
Model
Problem
Solver
_
Equations
and
Solutions
_
Answer
Generator
Answer
Frame
Creation
Programs
</figure>
<figureCaption confidence="0.999166">
Figure 1.1: Overall Program Organization
</figureCaption>
<bodyText confidence="0.995521175">
interactions of the objects according to physical laws are written and solved, and
answers are generated from the solutions. Finally, a picture model is constructed and
used to guide the drawing of a diagram of the problem. These processes are described
below in somewhat greater detail.
The parsing programs transform each sentence from a linear string of words
into a more structured form in which the relationships of words and phrases to each
other are clearly defined. Each type of phrase is parsed by a specialist program which
implements the grammar of the phrase as an augmented transition network. The
grammar programs call the semantic programs both to interpret the semantic network
structure- produced as a result of the parsing and to guide the parsing process itself,
Whether a particular modifier can be used to modify a noun phrase, for example, may
depend on the actual relationships between objects in the model of the problem. After
each clause has been parsed, the semantic routine associated with the main verb is
called to complete the semantic processing of the clause. This semantic processing
transfers the information provided by the sentence to* a growing model of the objects in
the problem and their relationshiPs. Once the semantic processing is completed, the
semantic network structures produced by the parser are no longer used. All of the
sentences in the problem statement are parsed and processed semantically before the
remaining parts of the program are executed.
The routines grouped under the heading of &amp;quot;Semantic Programs&amp;quot; perform a
variety of tasks. Semantic routines are associated with verbs and prepositions, and in
some cases with other words. Preposition semantic routines must determine the
appropriate sense-meaning of the preposition (using a decision network based on rough
semantic classifications of the modified phrase and the object of the preposition) and
then make the, appropriate changes in the semantic network token of the modified
phrase. Verb semantic routines typically act to transfer information from the semantic
network to the internal model. or define relationships among objects in the model;
determination of the proper sense-meaning of the verb is often needed as well. Another
major semantic task is the identification of the referent of a noun phrase. Given a noun
phrase which denotes an object or a location, it is necessary to ie.cide whether the
phrase refers to an object or location wh\ch already exists in the model (and if&apos; therr are
several possibilities, which one it refers to), or whether a new object or location must be
created as the referent of &apos;the phrase and added to the model.
After all the sentences of the problem statement have been read, the frame
creation programs a:re called to assign to each object a canonical object type (spell as a
point mass or an &amp;quot;ideal&amp;quot; spring) which represents the behavior of the object as it
eppears in the problem. The same type of actual object may be represented b:\1 different
canonical objects, depending on its context in the problem. Thus, a person be
represented as a pivot wheir carrying a plank, or as a point mass when standing on one.
Once a canonical object frame his been selected, the model of the object is examined to
</bodyText>
<equation confidence="0.98980593670886">
C-,
. 4-8 :-) a) ca
e..4 a; • s..4
4-
e
,....
.0. ,--4-4
•••• ! . 4--. e6
n :..
CI a 1) 0
:-.
•4-.4 ,..., ....
n Z.)
-a T.
;... CD
cl.., ci CI) n c4-•
n 11 0.0 ....
-4..,
n ::-.4.4 a)
0 ...-,
C 1-) Z ...a
.-.) ...e ...a -41.•
4... 7:3 te
- ,--,
a 0 rd.. (I) ••-•••
Ob) I..
.4 Z
•••■•1 • .4, t&apos;S ns
n n .... C.)
eN Ct) ...
.....
Cv ...... ;•-t
N :1:1
.i., -.4 as c
.---s u-... ce
C).) as x
a:s
,-.• n a) :-.
1,) es
.... e-.
.-... :_.
2-. CI)
.4--. a) - .--4
. - -
,...,
-4..• 4-4 1.)
0 — -__, tic)
.v.4 CI) &amp;quot;&amp;quot;&amp;quot;.
..a.) 0
fa&apos; -4..O
Ti CI)
•■•1
CZ &gt;
e•••, r...1
CZ 4-, •.= 0
:••4 aS a) 0
he ----44-)
-0 (-)
-- -4-.
ci) • —
• -, • — z C a4
‘•,•• ••■•,
li -4.4
S-.
&apos;-0 CO 41.54-4
CZ a.)
.- C)
4
.....-- 4-&gt;
-10
4-, 0
0 (1) C.) 1) C)
. Z.) Eri • .-.4
..--■ C) C....4
. 0.,
...., C.) • &apos;•&apos;:, a) 4_, • ..,
—
.40 s•-■ •:..)
Cr, -4..
</equation>
<bodyText confidence="0.6875855">
,-, 0 at. -C a)
,-. 0 4-,
</bodyText>
<figure confidence="0.828100101010101">
0 44) -., a) a)
4..., .e E 3. :,... fir
• — p.=
CC C) ....) T.-. :1) C.) a
C.) 4-0 CCS
0 C&apos;1 r_. Z 4-)
0 4-0
.-..-4 i..•
C) Z
....
C ...a 0.).
...0 &gt;4
C17 hp ....•
CA a)
E Cl) bp
...-1 1.)
r..)) 4-)
0.0
-.6-,
:-■ 1) ...-,
n
t....4
a.) a) -0 al
4..., .,.„ ..—
.- .,._.. cf) 0-4
0 ,-) r.
...
-4-&gt;
...4
iv -4•J e! CZ
a)
CC
E .,....,, ,n,
C6 0
-4-&gt;
7, a.) :11, .4
.-.
..... 1... .-4 0) --Ed,
Z
0 -4-&gt; • ..4
L) C.) U.) 0 a)
C4...1 CO) CZ X)
• In.4
0 S=24 fj)
CI) &lt;IC • .--t
appropriate
C) ())
..—
C
•
t.il■I
4...1,0 .......•
••
C-•••••
• •••N
5z
0
C.)u)
• . -0CCcn
cn.4 0 s..
C-) CL)
&apos;1&apos;0 E-1 E $:14
orientation specified in the picture model.
Cr&apos;d n C..)
cr)
-4-.)
tr, CO H be &gt;,
,•-• 4..., a CZ
•-•
,../ li
/1 ... • ••••• rs
v r-• e•-. g
,....,
awa■•■
..,
f/. r• • .-.4
...., ,r,, n
4,-.) -•.., CC 4.) a)
C) ca ct
0, -C
-0 a)
.--, r-... .-r, E
{-1 ..., ....
Vr; ....,
-.., C...) „:...,
••-•
•••0 .... a/
Cfi
...d ..-,
e. r_r tr, r.f) X n
... ...-...- Id
0
1.) n
.--. ....., . ,-.•
c.) ..... T. :...
.6-. -4-, n .4-.)
...,.., ..--, .....
v r-, &apos;....) CZ
-4. -...i =4-4
</figure>
<equation confidence="0.808867909090909">
..., c...., a) Z
,--• g) • --&gt; •
r. I&gt; I-, a) C7&apos;
.... -- ...-,
.... C &apos;&apos;&apos; a)
:-.) &amp;quot;-
...- t..) .....
.... .;_. ..... C.)
..-d
7., e-&apos; c3 /-••••
...J $4
-4--&gt; ,••• -4-0 ......
1.1 ...• C.) H
,-,
e. V 1.) f•-, $•li
l&amp;quot;. • ••&amp;quot;. C..)
4-, :.A. • .--, r. 6
,...z
c :-, :..)
a) ...., . — a.)
b.L •— l&apos;i CZ t-• l&apos;...3
r-,- .....4
V I., 0&apos;1
C) 0.) V .....I ...,&apos;• CD
4V •••••
.4 a) :-. .4
-4-, ..- 0 &apos;I)
4-, ,....... r, -4-)
1-4 ... 0 Z T.
CL) &gt; CZ CZ ..4
•--)
4-4 ri.) )-4
E
</equation>
<bodyText confidence="0.535042666666667">
...-
&lt; 5 ir.: be
-4-, 0 4-&gt;
</bodyText>
<figure confidence="0.966790350553505">
0c ... 0
....0 ov.I P•4 CI)
C) ••••-•4
.--4
.•-•4 CZ ..0
C.) j)) C.) CI
CD &gt;-&apos;4 0 4-)
;...., ..0 a) .4-,
as Sa. he MS
•••••.
-4-.
-.):
-. n •-•
— •....-4,....., .......,..--•
....) a, a,
e.
- — „.- .....
.--, ......
&apos;......E, •••• ,-,
..■- 1.: a..
... e-• tl:
e-,
4.-`, v n ---■
,-.., --. -7--.
13r, &amp;quot;...., CZ
:-. 14
&gt; 4-, 0
-. tr, --- ca 4-&gt;
- •-• es
....., T. ..--, g.
....., • e*
..-.
,---4 7...) e&amp;quot;.% C
■•••,
..... a) .
• n, 4•••+ .-P--.. C.)
1 /1 &apos;f+ 7:. C.)
E. ,
..... — .—
a.,
... -■ , - .,4 ...,.
&apos;,I .....-e 0
.■.-. ..J ..-4 ,-, .-C
e•-• ,-.0 ■1 •,../
....-,
,•••■ 4-. 1.) ...c
,..., c.4.... —4 .-7-.
,••■
...,
e-. &apos;.I. v &gt; ,
a.. .... .-,
t.,i) .!r,
77, a) 4-,
., • _ — 4.
.-.--, r•-• .-, ••
CZ - ....
v
...e •-r-e Z
CI .-.
-4.--1 v ...e
/ ] 4..., :.
....,
......
C.)
Li
•,•••4
s_.
sra
U)
•
..0
_0
-
C.)
■••••
1:17;
•
`da
0
expressions.
C.-
...., rTh ...d r--.
,. 1.--4 :.....&apos; I-.
I.-. r-■
•-•
lo•■•0 ,:l.&amp;quot; .2..; a,
- -4
,...• 4-, 1 ••-n .-.4 ;-..`
_.,...,., 4..., &apos;, r&apos;&apos; r-.
If: .. .- )
..... ...-. ,.......x
&amp;quot;7...., e-, ,.,r, ...... .... .....
....
.-.. -a-. .. , &amp;quot; a)
- 0 7..., b....., i•-•
/1 .-4,11
:••■
Li..1 1.• 5.:1E
f•-•
....,&apos; :-... e••■ ....&apos; 0 r•-•
:..) • .4 .....e •
Z., • .4 CZ
...-.4 /1 ••••
/.., /1 ..■••
.....• ..... 0 :•••
4-3 -r,
C) a.) 4.--,
rv.,
,..vg
.....
E
—
.4-..
st
•••-• 4-, ,-... e•
v
&gt;. 4-, ••••• C)
?a us ....
--a a) &gt;
/-4 ••••■1 a r•-• be, ..—
■17:, ••••4 .4
. •-■ C
. .,) 7,....„,4 CI )
a) ....4 ......, r&apos;&apos;&apos;
a) ,••••
V •-•-4
.....) W.
t•-• ••••■
f-.. V
l-s .....
..;-• ...-.,
VZ . ,..,, n...... •••••
••••• -19--•
C••••1 44■4 •••••
•••• ••••
..-.. ..-.
:... I. &gt;a
r. r-r-V ....•
.....I
C)
....
I... 1.) cu ...- =-&apos; a.) c3
V 0••• 4-.&gt; C.) • a..
• ..-. 4..i4 :•-■ .....i. •••44
.4., ...• • .4 pr,
4V fil CZ .,...
......, rs .....$) n, c..) Cs.?
v
.--, &amp;quot; a.. ,..„&apos;&apos;;-;
v
P ...„
to= C.)
e. ,..t e‘ 1■1 r-&apos;
...J `...,
• ,.. f&amp;quot;.•
Ci.)
PLI) ..,++ ....0
Cr. C.)
CI) tkE :2.-a . ....I
..&apos;&amp;quot;Z ••-■4 C)
Z 4-,
C /1 r..L.
/1, . ...I
r..) .4-, 1..4
....
4-1 •••••• be - ..-...
,--
-, rz) . - 00
ct
/•-•
..... ri •J: i-•••4
C.•••■
7...
n CZ: .z., -
t&amp;quot;.4.-4 ....., ....
. ..... n •••• C.) 4.-.
...-4
f.
•-•^S .....
Z
V
• .• ,...•
4..., -4.-I
&apos;-r. ,--, .
..-.■ 1.1
Z.) ten c.) .4 ___.
C) n n CZ ......
n
,--.1 e-&apos;
-.1-, 7:,&apos;
......., ..-c .....,
C
....,
co ..71.
C., n n
.--.. .....
C
:}.1 •••• :4.4 • •.--7,...„ -1■4
.....1 ao)
4.., •••••
v . L.
....,
4,-.,
co 1&amp;quot;-.. ...) r-..
..4
a.) . - _.,
- --
„..... • ,---, ,-, ad a., 4.-+
.4
&gt; ■ a) ona0 ■-•, • •••••Y
.4- •••■•4 ••••• 4-.. C-4 .,-.4,
f, C...;
v &apos;h.
1.-, v ..-.
n -r-•
....4 .....,...., -...
.1.)
4.-.
Z F-&apos;
r•-• r■-■
..., Co e.
.• CZ•Cr) CZ 1--4
..,.., ....-.
.... .1,-..
4-•
&gt;1 ...I CZ ,•-• ....) ,-*
:••••■ C.) •-• In
C.) ,...
. .-.. . .-.
0 ;:-. 4-, es
...) ...., .-,
•-. .
he
=4-4 e- r•-• .&apos;1..; CZ. a a)
..... ,.-.. .......
C)
CZ ...-.J
I1
.Y, • 0..
f:: r•
T., 4-■
•••••
41)
ra) ri; . •-•-■
C) ra,
...• 1.--4 . •vc ..-■ Z
•••.&apos; CD 7.....4
..... 0.) )&amp;quot;..4
&apos;1 i
4■1
• v.-4
e••••
se ••••••
...
.4 e-,
0 4.., t.e.
t14-■ C..)
6 ,,...
. bD 4••• ....= .....)
a) • ..-. r--4
!&amp;quot;) • ...... 4-, u; cx-t
• v-■ C.) 1.. 4-&apos;_.., CD C)
4m) e.
.6 •-•
4-) 4,-4 tilD
W Et tto
,-. „......
• .-4
C../ C71.)C:24
,-. • r&apos;l
4-4
</figure>
<equation confidence="0.94077">
. :... bp 4--.
IV &amp;quot;...V., 0 0 rd .&amp;quot;).
CI) •..., C1) •
0 0
s-• i:14 c.) cri g)
,... ..., a.) -,-
</equation>
<bodyText confidence="0.742925">
.... 0
</bodyText>
<figure confidence="0.965382125">
a) a) C.) ,- --
-0 Cl) 4...) Is r&amp;quot;.
V •-•-I
•••:.■ i. 4 e4
4-, ;.•• CZ • r•.I •-••■ ..•-• •-•1
•,..., Ct ....•
.■••1 Ce •-•• :...-a. ..
be
r•-• • ••• I&amp;quot;
C CI) e. :-.
C..) • ••-■
•.,
LT.4 :.... CI
4.4
0 .... P.4
..... 4-2 a.) .....4 .
•-4-■ b•O
r-•
E4 0
-....)
ce C
&apos;&amp;quot;Ct ..-..-
.--- 0 4-&gt; :II r--.
1.-.1
</figure>
<bodyText confidence="0.491772">
-- r. 4.. e•
</bodyText>
<equation confidence="0.934443387096773">
•,n :-. c..) ...
E =4.
0.) .71 0
cL)
C c3
RS cn .... s. 4-, .4
b.0 Cr) CZ; a) ,0 4-4 :.., 4...i
_C C te a)
C be :-. 0 s. ci....
c...) ,
— ._ c
a_. ce y-; 7.) -C3
tf.
CU i-4
7...)
C,) ce , -,
-4-, 0 C..) .-0 e&amp;quot;,
7.-. • .... ••••■,
C)4-
---./.,
;--&gt;. —
4-&gt;
....,o. bn as a) rn azs CZ
rv.1 r.
•E 4-&gt;
es ..r4,
C-
—
Cl)
- be, ,
;■I Cf)
.4 CC&apos; • ••••4 E
.... X C-) a) ;•-.
cl) f1
P.4 4--.. • 4-..,
cb a.) be
0)v.: si)
0.
a) ...c
0, -0
a)
2
.0
a)
0
c.)
-0
4_, (1E.
cb u...c .7) ......
4-, CO C.) 4-&gt;
s 0 0 7.--,
&apos;.4-4 • .... OA .0.1r-. a) a) —
.4 cr; .4 ,a1)
4-•
...,
U)-
C.) s-. -c::s g-, -.=)..., 7....
C
&gt;4 U) `It .-0 0 C.) 4-)
-C a)
s., ..y)
C) 0 ..0
&gt;, a)
C.) s-4 -.
C -LI
s.-. he
....0 .I.) acS - --
c.) :.) 0- .-- ,...,
0, s-. ce 4.) bz
C) 0 C4■0 C
...a 0-..) .....4
I.&amp;quot; a) a) ^0 ,-,
-, • .
_C
-0 E %ad -0
c,--.
0 4.0j, C--)ci; 4_,
. a)
C I- ,0
L..,
C C
Cl.)
as E a) o 4....
4 C.)
...) 0 bX :,...,
Qu E 7--.&amp;quot; x
..:.,_.
,r_. a)
... S ct a)
• 0 .--.
a) -4-., al a)
— . -
. - 0
</equation>
<figure confidence="0.982084292682927">
c.)
-0
0. .....4
0
&gt;-, 0 C....) a. ,...,
r-4
C1) Z I)
&gt;
••••-•I ,&amp;quot;-.
i•4 .•4•I • •-■
..., 4.) CZ 0
0 4-&gt;
P4) 4-0 0 C.) • .-4 &gt;
...)
• .-4 4-&gt;
0 •
.-0 -4-,
C) 4-&gt;
S.4
c•T4 • •-.4
Cl) 4-) Cl)
0)
0 0 0
fn ••-&apos;1 0 04 al
CL) (C C.) - •••••4
E...4 a) .4 •-ct
4-, • -4 ,4
-4-)
T-4 J..4
C.) 0
CZ Z
1••• C.) C 4■.) CKS at
bD &apos;CI CU
03 Cl) CD
.s..&amp;quot; X C
• .-•
&apos;10 (/) 4-) al 5-, 4-1
es.
The organization
10
2. Review of Previous Work
</figure>
<bodyText confidence="0.576007">
This review of previous work. is grouped into three sections: programs which
solve problems stated in natural language, natural languap processing, and theoretical
work.
</bodyText>
<subsectionHeader confidence="0.847014">
2.1 Natural Language Problem Solvers
</subsectionHeader>
<subsubsectionHeader confidence="0.934451">
2.1.1 Bobrow&apos;s STUDENT
</subsubsectionHeader>
<bodyText confidence="0.986781714285714">
The first natural language problem-solving program was the STUDENT
system of Bobrow [Bobrow 68] for solving algebra story problems. The natural
language processing of this program is based on pattern matching around key words
and phrases. The phrases around the key words become the &amp;quot;variables&amp;quot; in the
equations which are constructed from the sentences. Thus, in one of Bobrow&apos;s
examples,
If the number of customers Tom gets is twice the square of 20 percent of
the number of advertisements he runs, and the number of advertisements
he runs is 45, what is the number of customers Tom gets?
the two phrases &amp;quot;the number of customers Tom gets&amp;quot; and &amp;quot;the number of
advertisements he runs&amp;quot; are treated as variables. This problem is thus treated as if it
were stated
If x is twice the square of 20 percent of y, and y is 45, what is x?
The pattern-matching rules break the input sentences into a possibly embedded set of
&amp;quot;kernel sentences&amp;quot;, in an order determined by priority values assigned to the keywords.
In the above example, since &amp;quot;percent&amp;quot; has the highest priority, it would be processed
first. There is a fairly direct transformation from English sentences into equations: in
fact, the transformations are made upon the input sentences themselves until the
sentences become the equations used in solving the problem. Large segments of the
original sentences remain as &amp;quot;variables&amp;quot; in the equations.
When the equations constructed from the input are insufficient to find a
solution, other equations can be retrieved (based on words in common with &amp;quot;variable&amp;quot;
phrases) expressing general relationships, such as
(EQUAL (DISTANCE) (TIMES (SPEED) (TIME))).
Bobrow&apos;s program was impressive for its time (about 1965). However, this
type of approach has definite limitations. The technique of transforming sentences
directly into equations works only when the sentences express algebraic relationships
among quantities. The &amp;quot;variable&amp;quot; phrases must be similar in each occurrence so they
</bodyText>
<equation confidence="0.437348">
[1
</equation>
<bodyText confidence="0.999631">
can be matched properly, and the key words must, not be used in multiple ways which
might confuse the pattern matcher. These limitations make it difficult to extend the
techniques Bobrow used to more-complex problem areas.
</bodyText>
<subsubsectionHeader confidence="0.928554">
2.1.2 Charniak&apos;s CARPS
</subsubsectionHeader>
<bodyText confidence="0.998315076923077">
Charniak&apos;s CARPS program [Charniak 68] is a program for solving calculus
rate problems. In many ways, it is an extension of Bobrow&apos;s STUDENT program. The
analysis of the English input sentences is done by pattern matching which is slightly
more sophisticated than that of STUDENT. The type of rate problem (distance or
volume) is determined by the occurrence of certain key words in the problem statement.
Two sets of patterns are used to analyze the sentences appearing in the two types of
problems. Many of the patterns used are very ad hoc.
The CARPS program builds a structure (generally a single tree) containing
the information derived from the problem statement. This structure is used to generate
the equations required to solve the problem. Additional equations may be derived from
&amp;quot;world knowledge&amp;quot;, but this is again very ad hoc. Thus, while the problems solved by
CARPS appear very impressive, the program is tailored so closely to this specific set of
problems that it would be difficult to extend it to additional problems or problem areas.
</bodyText>
<subsubsectionHeader confidence="0.778402">
2.1.3 Gelb&apos;s HAPPINESS
</subsubsectionHeader>
<bodyText confidence="0.999907181818182">
HAPPINESS [Gelb 711 is a program which solves basic probability problems
stated in English. This program seems much like Charniak&apos;s: it builds a single tree
structure representing a single problem, and selects a solution method based on the
occurrence of keywords in the problem statement. The input sentences are broken into
simple clauses and phrases by pattern matching. These simple clauses are then
analyzed by a context-free grammar to extract the canonical verb and its voice, subject.
and predicate. If certain key words (e.g., those referring to dice and coins) are found, a
special search for possible modifiers of these words is made.
This program, like Charniak&apos;s, is tailored very closely to a small set of
specific problem types. It would be difficult to extend a program using these techniques
to handle a new problem area.
</bodyText>
<subsubsectionHeader confidence="0.770717">
2.1.4 Heidorn&apos;s Simulation Programming System.
</subsubsectionHeader>
<bodyText confidence="0.9999326">
The NLPQ system of Heidorn [Heidorn 72] aolcepts an English statement of a
queueing simulation problem, and produces from it a program in the GPSS simulation
language which will simulate the problem. The system is interactive: it requests
additional information from the user when the problem statement is incomplete, allows
the user to ask questions about the simulation model, and can generate a complete
</bodyText>
<page confidence="0.491651">
12
</page>
<bodyText confidence="0.988950083333333">
problem description in English from its internal model.
English sentences are parsed and generated from two interpreted phrase
structure grammars augmented by some semantic programs. These grammars go down
to the character level, and handle English morphology as well as phrase structure. The
grammar is based in part on the theory of stratificational linguistics. The basic unit of
storage in the internal model is the &amp;quot;record&amp;quot;, which is &apos;computationally equivalent to a
LISP atom with its property list.
This program represents an advance over those considered previously in this
section. It uses a legitimate grammar to parse the input/ sentences, and can construct a
model which expresses relationships among a number of objects. The grammar is
specialized for simulation problems, and would have to be modified to extend the
program to other areas. However, the performance of this system is quite impressive.
</bodyText>
<subsectionHeader confidence="0.719653">
2.2 Natural Language Processing
</subsectionHeader>
<subsubsectionHeader confidence="0.616063">
2.2.1 Woods&apos; Augmented Transition Networks
</subsubsectionHeader>
<bodyText confidence="0.9765473125">
The Augmented Transition Network (ATN) of Woods [Woods 701 is a
powerful formalism for representing grammars. The grammar of ISAAC, while written
in &amp;quot;pure&amp;quot; LISP, is equivalent to an ATN grammar. A transition network consists of a
set of nodes (representing states) and a set of directed arcs between the nodes which
specify transitions between states based upon the input string being scanned. An ATN is
augmented in several respects. The test associated with a state transition may be
arbitrarily complex, depending on the previously parsed structure as well as the input.
The test may be the name of another transition network, in which case control is given
to that network at a lower level, effecting a &amp;quot;subroutine call&amp;quot; to the subordinate
network. These calls may be recursive. Transition arcs may also be augmented by
arbitrarily complex structure-building actions: The structures so built are passed
among network levels in designated registers. If an attempted parsing of a subnet fails,
the ATN interpreter automatically handles backup from the failure point and tries
another possible transition. The automatic backup and clearly defined interface (via
named registers) between network levels make the ATN a very &amp;quot;clean&amp;quot; formalism for
writing grammars.
</bodyText>
<subsubsectionHeader confidence="0.965506">
2.2.2 Winograd&apos;s SHRDLU
</subsubsectionHeader>
<bodyText confidence="0.99976475">
Winograd&apos;s widely known SHRDLU program [Winograd 72] allows a person
to converse with a simulated robot about a &amp;quot;micro-world&amp;quot; consisting of various colored
blocks on a table. The robot may be asked to perform actions such as moving blocks or
building structures and to answer questions about the state of the micro-world or about
</bodyText>
<equation confidence="0.738242">
I :3
</equation>
<bodyText confidence="0.999955">
its motivations for performing particular actions. The system employs a large grammar,
based on Halliday&apos;s theory of Systemic Grammar. Much of the knowledge in the system
is represented in the form of MICRO-PLANNER theorems. This makes it easy for
programs to be generated to find the answers to questions about the world model, and
allows a number of logical forms such as conjunction, disjunction, and quantification to
be handled naturally. The theorem prover base is a source of considerable power for
certain types of semantic operations. The semantics is made much easier by the small,
finite world of very simple objects (colored blocks). Still, the SHRDLU system remains
one of the largest and most powerful natural language systems produced to date, and its
fame is well deserved.
</bodyText>
<subsubsectionHeader confidence="0.930627">
2.2.3 Wilks&apos; Preferential Semantics
</subsubsectionHeader>
<bodyText confidence="0.986209228571428">
The work of Wilks [Wilks 75] is unique among &amp;quot;artificial intelligtnce&amp;quot;
approaches to natural language processing in that Wilks is interested primarily in
machine translation, rather than in deep understanding of natural language by
computer. However, there is an interesting parallel between the semantic templates
used by Wilks and some of the semantic processing done in ISAAC, which is of course
concerned with deep understanding.
In Wilks&apos; system, a sense meaning of an English word is represented by a
formula, which is a list of element names. The elements are approximately 70 semantic
classes which roughly classify the entities, qualities, actions, etc. which occur in English
sentences. Examples of such elements are MAN (human being), STUFF (substances),
KIND (qualities), and CAUSE (cause to happen). These elements may be combined into
a formula to represent a word meaning, as in (FLOW STUFF) for the word &amp;quot;liquid&amp;quot;. A
sentence is analyzed by trying to fit a template (whicIfis a list of element types) to some
of the possible sense meanings of the words occurring in the sentence. The templates are
intended to represent the basic types of &amp;quot;messages&amp;quot; that people wish to convey in
language. For example, the templat6 MAN BE KIND would represent the class of
messages in which the sentence &amp;quot;My sister is pretty&amp;quot; is included.
After (possibly several) templates have been fitted 3 a piece of text,
&amp;quot;preference&amp;quot; of parts of each template are examined to s.K if they are satisfied. A verb,
for example, may prefer an animate subject. The template for which the greatest
number of preferences are fulfilled will be chosen as the intended meaning; however,
possible fillers for the template slots will be accepted even though they do not meet the
preferences, provided that the template as a whole is the best match.
There is considerably more detail to Wilks&apos; system which will not be covered
here. We mention Wilks because there seem to be parallels between some of his
techniques and techniques used in ISAAC. One such parallel is the use of rough
14
gemantic classes to distinguish between sense meanings of words, which we found to be
particularly useful for determining preposition meanings. Others have certainly used
rough semantic classes to distinguish sense meanings in special applications; Wilks&apos;
work is valuable for investigating this technique over a large subset of&apos;English.
A second parallel lies in the acceptance of a word (or larger unit) which fails
to meet the preferences of the template which covers it. In the ISAAC system, this
acceptance is an active process in which an acceptable interpretation must be
constructed from the given unit. These processes are discussed in more detail later.
</bodyText>
<subsubsectionHeader confidence="0.921867">
2.2.4 Simmons&apos; Semantic Networks
</subsubsectionHeader>
<bodyText confidence="0.99819675">
The Semantic Network, formalism of Simmons [Simmons 73; Simmons and
Bruce 711 provides a powerful and convenient method for representing the elements of a
sentence and the semantic relations. (derived from a variety of syntactic forms) which
hold between them. In effect, it prodtices an orde.t lag of the arguments of, a semantic
grouping (such as a verb and its case arga ments, modality, and optional modifiers)
which is invariant over the various syntactic orderings which express the same
relationships. Thus.
John &apos;gave Mary the book.
John gave the book to Mary.
The book was given to Mary by John.
would all generate the same semantic network structure. The semantic network
formalism has been used for language generation [Simmons and Slocum 721 as well as
parsing, [Simmons and Bennett-Novak 75] shows how these structures may be used to
produce a mall natural language understanding system with a minimum of effort.
The structures used by ISAAC in understanding sentences are ,a natural
extension of Semantic Networks as used by Simmons. In order to handle multiple
sentence discourse, links are made from tokens in individual sentences to the referents
of the tokens in the problem model which is being constructed. Semantic interpretations
are placed on some tokens as their meanings are determined Particular semantic
interpretations may be specified based on information from many different sources.
Making an interpretation of a token may cause links to be made from that token to
objects not mentioned in the sentence and may generate additional inferences about the
relationships of the objects involved. These processes are discussed in detail in later
chapters.
</bodyText>
<subsubsectionHeader confidence="0.901211">
2.2.5 Schank&apos;s Conceptual Dependency
</subsubsectionHeader>
<bodyText confidence="0.986362785714286">
The Conceptual Dependency system of Roger Schank [Schank 73, 51 is a
theory (embodied in a series of computer programs) which postulates that the concepts
transmitted in natural language can be represented as complex structures based on a
small number of primitive actions. The primitive actims are linked by named links to
their case arguments (some of which are other primitive action groups) and to other
groups to which they are related, e.g.; causally. Some case arguments are mandatory, so
that ih &amp;quot;John hit Mary&amp;quot; we must infer an instrument M this case John&apos;s hand) used in
performing the action.
While the structures and actions used by Schank are not very useful for
physics problems, some of the concepts he uses (such as inferring a required
semantic object when it is unspecified) are basic to almost any language understander.
Schank&apos;s work is also important because he has defined a set of primitive concepts and
actions which can be used to express a fairly wide range (though certainly not all) of
natural language sentences..
</bodyText>
<subsectionHeader confidence="0.998924">
2.3 Minsky&apos;s Frame System Theory
</subsectionHeader>
<bodyText confidence="0.997825346153846">
Minsky&apos;s frame system theory [Minsky 741 proposes that knowledge is
organized (in humans and, potentially, in computers) in terms of interconnected
elements called Frames.
A frame is a data-structure for representing a stereotyped situation, like
being in a certain kind of living room, or going to a child&apos;s birthday party.
Attached to each frame are several kinds of information. Some of this
information is about how to use the&apos; frame. Some is about what one can
expect to happen next. Some is about what to do if these expectations are
not confirmed.
A frame may have &amp;quot;slots&amp;quot; which can be filled by the particular &amp;quot;arguments&amp;quot; involved
in an instantiation of the frame. There may be procedures associated with a frame to
determine the suitability of proposed arguments and to infer values for those which are
unspecified.
Minsky also makes some general comments about how frames may be used
in computational linguistics.
... in understanding a discourse, the synthesis of a verb-structure with its
case-assignments may be a necessary but transient phase. As sentences
are understood, the resulting substructures must be transferred to a
gro-wing &amp;quot;scene-frame&amp;quot; to build up the larger picture.
Minsky&apos;s frame system theory has been immensely popular—so popular that
many people are claiming that-frames are exactly what they llave been doing all along.
There are many similarities between the processes and data structures used by ISAAC
and the frame systems described by Minsky, and the term &amp;quot;rrame&amp;quot; will be used in
describing some of them. The interpretations given will of course be those of the author.
The idea of frames is a powerful one, but the mechanics or their implementation
remains a problem for research.
</bodyText>
<page confidence="0.578951">
15
</page>
<sectionHeader confidence="0.747203" genericHeader="method">
3. Parsing
</sectionHeader>
<subsectionHeader confidence="0.709465">
3.1 Introduction
</subsectionHeader>
<bodyText confidence="0.995833909090909">
Parsing, as used in this chapter, means the process of assigning a structure to
the linear string of words comprising a sentence so that the syntactic relationships
among the words and phrases in the sentence are made explicit. The processes of
relating the structures in the sentence to parts of the developing model of the problem
and of determining the meaning of the structures will be treated in the chapter on
Semantics. Obviously, there is no clear division between what is syntax and what is
semantics; many constructions could be claimed to be either. In the sentence processing
done by ISAAC, syntactic and semantic processing are frequently intermixed. We shall
describe the two parts separately to make them easier to understand, while trying to
indicate the points at which they interact. How to best organize thd interactions of
syntactic and semantic processes in a language understanding program remains an
unsolved problem.
Although the parsing programs in ISAAC are written in &amp;quot;pure&amp;quot; LISP, their
structure is strongly influenced by the Augmented Transition Network (ATN)
formalism of Woods [Woods TOL An ATN grammar allows sub-grammars for phrases
to be called (recursively) as subroutines by other grammars. A grammar program may
build structures which are passed back to the program which calls it. In case an
attempted subgrammar fails, the grammar interpreter automatically backs up from the
failure point and tries the next possible alternative which is specified. These features of
ATN grammars are also present in the parsing programs of ISAAC. The grammar
programs are organized as a set of parsing functions, most of which parse a single
functional unit, such as a noun phrase. This organization in terms of functional units
seems natural because it allows the grammar functions to communicate with each other
by passing pointers to complete, well-defined functional structures. A noun phrase, for
example, causes the production of a noun phrase token structure which has a standard
form, independent of the function of the .noun phrase in the sentence. Grammar
functions which parse larger syntactic units, such as a clause, connect the smaller
structures, such as noun phrase and verb phrase tokens, by means of named links which
specify the relationships of the phrases in the sentence.
The structures which are produced by the parsing programs bear a strong
resemblance, to the semantic networks of Simmons [Simmons 73]. The grammar
functions which parse the major phrases, such as noun phrases and verb phrases,
produce/&amp;quot;token&amp;quot; structures which represent the information in the phrase in a standard
</bodyText>
<page confidence="0.740438">
16
17
</page>
<bodyText confidence="0.998697642857143">
and readily accessible form. Other grammar functions, such as those which parse
prepositional phrases and other modifiers, may make changes and add information to
the modified token structures rather than creating new structures themselves. The links
between token structures may specify semantic relationships (for example, that one
noun phrase names—a location on the object referred to by another noun phrase) as well
as syntactic relationships. In some cases (e.g., with prepositional phrase modifiers), the
semantics may be done at once, so that semantic links among the tokens are not needed.
As semantic processing proceeds, the token network structure is elaborated by adding
semantic interpretations to some tokens and. by creating links between some tokens and
the objects to which they refer in the program&apos;s model of the world. These semantic
processes may render a token unnecessary and leave it unlinked to the rest of the
structure. After all the semantic processing has been done, the information in the
sentence has been transferred to the world model, and the network of tokeas is no
longer needed.
</bodyText>
<subsectionHeader confidence="0.983411">
3.2 Control Structure of the Parser
</subsectionHeader>
<bodyText confidence="0.997779772727273">
The parsing programs are written as LISP functions, without using an
additional interpreter as a Woods system does. Automatic backup and control of the
scanner which points to the current position in the sentence being parsed are
accomplished by a set of small functions which are called from within the individual
parsing programs. These functions set the system registers (global variables)
appropriately for the current state of the parser.
A sentence is represented internally as an ordered list of words. As the
sentence is scanned from left to right, the global variable SENT is set to point to the
current position in the sentence. The current word (or multi-word unit) being scanned is
put into the * register. Thus, a grammar program could test whether the word currently
under the scanner is &amp;quot;and&amp;quot; by using the LISP code (EQ * &amp;quot;AND), where the quotation
marks are an abbreviation for the function QUOTE. The parsing of a sentence is
initiated by setting SENT to the sentence and calling the function SET* to set the *
register. When a grammar program wishes to move the scanner one position to the right,
it does so by calling the function ( =&gt; ). The next word to the right and the second word
to the right may be gotten by using the functions (NEXT) and (NEXT2), respectively,
without affecting the position of the scanner. The function CAT (category) is frequently
used to test whether the word currently under the scanner is in a particular category, as
defined in the lexicon. Thus, (CAT &amp;quot;ADJ) may be used to test whether the current word
is an adjective.
Since the parser operates from left to right, it sometimes happens that a
grammar program fails to)find the type of phrase it expects, after it has moved the
</bodyText>
<page confidence="0.635472">
18
</page>
<bodyText confidence="0.992919608695652">
scanner from its initial position. For example, in parsing the sentence &amp;quot;To err is
human&amp;quot;, the parser might first atteMpt to parse a prepositional phrase. The preposition
would be found, and the noun phrase parser would be called after moving the scanner.
The noun phrase parser would find the verb &amp;quot;err&amp;quot;, and so, it and the prepositional
phrase parser would fail. In order to handle such cases, it is necessary to be able to save
the current position in the sentence so that the parser can back up and try something
else when an attempted parsing fails. This is accomplished by calling three small
functions, SAVE, SUCCESS, and FAIL, within each parsing function. Normally, a
parsing functiun will execute (SAVE) as its first,action and execute either (FAIL) or
(SUCCESS), as appropriate, immediately before it exits. SAVE saves the pointers to the
current point in the sentence on a push-down stack. In addition, it saves the current
point in the list of generated atoms, so that any atoms generated by a function N% hich
later fails can be deleted. SUCCESS removes one set of pointers from the stack: since
the attempted parsing was successful, these pointers are no longer needed. FAIL
restores the pointers to the sentence to their original position, and calls SET to restore
the * register. In addition, it releases any atoms which may have been generated by the
function which failed.
In order to illustrate how the parsing functions are actually written, a simple
function to parse a noun phrase (using the same conventions as the parsing programs of
ISAAC) is shown below. This program parses a simple noun phra§e consisting of an
optional determiner, zero or more adjectives, and a noun. The program succeeds and
returns True if it finds such a phrase: otherwise, it restores the pointers using FAIL and
returns NIL. No structures are built by this program, but it is easy to see how structure-
</bodyText>
<figure confidence="0.873441444444445">
building code C&apos;ould be added.
(NP (LAMBDA ( ) (PROG (
(SAVE)
(COND ((CAT &amp;quot;DET) ( =&gt; )))
A (COND ((CAT &amp;quot;ADJ) ( =&gt; ) (GO A))
((CAT &amp;quot;NOUN) ( =&gt;) (RETURN
(SUCCESS)))
(T (RETURN (FAIL))))
)))
</figure>
<bodyText confidence="0.845183">
This prtgram accepts a noun phrase equivalent to that accepted by the
following grammar:
&lt; &lt; det&gt; &lt; npl&gt;
&lt; nir&gt; &lt; np I&gt;
</bodyText>
<equation confidence="0.822957">
&lt; npl&gt; &lt; adj&gt; &lt; npl&gt;
&lt; npl&gt; &lt; noun&gt;
19
Using the Woods ATN formalism, such a program could be written as follow&apos;
(NP/ (CAT DET T (TO NP1))
(TST T T (JUMP )))
(NP1 (CAT,ADJ T (TO ))
(CAT NOUN T (TO NP2)))
(NP2 (POP T T))
</equation>
<bodyText confidence="0.998849736842105">
Our method of writing parsing-functions requires the, writing of slightly more
code than is required for a Woods interpreter system, but it avoids the overhead of
interpretive execution.
The function SET*, which sets the value of the * register, checks for
multiple-word units, and replaces them with single words in the * register. &amp;quot;As much
as&apos;&apos;, &amp;quot;center of gravity&amp;quot;, &amp;quot;cross section&amp;quot;, &amp;quot;point of application&amp;quot;, and &amp;quot;so that&amp;quot; are
recognized as multiple-word units. These groupings could have been handled by other
methods, but replacing them by a single &amp;quot;constructed&amp;quot; word is a convenient way to do
it. A large parsing system would need to be able to back up in case the multiple-word
interpretation was incorrect; in our limited field of physics problems no such
ambiguities occurred. Becker [Becker 75] has argued that such groupings play a major
role in langtage.
Values are passed between levels of the grammar using the normal LISP
conventions of function arguments and returned values. A returned value of NIL
always indicates failure of a grammar program. A grammar program which succeeds
may return a generated token atom (as in the case of a Noun Phrase), or it may attach
its results to existing atoms and simply return True (as in the case of a Prepositional
Phrase). Some grammar functions have no arguments, but others (such as the Verb
Phrase) have quite a few.
</bodyText>
<subsectionHeader confidence="0.985801">
3.3 Data Structures Produced During Parsing
</subsectionHeader>
<bodyText confidence="0.985907666666667">
As a sentence is parsed, the grammar programs create a set of intertinked
nodes representing the major phrases (primarily Noun Phrases and Verb Phrases) of a
sentence. These networks initially bear a strong resemblance to the Semantic Networks
of Simmons [Simmons 731. As semantic processing of the sentence progresses, modifiers
of the nodes are removed or changed in form, semantic interpretations are added, and
links are made from the nodes to objects and relations in the developing model of the
problem. Finally, after execution of the verb semantics, the network is discarded.
Each node in the parse network is a GENSYM atom whose name is TOK
followed by a number. Features of the node (also called a &amp;quot;token atom&amp;quot; or &amp;quot;token&amp;quot;) are
stored on its property list. The &amp;quot;main&amp;quot; word of the phrase (usually, but not always, a
word from the sentence) is stored under the indicator TOK. The type of phrase is stored
under the indicator LFRAME (Linguistic Frame); the pos,sible types of LFRAMEs are
NP (Noun Phrase), VP (Verb Phrase), QNP (Question Noun Phrase), and RELNP
(Relative Noun Phrase). The noun phrase &amp;quot;each end&amp;quot; in P3 , for example, wonld
generate the following token:
</bodyText>
<equation confidence="0.650242714285714">
T0K89 TOK END
LFRAME NP
NBR (NS)
MODS ((QNTFR EACH))
SFRAME LOCPART
SEMOBJ (SCAFFOLD85)
RFNT (L0C91 LOON)
</equation>
<bodyText confidence="0.949871">
The first four items on the property list of the token, are created by the
parsing program. NBR,is the Number (Noun Singular Land MODS is a list of modifiers,
in this case the quantifier EACH. The remaining property list items are added during
semantic processing: SFRAME (Semantic Frame) is LOCation PART; AEN10L3,1
(Semantic Object) is a link to the object in the problem model which the location refers
to, in this case the scaffold SCAFFOLD85-. RFNT (Referent) is a list of pointers to the
items in the problemmodel to which the phrase refers: the locations LOC91 and LOC90.
When the semantic function for the verb is executed, it will deftl directly with the
Referents of the phrase, independent of the syntactic construction in the original
sentence which caused those referents to be selected.
:3.4 Noun Phrase Parsing
In this section we will examine in some detail the parsing of the noun phrase
and its modifiers.
</bodyText>
<subsubsectionHeader confidence="0.492465">
3.4.1 Basic Noun Phrase
</subsubsectionHeader>
<bodyText confidence="0.927244363636364">
A flowchart of the&apos; NP parsing program is shown in Figure 3.1. A flo‘crchart is
used to describe the program because a transition net of this size would be unwieldy,
and because a flowchart can more closely follow the actual program structure. A few
nonstandard conventions are used in the parser flowcharts in this chapter. A test
consisting of a word in capital letters indicates a test of whether the word currently
under the scanner (the word in the register) is in, that category. (NEXT) indicates the
next word to the right, and (NEXT2) indicates the second word to the right. The symbol
=&gt; appearing next to a line indicates that the scanner is moved to the right along that
control path. The symbol -4-- indicates that the right part is appended to the left:
* References to the example problems are denoted by the letter P followed
by the problem number.
</bodyText>
<figure confidence="0.998966216216217">
20
PRON * Pronoun
DET . Determiner
Yes
DET icAr
DETN
MEASU .IHeasurement Unit
Yes Yes
NOUN or
MEASU./
NULLADJ /
PROPN - Proper Noun
GEONAME . Geometric Name
a•
Yes
Mo
Yes
NEASt
Yes &amp;quot;10 Et&amp;quot;
10 ft from&amp;quot;
(NEXT) .
ADJ or NOUN &apos;
&amp;quot;10 rt:&apos;
Yes &amp;quot;10 ft pole&amp;quot;
MODS 44-
(&apos;HM tY *)
QTY - NIL •
Yes
R - (PRONMKTCH
(GET *
&amp;quot;ROOTPRON))
MODS A+. (&amp;quot;POSSBY Ti)
OSSPRON
MODS 404.&amp;quot;(*)
&amp;quot;two ropes&amp;quot;
(NEXT) .
RELPREP 1
</figure>
<figureCaption confidence="0.939336">
Figure 3.1 (3 pages): Noun Phrase Parsing Program
</figureCaption>
<figure confidence="0.997304555555556">
SUCCESS
m W.4 lugt tound
NBR - (qET * &amp;quot;NBR)
WD t(.ET * &amp;quot;NSFORM)
TOK • (MAKFNF WU)
Execute semantics for each
modifier on MODS
If a semantic routine is
unavailable or fails the
modifier is Put on TOK
Put DET, QTY, NBR on TOK
&amp;quot;at end (A)&amp;quot;
MODS &amp;quot;4-
(&amp;quot;NAME (COPY *))
Proper Noun
&amp;quot;At (B) the other end
TOK • (NPAPP NAME)
Put NAME on TOK
</figure>
<figureCaption confidence="0.88995">
Figure 3.1 (page 2)
</figureCaption>
<figure confidence="0.9985963">
•) )
Pronoun
SUCCESS
TOK = (MAKETO( (CET R &amp;quot;TOK) &amp;quot;NP)
IDRFNT
Identify referent of TOK
R - (PRONMATCH *)-
MODS 4-1-
&amp;quot;(QNTER EACH)
Yes
</figure>
<figureCaption confidence="0.980865">
Figure 3.1 (page 3)
</figureCaption>
<equation confidence="0.31623">
-4
generally, A 4+. B is implemented as
(SETQ A (NCONC A (LIST B))).
</equation>
<bodyText confidence="0.989254578947368">
Phrases in quotes next to control paths are examples of phrases which would follow the
indicated paths.
The initial tests in the flow diagram test for proper nouns, geometric names,
and pronouns, which are handled separately. [Geometric names, as in &amp;quot;AT END (A)&amp;quot;,
are represented in LISP as lists containing the names; in the original sources from
which the problems were taken, such names were written as italic capitals.] The
determiner, if present, is saved. A series of tests separates the use of a measurement
(e.g., &amp;quot;10 ft&amp;quot; ) as a noun phrase by itself or as a modifier (&amp;quot;a 10 ft pole&amp;quot; ), while
prohibiting it if it precedes a relative preposition (as in &amp;quot;10 ft from . .&amp;quot; ) since this form
is more easily handled as part of the prepositional phrase. Adjectives which are marked
NULLADJ are ignored. Thus, &amp;quot;a tapering wooden telegraph pole&amp;quot; (P11) is treated the
same as &amp;quot;a pole&amp;quot;. This is one of the few cases in the parser where information from the
problem statement is ignored. Possessive pronouns are rewritten at once; the referent of
the corresponding root pronoun is found, and a modifier of the form (POSSBY referent)
is constructed. This modifier retains the ambiguity of the type of possession. Not
surprisingly, there is considerable similarity between the semantics of POSSBY and
some of the sense meanings of OF. Thus, for example, &amp;quot;its end&amp;quot; and &amp;quot;the end of the
lever&amp;quot; will be reduced to an identical form when processed semantically.
When the noun is found, a token atom is created for the noun phrase, usually
using the singular form of the noun as the token name. In some cases, however, an
expanded definition is used, resulting in the use of a different token name and the
generation of additional modifiers. Thus, PAUL becomes PERSON, (SEX MALE),
(NAME PAUL) and BOY becomes PERSON, (SEX MALE), (AGE YOUNG). This
expansion eases the identification of the same object when it is referred to by different
words; the identification of these two tokens will result in the inference that Paul is
young. The modeling of words as carriers of modifiers to be applied to their root
concepts is an interesting area of research; [Simmons and Amsler 75] are investigating
this type of modeling for verbs of &apos;motion and communication.
After the noun token is made, an attempt is made to execute the semantics of
each of the modifiers which have been found. Some modifiers will make changes directly
to the NP token; others will create new modifiers which are saved for later processing.
&amp;quot;Both&amp;quot;rfor example, will create modifiers equivalent to &amp;quot;Each of the two . . .&amp;quot;.
The pronoun matching algorithm which is used is very simple. A pronoun
which was previously used is matched to the same referent as before. Otherwise, the
last-mentioned candidate which matches the pronoun in number and is appropriately
human or inanimate is chosen. This technique is fairly crude, but it worked for this class
of problems. In general, finding pronoun referents can be very difficult. [Charniak 72]
considers this problem in some detail.
</bodyText>
<subsubsectionHeader confidence="0.864575">
3.4.2 Noun Phrase Compounds and Modifiers
</subsubsectionHeader>
<bodyText confidence="0.9618584">
Conjunctions and modifying phrases introduce many potential ambiguities
into the parsing of a sentence. In a noun phrase containing two prepositional phrases,
for erample, the second prepositional phrase (PP) might modify either the top-level
noun phrase or the noun phrase in the first PP. A conjunction between two noun
phrases might join them into a compound noun phrase, or it might connect two toprlevel
clauses containing the noun phrases. Although syntactic constraintS may select the
correct interpretation in some cases, in many other cases the choice carale made only on
semantic grounds. For example, in
Lowering the level of the lake allows city officials to kill weeds and
residents to repair their docks.
we must use semantic interpretations to reject the possibility that &amp;quot;weeds and
residents&amp;quot; is a compound noun phrase. People seem to make these choices easily and
correctly the first time they read or hear a sentence; only rarely do they have to back up
and re-parse a sentence in order to interpret it correctly. The parsing programs of
ISAAC rely heavily orhsemantic tests to reject incorrect combinations of phrases.
A noun phrase may be modified by a prepositional phrase„ an adjective
phrase, or a dependent clause. In each case, the parser for the modifying phrase is called
with the NP token as an argument. The modifying phrase parser may reject the
combination on semantic grounds even though the appropriate syntactic constituent is
found. This is especially important in the case of prepositional phrases. Compound
modifiers, as in &amp;quot;a uniform scaffold 12 ft long and weighing 100 lb&amp;quot; (P5), are permitted.
Conjoined noun phrases are required to all be members of the same semantic
class, which may be one of the set PERSON, PHYSOB (physical object), LOCNAME
(location name), ATTRNAME (attribute name), or MEASU (measurement unit).
Pronouns are prohibited as members of compound noun phrases. These tests handled
almost all cases which occurred in the set of test problems. One pathological sentence
required additional treatment:
If it is placed on the edge of a block 1.5 m from the light end and a weight
of 750 nt added to the light end, it will be balanced. (P14)
Since the auxiliary &amp;quot;is&amp;quot; is omitted in the second clause, &amp;quot;added . . .&amp;quot; could be
considered a dependent clause modifying &amp;quot;weight&amp;quot;, and &amp;quot;block&amp;quot; and &amp;quot;weight&amp;quot; could be
combined as a compound noun phrase under the above rules. This problem was solved
by a semantic test associated with the preposition &amp;quot;of&amp;quot; which prohibits a compound
object noun phrase for such cases. This is not a very pleasing solution. People probably
;Pi
accept &amp;quot;edge of a block&amp;quot; as a well-formed unit before reaching the second clause, and
thus do not consider combining &amp;quot;block&amp;quot; and &amp;quot;weight&amp;quot;. The depth-first operation of this
parser allows it to go fairly far afield in such cases; additional semantic tests to allow
some constituents to be combined earlier would be a desirable, but difficult,
improvement.
</bodyText>
<subsectionHeader confidence="0.522671">
3.4.3 Noun Phrase Variants
</subsectionHeader>
<bodyText confidence="0.999509">
There are three &apos;small parsing programs which accept variants of noun
phrases. THERENP accepts &amp;quot;there&amp;quot; as a noun phrase in cases such as &amp;quot;there is
QNP accepts a noun phrase beginning with a question word, as in &amp;quot;what force . . It
RELNP parses a &amp;quot;relative noun phrase&amp;quot; containing &amp;quot;as much as&amp;quot;, as in &amp;quot;the man
supports twice as much as the boy&amp;quot; (P7). The multiplication factor is saved, and a link
is made to the noun phrase involved in the comparison.
</bodyText>
<subsectionHeader confidence="0.5635">
3.5 Verb Phrase Parsing
3.5.1 Basic Verb Group
</subsectionHeader>
<bodyText confidence="0.974818952380952">
The verb group, which is parsed by the program VG, consists of a set of
auxiliary verbs, a main verb, and optional adverbs. The flowchart of VG is shown in
Figure 3.2. Since tense and modality are not needed for our type of physics problems, the
auxiliary verbs are ignored except for determining whether the verb group is active or
passive. Other authors (for example, [Winograd 72]) have given procedures for
determining verb tense from, the- auxiliary verbs.
The program VG has six arguments. NPHD is a noun phrase token which is
the syntactic subject of the verb. VPHD (if specified) is a verb phrase token which is,
either the first part of a compound verb phrase or the initial auxiliary verb which is
separated from the rest of the verb group in a question. CMPND is a flag which is true if
the verb group is part of a compound verb phrase. DCLF is true if the verb group is part
of a dependent clause; DCLP is true if the dependent clause construction is passive.
QFLG is true if the verb group is a top-level verb group in a question.
The flowchart of VG is fairly straightforward. If a previous verb phrase is
available from a separated verb group in a question, it is deleted and incorporated into
the main verb group. The syntactic subject is attached to the verb phrase as subject or
object depending on whether the verb is active or passive. This transformation frees the
verb semantic programs from-having to concern themselves with the voice of the verb.
In a compound verb phrase without a subject (object if passive), the corresponding
phrase from the first verb phrase is used. Thus, in &amp;quot;John was tarred and feathered&amp;quot;,
&amp;quot;&apos;John&amp;quot; would be used as the object of &amp;quot;feathered&amp;quot;.
</bodyText>
<figure confidence="0.991969052631579">
Yes
Yes
Is this
question with a
revious ve
VB ■ previous
verb
Yes
so)
SUBJ NPND
OBJ ■2NPHD
Yes
Passive ?
Compound
Verb Phrase ?
Substitute SUBJ or
OBJ from previous VP
into this VP
SUCCESS
</figure>
<figureCaption confidence="0.668198">
Figure 3.2: Verb Group Parsing Program
</figureCaption>
<figure confidence="0.9166773">
Yes
Make VP token for
root verb
Set flags for
DCLAUSE
INTRANS / TRANS
IMPERATIVE
ACT / PASV
(as appropriate)
3.5.2 Verb Phrase
</figure>
<bodyText confidence="0.9990789375">
A flowchart of the verb phrase parsing program, VP, is shown in Figure :3.3.
VP first parses a verb group by calling VG, then collects the remaining predicate
phrases and modifiers and attaches them to the verb phrase token. These phrases
include the syntactic object noun phrase or-adjective phrase, an infinitive verb phrase
object (as in &amp;quot;they want to go . . .&amp;quot; ), and prepositional phrases or adverbs modifying
the verb.
After parsing a verb group, VP calls VPMODX to collect verb modifiers
(adverbs and prepositional phrases). An infinitive verb phrase object is collected if
present and attached to the verb phrase token under the indicator INFOBJ. If a
question is being parsed, the subject and the remainder of the separated verb group are
collected. A prepositional phrase on HOLD (that is, one which occurred at the start of
the sentence and could not be attached to anything, e.g. &amp;quot;At (By, the other end of the
pole, there is . • .&amp;quot; (P15) is attached to the verb phrase if possible. The predicate noun
phrase or adjective phrase is collected, along with any remaining modifiers. If the verb
phrase is part of a dependent clause, it is required to contain more than just a verb. A
dependent clause (DCLAUSE) is attached to the token of the phrase it modifies.
</bodyText>
<subsectionHeader confidence="0.947101">
3.6 Prepositional Phrase Parsing
</subsectionHeader>
<bodyText confidence="0.999601315789474">
The structure of the prepositional phrase is fairly simple. In addition to the
usual PP consisting of a preposition and noun phrase, the PP parser accepts a phrase
involving a measurement and a preposition and noun phrase (as in, &amp;quot;10 ft from one
end&amp;quot;) as a single prepositional phrase. Both types may involve question phrases, as in
&amp;quot;at what point&amp;quot; (P7) and &amp;quot;how far from the center&amp;quot; (P20).
The PP parser behaves differently from the other parsing programs in that it
saves a well-formed result which cannot be attached to the head token which was
specified, due to semantic constraints. If the PP parser is called again to reparse the
same phrase (as it surely will be), it applies the semantic tests to its previous result and
the new head token. This not only saves the work of reparsing an identical phrase twice,
but more importantly, it prevents side effects which occur during the parsing from being
repeated. These side effects (such as the creation of a new object in the model of the
problem) violate the restriction on a pure Woods net parser that all results be passed
between programs in designated registers; hence, the effects are not undone when
backup is made from a failing parse attempt. We could make all such actions reversible,
as in CONNIVER [McDermott and Sussman 72], but such an approach exacts a high
penalty in computational overhead. Our approach is probably safe for prepositional
phrases, which cannot in general be parsed as anything else. The pure Woods net
approach makes it difficult to mix syntactic and semantic processing. More research is
</bodyText>
<figure confidence="0.994952142857143">
29.
Fail
Succeed
VPHQDX
Get verb group modifiers
FML
V
SUCCESS
Get predicate Noun Phrase
or Adjective Phrase
Attach DCLAUSE to
its head
VPHODX
Get verb group modifiers
</figure>
<figureCaption confidence="0.90508">
Figure 3.3: Verb Phrase Parsipg Program
</figureCaption>
<figure confidence="0.989743">
VG
Get rest of verb
phrase
INFOBJ
(VP)
Yes
Get a
NOUA Phrase
Put SIM and
OBJ on verb
token
DOPPSEXL
Attach PP to Verb group
Process PP or QNP
on HOLD ,
</figure>
<bodyText confidence="0.997228166666667">
needed on way&apos;s to intermix the two and still be able to back up when necessary, without
incurring too much overhead.
Preposition semantics are executed, when possible, as soon as the
prepositional phrase has been parsed. In some cases, the semantic routine will elect lo
delay the semantic\ processing. In these cases, the PP is saved on the head token under
the indicator&amp;quot; PPS for later processing.
</bodyText>
<subsectionHeader confidence="0.921891">
3.7 Clause Parsing
</subsectionHeader>
<bodyText confidence="0.999941">
The clause parsing programs, CLAUSE and QCLAUSE, are relatively
simple programs which accept the several forms of declarative, imperative, and
question clauses, An initial prepositional phrase, if present, is placed on a HOLD list for
later processing. A noun phrase or question phrase is parsed and then used as an
argument for calling the verb phrase parser. The result of parsing a clause is the verb
phrase token, which contains pointers to its various arguments. This verb phrase token
is passed as an argument to the verb semantics driver, EXVBSEM, which completes
semantic processing of the sentence.
Figure 3.4 shows the structure formed after parsing and semantic processing
of a complete sentence. Much of the information in the structure is produced by the
semantic programs after parsing, but we will describe it briefly as an introduction to the
semantic processes. The root of the parse tree (the value returned by the SENTENCE
parsing function) is TOK185, the verb phrase token for the main verb of the sentence.
The object of the verb is TOK181, which was the syntactic subject (since the verb phrase
is passive); the subject (agent) of the verb is TOK186, which was introduced by the
preposition &amp;quot;by&amp;quot;. The semantic routine for &amp;quot;by&amp;quot; simply attached its object phrase
token, TOK186; to the verb phrase token as the subject of the verb; hence, there is no
need for &amp;quot;by&amp;quot; to appear anywhere in the structure) TOK181 is the noun phrase token
produced from the initial noun phrase of the sentence; it is a TOKen of the word
SCAFFOLD, is a Linguistic FRAME of type NP (Noun Phrase) has an INDEFinite
DETerminer, and has a NBR (number) of NS (Noun Singular). The modifier &amp;quot;12 ft
long&amp;quot; has been converted to the form (LENGTH 12 FT); the same modifier form would
be produced for the phrase &amp;quot;a 12 ft scaffold&amp;quot;. TOK181 is the syntactic subject of a
DCLAUSE (Dependent CLAUSE) whose verb token is T0K182. The SFRAME
(Semantic FRAME) interpretation of TOK181 is PHYSENT (PHYSical ENTity), and
its RFNT (Referent) is SCAFFOLD184, which is an object in the model of the problem.
The remaining tokens shown in the figure have a similar structure. The modifier
&amp;quot;vertical&amp;quot; of T0K186 has been cOnverted to the form (ROTN 90); this token has two
referent objects. The modifier&amp;quot;its&amp;quot; of TOK188 was converted to a modifier of the form
(POSSBY SCAFFOLD184), which was semantically processed to make T0K188 a
</bodyText>
<page confidence="0.875295">
31
</page>
<bodyText confidence="0.998241">
LOCPART (LOCation/PART) SFRAME whQse SEMOBJ (SEMantic OBJect) is
SCAFFOLD184; ideniification of the location referents of T0K188 yielddd the two
locations LOC190 and L0C189, which are locations on SCA FFOLD184 in the model of
the problem. Since TOK188 was the object of a preposition, semantic processing of the
prepositional phrase transferred its referents to a modifier of the verb phrase TOK187;
this left TOK188 unconnected to the rest of the structure.
</bodyText>
<subsectionHeader confidence="0.768049">
3.8 Conclusion
</subsectionHeader>
<bodyText confidence="0.999947777777778">
The computer time required for parsing and semantic processing averages
about one second per sentence, running on a CDC 6600 and using interpreted LISP. The
parsing programs constitute only about 15% of the total; the semantic programs are
twice as large. Syntactic processing is thus a -relatively small part of the complete
process of language understanding. On the other hand, this program has convinced the
author tha1 even in so constrained and well-defined an area as physics problems,
syntactic processing cannot reasonably be isolated and done without recourse to
semantic tests, some of which ultimately involve reasoning based on the particular facts
which are known about the objects being discussed.
</bodyText>
<page confidence="0.732275">
39
</page>
<tableCaption confidence="0.421519">
&amp;quot;A uniform scaffold 12 ft long and weighing 100 lb is supported horizontally by two
vertical ropes hung from its ends.&apos;&apos;
</tableCaption>
<table confidence="0.999612848484848">
TOK181 T0K182
TOK SCAFFOLD TOK WEIGH
LFRAME NP LFRAME VP
DET INDEF MAINVB WEIGHING
NBR (NS) DCLAUSE *T*
MODS (UNIFORM (LENGTH 12 FT)) INTRANS *T*
DCLAUSE (T0K182) ACT *T*
SFRAME PHYSENT SUBJ TOK181
RFNT (SCAFFOLD184) COMP T0K183
T0K183 T0K186
TOK LB TOK ROPE
LFRAME NP LFRAME NP
QTY 100 QTY 2
NBR (NPL)
T0K185 MODS ((ROTN 90))
TOK SUPPORT DCLAUSE (T0K187)
LFRAME VP SFRAME PHYSENT
MAINVB SUPPORTED RFNT (ROPE192 ROPE191)
AUX (IS)
TRANS *T* T0K188
PASV *T* TOK END
OBJ TOK181 LFRAME NP
SUBJ OK186 NBR (NEL)
SFRAME LOCPART
T0K187 SEMOBJ (SCAFFOLD184)
TOK HANG RFNT (LOC190 L0C189)
LFRAME VP
MAINVB HUNG
DCLAUSE *T*
INTRANS *T*
PASV *T*
OBJ TOK186
MODS (LOC FROM (LOC190 L0C189))
</table>
<figureCaption confidence="0.743504">
Figure 3.4: Structures Produced for a Complete Sentence
</figureCaption>
<page confidence="0.513851">
33
</page>
<bodyText confidence="0.782237166666667">
It may be helpful at this stage to realize that the primary form of
mathematical communication is not description, but injunction, In this
re,spect it is comparable with practical art forms like cookery, in which
the taste of a cake, although literally indescribable, can be conveyed to a
reader in the form of a set of injunctions called a recipe.
—G. Spencer Brown
</bodyText>
<sectionHeader confidence="0.852362" genericHeader="method">
4. Semantics
</sectionHeader>
<subsectionHeader confidence="0.7011">
4.1 Introduction
</subsectionHeader>
<bodyText confidence="0.998825857142857">
Semantics, for our purposes, is the process of constructing the meaning of a
sentence: the process of relating the objects in the sentence to objects in the world model
of the reader, and of updating the world model to reflect the meaning of the sentence.
The sentence itself is not a description of the meaning, but rather a set of injunctions, a
recipe which can be followed to construct the meaning from what the reader already
knows.
As the above definition implies, the way in which a sentence is interpreted
depends strongly on the knowledge, intelligence, and inclinations of the reader. As is
well known, different readers will interpret the same text (even in physics problems) in
different way. A semantic interpretation of a sentence may, be viewed as satisfactory or
unsatisfactory for a particular purpose, but it would be difficult to judge it as &amp;quot;right&amp;quot; or
&amp;quot;wrong.&amp;quot;
Updating the world model to reflect the meaning of a sentence can be a very
involved process, since the meaning of a single sentence can have many consequences.
In our physics problems, these deductions do not propagate very far beyond the
immediate understanding of a sentence during the time when the sentences are being
read. In this chapter, then, we will primarily discuss &amp;quot;linguistic semantics,&amp;quot; which we
may define as the semantic processing up to the point at which the parsing of a sentence
may be discarded. This distinction is well defined within the computer program. Under
this heading there are a number of distinct semantic processes: determining the
meaning of ambiguous words and phrases; finding anaphoric referents (such as
pronoun referents) and elliptical referents (such as the physical object referred to when
a location is named alone as in &amp;quot;one end&amp;quot;); determining the meaning of groups of
words whose meaning in combination is more than a combination of their individual
meanings; determining the meanings of modifiers of nouns and verbs and saving the
meanings so that they can be effective at the proper place in the processing; determining
whether an object or location mentioned in a sentence is a new one, or whether it refers
to one mentioned previously; adding objects and relations to the world model, and
</bodyText>
<page confidence="0.477668">
34
</page>
<bodyText confidence="0.999801166666667">
updating existing ones to reflect new information; expanding the model of an object so
that its subparts may be referenced; testing a modifier to determine whether it can
reasonably modify a given phrase (which may require reasoning based Lim the
particulars of the world model); interpreting an object of a given type as an object of a
desired type (for example, interpreting an object as a location or vice versa). All of these
processes will be discussed in this chapter.
</bodyText>
<subsectionHeader confidence="0.912616">
4.2 Preliminary Modifier Processing
</subsectionHeader>
<bodyText confidence="0.9999758">
Adjective and adverb modifiers of noun and verb phrases frequently have
their effects at a relatively late stage of semantic processing: the identification of the
referent of a noun phrase, or the execution of verb semantics. These modifiers must
therefore be saved for later reference. In some cases, a semantic routine will be
associated with the modifier itself; ill other cases. it is more convenient for a larger
routine to look for the existence of certain modifiers to guide its processing. Preliminary
modifier processing puts modifiers of certain classes into a standard form so that they
will be easy to identify or so that a single semantic routine can be used for the whole
class. In some cases, different meanings for a modifier may be selected depending on the
modified phrase.
Adjectives such as &amp;quot;one&amp;quot;, &amp;quot;other&amp;quot;, &amp;quot;first&amp;quot;, and &amp;quot;second&amp;quot; are put directly on
the noun phrase token under the indicator DET2. These modifiers are referenced in
determining the referent of the noun phrase. Adjectives such as &amp;quot;heavy&amp;quot;, &amp;quot;left&amp;quot;, and
&amp;quot;upper&amp;quot; are converted to modifiers of the form (SELECT adj); they are used in
selecting a particular referent from several possible ones. Quantifiers such as &amp;quot;each&amp;quot;
become modifiers of the form (QNTFR adj). Adjectives such as &amp;quot;horizontal&amp;quot;,
&amp;quot;vertical&amp;quot;, and &amp;quot;upward&amp;quot; are converted to rotation modifiers of the form (ROTN ang),
where &amp;quot;ang&amp;quot; is the appropriate angle.
Adjective phrases indicating measurement (as in &amp;quot;a 10 ft pole&amp;quot; or &amp;quot;a pole 10
ft long&amp;quot;) are converted to modifiers where the measured quantity is made explicit, e.g.,
(LENGTH 10 FT). When the referent of the noun phrase is found, the modifier is
transferred to the property list of the referent. In the case of unspecified force
measurements, tests are made on the modified noun phrase to determine the measured
quantity. Thus, a 150 lb man is a man whose weight is 150 lb, while a 150 lb force is a
force vector whose magnitude is 150 lb.
</bodyText>
<subsectionHeader confidence="0.977965">
4.3 Preposition Semantics
</subsectionHeader>
<bodyText confidence="0.997274">
Preposition semantics is an interesting area. A single preposition can have a
number of sense-meanings (as many as seven in our set of physics problems) depending
on the types of objects it connects. The actions required of the semantic routine are in
</bodyText>
<page confidence="0.536379">
35
</page>
<bodyText confidence="0.98248855">
general quite different for each sense-meaning; for our purposes, sense-meanings are
differentiated by the different actions required to process them adequately.
Discrimination net tests based on rough semantic classifications of the phrases
connected by the preposition were found to be adequate to distinguish the preposition
sense-meanings in our sample problems. We shall discuss in detail the semantic
processing for some prepositions, aind then compare our sense-meaning classifications
with dictionary classifications and postulate that techniques similar to ours may be
useful for machine translation of prepositional phrases.
4.3.1 Semantics of the Preposition &amp;quot;OF&amp;quot;
The sense-meaning classifications for the prepositions were determined by
listing the occurrences of each preposition together with the modified (or &amp;quot;head&amp;quot;)
phrase and the object phrase of each. Occurrences which seemed to be of the same
semantic class were grouped together, and a set of discrimination net tests was
developed which would distinguish between preposition uses in each of the diffeTent
classes. Using this procedure, seven distinct sense-meanings of the preposition &amp;quot;OF&amp;quot;
were found in our small sample of twenty physics problems—a surprisingly large
number considering that the problems are all of a similar. type. The seven sense-
meaning classes are listed below with examples. Although the classes were determined
from our physics problems, it is easy to think of examples of each class which are in
common usage and are not limited to the narrow area of physics problems.
</bodyText>
<listItem confidence="0.989651285714286">
1. &lt; quantifier&gt; OF &lt; objects&gt; each of the ropes
2. &lt; measurement&gt; OF &lt; value&gt; a length of 10 ft
3. &lt; object&gt; OF &lt; value&gt; &lt; attribute&gt; a pole of uniform cross section
4. &lt; location&gt; OF &lt; object&gt; the left end of the lever
5. &lt; attribute&gt; OF &lt; object&gt; the weight of the lever
6. &lt; group&gt; OF &lt; objects&gt; pair of legs
7. &lt; part&gt; OF &lt; object&gt; hinges of a door
</listItem>
<bodyText confidence="0.984619184210527">
The semantic classes for the head and object phrases are given for each
sense-meaning in the left-hand column; the discrimination net at the beginning of a
preposition semantic routine uses tests for these semantic classes to determine the
proper sense-meaning for a given use of the preposition. Once the proper sense-meaning
has been determined, the proc.essing required is fairly simple. For sense-meaning 1 of
&amp;quot;OF&amp;quot;, &lt; quantifier&gt; OF &lt; objects&gt; , the quantifier token is replaced by the object
token, and the quantifier is made a modifier of the token; thus, &amp;quot;each of the ropes&amp;quot; is
put into the same form as &amp;quot;each rope&amp;quot;. For sense-meaning 4, &lt; location&gt; OF
&lt; object&gt; , the SFRAME (Semantic Frame) of the head is set to LOCPART, and the
referent of the object phrase is put on the head token under the indicator SEMOBJ
36
(Semantic Object). [The process of referent identification is discussed in a later section.]
In cases such as this one, the determination of the preposition sense-meaning also serves
to determine the proper sernantic frame for the head phrase. The prepositional phrase
itself serves to supply one of the argumehts of the semantic frame. Just as parsing makes
explicit the syntactic relations which hold among the words in a sentence, the reduction
of phrases to their semantic frame form makes explicit the semantic relations which
hold among the objects referred to (explicitly or implicitly) by the phrases. The semantic
frames constitute a set of standard forms into which phrases representing similar
meanings are translated; thus, numerous different ways of expressing the same
meaning can all be translated into an identical semantic frame form.
In the case of senge-meaning 7, &lt; part&gt; OF &lt; object&gt; , a special semantic
routine may be called, into play to define the parts and their relation to the object they
are part of. In our example, &amp;quot;the hinges of a door&amp;quot; (P9), the correct formulation of the
problem requires the use of world knowledge that&apos;a door has two hinges (if the number
is unspecified) which are arranged vertically and attached to the door on one side. This
pragmatic knowledge is contained in a semantic routine for defining parts of doors. By
representing the knowledge in this way, it is possible to refer to the parts of a complex
object if necessary without expanding the internal model of the object into its parts if
they are not referenced.
In pur sample problems, there was* only one case where a prepositional
phrase modified a conjoined noun phrase: &amp;quot;magnitude, direction, and point of
application of the equilibrant&amp;quot; (P12 and P15). In this instance, the prepositional phrase
&amp;quot;of the equilibrant&amp;quot; should be assumed to modify each of the three conjoined phrases;
this is handled within the semantic routine for &amp;quot;OF&amp;quot;. It would be desirable to handle
such cases at a higher level and thus in a more general fashion. More research is needed
to find rules to govern the interpretation of prepositional phrases which modify
compound phrases.
</bodyText>
<subsectionHeader confidence="0.397522">
4.3.2 Semantics of Other Prepositions
</subsectionHeader>
<bodyText confidence="0.995486888888889">
In this section, we will briefly describe the sense meaning classifications and
semantic processing for the remaining prepositions. In each case, of course, there are
some sense-meanings of the preposition which are not handled by the program; we
discuss only those which are.
BY is used only to specify the agent of the verb in a passive verb phrase. The
object of the preposition is put on the verb token &apos;under the indicator SUBJ.
AGAINST is used to specify a case argument for a verb, as in &amp;quot;rests against a
vertical wall&amp;quot; (P8). The referent of the object phrase is identified, and the preposition
arid referent are put on the verb token as a modifier under the indicator CASEARG.
</bodyText>
<page confidence="0.486471">
37
</page>
<bodyText confidence="0.981359642857143">
CASEARG modifiers are processed by the verb semantic routines, which may have
specific interpretations for case arguments indicated by certain prepositions.
TO with a location object is used to specify a location for a verb phrase. The
location referent is identified, and the preposition and refhent are used as a. modifier
under the indicator LOC. Since modifiers are kept asli list under the property list
indicator MODS, there can be multiple LOC modifiers. The preposition is kept in case
the verb semantic routine can derive additional information from it; usually, however,
only the location referent will be used.
Proposed LOC modifiers are tested against the head phrase to determine
whether the modification is acceptable; this is done by a function called LOCTST. If the
head is a verb phrase, the verb is tested to see whether it can properly take a location
modifier. For example, in the sentence &amp;quot;There is a man weighing 150 lb at one end&amp;quot;, the
LOC modifier &amp;quot;at one end&amp;quot; would be rejected as a modifier of &amp;quot;weighing&amp;quot;, while in the
sentence &amp;quot;There is a man standing at one end&amp;quot; the LOC modifier would be accepted as
a modifier of &amp;quot;standing&amp;quot;. If the modified phrase is a noun phrase, the object referred to
(explicitly or implicitly) by the location modifier is tested against the head object; if they
are the same, the modification is rejected. Thus, in the sentence &amp;quot;one
painter . . . stands on the scaffold 4.0 ft from one end&amp;quot; (P3), the location modifier &amp;quot;4.0
ft from one end&amp;quot; is rejected as a modifier of &amp;quot;scaffold&amp;quot;, since its implicit object referent
is the scaffold. This rejection on semantic grounds (making reference to the
relationships among objects in the model of the problem which has been constructed, so
far) will cause the parsing in which the prepositional phrase modifies &amp;quot;scaffold&amp;quot; t45 be
rejected, so that the prepositional phrase will eventually be interpreted as a LOC
modifier of the verb &amp;quot;stands&amp;quot;. In the case &amp;quot;a boy 3 ft from one end&amp;quot; (P7), the location
modifier is accepted since different objects are referenced by the head and object
phrases.
FROM (without a measurement phrase preceding it) modifies a verb as a
CASEARG, as in &amp;quot;supported from the wall&amp;quot; (P8), or a LOC, as in &amp;quot;From end (A) a
weight of 2500 nt is hung&amp;quot; (P15). FROM2 (preceded by a measurement phrase) always
specifies a LOC; the measurement phrase may be a question phrase, a* in &amp;quot;how far from
the center&amp;quot; (P20). If the object of FROM2 specifies a physob rather than a location on a
RELPOBJ (an object on which relative positions are defined), an appropriate object for
the location to be on must be found. This is done by finding an attachment point
between the specified object and a RELPOBJ; thus, &amp;quot;0.5 m from Paul&amp;quot; (P17) specifies a
location on the pole Paul is carrying which is 0.5 m from the point of attachment
between Paul and the pole. The semantic routine for FROM2 must interpret the given
object (a physob) as an object of the desired type (a location on a different physob of a
particular type),
&apos;3 8
ETWEEN occurs only once in our problems: &amp;quot;on a pole between them&amp;quot;
(P17). When it connects a single physob and two physobs, as in this case, BETWEEN is
interpreted to mean that the first object is attached to the other two at the &amp;quot;usual&amp;quot;
places for the object (in this case, the ends of the pole).
AT always specifies a location, which may be a question phrase, as in &amp;quot;at
what point&amp;quot; (P7).
IN specifies either a location, as in &amp;quot;stand in the center&amp;quot;, or an attribute of
an object, as in &amp;quot;the tension in each rope&amp;quot; (P5). In the latter case, the SFRAME of the
head noun phrase is set to ATTROF and its SEMOBJ is set to the referent of the object
noun phrase. The same semantics are used for sense-meaning 5 of OF, &lt; attribute&gt; OF
&lt; object&gt; , and for one sense-meaning of ON.
WITH may be used to connect an object with an attribute and value, as in &amp;quot;a
spring with a constant of 40 lb/ft&amp;quot; (P1), or to connect a second participant in a
relationship with the relationship, as in &amp;quot;an angle of 60 deg with the horizontal&amp;quot; (P4).
The latter sense-meaning is frequently used in English to define the participants in a
relationship, usually using the verbs &amp;quot;have&amp;quot; and &amp;quot;make&amp;quot;.
There are five sense-meanings of ON which are recognized by the program:
</bodyText>
<listItem confidence="0.9920384">
1. &lt; physob&gt; on &lt; loc&gt;
2. &lt; attribute&gt; on &lt; physob&gt;
3. &lt; action&gt; on &lt; physob&gt;
4. &lt; verb&gt; on &lt; physob&gt;
5. &lt; verb&gt; on &lt; loc&gt;
</listItem>
<bodyText confidence="0.998723555555556">
the rope on the left end (P4)
the tension on each of the ropes (P3)
the forces on the supports (P6)
stands on the scaffold (P3)
placed on the edge of a block (P14)
Sense-meanings 1 and 5 are processed as LOC modifiers; meaning 2 is
converted to an ATTROF SFRAME; meaning 4 is converted to a CASEARG modifier.
Meaning 3 is converted to the SFRAME ACTON, with the referent of the object noun
phrase as its SEMOBJ.
</bodyText>
<subsubsectionHeader confidence="0.934103">
4.3.3 Definition and Translation of Prepositions
</subsubsectionHeader>
<bodyText confidence="0.9989129">
Out of curiosity, the sense-meaning classifications for the preposition OF
(which had the most sense-meanings of any in the program) were checked against the
definitions given for OF in several dictionaries. The agreement with the dictionary
definitions was very poor. Often, several of our classes would fit in a single dictionary
class, or one of our classes would fit in several dictionary classes. Prepositions are of
course hard to define, and native speakers of a language rarely need to look them up in
a dictionary. However, in translating from one natural language to another (whether
done by a human or by a machine), the correct translation of prepositional phrases is a
difficult problem. For example, the preposition OF can be translated into about a dozen
different prepositions in German; some uses of OF are translated into the genitive case
</bodyText>
<page confidence="0.603357">
39
</page>
<bodyText confidence="0.990963666666667">
or other constructions which do not use prepositions. It seems plausible that
discrimination nets similar to those used in our preposition semantic routines might be
used to discriminate preposition sense-meanings for machine translation. Hopefully,
sense-meaning classes could be found such that all usages of a preposition which fall
within each class could be acceptably translated into the same form in the target
language.
</bodyText>
<subsectionHeader confidence="0.960591">
4.4 Referent Identification
</subsectionHeader>
<bodyText confidence="0.9745454">
Referent Identification is the process of associating the phrases in a sentence
with the objects and relationships they refer to (explicitly or implicitly) in the reader&apos;s
model of the world. Such a process involves a number of possible steps. Candidate
referents must be found. In some cases the candidates will be identified by the same
word used in the sentence, or will be members of the same class which can be matched
together (e.g., &amp;quot;Paul&apos; and &amp;quot;boy&amp;quot;, both of which are members of the class PERSON with
the restriction (SEX MALE)). In other cases, the phrase in the sentence identifies the
candidates implicitly by identifying their relationships or attributes. (For example, in
(P17) the word &amp;quot;load&amp;quot; refers to a sack which is being carried on a pole.) In such a case,
the candidate can be considered an instance of the phrase in the sentence in its
particular instantiation, but not in general. If there are no candidates (or if there are
not enough), a referent must be created and added to the model. If there are several
candidates, it may be necessary to select a particular one, either arbitrarily or based on
modifiers of the phrase in the sentence. If modifiers are used, problem solving may be
required to determine which of the candidates satisfies the modifiers. Once the
referent(s) of the phrase have been identified, modifiers of the phrase must be processed
to add information to the referent as appropriate.
ISAAC contains programs to identify three types of referents: Physical
entities (objects and non-material physical entities such as forces), locations, and
attathments. These referent identification programs are described below.
</bodyText>
<subsubsectionHeader confidence="0.833835">
4.4.1 Identifying Physical Entity Referents
</subsubsectionHeader>
<bodyText confidence="0.9543905">
Physical entity referents are identified by the function IDRFNT. JT the
referent was previously identified, it is retrieved from the noun phrase token&apos;s property
list. Otherwise, the referent is identified using the function PHYSNP and put on the
token&apos;s property list under the indicator RFNT. (The &amp;quot;referent&amp;quot; is a list of pointers to
each of the objects or relations denoted by the noun phase.) If the noun phrase_is
compound, the referent of each component noun phrase is determined, and the
concatenation of all the referents is used as the referent of the compound.
A flowchart of PHYSNP is shown in Figure 4.1. The first step in identifying
</bodyText>
<figure confidence="0.852373181818182">
40
PHYSNP TO}( is the Noun Phrase token atom
Set SPRAMEtof TO(
to be PHYSENT
CANDS . Possible candidates
for WD
CANDS Candidates for
synonyms of WD
WD . Word for TOK
N . Number of referent&apos;s needed
QTY if spedIfied,
</figure>
<figureCaption confidence="0.593828">
2 if plural and not comppund
Ettuat to number of locatiOns If
there is a LOC modifleT,
</figureCaption>
<figure confidence="0.979129285714286">
1 otherwise
1
MAKEITe
Make N referent frames
DOMODS
Execute modiiex emantics
Return
</figure>
<figureCaption confidence="0.976208">
Figure 4.1 C2 pages): Flowchart of PHYSNP
</figureCaption>
<figure confidence="0.999409422222222">
Execute referent
semantic routine to egt
CANDS
41
CANDS is a list of possible
candidate referents
Po
Select first candidatp
(arbitrarily&apos;)
Eliminate candidates which
fail RSTRTEST or NAMETEST
CANDS NI
I Only one candidate
2. Quantifier EACH
QTY - Number of candidates
4. Plural and two candidates
,prop4r numhe
of referents 7
NO ci
DET2 one, other, first, second
Is there
a DET2
Yes Select approbriate
candidate
MODS - Modifiers of TOK
Yes
Yes
Yes
Does
candidate pass
semantic tea
7
Select current
candidate
No
Does
candidate hav4
dMering
MOD
No
Remove ctndidate
from CANDS
Yes
l■
Yes
</figure>
<figureCaption confidence="0.624776">
Figure 4.1 (page 2)
CDS - CANES
</figureCaption>
<bodyText confidence="0.957660512195122">
Get next
MOD
ES
the referent is to find the existing objects in the world model to which the noun phrase
might refer. (If the determiner is indefinite, it is assumed that a new object is being
referred to, and this step is bypassed.) The list of existing objects is searched first for
objects with the same token word as the noun phrase, and then for objects whose token
words are synonyms of the token word of the noun phrase. If no candidates are found by
either of these searches, a semantic routine associated with the noun phrase token word
is executed (if available) to see if there is a suitable -referent for that word in the model.
Such a semantic routine allows the noun phrase &amp;quot;the load&amp;quot; in (P17) to be matched to
the object whose token word is &amp;quot;sack&amp;quot; The referent semantic routine for &amp;quot;load&amp;quot; selects
an object which is a physical entity, is not a person, is supported by something, and does
not support anything itself. The semantic routine for &amp;quot;support&amp;quot; selects the appropriate
number of objects which all support the same object. If candidate objects are found by
any of these searches, they are subjected to further testing beginning at the flowchart
label (B) (page 2 of Figure 4.1).
If no candidate objects are found, or if all candidates are rejected on
semantic grounds, new referent objects must be created. The number of objects to be
created is set equal to the QTY (quantity) attribute of the noun phrase if specified (as in
&amp;quot;two boys&amp;quot; (P20)), to two if the noun phrase is plural and not compound, to the number
of locations if there is a location modifier (as in &amp;quot;a pier at each end&amp;quot; (P13)), or to one
otherwise. The proper number of objects is then created using the function MAKENT.
In most cases, MAKENT simply creates a GENSYM atom, sets its token
word appropriately, and adds it to the lit of created objects. Provision is made,
however, for special semantic routines to create referents for particular words. 4A
seesaw, for example, is not a single object, but a rigid plank pivoted at its center. The
semantic routine to make a referent for &amp;quot;seesaw&amp;quot; creates both objects and specifies their
attachment. Similarly, an equilibrant is a force which is applied to a rigid body to
produce equilibrium. The semantic routine to create a referent for &amp;quot;equilibrant&amp;quot; creates
a force, finds an appropriate rigid body, and specifies the attachment of the force to the
rigid body at an unknown position:
When the refereitts of the ,noun phrase have finally been determined or
created, the function DOMODS is called to execute the modifier semantics for each of
the modifiers which remain on the noun phrase token. Modifier semantics is discussed
in a later section.
The second page of Figure 4.1 shows the tests which are performed on
candidate referents for a noun phrase in order to reject those candidates which are
clearly inappropriate on semantic grounds and to select the proper candidate(s) from
those which remain. First, each candidate is subjected to RSTRTEST (restriction test)
and NAMETEST. RSTRTEST requires that if the candidate and the noun phrase have
</bodyText>
<page confidence="0.917936">
43
</page>
<bodyText confidence="0.989145419354839">
RESTRICT modifiers with the same indicator, the restriction values must be equal.
Thus, &amp;quot;Paul&amp;quot; and &amp;quot;boy&amp;quot;, both of which have the modifier (RESTRICT (SEX MALE)),
would match, while &amp;quot;Paul&amp;quot; and &amp;quot;girl&amp;quot; would not. NAMETEST requires that if both
the candidate and the noun phrase token have names, the names must match.
After any candidates which fail RSTRTEST or NAMETEST have been
removed, the *remaining candidates are examined to see if they constitute the proper
number of referents. If there is onry one candidate, if the quantifier &amp;quot;each&amp;quot; is present, if
the number of candidates matches the QTY (quantity) of the noun phrase, or if the noun
phrase is plural and there are two candidates, then the existing set of candidates is
accepted without further tests. If a determiner adjective is present, the corresponaing
candidate is picked: the first for &amp;quot;one&amp;quot; or &amp;quot;first&amp;quot;, or the second for &amp;quot;other&amp;quot; or &amp;quot;second&amp;quot;.
Otherwise, the candidates are tested against modifiers of the noun phrase. If a
candidate is found which has a matching modifier (e.g., both have the modifier
(WEIGHT 125 LB)), that candidate is selected. If a candidate has a mismatching
modifier (e.g., (WEIGHT 150 LB)), that candidate is removed from the list of
possibilities. Some modifiers, such as location modifiers, may have special semantic
routines fctr selecting candidates. A candidate is selected by the location semantic
routine if the location referent of the location modifier is a member of one of the
attachment relations of the candidate. Thus, &amp;quot;the rope on the left end&amp;quot; (P4) will select
the rope which is attached to the left end of the bar. If multiple candidates remain after
all the modifiers have been tested, the first one is selected arbitrarily.
In, some cases, the number of referents created for a noun phrase is not
enough when the context of the noun phrase is considered; in such cases, the function
MORERFNI may be called to create additional referents. For example, &amp;quot;the pier at
each end of the bridge&amp;quot; (P18) will cause two &amp;quot;pier&amp;quot; objects to be created because of the
two locations in the location modifier generated by the prepositional phrases. However,
in &amp;quot;a plank . . supported at each end by a stepladder&amp;quot; (P19), the location modifier is
attached to the verb phrase, so that initially only a single &amp;quot;stepladder&amp;quot; referent is
created. The verb semantics for SUPPORT, however, requires a separate supporting
object for each specified location, so that MORERFNT will be called to make a second
&amp;quot;stepladder&amp;quot; referent.
</bodyText>
<subsubsectionHeader confidence="0.486646">
4.4.2 Identifying Location Referents
</subsubsectionHeader>
<bodyText confidence="0.9966554">
There are two primary functions involved in the identification of location
referents, IDLOC and LOCNP. IDLOC identifies a location given the object to which the
location is relative, the location name, an optional SELECT modifier, and an optional
list of location frames to be excluded from the selection process. For example, the
phrase &amp;quot;the left end of the lever&amp;quot; would result in a call to IDLOC with the referent
</bodyText>
<page confidence="0.726991">
44
</page>
<bodyText confidence="0.999723789473684">
object for &amp;quot;the lever&amp;quot;, the location name &amp;quot;END&amp;quot;, the SELECT modifier &amp;quot;LEFT&amp;quot;, and
a null exclusion list as, arguments. IDLOC is used both by internal processes and by
LOCNP.
LOCNP identifies the location(s) referred to by a noun phrase. Since a
location may be specified by a wide variety of syntactic forms, LOCNP must identify the
form of the noun phrase and the features of the location which are specified. These
features are collected, and missing features are filled in by making inferences; finally,
IDLOC is called to identify the location referents. Thus, LOCNP serves as an interface
function to collect the arguments for IDLOC and put them into a standard form.
IDLOC and LOCNP are described in detail below.
A flowchart of IDLOC is shown in Figure 4.2. IDLOC first examines all the
existing locations on the specified object to see if one of them is suitable. An existing
location is rejected if it is a member of the excluded locations list, if it has the wrong
location name, or if it has a relative position (displacement) from the named position. If
the location passes these tests, it is examined for the specified SELECT value. In most
cases, the SELECT semantics consists of a test for an identical SELECT modifier (e.g.,
RIGHT or LEFT). In some cases, however, a special semantic routine must be used to
test the world model and determine whether a location meets the selection criterion. To
find &amp;quot;the heavy end&amp;quot; (P12), for example, it is necessary to eriamine the object frame for
the object involved; the &amp;quot;heavy&amp;quot; end is the one which is closest to the center of gravity of
the object. WhiCh end is the &amp;quot;heavy&amp;quot; one could be changed by changing the numeric
value of either the length of the bar or the distance from one end of the center of gravity,
while leaving all the English words the same. Thus, numerical problem solving by a
specialist program, based on the particular values specified for certain parameters, is
required to determine the proper location referent.
If no SELECT parameter is specified to IDLOC, or if the object being
examined has no SELECT modifier, the object is saved as a second choice in case a
better candidate is not found. Thus, if a SELECT value of LEFT is specified, all the
locations on the object with the proper location name (e.g., END) will be examined for a
SELECT LEFT modifier. If none is found, a location with no SELECT modifier will be
chosen; when the modifiers of the noun phrase are processed, the select value will be
added to that location frame.
In addition to its use by LOCNP, IDLOC is used internally by semantic
routines to identify particular locations on objects. For example, when a referent object
for &amp;quot;seesaw&amp;quot; is created, IDLOC is called to create a location frame for the center of the
newly created seesaw plank; this location is then used in specifying the attachment of
the plank to the pivot which is created.
LOCNP identifies the referent(s) of a location noun phrase; such a location
</bodyText>
<page confidence="0.908629">
43
</page>
<figure confidence="0.987542285714285">
,et all locations
for OBJ
OBJ - Object
LOCNAME Location Name
SELECT . Selection Modifier
EXCL -,List of Excluded Locations
SECC LOC
Yes
Return
1 Member of EXCL
2. Wrong location name
3. Has a relative position
offset.
Is LOC
unsuitable
Yes
SCC . &amp;quot;second choice&amp;quot;
SECC NIL
Yes
SELECT - NIL or
no SELECT on this
LOC ?
telurn
SECC
Any locations
left ?
Yes
Does LOC
pass SELECT
semantic
Yes
LOC - Next location
MAKELOC
Make a new
location frame
</figure>
<figureCaption confidence="0.999341">
Figure 4.2: Flowchart of IDLOC
</figureCaption>
<bodyText confidence="0.983246358974359">
46
may be denoted in many different ways. If the location has a name, the name alone may
be used (as in &amp;quot;80 cm from (A)&amp;quot; (P6)); the object to which the location is relative may or
may not be named (&amp;quot;the left end of the lever&amp;quot; or simply &amp;quot;the left, end&amp;quot;); a physical
object name may be used to specify a location, since every physical object occupies a
position in space.Most of the function LOCNP consists of code to make the &apos;inferences
and collect the arguments. needed to identify a location when the location is denoted by
any of the noun phrase forms mentioned above.
A flowchart of LOCNP is shown in Figure 4.3. If the referent of the noun
phrase is known, it is returned at once. Otherwise, a series of tests is made to determine
the type of location noun phrase. If a location is specified by name, the existing location
frames are searched for a location with that name. When the correct location is found, it
is saved on the noun phrase token under the indicator RFNT, and the function
DOMODS is called to process any modifiers of the noun phrase. If the noun phrase is
already marked as being a LOCPART SFRAME, the object to which the location is
relative is already known; this will be the case if a modifier of the location noun phrase
specifies the object, as in &amp;quot;the end of the lever&amp;quot; or &amp;quot;its left end&amp;quot;. In such cases. LOCNP
transfers directly to the label &amp;quot;B&amp;quot; (page 2 of Figure 4.3). If a location is named without
an object (as in &amp;quot;one end&amp;quot;), it is necessary to find an appropriate object. This is done by
examining the GEOMODEL (geometric model) of each object in the model of the
problem until an object for which the location name is appropriate has been found.
Once the appropriate object for the location has been inferred, the noun phrase token is
converted to a LOCPART SFRAME, and control iS transferred to label &amp;quot;B&amp;quot;. If the
noun phrase names a physical object or person, IDRFNT is called to identify the
physical object referent. If the object to which the location is relative is specified in the
call to LOCNP and is different from the object named by the noun phrase, a search is
made for a location at which the named object is attached to the desired object; thus, in
&amp;quot;0.5 m from Paul&amp;quot; (P17), which specifies a location on a pole which Paul is carrying,
&amp;quot;Paul&amp;quot; is interpreted as a location on the pole by finding the point on the pole where
Paul is attached to it. If the desired object is unspecified, a location is made for the
default location of the named object.
At label &amp;quot;B&amp;quot; of the flowchart, where LOCPART SFRAMEs are processed, a
test is made to ee if the noun phrase is plural or modified by the quantifier EACH, as in
&amp;quot;its ends&amp;quot; or &amp;quot;each end&amp;quot;. If so. the number of such locations is gotten from the
GEOMODEL of the object, and that number of locations is identified by calls to
IDLOC. Thus, &amp;quot;each end&amp;quot; (P3), referring to a scaffold, will cause two &amp;quot;end&amp;quot; location
frames to be generated. If the noun phrase is singular, IDLOC is called to identify a
single location referent. If a location name is specified, the location found is required to
pass NAMETEST, having either the correct name or no name. Once the proper referent
</bodyText>
<note confidence="0.413628">
9.1■ImPrawl■
</note>
<figureCaption confidence="0.97902">
Figure 4.3 (2 pages): Flowchart of LOCNP
</figureCaption>
<figure confidence="0.998097013888889">
Yes
Return
refnt,
Is ?eferent
already kno
Is HD
a name ?
Yes
CANDS - lokcation(s)
with specified
name (s)
DOMODS
Execute modifier
semantics
Yes
Is HD,a
LOCNAME ?
Find an object for
which the locname
is appropriate
Make HD a LOCPART
SFRAME
Is HD a
PERSON or
PHYSOB?
Is OBJ
specified t
IDRFNT
Identify referent
of HD
HD ; Noun Phrase Token
OBI) Object for Location (optional)
LOCNP
Is HD a
LOCPART SFRAME
Save referent on
HD token
Yes
Return
Yes
Return
Yes
No
IDRFNT
Identify referent
of HD •
Find a location on
OBJ where referent
is attached
4
Fail
IDLOC
Identify default locations
on referent of HD
Succeed
48
IDLOC
Identify proper
number of locations
IDLOC
Identify location
referent
HD is a LOCFART SFRAME
HD plural
or quantifier
EACH 7
Get the number of this
type of location for
this object
Yes
Add location referent to
exclusion list
</figure>
<figureCaption confidence="0.987856">
Figure 4.3 (page 2)
</figureCaption>
<page confidence="0.576316">
49
</page>
<bodyText confidence="0.9954315">
has been found, control is passed to the label &amp;quot;H&amp;quot; to save the referent and process
modifers of the noun phrase.
</bodyText>
<subsubsectionHeader confidence="0.968228">
4.4.3 Attachment Identification
</subsubsectionHeader>
<bodyText confidence="0.99976556">
An attachment relationship among two or more objects is identified by the
function IDATT. Attachment relations are not the direct referents of phrases in a
sentence, but are defined by verb semantic routines or modifier semantic routines. The
argument of IDATT is a paired list of objects and locations on the objects; one member
of each pair may be nil. IDATT identifies an attachment frame which specifies the
attachment of all the objects in the list; if no such attachment frame exists, one is
created, along with links between it and the objects involved. (The structure of
attachments and other frames is described in Appendix B.) If an existing attachment
which matches the list,is found and the list contains locations which were previously
unspecified, the locations are put into the existing attachment frame. Thus, in cases
such as
A painter . . . stands on a plank . . .
If he stands 1.0 in from one end of the plank . . . (P19),
the second attachment will be identified with the earlier one and will cause the location
on. the plank to be added to the attachment frame. The order in which the
object/location pairs are specified in the call to IDATT is unimportant.
A second parameter in the. call to IDATT is the type of attachment:
CONTACT (as in the above example) or PINJOINT. The type of attachment is not used
by IDATT, but is saved with the attachment frame for later use. The interaction of
objects at an attachment point may depend on the type of attachment. A CONTACT
attachment with a &amp;quot;smooth&amp;quot; surface, for example, implies that the force exerted by the
surface is nonnegative and perpendicular to the surface. A PINJOINT attachment may
transmit a force in any direction, but may not transmit a torque. Although other types of
attachments could be used, CONTACT and PINJOINT are the only ones used by the
program in its present form.
</bodyText>
<subsectionHeader confidence="0.927067">
4.5 Modifier Semantics
</subsectionHeader>
<bodyText confidence="0.986860222222222">
Modifiers of noun phrases are saved, after some preliminary processing
(Section 4.2), on the property list of the noun phrase token under the indicator MODS.
After the referent of the noun phrase has been determined, the semantic routines, of
these saved modifiers are executed so that the appropriate changes may be made to the
referent of the noun phrase. (Some modifiers, which are used in selecting the proper,
referent, are deleted before this stage is reached.)
Modifier semantic processing is controlled by the driver function DOMODS,
,)0
which calls PUTMODR for each modifier. PUTMODR (which is also used for modifier
processing by some verb semantic routines) transfers the modifier to the propert list of
each referent, or executes a special semantic routine if there is one associated with the
modifier. Thus, in simple cases such as &amp;quot;a 150 lb man&amp;quot;, the modifier (WEIGHT 150
LB) generated from the adjective phrase is transferred to the referent&apos;s property list as
the value (150 LB) under the indicator WEIGHT. In other cases, semantic routines may
make inferences from modifiers, e.g., that an object which is at a location on another
object is attached to the other object at that location.
RESTRICT modifiers are concatenated and placed on the referent object
under the indicator RESTRICT; this allows an object to have multiple RESTRICT
modifiers, which are used in determining noun phrase referents.
Measurement modifiers are transferred directly to the property list of the
referent. In the process, the measurement units for each type il)f measurement are saved
for use in answer generation. It would be easy to modify the measurement modifier
semantic routine to allow differing units (e.g., feet and meters) to be used in the same
problem.
NAME modifiers are processed in different ways depending on the type of
name and the type of object which is named. Simple names are transferred directly to
the property list of the named object. Geometric names which modify locations are
distributed to the named locations. If geometric names are assigned to a physical object,
as in &amp;quot;a uniform bar (A B)&amp;quot; (P6), location referents are created for the appropriate
locations on the object (in this case the ends of the bar) as determined by the object&apos;s
GEOMODEL, and the geometric names are assigned to the location referents.
An APART modifier gives the distance between tw&apos;o&apos; locations, as in &amp;quot;the
hinges of a door . . . are 12 ft apart&amp;quot; (P9). This modifier not only gives the distance
between the two locations, but also implicitly determines the size of the object if the two
locations are on the same object. In the above case, for example, we can infer that the
door is at least 12 ft tall. The semantic routine for APART modifiers consults the
GEOMODEL of the object, calculates the overall size dimension which would give the
specified distance between the two points, and assigns that size to the object.
In our set of physics problems, a location modifier of a noun phrase always
implies that the referent object is attached to something at that location, as in &amp;quot;an
automobile . . . which, is 30.0 ft from one end of the bridge&amp;quot; (P18). The modifier
semantics routine for location modifiers calls IDATT to define the attachment. In a
larger system which handled a wider range Of problems, some additional semantic tests
would be needed to determine whether an attachment was actually implied by the
location modifier.
</bodyText>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.052198">
<note confidence="0.83735">Journal of Computational Linguistics 53</note>
<title confidence="0.926793333333333">COMPUTER UNDERSTANDING OF PHYSICS PROBLEMS STATED IN NATURAL LANGUAGE</title>
<author confidence="0.980707">GORDON S NOVAK JR</author>
<affiliation confidence="0.998156">Department University of Texas</affiliation>
<address confidence="0.893816">Austin 78712</address>
<title confidence="0.700785">for Computational</title>
<abstract confidence="0.958165657142857">SUMMARY This paper describes a computer program, called ISAAC, which can read, understand, solve, and draw pictures of physics problems stated in English. The program has solved twenty problems, most of which were taken unedited from high school and college physics texts. These problems involve . rigid bodies in static equilibrium, and include such objects ,as levers, pivots, weights, ropes, and springs in various configurations. An example of the class of problems solved is the following Outline of College Physics): The foot of a ladder rests against a &apos;c&apos;ertical wall and on a horizontal floor. The top of the ladder is supporvi4 from the wall by a horizontal 30 ft long. The laddei is 50 ft long, weighs W ith its center of gravity 20 ft from the foot, and a 150 lb man is 10 ft from the top. Determine the tension in the rope. In order to understand and solve such a problem, it is necessary to build an model of the problem in which the various objects and then interrelationships are adequately represented. Many of the relationships and features of the objects are not specified explicitly in the problem statement but must be inferred by using common knowledge of what is usual. In the abow example, we that the mato is standing on the ladder, although this is not explicitly stated. Thus, the understanding of a physics problem is an active process in Which the :=:entences of the problem statement are used to guide the construction of a model which represents the relationships and features of objects with much greater detail and specificity rhan, they are specified in the original problem statement. paper, we investigate ways in which the meanings of phrases and sentences may be understood and related to a developing model of the problem, using common sense knowledge (represented by computer programs) to aid the understanding process. Was of representing objects and their relationships are developed. These representations, which are originally created in response to the sentences in the problem statement, are further elaborated by processes which construct.a geometric model of the problem, associate canonical objects (such as.a point mass) with physical objects t.su(h as a person), write and solve equations which describe the interactions of the objects and construct a diagram of the problem. This paper is a slightly edited version of the author.s Ph.D. dissertation. I am grateful to my committee membeis, Professors John Loehlin, Woodrow Bledsoe, and Norman Martin, and especially to my supervising pcofeswi., liobext F. Simmons.</abstract>
<note confidence="0.42847725">TABLE OF CONTENTS Page SUMMARY 2 LIST OF FIGURES 5</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>