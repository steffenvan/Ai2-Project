<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.996332">
Graph Ranking for Sentiment Transfer
</title>
<author confidence="0.999519">
Qiong Wu1,2, Songbo Tan1 and Xueqi Cheng1
</author>
<affiliation confidence="0.994198">
1Institute of Computing Technology, Chinese Academy of Sciences, China
2 Graduate University of Chinese Academy of Sciences, China
</affiliation>
<email confidence="0.995862">
{wuqiong,tansongbo}@software.ict.ac.cn, cxq@ict.ac.cn
</email>
<sectionHeader confidence="0.99738" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999622545454545">
With the aim to deal with sentiment-transfer
problem, we proposed a novel approach,
which integrates the sentiment orientations of
documents into the graph-ranking algorithm.
We apply the graph-ranking algorithm using
the accurate labels of old-domain documents
as well as the “pseudo” labels of new-domain
documents. Experimental results show that
proposed algorithm could improve the per-
formance of baseline methods dramatically for
sentiment transfer.
</bodyText>
<sectionHeader confidence="0.999392" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999921071428571">
With the rapid growth of reviewing pages, sen-
timent classification is drawing more and more
attention (Bai et al., 2005; Pang and Lee, 2008).
Generally speaking, sentiment classification can
be considered as a special kind of traditional text
classification (Tan et al., 2005; Tan, 2006). In
most cases, supervised learning methods can per-
form well (Pang et al., 2002). But when training
data and test data are drawn from different do-
mains, supervised learning methods always pro-
duce disappointing results. This is so-called
cross-domain sentiment classification problem
(or sentiment-transfer problem).
Sentiment transfer is a new study field. In re-
cent years, only a few works are conducted on
this field. They are generally divided into two
categories. The first one needs a small amount of
labeled training data for the new domain (Aue
and Gamon, 2005). The second one needs no
labeled data for the new domain (Blitzer et al.,
2007; Tan et al., 2007; Andreevskaia and Bergler,
2008; Tan et al., 2008; Tan et al., 2009). In this
paper, we concentrate on the second category
which proves to be used more widely.
Graph-ranking algorithm has been success-
fully used in many fields (Wan et al., 2006; Esuli
and Sebastiani, 2007), whose idea is to give a
node high score if it is strongly linked with other
high-score nodes. In this work, we extend the
graph-ranking algorithm for sentiment transfer
by integrating the sentiment orientations of the
documents, which could be considered as a sen-
timent-transfer version of the graph-ranking al-
gorithm. In this algorithm, we assign a score for
every unlabelled document to denote its extent to
“negative” or “positive”, then we iteratively cal-
culate the score by making use of the accurate
labels of old-domain data as well as the “pseudo”
labels of new-domain data, and the final score
for sentiment classification is achieved when the
algorithm converges, so we can label the new-
domain data based on these scores.
</bodyText>
<sectionHeader confidence="0.993085" genericHeader="method">
2 The Proposed Approach
</sectionHeader>
<subsectionHeader confidence="0.631236">
2.1 Overview
</subsectionHeader>
<bodyText confidence="0.997393733333333">
In this paper, we have two document sets: the
test data DU = {d1,...,dn} where di is the term
vector of the ith text document and each diEDU(i
= 1,...,n) is unlabeled; the training data DL =
{dn+1,...dn+m} where dj represents the term vector
of the jth text document and each djEDL(j =
n+1,...,n+m) should have a label from a category
set C = {negative, positive}. We assume the
training dataset DL is from the related but differ-
ent domain with the test dataset DU. Our objec-
tive is to maximize the accuracy of assigning a
label in C to diEDU (i = 1,...,n) utilizing the
training data DL in another domain.
The proposed algorithm is based on the fol-
lowing presumptions:
</bodyText>
<listItem confidence="0.9968886">
(1) Let WL denote the word space of old do-
main, WU denote the word space of new domain.
WLnWU#(D.
(2) The labels of documents appear both in the
training data and the test data should be the same.
Based on graph-ranking algorithm, it is
thought that if a document is strongly linked with
positive (negative) documents, it is probably
positive (negative). And this is the basic idea of
learning from a document’s neighbors.
</listItem>
<bodyText confidence="0.965474333333333">
Our algorithm integrates the sentiment orienta-
tions of the documents into the graph-ranking
algorithm. In our algorithm, we build a graph
</bodyText>
<page confidence="0.982293">
317
</page>
<note confidence="0.9257025">
Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 317–320,
Suntec, Singapore, 4 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999801588235294">
whose nodes denote documents and edges denote
the content similarities between documents. We
initialize every document a score (“1” denotes
positive, and “-1” denotes negative) to represent
its degree of sentiment orientation, and we call it
sentiment score. The proposed algorithm calcu-
lates the sentiment score of every unlabelled
document by learning from its neighbors in both
old domain and new domain, and then iteratively
calculates the scores with a unified formula. Fi-
nally, the algorithm converges and each docu-
ment gets its sentiment score. When its sentiment
score falls in the range [0, 1] (or [-1, 0]], the
document should be classified as “positive (or
negative)”. The closer its sentiment score is near
1 (or -1), the higher the “positive (or negative)”
degree is.
</bodyText>
<subsectionHeader confidence="0.994283">
2.2 Score Documents
</subsectionHeader>
<bodyText confidence="0.969425923076923">
Score Documents Using Old-domain Informa-
tion
We build a graph whose nodes denote documents
in both DL and DU and edges denote the content
similarities between documents. If the content
similarity between two documents is 0, there is
no edge between the two nodes. Otherwise, there
is an edge between the two nodes whose weight
is the content similarity. The content similarity
between two documents is computed with the
cosine measure. We use an adjacency matrix U
to denote the similarity matrix between DU and
DL. U=[Uij]nxm is defined as follows:
The weight associated with term t is computed
with tftidft where tft is the frequency of term t in
the document and idft is the inverse document
frequency of term t, i.e. 1+log(N/nt), where N is
the total number of documents and nt is the num-
ber of documents containing term t in a data set.
In consideration of convergence, we normal-
ize U to Uˆ by making the sum of each row equal
to 1:
In order to find the neighbors (in another word,
the nearest documents) of a document, we sort
every row of Uˆ to U% in descending order. That is:
Then for
</bodyText>
<equation confidence="0.907322">
(i = 1,...,n),
(j =
)
corresponds to K neighbors in DL. So we can
k≥j).
di∈DU
U% ij
1,...,K
get
its K neighbors. We use a matrix N = [Nij ]n×K
</equation>
<bodyText confidence="0.9999755">
to denote the neighbors of DU in old domain,
with Nij corresponding to the jth nearest neighbor
of di.
At last, we can calculate sentiment score si (i
= 1,...,n) using the scores of the di’s neighbors as
follows:
</bodyText>
<equation confidence="0.957024">
s () = ∑
k ( ˆ ×( k1 i
i ij j
j Ni•∈
</equation>
<bodyText confidence="0.808721">
where i • means the ith row of a matrix and
si denotes the si at the kth iteration.
(k)
</bodyText>
<subsectionHeader confidence="0.480899">
Score Documents Using New-domain Infor-
mation
</subsectionHeader>
<bodyText confidence="0.999973142857143">
Similarly, a graph is built, in which each node
corresponds to a document in DU and the weight
of the edge between any different documents is
computed by the cosine measure. We use an ad-
jacency matrix V=[Vij]nxn to describe the similar-
ity matrix. And V is similarly normalized to Vˆ to
make the sum of each row equal to 1. Then we
sort every row of Vˆ to V% in descending order,
thus we can get K neighbors of di∈DU (i =
1,...,n) from V% ij (j = 1,...K), and we use a matrix
M = [Mij ]n×K to denote the neighbors of DU in
the new domain. Finally, we can calculate si us-
ing the sentiment scores of the di’s neighbors as
follows:
</bodyText>
<equation confidence="0.977508857142857">
s( ) ( ˆ ( 1)),
k = ∑ V s
× −
k i = 1, . . . , n
ij
i j
Mi•
</equation>
<subsectionHeader confidence="0.997586">
2.3 Sentiment Transfer Algorithm
</subsectionHeader>
<bodyText confidence="0.961578230769231">
Initialization
Firstly, we classify the test data DU to get their
initial labels using a traditional classifier. For
simplicity, we use prototype classification algo-
rithm (Tan et al., 2005) in this work.
Then, we give “-1” to si(0) if di’s label is
“negative”, and “1” if “positive”. So we obtain
the initial sentiment score vector S(0) for both
domain data.
At last, si(0) (i = 1,...,n) is normalized as fol-
lows to make the sum of positive scores of DU
equal to 1, and the sum of negative scores of DU
equal to -1:
</bodyText>
<figure confidence="0.824629375">
Uij
(5)
d d
•
i j
U = , 1, ... , ,
i = n j n
= +1, ... ,n+
ij
m (1)
d × dj
m m
Uij ∑ Uij, if ∑ Uij
j = 1 j=1
0,
≠0
(2)
ˆ ⎪⎧
⎨⎪⎩
otherwise
% %
ik (i = 1,...n; j,k = 1,...m;
U ij ≥ U
n (3)
(4)
j∈
s
(0)
⎧ ∑ (
i
U
neg
⎪ ∈
s (0) j D
⎨ i =
i (0)
= ∑
s (0) 1, . . . ,
s , if s (0) &gt; 0
i j i
⎪⎪ j D U pos
⎩ ∈
n
− s (0) if s (
),
j i
0
)&lt;0
</figure>
<page confidence="0.991579">
318
</page>
<bodyText confidence="0.999704">
denote the negative and
positive document set of DU respectively. The
same as (5), sj (0) (j =n+1,...,n+m) is normalized.
</bodyText>
<sectionHeader confidence="0.539443" genericHeader="method">
Algorithm Introduction
</sectionHeader>
<bodyText confidence="0.999912">
In our algorithm, we label DU by making use of
information of both old domain and new domain.
We fuse equations (3) and (4), and get the itera-
tive equation as follows:
</bodyText>
<equation confidence="0.998993615384615">
s ( )
k k k
α U s + ∑ V s i
−
= ∑ • ×
( ˆ ( 1)) ( ˆ ( 1) ),
− β × =
ij ih
i j h
j N
∈ h M
∈
i i•
</equation>
<bodyText confidence="0.99774">
where α +β =1, and α andβ show the relative
importance of old domain and new domain to the
final sentiment scores. In consideration of the
convergence, S(k) (S at the kth iteration) is normal-
ized after each iteration.
Here is the complete algorithm:
</bodyText>
<listItem confidence="0.994201142857143">
1. Classify DU with a traditional classifier.
Initialize the sentiment score si of di∈DU
∪DL (i = 1,...n+m) and normalize it.
2. Iteratively calculate the S(k) of DU and
normalize it until it achieves the conver-
gence:
3. According to
</listItem>
<equation confidence="0.964217846153846">
S (i = 1,...,n), assign
each
= 1,...n) a label. If
is be-
tween -1 and 0, assign
the label
is between 0 an
si∈
di∈DU (i
si
di
“nega-
tive”;if si
</equation>
<bodyText confidence="0.92292">
d 1, assign di the
label “positive”.
</bodyText>
<sectionHeader confidence="0.999982" genericHeader="evaluation">
3 EXPERIMENTS
</sectionHeader>
<bodyText confidence="0.995611727272727">
And then we man
http://www.ctrip.com/).
ually
label the reviews as “negative” or “positive”.
The detailed composition of the data sets are
shown in Table 1, which shows the name of the
data set (DataSet), the number of negative re-
views (Neg), the number of positive reviews
(Pos), the average length of reviews (Length),
the number of different words (Vocabulary) in
this data set.
</bodyText>
<table confidence="0.6236515">
DataSet Neg Pos Length Vocabulary
Elec 554 1,054 121 6,200
Stock 683 364 460 13,012
Hotel 2,000 2,000 181 11,336
</table>
<bodyText confidence="0.9851016">
First, we use ICTCLAS (htt
p://ictclas.org/), a
Chinese text POS tool, to segment these Chinese
reviews. Second, the documents are represented
by vector space model.
</bodyText>
<equation confidence="0.76819">
Vector Machine is
supervised
learning algorithm. In our experiment, we use
LibSVM
with a
</equation>
<bodyText confidence="0.976473176470588">
linear kernel and set all options by default.
We also compare our algorithm to Structural
Correspondence Learning (SCL) (Blitzer et al.,
2007). SCL is a
sentiment-
transfer algorithm which automatically induces
correspondences among features from different
domains. It identifies correspondences among
features from different domains by modeling
their correlations with pivot features, which are
features that behave in the same way for dis-
criminative learning in both domains. In our ex-
a state-of-the-art
(www.csie.ntu.edu.tw/~cjlin/libsvm/)
state-of-the-art
ment, we use 100 pivot features.
n
</bodyText>
<subsectionHeader confidence="0.999098">
3.1 Data Preparation
</subsectionHeader>
<bodyText confidence="0.9913654">
We prepare three Chinese domain-specific data
sets from on-line reviews, which are: Electronics
Reviews (Elec, from http://detail.zol.com.cn/),
Stock Reviews (Stock, from http://blog.sohu.com
/stock/) and Hotel Reviews (Hotel, from
</bodyText>
<tableCaption confidence="0.960426">
Table 1. Data sets composition
</tableCaption>
<bodyText confidence="0.996868">
We make some preprocessing on the datasets.
</bodyText>
<subsectionHeader confidence="0.999582">
3.2 Evaluation Setup
</subsectionHeader>
<bodyText confidence="0.9999014">
In our experiment, we use prototype classifica-
tion algorithm (Tan et al., 2005) and Support
Vector Machine experimenting on the three data
sets as our baselines separately. The Support
peri
</bodyText>
<subsectionHeader confidence="0.990636">
3.3 Overall
</subsectionHeader>
<bodyText confidence="0.936138388888889">
Performance
In this section, we conduct two groups of ex-
periments where we separately initialize the sen-
timent scores in our algorithm by prototype clas-
sifier and Support Vector Machine.
There are two parameters in our algorithm, K
and
can be calculated by
). We set the
parameters K and
with 150 and 0.7 respec-
tively, which indicates we use 150 neighbors and
the contribution from old domain is a little more
important than that from new domain. It is
thought that the algorithm achieves the conver-
gence when the changing between the sentiment
score
computed at two successive iterations for
</bodyText>
<equation confidence="0.564348">
any
DU (i = 1,...n) falls below a given
</equation>
<tableCaption confidence="0.4611486">
threshold, and we set the threshold 0.00001 in
this work.
Table 2 shows the accuracy of Prototype,
LibSVM, SCL and our algorithm when training
data an
</tableCaption>
<figure confidence="0.810844324324324">
α(β
1-α
α
si
di∈
d test data belong to different domains.
s( )
k = α ∑(Qij × s(k−1)) + β ∑(�h × s(k−1)), i =
i jh
j∈Ni• h∈ Mi•
⎧ s ( )
k ∑
i
j DU
s ( )
k neg
⎪ ∈
⎨ i =
i s k s k if s k
= ∑
( ) ( ) ( )
, &gt; 0
i j i
⎪⎪ j DUpos
⎩ ∈
(
n
1, . . . ,
1,...,
jk) ),
−s
if si
k
) &lt;0
where U and U
Dneg Dpos
1, ... ,n(6)
</figure>
<page confidence="0.995426">
319
</page>
<table confidence="0.910600333333333">
Our algorithm is separately initialized by Proto-
type and LibSVM.
Baseline SCL Proposed Algorithm
Prototype LibSVM Prototype+ LibSVM+
OurApproach OurApproach
Elec-&gt;Stock 0.6652 0.6478 0.7507 0.7326 0.7304
Elec-&gt;Hotel 0.7304 0.7522 0.7750 0.7543 0.7543
Stock-&gt;Hotel 0.6848 0.6957 0.7683 0.7435 0.7457
Stock-&gt;Elec 0.7043 0.6696 0.8340 0.8457 0.8435
Hotel-&gt;Stock 0.6196 0.5978 0.6571 0.7848 0.7848
Hotel-&gt;Elec 0.6674 0.6413 0.7270 0.8609 0.8609
Average 0.6786 0.6674 0.7520 0.7870 0.7866
</table>
<tableCaption confidence="0.999899">
Table 2. Accuracy comparison of different methods
</tableCaption>
<bodyText confidence="0.999986357142857">
As we can observe from Table 2, our algo-
rithm can dramatically increase the accuracy of
sentiment-transfer. Seen from the 2nd column and
the 5th column, every accuracy of the proposed
algorithm is increased comparing to Prototype.
The average increase of accuracy over all the 6
problems is 10.8%. Similarly, the accuracy of
our algorithm is higher than LibSVM in every
problem and the average increase of accuracy is
11.9%. The great improvement comparing with
the baselines indicates that the proposed algo-
rithm performs very effectively and robustly.
Seen from Table 2, our result about SCL is in
accord with that in (Blitzer et al., 2007) on the
whole. The average accuracy of SCL is higher
than both baselines, which convinces that SCL is
effective for sentiment-transfer. However, our
approach outperforms SCL: the average accuracy
of our algorithm is about 3.5 % higher than SCL.
This is caused by two reasons. First, SCL is es-
sentially based on co-occurrence of words (the
window size is the whole document), so it is eas-
ily affected by low frequency words and the size
of data set. Second, the pivot features of SCL are
totally dependent on experts in the field, so the
quality of pivot features will seriously affect the
performance of SCL. This improvement con-
vinces us of the effectiveness of our algorithm.
</bodyText>
<sectionHeader confidence="0.998472" genericHeader="conclusions">
4 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.99994775">
In this paper, we propose a novel sentiment-
transfer algorithm. It integrates the sentiment
orientations of the documents into the graph-
ranking based method for sentiment-transfer
problem. The algorithm assigns a score for every
document being predicted, and it iteratively cal-
culates the score making use of the accurate la-
bels of old-domain data, as well as the “pseudo”
labels of new-domain data, finally it labels the
new-domain data as “negative” or “positive” bas-
ing on this score. The experiment results show
that the proposed approach can dramatically im-
prove the accuracy when transferred to a new
domain.
In this study, we find the neighbors of a given
document using cosine similarity. This is too
general, and perhaps not so proper for sentiment
classification. In the next step, we will try other
methods to calculate the similarity. Also, our
approach can be applied to multi-task learning.
</bodyText>
<sectionHeader confidence="0.999604" genericHeader="acknowledgments">
5 Acknowledgments
</sectionHeader>
<bodyText confidence="0.994405666666667">
This work was mainly supported by two funds, i.e.,
0704021000 and 60803085, and one another project,
i.e., 2004CB318109.
</bodyText>
<sectionHeader confidence="0.999278" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999881604651163">
B. Pang and L. Lee. 2008. Opinion mining and senti-
ment analysis. Foundations and Trends in Infor-
mation Retrieval, 2008
S. Tan, X. Cheng, M. Ghanem, B. Wang and H. Xu.
2005. A Novel Refinement Approach for Text
Categorization. In Proceedings of CIKM 2005.
S. Tan. 2006. An Effective Refinement Strategy for
KNN Text Classifier. Expert Systems With Appli-
cations. Elsevier. 30(2): 290-298.
B. Pang, L. Lee, and S. Vaithyanathan. 2002. Thumbs
up? Sentiment classification using machine learn-
ing techniques. In Proceedings of EMNLP, 2002.
X. Bai, R. Padman and E. Airoldi. 2005. On learning
parsimonious models for extracting consumer
opinions. In Proceedings of HICSS 2005.
A. Aue and M. Gamon. 2005. Customizing sentiment
classifiers to new domains: a case study. In
Proceedings of RANLP 2005.
J. Blitzer, M. Dredze, and F. Pereira. 2007. Biogra-
phies, Bollywood, Boom-boxes and Blenders:
Domain adaptation for sentiment classification. In
Proceedings of ACL 2007.
S. Tan, G. Wu, H. Tang and X. Cheng. 2007. A novel
scheme for domain-transfer problem in the context
of sentiment analysis. In Proceedings of CIKM
2007.
S. Tan, Y. Wang, G. Wu and X. Cheng. 2008. Using
unlabeled data to handle domain-transfer problem
of semantic detection. In Proceedings of SAC 2008.
S. Tan, X. Cheng, Y. Wang, H. Xu. 2009. Adapting
Naive Bayes to Domain Adaptation for Sentiment
Analysis. In Proceedings of ECIR 2009.
A. Esuli, F. Sebastiani. 2007. Random-walk models
of term semantics: An application to opinion-
related properties. In Proceedings of LTC 2007.
X. Wan, J. Yang and J. Xiao. 2006. Using Cross-
Document Random Walks for Topic-Focused
Multi-Document Summarization. In Proceedings
of WI 2006.
A. Andreevskaia and S. Bergler. 2008. When Special-
ists and Generalists Work Together: Overcoming
Domain Dependence in Sentiment Tagging. In
Proceedings of ACL 2008.
</reference>
<page confidence="0.998254">
320
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.455124">
<title confidence="0.997925">Graph Ranking for Sentiment Transfer</title>
<author confidence="0.942269">Songbo</author>
<author confidence="0.942269">Xueqi</author>
<affiliation confidence="0.992694">of Computing Technology, Chinese Academy of Sciences, China</affiliation>
<address confidence="0.502316">2Graduate University of Chinese Academy of Sciences, China</address>
<email confidence="0.969104">wuqiong@software.ict.ac.cn,cxq@ict.ac.cn</email>
<email confidence="0.969104">tansongbo@software.ict.ac.cn,cxq@ict.ac.cn</email>
<abstract confidence="0.998605416666667">With the aim to deal with sentiment-transfer problem, we proposed a novel approach, which integrates the sentiment orientations of documents into the graph-ranking algorithm. We apply the graph-ranking algorithm using the accurate labels of old-domain documents as well as the “pseudo” labels of new-domain documents. Experimental results show that proposed algorithm could improve the performance of baseline methods dramatically for sentiment transfer.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
</authors>
<title>Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval,</title>
<date>2008</date>
<contexts>
<context position="883" citStr="Pang and Lee, 2008" startWordPosition="118" endWordPosition="121">Abstract With the aim to deal with sentiment-transfer problem, we proposed a novel approach, which integrates the sentiment orientations of documents into the graph-ranking algorithm. We apply the graph-ranking algorithm using the accurate labels of old-domain documents as well as the “pseudo” labels of new-domain documents. Experimental results show that proposed algorithm could improve the performance of baseline methods dramatically for sentiment transfer. 1 Introduction With the rapid growth of reviewing pages, sentiment classification is drawing more and more attention (Bai et al., 2005; Pang and Lee, 2008). Generally speaking, sentiment classification can be considered as a special kind of traditional text classification (Tan et al., 2005; Tan, 2006). In most cases, supervised learning methods can perform well (Pang et al., 2002). But when training data and test data are drawn from different domains, supervised learning methods always produce disappointing results. This is so-called cross-domain sentiment classification problem (or sentiment-transfer problem). Sentiment transfer is a new study field. In recent years, only a few works are conducted on this field. They are generally divided into </context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>B. Pang and L. Lee. 2008. Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval, 2008</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Tan</author>
<author>X Cheng</author>
<author>M Ghanem</author>
<author>B Wang</author>
<author>H Xu</author>
</authors>
<title>A Novel Refinement Approach for Text Categorization.</title>
<date>2005</date>
<booktitle>In Proceedings of CIKM</booktitle>
<contexts>
<context position="1018" citStr="Tan et al., 2005" startWordPosition="137" endWordPosition="140">f documents into the graph-ranking algorithm. We apply the graph-ranking algorithm using the accurate labels of old-domain documents as well as the “pseudo” labels of new-domain documents. Experimental results show that proposed algorithm could improve the performance of baseline methods dramatically for sentiment transfer. 1 Introduction With the rapid growth of reviewing pages, sentiment classification is drawing more and more attention (Bai et al., 2005; Pang and Lee, 2008). Generally speaking, sentiment classification can be considered as a special kind of traditional text classification (Tan et al., 2005; Tan, 2006). In most cases, supervised learning methods can perform well (Pang et al., 2002). But when training data and test data are drawn from different domains, supervised learning methods always produce disappointing results. This is so-called cross-domain sentiment classification problem (or sentiment-transfer problem). Sentiment transfer is a new study field. In recent years, only a few works are conducted on this field. They are generally divided into two categories. The first one needs a small amount of labeled training data for the new domain (Aue and Gamon, 2005). The second one ne</context>
<context position="7436" citStr="Tan et al., 2005" startWordPosition="1280" endWordPosition="1283">e sum of each row equal to 1. Then we sort every row of Vˆ to V% in descending order, thus we can get K neighbors of di∈DU (i = 1,...,n) from V% ij (j = 1,...K), and we use a matrix M = [Mij ]n×K to denote the neighbors of DU in the new domain. Finally, we can calculate si using the sentiment scores of the di’s neighbors as follows: s( ) ( ˆ ( 1)), k = ∑ V s × − k i = 1, . . . , n ij i j Mi• 2.3 Sentiment Transfer Algorithm Initialization Firstly, we classify the test data DU to get their initial labels using a traditional classifier. For simplicity, we use prototype classification algorithm (Tan et al., 2005) in this work. Then, we give “-1” to si(0) if di’s label is “negative”, and “1” if “positive”. So we obtain the initial sentiment score vector S(0) for both domain data. At last, si(0) (i = 1,...,n) is normalized as follows to make the sum of positive scores of DU equal to 1, and the sum of negative scores of DU equal to -1: Uij (5) d d • i j U = , 1, ... , , i = n j n = +1, ... ,n+ ij m (1) d × dj m m Uij ∑ Uij, if ∑ Uij j = 1 j=1 0, ≠0 (2) ˆ ⎪⎧ ⎨⎪⎩ otherwise % % ik (i = 1,...n; j,k = 1,...m; U ij ≥ U n (3) (4) j∈ s (0) ⎧ ∑ ( i U neg ⎪ ∈ s (0) j D ⎨ i = i (0) = ∑ s (0) 1, . . . , s , if s (0)</context>
<context position="10955" citStr="Tan et al., 2005" startWordPosition="1955" endWordPosition="1958">hat behave in the same way for discriminative learning in both domains. In our exa state-of-the-art (www.csie.ntu.edu.tw/~cjlin/libsvm/) state-of-the-art ment, we use 100 pivot features. n 3.1 Data Preparation We prepare three Chinese domain-specific data sets from on-line reviews, which are: Electronics Reviews (Elec, from http://detail.zol.com.cn/), Stock Reviews (Stock, from http://blog.sohu.com /stock/) and Hotel Reviews (Hotel, from Table 1. Data sets composition We make some preprocessing on the datasets. 3.2 Evaluation Setup In our experiment, we use prototype classification algorithm (Tan et al., 2005) and Support Vector Machine experimenting on the three data sets as our baselines separately. The Support peri 3.3 Overall Performance In this section, we conduct two groups of experiments where we separately initialize the sentiment scores in our algorithm by prototype classifier and Support Vector Machine. There are two parameters in our algorithm, K and can be calculated by ). We set the parameters K and with 150 and 0.7 respectively, which indicates we use 150 neighbors and the contribution from old domain is a little more important than that from new domain. It is thought that the algorit</context>
</contexts>
<marker>Tan, Cheng, Ghanem, Wang, Xu, 2005</marker>
<rawString>S. Tan, X. Cheng, M. Ghanem, B. Wang and H. Xu. 2005. A Novel Refinement Approach for Text Categorization. In Proceedings of CIKM 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Tan</author>
</authors>
<title>An Effective Refinement Strategy for KNN Text Classifier. Expert Systems With Applications.</title>
<date>2006</date>
<journal>Elsevier.</journal>
<volume>30</volume>
<issue>2</issue>
<pages>290--298</pages>
<contexts>
<context position="1030" citStr="Tan, 2006" startWordPosition="141" endWordPosition="142">he graph-ranking algorithm. We apply the graph-ranking algorithm using the accurate labels of old-domain documents as well as the “pseudo” labels of new-domain documents. Experimental results show that proposed algorithm could improve the performance of baseline methods dramatically for sentiment transfer. 1 Introduction With the rapid growth of reviewing pages, sentiment classification is drawing more and more attention (Bai et al., 2005; Pang and Lee, 2008). Generally speaking, sentiment classification can be considered as a special kind of traditional text classification (Tan et al., 2005; Tan, 2006). In most cases, supervised learning methods can perform well (Pang et al., 2002). But when training data and test data are drawn from different domains, supervised learning methods always produce disappointing results. This is so-called cross-domain sentiment classification problem (or sentiment-transfer problem). Sentiment transfer is a new study field. In recent years, only a few works are conducted on this field. They are generally divided into two categories. The first one needs a small amount of labeled training data for the new domain (Aue and Gamon, 2005). The second one needs no label</context>
</contexts>
<marker>Tan, 2006</marker>
<rawString>S. Tan. 2006. An Effective Refinement Strategy for KNN Text Classifier. Expert Systems With Applications. Elsevier. 30(2): 290-298.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
<author>S Vaithyanathan</author>
</authors>
<title>Thumbs up? Sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<contexts>
<context position="1111" citStr="Pang et al., 2002" startWordPosition="153" endWordPosition="156">e accurate labels of old-domain documents as well as the “pseudo” labels of new-domain documents. Experimental results show that proposed algorithm could improve the performance of baseline methods dramatically for sentiment transfer. 1 Introduction With the rapid growth of reviewing pages, sentiment classification is drawing more and more attention (Bai et al., 2005; Pang and Lee, 2008). Generally speaking, sentiment classification can be considered as a special kind of traditional text classification (Tan et al., 2005; Tan, 2006). In most cases, supervised learning methods can perform well (Pang et al., 2002). But when training data and test data are drawn from different domains, supervised learning methods always produce disappointing results. This is so-called cross-domain sentiment classification problem (or sentiment-transfer problem). Sentiment transfer is a new study field. In recent years, only a few works are conducted on this field. They are generally divided into two categories. The first one needs a small amount of labeled training data for the new domain (Aue and Gamon, 2005). The second one needs no labeled data for the new domain (Blitzer et al., 2007; Tan et al., 2007; Andreevskaia </context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>B. Pang, L. Lee, and S. Vaithyanathan. 2002. Thumbs up? Sentiment classification using machine learning techniques. In Proceedings of EMNLP, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Bai</author>
<author>R Padman</author>
<author>E Airoldi</author>
</authors>
<title>On learning parsimonious models for extracting consumer opinions.</title>
<date>2005</date>
<booktitle>In Proceedings of HICSS</booktitle>
<contexts>
<context position="862" citStr="Bai et al., 2005" startWordPosition="114" endWordPosition="117">cn, cxq@ict.ac.cn Abstract With the aim to deal with sentiment-transfer problem, we proposed a novel approach, which integrates the sentiment orientations of documents into the graph-ranking algorithm. We apply the graph-ranking algorithm using the accurate labels of old-domain documents as well as the “pseudo” labels of new-domain documents. Experimental results show that proposed algorithm could improve the performance of baseline methods dramatically for sentiment transfer. 1 Introduction With the rapid growth of reviewing pages, sentiment classification is drawing more and more attention (Bai et al., 2005; Pang and Lee, 2008). Generally speaking, sentiment classification can be considered as a special kind of traditional text classification (Tan et al., 2005; Tan, 2006). In most cases, supervised learning methods can perform well (Pang et al., 2002). But when training data and test data are drawn from different domains, supervised learning methods always produce disappointing results. This is so-called cross-domain sentiment classification problem (or sentiment-transfer problem). Sentiment transfer is a new study field. In recent years, only a few works are conducted on this field. They are ge</context>
</contexts>
<marker>Bai, Padman, Airoldi, 2005</marker>
<rawString>X. Bai, R. Padman and E. Airoldi. 2005. On learning parsimonious models for extracting consumer opinions. In Proceedings of HICSS 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Aue</author>
<author>M Gamon</author>
</authors>
<title>Customizing sentiment classifiers to new domains: a case study.</title>
<date>2005</date>
<booktitle>In Proceedings of RANLP</booktitle>
<contexts>
<context position="1599" citStr="Aue and Gamon, 2005" startWordPosition="230" endWordPosition="233">l text classification (Tan et al., 2005; Tan, 2006). In most cases, supervised learning methods can perform well (Pang et al., 2002). But when training data and test data are drawn from different domains, supervised learning methods always produce disappointing results. This is so-called cross-domain sentiment classification problem (or sentiment-transfer problem). Sentiment transfer is a new study field. In recent years, only a few works are conducted on this field. They are generally divided into two categories. The first one needs a small amount of labeled training data for the new domain (Aue and Gamon, 2005). The second one needs no labeled data for the new domain (Blitzer et al., 2007; Tan et al., 2007; Andreevskaia and Bergler, 2008; Tan et al., 2008; Tan et al., 2009). In this paper, we concentrate on the second category which proves to be used more widely. Graph-ranking algorithm has been successfully used in many fields (Wan et al., 2006; Esuli and Sebastiani, 2007), whose idea is to give a node high score if it is strongly linked with other high-score nodes. In this work, we extend the graph-ranking algorithm for sentiment transfer by integrating the sentiment orientations of the documents,</context>
</contexts>
<marker>Aue, Gamon, 2005</marker>
<rawString>A. Aue and M. Gamon. 2005. Customizing sentiment classifiers to new domains: a case study. In Proceedings of RANLP 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Blitzer</author>
<author>M Dredze</author>
<author>F Pereira</author>
</authors>
<title>Biographies, Bollywood, Boom-boxes and Blenders: Domain adaptation for sentiment classification.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context position="1678" citStr="Blitzer et al., 2007" startWordPosition="245" endWordPosition="248">learning methods can perform well (Pang et al., 2002). But when training data and test data are drawn from different domains, supervised learning methods always produce disappointing results. This is so-called cross-domain sentiment classification problem (or sentiment-transfer problem). Sentiment transfer is a new study field. In recent years, only a few works are conducted on this field. They are generally divided into two categories. The first one needs a small amount of labeled training data for the new domain (Aue and Gamon, 2005). The second one needs no labeled data for the new domain (Blitzer et al., 2007; Tan et al., 2007; Andreevskaia and Bergler, 2008; Tan et al., 2008; Tan et al., 2009). In this paper, we concentrate on the second category which proves to be used more widely. Graph-ranking algorithm has been successfully used in many fields (Wan et al., 2006; Esuli and Sebastiani, 2007), whose idea is to give a node high score if it is strongly linked with other high-score nodes. In this work, we extend the graph-ranking algorithm for sentiment transfer by integrating the sentiment orientations of the documents, which could be considered as a sentiment-transfer version of the graph-ranking</context>
<context position="10076" citStr="Blitzer et al., 2007" startWordPosition="1836" endWordPosition="1839">ws (Pos), the average length of reviews (Length), the number of different words (Vocabulary) in this data set. DataSet Neg Pos Length Vocabulary Elec 554 1,054 121 6,200 Stock 683 364 460 13,012 Hotel 2,000 2,000 181 11,336 First, we use ICTCLAS (htt p://ictclas.org/), a Chinese text POS tool, to segment these Chinese reviews. Second, the documents are represented by vector space model. Vector Machine is supervised learning algorithm. In our experiment, we use LibSVM with a linear kernel and set all options by default. We also compare our algorithm to Structural Correspondence Learning (SCL) (Blitzer et al., 2007). SCL is a sentimenttransfer algorithm which automatically induces correspondences among features from different domains. It identifies correspondences among features from different domains by modeling their correlations with pivot features, which are features that behave in the same way for discriminative learning in both domains. In our exa state-of-the-art (www.csie.ntu.edu.tw/~cjlin/libsvm/) state-of-the-art ment, we use 100 pivot features. n 3.1 Data Preparation We prepare three Chinese domain-specific data sets from on-line reviews, which are: Electronics Reviews (Elec, from http://detai</context>
<context position="13352" citStr="Blitzer et al., 2007" startWordPosition="2389" endWordPosition="2392">m Table 2, our algorithm can dramatically increase the accuracy of sentiment-transfer. Seen from the 2nd column and the 5th column, every accuracy of the proposed algorithm is increased comparing to Prototype. The average increase of accuracy over all the 6 problems is 10.8%. Similarly, the accuracy of our algorithm is higher than LibSVM in every problem and the average increase of accuracy is 11.9%. The great improvement comparing with the baselines indicates that the proposed algorithm performs very effectively and robustly. Seen from Table 2, our result about SCL is in accord with that in (Blitzer et al., 2007) on the whole. The average accuracy of SCL is higher than both baselines, which convinces that SCL is effective for sentiment-transfer. However, our approach outperforms SCL: the average accuracy of our algorithm is about 3.5 % higher than SCL. This is caused by two reasons. First, SCL is essentially based on co-occurrence of words (the window size is the whole document), so it is easily affected by low frequency words and the size of data set. Second, the pivot features of SCL are totally dependent on experts in the field, so the quality of pivot features will seriously affect the performance</context>
</contexts>
<marker>Blitzer, Dredze, Pereira, 2007</marker>
<rawString>J. Blitzer, M. Dredze, and F. Pereira. 2007. Biographies, Bollywood, Boom-boxes and Blenders: Domain adaptation for sentiment classification. In Proceedings of ACL 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Tan</author>
<author>G Wu</author>
<author>H Tang</author>
<author>X Cheng</author>
</authors>
<title>A novel scheme for domain-transfer problem in the context of sentiment analysis.</title>
<date>2007</date>
<booktitle>In Proceedings of CIKM</booktitle>
<contexts>
<context position="1696" citStr="Tan et al., 2007" startWordPosition="249" endWordPosition="252">erform well (Pang et al., 2002). But when training data and test data are drawn from different domains, supervised learning methods always produce disappointing results. This is so-called cross-domain sentiment classification problem (or sentiment-transfer problem). Sentiment transfer is a new study field. In recent years, only a few works are conducted on this field. They are generally divided into two categories. The first one needs a small amount of labeled training data for the new domain (Aue and Gamon, 2005). The second one needs no labeled data for the new domain (Blitzer et al., 2007; Tan et al., 2007; Andreevskaia and Bergler, 2008; Tan et al., 2008; Tan et al., 2009). In this paper, we concentrate on the second category which proves to be used more widely. Graph-ranking algorithm has been successfully used in many fields (Wan et al., 2006; Esuli and Sebastiani, 2007), whose idea is to give a node high score if it is strongly linked with other high-score nodes. In this work, we extend the graph-ranking algorithm for sentiment transfer by integrating the sentiment orientations of the documents, which could be considered as a sentiment-transfer version of the graph-ranking algorithm. In thi</context>
</contexts>
<marker>Tan, Wu, Tang, Cheng, 2007</marker>
<rawString>S. Tan, G. Wu, H. Tang and X. Cheng. 2007. A novel scheme for domain-transfer problem in the context of sentiment analysis. In Proceedings of CIKM 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Tan</author>
<author>Y Wang</author>
<author>G Wu</author>
<author>X Cheng</author>
</authors>
<title>Using unlabeled data to handle domain-transfer problem of semantic detection.</title>
<date>2008</date>
<booktitle>In Proceedings of SAC</booktitle>
<contexts>
<context position="1746" citStr="Tan et al., 2008" startWordPosition="257" endWordPosition="260"> data and test data are drawn from different domains, supervised learning methods always produce disappointing results. This is so-called cross-domain sentiment classification problem (or sentiment-transfer problem). Sentiment transfer is a new study field. In recent years, only a few works are conducted on this field. They are generally divided into two categories. The first one needs a small amount of labeled training data for the new domain (Aue and Gamon, 2005). The second one needs no labeled data for the new domain (Blitzer et al., 2007; Tan et al., 2007; Andreevskaia and Bergler, 2008; Tan et al., 2008; Tan et al., 2009). In this paper, we concentrate on the second category which proves to be used more widely. Graph-ranking algorithm has been successfully used in many fields (Wan et al., 2006; Esuli and Sebastiani, 2007), whose idea is to give a node high score if it is strongly linked with other high-score nodes. In this work, we extend the graph-ranking algorithm for sentiment transfer by integrating the sentiment orientations of the documents, which could be considered as a sentiment-transfer version of the graph-ranking algorithm. In this algorithm, we assign a score for every unlabelle</context>
</contexts>
<marker>Tan, Wang, Wu, Cheng, 2008</marker>
<rawString>S. Tan, Y. Wang, G. Wu and X. Cheng. 2008. Using unlabeled data to handle domain-transfer problem of semantic detection. In Proceedings of SAC 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Tan</author>
<author>X Cheng</author>
<author>Y Wang</author>
<author>H Xu</author>
</authors>
<title>Adapting Naive Bayes to Domain Adaptation for Sentiment Analysis.</title>
<date>2009</date>
<booktitle>In Proceedings of ECIR</booktitle>
<contexts>
<context position="1765" citStr="Tan et al., 2009" startWordPosition="261" endWordPosition="264">a are drawn from different domains, supervised learning methods always produce disappointing results. This is so-called cross-domain sentiment classification problem (or sentiment-transfer problem). Sentiment transfer is a new study field. In recent years, only a few works are conducted on this field. They are generally divided into two categories. The first one needs a small amount of labeled training data for the new domain (Aue and Gamon, 2005). The second one needs no labeled data for the new domain (Blitzer et al., 2007; Tan et al., 2007; Andreevskaia and Bergler, 2008; Tan et al., 2008; Tan et al., 2009). In this paper, we concentrate on the second category which proves to be used more widely. Graph-ranking algorithm has been successfully used in many fields (Wan et al., 2006; Esuli and Sebastiani, 2007), whose idea is to give a node high score if it is strongly linked with other high-score nodes. In this work, we extend the graph-ranking algorithm for sentiment transfer by integrating the sentiment orientations of the documents, which could be considered as a sentiment-transfer version of the graph-ranking algorithm. In this algorithm, we assign a score for every unlabelled document to denot</context>
</contexts>
<marker>Tan, Cheng, Wang, Xu, 2009</marker>
<rawString>S. Tan, X. Cheng, Y. Wang, H. Xu. 2009. Adapting Naive Bayes to Domain Adaptation for Sentiment Analysis. In Proceedings of ECIR 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Esuli</author>
<author>F Sebastiani</author>
</authors>
<title>Random-walk models of term semantics: An application to opinionrelated properties.</title>
<date>2007</date>
<booktitle>In Proceedings of LTC</booktitle>
<contexts>
<context position="1969" citStr="Esuli and Sebastiani, 2007" startWordPosition="295" endWordPosition="298">em). Sentiment transfer is a new study field. In recent years, only a few works are conducted on this field. They are generally divided into two categories. The first one needs a small amount of labeled training data for the new domain (Aue and Gamon, 2005). The second one needs no labeled data for the new domain (Blitzer et al., 2007; Tan et al., 2007; Andreevskaia and Bergler, 2008; Tan et al., 2008; Tan et al., 2009). In this paper, we concentrate on the second category which proves to be used more widely. Graph-ranking algorithm has been successfully used in many fields (Wan et al., 2006; Esuli and Sebastiani, 2007), whose idea is to give a node high score if it is strongly linked with other high-score nodes. In this work, we extend the graph-ranking algorithm for sentiment transfer by integrating the sentiment orientations of the documents, which could be considered as a sentiment-transfer version of the graph-ranking algorithm. In this algorithm, we assign a score for every unlabelled document to denote its extent to “negative” or “positive”, then we iteratively calculate the score by making use of the accurate labels of old-domain data as well as the “pseudo” labels of new-domain data, and the final s</context>
</contexts>
<marker>Esuli, Sebastiani, 2007</marker>
<rawString>A. Esuli, F. Sebastiani. 2007. Random-walk models of term semantics: An application to opinionrelated properties. In Proceedings of LTC 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Wan</author>
<author>J Yang</author>
<author>J Xiao</author>
</authors>
<title>Using CrossDocument Random Walks for Topic-Focused Multi-Document Summarization.</title>
<date>2006</date>
<booktitle>In Proceedings of WI</booktitle>
<contexts>
<context position="1940" citStr="Wan et al., 2006" startWordPosition="291" endWordPosition="294">ent-transfer problem). Sentiment transfer is a new study field. In recent years, only a few works are conducted on this field. They are generally divided into two categories. The first one needs a small amount of labeled training data for the new domain (Aue and Gamon, 2005). The second one needs no labeled data for the new domain (Blitzer et al., 2007; Tan et al., 2007; Andreevskaia and Bergler, 2008; Tan et al., 2008; Tan et al., 2009). In this paper, we concentrate on the second category which proves to be used more widely. Graph-ranking algorithm has been successfully used in many fields (Wan et al., 2006; Esuli and Sebastiani, 2007), whose idea is to give a node high score if it is strongly linked with other high-score nodes. In this work, we extend the graph-ranking algorithm for sentiment transfer by integrating the sentiment orientations of the documents, which could be considered as a sentiment-transfer version of the graph-ranking algorithm. In this algorithm, we assign a score for every unlabelled document to denote its extent to “negative” or “positive”, then we iteratively calculate the score by making use of the accurate labels of old-domain data as well as the “pseudo” labels of new</context>
</contexts>
<marker>Wan, Yang, Xiao, 2006</marker>
<rawString>X. Wan, J. Yang and J. Xiao. 2006. Using CrossDocument Random Walks for Topic-Focused Multi-Document Summarization. In Proceedings of WI 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Andreevskaia</author>
<author>S Bergler</author>
</authors>
<title>When Specialists and Generalists Work Together: Overcoming Domain Dependence in Sentiment Tagging.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context position="1728" citStr="Andreevskaia and Bergler, 2008" startWordPosition="253" endWordPosition="256">et al., 2002). But when training data and test data are drawn from different domains, supervised learning methods always produce disappointing results. This is so-called cross-domain sentiment classification problem (or sentiment-transfer problem). Sentiment transfer is a new study field. In recent years, only a few works are conducted on this field. They are generally divided into two categories. The first one needs a small amount of labeled training data for the new domain (Aue and Gamon, 2005). The second one needs no labeled data for the new domain (Blitzer et al., 2007; Tan et al., 2007; Andreevskaia and Bergler, 2008; Tan et al., 2008; Tan et al., 2009). In this paper, we concentrate on the second category which proves to be used more widely. Graph-ranking algorithm has been successfully used in many fields (Wan et al., 2006; Esuli and Sebastiani, 2007), whose idea is to give a node high score if it is strongly linked with other high-score nodes. In this work, we extend the graph-ranking algorithm for sentiment transfer by integrating the sentiment orientations of the documents, which could be considered as a sentiment-transfer version of the graph-ranking algorithm. In this algorithm, we assign a score f</context>
</contexts>
<marker>Andreevskaia, Bergler, 2008</marker>
<rawString>A. Andreevskaia and S. Bergler. 2008. When Specialists and Generalists Work Together: Overcoming Domain Dependence in Sentiment Tagging. In Proceedings of ACL 2008.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>