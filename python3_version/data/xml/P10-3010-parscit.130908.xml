<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000232">
<title confidence="0.996806">
Transition-based parsing with Confidence-Weighted Classification
</title>
<author confidence="0.998177">
Martin Haulrich
</author>
<affiliation confidence="0.9866845">
Dept. of International Language Studies and Computational Linguistics
Copenhagen Business School
</affiliation>
<email confidence="0.990126">
mwh.isv@cbs.dk
</email>
<sectionHeader confidence="0.993701" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999562875">
We show that using confidence-weighted
classification in transition-based parsing
gives results comparable to using SVMs
with faster training and parsing time. We
also compare with other online learning
algorithms and investigate the effect of
pruning features when using confidence-
weighted classification.
</bodyText>
<sectionHeader confidence="0.998801" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99987675">
There has been a lot of work on data-driven depen-
dency parsing. The two dominating approaches
have been graph-based parsing, e.g. MST-parsing
(McDonald et al., 2005b) and transition-based
parsing, e.g. the MaltParser (Nivre et al., 2006a).
These two approaches differ radically but have
in common that the best results have been ob-
tained using margin-based machine learning ap-
proaches. For the MST-parsing MIRA (McDonald
et al., 2005a; McDonald and Pereira, 2006) and for
transition-based parsing Support-Vector Machines
(Hall et al., 2006; Nivre et al., 2006b).
Dredze et al. (2008) introduce a new approach
to margin-based online learning called confidence-
weighted classification (CW) and show that the
performance of this approach is comparable to
that of Support-Vector Machines. In this work
we use confidence-weighted classification with
transition-based parsing and show that this leads
to results comparable to the state-of-the-art results
obtained using SVMs.
We also compare training time and the effect
of pruning when using confidence-weighted learn-
ing.
</bodyText>
<sectionHeader confidence="0.98368" genericHeader="method">
2 Transition-based parsing
</sectionHeader>
<bodyText confidence="0.6975552">
Transition-based parsing builds on the idea that
parsing can be viewed as a sequence of transitions
between states. A transition-based parser (deter-
ministic classifier-based parser) consists of three
essential components (Nivre, 2008):
</bodyText>
<listItem confidence="0.991772333333333">
1. A parsing algorithm
2. A feature model
3. A classifier
</listItem>
<bodyText confidence="0.995633">
The focus here is on the classifier but we will
briefly describe the parsing algorithm in order to
understand the classification task better.
The parsing algorithm consists of two com-
ponents, a transition system and an oracle.
Nivre (2008) defines a transition system S =
(C, T, cs, Ct) in the following way:
</bodyText>
<listItem confidence="0.947074222222222">
1. C is a set of configurations, each of which
contains a buffer β of (remaining) nodes and
a set A of dependency arcs,
2. T is a set of transitions, each of which is a
partial function t : C → C,
3. cs is a initialization function mapping a sen-
tence x = (w0, w1, ... , wn) to a configura-
tion with β = [1, ... , n],
4. Ct is a set of terminal configurations.
</listItem>
<bodyText confidence="0.766141333333333">
A transition sequence for a sentence x in S is a se-
quence C0,m = (c0, c1 ..., cm) of configurations,
such that
</bodyText>
<listItem confidence="0.95933025">
1. c0 = cs(x),
2. cm E Ct,
3. for every i (1 G i G m)ci = t(ci−1) for some
t E T
</listItem>
<bodyText confidence="0.99944075">
The oracle is used during training to determine a
transition sequence that leads to the correct parse.
The job of the classifier is to ’imitate’ the ora-
cle, i.e. to try to always pick the transitions that
</bodyText>
<page confidence="0.986015">
55
</page>
<note confidence="0.6023395">
Proceedings of the ACL 2010 Student Research Workshop, pages 55–60,
Uppsala, Sweden, 13 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.995215">
lead to the correct parse. The information given to
the classifier is the current configuration. There-
fore the training data for the classifier consists of
a number of configurations and the transitions the
oracle chose with these configurations.
Here we focus on stack-based parsing algo-
rithms. A stack-based configuration for a sentence
x = (w0, wi, ... , wn) is a triple c = (σ, β, A),
where
</bodyText>
<listItem confidence="0.9550008">
1. σ is a stack of tokens i &lt; k (for some k &lt; n),
2. β is a buffer of tokens j &gt; k ,
3. A is a set of dependency arcs such that G =
(0, 1, ... , n, A) is a dependency graph for x.
(Nivre, 2008)
</listItem>
<bodyText confidence="0.9734095">
In the work presented here we use the NivreEager
algorithm which has four transitions:
Shift Push the token at the head of the buffer
onto the stack.
Reduce Pop the token on the top of the stack.
Left-Arcl Add to the analysis an arc with label l
from the token at the head of the buffer to the token
on the top of the stack, and push the buffer-token
onto the stack.
Right-Arcl Add to the analysis an arc with label
l from the token on the top of the stack to the token
at the head of the buffer, and pop the stack.
</bodyText>
<subsectionHeader confidence="0.962489">
2.1 Classification
</subsectionHeader>
<bodyText confidence="0.999934444444445">
Transition-based dependency parsing reduces
parsing to consecutive multiclass classification.
From each configuration one amongst some prede-
fined number of transitions has to be chosen. This
means that any classifier can be plugged into the
system. The training instances are created by the
oracle so the training is offline. So even though
we use online learners in the experiments these are
used in a batch setting.
The best results have been achieved using
Support-Vector Machines placing the MaltParser
very high in both the CoNNL shared tasks on de-
pendency parsing in 2006 and 2007 (Buchholz
and Marsi, 2006; Nivre et al., 2007) and it has
been shown that SVMs are better for the task than
Memory-based learning (Hall et al., 2006). The
standard setting in the MaltParser is to use a 2nd-
degree polynomial kernel with the SVM.
</bodyText>
<sectionHeader confidence="0.99671" genericHeader="method">
3 Confidence-weighted classification
</sectionHeader>
<bodyText confidence="0.999940897435897">
Dredze et al. (2008) introduce confidence-
weighted linear classifiers which are online-
classifiers that maintain a confidence parameter
for each weight and uses this to control how to
change the weights in each update. A problem
with online algorithms is that because they have
no memory of previously seen examples they do
not know if a given weight has been updated many
times or few times. If a weight has been updated
many times the current estimation of the weight is
probably relatively good and therefore should not
be changed too much. On the other hand if it has
never been updated before the estimation is prob-
ably very bad. CW classification deals with this
by having a confidence-parameter for each weight,
modeled by a Gaussian distribution, and this pa-
rameter is used to make more aggressive updates
on weights with lower confidence (Dredze et al.,
2008). The classifiers also use Passive-Aggressive
updates (Crammer et al., 2006) to try to maximize
the margin between positive and negative training
instances.
CW classifiers are online-algorithms and are
therefore fast to train, and it is not necessary to
keep all training examples in memory. Despite this
they perform as well or better than SVMs (Dredze
et al., 2008). Crammer et al. (2009) extend the ap-
proach to multiclass classification and show that
also in this setting the classifiers often outperform
SVMs. They show that updating only the weights
of the best of the wrongly classified classes yields
the best results. We also use this approach, called
top-1, here.
Crammer et al. (2008) present different update-
rules for CW classification and show that the ones
based on standard deviation rather than variance
yield the best results. Our experiments have con-
firmed this, so in all experiments the update-rule
from equation 10 (Crammer et al., 2008) is used.
</bodyText>
<sectionHeader confidence="0.999328" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.974082">
4.1 Software
</subsectionHeader>
<bodyText confidence="0.999894">
We use the open-source parser MaltParser1 for
all experiments. We have integrated confidence-
weighted, perceptron and MIRA classifiers into
the code. The code for the online classifiers has
</bodyText>
<footnote confidence="0.9725345">
1We have used version 1.3.1, available at maltparser.
org
</footnote>
<page confidence="0.986184">
56
</page>
<bodyText confidence="0.727266333333333">
LAS
been made available by the authors of the CW-
papers.
</bodyText>
<subsectionHeader confidence="0.980784">
4.2 Data
</subsectionHeader>
<bodyText confidence="0.9998548">
We have used the 10 smallest data sets from
CoNNL-X (Buchholz and Marsi, 2006) in our ex-
periments. Evaluation has been done with the offi-
cial evaluation script and evaluation data from this
task.
</bodyText>
<subsectionHeader confidence="0.983977">
4.3 Features
</subsectionHeader>
<bodyText confidence="0.99836125">
The standard setting for the MaltParser is to use
SVMs with polynomial kernels, and because of
this it uses a relatively small number of features.
In most of our experiments the default feature set
of MaltParser consisting of 14 features has been
used.
When using a linear-classifier without a ker-
nel we need to extend the feature set in order to
achieve good results. We have done this very un-
critically by adding all pair wise combinations of
all features. This leads to 91 additional features
when using the standard 14 features.
</bodyText>
<sectionHeader confidence="0.99917" genericHeader="method">
5 Results and discussion
</sectionHeader>
<bodyText confidence="0.999924666666667">
We will now discuss various results of our ex-
periments with using CW-classifiers in transition-
based parsing.
</bodyText>
<subsectionHeader confidence="0.918851">
5.1 Online classifiers
</subsectionHeader>
<bodyText confidence="0.999994769230769">
We compare CW-classifiers with other online al-
gorithms for linear classification. We compare
with perceptron (Rosenblatt, 1958) and MIRA
(Crammer et al., 2006). With both these classi-
fiers we use the same top-1 approach as with the
CW-classifers and also averaging which has been
shown to alleviate overfitting (Collins, 2002). Ta-
ble 2 shows Labeled Attachment Score obtained
with the three online classifiers. All classifiers
were trained with 10 iterations.
These results confirm those by Crammer et al.
(2009) and show that confidence-weighted classi-
fiers are better than both perceptron and MIRA.
</bodyText>
<subsectionHeader confidence="0.996522">
5.2 Training and parsing time
</subsectionHeader>
<bodyText confidence="0.9999885">
The training time of the CW-classifiers depends on
the number of iterations used, and this of course
affects the accuracy of the parser. Figure 1 shows
Labeled Attachment Score as a function of the
number of iterations used in training. The hori-
zontal line shows the LAS obtained with SVM.
</bodyText>
<subsubsectionHeader confidence="0.407947">
Iterations
</subsubsectionHeader>
<figureCaption confidence="0.98727">
Figure 1: LAS as a function of number of training
iterations on Danish data. The dotted horizontal
line shows the performance of the parser trained
with SVM.
</figureCaption>
<bodyText confidence="0.9993966">
We see that after 4 iterations the CW-classifier
has the best performance for the data set (Danish)
used in this experiment. In most experiments we
have used 10 iterations. Table 1 compares training
time (10 iterations) and parsing time of a parser
using a CW-classifiers and a parser using SVM on
the same data set. We see that training of the CW-
classifier is faster, which is to be expected given
their online-nature. We also see that parsing is
much faster.
</bodyText>
<table confidence="0.995514666666667">
SVM CW
Training 75 min 8 min
Parsing 29 min 1.5 min
</table>
<tableCaption confidence="0.999882">
Table 1: Training and parsing time on Danish data.
</tableCaption>
<subsectionHeader confidence="0.997712">
5.3 Pruning features
</subsectionHeader>
<bodyText confidence="0.99818">
Because we explicitly represent pair wise combi-
nations of all of the original features we get an ex-
tremely high number of binary features. For some
of the larger data sets, the number of features is
so big that we cannot hold the weight-vector in
memory. For instance the Czech data-set has 16
million binary features, and almost 800 classes -
which means that in practice there are 12 billion
binary features2.
</bodyText>
<footnote confidence="0.9928975">
2Which is also why we only have used the 10 smallest
data sets from CoNNL-X.
</footnote>
<figure confidence="0.585885">
2 4 6 8 10
79.0 79.5 80.0 80.5 81.0
</figure>
<page confidence="0.971262">
57
</page>
<table confidence="0.99981175">
Perceptron MIRA CW, manual fs CW SVM
Arabic 58.03 59.19 60.55 †60.57 59.93
Bulgarian 80.46 81.09 82.57 †82.76 82.12
Danish 79.42 79.90 81.06 †81.13 80.18
Dutch 75.75 77.47 77.65 †78.65 77.76
Japanese 87.74 88.06 88.14 88.19 †89.47
Portuguese 85.69 85.95 86.11 86.20 86.25
Slovene 64.35 65.38 66.09 †66.28 65.45
Spanish 74.06 74.86 75.58 75.90 75.46
Swedish 79.79 80.31 81.03 †81.24 80.56
Turkish 46.48 47.13 46.98 47.09 47.49
All 78.26 79.00 79.68 †79.86 79.59
</table>
<tableCaption confidence="0.993649">
Table 2: LAS on development data for three online classifers, CW-classifiers with manual feature se-
</tableCaption>
<bodyText confidence="0.936509083333333">
lection and SVM. Statistical significance is measuered between CW-classifiers without feature selection
and SVMs.
To solve this problem we have tried to use prun-
ing to remove the features occurring fewest times
in the training data. If a feature occurs fewer times
than a given cutoff limit the feature is not included.
This goes against the idea of CW classifiers which
are exactly developed so that rare features can be
used. Experiments also show that this pruning
hurts accuracy. Figure 2 shows the labeled attach-
ment score as a function of the cutoff limit on the
Danish data.
</bodyText>
<subsectionHeader confidence="0.996828">
5.4 Manual feature selection
</subsectionHeader>
<bodyText confidence="0.9883775">
Instead of pruning the features we tried manually
removing some of the pair wise feature combina-
tions. We removed some of the combinations that
lead to the most extra features, which is especially
the case with combinations of lexical features. In
the extended default feature set for instance we re-
moved all combinations of lexical features except
the combination of the word form of the token at
the top of the stack and of the word form of the
token at the head of the buffer.
Table 2 shows that this consistently leads to a
small decreases in LAS.
</bodyText>
<figure confidence="0.897031888888889">
0 2 4 6 8 10
LAS
81.0
80.5
80.0
79.5
Cutoff limit
5.5 Results without optimization
1500000
</figure>
<bodyText confidence="0.9996852">
Table 2 shows the results for the 10 CoNNL-X
data sets used. For comparison we have included
the results from using the standard classifier in the
1000000 MaltParser, i.e. SVM with a polynomial kernel.
The hyper-parameters for the SVM have not been
optimized, and neither has the number of iterations
for the CW-classifiers, which is always 10. We see
500000 that in many cases the CW-classifier does signifi-
cantly 3 better than the SVM, but that the opposite
is also the case.
</bodyText>
<subsectionHeader confidence="0.984416">
5.6 Results with optimization
</subsectionHeader>
<bodyText confidence="0.999883333333333">
The results presented above are suboptimal for the
SVMs because default parameters have been used
for these, and optimizing these can improve ac-
</bodyText>
<footnote confidence="0.96895875">
3In all tables statistical significance is marked with †. Sig-
nificance is calculated using McNemar’s test (p = 0.05).
These tests were made with MaltEval (Nilsson and Nivre,
2008)
</footnote>
<figureCaption confidence="0.972434">
Figure 2: LAS as a function of the cutoff limit
</figureCaption>
<bodyText confidence="0.864257">
when pruning rare features. The dotted line shows
the number of features left after pruning.
</bodyText>
<page confidence="0.994435">
58
</page>
<table confidence="0.998807">
SVM CW
LAS UAS LA LAS UAS LA
Arabic 66.71 77.52 80.34 67.03 77.52 †81.20
Bulgarian* 87.41 91.72 90.44 87.25 91.56 89.77
Danish †84.77 †89.80 89.16 84.15 88.98 88.74
Dutch* †78.59 †81.35 †83.69 77.21 80.21 82.63
Japanese †91.65 †93.10 †94.34 90.41 91.96 93.34
Portuguese* †87.60 †91.22 †91.54 86.66 90.58 90.34
Slovene 70.30 78.72 80.54 69.84 †79.62 79.42
Spanish 81.29 84.67 90.06 82.09 †85.55 90.52
Swedish* †84.58 89.50 87.39 83.69 89.11 87.01
Turkish †65.68 †75.82 †78.49 62.00 73.15 76.12
All †79.86 †85.35 †86.60 79.04 84.83 85.91
</table>
<tableCaption confidence="0.929712">
Table 3: Results on the CoNNL-X evaluation data. Manuel feature selection has been used for languages
marked with an *.
</tableCaption>
<bodyText confidence="0.999784363636364">
curacy a lot. In this section we will compare re-
sults obtained with CW-classifiers with the results
for the MaltParser from CoNNL-X. In CoNNL-X
both the hyper parameters for the SVMs and the
features have been optimized. Here we do not do
feature selection but use the features used by the
MaltParser in CoNNL-X4.
The only hyper parameter for CW classification
is the number of iterations. We optimize this by
doing 5-fold cross-validation on the training data.
Although the manual feature selection has been
shown to decrease accuracy this has been used for
some languages to reduce the size of the model.
The results are presented in table 3.
We see that even though the feature set used
are optimized for the SVMs there are not big dif-
ferences between the parses that use SVMs and
the parsers that use CW classification. In general
though the parsers with SVMs does better than
the parsers with CW classifiers and the difference
seems to be biggest on the languages where we did
manual feature selection.
</bodyText>
<sectionHeader confidence="0.995661" genericHeader="method">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.998765">
We have shown that using confidence-weighted
classifiers with transition-based dependency pars-
ing yields results comparable with the state-of-the-
art results achieved with Support Vector Machines
- with faster training and parsing times. Currently
we need a very high number of features to achieve
these results, and we have shown that pruning this
big feature set uncritically hurts performance of
</bodyText>
<footnote confidence="0.9960055">
4Available at http://maltparser.org/conll/
conllx/
</footnote>
<bodyText confidence="0.399211">
the confidence-weighted classifiers.
</bodyText>
<sectionHeader confidence="0.991135" genericHeader="method">
7 Future work
</sectionHeader>
<bodyText confidence="0.999872655172414">
Currently the biggest challenge in the approach
outlined here is the very high number of features
needed to achieve good results. A possible so-
lution is to use kernels with confidence-weighted
classification in the same way they are used with
the SVMs.
Another possibility is to extend the feature set
in a more critical way than what is done now. For
instance the combination of a POS-tag and CPOS-
tag for a given word is now included. This feature
does not convey any information that the POS-tag-
feature itself does not. The same is the case for
some word-form and word-lemma features. All in
all a lot of non-informative features are added as
things are now. We have not yet tried to use auto-
matic features selection to select only the combi-
nations that increase accuracy.
We will also try to do feature selection on a
more general level as this can boost accuracy a lot.
The results in table 3 are obtained with the features
optimized for the SVMs. These are not necessarily
the optimal features for the CW-classifiers.
Another comparison we would like to do is with
linear SVMs. Unlike the polynomial kernel SVMs
used as default in the MaltParser linear SVMs can
be trained in linear time (Joachims, 2006). Trying
to use the same extended feature set we use with
the CW-classifiers with a linear SVM would pro-
vide an interesting comparison.
</bodyText>
<page confidence="0.998524">
59
</page>
<sectionHeader confidence="0.997156" genericHeader="conclusions">
8 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999957">
The author thanks three anonymous reviewers and
Anders Søgaard for their helpful comments and
the authors of the CW-papers for making their
code available.
</bodyText>
<sectionHeader confidence="0.998305" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998868953488372">
Sabine Buchholz and Erwin Marsi. 2006. Conll-
x shared task on multilingual dependency parsing.
In Proceedings of the Tenth Conference on Com-
putational Natural Language Learning (CoNLL-X),
pages 149–164, New York City, June. Association
for Computational Linguistics.
Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: theory and experi-
ments with perceptron algorithms. In EMNLP ’02:
Proceedings of the ACL-02 conference on Empiri-
cal methods in natural language processing, pages
1–8, Morristown, NJ, USA. Association for Compu-
tational Linguistics.
Koby Crammer, Ofer Dekel, Joseph Keshet, Shai
Shalev-Shwartz, and Yoram Singer. 2006. On-
line passive-aggressive algorithms. J. Mach. Learn.
Res., 7:551–585.
Koby Crammer, Mark Dredze, and Fernando Pereira.
2008. Exact convex confidence-weighted learning.
In Daphne Koller, Dale Schuurmans, Yoshua Ben-
gio, and L´eon Bottou, editors, NIPS, pages 345–352.
MIT Press.
Koby Crammer, Mark Dredze, and Alex Kulesza.
2009. Multi-class confidence weighted algorithms.
In Proceedings of the 2009 Conference on Empiri-
cal Methods in Natural Language Processing, pages
496–504, Singapore, August. Association for Com-
putational Linguistics.
Mark Dredze, Koby Crammer, and Fernando Pereira.
2008. Confidence-weighted linear classification. In
ICML ’08: Proceedings of the 25th international
conference on Machine learning, pages 264–271,
New York, NY, USA. ACM.
Johan Hall, Joakim Nivre, and Jens Nilsson. 2006.
Discriminative classifiers for deterministic depen-
dency parsing. In Proceedings of the COLING/ACL
2006 Main Conference Poster Sessions, pages 316–
323, Sydney, Australia, July. Association for Com-
putational Linguistics.
Thorsten Joachims. 2006. Training linear svms in
linear time. In KDD ’06: Proceedings of the 12th
ACM SIGKDD international conference on Knowl-
edge discovery and data mining, pages 217–226,
New York, NY, USA. ACM.
Ryan T. McDonald and Fernando C. N. Pereira. 2006.
Online learning of approximate dependency parsing
algorithms. In EACL. The Association for Computer
Linguistics.
Ryan T. McDonald, Koby Crammer, and Fernando
C. N. Pereira. 2005a. Online large-margin train-
ing of dependency parsers. In ACL. The Association
for Computer Linguistics.
Ryan T. McDonald, Fernando Pereira, Kiril Ribarov,
and Jan Hajic. 2005b. Non-projective depen-
dency parsing using spanning tree algorithms. In
HLT/EMNLP. The Association for Computational
Linguistics.
Jens Nilsson and Joakim Nivre. 2008. Malteval:
An evaluation and visualization tool for dependency
parsing. In Proceedings of the Sixth International
Language Resources and Evaluation, Marrakech,
Morocco, May. LREC.
Joakim Nivre, Johan Hall, and Jens Nilsson. 2006a.
Maltparser: A data-driven parser-generator for de-
pendency parsing. In Proceedings of the fifth in-
ternational conference on Language Resources and
Evaluation (LREC2006), pages 2216–2219, May.
Joakim Nivre, Johan Hall, Jens Nilsson, G¨uls¸en
Eryiˇgit, and Svetoslav Marinov. 2006b. Labeled
pseudo-projective dependency parsing with support
vector machines. In Proceedings of the Tenth Con-
ference on Computational Natural Language Learn-
ing (CoNLL-X), pages 221–225, New York City,
June. Association for Computational Linguistics.
Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan Mc-
Donald, Jens Nilsson, Sebastian Riedel, and Deniz
Yuret. 2007. The CoNLL 2007 shared task on de-
pendency parsing. In Proceedings of the CoNLL
Shared Task Session of EMNLP-CoNLL 2007, pages
915–932.
Joakim Nivre. 2008. Algorithms for deterministic in-
cremental dependency parsing. Computational Lin-
guistics, 34(4):513–553.
Frank Rosenblatt. 1958. The perceptron: A probabilis-
tic model for information storage and organization in
the brain. Psychological Review, 65(6):386–408.
</reference>
<page confidence="0.998341">
60
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.700289">
<title confidence="0.998786">Transition-based parsing with Confidence-Weighted Classification</title>
<author confidence="0.999929">Martin Haulrich</author>
<affiliation confidence="0.9633835">Dept. of International Language Studies and Computational Linguistics Copenhagen Business School</affiliation>
<email confidence="0.97738">mwh.isv@cbs.dk</email>
<abstract confidence="0.974827333333333">We show that using confidence-weighted classification in transition-based parsing gives results comparable to using SVMs with faster training and parsing time. We also compare with other online learning algorithms and investigate the effect of pruning features when using confidenceweighted classification.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>Conllx shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLL-X),</booktitle>
<pages>149--164</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>New York City,</location>
<contexts>
<context position="4863" citStr="Buchholz and Marsi, 2006" startWordPosition="822" endWordPosition="825">ssification Transition-based dependency parsing reduces parsing to consecutive multiclass classification. From each configuration one amongst some predefined number of transitions has to be chosen. This means that any classifier can be plugged into the system. The training instances are created by the oracle so the training is offline. So even though we use online learners in the experiments these are used in a batch setting. The best results have been achieved using Support-Vector Machines placing the MaltParser very high in both the CoNNL shared tasks on dependency parsing in 2006 and 2007 (Buchholz and Marsi, 2006; Nivre et al., 2007) and it has been shown that SVMs are better for the task than Memory-based learning (Hall et al., 2006). The standard setting in the MaltParser is to use a 2nddegree polynomial kernel with the SVM. 3 Confidence-weighted classification Dredze et al. (2008) introduce confidenceweighted linear classifiers which are onlineclassifiers that maintain a confidence parameter for each weight and uses this to control how to change the weights in each update. A problem with online algorithms is that because they have no memory of previously seen examples they do not know if a given we</context>
<context position="7372" citStr="Buchholz and Marsi, 2006" startWordPosition="1237" endWordPosition="1240">he ones based on standard deviation rather than variance yield the best results. Our experiments have confirmed this, so in all experiments the update-rule from equation 10 (Crammer et al., 2008) is used. 4 Experiments 4.1 Software We use the open-source parser MaltParser1 for all experiments. We have integrated confidenceweighted, perceptron and MIRA classifiers into the code. The code for the online classifiers has 1We have used version 1.3.1, available at maltparser. org 56 LAS been made available by the authors of the CWpapers. 4.2 Data We have used the 10 smallest data sets from CoNNL-X (Buchholz and Marsi, 2006) in our experiments. Evaluation has been done with the official evaluation script and evaluation data from this task. 4.3 Features The standard setting for the MaltParser is to use SVMs with polynomial kernels, and because of this it uses a relatively small number of features. In most of our experiments the default feature set of MaltParser consisting of 14 features has been used. When using a linear-classifier without a kernel we need to extend the feature set in order to achieve good results. We have done this very uncritically by adding all pair wise combinations of all features. This leads</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Sabine Buchholz and Erwin Marsi. 2006. Conllx shared task on multilingual dependency parsing. In Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLL-X), pages 149–164, New York City, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training methods for hidden markov models: theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In EMNLP ’02: Proceedings of the ACL-02 conference on Empirical methods in natural language processing,</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="8519" citStr="Collins, 2002" startWordPosition="1427" endWordPosition="1428">ly by adding all pair wise combinations of all features. This leads to 91 additional features when using the standard 14 features. 5 Results and discussion We will now discuss various results of our experiments with using CW-classifiers in transitionbased parsing. 5.1 Online classifiers We compare CW-classifiers with other online algorithms for linear classification. We compare with perceptron (Rosenblatt, 1958) and MIRA (Crammer et al., 2006). With both these classifiers we use the same top-1 approach as with the CW-classifers and also averaging which has been shown to alleviate overfitting (Collins, 2002). Table 2 shows Labeled Attachment Score obtained with the three online classifiers. All classifiers were trained with 10 iterations. These results confirm those by Crammer et al. (2009) and show that confidence-weighted classifiers are better than both perceptron and MIRA. 5.2 Training and parsing time The training time of the CW-classifiers depends on the number of iterations used, and this of course affects the accuracy of the parser. Figure 1 shows Labeled Attachment Score as a function of the number of iterations used in training. The horizontal line shows the LAS obtained with SVM. Itera</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative training methods for hidden markov models: theory and experiments with perceptron algorithms. In EMNLP ’02: Proceedings of the ACL-02 conference on Empirical methods in natural language processing, pages 1–8, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Ofer Dekel</author>
<author>Joseph Keshet</author>
<author>Shai Shalev-Shwartz</author>
<author>Yoram Singer</author>
</authors>
<title>Online passive-aggressive algorithms.</title>
<date>2006</date>
<journal>J. Mach. Learn. Res.,</journal>
<pages>7--551</pages>
<contexts>
<context position="6061" citStr="Crammer et al., 2006" startWordPosition="1022" endWordPosition="1025"> not know if a given weight has been updated many times or few times. If a weight has been updated many times the current estimation of the weight is probably relatively good and therefore should not be changed too much. On the other hand if it has never been updated before the estimation is probably very bad. CW classification deals with this by having a confidence-parameter for each weight, modeled by a Gaussian distribution, and this parameter is used to make more aggressive updates on weights with lower confidence (Dredze et al., 2008). The classifiers also use Passive-Aggressive updates (Crammer et al., 2006) to try to maximize the margin between positive and negative training instances. CW classifiers are online-algorithms and are therefore fast to train, and it is not necessary to keep all training examples in memory. Despite this they perform as well or better than SVMs (Dredze et al., 2008). Crammer et al. (2009) extend the approach to multiclass classification and show that also in this setting the classifiers often outperform SVMs. They show that updating only the weights of the best of the wrongly classified classes yields the best results. We also use this approach, called top-1, here. Cra</context>
<context position="8352" citStr="Crammer et al., 2006" startWordPosition="1398" endWordPosition="1401"> features has been used. When using a linear-classifier without a kernel we need to extend the feature set in order to achieve good results. We have done this very uncritically by adding all pair wise combinations of all features. This leads to 91 additional features when using the standard 14 features. 5 Results and discussion We will now discuss various results of our experiments with using CW-classifiers in transitionbased parsing. 5.1 Online classifiers We compare CW-classifiers with other online algorithms for linear classification. We compare with perceptron (Rosenblatt, 1958) and MIRA (Crammer et al., 2006). With both these classifiers we use the same top-1 approach as with the CW-classifers and also averaging which has been shown to alleviate overfitting (Collins, 2002). Table 2 shows Labeled Attachment Score obtained with the three online classifiers. All classifiers were trained with 10 iterations. These results confirm those by Crammer et al. (2009) and show that confidence-weighted classifiers are better than both perceptron and MIRA. 5.2 Training and parsing time The training time of the CW-classifiers depends on the number of iterations used, and this of course affects the accuracy of the</context>
</contexts>
<marker>Crammer, Dekel, Keshet, Shalev-Shwartz, Singer, 2006</marker>
<rawString>Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-Shwartz, and Yoram Singer. 2006. Online passive-aggressive algorithms. J. Mach. Learn. Res., 7:551–585.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Mark Dredze</author>
<author>Fernando Pereira</author>
</authors>
<title>Exact convex confidence-weighted learning.</title>
<date>2008</date>
<pages>345--352</pages>
<editor>In Daphne Koller, Dale Schuurmans, Yoshua Bengio, and L´eon Bottou, editors, NIPS,</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="6679" citStr="Crammer et al. (2008)" startWordPosition="1124" endWordPosition="1127">06) to try to maximize the margin between positive and negative training instances. CW classifiers are online-algorithms and are therefore fast to train, and it is not necessary to keep all training examples in memory. Despite this they perform as well or better than SVMs (Dredze et al., 2008). Crammer et al. (2009) extend the approach to multiclass classification and show that also in this setting the classifiers often outperform SVMs. They show that updating only the weights of the best of the wrongly classified classes yields the best results. We also use this approach, called top-1, here. Crammer et al. (2008) present different updaterules for CW classification and show that the ones based on standard deviation rather than variance yield the best results. Our experiments have confirmed this, so in all experiments the update-rule from equation 10 (Crammer et al., 2008) is used. 4 Experiments 4.1 Software We use the open-source parser MaltParser1 for all experiments. We have integrated confidenceweighted, perceptron and MIRA classifiers into the code. The code for the online classifiers has 1We have used version 1.3.1, available at maltparser. org 56 LAS been made available by the authors of the CWpa</context>
</contexts>
<marker>Crammer, Dredze, Pereira, 2008</marker>
<rawString>Koby Crammer, Mark Dredze, and Fernando Pereira. 2008. Exact convex confidence-weighted learning. In Daphne Koller, Dale Schuurmans, Yoshua Bengio, and L´eon Bottou, editors, NIPS, pages 345–352. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Mark Dredze</author>
<author>Alex Kulesza</author>
</authors>
<title>Multi-class confidence weighted algorithms.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>496--504</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6375" citStr="Crammer et al. (2009)" startWordPosition="1074" endWordPosition="1077"> classification deals with this by having a confidence-parameter for each weight, modeled by a Gaussian distribution, and this parameter is used to make more aggressive updates on weights with lower confidence (Dredze et al., 2008). The classifiers also use Passive-Aggressive updates (Crammer et al., 2006) to try to maximize the margin between positive and negative training instances. CW classifiers are online-algorithms and are therefore fast to train, and it is not necessary to keep all training examples in memory. Despite this they perform as well or better than SVMs (Dredze et al., 2008). Crammer et al. (2009) extend the approach to multiclass classification and show that also in this setting the classifiers often outperform SVMs. They show that updating only the weights of the best of the wrongly classified classes yields the best results. We also use this approach, called top-1, here. Crammer et al. (2008) present different updaterules for CW classification and show that the ones based on standard deviation rather than variance yield the best results. Our experiments have confirmed this, so in all experiments the update-rule from equation 10 (Crammer et al., 2008) is used. 4 Experiments 4.1 Softw</context>
<context position="8705" citStr="Crammer et al. (2009)" startWordPosition="1454" endWordPosition="1457">ious results of our experiments with using CW-classifiers in transitionbased parsing. 5.1 Online classifiers We compare CW-classifiers with other online algorithms for linear classification. We compare with perceptron (Rosenblatt, 1958) and MIRA (Crammer et al., 2006). With both these classifiers we use the same top-1 approach as with the CW-classifers and also averaging which has been shown to alleviate overfitting (Collins, 2002). Table 2 shows Labeled Attachment Score obtained with the three online classifiers. All classifiers were trained with 10 iterations. These results confirm those by Crammer et al. (2009) and show that confidence-weighted classifiers are better than both perceptron and MIRA. 5.2 Training and parsing time The training time of the CW-classifiers depends on the number of iterations used, and this of course affects the accuracy of the parser. Figure 1 shows Labeled Attachment Score as a function of the number of iterations used in training. The horizontal line shows the LAS obtained with SVM. Iterations Figure 1: LAS as a function of number of training iterations on Danish data. The dotted horizontal line shows the performance of the parser trained with SVM. We see that after 4 it</context>
</contexts>
<marker>Crammer, Dredze, Kulesza, 2009</marker>
<rawString>Koby Crammer, Mark Dredze, and Alex Kulesza. 2009. Multi-class confidence weighted algorithms. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 496–504, Singapore, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Dredze</author>
<author>Koby Crammer</author>
<author>Fernando Pereira</author>
</authors>
<title>Confidence-weighted linear classification.</title>
<date>2008</date>
<booktitle>In ICML ’08: Proceedings of the 25th international conference on Machine learning,</booktitle>
<pages>264--271</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1107" citStr="Dredze et al. (2008)" startWordPosition="148" endWordPosition="151">ghted classification. 1 Introduction There has been a lot of work on data-driven dependency parsing. The two dominating approaches have been graph-based parsing, e.g. MST-parsing (McDonald et al., 2005b) and transition-based parsing, e.g. the MaltParser (Nivre et al., 2006a). These two approaches differ radically but have in common that the best results have been obtained using margin-based machine learning approaches. For the MST-parsing MIRA (McDonald et al., 2005a; McDonald and Pereira, 2006) and for transition-based parsing Support-Vector Machines (Hall et al., 2006; Nivre et al., 2006b). Dredze et al. (2008) introduce a new approach to margin-based online learning called confidenceweighted classification (CW) and show that the performance of this approach is comparable to that of Support-Vector Machines. In this work we use confidence-weighted classification with transition-based parsing and show that this leads to results comparable to the state-of-the-art results obtained using SVMs. We also compare training time and the effect of pruning when using confidence-weighted learning. 2 Transition-based parsing Transition-based parsing builds on the idea that parsing can be viewed as a sequence of tr</context>
<context position="5139" citStr="Dredze et al. (2008)" startWordPosition="869" endWordPosition="872">ces are created by the oracle so the training is offline. So even though we use online learners in the experiments these are used in a batch setting. The best results have been achieved using Support-Vector Machines placing the MaltParser very high in both the CoNNL shared tasks on dependency parsing in 2006 and 2007 (Buchholz and Marsi, 2006; Nivre et al., 2007) and it has been shown that SVMs are better for the task than Memory-based learning (Hall et al., 2006). The standard setting in the MaltParser is to use a 2nddegree polynomial kernel with the SVM. 3 Confidence-weighted classification Dredze et al. (2008) introduce confidenceweighted linear classifiers which are onlineclassifiers that maintain a confidence parameter for each weight and uses this to control how to change the weights in each update. A problem with online algorithms is that because they have no memory of previously seen examples they do not know if a given weight has been updated many times or few times. If a weight has been updated many times the current estimation of the weight is probably relatively good and therefore should not be changed too much. On the other hand if it has never been updated before the estimation is probab</context>
</contexts>
<marker>Dredze, Crammer, Pereira, 2008</marker>
<rawString>Mark Dredze, Koby Crammer, and Fernando Pereira. 2008. Confidence-weighted linear classification. In ICML ’08: Proceedings of the 25th international conference on Machine learning, pages 264–271, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Hall</author>
<author>Joakim Nivre</author>
<author>Jens Nilsson</author>
</authors>
<title>Discriminative classifiers for deterministic dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions,</booktitle>
<pages>316--323</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="1063" citStr="Hall et al., 2006" startWordPosition="140" endWordPosition="143">pruning features when using confidenceweighted classification. 1 Introduction There has been a lot of work on data-driven dependency parsing. The two dominating approaches have been graph-based parsing, e.g. MST-parsing (McDonald et al., 2005b) and transition-based parsing, e.g. the MaltParser (Nivre et al., 2006a). These two approaches differ radically but have in common that the best results have been obtained using margin-based machine learning approaches. For the MST-parsing MIRA (McDonald et al., 2005a; McDonald and Pereira, 2006) and for transition-based parsing Support-Vector Machines (Hall et al., 2006; Nivre et al., 2006b). Dredze et al. (2008) introduce a new approach to margin-based online learning called confidenceweighted classification (CW) and show that the performance of this approach is comparable to that of Support-Vector Machines. In this work we use confidence-weighted classification with transition-based parsing and show that this leads to results comparable to the state-of-the-art results obtained using SVMs. We also compare training time and the effect of pruning when using confidence-weighted learning. 2 Transition-based parsing Transition-based parsing builds on the idea th</context>
<context position="4987" citStr="Hall et al., 2006" startWordPosition="845" endWordPosition="848">one amongst some predefined number of transitions has to be chosen. This means that any classifier can be plugged into the system. The training instances are created by the oracle so the training is offline. So even though we use online learners in the experiments these are used in a batch setting. The best results have been achieved using Support-Vector Machines placing the MaltParser very high in both the CoNNL shared tasks on dependency parsing in 2006 and 2007 (Buchholz and Marsi, 2006; Nivre et al., 2007) and it has been shown that SVMs are better for the task than Memory-based learning (Hall et al., 2006). The standard setting in the MaltParser is to use a 2nddegree polynomial kernel with the SVM. 3 Confidence-weighted classification Dredze et al. (2008) introduce confidenceweighted linear classifiers which are onlineclassifiers that maintain a confidence parameter for each weight and uses this to control how to change the weights in each update. A problem with online algorithms is that because they have no memory of previously seen examples they do not know if a given weight has been updated many times or few times. If a weight has been updated many times the current estimation of the weight </context>
</contexts>
<marker>Hall, Nivre, Nilsson, 2006</marker>
<rawString>Johan Hall, Joakim Nivre, and Jens Nilsson. 2006. Discriminative classifiers for deterministic dependency parsing. In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 316– 323, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Training linear svms in linear time.</title>
<date>2006</date>
<booktitle>In KDD ’06: Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>217--226</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<marker>Joachims, 2006</marker>
<rawString>Thorsten Joachims. 2006. Training linear svms in linear time. In KDD ’06: Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 217–226, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan T McDonald</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Online learning of approximate dependency parsing algorithms.</title>
<date>2006</date>
<booktitle>In EACL. The Association</booktitle>
<institution>for Computer Linguistics.</institution>
<contexts>
<context position="987" citStr="McDonald and Pereira, 2006" startWordPosition="130" endWordPosition="133">. We also compare with other online learning algorithms and investigate the effect of pruning features when using confidenceweighted classification. 1 Introduction There has been a lot of work on data-driven dependency parsing. The two dominating approaches have been graph-based parsing, e.g. MST-parsing (McDonald et al., 2005b) and transition-based parsing, e.g. the MaltParser (Nivre et al., 2006a). These two approaches differ radically but have in common that the best results have been obtained using margin-based machine learning approaches. For the MST-parsing MIRA (McDonald et al., 2005a; McDonald and Pereira, 2006) and for transition-based parsing Support-Vector Machines (Hall et al., 2006; Nivre et al., 2006b). Dredze et al. (2008) introduce a new approach to margin-based online learning called confidenceweighted classification (CW) and show that the performance of this approach is comparable to that of Support-Vector Machines. In this work we use confidence-weighted classification with transition-based parsing and show that this leads to results comparable to the state-of-the-art results obtained using SVMs. We also compare training time and the effect of pruning when using confidence-weighted learnin</context>
</contexts>
<marker>McDonald, Pereira, 2006</marker>
<rawString>Ryan T. McDonald and Fernando C. N. Pereira. 2006. Online learning of approximate dependency parsing algorithms. In EACL. The Association for Computer Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan T McDonald</author>
<author>Koby Crammer</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Online large-margin training of dependency parsers.</title>
<date>2005</date>
<booktitle>In ACL. The Association</booktitle>
<institution>for Computer Linguistics.</institution>
<contexts>
<context position="688" citStr="McDonald et al., 2005" startWordPosition="85" endWordPosition="88">rtin Haulrich Dept. of International Language Studies and Computational Linguistics Copenhagen Business School mwh.isv@cbs.dk Abstract We show that using confidence-weighted classification in transition-based parsing gives results comparable to using SVMs with faster training and parsing time. We also compare with other online learning algorithms and investigate the effect of pruning features when using confidenceweighted classification. 1 Introduction There has been a lot of work on data-driven dependency parsing. The two dominating approaches have been graph-based parsing, e.g. MST-parsing (McDonald et al., 2005b) and transition-based parsing, e.g. the MaltParser (Nivre et al., 2006a). These two approaches differ radically but have in common that the best results have been obtained using margin-based machine learning approaches. For the MST-parsing MIRA (McDonald et al., 2005a; McDonald and Pereira, 2006) and for transition-based parsing Support-Vector Machines (Hall et al., 2006; Nivre et al., 2006b). Dredze et al. (2008) introduce a new approach to margin-based online learning called confidenceweighted classification (CW) and show that the performance of this approach is comparable to that of Suppo</context>
</contexts>
<marker>McDonald, Crammer, Pereira, 2005</marker>
<rawString>Ryan T. McDonald, Koby Crammer, and Fernando C. N. Pereira. 2005a. Online large-margin training of dependency parsers. In ACL. The Association for Computer Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan T McDonald</author>
<author>Fernando Pereira</author>
<author>Kiril Ribarov</author>
<author>Jan Hajic</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>In HLT/EMNLP. The Association for Computational Linguistics.</booktitle>
<contexts>
<context position="688" citStr="McDonald et al., 2005" startWordPosition="85" endWordPosition="88">rtin Haulrich Dept. of International Language Studies and Computational Linguistics Copenhagen Business School mwh.isv@cbs.dk Abstract We show that using confidence-weighted classification in transition-based parsing gives results comparable to using SVMs with faster training and parsing time. We also compare with other online learning algorithms and investigate the effect of pruning features when using confidenceweighted classification. 1 Introduction There has been a lot of work on data-driven dependency parsing. The two dominating approaches have been graph-based parsing, e.g. MST-parsing (McDonald et al., 2005b) and transition-based parsing, e.g. the MaltParser (Nivre et al., 2006a). These two approaches differ radically but have in common that the best results have been obtained using margin-based machine learning approaches. For the MST-parsing MIRA (McDonald et al., 2005a; McDonald and Pereira, 2006) and for transition-based parsing Support-Vector Machines (Hall et al., 2006; Nivre et al., 2006b). Dredze et al. (2008) introduce a new approach to margin-based online learning called confidenceweighted classification (CW) and show that the performance of this approach is comparable to that of Suppo</context>
</contexts>
<marker>McDonald, Pereira, Ribarov, Hajic, 2005</marker>
<rawString>Ryan T. McDonald, Fernando Pereira, Kiril Ribarov, and Jan Hajic. 2005b. Non-projective dependency parsing using spanning tree algorithms. In HLT/EMNLP. The Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jens Nilsson</author>
<author>Joakim Nivre</author>
</authors>
<title>Malteval: An evaluation and visualization tool for dependency parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of the Sixth International Language Resources and Evaluation,</booktitle>
<publisher>LREC.</publisher>
<location>Marrakech, Morocco,</location>
<contexts>
<context position="13041" citStr="Nilsson and Nivre, 2008" startWordPosition="2198" endWordPosition="2201">yper-parameters for the SVM have not been optimized, and neither has the number of iterations for the CW-classifiers, which is always 10. We see 500000 that in many cases the CW-classifier does significantly 3 better than the SVM, but that the opposite is also the case. 5.6 Results with optimization The results presented above are suboptimal for the SVMs because default parameters have been used for these, and optimizing these can improve ac3In all tables statistical significance is marked with †. Significance is calculated using McNemar’s test (p = 0.05). These tests were made with MaltEval (Nilsson and Nivre, 2008) Figure 2: LAS as a function of the cutoff limit when pruning rare features. The dotted line shows the number of features left after pruning. 58 SVM CW LAS UAS LA LAS UAS LA Arabic 66.71 77.52 80.34 67.03 77.52 †81.20 Bulgarian* 87.41 91.72 90.44 87.25 91.56 89.77 Danish †84.77 †89.80 89.16 84.15 88.98 88.74 Dutch* †78.59 †81.35 †83.69 77.21 80.21 82.63 Japanese †91.65 †93.10 †94.34 90.41 91.96 93.34 Portuguese* †87.60 †91.22 †91.54 86.66 90.58 90.34 Slovene 70.30 78.72 80.54 69.84 †79.62 79.42 Spanish 81.29 84.67 90.06 82.09 †85.55 90.52 Swedish* †84.58 89.50 87.39 83.69 89.11 87.01 Turkish †</context>
</contexts>
<marker>Nilsson, Nivre, 2008</marker>
<rawString>Jens Nilsson and Joakim Nivre. 2008. Malteval: An evaluation and visualization tool for dependency parsing. In Proceedings of the Sixth International Language Resources and Evaluation, Marrakech, Morocco, May. LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
</authors>
<title>Maltparser: A data-driven parser-generator for dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the fifth international conference on Language Resources and Evaluation (LREC2006),</booktitle>
<pages>2216--2219</pages>
<contexts>
<context position="760" citStr="Nivre et al., 2006" startWordPosition="95" endWordPosition="98">guistics Copenhagen Business School mwh.isv@cbs.dk Abstract We show that using confidence-weighted classification in transition-based parsing gives results comparable to using SVMs with faster training and parsing time. We also compare with other online learning algorithms and investigate the effect of pruning features when using confidenceweighted classification. 1 Introduction There has been a lot of work on data-driven dependency parsing. The two dominating approaches have been graph-based parsing, e.g. MST-parsing (McDonald et al., 2005b) and transition-based parsing, e.g. the MaltParser (Nivre et al., 2006a). These two approaches differ radically but have in common that the best results have been obtained using margin-based machine learning approaches. For the MST-parsing MIRA (McDonald et al., 2005a; McDonald and Pereira, 2006) and for transition-based parsing Support-Vector Machines (Hall et al., 2006; Nivre et al., 2006b). Dredze et al. (2008) introduce a new approach to margin-based online learning called confidenceweighted classification (CW) and show that the performance of this approach is comparable to that of Support-Vector Machines. In this work we use confidence-weighted classificati</context>
</contexts>
<marker>Nivre, Hall, Nilsson, 2006</marker>
<rawString>Joakim Nivre, Johan Hall, and Jens Nilsson. 2006a. Maltparser: A data-driven parser-generator for dependency parsing. In Proceedings of the fifth international conference on Language Resources and Evaluation (LREC2006), pages 2216–2219, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
<author>G¨uls¸en Eryiˇgit</author>
<author>Svetoslav Marinov</author>
</authors>
<title>Labeled pseudo-projective dependency parsing with support vector machines.</title>
<date>2006</date>
<booktitle>In Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLL-X),</booktitle>
<pages>221--225</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>New York City,</location>
<marker>Nivre, Hall, Nilsson, Eryiˇgit, Marinov, 2006</marker>
<rawString>Joakim Nivre, Johan Hall, Jens Nilsson, G¨uls¸en Eryiˇgit, and Svetoslav Marinov. 2006b. Labeled pseudo-projective dependency parsing with support vector machines. In Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLL-X), pages 221–225, New York City, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Sandra K¨ubler</author>
<author>Ryan McDonald</author>
<author>Jens Nilsson</author>
<author>Sebastian Riedel</author>
<author>Deniz Yuret</author>
</authors>
<title>The CoNLL</title>
<date>2007</date>
<booktitle>In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL</booktitle>
<pages>915--932</pages>
<marker>Nivre, Hall, K¨ubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan McDonald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret. 2007. The CoNLL 2007 shared task on dependency parsing. In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pages 915–932.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Algorithms for deterministic incremental dependency parsing.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>4</issue>
<contexts>
<context position="1851" citStr="Nivre, 2008" startWordPosition="253" endWordPosition="254">e of this approach is comparable to that of Support-Vector Machines. In this work we use confidence-weighted classification with transition-based parsing and show that this leads to results comparable to the state-of-the-art results obtained using SVMs. We also compare training time and the effect of pruning when using confidence-weighted learning. 2 Transition-based parsing Transition-based parsing builds on the idea that parsing can be viewed as a sequence of transitions between states. A transition-based parser (deterministic classifier-based parser) consists of three essential components (Nivre, 2008): 1. A parsing algorithm 2. A feature model 3. A classifier The focus here is on the classifier but we will briefly describe the parsing algorithm in order to understand the classification task better. The parsing algorithm consists of two components, a transition system and an oracle. Nivre (2008) defines a transition system S = (C, T, cs, Ct) in the following way: 1. C is a set of configurations, each of which contains a buffer β of (remaining) nodes and a set A of dependency arcs, 2. T is a set of transitions, each of which is a partial function t : C → C, 3. cs is a initialization function</context>
<context position="3715" citStr="Nivre, 2008" startWordPosition="621" endWordPosition="622">mputational Linguistics lead to the correct parse. The information given to the classifier is the current configuration. Therefore the training data for the classifier consists of a number of configurations and the transitions the oracle chose with these configurations. Here we focus on stack-based parsing algorithms. A stack-based configuration for a sentence x = (w0, wi, ... , wn) is a triple c = (σ, β, A), where 1. σ is a stack of tokens i &lt; k (for some k &lt; n), 2. β is a buffer of tokens j &gt; k , 3. A is a set of dependency arcs such that G = (0, 1, ... , n, A) is a dependency graph for x. (Nivre, 2008) In the work presented here we use the NivreEager algorithm which has four transitions: Shift Push the token at the head of the buffer onto the stack. Reduce Pop the token on the top of the stack. Left-Arcl Add to the analysis an arc with label l from the token at the head of the buffer to the token on the top of the stack, and push the buffer-token onto the stack. Right-Arcl Add to the analysis an arc with label l from the token on the top of the stack to the token at the head of the buffer, and pop the stack. 2.1 Classification Transition-based dependency parsing reduces parsing to consecuti</context>
<context position="13041" citStr="Nivre, 2008" startWordPosition="2200" endWordPosition="2201">ers for the SVM have not been optimized, and neither has the number of iterations for the CW-classifiers, which is always 10. We see 500000 that in many cases the CW-classifier does significantly 3 better than the SVM, but that the opposite is also the case. 5.6 Results with optimization The results presented above are suboptimal for the SVMs because default parameters have been used for these, and optimizing these can improve ac3In all tables statistical significance is marked with †. Significance is calculated using McNemar’s test (p = 0.05). These tests were made with MaltEval (Nilsson and Nivre, 2008) Figure 2: LAS as a function of the cutoff limit when pruning rare features. The dotted line shows the number of features left after pruning. 58 SVM CW LAS UAS LA LAS UAS LA Arabic 66.71 77.52 80.34 67.03 77.52 †81.20 Bulgarian* 87.41 91.72 90.44 87.25 91.56 89.77 Danish †84.77 †89.80 89.16 84.15 88.98 88.74 Dutch* †78.59 †81.35 †83.69 77.21 80.21 82.63 Japanese †91.65 †93.10 †94.34 90.41 91.96 93.34 Portuguese* †87.60 †91.22 †91.54 86.66 90.58 90.34 Slovene 70.30 78.72 80.54 69.84 †79.62 79.42 Spanish 81.29 84.67 90.06 82.09 †85.55 90.52 Swedish* †84.58 89.50 87.39 83.69 89.11 87.01 Turkish †</context>
</contexts>
<marker>Nivre, 2008</marker>
<rawString>Joakim Nivre. 2008. Algorithms for deterministic incremental dependency parsing. Computational Linguistics, 34(4):513–553.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Rosenblatt</author>
</authors>
<title>The perceptron: A probabilistic model for information storage and organization in the brain.</title>
<date>1958</date>
<journal>Psychological Review,</journal>
<volume>65</volume>
<issue>6</issue>
<contexts>
<context position="8320" citStr="Rosenblatt, 1958" startWordPosition="1394" endWordPosition="1395"> MaltParser consisting of 14 features has been used. When using a linear-classifier without a kernel we need to extend the feature set in order to achieve good results. We have done this very uncritically by adding all pair wise combinations of all features. This leads to 91 additional features when using the standard 14 features. 5 Results and discussion We will now discuss various results of our experiments with using CW-classifiers in transitionbased parsing. 5.1 Online classifiers We compare CW-classifiers with other online algorithms for linear classification. We compare with perceptron (Rosenblatt, 1958) and MIRA (Crammer et al., 2006). With both these classifiers we use the same top-1 approach as with the CW-classifers and also averaging which has been shown to alleviate overfitting (Collins, 2002). Table 2 shows Labeled Attachment Score obtained with the three online classifiers. All classifiers were trained with 10 iterations. These results confirm those by Crammer et al. (2009) and show that confidence-weighted classifiers are better than both perceptron and MIRA. 5.2 Training and parsing time The training time of the CW-classifiers depends on the number of iterations used, and this of co</context>
</contexts>
<marker>Rosenblatt, 1958</marker>
<rawString>Frank Rosenblatt. 1958. The perceptron: A probabilistic model for information storage and organization in the brain. Psychological Review, 65(6):386–408.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>