<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005766">
<title confidence="0.976724">
Models of Metaphor in NLP
</title>
<author confidence="0.990133">
Ekaterina Shutova
</author>
<affiliation confidence="0.9890025">
Computer Laboratory
University of Cambridge
</affiliation>
<address confidence="0.981309">
15 JJ Thomson Avenue
Cambridge CB3 0FD, UK
</address>
<email confidence="0.998883">
Ekaterina.Shutova@cl.cam.ac.uk
</email>
<sectionHeader confidence="0.993891" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999719384615385">
Automatic processing of metaphor can
be clearly divided into two subtasks:
metaphor recognition (distinguishing be-
tween literal and metaphorical language in
a text) and metaphor interpretation (iden-
tifying the intended literal meaning of a
metaphorical expression). Both of them
have been repeatedly addressed in NLP.
This paper is the first comprehensive and
systematic review of the existing compu-
tational models of metaphor, the issues of
metaphor annotation in corpora and the
available resources.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999927">
Our production and comprehension of language
is a multi-layered computational process. Hu-
mans carry out high-level semantic tasks effort-
lessly by subconsciously employing a vast inven-
tory of complex linguistic devices, while simulta-
neously integrating their background knowledge,
to reason about reality. An ideal model of lan-
guage understanding would also be capable of per-
forming such high-level semantic tasks.
However, a great deal of NLP research to date
focuses on processing lower-level linguistic infor-
mation, such as e.g. part-of-speech tagging, dis-
covering syntactic structure of a sentence (pars-
ing), coreference resolution, named entity recog-
nition and many others. Another cohort of re-
searchers set the goal of improving application-
based statistical inference (e.g. for recognizing
textual entailment or automatic summarization).
In contrast, there have been fewer attempts to
bring the state-of-the-art NLP technologies to-
gether to model the way humans use language to
frame high-level reasoning processes, such as for
example, creative thought.
The majority of computational approaches to
figurative language still exploit the ideas articu-
lated three decades ago (Wilks, 1978; Lakoff and
Johnson, 1980; Fass, 1991) and often rely on task-
specific hand-coded knowledge. However, recent
work on lexical semantics and lexical acquisition
techniques opens many new avenues for creation
of fully automated models for recognition and in-
terpretation of figurative language. In this pa-
per I will focus on the phenomenon of metaphor
and describe the most prominent computational
approaches to metaphor, as well the issues of re-
source creation and metaphor annotation.
Metaphors arise when one concept is viewed
in terms of the properties of the other. In other
words it is based on similarity between the con-
cepts. Similarity is a kind of association implying
the presence of characteristics in common. Here
are some examples of metaphor.
</bodyText>
<listItem confidence="0.943396">
(1) Hillary brushed aside the accusations.
(2) How can I kill a process? (Martin, 1988)
(3) I invested myself fully in this relationship.
(4) And then my heart with pleasure fills,
And dances with the daffodils.1
</listItem>
<bodyText confidence="0.999568692307693">
In metaphorical expressions seemingly unrelated
features of one concept are associated with an-
other concept. In the example (2) the computa-
tional process is viewed as something alive and,
therefore, its forced termination is associated with
the act of killing.
Metaphorical expressions represent a great vari-
ety, ranging from conventional metaphors, which
we reproduce and comprehend every day, e.g.
those in (2) and (3), to poetic and largely novel
ones, such as (4). The use of metaphor is ubiq-
uitous in natural language text and it is a seri-
ous bottleneck in automatic text understanding.
</bodyText>
<footnote confidence="0.943582">
1“I wandered lonely as a cloud”, William Wordsworth,
1804.
</footnote>
<page confidence="0.862862">
688
</page>
<note confidence="0.9473715">
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 688–697,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999893315789474">
In order to estimate the frequency of the phe-
nomenon, Shutova (2010) conducted a corpus
study on a subset of the British National Corpus
(BNC) (Burnard, 2007) representing various gen-
res. They manually annotated metaphorical ex-
pressions in this data and found that 241 out of
761 sentences contained a metaphor. Due to such
a high frequency of their use, a system capable of
recognizing and interpreting metaphorical expres-
sions in unrestricted text would become an invalu-
able component of any semantics-oriented NLP
application.
Automatic processing of metaphor can be
clearly divided into two subtasks: metaphor
recognition (distinguishing between literal and
metaphorical language in text) and metaphor in-
terpretation (identifying the intended literal mean-
ing of a metaphorical expression). Both of them
have been repeatedly addressed in NLP.
</bodyText>
<sectionHeader confidence="0.989821" genericHeader="method">
2 Theoretical Background
</sectionHeader>
<bodyText confidence="0.998030214285714">
Four different views on metaphor have been
broadly discussed in linguistics and philosophy:
the comparison view (Gentner, 1983), the inter-
action view (Black, 1962), (Hesse, 1966), the se-
lectional restrictions violation view (Wilks, 1975;
Wilks, 1978) and the conceptual metaphor view
(Lakoff and Johnson, 1980)2. All of these ap-
proaches share the idea of an interconceptual map-
ping that underlies the production of metaphorical
expressions. In other words, metaphor always in-
volves two concepts or conceptual domains: the
target (also called topic or tenor in the linguistics
literature) and the source (or vehicle). Consider
the examples in (5) and (6).
</bodyText>
<listItem confidence="0.99795375">
(5) He shot down all of my arguments. (Lakoff
and Johnson, 1980)
(6) He attacked every weak point in my argu-
ment. (Lakoff and Johnson, 1980)
</listItem>
<bodyText confidence="0.97067575">
According to Lakoff and Johnson (1980), a
mapping of a concept of argument to that of war
is employed here. The argument, which is the tar-
get concept, is viewed in terms of a battle (or a
war), the source concept. The existence of such
a link allows us to talk about arguments using the
war terminology, thus giving rise to a number of
metaphors.
</bodyText>
<footnote confidence="0.6898535">
2A detailed overview and criticism of these four views can
be found in (Tourangeau and Sternberg, 1982).
</footnote>
<bodyText confidence="0.999745130434783">
However, Lakoff and Johnson do not discuss
how metaphors can be recognized in the linguis-
tic data, which is the primary task in the auto-
matic processing of metaphor. Although humans
are highly capable of producing and comprehend-
ing metaphorical expressions, the task of distin-
guishing between literal and non-literal meanings
and, therefore, identifying metaphor in text ap-
pears to be challenging. This is due to the vari-
ation in its use and external form, as well as a
not clear-cut semantic distinction. Gibbs (1984)
suggests that literal and figurative meanings are
situated at the ends of a single continuum, along
which metaphoricity and idiomaticity are spread.
This makes demarcation of metaphorical and lit-
eral language fuzzy.
So far, the most influential account of metaphor
recognition is that of Wilks (1978). According to
Wilks, metaphors represent a violation of selec-
tional restrictions in a given context. Selectional
restrictions are the semantic constraints that a verb
places onto its arguments. Consider the following
example.
</bodyText>
<listItem confidence="0.699814">
(7) My car drinks gasoline. (Wilks, 1978)
</listItem>
<bodyText confidence="0.99950925">
The verb drink normally takes an animate subject
and a liquid object. Therefore, drink taking a car
as a subject is an anomaly, which may in turn in-
dicate the metaphorical use of drink.
</bodyText>
<sectionHeader confidence="0.990491" genericHeader="method">
3 Automatic Metaphor Recognition
</sectionHeader>
<bodyText confidence="0.99997975">
One of the first attempts to identify and inter-
pret metaphorical expressions in text automati-
cally is the approach of Fass (1991). It originates
in the work of Wilks (1978) and utilizes hand-
coded knowledge. Fass (1991) developed a system
called met*, capable of discriminating between
literalness, metonymy, metaphor and anomaly.
It does this in three stages. First, literalness
is distinguished from non-literalness using selec-
tional preference violation as an indicator. In the
case that non-literalness is detected, the respective
phrase is tested for being a metonymic relation us-
ing hand-coded patterns (such as CONTAINER-
for-CONTENT). If the system fails to recognize
metonymy, it proceeds to search the knowledge
base for a relevant analogy in order to discriminate
metaphorical relations from anomalous ones. E.g.,
the sentence in (7) would be represented in this
framework as (car,drink,gasoline), which does not
satisfy the preference (animal,drink,liquid), as car
</bodyText>
<page confidence="0.998571">
689
</page>
<bodyText confidence="0.99990112745098">
is not a hyponym of animal. met* then searches its
knowledge base for a triple containing a hypernym
of both the actual argument and the desired argu-
ment and finds (thing,use,energy source), which
represents the metaphorical interpretation.
However, Fass himself indicated a problem with
the selectional preference violation approach ap-
plied to metaphor recognition. The approach de-
tects any kind of non-literalness or anomaly in
language (metaphors, metonymies and others),
and not only metaphors, i.e., it overgenerates.
The methods met* uses to differentiate between
those are mainly based on hand-coded knowledge,
which implies a number of limitations.
Another problem with this approach arises from
the high conventionality of metaphor in language.
This means that some metaphorical senses are
very common. As a result the system would ex-
tract selectional preference distributions skewed
towards such conventional metaphorical senses of
the verb or one of its arguments. Therefore, al-
though some expressions may be fully metaphor-
ical in nature, no selectional preference violation
can be detected in their use. Another counterar-
gument is bound to the fact that interpretation is
always context dependent, e.g. the phrase all men
are animals can be used metaphorically, however,
without any violation of selectional restrictions.
Goatly (1997) addresses the phenomenon of
metaphor by identifying a set of linguistic cues
indicating it. He gives examples of lexical pat-
terns indicating the presence of a metaphorical ex-
pression, such as metaphorically speaking, utterly,
completely, so to speak and, surprisingly, liter-
ally. Such cues would probably not be enough for
metaphor extraction on their own, but could con-
tribute to a more complex system.
The work of Peters and Peters (2000) concen-
trates on detecting figurative language in lexical
resources. They mine WordNet (Fellbaum, 1998)
for the examples of systematic polysemy, which
allows to capture metonymic and metaphorical re-
lations. The authors search for nodes that are rel-
atively high up in the WordNet hierarchy and that
share a set of common word forms among their de-
scendants. Peters and Peters found that such nodes
often happen to be in metonymic (e.g. publica-
tion – publisher) or metaphorical (e.g. supporting
structure – theory) relation.
The CorMet system discussed in (Mason, 2004)
is the first attempt to discover source-target do-
main mappings automatically. This is done by
“finding systematic variations in domain-specific
selectional preferences, which are inferred from
large, dynamically mined Internet corpora”. For
example, Mason collects texts from the LAB do-
main and the FINANCE domain, in both of which
pour would be a characteristic verb. In the LAB
domain pour has a strong selectional preference
for objects of type liquid, whereas in the FI-
NANCE domain it selects for money. From this
Mason’s system infers the domain mapping FI-
NANCE – LAB and the concept mapping money
– liquid. He compares the output of his system
against the Master Metaphor List (Lakoff et al.,
1991) containing hand-crafted metaphorical map-
pings between concepts. Mason reports an accu-
racy of 77%, although it should be noted that as
any evaluation that is done by hand it contains an
element of subjectivity.
Birke and Sarkar (2006) present a sentence clus-
tering approach for non-literal language recog-
nition implemented in the TroFi system (Trope
Finder). This idea originates from a similarity-
based word sense disambiguation method devel-
oped by Karov and Edelman (1998). The method
employs a set of seed sentences, where the senses
are annotated; computes similarity between the
sentence containing the word to be disambiguated
and all of the seed sentences and selects the sense
corresponding to the annotation in the most simi-
lar seed sentences. Birke and Sarkar (2006) adapt
this algorithm to perform a two-way classification:
literal vs. non-literal, and they do not clearly de-
fine the kinds of tropes they aim to discover. They
attain a performance of 53.8% in terms of f-score.
The method of Gedigan et al. (2006) discrimi-
nates between literal and metaphorical use. They
trained a maximum entropy classifier for this pur-
pose. They obtained their data by extracting the
lexical items whose frames are related to MO-
TION and CURE from FrameNet (Fillmore et
al., 2003). Then they searched the PropBank
Wall Street Journal corpus (Kingsbury and Palmer,
2002) for sentences containing such lexical items
and annotated them with respect to metaphoric-
ity. They used PropBank annotation (arguments
and their semantic types) as features to train the
classifier and report an accuracy of 95.12%. This
result is, however, only a little higher than the per-
formance of the naive baseline assigning major-
ity class to all instances (92.90%). These numbers
</bodyText>
<page confidence="0.986007">
690
</page>
<bodyText confidence="0.999945731707317">
can be explained by the fact that 92.00% of the
verbs of MOTION and CURE in the Wall Street
Journal corpus are used metaphorically, thus mak-
ing the dataset unbalanced with respect to the tar-
get categories and the task notably easier.
Both Birke and Sarkar (2006) and Gedigan et
al. (2006) focus only on metaphors expressed by
a verb. As opposed to that the approach of Kr-
ishnakumaran and Zhu (2007) deals with verbs,
nouns and adjectives as parts of speech. They
use hyponymy relation in WordNet and word bi-
gram counts to predict metaphors at a sentence
level. Given an IS-A metaphor (e.g. The world
is a stage3) they verify if the two nouns involved
are in hyponymy relation in WordNet, and if
they are not then this sentence is tagged as con-
taining a metaphor. Along with this they con-
sider expressions containing a verb or an adjec-
tive used metaphorically (e.g. He planted good
ideas in their minds or He has a fertile imagi-
nation). Hereby they calculate bigram probabil-
ities of verb-noun and adjective-noun pairs (in-
cluding the hyponyms/hypernyms of the noun in
question). If the combination is not observed in
the data with sufficient frequency, the system tags
the sentence containing it as metaphorical. This
idea is a modification of the selectional prefer-
ence view of Wilks. However, by using bigram
counts over verb-noun pairs Krishnakumaran and
Zhu (2007) loose a great deal of information com-
pared to a system extracting verb-object relations
from parsed text. The authors evaluated their sys-
tem on a set of example sentences compiled from
the Master Metaphor List (Lakoff et al., 1991),
whereby highly conventionalized metaphors (they
call them dead metaphors) are taken to be negative
examples. Thus they do not deal with literal exam-
ples as such: essentially, the distinction they are
making is between the senses included in Word-
Net, even if they are conventional metaphors, and
those not included in WordNet.
</bodyText>
<sectionHeader confidence="0.989106" genericHeader="method">
4 Automatic Metaphor Interpretation
</sectionHeader>
<bodyText confidence="0.999960714285714">
Almost simultaneously with the work of Fass
(1991), Martin (1990) presents a Metaphor In-
terpretation, Denotation and Acquisition System
(MIDAS). In this work Martin captures hierarchi-
cal organisation of conventional metaphors. The
idea behind this is that the more specific conven-
tional metaphors descend from the general ones.
</bodyText>
<subsectionHeader confidence="0.6433">
3William Shakespeare
</subsectionHeader>
<bodyText confidence="0.999992117647059">
Given an example of a metaphorical expression,
MIDAS searches its database for a corresponding
metaphor that would explain the anomaly. If it
does not find any, it abstracts from the example to
more general concepts and repeats the search. If it
finds a suitable general metaphor, it creates a map-
ping for its descendant, a more specific metaphor,
based on this example. This is also how novel
metaphors are acquired. MIDAS has been inte-
grated with the Unix Consultant (UC), the sys-
tem that answers users questions about Unix. The
UC first tries to find a literal answer to the ques-
tion. If it is not able to, it calls MIDAS which
detects metaphorical expressions via selectional
preference violation and searches its database for a
metaphor explaining the anomaly in the question.
Another cohort of approaches relies on per-
forming inferences about entities and events in
the source and target domains for metaphor in-
terpretation. These include the KARMA sys-
tem (Narayanan, 1997; Narayanan, 1999; Feld-
man and Narayanan, 2004) and the ATT-Meta
project (Barnden and Lee, 2002; Agerri et al.,
2007). Within both systems the authors developed
a metaphor-based reasoning framework in accor-
dance with the theory of conceptual metaphor.
The reasoning process relies on manually coded
knowledge about the world and operates mainly in
the source domain. The results are then projected
onto the target domain using the conceptual map-
ping representation. The ATT-Meta project con-
cerns metaphorical and metonymic description of
mental states and reasoning about mental states
using first order logic. Their system, however,
does not take natural language sentences as input,
but logical expressions that are representations of
small discourse fragments. KARMA in turn deals
with a broad range of abstract actions and events
and takes parsed text as input.
Veale and Hao (2008) derive a “fluid knowl-
edge representation for metaphor interpretation
and generation”, called Talking Points. Talk-
ing Points are a set of characteristics of concepts
belonging to source and target domains and re-
lated facts about the world which the authors ac-
quire automatically from WordNet and from the
web. Talking Points are then organized in Slip-
net, a framework that allows for a number of
insertions, deletions and substitutions in defini-
tions of such characteristics in order to establish
a connection between the target and the source
</bodyText>
<page confidence="0.994363">
691
</page>
<bodyText confidence="0.999849333333333">
concepts. This work builds on the idea of slip-
page in knowledge representation for understand-
ing analogies in abstract domains (Hofstadter and
Mitchell, 1994; Hofstadter, 1995). Below is an
example demonstrating how slippage operates to
explain the metaphor Make-up is a Western burqa.
</bodyText>
<equation confidence="0.630267">
Make-up =&gt;
</equation>
<bodyText confidence="0.997281228571429">
� typically worn by women
� expected to be worn by women
� must be worn by women
� must be worn by Muslim women
Burqa &lt;=
By doing insertions and substitutions the sys-
tem arrives from the definition typically worn by
women to that of must be worn by Muslim women,
and thus establishes a link between the concepts
of make-up and burqa. Veale and Hao (2008),
however, did not evaluate to which extent their
knowledge base of Talking Points and the asso-
ciated reasoning framework are useful to interpret
metaphorical expressions occurring in text.
Shutova (2010) defines metaphor interpretation
as a paraphrasing task and presents a method for
deriving literal paraphrases for metaphorical ex-
pressions from the BNC. For example, for the
metaphors in “All of this stirred an unfathomable
excitement in her” or “a carelessly leaked report”
their system produces interpretations “All of this
provoked an unfathomable excitement in her” and
“a carelessly disclosed report” respectively. They
first apply a probabilistic model to rank all pos-
sible paraphrases for the metaphorical expression
given the context; and then use automatically in-
duced selectional preferences to discriminate be-
tween figurative and literal paraphrases. The se-
lectional preference distribution is defined in terms
of selectional association measure introduced by
Resnik (1993) over the noun classes automatically
produced by Sun and Korhonen (2009). Shutova
(2010) tested their system only on metaphors ex-
pressed by a verb and report a paraphrasing accu-
racy of 0.81.
</bodyText>
<sectionHeader confidence="0.997686" genericHeader="method">
5 Metaphor Resources
</sectionHeader>
<bodyText confidence="0.999845576923077">
Metaphor is a knowledge-hungry phenomenon.
Hence there is a need for either an exten-
sive manually-created knowledge-base or a robust
knowledge acquisition system for interpretation of
metaphorical expressions. The latter being a hard
task, a great deal of metaphor research resorted to
the first option. Although hand-coded knowledge
proved useful for metaphor interpretation (Fass,
1991; Martin, 1990), it should be noted that the
systems utilizing it have a very limited coverage.
One of the first attempts to create a multi-
purpose knowledge base of source–target domain
mappings is the Master Metaphor List (Lakoff et
al., 1991). It includes a classification of metaphor-
ical mappings (mainly those related to mind, feel-
ings and emotions) with the corresponding exam-
ples of language use. This resource has been criti-
cized for the lack of clear structuring principles of
the mapping ontology (L¨onneker-Rodman, 2008).
The taxonomical levels are often confused, and the
same classes are referred to by different class la-
bels. This fact and the chosen data representation
in the Master Metaphor List make it not suitable
for computational use. However, both the idea of
the list and its actual mappings ontology inspired
the creation of other metaphor resources.
The most prominent of them are MetaBank
(Martin, 1994) and the Mental Metaphor Data-
bank4 created in the framework of the ATT-meta
project (Barnden and Lee, 2002; Agerri et al.,
2007). The MetaBank is a knowledge-base of En-
glish metaphorical conventions, represented in the
form of metaphor maps (Martin, 1988) contain-
ing detailed information about source-target con-
cept mappings backed by empirical evidence. The
ATT-meta project databank contains a large num-
ber of examples of metaphors of mind classified
by source–target domain mappings taken from the
Master Metaphor List.
Along with this it is worth mentioning metaphor
resources in languages other than English. There
has been a wealth of research on metaphor
in Spanish, Chinese, Russian, German, French
and Italian. The Hamburg Metaphor Database
(L¨onneker, 2004; Reining and L¨onneker-Rodman,
2007) contains examples of metaphorical expres-
sions in German and French, which are mapped
to senses from EuroWordNet5 and annotated with
source–target domain mappings taken from the
Master Metaphor List.
Alonge and Castelli (2003) discuss how
metaphors can be represented in ItalWordNet for
</bodyText>
<footnote confidence="0.999582166666667">
4http://www.cs.bham.ac.uk/—jab/ATT-Meta/Databank/
5EuroWordNet is a multilingual database with wordnets
for several European languages (Dutch, Italian, Spanish, Ger-
man, French, Czech and Estonian). The wordnets are struc-
tured in the same way as the Princeton WordNet for English.
URL: http://www.illc.uva.nl/EuroWordNet/
</footnote>
<page confidence="0.997343">
692
</page>
<bodyText confidence="0.999956285714286">
Italian and motivate this by linguistic evidence.
Encoding metaphorical information in general-
domain lexical resources for English, e.g. Word-
Net (L¨onneker and Eilts, 2004), would undoubt-
edly provide a new platform for experiments and
enable researchers to directly compare their re-
sults.
</bodyText>
<sectionHeader confidence="0.982327" genericHeader="method">
6 Metaphor Annotation in Corpora
</sectionHeader>
<bodyText confidence="0.999986">
To reflect two distinct aspects of the phenomenon,
metaphor annotation can be split into two stages:
identifying metaphorical senses in text (akin word
sense disambiguation) and annotating source – tar-
get domain mappings underlying the production of
metaphorical expressions. Traditional approaches
to metaphor annotation include manual search
for lexical items used metaphorically (Pragglejaz
Group, 2007), for source and target domain vocab-
ulary (Deignan, 2006; Koivisto-Alanko and Tis-
sari, 2006; Martin, 2006) or for linguistic mark-
ers of metaphor (Goatly, 1997). Although there
is a consensus in the research community that
the phenomenon of metaphor is not restricted to
similarity-based extensions of meanings of iso-
lated words, but rather involves reconceptualiza-
tion of a whole area of experience in terms of an-
other, there still has been surprisingly little inter-
est in annotation of cross-domain mappings. How-
ever, a corpus annotated for conceptual mappings
could provide a new starting point for both linguis-
tic and cognitive experiments.
</bodyText>
<subsectionHeader confidence="0.990968">
6.1 Metaphor and Polysemy
</subsectionHeader>
<bodyText confidence="0.999964242424242">
The theorists of metaphor distinguish between two
kinds of metaphorical language: novel (or poetic)
metaphors, that surprise our imagination, and con-
ventionalized metaphors, that become a part of an
ordinary discourse. “Metaphors begin their lives
as novel poetic creations with marked rhetorical
effects, whose comprehension requires a special
imaginative leap. As time goes by, they become
a part of general usage, their comprehension be-
comes more automatic, and their rhetorical effect
is dulled” (Nunberg, 1987). Following Orwell
(1946) Nunberg calls such metaphors “dead” and
claims that they are not psychologically distinct
from literally-used terms.
This scheme demonstrates how metaphorical
associations capture some generalisations govern-
ing polysemy: over time some of the aspects of
the target domain are added to the meaning of a
term in a source domain, resulting in a (metaphor-
ical) sense extension of this term. Copestake
and Briscoe (1995) discuss sense extension mainly
based on metonymic examples and model the phe-
nomenon using lexical rules encoding metonymic
patterns. Along with this they suggest that similar
mechanisms can be used to account for metaphoric
processes, and the conceptual mappings encoded
in the sense extension rules would define the lim-
its to the possible shifts in meaning.
However, it is often unclear if a metaphorical
instance is a case of broadening of the sense in
context due to general vagueness in language, or it
manifests a formation of a new distinct metaphor-
ical sense. Consider the following examples.
</bodyText>
<listItem confidence="0.9891612">
(8) a. As soon as I entered the room I noticed
the difference.
b. How can I enter Emacs?
(9) a. My tea is cold.
b. He is such a cold person.
</listItem>
<bodyText confidence="0.999900045454545">
Enter in (8a) is defined as “to go or come into
a place, building, room, etc.; to pass within the
boundaries of a country, region, portion of space,
medium, etc.”6 In (8b) this sense stretches to
describe dealing with software, whereby COM-
PUTER PROGRAMS are viewed as PHYSICAL
SPACES. However, this extended sense of enter
does not appear to be sufficiently distinct or con-
ventional to be included into the dictionary, al-
though this could happen over time.
The sentence (9a) exemplifies the basic sense
of cold – “of a temperature sensibly lower than
that of the living human body”, whereas cold in
(9b) should be interpreted metaphorically as “void
of ardour, warmth, or intensity of feeling; lacking
enthusiasm, heartiness, or zeal; indifferent, apa-
thetic”. These two senses are clearly linked via
the metaphoric mapping between EMOTIONAL
STATES and TEMPERATURES.
A number of metaphorical senses are included
in WordNet, however without any accompanying
semantic annotation.
</bodyText>
<subsectionHeader confidence="0.994979">
6.2 Metaphor Identification
6.2.1 Pragglejaz Procedure
</subsectionHeader>
<bodyText confidence="0.9968555">
Pragglejaz Group (2007) proposes a metaphor
identification procedure (MIP) within the frame-
</bodyText>
<footnote confidence="0.990963">
6Sense definitions are taken from the Oxford English Dic-
tionary.
</footnote>
<page confidence="0.998535">
693
</page>
<bodyText confidence="0.99996925">
work of the Metaphor in Discourse project (Steen,
2007). The procedure involves metaphor annota-
tion at the word level as opposed to identifying
metaphorical relations (between words) or source–
target domain mappings (between concepts or do-
mains). In order to discriminate between the verbs
used metaphorically and literally the annotators
are asked to follow the guidelines:
</bodyText>
<listItem confidence="0.8853426">
1. For each verb establish its meaning in context
and try to imagine a more basic meaning of
this verb on other contexts. Basic meanings
normally are: (1) more concrete; (2) related
to bodily action; (3) more precise (as opposed
to vague); (4) historically older.
2. If you can establish the basic meaning that
is distinct from the meaning of the verb in
this context, the verb is likely to be used
metaphorically.
</listItem>
<bodyText confidence="0.962143666666667">
Such annotation can be viewed as a form of
word sense disambiguation with an emphasis on
metaphoricity.
</bodyText>
<subsectionHeader confidence="0.979635">
6.2.2 Source – Target Domain Vocabulary
</subsectionHeader>
<bodyText confidence="0.99979978125">
Another popular method that has been used to ex-
tract metaphors is searching for sentences contain-
ing lexical items from the source domain, the tar-
get domain, or both (Stefanowitsch, 2006). This
method requires exhaustive lists of source and tar-
get domain vocabulary.
Martin (2006) conducted a corpus study in
order to confirm that metaphorical expressions
occur in text in contexts containing such lex-
ical items. He performed his analysis on the
data from the Wall Street Journal (WSJ) cor-
pus and focused on four conceptual metaphors
that occur with considerable regularity in the
corpus. These include NUMERICAL VALUE
AS LOCATION, COMMERCIAL ACTIVITY
AS CONTAINER, COMMERCIAL ACTIVITY
AS PATH FOLLOWING and COMMERCIAL
ACTIVITY AS WAR. Martin manually compiled
the lists of terms characteristic for each domain
by examining sampled metaphors of these types
and then augmented them through the use of
thesaurus. He then searched the WSJ for sen-
tences containing vocabulary from these lists
and checked whether they contain metaphors of
the above types. The goal of this study was to
evaluate predictive ability of contexts containing
vocabulary from (1) source domain and (2) target
domain, as well as (3) estimating the likelihood
of a metaphorical expression following another
metaphorical expression described by the same
mapping. He obtained the most positive results for
metaphors of the type NUMERICAL-VALUE-
</bodyText>
<equation confidence="0.973009">
AS-LOCATION (P(Metaphor|Source) =
0.069, P (Metaphor|Target) = 0.677,
P (Metaphor|Metaphor) = 0.703).
</equation>
<subsectionHeader confidence="0.999983">
6.3 Annotating Source and Target Domains
</subsectionHeader>
<bodyText confidence="0.99998803125">
Wallington et al. (2003) carried out a metaphor an-
notation experiment in the framework of the ATT-
Meta project. They employed two teams of an-
notators. Team A was asked to annotate “inter-
esting stretches”, whereby a phrase was consid-
ered interesting if (1) its significance in the doc-
ument was non-physical, (2) it could have a phys-
ical significance in another context with a similar
syntactic frame, (3) this physical significance was
related to the abstract one. Team B had to anno-
tate phrases according to their own intuitive defi-
nition of metaphor. Besides metaphorical expres-
sions Wallington et al. (2003) attempted to anno-
tate the involved source – target domain mappings.
The annotators were given a set of mappings from
the Master Metaphor List and were asked to assign
the most suitable ones to the examples. However,
the authors do not report the level of interannota-
tor agreement nor the coverage of the mappings in
the Master Metaphor List on their data.
Shutova and Teufel (2010) adopt a different ap-
proach to the annotation of source – target do-
main mappings. They do not rely on prede-
fined mappings, but instead derive independent
sets of most common source and target categories.
They propose a two stage procedure, whereby the
metaphorical expressions are first identified using
MIP, and then the source domain (where the ba-
sic sense comes from) and the target domain (the
given context) are selected from the lists of cate-
gories. Shutova and Teufel (2010) report interan-
notator agreement of 0.61 (r.).
</bodyText>
<sectionHeader confidence="0.992811" genericHeader="conclusions">
7 Conclusion and Future Directions
</sectionHeader>
<bodyText confidence="0.999954571428571">
The eighties and nineties provided us with a
wealth of ideas on the structure and mechanisms
of the phenomenon of metaphor. The approaches
formulated back then are still highly influential,
although their use of hand-coded knowledge is
becoming increasingly less convincing. The last
decade witnessed a high technological leap in
</bodyText>
<page confidence="0.996646">
694
</page>
<bodyText confidence="0.999984233333333">
natural language computation, whereby manually
crafted rules gradually give way to more robust
corpus-based statistical methods. This is also the
case for metaphor research. The latest develop-
ments in the lexical acquisition technology will
in the near future enable fully automated corpus-
based processing of metaphor.
However, there is still a clear need in a uni-
fied metaphor annotation procedure and creation
of a large publicly available metaphor corpus.
Given such a resource the computational work on
metaphor is likely to proceed along the following
lines: (1) automatic acquisition of an extensive set
of valid metaphorical associations from linguis-
tic data via statistical pattern matching; (2) using
the knowledge of these associations for metaphor
recognition in the unseen unrestricted text and, fi-
nally, (3) interpretation of the identified metaphor-
ical expressions by deriving the closest literal
paraphrase (a representation that can be directly
embedded in other NLP applications to enhance
their performance).
Besides making our thoughts more vivid and
filling our communication with richer imagery,
metaphors also play an important structural role
in our cognition. Thus, one of the long term goals
of metaphor research in NLP and AI would be to
build a computational intelligence model account-
ing for the way metaphors organize our conceptual
system, in terms of which we think and act.
</bodyText>
<sectionHeader confidence="0.997639" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9997792">
I would like to thank Anna Korhonen and my re-
viewers for their most helpful feedback on this pa-
per. The support of Cambridge Overseas Trust,
who fully funds my studies, is gratefully acknowl-
edged.
</bodyText>
<sectionHeader confidence="0.998624" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999447677419355">
R. Agerri, J.A. Barnden, M.G. Lee, and A.M. Walling-
ton. 2007. Metaphor, inference and domain-
independent mappings. In Proceedings of RANLP-
2007, pages 17–23, Borovets, Bulgaria.
A. Alonge and M. Castelli. 2003. Encoding informa-
tion on metaphoric expressions in WordNet-like re-
sources. In Proceedings of the ACL 2003 Workshop
on Lexicon and Figurative Language, pages 10–17.
J.A. Barnden and M.G. Lee. 2002. An artificial intelli-
gence approach to metaphor understanding. Theoria
etHistoria Scientiarum, 6(1):399–412.
J. Birke and A. Sarkar. 2006. A clustering approach
for the nearly unsupervised recognition of nonlit-
eral language. In In Proceedings of EACL-06, pages
329–336.
M. Black. 1962. Models and Metaphors. Cornell Uni-
versity Press.
L. Burnard. 2007. Reference Guide for the British Na-
tional Corpus (XML Edition).
A. Copestake and T. Briscoe. 1995. Semi-productive
polysemy and sense extension. Journal of Seman-
tics, 12:15–67.
A. Deignan. 2006. The grammar of linguistic
metaphors. In A. Stefanowitsch and S. T. Gries,
editors, Corpus-Based Approaches to Metaphor and
Metonymy, Berlin. Mouton de Gruyter.
D. Fass. 1991. met*: A method for discriminating
metonymy and metaphor by computer. Computa-
tional Linguistics, 17(1):49–90.
J. Feldman and S. Narayanan. 2004. Embodied mean-
ing in a neural theory of language. Brain and Lan-
guage, 89(2):385–392.
C. Fellbaum, editor. 1998. WordNet: An Electronic
Lexical Database (ISBN: 0-262-06197-X). MIT
Press, first edition.
C. J. Fillmore, C. R. Johnson, and M. R. L. Petruck.
2003. Background to FrameNet. International
Journal of Lexicography, 16(3):235–250.
M. Gedigan, J. Bryant, S. Narayanan, and B. Ciric.
2006. Catching metaphors. In In Proceedings of the
3rd Workshop on Scalable Natural Language Un-
derstanding, pages 41–48, New York.
D. Gentner. 1983. Structure mapping: A theoretical
framework for analogy. Cognitive Science, 7:155–
170.
R. Gibbs. 1984. Literal meaning and psychological
theory. Cognitive Science, 8:275–304.
A. Goatly. 1997. The Language of Metaphors. Rout-
ledge, London.
M. Hesse. 1966. Models and Analogies in Science.
Notre Dame University Press.
D. Hofstadter and M. Mitchell. 1994. The Copycat
Project: A model of mental fluidity and analogy-
making. In K.J. Holyoak and J. A. Barnden, editors,
Advances in Connectionist and Neural Computation
Theory, Ablex, New Jersey.
D. Hofstadter. 1995. Fluid Concepts and Creative
Analogies: Computer Models of the Fundamental
Mechanisms of Thought. HarperCollins Publishers.
Y. Karov and S. Edelman. 1998. Similarity-based
word sense disambiguation. Computational Lin-
guistics, 24(1):41–59.
</reference>
<page confidence="0.99832">
695
</page>
<bodyText confidence="0.452795428571429">
S. Narayanan. 1999. Moving right along: A computa-
tional model of metaphoric reasoning about events.
In Proceedings of AAAI 99), pages 121–128, Or-
lando, Florida.
P. Kingsbury and M. Palmer. 2002. From TreeBank
to PropBank. In Proceedings of LREC-2002, Gran
Canaria, Canary Islands, Spain.
</bodyText>
<reference confidence="0.999832525773195">
P. Koivisto-Alanko and H. Tissari. 2006. Sense
and sensibility: Rational thought versus emotion
in metaphorical language. In A. Stefanowitsch
and S. T. Gries, editors, Corpus-Based Approaches
to Metaphor and Metonymy, Berlin. Mouton de
Gruyter.
S. Krishnakumaran and X. Zhu. 2007. Hunting elusive
metaphors using lexical resources. In Proceedings
of the Workshop on Computational Approaches to
Figurative Language, pages 13–20, Rochester, NY.
G. Lakoff and M. Johnson. 1980. Metaphors We Live
By. University of Chicago Press, Chicago.
G. Lakoff, J. Espenson, and A. Schwartz. 1991. The
master metaphor list. Technical report, University
of California at Berkeley.
B. L¨onneker and C. Eilts. 2004. A Current Re-
source and Future Perspectives for Enriching Word-
Nets with Metaphor Information. In Proceedings
of the Second International WordNet Conference—
GWC 2004, pages 157–162, Brno, Czech Republic.
B. L¨onneker-Rodman. 2008. The hamburg metaphor
database project: issues in resource creation. Lan-
guage Resources and Evaluation, 42(3):293–318.
B. L¨onneker. 2004. Lexical databases as resources
for linguistic creativity: Focus on metaphor. In Pro-
ceedings of the LREC 2004 Workshop on Language
Resources for Linguistic Creativity, pages 9–16, Lis-
bon, Portugal.
J. H. Martin. 1988. Representing regularities in the
metaphoric lexicon. In Proceedings of the 12th con-
ference on Computational linguistics, pages 396–
401.
J. H. Martin. 1990. A Computational Model of
Metaphor Interpretation. Academic Press Profes-
sional, Inc., San Diego, CA, USA.
J. H. Martin. 1994. Metabank: A knowledge-base of
metaphoric language conventions. Computational
Intelligence, 10:134–149.
J. H. Martin. 2006. A corpus-based analysis of con-
text effects on metaphor comprehension. In A. Ste-
fanowitsch and S. T. Gries, editors, Corpus-Based
Approaches to Metaphor and Metonymy, Berlin.
Mouton de Gruyter.
Z. J. Mason. 2004. Cormet: a computational,
corpus-based conventional metaphor extraction sys-
tem. Computational Linguistics, 30(1):23–44.
S. Narayanan. 1997. Knowledge-based action repre-
sentations for metaphor and aspect (karma. Tech-
nical report, PhD thesis, University of California at
Berkeley.
G. Nunberg. 1987. Poetic and prosaic metaphors. In
Proceedings of the 1987 workshop on Theoretical
issues in natural language processing, pages 198–
201.
G. Orwell. 1946. Politics and the english language.
Horizon.
W. Peters and I. Peters. 2000. Lexicalised system-
atic polysemy in wordnet. In Proceedings of LREC
2000, Athens.
Pragglejaz Group. 2007. MIP: A method for iden-
tifying metaphorically used words in discourse.
Metaphor and Symbol, 22:1–39.
A. Reining and B. L¨onneker-Rodman. 2007. Corpus-
driven metaphor harvesting. In Proceedings of
the HLT/NAACL-07 Workshop on Computational
Approaches to Figurative Language, pages 5–12,
Rochester, New York.
P. Resnik. 1993. Selection and Information: A Class-
based Approach to Lexical Relationships. Ph.D. the-
sis, Philadelphia, PA, USA.
E. Shutova and S. Teufel. 2010. Metaphor corpus an-
notated for source - target domain mappings. In Pro-
ceedings of LREC 2010, Malta.
E. Shutova. 2010. Automatic metaphor interpretation
as a paraphrasing task. In Proceedings of NAACL
2010, Los Angeles, USA.
G. J. Steen. 2007. Finding metaphor in discourse:
Pragglejaz and beyond. Cultura, Lenguaje y Rep-
resentacion /Culture, Language and Representation
(CLR), Revista de Estudios Culturales de la Univer-
sitat Jaume I, 5:9–26.
A. Stefanowitsch. 2006. Corpus-based approaches
to metaphor and metonymy. In A. Stefanowitsch
and S. T. Gries, editors, Corpus-Based Approaches
to Metaphor and Metonymy, Berlin. Mouton de
Gruyter.
L. Sun and A. Korhonen. 2009. Improving verb clus-
tering with automatically acquired selectional pref-
erences. In Proceedings of EMNLP 2009, pages
638–647, Singapore, August.
R. Tourangeau and R. Sternberg. 1982. Understand-
ing and appreciating metaphors. Cognition, 11:203–
244.
T. Veale and Y. Hao. 2008. A fluid knowledge repre-
sentation for understanding and generating creative
metaphors. In Proceedings of COLING 2008, pages
945–952, Manchester, UK.
</reference>
<page confidence="0.985935">
696
</page>
<reference confidence="0.9984464">
A. M. Wallington, J. A. Barnden, P. Buchlovsky, L. Fel-
lows, and S. R. Glasbey. 2003. Metaphor annota-
tion: A systematic study. Technical report, School
of Computer Science, The University of Birming-
ham.
Y. Wilks. 1975. A preferential pattern-seeking seman-
tics for natural language inference. Artificial Intelli-
gence, 6:53–74.
Y. Wilks. 1978. Making preferences more active. Ar-
tificialIntelligence, 11(3):197–223.
</reference>
<page confidence="0.997801">
697
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.970730">
<title confidence="0.999813">Models of Metaphor in NLP</title>
<author confidence="0.999872">Ekaterina Shutova</author>
<affiliation confidence="0.999991">Computer Laboratory University of Cambridge</affiliation>
<address confidence="0.994619">15 JJ Thomson Avenue Cambridge CB3 0FD, UK</address>
<email confidence="0.983923">Ekaterina.Shutova@cl.cam.ac.uk</email>
<abstract confidence="0.999827357142857">Automatic processing of metaphor can be clearly divided into two subtasks: recognition between literal and metaphorical language in text) and interpretation (identifying the intended literal meaning of a metaphorical expression). Both of them have been repeatedly addressed in NLP. This paper is the first comprehensive and systematic review of the existing computational models of metaphor, the issues of metaphor annotation in corpora and the available resources.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Agerri</author>
<author>J A Barnden</author>
<author>M G Lee</author>
<author>A M Wallington</author>
</authors>
<title>Metaphor, inference and domainindependent mappings.</title>
<date>2007</date>
<booktitle>In Proceedings of RANLP2007,</booktitle>
<pages>17--23</pages>
<location>Borovets, Bulgaria.</location>
<contexts>
<context position="16310" citStr="Agerri et al., 2007" startWordPosition="2565" endWordPosition="2568">the system that answers users questions about Unix. The UC first tries to find a literal answer to the question. If it is not able to, it calls MIDAS which detects metaphorical expressions via selectional preference violation and searches its database for a metaphor explaining the anomaly in the question. Another cohort of approaches relies on performing inferences about entities and events in the source and target domains for metaphor interpretation. These include the KARMA system (Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004) and the ATT-Meta project (Barnden and Lee, 2002; Agerri et al., 2007). Within both systems the authors developed a metaphor-based reasoning framework in accordance with the theory of conceptual metaphor. The reasoning process relies on manually coded knowledge about the world and operates mainly in the source domain. The results are then projected onto the target domain using the conceptual mapping representation. The ATT-Meta project concerns metaphorical and metonymic description of mental states and reasoning about mental states using first order logic. Their system, however, does not take natural language sentences as input, but logical expressions that are</context>
<context position="20923" citStr="Agerri et al., 2007" startWordPosition="3288" endWordPosition="3291">for the lack of clear structuring principles of the mapping ontology (L¨onneker-Rodman, 2008). The taxonomical levels are often confused, and the same classes are referred to by different class labels. This fact and the chosen data representation in the Master Metaphor List make it not suitable for computational use. However, both the idea of the list and its actual mappings ontology inspired the creation of other metaphor resources. The most prominent of them are MetaBank (Martin, 1994) and the Mental Metaphor Databank4 created in the framework of the ATT-meta project (Barnden and Lee, 2002; Agerri et al., 2007). The MetaBank is a knowledge-base of English metaphorical conventions, represented in the form of metaphor maps (Martin, 1988) containing detailed information about source-target concept mappings backed by empirical evidence. The ATT-meta project databank contains a large number of examples of metaphors of mind classified by source–target domain mappings taken from the Master Metaphor List. Along with this it is worth mentioning metaphor resources in languages other than English. There has been a wealth of research on metaphor in Spanish, Chinese, Russian, German, French and Italian. The Hamb</context>
</contexts>
<marker>Agerri, Barnden, Lee, Wallington, 2007</marker>
<rawString>R. Agerri, J.A. Barnden, M.G. Lee, and A.M. Wallington. 2007. Metaphor, inference and domainindependent mappings. In Proceedings of RANLP2007, pages 17–23, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Alonge</author>
<author>M Castelli</author>
</authors>
<title>Encoding information on metaphoric expressions in WordNet-like resources.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL 2003 Workshop on Lexicon and Figurative Language,</booktitle>
<pages>10--17</pages>
<contexts>
<context position="21824" citStr="Alonge and Castelli (2003)" startWordPosition="3420" endWordPosition="3423">umber of examples of metaphors of mind classified by source–target domain mappings taken from the Master Metaphor List. Along with this it is worth mentioning metaphor resources in languages other than English. There has been a wealth of research on metaphor in Spanish, Chinese, Russian, German, French and Italian. The Hamburg Metaphor Database (L¨onneker, 2004; Reining and L¨onneker-Rodman, 2007) contains examples of metaphorical expressions in German and French, which are mapped to senses from EuroWordNet5 and annotated with source–target domain mappings taken from the Master Metaphor List. Alonge and Castelli (2003) discuss how metaphors can be represented in ItalWordNet for 4http://www.cs.bham.ac.uk/—jab/ATT-Meta/Databank/ 5EuroWordNet is a multilingual database with wordnets for several European languages (Dutch, Italian, Spanish, German, French, Czech and Estonian). The wordnets are structured in the same way as the Princeton WordNet for English. URL: http://www.illc.uva.nl/EuroWordNet/ 692 Italian and motivate this by linguistic evidence. Encoding metaphorical information in generaldomain lexical resources for English, e.g. WordNet (L¨onneker and Eilts, 2004), would undoubtedly provide a new platform</context>
</contexts>
<marker>Alonge, Castelli, 2003</marker>
<rawString>A. Alonge and M. Castelli. 2003. Encoding information on metaphoric expressions in WordNet-like resources. In Proceedings of the ACL 2003 Workshop on Lexicon and Figurative Language, pages 10–17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Barnden</author>
<author>M G Lee</author>
</authors>
<title>An artificial intelligence approach to metaphor understanding. Theoria etHistoria</title>
<date>2002</date>
<journal>Scientiarum,</journal>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="16288" citStr="Barnden and Lee, 2002" startWordPosition="2561" endWordPosition="2564"> Unix Consultant (UC), the system that answers users questions about Unix. The UC first tries to find a literal answer to the question. If it is not able to, it calls MIDAS which detects metaphorical expressions via selectional preference violation and searches its database for a metaphor explaining the anomaly in the question. Another cohort of approaches relies on performing inferences about entities and events in the source and target domains for metaphor interpretation. These include the KARMA system (Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004) and the ATT-Meta project (Barnden and Lee, 2002; Agerri et al., 2007). Within both systems the authors developed a metaphor-based reasoning framework in accordance with the theory of conceptual metaphor. The reasoning process relies on manually coded knowledge about the world and operates mainly in the source domain. The results are then projected onto the target domain using the conceptual mapping representation. The ATT-Meta project concerns metaphorical and metonymic description of mental states and reasoning about mental states using first order logic. Their system, however, does not take natural language sentences as input, but logica</context>
<context position="20901" citStr="Barnden and Lee, 2002" startWordPosition="3284" endWordPosition="3287">ce has been criticized for the lack of clear structuring principles of the mapping ontology (L¨onneker-Rodman, 2008). The taxonomical levels are often confused, and the same classes are referred to by different class labels. This fact and the chosen data representation in the Master Metaphor List make it not suitable for computational use. However, both the idea of the list and its actual mappings ontology inspired the creation of other metaphor resources. The most prominent of them are MetaBank (Martin, 1994) and the Mental Metaphor Databank4 created in the framework of the ATT-meta project (Barnden and Lee, 2002; Agerri et al., 2007). The MetaBank is a knowledge-base of English metaphorical conventions, represented in the form of metaphor maps (Martin, 1988) containing detailed information about source-target concept mappings backed by empirical evidence. The ATT-meta project databank contains a large number of examples of metaphors of mind classified by source–target domain mappings taken from the Master Metaphor List. Along with this it is worth mentioning metaphor resources in languages other than English. There has been a wealth of research on metaphor in Spanish, Chinese, Russian, German, French</context>
</contexts>
<marker>Barnden, Lee, 2002</marker>
<rawString>J.A. Barnden and M.G. Lee. 2002. An artificial intelligence approach to metaphor understanding. Theoria etHistoria Scientiarum, 6(1):399–412.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Birke</author>
<author>A Sarkar</author>
</authors>
<title>A clustering approach for the nearly unsupervised recognition of nonliteral language. In</title>
<date>2006</date>
<booktitle>In Proceedings of EACL-06,</booktitle>
<pages>329--336</pages>
<contexts>
<context position="11384" citStr="Birke and Sarkar (2006)" startWordPosition="1759" endWordPosition="1762">in both of which pour would be a characteristic verb. In the LAB domain pour has a strong selectional preference for objects of type liquid, whereas in the FINANCE domain it selects for money. From this Mason’s system infers the domain mapping FINANCE – LAB and the concept mapping money – liquid. He compares the output of his system against the Master Metaphor List (Lakoff et al., 1991) containing hand-crafted metaphorical mappings between concepts. Mason reports an accuracy of 77%, although it should be noted that as any evaluation that is done by hand it contains an element of subjectivity. Birke and Sarkar (2006) present a sentence clustering approach for non-literal language recognition implemented in the TroFi system (Trope Finder). This idea originates from a similaritybased word sense disambiguation method developed by Karov and Edelman (1998). The method employs a set of seed sentences, where the senses are annotated; computes similarity between the sentence containing the word to be disambiguated and all of the seed sentences and selects the sense corresponding to the annotation in the most similar seed sentences. Birke and Sarkar (2006) adapt this algorithm to perform a two-way classification: </context>
<context position="13166" citStr="Birke and Sarkar (2006)" startWordPosition="2050" endWordPosition="2053"> lexical items and annotated them with respect to metaphoricity. They used PropBank annotation (arguments and their semantic types) as features to train the classifier and report an accuracy of 95.12%. This result is, however, only a little higher than the performance of the naive baseline assigning majority class to all instances (92.90%). These numbers 690 can be explained by the fact that 92.00% of the verbs of MOTION and CURE in the Wall Street Journal corpus are used metaphorically, thus making the dataset unbalanced with respect to the target categories and the task notably easier. Both Birke and Sarkar (2006) and Gedigan et al. (2006) focus only on metaphors expressed by a verb. As opposed to that the approach of Krishnakumaran and Zhu (2007) deals with verbs, nouns and adjectives as parts of speech. They use hyponymy relation in WordNet and word bigram counts to predict metaphors at a sentence level. Given an IS-A metaphor (e.g. The world is a stage3) they verify if the two nouns involved are in hyponymy relation in WordNet, and if they are not then this sentence is tagged as containing a metaphor. Along with this they consider expressions containing a verb or an adjective used metaphorically (e.</context>
</contexts>
<marker>Birke, Sarkar, 2006</marker>
<rawString>J. Birke and A. Sarkar. 2006. A clustering approach for the nearly unsupervised recognition of nonliteral language. In In Proceedings of EACL-06, pages 329–336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Black</author>
</authors>
<title>Models and Metaphors.</title>
<date>1962</date>
<publisher>Cornell University Press.</publisher>
<contexts>
<context position="4721" citStr="Black, 1962" startWordPosition="708" endWordPosition="709">ssions in unrestricted text would become an invaluable component of any semantics-oriented NLP application. Automatic processing of metaphor can be clearly divided into two subtasks: metaphor recognition (distinguishing between literal and metaphorical language in text) and metaphor interpretation (identifying the intended literal meaning of a metaphorical expression). Both of them have been repeatedly addressed in NLP. 2 Theoretical Background Four different views on metaphor have been broadly discussed in linguistics and philosophy: the comparison view (Gentner, 1983), the interaction view (Black, 1962), (Hesse, 1966), the selectional restrictions violation view (Wilks, 1975; Wilks, 1978) and the conceptual metaphor view (Lakoff and Johnson, 1980)2. All of these approaches share the idea of an interconceptual mapping that underlies the production of metaphorical expressions. In other words, metaphor always involves two concepts or conceptual domains: the target (also called topic or tenor in the linguistics literature) and the source (or vehicle). Consider the examples in (5) and (6). (5) He shot down all of my arguments. (Lakoff and Johnson, 1980) (6) He attacked every weak point in my argu</context>
</contexts>
<marker>Black, 1962</marker>
<rawString>M. Black. 1962. Models and Metaphors. Cornell University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Burnard</author>
</authors>
<date>2007</date>
<booktitle>Reference Guide for the British National Corpus (XML Edition).</booktitle>
<contexts>
<context position="3845" citStr="Burnard, 2007" startWordPosition="580" endWordPosition="581">ery day, e.g. those in (2) and (3), to poetic and largely novel ones, such as (4). The use of metaphor is ubiquitous in natural language text and it is a serious bottleneck in automatic text understanding. 1“I wandered lonely as a cloud”, William Wordsworth, 1804. 688 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 688–697, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics In order to estimate the frequency of the phenomenon, Shutova (2010) conducted a corpus study on a subset of the British National Corpus (BNC) (Burnard, 2007) representing various genres. They manually annotated metaphorical expressions in this data and found that 241 out of 761 sentences contained a metaphor. Due to such a high frequency of their use, a system capable of recognizing and interpreting metaphorical expressions in unrestricted text would become an invaluable component of any semantics-oriented NLP application. Automatic processing of metaphor can be clearly divided into two subtasks: metaphor recognition (distinguishing between literal and metaphorical language in text) and metaphor interpretation (identifying the intended literal mea</context>
</contexts>
<marker>Burnard, 2007</marker>
<rawString>L. Burnard. 2007. Reference Guide for the British National Corpus (XML Edition).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Copestake</author>
<author>T Briscoe</author>
</authors>
<title>Semi-productive polysemy and sense extension.</title>
<date>1995</date>
<journal>Journal of Semantics,</journal>
<pages>12--15</pages>
<contexts>
<context position="24564" citStr="Copestake and Briscoe (1995)" startWordPosition="3817" endWordPosition="3820">quires a special imaginative leap. As time goes by, they become a part of general usage, their comprehension becomes more automatic, and their rhetorical effect is dulled” (Nunberg, 1987). Following Orwell (1946) Nunberg calls such metaphors “dead” and claims that they are not psychologically distinct from literally-used terms. This scheme demonstrates how metaphorical associations capture some generalisations governing polysemy: over time some of the aspects of the target domain are added to the meaning of a term in a source domain, resulting in a (metaphorical) sense extension of this term. Copestake and Briscoe (1995) discuss sense extension mainly based on metonymic examples and model the phenomenon using lexical rules encoding metonymic patterns. Along with this they suggest that similar mechanisms can be used to account for metaphoric processes, and the conceptual mappings encoded in the sense extension rules would define the limits to the possible shifts in meaning. However, it is often unclear if a metaphorical instance is a case of broadening of the sense in context due to general vagueness in language, or it manifests a formation of a new distinct metaphorical sense. Consider the following examples.</context>
</contexts>
<marker>Copestake, Briscoe, 1995</marker>
<rawString>A. Copestake and T. Briscoe. 1995. Semi-productive polysemy and sense extension. Journal of Semantics, 12:15–67.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Deignan</author>
</authors>
<title>The grammar of linguistic metaphors.</title>
<date>2006</date>
<booktitle>Corpus-Based Approaches to Metaphor and Metonymy,</booktitle>
<editor>In A. Stefanowitsch and S. T. Gries, editors,</editor>
<location>Berlin. Mouton</location>
<note>de Gruyter.</note>
<contexts>
<context position="22994" citStr="Deignan, 2006" startWordPosition="3581" endWordPosition="3582">), would undoubtedly provide a new platform for experiments and enable researchers to directly compare their results. 6 Metaphor Annotation in Corpora To reflect two distinct aspects of the phenomenon, metaphor annotation can be split into two stages: identifying metaphorical senses in text (akin word sense disambiguation) and annotating source – target domain mappings underlying the production of metaphorical expressions. Traditional approaches to metaphor annotation include manual search for lexical items used metaphorically (Pragglejaz Group, 2007), for source and target domain vocabulary (Deignan, 2006; Koivisto-Alanko and Tissari, 2006; Martin, 2006) or for linguistic markers of metaphor (Goatly, 1997). Although there is a consensus in the research community that the phenomenon of metaphor is not restricted to similarity-based extensions of meanings of isolated words, but rather involves reconceptualization of a whole area of experience in terms of another, there still has been surprisingly little interest in annotation of cross-domain mappings. However, a corpus annotated for conceptual mappings could provide a new starting point for both linguistic and cognitive experiments. 6.1 Metaphor</context>
</contexts>
<marker>Deignan, 2006</marker>
<rawString>A. Deignan. 2006. The grammar of linguistic metaphors. In A. Stefanowitsch and S. T. Gries, editors, Corpus-Based Approaches to Metaphor and Metonymy, Berlin. Mouton de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Fass</author>
</authors>
<title>met*: A method for discriminating metonymy and metaphor by computer.</title>
<date>1991</date>
<journal>Computational Linguistics,</journal>
<volume>17</volume>
<issue>1</issue>
<contexts>
<context position="1917" citStr="Fass, 1991" startWordPosition="274" endWordPosition="275">rence resolution, named entity recognition and many others. Another cohort of researchers set the goal of improving applicationbased statistical inference (e.g. for recognizing textual entailment or automatic summarization). In contrast, there have been fewer attempts to bring the state-of-the-art NLP technologies together to model the way humans use language to frame high-level reasoning processes, such as for example, creative thought. The majority of computational approaches to figurative language still exploit the ideas articulated three decades ago (Wilks, 1978; Lakoff and Johnson, 1980; Fass, 1991) and often rely on taskspecific hand-coded knowledge. However, recent work on lexical semantics and lexical acquisition techniques opens many new avenues for creation of fully automated models for recognition and interpretation of figurative language. In this paper I will focus on the phenomenon of metaphor and describe the most prominent computational approaches to metaphor, as well the issues of resource creation and metaphor annotation. Metaphors arise when one concept is viewed in terms of the properties of the other. In other words it is based on similarity between the concepts. Similarit</context>
<context position="7242" citStr="Fass (1991)" startWordPosition="1122" endWordPosition="1123">rding to Wilks, metaphors represent a violation of selectional restrictions in a given context. Selectional restrictions are the semantic constraints that a verb places onto its arguments. Consider the following example. (7) My car drinks gasoline. (Wilks, 1978) The verb drink normally takes an animate subject and a liquid object. Therefore, drink taking a car as a subject is an anomaly, which may in turn indicate the metaphorical use of drink. 3 Automatic Metaphor Recognition One of the first attempts to identify and interpret metaphorical expressions in text automatically is the approach of Fass (1991). It originates in the work of Wilks (1978) and utilizes handcoded knowledge. Fass (1991) developed a system called met*, capable of discriminating between literalness, metonymy, metaphor and anomaly. It does this in three stages. First, literalness is distinguished from non-literalness using selectional preference violation as an indicator. In the case that non-literalness is detected, the respective phrase is tested for being a metonymic relation using hand-coded patterns (such as CONTAINERfor-CONTENT). If the system fails to recognize metonymy, it proceeds to search the knowledge base for a</context>
<context position="14916" citStr="Fass (1991)" startWordPosition="2343" endWordPosition="2344">compared to a system extracting verb-object relations from parsed text. The authors evaluated their system on a set of example sentences compiled from the Master Metaphor List (Lakoff et al., 1991), whereby highly conventionalized metaphors (they call them dead metaphors) are taken to be negative examples. Thus they do not deal with literal examples as such: essentially, the distinction they are making is between the senses included in WordNet, even if they are conventional metaphors, and those not included in WordNet. 4 Automatic Metaphor Interpretation Almost simultaneously with the work of Fass (1991), Martin (1990) presents a Metaphor Interpretation, Denotation and Acquisition System (MIDAS). In this work Martin captures hierarchical organisation of conventional metaphors. The idea behind this is that the more specific conventional metaphors descend from the general ones. 3William Shakespeare Given an example of a metaphorical expression, MIDAS searches its database for a corresponding metaphor that would explain the anomaly. If it does not find any, it abstracts from the example to more general concepts and repeats the search. If it finds a suitable general metaphor, it creates a mapping</context>
<context position="19866" citStr="Fass, 1991" startWordPosition="3118" endWordPosition="3119">snik (1993) over the noun classes automatically produced by Sun and Korhonen (2009). Shutova (2010) tested their system only on metaphors expressed by a verb and report a paraphrasing accuracy of 0.81. 5 Metaphor Resources Metaphor is a knowledge-hungry phenomenon. Hence there is a need for either an extensive manually-created knowledge-base or a robust knowledge acquisition system for interpretation of metaphorical expressions. The latter being a hard task, a great deal of metaphor research resorted to the first option. Although hand-coded knowledge proved useful for metaphor interpretation (Fass, 1991; Martin, 1990), it should be noted that the systems utilizing it have a very limited coverage. One of the first attempts to create a multipurpose knowledge base of source–target domain mappings is the Master Metaphor List (Lakoff et al., 1991). It includes a classification of metaphorical mappings (mainly those related to mind, feelings and emotions) with the corresponding examples of language use. This resource has been criticized for the lack of clear structuring principles of the mapping ontology (L¨onneker-Rodman, 2008). The taxonomical levels are often confused, and the same classes are </context>
</contexts>
<marker>Fass, 1991</marker>
<rawString>D. Fass. 1991. met*: A method for discriminating metonymy and metaphor by computer. Computational Linguistics, 17(1):49–90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Feldman</author>
<author>S Narayanan</author>
</authors>
<title>Embodied meaning in a neural theory of language.</title>
<date>2004</date>
<journal>Brain and Language,</journal>
<volume>89</volume>
<issue>2</issue>
<contexts>
<context position="16240" citStr="Feldman and Narayanan, 2004" startWordPosition="2552" endWordPosition="2556">aphors are acquired. MIDAS has been integrated with the Unix Consultant (UC), the system that answers users questions about Unix. The UC first tries to find a literal answer to the question. If it is not able to, it calls MIDAS which detects metaphorical expressions via selectional preference violation and searches its database for a metaphor explaining the anomaly in the question. Another cohort of approaches relies on performing inferences about entities and events in the source and target domains for metaphor interpretation. These include the KARMA system (Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004) and the ATT-Meta project (Barnden and Lee, 2002; Agerri et al., 2007). Within both systems the authors developed a metaphor-based reasoning framework in accordance with the theory of conceptual metaphor. The reasoning process relies on manually coded knowledge about the world and operates mainly in the source domain. The results are then projected onto the target domain using the conceptual mapping representation. The ATT-Meta project concerns metaphorical and metonymic description of mental states and reasoning about mental states using first order logic. Their system, however, does not take</context>
</contexts>
<marker>Feldman, Narayanan, 2004</marker>
<rawString>J. Feldman and S. Narayanan. 2004. Embodied meaning in a neural theory of language. Brain and Language, 89(2):385–392.</rawString>
</citation>
<citation valid="true">
<date>1998</date>
<booktitle>WordNet: An Electronic Lexical Database (ISBN:</booktitle>
<pages>0--262</pages>
<editor>C. Fellbaum, editor.</editor>
<publisher>MIT Press,</publisher>
<note>first edition.</note>
<contexts>
<context position="11623" citStr="(1998)" startWordPosition="1798" endWordPosition="1798">B and the concept mapping money – liquid. He compares the output of his system against the Master Metaphor List (Lakoff et al., 1991) containing hand-crafted metaphorical mappings between concepts. Mason reports an accuracy of 77%, although it should be noted that as any evaluation that is done by hand it contains an element of subjectivity. Birke and Sarkar (2006) present a sentence clustering approach for non-literal language recognition implemented in the TroFi system (Trope Finder). This idea originates from a similaritybased word sense disambiguation method developed by Karov and Edelman (1998). The method employs a set of seed sentences, where the senses are annotated; computes similarity between the sentence containing the word to be disambiguated and all of the seed sentences and selects the sense corresponding to the annotation in the most similar seed sentences. Birke and Sarkar (2006) adapt this algorithm to perform a two-way classification: literal vs. non-literal, and they do not clearly define the kinds of tropes they aim to discover. They attain a performance of 53.8% in terms of f-score. The method of Gedigan et al. (2006) discriminates between literal and metaphorical us</context>
</contexts>
<marker>1998</marker>
<rawString>C. Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database (ISBN: 0-262-06197-X). MIT Press, first edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J Fillmore</author>
<author>C R Johnson</author>
<author>M R L Petruck</author>
</authors>
<title>Background to FrameNet.</title>
<date>2003</date>
<journal>International Journal of Lexicography,</journal>
<volume>16</volume>
<issue>3</issue>
<contexts>
<context position="12424" citStr="Fillmore et al., 2003" startWordPosition="1928" endWordPosition="1931">sentences and selects the sense corresponding to the annotation in the most similar seed sentences. Birke and Sarkar (2006) adapt this algorithm to perform a two-way classification: literal vs. non-literal, and they do not clearly define the kinds of tropes they aim to discover. They attain a performance of 53.8% in terms of f-score. The method of Gedigan et al. (2006) discriminates between literal and metaphorical use. They trained a maximum entropy classifier for this purpose. They obtained their data by extracting the lexical items whose frames are related to MOTION and CURE from FrameNet (Fillmore et al., 2003). Then they searched the PropBank Wall Street Journal corpus (Kingsbury and Palmer, 2002) for sentences containing such lexical items and annotated them with respect to metaphoricity. They used PropBank annotation (arguments and their semantic types) as features to train the classifier and report an accuracy of 95.12%. This result is, however, only a little higher than the performance of the naive baseline assigning majority class to all instances (92.90%). These numbers 690 can be explained by the fact that 92.00% of the verbs of MOTION and CURE in the Wall Street Journal corpus are used meta</context>
</contexts>
<marker>Fillmore, Johnson, Petruck, 2003</marker>
<rawString>C. J. Fillmore, C. R. Johnson, and M. R. L. Petruck. 2003. Background to FrameNet. International Journal of Lexicography, 16(3):235–250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Gedigan</author>
<author>J Bryant</author>
<author>S Narayanan</author>
<author>B Ciric</author>
</authors>
<title>Catching metaphors. In</title>
<date>2006</date>
<booktitle>In Proceedings of the 3rd Workshop on Scalable Natural Language Understanding,</booktitle>
<pages>41--48</pages>
<location>New York.</location>
<contexts>
<context position="12173" citStr="Gedigan et al. (2006)" startWordPosition="1887" endWordPosition="1890"> word sense disambiguation method developed by Karov and Edelman (1998). The method employs a set of seed sentences, where the senses are annotated; computes similarity between the sentence containing the word to be disambiguated and all of the seed sentences and selects the sense corresponding to the annotation in the most similar seed sentences. Birke and Sarkar (2006) adapt this algorithm to perform a two-way classification: literal vs. non-literal, and they do not clearly define the kinds of tropes they aim to discover. They attain a performance of 53.8% in terms of f-score. The method of Gedigan et al. (2006) discriminates between literal and metaphorical use. They trained a maximum entropy classifier for this purpose. They obtained their data by extracting the lexical items whose frames are related to MOTION and CURE from FrameNet (Fillmore et al., 2003). Then they searched the PropBank Wall Street Journal corpus (Kingsbury and Palmer, 2002) for sentences containing such lexical items and annotated them with respect to metaphoricity. They used PropBank annotation (arguments and their semantic types) as features to train the classifier and report an accuracy of 95.12%. This result is, however, onl</context>
</contexts>
<marker>Gedigan, Bryant, Narayanan, Ciric, 2006</marker>
<rawString>M. Gedigan, J. Bryant, S. Narayanan, and B. Ciric. 2006. Catching metaphors. In In Proceedings of the 3rd Workshop on Scalable Natural Language Understanding, pages 41–48, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gentner</author>
</authors>
<title>Structure mapping: A theoretical framework for analogy.</title>
<date>1983</date>
<journal>Cognitive Science,</journal>
<volume>7</volume>
<pages>170</pages>
<contexts>
<context position="4685" citStr="Gentner, 1983" startWordPosition="702" endWordPosition="703">ng and interpreting metaphorical expressions in unrestricted text would become an invaluable component of any semantics-oriented NLP application. Automatic processing of metaphor can be clearly divided into two subtasks: metaphor recognition (distinguishing between literal and metaphorical language in text) and metaphor interpretation (identifying the intended literal meaning of a metaphorical expression). Both of them have been repeatedly addressed in NLP. 2 Theoretical Background Four different views on metaphor have been broadly discussed in linguistics and philosophy: the comparison view (Gentner, 1983), the interaction view (Black, 1962), (Hesse, 1966), the selectional restrictions violation view (Wilks, 1975; Wilks, 1978) and the conceptual metaphor view (Lakoff and Johnson, 1980)2. All of these approaches share the idea of an interconceptual mapping that underlies the production of metaphorical expressions. In other words, metaphor always involves two concepts or conceptual domains: the target (also called topic or tenor in the linguistics literature) and the source (or vehicle). Consider the examples in (5) and (6). (5) He shot down all of my arguments. (Lakoff and Johnson, 1980) (6) He </context>
</contexts>
<marker>Gentner, 1983</marker>
<rawString>D. Gentner. 1983. Structure mapping: A theoretical framework for analogy. Cognitive Science, 7:155– 170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Gibbs</author>
</authors>
<title>Literal meaning and psychological theory.</title>
<date>1984</date>
<journal>Cognitive Science,</journal>
<pages>8--275</pages>
<contexts>
<context position="6324" citStr="Gibbs (1984)" startWordPosition="977" endWordPosition="978"> overview and criticism of these four views can be found in (Tourangeau and Sternberg, 1982). However, Lakoff and Johnson do not discuss how metaphors can be recognized in the linguistic data, which is the primary task in the automatic processing of metaphor. Although humans are highly capable of producing and comprehending metaphorical expressions, the task of distinguishing between literal and non-literal meanings and, therefore, identifying metaphor in text appears to be challenging. This is due to the variation in its use and external form, as well as a not clear-cut semantic distinction. Gibbs (1984) suggests that literal and figurative meanings are situated at the ends of a single continuum, along which metaphoricity and idiomaticity are spread. This makes demarcation of metaphorical and literal language fuzzy. So far, the most influential account of metaphor recognition is that of Wilks (1978). According to Wilks, metaphors represent a violation of selectional restrictions in a given context. Selectional restrictions are the semantic constraints that a verb places onto its arguments. Consider the following example. (7) My car drinks gasoline. (Wilks, 1978) The verb drink normally takes </context>
</contexts>
<marker>Gibbs, 1984</marker>
<rawString>R. Gibbs. 1984. Literal meaning and psychological theory. Cognitive Science, 8:275–304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Goatly</author>
</authors>
<title>The Language of Metaphors.</title>
<date>1997</date>
<location>Routledge, London.</location>
<contexts>
<context position="9438" citStr="Goatly (1997)" startWordPosition="1447" endWordPosition="1448">taphor in language. This means that some metaphorical senses are very common. As a result the system would extract selectional preference distributions skewed towards such conventional metaphorical senses of the verb or one of its arguments. Therefore, although some expressions may be fully metaphorical in nature, no selectional preference violation can be detected in their use. Another counterargument is bound to the fact that interpretation is always context dependent, e.g. the phrase all men are animals can be used metaphorically, however, without any violation of selectional restrictions. Goatly (1997) addresses the phenomenon of metaphor by identifying a set of linguistic cues indicating it. He gives examples of lexical patterns indicating the presence of a metaphorical expression, such as metaphorically speaking, utterly, completely, so to speak and, surprisingly, literally. Such cues would probably not be enough for metaphor extraction on their own, but could contribute to a more complex system. The work of Peters and Peters (2000) concentrates on detecting figurative language in lexical resources. They mine WordNet (Fellbaum, 1998) for the examples of systematic polysemy, which allows t</context>
<context position="23097" citStr="Goatly, 1997" startWordPosition="3597" endWordPosition="3598">their results. 6 Metaphor Annotation in Corpora To reflect two distinct aspects of the phenomenon, metaphor annotation can be split into two stages: identifying metaphorical senses in text (akin word sense disambiguation) and annotating source – target domain mappings underlying the production of metaphorical expressions. Traditional approaches to metaphor annotation include manual search for lexical items used metaphorically (Pragglejaz Group, 2007), for source and target domain vocabulary (Deignan, 2006; Koivisto-Alanko and Tissari, 2006; Martin, 2006) or for linguistic markers of metaphor (Goatly, 1997). Although there is a consensus in the research community that the phenomenon of metaphor is not restricted to similarity-based extensions of meanings of isolated words, but rather involves reconceptualization of a whole area of experience in terms of another, there still has been surprisingly little interest in annotation of cross-domain mappings. However, a corpus annotated for conceptual mappings could provide a new starting point for both linguistic and cognitive experiments. 6.1 Metaphor and Polysemy The theorists of metaphor distinguish between two kinds of metaphorical language: novel (</context>
</contexts>
<marker>Goatly, 1997</marker>
<rawString>A. Goatly. 1997. The Language of Metaphors. Routledge, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hesse</author>
</authors>
<title>Models and Analogies in Science.</title>
<date>1966</date>
<publisher>Notre Dame University Press.</publisher>
<contexts>
<context position="4736" citStr="Hesse, 1966" startWordPosition="710" endWordPosition="711">tricted text would become an invaluable component of any semantics-oriented NLP application. Automatic processing of metaphor can be clearly divided into two subtasks: metaphor recognition (distinguishing between literal and metaphorical language in text) and metaphor interpretation (identifying the intended literal meaning of a metaphorical expression). Both of them have been repeatedly addressed in NLP. 2 Theoretical Background Four different views on metaphor have been broadly discussed in linguistics and philosophy: the comparison view (Gentner, 1983), the interaction view (Black, 1962), (Hesse, 1966), the selectional restrictions violation view (Wilks, 1975; Wilks, 1978) and the conceptual metaphor view (Lakoff and Johnson, 1980)2. All of these approaches share the idea of an interconceptual mapping that underlies the production of metaphorical expressions. In other words, metaphor always involves two concepts or conceptual domains: the target (also called topic or tenor in the linguistics literature) and the source (or vehicle). Consider the examples in (5) and (6). (5) He shot down all of my arguments. (Lakoff and Johnson, 1980) (6) He attacked every weak point in my argument. (Lakoff a</context>
</contexts>
<marker>Hesse, 1966</marker>
<rawString>M. Hesse. 1966. Models and Analogies in Science. Notre Dame University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hofstadter</author>
<author>M Mitchell</author>
</authors>
<title>The Copycat Project: A model of mental fluidity and analogymaking.</title>
<date>1994</date>
<booktitle>Advances in Connectionist and Neural Computation Theory,</booktitle>
<editor>In K.J. Holyoak and J. A. Barnden, editors,</editor>
<location>Ablex, New Jersey.</location>
<contexts>
<context position="17784" citStr="Hofstadter and Mitchell, 1994" startWordPosition="2794" endWordPosition="2797">neration”, called Talking Points. Talking Points are a set of characteristics of concepts belonging to source and target domains and related facts about the world which the authors acquire automatically from WordNet and from the web. Talking Points are then organized in Slipnet, a framework that allows for a number of insertions, deletions and substitutions in definitions of such characteristics in order to establish a connection between the target and the source 691 concepts. This work builds on the idea of slippage in knowledge representation for understanding analogies in abstract domains (Hofstadter and Mitchell, 1994; Hofstadter, 1995). Below is an example demonstrating how slippage operates to explain the metaphor Make-up is a Western burqa. Make-up =&gt; � typically worn by women � expected to be worn by women � must be worn by women � must be worn by Muslim women Burqa &lt;= By doing insertions and substitutions the system arrives from the definition typically worn by women to that of must be worn by Muslim women, and thus establishes a link between the concepts of make-up and burqa. Veale and Hao (2008), however, did not evaluate to which extent their knowledge base of Talking Points and the associated reas</context>
</contexts>
<marker>Hofstadter, Mitchell, 1994</marker>
<rawString>D. Hofstadter and M. Mitchell. 1994. The Copycat Project: A model of mental fluidity and analogymaking. In K.J. Holyoak and J. A. Barnden, editors, Advances in Connectionist and Neural Computation Theory, Ablex, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hofstadter</author>
</authors>
<title>Fluid Concepts and Creative Analogies: Computer Models of the Fundamental Mechanisms of Thought.</title>
<date>1995</date>
<publisher>HarperCollins Publishers.</publisher>
<contexts>
<context position="17803" citStr="Hofstadter, 1995" startWordPosition="2798" endWordPosition="2799">s. Talking Points are a set of characteristics of concepts belonging to source and target domains and related facts about the world which the authors acquire automatically from WordNet and from the web. Talking Points are then organized in Slipnet, a framework that allows for a number of insertions, deletions and substitutions in definitions of such characteristics in order to establish a connection between the target and the source 691 concepts. This work builds on the idea of slippage in knowledge representation for understanding analogies in abstract domains (Hofstadter and Mitchell, 1994; Hofstadter, 1995). Below is an example demonstrating how slippage operates to explain the metaphor Make-up is a Western burqa. Make-up =&gt; � typically worn by women � expected to be worn by women � must be worn by women � must be worn by Muslim women Burqa &lt;= By doing insertions and substitutions the system arrives from the definition typically worn by women to that of must be worn by Muslim women, and thus establishes a link between the concepts of make-up and burqa. Veale and Hao (2008), however, did not evaluate to which extent their knowledge base of Talking Points and the associated reasoning framework are</context>
</contexts>
<marker>Hofstadter, 1995</marker>
<rawString>D. Hofstadter. 1995. Fluid Concepts and Creative Analogies: Computer Models of the Fundamental Mechanisms of Thought. HarperCollins Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Karov</author>
<author>S Edelman</author>
</authors>
<title>Similarity-based word sense disambiguation.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>1</issue>
<contexts>
<context position="11623" citStr="Karov and Edelman (1998)" startWordPosition="1795" endWordPosition="1798">pping FINANCE – LAB and the concept mapping money – liquid. He compares the output of his system against the Master Metaphor List (Lakoff et al., 1991) containing hand-crafted metaphorical mappings between concepts. Mason reports an accuracy of 77%, although it should be noted that as any evaluation that is done by hand it contains an element of subjectivity. Birke and Sarkar (2006) present a sentence clustering approach for non-literal language recognition implemented in the TroFi system (Trope Finder). This idea originates from a similaritybased word sense disambiguation method developed by Karov and Edelman (1998). The method employs a set of seed sentences, where the senses are annotated; computes similarity between the sentence containing the word to be disambiguated and all of the seed sentences and selects the sense corresponding to the annotation in the most similar seed sentences. Birke and Sarkar (2006) adapt this algorithm to perform a two-way classification: literal vs. non-literal, and they do not clearly define the kinds of tropes they aim to discover. They attain a performance of 53.8% in terms of f-score. The method of Gedigan et al. (2006) discriminates between literal and metaphorical us</context>
</contexts>
<marker>Karov, Edelman, 1998</marker>
<rawString>Y. Karov and S. Edelman. 1998. Similarity-based word sense disambiguation. Computational Linguistics, 24(1):41–59.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koivisto-Alanko</author>
<author>H Tissari</author>
</authors>
<title>Sense and sensibility: Rational thought versus emotion in metaphorical language.</title>
<date>2006</date>
<booktitle>Corpus-Based Approaches to Metaphor and Metonymy,</booktitle>
<editor>In A. Stefanowitsch and S. T. Gries, editors,</editor>
<location>Berlin. Mouton</location>
<note>de Gruyter.</note>
<contexts>
<context position="23029" citStr="Koivisto-Alanko and Tissari, 2006" startWordPosition="3583" endWordPosition="3587">tedly provide a new platform for experiments and enable researchers to directly compare their results. 6 Metaphor Annotation in Corpora To reflect two distinct aspects of the phenomenon, metaphor annotation can be split into two stages: identifying metaphorical senses in text (akin word sense disambiguation) and annotating source – target domain mappings underlying the production of metaphorical expressions. Traditional approaches to metaphor annotation include manual search for lexical items used metaphorically (Pragglejaz Group, 2007), for source and target domain vocabulary (Deignan, 2006; Koivisto-Alanko and Tissari, 2006; Martin, 2006) or for linguistic markers of metaphor (Goatly, 1997). Although there is a consensus in the research community that the phenomenon of metaphor is not restricted to similarity-based extensions of meanings of isolated words, but rather involves reconceptualization of a whole area of experience in terms of another, there still has been surprisingly little interest in annotation of cross-domain mappings. However, a corpus annotated for conceptual mappings could provide a new starting point for both linguistic and cognitive experiments. 6.1 Metaphor and Polysemy The theorists of meta</context>
</contexts>
<marker>Koivisto-Alanko, Tissari, 2006</marker>
<rawString>P. Koivisto-Alanko and H. Tissari. 2006. Sense and sensibility: Rational thought versus emotion in metaphorical language. In A. Stefanowitsch and S. T. Gries, editors, Corpus-Based Approaches to Metaphor and Metonymy, Berlin. Mouton de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Krishnakumaran</author>
<author>X Zhu</author>
</authors>
<title>Hunting elusive metaphors using lexical resources.</title>
<date>2007</date>
<booktitle>In Proceedings of the Workshop on Computational Approaches to Figurative Language,</booktitle>
<pages>13--20</pages>
<location>Rochester, NY.</location>
<contexts>
<context position="13302" citStr="Krishnakumaran and Zhu (2007)" startWordPosition="2074" endWordPosition="2078">) as features to train the classifier and report an accuracy of 95.12%. This result is, however, only a little higher than the performance of the naive baseline assigning majority class to all instances (92.90%). These numbers 690 can be explained by the fact that 92.00% of the verbs of MOTION and CURE in the Wall Street Journal corpus are used metaphorically, thus making the dataset unbalanced with respect to the target categories and the task notably easier. Both Birke and Sarkar (2006) and Gedigan et al. (2006) focus only on metaphors expressed by a verb. As opposed to that the approach of Krishnakumaran and Zhu (2007) deals with verbs, nouns and adjectives as parts of speech. They use hyponymy relation in WordNet and word bigram counts to predict metaphors at a sentence level. Given an IS-A metaphor (e.g. The world is a stage3) they verify if the two nouns involved are in hyponymy relation in WordNet, and if they are not then this sentence is tagged as containing a metaphor. Along with this they consider expressions containing a verb or an adjective used metaphorically (e.g. He planted good ideas in their minds or He has a fertile imagination). Hereby they calculate bigram probabilities of verb-noun and ad</context>
</contexts>
<marker>Krishnakumaran, Zhu, 2007</marker>
<rawString>S. Krishnakumaran and X. Zhu. 2007. Hunting elusive metaphors using lexical resources. In Proceedings of the Workshop on Computational Approaches to Figurative Language, pages 13–20, Rochester, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Lakoff</author>
<author>M Johnson</author>
</authors>
<title>Metaphors We Live By.</title>
<date>1980</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago.</location>
<contexts>
<context position="1904" citStr="Lakoff and Johnson, 1980" startWordPosition="270" endWordPosition="273">sentence (parsing), coreference resolution, named entity recognition and many others. Another cohort of researchers set the goal of improving applicationbased statistical inference (e.g. for recognizing textual entailment or automatic summarization). In contrast, there have been fewer attempts to bring the state-of-the-art NLP technologies together to model the way humans use language to frame high-level reasoning processes, such as for example, creative thought. The majority of computational approaches to figurative language still exploit the ideas articulated three decades ago (Wilks, 1978; Lakoff and Johnson, 1980; Fass, 1991) and often rely on taskspecific hand-coded knowledge. However, recent work on lexical semantics and lexical acquisition techniques opens many new avenues for creation of fully automated models for recognition and interpretation of figurative language. In this paper I will focus on the phenomenon of metaphor and describe the most prominent computational approaches to metaphor, as well the issues of resource creation and metaphor annotation. Metaphors arise when one concept is viewed in terms of the properties of the other. In other words it is based on similarity between the concep</context>
<context position="4868" citStr="Lakoff and Johnson, 1980" startWordPosition="727" endWordPosition="730">taphor can be clearly divided into two subtasks: metaphor recognition (distinguishing between literal and metaphorical language in text) and metaphor interpretation (identifying the intended literal meaning of a metaphorical expression). Both of them have been repeatedly addressed in NLP. 2 Theoretical Background Four different views on metaphor have been broadly discussed in linguistics and philosophy: the comparison view (Gentner, 1983), the interaction view (Black, 1962), (Hesse, 1966), the selectional restrictions violation view (Wilks, 1975; Wilks, 1978) and the conceptual metaphor view (Lakoff and Johnson, 1980)2. All of these approaches share the idea of an interconceptual mapping that underlies the production of metaphorical expressions. In other words, metaphor always involves two concepts or conceptual domains: the target (also called topic or tenor in the linguistics literature) and the source (or vehicle). Consider the examples in (5) and (6). (5) He shot down all of my arguments. (Lakoff and Johnson, 1980) (6) He attacked every weak point in my argument. (Lakoff and Johnson, 1980) According to Lakoff and Johnson (1980), a mapping of a concept of argument to that of war is employed here. The ar</context>
</contexts>
<marker>Lakoff, Johnson, 1980</marker>
<rawString>G. Lakoff and M. Johnson. 1980. Metaphors We Live By. University of Chicago Press, Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Lakoff</author>
<author>J Espenson</author>
<author>A Schwartz</author>
</authors>
<title>The master metaphor list.</title>
<date>1991</date>
<tech>Technical report,</tech>
<institution>University of California at Berkeley.</institution>
<contexts>
<context position="11150" citStr="Lakoff et al., 1991" startWordPosition="1721" endWordPosition="1724">s done by “finding systematic variations in domain-specific selectional preferences, which are inferred from large, dynamically mined Internet corpora”. For example, Mason collects texts from the LAB domain and the FINANCE domain, in both of which pour would be a characteristic verb. In the LAB domain pour has a strong selectional preference for objects of type liquid, whereas in the FINANCE domain it selects for money. From this Mason’s system infers the domain mapping FINANCE – LAB and the concept mapping money – liquid. He compares the output of his system against the Master Metaphor List (Lakoff et al., 1991) containing hand-crafted metaphorical mappings between concepts. Mason reports an accuracy of 77%, although it should be noted that as any evaluation that is done by hand it contains an element of subjectivity. Birke and Sarkar (2006) present a sentence clustering approach for non-literal language recognition implemented in the TroFi system (Trope Finder). This idea originates from a similaritybased word sense disambiguation method developed by Karov and Edelman (1998). The method employs a set of seed sentences, where the senses are annotated; computes similarity between the sentence containi</context>
<context position="14502" citStr="Lakoff et al., 1991" startWordPosition="2277" endWordPosition="2280"> of verb-noun and adjective-noun pairs (including the hyponyms/hypernyms of the noun in question). If the combination is not observed in the data with sufficient frequency, the system tags the sentence containing it as metaphorical. This idea is a modification of the selectional preference view of Wilks. However, by using bigram counts over verb-noun pairs Krishnakumaran and Zhu (2007) loose a great deal of information compared to a system extracting verb-object relations from parsed text. The authors evaluated their system on a set of example sentences compiled from the Master Metaphor List (Lakoff et al., 1991), whereby highly conventionalized metaphors (they call them dead metaphors) are taken to be negative examples. Thus they do not deal with literal examples as such: essentially, the distinction they are making is between the senses included in WordNet, even if they are conventional metaphors, and those not included in WordNet. 4 Automatic Metaphor Interpretation Almost simultaneously with the work of Fass (1991), Martin (1990) presents a Metaphor Interpretation, Denotation and Acquisition System (MIDAS). In this work Martin captures hierarchical organisation of conventional metaphors. The idea </context>
<context position="20110" citStr="Lakoff et al., 1991" startWordPosition="3157" endWordPosition="3160"> a knowledge-hungry phenomenon. Hence there is a need for either an extensive manually-created knowledge-base or a robust knowledge acquisition system for interpretation of metaphorical expressions. The latter being a hard task, a great deal of metaphor research resorted to the first option. Although hand-coded knowledge proved useful for metaphor interpretation (Fass, 1991; Martin, 1990), it should be noted that the systems utilizing it have a very limited coverage. One of the first attempts to create a multipurpose knowledge base of source–target domain mappings is the Master Metaphor List (Lakoff et al., 1991). It includes a classification of metaphorical mappings (mainly those related to mind, feelings and emotions) with the corresponding examples of language use. This resource has been criticized for the lack of clear structuring principles of the mapping ontology (L¨onneker-Rodman, 2008). The taxonomical levels are often confused, and the same classes are referred to by different class labels. This fact and the chosen data representation in the Master Metaphor List make it not suitable for computational use. However, both the idea of the list and its actual mappings ontology inspired the creatio</context>
</contexts>
<marker>Lakoff, Espenson, Schwartz, 1991</marker>
<rawString>G. Lakoff, J. Espenson, and A. Schwartz. 1991. The master metaphor list. Technical report, University of California at Berkeley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B L¨onneker</author>
<author>C Eilts</author>
</authors>
<title>A Current Resource and Future Perspectives for Enriching WordNets with Metaphor Information.</title>
<date>2004</date>
<booktitle>In Proceedings of the Second International WordNet Conference— GWC 2004,</booktitle>
<pages>157--162</pages>
<location>Brno, Czech Republic.</location>
<marker>L¨onneker, Eilts, 2004</marker>
<rawString>B. L¨onneker and C. Eilts. 2004. A Current Resource and Future Perspectives for Enriching WordNets with Metaphor Information. In Proceedings of the Second International WordNet Conference— GWC 2004, pages 157–162, Brno, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B L¨onneker-Rodman</author>
</authors>
<title>The hamburg metaphor database project: issues in resource creation.</title>
<date>2008</date>
<journal>Language Resources and Evaluation,</journal>
<volume>42</volume>
<issue>3</issue>
<marker>L¨onneker-Rodman, 2008</marker>
<rawString>B. L¨onneker-Rodman. 2008. The hamburg metaphor database project: issues in resource creation. Language Resources and Evaluation, 42(3):293–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B L¨onneker</author>
</authors>
<title>Lexical databases as resources for linguistic creativity: Focus on metaphor.</title>
<date>2004</date>
<booktitle>In Proceedings of the LREC 2004 Workshop on Language Resources for Linguistic Creativity,</booktitle>
<pages>9--16</pages>
<location>Lisbon, Portugal.</location>
<marker>L¨onneker, 2004</marker>
<rawString>B. L¨onneker. 2004. Lexical databases as resources for linguistic creativity: Focus on metaphor. In Proceedings of the LREC 2004 Workshop on Language Resources for Linguistic Creativity, pages 9–16, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J H Martin</author>
</authors>
<title>Representing regularities in the metaphoric lexicon.</title>
<date>1988</date>
<booktitle>In Proceedings of the 12th conference on Computational linguistics,</booktitle>
<pages>396--401</pages>
<contexts>
<context position="2719" citStr="Martin, 1988" startWordPosition="403" endWordPosition="404">els for recognition and interpretation of figurative language. In this paper I will focus on the phenomenon of metaphor and describe the most prominent computational approaches to metaphor, as well the issues of resource creation and metaphor annotation. Metaphors arise when one concept is viewed in terms of the properties of the other. In other words it is based on similarity between the concepts. Similarity is a kind of association implying the presence of characteristics in common. Here are some examples of metaphor. (1) Hillary brushed aside the accusations. (2) How can I kill a process? (Martin, 1988) (3) I invested myself fully in this relationship. (4) And then my heart with pleasure fills, And dances with the daffodils.1 In metaphorical expressions seemingly unrelated features of one concept are associated with another concept. In the example (2) the computational process is viewed as something alive and, therefore, its forced termination is associated with the act of killing. Metaphorical expressions represent a great variety, ranging from conventional metaphors, which we reproduce and comprehend every day, e.g. those in (2) and (3), to poetic and largely novel ones, such as (4). The u</context>
<context position="21050" citStr="Martin, 1988" startWordPosition="3309" endWordPosition="3310">ed, and the same classes are referred to by different class labels. This fact and the chosen data representation in the Master Metaphor List make it not suitable for computational use. However, both the idea of the list and its actual mappings ontology inspired the creation of other metaphor resources. The most prominent of them are MetaBank (Martin, 1994) and the Mental Metaphor Databank4 created in the framework of the ATT-meta project (Barnden and Lee, 2002; Agerri et al., 2007). The MetaBank is a knowledge-base of English metaphorical conventions, represented in the form of metaphor maps (Martin, 1988) containing detailed information about source-target concept mappings backed by empirical evidence. The ATT-meta project databank contains a large number of examples of metaphors of mind classified by source–target domain mappings taken from the Master Metaphor List. Along with this it is worth mentioning metaphor resources in languages other than English. There has been a wealth of research on metaphor in Spanish, Chinese, Russian, German, French and Italian. The Hamburg Metaphor Database (L¨onneker, 2004; Reining and L¨onneker-Rodman, 2007) contains examples of metaphorical expressions in Ge</context>
</contexts>
<marker>Martin, 1988</marker>
<rawString>J. H. Martin. 1988. Representing regularities in the metaphoric lexicon. In Proceedings of the 12th conference on Computational linguistics, pages 396– 401.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J H Martin</author>
</authors>
<title>A Computational Model of Metaphor Interpretation.</title>
<date>1990</date>
<publisher>Academic Press Professional, Inc.,</publisher>
<location>San Diego, CA, USA.</location>
<contexts>
<context position="14931" citStr="Martin (1990)" startWordPosition="2345" endWordPosition="2346"> system extracting verb-object relations from parsed text. The authors evaluated their system on a set of example sentences compiled from the Master Metaphor List (Lakoff et al., 1991), whereby highly conventionalized metaphors (they call them dead metaphors) are taken to be negative examples. Thus they do not deal with literal examples as such: essentially, the distinction they are making is between the senses included in WordNet, even if they are conventional metaphors, and those not included in WordNet. 4 Automatic Metaphor Interpretation Almost simultaneously with the work of Fass (1991), Martin (1990) presents a Metaphor Interpretation, Denotation and Acquisition System (MIDAS). In this work Martin captures hierarchical organisation of conventional metaphors. The idea behind this is that the more specific conventional metaphors descend from the general ones. 3William Shakespeare Given an example of a metaphorical expression, MIDAS searches its database for a corresponding metaphor that would explain the anomaly. If it does not find any, it abstracts from the example to more general concepts and repeats the search. If it finds a suitable general metaphor, it creates a mapping for its descen</context>
<context position="19881" citStr="Martin, 1990" startWordPosition="3120" endWordPosition="3121">over the noun classes automatically produced by Sun and Korhonen (2009). Shutova (2010) tested their system only on metaphors expressed by a verb and report a paraphrasing accuracy of 0.81. 5 Metaphor Resources Metaphor is a knowledge-hungry phenomenon. Hence there is a need for either an extensive manually-created knowledge-base or a robust knowledge acquisition system for interpretation of metaphorical expressions. The latter being a hard task, a great deal of metaphor research resorted to the first option. Although hand-coded knowledge proved useful for metaphor interpretation (Fass, 1991; Martin, 1990), it should be noted that the systems utilizing it have a very limited coverage. One of the first attempts to create a multipurpose knowledge base of source–target domain mappings is the Master Metaphor List (Lakoff et al., 1991). It includes a classification of metaphorical mappings (mainly those related to mind, feelings and emotions) with the corresponding examples of language use. This resource has been criticized for the lack of clear structuring principles of the mapping ontology (L¨onneker-Rodman, 2008). The taxonomical levels are often confused, and the same classes are referred to by </context>
</contexts>
<marker>Martin, 1990</marker>
<rawString>J. H. Martin. 1990. A Computational Model of Metaphor Interpretation. Academic Press Professional, Inc., San Diego, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J H Martin</author>
</authors>
<title>Metabank: A knowledge-base of metaphoric language conventions.</title>
<date>1994</date>
<journal>Computational Intelligence,</journal>
<pages>10--134</pages>
<contexts>
<context position="20795" citStr="Martin, 1994" startWordPosition="3268" endWordPosition="3269">lated to mind, feelings and emotions) with the corresponding examples of language use. This resource has been criticized for the lack of clear structuring principles of the mapping ontology (L¨onneker-Rodman, 2008). The taxonomical levels are often confused, and the same classes are referred to by different class labels. This fact and the chosen data representation in the Master Metaphor List make it not suitable for computational use. However, both the idea of the list and its actual mappings ontology inspired the creation of other metaphor resources. The most prominent of them are MetaBank (Martin, 1994) and the Mental Metaphor Databank4 created in the framework of the ATT-meta project (Barnden and Lee, 2002; Agerri et al., 2007). The MetaBank is a knowledge-base of English metaphorical conventions, represented in the form of metaphor maps (Martin, 1988) containing detailed information about source-target concept mappings backed by empirical evidence. The ATT-meta project databank contains a large number of examples of metaphors of mind classified by source–target domain mappings taken from the Master Metaphor List. Along with this it is worth mentioning metaphor resources in languages other </context>
</contexts>
<marker>Martin, 1994</marker>
<rawString>J. H. Martin. 1994. Metabank: A knowledge-base of metaphoric language conventions. Computational Intelligence, 10:134–149.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J H Martin</author>
</authors>
<title>A corpus-based analysis of context effects on metaphor comprehension.</title>
<date>2006</date>
<booktitle>Corpus-Based Approaches to Metaphor and Metonymy,</booktitle>
<editor>In A. Stefanowitsch and S. T. Gries, editors,</editor>
<location>Berlin. Mouton</location>
<note>de Gruyter.</note>
<contexts>
<context position="23044" citStr="Martin, 2006" startWordPosition="3588" endWordPosition="3589">periments and enable researchers to directly compare their results. 6 Metaphor Annotation in Corpora To reflect two distinct aspects of the phenomenon, metaphor annotation can be split into two stages: identifying metaphorical senses in text (akin word sense disambiguation) and annotating source – target domain mappings underlying the production of metaphorical expressions. Traditional approaches to metaphor annotation include manual search for lexical items used metaphorically (Pragglejaz Group, 2007), for source and target domain vocabulary (Deignan, 2006; Koivisto-Alanko and Tissari, 2006; Martin, 2006) or for linguistic markers of metaphor (Goatly, 1997). Although there is a consensus in the research community that the phenomenon of metaphor is not restricted to similarity-based extensions of meanings of isolated words, but rather involves reconceptualization of a whole area of experience in terms of another, there still has been surprisingly little interest in annotation of cross-domain mappings. However, a corpus annotated for conceptual mappings could provide a new starting point for both linguistic and cognitive experiments. 6.1 Metaphor and Polysemy The theorists of metaphor distinguis</context>
<context position="27713" citStr="Martin (2006)" startWordPosition="4329" endWordPosition="4330">ed to vague); (4) historically older. 2. If you can establish the basic meaning that is distinct from the meaning of the verb in this context, the verb is likely to be used metaphorically. Such annotation can be viewed as a form of word sense disambiguation with an emphasis on metaphoricity. 6.2.2 Source – Target Domain Vocabulary Another popular method that has been used to extract metaphors is searching for sentences containing lexical items from the source domain, the target domain, or both (Stefanowitsch, 2006). This method requires exhaustive lists of source and target domain vocabulary. Martin (2006) conducted a corpus study in order to confirm that metaphorical expressions occur in text in contexts containing such lexical items. He performed his analysis on the data from the Wall Street Journal (WSJ) corpus and focused on four conceptual metaphors that occur with considerable regularity in the corpus. These include NUMERICAL VALUE AS LOCATION, COMMERCIAL ACTIVITY AS CONTAINER, COMMERCIAL ACTIVITY AS PATH FOLLOWING and COMMERCIAL ACTIVITY AS WAR. Martin manually compiled the lists of terms characteristic for each domain by examining sampled metaphors of these types and then augmented them</context>
</contexts>
<marker>Martin, 2006</marker>
<rawString>J. H. Martin. 2006. A corpus-based analysis of context effects on metaphor comprehension. In A. Stefanowitsch and S. T. Gries, editors, Corpus-Based Approaches to Metaphor and Metonymy, Berlin. Mouton de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z J Mason</author>
</authors>
<title>Cormet: a computational, corpus-based conventional metaphor extraction system.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>1</issue>
<contexts>
<context position="10445" citStr="Mason, 2004" startWordPosition="1608" endWordPosition="1609">x system. The work of Peters and Peters (2000) concentrates on detecting figurative language in lexical resources. They mine WordNet (Fellbaum, 1998) for the examples of systematic polysemy, which allows to capture metonymic and metaphorical relations. The authors search for nodes that are relatively high up in the WordNet hierarchy and that share a set of common word forms among their descendants. Peters and Peters found that such nodes often happen to be in metonymic (e.g. publication – publisher) or metaphorical (e.g. supporting structure – theory) relation. The CorMet system discussed in (Mason, 2004) is the first attempt to discover source-target domain mappings automatically. This is done by “finding systematic variations in domain-specific selectional preferences, which are inferred from large, dynamically mined Internet corpora”. For example, Mason collects texts from the LAB domain and the FINANCE domain, in both of which pour would be a characteristic verb. In the LAB domain pour has a strong selectional preference for objects of type liquid, whereas in the FINANCE domain it selects for money. From this Mason’s system infers the domain mapping FINANCE – LAB and the concept mapping mo</context>
</contexts>
<marker>Mason, 2004</marker>
<rawString>Z. J. Mason. 2004. Cormet: a computational, corpus-based conventional metaphor extraction system. Computational Linguistics, 30(1):23–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Narayanan</author>
</authors>
<title>Knowledge-based action representations for metaphor and aspect (karma.</title>
<date>1997</date>
<tech>Technical report, PhD thesis,</tech>
<institution>University of California at Berkeley.</institution>
<contexts>
<context position="16193" citStr="Narayanan, 1997" startWordPosition="2548" endWordPosition="2549">xample. This is also how novel metaphors are acquired. MIDAS has been integrated with the Unix Consultant (UC), the system that answers users questions about Unix. The UC first tries to find a literal answer to the question. If it is not able to, it calls MIDAS which detects metaphorical expressions via selectional preference violation and searches its database for a metaphor explaining the anomaly in the question. Another cohort of approaches relies on performing inferences about entities and events in the source and target domains for metaphor interpretation. These include the KARMA system (Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004) and the ATT-Meta project (Barnden and Lee, 2002; Agerri et al., 2007). Within both systems the authors developed a metaphor-based reasoning framework in accordance with the theory of conceptual metaphor. The reasoning process relies on manually coded knowledge about the world and operates mainly in the source domain. The results are then projected onto the target domain using the conceptual mapping representation. The ATT-Meta project concerns metaphorical and metonymic description of mental states and reasoning about mental states using first or</context>
</contexts>
<marker>Narayanan, 1997</marker>
<rawString>S. Narayanan. 1997. Knowledge-based action representations for metaphor and aspect (karma. Technical report, PhD thesis, University of California at Berkeley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Nunberg</author>
</authors>
<title>Poetic and prosaic metaphors.</title>
<date>1987</date>
<booktitle>In Proceedings of the 1987 workshop on Theoretical issues in natural language processing,</booktitle>
<pages>198--201</pages>
<contexts>
<context position="24123" citStr="Nunberg, 1987" startWordPosition="3752" endWordPosition="3753">vide a new starting point for both linguistic and cognitive experiments. 6.1 Metaphor and Polysemy The theorists of metaphor distinguish between two kinds of metaphorical language: novel (or poetic) metaphors, that surprise our imagination, and conventionalized metaphors, that become a part of an ordinary discourse. “Metaphors begin their lives as novel poetic creations with marked rhetorical effects, whose comprehension requires a special imaginative leap. As time goes by, they become a part of general usage, their comprehension becomes more automatic, and their rhetorical effect is dulled” (Nunberg, 1987). Following Orwell (1946) Nunberg calls such metaphors “dead” and claims that they are not psychologically distinct from literally-used terms. This scheme demonstrates how metaphorical associations capture some generalisations governing polysemy: over time some of the aspects of the target domain are added to the meaning of a term in a source domain, resulting in a (metaphorical) sense extension of this term. Copestake and Briscoe (1995) discuss sense extension mainly based on metonymic examples and model the phenomenon using lexical rules encoding metonymic patterns. Along with this they sugg</context>
</contexts>
<marker>Nunberg, 1987</marker>
<rawString>G. Nunberg. 1987. Poetic and prosaic metaphors. In Proceedings of the 1987 workshop on Theoretical issues in natural language processing, pages 198– 201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Orwell</author>
</authors>
<title>Politics and the english language.</title>
<date>1946</date>
<journal>Horizon.</journal>
<contexts>
<context position="24148" citStr="Orwell (1946)" startWordPosition="3755" endWordPosition="3756">for both linguistic and cognitive experiments. 6.1 Metaphor and Polysemy The theorists of metaphor distinguish between two kinds of metaphorical language: novel (or poetic) metaphors, that surprise our imagination, and conventionalized metaphors, that become a part of an ordinary discourse. “Metaphors begin their lives as novel poetic creations with marked rhetorical effects, whose comprehension requires a special imaginative leap. As time goes by, they become a part of general usage, their comprehension becomes more automatic, and their rhetorical effect is dulled” (Nunberg, 1987). Following Orwell (1946) Nunberg calls such metaphors “dead” and claims that they are not psychologically distinct from literally-used terms. This scheme demonstrates how metaphorical associations capture some generalisations governing polysemy: over time some of the aspects of the target domain are added to the meaning of a term in a source domain, resulting in a (metaphorical) sense extension of this term. Copestake and Briscoe (1995) discuss sense extension mainly based on metonymic examples and model the phenomenon using lexical rules encoding metonymic patterns. Along with this they suggest that similar mechanis</context>
</contexts>
<marker>Orwell, 1946</marker>
<rawString>G. Orwell. 1946. Politics and the english language. Horizon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Peters</author>
<author>I Peters</author>
</authors>
<title>Lexicalised systematic polysemy in wordnet.</title>
<date>2000</date>
<booktitle>In Proceedings of LREC 2000,</booktitle>
<location>Athens.</location>
<contexts>
<context position="9879" citStr="Peters and Peters (2000)" startWordPosition="1516" endWordPosition="1519">t interpretation is always context dependent, e.g. the phrase all men are animals can be used metaphorically, however, without any violation of selectional restrictions. Goatly (1997) addresses the phenomenon of metaphor by identifying a set of linguistic cues indicating it. He gives examples of lexical patterns indicating the presence of a metaphorical expression, such as metaphorically speaking, utterly, completely, so to speak and, surprisingly, literally. Such cues would probably not be enough for metaphor extraction on their own, but could contribute to a more complex system. The work of Peters and Peters (2000) concentrates on detecting figurative language in lexical resources. They mine WordNet (Fellbaum, 1998) for the examples of systematic polysemy, which allows to capture metonymic and metaphorical relations. The authors search for nodes that are relatively high up in the WordNet hierarchy and that share a set of common word forms among their descendants. Peters and Peters found that such nodes often happen to be in metonymic (e.g. publication – publisher) or metaphorical (e.g. supporting structure – theory) relation. The CorMet system discussed in (Mason, 2004) is the first attempt to discover </context>
</contexts>
<marker>Peters, Peters, 2000</marker>
<rawString>W. Peters and I. Peters. 2000. Lexicalised systematic polysemy in wordnet. In Proceedings of LREC 2000, Athens.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pragglejaz Group</author>
</authors>
<title>MIP: A method for identifying metaphorically used words in discourse.</title>
<date>2007</date>
<booktitle>Metaphor and Symbol,</booktitle>
<pages>22--1</pages>
<contexts>
<context position="22938" citStr="Group, 2007" startWordPosition="3572" endWordPosition="3573">es for English, e.g. WordNet (L¨onneker and Eilts, 2004), would undoubtedly provide a new platform for experiments and enable researchers to directly compare their results. 6 Metaphor Annotation in Corpora To reflect two distinct aspects of the phenomenon, metaphor annotation can be split into two stages: identifying metaphorical senses in text (akin word sense disambiguation) and annotating source – target domain mappings underlying the production of metaphorical expressions. Traditional approaches to metaphor annotation include manual search for lexical items used metaphorically (Pragglejaz Group, 2007), for source and target domain vocabulary (Deignan, 2006; Koivisto-Alanko and Tissari, 2006; Martin, 2006) or for linguistic markers of metaphor (Goatly, 1997). Although there is a consensus in the research community that the phenomenon of metaphor is not restricted to similarity-based extensions of meanings of isolated words, but rather involves reconceptualization of a whole area of experience in terms of another, there still has been surprisingly little interest in annotation of cross-domain mappings. However, a corpus annotated for conceptual mappings could provide a new starting point for</context>
<context position="26361" citStr="Group (2007)" startWordPosition="4112" endWordPosition="4113">en over time. The sentence (9a) exemplifies the basic sense of cold – “of a temperature sensibly lower than that of the living human body”, whereas cold in (9b) should be interpreted metaphorically as “void of ardour, warmth, or intensity of feeling; lacking enthusiasm, heartiness, or zeal; indifferent, apathetic”. These two senses are clearly linked via the metaphoric mapping between EMOTIONAL STATES and TEMPERATURES. A number of metaphorical senses are included in WordNet, however without any accompanying semantic annotation. 6.2 Metaphor Identification 6.2.1 Pragglejaz Procedure Pragglejaz Group (2007) proposes a metaphor identification procedure (MIP) within the frame6Sense definitions are taken from the Oxford English Dictionary. 693 work of the Metaphor in Discourse project (Steen, 2007). The procedure involves metaphor annotation at the word level as opposed to identifying metaphorical relations (between words) or source– target domain mappings (between concepts or domains). In order to discriminate between the verbs used metaphorically and literally the annotators are asked to follow the guidelines: 1. For each verb establish its meaning in context and try to imagine a more basic meani</context>
</contexts>
<marker>Group, 2007</marker>
<rawString>Pragglejaz Group. 2007. MIP: A method for identifying metaphorically used words in discourse. Metaphor and Symbol, 22:1–39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Reining</author>
<author>B L¨onneker-Rodman</author>
</authors>
<title>Corpusdriven metaphor harvesting.</title>
<date>2007</date>
<booktitle>In Proceedings of the HLT/NAACL-07 Workshop on Computational Approaches to Figurative Language,</booktitle>
<pages>5--12</pages>
<location>Rochester, New York.</location>
<marker>Reining, L¨onneker-Rodman, 2007</marker>
<rawString>A. Reining and B. L¨onneker-Rodman. 2007. Corpusdriven metaphor harvesting. In Proceedings of the HLT/NAACL-07 Workshop on Computational Approaches to Figurative Language, pages 5–12, Rochester, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Resnik</author>
</authors>
<title>Selection and Information: A Classbased Approach to Lexical Relationships.</title>
<date>1993</date>
<tech>Ph.D. thesis,</tech>
<location>Philadelphia, PA, USA.</location>
<contexts>
<context position="19267" citStr="Resnik (1993)" startWordPosition="3028" endWordPosition="3029">he metaphors in “All of this stirred an unfathomable excitement in her” or “a carelessly leaked report” their system produces interpretations “All of this provoked an unfathomable excitement in her” and “a carelessly disclosed report” respectively. They first apply a probabilistic model to rank all possible paraphrases for the metaphorical expression given the context; and then use automatically induced selectional preferences to discriminate between figurative and literal paraphrases. The selectional preference distribution is defined in terms of selectional association measure introduced by Resnik (1993) over the noun classes automatically produced by Sun and Korhonen (2009). Shutova (2010) tested their system only on metaphors expressed by a verb and report a paraphrasing accuracy of 0.81. 5 Metaphor Resources Metaphor is a knowledge-hungry phenomenon. Hence there is a need for either an extensive manually-created knowledge-base or a robust knowledge acquisition system for interpretation of metaphorical expressions. The latter being a hard task, a great deal of metaphor research resorted to the first option. Although hand-coded knowledge proved useful for metaphor interpretation (Fass, 1991;</context>
</contexts>
<marker>Resnik, 1993</marker>
<rawString>P. Resnik. 1993. Selection and Information: A Classbased Approach to Lexical Relationships. Ph.D. thesis, Philadelphia, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Shutova</author>
<author>S Teufel</author>
</authors>
<title>Metaphor corpus annotated for source - target domain mappings.</title>
<date>2010</date>
<booktitle>In Proceedings of LREC</booktitle>
<contexts>
<context position="29978" citStr="Shutova and Teufel (2010)" startWordPosition="4687" endWordPosition="4690">t with a similar syntactic frame, (3) this physical significance was related to the abstract one. Team B had to annotate phrases according to their own intuitive definition of metaphor. Besides metaphorical expressions Wallington et al. (2003) attempted to annotate the involved source – target domain mappings. The annotators were given a set of mappings from the Master Metaphor List and were asked to assign the most suitable ones to the examples. However, the authors do not report the level of interannotator agreement nor the coverage of the mappings in the Master Metaphor List on their data. Shutova and Teufel (2010) adopt a different approach to the annotation of source – target domain mappings. They do not rely on predefined mappings, but instead derive independent sets of most common source and target categories. They propose a two stage procedure, whereby the metaphorical expressions are first identified using MIP, and then the source domain (where the basic sense comes from) and the target domain (the given context) are selected from the lists of categories. Shutova and Teufel (2010) report interannotator agreement of 0.61 (r.). 7 Conclusion and Future Directions The eighties and nineties provided us</context>
</contexts>
<marker>Shutova, Teufel, 2010</marker>
<rawString>E. Shutova and S. Teufel. 2010. Metaphor corpus annotated for source - target domain mappings. In Proceedings of LREC 2010, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Shutova</author>
</authors>
<title>Automatic metaphor interpretation as a paraphrasing task.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL 2010,</booktitle>
<location>Los Angeles, USA.</location>
<contexts>
<context position="3755" citStr="Shutova (2010)" startWordPosition="565" endWordPosition="566">a great variety, ranging from conventional metaphors, which we reproduce and comprehend every day, e.g. those in (2) and (3), to poetic and largely novel ones, such as (4). The use of metaphor is ubiquitous in natural language text and it is a serious bottleneck in automatic text understanding. 1“I wandered lonely as a cloud”, William Wordsworth, 1804. 688 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 688–697, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics In order to estimate the frequency of the phenomenon, Shutova (2010) conducted a corpus study on a subset of the British National Corpus (BNC) (Burnard, 2007) representing various genres. They manually annotated metaphorical expressions in this data and found that 241 out of 761 sentences contained a metaphor. Due to such a high frequency of their use, a system capable of recognizing and interpreting metaphorical expressions in unrestricted text would become an invaluable component of any semantics-oriented NLP application. Automatic processing of metaphor can be clearly divided into two subtasks: metaphor recognition (distinguishing between literal and metaph</context>
<context position="18482" citStr="Shutova (2010)" startWordPosition="2915" endWordPosition="2916">ain the metaphor Make-up is a Western burqa. Make-up =&gt; � typically worn by women � expected to be worn by women � must be worn by women � must be worn by Muslim women Burqa &lt;= By doing insertions and substitutions the system arrives from the definition typically worn by women to that of must be worn by Muslim women, and thus establishes a link between the concepts of make-up and burqa. Veale and Hao (2008), however, did not evaluate to which extent their knowledge base of Talking Points and the associated reasoning framework are useful to interpret metaphorical expressions occurring in text. Shutova (2010) defines metaphor interpretation as a paraphrasing task and presents a method for deriving literal paraphrases for metaphorical expressions from the BNC. For example, for the metaphors in “All of this stirred an unfathomable excitement in her” or “a carelessly leaked report” their system produces interpretations “All of this provoked an unfathomable excitement in her” and “a carelessly disclosed report” respectively. They first apply a probabilistic model to rank all possible paraphrases for the metaphorical expression given the context; and then use automatically induced selectional preferenc</context>
</contexts>
<marker>Shutova, 2010</marker>
<rawString>E. Shutova. 2010. Automatic metaphor interpretation as a paraphrasing task. In Proceedings of NAACL 2010, Los Angeles, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G J Steen</author>
</authors>
<title>Finding metaphor in discourse: Pragglejaz and beyond.</title>
<date>2007</date>
<booktitle>Cultura, Lenguaje y Representacion /Culture, Language and Representation (CLR), Revista de Estudios Culturales de la Universitat Jaume I,</booktitle>
<pages>5--9</pages>
<contexts>
<context position="26553" citStr="Steen, 2007" startWordPosition="4141" endWordPosition="4142">cally as “void of ardour, warmth, or intensity of feeling; lacking enthusiasm, heartiness, or zeal; indifferent, apathetic”. These two senses are clearly linked via the metaphoric mapping between EMOTIONAL STATES and TEMPERATURES. A number of metaphorical senses are included in WordNet, however without any accompanying semantic annotation. 6.2 Metaphor Identification 6.2.1 Pragglejaz Procedure Pragglejaz Group (2007) proposes a metaphor identification procedure (MIP) within the frame6Sense definitions are taken from the Oxford English Dictionary. 693 work of the Metaphor in Discourse project (Steen, 2007). The procedure involves metaphor annotation at the word level as opposed to identifying metaphorical relations (between words) or source– target domain mappings (between concepts or domains). In order to discriminate between the verbs used metaphorically and literally the annotators are asked to follow the guidelines: 1. For each verb establish its meaning in context and try to imagine a more basic meaning of this verb on other contexts. Basic meanings normally are: (1) more concrete; (2) related to bodily action; (3) more precise (as opposed to vague); (4) historically older. 2. If you can e</context>
</contexts>
<marker>Steen, 2007</marker>
<rawString>G. J. Steen. 2007. Finding metaphor in discourse: Pragglejaz and beyond. Cultura, Lenguaje y Representacion /Culture, Language and Representation (CLR), Revista de Estudios Culturales de la Universitat Jaume I, 5:9–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stefanowitsch</author>
</authors>
<title>Corpus-based approaches to metaphor and metonymy.</title>
<date>2006</date>
<booktitle>Corpus-Based Approaches to Metaphor and Metonymy,</booktitle>
<editor>In A. Stefanowitsch and S. T. Gries, editors,</editor>
<location>Berlin. Mouton</location>
<note>de Gruyter.</note>
<contexts>
<context position="27620" citStr="Stefanowitsch, 2006" startWordPosition="4315" endWordPosition="4316">c meanings normally are: (1) more concrete; (2) related to bodily action; (3) more precise (as opposed to vague); (4) historically older. 2. If you can establish the basic meaning that is distinct from the meaning of the verb in this context, the verb is likely to be used metaphorically. Such annotation can be viewed as a form of word sense disambiguation with an emphasis on metaphoricity. 6.2.2 Source – Target Domain Vocabulary Another popular method that has been used to extract metaphors is searching for sentences containing lexical items from the source domain, the target domain, or both (Stefanowitsch, 2006). This method requires exhaustive lists of source and target domain vocabulary. Martin (2006) conducted a corpus study in order to confirm that metaphorical expressions occur in text in contexts containing such lexical items. He performed his analysis on the data from the Wall Street Journal (WSJ) corpus and focused on four conceptual metaphors that occur with considerable regularity in the corpus. These include NUMERICAL VALUE AS LOCATION, COMMERCIAL ACTIVITY AS CONTAINER, COMMERCIAL ACTIVITY AS PATH FOLLOWING and COMMERCIAL ACTIVITY AS WAR. Martin manually compiled the lists of terms charact</context>
</contexts>
<marker>Stefanowitsch, 2006</marker>
<rawString>A. Stefanowitsch. 2006. Corpus-based approaches to metaphor and metonymy. In A. Stefanowitsch and S. T. Gries, editors, Corpus-Based Approaches to Metaphor and Metonymy, Berlin. Mouton de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Sun</author>
<author>A Korhonen</author>
</authors>
<title>Improving verb clustering with automatically acquired selectional preferences.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP 2009,</booktitle>
<pages>638--647</pages>
<location>Singapore,</location>
<contexts>
<context position="19339" citStr="Sun and Korhonen (2009)" startWordPosition="3037" endWordPosition="3040">t in her” or “a carelessly leaked report” their system produces interpretations “All of this provoked an unfathomable excitement in her” and “a carelessly disclosed report” respectively. They first apply a probabilistic model to rank all possible paraphrases for the metaphorical expression given the context; and then use automatically induced selectional preferences to discriminate between figurative and literal paraphrases. The selectional preference distribution is defined in terms of selectional association measure introduced by Resnik (1993) over the noun classes automatically produced by Sun and Korhonen (2009). Shutova (2010) tested their system only on metaphors expressed by a verb and report a paraphrasing accuracy of 0.81. 5 Metaphor Resources Metaphor is a knowledge-hungry phenomenon. Hence there is a need for either an extensive manually-created knowledge-base or a robust knowledge acquisition system for interpretation of metaphorical expressions. The latter being a hard task, a great deal of metaphor research resorted to the first option. Although hand-coded knowledge proved useful for metaphor interpretation (Fass, 1991; Martin, 1990), it should be noted that the systems utilizing it have a </context>
</contexts>
<marker>Sun, Korhonen, 2009</marker>
<rawString>L. Sun and A. Korhonen. 2009. Improving verb clustering with automatically acquired selectional preferences. In Proceedings of EMNLP 2009, pages 638–647, Singapore, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Tourangeau</author>
<author>R Sternberg</author>
</authors>
<title>Understanding and appreciating metaphors.</title>
<date>1982</date>
<journal>Cognition,</journal>
<volume>11</volume>
<pages>244</pages>
<contexts>
<context position="5804" citStr="Tourangeau and Sternberg, 1982" startWordPosition="890" endWordPosition="893">. Consider the examples in (5) and (6). (5) He shot down all of my arguments. (Lakoff and Johnson, 1980) (6) He attacked every weak point in my argument. (Lakoff and Johnson, 1980) According to Lakoff and Johnson (1980), a mapping of a concept of argument to that of war is employed here. The argument, which is the target concept, is viewed in terms of a battle (or a war), the source concept. The existence of such a link allows us to talk about arguments using the war terminology, thus giving rise to a number of metaphors. 2A detailed overview and criticism of these four views can be found in (Tourangeau and Sternberg, 1982). However, Lakoff and Johnson do not discuss how metaphors can be recognized in the linguistic data, which is the primary task in the automatic processing of metaphor. Although humans are highly capable of producing and comprehending metaphorical expressions, the task of distinguishing between literal and non-literal meanings and, therefore, identifying metaphor in text appears to be challenging. This is due to the variation in its use and external form, as well as a not clear-cut semantic distinction. Gibbs (1984) suggests that literal and figurative meanings are situated at the ends of a sin</context>
</contexts>
<marker>Tourangeau, Sternberg, 1982</marker>
<rawString>R. Tourangeau and R. Sternberg. 1982. Understanding and appreciating metaphors. Cognition, 11:203– 244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Veale</author>
<author>Y Hao</author>
</authors>
<title>A fluid knowledge representation for understanding and generating creative metaphors.</title>
<date>2008</date>
<booktitle>In Proceedings of COLING</booktitle>
<pages>945--952</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="17079" citStr="Veale and Hao (2008)" startWordPosition="2682" endWordPosition="2685">process relies on manually coded knowledge about the world and operates mainly in the source domain. The results are then projected onto the target domain using the conceptual mapping representation. The ATT-Meta project concerns metaphorical and metonymic description of mental states and reasoning about mental states using first order logic. Their system, however, does not take natural language sentences as input, but logical expressions that are representations of small discourse fragments. KARMA in turn deals with a broad range of abstract actions and events and takes parsed text as input. Veale and Hao (2008) derive a “fluid knowledge representation for metaphor interpretation and generation”, called Talking Points. Talking Points are a set of characteristics of concepts belonging to source and target domains and related facts about the world which the authors acquire automatically from WordNet and from the web. Talking Points are then organized in Slipnet, a framework that allows for a number of insertions, deletions and substitutions in definitions of such characteristics in order to establish a connection between the target and the source 691 concepts. This work builds on the idea of slippage i</context>
</contexts>
<marker>Veale, Hao, 2008</marker>
<rawString>T. Veale and Y. Hao. 2008. A fluid knowledge representation for understanding and generating creative metaphors. In Proceedings of COLING 2008, pages 945–952, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A M Wallington</author>
<author>J A Barnden</author>
<author>P Buchlovsky</author>
<author>L Fellows</author>
<author>S R Glasbey</author>
</authors>
<title>Metaphor annotation: A systematic study.</title>
<date>2003</date>
<tech>Technical report,</tech>
<institution>School of Computer Science, The University of Birmingham.</institution>
<contexts>
<context position="29012" citStr="Wallington et al. (2003)" startWordPosition="4523" endWordPosition="4526">ining vocabulary from these lists and checked whether they contain metaphors of the above types. The goal of this study was to evaluate predictive ability of contexts containing vocabulary from (1) source domain and (2) target domain, as well as (3) estimating the likelihood of a metaphorical expression following another metaphorical expression described by the same mapping. He obtained the most positive results for metaphors of the type NUMERICAL-VALUEAS-LOCATION (P(Metaphor|Source) = 0.069, P (Metaphor|Target) = 0.677, P (Metaphor|Metaphor) = 0.703). 6.3 Annotating Source and Target Domains Wallington et al. (2003) carried out a metaphor annotation experiment in the framework of the ATTMeta project. They employed two teams of annotators. Team A was asked to annotate “interesting stretches”, whereby a phrase was considered interesting if (1) its significance in the document was non-physical, (2) it could have a physical significance in another context with a similar syntactic frame, (3) this physical significance was related to the abstract one. Team B had to annotate phrases according to their own intuitive definition of metaphor. Besides metaphorical expressions Wallington et al. (2003) attempted to an</context>
</contexts>
<marker>Wallington, Barnden, Buchlovsky, Fellows, Glasbey, 2003</marker>
<rawString>A. M. Wallington, J. A. Barnden, P. Buchlovsky, L. Fellows, and S. R. Glasbey. 2003. Metaphor annotation: A systematic study. Technical report, School of Computer Science, The University of Birmingham.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Wilks</author>
</authors>
<title>A preferential pattern-seeking semantics for natural language inference.</title>
<date>1975</date>
<journal>Artificial Intelligence,</journal>
<pages>6--53</pages>
<contexts>
<context position="4794" citStr="Wilks, 1975" startWordPosition="718" endWordPosition="719">mantics-oriented NLP application. Automatic processing of metaphor can be clearly divided into two subtasks: metaphor recognition (distinguishing between literal and metaphorical language in text) and metaphor interpretation (identifying the intended literal meaning of a metaphorical expression). Both of them have been repeatedly addressed in NLP. 2 Theoretical Background Four different views on metaphor have been broadly discussed in linguistics and philosophy: the comparison view (Gentner, 1983), the interaction view (Black, 1962), (Hesse, 1966), the selectional restrictions violation view (Wilks, 1975; Wilks, 1978) and the conceptual metaphor view (Lakoff and Johnson, 1980)2. All of these approaches share the idea of an interconceptual mapping that underlies the production of metaphorical expressions. In other words, metaphor always involves two concepts or conceptual domains: the target (also called topic or tenor in the linguistics literature) and the source (or vehicle). Consider the examples in (5) and (6). (5) He shot down all of my arguments. (Lakoff and Johnson, 1980) (6) He attacked every weak point in my argument. (Lakoff and Johnson, 1980) According to Lakoff and Johnson (1980), </context>
</contexts>
<marker>Wilks, 1975</marker>
<rawString>Y. Wilks. 1975. A preferential pattern-seeking semantics for natural language inference. Artificial Intelligence, 6:53–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Wilks</author>
</authors>
<title>Making preferences more active.</title>
<date>1978</date>
<journal>ArtificialIntelligence,</journal>
<volume>11</volume>
<issue>3</issue>
<contexts>
<context position="1878" citStr="Wilks, 1978" startWordPosition="268" endWordPosition="269">ructure of a sentence (parsing), coreference resolution, named entity recognition and many others. Another cohort of researchers set the goal of improving applicationbased statistical inference (e.g. for recognizing textual entailment or automatic summarization). In contrast, there have been fewer attempts to bring the state-of-the-art NLP technologies together to model the way humans use language to frame high-level reasoning processes, such as for example, creative thought. The majority of computational approaches to figurative language still exploit the ideas articulated three decades ago (Wilks, 1978; Lakoff and Johnson, 1980; Fass, 1991) and often rely on taskspecific hand-coded knowledge. However, recent work on lexical semantics and lexical acquisition techniques opens many new avenues for creation of fully automated models for recognition and interpretation of figurative language. In this paper I will focus on the phenomenon of metaphor and describe the most prominent computational approaches to metaphor, as well the issues of resource creation and metaphor annotation. Metaphors arise when one concept is viewed in terms of the properties of the other. In other words it is based on sim</context>
<context position="4808" citStr="Wilks, 1978" startWordPosition="720" endWordPosition="721">ted NLP application. Automatic processing of metaphor can be clearly divided into two subtasks: metaphor recognition (distinguishing between literal and metaphorical language in text) and metaphor interpretation (identifying the intended literal meaning of a metaphorical expression). Both of them have been repeatedly addressed in NLP. 2 Theoretical Background Four different views on metaphor have been broadly discussed in linguistics and philosophy: the comparison view (Gentner, 1983), the interaction view (Black, 1962), (Hesse, 1966), the selectional restrictions violation view (Wilks, 1975; Wilks, 1978) and the conceptual metaphor view (Lakoff and Johnson, 1980)2. All of these approaches share the idea of an interconceptual mapping that underlies the production of metaphorical expressions. In other words, metaphor always involves two concepts or conceptual domains: the target (also called topic or tenor in the linguistics literature) and the source (or vehicle). Consider the examples in (5) and (6). (5) He shot down all of my arguments. (Lakoff and Johnson, 1980) (6) He attacked every weak point in my argument. (Lakoff and Johnson, 1980) According to Lakoff and Johnson (1980), a mapping of a</context>
<context position="6625" citStr="Wilks (1978)" startWordPosition="1023" endWordPosition="1024">ducing and comprehending metaphorical expressions, the task of distinguishing between literal and non-literal meanings and, therefore, identifying metaphor in text appears to be challenging. This is due to the variation in its use and external form, as well as a not clear-cut semantic distinction. Gibbs (1984) suggests that literal and figurative meanings are situated at the ends of a single continuum, along which metaphoricity and idiomaticity are spread. This makes demarcation of metaphorical and literal language fuzzy. So far, the most influential account of metaphor recognition is that of Wilks (1978). According to Wilks, metaphors represent a violation of selectional restrictions in a given context. Selectional restrictions are the semantic constraints that a verb places onto its arguments. Consider the following example. (7) My car drinks gasoline. (Wilks, 1978) The verb drink normally takes an animate subject and a liquid object. Therefore, drink taking a car as a subject is an anomaly, which may in turn indicate the metaphorical use of drink. 3 Automatic Metaphor Recognition One of the first attempts to identify and interpret metaphorical expressions in text automatically is the approa</context>
</contexts>
<marker>Wilks, 1978</marker>
<rawString>Y. Wilks. 1978. Making preferences more active. ArtificialIntelligence, 11(3):197–223.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>