<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.016837">
<title confidence="0.984006">
Classifying Temporal Relations Between Events
</title>
<author confidence="0.994604">
Nathanael Chambers and Shan Wang and Dan Jurafsky
</author>
<affiliation confidence="0.9866745">
Department of Computer Science
Stanford University
</affiliation>
<address confidence="0.93093">
Stanford, CA 94305
</address>
<email confidence="0.999285">
inatec,shanwang,jurafskyl@stanford.edu
</email>
<sectionHeader confidence="0.995648" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999330285714286">
This paper describes a fully automatic two-
stage machine learning architecture that
learns temporal relations between pairs of
events. The first stage learns the temporal
attributes of single event descriptions, such
as tense, grammatical aspect, and aspectual
class. These imperfect guesses, combined
with other linguistic features, are then used
in a second stage to classify the temporal re-
lationship between two events. We present
both an analysis of our new features and re-
sults on the TimeBank Corpus that is 3%
higher than previous work that used perfect
human tagged features.
</bodyText>
<sectionHeader confidence="0.998996" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999907037037037">
Temporal information encoded in textual descrip-
tions of events has been of interest since the early
days of natural language processing. Lately, it has
seen renewed interest as Question Answering, Infor-
mation Extraction and Summarization domains find
it critical in order to proceed beyond surface under-
standing. With the recent creation of the Timebank
Corpus (Pustejovsky et al., 2003), the utility of ma-
chine learning techniques can now be tested.
Recent work with the Timebank Corpus has re-
vealed that the six-class classification of temporal
relations is very difficult, even for human annotators.
The highest score reported on Timebank achieved
62.5% accuracy when using gold-standard features
as marked by humans (Mani et al., 2006). This pa-
per describes an approach using features extracted
automatically from raw text that not only dupli-
cates this performance, but surpasses its accuracy
by 3%. We do so through advanced linguistic fea-
tures and a surprising finding that using automatic
rather than hand-labeled tense and aspect knowledge
causes only a slight performance degradation.
We briefly describe current work on temporal or-
dering in section 2. Section 4 describes the first stage
of basic temporal extraction, followed by a full de-
scription of the second stage in 5. The evaluation
and results on Timebank then follow in section 6.
</bodyText>
<sectionHeader confidence="0.993797" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.998276857142857">
Mani et. al (2006) built a MaxEnt classifier that as-
signs each pair of events one of 6 relations from an
augmented Timebank corpus. Their classifier relies
on perfect features that were hand-tagged in the cor-
pus, including tense, aspect, modality, polarity and
event class. Pairwise agreement on tense and aspect
are also included. In a second study, they applied
rules of temporal transitivity to greatly expand the
corpus, providing different results on this enlarged
dataset. We could not duplicate their reported per-
formance on this enlarged data, and instead focus on
performing well on the Timebank data itself.
Lapata and Lascarides (2006) trained an event
classifier for inter-sentential events. They built a cor-
pus by saving sentences that contained two events,
one of which is triggered by a key time word (e.g.
after and before). Their learner was based on syntax
and clausal ordering features. Boguraev and Ando
(2005) evaluated machine learning on related tasks,
but not relevant to event-event classification.
Our work is most similar to Mani’s in that we are
</bodyText>
<page confidence="0.985727">
173
</page>
<bodyText confidence="0.6948845">
Proceedings of the ACL 2007 Demo and Poster Sessions, pages 173–176,
Prague, June 2007. c�2007 Association for Computational Linguistics
tense POS-2-event, POS-1-event
POS-of-event, have word, be word
aspect POS-of-event, modal word, be word
class synset
modality none
polarity none
learning relations given event pairs, but our work ex-
tends their results both with new features and by us-
ing fully automatic linguistic features from raw text
that are not hand selected from a corpus.
</bodyText>
<sectionHeader confidence="0.897806" genericHeader="method">
3 Data
</sectionHeader>
<bodyText confidence="0.999951625">
We used the Timebank Corpus (v1.1) for evaluation,
186 newswire documents with 3345 event pairs.
Solely for comparison with Mani, we add the 73
document Opinion Corpus (Mani et al., 2006) to cre-
ate a larger dataset called the OTC. We present both
Timebank and OTC results so future work can com-
pare against either. All results below are from 10-
fold cross validation.
</bodyText>
<sectionHeader confidence="0.950067" genericHeader="method">
4 Stage One: Learning Event Attributes
</sectionHeader>
<bodyText confidence="0.99939205">
The task in Stage One is to learn the five tempo-
ral attributes associated with events as tagged in the
Timebank Corpus. (1) Tense and (2) grammatical
aspect are necessary in any approach to temporal
ordering as they define both temporal location and
structure of the event. (3) Modality and (4) polar-
ity indicate hypothetical or non-occuring situations,
and finally, (5) event class is the type of event (e.g.
process, state, etc.). The event class has 7 values in
Timebank, but we believe this paper’s approach is
compatible with other class divisions as well. The
range of values for each event attribute is as follows,
also found in (Pustejovsky et al., 2003):
tense none, present, past, future
aspect none, prog, perfect, prog perfect
class report, aspectual, state, I state
I action, perception, occurrence
modality none, to, should, would, could
can, might
polarity positive, negative
</bodyText>
<subsectionHeader confidence="0.992555">
4.1 Machine Learning Classification
</subsectionHeader>
<bodyText confidence="0.998828444444445">
We used a machine learning approach to learn each
of the five event attributes. We implemented both
Naive Bayes and Maximum Entropy classifiers, but
found Naive Bayes to perform as well or better than
Maximum Entropy. The results in this paper are
from Naive Bayes with Laplace smoothing.
The features we used on this stage include part of
speech tags (two before the event), lemmas of the
event words, WordNet synsets, and the appearance
</bodyText>
<figureCaption confidence="0.9973025">
Figure 1: Features selected for learning each tempo-
ral attribute. POS-2 is two tokens before the event.
</figureCaption>
<table confidence="0.995398">
Timebank Corpus
tense aspect class
Baseline 52.21 84.34 54.21
Accuracy 88.28 94.24 75.2
Baseline (OTC) 48.52 86.68 59.39
Accuracy (OTC) 87.46 88.15 76.1
</table>
<figureCaption confidence="0.994749">
Figure 2: Stage One results on classification.
</figureCaption>
<bodyText confidence="0.99916365">
of auxiliaries and modals before the event. This lat-
ter set included all derivations of be and have auxil-
iaries, modal words (e.g. may, might, etc.), and the
presence/absence of not. We performed feature se-
lection on this list of features, learning a different set
of features for each of the five attributes. The list of
selected features for each is shown in figure 1.
Modality and polarity did not select any features
because their majority class baselines were so high
(98%) that learning these attributes does not provide
much utility. A deeper analysis of event interaction
would require a modal analysis, but it seems that a
newswire domain does not provide great variation
in modalities. Consequently, modality and polarity
are not used in Stage Two. Tense, aspect and class
are shown in figure 2 with majority class baselines.
Tense classification achieves 36% absolute improve-
ment, aspect 10% and class 21%. Performance on
the OTC set is similar, although aspect is not as
good. These guesses are then passed to Stage Two.
</bodyText>
<sectionHeader confidence="0.993144" genericHeader="method">
5 Stage Two: Event-Event Features
</sectionHeader>
<bodyText confidence="0.99793">
The task in this stage is to choose the temporal re-
lation between two events, given the pair of events.
We assume that the events have been extracted and
that there exists some relation between them; the
task is to choose the relation. The Timebank Corpus
uses relations that are based on Allen’s set of thir-
</bodyText>
<page confidence="0.992586">
174
</page>
<bodyText confidence="0.999917444444444">
teen (Allen, 1984). Six of the relations are inverses
of the other six, and so we condense the set to be-
fore, ibefore, includes, begins, ends and simultane-
ous. We map the thirteenth identity into simultane-
ous. One oddity is that Timebank includes both dur-
ing and included by relations, but during does not
appear in Timebank documentation. While we don’t
know how previous work handles this, we condense
during into included by (invert to includes).
</bodyText>
<subsectionHeader confidence="0.712778">
5.1 Features
</subsectionHeader>
<bodyText confidence="0.999190117647059">
Event Specific: The five temporal attributes from
Stage One are used for each event in the pair, as well
as the event strings, lemmas and WordNet synsets.
Mani added two other features from these, indica-
tors if the events agree on tense and aspect. We add
a third, event class agreement. Further, to capture
the dependency between events in a discourse, we
create new bigram features of tense, aspect and class
(e.g. “present past” if the first event is in the present,
and the second past).
Part of Speech: For each event, we include the Penn
Treebank POS tag of the event, the tags for the two
tokens preceding, and one token following. We use
the Stanford Parser1 to extract them. We also extend
previous work and create bigram POS features of the
event and the token before it, as well as the bigram
POS of the first event and the second event.
Event-Event Syntactic Properties: A phrase P is
said to dominate another phrase Q if Q is a daugh-
ter node of P in the syntactic parse tree. We lever-
age the syntactic output of the parser to create the
dominance feature for intra-sentential events. It is
either on or off, depending on the two events’ syn-
tactic dominance. Lapata used a similar feature for
subordinate phrases and an indicator before for tex-
tual event ordering. We adopt these features and also
add a same-sentence indicator if the events appear in
the same sentence.
Prepositional Phrase: Since preposition heads are
often indicators of temporal class, we created a new
feature indicating when an event is part of a prepo-
sitional phrase. The feature’s values range over 34
English prepositions. Combined with event dom-
inance (above), these two features capture direct
</bodyText>
<footnote confidence="0.869901">
1http://nlp.stanford.edu/software/lex-parser.shtml
</footnote>
<bodyText confidence="0.999864266666667">
intra-sentential relationships. To our knowledge, we
are the first to use this feature in temporal ordering.
Temporal Discourse: Seeing tense as a type of
anaphora, it is a natural conclusion that the rela-
tionship between two events becomes stronger as
the textual distance draws closer. Because of this,
we adopted the view that intra-sentential events are
generated from a different distribution than inter-
sentential events. We therefore train two models
during learning, one for events in the same sen-
tence, and the other for events crossing sentence
boundaries. It essentially splits the data on the
same sentence feature. As we will see, this turned
out to be a very useful feature. It is called the split
approach in the next section.
</bodyText>
<equation confidence="0.649218666666667">
Example (require, compromise):
“Their solution required a compromise...”
Features
(lemma1: require) (lemma2: compromise) (dominates: yes)
(tense-bigram: past-none) (aspect-bigram: none-none) (tense-
match: no) (aspect-match: yes) (before: yes) (same-sent: yes)
</equation>
<sectionHeader confidence="0.972003" genericHeader="evaluation">
6 Evaluation and Results
</sectionHeader>
<bodyText confidence="0.999902434782609">
All results are from a 10-fold cross validation us-
ing SVM (Chang and Lin, 2001). We also eval-
uated Naive Bayes and Maximum Entropy. Naive
Bayes (NB) returned similar results to SVM and we
present feature selection results from NB to compare
the added value of our new features.
The input to Stage Two is a list of pairs of events;
the task is to classify each according to one of six
temporal relations. Four sets of results are shown
in figure 3. Mani, Mani+Zapata and All+New cor-
respond to performance on features as listed in the
figure. The three table columns indicate how a gold-
standard Stage One (Gold) compares against imper-
fect guesses (Auto) and the guesses with split distri-
butions (Auto-Split).
A clear improvement is seen in each row, indi-
cating that our new features provide significant im-
provement over previous work. A decrease in per-
formance is seen between columns gold and auto,
as expected, because imperfect data is introduced,
however, the drop is manageable. The auto-split dis-
tributions make significant gains for the Mani and
Lapata features, but less when all new features are
</bodyText>
<page confidence="0.994998">
175
</page>
<table confidence="0.9473185">
Timebank Corpus Gold Auto Auto-Split
Baseline 37.22 37.22 46.58
Mani 50.97 50.19 53.42
Mani+Lapata 52.29 51.57 55.10
All+New 60.45 59.13 59.43
Mani stage one attributes, tense/aspect-match, event strings
Lapata dominance, before, lemma, synset
New prep-phrases, same-sent, class-match, POS uni/bigrams,
tense/aspect/class-bigrams
Figure 3: Incremental accuracy by adding features.
Same Sentence Diff Sentence
POS-1 Ev1 2.5% Tense Pair 1.6%
POS Bigram Ev1 3.5% Aspect Ev1 0.5%
Preposition Ev1 2.0% POS Bigram 0.2%
Tense Ev2 0.7% POS-1 Ev2 0.3%
Preposition Ev2 0.6% Word EV2 0.2%
</table>
<figureCaption confidence="0.7316855">
Figure 4: Top 5 features as added in feature selection
w/ Naive Bayes, with their percentage improvement.
</figureCaption>
<bodyText confidence="0.999838333333333">
involved. The highest fully-automatic accuracy on
Timebank is 59.43%, a 4.3% gain from our new fea-
tures. We also report 67.57% gold and 65.48% auto-
split on the OTC dataset to compare against Mani’s
reported hand-tagged features of 62.5%, a gain of
3% with our automatic features.
</bodyText>
<sectionHeader confidence="0.999521" genericHeader="discussions">
7 Discussion
</sectionHeader>
<bodyText confidence="0.999965705882353">
Previous work on OTC achieved classification accu-
racy of 62.5%, but this result was based on “perfect
data” from human annotators. A low number from
good data is at first disappointing, however, we show
that performance can be improved through more lin-
guistic features and by isolating the distinct tasks of
ordering inter-sentential and intra-sentential events.
Our new features show a clear improvement over
previous work. The features that capture dependen-
cies between the events, rather than isolated features
provide the greatest utility. Also, the impact of im-
perfect temporal data is surprisingly minimal. Us-
ing Stage One’s results instead of gold values hurts
performance by less than 1.4%. This suggests that
much of the value of the hand-coded information
can be achieved via automatic approaches. Stage
One’s event class shows room for improvement, yet
the negative impact on Event-Event relationships is
manageable. It is conceivable that more advanced
features would better classify the event class, but im-
provement on the event-event task would be slight.
Finally, it is important to note the difference in
classifying events in the same sentence vs. cross-
boundary. Splitting the 3345 pairs of corpus events
into two separate training sets makes our data more
sparse, but we still see a performance improvement
when using Mani/Lapata features. Figure 4 gives a
hint to the difference in distributions as the best fea-
tures of each task are very different. Intra-sentence
events rely on syntax cues (e.g. preposition phrases
and POS), while inter-sentence events use tense and
aspect. However, the differences are minimized as
more advanced features are added. The final row in
figure 3 shows minimal split improvement.
</bodyText>
<sectionHeader confidence="0.998643" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.997734692307692">
We have described a two-stage machine learning
approach to event-event temporal relation classifi-
cation. We have shown that imperfect event at-
tributes can be used effectively, that a range of event-
event dependency features provide added utility to a
classifier, and that events within the same sentence
have distinct characteristics from those across sen-
tence boundaries. This fully automatic raw text ap-
proach achieves a 3% improvement over previous
work based on perfect human tagged features.
Acknowledgement: This work was supported in
part by the DARPA GALE Program and the DTO
AQUAINT Program.
</bodyText>
<sectionHeader confidence="0.999155" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999930588235294">
James Allen. 1984. Towards a general theory of action and
time. Artificial Intelligence, 23:123–154.
Branimir Boguraev and Rie Kubota Ando. 2005. Timeml-
compliant text analysis for temporal reasoning. In IJCA-05.
Chih-Chung Chang and Chih-Jen Lin, 2001. LIBSVM: a li-
brary for support vector machines. Software available at
http://www.csie.ntu.edu.tw/ cjlin/libsvm.
Mirella Lapata and Alex Lascarides. 2006. Learning sentence-
internal temporal relations. In Journal of AI Research, vol-
ume 27, pages 85–117.
Inderjeet Mani, Marc Verhagen, Ben Wellner, Chong Min Lee,
and James Pustejovsky. 2006. Machine learning of temporal
relations. In ACL-06, July.
James Pustejovsky, Patrick Hanks, Roser Sauri, Andrew See,
David Day, Lisa Ferro, Robert Gaizauskas, Marcia Lazo,
Andrea Setzer, and Beth Sundheim. 2003. The timebank
corpus. Corpus Linguistics, pages 647–656.
</reference>
<page confidence="0.998747">
176
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.995022">
<title confidence="0.999773">Classifying Temporal Relations Between Events</title>
<author confidence="0.999551">Chambers Wang Jurafsky</author>
<affiliation confidence="0.999891">Department of Computer Science Stanford University</affiliation>
<address confidence="0.999809">Stanford, CA 94305</address>
<abstract confidence="0.999738666666667">This paper describes a fully automatic twostage machine learning architecture that learns temporal relations between pairs of events. The first stage learns the temporal attributes of single event descriptions, such as tense, grammatical aspect, and aspectual class. These imperfect guesses, combined with other linguistic features, are then used in a second stage to classify the temporal relationship between two events. We present both an analysis of our new features and reon the TimeBank Corpus that is higher than previous work that used perfect human tagged features.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James Allen</author>
</authors>
<title>Towards a general theory of action and time.</title>
<date>1984</date>
<journal>Artificial Intelligence,</journal>
<pages>23--123</pages>
<contexts>
<context position="7223" citStr="Allen, 1984" startWordPosition="1157" endWordPosition="1158">e shown in figure 2 with majority class baselines. Tense classification achieves 36% absolute improvement, aspect 10% and class 21%. Performance on the OTC set is similar, although aspect is not as good. These guesses are then passed to Stage Two. 5 Stage Two: Event-Event Features The task in this stage is to choose the temporal relation between two events, given the pair of events. We assume that the events have been extracted and that there exists some relation between them; the task is to choose the relation. The Timebank Corpus uses relations that are based on Allen’s set of thir174 teen (Allen, 1984). Six of the relations are inverses of the other six, and so we condense the set to before, ibefore, includes, begins, ends and simultaneous. We map the thirteenth identity into simultaneous. One oddity is that Timebank includes both during and included by relations, but during does not appear in Timebank documentation. While we don’t know how previous work handles this, we condense during into included by (invert to includes). 5.1 Features Event Specific: The five temporal attributes from Stage One are used for each event in the pair, as well as the event strings, lemmas and WordNet synsets. </context>
</contexts>
<marker>Allen, 1984</marker>
<rawString>James Allen. 1984. Towards a general theory of action and time. Artificial Intelligence, 23:123–154.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Branimir Boguraev</author>
<author>Rie Kubota Ando</author>
</authors>
<title>Timemlcompliant text analysis for temporal reasoning.</title>
<date>2005</date>
<booktitle>In IJCA-05.</booktitle>
<contexts>
<context position="3109" citStr="Boguraev and Ando (2005)" startWordPosition="479" endWordPosition="482">aspect are also included. In a second study, they applied rules of temporal transitivity to greatly expand the corpus, providing different results on this enlarged dataset. We could not duplicate their reported performance on this enlarged data, and instead focus on performing well on the Timebank data itself. Lapata and Lascarides (2006) trained an event classifier for inter-sentential events. They built a corpus by saving sentences that contained two events, one of which is triggered by a key time word (e.g. after and before). Their learner was based on syntax and clausal ordering features. Boguraev and Ando (2005) evaluated machine learning on related tasks, but not relevant to event-event classification. Our work is most similar to Mani’s in that we are 173 Proceedings of the ACL 2007 Demo and Poster Sessions, pages 173–176, Prague, June 2007. c�2007 Association for Computational Linguistics tense POS-2-event, POS-1-event POS-of-event, have word, be word aspect POS-of-event, modal word, be word class synset modality none polarity none learning relations given event pairs, but our work extends their results both with new features and by using fully automatic linguistic features from raw text that are n</context>
</contexts>
<marker>Boguraev, Ando, 2005</marker>
<rawString>Branimir Boguraev and Rie Kubota Ando. 2005. Timemlcompliant text analysis for temporal reasoning. In IJCA-05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM: a library for support vector machines. Software available at http://www.csie.ntu.edu.tw/ cjlin/libsvm.</title>
<date>2001</date>
<contexts>
<context position="10507" citStr="Chang and Lin, 2001" startWordPosition="1691" endWordPosition="1694">ents in the same sentence, and the other for events crossing sentence boundaries. It essentially splits the data on the same sentence feature. As we will see, this turned out to be a very useful feature. It is called the split approach in the next section. Example (require, compromise): “Their solution required a compromise...” Features (lemma1: require) (lemma2: compromise) (dominates: yes) (tense-bigram: past-none) (aspect-bigram: none-none) (tensematch: no) (aspect-match: yes) (before: yes) (same-sent: yes) 6 Evaluation and Results All results are from a 10-fold cross validation using SVM (Chang and Lin, 2001). We also evaluated Naive Bayes and Maximum Entropy. Naive Bayes (NB) returned similar results to SVM and we present feature selection results from NB to compare the added value of our new features. The input to Stage Two is a list of pairs of events; the task is to classify each according to one of six temporal relations. Four sets of results are shown in figure 3. Mani, Mani+Zapata and All+New correspond to performance on features as listed in the figure. The three table columns indicate how a goldstandard Stage One (Gold) compares against imperfect guesses (Auto) and the guesses with split </context>
</contexts>
<marker>Chang, Lin, 2001</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin, 2001. LIBSVM: a library for support vector machines. Software available at http://www.csie.ntu.edu.tw/ cjlin/libsvm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirella Lapata</author>
<author>Alex Lascarides</author>
</authors>
<title>Learning sentenceinternal temporal relations.</title>
<date>2006</date>
<journal>In Journal of AI Research,</journal>
<volume>27</volume>
<pages>85--117</pages>
<contexts>
<context position="2825" citStr="Lapata and Lascarides (2006)" startWordPosition="432" endWordPosition="435"> built a MaxEnt classifier that assigns each pair of events one of 6 relations from an augmented Timebank corpus. Their classifier relies on perfect features that were hand-tagged in the corpus, including tense, aspect, modality, polarity and event class. Pairwise agreement on tense and aspect are also included. In a second study, they applied rules of temporal transitivity to greatly expand the corpus, providing different results on this enlarged dataset. We could not duplicate their reported performance on this enlarged data, and instead focus on performing well on the Timebank data itself. Lapata and Lascarides (2006) trained an event classifier for inter-sentential events. They built a corpus by saving sentences that contained two events, one of which is triggered by a key time word (e.g. after and before). Their learner was based on syntax and clausal ordering features. Boguraev and Ando (2005) evaluated machine learning on related tasks, but not relevant to event-event classification. Our work is most similar to Mani’s in that we are 173 Proceedings of the ACL 2007 Demo and Poster Sessions, pages 173–176, Prague, June 2007. c�2007 Association for Computational Linguistics tense POS-2-event, POS-1-event </context>
</contexts>
<marker>Lapata, Lascarides, 2006</marker>
<rawString>Mirella Lapata and Alex Lascarides. 2006. Learning sentenceinternal temporal relations. In Journal of AI Research, volume 27, pages 85–117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjeet Mani</author>
<author>Marc Verhagen</author>
<author>Ben Wellner</author>
<author>Chong Min Lee</author>
<author>James Pustejovsky</author>
</authors>
<title>Machine learning of temporal relations.</title>
<date>2006</date>
<booktitle>In ACL-06,</booktitle>
<contexts>
<context position="1552" citStr="Mani et al., 2006" startWordPosition="227" endWordPosition="230">age processing. Lately, it has seen renewed interest as Question Answering, Information Extraction and Summarization domains find it critical in order to proceed beyond surface understanding. With the recent creation of the Timebank Corpus (Pustejovsky et al., 2003), the utility of machine learning techniques can now be tested. Recent work with the Timebank Corpus has revealed that the six-class classification of temporal relations is very difficult, even for human annotators. The highest score reported on Timebank achieved 62.5% accuracy when using gold-standard features as marked by humans (Mani et al., 2006). This paper describes an approach using features extracted automatically from raw text that not only duplicates this performance, but surpasses its accuracy by 3%. We do so through advanced linguistic features and a surprising finding that using automatic rather than hand-labeled tense and aspect knowledge causes only a slight performance degradation. We briefly describe current work on temporal ordering in section 2. Section 4 describes the first stage of basic temporal extraction, followed by a full description of the second stage in 5. The evaluation and results on Timebank then follow in </context>
<context position="3935" citStr="Mani et al., 2006" startWordPosition="610" endWordPosition="613">173–176, Prague, June 2007. c�2007 Association for Computational Linguistics tense POS-2-event, POS-1-event POS-of-event, have word, be word aspect POS-of-event, modal word, be word class synset modality none polarity none learning relations given event pairs, but our work extends their results both with new features and by using fully automatic linguistic features from raw text that are not hand selected from a corpus. 3 Data We used the Timebank Corpus (v1.1) for evaluation, 186 newswire documents with 3345 event pairs. Solely for comparison with Mani, we add the 73 document Opinion Corpus (Mani et al., 2006) to create a larger dataset called the OTC. We present both Timebank and OTC results so future work can compare against either. All results below are from 10- fold cross validation. 4 Stage One: Learning Event Attributes The task in Stage One is to learn the five temporal attributes associated with events as tagged in the Timebank Corpus. (1) Tense and (2) grammatical aspect are necessary in any approach to temporal ordering as they define both temporal location and structure of the event. (3) Modality and (4) polarity indicate hypothetical or non-occuring situations, and finally, (5) event cl</context>
</contexts>
<marker>Mani, Verhagen, Wellner, Lee, Pustejovsky, 2006</marker>
<rawString>Inderjeet Mani, Marc Verhagen, Ben Wellner, Chong Min Lee, and James Pustejovsky. 2006. Machine learning of temporal relations. In ACL-06, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Patrick Hanks</author>
<author>Roser Sauri</author>
<author>Andrew See</author>
<author>David Day</author>
<author>Lisa Ferro</author>
<author>Robert Gaizauskas</author>
<author>Marcia Lazo</author>
<author>Andrea Setzer</author>
<author>Beth Sundheim</author>
</authors>
<title>The timebank corpus. Corpus Linguistics,</title>
<date>2003</date>
<pages>647--656</pages>
<contexts>
<context position="1200" citStr="Pustejovsky et al., 2003" startWordPosition="172" endWordPosition="175">age to classify the temporal relationship between two events. We present both an analysis of our new features and results on the TimeBank Corpus that is 3% higher than previous work that used perfect human tagged features. 1 Introduction Temporal information encoded in textual descriptions of events has been of interest since the early days of natural language processing. Lately, it has seen renewed interest as Question Answering, Information Extraction and Summarization domains find it critical in order to proceed beyond surface understanding. With the recent creation of the Timebank Corpus (Pustejovsky et al., 2003), the utility of machine learning techniques can now be tested. Recent work with the Timebank Corpus has revealed that the six-class classification of temporal relations is very difficult, even for human annotators. The highest score reported on Timebank achieved 62.5% accuracy when using gold-standard features as marked by humans (Mani et al., 2006). This paper describes an approach using features extracted automatically from raw text that not only duplicates this performance, but surpasses its accuracy by 3%. We do so through advanced linguistic features and a surprising finding that using a</context>
<context position="4818" citStr="Pustejovsky et al., 2003" startWordPosition="761" endWordPosition="764"> five temporal attributes associated with events as tagged in the Timebank Corpus. (1) Tense and (2) grammatical aspect are necessary in any approach to temporal ordering as they define both temporal location and structure of the event. (3) Modality and (4) polarity indicate hypothetical or non-occuring situations, and finally, (5) event class is the type of event (e.g. process, state, etc.). The event class has 7 values in Timebank, but we believe this paper’s approach is compatible with other class divisions as well. The range of values for each event attribute is as follows, also found in (Pustejovsky et al., 2003): tense none, present, past, future aspect none, prog, perfect, prog perfect class report, aspectual, state, I state I action, perception, occurrence modality none, to, should, would, could can, might polarity positive, negative 4.1 Machine Learning Classification We used a machine learning approach to learn each of the five event attributes. We implemented both Naive Bayes and Maximum Entropy classifiers, but found Naive Bayes to perform as well or better than Maximum Entropy. The results in this paper are from Naive Bayes with Laplace smoothing. The features we used on this stage include par</context>
</contexts>
<marker>Pustejovsky, Hanks, Sauri, See, Day, Ferro, Gaizauskas, Lazo, Setzer, Sundheim, 2003</marker>
<rawString>James Pustejovsky, Patrick Hanks, Roser Sauri, Andrew See, David Day, Lisa Ferro, Robert Gaizauskas, Marcia Lazo, Andrea Setzer, and Beth Sundheim. 2003. The timebank corpus. Corpus Linguistics, pages 647–656.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>