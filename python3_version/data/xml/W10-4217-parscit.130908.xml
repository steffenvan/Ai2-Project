<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.109675">
<title confidence="0.9984495">
Extracting Parallel Fragments from Comparable Corpora for
Data-to-text Generation
</title>
<author confidence="0.994383">
Anja Belz Eric Kow
</author>
<affiliation confidence="0.997213666666667">
Natural Language Technology Group
School of Computing, Mathematical and Information Sciences
University of Brighton
</affiliation>
<address confidence="0.995879">
Brighton BN2 4GJ, UK
</address>
<email confidence="0.999638">
{asb,eykk10}@bton.ac.uk
</email>
<sectionHeader confidence="0.9974" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998764083333333">
Building NLG systems, in particular sta-
tistical ones, requires parallel data (paired
inputs and outputs) which do not gener-
ally occur naturally. In this paper, we in-
vestigate the idea of automatically extract-
ing parallel resources for data-to-text gen-
eration from comparable corpora obtained
from the Web. We describe our compa-
rable corpus of data and texts relating to
British hills and the techniques for extract-
ing paired input/output fragments we have
developed so far.
</bodyText>
<sectionHeader confidence="0.999392" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999817">
Starting with Knight, Langkilde and Hatzivas-
siloglou’s work on Nitrogen and its successor
Halogen (Knight and Hatzivassiloglou, 1995;
Knight and Langkilde, 2000), NLG has over the
past 15 years moved towards using statistical tech-
niques, in particular in surface realisation (Langk-
ilde, 2002; White, 2004), referring expression
generation (most of the sytems submitted to the
TUNA and GREC shared task evaluation challenges
are statistical, see Gatt et al. (2008), for example),
and data-to-text generation (Belz, 2008).
The impetus for introducing statistical tech-
niques in NLG can be said to have originally come
from machine translation (MT),1 but unlike MT,
where parallel corpora of inputs (source language
texts) and outputs (translated texts) occur naturally
at least in some domains,2 NLG on the whole has
to use manually created input/output pairs.
Data-to-text generation (D2T) is the type of NLG
that perhaps comes closest to having naturally oc-
curing inputs and outputs at its disposal. Work
in D2T has involved different domains including
generating weather forecasts from meteorological
</bodyText>
<footnote confidence="0.975544">
1Nitrogen was conceived as an MT system component.
2Canadian and European parliamentary proceedings, etc.
</footnote>
<bodyText confidence="0.995368390243903">
data (Sripada et al., 2003), nursing reports from in-
tensive care data (Portet et al., 2009), and museum
exhibit descriptions from database records (Isard
et al., 2003; Stock et al., 2007); types of data in-
clude dynamic time-series data (e.g. medical data)
and static database entries (museum exhibits).
While data and texts in the three example do-
mains cited above do occur naturally, two factors
mean they cannot be used directly as example cor-
pora or training data for building D2T systems:
one, most are not freely available to researchers
(e.g. by simply being available on the Web), and
two, more problematically, for the most part, there
is no direct correspondence between inputs and
outputs as there is, say, between a source language
text and its translation. On the whole, naturally
occurring resources of data and related texts are
not strictly parallel, but are merely what has be-
come known as comparable in the MT literature,
with only a subset of data having corresponding
text fragments, and other text fragments having
no obvious corresponding data items. Moreover,
data transformations may be necessary before cor-
responding text fragments can be identified.
In this report, we look at the possibility of au-
tomatically extracting parallel data-text fragments
from comparable corpora in the case of D2T from
static database records. Such a parallel data-text
resource could then be used to train an existing
D2T generation system, or even build a new statis-
tical generator from scratch, e.g. using techniques
from statistical MT (Belz and Kow, 2009). The
steps involved in going from comparable data and
text resources to generators that produce texts sim-
ilar to those in the text resource are then as fol-
lows: (1) identify sources on the Web for com-
parable data and texts; (2) pair up data records
and texts; (3) extract parallel fragments (sets of
data fields paired with word strings); (4) train a
D2T generator using the parallel fragments; and
(5) feed data inputs to the generator which then
</bodyText>
<figureCaption confidence="0.999221">
Figure 1: Overview of processing steps.
</figureCaption>
<bodyText confidence="0.986674">
generates new texts describing them. Figure 1 il-
lustrates steps 1–3 which this paper focuses on. In
Section 3 we look at steps 1 and 2; in Section 4 at
step 3. First we briefly survey related work in MT.
</bodyText>
<sectionHeader confidence="0.999231" genericHeader="introduction">
2 Related work in MT
</sectionHeader>
<bodyText confidence="0.999988266666667">
In statistical MT, the expense of manually creat-
ing new parallel MT corpora, and the need for very
large amounts of parallel training data, has led
to a sizeable research effort to develop methods
for automatically constructing parallel resources.
This work typically starts by identifying compara-
ble corpora. Much of it has focused on identify-
ing word translations in comparable corpora, e.g.
Rapp’s approach was based on the simple and el-
egant assumption that if words Af and Bf have
a higher than chance co-occurrence frequency in
one language, then two appropriate translations
Ae and Be in another language will also have
a higher than chance co-occurrence frequency
(Rapp, 1995; Rapp, 1999). At the other end of
the spectrum, Resnik &amp; Smith (2003) search the
Web to detect web pages that are translations of
each other. Other approaches aim to identify pairs
of sentences (Munteanu and Marcu, 2005) or sub-
sentential fragments (Munteanu and Marcu, 2006)
that are parallel within comparable corpora.
The latter approach is particularly relevant to
our work. They start by translating each docu-
ment in the source language (SL) word for word
into the target language (TL). The result is given
to an information retrieval (IR) system as a query,
and the top 20 results are retained and paired with
the given SL document. They then obtain all sen-
tence pairs from each pair of SL and TL docu-
ments, and discard those sentence pairs with few
words that are translations of each other. To the re-
maining sentences they then apply a fragment de-
tection method which tries to distinguish between
source fragments that have a translation on the tar-
get side, and fragments that do not.
The biggest difference between the MT situation
and the D2T situation is that in the latter sentence-
aligned parallel resources exist and can be used as
a starting point. E.g. Munteanu &amp; Marcu use an
existing parallel Romanian-English corpus to (au-
tomatically) create a lexicon from which is then
used in various ways in their method.
In D2T we have no analogous resources to help
us get started, and the methods described in this
paper use no such prior knowledge.
</bodyText>
<sectionHeader confidence="0.980156" genericHeader="method">
3 A Comparable Corpus of British Hills
</sectionHeader>
<bodyText confidence="0.99881432">
As a source of data, we use the Database of British
Hills (BHDB) created by Chris Crocker,3 version
11.3, which currently contains measurements and
other information about 5,614 British hills. Ad-
ditionally, we perform reverse geocoding via the
Google Map API4 which allows us to convert
latitude and longitude information from the hills
database into country and region names. We add
the latter to each database entry.
On the text side, we use Wikipedia texts in the
WikiProject British and Irish Hills (retrieved on
2009-11-09). There are currently 899 pages cov-
ered by this WikiProject, 242 of which are of qual-
ity category B or above.5
Matching up data records and documents:
Matching up the data records in the BHDB with
articles in Wikipedia is not trivial: not all BHDB
entries have corresponding Wikipedia articles, dif-
ferent hills often share the same name, and the
same hill can have different names and spellings.
We perform a search of Wikipedia with the hill’s
name as the search term, using the Mediawiki API,
and then retain the top n search results returned
(currently n = 1). The top search result is not
always a correct match for the database record. We
</bodyText>
<footnote confidence="0.93176925">
3http://www.biber.fsnet.co.uk
4http://code.google.com/apis/maps/
5B = The article is mostly complete and without major
issues, but requires some further work.
</footnote>
<table confidence="0.941449857142857">
{ &amp;quot;id&amp;quot;: 1679, &amp;quot;main-name-info&amp;quot;: {&amp;quot;name&amp;quot;: &amp;quot;Hill of Stake&amp;quot;, &amp;quot;notes&amp;quot;: &amp;quot;&amp;quot;,
&amp;quot;parent&amp;quot;: &amp;quot;&amp;quot;, &amp;quot;parent-notes&amp;quot;: &amp;quot;&amp;quot;},
&amp;quot;alt-name-info&amp;quot;: [], &amp;quot;raw-name&amp;quot;: &amp;quot;Hill of Stake&amp;quot;, &amp;quot;rhb-section&amp;quot;: &amp;quot;27A&amp;quot;, &amp;quot;area&amp;quot;: &amp;quot;Ayr to River Clyde&amp;quot;,
&amp;quot;height-metres&amp;quot;: 522, &amp;quot;height-feet&amp;quot;: 1713, &amp;quot;map-1to50k&amp;quot;: &amp;quot;63&amp;quot;, &amp;quot;map-1to25k&amp;quot;: &amp;quot;341N&amp;quot;, &amp;quot;gridref&amp;quot;: &amp;quot;NS273630&amp;quot;,
&amp;quot;col-gridref&amp;quot;: &amp;quot;NS320527&amp;quot;, &amp;quot;col-height&amp;quot;: 33, &amp;quot;drop&amp;quot;: 489, &amp;quot;gridref10&amp;quot;: &amp;quot;NS 27360 62998&amp;quot;, &amp;quot;feature&amp;quot;: &amp;quot;trig point&amp;quot;,
&amp;quot;observations&amp;quot;: &amp;quot;&amp;quot;, &amp;quot;survey&amp;quot;: &amp;quot;&amp;quot;, &amp;quot;date-climbed&amp;quot;: &amp;quot;&amp;quot;, &amp;quot;classification&amp;quot;: &amp;quot;Ma,CoH,CoU&amp;quot;,
&amp;quot;county-name&amp;quot;: &amp;quot;Renfrewshire(CoH); Renfrewshire(CoU)&amp;quot;, &amp;quot;revision&amp;quot;: &amp;quot;28-Oct-2001&amp;quot;, &amp;quot;comments&amp;quot;: &amp;quot;&amp;quot;,
&amp;quot;streetmap&amp;quot;: &amp;quot;http://www.streetmap.co.uk/newmap.srf?x=227356&amp;y=663005&amp;z=3&amp;sv=227356,663005&amp;st=4&amp;tl=˜&amp;bi=˜&amp;lu=N&amp;ar=n&amp;quot;,
&amp;quot;ordanancesurvey-map&amp;quot;: &amp;quot;http://getamap.ordnancesurvey.co.uk/getamap/frames.htm?mapAction=gaz&amp;gazName=g&amp;gazString=NS273630&amp;quot;,
&amp;quot;x-coord&amp;quot;: 227356, &amp;quot;y-coord&amp;quot;: 663005, &amp;quot;latitude&amp;quot;: 55.82931,
&amp;quot;longitude&amp;quot;: -4.75789, &amp;quot;country&amp;quot;: &amp;quot;Scotland&amp;quot;, &amp;quot;region&amp;quot;: &amp;quot;Renfrewshire&amp;quot; }
Hill of Stake is a hill on the boundary between North Ayrshire and Renfrewshire, Scotland. It is 522 metres ( 1712 feet) high
. It is one of the Marilyns of Lowland Scotland. It is the highest point of the relatively low-lying county of Renfrewshire and
indeed the entire Clyde Muirshiel Regional Park of which it is a part.
</table>
<tableCaption confidence="0.999887">
Table 1: Output of step 1: data record from British Hills DB and matched Wikipedia text (Hill of Stake).
</tableCaption>
<bodyText confidence="0.9981175">
manually selected the pairs we are confident are a
correct match. This left us with 759 matched pairs
out of a possible 899.
Table 1 shows an example of an automatically
matched database entry and Wikipedia article. It
illustrates the non-parallelism discussed in the pre-
ceding section; e.g. there is no information in the
database corresponding to the last sentence.
</bodyText>
<sectionHeader confidence="0.954206" genericHeader="method">
4 Towards a Parallelised Corpus
</sectionHeader>
<subsectionHeader confidence="0.998516">
4.1 Aligning data fields and sentences
</subsectionHeader>
<bodyText confidence="0.999993">
In the second processing step, we pair up data
fields and sentences. Related methods in MT have
translation lexicons and thesauri that can be used
as bridges between SL and TL texts, but there is
no equivalents in NLG. Our current method asso-
ciates each data field with a hand-written ‘match
predicate’. For example, the match predicate for
height-metres returns True if the sentence con-
tains the words ‘X metres’ (among other patterns),
where X is some number within 5% of the height
of the hill in the database. We retain only the sen-
tences that match at least one data field. Table 2
shows what the data field/sentence alignment pro-
cedure outputs for the Hill of Stake.
</bodyText>
<subsectionHeader confidence="0.98386">
4.2 Identifying Parallel Fragments
</subsectionHeader>
<bodyText confidence="0.999394166666667">
While it was fine for step 2 to produce some rough
matches, in step 3, parallel fragment detection, the
aim is to retain only those parts of a sentence that
can be said to realise some data field(s) in the set
of data fields with which it has been matched.
Computing data-text associations: Following
some preprocessing of sentences where each oc-
currence of a hill’s name and height is replaced
by lexical class tokens NAME, HEIGHT METRES
or HEIGHT FEET , the first step is to construct a
kind of lexicon of pairs (d, w) of data fields d and
words w, such that w is often seen in the realisa-
tion of d. For this purpose we adapt Munteanu
&amp; Marcu’s (2006) method for (language to lan-
guage) lexicon construction. For this purpose we
compute a measure of the strength of association
between data fields and words; we use the G2 log-
likelihood ratio which has been widely used for
this sort of purpose (especially lexical association)
since it was introduced to NLP (Dunning, 1993).
Following Moore (2004a) rather than Munteanu &amp;
Marcu, our current notion of cooccurrence is that
a data field and word cooccur if they are present
in the same pair of data fields and sentence (as
identified by the method described in Section 4.1
above). We then obtain counts for the number of
times each word cooccurs with each data field, and
the number of times it occurs without the data field
being present (and conversely). This allows us to
compute the G2 score, for which we use the for-
mulation from Moore (2004b) shown in Figure 2.
If the G2 score for a given (d, w) pair is greater
than p(d)p(w), then the association is taken to be
positive, i.e. w is likely to be a realisation of d,
otherwise the association is taken to be negative,
i.e. w is likely not to be part of a realisation of d.
For each d we then convert G2 scores to proba-
bilities by dividing G2 by the appropriate normal-
ising factor (the sum over all negative G2 scores
for d for obtaining the negative association proba-
bilities, and analogously for positive associations).
Table 3 shows the three words with the highest
positive association probabilities for each of our
six data fields. Note that these are not the three
most likely alternative ‘translations’ of each data
key, but rather the three words which are most
likely to be part of a realisation of a data field, if
seen in conjunction with it.
</bodyText>
<note confidence="0.998834125">
&amp;quot;main-name-only&amp;quot;: &amp;quot;Hill of Stake&amp;quot;, NAME is a hill on the boundary between North Ayrshire and Renfrewshire,
&amp;quot;country&amp;quot;: &amp;quot;Scotland&amp;quot; Scotland.
&amp;quot;height-metres&amp;quot;: 522, It is HEIGHT METERS metres ( HEIGHT FEET feet) high.
&amp;quot;height-feet&amp;quot;: 1713
&amp;quot;country&amp;quot;: &amp;quot;Scotland&amp;quot;, &amp;quot;CoH&amp;quot;, &amp;quot;CoU&amp;quot;] It is one of the Marilyns of Lowland Scotland.
&amp;quot;classification&amp;quot;: [&amp;quot;Ma&amp;quot;,
&amp;quot;main-name-only&amp;quot;: &amp;quot;Hill of Stake&amp;quot; It is the highest point of the relatively low-lying county of Renfrewshire and
indeed the entire Clyde Muirshiel Regional Park of which it is a part.
</note>
<tableCaption confidence="0.996596">
Table 2: Output of step 2: aligned data fields and sentences, for Hill of Stake.
</tableCaption>
<equation confidence="0.400612666666667">
2N (�
p(d, w)log p(d, w) + p(d, ¬w)log p(d, ¬w) + p(¬d, w)log p(¬d, w) + p(¬d, ¬w)log p(¬d, ¬w)
p(d)p(w) p(d)p(¬w) p(¬d)p(w) p(¬d)p(¬w)
</equation>
<figureCaption confidence="0.713903">
Figure 2: Formula for computing G2 from Moore (2004b) (N is the sample size).
</figureCaption>
<table confidence="0.999285210526316">
Data key d Word w P+(w|d)
main-name-only NAME 0.1355
a 0.0742
in 0.0660
classification as 0.0412
adjoining 0.0193
qualifies 0.0177
region District 0.1855
Lake 0.1661
area 0.1095
country in 0.1640
NAME 0.1122
Scotland 0.0732
height-metres metres 0.1255
m 0.0791
height 0.0679
height-feet feet 0.1511
HEIGHT METERS 0.0974
( 0.0900
</table>
<tableCaption confidence="0.999848">
Table 3: Data keys with 3 most likely words.
</tableCaption>
<bodyText confidence="0.999262157894737">
Identifying realisations: The next step is to ap-
ply these probabilities to identify those parts of a
sentence that are likely to be a valid realisation of
the data fields in the input. In Figure 3 we plot
the positive and negative association probabilities
for one of the sentences from our running exam-
ple, Hill of Stake. The light grey graph represents
the association probabilities between each word
in the sentence and height-feet, the dark grey
line those between the words in the sentence and
height-metres. We plot the negative association
probabilities simply by multiplying each by −1.
The part of the sentence that one would
want to extract as a possible realisation of
{ height-metres, height-feet }, namely
“ HEIGHT METRES metres ( HEIGHT FEET feet )
high”, shows up clearly as a sequence of relatively
strong positive association values. Our current
approach identifies such contiguous positive
</bodyText>
<figureCaption confidence="0.890718">
Figure 3: Positive and negative association prob-
abilities plotted against the words they were com-
puted for.
</figureCaption>
<bodyText confidence="0.997">
association scores and extracts the corresponding
sentence fragments. This works well in many
cases, but is too simple as a general approach; we
are currently developing this method further.
</bodyText>
<sectionHeader confidence="0.985709" genericHeader="conclusions">
5 Concluding Remarks
</sectionHeader>
<bodyText confidence="0.999027428571429">
In this paper we have been interested in the prob-
lem of automatically obtaining parallel corpora for
data-to-text generation. We presented our com-
parable corpus of 759 paired database entries and
human-authored articles about British Hills. We
described the three techniques which we have im-
plemented so far and which we combine to extract
parallel data-text fragments from the corpus: (i)
identification of candidate pairs of data fields and
sentences; (ii) computing scores for the strength
of association between data and words; and (iii)
identifying sequences of words in sentences that
have positive association scores with the given
data fields.
</bodyText>
<sectionHeader confidence="0.993082" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.989871024096385">
Anja Belz and Eric Kow. 2009. System building cost
vs. output quality in data-to-text generation. In Pro-
ceedings of the 12th European Workshop on Natural
Language Generation, pages 16–24.
A. Belz. 2008. Automatic generation of weather
forecast texts using comprehensive probabilistic
generation-space models. Natural Language Engi-
neering, 14(4):431–455.
Ted Dunning. 1993. Accurate methods for the statis-
tics of surprise and coincidence. Computational
Linguistics, 1:61–74.
A. Gatt, A. Belz, and E. Kow. 2008. The TUNA
Challenge 2008: Overview and evaluation results.
In Proceedings of the 5th International Natural
Language Generation Conference (INLG’08), pages
198–206.
A. Isard, J. Oberlander, I. Androutsopoulos, and
C. Matheson. 2003. Speaking the users’ languages.
18(1):40–45.
K. Knight and V. Hatzivassiloglou. 1995. Two-level,
many-paths generation. In Proceedings of the 33rd
Annual Meeting of the Association for Computa-
tional Linguistics (ACL ’95).
Kevin Knight and Irene Langkilde. 2000. Preserving
ambiguity in generation via automata intersection.
In Proceedings ofAAAI/IAAI, pages 697–702.
I. Langkilde. 2002. An empirical verification of cover-
age and correctness for a general-purpose sentence
generator. In Proc. 2nd International Natural Lan-
guage Generation Conference (INLG ’02).
Robert C. Moore. 2004a. Improving ibm word-
alignment model 1. In Proceedings of the 42nd An-
nual Meeting of the Association for Computational
Linguistics, pages 519–526.
Robert C. Moore. 2004b. On log-likelihood-ratios and
the significance of rare events. In Proceedings of
the 9th Converence on Empirical Methods in Natu-
ral Language Processing (EMNLP’04), pages 333–
340.
Dragos Munteanu and Daniel Marcu. 2005. Improv-
ing machine translation performance by exploiting
non-parallel corpora. Computational Linguistics,
31:477–504.
Dragos Stefan Munteanu and Daniel Marcu. 2006. Ex-
tracting parallel sub-sentential fragments from non-
parallel corpora. In Proceedings of the 21st In-
ternational Conference on Computational Linguis-
tics and the 44th annual meeting of the Association
for Computational Linguistics (COLING-ACL’06),
pages 81–88, Morristown, NJ, USA. Association for
Computational Linguistics.
F. Portet, E. Reiter, A. Gatt, J. Hunter, S. Sripada,
Y. Freer, and C. Sykes. 2009. Automatic gener-
ation of textual summaries from neonatal intensive
care data. Artificial Intelligence, 173:789–816.
Reinhard Rapp. 1995. Identifying word translations in
non-parallel texts. In Proceedings of the 33rd an-
nual meeting on Association for Computational Lin-
guistics, pages 320–322, Morristown, NJ, USA. As-
sociation for Computational Linguistics.
Reinhard Rapp. 1999. Automatic identification of
word translations from unrelated english and german
corpora. In Proceedings of the 37th annual meeting
of the Association for Computational Linguistics on
Computational Linguistics, pages 519–526, Morris-
town, NJ, USA. Association for Computational Lin-
guistics.
Philip Resnik and Noah Smith. 2003. The web as a
parallel corpus. Computational Linguistics, 29:349–
380.
S. Sripada, E. Reiter, J. Hunter, and J. Yu. 2003. Ex-
ploiting a parallel text-data corpus. In Proceedings
of Corpus Linguistics 2003, pages 734–743.
Oliviero Stock, Massimo Zancanaro, Paolo Busetta
adn Charles Callaway, Anbtonio Kr¨uger, Michael
Kruppa, Tsvi Kuflik, Elena Not, and Cesare Rocchi.
2007. Adaptive, intelligent presentation of informa-
tion for the museum visitor in PEACH. User Mod-
eling and User-Adapted Interaction, 17(3):257–304.
M. White. 2004. Reining in CCG chart realization. In
A. Belz, R. Evans, and P. Piwek, editors, Proceed-
ings INLG’04, volume 3123 of LNAI, pages 182–
191. Springer.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.481357">
<title confidence="0.994416">Extracting Parallel Fragments from Comparable Corpora Data-to-text Generation</title>
<author confidence="0.993818">Anja Belz Eric Kow</author>
<affiliation confidence="0.975451666666667">Natural Language Technology School of Computing, Mathematical and Information University of</affiliation>
<address confidence="0.534535">Brighton BN2 4GJ,</address>
<abstract confidence="0.997700846153846">in particular statistical ones, requires parallel data (paired inputs and outputs) which do not generally occur naturally. In this paper, we investigate the idea of automatically extracting parallel resources for data-to-text genfrom obtained from the Web. We describe our comparable corpus of data and texts relating to British hills and the techniques for extracting paired input/output fragments we have developed so far.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anja Belz</author>
<author>Eric Kow</author>
</authors>
<title>System building cost vs. output quality in data-to-text generation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th European Workshop on Natural Language Generation,</booktitle>
<pages>16--24</pages>
<contexts>
<context position="3531" citStr="Belz and Kow, 2009" startWordPosition="538" endWordPosition="541">nly a subset of data having corresponding text fragments, and other text fragments having no obvious corresponding data items. Moreover, data transformations may be necessary before corresponding text fragments can be identified. In this report, we look at the possibility of automatically extracting parallel data-text fragments from comparable corpora in the case of D2T from static database records. Such a parallel data-text resource could then be used to train an existing D2T generation system, or even build a new statistical generator from scratch, e.g. using techniques from statistical MT (Belz and Kow, 2009). The steps involved in going from comparable data and text resources to generators that produce texts similar to those in the text resource are then as follows: (1) identify sources on the Web for comparable data and texts; (2) pair up data records and texts; (3) extract parallel fragments (sets of data fields paired with word strings); (4) train a D2T generator using the parallel fragments; and (5) feed data inputs to the generator which then Figure 1: Overview of processing steps. generates new texts describing them. Figure 1 illustrates steps 1–3 which this paper focuses on. In Section 3 w</context>
</contexts>
<marker>Belz, Kow, 2009</marker>
<rawString>Anja Belz and Eric Kow. 2009. System building cost vs. output quality in data-to-text generation. In Proceedings of the 12th European Workshop on Natural Language Generation, pages 16–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Belz</author>
</authors>
<title>Automatic generation of weather forecast texts using comprehensive probabilistic generation-space models.</title>
<date>2008</date>
<journal>Natural Language Engineering,</journal>
<volume>14</volume>
<issue>4</issue>
<contexts>
<context position="1279" citStr="Belz, 2008" startWordPosition="184" endWordPosition="185">iques for extracting paired input/output fragments we have developed so far. 1 Introduction Starting with Knight, Langkilde and Hatzivassiloglou’s work on Nitrogen and its successor Halogen (Knight and Hatzivassiloglou, 1995; Knight and Langkilde, 2000), NLG has over the past 15 years moved towards using statistical techniques, in particular in surface realisation (Langkilde, 2002; White, 2004), referring expression generation (most of the sytems submitted to the TUNA and GREC shared task evaluation challenges are statistical, see Gatt et al. (2008), for example), and data-to-text generation (Belz, 2008). The impetus for introducing statistical techniques in NLG can be said to have originally come from machine translation (MT),1 but unlike MT, where parallel corpora of inputs (source language texts) and outputs (translated texts) occur naturally at least in some domains,2 NLG on the whole has to use manually created input/output pairs. Data-to-text generation (D2T) is the type of NLG that perhaps comes closest to having naturally occuring inputs and outputs at its disposal. Work in D2T has involved different domains including generating weather forecasts from meteorological 1Nitrogen was conc</context>
</contexts>
<marker>Belz, 2008</marker>
<rawString>A. Belz. 2008. Automatic generation of weather forecast texts using comprehensive probabilistic generation-space models. Natural Language Engineering, 14(4):431–455.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Dunning</author>
</authors>
<title>Accurate methods for the statistics of surprise and coincidence.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>1--61</pages>
<contexts>
<context position="11297" citStr="Dunning, 1993" startWordPosition="1785" endWordPosition="1786">ill’s name and height is replaced by lexical class tokens NAME, HEIGHT METRES or HEIGHT FEET , the first step is to construct a kind of lexicon of pairs (d, w) of data fields d and words w, such that w is often seen in the realisation of d. For this purpose we adapt Munteanu &amp; Marcu’s (2006) method for (language to language) lexicon construction. For this purpose we compute a measure of the strength of association between data fields and words; we use the G2 loglikelihood ratio which has been widely used for this sort of purpose (especially lexical association) since it was introduced to NLP (Dunning, 1993). Following Moore (2004a) rather than Munteanu &amp; Marcu, our current notion of cooccurrence is that a data field and word cooccur if they are present in the same pair of data fields and sentence (as identified by the method described in Section 4.1 above). We then obtain counts for the number of times each word cooccurs with each data field, and the number of times it occurs without the data field being present (and conversely). This allows us to compute the G2 score, for which we use the formulation from Moore (2004b) shown in Figure 2. If the G2 score for a given (d, w) pair is greater than p</context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>Ted Dunning. 1993. Accurate methods for the statistics of surprise and coincidence. Computational Linguistics, 1:61–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Gatt</author>
<author>A Belz</author>
<author>E Kow</author>
</authors>
<title>The TUNA Challenge 2008: Overview and evaluation results.</title>
<date>2008</date>
<booktitle>In Proceedings of the 5th International Natural Language Generation Conference (INLG’08),</booktitle>
<pages>198--206</pages>
<contexts>
<context position="1223" citStr="Gatt et al. (2008)" startWordPosition="175" endWordPosition="178">orpus of data and texts relating to British hills and the techniques for extracting paired input/output fragments we have developed so far. 1 Introduction Starting with Knight, Langkilde and Hatzivassiloglou’s work on Nitrogen and its successor Halogen (Knight and Hatzivassiloglou, 1995; Knight and Langkilde, 2000), NLG has over the past 15 years moved towards using statistical techniques, in particular in surface realisation (Langkilde, 2002; White, 2004), referring expression generation (most of the sytems submitted to the TUNA and GREC shared task evaluation challenges are statistical, see Gatt et al. (2008), for example), and data-to-text generation (Belz, 2008). The impetus for introducing statistical techniques in NLG can be said to have originally come from machine translation (MT),1 but unlike MT, where parallel corpora of inputs (source language texts) and outputs (translated texts) occur naturally at least in some domains,2 NLG on the whole has to use manually created input/output pairs. Data-to-text generation (D2T) is the type of NLG that perhaps comes closest to having naturally occuring inputs and outputs at its disposal. Work in D2T has involved different domains including generating </context>
</contexts>
<marker>Gatt, Belz, Kow, 2008</marker>
<rawString>A. Gatt, A. Belz, and E. Kow. 2008. The TUNA Challenge 2008: Overview and evaluation results. In Proceedings of the 5th International Natural Language Generation Conference (INLG’08), pages 198–206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Isard</author>
<author>J Oberlander</author>
<author>I Androutsopoulos</author>
<author>C Matheson</author>
</authors>
<title>Speaking the users’ languages.</title>
<date>2003</date>
<pages>18--1</pages>
<contexts>
<context position="2133" citStr="Isard et al., 2003" startWordPosition="312" endWordPosition="315"> naturally at least in some domains,2 NLG on the whole has to use manually created input/output pairs. Data-to-text generation (D2T) is the type of NLG that perhaps comes closest to having naturally occuring inputs and outputs at its disposal. Work in D2T has involved different domains including generating weather forecasts from meteorological 1Nitrogen was conceived as an MT system component. 2Canadian and European parliamentary proceedings, etc. data (Sripada et al., 2003), nursing reports from intensive care data (Portet et al., 2009), and museum exhibit descriptions from database records (Isard et al., 2003; Stock et al., 2007); types of data include dynamic time-series data (e.g. medical data) and static database entries (museum exhibits). While data and texts in the three example domains cited above do occur naturally, two factors mean they cannot be used directly as example corpora or training data for building D2T systems: one, most are not freely available to researchers (e.g. by simply being available on the Web), and two, more problematically, for the most part, there is no direct correspondence between inputs and outputs as there is, say, between a source language text and its translatio</context>
</contexts>
<marker>Isard, Oberlander, Androutsopoulos, Matheson, 2003</marker>
<rawString>A. Isard, J. Oberlander, I. Androutsopoulos, and C. Matheson. 2003. Speaking the users’ languages. 18(1):40–45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
<author>V Hatzivassiloglou</author>
</authors>
<title>Two-level, many-paths generation.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics (ACL ’95).</booktitle>
<contexts>
<context position="892" citStr="Knight and Hatzivassiloglou, 1995" startWordPosition="124" endWordPosition="127">uk Abstract Building NLG systems, in particular statistical ones, requires parallel data (paired inputs and outputs) which do not generally occur naturally. In this paper, we investigate the idea of automatically extracting parallel resources for data-to-text generation from comparable corpora obtained from the Web. We describe our comparable corpus of data and texts relating to British hills and the techniques for extracting paired input/output fragments we have developed so far. 1 Introduction Starting with Knight, Langkilde and Hatzivassiloglou’s work on Nitrogen and its successor Halogen (Knight and Hatzivassiloglou, 1995; Knight and Langkilde, 2000), NLG has over the past 15 years moved towards using statistical techniques, in particular in surface realisation (Langkilde, 2002; White, 2004), referring expression generation (most of the sytems submitted to the TUNA and GREC shared task evaluation challenges are statistical, see Gatt et al. (2008), for example), and data-to-text generation (Belz, 2008). The impetus for introducing statistical techniques in NLG can be said to have originally come from machine translation (MT),1 but unlike MT, where parallel corpora of inputs (source language texts) and outputs (</context>
</contexts>
<marker>Knight, Hatzivassiloglou, 1995</marker>
<rawString>K. Knight and V. Hatzivassiloglou. 1995. Two-level, many-paths generation. In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics (ACL ’95).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Irene Langkilde</author>
</authors>
<title>Preserving ambiguity in generation via automata intersection.</title>
<date>2000</date>
<booktitle>In Proceedings ofAAAI/IAAI,</booktitle>
<pages>697--702</pages>
<contexts>
<context position="921" citStr="Knight and Langkilde, 2000" startWordPosition="128" endWordPosition="131">n particular statistical ones, requires parallel data (paired inputs and outputs) which do not generally occur naturally. In this paper, we investigate the idea of automatically extracting parallel resources for data-to-text generation from comparable corpora obtained from the Web. We describe our comparable corpus of data and texts relating to British hills and the techniques for extracting paired input/output fragments we have developed so far. 1 Introduction Starting with Knight, Langkilde and Hatzivassiloglou’s work on Nitrogen and its successor Halogen (Knight and Hatzivassiloglou, 1995; Knight and Langkilde, 2000), NLG has over the past 15 years moved towards using statistical techniques, in particular in surface realisation (Langkilde, 2002; White, 2004), referring expression generation (most of the sytems submitted to the TUNA and GREC shared task evaluation challenges are statistical, see Gatt et al. (2008), for example), and data-to-text generation (Belz, 2008). The impetus for introducing statistical techniques in NLG can be said to have originally come from machine translation (MT),1 but unlike MT, where parallel corpora of inputs (source language texts) and outputs (translated texts) occur natur</context>
</contexts>
<marker>Knight, Langkilde, 2000</marker>
<rawString>Kevin Knight and Irene Langkilde. 2000. Preserving ambiguity in generation via automata intersection. In Proceedings ofAAAI/IAAI, pages 697–702.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Langkilde</author>
</authors>
<title>An empirical verification of coverage and correctness for a general-purpose sentence generator.</title>
<date>2002</date>
<booktitle>In Proc. 2nd International Natural Language Generation Conference (INLG ’02).</booktitle>
<contexts>
<context position="1051" citStr="Langkilde, 2002" startWordPosition="150" endWordPosition="152">vestigate the idea of automatically extracting parallel resources for data-to-text generation from comparable corpora obtained from the Web. We describe our comparable corpus of data and texts relating to British hills and the techniques for extracting paired input/output fragments we have developed so far. 1 Introduction Starting with Knight, Langkilde and Hatzivassiloglou’s work on Nitrogen and its successor Halogen (Knight and Hatzivassiloglou, 1995; Knight and Langkilde, 2000), NLG has over the past 15 years moved towards using statistical techniques, in particular in surface realisation (Langkilde, 2002; White, 2004), referring expression generation (most of the sytems submitted to the TUNA and GREC shared task evaluation challenges are statistical, see Gatt et al. (2008), for example), and data-to-text generation (Belz, 2008). The impetus for introducing statistical techniques in NLG can be said to have originally come from machine translation (MT),1 but unlike MT, where parallel corpora of inputs (source language texts) and outputs (translated texts) occur naturally at least in some domains,2 NLG on the whole has to use manually created input/output pairs. Data-to-text generation (D2T) is </context>
</contexts>
<marker>Langkilde, 2002</marker>
<rawString>I. Langkilde. 2002. An empirical verification of coverage and correctness for a general-purpose sentence generator. In Proc. 2nd International Natural Language Generation Conference (INLG ’02).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C Moore</author>
</authors>
<title>Improving ibm wordalignment model 1.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>519--526</pages>
<contexts>
<context position="11320" citStr="Moore (2004" startWordPosition="1788" endWordPosition="1789">eplaced by lexical class tokens NAME, HEIGHT METRES or HEIGHT FEET , the first step is to construct a kind of lexicon of pairs (d, w) of data fields d and words w, such that w is often seen in the realisation of d. For this purpose we adapt Munteanu &amp; Marcu’s (2006) method for (language to language) lexicon construction. For this purpose we compute a measure of the strength of association between data fields and words; we use the G2 loglikelihood ratio which has been widely used for this sort of purpose (especially lexical association) since it was introduced to NLP (Dunning, 1993). Following Moore (2004a) rather than Munteanu &amp; Marcu, our current notion of cooccurrence is that a data field and word cooccur if they are present in the same pair of data fields and sentence (as identified by the method described in Section 4.1 above). We then obtain counts for the number of times each word cooccurs with each data field, and the number of times it occurs without the data field being present (and conversely). This allows us to compute the G2 score, for which we use the formulation from Moore (2004b) shown in Figure 2. If the G2 score for a given (d, w) pair is greater than p(d)p(w), then the assoc</context>
<context position="13476" citStr="Moore (2004" startWordPosition="2162" endWordPosition="2163">res ( HEIGHT FEET feet) high. &amp;quot;height-feet&amp;quot;: 1713 &amp;quot;country&amp;quot;: &amp;quot;Scotland&amp;quot;, &amp;quot;CoH&amp;quot;, &amp;quot;CoU&amp;quot;] It is one of the Marilyns of Lowland Scotland. &amp;quot;classification&amp;quot;: [&amp;quot;Ma&amp;quot;, &amp;quot;main-name-only&amp;quot;: &amp;quot;Hill of Stake&amp;quot; It is the highest point of the relatively low-lying county of Renfrewshire and indeed the entire Clyde Muirshiel Regional Park of which it is a part. Table 2: Output of step 2: aligned data fields and sentences, for Hill of Stake. 2N (� p(d, w)log p(d, w) + p(d, ¬w)log p(d, ¬w) + p(¬d, w)log p(¬d, w) + p(¬d, ¬w)log p(¬d, ¬w) p(d)p(w) p(d)p(¬w) p(¬d)p(w) p(¬d)p(¬w) Figure 2: Formula for computing G2 from Moore (2004b) (N is the sample size). Data key d Word w P+(w|d) main-name-only NAME 0.1355 a 0.0742 in 0.0660 classification as 0.0412 adjoining 0.0193 qualifies 0.0177 region District 0.1855 Lake 0.1661 area 0.1095 country in 0.1640 NAME 0.1122 Scotland 0.0732 height-metres metres 0.1255 m 0.0791 height 0.0679 height-feet feet 0.1511 HEIGHT METERS 0.0974 ( 0.0900 Table 3: Data keys with 3 most likely words. Identifying realisations: The next step is to apply these probabilities to identify those parts of a sentence that are likely to be a valid realisation of the data fields in the input. In Figure 3 we</context>
</contexts>
<marker>Moore, 2004</marker>
<rawString>Robert C. Moore. 2004a. Improving ibm wordalignment model 1. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics, pages 519–526.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C Moore</author>
</authors>
<title>On log-likelihood-ratios and the significance of rare events.</title>
<date>2004</date>
<booktitle>In Proceedings of the 9th Converence on Empirical Methods in Natural Language Processing (EMNLP’04),</booktitle>
<pages>333--340</pages>
<contexts>
<context position="11320" citStr="Moore (2004" startWordPosition="1788" endWordPosition="1789">eplaced by lexical class tokens NAME, HEIGHT METRES or HEIGHT FEET , the first step is to construct a kind of lexicon of pairs (d, w) of data fields d and words w, such that w is often seen in the realisation of d. For this purpose we adapt Munteanu &amp; Marcu’s (2006) method for (language to language) lexicon construction. For this purpose we compute a measure of the strength of association between data fields and words; we use the G2 loglikelihood ratio which has been widely used for this sort of purpose (especially lexical association) since it was introduced to NLP (Dunning, 1993). Following Moore (2004a) rather than Munteanu &amp; Marcu, our current notion of cooccurrence is that a data field and word cooccur if they are present in the same pair of data fields and sentence (as identified by the method described in Section 4.1 above). We then obtain counts for the number of times each word cooccurs with each data field, and the number of times it occurs without the data field being present (and conversely). This allows us to compute the G2 score, for which we use the formulation from Moore (2004b) shown in Figure 2. If the G2 score for a given (d, w) pair is greater than p(d)p(w), then the assoc</context>
<context position="13476" citStr="Moore (2004" startWordPosition="2162" endWordPosition="2163">res ( HEIGHT FEET feet) high. &amp;quot;height-feet&amp;quot;: 1713 &amp;quot;country&amp;quot;: &amp;quot;Scotland&amp;quot;, &amp;quot;CoH&amp;quot;, &amp;quot;CoU&amp;quot;] It is one of the Marilyns of Lowland Scotland. &amp;quot;classification&amp;quot;: [&amp;quot;Ma&amp;quot;, &amp;quot;main-name-only&amp;quot;: &amp;quot;Hill of Stake&amp;quot; It is the highest point of the relatively low-lying county of Renfrewshire and indeed the entire Clyde Muirshiel Regional Park of which it is a part. Table 2: Output of step 2: aligned data fields and sentences, for Hill of Stake. 2N (� p(d, w)log p(d, w) + p(d, ¬w)log p(d, ¬w) + p(¬d, w)log p(¬d, w) + p(¬d, ¬w)log p(¬d, ¬w) p(d)p(w) p(d)p(¬w) p(¬d)p(w) p(¬d)p(¬w) Figure 2: Formula for computing G2 from Moore (2004b) (N is the sample size). Data key d Word w P+(w|d) main-name-only NAME 0.1355 a 0.0742 in 0.0660 classification as 0.0412 adjoining 0.0193 qualifies 0.0177 region District 0.1855 Lake 0.1661 area 0.1095 country in 0.1640 NAME 0.1122 Scotland 0.0732 height-metres metres 0.1255 m 0.0791 height 0.0679 height-feet feet 0.1511 HEIGHT METERS 0.0974 ( 0.0900 Table 3: Data keys with 3 most likely words. Identifying realisations: The next step is to apply these probabilities to identify those parts of a sentence that are likely to be a valid realisation of the data fields in the input. In Figure 3 we</context>
</contexts>
<marker>Moore, 2004</marker>
<rawString>Robert C. Moore. 2004b. On log-likelihood-ratios and the significance of rare events. In Proceedings of the 9th Converence on Empirical Methods in Natural Language Processing (EMNLP’04), pages 333– 340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragos Munteanu</author>
<author>Daniel Marcu</author>
</authors>
<title>Improving machine translation performance by exploiting non-parallel corpora.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<pages>31--477</pages>
<contexts>
<context position="5149" citStr="Munteanu and Marcu, 2005" startWordPosition="816" endWordPosition="819">dentifying comparable corpora. Much of it has focused on identifying word translations in comparable corpora, e.g. Rapp’s approach was based on the simple and elegant assumption that if words Af and Bf have a higher than chance co-occurrence frequency in one language, then two appropriate translations Ae and Be in another language will also have a higher than chance co-occurrence frequency (Rapp, 1995; Rapp, 1999). At the other end of the spectrum, Resnik &amp; Smith (2003) search the Web to detect web pages that are translations of each other. Other approaches aim to identify pairs of sentences (Munteanu and Marcu, 2005) or subsentential fragments (Munteanu and Marcu, 2006) that are parallel within comparable corpora. The latter approach is particularly relevant to our work. They start by translating each document in the source language (SL) word for word into the target language (TL). The result is given to an information retrieval (IR) system as a query, and the top 20 results are retained and paired with the given SL document. They then obtain all sentence pairs from each pair of SL and TL documents, and discard those sentence pairs with few words that are translations of each other. To the remaining sente</context>
</contexts>
<marker>Munteanu, Marcu, 2005</marker>
<rawString>Dragos Munteanu and Daniel Marcu. 2005. Improving machine translation performance by exploiting non-parallel corpora. Computational Linguistics, 31:477–504.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragos Stefan Munteanu</author>
<author>Daniel Marcu</author>
</authors>
<title>Extracting parallel sub-sentential fragments from nonparallel corpora.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics (COLING-ACL’06),</booktitle>
<pages>81--88</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="5203" citStr="Munteanu and Marcu, 2006" startWordPosition="824" endWordPosition="827">on identifying word translations in comparable corpora, e.g. Rapp’s approach was based on the simple and elegant assumption that if words Af and Bf have a higher than chance co-occurrence frequency in one language, then two appropriate translations Ae and Be in another language will also have a higher than chance co-occurrence frequency (Rapp, 1995; Rapp, 1999). At the other end of the spectrum, Resnik &amp; Smith (2003) search the Web to detect web pages that are translations of each other. Other approaches aim to identify pairs of sentences (Munteanu and Marcu, 2005) or subsentential fragments (Munteanu and Marcu, 2006) that are parallel within comparable corpora. The latter approach is particularly relevant to our work. They start by translating each document in the source language (SL) word for word into the target language (TL). The result is given to an information retrieval (IR) system as a query, and the top 20 results are retained and paired with the given SL document. They then obtain all sentence pairs from each pair of SL and TL documents, and discard those sentence pairs with few words that are translations of each other. To the remaining sentences they then apply a fragment detection method which</context>
</contexts>
<marker>Munteanu, Marcu, 2006</marker>
<rawString>Dragos Stefan Munteanu and Daniel Marcu. 2006. Extracting parallel sub-sentential fragments from nonparallel corpora. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics (COLING-ACL’06), pages 81–88, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Portet</author>
<author>E Reiter</author>
<author>A Gatt</author>
<author>J Hunter</author>
<author>S Sripada</author>
<author>Y Freer</author>
<author>C Sykes</author>
</authors>
<title>Automatic generation of textual summaries from neonatal intensive care data.</title>
<date>2009</date>
<journal>Artificial Intelligence,</journal>
<pages>173--789</pages>
<contexts>
<context position="2058" citStr="Portet et al., 2009" startWordPosition="301" endWordPosition="304">orpora of inputs (source language texts) and outputs (translated texts) occur naturally at least in some domains,2 NLG on the whole has to use manually created input/output pairs. Data-to-text generation (D2T) is the type of NLG that perhaps comes closest to having naturally occuring inputs and outputs at its disposal. Work in D2T has involved different domains including generating weather forecasts from meteorological 1Nitrogen was conceived as an MT system component. 2Canadian and European parliamentary proceedings, etc. data (Sripada et al., 2003), nursing reports from intensive care data (Portet et al., 2009), and museum exhibit descriptions from database records (Isard et al., 2003; Stock et al., 2007); types of data include dynamic time-series data (e.g. medical data) and static database entries (museum exhibits). While data and texts in the three example domains cited above do occur naturally, two factors mean they cannot be used directly as example corpora or training data for building D2T systems: one, most are not freely available to researchers (e.g. by simply being available on the Web), and two, more problematically, for the most part, there is no direct correspondence between inputs and </context>
</contexts>
<marker>Portet, Reiter, Gatt, Hunter, Sripada, Freer, Sykes, 2009</marker>
<rawString>F. Portet, E. Reiter, A. Gatt, J. Hunter, S. Sripada, Y. Freer, and C. Sykes. 2009. Automatic generation of textual summaries from neonatal intensive care data. Artificial Intelligence, 173:789–816.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Rapp</author>
</authors>
<title>Identifying word translations in non-parallel texts.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd annual meeting on Association for Computational Linguistics,</booktitle>
<pages>320--322</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="4928" citStr="Rapp, 1995" startWordPosition="780" endWordPosition="781">ra, and the need for very large amounts of parallel training data, has led to a sizeable research effort to develop methods for automatically constructing parallel resources. This work typically starts by identifying comparable corpora. Much of it has focused on identifying word translations in comparable corpora, e.g. Rapp’s approach was based on the simple and elegant assumption that if words Af and Bf have a higher than chance co-occurrence frequency in one language, then two appropriate translations Ae and Be in another language will also have a higher than chance co-occurrence frequency (Rapp, 1995; Rapp, 1999). At the other end of the spectrum, Resnik &amp; Smith (2003) search the Web to detect web pages that are translations of each other. Other approaches aim to identify pairs of sentences (Munteanu and Marcu, 2005) or subsentential fragments (Munteanu and Marcu, 2006) that are parallel within comparable corpora. The latter approach is particularly relevant to our work. They start by translating each document in the source language (SL) word for word into the target language (TL). The result is given to an information retrieval (IR) system as a query, and the top 20 results are retained </context>
</contexts>
<marker>Rapp, 1995</marker>
<rawString>Reinhard Rapp. 1995. Identifying word translations in non-parallel texts. In Proceedings of the 33rd annual meeting on Association for Computational Linguistics, pages 320–322, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Rapp</author>
</authors>
<title>Automatic identification of word translations from unrelated english and german corpora.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics,</booktitle>
<pages>519--526</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="4941" citStr="Rapp, 1999" startWordPosition="782" endWordPosition="783">need for very large amounts of parallel training data, has led to a sizeable research effort to develop methods for automatically constructing parallel resources. This work typically starts by identifying comparable corpora. Much of it has focused on identifying word translations in comparable corpora, e.g. Rapp’s approach was based on the simple and elegant assumption that if words Af and Bf have a higher than chance co-occurrence frequency in one language, then two appropriate translations Ae and Be in another language will also have a higher than chance co-occurrence frequency (Rapp, 1995; Rapp, 1999). At the other end of the spectrum, Resnik &amp; Smith (2003) search the Web to detect web pages that are translations of each other. Other approaches aim to identify pairs of sentences (Munteanu and Marcu, 2005) or subsentential fragments (Munteanu and Marcu, 2006) that are parallel within comparable corpora. The latter approach is particularly relevant to our work. They start by translating each document in the source language (SL) word for word into the target language (TL). The result is given to an information retrieval (IR) system as a query, and the top 20 results are retained and paired wi</context>
</contexts>
<marker>Rapp, 1999</marker>
<rawString>Reinhard Rapp. 1999. Automatic identification of word translations from unrelated english and german corpora. In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics, pages 519–526, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
<author>Noah Smith</author>
</authors>
<title>The web as a parallel corpus.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<pages>380</pages>
<contexts>
<context position="4998" citStr="Resnik &amp; Smith (2003)" startWordPosition="791" endWordPosition="794">g data, has led to a sizeable research effort to develop methods for automatically constructing parallel resources. This work typically starts by identifying comparable corpora. Much of it has focused on identifying word translations in comparable corpora, e.g. Rapp’s approach was based on the simple and elegant assumption that if words Af and Bf have a higher than chance co-occurrence frequency in one language, then two appropriate translations Ae and Be in another language will also have a higher than chance co-occurrence frequency (Rapp, 1995; Rapp, 1999). At the other end of the spectrum, Resnik &amp; Smith (2003) search the Web to detect web pages that are translations of each other. Other approaches aim to identify pairs of sentences (Munteanu and Marcu, 2005) or subsentential fragments (Munteanu and Marcu, 2006) that are parallel within comparable corpora. The latter approach is particularly relevant to our work. They start by translating each document in the source language (SL) word for word into the target language (TL). The result is given to an information retrieval (IR) system as a query, and the top 20 results are retained and paired with the given SL document. They then obtain all sentence p</context>
</contexts>
<marker>Resnik, Smith, 2003</marker>
<rawString>Philip Resnik and Noah Smith. 2003. The web as a parallel corpus. Computational Linguistics, 29:349– 380.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Sripada</author>
<author>E Reiter</author>
<author>J Hunter</author>
<author>J Yu</author>
</authors>
<title>Exploiting a parallel text-data corpus.</title>
<date>2003</date>
<booktitle>In Proceedings of Corpus Linguistics</booktitle>
<pages>734--743</pages>
<contexts>
<context position="1994" citStr="Sripada et al., 2003" startWordPosition="290" endWordPosition="293">e from machine translation (MT),1 but unlike MT, where parallel corpora of inputs (source language texts) and outputs (translated texts) occur naturally at least in some domains,2 NLG on the whole has to use manually created input/output pairs. Data-to-text generation (D2T) is the type of NLG that perhaps comes closest to having naturally occuring inputs and outputs at its disposal. Work in D2T has involved different domains including generating weather forecasts from meteorological 1Nitrogen was conceived as an MT system component. 2Canadian and European parliamentary proceedings, etc. data (Sripada et al., 2003), nursing reports from intensive care data (Portet et al., 2009), and museum exhibit descriptions from database records (Isard et al., 2003; Stock et al., 2007); types of data include dynamic time-series data (e.g. medical data) and static database entries (museum exhibits). While data and texts in the three example domains cited above do occur naturally, two factors mean they cannot be used directly as example corpora or training data for building D2T systems: one, most are not freely available to researchers (e.g. by simply being available on the Web), and two, more problematically, for the </context>
</contexts>
<marker>Sripada, Reiter, Hunter, Yu, 2003</marker>
<rawString>S. Sripada, E. Reiter, J. Hunter, and J. Yu. 2003. Exploiting a parallel text-data corpus. In Proceedings of Corpus Linguistics 2003, pages 734–743.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oliviero Stock</author>
<author>Massimo Zancanaro</author>
</authors>
<title>Paolo Busetta adn Charles Callaway, Anbtonio Kr¨uger, Michael Kruppa, Tsvi Kuflik,</title>
<date>2007</date>
<location>Elena</location>
<marker>Stock, Zancanaro, 2007</marker>
<rawString>Oliviero Stock, Massimo Zancanaro, Paolo Busetta adn Charles Callaway, Anbtonio Kr¨uger, Michael Kruppa, Tsvi Kuflik, Elena Not, and Cesare Rocchi. 2007. Adaptive, intelligent presentation of information for the museum visitor in PEACH. User Modeling and User-Adapted Interaction, 17(3):257–304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M White</author>
</authors>
<title>Reining in CCG chart realization.</title>
<date>2004</date>
<booktitle>Proceedings INLG’04, volume 3123 of LNAI,</booktitle>
<pages>182--191</pages>
<editor>In A. Belz, R. Evans, and P. Piwek, editors,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="1065" citStr="White, 2004" startWordPosition="153" endWordPosition="154">a of automatically extracting parallel resources for data-to-text generation from comparable corpora obtained from the Web. We describe our comparable corpus of data and texts relating to British hills and the techniques for extracting paired input/output fragments we have developed so far. 1 Introduction Starting with Knight, Langkilde and Hatzivassiloglou’s work on Nitrogen and its successor Halogen (Knight and Hatzivassiloglou, 1995; Knight and Langkilde, 2000), NLG has over the past 15 years moved towards using statistical techniques, in particular in surface realisation (Langkilde, 2002; White, 2004), referring expression generation (most of the sytems submitted to the TUNA and GREC shared task evaluation challenges are statistical, see Gatt et al. (2008), for example), and data-to-text generation (Belz, 2008). The impetus for introducing statistical techniques in NLG can be said to have originally come from machine translation (MT),1 but unlike MT, where parallel corpora of inputs (source language texts) and outputs (translated texts) occur naturally at least in some domains,2 NLG on the whole has to use manually created input/output pairs. Data-to-text generation (D2T) is the type of NL</context>
</contexts>
<marker>White, 2004</marker>
<rawString>M. White. 2004. Reining in CCG chart realization. In A. Belz, R. Evans, and P. Piwek, editors, Proceedings INLG’04, volume 3123 of LNAI, pages 182– 191. Springer.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>