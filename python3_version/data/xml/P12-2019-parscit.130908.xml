<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.025664">
<title confidence="0.992226">
Automatically Learning Measures of Child Language Development
</title>
<author confidence="0.997291">
Sam Sahakian
</author>
<affiliation confidence="0.996564">
University of Wisconsin - Madison
</affiliation>
<email confidence="0.997988">
sahakian@cs.wisc.edu
</email>
<author confidence="0.992681">
Benjamin Snyder
</author>
<affiliation confidence="0.994072">
University of Wisconsin - Madison
</affiliation>
<email confidence="0.998421">
bsnyder@cs.wisc.edu
</email>
<sectionHeader confidence="0.995634" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999826285714286">
We propose a new approach for the creation of
child language development metrics. A set of
linguistic features is computed on child speech
samples and used as input in two age predic-
tion experiments. In the first experiment, we
learn a child-specific metric and predicts the
ages at which speech samples were produced.
We then learn a more general developmen-
tal index by applying our method across chil-
dren, predicting relative temporal orderings of
speech samples. In both cases we compare
our results with established measures of lan-
guage development, showing improvements in
age prediction performance.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.996529431372549">
The rapid childhood development from a seem-
ingly blank slate to language mastery is a puzzle
that linguists and psychologists continue to ponder.
While the precise mechanism of language learning
remains poorly understood, researchers have devel-
oped measures of developmental language progress
using child speech patterns. These metrics pro-
vide a means of diagnosing early language disor-
ders. Besides this practical benefit, precisely mea-
suring grammatical development is a step towards
understanding the underlying language learning pro-
cess.
Previous NLP work has sought to automate the
calculation of handcrafted developmental metrics
proposed by psychologists and linguists. In this pa-
per, we investigate a more fundamental question:
Can we use machine learning techniques to create
a more robust developmental measure itself? If so,
how well would such a measure generalize across
children? This last question touches on an underly-
ing assumption made in much of the child language
literature– that while children progress grammati-
cally at different rates, they follow fixed stages in
their development. If a developmental index auto-
matically learned from one set of children could be
accurately applied to others, it would vindicate this
assumption of shared developmental paths.
Several metrics of language development have
been set forth in the psycholinguistics literature.
Standard measures include Mean Length of Utter-
ance (MLU) (Brown, 1973)– the average length in
morphemes of conversational turns, Index of Pro-
ductive Syntax (IPSYN) (Scarborough, 1990)– a
multi-tiered scoring process where over 60 individ-
ual features are counted by hand and combined into
tiered scores, and D-Level (Rosenberg et al., 1987;
Covington et al., 2006)– a score for individual sen-
tences based on the observed presence of key syn-
tactic structures. Today, these hand-crafted metrics
persist as measurements of child language develop-
ment, each taking a slightly different angle to assess
the same question: Exactly how much grammatical
knowledge does a young learner possess?
NLP technology has been applied to help au-
tomate the otherwise tedious calculation of these
measures. Computerized Profiling (CP) (Long and
Channell, 2001) is a software package that produces
semi-automated language assessments, using part-
of-speech tagging and human supervision. In re-
sponse to its limited depth of analysis and the neces-
sity for human supervision in CP, there have since
</bodyText>
<page confidence="0.991433">
95
</page>
<note confidence="0.833277">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 95–99,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<table confidence="0.999517">
D-Level Article Count “Be” Count Fn. / Content Prep. Count Word Freq. MLU
Depth
Adam 0.798 0.532 0.817 0.302 0.399 0.371 0.847 0.855
Abe 0.633 0.479 0.591 0.144 0.269 0.413 0.534 0.625
Ross 0.252 0.153 -0.061 0.125 0.314 0.209 0.134 0.165
Peter 0.371 0.429 0.781 0.562 0.638 0.657 0.524 0.638
Naomi 0.812 0.746 0.540 0.652 0.504 0.609 0.710 0.710
Sarah 0.829 0.550 0.733 0.382 0.654 0.570 0.731 0.808
Nina 0.824 0.758 0.780 0.560 0.451 0.429 0.780 0.890
Mean: 0.646 0.521 0.597 0.390 0.461 0.465 0.609 0.670
</table>
<tableCaption confidence="0.997886">
Table 1: T of each feature versus time, for each individual
child. In this and all following tables, traditional devel-
opmental metrics are shaded.
</tableCaption>
<bodyText confidence="0.999811633333333">
been implementations of completely automated as-
sessments of IPSYN (Sagae et al., 2005) and D-
Level (Lu, 2009) which take advantage of automatic
parsing and achieve results comparable to manual
assessments. Likewise, in the ESL domain, Chen
and Zechner (2011) automate the evaluation of syn-
tactic complexity of non-native speech.
Thus, it has been demonstrated that NLP tech-
niques can compute existing scores of language pro-
ficiency. However, the definition of first-language
developmental metrics has as yet been left up to hu-
man reasoning. In this paper, we consider the au-
tomatic induction of more accurate developmental
metrics using child language data. We extract fea-
tures from longitudinal child language data and con-
duct two sets of experiments. For individual chil-
dren, we use least-squares regression over our fea-
tures to predict the age of a held-out language sam-
ple. We find that on average, existing single met-
rics of development are outperformed by a weighted
combination of our features.
In our second set of experiments, we investigate
whether metrics can be learned across children. To
do so, we consider a speech sample ordering task.
We use optimization techniques to learn weight-
ings over features that allow generalization across
children. Although traditional measures like MLU
and D-level perform well on this task, we find that
a learned combination of features outperforms any
single pre-defined developmental score.
</bodyText>
<sectionHeader confidence="0.989578" genericHeader="introduction">
2 Data
</sectionHeader>
<bodyText confidence="0.97604">
To identify trends in child language learning we
need a corpus of child speech samples, which we
</bodyText>
<figure confidence="0.595488">
Age (months)
</figure>
<figureCaption confidence="0.9761755">
Figure 1: Number of utterances across ages of
each child in our corpus. Sources: Nina (Suppes,
1974), Sarah (Brown, 1973), Naomi (Sachs, 1983),
Peter (Bloom et al., 1974; Bloom et al., 1975),
Ross (MacWhinney, 2000), Abe (Kuczaj, 1977) and
Adam (Brown, 1973)
</figureCaption>
<bodyText confidence="0.999976551724138">
take from the CHILDES database (MacWhinney,
2000). CHILDES is a collection of corpora from
many studies of child language based on episodic
speech data. Since we are interested in development
over time, our corpus consists of seven longitudinal
studies of individual children. Data for each child
is grouped and sorted by the child’s age in months,
so that we have a single data point for each month
in which a child was observed. The size of our data
set, broken down by child, is shown in Figure 1.
We take advantage of automatic dependency
parses bundled with the CHILDES transcripts
(Sagae et al., 2007) and harvest features that should
be informative and complementary in assessing
grammatical knowledge. We first note three stan-
dard measures of language development: (i) MLU,
a measure of utterance length, (ii) mean depth of de-
pendency parse trees, a measure of syntactic com-
plexity similar to that of Yngve (1960), and (iii) D-
level, a measure of linguistic competence based on
observations of syntactic constructions.
Beyond the three traditional developmental met-
rics, we record five additional features. We count
two of Brown’s (1973) obligatory morphemes — ar-
ticles and contracted auxiliary “be” verbs — as well
as occurrences of any preposition. These counted
features are normalized by a child’s total number
of utterances at a given age. Finally, we include
two vocabulary-centric features: Average word fre-
</bodyText>
<figure confidence="0.994936714285714">
Nina
Sarah
Naomi
Peter
Ross
Abe
Adam
2,250
0
14 21 28 35 42 49 56 63 70 77
9,000
6,750
Utterances
4,500
</figure>
<page confidence="0.973324">
96
</page>
<table confidence="0.997418666666667">
D-Level Depth MLU All Features
Adam 14.037 14.149 11.128 14.175
Abe 34.69 44.701 34.509 39.931
Ross 329.64 336.612 345.046 244.071
Peter 23.58 13.045 8.245 24.128
Naomi 24.458 28.426 34.956 45.036
Sarah 12.503 20.878 13.905 6.989
Nina 7.654 6.477 4.255 3.96
Mean 63.795 66.327 64.578 54.041
</table>
<tableCaption confidence="0.789456">
Table 2: Mean squared error from 10-fold cross valida-
tion of linear regression on individual children. The low-
est error for each child is shown in bold.
</tableCaption>
<bodyText confidence="0.999624916666667">
quency (i.e. how often a word is used in a stan-
dard corpus) as indicated by CELEX (Baayen et al.,
1995), and the child’s ratio of function words (deter-
miners, pronouns, prepositions, auxiliaries and con-
junctions) to content words.
To validate a developmental measure, we rely on
the assumption that a perfect metric should increase
monotonically over time. We therefore calculate
Kendall’s Tau coefficient (T) between an ordering of
each child’s speech samples by age, and an order-
ing by the given scoring metric. The T coefficient
is a measure of rank correlation where two identical
orderings receive a T of 1, complete opposite order-
ings receive a T of -1, and independent orderings are
expected to receive a T of zero. The T coefficients
for each of our 8 features individually applied to the
7 children are shown in Table 1.
We note that the pre-defined indices of language
development — MLU, tree depth and D-Level —
perform the ordering task most accurately. To illus-
trate the degree of variance between children and
features, we also include plots of each child’s D-
Level and contracted auxiliary “be” usage in Figure
2.
</bodyText>
<sectionHeader confidence="0.99973" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.996438555555555">
Learning Individual Child Metrics Our first task
is to predict the age at which a held-out speech sam-
ple was produced, given a set of age-stamped sam-
ples from the same child. We perform a least squares
regression on each child, treating age as the depen-
dent variable, and our features as independent vari-
ables. Each data set is split into 10 random folds of
90% training and 10% test data. Mean squared error
is reported in Table 2. On average, our regression
</bodyText>
<table confidence="0.994116">
MLU All Features MLU &amp; Fn. / Content
0.7456 0.7457 0.7780
</table>
<tableCaption confidence="0.949448333333333">
Table 3: Average T of orderings produced by MLU (the
best traditional index) and our learned metric, versus true
chronological order. Highest T is shown in bold.
</tableCaption>
<bodyText confidence="0.982232852941176">
achieves lower error than any individual feature by
itself.
Learning General Metrics Across Children To
produce a universal metric of language development
like MLU or D-Level, we train on data pooled across
many children. For each of 7 folds, a single child’s
data is separated as a test set while the remaining
children are used for training. Since Ross is the only
child with samples beyond 62 months, we do not at-
tempt to learn a general measure of language devel-
opment at these ages, but rather remove these data
points.
Unlike the individual-child case, we do not pre-
dict absolute ages based on speech samples, as each
child is expected to learn at a different rate. Instead,
we learn an ordering model which attempts to place
each sample in its relative place in time. The model
computes a score from a weighted quadratic combi-
nation of our features and orders the samples based
on their computed scores. To learn the parameters
of the model, we seek to maximize the Kendall T
between true and predicted orderings, summed over
the training children. We pass this objective function
to Nelder-Mead (Nelder and Mead, 1965), a stan-
dard gradient-free optimization algorithm. Nelder-
Mead constructs a simplex at its initial guess of pa-
rameter values and iteratively makes small shifts in
the simplex to satisfy a descent condition until a lo-
cal maximum is reached.
We report the average Kendall T achieved by this
algorithm over several feature combinations in Ta-
ble 3. Because we modify our data set in this ex-
periment, for comparison we also show the average
Kendall T achieved by MLU on the truncated data.
</bodyText>
<sectionHeader confidence="0.999764" genericHeader="conclusions">
4 Discussion
</sectionHeader>
<bodyText confidence="0.99996725">
Our first set of experiments verified that we can
achieve a decrease in mean squared error over ex-
isting metrics in a child-specific age prediction task.
However, the results of this experiment are skewed
</bodyText>
<page confidence="0.998051">
97
</page>
<bodyText confidence="0.960843333333333">
in favor of the learned metric by the apparent diffi-
in favor of the learned metric by the apparent diffi- Through trial and error, we discovered we could
Through trial and error, we discovered we could
culty of predicting Ross’s age. As demonstrated in
improve performance by omitting certain features.
culty of predicting Ross’s age. As demonstrated in improve performance by omitting certain features.
</bodyText>
<figureCaption confidence="0.875366666666667">
Figure 2, Ross’s data exhibits major variance, and
In Table 3, we report the best discovered feature
Figure 2, Ross’s data exhibits major variance, and In Table 3, we report the best discovered feature
</figureCaption>
<bodyText confidence="0.984692232323232">
also includes data from later ages than that of the
combination including only two relatively uncorre-
also includes data from later ages than that of the combination including only two relatively uncorre-
other children. It is well known that MLU’s per-
lated features, MLU and function/content word ra-
other children. It is well known that MLU’s per- lated features, MLU and function/content word ra-
formance as a measure of linguistic ability quickly
tio. If downweighting some features yields a better
formance as a measure of linguistic ability quickly tio. If downweighting some features yields a better
drops off with age.
result, we would expect to discover that with our op-
drops off with age. result, we would expect to discover that with our op-
timization algorithm, but this evidently not the case,
During our first experiment, we also attempted to timization algorithm, but this evidently not the case,
During our first experiment, we also attempted to
perhaps due to our limited sample of 7 children.
capture more nuanced learning curves than the lin- perhaps due to our limited sample of 7 children.
capture more nuanced learning curves than the lin-
ear case. Specifically, we anticipated that learning
The fact that weights move so little suggests that
ear case. Specifically, we anticipated that learning The fact that weights move so little suggests that
over time should follow an S-shaped curve. This
our best result is stuck in a local maximum. To
over time should follow an S-shaped curve. This our best result is stuck in a local maximum. To
follows from observations of a “fast mapping” spurt
investigate this, we also experimented with Differ-
follows from observations of a “fast mapping” spurt investigate this, we also experimented with Differ-
in child word learning (Woodward et al., 1994), and
ential Evolution (Storn and Price, 1997) and SVM-
in child word learning (Woodward et al., 1994), and ential Evolution (Storn and Price, 1997) and SVM-
the idea that learning must eventually level off as
ranking (Joachims, 2002), the former a global op-
the idea that learning must eventually level off as ranking (Joachims, 2002), the former a global op-
mastery is attained. To allow our model to capture
timization technique, and the latter a method de-
mastery is attained. To allow our model to capture timization technique, and the latter a method de-
non-linear learning rates, we fit logit and quadratic
veloped specifically to learn orderings. Although
non-linear learning rates, we fit logit and quadratic veloped specifically to learn orderings. Although
functions to the data. Despite the increased free-
these algorithms are more willing to adjust param-
functions to the data. Despite the increased free- these algorithms are more willing to adjust param-
dom, only Nina’s predictions benefited from these
eter weights and theoretically should not get stuck
dom, only Nina’s predictions benefited from these eter weights and theoretically should not get stuck
more complex models. With every other child, these
in local maxima, they are still edged out in perfor-
more complex models. With every other child, these in local maxima, they are still edged out in perfor-
functions fit the data to a linear section of the curve
mance by Nelder-Mead. It may be that the early
functions fit the data to a linear section of the curve mance by Nelder-Mead. It may be that the early
and yielded much larger errors than simple linear
stopping of Nelder-Mead serves as a sort of smooth-
and yielded much larger errors than simple linear stopping of Nelder-Mead serves as a sort of smooth-
regression. The preference towards linearity may
ing in this very small data-set of 7 children.
regression. The preference towards linearity may ing in this very small data-set of 7 children.
be due to the limited time span of our data. With
be due to the limited time span of our data. With Our improvements over hand-crafted measures
Our improvements over hand-crafted measures
higher ages, the leveling off of linguistic perfor-
higher ages, the leveling off of linguistic perfor- of language development show promise. In the
of language development show promise. In the
mance would need to be modeled.
mance would need to be modeled. case of individual children, we outperform existing
case of individual children, we outperform existing
In our second set of experiments, we attempted
measures of development, especially past the early
In our second set of experiments, we attempted measures of development, especially past the early
to learn a general metric across children. Here we
stages of development when MLU ceases to corre-
to learn a general metric across children. Here we stages of development when MLU ceases to corre-
also achieved positive results with simple methods,
late with age. Our attempts to learn a metric across
also achieved positive results with simple methods, late with age. Our attempts to learn a metric across
just edging out established measures of language de-
children met with more limited success. However,
just edging out established measures of language de- children met with more limited success. However,
velopment. The generality of our learned metric
when we restricted our regression to two of the least
velopment. The generality of our learned metric when we restricted our regression to two of the least
supports the hypothesis that children follow simi-
correlated features, MLU and the function/content
supports the hypothesis that children follow simi- correlated features, MLU and the function/content
lar paths of language development. Although our
word ratio, we were able to beat manually created
lar paths of language development. Although our word ratio, we were able to beat manually created
learned solution is slightly more favorable than pre-
metrics. These results suggest that more sophisti-
learned solution is slightly more favorable than pre- metrics. These results suggest that more sophisti-
existing metrics, it performs very little learning. Us-
cated models and techniques combined with more
existing metrics, it performs very little learning. Us- cated models and techniques combined with more
ing all features, learned parameter weights remain at
data could lead to more accurate metrics as well as
ing all features, learned parameter weights remain at data could lead to more accurate metrics as well as
or extremely close to the starting point of 1.
insights into the language learning process.
or extremely close to the starting point of 1. insights into the language learning process.
</bodyText>
<page confidence="0.987855">
98
</page>
<figure confidence="0.99836676">
100
100
100
100
100
100
100
Abe
Naomi
Sarah
Adam
Peter
Ross
Nina
80
80
80
80
80
80
60
60
60
60
60
60
40
40
40
40
40
40
20
20
20
20
20
20
0
0 1 2
0
0 1 2
0
0 1 2
0
0 1 2
0
0 1 2
0
0 1 2
</figure>
<figureCaption confidence="0.9656285">
Figure 2: Child age plotted against D-Level (top) and counts of contracted auxiliary “be” (bottom) with best fit lines.
Since our regression predicts child age, age in months is plotted on the y-axis.
</figureCaption>
<figure confidence="0.999776545454546">
0 1 2
80
60
40
20
0
0 0.1 0.2
20
0 0.1 0.2
0 0.1 0.2
0 0.1 0.2
0 0.1 0.2
0 0.1 0.2
100
80
60
40
20
0 0.1 0.2
0
0
0
100
80
60
40
20
100
80
60
40
100
80
60
40
20
0
100
80
60
40
20
0
100
80
60
40
20
0
100
80
60
40
20
0
</figure>
<sectionHeader confidence="0.886776" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999554135135135">
R.H. Baayen, R. Piepenbrock, and L. Gulikers. 1995.
The CELEX lexical database (release 2)[cd-rom].
Philadelphia, PA: Linguistic Data Consortium, Uni-
versity of Pennsylvania [Distributor].
L. Bloom, L. Hood, and P. Lightbown. 1974. Imitation in
language development: If, when, and why. Cognitive
Psychology, 6(3):380–420.
L. Bloom, P. Lightbown, L. Hood, M. Bowerman,
M. Maratsos, and M.P. Maratsos. 1975. Structure and
variation in child language. Monographs of the Soci-
ety for Research in Child Development, pages 1–97.
R. Brown. 1973. A First Language: The Early Stages.
Harvard U. Press.
M. Chen and K. Zechner. 2011. Computing and evaluat-
ing syntactic complexity features for automated scor-
ing of spontaneous non-native speech. In Proceed-
ings of the 49th Annual Meeting of the Association for
Computational Linguistics, pages 722–731.
M.A. Covington, C. He, C. Brown, L. Naci, and J. Brown.
2006. How complex is that sentence? a proposed re-
vision of the Rosenberg and Abbeduto D-level scale.
Research Report, AI Center, University of Georgia.
T. Joachims. 2002. Optimizing search engines us-
ing clickthrough data. In Proceedings of the Eighth
ACM SIGKDD International Conference on Knowl-
edge Discovery and Data Mining, pages 133–142.
ACM.
S.A. Kuczaj. 1977. The acquisition of regular and irreg-
ular past tense forms. Journal of Verbal Learning and
Verbal Behavior, 16(5):589–600.
S.H. Long and R.W. Channell. 2001. Accuracy of
four language analysis procedures performed automat-
ically. American Journal of Speech-Language Pathol-
ogy, 10(2):180.
X. Lu. 2009. Automatic measurement of syntactic com-
plexity in child language acquisition. International
Journal of Corpus Linguistics, 14(1):3–28.
B. MacWhinney. 2000. The CHILDES project: Tools for
analyzing talk, volume 2. Psychology Press.
J.A. Nelder and R. Mead. 1965. A simplex method
for function minimization. The Computer Journal,
7(4):308–313.
S. Rosenberg, L. Abbeduto, et al. 1987. Indicators of
linguistic competence in the peer group conversational
behavior of mildly retarded adults. Applied Psycholin-
guistics, 8(1):19–32.
J. Sachs. 1983. Talking about the there and then: The
emergence of displaced reference in parent-child dis-
course. Childrens Language, 4.
K. Sagae, A. Lavie, and B. MacWhinney. 2005. Auto-
matic measurement of syntactic development in child
language. In Proceedings of the 43rd Annual Meeting
on Association for Computational Linguistics, pages
197–204. Association for Computational Linguistics.
K. Sagae, E. Davis, A. Lavie, B. MacWhinney, and
S. Wintner. 2007. High-accuracy annotation and
parsing of CHILDES transcripts. In Proceedings of
the Workshop on Cognitive Aspects of Computational
Language Acquisition, pages 25–32. Association for
Computational Linguistics.
H.S. Scarborough. 1990. Index of productive syntax.
Applied Psycholinguistics, 11(1):1–22.
R. Storn and K. Price. 1997. Differential evolution–a
simple and efficient heuristic for global optimization
over continuous spaces. Journal of Global Optimiza-
tion, 11(4):341–359.
P. Suppes. 1974. The semantics of children’s language.
American Psychologist, 29(2):103.
A.L. Woodward, E.M. Markman, and C.M. Fitzsimmons.
1994. Rapid word learning in 13-and 18-month-olds.
Developmental Psychology, 30(4):553.
V.H. Yngve. 1960. A model and an hypothesis for lan-
guage structure. Proceedings of the American Philo-
sophical Society, 104(5):444–466.
</reference>
<page confidence="0.99897">
99
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.860557">
<title confidence="0.999908">Automatically Learning Measures of Child Language Development</title>
<author confidence="0.99996">Sam Sahakian</author>
<affiliation confidence="0.99978">University of Wisconsin - Madison</affiliation>
<email confidence="0.999348">sahakian@cs.wisc.edu</email>
<author confidence="0.869524">Benjamin</author>
<affiliation confidence="0.999031">University of Wisconsin -</affiliation>
<email confidence="0.999465">bsnyder@cs.wisc.edu</email>
<abstract confidence="0.999454533333334">We propose a new approach for the creation of child language development metrics. A set of linguistic features is computed on child speech samples and used as input in two age prediction experiments. In the first experiment, we learn a child-specific metric and predicts the ages at which speech samples were produced. We then learn a more general developmental index by applying our method across children, predicting relative temporal orderings of speech samples. In both cases we compare our results with established measures of language development, showing improvements in age prediction performance.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R H Baayen</author>
<author>R Piepenbrock</author>
<author>L Gulikers</author>
</authors>
<date>1995</date>
<booktitle>The CELEX lexical database (release 2)[cd-rom].</booktitle>
<institution>Linguistic Data Consortium, University of Pennsylvania [Distributor].</institution>
<location>Philadelphia, PA:</location>
<contexts>
<context position="8024" citStr="Baayen et al., 1995" startWordPosition="1260" endWordPosition="1263">am 2,250 0 14 21 28 35 42 49 56 63 70 77 9,000 6,750 Utterances 4,500 96 D-Level Depth MLU All Features Adam 14.037 14.149 11.128 14.175 Abe 34.69 44.701 34.509 39.931 Ross 329.64 336.612 345.046 244.071 Peter 23.58 13.045 8.245 24.128 Naomi 24.458 28.426 34.956 45.036 Sarah 12.503 20.878 13.905 6.989 Nina 7.654 6.477 4.255 3.96 Mean 63.795 66.327 64.578 54.041 Table 2: Mean squared error from 10-fold cross validation of linear regression on individual children. The lowest error for each child is shown in bold. quency (i.e. how often a word is used in a standard corpus) as indicated by CELEX (Baayen et al., 1995), and the child’s ratio of function words (determiners, pronouns, prepositions, auxiliaries and conjunctions) to content words. To validate a developmental measure, we rely on the assumption that a perfect metric should increase monotonically over time. We therefore calculate Kendall’s Tau coefficient (T) between an ordering of each child’s speech samples by age, and an ordering by the given scoring metric. The T coefficient is a measure of rank correlation where two identical orderings receive a T of 1, complete opposite orderings receive a T of -1, and independent orderings are expected to r</context>
</contexts>
<marker>Baayen, Piepenbrock, Gulikers, 1995</marker>
<rawString>R.H. Baayen, R. Piepenbrock, and L. Gulikers. 1995. The CELEX lexical database (release 2)[cd-rom]. Philadelphia, PA: Linguistic Data Consortium, University of Pennsylvania [Distributor].</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Bloom</author>
<author>L Hood</author>
<author>P Lightbown</author>
</authors>
<title>Imitation in language development: If, when, and why.</title>
<date>1974</date>
<journal>Cognitive Psychology,</journal>
<volume>6</volume>
<issue>3</issue>
<contexts>
<context position="5859" citStr="Bloom et al., 1974" startWordPosition="899" endWordPosition="902">we consider a speech sample ordering task. We use optimization techniques to learn weightings over features that allow generalization across children. Although traditional measures like MLU and D-level perform well on this task, we find that a learned combination of features outperforms any single pre-defined developmental score. 2 Data To identify trends in child language learning we need a corpus of child speech samples, which we Age (months) Figure 1: Number of utterances across ages of each child in our corpus. Sources: Nina (Suppes, 1974), Sarah (Brown, 1973), Naomi (Sachs, 1983), Peter (Bloom et al., 1974; Bloom et al., 1975), Ross (MacWhinney, 2000), Abe (Kuczaj, 1977) and Adam (Brown, 1973) take from the CHILDES database (MacWhinney, 2000). CHILDES is a collection of corpora from many studies of child language based on episodic speech data. Since we are interested in development over time, our corpus consists of seven longitudinal studies of individual children. Data for each child is grouped and sorted by the child’s age in months, so that we have a single data point for each month in which a child was observed. The size of our data set, broken down by child, is shown in Figure 1. We take a</context>
</contexts>
<marker>Bloom, Hood, Lightbown, 1974</marker>
<rawString>L. Bloom, L. Hood, and P. Lightbown. 1974. Imitation in language development: If, when, and why. Cognitive Psychology, 6(3):380–420.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Bloom</author>
<author>P Lightbown</author>
<author>L Hood</author>
<author>M Bowerman</author>
<author>M Maratsos</author>
<author>M P Maratsos</author>
</authors>
<title>Structure and variation in child language. Monographs of the Society for Research in Child Development,</title>
<date>1975</date>
<pages>1--97</pages>
<contexts>
<context position="5880" citStr="Bloom et al., 1975" startWordPosition="903" endWordPosition="906"> sample ordering task. We use optimization techniques to learn weightings over features that allow generalization across children. Although traditional measures like MLU and D-level perform well on this task, we find that a learned combination of features outperforms any single pre-defined developmental score. 2 Data To identify trends in child language learning we need a corpus of child speech samples, which we Age (months) Figure 1: Number of utterances across ages of each child in our corpus. Sources: Nina (Suppes, 1974), Sarah (Brown, 1973), Naomi (Sachs, 1983), Peter (Bloom et al., 1974; Bloom et al., 1975), Ross (MacWhinney, 2000), Abe (Kuczaj, 1977) and Adam (Brown, 1973) take from the CHILDES database (MacWhinney, 2000). CHILDES is a collection of corpora from many studies of child language based on episodic speech data. Since we are interested in development over time, our corpus consists of seven longitudinal studies of individual children. Data for each child is grouped and sorted by the child’s age in months, so that we have a single data point for each month in which a child was observed. The size of our data set, broken down by child, is shown in Figure 1. We take advantage of automatic</context>
</contexts>
<marker>Bloom, Lightbown, Hood, Bowerman, Maratsos, Maratsos, 1975</marker>
<rawString>L. Bloom, P. Lightbown, L. Hood, M. Bowerman, M. Maratsos, and M.P. Maratsos. 1975. Structure and variation in child language. Monographs of the Society for Research in Child Development, pages 1–97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Brown</author>
</authors>
<title>A First Language: The Early Stages.</title>
<date>1973</date>
<publisher>Harvard U. Press.</publisher>
<contexts>
<context position="2280" citStr="Brown, 1973" startWordPosition="335" endWordPosition="336">w well would such a measure generalize across children? This last question touches on an underlying assumption made in much of the child language literature– that while children progress grammatically at different rates, they follow fixed stages in their development. If a developmental index automatically learned from one set of children could be accurately applied to others, it would vindicate this assumption of shared developmental paths. Several metrics of language development have been set forth in the psycholinguistics literature. Standard measures include Mean Length of Utterance (MLU) (Brown, 1973)– the average length in morphemes of conversational turns, Index of Productive Syntax (IPSYN) (Scarborough, 1990)– a multi-tiered scoring process where over 60 individual features are counted by hand and combined into tiered scores, and D-Level (Rosenberg et al., 1987; Covington et al., 2006)– a score for individual sentences based on the observed presence of key syntactic structures. Today, these hand-crafted metrics persist as measurements of child language development, each taking a slightly different angle to assess the same question: Exactly how much grammatical knowledge does a young lea</context>
<context position="5811" citStr="Brown, 1973" startWordPosition="893" endWordPosition="894">can be learned across children. To do so, we consider a speech sample ordering task. We use optimization techniques to learn weightings over features that allow generalization across children. Although traditional measures like MLU and D-level perform well on this task, we find that a learned combination of features outperforms any single pre-defined developmental score. 2 Data To identify trends in child language learning we need a corpus of child speech samples, which we Age (months) Figure 1: Number of utterances across ages of each child in our corpus. Sources: Nina (Suppes, 1974), Sarah (Brown, 1973), Naomi (Sachs, 1983), Peter (Bloom et al., 1974; Bloom et al., 1975), Ross (MacWhinney, 2000), Abe (Kuczaj, 1977) and Adam (Brown, 1973) take from the CHILDES database (MacWhinney, 2000). CHILDES is a collection of corpora from many studies of child language based on episodic speech data. Since we are interested in development over time, our corpus consists of seven longitudinal studies of individual children. Data for each child is grouped and sorted by the child’s age in months, so that we have a single data point for each month in which a child was observed. The size of our data set, broke</context>
</contexts>
<marker>Brown, 1973</marker>
<rawString>R. Brown. 1973. A First Language: The Early Stages. Harvard U. Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Chen</author>
<author>K Zechner</author>
</authors>
<title>Computing and evaluating syntactic complexity features for automated scoring of spontaneous non-native speech.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>722--731</pages>
<contexts>
<context position="4390" citStr="Chen and Zechner (2011)" startWordPosition="664" endWordPosition="667">638 Naomi 0.812 0.746 0.540 0.652 0.504 0.609 0.710 0.710 Sarah 0.829 0.550 0.733 0.382 0.654 0.570 0.731 0.808 Nina 0.824 0.758 0.780 0.560 0.451 0.429 0.780 0.890 Mean: 0.646 0.521 0.597 0.390 0.461 0.465 0.609 0.670 Table 1: T of each feature versus time, for each individual child. In this and all following tables, traditional developmental metrics are shaded. been implementations of completely automated assessments of IPSYN (Sagae et al., 2005) and DLevel (Lu, 2009) which take advantage of automatic parsing and achieve results comparable to manual assessments. Likewise, in the ESL domain, Chen and Zechner (2011) automate the evaluation of syntactic complexity of non-native speech. Thus, it has been demonstrated that NLP techniques can compute existing scores of language proficiency. However, the definition of first-language developmental metrics has as yet been left up to human reasoning. In this paper, we consider the automatic induction of more accurate developmental metrics using child language data. We extract features from longitudinal child language data and conduct two sets of experiments. For individual children, we use least-squares regression over our features to predict the age of a held-o</context>
</contexts>
<marker>Chen, Zechner, 2011</marker>
<rawString>M. Chen and K. Zechner. 2011. Computing and evaluating syntactic complexity features for automated scoring of spontaneous non-native speech. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 722–731.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Covington</author>
<author>C He</author>
<author>C Brown</author>
<author>L Naci</author>
<author>J Brown</author>
</authors>
<title>How complex is that sentence? a proposed revision of the Rosenberg and Abbeduto D-level scale. Research Report,</title>
<date>2006</date>
<institution>AI Center, University of Georgia.</institution>
<contexts>
<context position="2573" citStr="Covington et al., 2006" startWordPosition="378" endWordPosition="381">ntal index automatically learned from one set of children could be accurately applied to others, it would vindicate this assumption of shared developmental paths. Several metrics of language development have been set forth in the psycholinguistics literature. Standard measures include Mean Length of Utterance (MLU) (Brown, 1973)– the average length in morphemes of conversational turns, Index of Productive Syntax (IPSYN) (Scarborough, 1990)– a multi-tiered scoring process where over 60 individual features are counted by hand and combined into tiered scores, and D-Level (Rosenberg et al., 1987; Covington et al., 2006)– a score for individual sentences based on the observed presence of key syntactic structures. Today, these hand-crafted metrics persist as measurements of child language development, each taking a slightly different angle to assess the same question: Exactly how much grammatical knowledge does a young learner possess? NLP technology has been applied to help automate the otherwise tedious calculation of these measures. Computerized Profiling (CP) (Long and Channell, 2001) is a software package that produces semi-automated language assessments, using partof-speech tagging and human supervision.</context>
</contexts>
<marker>Covington, He, Brown, Naci, Brown, 2006</marker>
<rawString>M.A. Covington, C. He, C. Brown, L. Naci, and J. Brown. 2006. How complex is that sentence? a proposed revision of the Rosenberg and Abbeduto D-level scale. Research Report, AI Center, University of Georgia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Optimizing search engines using clickthrough data.</title>
<date>2002</date>
<booktitle>In Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,</booktitle>
<pages>133--142</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="14214" citStr="Joachims, 2002" startWordPosition="2301" endWordPosition="2302">result is stuck in a local maximum. To over time should follow an S-shaped curve. This our best result is stuck in a local maximum. To follows from observations of a “fast mapping” spurt investigate this, we also experimented with Differfollows from observations of a “fast mapping” spurt investigate this, we also experimented with Differin child word learning (Woodward et al., 1994), and ential Evolution (Storn and Price, 1997) and SVMin child word learning (Woodward et al., 1994), and ential Evolution (Storn and Price, 1997) and SVMthe idea that learning must eventually level off as ranking (Joachims, 2002), the former a global opthe idea that learning must eventually level off as ranking (Joachims, 2002), the former a global opmastery is attained. To allow our model to capture timization technique, and the latter a method demastery is attained. To allow our model to capture timization technique, and the latter a method denon-linear learning rates, we fit logit and quadratic veloped specifically to learn orderings. Although non-linear learning rates, we fit logit and quadratic veloped specifically to learn orderings. Although functions to the data. Despite the increased freethese algorithms are </context>
</contexts>
<marker>Joachims, 2002</marker>
<rawString>T. Joachims. 2002. Optimizing search engines using clickthrough data. In Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 133–142. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S A Kuczaj</author>
</authors>
<title>The acquisition of regular and irregular past tense forms.</title>
<date>1977</date>
<journal>Journal of Verbal Learning and Verbal Behavior,</journal>
<volume>16</volume>
<issue>5</issue>
<contexts>
<context position="5925" citStr="Kuczaj, 1977" startWordPosition="911" endWordPosition="912">es to learn weightings over features that allow generalization across children. Although traditional measures like MLU and D-level perform well on this task, we find that a learned combination of features outperforms any single pre-defined developmental score. 2 Data To identify trends in child language learning we need a corpus of child speech samples, which we Age (months) Figure 1: Number of utterances across ages of each child in our corpus. Sources: Nina (Suppes, 1974), Sarah (Brown, 1973), Naomi (Sachs, 1983), Peter (Bloom et al., 1974; Bloom et al., 1975), Ross (MacWhinney, 2000), Abe (Kuczaj, 1977) and Adam (Brown, 1973) take from the CHILDES database (MacWhinney, 2000). CHILDES is a collection of corpora from many studies of child language based on episodic speech data. Since we are interested in development over time, our corpus consists of seven longitudinal studies of individual children. Data for each child is grouped and sorted by the child’s age in months, so that we have a single data point for each month in which a child was observed. The size of our data set, broken down by child, is shown in Figure 1. We take advantage of automatic dependency parses bundled with the CHILDES t</context>
</contexts>
<marker>Kuczaj, 1977</marker>
<rawString>S.A. Kuczaj. 1977. The acquisition of regular and irregular past tense forms. Journal of Verbal Learning and Verbal Behavior, 16(5):589–600.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S H Long</author>
<author>R W Channell</author>
</authors>
<title>Accuracy of four language analysis procedures performed automatically.</title>
<date>2001</date>
<journal>American Journal of Speech-Language Pathology,</journal>
<volume>10</volume>
<issue>2</issue>
<contexts>
<context position="3049" citStr="Long and Channell, 2001" startWordPosition="450" endWordPosition="453"> where over 60 individual features are counted by hand and combined into tiered scores, and D-Level (Rosenberg et al., 1987; Covington et al., 2006)– a score for individual sentences based on the observed presence of key syntactic structures. Today, these hand-crafted metrics persist as measurements of child language development, each taking a slightly different angle to assess the same question: Exactly how much grammatical knowledge does a young learner possess? NLP technology has been applied to help automate the otherwise tedious calculation of these measures. Computerized Profiling (CP) (Long and Channell, 2001) is a software package that produces semi-automated language assessments, using partof-speech tagging and human supervision. In response to its limited depth of analysis and the necessity for human supervision in CP, there have since 95 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 95–99, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics D-Level Article Count “Be” Count Fn. / Content Prep. Count Word Freq. MLU Depth Adam 0.798 0.532 0.817 0.302 0.399 0.371 0.847 0.855 Abe 0.633 0.479 0.591 0.144 0.269 0.41</context>
</contexts>
<marker>Long, Channell, 2001</marker>
<rawString>S.H. Long and R.W. Channell. 2001. Accuracy of four language analysis procedures performed automatically. American Journal of Speech-Language Pathology, 10(2):180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Lu</author>
</authors>
<title>Automatic measurement of syntactic complexity in child language acquisition.</title>
<date>2009</date>
<journal>International Journal of Corpus Linguistics,</journal>
<volume>14</volume>
<issue>1</issue>
<contexts>
<context position="4241" citStr="Lu, 2009" startWordPosition="644" endWordPosition="645"> 0.144 0.269 0.413 0.534 0.625 Ross 0.252 0.153 -0.061 0.125 0.314 0.209 0.134 0.165 Peter 0.371 0.429 0.781 0.562 0.638 0.657 0.524 0.638 Naomi 0.812 0.746 0.540 0.652 0.504 0.609 0.710 0.710 Sarah 0.829 0.550 0.733 0.382 0.654 0.570 0.731 0.808 Nina 0.824 0.758 0.780 0.560 0.451 0.429 0.780 0.890 Mean: 0.646 0.521 0.597 0.390 0.461 0.465 0.609 0.670 Table 1: T of each feature versus time, for each individual child. In this and all following tables, traditional developmental metrics are shaded. been implementations of completely automated assessments of IPSYN (Sagae et al., 2005) and DLevel (Lu, 2009) which take advantage of automatic parsing and achieve results comparable to manual assessments. Likewise, in the ESL domain, Chen and Zechner (2011) automate the evaluation of syntactic complexity of non-native speech. Thus, it has been demonstrated that NLP techniques can compute existing scores of language proficiency. However, the definition of first-language developmental metrics has as yet been left up to human reasoning. In this paper, we consider the automatic induction of more accurate developmental metrics using child language data. We extract features from longitudinal child languag</context>
</contexts>
<marker>Lu, 2009</marker>
<rawString>X. Lu. 2009. Automatic measurement of syntactic complexity in child language acquisition. International Journal of Corpus Linguistics, 14(1):3–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B MacWhinney</author>
</authors>
<title>The CHILDES project: Tools for analyzing talk, volume 2.</title>
<date>2000</date>
<publisher>Psychology Press.</publisher>
<contexts>
<context position="5905" citStr="MacWhinney, 2000" startWordPosition="908" endWordPosition="909">se optimization techniques to learn weightings over features that allow generalization across children. Although traditional measures like MLU and D-level perform well on this task, we find that a learned combination of features outperforms any single pre-defined developmental score. 2 Data To identify trends in child language learning we need a corpus of child speech samples, which we Age (months) Figure 1: Number of utterances across ages of each child in our corpus. Sources: Nina (Suppes, 1974), Sarah (Brown, 1973), Naomi (Sachs, 1983), Peter (Bloom et al., 1974; Bloom et al., 1975), Ross (MacWhinney, 2000), Abe (Kuczaj, 1977) and Adam (Brown, 1973) take from the CHILDES database (MacWhinney, 2000). CHILDES is a collection of corpora from many studies of child language based on episodic speech data. Since we are interested in development over time, our corpus consists of seven longitudinal studies of individual children. Data for each child is grouped and sorted by the child’s age in months, so that we have a single data point for each month in which a child was observed. The size of our data set, broken down by child, is shown in Figure 1. We take advantage of automatic dependency parses bundle</context>
</contexts>
<marker>MacWhinney, 2000</marker>
<rawString>B. MacWhinney. 2000. The CHILDES project: Tools for analyzing talk, volume 2. Psychology Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Nelder</author>
<author>R Mead</author>
</authors>
<title>A simplex method for function minimization.</title>
<date>1965</date>
<journal>The Computer Journal,</journal>
<volume>7</volume>
<issue>4</issue>
<contexts>
<context position="10869" citStr="Nelder and Mead, 1965" startWordPosition="1747" endWordPosition="1750">e these data points. Unlike the individual-child case, we do not predict absolute ages based on speech samples, as each child is expected to learn at a different rate. Instead, we learn an ordering model which attempts to place each sample in its relative place in time. The model computes a score from a weighted quadratic combination of our features and orders the samples based on their computed scores. To learn the parameters of the model, we seek to maximize the Kendall T between true and predicted orderings, summed over the training children. We pass this objective function to Nelder-Mead (Nelder and Mead, 1965), a standard gradient-free optimization algorithm. NelderMead constructs a simplex at its initial guess of parameter values and iteratively makes small shifts in the simplex to satisfy a descent condition until a local maximum is reached. We report the average Kendall T achieved by this algorithm over several feature combinations in Table 3. Because we modify our data set in this experiment, for comparison we also show the average Kendall T achieved by MLU on the truncated data. 4 Discussion Our first set of experiments verified that we can achieve a decrease in mean squared error over existin</context>
</contexts>
<marker>Nelder, Mead, 1965</marker>
<rawString>J.A. Nelder and R. Mead. 1965. A simplex method for function minimization. The Computer Journal, 7(4):308–313.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Rosenberg</author>
<author>L Abbeduto</author>
</authors>
<title>Indicators of linguistic competence in the peer group conversational behavior of mildly retarded adults.</title>
<date>1987</date>
<journal>Applied Psycholinguistics,</journal>
<volume>8</volume>
<issue>1</issue>
<marker>Rosenberg, Abbeduto, 1987</marker>
<rawString>S. Rosenberg, L. Abbeduto, et al. 1987. Indicators of linguistic competence in the peer group conversational behavior of mildly retarded adults. Applied Psycholinguistics, 8(1):19–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Sachs</author>
</authors>
<title>Talking about the there and then: The emergence of displaced reference in parent-child discourse.</title>
<date>1983</date>
<journal>Childrens Language,</journal>
<volume>4</volume>
<contexts>
<context position="5832" citStr="Sachs, 1983" startWordPosition="896" endWordPosition="897"> children. To do so, we consider a speech sample ordering task. We use optimization techniques to learn weightings over features that allow generalization across children. Although traditional measures like MLU and D-level perform well on this task, we find that a learned combination of features outperforms any single pre-defined developmental score. 2 Data To identify trends in child language learning we need a corpus of child speech samples, which we Age (months) Figure 1: Number of utterances across ages of each child in our corpus. Sources: Nina (Suppes, 1974), Sarah (Brown, 1973), Naomi (Sachs, 1983), Peter (Bloom et al., 1974; Bloom et al., 1975), Ross (MacWhinney, 2000), Abe (Kuczaj, 1977) and Adam (Brown, 1973) take from the CHILDES database (MacWhinney, 2000). CHILDES is a collection of corpora from many studies of child language based on episodic speech data. Since we are interested in development over time, our corpus consists of seven longitudinal studies of individual children. Data for each child is grouped and sorted by the child’s age in months, so that we have a single data point for each month in which a child was observed. The size of our data set, broken down by child, is s</context>
</contexts>
<marker>Sachs, 1983</marker>
<rawString>J. Sachs. 1983. Talking about the there and then: The emergence of displaced reference in parent-child discourse. Childrens Language, 4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sagae</author>
<author>A Lavie</author>
<author>B MacWhinney</author>
</authors>
<title>Automatic measurement of syntactic development in child language.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>197--204</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4219" citStr="Sagae et al., 2005" startWordPosition="637" endWordPosition="640">.847 0.855 Abe 0.633 0.479 0.591 0.144 0.269 0.413 0.534 0.625 Ross 0.252 0.153 -0.061 0.125 0.314 0.209 0.134 0.165 Peter 0.371 0.429 0.781 0.562 0.638 0.657 0.524 0.638 Naomi 0.812 0.746 0.540 0.652 0.504 0.609 0.710 0.710 Sarah 0.829 0.550 0.733 0.382 0.654 0.570 0.731 0.808 Nina 0.824 0.758 0.780 0.560 0.451 0.429 0.780 0.890 Mean: 0.646 0.521 0.597 0.390 0.461 0.465 0.609 0.670 Table 1: T of each feature versus time, for each individual child. In this and all following tables, traditional developmental metrics are shaded. been implementations of completely automated assessments of IPSYN (Sagae et al., 2005) and DLevel (Lu, 2009) which take advantage of automatic parsing and achieve results comparable to manual assessments. Likewise, in the ESL domain, Chen and Zechner (2011) automate the evaluation of syntactic complexity of non-native speech. Thus, it has been demonstrated that NLP techniques can compute existing scores of language proficiency. However, the definition of first-language developmental metrics has as yet been left up to human reasoning. In this paper, we consider the automatic induction of more accurate developmental metrics using child language data. We extract features from long</context>
</contexts>
<marker>Sagae, Lavie, MacWhinney, 2005</marker>
<rawString>K. Sagae, A. Lavie, and B. MacWhinney. 2005. Automatic measurement of syntactic development in child language. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 197–204. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sagae</author>
<author>E Davis</author>
<author>A Lavie</author>
<author>B MacWhinney</author>
<author>S Wintner</author>
</authors>
<title>High-accuracy annotation and parsing of CHILDES transcripts.</title>
<date>2007</date>
<booktitle>In Proceedings of the Workshop on Cognitive Aspects of Computational Language Acquisition,</booktitle>
<pages>25--32</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6556" citStr="Sagae et al., 2007" startWordPosition="1017" endWordPosition="1020">rown, 1973) take from the CHILDES database (MacWhinney, 2000). CHILDES is a collection of corpora from many studies of child language based on episodic speech data. Since we are interested in development over time, our corpus consists of seven longitudinal studies of individual children. Data for each child is grouped and sorted by the child’s age in months, so that we have a single data point for each month in which a child was observed. The size of our data set, broken down by child, is shown in Figure 1. We take advantage of automatic dependency parses bundled with the CHILDES transcripts (Sagae et al., 2007) and harvest features that should be informative and complementary in assessing grammatical knowledge. We first note three standard measures of language development: (i) MLU, a measure of utterance length, (ii) mean depth of dependency parse trees, a measure of syntactic complexity similar to that of Yngve (1960), and (iii) Dlevel, a measure of linguistic competence based on observations of syntactic constructions. Beyond the three traditional developmental metrics, we record five additional features. We count two of Brown’s (1973) obligatory morphemes — articles and contracted auxiliary “be” </context>
</contexts>
<marker>Sagae, Davis, Lavie, MacWhinney, Wintner, 2007</marker>
<rawString>K. Sagae, E. Davis, A. Lavie, B. MacWhinney, and S. Wintner. 2007. High-accuracy annotation and parsing of CHILDES transcripts. In Proceedings of the Workshop on Cognitive Aspects of Computational Language Acquisition, pages 25–32. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H S Scarborough</author>
</authors>
<title>Index of productive syntax.</title>
<date>1990</date>
<journal>Applied Psycholinguistics,</journal>
<volume>11</volume>
<issue>1</issue>
<contexts>
<context position="2393" citStr="Scarborough, 1990" startWordPosition="351" endWordPosition="352">ion made in much of the child language literature– that while children progress grammatically at different rates, they follow fixed stages in their development. If a developmental index automatically learned from one set of children could be accurately applied to others, it would vindicate this assumption of shared developmental paths. Several metrics of language development have been set forth in the psycholinguistics literature. Standard measures include Mean Length of Utterance (MLU) (Brown, 1973)– the average length in morphemes of conversational turns, Index of Productive Syntax (IPSYN) (Scarborough, 1990)– a multi-tiered scoring process where over 60 individual features are counted by hand and combined into tiered scores, and D-Level (Rosenberg et al., 1987; Covington et al., 2006)– a score for individual sentences based on the observed presence of key syntactic structures. Today, these hand-crafted metrics persist as measurements of child language development, each taking a slightly different angle to assess the same question: Exactly how much grammatical knowledge does a young learner possess? NLP technology has been applied to help automate the otherwise tedious calculation of these measure</context>
</contexts>
<marker>Scarborough, 1990</marker>
<rawString>H.S. Scarborough. 1990. Index of productive syntax. Applied Psycholinguistics, 11(1):1–22.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Storn</author>
<author>K Price</author>
</authors>
<title>Differential evolution–a simple and efficient heuristic for global optimization over continuous spaces.</title>
<date>1997</date>
<journal>Journal of Global Optimization,</journal>
<volume>11</volume>
<issue>4</issue>
<contexts>
<context position="14030" citStr="Storn and Price, 1997" startWordPosition="2268" endWordPosition="2271"> move so little suggests that ear case. Specifically, we anticipated that learning The fact that weights move so little suggests that over time should follow an S-shaped curve. This our best result is stuck in a local maximum. To over time should follow an S-shaped curve. This our best result is stuck in a local maximum. To follows from observations of a “fast mapping” spurt investigate this, we also experimented with Differfollows from observations of a “fast mapping” spurt investigate this, we also experimented with Differin child word learning (Woodward et al., 1994), and ential Evolution (Storn and Price, 1997) and SVMin child word learning (Woodward et al., 1994), and ential Evolution (Storn and Price, 1997) and SVMthe idea that learning must eventually level off as ranking (Joachims, 2002), the former a global opthe idea that learning must eventually level off as ranking (Joachims, 2002), the former a global opmastery is attained. To allow our model to capture timization technique, and the latter a method demastery is attained. To allow our model to capture timization technique, and the latter a method denon-linear learning rates, we fit logit and quadratic veloped specifically to learn orderings.</context>
</contexts>
<marker>Storn, Price, 1997</marker>
<rawString>R. Storn and K. Price. 1997. Differential evolution–a simple and efficient heuristic for global optimization over continuous spaces. Journal of Global Optimization, 11(4):341–359.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Suppes</author>
</authors>
<title>The semantics of children’s language.</title>
<date>1974</date>
<journal>American Psychologist,</journal>
<volume>29</volume>
<issue>2</issue>
<contexts>
<context position="5790" citStr="Suppes, 1974" startWordPosition="890" endWordPosition="891">igate whether metrics can be learned across children. To do so, we consider a speech sample ordering task. We use optimization techniques to learn weightings over features that allow generalization across children. Although traditional measures like MLU and D-level perform well on this task, we find that a learned combination of features outperforms any single pre-defined developmental score. 2 Data To identify trends in child language learning we need a corpus of child speech samples, which we Age (months) Figure 1: Number of utterances across ages of each child in our corpus. Sources: Nina (Suppes, 1974), Sarah (Brown, 1973), Naomi (Sachs, 1983), Peter (Bloom et al., 1974; Bloom et al., 1975), Ross (MacWhinney, 2000), Abe (Kuczaj, 1977) and Adam (Brown, 1973) take from the CHILDES database (MacWhinney, 2000). CHILDES is a collection of corpora from many studies of child language based on episodic speech data. Since we are interested in development over time, our corpus consists of seven longitudinal studies of individual children. Data for each child is grouped and sorted by the child’s age in months, so that we have a single data point for each month in which a child was observed. The size o</context>
</contexts>
<marker>Suppes, 1974</marker>
<rawString>P. Suppes. 1974. The semantics of children’s language. American Psychologist, 29(2):103.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A L Woodward</author>
<author>E M Markman</author>
<author>C M Fitzsimmons</author>
</authors>
<date>1994</date>
<booktitle>Rapid word learning in 13-and 18-month-olds. Developmental Psychology,</booktitle>
<volume>30</volume>
<issue>4</issue>
<contexts>
<context position="13984" citStr="Woodward et al., 1994" startWordPosition="2261" endWordPosition="2264">nticipated that learning The fact that weights move so little suggests that ear case. Specifically, we anticipated that learning The fact that weights move so little suggests that over time should follow an S-shaped curve. This our best result is stuck in a local maximum. To over time should follow an S-shaped curve. This our best result is stuck in a local maximum. To follows from observations of a “fast mapping” spurt investigate this, we also experimented with Differfollows from observations of a “fast mapping” spurt investigate this, we also experimented with Differin child word learning (Woodward et al., 1994), and ential Evolution (Storn and Price, 1997) and SVMin child word learning (Woodward et al., 1994), and ential Evolution (Storn and Price, 1997) and SVMthe idea that learning must eventually level off as ranking (Joachims, 2002), the former a global opthe idea that learning must eventually level off as ranking (Joachims, 2002), the former a global opmastery is attained. To allow our model to capture timization technique, and the latter a method demastery is attained. To allow our model to capture timization technique, and the latter a method denon-linear learning rates, we fit logit and quad</context>
</contexts>
<marker>Woodward, Markman, Fitzsimmons, 1994</marker>
<rawString>A.L. Woodward, E.M. Markman, and C.M. Fitzsimmons. 1994. Rapid word learning in 13-and 18-month-olds. Developmental Psychology, 30(4):553.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V H Yngve</author>
</authors>
<title>A model and an hypothesis for language structure.</title>
<date>1960</date>
<journal>Proceedings of the American Philosophical Society,</journal>
<volume>104</volume>
<issue>5</issue>
<contexts>
<context position="6870" citStr="Yngve (1960)" startWordPosition="1069" endWordPosition="1070">nd sorted by the child’s age in months, so that we have a single data point for each month in which a child was observed. The size of our data set, broken down by child, is shown in Figure 1. We take advantage of automatic dependency parses bundled with the CHILDES transcripts (Sagae et al., 2007) and harvest features that should be informative and complementary in assessing grammatical knowledge. We first note three standard measures of language development: (i) MLU, a measure of utterance length, (ii) mean depth of dependency parse trees, a measure of syntactic complexity similar to that of Yngve (1960), and (iii) Dlevel, a measure of linguistic competence based on observations of syntactic constructions. Beyond the three traditional developmental metrics, we record five additional features. We count two of Brown’s (1973) obligatory morphemes — articles and contracted auxiliary “be” verbs — as well as occurrences of any preposition. These counted features are normalized by a child’s total number of utterances at a given age. Finally, we include two vocabulary-centric features: Average word freNina Sarah Naomi Peter Ross Abe Adam 2,250 0 14 21 28 35 42 49 56 63 70 77 9,000 6,750 Utterances 4,</context>
</contexts>
<marker>Yngve, 1960</marker>
<rawString>V.H. Yngve. 1960. A model and an hypothesis for language structure. Proceedings of the American Philosophical Society, 104(5):444–466.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>