<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.99386">
Target Language Adaptation of Discriminative Transfer Parsers
</title>
<author confidence="0.988926">
Oscar Täckström* Ryan McDonald Joakim Nivre*
</author>
<affiliation confidence="0.938658">
SICS I Uppsala University Google Uppsala University
Sweden New York Sweden
</affiliation>
<email confidence="0.993918">
oscar@sics.se ryanmcd@google.com joakim.nivre@lingfil.uu.se
</email>
<sectionHeader confidence="0.997341" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999922428571429">
We study multi-source transfer parsing for
resource-poor target languages; specifically
methods for target language adaptation of
delexicalized discriminative graph-based de-
pendency parsers. We first show how recent
insights on selective parameter sharing, based
on typological and language-family features,
can be applied to a discriminative parser by
carefully decomposing its model features. We
then show how the parser can be relexicalized
and adapted using unlabeled target language
data and a learning method that can incorporate
diverse knowledge sources through ambiguous
labelings. In the latter scenario, we exploit
two sources of knowledge: arc marginals de-
rived from the base parser in a self-training
algorithm, and arc predictions from multiple
transfer parsers in an ensemble-training algo-
rithm. Our final model outperforms the state of
the art in multi-source transfer parsing on 15
out of 16 evaluated languages.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999598181818182">
Many languages still lack access to core NLP tools,
such as part-of-speech taggers and syntactic parsers.
This is largely due to the reliance on fully supervised
learning methods, which require large quantities of
manually annotated training data. Recently, meth-
ods for cross-lingual transfer have appeared as a
promising avenue for overcoming this hurdle for both
part-of-speech tagging (Yarowsky et al., 2001; Das
and Petrov, 2011) and syntactic dependency parsing
(Hwa et al., 2005; Zeman and Resnik, 2008; Ganchev
et al., 2009; McDonald et al., 2011; Naseem et al.,
</bodyText>
<note confidence="0.461896">
* Work primarily carried out while at Google, NY.
</note>
<bodyText confidence="0.999768527777778">
2012). While these methods do not yet compete with
fully supervised approaches, they can drastically out-
perform both unsupervised methods (Klein and Man-
ning, 2004) and weakly supervised methods (Naseem
et al., 2010; Berg-Kirkpatrick and Klein, 2010).
A promising approach to cross-lingual transfer
of syntactic dependency parsers is to use multiple
source languages and to tie model parameters across
related languages. This idea was first explored for
weakly supervised learning (Cohen and Smith, 2009;
Snyder et al., 2009; Berg-Kirkpatrick and Klein,
2010) and recently by Naseem et al. (2012) for multi-
source cross-lingual transfer. In particular, Naseem
et al. showed that by selectively sharing parameters
based on typological features of each language, sub-
stantial improvements can be achieved, compared
to using a single set of parameters for all languages.
However, these methods all employ generative mod-
els with strong independence assumptions and weak
feature representations, which upper bounds their ac-
curacy far below that of feature-rich discriminative
parsers (McDonald et al., 2005; Nivre, 2008).
In this paper, we improve upon the state of the art
in cross-lingual transfer of dependency parsers from
multiple source languages by adapting feature-rich
discriminatively trained parsers to a specific target
language. First, in §4 we show how selective sharing
of model parameters based on typological traits can
be incorporated into a delexicalized discriminative
graph-based parsing model. This requires a careful
decomposition of features into language-generic and
language-specific sets in order to tie specific target
language parameters to their relevant source language
counterparts. The resulting parser outperforms the
method of Naseem et al. (2012) on 12 out of 16 eval-
uated languages. Second, in §5 we introduce a train-
</bodyText>
<page confidence="0.910273">
1061
</page>
<note confidence="0.468952">
Proceedings of NAACL-HLT 2013, pages 1061–1071,
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.9999383125">
ing method that can incorporate diverse knowledge
sources through ambiguously predicted labelings of
unlabeled target language data. This permits effective
relexicalization and target language adaptation of the
transfer parser. Here, we experiment with two differ-
ent knowledge sources: arc sets, which are filtered by
marginal probabilities from the cross-lingual transfer
parser, are used in an ambiguity-aware self-training
algorithm (§5.2); these arc sets are then combined
with the predictions of a different transfer parser in an
ambiguity-aware ensemble-training algorithm (§5.3).
The resulting parser provides significant improve-
ments over a strong baseline parser and achieves a
13% relative error reduction on average with respect
to the best model of Naseem et al. (2012), outper-
forming it on 15 out of the 16 evaluated languages.
</bodyText>
<sectionHeader confidence="0.97643" genericHeader="method">
2 Multi-Source Delexicalized Transfer
</sectionHeader>
<bodyText confidence="0.992942846153846">
The methods proposed in this paper fall into the delex-
icalized transfer approach to multilingual syntactic
parsing (Zeman and Resnik, 2008; McDonald et al.,
2011; Cohen et al., 2011; Søgaard, 2011). In contrast
to annotation projection approaches (Yarowsky et al.,
2001; Hwa et al., 2005; Ganchev et al., 2009; Spreyer
and Kuhn, 2009), delexicalized transfer methods do
not rely on any bitext. Instead, a parser is trained
on annotations in a source language, relying solely
on features that are available in both the source
and the target language, such as “universal” part-of-
speech tags (Zeman and Resnik, 2008; Naseem et al.,
2010; Petrov et al., 2012), cross-lingual word clusters
(Täckström et al., 2012) or type-level features derived
from bilingual dictionaries (Durrett et al., 2012).1
This parser is then directly used to parse the target
language. For languages with similar typology, this
method can be quite accurate, especially when com-
pared to purely unsupervised methods. For instance,
a parser trained on English with only part-of-speech
features can correctly parse the Greek sentence in Fig-
ure 1, even without knowledge of the lexical items
since the sequence of part-of-speech tags determines
the syntactic structure almost unambiguously.
Learning with multiple languages has been shown
to benefit unsupervised learning (Cohen and Smith,
</bodyText>
<footnote confidence="0.928899333333333">
1Note that Täckström et al. (2012) and Durrett et al. (2012)
do require bitext or a bilingual dictionary. The same holds for
most cross-lingual representations, e.g., Klementiev et al. (2012).
</footnote>
<figure confidence="0.45834">
PUNC
DOBJ
PREP POBJ
O TC6v 68W6E a-c&apos;v Map(a -co RLRX(o .
(The) (John) (gave) (to-the) (Maria) (the) (book) .
DET NOUN VERB ADP NOUN DET NOUN P
</figure>
<figureCaption confidence="0.998961333333333">
Figure 1: A Greek sentence which is correctly parsed by a
delexicalized English parser, provided that part-of-speech
tags are available in both the source and target language.
</figureCaption>
<bodyText confidence="0.996179">
2009; Snyder et al., 2009; Berg-Kirkpatrick and
Klein, 2010). Annotations in multiple languages
can be combined in delexicalized transfer as well, as
long as the parser features are available across the in-
volved languages. This idea was explored by McDon-
ald et al. (2011), who showed that target language
accuracy can be improved by simply concatenating
delexicalized treebanks in multiple languages. In
similar work, Cohen et al. (2011) proposed a mixture
model in which the parameters of a generative target
language parser is expressed as a linear interpola-
tion of source language parameters, whereas Søgaard
(2011) showed that target side language models can
be used to selectively subsample training sentences
to improve accuracy. Recently, inspired by the phylo-
genetic prior of Berg-Kirkpatrick and Klein (2010),
Søgaard and Wulff (2012) proposed — among other
ideas — a typologically informed weighting heuristic
for linearly interpolating source language parameters.
However, this weighting did not provide significant
improvements over uniform weighting.
The aforementioned approaches work well for
transfer between similar languages. However, their
assumptions cease to hold for typologically divergent
languages; a target language can rarely be described
as a linear combination of data or model parameters
from a set of source languages, as languages tend
to share varied typological traits; this critical insight
is discussed further in §4. To account for this issue,
Naseem et al. (2012) recently introduced a novel gen-
erative model of dependency parsing, in which the
generative process is factored into separate steps for
the selection of dependents and their ordering. The
parameters used in the selection step are all language
independent, capturing only head-dependent attach-
ment preferences. In the ordering step, however, pa-
rameters are selectively shared between subsets of
</bodyText>
<figure confidence="0.856287666666667">
ROOT
DET NSUBJ
DET
</figure>
<page confidence="0.746268">
1062
</page>
<bodyText confidence="0.478461">
Feature Description
</bodyText>
<note confidence="0.4626115">
81A Order of Subject, Object and Verb
85A Order of Adposition and Noun
86A Order of Genitive and Noun
87A Order of Adjective and Noun
</note>
<tableCaption confidence="0.816301714285714">
88A Order of Demonstrative and Noun
89A Order of Numeral and Noun
Table 1: Typological features from WALS (Dryer and
Haspelmath, 2011), proposed for selective sharing by
Naseem et al. (2012). Feature 89A has the same value for
all studied languages, while 88A differs only for Basque.
These features are therefore subsequently excluded.
</tableCaption>
<bodyText confidence="0.999915083333334">
source languages based on typological features of
the languages extracted from WALS — the World
Atlas of Language Structures (Dryer and Haspelmath,
2011) — as shown in Table 1. In the transfer scenario,
where no supervision is available in the target lan-
guage, this parser achieves the hitherto best published
results across a number of languages; in particular
for target languages with a word order divergent from
the source languages.
However, the generative model of Naseem et al. is
quite impoverished. In the fully supervised setting,
it obtains substantially lower accuracies compared
to a standard arc-factored graph-based parser (Mc-
Donald et al., 2005). Averaged across 16 languages,2
the generative model trained with full supervision on
the target language obtains an accuracy of 67.1%. A
comparable lexicalized discriminative arc-factored
model (McDonald et al., 2005) obtains 84.1%. Even
when delexicalized, this model reaches 78.9%. This
gap in supervised accuracy holds for all 16 languages.
Thus, while selective sharing is a powerful device for
transferring parsers across languages, the underly-
ing generative model used by Naseem et al. (2012)
restricts its potential performance.
</bodyText>
<sectionHeader confidence="0.928634" genericHeader="method">
3 Basic Models and Experimental Setup
</sectionHeader>
<bodyText confidence="0.999114166666667">
Inspired by the superiority of discriminative graph-
based parsing in the supervised scenario, we inves-
tigate whether the insights of Naseem et al. (2012)
on selective parameter sharing can be incorporated
into such models in the transfer scenario. We first re-
view the basic graph-based parser framework and the
</bodyText>
<footnote confidence="0.765658">
2Based on results in Naseem et al. (2012), excluding English.
</footnote>
<bodyText confidence="0.999428333333333">
experimental setup that we will use throughout. We
then delve into details on how to incorporate selec-
tive sharing in this model in §4. In §5, we show how
learning with ambiguous labelings in this parser can
be used for further target language adaptation, both
through self-training and through ensemble-training.
</bodyText>
<subsectionHeader confidence="0.999818">
3.1 Discriminative Graph-Based Parser
</subsectionHeader>
<bodyText confidence="0.999870875">
Let x denote an input sentence and let y E Y(x)
denote a dependency tree, where Y(x) is the set of
well-formed dependency trees spanning x. Hence-
forth, we restrict Y(x) to projective dependency trees,
but all our methods are equally applicable in the non-
projective case. Provided a vector of model parame-
ters θ, the probability of a dependency tree y E Y(x),
conditioned on a sentence x, has the following form:
</bodyText>
<equation confidence="0.845011">
exp {θTb(x, y)}
pθ(y x) = EyIEY(x) exp {θTb(x, y1)} .
</equation>
<bodyText confidence="0.999666">
Without loss of generality, we restrict ourselves to
first-order models, where the feature function b(x, y)
factors over individual arcs (h, m) in y, such that
</bodyText>
<equation confidence="0.933829">
b(x, y) = � φ(x, h, m) ,
(h,m)Ey
</equation>
<bodyText confidence="0.9999756">
where h E [0, x ] and m E [1, x ] are the indices
of the head word and the dependent word of the
arc; h = 0 represents a dummy ROOT token. The
model parameters are estimated by maximizing the
log-likelihood of the training data D = {(xi, yi)}ni=1,
</bodyText>
<equation confidence="0.935819">
n
L(θ; D) = log pθ(yi xi) .
i=1
</equation>
<bodyText confidence="0.99999225">
We use the standard gradient-based L-BFGS algo-
rithm (Liu and Nocedal, 1989) to maximize the log-
likelihood. Eisner’s algorithm (Eisner, 1996) is used
for inference of the Viterbi parse and arc-marginals.
</bodyText>
<subsectionHeader confidence="0.999974">
3.2 Data Sets and Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999952285714286">
To facilitate comparison with the state of the art, we
use the same treebanks and experimental setup as
Naseem et al. (2012). Notably, we use the map-
ping proposed by Naseem et al. (2010) to map from
fine-grained treebank specific part-of-speech tags to
coarse-grained “universal” tags, rather than the more
recent mapping proposed by Petrov et al. (2012). For
</bodyText>
<page confidence="0.744572">
1063
</page>
<figure confidence="0.920859833333334">
Delexicalized MSTParser Bare Selectively shared
d ⊗ l; [d ⊗ l] ⊗ h.p; [d ⊗ l] ⊗ m.p
[d ⊗ l] ⊗ h.p ⊗ m.p
[d ⊗ l] ⊗ h.p ⊗ h+1.p ⊗ m−1.p ⊗ m.p
[d ⊗ l] ⊗ h−1.p ⊗ h.p ⊗ m−1.p ⊗ m.p
[d ⊗ l] ⊗ h.p ⊗ h+1.p ⊗ m.p ⊗ m+1.p
[d ⊗ l] ⊗ h−1.p ⊗ h.p ⊗ m.p ⊗ m+1.p
h.p ⊗ between.p ⊗ m.p
l
[l] ⊗ h.p
[l] ⊗ m.p
[l] ⊗ h.p ⊗ m.p
d ⊗ w.81A ⊗ 1[h.p = VERB ∧ m.p = NOUN]
d ⊗ w.81A ⊗ 1[h.p = VERB ∧ m.p = PRON]
d ⊗ w.85A ⊗ 1[h.p = ADP ∧ m.p = NOUN]
d ⊗ w.85A ⊗ 1[h.p = ADP ∧ m.p = PRON]
d ⊗ w.86A ⊗ 1[h.p = NOUN ∧ m.p = NOUN]
d ⊗ w.87A ⊗ 1[h.p = NOUN ∧ m.p = ADJ]
</figure>
<figureCaption confidence="0.8539575">
Figure 2: Arc-factored feature templates for graph-based parsing. Direction: d ∈ {LEFT, RIGHT}; dependency length:
1 ∈ {1, 2, 3, 4, 5+}; part of speech of head / dependent / words between head and dependent: h.p / m.p / between.p ∈
</figureCaption>
<bodyText confidence="0.944026375">
{NOUN, VERB, ADJ, ADV, PRON, DET, ADP, NUM, CONJ, PRT, PUNC, X}; token to the left / right of z: z_1 / z+1; WALS
features: w.X for X = 81A, 85A, 86A, 87A (see Table 1). [·] denotes an optional template, e.g., [d ⊗ 1] ⊗ h.p ⊗ m.p
expands to templates d ⊗ 1 ⊗ h.p ⊗ m.p and h.p ⊗ m.p, so that the template also falls back on its undirectional variant.
each target language evaluated, the treebanks of the
remaining languages are used as labeled training data,
while the target language treebank is used for testing
only (in §5 a different portion of the target language
treebank is additionally used as unlabeled training
data). We refer the reader to Naseem et al. (2012) for
detailed information on the different treebanks. Due
to divergent treebank annotation guidelines, which
makes fine-grained evaluation difficult, all results
are evaluated in terms of unlabeled attachment score
(UAS). In line with Naseem et al. (2012), we use gold
part-of-speech tags and evaluate only on sentences
of length 50 or less excluding punctuation.
</bodyText>
<subsectionHeader confidence="0.993508">
3.3 Baseline Models
</subsectionHeader>
<bodyText confidence="0.96241825">
We compare our models to two multi-source base-
line models. The first baseline, NBG, is the gener-
ative model with selective parameter sharing from
Naseem et al. (2012).3 This model is trained without
target language data, but we investigate the use of
such data in §5.4. The second baseline, Delex, is a
delexicalized projective version of the well-known
graph-based MSTParser (McDonald et al., 2005).
The feature templates used by this model are shown
to the left in Figure 2. Note that there is no selective
sharing in this model.
The second and third columns of Table 2 show the
unlabeled attachment scores of the baseline models
for each target language. We see that Delex performs
well on target languages that are related to the major-
ity of the source languages. However, for languages
3Model “D-,To” in Table 2 from Naseem et al. (2012).
that diverge from the Indo-European majority family,
the selective sharing model, NBG, achieves substan-
tially higher accuracies.
</bodyText>
<sectionHeader confidence="0.992434" genericHeader="method">
4 Feature-Based Selective Sharing
</sectionHeader>
<bodyText confidence="0.999994833333333">
The results for the baseline models are not surpris-
ing considering the feature templates used by Delex.
There are two fundamental issues with these fea-
tures when used for direct transfer. First, all but
one template include the arc direction. Second,
some features are sensitive to local word order; e.g.,
[d ⊗ 1] ⊗ h.p ⊗ h+1.p ⊗ m_1.p ⊗ m.p, which models
direction as well as word order in the local contexts
of the head and the dependent. Such features do not
transfer well across typologically different languages.
In order to verify that these issues are the cause of
the poor performance of the Delex model, we remove
all directional features and all features that model
local word order from Delex. The feature templates
of the resulting Bare model are shown in the center
of Figure 2. These features only model selectional
preferences and dependency length, analogously to
the selection component of NBG. The performance
of Bare is shown in the fourth column of Table 2.
The removal of most of the features results in a per-
formance drop on average. However, for languages
outside of the Indo-European family, Bare is often
more accurate, especially for Basque, Hungarian and
Japanese, which supports our hypothesis.
</bodyText>
<subsectionHeader confidence="0.999655">
4.1 Sharing Based on Typological Features
</subsectionHeader>
<bodyText confidence="0.996922">
After removing all directional features, we now care-
fully reintroduce them. Inspired by Naseem et al.
</bodyText>
<page confidence="0.944729">
1064
</page>
<table confidence="0.999952842105263">
Lang. NBG Graph-Based Models
Delex Bare Share Similar Family
ar 57.2 43.3 43.1 52.7 52.7 52.7
bg 67.6 64.5 56.1 65.4 62.4 65.4
ca 71.9 72.0 58.1 66.1 80.2 77.6
cs 43.9 40.5 43.1 42.5 45.3 43.5
de 54.0 57.0 49.3 55.2 58.1 59.2
el 61.9 63.2 57.7 62.9 59.9 63.2
es 62.3 66.9 52.6 59.3 69.0 67.1
eu 39.7 29.5 43.3 46.8 46.8 46.8
hu 56.9 56.2 60.5 64.5 64.5 64.5
it 68.0 70.8 55.7 63.5 74.6 72.5
ja 62.3 38.9 50.6 57.1 64.6 65.9
nl 56.2 57.9 51.6 55.0 51.8 56.8
pt 76.2 77.5 63.0 72.7 78.4 78.4
sv 52.0 61.4 55.9 58.8 48.8 63.5
tr 59.1 37.4 36.0 41.7 59.5 59.4
zh 59.9 45.1 47.9 54.8 54.8 54.8
avg 59.3 55.1 51.5 57.4 60.7 62.0
</table>
<tableCaption confidence="0.452545333333333">
Table 2: Unlabeled attachment scores of the multi-source
transfer models. Boldface numbers indicate the best result
per language. Underlined numbers indicate languages
whose group is not represented in the training data (these
default to Share under Similarity and Family). NBG is the
“D-,T,,” model in Table 2 from Naseem et al. (2012).
</tableCaption>
<bodyText confidence="0.999855736842105">
(2012), we make use of the typological features from
WALS (Dryer and Haspelmath, 2011), listed in Ta-
ble 1, to selectively share directional parameters be-
tween languages. As a natural first attempt at sharing
parameters, one might consider forming the cross-
product of all features of Delex with all WALS prop-
erties, similarly to a common domain adaptation tech-
nique (Daumé III, 2007; Finkel and Manning, 2009).
However, this approach has two issues. First, it re-
sults in a huge number of features, making the model
prone to overfitting. Second, and more critically, it
ties together languages via features for which they
are not typologically similar. Consider English and
French, which are both prepositional and thus have
the same value for WALS property 85A. These lan-
guages will end up sharing a parameter for the feature
[d ® 1]®h.p = NOUN®m.p = ADJ®w.85A; yet they
have the exact opposite direction of attachment pref-
erence when it comes to nouns and adjectives. This
problem applies to any method for parameter mixing
that treats all the parameters as equal.
Like Naseem et al. (2012), we instead share pa-
rameters more selectively. Our strategy is to use the
relevant part-of-speech tags of the head and depen-
dent to select which parameters to share, based on
very basic linguistic knowledge. The resulting fea-
tures are shown to the right in Figure 2. For example,
there is a shared directional feature that models the or-
der of Subject, Object and Verb by conjoining WALS
feature 81A with the arc direction and an indicator
feature that fires only if the head is a verb and the de-
pendent is a noun. These features would not be very
useful by themselves, so we combine them with the
Bare features. The accuracy of the resulting Share
model is shown in column five of Table 2. Although
this model still performs worse than NBG, it is an
improvement over the Delex baseline and actually
outperforms the former on 5 out of the 16 languages.
</bodyText>
<subsectionHeader confidence="0.997741">
4.2 Sharing Based on Language Groups
</subsectionHeader>
<bodyText confidence="0.993486533333333">
While Share models selectional preferences and arc
directions for a subset of dependency relations, it
does not capture the rich local word order informa-
tion captured by Delex. We now consider two ways of
selectively including such information based on lan-
guage similarity. While more complex sharing could
be explored (Berg-Kirkpatrick and Klein, 2010), we
use a flat structure and consider two simple groupings
of the source and target languages.
First, the Similar model consists of the features
used by Share together with the features from Delex
in Figure 2. The latter are conjoined with an indicator
feature that fires only when the source and target
languages share values for all the WALS features in
Table 1. This is accomplished by adding the template
</bodyText>
<equation confidence="0.859605">
f ® [w.81A ® w.85A ® w.86A ® w.87A ® w.88A]
</equation>
<bodyText confidence="0.996907545454545">
for each template f in Delex. This groups: 1) Cata-
lan, Italian, Portuguese and Spanish; 2) Bulgarian,
Czech and English; 3) Dutch, German and Greek;
and 4) Japanese and Turkish. The remaining lan-
guages do not share all WALS properties with at
least one source language and thus revert to Share,
since they cannot exploit these grouped features.
Second, instead of grouping languages according
to WALS, the Family model is based on a simple
subdivision into Indo-European languages (Bulgar-
ian, Catalan, Czech, Greek, English, Spanish, Italian,
</bodyText>
<page confidence="0.947418">
1065
</page>
<bodyText confidence="0.999688047619048">
Dutch, Portuguese, Swedish) and Altaic languages
(Japanese, Turkish). This is accomplished with in-
dicator features analogous to those used in Similar.
The remaining languages are again treated as isolates
and revert to Similar.
The results for these models are given in the last
two columns of Table 2. We see that by adding these
rich features back into the fold, but having them fire
only for languages in the same group, we can sig-
nificantly increase the performance — from 57.4%
to 62.0% on average when considering Family. If
we consider our original Delex baseline, we see an
absolute improvement of 6.9% on average and a rela-
tive error reduction of 15%. Particular gains are seen
for non-Indo-European languages; e.g., Japanese in-
creases from 38.9% to 65.9%. Furthermore, Family
achieves a 7% relative error reduction over the NBG
baseline and outperforms it on 12 of the 16 languages.
This shows that a discriminative graph-based parser
can achieve higher accuracies compared to generative
models when the features are carefully constructed.
</bodyText>
<sectionHeader confidence="0.991189" genericHeader="method">
5 Target Language Adaptation
</sectionHeader>
<bodyText confidence="0.999967166666667">
While some higher-level linguistic properties of the
target language have been incorporated through se-
lective sharing, so far no features specific to the target
language have been employed. Cohen et al. (2011)
and Naseem et al. (2012) have shown that using
expectation-maximization (EM) to this end can in
some cases bring substantial accuracy gains. For dis-
criminative models, self-training has been shown to
be quite effective for adapting monolingual parsers to
new domains (McClosky et al., 2006), as well as for
relexicalizing delexicalized parsers using unlabeled
target language data (Zeman and Resnik, 2008). Sim-
ilarly Täckström (2012) used self-training to adapt a
multi-source direct transfer named-entity recognizer
(Täckström et al., 2012) to different target languages,
“relexicalizing” the model with word cluster features.
However, as discussed in §5.2, standard self-training
is not optimal for target language adaptation.
</bodyText>
<subsectionHeader confidence="0.980659">
5.1 Ambiguity-Aware Training
</subsectionHeader>
<bodyText confidence="0.998724021276596">
In this section, we propose a related training method:
ambiguity-aware training. In this setting a discrimi-
native probabilistic model is induced from automat-
ically inferred ambiguous labelings over unlabeled
target language data, in place of gold-standard depen-
dency trees. The ambiguous labelings can combine
multiple sources of evidence to guide the estimation
or simply encode the underlying uncertainty from the
base parser. This uncertainty is marginalized out dur-
ing training. The structure of the output space, e.g.,
projectivity and single-headedness constraints, along
with regularities in the feature space, can together
guide the estimation, similar to what occurs with the
expectation-maximization algorithm.
Core to this method is the idea of an ambiguous
labeling y(x) C Y(x), which encodes a set of pos-
sible dependency trees for an input sentence x. In
subsequent sections we describe how to define such
labelings. Critically, y(x) should be large enough to
capture the correct labeling, but on the other hand
small enough to provide concrete guidance for model
estimation. Ideally, y(x) will capture heterogenous
knowledge that can aid the parser in target language
adaptation. In a first-order arc-factored model, we
define y(x) in terms of a collection of ambiguous
arc sets A(x) = {A(x, m)}|x|
m=1, where A(x, m) de-
notes the set of ambiguously specified heads for the
mth token in x. Then, y(x) is defined as the set of
all projective dependency trees spanning x that can
be assembled from the arcs in A(x).
Methods for learning with ambiguous labelings
have previously been proposed in the context of
multi-class classification (Jin and Ghahramani, 2002),
sequence-labeling (Dredze et al., 2009), log-linear
LFG parsing (Riezler et al., 2002), as well as for
discriminative reranking of generative constituency
parsers (Charniak and Johnson, 2005). In contrast to
Dredze et al., who allow for weights to be assigned
to partial labels, we assume that the ambiguous arcs
are weighted uniformly. For target language adapta-
tion, these weights would typically be derived from
unreliable sources and we do not want to train the
model to simply mimic their beliefs. Furthermore,
with this assumption, learning is simply achieved
by maximizing the marginal log-likelihood of the
ambiguous training set D = {(xi, y(xi)}ni=1,
</bodyText>
<equation confidence="0.912827">
G(θ; D) =
</equation>
<bodyText confidence="0.999051">
In maximizing the marginal log-likelihood, the model
is free to distribute probability mass among the trees
</bodyText>
<equation confidence="0.999">
n log { � pθ(y  |xi) } − λ 11θ1122 .
i=1 yE?/(xi)
</equation>
<page confidence="0.918685">
1066
</page>
<bodyText confidence="0.9999854">
in the ambiguous labeling to its liking, as long as the
marginal log-likelihood improves. The same objec-
tive function is used by Riezler et al. (2002) and Char-
niak and Johnson (2005). A key difference is that in
these works, the ambiguity is constrained through a
supervised signal, while we use ambiguity as a way
to achieve self-training, using the base-parser itself,
or some other potentially noisy knowledge source as
the sole constraints. Note that we have introduced
an E2-regularizer, weighted by A. This is important
as we are now training lexicalized target language
models which can easily overfit. In all experiments,
we optimize parameters with L-BFGS. Note also that
the marginal likelihood is non-concave, so that we
are only guaranteed to find a local maximum.
</bodyText>
<subsectionHeader confidence="0.999264">
5.2 Ambiguity-Aware Self-Training
</subsectionHeader>
<bodyText confidence="0.971902689655172">
In standard self-training — hereafter referred to as
Viterbi self-training — a base parser is used to la-
bel each unlabeled sentence with its most probable
parse tree to create a self-labeled data set, which is
subsequently used to train a supervised parser. There
are two reasons why this simple approach may work.
First, if the base parser’s errors are not too systematic
and if the self-training model is not too expressive,
self-training can reduce the variance on the new do-
main. Second, self-training allows for features in the
new domain with low support — or no support in the
case of lexicalized features — in the base parser to
be “filled in” by exploiting correlations in the feature
representation. However, a potential pitfall of this
approach is that the self-trained parser is encouraged
to blindly mimic the base parser, which leads to error
reinforcement. This may be particularly problematic
when relexicalizing a transfer parser, since the lexical
features provide the parser with increased power and
thereby an increased risk of overfitting to the noise.
To overcome this potential problem, we propose an
ambiguity-aware self-training (AAST) method that is
able to take the noise of the base parser into account.
We use the arc-marginals of the base parser to
construct the ambiguous labeling y(x) for a sentence
x. For each token m E [1,|x|], we first sort the set of
arcs in which m is the dependent, {(h, m)}�x�
h�0, by
the marginal probabilities of the arcs:
</bodyText>
<equation confidence="0.98021">
pθ(h, m  |x) = 1: pθ(y  |x)
IyEY(x) I (h,m)Ey}
</equation>
<bodyText confidence="0.999821666666667">
We next construct the ambiguous arc set A(x, m) by
adding arcs (h, m) in order of decreasing probability,
until their cumulative probability exceeds a, i.e. until
</bodyText>
<equation confidence="0.978067">
pθ(h, m  |x) &gt; a .
(h,m)EA(x,m)
</equation>
<bodyText confidence="0.999951045454545">
Lower values of a result in more aggressive pruning,
with a = 0 corresponding to including no arc and
a = 1 corresponding to including all arcs. We always
add the highest scoring tree y� to y(x) to ensure that
it contains at least one complete projective tree.
Figure 3 outlines an example of how (and why)
AAST works. In the Greek example, the genitive
phrase H napapov� axay6v (the stay of vessels) is
incorrectly analyzed as a flat noun phrase. This is not
surprising given that the base parser simply observes
this phrase as DET NOUN NOUN. However, looking
at the arc marginals we can see that the correct anal-
ysis is available during AAST, although the actual
marginal probabilities are quite misleading. Further-
more, the genitive noun axay6v also appears in other
less ambiguous contexts, where the base parser cor-
rectly predicts it to modify a noun and not a verb.
This allows the training process to add weight to the
corresponding lexical feature pairing axay6v with a
noun head and away from the feature pairing it with
a verb. The resulting parser correctly predicts the
genitive construction.
</bodyText>
<subsectionHeader confidence="0.999515">
5.3 Ambiguity-Aware Ensemble-Training
</subsectionHeader>
<bodyText confidence="0.999972111111111">
While ambiguous labelings can be used as a means
to improve self-training, any information that can
be expressed as hard arc-factored constraints can be
incorporated, including linguistic expert knowledge
and annotation projected via bitext. Here we explore
another natural source of information: the predic-
tions of other transfer parsers. It is well known that
combining several diverse predictions in an ensem-
ble often leads to improved predictions. However, in
most ensemble methods there is typically no learning
involved once the base learners have been trained
(Sagae and Lavie, 2006). An exception is the method
of Sagae and Tsujii (2007), who combine the outputs
of many parsers on unlabeled data to train a parser
for a new domain. However, in that work the learner
is not exposed to the underlying ambiguity of the
base parsers; it is only given the Viterbi parse of the
combination system as the gold standard. In contrast,
</bodyText>
<page confidence="0.978463">
1067
</page>
<table confidence="0.5799405">
Η παραmονή σκαφών επιτρέπεται mόνο τη mέρα
DET NOUN NOUN VERB ADV DET NOUN
Η παραmονή σκαφών επιτρέπεται mόνο τη mέρα
DET NOUN NOUN VERB ADV DET NOUN
Η παραmονή σκαφών επιτρέπεται mόνο τη mέρα
DET NOUN NOUN VERB ADV DET NOUN
</table>
<figureCaption confidence="0.8799335">
Figure 3: An example of ambiguity-aware self-training
(AAST) on a sentence from the Greek self-training data.
</figureCaption>
<bodyText confidence="0.984733">
The sentence roughly translates to The stay of vessels
is permitted only for the day. Top: Arcs from the base
model’s Viterbi parse are shown above the sentence. When
only the part-of-speech tags are observed, the parser tends
to treat everything to the left of the verb as a head-final
noun phrase. The dashed arcs below the sentence are
the arcs for the true genitive construction stay of vessels.
These arcs and the corresponding incorrect arcs in the
Viterbi parse are marked with their marginal probabilities.
Middle: The ambiguous labeling y(x), which is used
as supervision in AAST. Additional non-Viterbi arcs are
present in y(x); for clarity, these are not shown. When
learning with AAST, probability mass will be pushed to-
wards any tree consistent with y(x). Marginal probabili-
ties are ignored at this stage, so that all arcs in y(x) are
treated as equals. Bottom: The Viterbi parse of the AAST
model, which has selected the correct arcs from y(x).
we propose an ambiguity-aware ensemble-training
(AAET) method that treats the union of the ensemble
predictions for a sentence x as an ambiguous labeling
y(x). An additional advantage of this approach is
that the ensemble is compiled into a single model
and therefore does not require multiple models to be
stored and used at runtime.
It is straightforward to construct y(x) from multi-
ple parsers. Let Ak(x, m) be the set of arcs for the
mth token in x according to the kth parser in the en-
semble. When arc-marginals are used to construct the
ambiguity set, |Ak(x, m) |&gt; 1, but when the Viterbi-
parse is used, Ak(x, m) is a singleton. We next form
A(x, m) = Uk Ak(x, m) as the ensemble arc ambi-
guity set from which y(x) is assembled. In this study,
we combine the arc sets of two base parsers: first, the
arc-marginal ambiguity set of the base parser (§5.2);
and second, the Viterbi arc set from the NBG parser
of Naseem et al. (2012) in Table 2.4 Thus, the lat-
ter will have singleton arc ambiguity sets, but when
combined with the arc-marginal ambiguity sets of
our base parser, the result will encode uncertainty
derived from both parsers.
</bodyText>
<subsectionHeader confidence="0.998858">
5.4 Adaptation Experiments
</subsectionHeader>
<bodyText confidence="0.999665911764706">
We now study the different approaches to target lan-
guage adaptation empirically. As in Naseem et al.
(2012), we use the CoNLL training sets, stripped of
all dependency information, as the unlabeled target
language data in our experiments. We use the Family
model as the base parser, which is used to label the
unlabeled target data with the Viterbi parses as well
as with the ambiguous labelings. The final model
is then trained on this data using standard lexical-
ized features (McDonald et al., 2005). Since labeled
training data is unavailable in the target language,
we cannot tune any hyper-parameters and simply set
A =1 and a = 0.95 throughout. Although the latter
may suggest that y(x) contains a high degree of am-
biguity, in reality, the marginal distributions of the
base model have low entropy and after filtering with
a = 0.95, the average number of potential heads per
dependent ranges from 1.4 to 3.2, depending on the
target language.
The ambiguity-aware training methods, that is
ambiguity-aware self-training (AAST) and ambiguity-
aware ensemble-training (AAET), are compared to
three baseline systems. First, NBG+EM is the gen-
erative model of Naseem et al. (2012) trained with
expectation-maximization on additional unlabeled
target language text. Second, Family is the best dis-
criminative model from the previous section. Third,
Viterbi is the basic Viterbi self-training model. The
results of each of these models are shown in Table 3.
There are a number of things that can be observed.
First, Viterbi self-training helps slightly on average,
but the gains are not consistent and there are even
drops in accuracy for some languages. Second, AAST
outperforms the Viterbi variant on all languages and
</bodyText>
<footnote confidence="0.637607">
4We do not have access to the marginals of NBG.
</footnote>
<figure confidence="0.993754">
0.55
0.62
0.87
0.44
0.10
0.36
</figure>
<page confidence="0.915089">
1068
</page>
<table confidence="0.999728947368421">
Lang. NBG+EM Family Target Adaptation
Viterbi AAST AAET
ar 59.3 52.7 52.6 53.5 58.7
bg 67.0 65.4 66.4 67.9 73.0
ca 71.7 77.6 78.0 79.9 76.1
cs 44.3 43.5 43.6 44.4 48.3
de 54.1 59.2 59.7 62.5 61.5
el 67.9 63.2 64.5 65.5 69.6
es 62.0 67.1 68.2 68.5 66.9
eu 47.8 46.8 47.5 48.6 49.4
hu 58.6 64.5 64.6 65.6 67.5
it 65.6 72.5 71.6 72.4 73.4
ja 64.1 65.9 65.7 68.8 72.0
nl 56.6 56.8 57.9 58.1 60.2
pt 75.8 78.4 79.9 80.7 79.9
sv 61.7 63.5 63.4 65.5 65.5
tr 59.4 59.4 59.5 64.1 64.2
zh 51.0 54.8 54.8 57.9 60.7
avg 60.4 62.0 62.4 64.0 65.4
</table>
<tableCaption confidence="0.996248">
Table 3: Target language adaptation using unlabeled tar-
</tableCaption>
<bodyText confidence="0.987821813953489">
get data. AAST: ambiguity-aware self-training. AAET:
ambiguity-aware ensemble-training. Boldface numbers
indicate the best result per language. Underlined numbers
indicate the best result, excluding AAET. NBG+EM is the
“D+,T,,” model from Naseem et al. (2012).
nearly always improves on the base parser, although
it sees a slight drop for Italian. AAST improves the
accuracy over the base model by 2% absolute on av-
erage and by as much as 5% absolute for Turkish.
Comparing this model to the NBG+EM baseline, we
observe an improvement by 3.6% absolute, outper-
forming it on 14 of the 16 languages. Furthermore,
ambiguity-aware self-training appears to help more
than expectation-maximization for generative (unlex-
icalized) models. Naseem et al. observed an increase
from 59.3% to 60.4% on average by adding unlabeled
target language data and the gains were not consistent
across languages. AAST, on the other hand, achieves
consistent gains, rising from 62.0% to 64.0% on av-
erage. Third, as shown in the rightmost column of
Table 3, ambiguity-aware ensemble-training is indeed
a successful strategy; AAET outperforms the previ-
ous best self-trained model on 13 and NB&amp;G+EM
on 15 out of 16 languages. The relative error reduc-
tion with respect to the base Family model is 9% on
average, while the average reduction with respect to
NBG+EM is 13%.
Before concluding, two additional points are worth
making. First, further gains may potentially be
achievable with feature-rich discriminative models.
While the best generative transfer model of Naseem
et al. (2012) approaches its upper-bounding super-
vised accuracy (60.4% vs. 67.1%), our relaxed self-
training model is still far below its supervised coun-
terpart (64.0% vs. 84.1%). One promising statistic
along these lines is that the oracle accuracy for the
ambiguous labelings of AAST is 75.7%, averaged
across languages, which suggests that other training
algorithms, priors or constraints could improve the
accuracy substantially. Second, relexicalization is a
key component of self-training. If we use delexical-
ized features during self-training, we only observe a
small average improvement from 62.0% to 62.1%.
</bodyText>
<sectionHeader confidence="0.999654" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.998563">
We contributed to the understanding of multi-source
syntactic transfer in several complementary ways.
First, we showed how selective parameter sharing,
based on typological features and language family
membership, can be incorporated in a discriminative
graph-based model of dependency parsing. We then
showed how ambiguous labelings can be used to in-
tegrate heterogenous knowledge sources in parser
training. Two instantiations of this framework were
explored. First, an ambiguity-aware self-training
method that can be used to effectively relexicalize
and adapt a delexicalized transfer parser using unla-
beled target language data. Second, an ambiguity-
aware ensemble-training method, in which predic-
tions from different parsers can be incorporated and
further adapted. On average, our best model provides
a relative error reduction of 13% over the state-of-
the-art model of Naseem et al. (2012), outperforming
it on 15 out of 16 evaluated languages.
Acknowledgments We thank Alexander Rush for
help with the hypergraph framework used for inference.
Tahira Naseem kindly provided us with her data sets and
the predictions of her systems. This work benefited from
many discussions with Yoav Goldberg and members of the
Google parsing team. We finally thank the three anony-
mous reviewers for their valuable feedback. The work of
the first author was partly funded by the Swedish National
Graduate School of Language Technology (GSLT).
</bodyText>
<page confidence="0.992238">
1069
</page>
<sectionHeader confidence="0.99833" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999933192307693">
Taylor Berg-Kirkpatrick and Dan Klein. 2010. Phyloge-
netic grammar induction. In Proceedings of ACL.
Eugene Charniak and Mark Johnson. 2005. Coarse-to-
fine n-best parsing and maxent discriminative reranking.
In Proceedings of ACL.
Shay B. Cohen and Noah A. Smith. 2009. Shared lo-
gistic normal distributions for soft parameter tying in
unsupervised grammar induction. In Proceedings of
NAACL.
Shay B. Cohen, Dipanjan Das, and Noah A. Smith. 2011.
Unsupervised structure prediction with non-parallel
multilingual guidance. In Proceedings of EMNLP.
Dipanjan Das and Slav Petrov. 2011. Unsupervised part-
of-speech tagging with bilingual graph-based projec-
tions. In Proceedings of ACL-HLT.
Hal Daumé III. 2007. Frustratingly easy domain adapta-
tion. In Proceedings of ACL.
Mark Dredze, Partha Pratim Talukdar, and Koby Cram-
mer. 2009. Sequence learning from data with multiple
labels. In Proceedings of the ECML/PKDD Workshop
on Learning from Multi-Label Data.
Matthew S. Dryer and Martin Haspelmath, editors. 2011.
The World Atlas of Language Structures Online. Mu-
nich: Max Planck Digital Library. http://wals.info/.
Greg Durrett, Adam Pauls, and Dan Klein. 2012. Syntac-
tic transfer using a bilingual lexicon. In Proceedings of
EMNLP-CoNLL.
Jason Eisner. 1996. Three new probabilistic models for
dependency parsing: an exploration. In Proceedings of
COLING.
Jenny Rose Finkel and Christopher D. Manning. 2009.
Hierarchical Bayesian domain adaptation. In Proceed-
ings of HLT-NAACL.
Kuzman Ganchev, Jennifer Gillenwater, and Ben Taskar.
2009. Dependency grammar induction via bitext pro-
jection constraints. In Proceedings of ACL-IJCNLP.
Rebecca Hwa, Philip Resnik, Amy Weinberg, Clara
Cabezas, and Okan Kolak. 2005. Bootstrapping
parsers via syntactic projection across parallel texts.
Natural Language Engineering, 11(03):311–325.
Rong Jin and Zoubin Ghahramani. 2002. Learning with
multiple labels. In Proceedings of NIPS.
Dan Klein and Chris D. Manning. 2004. Corpus-based
induction of syntactic structure: models of dependency
and constituency. In Proceedings of ACL.
Alexandre Klementiev, Ivan Titov, and Binod Bhattarai.
2012. Inducing crosslingual distributed representations
of words. In Proceedings of COLING.
Dong C. Liu and Jorge Nocedal. 1989. On the limited
memory BFGS method for large scale optimization.
Mathematical Programming, 45.
David McClosky, Eugene Charniak, and Mark Johnson.
2006. Reranking and self-training for parser adaptation.
In Proceedings of ACL.
Ryan McDonald, Koby Crammer, and Fernando Pereira.
2005. Online large-margin training of dependency
parsers. In Proceedings of ACL.
Ryan McDonald, Slav Petrov, and Keith Hall. 2011.
Multi-source transfer of delexicalized dependency
parsers. In Proceedings of EMNLP.
Tahira Naseem, Harr Chen, Regina Barzilay, and Mark
Johnson. 2010. Using universal linguistic knowl-
edge to guide grammar induction. In Proceedings of
EMNLP.
Tahira Naseem, Regina Barzilay, and Amir Globerson.
2012. Selective sharing for multilingual dependency
parsing. In Proceedings of ACL.
Joakim Nivre. 2008. Algorithms for deterministic incre-
mental dependency parsing. Computational Linguis-
tics, 34(4):513–553.
Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012.
A universal part-of-speech tagset. In Proceedings of
LREC.
Stefan Riezler, Tracy H. King, Ronald M. Kaplan, Richard
Crouch, John T. Maxwell, III, and Mark Johnson.
2002. Parsing the Wall Street Journal using a lexical-
functional grammar and discriminative estimation tech-
niques. In Proceedings of ACL.
Kenji Sagae and Alon Lavie. 2006. Parser combination
by reparsing. In Proceedings of NAACL.
Kenji Sagae and Jun’ichi Tsujii. 2007. Dependency pars-
ing and domain adaptation with LR models and parser
ensembles. In Proceedings of EMNLP-CoNLL.
Benjamin Snyder, Tahira Naseem, Jacob Eisenstein, and
Regina Barzilay. 2009. Adding more languages im-
proves unsupervised multilingual part-of-speech tag-
ging: A Bayesian non-parametric approach. In Pro-
ceedings of NAACL.
Anders Søgaard and Julie Wulff. 2012. An empirical
study of non-lexical extensions to delexicalized transfer.
In Proceedings of COLING.
Anders Søgaard. 2011. Data point selection for cross-
language adaptation of dependency parsers. In Pro-
ceedings of ACL.
Kathrin Spreyer and Jonas Kuhn. 2009. Data-driven
dependency parsing of new languages using incomplete
and noisy training data. In Proceedings of CONLL.
Oscar Täckström, Ryan McDonald, and Jakob Uszkoreit.
2012. Cross-lingual word clusters for direct transfer of
linguistic structure. In Proceedings of NAACL-HLT.
Oscar Täckström. 2012. Nudging the envelope of direct
transfer methods for multilingual named entity recog-
nition. In Proceedings of the NAACL-HLT 2012 Work-
shop on Inducing Linguistic Structure (WILS 2012).
</reference>
<page confidence="0.8141">
1070
</page>
<reference confidence="0.992006428571428">
David Yarowsky, Grace Ngai, and Richard Wicentowski.
2001. Inducing multilingual text analysis tools via ro-
bust projection across aligned corpora. In Proceedings
of HLT.
Daniel Zeman and Philip Resnik. 2008. Cross-language
parser adaptation between related languages. In IJC-
NLP Workshop: NLP for Less Privileged Languages.
</reference>
<page confidence="0.995127">
1071
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.472633">
<title confidence="0.999713">Target Language Adaptation of Discriminative Transfer Parsers</title>
<author confidence="0.99164">McDonald Joakim</author>
<affiliation confidence="0.992243">SICS I Uppsala University Google Uppsala University</affiliation>
<author confidence="0.549858">Sweden New York Sweden</author>
<email confidence="0.897842">oscar@sics.seryanmcd@google.comjoakim.nivre@lingfil.uu.se</email>
<abstract confidence="0.998431409090909">We study multi-source transfer parsing for resource-poor target languages; specifically methods for target language adaptation of delexicalized discriminative graph-based dependency parsers. We first show how recent insights on selective parameter sharing, based on typological and language-family features, can be applied to a discriminative parser by carefully decomposing its model features. We then show how the parser can be relexicalized and adapted using unlabeled target language data and a learning method that can incorporate diverse knowledge sources through ambiguous labelings. In the latter scenario, we exploit two sources of knowledge: arc marginals derived from the base parser in a self-training algorithm, and arc predictions from multiple transfer parsers in an ensemble-training algorithm. Our final model outperforms the state of the art in multi-source transfer parsing on 15 out of 16 evaluated languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Taylor Berg-Kirkpatrick</author>
<author>Dan Klein</author>
</authors>
<title>Phylogenetic grammar induction.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="2065" citStr="Berg-Kirkpatrick and Klein, 2010" startWordPosition="294" endWordPosition="297">ining data. Recently, methods for cross-lingual transfer have appeared as a promising avenue for overcoming this hurdle for both part-of-speech tagging (Yarowsky et al., 2001; Das and Petrov, 2011) and syntactic dependency parsing (Hwa et al., 2005; Zeman and Resnik, 2008; Ganchev et al., 2009; McDonald et al., 2011; Naseem et al., * Work primarily carried out while at Google, NY. 2012). While these methods do not yet compete with fully supervised approaches, they can drastically outperform both unsupervised methods (Klein and Manning, 2004) and weakly supervised methods (Naseem et al., 2010; Berg-Kirkpatrick and Klein, 2010). A promising approach to cross-lingual transfer of syntactic dependency parsers is to use multiple source languages and to tie model parameters across related languages. This idea was first explored for weakly supervised learning (Cohen and Smith, 2009; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010) and recently by Naseem et al. (2012) for multisource cross-lingual transfer. In particular, Naseem et al. showed that by selectively sharing parameters based on typological features of each language, substantial improvements can be achieved, compared to using a single set of parameters for</context>
<context position="6607" citStr="Berg-Kirkpatrick and Klein, 2010" startWordPosition="975" endWordPosition="978">en shown to benefit unsupervised learning (Cohen and Smith, 1Note that Täckström et al. (2012) and Durrett et al. (2012) do require bitext or a bilingual dictionary. The same holds for most cross-lingual representations, e.g., Klementiev et al. (2012). PUNC DOBJ PREP POBJ O TC6v 68W6E a-c&apos;v Map(a -co RLRX(o . (The) (John) (gave) (to-the) (Maria) (the) (book) . DET NOUN VERB ADP NOUN DET NOUN P Figure 1: A Greek sentence which is correctly parsed by a delexicalized English parser, provided that part-of-speech tags are available in both the source and target language. 2009; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010). Annotations in multiple languages can be combined in delexicalized transfer as well, as long as the parser features are available across the involved languages. This idea was explored by McDonald et al. (2011), who showed that target language accuracy can be improved by simply concatenating delexicalized treebanks in multiple languages. In similar work, Cohen et al. (2011) proposed a mixture model in which the parameters of a generative target language parser is expressed as a linear interpolation of source language parameters, whereas Søgaard (2011) showed that target side language models c</context>
<context position="19961" citStr="Berg-Kirkpatrick and Klein, 2010" startWordPosition="3250" endWordPosition="3253">s. The accuracy of the resulting Share model is shown in column five of Table 2. Although this model still performs worse than NBG, it is an improvement over the Delex baseline and actually outperforms the former on 5 out of the 16 languages. 4.2 Sharing Based on Language Groups While Share models selectional preferences and arc directions for a subset of dependency relations, it does not capture the rich local word order information captured by Delex. We now consider two ways of selectively including such information based on language similarity. While more complex sharing could be explored (Berg-Kirkpatrick and Klein, 2010), we use a flat structure and consider two simple groupings of the source and target languages. First, the Similar model consists of the features used by Share together with the features from Delex in Figure 2. The latter are conjoined with an indicator feature that fires only when the source and target languages share values for all the WALS features in Table 1. This is accomplished by adding the template f ® [w.81A ® w.85A ® w.86A ® w.87A ® w.88A] for each template f in Delex. This groups: 1) Catalan, Italian, Portuguese and Spanish; 2) Bulgarian, Czech and English; 3) Dutch, German and Gree</context>
</contexts>
<marker>Berg-Kirkpatrick, Klein, 2010</marker>
<rawString>Taylor Berg-Kirkpatrick and Dan Klein. 2010. Phylogenetic grammar induction. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Coarse-tofine n-best parsing and maxent discriminative reranking.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="24877" citStr="Charniak and Johnson, 2005" startWordPosition="4017" endWordPosition="4020"> y(x) in terms of a collection of ambiguous arc sets A(x) = {A(x, m)}|x| m=1, where A(x, m) denotes the set of ambiguously specified heads for the mth token in x. Then, y(x) is defined as the set of all projective dependency trees spanning x that can be assembled from the arcs in A(x). Methods for learning with ambiguous labelings have previously been proposed in the context of multi-class classification (Jin and Ghahramani, 2002), sequence-labeling (Dredze et al., 2009), log-linear LFG parsing (Riezler et al., 2002), as well as for discriminative reranking of generative constituency parsers (Charniak and Johnson, 2005). In contrast to Dredze et al., who allow for weights to be assigned to partial labels, we assume that the ambiguous arcs are weighted uniformly. For target language adaptation, these weights would typically be derived from unreliable sources and we do not want to train the model to simply mimic their beliefs. Furthermore, with this assumption, learning is simply achieved by maximizing the marginal log-likelihood of the ambiguous training set D = {(xi, y(xi)}ni=1, G(θ; D) = In maximizing the marginal log-likelihood, the model is free to distribute probability mass among the trees n log { � pθ(</context>
</contexts>
<marker>Charniak, Johnson, 2005</marker>
<rawString>Eugene Charniak and Mark Johnson. 2005. Coarse-tofine n-best parsing and maxent discriminative reranking. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shay B Cohen</author>
<author>Noah A Smith</author>
</authors>
<title>Shared logistic normal distributions for soft parameter tying in unsupervised grammar induction.</title>
<date>2009</date>
<booktitle>In Proceedings of NAACL.</booktitle>
<contexts>
<context position="2318" citStr="Cohen and Smith, 2009" startWordPosition="331" endWordPosition="334">k, 2008; Ganchev et al., 2009; McDonald et al., 2011; Naseem et al., * Work primarily carried out while at Google, NY. 2012). While these methods do not yet compete with fully supervised approaches, they can drastically outperform both unsupervised methods (Klein and Manning, 2004) and weakly supervised methods (Naseem et al., 2010; Berg-Kirkpatrick and Klein, 2010). A promising approach to cross-lingual transfer of syntactic dependency parsers is to use multiple source languages and to tie model parameters across related languages. This idea was first explored for weakly supervised learning (Cohen and Smith, 2009; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010) and recently by Naseem et al. (2012) for multisource cross-lingual transfer. In particular, Naseem et al. showed that by selectively sharing parameters based on typological features of each language, substantial improvements can be achieved, compared to using a single set of parameters for all languages. However, these methods all employ generative models with strong independence assumptions and weak feature representations, which upper bounds their accuracy far below that of feature-rich discriminative parsers (McDonald et al., 2005; Ni</context>
</contexts>
<marker>Cohen, Smith, 2009</marker>
<rawString>Shay B. Cohen and Noah A. Smith. 2009. Shared logistic normal distributions for soft parameter tying in unsupervised grammar induction. In Proceedings of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shay B Cohen</author>
<author>Dipanjan Das</author>
<author>Noah A Smith</author>
</authors>
<title>Unsupervised structure prediction with non-parallel multilingual guidance.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="4858" citStr="Cohen et al., 2011" startWordPosition="702" endWordPosition="705">; these arc sets are then combined with the predictions of a different transfer parser in an ambiguity-aware ensemble-training algorithm (§5.3). The resulting parser provides significant improvements over a strong baseline parser and achieves a 13% relative error reduction on average with respect to the best model of Naseem et al. (2012), outperforming it on 15 out of the 16 evaluated languages. 2 Multi-Source Delexicalized Transfer The methods proposed in this paper fall into the delexicalized transfer approach to multilingual syntactic parsing (Zeman and Resnik, 2008; McDonald et al., 2011; Cohen et al., 2011; Søgaard, 2011). In contrast to annotation projection approaches (Yarowsky et al., 2001; Hwa et al., 2005; Ganchev et al., 2009; Spreyer and Kuhn, 2009), delexicalized transfer methods do not rely on any bitext. Instead, a parser is trained on annotations in a source language, relying solely on features that are available in both the source and the target language, such as “universal” part-ofspeech tags (Zeman and Resnik, 2008; Naseem et al., 2010; Petrov et al., 2012), cross-lingual word clusters (Täckström et al., 2012) or type-level features derived from bilingual dictionaries (Durrett et </context>
<context position="6984" citStr="Cohen et al. (2011)" startWordPosition="1034" endWordPosition="1037">OUN P Figure 1: A Greek sentence which is correctly parsed by a delexicalized English parser, provided that part-of-speech tags are available in both the source and target language. 2009; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010). Annotations in multiple languages can be combined in delexicalized transfer as well, as long as the parser features are available across the involved languages. This idea was explored by McDonald et al. (2011), who showed that target language accuracy can be improved by simply concatenating delexicalized treebanks in multiple languages. In similar work, Cohen et al. (2011) proposed a mixture model in which the parameters of a generative target language parser is expressed as a linear interpolation of source language parameters, whereas Søgaard (2011) showed that target side language models can be used to selectively subsample training sentences to improve accuracy. Recently, inspired by the phylogenetic prior of Berg-Kirkpatrick and Klein (2010), Søgaard and Wulff (2012) proposed — among other ideas — a typologically informed weighting heuristic for linearly interpolating source language parameters. However, this weighting did not provide significant improvemen</context>
<context position="22251" citStr="Cohen et al. (2011)" startWordPosition="3623" endWordPosition="3626">ar gains are seen for non-Indo-European languages; e.g., Japanese increases from 38.9% to 65.9%. Furthermore, Family achieves a 7% relative error reduction over the NBG baseline and outperforms it on 12 of the 16 languages. This shows that a discriminative graph-based parser can achieve higher accuracies compared to generative models when the features are carefully constructed. 5 Target Language Adaptation While some higher-level linguistic properties of the target language have been incorporated through selective sharing, so far no features specific to the target language have been employed. Cohen et al. (2011) and Naseem et al. (2012) have shown that using expectation-maximization (EM) to this end can in some cases bring substantial accuracy gains. For discriminative models, self-training has been shown to be quite effective for adapting monolingual parsers to new domains (McClosky et al., 2006), as well as for relexicalizing delexicalized parsers using unlabeled target language data (Zeman and Resnik, 2008). Similarly Täckström (2012) used self-training to adapt a multi-source direct transfer named-entity recognizer (Täckström et al., 2012) to different target languages, “relexicalizing” the model</context>
</contexts>
<marker>Cohen, Das, Smith, 2011</marker>
<rawString>Shay B. Cohen, Dipanjan Das, and Noah A. Smith. 2011. Unsupervised structure prediction with non-parallel multilingual guidance. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dipanjan Das</author>
<author>Slav Petrov</author>
</authors>
<title>Unsupervised partof-speech tagging with bilingual graph-based projections.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL-HLT.</booktitle>
<contexts>
<context position="1629" citStr="Das and Petrov, 2011" startWordPosition="225" endWordPosition="228">e transfer parsers in an ensemble-training algorithm. Our final model outperforms the state of the art in multi-source transfer parsing on 15 out of 16 evaluated languages. 1 Introduction Many languages still lack access to core NLP tools, such as part-of-speech taggers and syntactic parsers. This is largely due to the reliance on fully supervised learning methods, which require large quantities of manually annotated training data. Recently, methods for cross-lingual transfer have appeared as a promising avenue for overcoming this hurdle for both part-of-speech tagging (Yarowsky et al., 2001; Das and Petrov, 2011) and syntactic dependency parsing (Hwa et al., 2005; Zeman and Resnik, 2008; Ganchev et al., 2009; McDonald et al., 2011; Naseem et al., * Work primarily carried out while at Google, NY. 2012). While these methods do not yet compete with fully supervised approaches, they can drastically outperform both unsupervised methods (Klein and Manning, 2004) and weakly supervised methods (Naseem et al., 2010; Berg-Kirkpatrick and Klein, 2010). A promising approach to cross-lingual transfer of syntactic dependency parsers is to use multiple source languages and to tie model parameters across related lang</context>
</contexts>
<marker>Das, Petrov, 2011</marker>
<rawString>Dipanjan Das and Slav Petrov. 2011. Unsupervised partof-speech tagging with bilingual graph-based projections. In Proceedings of ACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daumé</author>
</authors>
<title>Frustratingly easy domain adaptation.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL.</booktitle>
<marker>Daumé, 2007</marker>
<rawString>Hal Daumé III. 2007. Frustratingly easy domain adaptation. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Dredze</author>
</authors>
<title>Partha Pratim Talukdar, and Koby Crammer.</title>
<date>2009</date>
<booktitle>In Proceedings of the ECML/PKDD Workshop on Learning from Multi-Label Data.</booktitle>
<marker>Dredze, 2009</marker>
<rawString>Mark Dredze, Partha Pratim Talukdar, and Koby Crammer. 2009. Sequence learning from data with multiple labels. In Proceedings of the ECML/PKDD Workshop on Learning from Multi-Label Data.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew S Dryer</author>
<author>Martin Haspelmath</author>
<author>editors</author>
</authors>
<date>2011</date>
<booktitle>The World Atlas of Language Structures Online. Munich: Max Planck Digital Library. http://wals.info/.</booktitle>
<marker>Dryer, Haspelmath, editors, 2011</marker>
<rawString>Matthew S. Dryer and Martin Haspelmath, editors. 2011. The World Atlas of Language Structures Online. Munich: Max Planck Digital Library. http://wals.info/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Greg Durrett</author>
<author>Adam Pauls</author>
<author>Dan Klein</author>
</authors>
<title>Syntactic transfer using a bilingual lexicon.</title>
<date>2012</date>
<booktitle>In Proceedings of EMNLP-CoNLL.</booktitle>
<contexts>
<context position="5468" citStr="Durrett et al., 2012" startWordPosition="797" endWordPosition="800">t al., 2011; Søgaard, 2011). In contrast to annotation projection approaches (Yarowsky et al., 2001; Hwa et al., 2005; Ganchev et al., 2009; Spreyer and Kuhn, 2009), delexicalized transfer methods do not rely on any bitext. Instead, a parser is trained on annotations in a source language, relying solely on features that are available in both the source and the target language, such as “universal” part-ofspeech tags (Zeman and Resnik, 2008; Naseem et al., 2010; Petrov et al., 2012), cross-lingual word clusters (Täckström et al., 2012) or type-level features derived from bilingual dictionaries (Durrett et al., 2012).1 This parser is then directly used to parse the target language. For languages with similar typology, this method can be quite accurate, especially when compared to purely unsupervised methods. For instance, a parser trained on English with only part-of-speech features can correctly parse the Greek sentence in Figure 1, even without knowledge of the lexical items since the sequence of part-of-speech tags determines the syntactic structure almost unambiguously. Learning with multiple languages has been shown to benefit unsupervised learning (Cohen and Smith, 1Note that Täckström et al. (2012)</context>
</contexts>
<marker>Durrett, Pauls, Klein, 2012</marker>
<rawString>Greg Durrett, Adam Pauls, and Dan Klein. 2012. Syntactic transfer using a bilingual lexicon. In Proceedings of EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Eisner</author>
</authors>
<title>Three new probabilistic models for dependency parsing: an exploration.</title>
<date>1996</date>
<booktitle>In Proceedings of COLING.</booktitle>
<contexts>
<context position="11998" citStr="Eisner, 1996" startWordPosition="1834" endWordPosition="1835">Without loss of generality, we restrict ourselves to first-order models, where the feature function b(x, y) factors over individual arcs (h, m) in y, such that b(x, y) = � φ(x, h, m) , (h,m)Ey where h E [0, x ] and m E [1, x ] are the indices of the head word and the dependent word of the arc; h = 0 represents a dummy ROOT token. The model parameters are estimated by maximizing the log-likelihood of the training data D = {(xi, yi)}ni=1, n L(θ; D) = log pθ(yi xi) . i=1 We use the standard gradient-based L-BFGS algorithm (Liu and Nocedal, 1989) to maximize the loglikelihood. Eisner’s algorithm (Eisner, 1996) is used for inference of the Viterbi parse and arc-marginals. 3.2 Data Sets and Experimental Setup To facilitate comparison with the state of the art, we use the same treebanks and experimental setup as Naseem et al. (2012). Notably, we use the mapping proposed by Naseem et al. (2010) to map from fine-grained treebank specific part-of-speech tags to coarse-grained “universal” tags, rather than the more recent mapping proposed by Petrov et al. (2012). For 1063 Delexicalized MSTParser Bare Selectively shared d ⊗ l; [d ⊗ l] ⊗ h.p; [d ⊗ l] ⊗ m.p [d ⊗ l] ⊗ h.p ⊗ m.p [d ⊗ l] ⊗ h.p ⊗ h+1.p ⊗ m−1.p ⊗</context>
</contexts>
<marker>Eisner, 1996</marker>
<rawString>Jason Eisner. 1996. Three new probabilistic models for dependency parsing: an exploration. In Proceedings of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Christopher D Manning</author>
</authors>
<title>Hierarchical Bayesian domain adaptation.</title>
<date>2009</date>
<booktitle>In Proceedings of HLT-NAACL.</booktitle>
<contexts>
<context position="18036" citStr="Finkel and Manning, 2009" startWordPosition="2922" endWordPosition="2925">anguage. Underlined numbers indicate languages whose group is not represented in the training data (these default to Share under Similarity and Family). NBG is the “D-,T,,” model in Table 2 from Naseem et al. (2012). (2012), we make use of the typological features from WALS (Dryer and Haspelmath, 2011), listed in Table 1, to selectively share directional parameters between languages. As a natural first attempt at sharing parameters, one might consider forming the crossproduct of all features of Delex with all WALS properties, similarly to a common domain adaptation technique (Daumé III, 2007; Finkel and Manning, 2009). However, this approach has two issues. First, it results in a huge number of features, making the model prone to overfitting. Second, and more critically, it ties together languages via features for which they are not typologically similar. Consider English and French, which are both prepositional and thus have the same value for WALS property 85A. These languages will end up sharing a parameter for the feature [d ® 1]®h.p = NOUN®m.p = ADJ®w.85A; yet they have the exact opposite direction of attachment preference when it comes to nouns and adjectives. This problem applies to any method for p</context>
</contexts>
<marker>Finkel, Manning, 2009</marker>
<rawString>Jenny Rose Finkel and Christopher D. Manning. 2009. Hierarchical Bayesian domain adaptation. In Proceedings of HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuzman Ganchev</author>
<author>Jennifer Gillenwater</author>
<author>Ben Taskar</author>
</authors>
<title>Dependency grammar induction via bitext projection constraints.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL-IJCNLP.</booktitle>
<contexts>
<context position="1726" citStr="Ganchev et al., 2009" startWordPosition="241" endWordPosition="244"> art in multi-source transfer parsing on 15 out of 16 evaluated languages. 1 Introduction Many languages still lack access to core NLP tools, such as part-of-speech taggers and syntactic parsers. This is largely due to the reliance on fully supervised learning methods, which require large quantities of manually annotated training data. Recently, methods for cross-lingual transfer have appeared as a promising avenue for overcoming this hurdle for both part-of-speech tagging (Yarowsky et al., 2001; Das and Petrov, 2011) and syntactic dependency parsing (Hwa et al., 2005; Zeman and Resnik, 2008; Ganchev et al., 2009; McDonald et al., 2011; Naseem et al., * Work primarily carried out while at Google, NY. 2012). While these methods do not yet compete with fully supervised approaches, they can drastically outperform both unsupervised methods (Klein and Manning, 2004) and weakly supervised methods (Naseem et al., 2010; Berg-Kirkpatrick and Klein, 2010). A promising approach to cross-lingual transfer of syntactic dependency parsers is to use multiple source languages and to tie model parameters across related languages. This idea was first explored for weakly supervised learning (Cohen and Smith, 2009; Snyder</context>
<context position="4986" citStr="Ganchev et al., 2009" startWordPosition="722" endWordPosition="725"> algorithm (§5.3). The resulting parser provides significant improvements over a strong baseline parser and achieves a 13% relative error reduction on average with respect to the best model of Naseem et al. (2012), outperforming it on 15 out of the 16 evaluated languages. 2 Multi-Source Delexicalized Transfer The methods proposed in this paper fall into the delexicalized transfer approach to multilingual syntactic parsing (Zeman and Resnik, 2008; McDonald et al., 2011; Cohen et al., 2011; Søgaard, 2011). In contrast to annotation projection approaches (Yarowsky et al., 2001; Hwa et al., 2005; Ganchev et al., 2009; Spreyer and Kuhn, 2009), delexicalized transfer methods do not rely on any bitext. Instead, a parser is trained on annotations in a source language, relying solely on features that are available in both the source and the target language, such as “universal” part-ofspeech tags (Zeman and Resnik, 2008; Naseem et al., 2010; Petrov et al., 2012), cross-lingual word clusters (Täckström et al., 2012) or type-level features derived from bilingual dictionaries (Durrett et al., 2012).1 This parser is then directly used to parse the target language. For languages with similar typology, this method ca</context>
</contexts>
<marker>Ganchev, Gillenwater, Taskar, 2009</marker>
<rawString>Kuzman Ganchev, Jennifer Gillenwater, and Ben Taskar. 2009. Dependency grammar induction via bitext projection constraints. In Proceedings of ACL-IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Hwa</author>
<author>Philip Resnik</author>
<author>Amy Weinberg</author>
<author>Clara Cabezas</author>
<author>Okan Kolak</author>
</authors>
<title>Bootstrapping parsers via syntactic projection across parallel texts.</title>
<date>2005</date>
<journal>Natural Language Engineering,</journal>
<volume>11</volume>
<issue>03</issue>
<contexts>
<context position="1680" citStr="Hwa et al., 2005" startWordPosition="233" endWordPosition="236">r final model outperforms the state of the art in multi-source transfer parsing on 15 out of 16 evaluated languages. 1 Introduction Many languages still lack access to core NLP tools, such as part-of-speech taggers and syntactic parsers. This is largely due to the reliance on fully supervised learning methods, which require large quantities of manually annotated training data. Recently, methods for cross-lingual transfer have appeared as a promising avenue for overcoming this hurdle for both part-of-speech tagging (Yarowsky et al., 2001; Das and Petrov, 2011) and syntactic dependency parsing (Hwa et al., 2005; Zeman and Resnik, 2008; Ganchev et al., 2009; McDonald et al., 2011; Naseem et al., * Work primarily carried out while at Google, NY. 2012). While these methods do not yet compete with fully supervised approaches, they can drastically outperform both unsupervised methods (Klein and Manning, 2004) and weakly supervised methods (Naseem et al., 2010; Berg-Kirkpatrick and Klein, 2010). A promising approach to cross-lingual transfer of syntactic dependency parsers is to use multiple source languages and to tie model parameters across related languages. This idea was first explored for weakly supe</context>
<context position="4964" citStr="Hwa et al., 2005" startWordPosition="718" endWordPosition="721"> ensemble-training algorithm (§5.3). The resulting parser provides significant improvements over a strong baseline parser and achieves a 13% relative error reduction on average with respect to the best model of Naseem et al. (2012), outperforming it on 15 out of the 16 evaluated languages. 2 Multi-Source Delexicalized Transfer The methods proposed in this paper fall into the delexicalized transfer approach to multilingual syntactic parsing (Zeman and Resnik, 2008; McDonald et al., 2011; Cohen et al., 2011; Søgaard, 2011). In contrast to annotation projection approaches (Yarowsky et al., 2001; Hwa et al., 2005; Ganchev et al., 2009; Spreyer and Kuhn, 2009), delexicalized transfer methods do not rely on any bitext. Instead, a parser is trained on annotations in a source language, relying solely on features that are available in both the source and the target language, such as “universal” part-ofspeech tags (Zeman and Resnik, 2008; Naseem et al., 2010; Petrov et al., 2012), cross-lingual word clusters (Täckström et al., 2012) or type-level features derived from bilingual dictionaries (Durrett et al., 2012).1 This parser is then directly used to parse the target language. For languages with similar ty</context>
</contexts>
<marker>Hwa, Resnik, Weinberg, Cabezas, Kolak, 2005</marker>
<rawString>Rebecca Hwa, Philip Resnik, Amy Weinberg, Clara Cabezas, and Okan Kolak. 2005. Bootstrapping parsers via syntactic projection across parallel texts. Natural Language Engineering, 11(03):311–325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rong Jin</author>
<author>Zoubin Ghahramani</author>
</authors>
<title>Learning with multiple labels.</title>
<date>2002</date>
<booktitle>In Proceedings of NIPS.</booktitle>
<contexts>
<context position="24684" citStr="Jin and Ghahramani, 2002" startWordPosition="3991" endWordPosition="3994">concrete guidance for model estimation. Ideally, y(x) will capture heterogenous knowledge that can aid the parser in target language adaptation. In a first-order arc-factored model, we define y(x) in terms of a collection of ambiguous arc sets A(x) = {A(x, m)}|x| m=1, where A(x, m) denotes the set of ambiguously specified heads for the mth token in x. Then, y(x) is defined as the set of all projective dependency trees spanning x that can be assembled from the arcs in A(x). Methods for learning with ambiguous labelings have previously been proposed in the context of multi-class classification (Jin and Ghahramani, 2002), sequence-labeling (Dredze et al., 2009), log-linear LFG parsing (Riezler et al., 2002), as well as for discriminative reranking of generative constituency parsers (Charniak and Johnson, 2005). In contrast to Dredze et al., who allow for weights to be assigned to partial labels, we assume that the ambiguous arcs are weighted uniformly. For target language adaptation, these weights would typically be derived from unreliable sources and we do not want to train the model to simply mimic their beliefs. Furthermore, with this assumption, learning is simply achieved by maximizing the marginal log-l</context>
</contexts>
<marker>Jin, Ghahramani, 2002</marker>
<rawString>Rong Jin and Zoubin Ghahramani. 2002. Learning with multiple labels. In Proceedings of NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Chris D Manning</author>
</authors>
<title>Corpus-based induction of syntactic structure: models of dependency and constituency.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="1979" citStr="Klein and Manning, 2004" startWordPosition="281" endWordPosition="285">ed learning methods, which require large quantities of manually annotated training data. Recently, methods for cross-lingual transfer have appeared as a promising avenue for overcoming this hurdle for both part-of-speech tagging (Yarowsky et al., 2001; Das and Petrov, 2011) and syntactic dependency parsing (Hwa et al., 2005; Zeman and Resnik, 2008; Ganchev et al., 2009; McDonald et al., 2011; Naseem et al., * Work primarily carried out while at Google, NY. 2012). While these methods do not yet compete with fully supervised approaches, they can drastically outperform both unsupervised methods (Klein and Manning, 2004) and weakly supervised methods (Naseem et al., 2010; Berg-Kirkpatrick and Klein, 2010). A promising approach to cross-lingual transfer of syntactic dependency parsers is to use multiple source languages and to tie model parameters across related languages. This idea was first explored for weakly supervised learning (Cohen and Smith, 2009; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010) and recently by Naseem et al. (2012) for multisource cross-lingual transfer. In particular, Naseem et al. showed that by selectively sharing parameters based on typological features of each language, subs</context>
</contexts>
<marker>Klein, Manning, 2004</marker>
<rawString>Dan Klein and Chris D. Manning. 2004. Corpus-based induction of syntactic structure: models of dependency and constituency. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandre Klementiev</author>
<author>Ivan Titov</author>
<author>Binod Bhattarai</author>
</authors>
<title>Inducing crosslingual distributed representations of words.</title>
<date>2012</date>
<booktitle>In Proceedings of COLING.</booktitle>
<contexts>
<context position="6225" citStr="Klementiev et al. (2012)" startWordPosition="911" endWordPosition="914">rate, especially when compared to purely unsupervised methods. For instance, a parser trained on English with only part-of-speech features can correctly parse the Greek sentence in Figure 1, even without knowledge of the lexical items since the sequence of part-of-speech tags determines the syntactic structure almost unambiguously. Learning with multiple languages has been shown to benefit unsupervised learning (Cohen and Smith, 1Note that Täckström et al. (2012) and Durrett et al. (2012) do require bitext or a bilingual dictionary. The same holds for most cross-lingual representations, e.g., Klementiev et al. (2012). PUNC DOBJ PREP POBJ O TC6v 68W6E a-c&apos;v Map(a -co RLRX(o . (The) (John) (gave) (to-the) (Maria) (the) (book) . DET NOUN VERB ADP NOUN DET NOUN P Figure 1: A Greek sentence which is correctly parsed by a delexicalized English parser, provided that part-of-speech tags are available in both the source and target language. 2009; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010). Annotations in multiple languages can be combined in delexicalized transfer as well, as long as the parser features are available across the involved languages. This idea was explored by McDonald et al. (2011), who s</context>
</contexts>
<marker>Klementiev, Titov, Bhattarai, 2012</marker>
<rawString>Alexandre Klementiev, Ivan Titov, and Binod Bhattarai. 2012. Inducing crosslingual distributed representations of words. In Proceedings of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dong C Liu</author>
<author>Jorge Nocedal</author>
</authors>
<title>On the limited memory BFGS method for large scale optimization.</title>
<date>1989</date>
<booktitle>Mathematical Programming,</booktitle>
<volume>45</volume>
<contexts>
<context position="11933" citStr="Liu and Nocedal, 1989" startWordPosition="1823" endWordPosition="1826">the following form: exp {θTb(x, y)} pθ(y x) = EyIEY(x) exp {θTb(x, y1)} . Without loss of generality, we restrict ourselves to first-order models, where the feature function b(x, y) factors over individual arcs (h, m) in y, such that b(x, y) = � φ(x, h, m) , (h,m)Ey where h E [0, x ] and m E [1, x ] are the indices of the head word and the dependent word of the arc; h = 0 represents a dummy ROOT token. The model parameters are estimated by maximizing the log-likelihood of the training data D = {(xi, yi)}ni=1, n L(θ; D) = log pθ(yi xi) . i=1 We use the standard gradient-based L-BFGS algorithm (Liu and Nocedal, 1989) to maximize the loglikelihood. Eisner’s algorithm (Eisner, 1996) is used for inference of the Viterbi parse and arc-marginals. 3.2 Data Sets and Experimental Setup To facilitate comparison with the state of the art, we use the same treebanks and experimental setup as Naseem et al. (2012). Notably, we use the mapping proposed by Naseem et al. (2010) to map from fine-grained treebank specific part-of-speech tags to coarse-grained “universal” tags, rather than the more recent mapping proposed by Petrov et al. (2012). For 1063 Delexicalized MSTParser Bare Selectively shared d ⊗ l; [d ⊗ l] ⊗ h.p; </context>
</contexts>
<marker>Liu, Nocedal, 1989</marker>
<rawString>Dong C. Liu and Jorge Nocedal. 1989. On the limited memory BFGS method for large scale optimization. Mathematical Programming, 45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David McClosky</author>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Reranking and self-training for parser adaptation.</title>
<date>2006</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="22542" citStr="McClosky et al., 2006" startWordPosition="3668" endWordPosition="3671">higher accuracies compared to generative models when the features are carefully constructed. 5 Target Language Adaptation While some higher-level linguistic properties of the target language have been incorporated through selective sharing, so far no features specific to the target language have been employed. Cohen et al. (2011) and Naseem et al. (2012) have shown that using expectation-maximization (EM) to this end can in some cases bring substantial accuracy gains. For discriminative models, self-training has been shown to be quite effective for adapting monolingual parsers to new domains (McClosky et al., 2006), as well as for relexicalizing delexicalized parsers using unlabeled target language data (Zeman and Resnik, 2008). Similarly Täckström (2012) used self-training to adapt a multi-source direct transfer named-entity recognizer (Täckström et al., 2012) to different target languages, “relexicalizing” the model with word cluster features. However, as discussed in §5.2, standard self-training is not optimal for target language adaptation. 5.1 Ambiguity-Aware Training In this section, we propose a related training method: ambiguity-aware training. In this setting a discriminative probabilistic mode</context>
</contexts>
<marker>McClosky, Charniak, Johnson, 2006</marker>
<rawString>David McClosky, Eugene Charniak, and Mark Johnson. 2006. Reranking and self-training for parser adaptation. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Koby Crammer</author>
<author>Fernando Pereira</author>
</authors>
<title>Online large-margin training of dependency parsers.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="2914" citStr="McDonald et al., 2005" startWordPosition="419" endWordPosition="422">ng (Cohen and Smith, 2009; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010) and recently by Naseem et al. (2012) for multisource cross-lingual transfer. In particular, Naseem et al. showed that by selectively sharing parameters based on typological features of each language, substantial improvements can be achieved, compared to using a single set of parameters for all languages. However, these methods all employ generative models with strong independence assumptions and weak feature representations, which upper bounds their accuracy far below that of feature-rich discriminative parsers (McDonald et al., 2005; Nivre, 2008). In this paper, we improve upon the state of the art in cross-lingual transfer of dependency parsers from multiple source languages by adapting feature-rich discriminatively trained parsers to a specific target language. First, in §4 we show how selective sharing of model parameters based on typological traits can be incorporated into a delexicalized discriminative graph-based parsing model. This requires a careful decomposition of features into language-generic and language-specific sets in order to tie specific target language parameters to their relevant source language count</context>
<context position="9619" citStr="McDonald et al., 2005" startWordPosition="1435" endWordPosition="1439">eatures of the languages extracted from WALS — the World Atlas of Language Structures (Dryer and Haspelmath, 2011) — as shown in Table 1. In the transfer scenario, where no supervision is available in the target language, this parser achieves the hitherto best published results across a number of languages; in particular for target languages with a word order divergent from the source languages. However, the generative model of Naseem et al. is quite impoverished. In the fully supervised setting, it obtains substantially lower accuracies compared to a standard arc-factored graph-based parser (McDonald et al., 2005). Averaged across 16 languages,2 the generative model trained with full supervision on the target language obtains an accuracy of 67.1%. A comparable lexicalized discriminative arc-factored model (McDonald et al., 2005) obtains 84.1%. Even when delexicalized, this model reaches 78.9%. This gap in supervised accuracy holds for all 16 languages. Thus, while selective sharing is a powerful device for transferring parsers across languages, the underlying generative model used by Naseem et al. (2012) restricts its potential performance. 3 Basic Models and Experimental Setup Inspired by the superior</context>
<context position="14687" citStr="McDonald et al., 2005" startWordPosition="2347" endWordPosition="2350"> are evaluated in terms of unlabeled attachment score (UAS). In line with Naseem et al. (2012), we use gold part-of-speech tags and evaluate only on sentences of length 50 or less excluding punctuation. 3.3 Baseline Models We compare our models to two multi-source baseline models. The first baseline, NBG, is the generative model with selective parameter sharing from Naseem et al. (2012).3 This model is trained without target language data, but we investigate the use of such data in §5.4. The second baseline, Delex, is a delexicalized projective version of the well-known graph-based MSTParser (McDonald et al., 2005). The feature templates used by this model are shown to the left in Figure 2. Note that there is no selective sharing in this model. The second and third columns of Table 2 show the unlabeled attachment scores of the baseline models for each target language. We see that Delex performs well on target languages that are related to the majority of the source languages. However, for languages 3Model “D-,To” in Table 2 from Naseem et al. (2012). that diverge from the Indo-European majority family, the selective sharing model, NBG, achieves substantially higher accuracies. 4 Feature-Based Selective </context>
<context position="33096" citStr="McDonald et al., 2005" startWordPosition="5401" endWordPosition="5404">iguity sets of our base parser, the result will encode uncertainty derived from both parsers. 5.4 Adaptation Experiments We now study the different approaches to target language adaptation empirically. As in Naseem et al. (2012), we use the CoNLL training sets, stripped of all dependency information, as the unlabeled target language data in our experiments. We use the Family model as the base parser, which is used to label the unlabeled target data with the Viterbi parses as well as with the ambiguous labelings. The final model is then trained on this data using standard lexicalized features (McDonald et al., 2005). Since labeled training data is unavailable in the target language, we cannot tune any hyper-parameters and simply set A =1 and a = 0.95 throughout. Although the latter may suggest that y(x) contains a high degree of ambiguity, in reality, the marginal distributions of the base model have low entropy and after filtering with a = 0.95, the average number of potential heads per dependent ranges from 1.4 to 3.2, depending on the target language. The ambiguity-aware training methods, that is ambiguity-aware self-training (AAST) and ambiguityaware ensemble-training (AAET), are compared to three ba</context>
</contexts>
<marker>McDonald, Crammer, Pereira, 2005</marker>
<rawString>Ryan McDonald, Koby Crammer, and Fernando Pereira. 2005. Online large-margin training of dependency parsers. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Slav Petrov</author>
<author>Keith Hall</author>
</authors>
<title>Multi-source transfer of delexicalized dependency parsers.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="1749" citStr="McDonald et al., 2011" startWordPosition="245" endWordPosition="248">ransfer parsing on 15 out of 16 evaluated languages. 1 Introduction Many languages still lack access to core NLP tools, such as part-of-speech taggers and syntactic parsers. This is largely due to the reliance on fully supervised learning methods, which require large quantities of manually annotated training data. Recently, methods for cross-lingual transfer have appeared as a promising avenue for overcoming this hurdle for both part-of-speech tagging (Yarowsky et al., 2001; Das and Petrov, 2011) and syntactic dependency parsing (Hwa et al., 2005; Zeman and Resnik, 2008; Ganchev et al., 2009; McDonald et al., 2011; Naseem et al., * Work primarily carried out while at Google, NY. 2012). While these methods do not yet compete with fully supervised approaches, they can drastically outperform both unsupervised methods (Klein and Manning, 2004) and weakly supervised methods (Naseem et al., 2010; Berg-Kirkpatrick and Klein, 2010). A promising approach to cross-lingual transfer of syntactic dependency parsers is to use multiple source languages and to tie model parameters across related languages. This idea was first explored for weakly supervised learning (Cohen and Smith, 2009; Snyder et al., 2009; Berg-Kir</context>
<context position="4838" citStr="McDonald et al., 2011" startWordPosition="698" endWordPosition="701">aining algorithm (§5.2); these arc sets are then combined with the predictions of a different transfer parser in an ambiguity-aware ensemble-training algorithm (§5.3). The resulting parser provides significant improvements over a strong baseline parser and achieves a 13% relative error reduction on average with respect to the best model of Naseem et al. (2012), outperforming it on 15 out of the 16 evaluated languages. 2 Multi-Source Delexicalized Transfer The methods proposed in this paper fall into the delexicalized transfer approach to multilingual syntactic parsing (Zeman and Resnik, 2008; McDonald et al., 2011; Cohen et al., 2011; Søgaard, 2011). In contrast to annotation projection approaches (Yarowsky et al., 2001; Hwa et al., 2005; Ganchev et al., 2009; Spreyer and Kuhn, 2009), delexicalized transfer methods do not rely on any bitext. Instead, a parser is trained on annotations in a source language, relying solely on features that are available in both the source and the target language, such as “universal” part-ofspeech tags (Zeman and Resnik, 2008; Naseem et al., 2010; Petrov et al., 2012), cross-lingual word clusters (Täckström et al., 2012) or type-level features derived from bilingual dicti</context>
<context position="6818" citStr="McDonald et al. (2011)" startWordPosition="1009" endWordPosition="1013">.g., Klementiev et al. (2012). PUNC DOBJ PREP POBJ O TC6v 68W6E a-c&apos;v Map(a -co RLRX(o . (The) (John) (gave) (to-the) (Maria) (the) (book) . DET NOUN VERB ADP NOUN DET NOUN P Figure 1: A Greek sentence which is correctly parsed by a delexicalized English parser, provided that part-of-speech tags are available in both the source and target language. 2009; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010). Annotations in multiple languages can be combined in delexicalized transfer as well, as long as the parser features are available across the involved languages. This idea was explored by McDonald et al. (2011), who showed that target language accuracy can be improved by simply concatenating delexicalized treebanks in multiple languages. In similar work, Cohen et al. (2011) proposed a mixture model in which the parameters of a generative target language parser is expressed as a linear interpolation of source language parameters, whereas Søgaard (2011) showed that target side language models can be used to selectively subsample training sentences to improve accuracy. Recently, inspired by the phylogenetic prior of Berg-Kirkpatrick and Klein (2010), Søgaard and Wulff (2012) proposed — among other idea</context>
</contexts>
<marker>McDonald, Petrov, Hall, 2011</marker>
<rawString>Ryan McDonald, Slav Petrov, and Keith Hall. 2011. Multi-source transfer of delexicalized dependency parsers. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tahira Naseem</author>
<author>Harr Chen</author>
<author>Regina Barzilay</author>
<author>Mark Johnson</author>
</authors>
<title>Using universal linguistic knowledge to guide grammar induction.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="2030" citStr="Naseem et al., 2010" startWordPosition="290" endWordPosition="293">anually annotated training data. Recently, methods for cross-lingual transfer have appeared as a promising avenue for overcoming this hurdle for both part-of-speech tagging (Yarowsky et al., 2001; Das and Petrov, 2011) and syntactic dependency parsing (Hwa et al., 2005; Zeman and Resnik, 2008; Ganchev et al., 2009; McDonald et al., 2011; Naseem et al., * Work primarily carried out while at Google, NY. 2012). While these methods do not yet compete with fully supervised approaches, they can drastically outperform both unsupervised methods (Klein and Manning, 2004) and weakly supervised methods (Naseem et al., 2010; Berg-Kirkpatrick and Klein, 2010). A promising approach to cross-lingual transfer of syntactic dependency parsers is to use multiple source languages and to tie model parameters across related languages. This idea was first explored for weakly supervised learning (Cohen and Smith, 2009; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010) and recently by Naseem et al. (2012) for multisource cross-lingual transfer. In particular, Naseem et al. showed that by selectively sharing parameters based on typological features of each language, substantial improvements can be achieved, compared to u</context>
<context position="5310" citStr="Naseem et al., 2010" startWordPosition="775" endWordPosition="778">oposed in this paper fall into the delexicalized transfer approach to multilingual syntactic parsing (Zeman and Resnik, 2008; McDonald et al., 2011; Cohen et al., 2011; Søgaard, 2011). In contrast to annotation projection approaches (Yarowsky et al., 2001; Hwa et al., 2005; Ganchev et al., 2009; Spreyer and Kuhn, 2009), delexicalized transfer methods do not rely on any bitext. Instead, a parser is trained on annotations in a source language, relying solely on features that are available in both the source and the target language, such as “universal” part-ofspeech tags (Zeman and Resnik, 2008; Naseem et al., 2010; Petrov et al., 2012), cross-lingual word clusters (Täckström et al., 2012) or type-level features derived from bilingual dictionaries (Durrett et al., 2012).1 This parser is then directly used to parse the target language. For languages with similar typology, this method can be quite accurate, especially when compared to purely unsupervised methods. For instance, a parser trained on English with only part-of-speech features can correctly parse the Greek sentence in Figure 1, even without knowledge of the lexical items since the sequence of part-of-speech tags determines the syntactic structu</context>
<context position="12284" citStr="Naseem et al. (2010)" startWordPosition="1882" endWordPosition="1885">ord of the arc; h = 0 represents a dummy ROOT token. The model parameters are estimated by maximizing the log-likelihood of the training data D = {(xi, yi)}ni=1, n L(θ; D) = log pθ(yi xi) . i=1 We use the standard gradient-based L-BFGS algorithm (Liu and Nocedal, 1989) to maximize the loglikelihood. Eisner’s algorithm (Eisner, 1996) is used for inference of the Viterbi parse and arc-marginals. 3.2 Data Sets and Experimental Setup To facilitate comparison with the state of the art, we use the same treebanks and experimental setup as Naseem et al. (2012). Notably, we use the mapping proposed by Naseem et al. (2010) to map from fine-grained treebank specific part-of-speech tags to coarse-grained “universal” tags, rather than the more recent mapping proposed by Petrov et al. (2012). For 1063 Delexicalized MSTParser Bare Selectively shared d ⊗ l; [d ⊗ l] ⊗ h.p; [d ⊗ l] ⊗ m.p [d ⊗ l] ⊗ h.p ⊗ m.p [d ⊗ l] ⊗ h.p ⊗ h+1.p ⊗ m−1.p ⊗ m.p [d ⊗ l] ⊗ h−1.p ⊗ h.p ⊗ m−1.p ⊗ m.p [d ⊗ l] ⊗ h.p ⊗ h+1.p ⊗ m.p ⊗ m+1.p [d ⊗ l] ⊗ h−1.p ⊗ h.p ⊗ m.p ⊗ m+1.p h.p ⊗ between.p ⊗ m.p l [l] ⊗ h.p [l] ⊗ m.p [l] ⊗ h.p ⊗ m.p d ⊗ w.81A ⊗ 1[h.p = VERB ∧ m.p = NOUN] d ⊗ w.81A ⊗ 1[h.p = VERB ∧ m.p = PRON] d ⊗ w.85A ⊗ 1[h.p = ADP ∧ m.p = NOU</context>
</contexts>
<marker>Naseem, Chen, Barzilay, Johnson, 2010</marker>
<rawString>Tahira Naseem, Harr Chen, Regina Barzilay, and Mark Johnson. 2010. Using universal linguistic knowledge to guide grammar induction. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tahira Naseem</author>
<author>Regina Barzilay</author>
<author>Amir Globerson</author>
</authors>
<title>Selective sharing for multilingual dependency parsing.</title>
<date>2012</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="2411" citStr="Naseem et al. (2012)" startWordPosition="346" endWordPosition="349">out while at Google, NY. 2012). While these methods do not yet compete with fully supervised approaches, they can drastically outperform both unsupervised methods (Klein and Manning, 2004) and weakly supervised methods (Naseem et al., 2010; Berg-Kirkpatrick and Klein, 2010). A promising approach to cross-lingual transfer of syntactic dependency parsers is to use multiple source languages and to tie model parameters across related languages. This idea was first explored for weakly supervised learning (Cohen and Smith, 2009; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010) and recently by Naseem et al. (2012) for multisource cross-lingual transfer. In particular, Naseem et al. showed that by selectively sharing parameters based on typological features of each language, substantial improvements can be achieved, compared to using a single set of parameters for all languages. However, these methods all employ generative models with strong independence assumptions and weak feature representations, which upper bounds their accuracy far below that of feature-rich discriminative parsers (McDonald et al., 2005; Nivre, 2008). In this paper, we improve upon the state of the art in cross-lingual transfer of </context>
<context position="4579" citStr="Naseem et al. (2012)" startWordPosition="658" endWordPosition="661">icalization and target language adaptation of the transfer parser. Here, we experiment with two different knowledge sources: arc sets, which are filtered by marginal probabilities from the cross-lingual transfer parser, are used in an ambiguity-aware self-training algorithm (§5.2); these arc sets are then combined with the predictions of a different transfer parser in an ambiguity-aware ensemble-training algorithm (§5.3). The resulting parser provides significant improvements over a strong baseline parser and achieves a 13% relative error reduction on average with respect to the best model of Naseem et al. (2012), outperforming it on 15 out of the 16 evaluated languages. 2 Multi-Source Delexicalized Transfer The methods proposed in this paper fall into the delexicalized transfer approach to multilingual syntactic parsing (Zeman and Resnik, 2008; McDonald et al., 2011; Cohen et al., 2011; Søgaard, 2011). In contrast to annotation projection approaches (Yarowsky et al., 2001; Hwa et al., 2005; Ganchev et al., 2009; Spreyer and Kuhn, 2009), delexicalized transfer methods do not rely on any bitext. Instead, a parser is trained on annotations in a source language, relying solely on features that are availa</context>
<context position="8048" citStr="Naseem et al. (2012)" startWordPosition="1190" endWordPosition="1193">logically informed weighting heuristic for linearly interpolating source language parameters. However, this weighting did not provide significant improvements over uniform weighting. The aforementioned approaches work well for transfer between similar languages. However, their assumptions cease to hold for typologically divergent languages; a target language can rarely be described as a linear combination of data or model parameters from a set of source languages, as languages tend to share varied typological traits; this critical insight is discussed further in §4. To account for this issue, Naseem et al. (2012) recently introduced a novel generative model of dependency parsing, in which the generative process is factored into separate steps for the selection of dependents and their ordering. The parameters used in the selection step are all language independent, capturing only head-dependent attachment preferences. In the ordering step, however, parameters are selectively shared between subsets of ROOT DET NSUBJ DET 1062 Feature Description 81A Order of Subject, Object and Verb 85A Order of Adposition and Noun 86A Order of Genitive and Noun 87A Order of Adjective and Noun 88A Order of Demonstrative </context>
<context position="10119" citStr="Naseem et al. (2012)" startWordPosition="1509" endWordPosition="1512">it obtains substantially lower accuracies compared to a standard arc-factored graph-based parser (McDonald et al., 2005). Averaged across 16 languages,2 the generative model trained with full supervision on the target language obtains an accuracy of 67.1%. A comparable lexicalized discriminative arc-factored model (McDonald et al., 2005) obtains 84.1%. Even when delexicalized, this model reaches 78.9%. This gap in supervised accuracy holds for all 16 languages. Thus, while selective sharing is a powerful device for transferring parsers across languages, the underlying generative model used by Naseem et al. (2012) restricts its potential performance. 3 Basic Models and Experimental Setup Inspired by the superiority of discriminative graphbased parsing in the supervised scenario, we investigate whether the insights of Naseem et al. (2012) on selective parameter sharing can be incorporated into such models in the transfer scenario. We first review the basic graph-based parser framework and the 2Based on results in Naseem et al. (2012), excluding English. experimental setup that we will use throughout. We then delve into details on how to incorporate selective sharing in this model in §4. In §5, we show h</context>
<context position="12222" citStr="Naseem et al. (2012)" startWordPosition="1870" endWordPosition="1873">E [1, x ] are the indices of the head word and the dependent word of the arc; h = 0 represents a dummy ROOT token. The model parameters are estimated by maximizing the log-likelihood of the training data D = {(xi, yi)}ni=1, n L(θ; D) = log pθ(yi xi) . i=1 We use the standard gradient-based L-BFGS algorithm (Liu and Nocedal, 1989) to maximize the loglikelihood. Eisner’s algorithm (Eisner, 1996) is used for inference of the Viterbi parse and arc-marginals. 3.2 Data Sets and Experimental Setup To facilitate comparison with the state of the art, we use the same treebanks and experimental setup as Naseem et al. (2012). Notably, we use the mapping proposed by Naseem et al. (2010) to map from fine-grained treebank specific part-of-speech tags to coarse-grained “universal” tags, rather than the more recent mapping proposed by Petrov et al. (2012). For 1063 Delexicalized MSTParser Bare Selectively shared d ⊗ l; [d ⊗ l] ⊗ h.p; [d ⊗ l] ⊗ m.p [d ⊗ l] ⊗ h.p ⊗ m.p [d ⊗ l] ⊗ h.p ⊗ h+1.p ⊗ m−1.p ⊗ m.p [d ⊗ l] ⊗ h−1.p ⊗ h.p ⊗ m−1.p ⊗ m.p [d ⊗ l] ⊗ h.p ⊗ h+1.p ⊗ m.p ⊗ m+1.p [d ⊗ l] ⊗ h−1.p ⊗ h.p ⊗ m.p ⊗ m+1.p h.p ⊗ between.p ⊗ m.p l [l] ⊗ h.p [l] ⊗ m.p [l] ⊗ h.p ⊗ m.p d ⊗ w.81A ⊗ 1[h.p = VERB ∧ m.p = NOUN] d ⊗ w.81A ⊗ </context>
<context position="13904" citStr="Naseem et al. (2012)" startWordPosition="2227" endWordPosition="2230">PRT, PUNC, X}; token to the left / right of z: z_1 / z+1; WALS features: w.X for X = 81A, 85A, 86A, 87A (see Table 1). [·] denotes an optional template, e.g., [d ⊗ 1] ⊗ h.p ⊗ m.p expands to templates d ⊗ 1 ⊗ h.p ⊗ m.p and h.p ⊗ m.p, so that the template also falls back on its undirectional variant. each target language evaluated, the treebanks of the remaining languages are used as labeled training data, while the target language treebank is used for testing only (in §5 a different portion of the target language treebank is additionally used as unlabeled training data). We refer the reader to Naseem et al. (2012) for detailed information on the different treebanks. Due to divergent treebank annotation guidelines, which makes fine-grained evaluation difficult, all results are evaluated in terms of unlabeled attachment score (UAS). In line with Naseem et al. (2012), we use gold part-of-speech tags and evaluate only on sentences of length 50 or less excluding punctuation. 3.3 Baseline Models We compare our models to two multi-source baseline models. The first baseline, NBG, is the generative model with selective parameter sharing from Naseem et al. (2012).3 This model is trained without target language d</context>
<context position="15130" citStr="Naseem et al. (2012)" startWordPosition="2426" endWordPosition="2429">ut we investigate the use of such data in §5.4. The second baseline, Delex, is a delexicalized projective version of the well-known graph-based MSTParser (McDonald et al., 2005). The feature templates used by this model are shown to the left in Figure 2. Note that there is no selective sharing in this model. The second and third columns of Table 2 show the unlabeled attachment scores of the baseline models for each target language. We see that Delex performs well on target languages that are related to the majority of the source languages. However, for languages 3Model “D-,To” in Table 2 from Naseem et al. (2012). that diverge from the Indo-European majority family, the selective sharing model, NBG, achieves substantially higher accuracies. 4 Feature-Based Selective Sharing The results for the baseline models are not surprising considering the feature templates used by Delex. There are two fundamental issues with these features when used for direct transfer. First, all but one template include the arc direction. Second, some features are sensitive to local word order; e.g., [d ⊗ 1] ⊗ h.p ⊗ h+1.p ⊗ m_1.p ⊗ m.p, which models direction as well as word order in the local contexts of the head and the depen</context>
<context position="17626" citStr="Naseem et al. (2012)" startWordPosition="2855" endWordPosition="2858">0.5 64.5 64.5 64.5 it 68.0 70.8 55.7 63.5 74.6 72.5 ja 62.3 38.9 50.6 57.1 64.6 65.9 nl 56.2 57.9 51.6 55.0 51.8 56.8 pt 76.2 77.5 63.0 72.7 78.4 78.4 sv 52.0 61.4 55.9 58.8 48.8 63.5 tr 59.1 37.4 36.0 41.7 59.5 59.4 zh 59.9 45.1 47.9 54.8 54.8 54.8 avg 59.3 55.1 51.5 57.4 60.7 62.0 Table 2: Unlabeled attachment scores of the multi-source transfer models. Boldface numbers indicate the best result per language. Underlined numbers indicate languages whose group is not represented in the training data (these default to Share under Similarity and Family). NBG is the “D-,T,,” model in Table 2 from Naseem et al. (2012). (2012), we make use of the typological features from WALS (Dryer and Haspelmath, 2011), listed in Table 1, to selectively share directional parameters between languages. As a natural first attempt at sharing parameters, one might consider forming the crossproduct of all features of Delex with all WALS properties, similarly to a common domain adaptation technique (Daumé III, 2007; Finkel and Manning, 2009). However, this approach has two issues. First, it results in a huge number of features, making the model prone to overfitting. Second, and more critically, it ties together languages via fe</context>
<context position="22276" citStr="Naseem et al. (2012)" startWordPosition="3628" endWordPosition="3631">n-Indo-European languages; e.g., Japanese increases from 38.9% to 65.9%. Furthermore, Family achieves a 7% relative error reduction over the NBG baseline and outperforms it on 12 of the 16 languages. This shows that a discriminative graph-based parser can achieve higher accuracies compared to generative models when the features are carefully constructed. 5 Target Language Adaptation While some higher-level linguistic properties of the target language have been incorporated through selective sharing, so far no features specific to the target language have been employed. Cohen et al. (2011) and Naseem et al. (2012) have shown that using expectation-maximization (EM) to this end can in some cases bring substantial accuracy gains. For discriminative models, self-training has been shown to be quite effective for adapting monolingual parsers to new domains (McClosky et al., 2006), as well as for relexicalizing delexicalized parsers using unlabeled target language data (Zeman and Resnik, 2008). Similarly Täckström (2012) used self-training to adapt a multi-source direct transfer named-entity recognizer (Täckström et al., 2012) to different target languages, “relexicalizing” the model with word cluster featur</context>
<context position="32360" citStr="Naseem et al. (2012)" startWordPosition="5279" endWordPosition="5282"> and used at runtime. It is straightforward to construct y(x) from multiple parsers. Let Ak(x, m) be the set of arcs for the mth token in x according to the kth parser in the ensemble. When arc-marginals are used to construct the ambiguity set, |Ak(x, m) |&gt; 1, but when the Viterbiparse is used, Ak(x, m) is a singleton. We next form A(x, m) = Uk Ak(x, m) as the ensemble arc ambiguity set from which y(x) is assembled. In this study, we combine the arc sets of two base parsers: first, the arc-marginal ambiguity set of the base parser (§5.2); and second, the Viterbi arc set from the NBG parser of Naseem et al. (2012) in Table 2.4 Thus, the latter will have singleton arc ambiguity sets, but when combined with the arc-marginal ambiguity sets of our base parser, the result will encode uncertainty derived from both parsers. 5.4 Adaptation Experiments We now study the different approaches to target language adaptation empirically. As in Naseem et al. (2012), we use the CoNLL training sets, stripped of all dependency information, as the unlabeled target language data in our experiments. We use the Family model as the base parser, which is used to label the unlabeled target data with the Viterbi parses as well a</context>
</contexts>
<marker>Naseem, Barzilay, Globerson, 2012</marker>
<rawString>Tahira Naseem, Regina Barzilay, and Amir Globerson. 2012. Selective sharing for multilingual dependency parsing. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Algorithms for deterministic incremental dependency parsing.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>4</issue>
<marker>Nivre, 2008</marker>
<rawString>Joakim Nivre. 2008. Algorithms for deterministic incremental dependency parsing. Computational Linguistics, 34(4):513–553.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dipanjan Das</author>
<author>Ryan McDonald</author>
</authors>
<title>A universal part-of-speech tagset.</title>
<date>2012</date>
<booktitle>In Proceedings of LREC.</booktitle>
<contexts>
<context position="5332" citStr="Petrov et al., 2012" startWordPosition="779" endWordPosition="782">fall into the delexicalized transfer approach to multilingual syntactic parsing (Zeman and Resnik, 2008; McDonald et al., 2011; Cohen et al., 2011; Søgaard, 2011). In contrast to annotation projection approaches (Yarowsky et al., 2001; Hwa et al., 2005; Ganchev et al., 2009; Spreyer and Kuhn, 2009), delexicalized transfer methods do not rely on any bitext. Instead, a parser is trained on annotations in a source language, relying solely on features that are available in both the source and the target language, such as “universal” part-ofspeech tags (Zeman and Resnik, 2008; Naseem et al., 2010; Petrov et al., 2012), cross-lingual word clusters (Täckström et al., 2012) or type-level features derived from bilingual dictionaries (Durrett et al., 2012).1 This parser is then directly used to parse the target language. For languages with similar typology, this method can be quite accurate, especially when compared to purely unsupervised methods. For instance, a parser trained on English with only part-of-speech features can correctly parse the Greek sentence in Figure 1, even without knowledge of the lexical items since the sequence of part-of-speech tags determines the syntactic structure almost unambiguousl</context>
<context position="12452" citStr="Petrov et al. (2012)" startWordPosition="1906" endWordPosition="1909"> D) = log pθ(yi xi) . i=1 We use the standard gradient-based L-BFGS algorithm (Liu and Nocedal, 1989) to maximize the loglikelihood. Eisner’s algorithm (Eisner, 1996) is used for inference of the Viterbi parse and arc-marginals. 3.2 Data Sets and Experimental Setup To facilitate comparison with the state of the art, we use the same treebanks and experimental setup as Naseem et al. (2012). Notably, we use the mapping proposed by Naseem et al. (2010) to map from fine-grained treebank specific part-of-speech tags to coarse-grained “universal” tags, rather than the more recent mapping proposed by Petrov et al. (2012). For 1063 Delexicalized MSTParser Bare Selectively shared d ⊗ l; [d ⊗ l] ⊗ h.p; [d ⊗ l] ⊗ m.p [d ⊗ l] ⊗ h.p ⊗ m.p [d ⊗ l] ⊗ h.p ⊗ h+1.p ⊗ m−1.p ⊗ m.p [d ⊗ l] ⊗ h−1.p ⊗ h.p ⊗ m−1.p ⊗ m.p [d ⊗ l] ⊗ h.p ⊗ h+1.p ⊗ m.p ⊗ m+1.p [d ⊗ l] ⊗ h−1.p ⊗ h.p ⊗ m.p ⊗ m+1.p h.p ⊗ between.p ⊗ m.p l [l] ⊗ h.p [l] ⊗ m.p [l] ⊗ h.p ⊗ m.p d ⊗ w.81A ⊗ 1[h.p = VERB ∧ m.p = NOUN] d ⊗ w.81A ⊗ 1[h.p = VERB ∧ m.p = PRON] d ⊗ w.85A ⊗ 1[h.p = ADP ∧ m.p = NOUN] d ⊗ w.85A ⊗ 1[h.p = ADP ∧ m.p = PRON] d ⊗ w.86A ⊗ 1[h.p = NOUN ∧ m.p = NOUN] d ⊗ w.87A ⊗ 1[h.p = NOUN ∧ m.p = ADJ] Figure 2: Arc-factored feature templates for graph</context>
</contexts>
<marker>Petrov, Das, McDonald, 2012</marker>
<rawString>Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012. A universal part-of-speech tagset. In Proceedings of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Riezler</author>
<author>Tracy H King</author>
<author>Ronald M Kaplan</author>
<author>Richard Crouch</author>
<author>John T Maxwell</author>
<author>Mark Johnson</author>
</authors>
<title>Parsing the Wall Street Journal using a lexicalfunctional grammar and discriminative estimation techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="24772" citStr="Riezler et al., 2002" startWordPosition="4003" endWordPosition="4006">at can aid the parser in target language adaptation. In a first-order arc-factored model, we define y(x) in terms of a collection of ambiguous arc sets A(x) = {A(x, m)}|x| m=1, where A(x, m) denotes the set of ambiguously specified heads for the mth token in x. Then, y(x) is defined as the set of all projective dependency trees spanning x that can be assembled from the arcs in A(x). Methods for learning with ambiguous labelings have previously been proposed in the context of multi-class classification (Jin and Ghahramani, 2002), sequence-labeling (Dredze et al., 2009), log-linear LFG parsing (Riezler et al., 2002), as well as for discriminative reranking of generative constituency parsers (Charniak and Johnson, 2005). In contrast to Dredze et al., who allow for weights to be assigned to partial labels, we assume that the ambiguous arcs are weighted uniformly. For target language adaptation, these weights would typically be derived from unreliable sources and we do not want to train the model to simply mimic their beliefs. Furthermore, with this assumption, learning is simply achieved by maximizing the marginal log-likelihood of the ambiguous training set D = {(xi, y(xi)}ni=1, G(θ; D) = In maximizing th</context>
</contexts>
<marker>Riezler, King, Kaplan, Crouch, Maxwell, Johnson, 2002</marker>
<rawString>Stefan Riezler, Tracy H. King, Ronald M. Kaplan, Richard Crouch, John T. Maxwell, III, and Mark Johnson. 2002. Parsing the Wall Street Journal using a lexicalfunctional grammar and discriminative estimation techniques. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Sagae</author>
<author>Alon Lavie</author>
</authors>
<title>Parser combination by reparsing.</title>
<date>2006</date>
<booktitle>In Proceedings of NAACL.</booktitle>
<contexts>
<context position="29783" citStr="Sagae and Lavie, 2006" startWordPosition="4827" endWordPosition="4830">biguity-Aware Ensemble-Training While ambiguous labelings can be used as a means to improve self-training, any information that can be expressed as hard arc-factored constraints can be incorporated, including linguistic expert knowledge and annotation projected via bitext. Here we explore another natural source of information: the predictions of other transfer parsers. It is well known that combining several diverse predictions in an ensemble often leads to improved predictions. However, in most ensemble methods there is typically no learning involved once the base learners have been trained (Sagae and Lavie, 2006). An exception is the method of Sagae and Tsujii (2007), who combine the outputs of many parsers on unlabeled data to train a parser for a new domain. However, in that work the learner is not exposed to the underlying ambiguity of the base parsers; it is only given the Viterbi parse of the combination system as the gold standard. In contrast, 1067 Η παραmονή σκαφών επιτρέπεται mόνο τη mέρα DET NOUN NOUN VERB ADV DET NOUN Η παραmονή σκαφών επιτρέπεται mόνο τη mέρα DET NOUN NOUN VERB ADV DET NOUN Η παραmονή σκαφών επιτρέπεται mόνο τη mέρα DET NOUN NOUN VERB ADV DET NOUN Figure 3: An example of a</context>
</contexts>
<marker>Sagae, Lavie, 2006</marker>
<rawString>Kenji Sagae and Alon Lavie. 2006. Parser combination by reparsing. In Proceedings of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Sagae</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Dependency parsing and domain adaptation with LR models and parser ensembles.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP-CoNLL.</booktitle>
<contexts>
<context position="29838" citStr="Sagae and Tsujii (2007)" startWordPosition="4837" endWordPosition="4840">ngs can be used as a means to improve self-training, any information that can be expressed as hard arc-factored constraints can be incorporated, including linguistic expert knowledge and annotation projected via bitext. Here we explore another natural source of information: the predictions of other transfer parsers. It is well known that combining several diverse predictions in an ensemble often leads to improved predictions. However, in most ensemble methods there is typically no learning involved once the base learners have been trained (Sagae and Lavie, 2006). An exception is the method of Sagae and Tsujii (2007), who combine the outputs of many parsers on unlabeled data to train a parser for a new domain. However, in that work the learner is not exposed to the underlying ambiguity of the base parsers; it is only given the Viterbi parse of the combination system as the gold standard. In contrast, 1067 Η παραmονή σκαφών επιτρέπεται mόνο τη mέρα DET NOUN NOUN VERB ADV DET NOUN Η παραmονή σκαφών επιτρέπεται mόνο τη mέρα DET NOUN NOUN VERB ADV DET NOUN Η παραmονή σκαφών επιτρέπεται mόνο τη mέρα DET NOUN NOUN VERB ADV DET NOUN Figure 3: An example of ambiguity-aware self-training (AAST) on a sentence from </context>
</contexts>
<marker>Sagae, Tsujii, 2007</marker>
<rawString>Kenji Sagae and Jun’ichi Tsujii. 2007. Dependency parsing and domain adaptation with LR models and parser ensembles. In Proceedings of EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Snyder</author>
<author>Tahira Naseem</author>
<author>Jacob Eisenstein</author>
<author>Regina Barzilay</author>
</authors>
<title>Adding more languages improves unsupervised multilingual part-of-speech tagging: A Bayesian non-parametric approach.</title>
<date>2009</date>
<booktitle>In Proceedings of NAACL.</booktitle>
<contexts>
<context position="2339" citStr="Snyder et al., 2009" startWordPosition="335" endWordPosition="338">, 2009; McDonald et al., 2011; Naseem et al., * Work primarily carried out while at Google, NY. 2012). While these methods do not yet compete with fully supervised approaches, they can drastically outperform both unsupervised methods (Klein and Manning, 2004) and weakly supervised methods (Naseem et al., 2010; Berg-Kirkpatrick and Klein, 2010). A promising approach to cross-lingual transfer of syntactic dependency parsers is to use multiple source languages and to tie model parameters across related languages. This idea was first explored for weakly supervised learning (Cohen and Smith, 2009; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010) and recently by Naseem et al. (2012) for multisource cross-lingual transfer. In particular, Naseem et al. showed that by selectively sharing parameters based on typological features of each language, substantial improvements can be achieved, compared to using a single set of parameters for all languages. However, these methods all employ generative models with strong independence assumptions and weak feature representations, which upper bounds their accuracy far below that of feature-rich discriminative parsers (McDonald et al., 2005; Nivre, 2008). In this p</context>
<context position="6572" citStr="Snyder et al., 2009" startWordPosition="971" endWordPosition="974">iple languages has been shown to benefit unsupervised learning (Cohen and Smith, 1Note that Täckström et al. (2012) and Durrett et al. (2012) do require bitext or a bilingual dictionary. The same holds for most cross-lingual representations, e.g., Klementiev et al. (2012). PUNC DOBJ PREP POBJ O TC6v 68W6E a-c&apos;v Map(a -co RLRX(o . (The) (John) (gave) (to-the) (Maria) (the) (book) . DET NOUN VERB ADP NOUN DET NOUN P Figure 1: A Greek sentence which is correctly parsed by a delexicalized English parser, provided that part-of-speech tags are available in both the source and target language. 2009; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010). Annotations in multiple languages can be combined in delexicalized transfer as well, as long as the parser features are available across the involved languages. This idea was explored by McDonald et al. (2011), who showed that target language accuracy can be improved by simply concatenating delexicalized treebanks in multiple languages. In similar work, Cohen et al. (2011) proposed a mixture model in which the parameters of a generative target language parser is expressed as a linear interpolation of source language parameters, whereas Søgaard (2011) showed</context>
</contexts>
<marker>Snyder, Naseem, Eisenstein, Barzilay, 2009</marker>
<rawString>Benjamin Snyder, Tahira Naseem, Jacob Eisenstein, and Regina Barzilay. 2009. Adding more languages improves unsupervised multilingual part-of-speech tagging: A Bayesian non-parametric approach. In Proceedings of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Søgaard</author>
<author>Julie Wulff</author>
</authors>
<title>An empirical study of non-lexical extensions to delexicalized transfer.</title>
<date>2012</date>
<booktitle>In Proceedings of COLING.</booktitle>
<contexts>
<context position="7390" citStr="Søgaard and Wulff (2012)" startWordPosition="1095" endWordPosition="1098">es. This idea was explored by McDonald et al. (2011), who showed that target language accuracy can be improved by simply concatenating delexicalized treebanks in multiple languages. In similar work, Cohen et al. (2011) proposed a mixture model in which the parameters of a generative target language parser is expressed as a linear interpolation of source language parameters, whereas Søgaard (2011) showed that target side language models can be used to selectively subsample training sentences to improve accuracy. Recently, inspired by the phylogenetic prior of Berg-Kirkpatrick and Klein (2010), Søgaard and Wulff (2012) proposed — among other ideas — a typologically informed weighting heuristic for linearly interpolating source language parameters. However, this weighting did not provide significant improvements over uniform weighting. The aforementioned approaches work well for transfer between similar languages. However, their assumptions cease to hold for typologically divergent languages; a target language can rarely be described as a linear combination of data or model parameters from a set of source languages, as languages tend to share varied typological traits; this critical insight is discussed furt</context>
</contexts>
<marker>Søgaard, Wulff, 2012</marker>
<rawString>Anders Søgaard and Julie Wulff. 2012. An empirical study of non-lexical extensions to delexicalized transfer. In Proceedings of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Søgaard</author>
</authors>
<title>Data point selection for crosslanguage adaptation of dependency parsers.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="4874" citStr="Søgaard, 2011" startWordPosition="706" endWordPosition="707"> then combined with the predictions of a different transfer parser in an ambiguity-aware ensemble-training algorithm (§5.3). The resulting parser provides significant improvements over a strong baseline parser and achieves a 13% relative error reduction on average with respect to the best model of Naseem et al. (2012), outperforming it on 15 out of the 16 evaluated languages. 2 Multi-Source Delexicalized Transfer The methods proposed in this paper fall into the delexicalized transfer approach to multilingual syntactic parsing (Zeman and Resnik, 2008; McDonald et al., 2011; Cohen et al., 2011; Søgaard, 2011). In contrast to annotation projection approaches (Yarowsky et al., 2001; Hwa et al., 2005; Ganchev et al., 2009; Spreyer and Kuhn, 2009), delexicalized transfer methods do not rely on any bitext. Instead, a parser is trained on annotations in a source language, relying solely on features that are available in both the source and the target language, such as “universal” part-ofspeech tags (Zeman and Resnik, 2008; Naseem et al., 2010; Petrov et al., 2012), cross-lingual word clusters (Täckström et al., 2012) or type-level features derived from bilingual dictionaries (Durrett et al., 2012).1 Thi</context>
<context position="7165" citStr="Søgaard (2011)" startWordPosition="1064" endWordPosition="1065">; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010). Annotations in multiple languages can be combined in delexicalized transfer as well, as long as the parser features are available across the involved languages. This idea was explored by McDonald et al. (2011), who showed that target language accuracy can be improved by simply concatenating delexicalized treebanks in multiple languages. In similar work, Cohen et al. (2011) proposed a mixture model in which the parameters of a generative target language parser is expressed as a linear interpolation of source language parameters, whereas Søgaard (2011) showed that target side language models can be used to selectively subsample training sentences to improve accuracy. Recently, inspired by the phylogenetic prior of Berg-Kirkpatrick and Klein (2010), Søgaard and Wulff (2012) proposed — among other ideas — a typologically informed weighting heuristic for linearly interpolating source language parameters. However, this weighting did not provide significant improvements over uniform weighting. The aforementioned approaches work well for transfer between similar languages. However, their assumptions cease to hold for typologically divergent langu</context>
</contexts>
<marker>Søgaard, 2011</marker>
<rawString>Anders Søgaard. 2011. Data point selection for crosslanguage adaptation of dependency parsers. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathrin Spreyer</author>
<author>Jonas Kuhn</author>
</authors>
<title>Data-driven dependency parsing of new languages using incomplete and noisy training data.</title>
<date>2009</date>
<booktitle>In Proceedings of CONLL.</booktitle>
<contexts>
<context position="5011" citStr="Spreyer and Kuhn, 2009" startWordPosition="726" endWordPosition="729"> resulting parser provides significant improvements over a strong baseline parser and achieves a 13% relative error reduction on average with respect to the best model of Naseem et al. (2012), outperforming it on 15 out of the 16 evaluated languages. 2 Multi-Source Delexicalized Transfer The methods proposed in this paper fall into the delexicalized transfer approach to multilingual syntactic parsing (Zeman and Resnik, 2008; McDonald et al., 2011; Cohen et al., 2011; Søgaard, 2011). In contrast to annotation projection approaches (Yarowsky et al., 2001; Hwa et al., 2005; Ganchev et al., 2009; Spreyer and Kuhn, 2009), delexicalized transfer methods do not rely on any bitext. Instead, a parser is trained on annotations in a source language, relying solely on features that are available in both the source and the target language, such as “universal” part-ofspeech tags (Zeman and Resnik, 2008; Naseem et al., 2010; Petrov et al., 2012), cross-lingual word clusters (Täckström et al., 2012) or type-level features derived from bilingual dictionaries (Durrett et al., 2012).1 This parser is then directly used to parse the target language. For languages with similar typology, this method can be quite accurate, espe</context>
</contexts>
<marker>Spreyer, Kuhn, 2009</marker>
<rawString>Kathrin Spreyer and Jonas Kuhn. 2009. Data-driven dependency parsing of new languages using incomplete and noisy training data. In Proceedings of CONLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar Täckström</author>
<author>Ryan McDonald</author>
<author>Jakob Uszkoreit</author>
</authors>
<title>Cross-lingual word clusters for direct transfer of linguistic structure.</title>
<date>2012</date>
<booktitle>In Proceedings of NAACL-HLT.</booktitle>
<contexts>
<context position="5386" citStr="Täckström et al., 2012" startWordPosition="786" endWordPosition="789">ltilingual syntactic parsing (Zeman and Resnik, 2008; McDonald et al., 2011; Cohen et al., 2011; Søgaard, 2011). In contrast to annotation projection approaches (Yarowsky et al., 2001; Hwa et al., 2005; Ganchev et al., 2009; Spreyer and Kuhn, 2009), delexicalized transfer methods do not rely on any bitext. Instead, a parser is trained on annotations in a source language, relying solely on features that are available in both the source and the target language, such as “universal” part-ofspeech tags (Zeman and Resnik, 2008; Naseem et al., 2010; Petrov et al., 2012), cross-lingual word clusters (Täckström et al., 2012) or type-level features derived from bilingual dictionaries (Durrett et al., 2012).1 This parser is then directly used to parse the target language. For languages with similar typology, this method can be quite accurate, especially when compared to purely unsupervised methods. For instance, a parser trained on English with only part-of-speech features can correctly parse the Greek sentence in Figure 1, even without knowledge of the lexical items since the sequence of part-of-speech tags determines the syntactic structure almost unambiguously. Learning with multiple languages has been shown to </context>
<context position="22793" citStr="Täckström et al., 2012" startWordPosition="3702" endWordPosition="3705"> features specific to the target language have been employed. Cohen et al. (2011) and Naseem et al. (2012) have shown that using expectation-maximization (EM) to this end can in some cases bring substantial accuracy gains. For discriminative models, self-training has been shown to be quite effective for adapting monolingual parsers to new domains (McClosky et al., 2006), as well as for relexicalizing delexicalized parsers using unlabeled target language data (Zeman and Resnik, 2008). Similarly Täckström (2012) used self-training to adapt a multi-source direct transfer named-entity recognizer (Täckström et al., 2012) to different target languages, “relexicalizing” the model with word cluster features. However, as discussed in §5.2, standard self-training is not optimal for target language adaptation. 5.1 Ambiguity-Aware Training In this section, we propose a related training method: ambiguity-aware training. In this setting a discriminative probabilistic model is induced from automatically inferred ambiguous labelings over unlabeled target language data, in place of gold-standard dependency trees. The ambiguous labelings can combine multiple sources of evidence to guide the estimation or simply encode the</context>
</contexts>
<marker>Täckström, McDonald, Uszkoreit, 2012</marker>
<rawString>Oscar Täckström, Ryan McDonald, and Jakob Uszkoreit. 2012. Cross-lingual word clusters for direct transfer of linguistic structure. In Proceedings of NAACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar Täckström</author>
</authors>
<title>Nudging the envelope of direct transfer methods for multilingual named entity recognition.</title>
<date>2012</date>
<booktitle>In Proceedings of the NAACL-HLT 2012 Workshop on Inducing Linguistic Structure (WILS</booktitle>
<contexts>
<context position="22685" citStr="Täckström (2012)" startWordPosition="3690" endWordPosition="3691">guistic properties of the target language have been incorporated through selective sharing, so far no features specific to the target language have been employed. Cohen et al. (2011) and Naseem et al. (2012) have shown that using expectation-maximization (EM) to this end can in some cases bring substantial accuracy gains. For discriminative models, self-training has been shown to be quite effective for adapting monolingual parsers to new domains (McClosky et al., 2006), as well as for relexicalizing delexicalized parsers using unlabeled target language data (Zeman and Resnik, 2008). Similarly Täckström (2012) used self-training to adapt a multi-source direct transfer named-entity recognizer (Täckström et al., 2012) to different target languages, “relexicalizing” the model with word cluster features. However, as discussed in §5.2, standard self-training is not optimal for target language adaptation. 5.1 Ambiguity-Aware Training In this section, we propose a related training method: ambiguity-aware training. In this setting a discriminative probabilistic model is induced from automatically inferred ambiguous labelings over unlabeled target language data, in place of gold-standard dependency trees. T</context>
</contexts>
<marker>Täckström, 2012</marker>
<rawString>Oscar Täckström. 2012. Nudging the envelope of direct transfer methods for multilingual named entity recognition. In Proceedings of the NAACL-HLT 2012 Workshop on Inducing Linguistic Structure (WILS 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
<author>Grace Ngai</author>
<author>Richard Wicentowski</author>
</authors>
<title>Inducing multilingual text analysis tools via robust projection across aligned corpora. In</title>
<date>2001</date>
<booktitle>Proceedings of HLT.</booktitle>
<contexts>
<context position="1606" citStr="Yarowsky et al., 2001" startWordPosition="221" endWordPosition="224">redictions from multiple transfer parsers in an ensemble-training algorithm. Our final model outperforms the state of the art in multi-source transfer parsing on 15 out of 16 evaluated languages. 1 Introduction Many languages still lack access to core NLP tools, such as part-of-speech taggers and syntactic parsers. This is largely due to the reliance on fully supervised learning methods, which require large quantities of manually annotated training data. Recently, methods for cross-lingual transfer have appeared as a promising avenue for overcoming this hurdle for both part-of-speech tagging (Yarowsky et al., 2001; Das and Petrov, 2011) and syntactic dependency parsing (Hwa et al., 2005; Zeman and Resnik, 2008; Ganchev et al., 2009; McDonald et al., 2011; Naseem et al., * Work primarily carried out while at Google, NY. 2012). While these methods do not yet compete with fully supervised approaches, they can drastically outperform both unsupervised methods (Klein and Manning, 2004) and weakly supervised methods (Naseem et al., 2010; Berg-Kirkpatrick and Klein, 2010). A promising approach to cross-lingual transfer of syntactic dependency parsers is to use multiple source languages and to tie model paramet</context>
<context position="4946" citStr="Yarowsky et al., 2001" startWordPosition="714" endWordPosition="717">r in an ambiguity-aware ensemble-training algorithm (§5.3). The resulting parser provides significant improvements over a strong baseline parser and achieves a 13% relative error reduction on average with respect to the best model of Naseem et al. (2012), outperforming it on 15 out of the 16 evaluated languages. 2 Multi-Source Delexicalized Transfer The methods proposed in this paper fall into the delexicalized transfer approach to multilingual syntactic parsing (Zeman and Resnik, 2008; McDonald et al., 2011; Cohen et al., 2011; Søgaard, 2011). In contrast to annotation projection approaches (Yarowsky et al., 2001; Hwa et al., 2005; Ganchev et al., 2009; Spreyer and Kuhn, 2009), delexicalized transfer methods do not rely on any bitext. Instead, a parser is trained on annotations in a source language, relying solely on features that are available in both the source and the target language, such as “universal” part-ofspeech tags (Zeman and Resnik, 2008; Naseem et al., 2010; Petrov et al., 2012), cross-lingual word clusters (Täckström et al., 2012) or type-level features derived from bilingual dictionaries (Durrett et al., 2012).1 This parser is then directly used to parse the target language. For languag</context>
</contexts>
<marker>Yarowsky, Ngai, Wicentowski, 2001</marker>
<rawString>David Yarowsky, Grace Ngai, and Richard Wicentowski. 2001. Inducing multilingual text analysis tools via robust projection across aligned corpora. In Proceedings of HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Zeman</author>
<author>Philip Resnik</author>
</authors>
<title>Cross-language parser adaptation between related languages.</title>
<date>2008</date>
<booktitle>In IJCNLP Workshop: NLP for Less Privileged Languages.</booktitle>
<contexts>
<context position="1704" citStr="Zeman and Resnik, 2008" startWordPosition="237" endWordPosition="240">erforms the state of the art in multi-source transfer parsing on 15 out of 16 evaluated languages. 1 Introduction Many languages still lack access to core NLP tools, such as part-of-speech taggers and syntactic parsers. This is largely due to the reliance on fully supervised learning methods, which require large quantities of manually annotated training data. Recently, methods for cross-lingual transfer have appeared as a promising avenue for overcoming this hurdle for both part-of-speech tagging (Yarowsky et al., 2001; Das and Petrov, 2011) and syntactic dependency parsing (Hwa et al., 2005; Zeman and Resnik, 2008; Ganchev et al., 2009; McDonald et al., 2011; Naseem et al., * Work primarily carried out while at Google, NY. 2012). While these methods do not yet compete with fully supervised approaches, they can drastically outperform both unsupervised methods (Klein and Manning, 2004) and weakly supervised methods (Naseem et al., 2010; Berg-Kirkpatrick and Klein, 2010). A promising approach to cross-lingual transfer of syntactic dependency parsers is to use multiple source languages and to tie model parameters across related languages. This idea was first explored for weakly supervised learning (Cohen a</context>
<context position="4815" citStr="Zeman and Resnik, 2008" startWordPosition="694" endWordPosition="697"> ambiguity-aware self-training algorithm (§5.2); these arc sets are then combined with the predictions of a different transfer parser in an ambiguity-aware ensemble-training algorithm (§5.3). The resulting parser provides significant improvements over a strong baseline parser and achieves a 13% relative error reduction on average with respect to the best model of Naseem et al. (2012), outperforming it on 15 out of the 16 evaluated languages. 2 Multi-Source Delexicalized Transfer The methods proposed in this paper fall into the delexicalized transfer approach to multilingual syntactic parsing (Zeman and Resnik, 2008; McDonald et al., 2011; Cohen et al., 2011; Søgaard, 2011). In contrast to annotation projection approaches (Yarowsky et al., 2001; Hwa et al., 2005; Ganchev et al., 2009; Spreyer and Kuhn, 2009), delexicalized transfer methods do not rely on any bitext. Instead, a parser is trained on annotations in a source language, relying solely on features that are available in both the source and the target language, such as “universal” part-ofspeech tags (Zeman and Resnik, 2008; Naseem et al., 2010; Petrov et al., 2012), cross-lingual word clusters (Täckström et al., 2012) or type-level features deriv</context>
<context position="22657" citStr="Zeman and Resnik, 2008" startWordPosition="3684" endWordPosition="3687">ptation While some higher-level linguistic properties of the target language have been incorporated through selective sharing, so far no features specific to the target language have been employed. Cohen et al. (2011) and Naseem et al. (2012) have shown that using expectation-maximization (EM) to this end can in some cases bring substantial accuracy gains. For discriminative models, self-training has been shown to be quite effective for adapting monolingual parsers to new domains (McClosky et al., 2006), as well as for relexicalizing delexicalized parsers using unlabeled target language data (Zeman and Resnik, 2008). Similarly Täckström (2012) used self-training to adapt a multi-source direct transfer named-entity recognizer (Täckström et al., 2012) to different target languages, “relexicalizing” the model with word cluster features. However, as discussed in §5.2, standard self-training is not optimal for target language adaptation. 5.1 Ambiguity-Aware Training In this section, we propose a related training method: ambiguity-aware training. In this setting a discriminative probabilistic model is induced from automatically inferred ambiguous labelings over unlabeled target language data, in place of gold-</context>
</contexts>
<marker>Zeman, Resnik, 2008</marker>
<rawString>Daniel Zeman and Philip Resnik. 2008. Cross-language parser adaptation between related languages. In IJCNLP Workshop: NLP for Less Privileged Languages.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>