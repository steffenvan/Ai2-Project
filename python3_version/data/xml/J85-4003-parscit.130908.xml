<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.038167">
<sectionHeader confidence="0.5286225" genericHeader="abstract">
TECHNICAL CORRESPONDENCE
THE CONCEPT OF SUPERAUTOMATON
</sectionHeader>
<bodyText confidence="0.999437888888889">
A recent review of my book The Logic of Mind in this
journal refers to the key idea of the book, that of a
superautomaton, as a &amp;quot;Moore machine&amp;quot;. However,
none of the central arguments of the book go through
for Moore Machines. This note presents a sketch of
the correct construction.
In his review of The Logic of Mind (Nelson 1982) in this
journal (Vol. 11, no. 1), David Israel correctly identifies
the idea of superautomaton as the key theoretical tool I
use in attempting to explicate intentional terms of
psychology such as take, expectation, and belief. Howev-
er, his characterization of a superautomaton as a variety
of Moore machine (Moore 1956) is very misleading.
Inasmuch as the concept is central to the main argument
of the book, I would like to describe it here in enough
detail to cover the idea I really intended.
I specify, but do not offer a design or model of, an
executive Turing machine T&apos; that (a) comprehends a
finite number of finite automata connected in parallel,
which it monitors; (b) has access to a stored encoded
table representing the transition functions of each
component automaton T; (c) includes means for deciding
whether a given state of a component automaton can
reach a final state. This complex device T&apos; is a
&amp;quot;superautomaton&amp;quot;.
The way it works is this. If an input string x to a
component automaton T includes undefined (vague,
degraded, or unclear) symbols u, then when T reach u it
ceases processing. T&apos; decides whether there is a string y
that could drive T to a final state. If not, it rejects x as
not acceptable to T. If there is a string, T&apos; consults the
table of T and determines by random choice a symbol s
defined for T that drives T to a state for which there is a
string leading to a final state. Then the undefined
symbol u is taken to be s, and the computation of the
string x continues.
Given the indicated resources T&apos; can take ill-defined,
fuzzy input to be such as to satisfy expectations of the
system. &amp;quot;Expectation&amp;quot; as well as other intentional
concepts at the perceptual level are all analyzable in
terms of ordinary logic operations, the indicated
construction of T&apos;, and standard mathematical machine
theory.
(c) is equivalent to means for solving the halting prob-
lem; this entails that the component automata (which
could be as complex as pushdown automata) must be less
than full Turing machines, for which the halting problem
is recursively unsolvable. It also entails that the execu-
tive part of T&apos; must be, in terms of competence, a two-
way tape Turing machine, not a Moore machine. (In
terms of performance, of course, one would be limited in
the real world to Turing machines that are approximated
by brains or digital computers, i.e., by finite sequential
machines; but this is of little theoretical moment.)
Beyond the specification (a)—(c) and a program-like
description of the function of T&apos; (Nelson 1976), I do not
pretend to know what T&apos; would look like. By the recur-
sion theorem of mathematical logic (Rogers 1967), some
such thing must exist — i.e., there are self-describing
Turing machines. There are also concrete analogous
instances, i.e., generic codes.
I think this kind of idea is significantly relevant to
computational theory and cognitive science, not just to
the concerns of my book (which is meant to be a philo-
sophical argument for the plausibility of computationalist
theories of mind and cognition), but also to the very
pervasive current employment of self-reference in cogni-
tive science and artificial intelligence. My version, of
course, is not strictly new as it is an adaptation of the
insights of others (Lee 1963, von Neumann 1966), all of
which stem from Goedel&apos;s work (1931) on the incom-
pleteness of arithmetic.
</bodyText>
<note confidence="0.650903">
R. J. Nelson
</note>
<reference confidence="0.609910333333333">
Department of Philosophy
Case Western Reserve University
Cleveland, OH 44106
</reference>
<sectionHeader confidence="0.66515" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.97862695">
Goedel, Kurt 1931 Uber Formal Unentscheidbare Satze der Principia
Mathematica und Verwandter Systeme I. Monatsheft fur Mathema-
tik und Physik 38: 173-198.
Lee, C.Y. 1963 A Turing Machine which Prints its own Code Script.
In Fox, Jerome, Ed., Proceedings of the Symposium on Mathematical
Theory of Automata. Brooklyn Polytechnic Press, Brooklyn, New
York: 155-164.
Moore, E.F. 1956 Gedanken Experiments on Sequential Machines. In
Shannon, Claude E. and McCarthy, John, Eds., Automata Studies.
Princeton Press, Princeton, New Jersey: 129-153.
Nelson, R.J. 1976 On Mechanical Recognition. Philosophy of Science
43(1): 24-52.
Nelson, R.J. 1982 The Logic of Mind. D. Reidel Publishing Co.,
Dordrecht, Holland.
Rogers, H. Jr. 1967 Theory of Recursive Functions and Effective
Computability. McGraw-Hill Book Company, New York, New
York.
von Neumann, J. 1966 Theory of Self-Reproducing Automata. (Burks,
Arthurs W., Ed.) University of Illinois Press, Urbana, Illinois.
Computational Linguistics, Volume 11, Number 4, October-December 1985 243
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.036821">
<title confidence="0.9565525">TECHNICAL CORRESPONDENCE THE CONCEPT OF SUPERAUTOMATON</title>
<abstract confidence="0.995119506849315">recent review of my book Logic of Mind this journal refers to the key idea of the book, that of a superautomaton, as a &amp;quot;Moore machine&amp;quot;. However, none of the central arguments of the book go through for Moore Machines. This note presents a sketch of the correct construction. his review of Logic of Mind 1982) in this journal (Vol. 11, no. 1), David Israel correctly identifies the idea of superautomaton as the key theoretical tool I use in attempting to explicate intentional terms of such as expectation, However, his characterization of a superautomaton as a variety of Moore machine (Moore 1956) is very misleading. Inasmuch as the concept is central to the main argument of the book, I would like to describe it here in enough detail to cover the idea I really intended. I specify, but do not offer a design or model of, an executive Turing machine T&apos; that (a) comprehends a finite number of finite automata connected in parallel, which it monitors; (b) has access to a stored encoded table representing the transition functions of each component automaton T; (c) includes means for deciding whether a given state of a component automaton can reach a final state. This complex device T&apos; is a &amp;quot;superautomaton&amp;quot;. The way it works is this. If an input string x to a component automaton T includes undefined (vague, or unclear) symbols when T reach ceases processing. T&apos; decides whether there is a string y that could drive T to a final state. If not, it rejects x as acceptable to there is a string, T&apos; consults the of T and determines by random choice a symbol defined for T that drives T to a state for which there is a string leading to a final state. Then the undefined be the computation of the string x continues. the indicated resources T&apos; can input to be such as to satisfy the system. &amp;quot;Expectation&amp;quot; as well as other intentional concepts at the perceptual level are all analyzable in terms of ordinary logic operations, the indicated construction of T&apos;, and standard mathematical machine theory. (c) is equivalent to means for solving the halting problem; this entails that the component automata (which could be as complex as pushdown automata) must be less than full Turing machines, for which the halting problem is recursively unsolvable. It also entails that the executive part of T&apos; must be, in terms of competence, a twoway tape Turing machine, not a Moore machine. (In of course, one would be limited in the real world to Turing machines that are approximated by brains or digital computers, i.e., by finite sequential machines; but this is of little theoretical moment.) Beyond the specification (a)—(c) and a program-like description of the function of T&apos; (Nelson 1976), I do not pretend to know what T&apos; would look like. By the recursion theorem of mathematical logic (Rogers 1967), some such thing must exist — i.e., there are self-describing Turing machines. There are also concrete analogous instances, i.e., generic codes. I think this kind of idea is significantly relevant to computational theory and cognitive science, not just to the concerns of my book (which is meant to be a philosophical argument for the plausibility of computationalist theories of mind and cognition), but also to the very current employment of cognitive science and artificial intelligence. My version, of course, is not strictly new as it is an adaptation of the insights of others (Lee 1963, von Neumann 1966), all of which stem from Goedel&apos;s work (1931) on the incompleteness of arithmetic. J.</abstract>
<affiliation confidence="0.9737115">Department of Philosophy Case Western Reserve University</affiliation>
<address confidence="0.999698">Cleveland, OH 44106</address>
<note confidence="0.791492095238095">REFERENCES Goedel, Kurt 1931 Uber Formal Unentscheidbare Satze der Principia und Verwandter Systeme I. fur Mathemaund Physik 173-198. Lee, C.Y. 1963 A Turing Machine which Prints its own Code Script. Fox, Jerome, Ed., of the Symposium on Mathematical of Automata. Polytechnic Press, Brooklyn, New York: 155-164. Moore, E.F. 1956 Gedanken Experiments on Sequential Machines. In Claude E. and McCarthy, John, Eds., Studies. Princeton Press, Princeton, New Jersey: 129-153. R.J. 1976 On Mechanical Recognition. of Science 43(1): 24-52. R.J. 1982 Logic of Mind. Reidel Publishing Co., Dordrecht, Holland. H. Jr. 1967 of Recursive Functions and Effective Book Company, New York, New York. Neumann, J. 1966 of Self-Reproducing Automata. Arthurs W., Ed.) University of Illinois Press, Urbana, Illinois. Computational Linguistics, Volume 11, Number 4, October-December 1985 243</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<pages>44106</pages>
<institution>Department of Philosophy Case Western Reserve University</institution>
<location>Cleveland, OH</location>
<marker></marker>
<rawString>Department of Philosophy Case Western Reserve University Cleveland, OH 44106</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kurt Goedel</author>
</authors>
<title>Uber Formal Unentscheidbare Satze der</title>
<date>1931</date>
<booktitle>Principia Mathematica und Verwandter Systeme I. Monatsheft fur Mathematik und Physik</booktitle>
<volume>38</volume>
<pages>173--198</pages>
<marker>Goedel, 1931</marker>
<rawString>Goedel, Kurt 1931 Uber Formal Unentscheidbare Satze der Principia Mathematica und Verwandter Systeme I. Monatsheft fur Mathematik und Physik 38: 173-198.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Y Lee</author>
</authors>
<title>A Turing Machine which Prints its own Code Script.</title>
<date>1963</date>
<booktitle>In Fox, Jerome, Ed., Proceedings of the Symposium on Mathematical Theory of Automata. Brooklyn</booktitle>
<pages>155--164</pages>
<publisher>Polytechnic Press,</publisher>
<location>Brooklyn, New York:</location>
<marker>Lee, 1963</marker>
<rawString>Lee, C.Y. 1963 A Turing Machine which Prints its own Code Script. In Fox, Jerome, Ed., Proceedings of the Symposium on Mathematical Theory of Automata. Brooklyn Polytechnic Press, Brooklyn, New York: 155-164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E F Moore</author>
</authors>
<title>Gedanken Experiments on Sequential Machines. In</title>
<date>1956</date>
<pages>129--153</pages>
<publisher>Princeton Press,</publisher>
<location>Princeton, New Jersey:</location>
<contexts>
<context position="707" citStr="Moore 1956" startWordPosition="117" endWordPosition="118">ind in this journal refers to the key idea of the book, that of a superautomaton, as a &amp;quot;Moore machine&amp;quot;. However, none of the central arguments of the book go through for Moore Machines. This note presents a sketch of the correct construction. In his review of The Logic of Mind (Nelson 1982) in this journal (Vol. 11, no. 1), David Israel correctly identifies the idea of superautomaton as the key theoretical tool I use in attempting to explicate intentional terms of psychology such as take, expectation, and belief. However, his characterization of a superautomaton as a variety of Moore machine (Moore 1956) is very misleading. Inasmuch as the concept is central to the main argument of the book, I would like to describe it here in enough detail to cover the idea I really intended. I specify, but do not offer a design or model of, an executive Turing machine T&apos; that (a) comprehends a finite number of finite automata connected in parallel, which it monitors; (b) has access to a stored encoded table representing the transition functions of each component automaton T; (c) includes means for deciding whether a given state of a component automaton can reach a final state. This complex device T&apos; is a &amp;quot;s</context>
</contexts>
<marker>Moore, 1956</marker>
<rawString>Moore, E.F. 1956 Gedanken Experiments on Sequential Machines. In Shannon, Claude E. and McCarthy, John, Eds., Automata Studies. Princeton Press, Princeton, New Jersey: 129-153.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R J Nelson</author>
</authors>
<title>On Mechanical Recognition.</title>
<date>1976</date>
<journal>Philosophy of Science</journal>
<volume>43</volume>
<issue>1</issue>
<pages>24--52</pages>
<contexts>
<context position="2933" citStr="Nelson 1976" startWordPosition="506" endWordPosition="507">utomata (which could be as complex as pushdown automata) must be less than full Turing machines, for which the halting problem is recursively unsolvable. It also entails that the executive part of T&apos; must be, in terms of competence, a twoway tape Turing machine, not a Moore machine. (In terms of performance, of course, one would be limited in the real world to Turing machines that are approximated by brains or digital computers, i.e., by finite sequential machines; but this is of little theoretical moment.) Beyond the specification (a)—(c) and a program-like description of the function of T&apos; (Nelson 1976), I do not pretend to know what T&apos; would look like. By the recursion theorem of mathematical logic (Rogers 1967), some such thing must exist — i.e., there are self-describing Turing machines. There are also concrete analogous instances, i.e., generic codes. I think this kind of idea is significantly relevant to computational theory and cognitive science, not just to the concerns of my book (which is meant to be a philosophical argument for the plausibility of computationalist theories of mind and cognition), but also to the very pervasive current employment of self-reference in cognitive scien</context>
</contexts>
<marker>Nelson, 1976</marker>
<rawString>Nelson, R.J. 1976 On Mechanical Recognition. Philosophy of Science 43(1): 24-52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R J Nelson</author>
</authors>
<title>The Logic of Mind.</title>
<date>1982</date>
<publisher>D. Reidel Publishing Co.,</publisher>
<location>Dordrecht, Holland.</location>
<marker>Nelson, 1982</marker>
<rawString>Nelson, R.J. 1982 The Logic of Mind. D. Reidel Publishing Co., Dordrecht, Holland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Jr Rogers</author>
</authors>
<title>Theory of Recursive Functions and Effective Computability.</title>
<date>1967</date>
<publisher>McGraw-Hill Book Company,</publisher>
<location>New York, New York.</location>
<contexts>
<context position="3045" citStr="Rogers 1967" startWordPosition="527" endWordPosition="528">alting problem is recursively unsolvable. It also entails that the executive part of T&apos; must be, in terms of competence, a twoway tape Turing machine, not a Moore machine. (In terms of performance, of course, one would be limited in the real world to Turing machines that are approximated by brains or digital computers, i.e., by finite sequential machines; but this is of little theoretical moment.) Beyond the specification (a)—(c) and a program-like description of the function of T&apos; (Nelson 1976), I do not pretend to know what T&apos; would look like. By the recursion theorem of mathematical logic (Rogers 1967), some such thing must exist — i.e., there are self-describing Turing machines. There are also concrete analogous instances, i.e., generic codes. I think this kind of idea is significantly relevant to computational theory and cognitive science, not just to the concerns of my book (which is meant to be a philosophical argument for the plausibility of computationalist theories of mind and cognition), but also to the very pervasive current employment of self-reference in cognitive science and artificial intelligence. My version, of course, is not strictly new as it is an adaptation of the insight</context>
</contexts>
<marker>Rogers, 1967</marker>
<rawString>Rogers, H. Jr. 1967 Theory of Recursive Functions and Effective Computability. McGraw-Hill Book Company, New York, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J von Neumann</author>
</authors>
<title>Theory of Self-Reproducing Automata.</title>
<date>1966</date>
<institution>W., Ed.) University of Illinois Press,</institution>
<location>Burks, Arthurs</location>
<marker>von Neumann, 1966</marker>
<rawString>von Neumann, J. 1966 Theory of Self-Reproducing Automata. (Burks, Arthurs W., Ed.) University of Illinois Press, Urbana, Illinois.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Computational Linguistics</author>
</authors>
<date>1985</date>
<volume>11</volume>
<pages>243</pages>
<marker>Linguistics, 1985</marker>
<rawString>Computational Linguistics, Volume 11, Number 4, October-December 1985 243</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>