<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.027680">
<title confidence="0.9973885">
Grammar Error Correction
Using Pseudo-Error Sentences and Domain Adaptation
</title>
<author confidence="0.908647">
Kenji Imamura, Kuniko Saito, Kugatsu Sadamitsu, and Hitoshi Nishikawa
</author>
<affiliation confidence="0.745024">
NTT Cyber Space Laboratories, NTT Corporation
</affiliation>
<address confidence="0.8507295">
1-1 Hikari-no-oka, Yokosuka, 239-0847, Japan
imamura.kenj i, saito.kuniko
</address>
<email confidence="0.996983">
sadamitsu.kugatsu, nishikawa.hitoshi @lab.ntt.co.jp}
</email>
<sectionHeader confidence="0.99737" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999515642857143">
This paper presents grammar error correction
for Japanese particles that uses discrimina-
tive sequence conversion, which corrects erro-
neous particles by substitution, insertion, and
deletion. The error correction task is hindered
by the difficulty of collecting large error cor-
pora. We tackle this problem by using pseudo-
error sentences generated automatically. Fur-
thermore, we apply domain adaptation, the
pseudo-error sentences are from the source
domain, and the real-error sentences are from
the target domain. Experiments show that sta-
ble improvement is achieved by using domain
adaptation.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.996774853658536">
Case marks of a sentence are represented by postpo-
sitional particles in Japanese. Incorrect usage of the
particles causes serious communication errors be-
cause the cases become unclear. For example, in
the following sentence, it is unclear what must be
deleted.
mail o todoi tara sakujo onegai-shi-masu
mail ACC. arrive when delete please
“When φ has arrived an e-mail, please delete it.”
If the accusative particle o is replaced by a nomi-
native one ga, it becomes clear that the writer wants
to delete the e-mail (“When the e-mail has arrived,
please delete it.”). Such particle errors frequently
occur in sentences written by non-native Japanese
speakers.
This paper presents a method that can automat-
ically correct Japanese particle errors. This task
corresponds to preposition/article error correction in
English. For English error correction, many stud-
ies employ classifiers, which select the appropriate
prepositions/articles, by restricting the error types
to articles and frequent prepositions (Gamon, 2010;
Han et al., 2010; Rozovskaya and Roth, 2011).
On the contrary, Mizumoto et al. (2011) proposed
translator-based error correction. This approach can
handle all error types by converting the learner’s
sentences into the correct ones. Although the target
of this paper is particle error, we employ a similar
approach based on sequence conversion (Imamura
et al., 2011) since this offers excellent scalability.
The conversion approach requires pairs of the
learner’s and the correct sentences. However, col-
lecting a sufficient number of pairs is expensive. To
avoid this problem, we use additional corpus con-
sisting of pseudo-error sentences automatically gen-
erated from correct sentences that mimic the real-
errors (Rozovskaya and Roth, 2010b). Furthermore,
we apply a domain adaptation technique that re-
gards the pseudo-errors and the real-errors as the
source and the target domain, respectively, so that
the pseudo-errors better match the real-errors.
</bodyText>
<sectionHeader confidence="0.996407" genericHeader="method">
2 Error Correction by Discriminative
</sectionHeader>
<subsectionHeader confidence="0.665275">
Sequence Conversion
</subsectionHeader>
<bodyText confidence="0.992144875">
We start by describing discriminative sequence con-
version. Our error correction method converts the
learner’s word sequences into the correct sequences.
Our method is similar to phrase-based statistical ma-
chine translation (PBSMT), but there are three dif-
ferences; 1) it adopts the conditional random fields,
2) it allows insertion and deletion, and 3) binary and
real features are combined. Unlike the classification
</bodyText>
<page confidence="0.984062">
388
</page>
<note confidence="0.8344235">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 388–392,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<table confidence="0.994809">
Incorrect Particle Correct Particle Note
φ no/POSS. INS
φ o/ACC. INS
ga/NOM. o/ACC. SUB
o/ACC. ni/DAT. SUB
o/ACC. ga/NOM. SUB
wa/TOP. o/ACC. SUB
no/POSS. φ DEL
: :
</table>
<tableCaption confidence="0.999933">
Table 1: Example of Phrase Table (partial)
</tableCaption>
<bodyText confidence="0.594522">
approach, the conversion approach can correct mul-
tiple errors of all types in a sentence.
</bodyText>
<subsectionHeader confidence="0.986566">
2.1 Basic Procedure
</subsectionHeader>
<bodyText confidence="0.9999318">
We apply the morpheme conversion approach that
converts the results of a speech recognizer into word
sequences for language analyzer processing (Ima-
mura et al., 2011). It corrects particle errors in the
input sentences as follows.
</bodyText>
<listItem confidence="0.98475685">
• First, all modification candidates are obtained by
referring to a phrase table. This table, called the
confusion set (Rozovskaya and Roth, 2010a) in
the error correction task, stores pairs of incorrect
and correct particles (Table 1). The candidates are
packed into a lattice structure, called the phrase
lattice (Figure 1). To deal with unchanged words,
it also copies the input words and inserts them into
the phrase lattice.
• Next, the best phrase sequence in the phrase lat-
tice is identified based on the conditional random
fields (CRFs (Lafferty et al., 2001)). The Viterbi
algorithm is applied to the decoding because error
correction does not change the word order.
• While training, word alignment is carried out by
dynamic programming matching. From the align-
ment results, the phrase table is constructed by ac-
quiring particle errors, and the CRF models are
trained using the alignment results as supervised
data.
</listItem>
<subsectionHeader confidence="0.994813">
2.2 Insertion / Deletion
</subsectionHeader>
<bodyText confidence="0.9999168">
Since an insertion can be regarded as replacing an
empty word with an actual word, and deletion is the
replacement of an actual word with an empty one,
we treat these operations as substitution without dis-
tinction while learning/applying the CRF models.
</bodyText>
<figureCaption confidence="0.999738">
Figure 1: Example of Phrase Lattice
</figureCaption>
<bodyText confidence="0.99953275">
However, insertion is a high cost operation be-
cause it may occur at any location and can cause
lattice size to explode. To avoid this problem, we
permit insertion only immediately after nouns.
</bodyText>
<subsectionHeader confidence="0.938335">
2.3 Features
</subsectionHeader>
<bodyText confidence="0.999680388888889">
In this paper, we use mapping features and link fea-
tures. The former measure the correspondence be-
tween input and output words (similar to the trans-
lation models of PBSMT). The latter measure the
fluency of the output word sequence (similar to lan-
guage models).
The mapping features are all binary. The focusing
phrase and its two surrounding words of the input
are regarded as the window. The mapping features
are defined as the pairs of the output phrase and 1-,
2-, and 3-grams in the window.
The link features are important for the error cor-
rection task because the system has to judge output
correctness. Fortunately, CRF, which is a kind of
discriminative model, can handle features that de-
pend on each other; we mix two types of features
as follows and optimize their weights in the CRF
framework.
</bodyText>
<listItem confidence="0.965985545454545">
• N-gram features: N-grams of the output words,
from 1 to 3, are used as binary features. These
are obtained from a training corpus (paired sen-
tences). Since the feature weights are optimized
considering the entire feature space, fine-tuning
can be achieved. The accuracy becomes almost
perfect on the training corpus.
• Language model probability: This is a logarith-
mic value (real value) of the n-gram probability
of the output word sequence. One feature weight
is assigned. The n-gram language model can be
</listItem>
<figure confidence="0.98993868">
mail o todoi
In�ut WOrds tara
now ACC. verb PART
mail
now
COPY COpY COPY
COPY INS SUB
no
POss.
o
ACC.
ga
NOM.
o
ACC.
ni
DAT.
todoi
verb
tara
PART
Incorrect Particle
&lt;s&gt;
Phrase �
Latt�Ce
</figure>
<page confidence="0.993065">
389
</page>
<bodyText confidence="0.998073714285714">
constructed from a large sentence set because it
does not need the learner’s sentences.
Incorporating binary and real features yields a
rough approximation of generative models in semi-
supervised CRFs (Suzuki and Isozaki, 2008). It can
appropriately correct new sentences while maintain-
ing high accuracy on the training corpus.
</bodyText>
<sectionHeader confidence="0.997921" genericHeader="method">
3 Pseudo-error Sentences and Domain
Adaptation
</sectionHeader>
<bodyText confidence="0.999849">
The error corrector described in Section 2 requires
paired sentences. However, it is expensive to col-
lect them. We resolve this problem by using pseudo-
error sentences and domain adaptation.
</bodyText>
<subsectionHeader confidence="0.967309">
3.1 Pseudo-Error Generation
</subsectionHeader>
<bodyText confidence="0.9999234">
Correct sentences, which are halves of the paired
sentences, can be easily acquired from corpora such
as newspaper articles. Pseudo-errors are generated
from them by the substitution, insertion, and dele-
tion functions according to the desired error pat-
terns.
We utilize the method of Rozovskaya and Roth
(2010b). Namely, when particles appear in the cor-
rect sentence, they are replaced by incorrect ones in
a probabilistic manner by applying the phrase table
(which stores the error patterns) in the opposite di-
rection. The error generation probabilities are rel-
ative frequencies on the training corpus. The mod-
els are learnt using both the training corpus and the
pseudo-error sentences.
</bodyText>
<subsectionHeader confidence="0.99984">
3.2 Adaptation by Feature Augmentation
</subsectionHeader>
<bodyText confidence="0.999756">
Although the error generation probabilities are com-
puted from the real-error corpus, the error distribu-
tion that results may be inappropriate. To better fit
the pseudo-errors to the real-errors, we apply a do-
main adaptation technique. Namely, we regard the
pseudo-error corpus as the source domain and the
real-error corpus as the target domain, and models
are learnt that fit the target domain.
In this paper, we use Daume (2007)’s feature aug-
mentation method for the domain adaptation, which
eliminates the need to change the learning algo-
rithm. This method regards the models for the
source domain as the prior distribution and learns
the models for the target domain.
</bodyText>
<table confidence="0.81838675">
Feature Space
Common Source Target
DS DS 0
Dt 0 Dt
</table>
<figureCaption confidence="0.962394">
Figure 2: Feature Augmentation
</figureCaption>
<bodyText confidence="0.999989869565217">
We briefly review feature augmentation. The fea-
ture space is segmented into three parts: common,
source, and target. The features extracted from the
source domain data are deployed to the common
and the source spaces, and those from the target do-
main data are deployed to the common and the target
spaces. Namely, the feature space is tripled (Figure
2).
The parameter estimation is carried out in the
usual way on the above feature space. Consequently,
the weights of the common features are emphasized
if the features are consistent between the source and
the target. With regard to domain dependent fea-
tures, the weights in the source or the target space
are emphasized.
Error correction uses only the features in the com-
mon and target spaces. The error distribution ap-
proaches that of the real-errors because the weights
of features are optimized to the target domain. In ad-
dition, it becomes robust against new sentences be-
cause the common features acquired from the source
domain can be used even when they do not appear in
the target domain.
</bodyText>
<sectionHeader confidence="0.999948" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.999141">
4.1 Experimental Settings
</subsectionHeader>
<bodyText confidence="0.968887692307692">
Real-error Corpus: We collected learner’s sen-
tences written by Chinese native speakers. The sen-
tences were created from English Linux manuals
and figures, and Japanese native speakers revised
them. From these sentences, only particle errors
were retained; the other errors were corrected. As
a result, we obtained 2,770 paired sentences. The
number of incorrect particles was 1,087 (8.0%) of
13,534. Note that most particles did not need to be
revised. The number of pair types of incorrect parti-
cles and their correct ones was 132.
Language Model: It was constructed from
Japanese Wikipedia articles about computers and
</bodyText>
<figure confidence="0.993025878787879">
Source Data
Target Data
390
1
0.9
0.8
0.7
0.6
.
0.5
0.4
0.3
TRG
SRC
ALL
AUG
0 0.05 0.1 0.15 0.2 0.25
Recall Rate
0.0 0.5 1.0 1.5 2.0
Error Generation Probability
(Magnification)
Precision Rate
TRG
SRC
ALL
AUG
+100
+50
0
Relative Improvement
-50
-100
-150
</figure>
<figureCaption confidence="0.9992645">
Figure 3: Recall/Precision Curve (Error Generation Mag-
nification is 1.0)
</figureCaption>
<bodyText confidence="0.999041666666667">
Japanese Linux manuals, 527,151 sentences in total.
SRILM (Stolcke et al., 2011) was used to train a
trigram model.
Pseudo-error Corpus: The pseudo-errors were
generated using 10,000 sentences randomly selected
from the corpus for the language model. The mag-
nification of the error generation probabilities was
changed from 0.0 (i.e., no errors) to 2.0 (the relative
frequency in the real-error corpus was taken as 1.0).
Evaluation Metrics: Five-fold cross-validation
on the real-error corpus was used. We used two met-
rics: 1) Precision and recall rates of the error correc-
tion by the systems, and 2) Relative improvement,
the number of differences between improved and de-
graded particles in the output sentences (no changes
were ignored). This is a practical metric because it
denotes the number of particles that human rewriters
do not need to revise after the system correction.
</bodyText>
<subsectionHeader confidence="0.676329">
4.2 Results
</subsectionHeader>
<bodyText confidence="0.967774333333333">
Figure 3 plots the precision/recall curves for the fol-
lowing four combinations of training corpora and
method.
</bodyText>
<listItem confidence="0.997387">
• TRG: The models were trained using only the
real-error corpus (baseline).
• SRC: Trained using only the pseudo-error corpus.
• ALL: Trained using the real-error and pseudo-
error corpora by simply adding them.
• AUG:
</listItem>
<bodyText confidence="0.9991445">
The proposed method. The feature augmentation
was realized by regarding the pseudo-errors as the
</bodyText>
<figureCaption confidence="0.986303">
Figure 4: Relative Improvement among Error Generation
Probabilities
</figureCaption>
<bodyText confidence="0.999727304347826">
source domain and the real-errors as the target do-
main.
The SRC case, which uses only the pseudo-error
sentences, did not match the precision of TRG. The
ALL case matched the precision of TRG at high
recall rates. AUG, the proposed method, achieved
higher precision than TRG at high recall rates. At
the recall rate of 18%, the precision rate of AUG was
55.4%; in contrast, that of TRG was 50.5%. Fea-
ture augmentation effectively leverages the pseudo-
errors for error correction.
Figure 4 shows the relative improvement of each
method according to the error generation probabil-
ities. In this experiment, ALL achieved higher im-
provement than TRG at error generation probabili-
ties ranging from 0.0 to 0.6. Although the improve-
ments were high, we have to control the error gen-
eration probability because the improvements in the
SRC case fell as the magnification was raised. On
the other hand, AUG achieved stable improvement
regardless of the error generation probability. We
can conclude that domain adaptation to the pseudo-
error sentences is the preferred approach.
</bodyText>
<sectionHeader confidence="0.999512" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.9999565">
This paper presented an error correction method of
Japanese particles that uses pseudo-error generation.
We applied domain adaptation in which the pseudo-
errors are regarded as the source domain and the
real-errors as the target domain. In our experiments,
domain adaptation achieved stable improvement in
system performance regardless of the error genera-
tion probability.
</bodyText>
<page confidence="0.997907">
391
</page>
<sectionHeader confidence="0.996333" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999798555555556">
Hal Daume, III. 2007. Frustratingly easy domain adapta-
tion. In Proceedings of the 45th Annual Meeting of the
Association of Computational Linguistics (ACL 2007),
pages 256–263, Prague, Czech Republic.
Michael Gamon. 2010. Using mostly native data to
correct errors in learners’ writing. In Human Lan-
guage Technologies: The 2010 Annual Conference of
the North American Chapter of the Association for
Computational Linguistics (NAACL-HLT 2010), pages
163–171, Los Angeles, California.
Na-Rae Han, Joel Tetreault, Soo-Hwa Lee, and Jin-
Young Ha. 2010. Using an error-annotated learner
corpus to develop an ESL/EFL error correction sys-
tem. In Proceedings of the Seventh International
Conference on Language Resources and Evaluation
(LREC’10), Valletta, Malta.
Kenji Imamura, Tomoko Izumi, Kugatsu Sadamitsu, Ku-
niko Saito, Satoshi Kobashikawa, and Hirokazu Masa-
taki. 2011. Morpheme conversion for connecting
speech recognizer and language analyzers in unseg-
mented languages. In Proceedings of Interspeech
2011, pages 1405–1408, Florence, Italy.
John Lafferty, Andrew McCallum, and Fernando Pereira.
2001. Conditional random fields: Probabilistic mod-
els for segmenting and labeling sequence data. In
Proceedings of the 18th International Conference
on Machine Learning (ICML-2001), pages 282–289,
Williamstown, Massachusetts.
Tomoya Mizumoto, Mamoru Komachi, Masaaki Nagata,
and Yuji Matsumoto. 2011. Mining revision log of
language learning SNS for automated Japanese error
correction of second language learners. In Proceed-
ings of 5th International Joint Conference on Natural
Language Processing (IJCNLP 2011), pages 147–155,
Chiang Mai, Thailand.
Alla Rozovskaya and Dan Roth. 2010a. Generating
confusion sets for context-sensitive error correction.
In Proceedings of the 2010 Conference on Empirical
Methods in Natural Language Processing (EMNLP
2010), pages 961–970, Cambridge, Massachusetts.
Alla Rozovskaya and Dan Roth. 2010b. Training
paradigms for correcting errors in grammar and usage.
In Human Language Technologies: The 2010 Annual
Conference of the North American Chapter of the As-
sociation for Computational Linguistics (NAACL-HLT
2010), pages 154–162, Los Angeles, California.
Alla Rozovskaya and Dan Roth. 2011. Algorithm se-
lection and model adaptation for ESL correction tasks.
In Proceedings of the 49th Annual Meeting of the As-
sociation for Computational Linguistics: Human Lan-
guage Techologies (ACL-HLT 2011), pages 924–933,
Portland, Oregon.
Andreas Stolcke, Jing Zheng, Wen Wang, and Victor
Abrash. 2011. SRILM at sixteen: Update and
outlook. In Proceedings of IEEE Automatic Speech
Recognition and Understanding Workshop (ASRU
2011), Waikoloa, Hawaii.
Jun Suzuki and Hideki Isozaki. 2008. Semi-supervised
sequential labeling and segmentation using giga-word
scale unlabeled data. In Proceedings of the 46th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies (ACL-08:
HLT), pages 665–673, Columbus, Ohio.
</reference>
<page confidence="0.998304">
392
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.664751">
<title confidence="0.99826">Grammar Error Correction Using Pseudo-Error Sentences and Domain Adaptation</title>
<author confidence="0.907585">Kuniko Saito Imamura</author>
<author confidence="0.907585">Kugatsu Sadamitsu</author>
<affiliation confidence="0.82242">NTT Cyber Space Laboratories, NTT</affiliation>
<address confidence="0.848764">1-1 Hikari-no-oka, Yokosuka, 239-0847, Japan</address>
<abstract confidence="0.993027333333333">This paper presents grammar error correction for Japanese particles that uses discriminative sequence conversion, which corrects erroneous particles by substitution, insertion, and deletion. The error correction task is hindered by the difficulty of collecting large error corpora. We tackle this problem by using pseudoerror sentences generated automatically. Furthermore, we apply domain adaptation, the pseudo-error sentences are from the source domain, and the real-error sentences are from the target domain. Experiments show that stable improvement is achieved by using domain adaptation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Hal Daume</author>
</authors>
<title>Frustratingly easy domain adaptation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics (ACL</booktitle>
<pages>256--263</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="8827" citStr="Daume (2007)" startWordPosition="1374" endWordPosition="1375">bilities are relative frequencies on the training corpus. The models are learnt using both the training corpus and the pseudo-error sentences. 3.2 Adaptation by Feature Augmentation Although the error generation probabilities are computed from the real-error corpus, the error distribution that results may be inappropriate. To better fit the pseudo-errors to the real-errors, we apply a domain adaptation technique. Namely, we regard the pseudo-error corpus as the source domain and the real-error corpus as the target domain, and models are learnt that fit the target domain. In this paper, we use Daume (2007)’s feature augmentation method for the domain adaptation, which eliminates the need to change the learning algorithm. This method regards the models for the source domain as the prior distribution and learns the models for the target domain. Feature Space Common Source Target DS DS 0 Dt 0 Dt Figure 2: Feature Augmentation We briefly review feature augmentation. The feature space is segmented into three parts: common, source, and target. The features extracted from the source domain data are deployed to the common and the source spaces, and those from the target domain data are deployed to the </context>
</contexts>
<marker>Daume, 2007</marker>
<rawString>Hal Daume, III. 2007. Frustratingly easy domain adaptation. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics (ACL 2007), pages 256–263, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Gamon</author>
</authors>
<title>Using mostly native data to correct errors in learners’ writing.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT 2010),</booktitle>
<pages>163--171</pages>
<location>Los Angeles, California.</location>
<contexts>
<context position="1951" citStr="Gamon, 2010" startWordPosition="276" endWordPosition="277">ive particle o is replaced by a nominative one ga, it becomes clear that the writer wants to delete the e-mail (“When the e-mail has arrived, please delete it.”). Such particle errors frequently occur in sentences written by non-native Japanese speakers. This paper presents a method that can automatically correct Japanese particle errors. This task corresponds to preposition/article error correction in English. For English error correction, many studies employ classifiers, which select the appropriate prepositions/articles, by restricting the error types to articles and frequent prepositions (Gamon, 2010; Han et al., 2010; Rozovskaya and Roth, 2011). On the contrary, Mizumoto et al. (2011) proposed translator-based error correction. This approach can handle all error types by converting the learner’s sentences into the correct ones. Although the target of this paper is particle error, we employ a similar approach based on sequence conversion (Imamura et al., 2011) since this offers excellent scalability. The conversion approach requires pairs of the learner’s and the correct sentences. However, collecting a sufficient number of pairs is expensive. To avoid this problem, we use additional corp</context>
</contexts>
<marker>Gamon, 2010</marker>
<rawString>Michael Gamon. 2010. Using mostly native data to correct errors in learners’ writing. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT 2010), pages 163–171, Los Angeles, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Na-Rae Han</author>
<author>Joel Tetreault</author>
<author>Soo-Hwa Lee</author>
<author>JinYoung Ha</author>
</authors>
<title>Using an error-annotated learner corpus to develop an ESL/EFL error correction system.</title>
<date>2010</date>
<booktitle>In Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC’10),</booktitle>
<location>Valletta,</location>
<contexts>
<context position="1969" citStr="Han et al., 2010" startWordPosition="278" endWordPosition="281">o is replaced by a nominative one ga, it becomes clear that the writer wants to delete the e-mail (“When the e-mail has arrived, please delete it.”). Such particle errors frequently occur in sentences written by non-native Japanese speakers. This paper presents a method that can automatically correct Japanese particle errors. This task corresponds to preposition/article error correction in English. For English error correction, many studies employ classifiers, which select the appropriate prepositions/articles, by restricting the error types to articles and frequent prepositions (Gamon, 2010; Han et al., 2010; Rozovskaya and Roth, 2011). On the contrary, Mizumoto et al. (2011) proposed translator-based error correction. This approach can handle all error types by converting the learner’s sentences into the correct ones. Although the target of this paper is particle error, we employ a similar approach based on sequence conversion (Imamura et al., 2011) since this offers excellent scalability. The conversion approach requires pairs of the learner’s and the correct sentences. However, collecting a sufficient number of pairs is expensive. To avoid this problem, we use additional corpus consisting of p</context>
</contexts>
<marker>Han, Tetreault, Lee, Ha, 2010</marker>
<rawString>Na-Rae Han, Joel Tetreault, Soo-Hwa Lee, and JinYoung Ha. 2010. Using an error-annotated learner corpus to develop an ESL/EFL error correction system. In Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC’10), Valletta, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Imamura</author>
</authors>
<title>Tomoko Izumi, Kugatsu Sadamitsu, Kuniko Saito, Satoshi Kobashikawa, and Hirokazu Masataki.</title>
<date>2011</date>
<booktitle>In Proceedings of Interspeech</booktitle>
<pages>1405--1408</pages>
<location>Florence, Italy.</location>
<marker>Imamura, 2011</marker>
<rawString>Kenji Imamura, Tomoko Izumi, Kugatsu Sadamitsu, Kuniko Saito, Satoshi Kobashikawa, and Hirokazu Masataki. 2011. Morpheme conversion for connecting speech recognizer and language analyzers in unsegmented languages. In Proceedings of Interspeech 2011, pages 1405–1408, Florence, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of the 18th International Conference on Machine Learning (ICML-2001),</booktitle>
<pages>282--289</pages>
<location>Williamstown, Massachusetts.</location>
<contexts>
<context position="4692" citStr="Lafferty et al., 2001" startWordPosition="695" endWordPosition="698">cts particle errors in the input sentences as follows. • First, all modification candidates are obtained by referring to a phrase table. This table, called the confusion set (Rozovskaya and Roth, 2010a) in the error correction task, stores pairs of incorrect and correct particles (Table 1). The candidates are packed into a lattice structure, called the phrase lattice (Figure 1). To deal with unchanged words, it also copies the input words and inserts them into the phrase lattice. • Next, the best phrase sequence in the phrase lattice is identified based on the conditional random fields (CRFs (Lafferty et al., 2001)). The Viterbi algorithm is applied to the decoding because error correction does not change the word order. • While training, word alignment is carried out by dynamic programming matching. From the alignment results, the phrase table is constructed by acquiring particle errors, and the CRF models are trained using the alignment results as supervised data. 2.2 Insertion / Deletion Since an insertion can be regarded as replacing an empty word with an actual word, and deletion is the replacement of an actual word with an empty one, we treat these operations as substitution without distinction wh</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the 18th International Conference on Machine Learning (ICML-2001), pages 282–289, Williamstown, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomoya Mizumoto</author>
<author>Mamoru Komachi</author>
<author>Masaaki Nagata</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Mining revision log of language learning SNS for automated Japanese error correction of second language learners.</title>
<date>2011</date>
<booktitle>In Proceedings of 5th International Joint Conference on Natural Language Processing (IJCNLP 2011),</booktitle>
<pages>147--155</pages>
<location>Chiang Mai, Thailand.</location>
<contexts>
<context position="2038" citStr="Mizumoto et al. (2011)" startWordPosition="289" endWordPosition="292"> writer wants to delete the e-mail (“When the e-mail has arrived, please delete it.”). Such particle errors frequently occur in sentences written by non-native Japanese speakers. This paper presents a method that can automatically correct Japanese particle errors. This task corresponds to preposition/article error correction in English. For English error correction, many studies employ classifiers, which select the appropriate prepositions/articles, by restricting the error types to articles and frequent prepositions (Gamon, 2010; Han et al., 2010; Rozovskaya and Roth, 2011). On the contrary, Mizumoto et al. (2011) proposed translator-based error correction. This approach can handle all error types by converting the learner’s sentences into the correct ones. Although the target of this paper is particle error, we employ a similar approach based on sequence conversion (Imamura et al., 2011) since this offers excellent scalability. The conversion approach requires pairs of the learner’s and the correct sentences. However, collecting a sufficient number of pairs is expensive. To avoid this problem, we use additional corpus consisting of pseudo-error sentences automatically generated from correct sentences </context>
</contexts>
<marker>Mizumoto, Komachi, Nagata, Matsumoto, 2011</marker>
<rawString>Tomoya Mizumoto, Mamoru Komachi, Masaaki Nagata, and Yuji Matsumoto. 2011. Mining revision log of language learning SNS for automated Japanese error correction of second language learners. In Proceedings of 5th International Joint Conference on Natural Language Processing (IJCNLP 2011), pages 147–155, Chiang Mai, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alla Rozovskaya</author>
<author>Dan Roth</author>
</authors>
<title>Generating confusion sets for context-sensitive error correction.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP 2010),</booktitle>
<pages>961--970</pages>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="2690" citStr="Rozovskaya and Roth, 2010" startWordPosition="386" endWordPosition="389">error correction. This approach can handle all error types by converting the learner’s sentences into the correct ones. Although the target of this paper is particle error, we employ a similar approach based on sequence conversion (Imamura et al., 2011) since this offers excellent scalability. The conversion approach requires pairs of the learner’s and the correct sentences. However, collecting a sufficient number of pairs is expensive. To avoid this problem, we use additional corpus consisting of pseudo-error sentences automatically generated from correct sentences that mimic the realerrors (Rozovskaya and Roth, 2010b). Furthermore, we apply a domain adaptation technique that regards the pseudo-errors and the real-errors as the source and the target domain, respectively, so that the pseudo-errors better match the real-errors. 2 Error Correction by Discriminative Sequence Conversion We start by describing discriminative sequence conversion. Our error correction method converts the learner’s word sequences into the correct sequences. Our method is similar to phrase-based statistical machine translation (PBSMT), but there are three differences; 1) it adopts the conditional random fields, 2) it allows inserti</context>
<context position="4270" citStr="Rozovskaya and Roth, 2010" startWordPosition="625" endWordPosition="628"> ga/NOM. o/ACC. SUB o/ACC. ni/DAT. SUB o/ACC. ga/NOM. SUB wa/TOP. o/ACC. SUB no/POSS. φ DEL : : Table 1: Example of Phrase Table (partial) approach, the conversion approach can correct multiple errors of all types in a sentence. 2.1 Basic Procedure We apply the morpheme conversion approach that converts the results of a speech recognizer into word sequences for language analyzer processing (Imamura et al., 2011). It corrects particle errors in the input sentences as follows. • First, all modification candidates are obtained by referring to a phrase table. This table, called the confusion set (Rozovskaya and Roth, 2010a) in the error correction task, stores pairs of incorrect and correct particles (Table 1). The candidates are packed into a lattice structure, called the phrase lattice (Figure 1). To deal with unchanged words, it also copies the input words and inserts them into the phrase lattice. • Next, the best phrase sequence in the phrase lattice is identified based on the conditional random fields (CRFs (Lafferty et al., 2001)). The Viterbi algorithm is applied to the decoding because error correction does not change the word order. • While training, word alignment is carried out by dynamic programmin</context>
<context position="7978" citStr="Rozovskaya and Roth (2010" startWordPosition="1237" endWordPosition="1240"> maintaining high accuracy on the training corpus. 3 Pseudo-error Sentences and Domain Adaptation The error corrector described in Section 2 requires paired sentences. However, it is expensive to collect them. We resolve this problem by using pseudoerror sentences and domain adaptation. 3.1 Pseudo-Error Generation Correct sentences, which are halves of the paired sentences, can be easily acquired from corpora such as newspaper articles. Pseudo-errors are generated from them by the substitution, insertion, and deletion functions according to the desired error patterns. We utilize the method of Rozovskaya and Roth (2010b). Namely, when particles appear in the correct sentence, they are replaced by incorrect ones in a probabilistic manner by applying the phrase table (which stores the error patterns) in the opposite direction. The error generation probabilities are relative frequencies on the training corpus. The models are learnt using both the training corpus and the pseudo-error sentences. 3.2 Adaptation by Feature Augmentation Although the error generation probabilities are computed from the real-error corpus, the error distribution that results may be inappropriate. To better fit the pseudo-errors to the</context>
</contexts>
<marker>Rozovskaya, Roth, 2010</marker>
<rawString>Alla Rozovskaya and Dan Roth. 2010a. Generating confusion sets for context-sensitive error correction. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP 2010), pages 961–970, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alla Rozovskaya</author>
<author>Dan Roth</author>
</authors>
<title>Training paradigms for correcting errors in grammar and usage.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT 2010),</booktitle>
<pages>154--162</pages>
<location>Los Angeles, California.</location>
<contexts>
<context position="2690" citStr="Rozovskaya and Roth, 2010" startWordPosition="386" endWordPosition="389">error correction. This approach can handle all error types by converting the learner’s sentences into the correct ones. Although the target of this paper is particle error, we employ a similar approach based on sequence conversion (Imamura et al., 2011) since this offers excellent scalability. The conversion approach requires pairs of the learner’s and the correct sentences. However, collecting a sufficient number of pairs is expensive. To avoid this problem, we use additional corpus consisting of pseudo-error sentences automatically generated from correct sentences that mimic the realerrors (Rozovskaya and Roth, 2010b). Furthermore, we apply a domain adaptation technique that regards the pseudo-errors and the real-errors as the source and the target domain, respectively, so that the pseudo-errors better match the real-errors. 2 Error Correction by Discriminative Sequence Conversion We start by describing discriminative sequence conversion. Our error correction method converts the learner’s word sequences into the correct sequences. Our method is similar to phrase-based statistical machine translation (PBSMT), but there are three differences; 1) it adopts the conditional random fields, 2) it allows inserti</context>
<context position="4270" citStr="Rozovskaya and Roth, 2010" startWordPosition="625" endWordPosition="628"> ga/NOM. o/ACC. SUB o/ACC. ni/DAT. SUB o/ACC. ga/NOM. SUB wa/TOP. o/ACC. SUB no/POSS. φ DEL : : Table 1: Example of Phrase Table (partial) approach, the conversion approach can correct multiple errors of all types in a sentence. 2.1 Basic Procedure We apply the morpheme conversion approach that converts the results of a speech recognizer into word sequences for language analyzer processing (Imamura et al., 2011). It corrects particle errors in the input sentences as follows. • First, all modification candidates are obtained by referring to a phrase table. This table, called the confusion set (Rozovskaya and Roth, 2010a) in the error correction task, stores pairs of incorrect and correct particles (Table 1). The candidates are packed into a lattice structure, called the phrase lattice (Figure 1). To deal with unchanged words, it also copies the input words and inserts them into the phrase lattice. • Next, the best phrase sequence in the phrase lattice is identified based on the conditional random fields (CRFs (Lafferty et al., 2001)). The Viterbi algorithm is applied to the decoding because error correction does not change the word order. • While training, word alignment is carried out by dynamic programmin</context>
<context position="7978" citStr="Rozovskaya and Roth (2010" startWordPosition="1237" endWordPosition="1240"> maintaining high accuracy on the training corpus. 3 Pseudo-error Sentences and Domain Adaptation The error corrector described in Section 2 requires paired sentences. However, it is expensive to collect them. We resolve this problem by using pseudoerror sentences and domain adaptation. 3.1 Pseudo-Error Generation Correct sentences, which are halves of the paired sentences, can be easily acquired from corpora such as newspaper articles. Pseudo-errors are generated from them by the substitution, insertion, and deletion functions according to the desired error patterns. We utilize the method of Rozovskaya and Roth (2010b). Namely, when particles appear in the correct sentence, they are replaced by incorrect ones in a probabilistic manner by applying the phrase table (which stores the error patterns) in the opposite direction. The error generation probabilities are relative frequencies on the training corpus. The models are learnt using both the training corpus and the pseudo-error sentences. 3.2 Adaptation by Feature Augmentation Although the error generation probabilities are computed from the real-error corpus, the error distribution that results may be inappropriate. To better fit the pseudo-errors to the</context>
</contexts>
<marker>Rozovskaya, Roth, 2010</marker>
<rawString>Alla Rozovskaya and Dan Roth. 2010b. Training paradigms for correcting errors in grammar and usage. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT 2010), pages 154–162, Los Angeles, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alla Rozovskaya</author>
<author>Dan Roth</author>
</authors>
<title>Algorithm selection and model adaptation for ESL correction tasks.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Techologies (ACL-HLT 2011),</booktitle>
<pages>924--933</pages>
<location>Portland, Oregon.</location>
<contexts>
<context position="1997" citStr="Rozovskaya and Roth, 2011" startWordPosition="282" endWordPosition="285"> nominative one ga, it becomes clear that the writer wants to delete the e-mail (“When the e-mail has arrived, please delete it.”). Such particle errors frequently occur in sentences written by non-native Japanese speakers. This paper presents a method that can automatically correct Japanese particle errors. This task corresponds to preposition/article error correction in English. For English error correction, many studies employ classifiers, which select the appropriate prepositions/articles, by restricting the error types to articles and frequent prepositions (Gamon, 2010; Han et al., 2010; Rozovskaya and Roth, 2011). On the contrary, Mizumoto et al. (2011) proposed translator-based error correction. This approach can handle all error types by converting the learner’s sentences into the correct ones. Although the target of this paper is particle error, we employ a similar approach based on sequence conversion (Imamura et al., 2011) since this offers excellent scalability. The conversion approach requires pairs of the learner’s and the correct sentences. However, collecting a sufficient number of pairs is expensive. To avoid this problem, we use additional corpus consisting of pseudo-error sentences automa</context>
</contexts>
<marker>Rozovskaya, Roth, 2011</marker>
<rawString>Alla Rozovskaya and Dan Roth. 2011. Algorithm selection and model adaptation for ESL correction tasks. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Techologies (ACL-HLT 2011), pages 924–933, Portland, Oregon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
<author>Jing Zheng</author>
<author>Wen Wang</author>
<author>Victor Abrash</author>
</authors>
<title>SRILM at sixteen: Update and outlook.</title>
<date>2011</date>
<booktitle>In Proceedings of IEEE Automatic Speech Recognition and Understanding Workshop (ASRU</booktitle>
<location>Waikoloa, Hawaii.</location>
<contexts>
<context position="11269" citStr="Stolcke et al., 2011" startWordPosition="1777" endWordPosition="1780">t most particles did not need to be revised. The number of pair types of incorrect particles and their correct ones was 132. Language Model: It was constructed from Japanese Wikipedia articles about computers and Source Data Target Data 390 1 0.9 0.8 0.7 0.6 . 0.5 0.4 0.3 TRG SRC ALL AUG 0 0.05 0.1 0.15 0.2 0.25 Recall Rate 0.0 0.5 1.0 1.5 2.0 Error Generation Probability (Magnification) Precision Rate TRG SRC ALL AUG +100 +50 0 Relative Improvement -50 -100 -150 Figure 3: Recall/Precision Curve (Error Generation Magnification is 1.0) Japanese Linux manuals, 527,151 sentences in total. SRILM (Stolcke et al., 2011) was used to train a trigram model. Pseudo-error Corpus: The pseudo-errors were generated using 10,000 sentences randomly selected from the corpus for the language model. The magnification of the error generation probabilities was changed from 0.0 (i.e., no errors) to 2.0 (the relative frequency in the real-error corpus was taken as 1.0). Evaluation Metrics: Five-fold cross-validation on the real-error corpus was used. We used two metrics: 1) Precision and recall rates of the error correction by the systems, and 2) Relative improvement, the number of differences between improved and degraded p</context>
</contexts>
<marker>Stolcke, Zheng, Wang, Abrash, 2011</marker>
<rawString>Andreas Stolcke, Jing Zheng, Wen Wang, and Victor Abrash. 2011. SRILM at sixteen: Update and outlook. In Proceedings of IEEE Automatic Speech Recognition and Understanding Workshop (ASRU 2011), Waikoloa, Hawaii.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Suzuki</author>
<author>Hideki Isozaki</author>
</authors>
<title>Semi-supervised sequential labeling and segmentation using giga-word scale unlabeled data.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-08: HLT),</booktitle>
<pages>665--673</pages>
<location>Columbus, Ohio.</location>
<contexts>
<context position="7303" citStr="Suzuki and Isozaki, 2008" startWordPosition="1135" endWordPosition="1138"> training corpus. • Language model probability: This is a logarithmic value (real value) of the n-gram probability of the output word sequence. One feature weight is assigned. The n-gram language model can be mail o todoi In�ut WOrds tara now ACC. verb PART mail now COPY COpY COPY COPY INS SUB no POss. o ACC. ga NOM. o ACC. ni DAT. todoi verb tara PART Incorrect Particle &lt;s&gt; Phrase � Latt�Ce 389 constructed from a large sentence set because it does not need the learner’s sentences. Incorporating binary and real features yields a rough approximation of generative models in semisupervised CRFs (Suzuki and Isozaki, 2008). It can appropriately correct new sentences while maintaining high accuracy on the training corpus. 3 Pseudo-error Sentences and Domain Adaptation The error corrector described in Section 2 requires paired sentences. However, it is expensive to collect them. We resolve this problem by using pseudoerror sentences and domain adaptation. 3.1 Pseudo-Error Generation Correct sentences, which are halves of the paired sentences, can be easily acquired from corpora such as newspaper articles. Pseudo-errors are generated from them by the substitution, insertion, and deletion functions according to the</context>
</contexts>
<marker>Suzuki, Isozaki, 2008</marker>
<rawString>Jun Suzuki and Hideki Isozaki. 2008. Semi-supervised sequential labeling and segmentation using giga-word scale unlabeled data. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-08: HLT), pages 665–673, Columbus, Ohio.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>