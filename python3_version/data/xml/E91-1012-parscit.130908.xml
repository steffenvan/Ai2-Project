<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.931255">
Non-deterministic Recursive Ascent Parsing
</title>
<note confidence="0.706947666666667">
René Leermakers
Philips Research Laboratories,
P.O. Box 80.000, 5600 JA Eindhoven, The Netherlands
</note>
<email confidence="0.97303">
E-mailleermake@rosetta.prl.philips.n1
</email>
<sectionHeader confidence="0.986684" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999957933333334">
A purely functional implementation of LR-parsers is
given, together with a simple correctness proof. It is
presented as a generalization of the recursive descent
parser. For non-LR grammars the time-complexity of
our parser is cubic if the functions that constitute the
parser are implemented as memo-functions, i.e. func-
tions that memorize the results of previous invocations.
Memo-functions also facilitate a simple way to construct
a very compact representation of the parse forest. For
LR(0) grammars, our algorithm is closely related to the
recursive ascent parsers recently discovered by Kruse-
man Aretz [1] and Roberts [2]. Extended CF grammars
(grammars with regular expressions at the right hand
side) can be parsed with a simple modification of the
LR-parser for normal CF grammars.
</bodyText>
<sectionHeader confidence="0.998432" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999838754385965">
In this paper we give a purely functional implementa-
tion of LR-parsers, applicable to general CF grammars.
It will be obtained as a generalization of the well-known
recursive descent parsing technique. For LR(0) gram-
mars, our result implies a deterministic parser that is
closely related to the recursive ascent parsers discovered
by Kruseman Aretz [1] and Roberts [2]. In the gen-
eral non-deterministic case, the parser has cubic time
complexity if the parse functions are implemented as
memo-functions [3], which are functions that memorize
and re-use the results of previous invocations. Memo-
functions are easily implemented in most programming
languages. The notion of memo-functions is also used
to define an algorithm that constructs a cubic represen-
tation for the parse forest, i.e. the collection of parse
trees.
It has been claimed by Tomita that non-deterministic
LR-parsers are useful for natural language processing.
In [4] he presented a discussion about how to do non-
deterministic LR-parsing, with a device called a graph-
structured stack. With our parser we show that no ex-
plicit stack manipulations are needed; they can be ex-
pressed implicitly with the use of appropriate program-
ming language concepts.
Most textbooks on parsing do not include proper
correctness proofs for LR-parsers, mainly because such
proofs tend to be rather involved. The theory of LR-
parsing should still be considered underdeveloped, for
this reason. Our presentation, however, contains a sur-
prisingly simple correctness proof. In fact, this proof is
this paper&apos;s major contribution to parsing theory. One
of its lessons is that the CF grammar class is often the
natural one to proof parsers for, even if these parsers are
devoted to some special class of grammars. If the gram-
mar is restricted in some way, a parser for general CF
grammars may have properties that enable smart imple-
mentation tricks to enhance efficiency. As we show be-
low, the relation between LR-parsers and LR-grammars
is of this kind.
Especially in natural language processing, standard
CF grammars are often too limited in their strong gen-
erative power. The extended CF grammar formalism,
allowing rules to have regular expressions at the right
hand side, is a useful extension, for that reason. It is not
difficult to generalize our parser to cope with extended
grammars, although the application of LR-parsing to
extended CF grammars is well-known to be problematic
[5].
We first present the recursive descent recognizer in
a way that allows the desired generalization. Then we
obtain the recursive ascent recognizer and its proof. If
the grammar is LR(0) a few implementation tricks lead
to the recursive ascent recognizer of ref. [1]. Subse-
quently, the time and space complexities of the recog-
nizer are analysed, and the algorithm for constructing
a cubic representation for parse forests is given. The
paper ends with a. discussion of extended CF grammars.
</bodyText>
<sectionHeader confidence="0.963521" genericHeader="introduction">
2 Recursive descent
</sectionHeader>
<bodyText confidence="0.999911666666667">
Consider CF grammar G, with terminals VT and non-
terminals VN. Let V = VN U VT. A well-known top-
down parsing technique is the recursive descent parser.
Recursive descent parsers consist of a number of pro-
cedures, usually one for each non-terminal. Here we
present a variant that consists of functions, one for each
item (dotted rule). We use the unorthodox embracing
operator [.] to map each item to its function: (we use
greek letters for arbitrary elements of V&apos;)
</bodyText>
<equation confidence="0.48028">
[A a.P] : N 2N
</equation>
<bodyText confidence="0.999879333333333">
where N is the set of integers, or a subset (0...n..,),
with nma. the maximum sentence length. The functions
are to meet the following specification:
</bodyText>
<equation confidence="0.989224">
[A =
- 63 -
</equation>
<bodyText confidence="0.9466965">
with xl...x,, the sentence to be parsed. A recursive im-
plementation for these functions is given by (b E VT, B E
</bodyText>
<equation confidence="0.928173">
VN)
[A -• cr.](i) = {i}
[A a .67](i) = (jib = zi+1 A j E [A -4. ab .71(i + 1))
[A a.B7](i)
f jlk E [B • .6](i) Aj E [A -■ B .7](k))
</equation>
<bodyText confidence="0.997967333333333">
We keep to the custom of omitting existential quantifi-
cation (here for k, b) in definitions of this kind.
The proof is elementary and based on
</bodyText>
<equation confidence="0.849616833333333">
/3 --•* (A3 = tA i = j)V
3/0 = XI. 17 A 7 --**
313-y5k(S = B7 AB.bAb kA
--4•* xk4.1...xj)
If we add a grammar rule S&apos; -+ S to G, with S&apos; ft V
then S xi...x,,, is equivalent to n E [S&apos;
</equation>
<bodyText confidence="0.997961375">
The recursive descent recognizer works for any CF
grammar except for grammars for which 3,1,,,p(A -•
Ao, -•• A,3). For such left-recursive grammars the rec-
ognizer does not terminate, as exocution of [A -+ .cd(i)
will lead to a call of itself. The recognition is not a linear
process in general: the function calls [A cv./37](i) lead
to calls [B .6](i) for all values of 6 such that B
is a grammar rule.
</bodyText>
<sectionHeader confidence="0.964396" genericHeader="method">
3 The ascent recognizer
</sectionHeader>
<bodyText confidence="0.999982833333333">
One way to make the recognizer more deterministic is by
combining functions corresponding to a number of com-
peting items into one function. Let the set of all items
of G be given by lc. Subsets of IG are called states, and
we use q to be an arbitrary state. We associate to each
state q a function, re-using the above operator [.],
</bodyText>
<equation confidence="0.588859">
[ N 21a xN
</equation>
<bodyText confidence="0.9624608">
that meets the specification
[CO = ((A a./3, j)1A -+ cf./3 E q A #
As above, the function reports which parts of the sen-
tence can be derived. But as the function is associated
to a set q of items, it has to do so for each item in
q. If we define the initial state qo = {S&apos; .S}, now
S xi ...x„ is equivalent to (S&apos; .S,n) E [q0](0).
Before proceeding, we need a couple of definitions.
Let ini(q) be the set of initial items for state q, that
are derived from q by the closure operation:
</bodyText>
<equation confidence="0.987367">
ini(q) = IB AAA--0er./3EqAti* B7).
</equation>
<bodyText confidence="0.957316666666667">
The double arrow denotes a left-most-symbol rewrit-
ing Bci C 13a, using a lion-f rule B C/3. The
transition function gob o is defined by (B E V)
</bodyText>
<construct confidence="0.7274982">
goto(q, B) = (A B filA a.I E (q U ini(q))}
Also define
pop(A a B .fi) = A
Ihs(A a. )3) = A
f inal(A a 13) = (1131= 0)
</construct>
<bodyText confidence="0.9708828">
with B E V, and 1$1 the number of symbols in (with
lel = 0). A recursive ascent recognizer may be obtained
by relating to each state q not only the above [q], but
also a function that we take to be the result of applying
operator [.] to the state:
</bodyText>
<equation confidence="0.784628">
[q] : V x N 210 x N
It has the specification
1-0(B , i) = ((A a.# , j)IA E qA
</equation>
<bodyText confidence="0.750254333333333">
For i &gt;n (n is the sentence length) it follows that
[q](i) = [q](B , = 0, whereas for i &lt; n the functions
are recursively implemented by
</bodyText>
<equation confidence="0.992729833333333">
[CO = [(x i A- 1)U
{(I, j)113 .e E ini(q) A (/, j) E [q](B,i)}U
((1,1)11 EqAfinal(1)}
[q](B, = (pop(/), j)I
(/, j) E [goto(q, B)](i) pop(I) E q)U
j)I(J,k) E [goto(q, B)]19A
pop(J) E ini(q) A (I, j) E [q](1hs(J),k)}
Proof:
First we notice that
xs+17 A -y ...xj)V
3 131(13 Thy AB -4.c A7 V
(#=cAi=j)
Hence
==
f(A --• a.13,j)I(A j) E I))U
{(A a.thj)I
B E A (A a . f3 , j) E &amp;quot;R(B, 0}U
((A a., i)IA -• cr. E q}
</equation>
<bodyText confidence="0.986700444444444">
This is equivalent to the earlier version because we may
replace the clause B c by B .c E ini(q). Indeed,
if state q has item A cr.# and if there is a left-most-
symbol derivation 13 = Thy then all items B --0 .A are
included in ini(q).
—
For establishing the correctness of kJ notice that
/3 ** B7 either contains zero steps, in which case
= B- y, or it contains at least one step:
</bodyText>
<equation confidence="0.845410777777778">
3+,(13 B-y A 7 -•* xa+1...xj)
3-,(# = 137 A 7 -••
3c6-ik(13 ** C7 AC -■ 136 AO x,.4.1...xk A7 .•
Hence -1q](B , i) may be written as the union of two sets,
[q](B, = So U
So = ((A
A ---+ a.B-y E q A -y
= {(A a. .i)IA &amp;quot; q A 13 * C7A
C Bb A 6 xs4.1.••xk A 7 -■• zk+2.••x,/•
</equation>
<bodyText confidence="0.651623666666667">
By the definition of gob, if A a.B-y E q then A
a B.7 E goto(q, B). Hence, with the specification of [q],
So may be rewritten as
</bodyText>
<equation confidence="0.865276666666667">
So = ((A -• a.B7, j)IA -0 ct./37 E qA
(A 043.7, j) E [goto(q, B)](i)}
- 64 -
</equation>
<bodyText confidence="0.93366">
The set S1 may be rewritten using the specification of
[q](C,k):
= f(A --0 a.f j)I(A —0 a .fl , j) E [q](C, k)A
C —• Bb A b
Also, as before, 0 =• C7 implies that all items C
are in ini(q), and the existence of C .Bb in ini(q)
implies C B.8 E goto(q, B):
</bodyText>
<equation confidence="0.86816225">
= f(A a.t1, j)I(A , j) [q](C,k)A
C .Bb E ini(q)A
(C B.b, k) E[goto(q,B)](i)).
0
</equation>
<bodyText confidence="0.996222571428571">
In the computation of [qo](0), functions are needed
only for states in the canonical collection of LR(0) states
[6] for G, i.e. for every state that can be reached from the
initial state by repeated application of the got° function.
Note that in general the state 0 will be among these, and
that both [0](i) and [0](B, i) are empty sets for all i &gt; 0
and B E V.
</bodyText>
<sectionHeader confidence="0.997631" genericHeader="method">
4 Deterministic variants
</sectionHeader>
<bodyText confidence="0.9997295">
One can prove that, if the grammar is LR(0), each rec-
ognizer function for a canonical LR(0) state results in
a set with at most one element. The functions for non-
empty q may in this case be rephrased as
</bodyText>
<equation confidence="0.56757">
[q](i) :
</equation>
<bodyText confidence="0.971147090909091">
if, for some I, IE qAf inal(I) then return ((I,1)) else
if B .c E ini(q) then return [q](B,i)
else if i &lt; n then return [q](x1.4.1,1+ 1)
else return 0
fi
[q](B,i):
if [goto(q, B)](i) = 0 then return 0 else
let (I, j) be the unique element of [goto(q, B)](i). Then:
if pop(I) E q then return f(pop(I), j))
else return fq1(11is(1), j)
fi
fi
Reversely, the implementations of [q](i) and [q](B , i) of
the previous section can be seen as non-deterministic
versions of the present formulation, which therefore pro-
vides an intuitive picture that may be helpful to under-
stand the non-deterministic parsing process in an oper-
ational way.
Each function can be replaced by a procedure that,
instead of returning a function result, assigns the result
to a global (set) variable. As this set variable may con-
tain at most one element, it can be represented by three
variables, a boolean b, an item R and an integer 1. If
a function would have resulted in the set {(/, j)}, the
global variables are set to b =TRUE, R = I and i = j.
A function value 0 is represented by b= FALSE. Also
the arguments of the functions are superfluous now. The
role of argument i can be played by the global variable
with the same name, and ths(R) can be used instead of
argument B of [q]. Consequently, procedure [0] becomes
a statement b := FALSE, whereas for non-empty q one
gets the procedures (keeping the names [q] and [q], trust-
ing no confusion will arise):
</bodyText>
<figure confidence="0.867508333333333">
fg1
if, for some I, IE qAfinal(I) then R :=L
else if B E ini(q) then R := B (.; [q]
else if i &lt; n then R := x1+1.; i := i 1; [q]
else b:= FALSE
Ii.
Egoto(q,lhs(R))];
if b then
if pop(R) E g then I? := pop(R)
else [q]
fi
fi
</figure>
<bodyText confidence="0.999682666666667">
Note that these procedures do not depend on the details
of the right hand side of R. Only the number of sym-
bols before the dot is relevant for the test &amp;quot;pop(R) E q&amp;quot;.
Therefore, R can be replaced by two variables X E V
and an integer 1, making the following substitutions in
the previous procedures:
</bodyText>
<equation confidence="0.99963">
X := A;1 := lal
R := pop(R) 1 := 1 — 1
pop(R) E q 101vX= S&apos;
lhs(R) X
</equation>
<bodyText confidence="0.999810444444444">
After these substitutions, one gets close to the recursive
ascent recognizer as it was presented in [1]. A recognizer
that is virtually the same as in [Ills obtained by replac-
ing the tail-recursive procedure [q] by an iterative loop.
Then one is left with one procedure for each state. While
parsing there is, at each instance, a stack of activated
procedures that corresponds to the stacks that are ex-
plicitly maintained in conventional implementations of
deterministic LR-parsers.
</bodyText>
<sectionHeader confidence="0.998522" genericHeader="method">
5 Complexity
</sectionHeader>
<bodyText confidence="0.994843454545455">
For LL(0) grammars the recursive descent recognizer is
deterministic and works in linear time. The same is
true of the ascent recognizer for LR(0) grammars. In
the general, non-deterministic, case the recursive de-
scent and ascent recognizers need exponential time un-
less the functions are implemented as memo-functions
[3]. Memo-functions memorize for which arguments they
have been called. If a function is called with the same
arguments as before, the function returns the previous
result without recomputing it. In conventional program-
ming languages memo-functions are not available, but
they can easily be implemented. Devices like graph-
structured stacks [4], parse matrices [7], or well-formed
- 65 -
substring tables [8], are in fact low-level realizations of
the abstract notion of memo-functions. The complex-
ity analysis of the recognizers is quite simple. There are
0(n) different invocations of parser functions. The func-
tions call at most 0(n) other functions, that all result
in a set with 0(n) elements (note that there exist only
0(n) pairs (/, j) with 1€ 10,i &lt; j &lt; n). Merging these
sets to one set with no duplicates can be accomplished in
0(n2) time on a random access machine. Hence, the to-
tal time-complexity is 0(n3). The space needed for stor-
ing function results is 0(n) per invocation, i.e. 0(n2)
for the whole recognizer.
The above considerations only hold if the parser ter-
minates. The recursive descent parser terminates for all
grammars that are not left-recursive. For the recursive
ascent parser, the situation is more complicated. lithe
grammar has a cyclic derivation B B, the execution
of [d(B,i) leads to a call of itself. Also, there may be a
cycle of transitions labeled by non-terminals that derive
c, e.g. if goto(q, B) = q A B c, so that the execution
of [d(i) leads to a call of itself. There are non-cyclic
grammars that suffer from such a cycle (e.g. S SSb,
S c). Hence, the ascent parser does not terminate if
the grammar is cyclic or if it leads to a cycle of transi-
tions labeledby non-terminals that derive e. Otherwise,
execution of [q](B,i) can only lead to calls of [p](i) with
p q and to calls of NYC, k), such that either k &gt; i
orC—+` BACOB. As there are only finitely many
such p, C, the parser terminates. Note that both the re-
cursive descent and ascent recognizer terminate for any
grammar, if the recognizer functions are implemented
as memo-functions with the property that a call of a
function with some arguments yields 8 while it is under
execution. For instance, if execution of [q](i) leads to
a call of itself, the second call is to yield 0. A remark
of this kind, for the recursive descent parser, was first
made in ref. [8]. The recursive descent parser then be-
comes virtually equivalent to a version of the standard
Earley algorithm [9] that stores items A --i a.# in parse
matrix entry Ts, if /3 —+&apos; instead of storing it
if a --+• xs+1...xj.
The space required for a parser that also calculates
a parse forest, is dominated by this forest. We show
in the next section that it may be compressed into a
cubic amount of space. In the complexity domain our
ascent parser beats its rival, Tot-rates parsing method
[4], which is non-polynomial: for each integer k there
exists a grammar such that the complexity of the Tomita
parser is worse than nk.
In addition to the complexity as a function of sen-
tence length, one may also consider the complexity as
a function of grammar size. It is clear that both time
and space complexity are proportional to the number of
parsing procedures. The number of procedures of the
recursive descent parser is proportional to the number
of items, and hence a linear function of the grammar
size. The recursive ascent parser, however, contains two
functions for each LR-state and is hence proportional to
the size of the canonical collection of LR(0) states. In
the worst case, this size is an exponential function of
grammar size, but in the average natural language case
there seems to be a linear, or even sublinear, dependence
[4].
</bodyText>
<sectionHeader confidence="0.977659" genericHeader="method">
6 Parse forest
</sectionHeader>
<bodyText confidence="0.999827171428571">
Usually, the recognition process is followed by the con-
struction of parse trees. For ambiguous grammars, it
becomes an issue how to represent the set of parse trees
as compactly as possible. Below, we describe how to
obtain a cubic representation in cubic time. We do so
in three steps.
In the first step, we observe that ambiguity often
arises locally: given a certain context CH, there might
be several parse subtrees ti...tk (all deriving the same
substring from the same symbol A) that fit
in that same context, leading to the parse trees C[11],
C[12], ,C[tk] for the given string xi...x.. Instead of
representing these parse trees separately, repeating each
time the context C, we can represent them collectively
as C[It1, tk)]. Of course, this idea should be applied
recursively. Technically, this leads to a kind of tree-like
structure in which each child is a set of substructures
rather than a single one.
The sharing of context can be carried one step further.
If we have, in one and the same context, a number of
applied occurrences of a production rule A --. f3 which
share also the same parse forest for a, we can represent
the context of A a# itself and the common parse
forest for a only once and fit the set of parse forests for
13 into that. Again this idea has to be applied recursively.
Technically, this leads to a binary representation of parse
trees, with each node having at most two sons, and to
the application of the context sharing technique to this
binary representation.
These two ideas are captured by introducing a func-
tion f with the interpretation that f(fi, j) represents
the parse forest of all derivations from j3 E V* to
x.4.1...x), for all i,j such that 0 &lt; &lt; j &lt; n. The
following recursive definitions fix the parse forest repre-
sentation formally:
</bodyText>
<equation confidence="0.675954428571429">
f (c, i) = {GI= =
f (a, i, j) = 1+1 A x8+1 = a), for all a E VT)
f (As is .i) = {(As f(cr, is MIA aA
for all A E VN,
f(ABP,i,j)= {(f(A,i, k), JIBS, k,
&lt; k &lt; jAA x,+1...rk Bfl —•• xk+1...z,), for
all A, B E V.
</equation>
<bodyText confidence="0.989309125">
The representation for the set of parse trees is then just
f (S, 0, n).
We now come to our third step. Suppose, for the mo-
ment, that the guards a x,+1...x, and the like, oc-
curring above, can be evaluated in some way or another.
Then we can use function f to compute the representa-
tion of the set of parse trees for sentence If we
make use of memo-functions to avoid repeated compu-
tation of a function applied to the same arguments, we
see that there are at most 0(n2) function evaluations.
- 66 -
If we represent function values by references to the set
representations rather than by the sets themselves, the
most complicated function evaluation consumes an ad-
ditional amount of storage that is 0(n): for j — i + 1
values of k we have to perform the construction of a
pair of (copies of) two references, costing a unit amount
of storage each. Therefore, the total amount of space
needed for the representation of all parse trees is 0(n3).
The evaluation of the guards a xi4.1...x, etc.
amounts exactly to solving a collection of recognition
problems. Note that a top-down parser is possible
that merges the recognition and tree-building phases,
by writing
</bodyText>
<equation confidence="0.6809228">
f (A, i, = {(A, /(a, i,i))IA &amp;quot; a A f(a, )) 0), for
all A E VN,
f (AB )3,1, j) = {( f (A, i, k), f (B k,
i&lt;k&lt;jA f(A,i, k) 0 A f(Bfl, k, j) 0),
for all A, B E V,
</equation>
<bodyText confidence="0.998966777777778">
the other cases for f being left unchanged. Note the sim-
ilarity between the recognizing part of this algorithm
and the descent recognizer of section 2. Again, this
parser is a cubic algorithm if we use memo-functions.
Another approach is to apply a bottom-up recognizer
first and derive from it a set P containing triples (13,i, j)
only if 13 x,+1...xj, and at least those triples (f3, j)
for which the guards /3 x,1 ...z, are evaluated dur-
ing the computation of f(S, 0, n) (i.e., for each deriva-
</bodyText>
<subsectionHeader confidence="0.535241">
tion S Xi...ZkA21+1•••Xn X1...Xha/3X3+1.••Xn —4*
</subsectionHeader>
<bodyText confidence="0.873841230769231">
21...X03X34.1...Xn Xi...Xn, the triples (fl,i,j) and
(A, k, j) should be in P). The simplest way to obtain
such P from our recognizer is to assume an implementa-
tion of memo-functions that enables access to the mem-
oized function results, after executing [0](0). Then one
has the disposal of the set
{(ft, i,j)1[q](i) was invocated and
(A &amp;quot; E M(01
Clearly, (,3,1, j) is only in this set if fi
Note, however, that no pairs (A --0 . )3, j) are included
in [q](i) (except if A = S&apos;). We remedy this with a
slight change of the specifications of [q] and [q], defining
tz-=. q U ini(q):
</bodyText>
<equation confidence="0.8817195">
[q](i)
{(A . fl, --• a.0 E )3 --0`
19-1(B, 0 = {(A &amp;quot;./1,.01A a.0 E VA
137 A 7 —■*
</equation>
<bodyText confidence="0.887787">
A recursive implementation of the recognition functions
now is
</bodyText>
<equation confidence="0.996651333333333">
Eql(0 = , + 1119
{(/, j)1B .c E ini(q) A (/, j) E [q](B, i)}u
1(1,1)11 EgAfinal(I))
i) = ((pop(1), j)I(I, j) E [goto(q, B)](0}U
((I, j)1(J, k) E [goto(q, B)].(DA
pop(J) E ini(q) A (1, j) E Nlilhs(J), k))
</equation>
<bodyText confidence="0.823139">
If we define, for this revised recognizer,
</bodyText>
<equation confidence="0.990378">
P = {(0,i, j)1(q}(i) was invocated and
(A a , j) E {q}(i)}U
((A, , j)l[q](i) was invocated and
(A j) E [q](i)}U
{(x1.4.1,i,i +1)10 &lt; i &lt; n),
it contains all triples that are needed in f(S, 0,n), and
we may write the forest constructing function as
f (A, i, j) = {(A, f (a , a A (a, i, j) E P}, for
all A E VN,
= {(f(A,i,k), f(11,9, k,
(A, i, k) 6 P (II t , k, j) 6 P} , for all A, B E V,
</equation>
<bodyText confidence="0.999499">
the other cases for f being left unchanged again. There
exists a representation of P in quadratic space such that
the presence or absence of an arbitrary triple can be de-
cided upon in unit time. As a result, the time complexity
of f (S, 0, n) is cubic.
</bodyText>
<sectionHeader confidence="0.999075" genericHeader="method">
7 Extended CF grammars
</sectionHeader>
<bodyText confidence="0.973063621621622">
An extended CF grammar consists of grammar rules
with regular expressions at the right hand side. Every
extended CF grammar can be translated into a normal
CF grammar by replacing each right hand side by a
regular (sub)grammar. The strong generative power is
different from CF grammars, however, as the degree of
the nodes in a derivation tree is unbounded. To apply
our recognizer directly to extended grammars, a few of
the foregoing definitions have to be revised.
As before, a grammar rule is written A --. a, but with
a now a regular expression with Na symbols (elements
of V). Defining T = 1...N. and T. = 0...N0, regular
expression a can be characterized by
1. a mapping 1;60, : rct V associating a grammar
symbol to each number.
2„ a function succa : 2T.j- mapping each num-
ber to its set of successors. The regular expression
can start with the symbols corresponding to the
numbers in succ0(0).
3, a set a. E 2T of numbers of symbols the regular
expression can end with.
Note that 0 is not associated to a symbol in V and is not
a possible element of succa(k). It can be element of 00
though, in which case there is an empty path through
the regular expression.
We define an item as a pair (A --. a, k), with the
interpretation that number k is &apos;just before the dot&apos;.
The correspondence with dotted rules is the following.
Let a = Bi....Bi, then a is a simple regular expression
characterized by c4a(k) = Bk, SUCCo(k) = {k + 1} if
0 &lt; k &lt; 1, succ0(1) = 0, and a. = {l}. Item (A a,0)
corresponds to the initial item A —0 .a and (A a, k)
to the dotted-rule item with the dot just after Bk.
The predicate final for the new kind of items is defined
by
final((A —+ a, k)) = (k E era)
Given a set q of items, we define
</bodyText>
<equation confidence="0.977292">
- 67 -
ini(q) = f(A —4 a, 0)1(B —+ )3,1) E qA
k E succo(1) A 00(k) =• Ay)
</equation>
<bodyText confidence="0.997545">
The function pop becomes set-valued and the transition
function can be defined in terms of it (remember: -4 =
q Li ini(q)):
</bodyText>
<equation confidence="0.974806166666667">
pop((A a, 1)) = ((A a, k)I1 E succ.,„(k))
goto(q, B) = ((A —+ a, k)1(ka(k) =BAIE
I E pop((A —■ a, k)))
A recursive ascent recognizer is now implemented by
191(i) = [ars+r, i)y
E ini(q) A f inal(J)A
(I, j) E (q)(1hs(J),i)}U
((1,1)11 EqAfinal(1)}
(CB, i) = j)1.1 EqAJE pop(I)A
(I , j) E Egoto(q, B)1(i)}u
1(/, k) E [goto(q, B)](i) A K E ini(g)A
K E pop(J) A (I, j) E [Clhs(J), k)}
</equation>
<bodyText confidence="0.715181666666667">
The initial state go is ((S&apos; S,0)), and a sentence
xi ...x„ is grammatical if ((S&apos; —+ S, 0), n) E [go](0). The
recognizer is deterministic if
</bodyText>
<listItem confidence="0.95634">
1. there is no shift-reduce or reduce-reduce conflict,
i.e. every state has at most one final item, and in
case it has a final item it has no items (A -4
with k E succ(j) A ib„(k) E VT.
2. for all reachable states q, q fl ini(q) = 0, and for all
</listItem>
<bodyText confidence="0.979161875">
I there is at most one J E such that J E pop(l).
In the deterministic case, the analysis of section 4 can be
repeated with one exception: extended grammar items
can not be represented by a non-terminal and an integer
that equals the number of symbols before the dot, as this
notion is irrelevant in the case of regular expressions. In
standard presentations of deterministic LR-parsing this
leads to almost unsurmountable problems [5].
</bodyText>
<sectionHeader confidence="0.99934" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.999989793103448">
We established a very simple and elegant implementa-
tion of LR(0) parsing. It is easily extended to LALR(k)
parsing by letting the functions [q] produce pairs with
final items only after inspection of the next k input sym-
bols.
The functional LR-parser provides a high-level view of
LR-parsing, compared to conventional implementations.
A case in point is the ubiquitous stack, that simply cor-
responds to the procedure stack in the functional case.
As the proof of a functional LR-parser is not hindered
by unnecessary implementation details, it can be very
compact. Nevertheless, the functional implementation
is as efficient as conventional ones. Also, the notion of
memo-functions is an important primitive for present-
ing algorithms at a level of abstraction that can not
be achieved without them, as is exemplified by this pa-
per&apos;s presentation of both the recognizers and the parse
forests.
For non-LR grammars, there is no reason to use
the complicated Tomita algorithm. If indeed non-
deterministic LR-parsers beat the Earley algorithm for
some natural language grammars, as claimed in [4], this
is because the number of LR(0) states may be smaller
than the size of /G for such grammars. Evidently, for the
grammars examined in [4] this advantage compensates
the loss of efficiency caused by the non-polynomiality
of Tomita&apos;s algorithm. The present algorithm seems to
have the possible advantage of Tomita&apos;s parser, while
being polynomial.
</bodyText>
<sectionHeader confidence="0.972944" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.999241333333333">
A considerable part of this research was done in collabo-
ration with Lex Augusteyn and Frans Krusernan Aretz.
Both are colleagues at Philips Research.
</bodyText>
<sectionHeader confidence="0.998845" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.985619103448276">
1 F.E.J. Kruseman Aretz, On a recursive ascent parser,
Information Processing Letters (1988) 29:201-206.
2 G.H. Roberts, Recursive Ascent: An LR Analog
to Recursive Descent, SIGPLAN Notices (1988)
23(8):23-29.
3 J. Hughes, Lazy Memo-Functions in Functional Pro-
gramming Languages and Computer Architecture
edited by J.-P. Jouannaud, Springer Lecture Notes
in Computer Science (1985) 201.
4 M. Tomita, Efficient Parsing for Natural Language
(Kluwer Academic Publishers, 1986).
5 P.W. Purdom and C.A. Brown, Parsing extended
LR(k) grammars, Acta Informatica (1981) 15:115-
127.
6 A.V. Aho and .1 D. Ullman, Principles of Compiler
Design (Addison-Wesley publishing company,1977)
7 A,V. Aho and J.D. Ullman, The theory of parsing,
translation, and compiling (Prentice Hall Inc. En-
glewood Cliffs N.J.,1972).
8 B.A. Shed. Observations on Context Free Parsing in
Statistical Methods in Linguistics (Stockholm (Swe-
den) 1976).
Also: Technical Report TR 12-76, Center for Re-
search in Computing Technology, Aiken Computa-
tion Laboratory, Harvard Univ., Cambridge (Mas-
sachusetts).
9 J. Earley, 1970. An Efficient Context-Free Parsing
Algorithm, Communications ACM 13(2):94-102.
- 68 -
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.292236">
<title confidence="0.9594725">Non-deterministic Recursive Ascent Parsing René Leermakers</title>
<affiliation confidence="0.915187">Philips Research Laboratories,</affiliation>
<address confidence="0.993965">P.O. Box 80.000, 5600 JA Eindhoven, The Netherlands</address>
<email confidence="0.375392">E-mailleermake@rosetta.prl.philips.n1</email>
<abstract confidence="0.9955604375">A purely functional implementation of LR-parsers is given, together with a simple correctness proof. It is presented as a generalization of the recursive descent parser. For non-LR grammars the time-complexity of our parser is cubic if the functions that constitute the parser are implemented as memo-functions, i.e. functions that memorize the results of previous invocations. Memo-functions also facilitate a simple way to construct a very compact representation of the parse forest. For LR(0) grammars, our algorithm is closely related to the recursive ascent parsers recently discovered by Kruseman Aretz [1] and Roberts [2]. Extended CF grammars (grammars with regular expressions at the right hand side) can be parsed with a simple modification of the LR-parser for normal CF grammars.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>F E J Kruseman</author>
</authors>
<title>Aretz, On a recursive ascent parser, Information Processing Letters</title>
<date>1988</date>
<pages>29--201</pages>
<contexts>
<context position="801" citStr="[1]" startWordPosition="110" endWordPosition="110">functional implementation of LR-parsers is given, together with a simple correctness proof. It is presented as a generalization of the recursive descent parser. For non-LR grammars the time-complexity of our parser is cubic if the functions that constitute the parser are implemented as memo-functions, i.e. functions that memorize the results of previous invocations. Memo-functions also facilitate a simple way to construct a very compact representation of the parse forest. For LR(0) grammars, our algorithm is closely related to the recursive ascent parsers recently discovered by Kruseman Aretz [1] and Roberts [2]. Extended CF grammars (grammars with regular expressions at the right hand side) can be parsed with a simple modification of the LR-parser for normal CF grammars. 1 Introduction In this paper we give a purely functional implementation of LR-parsers, applicable to general CF grammars. It will be obtained as a generalization of the well-known recursive descent parsing technique. For LR(0) grammars, our result implies a deterministic parser that is closely related to the recursive ascent parsers discovered by Kruseman Aretz [1] and Roberts [2]. In the general non-deterministic ca</context>
<context position="3694" citStr="[1]" startWordPosition="573" endWordPosition="573">g generative power. The extended CF grammar formalism, allowing rules to have regular expressions at the right hand side, is a useful extension, for that reason. It is not difficult to generalize our parser to cope with extended grammars, although the application of LR-parsing to extended CF grammars is well-known to be problematic [5]. We first present the recursive descent recognizer in a way that allows the desired generalization. Then we obtain the recursive ascent recognizer and its proof. If the grammar is LR(0) a few implementation tricks lead to the recursive ascent recognizer of ref. [1]. Subsequently, the time and space complexities of the recognizer are analysed, and the algorithm for constructing a cubic representation for parse forests is given. The paper ends with a. discussion of extended CF grammars. 2 Recursive descent Consider CF grammar G, with terminals VT and nonterminals VN. Let V = VN U VT. A well-known topdown parsing technique is the recursive descent parser. Recursive descent parsers consist of a number of procedures, usually one for each non-terminal. Here we present a variant that consists of functions, one for each item (dotted rule). We use the unorthodox</context>
<context position="11489" citStr="[1]" startWordPosition="2149" endWordPosition="2149"> i &lt; n then R := x1+1.; i := i 1; [q] else b:= FALSE Ii. Egoto(q,lhs(R))]; if b then if pop(R) E g then I? := pop(R) else [q] fi fi Note that these procedures do not depend on the details of the right hand side of R. Only the number of symbols before the dot is relevant for the test &amp;quot;pop(R) E q&amp;quot;. Therefore, R can be replaced by two variables X E V and an integer 1, making the following substitutions in the previous procedures: X := A;1 := lal R := pop(R) 1 := 1 — 1 pop(R) E q 101vX= S&apos; lhs(R) X After these substitutions, one gets close to the recursive ascent recognizer as it was presented in [1]. A recognizer that is virtually the same as in [Ills obtained by replacing the tail-recursive procedure [q] by an iterative loop. Then one is left with one procedure for each state. While parsing there is, at each instance, a stack of activated procedures that corresponds to the stacks that are explicitly maintained in conventional implementations of deterministic LR-parsers. 5 Complexity For LL(0) grammars the recursive descent recognizer is deterministic and works in linear time. The same is true of the ascent recognizer for LR(0) grammars. In the general, non-deterministic, case the recurs</context>
</contexts>
<marker>1</marker>
<rawString>F.E.J. Kruseman Aretz, On a recursive ascent parser, Information Processing Letters (1988) 29:201-206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G H Roberts</author>
</authors>
<title>Recursive Ascent: An LR Analog to Recursive Descent,</title>
<date>1988</date>
<journal>SIGPLAN Notices</journal>
<contexts>
<context position="817" citStr="[2]" startWordPosition="113" endWordPosition="113">mentation of LR-parsers is given, together with a simple correctness proof. It is presented as a generalization of the recursive descent parser. For non-LR grammars the time-complexity of our parser is cubic if the functions that constitute the parser are implemented as memo-functions, i.e. functions that memorize the results of previous invocations. Memo-functions also facilitate a simple way to construct a very compact representation of the parse forest. For LR(0) grammars, our algorithm is closely related to the recursive ascent parsers recently discovered by Kruseman Aretz [1] and Roberts [2]. Extended CF grammars (grammars with regular expressions at the right hand side) can be parsed with a simple modification of the LR-parser for normal CF grammars. 1 Introduction In this paper we give a purely functional implementation of LR-parsers, applicable to general CF grammars. It will be obtained as a generalization of the well-known recursive descent parsing technique. For LR(0) grammars, our result implies a deterministic parser that is closely related to the recursive ascent parsers discovered by Kruseman Aretz [1] and Roberts [2]. In the general non-deterministic case, the parser h</context>
</contexts>
<marker>2</marker>
<rawString>G.H. Roberts, Recursive Ascent: An LR Analog to Recursive Descent, SIGPLAN Notices (1988)</rawString>
</citation>
<citation valid="false">
<pages>8--23</pages>
<marker>23</marker>
<rawString>(8):23-29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hughes</author>
</authors>
<title>Lazy Memo-Functions in Functional Programming Languages and Computer Architecture edited by J.-P.</title>
<date>1985</date>
<booktitle>Lecture Notes in Computer Science</booktitle>
<pages>201</pages>
<publisher>Jouannaud, Springer</publisher>
<contexts>
<context position="1502" citStr="[3]" startWordPosition="220" endWordPosition="220">can be parsed with a simple modification of the LR-parser for normal CF grammars. 1 Introduction In this paper we give a purely functional implementation of LR-parsers, applicable to general CF grammars. It will be obtained as a generalization of the well-known recursive descent parsing technique. For LR(0) grammars, our result implies a deterministic parser that is closely related to the recursive ascent parsers discovered by Kruseman Aretz [1] and Roberts [2]. In the general non-deterministic case, the parser has cubic time complexity if the parse functions are implemented as memo-functions [3], which are functions that memorize and re-use the results of previous invocations. Memofunctions are easily implemented in most programming languages. The notion of memo-functions is also used to define an algorithm that constructs a cubic representation for the parse forest, i.e. the collection of parse trees. It has been claimed by Tomita that non-deterministic LR-parsers are useful for natural language processing. In [4] he presented a discussion about how to do nondeterministic LR-parsing, with a device called a graphstructured stack. With our parser we show that no explicit stack manipul</context>
<context position="12204" citStr="[3]" startWordPosition="2260" endWordPosition="2260">an iterative loop. Then one is left with one procedure for each state. While parsing there is, at each instance, a stack of activated procedures that corresponds to the stacks that are explicitly maintained in conventional implementations of deterministic LR-parsers. 5 Complexity For LL(0) grammars the recursive descent recognizer is deterministic and works in linear time. The same is true of the ascent recognizer for LR(0) grammars. In the general, non-deterministic, case the recursive descent and ascent recognizers need exponential time unless the functions are implemented as memo-functions [3]. Memo-functions memorize for which arguments they have been called. If a function is called with the same arguments as before, the function returns the previous result without recomputing it. In conventional programming languages memo-functions are not available, but they can easily be implemented. Devices like graphstructured stacks [4], parse matrices [7], or well-formed - 65 - substring tables [8], are in fact low-level realizations of the abstract notion of memo-functions. The complexity analysis of the recognizers is quite simple. There are 0(n) different invocations of parser functions.</context>
</contexts>
<marker>3</marker>
<rawString>J. Hughes, Lazy Memo-Functions in Functional Programming Languages and Computer Architecture edited by J.-P. Jouannaud, Springer Lecture Notes in Computer Science (1985) 201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Tomita</author>
</authors>
<title>Efficient Parsing for Natural Language</title>
<date>1986</date>
<publisher>Kluwer Academic Publishers,</publisher>
<contexts>
<context position="1930" citStr="[4]" startWordPosition="285" endWordPosition="285">by Kruseman Aretz [1] and Roberts [2]. In the general non-deterministic case, the parser has cubic time complexity if the parse functions are implemented as memo-functions [3], which are functions that memorize and re-use the results of previous invocations. Memofunctions are easily implemented in most programming languages. The notion of memo-functions is also used to define an algorithm that constructs a cubic representation for the parse forest, i.e. the collection of parse trees. It has been claimed by Tomita that non-deterministic LR-parsers are useful for natural language processing. In [4] he presented a discussion about how to do nondeterministic LR-parsing, with a device called a graphstructured stack. With our parser we show that no explicit stack manipulations are needed; they can be expressed implicitly with the use of appropriate programming language concepts. Most textbooks on parsing do not include proper correctness proofs for LR-parsers, mainly because such proofs tend to be rather involved. The theory of LRparsing should still be considered underdeveloped, for this reason. Our presentation, however, contains a surprisingly simple correctness proof. In fact, this proo</context>
<context position="12544" citStr="[4]" startWordPosition="2310" endWordPosition="2310">rministic and works in linear time. The same is true of the ascent recognizer for LR(0) grammars. In the general, non-deterministic, case the recursive descent and ascent recognizers need exponential time unless the functions are implemented as memo-functions [3]. Memo-functions memorize for which arguments they have been called. If a function is called with the same arguments as before, the function returns the previous result without recomputing it. In conventional programming languages memo-functions are not available, but they can easily be implemented. Devices like graphstructured stacks [4], parse matrices [7], or well-formed - 65 - substring tables [8], are in fact low-level realizations of the abstract notion of memo-functions. The complexity analysis of the recognizers is quite simple. There are 0(n) different invocations of parser functions. The functions call at most 0(n) other functions, that all result in a set with 0(n) elements (note that there exist only 0(n) pairs (/, j) with 1€ 10,i &lt; j &lt; n). Merging these sets to one set with no duplicates can be accomplished in 0(n2) time on a random access machine. Hence, the total time-complexity is 0(n3). The space needed for st</context>
<context position="15059" citStr="[4]" startWordPosition="2760" endWordPosition="2760"> second call is to yield 0. A remark of this kind, for the recursive descent parser, was first made in ref. [8]. The recursive descent parser then becomes virtually equivalent to a version of the standard Earley algorithm [9] that stores items A --i a.# in parse matrix entry Ts, if /3 —+&apos; instead of storing it if a --+• xs+1...xj. The space required for a parser that also calculates a parse forest, is dominated by this forest. We show in the next section that it may be compressed into a cubic amount of space. In the complexity domain our ascent parser beats its rival, Tot-rates parsing method [4], which is non-polynomial: for each integer k there exists a grammar such that the complexity of the Tomita parser is worse than nk. In addition to the complexity as a function of sentence length, one may also consider the complexity as a function of grammar size. It is clear that both time and space complexity are proportional to the number of parsing procedures. The number of procedures of the recursive descent parser is proportional to the number of items, and hence a linear function of the grammar size. The recursive ascent parser, however, contains two functions for each LR-state and is h</context>
</contexts>
<marker>4</marker>
<rawString>M. Tomita, Efficient Parsing for Natural Language (Kluwer Academic Publishers, 1986).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P W Purdom</author>
<author>C A Brown</author>
</authors>
<title>Parsing extended LR(k) grammars, Acta Informatica</title>
<date>1981</date>
<pages>15--115</pages>
<contexts>
<context position="3428" citStr="[5]" startWordPosition="530" endWordPosition="530">may have properties that enable smart implementation tricks to enhance efficiency. As we show below, the relation between LR-parsers and LR-grammars is of this kind. Especially in natural language processing, standard CF grammars are often too limited in their strong generative power. The extended CF grammar formalism, allowing rules to have regular expressions at the right hand side, is a useful extension, for that reason. It is not difficult to generalize our parser to cope with extended grammars, although the application of LR-parsing to extended CF grammars is well-known to be problematic [5]. We first present the recursive descent recognizer in a way that allows the desired generalization. Then we obtain the recursive ascent recognizer and its proof. If the grammar is LR(0) a few implementation tricks lead to the recursive ascent recognizer of ref. [1]. Subsequently, the time and space complexities of the recognizer are analysed, and the algorithm for constructing a cubic representation for parse forests is given. The paper ends with a. discussion of extended CF grammars. 2 Recursive descent Consider CF grammar G, with terminals VT and nonterminals VN. Let V = VN U VT. A well-kno</context>
<context position="24540" citStr="[5]" startWordPosition="4558" endWordPosition="4558">t most one final item, and in case it has a final item it has no items (A -4 with k E succ(j) A ib„(k) E VT. 2. for all reachable states q, q fl ini(q) = 0, and for all I there is at most one J E such that J E pop(l). In the deterministic case, the analysis of section 4 can be repeated with one exception: extended grammar items can not be represented by a non-terminal and an integer that equals the number of symbols before the dot, as this notion is irrelevant in the case of regular expressions. In standard presentations of deterministic LR-parsing this leads to almost unsurmountable problems [5]. 8 Conclusions We established a very simple and elegant implementation of LR(0) parsing. It is easily extended to LALR(k) parsing by letting the functions [q] produce pairs with final items only after inspection of the next k input symbols. The functional LR-parser provides a high-level view of LR-parsing, compared to conventional implementations. A case in point is the ubiquitous stack, that simply corresponds to the procedure stack in the functional case. As the proof of a functional LR-parser is not hindered by unnecessary implementation details, it can be very compact. Nevertheless, the f</context>
</contexts>
<marker>5</marker>
<rawString>P.W. Purdom and C.A. Brown, Parsing extended LR(k) grammars, Acta Informatica (1981) 15:115-</rawString>
</citation>
<citation valid="false">
<marker>127</marker>
<rawString>.</rawString>
</citation>
<citation valid="false">
<authors>
<author>A V Aho</author>
</authors>
<booktitle>Principles of Compiler Design (Addison-Wesley publishing company,1977)</booktitle>
<contexts>
<context position="8881" citStr="[6]" startWordPosition="1640" endWordPosition="1640">7 E goto(q, B). Hence, with the specification of [q], So may be rewritten as So = ((A -• a.B7, j)IA -0 ct./37 E qA (A 043.7, j) E [goto(q, B)](i)} - 64 - The set S1 may be rewritten using the specification of [q](C,k): = f(A --0 a.f j)I(A —0 a .fl , j) E [q](C, k)A C —• Bb A b Also, as before, 0 =• C7 implies that all items C are in ini(q), and the existence of C .Bb in ini(q) implies C B.8 E goto(q, B): = f(A a.t1, j)I(A , j) [q](C,k)A C .Bb E ini(q)A (C B.b, k) E[goto(q,B)](i)). 0 In the computation of [qo](0), functions are needed only for states in the canonical collection of LR(0) states [6] for G, i.e. for every state that can be reached from the initial state by repeated application of the got° function. Note that in general the state 0 will be among these, and that both [0](i) and [0](B, i) are empty sets for all i &gt; 0 and B E V. 4 Deterministic variants One can prove that, if the grammar is LR(0), each recognizer function for a canonical LR(0) state results in a set with at most one element. The functions for nonempty q may in this case be rephrased as [q](i) : if, for some I, IE qAf inal(I) then return ((I,1)) else if B .c E ini(q) then return [q](B,i) else if i &lt; n then ret</context>
</contexts>
<marker>6</marker>
<rawString>A.V. Aho and .1 D. Ullman, Principles of Compiler Design (Addison-Wesley publishing company,1977)</rawString>
</citation>
<citation valid="false">
<authors>
<author>V Aho A</author>
<author>J D Ullman</author>
</authors>
<title>The theory of parsing, translation, and compiling (Prentice Hall Inc. Englewood Cliffs N.J.,1972).</title>
<contexts>
<context position="12564" citStr="[7]" startWordPosition="2313" endWordPosition="2313">in linear time. The same is true of the ascent recognizer for LR(0) grammars. In the general, non-deterministic, case the recursive descent and ascent recognizers need exponential time unless the functions are implemented as memo-functions [3]. Memo-functions memorize for which arguments they have been called. If a function is called with the same arguments as before, the function returns the previous result without recomputing it. In conventional programming languages memo-functions are not available, but they can easily be implemented. Devices like graphstructured stacks [4], parse matrices [7], or well-formed - 65 - substring tables [8], are in fact low-level realizations of the abstract notion of memo-functions. The complexity analysis of the recognizers is quite simple. There are 0(n) different invocations of parser functions. The functions call at most 0(n) other functions, that all result in a set with 0(n) elements (note that there exist only 0(n) pairs (/, j) with 1€ 10,i &lt; j &lt; n). Merging these sets to one set with no duplicates can be accomplished in 0(n2) time on a random access machine. Hence, the total time-complexity is 0(n3). The space needed for storing function resul</context>
</contexts>
<marker>7</marker>
<rawString>A,V. Aho and J.D. Ullman, The theory of parsing, translation, and compiling (Prentice Hall Inc. Englewood Cliffs N.J.,1972).</rawString>
</citation>
<citation valid="true">
<authors>
<author>B A Shed</author>
</authors>
<title>Observations on Context Free Parsing in Statistical Methods in Linguistics</title>
<date>1976</date>
<tech>Also: Technical Report TR 12-76,</tech>
<institution>Center for Research in Computing Technology, Aiken Computation Laboratory, Harvard Univ.,</institution>
<location>Stockholm</location>
<contexts>
<context position="12608" citStr="[8]" startWordPosition="2321" endWordPosition="2321">nt recognizer for LR(0) grammars. In the general, non-deterministic, case the recursive descent and ascent recognizers need exponential time unless the functions are implemented as memo-functions [3]. Memo-functions memorize for which arguments they have been called. If a function is called with the same arguments as before, the function returns the previous result without recomputing it. In conventional programming languages memo-functions are not available, but they can easily be implemented. Devices like graphstructured stacks [4], parse matrices [7], or well-formed - 65 - substring tables [8], are in fact low-level realizations of the abstract notion of memo-functions. The complexity analysis of the recognizers is quite simple. There are 0(n) different invocations of parser functions. The functions call at most 0(n) other functions, that all result in a set with 0(n) elements (note that there exist only 0(n) pairs (/, j) with 1€ 10,i &lt; j &lt; n). Merging these sets to one set with no duplicates can be accomplished in 0(n2) time on a random access machine. Hence, the total time-complexity is 0(n3). The space needed for storing function results is 0(n) per invocation, i.e. 0(n2) for th</context>
<context position="14567" citStr="[8]" startWordPosition="2672" endWordPosition="2672">B,i) can only lead to calls of [p](i) with p q and to calls of NYC, k), such that either k &gt; i orC—+` BACOB. As there are only finitely many such p, C, the parser terminates. Note that both the recursive descent and ascent recognizer terminate for any grammar, if the recognizer functions are implemented as memo-functions with the property that a call of a function with some arguments yields 8 while it is under execution. For instance, if execution of [q](i) leads to a call of itself, the second call is to yield 0. A remark of this kind, for the recursive descent parser, was first made in ref. [8]. The recursive descent parser then becomes virtually equivalent to a version of the standard Earley algorithm [9] that stores items A --i a.# in parse matrix entry Ts, if /3 —+&apos; instead of storing it if a --+• xs+1...xj. The space required for a parser that also calculates a parse forest, is dominated by this forest. We show in the next section that it may be compressed into a cubic amount of space. In the complexity domain our ascent parser beats its rival, Tot-rates parsing method [4], which is non-polynomial: for each integer k there exists a grammar such that the complexity of the Tomita </context>
</contexts>
<marker>8</marker>
<rawString>B.A. Shed. Observations on Context Free Parsing in Statistical Methods in Linguistics (Stockholm (Sweden) 1976). Also: Technical Report TR 12-76, Center for Research in Computing Technology, Aiken Computation Laboratory, Harvard Univ., Cambridge (Massachusetts).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Earley</author>
</authors>
<title>An Efficient Context-Free Parsing Algorithm,</title>
<date>1970</date>
<journal>Communications ACM</journal>
<pages>13--2</pages>
<contexts>
<context position="14681" citStr="[9]" startWordPosition="2690" endWordPosition="2690">ere are only finitely many such p, C, the parser terminates. Note that both the recursive descent and ascent recognizer terminate for any grammar, if the recognizer functions are implemented as memo-functions with the property that a call of a function with some arguments yields 8 while it is under execution. For instance, if execution of [q](i) leads to a call of itself, the second call is to yield 0. A remark of this kind, for the recursive descent parser, was first made in ref. [8]. The recursive descent parser then becomes virtually equivalent to a version of the standard Earley algorithm [9] that stores items A --i a.# in parse matrix entry Ts, if /3 —+&apos; instead of storing it if a --+• xs+1...xj. The space required for a parser that also calculates a parse forest, is dominated by this forest. We show in the next section that it may be compressed into a cubic amount of space. In the complexity domain our ascent parser beats its rival, Tot-rates parsing method [4], which is non-polynomial: for each integer k there exists a grammar such that the complexity of the Tomita parser is worse than nk. In addition to the complexity as a function of sentence length, one may also consider the</context>
</contexts>
<marker>9</marker>
<rawString>J. Earley, 1970. An Efficient Context-Free Parsing Algorithm, Communications ACM 13(2):94-102. - 68 -</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>