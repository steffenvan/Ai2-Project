<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000009">
<title confidence="0.826969">
Briefly Noted
Computers and Musical Style
</title>
<author confidence="0.9718">
David Cope
</author>
<affiliation confidence="0.667395">
(University of California, Santa Cruz)
Madison, Wisconsin: A-R Editions Inc (The
Computer Music and Digital Audio Series,
</affiliation>
<bodyText confidence="0.988771949367088">
edited by John Strawn, Volume 6), 1991, xvii
+ 246 pp.
Hardbound, ISBN 0-89579-256-7, $45.95
Music, it has often been suggested, is a form
of language. If this is true, perhaps some
of the techniques of computational linguis-
tics might be profitably applied to musical
issues. In Computers and Musical Style, com-
poser David Cope describes a new way of an-
alyzing musical style, by using computer pat-
tern matching to identify characteristic mo-
tives, or short sequences of musical inter-
vals. Cope has developed an automatic com-
poser, using an ATN music grammar to re-
combine these motives, producing convinc-
ing music in the style of composers ranging
from Mozart to Gershwin.
Cope&apos;s primary motivation in this work
was a practical one: suffering from &amp;quot;com-
poser&apos;s block,&amp;quot; he felt the need for a &amp;quot;com-
poser&apos;s partner.&amp;quot; To that end, Cope has de-
veloped a series of computer programs ca-
pable of composing music in the style of
a particular composer. Drawing on the fre-
quently observed parallel between linguis-
tic phrase structure rules and the structure
underlying musical phrases, Cope defines
an ATN grammar as the basis of his auto-
matic composer. Using work by music the-
orists such as Schenker, Cope defines five
musical categories: statement, preparation,
extension, antecedent, and consequent. The
grammar governs the ways in which these
five basic categories can be combined to
form phrases. Cope creates a lexicon by ex-
tracting characteristic patterns from exist-
ing works of a given composer, and cata-
loging these patterns as to category. With
a composer-specific lexicon and ATN gram-
mar, the program is capable of randomly pro-
ducing new works in the style of that com-
poser. The program has produced works in
the styles of composers such as Bach, Mozart,
Brahms, Chopin, and Scott Joplin. Although
none of these compositions could be mis-
taken for genuine works of the composers
they are meant to emulate, the resemblance is
at times quite striking. In particular, I found
the works in the style of Brahms and Chopin
surprisingly evocative.
However, it is far from clear how the pro-
gram produced these compositions. Com-
poser Cope is clearly a convert to the joys
of Lisp hacking, and he presents a simple
version of his program virtually line by line,
including many program traces. The more
elaborate version of the program, which actu-
ally produced all the musical examples, is too
large for such treatment. Instead, Cope con-
tents himself with a vague, partial descrip-
tion of the program, leaving it quite unclear
how the program actually produced all these
interesting compositions.
The most innovative aspect of this work is
the notion that signatures, or common pat-
terns, can be automatically extracted from a
body of work. In the current implementation,
the patterns are found by comparing simple
sequences of intervals of a fixed length. Even
with such simple comparisons, some strik-
ing regularities emerge, suggesting that this
is a promising approach to the definition and
analysis of musical style.—Daniel Hardt, Uni-
versity of Pennsylvania
Daniel Hardt is a Ph.D. candidate in Compu-
tational Linguistics at the University of Penn-
sylvania. He has a Bachelor of Music in Vio-
lin Performance from the Curtis Institute of
Music.
</bodyText>
<sectionHeader confidence="0.686355" genericHeader="abstract">
Logic and Information
</sectionHeader>
<reference confidence="0.15010425">
Keith Devlin
(Colby College, Maine)
Cambridge, England: Cambridge University
Press, 1991, xii + 308 pp.
</reference>
<bodyText confidence="0.99615075">
Hardbound, ISBN 0-521-41031-4, $34.50
In Logic and Information, Keith Devlin at-
tempts to develop a theory of information
suitable for the study of cognition. It is in-
tended that the theory be amenable to all
varieties of information flow, though natural
language semantics is given special consid-
eration.
Apart from the introductory and conclud-
ing chapters, the book divides into two parts.
Chapters 2 through 5 spell out Devlin&apos;s the-
ory of information, a version of Situation
Theory. Chapters 6 through 9 then explore
the application of this theory to two areas:
mental states, perception, and action, and
natural language semantics. Devlin explicitly
</bodyText>
<page confidence="0.990529">
566
</page>
<bodyText confidence="0.995777484848485">
Briefly Noted
argues that an account of the former is re-
quired by any adequate theory of the latter,
and such concerns are evident in his seman-
tic treatment of natural language.
The version of Situation Theory presented
is the most complete and accessible pub-
lished since Barwise and Perry&apos;s original
work, including many of the advances that
have been made in recent years. As Devlin
is quick to acknowledge, however, it is not
a definitive statement of Situation Theory
per se, which continues to evolve. Unfortu-
nately, Devlin does not highlight areas of Sit-
uation Theory where opinions differ, and it
is difficult to distinguish what is the received
view from Devlin&apos;s own persuasions. Fur-
thermore, while Devlin does attempt to mo-
tivate all aspects of his theory, the motivation
is not always convincing.
With regard to natural language semantics,
Devlin considers the meanings of both indi-
vidual words and sentences, as well as the
impact of various classes of utterance. Fur-
ther application of the theory is given via
the specific consideration of quantification,
negation, conditionals, speaker&apos;s intentions,
and paradox and ambiguity. Devlin projects
his attempts at these areas as first approxi-
mations. Nevertheless his accounts do show
promise and, I think, merit more discussion
than is given.—Richard Cooper, University Col-
lege London
</bodyText>
<subsectionHeader confidence="0.96025">
Structures for Semantics
</subsectionHeader>
<bodyText confidence="0.94502780952381">
Fred Landman
(Cornell University)
Dordrecht: Kluwer Academic Publishers
(Studies in Linguistics and Philosophy 45,
edited by Gennaro Chierchia, Pauline
Jacobson, and Francis J. Pelletier), 1991, x +
366 pp.
Hardbound, ISBN 0-7923-1239-2, $110.00,
£67.00, Dfl 200.00
&amp;quot;Structures for Semantics offers an advanced
course in logical and mathematical tech-
niques and structures that are used in seman-
tics, in relation to their semantic applications.
The book helps students with a background
in semantics to develop their skills of formal-
ization and it makes research in semantics ac-
cessible. Workers in other disciplines will use
it to discover more about the role of formal
modelling in current semantic research, and
about semantics itself.&amp;quot;—From the publisher&apos;s
announcement
</bodyText>
<table confidence="0.877778444444444">
Partitioned Representations: A Study in
Mental Representation, Language Un-
derstanding and Linguistic Structure
John Dinsmore
(Southern Illinois University at Carbondale)
Dordrecht: Kluwer Academic Publishers
(Studies in Cognitive Systems, edited by
James H. Fetzer, Volume 8), 1991, xvii + 331
PP.
</table>
<bodyText confidence="0.986254666666667">
Hardbound, ISBN 0-7923-1348-8, $59.50,
£42.00, Dfl 125.00
Dinsmore proposes a formalism for mental
representations divided into locally consis-
tent domains called spaces. The theory does
not specify the representation within the
spaces; Dinsmore relies primarily on first-
order logic, but also employs a semantic
network. The primary application area is
language and in this respect the work can
be regarded as a formalization of Faucon-
nier&apos;s (1985) mental spaces, sharing a con-
cern with presupposition, counterfactuals,
and aspect. Correspondences to natural de-
duction, Kamp&apos;s (1981) discourse represen-
tation theory, frames, belief spaces, context-
layered databases, and mental models are
also outlined.
The approach views language comprehen-
sion as the firing of a series of produc-
tion rules that project an utterance through
various intermediate representations or pro-
jections. Intermediate projections are mix-
tures of semantic structures and as-yet-
unprocessed surface fragments. This simpli-
fication allows Dinsmore to focus on the con-
struction and maintenance of spaces as a
sentence is processed. Rules perform three
classes of operations: Con textualization makes
decisions about the global placement of in-
put forms on the basis of the pragmatic set-
ting. Distribution allocates structures already
in one space to other spaces, relying more
heavily on surface cues. Parochial processing
includes more familiar interpretation pro-
cesses such as definite reference determina-
tion, lexical and structural disambiguation,
and metonymy and metaphor interpretation.
The power of the theory, however, derives
largely from the restriction that these pro-
cesses are confined to operation solely within
single spaces.
The book can be seen as making two pri-
mary contributions. First, it synthesizes loose
ideas that have been floating around in Al
</bodyText>
<page confidence="0.984706">
567
</page>
<note confidence="0.528662">
Computational Linguistics Volume 18, Number 4
</note>
<bodyText confidence="0.996623419354839">
and cognitive science for some time, and
which many theories and systems have al-
ready incorporated in specialized form. On
the whole Dinsmore does a good job of
sketching the relationships to other frame-
works. Second, it proposes a specific architec-
ture and set of production rules for process-
ing a variety of language constructs. Since
the major part of the book is concerned
with these language examples, it is some-
what frustrating that correspondences, dif-
ferences, and extensions to Fauconnier&apos;s the-
ory are not specifically clarified. Interestingly,
connections to the line of work on represent-
ing existence by Meinong (1904/1960), Par-
sons (1980), Lambert (1983), Rapaport (1985),
and Hirst (1989, 1991) are also missing,
though overlapping concerns are addressed
(we might profitably think of spaces as hold-
ing cells for nuclear relations, with extranu-
clear relations being those that span spaces).
The book is well written and Dinsmore&apos;s
style is generally easy to read. The rules and
processes are illustrated through many ex-
amples. All the more technical and formal
discussion is confined to the last three chap-
ters, which form an appendix. This arrange-
ment makes the book more difficult for the
computer scientist, but probably improves its
readability for linguists.—Dekai Wu, Univer-
sity of Toronto
</bodyText>
<sectionHeader confidence="0.964897" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.880524583333333">
Fauconnier, Gilles (1985). Mental Spaces.
Cambridge, MA: The MIT Press.
Hirst, Graeme (1989). &amp;quot;Ontological
assumptions in knowledge
representation.&amp;quot; In Proceedings, 1st
International Conference on Principles of
Knowledge Representation and Reasoning.
Toronto, May 1989. Morgan Kaufmann,
157-169.
Hirst, Graeme (1991). &amp;quot;Existence
assumptions in knowledge
representation.&amp;quot; Artificial Intelligence, 49,
199-242.
Kamp, Hans (1981). &amp;quot;A theory of truth and
semantic representation.&amp;quot; In Truth,
Interpretation, and Information (Selected
Papers from the Third Amsterdam
Symposium), (Groningen-Amsterdam
Studies in Semantics), edited by Jeroen
A. G. Groenendijk, Theo M. V. Janssen,
and Martin B. J. Stokhof, 1-41. Foris.
Lambert, Karel (1983). Meinong and the
Principle of Independence. Cambridge
University Press.
Meinong, Alexius (1904/1960). &amp;quot;Ober
Gegenstandstheorie&amp;quot;. In Alexius Meinong
(ed.), Untersuchungen zur
Gegenstandstheorie und Psychologie. Leipzig:
Barth. (In English as &amp;quot;The theory of
objects&amp;quot; (Isaac Levi, D. B. Terrell, and
Roderick Milton Chisholm, trans.), in
Roderick Milton Chisholm (ed.), Realism
and the background of phenomenology.
Glencoe, IL: Free Press, 1960, 76-117.)‘
Parsons, Terence (1980). Nonexistent Objects.
Yale University Press.
Rapaport, William J. (1985). &amp;quot;Meinongian
semantics for propositional semantic
networks.&amp;quot; In Proceedings, 23rd Annual
Meeting of the Association for Computational
Linguistics. Chicago, IL, 43-48.
Connectionist Natural Language
Processing: Readings from Connection
Science
Noel Sharkey (editor)
(University of Exeter)
Dordrecht: Kluwer Academic Publishers,
1992, ix 375 pp.
</reference>
<bodyText confidence="0.991937333333333">
Hardbound, ISBN 0-7923-1542-1, $88.50,
£51.50, Dfl 150.00
Seventeen papers on connectionist natural
language processing that were originally
published in the journal Connection Science
are reprinted in this volume:
</bodyText>
<reference confidence="0.47106880952381">
Catherine L. Harris &amp;quot;Connectionism and
cognitive linguistics&amp;quot;
John Rager and George Berg &amp;quot;A connectionist
model of motion and government in
Chomsky&apos;s government-binding theory&amp;quot;
David J. Chalmers &amp;quot;Syntactic transformations
on distributed representations&amp;quot;
S.M. Lucas and RI. Damper &amp;quot;Syntactic neural
networks&amp;quot;
Gerard Kempen and Theo Vosse &amp;quot;Incremental
syntactic tree formation in human
sentence processing: A cognitive
architecture based on activation
decay and simulated annealing&amp;quot;
Stefan Wermter and Wendy G. Lehnert &amp;quot;A
hybrid symbolic/connectionist model for
noun phrase understanding&amp;quot;
Stan C. Kwasny and Kanaan A. Faisal
&amp;quot;Connectionism and determinism in
a syntactic parser&amp;quot;
Peter J. Wyard and Charles Nightingale &amp;quot;A
</reference>
<page confidence="0.996226">
568
</page>
<bodyText confidence="0.985443">
Briefly Noted
single layer higher order neural net and
its application to context free grammar
recognition&amp;quot;
</bodyText>
<reference confidence="0.956339257142857">
Robert B. Allen &amp;quot;Connectionist language
users&amp;quot;
Risto Miikkulainen &amp;quot;Script recognition with
hierarchical feature maps&amp;quot;
Guenbee Lee, Margot Flowers, and Michael Dyer
&amp;quot;Learning distributed representations of
conceptual knowledge and their
application to script-based story
processing&amp;quot;
Suzanne M. Mannes and Stephanie M. Doane
&amp;quot;A hybrid model of script generation: Or
getting the best from both worlds&amp;quot;
Lorraine F.R. Karen &amp;quot;Identification of topical
entities in discourse: A connectionist
approach to attentional mechanisms in
language&amp;quot;
Mary Hare &amp;quot;The role of similarity in
Hungarian vowel harmony: A
connectionist account&amp;quot;
Robert F. Port &amp;quot;Representation and
recognition of temporal patterns&amp;quot;
Michael Gasser and Chan-Do Lee &amp;quot;Networks
that learn about phonological feature
persistence&amp;quot;
WA. Ainsworth and N.P. Warren &amp;quot;Pronuncia-
tion of digit sequences in text-to-speech
systems&amp;quot;
The Compact Disk Handbook (Second
Edition)
Ken C. Pohlmann
(University of Miami)
Madison, Wisconsin: A-R Editions Inc (The
Computer Music and Digital Audio Series,
edited by John Strawn, Volume 5) 1992, xv
+ 349 pp.
</reference>
<bodyText confidence="0.997798266666667">
Hardbound, ISBN 0-89579-301-6, $49.95;
paperbound, ISBN 0-89579-300-8, $34.95
Now that you&apos;ve got the first CD-ROM from
the ACL Data Collection Initiative spinning
happily in its drive and visions of user in-
terfaces for CDs are dancing in your head,
maybe it&apos;s time to open up the black box and
learn a bit about how CDs actually work.
While the emphasis, obviously, is on audio
CDs, Pohlmann&apos;s comprehensive, up-to-the-
minute handbook covers all aspects of all
types of CDs, including data formats, en-
coding, error correction, disk manufacturing,
and the architecture of drives and players.—
G.H.
</bodyText>
<page confidence="0.997579">
569
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.999091">Briefly Noted Computers and Musical Style</title>
<author confidence="0.999914">David Cope</author>
<affiliation confidence="0.998984">(University of California, Santa Cruz)</affiliation>
<address confidence="0.895312">Madison, Wisconsin: A-R Editions Inc (The</address>
<note confidence="0.78019775">Computer Music and Digital Audio Series, edited by John Strawn, Volume 6), 1991, xvii + 246 pp. Hardbound, ISBN 0-89579-256-7, $45.95</note>
<abstract confidence="0.986370105263158">Music, it has often been suggested, is a form of language. If this is true, perhaps some of the techniques of computational linguistics might be profitably applied to musical In and Musical Style, composer David Cope describes a new way of analyzing musical style, by using computer pattern matching to identify characteristic motives, or short sequences of musical intervals. Cope has developed an automatic composer, using an ATN music grammar to recombine these motives, producing convincing music in the style of composers ranging from Mozart to Gershwin. Cope&apos;s primary motivation in this work was a practical one: suffering from &amp;quot;composer&apos;s block,&amp;quot; he felt the need for a &amp;quot;composer&apos;s partner.&amp;quot; To that end, Cope has developed a series of computer programs capable of composing music in the style of a particular composer. Drawing on the frequently observed parallel between linguistic phrase structure rules and the structure underlying musical phrases, Cope defines an ATN grammar as the basis of his automatic composer. Using work by music theorists such as Schenker, Cope defines five musical categories: statement, preparation, extension, antecedent, and consequent. The grammar governs the ways in which these five basic categories can be combined to form phrases. Cope creates a lexicon by extracting characteristic patterns from existing works of a given composer, and cataloging these patterns as to category. With a composer-specific lexicon and ATN grammar, the program is capable of randomly producing new works in the style of that composer. The program has produced works in the styles of composers such as Bach, Mozart, Brahms, Chopin, and Scott Joplin. Although none of these compositions could be mistaken for genuine works of the composers they are meant to emulate, the resemblance is at times quite striking. In particular, I found the works in the style of Brahms and Chopin surprisingly evocative. However, it is far from clear how the program produced these compositions. Composer Cope is clearly a convert to the joys of Lisp hacking, and he presents a simple version of his program virtually line by line, including many program traces. The more elaborate version of the program, which actually produced all the musical examples, is too large for such treatment. Instead, Cope contents himself with a vague, partial description of the program, leaving it quite unclear how the program actually produced all these interesting compositions. The most innovative aspect of this work is the notion that signatures, or common patterns, can be automatically extracted from a body of work. In the current implementation, the patterns are found by comparing simple sequences of intervals of a fixed length. Even with such simple comparisons, some striking regularities emerge, suggesting that this is a promising approach to the definition and of musical Hardt, University of Pennsylvania Hardt a Ph.D. candidate in Computational Linguistics at the University of Pennsylvania. He has a Bachelor of Music in Violin Performance from the Curtis Institute of Music.</abstract>
<title confidence="0.979304">Logic and Information</title>
<author confidence="0.994119">Keith Devlin</author>
<affiliation confidence="0.8177705">(Colby College, Maine) Cambridge, England: Cambridge University</affiliation>
<address confidence="0.581535">Press, 1991, xii + 308 pp. Hardbound, ISBN 0-521-41031-4, $34.50</address>
<abstract confidence="0.9839364375">and Information, Devlin attempts to develop a theory of information suitable for the study of cognition. It is intended that the theory be amenable to all varieties of information flow, though natural language semantics is given special consideration. Apart from the introductory and concluding chapters, the book divides into two parts. Chapters 2 through 5 spell out Devlin&apos;s theory of information, a version of Situation Theory. Chapters 6 through 9 then explore the application of this theory to two areas: mental states, perception, and action, and natural language semantics. Devlin explicitly 566 Briefly Noted argues that an account of the former is required by any adequate theory of the latter, and such concerns are evident in his semantic treatment of natural language. The version of Situation Theory presented is the most complete and accessible published since Barwise and Perry&apos;s original work, including many of the advances that have been made in recent years. As Devlin is quick to acknowledge, however, it is not a definitive statement of Situation Theory per se, which continues to evolve. Unfortunately, Devlin does not highlight areas of Situation Theory where opinions differ, and it is difficult to distinguish what is the received view from Devlin&apos;s own persuasions. Furthermore, while Devlin does attempt to motivate all aspects of his theory, the motivation is not always convincing. With regard to natural language semantics, Devlin considers the meanings of both individual words and sentences, as well as the impact of various classes of utterance. Further application of the theory is given via the specific consideration of quantification, negation, conditionals, speaker&apos;s intentions, and paradox and ambiguity. Devlin projects his attempts at these areas as first approximations. Nevertheless his accounts do show promise and, I think, merit more discussion is Cooper, University Col-</abstract>
<title confidence="0.7980755">lege London Structures for Semantics</title>
<author confidence="0.99968">Fred Landman</author>
<affiliation confidence="0.8721405">(Cornell University) Dordrecht: Kluwer Academic Publishers</affiliation>
<note confidence="0.7639952">(Studies in Linguistics and Philosophy 45, edited by Gennaro Chierchia, Pauline Jacobson, and Francis J. Pelletier), 1991, x + 366 pp. Hardbound, ISBN 0-7923-1239-2, $110.00,</note>
<address confidence="0.39031">67.00, Dfl 200.00</address>
<abstract confidence="0.993549083333333">for Semantics an advanced course in logical and mathematical techniques and structures that are used in semantics, in relation to their semantic applications. The book helps students with a background in semantics to develop their skills of formalization and it makes research in semantics accessible. Workers in other disciplines will use it to discover more about the role of formal modelling in current semantic research, and semantics the publisher&apos;s announcement</abstract>
<title confidence="0.619751666666667">Partitioned Representations: A Study in Mental Representation, Language Understanding and Linguistic Structure</title>
<author confidence="0.999226">John Dinsmore</author>
<affiliation confidence="0.987426">(Southern Illinois University at Carbondale)</affiliation>
<title confidence="0.4495865">Dordrecht: Kluwer Academic Publishers (Studies in Cognitive Systems, edited by</title>
<affiliation confidence="0.417873">PP.</affiliation>
<address confidence="0.50999">Hardbound, ISBN 0-7923-1348-8, $59.50, £42.00, Dfl 125.00</address>
<abstract confidence="0.996024723684211">Dinsmore proposes a formalism for mental representations divided into locally consisdomains called theory does not specify the representation within the spaces; Dinsmore relies primarily on firstorder logic, but also employs a semantic network. The primary application area is language and in this respect the work can be regarded as a formalization of Fauconnier&apos;s (1985) mental spaces, sharing a concern with presupposition, counterfactuals, and aspect. Correspondences to natural deduction, Kamp&apos;s (1981) discourse representation theory, frames, belief spaces, contextlayered databases, and mental models are also outlined. The approach views language comprehension as the firing of a series of producrules that utterance through intermediate representations or proprojections are mixtures of semantic structures and as-yetunprocessed surface fragments. This simplification allows Dinsmore to focus on the construction and maintenance of spaces as a sentence is processed. Rules perform three of operations: textualization decisions about the global placement of input forms on the basis of the pragmatic setstructures already in one space to other spaces, relying more on surface cues. processing includes more familiar interpretation processes such as definite reference determination, lexical and structural disambiguation, and metonymy and metaphor interpretation. The power of the theory, however, derives largely from the restriction that these processes are confined to operation solely within single spaces. The book can be seen as making two primary contributions. First, it synthesizes loose ideas that have been floating around in Al 567 Computational Linguistics Volume 18, Number 4 and cognitive science for some time, and which many theories and systems have already incorporated in specialized form. On the whole Dinsmore does a good job of sketching the relationships to other frameworks. Second, it proposes a specific architecture and set of production rules for processing a variety of language constructs. Since the major part of the book is concerned with these language examples, it is somewhat frustrating that correspondences, differences, and extensions to Fauconnier&apos;s theory are not specifically clarified. Interestingly, connections to the line of work on representing existence by Meinong (1904/1960), Parsons (1980), Lambert (1983), Rapaport (1985), and Hirst (1989, 1991) are also missing, though overlapping concerns are addressed (we might profitably think of spaces as holdcells for with extranubeing those that span spaces). The book is well written and Dinsmore&apos;s style is generally easy to read. The rules and processes are illustrated through many examples. All the more technical and formal discussion is confined to the last three chapters, which form an appendix. This arrangement makes the book more difficult for the computer scientist, but probably improves its for linguists.—Dekai University of Toronto</abstract>
<note confidence="0.869717">References Gilles (1985). Spaces. Cambridge, MA: The MIT Press. Hirst, Graeme (1989). &amp;quot;Ontological assumptions in knowledge In 1st International Conference on Principles of Knowledge Representation and Reasoning. Toronto, May 1989. Morgan Kaufmann, 157-169. Hirst, Graeme (1991). &amp;quot;Existence assumptions in knowledge Intelligence, 199-242. Kamp, Hans (1981). &amp;quot;A theory of truth and</note>
<title confidence="0.75949675">representation.&amp;quot; In Interpretation, and Information (Selected Papers from the Third Amsterdam Studies in Semantics), edited by Jeroen</title>
<author confidence="0.951983">A G Groenendijk</author>
<author confidence="0.951983">Theo M V Janssen</author>
<note confidence="0.554819">and Martin B. J. Stokhof, 1-41. Foris. Karel (1983). and the</note>
<affiliation confidence="0.7771135">of Independence. University Press.</affiliation>
<address confidence="0.5852005">Meinong, Alexius (1904/1960). &amp;quot;Ober Gegenstandstheorie&amp;quot;. In Alexius Meinong</address>
<email confidence="0.384674">zur</email>
<degree confidence="0.779687">und Psychologie. Barth. (In English as &amp;quot;The theory of objects&amp;quot; (Isaac Levi, D. B. Terrell, and Roderick Milton Chisholm, trans.), in</degree>
<author confidence="0.340951">Milton Chisholm</author>
<note confidence="0.846773444444444">and the background of phenomenology. Glencoe, IL: Free Press, 1960, 76-117.)‘ Terence (1980). Objects. Yale University Press. Rapaport, William J. (1985). &amp;quot;Meinongian semantics for propositional semantic In 23rd Annual Meeting of the Association for Computational IL, 43-48.</note>
<title confidence="0.548845333333333">Connectionist Natural Language Readings from Science</title>
<author confidence="0.998052">Noel Sharkey</author>
<affiliation confidence="0.99287">(University of Exeter) Dordrecht: Kluwer Academic Publishers,</affiliation>
<address confidence="0.919974333333333">ix 375 Hardbound, ISBN 0-7923-1542-1, $88.50, £51.50, Dfl 150.00</address>
<abstract confidence="0.979514245614035">Seventeen papers on connectionist natural language processing that were originally in the journal Science are reprinted in this volume: L. Harris and cognitive linguistics&amp;quot; Rager and George Berg connectionist model of motion and government in Chomsky&apos;s government-binding theory&amp;quot; J. Chalmers transformations on distributed representations&amp;quot; Lucas and RI. Damper neural networks&amp;quot; Kempen and Theo Vosse syntactic tree formation in human sentence processing: A cognitive architecture based on activation decay and simulated annealing&amp;quot; Wermter and Wendy G. Lehnert hybrid symbolic/connectionist model for noun phrase understanding&amp;quot; Stan C. Kwasny and Kanaan A. Faisal &amp;quot;Connectionism and determinism in a syntactic parser&amp;quot; and Charles Nightingale 568 Briefly Noted single layer higher order neural net and its application to context free grammar recognition&amp;quot; B. Allen language users&amp;quot; Miikkulainen recognition with hierarchical feature maps&amp;quot; Guenbee Lee, Margot Flowers, and Michael Dyer &amp;quot;Learning distributed representations of conceptual knowledge and their application to script-based story processing&amp;quot; Suzanne M. Mannes and Stephanie M. Doane &amp;quot;A hybrid model of script generation: Or getting the best from both worlds&amp;quot; F.R. Karen of topical entities in discourse: A connectionist approach to attentional mechanisms in language&amp;quot; Hare role of similarity in Hungarian vowel harmony: A connectionist account&amp;quot; F. Port and recognition of temporal patterns&amp;quot; Gasser and Chan-Do Lee that learn about phonological feature persistence&amp;quot; Ainsworth and N.P. Warren &amp;quot;Pronunciation of digit sequences in text-to-speech systems&amp;quot;</abstract>
<title confidence="0.84167">The Compact Disk Handbook (Second Edition)</title>
<author confidence="0.999823">Ken C Pohlmann</author>
<affiliation confidence="0.999208">(University of Miami)</affiliation>
<address confidence="0.930518">Madison, Wisconsin: A-R Editions Inc (The</address>
<note confidence="0.809659833333333">Computer Music and Digital Audio Series, edited by John Strawn, Volume 5) 1992, xv + 349 pp. Hardbound, ISBN 0-89579-301-6, $49.95; paperbound, ISBN 0-89579-300-8, $34.95 Now that you&apos;ve got the first CD-ROM from</note>
<abstract confidence="0.989050333333333">the ACL Data Collection Initiative spinning happily in its drive and visions of user interfaces for CDs are dancing in your head, maybe it&apos;s time to open up the black box and learn a bit about how CDs actually work. While the emphasis, obviously, is on audio CDs, Pohlmann&apos;s comprehensive, up-to-theminute handbook covers all aspects of all types of CDs, including data formats, encoding, error correction, disk manufacturing, and the architecture of drives and players.— G.H.</abstract>
<intro confidence="0.722584">569</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Keith Devlin</author>
</authors>
<title>Colby College,</title>
<date>1991</date>
<journal>xii +</journal>
<volume>308</volume>
<pages>pp.</pages>
<publisher>Cambridge University Press,</publisher>
<location>Maine) Cambridge, England:</location>
<marker>Devlin, 1991</marker>
<rawString>Keith Devlin (Colby College, Maine) Cambridge, England: Cambridge University Press, 1991, xii + 308 pp.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gilles Fauconnier</author>
</authors>
<title>Mental Spaces.</title>
<date>1985</date>
<publisher>The MIT Press.</publisher>
<location>Cambridge, MA:</location>
<marker>Fauconnier, 1985</marker>
<rawString>Fauconnier, Gilles (1985). Mental Spaces. Cambridge, MA: The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graeme Hirst</author>
</authors>
<title>Ontological assumptions in knowledge representation.&amp;quot;</title>
<date>1989</date>
<booktitle>In Proceedings, 1st International Conference on Principles of Knowledge Representation and Reasoning.</booktitle>
<pages>157--169</pages>
<publisher>Morgan Kaufmann,</publisher>
<location>Toronto,</location>
<marker>Hirst, 1989</marker>
<rawString>Hirst, Graeme (1989). &amp;quot;Ontological assumptions in knowledge representation.&amp;quot; In Proceedings, 1st International Conference on Principles of Knowledge Representation and Reasoning. Toronto, May 1989. Morgan Kaufmann, 157-169.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graeme Hirst</author>
</authors>
<title>Existence assumptions in knowledge representation.&amp;quot;</title>
<date>1991</date>
<journal>Artificial Intelligence,</journal>
<volume>49</volume>
<pages>199--242</pages>
<marker>Hirst, 1991</marker>
<rawString>Hirst, Graeme (1991). &amp;quot;Existence assumptions in knowledge representation.&amp;quot; Artificial Intelligence, 49, 199-242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans Kamp</author>
</authors>
<title>A theory of truth and semantic representation.&amp;quot; In Truth, Interpretation, and Information (Selected Papers from the Third Amsterdam Symposium),</title>
<date>1981</date>
<journal>Groningen-Amsterdam Studies</journal>
<pages>1--41</pages>
<publisher>Foris.</publisher>
<note>in Semantics), edited by</note>
<marker>Kamp, 1981</marker>
<rawString>Kamp, Hans (1981). &amp;quot;A theory of truth and semantic representation.&amp;quot; In Truth, Interpretation, and Information (Selected Papers from the Third Amsterdam Symposium), (Groningen-Amsterdam Studies in Semantics), edited by Jeroen A. G. Groenendijk, Theo M. V. Janssen, and Martin B. J. Stokhof, 1-41. Foris.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karel Lambert</author>
</authors>
<title>Meinong and the Principle of Independence.</title>
<date>1983</date>
<publisher>Cambridge University Press.</publisher>
<marker>Lambert, 1983</marker>
<rawString>Lambert, Karel (1983). Meinong and the Principle of Independence. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Meinong</author>
</authors>
<title>Alexius (1904/1960). &amp;quot;Ober Gegenstandstheorie&amp;quot;. In Alexius Meinong (ed.), Untersuchungen zur Gegenstandstheorie und Psychologie. Leipzig: Barth. (In English as &amp;quot;The theory of objects&amp;quot;</title>
<date>1960</date>
<pages>76--117</pages>
<editor>(Isaac Levi, D. B. Terrell, and Roderick Milton Chisholm, trans.), in Roderick Milton Chisholm (ed.),</editor>
<publisher>Free Press,</publisher>
<location>Glencoe, IL:</location>
<marker>Meinong, 1960</marker>
<rawString>Meinong, Alexius (1904/1960). &amp;quot;Ober Gegenstandstheorie&amp;quot;. In Alexius Meinong (ed.), Untersuchungen zur Gegenstandstheorie und Psychologie. Leipzig: Barth. (In English as &amp;quot;The theory of objects&amp;quot; (Isaac Levi, D. B. Terrell, and Roderick Milton Chisholm, trans.), in Roderick Milton Chisholm (ed.), Realism and the background of phenomenology. Glencoe, IL: Free Press, 1960, 76-117.)‘</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terence Parsons</author>
</authors>
<title>Nonexistent Objects.</title>
<date>1980</date>
<publisher>Yale University Press.</publisher>
<marker>Parsons, 1980</marker>
<rawString>Parsons, Terence (1980). Nonexistent Objects. Yale University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William J Rapaport</author>
</authors>
<title>Meinongian semantics for propositional semantic networks.&amp;quot;</title>
<date>1985</date>
<booktitle>In Proceedings, 23rd Annual Meeting of the Association for Computational Linguistics.</booktitle>
<pages>43--48</pages>
<location>Chicago, IL,</location>
<marker>Rapaport, 1985</marker>
<rawString>Rapaport, William J. (1985). &amp;quot;Meinongian semantics for propositional semantic networks.&amp;quot; In Proceedings, 23rd Annual Meeting of the Association for Computational Linguistics. Chicago, IL, 43-48.</rawString>
</citation>
<citation valid="false">
<booktitle>Connectionist Natural Language Processing: Readings from Connection Science</booktitle>
<marker></marker>
<rawString>Connectionist Natural Language Processing: Readings from Connection Science</rawString>
</citation>
<citation valid="false">
<date>1992</date>
<pages>375</pages>
<editor>Noel Sharkey (editor)</editor>
<publisher>Kluwer Academic Publishers,</publisher>
<institution>(University of Exeter)</institution>
<location>Dordrecht:</location>
<marker>1992</marker>
<rawString>Noel Sharkey (editor) (University of Exeter) Dordrecht: Kluwer Academic Publishers, 1992, ix 375 pp.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Catherine L Harris</author>
</authors>
<title>Connectionism and cognitive linguistics&amp;quot;</title>
<marker>Harris, </marker>
<rawString>Catherine L. Harris &amp;quot;Connectionism and cognitive linguistics&amp;quot;</rawString>
</citation>
<citation valid="false">
<authors>
<author>John Rager</author>
<author>George Berg</author>
</authors>
<title>A connectionist model of motion and government in Chomsky&apos;s government-binding theory&amp;quot;</title>
<marker>Rager, Berg, </marker>
<rawString>John Rager and George Berg &amp;quot;A connectionist model of motion and government in Chomsky&apos;s government-binding theory&amp;quot; David J. Chalmers &amp;quot;Syntactic transformations on distributed representations&amp;quot; S.M. Lucas and RI. Damper &amp;quot;Syntactic neural networks&amp;quot;</rawString>
</citation>
<citation valid="false">
<authors>
<author>Gerard Kempen</author>
</authors>
<title>and Theo Vosse &amp;quot;Incremental syntactic tree formation in human sentence processing: A cognitive architecture based on activation decay and simulated annealing&amp;quot;</title>
<marker>Kempen, </marker>
<rawString>Gerard Kempen and Theo Vosse &amp;quot;Incremental syntactic tree formation in human sentence processing: A cognitive architecture based on activation decay and simulated annealing&amp;quot;</rawString>
</citation>
<citation valid="false">
<authors>
<author>Stefan Wermter</author>
<author>G Wendy</author>
</authors>
<title>Lehnert &amp;quot;A hybrid symbolic/connectionist model for noun phrase understanding&amp;quot;</title>
<marker>Wermter, Wendy, </marker>
<rawString>Stefan Wermter and Wendy G. Lehnert &amp;quot;A hybrid symbolic/connectionist model for noun phrase understanding&amp;quot;</rawString>
</citation>
<citation valid="false">
<authors>
<author>Stan C Kwasny</author>
<author>A Kanaan</author>
</authors>
<title>Faisal &amp;quot;Connectionism and determinism in a syntactic parser&amp;quot;</title>
<marker>Kwasny, Kanaan, </marker>
<rawString>Stan C. Kwasny and Kanaan A. Faisal &amp;quot;Connectionism and determinism in a syntactic parser&amp;quot;</rawString>
</citation>
<citation valid="false">
<authors>
<author>J Peter</author>
</authors>
<title>Wyard and Charles Nightingale &amp;quot;A</title>
<marker>Peter, </marker>
<rawString>Peter J. Wyard and Charles Nightingale &amp;quot;A</rawString>
</citation>
<citation valid="false">
<authors>
<author>Robert B Allen</author>
</authors>
<title>Connectionist language users&amp;quot;</title>
<marker>Allen, </marker>
<rawString>Robert B. Allen &amp;quot;Connectionist language users&amp;quot;</rawString>
</citation>
<citation valid="false">
<authors>
<author>Risto Miikkulainen</author>
</authors>
<title>Script recognition with hierarchical feature maps&amp;quot;</title>
<marker>Miikkulainen, </marker>
<rawString>Risto Miikkulainen &amp;quot;Script recognition with hierarchical feature maps&amp;quot;</rawString>
</citation>
<citation valid="false">
<authors>
<author>Guenbee Lee</author>
<author>Margot Flowers</author>
<author>Michael Dyer</author>
</authors>
<title>Learning distributed representations of conceptual knowledge and their application to script-based story processing&amp;quot;</title>
<marker>Lee, Flowers, Dyer, </marker>
<rawString>Guenbee Lee, Margot Flowers, and Michael Dyer &amp;quot;Learning distributed representations of conceptual knowledge and their application to script-based story processing&amp;quot;</rawString>
</citation>
<citation valid="false">
<authors>
<author>Suzanne M Mannes</author>
<author>Stephanie M Doane</author>
</authors>
<title>A hybrid model of script generation: Or getting the best from both worlds&amp;quot;</title>
<marker>Mannes, Doane, </marker>
<rawString>Suzanne M. Mannes and Stephanie M. Doane &amp;quot;A hybrid model of script generation: Or getting the best from both worlds&amp;quot;</rawString>
</citation>
<citation valid="false">
<authors>
<author>Lorraine F R Karen</author>
</authors>
<title>Identification of topical entities in discourse: A connectionist approach to attentional mechanisms in language&amp;quot;</title>
<marker>Karen, </marker>
<rawString>Lorraine F.R. Karen &amp;quot;Identification of topical entities in discourse: A connectionist approach to attentional mechanisms in language&amp;quot;</rawString>
</citation>
<citation valid="false">
<authors>
<author>Mary Hare</author>
</authors>
<title>The role of similarity in Hungarian vowel harmony: A connectionist account&amp;quot;</title>
<marker>Hare, </marker>
<rawString>Mary Hare &amp;quot;The role of similarity in Hungarian vowel harmony: A connectionist account&amp;quot;</rawString>
</citation>
<citation valid="false">
<authors>
<author>Robert F Port</author>
</authors>
<title>Representation and recognition of temporal patterns&amp;quot;</title>
<marker>Port, </marker>
<rawString>Robert F. Port &amp;quot;Representation and recognition of temporal patterns&amp;quot;</rawString>
</citation>
<citation valid="false">
<authors>
<author>Michael Gasser</author>
<author>Chan-Do Lee</author>
</authors>
<title>Networks that learn about phonological feature persistence&amp;quot;</title>
<marker>Gasser, Lee, </marker>
<rawString>Michael Gasser and Chan-Do Lee &amp;quot;Networks that learn about phonological feature persistence&amp;quot;</rawString>
</citation>
<citation valid="false">
<authors>
<author>Ainsworth</author>
<author>N P Warren</author>
</authors>
<title>Pronunciation of digit sequences in text-to-speech systems&amp;quot;</title>
<marker>Ainsworth, Warren, </marker>
<rawString>WA. Ainsworth and N.P. Warren &amp;quot;Pronunciation of digit sequences in text-to-speech systems&amp;quot;</rawString>
</citation>
<citation valid="false">
<institution>The Compact Disk Handbook (Second Edition)</institution>
<marker></marker>
<rawString>The Compact Disk Handbook (Second Edition)</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Ken</author>
</authors>
<date>1992</date>
<journal>xv +</journal>
<booktitle>The Computer Music and Digital Audio Series, edited by John Strawn, Volume</booktitle>
<volume>5</volume>
<pages>pp.</pages>
<publisher>A-R Editions Inc</publisher>
<institution>Pohlmann (University of Miami) Madison,</institution>
<location>Wisconsin:</location>
<marker>Ken, 1992</marker>
<rawString>Ken C. Pohlmann (University of Miami) Madison, Wisconsin: A-R Editions Inc (The Computer Music and Digital Audio Series, edited by John Strawn, Volume 5) 1992, xv + 349 pp.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>