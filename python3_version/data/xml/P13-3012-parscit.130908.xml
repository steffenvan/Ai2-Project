<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000766">
<title confidence="0.994848">
Multigraph Clustering for Unsupervised Coreference Resolution
</title>
<author confidence="0.99504">
Sebastian Martschat
</author>
<affiliation confidence="0.985881">
Heidelberg Institute for Theoretical Studies gGmbH
</affiliation>
<address confidence="0.9453495">
Schloss-Wolfsbrunnenweg 35
69118 Heidelberg, Germany
</address>
<email confidence="0.937169">
sebastian.martschat@h-its.org
</email>
<sectionHeader confidence="0.996387" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999637285714286">
We present an unsupervised model for
coreference resolution that casts the prob-
lem as a clustering task in a directed la-
beled weighted multigraph. The model
outperforms most systems participating in
the English track of the CoNLL’12 shared
task.
</bodyText>
<sectionHeader confidence="0.999392" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99996975">
Coreference resolution is the task of determining
which mentions in a text refer to the same en-
tity. With the advent of machine learning and
the availability of annotated corpora in the mid
1990s the research focus shifted from rule-based
approaches to supervised machine learning tech-
niques. Quite recently, however, rule-based ap-
proaches regained popularity due to Stanford’s
multi-pass sieve approach which exhibits state-
of-the-art performance on many standard coref-
erence data sets (Raghunathan et al., 2010) and
also won the CoNLL-2011 shared task on coref-
erence resolution (Lee et al., 2011; Pradhan et
al., 2011). These results show that carefully
crafted rule-based systems which employ suitable
inference schemes can achieve competitive perfor-
mance. Such a system can be considered unsuper-
vised in the sense that it does not employ training
data for optimizing parameters.
In this paper we present a graph-based approach
for coreference resolution that models a document
to be processed as a graph. The nodes are men-
tions and the edges correspond to relations be-
tween mentions. Coreference resolution is per-
formed via graph clustering. Our approach be-
longs to a class of recently proposed graph models
for coreference resolution (Cai and Strube, 2010;
Sapena et al., 2010; Martschat et al., 2012) and
is designed to be a simplified version of existing
approaches. In contrast to previous models be-
longing to this class we do not learn any edge
weights but perform inference on the graph struc-
ture only which renders our model unsupervised.
On the English data of the CoNLL’12 shared task
the model outperforms most systems which partic-
ipated in the shared task.
</bodyText>
<sectionHeader confidence="0.999926" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.996351148148148">
Graph-based coreference resolution. While
not developed within a graph-based framework,
factor-based approaches for pronoun resolution
(Mitkov, 1998) can be regarded as greedy clus-
tering in a multigraph, where edges representing
factors for pronoun resolution have negative or
positive weight. This yields a model similar to
the one presented in this paper though Mitkov’s
work has only been applied to pronoun resolu-
tion. Nicolae and Nicolae (2006) phrase coref-
erence resolution as a graph clustering problem:
they first perform pairwise classification and then
construct a graph using the derived confidence val-
ues as edge weights. In contrast, work by Culotta
et al. (2007), Cai and Strube (2010) and Sapena
et al. (2010) omits the classification step entirely.
Sapena et al. (2010) and Cai and Strube (2010)
perform coreference resolution in one step using
graph partitioning approaches. These approaches
participated in the recent CoNLL’11 shared task
(Pradhan et al., 2011; Sapena et al., 2011; Cai
et al., 2011b) with excellent results. The ap-
proach by Cai et al. (2011b) has been modified by
Martschat et al. (2012) and ranked second in the
English track at the CoNLL’12 shared task (Prad-
han et al., 2012). The top performing system at
the CoNLL’12 shared task (Fernandes et al., 2012)
</bodyText>
<page confidence="0.987634">
81
</page>
<note confidence="0.6546635">
Proceedings of the ACL Student Research Workshop, pages 81–88,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.99648625">
also represents the problem as a graph by per-
forming inference on trees constructed using the
multi-pass sieve approach by Raghunathan et al.
(2010) and Lee et al. (2011), which in turn won
the CoNLL’11 shared task.
Unsupervised coreference resolution. Cardie
and Wagstaff (1999) present an early approach to
unsupervised coreference resolution based on a
straightforward clustering approach. Angheluta et
al. (2004) build on their approach and devise more
sophisticated clustering algorithms. Haghighi and
Klein (2007), Ng (2008) and Charniak and El-
sner (2009) employ unsupervised generative mod-
els. Poon and Domingos (2008) present a Markov
Logic Network approach to unsupervised corefer-
ence resolution. These approaches reach competi-
tive performance on gold mentions but not on sys-
tem mentions (Ng, 2008). The multi-pass sieve
approach by Raghunathan et al. (2010) can also be
viewed as unsupervised.
</bodyText>
<sectionHeader confidence="0.997723" genericHeader="method">
3 A Multigraph Model
</sectionHeader>
<bodyText confidence="0.999572666666667">
We aim for a model which directly represents the
relations between mentions in a graph structure.
Clusters in the graph then correspond to entities.
</bodyText>
<subsectionHeader confidence="0.998532">
3.1 Motivation
</subsectionHeader>
<bodyText confidence="0.999809571428571">
To motivate the choice of our model, let us con-
sider a simple made-up example.
Leaders met in Paris to discuss recent
developments. They left the city today.
We want to model that Paris is not a likely candi-
date antecedent for They due to number disagree-
ment, but that Leaders and recent developments
are potential antecedents for They. We want to
express that Leaders is the preferred antecedent,
since Leaders and They are in a parallel construc-
tion both occupying the subject position in their
respective sentences.
In other words, our model should express the
following relations for this example:
</bodyText>
<listItem confidence="0.95153925">
• number disagreement for (They, Paris), which
indicates that the mentions are not coreferent,
• the anaphor being a pronoun for (They, Lead-
ers), (They, recent developments) and (They,
Paris), which is a weak indicator for corefer-
ence if the mentions are close to each other,
• syntactic parallelism for (They, Leaders): both
mentions are in a parallel construction in adja-
</listItem>
<bodyText confidence="0.961388571428571">
cent sentences (both in the subject slot), which
is also a weak coreference indicator.
We denote these relations as N Number,
P AnaPron and P Subject respectively. The
graphical structure depicted in Figure 1 mod-
els these relations between the four mentions
Leaders, Paris, recent developments and They.
</bodyText>
<figureCaption confidence="0.9877575">
Figure 1: An example graph modeling relations
between mentions.
</figureCaption>
<bodyText confidence="0.9996725">
A directed edge from a mention m to n indi-
cates that n precedes m and that there is some rela-
tion between m and n that indicates coreference or
non-coreference. Labeled edges describe the rela-
tions between the mentions, multiple relations can
hold between a pair. Edges may be weighted.
</bodyText>
<subsectionHeader confidence="0.99294">
3.2 Multigraphs for Coreference Resolution
</subsectionHeader>
<bodyText confidence="0.999983666666667">
Formally, the model is a directed labeled weighted
multigraph. That is a tuple D = (R, V, A, w)
where
</bodyText>
<listItem confidence="0.97324725">
• R is the set of labels (in our case relations such
as P Subject that hold between mentions),
• V is the set of nodes (the mentions extracted
from a document),
• A ⊆ V x V x R is the set of edges (relations
between two mentions),
• w is a mapping w: A → R U {foo} (weights
for edges).
</listItem>
<bodyText confidence="0.958100636363637">
Many graph models for coreference resolution op-
erate on A = V xV . Our multigraph model allows
us to have multiple edges with different labels be-
tween mentions.
To have a notion of order we employ a directed
graph: We only allow an edge from m to n if m
appears later in the text than n.
To perform coreference resolution for a docu-
ment d, we first construct a directed labeled multi-
graph (Section 3.3). We then assign a weight to
each edge (Section 3.4). The resulting graph is
</bodyText>
<figure confidence="0.9955955">
recent de-
velopments
Leaders
P Subject
P AnaPron
P AnaPron
N Number
They
Paris
P AnaPron
</figure>
<page confidence="0.995584">
82
</page>
<bodyText confidence="0.993699">
clustered to obtain the mentions that refer to the
same entity (Section 3.5).
</bodyText>
<subsectionHeader confidence="0.998633">
3.3 Graph Construction
</subsectionHeader>
<bodyText confidence="0.997719714285714">
Given a set M of mentions extracted from a doc-
ument d, we set V = M, i.e. the nodes of the
graph are the mentions. To construct the edges
A, we consider each pair (m, n) of mentions with
n ≺ m. We then check for every relation r E R
if r holds for the pair (m, n). If this is the case
we add the edge (m, n, r) to A. For simplicity,
we restrict ourselves to binary relations that hold
between pairs of mentions (see Section 4).
The graph displayed in Figure 1 is the graph
constructed for the mentions Leaders, Paris, re-
cent developments and They from the example
sentence at the beginning of this Section, where
R = {P AnaPron, P Subject, N Number}.
</bodyText>
<subsectionHeader confidence="0.997149">
3.4 Assigning Weights
</subsectionHeader>
<bodyText confidence="0.990745565217391">
Depending on whether a relation r E R is indica-
tive for non-coreference (e.g. number disagree-
ment) or for coreference (e.g. string matching) it
should be weighted differently. We therefore di-
vide R into a set of negative relations R_ and a
set of positive relations R+.
Previous work on multigraphs for coreference
resolution disallows any edge between mentions
for which a negative relations holds (Cai et al.,
2011b; Martschat et al., 2012). We take a sim-
ilar approach and set w(m, n, r) = −oo for
(m, n, r) E A when r E R_1.
Work on graph-based models similar to ours re-
port robustness with regard to the amount of train-
ing data used (Cai et al., 2011b; Cai et al., 2011a;
Martschat et al., 2012). Motivated by their obser-
vations we treat every positive relation equally and
set w(m, n, r) = 1 for (m, n, r) E A if r E R+.
In contrast to previous work on similar graph
models we do not learn any edge weights from
training data. We compare this unsupervised
scheme with supervised variants empirically in
Section 5.
</bodyText>
<subsectionHeader confidence="0.964178">
3.5 Clustering
</subsectionHeader>
<bodyText confidence="0.997844923076923">
To describe the clustering algorithm used in this
work we need some additional terminology. If
there exists an edge (m, n, r) E A we say that n is
a child of m.
1We experimented with different weighting schemes
for negative relations on development data (e.g. setting
w(m, n, r) = −1) but did not observe a gain in performance.
In the graph constructed according to the pro-
cedure described in Section 3.3, all children of a
mention m are candidate antecedents for m. The
relations we employ are indicators for coreference
(which get a positive weight) and indicators for
non-coreference (which get a negative weight).
We aim to employ a simple and efficient cluster-
ing scheme on this graph and therefore choose
1-nearest-neighbor clustering: for every m, we
choose as antecedent m’s child n such that the sum
of edge weights is maximal and positive. We break
ties by choosing the closest mention.
In the unsupervised setting described in Section
3.4 this algorithm reduces to choosing the child
that is connected via the highest number of posi-
tive relations and via no negative relation.
For the graph depicted in Figure 1 this algorithm
computes the clusters {They, Leaders}, {Paris}
and {recent developments}.
</bodyText>
<sectionHeader confidence="0.999444" genericHeader="method">
4 Relations
</sectionHeader>
<bodyText confidence="0.999985857142857">
The graph model described in Section 3 is based
on expressing relations between pairs of mentions
via edges built from such relations. We now de-
scribe the relations currently used by our system.
They are well-known indicators and constraints
for coreference and are taken from previous work
(Cardie and Wagstaff, 1999; Soon et al., 2001;
Rahman and Ng, 2009; Lee et al., 2011; Cai et al.,
2011b). All relations operate on pairs of mentions
(m, n), where m is the anaphor and n is a candi-
date antecedent. If a relation r holds for (m, n),
the edge (m, n, r) is added to the graph. We final-
ized the set of relations and their distance thresh-
olds on development data.
</bodyText>
<subsectionHeader confidence="0.992119">
4.1 Negative Relations
</subsectionHeader>
<bodyText confidence="0.85431875">
Negative relations receive negative weights. They
allow us to introduce well-known constraints such
as agreement into our model.
(1) N Gender, (2) N Number: Two mentions do
not agree in gender or number. We compute
number and gender for common nouns us-
ing the number and gender data provided by
Bergsma and Lin (2006).
</bodyText>
<listItem confidence="0.999528">
(3) N SemanticClass: Two mentions do not
agree in semantic class (we only use the top
categories Object, Date and Person from
WordNet (Fellbaum, 1998)).
(4) N ItDist: The anaphor is it or they and the
sentence distance to the antecedent is larger
</listItem>
<page confidence="0.93356">
83
</page>
<listItem confidence="0.945905444444444">
than one.
(5) N Speaker12Pron: Two first person pro-
nouns or two second person pronouns with dif-
ferent speakers, or one first person pronoun
and one second person pronoun with the same
speaker2.
(6) N ContraSubObj: Two mentions are in the
subject/object positions of the same verb, the
anaphor is a non-possessive/reflexive pronoun.
(7) N Mod: Two mentions have the same syntac-
tic heads, and the anaphor has a nominal mod-
ifier which does not occur in the antecedent.
(8) N Embedding: Two mentions where one em-
beds the other, which is not a reflexive or pos-
sessive pronoun.
(9) N 2PronNonSpeech: Two second person
pronouns without speaker information and not
in direct speech.
</listItem>
<subsectionHeader confidence="0.944462">
4.2 Positive Relations
</subsectionHeader>
<bodyText confidence="0.9659745">
Positive relations are coreference indicators which
are added as edges with positive weights.
</bodyText>
<listItem confidence="0.999139521739131">
(10) P NonPron StrMatch: Applies only if the
anaphor is definite or a proper name3. This re-
lation holds if after discarding stop words the
strings of mentions completely match.
(11) P HeadMatch: If the syntactic heads of
mentions match.
(12) P Alias: If mentions are aliases of each other
(i.e. proper names with partial match, full
names and acronyms, etc.).
(13) P Speaker12Pron: If the speaker of the sec-
ond person pronoun is talking to the speaker
of the first person pronoun (applies only to
first/second person pronouns).
(14) P DSPron: One mention is a speak verb’s
subject, the other mention is a first person pro-
noun within the corresponding direct speech.
(15) P ReflPronSub: If the anaphor is a reflexive
pronoun, and the antecedent is the subject of
the sentence.
(16) P PossPronSub: If the anaphor is a posses-
sive pronoun, and the antecedent is the subject
of the anaphor’s sentence or subclause.
(17) P PossPronEmb: The anaphor is a posses-
</listItem>
<footnote confidence="0.9916075">
2Like all relations using speaker information, this relation
depends on the gold speaker annotation layer in the corpus.
3This condition is necessary to cope with the high-recall
output of the mention tagger.
</footnote>
<bodyText confidence="0.879546">
sive pronoun embedded in the antecedent.
</bodyText>
<listItem confidence="0.999391764705883">
(18) P AnaPron: If the anaphor is a pronoun and
none of the mentions is a first or second per-
son pronoun. This relation is restricted to a
sentence distance of 3.
(19) P VerbAgree: If the anaphor is a third per-
son pronoun and has the same predicate as the
antecedent. This relation is restricted to a sen-
tence distance of 1.
(20) P Subject, (21) P Object: The anaphor is a
third person pronoun and both mentions are
subjects/objects. These relations are restricted
to a sentence distance of 1.
(22) P Pron StrMatch: If both mentions are
pronouns and their strings match.
(23) P Pron Agreement: If both mentions are
different pronoun tokens but agree in number,
gender and person.
</listItem>
<sectionHeader confidence="0.999041" genericHeader="method">
5 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.997106">
5.1 Data and Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.999971291666667">
We use the data provided for the English track of
the CoNLL’12 shared task on multilingual coref-
erence resolution (Pradhan et al., 2012) which is
a subset of the upcoming OntoNotes 5.0 release
and comes with various annotation layers provided
by state-of-the-art NLP tools. We used the official
dev/test split for development and evaluation. We
evaluate the model in a setting that corresponds
to the shared task’s closed track, i.e. we use only
WordNet (Fellbaum, 1998), the number and gen-
der data of Bergsma and Lin (2006) and the pro-
vided annotation layers. To extract system men-
tions we employ the mention extractor described
in Martschat et al. (2012).
We evaluate our system with the coreference
resolution evaluation metrics that were used for
the CoNLL shared tasks on coreference, which are
MUC (Vilain et al., 1995), B3 (Bagga and Bald-
win, 1998) and CEAFe (Luo, 2005). We also re-
port the unweighted average of the three scores,
which was the official evaluation metric in the
shared tasks. To compute the scores we employed
the official scorer supplied by the shared task or-
ganizers.
</bodyText>
<subsectionHeader confidence="0.688491">
5.2 Results
</subsectionHeader>
<bodyText confidence="0.999281333333333">
Table 1 displays the performance of our model and
of the systems that obtained the best (Fernandes
et al., 2012) and the median performance in the
</bodyText>
<page confidence="0.981414">
84
</page>
<table confidence="0.855147631578947">
MUC
average
R P F1
R P F1
R P F1
B3
CEAF,
CoNLL’12 English development data
best 64.88 74.74 69.46 66.53 78.28 71.93 54.93 43.68 48.66 63.35
median 62.3 62.8 62.0 66.7 71.8 69.1 46.4 44.9 45.6 58.9
this work (weights fraction) 64.00 68.56 66.20 66.59 75.67 70.84 50.48 45.52 47.87 61.63
this work (weights MaxEnt) 63.72 65.78 64.73 66.60 73.76 70.00 47.46 45.30 46.36 60.36
this work (unsupervised) 64.01 68.58 66.22 67.00 76.45 71.41 51.10 46.16 48.51 62.05
CoNLL’12 English test data
best 65.83 75.91 70.51 65.79 77.69 71.24 55.00 43.17 48.37 63.37
median 62.08 63.02 62.55 66.23 70.45 68.27 45.74 44.74 45.23 58.68
this work (weights fraction) 64.25 68.31 66.22 65.44 74.20 69.54 49.18 44.71 46.84 60.87
this work (weights MaxEnt) 63.58 64.70 64.14 65.63 72.09 68.71 45.58 44.41 44.99 59.28
this work (unsupervised) 63.95 67.99 65.91 65.47 74.93 69.88 49.83 45.40 47.51 61.10
</table>
<tableCaption confidence="0.999936">
Table 1: Results of different systems on the CoNLL’12 English data sets.
</tableCaption>
<bodyText confidence="0.998875733333333">
CoNLL’12 shared task, which are denoted as best
and median respectively. best employs a struc-
tured prediction model with learned combinations
of 70 basic features. We also compare with two
supervised variants of our model which use the
same relations and the same clustering algorithm
as the unsupervised model: weights fraction sets
the weight of a relation to the fraction of posi-
tive instances in training data (as in Martschat et
al. (2012)). weights MaxEnt trains a mention-pair
model (Soon et al., 2001) via the maximum en-
tropy classifier implemented in the BART toolkit
(Versley et al., 2008) and builds a graph where
the weight of an edge connecting two mentions
is the classifier’s prediction4. We use the official
CoNLL’12 English training set for training.
Our unsupervised model performs considerably
better than the median system from the CoNLL’12
shared task on both data sets according to all met-
rics. It also seems to be able to accommodate well
for the relations described in Section 4 since it out-
performs both supervised variants5. The model
performs worse than best, the gap according to B3
and CEAFe being considerably smaller than ac-
cording to MUC. While we observe a decrease of
1 point average score when evaluating on test data
the model still would have ranked fourth in the En-
glish track of the CoNLL’12 shared task with only
0.2 points difference in average score to the sec-
ond ranked system.
</bodyText>
<footnote confidence="0.995881666666667">
4The classifier’s output is a number p ∈ [0, 1]. In order to
have negative weights we use the transformation p� = 2p−1.
5Compared with the supervised variants all improvements
in F1 score are statistically significant according to a paired
t-test (p &lt; 0.05) except for the difference in MUC F1 to
weights fraction.
</footnote>
<sectionHeader confidence="0.999166" genericHeader="method">
6 Error Analysis
</sectionHeader>
<bodyText confidence="0.999981">
In order to understand weaknesses of our model
we perform an error analysis on the development
data. We distinguish between precision and recall
errors. For an initial analysis we split the errors
according to the mention type of anaphor and an-
tecedent (name, nominal and pronoun).
</bodyText>
<subsectionHeader confidence="0.998823">
6.1 Precision Errors
</subsectionHeader>
<bodyText confidence="0.99996075">
Our system operates in a pairwise fashion. We
therefore count one precision error whenever the
clustering algorithm assigns two non-coreferent
mentions to the same cluster. Table 2 shows the
</bodyText>
<table confidence="0.980369">
NAM NOM PRO
NAM 3413 (21%) 67 (66%) 11 (46%)
NOM 43 (67%) 2148 (49%) 9 (89%)
PRO 868 (32%) 1771 (55%) 5308 (24%)
</table>
<tableCaption confidence="0.972536">
Table 2: Number of clustering decisions made ac-
</tableCaption>
<bodyText confidence="0.957733866666667">
cording to mention type (rows anaphor, columns
antecedent) and percentage of wrong decisions.
number of clustering decisions made according to
the mention type and in brackets the fraction of de-
cisions that erroneously assign two non-coreferent
mentions to the same cluster. We see that two main
sources of error are nominal-nominal pairs and the
resolution of pronouns. We now focus on gain-
ing further insight into the system’s performance
for pronoun resolution by investigating the perfor-
mance per pronoun type. The results are displayed
in Table 3. We obtain good performance for I and
my which in the majority of cases can be resolved
unambiguously by the speaker relations employed
by our system. The relations we use also seem
</bodyText>
<page confidence="0.999204">
85
</page>
<table confidence="0.999669888888889">
Anaphor all anaphoric
I 1260 (13%) 1239 (11%)
my 192 (14%) 181 (9%)
he 824 (14%) 812 (13%)
. . . . . .
they 764 (29%) 725 (26%)
. . . . . .
you 802 (41%) 555 (15%)
it 1114 (64%) 720 (44%)
</table>
<tableCaption confidence="0.999813">
Table 3: Precision statistics for pronouns. Rows
</tableCaption>
<bodyText confidence="0.9334925">
are pronoun surfaces, columns number of cluster-
ing decisions and percentage of wrong decisions
for all and only anaphoric pronouns respectively.
to work well for he. In contrast, the local, shal-
low approach we currently employ is not able to
resolve highly ambiguous pronouns such as they,
you or it in many cases. The reduction in error rate
when only considering anaphoric pronouns shows
that our system could benefit from an improved
detection of expletive it and you.
</bodyText>
<subsectionHeader confidence="0.999671">
6.2 Recall Errors
</subsectionHeader>
<bodyText confidence="0.999843777777777">
Estimating recall errors by counting all missing
pairwise links would consider each entity many
times. Therefore, we instead count one recall er-
ror for a pair (m, n) of anaphor m and antecedent
n if (i) m and n are coreferent, (ii) m and n are
not assigned to the same cluster, (iii) m is the first
mention in its cluster that is coreferent with n, and
(iv) n is the closest mention coreferent with m that
is not in m’s cluster.
This can be illustrated by an example. Consid-
ering mentions m1, ... , m5, assume that m1, m3,
m4 and m5 are coreferent but the system clusters
are {m2, m31 and {m4, m51. We then count two
recall errors: one for the missing link from m3 to
m1 and one for the missing link from m4 to m3.
According to this definition we count 3528 re-
call errors on the development set. The distribu-
tion of errors is displayed in Table 4. We see that
</bodyText>
<table confidence="0.9928">
NAM NOM PRO
NAM 321 220 247
NOM 306 797 330
PRO 306 476 525
</table>
<tableCaption confidence="0.983517">
Table 4: Number of recall errors according to
</tableCaption>
<bodyText confidence="0.9451186">
mention type (rows anaphor, columns antecedent).
the main source of recall errors are missing links
of nominal-nominal pairs. We randomly extracted
50 of these errors and manually assigned them to
different categories.
29 errors: missing semantic knowledge. In these
cases lexical or world knowledge is needed to
build coreference links between mentions with dif-
ferent heads. For example our system misses the
link between the sauna and the hotbox sweatbox.
14 errors: too restrictive N Mod. In these cases
the heads of the mentions matched but no link was
built due to N Mod. An example is the missing
link between our island’s last remaining forest of
these giant trees and the forest of Chilan.
4 errors: too cautious string match. We only
apply string matching for common nouns when the
noun is definite.
Three errors could not be attributed to any of the
above categories.
</bodyText>
<sectionHeader confidence="0.992847" genericHeader="conclusions">
7 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999988571428571">
We presented an unsupervised graph-based model
for coreference resolution. Experiments show that
our model exhibits competitive performance on
the English CoNLL’12 shared task data sets.
An error analysis revealed that two main
sources of errors of our model are the inaccurate
resolution of highly ambiguous pronouns such as
it and missing links between nominals with dif-
ferent heads. Future work should investigate how
semantic knowledge and more complex relations
capturing deeper discourse properties such as co-
herence or information status can be added to the
model. Processing these features efficently may
require a more sophisticated clustering algorithm.
We are surprised by the good performance of
this unsupervised model in comparison to the
state-of-the-art which uses sophisticated machine
learning techniques (Fernandes et al., 2012) or
well-engineered rules (Lee et al., 2011). We are
not sure how to interpret these results and want to
leave different interpretations for discussion:
</bodyText>
<listItem confidence="0.992191">
• our unsupervised model is really that good
(hopefully),
• the evaluation metrics employed are to be
questioned (certainly),
• efficiently making use of annotated training
data still remains a challenge for the state-of-
the-art (likely).
</listItem>
<sectionHeader confidence="0.998496" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.945928666666667">
This work has been funded by the Klaus Tschira
Foundation, Germany. The author has been sup-
ported by a HITS PhD scholarship.
</bodyText>
<page confidence="0.995936">
86
</page>
<sectionHeader confidence="0.995458" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999391009009009">
Roxana Angheluta, Patrick Jeuniaux, Rudradeb Mitra,
and Marie-Francine Moens. 2004. Clustering al-
gorithms for noun phrase coreference resolution. In
Proceedings of the 7`emes Journ´ees Internationales
d’Analyse Statistique des Donn´ees Textuelles, Lou-
vain La Neuve, Belgium, 10–12 March 2004, pages
60–70.
Amit Bagga and Breck Baldwin. 1998. Algorithms
for scoring coreference chains. In Proceedings
of the 1st International Conference on Language
Resources and Evaluation, Granada, Spain, 28–30
May 1998, pages 563–566.
Shane Bergsma and Dekang Lin. 2006. Bootstrap-
ping path-based pronoun resolution. In Proceedings
of the 21st International Conference on Computa-
tional Linguistics and 44th Annual Meeting of the
Association for Computational Linguistics, Sydney,
Australia, 17–21 July 2006, pages 33–40.
Jie Cai and Michael Strube. 2010. End-to-end coref-
erence resolution via hypergraph partitioning. In
Proceedings of the 23rd International Conference
on Computational Linguistics, Beijing, China, 23–
27 August 2010, pages 143–151.
Jie Cai, ´Eva M´ujdricza-Maydt, Yufang Hou, and
Michael Strube. 2011a. Weakly supervised graph-
based coreference resolution for clinical data. In
Proceedings of the 5th i2b2 Shared Tasks and Work-
shop on Challenges in Natural Language Processing
for Clinical Data, Washington, D.C., 20-21 October
2011.
Jie Cai, ´Eva M´ujdricza-Maydt, and Michael Strube.
2011b. Unrestricted coreference resolution via
global hypergraph partitioning. In Proceedings of
the Shared Task of the 15th Conference on Computa-
tional Natural Language Learning, Portland, Oreg.,
23–24 June 2011, pages 56–60.
Claire Cardie and Kiri Wagstaff. 1999. Noun phrase
coreference as clustering. In Proceedings of the
1999 SIGDAT Conference on Empirical Methods in
Natural Language Processing and Very Large Cor-
pora, College Park, Md., 21–22 June 1999, pages
82–89.
Eugene Charniak and Micha Elsner. 2009. EM works
for pronoun anaphora resolution. In Proceedings of
the 12th Conference of the European Chapter of the
Association for Computational Linguistics, Athens,
Greece, 30 March – 3 April 2009, pages 148–156.
Aron Culotta, Michael Wick, and Andrew McCal-
lum. 2007. First-order probabilistic models for
coreference resolution. In Proceedings of Human
Language Technologies 2007: The Conference of
the North American Chapter of the Association for
Computational Linguistics, Rochester, N.Y., 22–27
April 2007, pages 81–88.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press, Cambridge,
Mass.
Eraldo Fernandes, C´ıcero dos Santos, and Ruy Milidi´u.
2012. Latent structure perceptron with feature in-
duction for unrestricted coreference resolution. In
Proceedings of the Shared Task of the 16th Confer-
ence on Computational Natural Language Learning,
Jeju Island, Korea, 12–14 July 2012, pages 41–48.
Aria Haghighi and Dan Klein. 2007. Unsupervised
coreference resolution in a nonparametric Bayesian
model. In Proceedings of the 45th Annual Meeting
of the Association for Computational Linguistics,
Prague, Czech Republic, 23–30 June 2007, pages
848–855.
Heeyoung Lee, Yves Peirsman, Angel Chang,
Nathanael Chambers, Mihai Surdeanu, and Dan Ju-
rafsky. 2011. Stanford’s multi-pass sieve corefer-
ence resolution system at the CoNLL-2011 shared
task. In Proceedings of the Shared Task of the
15th Conference on Computational Natural Lan-
guage Learning, Portland, Oreg., 23–24 June 2011,
pages 28–34.
Xiaoqiang Luo. 2005. On coreference resolution
performance metrics. In Proceedings of the Hu-
man Language Technology Conference and the 2005
Conference on Empirical Methods in Natural Lan-
guage Processing, Vancouver, B.C., Canada, 6–8
October 2005, pages 25–32.
Sebastian Martschat, Jie Cai, Samuel Broscheit, ´Eva
M´ujdricza-Maydt, and Michael Strube. 2012. A
multigraph model for coreference resolution. In
Proceedings of the Shared Task of the 16th Confer-
ence on Computational Natural Language Learning,
Jeju Island, Korea, 12–14 July 2012, pages 100–106.
Ruslan Mitkov. 1998. Robust pronoun resolution with
limited knowledge. In Proceedings of the 17th In-
ternational Conference on Computational Linguis-
tics and 36th Annual Meeting of the Association
for Computational Linguistics, Montr´eal, Qu´ebec,
Canada, 10–14 August 1998, pages 869–875.
Vincent Ng. 2008. Unsupervised models for corefer-
ence resolution. In Proceedings of the 2008 Con-
ference on Empirical Methods in Natural Language
Processing, Waikiki, Honolulu, Hawaii, 25–27 Oc-
tober 2008, pages 640–649.
Cristina Nicolae and Gabriel Nicolae. 2006. BestCut:
A graph algorithm for coreference resolution. In
Proceedings of the 2006 Conference on Empirical
Methods in Natural Language Processing, Sydney,
Australia, 22–23 July 2006, pages 275–283.
Hoifung Poon and Pedro Domingos. 2008. Joint unsu-
pervised coreference resolution with Markov Logic.
In Proceedings of the 2008 Conference on Empirical
Methods in Natural Language Processing, Waikiki,
Honolulu, Hawaii, 25–27 October 2008, pages 650–
659.
</reference>
<page confidence="0.98793">
87
</page>
<reference confidence="0.999629181818182">
Sameer Pradhan, Lance Ramshaw, Mitchell Marcus,
Martha Palmer, Ralph Weischedel, and Nianwen
Xue. 2011. CoNLL-2011 Shared Task: Modeling
unrestricted coreference in OntoNotes. In Proceed-
ings of the Shared Task of the 15th Conference on
Computational Natural Language Learning, Port-
land, Oreg., 23–24 June 2011, pages 1–27.
Sameer Pradhan, Alessandro Moschitti, and Nianwen
Xue. 2012. CoNLL-2012 Shared Task: Modeling
multilingual unrestricted coreference in OntoNotes.
In Proceedings of the Shared Task of the 16th Con-
ference on Computational Natural Language Learn-
ing, Jeju Island, Korea, 12–14 July 2012, pages 1–
40.
Karthik Raghunathan, Heeyoung Lee, Sudarshan Ran-
garajan, Nathanael Chambers, Mihai Surdeanu, Dan
Jurafsky, and Christopher Manning. 2010. A multi-
pass sieve for coreference resolution. In Proceed-
ings of the 2010 Conference on Empirical Methods
in Natural Language Processing, Cambridge, Mass.,
9–11 October 2010, pages 492–501.
Altaf Rahman and Vincent Ng. 2009. Supervised mod-
els for coreference resolution. In Proceedings of the
2009 Conference on Empirical Methods in Natural
Language Processing, Singapore, 6–7 August 2009,
pages 968–977.
Emili Sapena, Llu´ıs Padr´o, and Jordi Turmo. 2010. A
global relaxation labeling approach to coreference
resolution. In Proceedings of Coling 2010: Poster
Volume, Beijing, China, 23–27 August 2010, pages
1086–1094.
Emili Sapena, Llu´ıs Padr´o, and Jordi Turmo. 2011.
RelaxCor participation in CoNLL shared task on
coreference resolution. In Proceedings of the
Shared Task of the 15th Conference on Computa-
tional Natural Language Learning, Portland, Oreg.,
23–24 June 2011, pages 35–39.
Wee Meng Soon, Hwee Tou Ng, and Daniel
Chung Yong Lim. 2001. A machine learning ap-
proach to coreference resolution of noun phrases.
Computational Linguistics, 27(4):521–544.
Yannick Versley, Simone Paolo Ponzetto, Massimo
Poesio, Vladimir Eidelman, Alan Jern, Jason Smith,
Xiaofeng Yang, and Alessandro Moschitti. 2008.
BART: A modular toolkit for coreference resolu-
tion. In Companion Volume to the Proceedings of
the 46th Annual Meeting of the Association for Com-
putational Linguistics, Columbus, Ohio, 15–20 June
2008, pages 9–12.
Marc Vilain, John Burger, John Aberdeen, Dennis Con-
nolly, and Lynette Hirschman. 1995. A model-
theoretic coreference scoring scheme. In Proceed-
ings of the 6th Message Understanding Conference
(MUC-6), pages 45–52, San Mateo, Cal. Morgan
Kaufmann.
</reference>
<page confidence="0.999405">
88
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.495514">
<title confidence="0.999873">Multigraph Clustering for Unsupervised Coreference Resolution</title>
<author confidence="0.981601">Sebastian</author>
<affiliation confidence="0.785649">Heidelberg Institute for Theoretical Studies Schloss-Wolfsbrunnenweg</affiliation>
<address confidence="0.997849">69118 Heidelberg,</address>
<email confidence="0.998922">sebastian.martschat@h-its.org</email>
<abstract confidence="0.977444375">We present an unsupervised model for coreference resolution that casts the problem as a clustering task in a directed labeled weighted multigraph. The model outperforms most systems participating in the English track of the CoNLL’12 shared task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Roxana Angheluta</author>
<author>Patrick Jeuniaux</author>
<author>Rudradeb Mitra</author>
<author>Marie-Francine Moens</author>
</authors>
<title>Clustering algorithms for noun phrase coreference resolution.</title>
<date>2004</date>
<booktitle>In Proceedings of the 7`emes Journ´ees Internationales d’Analyse Statistique des Donn´ees Textuelles, Louvain La Neuve, Belgium,</booktitle>
<pages>10--12</pages>
<contexts>
<context position="4031" citStr="Angheluta et al. (2004)" startWordPosition="616" endWordPosition="619">stem at the CoNLL’12 shared task (Fernandes et al., 2012) 81 Proceedings of the ACL Student Research Workshop, pages 81–88, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics also represents the problem as a graph by performing inference on trees constructed using the multi-pass sieve approach by Raghunathan et al. (2010) and Lee et al. (2011), which in turn won the CoNLL’11 shared task. Unsupervised coreference resolution. Cardie and Wagstaff (1999) present an early approach to unsupervised coreference resolution based on a straightforward clustering approach. Angheluta et al. (2004) build on their approach and devise more sophisticated clustering algorithms. Haghighi and Klein (2007), Ng (2008) and Charniak and Elsner (2009) employ unsupervised generative models. Poon and Domingos (2008) present a Markov Logic Network approach to unsupervised coreference resolution. These approaches reach competitive performance on gold mentions but not on system mentions (Ng, 2008). The multi-pass sieve approach by Raghunathan et al. (2010) can also be viewed as unsupervised. 3 A Multigraph Model We aim for a model which directly represents the relations between mentions in a graph stru</context>
</contexts>
<marker>Angheluta, Jeuniaux, Mitra, Moens, 2004</marker>
<rawString>Roxana Angheluta, Patrick Jeuniaux, Rudradeb Mitra, and Marie-Francine Moens. 2004. Clustering algorithms for noun phrase coreference resolution. In Proceedings of the 7`emes Journ´ees Internationales d’Analyse Statistique des Donn´ees Textuelles, Louvain La Neuve, Belgium, 10–12 March 2004, pages 60–70.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amit Bagga</author>
<author>Breck Baldwin</author>
</authors>
<title>Algorithms for scoring coreference chains.</title>
<date>1998</date>
<booktitle>In Proceedings of the 1st International Conference on Language Resources and Evaluation,</booktitle>
<pages>563--566</pages>
<location>Granada,</location>
<contexts>
<context position="15199" citStr="Bagga and Baldwin, 1998" startWordPosition="2552" endWordPosition="2556">rs provided by state-of-the-art NLP tools. We used the official dev/test split for development and evaluation. We evaluate the model in a setting that corresponds to the shared task’s closed track, i.e. we use only WordNet (Fellbaum, 1998), the number and gender data of Bergsma and Lin (2006) and the provided annotation layers. To extract system mentions we employ the mention extractor described in Martschat et al. (2012). We evaluate our system with the coreference resolution evaluation metrics that were used for the CoNLL shared tasks on coreference, which are MUC (Vilain et al., 1995), B3 (Bagga and Baldwin, 1998) and CEAFe (Luo, 2005). We also report the unweighted average of the three scores, which was the official evaluation metric in the shared tasks. To compute the scores we employed the official scorer supplied by the shared task organizers. 5.2 Results Table 1 displays the performance of our model and of the systems that obtained the best (Fernandes et al., 2012) and the median performance in the 84 MUC average R P F1 R P F1 R P F1 B3 CEAF, CoNLL’12 English development data best 64.88 74.74 69.46 66.53 78.28 71.93 54.93 43.68 48.66 63.35 median 62.3 62.8 62.0 66.7 71.8 69.1 46.4 44.9 45.6 58.9 t</context>
</contexts>
<marker>Bagga, Baldwin, 1998</marker>
<rawString>Amit Bagga and Breck Baldwin. 1998. Algorithms for scoring coreference chains. In Proceedings of the 1st International Conference on Language Resources and Evaluation, Granada, Spain, 28–30 May 1998, pages 563–566.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shane Bergsma</author>
<author>Dekang Lin</author>
</authors>
<title>Bootstrapping path-based pronoun resolution.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>33--40</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="11372" citStr="Bergsma and Lin (2006)" startWordPosition="1907" endWordPosition="1910"> al., 2011b). All relations operate on pairs of mentions (m, n), where m is the anaphor and n is a candidate antecedent. If a relation r holds for (m, n), the edge (m, n, r) is added to the graph. We finalized the set of relations and their distance thresholds on development data. 4.1 Negative Relations Negative relations receive negative weights. They allow us to introduce well-known constraints such as agreement into our model. (1) N Gender, (2) N Number: Two mentions do not agree in gender or number. We compute number and gender for common nouns using the number and gender data provided by Bergsma and Lin (2006). (3) N SemanticClass: Two mentions do not agree in semantic class (we only use the top categories Object, Date and Person from WordNet (Fellbaum, 1998)). (4) N ItDist: The anaphor is it or they and the sentence distance to the antecedent is larger 83 than one. (5) N Speaker12Pron: Two first person pronouns or two second person pronouns with different speakers, or one first person pronoun and one second person pronoun with the same speaker2. (6) N ContraSubObj: Two mentions are in the subject/object positions of the same verb, the anaphor is a non-possessive/reflexive pronoun. (7) N Mod: Two m</context>
<context position="14868" citStr="Bergsma and Lin (2006)" startWordPosition="2498" endWordPosition="2501">onoun tokens but agree in number, gender and person. 5 Evaluation 5.1 Data and Evaluation Metrics We use the data provided for the English track of the CoNLL’12 shared task on multilingual coreference resolution (Pradhan et al., 2012) which is a subset of the upcoming OntoNotes 5.0 release and comes with various annotation layers provided by state-of-the-art NLP tools. We used the official dev/test split for development and evaluation. We evaluate the model in a setting that corresponds to the shared task’s closed track, i.e. we use only WordNet (Fellbaum, 1998), the number and gender data of Bergsma and Lin (2006) and the provided annotation layers. To extract system mentions we employ the mention extractor described in Martschat et al. (2012). We evaluate our system with the coreference resolution evaluation metrics that were used for the CoNLL shared tasks on coreference, which are MUC (Vilain et al., 1995), B3 (Bagga and Baldwin, 1998) and CEAFe (Luo, 2005). We also report the unweighted average of the three scores, which was the official evaluation metric in the shared tasks. To compute the scores we employed the official scorer supplied by the shared task organizers. 5.2 Results Table 1 displays t</context>
</contexts>
<marker>Bergsma, Lin, 2006</marker>
<rawString>Shane Bergsma and Dekang Lin. 2006. Bootstrapping path-based pronoun resolution. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, Sydney, Australia, 17–21 July 2006, pages 33–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jie Cai</author>
<author>Michael Strube</author>
</authors>
<title>End-to-end coreference resolution via hypergraph partitioning.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics,</booktitle>
<volume>23</volume>
<pages>143--151</pages>
<location>Beijing,</location>
<contexts>
<context position="1745" citStr="Cai and Strube, 2010" startWordPosition="255" endWordPosition="258"> that carefully crafted rule-based systems which employ suitable inference schemes can achieve competitive performance. Such a system can be considered unsupervised in the sense that it does not employ training data for optimizing parameters. In this paper we present a graph-based approach for coreference resolution that models a document to be processed as a graph. The nodes are mentions and the edges correspond to relations between mentions. Coreference resolution is performed via graph clustering. Our approach belongs to a class of recently proposed graph models for coreference resolution (Cai and Strube, 2010; Sapena et al., 2010; Martschat et al., 2012) and is designed to be a simplified version of existing approaches. In contrast to previous models belonging to this class we do not learn any edge weights but perform inference on the graph structure only which renders our model unsupervised. On the English data of the CoNLL’12 shared task the model outperforms most systems which participated in the shared task. 2 Related Work Graph-based coreference resolution. While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as gree</context>
<context position="2983" citStr="Cai and Strube (2010)" startWordPosition="454" endWordPosition="457">a multigraph, where edges representing factors for pronoun resolution have negative or positive weight. This yields a model similar to the one presented in this paper though Mitkov’s work has only been applied to pronoun resolution. Nicolae and Nicolae (2006) phrase coreference resolution as a graph clustering problem: they first perform pairwise classification and then construct a graph using the derived confidence values as edge weights. In contrast, work by Culotta et al. (2007), Cai and Strube (2010) and Sapena et al. (2010) omits the classification step entirely. Sapena et al. (2010) and Cai and Strube (2010) perform coreference resolution in one step using graph partitioning approaches. These approaches participated in the recent CoNLL’11 shared task (Pradhan et al., 2011; Sapena et al., 2011; Cai et al., 2011b) with excellent results. The approach by Cai et al. (2011b) has been modified by Martschat et al. (2012) and ranked second in the English track at the CoNLL’12 shared task (Pradhan et al., 2012). The top performing system at the CoNLL’12 shared task (Fernandes et al., 2012) 81 Proceedings of the ACL Student Research Workshop, pages 81–88, Sofia, Bulgaria, August 4-9 2013. c�2013 Associatio</context>
</contexts>
<marker>Cai, Strube, 2010</marker>
<rawString>Jie Cai and Michael Strube. 2010. End-to-end coreference resolution via hypergraph partitioning. In Proceedings of the 23rd International Conference on Computational Linguistics, Beijing, China, 23– 27 August 2010, pages 143–151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jie Cai</author>
<author>´Eva M´ujdricza-Maydt</author>
<author>Yufang Hou</author>
<author>Michael Strube</author>
</authors>
<title>Weakly supervised graphbased coreference resolution for clinical data.</title>
<date>2011</date>
<booktitle>In Proceedings of the 5th i2b2 Shared Tasks and Workshop on Challenges in Natural Language Processing for Clinical Data,</booktitle>
<location>Washington, D.C.,</location>
<marker>Cai, M´ujdricza-Maydt, Hou, Strube, 2011</marker>
<rawString>Jie Cai, ´Eva M´ujdricza-Maydt, Yufang Hou, and Michael Strube. 2011a. Weakly supervised graphbased coreference resolution for clinical data. In Proceedings of the 5th i2b2 Shared Tasks and Workshop on Challenges in Natural Language Processing for Clinical Data, Washington, D.C., 20-21 October 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jie Cai</author>
<author>´Eva M´ujdricza-Maydt</author>
<author>Michael Strube</author>
</authors>
<title>Unrestricted coreference resolution via global hypergraph partitioning.</title>
<date>2011</date>
<booktitle>In Proceedings of the Shared Task of the 15th Conference on Computational Natural Language Learning,</booktitle>
<pages>56--60</pages>
<location>Portland, Oreg., 23–24</location>
<marker>Cai, M´ujdricza-Maydt, Strube, 2011</marker>
<rawString>Jie Cai, ´Eva M´ujdricza-Maydt, and Michael Strube. 2011b. Unrestricted coreference resolution via global hypergraph partitioning. In Proceedings of the Shared Task of the 15th Conference on Computational Natural Language Learning, Portland, Oreg., 23–24 June 2011, pages 56–60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Cardie</author>
<author>Kiri Wagstaff</author>
</authors>
<title>Noun phrase coreference as clustering.</title>
<date>1999</date>
<booktitle>In Proceedings of the 1999 SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora,</booktitle>
<pages>82--89</pages>
<location>College Park, Md., 21–22</location>
<contexts>
<context position="3894" citStr="Cardie and Wagstaff (1999)" startWordPosition="598" endWordPosition="601"> by Martschat et al. (2012) and ranked second in the English track at the CoNLL’12 shared task (Pradhan et al., 2012). The top performing system at the CoNLL’12 shared task (Fernandes et al., 2012) 81 Proceedings of the ACL Student Research Workshop, pages 81–88, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics also represents the problem as a graph by performing inference on trees constructed using the multi-pass sieve approach by Raghunathan et al. (2010) and Lee et al. (2011), which in turn won the CoNLL’11 shared task. Unsupervised coreference resolution. Cardie and Wagstaff (1999) present an early approach to unsupervised coreference resolution based on a straightforward clustering approach. Angheluta et al. (2004) build on their approach and devise more sophisticated clustering algorithms. Haghighi and Klein (2007), Ng (2008) and Charniak and Elsner (2009) employ unsupervised generative models. Poon and Domingos (2008) present a Markov Logic Network approach to unsupervised coreference resolution. These approaches reach competitive performance on gold mentions but not on system mentions (Ng, 2008). The multi-pass sieve approach by Raghunathan et al. (2010) can also be</context>
<context position="10684" citStr="Cardie and Wagstaff, 1999" startWordPosition="1780" endWordPosition="1783"> setting described in Section 3.4 this algorithm reduces to choosing the child that is connected via the highest number of positive relations and via no negative relation. For the graph depicted in Figure 1 this algorithm computes the clusters {They, Leaders}, {Paris} and {recent developments}. 4 Relations The graph model described in Section 3 is based on expressing relations between pairs of mentions via edges built from such relations. We now describe the relations currently used by our system. They are well-known indicators and constraints for coreference and are taken from previous work (Cardie and Wagstaff, 1999; Soon et al., 2001; Rahman and Ng, 2009; Lee et al., 2011; Cai et al., 2011b). All relations operate on pairs of mentions (m, n), where m is the anaphor and n is a candidate antecedent. If a relation r holds for (m, n), the edge (m, n, r) is added to the graph. We finalized the set of relations and their distance thresholds on development data. 4.1 Negative Relations Negative relations receive negative weights. They allow us to introduce well-known constraints such as agreement into our model. (1) N Gender, (2) N Number: Two mentions do not agree in gender or number. We compute number and gen</context>
</contexts>
<marker>Cardie, Wagstaff, 1999</marker>
<rawString>Claire Cardie and Kiri Wagstaff. 1999. Noun phrase coreference as clustering. In Proceedings of the 1999 SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora, College Park, Md., 21–22 June 1999, pages 82–89.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Micha Elsner</author>
</authors>
<title>EM works for pronoun anaphora resolution.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<volume>3</volume>
<pages>148--156</pages>
<location>Athens,</location>
<contexts>
<context position="4176" citStr="Charniak and Elsner (2009)" startWordPosition="637" endWordPosition="641">ugust 4-9 2013. c�2013 Association for Computational Linguistics also represents the problem as a graph by performing inference on trees constructed using the multi-pass sieve approach by Raghunathan et al. (2010) and Lee et al. (2011), which in turn won the CoNLL’11 shared task. Unsupervised coreference resolution. Cardie and Wagstaff (1999) present an early approach to unsupervised coreference resolution based on a straightforward clustering approach. Angheluta et al. (2004) build on their approach and devise more sophisticated clustering algorithms. Haghighi and Klein (2007), Ng (2008) and Charniak and Elsner (2009) employ unsupervised generative models. Poon and Domingos (2008) present a Markov Logic Network approach to unsupervised coreference resolution. These approaches reach competitive performance on gold mentions but not on system mentions (Ng, 2008). The multi-pass sieve approach by Raghunathan et al. (2010) can also be viewed as unsupervised. 3 A Multigraph Model We aim for a model which directly represents the relations between mentions in a graph structure. Clusters in the graph then correspond to entities. 3.1 Motivation To motivate the choice of our model, let us consider a simple made-up ex</context>
</contexts>
<marker>Charniak, Elsner, 2009</marker>
<rawString>Eugene Charniak and Micha Elsner. 2009. EM works for pronoun anaphora resolution. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, Athens, Greece, 30 March – 3 April 2009, pages 148–156.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aron Culotta</author>
<author>Michael Wick</author>
<author>Andrew McCallum</author>
</authors>
<title>First-order probabilistic models for coreference resolution.</title>
<date>2007</date>
<booktitle>In Proceedings of Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>81--88</pages>
<location>Rochester, N.Y.,</location>
<contexts>
<context position="2848" citStr="Culotta et al. (2007)" startWordPosition="431" endWordPosition="434"> within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight. This yields a model similar to the one presented in this paper though Mitkov’s work has only been applied to pronoun resolution. Nicolae and Nicolae (2006) phrase coreference resolution as a graph clustering problem: they first perform pairwise classification and then construct a graph using the derived confidence values as edge weights. In contrast, work by Culotta et al. (2007), Cai and Strube (2010) and Sapena et al. (2010) omits the classification step entirely. Sapena et al. (2010) and Cai and Strube (2010) perform coreference resolution in one step using graph partitioning approaches. These approaches participated in the recent CoNLL’11 shared task (Pradhan et al., 2011; Sapena et al., 2011; Cai et al., 2011b) with excellent results. The approach by Cai et al. (2011b) has been modified by Martschat et al. (2012) and ranked second in the English track at the CoNLL’12 shared task (Pradhan et al., 2012). The top performing system at the CoNLL’12 shared task (Fernan</context>
</contexts>
<marker>Culotta, Wick, McCallum, 2007</marker>
<rawString>Aron Culotta, Michael Wick, and Andrew McCallum. 2007. First-order probabilistic models for coreference resolution. In Proceedings of Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics, Rochester, N.Y., 22–27 April 2007, pages 81–88.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, Mass.</location>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. MIT Press, Cambridge, Mass.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eraldo Fernandes</author>
<author>C´ıcero dos Santos</author>
<author>Ruy Milidi´u</author>
</authors>
<title>Latent structure perceptron with feature induction for unrestricted coreference resolution.</title>
<date>2012</date>
<booktitle>In Proceedings of the Shared Task of the 16th Conference on Computational Natural Language Learning,</booktitle>
<pages>41--48</pages>
<location>Jeju Island,</location>
<marker>Fernandes, Santos, Milidi´u, 2012</marker>
<rawString>Eraldo Fernandes, C´ıcero dos Santos, and Ruy Milidi´u. 2012. Latent structure perceptron with feature induction for unrestricted coreference resolution. In Proceedings of the Shared Task of the 16th Conference on Computational Natural Language Learning, Jeju Island, Korea, 12–14 July 2012, pages 41–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Dan Klein</author>
</authors>
<title>Unsupervised coreference resolution in a nonparametric Bayesian model.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>848--855</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="4134" citStr="Haghighi and Klein (2007)" startWordPosition="630" endWordPosition="633">Workshop, pages 81–88, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics also represents the problem as a graph by performing inference on trees constructed using the multi-pass sieve approach by Raghunathan et al. (2010) and Lee et al. (2011), which in turn won the CoNLL’11 shared task. Unsupervised coreference resolution. Cardie and Wagstaff (1999) present an early approach to unsupervised coreference resolution based on a straightforward clustering approach. Angheluta et al. (2004) build on their approach and devise more sophisticated clustering algorithms. Haghighi and Klein (2007), Ng (2008) and Charniak and Elsner (2009) employ unsupervised generative models. Poon and Domingos (2008) present a Markov Logic Network approach to unsupervised coreference resolution. These approaches reach competitive performance on gold mentions but not on system mentions (Ng, 2008). The multi-pass sieve approach by Raghunathan et al. (2010) can also be viewed as unsupervised. 3 A Multigraph Model We aim for a model which directly represents the relations between mentions in a graph structure. Clusters in the graph then correspond to entities. 3.1 Motivation To motivate the choice of our </context>
</contexts>
<marker>Haghighi, Klein, 2007</marker>
<rawString>Aria Haghighi and Dan Klein. 2007. Unsupervised coreference resolution in a nonparametric Bayesian model. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics, Prague, Czech Republic, 23–30 June 2007, pages 848–855.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heeyoung Lee</author>
<author>Yves Peirsman</author>
<author>Angel Chang</author>
<author>Nathanael Chambers</author>
<author>Mihai Surdeanu</author>
<author>Dan Jurafsky</author>
</authors>
<title>Stanford’s multi-pass sieve coreference resolution system at the CoNLL-2011 shared task.</title>
<date>2011</date>
<booktitle>In Proceedings of the Shared Task of the 15th Conference on Computational Natural Language Learning,</booktitle>
<pages>28--34</pages>
<location>Portland, Oreg., 23–24</location>
<contexts>
<context position="1082" citStr="Lee et al., 2011" startWordPosition="150" endWordPosition="153">ask. 1 Introduction Coreference resolution is the task of determining which mentions in a text refer to the same entity. With the advent of machine learning and the availability of annotated corpora in the mid 1990s the research focus shifted from rule-based approaches to supervised machine learning techniques. Quite recently, however, rule-based approaches regained popularity due to Stanford’s multi-pass sieve approach which exhibits stateof-the-art performance on many standard coreference data sets (Raghunathan et al., 2010) and also won the CoNLL-2011 shared task on coreference resolution (Lee et al., 2011; Pradhan et al., 2011). These results show that carefully crafted rule-based systems which employ suitable inference schemes can achieve competitive performance. Such a system can be considered unsupervised in the sense that it does not employ training data for optimizing parameters. In this paper we present a graph-based approach for coreference resolution that models a document to be processed as a graph. The nodes are mentions and the edges correspond to relations between mentions. Coreference resolution is performed via graph clustering. Our approach belongs to a class of recently propose</context>
<context position="3785" citStr="Lee et al. (2011)" startWordPosition="583" endWordPosition="586">011; Cai et al., 2011b) with excellent results. The approach by Cai et al. (2011b) has been modified by Martschat et al. (2012) and ranked second in the English track at the CoNLL’12 shared task (Pradhan et al., 2012). The top performing system at the CoNLL’12 shared task (Fernandes et al., 2012) 81 Proceedings of the ACL Student Research Workshop, pages 81–88, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics also represents the problem as a graph by performing inference on trees constructed using the multi-pass sieve approach by Raghunathan et al. (2010) and Lee et al. (2011), which in turn won the CoNLL’11 shared task. Unsupervised coreference resolution. Cardie and Wagstaff (1999) present an early approach to unsupervised coreference resolution based on a straightforward clustering approach. Angheluta et al. (2004) build on their approach and devise more sophisticated clustering algorithms. Haghighi and Klein (2007), Ng (2008) and Charniak and Elsner (2009) employ unsupervised generative models. Poon and Domingos (2008) present a Markov Logic Network approach to unsupervised coreference resolution. These approaches reach competitive performance on gold mentions </context>
<context position="10742" citStr="Lee et al., 2011" startWordPosition="1792" endWordPosition="1795">g the child that is connected via the highest number of positive relations and via no negative relation. For the graph depicted in Figure 1 this algorithm computes the clusters {They, Leaders}, {Paris} and {recent developments}. 4 Relations The graph model described in Section 3 is based on expressing relations between pairs of mentions via edges built from such relations. We now describe the relations currently used by our system. They are well-known indicators and constraints for coreference and are taken from previous work (Cardie and Wagstaff, 1999; Soon et al., 2001; Rahman and Ng, 2009; Lee et al., 2011; Cai et al., 2011b). All relations operate on pairs of mentions (m, n), where m is the anaphor and n is a candidate antecedent. If a relation r holds for (m, n), the edge (m, n, r) is added to the graph. We finalized the set of relations and their distance thresholds on development data. 4.1 Negative Relations Negative relations receive negative weights. They allow us to introduce well-known constraints such as agreement into our model. (1) N Gender, (2) N Number: Two mentions do not agree in gender or number. We compute number and gender for common nouns using the number and gender data prov</context>
</contexts>
<marker>Lee, Peirsman, Chang, Chambers, Surdeanu, Jurafsky, 2011</marker>
<rawString>Heeyoung Lee, Yves Peirsman, Angel Chang, Nathanael Chambers, Mihai Surdeanu, and Dan Jurafsky. 2011. Stanford’s multi-pass sieve coreference resolution system at the CoNLL-2011 shared task. In Proceedings of the Shared Task of the 15th Conference on Computational Natural Language Learning, Portland, Oreg., 23–24 June 2011, pages 28–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoqiang Luo</author>
</authors>
<title>On coreference resolution performance metrics.</title>
<date>2005</date>
<booktitle>In Proceedings of the Human Language Technology Conference and the 2005 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>25--32</pages>
<location>Vancouver, B.C.,</location>
<contexts>
<context position="15221" citStr="Luo, 2005" startWordPosition="2559" endWordPosition="2560">tools. We used the official dev/test split for development and evaluation. We evaluate the model in a setting that corresponds to the shared task’s closed track, i.e. we use only WordNet (Fellbaum, 1998), the number and gender data of Bergsma and Lin (2006) and the provided annotation layers. To extract system mentions we employ the mention extractor described in Martschat et al. (2012). We evaluate our system with the coreference resolution evaluation metrics that were used for the CoNLL shared tasks on coreference, which are MUC (Vilain et al., 1995), B3 (Bagga and Baldwin, 1998) and CEAFe (Luo, 2005). We also report the unweighted average of the three scores, which was the official evaluation metric in the shared tasks. To compute the scores we employed the official scorer supplied by the shared task organizers. 5.2 Results Table 1 displays the performance of our model and of the systems that obtained the best (Fernandes et al., 2012) and the median performance in the 84 MUC average R P F1 R P F1 R P F1 B3 CEAF, CoNLL’12 English development data best 64.88 74.74 69.46 66.53 78.28 71.93 54.93 43.68 48.66 63.35 median 62.3 62.8 62.0 66.7 71.8 69.1 46.4 44.9 45.6 58.9 this work (weights frac</context>
</contexts>
<marker>Luo, 2005</marker>
<rawString>Xiaoqiang Luo. 2005. On coreference resolution performance metrics. In Proceedings of the Human Language Technology Conference and the 2005 Conference on Empirical Methods in Natural Language Processing, Vancouver, B.C., Canada, 6–8 October 2005, pages 25–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Martschat</author>
<author>Jie Cai</author>
<author>Samuel Broscheit</author>
<author>´Eva M´ujdricza-Maydt</author>
<author>Michael Strube</author>
</authors>
<title>A multigraph model for coreference resolution.</title>
<date>2012</date>
<booktitle>In Proceedings of the Shared Task of the 16th Conference on Computational Natural Language Learning,</booktitle>
<pages>100--106</pages>
<location>Jeju Island,</location>
<marker>Martschat, Cai, Broscheit, M´ujdricza-Maydt, Strube, 2012</marker>
<rawString>Sebastian Martschat, Jie Cai, Samuel Broscheit, ´Eva M´ujdricza-Maydt, and Michael Strube. 2012. A multigraph model for coreference resolution. In Proceedings of the Shared Task of the 16th Conference on Computational Natural Language Learning, Jeju Island, Korea, 12–14 July 2012, pages 100–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruslan Mitkov</author>
</authors>
<title>Robust pronoun resolution with limited knowledge.</title>
<date>1998</date>
<booktitle>In Proceedings of the 17th International Conference on Computational Linguistics and 36th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>869--875</pages>
<location>Montr´eal, Qu´ebec, Canada, 10–14</location>
<contexts>
<context position="2321" citStr="Mitkov, 1998" startWordPosition="348" endWordPosition="349">ence resolution (Cai and Strube, 2010; Sapena et al., 2010; Martschat et al., 2012) and is designed to be a simplified version of existing approaches. In contrast to previous models belonging to this class we do not learn any edge weights but perform inference on the graph structure only which renders our model unsupervised. On the English data of the CoNLL’12 shared task the model outperforms most systems which participated in the shared task. 2 Related Work Graph-based coreference resolution. While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight. This yields a model similar to the one presented in this paper though Mitkov’s work has only been applied to pronoun resolution. Nicolae and Nicolae (2006) phrase coreference resolution as a graph clustering problem: they first perform pairwise classification and then construct a graph using the derived confidence values as edge weights. In contrast, work by Culotta et al. (2007), Cai and Strube (2010) and Sapena et al. (2010) omits the classification</context>
</contexts>
<marker>Mitkov, 1998</marker>
<rawString>Ruslan Mitkov. 1998. Robust pronoun resolution with limited knowledge. In Proceedings of the 17th International Conference on Computational Linguistics and 36th Annual Meeting of the Association for Computational Linguistics, Montr´eal, Qu´ebec, Canada, 10–14 August 1998, pages 869–875.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
</authors>
<title>Unsupervised models for coreference resolution.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>640--649</pages>
<location>Waikiki, Honolulu, Hawaii,</location>
<contexts>
<context position="4145" citStr="Ng (2008)" startWordPosition="634" endWordPosition="635">a, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics also represents the problem as a graph by performing inference on trees constructed using the multi-pass sieve approach by Raghunathan et al. (2010) and Lee et al. (2011), which in turn won the CoNLL’11 shared task. Unsupervised coreference resolution. Cardie and Wagstaff (1999) present an early approach to unsupervised coreference resolution based on a straightforward clustering approach. Angheluta et al. (2004) build on their approach and devise more sophisticated clustering algorithms. Haghighi and Klein (2007), Ng (2008) and Charniak and Elsner (2009) employ unsupervised generative models. Poon and Domingos (2008) present a Markov Logic Network approach to unsupervised coreference resolution. These approaches reach competitive performance on gold mentions but not on system mentions (Ng, 2008). The multi-pass sieve approach by Raghunathan et al. (2010) can also be viewed as unsupervised. 3 A Multigraph Model We aim for a model which directly represents the relations between mentions in a graph structure. Clusters in the graph then correspond to entities. 3.1 Motivation To motivate the choice of our model, let </context>
</contexts>
<marker>Ng, 2008</marker>
<rawString>Vincent Ng. 2008. Unsupervised models for coreference resolution. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, Waikiki, Honolulu, Hawaii, 25–27 October 2008, pages 640–649.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cristina Nicolae</author>
<author>Gabriel Nicolae</author>
</authors>
<title>BestCut: A graph algorithm for coreference resolution.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>275--283</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="2621" citStr="Nicolae and Nicolae (2006)" startWordPosition="395" endWordPosition="398">y which renders our model unsupervised. On the English data of the CoNLL’12 shared task the model outperforms most systems which participated in the shared task. 2 Related Work Graph-based coreference resolution. While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight. This yields a model similar to the one presented in this paper though Mitkov’s work has only been applied to pronoun resolution. Nicolae and Nicolae (2006) phrase coreference resolution as a graph clustering problem: they first perform pairwise classification and then construct a graph using the derived confidence values as edge weights. In contrast, work by Culotta et al. (2007), Cai and Strube (2010) and Sapena et al. (2010) omits the classification step entirely. Sapena et al. (2010) and Cai and Strube (2010) perform coreference resolution in one step using graph partitioning approaches. These approaches participated in the recent CoNLL’11 shared task (Pradhan et al., 2011; Sapena et al., 2011; Cai et al., 2011b) with excellent results. The a</context>
</contexts>
<marker>Nicolae, Nicolae, 2006</marker>
<rawString>Cristina Nicolae and Gabriel Nicolae. 2006. BestCut: A graph algorithm for coreference resolution. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, Sydney, Australia, 22–23 July 2006, pages 275–283.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoifung Poon</author>
<author>Pedro Domingos</author>
</authors>
<title>Joint unsupervised coreference resolution with Markov Logic.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>650--659</pages>
<location>Waikiki, Honolulu, Hawaii,</location>
<contexts>
<context position="4240" citStr="Poon and Domingos (2008)" startWordPosition="647" endWordPosition="650">lso represents the problem as a graph by performing inference on trees constructed using the multi-pass sieve approach by Raghunathan et al. (2010) and Lee et al. (2011), which in turn won the CoNLL’11 shared task. Unsupervised coreference resolution. Cardie and Wagstaff (1999) present an early approach to unsupervised coreference resolution based on a straightforward clustering approach. Angheluta et al. (2004) build on their approach and devise more sophisticated clustering algorithms. Haghighi and Klein (2007), Ng (2008) and Charniak and Elsner (2009) employ unsupervised generative models. Poon and Domingos (2008) present a Markov Logic Network approach to unsupervised coreference resolution. These approaches reach competitive performance on gold mentions but not on system mentions (Ng, 2008). The multi-pass sieve approach by Raghunathan et al. (2010) can also be viewed as unsupervised. 3 A Multigraph Model We aim for a model which directly represents the relations between mentions in a graph structure. Clusters in the graph then correspond to entities. 3.1 Motivation To motivate the choice of our model, let us consider a simple made-up example. Leaders met in Paris to discuss recent developments. They</context>
</contexts>
<marker>Poon, Domingos, 2008</marker>
<rawString>Hoifung Poon and Pedro Domingos. 2008. Joint unsupervised coreference resolution with Markov Logic. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, Waikiki, Honolulu, Hawaii, 25–27 October 2008, pages 650– 659.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Lance Ramshaw</author>
<author>Mitchell Marcus</author>
<author>Martha Palmer</author>
<author>Ralph Weischedel</author>
<author>Nianwen Xue</author>
</authors>
<title>CoNLL-2011 Shared Task: Modeling unrestricted coreference in OntoNotes.</title>
<date>2011</date>
<booktitle>In Proceedings of the Shared Task of the 15th Conference on Computational Natural Language Learning,</booktitle>
<pages>1--27</pages>
<location>Portland, Oreg., 23–24</location>
<contexts>
<context position="1105" citStr="Pradhan et al., 2011" startWordPosition="154" endWordPosition="157">n Coreference resolution is the task of determining which mentions in a text refer to the same entity. With the advent of machine learning and the availability of annotated corpora in the mid 1990s the research focus shifted from rule-based approaches to supervised machine learning techniques. Quite recently, however, rule-based approaches regained popularity due to Stanford’s multi-pass sieve approach which exhibits stateof-the-art performance on many standard coreference data sets (Raghunathan et al., 2010) and also won the CoNLL-2011 shared task on coreference resolution (Lee et al., 2011; Pradhan et al., 2011). These results show that carefully crafted rule-based systems which employ suitable inference schemes can achieve competitive performance. Such a system can be considered unsupervised in the sense that it does not employ training data for optimizing parameters. In this paper we present a graph-based approach for coreference resolution that models a document to be processed as a graph. The nodes are mentions and the edges correspond to relations between mentions. Coreference resolution is performed via graph clustering. Our approach belongs to a class of recently proposed graph models for core</context>
<context position="3150" citStr="Pradhan et al., 2011" startWordPosition="477" endWordPosition="480">hough Mitkov’s work has only been applied to pronoun resolution. Nicolae and Nicolae (2006) phrase coreference resolution as a graph clustering problem: they first perform pairwise classification and then construct a graph using the derived confidence values as edge weights. In contrast, work by Culotta et al. (2007), Cai and Strube (2010) and Sapena et al. (2010) omits the classification step entirely. Sapena et al. (2010) and Cai and Strube (2010) perform coreference resolution in one step using graph partitioning approaches. These approaches participated in the recent CoNLL’11 shared task (Pradhan et al., 2011; Sapena et al., 2011; Cai et al., 2011b) with excellent results. The approach by Cai et al. (2011b) has been modified by Martschat et al. (2012) and ranked second in the English track at the CoNLL’12 shared task (Pradhan et al., 2012). The top performing system at the CoNLL’12 shared task (Fernandes et al., 2012) 81 Proceedings of the ACL Student Research Workshop, pages 81–88, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics also represents the problem as a graph by performing inference on trees constructed using the multi-pass sieve approach by Raghunathan </context>
</contexts>
<marker>Pradhan, Ramshaw, Marcus, Palmer, Weischedel, Xue, 2011</marker>
<rawString>Sameer Pradhan, Lance Ramshaw, Mitchell Marcus, Martha Palmer, Ralph Weischedel, and Nianwen Xue. 2011. CoNLL-2011 Shared Task: Modeling unrestricted coreference in OntoNotes. In Proceedings of the Shared Task of the 15th Conference on Computational Natural Language Learning, Portland, Oreg., 23–24 June 2011, pages 1–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Alessandro Moschitti</author>
<author>Nianwen Xue</author>
</authors>
<title>CoNLL-2012 Shared Task: Modeling multilingual unrestricted coreference in OntoNotes.</title>
<date>2012</date>
<booktitle>In Proceedings of the Shared Task of the 16th Conference on Computational Natural Language Learning,</booktitle>
<pages>1--40</pages>
<location>Jeju Island,</location>
<contexts>
<context position="3385" citStr="Pradhan et al., 2012" startWordPosition="520" endWordPosition="524">erived confidence values as edge weights. In contrast, work by Culotta et al. (2007), Cai and Strube (2010) and Sapena et al. (2010) omits the classification step entirely. Sapena et al. (2010) and Cai and Strube (2010) perform coreference resolution in one step using graph partitioning approaches. These approaches participated in the recent CoNLL’11 shared task (Pradhan et al., 2011; Sapena et al., 2011; Cai et al., 2011b) with excellent results. The approach by Cai et al. (2011b) has been modified by Martschat et al. (2012) and ranked second in the English track at the CoNLL’12 shared task (Pradhan et al., 2012). The top performing system at the CoNLL’12 shared task (Fernandes et al., 2012) 81 Proceedings of the ACL Student Research Workshop, pages 81–88, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics also represents the problem as a graph by performing inference on trees constructed using the multi-pass sieve approach by Raghunathan et al. (2010) and Lee et al. (2011), which in turn won the CoNLL’11 shared task. Unsupervised coreference resolution. Cardie and Wagstaff (1999) present an early approach to unsupervised coreference resolution based on a straightforwar</context>
<context position="14480" citStr="Pradhan et al., 2012" startWordPosition="2434" endWordPosition="2437">redicate as the antecedent. This relation is restricted to a sentence distance of 1. (20) P Subject, (21) P Object: The anaphor is a third person pronoun and both mentions are subjects/objects. These relations are restricted to a sentence distance of 1. (22) P Pron StrMatch: If both mentions are pronouns and their strings match. (23) P Pron Agreement: If both mentions are different pronoun tokens but agree in number, gender and person. 5 Evaluation 5.1 Data and Evaluation Metrics We use the data provided for the English track of the CoNLL’12 shared task on multilingual coreference resolution (Pradhan et al., 2012) which is a subset of the upcoming OntoNotes 5.0 release and comes with various annotation layers provided by state-of-the-art NLP tools. We used the official dev/test split for development and evaluation. We evaluate the model in a setting that corresponds to the shared task’s closed track, i.e. we use only WordNet (Fellbaum, 1998), the number and gender data of Bergsma and Lin (2006) and the provided annotation layers. To extract system mentions we employ the mention extractor described in Martschat et al. (2012). We evaluate our system with the coreference resolution evaluation metrics that</context>
</contexts>
<marker>Pradhan, Moschitti, Xue, 2012</marker>
<rawString>Sameer Pradhan, Alessandro Moschitti, and Nianwen Xue. 2012. CoNLL-2012 Shared Task: Modeling multilingual unrestricted coreference in OntoNotes. In Proceedings of the Shared Task of the 16th Conference on Computational Natural Language Learning, Jeju Island, Korea, 12–14 July 2012, pages 1– 40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karthik Raghunathan</author>
<author>Heeyoung Lee</author>
<author>Sudarshan Rangarajan</author>
<author>Nathanael Chambers</author>
<author>Mihai Surdeanu</author>
<author>Dan Jurafsky</author>
<author>Christopher Manning</author>
</authors>
<title>A multipass sieve for coreference resolution.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>492--501</pages>
<location>Cambridge, Mass., 9–11</location>
<contexts>
<context position="998" citStr="Raghunathan et al., 2010" startWordPosition="135" endWordPosition="138">he model outperforms most systems participating in the English track of the CoNLL’12 shared task. 1 Introduction Coreference resolution is the task of determining which mentions in a text refer to the same entity. With the advent of machine learning and the availability of annotated corpora in the mid 1990s the research focus shifted from rule-based approaches to supervised machine learning techniques. Quite recently, however, rule-based approaches regained popularity due to Stanford’s multi-pass sieve approach which exhibits stateof-the-art performance on many standard coreference data sets (Raghunathan et al., 2010) and also won the CoNLL-2011 shared task on coreference resolution (Lee et al., 2011; Pradhan et al., 2011). These results show that carefully crafted rule-based systems which employ suitable inference schemes can achieve competitive performance. Such a system can be considered unsupervised in the sense that it does not employ training data for optimizing parameters. In this paper we present a graph-based approach for coreference resolution that models a document to be processed as a graph. The nodes are mentions and the edges correspond to relations between mentions. Coreference resolution is</context>
<context position="3763" citStr="Raghunathan et al. (2010)" startWordPosition="578" endWordPosition="581">et al., 2011; Sapena et al., 2011; Cai et al., 2011b) with excellent results. The approach by Cai et al. (2011b) has been modified by Martschat et al. (2012) and ranked second in the English track at the CoNLL’12 shared task (Pradhan et al., 2012). The top performing system at the CoNLL’12 shared task (Fernandes et al., 2012) 81 Proceedings of the ACL Student Research Workshop, pages 81–88, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics also represents the problem as a graph by performing inference on trees constructed using the multi-pass sieve approach by Raghunathan et al. (2010) and Lee et al. (2011), which in turn won the CoNLL’11 shared task. Unsupervised coreference resolution. Cardie and Wagstaff (1999) present an early approach to unsupervised coreference resolution based on a straightforward clustering approach. Angheluta et al. (2004) build on their approach and devise more sophisticated clustering algorithms. Haghighi and Klein (2007), Ng (2008) and Charniak and Elsner (2009) employ unsupervised generative models. Poon and Domingos (2008) present a Markov Logic Network approach to unsupervised coreference resolution. These approaches reach competitive perform</context>
</contexts>
<marker>Raghunathan, Lee, Rangarajan, Chambers, Surdeanu, Jurafsky, Manning, 2010</marker>
<rawString>Karthik Raghunathan, Heeyoung Lee, Sudarshan Rangarajan, Nathanael Chambers, Mihai Surdeanu, Dan Jurafsky, and Christopher Manning. 2010. A multipass sieve for coreference resolution. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, Cambridge, Mass., 9–11 October 2010, pages 492–501.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Altaf Rahman</author>
<author>Vincent Ng</author>
</authors>
<title>Supervised models for coreference resolution.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, Singapore, 6–7</booktitle>
<pages>968--977</pages>
<contexts>
<context position="10724" citStr="Rahman and Ng, 2009" startWordPosition="1788" endWordPosition="1791">hm reduces to choosing the child that is connected via the highest number of positive relations and via no negative relation. For the graph depicted in Figure 1 this algorithm computes the clusters {They, Leaders}, {Paris} and {recent developments}. 4 Relations The graph model described in Section 3 is based on expressing relations between pairs of mentions via edges built from such relations. We now describe the relations currently used by our system. They are well-known indicators and constraints for coreference and are taken from previous work (Cardie and Wagstaff, 1999; Soon et al., 2001; Rahman and Ng, 2009; Lee et al., 2011; Cai et al., 2011b). All relations operate on pairs of mentions (m, n), where m is the anaphor and n is a candidate antecedent. If a relation r holds for (m, n), the edge (m, n, r) is added to the graph. We finalized the set of relations and their distance thresholds on development data. 4.1 Negative Relations Negative relations receive negative weights. They allow us to introduce well-known constraints such as agreement into our model. (1) N Gender, (2) N Number: Two mentions do not agree in gender or number. We compute number and gender for common nouns using the number an</context>
</contexts>
<marker>Rahman, Ng, 2009</marker>
<rawString>Altaf Rahman and Vincent Ng. 2009. Supervised models for coreference resolution. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, Singapore, 6–7 August 2009, pages 968–977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emili Sapena</author>
<author>Llu´ıs Padr´o</author>
<author>Jordi Turmo</author>
</authors>
<title>A global relaxation labeling approach to coreference resolution.</title>
<date>2010</date>
<booktitle>In Proceedings of Coling 2010: Poster Volume,</booktitle>
<pages>1086--1094</pages>
<location>Beijing, China, 23–27</location>
<marker>Sapena, Padr´o, Turmo, 2010</marker>
<rawString>Emili Sapena, Llu´ıs Padr´o, and Jordi Turmo. 2010. A global relaxation labeling approach to coreference resolution. In Proceedings of Coling 2010: Poster Volume, Beijing, China, 23–27 August 2010, pages 1086–1094.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emili Sapena</author>
<author>Llu´ıs Padr´o</author>
<author>Jordi Turmo</author>
</authors>
<title>RelaxCor participation in CoNLL shared task on coreference resolution.</title>
<date>2011</date>
<booktitle>In Proceedings of the Shared Task of the 15th Conference on Computational Natural Language Learning,</booktitle>
<pages>35--39</pages>
<location>Portland, Oreg., 23–24</location>
<marker>Sapena, Padr´o, Turmo, 2011</marker>
<rawString>Emili Sapena, Llu´ıs Padr´o, and Jordi Turmo. 2011. RelaxCor participation in CoNLL shared task on coreference resolution. In Proceedings of the Shared Task of the 15th Conference on Computational Natural Language Learning, Portland, Oreg., 23–24 June 2011, pages 35–39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wee Meng Soon</author>
<author>Hwee Tou Ng</author>
<author>Daniel Chung Yong Lim</author>
</authors>
<title>A machine learning approach to coreference resolution of noun phrases.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>4</issue>
<contexts>
<context position="10703" citStr="Soon et al., 2001" startWordPosition="1784" endWordPosition="1787">on 3.4 this algorithm reduces to choosing the child that is connected via the highest number of positive relations and via no negative relation. For the graph depicted in Figure 1 this algorithm computes the clusters {They, Leaders}, {Paris} and {recent developments}. 4 Relations The graph model described in Section 3 is based on expressing relations between pairs of mentions via edges built from such relations. We now describe the relations currently used by our system. They are well-known indicators and constraints for coreference and are taken from previous work (Cardie and Wagstaff, 1999; Soon et al., 2001; Rahman and Ng, 2009; Lee et al., 2011; Cai et al., 2011b). All relations operate on pairs of mentions (m, n), where m is the anaphor and n is a candidate antecedent. If a relation r holds for (m, n), the edge (m, n, r) is added to the graph. We finalized the set of relations and their distance thresholds on development data. 4.1 Negative Relations Negative relations receive negative weights. They allow us to introduce well-known constraints such as agreement into our model. (1) N Gender, (2) N Number: Two mentions do not agree in gender or number. We compute number and gender for common noun</context>
<context position="17061" citStr="Soon et al., 2001" startWordPosition="2865" endWordPosition="2868">74.93 69.88 49.83 45.40 47.51 61.10 Table 1: Results of different systems on the CoNLL’12 English data sets. CoNLL’12 shared task, which are denoted as best and median respectively. best employs a structured prediction model with learned combinations of 70 basic features. We also compare with two supervised variants of our model which use the same relations and the same clustering algorithm as the unsupervised model: weights fraction sets the weight of a relation to the fraction of positive instances in training data (as in Martschat et al. (2012)). weights MaxEnt trains a mention-pair model (Soon et al., 2001) via the maximum entropy classifier implemented in the BART toolkit (Versley et al., 2008) and builds a graph where the weight of an edge connecting two mentions is the classifier’s prediction4. We use the official CoNLL’12 English training set for training. Our unsupervised model performs considerably better than the median system from the CoNLL’12 shared task on both data sets according to all metrics. It also seems to be able to accommodate well for the relations described in Section 4 since it outperforms both supervised variants5. The model performs worse than best, the gap according to B</context>
</contexts>
<marker>Soon, Ng, Lim, 2001</marker>
<rawString>Wee Meng Soon, Hwee Tou Ng, and Daniel Chung Yong Lim. 2001. A machine learning approach to coreference resolution of noun phrases. Computational Linguistics, 27(4):521–544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yannick Versley</author>
<author>Simone Paolo Ponzetto</author>
<author>Massimo Poesio</author>
<author>Vladimir Eidelman</author>
<author>Alan Jern</author>
<author>Jason Smith</author>
<author>Xiaofeng Yang</author>
<author>Alessandro Moschitti</author>
</authors>
<title>BART: A modular toolkit for coreference resolution.</title>
<date>2008</date>
<booktitle>In Companion Volume to the Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>9--12</pages>
<location>Columbus, Ohio,</location>
<contexts>
<context position="17151" citStr="Versley et al., 2008" startWordPosition="2880" endWordPosition="2883">12 English data sets. CoNLL’12 shared task, which are denoted as best and median respectively. best employs a structured prediction model with learned combinations of 70 basic features. We also compare with two supervised variants of our model which use the same relations and the same clustering algorithm as the unsupervised model: weights fraction sets the weight of a relation to the fraction of positive instances in training data (as in Martschat et al. (2012)). weights MaxEnt trains a mention-pair model (Soon et al., 2001) via the maximum entropy classifier implemented in the BART toolkit (Versley et al., 2008) and builds a graph where the weight of an edge connecting two mentions is the classifier’s prediction4. We use the official CoNLL’12 English training set for training. Our unsupervised model performs considerably better than the median system from the CoNLL’12 shared task on both data sets according to all metrics. It also seems to be able to accommodate well for the relations described in Section 4 since it outperforms both supervised variants5. The model performs worse than best, the gap according to B3 and CEAFe being considerably smaller than according to MUC. While we observe a decrease </context>
</contexts>
<marker>Versley, Ponzetto, Poesio, Eidelman, Jern, Smith, Yang, Moschitti, 2008</marker>
<rawString>Yannick Versley, Simone Paolo Ponzetto, Massimo Poesio, Vladimir Eidelman, Alan Jern, Jason Smith, Xiaofeng Yang, and Alessandro Moschitti. 2008. BART: A modular toolkit for coreference resolution. In Companion Volume to the Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics, Columbus, Ohio, 15–20 June 2008, pages 9–12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Vilain</author>
<author>John Burger</author>
<author>John Aberdeen</author>
<author>Dennis Connolly</author>
<author>Lynette Hirschman</author>
</authors>
<title>A modeltheoretic coreference scoring scheme.</title>
<date>1995</date>
<booktitle>In Proceedings of the 6th Message Understanding Conference (MUC-6),</booktitle>
<pages>45--52</pages>
<publisher>Morgan Kaufmann.</publisher>
<location>San Mateo, Cal.</location>
<contexts>
<context position="15169" citStr="Vilain et al., 1995" startWordPosition="2547" endWordPosition="2550">th various annotation layers provided by state-of-the-art NLP tools. We used the official dev/test split for development and evaluation. We evaluate the model in a setting that corresponds to the shared task’s closed track, i.e. we use only WordNet (Fellbaum, 1998), the number and gender data of Bergsma and Lin (2006) and the provided annotation layers. To extract system mentions we employ the mention extractor described in Martschat et al. (2012). We evaluate our system with the coreference resolution evaluation metrics that were used for the CoNLL shared tasks on coreference, which are MUC (Vilain et al., 1995), B3 (Bagga and Baldwin, 1998) and CEAFe (Luo, 2005). We also report the unweighted average of the three scores, which was the official evaluation metric in the shared tasks. To compute the scores we employed the official scorer supplied by the shared task organizers. 5.2 Results Table 1 displays the performance of our model and of the systems that obtained the best (Fernandes et al., 2012) and the median performance in the 84 MUC average R P F1 R P F1 R P F1 B3 CEAF, CoNLL’12 English development data best 64.88 74.74 69.46 66.53 78.28 71.93 54.93 43.68 48.66 63.35 median 62.3 62.8 62.0 66.7 7</context>
</contexts>
<marker>Vilain, Burger, Aberdeen, Connolly, Hirschman, 1995</marker>
<rawString>Marc Vilain, John Burger, John Aberdeen, Dennis Connolly, and Lynette Hirschman. 1995. A modeltheoretic coreference scoring scheme. In Proceedings of the 6th Message Understanding Conference (MUC-6), pages 45–52, San Mateo, Cal. Morgan Kaufmann.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>