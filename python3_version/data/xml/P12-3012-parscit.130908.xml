<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.121977">
<title confidence="0.955841">
Multilingual WSD with Just a Few Lines of Code: the BabelNet API
</title>
<author confidence="0.813083">
Roberto Navigli and Simone Paolo Ponzetto
</author>
<affiliation confidence="0.623008">
Dipartimento di Informatica
</affiliation>
<address confidence="0.499684">
Sapienza Universit`a di Roma
</address>
<email confidence="0.994401">
{navigli,ponzetto}@di.uniroma1.it
</email>
<sectionHeader confidence="0.997634" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.98134775">
In this paper we present an API for program-
matic access to BabelNet – a wide-coverage
multilingual lexical knowledge base – and
multilingual knowledge-rich Word Sense Dis-
ambiguation (WSD). Our aim is to provide the
research community with easy-to-use tools to
perform multilingual lexical semantic analysis
and foster further research in this direction.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999968233333333">
In recent years research in Natural Language Pro-
cessing (NLP) has been steadily moving towards
multilingual processing: the availability of ever
growing amounts of text in different languages, in
fact, has been a major driving force behind re-
search on multilingual approaches, from morpho-
syntactic (Das and Petrov, 2011) and syntactico-
semantic (Peirsman and Pad´o, 2010) phenomena to
high-end tasks like textual entailment (Mehdad et
al., 2011) and sentiment analysis (Lu et al., 2011).
These research trends would seem to indicate the
time is ripe for developing methods capable of per-
forming semantic analysis of texts written in any
language: however, this objective is still far from be-
ing attained, as is demonstrated by research in a core
language understanding task such as Word Sense
Disambiguation (Navigli, 2009, WSD) continuing to
be focused primarily on English. While the lack of
resources has hampered the development of effec-
tive multilingual approaches to WSD, recently this
idea has been revamped with the organization of
SemEval tasks on cross-lingual WSD (Lefever and
Hoste, 2010) and cross-lingual lexical substitution
(Mihalcea et al., 2010). In addition, new research on
the topic has explored the translation of sentences
into many languages (Navigli and Ponzetto, 2010;
Lefever et al., 2011; Banea and Mihalcea, 2011),
as well as the projection of monolingual knowledge
onto another language (Khapra et al., 2011).
In our research we focus on knowledge-based
methods and tools for multilingual WSD, since
knowledge-rich WSD has been shown to achieve
high performance across domains (Agirre et al.,
2009; Navigli et al., 2011) and to compete with su-
pervised methods on a variety of lexical disambigua-
tion tasks (Ponzetto and Navigli, 2010). Our vi-
sion of knowledge-rich multilingual WSD requires
two fundamental components: first, a wide-coverage
multilingual lexical knowledge base; second, tools
to effectively query, retrieve and exploit its informa-
tion for disambiguation. Nevertheless, to date, no
integrated resources and tools exist that are freely
available to the research community on a multi-
lingual scale. Previous endeavors are either not
freely available (EuroWordNet (Vossen, 1998)), or
are only accessible via a Web interface (cf. the Mul-
tilingual Research Repository (Atserias et al., 2004)
and MENTA (de Melo and Weikum, 2010)), thus
providing no programmatic access. And this is de-
spite the fact that the availability of easy-to-use li-
braries for efficient information access is known to
foster top-level research – cf. the widespread use of
semantic similarity measures in NLP, thanks to the
availability of WordNet::Similarity (Peder-
sen et al., 2004).
With the present contribution we aim to fill this
gap in multilingual tools, providing a multi-tiered
contribution consisting of (a) an Application Pro-
gramming Interface (API) for efficiently accessing
the information available in BabelNet (Navigli and
</bodyText>
<page confidence="0.996611">
67
</page>
<note confidence="0.8165895">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 67–72,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<figure confidence="0.910713">
bn:00008364n WIKIWN 08420278n 85 WN:EN:bank WIKI:EN:Bank WIKI:DE:Bank WIKI:IT:Banca
WIKIRED:DE:Finanzinstitut WN:EN:banking_company
WNTR:ES:banco WNTR:FR:soci´et´e_bancaire WIKI:FR:Banque ...
35 1_7 2_3,4,9 6_8 ...
228 r bn:02945246n r bn:02854884n|FROM_IT @ bn:00034537n ...
</figure>
<figureCaption confidence="0.999931">
Figure 1: The Babel synset for bank2 , i.e. its ‘financial’ sense (excerpt, formatted for ease of readability).
</figureCaption>
<bodyText confidence="0.9997905">
Ponzetto, 2010), a very large knowledge repository
with concept lexicalizations in 6 languages (Cata-
lan, English, French, German, Italian and Spanish),
at the lexicographic (i.e., word senses), encyclope-
dic (i.e., named entities) and conceptual (i.e., con-
cepts and semantic relations) levels; (b) an API to
perform graph-based WSD with BabelNet, thus pro-
viding, for the first time, a freely-available toolkit for
performing knowledge-based WSD in a multilingual
and cross-lingual setting.
</bodyText>
<sectionHeader confidence="0.993573" genericHeader="introduction">
2 BabelNet
</sectionHeader>
<bodyText confidence="0.99988392">
BabelNet follows the structure of a traditional lex-
ical knowledge base and accordingly consists of a
labeled directed graph where nodes represent con-
cepts and named entities and edges express semantic
relations between them. Concepts and relations are
harvested from the largest available semantic lexi-
con of English, i.e., WordNet (Fellbaum, 1998), and
a wide-coverage collaboratively-edited encyclope-
dia, i.e., Wikipedia1, thus making BabelNet a mul-
tilingual ‘encyclopedic dictionary’ which automati-
cally integrates fine-grained lexicographic informa-
tion with large amounts of encyclopedic knowledge
by means of a high-performing mapping algorithm
(Navigli and Ponzetto, 2010). In addition to this
conceptual backbone, BabelNet provides a multilin-
gual lexical dimension. Each of its nodes, called
Babel synsets, contains a set of lexicalizations of
the concept for different languages, e.g., { bankEN,
BankDE, bancaIT, ..., bancoES I.
Similar in spirit to WordNet, BabelNet consists,
at its lowest level, of a plain text file. An ex-
cerpt of the entry for the Babel synset containing
bank&apos; is shown in Figure 12. The record contains
(a) the synset’s id; (b) the region of BabelNet
where it lies (e.g., WIKIWN means at the intersec-
</bodyText>
<footnote confidence="0.932709333333333">
1http://www.wikipedia.org
2We denote with wP the i-th WordNet sense of a word w
with part of speech p.
</footnote>
<bodyText confidence="0.999182607142857">
tion of WordNet and Wikipedia); (c) the correspond-
ing (possibly empty) WordNet 3.0 synset offset;
(d) the number of senses in all languages and
their full listing; (e) the number of translation re-
lations and their full listing; (f) the number of se-
mantic pointers (i.e., relations) to other Babel
synsets and their full listing. Senses encode in-
formation about their source – i.e., whether they
come from WordNet (WN), Wikipedia pages (WIKI)
or their redirections (WIKIRED), or are automatic
translations (WNTR / WIKITR) – and about their
language and lemma. In addition, translation rela-
tions among lexical items are represented as a map-
ping from source to target senses – e.g., 2 3,4,9
means that the second element in the list of senses
(the English word bank) translates into items #3
(German Bank), #4 (Italian banca), and #9 (French
banque). Finally, semantic relations are encoded
using WordNet’s pointers and an additional sym-
bol for Wikipedia relations (r), which can also
specify the source of the relation (e.g., FROM IT
means that the relation was harvested from the Ital-
ian Wikipedia). In Figure 1, the Babel synset in-
herits the WordNet hypernym (@) relation to finan-
cial institution&apos; (offset bn:00034537n), as well
as Wikipedia relations to the synsets of FINAN-
CIAL INSTRUMENT (bn:02945246n) and ETH-
ICAL BANKING (bn:02854884n, from Italian).
</bodyText>
<sectionHeader confidence="0.961313" genericHeader="method">
3 An API for multilingual WSD
</sectionHeader>
<bodyText confidence="0.999797777777778">
BabelNet API. BabelNet can be effectively ac-
cessed and automatically embedded within applica-
tions by means of a programmatic access. In order
to achieve this, we developed a Java API, based on
Apache Lucene3, which indexes the BabelNet tex-
tual dump and includes a variety of methods to ac-
cess the four main levels of information encoded in
BabelNet, namely: (a) lexicographic (information
about word senses), (b) encyclopedic (i.e. named en-
</bodyText>
<footnote confidence="0.986058">
3http://lucene.apache.org
</footnote>
<page confidence="0.995134">
68
</page>
<figure confidence="0.983873904761905">
1 BabelNet bn = BabelNet.getInstance();
2 System.out.println(&amp;quot;SYNSETS WITH English word: \&amp;quot;bank\&amp;quot;&amp;quot;);
3 List&lt;BabelSynset&gt; synsets = bn.getSynsets(Language.EN, &amp;quot;bank&amp;quot;);
4 for (BabelSynset synset : synsets) {
5 System.out.print(&amp;quot; =&gt;(&amp;quot; + synset.getId() + &amp;quot;) SOURCE: &amp;quot; + synset.getSource() +
6 &amp;quot;; WN SYNSET: &amp;quot; + synset.getWordNetOffsets() + &amp;quot;;\n&amp;quot; +
7 &amp;quot; MAIN LEMMA: &amp;quot; + synset.getMainLemma() + &amp;quot;;\n SENSES (IT): { &amp;quot;);
8 for (BabelSense sense : synset.getSenses(Language.IT))
9 System.out.print(sense.toString()+&amp;quot; &amp;quot;);
10 System.out.println(&amp;quot;}\n &amp;quot;);
11 Map&lt;IPointer, List&lt;BabelSynset&gt;&gt; relatedSynsets = synset.getRelatedMap();
12 for (IPointer relationType : relatedSynsets.keySet()) {
13 List&lt;BabelSynset&gt; relationSynsets = relatedSynsets.get(relationType);
14 for (BabelSynset relationSynset : relationSynsets) {
15 System.out.println(&amp;quot; EDGE &amp;quot; + relationType.getSymbol() +
16 &amp;quot; &amp;quot; + relationSynset.getId() +
17 &amp;quot; &amp;quot; + relationSynset.toString(Language.EN));
18 }
19 }
20 System.out.println(&amp;quot; &amp;quot;);
21 }
</figure>
<figureCaption confidence="0.999796">
Figure 2: Sample BabelNet API usage.
</figureCaption>
<bodyText confidence="0.999932714285715">
tities), (c) conceptual (the semantic network made
up of its concepts), (d) and multilingual level (in-
formation about word translations). Figure 2 shows
a usage example of the BabelNet API. In the code
snippet we start by querying the Babel synsets for
the English word bank (line 3). Next, we access dif-
ferent kinds of information for each synset: first, we
print their id, source (WordNet, Wikipedia, or both),
the corresponding, possibly empty, WordNet offsets,
and ‘main lemma’ – namely, a compact string rep-
resentation of the Babel synset consisting of its cor-
responding WordNet synset in stringified form, or
the first non-redirection Wikipedia page found in it
(lines 5–7). Then, we access and print the Italian
word senses they contain (lines 8–10), and finally
the synsets they are related to (lines 11–19). Thanks
to carefully designed Java classes, we are able to ac-
complish all of this in about 20 lines of code.
Multilingual WSD API. We use the BabelNet API
as a framework to build a toolkit that allows the
user to perform multilingual graph-based lexical dis-
ambiguation – namely, to identify the most suitable
meanings of the input words on the basis of the se-
mantic connections found in the lexical knowledge
base, along the lines of Navigli and Lapata (2010).
At its core, the API leverages an in-house Java li-
brary to query paths and create semantic graphs
with BabelNet. The latter works by pre-computing
off-line paths connecting any pair of Babel synsets,
which are collected by iterating through each synset
in turn, and performing a depth-first search up to a
maximum depth – which we set to 3, on the basis of
experimental evidence from a variety of knowledge
base linking and lexical disambiguation tasks (Nav-
igli and Lapata, 2010; Ponzetto and Navigli, 2010).
Next, these paths are stored within a Lucene index,
which ensures efficient lookups for querying those
paths starting and ending in a specific synset. Given
a set of words as input, a semantic graph factory
class searches for their meanings within BabelNet,
looks for their connecting paths, and merges such
paths within a single graph. Optionally, the paths
making up the graph can be filtered – e.g., it is possi-
ble to remove loops, weighted edges below a certain
threshold, etc. – and the graph nodes can be scored
using a variety of methods – such as, for instance,
their outdegree or PageRank value in the context of
the semantic graph. These graph connectivity mea-
sures can be used to rank senses of the input words,
thus performing graph-based WSD on the basis of
the structure of the underlying knowledge base.
We show in Figure 3 a usage example of our
disambiguation API. The method which performs
WSD (disambiguate) takes as input a col-
lection of words (i.e., typically a sentence), a
KnowledgeBase with which to perform dis-
</bodyText>
<page confidence="0.986602">
69
</page>
<figure confidence="0.96941262962963">
1 public static void disambiguate(Collection&lt;Word&gt; words,
2 KnowledgeBase kb, KnowledgeGraphScorer scorer) {
3 KnowledgeGraphFactory factory = KnowledgeGraphFactory.getInstance(kb);
4 KnowledgeGraph kGraph = factory.getKnowledgeGraph(words);
5 Map&lt;String, Double&gt; scores = scorer.score(kGraph);
6 for (String concept : scores.keySet()) {
7 double score = scores.get(concept);
8 for (Word word : kGraph.wordsForConcept(concept))
9 word.addLabel(concept, score);
10 }
11 for (Word word : words) {
12 System.out.println(&amp;quot;\n\t&amp;quot; + word.getWord() + &amp;quot; -- ID &amp;quot; + word.getId() +
13 &amp;quot; =&gt; SENSE DISTRIBUTION: &amp;quot;);
14 for (ScoredItem&lt;String&gt; label : word.getLabels()) {
15 System.out.println(&amp;quot;\t [&amp;quot; + label.getItem() + &amp;quot;]:&amp;quot; +
16 Strings.format(label.getScore()));
17 }
18 }
19 }
20
21 public static void main(String[] args) {
22 List&lt;Word&gt; sentence = Arrays.asList(
23 new Word[]{new Word(&amp;quot;bank&amp;quot;, ’n’, Language.EN), new Word(&amp;quot;bonus&amp;quot; &apos;
&apos;n&apos; Language.EN),
24 new Word(&amp;quot;pay&amp;quot;, ’v’, Language.EN), new Word(&amp;quot;stock&amp;quot;, ’n’, Language.EN)});
25 disambiguate(sentence, KnowledgeBase.BABELNET, KnowledgeGraphScorer.DEGREE);
26 }
</figure>
<figureCaption confidence="0.999924">
Figure 3: Sample Word Sense Disambiguation API usage.
</figureCaption>
<bodyText confidence="0.999908633333333">
ambiguation, and a KnowledgeGraphScorer,
namely a value from an enumeration of different
graph connectivity measures (e.g., node outdegree),
which are responsible for scoring nodes (i.e., con-
cepts) in the graph. KnowledgeBase is an enu-
meration of supported knowledge bases: currently, it
includes BabelNet, as well as WordNet++ (namely,
an English WordNet-based subset of it (Ponzetto and
Navigli, 2010)) and WordNet. Note that, while Ba-
belNet is presently the only lexical knowledge base
which allows for multilingual processing, our frame-
work can easily be extended to work with other ex-
isting lexical knowledge resources, provided they
can be wrapped around Java classes and implement
interface methods for querying senses, concepts, and
their semantic relations. In the snippet we start in
line 3 by obtaining an instance of the factory class
which creates the semantic graphs for a given knowl-
edge base. Next, we use this factory to create the
graph for the input words (line 4). We then score the
senses of the input words occurring within this graph
(line 5–10). Finally, we output the sense distribu-
tions of each word in lines 11–18. The disambigua-
tion method, in turn, can be called by any other Java
program in a way similar to the one highlighted by
the main method of lines 21–26, where we disam-
biguate the sample sentence ‘bank bonuses are paid
in stocks’ (note that each input word can be written
in any of the 6 languages, i.e. we could mix lan-
guages).
</bodyText>
<sectionHeader confidence="0.999788" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999996333333333">
We benchmark our API by performing knowledge-
based WSD with BabelNet on standard SemEval
datasets, namely the SemEval-2007 coarse-grained
all-words (Navigli et al., 2007, Coarse-WSD, hence-
forth) and the SemEval-2010 cross-lingual (Lefever
and Hoste, 2010, CL-WSD) WSD tasks. For
both experimental settings we use a standard graph-
based algorithm, Degree (Navigli and Lapata, 2010),
which has been previously shown to yield a highly
competitive performance on different lexical disam-
biguation tasks (Ponzetto and Navigli, 2010). Given
a semantic graph for the input context, Degree se-
lects the sense of the target word with the highest
vertex degree. In addition, in the CL-WSD setting
we need to output appropriate lexicalization(s) in
different languages. Since the selected Babel synset
can contain multiple translations in a target language
for the given English word, we use for this task an
</bodyText>
<page confidence="0.993763">
70
</page>
<table confidence="0.998252166666667">
Algorithm Nouns only All words
NUS-PT 82.3 82.5
SUSSX-FR 81.1 77.0
Degree 84.7 82.3
MFS BL 77.4 78.9
Random BL 63.5 62.7
</table>
<tableCaption confidence="0.9896545">
Table 1: Performance on SemEval-2007 coarse-grained
all-words WSD (Navigli et al., 2007).
</tableCaption>
<bodyText confidence="0.9999482">
unsupervised approach where we return for each test
instance only the most frequent translation found in
the synset, as given by its frequency of alignment
obtained from the Europarl corpus (Koehn, 2005).
Tables 1 and 2 summarize our results in terms
of recall (the primary metric for WSD tasks): for
each SemEval task, we benchmark our disambigua-
tion API against the best unsupervised and super-
vised systems, namely SUSSX-FR (Koeling and
McCarthy, 2007) and NUS-PT (Chan et al., 2007)
for Coarse-WSD, and T3-COLEUR (Guo and Diab,
2010) and UvT-v (van Gompel, 2010) for CL-WSD.
In the Coarse-WSD task our API achieves the best
overall performance on the nouns-only subset of
the data, thus supporting previous findings indicat-
ing the benefits of using rich knowledge bases like
BabelNet. In the CL-WSD evaluation, instead, us-
ing BabelNet allows us to surpass the best unsuper-
vised system by a substantial margin, thus indicating
the viability of high-performing WSD with a multi-
lingual lexical knowledge base. While our perfor-
mance still lags behind the application of supervised
techniques to this task (cf. also results from Lefever
and Hoste (2010)), we argue that further improve-
ments can still be obtained by exploiting more com-
plex disambiguation strategies. In general, using our
toolkit we are able to achieve a performance which
is competitive with the state of the art for these tasks,
thus supporting previous findings on knowledge-rich
WSD, and confirming the robustness of our toolkit.
</bodyText>
<sectionHeader confidence="0.999946" genericHeader="related work">
5 Related Work
</sectionHeader>
<bodyText confidence="0.996280833333333">
Our work complements recent efforts focused on vi-
sual browsing of wide-coverage knowledge bases
(Tylenda et al., 2011; Navigli and Ponzetto, 2012)
by means of an API which allows the user to pro-
grammatically query and search BabelNet. This
knowledge resource, in turn, can be used for eas-
</bodyText>
<table confidence="0.997710166666667">
Degree T3-Coleur UvT-v
Dutch 15.52 10.56 17.70
French 22.94 21.75 −
German 17.15 13.05 −
Italian 18.03 14.67 −
Spanish 22.48 19.64 23.39
</table>
<tableCaption confidence="0.971431">
Table 2: Performance on SemEval-2010 cross-lingual
WSD (Lefever and Hoste, 2010).
</tableCaption>
<bodyText confidence="0.99990075">
ily performing multilingual and cross-lingual WSD
out-of-the-box. In comparison with other contribu-
tions, our toolkit for multilingual WSD takes pre-
vious work from Navigli (2006), in which an on-
line interface for graph-based monolingual WSD is
presented, one step further by adding a multilin-
gual dimension as well as a full-fledged API. Our
work also complements previous attempts by NLP
researchers to provide the community with freely
available tools to perform state-of-the-art WSD us-
ing WordNet-based measures of semantic related-
ness (Patwardhan et al., 2005), as well as supervised
WSD techniques (Zhong and Ng, 2010). We achieve
this by building upon BabelNet, a multilingual ‘en-
cyclopedic dictionary’ bringing together the lexico-
graphic and encyclopedic knowledge from WordNet
and Wikipedia. Other recent projects on creating
multilingual knowledge bases from Wikipedia in-
clude WikiNet (Nastase et al., 2010) and MENTA
(de Melo and Weikum, 2010): both these resources
offer structured information complementary to Ba-
belNet – i.e., large amounts of facts about entities
(MENTA), and explicit semantic relations harvested
from Wikipedia categories (WikiNet).
</bodyText>
<sectionHeader confidence="0.998139" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.995424">
The authors gratefully acknowledge
the support of the ERC Starting Grant
MultiJEDI No. 259234.
BabelNet and its API are available for download at
http://lcl.uniroma1.it/babelnet.
</bodyText>
<sectionHeader confidence="0.998712" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.955392">
Eneko Agirre, Oier Lopez de Lacalle, and Aitor Soroa.
2009. Knowledge-based WSD on specific domains:
performing better than generic supervised WSD. In
Proc. of IJCAI-09, pages 1501–1506.
</reference>
<page confidence="0.992224">
71
</page>
<reference confidence="0.998732729729729">
Jordi Atserias, Luis Villarejo, German Rigau, Eneko
Agirre, John Carroll, Bernardo Magnini, and Piek
Vossen. 2004. The MEANING multilingual central
repository. In Proc. of GWC-04, pages 22–31.
Carmen Banea and Rada Mihalcea. 2011. Word Sense
Disambiguation with multilingual features. In Proc.
of IWCS-11, pages 25–34.
Yee Seng Chan, Hwee Tou Ng, and Zhi Zhong. 2007.
NUS-ML: Exploiting parallel texts for Word Sense
Disambiguation in the English all-words tasks. In
Proc. of SemEval-2007, pages 253–256.
Dipanjan Das and Slav Petrov. 2011. Unsupervised part-
of-speech tagging with bilingual graph-based projec-
tions. In Proc. of ACL-11, pages 600–609.
Gerard de Melo and Gerhard Weikum. 2010. MENTA:
inducing multilingual taxonomies from Wikipedia. In
Proc. of CIKM-10, pages 1099–1108.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press, Cambridge, MA.
Weiwei Guo and Mona Diab. 2010. COLEPL and COL-
SLM: An unsupervised WSD approach to multilingual
lexical substitution, tasks 2 and 3 SemEval 2010. In
Proc. of SemEval-2010, pages 129–133.
Mitesh M. Khapra, Salil Joshi, Arindam Chatterjee, and
Pushpak Bhattacharyya. 2011. Together we can:
Bilingual bootstrapping for WSD. In Proc. of ACL-
11, pages 561–569.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In Proceedings of Ma-
chine Translation Summit X.
Rob Koeling and Diana McCarthy. 2007. Sussx: WSD
using automatically acquired predominant senses. In
Proc. of SemEval-2007, pages 314–317.
Els Lefever and Veronique Hoste. 2010. SemEval-2010
Task 3: Cross-lingual Word Sense Disambiguation. In
Proc. of SemEval-2010, pages 15–20.
Els Lefever, V´eronique Hoste, and Martine De Cock.
2011. Parasense or how to use parallel corpora for
Word Sense Disambiguation. In Proc. of ACL-11,
pages 317–322.
Bin Lu, Chenhao Tan, Claire Cardie, and Benjamin
K. Tsou. 2011. Joint bilingual sentiment classification
with unlabeled parallel corpora. In Proc. of ACL-11,
pages 320–330.
Yashar Mehdad, Matteo Negri, and Marcello Federico.
2011. Using bilingual parallel corpora for cross-
lingual textual entailment. In Proc. of ACL-11, pages
1336–1345.
Rada Mihalcea, Ravi Sinha, and Diana McCarthy. 2010.
SemEval-2010 Task 2: Cross-lingual lexical substitu-
tion. In Proc. of SemEval-2010, pages 9–14.
Vivi Nastase, Michael Strube, Benjamin B¨orschinger,
Caecilia Zirn, and Anas Elghafari. 2010. WikiNet:
A very large scale multi-lingual concept network. In
Proc. of LREC ’10.
Roberto Navigli and Mirella Lapata. 2010. An exper-
imental study on graph connectivity for unsupervised
Word Sense Disambiguation. IEEE Transactions on
Pattern Analysis and Machine Intelligence, 32(4):678–
692.
Roberto Navigli and Simone Paolo Ponzetto. 2010. Ba-
belNet: Building a very large multilingual semantic
network. In Proc. ofACL-10, pages 216–225.
Roberto Navigli and Simone Paolo Ponzetto. 2012.
BabelNetXplorer: a platform for multilingual lexical
knowledge base access and exploration. In Comp. Vol.
to Proc. of WWW-12, pages 393–396.
Roberto Navigli, Kenneth C. Litkowski, and Orin Har-
graves. 2007. Semeval-2007 task 07: Coarse-grained
English all-words task. In Proc. of SemEval-2007,
pages 30–35.
Roberto Navigli, Stefano Faralli, Aitor Soroa, Oier Lopez
de Lacalle, and Eneko Agirre. 2011. Two birds with
one stone: learning semantic models for Text Catego-
rization and Word Sense Disambiguation. In Proc. of
CIKM-11, pages 2317–2320.
Roberto Navigli. 2006. Online word sense disambigua-
tion with structural semantic interconnections. In
Proc. of EACL-06, pages 107–110.
Roberto Navigli. 2009. Word Sense Disambiguation: A
survey. ACM Computing Surveys, 41(2):1–69.
Siddharth Patwardhan, Satanjeev Banerjee, and Ted Ped-
ersen. 2005. SenseRelate::TargetWord – a generalized
framework for Word Sense Disambiguation. In Comp.
Vol. to Proc. of ACL-05, pages 73–76.
Ted Pedersen, Siddharth Patwardhan, and Jason Miche-
lizzi. 2004. WordNet::Similarity – Measuring the re-
latedness of concepts. In Comp. Vol. to Proc. of HLT-
NAACL-04, pages 267–270.
Yves Peirsman and Sebastian Pad´o. 2010. Cross-
lingual induction of selectional preferences with bilin-
gual vector spaces. In Proc. of NAACL-HLT-10, pages
921–929.
Simone Paolo Ponzetto and Roberto Navigli. 2010.
Knowledge-rich Word Sense Disambiguation rivaling
supervised system. In Proc. of ACL-10, pages 1522–
1531.
Tomasz Tylenda, Mauro Sozio, and Gerhard Weikum.
2011. Einstein: physicist or vegetarian? Summariz-
ing semantic type graphs for knowledge discovery. In
Proc. of WWW-11, pages 273–276.
Maarten van Gompel. 2010. UvT-WSD1: A cross-
lingual word sense disambiguation system. In Proc.
of SemEval-2010, pages 238–241.
Piek Vossen, editor. 1998. EuroWordNet: A Multilingual
Database with Lexical Semantic Networks. Kluwer,
Dordrecht, The Netherlands.
Zhi Zhong and Hwee Tou Ng. 2010. It Makes Sense:
A wide-coverage Word Sense Disambiguation system
for free text. In Proc. of ACL-10 System Demonstra-
tions, pages 78–83.
</reference>
<page confidence="0.998723">
72
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.333183">
<title confidence="0.999251">Multilingual WSD with Just a Few Lines of Code: the BabelNet API</title>
<author confidence="0.753125">Navigli Paolo Ponzetto</author>
<affiliation confidence="0.5385565">Dipartimento di Informatica Sapienza Universit`a di Roma</affiliation>
<abstract confidence="0.998300666666667">In this paper we present an API for programmatic access to BabelNet – a wide-coverage multilingual lexical knowledge base – and multilingual knowledge-rich Word Sense Disambiguation (WSD). Our aim is to provide the research community with easy-to-use tools to perform multilingual lexical semantic analysis and foster further research in this direction.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Oier Lopez de Lacalle</author>
<author>Aitor Soroa</author>
</authors>
<title>Knowledge-based WSD on specific domains: performing better than generic supervised WSD.</title>
<date>2009</date>
<booktitle>In Proc. of IJCAI-09,</booktitle>
<pages>1501--1506</pages>
<marker>Agirre, de Lacalle, Soroa, 2009</marker>
<rawString>Eneko Agirre, Oier Lopez de Lacalle, and Aitor Soroa. 2009. Knowledge-based WSD on specific domains: performing better than generic supervised WSD. In Proc. of IJCAI-09, pages 1501–1506.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jordi Atserias</author>
<author>Luis Villarejo</author>
<author>German Rigau</author>
<author>Eneko Agirre</author>
<author>John Carroll</author>
<author>Bernardo Magnini</author>
<author>Piek Vossen</author>
</authors>
<title>The MEANING multilingual central repository.</title>
<date>2004</date>
<booktitle>In Proc. of GWC-04,</booktitle>
<pages>22--31</pages>
<contexts>
<context position="2905" citStr="Atserias et al., 2004" startWordPosition="433" endWordPosition="436">xical disambiguation tasks (Ponzetto and Navigli, 2010). Our vision of knowledge-rich multilingual WSD requires two fundamental components: first, a wide-coverage multilingual lexical knowledge base; second, tools to effectively query, retrieve and exploit its information for disambiguation. Nevertheless, to date, no integrated resources and tools exist that are freely available to the research community on a multilingual scale. Previous endeavors are either not freely available (EuroWordNet (Vossen, 1998)), or are only accessible via a Web interface (cf. the Multilingual Research Repository (Atserias et al., 2004) and MENTA (de Melo and Weikum, 2010)), thus providing no programmatic access. And this is despite the fact that the availability of easy-to-use libraries for efficient information access is known to foster top-level research – cf. the widespread use of semantic similarity measures in NLP, thanks to the availability of WordNet::Similarity (Pedersen et al., 2004). With the present contribution we aim to fill this gap in multilingual tools, providing a multi-tiered contribution consisting of (a) an Application Programming Interface (API) for efficiently accessing the information available in Bab</context>
</contexts>
<marker>Atserias, Villarejo, Rigau, Agirre, Carroll, Magnini, Vossen, 2004</marker>
<rawString>Jordi Atserias, Luis Villarejo, German Rigau, Eneko Agirre, John Carroll, Bernardo Magnini, and Piek Vossen. 2004. The MEANING multilingual central repository. In Proc. of GWC-04, pages 22–31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carmen Banea</author>
<author>Rada Mihalcea</author>
</authors>
<title>Word Sense Disambiguation with multilingual features.</title>
<date>2011</date>
<booktitle>In Proc. of IWCS-11,</booktitle>
<pages>25--34</pages>
<contexts>
<context position="1917" citStr="Banea and Mihalcea, 2011" startWordPosition="285" endWordPosition="288">trated by research in a core language understanding task such as Word Sense Disambiguation (Navigli, 2009, WSD) continuing to be focused primarily on English. While the lack of resources has hampered the development of effective multilingual approaches to WSD, recently this idea has been revamped with the organization of SemEval tasks on cross-lingual WSD (Lefever and Hoste, 2010) and cross-lingual lexical substitution (Mihalcea et al., 2010). In addition, new research on the topic has explored the translation of sentences into many languages (Navigli and Ponzetto, 2010; Lefever et al., 2011; Banea and Mihalcea, 2011), as well as the projection of monolingual knowledge onto another language (Khapra et al., 2011). In our research we focus on knowledge-based methods and tools for multilingual WSD, since knowledge-rich WSD has been shown to achieve high performance across domains (Agirre et al., 2009; Navigli et al., 2011) and to compete with supervised methods on a variety of lexical disambiguation tasks (Ponzetto and Navigli, 2010). Our vision of knowledge-rich multilingual WSD requires two fundamental components: first, a wide-coverage multilingual lexical knowledge base; second, tools to effectively query</context>
</contexts>
<marker>Banea, Mihalcea, 2011</marker>
<rawString>Carmen Banea and Rada Mihalcea. 2011. Word Sense Disambiguation with multilingual features. In Proc. of IWCS-11, pages 25–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yee Seng Chan</author>
<author>Hwee Tou Ng</author>
<author>Zhi Zhong</author>
</authors>
<title>NUS-ML: Exploiting parallel texts for Word Sense Disambiguation in the English all-words tasks.</title>
<date>2007</date>
<booktitle>In Proc. of SemEval-2007,</booktitle>
<pages>253--256</pages>
<contexts>
<context position="15880" citStr="Chan et al., 2007" startWordPosition="2424" endWordPosition="2427"> 82.3 MFS BL 77.4 78.9 Random BL 63.5 62.7 Table 1: Performance on SemEval-2007 coarse-grained all-words WSD (Navigli et al., 2007). unsupervised approach where we return for each test instance only the most frequent translation found in the synset, as given by its frequency of alignment obtained from the Europarl corpus (Koehn, 2005). Tables 1 and 2 summarize our results in terms of recall (the primary metric for WSD tasks): for each SemEval task, we benchmark our disambiguation API against the best unsupervised and supervised systems, namely SUSSX-FR (Koeling and McCarthy, 2007) and NUS-PT (Chan et al., 2007) for Coarse-WSD, and T3-COLEUR (Guo and Diab, 2010) and UvT-v (van Gompel, 2010) for CL-WSD. In the Coarse-WSD task our API achieves the best overall performance on the nouns-only subset of the data, thus supporting previous findings indicating the benefits of using rich knowledge bases like BabelNet. In the CL-WSD evaluation, instead, using BabelNet allows us to surpass the best unsupervised system by a substantial margin, thus indicating the viability of high-performing WSD with a multilingual lexical knowledge base. While our performance still lags behind the application of supervised techn</context>
</contexts>
<marker>Chan, Ng, Zhong, 2007</marker>
<rawString>Yee Seng Chan, Hwee Tou Ng, and Zhi Zhong. 2007. NUS-ML: Exploiting parallel texts for Word Sense Disambiguation in the English all-words tasks. In Proc. of SemEval-2007, pages 253–256.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dipanjan Das</author>
<author>Slav Petrov</author>
</authors>
<title>Unsupervised partof-speech tagging with bilingual graph-based projections.</title>
<date>2011</date>
<booktitle>In Proc. of ACL-11,</booktitle>
<pages>600--609</pages>
<contexts>
<context position="896" citStr="Das and Petrov, 2011" startWordPosition="127" endWordPosition="130">– a wide-coverage multilingual lexical knowledge base – and multilingual knowledge-rich Word Sense Disambiguation (WSD). Our aim is to provide the research community with easy-to-use tools to perform multilingual lexical semantic analysis and foster further research in this direction. 1 Introduction In recent years research in Natural Language Processing (NLP) has been steadily moving towards multilingual processing: the availability of ever growing amounts of text in different languages, in fact, has been a major driving force behind research on multilingual approaches, from morphosyntactic (Das and Petrov, 2011) and syntacticosemantic (Peirsman and Pad´o, 2010) phenomena to high-end tasks like textual entailment (Mehdad et al., 2011) and sentiment analysis (Lu et al., 2011). These research trends would seem to indicate the time is ripe for developing methods capable of performing semantic analysis of texts written in any language: however, this objective is still far from being attained, as is demonstrated by research in a core language understanding task such as Word Sense Disambiguation (Navigli, 2009, WSD) continuing to be focused primarily on English. While the lack of resources has hampered the </context>
</contexts>
<marker>Das, Petrov, 2011</marker>
<rawString>Dipanjan Das and Slav Petrov. 2011. Unsupervised partof-speech tagging with bilingual graph-based projections. In Proc. of ACL-11, pages 600–609.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard de Melo</author>
<author>Gerhard Weikum</author>
</authors>
<title>MENTA: inducing multilingual taxonomies from Wikipedia.</title>
<date>2010</date>
<booktitle>In Proc. of CIKM-10,</booktitle>
<pages>1099--1108</pages>
<marker>de Melo, Weikum, 2010</marker>
<rawString>Gerard de Melo and Gerhard Weikum. 2010. MENTA: inducing multilingual taxonomies from Wikipedia. In Proc. of CIKM-10, pages 1099–1108.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weiwei Guo</author>
<author>Mona Diab</author>
</authors>
<title>COLEPL and COLSLM: An unsupervised WSD approach to multilingual lexical substitution,</title>
<date>2010</date>
<journal>tasks</journal>
<booktitle>In Proc. of SemEval-2010,</booktitle>
<volume>2</volume>
<pages>129--133</pages>
<contexts>
<context position="15931" citStr="Guo and Diab, 2010" startWordPosition="2432" endWordPosition="2435">: Performance on SemEval-2007 coarse-grained all-words WSD (Navigli et al., 2007). unsupervised approach where we return for each test instance only the most frequent translation found in the synset, as given by its frequency of alignment obtained from the Europarl corpus (Koehn, 2005). Tables 1 and 2 summarize our results in terms of recall (the primary metric for WSD tasks): for each SemEval task, we benchmark our disambiguation API against the best unsupervised and supervised systems, namely SUSSX-FR (Koeling and McCarthy, 2007) and NUS-PT (Chan et al., 2007) for Coarse-WSD, and T3-COLEUR (Guo and Diab, 2010) and UvT-v (van Gompel, 2010) for CL-WSD. In the Coarse-WSD task our API achieves the best overall performance on the nouns-only subset of the data, thus supporting previous findings indicating the benefits of using rich knowledge bases like BabelNet. In the CL-WSD evaluation, instead, using BabelNet allows us to surpass the best unsupervised system by a substantial margin, thus indicating the viability of high-performing WSD with a multilingual lexical knowledge base. While our performance still lags behind the application of supervised techniques to this task (cf. also results from Lefever a</context>
</contexts>
<marker>Guo, Diab, 2010</marker>
<rawString>Weiwei Guo and Mona Diab. 2010. COLEPL and COLSLM: An unsupervised WSD approach to multilingual lexical substitution, tasks 2 and 3 SemEval 2010. In Proc. of SemEval-2010, pages 129–133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitesh M Khapra</author>
<author>Salil Joshi</author>
<author>Arindam Chatterjee</author>
<author>Pushpak Bhattacharyya</author>
</authors>
<title>Together we can: Bilingual bootstrapping for WSD.</title>
<date>2011</date>
<booktitle>In Proc. of ACL11,</booktitle>
<pages>561--569</pages>
<contexts>
<context position="2013" citStr="Khapra et al., 2011" startWordPosition="300" endWordPosition="303">2009, WSD) continuing to be focused primarily on English. While the lack of resources has hampered the development of effective multilingual approaches to WSD, recently this idea has been revamped with the organization of SemEval tasks on cross-lingual WSD (Lefever and Hoste, 2010) and cross-lingual lexical substitution (Mihalcea et al., 2010). In addition, new research on the topic has explored the translation of sentences into many languages (Navigli and Ponzetto, 2010; Lefever et al., 2011; Banea and Mihalcea, 2011), as well as the projection of monolingual knowledge onto another language (Khapra et al., 2011). In our research we focus on knowledge-based methods and tools for multilingual WSD, since knowledge-rich WSD has been shown to achieve high performance across domains (Agirre et al., 2009; Navigli et al., 2011) and to compete with supervised methods on a variety of lexical disambiguation tasks (Ponzetto and Navigli, 2010). Our vision of knowledge-rich multilingual WSD requires two fundamental components: first, a wide-coverage multilingual lexical knowledge base; second, tools to effectively query, retrieve and exploit its information for disambiguation. Nevertheless, to date, no integrated </context>
</contexts>
<marker>Khapra, Joshi, Chatterjee, Bhattacharyya, 2011</marker>
<rawString>Mitesh M. Khapra, Salil Joshi, Arindam Chatterjee, and Pushpak Bhattacharyya. 2011. Together we can: Bilingual bootstrapping for WSD. In Proc. of ACL11, pages 561–569.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of Machine Translation Summit X.</booktitle>
<contexts>
<context position="15598" citStr="Koehn, 2005" startWordPosition="2379" endWordPosition="2380">t appropriate lexicalization(s) in different languages. Since the selected Babel synset can contain multiple translations in a target language for the given English word, we use for this task an 70 Algorithm Nouns only All words NUS-PT 82.3 82.5 SUSSX-FR 81.1 77.0 Degree 84.7 82.3 MFS BL 77.4 78.9 Random BL 63.5 62.7 Table 1: Performance on SemEval-2007 coarse-grained all-words WSD (Navigli et al., 2007). unsupervised approach where we return for each test instance only the most frequent translation found in the synset, as given by its frequency of alignment obtained from the Europarl corpus (Koehn, 2005). Tables 1 and 2 summarize our results in terms of recall (the primary metric for WSD tasks): for each SemEval task, we benchmark our disambiguation API against the best unsupervised and supervised systems, namely SUSSX-FR (Koeling and McCarthy, 2007) and NUS-PT (Chan et al., 2007) for Coarse-WSD, and T3-COLEUR (Guo and Diab, 2010) and UvT-v (van Gompel, 2010) for CL-WSD. In the Coarse-WSD task our API achieves the best overall performance on the nouns-only subset of the data, thus supporting previous findings indicating the benefits of using rich knowledge bases like BabelNet. In the CL-WSD e</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In Proceedings of Machine Translation Summit X.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rob Koeling</author>
<author>Diana McCarthy</author>
</authors>
<title>Sussx: WSD using automatically acquired predominant senses.</title>
<date>2007</date>
<booktitle>In Proc. of SemEval-2007,</booktitle>
<pages>314--317</pages>
<contexts>
<context position="15849" citStr="Koeling and McCarthy, 2007" startWordPosition="2418" endWordPosition="2421">82.3 82.5 SUSSX-FR 81.1 77.0 Degree 84.7 82.3 MFS BL 77.4 78.9 Random BL 63.5 62.7 Table 1: Performance on SemEval-2007 coarse-grained all-words WSD (Navigli et al., 2007). unsupervised approach where we return for each test instance only the most frequent translation found in the synset, as given by its frequency of alignment obtained from the Europarl corpus (Koehn, 2005). Tables 1 and 2 summarize our results in terms of recall (the primary metric for WSD tasks): for each SemEval task, we benchmark our disambiguation API against the best unsupervised and supervised systems, namely SUSSX-FR (Koeling and McCarthy, 2007) and NUS-PT (Chan et al., 2007) for Coarse-WSD, and T3-COLEUR (Guo and Diab, 2010) and UvT-v (van Gompel, 2010) for CL-WSD. In the Coarse-WSD task our API achieves the best overall performance on the nouns-only subset of the data, thus supporting previous findings indicating the benefits of using rich knowledge bases like BabelNet. In the CL-WSD evaluation, instead, using BabelNet allows us to surpass the best unsupervised system by a substantial margin, thus indicating the viability of high-performing WSD with a multilingual lexical knowledge base. While our performance still lags behind the </context>
</contexts>
<marker>Koeling, McCarthy, 2007</marker>
<rawString>Rob Koeling and Diana McCarthy. 2007. Sussx: WSD using automatically acquired predominant senses. In Proc. of SemEval-2007, pages 314–317.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Els Lefever</author>
<author>Veronique Hoste</author>
</authors>
<date>2010</date>
<booktitle>SemEval-2010 Task 3: Cross-lingual Word Sense Disambiguation. In Proc. of SemEval-2010,</booktitle>
<pages>15--20</pages>
<contexts>
<context position="1675" citStr="Lefever and Hoste, 2010" startWordPosition="249" endWordPosition="252">al., 2011). These research trends would seem to indicate the time is ripe for developing methods capable of performing semantic analysis of texts written in any language: however, this objective is still far from being attained, as is demonstrated by research in a core language understanding task such as Word Sense Disambiguation (Navigli, 2009, WSD) continuing to be focused primarily on English. While the lack of resources has hampered the development of effective multilingual approaches to WSD, recently this idea has been revamped with the organization of SemEval tasks on cross-lingual WSD (Lefever and Hoste, 2010) and cross-lingual lexical substitution (Mihalcea et al., 2010). In addition, new research on the topic has explored the translation of sentences into many languages (Navigli and Ponzetto, 2010; Lefever et al., 2011; Banea and Mihalcea, 2011), as well as the projection of monolingual knowledge onto another language (Khapra et al., 2011). In our research we focus on knowledge-based methods and tools for multilingual WSD, since knowledge-rich WSD has been shown to achieve high performance across domains (Agirre et al., 2009; Navigli et al., 2011) and to compete with supervised methods on a varie</context>
<context position="14540" citStr="Lefever and Hoste, 2010" startWordPosition="2209" endWordPosition="2212"> of each word in lines 11–18. The disambiguation method, in turn, can be called by any other Java program in a way similar to the one highlighted by the main method of lines 21–26, where we disambiguate the sample sentence ‘bank bonuses are paid in stocks’ (note that each input word can be written in any of the 6 languages, i.e. we could mix languages). 4 Experiments We benchmark our API by performing knowledgebased WSD with BabelNet on standard SemEval datasets, namely the SemEval-2007 coarse-grained all-words (Navigli et al., 2007, Coarse-WSD, henceforth) and the SemEval-2010 cross-lingual (Lefever and Hoste, 2010, CL-WSD) WSD tasks. For both experimental settings we use a standard graphbased algorithm, Degree (Navigli and Lapata, 2010), which has been previously shown to yield a highly competitive performance on different lexical disambiguation tasks (Ponzetto and Navigli, 2010). Given a semantic graph for the input context, Degree selects the sense of the target word with the highest vertex degree. In addition, in the CL-WSD setting we need to output appropriate lexicalization(s) in different languages. Since the selected Babel synset can contain multiple translations in a target language for the giv</context>
<context position="16546" citStr="Lefever and Hoste (2010)" startWordPosition="2530" endWordPosition="2533">ab, 2010) and UvT-v (van Gompel, 2010) for CL-WSD. In the Coarse-WSD task our API achieves the best overall performance on the nouns-only subset of the data, thus supporting previous findings indicating the benefits of using rich knowledge bases like BabelNet. In the CL-WSD evaluation, instead, using BabelNet allows us to surpass the best unsupervised system by a substantial margin, thus indicating the viability of high-performing WSD with a multilingual lexical knowledge base. While our performance still lags behind the application of supervised techniques to this task (cf. also results from Lefever and Hoste (2010)), we argue that further improvements can still be obtained by exploiting more complex disambiguation strategies. In general, using our toolkit we are able to achieve a performance which is competitive with the state of the art for these tasks, thus supporting previous findings on knowledge-rich WSD, and confirming the robustness of our toolkit. 5 Related Work Our work complements recent efforts focused on visual browsing of wide-coverage knowledge bases (Tylenda et al., 2011; Navigli and Ponzetto, 2012) by means of an API which allows the user to programmatically query and search BabelNet. Th</context>
</contexts>
<marker>Lefever, Hoste, 2010</marker>
<rawString>Els Lefever and Veronique Hoste. 2010. SemEval-2010 Task 3: Cross-lingual Word Sense Disambiguation. In Proc. of SemEval-2010, pages 15–20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Els Lefever</author>
<author>V´eronique Hoste</author>
<author>Martine De Cock</author>
</authors>
<title>Parasense or how to use parallel corpora for Word Sense Disambiguation.</title>
<date>2011</date>
<booktitle>In Proc. of ACL-11,</booktitle>
<pages>317--322</pages>
<marker>Lefever, Hoste, De Cock, 2011</marker>
<rawString>Els Lefever, V´eronique Hoste, and Martine De Cock. 2011. Parasense or how to use parallel corpora for Word Sense Disambiguation. In Proc. of ACL-11, pages 317–322.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bin Lu</author>
<author>Chenhao Tan</author>
<author>Claire Cardie</author>
<author>Benjamin K Tsou</author>
</authors>
<title>Joint bilingual sentiment classification with unlabeled parallel corpora.</title>
<date>2011</date>
<booktitle>In Proc. of ACL-11,</booktitle>
<pages>320--330</pages>
<contexts>
<context position="1061" citStr="Lu et al., 2011" startWordPosition="152" endWordPosition="155"> easy-to-use tools to perform multilingual lexical semantic analysis and foster further research in this direction. 1 Introduction In recent years research in Natural Language Processing (NLP) has been steadily moving towards multilingual processing: the availability of ever growing amounts of text in different languages, in fact, has been a major driving force behind research on multilingual approaches, from morphosyntactic (Das and Petrov, 2011) and syntacticosemantic (Peirsman and Pad´o, 2010) phenomena to high-end tasks like textual entailment (Mehdad et al., 2011) and sentiment analysis (Lu et al., 2011). These research trends would seem to indicate the time is ripe for developing methods capable of performing semantic analysis of texts written in any language: however, this objective is still far from being attained, as is demonstrated by research in a core language understanding task such as Word Sense Disambiguation (Navigli, 2009, WSD) continuing to be focused primarily on English. While the lack of resources has hampered the development of effective multilingual approaches to WSD, recently this idea has been revamped with the organization of SemEval tasks on cross-lingual WSD (Lefever an</context>
</contexts>
<marker>Lu, Tan, Cardie, Tsou, 2011</marker>
<rawString>Bin Lu, Chenhao Tan, Claire Cardie, and Benjamin K. Tsou. 2011. Joint bilingual sentiment classification with unlabeled parallel corpora. In Proc. of ACL-11, pages 320–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yashar Mehdad</author>
<author>Matteo Negri</author>
<author>Marcello Federico</author>
</authors>
<title>Using bilingual parallel corpora for crosslingual textual entailment.</title>
<date>2011</date>
<booktitle>In Proc. of ACL-11,</booktitle>
<pages>1336--1345</pages>
<contexts>
<context position="1020" citStr="Mehdad et al., 2011" startWordPosition="145" endWordPosition="148">aim is to provide the research community with easy-to-use tools to perform multilingual lexical semantic analysis and foster further research in this direction. 1 Introduction In recent years research in Natural Language Processing (NLP) has been steadily moving towards multilingual processing: the availability of ever growing amounts of text in different languages, in fact, has been a major driving force behind research on multilingual approaches, from morphosyntactic (Das and Petrov, 2011) and syntacticosemantic (Peirsman and Pad´o, 2010) phenomena to high-end tasks like textual entailment (Mehdad et al., 2011) and sentiment analysis (Lu et al., 2011). These research trends would seem to indicate the time is ripe for developing methods capable of performing semantic analysis of texts written in any language: however, this objective is still far from being attained, as is demonstrated by research in a core language understanding task such as Word Sense Disambiguation (Navigli, 2009, WSD) continuing to be focused primarily on English. While the lack of resources has hampered the development of effective multilingual approaches to WSD, recently this idea has been revamped with the organization of SemEv</context>
</contexts>
<marker>Mehdad, Negri, Federico, 2011</marker>
<rawString>Yashar Mehdad, Matteo Negri, and Marcello Federico. 2011. Using bilingual parallel corpora for crosslingual textual entailment. In Proc. of ACL-11, pages 1336–1345.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Ravi Sinha</author>
<author>Diana McCarthy</author>
</authors>
<title>SemEval-2010 Task 2: Cross-lingual lexical substitution.</title>
<date>2010</date>
<booktitle>In Proc. of SemEval-2010,</booktitle>
<pages>9--14</pages>
<contexts>
<context position="1738" citStr="Mihalcea et al., 2010" startWordPosition="257" endWordPosition="260"> is ripe for developing methods capable of performing semantic analysis of texts written in any language: however, this objective is still far from being attained, as is demonstrated by research in a core language understanding task such as Word Sense Disambiguation (Navigli, 2009, WSD) continuing to be focused primarily on English. While the lack of resources has hampered the development of effective multilingual approaches to WSD, recently this idea has been revamped with the organization of SemEval tasks on cross-lingual WSD (Lefever and Hoste, 2010) and cross-lingual lexical substitution (Mihalcea et al., 2010). In addition, new research on the topic has explored the translation of sentences into many languages (Navigli and Ponzetto, 2010; Lefever et al., 2011; Banea and Mihalcea, 2011), as well as the projection of monolingual knowledge onto another language (Khapra et al., 2011). In our research we focus on knowledge-based methods and tools for multilingual WSD, since knowledge-rich WSD has been shown to achieve high performance across domains (Agirre et al., 2009; Navigli et al., 2011) and to compete with supervised methods on a variety of lexical disambiguation tasks (Ponzetto and Navigli, 2010)</context>
</contexts>
<marker>Mihalcea, Sinha, McCarthy, 2010</marker>
<rawString>Rada Mihalcea, Ravi Sinha, and Diana McCarthy. 2010. SemEval-2010 Task 2: Cross-lingual lexical substitution. In Proc. of SemEval-2010, pages 9–14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vivi Nastase</author>
<author>Michael Strube</author>
<author>Benjamin B¨orschinger</author>
</authors>
<title>Caecilia Zirn, and Anas Elghafari.</title>
<date>2010</date>
<booktitle>Proc. of LREC ’10.</booktitle>
<marker>Nastase, Strube, B¨orschinger, 2010</marker>
<rawString>Vivi Nastase, Michael Strube, Benjamin B¨orschinger, Caecilia Zirn, and Anas Elghafari. 2010. WikiNet: A very large scale multi-lingual concept network. In Proc. of LREC ’10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Mirella Lapata</author>
</authors>
<title>An experimental study on graph connectivity for unsupervised Word Sense Disambiguation.</title>
<date>2010</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<volume>32</volume>
<issue>4</issue>
<pages>692</pages>
<contexts>
<context position="10100" citStr="Navigli and Lapata (2010)" startWordPosition="1517" endWordPosition="1520"> page found in it (lines 5–7). Then, we access and print the Italian word senses they contain (lines 8–10), and finally the synsets they are related to (lines 11–19). Thanks to carefully designed Java classes, we are able to accomplish all of this in about 20 lines of code. Multilingual WSD API. We use the BabelNet API as a framework to build a toolkit that allows the user to perform multilingual graph-based lexical disambiguation – namely, to identify the most suitable meanings of the input words on the basis of the semantic connections found in the lexical knowledge base, along the lines of Navigli and Lapata (2010). At its core, the API leverages an in-house Java library to query paths and create semantic graphs with BabelNet. The latter works by pre-computing off-line paths connecting any pair of Babel synsets, which are collected by iterating through each synset in turn, and performing a depth-first search up to a maximum depth – which we set to 3, on the basis of experimental evidence from a variety of knowledge base linking and lexical disambiguation tasks (Navigli and Lapata, 2010; Ponzetto and Navigli, 2010). Next, these paths are stored within a Lucene index, which ensures efficient lookups for q</context>
<context position="14665" citStr="Navigli and Lapata, 2010" startWordPosition="2228" endWordPosition="2231">to the one highlighted by the main method of lines 21–26, where we disambiguate the sample sentence ‘bank bonuses are paid in stocks’ (note that each input word can be written in any of the 6 languages, i.e. we could mix languages). 4 Experiments We benchmark our API by performing knowledgebased WSD with BabelNet on standard SemEval datasets, namely the SemEval-2007 coarse-grained all-words (Navigli et al., 2007, Coarse-WSD, henceforth) and the SemEval-2010 cross-lingual (Lefever and Hoste, 2010, CL-WSD) WSD tasks. For both experimental settings we use a standard graphbased algorithm, Degree (Navigli and Lapata, 2010), which has been previously shown to yield a highly competitive performance on different lexical disambiguation tasks (Ponzetto and Navigli, 2010). Given a semantic graph for the input context, Degree selects the sense of the target word with the highest vertex degree. In addition, in the CL-WSD setting we need to output appropriate lexicalization(s) in different languages. Since the selected Babel synset can contain multiple translations in a target language for the given English word, we use for this task an 70 Algorithm Nouns only All words NUS-PT 82.3 82.5 SUSSX-FR 81.1 77.0 Degree 84.7 82</context>
</contexts>
<marker>Navigli, Lapata, 2010</marker>
<rawString>Roberto Navigli and Mirella Lapata. 2010. An experimental study on graph connectivity for unsupervised Word Sense Disambiguation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 32(4):678– 692.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>BabelNet: Building a very large multilingual semantic network. In</title>
<date>2010</date>
<booktitle>Proc. ofACL-10,</booktitle>
<pages>216--225</pages>
<contexts>
<context position="1868" citStr="Navigli and Ponzetto, 2010" startWordPosition="277" endWordPosition="280">ive is still far from being attained, as is demonstrated by research in a core language understanding task such as Word Sense Disambiguation (Navigli, 2009, WSD) continuing to be focused primarily on English. While the lack of resources has hampered the development of effective multilingual approaches to WSD, recently this idea has been revamped with the organization of SemEval tasks on cross-lingual WSD (Lefever and Hoste, 2010) and cross-lingual lexical substitution (Mihalcea et al., 2010). In addition, new research on the topic has explored the translation of sentences into many languages (Navigli and Ponzetto, 2010; Lefever et al., 2011; Banea and Mihalcea, 2011), as well as the projection of monolingual knowledge onto another language (Khapra et al., 2011). In our research we focus on knowledge-based methods and tools for multilingual WSD, since knowledge-rich WSD has been shown to achieve high performance across domains (Agirre et al., 2009; Navigli et al., 2011) and to compete with supervised methods on a variety of lexical disambiguation tasks (Ponzetto and Navigli, 2010). Our vision of knowledge-rich multilingual WSD requires two fundamental components: first, a wide-coverage multilingual lexical k</context>
<context position="5285" citStr="Navigli and Ponzetto, 2010" startWordPosition="764" endWordPosition="767">ical knowledge base and accordingly consists of a labeled directed graph where nodes represent concepts and named entities and edges express semantic relations between them. Concepts and relations are harvested from the largest available semantic lexicon of English, i.e., WordNet (Fellbaum, 1998), and a wide-coverage collaboratively-edited encyclopedia, i.e., Wikipedia1, thus making BabelNet a multilingual ‘encyclopedic dictionary’ which automatically integrates fine-grained lexicographic information with large amounts of encyclopedic knowledge by means of a high-performing mapping algorithm (Navigli and Ponzetto, 2010). In addition to this conceptual backbone, BabelNet provides a multilingual lexical dimension. Each of its nodes, called Babel synsets, contains a set of lexicalizations of the concept for different languages, e.g., { bankEN, BankDE, bancaIT, ..., bancoES I. Similar in spirit to WordNet, BabelNet consists, at its lowest level, of a plain text file. An excerpt of the entry for the Babel synset containing bank&apos; is shown in Figure 12. The record contains (a) the synset’s id; (b) the region of BabelNet where it lies (e.g., WIKIWN means at the intersec1http://www.wikipedia.org 2We denote with wP th</context>
</contexts>
<marker>Navigli, Ponzetto, 2010</marker>
<rawString>Roberto Navigli and Simone Paolo Ponzetto. 2010. BabelNet: Building a very large multilingual semantic network. In Proc. ofACL-10, pages 216–225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>BabelNetXplorer: a platform for multilingual lexical knowledge base access and exploration.</title>
<date>2012</date>
<booktitle>In Comp. Vol. to Proc. of WWW-12,</booktitle>
<pages>393--396</pages>
<contexts>
<context position="17055" citStr="Navigli and Ponzetto, 2012" startWordPosition="2610" endWordPosition="2613">till lags behind the application of supervised techniques to this task (cf. also results from Lefever and Hoste (2010)), we argue that further improvements can still be obtained by exploiting more complex disambiguation strategies. In general, using our toolkit we are able to achieve a performance which is competitive with the state of the art for these tasks, thus supporting previous findings on knowledge-rich WSD, and confirming the robustness of our toolkit. 5 Related Work Our work complements recent efforts focused on visual browsing of wide-coverage knowledge bases (Tylenda et al., 2011; Navigli and Ponzetto, 2012) by means of an API which allows the user to programmatically query and search BabelNet. This knowledge resource, in turn, can be used for easDegree T3-Coleur UvT-v Dutch 15.52 10.56 17.70 French 22.94 21.75 − German 17.15 13.05 − Italian 18.03 14.67 − Spanish 22.48 19.64 23.39 Table 2: Performance on SemEval-2010 cross-lingual WSD (Lefever and Hoste, 2010). ily performing multilingual and cross-lingual WSD out-of-the-box. In comparison with other contributions, our toolkit for multilingual WSD takes previous work from Navigli (2006), in which an online interface for graph-based monolingual WS</context>
</contexts>
<marker>Navigli, Ponzetto, 2012</marker>
<rawString>Roberto Navigli and Simone Paolo Ponzetto. 2012. BabelNetXplorer: a platform for multilingual lexical knowledge base access and exploration. In Comp. Vol. to Proc. of WWW-12, pages 393–396.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Kenneth C Litkowski</author>
<author>Orin Hargraves</author>
</authors>
<title>Semeval-2007 task 07: Coarse-grained English all-words task.</title>
<date>2007</date>
<booktitle>In Proc. of SemEval-2007,</booktitle>
<pages>30--35</pages>
<contexts>
<context position="14455" citStr="Navigli et al., 2007" startWordPosition="2198" endWordPosition="2201">ccurring within this graph (line 5–10). Finally, we output the sense distributions of each word in lines 11–18. The disambiguation method, in turn, can be called by any other Java program in a way similar to the one highlighted by the main method of lines 21–26, where we disambiguate the sample sentence ‘bank bonuses are paid in stocks’ (note that each input word can be written in any of the 6 languages, i.e. we could mix languages). 4 Experiments We benchmark our API by performing knowledgebased WSD with BabelNet on standard SemEval datasets, namely the SemEval-2007 coarse-grained all-words (Navigli et al., 2007, Coarse-WSD, henceforth) and the SemEval-2010 cross-lingual (Lefever and Hoste, 2010, CL-WSD) WSD tasks. For both experimental settings we use a standard graphbased algorithm, Degree (Navigli and Lapata, 2010), which has been previously shown to yield a highly competitive performance on different lexical disambiguation tasks (Ponzetto and Navigli, 2010). Given a semantic graph for the input context, Degree selects the sense of the target word with the highest vertex degree. In addition, in the CL-WSD setting we need to output appropriate lexicalization(s) in different languages. Since the sel</context>
</contexts>
<marker>Navigli, Litkowski, Hargraves, 2007</marker>
<rawString>Roberto Navigli, Kenneth C. Litkowski, and Orin Hargraves. 2007. Semeval-2007 task 07: Coarse-grained English all-words task. In Proc. of SemEval-2007, pages 30–35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
</authors>
<title>Stefano Faralli, Aitor Soroa, Oier Lopez de Lacalle, and Eneko Agirre.</title>
<date>2011</date>
<booktitle>In Proc. of CIKM-11,</booktitle>
<pages>2317--2320</pages>
<marker>Navigli, 2011</marker>
<rawString>Roberto Navigli, Stefano Faralli, Aitor Soroa, Oier Lopez de Lacalle, and Eneko Agirre. 2011. Two birds with one stone: learning semantic models for Text Categorization and Word Sense Disambiguation. In Proc. of CIKM-11, pages 2317–2320.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
</authors>
<title>Online word sense disambiguation with structural semantic interconnections.</title>
<date>2006</date>
<booktitle>In Proc. of EACL-06,</booktitle>
<pages>107--110</pages>
<contexts>
<context position="17594" citStr="Navigli (2006)" startWordPosition="2697" endWordPosition="2698">coverage knowledge bases (Tylenda et al., 2011; Navigli and Ponzetto, 2012) by means of an API which allows the user to programmatically query and search BabelNet. This knowledge resource, in turn, can be used for easDegree T3-Coleur UvT-v Dutch 15.52 10.56 17.70 French 22.94 21.75 − German 17.15 13.05 − Italian 18.03 14.67 − Spanish 22.48 19.64 23.39 Table 2: Performance on SemEval-2010 cross-lingual WSD (Lefever and Hoste, 2010). ily performing multilingual and cross-lingual WSD out-of-the-box. In comparison with other contributions, our toolkit for multilingual WSD takes previous work from Navigli (2006), in which an online interface for graph-based monolingual WSD is presented, one step further by adding a multilingual dimension as well as a full-fledged API. Our work also complements previous attempts by NLP researchers to provide the community with freely available tools to perform state-of-the-art WSD using WordNet-based measures of semantic relatedness (Patwardhan et al., 2005), as well as supervised WSD techniques (Zhong and Ng, 2010). We achieve this by building upon BabelNet, a multilingual ‘encyclopedic dictionary’ bringing together the lexicographic and encyclopedic knowledge from W</context>
</contexts>
<marker>Navigli, 2006</marker>
<rawString>Roberto Navigli. 2006. Online word sense disambiguation with structural semantic interconnections. In Proc. of EACL-06, pages 107–110.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
</authors>
<title>Word Sense Disambiguation: A survey.</title>
<date>2009</date>
<journal>ACM Computing Surveys,</journal>
<volume>41</volume>
<issue>2</issue>
<contexts>
<context position="1397" citStr="Navigli, 2009" startWordPosition="208" endWordPosition="209">en a major driving force behind research on multilingual approaches, from morphosyntactic (Das and Petrov, 2011) and syntacticosemantic (Peirsman and Pad´o, 2010) phenomena to high-end tasks like textual entailment (Mehdad et al., 2011) and sentiment analysis (Lu et al., 2011). These research trends would seem to indicate the time is ripe for developing methods capable of performing semantic analysis of texts written in any language: however, this objective is still far from being attained, as is demonstrated by research in a core language understanding task such as Word Sense Disambiguation (Navigli, 2009, WSD) continuing to be focused primarily on English. While the lack of resources has hampered the development of effective multilingual approaches to WSD, recently this idea has been revamped with the organization of SemEval tasks on cross-lingual WSD (Lefever and Hoste, 2010) and cross-lingual lexical substitution (Mihalcea et al., 2010). In addition, new research on the topic has explored the translation of sentences into many languages (Navigli and Ponzetto, 2010; Lefever et al., 2011; Banea and Mihalcea, 2011), as well as the projection of monolingual knowledge onto another language (Khap</context>
</contexts>
<marker>Navigli, 2009</marker>
<rawString>Roberto Navigli. 2009. Word Sense Disambiguation: A survey. ACM Computing Surveys, 41(2):1–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Siddharth Patwardhan</author>
<author>Satanjeev Banerjee</author>
<author>Ted Pedersen</author>
</authors>
<title>SenseRelate::TargetWord – a generalized framework for Word Sense Disambiguation.</title>
<date>2005</date>
<booktitle>In Comp. Vol. to Proc. of ACL-05,</booktitle>
<pages>73--76</pages>
<contexts>
<context position="17980" citStr="Patwardhan et al., 2005" startWordPosition="2755" endWordPosition="2758">n SemEval-2010 cross-lingual WSD (Lefever and Hoste, 2010). ily performing multilingual and cross-lingual WSD out-of-the-box. In comparison with other contributions, our toolkit for multilingual WSD takes previous work from Navigli (2006), in which an online interface for graph-based monolingual WSD is presented, one step further by adding a multilingual dimension as well as a full-fledged API. Our work also complements previous attempts by NLP researchers to provide the community with freely available tools to perform state-of-the-art WSD using WordNet-based measures of semantic relatedness (Patwardhan et al., 2005), as well as supervised WSD techniques (Zhong and Ng, 2010). We achieve this by building upon BabelNet, a multilingual ‘encyclopedic dictionary’ bringing together the lexicographic and encyclopedic knowledge from WordNet and Wikipedia. Other recent projects on creating multilingual knowledge bases from Wikipedia include WikiNet (Nastase et al., 2010) and MENTA (de Melo and Weikum, 2010): both these resources offer structured information complementary to BabelNet – i.e., large amounts of facts about entities (MENTA), and explicit semantic relations harvested from Wikipedia categories (WikiNet).</context>
</contexts>
<marker>Patwardhan, Banerjee, Pedersen, 2005</marker>
<rawString>Siddharth Patwardhan, Satanjeev Banerjee, and Ted Pedersen. 2005. SenseRelate::TargetWord – a generalized framework for Word Sense Disambiguation. In Comp. Vol. to Proc. of ACL-05, pages 73–76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
<author>Siddharth Patwardhan</author>
<author>Jason Michelizzi</author>
</authors>
<title>WordNet::Similarity – Measuring the relatedness of concepts.</title>
<date>2004</date>
<booktitle>In Comp. Vol. to Proc. of HLTNAACL-04,</booktitle>
<pages>267--270</pages>
<contexts>
<context position="3269" citStr="Pedersen et al., 2004" startWordPosition="490" endWordPosition="494"> freely available to the research community on a multilingual scale. Previous endeavors are either not freely available (EuroWordNet (Vossen, 1998)), or are only accessible via a Web interface (cf. the Multilingual Research Repository (Atserias et al., 2004) and MENTA (de Melo and Weikum, 2010)), thus providing no programmatic access. And this is despite the fact that the availability of easy-to-use libraries for efficient information access is known to foster top-level research – cf. the widespread use of semantic similarity measures in NLP, thanks to the availability of WordNet::Similarity (Pedersen et al., 2004). With the present contribution we aim to fill this gap in multilingual tools, providing a multi-tiered contribution consisting of (a) an Application Programming Interface (API) for efficiently accessing the information available in BabelNet (Navigli and 67 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 67–72, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics bn:00008364n WIKIWN 08420278n 85 WN:EN:bank WIKI:EN:Bank WIKI:DE:Bank WIKI:IT:Banca WIKIRED:DE:Finanzinstitut WN:EN:banking_company WNTR:ES:banco WNTR</context>
</contexts>
<marker>Pedersen, Patwardhan, Michelizzi, 2004</marker>
<rawString>Ted Pedersen, Siddharth Patwardhan, and Jason Michelizzi. 2004. WordNet::Similarity – Measuring the relatedness of concepts. In Comp. Vol. to Proc. of HLTNAACL-04, pages 267–270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Peirsman</author>
<author>Sebastian Pad´o</author>
</authors>
<title>Crosslingual induction of selectional preferences with bilingual vector spaces.</title>
<date>2010</date>
<booktitle>In Proc. of NAACL-HLT-10,</booktitle>
<pages>921--929</pages>
<marker>Peirsman, Pad´o, 2010</marker>
<rawString>Yves Peirsman and Sebastian Pad´o. 2010. Crosslingual induction of selectional preferences with bilingual vector spaces. In Proc. of NAACL-HLT-10, pages 921–929.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simone Paolo Ponzetto</author>
<author>Roberto Navigli</author>
</authors>
<title>Knowledge-rich Word Sense Disambiguation rivaling supervised system.</title>
<date>2010</date>
<booktitle>In Proc. of ACL-10,</booktitle>
<pages>1522--1531</pages>
<contexts>
<context position="2338" citStr="Ponzetto and Navigli, 2010" startWordPosition="352" endWordPosition="355">ion (Mihalcea et al., 2010). In addition, new research on the topic has explored the translation of sentences into many languages (Navigli and Ponzetto, 2010; Lefever et al., 2011; Banea and Mihalcea, 2011), as well as the projection of monolingual knowledge onto another language (Khapra et al., 2011). In our research we focus on knowledge-based methods and tools for multilingual WSD, since knowledge-rich WSD has been shown to achieve high performance across domains (Agirre et al., 2009; Navigli et al., 2011) and to compete with supervised methods on a variety of lexical disambiguation tasks (Ponzetto and Navigli, 2010). Our vision of knowledge-rich multilingual WSD requires two fundamental components: first, a wide-coverage multilingual lexical knowledge base; second, tools to effectively query, retrieve and exploit its information for disambiguation. Nevertheless, to date, no integrated resources and tools exist that are freely available to the research community on a multilingual scale. Previous endeavors are either not freely available (EuroWordNet (Vossen, 1998)), or are only accessible via a Web interface (cf. the Multilingual Research Repository (Atserias et al., 2004) and MENTA (de Melo and Weikum, 2</context>
<context position="10609" citStr="Ponzetto and Navigli, 2010" startWordPosition="1602" endWordPosition="1605">he basis of the semantic connections found in the lexical knowledge base, along the lines of Navigli and Lapata (2010). At its core, the API leverages an in-house Java library to query paths and create semantic graphs with BabelNet. The latter works by pre-computing off-line paths connecting any pair of Babel synsets, which are collected by iterating through each synset in turn, and performing a depth-first search up to a maximum depth – which we set to 3, on the basis of experimental evidence from a variety of knowledge base linking and lexical disambiguation tasks (Navigli and Lapata, 2010; Ponzetto and Navigli, 2010). Next, these paths are stored within a Lucene index, which ensures efficient lookups for querying those paths starting and ending in a specific synset. Given a set of words as input, a semantic graph factory class searches for their meanings within BabelNet, looks for their connecting paths, and merges such paths within a single graph. Optionally, the paths making up the graph can be filtered – e.g., it is possible to remove loops, weighted edges below a certain threshold, etc. – and the graph nodes can be scored using a variety of methods – such as, for instance, their outdegree or PageRank </context>
<context position="13208" citStr="Ponzetto and Navigli, 2010" startWordPosition="1985" endWordPosition="1988">ge.EN), 24 new Word(&amp;quot;pay&amp;quot;, ’v’, Language.EN), new Word(&amp;quot;stock&amp;quot;, ’n’, Language.EN)}); 25 disambiguate(sentence, KnowledgeBase.BABELNET, KnowledgeGraphScorer.DEGREE); 26 } Figure 3: Sample Word Sense Disambiguation API usage. ambiguation, and a KnowledgeGraphScorer, namely a value from an enumeration of different graph connectivity measures (e.g., node outdegree), which are responsible for scoring nodes (i.e., concepts) in the graph. KnowledgeBase is an enumeration of supported knowledge bases: currently, it includes BabelNet, as well as WordNet++ (namely, an English WordNet-based subset of it (Ponzetto and Navigli, 2010)) and WordNet. Note that, while BabelNet is presently the only lexical knowledge base which allows for multilingual processing, our framework can easily be extended to work with other existing lexical knowledge resources, provided they can be wrapped around Java classes and implement interface methods for querying senses, concepts, and their semantic relations. In the snippet we start in line 3 by obtaining an instance of the factory class which creates the semantic graphs for a given knowledge base. Next, we use this factory to create the graph for the input words (line 4). We then score the </context>
<context position="14811" citStr="Ponzetto and Navigli, 2010" startWordPosition="2249" endWordPosition="2252"> each input word can be written in any of the 6 languages, i.e. we could mix languages). 4 Experiments We benchmark our API by performing knowledgebased WSD with BabelNet on standard SemEval datasets, namely the SemEval-2007 coarse-grained all-words (Navigli et al., 2007, Coarse-WSD, henceforth) and the SemEval-2010 cross-lingual (Lefever and Hoste, 2010, CL-WSD) WSD tasks. For both experimental settings we use a standard graphbased algorithm, Degree (Navigli and Lapata, 2010), which has been previously shown to yield a highly competitive performance on different lexical disambiguation tasks (Ponzetto and Navigli, 2010). Given a semantic graph for the input context, Degree selects the sense of the target word with the highest vertex degree. In addition, in the CL-WSD setting we need to output appropriate lexicalization(s) in different languages. Since the selected Babel synset can contain multiple translations in a target language for the given English word, we use for this task an 70 Algorithm Nouns only All words NUS-PT 82.3 82.5 SUSSX-FR 81.1 77.0 Degree 84.7 82.3 MFS BL 77.4 78.9 Random BL 63.5 62.7 Table 1: Performance on SemEval-2007 coarse-grained all-words WSD (Navigli et al., 2007). unsupervised app</context>
</contexts>
<marker>Ponzetto, Navigli, 2010</marker>
<rawString>Simone Paolo Ponzetto and Roberto Navigli. 2010. Knowledge-rich Word Sense Disambiguation rivaling supervised system. In Proc. of ACL-10, pages 1522– 1531.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomasz Tylenda</author>
<author>Mauro Sozio</author>
<author>Gerhard Weikum</author>
</authors>
<title>Einstein: physicist or vegetarian? Summarizing semantic type graphs for knowledge discovery.</title>
<date>2011</date>
<booktitle>In Proc. of WWW-11,</booktitle>
<pages>273--276</pages>
<contexts>
<context position="17026" citStr="Tylenda et al., 2011" startWordPosition="2606" endWordPosition="2609">hile our performance still lags behind the application of supervised techniques to this task (cf. also results from Lefever and Hoste (2010)), we argue that further improvements can still be obtained by exploiting more complex disambiguation strategies. In general, using our toolkit we are able to achieve a performance which is competitive with the state of the art for these tasks, thus supporting previous findings on knowledge-rich WSD, and confirming the robustness of our toolkit. 5 Related Work Our work complements recent efforts focused on visual browsing of wide-coverage knowledge bases (Tylenda et al., 2011; Navigli and Ponzetto, 2012) by means of an API which allows the user to programmatically query and search BabelNet. This knowledge resource, in turn, can be used for easDegree T3-Coleur UvT-v Dutch 15.52 10.56 17.70 French 22.94 21.75 − German 17.15 13.05 − Italian 18.03 14.67 − Spanish 22.48 19.64 23.39 Table 2: Performance on SemEval-2010 cross-lingual WSD (Lefever and Hoste, 2010). ily performing multilingual and cross-lingual WSD out-of-the-box. In comparison with other contributions, our toolkit for multilingual WSD takes previous work from Navigli (2006), in which an online interface f</context>
</contexts>
<marker>Tylenda, Sozio, Weikum, 2011</marker>
<rawString>Tomasz Tylenda, Mauro Sozio, and Gerhard Weikum. 2011. Einstein: physicist or vegetarian? Summarizing semantic type graphs for knowledge discovery. In Proc. of WWW-11, pages 273–276.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maarten van Gompel</author>
</authors>
<title>UvT-WSD1: A crosslingual word sense disambiguation system.</title>
<date>2010</date>
<booktitle>In Proc. of SemEval-2010,</booktitle>
<pages>238--241</pages>
<marker>van Gompel, 2010</marker>
<rawString>Maarten van Gompel. 2010. UvT-WSD1: A crosslingual word sense disambiguation system. In Proc. of SemEval-2010, pages 238–241.</rawString>
</citation>
<citation valid="true">
<date>1998</date>
<booktitle>EuroWordNet: A Multilingual Database with Lexical Semantic Networks.</booktitle>
<editor>Piek Vossen, editor.</editor>
<publisher>Kluwer,</publisher>
<location>Dordrecht, The Netherlands.</location>
<marker>1998</marker>
<rawString>Piek Vossen, editor. 1998. EuroWordNet: A Multilingual Database with Lexical Semantic Networks. Kluwer, Dordrecht, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhi Zhong</author>
<author>Hwee Tou Ng</author>
</authors>
<title>It Makes Sense: A wide-coverage Word Sense Disambiguation system for free text.</title>
<date>2010</date>
<booktitle>In Proc. of ACL-10 System Demonstrations,</booktitle>
<pages>78--83</pages>
<contexts>
<context position="18039" citStr="Zhong and Ng, 2010" startWordPosition="2765" endWordPosition="2768">performing multilingual and cross-lingual WSD out-of-the-box. In comparison with other contributions, our toolkit for multilingual WSD takes previous work from Navigli (2006), in which an online interface for graph-based monolingual WSD is presented, one step further by adding a multilingual dimension as well as a full-fledged API. Our work also complements previous attempts by NLP researchers to provide the community with freely available tools to perform state-of-the-art WSD using WordNet-based measures of semantic relatedness (Patwardhan et al., 2005), as well as supervised WSD techniques (Zhong and Ng, 2010). We achieve this by building upon BabelNet, a multilingual ‘encyclopedic dictionary’ bringing together the lexicographic and encyclopedic knowledge from WordNet and Wikipedia. Other recent projects on creating multilingual knowledge bases from Wikipedia include WikiNet (Nastase et al., 2010) and MENTA (de Melo and Weikum, 2010): both these resources offer structured information complementary to BabelNet – i.e., large amounts of facts about entities (MENTA), and explicit semantic relations harvested from Wikipedia categories (WikiNet). Acknowledgments The authors gratefully acknowledge the sup</context>
</contexts>
<marker>Zhong, Ng, 2010</marker>
<rawString>Zhi Zhong and Hwee Tou Ng. 2010. It Makes Sense: A wide-coverage Word Sense Disambiguation system for free text. In Proc. of ACL-10 System Demonstrations, pages 78–83.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>