<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.039663">
<title confidence="0.973594">
SVD and Clustering for Unsupervised POS Tagging
</title>
<author confidence="0.995417">
Michael Lamar*
</author>
<affiliation confidence="0.983184">
Division of Applied Mathematics
Brown University
</affiliation>
<address confidence="0.939681">
Providence, RI, USA
</address>
<email confidence="0.999769">
mlamar@dam.brown.edu
</email>
<author confidence="0.99864">
Mark Johnson
</author>
<affiliation confidence="0.9114305">
Department of Computing
Faculty of Science
Macquarie University
Sydney, Australia
</affiliation>
<email confidence="0.996319">
mjohnson@science.mq.edu.au
</email>
<sectionHeader confidence="0.995599" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999805083333333">
We revisit the algorithm of Schütze
(1995) for unsupervised part of speech
tagging. The algorithm uses reduced rank
singular value decomposition followed
by clustering to extract latent features
from context distributions. As imple
mented here, it achieves state of the art
tagging accuracy at considerably less cost
than more recent methods. It can also
produce a range of finer grained tag
gings, with potential applications to vari
ous tasks.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999942125">
While supervised approaches are able to solve
the part of speech (POS) tagging problem with
over 97% accuracy (Collins 2002; Toutanova et
al. 2003), unsupervised algorithms perform con
siderably less well. These models attempt to tag
text without resources such as an annotated cor
pus, a dictionary, etc. The use of singular value
decomposition (SVD) for this problem was in
troduced in Schütze (1995). Subsequently, a
number of methods for POS tagging without a
dictionary were examined, e.g., by Clark (2000),
Clark (2003), Haghighi and Klein (2006), John
son (2007), Goldwater and Griffiths (2007), Gao
and Johnson (2008), and Graça et al. (2009).
The latter two, using Hidden Markov Models
(HMMs), exhibit the highest performances to
</bodyText>
<note confidence="0.982781">
* These authors contributed equally.
</note>
<author confidence="0.976868">
Yariv Maron*
</author>
<affiliation confidence="0.858199666666667">
Gonda Brain Research Center
Bar Ilan University
Ramat Gan, Israel
</affiliation>
<email confidence="0.99584">
syarivm@yahoo.com
</email>
<author confidence="0.99074">
Elie Bienenstock
</author>
<affiliation confidence="0.995394666666667">
Division of Applied Mathematics
and Department of Neuroscience
Brown University
</affiliation>
<address confidence="0.871322">
Providence, RI, USA
</address>
<email confidence="0.995637">
elie@brown.edu
</email>
<bodyText confidence="0.999147055555556">
date for fully unsupervised POS tagging.
The revisited SVD based approach presented
here, which we call “two step SVD” or SVD2,
has four important characteristics. First, it
achieves state of the art tagging accuracy.
Second, it requires drastically less computational
effort than the best currently available models.
Third, it demonstrates that state of the art accu
racy can be realized without disambiguation, i.e.,
without attempting to assign different tags to dif
ferent tokens of the same type. Finally, with no
significant increase in computational cost, SVD2
can create much finer grained labelings than typ
ically produced by other algorithms. When com
bined with some minimal supervision in post
processing, this makes the approach useful for
tagging languages that lack the resources re
quired by fully supervised models.
</bodyText>
<sectionHeader confidence="0.993107" genericHeader="introduction">
2 Methods
</sectionHeader>
<bodyText confidence="0.997652071428571">
Following the original work of Schütze (1995),
we begin by constructing a right context matrix,
R, and a left context matrix, L. R,ij counts the
number of times in the corpus a token of word
type i is immediately followed by a token of
word type j. Similarly, L,ij counts the number of
times a token of type i is preceded by a token of
type j. We truncate these matrices, including, in
the right and left contexts, only the w1 most fre
quent word types. The resulting L and R are of
dimension Ntypesxw1, where Nypes is the number
of word types (spelling forms) in the corpus, and
w1 is set to 1000. (The full Ntypesx Ntypes context
matrices satisfy R = LT.)
</bodyText>
<page confidence="0.984945">
215
</page>
<note confidence="0.5032095">
Proceedings of the ACL 2010 Conference Short Papers, pages 215–219,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<equation confidence="0.999679">
L* = UL SL*
R* = UR SR*.
</equation>
<bodyText confidence="0.991273791666667">
Row i in matrix L* (resp. R*) is the left (resp.
right) latent descriptor for word type i. We next
include a normalization step in which each row
in each of L* and R* is scaled to unit length,
yielding matrices L** and R**. Finally, we form a
single descriptor matrix D by concatenating these
matrices into D = [L** R**]. Row i in matrix D is
the complete latent descriptor for word type i;
this latent descriptor sits on the Cartesian product
of two 100 dimensional unit spheres, hereafter
the 2-sphere.
We next categorize these descriptors into
k1 = 500 groups, using a k means clustering algo
rithm. Centroid initialization is done by placing
the k initial centroids on the descriptors of the k
most frequent words in the corpus. As the de
scriptors sit on the 2 sphere, we measure the
proximity of a descriptor to a centroid by the dot
product between them; this is equal to the sum of
the cosines of the angles—computed on the left
and right parts—between them. We update each
cluster’s centroid as the weighted average of its
constituents, the weight being the frequency of
the word type; the centroids are then scaled, so
they sit on the 2 sphere. Typically, only a few
dozen iterations are required for full convergence
of the clustering algorithm.
We then apply a second pass of this entire
SVD and clustering procedure. In this second
pass, we use the k1 = 500 clusters from the first
iteration to assemble a new pair of context ma
trices. Now, Ri� counts all the cluster � (�=1... k1)
words to the right of word i, and Li� counts all the
cluster � words to the left of word i. The new ma
trices L and R have dimension Nypes x k1.
As in the first pass, we perform reduced rank
SVD, this time down to rank r2 = 300, and we
again normalize the descriptors to unit length,
yielding a new pair of latent descriptor matrices
L** and R**. Finally, we concatenate L** and R**
into a single matrix of descriptors, and cluster
these descriptors into k2 groups, where k2 is the
desired number of induced tags. We use the same
weighted k means algorithm as in the first pass,
again placing the k initial centroids on the de
scriptors of the k most frequent words in the cor
pus. The final tag of any token in the corpus is
the cluster number of its type.
</bodyText>
<sectionHeader confidence="0.956335" genericHeader="method">
3 Data and Evaluation
</sectionHeader>
<bodyText confidence="0.999663806451613">
We ran the SVD2 algorithm described above on
the full Wall Street Journal part of the Penn
Treebank (1,173,766 tokens). Capitalization was
ignored, resulting in Nypes = 43,766, with only a
minor effect on accuracy. Evaluation was done
against the POS tag annotations of the 45 tag
PTB tagset (hereafter PTB45), and against the
Smith and Eisner (2005) coarse version of the
PTB tagset (hereafter PTB17). We selected the
three evaluation criteria of Gao and Johnson
(2008): M to 1, 1 to 1, and VI. M to 1 and 1 to
1 are the tagging accuracies under the best many
to one map and the greedy one to one map re
spectively; VI is a map free information
theoretic criterion—see Gao and Johnson (2008)
for details. Although we find M to 1 to be the
most reliable criterion of the three, we include
the other two criteria for completeness.
In addition to the best M to 1 map, we also
employ here, for large values of k2, a prototype-
based M to 1 map. To construct this map, we
first find, for each induced tag t, the word type
with which it co occurs most frequently; we call
this word type the prototype of t. We then query
the annotated data for the most common gold tag
for each prototype, and we map induced tag t to
this gold tag. This prototype based M to 1 map
produces accuracy scores no greater—typically
lower—than the best M to 1 map. We discuss
the value of this approach as a minimally
supervised post processing step in Section 5.
</bodyText>
<sectionHeader confidence="0.999911" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.984254857142857">
Low-k performance. Here we present the per
formance of the SVD2 model when k2, the num
ber of induced tags, is the same or roughly the
same as the number of tags in the gold stan
dard—hence small. Table 1 compares the per
formance of SVD2 to other leading models. Fol
lowing Gao and Johnson (2008), the number of
induced tags is 17 for PTB17 evaluation and 50
for PTB45 evaluation. Thus, with the exception
of Graça et al. (2009) who use 45 induced tags
for PTB45, the number of induced tags is the
same across each column of Table 1.
Next, both context matrices are factored using
singular value decomposition:
</bodyText>
<equation confidence="0.9974385">
L = UL SL VLT
R = UR SR VRT.
</equation>
<bodyText confidence="0.994003833333334">
The diagonal matrices SL and SR (each of rank
1000) are reduced down to rank r1 = 100 by re
placing the 900 smallest singular values in each
matrix with zeros, yielding SL* and SR*. We then
form a pair of latent descriptor matrices defined
by:
</bodyText>
<page confidence="0.99213">
216
</page>
<table confidence="0.999473875">
M-to-1 1-to-1 VI
Model PTB17 PTB45 PTB17 PTB45 PTB17 PTB45
SVD2 0.730 0.660 0.513 0.467 3.02 3.84
HMM EM 0.647 0.621 0.431 0.405 3.86 4.48
HMM VB 0.637 0.605 0.514 0.461 3.44 4.28
HMM GS 0.674 0.660 0.466 0.499 3.46 4.04
HMM Sparse(32) 0.702(2.2) 0.654(1.0) 0.495 0.445
VEM (10 1,10 1) 0.682(0.8) 0.546(1.7) 0.528 0.460
</table>
<tableCaption confidence="0.993157">
Table 1. Tagging accuracy under the best M to 1 map, the greedy 1 to 1 map, and
</tableCaption>
<bodyText confidence="0.999043725">
VI, for the full PTB45 tagset and the reduced PTB17 tagset. HMM EM, HMM VB
and HMM GS show the best results from Gao and Johnson (2008); HMM Sparse(32)
and VEM (10 1,10 1) show the best results from Graça et al. (2009).
The performance of SVD2 compares favora
bly to the HMM models. Note that SVD2 is a
deterministic algorithm. The table shows, in pa
rentheses, the standard deviations reported in
Graça et al. (2009). For the sake of comparison
with Graça et al. (2009), we also note that, with
k2 = 45, SVD2 scores 0.659 on PTB45. The NVI
scores (Reichart and Rappoport 2009) corres
ponding to the VI scores for SVD2 are 0.938 for
PTB17 and 0.885 for PTB45. To examine the
sensitivity of the algorithm to its four parameters,
w1, r1, k1, and r2, we changed each of these para
meters separately by a multiplicative factor of
either 0.5 or 2; in neither case did M to 1 accura
cy drop by more than 0.014.
This performance was achieved despite the
fact that the SVD2 tagger is mathematically
much simpler than the other models. Our MAT
LAB implementation of SVD2 takes only a few
minutes to run on a desktop computer, in contrast
to HMM training times of several hours or days
(Gao and Johnson 2008; Johnson 2007).
High-k performance. Not suffering from the
same computational limitations as other models,
SVD2 can easily accommodate high numbers of
induced tags, resulting in fine grained labelings.
The value of this flexibility is discussed in the
next section. Figure 1 shows, as a function of k2,
the tagging accuracy of SVD2 under both the
best and the prototype based M to 1 maps (see
Section 3), for both the PTB45 and the PTB17
tagsets. The horizontal one tag per word type
line in each panel is the theoretical upper limit
for tagging accuracy in non disambiguating
models (such as SVD2). This limit is the fraction
of all tokens in the corpus whose gold tag is the
most frequent for their type.
</bodyText>
<sectionHeader confidence="0.999491" genericHeader="conclusions">
5 Discussion
</sectionHeader>
<bodyText confidence="0.989540380952381">
At the heart of the algorithm presented here is
the reduced rank SVD method of Schütze
(1995), which transforms bigram counts into la
tent descriptors. In view of the present work,
Figure 1. Performance of the SVD2 algo
rithm as a function of the number of induced
tags. Top: PTB45; bottom: PTB17. Each
plot shows the tagging accuracy under the
best and the prototype based M to 1 maps, as
well as the upper limit for non
disambiguating taggers.
which achieves state of the art performance
when evaluation is done with the criteria now in
common use, Schütze&apos;s original work should
rightly be praised as ahead of its time. The SVD2
model presented here differs from Schütze&apos;s
work in many details of implementation—not all
of which are explicitly specified in Schütze
(1995). In what follows, we discuss the features
of SVD2 that are most critical to its performance.
Failure to incorporate any one of them signifi
</bodyText>
<page confidence="0.994685">
217
</page>
<bodyText confidence="0.999826990740741">
cantly reduces the performance of the algorithm
(M to 1 reduced by 0.04 to 0.08).
First, the reduced rank left singular vectors
(for the right and left context matrices) are
scaled, i.e., multiplied, by the singular values.
While the resulting descriptors, the rows of L*
and R*, live in a much lower dimensional space
than the original context vectors, they are
mapped by an angle preserving map (defined by
the matrices of right singular vectors VL and VR)
into vectors in the original space. These mapped
vectors best approximate (in the least squares
sense) the original context vectors; they have the
same geometric relationships as their equivalent
high dimensional images, making them good
candidates for the role of word type descriptors.
A second important feature of the SVD2 algo
rithm is the unit length normalization of the la
tent descriptors, along with the computation of
cluster centroids as the weighted averages of
their constituent vectors. Thanks to this com
bined device, rare words are treated equally to
frequent words regarding the length of their de
scriptor vectors, yet contribute less to the place
ment of centroids.
Finally, while the usual drawback of k means
clustering algorithms is the dependency of the
outcome on the initial—usually random—
placement of centroids, our initialization of the k
centroids as the descriptors of the k most fre
quent word types in the corpus makes the algo
rithm fully deterministic, and improves its per
formance substantially: M to 1 PTB45 by 0.043,
M to 1 PTB17 by 0.063.
As noted in the Results section, SVD2 is fairly
robust to changes in all four parameters w1, r1, k1,
and r2. The values used here were obtained by a
coarse, greedy strategy, where each parameter
was optimized independently. It is worth noting
that dispensing with the second pass altogether,
i.e., clustering directly the latent descriptor vec
tors obtained in the first pass into the desired
number of induced tags, results in a drop of
Many to 1 score of only 0.021 for the PTB45
tagset and 0.009 for the PTB17 tagset.
Disambiguation. An obvious limitation of
SVD2 is that it is a non disambiguating tagger,
assigning the same label to all tokens of a type.
However, this limitation per se is unlikely to be
the main obstacle to the improvement of low k
performance, since, as is well known, the theo
retical upper limit for the tagging accuracy of
non disambiguating models (shown in Fig. 1) is
much higher than the current state of the art for
unsupervised taggers, whether disambiguating or
not.
To further gain insight into how successful
current models are at disambiguating when they
have the power to do so, we examined a collec
tion of HMM VB runs (Gao and Johnson 2008)
and asked how the accuracy scores would change
if, after training was completed, the model were
forced to assign the same label to all tokens of
the same type. To answer this question, we de
termined, for each word type, the modal HMM
state, i.e., the state most frequently assigned by
the HMM to tokens of that type. We then re
labeled all words with their modal label. The ef
fect of thus eliminating the disambiguation ca
pacity of the model was to slightly increase the
tagging accuracy under the best M to 1 map for
every HMM VB run (the average increase was
0.026 for PTB17, and 0.015 for PTB45). We
view this as a further indication that, in the cur
rent state of the art and with regards to tagging
accuracy, limiting oneself to non disambiguating
models may not adversely affect performance.
To the contrary, this limitation may actually
benefit an approach such as SVD2. Indeed, on
difficult learning tasks, simpler models often be
have better than more powerful ones (Geman et
al. 1992). HMMs are powerful since they can, in
theory, induce both a system of tags and a system
of contextual patterns that allow them to disam
biguate word types in terms of these tags. How
ever, carrying out both of these unsupervised
learning tasks at once is problematic in view of
the very large number of parameters to be esti
mated compared to the size of the training data
set.
The POS tagging subtask of disambiguation
may then be construed as a challenge in its own
right: demonstrate effective disambiguation in an
unsupervised model. Specifically, show that tag
ging accuracy decreases when the model&apos;s dis
ambiguation capacity is removed, by re labeling
all tokens with their modal label, defined above.
We believe that the SVD2 algorithm presented
here could provide a launching pad for an ap
proach that would successfully address the dis
ambiguation challenge. It would do so by allow
ing a gradual and carefully controlled amount of
ambiguity into an initially non disambiguating
model. This is left for future work.
Fine-grained labeling. An important feature of
the SVD2 algorithm is its ability to produce a
fine grained labeling of the data, using a number
of clusters much larger than the number of tags
</bodyText>
<page confidence="0.994862">
218
</page>
<bodyText confidence="0.999769366666667">
in a syntax motivated POS tag system. Such
fine grained labelings can capture additional lin
guistic features. To achieve a fine grained labe
ling, only the final clustering step in the SVD2
algorithm needs to be changed; the computation
al cost this entails is negligible. A high quality
fine grained labeling, such as achieved by the
SVD2 approach, may be of practical interest as
an input to various types of unsupervised gram
mar induction algorithms (Headden et al. 2008).
This application is left for future work.
Prototype-based tagging. One potentially im
portant practical application of a high quality
fine grained labeling is its use for languages
which lack any kind of annotated data. By first
applying the SVD2 algorithm, word types are
grouped together into a few hundred clusters.
Then, a prototype word is automatically ex
tracted from each cluster. This produces, in a
completely unsupervised way, a list of only a
few hundred words that need to be hand tagged
by an expert. The results shown in Fig. 1 indicate
that these prototype tags can then be used to tag
the entire corpus with only a minor decrease in
accuracy compared to the best M to 1 map—the
construction of which requires a fully annotated
corpus. Fig. 1 also indicates that, with only a few
hundred prototypes, the gap left between the ac
curacy thus achieved and the upper bound for
non disambiguating models is fairly small.
</bodyText>
<sectionHeader confidence="0.998539" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999115845070423">
Alexander Clark. 2000. Inducing syntactic categories
by context distribution clustering. In The Fourth
Conference on Natural Language Learning.
Alexander Clark. 2003. Combining distributional and
morphological information for part of speech in
duction. In 10th Conference of the European Chap-
ter of the Association for Computational Linguis-
tics, pages 59–66.
Michael Collins. 2002. Discriminative training me
thods for hidden markov models: Theory and expe
riments with perceptron algorithms. In Proceedings of
the ACL-02 conference on Empirical methods in
natural language processing – Volume 10.
Jianfeng Gao and Mark Johnson. 2008. A comparison
of bayesian estimators for unsupervised Hidden
Markov Model POS taggers. In Proceedings of the
2008 Conference on Empirical Methods in Natural
Language Processing, pages 344–352.
Stuart Geman, Elie Bienenstock and René Doursat.
1992. Neural Networks and the Bias/Variance Di
lemma. Neural Computation, 4 (1), pages 1–58.
Sharon Goldwater and Tom Griffiths. 2007. A fully
Bayesian approach to unsupervised part of speech
tagging. In Proceedings of the 45th Annual Meet-
ing of the Association of Computational Linguis-
tics, pages 744–751.
João V. Graça, Kuzman Ganchev, Ben Taskar, and
Fernando Pereira. 2009. Posterior vs. Parameter
Sparsity in Latent Variable Models. In Neural In
formation Processing Systems Conference (NIPS).
Aria Haghighi and Dan Klein. 2006. Prototype driven
learning for sequence models. In Proceedings of
the Human Language Technology Conference of
the NAACL, Main Conference, pages 320–327,
New York City, USA, June. Association for Com
putational Linguistics.
William P. Headden, David McClosky, and Eugene
Charniak. 2008. Evaluating unsupervised part of
speech tagging for grammar induction. In Proceed-
ings of the International Conference on Computa-
tional Linguistics (COLING &apos;08).
Mark Johnson. 2007. Why doesn’t EM find good
HMM POS taggers? In Proceedings of the 2007
Joint Conference on Empirical Methods in Natural
Language Processing and Computational Natural
Language Learning (EMNLP CoNLL), pages 296–
305.
Marina Meilă. 2003. Comparing clusterings by the
variation of information. In Bernhard Schölkopf
and Manfred K. Warmuth, editors, COLT 2003:
The Sixteenth Annual Conference on Learning
Theory, volume 2777 of Lecture Notes in Comput-
er Science, pages 173–187. Springer.
Roi Reichart and Ari Rappoport. 2009. The NVI
Clustering Evaluation Measure. In Proceedings of
the Thirteenth Conference on Computational Natu-
ral Language Learning (CoNLL), pages 165–173.
Hinrich Schütze. 1995. Distributional part of speech
tagging. In Proceedings of the seventh conference
on European chapter of the Association for Com
putational Linguistics, pages 141–148.
Noah A. Smith and Jason Eisner. 2005. Contrastive
estimation: Training log linear models on unla
beled data. In Proceedings of the 43rd Annual
Meeting of the Association for Computational Lin-
guistics (ACL&apos;05), pages 354–362.
Kristina Toutanova, Dan Klein, Christopher D. Man
ning and Yoram Singer. 2003. Feature rich part of
speech tagging with a cyclic dependency network.
In Proceedings of HLT-NAACL 2003, pages 252
259.
</reference>
<page confidence="0.999214">
219
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.966848">
<title confidence="0.999767">SVD and Clustering for Unsupervised POS Tagging</title>
<author confidence="0.999615">Michael Lamar</author>
<affiliation confidence="0.9998265">Division of Applied Mathematics Brown University</affiliation>
<address confidence="0.99018">Providence, RI, USA</address>
<email confidence="0.999784">mlamar@dam.brown.edu</email>
<author confidence="0.999996">Mark Johnson</author>
<affiliation confidence="0.999883">Department of Computing Faculty of Science Macquarie University</affiliation>
<address confidence="0.987962">Sydney, Australia</address>
<email confidence="0.99862">mjohnson@science.mq.edu.au</email>
<abstract confidence="0.999316846153846">We revisit the algorithm of Schütze (1995) for unsupervised part of speech tagging. The algorithm uses reduced rank singular value decomposition followed by clustering to extract latent features from context distributions. As imple mented here, it achieves state of the art tagging accuracy at considerably less cost than more recent methods. It can also produce a range of finer grained tag gings, with potential applications to vari ous tasks.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alexander Clark</author>
</authors>
<title>Inducing syntactic categories by context distribution clustering.</title>
<date>2000</date>
<booktitle>In The Fourth Conference on Natural Language Learning.</booktitle>
<contexts>
<context position="1256" citStr="Clark (2000)" startWordPosition="183" endWordPosition="184">ce a range of finer grained tag gings, with potential applications to vari ous tasks. 1 Introduction While supervised approaches are able to solve the part of speech (POS) tagging problem with over 97% accuracy (Collins 2002; Toutanova et al. 2003), unsupervised algorithms perform con siderably less well. These models attempt to tag text without resources such as an annotated cor pus, a dictionary, etc. The use of singular value decomposition (SVD) for this problem was in troduced in Schütze (1995). Subsequently, a number of methods for POS tagging without a dictionary were examined, e.g., by Clark (2000), Clark (2003), Haghighi and Klein (2006), John son (2007), Goldwater and Griffiths (2007), Gao and Johnson (2008), and Graça et al. (2009). The latter two, using Hidden Markov Models (HMMs), exhibit the highest performances to * These authors contributed equally. Yariv Maron* Gonda Brain Research Center Bar Ilan University Ramat Gan, Israel syarivm@yahoo.com Elie Bienenstock Division of Applied Mathematics and Department of Neuroscience Brown University Providence, RI, USA elie@brown.edu date for fully unsupervised POS tagging. The revisited SVD based approach presented here, which we call “t</context>
</contexts>
<marker>Clark, 2000</marker>
<rawString>Alexander Clark. 2000. Inducing syntactic categories by context distribution clustering. In The Fourth Conference on Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Clark</author>
</authors>
<title>Combining distributional and morphological information for part of speech in duction.</title>
<date>2003</date>
<booktitle>In 10th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>59--66</pages>
<contexts>
<context position="1270" citStr="Clark (2003)" startWordPosition="185" endWordPosition="186">finer grained tag gings, with potential applications to vari ous tasks. 1 Introduction While supervised approaches are able to solve the part of speech (POS) tagging problem with over 97% accuracy (Collins 2002; Toutanova et al. 2003), unsupervised algorithms perform con siderably less well. These models attempt to tag text without resources such as an annotated cor pus, a dictionary, etc. The use of singular value decomposition (SVD) for this problem was in troduced in Schütze (1995). Subsequently, a number of methods for POS tagging without a dictionary were examined, e.g., by Clark (2000), Clark (2003), Haghighi and Klein (2006), John son (2007), Goldwater and Griffiths (2007), Gao and Johnson (2008), and Graça et al. (2009). The latter two, using Hidden Markov Models (HMMs), exhibit the highest performances to * These authors contributed equally. Yariv Maron* Gonda Brain Research Center Bar Ilan University Ramat Gan, Israel syarivm@yahoo.com Elie Bienenstock Division of Applied Mathematics and Department of Neuroscience Brown University Providence, RI, USA elie@brown.edu date for fully unsupervised POS tagging. The revisited SVD based approach presented here, which we call “two step SVD” o</context>
</contexts>
<marker>Clark, 2003</marker>
<rawString>Alexander Clark. 2003. Combining distributional and morphological information for part of speech in duction. In 10th Conference of the European Chapter of the Association for Computational Linguistics, pages 59–66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training me thods for hidden markov models: Theory and expe riments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 conference on Empirical methods in natural language processing – Volume</booktitle>
<volume>10</volume>
<contexts>
<context position="868" citStr="Collins 2002" startWordPosition="122" endWordPosition="123">@science.mq.edu.au Abstract We revisit the algorithm of Schütze (1995) for unsupervised part of speech tagging. The algorithm uses reduced rank singular value decomposition followed by clustering to extract latent features from context distributions. As imple mented here, it achieves state of the art tagging accuracy at considerably less cost than more recent methods. It can also produce a range of finer grained tag gings, with potential applications to vari ous tasks. 1 Introduction While supervised approaches are able to solve the part of speech (POS) tagging problem with over 97% accuracy (Collins 2002; Toutanova et al. 2003), unsupervised algorithms perform con siderably less well. These models attempt to tag text without resources such as an annotated cor pus, a dictionary, etc. The use of singular value decomposition (SVD) for this problem was in troduced in Schütze (1995). Subsequently, a number of methods for POS tagging without a dictionary were examined, e.g., by Clark (2000), Clark (2003), Haghighi and Klein (2006), John son (2007), Goldwater and Griffiths (2007), Gao and Johnson (2008), and Graça et al. (2009). The latter two, using Hidden Markov Models (HMMs), exhibit the highest </context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative training me thods for hidden markov models: Theory and expe riments with perceptron algorithms. In Proceedings of the ACL-02 conference on Empirical methods in natural language processing – Volume 10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianfeng Gao</author>
<author>Mark Johnson</author>
</authors>
<title>A comparison of bayesian estimators for unsupervised Hidden Markov Model POS taggers.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>344--352</pages>
<contexts>
<context position="1370" citStr="Gao and Johnson (2008)" startWordPosition="198" endWordPosition="201">le supervised approaches are able to solve the part of speech (POS) tagging problem with over 97% accuracy (Collins 2002; Toutanova et al. 2003), unsupervised algorithms perform con siderably less well. These models attempt to tag text without resources such as an annotated cor pus, a dictionary, etc. The use of singular value decomposition (SVD) for this problem was in troduced in Schütze (1995). Subsequently, a number of methods for POS tagging without a dictionary were examined, e.g., by Clark (2000), Clark (2003), Haghighi and Klein (2006), John son (2007), Goldwater and Griffiths (2007), Gao and Johnson (2008), and Graça et al. (2009). The latter two, using Hidden Markov Models (HMMs), exhibit the highest performances to * These authors contributed equally. Yariv Maron* Gonda Brain Research Center Bar Ilan University Ramat Gan, Israel syarivm@yahoo.com Elie Bienenstock Division of Applied Mathematics and Department of Neuroscience Brown University Providence, RI, USA elie@brown.edu date for fully unsupervised POS tagging. The revisited SVD based approach presented here, which we call “two step SVD” or SVD2, has four important characteristics. First, it achieves state of the art tagging accuracy. Se</context>
<context position="6178" citStr="Gao and Johnson (2008)" startWordPosition="1030" endWordPosition="1033">criptors of the k most frequent words in the cor pus. The final tag of any token in the corpus is the cluster number of its type. 3 Data and Evaluation We ran the SVD2 algorithm described above on the full Wall Street Journal part of the Penn Treebank (1,173,766 tokens). Capitalization was ignored, resulting in Nypes = 43,766, with only a minor effect on accuracy. Evaluation was done against the POS tag annotations of the 45 tag PTB tagset (hereafter PTB45), and against the Smith and Eisner (2005) coarse version of the PTB tagset (hereafter PTB17). We selected the three evaluation criteria of Gao and Johnson (2008): M to 1, 1 to 1, and VI. M to 1 and 1 to 1 are the tagging accuracies under the best many to one map and the greedy one to one map re spectively; VI is a map free information theoretic criterion—see Gao and Johnson (2008) for details. Although we find M to 1 to be the most reliable criterion of the three, we include the other two criteria for completeness. In addition to the best M to 1 map, we also employ here, for large values of k2, a prototypebased M to 1 map. To construct this map, we first find, for each induced tag t, the word type with which it co occurs most frequently; we call this </context>
<context position="7449" citStr="Gao and Johnson (2008)" startWordPosition="1277" endWordPosition="1280">nnotated data for the most common gold tag for each prototype, and we map induced tag t to this gold tag. This prototype based M to 1 map produces accuracy scores no greater—typically lower—than the best M to 1 map. We discuss the value of this approach as a minimally supervised post processing step in Section 5. 4 Results Low-k performance. Here we present the per formance of the SVD2 model when k2, the num ber of induced tags, is the same or roughly the same as the number of tags in the gold stan dard—hence small. Table 1 compares the per formance of SVD2 to other leading models. Fol lowing Gao and Johnson (2008), the number of induced tags is 17 for PTB17 evaluation and 50 for PTB45 evaluation. Thus, with the exception of Graça et al. (2009) who use 45 induced tags for PTB45, the number of induced tags is the same across each column of Table 1. Next, both context matrices are factored using singular value decomposition: L = UL SL VLT R = UR SR VRT. The diagonal matrices SL and SR (each of rank 1000) are reduced down to rank r1 = 100 by re placing the 900 smallest singular values in each matrix with zeros, yielding SL* and SR*. We then form a pair of latent descriptor matrices defined by: 216 M-to-1 1</context>
<context position="9638" citStr="Gao and Johnson 2008" startWordPosition="1682" endWordPosition="1685"> corres ponding to the VI scores for SVD2 are 0.938 for PTB17 and 0.885 for PTB45. To examine the sensitivity of the algorithm to its four parameters, w1, r1, k1, and r2, we changed each of these para meters separately by a multiplicative factor of either 0.5 or 2; in neither case did M to 1 accura cy drop by more than 0.014. This performance was achieved despite the fact that the SVD2 tagger is mathematically much simpler than the other models. Our MAT LAB implementation of SVD2 takes only a few minutes to run on a desktop computer, in contrast to HMM training times of several hours or days (Gao and Johnson 2008; Johnson 2007). High-k performance. Not suffering from the same computational limitations as other models, SVD2 can easily accommodate high numbers of induced tags, resulting in fine grained labelings. The value of this flexibility is discussed in the next section. Figure 1 shows, as a function of k2, the tagging accuracy of SVD2 under both the best and the prototype based M to 1 maps (see Section 3), for both the PTB45 and the PTB17 tagsets. The horizontal one tag per word type line in each panel is the theoretical upper limit for tagging accuracy in non disambiguating models (such as SVD2).</context>
<context position="13998" citStr="Gao and Johnson 2008" startWordPosition="2422" endWordPosition="2425">of SVD2 is that it is a non disambiguating tagger, assigning the same label to all tokens of a type. However, this limitation per se is unlikely to be the main obstacle to the improvement of low k performance, since, as is well known, the theo retical upper limit for the tagging accuracy of non disambiguating models (shown in Fig. 1) is much higher than the current state of the art for unsupervised taggers, whether disambiguating or not. To further gain insight into how successful current models are at disambiguating when they have the power to do so, we examined a collec tion of HMM VB runs (Gao and Johnson 2008) and asked how the accuracy scores would change if, after training was completed, the model were forced to assign the same label to all tokens of the same type. To answer this question, we de termined, for each word type, the modal HMM state, i.e., the state most frequently assigned by the HMM to tokens of that type. We then re labeled all words with their modal label. The ef fect of thus eliminating the disambiguation ca pacity of the model was to slightly increase the tagging accuracy under the best M to 1 map for every HMM VB run (the average increase was 0.026 for PTB17, and 0.015 for PTB4</context>
</contexts>
<marker>Gao, Johnson, 2008</marker>
<rawString>Jianfeng Gao and Mark Johnson. 2008. A comparison of bayesian estimators for unsupervised Hidden Markov Model POS taggers. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 344–352.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Geman</author>
<author>Elie Bienenstock</author>
<author>René Doursat</author>
</authors>
<date>1992</date>
<booktitle>Neural Networks and the Bias/Variance Di lemma. Neural Computation,</booktitle>
<volume>4</volume>
<issue>1</issue>
<pages>1--58</pages>
<contexts>
<context position="14996" citStr="Geman et al. 1992" startWordPosition="2598" endWordPosition="2601">ect of thus eliminating the disambiguation ca pacity of the model was to slightly increase the tagging accuracy under the best M to 1 map for every HMM VB run (the average increase was 0.026 for PTB17, and 0.015 for PTB45). We view this as a further indication that, in the cur rent state of the art and with regards to tagging accuracy, limiting oneself to non disambiguating models may not adversely affect performance. To the contrary, this limitation may actually benefit an approach such as SVD2. Indeed, on difficult learning tasks, simpler models often be have better than more powerful ones (Geman et al. 1992). HMMs are powerful since they can, in theory, induce both a system of tags and a system of contextual patterns that allow them to disam biguate word types in terms of these tags. How ever, carrying out both of these unsupervised learning tasks at once is problematic in view of the very large number of parameters to be esti mated compared to the size of the training data set. The POS tagging subtask of disambiguation may then be construed as a challenge in its own right: demonstrate effective disambiguation in an unsupervised model. Specifically, show that tag ging accuracy decreases when the </context>
</contexts>
<marker>Geman, Bienenstock, Doursat, 1992</marker>
<rawString>Stuart Geman, Elie Bienenstock and René Doursat. 1992. Neural Networks and the Bias/Variance Di lemma. Neural Computation, 4 (1), pages 1–58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon Goldwater</author>
<author>Tom Griffiths</author>
</authors>
<title>A fully Bayesian approach to unsupervised part of speech tagging.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>744--751</pages>
<contexts>
<context position="1346" citStr="Goldwater and Griffiths (2007)" startWordPosition="194" endWordPosition="197">ri ous tasks. 1 Introduction While supervised approaches are able to solve the part of speech (POS) tagging problem with over 97% accuracy (Collins 2002; Toutanova et al. 2003), unsupervised algorithms perform con siderably less well. These models attempt to tag text without resources such as an annotated cor pus, a dictionary, etc. The use of singular value decomposition (SVD) for this problem was in troduced in Schütze (1995). Subsequently, a number of methods for POS tagging without a dictionary were examined, e.g., by Clark (2000), Clark (2003), Haghighi and Klein (2006), John son (2007), Goldwater and Griffiths (2007), Gao and Johnson (2008), and Graça et al. (2009). The latter two, using Hidden Markov Models (HMMs), exhibit the highest performances to * These authors contributed equally. Yariv Maron* Gonda Brain Research Center Bar Ilan University Ramat Gan, Israel syarivm@yahoo.com Elie Bienenstock Division of Applied Mathematics and Department of Neuroscience Brown University Providence, RI, USA elie@brown.edu date for fully unsupervised POS tagging. The revisited SVD based approach presented here, which we call “two step SVD” or SVD2, has four important characteristics. First, it achieves state of the </context>
</contexts>
<marker>Goldwater, Griffiths, 2007</marker>
<rawString>Sharon Goldwater and Tom Griffiths. 2007. A fully Bayesian approach to unsupervised part of speech tagging. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 744–751.</rawString>
</citation>
<citation valid="true">
<authors>
<author>João V Graça</author>
<author>Kuzman Ganchev</author>
<author>Ben Taskar</author>
<author>Fernando Pereira</author>
</authors>
<title>Posterior vs. Parameter Sparsity in Latent Variable Models.</title>
<date>2009</date>
<booktitle>In Neural In formation Processing Systems Conference (NIPS).</booktitle>
<contexts>
<context position="1395" citStr="Graça et al. (2009)" startWordPosition="203" endWordPosition="206"> able to solve the part of speech (POS) tagging problem with over 97% accuracy (Collins 2002; Toutanova et al. 2003), unsupervised algorithms perform con siderably less well. These models attempt to tag text without resources such as an annotated cor pus, a dictionary, etc. The use of singular value decomposition (SVD) for this problem was in troduced in Schütze (1995). Subsequently, a number of methods for POS tagging without a dictionary were examined, e.g., by Clark (2000), Clark (2003), Haghighi and Klein (2006), John son (2007), Goldwater and Griffiths (2007), Gao and Johnson (2008), and Graça et al. (2009). The latter two, using Hidden Markov Models (HMMs), exhibit the highest performances to * These authors contributed equally. Yariv Maron* Gonda Brain Research Center Bar Ilan University Ramat Gan, Israel syarivm@yahoo.com Elie Bienenstock Division of Applied Mathematics and Department of Neuroscience Brown University Providence, RI, USA elie@brown.edu date for fully unsupervised POS tagging. The revisited SVD based approach presented here, which we call “two step SVD” or SVD2, has four important characteristics. First, it achieves state of the art tagging accuracy. Second, it requires drastic</context>
<context position="7581" citStr="Graça et al. (2009)" startWordPosition="1301" endWordPosition="1304">ap produces accuracy scores no greater—typically lower—than the best M to 1 map. We discuss the value of this approach as a minimally supervised post processing step in Section 5. 4 Results Low-k performance. Here we present the per formance of the SVD2 model when k2, the num ber of induced tags, is the same or roughly the same as the number of tags in the gold stan dard—hence small. Table 1 compares the per formance of SVD2 to other leading models. Fol lowing Gao and Johnson (2008), the number of induced tags is 17 for PTB17 evaluation and 50 for PTB45 evaluation. Thus, with the exception of Graça et al. (2009) who use 45 induced tags for PTB45, the number of induced tags is the same across each column of Table 1. Next, both context matrices are factored using singular value decomposition: L = UL SL VLT R = UR SR VRT. The diagonal matrices SL and SR (each of rank 1000) are reduced down to rank r1 = 100 by re placing the 900 smallest singular values in each matrix with zeros, yielding SL* and SR*. We then form a pair of latent descriptor matrices defined by: 216 M-to-1 1-to-1 VI Model PTB17 PTB45 PTB17 PTB45 PTB17 PTB45 SVD2 0.730 0.660 0.513 0.467 3.02 3.84 HMM EM 0.647 0.621 0.431 0.405 3.86 4.48 H</context>
<context position="8858" citStr="Graça et al. (2009)" startWordPosition="1538" endWordPosition="1541"> 0.466 0.499 3.46 4.04 HMM Sparse(32) 0.702(2.2) 0.654(1.0) 0.495 0.445 VEM (10 1,10 1) 0.682(0.8) 0.546(1.7) 0.528 0.460 Table 1. Tagging accuracy under the best M to 1 map, the greedy 1 to 1 map, and VI, for the full PTB45 tagset and the reduced PTB17 tagset. HMM EM, HMM VB and HMM GS show the best results from Gao and Johnson (2008); HMM Sparse(32) and VEM (10 1,10 1) show the best results from Graça et al. (2009). The performance of SVD2 compares favora bly to the HMM models. Note that SVD2 is a deterministic algorithm. The table shows, in pa rentheses, the standard deviations reported in Graça et al. (2009). For the sake of comparison with Graça et al. (2009), we also note that, with k2 = 45, SVD2 scores 0.659 on PTB45. The NVI scores (Reichart and Rappoport 2009) corres ponding to the VI scores for SVD2 are 0.938 for PTB17 and 0.885 for PTB45. To examine the sensitivity of the algorithm to its four parameters, w1, r1, k1, and r2, we changed each of these para meters separately by a multiplicative factor of either 0.5 or 2; in neither case did M to 1 accura cy drop by more than 0.014. This performance was achieved despite the fact that the SVD2 tagger is mathematically much simpler than the othe</context>
</contexts>
<marker>Graça, Ganchev, Taskar, Pereira, 2009</marker>
<rawString>João V. Graça, Kuzman Ganchev, Ben Taskar, and Fernando Pereira. 2009. Posterior vs. Parameter Sparsity in Latent Variable Models. In Neural In formation Processing Systems Conference (NIPS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Dan Klein</author>
</authors>
<title>Prototype driven learning for sequence models.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference,</booktitle>
<pages>320--327</pages>
<location>New York City, USA,</location>
<contexts>
<context position="1297" citStr="Haghighi and Klein (2006)" startWordPosition="187" endWordPosition="190">tag gings, with potential applications to vari ous tasks. 1 Introduction While supervised approaches are able to solve the part of speech (POS) tagging problem with over 97% accuracy (Collins 2002; Toutanova et al. 2003), unsupervised algorithms perform con siderably less well. These models attempt to tag text without resources such as an annotated cor pus, a dictionary, etc. The use of singular value decomposition (SVD) for this problem was in troduced in Schütze (1995). Subsequently, a number of methods for POS tagging without a dictionary were examined, e.g., by Clark (2000), Clark (2003), Haghighi and Klein (2006), John son (2007), Goldwater and Griffiths (2007), Gao and Johnson (2008), and Graça et al. (2009). The latter two, using Hidden Markov Models (HMMs), exhibit the highest performances to * These authors contributed equally. Yariv Maron* Gonda Brain Research Center Bar Ilan University Ramat Gan, Israel syarivm@yahoo.com Elie Bienenstock Division of Applied Mathematics and Department of Neuroscience Brown University Providence, RI, USA elie@brown.edu date for fully unsupervised POS tagging. The revisited SVD based approach presented here, which we call “two step SVD” or SVD2, has four important </context>
</contexts>
<marker>Haghighi, Klein, 2006</marker>
<rawString>Aria Haghighi and Dan Klein. 2006. Prototype driven learning for sequence models. In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference, pages 320–327, New York City, USA, June. Association for Com putational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William P Headden</author>
<author>David McClosky</author>
<author>Eugene Charniak</author>
</authors>
<title>Evaluating unsupervised part of speech tagging for grammar induction.</title>
<date>2008</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics (COLING &apos;08).</booktitle>
<contexts>
<context position="16695" citStr="Headden et al. 2008" startWordPosition="2882" endWordPosition="2885">VD2 algorithm is its ability to produce a fine grained labeling of the data, using a number of clusters much larger than the number of tags 218 in a syntax motivated POS tag system. Such fine grained labelings can capture additional lin guistic features. To achieve a fine grained labe ling, only the final clustering step in the SVD2 algorithm needs to be changed; the computation al cost this entails is negligible. A high quality fine grained labeling, such as achieved by the SVD2 approach, may be of practical interest as an input to various types of unsupervised gram mar induction algorithms (Headden et al. 2008). This application is left for future work. Prototype-based tagging. One potentially im portant practical application of a high quality fine grained labeling is its use for languages which lack any kind of annotated data. By first applying the SVD2 algorithm, word types are grouped together into a few hundred clusters. Then, a prototype word is automatically ex tracted from each cluster. This produces, in a completely unsupervised way, a list of only a few hundred words that need to be hand tagged by an expert. The results shown in Fig. 1 indicate that these prototype tags can then be used to </context>
</contexts>
<marker>Headden, McClosky, Charniak, 2008</marker>
<rawString>William P. Headden, David McClosky, and Eugene Charniak. 2008. Evaluating unsupervised part of speech tagging for grammar induction. In Proceedings of the International Conference on Computational Linguistics (COLING &apos;08).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
</authors>
<title>Why doesn’t EM find good HMM POS taggers?</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP CoNLL),</booktitle>
<pages>296--305</pages>
<contexts>
<context position="9653" citStr="Johnson 2007" startWordPosition="1686" endWordPosition="1687"> VI scores for SVD2 are 0.938 for PTB17 and 0.885 for PTB45. To examine the sensitivity of the algorithm to its four parameters, w1, r1, k1, and r2, we changed each of these para meters separately by a multiplicative factor of either 0.5 or 2; in neither case did M to 1 accura cy drop by more than 0.014. This performance was achieved despite the fact that the SVD2 tagger is mathematically much simpler than the other models. Our MAT LAB implementation of SVD2 takes only a few minutes to run on a desktop computer, in contrast to HMM training times of several hours or days (Gao and Johnson 2008; Johnson 2007). High-k performance. Not suffering from the same computational limitations as other models, SVD2 can easily accommodate high numbers of induced tags, resulting in fine grained labelings. The value of this flexibility is discussed in the next section. Figure 1 shows, as a function of k2, the tagging accuracy of SVD2 under both the best and the prototype based M to 1 maps (see Section 3), for both the PTB45 and the PTB17 tagsets. The horizontal one tag per word type line in each panel is the theoretical upper limit for tagging accuracy in non disambiguating models (such as SVD2). This limit is </context>
</contexts>
<marker>Johnson, 2007</marker>
<rawString>Mark Johnson. 2007. Why doesn’t EM find good HMM POS taggers? In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP CoNLL), pages 296– 305.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marina Meilă</author>
</authors>
<title>Comparing clusterings by the variation of information.</title>
<date>2003</date>
<booktitle>COLT 2003: The Sixteenth Annual Conference on Learning Theory,</booktitle>
<volume>2777</volume>
<pages>173--187</pages>
<editor>In Bernhard Schölkopf and Manfred K. Warmuth, editors,</editor>
<publisher>Springer.</publisher>
<marker>Meilă, 2003</marker>
<rawString>Marina Meilă. 2003. Comparing clusterings by the variation of information. In Bernhard Schölkopf and Manfred K. Warmuth, editors, COLT 2003: The Sixteenth Annual Conference on Learning Theory, volume 2777 of Lecture Notes in Computer Science, pages 173–187. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roi Reichart</author>
<author>Ari Rappoport</author>
</authors>
<title>The NVI Clustering Evaluation Measure.</title>
<date>2009</date>
<booktitle>In Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL),</booktitle>
<pages>165--173</pages>
<contexts>
<context position="9018" citStr="Reichart and Rappoport 2009" startWordPosition="1568" endWordPosition="1571">er the best M to 1 map, the greedy 1 to 1 map, and VI, for the full PTB45 tagset and the reduced PTB17 tagset. HMM EM, HMM VB and HMM GS show the best results from Gao and Johnson (2008); HMM Sparse(32) and VEM (10 1,10 1) show the best results from Graça et al. (2009). The performance of SVD2 compares favora bly to the HMM models. Note that SVD2 is a deterministic algorithm. The table shows, in pa rentheses, the standard deviations reported in Graça et al. (2009). For the sake of comparison with Graça et al. (2009), we also note that, with k2 = 45, SVD2 scores 0.659 on PTB45. The NVI scores (Reichart and Rappoport 2009) corres ponding to the VI scores for SVD2 are 0.938 for PTB17 and 0.885 for PTB45. To examine the sensitivity of the algorithm to its four parameters, w1, r1, k1, and r2, we changed each of these para meters separately by a multiplicative factor of either 0.5 or 2; in neither case did M to 1 accura cy drop by more than 0.014. This performance was achieved despite the fact that the SVD2 tagger is mathematically much simpler than the other models. Our MAT LAB implementation of SVD2 takes only a few minutes to run on a desktop computer, in contrast to HMM training times of several hours or days (</context>
</contexts>
<marker>Reichart, Rappoport, 2009</marker>
<rawString>Roi Reichart and Ari Rappoport. 2009. The NVI Clustering Evaluation Measure. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL), pages 165–173.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Schütze</author>
</authors>
<title>Distributional part of speech tagging.</title>
<date>1995</date>
<booktitle>In Proceedings of the seventh conference on European chapter of the Association for Com putational Linguistics,</booktitle>
<pages>141--148</pages>
<contexts>
<context position="1147" citStr="Schütze (1995)" startWordPosition="166" endWordPosition="167">chieves state of the art tagging accuracy at considerably less cost than more recent methods. It can also produce a range of finer grained tag gings, with potential applications to vari ous tasks. 1 Introduction While supervised approaches are able to solve the part of speech (POS) tagging problem with over 97% accuracy (Collins 2002; Toutanova et al. 2003), unsupervised algorithms perform con siderably less well. These models attempt to tag text without resources such as an annotated cor pus, a dictionary, etc. The use of singular value decomposition (SVD) for this problem was in troduced in Schütze (1995). Subsequently, a number of methods for POS tagging without a dictionary were examined, e.g., by Clark (2000), Clark (2003), Haghighi and Klein (2006), John son (2007), Goldwater and Griffiths (2007), Gao and Johnson (2008), and Graça et al. (2009). The latter two, using Hidden Markov Models (HMMs), exhibit the highest performances to * These authors contributed equally. Yariv Maron* Gonda Brain Research Center Bar Ilan University Ramat Gan, Israel syarivm@yahoo.com Elie Bienenstock Division of Applied Mathematics and Department of Neuroscience Brown University Providence, RI, USA elie@brown.e</context>
<context position="2639" citStr="Schütze (1995)" startWordPosition="388" endWordPosition="389"> than the best currently available models. Third, it demonstrates that state of the art accu racy can be realized without disambiguation, i.e., without attempting to assign different tags to dif ferent tokens of the same type. Finally, with no significant increase in computational cost, SVD2 can create much finer grained labelings than typ ically produced by other algorithms. When com bined with some minimal supervision in post processing, this makes the approach useful for tagging languages that lack the resources re quired by fully supervised models. 2 Methods Following the original work of Schütze (1995), we begin by constructing a right context matrix, R, and a left context matrix, L. R,ij counts the number of times in the corpus a token of word type i is immediately followed by a token of word type j. Similarly, L,ij counts the number of times a token of type i is preceded by a token of type j. We truncate these matrices, including, in the right and left contexts, only the w1 most fre quent word types. The resulting L and R are of dimension Ntypesxw1, where Nypes is the number of word types (spelling forms) in the corpus, and w1 is set to 1000. (The full Ntypesx Ntypes context matrices sati</context>
<context position="10452" citStr="Schütze (1995)" startWordPosition="1825" endWordPosition="1826">s. The value of this flexibility is discussed in the next section. Figure 1 shows, as a function of k2, the tagging accuracy of SVD2 under both the best and the prototype based M to 1 maps (see Section 3), for both the PTB45 and the PTB17 tagsets. The horizontal one tag per word type line in each panel is the theoretical upper limit for tagging accuracy in non disambiguating models (such as SVD2). This limit is the fraction of all tokens in the corpus whose gold tag is the most frequent for their type. 5 Discussion At the heart of the algorithm presented here is the reduced rank SVD method of Schütze (1995), which transforms bigram counts into la tent descriptors. In view of the present work, Figure 1. Performance of the SVD2 algo rithm as a function of the number of induced tags. Top: PTB45; bottom: PTB17. Each plot shows the tagging accuracy under the best and the prototype based M to 1 maps, as well as the upper limit for non disambiguating taggers. which achieves state of the art performance when evaluation is done with the criteria now in common use, Schütze&apos;s original work should rightly be praised as ahead of its time. The SVD2 model presented here differs from Schütze&apos;s work in many deta</context>
</contexts>
<marker>Schütze, 1995</marker>
<rawString>Hinrich Schütze. 1995. Distributional part of speech tagging. In Proceedings of the seventh conference on European chapter of the Association for Com putational Linguistics, pages 141–148.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noah A Smith</author>
<author>Jason Eisner</author>
</authors>
<title>Contrastive estimation: Training log linear models on unla beled data.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL&apos;05),</booktitle>
<pages>354--362</pages>
<contexts>
<context position="6058" citStr="Smith and Eisner (2005)" startWordPosition="1011" endWordPosition="1014"> tags. We use the same weighted k means algorithm as in the first pass, again placing the k initial centroids on the de scriptors of the k most frequent words in the cor pus. The final tag of any token in the corpus is the cluster number of its type. 3 Data and Evaluation We ran the SVD2 algorithm described above on the full Wall Street Journal part of the Penn Treebank (1,173,766 tokens). Capitalization was ignored, resulting in Nypes = 43,766, with only a minor effect on accuracy. Evaluation was done against the POS tag annotations of the 45 tag PTB tagset (hereafter PTB45), and against the Smith and Eisner (2005) coarse version of the PTB tagset (hereafter PTB17). We selected the three evaluation criteria of Gao and Johnson (2008): M to 1, 1 to 1, and VI. M to 1 and 1 to 1 are the tagging accuracies under the best many to one map and the greedy one to one map re spectively; VI is a map free information theoretic criterion—see Gao and Johnson (2008) for details. Although we find M to 1 to be the most reliable criterion of the three, we include the other two criteria for completeness. In addition to the best M to 1 map, we also employ here, for large values of k2, a prototypebased M to 1 map. To constru</context>
</contexts>
<marker>Smith, Eisner, 2005</marker>
<rawString>Noah A. Smith and Jason Eisner. 2005. Contrastive estimation: Training log linear models on unla beled data. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL&apos;05), pages 354–362.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Dan Klein</author>
<author>Christopher D Man ning</author>
<author>Yoram Singer</author>
</authors>
<title>Feature rich part of speech tagging with a cyclic dependency network.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL 2003,</booktitle>
<pages>252--259</pages>
<contexts>
<context position="892" citStr="Toutanova et al. 2003" startWordPosition="124" endWordPosition="127">u.au Abstract We revisit the algorithm of Schütze (1995) for unsupervised part of speech tagging. The algorithm uses reduced rank singular value decomposition followed by clustering to extract latent features from context distributions. As imple mented here, it achieves state of the art tagging accuracy at considerably less cost than more recent methods. It can also produce a range of finer grained tag gings, with potential applications to vari ous tasks. 1 Introduction While supervised approaches are able to solve the part of speech (POS) tagging problem with over 97% accuracy (Collins 2002; Toutanova et al. 2003), unsupervised algorithms perform con siderably less well. These models attempt to tag text without resources such as an annotated cor pus, a dictionary, etc. The use of singular value decomposition (SVD) for this problem was in troduced in Schütze (1995). Subsequently, a number of methods for POS tagging without a dictionary were examined, e.g., by Clark (2000), Clark (2003), Haghighi and Klein (2006), John son (2007), Goldwater and Griffiths (2007), Gao and Johnson (2008), and Graça et al. (2009). The latter two, using Hidden Markov Models (HMMs), exhibit the highest performances to * These </context>
</contexts>
<marker>Toutanova, Klein, ning, Singer, 2003</marker>
<rawString>Kristina Toutanova, Dan Klein, Christopher D. Man ning and Yoram Singer. 2003. Feature rich part of speech tagging with a cyclic dependency network. In Proceedings of HLT-NAACL 2003, pages 252 259.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>