<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000860">
<title confidence="0.911002">
Kernel-Based Pronoun Resolution with Structured Syntactic Knowledge
</title>
<author confidence="0.971856">
Xiaofeng Yangt Jian Sut Chew Lim Tan$
</author>
<affiliation confidence="0.979534">
tInstitute for Infocomm Research
</affiliation>
<address confidence="0.9792645">
21 Heng Mui Keng Terrace,
Singapore, 119613
</address>
<email confidence="0.962744">
Ixiaofengy,sujianl@i2r.a-star.edu.sg
</email>
<affiliation confidence="0.996322">
t Department of Computer Science
National University of Singapore,
</affiliation>
<address confidence="0.968013">
Singapore, 117543
</address>
<email confidence="0.990133">
tancl@comp.nus.edu.sg
</email>
<sectionHeader confidence="0.99486" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999295">
Syntactic knowledge is important for pro-
noun resolution. Traditionally, the syntac-
tic information for pronoun resolution is
represented in terms of features that have
to be selected and defined heuristically.
In the paper, we propose a kernel-based
method that can automatically mine the
syntactic information from the parse trees
for pronoun resolution. Specifically, we
utilize the parse trees directly as a struc-
tured feature and apply kernel functions to
this feature, as well as other normal fea-
tures, to learn the resolution classifier. In
this way, our approach avoids the efforts
of decoding the parse trees into the set of
flat syntactic features. The experimental
results show that our approach can bring
significant performance improvement and
is reliably effective for the pronoun reso-
lution task.
</bodyText>
<sectionHeader confidence="0.998118" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999881035714286">
Pronoun resolution is the task of finding the cor-
rect antecedent for a given pronominal anaphor
in a document. Prior studies have suggested that
syntactic knowledge plays an important role in
pronoun resolution. For a practical pronoun res-
olution system, the syntactic knowledge usually
comes from the parse trees of the text. The is-
sue that arises is how to effectively incorporate the
syntactic information embedded in the parse trees
to help resolution. One common solution seen in
previous work is to define a set of features that rep-
resent particular syntactic knowledge, such as the
grammatical role of the antecedent candidates, the
governing relations between the candidate and the
pronoun, and so on. These features are calculated
by mining the parse trees, and then could be used
for resolution by using manually designed rules
(Lappin and Leass, 1994; Kennedy and Boguraev,
1996; Mitkov, 1998), or using machine-learning
methods (Aone and Bennett, 1995; Yang et al.,
2004; Luo and Zitouni, 2005).
However, such a solution has its limitation. The
syntactic features have to be selected and defined
manually, usually by linguistic intuition. Unfor-
tunately, what kinds of syntactic information are
effective for pronoun resolution still remains an
open question in this research community. The
heuristically selected feature set may be insuffi-
cient to represent all the information necessary for
pronoun resolution contained in the parse trees.
In this paper we will explore how to utilize the
syntactic parse trees to help learning-based pro-
noun resolution. Specifically, we directly utilize
the parse trees as a structured feature, and then use
a kernel-based method to automatically mine the
knowledge embedded in the parse trees. The struc-
tured syntactic feature, together with other nor-
mal features, is incorporated in a trainable model
based on Support Vector Machine (SVM) (Vapnik,
1995) to learn the decision classifier for resolution.
Indeed, using kernel methods to mine structural
knowledge has shown success in some NLP ap-
plications like parsing (Collins and Duffy, 2002;
Moschitti, 2004) and relation extraction (Zelenko
et al., 2003; Zhao and Grishman, 2005). However,
to our knowledge, the application of such a tech-
nique to the pronoun resolution task still remains
unexplored.
Compared with previous work, our approach
has several advantages: (1) The approach uti-
lizes the parse trees as a structured feature, which
avoids the efforts of decoding the parse trees into
a set of syntactic features in a heuristic manner.
(2) The approach is able to put together the struc-
tured feature and the normal flat features in a
trainable model, which allows different types of
</bodyText>
<page confidence="0.753773">
41
</page>
<note confidence="0.8325175">
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 41–48,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.99976124">
information to be considered in combination for
both learning and resolution. (3) The approach
is applicable for practical pronoun resolution as
the syntactic information can be automatically ob-
tained from machine-generated parse trees. And
our study shows that the approach works well un-
der the commonly available parsers.
We evaluate our approach on the ACE data set.
The experimental results over the different do-
mains indicate that the structured syntactic fea-
ture incorporated with kernels can significantly
improve the resolution performance (by 5%-8%
in the success rates), and is reliably effective for
the pronoun resolution task.
The remainder of the paper is organized as fol-
lows. Section 2 gives some related work that uti-
lizes the structured syntactic knowledge to do pro-
noun resolution. Section 3 introduces the frame-
work for the pronoun resolution, as well as the
baseline feature space and the SVM classifier.
Section 4 presents in detail the structured feature
and the kernel functions to incorporate such a fea-
ture in the resolution. Section 5 shows the exper-
imental results and has some discussion. Finally,
Section 6 concludes the paper.
</bodyText>
<sectionHeader confidence="0.999786" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.998663818181818">
One of the early work on pronoun resolution rely-
ing on parse trees was proposed by Hobbs (1978).
For a pronoun to be resolved, Hobbs’ algorithm
works by searching the parse trees of the current
text. Specifically, the algorithm processes one sen-
tence at a time, using a left-to-right breadth-first
searching strategy. It first checks the current sen-
tence where the pronoun occurs. The first NP
that satisfies constraints, like number and gender
agreements, would be selected as the antecedent.
If the antecedent is not found in the current sen-
tence, the algorithm would traverse the trees of
previous sentences in the text. As the searching
processing is completely done on the parse trees,
the performance of the algorithm would rely heav-
ily on the accuracy of the parsing results.
Lappin and Leass (1994) reported a pronoun
resolution algorithm which uses the syntactic rep-
resentation output by McCord’s Slot Grammar
parser. A set of salience measures (e.g. Sub-
ject, Object or Accusative emphasis) is derived
from the syntactic structure. The candidate with
the highest salience score would be selected as
the antecedent. In their algorithm, the weights of
Category: whether the candidate is a definite noun phrase,
indefinite noun phrase, pronoun, named-entity or others.
Reflexiveness: whether the pronominal anaphor is a reflex-
ive pronoun.
Type: whether the pronominal anaphor is a male-person
pronoun (like he), female-person pronoun (like she), sin-
gle gender-neuter pronoun (like it), or plural gender-neuter
pronoun (like they)
Subject: whether the candidate is a subject of a sentence, a
subject of a clause, or not.
Object: whether the candidate is an object of a verb, an
object of a preposition, or not.
Distance: the sentence distance between the candidate and
the pronominal anaphor.
Closeness: whether the candidate is the candidate closest
to the pronominal anaphor.
FirstNP: whether the candidate is the first noun phrase in
the current sentence.
Parallelism: whether the candidate has an identical collo-
cation pattern with the pronominal anaphor.
</bodyText>
<tableCaption confidence="0.9635185">
Table 1: Feature set for the baseline pronoun res-
olution system
</tableCaption>
<bodyText confidence="0.991291352941177">
salience measures have to be assigned manually.
Luo and Zitouni (2005) proposed a coreference
resolution approach which also explores the infor-
mation from the syntactic parse trees. Different
from Lappin and Leass (1994)’s algorithm, they
employed a maximum entropy based model to au-
tomatically compute the importance (in terms of
weights) of the features extracted from the trees.
In their work, the selection of their features is
mainly inspired by the government and binding
theory, aiming to capture the c-command relation-
ships between the pronoun and its antecedent can-
didate. By contrast, our approach simply utilizes
the parse trees as a structured feature, and lets the
learning algorithm discover all possible embedded
information that is necessary for pronoun resolu-
tion.
</bodyText>
<sectionHeader confidence="0.983922" genericHeader="method">
3 The Resolution Framework
</sectionHeader>
<bodyText confidence="0.9999506">
Our pronoun resolution system adopts the com-
mon learning-based framework similar to those
by Soon et al. (2001) and Ng and Cardie (2002).
In the learning framework, a training or testing
instance is formed by a pronoun and one of its
antecedent candidate. During training, for each
pronominal anaphor encountered, a positive in-
stance is created by paring the anaphor and its
closest antecedent. Also a set of negative instances
is formed by paring the anaphor with each of the
</bodyText>
<page confidence="0.886682">
42
</page>
<bodyText confidence="0.999752818181818">
non-coreferential candidates. Based on the train-
ing instances, a binary classifier is generated using
a particular learning algorithm. During resolution,
a pronominal anaphor to be resolved is paired in
turn with each preceding antecedent candidate to
form a testing instance. This instance is presented
to the classifier which then returns a class label
with a confidence value indicating the likelihood
that the candidate is the antecedent. The candidate
with the highest confidence value will be selected
as the antecedent of the pronominal anaphor.
</bodyText>
<subsectionHeader confidence="0.999461">
3.1 Feature Space
</subsectionHeader>
<bodyText confidence="0.999988777777778">
As with many other learning-based approaches,
the knowledge for the reference determination is
represented as a set of features associated with
the training or test instances. In our baseline sys-
tem, the features adopted include lexical property,
morphologic type, distance, salience, parallelism,
grammatical role and so on. Listed in Table 1, all
these features have been proved effective for pro-
noun resolution in previous work.
</bodyText>
<subsectionHeader confidence="0.999859">
3.2 Support Vector Machine
</subsectionHeader>
<bodyText confidence="0.999990222222222">
In theory, any discriminative learning algorithm is
applicable to learn the classifier for pronoun res-
olution. In our study, we use Support Vector Ma-
chine (Vapnik, 1995) to allow the use of kernels to
incorporate the structured feature.
Suppose the training set S consists of labelled
vectors {(xi, yi)}, where xi is the feature vector
of a training instance and yi is its class label. The
classifier learned by SVM is
</bodyText>
<equation confidence="0.999089">
f(x) = sgn( � yiaix * xi + b) (1)
i=1
</equation>
<bodyText confidence="0.997778166666667">
where ai is the learned parameter for a support
vector xi. An instance x is classified as positive
(negative) if f(x) &gt; 0 (f(x) &lt; 0)1.
One advantage of SVM is that we can use ker-
nel methods to map a feature space to a particu-
lar high-dimension space, in case that the current
problem could not be separated in a linear way.
Thus the dot-product x1 * x2 is replaced by a ker-
nel function (or kernel) between two vectors, that
is K(x1, x2). For the learning with the normal
features listed in Table 1, we can just employ the
well-known polynomial or radial basis kernels that
can be computed efficiently. In the next section we
1For our task, the result of f(x) is used as the confidence
value of the candidate to be the antecedent of the pronoun
described by x.
will discuss how to use kernels to incorporate the
more complex structured feature.
</bodyText>
<sectionHeader confidence="0.997423" genericHeader="method">
4 Incorporating Structured Syntactic
Information
</sectionHeader>
<subsectionHeader confidence="0.99955">
4.1 Main Idea
</subsectionHeader>
<bodyText confidence="0.999996238095238">
A parse tree that covers a pronoun and its an-
tecedent candidate could provide us much syntac-
tic information related to the pair. The commonly
used syntactic knowledge for pronoun resolution,
such as grammatical roles or the governing rela-
tions, can be directly described by the tree struc-
ture. Other syntactic knowledge that may be help-
ful for resolution could also be implicitly repre-
sented in the tree. Therefore, by comparing the
common substructures between two trees we can
find out to what degree two trees contain similar
syntactic information, which can be done using a
convolution tree kernel.
The value returned from the tree kernel reflects
the similarity between two instances in syntax.
Such syntactic similarity can be further combined
with other knowledge to compute the overall simi-
larity between two instances, through a composite
kernel. And thus a SVM classifier can be learned
and then used for resolution. This is just the main
idea of our approach.
</bodyText>
<subsectionHeader confidence="0.994751">
4.2 Structured Syntactic Feature
</subsectionHeader>
<bodyText confidence="0.999093272727273">
Normally, parsing is done on the sentence level.
However, in many cases a pronoun and an an-
tecedent candidate do not occur in the same sen-
tence. To present their syntactic properties and
relations in a single tree structure, we construct a
syntax tree for an entire text, by attaching the parse
trees of all its sentences to an upper node.
Having obtained the parse tree of a text, we shall
consider how to select the appropriate portion of
the tree as the structured feature for a given in-
stance. As each instance is related to a pronoun
and a candidate, the structured feature at least
should be able to cover both of these two expres-
sions. Generally, the more substructure of the tree
is included, the more syntactic information would
be provided, but at the same time the more noisy
information that comes from parsing errors would
likely be introduced. In our study, we examine
three possible structured features that contain dif-
ferent substructures of the parse tree:
Min-Expansion This feature records the mini-
mal structure covering both the pronoun and
</bodyText>
<page confidence="0.868569">
43
</page>
<figure confidence="0.691432">
Min-Expansion Simple-Expansion Full-Expansion
</figure>
<figureCaption confidence="0.998642">
Figure 1: structured-features for the instance i{“him”, “the man”}
</figureCaption>
<bodyText confidence="0.999055462962963">
the candidate in the parse tree. It only in-
cludes the nodes occurring in the shortest
path connecting the pronoun and the candi-
date, via the nearest commonly commanding
node. For example, considering the sentence
“The man in the room saw him.”, the struc-
tured feature for the instance i{“him”,“the
man”} is circled with dash lines as shown in
the leftmost picture of Figure 1.
Simple-Expansion Min-Expansion could, to
some degree, describe the syntactic relation-
ships between the candidate and pronoun.
However, it is incapable of capturing the
syntactic properties of the candidate or
the pronoun, because the tree structure
surrounding the expression is not taken into
consideration. To incorporate such infor-
mation, feature Simple-Expansion not only
contains all the nodes in Min-Expansion, but
also includes the first-level children of these
nodes2. The middle of Figure 1 shows such a
feature for i{“him”, ”the man”}. We can see
that the nodes “PP” (for “in the room”) and
“VB” (for “saw”) are included in the feature,
which provides clues that the candidate is
modified by a prepositional phrase and the
pronoun is the object of a verb.
Full-Expansion This feature focusses on the
whole tree structure between the candidate
and pronoun. It not only includes all the
nodes in Simple-Expansion, but also the
nodes (beneath the nearest commanding par-
ent) that cover the words between the candi-
date and the pronoun3. Such a feature keeps
the most information related to the pronoun
2If the pronoun and the candidate are not in the same sen-
tence, we will not include the nodes denoting the sentences
before the candidate or after the pronoun.
3We will not expand the nodes denoting the sentences
other than where the pronoun and the candidate occur.
and candidate pair. The rightmost picture of
Figure 1 shows the structure for feature Full-
Expansion of i{“him”, ”the man”}. As illus-
trated, different from in Simple-Expansion,
the subtree of “PP” (for “in the room”) is
fully expanded and all its children nodes are
included in Full-Expansion.
Note that to distinguish from other words, we
explicitly mark up in the structured feature the
pronoun and the antecedent candidate under con-
sideration, by appending a string tag “ANA” and
“CANDI” in their respective nodes (e.g.,“NN-
CANDI” for “man” and “PRP-ANA” for “him” as
shown in Figure 1).
</bodyText>
<subsectionHeader confidence="0.998672">
4.3 Structural Kernel and Composite Kernel
</subsectionHeader>
<bodyText confidence="0.999997071428571">
To calculate the similarity between two structured
features, we use the convolution tree kernel that is
defined by Collins and Duffy (2002) and Moschitti
(2004). Given two trees, the kernel will enumerate
all their subtrees and use the number of common
subtrees as the measure of the similarity between
the trees. As has been proved, the convolution
kernel can be efficiently computed in polynomial
time.
The above tree kernel only aims for the struc-
tured feature. We also need a composite kernel
to combine together the structured feature and the
normal features described in Section 3.1. In our
study we define the composite kernel as follows:
</bodyText>
<equation confidence="0.999543">
Kn(x1, x2) Kt(x1, x2)
Kc(x1, x2) = |Kn(x1, x2) |∗ |Kt(x1, x2)|(2)
</equation>
<bodyText confidence="0.999969">
where Kt is the convolution tree kernel defined
for the structured feature, and Kn is the kernel
applied on the normal features. Both kernels are
divided by their respective length4 for normaliza-
tion. The new composite kernel Kc, defined as the
</bodyText>
<footnote confidence="0.646367">
4The length of a kernel K is defined as |K(x1, x2) |=
</footnote>
<equation confidence="0.82791">
V/ K(x1, x1) * K(x2, x2)
44
</equation>
<bodyText confidence="0.99973625">
multiplier of normalized Kt and Kr,,, will return a
value close to 1 only if both the structured features
and the normal features from the two vectors have
high similarity under their respective kernels.
</bodyText>
<sectionHeader confidence="0.997061" genericHeader="evaluation">
5 Experiments and Discussions
</sectionHeader>
<subsectionHeader confidence="0.898549">
5.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999995027027027">
In our study we focussed on the third-person
pronominal anaphora resolution. All the exper-
iments were done on the ACE-2 V1.0 corpus
(NIST, 2003), which contain two data sets, train-
ing and devtest, used for training and testing re-
spectively. Each of these sets is further divided
into three domains: newswire (NWire), newspa-
per (NPaper), and broadcast news (BNews).
An input raw text was preprocessed automati-
cally by a pipeline of NLP components, including
sentence boundary detection, POS-tagging, Text
Chunking and Named-Entity Recognition. The
texts were parsed using the maximum-entropy-
based Charniak parser (Charniak, 2000), based on
which the structured features were computed au-
tomatically. For learning, the SVM-Light soft-
ware (Joachims, 1999) was employed with the
convolution tree kernel implemented by Moschitti
(2004). All classifiers were trained with default
learning parameters.
The performance was evaluated based on the
metric success, the ratio of the number of cor-
rectly resolved5 anaphor over the number of all
anaphors. For each anaphor, the NPs occurring
within the current and previous two sentences
were taken as the initial antecedent candidates.
Those with mismatched number and gender agree-
ments were filtered from the candidate set. Also,
pronouns or NEs that disagreed in person with the
anaphor were removed in advance. For training,
there were 1207, 1440, and 1260 pronouns with
non-empty candidate set found pronouns in the
three domains respectively, while for testing, the
number was 313, 399 and 271. On average, a
pronoun anaphor had 6-9 antecedent candidates
ahead. Totally, we got around 10k, 13k and 8k
training instances for the three domains.
</bodyText>
<subsectionHeader confidence="0.99823">
5.2 Baseline Systems
</subsectionHeader>
<bodyText confidence="0.9928625">
Table 2 lists the performance of different systems.
We first tested Hobbs’ algorithm (Hobbs, 1978).
</bodyText>
<footnote confidence="0.8281015">
5An anaphor was deemed correctly resolved if the found
antecedent is in the same coreference chain of the anaphor.
</footnote>
<table confidence="0.999456727272727">
NWire NPaper BNews
Hobbs (1978) 66.1 66.4 72.7
NORM 74.4 77.4 74.2
NORM MaxEnt 72.8 77.9 75.3
NORM C5 71.9 75.9 71.6
S Min 76.4 81.0 76.8
S Simple 73.2 82.7 82.3
S Full 73.2 80.5 79.0
NORM+S Min 77.6 82.5 82.3
NORM+S Simple 79.2 82.7 82.3
NORM+S Full 81.5 83.2 81.5
</table>
<tableCaption confidence="0.916422">
Table 2: Results of the syntactic structured fea-
tures
</tableCaption>
<bodyText confidence="0.997153851851852">
Described in Section 2, the algorithm uses heuris-
tic rules to search the parse tree for the antecedent,
and will act as a good baseline to compare with the
learned-based approach with the structured fea-
ture. As shown in the first line of Table 2, Hobbs’
algorithm obtains 66%-72% success rates on the
three domains.
The second block of Table 2 shows the baseline
system (NORM) that uses only the normal features
listed in Table 1. Throughout our experiments, we
applied the polynomial kernel on the normal fea-
tures to learn the SVM classifiers. In the table we
also compared the SVM-based results with those
using other learning algorithms, i.e., Maximum
Entropy (Maxent) and C5 decision tree, which are
more commonly used in the anaphora resolution
task.
As shown in the table, the system with normal
features (NORM) obtains 74%-77% success rates
for the three domains. The performance is simi-
lar to other published results like those by Keller
and Lapata (2003), who adopted a similar fea-
ture set and reported around 75% success rates
on the ACE data set. The comparison between
different learning algorithms indicates that SVM
can work as well as or even better than Maxent
(NORM MaxEnt) or C5 (NORM C5).
</bodyText>
<subsectionHeader confidence="0.998375">
5.3 Systems with Structured Features
</subsectionHeader>
<bodyText confidence="0.999948714285714">
The last two blocks of Table 2 summarize the re-
sults using the three syntactic structured features,
i.e, Min Expansion (S MIN), Simple Expansion
(S SIMPLE) and Full Expansion (S FULL). Be-
tween them, the third block is for the systems us-
ing the individual structured feature alone. We
can see that all the three structured features per-
</bodyText>
<page confidence="0.882309">
45
</page>
<table confidence="0.999470166666667">
NWire NPaper BNews
Sentence Distance 0 1 2 0 1 2 0 1 2
(Number of Prons) (192) (102) (19) (237) (147) (15) (175) (82) (14)
NORM 80.2 72.5 26.3 81.4 75.5 33.3 80.0 65.9 50.0
S Simple 79.7 70.6 21.1 87.3 81.0 26.7 89.7 70.7 57.1
NORM+S Simple 85.4 76.5 31.6 87.3 79.6 40.0 88.6 74.4 50.0
</table>
<tableCaption confidence="0.992819">
Table 3: The resolution results for pronouns with antecedent in different sentences apart
</tableCaption>
<table confidence="0.999613833333333">
NWire NPaper BNews
Type person neuter person neuter person neuter
(Number of Prons) (171) (142) (250) (149) (153) (118)
NORM 81.9 65.5 80.0 73.2 74.5 73.7
S Simple 81.9 62.7 83.2 81.9 82.4 82.2
NORM+S Simple 87.1 69.7 83.6 81.2 86.9 76.3
</table>
<tableCaption confidence="0.999695">
Table 4: The resolution results for different types of pronouns
</tableCaption>
<bodyText confidence="0.994999538461539">
form better than the normal features for NPaper
(up to 5.3% success) and BNews (up to 8.1% suc-
cess), or equally well (±1 - 2% in success) for
NWire. When used together with the normal fea-
tures, as shown in the last block, the three struc-
tured features all outperform the baselines. Es-
pecially, the combinations of NORM+S SIMPLE
and NORM+S FULL can achieve significantly6
better results than NORM, with the success rate
increasing by (4.8%, 5.3% and 8.1%) and (7.1%,
5.8%, 7.2%) respectively. All these results prove
that the structured syntactic feature is effective for
pronoun resolution.
We further compare the performance of the
three different structured features. As shown in
Table 2, when used together with the normal
features, Full Expansion gives the highest suc-
cess rates in NWire and NPaper, but neverthe-
less the lowest in BNews. This should be be-
cause feature Full-Expansion captures a larger
portion of the parse trees, and thus can provide
more syntactic information than Min Expansion
or Simple Expansion. However, if the texts are
less-formally structured as those in BNews, Full-
Expansion would inevitably involve more noises
and thus adversely affect the resolution perfor-
mance. By contrast, feature Simple Expansion
would achieve balance between the information
and the noises to be introduced: from Table 2 we
can find that compared with the other two features,
Simple Expansion is capable of producing aver-
age results for all the three domains. And for this
6p &lt; 0.05 by a 2-tailed t test.
reason, our subsequent reports will focus on Sim-
ple Expansion, unless otherwise specified.
As described, to compute the structured fea-
ture, parse trees for different sentences are con-
nected to form a large tree for the text. It would
be interesting to find how the structured feature
works for pronouns whose antecedents reside in
different sentences. For this purpose we tested
the success rates for the pronouns with the clos-
est antecedent occurring in the same sentence,
one-sentence apart, and two-sentence apart. Ta-
ble 3 compares the learning systems with/without
the structured feature present. From the table,
for all the systems, the success rates drop with
the increase of the distances between the pro-
noun and the antecedent. However, in most cases,
adding the structured feature would bring consis-
tent improvement against the baselines regardless
of the number of sentence distance. This observa-
tion suggests that the structured syntactic informa-
tion is helpful for both intra-sentential and inter-
sentential pronoun resolution.
We were also concerned about how the struc-
tured feature works for different types of pro-
nouns. Table 4 lists the resolution results for two
types of pronouns: person pronouns (i.e., “he”,
“she”) and neuter-gender pronouns (i.e., “it” and
“they”). As shown, with the structured feature in-
corporated, the system NORM+S Simple can sig-
nificantly boost the performance of the baseline
(NORM), for both personal pronoun and neuter-
gender pronoun resolution.
</bodyText>
<page confidence="0.837649">
46
</page>
<figure confidence="0.96174312">
0.75
0.65
0.8
0.7
1 2 3 4 5 6 7 8 9 10
NORM
S_Simple
NORM+S_Simple
0.75
0.65
0.8
0.7
2 4 6 8 10 12
NORM
S_SimpleNORM+S_Simple
0.75
0.65
0.8
0.7
1 2 3 4 5 6 7 8
NORM
S_Simple
NORM+S_Simple
Number of Training Documents Number of Training Documents Number of Training Documents
NWire NPaper BNews
</figure>
<figureCaption confidence="0.986222">
Figure 2: Learning curves of systems with different features
</figureCaption>
<bodyText confidence="0.631848">
Su
</bodyText>
<subsectionHeader confidence="0.991365">
5.4 Learning Curves
</subsectionHeader>
<bodyText confidence="0.874291285714286">
Figure 2 plots the learning curves for the sys-
tems with three feature sets, i.e, normal features
(NORM), structured feature alone (S Simple),
and combined features (NORM+S Simple). We
trained each system with different number of in-
stances from 1k, 2k, 3k, ... , till the full size. Each
point in the figures was the average over two trails
with instances selected forwards and backwards
respectively. From the figures we can find that
(1) Used in combination (NORM+S Simple), the
structured feature shows superiority over NORM,
achieving results consistently better than the nor-
mal features (NORM) do in all the three domains.
(2) With training instances above 3k, the struc-
tured feature, used either in isolation (S Simple)
or in combination (NORM+S Simple), leads to
steady increase in the success rates and exhibit
smoother learning curves than the normal features
(NORM). These observations further prove the re-
liability of the structured feature in pronoun reso-
lution.
</bodyText>
<subsectionHeader confidence="0.979663">
5.5 Feature Analysis
</subsectionHeader>
<bodyText confidence="0.999964666666667">
In our experiment we were also interested to com-
pare the structured feature with the normal flat
features extracted from the parse tree, like fea-
ture Subject and Object. For this purpose we
took out these two grammatical features from the
normal feature set, and then trained the systems
again. As shown in Table 5, the two grammatical-
role features are important for the pronoun resolu-
tion: removing these features results in up to 5.7%
(NWire) decrease in success. However, when the
structured feature is included, the loss in success
reduces to 1.9% and 1.1% for NWire and BNews,
and a slight improvement can even be achieved for
NPaper. This indicates that the structured feature
can effectively provide the syntactic information
</bodyText>
<table confidence="0.9409986">
NORM
NORM - subj/obj
NORM + S Simple
NORM + S Simple - subj/obj
NORM + Luo05
</table>
<tableCaption confidence="0.834185">
Table 5: Comparison of the structured feature and
the flat features extracted from parse trees
</tableCaption>
<table confidence="0.9999608">
Feature Parser NWire NPaper BNews
Charniak00 73.2 82.7 82.3
S Simple Collins99 75.1 83.2 80.4
NORM+ Charniak00 79.2 82.7 82.3
S Simple Collins99 80.8 81.5 82.3
</table>
<tableCaption confidence="0.999357">
Table 6: Results using different parsers
</tableCaption>
<bodyText confidence="0.992797533333333">
important for pronoun resolution.
We also tested the flat syntactic feature set pro-
posed in Luo and Zitouni (2005)’s work. As de-
scribed in Section 2, the feature set is inspired
the binding theory, including those features like
whether the candidate is c commanding the pro-
noun, and the counts of “NP”, “VP”, “S” nodes
in the commanding path. The last line of Table 5
shows the results by adding these features into the
normal feature set. In line with the reports in (Luo
and Zitouni, 2005) we do observe the performance
improvement against the baseline (NORM) for all
the domains. However, the increase in the success
rates (up to 1.3%) is not so large as by adding the
structured feature (NORM+S Simple) instead.
</bodyText>
<subsectionHeader confidence="0.992904">
5.6 Comparison with Different Parsers
</subsectionHeader>
<bodyText confidence="0.9999648">
As mentioned, the above reported results were
based on Charniak (2000)’s parser. It would be
interesting to examine the influence of different
parsers on the resolution performance. For this
purpose, we also tried the parser by Collins (1999)
</bodyText>
<table confidence="0.778159">
NWire NPaper BNews
ces 77.4 74.2
74.4
Su 76.2 72.7
68.7
79.2 82.7 82.3
77.3 83.0 81.2
75.7 77.9 74.9
</table>
<page confidence="0.873308">
47
</page>
<bodyText confidence="0.99993875">
(Mode II)7, and the results are shown in Table 6.
We can see that Charniak (2000)’s parser leads to
higher success rates for NPaper and BNews, while
Collins (1999)’s achieves better results for NWire.
However, the difference between the results of the
two parsers is not significant (less than 2% suc-
cess) for the three domains, no matter whether the
structured feature is used alone or in combination.
</bodyText>
<sectionHeader confidence="0.999142" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999990260869565">
The purpose of this paper is to explore how to
make use of the structured syntactic knowledge to
do pronoun resolution. Traditionally, syntactic in-
formation from parse trees is represented as a set
of flat features. However, the features are usu-
ally selected and defined by heuristics and may
not necessarily capture all the syntactic informa-
tion provided by the parse trees. In the paper, we
propose a kernel-based method to incorporate the
information from parse trees. Specifically, we di-
rectly utilize the syntactic parse tree as a struc-
tured feature, and then apply kernels to such a fea-
ture, together with other normal features, to learn
the decision classifier and do the resolution. Our
experimental results on ACE data set show that
the system with the structured feature included
can achieve significant increase in the success rate
by around 5%-8%, for all the different domains.
The deeper analysis on various factors like training
size, feature set or parsers further proves that the
structured feature incorporated with our kernel-
based method is reliably effective for the pronoun
resolution task.
</bodyText>
<sectionHeader confidence="0.998471" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999750644736842">
C. Aone and S. W. Bennett. 1995. Evaluating auto-
mated and manual acquisition of anaphora resolu-
tion strategies. In Proceedings of the 33rd Annual
Meeting of the Association for Compuational Lin-
guistics, pages 122–129.
E. Charniak. 2000. A maximum-entropy-inspired
parser. In Proceedings of North American chapter
of the Association for Computational Linguistics an-
nual meeting, pages 132–139.
M. Collins and N. Duffy. 2002. New ranking algo-
rithms for parsing and tagging: kernels over discrete
structures and the voted perceptron. In Proceed-
ings of the 40th Annual Meeting of the Association
7As in their pulic reports on Section 23 of WSJ TreeBank,
Charniak (2000)’s parser achieves 89.6% recall and 89.5%
precision with 0.88 crossing brackets (words &lt; 100), against
Collins (1999)’s 88.1% recall and 88.3% precision with 1.06
crossing brackets.
for Computational Linguistics (ACL’02), pages 263–
270.
M. Collins. 1999. Head-Driven Statistical Models for
Natural Language Parsing. Ph.D. thesis, University
of Pennsylvania.
J. Hobbs. 1978. Resolving pronoun references. Lin-
gua, 44:339–352.
T. Joachims. 1999. Making large-scale svm learning
practical. In Advances in Kernel Methods - Support
Vector Learning. MIT Press.
F. Keller and M. Lapata. 2003. Using the web to ob-
tain freqencies for unseen bigrams. Computational
Linguistics, 29(3):459–484.
C. Kennedy and B. Boguraev. 1996. Anaphora
for everyone: pronominal anaphra resolution with-
out a parser. In Proceedings of the 16th Inter-
national Conference on Computational Linguistics,
pages 113–118, Copenhagen, Denmark.
S. Lappin and H. Leass. 1994. An algorithm for
pronominal anaphora resolution. Computational
Linguistics, 20(4):525–561.
X. Luo and I. Zitouni. 2005. Milti-lingual coreference
resolution with syntactic features. In Proceedings of
Human Language Techonology conference and Con-
ference on Empirical Methods in Natural Language
Processing (HLT/EMNLP), pages 660–667.
R. Mitkov. 1998. Robust pronoun resolution with lim-
ited knowledge. In Proceedings of the 17th Int. Con-
ference on Computational Linguistics, pages 869–
875.
A. Moschitti. 2004. A study on convolution kernels
for shallow semantic parsing. In Proceedings of the
42nd Annual Meeting of the Association for Compu-
tational Linguistics (ACL’04), pages 335–342.
V. Ng and C. Cardie. 2002. Improving machine learn-
ing approaches to coreference resolution. In Pro-
ceedings of the 40th Annual Meeting of the Associa-
tion for Computational Linguistics, pages 104–111,
Philadelphia.
W. Soon, H. Ng, and D. Lim. 2001. A machine
learning approach to coreference resolution of noun
phrases. Computational Linguistics, 27(4):521–
544.
V. Vapnik. 1995. The Nature of Statistical Learning
Theory. Springer.
X. Yang, J. Su, G. Zhou, and C. Tan. 2004. Improv-
ing pronoun resolution by incorporating coreferen-
tial information of candidates. In Proceedings of
42th Annual Meeting of the Association for Compu-
tational Linguistics, pages 127–134, Barcelona.
D. Zelenko, C. Aone, and A. Richardella. 2003. Ker-
nel methods for relation extraction. Journal of Ma-
chine Learning Research, 3(6):1083 – 1106.
S. Zhao and R. Grishman. 2005. Extracting rela-
tions with integrated information using kernel meth-
ods. In Proceedings of 43rd Annual Meeting of the
Association for Computational Linguistics (ACL05),
pages 419–426.
</reference>
<page confidence="0.963297">
48
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.766705">
<title confidence="0.996284">Kernel-Based Pronoun Resolution with Structured Syntactic Knowledge</title>
<author confidence="0.945641">Lim</author>
<affiliation confidence="0.980734">for Infocomm Research</affiliation>
<address confidence="0.92628">21 Heng Mui Keng Terrace, Singapore, 119613</address>
<affiliation confidence="0.9969705">of Computer Science National University of Singapore,</affiliation>
<address confidence="0.999702">Singapore, 117543</address>
<email confidence="0.984863">tancl@comp.nus.edu.sg</email>
<abstract confidence="0.998506238095238">Syntactic knowledge is important for pronoun resolution. Traditionally, the syntactic information for pronoun resolution is represented in terms of features that have to be selected and defined heuristically. In the paper, we propose a kernel-based method that can automatically mine the syntactic information from the parse trees for pronoun resolution. Specifically, we utilize the parse trees directly as a structured feature and apply kernel functions to this feature, as well as other normal features, to learn the resolution classifier. In this way, our approach avoids the efforts of decoding the parse trees into the set of flat syntactic features. The experimental results show that our approach can bring significant performance improvement and is reliably effective for the pronoun resolution task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C Aone</author>
<author>S W Bennett</author>
</authors>
<title>Evaluating automated and manual acquisition of anaphora resolution strategies.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd Annual Meeting of the Association for Compuational Linguistics,</booktitle>
<pages>122--129</pages>
<contexts>
<context position="2124" citStr="Aone and Bennett, 1995" startWordPosition="315" endWordPosition="318"> arises is how to effectively incorporate the syntactic information embedded in the parse trees to help resolution. One common solution seen in previous work is to define a set of features that represent particular syntactic knowledge, such as the grammatical role of the antecedent candidates, the governing relations between the candidate and the pronoun, and so on. These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005). However, such a solution has its limitation. The syntactic features have to be selected and defined manually, usually by linguistic intuition. Unfortunately, what kinds of syntactic information are effective for pronoun resolution still remains an open question in this research community. The heuristically selected feature set may be insufficient to represent all the information necessary for pronoun resolution contained in the parse trees. In this paper we will explore how to utilize the syntactic parse trees to help learning-based pronoun resoluti</context>
</contexts>
<marker>Aone, Bennett, 1995</marker>
<rawString>C. Aone and S. W. Bennett. 1995. Evaluating automated and manual acquisition of anaphora resolution strategies. In Proceedings of the 33rd Annual Meeting of the Association for Compuational Linguistics, pages 122–129.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
</authors>
<title>A maximum-entropy-inspired parser.</title>
<date>2000</date>
<booktitle>In Proceedings of North American chapter of the Association for Computational Linguistics annual meeting,</booktitle>
<pages>132--139</pages>
<contexts>
<context position="17523" citStr="Charniak, 2000" startWordPosition="2805" endWordPosition="2806">we focussed on the third-person pronominal anaphora resolution. All the experiments were done on the ACE-2 V1.0 corpus (NIST, 2003), which contain two data sets, training and devtest, used for training and testing respectively. Each of these sets is further divided into three domains: newswire (NWire), newspaper (NPaper), and broadcast news (BNews). An input raw text was preprocessed automatically by a pipeline of NLP components, including sentence boundary detection, POS-tagging, Text Chunking and Named-Entity Recognition. The texts were parsed using the maximum-entropybased Charniak parser (Charniak, 2000), based on which the structured features were computed automatically. For learning, the SVM-Light software (Joachims, 1999) was employed with the convolution tree kernel implemented by Moschitti (2004). All classifiers were trained with default learning parameters. The performance was evaluated based on the metric success, the ratio of the number of correctly resolved5 anaphor over the number of all anaphors. For each anaphor, the NPs occurring within the current and previous two sentences were taken as the initial antecedent candidates. Those with mismatched number and gender agreements were </context>
<context position="27702" citStr="Charniak (2000)" startWordPosition="4498" endWordPosition="4499">hose features like whether the candidate is c commanding the pronoun, and the counts of “NP”, “VP”, “S” nodes in the commanding path. The last line of Table 5 shows the results by adding these features into the normal feature set. In line with the reports in (Luo and Zitouni, 2005) we do observe the performance improvement against the baseline (NORM) for all the domains. However, the increase in the success rates (up to 1.3%) is not so large as by adding the structured feature (NORM+S Simple) instead. 5.6 Comparison with Different Parsers As mentioned, the above reported results were based on Charniak (2000)’s parser. It would be interesting to examine the influence of different parsers on the resolution performance. For this purpose, we also tried the parser by Collins (1999) NWire NPaper BNews ces 77.4 74.2 74.4 Su 76.2 72.7 68.7 79.2 82.7 82.3 77.3 83.0 81.2 75.7 77.9 74.9 47 (Mode II)7, and the results are shown in Table 6. We can see that Charniak (2000)’s parser leads to higher success rates for NPaper and BNews, while Collins (1999)’s achieves better results for NWire. However, the difference between the results of the two parsers is not significant (less than 2% success) for the three dom</context>
</contexts>
<marker>Charniak, 2000</marker>
<rawString>E. Charniak. 2000. A maximum-entropy-inspired parser. In Proceedings of North American chapter of the Association for Computational Linguistics annual meeting, pages 132–139.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M Collins</author>
<author>N Duffy</author>
</authors>
<title>New ranking algorithms for parsing and tagging: kernels over discrete structures and the voted perceptron.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association 7As in their pulic reports on Section 23 of WSJ TreeBank, Charniak (2000)’s parser achieves 89.6% recall and 89.5% precision with 0.88 crossing brackets (words &lt; 100), against Collins</booktitle>
<contexts>
<context position="3251" citStr="Collins and Duffy, 2002" startWordPosition="488" endWordPosition="491">we will explore how to utilize the syntactic parse trees to help learning-based pronoun resolution. Specifically, we directly utilize the parse trees as a structured feature, and then use a kernel-based method to automatically mine the knowledge embedded in the parse trees. The structured syntactic feature, together with other normal features, is incorporated in a trainable model based on Support Vector Machine (SVM) (Vapnik, 1995) to learn the decision classifier for resolution. Indeed, using kernel methods to mine structural knowledge has shown success in some NLP applications like parsing (Collins and Duffy, 2002; Moschitti, 2004) and relation extraction (Zelenko et al., 2003; Zhao and Grishman, 2005). However, to our knowledge, the application of such a technique to the pronoun resolution task still remains unexplored. Compared with previous work, our approach has several advantages: (1) The approach utilizes the parse trees as a structured feature, which avoids the efforts of decoding the parse trees into a set of syntactic features in a heuristic manner. (2) The approach is able to put together the structured feature and the normal flat features in a trainable model, which allows different types of</context>
<context position="15738" citStr="Collins and Duffy (2002)" startWordPosition="2511" endWordPosition="2514">nt from in Simple-Expansion, the subtree of “PP” (for “in the room”) is fully expanded and all its children nodes are included in Full-Expansion. Note that to distinguish from other words, we explicitly mark up in the structured feature the pronoun and the antecedent candidate under consideration, by appending a string tag “ANA” and “CANDI” in their respective nodes (e.g.,“NNCANDI” for “man” and “PRP-ANA” for “him” as shown in Figure 1). 4.3 Structural Kernel and Composite Kernel To calculate the similarity between two structured features, we use the convolution tree kernel that is defined by Collins and Duffy (2002) and Moschitti (2004). Given two trees, the kernel will enumerate all their subtrees and use the number of common subtrees as the measure of the similarity between the trees. As has been proved, the convolution kernel can be efficiently computed in polynomial time. The above tree kernel only aims for the structured feature. We also need a composite kernel to combine together the structured feature and the normal features described in Section 3.1. In our study we define the composite kernel as follows: Kn(x1, x2) Kt(x1, x2) Kc(x1, x2) = |Kn(x1, x2) |∗ |Kt(x1, x2)|(2) where Kt is the convolution</context>
</contexts>
<marker>Collins, Duffy, 2002</marker>
<rawString>M. Collins and N. Duffy. 2002. New ranking algorithms for parsing and tagging: kernels over discrete structures and the voted perceptron. In Proceedings of the 40th Annual Meeting of the Association 7As in their pulic reports on Section 23 of WSJ TreeBank, Charniak (2000)’s parser achieves 89.6% recall and 89.5% precision with 0.88 crossing brackets (words &lt; 100), against Collins (1999)’s 88.1% recall and 88.3% precision with 1.06 crossing brackets.</rawString>
</citation>
<citation valid="false">
<date></date>
<pages>263--270</pages>
<institution>for Computational Linguistics</institution>
<marker></marker>
<rawString>for Computational Linguistics (ACL’02), pages 263– 270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
</authors>
<title>Head-Driven Statistical Models for Natural Language Parsing.</title>
<date>1999</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="27874" citStr="Collins (1999)" startWordPosition="4525" endWordPosition="4526">lts by adding these features into the normal feature set. In line with the reports in (Luo and Zitouni, 2005) we do observe the performance improvement against the baseline (NORM) for all the domains. However, the increase in the success rates (up to 1.3%) is not so large as by adding the structured feature (NORM+S Simple) instead. 5.6 Comparison with Different Parsers As mentioned, the above reported results were based on Charniak (2000)’s parser. It would be interesting to examine the influence of different parsers on the resolution performance. For this purpose, we also tried the parser by Collins (1999) NWire NPaper BNews ces 77.4 74.2 74.4 Su 76.2 72.7 68.7 79.2 82.7 82.3 77.3 83.0 81.2 75.7 77.9 74.9 47 (Mode II)7, and the results are shown in Table 6. We can see that Charniak (2000)’s parser leads to higher success rates for NPaper and BNews, while Collins (1999)’s achieves better results for NWire. However, the difference between the results of the two parsers is not significant (less than 2% success) for the three domains, no matter whether the structured feature is used alone or in combination. 6 Conclusion The purpose of this paper is to explore how to make use of the structured synta</context>
</contexts>
<marker>Collins, 1999</marker>
<rawString>M. Collins. 1999. Head-Driven Statistical Models for Natural Language Parsing. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hobbs</author>
</authors>
<title>Resolving pronoun references.</title>
<date>1978</date>
<journal>Lingua,</journal>
<pages>44--339</pages>
<contexts>
<context position="5318" citStr="Hobbs (1978)" startWordPosition="819" endWordPosition="820"> the paper is organized as follows. Section 2 gives some related work that utilizes the structured syntactic knowledge to do pronoun resolution. Section 3 introduces the framework for the pronoun resolution, as well as the baseline feature space and the SVM classifier. Section 4 presents in detail the structured feature and the kernel functions to incorporate such a feature in the resolution. Section 5 shows the experimental results and has some discussion. Finally, Section 6 concludes the paper. 2 Related Work One of the early work on pronoun resolution relying on parse trees was proposed by Hobbs (1978). For a pronoun to be resolved, Hobbs’ algorithm works by searching the parse trees of the current text. Specifically, the algorithm processes one sentence at a time, using a left-to-right breadth-first searching strategy. It first checks the current sentence where the pronoun occurs. The first NP that satisfies constraints, like number and gender agreements, would be selected as the antecedent. If the antecedent is not found in the current sentence, the algorithm would traverse the trees of previous sentences in the text. As the searching processing is completely done on the parse trees, the </context>
<context position="18698" citStr="Hobbs, 1978" startWordPosition="2988" endWordPosition="2989">ed number and gender agreements were filtered from the candidate set. Also, pronouns or NEs that disagreed in person with the anaphor were removed in advance. For training, there were 1207, 1440, and 1260 pronouns with non-empty candidate set found pronouns in the three domains respectively, while for testing, the number was 313, 399 and 271. On average, a pronoun anaphor had 6-9 antecedent candidates ahead. Totally, we got around 10k, 13k and 8k training instances for the three domains. 5.2 Baseline Systems Table 2 lists the performance of different systems. We first tested Hobbs’ algorithm (Hobbs, 1978). 5An anaphor was deemed correctly resolved if the found antecedent is in the same coreference chain of the anaphor. NWire NPaper BNews Hobbs (1978) 66.1 66.4 72.7 NORM 74.4 77.4 74.2 NORM MaxEnt 72.8 77.9 75.3 NORM C5 71.9 75.9 71.6 S Min 76.4 81.0 76.8 S Simple 73.2 82.7 82.3 S Full 73.2 80.5 79.0 NORM+S Min 77.6 82.5 82.3 NORM+S Simple 79.2 82.7 82.3 NORM+S Full 81.5 83.2 81.5 Table 2: Results of the syntactic structured features Described in Section 2, the algorithm uses heuristic rules to search the parse tree for the antecedent, and will act as a good baseline to compare with the learned</context>
</contexts>
<marker>Hobbs, 1978</marker>
<rawString>J. Hobbs. 1978. Resolving pronoun references. Lingua, 44:339–352.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Making large-scale svm learning practical.</title>
<date>1999</date>
<booktitle>In Advances in Kernel Methods - Support Vector Learning.</booktitle>
<publisher>MIT Press.</publisher>
<contexts>
<context position="17646" citStr="Joachims, 1999" startWordPosition="2823" endWordPosition="2824">T, 2003), which contain two data sets, training and devtest, used for training and testing respectively. Each of these sets is further divided into three domains: newswire (NWire), newspaper (NPaper), and broadcast news (BNews). An input raw text was preprocessed automatically by a pipeline of NLP components, including sentence boundary detection, POS-tagging, Text Chunking and Named-Entity Recognition. The texts were parsed using the maximum-entropybased Charniak parser (Charniak, 2000), based on which the structured features were computed automatically. For learning, the SVM-Light software (Joachims, 1999) was employed with the convolution tree kernel implemented by Moschitti (2004). All classifiers were trained with default learning parameters. The performance was evaluated based on the metric success, the ratio of the number of correctly resolved5 anaphor over the number of all anaphors. For each anaphor, the NPs occurring within the current and previous two sentences were taken as the initial antecedent candidates. Those with mismatched number and gender agreements were filtered from the candidate set. Also, pronouns or NEs that disagreed in person with the anaphor were removed in advance. F</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>T. Joachims. 1999. Making large-scale svm learning practical. In Advances in Kernel Methods - Support Vector Learning. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Keller</author>
<author>M Lapata</author>
</authors>
<title>Using the web to obtain freqencies for unseen bigrams.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>3</issue>
<contexts>
<context position="20098" citStr="Keller and Lapata (2003)" startWordPosition="3228" endWordPosition="3231">le 2 shows the baseline system (NORM) that uses only the normal features listed in Table 1. Throughout our experiments, we applied the polynomial kernel on the normal features to learn the SVM classifiers. In the table we also compared the SVM-based results with those using other learning algorithms, i.e., Maximum Entropy (Maxent) and C5 decision tree, which are more commonly used in the anaphora resolution task. As shown in the table, the system with normal features (NORM) obtains 74%-77% success rates for the three domains. The performance is similar to other published results like those by Keller and Lapata (2003), who adopted a similar feature set and reported around 75% success rates on the ACE data set. The comparison between different learning algorithms indicates that SVM can work as well as or even better than Maxent (NORM MaxEnt) or C5 (NORM C5). 5.3 Systems with Structured Features The last two blocks of Table 2 summarize the results using the three syntactic structured features, i.e, Min Expansion (S MIN), Simple Expansion (S SIMPLE) and Full Expansion (S FULL). Between them, the third block is for the systems using the individual structured feature alone. We can see that all the three structu</context>
</contexts>
<marker>Keller, Lapata, 2003</marker>
<rawString>F. Keller and M. Lapata. 2003. Using the web to obtain freqencies for unseen bigrams. Computational Linguistics, 29(3):459–484.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Kennedy</author>
<author>B Boguraev</author>
</authors>
<title>Anaphora for everyone: pronominal anaphra resolution without a parser.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics,</booktitle>
<pages>113--118</pages>
<location>Copenhagen, Denmark.</location>
<contexts>
<context position="2050" citStr="Kennedy and Boguraev, 1996" startWordPosition="305" endWordPosition="308">actic knowledge usually comes from the parse trees of the text. The issue that arises is how to effectively incorporate the syntactic information embedded in the parse trees to help resolution. One common solution seen in previous work is to define a set of features that represent particular syntactic knowledge, such as the grammatical role of the antecedent candidates, the governing relations between the candidate and the pronoun, and so on. These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005). However, such a solution has its limitation. The syntactic features have to be selected and defined manually, usually by linguistic intuition. Unfortunately, what kinds of syntactic information are effective for pronoun resolution still remains an open question in this research community. The heuristically selected feature set may be insufficient to represent all the information necessary for pronoun resolution contained in the parse trees. In this paper we will explore how to</context>
</contexts>
<marker>Kennedy, Boguraev, 1996</marker>
<rawString>C. Kennedy and B. Boguraev. 1996. Anaphora for everyone: pronominal anaphra resolution without a parser. In Proceedings of the 16th International Conference on Computational Linguistics, pages 113–118, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Lappin</author>
<author>H Leass</author>
</authors>
<title>An algorithm for pronominal anaphora resolution.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>4</issue>
<contexts>
<context position="2022" citStr="Lappin and Leass, 1994" startWordPosition="301" endWordPosition="304">olution system, the syntactic knowledge usually comes from the parse trees of the text. The issue that arises is how to effectively incorporate the syntactic information embedded in the parse trees to help resolution. One common solution seen in previous work is to define a set of features that represent particular syntactic knowledge, such as the grammatical role of the antecedent candidates, the governing relations between the candidate and the pronoun, and so on. These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005). However, such a solution has its limitation. The syntactic features have to be selected and defined manually, usually by linguistic intuition. Unfortunately, what kinds of syntactic information are effective for pronoun resolution still remains an open question in this research community. The heuristically selected feature set may be insufficient to represent all the information necessary for pronoun resolution contained in the parse trees. In this </context>
<context position="6029" citStr="Lappin and Leass (1994)" startWordPosition="933" endWordPosition="936">he current text. Specifically, the algorithm processes one sentence at a time, using a left-to-right breadth-first searching strategy. It first checks the current sentence where the pronoun occurs. The first NP that satisfies constraints, like number and gender agreements, would be selected as the antecedent. If the antecedent is not found in the current sentence, the algorithm would traverse the trees of previous sentences in the text. As the searching processing is completely done on the parse trees, the performance of the algorithm would rely heavily on the accuracy of the parsing results. Lappin and Leass (1994) reported a pronoun resolution algorithm which uses the syntactic representation output by McCord’s Slot Grammar parser. A set of salience measures (e.g. Subject, Object or Accusative emphasis) is derived from the syntactic structure. The candidate with the highest salience score would be selected as the antecedent. In their algorithm, the weights of Category: whether the candidate is a definite noun phrase, indefinite noun phrase, pronoun, named-entity or others. Reflexiveness: whether the pronominal anaphor is a reflexive pronoun. Type: whether the pronominal anaphor is a male-person pronoun</context>
<context position="7572" citStr="Lappin and Leass (1994)" startWordPosition="1168" endWordPosition="1171">the sentence distance between the candidate and the pronominal anaphor. Closeness: whether the candidate is the candidate closest to the pronominal anaphor. FirstNP: whether the candidate is the first noun phrase in the current sentence. Parallelism: whether the candidate has an identical collocation pattern with the pronominal anaphor. Table 1: Feature set for the baseline pronoun resolution system salience measures have to be assigned manually. Luo and Zitouni (2005) proposed a coreference resolution approach which also explores the information from the syntactic parse trees. Different from Lappin and Leass (1994)’s algorithm, they employed a maximum entropy based model to automatically compute the importance (in terms of weights) of the features extracted from the trees. In their work, the selection of their features is mainly inspired by the government and binding theory, aiming to capture the c-command relationships between the pronoun and its antecedent candidate. By contrast, our approach simply utilizes the parse trees as a structured feature, and lets the learning algorithm discover all possible embedded information that is necessary for pronoun resolution. 3 The Resolution Framework Our pronoun</context>
</contexts>
<marker>Lappin, Leass, 1994</marker>
<rawString>S. Lappin and H. Leass. 1994. An algorithm for pronominal anaphora resolution. Computational Linguistics, 20(4):525–561.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Luo</author>
<author>I Zitouni</author>
</authors>
<title>Milti-lingual coreference resolution with syntactic features.</title>
<date>2005</date>
<booktitle>In Proceedings of Human Language Techonology conference and Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP),</booktitle>
<pages>660--667</pages>
<contexts>
<context position="2167" citStr="Luo and Zitouni, 2005" startWordPosition="323" endWordPosition="326">he syntactic information embedded in the parse trees to help resolution. One common solution seen in previous work is to define a set of features that represent particular syntactic knowledge, such as the grammatical role of the antecedent candidates, the governing relations between the candidate and the pronoun, and so on. These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005). However, such a solution has its limitation. The syntactic features have to be selected and defined manually, usually by linguistic intuition. Unfortunately, what kinds of syntactic information are effective for pronoun resolution still remains an open question in this research community. The heuristically selected feature set may be insufficient to represent all the information necessary for pronoun resolution contained in the parse trees. In this paper we will explore how to utilize the syntactic parse trees to help learning-based pronoun resolution. Specifically, we directly utilize the p</context>
<context position="7422" citStr="Luo and Zitouni (2005)" startWordPosition="1146" endWordPosition="1149">ct of a sentence, a subject of a clause, or not. Object: whether the candidate is an object of a verb, an object of a preposition, or not. Distance: the sentence distance between the candidate and the pronominal anaphor. Closeness: whether the candidate is the candidate closest to the pronominal anaphor. FirstNP: whether the candidate is the first noun phrase in the current sentence. Parallelism: whether the candidate has an identical collocation pattern with the pronominal anaphor. Table 1: Feature set for the baseline pronoun resolution system salience measures have to be assigned manually. Luo and Zitouni (2005) proposed a coreference resolution approach which also explores the information from the syntactic parse trees. Different from Lappin and Leass (1994)’s algorithm, they employed a maximum entropy based model to automatically compute the importance (in terms of weights) of the features extracted from the trees. In their work, the selection of their features is mainly inspired by the government and binding theory, aiming to capture the c-command relationships between the pronoun and its antecedent candidate. By contrast, our approach simply utilizes the parse trees as a structured feature, and l</context>
<context position="26992" citStr="Luo and Zitouni (2005)" startWordPosition="4375" endWordPosition="4378">rovement can even be achieved for NPaper. This indicates that the structured feature can effectively provide the syntactic information NORM NORM - subj/obj NORM + S Simple NORM + S Simple - subj/obj NORM + Luo05 Table 5: Comparison of the structured feature and the flat features extracted from parse trees Feature Parser NWire NPaper BNews Charniak00 73.2 82.7 82.3 S Simple Collins99 75.1 83.2 80.4 NORM+ Charniak00 79.2 82.7 82.3 S Simple Collins99 80.8 81.5 82.3 Table 6: Results using different parsers important for pronoun resolution. We also tested the flat syntactic feature set proposed in Luo and Zitouni (2005)’s work. As described in Section 2, the feature set is inspired the binding theory, including those features like whether the candidate is c commanding the pronoun, and the counts of “NP”, “VP”, “S” nodes in the commanding path. The last line of Table 5 shows the results by adding these features into the normal feature set. In line with the reports in (Luo and Zitouni, 2005) we do observe the performance improvement against the baseline (NORM) for all the domains. However, the increase in the success rates (up to 1.3%) is not so large as by adding the structured feature (NORM+S Simple) instead</context>
</contexts>
<marker>Luo, Zitouni, 2005</marker>
<rawString>X. Luo and I. Zitouni. 2005. Milti-lingual coreference resolution with syntactic features. In Proceedings of Human Language Techonology conference and Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP), pages 660–667.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mitkov</author>
</authors>
<title>Robust pronoun resolution with limited knowledge.</title>
<date>1998</date>
<booktitle>In Proceedings of the 17th Int. Conference on Computational Linguistics,</booktitle>
<pages>869--875</pages>
<contexts>
<context position="2065" citStr="Mitkov, 1998" startWordPosition="309" endWordPosition="310">s from the parse trees of the text. The issue that arises is how to effectively incorporate the syntactic information embedded in the parse trees to help resolution. One common solution seen in previous work is to define a set of features that represent particular syntactic knowledge, such as the grammatical role of the antecedent candidates, the governing relations between the candidate and the pronoun, and so on. These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005). However, such a solution has its limitation. The syntactic features have to be selected and defined manually, usually by linguistic intuition. Unfortunately, what kinds of syntactic information are effective for pronoun resolution still remains an open question in this research community. The heuristically selected feature set may be insufficient to represent all the information necessary for pronoun resolution contained in the parse trees. In this paper we will explore how to utilize the sy</context>
</contexts>
<marker>Mitkov, 1998</marker>
<rawString>R. Mitkov. 1998. Robust pronoun resolution with limited knowledge. In Proceedings of the 17th Int. Conference on Computational Linguistics, pages 869– 875.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Moschitti</author>
</authors>
<title>A study on convolution kernels for shallow semantic parsing.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL’04),</booktitle>
<pages>335--342</pages>
<contexts>
<context position="3269" citStr="Moschitti, 2004" startWordPosition="492" endWordPosition="493">ilize the syntactic parse trees to help learning-based pronoun resolution. Specifically, we directly utilize the parse trees as a structured feature, and then use a kernel-based method to automatically mine the knowledge embedded in the parse trees. The structured syntactic feature, together with other normal features, is incorporated in a trainable model based on Support Vector Machine (SVM) (Vapnik, 1995) to learn the decision classifier for resolution. Indeed, using kernel methods to mine structural knowledge has shown success in some NLP applications like parsing (Collins and Duffy, 2002; Moschitti, 2004) and relation extraction (Zelenko et al., 2003; Zhao and Grishman, 2005). However, to our knowledge, the application of such a technique to the pronoun resolution task still remains unexplored. Compared with previous work, our approach has several advantages: (1) The approach utilizes the parse trees as a structured feature, which avoids the efforts of decoding the parse trees into a set of syntactic features in a heuristic manner. (2) The approach is able to put together the structured feature and the normal flat features in a trainable model, which allows different types of 41 Proceedings of</context>
<context position="15759" citStr="Moschitti (2004)" startWordPosition="2516" endWordPosition="2517">the subtree of “PP” (for “in the room”) is fully expanded and all its children nodes are included in Full-Expansion. Note that to distinguish from other words, we explicitly mark up in the structured feature the pronoun and the antecedent candidate under consideration, by appending a string tag “ANA” and “CANDI” in their respective nodes (e.g.,“NNCANDI” for “man” and “PRP-ANA” for “him” as shown in Figure 1). 4.3 Structural Kernel and Composite Kernel To calculate the similarity between two structured features, we use the convolution tree kernel that is defined by Collins and Duffy (2002) and Moschitti (2004). Given two trees, the kernel will enumerate all their subtrees and use the number of common subtrees as the measure of the similarity between the trees. As has been proved, the convolution kernel can be efficiently computed in polynomial time. The above tree kernel only aims for the structured feature. We also need a composite kernel to combine together the structured feature and the normal features described in Section 3.1. In our study we define the composite kernel as follows: Kn(x1, x2) Kt(x1, x2) Kc(x1, x2) = |Kn(x1, x2) |∗ |Kt(x1, x2)|(2) where Kt is the convolution tree kernel defined </context>
<context position="17724" citStr="Moschitti (2004)" startWordPosition="2834" endWordPosition="2835">g and testing respectively. Each of these sets is further divided into three domains: newswire (NWire), newspaper (NPaper), and broadcast news (BNews). An input raw text was preprocessed automatically by a pipeline of NLP components, including sentence boundary detection, POS-tagging, Text Chunking and Named-Entity Recognition. The texts were parsed using the maximum-entropybased Charniak parser (Charniak, 2000), based on which the structured features were computed automatically. For learning, the SVM-Light software (Joachims, 1999) was employed with the convolution tree kernel implemented by Moschitti (2004). All classifiers were trained with default learning parameters. The performance was evaluated based on the metric success, the ratio of the number of correctly resolved5 anaphor over the number of all anaphors. For each anaphor, the NPs occurring within the current and previous two sentences were taken as the initial antecedent candidates. Those with mismatched number and gender agreements were filtered from the candidate set. Also, pronouns or NEs that disagreed in person with the anaphor were removed in advance. For training, there were 1207, 1440, and 1260 pronouns with non-empty candidate</context>
</contexts>
<marker>Moschitti, 2004</marker>
<rawString>A. Moschitti. 2004. A study on convolution kernels for shallow semantic parsing. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL’04), pages 335–342.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Ng</author>
<author>C Cardie</author>
</authors>
<title>Improving machine learning approaches to coreference resolution.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>104--111</pages>
<location>Philadelphia.</location>
<contexts>
<context position="8297" citStr="Ng and Cardie (2002)" startWordPosition="1282" endWordPosition="1285">ms of weights) of the features extracted from the trees. In their work, the selection of their features is mainly inspired by the government and binding theory, aiming to capture the c-command relationships between the pronoun and its antecedent candidate. By contrast, our approach simply utilizes the parse trees as a structured feature, and lets the learning algorithm discover all possible embedded information that is necessary for pronoun resolution. 3 The Resolution Framework Our pronoun resolution system adopts the common learning-based framework similar to those by Soon et al. (2001) and Ng and Cardie (2002). In the learning framework, a training or testing instance is formed by a pronoun and one of its antecedent candidate. During training, for each pronominal anaphor encountered, a positive instance is created by paring the anaphor and its closest antecedent. Also a set of negative instances is formed by paring the anaphor with each of the 42 non-coreferential candidates. Based on the training instances, a binary classifier is generated using a particular learning algorithm. During resolution, a pronominal anaphor to be resolved is paired in turn with each preceding antecedent candidate to form</context>
</contexts>
<marker>Ng, Cardie, 2002</marker>
<rawString>V. Ng and C. Cardie. 2002. Improving machine learning approaches to coreference resolution. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 104–111, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Soon</author>
<author>H Ng</author>
<author>D Lim</author>
</authors>
<title>A machine learning approach to coreference resolution of noun phrases.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>4</issue>
<pages>544</pages>
<contexts>
<context position="8272" citStr="Soon et al. (2001)" startWordPosition="1277" endWordPosition="1280"> the importance (in terms of weights) of the features extracted from the trees. In their work, the selection of their features is mainly inspired by the government and binding theory, aiming to capture the c-command relationships between the pronoun and its antecedent candidate. By contrast, our approach simply utilizes the parse trees as a structured feature, and lets the learning algorithm discover all possible embedded information that is necessary for pronoun resolution. 3 The Resolution Framework Our pronoun resolution system adopts the common learning-based framework similar to those by Soon et al. (2001) and Ng and Cardie (2002). In the learning framework, a training or testing instance is formed by a pronoun and one of its antecedent candidate. During training, for each pronominal anaphor encountered, a positive instance is created by paring the anaphor and its closest antecedent. Also a set of negative instances is formed by paring the anaphor with each of the 42 non-coreferential candidates. Based on the training instances, a binary classifier is generated using a particular learning algorithm. During resolution, a pronominal anaphor to be resolved is paired in turn with each preceding ant</context>
</contexts>
<marker>Soon, Ng, Lim, 2001</marker>
<rawString>W. Soon, H. Ng, and D. Lim. 2001. A machine learning approach to coreference resolution of noun phrases. Computational Linguistics, 27(4):521– 544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Vapnik</author>
</authors>
<title>The Nature of Statistical Learning Theory.</title>
<date>1995</date>
<publisher>Springer.</publisher>
<contexts>
<context position="3063" citStr="Vapnik, 1995" startWordPosition="461" endWordPosition="462">mmunity. The heuristically selected feature set may be insufficient to represent all the information necessary for pronoun resolution contained in the parse trees. In this paper we will explore how to utilize the syntactic parse trees to help learning-based pronoun resolution. Specifically, we directly utilize the parse trees as a structured feature, and then use a kernel-based method to automatically mine the knowledge embedded in the parse trees. The structured syntactic feature, together with other normal features, is incorporated in a trainable model based on Support Vector Machine (SVM) (Vapnik, 1995) to learn the decision classifier for resolution. Indeed, using kernel methods to mine structural knowledge has shown success in some NLP applications like parsing (Collins and Duffy, 2002; Moschitti, 2004) and relation extraction (Zelenko et al., 2003; Zhao and Grishman, 2005). However, to our knowledge, the application of such a technique to the pronoun resolution task still remains unexplored. Compared with previous work, our approach has several advantages: (1) The approach utilizes the parse trees as a structured feature, which avoids the efforts of decoding the parse trees into a set of </context>
<context position="9840" citStr="Vapnik, 1995" startWordPosition="1524" endWordPosition="1525">her learning-based approaches, the knowledge for the reference determination is represented as a set of features associated with the training or test instances. In our baseline system, the features adopted include lexical property, morphologic type, distance, salience, parallelism, grammatical role and so on. Listed in Table 1, all these features have been proved effective for pronoun resolution in previous work. 3.2 Support Vector Machine In theory, any discriminative learning algorithm is applicable to learn the classifier for pronoun resolution. In our study, we use Support Vector Machine (Vapnik, 1995) to allow the use of kernels to incorporate the structured feature. Suppose the training set S consists of labelled vectors {(xi, yi)}, where xi is the feature vector of a training instance and yi is its class label. The classifier learned by SVM is f(x) = sgn( � yiaix * xi + b) (1) i=1 where ai is the learned parameter for a support vector xi. An instance x is classified as positive (negative) if f(x) &gt; 0 (f(x) &lt; 0)1. One advantage of SVM is that we can use kernel methods to map a feature space to a particular high-dimension space, in case that the current problem could not be separated in a </context>
</contexts>
<marker>Vapnik, 1995</marker>
<rawString>V. Vapnik. 1995. The Nature of Statistical Learning Theory. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Yang</author>
<author>J Su</author>
<author>G Zhou</author>
<author>C Tan</author>
</authors>
<title>Improving pronoun resolution by incorporating coreferential information of candidates.</title>
<date>2004</date>
<booktitle>In Proceedings of 42th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>127--134</pages>
<location>Barcelona.</location>
<contexts>
<context position="2143" citStr="Yang et al., 2004" startWordPosition="319" endWordPosition="322">ively incorporate the syntactic information embedded in the parse trees to help resolution. One common solution seen in previous work is to define a set of features that represent particular syntactic knowledge, such as the grammatical role of the antecedent candidates, the governing relations between the candidate and the pronoun, and so on. These features are calculated by mining the parse trees, and then could be used for resolution by using manually designed rules (Lappin and Leass, 1994; Kennedy and Boguraev, 1996; Mitkov, 1998), or using machine-learning methods (Aone and Bennett, 1995; Yang et al., 2004; Luo and Zitouni, 2005). However, such a solution has its limitation. The syntactic features have to be selected and defined manually, usually by linguistic intuition. Unfortunately, what kinds of syntactic information are effective for pronoun resolution still remains an open question in this research community. The heuristically selected feature set may be insufficient to represent all the information necessary for pronoun resolution contained in the parse trees. In this paper we will explore how to utilize the syntactic parse trees to help learning-based pronoun resolution. Specifically, w</context>
</contexts>
<marker>Yang, Su, Zhou, Tan, 2004</marker>
<rawString>X. Yang, J. Su, G. Zhou, and C. Tan. 2004. Improving pronoun resolution by incorporating coreferential information of candidates. In Proceedings of 42th Annual Meeting of the Association for Computational Linguistics, pages 127–134, Barcelona.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Zelenko</author>
<author>C Aone</author>
<author>A Richardella</author>
</authors>
<title>Kernel methods for relation extraction.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<volume>3</volume>
<issue>6</issue>
<pages>1106</pages>
<contexts>
<context position="3315" citStr="Zelenko et al., 2003" startWordPosition="497" endWordPosition="500">arning-based pronoun resolution. Specifically, we directly utilize the parse trees as a structured feature, and then use a kernel-based method to automatically mine the knowledge embedded in the parse trees. The structured syntactic feature, together with other normal features, is incorporated in a trainable model based on Support Vector Machine (SVM) (Vapnik, 1995) to learn the decision classifier for resolution. Indeed, using kernel methods to mine structural knowledge has shown success in some NLP applications like parsing (Collins and Duffy, 2002; Moschitti, 2004) and relation extraction (Zelenko et al., 2003; Zhao and Grishman, 2005). However, to our knowledge, the application of such a technique to the pronoun resolution task still remains unexplored. Compared with previous work, our approach has several advantages: (1) The approach utilizes the parse trees as a structured feature, which avoids the efforts of decoding the parse trees into a set of syntactic features in a heuristic manner. (2) The approach is able to put together the structured feature and the normal flat features in a trainable model, which allows different types of 41 Proceedings of the 21st International Conference on Computat</context>
</contexts>
<marker>Zelenko, Aone, Richardella, 2003</marker>
<rawString>D. Zelenko, C. Aone, and A. Richardella. 2003. Kernel methods for relation extraction. Journal of Machine Learning Research, 3(6):1083 – 1106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Zhao</author>
<author>R Grishman</author>
</authors>
<title>Extracting relations with integrated information using kernel methods.</title>
<date>2005</date>
<booktitle>In Proceedings of 43rd Annual Meeting of the Association for Computational Linguistics (ACL05),</booktitle>
<pages>419--426</pages>
<contexts>
<context position="3341" citStr="Zhao and Grishman, 2005" startWordPosition="501" endWordPosition="504">esolution. Specifically, we directly utilize the parse trees as a structured feature, and then use a kernel-based method to automatically mine the knowledge embedded in the parse trees. The structured syntactic feature, together with other normal features, is incorporated in a trainable model based on Support Vector Machine (SVM) (Vapnik, 1995) to learn the decision classifier for resolution. Indeed, using kernel methods to mine structural knowledge has shown success in some NLP applications like parsing (Collins and Duffy, 2002; Moschitti, 2004) and relation extraction (Zelenko et al., 2003; Zhao and Grishman, 2005). However, to our knowledge, the application of such a technique to the pronoun resolution task still remains unexplored. Compared with previous work, our approach has several advantages: (1) The approach utilizes the parse trees as a structured feature, which avoids the efforts of decoding the parse trees into a set of syntactic features in a heuristic manner. (2) The approach is able to put together the structured feature and the normal flat features in a trainable model, which allows different types of 41 Proceedings of the 21st International Conference on Computational Linguistics and 44th</context>
</contexts>
<marker>Zhao, Grishman, 2005</marker>
<rawString>S. Zhao and R. Grishman. 2005. Extracting relations with integrated information using kernel methods. In Proceedings of 43rd Annual Meeting of the Association for Computational Linguistics (ACL05), pages 419–426.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>