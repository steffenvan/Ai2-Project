<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000131">
<title confidence="0.996131">
First-Order Probabilistic Models for Coreference Resolution
</title>
<author confidence="0.998451">
Aron Culotta and Michael Wick and Andrew McCallum
</author>
<affiliation confidence="0.998445">
Department of Computer Science
University of Massachusetts
</affiliation>
<address confidence="0.860891">
Amherst, MA 01003
</address>
<email confidence="0.999535">
{culotta,mwick,mccallum}@cs.umass.edu
</email>
<sectionHeader confidence="0.996672" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999831">
Traditional noun phrase coreference res-
olution systems represent features only
of pairs of noun phrases. In this paper,
we propose a machine learning method
that enables features over sets of noun
phrases, resulting in a first-order proba-
bilistic model for coreference. We out-
line a set of approximations that make this
approach practical, and apply our method
to the ACE coreference dataset, achiev-
ing a 45% error reduction over a com-
parable method that only considers fea-
tures of pairs of noun phrases. This result
demonstrates an example of how a first-
order logic representation can be incorpo-
rated into a probabilistic model and scaled
efficiently.
</bodyText>
<sectionHeader confidence="0.998883" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999863692307692">
Noun phrase coreference resolution is the problem
of clustering noun phrases into anaphoric sets. A
standard machine learning approach is to perform a
set of independent binary classifications of the form
“Is mention a coreferent with mention b?”
This approach of decomposing the problem into
pairwise decisions presents at least two related diffi-
culties. First, it is not clear how best to convert the
set of pairwise classifications into a disjoint cluster-
ing of noun phrases. The problem stems from the
transitivity constraints of coreference: If a and b are
coreferent, and b and c are coreferent, then a and c
must be coreferent.
</bodyText>
<page confidence="0.978715">
81
</page>
<bodyText confidence="0.9999585">
This problem has recently been addressed by a
number of researchers. A simple approach is to per-
form the transitive closure of the pairwise decisions.
However, as shown in recent work (McCallum and
Wellner, 2003; Singla and Domingos, 2005), bet-
ter performance can be obtained by performing rela-
tional inference to directly consider the dependence
among a set of predictions. For example, McCal-
lum and Wellner (2005) apply a graph partitioning
algorithm on a weighted, undirected graph in which
vertices are noun phrases and edges are weighted by
the pairwise score between noun phrases.
A second and less studied difficulty is that the
pairwise decomposition restricts the feature set to
evidence about pairs of noun phrases only. This re-
striction can be detrimental if there exist features of
sets of noun phrases that cannot be captured by a
combination of pairwise features. As a simple exam-
ple, consider prohibiting coreferent sets that consist
only of pronouns. That is, we would like to require
that there be at least one antecedent for a set of pro-
nouns. The pairwise decomposition does not make
it possible to capture this constraint.
In general, we would like to construct arbitrary
features over a cluster of noun phrases using the
full expressivity of first-order logic. Enabling this
sort of flexible representation within a statistical
model has been the subject of a long line of research
on first-order probabilistic models (Gaifman, 1964;
Halpern, 1990; Paskin, 2002; Poole, 2003; Richard-
son and Domingos, 2006).
Conceptually, a first-order probabilistic model
can be described quite compactly. A configura-
tion of the world is represented by a set of predi-
</bodyText>
<note confidence="0.8295085">
Proceedings of NAACL HLT 2007, pages 81–88,
Rochester, NY, April 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.9994074">
Choosing the closest preceding phrase is common
because nearby phrases are a priori more likely to
be coreferent.
We refer to the training and inference methods de-
scribed in this section as the Pairwise Model.
</bodyText>
<sectionHeader confidence="0.988285" genericHeader="method">
3 First-Order Logic Model
</sectionHeader>
<equation confidence="0.393505">
k
</equation>
<bodyText confidence="0.999711487804879">
where ZX; is a normalizer that sums over the two
settings of yj.
Note that this model gives us the representational
power of recently proposed Markov logic networks
(Richardson and Domingos, 2006); that is, we can
construct arbitrary formulae in first-order logic to
characterize the noun coreference task, and can learn
weights for instantiations of these formulae. How-
ever, naively grounding the corresponding Markov
logic network results in a combinatorial explosion of
variables. Below we outline methods to scale train-
ing and prediction with this representation.
As in the Pairwise Model, we must decide how to
sample training examples and how to combine inde-
pendent classifications at testing time. It is impor-
tant to note that by moving to the First-Order Logic
Model, the number of possible predictions has in-
creased exponentially. In the Pairwise Model, the
number of possible y variables is O(|x|2), where
x is the set of noun phrases. In the First-Order
Logic Model, the number of possible y variables is
O(21&amp;quot;l): There is a y variable for each possible el-
ement of the powerset of x. Of course, we do not
enumerate this set; rather, we incrementally instan-
tiate y variables as needed during prediction.
A simple method to generate training examples
is to sample positive and negative cluster examples
uniformly at random from the training data. Positive
examples are generated by first sampling a true clus-
ter, then sampling a subset of that cluster. Negative
examples are generated by sampling two positive ex-
amples and merging them into the same cluster.
At testing time, we perform standard greedy ag-
glomerative clustering, where the score for each
merger is proportional to the probability of the
newly formed clustering according to the model.
Clustering terminates when there exists no addi-
tional merge that improves the probability of the
clustering.
We refer to the system described in this section as
First-Order Uniform.
</bodyText>
<sectionHeader confidence="0.988343" genericHeader="method">
4 Error-driven and Rank-based training
</sectionHeader>
<subsectionHeader confidence="0.559381">
of the First-Order Model
</subsectionHeader>
<bodyText confidence="0.997670926829269">
In this section we propose two enhancements to
the training procedure for the First-Order Uniform
model.
First, because each training example consists of
a subset of noun phrases, the number of possible
training examples we can generate is exponential in
the number of noun phrases. We propose an error-
driven sampling method that generates training ex-
amples from errors the model makes on the training
data. The algorithm is as follows: Given initial pa-
rameters A, perform greedy agglomerative cluster-
ing on training document i until an incorrect cluster
is formed. Update the parameter vector according to
this mistake, then repeat for the next training docu-
ment. This process is repeated for a fixed number of
iterations.
Exactly how to update the parameter vector is ad-
dressed by the second enhancement. We propose
modifying the optimization criterion of training to
perform ranking rather than classification of clus-
ters. Consider a training example cluster with a neg-
ative label, indicating that not all of the noun phrases
it contains are coreferent. A classification training
algorithm will “penalize” all the features associated
with this cluster, since they correspond to a negative
example. However, because there may exists subsets
of the cluster that are coreferent, features represent-
ing these positive subsets may be unjustly penalized.
To address this problem, we propose constructing
training examples consisting of one negative exam-
We propose augmenting the Pairwise Model to
enable classification decisions over sets of noun
phrases.
Given a set of noun phrases xj = {xi}, let the bi-
nary random variable yj be 1 if all the noun phrases
xi E xj are coreferent. The features fk and weights
Ak are defined as before, but now the features can
represent arbitrary attributes over the entire set xj.
This allows us to use the full flexibility of first-order
logic to construct features about sets of nouns. The
First-Order Logic Model is
</bodyText>
<equation confidence="0.7172945">
1
p(yj |xj) = ZX; exp 1:Akfk(xj, yj)
</equation>
<page confidence="0.777599">
83
</page>
<figure confidence="0.99756">
x1
ft
y13 fc
y23
x3
x2
fc
y12
fc
x2
fc
</figure>
<figureCaption confidence="0.7306755">
Figure 2: An example noun coreference factor graph
for the Pairwise Model in which factors f, model the
coreference between two nouns, and ft enforce the
transitivity among related decisions. The number of
y variables increases quadratically in the number of
x variables.
</figureCaption>
<bodyText confidence="0.929528371428572">
ple and one “nearby” positive example. In particular,
when agglomerative clustering incorrectly merges
two clusters, we select the resulting cluster as the
negative example, and select as the positive example
a cluster that can be created by merging other exist-
ing clusters.1 We then update the weight vector so
that the positive example is assigned a higher score
than the negative example. This approach allows
the update to only penalize the difference between
the two features of examples, thereby not penaliz-
ing features representing any overlapping coreferent
clusters.
To implement this update, we use MIRA (Mar-
gin Infused Relaxed Algorithm), a relaxed, online
maximum margin training algorithm (Crammer and
Singer, 2003). It updates the parameter vector with
two constraints: (1) the positive example must have
a higher score by a given margin, and (2) the change
to A should be minimal. This second constraint is
to reduce fluctuations in A. Let s+(A, xj) be the
unnormalized score for the positive example and
s−(A,xk) be the unnormalized score of the neg-
ative example. Each update solves the following
1Of the possible positive examples, we choose the one with
the highest probability under the current model to guard against
large fluctuations in parameter updates
fc
Figure 3: An example noun coreference factor graph
for the First-Order Model in which factors f, model
the coreference between sets of nouns, and ft en-
force the transitivity among related decisions. Here,
the additional node y123 indicates whether nouns
{x1, x2, x3} are all coreferent. The number of y
variables increases exponentially in the number of
x variables.
</bodyText>
<equation confidence="0.8912424">
quadratic program:
At+1 = argmin
A
s.t.
s+(A, xj) − s−(A, xk) ≥ 1
</equation>
<bodyText confidence="0.999811857142857">
In this case, MIRA with a single constraint can be
efficiently solved in one iteration of the Hildreth and
D’Esopo method (Censor and Zenios, 1997). Ad-
ditionally, we average the parameters calculated at
each iteration to improve convergence.
We refer to the system described in this section as
First-Order MIRA.
</bodyText>
<sectionHeader confidence="0.965191" genericHeader="method">
5 Probabilistic Interpretation
</sectionHeader>
<bodyText confidence="0.999863">
In this section, we describe the Pairwise and First-
Order models in terms of the factor graphs they ap-
proximate.
For the Pairwise Model, a corresponding undi-
rected graphical model can be defined as
</bodyText>
<equation confidence="0.492492285714286">
1 P(y|x) = ZX ri
yijEY
ri ft(yij, yj,k, yik, xij, xjk, xik)
yij,yjkEY
x1
y123
fc
y13 fc
ft
y12
y23
x3
||At − A||2
f�(yij, xij)
</equation>
<page confidence="0.985005">
84
</page>
<bodyText confidence="0.999894970588235">
where Zx is the input-dependent normalizer and fac-
tor fc parameterizes the pairwise noun phrase com-
patibility as fc(yij, xij) = exp(Ek λkfk(yij, xij)).
Factor ft enforces the transitivity constraints by
ft(·) = −oc if transitivity is not satisfied, 1 oth-
erwise. This is similar to the model presented in
McCallum and Wellner (2005). A factor graph for
the Pairwise Model is presented in Figure 2 for three
noun phrases.
For the First-Order model, an undirected graphi-
cal model can be defined as
where Zx is the input-dependent nor-
malizer and factor fc parameterizes the
cluster-wise noun phrase compatibility as
fc(yj, xj) = exp(Ek λkfk(yj, xj)). Again,
factor ft enforces the transitivity constraints by
ft(·) = −oc if transitivity is not satisfied, 1 other-
wise. Here, transitivity is a bit more complicated,
since it also requires that if yj = 1, then for any
subset xk C_ xj, yk = 1. A factor graph for the
First-Order Model is presented in Figure 3 for three
noun phrases.
The methods described in Sections 2, 3 and 4 can
be viewed as estimating the parameters of each fac-
tor fc independently. This approach can therefore
be viewed as a type of piecewise approximation of
exact parameter estimation in these models (Sutton
and McCallum, 2005). Here, each fc is a “piece”
of the model trained independently. These pieces
are combined at prediction time using clustering al-
gorithms to enforce transitivity. Sutton and McCal-
lum (2005) show that such a piecewise approxima-
tion can be theoretically justified as minimizing an
upper bound of the exact loss function.
</bodyText>
<sectionHeader confidence="0.999563" genericHeader="method">
6 Experiments
</sectionHeader>
<subsectionHeader confidence="0.972014">
6.1 Data
</subsectionHeader>
<bodyText confidence="0.999962333333333">
We apply our approach to the noun coreference ACE
2004 data, containing 443 news documents with
28,135 noun phrases to be coreferenced. 336 doc-
uments are used for training, and the remainder for
testing. All entity types are candidates for corefer-
ence (pronouns, named entities, and nominal enti-
ties). We use the true entity segmentation, and parse
each sentence in the corpus using a phrase-structure
grammar, as is common for this task.
</bodyText>
<subsectionHeader confidence="0.976669">
6.2 Features
</subsectionHeader>
<bodyText confidence="0.982131">
We follow Soon et al. (2001) and Ng and Cardie
(2002) to generate most of our features for the Pair-
wise Model. These include:
</bodyText>
<listItem confidence="0.999508173913043">
• Match features - Check whether gender, num-
ber, head text, or entire phrase matches
• Mention type (pronoun, name, nominal)
• Aliases - Heuristically decide if one noun is the
acronym of the other
• Apposition - Heuristically decide if one noun is
in apposition to the other
• Relative Pronoun - Heuristically decide if one
noun is a relative pronoun referring to the other.
• Wordnet features - Use Wordnet to decide if
one noun is a hypernym, synonym, or antonym
of another, or if they share a hypernym.
• Both speak - True if both contain an adjacent
context word that is a synonym of “said.” This
is a domain-specific feature that helps for many
newswire articles.
• Modifiers Match - for example, in the phrase
“President Clinton”, “President” is a modifier
of “Clinton”. This feature indicates if one noun
is a modifier of the other, or they share a modi-
fier.
• Substring - True if one noun is a substring of
the other (e.g. “Egypt” and “Egyptian”).
</listItem>
<bodyText confidence="0.608174875">
The First-Order Model includes the following fea-
tures:
• Enumerate each pair of noun phrases and com-
pute the features listed above. All-X is true if
all pairs share a feature X, Most-True-X is true
if the majority of pairs share a feature X, and
Most-False-X is true if most of the pairs do not
share feature X.
</bodyText>
<equation confidence="0.970619">
P(y|x) = 1 jT fc(yj, xj)
Zx yj Ely
ri ft(yj, xj)
yjEy
</equation>
<page confidence="0.996293">
85
</page>
<listItem confidence="0.872644833333333">
• Use the output of the Pairwise Model for each
pair of nouns. All-True is true if all pairs are
predicted to be coreferent, Most-True is true if
most pairs are predicted to be coreferent, and
Most-False is true if most pairs are predicted
to not be coreferent. Additionally, Max-True
is true if the maximum pairwise score is above
threshold, and Min-True if the minimum pair-
wise score is above threshold.
• Cluster Size indicates the size of the cluster.
• Count how many phrases in the cluster are
of each mention type (name, pronoun, nom-
inal), number (singular/plural) and gender
(male/female). The features All-X and Most-
True-X indicate how frequent each feature is
in the cluster. This feature can capture the soft
constraint such that no cluster consists only of
pronouns.
</listItem>
<bodyText confidence="0.989887">
In addition to the listed features, we also include
conjunctions of size 2, for example “Genders match
AND numbers match”.
</bodyText>
<subsectionHeader confidence="0.993003">
6.3 Evaluation
</subsectionHeader>
<bodyText confidence="0.999968">
We use the B3 algorithm to evaluate the predicted
coreferent clusters (Amit and Baldwin, 1998). B3
is common in coreference evaluation and is similar
to the precision and recall of coreferent links, ex-
cept that systems are rewarded for singleton clus-
ters. For each noun phrase xi, let ci be the number
of mentions in xi’s predicted cluster that are in fact
coreferent with xi (including xi itself). Precision for
xi is defined as ci divided by the number of noun
phrases in xi’s cluster. Recall for xi is defined as
the ci divided by the number of mentions in the gold
standard cluster for xi. F1 is the harmonic mean of
recall and precision.
</bodyText>
<subsectionHeader confidence="0.534999">
6.4 Results
</subsectionHeader>
<bodyText confidence="0.9998084">
In addition to Pairwise, First-Order Uniform, and
First-Order MIRA, we also compare against Pair-
wise MIRA, which differs from First-Order MIRA
only by the fact that it is restricted to pairwise fea-
tures.
</bodyText>
<tableCaption confidence="0.774466333333333">
Table 1 suggests both that first-order features and
error-driven training can greatly improve perfor-
mance. The First-Order Model outperforms the Pair-
</tableCaption>
<table confidence="0.9992748">
F1 Prec Rec
First-Order MIRA 79.3 86.7 73.2
Pairwise MIRA 72.5 92.0 59.8
First-Order Uniform 69.2 79.0 61.5
Pairwise 62.4 62.5 62.3
</table>
<tableCaption confidence="0.989925">
Table 1: B3 results for ACE noun phrase corefer-
</tableCaption>
<bodyText confidence="0.990701878787879">
ence. FIRST-ORDER MIRA is our proposed model
that takes advantage of first-order features of the
data and is trained with error-driven and rank-based
methods. We see that both the first-order features
and the training enhancements improve performance
consistently.
wise Model in F1 measure for both standard train-
ing and error-driven training. We attribute some of
this improvement to the capability of the First-Order
model to capture features of entire clusters that may
indicate some phrases are not coreferent. Also, we
attribute the gains from error-driven training to the
fact that training examples are generated based on
errors made on the training data. (However, we
should note that there are also small differences in
the feature sets used for error-driven and standard
training results.)
Error analysis indicates that often noun xi is cor-
rectly not merged with a cluster xj when xj has a
strong internal coherence. For example, if all 5 men-
tions of France in a document are string identical,
then the system will be extremely cautious of merg-
ing a noun that is not equivalent to France into xj,
since this will turn off the “All-String-Match” fea-
ture for cluster xj.
To our knowledge, the best results on this dataset
were obtained by the meta-classification scheme of
Ng (2005). Although our train-test splits may differ
slightly, the best B-Cubed F1 score reported in Ng
(2005) is 69.3%, which is considerably lower than
the 79.3% obtained with our method. Also note that
the Pairwise baseline obtains results similar to those
in Ng and Cardie (2002).
</bodyText>
<sectionHeader confidence="0.999714" genericHeader="method">
7 Related Work
</sectionHeader>
<bodyText confidence="0.95156075">
There has been a recent interest in training methods
that enable the use of first-order features (Paskin,
2002; Daum´e III and Marcu, 2005b; Richardson
and Domingos, 2006). Perhaps the most related is
</bodyText>
<page confidence="0.992565">
86
</page>
<bodyText confidence="0.999981793650794">
“learning as search optimization” (LASO) (Daum´e
III and Marcu, 2005b; Daum´e III and Marcu,
2005a). Like the current paper, LASO is also an
error-driven training method that integrates predic-
tion and training. However, whereas we explic-
itly use a ranking-based loss function, LASO uses
a binary classification loss function that labels each
candidate structure as correct or incorrect. Thus,
each LASO training example contains all candidate
predictions, whereas our training examples contain
only the highest scoring incorrect prediction and the
highest scoring correct prediction. Our experiments
show the advantages of this ranking-based loss func-
tion. Additionally, we provide an empirical study to
quantify the effects of different example generation
and loss function decisions.
Collins and Roark (2004) present an incremental
perceptron algorithm for parsing that uses “early up-
date” to update the parameters when an error is en-
countered. Our method uses a similar “early update”
in that training examples are only generated for the
first mistake made during prediction. However, they
do not investigate rank-based loss functions.
Others have attempted to train global scoring
functions using Gibbs sampling (Finkel et al., 2005),
message propagation, (Bunescu and Mooney, 2004;
Sutton and McCallum, 2004), and integer linear pro-
gramming (Roth and Yih, 2004). The main distinc-
tions of our approach are that it is simple to imple-
ment, not computationally intensive, and adaptable
to arbitrary loss functions.
There have been a number of machine learning
approaches to coreference resolution, traditionally
factored into classification decisions over pairs of
nouns (Soon et al., 2001; Ng and Cardie, 2002).
Nicolae and Nicolae (2006) combine pairwise clas-
sification with graph-cut algorithms. Luo et al.
(2004) do enable features between mention-cluster
pairs, but do not perform the error-driven and rank-
ing enhancements proposed in our work. Denis and
Baldridge (2007) use a ranking loss function for pro-
noun coreference; however the examples are still
pairs of pronouns, and the example generation is not
error driven. Ng (2005) learns a meta-classifier to
choose the best prediction from the output of sev-
eral coreference systems. While in theory a meta-
classifier can flexibly represent features, they do not
explore features using the full flexibility of first-
order logic. Also, their method is neither error-
driven nor rank-based.
McCallum and Wellner (2003) use a conditional
random field that factors into a product of pairwise
decisions about pairs of nouns. These pairwise de-
cisions are made collectively using relational infer-
ence; however, as pointed out in Milch et al. (2004),
this model has limited representational power since
it does not capture features of entities, only of pairs
of mention. Milch et al. (2005) address these issues
by constructing a generative probabilistic model,
where noun clusters are sampled from a generative
process. Our current work has similar representa-
tional flexibility as Milch et al. (2005) but is discrim-
inatively trained.
</bodyText>
<sectionHeader confidence="0.99658" genericHeader="conclusions">
8 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999981758620689">
We have presented learning and inference proce-
dures for coreference models using first-order fea-
tures. By relying on sampling methods at training
time and approximate inference methods at testing
time, this approach can be made scalable. This re-
sults in a coreference model that can capture features
over sets of noun phrases, rather than simply pairs of
noun phrases.
This is an example of a model with extremely
flexible representational power, but for which exact
inference is intractable. The simple approximations
we have described here have enabled this more flex-
ible model to outperform a model that is simplified
for tractability.
A short-term extension would be to consider fea-
tures over entire clusterings, such as the number of
clusters. This could be incorporated in a ranking
scheme, as in Ng (2005).
Future work will extend our approach to a wider
variety of tasks. The model we have described here
is specific to clustering tasks; however a similar for-
mulation could be used to approach a number of lan-
guage processing tasks, such as parsing and relation
extraction. These tasks could benefit from first-order
features, and the present work can guide the approx-
imations required in those domains.
Additionally, we are investigating more sophis-
ticated inference algorithms that will reduce the
greediness of the search procedures described here.
</bodyText>
<page confidence="0.998665">
87
</page>
<sectionHeader confidence="0.998157" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.992488357142857">
We thank Robert Hall for helpful contributions. This work
was supported in part by the Defense Advanced Research
Projects Agency (DARPA), through the Department of the
Interior, NBC, Acquisition Services Division, under con-
tract #NBCHD030010, in part by U.S. Government contract
#NBCH040171 through a subcontract with BBNT Solutions
LLC, in part by The Central Intelligence Agency, the National
Security Agency and National Science Foundation under NSF
grant #IIS-0326249, in part by Microsoft Live Labs, and in part
by the Defense Advanced Research Projects Agency (DARPA)
under contract #HR0011-06-C-0023. Any opinions, findings
and conclusions or recommendations expressed in this mate-
rial are the author(s)’ and do not necessarily reflect those of the
sponsor.
</bodyText>
<sectionHeader confidence="0.998336" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999876372093024">
B. Amit and B. Baldwin. 1998. Algorithms for scoring coref-
erence chains. In Proceedings of the Seventh Message Un-
derstanding Conference (MUC7).
Razvan Bunescu and Raymond J. Mooney. 2004. Collective
information extraction with relational markov networks. In
ACL.
Y. Censor and S.A. Zenios. 1997. Parallel optimization : the-
ory, algorithms, and applications. Oxford University Press.
Michael Collins and Brian Roark. 2004. Incremental parsing
with the perceptron algorithm. In ACL.
Koby Crammer and Yoram Singer. 2003. Ultraconservative
online algorithms for multiclass problems. JMLR, 3:951–
991.
Aron Culotta and Andrew McCallum. 2006. Tractable learn-
ing and inference with high-order representations. In ICML
Workshop on Open Problems in Statistical Relational Learn-
ing, Pittsburgh, PA.
Hal Daum´e III and Daniel Marcu. 2005a. A large-scale explo-
ration of effective global features for a joint entity detection
and tracking model. In HLT/EMNLP, Vancouver, Canada.
Hal Daum´e III and Daniel Marcu. 2005b. Learning as search
optimization: Approximate large margin methods for struc-
tured prediction. In ICML, Bonn, Germany.
Rodrigo de Salvo Braz, Eyal Amir, and Dan Roth. 2005. Lifted
first-order probabilistic inference. In IJCAI, pages 1319–
1325.
Pascal Denis and Jason Baldridge. 2007. A ranking approach
to pronoun resolution. In IJCAI.
Jenny Rose Finkel, Trond Grenager, and Christopher Manning.
2005. Incorporating non-local information into information
extraction systems by gibbs sampling. In ACL, pages 363–
370.
H. Gaifman. 1964. Concerning measures in first order calculi.
Israel J. Math, 2:1–18.
J. Y. Halpern. 1990. An analysis of first-order logics of proba-
bility. Artificial Intelligence, 46:311–350.
Xiaoqiang Luo, Abe Ittycheriah, Hongyan Jing, Nanda Kamb-
hatla, and Salim Roukos. 2004. A mention-synchronous
coreference resolution algorithm based on the Bell tree. In
ACL, page 135.
A. McCallum and B. Wellner. 2003. Toward conditional mod-
els of identity uncertainty with application to proper noun
coreference. In IJCAI Workshop on Information Integration
on the Web.
Andrew McCallum and Ben Wellner. 2005. Conditional mod-
els of identity uncertainty with application to noun corefer-
ence. In Lawrence K. Saul, Yair Weiss, and L´eon Bottou,
editors, NIPS17. MIT Press, Cambridge, MA.
Brian Milch, Bhaskara Marthi, and Stuart Russell. 2004.
BLOG: Relational modeling with unknown objects. In
ICML 2004 Workshop on Statistical Relational Learning and
Its Connections to Other Fields.
Brian Milch, Bhaskara Marthi, Stuart Russell, David Sontag,
Daniel L. Ong, and Andrey Kolobov. 2005. BLOG: Proba-
bilistic models with unknown objects. In IJCAI.
Vincent Ng and Claire Cardie. 2002. Improving machine learn-
ing approaches to coreference resolution. In ACL.
Vincent Ng. 2005. Machine learning for coreference resolu-
tion: From local classification to global ranking. In ACL.
Cristina Nicolae and Gabriel Nicolae. 2006. Bestcut: A graph
algorithm for coreference resolution. In EMNLP, pages
275–283, Sydney, Australia, July. Association for Compu-
tational Linguistics.
Mark A. Paskin. 2002. Maximum entropy probabilistic logic.
Technical Report UCB/CSD-01-1161, University of Califor-
nia, Berkeley.
D. Poole. 2003. First-order probabilistic inference. In IJCAI,
pages 985–991, Acapulco, Mexico. Morgan Kaufman.
Matthew Richardson and Pedro Domingos. 2006. Markov
logic networks. Machine Learning, 62:107–136.
D. Roth and W. Yih. 2004. A linear programming formulation
for global inference in natural language tasks. In The 8th
Conference on Compuational Natural Language Learning,
May.
Parag Singla and Pedro Domingos. 2005. Discriminative train-
ing of markov logic networks. In AAAI, Pittsburgh, PA.
Wee Meng Soon, Hwee Tou Ng, and Daniel Chung Yong Lim.
2001. A machine learning approach to coreference resolu-
tion of noun phrases. Comput. Linguist., 27(4):521–544.
Charles Sutton and Andrew McCallum. 2004. Collective seg-
mentation and labeling of distant entities in information ex-
traction. Technical Report TR # 04-49, University of Mas-
sachusetts, July.
Charles Sutton and Andrew McCallum. 2005. Piecewise train-
ing of undirected models. In 21st Conference on Uncertainty
in Artificial Intelligence.
</reference>
<page confidence="0.999406">
88
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.848521">
<title confidence="0.999598">First-Order Probabilistic Models for Coreference Resolution</title>
<author confidence="0.999341">Culotta Wick</author>
<affiliation confidence="0.9998075">Department of Computer University of</affiliation>
<address confidence="0.993778">Amherst, MA</address>
<abstract confidence="0.9915705">Traditional noun phrase coreference resolution systems represent features only of pairs of noun phrases. In this paper, we propose a machine learning method enables features over noun phrases, resulting in a first-order probabilistic model for coreference. We outline a set of approximations that make this approach practical, and apply our method to the ACE coreference dataset, achieving a 45% error reduction over a comparable method that only considers features of pairs of noun phrases. This result demonstrates an example of how a firstorder logic representation can be incorporated into a probabilistic model and scaled efficiently.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B Amit</author>
<author>B Baldwin</author>
</authors>
<title>Algorithms for scoring coreference chains.</title>
<date>1998</date>
<booktitle>In Proceedings of the Seventh Message Understanding Conference (MUC7).</booktitle>
<contexts>
<context position="14763" citStr="Amit and Baldwin, 1998" startWordPosition="2433" endWordPosition="2436"> above threshold. • Cluster Size indicates the size of the cluster. • Count how many phrases in the cluster are of each mention type (name, pronoun, nominal), number (singular/plural) and gender (male/female). The features All-X and MostTrue-X indicate how frequent each feature is in the cluster. This feature can capture the soft constraint such that no cluster consists only of pronouns. In addition to the listed features, we also include conjunctions of size 2, for example “Genders match AND numbers match”. 6.3 Evaluation We use the B3 algorithm to evaluate the predicted coreferent clusters (Amit and Baldwin, 1998). B3 is common in coreference evaluation and is similar to the precision and recall of coreferent links, except that systems are rewarded for singleton clusters. For each noun phrase xi, let ci be the number of mentions in xi’s predicted cluster that are in fact coreferent with xi (including xi itself). Precision for xi is defined as ci divided by the number of noun phrases in xi’s cluster. Recall for xi is defined as the ci divided by the number of mentions in the gold standard cluster for xi. F1 is the harmonic mean of recall and precision. 6.4 Results In addition to Pairwise, First-Order Un</context>
</contexts>
<marker>Amit, Baldwin, 1998</marker>
<rawString>B. Amit and B. Baldwin. 1998. Algorithms for scoring coreference chains. In Proceedings of the Seventh Message Understanding Conference (MUC7).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Razvan Bunescu</author>
<author>Raymond J Mooney</author>
</authors>
<title>Collective information extraction with relational markov networks.</title>
<date>2004</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="18926" citStr="Bunescu and Mooney, 2004" startWordPosition="3101" endWordPosition="3104">tionally, we provide an empirical study to quantify the effects of different example generation and loss function decisions. Collins and Roark (2004) present an incremental perceptron algorithm for parsing that uses “early update” to update the parameters when an error is encountered. Our method uses a similar “early update” in that training examples are only generated for the first mistake made during prediction. However, they do not investigate rank-based loss functions. Others have attempted to train global scoring functions using Gibbs sampling (Finkel et al., 2005), message propagation, (Bunescu and Mooney, 2004; Sutton and McCallum, 2004), and integer linear programming (Roth and Yih, 2004). The main distinctions of our approach are that it is simple to implement, not computationally intensive, and adaptable to arbitrary loss functions. There have been a number of machine learning approaches to coreference resolution, traditionally factored into classification decisions over pairs of nouns (Soon et al., 2001; Ng and Cardie, 2002). Nicolae and Nicolae (2006) combine pairwise classification with graph-cut algorithms. Luo et al. (2004) do enable features between mention-cluster pairs, but do not perfor</context>
</contexts>
<marker>Bunescu, Mooney, 2004</marker>
<rawString>Razvan Bunescu and Raymond J. Mooney. 2004. Collective information extraction with relational markov networks. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Censor</author>
<author>S A Zenios</author>
</authors>
<title>Parallel optimization : theory, algorithms, and applications.</title>
<date>1997</date>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="9737" citStr="Censor and Zenios, 1997" startWordPosition="1564" endWordPosition="1567"> large fluctuations in parameter updates fc Figure 3: An example noun coreference factor graph for the First-Order Model in which factors f, model the coreference between sets of nouns, and ft enforce the transitivity among related decisions. Here, the additional node y123 indicates whether nouns {x1, x2, x3} are all coreferent. The number of y variables increases exponentially in the number of x variables. quadratic program: At+1 = argmin A s.t. s+(A, xj) − s−(A, xk) ≥ 1 In this case, MIRA with a single constraint can be efficiently solved in one iteration of the Hildreth and D’Esopo method (Censor and Zenios, 1997). Additionally, we average the parameters calculated at each iteration to improve convergence. We refer to the system described in this section as First-Order MIRA. 5 Probabilistic Interpretation In this section, we describe the Pairwise and FirstOrder models in terms of the factor graphs they approximate. For the Pairwise Model, a corresponding undirected graphical model can be defined as 1 P(y|x) = ZX ri yijEY ri ft(yij, yj,k, yik, xij, xjk, xik) yij,yjkEY x1 y123 fc y13 fc ft y12 y23 x3 ||At − A||2 f�(yij, xij) 84 where Zx is the input-dependent normalizer and factor fc parameterizes the pa</context>
</contexts>
<marker>Censor, Zenios, 1997</marker>
<rawString>Y. Censor and S.A. Zenios. 1997. Parallel optimization : theory, algorithms, and applications. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Brian Roark</author>
</authors>
<title>Incremental parsing with the perceptron algorithm.</title>
<date>2004</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="18451" citStr="Collins and Roark (2004)" startWordPosition="3029" endWordPosition="3032">prediction and training. However, whereas we explicitly use a ranking-based loss function, LASO uses a binary classification loss function that labels each candidate structure as correct or incorrect. Thus, each LASO training example contains all candidate predictions, whereas our training examples contain only the highest scoring incorrect prediction and the highest scoring correct prediction. Our experiments show the advantages of this ranking-based loss function. Additionally, we provide an empirical study to quantify the effects of different example generation and loss function decisions. Collins and Roark (2004) present an incremental perceptron algorithm for parsing that uses “early update” to update the parameters when an error is encountered. Our method uses a similar “early update” in that training examples are only generated for the first mistake made during prediction. However, they do not investigate rank-based loss functions. Others have attempted to train global scoring functions using Gibbs sampling (Finkel et al., 2005), message propagation, (Bunescu and Mooney, 2004; Sutton and McCallum, 2004), and integer linear programming (Roth and Yih, 2004). The main distinctions of our approach are </context>
</contexts>
<marker>Collins, Roark, 2004</marker>
<rawString>Michael Collins and Brian Roark. 2004. Incremental parsing with the perceptron algorithm. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Yoram Singer</author>
</authors>
<title>Ultraconservative online algorithms for multiclass problems.</title>
<date>2003</date>
<journal>JMLR,</journal>
<volume>3</volume>
<pages>991</pages>
<contexts>
<context position="8605" citStr="Crammer and Singer, 2003" startWordPosition="1374" endWordPosition="1377">two clusters, we select the resulting cluster as the negative example, and select as the positive example a cluster that can be created by merging other existing clusters.1 We then update the weight vector so that the positive example is assigned a higher score than the negative example. This approach allows the update to only penalize the difference between the two features of examples, thereby not penalizing features representing any overlapping coreferent clusters. To implement this update, we use MIRA (Margin Infused Relaxed Algorithm), a relaxed, online maximum margin training algorithm (Crammer and Singer, 2003). It updates the parameter vector with two constraints: (1) the positive example must have a higher score by a given margin, and (2) the change to A should be minimal. This second constraint is to reduce fluctuations in A. Let s+(A, xj) be the unnormalized score for the positive example and s−(A,xk) be the unnormalized score of the negative example. Each update solves the following 1Of the possible positive examples, we choose the one with the highest probability under the current model to guard against large fluctuations in parameter updates fc Figure 3: An example noun coreference factor gra</context>
</contexts>
<marker>Crammer, Singer, 2003</marker>
<rawString>Koby Crammer and Yoram Singer. 2003. Ultraconservative online algorithms for multiclass problems. JMLR, 3:951– 991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aron Culotta</author>
<author>Andrew McCallum</author>
</authors>
<title>Tractable learning and inference with high-order representations.</title>
<date>2006</date>
<booktitle>In ICML Workshop on Open Problems in Statistical Relational Learning,</booktitle>
<location>Pittsburgh, PA.</location>
<marker>Culotta, McCallum, 2006</marker>
<rawString>Aron Culotta and Andrew McCallum. 2006. Tractable learning and inference with high-order representations. In ICML Workshop on Open Problems in Statistical Relational Learning, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
<author>Daniel Marcu</author>
</authors>
<title>A large-scale exploration of effective global features for a joint entity detection and tracking model.</title>
<date>2005</date>
<booktitle>In HLT/EMNLP,</booktitle>
<location>Vancouver, Canada.</location>
<marker>Daum´e, Marcu, 2005</marker>
<rawString>Hal Daum´e III and Daniel Marcu. 2005a. A large-scale exploration of effective global features for a joint entity detection and tracking model. In HLT/EMNLP, Vancouver, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
<author>Daniel Marcu</author>
</authors>
<title>Learning as search optimization: Approximate large margin methods for structured prediction. In ICML,</title>
<date>2005</date>
<location>Bonn, Germany.</location>
<marker>Daum´e, Marcu, 2005</marker>
<rawString>Hal Daum´e III and Daniel Marcu. 2005b. Learning as search optimization: Approximate large margin methods for structured prediction. In ICML, Bonn, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rodrigo de Salvo Braz</author>
<author>Eyal Amir</author>
<author>Dan Roth</author>
</authors>
<title>Lifted first-order probabilistic inference.</title>
<date>2005</date>
<booktitle>In IJCAI,</booktitle>
<pages>1319--1325</pages>
<marker>Braz, Amir, Roth, 2005</marker>
<rawString>Rodrigo de Salvo Braz, Eyal Amir, and Dan Roth. 2005. Lifted first-order probabilistic inference. In IJCAI, pages 1319– 1325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascal Denis</author>
<author>Jason Baldridge</author>
</authors>
<title>A ranking approach to pronoun resolution.</title>
<date>2007</date>
<booktitle>In IJCAI.</booktitle>
<contexts>
<context position="19618" citStr="Denis and Baldridge (2007)" startWordPosition="3206" endWordPosition="3209"> and Yih, 2004). The main distinctions of our approach are that it is simple to implement, not computationally intensive, and adaptable to arbitrary loss functions. There have been a number of machine learning approaches to coreference resolution, traditionally factored into classification decisions over pairs of nouns (Soon et al., 2001; Ng and Cardie, 2002). Nicolae and Nicolae (2006) combine pairwise classification with graph-cut algorithms. Luo et al. (2004) do enable features between mention-cluster pairs, but do not perform the error-driven and ranking enhancements proposed in our work. Denis and Baldridge (2007) use a ranking loss function for pronoun coreference; however the examples are still pairs of pronouns, and the example generation is not error driven. Ng (2005) learns a meta-classifier to choose the best prediction from the output of several coreference systems. While in theory a metaclassifier can flexibly represent features, they do not explore features using the full flexibility of firstorder logic. Also, their method is neither errordriven nor rank-based. McCallum and Wellner (2003) use a conditional random field that factors into a product of pairwise decisions about pairs of nouns. The</context>
</contexts>
<marker>Denis, Baldridge, 2007</marker>
<rawString>Pascal Denis and Jason Baldridge. 2007. A ranking approach to pronoun resolution. In IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Trond Grenager</author>
<author>Christopher Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by gibbs sampling.</title>
<date>2005</date>
<booktitle>In ACL,</booktitle>
<pages>363--370</pages>
<contexts>
<context position="18878" citStr="Finkel et al., 2005" startWordPosition="3095" endWordPosition="3098">es of this ranking-based loss function. Additionally, we provide an empirical study to quantify the effects of different example generation and loss function decisions. Collins and Roark (2004) present an incremental perceptron algorithm for parsing that uses “early update” to update the parameters when an error is encountered. Our method uses a similar “early update” in that training examples are only generated for the first mistake made during prediction. However, they do not investigate rank-based loss functions. Others have attempted to train global scoring functions using Gibbs sampling (Finkel et al., 2005), message propagation, (Bunescu and Mooney, 2004; Sutton and McCallum, 2004), and integer linear programming (Roth and Yih, 2004). The main distinctions of our approach are that it is simple to implement, not computationally intensive, and adaptable to arbitrary loss functions. There have been a number of machine learning approaches to coreference resolution, traditionally factored into classification decisions over pairs of nouns (Soon et al., 2001; Ng and Cardie, 2002). Nicolae and Nicolae (2006) combine pairwise classification with graph-cut algorithms. Luo et al. (2004) do enable features </context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Jenny Rose Finkel, Trond Grenager, and Christopher Manning. 2005. Incorporating non-local information into information extraction systems by gibbs sampling. In ACL, pages 363– 370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Gaifman</author>
</authors>
<title>Concerning measures in first order calculi.</title>
<date>1964</date>
<journal>Israel J. Math,</journal>
<pages>2--1</pages>
<contexts>
<context position="2993" citStr="Gaifman, 1964" startWordPosition="473" endWordPosition="474">y a combination of pairwise features. As a simple example, consider prohibiting coreferent sets that consist only of pronouns. That is, we would like to require that there be at least one antecedent for a set of pronouns. The pairwise decomposition does not make it possible to capture this constraint. In general, we would like to construct arbitrary features over a cluster of noun phrases using the full expressivity of first-order logic. Enabling this sort of flexible representation within a statistical model has been the subject of a long line of research on first-order probabilistic models (Gaifman, 1964; Halpern, 1990; Paskin, 2002; Poole, 2003; Richardson and Domingos, 2006). Conceptually, a first-order probabilistic model can be described quite compactly. A configuration of the world is represented by a set of prediProceedings of NAACL HLT 2007, pages 81–88, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics Choosing the closest preceding phrase is common because nearby phrases are a priori more likely to be coreferent. We refer to the training and inference methods described in this section as the Pairwise Model. 3 First-Order Logic Model k where ZX; is a normaliz</context>
</contexts>
<marker>Gaifman, 1964</marker>
<rawString>H. Gaifman. 1964. Concerning measures in first order calculi. Israel J. Math, 2:1–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Y Halpern</author>
</authors>
<title>An analysis of first-order logics of probability.</title>
<date>1990</date>
<journal>Artificial Intelligence,</journal>
<pages>46--311</pages>
<contexts>
<context position="3008" citStr="Halpern, 1990" startWordPosition="475" endWordPosition="476"> of pairwise features. As a simple example, consider prohibiting coreferent sets that consist only of pronouns. That is, we would like to require that there be at least one antecedent for a set of pronouns. The pairwise decomposition does not make it possible to capture this constraint. In general, we would like to construct arbitrary features over a cluster of noun phrases using the full expressivity of first-order logic. Enabling this sort of flexible representation within a statistical model has been the subject of a long line of research on first-order probabilistic models (Gaifman, 1964; Halpern, 1990; Paskin, 2002; Poole, 2003; Richardson and Domingos, 2006). Conceptually, a first-order probabilistic model can be described quite compactly. A configuration of the world is represented by a set of prediProceedings of NAACL HLT 2007, pages 81–88, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics Choosing the closest preceding phrase is common because nearby phrases are a priori more likely to be coreferent. We refer to the training and inference methods described in this section as the Pairwise Model. 3 First-Order Logic Model k where ZX; is a normalizer that sums ov</context>
</contexts>
<marker>Halpern, 1990</marker>
<rawString>J. Y. Halpern. 1990. An analysis of first-order logics of probability. Artificial Intelligence, 46:311–350.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoqiang Luo</author>
<author>Abe Ittycheriah</author>
<author>Hongyan Jing</author>
<author>Nanda Kambhatla</author>
<author>Salim Roukos</author>
</authors>
<title>A mention-synchronous coreference resolution algorithm based on the Bell tree.</title>
<date>2004</date>
<booktitle>In ACL,</booktitle>
<pages>135</pages>
<contexts>
<context position="19458" citStr="Luo et al. (2004)" startWordPosition="3182" endWordPosition="3185"> Gibbs sampling (Finkel et al., 2005), message propagation, (Bunescu and Mooney, 2004; Sutton and McCallum, 2004), and integer linear programming (Roth and Yih, 2004). The main distinctions of our approach are that it is simple to implement, not computationally intensive, and adaptable to arbitrary loss functions. There have been a number of machine learning approaches to coreference resolution, traditionally factored into classification decisions over pairs of nouns (Soon et al., 2001; Ng and Cardie, 2002). Nicolae and Nicolae (2006) combine pairwise classification with graph-cut algorithms. Luo et al. (2004) do enable features between mention-cluster pairs, but do not perform the error-driven and ranking enhancements proposed in our work. Denis and Baldridge (2007) use a ranking loss function for pronoun coreference; however the examples are still pairs of pronouns, and the example generation is not error driven. Ng (2005) learns a meta-classifier to choose the best prediction from the output of several coreference systems. While in theory a metaclassifier can flexibly represent features, they do not explore features using the full flexibility of firstorder logic. Also, their method is neither er</context>
</contexts>
<marker>Luo, Ittycheriah, Jing, Kambhatla, Roukos, 2004</marker>
<rawString>Xiaoqiang Luo, Abe Ittycheriah, Hongyan Jing, Nanda Kambhatla, and Salim Roukos. 2004. A mention-synchronous coreference resolution algorithm based on the Bell tree. In ACL, page 135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A McCallum</author>
<author>B Wellner</author>
</authors>
<title>Toward conditional models of identity uncertainty with application to proper noun coreference.</title>
<date>2003</date>
<booktitle>In IJCAI Workshop on Information Integration on the Web.</booktitle>
<contexts>
<context position="1751" citStr="McCallum and Wellner, 2003" startWordPosition="270" endWordPosition="273">ferent with mention b?” This approach of decomposing the problem into pairwise decisions presents at least two related difficulties. First, it is not clear how best to convert the set of pairwise classifications into a disjoint clustering of noun phrases. The problem stems from the transitivity constraints of coreference: If a and b are coreferent, and b and c are coreferent, then a and c must be coreferent. 81 This problem has recently been addressed by a number of researchers. A simple approach is to perform the transitive closure of the pairwise decisions. However, as shown in recent work (McCallum and Wellner, 2003; Singla and Domingos, 2005), better performance can be obtained by performing relational inference to directly consider the dependence among a set of predictions. For example, McCallum and Wellner (2005) apply a graph partitioning algorithm on a weighted, undirected graph in which vertices are noun phrases and edges are weighted by the pairwise score between noun phrases. A second and less studied difficulty is that the pairwise decomposition restricts the feature set to evidence about pairs of noun phrases only. This restriction can be detrimental if there exist features of sets of noun phra</context>
<context position="20111" citStr="McCallum and Wellner (2003)" startWordPosition="3285" endWordPosition="3288">n mention-cluster pairs, but do not perform the error-driven and ranking enhancements proposed in our work. Denis and Baldridge (2007) use a ranking loss function for pronoun coreference; however the examples are still pairs of pronouns, and the example generation is not error driven. Ng (2005) learns a meta-classifier to choose the best prediction from the output of several coreference systems. While in theory a metaclassifier can flexibly represent features, they do not explore features using the full flexibility of firstorder logic. Also, their method is neither errordriven nor rank-based. McCallum and Wellner (2003) use a conditional random field that factors into a product of pairwise decisions about pairs of nouns. These pairwise decisions are made collectively using relational inference; however, as pointed out in Milch et al. (2004), this model has limited representational power since it does not capture features of entities, only of pairs of mention. Milch et al. (2005) address these issues by constructing a generative probabilistic model, where noun clusters are sampled from a generative process. Our current work has similar representational flexibility as Milch et al. (2005) but is discriminativel</context>
</contexts>
<marker>McCallum, Wellner, 2003</marker>
<rawString>A. McCallum and B. Wellner. 2003. Toward conditional models of identity uncertainty with application to proper noun coreference. In IJCAI Workshop on Information Integration on the Web.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew McCallum</author>
<author>Ben Wellner</author>
</authors>
<title>Conditional models of identity uncertainty with application to noun coreference. In</title>
<date>2005</date>
<editor>Lawrence K. Saul, Yair Weiss, and L´eon Bottou, editors, NIPS17.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="1955" citStr="McCallum and Wellner (2005)" startWordPosition="301" endWordPosition="305">ications into a disjoint clustering of noun phrases. The problem stems from the transitivity constraints of coreference: If a and b are coreferent, and b and c are coreferent, then a and c must be coreferent. 81 This problem has recently been addressed by a number of researchers. A simple approach is to perform the transitive closure of the pairwise decisions. However, as shown in recent work (McCallum and Wellner, 2003; Singla and Domingos, 2005), better performance can be obtained by performing relational inference to directly consider the dependence among a set of predictions. For example, McCallum and Wellner (2005) apply a graph partitioning algorithm on a weighted, undirected graph in which vertices are noun phrases and edges are weighted by the pairwise score between noun phrases. A second and less studied difficulty is that the pairwise decomposition restricts the feature set to evidence about pairs of noun phrases only. This restriction can be detrimental if there exist features of sets of noun phrases that cannot be captured by a combination of pairwise features. As a simple example, consider prohibiting coreferent sets that consist only of pronouns. That is, we would like to require that there be </context>
<context position="10591" citStr="McCallum and Wellner (2005)" startWordPosition="1709" endWordPosition="1712">e Pairwise and FirstOrder models in terms of the factor graphs they approximate. For the Pairwise Model, a corresponding undirected graphical model can be defined as 1 P(y|x) = ZX ri yijEY ri ft(yij, yj,k, yik, xij, xjk, xik) yij,yjkEY x1 y123 fc y13 fc ft y12 y23 x3 ||At − A||2 f�(yij, xij) 84 where Zx is the input-dependent normalizer and factor fc parameterizes the pairwise noun phrase compatibility as fc(yij, xij) = exp(Ek λkfk(yij, xij)). Factor ft enforces the transitivity constraints by ft(·) = −oc if transitivity is not satisfied, 1 otherwise. This is similar to the model presented in McCallum and Wellner (2005). A factor graph for the Pairwise Model is presented in Figure 2 for three noun phrases. For the First-Order model, an undirected graphical model can be defined as where Zx is the input-dependent normalizer and factor fc parameterizes the cluster-wise noun phrase compatibility as fc(yj, xj) = exp(Ek λkfk(yj, xj)). Again, factor ft enforces the transitivity constraints by ft(·) = −oc if transitivity is not satisfied, 1 otherwise. Here, transitivity is a bit more complicated, since it also requires that if yj = 1, then for any subset xk C_ xj, yk = 1. A factor graph for the First-Order Model is </context>
</contexts>
<marker>McCallum, Wellner, 2005</marker>
<rawString>Andrew McCallum and Ben Wellner. 2005. Conditional models of identity uncertainty with application to noun coreference. In Lawrence K. Saul, Yair Weiss, and L´eon Bottou, editors, NIPS17. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Milch</author>
<author>Bhaskara Marthi</author>
<author>Stuart Russell</author>
</authors>
<title>BLOG: Relational modeling with unknown objects.</title>
<date>2004</date>
<booktitle>In ICML 2004 Workshop on Statistical Relational Learning and Its Connections to Other</booktitle>
<location>Fields.</location>
<contexts>
<context position="20336" citStr="Milch et al. (2004)" startWordPosition="3322" endWordPosition="3325">uns, and the example generation is not error driven. Ng (2005) learns a meta-classifier to choose the best prediction from the output of several coreference systems. While in theory a metaclassifier can flexibly represent features, they do not explore features using the full flexibility of firstorder logic. Also, their method is neither errordriven nor rank-based. McCallum and Wellner (2003) use a conditional random field that factors into a product of pairwise decisions about pairs of nouns. These pairwise decisions are made collectively using relational inference; however, as pointed out in Milch et al. (2004), this model has limited representational power since it does not capture features of entities, only of pairs of mention. Milch et al. (2005) address these issues by constructing a generative probabilistic model, where noun clusters are sampled from a generative process. Our current work has similar representational flexibility as Milch et al. (2005) but is discriminatively trained. 8 Conclusions and Future Work We have presented learning and inference procedures for coreference models using first-order features. By relying on sampling methods at training time and approximate inference methods</context>
</contexts>
<marker>Milch, Marthi, Russell, 2004</marker>
<rawString>Brian Milch, Bhaskara Marthi, and Stuart Russell. 2004. BLOG: Relational modeling with unknown objects. In ICML 2004 Workshop on Statistical Relational Learning and Its Connections to Other Fields.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Milch</author>
<author>Bhaskara Marthi</author>
<author>Stuart Russell</author>
<author>David Sontag</author>
<author>Daniel L Ong</author>
<author>Andrey Kolobov</author>
</authors>
<title>BLOG: Probabilistic models with unknown objects.</title>
<date>2005</date>
<booktitle>In IJCAI.</booktitle>
<contexts>
<context position="20477" citStr="Milch et al. (2005)" startWordPosition="3345" endWordPosition="3348">ral coreference systems. While in theory a metaclassifier can flexibly represent features, they do not explore features using the full flexibility of firstorder logic. Also, their method is neither errordriven nor rank-based. McCallum and Wellner (2003) use a conditional random field that factors into a product of pairwise decisions about pairs of nouns. These pairwise decisions are made collectively using relational inference; however, as pointed out in Milch et al. (2004), this model has limited representational power since it does not capture features of entities, only of pairs of mention. Milch et al. (2005) address these issues by constructing a generative probabilistic model, where noun clusters are sampled from a generative process. Our current work has similar representational flexibility as Milch et al. (2005) but is discriminatively trained. 8 Conclusions and Future Work We have presented learning and inference procedures for coreference models using first-order features. By relying on sampling methods at training time and approximate inference methods at testing time, this approach can be made scalable. This results in a coreference model that can capture features over sets of noun phrases</context>
</contexts>
<marker>Milch, Marthi, Russell, Sontag, Ong, Kolobov, 2005</marker>
<rawString>Brian Milch, Bhaskara Marthi, Stuart Russell, David Sontag, Daniel L. Ong, and Andrey Kolobov. 2005. BLOG: Probabilistic models with unknown objects. In IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
<author>Claire Cardie</author>
</authors>
<title>Improving machine learning approaches to coreference resolution.</title>
<date>2002</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="12353" citStr="Ng and Cardie (2002)" startWordPosition="2007" endWordPosition="2010">ion can be theoretically justified as minimizing an upper bound of the exact loss function. 6 Experiments 6.1 Data We apply our approach to the noun coreference ACE 2004 data, containing 443 news documents with 28,135 noun phrases to be coreferenced. 336 documents are used for training, and the remainder for testing. All entity types are candidates for coreference (pronouns, named entities, and nominal entities). We use the true entity segmentation, and parse each sentence in the corpus using a phrase-structure grammar, as is common for this task. 6.2 Features We follow Soon et al. (2001) and Ng and Cardie (2002) to generate most of our features for the Pairwise Model. These include: • Match features - Check whether gender, number, head text, or entire phrase matches • Mention type (pronoun, name, nominal) • Aliases - Heuristically decide if one noun is the acronym of the other • Apposition - Heuristically decide if one noun is in apposition to the other • Relative Pronoun - Heuristically decide if one noun is a relative pronoun referring to the other. • Wordnet features - Use Wordnet to decide if one noun is a hypernym, synonym, or antonym of another, or if they share a hypernym. • Both speak - True </context>
<context position="17420" citStr="Ng and Cardie (2002)" startWordPosition="2876" endWordPosition="2879">ll 5 mentions of France in a document are string identical, then the system will be extremely cautious of merging a noun that is not equivalent to France into xj, since this will turn off the “All-String-Match” feature for cluster xj. To our knowledge, the best results on this dataset were obtained by the meta-classification scheme of Ng (2005). Although our train-test splits may differ slightly, the best B-Cubed F1 score reported in Ng (2005) is 69.3%, which is considerably lower than the 79.3% obtained with our method. Also note that the Pairwise baseline obtains results similar to those in Ng and Cardie (2002). 7 Related Work There has been a recent interest in training methods that enable the use of first-order features (Paskin, 2002; Daum´e III and Marcu, 2005b; Richardson and Domingos, 2006). Perhaps the most related is 86 “learning as search optimization” (LASO) (Daum´e III and Marcu, 2005b; Daum´e III and Marcu, 2005a). Like the current paper, LASO is also an error-driven training method that integrates prediction and training. However, whereas we explicitly use a ranking-based loss function, LASO uses a binary classification loss function that labels each candidate structure as correct or inc</context>
<context position="19353" citStr="Ng and Cardie, 2002" startWordPosition="3167" endWordPosition="3170"> do not investigate rank-based loss functions. Others have attempted to train global scoring functions using Gibbs sampling (Finkel et al., 2005), message propagation, (Bunescu and Mooney, 2004; Sutton and McCallum, 2004), and integer linear programming (Roth and Yih, 2004). The main distinctions of our approach are that it is simple to implement, not computationally intensive, and adaptable to arbitrary loss functions. There have been a number of machine learning approaches to coreference resolution, traditionally factored into classification decisions over pairs of nouns (Soon et al., 2001; Ng and Cardie, 2002). Nicolae and Nicolae (2006) combine pairwise classification with graph-cut algorithms. Luo et al. (2004) do enable features between mention-cluster pairs, but do not perform the error-driven and ranking enhancements proposed in our work. Denis and Baldridge (2007) use a ranking loss function for pronoun coreference; however the examples are still pairs of pronouns, and the example generation is not error driven. Ng (2005) learns a meta-classifier to choose the best prediction from the output of several coreference systems. While in theory a metaclassifier can flexibly represent features, they</context>
</contexts>
<marker>Ng, Cardie, 2002</marker>
<rawString>Vincent Ng and Claire Cardie. 2002. Improving machine learning approaches to coreference resolution. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
</authors>
<title>Machine learning for coreference resolution: From local classification to global ranking.</title>
<date>2005</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="17146" citStr="Ng (2005)" startWordPosition="2833" endWordPosition="2834">d note that there are also small differences in the feature sets used for error-driven and standard training results.) Error analysis indicates that often noun xi is correctly not merged with a cluster xj when xj has a strong internal coherence. For example, if all 5 mentions of France in a document are string identical, then the system will be extremely cautious of merging a noun that is not equivalent to France into xj, since this will turn off the “All-String-Match” feature for cluster xj. To our knowledge, the best results on this dataset were obtained by the meta-classification scheme of Ng (2005). Although our train-test splits may differ slightly, the best B-Cubed F1 score reported in Ng (2005) is 69.3%, which is considerably lower than the 79.3% obtained with our method. Also note that the Pairwise baseline obtains results similar to those in Ng and Cardie (2002). 7 Related Work There has been a recent interest in training methods that enable the use of first-order features (Paskin, 2002; Daum´e III and Marcu, 2005b; Richardson and Domingos, 2006). Perhaps the most related is 86 “learning as search optimization” (LASO) (Daum´e III and Marcu, 2005b; Daum´e III and Marcu, 2005a). Like</context>
<context position="19779" citStr="Ng (2005)" startWordPosition="3235" endWordPosition="3236">en a number of machine learning approaches to coreference resolution, traditionally factored into classification decisions over pairs of nouns (Soon et al., 2001; Ng and Cardie, 2002). Nicolae and Nicolae (2006) combine pairwise classification with graph-cut algorithms. Luo et al. (2004) do enable features between mention-cluster pairs, but do not perform the error-driven and ranking enhancements proposed in our work. Denis and Baldridge (2007) use a ranking loss function for pronoun coreference; however the examples are still pairs of pronouns, and the example generation is not error driven. Ng (2005) learns a meta-classifier to choose the best prediction from the output of several coreference systems. While in theory a metaclassifier can flexibly represent features, they do not explore features using the full flexibility of firstorder logic. Also, their method is neither errordriven nor rank-based. McCallum and Wellner (2003) use a conditional random field that factors into a product of pairwise decisions about pairs of nouns. These pairwise decisions are made collectively using relational inference; however, as pointed out in Milch et al. (2004), this model has limited representational p</context>
<context position="21564" citStr="Ng (2005)" startWordPosition="3519" endWordPosition="3520">his approach can be made scalable. This results in a coreference model that can capture features over sets of noun phrases, rather than simply pairs of noun phrases. This is an example of a model with extremely flexible representational power, but for which exact inference is intractable. The simple approximations we have described here have enabled this more flexible model to outperform a model that is simplified for tractability. A short-term extension would be to consider features over entire clusterings, such as the number of clusters. This could be incorporated in a ranking scheme, as in Ng (2005). Future work will extend our approach to a wider variety of tasks. The model we have described here is specific to clustering tasks; however a similar formulation could be used to approach a number of language processing tasks, such as parsing and relation extraction. These tasks could benefit from first-order features, and the present work can guide the approximations required in those domains. Additionally, we are investigating more sophisticated inference algorithms that will reduce the greediness of the search procedures described here. 87 Acknowledgments We thank Robert Hall for helpful </context>
</contexts>
<marker>Ng, 2005</marker>
<rawString>Vincent Ng. 2005. Machine learning for coreference resolution: From local classification to global ranking. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cristina Nicolae</author>
<author>Gabriel Nicolae</author>
</authors>
<title>Bestcut: A graph algorithm for coreference resolution. In</title>
<date>2006</date>
<booktitle>EMNLP,</booktitle>
<pages>275--283</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="19381" citStr="Nicolae and Nicolae (2006)" startWordPosition="3171" endWordPosition="3174">nk-based loss functions. Others have attempted to train global scoring functions using Gibbs sampling (Finkel et al., 2005), message propagation, (Bunescu and Mooney, 2004; Sutton and McCallum, 2004), and integer linear programming (Roth and Yih, 2004). The main distinctions of our approach are that it is simple to implement, not computationally intensive, and adaptable to arbitrary loss functions. There have been a number of machine learning approaches to coreference resolution, traditionally factored into classification decisions over pairs of nouns (Soon et al., 2001; Ng and Cardie, 2002). Nicolae and Nicolae (2006) combine pairwise classification with graph-cut algorithms. Luo et al. (2004) do enable features between mention-cluster pairs, but do not perform the error-driven and ranking enhancements proposed in our work. Denis and Baldridge (2007) use a ranking loss function for pronoun coreference; however the examples are still pairs of pronouns, and the example generation is not error driven. Ng (2005) learns a meta-classifier to choose the best prediction from the output of several coreference systems. While in theory a metaclassifier can flexibly represent features, they do not explore features usi</context>
</contexts>
<marker>Nicolae, Nicolae, 2006</marker>
<rawString>Cristina Nicolae and Gabriel Nicolae. 2006. Bestcut: A graph algorithm for coreference resolution. In EMNLP, pages 275–283, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark A Paskin</author>
</authors>
<title>Maximum entropy probabilistic logic.</title>
<date>2002</date>
<tech>Technical Report UCB/CSD-01-1161,</tech>
<institution>University of California, Berkeley.</institution>
<contexts>
<context position="3022" citStr="Paskin, 2002" startWordPosition="477" endWordPosition="478">atures. As a simple example, consider prohibiting coreferent sets that consist only of pronouns. That is, we would like to require that there be at least one antecedent for a set of pronouns. The pairwise decomposition does not make it possible to capture this constraint. In general, we would like to construct arbitrary features over a cluster of noun phrases using the full expressivity of first-order logic. Enabling this sort of flexible representation within a statistical model has been the subject of a long line of research on first-order probabilistic models (Gaifman, 1964; Halpern, 1990; Paskin, 2002; Poole, 2003; Richardson and Domingos, 2006). Conceptually, a first-order probabilistic model can be described quite compactly. A configuration of the world is represented by a set of prediProceedings of NAACL HLT 2007, pages 81–88, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics Choosing the closest preceding phrase is common because nearby phrases are a priori more likely to be coreferent. We refer to the training and inference methods described in this section as the Pairwise Model. 3 First-Order Logic Model k where ZX; is a normalizer that sums over the two set</context>
<context position="17547" citStr="Paskin, 2002" startWordPosition="2899" endWordPosition="2900">uivalent to France into xj, since this will turn off the “All-String-Match” feature for cluster xj. To our knowledge, the best results on this dataset were obtained by the meta-classification scheme of Ng (2005). Although our train-test splits may differ slightly, the best B-Cubed F1 score reported in Ng (2005) is 69.3%, which is considerably lower than the 79.3% obtained with our method. Also note that the Pairwise baseline obtains results similar to those in Ng and Cardie (2002). 7 Related Work There has been a recent interest in training methods that enable the use of first-order features (Paskin, 2002; Daum´e III and Marcu, 2005b; Richardson and Domingos, 2006). Perhaps the most related is 86 “learning as search optimization” (LASO) (Daum´e III and Marcu, 2005b; Daum´e III and Marcu, 2005a). Like the current paper, LASO is also an error-driven training method that integrates prediction and training. However, whereas we explicitly use a ranking-based loss function, LASO uses a binary classification loss function that labels each candidate structure as correct or incorrect. Thus, each LASO training example contains all candidate predictions, whereas our training examples contain only the hig</context>
</contexts>
<marker>Paskin, 2002</marker>
<rawString>Mark A. Paskin. 2002. Maximum entropy probabilistic logic. Technical Report UCB/CSD-01-1161, University of California, Berkeley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Poole</author>
</authors>
<title>First-order probabilistic inference.</title>
<date>2003</date>
<booktitle>In IJCAI,</booktitle>
<pages>985--991</pages>
<publisher>Morgan Kaufman.</publisher>
<location>Acapulco, Mexico.</location>
<contexts>
<context position="3035" citStr="Poole, 2003" startWordPosition="479" endWordPosition="480">imple example, consider prohibiting coreferent sets that consist only of pronouns. That is, we would like to require that there be at least one antecedent for a set of pronouns. The pairwise decomposition does not make it possible to capture this constraint. In general, we would like to construct arbitrary features over a cluster of noun phrases using the full expressivity of first-order logic. Enabling this sort of flexible representation within a statistical model has been the subject of a long line of research on first-order probabilistic models (Gaifman, 1964; Halpern, 1990; Paskin, 2002; Poole, 2003; Richardson and Domingos, 2006). Conceptually, a first-order probabilistic model can be described quite compactly. A configuration of the world is represented by a set of prediProceedings of NAACL HLT 2007, pages 81–88, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics Choosing the closest preceding phrase is common because nearby phrases are a priori more likely to be coreferent. We refer to the training and inference methods described in this section as the Pairwise Model. 3 First-Order Logic Model k where ZX; is a normalizer that sums over the two settings of yj. </context>
</contexts>
<marker>Poole, 2003</marker>
<rawString>D. Poole. 2003. First-order probabilistic inference. In IJCAI, pages 985–991, Acapulco, Mexico. Morgan Kaufman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Richardson</author>
<author>Pedro Domingos</author>
</authors>
<title>Markov logic networks.</title>
<date>2006</date>
<booktitle>Machine Learning,</booktitle>
<pages>62--107</pages>
<contexts>
<context position="3067" citStr="Richardson and Domingos, 2006" startWordPosition="481" endWordPosition="485">, consider prohibiting coreferent sets that consist only of pronouns. That is, we would like to require that there be at least one antecedent for a set of pronouns. The pairwise decomposition does not make it possible to capture this constraint. In general, we would like to construct arbitrary features over a cluster of noun phrases using the full expressivity of first-order logic. Enabling this sort of flexible representation within a statistical model has been the subject of a long line of research on first-order probabilistic models (Gaifman, 1964; Halpern, 1990; Paskin, 2002; Poole, 2003; Richardson and Domingos, 2006). Conceptually, a first-order probabilistic model can be described quite compactly. A configuration of the world is represented by a set of prediProceedings of NAACL HLT 2007, pages 81–88, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics Choosing the closest preceding phrase is common because nearby phrases are a priori more likely to be coreferent. We refer to the training and inference methods described in this section as the Pairwise Model. 3 First-Order Logic Model k where ZX; is a normalizer that sums over the two settings of yj. Note that this model gives us th</context>
<context position="17608" citStr="Richardson and Domingos, 2006" startWordPosition="2906" endWordPosition="2909"> turn off the “All-String-Match” feature for cluster xj. To our knowledge, the best results on this dataset were obtained by the meta-classification scheme of Ng (2005). Although our train-test splits may differ slightly, the best B-Cubed F1 score reported in Ng (2005) is 69.3%, which is considerably lower than the 79.3% obtained with our method. Also note that the Pairwise baseline obtains results similar to those in Ng and Cardie (2002). 7 Related Work There has been a recent interest in training methods that enable the use of first-order features (Paskin, 2002; Daum´e III and Marcu, 2005b; Richardson and Domingos, 2006). Perhaps the most related is 86 “learning as search optimization” (LASO) (Daum´e III and Marcu, 2005b; Daum´e III and Marcu, 2005a). Like the current paper, LASO is also an error-driven training method that integrates prediction and training. However, whereas we explicitly use a ranking-based loss function, LASO uses a binary classification loss function that labels each candidate structure as correct or incorrect. Thus, each LASO training example contains all candidate predictions, whereas our training examples contain only the highest scoring incorrect prediction and the highest scoring cor</context>
</contexts>
<marker>Richardson, Domingos, 2006</marker>
<rawString>Matthew Richardson and Pedro Domingos. 2006. Markov logic networks. Machine Learning, 62:107–136.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roth</author>
<author>W Yih</author>
</authors>
<title>A linear programming formulation for global inference in natural language tasks.</title>
<date>2004</date>
<booktitle>In The 8th Conference on Compuational Natural Language Learning,</booktitle>
<contexts>
<context position="19007" citStr="Roth and Yih, 2004" startWordPosition="3114" endWordPosition="3117">eneration and loss function decisions. Collins and Roark (2004) present an incremental perceptron algorithm for parsing that uses “early update” to update the parameters when an error is encountered. Our method uses a similar “early update” in that training examples are only generated for the first mistake made during prediction. However, they do not investigate rank-based loss functions. Others have attempted to train global scoring functions using Gibbs sampling (Finkel et al., 2005), message propagation, (Bunescu and Mooney, 2004; Sutton and McCallum, 2004), and integer linear programming (Roth and Yih, 2004). The main distinctions of our approach are that it is simple to implement, not computationally intensive, and adaptable to arbitrary loss functions. There have been a number of machine learning approaches to coreference resolution, traditionally factored into classification decisions over pairs of nouns (Soon et al., 2001; Ng and Cardie, 2002). Nicolae and Nicolae (2006) combine pairwise classification with graph-cut algorithms. Luo et al. (2004) do enable features between mention-cluster pairs, but do not perform the error-driven and ranking enhancements proposed in our work. Denis and Baldr</context>
</contexts>
<marker>Roth, Yih, 2004</marker>
<rawString>D. Roth and W. Yih. 2004. A linear programming formulation for global inference in natural language tasks. In The 8th Conference on Compuational Natural Language Learning, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Parag Singla</author>
<author>Pedro Domingos</author>
</authors>
<title>Discriminative training of markov logic networks.</title>
<date>2005</date>
<booktitle>In AAAI,</booktitle>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="1779" citStr="Singla and Domingos, 2005" startWordPosition="274" endWordPosition="277"> approach of decomposing the problem into pairwise decisions presents at least two related difficulties. First, it is not clear how best to convert the set of pairwise classifications into a disjoint clustering of noun phrases. The problem stems from the transitivity constraints of coreference: If a and b are coreferent, and b and c are coreferent, then a and c must be coreferent. 81 This problem has recently been addressed by a number of researchers. A simple approach is to perform the transitive closure of the pairwise decisions. However, as shown in recent work (McCallum and Wellner, 2003; Singla and Domingos, 2005), better performance can be obtained by performing relational inference to directly consider the dependence among a set of predictions. For example, McCallum and Wellner (2005) apply a graph partitioning algorithm on a weighted, undirected graph in which vertices are noun phrases and edges are weighted by the pairwise score between noun phrases. A second and less studied difficulty is that the pairwise decomposition restricts the feature set to evidence about pairs of noun phrases only. This restriction can be detrimental if there exist features of sets of noun phrases that cannot be captured </context>
</contexts>
<marker>Singla, Domingos, 2005</marker>
<rawString>Parag Singla and Pedro Domingos. 2005. Discriminative training of markov logic networks. In AAAI, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wee Meng Soon</author>
<author>Hwee Tou Ng</author>
<author>Daniel Chung Yong Lim</author>
</authors>
<title>A machine learning approach to coreference resolution of noun phrases.</title>
<date>2001</date>
<journal>Comput. Linguist.,</journal>
<volume>27</volume>
<issue>4</issue>
<contexts>
<context position="12328" citStr="Soon et al. (2001)" startWordPosition="2002" endWordPosition="2005"> a piecewise approximation can be theoretically justified as minimizing an upper bound of the exact loss function. 6 Experiments 6.1 Data We apply our approach to the noun coreference ACE 2004 data, containing 443 news documents with 28,135 noun phrases to be coreferenced. 336 documents are used for training, and the remainder for testing. All entity types are candidates for coreference (pronouns, named entities, and nominal entities). We use the true entity segmentation, and parse each sentence in the corpus using a phrase-structure grammar, as is common for this task. 6.2 Features We follow Soon et al. (2001) and Ng and Cardie (2002) to generate most of our features for the Pairwise Model. These include: • Match features - Check whether gender, number, head text, or entire phrase matches • Mention type (pronoun, name, nominal) • Aliases - Heuristically decide if one noun is the acronym of the other • Apposition - Heuristically decide if one noun is in apposition to the other • Relative Pronoun - Heuristically decide if one noun is a relative pronoun referring to the other. • Wordnet features - Use Wordnet to decide if one noun is a hypernym, synonym, or antonym of another, or if they share a hyper</context>
<context position="19331" citStr="Soon et al., 2001" startWordPosition="3163" endWordPosition="3166">tion. However, they do not investigate rank-based loss functions. Others have attempted to train global scoring functions using Gibbs sampling (Finkel et al., 2005), message propagation, (Bunescu and Mooney, 2004; Sutton and McCallum, 2004), and integer linear programming (Roth and Yih, 2004). The main distinctions of our approach are that it is simple to implement, not computationally intensive, and adaptable to arbitrary loss functions. There have been a number of machine learning approaches to coreference resolution, traditionally factored into classification decisions over pairs of nouns (Soon et al., 2001; Ng and Cardie, 2002). Nicolae and Nicolae (2006) combine pairwise classification with graph-cut algorithms. Luo et al. (2004) do enable features between mention-cluster pairs, but do not perform the error-driven and ranking enhancements proposed in our work. Denis and Baldridge (2007) use a ranking loss function for pronoun coreference; however the examples are still pairs of pronouns, and the example generation is not error driven. Ng (2005) learns a meta-classifier to choose the best prediction from the output of several coreference systems. While in theory a metaclassifier can flexibly re</context>
</contexts>
<marker>Soon, Ng, Lim, 2001</marker>
<rawString>Wee Meng Soon, Hwee Tou Ng, and Daniel Chung Yong Lim. 2001. A machine learning approach to coreference resolution of noun phrases. Comput. Linguist., 27(4):521–544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Sutton</author>
<author>Andrew McCallum</author>
</authors>
<title>Collective segmentation and labeling of distant entities in information extraction.</title>
<date>2004</date>
<tech>Technical Report TR # 04-49,</tech>
<institution>University of Massachusetts,</institution>
<contexts>
<context position="18954" citStr="Sutton and McCallum, 2004" startWordPosition="3105" endWordPosition="3108">pirical study to quantify the effects of different example generation and loss function decisions. Collins and Roark (2004) present an incremental perceptron algorithm for parsing that uses “early update” to update the parameters when an error is encountered. Our method uses a similar “early update” in that training examples are only generated for the first mistake made during prediction. However, they do not investigate rank-based loss functions. Others have attempted to train global scoring functions using Gibbs sampling (Finkel et al., 2005), message propagation, (Bunescu and Mooney, 2004; Sutton and McCallum, 2004), and integer linear programming (Roth and Yih, 2004). The main distinctions of our approach are that it is simple to implement, not computationally intensive, and adaptable to arbitrary loss functions. There have been a number of machine learning approaches to coreference resolution, traditionally factored into classification decisions over pairs of nouns (Soon et al., 2001; Ng and Cardie, 2002). Nicolae and Nicolae (2006) combine pairwise classification with graph-cut algorithms. Luo et al. (2004) do enable features between mention-cluster pairs, but do not perform the error-driven and ranki</context>
</contexts>
<marker>Sutton, McCallum, 2004</marker>
<rawString>Charles Sutton and Andrew McCallum. 2004. Collective segmentation and labeling of distant entities in information extraction. Technical Report TR # 04-49, University of Massachusetts, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Sutton</author>
<author>Andrew McCallum</author>
</authors>
<title>Piecewise training of undirected models.</title>
<date>2005</date>
<booktitle>In 21st Conference on Uncertainty in Artificial Intelligence.</booktitle>
<contexts>
<context position="11506" citStr="Sutton and McCallum, 2005" startWordPosition="1867" endWordPosition="1870">j) = exp(Ek λkfk(yj, xj)). Again, factor ft enforces the transitivity constraints by ft(·) = −oc if transitivity is not satisfied, 1 otherwise. Here, transitivity is a bit more complicated, since it also requires that if yj = 1, then for any subset xk C_ xj, yk = 1. A factor graph for the First-Order Model is presented in Figure 3 for three noun phrases. The methods described in Sections 2, 3 and 4 can be viewed as estimating the parameters of each factor fc independently. This approach can therefore be viewed as a type of piecewise approximation of exact parameter estimation in these models (Sutton and McCallum, 2005). Here, each fc is a “piece” of the model trained independently. These pieces are combined at prediction time using clustering algorithms to enforce transitivity. Sutton and McCallum (2005) show that such a piecewise approximation can be theoretically justified as minimizing an upper bound of the exact loss function. 6 Experiments 6.1 Data We apply our approach to the noun coreference ACE 2004 data, containing 443 news documents with 28,135 noun phrases to be coreferenced. 336 documents are used for training, and the remainder for testing. All entity types are candidates for coreference (prono</context>
</contexts>
<marker>Sutton, McCallum, 2005</marker>
<rawString>Charles Sutton and Andrew McCallum. 2005. Piecewise training of undirected models. In 21st Conference on Uncertainty in Artificial Intelligence.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>