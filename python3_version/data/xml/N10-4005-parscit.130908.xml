<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000155">
<title confidence="0.95579">
Integer Linear Programming in NLP - Constrained Conditional Models
</title>
<author confidence="0.903069">
Ming-Wei Chang, Nicholas Rizzolo, Dan Roth
</author>
<affiliation confidence="0.738017">
University of Illinois at Urbana-Champaign
</affiliation>
<bodyText confidence="0.999570783783784">
Making decisions in natural language processing problems often involves assigning
values to sets of interdependent variables where the expressive dependency structure
can influence, or even dictate, what assignments are possible. Structured learning
problems such as semantic role labeling provide one such example, but the setting is
broader and includes a range of problems such as name entity and relation recognition
and co-reference resolution. The setting is also appropriate for cases that may require a
solution to make use of multiple (possible pre-designed or pre-learned components) as
in summarization, textual entailment and question answering. In all these cases, it is
natural to formulate the decision problem as a constrained optimization problem, with an
objective function that is composed of learned models, subject to domain or problem
specific constraints.
Constrained Conditional Models (aka Integer Linear Programming formulation of NLP
problems) is a learning and inference framework that augments the learning of
conditional (probabilistic or discriminative) models with declarative constraints (written,
for example, using a first-order representation) as a way to support decisions in an
expressive output space while maintaining modularity and tractability of training and
inference. In most applications of this framework in NLP, following [Roth &amp; Yih,
CoNLL&apos;04], Integer Linear Programming (ILP) was used as the inference framework,
although other algorithms can be used for that purpose.
This framework, with and without Integer Linear Programming as its inference engine,
has recently attracted much attention within the NLP community, with multiple papers in
all the recent major conferences, and a related workshop in NAACL&apos;09. Formulating
problems as constrained optimization problems over the output of learned models has
several advantages. It allows one to focus on the modeling of problems by providing the
opportunity to incorporate problem specific global constraints using a first order
language – thus frees the developer from (much of the) low level feature engineering –
and it guarantees exact inference. It provides also the freedom of decoupling the stage
of model generation (learning) from that of the constrained inference stage, often
resulting in simplifying the learning stage as well as the engineering problem of building
an NLP system, while improving the quality of the solutions.
These advantages and the availability of off-the-shelf solvers have led to a large variety
of natural language processing tasks being formulated within framework, including
semantic role labeling, syntactic parsing, coreference resolution, summarization,
transliteration and joint information extraction.
The goal of this tutorial is to introduce the framework of Constrained Conditional Models
(CCMs) to the broader ACL community, motivate it as a generic framework for learning
and inference in global NLP decision problems, present some of the key theoretical and
</bodyText>
<page confidence="0.995131">
9
</page>
<bodyText confidence="0.9998442">
practical issues involved in using CCMs and survey some of the existing applications of
it as a way to promote further development of the framework and additional
applications. The tutorial will thus be useful for many of the senior and junior
researchers that have interest in global decision problems in NLP, providing a concise
overview of recent perspectives and research results.
</bodyText>
<subsectionHeader confidence="0.976807">
Tutorial Outline
</subsectionHeader>
<bodyText confidence="0.9994648">
After shortly motivating and introducing the general framework, the main part of the
tutorial is a methodological presentation of some of the key computational issues
studied within CCMs that we will present by looking at case studies published in the
NLP literature. In the last part of the tutorial, we will discuss engineering issues that
arise in using CCMs and present some tool that facilitate developing CCM models.
</bodyText>
<listItem confidence="0.899683">
1. Motivation and Task Definition [30 min]
</listItem>
<bodyText confidence="0.9620085">
We will motivate the framework of Constrained Conditional Models and exemplify it
using the example of Semantic Role Labeling.
</bodyText>
<listItem confidence="0.540627">
2. Examples of Existing Applications [30 min]
</listItem>
<bodyText confidence="0.954513">
We will present in details several applications that made use of CCMs – including
coreference resolution, sentence compression and information extraction and use these
to explain several of the key advantages the framework offers. We will discuss in this
context several ways in which constraints can be introduced to an application.
3. Training Paradigms [30 min]
The objective function used by CCMs can be decomposed and learned in several ways,
ranging from a complete joint training of the model along with the constraints to a
complete decoupling between the learning and the inference stage. We will present the
advantages and disadvantages offered by different training paradigms and provide
theoretical and experimental understanding. In this part we will also discuss comparison
to other approaches studied in the literature.
</bodyText>
<listItem confidence="0.454936">
4. Inference methods and Constraints [30 min]
</listItem>
<bodyText confidence="0.918178333333333">
We will present and discuss several possibilities for modeling inference in CCMs, from
Integer Linear Programming to search techniques. We will also discuss the use of hard
constraints and soft constraints and present ways for modeling constraints.
5. Introducing background knowledge via CCMs [30 min]
We will look at ways in which Constrained Conditional Models (CCMs)can be used to
augment probabilistic models with declarative constraints in order to support decisions
</bodyText>
<page confidence="0.991708">
10
</page>
<bodyText confidence="0.8781085">
in an expressive output space, and how declarative constraints can be used to aid
supervised and semi-supervised training.
</bodyText>
<listItem confidence="0.626148">
6. Developing CCMs Applications [30 min]
</listItem>
<bodyText confidence="0.976366">
We present a modeling language that facilitates developing applications within the CCM
framework and present some “templates” for possible applications.
</bodyText>
<subsectionHeader confidence="0.829933">
Tutorial Instructors
</subsectionHeader>
<author confidence="0.563552">
Ming-Wei Chang
</author>
<affiliation confidence="0.905966">
Computer Science Department, University of Illinois at Urbana-Champaign, IL, 61801
</affiliation>
<email confidence="0.723041">
Email: mchang21@uiuc.edu
</email>
<bodyText confidence="0.9052806875">
Ming-Wei Chang is a Phd candidate in University of Illinois at Urbana-Champaign.
He has done work on Machine Learning in Natural Language Processing and
Information Extraction and has published a number of papers in several international
conferences including &amp;quot;Learning and Inference with Constraints&amp;quot; (AAAI&apos;08), &amp;quot;Guiding
Semi-Supervision with Constraint-Driven Learning&amp;quot; (ACL&apos;07) and “Unsupervised
Constraint Driven Learning For Transliteration Discovery. (NAACL&apos;09). He co-presented
a tutorial on CCMs in EACL&apos;09.
Nicholas Rizzolo
Computer Science Department, University of Illinois at Urbana-Champaign, IL, 61801
Email: ratinov2@uiuc.edu
Nicholas Rizollo is a Phd candidate in University of Illinois at Urbana-Champaign.
He has done work on Machine Learning in Natural Language Processing and is the
principal developer of Learning Based Java (LBJ) a modeling language for Constrained
Conditional Models. He has published a number of papers on these topics, including
&amp;quot;Learning and Inference with Constraints&amp;quot; (AAAI&apos;08) and “Modeling Discriminative
Global Inference” (ICSC&apos;07)
</bodyText>
<footnote confidence="0.44056">
Dan Roth
Computer Science Department, University of Illinois at Urbana-Champaign, IL, 61801
Phone: +(217) 244-7068; Email: danr@cs.uiuc.edu
</footnote>
<page confidence="0.999064">
11
</page>
<bodyText confidence="0.999825230769231">
Dan Roth is a Professor in the Department of Computer Science at the University of
Illinois at Urbana-Champaign and the Beckman Institute of Advanced Science and
Technology (UIUC) and a Willett Faculty Scholar of the College of Engineering. He has
published broadly in machine learning, natural language processing, knowledge
representation and reasoning and received several best paper and research awards. He
has developed several machine learning based natural language processing systems
including an award winning semantic parser, and has presented invited talks in several
international conferences, and several tutorials on machine learning for NLP. Dan Roth
has written the first paper on Constrained Conditional Models along with his student
Scott Yih, presented in CoNLLʼ04, and since then has worked on learning and inference
issue within this framework as well as on applying it for several NLP problems, including
Semantic Role Labeling, Information Extraction and Transliteration. He has presented
several invited talks that have addresses aspect of this model.
</bodyText>
<subsectionHeader confidence="0.675748">
Bibliography
</subsectionHeader>
<bodyText confidence="0.924435333333333">
Dan Roth and Wen-tau Yih. A Linear Programming Formulation for Global Inference
in Natural Language Tasks. In Proceedings of the Eighth Conference on Computational
Natural Language Learning (CoNLL-2004), pages 1-8, 2004.
Vasin Punyakanok, Dan Roth, Wen-tau Yih, and Dav Zimak. Semantic Role Labeling
Via Integer Linear Programming Inference. In Proceedings of the International
Conference on Computational Linguistics (COLING-2004), pages 1346-1352, 2004.)
Tomacz Marciniak and Michael Strube. Beyond the Pipeline: Discrete Optimization in
NLP. In Proceedings of the Ninth Conference on Computational Natural Language
Learning (CoNLL-2005), pages 136-145, 2005.
</bodyText>
<reference confidence="0.526033363636364">
Tzong-Han Tsai, Chia-Wei Wu, Yu-Chun Lin, and Wen-Lian Hsu. Exploiting Full
Parsing Information to Label Semantic Roles Using an Ensemble of ME and SVM via
Integer Linear Programming. In Proceedings of the Ninth Conference on Computational
Natural Language Learning: Shared Task (CoNLL-2005) Shared Task, pages 233-236,
2005.
Vasin Punyakanok, Dan Roth and Wen-tau Yih. The Necessity of Syntactic Parsing
for Semantic Role Labeling. In Proceedings of the International Joint Conference on
Artificial Intelligence (IJCAI-2005), pages 1117-1123, 2005.
Vasin Punyakanok, Dan Roth, Wen-tau Yih and Dav Zimak. Learning and Inference
over Constrained Output. In Proceedings of the International Joint Conference on
Artificial Intelligence (IJCAI-2005), pages 1124-1129, 2005.
</reference>
<page confidence="0.995485">
12
</page>
<reference confidence="0.998703085714286">
Dan Roth and Wen-tau Yih. Integer Linear Programming Inference for Conditional
Random Fields. In Proceedings of the International Conference on Machine Learning
(ICML-2005), pages 737-744, 2005.
Regina Barzilay and Mirella Lapata. Aggregation via Set Partitioning for Natural
Language Generation. In Proceedings of the Human Language Technology Conference
of the North American Chapter of the Association of Computational Linguistics (HLT-
NAACL-2006), pages 359-366, 2006.
James Clarke and Mirella Lapata. Constraint-Based Sentence Compression: An
Integer Programming Approach. In Proceedings of the COLING/ACL 2006 Main
Conference Poster Sessions (ACL-2006), pages 144-151, 2006.
Sebastian Riedel and James Clarke. Incremental Integer Linear Programming for
Non-projective Dependency Parsing. In Proceedings of the 2006 Conference on
Empirical Methods in Natural Language Processing (EMNLP-2006), pages 129-137,
2006.
Philip Bramsen, Pawan Deshpande, Yoong Keok Lee, and Regina Barzilay. Inducing
Temporal Graphs. In Proceedings of the 2006 Conference on Empirical Methods in
Natural Language Processing (EMNLP-2006), 189-198, 2006.
Yejin Choi, Eric Breck, and Claire Cardie. Joint Extraction of Entities and Relations for
Opinion Recognition. In Proceedings of the 2006 Conference on Empirical Methods in
Natural Language Processing (EMNLP-2006), 431-439, 2006.
Manfred Klenner. Grammatical Role Labeling with Integer Linear Programming. In
Proceedings of the 11th Conference of the European Chapter of the Association for
Computational Linguistics, Conference Companion (EACL-2006), pages 187-190, 2006.
Pascal Denis and Jason Baldridge. Joint Determination of Anaphoricity and
Coreference Resolution using Integer Programming. In Proceedings of the Annual
Meeting of the North American Chapter of the Association for Computational Linguistics
- Human Language Technology Conference (NAACL-HLT-2007), pages 236-243, 2007.
James Clarke and Mirella Lapata. Modelling Compression with Discourse
Constraints. In Proceedings of the Conference on Empirical Methods in Natural
Language Processing and on Computational Natural Language Learning (EMNLP-
CoNLL-2007), pages 1-11, 2007.
Manfred Klenner. Enforcing Consistency on Coreference Sets. In Recent Advances in
Natural Language Processing (RANLP), pages 323-328, 2007
Dan Roth and Wen-tau Yih. Global Inference for Entity and Relation Identification via
a Linear Programming Formulation. Introduction to Statistical Relational Learning, 2007.
</reference>
<page confidence="0.987776">
13
</page>
<reference confidence="0.998535333333334">
K. Ganchev, Jo‹o Graga and B. Taskar. Expectation Maximization and Posterior
Constraints, Neural Information Processing Systems Conference (NIPS), Vancouver,
BC, December 2007.
James Clarke and Mirella Lapata. Global Inference for Sentence Compression: An
Integer Linear Programming Approach. Journal of Artificial Intelligence Research (JAIR),
31, pages 399-429, 2008.
Vasin Punyakanok, Dan Roth and Wen-tau Yih. The Importance of Syntactic Parsing
and Inference in Semantic Role Labeling. Computational Linguistics 34(2), pages
257-287, 2008.
Jenny Rose Finkel and Christopher D. Manning. Enforcing Transitivity in Coreference
Resolution. In Proceedings of the Annual Meeting of the Association for Computational
Linguistics - Human Language Technology Conference, Short Papers (ACL-HLT-2008),
pages 45-48, 2008.
K. Ganchev, Jo‹o Graga and B. Taskar. Better Alignments = Better Translations?,
Association for Computational Linguistics (ACL), Columbus, Ohio, June 2008.
Hal Daume. Cross-Task Knowledge-Constrained Self Training In Proceedings of the
2008 Conference on Empirical Methods in Natural Language Processing
(EMNLP-2008).
Dan Goldwasser and Dan Roth. Transliteration as Constrained Optimization. In
Proceedings of the 2008 Conference on Empirical Methods in Natural Language
Processing (EMNLP-2008), pages 353-362, 2008.
</reference>
<page confidence="0.999265">
14
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000013">
<title confidence="0.997655">Integer Linear Programming in NLP - Constrained Conditional Models</title>
<author confidence="0.999859">Ming-Wei Chang</author>
<author confidence="0.999859">Nicholas Rizzolo</author>
<author confidence="0.999859">Dan Roth</author>
<affiliation confidence="0.993775">University of Illinois at Urbana-Champaign</affiliation>
<abstract confidence="0.998748168831169">Making decisions in natural language processing problems often involves assigning values to sets of interdependent variables where the expressive dependency structure can influence, or even dictate, what assignments are possible. Structured learning problems such as semantic role labeling provide one such example, but the setting is broader and includes a range of problems such as name entity and relation recognition and co-reference resolution. The setting is also appropriate for cases that may require a solution to make use of multiple (possible pre-designed or pre-learned components) as in summarization, textual entailment and question answering. In all these cases, it is natural to formulate the decision problem as a constrained optimization problem, with an objective function that is composed of learned models, subject to domain or problem specific constraints. Constrained Conditional Models (aka Integer Linear Programming formulation of NLP problems) is a learning and inference framework that augments the learning of conditional (probabilistic or discriminative) models with declarative constraints (written, for example, using a first-order representation) as a way to support decisions in an expressive output space while maintaining modularity and tractability of training and inference. In most applications of this framework in NLP, following [Roth &amp; Yih, Integer Linear Programming (ILP) was used as the inference framework, although other algorithms can be used for that purpose. This framework, with and without Integer Linear Programming as its inference engine, has recently attracted much attention within the NLP community, with multiple papers in the recent major conferences, and a related workshop in Formulating problems as constrained optimization problems over the output of learned models has several advantages. It allows one to focus on the modeling of problems by providing the opportunity to incorporate problem specific global constraints using a first order language – thus frees the developer from (much of the) low level feature engineering – and it guarantees exact inference. It provides also the freedom of decoupling the stage of model generation (learning) from that of the constrained inference stage, often resulting in simplifying the learning stage as well as the engineering problem of building an NLP system, while improving the quality of the solutions. These advantages and the availability of off-the-shelf solvers have led to a large variety of natural language processing tasks being formulated within framework, including semantic role labeling, syntactic parsing, coreference resolution, summarization, transliteration and joint information extraction. The goal of this tutorial is to introduce the framework of Constrained Conditional Models (CCMs) to the broader ACL community, motivate it as a generic framework for learning and inference in global NLP decision problems, present some of the key theoretical and 9 practical issues involved in using CCMs and survey some of the existing applications of it as a way to promote further development of the framework and additional applications. The tutorial will thus be useful for many of the senior and junior researchers that have interest in global decision problems in NLP, providing a concise overview of recent perspectives and research results. Tutorial Outline After shortly motivating and introducing the general framework, the main part of the tutorial is a methodological presentation of some of the key computational issues studied within CCMs that we will present by looking at case studies published in the NLP literature. In the last part of the tutorial, we will discuss engineering issues that arise in using CCMs and present some tool that facilitate developing CCM models. 1. Motivation and Task Definition [30 min] We will motivate the framework of Constrained Conditional Models and exemplify it using the example of Semantic Role Labeling. 2. Examples of Existing Applications [30 min] We will present in details several applications that made use of CCMs – including coreference resolution, sentence compression and information extraction and use these to explain several of the key advantages the framework offers. We will discuss in this context several ways in which constraints can be introduced to an application. 3. Training Paradigms [30 min] The objective function used by CCMs can be decomposed and learned in several ways, ranging from a complete joint training of the model along with the constraints to a complete decoupling between the learning and the inference stage. We will present the advantages and disadvantages offered by different training paradigms and provide theoretical and experimental understanding. In this part we will also discuss comparison to other approaches studied in the literature. 4. Inference methods and Constraints [30 min] We will present and discuss several possibilities for modeling inference in CCMs, from Integer Linear Programming to search techniques. We will also discuss the use of hard constraints and soft constraints and present ways for modeling constraints. 5. Introducing background knowledge via CCMs [30 min] We will look at ways in which Constrained Conditional Models (CCMs)can be used to augment probabilistic models with declarative constraints in order to support decisions 10 in an expressive output space, and how declarative constraints can be used to aid supervised and semi-supervised training. 6. Developing CCMs Applications [30 min] We present a modeling language that facilitates developing applications within the CCM framework and present some “templates” for possible applications.</abstract>
<title confidence="0.978434">Tutorial Instructors</title>
<author confidence="0.996787">Ming-Wei Chang</author>
<affiliation confidence="0.54342">Computer Science Department, University of Illinois at Urbana-Champaign, IL, 61801</affiliation>
<email confidence="0.977506">mchang21@uiuc.edu</email>
<title confidence="0.868785857142857">Ming-Wei Chang is a Phd candidate in University of Illinois at Urbana-Champaign. He has done work on Machine Learning in Natural Language Processing and Information Extraction and has published a number of papers in several international including &amp;quot;Learning and Inference with Constraints&amp;quot; &amp;quot;Guiding with Constraint-Driven Learning&amp;quot; and “Unsupervised Driven Learning For Transliteration Discovery. He co-presented tutorial on CCMs in</title>
<author confidence="0.999143">Nicholas Rizzolo</author>
<affiliation confidence="0.582793">Computer Science Department, University of Illinois at Urbana-Champaign, IL, 61801</affiliation>
<email confidence="0.952975">ratinov2@uiuc.edu</email>
<note confidence="0.88603475">Nicholas Rizollo is a Phd candidate in University of Illinois at Urbana-Champaign. He has done work on Machine Learning in Natural Language Processing and is the principal developer of Learning Based Java (LBJ) a modeling language for Constrained Conditional Models. He has published a number of papers on these topics, including</note>
<title confidence="0.9804705">and Inference with Constraints&amp;quot; and “Modeling Discriminative Inference”</title>
<author confidence="0.995603">Dan Roth</author>
<note confidence="0.570146666666667">Computer Science Department, University of Illinois at Urbana-Champaign, IL, 61801 +(217) 244-7068; Email:danr@cs.uiuc.edu 11 Dan Roth is a Professor in the Department of Computer Science at the University of Illinois at Urbana-Champaign and the Beckman Institute of Advanced Science and Technology (UIUC) and a Willett Faculty Scholar of the College of Engineering. He has</note>
<abstract confidence="0.9880148">published broadly in machine learning, natural language processing, knowledge representation and reasoning and received several best paper and research awards. He has developed several machine learning based natural language processing systems including an award winning semantic parser, and has presented invited talks in several international conferences, and several tutorials on machine learning for NLP. Dan Roth has written the first paper on Constrained Conditional Models along with his student Yih, presented in and since then has worked on learning and inference issue within this framework as well as on applying it for several NLP problems, including Semantic Role Labeling, Information Extraction and Transliteration. He has presented several invited talks that have addresses aspect of this model.</abstract>
<note confidence="0.6654014">Bibliography Dan Roth and Wen-tau Yih. A Linear Programming Formulation for Global Inference in Natural Language Tasks. In Proceedings of the Eighth Conference on Computational Natural Language Learning (CoNLL-2004), pages 1-8, 2004. Vasin Punyakanok, Dan Roth, Wen-tau Yih, and Dav Zimak. Semantic Role Labeling Via Integer Linear Programming Inference. In Proceedings of the International Conference on Computational Linguistics (COLING-2004), pages 1346-1352, 2004.) Tomacz Marciniak and Michael Strube. Beyond the Pipeline: Discrete Optimization in NLP. In Proceedings of the Ninth Conference on Computational Natural Language Learning (CoNLL-2005), pages 136-145, 2005.</note>
<title confidence="0.735675333333333">Tzong-Han Tsai, Chia-Wei Wu, Yu-Chun Lin, and Wen-Lian Hsu. Exploiting Full Parsing Information to Label Semantic Roles Using an Ensemble of ME and SVM via Integer Linear Programming. In Proceedings of the Ninth Conference on Computational</title>
<note confidence="0.893599571428571">Natural Language Learning: Shared Task (CoNLL-2005) Shared Task, pages 233-236, 2005. Vasin Punyakanok, Dan Roth and Wen-tau Yih. The Necessity of Syntactic Parsing for Semantic Role Labeling. In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI-2005), pages 1117-1123, 2005. Vasin Punyakanok, Dan Roth, Wen-tau Yih and Dav Zimak. Learning and Inference over Constrained Output. In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI-2005), pages 1124-1129, 2005. 12 Dan Roth and Wen-tau Yih. Integer Linear Programming Inference for Conditional Random Fields. In Proceedings of the International Conference on Machine Learning (ICML-2005), pages 737-744, 2005. Regina Barzilay and Mirella Lapata. Aggregation via Set Partitioning for Natural Language Generation. In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics (HLT- NAACL-2006), pages 359-366, 2006. James Clarke and Mirella Lapata. Constraint-Based Sentence Compression: An Integer Programming Approach. In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions (ACL-2006), pages 144-151, 2006. Sebastian Riedel and James Clarke. Incremental Integer Linear Programming for Non-projective Dependency Parsing. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP-2006), pages 129-137, 2006. Philip Bramsen, Pawan Deshpande, Yoong Keok Lee, and Regina Barzilay. Inducing Temporal Graphs. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP-2006), 189-198, 2006. Yejin Choi, Eric Breck, and Claire Cardie. Joint Extraction of Entities and Relations for Opinion Recognition. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP-2006), 431-439, 2006. Manfred Klenner. Grammatical Role Labeling with Integer Linear Programming. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics, Conference Companion (EACL-2006), pages 187-190, 2006. Pascal Denis and Jason Baldridge. Joint Determination of Anaphoricity and Coreference Resolution using Integer Programming. In Proceedings of the Annual Meeting of the North American Chapter of the Association for Computational Linguistics - Human Language Technology Conference (NAACL-HLT-2007), pages 236-243, 2007. James Clarke and Mirella Lapata. Modelling Compression with Discourse Constraints. In Proceedings of the Conference on Empirical Methods in Natural Language Processing and on Computational Natural Language Learning (EMNLP- CoNLL-2007), pages 1-11, 2007. Manfred Klenner. Enforcing Consistency on Coreference Sets. In Recent Advances in Natural Language Processing (RANLP), pages 323-328, 2007</note>
<author confidence="0.507659">Global Inference for Entity</author>
<author confidence="0.507659">Relation Identification via</author>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Tzong-Han Tsai</author>
<author>Chia-Wei Wu</author>
<author>Yu-Chun Lin</author>
<author>Wen-Lian Hsu</author>
</authors>
<title>Exploiting Full Parsing Information to Label Semantic Roles Using an Ensemble of ME and SVM via Integer Linear Programming.</title>
<date>2005</date>
<booktitle>In Proceedings of the Ninth Conference on Computational Natural Language Learning: Shared Task (CoNLL-2005) Shared Task,</booktitle>
<pages>233--236</pages>
<marker>Tsai, Wu, Lin, Hsu, 2005</marker>
<rawString>Tzong-Han Tsai, Chia-Wei Wu, Yu-Chun Lin, and Wen-Lian Hsu. Exploiting Full Parsing Information to Label Semantic Roles Using an Ensemble of ME and SVM via Integer Linear Programming. In Proceedings of the Ninth Conference on Computational Natural Language Learning: Shared Task (CoNLL-2005) Shared Task, pages 233-236, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasin Punyakanok</author>
<author>Dan Roth</author>
<author>Wen-tau Yih</author>
</authors>
<title>The Necessity of Syntactic Parsing for Semantic Role Labeling.</title>
<date>2005</date>
<booktitle>In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI-2005),</booktitle>
<pages>1117--1123</pages>
<marker>Punyakanok, Roth, Yih, 2005</marker>
<rawString>Vasin Punyakanok, Dan Roth and Wen-tau Yih. The Necessity of Syntactic Parsing for Semantic Role Labeling. In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI-2005), pages 1117-1123, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasin Punyakanok</author>
<author>Dan Roth</author>
<author>Wen-tau Yih</author>
<author>Dav Zimak</author>
</authors>
<title>Learning and Inference over Constrained Output.</title>
<date>2005</date>
<booktitle>In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI-2005),</booktitle>
<pages>1124--1129</pages>
<marker>Punyakanok, Roth, Yih, Zimak, 2005</marker>
<rawString>Vasin Punyakanok, Dan Roth, Wen-tau Yih and Dav Zimak. Learning and Inference over Constrained Output. In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI-2005), pages 1124-1129, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Roth</author>
<author>Wen-tau Yih</author>
</authors>
<title>Integer Linear Programming Inference for Conditional Random Fields.</title>
<date>2005</date>
<booktitle>In Proceedings of the International Conference on Machine Learning (ICML-2005),</booktitle>
<pages>737--744</pages>
<marker>Roth, Yih, 2005</marker>
<rawString>Dan Roth and Wen-tau Yih. Integer Linear Programming Inference for Conditional Random Fields. In Proceedings of the International Conference on Machine Learning (ICML-2005), pages 737-744, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Mirella Lapata</author>
</authors>
<title>Aggregation via Set Partitioning for Natural Language Generation.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics (HLTNAACL-2006),</booktitle>
<pages>359--366</pages>
<marker>Barzilay, Lapata, 2006</marker>
<rawString>Regina Barzilay and Mirella Lapata. Aggregation via Set Partitioning for Natural Language Generation. In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics (HLTNAACL-2006), pages 359-366, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Clarke</author>
<author>Mirella Lapata</author>
</authors>
<title>Constraint-Based Sentence Compression: An Integer Programming Approach.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions (ACL-2006),</booktitle>
<pages>144--151</pages>
<marker>Clarke, Lapata, 2006</marker>
<rawString>James Clarke and Mirella Lapata. Constraint-Based Sentence Compression: An Integer Programming Approach. In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions (ACL-2006), pages 144-151, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>James Clarke</author>
</authors>
<title>Incremental Integer Linear Programming for Non-projective Dependency Parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP-2006),</booktitle>
<pages>129--137</pages>
<marker>Riedel, Clarke, 2006</marker>
<rawString>Sebastian Riedel and James Clarke. Incremental Integer Linear Programming for Non-projective Dependency Parsing. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP-2006), pages 129-137, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Bramsen</author>
</authors>
<title>Pawan Deshpande, Yoong Keok Lee, and Regina Barzilay. Inducing Temporal Graphs.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP-2006),</booktitle>
<pages>189--198</pages>
<marker>Bramsen, 2006</marker>
<rawString>Philip Bramsen, Pawan Deshpande, Yoong Keok Lee, and Regina Barzilay. Inducing Temporal Graphs. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP-2006), 189-198, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yejin Choi</author>
<author>Eric Breck</author>
<author>Claire Cardie</author>
</authors>
<title>Joint Extraction of Entities and Relations for Opinion Recognition.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP-2006),</booktitle>
<pages>431--439</pages>
<marker>Choi, Breck, Cardie, 2006</marker>
<rawString>Yejin Choi, Eric Breck, and Claire Cardie. Joint Extraction of Entities and Relations for Opinion Recognition. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP-2006), 431-439, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manfred Klenner</author>
</authors>
<title>Grammatical Role Labeling with Integer Linear Programming.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics, Conference Companion (EACL-2006),</booktitle>
<pages>187--190</pages>
<marker>Klenner, 2006</marker>
<rawString>Manfred Klenner. Grammatical Role Labeling with Integer Linear Programming. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics, Conference Companion (EACL-2006), pages 187-190, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascal Denis</author>
<author>Jason Baldridge</author>
</authors>
<title>Joint Determination of Anaphoricity and Coreference Resolution using Integer Programming.</title>
<date>2007</date>
<booktitle>In Proceedings of the Annual Meeting of the North American Chapter of the Association for Computational Linguistics - Human Language Technology Conference (NAACL-HLT-2007),</booktitle>
<pages>236--243</pages>
<marker>Denis, Baldridge, 2007</marker>
<rawString>Pascal Denis and Jason Baldridge. Joint Determination of Anaphoricity and Coreference Resolution using Integer Programming. In Proceedings of the Annual Meeting of the North American Chapter of the Association for Computational Linguistics - Human Language Technology Conference (NAACL-HLT-2007), pages 236-243, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Clarke</author>
<author>Mirella Lapata</author>
</authors>
<title>Modelling Compression with Discourse Constraints.</title>
<date>2007</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing and on Computational Natural Language Learning (EMNLPCoNLL-2007),</booktitle>
<pages>1--11</pages>
<marker>Clarke, Lapata, 2007</marker>
<rawString>James Clarke and Mirella Lapata. Modelling Compression with Discourse Constraints. In Proceedings of the Conference on Empirical Methods in Natural Language Processing and on Computational Natural Language Learning (EMNLPCoNLL-2007), pages 1-11, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manfred Klenner</author>
</authors>
<title>Enforcing Consistency on Coreference Sets.</title>
<date>2007</date>
<booktitle>In Recent Advances in Natural Language Processing (RANLP),</booktitle>
<pages>323--328</pages>
<marker>Klenner, 2007</marker>
<rawString>Manfred Klenner. Enforcing Consistency on Coreference Sets. In Recent Advances in Natural Language Processing (RANLP), pages 323-328, 2007</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Roth</author>
<author>Wen-tau Yih</author>
</authors>
<title>Global Inference for Entity and Relation Identification via a Linear Programming Formulation. Introduction to Statistical Relational Learning,</title>
<date>2007</date>
<marker>Roth, Yih, 2007</marker>
<rawString>Dan Roth and Wen-tau Yih. Global Inference for Entity and Relation Identification via a Linear Programming Formulation. Introduction to Statistical Relational Learning, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Ganchev</author>
<author>Jo‹o Graga</author>
<author>B Taskar</author>
</authors>
<title>Expectation Maximization and Posterior Constraints,</title>
<date>2007</date>
<booktitle>Neural Information Processing Systems Conference (NIPS),</booktitle>
<location>Vancouver, BC,</location>
<marker>Ganchev, Graga, Taskar, 2007</marker>
<rawString>K. Ganchev, Jo‹o Graga and B. Taskar. Expectation Maximization and Posterior Constraints, Neural Information Processing Systems Conference (NIPS), Vancouver, BC, December 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Clarke</author>
<author>Mirella Lapata</author>
</authors>
<title>Global Inference for Sentence Compression: An Integer Linear Programming Approach.</title>
<date>2008</date>
<journal>Journal of Artificial Intelligence Research (JAIR),</journal>
<volume>31</volume>
<pages>399--429</pages>
<marker>Clarke, Lapata, 2008</marker>
<rawString>James Clarke and Mirella Lapata. Global Inference for Sentence Compression: An Integer Linear Programming Approach. Journal of Artificial Intelligence Research (JAIR), 31, pages 399-429, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasin Punyakanok</author>
<author>Dan Roth</author>
<author>Wen-tau Yih</author>
</authors>
<date>2008</date>
<booktitle>The Importance of Syntactic Parsing and Inference in Semantic Role Labeling. Computational Linguistics 34(2),</booktitle>
<pages>257--287</pages>
<marker>Punyakanok, Roth, Yih, 2008</marker>
<rawString>Vasin Punyakanok, Dan Roth and Wen-tau Yih. The Importance of Syntactic Parsing and Inference in Semantic Role Labeling. Computational Linguistics 34(2), pages 257-287, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Christopher D Manning</author>
</authors>
<title>Enforcing Transitivity in Coreference Resolution.</title>
<date>2008</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics - Human Language Technology Conference, Short Papers (ACL-HLT-2008),</booktitle>
<pages>45--48</pages>
<marker>Finkel, Manning, 2008</marker>
<rawString>Jenny Rose Finkel and Christopher D. Manning. Enforcing Transitivity in Coreference Resolution. In Proceedings of the Annual Meeting of the Association for Computational Linguistics - Human Language Technology Conference, Short Papers (ACL-HLT-2008), pages 45-48, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Ganchev</author>
<author>Jo‹o Graga</author>
<author>B Taskar</author>
</authors>
<title>Better Alignments = Better Translations?, Association for Computational Linguistics (ACL),</title>
<date>2008</date>
<location>Columbus, Ohio,</location>
<marker>Ganchev, Graga, Taskar, 2008</marker>
<rawString>K. Ganchev, Jo‹o Graga and B. Taskar. Better Alignments = Better Translations?, Association for Computational Linguistics (ACL), Columbus, Ohio, June 2008.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Hal Daume</author>
</authors>
<title>Cross-Task Knowledge-Constrained Self Training</title>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing (EMNLP-2008).</booktitle>
<marker>Daume, </marker>
<rawString>Hal Daume. Cross-Task Knowledge-Constrained Self Training In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing (EMNLP-2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Goldwasser</author>
<author>Dan Roth</author>
</authors>
<title>Transliteration as Constrained Optimization.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing (EMNLP-2008),</booktitle>
<pages>353--362</pages>
<marker>Goldwasser, Roth, 2008</marker>
<rawString>Dan Goldwasser and Dan Roth. Transliteration as Constrained Optimization. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing (EMNLP-2008), pages 353-362, 2008.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>