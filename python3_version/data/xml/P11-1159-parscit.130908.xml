<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000087">
<title confidence="0.9991385">
Improving Arabic Dependency Parsing with Form-based and Functional
Morphological Features
</title>
<author confidence="0.889722">
Yuval Marton Nizar Habash and Owen Rambow
</author>
<affiliation confidence="0.870723">
T.J. Watson Research Center Center for Computational Learning Systems
IBM Columbia University
</affiliation>
<email confidence="0.997855">
yymarton@us.ibm.com {habash,rambow}@ccls.columbia.edu
</email>
<sectionHeader confidence="0.998591" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999816785714286">
We explore the contribution of morphologi-
cal features – both lexical and inflectional –
to dependency parsing of Arabic, a morpho-
logically rich language. Using controlled ex-
periments, we find that definiteness, person,
number, gender, and the undiacritzed lemma
are most helpful for parsing on automatically
tagged input. We further contrast the contri-
bution of form-based and functional features,
and show that functional gender and number
(e.g., “broken plurals”) and the related ratio-
nality feature improve over form-based fea-
tures. It is the first time functional morpho-
logical features are used for Arabic NLP.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999957206896552">
Parsers need to learn the syntax of the modeled lan-
guage in order to project structure on newly seen
sentences. Parsing model design aims to come up
with features that best help parsers to learn the syn-
tax and choose among different parses. One as-
pect of syntax, which is often not explicitly mod-
eled in parsing, involves morphological constraints
on syntactic structure, such as agreement, which of-
ten plays an important role in morphologically rich
languages. In this paper, we explore the role of
morphological features in parsing Modern Standard
Arabic (MSA). For MSA, the space of possible mor-
phological features is fairly large. We determine
which morphological features help and why. We
also explore going beyond the easily detectable, reg-
ular form-based (“surface”) features, by represent-
ing functional values for some morphological fea-
tures. We expect that representing lexical abstrac-
tions and inflectional features participating in agree-
ment relations would help parsing quality, but other
inflectional features would not help. We further ex-
pect functional features to be superior to surface-
only features.
The paper is structured as follows. We first
present the corpus we use (Section 2), then rele-
vant Arabic linguistic facts (Section 3); we survey
related work (Section 4), describe our experiments
(Section 5), and conclude with an analysis of pars-
ing error types (Section 6).
</bodyText>
<sectionHeader confidence="0.995961" genericHeader="introduction">
2 Corpus
</sectionHeader>
<bodyText confidence="0.999977952380952">
We use the Columbia Arabic Treebank (CATiB)
(Habash and Roth, 2009). Specifically, we use
the portion converted automatically from part 3 of
the Penn Arabic Treebank (PATB) (Maamouri et
al., 2004) to the CATiB format, which enriches the
CATiB dependency trees with full PATB morpho-
logical information. CATiB’s dependency represen-
tation is based on traditional Arabic grammar and
emphasizes syntactic case relations. It has a re-
duced POS tagset (with six tags only – henceforth
CATIB6), but a standard set of eight dependency re-
lations: SBJ and OBJ for subject and (direct or indi-
rect) object, respectively, (whether they appear pre-
or post-verbally); IDF for the idafa (possessive) re-
lation; MOD for most other modifications; and other
less common relations that we will not discuss here.
For more information, see Habash et al. (2009). The
CATiB treebank uses the word segmentation of the
PATB: it splits off several categories of orthographic
clitics, but not the definite article JI Al. In all of the
experiments reported in this paper, we use the gold
</bodyText>
<page confidence="0.9328">
1586
</page>
<note confidence="0.989643">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1586–1596,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<figure confidence="0.892004142857143">
VRB
ÉÒª�K tsml
‘work’
MOD SBJ
NOM
u@YJ�&amp;quot;®k HfydAt
‘granddaughters’
NOM
€P@YÖÏ@ AlmdArs
‘the-schools’
MOD
NOM
éJ��ÓñºmÌ @ AlHkwmyh
‘the-governmental’
</figure>
<figureCaption confidence="0.999945">
Figure 1: CATiB Annotation example (tree display from right
</figureCaption>
<bodyText confidence="0.534257">
to left). :J�ÓñºmÌ @ €P@YÖÏ@ ú�¯� vAJ�»aË@ I. jA3/4Ë@ v@YJ��®k ÉÒª�K
</bodyText>
<subsubsectionHeader confidence="0.451392">
tSml HfydAt AlkAtb AlðkyAt fy AlmdArs AlHkwmyh ‘The
</subsubsectionHeader>
<bodyText confidence="0.844918333333333">
writer’s smart granddaughters work for public schools.’
segmentation. An example CATiB dependency tree
is shown in Figure 1.
</bodyText>
<sectionHeader confidence="0.996949" genericHeader="method">
3 Relevant Linguistic Concepts
</sectionHeader>
<bodyText confidence="0.99962726984127">
In this section, we present the linguistic concepts rel-
evant to our discussion of Arabic parsing.
Orthography The Arabic script uses optional di-
acritics to represent short vowels, consonantal dou-
bling and the indefininteness morpheme (nunation).
For example, the word ~I. ��
J�»kataba ‘he wrote’ is of-
ten written as I. -J»ktb, which can be ambiguous with
text, only around 1.6% of all words have any dia-
critic (Habash, 2010). As expected, the lack of dia-
critics contributes heavily to Arabic’s morphological
ambiguity. In this work, we only use undiacritized
text; however, some of our parsing features which
are derived through morphological disambiguation
include diacritics (specifically, lemmas, see below).
Morphemes Words can be described in terms of
their morphemes; in Arabic, in addition to concate-
native prefixes and suffixes, there are templatic mor-
phemes called root and pattern. For example, the
word vñJ.�KA3/4K� yu+kAtib+uwn ‘they correspond’ has
one prefix and one suffix, in addition to a stem com-
posed of the root H. u1/4 k-t-b ‘writing related’ and
the pattern 1A2i3.1
Lexeme and features Alternatively, Arabic
words can be described in terms of lexemes and
inflectional features. The set of word forms that
only vary inflectionally among each other is called
the lexeme. A lemma is a specific word form cho-
sen to represent the lexeme word set; for example,
Arabic verb lemmas are third person masculine sin-
gular perfective. We explore using both the dia-
critized lemma and the undiacritized lemma (here-
after LMM). Just as the lemma abstracts over in-
flectional morphology, the root abstracts over both
inflectional and derivational morphology and thus
provides a deeper level of lexical abstraction, indi-
cating the “core” meaning of the word. The pat-
tern is a generally complementary abstraction some-
times indicating sematic notions such causation and
reflexiveness. We use the pattern of the lemma, not
of the word form. We group the ROOT, PATTERN,
LEMMA and LMM in our discussion as lexical fea-
tures. Nominal lexemes can also be classified into
two groups: rational (i.e., human) or irrational (i.e.„
non-human).2 The rationality feature interacts with
syntactic agreement and other inflectional features
(discussed next); as such, we group it with those fea-
tures in this paper’s experiments.
The inflectional features define the the space of
variations of the word forms associated with a lex-
eme. PATB-tokenized words vary along nine di-
mensions: GENDER and NUMBER (for nominals and
verbs); PERSON, ASPECT, VOICE and MOOD (for
verbs); and CASE, STATE, and the attached defi-
nite article proclitic DET (for nominals). Inflectional
features abstract away from the specifics of mor-
pheme forms. Some inflectional features affect more
than one morpheme in the same word. For exam-
ple, changing the value of the ASPECT feature in
the example above from imperfective to perfective
yields the word form @ñJ.�KA¿kAtab+uwA ‘they corre-
sponded’, which differs in terms of prefix, suffix and
pattern.
</bodyText>
<footnote confidence="0.983570833333333">
1The digits in the pattern correspond to the positions root
radicals are inserted.
2Note that rationality (‘human-ness’ ‘É�¯A« Q���«/ÉSA«’) is nar-
rower than animacy; its expression is wide-spead in Arabic, but
less so English, where it mainly shows in pronouns (he/she vs.
it) and relativizers (the student who... vs. the desk/bird which...).
</footnote>
<bodyText confidence="0.378292">
other words such as `.. J»
kutub˜u ‘books’. In news
</bodyText>
<figure confidence="0.993790625">
~ IA
PRT
ú¯� fy
�
‘in’
OBJ
MOD
NOM
&amp;quot;AJ
» YË@ AlðkyAt
‘smart’
IDF
NOM
I. KA3/4Ë@ AlkAtb
�
‘the-writer’
</figure>
<page confidence="0.991419">
1587
</page>
<bodyText confidence="0.997658695652174">
Surface vs. functional features Additionally,
some inflectional features, specifically gender and
number, are expressed using different morphemes
in different words (even within the same part-of-
speech). There are four sound gender-number suf-
fixes in Arabic:3 +0 (null morpheme) for masculine
singular, o+ +fig for feminine singular, vð+ +wn for
masculine plural and u@+ +At for feminine plural.
Plurality can be expressed using sound plural suf-
fixes or using a pattern change together with singu-
lar suffixes. A sound plural example is the word pair
:,@YJ�Lk/oYJ�Lk Hafiyd+ah/Hafiyd+At ‘granddaugh-
ter/granddaughters’. On the other hand, the plural of
the inflectionally and morphemically feminine sin-
gular word ;L-JYÓ madras+ah ‘school’ is the word
€P@YÓ madAris+0 ‘schools’, which is feminine and
plural inflectionally, but has a masculine singular
suffix. This irregular inflection, known as broken
plural, is similar to the English mouse/mice, but is
much more common in Arabic (over 50% of plurals
in our training data). A similar inconsistency ap-
pears in feminine nouns that are not inflected using
sound gender suffixes, e.g., the feminine form of the
</bodyText>
<page confidence="0.437482">
6
</page>
<bodyText confidence="0.988994476190477">
masculine singular adjective �†„@Âzraq+0 ‘blue’ is
ZA79PP� zarqA’+0 not �é�¯P �P�@* *Âzraq+ah. To address
this inconsistency in the correspondence between in-
flectional features and morphemes, and inspired by
(Smrž, 2007), we distinguish between two types of
inflectional features: surface (or form-based)4 fea-
tures and functional features.
Most available Arabic NLP tools and resources
model morphology using surface inflectional fea-
tures and do not mark rationality; this includes the
PATB (Maamouri et al., 2004), the Buckwalter mor-
phological analyzer (BAMA) (Buckwalter, 2004)
and tools using them such as the Morphological
Analysis and Disambiguation for Arabic (MADA)
system (Habash and Rambow, 2005). The Elixir-
FM analyzer (Smrž, 2007) readily provides the func-
tional inflectional number feature, but not full func-
tional gender (only for adjectives and verbs but not
for nouns), nor rationality. Most recently, Alkuhlani
and Habash (2011) present a version of the PATB
(part 3) that is annotated for functional gender, num-
</bodyText>
<footnote confidence="0.995348">
3We ignore duals, which are regular in Arabic, and case/state
variations in this discussion for simplicity.
4Smrž (2007) uses the term illusory for surface features.
</footnote>
<bodyText confidence="0.994548212765958">
ber and rationality features for Arabic. We use this
resource in modeling these features in Section 5.5.
Morpho-syntactic interactions Inflectional fea-
tures and rationality interact with syntax in two
ways. In agreement relations, two words in a spe-
cific syntactic configuration have coordinated values
for specific sets of features. MSA has standard (i.e.,
matching value) agreement for subject-verb pairs on
PERSON, GENDER, and NUMBER, and for noun-
adjective pairs on NUMBER, GENDER, CASE, and
DET. There are three very common cases of excep-
tional agreement: verbs preceding subjects are al-
ways singular, adjectives of irrational plural nouns
are always feminine singular, and verbs whose sub-
jects are irrational plural are also always feminine
singular. See the example in Figure 1: the adjective,
uAJ�»�YË@ AlðkyAt ‘smart’, of the feminine plural (and
rational) u@YJ��®k HafiydAt ‘granddaughters’ is fem-
inine plural; but the adjective, �éJ�ÓñºmÌ @ AlHkwmyh
‘the-governmental’, of the feminine plural (and irra-
tional) €P@YÓ madAris ‘schools’ is feminine singu-
lar. These agreement rules always refer to functional
morphology categories; they are orthogonal to the
morpheme-feature inconsistency discussed above.
MSA exhibits marking relations in CASE and
STATE marking. Different types of dependents
have different CASE, e.g., verbal subjects are al-
ways marked NOMINATIVE. CASE and STATE are
rarely explicitly manifested in undiacritized MSA.
The DET feature plays an important role in distin-
guishing between the N-N idafa (possessive) con-
struction, in which only the last noun may bear the
definite article, and the N-A modifier construction,
in which both elements generally exhibit agreement
in definiteness.
Lexical features do not constrain syntactic struc-
ture as inflectional features do. Instead, bilexical
dependencies are used to model semantic relations
which often are the only way to disambiguate among
different possible syntactic structures. Lexical ab-
straction also reduces data sparseness.
The core POS tagsets Words also have associ-
ated part-of-speech (POS) tags, e.g., “verb”, which
further abstract over morphologically and syntac-
tically similar lexemes. Traditional Arabic gram-
mars often describe a very general three-way dis-
tinction into verbs, nominals and particles. In com-
</bodyText>
<page confidence="0.959042">
1588
</page>
<bodyText confidence="0.999736">
parison, the tagset of the Buckwalter Morphologi-
cal Analyzer (Buckwalter, 2004) used in the PATB
has a core POS set of 44 tags (before morphologi-
cal extension). Cross-linguistically, a core set con-
taining around 12 tags is often assumed, including:
noun, proper noun, verb, adjective, adverb, preposi-
tion, particles, connectives, and punctuation. Hence-
forth, we reduce CORE44 to such a tagset, and dub
it CORE12. The CATIB6 tagset can be viewed as
a further reduction, with the exception that CATIB6
contains a passive voice tag; however, this tag con-
stitutes only 0.5% of the tags in the training.
Extended POS tagsets The notion of “POS
tagset” in natural language processing usually does
not refer to a core set. Instead, the Penn English
Treebank (PTB) uses a set of 46 tags, including
not only the core POS, but also the complete set
of morphological features (this tagset is still fairly
small since English is morphologically impover-
ished). In PATB-tokenized MSA, the corresponding
type of tagset (core POS extended with a complete
description of morphology) would contain upwards
of 2,000 tags, many of which are extremely rare (in
our training corpus of about 300,000 words, we en-
counter only 430 of such POS tags with complete
morphology). Therefore, researchers have proposed
tagsets for MSA whose size is similar to that of the
English PTB tagset, as this has proven to be a useful
size computationally. These tagsets are hybrids in
the sense that they are neither simply the core POS,
nor the complete morphologically enriched tagset,
but instead they selectively enrich the core POS
tagset with only certain morphological features. A
full dicussion of how these tagsets affect parsing is
presented in Marton et al. (2010); we summarize the
main points here.
The following are the various tagsets we use in
this paper: (a) the core POS tagset CORE12; (b)
the CATiB treebank tagset CATIBEX, a newly in-
troduced extension of CATIB6 (Habash and Roth,
2009) by simple regular expressions of the word
form, indicating particular morphemes such as the
prefix JI Al+ or the suffix v_3 +wn; this tagset
is the best-performing tagset for Arabic on pre-
dicted values. (c) the PATB full tagset (BW), size
≈2000+ (Buckwalter, 2004); We only discuss here
the best performing tagsets (on predicted values),
and BW for comparison.
</bodyText>
<sectionHeader confidence="0.999916" genericHeader="method">
4 Related Work
</sectionHeader>
<bodyText confidence="0.99998">
Much work has been done on the use of morpholog-
ical features for parsing of morphologically rich lan-
guages. Collins et al. (1999) report that an optimal
tagset for parsing Czech consists of a basic POS tag
plus a CASE feature (when applicable). This tagset
(size 58) outperforms the basic Czech POS tagset
(size 13) and the complete tagset (size ,:3000+).
They also report that the use of gender, number and
person features did not yield any improvements. We
got similar results for CASE in the gold experimen-
tal setting (Marton et al., 2010) but not when using
predicted POS tags (POS tagger output). This may
be a result of CASE tagging having a lower error rate
in Czech (5.0%) (Hajiˇc and Vidová-Hladká, 1998)
compared to Arabic (,:14.0%, see Table 2). Simi-
larly, Cowan and Collins (2005) report that the use
of a subset of Spanish morphological features (num-
ber for adjectives, determiners, nouns, pronouns,
and verbs; and mode for verbs) outperforms other
combinations. Our approach is comparable to their
work in terms of its systematic exploration of the
space of morphological features. We also find that
the number feature helps for Arabic. Looking at He-
brew, a Semitic language related to Arabic, Tsarfaty
and Sima’an (2007) report that extending POS and
phrase structure tags with definiteness information
helps unlexicalized PCFG parsing.
As for work on Arabic, results have been reported
on PATB (Kulick et al., 2006; Diab, 2007; Green
and Manning, 2010), the Prague Dependency Tree-
bank (PADT) (Buchholz and Marsi, 2006; Nivre,
2008) and the Columbia Arabic Treebank (CATiB)
(Habash and Roth, 2009). Recently, Green and
Manning (2010) analyzed the PATB for annotation
consistency, and introduced an enhanced split-state
constituency grammar, including labels for short
Idafa constructions and verbal or equational clauses.
Nivre (2008) reports experiments on Arabic pars-
ing using his MaltParser (Nivre et al., 2007), trained
on the PADT. His results are not directly compara-
ble to ours because of the different treebanks’ repre-
sentations, even though all the experiments reported
here were performed using MaltParser. Our results
agree with previous work on Arabic and Hebrew in
that marking the definite article is helpful for pars-
ing. However, we go beyond previous work in that
</bodyText>
<page confidence="0.97904">
1589
</page>
<bodyText confidence="0.999882">
we also extend this morphologically enhanced fea-
ture set to include additional lexical and inflectional
features. Previous work with MaltParser in Russian,
Turkish and Hindi showed gains with case but not
with agreement features (Nivre et al., 2008; Eryigit
et al., 2008; Nivre, 2009). Our work is the first using
MaltParser to show gains using agreement-oriented
features (Marton et al., 2010), and the first to use
functional features for this task (this paper).
</bodyText>
<sectionHeader confidence="0.999725" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999973318181818">
Throughout this section, we only report results us-
ing predicted input feature values (e.g., generated
automatically by a POS tagger). After presenting
the parser we use (Section 5.1), we examine a large
space of settings in the following order: the contri-
bution of numerous inflectional features in a con-
trolled fashion (Section 5.2);5 the contribution of
the lexical features in a similar fashion, as well as
the combination of lexical and inflectional features
(Section 5.3); an extension of the DET feature (Sec-
tion 5.4); using functional NUMBER and GENDER
feature values, as well as the RATIONALITY feature
(Section 5.5); finally, putting best feature combina-
tions to test with the best-performing POS tagset,
and on an unseen test set (Section 5.6). All results
are reported mainly in terms of labeled attachment
accuracy score (parent word and the dependency re-
lation to it, a.k.a. LAS). Unlabeled attachment ac-
curacy score (UAS) is also given. We use McNe-
mar’s statistical significance test as implemented by
Nilsson and Nivre (2008), and denote p &lt; 0.05 and
p &lt; 0.01 with + and ++, respectively.
</bodyText>
<subsectionHeader confidence="0.919947">
5.1 Parser
</subsectionHeader>
<bodyText confidence="0.999910571428571">
For all experiments reported here we used the syn-
tactic dependency parser MaltParser v1.3 (Nivre,
2003; Nivre, 2008; Kübler et al., 2009) – a
transition-based parser with an input buffer and a
stack, using SVM classifiers to predict the next state
in the parse derivation. All experiments were done
using the Nivre &amp;quot;eager&amp;quot; algorithm.6 For training, de-
</bodyText>
<footnote confidence="0.965022333333333">
5In this paper, we do not examine the contribution of differ-
ent POS tagsets, see Marton et al. (2010) for details.
6Nivre (2008) reports that non-projective and pseudo-
projective algorithms outperform the &amp;quot;eager&amp;quot; projective algo-
rithm in MaltParser, but our training data did not contain any
non-projective dependencies. The Nivre &amp;quot;standard&amp;quot; algorithm
</footnote>
<bodyText confidence="0.999792166666667">
velopment and testing, we follow the splits used by
Roth et al. (2008) for PATB part 3 (Maamouri et al.,
2004). We kept the test unseen during training.
There are five default attributes, in the MaltParser
terminology, for each token in the text: word ID (or-
dinal position in the sentence), word form, POS tag,
head (parent word ID), and deprel (the dependency
relation between the current word and its parent).
There are default MaltParser features (in the ma-
chine learning sense),7 which are the values of func-
tions over these attributes, serving as input to the
MaltParser internal classifiers. The most commonly
used feature functions are the top of the input buffer
(next word to process, denoted buf[0]), or top of the
stack (denoted stk[0]); following items on buffer or
stack are also accessible (buf[1], buf[2], stk[1], etc.).
Hence MaltParser features are defined as POS tag
at stk[0], word form at buf[0], etc. Kübler et al.
(2009) describe a “typical” MaltParser model con-
figuration of attributes and features.8 Starting with
it, in a series of initial controlled experiments, we
settled on using buf[0-1] + stk[0-1] for wordforms,
and buf[0-3] + stk[0-2] for POS tags. For features of
new MaltParser-attributes (discussed later), we used
buf[0] + stk[0]. We did not change the features for
deprel. This new MaltParser configuration resulted
in gains of 0.3-1.1% in labeled attachment accuracy
(depending on the POS tagset) over the default Malt-
Parser configuration.9 All experiments reported be-
low were conducted using this new configuration.
</bodyText>
<subsectionHeader confidence="0.962144">
5.2 Inflectional features
</subsectionHeader>
<bodyText confidence="0.993527444444444">
In order to explore the contribution of inflectional
and lexical information in a controlled manner, we
focused on the best performing core (“morphology-
free”) POS tagset, CORE12, as baseline; using three
is also reported to do better on Arabic, but in a preliminary ex-
perimentation, it did similarly or slightly worse than the &amp;quot;eager”
one, perhaps due to high percentage of right branching (left
headed structures) in our Arabic training set – an observation
already noted in Nivre (2008).
</bodyText>
<footnote confidence="0.875672888888889">
7The terms “feature” and “attribute” are overloaded in the
literature. We use them in the linguistic sense, unless specifi-
cally noted otherwise, e.g., “MaltParser feature(s)”.
8It is slightly different from the default configuration.
9We also experimented with normalizing word forms (Alif
Maqsura conversion to Ya, and hamza removal from Alif forms)
as is common in parsing and statistical machine translation lit-
erature – but it resulted in a similar or slightly decreased perfor-
mance, so we settled on using non-normalized word forms.
</footnote>
<page confidence="0.771508">
1590
</page>
<table confidence="0.999796552631579">
setup LAS LASdzff UAS
CORE12 78.68 — 82.48
+ all inflectional features 77.91 -0.77 82.14
+DET 79.82++ 1.14 83.18
+STATE 79.34++ 0.66 82.85
+GENDER 78.75 0.07 82.35
+PERSON 78.74 0.06 82.45
+NUMBER 78.66 -0.02 82.39
+VOICE 78.64 -0.04 82.41
+ASPECT 78.60 -0.08 82.39
+MOOD 78.54 -0.14 82.35
+CASE 75.81 -2.87 80.24
+DET+STATE 79.42++ 0.74 82.84
+DET+GENDER 79.90++ 1.22 83.20
+DET+GENDER+PERSON 79.94++ 1.26 83.21
+DET+PNG 80.11++ 1.43 83.29
+DET+PNG+VOICE 79.96++ 1.28 83.18
+DET+PNG+ASPECT 80.01++ 1.33 83.20
+DET+PNG+MOOD 80.03++ 1.35 83.21
All
Sep
Greedy
feature acc set size
DET 99.6 3*
PERSON 99.1 4*
ASPECT 99.1 5*
VOICE 98.9 4*
MOOD 98.6 5*
GENDER 99.3 3*
NUMBER 99.5 4*
STATE 95.6 4*
CASE 86.3 5*
ROOT 98.4 9646
PATTERN 97.0 338
LEMMA (diacritized) 96.7 16837
LMM (undiacritized lemma) 98.3 15305
normalized word form (A,Y) 99.3 29737
non-normalized word form 98.9 29980
</table>
<tableCaption confidence="0.978674833333333">
Table 2: Feature prediction accuracy and set sizes. * = The set
includes a &amp;quot;N/A&amp;quot; value.
Table 1: CORE12 with inflectional features, predicted input.
Top: Adding all nine features to CORE12. Second part: Adding
each feature separately, comparing difference from CORE12.
Third part: Greedily adding best features from second part.
</tableCaption>
<bodyText confidence="0.999696884615384">
different setups, we added nine morphological fea-
tures with values predicted by MADA: DET (pres-
ence of the definite determiner), PERSON, ASPECT,
VOICE, MOOD, GENDER, NUMBER, STATE (mor-
phological marking as head of an idafa construc-
tion), and CASE. In setup All, we augmented the
baseline model with all nine MADA features (as
nine additional MaltParser attributes); in setup Sep,
we augmented the baseline model with the MADA
features, one at a time; and in setup Greedy, we
combined them in a greedy heuristic (since the entire
feature space is too vast to exhaust): starting with the
most gainful feature from Sep, adding the next most
gainful feature, keeping it if it helped, or discarding
it otherwise, and continuing through the least gainful
feature. See Table 1.
Somewhat surprisingly, setup All hurts perfor-
mance. This can be explained if one examines the
prediction accuracy of each feature (top of Table 2).
Features which are not predicted with very high ac-
curacy, such as CASE (86.3%), can dominate the
negative contribution, even though they are top con-
tributors when provided as gold input (Marton et al.,
2010); when all features are provided as gold in-
put, All actually does better than individual features,
which puts to rest a concern that its decrease here
</bodyText>
<table confidence="0.9843595">
setup LAS LASdzff UAS
CORE12 (repeated) 78.68 — 82.48
+ all lexical features 78.85 0.17 82.46
+LMM 78.96+ 0.28 82.54
+ROOT 78.94+ 0.26 82.64
+LEMMA 78.80 0.12 82.42
+PATTERN 78.59 -0.09 82.39
+LMM+ROOT 79.04++ 0.36 82.63
+LMM+ROOT+LEMMA 79.05++ 0.37 82.63
+LMM+ROOT+PATTERN 78.93 0.25 82.58
</table>
<tableCaption confidence="0.996788">
Table 3: Lexical features. Top part: Adding each feature
</tableCaption>
<bodyText confidence="0.908753">
separately; difference from CORE12 (predicted). Bottom part:
Greedily adding best features from previous part.
is due to data sparseness. Here, when features are
predicted, the DET feature (determiner), followed by
the STATE (construct state, idafa) feature, are top in-
dividual contributors in setup Sep. Adding DET and
the so-called 0-features (PERSON, NUMBER, GEN-
DER, also shorthanded PNG) in the Greedy setup,
yields 1.43% gain over the CORE12 baseline.
</bodyText>
<subsectionHeader confidence="0.997446">
5.3 Lexical features
</subsectionHeader>
<bodyText confidence="0.99795325">
Next, we experimented with adding the lexical fea-
tures, which involve semantic abstraction to some
degree: LEMMA, LMM (the undiacritized lemma),
and ROOT. We experimented with the same setups
as above: All, Sep, and Greedy. Adding all four
features yielded a minor gain in setup All. LMM
was the best single contributor, closely followed by
ROOT in Sep. CORE12+LMM+ROOT (with or with-
</bodyText>
<figure confidence="0.712655333333333">
All
Sep
Greedy
</figure>
<page confidence="0.715186">
1591
</page>
<table confidence="0.9983684">
CORE12+... LAS LASdzff UAS
+DET+PNG (repeated) 80.11++ 1.43 83.29
+DET+PNG+LMM 80.23++ 1.55 83.34
+DET+PNG+LMM +ROOT 80.10++ 1.42 83.25
+DET+PNG+LMM +PATTERN 80.03++ 1.35 83.15
</table>
<tableCaption confidence="0.880458">
Table 4: Inflectional+lexical features together.
</tableCaption>
<table confidence="0.999509">
CORE12+... LAS LASddff UAS
+DET (repeated) 79.82++ — 83.18
+DET2 80.13++ 0.31 83.49
+DET+PNG+LMM (repeated) 80.23++ — 83.34
+DET2+PNG+LMM 80.21++ -0.02 83.39
</table>
<tableCaption confidence="0.999878">
Table 5: Extended inflectional features.
</tableCaption>
<bodyText confidence="0.997323875">
out LEMMA) was the best greedy combination in
setup Greedy. See Table 3. All lexical features are
predicted with high accuracy (bottom of Table 2).
Following the same greedy heuristic, we
augmented the best inflection-based model
CORE12+DET+PNG with lexical features, and
found that only the undiacritized lemma (LMM)
alone improved performance (80.23%). See Table 4.
</bodyText>
<subsectionHeader confidence="0.926094">
5.4 Inflectional feature engineering
</subsectionHeader>
<bodyText confidence="0.998999818181819">
So far we experimented with morphological fea-
ture values as predicted by MADA. However, it is
likely that from a machine-learning perspective, rep-
resenting similar categories with the same tag may
be useful for learning. Therefore, we next exper-
imented with modifying inflectional features that
proved most useful.
As DET may help distinguish the N-N idafa con-
struction from the N-A modifier construction, we
attempted modeling also the DET values of pre-
vious and next elements (as MaltParser’s stk[1] +
buf[1], in addition to stk[0] + buf[0]). This vari-
ant, denoted DET2, indeed helps: when added to
the CORE12, DET2 improves non-gold parsing qual-
ity by more than 0.3%, compared to DET (Ta-
ble 5). This improvement unfortunately does not
carry over to our best feature combination to date,
CORE12+DET+PNG+LMM. However, in subsequent
feature combinations, we see that DET2 helps again,
or at least, doesn’t hurt: LAS goes up by 0.06% in
conjunction with features LMM+PERSON +FN*NGR
in Table 6.
</bodyText>
<table confidence="0.999251789473685">
CORE12 + ... LAS LASddff UAS
CORE12 (repeated) 78.68 – 82.48
+PERSON (repeated) 78.74 0.06 82.45
+GENDER (repeated) 78.75 0.07 82.35
+NUMBER (repeated) 78.66 -0.02 82.39
+FN*GENDER 78.96++ 0.28 82.53
+FN*NUMBER 78.88+ 0.20 82.53
+FN*NUMDGTBIN 78.87 0.19 82.53
+FN*RATIONALITY 78.91+ 0.23 82.60
+FN*GNR 79.32++ 0.64 82.78
+PERSON+FN*GNR 79.34++ 0.66 82.82
+DET+LMM+PERSON+FN*NGR 80.47++ 1.79 83.57
+DET2+LMM+PERSON+FN*NGR 80.53++ 1.85 83.66
+DET2+LMM+PERSON+FN*NG 80.43++ 1.75 83.56
+DET2+LMM+PNG+FN*NGR 80.51++ 1.83 83.66
CATIBEX 79.74 – 83.30
+DET2+LMM +PERSON+FN*NGR 80.83++ 1.09 84.02
BW 72.64 – 77.91
+DET2+LMM +PERSON+FN*NGR 74.40++ 1.76 79.40
</table>
<tableCaption confidence="0.999298">
Table 6: Functional features: gender, number, rationality.
</tableCaption>
<bodyText confidence="0.99992925">
We also experimented with PERSON. We changed
the values of proper names from “N/A” to “3” (third
person), but it resulted in a similar or slightly de-
creased performance, so it was abandoned.
</bodyText>
<subsectionHeader confidence="0.995629">
5.5 Functional feature values
</subsectionHeader>
<bodyText confidence="0.999983954545455">
The NUMBER and GENDER features we have used
so far only reflect surface (as opposed to functional)
values, e.g., broken plurals are marked as singular.
This might have a negative effect on learning gen-
eralizations over the complex agreement patterns in
MSA (see Section 3), beyond memorization of word
pairs seen together in training.
Predicting functional features To predict func-
tional GENDER, functional NUMBER and RATIO-
NALITY, we build a simple maximum likelihood es-
timate (MLE) model using these annotations in the
corpus created by Alkuhlani and Habash (2011). We
train using the same training data we use through-
out this paper. For all three features, we select the
most seen value in training associated with the triple
word-CATIBEX-lemma; we back off to CATIBEX-
lemma and then to lemma. For gender and num-
ber, we further back off to the surface values; for
rationality, we back off to the most common value
(irrational). On our predicted dev set, the over-
all accuracy baseline of predicting correct functional
gender-number-rationality using surface features is
</bodyText>
<page confidence="0.988205">
1592
</page>
<bodyText confidence="0.998196846153846">
85.1% (for all POS tags). Our MLE model reduces
the error by two thirds reaching an overall accuracy
of 95.5%. The high accuracy may be a result of the
low percentage of words in the dev set that do not
appear in training (around 4.6%).
Digit tokens (e.g., “4”) are also marked singu-
lar by default. They don’t show surface agreement,
even though the corresponding number-word token
(a,..,�IArbkh ‘four.fem.sing’) would. We further ob-
serve that MSA displays complex agreement pat-
terns with numbers (Dada, 2007). Therefore, we
alternatively experimented with binning the digit to-
kens’ NUMBER value accordingly:
</bodyText>
<listItem confidence="0.999794">
• the number 0 and numbers ending with 00
• the number 1 and numbers ending with 01
• the number 2 and numbers ending with 02
• the numbers 3-10 and those ending with 03-10
• the numbers, and numbers ending with, 11-99
• all other number tokens (e.g., 0.35 or 7/16)
</listItem>
<bodyText confidence="0.9935624">
and denoted these experiments with NUMDGTBIN.
Almost 1.5% of the tokens are digit tokens in the
training set, and 1.2% in the dev set.10
Results using these new features are shown in Ta-
ble 6. The first part repeats the CORE12 baseline.
The second part repeats previous experiments with
surface morphological features. The third part uses
the new functional morphological features instead.
The performance using NUMBER and GENDER in-
creases by 0.21% and 0.22%, respectively, as we re-
place surface features with functional features. (Re-
call that there is no functional PERSON.) We then see
that the change in the representation of digits does
not help; in the large space of experiments we have
performed, we saw some improvement through the
use of this alternative representation, but not in any
of the feature combinations that performed best and
that we report on in this paper. We then use just the
RATIONALITY feature, which results in an increase
over the baseline. The combination of all three func-
tional features (NUMBER, GENDER, RATIONALITY)
provides for a nice cumulative effect. Adding PER-
SON hardly improves further.
In the fourth part of the table, we include the other
features which we found previously to be helpful,
10We didn’t mark the number-words since in our training data
there were less than 30 lemmas of less than 2000 such tokens, so
presumably their agreement patterns can be more easily learned.
namely DET and LMM. Here, using DET2 instead of
DET (see Section 5.4) gives us a slight improvement,
providing our best result using the CORE12 POS
tagset: 80.53%. This is a 1.85% improvement over
using only the CORE12 POS tags (an 8.7% error re-
duction); of this improvement, 0.3% absolute (35%
relative) is due to the use of functional features. We
then use the best configuration, but without the RA-
TIONALITY feature; we see that this feature on its
own contributes 0.1% absolute, confirming its place
in Arabic syntax. In gold experiments which we
do not report here, the contribution was even higher
(0.6-0.7%). The last row in the fourth part of Table 6
shows that using both surface and functional variants
of NUMBER and GENDER does not help (hurts, in
fact); the functional morphology features carry suf-
ficient information for syntactic disambiguation.
The last part of the table revalidates the gains
achieved of the best feature combination using the
two other POS tagsets mentioned in Section 3: CAT-
IBEX (the best performing tagset with predicted val-
ues), and BW (the best POS tagset with gold val-
ues in Marton et al. (2010), but results shown here
are with predicted values). The CATIBEX result of
80.83% is our overall best result. The result using
BW reconfirms that BW is not the best tagset to use
for parsing Arabic with current prediction ability.
</bodyText>
<subsectionHeader confidence="0.992464">
5.6 Validating results on unseen test set
</subsectionHeader>
<bodyText confidence="0.9984">
Once experiments on the development set were
done, we ran the best performing models on the pre-
viously unseen test set (Section 5.1). Table 7 shows
that the same trends hold on this set as well.
</bodyText>
<table confidence="0.929884666666667">
Model LAS LASdiff UAS
CATIBEX 78.46 — 81.81
+DET2+LMM+PER+FN*NGR 79.45++ 0.99 82.56
</table>
<tableCaption confidence="0.9915455">
Table 7: Results on unseen test set for models which performed
best on dev set – predicted input.
</tableCaption>
<sectionHeader confidence="0.999694" genericHeader="method">
6 Error Analysis
</sectionHeader>
<bodyText confidence="0.9999674">
We analyze the attachment accuracy by attachment
type. We show the accuracy for selected attach-
ment types in Table 8. Using just CORE12, we see
that some attachments (subject, modifications) are
harder than others (objects, idafa). We see that by
</bodyText>
<page confidence="0.901415">
1593
</page>
<table confidence="0.99914225">
Features SBJ OBJ MN MP IDF Tot.
CORE12 67.9 90.4 72.0 70.3 94.5 78.7
CORE12 + LMM 68.8 90.4 72.6 70.9 94.6 79.0
CORE12 + DET2 71.7 91.0 74.9 72.4 95.5 80.2
+LMM+PNG
CORE12 + DET2 72.3 91.0 76.0 73.3 95.4 80.5
+LMM+PERS
+FN*NGR
</table>
<tableCaption confidence="0.61257975">
Table 8: Error analysis: Accuracy by attachment type (se-
lected): subject, object, modification by a noun, modification
(of a verb or a noun) by a preposition, idafa, and overall results
(which match previously shown results)
</tableCaption>
<bodyText confidence="0.999851666666667">
adding LMM, all attachment types improve a little
bit; this is as expected, since this feature provides
a slight lexical abstraction. We then add features
designed to improve idafa and those relations sub-
ject to agreement, subject and nominal modification
(DET2, PERSON, NUMBER, GENDER). We see that
as expected, subject, nominal modification (MN),
and idafa reduce error by substantial margins (error
reduction over CORE12+LMM greater than 8%, in
the case of idafa the error reduction is 16.7%), while
object and prepositional attachment (MP) improve
to a lesser degree (error reduction of 6.2% or less).
We assume that the relations not subject to agree-
ment (object and prepositional attachment) improve
because of the overall improvement in the parse due
to the improvements in the other relations.
When we move to the functional features, we
again see a reduction in the attachments which are
subject to agreement, namely subject and nomi-
nal modification (error reductions over surface fea-
tures of 2.1% and 4.4%, respectively). Idafa de-
creases slightly (since this relation is not affected
by the functional features), while object stays the
same. Surprisingly, prepositional attachment also
improves, with an error reduction of 3.3%. Again,
we can only explain this by proposing that the im-
provement in nominal modification attachment has
the indirect effect of ruling out some bad preposi-
tional attachments as well.
In summary, we see that not only do morphologi-
cal features – and functional morphology features in
particular – improve parsing, but they improve pars-
ing in the way that we expect: those relations subject
to agreement improve more than those that are not.
Last, we point out that MaltParser does not model
generalized feature checking or matching directly,
i.e., it has not learned that certain syntactic relations
require identical (functional) morphological feature
values. The gains in parsing quality reflect that the
MaltParser SVM classifier has learned that the pair-
ing of specific morphological feature values – e.g.,
fem.sing. for both the verb and its subject – is use-
ful, with no generalization from each specific value
to other values, or to general pair-wise value match-
ing.
</bodyText>
<sectionHeader confidence="0.99783" genericHeader="conclusions">
7 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999990523809524">
We explored the contribution of different morpho-
logical (inflectional and lexical) features to depen-
dency parsing of Arabic. We find that definiteness
(DET), 0-features (PERSON, NUMBER, GENDER),
and undiacritized lemma (LMM) are most helpful for
Arabic dependency parsing on predicted input. We
further find that functional morphology features and
rationality improve over surface morphological fea-
tures, as predicted by the complex agreement rules
of Arabic. To our knowledge, this is the first result
in Arabic NLP that uses functional morphology fea-
tures, and that shows an improvement over surface
features.
In future work, we intend to improve the predic-
tion of functional morphological features in order to
improve parsing accuracy. We also intend to investi-
gate how these features can be integrated into other
parsing frameworks; we expect them to help inde-
pendently of the framework. We plan to make our
parser available to other researchers. Please contact
the authors if interested.
</bodyText>
<sectionHeader confidence="0.998137" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99956675">
This work was supported by the DARPA GALE
program, contract HR0011-08-C-0110. We thank
Joakim Nivre for his useful remarks, Otakar Smrž
for his help with Elixir-FM, Ryan Roth and Sarah
Alkuhlani for their help with data, and three anony-
mous reviewers for useful comments. Part of
the work was done while the first author was at
Columbia University.
</bodyText>
<page confidence="0.993863">
1594
</page>
<sectionHeader confidence="0.995946" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998288112149532">
Sarah Alkuhlani and Nizar Habash. 2011. A corpus for
modeling morpho-syntactic agreement in Arabic: gen-
der, number and rationality. In Proceedings of the 49th
Annual Meeting of the Association for Computational
Linguistics (ACL), Portland, Oregon, USA.
Sabine Buchholz and Erwin Marsi. 2006. CoNLL-
X shared task on multilingual dependency parsing.
In Proceedings of Computational Natural Language
Learning (CoNLL), pages 149–164.
Timothy A. Buckwalter. 2004. Buckwalter Arabic Mor-
phological Analyzer Version 2.0. Linguistic Data
Consortium, University of Pennsylvania, 2002. LDC
Cat alog No.: LDC2004L02, ISBN 1-58563-324-0.
Michael Collins, Jan Hajic, Lance Ramshaw, and
Christoph Tillmann. 1999. A statistical parser for
czech. In Proceedings of the 37th Annual Meeting of
the Association for Computational Linguistics (ACL),
College Park, Maryland, USA, June.
Brooke Cowan and Michael Collins. 2005. Morphology
and reranking for the statistical parsing of spanish. In
Proceedings of Human Language Technology (HLT)
and the Conference on Empirical Methods in Natural
Language Processing (EMNLP), pages 795–802.
Ali Dada. 2007. Implementation of Arabic numerals and
their syntax in GF. In Proceedings of the Workshop
on Computational Approaches to Semitic Languages,
pages 9–16, Prague, Czech Republic.
Mona Diab. 2007. Towards an optimal pos tag set for
modern standard arabic processing. In Proceedings
of Recent Advances in Natural Language Processing
(RANLP), Borovets, Bulgaria.
Gülsen Eryigit, Joakim Nivre, and Kemal Oflazer. 2008.
Dependency parsing of turkish. Computational Lin-
guistics, 34(3):357–389.
Spence Green and Christopher D. Manning. 2010. Better
Arabic parsing: Baselines, evaluations, and analysis.
In Proceedings of the 23rd International Conference
on Computational Linguistics (COLING), pages 394–
402, Beijing, China.
Nizar Habash and Owen Rambow. 2005. Arabic Tok-
enization, Part-of-Speech Tagging and Morphological
Disambiguation in One Fell Swoop. In Proceedings of
the 43rd Annual Meeting of the Association for Com-
putational Linguistics (ACL), pages 573–580, Ann Ar-
bor, Michigan.
Nizar Habash and Ryan Roth. 2009. Catib: The
columbia arabic treebank. In Proceedings of the ACL-
IJCNLP 2009 Conference Short Papers, pages 221–
224, Suntec, Singapore, August.
Nizar Habash, Reem Faraj, and Ryan Roth. 2009. Syn-
tactic Annotation in the Columbia Arabic Treebank. In
Proceedings of MEDAR International Conference on
Arabic Language Resources and Tools, Cairo, Egypt.
Nizar Habash. 2010. Introduction to Arabic Natural
Language Processing. Morgan &amp; Claypool Publish-
ers.
Jan Hajiˇc and Barbora Vidová-Hladká. 1998. Tag-
ging Inflective Languages: Prediction of Morpholog-
ical Categories for a Rich, Structured Tagset. In Pro-
ceedings of the International Conference on Com-
putational Linguistics (COLING)- the Association for
Computational Linguistics (ACL), pages 483–490.
Sandra Kübler, Ryan McDonald, and Joakim Nivre.
2009. Dependency Parsing. Synthesis Lectures on
Human Language Technologies. Morgan and Claypool
Publishers.
Seth Kulick, Ryan Gabbard, and Mitch Marcus. 2006.
Parsing the Arabic Treebank: Analysis and improve-
ments. In Proceedings of the Treebanks and Linguis-
tic Theories Conference, pages 31–42, Prague, Czech
Republic.
Mohamed Maamouri, Ann Bies, Timothy A. Buckwalter,
and Wigdan Mekki. 2004. The Penn Arabic Treebank:
Building a Large-Scale Annotated Arabic Corpus. In
Proceedings of the NEMLAR Conference on Arabic
Language Resources and Tools, pages 102–109, Cairo,
Egypt.
Yuval Marton, Nizar Habash, and Owen Rambow. 2010.
Improving Arabic dependency parsing with inflec-
tional and lexical morphological features. In Proceed-
ings of Workshop on Statistical Parsing of Morpho-
logically Rich Languages (SPMRL) at the 11th Meet-
ing of the North American Chapter of the Association
for Computational Linguistics (NAACL) - Human Lan-
guage Technology (HLT), Los Angeles, USA.
Jens Nilsson and Joakim Nivre. 2008. MaltEval: An
evaluation and visualization tool for dependency pars-
ing. In Proceedings of the sixth International Confer-
ence on Language Resources and Evaluation (LREC),
Marrakech, Morocco.
Joakim Nivre, Johan Hall, Jens Nilsson, Atanas Chanev,
Gulsen Eryigit, Sandra Kubler, Svetoslav Marinov,
and Erwin Marsi. 2007. MaltParser: A language-
independent system for data-driven dependency pars-
ing. Natural Language Engineering, 13(2):95–135.
Joakim Nivre, Igor M. Boguslavsky, and Leonid K.
Iomdin. 2008. Parsing the SynTagRus Treebank of
Russian. In Proceedings of the 22nd International
Conference on Computational Linguistics (COLING),
pages 641–648.
Joakim Nivre. 2003. An efficient algorithm for pro-
jective dependency parsing. In Proceedings of the
8th International Conference on Parsing Technologies
(IWPT), pages 149–160, Nancy, France.
Joakim Nivre. 2008. Algorithms for deterministic incre-
mental dependency parsing. Computational Linguis-
tics, 34(4).
</reference>
<page confidence="0.802969">
1595
</page>
<reference confidence="0.999668473684211">
Joakim Nivre. 2009. Parsing Indian languages with
MaltParser. In Proceedings of the ICON09 NLP Tools
Contest: Indian Language Dependency Parsing, pages
12–18.
Ryan Roth, Owen Rambow, Nizar Habash, Mona Diab,
and Cynthia Rudin. 2008. Arabic morphological tag-
ging, diacritization, and lemmatization using lexeme
models and feature ranking. In Proceedings of ACL-
08: HLT, Short Papers, pages 117–120, Columbus,
Ohio, June. Association for Computational Linguis-
tics.
Otakar Smrž. 2007. FunctionalArabic Morphology. For-
mal System and Implementation. Ph.D. thesis, Charles
University, Prague.
Reut Tsarfaty and Khalil Sima’an. 2007. Three-
dimensional parametrization for parsing morphologi-
cally rich languages. In Proceedings of the 10th Inter-
national Conference on Parsing Technologies (IWPT),
pages 156–167, Morristown, NJ, USA.
</reference>
<page confidence="0.992516">
1596
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.396451">
<title confidence="0.9986835">Improving Arabic Dependency Parsing with Form-based and Morphological Features</title>
<author confidence="0.673539">Marton Nizar Habash Rambow T J Watson Research Center Center for Computational Learning Systems</author>
<affiliation confidence="0.992903">IBM Columbia</affiliation>
<email confidence="0.999657">yymarton@us.ibm.com{habash,rambow}@ccls.columbia.edu</email>
<abstract confidence="0.983361466666667">We explore the contribution of morphological features – both lexical and inflectional – to dependency parsing of Arabic, a morphologically rich language. Using controlled experiments, we find that definiteness, person, number, gender, and the undiacritzed lemma are most helpful for parsing on automatically tagged input. We further contrast the contribution of form-based and functional features, and show that functional gender and number (e.g., “broken plurals”) and the related rationality feature improve over form-based features. It is the first time functional morphological features are used for Arabic NLP.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Sarah Alkuhlani</author>
<author>Nizar Habash</author>
</authors>
<title>A corpus for modeling morpho-syntactic agreement in Arabic: gender, number and rationality.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<location>Portland, Oregon, USA.</location>
<contexts>
<context position="9669" citStr="Alkuhlani and Habash (2011)" startWordPosition="1487" endWordPosition="1490">d functional features. Most available Arabic NLP tools and resources model morphology using surface inflectional features and do not mark rationality; this includes the PATB (Maamouri et al., 2004), the Buckwalter morphological analyzer (BAMA) (Buckwalter, 2004) and tools using them such as the Morphological Analysis and Disambiguation for Arabic (MADA) system (Habash and Rambow, 2005). The ElixirFM analyzer (Smrž, 2007) readily provides the functional inflectional number feature, but not full functional gender (only for adjectives and verbs but not for nouns), nor rationality. Most recently, Alkuhlani and Habash (2011) present a version of the PATB (part 3) that is annotated for functional gender, num3We ignore duals, which are regular in Arabic, and case/state variations in this discussion for simplicity. 4Smrž (2007) uses the term illusory for surface features. ber and rationality features for Arabic. We use this resource in modeling these features in Section 5.5. Morpho-syntactic interactions Inflectional features and rationality interact with syntax in two ways. In agreement relations, two words in a specific syntactic configuration have coordinated values for specific sets of features. MSA has standard</context>
<context position="28817" citStr="Alkuhlani and Habash (2011)" startWordPosition="4484" endWordPosition="4487">rformance, so it was abandoned. 5.5 Functional feature values The NUMBER and GENDER features we have used so far only reflect surface (as opposed to functional) values, e.g., broken plurals are marked as singular. This might have a negative effect on learning generalizations over the complex agreement patterns in MSA (see Section 3), beyond memorization of word pairs seen together in training. Predicting functional features To predict functional GENDER, functional NUMBER and RATIONALITY, we build a simple maximum likelihood estimate (MLE) model using these annotations in the corpus created by Alkuhlani and Habash (2011). We train using the same training data we use throughout this paper. For all three features, we select the most seen value in training associated with the triple word-CATIBEX-lemma; we back off to CATIBEXlemma and then to lemma. For gender and number, we further back off to the surface values; for rationality, we back off to the most common value (irrational). On our predicted dev set, the overall accuracy baseline of predicting correct functional gender-number-rationality using surface features is 1592 85.1% (for all POS tags). Our MLE model reduces the error by two thirds reaching an overal</context>
</contexts>
<marker>Alkuhlani, Habash, 2011</marker>
<rawString>Sarah Alkuhlani and Nizar Habash. 2011. A corpus for modeling morpho-syntactic agreement in Arabic: gender, number and rationality. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL), Portland, Oregon, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>CoNLLX shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of Computational Natural Language Learning (CoNLL),</booktitle>
<pages>149--164</pages>
<contexts>
<context position="16096" citStr="Buchholz and Marsi, 2006" startWordPosition="2504" endWordPosition="2507">ns, and verbs; and mode for verbs) outperforms other combinations. Our approach is comparable to their work in terms of its systematic exploration of the space of morphological features. We also find that the number feature helps for Arabic. Looking at Hebrew, a Semitic language related to Arabic, Tsarfaty and Sima’an (2007) report that extending POS and phrase structure tags with definiteness information helps unlexicalized PCFG parsing. As for work on Arabic, results have been reported on PATB (Kulick et al., 2006; Diab, 2007; Green and Manning, 2010), the Prague Dependency Treebank (PADT) (Buchholz and Marsi, 2006; Nivre, 2008) and the Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009). Recently, Green and Manning (2010) analyzed the PATB for annotation consistency, and introduced an enhanced split-state constituency grammar, including labels for short Idafa constructions and verbal or equational clauses. Nivre (2008) reports experiments on Arabic parsing using his MaltParser (Nivre et al., 2007), trained on the PADT. His results are not directly comparable to ours because of the different treebanks’ representations, even though all the experiments reported here were performed using MaltParser. O</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Sabine Buchholz and Erwin Marsi. 2006. CoNLLX shared task on multilingual dependency parsing. In Proceedings of Computational Natural Language Learning (CoNLL), pages 149–164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy A Buckwalter</author>
</authors>
<title>Buckwalter Arabic Morphological Analyzer Version 2.0. Linguistic Data Consortium,</title>
<date>2004</date>
<booktitle>LDC Cat alog No.: LDC2004L02, ISBN</booktitle>
<pages>1--58563</pages>
<institution>University of Pennsylvania,</institution>
<contexts>
<context position="9304" citStr="Buckwalter, 2004" startWordPosition="1433" endWordPosition="1434">xes, e.g., the feminine form of the 6 masculine singular adjective �†„@Âzraq+0 ‘blue’ is ZA79PP� zarqA’+0 not �é�¯P �P�@* *Âzraq+ah. To address this inconsistency in the correspondence between inflectional features and morphemes, and inspired by (Smrž, 2007), we distinguish between two types of inflectional features: surface (or form-based)4 features and functional features. Most available Arabic NLP tools and resources model morphology using surface inflectional features and do not mark rationality; this includes the PATB (Maamouri et al., 2004), the Buckwalter morphological analyzer (BAMA) (Buckwalter, 2004) and tools using them such as the Morphological Analysis and Disambiguation for Arabic (MADA) system (Habash and Rambow, 2005). The ElixirFM analyzer (Smrž, 2007) readily provides the functional inflectional number feature, but not full functional gender (only for adjectives and verbs but not for nouns), nor rationality. Most recently, Alkuhlani and Habash (2011) present a version of the PATB (part 3) that is annotated for functional gender, num3We ignore duals, which are regular in Arabic, and case/state variations in this discussion for simplicity. 4Smrž (2007) uses the term illusory for sur</context>
<context position="12300" citStr="Buckwalter, 2004" startWordPosition="1878" endWordPosition="1879">re as inflectional features do. Instead, bilexical dependencies are used to model semantic relations which often are the only way to disambiguate among different possible syntactic structures. Lexical abstraction also reduces data sparseness. The core POS tagsets Words also have associated part-of-speech (POS) tags, e.g., “verb”, which further abstract over morphologically and syntactically similar lexemes. Traditional Arabic grammars often describe a very general three-way distinction into verbs, nominals and particles. In com1588 parison, the tagset of the Buckwalter Morphological Analyzer (Buckwalter, 2004) used in the PATB has a core POS set of 44 tags (before morphological extension). Cross-linguistically, a core set containing around 12 tags is often assumed, including: noun, proper noun, verb, adjective, adverb, preposition, particles, connectives, and punctuation. Henceforth, we reduce CORE44 to such a tagset, and dub it CORE12. The CATIB6 tagset can be viewed as a further reduction, with the exception that CATIB6 contains a passive voice tag; however, this tag constitutes only 0.5% of the tags in the training. Extended POS tagsets The notion of “POS tagset” in natural language processing u</context>
<context position="14451" citStr="Buckwalter, 2004" startWordPosition="2235" endWordPosition="2236"> certain morphological features. A full dicussion of how these tagsets affect parsing is presented in Marton et al. (2010); we summarize the main points here. The following are the various tagsets we use in this paper: (a) the core POS tagset CORE12; (b) the CATiB treebank tagset CATIBEX, a newly introduced extension of CATIB6 (Habash and Roth, 2009) by simple regular expressions of the word form, indicating particular morphemes such as the prefix JI Al+ or the suffix v_3 +wn; this tagset is the best-performing tagset for Arabic on predicted values. (c) the PATB full tagset (BW), size ≈2000+ (Buckwalter, 2004); We only discuss here the best performing tagsets (on predicted values), and BW for comparison. 4 Related Work Much work has been done on the use of morphological features for parsing of morphologically rich languages. Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable). This tagset (size 58) outperforms the basic Czech POS tagset (size 13) and the complete tagset (size ,:3000+). They also report that the use of gender, number and person features did not yield any improvements. We got similar results for CASE </context>
</contexts>
<marker>Buckwalter, 2004</marker>
<rawString>Timothy A. Buckwalter. 2004. Buckwalter Arabic Morphological Analyzer Version 2.0. Linguistic Data Consortium, University of Pennsylvania, 2002. LDC Cat alog No.: LDC2004L02, ISBN 1-58563-324-0.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Jan Hajic</author>
<author>Lance Ramshaw</author>
<author>Christoph Tillmann</author>
</authors>
<title>A statistical parser for czech.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<location>College Park, Maryland, USA,</location>
<contexts>
<context position="14692" citStr="Collins et al. (1999)" startWordPosition="2274" endWordPosition="2277">agset CORE12; (b) the CATiB treebank tagset CATIBEX, a newly introduced extension of CATIB6 (Habash and Roth, 2009) by simple regular expressions of the word form, indicating particular morphemes such as the prefix JI Al+ or the suffix v_3 +wn; this tagset is the best-performing tagset for Arabic on predicted values. (c) the PATB full tagset (BW), size ≈2000+ (Buckwalter, 2004); We only discuss here the best performing tagsets (on predicted values), and BW for comparison. 4 Related Work Much work has been done on the use of morphological features for parsing of morphologically rich languages. Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable). This tagset (size 58) outperforms the basic Czech POS tagset (size 13) and the complete tagset (size ,:3000+). They also report that the use of gender, number and person features did not yield any improvements. We got similar results for CASE in the gold experimental setting (Marton et al., 2010) but not when using predicted POS tags (POS tagger output). This may be a result of CASE tagging having a lower error rate in Czech (5.0%) (Hajiˇc and Vidová-Hladká, 1998) compared to Ara</context>
</contexts>
<marker>Collins, Hajic, Ramshaw, Tillmann, 1999</marker>
<rawString>Michael Collins, Jan Hajic, Lance Ramshaw, and Christoph Tillmann. 1999. A statistical parser for czech. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics (ACL), College Park, Maryland, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brooke Cowan</author>
<author>Michael Collins</author>
</authors>
<title>Morphology and reranking for the statistical parsing of spanish.</title>
<date>2005</date>
<booktitle>In Proceedings of Human Language Technology (HLT) and the Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>795--802</pages>
<contexts>
<context position="15355" citStr="Cowan and Collins (2005)" startWordPosition="2388" endWordPosition="2391">ing Czech consists of a basic POS tag plus a CASE feature (when applicable). This tagset (size 58) outperforms the basic Czech POS tagset (size 13) and the complete tagset (size ,:3000+). They also report that the use of gender, number and person features did not yield any improvements. We got similar results for CASE in the gold experimental setting (Marton et al., 2010) but not when using predicted POS tags (POS tagger output). This may be a result of CASE tagging having a lower error rate in Czech (5.0%) (Hajiˇc and Vidová-Hladká, 1998) compared to Arabic (,:14.0%, see Table 2). Similarly, Cowan and Collins (2005) report that the use of a subset of Spanish morphological features (number for adjectives, determiners, nouns, pronouns, and verbs; and mode for verbs) outperforms other combinations. Our approach is comparable to their work in terms of its systematic exploration of the space of morphological features. We also find that the number feature helps for Arabic. Looking at Hebrew, a Semitic language related to Arabic, Tsarfaty and Sima’an (2007) report that extending POS and phrase structure tags with definiteness information helps unlexicalized PCFG parsing. As for work on Arabic, results have been</context>
</contexts>
<marker>Cowan, Collins, 2005</marker>
<rawString>Brooke Cowan and Michael Collins. 2005. Morphology and reranking for the statistical parsing of spanish. In Proceedings of Human Language Technology (HLT) and the Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 795–802.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ali Dada</author>
</authors>
<title>Implementation of Arabic numerals and their syntax in GF.</title>
<date>2007</date>
<booktitle>In Proceedings of the Workshop on Computational Approaches to Semitic Languages,</booktitle>
<pages>9--16</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="29836" citStr="Dada, 2007" startWordPosition="4655" endWordPosition="4656">cy baseline of predicting correct functional gender-number-rationality using surface features is 1592 85.1% (for all POS tags). Our MLE model reduces the error by two thirds reaching an overall accuracy of 95.5%. The high accuracy may be a result of the low percentage of words in the dev set that do not appear in training (around 4.6%). Digit tokens (e.g., “4”) are also marked singular by default. They don’t show surface agreement, even though the corresponding number-word token (a,..,�IArbkh ‘four.fem.sing’) would. We further observe that MSA displays complex agreement patterns with numbers (Dada, 2007). Therefore, we alternatively experimented with binning the digit tokens’ NUMBER value accordingly: • the number 0 and numbers ending with 00 • the number 1 and numbers ending with 01 • the number 2 and numbers ending with 02 • the numbers 3-10 and those ending with 03-10 • the numbers, and numbers ending with, 11-99 • all other number tokens (e.g., 0.35 or 7/16) and denoted these experiments with NUMDGTBIN. Almost 1.5% of the tokens are digit tokens in the training set, and 1.2% in the dev set.10 Results using these new features are shown in Table 6. The first part repeats the CORE12 baseline</context>
</contexts>
<marker>Dada, 2007</marker>
<rawString>Ali Dada. 2007. Implementation of Arabic numerals and their syntax in GF. In Proceedings of the Workshop on Computational Approaches to Semitic Languages, pages 9–16, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
</authors>
<title>Towards an optimal pos tag set for modern standard arabic processing.</title>
<date>2007</date>
<booktitle>In Proceedings of Recent Advances in Natural Language Processing (RANLP), Borovets,</booktitle>
<contexts>
<context position="16005" citStr="Diab, 2007" startWordPosition="2492" endWordPosition="2493">ish morphological features (number for adjectives, determiners, nouns, pronouns, and verbs; and mode for verbs) outperforms other combinations. Our approach is comparable to their work in terms of its systematic exploration of the space of morphological features. We also find that the number feature helps for Arabic. Looking at Hebrew, a Semitic language related to Arabic, Tsarfaty and Sima’an (2007) report that extending POS and phrase structure tags with definiteness information helps unlexicalized PCFG parsing. As for work on Arabic, results have been reported on PATB (Kulick et al., 2006; Diab, 2007; Green and Manning, 2010), the Prague Dependency Treebank (PADT) (Buchholz and Marsi, 2006; Nivre, 2008) and the Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009). Recently, Green and Manning (2010) analyzed the PATB for annotation consistency, and introduced an enhanced split-state constituency grammar, including labels for short Idafa constructions and verbal or equational clauses. Nivre (2008) reports experiments on Arabic parsing using his MaltParser (Nivre et al., 2007), trained on the PADT. His results are not directly comparable to ours because of the different treebanks’ repres</context>
</contexts>
<marker>Diab, 2007</marker>
<rawString>Mona Diab. 2007. Towards an optimal pos tag set for modern standard arabic processing. In Proceedings of Recent Advances in Natural Language Processing (RANLP), Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gülsen Eryigit</author>
<author>Joakim Nivre</author>
<author>Kemal Oflazer</author>
</authors>
<title>Dependency parsing of turkish.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>3</issue>
<contexts>
<context position="17133" citStr="Eryigit et al., 2008" startWordPosition="2663" endWordPosition="2666">. His results are not directly comparable to ours because of the different treebanks’ representations, even though all the experiments reported here were performed using MaltParser. Our results agree with previous work on Arabic and Hebrew in that marking the definite article is helpful for parsing. However, we go beyond previous work in that 1589 we also extend this morphologically enhanced feature set to include additional lexical and inflectional features. Previous work with MaltParser in Russian, Turkish and Hindi showed gains with case but not with agreement features (Nivre et al., 2008; Eryigit et al., 2008; Nivre, 2009). Our work is the first using MaltParser to show gains using agreement-oriented features (Marton et al., 2010), and the first to use functional features for this task (this paper). 5 Experiments Throughout this section, we only report results using predicted input feature values (e.g., generated automatically by a POS tagger). After presenting the parser we use (Section 5.1), we examine a large space of settings in the following order: the contribution of numerous inflectional features in a controlled fashion (Section 5.2);5 the contribution of the lexical features in a similar f</context>
</contexts>
<marker>Eryigit, Nivre, Oflazer, 2008</marker>
<rawString>Gülsen Eryigit, Joakim Nivre, and Kemal Oflazer. 2008. Dependency parsing of turkish. Computational Linguistics, 34(3):357–389.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Spence Green</author>
<author>Christopher D Manning</author>
</authors>
<title>Better Arabic parsing: Baselines, evaluations, and analysis.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (COLING),</booktitle>
<pages>394--402</pages>
<location>Beijing, China.</location>
<contexts>
<context position="16031" citStr="Green and Manning, 2010" startWordPosition="2494" endWordPosition="2497">gical features (number for adjectives, determiners, nouns, pronouns, and verbs; and mode for verbs) outperforms other combinations. Our approach is comparable to their work in terms of its systematic exploration of the space of morphological features. We also find that the number feature helps for Arabic. Looking at Hebrew, a Semitic language related to Arabic, Tsarfaty and Sima’an (2007) report that extending POS and phrase structure tags with definiteness information helps unlexicalized PCFG parsing. As for work on Arabic, results have been reported on PATB (Kulick et al., 2006; Diab, 2007; Green and Manning, 2010), the Prague Dependency Treebank (PADT) (Buchholz and Marsi, 2006; Nivre, 2008) and the Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009). Recently, Green and Manning (2010) analyzed the PATB for annotation consistency, and introduced an enhanced split-state constituency grammar, including labels for short Idafa constructions and verbal or equational clauses. Nivre (2008) reports experiments on Arabic parsing using his MaltParser (Nivre et al., 2007), trained on the PADT. His results are not directly comparable to ours because of the different treebanks’ representations, even though all</context>
</contexts>
<marker>Green, Manning, 2010</marker>
<rawString>Spence Green and Christopher D. Manning. 2010. Better Arabic parsing: Baselines, evaluations, and analysis. In Proceedings of the 23rd International Conference on Computational Linguistics (COLING), pages 394– 402, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
</authors>
<title>Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>573--580</pages>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="9430" citStr="Habash and Rambow, 2005" startWordPosition="1450" endWordPosition="1453">@* *Âzraq+ah. To address this inconsistency in the correspondence between inflectional features and morphemes, and inspired by (Smrž, 2007), we distinguish between two types of inflectional features: surface (or form-based)4 features and functional features. Most available Arabic NLP tools and resources model morphology using surface inflectional features and do not mark rationality; this includes the PATB (Maamouri et al., 2004), the Buckwalter morphological analyzer (BAMA) (Buckwalter, 2004) and tools using them such as the Morphological Analysis and Disambiguation for Arabic (MADA) system (Habash and Rambow, 2005). The ElixirFM analyzer (Smrž, 2007) readily provides the functional inflectional number feature, but not full functional gender (only for adjectives and verbs but not for nouns), nor rationality. Most recently, Alkuhlani and Habash (2011) present a version of the PATB (part 3) that is annotated for functional gender, num3We ignore duals, which are regular in Arabic, and case/state variations in this discussion for simplicity. 4Smrž (2007) uses the term illusory for surface features. ber and rationality features for Arabic. We use this resource in modeling these features in Section 5.5. Morpho</context>
</contexts>
<marker>Habash, Rambow, 2005</marker>
<rawString>Nizar Habash and Owen Rambow. 2005. Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL), pages 573–580, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Ryan Roth</author>
</authors>
<title>Catib: The columbia arabic treebank.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACLIJCNLP 2009 Conference Short Papers,</booktitle>
<pages>221--224</pages>
<location>Suntec, Singapore,</location>
<contexts>
<context position="2388" citStr="Habash and Roth, 2009" startWordPosition="358" endWordPosition="361">res. We expect that representing lexical abstractions and inflectional features participating in agreement relations would help parsing quality, but other inflectional features would not help. We further expect functional features to be superior to surfaceonly features. The paper is structured as follows. We first present the corpus we use (Section 2), then relevant Arabic linguistic facts (Section 3); we survey related work (Section 4), describe our experiments (Section 5), and conclude with an analysis of parsing error types (Section 6). 2 Corpus We use the Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009). Specifically, we use the portion converted automatically from part 3 of the Penn Arabic Treebank (PATB) (Maamouri et al., 2004) to the CATiB format, which enriches the CATiB dependency trees with full PATB morphological information. CATiB’s dependency representation is based on traditional Arabic grammar and emphasizes syntactic case relations. It has a reduced POS tagset (with six tags only – henceforth CATIB6), but a standard set of eight dependency relations: SBJ and OBJ for subject and (direct or indirect) object, respectively, (whether they appear preor post-verbally); IDF for the idafa</context>
<context position="14186" citStr="Habash and Roth, 2009" startWordPosition="2189" endWordPosition="2192">lish PTB tagset, as this has proven to be a useful size computationally. These tagsets are hybrids in the sense that they are neither simply the core POS, nor the complete morphologically enriched tagset, but instead they selectively enrich the core POS tagset with only certain morphological features. A full dicussion of how these tagsets affect parsing is presented in Marton et al. (2010); we summarize the main points here. The following are the various tagsets we use in this paper: (a) the core POS tagset CORE12; (b) the CATiB treebank tagset CATIBEX, a newly introduced extension of CATIB6 (Habash and Roth, 2009) by simple regular expressions of the word form, indicating particular morphemes such as the prefix JI Al+ or the suffix v_3 +wn; this tagset is the best-performing tagset for Arabic on predicted values. (c) the PATB full tagset (BW), size ≈2000+ (Buckwalter, 2004); We only discuss here the best performing tagsets (on predicted values), and BW for comparison. 4 Related Work Much work has been done on the use of morphological features for parsing of morphologically rich languages. Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE featu</context>
<context position="16175" citStr="Habash and Roth, 2009" startWordPosition="2516" endWordPosition="2519">s comparable to their work in terms of its systematic exploration of the space of morphological features. We also find that the number feature helps for Arabic. Looking at Hebrew, a Semitic language related to Arabic, Tsarfaty and Sima’an (2007) report that extending POS and phrase structure tags with definiteness information helps unlexicalized PCFG parsing. As for work on Arabic, results have been reported on PATB (Kulick et al., 2006; Diab, 2007; Green and Manning, 2010), the Prague Dependency Treebank (PADT) (Buchholz and Marsi, 2006; Nivre, 2008) and the Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009). Recently, Green and Manning (2010) analyzed the PATB for annotation consistency, and introduced an enhanced split-state constituency grammar, including labels for short Idafa constructions and verbal or equational clauses. Nivre (2008) reports experiments on Arabic parsing using his MaltParser (Nivre et al., 2007), trained on the PADT. His results are not directly comparable to ours because of the different treebanks’ representations, even though all the experiments reported here were performed using MaltParser. Our results agree with previous work on Arabic and Hebrew in that marking the de</context>
</contexts>
<marker>Habash, Roth, 2009</marker>
<rawString>Nizar Habash and Ryan Roth. 2009. Catib: The columbia arabic treebank. In Proceedings of the ACLIJCNLP 2009 Conference Short Papers, pages 221– 224, Suntec, Singapore, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Reem Faraj</author>
<author>Ryan Roth</author>
</authors>
<title>Syntactic Annotation in the Columbia Arabic Treebank.</title>
<date>2009</date>
<booktitle>In Proceedings of MEDAR International Conference on Arabic Language Resources and Tools,</booktitle>
<location>Cairo, Egypt.</location>
<contexts>
<context position="3155" citStr="Habash et al. (2009)" startWordPosition="481" endWordPosition="484">at, which enriches the CATiB dependency trees with full PATB morphological information. CATiB’s dependency representation is based on traditional Arabic grammar and emphasizes syntactic case relations. It has a reduced POS tagset (with six tags only – henceforth CATIB6), but a standard set of eight dependency relations: SBJ and OBJ for subject and (direct or indirect) object, respectively, (whether they appear preor post-verbally); IDF for the idafa (possessive) relation; MOD for most other modifications; and other less common relations that we will not discuss here. For more information, see Habash et al. (2009). The CATiB treebank uses the word segmentation of the PATB: it splits off several categories of orthographic clitics, but not the definite article JI Al. In all of the experiments reported in this paper, we use the gold 1586 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1586–1596, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics VRB ÉÒª�K tsml ‘work’ MOD SBJ NOM u@YJ�&amp;quot;®k HfydAt ‘granddaughters’ NOM €P@YÖÏ@ AlmdArs ‘the-schools’ MOD NOM éJ��ÓñºmÌ @ AlHkwmyh ‘the-governmental’ Figure 1: CATiB Annotation example</context>
</contexts>
<marker>Habash, Faraj, Roth, 2009</marker>
<rawString>Nizar Habash, Reem Faraj, and Ryan Roth. 2009. Syntactic Annotation in the Columbia Arabic Treebank. In Proceedings of MEDAR International Conference on Arabic Language Resources and Tools, Cairo, Egypt.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
</authors>
<title>Introduction to Arabic Natural Language Processing.</title>
<date>2010</date>
<publisher>Morgan &amp; Claypool Publishers.</publisher>
<contexts>
<context position="4482" citStr="Habash, 2010" startWordPosition="686" endWordPosition="687">AlðkyAt fy AlmdArs AlHkwmyh ‘The writer’s smart granddaughters work for public schools.’ segmentation. An example CATiB dependency tree is shown in Figure 1. 3 Relevant Linguistic Concepts In this section, we present the linguistic concepts relevant to our discussion of Arabic parsing. Orthography The Arabic script uses optional diacritics to represent short vowels, consonantal doubling and the indefininteness morpheme (nunation). For example, the word ~I. �� J�»kataba ‘he wrote’ is often written as I. -J»ktb, which can be ambiguous with text, only around 1.6% of all words have any diacritic (Habash, 2010). As expected, the lack of diacritics contributes heavily to Arabic’s morphological ambiguity. In this work, we only use undiacritized text; however, some of our parsing features which are derived through morphological disambiguation include diacritics (specifically, lemmas, see below). Morphemes Words can be described in terms of their morphemes; in Arabic, in addition to concatenative prefixes and suffixes, there are templatic morphemes called root and pattern. For example, the word vñJ.�KA3/4K� yu+kAtib+uwn ‘they correspond’ has one prefix and one suffix, in addition to a stem composed of t</context>
</contexts>
<marker>Habash, 2010</marker>
<rawString>Nizar Habash. 2010. Introduction to Arabic Natural Language Processing. Morgan &amp; Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
<author>Barbora Vidová-Hladká</author>
</authors>
<title>Tagging Inflective Languages: Prediction of Morphological Categories for a Rich, Structured Tagset.</title>
<date>1998</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics (COLING)- the Association for Computational Linguistics (ACL),</booktitle>
<pages>483--490</pages>
<marker>Hajiˇc, Vidová-Hladká, 1998</marker>
<rawString>Jan Hajiˇc and Barbora Vidová-Hladká. 1998. Tagging Inflective Languages: Prediction of Morphological Categories for a Rich, Structured Tagset. In Proceedings of the International Conference on Computational Linguistics (COLING)- the Association for Computational Linguistics (ACL), pages 483–490.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sandra Kübler</author>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Dependency Parsing. Synthesis Lectures on Human Language Technologies.</title>
<date>2009</date>
<publisher>Morgan and Claypool Publishers.</publisher>
<contexts>
<context position="18594" citStr="Kübler et al., 2009" startWordPosition="2900" endWordPosition="2903">y, putting best feature combinations to test with the best-performing POS tagset, and on an unseen test set (Section 5.6). All results are reported mainly in terms of labeled attachment accuracy score (parent word and the dependency relation to it, a.k.a. LAS). Unlabeled attachment accuracy score (UAS) is also given. We use McNemar’s statistical significance test as implemented by Nilsson and Nivre (2008), and denote p &lt; 0.05 and p &lt; 0.01 with + and ++, respectively. 5.1 Parser For all experiments reported here we used the syntactic dependency parser MaltParser v1.3 (Nivre, 2003; Nivre, 2008; Kübler et al., 2009) – a transition-based parser with an input buffer and a stack, using SVM classifiers to predict the next state in the parse derivation. All experiments were done using the Nivre &amp;quot;eager&amp;quot; algorithm.6 For training, de5In this paper, we do not examine the contribution of different POS tagsets, see Marton et al. (2010) for details. 6Nivre (2008) reports that non-projective and pseudoprojective algorithms outperform the &amp;quot;eager&amp;quot; projective algorithm in MaltParser, but our training data did not contain any non-projective dependencies. The Nivre &amp;quot;standard&amp;quot; algorithm velopment and testing, we follow the</context>
<context position="20100" citStr="Kübler et al. (2009)" startWordPosition="3145" endWordPosition="3148">t word ID), and deprel (the dependency relation between the current word and its parent). There are default MaltParser features (in the machine learning sense),7 which are the values of functions over these attributes, serving as input to the MaltParser internal classifiers. The most commonly used feature functions are the top of the input buffer (next word to process, denoted buf[0]), or top of the stack (denoted stk[0]); following items on buffer or stack are also accessible (buf[1], buf[2], stk[1], etc.). Hence MaltParser features are defined as POS tag at stk[0], word form at buf[0], etc. Kübler et al. (2009) describe a “typical” MaltParser model configuration of attributes and features.8 Starting with it, in a series of initial controlled experiments, we settled on using buf[0, 1] + stk[0, 1] for wordforms, and buf[0, 1, 2, 3] + stk[0, 1, 2] for POS tags. For features of new MaltParser-attributes (discussed later), we used buf[0] + stk[0]. We did not change the features for deprel. This new MaltParser configuration resulted in gains of 0.3-1.1% in labeled attachment accuracy (depending on the POS tagset) over the default MaltParser configuration.9 All experiments reported below were conducted usi</context>
</contexts>
<marker>Kübler, McDonald, Nivre, 2009</marker>
<rawString>Sandra Kübler, Ryan McDonald, and Joakim Nivre. 2009. Dependency Parsing. Synthesis Lectures on Human Language Technologies. Morgan and Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seth Kulick</author>
<author>Ryan Gabbard</author>
<author>Mitch Marcus</author>
</authors>
<title>Parsing the Arabic Treebank: Analysis and improvements.</title>
<date>2006</date>
<booktitle>In Proceedings of the Treebanks and Linguistic Theories Conference,</booktitle>
<pages>31--42</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="15993" citStr="Kulick et al., 2006" startWordPosition="2488" endWordPosition="2491">e of a subset of Spanish morphological features (number for adjectives, determiners, nouns, pronouns, and verbs; and mode for verbs) outperforms other combinations. Our approach is comparable to their work in terms of its systematic exploration of the space of morphological features. We also find that the number feature helps for Arabic. Looking at Hebrew, a Semitic language related to Arabic, Tsarfaty and Sima’an (2007) report that extending POS and phrase structure tags with definiteness information helps unlexicalized PCFG parsing. As for work on Arabic, results have been reported on PATB (Kulick et al., 2006; Diab, 2007; Green and Manning, 2010), the Prague Dependency Treebank (PADT) (Buchholz and Marsi, 2006; Nivre, 2008) and the Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009). Recently, Green and Manning (2010) analyzed the PATB for annotation consistency, and introduced an enhanced split-state constituency grammar, including labels for short Idafa constructions and verbal or equational clauses. Nivre (2008) reports experiments on Arabic parsing using his MaltParser (Nivre et al., 2007), trained on the PADT. His results are not directly comparable to ours because of the different treeb</context>
</contexts>
<marker>Kulick, Gabbard, Marcus, 2006</marker>
<rawString>Seth Kulick, Ryan Gabbard, and Mitch Marcus. 2006. Parsing the Arabic Treebank: Analysis and improvements. In Proceedings of the Treebanks and Linguistic Theories Conference, pages 31–42, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohamed Maamouri</author>
<author>Ann Bies</author>
<author>Timothy A Buckwalter</author>
<author>Wigdan Mekki</author>
</authors>
<title>The Penn Arabic Treebank: Building a Large-Scale Annotated Arabic Corpus.</title>
<date>2004</date>
<booktitle>In Proceedings of the NEMLAR Conference on Arabic Language Resources and Tools,</booktitle>
<pages>102--109</pages>
<location>Cairo, Egypt.</location>
<contexts>
<context position="2517" citStr="Maamouri et al., 2004" startWordPosition="378" endWordPosition="381">arsing quality, but other inflectional features would not help. We further expect functional features to be superior to surfaceonly features. The paper is structured as follows. We first present the corpus we use (Section 2), then relevant Arabic linguistic facts (Section 3); we survey related work (Section 4), describe our experiments (Section 5), and conclude with an analysis of parsing error types (Section 6). 2 Corpus We use the Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009). Specifically, we use the portion converted automatically from part 3 of the Penn Arabic Treebank (PATB) (Maamouri et al., 2004) to the CATiB format, which enriches the CATiB dependency trees with full PATB morphological information. CATiB’s dependency representation is based on traditional Arabic grammar and emphasizes syntactic case relations. It has a reduced POS tagset (with six tags only – henceforth CATIB6), but a standard set of eight dependency relations: SBJ and OBJ for subject and (direct or indirect) object, respectively, (whether they appear preor post-verbally); IDF for the idafa (possessive) relation; MOD for most other modifications; and other less common relations that we will not discuss here. For more</context>
<context position="9239" citStr="Maamouri et al., 2004" startWordPosition="1423" endWordPosition="1426">ears in feminine nouns that are not inflected using sound gender suffixes, e.g., the feminine form of the 6 masculine singular adjective �†„@Âzraq+0 ‘blue’ is ZA79PP� zarqA’+0 not �é�¯P �P�@* *Âzraq+ah. To address this inconsistency in the correspondence between inflectional features and morphemes, and inspired by (Smrž, 2007), we distinguish between two types of inflectional features: surface (or form-based)4 features and functional features. Most available Arabic NLP tools and resources model morphology using surface inflectional features and do not mark rationality; this includes the PATB (Maamouri et al., 2004), the Buckwalter morphological analyzer (BAMA) (Buckwalter, 2004) and tools using them such as the Morphological Analysis and Disambiguation for Arabic (MADA) system (Habash and Rambow, 2005). The ElixirFM analyzer (Smrž, 2007) readily provides the functional inflectional number feature, but not full functional gender (only for adjectives and verbs but not for nouns), nor rationality. Most recently, Alkuhlani and Habash (2011) present a version of the PATB (part 3) that is annotated for functional gender, num3We ignore duals, which are regular in Arabic, and case/state variations in this discu</context>
<context position="19268" citStr="Maamouri et al., 2004" startWordPosition="3008" endWordPosition="3011">d a stack, using SVM classifiers to predict the next state in the parse derivation. All experiments were done using the Nivre &amp;quot;eager&amp;quot; algorithm.6 For training, de5In this paper, we do not examine the contribution of different POS tagsets, see Marton et al. (2010) for details. 6Nivre (2008) reports that non-projective and pseudoprojective algorithms outperform the &amp;quot;eager&amp;quot; projective algorithm in MaltParser, but our training data did not contain any non-projective dependencies. The Nivre &amp;quot;standard&amp;quot; algorithm velopment and testing, we follow the splits used by Roth et al. (2008) for PATB part 3 (Maamouri et al., 2004). We kept the test unseen during training. There are five default attributes, in the MaltParser terminology, for each token in the text: word ID (ordinal position in the sentence), word form, POS tag, head (parent word ID), and deprel (the dependency relation between the current word and its parent). There are default MaltParser features (in the machine learning sense),7 which are the values of functions over these attributes, serving as input to the MaltParser internal classifiers. The most commonly used feature functions are the top of the input buffer (next word to process, denoted buf[0]),</context>
</contexts>
<marker>Maamouri, Bies, Buckwalter, Mekki, 2004</marker>
<rawString>Mohamed Maamouri, Ann Bies, Timothy A. Buckwalter, and Wigdan Mekki. 2004. The Penn Arabic Treebank: Building a Large-Scale Annotated Arabic Corpus. In Proceedings of the NEMLAR Conference on Arabic Language Resources and Tools, pages 102–109, Cairo, Egypt.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuval Marton</author>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
</authors>
<title>Improving Arabic dependency parsing with inflectional and lexical morphological features.</title>
<date>2010</date>
<booktitle>In Proceedings of Workshop on Statistical Parsing of Morphologically Rich Languages (SPMRL) at the 11th Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL) - Human Language Technology (HLT),</booktitle>
<location>Los Angeles, USA.</location>
<contexts>
<context position="13956" citStr="Marton et al. (2010)" startWordPosition="2149" endWordPosition="2152">h are extremely rare (in our training corpus of about 300,000 words, we encounter only 430 of such POS tags with complete morphology). Therefore, researchers have proposed tagsets for MSA whose size is similar to that of the English PTB tagset, as this has proven to be a useful size computationally. These tagsets are hybrids in the sense that they are neither simply the core POS, nor the complete morphologically enriched tagset, but instead they selectively enrich the core POS tagset with only certain morphological features. A full dicussion of how these tagsets affect parsing is presented in Marton et al. (2010); we summarize the main points here. The following are the various tagsets we use in this paper: (a) the core POS tagset CORE12; (b) the CATiB treebank tagset CATIBEX, a newly introduced extension of CATIB6 (Habash and Roth, 2009) by simple regular expressions of the word form, indicating particular morphemes such as the prefix JI Al+ or the suffix v_3 +wn; this tagset is the best-performing tagset for Arabic on predicted values. (c) the PATB full tagset (BW), size ≈2000+ (Buckwalter, 2004); We only discuss here the best performing tagsets (on predicted values), and BW for comparison. 4 Relate</context>
<context position="17257" citStr="Marton et al., 2010" startWordPosition="2682" endWordPosition="2685">xperiments reported here were performed using MaltParser. Our results agree with previous work on Arabic and Hebrew in that marking the definite article is helpful for parsing. However, we go beyond previous work in that 1589 we also extend this morphologically enhanced feature set to include additional lexical and inflectional features. Previous work with MaltParser in Russian, Turkish and Hindi showed gains with case but not with agreement features (Nivre et al., 2008; Eryigit et al., 2008; Nivre, 2009). Our work is the first using MaltParser to show gains using agreement-oriented features (Marton et al., 2010), and the first to use functional features for this task (this paper). 5 Experiments Throughout this section, we only report results using predicted input feature values (e.g., generated automatically by a POS tagger). After presenting the parser we use (Section 5.1), we examine a large space of settings in the following order: the contribution of numerous inflectional features in a controlled fashion (Section 5.2);5 the contribution of the lexical features in a similar fashion, as well as the combination of lexical and inflectional features (Section 5.3); an extension of the DET feature (Sect</context>
<context position="18909" citStr="Marton et al. (2010)" startWordPosition="2954" endWordPosition="2957">en. We use McNemar’s statistical significance test as implemented by Nilsson and Nivre (2008), and denote p &lt; 0.05 and p &lt; 0.01 with + and ++, respectively. 5.1 Parser For all experiments reported here we used the syntactic dependency parser MaltParser v1.3 (Nivre, 2003; Nivre, 2008; Kübler et al., 2009) – a transition-based parser with an input buffer and a stack, using SVM classifiers to predict the next state in the parse derivation. All experiments were done using the Nivre &amp;quot;eager&amp;quot; algorithm.6 For training, de5In this paper, we do not examine the contribution of different POS tagsets, see Marton et al. (2010) for details. 6Nivre (2008) reports that non-projective and pseudoprojective algorithms outperform the &amp;quot;eager&amp;quot; projective algorithm in MaltParser, but our training data did not contain any non-projective dependencies. The Nivre &amp;quot;standard&amp;quot; algorithm velopment and testing, we follow the splits used by Roth et al. (2008) for PATB part 3 (Maamouri et al., 2004). We kept the test unseen during training. There are five default attributes, in the MaltParser terminology, for each token in the text: word ID (ordinal position in the sentence), word form, POS tag, head (parent word ID), and deprel (the d</context>
<context position="24120" citStr="Marton et al., 2010" startWordPosition="3777" endWordPosition="3780">stic (since the entire feature space is too vast to exhaust): starting with the most gainful feature from Sep, adding the next most gainful feature, keeping it if it helped, or discarding it otherwise, and continuing through the least gainful feature. See Table 1. Somewhat surprisingly, setup All hurts performance. This can be explained if one examines the prediction accuracy of each feature (top of Table 2). Features which are not predicted with very high accuracy, such as CASE (86.3%), can dominate the negative contribution, even though they are top contributors when provided as gold input (Marton et al., 2010); when all features are provided as gold input, All actually does better than individual features, which puts to rest a concern that its decrease here setup LAS LASdzff UAS CORE12 (repeated) 78.68 — 82.48 + all lexical features 78.85 0.17 82.46 +LMM 78.96+ 0.28 82.54 +ROOT 78.94+ 0.26 82.64 +LEMMA 78.80 0.12 82.42 +PATTERN 78.59 -0.09 82.39 +LMM+ROOT 79.04++ 0.36 82.63 +LMM+ROOT+LEMMA 79.05++ 0.37 82.63 +LMM+ROOT+PATTERN 78.93 0.25 82.58 Table 3: Lexical features. Top part: Adding each feature separately; difference from CORE12 (predicted). Bottom part: Greedily adding best features from previ</context>
<context position="32756" citStr="Marton et al. (2010)" startWordPosition="5146" endWordPosition="5149">syntax. In gold experiments which we do not report here, the contribution was even higher (0.6-0.7%). The last row in the fourth part of Table 6 shows that using both surface and functional variants of NUMBER and GENDER does not help (hurts, in fact); the functional morphology features carry sufficient information for syntactic disambiguation. The last part of the table revalidates the gains achieved of the best feature combination using the two other POS tagsets mentioned in Section 3: CATIBEX (the best performing tagset with predicted values), and BW (the best POS tagset with gold values in Marton et al. (2010), but results shown here are with predicted values). The CATIBEX result of 80.83% is our overall best result. The result using BW reconfirms that BW is not the best tagset to use for parsing Arabic with current prediction ability. 5.6 Validating results on unseen test set Once experiments on the development set were done, we ran the best performing models on the previously unseen test set (Section 5.1). Table 7 shows that the same trends hold on this set as well. Model LAS LASdiff UAS CATIBEX 78.46 — 81.81 +DET2+LMM+PER+FN*NGR 79.45++ 0.99 82.56 Table 7: Results on unseen test set for models w</context>
</contexts>
<marker>Marton, Habash, Rambow, 2010</marker>
<rawString>Yuval Marton, Nizar Habash, and Owen Rambow. 2010. Improving Arabic dependency parsing with inflectional and lexical morphological features. In Proceedings of Workshop on Statistical Parsing of Morphologically Rich Languages (SPMRL) at the 11th Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL) - Human Language Technology (HLT), Los Angeles, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jens Nilsson</author>
<author>Joakim Nivre</author>
</authors>
<title>MaltEval: An evaluation and visualization tool for dependency parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of the sixth International Conference on Language Resources and Evaluation (LREC),</booktitle>
<location>Marrakech, Morocco.</location>
<contexts>
<context position="18382" citStr="Nilsson and Nivre (2008)" startWordPosition="2862" endWordPosition="2865">mbination of lexical and inflectional features (Section 5.3); an extension of the DET feature (Section 5.4); using functional NUMBER and GENDER feature values, as well as the RATIONALITY feature (Section 5.5); finally, putting best feature combinations to test with the best-performing POS tagset, and on an unseen test set (Section 5.6). All results are reported mainly in terms of labeled attachment accuracy score (parent word and the dependency relation to it, a.k.a. LAS). Unlabeled attachment accuracy score (UAS) is also given. We use McNemar’s statistical significance test as implemented by Nilsson and Nivre (2008), and denote p &lt; 0.05 and p &lt; 0.01 with + and ++, respectively. 5.1 Parser For all experiments reported here we used the syntactic dependency parser MaltParser v1.3 (Nivre, 2003; Nivre, 2008; Kübler et al., 2009) – a transition-based parser with an input buffer and a stack, using SVM classifiers to predict the next state in the parse derivation. All experiments were done using the Nivre &amp;quot;eager&amp;quot; algorithm.6 For training, de5In this paper, we do not examine the contribution of different POS tagsets, see Marton et al. (2010) for details. 6Nivre (2008) reports that non-projective and pseudoproject</context>
</contexts>
<marker>Nilsson, Nivre, 2008</marker>
<rawString>Jens Nilsson and Joakim Nivre. 2008. MaltEval: An evaluation and visualization tool for dependency parsing. In Proceedings of the sixth International Conference on Language Resources and Evaluation (LREC), Marrakech, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
</authors>
<title>Atanas Chanev, Gulsen Eryigit, Sandra Kubler, Svetoslav Marinov, and Erwin Marsi.</title>
<date>2007</date>
<journal>Natural Language Engineering,</journal>
<volume>13</volume>
<issue>2</issue>
<contexts>
<context position="16492" citStr="Nivre et al., 2007" startWordPosition="2560" endWordPosition="2563">rmation helps unlexicalized PCFG parsing. As for work on Arabic, results have been reported on PATB (Kulick et al., 2006; Diab, 2007; Green and Manning, 2010), the Prague Dependency Treebank (PADT) (Buchholz and Marsi, 2006; Nivre, 2008) and the Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009). Recently, Green and Manning (2010) analyzed the PATB for annotation consistency, and introduced an enhanced split-state constituency grammar, including labels for short Idafa constructions and verbal or equational clauses. Nivre (2008) reports experiments on Arabic parsing using his MaltParser (Nivre et al., 2007), trained on the PADT. His results are not directly comparable to ours because of the different treebanks’ representations, even though all the experiments reported here were performed using MaltParser. Our results agree with previous work on Arabic and Hebrew in that marking the definite article is helpful for parsing. However, we go beyond previous work in that 1589 we also extend this morphologically enhanced feature set to include additional lexical and inflectional features. Previous work with MaltParser in Russian, Turkish and Hindi showed gains with case but not with agreement features </context>
</contexts>
<marker>Nivre, Hall, Nilsson, 2007</marker>
<rawString>Joakim Nivre, Johan Hall, Jens Nilsson, Atanas Chanev, Gulsen Eryigit, Sandra Kubler, Svetoslav Marinov, and Erwin Marsi. 2007. MaltParser: A languageindependent system for data-driven dependency parsing. Natural Language Engineering, 13(2):95–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Igor M Boguslavsky</author>
<author>Leonid K Iomdin</author>
</authors>
<title>Parsing the SynTagRus Treebank of Russian.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (COLING),</booktitle>
<pages>641--648</pages>
<contexts>
<context position="17111" citStr="Nivre et al., 2008" startWordPosition="2659" endWordPosition="2662"> trained on the PADT. His results are not directly comparable to ours because of the different treebanks’ representations, even though all the experiments reported here were performed using MaltParser. Our results agree with previous work on Arabic and Hebrew in that marking the definite article is helpful for parsing. However, we go beyond previous work in that 1589 we also extend this morphologically enhanced feature set to include additional lexical and inflectional features. Previous work with MaltParser in Russian, Turkish and Hindi showed gains with case but not with agreement features (Nivre et al., 2008; Eryigit et al., 2008; Nivre, 2009). Our work is the first using MaltParser to show gains using agreement-oriented features (Marton et al., 2010), and the first to use functional features for this task (this paper). 5 Experiments Throughout this section, we only report results using predicted input feature values (e.g., generated automatically by a POS tagger). After presenting the parser we use (Section 5.1), we examine a large space of settings in the following order: the contribution of numerous inflectional features in a controlled fashion (Section 5.2);5 the contribution of the lexical f</context>
</contexts>
<marker>Nivre, Boguslavsky, Iomdin, 2008</marker>
<rawString>Joakim Nivre, Igor M. Boguslavsky, and Leonid K. Iomdin. 2008. Parsing the SynTagRus Treebank of Russian. In Proceedings of the 22nd International Conference on Computational Linguistics (COLING), pages 641–648.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>An efficient algorithm for projective dependency parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 8th International Conference on Parsing Technologies (IWPT),</booktitle>
<pages>149--160</pages>
<location>Nancy, France.</location>
<contexts>
<context position="18559" citStr="Nivre, 2003" startWordPosition="2896" endWordPosition="2897">ture (Section 5.5); finally, putting best feature combinations to test with the best-performing POS tagset, and on an unseen test set (Section 5.6). All results are reported mainly in terms of labeled attachment accuracy score (parent word and the dependency relation to it, a.k.a. LAS). Unlabeled attachment accuracy score (UAS) is also given. We use McNemar’s statistical significance test as implemented by Nilsson and Nivre (2008), and denote p &lt; 0.05 and p &lt; 0.01 with + and ++, respectively. 5.1 Parser For all experiments reported here we used the syntactic dependency parser MaltParser v1.3 (Nivre, 2003; Nivre, 2008; Kübler et al., 2009) – a transition-based parser with an input buffer and a stack, using SVM classifiers to predict the next state in the parse derivation. All experiments were done using the Nivre &amp;quot;eager&amp;quot; algorithm.6 For training, de5In this paper, we do not examine the contribution of different POS tagsets, see Marton et al. (2010) for details. 6Nivre (2008) reports that non-projective and pseudoprojective algorithms outperform the &amp;quot;eager&amp;quot; projective algorithm in MaltParser, but our training data did not contain any non-projective dependencies. The Nivre &amp;quot;standard&amp;quot; algorithm v</context>
</contexts>
<marker>Nivre, 2003</marker>
<rawString>Joakim Nivre. 2003. An efficient algorithm for projective dependency parsing. In Proceedings of the 8th International Conference on Parsing Technologies (IWPT), pages 149–160, Nancy, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Algorithms for deterministic incremental dependency parsing.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>4</issue>
<contexts>
<context position="16110" citStr="Nivre, 2008" startWordPosition="2508" endWordPosition="2509">r verbs) outperforms other combinations. Our approach is comparable to their work in terms of its systematic exploration of the space of morphological features. We also find that the number feature helps for Arabic. Looking at Hebrew, a Semitic language related to Arabic, Tsarfaty and Sima’an (2007) report that extending POS and phrase structure tags with definiteness information helps unlexicalized PCFG parsing. As for work on Arabic, results have been reported on PATB (Kulick et al., 2006; Diab, 2007; Green and Manning, 2010), the Prague Dependency Treebank (PADT) (Buchholz and Marsi, 2006; Nivre, 2008) and the Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009). Recently, Green and Manning (2010) analyzed the PATB for annotation consistency, and introduced an enhanced split-state constituency grammar, including labels for short Idafa constructions and verbal or equational clauses. Nivre (2008) reports experiments on Arabic parsing using his MaltParser (Nivre et al., 2007), trained on the PADT. His results are not directly comparable to ours because of the different treebanks’ representations, even though all the experiments reported here were performed using MaltParser. Our results agr</context>
<context position="18382" citStr="Nivre (2008)" startWordPosition="2864" endWordPosition="2865"> lexical and inflectional features (Section 5.3); an extension of the DET feature (Section 5.4); using functional NUMBER and GENDER feature values, as well as the RATIONALITY feature (Section 5.5); finally, putting best feature combinations to test with the best-performing POS tagset, and on an unseen test set (Section 5.6). All results are reported mainly in terms of labeled attachment accuracy score (parent word and the dependency relation to it, a.k.a. LAS). Unlabeled attachment accuracy score (UAS) is also given. We use McNemar’s statistical significance test as implemented by Nilsson and Nivre (2008), and denote p &lt; 0.05 and p &lt; 0.01 with + and ++, respectively. 5.1 Parser For all experiments reported here we used the syntactic dependency parser MaltParser v1.3 (Nivre, 2003; Nivre, 2008; Kübler et al., 2009) – a transition-based parser with an input buffer and a stack, using SVM classifiers to predict the next state in the parse derivation. All experiments were done using the Nivre &amp;quot;eager&amp;quot; algorithm.6 For training, de5In this paper, we do not examine the contribution of different POS tagsets, see Marton et al. (2010) for details. 6Nivre (2008) reports that non-projective and pseudoproject</context>
<context position="21241" citStr="Nivre (2008)" startWordPosition="3321" endWordPosition="3322">arser configuration.9 All experiments reported below were conducted using this new configuration. 5.2 Inflectional features In order to explore the contribution of inflectional and lexical information in a controlled manner, we focused on the best performing core (“morphologyfree”) POS tagset, CORE12, as baseline; using three is also reported to do better on Arabic, but in a preliminary experimentation, it did similarly or slightly worse than the &amp;quot;eager” one, perhaps due to high percentage of right branching (left headed structures) in our Arabic training set – an observation already noted in Nivre (2008). 7The terms “feature” and “attribute” are overloaded in the literature. We use them in the linguistic sense, unless specifically noted otherwise, e.g., “MaltParser feature(s)”. 8It is slightly different from the default configuration. 9We also experimented with normalizing word forms (Alif Maqsura conversion to Ya, and hamza removal from Alif forms) as is common in parsing and statistical machine translation literature – but it resulted in a similar or slightly decreased performance, so we settled on using non-normalized word forms. 1590 setup LAS LASdzff UAS CORE12 78.68 — 82.48 + all inflec</context>
</contexts>
<marker>Nivre, 2008</marker>
<rawString>Joakim Nivre. 2008. Algorithms for deterministic incremental dependency parsing. Computational Linguistics, 34(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Parsing Indian languages with MaltParser.</title>
<date>2009</date>
<booktitle>In Proceedings of the ICON09 NLP Tools Contest: Indian Language Dependency Parsing,</booktitle>
<pages>12--18</pages>
<contexts>
<context position="17147" citStr="Nivre, 2009" startWordPosition="2667" endWordPosition="2668">directly comparable to ours because of the different treebanks’ representations, even though all the experiments reported here were performed using MaltParser. Our results agree with previous work on Arabic and Hebrew in that marking the definite article is helpful for parsing. However, we go beyond previous work in that 1589 we also extend this morphologically enhanced feature set to include additional lexical and inflectional features. Previous work with MaltParser in Russian, Turkish and Hindi showed gains with case but not with agreement features (Nivre et al., 2008; Eryigit et al., 2008; Nivre, 2009). Our work is the first using MaltParser to show gains using agreement-oriented features (Marton et al., 2010), and the first to use functional features for this task (this paper). 5 Experiments Throughout this section, we only report results using predicted input feature values (e.g., generated automatically by a POS tagger). After presenting the parser we use (Section 5.1), we examine a large space of settings in the following order: the contribution of numerous inflectional features in a controlled fashion (Section 5.2);5 the contribution of the lexical features in a similar fashion, as wel</context>
</contexts>
<marker>Nivre, 2009</marker>
<rawString>Joakim Nivre. 2009. Parsing Indian languages with MaltParser. In Proceedings of the ICON09 NLP Tools Contest: Indian Language Dependency Parsing, pages 12–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan Roth</author>
<author>Owen Rambow</author>
<author>Nizar Habash</author>
<author>Mona Diab</author>
<author>Cynthia Rudin</author>
</authors>
<title>Arabic morphological tagging, diacritization, and lemmatization using lexeme models and feature ranking.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL08: HLT, Short Papers,</booktitle>
<pages>117--120</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<contexts>
<context position="19228" citStr="Roth et al. (2008)" startWordPosition="3000" endWordPosition="3003">based parser with an input buffer and a stack, using SVM classifiers to predict the next state in the parse derivation. All experiments were done using the Nivre &amp;quot;eager&amp;quot; algorithm.6 For training, de5In this paper, we do not examine the contribution of different POS tagsets, see Marton et al. (2010) for details. 6Nivre (2008) reports that non-projective and pseudoprojective algorithms outperform the &amp;quot;eager&amp;quot; projective algorithm in MaltParser, but our training data did not contain any non-projective dependencies. The Nivre &amp;quot;standard&amp;quot; algorithm velopment and testing, we follow the splits used by Roth et al. (2008) for PATB part 3 (Maamouri et al., 2004). We kept the test unseen during training. There are five default attributes, in the MaltParser terminology, for each token in the text: word ID (ordinal position in the sentence), word form, POS tag, head (parent word ID), and deprel (the dependency relation between the current word and its parent). There are default MaltParser features (in the machine learning sense),7 which are the values of functions over these attributes, serving as input to the MaltParser internal classifiers. The most commonly used feature functions are the top of the input buffer</context>
</contexts>
<marker>Roth, Rambow, Habash, Diab, Rudin, 2008</marker>
<rawString>Ryan Roth, Owen Rambow, Nizar Habash, Mona Diab, and Cynthia Rudin. 2008. Arabic morphological tagging, diacritization, and lemmatization using lexeme models and feature ranking. In Proceedings of ACL08: HLT, Short Papers, pages 117–120, Columbus, Ohio, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Otakar Smrž</author>
</authors>
<title>FunctionalArabic Morphology. Formal System and Implementation.</title>
<date>2007</date>
<tech>Ph.D. thesis,</tech>
<institution>Charles University,</institution>
<location>Prague.</location>
<contexts>
<context position="8945" citStr="Smrž, 2007" startWordPosition="1382" endWordPosition="1383">ools’, which is feminine and plural inflectionally, but has a masculine singular suffix. This irregular inflection, known as broken plural, is similar to the English mouse/mice, but is much more common in Arabic (over 50% of plurals in our training data). A similar inconsistency appears in feminine nouns that are not inflected using sound gender suffixes, e.g., the feminine form of the 6 masculine singular adjective �†„@Âzraq+0 ‘blue’ is ZA79PP� zarqA’+0 not �é�¯P �P�@* *Âzraq+ah. To address this inconsistency in the correspondence between inflectional features and morphemes, and inspired by (Smrž, 2007), we distinguish between two types of inflectional features: surface (or form-based)4 features and functional features. Most available Arabic NLP tools and resources model morphology using surface inflectional features and do not mark rationality; this includes the PATB (Maamouri et al., 2004), the Buckwalter morphological analyzer (BAMA) (Buckwalter, 2004) and tools using them such as the Morphological Analysis and Disambiguation for Arabic (MADA) system (Habash and Rambow, 2005). The ElixirFM analyzer (Smrž, 2007) readily provides the functional inflectional number feature, but not full func</context>
</contexts>
<marker>Smrž, 2007</marker>
<rawString>Otakar Smrž. 2007. FunctionalArabic Morphology. Formal System and Implementation. Ph.D. thesis, Charles University, Prague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reut Tsarfaty</author>
<author>Khalil Sima’an</author>
</authors>
<title>Threedimensional parametrization for parsing morphologically rich languages.</title>
<date>2007</date>
<booktitle>In Proceedings of the 10th International Conference on Parsing Technologies (IWPT),</booktitle>
<pages>156--167</pages>
<location>Morristown, NJ, USA.</location>
<marker>Tsarfaty, Sima’an, 2007</marker>
<rawString>Reut Tsarfaty and Khalil Sima’an. 2007. Threedimensional parametrization for parsing morphologically rich languages. In Proceedings of the 10th International Conference on Parsing Technologies (IWPT), pages 156–167, Morristown, NJ, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>