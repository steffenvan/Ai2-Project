<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007641">
<title confidence="0.9970685">
Using Paraphrases of Deep Semantic Representions
to Support Regression Testing in Spoken Dialogue Systems
</title>
<author confidence="0.597212">
Beth Ann Hockey
</author>
<affiliation confidence="0.444663666666667">
UC Santa Cruz and BAHRC LLC
Mail Stop 19-26, UCSC UARC
NASA Ames Research Center, Moffett Field, CA 94035–1000
</affiliation>
<email confidence="0.988642">
bahockey@bahrc.net
</email>
<author confidence="0.996024">
Manny Rayner
</author>
<affiliation confidence="0.998692">
University of Geneva, TIM/ISSCO
</affiliation>
<address confidence="0.970686">
40 bvd du Pont-d’Arve, CH-1211 Geneva 4, Switzerland
</address>
<email confidence="0.988222">
Emmanuel.Rayner@unige.ch
</email>
<sectionHeader confidence="0.926642" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998653612903226">
Rule-based spoken dialogue systems require
a good regression testing framework if they
are to be maintainable. We argue that there
is a tension between two extreme positions
when constructing the database of test exam-
ples. On the one hand, if the examples con-
sist of input/output tuples representing many
levels of internal processing, they are fine-
grained enough to catch most processing er-
rors, but unstable under most system modi-
fications. If the examples are pairs of user
input and final system output, they are much
more stable, but too coarse-grained to catch
many errors. In either case, there are fairly
severe difficulties in judging examples cor-
rectly. We claim that a good compromise can
be reached by implementing a paraphrasing
mechanism which maps internal semantic rep-
resentations into surface forms, and carrying
out regression testing using paraphrases of se-
mantic forms rather than the semantic forms
themselves. We describe an implementation
of the idea using the Open Source Regulus
toolkit, where paraphrases are produced us-
ing Regulus grammars compiled in generation
mode. Paraphrases can also be used at run-
time to produce confirmations. By compiling
the paraphrase grammar a second time, as a
recogniser, it is possible in a simple and nat-
ural way to guarantee that confirmations are
always within system coverage.
</bodyText>
<sectionHeader confidence="0.999265" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.996038379310345">
Design features that enable important functionality
in medium vocabulary, mixed-initiative spoken dia-
logue systems also create challenges for the project
cycle, and in particular for regression testing. Two
issues that make regression testing particularly dif-
ficult are the need for context dependent interpre-
tation, and the use of multiple levels of representa-
tion. Both of these features are typically necessary
for non-trivial dialogue systems of this type. Mul-
tiple levels of processing, as usual, provide neces-
sary modularity. Context dependent interpretation
enables responses that are tuned to the current cir-
cumstances of the interaction or the world, and fre-
quently helps resolve ambiguity.
The implications for regression testing, though,
are less happy. The context of each interaction in
the test suite needs to be stored as part of the inter-
action. Multiple levels of representation that are, for
example, useful for doing ellipsis resolution or ref-
erence resolution, also complicate testing. If regres-
sion testing is done on each separate level of pro-
cessing, or involves internal representations, small
changes to a representation at one level can mean
having to revise and rejudge the entire test suite to
keep it up to date.
This paper discusses the methodology we have
developed to address regression testing issues within
the Regulus framework. Regulus (Rayner et al.,
2006) is an Open Source toolkit for builting medium
</bodyText>
<page confidence="0.990113">
14
</page>
<note confidence="0.9956465">
Proceedings of the NAACL HLT Workshop on Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 14–21,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.99973871875">
vocabulary spoken dialogue and translation appli-
cations, and has been used to build a number of
non-trivial spoken dialogue systems. Prominent ex-
amples include NASA’s Clarissa Procedure Navi-
gator (Rayner et al., 2005), Geneva University’s
multi-modal mobile-platform Calendar application
(Tsourakis et al., 2008), SDS, a prototype in-car sys-
tem developed by UC Santa Cruz in collaboration
with Ford Motors Research which was voted first
in Ford’s 2007 internal technology fair, and Taxi,
a speech-enabled game in which the user interacts
with a simulated cab driver to navigate around a map
of Manhattan. It has also been used to build the
MedSLT medical speech translation system (Bouil-
lon et al., 2008).
The Regulus platform includes tools for develop-
ing feature grammars, and compiling them in var-
ious ways. In particular, it is possible to compile
grammars into generators, and use them to support
paraphrasing from the internal semantic representa-
tions created during dialogue processing. This ca-
pability is key to the newest part of our regression
testing approach, and is discussed in detail in Sec-
tion 3. First, though, Section 2 gives an overview of
Regulus and the architecture of Regulus-based sys-
tems; we discuss features that complicate regression
testing, and how to address these problems within
this type of architecture. Section 4 discusses how
test suites are constructed and what types of items
they may contain. In Section 5 we show how para-
phrases can also be included in the run-time archi-
tecture. The final section concludes.
</bodyText>
<sectionHeader confidence="0.954407" genericHeader="method">
2 The Regulus platform
</sectionHeader>
<bodyText confidence="0.998570615384615">
Regulus is an Open Source toolkit for building
medium vocabulary grammar-based spoken dia-
logue and translation systems. The central idea is to
base run-time processing on efficient, task-specific
grammars derived from general, reusable, domain-
independent core grammars. Early versions of Reg-
ulus used a single core grammar per language; a de-
tailed description of the core grammar for English
can be found in (Rayner et al., 2006, Chapter 9).
More recently, there have been attempts to go fur-
ther, and merge together core grammars for closely
related languages (Bouillon et al., 2007).
The core grammars are automatically specialised,
</bodyText>
<figureCaption confidence="0.9987354">
Figure 1: The Regulus compilation path. The general
unification grammar is first transformed into a specialised
feature grammar. This can then be transformed either into
a CFG grammar and Nuance recogniser, or into a gener-
ator. and a Nuance recogniser.
</figureCaption>
<bodyText confidence="0.999866935483871">
using corpus-driven methods based on small cor-
pora, to derive simpler grammars. Specialisation
is both with respect to task (recognition, analysis,
generation) and to application domain. The special-
isation process uses the Explanation Based Learning
algorithm (van Harmelen and Bundy, 1988; Rayner,
1988). It starts with a parsed treebank derived from
the training corpus, and then divides the parse tree
created from each training example into a set of one
or more subtrees, following a set of domain- and
grammar-specific rules conventionally known in the
Machine Learning literature as operationality crite-
ria. The rules in each subtree are then combined, us-
ing the unification operation, into a single rule. The
set of all such rules constitutes a specialised unifica-
tion grammar. Each of these specialised unification
grammars is then subjected to a second compila-
tion step, which converts it into its executable form.
For analysis and generation, this form is a standard
parser or generator. For recognition, it is a semanti-
cally annotated CFG grammar in the form required
by the Nuance engine, which is then subjected to
further Nuance-specific compilation steps to derive
a speech recognition package. Figure 1 summarises
compile-time processing.
The Regulus platform also contains infrastructure
to support construction of applications which use the
recognisers, parsers and generators as components.
In this paper, we will only discuss spoken dialogue
system applications. (There is also an elaborate in-
frastructure to support speech translation systems).
</bodyText>
<page confidence="0.995763">
15
</page>
<figureCaption confidence="0.9987305">
Figure 2: Top-level architecture for Regulus-based spo-
ken dialogue system
</figureCaption>
<bodyText confidence="0.9998365">
At a high level of generality, the architecture is a
standard one (Figure 2; cf. for example (Allen et
al., 2000)). The central component is the Dialogue
Manager (DM), which receives dialogue moves and
produces abstract actions. It also manipulates an in-
formation state, which maintains context; process-
ing will generally be context-dependent. The DM is
bracketed between two other components, the Input
Manager (IM) and the Output Manager (OM). The
IM receives logical forms, and non-speech inputs if
there are any, and turns them into dialogue moves.
The OM received abstract actions and turns them
into concrete actions. Usually, these actions will be
either speaking, though TTS or recorded speech, or
manipulation of a GUI’s screen area.
In the next section, we examine in more detail
how the various components are constructed, and
what the implications are for the software develop-
ment cycle. We will in particular be interested in
regression testing.
</bodyText>
<sectionHeader confidence="0.8860545" genericHeader="method">
3 Context, regression testing and
paraphrasing
</sectionHeader>
<bodyText confidence="0.999986244897959">
The three main components of the spoken dia-
logue system — the IM, DM and OM — all trans-
form one or more inputs into one or more outputs.
With the current focus on machine learning tech-
niques, a natural thought is to learn the relevant
tranformations from examples. Implemented mainly
through Partially Observable Markov Decision Pro-
cesses (POMDPs), this idea is attractive theoreti-
cally, but has been challenging to scale up. Systems
have been restricted to very simple domains (Roy
et al., 2000; Zhang et al., 2001) and only recently
have techniques been developed that show promise
for use in real-world systems (Williams and Young,
2007; Gasi´c et al., 2008). The representations re-
quired in many systems are more complex than those
employed even in the more recent POMDP based
work, and there is also the usual problem that it is not
easy to obtain training data. In practice, most peo-
ple are forced to construct the transformation rules
by hand; the Regulus framework assumes this will
be the case. Hand-coding of dialogue processing
components involves the usual software engineering
problems that arise when building and maintaining
substantial rule-sets. In particular, it is necessary to
have a framework that supports efficient regression
testing.
As everyone who has tried will know, the thing
that makes regression testing difficult for this kind
of application is context-dependency. In the worst
case, the context is the whole world, or at least the
part of it that the system is interacting with, and re-
gression testing is impossible. In more typical cases,
however, good architectural choices can make the
problem reasonably tractable. In particular, things
become enormously simpler if it is possible to en-
capsulate all the context information in a datastruc-
ture that can be passed around. In the dialogue man-
agement architecture realised in Regulus (Rayner et
al., 2006, Chapter 5), the assumption is that this is
the case; it is then possible to use a version of “up-
date semantics” (Larsson and Traum, 2000). The
central concepts are those of dialogue move, infor-
mation state and dialogue action. At the beginning
of each turn, the dialogue manager is in an infor-
mation state. Inputs to the dialogue manager are by
definition dialogue moves, and outputs are dialogue
actions. The behaviour of the dialogue manager over
a turn is completely specified by an update function
f of the form
</bodyText>
<equation confidence="0.633382">
f : State×Move → State×Actions
</equation>
<bodyText confidence="0.999809">
Thus if a dialogue move is applied in a given infor-
mation state, the result is a new information state
and a set of zero or more dialogue actions.
</bodyText>
<subsectionHeader confidence="0.999261">
3.1 Regression testing
</subsectionHeader>
<bodyText confidence="0.9998365">
Using the side-effect free framework is certainly a
large step in the right direction; it is in principle pos-
</bodyText>
<page confidence="0.983206">
16
</page>
<bodyText confidence="0.992879904255319">
sible to construct a regression test suite consisting of
4-tuples of the form
(In5tate, Move, Out5tate, Actions)
There are however several problems. First, pro-
cessing consists of much more than just the update
function. It is optimistic to assume that the speech
recogniser will be able to produce dialogue moves
directly. In simple cases, this may be possible. In
more complex cases, extra levels of processing be-
come necessary; in other words, the IM component
will generally have a substantial amount of structure.
There are several reasons for this. The representa-
tion delivered by the grammar-based speech recog-
niser is syntax-oriented; it needs to be translated
into a semantic form. Again, because of context-
dependency, this translation often needs to be car-
ried out in more than one step. For example, in the
Calendar application, a question like “When is the
next meeting in Switzerland?” might be followed by
the elliptical utterance “In England?”. Some kind
of mechanism is needed in order to resolve this to
a representation meaning “When is the next meet-
ing in England?” A separate mechanism is used to
perform reference resolution. For instance, the de-
fault database for the Calendar application contains
one person called “Nikos” and two called “Mari-
anne”. The question “Is Nikos attending the meet-
ing?” needs to be converted into a database query
that looks up the appropriate record; however, the
structurally similar query “Is Marianne attending the
meeting?” should produce a disambiguation query.
Examples like these motivate the introduction of yet
another processing step, which carries out reference
resolution.
Of course, different systems will address these is-
sues in different ways; but, whatever the solution,
the general point remains that there will usually be
many layers of representation. From a system devel-
opment point of view, the problem is how to struc-
ture the regression testing needed in order to main-
tain the stability of each processing step. The most
cautious and direct way to do this is to have a corpus
of input/output tuples representing each individual
step, but experience shows that this type of solution
places an enormous burden on the annotators who
are required to judge the correctness or otherwise of
the tuples. First of all, under this approach the anno-
tators must be experts capable of reading and under-
standing internal representations. Second, even very
small changes in the system often require complete
reannotation of the test corpus; for example, some
data structure may have been changed so as to in-
clude an extra field. If constant rejudging is required
to keep the test suite coherent with the current ver-
sion of the system, either the testing is abandoned as
overly difficult and time consuming, or it is done in
a less careful way in order to speed up the process.
Neither outcome is satisfactory.
If annotation uses input/output tuples referring to
internal representations, the problems we have just
named appear inescapable. At the opposite end of
the spectrum, a common approach is not to look
at internal representations at all, but only at in-
put/output pairs consisting of top-level inputs and
outputs. For example, we can pair “When is the next
meeting in Geneva?” with “March 31 2009”, and
“Is Marianne attending the meeting?” with “Which
Marianne do you mean?” This is generally, in prac-
tice, easier than doing regression testing on internal
representations; the key advantages are that, since
we are only dealing with pre-theoretical notions, an-
notation can be performed by non-experts, and an-
notations remain stable across most changes to in-
ternal representations.
Unfortunately, however, new problems arise.
First, determining the correct output response for a
given input is often tedious and slow. For example,
in the Calendar application, this generally involves
carrying out a database search. Suitable annotation
tools can alleviate the pain here, but then a worse
problem arises; it is often possible to produce a cor-
rect system response, even if processing is incorrect.
For instance, even if the system correctly answers
“No” to a yes/no question, this proves very little;
the question could have been interpreted in a mul-
titude of ways, and still produced a negative answer.
Knowing that a WH-question provides a correct an-
swer says more, but can still often be misleading.
Suppose, for example, that we know that the Calen-
dar system correctly answers “None” to the question
“What meetings are there during the next week?”
and there are no meetings for the next 15 days. We
will be unable to tell whether the question has been
interpreted as “What meetings are there during the
</bodyText>
<page confidence="0.98615">
17
</page>
<table confidence="0.999908166666667">
World Context time=2008-10-14 14:34, speaker=mike
Last Para (none)
Input when is the next meeting with mark
Paraphrase when is [ the next meeting attended by mark green ]
World Context time=2008-10-16 09:47, speaker=mike
Last Para (none)
Input when is my next meeting with mark
Paraphrase when is [ the next meeting attended by mark green and mike jones ]
World Context time=2007-07-08 15:03, speaker=susan
Last Para (none)
Input is there a meeting next week
Paraphrase are there meetings between Mon Jul 9 2007 and Sun Jul 15 2007
World Context time=2008-11-17 18:20, speaker=mike
Last Para (none)
Input do i have a meeting on friday morning this week
Paraphrase are there meetings between 06:00 and 12:00 on Fri Nov 21 2008 attended by mike jones
World Context time=2008-11-12 10:19, speaker=mike
Last Para when is [ the next meeting attended by mike jones ]
Input will alex participate
Paraphrase will that meeting be attended by alex miller
World Context time=2007-07-08 15:56), speaker=susan
Last Para are there meetings on Mon Jul 9 2007
Input how about on tuesday
Paraphrase are there meetings on Tue Jul 10 2007
</table>
<tableCaption confidence="0.993452">
Table 1: Examples of regression testing tuples in the English Calendar system. Each tuple shows the current world
context (timestamp and speaker), the preceding paraphrase, the input, and the paraphrase produced from it.
</tableCaption>
<bodyText confidence="0.680028666666667">
next 7 days?”, as “What meetings are there during
the 7 day period starting this Sunday?” or as “What
meetings are there during the 7 day period starting
this Monday?” Examples like these mean that re-
gression testing often fails to catch bugs introduced
by system changes.
</bodyText>
<subsectionHeader confidence="0.999896">
3.2 Paraphrasing dialogue moves
</subsectionHeader>
<bodyText confidence="0.999986433333333">
To summarise: when carrying out regression testing,
we have two competing requirements. First, we need
to be able to access internal representations, since
they are so informative. At the same time, we prefer
to work with human-readable, pretheorically mean-
ingful objects, which will be stable at least under
most small changes in underlying representations.
There is, in fact, a good compromise between these
goals: we define a transformation which realises the
dialogue move as a human-readable string, which
we call a dialogue move paraphrase. So, for ex-
ample, consider the possible interpretations when,
on March 6 2009, a user asks “What meetings are
there during the next week?”. If “What meetings
are there during the next week?” is interpreted as
“What meetings are there during the next 7 days?”,
then the paraphrase might be “What meetings are
there between Fri Mar 6 and Thu Mar 12 2009?”; if
the interpretation is “What meetings are there dur-
ing the 7 day period starting this Monday?”, then
the corresponding paraphrase would be “What meet-
ings are there between Mon Mar 9 and Sun Mar 15
2009?” Regression testing can be carried out using
paraphrases of dialogue moves, rather than the dia-
logue moves themselves.
The paraphrase mechanism is implemented as a
Regulus grammar, compiled in generation mode,
which directly relates a dialogue move and its sur-
face form. We have found that it is not hard to de-
sign “paraphrase grammars” which produce outputs
</bodyText>
<page confidence="0.998132">
18
</page>
<bodyText confidence="0.99997425">
fulfilling the main design requirements. Regression
testing is carried out on tuples consisting of the pre-
ceding paraphrase, the world context (if any), the in-
put, and the resulting paraphrase. Examples of such
tuples for the English Calendar grammar are shown
in Table 1; in Calendar, the world context consists of
the utterance time-stamp and the speaker.
A tuple combines the results of IM and DM
(but not OM) processing for a given example, and
presents them in a pre-theoretically meaningful way.
Although they are not as fine-grained as tuples for
individual processing steps, they are stable over
most system changes. In the opposite direction, they
are far more fine-grained than straight system in-
put/system output tuples. They are much easier to
judge than both of the other types of tuple. The bot-
tom line, at least as far as we are concerned, is that a
regression testing database of paraphrase-based tu-
ples can actually be maintained without inordinate
effort, implying corresponding gains for system sta-
bility. Previously, this was impossible.
The idea of creating paraphrases from dialogue
moves is of course not new; in previous work, how-
ever, they have generally been used at runtime to
provide feedback to the user as to how their input has
been interpreted by the system. Although in the cur-
rent discussion we have been more concerned with
their use in regression testing, we have in fact also
employed them for the more traditional purpose.
We return to this theme in Section 5. First, we
describe in more detail where our test suites come
from.
</bodyText>
<sectionHeader confidence="0.97924" genericHeader="method">
4 Collecting test suites
</sectionHeader>
<bodyText confidence="0.999981137254902">
The tradition in the speech engineering community
is that a test suite consists of a list of recorded wav-
files, together with accompanying transcriptions.
The Nuance platform contains a fair amount of in-
frastructure, in particular the batchrec utility, for
processing lists of wavfiles. These tools are very
useful for computing measures like WER, and there
is a strong temptation to try to build on top of
them. After a while, however, we discovered that
they meshed poorly with the the basic goals of re-
gression testing in a spoken dialogue system, which
revolve around speech understanding rather than
speech recognition. There are two central problems.
One of them is context-dependence, which we have
already discussed at length. The other is the fact that
many applications require that the IM process both
speech and non-speech actions, with the sequence
and even the timing of actions being important.
For example, as we have already seen, time is
a central concept in the Calendar system. If the
user says “Are there any meetings this afternoon?”
the system interprets her as meaning “Are there any
meetings from now until the end of the afternoon?”
This means that the exact clock time for each utter-
ance is important. In the Taxi application, the taxi is
continually in motion, even when the user is not talk-
ing. The simulator sends the IM an non-speech mes-
sage several times a second, giving the taxi’s new
position and heading. This information is passed to
the DM, updating its state, and is essential for cor-
rect interpretation of commands like “Turn right at
the next corner”.
Considerations like these finally convinced us to
move to a different strategy, in which offline regres-
sion testing more closely models the runtime be-
haviour of the application. At runtime, the system
produces a time-stamped log of all input passed to
the IM, including both speech and non-speech mes-
sages, in the sequence in which they were received.
Each speech message is paired with a pointer to the
recorded wavfile which produced it. Sets of such
logs make up the test suite. Offline testing essen-
tially re-runs the sequence of time-stamped records.
Wavfiles are passed to a recognition server, which
returns recognition results; time-stamps are used to
set a notional internal clock, which replaces the real
one for the purposes of performing temporal calcula-
tions. The test harness was quite easy to implement,
and solves all the problems that arose from close ad-
herence to a more speech recognition oriented test
framework.
</bodyText>
<sectionHeader confidence="0.651688" genericHeader="method">
5 Using paraphrases at run-time
</sectionHeader>
<bodyText confidence="0.997230857142857">
As mentioned in Section 3.2, paraphrase grammars
can also be used at runtime, in order to provide
a direct confirmation to the user showing how the
system has interpreted what they have said. This
is not a compelling design for every system; in a
speech-only system, constant direct confirmation us-
ing paraphrases is in most cases unnatural and te-
</bodyText>
<page confidence="0.998177">
19
</page>
<bodyText confidence="0.99995384">
dious. It is, however, a potentially valid strategy in a
multi-modal system where it is possible to present a
visual display of the paraphrase. In such a system, if
paraphrases are regularly displayed to a user, there
is, however, a good possibility of lexical and/or syn-
tactic entrainment. Entrainment increases the likeli-
hood that the user will produce the paraphrase lan-
guage, which means that it would be valuable to be
able to process that language through the system.
In the Regulus framework, this problem can be
very straightforwardly addressed. Since the para-
phrase grammar is a valid Regulus grammar, it can
be compiled into a Nuance grammar, and hence into
a second recognition package. At runtime, this pack-
age can be used in parallel with the main system
recogniser. Because the paraphrase grammar is de-
signed to directly relate surface language to dialogue
moves, dialogue moves are generated directly, skip-
ping the Input Manager processing. In particular,
since the original point of the paraphrase grammar
is to restate the user’s content in a way that resolves
and disambiguates underspecified material, there is
no need for resolution processing. Figure 3 shows
the dialogue system architecture with the additional
paraphrase processing path.
</bodyText>
<figureCaption confidence="0.933998666666667">
Figure 3: Regulus dialogue architecture with a processing
path for paraphrases added. The paraphrase recognizer
sends a dialogue move directly to the Dialogue Manager.
</figureCaption>
<bodyText confidence="0.99996106779661">
Although it may seem preferable to include the
paraphrase coverage in the main recogniser cover-
age, we have found, somewhat to our surprise, that
this is not nearly as straightforward as it first ap-
pears. The problem is that the two grammars are de-
signed for very different tasks; the recognition gram-
mar is intended to capture natural user language,
while the paraphrase grammar’s job is to produce
unambiguous surface renderings of resolved seman-
tic representations. Although we have endeavoured
to make the paraphrase language as natural as pos-
sible, it is hard to avoid at least a few marginal
constructions, which do not fit well into the struc-
ture of the normal recognition grammar; even if we
did try to include them, the burden of keeping the
two different grammars in synch would be consider-
able. From a software engineering point of view, it
is far simpler just to maintain the two grammars sep-
arately, with each of them generating its own version
of the recogniser.
We tested the paraphrase grammar recognizer for
the Calendar application using paraphrases taken
from a previous run log and recorded by the two
authors. There were 249 recorded paraphrases to-
tal used. Because the Calendar paraphrase grammar
had originally been designed with only visual dis-
play in mind, some augmentation of the paraphrase
grammar was needed to cover the spoken versions
of the paraphrases. There is often more than one
possible spoken version corresponding to a written
representation as was the case for this data. For ex-
ample with a paraphrase such as “when are meet-
ings on Sat Jan 3 2009”, “Sat” could be pronounced
“sat” or “Saturday”, “3” could be “third” or “three”,
“Jan” could be produced as either “jan” or “January”
and “2009” could be “two thousand nine” or “two
thousand and nine”. With the paraphrase compo-
nent structured as a standard Regulus grammar, all
that was needed was to add lexical items to cover
the spoken variants. These additions were restricted
to the recognition use of the paraphrase grammar
and not used for generation. Word Error (WER) was
4.43% for the paraphrase grammar recognizer, Sen-
tence Error (SER)was 34.53% and Semantic Error
(SemER)was 17.9%. This SemER was calculated
on untuned n-best. Clearly it is not possible to com-
pare with the main recognizer on the same data, but
for a rough comparison, we can look at numbers re-
ported for the Calendar application in (Georgescul
et al., 2008). That paper reports WER of 11.17%
and SemER of 18.85% for the 1-best baseline. The
SemER on the paraphrase grammar is 21.5% for 1-
best. The paraphrase grammar recognizer has much
better WER because it is so much more restricted
than the main recognizer. However, the sentences
covered by the paraphrase grammar are much longer
than those covered in the main grammar, and this
difference is reflected in the poorer performance by
paraphrase grammar when measured in terms of Se-
</bodyText>
<figure confidence="0.9988795">
Output
Manager
Playback
or TTS
Logical Form
Main
Recognizer
Input
Manager
Dialogue
Move
Abstract
Action
Dialogue
Move
Paraphrase
Recognizer
Dialogue
Manager
GUI
Concrete
Action
Concrete
Action
</figure>
<page confidence="0.886355">
20
</page>
<bodyText confidence="0.999973909090909">
mER. The paraphrase language is long, very unnatu-
ral, yet we are able to produce a level of recognition
performance that is quite usable.
Given the ability to recognize with the paraphrase
grammar, a question which we hope to be able
to investigate empirically is the effect that entrain-
ment from exposure to the longer and less natural
paraphrases actually has on user language, which
initially tends to be biased towards short, natural-
sounding utterances, with frequent use of ellipsis.
This is a interesting topic for future research.
</bodyText>
<sectionHeader confidence="0.999462" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999993956521739">
The dialogue move paraphrase mechanism provides
a useful approach to streamlining regression testing
without abandoning necessary detail. In non-trivial
spoken dialogue systems, it is generally necessary
to have a number of levels of representation. Our
approach provides a middle ground between track-
ing each of these levels in the test suites, creating a
excessive maintenance burden, and keeping only top
level inputs and outputs, which is too coarse-grained
to catch many errors. The Regulus framework pro-
vides the opportunity to implement this mechanism
as a Regulus grammar, which makes the compilation
into recognisers, parsers and generators available.
While generation with the paraphrase grammar sup-
ports the described improvement in regression test-
ing methodology, compiling the paraphrase gram-
mar into a recogniser allows us to ensure that para-
phrases used as confirmations can also be processed
if directed at the dialogue system. The framework
has been used with several fairly different kinds of
applications, and appears to have a major impact on
the overhead associated with maintenance of a use-
ful regression testing regime.
</bodyText>
<sectionHeader confidence="0.99926" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999873758064516">
J. Allen, D. Byron, M. Dzikovska, G. Ferguson,
L. Galescu, and A. Stent. 2000. An architecture for
a generic dialogue shell. Natural Language Engineer-
ing, Special Issue on Best Practice in Spoken Lan-
guage Dialogue Systems Engineering, pages 1–16.
P. Bouillon, M. Rayner, B. Novellas, M. Starlander,
M. Santaholma, Y. Nakao, and N. Chatzichrisafis.
2007. Une grammaire partag´ee multi-tˆache pour le
traitement de la parole: application aux langues ro-
manes. TAL.
P. Bouillon, G. Flores, M. Georgescul, S. Halimi, B.A.
Hockey, H. Isahara, K. Kanzaki, Y. Nakao, M. Rayner,
M. Santaholma, M. Starlander, and N. Tsourakis.
2008. Many-to-many multilingual medical speech
translation on a PDA. In Proceedings of The Eighth
Conference ofthe Associationfor Machine Translation
in the Americas, Waikiki, Hawaii.
Milica Gasi´c, Simon Keizer, Francois Mairesse, Jost
Schatzmann, Blaise Thomson, Kai Yu, and Steve
Young. 2008. Training and evaluation of the his
pomdp dialogue system in noise. In Proceedings of the
9th SIGDIAL Workshop on Discourse and Dialogue.
Maria Georgescul, Manny Rayner, Pierrette Bouillon,
and Nikos Tsourakis. 2008. Discriminative learning
using linguistic features to rescore n-best speech hy-
potheses. In The IEEE Workshop on Spoken Language
Technology, Goa, India.
S. Larsson and D. Traum. 2000. Information state and
dialogue management in the TRINDI dialogue move
engine toolkit. Natural Language Engineering, Spe-
cial Issue on Best Practice in Spoken Language Dia-
logue Systems Engineering, pages 323–340.
M. Rayner, B.A. Hockey, J.M. Renders,
N. Chatzichrisafis, and K. Farrell. 2005. A voice
enabled procedure browser for the international space
station. In Proceedings of the 43rd Annual Meeting
of the Association for Computational Linguistics
(interactive poster and demo track), Ann Arbor, MI.
M. Rayner, B.A. Hockey, and P. Bouillon. 2006. Putting
Linguistics into Speech Recognition: The Regulus
Grammar Compiler. CSLI Press, Chicago.
M. Rayner. 1988. Applying explanation-based general-
ization to natural-language processing. In Proceedings
of the International Conference on Fifth Generation
Computer Systems, pages 1267–1274, Tokyo, Japan.
N. Roy, J Pineau, and S. Thrun. 2000. Spoken dia-
logue management using probabilistic reasoning. In
Proceedings ofACL, Hong Kong.
N. Tsourakis, M. Georghescul, P. Bouillon, and
M. Rayner. 2008. Building mobile spoken dialogue
applications using regulus. In Proceedings of LREC
2008, Marrakesh, Morocco.
T. van Harmelen and A. Bundy. 1988. Explanation-
based generalization = partial evaluation (research
note). Artificial Intelligence, 36:401–412.
JD Williams and SJ Young. 2007. Partially observable
markov decision processes for spoken dialog systems.
Computer Speech and Language.
B. Zhang, Q Cai, J. Mao, E. Chang, and B Guo. 2001.
Spoken dialogue management as planning and acting
under uncertainty. In Proceedings ofEurospeech, Aal-
borg, Denmark.
</reference>
<page confidence="0.999438">
21
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.714746">
<title confidence="0.9963225">Using Paraphrases of Deep Semantic to Support Regression Testing in Spoken Dialogue Systems</title>
<author confidence="0.999286">Beth Ann</author>
<affiliation confidence="0.998494">UC Santa Cruz and BAHRC</affiliation>
<address confidence="0.9010535">Mail Stop 19-26, UCSC NASA Ames Research Center, Moffett Field, CA</address>
<email confidence="0.956192">bahockey@bahrc.net</email>
<author confidence="0.98096">Manny</author>
<affiliation confidence="0.999974">University of Geneva,</affiliation>
<address confidence="0.969874">40 bvd du Pont-d’Arve, CH-1211 Geneva 4,</address>
<email confidence="0.958671">Emmanuel.Rayner@unige.ch</email>
<abstract confidence="0.99966975">Rule-based spoken dialogue systems require a good regression testing framework if they are to be maintainable. We argue that there is a tension between two extreme positions when constructing the database of test examples. On the one hand, if the examples consist of input/output tuples representing many levels of internal processing, they are finegrained enough to catch most processing errors, but unstable under most system modifications. If the examples are pairs of user input and final system output, they are much more stable, but too coarse-grained to catch many errors. In either case, there are fairly severe difficulties in judging examples correctly. We claim that a good compromise can be reached by implementing a paraphrasing mechanism which maps internal semantic representations into surface forms, and carrying out regression testing using paraphrases of semantic forms rather than the semantic forms themselves. We describe an implementation of the idea using the Open Source Regulus toolkit, where paraphrases are produced using Regulus grammars compiled in generation mode. Paraphrases can also be used at runtime to produce confirmations. By compiling the paraphrase grammar a second time, as a recogniser, it is possible in a simple and natural way to guarantee that confirmations are always within system coverage.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Allen</author>
<author>D Byron</author>
<author>M Dzikovska</author>
<author>G Ferguson</author>
<author>L Galescu</author>
<author>A Stent</author>
</authors>
<title>An architecture for a generic dialogue shell. Natural Language Engineering, Special Issue on Best Practice in Spoken Language Dialogue Systems Engineering,</title>
<date>2000</date>
<pages>1--16</pages>
<contexts>
<context position="7616" citStr="Allen et al., 2000" startWordPosition="1174" endWordPosition="1177">uance-specific compilation steps to derive a speech recognition package. Figure 1 summarises compile-time processing. The Regulus platform also contains infrastructure to support construction of applications which use the recognisers, parsers and generators as components. In this paper, we will only discuss spoken dialogue system applications. (There is also an elaborate infrastructure to support speech translation systems). 15 Figure 2: Top-level architecture for Regulus-based spoken dialogue system At a high level of generality, the architecture is a standard one (Figure 2; cf. for example (Allen et al., 2000)). The central component is the Dialogue Manager (DM), which receives dialogue moves and produces abstract actions. It also manipulates an information state, which maintains context; processing will generally be context-dependent. The DM is bracketed between two other components, the Input Manager (IM) and the Output Manager (OM). The IM receives logical forms, and non-speech inputs if there are any, and turns them into dialogue moves. The OM received abstract actions and turns them into concrete actions. Usually, these actions will be either speaking, though TTS or recorded speech, or manipul</context>
</contexts>
<marker>Allen, Byron, Dzikovska, Ferguson, Galescu, Stent, 2000</marker>
<rawString>J. Allen, D. Byron, M. Dzikovska, G. Ferguson, L. Galescu, and A. Stent. 2000. An architecture for a generic dialogue shell. Natural Language Engineering, Special Issue on Best Practice in Spoken Language Dialogue Systems Engineering, pages 1–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Bouillon</author>
<author>M Rayner</author>
<author>B Novellas</author>
<author>M Starlander</author>
<author>M Santaholma</author>
<author>Y Nakao</author>
<author>N Chatzichrisafis</author>
</authors>
<title>Une grammaire partag´ee multi-tˆache pour le traitement de la parole: application aux langues romanes.</title>
<date>2007</date>
<publisher>TAL.</publisher>
<contexts>
<context position="5556" citStr="Bouillon et al., 2007" startWordPosition="860" endWordPosition="863">tion concludes. 2 The Regulus platform Regulus is an Open Source toolkit for building medium vocabulary grammar-based spoken dialogue and translation systems. The central idea is to base run-time processing on efficient, task-specific grammars derived from general, reusable, domainindependent core grammars. Early versions of Regulus used a single core grammar per language; a detailed description of the core grammar for English can be found in (Rayner et al., 2006, Chapter 9). More recently, there have been attempts to go further, and merge together core grammars for closely related languages (Bouillon et al., 2007). The core grammars are automatically specialised, Figure 1: The Regulus compilation path. The general unification grammar is first transformed into a specialised feature grammar. This can then be transformed either into a CFG grammar and Nuance recogniser, or into a generator. and a Nuance recogniser. using corpus-driven methods based on small corpora, to derive simpler grammars. Specialisation is both with respect to task (recognition, analysis, generation) and to application domain. The specialisation process uses the Explanation Based Learning algorithm (van Harmelen and Bundy, 1988; Rayne</context>
</contexts>
<marker>Bouillon, Rayner, Novellas, Starlander, Santaholma, Nakao, Chatzichrisafis, 2007</marker>
<rawString>P. Bouillon, M. Rayner, B. Novellas, M. Starlander, M. Santaholma, Y. Nakao, and N. Chatzichrisafis. 2007. Une grammaire partag´ee multi-tˆache pour le traitement de la parole: application aux langues romanes. TAL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Bouillon</author>
<author>G Flores</author>
<author>M Georgescul</author>
<author>S Halimi</author>
<author>B A Hockey</author>
<author>H Isahara</author>
<author>K Kanzaki</author>
<author>Y Nakao</author>
<author>M Rayner</author>
<author>M Santaholma</author>
<author>M Starlander</author>
<author>N Tsourakis</author>
</authors>
<title>Many-to-many multilingual medical speech translation on a PDA.</title>
<date>2008</date>
<booktitle>In Proceedings of The Eighth Conference ofthe Associationfor Machine Translation in the Americas,</booktitle>
<location>Waikiki, Hawaii.</location>
<contexts>
<context position="4105" citStr="Bouillon et al., 2008" startWordPosition="626" endWordPosition="630">d a number of non-trivial spoken dialogue systems. Prominent examples include NASA’s Clarissa Procedure Navigator (Rayner et al., 2005), Geneva University’s multi-modal mobile-platform Calendar application (Tsourakis et al., 2008), SDS, a prototype in-car system developed by UC Santa Cruz in collaboration with Ford Motors Research which was voted first in Ford’s 2007 internal technology fair, and Taxi, a speech-enabled game in which the user interacts with a simulated cab driver to navigate around a map of Manhattan. It has also been used to build the MedSLT medical speech translation system (Bouillon et al., 2008). The Regulus platform includes tools for developing feature grammars, and compiling them in various ways. In particular, it is possible to compile grammars into generators, and use them to support paraphrasing from the internal semantic representations created during dialogue processing. This capability is key to the newest part of our regression testing approach, and is discussed in detail in Section 3. First, though, Section 2 gives an overview of Regulus and the architecture of Regulus-based systems; we discuss features that complicate regression testing, and how to address these problems </context>
</contexts>
<marker>Bouillon, Flores, Georgescul, Halimi, Hockey, Isahara, Kanzaki, Nakao, Rayner, Santaholma, Starlander, Tsourakis, 2008</marker>
<rawString>P. Bouillon, G. Flores, M. Georgescul, S. Halimi, B.A. Hockey, H. Isahara, K. Kanzaki, Y. Nakao, M. Rayner, M. Santaholma, M. Starlander, and N. Tsourakis. 2008. Many-to-many multilingual medical speech translation on a PDA. In Proceedings of The Eighth Conference ofthe Associationfor Machine Translation in the Americas, Waikiki, Hawaii.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Milica Gasi´c</author>
<author>Simon Keizer</author>
<author>Francois Mairesse</author>
<author>Jost Schatzmann</author>
<author>Blaise Thomson</author>
<author>Kai Yu</author>
<author>Steve Young</author>
</authors>
<title>Training and evaluation of the his pomdp dialogue system in noise.</title>
<date>2008</date>
<booktitle>In Proceedings of the 9th SIGDIAL Workshop on Discourse and Dialogue.</booktitle>
<marker>Gasi´c, Keizer, Mairesse, Schatzmann, Thomson, Yu, Young, 2008</marker>
<rawString>Milica Gasi´c, Simon Keizer, Francois Mairesse, Jost Schatzmann, Blaise Thomson, Kai Yu, and Steve Young. 2008. Training and evaluation of the his pomdp dialogue system in noise. In Proceedings of the 9th SIGDIAL Workshop on Discourse and Dialogue.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Georgescul</author>
<author>Manny Rayner</author>
<author>Pierrette Bouillon</author>
<author>Nikos Tsourakis</author>
</authors>
<title>Discriminative learning using linguistic features to rescore n-best speech hypotheses.</title>
<date>2008</date>
<booktitle>In The IEEE Workshop on Spoken Language Technology,</booktitle>
<location>Goa, India.</location>
<contexts>
<context position="27364" citStr="Georgescul et al., 2008" startWordPosition="4424" endWordPosition="4427">araphrase component structured as a standard Regulus grammar, all that was needed was to add lexical items to cover the spoken variants. These additions were restricted to the recognition use of the paraphrase grammar and not used for generation. Word Error (WER) was 4.43% for the paraphrase grammar recognizer, Sentence Error (SER)was 34.53% and Semantic Error (SemER)was 17.9%. This SemER was calculated on untuned n-best. Clearly it is not possible to compare with the main recognizer on the same data, but for a rough comparison, we can look at numbers reported for the Calendar application in (Georgescul et al., 2008). That paper reports WER of 11.17% and SemER of 18.85% for the 1-best baseline. The SemER on the paraphrase grammar is 21.5% for 1- best. The paraphrase grammar recognizer has much better WER because it is so much more restricted than the main recognizer. However, the sentences covered by the paraphrase grammar are much longer than those covered in the main grammar, and this difference is reflected in the poorer performance by paraphrase grammar when measured in terms of SeOutput Manager Playback or TTS Logical Form Main Recognizer Input Manager Dialogue Move Abstract Action Dialogue Move Para</context>
</contexts>
<marker>Georgescul, Rayner, Bouillon, Tsourakis, 2008</marker>
<rawString>Maria Georgescul, Manny Rayner, Pierrette Bouillon, and Nikos Tsourakis. 2008. Discriminative learning using linguistic features to rescore n-best speech hypotheses. In The IEEE Workshop on Spoken Language Technology, Goa, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Larsson</author>
<author>D Traum</author>
</authors>
<title>Information state and dialogue management in the TRINDI dialogue move engine toolkit.</title>
<date>2000</date>
<journal>Natural Language Engineering, Special</journal>
<booktitle>Issue on Best Practice in Spoken Language Dialogue Systems Engineering,</booktitle>
<pages>323--340</pages>
<contexts>
<context position="10535" citStr="Larsson and Traum, 2000" startWordPosition="1645" endWordPosition="1648">e worst case, the context is the whole world, or at least the part of it that the system is interacting with, and regression testing is impossible. In more typical cases, however, good architectural choices can make the problem reasonably tractable. In particular, things become enormously simpler if it is possible to encapsulate all the context information in a datastructure that can be passed around. In the dialogue management architecture realised in Regulus (Rayner et al., 2006, Chapter 5), the assumption is that this is the case; it is then possible to use a version of “update semantics” (Larsson and Traum, 2000). The central concepts are those of dialogue move, information state and dialogue action. At the beginning of each turn, the dialogue manager is in an information state. Inputs to the dialogue manager are by definition dialogue moves, and outputs are dialogue actions. The behaviour of the dialogue manager over a turn is completely specified by an update function f of the form f : State×Move → State×Actions Thus if a dialogue move is applied in a given information state, the result is a new information state and a set of zero or more dialogue actions. 3.1 Regression testing Using the side-effec</context>
</contexts>
<marker>Larsson, Traum, 2000</marker>
<rawString>S. Larsson and D. Traum. 2000. Information state and dialogue management in the TRINDI dialogue move engine toolkit. Natural Language Engineering, Special Issue on Best Practice in Spoken Language Dialogue Systems Engineering, pages 323–340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
<author>B A Hockey</author>
<author>J M Renders</author>
<author>N Chatzichrisafis</author>
<author>K Farrell</author>
</authors>
<title>A voice enabled procedure browser for the international space station.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (interactive poster and demo track),</booktitle>
<location>Ann Arbor, MI.</location>
<contexts>
<context position="3618" citStr="Rayner et al., 2005" startWordPosition="550" endWordPosition="553">ses the methodology we have developed to address regression testing issues within the Regulus framework. Regulus (Rayner et al., 2006) is an Open Source toolkit for builting medium 14 Proceedings of the NAACL HLT Workshop on Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 14–21, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics vocabulary spoken dialogue and translation applications, and has been used to build a number of non-trivial spoken dialogue systems. Prominent examples include NASA’s Clarissa Procedure Navigator (Rayner et al., 2005), Geneva University’s multi-modal mobile-platform Calendar application (Tsourakis et al., 2008), SDS, a prototype in-car system developed by UC Santa Cruz in collaboration with Ford Motors Research which was voted first in Ford’s 2007 internal technology fair, and Taxi, a speech-enabled game in which the user interacts with a simulated cab driver to navigate around a map of Manhattan. It has also been used to build the MedSLT medical speech translation system (Bouillon et al., 2008). The Regulus platform includes tools for developing feature grammars, and compiling them in various ways. In par</context>
</contexts>
<marker>Rayner, Hockey, Renders, Chatzichrisafis, Farrell, 2005</marker>
<rawString>M. Rayner, B.A. Hockey, J.M. Renders, N. Chatzichrisafis, and K. Farrell. 2005. A voice enabled procedure browser for the international space station. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (interactive poster and demo track), Ann Arbor, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
<author>B A Hockey</author>
<author>P Bouillon</author>
</authors>
<title>Putting Linguistics into Speech Recognition: The Regulus Grammar Compiler.</title>
<date>2006</date>
<publisher>CSLI Press,</publisher>
<location>Chicago.</location>
<contexts>
<context position="3132" citStr="Rayner et al., 2006" startWordPosition="480" endWordPosition="483">ext of each interaction in the test suite needs to be stored as part of the interaction. Multiple levels of representation that are, for example, useful for doing ellipsis resolution or reference resolution, also complicate testing. If regression testing is done on each separate level of processing, or involves internal representations, small changes to a representation at one level can mean having to revise and rejudge the entire test suite to keep it up to date. This paper discusses the methodology we have developed to address regression testing issues within the Regulus framework. Regulus (Rayner et al., 2006) is an Open Source toolkit for builting medium 14 Proceedings of the NAACL HLT Workshop on Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 14–21, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics vocabulary spoken dialogue and translation applications, and has been used to build a number of non-trivial spoken dialogue systems. Prominent examples include NASA’s Clarissa Procedure Navigator (Rayner et al., 2005), Geneva University’s multi-modal mobile-platform Calendar application (Tsourakis et al., 2008), SDS, a prototype </context>
<context position="5401" citStr="Rayner et al., 2006" startWordPosition="835" endWordPosition="838">structed and what types of items they may contain. In Section 5 we show how paraphrases can also be included in the run-time architecture. The final section concludes. 2 The Regulus platform Regulus is an Open Source toolkit for building medium vocabulary grammar-based spoken dialogue and translation systems. The central idea is to base run-time processing on efficient, task-specific grammars derived from general, reusable, domainindependent core grammars. Early versions of Regulus used a single core grammar per language; a detailed description of the core grammar for English can be found in (Rayner et al., 2006, Chapter 9). More recently, there have been attempts to go further, and merge together core grammars for closely related languages (Bouillon et al., 2007). The core grammars are automatically specialised, Figure 1: The Regulus compilation path. The general unification grammar is first transformed into a specialised feature grammar. This can then be transformed either into a CFG grammar and Nuance recogniser, or into a generator. and a Nuance recogniser. using corpus-driven methods based on small corpora, to derive simpler grammars. Specialisation is both with respect to task (recognition, ana</context>
<context position="10396" citStr="Rayner et al., 2006" startWordPosition="1619" endWordPosition="1622">e who has tried will know, the thing that makes regression testing difficult for this kind of application is context-dependency. In the worst case, the context is the whole world, or at least the part of it that the system is interacting with, and regression testing is impossible. In more typical cases, however, good architectural choices can make the problem reasonably tractable. In particular, things become enormously simpler if it is possible to encapsulate all the context information in a datastructure that can be passed around. In the dialogue management architecture realised in Regulus (Rayner et al., 2006, Chapter 5), the assumption is that this is the case; it is then possible to use a version of “update semantics” (Larsson and Traum, 2000). The central concepts are those of dialogue move, information state and dialogue action. At the beginning of each turn, the dialogue manager is in an information state. Inputs to the dialogue manager are by definition dialogue moves, and outputs are dialogue actions. The behaviour of the dialogue manager over a turn is completely specified by an update function f of the form f : State×Move → State×Actions Thus if a dialogue move is applied in a given infor</context>
</contexts>
<marker>Rayner, Hockey, Bouillon, 2006</marker>
<rawString>M. Rayner, B.A. Hockey, and P. Bouillon. 2006. Putting Linguistics into Speech Recognition: The Regulus Grammar Compiler. CSLI Press, Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
</authors>
<title>Applying explanation-based generalization to natural-language processing.</title>
<date>1988</date>
<booktitle>In Proceedings of the International Conference on Fifth Generation Computer Systems,</booktitle>
<pages>1267--1274</pages>
<location>Tokyo, Japan.</location>
<contexts>
<context position="6164" citStr="Rayner, 1988" startWordPosition="951" endWordPosition="952">2007). The core grammars are automatically specialised, Figure 1: The Regulus compilation path. The general unification grammar is first transformed into a specialised feature grammar. This can then be transformed either into a CFG grammar and Nuance recogniser, or into a generator. and a Nuance recogniser. using corpus-driven methods based on small corpora, to derive simpler grammars. Specialisation is both with respect to task (recognition, analysis, generation) and to application domain. The specialisation process uses the Explanation Based Learning algorithm (van Harmelen and Bundy, 1988; Rayner, 1988). It starts with a parsed treebank derived from the training corpus, and then divides the parse tree created from each training example into a set of one or more subtrees, following a set of domain- and grammar-specific rules conventionally known in the Machine Learning literature as operationality criteria. The rules in each subtree are then combined, using the unification operation, into a single rule. The set of all such rules constitutes a specialised unification grammar. Each of these specialised unification grammars is then subjected to a second compilation step, which converts it into i</context>
</contexts>
<marker>Rayner, 1988</marker>
<rawString>M. Rayner. 1988. Applying explanation-based generalization to natural-language processing. In Proceedings of the International Conference on Fifth Generation Computer Systems, pages 1267–1274, Tokyo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Roy</author>
<author>J Pineau</author>
<author>S Thrun</author>
</authors>
<title>Spoken dialogue management using probabilistic reasoning.</title>
<date>2000</date>
<booktitle>In Proceedings ofACL, Hong Kong.</booktitle>
<contexts>
<context position="9004" citStr="Roy et al., 2000" startWordPosition="1396" endWordPosition="1399">lopment cycle. We will in particular be interested in regression testing. 3 Context, regression testing and paraphrasing The three main components of the spoken dialogue system — the IM, DM and OM — all transform one or more inputs into one or more outputs. With the current focus on machine learning techniques, a natural thought is to learn the relevant tranformations from examples. Implemented mainly through Partially Observable Markov Decision Processes (POMDPs), this idea is attractive theoretically, but has been challenging to scale up. Systems have been restricted to very simple domains (Roy et al., 2000; Zhang et al., 2001) and only recently have techniques been developed that show promise for use in real-world systems (Williams and Young, 2007; Gasi´c et al., 2008). The representations required in many systems are more complex than those employed even in the more recent POMDP based work, and there is also the usual problem that it is not easy to obtain training data. In practice, most people are forced to construct the transformation rules by hand; the Regulus framework assumes this will be the case. Hand-coding of dialogue processing components involves the usual software engineering probl</context>
</contexts>
<marker>Roy, Pineau, Thrun, 2000</marker>
<rawString>N. Roy, J Pineau, and S. Thrun. 2000. Spoken dialogue management using probabilistic reasoning. In Proceedings ofACL, Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Tsourakis</author>
<author>M Georghescul</author>
<author>P Bouillon</author>
<author>M Rayner</author>
</authors>
<title>Building mobile spoken dialogue applications using regulus.</title>
<date>2008</date>
<booktitle>In Proceedings of LREC</booktitle>
<location>Marrakesh, Morocco.</location>
<contexts>
<context position="3713" citStr="Tsourakis et al., 2008" startWordPosition="560" endWordPosition="563">s framework. Regulus (Rayner et al., 2006) is an Open Source toolkit for builting medium 14 Proceedings of the NAACL HLT Workshop on Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 14–21, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics vocabulary spoken dialogue and translation applications, and has been used to build a number of non-trivial spoken dialogue systems. Prominent examples include NASA’s Clarissa Procedure Navigator (Rayner et al., 2005), Geneva University’s multi-modal mobile-platform Calendar application (Tsourakis et al., 2008), SDS, a prototype in-car system developed by UC Santa Cruz in collaboration with Ford Motors Research which was voted first in Ford’s 2007 internal technology fair, and Taxi, a speech-enabled game in which the user interacts with a simulated cab driver to navigate around a map of Manhattan. It has also been used to build the MedSLT medical speech translation system (Bouillon et al., 2008). The Regulus platform includes tools for developing feature grammars, and compiling them in various ways. In particular, it is possible to compile grammars into generators, and use them to support paraphrasi</context>
</contexts>
<marker>Tsourakis, Georghescul, Bouillon, Rayner, 2008</marker>
<rawString>N. Tsourakis, M. Georghescul, P. Bouillon, and M. Rayner. 2008. Building mobile spoken dialogue applications using regulus. In Proceedings of LREC 2008, Marrakesh, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T van Harmelen</author>
<author>A Bundy</author>
</authors>
<title>Explanationbased generalization = partial evaluation (research note).</title>
<date>1988</date>
<journal>Artificial Intelligence,</journal>
<pages>36--401</pages>
<marker>van Harmelen, Bundy, 1988</marker>
<rawString>T. van Harmelen and A. Bundy. 1988. Explanationbased generalization = partial evaluation (research note). Artificial Intelligence, 36:401–412.</rawString>
</citation>
<citation valid="true">
<authors>
<author>JD Williams</author>
<author>SJ Young</author>
</authors>
<title>Partially observable markov decision processes for spoken dialog systems. Computer Speech and Language.</title>
<date>2007</date>
<contexts>
<context position="9148" citStr="Williams and Young, 2007" startWordPosition="1419" endWordPosition="1422">components of the spoken dialogue system — the IM, DM and OM — all transform one or more inputs into one or more outputs. With the current focus on machine learning techniques, a natural thought is to learn the relevant tranformations from examples. Implemented mainly through Partially Observable Markov Decision Processes (POMDPs), this idea is attractive theoretically, but has been challenging to scale up. Systems have been restricted to very simple domains (Roy et al., 2000; Zhang et al., 2001) and only recently have techniques been developed that show promise for use in real-world systems (Williams and Young, 2007; Gasi´c et al., 2008). The representations required in many systems are more complex than those employed even in the more recent POMDP based work, and there is also the usual problem that it is not easy to obtain training data. In practice, most people are forced to construct the transformation rules by hand; the Regulus framework assumes this will be the case. Hand-coding of dialogue processing components involves the usual software engineering problems that arise when building and maintaining substantial rule-sets. In particular, it is necessary to have a framework that supports efficient r</context>
</contexts>
<marker>Williams, Young, 2007</marker>
<rawString>JD Williams and SJ Young. 2007. Partially observable markov decision processes for spoken dialog systems. Computer Speech and Language.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Zhang</author>
<author>Q Cai</author>
<author>J Mao</author>
<author>E Chang</author>
<author>B Guo</author>
</authors>
<title>Spoken dialogue management as planning and acting under uncertainty.</title>
<date>2001</date>
<booktitle>In Proceedings ofEurospeech,</booktitle>
<location>Aalborg, Denmark.</location>
<contexts>
<context position="9025" citStr="Zhang et al., 2001" startWordPosition="1400" endWordPosition="1403">will in particular be interested in regression testing. 3 Context, regression testing and paraphrasing The three main components of the spoken dialogue system — the IM, DM and OM — all transform one or more inputs into one or more outputs. With the current focus on machine learning techniques, a natural thought is to learn the relevant tranformations from examples. Implemented mainly through Partially Observable Markov Decision Processes (POMDPs), this idea is attractive theoretically, but has been challenging to scale up. Systems have been restricted to very simple domains (Roy et al., 2000; Zhang et al., 2001) and only recently have techniques been developed that show promise for use in real-world systems (Williams and Young, 2007; Gasi´c et al., 2008). The representations required in many systems are more complex than those employed even in the more recent POMDP based work, and there is also the usual problem that it is not easy to obtain training data. In practice, most people are forced to construct the transformation rules by hand; the Regulus framework assumes this will be the case. Hand-coding of dialogue processing components involves the usual software engineering problems that arise when b</context>
</contexts>
<marker>Zhang, Cai, Mao, Chang, Guo, 2001</marker>
<rawString>B. Zhang, Q Cai, J. Mao, E. Chang, and B Guo. 2001. Spoken dialogue management as planning and acting under uncertainty. In Proceedings ofEurospeech, Aalborg, Denmark.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>