<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.006988">
<title confidence="0.981519">
Multi-domain Dialog State Tracking using Recurrent Neural Networks
</title>
<author confidence="0.981015">
Nikola Mrkˇsi´c1 2, Diarmuid O´ S´eaghdha2, Blaise Thomson2, Milica Gaˇsi´c1
Pei-Hao Su1, David Vandyke1, Tsung-Hsien Wen1 and Steve Young1
</author>
<affiliation confidence="0.718139">
1 Department of Engineering, University of Cambridge, UK
2 VocalIQ Ltd. , Cambridge, UK
</affiliation>
<email confidence="0.984537">
{nm480,mg436,phs26,djv27,thw28,sjy}@cam.ac.uk {diarmuid, blaise}@vocaliq.com
</email>
<sectionHeader confidence="0.993593" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999956125">
Dialog state tracking is a key component
of many modern dialog systems, most of
which are designed with a single, well-
defined domain in mind. This paper shows
that dialog data drawn from different dia-
log domains can be used to train a general
belief tracking model which can operate
across all of these domains, exhibiting su-
perior performance to each of the domain-
specific models. We propose a training pro-
cedure which uses out-of-domain data to
initialise belief tracking models for entirely
new domains. This procedure leads to im-
provements in belief tracking performance
regardless of the amount of in-domain data
available for training the model.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999960434782609">
Spoken dialog systems allow users to interact with
computer applications through a conversational in-
terface. Modern dialog systems are typically de-
signed with a well-defined domain in mind, e.g.,
restaurant search, travel reservations or shopping
for a new laptop. The goal of building open-domain
dialog systems capable of conversing about any
topic remains far off. In this work, we move to-
wards this goal by showing how to build dialog
state tracking models which can operate across
entirely different domains. The state tracking com-
ponent of a dialog system is responsible for inter-
preting the users’ utterances and thus updating the
system’s belief state: a probability distribution over
all possible states of the dialog. This belief state is
used by the system to decide what to do next.
Recurrent Neural Networks (RNNs) are well
suited to dialog state tracking, as their ability to cap-
ture contextual information allows them to model
and label complex dynamic sequences (Graves,
2012). In recent shared tasks, approaches based on
these models have shown competitive performance
(Henderson et al., 2014d; Henderson et al., 2014c).
This approach is particularly well suited to our goal
of building open-domain dialog systems, as it does
not require handcrafted domain-specific resources
for semantic interpretation.
We propose a method for training multi-domain
RNN dialog state tracking models. Our hierarchical
training procedure first uses all the data available
to train a very general belief tracking model. This
model learns the most frequent and general dialog
features present across the various domains. The
general model is then specialised for each domain,
learning domain-specific behaviour while retaining
the cross-domain dialog patterns learned during the
initial training stages. These models show robust
performance across all the domains investigated,
typically outperforming trackers trained on target-
domain data alone. The procedure can also be used
to initialise dialog systems for entirely new do-
mains. In the evaluation, we show that such initiali-
sation always improves performance, regardless of
the amount of the in-domain training data available.
We believe that this work is the first to address the
question of multi-domain belief tracking.
</bodyText>
<sectionHeader confidence="0.999766" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.998986928571429">
Traditional rule-based approaches to understanding
in dialog systems (e.g. Goddeau et al. (1996)) have
been superseded by data-driven systems that are
more robust and can provide the probabilistic dia-
log state distributions that are needed by POMDP-
based dialog managers. The recent Dialog State
Tracking Challenge (DSTC) shared tasks (Williams
et al., 2013; Henderson et al., 2014a; Henderson
et al., 2014b) saw a variety of novel approaches,
including robust sets of hand-crafted rules (Wang
and Lemon, 2013), conditional random fields (Lee
and Eskenazi, 2013; Lee, 2013; Ren et al., 2013),
maximum entropy models (Williams, 2013) and
web-style ranking (Williams, 2014).
</bodyText>
<page confidence="0.916231">
794
</page>
<bodyText confidence="0.95860990625">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 794–799,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
Henderson et al. (2013; 2014d; 2014c) proposed
a belief tracker based on recurrent neural networks.
This approach maps directly from the ASR (au-
tomatic speech recognition) output to the belief
state update, avoiding the use of complex semantic
decoders while still attaining state-of-the-art per-
formance. We adopt this RNN framework as the
starting point for the work described here.
It is well-known in machine learning that a sys-
tem trained on data from one domain may not per-
form as well when deployed in a different domain.
Researchers have investigated methods for mitigat-
ing this problem, with NLP applications in parsing
(McClosky et al., 2006; McClosky et al., 2010),
sentiment analysis (Blitzer et al., 2007; Glorot et
al., 2011) and many other tasks. There has been a
small amount of previous work on domain adapta-
tion for dialog systems. Tur et al. (2007) and Mar-
golis et al. (2010) investigated domain adaptation
for dialog act tagging. Walker et al. (2007) trained
a sentence planner/generator that adapts to differ-
ent individuals and domains. In the third DSTC
shared task (Henderson et al., 2014b), participants
deployed belief trackers trained on a restaurant do-
main in an expanded version of the same domain,
with a richer output space but essentially the same
topic. To the best of our knowledge, our work is
the first attempt to build a belief tracker capable of
operating across disjoint dialog domains.
</bodyText>
<sectionHeader confidence="0.98598" genericHeader="method">
3 Dialog State Tracking using RNNs
</sectionHeader>
<bodyText confidence="0.981921596153846">
Belief tracking models capture users’ goals given
their utterances. Goals are represented as sets of
constraints expressed by slot-value mappings such
as [food: chinese] or [wifi: available]. The set of
slots S and the set of values Vs for each slot make
up the ontology for an application domain.
Our starting point is the RNN framework for
belief tracking that was introduced by Henderson
et al. (2014d; 2014c). This is a single-hidden-layer
recurrent neural network that outputs a distribution
over all goal slot-value pairs for each user utterance
in a dialog. It also maintains a memory vector
that stores internal information about the dialog
context. The input for each user utterance consists
of the ASR hypotheses, the last system action, the
current memory vector and the previous belief state.
Rather than using a spoken language understanding
(SLU) decoder to convert this input into a meaning
representation, the system uses the turn input to
extract a large number of word n-gram features.
These features capture some of the dialog dynamics
but are not ideal for sharing information across
different slots and domains.
Delexicalised n-gram features overcome this
problem by replacing all references to slot names
and values with generic symbols. Lexical n-grams
such as [want cheap price] and [want Chinese
food] map to the same delexicalised feature, rep-
resented by [want tagged-slot-value tagged-slot-
name]. Such features facilitate transfer learning
between slots and allow the system to operate on
unseen values or entirely new slots. As an example,
[want available internet] would be delexicalised to
[want tagged-slot-value tagged-slot-name] as well,
a useful feature even if there is no training data
available for the internet slot. The delexicalised
model learns the belief state update corresponding
to this feature from its occurrences across the other
slots and domains. Subsequently, it can apply the
learned behaviour to slots in entirely new domains.
The system maintains a separate belief state for
each slot s, represented by the distribution ps over
all possible slot values v E Vs. The model input
at turn t, xt, consists of the previous belief state
pt−1
s , the previous memory state mt−1, as well as
the vectors fl and fd of lexical and delexicalised
features extracted from the turn input1. The belief
state of each slot s is updated for each of its slot
values v E Vs. The RNN memory layer is updated
as well. The updates are as follows2:
= ftl ® ft d ® mt−1 ® pt−1
</bodyText>
<equation confidence="0.995096857142857">
v ® pt−1
∅
) + bs
gt v = ws 1 &apos; Q (Ws 0xt v + bs 0 1
exp(gt v)
pt v = exp(gt∅) + Ev,∈V exp(gtv,)
mt = Q (Wsm0xt + Wsm1mt−1)
</equation>
<bodyText confidence="0.99999225">
where ® denotes vector concatenation and pt ∅ is the
probability that the user has expressed no constraint
up to turn t. Matrices Ws0, Ws m0, Wsm1 and the
vector ws1 are the RNN weights, and b0 and b1 are
the hidden and output layer RNN bias terms.
For training, the model is unrolled across turns
and trained using backpropagation through time
and stochastic gradient descent (Graves, 2012).
</bodyText>
<footnote confidence="0.628289875">
1Henderson et al.’s work distinguished between three types
of features: the delexicalised feature sets f$ and f&amp;quot; are sub-
sumed by our delexicalised feature vector fd, and the turn
input f corresponds to our lexical feature vector fl.
2The original RNN architecture had a second component
which learned mappings from lexical n-grams to specific slot
values. In order to move towards domain-independence, we
do not use this part of the network.
</footnote>
<bodyText confidence="0.7198665">
xt
v
</bodyText>
<page confidence="0.995646">
795
</page>
<sectionHeader confidence="0.997935" genericHeader="method">
4 Hierarchical Model Training
</sectionHeader>
<bodyText confidence="0.999949378378378">
Delexicalised features allow transfer learning be-
tween slots. We extend this approach to achieve
transfer learning between domains: a model trained
to talk about hotels should have some success talk-
ing about restaurants, or even laptops. If we can
incorporate features learned from different domains
into a single model, this model should be able to
track belief state across all of these domains.
The training procedure starts by performing
shared initialisation: the RNN parameters of all
the slots are tied and all the slot value occurrences
are replaced with a single generic tag. These slot-
agnostic delexicalised dialogs are then used to train
the parameters of the shared RNN model.
Extending shared initialisation to training across
multiple domains is straightforward. We first delex-
icalise all slot value occurrences for all slots across
the different domains in the training data. This
combined (delexicalised) dataset is then used to
train the multi-domain shared model.
The shared RNN model is trained with the pur-
pose of extracting a very rich set of lexical and
delexicalised features which capture general dialog
dynamics. While the features are general, the RNN
parameters are not, since not all of the features
are equally relevant for different slots. For exam-
ple, [eat tagged-slot-value food] and [near tagged-
slot-value] are clearly features related to food and
area slots respectively. To ensure that the model
learns the relative importance of different features
for each of the slots, we train slot specific mod-
els for each slot across all the available domains.
To train these slot-specialised models, the shared
RNN’s parameters are replicated for each slot and
specialised further by performing additional runs
of stochastic gradient descent using only the slot-
specific (delexicalised) training data.
</bodyText>
<sectionHeader confidence="0.978886" genericHeader="method">
5 Dialog domains considered
</sectionHeader>
<bodyText confidence="0.975835727272727">
We use the experimental setup of the Dialog State
Tracking Challenges. The key metric used to mea-
sure the success of belief tracking is goal accuracy,
which represents the ability of the system to cor-
rectly infer users’ constraints. We report the joint
goal accuracy, which represents the marginal test
accuracy across all slots in the domain.
We evaluate on data from six domains, varying
across topic and geographical location (Table 1).
The Cambridge Restaurants data is the data from
DSTC 2. The San Francisco Restaurants and Ho-
</bodyText>
<table confidence="0.9998434">
Dataset / Model Domain Train Test Slots
Cambridge Rest. Restaurants 2118 1117 4
SF Restaurants Restaurants 1608 176 7
Michigan Rest. Restaurants 845 146 12
All Restaurants Restaurants 4398 - 23
Tourist Info. Tourist Info 2039 225 9
SF Hotels Hotels Info 1086 120 7
R+T+H Model Mixed 7523 - 39
Laptops Laptops 900 100 6
R+T+H+L Model Mixed 8423 - 45
</table>
<tableCaption confidence="0.999967">
Table 1: datasets used in our experiments
</tableCaption>
<bodyText confidence="0.998602071428571">
tels data was collected during the Parlance project
(Gaˇsi´c et al., 2014). The Tourist Information do-
main is the DSTC 3 dataset: it contains dialogs
about hotels, restaurants, pubs and coffee shops.
The Michigan Restaurants and Laptops datasets
are collections of dialogs sourced using Amazon
Mechanical Turk. The Laptops domain contains
conversations with users instructed to find laptops
with certain characteristics. This domain is sub-
stantially different from the other ones, making it
particularly useful for assessing the quality of the
multi-domain models trained.
We introduce three combined datasets used to
train increasingly general belief tracking models:
</bodyText>
<listItem confidence="0.999202166666667">
1. All Restaurants model: trained using the com-
bined data of all three restaurant domains;
2. R+T+H model: trained on all dialogs related
to restaurants, hotels, pubs and coffee shops;
3. R+T+H+L model: the most general model,
trained using all the available dialog data.
</listItem>
<sectionHeader confidence="0.999693" genericHeader="evaluation">
6 Results
</sectionHeader>
<bodyText confidence="0.999993166666667">
As part of the evaluation, we use the three com-
binations of our dialog domains to build increas-
ingly general belief tracking models. The domain-
specific models trained using only data from each
of the six dialog domains provide the baseline per-
formance for the three general models.
</bodyText>
<subsectionHeader confidence="0.99792">
6.1 Training General Models
</subsectionHeader>
<bodyText confidence="0.999946888888889">
Training the shared RNN models is the first step of
the training procedure. Table 2 shows the perfor-
mance of shared models trained using dialogs from
the six individual and the three combined domains.
The joint accuracies are not comparable between
the domains as each of them contains a different
number of slots. The geometric mean of the six ac-
curacies is calculated to determine how well these
models operate across different dialog domains.
</bodyText>
<page confidence="0.996713">
796
</page>
<table confidence="0.9988653">
Model / Domain Cam Rest SF Rest Mich Rest Tourist SF Hotels Laptops Geo. Mean
Cambridge Restaurants 75.0 26.2 33.1 48.7 5.5 54.1 31.3
San Francisco Restaurants 66.8 51.6 31.5 38.2 17.5 47.4 38.8
Michigan Restaurants 57.9 22.3 64.2 32.6 10.2 45.4 32.8
All Restaurants 75.5 49.6 67.4 48.2 19.8 53.7 48.5
Tourist Information 71.7 27.1 31.5 62.9 10.1 55.7 36.0
San Francisco Hotels 26.2 28.7 27.1 27.9 57.1 25.3 30.6
Rest ∪ Tourist ∪ Hotels (R+T+H) 76.8 51.2 68.7 65.0 58.8 48.1 60.7
Laptops 66.9 26.1 32.0 46.2 4.6 74.7 31.0
All Domains (R+T+H+L) 76.8 50.8 64.4 63.6 57.8 76.7 64.3
</table>
<tableCaption confidence="0.999326">
Table 2: Goal accuracy of shared models trained using different dialog domains (ensembles of 12 models)
</tableCaption>
<bodyText confidence="0.999665833333333">
The parameters of the three multi-domain mod-
els are not slot or even domain specific. Nonethe-
less, all of them improve over the domain-specific
model for all but one of their constituent domains.
The R+T+H model outperforms the R+T+H+L
model across four domains, showing that the use
of laptops-related dialogs decreases performance
slightly across other more closely related domains.
However, the latter model is much better at balanc-
ing its performance across all six domains, achiev-
ing the highest geometric mean and still improving
over all but one of the domain-specific models.
</bodyText>
<subsectionHeader confidence="0.999703">
6.2 Slot-specialising the General Models
</subsectionHeader>
<bodyText confidence="0.999490615384615">
Slot specialising the shared model allows the train-
ing procedure to learn the relative importance of
different delexicalised features for each slot in a
given domain. Table 3 shows the effect of slot-
specialising shared models across the six dialog
domains. Moving down in these tables corresponds
to adding more out-of-domain training data and
moving right corresponds to slot-specialising the
shared model for each slot in the current domain.
Slot-specialisation improved performance in the
vast majority of the experiments. All three slot-
specialised general models outperformed the RNN
model’s performance reported in DSTC 2.
</bodyText>
<subsectionHeader confidence="0.99985">
6.3 Out of Domain Initialisation
</subsectionHeader>
<bodyText confidence="0.99974848">
The hierarchical training procedure can exploit the
available out-of-domain dialogs to initialise im-
proved shared models for new dialog domains.
In our experiments, we choose one of the do-
mains to act as the new domain, and we use a subset
of the remaining ones as out-of-domain data. The
number of in-domain dialogs available for train-
ing is increased at each stage of the experiment
and used to train and compare the performance of
two slot-specialised models. These models slot-
specialise from two different shared models. One
is trained using in-domain data only, and the other
is trained on all the out-of-domain data as well.
The two experiments vary in the degree of sim-
ilarity between the in-domain and out-of-domain
dialogs. In the first experiment, Michigan Restau-
rants act as the new domain and the remaining
R+T+H dialogs are used as out-of-domain data. In
the second experiment, Laptops dialogs are the in-
domain data and the remaining dialog domains are
used to initialise the more general shared model.
Figure 1 shows how the performance of the
two differently initialised models improves as ad-
ditional in-domain dialogs are introduced. In both
experiments, the use of out-of-domain data helps to
</bodyText>
<table confidence="0.997868272727273">
Model Cambridge Restaurants SF Restaurants Michigan Restaurants
Shared Model Slot-specialised Shared Model Slot-specialised Shared Model Slot-specialised
Domain Specific 75.0 75.4 51.6 56.5 64.2 65.6
All Restaurants 75.5 77.3 49.6 53.6 67.4 65.9
R+T+H 76.8 77.4 51.2 54.6 68.7 65.8
R+T+H+L 76.8 77.0 50.8 54.1 64.4 66.9
Tourist Information SF Hotels Laptops
Shared Model Slot-specialised Shared Model Slot-specialised Shared Model Slot-specialised
Domain Specific 62.9 65.1 57.1 57.4 74.7 78.4
R+T+H 65.0 67.1 58.8 60.7 - -
R+T+H+L 63.6 65.5 57.8 61.6 76.7 78.9
</table>
<tableCaption confidence="0.999741">
Table 3: Impact of slot specialisation on performance across the six domains (ensembles of 12 models)
</tableCaption>
<page confidence="0.96157">
797
</page>
<figure confidence="0.994782">
80
60
40
50
0 200 400 600 800
0 200 400 600 800
In-domain Initialisation
Out-of-domain Initialisation
In-domain Initialisation
Out-of-domain Initialisation
65
60
55
</figure>
<figureCaption confidence="0.9873825">
Figure 1: Joint goal accuracy on Michigan Restaurants (left) and the Laptops domain (right) as a function
of the number of in-domain training dialogs available to the training procedure (ensembles of four models)
</figureCaption>
<bodyText confidence="0.99990797368421">
initialise the model to a much better starting point
when the in-domain training data set is small. The
out-of-domain initialisation consistently improves
performance: the joint goal accuracy is improved
even when the entire in-domain dataset becomes
available to the training procedure.
These results are not surprising in the case of
the system trained to talk about Michigan Restau-
rants. Dialog systems trained to help users find
restaurants or hotels should have no trouble find-
ing restaurants in alternative geographies. In line
with these expectations, the use of a shared model
initialised using R+T+H dialogs results in a model
with strong starting performance. As additional
restaurants dialogs are revealed to the training pro-
cedure, this model shows relatively minor perfor-
mance gains over the domain-specific one.
The results of the Laptops experiment are even
more compelling, as the difference in performance
between the differently initialised models becomes
larger and more consistent. There are two factors at
play here: exposing the training procedure to sub-
stantially different out-of-domain dialogs allows
it to learn delexicalised features not present in the
in-domain training data. These features are appli-
cable to the Laptops domain, as evidenced by the
very strong starting performance. As additional
in-domain dialogs are introduced, the delexicalised
features not present in the out-of-domain data are
learned as well, leading to consistent improvements
in belief tracking performance.
In the context of these results, it is clear that
the out-of-domain training data has the potential to
be even more beneficial to tracking performance
than data from relatively similar domains. This is
especially the case when the available in-domain
training datasets are too small to allow the proce-
dure to learn appropriate delexicalised features.
</bodyText>
<sectionHeader confidence="0.998377" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999987714285714">
We have shown that it is possible to train general be-
lief tracking models capable of talking about many
different topics at once. The most general model
exhibits robust performance across all domains,
outperforming most domain-specific models. This
shows that training using diverse dialog domains
allows the model to better capture general dialog
dynamics applicable to different domains at once.
The proposed hierarchical training procedure
can also be used to adapt the general model to new
dialog domains, with very small in-domain data
sets required for adaptation. This procedure im-
proves tracking performance even when substantial
amounts of in-domain data become available.
</bodyText>
<subsectionHeader confidence="0.718613">
7.1 Further Work
</subsectionHeader>
<bodyText confidence="0.999835666666667">
The suggested domain adaptation procedure re-
quires a small collection of annotated in-domain
dialogs to adapt the general model to a new domain.
In our future work, we intend to focus on initialis-
ing good belief tracking models when no annotated
dialogs are available for the new dialog domain.
</bodyText>
<sectionHeader confidence="0.998888" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99329575">
John Blitzer, Mark Dredze, and Fernando Pereira.
2007. Biographies, Bollywood, boom-boxes and
blenders: Domain adaptation for sentiment classifi-
cation. In Proceedings of ACL.
</reference>
<page confidence="0.989836">
798
</page>
<reference confidence="0.980818333333333">
Milica Gaˇsi´c, Dongho Kim, Pirros Tsiakoulis, Cather-
ine Breslin, Matthew Henderson, Martin Szummer,
Blaise Thomson, and Steve Young. 2014. Incremen-
tal on-line adaptation of POMDP-based dialogue
managers to extended domains. In Proceedings of
INTERSPEECH.
Xavier Glorot, Antoine Bordes, and Yoshua Bengio.
2011. Domain adaptation for large-scale sentiment
classification: A deep learning approach. In Pro-
ceedings of ICML.
D. Goddeau, H. Meng, J. Polifroni, S. Seneff, and
S. Busayapongchai. 1996. A form-based dialogue
manager for spoken language applications. In Pro-
ceedings of ICSLP.
Alex Graves. 2012. Supervised Sequence Labelling
with Recurrent Neural Networks. Springer, Berlin.
Matthew Henderson, Blaise Thomson, and Steve
Young. 2013. Deep neural network approach for the
Dialog State Tracking Challenge. In Proceedings of
SIGDIAL.
Matthew Henderson, Blaise Thomson, and Jason D.
Wiliams. 2014a. The Second Dialog State Tracking
Challenge. In Proceedings of SIGDIAL.
Matthew Henderson, Blaise Thomson, and Jason D.
Wiliams. 2014b. The Third Dialog State Tracking
Challenge. In Proceedings of IEEE SLT.
Matthew Henderson, Blaise Thomson, and Steve
Young. 2014c. Robust dialog state tracking using
delexicalised recurrent neural networks and unsuper-
vised adaptation. In Proceedings of IEEE SLT.
Matthew Henderson, Blaise Thomson, and Steve
Young. 2014d. Word-based dialog state tracking
with recurrent neural networks. In Proceedings of
SIGDIAL.
Sungjin Lee and Maxine Eskenazi. 2013. Recipe for
building robust spoken dialog state trackers: Dia-
log State Tracking Challenge system description. In
Proceedings of SIGDIAL.
Sungjin Lee. 2013. Structured discriminative model
for dialog state tracking. In Proceedings of SIG-
DIAL.
Anna Margolis, Karen Livescu, and Mari Ostendorf.
2010. Domain adaptation with unlabeled data for
dialog act tagging. In Proceedings of the ACL Work-
shop on Domain Adaptation.
David McClosky, Eugene Charniak, and Mark Johnson.
2006. Effective self-training for parsing. In Pro-
ceedings of HLT-NAACL.
David McClosky, Eugene Charniak, and Mark Johnson.
2010. Automatic domain adaptation for parsing. In
Proceedings of NAACL HLT.
Hang Ren, Weiqun Xu, Yan Zhang, and Yonghong Yan.
2013. Dialog state tracking using conditional ran-
dom fields. In Proceedings of SIGDIAL.
Gokhan Tur, Umit Guz, and Dilek Hakkani-T¨ur. 2007.
Model adaptation for dialog act tagging. In Proceed-
ings of IEEE SLT.
Marilyn Walker, Amanda Stent, Franc¸ois Mairesse, and
Rashmi Prasad. 2007. Individual and domain adap-
tation in sentence planning for dialogue. Journal of
Artificial Intelligence Research, 30:413–456.
Zhuoran Wang and Oliver Lemon. 2013. A simple
and generic belief tracking mechanism for the Dia-
log State Tracking Challenge: On the believability
of observed information. In Proceedings of SIG-
DIAL.
Jason D. Williams, Antoine Raux, Deepak Ramachan-
dran, and Alan W. Black. 2013. The Dialogue State
Tracking Challenge. In Proceedings of SIGDIAL.
Jason D. Williams. 2013. Multi-domain learning and
generalization in dialog state tracking. In Proceed-
ings of SIGDIAL.
Jason D. Williams. 2014. Web-style ranking and slu
combination for dialog state tracking. In Proceed-
ings of SIGDIAL.
</reference>
<page confidence="0.998655">
799
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.979594">
<title confidence="0.997025">Multi-domain Dialog State Tracking using Recurrent Neural Networks Diarmuid O´Blaise Milica</title>
<author confidence="0.999003">David Tsung-Hsien</author>
<author confidence="0.999003">Steve</author>
<affiliation confidence="0.999973">1Department of Engineering, University of Cambridge,</affiliation>
<address confidence="0.99789">2VocalIQ Ltd. , Cambridge, UK</address>
<abstract confidence="0.999309882352941">Dialog state tracking is a key component of many modern dialog systems, most of which are designed with a single, welldefined domain in mind. This paper shows that dialog data drawn from different dialog domains can be used to train a general belief tracking model which can operate across all of these domains, exhibiting superior performance to each of the domainspecific models. We propose a training procedure which uses out-of-domain data to initialise belief tracking models for entirely new domains. This procedure leads to improvements in belief tracking performance regardless of the amount of in-domain data available for training the model.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>John Blitzer</author>
<author>Mark Dredze</author>
<author>Fernando Pereira</author>
</authors>
<title>Biographies, Bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="5006" citStr="Blitzer et al., 2007" startWordPosition="750" endWordPosition="753">ks. This approach maps directly from the ASR (automatic speech recognition) output to the belief state update, avoiding the use of complex semantic decoders while still attaining state-of-the-art performance. We adopt this RNN framework as the starting point for the work described here. It is well-known in machine learning that a system trained on data from one domain may not perform as well when deployed in a different domain. Researchers have investigated methods for mitigating this problem, with NLP applications in parsing (McClosky et al., 2006; McClosky et al., 2010), sentiment analysis (Blitzer et al., 2007; Glorot et al., 2011) and many other tasks. There has been a small amount of previous work on domain adaptation for dialog systems. Tur et al. (2007) and Margolis et al. (2010) investigated domain adaptation for dialog act tagging. Walker et al. (2007) trained a sentence planner/generator that adapts to different individuals and domains. In the third DSTC shared task (Henderson et al., 2014b), participants deployed belief trackers trained on a restaurant domain in an expanded version of the same domain, with a richer output space but essentially the same topic. To the best of our knowledge, o</context>
</contexts>
<marker>Blitzer, Dredze, Pereira, 2007</marker>
<rawString>John Blitzer, Mark Dredze, and Fernando Pereira. 2007. Biographies, Bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Milica Gaˇsi´c</author>
<author>Dongho Kim</author>
<author>Pirros Tsiakoulis</author>
<author>Catherine Breslin</author>
<author>Matthew Henderson</author>
<author>Martin Szummer</author>
<author>Blaise Thomson</author>
<author>Steve Young</author>
</authors>
<title>Incremental on-line adaptation of POMDP-based dialogue managers to extended domains.</title>
<date>2014</date>
<booktitle>In Proceedings of INTERSPEECH.</booktitle>
<marker>Gaˇsi´c, Kim, Tsiakoulis, Breslin, Henderson, Szummer, Thomson, Young, 2014</marker>
<rawString>Milica Gaˇsi´c, Dongho Kim, Pirros Tsiakoulis, Catherine Breslin, Matthew Henderson, Martin Szummer, Blaise Thomson, and Steve Young. 2014. Incremental on-line adaptation of POMDP-based dialogue managers to extended domains. In Proceedings of INTERSPEECH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Glorot</author>
<author>Antoine Bordes</author>
<author>Yoshua Bengio</author>
</authors>
<title>Domain adaptation for large-scale sentiment classification: A deep learning approach.</title>
<date>2011</date>
<booktitle>In Proceedings of ICML.</booktitle>
<contexts>
<context position="5028" citStr="Glorot et al., 2011" startWordPosition="754" endWordPosition="757"> directly from the ASR (automatic speech recognition) output to the belief state update, avoiding the use of complex semantic decoders while still attaining state-of-the-art performance. We adopt this RNN framework as the starting point for the work described here. It is well-known in machine learning that a system trained on data from one domain may not perform as well when deployed in a different domain. Researchers have investigated methods for mitigating this problem, with NLP applications in parsing (McClosky et al., 2006; McClosky et al., 2010), sentiment analysis (Blitzer et al., 2007; Glorot et al., 2011) and many other tasks. There has been a small amount of previous work on domain adaptation for dialog systems. Tur et al. (2007) and Margolis et al. (2010) investigated domain adaptation for dialog act tagging. Walker et al. (2007) trained a sentence planner/generator that adapts to different individuals and domains. In the third DSTC shared task (Henderson et al., 2014b), participants deployed belief trackers trained on a restaurant domain in an expanded version of the same domain, with a richer output space but essentially the same topic. To the best of our knowledge, our work is the first a</context>
</contexts>
<marker>Glorot, Bordes, Bengio, 2011</marker>
<rawString>Xavier Glorot, Antoine Bordes, and Yoshua Bengio. 2011. Domain adaptation for large-scale sentiment classification: A deep learning approach. In Proceedings of ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Goddeau</author>
<author>H Meng</author>
<author>J Polifroni</author>
<author>S Seneff</author>
<author>S Busayapongchai</author>
</authors>
<title>A form-based dialogue manager for spoken language applications.</title>
<date>1996</date>
<booktitle>In Proceedings of ICSLP.</booktitle>
<contexts>
<context position="3434" citStr="Goddeau et al. (1996)" startWordPosition="511" endWordPosition="514"> during the initial training stages. These models show robust performance across all the domains investigated, typically outperforming trackers trained on targetdomain data alone. The procedure can also be used to initialise dialog systems for entirely new domains. In the evaluation, we show that such initialisation always improves performance, regardless of the amount of the in-domain training data available. We believe that this work is the first to address the question of multi-domain belief tracking. 2 Related Work Traditional rule-based approaches to understanding in dialog systems (e.g. Goddeau et al. (1996)) have been superseded by data-driven systems that are more robust and can provide the probabilistic dialog state distributions that are needed by POMDPbased dialog managers. The recent Dialog State Tracking Challenge (DSTC) shared tasks (Williams et al., 2013; Henderson et al., 2014a; Henderson et al., 2014b) saw a variety of novel approaches, including robust sets of hand-crafted rules (Wang and Lemon, 2013), conditional random fields (Lee and Eskenazi, 2013; Lee, 2013; Ren et al., 2013), maximum entropy models (Williams, 2013) and web-style ranking (Williams, 2014). 794 Proceedings of the 5</context>
</contexts>
<marker>Goddeau, Meng, Polifroni, Seneff, Busayapongchai, 1996</marker>
<rawString>D. Goddeau, H. Meng, J. Polifroni, S. Seneff, and S. Busayapongchai. 1996. A form-based dialogue manager for spoken language applications. In Proceedings of ICSLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alex Graves</author>
</authors>
<title>Supervised Sequence Labelling with Recurrent Neural Networks.</title>
<date>2012</date>
<publisher>Springer,</publisher>
<location>Berlin.</location>
<contexts>
<context position="2040" citStr="Graves, 2012" startWordPosition="310" endWordPosition="311">k, we move towards this goal by showing how to build dialog state tracking models which can operate across entirely different domains. The state tracking component of a dialog system is responsible for interpreting the users’ utterances and thus updating the system’s belief state: a probability distribution over all possible states of the dialog. This belief state is used by the system to decide what to do next. Recurrent Neural Networks (RNNs) are well suited to dialog state tracking, as their ability to capture contextual information allows them to model and label complex dynamic sequences (Graves, 2012). In recent shared tasks, approaches based on these models have shown competitive performance (Henderson et al., 2014d; Henderson et al., 2014c). This approach is particularly well suited to our goal of building open-domain dialog systems, as it does not require handcrafted domain-specific resources for semantic interpretation. We propose a method for training multi-domain RNN dialog state tracking models. Our hierarchical training procedure first uses all the data available to train a very general belief tracking model. This model learns the most frequent and general dialog features present a</context>
<context position="8767" citStr="Graves, 2012" startWordPosition="1391" endWordPosition="1392"> The RNN memory layer is updated as well. The updates are as follows2: = ftl ® ft d ® mt−1 ® pt−1 v ® pt−1 ∅ ) + bs gt v = ws 1 &apos; Q (Ws 0xt v + bs 0 1 exp(gt v) pt v = exp(gt∅) + Ev,∈V exp(gtv,) mt = Q (Wsm0xt + Wsm1mt−1) where ® denotes vector concatenation and pt ∅ is the probability that the user has expressed no constraint up to turn t. Matrices Ws0, Ws m0, Wsm1 and the vector ws1 are the RNN weights, and b0 and b1 are the hidden and output layer RNN bias terms. For training, the model is unrolled across turns and trained using backpropagation through time and stochastic gradient descent (Graves, 2012). 1Henderson et al.’s work distinguished between three types of features: the delexicalised feature sets f$ and f&amp;quot; are subsumed by our delexicalised feature vector fd, and the turn input f corresponds to our lexical feature vector fl. 2The original RNN architecture had a second component which learned mappings from lexical n-grams to specific slot values. In order to move towards domain-independence, we do not use this part of the network. xt v 795 4 Hierarchical Model Training Delexicalised features allow transfer learning between slots. We extend this approach to achieve transfer learning be</context>
</contexts>
<marker>Graves, 2012</marker>
<rawString>Alex Graves. 2012. Supervised Sequence Labelling with Recurrent Neural Networks. Springer, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Henderson</author>
<author>Blaise Thomson</author>
<author>Steve Young</author>
</authors>
<title>Deep neural network approach for the Dialog State Tracking Challenge.</title>
<date>2013</date>
<booktitle>In Proceedings of SIGDIAL.</booktitle>
<contexts>
<context position="4312" citStr="Henderson et al. (2013" startWordPosition="639" endWordPosition="642">2013; Henderson et al., 2014a; Henderson et al., 2014b) saw a variety of novel approaches, including robust sets of hand-crafted rules (Wang and Lemon, 2013), conditional random fields (Lee and Eskenazi, 2013; Lee, 2013; Ren et al., 2013), maximum entropy models (Williams, 2013) and web-style ranking (Williams, 2014). 794 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 794–799, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics Henderson et al. (2013; 2014d; 2014c) proposed a belief tracker based on recurrent neural networks. This approach maps directly from the ASR (automatic speech recognition) output to the belief state update, avoiding the use of complex semantic decoders while still attaining state-of-the-art performance. We adopt this RNN framework as the starting point for the work described here. It is well-known in machine learning that a system trained on data from one domain may not perform as well when deployed in a different domain. Researchers have investigated methods for mitigating this problem, with NLP applications in pa</context>
</contexts>
<marker>Henderson, Thomson, Young, 2013</marker>
<rawString>Matthew Henderson, Blaise Thomson, and Steve Young. 2013. Deep neural network approach for the Dialog State Tracking Challenge. In Proceedings of SIGDIAL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Henderson</author>
<author>Blaise Thomson</author>
<author>Jason D Wiliams</author>
</authors>
<title>The Second Dialog State Tracking Challenge.</title>
<date>2014</date>
<booktitle>In Proceedings of SIGDIAL.</booktitle>
<contexts>
<context position="2157" citStr="Henderson et al., 2014" startWordPosition="325" endWordPosition="328">ntirely different domains. The state tracking component of a dialog system is responsible for interpreting the users’ utterances and thus updating the system’s belief state: a probability distribution over all possible states of the dialog. This belief state is used by the system to decide what to do next. Recurrent Neural Networks (RNNs) are well suited to dialog state tracking, as their ability to capture contextual information allows them to model and label complex dynamic sequences (Graves, 2012). In recent shared tasks, approaches based on these models have shown competitive performance (Henderson et al., 2014d; Henderson et al., 2014c). This approach is particularly well suited to our goal of building open-domain dialog systems, as it does not require handcrafted domain-specific resources for semantic interpretation. We propose a method for training multi-domain RNN dialog state tracking models. Our hierarchical training procedure first uses all the data available to train a very general belief tracking model. This model learns the most frequent and general dialog features present across the various domains. The general model is then specialised for each domain, learning domain-specific behaviour </context>
<context position="3718" citStr="Henderson et al., 2014" startWordPosition="555" endWordPosition="558">, we show that such initialisation always improves performance, regardless of the amount of the in-domain training data available. We believe that this work is the first to address the question of multi-domain belief tracking. 2 Related Work Traditional rule-based approaches to understanding in dialog systems (e.g. Goddeau et al. (1996)) have been superseded by data-driven systems that are more robust and can provide the probabilistic dialog state distributions that are needed by POMDPbased dialog managers. The recent Dialog State Tracking Challenge (DSTC) shared tasks (Williams et al., 2013; Henderson et al., 2014a; Henderson et al., 2014b) saw a variety of novel approaches, including robust sets of hand-crafted rules (Wang and Lemon, 2013), conditional random fields (Lee and Eskenazi, 2013; Lee, 2013; Ren et al., 2013), maximum entropy models (Williams, 2013) and web-style ranking (Williams, 2014). 794 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 794–799, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics Henderson et al. (2013; 2014</context>
<context position="5400" citStr="Henderson et al., 2014" startWordPosition="817" endWordPosition="820">ll when deployed in a different domain. Researchers have investigated methods for mitigating this problem, with NLP applications in parsing (McClosky et al., 2006; McClosky et al., 2010), sentiment analysis (Blitzer et al., 2007; Glorot et al., 2011) and many other tasks. There has been a small amount of previous work on domain adaptation for dialog systems. Tur et al. (2007) and Margolis et al. (2010) investigated domain adaptation for dialog act tagging. Walker et al. (2007) trained a sentence planner/generator that adapts to different individuals and domains. In the third DSTC shared task (Henderson et al., 2014b), participants deployed belief trackers trained on a restaurant domain in an expanded version of the same domain, with a richer output space but essentially the same topic. To the best of our knowledge, our work is the first attempt to build a belief tracker capable of operating across disjoint dialog domains. 3 Dialog State Tracking using RNNs Belief tracking models capture users’ goals given their utterances. Goals are represented as sets of constraints expressed by slot-value mappings such as [food: chinese] or [wifi: available]. The set of slots S and the set of values Vs for each slot m</context>
</contexts>
<marker>Henderson, Thomson, Wiliams, 2014</marker>
<rawString>Matthew Henderson, Blaise Thomson, and Jason D. Wiliams. 2014a. The Second Dialog State Tracking Challenge. In Proceedings of SIGDIAL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Henderson</author>
<author>Blaise Thomson</author>
<author>Jason D Wiliams</author>
</authors>
<title>The Third Dialog State Tracking Challenge.</title>
<date>2014</date>
<booktitle>In Proceedings of IEEE SLT.</booktitle>
<contexts>
<context position="2157" citStr="Henderson et al., 2014" startWordPosition="325" endWordPosition="328">ntirely different domains. The state tracking component of a dialog system is responsible for interpreting the users’ utterances and thus updating the system’s belief state: a probability distribution over all possible states of the dialog. This belief state is used by the system to decide what to do next. Recurrent Neural Networks (RNNs) are well suited to dialog state tracking, as their ability to capture contextual information allows them to model and label complex dynamic sequences (Graves, 2012). In recent shared tasks, approaches based on these models have shown competitive performance (Henderson et al., 2014d; Henderson et al., 2014c). This approach is particularly well suited to our goal of building open-domain dialog systems, as it does not require handcrafted domain-specific resources for semantic interpretation. We propose a method for training multi-domain RNN dialog state tracking models. Our hierarchical training procedure first uses all the data available to train a very general belief tracking model. This model learns the most frequent and general dialog features present across the various domains. The general model is then specialised for each domain, learning domain-specific behaviour </context>
<context position="3718" citStr="Henderson et al., 2014" startWordPosition="555" endWordPosition="558">, we show that such initialisation always improves performance, regardless of the amount of the in-domain training data available. We believe that this work is the first to address the question of multi-domain belief tracking. 2 Related Work Traditional rule-based approaches to understanding in dialog systems (e.g. Goddeau et al. (1996)) have been superseded by data-driven systems that are more robust and can provide the probabilistic dialog state distributions that are needed by POMDPbased dialog managers. The recent Dialog State Tracking Challenge (DSTC) shared tasks (Williams et al., 2013; Henderson et al., 2014a; Henderson et al., 2014b) saw a variety of novel approaches, including robust sets of hand-crafted rules (Wang and Lemon, 2013), conditional random fields (Lee and Eskenazi, 2013; Lee, 2013; Ren et al., 2013), maximum entropy models (Williams, 2013) and web-style ranking (Williams, 2014). 794 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 794–799, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics Henderson et al. (2013; 2014</context>
<context position="5400" citStr="Henderson et al., 2014" startWordPosition="817" endWordPosition="820">ll when deployed in a different domain. Researchers have investigated methods for mitigating this problem, with NLP applications in parsing (McClosky et al., 2006; McClosky et al., 2010), sentiment analysis (Blitzer et al., 2007; Glorot et al., 2011) and many other tasks. There has been a small amount of previous work on domain adaptation for dialog systems. Tur et al. (2007) and Margolis et al. (2010) investigated domain adaptation for dialog act tagging. Walker et al. (2007) trained a sentence planner/generator that adapts to different individuals and domains. In the third DSTC shared task (Henderson et al., 2014b), participants deployed belief trackers trained on a restaurant domain in an expanded version of the same domain, with a richer output space but essentially the same topic. To the best of our knowledge, our work is the first attempt to build a belief tracker capable of operating across disjoint dialog domains. 3 Dialog State Tracking using RNNs Belief tracking models capture users’ goals given their utterances. Goals are represented as sets of constraints expressed by slot-value mappings such as [food: chinese] or [wifi: available]. The set of slots S and the set of values Vs for each slot m</context>
</contexts>
<marker>Henderson, Thomson, Wiliams, 2014</marker>
<rawString>Matthew Henderson, Blaise Thomson, and Jason D. Wiliams. 2014b. The Third Dialog State Tracking Challenge. In Proceedings of IEEE SLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Henderson</author>
<author>Blaise Thomson</author>
<author>Steve Young</author>
</authors>
<title>Robust dialog state tracking using delexicalised recurrent neural networks and unsupervised adaptation.</title>
<date>2014</date>
<booktitle>In Proceedings of IEEE SLT.</booktitle>
<contexts>
<context position="2157" citStr="Henderson et al., 2014" startWordPosition="325" endWordPosition="328">ntirely different domains. The state tracking component of a dialog system is responsible for interpreting the users’ utterances and thus updating the system’s belief state: a probability distribution over all possible states of the dialog. This belief state is used by the system to decide what to do next. Recurrent Neural Networks (RNNs) are well suited to dialog state tracking, as their ability to capture contextual information allows them to model and label complex dynamic sequences (Graves, 2012). In recent shared tasks, approaches based on these models have shown competitive performance (Henderson et al., 2014d; Henderson et al., 2014c). This approach is particularly well suited to our goal of building open-domain dialog systems, as it does not require handcrafted domain-specific resources for semantic interpretation. We propose a method for training multi-domain RNN dialog state tracking models. Our hierarchical training procedure first uses all the data available to train a very general belief tracking model. This model learns the most frequent and general dialog features present across the various domains. The general model is then specialised for each domain, learning domain-specific behaviour </context>
<context position="3718" citStr="Henderson et al., 2014" startWordPosition="555" endWordPosition="558">, we show that such initialisation always improves performance, regardless of the amount of the in-domain training data available. We believe that this work is the first to address the question of multi-domain belief tracking. 2 Related Work Traditional rule-based approaches to understanding in dialog systems (e.g. Goddeau et al. (1996)) have been superseded by data-driven systems that are more robust and can provide the probabilistic dialog state distributions that are needed by POMDPbased dialog managers. The recent Dialog State Tracking Challenge (DSTC) shared tasks (Williams et al., 2013; Henderson et al., 2014a; Henderson et al., 2014b) saw a variety of novel approaches, including robust sets of hand-crafted rules (Wang and Lemon, 2013), conditional random fields (Lee and Eskenazi, 2013; Lee, 2013; Ren et al., 2013), maximum entropy models (Williams, 2013) and web-style ranking (Williams, 2014). 794 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 794–799, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics Henderson et al. (2013; 2014</context>
<context position="5400" citStr="Henderson et al., 2014" startWordPosition="817" endWordPosition="820">ll when deployed in a different domain. Researchers have investigated methods for mitigating this problem, with NLP applications in parsing (McClosky et al., 2006; McClosky et al., 2010), sentiment analysis (Blitzer et al., 2007; Glorot et al., 2011) and many other tasks. There has been a small amount of previous work on domain adaptation for dialog systems. Tur et al. (2007) and Margolis et al. (2010) investigated domain adaptation for dialog act tagging. Walker et al. (2007) trained a sentence planner/generator that adapts to different individuals and domains. In the third DSTC shared task (Henderson et al., 2014b), participants deployed belief trackers trained on a restaurant domain in an expanded version of the same domain, with a richer output space but essentially the same topic. To the best of our knowledge, our work is the first attempt to build a belief tracker capable of operating across disjoint dialog domains. 3 Dialog State Tracking using RNNs Belief tracking models capture users’ goals given their utterances. Goals are represented as sets of constraints expressed by slot-value mappings such as [food: chinese] or [wifi: available]. The set of slots S and the set of values Vs for each slot m</context>
</contexts>
<marker>Henderson, Thomson, Young, 2014</marker>
<rawString>Matthew Henderson, Blaise Thomson, and Steve Young. 2014c. Robust dialog state tracking using delexicalised recurrent neural networks and unsupervised adaptation. In Proceedings of IEEE SLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Henderson</author>
<author>Blaise Thomson</author>
<author>Steve Young</author>
</authors>
<title>Word-based dialog state tracking with recurrent neural networks.</title>
<date>2014</date>
<booktitle>In Proceedings of SIGDIAL.</booktitle>
<contexts>
<context position="2157" citStr="Henderson et al., 2014" startWordPosition="325" endWordPosition="328">ntirely different domains. The state tracking component of a dialog system is responsible for interpreting the users’ utterances and thus updating the system’s belief state: a probability distribution over all possible states of the dialog. This belief state is used by the system to decide what to do next. Recurrent Neural Networks (RNNs) are well suited to dialog state tracking, as their ability to capture contextual information allows them to model and label complex dynamic sequences (Graves, 2012). In recent shared tasks, approaches based on these models have shown competitive performance (Henderson et al., 2014d; Henderson et al., 2014c). This approach is particularly well suited to our goal of building open-domain dialog systems, as it does not require handcrafted domain-specific resources for semantic interpretation. We propose a method for training multi-domain RNN dialog state tracking models. Our hierarchical training procedure first uses all the data available to train a very general belief tracking model. This model learns the most frequent and general dialog features present across the various domains. The general model is then specialised for each domain, learning domain-specific behaviour </context>
<context position="3718" citStr="Henderson et al., 2014" startWordPosition="555" endWordPosition="558">, we show that such initialisation always improves performance, regardless of the amount of the in-domain training data available. We believe that this work is the first to address the question of multi-domain belief tracking. 2 Related Work Traditional rule-based approaches to understanding in dialog systems (e.g. Goddeau et al. (1996)) have been superseded by data-driven systems that are more robust and can provide the probabilistic dialog state distributions that are needed by POMDPbased dialog managers. The recent Dialog State Tracking Challenge (DSTC) shared tasks (Williams et al., 2013; Henderson et al., 2014a; Henderson et al., 2014b) saw a variety of novel approaches, including robust sets of hand-crafted rules (Wang and Lemon, 2013), conditional random fields (Lee and Eskenazi, 2013; Lee, 2013; Ren et al., 2013), maximum entropy models (Williams, 2013) and web-style ranking (Williams, 2014). 794 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 794–799, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics Henderson et al. (2013; 2014</context>
<context position="5400" citStr="Henderson et al., 2014" startWordPosition="817" endWordPosition="820">ll when deployed in a different domain. Researchers have investigated methods for mitigating this problem, with NLP applications in parsing (McClosky et al., 2006; McClosky et al., 2010), sentiment analysis (Blitzer et al., 2007; Glorot et al., 2011) and many other tasks. There has been a small amount of previous work on domain adaptation for dialog systems. Tur et al. (2007) and Margolis et al. (2010) investigated domain adaptation for dialog act tagging. Walker et al. (2007) trained a sentence planner/generator that adapts to different individuals and domains. In the third DSTC shared task (Henderson et al., 2014b), participants deployed belief trackers trained on a restaurant domain in an expanded version of the same domain, with a richer output space but essentially the same topic. To the best of our knowledge, our work is the first attempt to build a belief tracker capable of operating across disjoint dialog domains. 3 Dialog State Tracking using RNNs Belief tracking models capture users’ goals given their utterances. Goals are represented as sets of constraints expressed by slot-value mappings such as [food: chinese] or [wifi: available]. The set of slots S and the set of values Vs for each slot m</context>
</contexts>
<marker>Henderson, Thomson, Young, 2014</marker>
<rawString>Matthew Henderson, Blaise Thomson, and Steve Young. 2014d. Word-based dialog state tracking with recurrent neural networks. In Proceedings of SIGDIAL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sungjin Lee</author>
<author>Maxine Eskenazi</author>
</authors>
<title>Recipe for building robust spoken dialog state trackers: Dialog State Tracking Challenge system description.</title>
<date>2013</date>
<booktitle>In Proceedings of SIGDIAL.</booktitle>
<contexts>
<context position="3898" citStr="Lee and Eskenazi, 2013" startWordPosition="582" endWordPosition="585"> the question of multi-domain belief tracking. 2 Related Work Traditional rule-based approaches to understanding in dialog systems (e.g. Goddeau et al. (1996)) have been superseded by data-driven systems that are more robust and can provide the probabilistic dialog state distributions that are needed by POMDPbased dialog managers. The recent Dialog State Tracking Challenge (DSTC) shared tasks (Williams et al., 2013; Henderson et al., 2014a; Henderson et al., 2014b) saw a variety of novel approaches, including robust sets of hand-crafted rules (Wang and Lemon, 2013), conditional random fields (Lee and Eskenazi, 2013; Lee, 2013; Ren et al., 2013), maximum entropy models (Williams, 2013) and web-style ranking (Williams, 2014). 794 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 794–799, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics Henderson et al. (2013; 2014d; 2014c) proposed a belief tracker based on recurrent neural networks. This approach maps directly from the ASR (automatic speech recognition) output to the belief state update, a</context>
</contexts>
<marker>Lee, Eskenazi, 2013</marker>
<rawString>Sungjin Lee and Maxine Eskenazi. 2013. Recipe for building robust spoken dialog state trackers: Dialog State Tracking Challenge system description. In Proceedings of SIGDIAL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sungjin Lee</author>
</authors>
<title>Structured discriminative model for dialog state tracking.</title>
<date>2013</date>
<booktitle>In Proceedings of SIGDIAL.</booktitle>
<contexts>
<context position="3909" citStr="Lee, 2013" startWordPosition="586" endWordPosition="587">omain belief tracking. 2 Related Work Traditional rule-based approaches to understanding in dialog systems (e.g. Goddeau et al. (1996)) have been superseded by data-driven systems that are more robust and can provide the probabilistic dialog state distributions that are needed by POMDPbased dialog managers. The recent Dialog State Tracking Challenge (DSTC) shared tasks (Williams et al., 2013; Henderson et al., 2014a; Henderson et al., 2014b) saw a variety of novel approaches, including robust sets of hand-crafted rules (Wang and Lemon, 2013), conditional random fields (Lee and Eskenazi, 2013; Lee, 2013; Ren et al., 2013), maximum entropy models (Williams, 2013) and web-style ranking (Williams, 2014). 794 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 794–799, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics Henderson et al. (2013; 2014d; 2014c) proposed a belief tracker based on recurrent neural networks. This approach maps directly from the ASR (automatic speech recognition) output to the belief state update, avoiding the</context>
</contexts>
<marker>Lee, 2013</marker>
<rawString>Sungjin Lee. 2013. Structured discriminative model for dialog state tracking. In Proceedings of SIGDIAL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna Margolis</author>
<author>Karen Livescu</author>
<author>Mari Ostendorf</author>
</authors>
<title>Domain adaptation with unlabeled data for dialog act tagging.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL Workshop on Domain Adaptation.</booktitle>
<contexts>
<context position="5183" citStr="Margolis et al. (2010)" startWordPosition="783" endWordPosition="787">ing state-of-the-art performance. We adopt this RNN framework as the starting point for the work described here. It is well-known in machine learning that a system trained on data from one domain may not perform as well when deployed in a different domain. Researchers have investigated methods for mitigating this problem, with NLP applications in parsing (McClosky et al., 2006; McClosky et al., 2010), sentiment analysis (Blitzer et al., 2007; Glorot et al., 2011) and many other tasks. There has been a small amount of previous work on domain adaptation for dialog systems. Tur et al. (2007) and Margolis et al. (2010) investigated domain adaptation for dialog act tagging. Walker et al. (2007) trained a sentence planner/generator that adapts to different individuals and domains. In the third DSTC shared task (Henderson et al., 2014b), participants deployed belief trackers trained on a restaurant domain in an expanded version of the same domain, with a richer output space but essentially the same topic. To the best of our knowledge, our work is the first attempt to build a belief tracker capable of operating across disjoint dialog domains. 3 Dialog State Tracking using RNNs Belief tracking models capture use</context>
</contexts>
<marker>Margolis, Livescu, Ostendorf, 2010</marker>
<rawString>Anna Margolis, Karen Livescu, and Mari Ostendorf. 2010. Domain adaptation with unlabeled data for dialog act tagging. In Proceedings of the ACL Workshop on Domain Adaptation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David McClosky</author>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Effective self-training for parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of HLT-NAACL.</booktitle>
<contexts>
<context position="4940" citStr="McClosky et al., 2006" startWordPosition="740" endWordPosition="743">; 2014c) proposed a belief tracker based on recurrent neural networks. This approach maps directly from the ASR (automatic speech recognition) output to the belief state update, avoiding the use of complex semantic decoders while still attaining state-of-the-art performance. We adopt this RNN framework as the starting point for the work described here. It is well-known in machine learning that a system trained on data from one domain may not perform as well when deployed in a different domain. Researchers have investigated methods for mitigating this problem, with NLP applications in parsing (McClosky et al., 2006; McClosky et al., 2010), sentiment analysis (Blitzer et al., 2007; Glorot et al., 2011) and many other tasks. There has been a small amount of previous work on domain adaptation for dialog systems. Tur et al. (2007) and Margolis et al. (2010) investigated domain adaptation for dialog act tagging. Walker et al. (2007) trained a sentence planner/generator that adapts to different individuals and domains. In the third DSTC shared task (Henderson et al., 2014b), participants deployed belief trackers trained on a restaurant domain in an expanded version of the same domain, with a richer output spa</context>
</contexts>
<marker>McClosky, Charniak, Johnson, 2006</marker>
<rawString>David McClosky, Eugene Charniak, and Mark Johnson. 2006. Effective self-training for parsing. In Proceedings of HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David McClosky</author>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Automatic domain adaptation for parsing.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL HLT.</booktitle>
<contexts>
<context position="4964" citStr="McClosky et al., 2010" startWordPosition="744" endWordPosition="747">ief tracker based on recurrent neural networks. This approach maps directly from the ASR (automatic speech recognition) output to the belief state update, avoiding the use of complex semantic decoders while still attaining state-of-the-art performance. We adopt this RNN framework as the starting point for the work described here. It is well-known in machine learning that a system trained on data from one domain may not perform as well when deployed in a different domain. Researchers have investigated methods for mitigating this problem, with NLP applications in parsing (McClosky et al., 2006; McClosky et al., 2010), sentiment analysis (Blitzer et al., 2007; Glorot et al., 2011) and many other tasks. There has been a small amount of previous work on domain adaptation for dialog systems. Tur et al. (2007) and Margolis et al. (2010) investigated domain adaptation for dialog act tagging. Walker et al. (2007) trained a sentence planner/generator that adapts to different individuals and domains. In the third DSTC shared task (Henderson et al., 2014b), participants deployed belief trackers trained on a restaurant domain in an expanded version of the same domain, with a richer output space but essentially the s</context>
</contexts>
<marker>McClosky, Charniak, Johnson, 2010</marker>
<rawString>David McClosky, Eugene Charniak, and Mark Johnson. 2010. Automatic domain adaptation for parsing. In Proceedings of NAACL HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hang Ren</author>
<author>Weiqun Xu</author>
<author>Yan Zhang</author>
<author>Yonghong Yan</author>
</authors>
<title>Dialog state tracking using conditional random fields.</title>
<date>2013</date>
<booktitle>In Proceedings of SIGDIAL.</booktitle>
<contexts>
<context position="3928" citStr="Ren et al., 2013" startWordPosition="588" endWordPosition="591">f tracking. 2 Related Work Traditional rule-based approaches to understanding in dialog systems (e.g. Goddeau et al. (1996)) have been superseded by data-driven systems that are more robust and can provide the probabilistic dialog state distributions that are needed by POMDPbased dialog managers. The recent Dialog State Tracking Challenge (DSTC) shared tasks (Williams et al., 2013; Henderson et al., 2014a; Henderson et al., 2014b) saw a variety of novel approaches, including robust sets of hand-crafted rules (Wang and Lemon, 2013), conditional random fields (Lee and Eskenazi, 2013; Lee, 2013; Ren et al., 2013), maximum entropy models (Williams, 2013) and web-style ranking (Williams, 2014). 794 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 794–799, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics Henderson et al. (2013; 2014d; 2014c) proposed a belief tracker based on recurrent neural networks. This approach maps directly from the ASR (automatic speech recognition) output to the belief state update, avoiding the use of complex sem</context>
</contexts>
<marker>Ren, Xu, Zhang, Yan, 2013</marker>
<rawString>Hang Ren, Weiqun Xu, Yan Zhang, and Yonghong Yan. 2013. Dialog state tracking using conditional random fields. In Proceedings of SIGDIAL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gokhan Tur</author>
<author>Umit Guz</author>
<author>Dilek Hakkani-T¨ur</author>
</authors>
<title>Model adaptation for dialog act tagging.</title>
<date>2007</date>
<booktitle>In Proceedings of IEEE SLT.</booktitle>
<marker>Tur, Guz, Hakkani-T¨ur, 2007</marker>
<rawString>Gokhan Tur, Umit Guz, and Dilek Hakkani-T¨ur. 2007. Model adaptation for dialog act tagging. In Proceedings of IEEE SLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn Walker</author>
<author>Amanda Stent</author>
<author>Franc¸ois Mairesse</author>
<author>Rashmi Prasad</author>
</authors>
<title>Individual and domain adaptation in sentence planning for dialogue.</title>
<date>2007</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>30--413</pages>
<contexts>
<context position="5259" citStr="Walker et al. (2007)" startWordPosition="795" endWordPosition="798">point for the work described here. It is well-known in machine learning that a system trained on data from one domain may not perform as well when deployed in a different domain. Researchers have investigated methods for mitigating this problem, with NLP applications in parsing (McClosky et al., 2006; McClosky et al., 2010), sentiment analysis (Blitzer et al., 2007; Glorot et al., 2011) and many other tasks. There has been a small amount of previous work on domain adaptation for dialog systems. Tur et al. (2007) and Margolis et al. (2010) investigated domain adaptation for dialog act tagging. Walker et al. (2007) trained a sentence planner/generator that adapts to different individuals and domains. In the third DSTC shared task (Henderson et al., 2014b), participants deployed belief trackers trained on a restaurant domain in an expanded version of the same domain, with a richer output space but essentially the same topic. To the best of our knowledge, our work is the first attempt to build a belief tracker capable of operating across disjoint dialog domains. 3 Dialog State Tracking using RNNs Belief tracking models capture users’ goals given their utterances. Goals are represented as sets of constrain</context>
</contexts>
<marker>Walker, Stent, Mairesse, Prasad, 2007</marker>
<rawString>Marilyn Walker, Amanda Stent, Franc¸ois Mairesse, and Rashmi Prasad. 2007. Individual and domain adaptation in sentence planning for dialogue. Journal of Artificial Intelligence Research, 30:413–456.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhuoran Wang</author>
<author>Oliver Lemon</author>
</authors>
<title>A simple and generic belief tracking mechanism for the Dialog State Tracking Challenge: On the believability of observed information.</title>
<date>2013</date>
<booktitle>In Proceedings of SIGDIAL.</booktitle>
<contexts>
<context position="3847" citStr="Wang and Lemon, 2013" startWordPosition="575" endWordPosition="578"> We believe that this work is the first to address the question of multi-domain belief tracking. 2 Related Work Traditional rule-based approaches to understanding in dialog systems (e.g. Goddeau et al. (1996)) have been superseded by data-driven systems that are more robust and can provide the probabilistic dialog state distributions that are needed by POMDPbased dialog managers. The recent Dialog State Tracking Challenge (DSTC) shared tasks (Williams et al., 2013; Henderson et al., 2014a; Henderson et al., 2014b) saw a variety of novel approaches, including robust sets of hand-crafted rules (Wang and Lemon, 2013), conditional random fields (Lee and Eskenazi, 2013; Lee, 2013; Ren et al., 2013), maximum entropy models (Williams, 2013) and web-style ranking (Williams, 2014). 794 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 794–799, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics Henderson et al. (2013; 2014d; 2014c) proposed a belief tracker based on recurrent neural networks. This approach maps directly from the ASR (automatic speec</context>
</contexts>
<marker>Wang, Lemon, 2013</marker>
<rawString>Zhuoran Wang and Oliver Lemon. 2013. A simple and generic belief tracking mechanism for the Dialog State Tracking Challenge: On the believability of observed information. In Proceedings of SIGDIAL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason D Williams</author>
<author>Antoine Raux</author>
<author>Deepak Ramachandran</author>
<author>Alan W Black</author>
</authors>
<title>The Dialogue State Tracking Challenge.</title>
<date>2013</date>
<booktitle>In Proceedings of SIGDIAL.</booktitle>
<contexts>
<context position="3694" citStr="Williams et al., 2013" startWordPosition="551" endWordPosition="554">ains. In the evaluation, we show that such initialisation always improves performance, regardless of the amount of the in-domain training data available. We believe that this work is the first to address the question of multi-domain belief tracking. 2 Related Work Traditional rule-based approaches to understanding in dialog systems (e.g. Goddeau et al. (1996)) have been superseded by data-driven systems that are more robust and can provide the probabilistic dialog state distributions that are needed by POMDPbased dialog managers. The recent Dialog State Tracking Challenge (DSTC) shared tasks (Williams et al., 2013; Henderson et al., 2014a; Henderson et al., 2014b) saw a variety of novel approaches, including robust sets of hand-crafted rules (Wang and Lemon, 2013), conditional random fields (Lee and Eskenazi, 2013; Lee, 2013; Ren et al., 2013), maximum entropy models (Williams, 2013) and web-style ranking (Williams, 2014). 794 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 794–799, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics Hend</context>
</contexts>
<marker>Williams, Raux, Ramachandran, Black, 2013</marker>
<rawString>Jason D. Williams, Antoine Raux, Deepak Ramachandran, and Alan W. Black. 2013. The Dialogue State Tracking Challenge. In Proceedings of SIGDIAL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason D Williams</author>
</authors>
<title>Multi-domain learning and generalization in dialog state tracking.</title>
<date>2013</date>
<booktitle>In Proceedings of SIGDIAL.</booktitle>
<contexts>
<context position="3969" citStr="Williams, 2013" startWordPosition="595" endWordPosition="596">-based approaches to understanding in dialog systems (e.g. Goddeau et al. (1996)) have been superseded by data-driven systems that are more robust and can provide the probabilistic dialog state distributions that are needed by POMDPbased dialog managers. The recent Dialog State Tracking Challenge (DSTC) shared tasks (Williams et al., 2013; Henderson et al., 2014a; Henderson et al., 2014b) saw a variety of novel approaches, including robust sets of hand-crafted rules (Wang and Lemon, 2013), conditional random fields (Lee and Eskenazi, 2013; Lee, 2013; Ren et al., 2013), maximum entropy models (Williams, 2013) and web-style ranking (Williams, 2014). 794 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 794–799, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics Henderson et al. (2013; 2014d; 2014c) proposed a belief tracker based on recurrent neural networks. This approach maps directly from the ASR (automatic speech recognition) output to the belief state update, avoiding the use of complex semantic decoders while still attaining stat</context>
</contexts>
<marker>Williams, 2013</marker>
<rawString>Jason D. Williams. 2013. Multi-domain learning and generalization in dialog state tracking. In Proceedings of SIGDIAL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason D Williams</author>
</authors>
<title>Web-style ranking and slu combination for dialog state tracking.</title>
<date>2014</date>
<booktitle>In Proceedings of SIGDIAL.</booktitle>
<contexts>
<context position="4008" citStr="Williams, 2014" startWordPosition="600" endWordPosition="601">ialog systems (e.g. Goddeau et al. (1996)) have been superseded by data-driven systems that are more robust and can provide the probabilistic dialog state distributions that are needed by POMDPbased dialog managers. The recent Dialog State Tracking Challenge (DSTC) shared tasks (Williams et al., 2013; Henderson et al., 2014a; Henderson et al., 2014b) saw a variety of novel approaches, including robust sets of hand-crafted rules (Wang and Lemon, 2013), conditional random fields (Lee and Eskenazi, 2013; Lee, 2013; Ren et al., 2013), maximum entropy models (Williams, 2013) and web-style ranking (Williams, 2014). 794 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 794–799, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics Henderson et al. (2013; 2014d; 2014c) proposed a belief tracker based on recurrent neural networks. This approach maps directly from the ASR (automatic speech recognition) output to the belief state update, avoiding the use of complex semantic decoders while still attaining state-of-the-art performance. We adopt this</context>
</contexts>
<marker>Williams, 2014</marker>
<rawString>Jason D. Williams. 2014. Web-style ranking and slu combination for dialog state tracking. In Proceedings of SIGDIAL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>