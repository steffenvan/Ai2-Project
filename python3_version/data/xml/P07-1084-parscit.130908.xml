<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.994434">
Bilingual Terminology Mining – Using Brain, not brawn comparable
corpora
</title>
<author confidence="0.953721">
E. Morin, B. Daille
</author>
<bodyText confidence="0.614913285714286">
Université de Nantes
LINA FRE CNRS 2729
2, rue de la Houssinière
BP 92208
F-44322 Nantes Cedex 03
{morin-e,daille-b}@
univ-nantes.fr
</bodyText>
<author confidence="0.952695">
K. Takeuchi
</author>
<affiliation confidence="0.976881">
Okayama University
</affiliation>
<address confidence="0.6694265">
3-1-1, Tsushimanaka
Okayama-shi, Okayama,
700-8530, Japan
koichi@
</address>
<email confidence="0.724757">
cl.it.okayama-u.ac.jp
</email>
<author confidence="0.993524">
K. Kageura
</author>
<affiliation confidence="0.9993465">
Graduate School of Education
The University of Tokyo
</affiliation>
<address confidence="0.915895">
7-3-1 Hongo, Bunkyo-ku,
Tokyo, 113-0033, Japan
</address>
<email confidence="0.996315">
kyo@p.u-tokyo.ac.jp
</email>
<sectionHeader confidence="0.995604" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997634">
Current research in text mining favours the
quantity of texts over their quality. But for
bilingual terminology mining, and for many
language pairs, large comparable corpora
are not available. More importantly, as terms
are defined vis-à-vis a specific domain with
a restricted register, it is expected that the
quality rather than the quantity of the corpus
matters more in terminology mining. Our
hypothesis, therefore, is that the quality of
the corpus is more important than the quan-
tity and ensures the quality of the acquired
terminological resources. We show how im-
portant the type of discourse is as a charac-
teristic of the comparable corpus.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999892829268293">
Two main approaches exist for compiling corpora:
“Big is beautiful” or “Insecurity in large collec-
tions”. Text mining research commonly adopts the
first approach and favors data quantity over qual-
ity. This is normally justified on the one hand by
the need for large amounts of data in order to make
use of statistic or stochastic methods (Manning and
Schütze, 1999), and on the other by the lack of oper-
ational methods to automatize the building of a cor-
pus answering to selected criteria, such as domain,
register, media, style or discourse.
For lexical alignment from comparable corpora,
good results on single words can be obtained from
large corpora — several millions words — the accu-
racy of proposed translation is about 80% for the top
10-20 candidates (Fung, 1998; Rapp, 1999; Chiao
and Zweigenbaum, 2002). (Cao and Li, 2002) have
achieved 91% accuracy for the top three candidates
using the Web as a comparable corpus. But for spe-
cific domains, and many pairs of languages, such
huge corpora are not available. More importantly,
as terms are defined vis-à-vis a specific domain with
a restricted register, it is expected that the quality
rather than the quantity of the corpus matters more in
terminology mining. For terminology mining, there-
fore, our hypothesis is that the quality of the corpora
is more important than the quantity and that this en-
sures the quality of the acquired terminological re-
sources.
Comparable corpora are “sets of texts in different
languages, that are not translations of each other”
(Bowker and Pearson, 2002, p. 93). The term com-
parable is used to indicate that these texts share
some characteristics or features: topic, period, me-
dia, author, register (Biber, 1994), discourse... This
corpus comparability is discussed by lexical align-
ment researchers but never demonstrated: it is of-
ten reduced to a specific domain, such as the med-
ical (Chiao and Zweigenbaum, 2002) or financial
domains (Fung, 1998), or to a register, such as
newspaper articles (Fung, 1998). For terminology
</bodyText>
<page confidence="0.975555">
664
</page>
<note confidence="0.331935">
Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 664–671,
Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.999952902439024">
mining, the comparability of the corpus should be
based on the domain or the sub-domaine, but also
on the type of discourse. Indeed, discourse acts
semantically upon the lexical units. For a defined
topic, some terms are specific to one discourse or
another. For example, for French, within the sub-
domain of obesity in the domain of medicine, we
find the term excès de poids (overweight) only in-
side texts sharing a popular science discourse, and
the synonym excès pondéral (overweight) only in
scientific discourse. In order to evaluate how impor-
tant the discourse criterion is for building bilingual
terminological lists, we carried out experiments on
French-Japanese comparable corpora in the domain
of medicine, more precisely on the topic of diabetes
and nutrition, using texts collected from the Web and
manually selected and classified into two discourse
categories: one contains only scientific documents
and the other contains both scientific and popular
science documents.
We used a state-of-the-art multilingual terminol-
ogy mining chain composed of two term extraction
programs, one in each language, and an alignment
program. The term extraction programs are pub-
licly available and both extract multi-word terms
that are more precise and specific to a particular sci-
entific domain than single word terms. The align-
ment program makes use of the direct context-vector
approach (Fung, 1998; Peters and Picchi, 1998;
Rapp, 1999) slightly modified to handle both single-
and multi-word terms. We evaluated the candidate
translations of multi-word terms using a reference
list compiled from publicly available resources. We
found that taking discourse type into account re-
sulted in candidate translations of a better quality
even when the corpus size is reduced by half. Thus,
even using a state-of-the-art alignment method well-
known as data greedy, we reached the conclusion
that the quantity of data is not sufficient to obtain
a terminological list of high quality and that a real
comparability of corpora is required.
</bodyText>
<sectionHeader confidence="0.921286" genericHeader="method">
2 Multilingual terminology mining chain
</sectionHeader>
<bodyText confidence="0.991173">
Taking as input a comparable corpora, the multilin-
gual terminology chain outputs a list of single- and
multi-word candidate terms along with their candi-
date translations. Its architecture is summarized in
Figure 1 and comprises term extraction and align-
ment programs.
</bodyText>
<subsectionHeader confidence="0.985911">
2.1 Term extraction programs
</subsectionHeader>
<bodyText confidence="0.968971294117647">
The terminology extraction programs are avail-
able for both French1 (Daille, 2003) and Japanese2
(Takeuchi et al., 2004). The terminological units
that are extracted are multi-word terms whose syn-
tactic patterns correspond either to a canonical or a
variation structure. The patterns are expressed us-
ing part-of-speech tags: for French, Brill’s POS tag-
ger3 and the FLEM lemmatiser4 are utilised, and for
Japanese, CHASEN5. For French, the main patterns
are N N, N Prep N et N Adj and for Japanese, N N,
N Suff, Adj N and Pref N. The variants handled are
morphological for both languages, syntactical only
for French, and compounding only for Japanese. We
consider as a morphological variant a morphological
modification of one of the components of the base
form, as a syntactical variant the insertion of another
word into the components of the base form, and as
a compounding variant the agglutination of another
word to one of the components of the base form. For
example, in French, the candidate MWT sécrétion
d’insuline (insulin secretion) appears in the follow-
ing forms:
base form of N Prep N pattern: sécrétion
d’insuline (insulin secretion);
inflexional variant: sécrétions d’insuline (in-
sulin secretions);
syntactic variant (insertion inside the base
form of a modifier): sécrétion pancréatique
d’insuline (pancreatic insulin secretion);
syntactic variant (expansion coordination of
base form): secrétion de peptide et d’insuline
(insulin and peptide secretion).
The MWT candidates secrétion insulinique (insulin
secretion) and hypersécrétion insulinique (insulin
</bodyText>
<footnote confidence="0.991909111111111">
1http://www.sciences.univ-nantes.fr/
info/perso/permanents/daille/ and release
LINUX.
2http://research.nii.ac.jp/~koichi/
study/hotal/
3http://www.atilf.fr/winbrill/
4http://www.univ-nancy2.fr/pers/namer/
5http://chasen.org/$\sim$taku/software/
mecab/
</footnote>
<page confidence="0.989899">
665
</page>
<figure confidence="0.99967595">
French documents Japanese documents
WEB
haversting
documents
terminology
extraction
terminology
extraction
lexical context
extraction
terms to be
translated
lexical context
extraction
candidate
translations
lexical alignment
process
dictionary
bilingual
</figure>
<figureCaption confidence="0.999997">
Figure 1: Architecture of the multilingual terminology mining chain
</figureCaption>
<bodyText confidence="0.903137375">
hypersecretion) have also been identified and lead
together with sécrétion d’insuline (insulin secretion)
to a cluster of semantically linked MWTs.
In Japanese, the MWT . 6 (in-
sulin secretion) appears in the following forms:
/N (insulin secretion);
compounding variant (agglutination of a
word at the end of the base form):
</bodyText>
<equation confidence="0.648123">
/N . /N . /N (insulin secretion
ability)
</equation>
<bodyText confidence="0.9979145">
At present, the Japanese term extraction program
does not cluster terms.
</bodyText>
<subsectionHeader confidence="0.997791">
2.2 Term alignment
</subsectionHeader>
<bodyText confidence="0.911140692307692">
The lexical alignment program adapts the direct
context-vector approach proposed by (Fung, 1998)
for single-word terms (SWTs) to multi-word terms
(MWTs). It aligns source MWTs with target single
6For all Japanese examples, we explicitly segment the com-
pound into its component parts through the use of the “.” sym-
bol.
words, SWTs or MWTs. From now on, we will refer
to lexical units as words, SWTs or MWTs.
2.2.1 Implementation of the direct
context-vector method
Our implementation of the direct context-vector
method consists of the following 4 steps:
1. We collect all the lexical units in the context of
each lexical unit and count their occurrence
frequency in a window of words around .
For each lexical unit of the source and the
target language, we obtain a context vector
which gathers the set of co-occurrence units
associated with the number of times that and
occur together . We normalise context vec-
tors using an association score such as Mutual
Information or Log-likelihood. In order to re-
duce the arity of context vectors, we keep only
the co-occurrences with the highest association
scores.
</bodyText>
<listItem confidence="0.9543335">
2. Using a bilingual dictionary, we translate the
lexical units of the source context vector.
</listItem>
<figure confidence="0.306868">
base form of NN pattern:
/N .
</figure>
<page confidence="0.944632">
666
</page>
<listItem confidence="0.871767125">
3. For a word to be translated, we compute the
similarity between the translated context vector
and all target vectors through vector distance
measures such as Cosine (Salton and Lesk,
1968) or Jaccard (Tanimoto, 1958).
4. The candidate translations of a lexical unit are
the target lexical units closest to the translated
context vector according to vector distance.
</listItem>
<subsectionHeader confidence="0.707101">
2.2.2 Translation of lexical units
</subsectionHeader>
<bodyText confidence="0.999963">
The translation of the lexical units of the context
vectors, which depends on the coverage of the bilin-
gual dictionary vis-à-vis the corpus, is an important
step of the direct approach: more elements of the
context vector are translated more the context vector
will be discrimating for selecting translations in the
target language. If the bilingual dictionary provides
several translations for a lexical unit, we consider all
of them but weight the different translations by their
frequency in the target language. If an MWT cannot
be directly translated, we generate possible trans-
lations by using a compositional method (Grefen-
stette, 1999). For each element of the MWT found
in the bilingual dictionary, we generate all the trans-
lated combinations identified by the term extraction
program. For example, in the case of the MWT fa-
tigue chronique (chronic fatigue), we have the fol-
lowing four translations for fatigue:
</bodyText>
<footnote confidence="0.968396">
7the French word order is inverted to take into account the
different constraints between French and Japanese.
</footnote>
<table confidence="0.892097">
chronique fatigue
</table>
<tableCaption confidence="0.908965">
Table 1: Illustration of the compositional method.
The underlined Japanese MWT actually exists.
</tableCaption>
<bodyText confidence="0.997899416666666">
bilingual dictionary. For an MWT of length , (Ro-
bitaille et al., 2006) produce all the combinations of
MWU elements of a length less than or equal to .
For example, the French term syndrome de fatigue
chronique (chronic fatigue disease) yields the fol-
lowing four combinations: i) syndrome de fatigue
chronique , ii) syndrome de fatigue chronique , iii)
syndrome fatigue chronique and iv) syndrome
fatigue chronique . We limit ourselves to the com-
bination of type iv) above since 90% of the candidate
terms provided by the term extraction process, after
clustering, are only composed of two content words.
</bodyText>
<sectionHeader confidence="0.994534" genericHeader="method">
3 Linguistic resources
</sectionHeader>
<bodyText confidence="0.999848">
In this section we outline the different textual re-
sources used for our experiments: the comparable
corpora, bilingual dictionary and reference lexicon.
</bodyText>
<subsectionHeader confidence="0.99889">
3.1 Comparable corpora
</subsectionHeader>
<bodyText confidence="0.999760875">
The French and Japanese documents were harvested
from the Web by native speakers of each language
who are not domain specialists. The texts are from
the medical domain, within the sub-domain of dia-
betes and nutrition. Document harvesting was car-
ried out by a domain-based search, then by man-
ual selection. The search for documents sharing the
same domain can be achieved using keywords re-
flecting the specialized domain: for French, diabète
and obésité (diabetes and obesity); for Japanese,
and . Then the documents were classified
according to the type of discourse: scientific or pop-
ularized science. At present, the selection and clas-
sification phases are carried out manually although
, ,
,and the following two translations for
chronique: ,. Next, we generate all
combinations of translated elements (See Table 17)
and select those which refer to an existing MWT
in the target language. Here, only one term has
been identified by the Japanese terminology extrac-
tion program: . . In this approach, when
it is not possible to translate all parts of an MWT,
or when the translated combinations are not identi-
fied by the term extraction program, the MWT is not
taken into account in the translation process.
This approach differs from that used by (Ro-
bitaille et al., 2006) for French/Japanese translation.
They first decompose the French MWT into com-
binations of shorter multi-word units (MWU) ele-
ments. This approach makes the direct translation of
a subpart of the MWT possible if it is present in the
</bodyText>
<page confidence="0.995593">
667
</page>
<bodyText confidence="0.9998446">
research into how to automatize these two steps is
ongoing. Table 2 shows the main features of the
harvested comparable corpora: the number of doc-
uments, and the number of words for each language
and each type of discourse.
</bodyText>
<table confidence="0.999396333333333">
French Japanese
doc. words doc. words
Scientific 65 425,781 119 234,857
Popular 183 267,885 419 572,430
science
Total 248 693,666 538 807,287
</table>
<tableCaption confidence="0.999472">
Table 2: Comparable corpora statistics
</tableCaption>
<bodyText confidence="0.96450925">
From these documents, we created two compara-
ble corpora:
scientific corpora✜, composed only of scientific
documents;
</bodyText>
<subsectionHeader confidence="0.999692">
3.2 Bilingual dictionary
</subsectionHeader>
<bodyText confidence="0.999022857142857">
The French-Japanese bilingual dictionary required
for the translation phase is composed of four dic-
tionaries freely available from the Webb, and of
the French-Japanese Scientific Dictionary (1989).
It contains about 173,156 entries (114,461 single
words and 58,695 multi words) with an average of
2.1 translations per entry.
</bodyText>
<subsectionHeader confidence="0.998152">
3.3 Terminology reference lists
</subsectionHeader>
<bodyText confidence="0.998985857142857">
To evaluate the quality of the terminology min-
ing chain, we built two bilingual terminology refer-
ence lists which include either SWTs or SMTs and
MWTs:
lexicon 2 60 French SWTs and MWTs of
which the translation could be Japanese SWTs
or MWTs.
</bodyText>
<footnote confidence="0.9934152">
8http://kanji.free.fr/,http://
quebec-japon.com/lexique/index.php?a=
index&amp;d=25,http://dico.fj.free.fr/index.
php,http://quebec-japon.com/lexique/index.
php?a=index&amp;d=3
</footnote>
<bodyText confidence="0.999912931034483">
These lexicons contains terms that occur at least
twice in the scientific corpus, have been identified
monolingually by both the French and the Japanese
term extraction programs, and are found in either
the UMLS9 thesaurus or in the French part of the
Grand dictionnaire terminologique10 in the domain
of medicine. These constraints prevented us from
obtaining 100 French SWTs and MWTs for lexicon
2. The main reasons for this are the small number
of UMLS terms dealing with the sub-domain of di-
abetes and the great difference between the linguis-
tic structures of French and Japanese terms: French
pattern definitions tend to cover more phrasal units
while Japanese pattern definitions focus more nar-
rowly on compounds. So, even if monolingually
the same percentage of terms are detected in both
languages, this does not guarantee a good result in
bilingual terminology extraction. For example, the
French term diabète de type 1 (Diabetes mellitus
type I) extracted by the French term extraction pro-
gram and found in UMLS was not extracted by the
Japanese term extraction program although it ap-
pears frequently in the Japanese corpus (
).
In bilingual terminology mining from specialized
comparable corpora, the terminology reference lists
are often composed of a hundred words (180 SWTs
in (Déjean and Gaussier, 2002) and 97 SWTs in
(Chiao and Zweigenbaum, 2002)).
</bodyText>
<sectionHeader confidence="0.999651" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<bodyText confidence="0.9999875">
In order to evaluate the influence of discourse type
on the quality of bilingual terminology extraction,
two experiments were carried out. Since the main
studies relating to bilingual lexicon extraction from
comparable corpora concentrate on finding transla-
tion candidates for SWTs, we first perform an ex-
periment using lexicon 1 , which is composed of
SWTs. In order to evaluate the hypothesis of this
study, we then conducted a second experiment using
lexicon 2 , which is composed of MWTs.
</bodyText>
<subsectionHeader confidence="0.997823">
4.1 Alignment results for lexicon 1
</subsectionHeader>
<bodyText confidence="0.9740965">
Table 3 shows the results obtained. The first three
columns indicate the number of translations found
</bodyText>
<footnote confidence="0.999375">
9http://www.nlm.nih.gov/research/umls
10http://www.granddictionnaire.com/
</footnote>
<figureCaption confidence="0.6996455">
mixed corpora✜, composed of both popular and
scientific documents.
lexicon 1 100 French SWTs of which the
translation are Japanese SWTs.
</figureCaption>
<page confidence="0.896353">
668
</page>
<table confidence="0.9717825">
scientific corpora 64 11.6 20.2 49 52
mixed corpora 76 11.5 16.3 51 60
</table>
<tableCaption confidence="0.652472">
Table 3: Bilingual terminology extraction results for lexicon 1
scientific corpora 32 16.1 21.9 18 25
mixed corpora 32 23.9 27.6 17 20
Table 4: Bilingual terminology extraction results for lexicon 2
</tableCaption>
<bodyText confidence="0.980449272727273">
).
The results of this experiment (see Table 3) show
that the terms belonging to lexicon 1 were more
easily identified in the corpus of scientific and pop-
ular documents (51% and 60% respectively for
and ) than in the corpus of scien-
tific documents (49% and 52%). Since lexicon 1 is
composed of SWTs, these terms are not more char-
acteristic of popular discourse than scientific dis-
course.
The frequency of the terms to be translated is an
important factor in the vectorial approach. In fact,
the higher the frequency of the term to be translated,
the more the associated context vector will be dis-
criminant. Table 5 confirms this hypothesis since
the most frequent terms, such as insuline (#occ. 364
- insulin: ), obésité (#occ. 333 - obe-
sity: ), and prévention (#occ. 120 -prevention:
), were the best translated.
[2,10] [11,50] [51,100] [101,...]
fr 3/17 12/29 17/23 28/31
jp 4/26 32/41 14/20 10/13
As a baseline, (Déjean et al., 2002) obtain 43%
and 51% for the first 10 and 20 candidates respec-
tively in a 100,000-word medical corpus, and 79%
and 84% in a multi-domain 8 million-word cor-
pus. For single-item French-English words applied
on a medical corpus of 0.66 million words, (Chiao
and Zweigenbaum, 2002) obtained 61% and 94%
precision on the top-10 and top-20 candidates. In
our case, we obtained 51% and 60% precision for
the top 10 and 20 candidates in a 1.5 million-word
French/Japanese corpus.
</bodyText>
<subsectionHeader confidence="0.998974">
4.2 Alignment results for lexicon 2
</subsectionHeader>
<bodyText confidence="0.98901704">
The analysis results in table 4 indicate only a small
number of the terms in lexicon 2 were found.
Since we work with small-size corpora, this result
is not surprising. Because multi-word terms are
more specific than single-word terms, they tend to
occur less frequently in a corpus and are more diffi-
cult to translate. Here, the terms belonging lexicon
2 were more accurately identified from the corpus
which consists of scientific documents than the cor-
pus which consists of scientific and popular doc-
uments. In this instance, we obtained 30% and
42% precision for the top 10 and top 20 candi-
dates in a 0.84 million-word scientific corpus. More-
over, if we count the number of terms which are
correctly translated between scientific corpora and
mixed corpora , we find the majority of the trans-
lated terms with mixed corpora in those obtained
with scientific corpora 11 By combining parameters
( ), and the average ( ) and standard
deviation ( ) positions for the transla-
tions in the ranked list of candidate translations.
The other two columns indicate the percentage of
French terms for which the correct translation was
obtained among the top ten and top twenty candi-
dates ( ,
</bodyText>
<tableCaption confidence="0.962906">
Table 5: Frequency in corpus 2 of the terms trans-
</tableCaption>
<bodyText confidence="0.422946">
lated belonging to lexicon 1 (for )
&amp;quot;Here, , and
.
</bodyText>
<page confidence="0.953483">
669
</page>
<figure confidence="0.999014642857142">
nbr.
×
×
×
×
×
× ×
win.
nbr.
×
×
× × ×
×
win.
(a) parameter: Log-likelihood &amp; cosinus (b) parameter: Log-likelihood &amp;jaccard
nbr.
× × × ×
×
×
×
win.
nbr.
☎ ☎ ☎
× × × ×
× ×
×
win.
(c) parameter: MI &amp; cosinus (d) parameter : MI &amp; jaccard
</figure>
<figureCaption confidence="0.999987">
Figure 2: Evolution of the number of translations found in according to the size of the contextual
</figureCaption>
<bodyText confidence="0.97596835">
window for several combinations of parameters with lexicon 2 (scientific corpora —–; mixed corpora -
- -, the points indicated are the computed values)
such as the window size of the context vector, as-
sociation score, and vector distance measure, the
terms were often identified with more precision from
the corpus consisting of scientific documents than
the corpus consisting of scientific and popular docu-
ments (see Figure 2).
Here again, the most frequent terms (see Table 6),
such as diabète (#occ. 899 - diabetes: . ),
facteur de risque (#occ. 267 - risk factor:
), hyperglycémie (#occ. 127 - hyperglycaemia:
. ), tissu adipeux (#occ. 62 - adipose tissue:
. ) were the best translated. On the other
hand, some terms with low frequency, such as édul-
corant (#occ. 13 - sweetener:
imentaire (#occ. 11 -feeding preferences: .
), or very low frequency, such as obésité massive
(#occ. 6 - massive obesity: . ), were also
identified with this approach.
</bodyText>
<table confidence="0.631409666666667">
[2,10] [11,50] [51,100] [101,...]
fr 1/11 11/25 6/14 7/10
jp 5/21 13/25 5/9 2/5
</table>
<tableCaption confidence="0.991605">
Table 6: Frequency in scientific corpora of trans-
</tableCaption>
<bodyText confidence="0.910969">
lated terms belonging to lexicon 2 (for )
</bodyText>
<sectionHeader confidence="0.998894" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9988215">
This article describes a first attempt at compiling
French-Japanese terminology from comparable cor-
pora taking into account both single- and multi-word
terms. Our claim was that a real comparability of
the corpora is required to obtain relevant terms of
the domain. This comparability should be based not
only on the domain and the sub-domain but also on
the type of discourse, which acts semantically upon
the lexical units. The discourse categorization of
documents allows lexical acquisition to increase pre-
.
. ) and choix al-
</bodyText>
<page confidence="0.94145">
670
</page>
<bodyText confidence="0.9999878125">
cision despite the data sparsity problem that is of-
ten encountered for terminology mining and for lan-
guage pairs not involving the English language, such
as French-Japanese. We carried out experiments us-
ing two corpora of the specialised domain concern-
ing diabetes and nutrition: one gathering documents
from both scientific and popular science discourses,
the other limited to scientific discourse. Our align-
ment results are close to previous works involving
the English language, and are of better quality for
the scientific corpus despite a corpus size that was
reduced by half. The results demonstrate that the
more frequent a term and its translation, the better
the quality of the alignment will be, but also that the
data sparsity problem could be partially solved by
using comparable corpora of high quality.
</bodyText>
<sectionHeader confidence="0.999441" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999945948051948">
Douglas Biber. 1994. Representativeness in corpus de-
sign. In A. Zampolli, N. Calzolari, and M. Palmer,
editors, Current Issues in Computational Linguistics:
in Honour ofDon Walker, pages 377–407. Pisa: Giar-
dini/Dordrecht: Kluwer.
Lynne Bowker and Jennifer Pearson. 2002. Working
with Specialized Language: A Practical Guide to Us-
ing Corpora. London/New York: Routledge.
Yunbo Cao and Hang Li. 2002. Base Noun Phrase Trans-
lation Using Web Data and the EM Algorithm. In
Proceedings of the 19th International Conference on
Computational Linguistics (COLING’02), pages 127–
133, Tapei, Taiwan.
Yun-Chuang Chiao and Pierre Zweigenbaum. 2002.
Looking for candidate translational equivalents in spe-
cialized, comparable corpora. In Proceedings of the
19th International Conference on Computational Lin-
guistics (COLING’02), pages 1208–1212, Tapei, Tai-
wan.
Béatrice Daille. 2003. Terminology Mining. In
Maria Teresa Pazienza, editor, Information Extraction
in the Web Era, pages 29–44. Springer.
Hervé Déjean and Éric Gaussier. 2002. Une nouvelle ap-
proche l’extraction de lexiques bilingues partir de
corpus comparables. Lexicometrica, Alignement lexi-
cal dans les corpus multilingues, pages 1–22.
Hervé Déjean, Fatia Sadat, and Éric Gaussier. 2002.
An approach based on multilingual thesauri and model
combination for bilingual lexicon extraction. In Pro-
ceedings of the 19th International Conference on
Computational Linguistics (COLING’02), pages 218–
224, Tapei, Taiwan.
French-Japanese Scientific Dictionary. 1989. Hakusu-
isha. 4th edition.
Pascale Fung. 1998. A Statistical View on Bilingual
Lexicon Extraction: From Parallel Corpora to Non-
parallel Corpora. In David Farwell, Laurie Gerber,
and Eduard Hovy, editors, Proceedings of the 3rd Con-
ference of the Association for Machine Translation in
the Americas (AMTA’98), pages 1–16, Langhorne, PA,
USA. Springer.
Gregory Grefenstette. 1999. The Word Wide Web as
a Resource for Example-Based Machine Translation
Tasks. In ASLIB’99 Translating and the Computer 21,
London, UK.
Christopher D. Manning and Hinrich Schütze. 1999.
Foundations of Statistical Natural Language Process-
ing. MIT Press, Cambridge, MA.
Carol Peters and Eugenio Picchi. 1998. Cross-language
information retrieval: A system for comparable cor-
pus querying. In Gregory Grefenstette, editor, Cross-
language information retrieval, chapter 7, pages 81–
90. Kluwer.
Reinhard Rapp. 1999. Automatic Identification of Word
Translations from Unrelated English and German Cor-
pora. In Proceedings of the 37th Annual Meeting ofthe
Association for Computational Linguistics (ACL’99),
pages 519–526, College Park, Maryland, USA.
Xavier Robitaille, Xavier Sasaki, Masatsugu Tonoike,
Satoshi Sato, and Satoshi Utsuro. 2006. Compil-
ing French-Japanese Terminologies from the Web. In
Proceedings of the 11th Conference of the European
Chapter ofthe Associationfor Computational Linguis-
tics (EACL’06), pages 225–232, Trento, Italy.
Gerard Salton and Michael E. Lesk. 1968. Computer
evaluation of indexing and text processing. Jour-
nal of the Association for Computational Machinery,
15(1):8–36.
Koichi Takeuchi, Kyo Kageura, Béatrice Daille, and Lau-
rent Romary. 2004. Construction of grammar based
term extraction model for japanese. In Sophia Anana-
diou and Pierre Zweigenbaum, editors, Proceeding
of the COLING 2004, 3rd International Workshop
on Computational Terminology (COMPUTERM’04),
pages 91–94, Geneva, Switzerland.
T. T. Tanimoto. 1958. An elementary mathematical the-
ory of classification. Technical report, IBM Research.
</reference>
<page confidence="0.998547">
671
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.356524">
<title confidence="0.822399">Bilingual Terminology Mining – Using Brain, not brawn comparable corpora</title>
<author confidence="0.988943">E Morin</author>
<author confidence="0.988943">B Daille</author>
<affiliation confidence="0.998522">Université de Nantes</affiliation>
<address confidence="0.97842325">LINA FRE CNRS 2729 2, rue de la Houssinière BP 92208 F-44322 Nantes Cedex 03</address>
<email confidence="0.932766">morin-e@univ-nantes.fr</email>
<email confidence="0.932766">daille-b@univ-nantes.fr</email>
<author confidence="0.997373">K Takeuchi</author>
<affiliation confidence="0.999997">Okayama University</affiliation>
<address confidence="0.977436666666667">3-1-1, Tsushimanaka Okayama-shi, Okayama, 700-8530, Japan</address>
<email confidence="0.843086">koichi@cl.it.okayama-u.ac.jp</email>
<author confidence="0.986273">K Kageura</author>
<affiliation confidence="0.9998485">Graduate School of Education The University of Tokyo</affiliation>
<address confidence="0.9983745">7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-0033, Japan</address>
<email confidence="0.987699">kyo@p.u-tokyo.ac.jp</email>
<abstract confidence="0.9992320625">Current research in text mining favours the quantity of texts over their quality. But for bilingual terminology mining, and for many language pairs, large comparable corpora are not available. More importantly, as terms are defined vis-à-vis a specific domain with a restricted register, it is expected that the quality rather than the quantity of the corpus matters more in terminology mining. Our hypothesis, therefore, is that the quality of the corpus is more important than the quantity and ensures the quality of the acquired terminological resources. We show how important the type of discourse is as a characteristic of the comparable corpus.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Douglas Biber</author>
</authors>
<title>Representativeness in corpus design. In</title>
<date>1994</date>
<booktitle>Current Issues in Computational Linguistics: in Honour ofDon Walker,</booktitle>
<pages>377--407</pages>
<editor>A. Zampolli, N. Calzolari, and M. Palmer, editors,</editor>
<publisher>Giardini/Dordrecht: Kluwer.</publisher>
<location>Pisa:</location>
<contexts>
<context position="2857" citStr="Biber, 1994" startWordPosition="452" endWordPosition="453">restricted register, it is expected that the quality rather than the quantity of the corpus matters more in terminology mining. For terminology mining, therefore, our hypothesis is that the quality of the corpora is more important than the quantity and that this ensures the quality of the acquired terminological resources. Comparable corpora are “sets of texts in different languages, that are not translations of each other” (Bowker and Pearson, 2002, p. 93). The term comparable is used to indicate that these texts share some characteristics or features: topic, period, media, author, register (Biber, 1994), discourse... This corpus comparability is discussed by lexical alignment researchers but never demonstrated: it is often reduced to a specific domain, such as the medical (Chiao and Zweigenbaum, 2002) or financial domains (Fung, 1998), or to a register, such as newspaper articles (Fung, 1998). For terminology 664 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 664–671, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics mining, the comparability of the corpus should be based on the domain or the sub-domaine, but al</context>
</contexts>
<marker>Biber, 1994</marker>
<rawString>Douglas Biber. 1994. Representativeness in corpus design. In A. Zampolli, N. Calzolari, and M. Palmer, editors, Current Issues in Computational Linguistics: in Honour ofDon Walker, pages 377–407. Pisa: Giardini/Dordrecht: Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lynne Bowker</author>
<author>Jennifer Pearson</author>
</authors>
<title>Working with Specialized Language: A Practical Guide to Using Corpora.</title>
<date>2002</date>
<location>London/New York: Routledge.</location>
<contexts>
<context position="2698" citStr="Bowker and Pearson, 2002" startWordPosition="424" endWordPosition="427">pus. But for specific domains, and many pairs of languages, such huge corpora are not available. More importantly, as terms are defined vis-à-vis a specific domain with a restricted register, it is expected that the quality rather than the quantity of the corpus matters more in terminology mining. For terminology mining, therefore, our hypothesis is that the quality of the corpora is more important than the quantity and that this ensures the quality of the acquired terminological resources. Comparable corpora are “sets of texts in different languages, that are not translations of each other” (Bowker and Pearson, 2002, p. 93). The term comparable is used to indicate that these texts share some characteristics or features: topic, period, media, author, register (Biber, 1994), discourse... This corpus comparability is discussed by lexical alignment researchers but never demonstrated: it is often reduced to a specific domain, such as the medical (Chiao and Zweigenbaum, 2002) or financial domains (Fung, 1998), or to a register, such as newspaper articles (Fung, 1998). For terminology 664 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 664–671, Prague, Czech Republi</context>
</contexts>
<marker>Bowker, Pearson, 2002</marker>
<rawString>Lynne Bowker and Jennifer Pearson. 2002. Working with Specialized Language: A Practical Guide to Using Corpora. London/New York: Routledge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yunbo Cao</author>
<author>Hang Li</author>
</authors>
<title>Base Noun Phrase Translation Using Web Data and the EM Algorithm.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Computational Linguistics (COLING’02),</booktitle>
<pages>127--133</pages>
<location>Tapei, Taiwan.</location>
<contexts>
<context position="1984" citStr="Cao and Li, 2002" startWordPosition="307" endWordPosition="310">y justified on the one hand by the need for large amounts of data in order to make use of statistic or stochastic methods (Manning and Schütze, 1999), and on the other by the lack of operational methods to automatize the building of a corpus answering to selected criteria, such as domain, register, media, style or discourse. For lexical alignment from comparable corpora, good results on single words can be obtained from large corpora — several millions words — the accuracy of proposed translation is about 80% for the top 10-20 candidates (Fung, 1998; Rapp, 1999; Chiao and Zweigenbaum, 2002). (Cao and Li, 2002) have achieved 91% accuracy for the top three candidates using the Web as a comparable corpus. But for specific domains, and many pairs of languages, such huge corpora are not available. More importantly, as terms are defined vis-à-vis a specific domain with a restricted register, it is expected that the quality rather than the quantity of the corpus matters more in terminology mining. For terminology mining, therefore, our hypothesis is that the quality of the corpora is more important than the quantity and that this ensures the quality of the acquired terminological resources. Comparable cor</context>
</contexts>
<marker>Cao, Li, 2002</marker>
<rawString>Yunbo Cao and Hang Li. 2002. Base Noun Phrase Translation Using Web Data and the EM Algorithm. In Proceedings of the 19th International Conference on Computational Linguistics (COLING’02), pages 127– 133, Tapei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yun-Chuang Chiao</author>
<author>Pierre Zweigenbaum</author>
</authors>
<title>Looking for candidate translational equivalents in specialized, comparable corpora.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Computational Linguistics (COLING’02),</booktitle>
<pages>1208--1212</pages>
<location>Tapei, Taiwan.</location>
<contexts>
<context position="1964" citStr="Chiao and Zweigenbaum, 2002" startWordPosition="303" endWordPosition="306">y over quality. This is normally justified on the one hand by the need for large amounts of data in order to make use of statistic or stochastic methods (Manning and Schütze, 1999), and on the other by the lack of operational methods to automatize the building of a corpus answering to selected criteria, such as domain, register, media, style or discourse. For lexical alignment from comparable corpora, good results on single words can be obtained from large corpora — several millions words — the accuracy of proposed translation is about 80% for the top 10-20 candidates (Fung, 1998; Rapp, 1999; Chiao and Zweigenbaum, 2002). (Cao and Li, 2002) have achieved 91% accuracy for the top three candidates using the Web as a comparable corpus. But for specific domains, and many pairs of languages, such huge corpora are not available. More importantly, as terms are defined vis-à-vis a specific domain with a restricted register, it is expected that the quality rather than the quantity of the corpus matters more in terminology mining. For terminology mining, therefore, our hypothesis is that the quality of the corpora is more important than the quantity and that this ensures the quality of the acquired terminological resou</context>
<context position="16109" citStr="Chiao and Zweigenbaum, 2002" startWordPosition="2482" endWordPosition="2485">olingually the same percentage of terms are detected in both languages, this does not guarantee a good result in bilingual terminology extraction. For example, the French term diabète de type 1 (Diabetes mellitus type I) extracted by the French term extraction program and found in UMLS was not extracted by the Japanese term extraction program although it appears frequently in the Japanese corpus ( ). In bilingual terminology mining from specialized comparable corpora, the terminology reference lists are often composed of a hundred words (180 SWTs in (Déjean and Gaussier, 2002) and 97 SWTs in (Chiao and Zweigenbaum, 2002)). 4 Experiments In order to evaluate the influence of discourse type on the quality of bilingual terminology extraction, two experiments were carried out. Since the main studies relating to bilingual lexicon extraction from comparable corpora concentrate on finding translation candidates for SWTs, we first perform an experiment using lexicon 1 , which is composed of SWTs. In order to evaluate the hypothesis of this study, we then conducted a second experiment using lexicon 2 , which is composed of MWTs. 4.1 Alignment results for lexicon 1 Table 3 shows the results obtained. The first three co</context>
<context position="18454" citStr="Chiao and Zweigenbaum, 2002" startWordPosition="2865" endWordPosition="2868"> will be discriminant. Table 5 confirms this hypothesis since the most frequent terms, such as insuline (#occ. 364 - insulin: ), obésité (#occ. 333 - obesity: ), and prévention (#occ. 120 -prevention: ), were the best translated. [2,10] [11,50] [51,100] [101,...] fr 3/17 12/29 17/23 28/31 jp 4/26 32/41 14/20 10/13 As a baseline, (Déjean et al., 2002) obtain 43% and 51% for the first 10 and 20 candidates respectively in a 100,000-word medical corpus, and 79% and 84% in a multi-domain 8 million-word corpus. For single-item French-English words applied on a medical corpus of 0.66 million words, (Chiao and Zweigenbaum, 2002) obtained 61% and 94% precision on the top-10 and top-20 candidates. In our case, we obtained 51% and 60% precision for the top 10 and 20 candidates in a 1.5 million-word French/Japanese corpus. 4.2 Alignment results for lexicon 2 The analysis results in table 4 indicate only a small number of the terms in lexicon 2 were found. Since we work with small-size corpora, this result is not surprising. Because multi-word terms are more specific than single-word terms, they tend to occur less frequently in a corpus and are more difficult to translate. Here, the terms belonging lexicon 2 were more acc</context>
</contexts>
<marker>Chiao, Zweigenbaum, 2002</marker>
<rawString>Yun-Chuang Chiao and Pierre Zweigenbaum. 2002. Looking for candidate translational equivalents in specialized, comparable corpora. In Proceedings of the 19th International Conference on Computational Linguistics (COLING’02), pages 1208–1212, Tapei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Béatrice Daille</author>
</authors>
<title>Terminology Mining.</title>
<date>2003</date>
<booktitle>Information Extraction in the Web Era,</booktitle>
<pages>29--44</pages>
<editor>In Maria Teresa Pazienza, editor,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="5805" citStr="Daille, 2003" startWordPosition="905" endWordPosition="906">lknown as data greedy, we reached the conclusion that the quantity of data is not sufficient to obtain a terminological list of high quality and that a real comparability of corpora is required. 2 Multilingual terminology mining chain Taking as input a comparable corpora, the multilingual terminology chain outputs a list of single- and multi-word candidate terms along with their candidate translations. Its architecture is summarized in Figure 1 and comprises term extraction and alignment programs. 2.1 Term extraction programs The terminology extraction programs are available for both French1 (Daille, 2003) and Japanese2 (Takeuchi et al., 2004). The terminological units that are extracted are multi-word terms whose syntactic patterns correspond either to a canonical or a variation structure. The patterns are expressed using part-of-speech tags: for French, Brill’s POS tagger3 and the FLEM lemmatiser4 are utilised, and for Japanese, CHASEN5. For French, the main patterns are N N, N Prep N et N Adj and for Japanese, N N, N Suff, Adj N and Pref N. The variants handled are morphological for both languages, syntactical only for French, and compounding only for Japanese. We consider as a morphological</context>
</contexts>
<marker>Daille, 2003</marker>
<rawString>Béatrice Daille. 2003. Terminology Mining. In Maria Teresa Pazienza, editor, Information Extraction in the Web Era, pages 29–44. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hervé Déjean</author>
<author>Éric Gaussier</author>
</authors>
<title>Une nouvelle approche l’extraction de lexiques bilingues partir de corpus comparables. Lexicometrica, Alignement lexical dans les corpus multilingues,</title>
<date>2002</date>
<pages>1--22</pages>
<contexts>
<context position="16064" citStr="Déjean and Gaussier, 2002" startWordPosition="2474" endWordPosition="2477">more narrowly on compounds. So, even if monolingually the same percentage of terms are detected in both languages, this does not guarantee a good result in bilingual terminology extraction. For example, the French term diabète de type 1 (Diabetes mellitus type I) extracted by the French term extraction program and found in UMLS was not extracted by the Japanese term extraction program although it appears frequently in the Japanese corpus ( ). In bilingual terminology mining from specialized comparable corpora, the terminology reference lists are often composed of a hundred words (180 SWTs in (Déjean and Gaussier, 2002) and 97 SWTs in (Chiao and Zweigenbaum, 2002)). 4 Experiments In order to evaluate the influence of discourse type on the quality of bilingual terminology extraction, two experiments were carried out. Since the main studies relating to bilingual lexicon extraction from comparable corpora concentrate on finding translation candidates for SWTs, we first perform an experiment using lexicon 1 , which is composed of SWTs. In order to evaluate the hypothesis of this study, we then conducted a second experiment using lexicon 2 , which is composed of MWTs. 4.1 Alignment results for lexicon 1 Table 3 s</context>
</contexts>
<marker>Déjean, Gaussier, 2002</marker>
<rawString>Hervé Déjean and Éric Gaussier. 2002. Une nouvelle approche l’extraction de lexiques bilingues partir de corpus comparables. Lexicometrica, Alignement lexical dans les corpus multilingues, pages 1–22.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hervé Déjean</author>
<author>Fatia Sadat</author>
<author>Éric Gaussier</author>
</authors>
<title>An approach based on multilingual thesauri and model combination for bilingual lexicon extraction.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Computational Linguistics (COLING’02),</booktitle>
<pages>218--224</pages>
<location>Tapei, Taiwan.</location>
<contexts>
<context position="18178" citStr="Déjean et al., 2002" startWordPosition="2819" endWordPosition="2822">not more characteristic of popular discourse than scientific discourse. The frequency of the terms to be translated is an important factor in the vectorial approach. In fact, the higher the frequency of the term to be translated, the more the associated context vector will be discriminant. Table 5 confirms this hypothesis since the most frequent terms, such as insuline (#occ. 364 - insulin: ), obésité (#occ. 333 - obesity: ), and prévention (#occ. 120 -prevention: ), were the best translated. [2,10] [11,50] [51,100] [101,...] fr 3/17 12/29 17/23 28/31 jp 4/26 32/41 14/20 10/13 As a baseline, (Déjean et al., 2002) obtain 43% and 51% for the first 10 and 20 candidates respectively in a 100,000-word medical corpus, and 79% and 84% in a multi-domain 8 million-word corpus. For single-item French-English words applied on a medical corpus of 0.66 million words, (Chiao and Zweigenbaum, 2002) obtained 61% and 94% precision on the top-10 and top-20 candidates. In our case, we obtained 51% and 60% precision for the top 10 and 20 candidates in a 1.5 million-word French/Japanese corpus. 4.2 Alignment results for lexicon 2 The analysis results in table 4 indicate only a small number of the terms in lexicon 2 were f</context>
</contexts>
<marker>Déjean, Sadat, Gaussier, 2002</marker>
<rawString>Hervé Déjean, Fatia Sadat, and Éric Gaussier. 2002. An approach based on multilingual thesauri and model combination for bilingual lexicon extraction. In Proceedings of the 19th International Conference on Computational Linguistics (COLING’02), pages 218– 224, Tapei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>French-Japanese Scientific Dictionary</author>
</authors>
<date>1989</date>
<note>Hakusuisha. 4th edition.</note>
<contexts>
<context position="14173" citStr="Dictionary (1989)" startWordPosition="2192" endWordPosition="2193">a: the number of documents, and the number of words for each language and each type of discourse. French Japanese doc. words doc. words Scientific 65 425,781 119 234,857 Popular 183 267,885 419 572,430 science Total 248 693,666 538 807,287 Table 2: Comparable corpora statistics From these documents, we created two comparable corpora: scientific corpora✜, composed only of scientific documents; 3.2 Bilingual dictionary The French-Japanese bilingual dictionary required for the translation phase is composed of four dictionaries freely available from the Webb, and of the French-Japanese Scientific Dictionary (1989). It contains about 173,156 entries (114,461 single words and 58,695 multi words) with an average of 2.1 translations per entry. 3.3 Terminology reference lists To evaluate the quality of the terminology mining chain, we built two bilingual terminology reference lists which include either SWTs or SMTs and MWTs: lexicon 2 60 French SWTs and MWTs of which the translation could be Japanese SWTs or MWTs. 8http://kanji.free.fr/,http:// quebec-japon.com/lexique/index.php?a= index&amp;d=25,http://dico.fj.free.fr/index. php,http://quebec-japon.com/lexique/index. php?a=index&amp;d=3 These lexicons contains ter</context>
</contexts>
<marker>Dictionary, 1989</marker>
<rawString>French-Japanese Scientific Dictionary. 1989. Hakusuisha. 4th edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
</authors>
<title>A Statistical View on Bilingual Lexicon Extraction: From Parallel Corpora to Nonparallel Corpora. In</title>
<date>1998</date>
<booktitle>Proceedings of the 3rd Conference of the Association for Machine Translation in the Americas (AMTA’98),</booktitle>
<pages>1--16</pages>
<editor>David Farwell, Laurie Gerber, and Eduard Hovy, editors,</editor>
<publisher>USA. Springer.</publisher>
<location>Langhorne, PA,</location>
<contexts>
<context position="1922" citStr="Fung, 1998" startWordPosition="299" endWordPosition="300"> and favors data quantity over quality. This is normally justified on the one hand by the need for large amounts of data in order to make use of statistic or stochastic methods (Manning and Schütze, 1999), and on the other by the lack of operational methods to automatize the building of a corpus answering to selected criteria, such as domain, register, media, style or discourse. For lexical alignment from comparable corpora, good results on single words can be obtained from large corpora — several millions words — the accuracy of proposed translation is about 80% for the top 10-20 candidates (Fung, 1998; Rapp, 1999; Chiao and Zweigenbaum, 2002). (Cao and Li, 2002) have achieved 91% accuracy for the top three candidates using the Web as a comparable corpus. But for specific domains, and many pairs of languages, such huge corpora are not available. More importantly, as terms are defined vis-à-vis a specific domain with a restricted register, it is expected that the quality rather than the quantity of the corpus matters more in terminology mining. For terminology mining, therefore, our hypothesis is that the quality of the corpora is more important than the quantity and that this ensures the qu</context>
<context position="3152" citStr="Fung, 1998" startWordPosition="499" endWordPosition="500">ed terminological resources. Comparable corpora are “sets of texts in different languages, that are not translations of each other” (Bowker and Pearson, 2002, p. 93). The term comparable is used to indicate that these texts share some characteristics or features: topic, period, media, author, register (Biber, 1994), discourse... This corpus comparability is discussed by lexical alignment researchers but never demonstrated: it is often reduced to a specific domain, such as the medical (Chiao and Zweigenbaum, 2002) or financial domains (Fung, 1998), or to a register, such as newspaper articles (Fung, 1998). For terminology 664 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 664–671, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics mining, the comparability of the corpus should be based on the domain or the sub-domaine, but also on the type of discourse. Indeed, discourse acts semantically upon the lexical units. For a defined topic, some terms are specific to one discourse or another. For example, for French, within the subdomain of obesity in the domain of medicine, we find the term excès de poids (overweight) onl</context>
<context position="4759" citStr="Fung, 1998" startWordPosition="744" endWordPosition="745">cted from the Web and manually selected and classified into two discourse categories: one contains only scientific documents and the other contains both scientific and popular science documents. We used a state-of-the-art multilingual terminology mining chain composed of two term extraction programs, one in each language, and an alignment program. The term extraction programs are publicly available and both extract multi-word terms that are more precise and specific to a particular scientific domain than single word terms. The alignment program makes use of the direct context-vector approach (Fung, 1998; Peters and Picchi, 1998; Rapp, 1999) slightly modified to handle both singleand multi-word terms. We evaluated the candidate translations of multi-word terms using a reference list compiled from publicly available resources. We found that taking discourse type into account resulted in candidate translations of a better quality even when the corpus size is reduced by half. Thus, even using a state-of-the-art alignment method wellknown as data greedy, we reached the conclusion that the quantity of data is not sufficient to obtain a terminological list of high quality and that a real comparabil</context>
<context position="8427" citStr="Fung, 1998" startWordPosition="1265" endWordPosition="1266">Architecture of the multilingual terminology mining chain hypersecretion) have also been identified and lead together with sécrétion d’insuline (insulin secretion) to a cluster of semantically linked MWTs. In Japanese, the MWT . 6 (insulin secretion) appears in the following forms: /N (insulin secretion); compounding variant (agglutination of a word at the end of the base form): /N . /N . /N (insulin secretion ability) At present, the Japanese term extraction program does not cluster terms. 2.2 Term alignment The lexical alignment program adapts the direct context-vector approach proposed by (Fung, 1998) for single-word terms (SWTs) to multi-word terms (MWTs). It aligns source MWTs with target single 6For all Japanese examples, we explicitly segment the compound into its component parts through the use of the “.” symbol. words, SWTs or MWTs. From now on, we will refer to lexical units as words, SWTs or MWTs. 2.2.1 Implementation of the direct context-vector method Our implementation of the direct context-vector method consists of the following 4 steps: 1. We collect all the lexical units in the context of each lexical unit and count their occurrence frequency in a window of words around . For</context>
</contexts>
<marker>Fung, 1998</marker>
<rawString>Pascale Fung. 1998. A Statistical View on Bilingual Lexicon Extraction: From Parallel Corpora to Nonparallel Corpora. In David Farwell, Laurie Gerber, and Eduard Hovy, editors, Proceedings of the 3rd Conference of the Association for Machine Translation in the Americas (AMTA’98), pages 1–16, Langhorne, PA, USA. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory Grefenstette</author>
</authors>
<title>The Word Wide Web as a Resource for Example-Based Machine Translation Tasks.</title>
<date>1999</date>
<booktitle>In ASLIB’99 Translating and the Computer 21,</booktitle>
<location>London, UK.</location>
<contexts>
<context position="10613" citStr="Grefenstette, 1999" startWordPosition="1621" endWordPosition="1623">exical units of the context vectors, which depends on the coverage of the bilingual dictionary vis-à-vis the corpus, is an important step of the direct approach: more elements of the context vector are translated more the context vector will be discrimating for selecting translations in the target language. If the bilingual dictionary provides several translations for a lexical unit, we consider all of them but weight the different translations by their frequency in the target language. If an MWT cannot be directly translated, we generate possible translations by using a compositional method (Grefenstette, 1999). For each element of the MWT found in the bilingual dictionary, we generate all the translated combinations identified by the term extraction program. For example, in the case of the MWT fatigue chronique (chronic fatigue), we have the following four translations for fatigue: 7the French word order is inverted to take into account the different constraints between French and Japanese. chronique fatigue Table 1: Illustration of the compositional method. The underlined Japanese MWT actually exists. bilingual dictionary. For an MWT of length , (Robitaille et al., 2006) produce all the combinatio</context>
</contexts>
<marker>Grefenstette, 1999</marker>
<rawString>Gregory Grefenstette. 1999. The Word Wide Web as a Resource for Example-Based Machine Translation Tasks. In ASLIB’99 Translating and the Computer 21, London, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Hinrich Schütze</author>
</authors>
<date>1999</date>
<booktitle>Foundations of Statistical Natural Language Processing.</booktitle>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="1516" citStr="Manning and Schütze, 1999" startWordPosition="228" endWordPosition="231">esis, therefore, is that the quality of the corpus is more important than the quantity and ensures the quality of the acquired terminological resources. We show how important the type of discourse is as a characteristic of the comparable corpus. 1 Introduction Two main approaches exist for compiling corpora: “Big is beautiful” or “Insecurity in large collections”. Text mining research commonly adopts the first approach and favors data quantity over quality. This is normally justified on the one hand by the need for large amounts of data in order to make use of statistic or stochastic methods (Manning and Schütze, 1999), and on the other by the lack of operational methods to automatize the building of a corpus answering to selected criteria, such as domain, register, media, style or discourse. For lexical alignment from comparable corpora, good results on single words can be obtained from large corpora — several millions words — the accuracy of proposed translation is about 80% for the top 10-20 candidates (Fung, 1998; Rapp, 1999; Chiao and Zweigenbaum, 2002). (Cao and Li, 2002) have achieved 91% accuracy for the top three candidates using the Web as a comparable corpus. But for specific domains, and many pa</context>
</contexts>
<marker>Manning, Schütze, 1999</marker>
<rawString>Christopher D. Manning and Hinrich Schütze. 1999. Foundations of Statistical Natural Language Processing. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carol Peters</author>
<author>Eugenio Picchi</author>
</authors>
<title>Cross-language information retrieval: A system for comparable corpus querying.</title>
<date>1998</date>
<booktitle>Crosslanguage information retrieval, chapter 7,</booktitle>
<pages>81--90</pages>
<editor>In Gregory Grefenstette, editor,</editor>
<publisher>Kluwer.</publisher>
<contexts>
<context position="4784" citStr="Peters and Picchi, 1998" startWordPosition="746" endWordPosition="749">e Web and manually selected and classified into two discourse categories: one contains only scientific documents and the other contains both scientific and popular science documents. We used a state-of-the-art multilingual terminology mining chain composed of two term extraction programs, one in each language, and an alignment program. The term extraction programs are publicly available and both extract multi-word terms that are more precise and specific to a particular scientific domain than single word terms. The alignment program makes use of the direct context-vector approach (Fung, 1998; Peters and Picchi, 1998; Rapp, 1999) slightly modified to handle both singleand multi-word terms. We evaluated the candidate translations of multi-word terms using a reference list compiled from publicly available resources. We found that taking discourse type into account resulted in candidate translations of a better quality even when the corpus size is reduced by half. Thus, even using a state-of-the-art alignment method wellknown as data greedy, we reached the conclusion that the quantity of data is not sufficient to obtain a terminological list of high quality and that a real comparability of corpora is require</context>
</contexts>
<marker>Peters, Picchi, 1998</marker>
<rawString>Carol Peters and Eugenio Picchi. 1998. Cross-language information retrieval: A system for comparable corpus querying. In Gregory Grefenstette, editor, Crosslanguage information retrieval, chapter 7, pages 81– 90. Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Rapp</author>
</authors>
<title>Automatic Identification of Word Translations from Unrelated English and German Corpora.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting ofthe Association for Computational Linguistics (ACL’99),</booktitle>
<pages>519--526</pages>
<location>College Park, Maryland, USA.</location>
<contexts>
<context position="1934" citStr="Rapp, 1999" startWordPosition="301" endWordPosition="302">data quantity over quality. This is normally justified on the one hand by the need for large amounts of data in order to make use of statistic or stochastic methods (Manning and Schütze, 1999), and on the other by the lack of operational methods to automatize the building of a corpus answering to selected criteria, such as domain, register, media, style or discourse. For lexical alignment from comparable corpora, good results on single words can be obtained from large corpora — several millions words — the accuracy of proposed translation is about 80% for the top 10-20 candidates (Fung, 1998; Rapp, 1999; Chiao and Zweigenbaum, 2002). (Cao and Li, 2002) have achieved 91% accuracy for the top three candidates using the Web as a comparable corpus. But for specific domains, and many pairs of languages, such huge corpora are not available. More importantly, as terms are defined vis-à-vis a specific domain with a restricted register, it is expected that the quality rather than the quantity of the corpus matters more in terminology mining. For terminology mining, therefore, our hypothesis is that the quality of the corpora is more important than the quantity and that this ensures the quality of the</context>
<context position="4797" citStr="Rapp, 1999" startWordPosition="750" endWordPosition="751">ed and classified into two discourse categories: one contains only scientific documents and the other contains both scientific and popular science documents. We used a state-of-the-art multilingual terminology mining chain composed of two term extraction programs, one in each language, and an alignment program. The term extraction programs are publicly available and both extract multi-word terms that are more precise and specific to a particular scientific domain than single word terms. The alignment program makes use of the direct context-vector approach (Fung, 1998; Peters and Picchi, 1998; Rapp, 1999) slightly modified to handle both singleand multi-word terms. We evaluated the candidate translations of multi-word terms using a reference list compiled from publicly available resources. We found that taking discourse type into account resulted in candidate translations of a better quality even when the corpus size is reduced by half. Thus, even using a state-of-the-art alignment method wellknown as data greedy, we reached the conclusion that the quantity of data is not sufficient to obtain a terminological list of high quality and that a real comparability of corpora is required. 2 Multilin</context>
</contexts>
<marker>Rapp, 1999</marker>
<rawString>Reinhard Rapp. 1999. Automatic Identification of Word Translations from Unrelated English and German Corpora. In Proceedings of the 37th Annual Meeting ofthe Association for Computational Linguistics (ACL’99), pages 519–526, College Park, Maryland, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Robitaille</author>
<author>Xavier Sasaki</author>
<author>Masatsugu Tonoike</author>
<author>Satoshi Sato</author>
<author>Satoshi Utsuro</author>
</authors>
<title>Compiling French-Japanese Terminologies from the Web.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter ofthe Associationfor Computational Linguistics (EACL’06),</booktitle>
<pages>225--232</pages>
<location>Trento, Italy.</location>
<contexts>
<context position="11186" citStr="Robitaille et al., 2006" startWordPosition="1710" endWordPosition="1714">y using a compositional method (Grefenstette, 1999). For each element of the MWT found in the bilingual dictionary, we generate all the translated combinations identified by the term extraction program. For example, in the case of the MWT fatigue chronique (chronic fatigue), we have the following four translations for fatigue: 7the French word order is inverted to take into account the different constraints between French and Japanese. chronique fatigue Table 1: Illustration of the compositional method. The underlined Japanese MWT actually exists. bilingual dictionary. For an MWT of length , (Robitaille et al., 2006) produce all the combinations of MWU elements of a length less than or equal to . For example, the French term syndrome de fatigue chronique (chronic fatigue disease) yields the following four combinations: i) syndrome de fatigue chronique , ii) syndrome de fatigue chronique , iii) syndrome fatigue chronique and iv) syndrome fatigue chronique . We limit ourselves to the combination of type iv) above since 90% of the candidate terms provided by the term extraction process, after clustering, are only composed of two content words. 3 Linguistic resources In this section we outline the different t</context>
<context position="13194" citStr="Robitaille et al., 2006" startWordPosition="2038" endWordPosition="2042">ases are carried out manually although , , ,and the following two translations for chronique: ,. Next, we generate all combinations of translated elements (See Table 17) and select those which refer to an existing MWT in the target language. Here, only one term has been identified by the Japanese terminology extraction program: . . In this approach, when it is not possible to translate all parts of an MWT, or when the translated combinations are not identified by the term extraction program, the MWT is not taken into account in the translation process. This approach differs from that used by (Robitaille et al., 2006) for French/Japanese translation. They first decompose the French MWT into combinations of shorter multi-word units (MWU) elements. This approach makes the direct translation of a subpart of the MWT possible if it is present in the 667 research into how to automatize these two steps is ongoing. Table 2 shows the main features of the harvested comparable corpora: the number of documents, and the number of words for each language and each type of discourse. French Japanese doc. words doc. words Scientific 65 425,781 119 234,857 Popular 183 267,885 419 572,430 science Total 248 693,666 538 807,28</context>
</contexts>
<marker>Robitaille, Sasaki, Tonoike, Sato, Utsuro, 2006</marker>
<rawString>Xavier Robitaille, Xavier Sasaki, Masatsugu Tonoike, Satoshi Sato, and Satoshi Utsuro. 2006. Compiling French-Japanese Terminologies from the Web. In Proceedings of the 11th Conference of the European Chapter ofthe Associationfor Computational Linguistics (EACL’06), pages 225–232, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Salton</author>
<author>Michael E Lesk</author>
</authors>
<title>Computer evaluation of indexing and text processing.</title>
<date>1968</date>
<journal>Journal of the Association for Computational Machinery,</journal>
<volume>15</volume>
<issue>1</issue>
<contexts>
<context position="9757" citStr="Salton and Lesk, 1968" startWordPosition="1487" endWordPosition="1490">f co-occurrence units associated with the number of times that and occur together . We normalise context vectors using an association score such as Mutual Information or Log-likelihood. In order to reduce the arity of context vectors, we keep only the co-occurrences with the highest association scores. 2. Using a bilingual dictionary, we translate the lexical units of the source context vector. base form of NN pattern: /N . 666 3. For a word to be translated, we compute the similarity between the translated context vector and all target vectors through vector distance measures such as Cosine (Salton and Lesk, 1968) or Jaccard (Tanimoto, 1958). 4. The candidate translations of a lexical unit are the target lexical units closest to the translated context vector according to vector distance. 2.2.2 Translation of lexical units The translation of the lexical units of the context vectors, which depends on the coverage of the bilingual dictionary vis-à-vis the corpus, is an important step of the direct approach: more elements of the context vector are translated more the context vector will be discrimating for selecting translations in the target language. If the bilingual dictionary provides several translati</context>
</contexts>
<marker>Salton, Lesk, 1968</marker>
<rawString>Gerard Salton and Michael E. Lesk. 1968. Computer evaluation of indexing and text processing. Journal of the Association for Computational Machinery, 15(1):8–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koichi Takeuchi</author>
</authors>
<title>Kyo Kageura, Béatrice Daille, and Laurent Romary.</title>
<date>2004</date>
<booktitle>In Sophia Ananadiou and Pierre Zweigenbaum, editors, Proceeding of the COLING 2004, 3rd International Workshop on Computational Terminology (COMPUTERM’04),</booktitle>
<pages>91--94</pages>
<location>Geneva, Switzerland.</location>
<marker>Takeuchi, 2004</marker>
<rawString>Koichi Takeuchi, Kyo Kageura, Béatrice Daille, and Laurent Romary. 2004. Construction of grammar based term extraction model for japanese. In Sophia Ananadiou and Pierre Zweigenbaum, editors, Proceeding of the COLING 2004, 3rd International Workshop on Computational Terminology (COMPUTERM’04), pages 91–94, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T T Tanimoto</author>
</authors>
<title>An elementary mathematical theory of classification.</title>
<date>1958</date>
<tech>Technical report, IBM Research.</tech>
<contexts>
<context position="9785" citStr="Tanimoto, 1958" startWordPosition="1493" endWordPosition="1494">th the number of times that and occur together . We normalise context vectors using an association score such as Mutual Information or Log-likelihood. In order to reduce the arity of context vectors, we keep only the co-occurrences with the highest association scores. 2. Using a bilingual dictionary, we translate the lexical units of the source context vector. base form of NN pattern: /N . 666 3. For a word to be translated, we compute the similarity between the translated context vector and all target vectors through vector distance measures such as Cosine (Salton and Lesk, 1968) or Jaccard (Tanimoto, 1958). 4. The candidate translations of a lexical unit are the target lexical units closest to the translated context vector according to vector distance. 2.2.2 Translation of lexical units The translation of the lexical units of the context vectors, which depends on the coverage of the bilingual dictionary vis-à-vis the corpus, is an important step of the direct approach: more elements of the context vector are translated more the context vector will be discrimating for selecting translations in the target language. If the bilingual dictionary provides several translations for a lexical unit, we c</context>
</contexts>
<marker>Tanimoto, 1958</marker>
<rawString>T. T. Tanimoto. 1958. An elementary mathematical theory of classification. Technical report, IBM Research.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>