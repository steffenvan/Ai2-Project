<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.967571">
Structural Ambiguity and Conceptual Relations
</title>
<author confidence="0.969389">
Philip Resnik
</author>
<affiliation confidence="0.9938225">
Computer and Information Science
University of Pennsylvania
</affiliation>
<address confidence="0.938016">
200 South 33rd Street
Philadelphia, PA, 19104 USA
</address>
<email confidence="0.999541">
resnik@linc.cis.upenn.edu
</email>
<sectionHeader confidence="0.995707" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.9989145">
Lexical co-occurrence statistics are becoming widely used
in the syntactic analysis of unconstrained text. However, anal-
yses based solely on lexical relationships suffer from sparse-
ness of data: it is sometimes necessary to use a less informed
model in order to reliably estimate statistical parameters. For
example, the &amp;quot;lexical association&amp;quot; strategy for resolving am-
biguous prepositional phrase attachments [Hindle and Rooth.
1991) takes into account only the attachment site (a verb or its
direct object) and the preposition, ignoring the object of the
preposition.
We investigated an extension of the lexical association strat-
egy to make use of noun class information, thus permitting a
disambiguation strategy to take more information into account.
Although in preliminary experiments the extended strategy did
not yield improved performance over lexical association alone.
a qualitative analysis of the results suggests that the problem
lies not in the noun class information, but rather in the multi-
plicity of classes available for each noun in the absence of sense
disambiguation. This suggests several possible revisions of our
proposal.
</bodyText>
<sectionHeader confidence="0.935387" genericHeader="keywords">
1. Preference Strategies
</sectionHeader>
<bodyText confidence="0.9942475">
Prepositional phrase attachment is a paradigmatic case
of the structural ambiguity problems faced by natural lan-
guage parsing systems. Most models of grammar will not
constrain the analysis of such attachments in examples
like (1): the grammar simply specifies that a preposi-
tional phrase such as on computer theft can be attached
in several ways, and leaves the problem of selecting the
correct choice to some other process.
</bodyText>
<listItem confidence="0.980687">
(1) a. Eventually, Mr. Stoll was invited to both the
CIA and NSA to brief high-ranking officers
on computer theft.
b. Eventually, Mr. Stoll was invited to both the
CIA and NSA [to brief [high-ranking officers
on computer theft]).
c. Eventually, Mr. Stoll was invited to both
the CIA and NSA [to brief [high-ranking
officers] [on computer theft]].
</listItem>
<bodyText confidence="0.984945">
As [Church and Pati1,1982] point out, the number of anal-
yses given combinations of such &apos;all ways ambiguous&amp;quot;
constructions grows rapidly even for sentences Of quite
</bodyText>
<note confidence="0.763502333333333">
Marti A. Hearst
Computer Science Division
465 Evans fiall
</note>
<affiliation confidence="0.694525">
University of California, Berkeley
Berkeley, CA 94720 USA
</affiliation>
<email confidence="0.98736">
marti@cs.berkeley.edu
</email>
<bodyText confidence="0.998533133333333">
reasonable length, so this other process has an important
role to play.
Discussions of sentence processing have focused pri-
marily on structurally-based preference strategies such
as right association and minimal attachment [Kimball,
1973; Frazier. 1979; Ford et at, 1982]; [Hobbs and Bear,
19901, while acknowledging the importance of seman-
tics and pragmatics in attachment decisions, propose two
syntactically-based attachment rules that are meant to be
generalizations of those structural strategies.
Others, however, have argued that syntactic consider-
ations alone are insufficient for determining prepositional
phrase attachments, suggesting instead that preference re-
lationships among lexical items are the crucial factor. For
example:
</bodyText>
<listItem confidence="0.926410230769231">
• [Wilks er at, 1985] argue that the right attachment
rules posited by [Frazier, 1979] are incorrect for
phrases in general, and supply counterexamples.
They further argue that lexical preferences alone as
suggested by [Ford el at., 1982) are too simplistic,
and suggest instacl the use of preference semantics.
In the preference semantics framework, attachment
relations of phrases are determined by comparing the
preferences emanating from all the entities involved
in the attachment, until the best mutual fit is found.
Their CASSEX system represents the various mean-
ings of the preposition in terms of (a) the preferred
semantic class of the noun or verb that proceeds the
preposition (e.g., move, be, strike), (b) the case of the
preposition (e.g., instrument, time, toe-static), and
(c) the preferred semantic class of the head noun of
the prepositional phrase (e.g., physob, event). The
difficult part of this method is the identification of
preference relationships and particularly determin-
ing the strengths of the preferences and how they
should interact. (See also discussion in [Schubert,
1984].)
• [Dahlgren and McDowell, 1986] also suggests using
preferences based on hand-built knowledge about
the prepositions and their objects, specifying a sim-
pler set of rules than those of [Wilks et al., 1985).
</listItem>
<page confidence="0.997931">
58
</page>
<bodyText confidence="0.979704269230769">
She argues that the knowledge is needed for un-
derstanding the text as well as for parsing it. Like
CASSEX, this system requires considerable effort
to provide hand-encoded preference information.
• [Jensen and inot, 1987] resolve prepositional
phrase attachments by using preferences obtained
by applying a set of heuristic rules to dictionary def-
initions. The rules match against lexico-syntactic
patterns in the definitions — for example, if con-
fronted with the sentence She are a fish with a fork,
the system evaluates separately the plausibility of
the two proposed constructs eat with fork and fish
with fork based on how well the dictionary supports
each. By making use of on-line dictionaries, the
authors hope to create a system that will scale up;
however, they report no overall evaluation.
An empirical study by [Whittemore et at,, 1990] sup-
ports the main premise of these proposals: they observe
that in naturally-occurring data, lexical preferences (e.g.,
arrive az, flight to) provide more reliable attachment
predictions than structural strategies. Unfortunately, it
seems clear that, outside of restricted domains, hand-
encoding of preference rules will not suffice for uncon-
strained text. Information gleaned from dictionaries may
provide a solution, but the problem of how to weight and
combine preferences remains.
</bodyText>
<sectionHeader confidence="0.97114" genericHeader="introduction">
2. Lexical Association
</sectionHeader>
<bodyText confidence="0.991832905660378">
[Hindle and Rooth, 1990 offer an alternative method
for discovering and using lexical attachment preferences,
based on corpus-based lexical co-occurrence statistics.
In this section, we briefly summarize their proposal and
experimental results.
An &amp;quot;instance&amp;quot; of ambiguous prepositional phrase at-
tachment is taken to consist of a verb, its direct object,
a preposition, and the object of the preposition. Further-
more, only the heads of the respective phrases are consid-
ered; so, for example, the ambiguous attachment in (1)
would be construed as the 4-tuple (brief,officer,on,theft).1
We will refer to its elements as v, nl, p, and n2, respec-
tively.
The attachment strategy is based on an assessment of
how likely the preposition is, given each potential attach-
ment site; that is, a comparison of the values Pr(plii1)
and Pr(plu). For (1), one would expect Pr(ortibrief)
to be greater than Pr(onl officer), reflecting the intuition
that brief X on Y is more plausible as a verb phrase than
officer on Z is as a noun phrase.
Hindle and Rooth extracted their training data from a
corpus of Associated Press news stories. A robust parser
I Verbs and nouns are reduced to tiles root forms. hence officerrather
than officers.
(Hindle. 1983) was used to construct a table in which
each row contains the head noun of each noun phrase, the
preceding verb (if the noun phrase was the verb&apos;s direct
object), and the following preposition, if any occurred.
Attachment decisions for the training data in the table
were then made using a heuristic procedure — for ex-
ample, given spare it from, the procedure will count this
row as an instance of spare from rather than it from, since
a prepositional phrase cannot be attached to a pronoun.
Not all the data can be assigned with such certainty: am-
biguous cases in the training data were handled either by
using statistics collected from the unambiguous cases, by
splitting the attachment between the noun and the verb,
or by defaulting to attachment to the noun.
Given an instance of ambiguous prepositional phrase
attachment from the test set, the lexical association pro-
cedure for guessing attachments used the t-score [Church
et at., 1991] to assess the direction and significance of
the difference between Pr(plul) and Pr(plv) t will be
positive, zero, or negative according to whether Pr(pl n1)
is greater, equal to, or less than Pr(70), respectively,
and its magnitude indicates the level of confidence in die
significance of this difference.
On a set of test sentences held out from the training
data, the lexical association procedure made the correct
attachment 78.3% of the time. For choices with a high
level of confidence (magnitude oft greater than 2.1, about
70% of the time), correct attachments were made 84.5%
of the time.
</bodyText>
<sectionHeader confidence="0.961825" genericHeader="method">
3. Prepositional Objects
</sectionHeader>
<bodyText confidence="0.959951363636364">
The lexical association strategy performs quite well,
despite the fact that the object of the preposition is ig-
nored. However, Hindle and Rooth note that neglecting
this information can hurt in some cases. For instance,
the lexical association strategy is presented with exactly
the same information in (2a) and (2b), and is therefore
unable to distinguish them.
(2) a. Britain reopened its embassy in December.
b. Britain reopened its embassy in Teheran.
In addition, [Hearst and Church, in preparation] have con-
ducted a pilot study in which human subjects are asked to
guess prepositional phrase attachments despite the omis-
sion of the direct object, the object of the preposition,
or both. The results of this study, though preliminary,
suggest that the object of the preposition contributes an
amount of information comparable to that contributed by
the direct object; more important, for some prepositions,
the object of the preposition appears to be more informa-
tive.
Thus, there appears to be good reason to incorporate
the object of the preposition in lexical association calcula-
tions. The difficulty, of course. is that the data are far too
</bodyText>
<page confidence="0.993332">
59
</page>
<bodyText confidence="0.999818333333333">
sparse to permit the most obvious extension. Attempts to
simply compare Pr(p, n2.1721) against Pr(p, n217.)) using
the [-score fail dismally.2
</bodyText>
<sectionHeader confidence="0.916717" genericHeader="method">
4. Word Classes
</sectionHeader>
<bodyText confidence="0.999806404761905">
We are faced with a well-known tradeoff: increas-
ing the number of words attended to by a statistical lan-
guage model will in general tend to increase its accuracy,
but doing so increases the number of probabilities to be
estimated, leading to the need for larger (and often im-
&apos;practically larger) sets of training data in order to obtain
accurate estimates. One option is simply to pay attention
to fewer words, as do Hindle and Rooth. Another possi-
bility, however, is to reduce the number of parameters by
grouping words into equivalence classes, as discussed,
for example, by [Brown et al., 1990].
[Resnik, 1992] discusses the use of word classes
in discovering lexical relationships, demonstrating that
WordNet [Beckwith et al., 1991; Miller, 1990], a broad-
coverage, hand-constructed lexical database, provides a
reasonable foundation upon which to build class-based
statistical algorithms. Here we briefly describe WordNet,
and in the following section describe its use in resolving
prepositional phrase attachment ambiguity.
WordNet is a large lexical database organized as a set
of word taxonomies, one for each of four parts of speech
(noun, verb, adjective, and adverb). In the noun taxon-
omy, the only one used here, each word is mapped to a set
of word classes, corresponding roughly to word senses,
which Miller et al. term synonym sets. For example, the
word paper is a member of synonym sets [newspaper, pa-
per] and [composition, paper, report, theme], among oth-
ers. For notational convenience, we will refer to each
synonym set by its first word, sometimes together with a
unique identifier for example (paper, 2241323) and
(newspaper, 2202048).3
The classes in the taxonomy form the nodes of a
semantic network, with links to superordinates, subor-
dinates, antonyms, members, parts, etc. In this work
only the superordinate/subordinate (i.e., Is-A) links are
used for example, (newspaper, 2202048) is a sub-
class of (press , 2200204), which is a subclass of
(print_media, 22003 60), and so forth.
Denoting the set of words subsumed by a class c (that
is, the set of all words that are a member of c or any
subordinate class) as words(c), the frequency of a class
can be estimated as follows:
</bodyText>
<equation confidence="0.9275485">
.f(c) = E f(n) (1)
nEwards(c)
</equation>
<bodyText confidence="0.972654181818182">
2This experiment was anempted using expected likelihood esti-
mates, as in [Hindle and Rooth, 1991]. with data extracted from the
Penn Trechack as described below.
}These identifiers differ depending upon the version of WordNei
used; the work described in this paper was done using version 1.2.
Owing to multiple inheritance and word sense ambiguity,
equation (1) represents only a coarse estimate— for ex-
ample, each occurrence of a word contributes equally to
the count of all classes of which it is a member. However,
[Resnik, 1992] estimated class frequencies in a similar
fashion with acceptable results.
</bodyText>
<sectionHeader confidence="0.976604" genericHeader="method">
5. Conceptual Association
</sectionHeader>
<bodyText confidence="0.999883628571428">
In what follows, we propose to extend Hindle and
Rooth&apos;s lexical association method to take advantage of
knowledge about word-class memberships, following a
strategy one might call conceptual association. From a
practical point of view, the use of word classes reduces
the sparseness of the training data, permitting us to make
use of the object of the preposition, and also decreases
the sensitivity of the attachment strategy to the specifics
of the training corpus. From a more philosophical point
of view, using a strategy based on conceptual rather than
purely lexical relationships accords with our intuition
that, at least in many cases, much of the work done by
lexical statistics is a result of the semantic relationships
they indirectly encode.
Our proposal for conceptual association is to calculate
a measure of association using the classes to which the
direct object and object of the preposition belong, and
to select the attachment site for which the evidence of
association is strongest. The use of classes introduces
two sources of ambiguity. The first, shared by lexical
association, is word sense ambiguity: just as lexically.
based methods conflate multiple senses of a word into the
count of a single token, here each word may he mapped
to many different classes in the WordNet taxonomy. Sec-
ond, even for a single sense, a word may be classified
at many levels of abstraction — for example, even inter-
preted solely as a physical object (rather than a monetary
unit), penny may be categorized as a (coin, 3566679),
(cash,3566144), (money,3565439), and so forth on
up to (possession, 11572).
In our experiments, we adopted the simplest possible
approach: we consider each classification of the nouns
as a source of evidence about association, and combine
these sources of evidence to reach a single attachment
decision.
</bodyText>
<listItem confidence="0.78495025">
Algorithm 1. Given (v, p, ri2),
1. Let Cl = {c I 711 E words(c)}
Let C2 = ri2 E words(c)}= 1 C2, I • • - C2,N1
2. For i from 1 to N ,
</listItem>
<equation confidence="0.8320034">
= argmax 1(c; p, c2,i)
C E Cl
= i(ci,i;P, r2,i)
60
= tr, p, c2,i)
</equation>
<listItem confidence="0.911486444444444">
3. For i from 1 to N
Sr = freq(ci,i, p, c)
57 = freci(v,P, c2,i)17
4. Compute a paired samples t-test for a difference of
the means of S&amp;quot; and S. . Let &amp;quot;confidence&amp;quot; be the
significance of the test with N – I degrees of
freedom.
5. Select attachment to nl or v according to whether t
is positive or negative, respectively.
</listItem>
<bodyText confidence="0.911130183673469">
Step 1 of the algorithm establishes the range of pos-
sible classifications for n1 and n2. For example, if the
algorithm is trying to disambiguate
(3) But they foresee little substantial progress in
exports...
the word export can be classified alter-
natively as (expor t 24 8913), (c omme r ce , 244 37 o ) ,
(group_action, 241055), and (act, 10212).
In step 2, each candidate classification for n2 is held
fixed, and a classification for n 1 is chosen that maxi-
mizes the association (as measured by mutual informa-
tion) between the noun-attachment site and the preposi-
tional phrase. In effect, this answers the question, &amp;quot;If we
were to categorize n2 in this way, what would be the best
class to use for nl ?&amp;quot; This is done for each classification
of n2, yielding N different class-based interpretations for
(nl,p,n2). ./r is the noun-attachment association score
for the ith interpretation. Correspondingly, there are N
interpretations ir for (v,p,n2).
At this point, each of the N classifications for n1
(progress) and n2 (export) provides one possible interpre-
tation of (foresee.progress,in,export), and each of these
interpretations provides associational evidence in favor
of one attachment choice or the other. How are these
sources of evidence to be combined?
As a first effort, we have proceeded as follows. Each
of the values for /r and /2&apos; are not equally reliable: val-
ues calculated using classes low in the taxonomy involve
lower frequencies than those using higher-level classes.
In an attempt to assign more credit to scores calculated
using higher counts, we weight each of the mutual infor-
mation scores by the corresponding trigram frequency —
thus in step 3 the association score for noun-attachment
is calculated as the product of f (el , P, c2,1) I. The cor-
responding verb-attachment score is f (v, p, c2,1)1. This
leaves us with a table like the following:
foresee..
(situa&apos;zion) in (exp:rt) 67.4 39.8
(rise) in (commerce) 178.3 23.8
(advance) in (group_ar::. ion) 104.9 19.9
(advance) in (act 149.5 40.6
In step 4 the N different sources of evidence are com-
bined: a t-test for the difference of the means is per-
formed, treating S&amp;quot; and Sy as paired samples (see, e.g.,
(Woods et al., 19861). In step 5 the resulting value of t
determines the choice of attachment site, as well as an es-
timate of how significant the difference is between the two
alternatives. (For this example, t(3) = 3.57,p &lt; 0.05,
yielding the correct choice of attachment.)
</bodyText>
<sectionHeader confidence="0.923678" genericHeader="method">
6. Combining Strategies
</sectionHeader>
<bodyText confidence="0.999439375">
In addition to evaluating the performance of the con-
ceptual association strategy in isolation, it is natural to
combine the predictions of the lexical and conceptual as-
sociation strategies to make a single prediction. Although
well-founded strategies for combining the predictions of
multiple models do exist in the speech recognition liter-
ature [Jelinek and Mercer, 1980; Katz, 1987], we have
chosen a simpler &amp;quot;hacking off&amp;quot; style procedure:
</bodyText>
<construct confidence="0.600292">
Algorithm 2. Given (v, 7tl,p, n2),
</construct>
<listItem confidence="0.99843575">
1. Calculate an attachment decision using
Algorithm 1.
2. If significance &lt; 0.1, use this decision,
3. Otherwise, use lexical association.
</listItem>
<sectionHeader confidence="0.8383705" genericHeader="method">
7. Experimental Results
7.1. Experiment 1
</sectionHeader>
<bodyText confidence="0.999961705882353">
An experiment was conducted to evaluate the perfor-
mance of the lexical association, conceptual association,
and combined strategies. The corpus used was a collec-
tion of parses from articles in the 1988-89 Wall Street
Journal, found as part of the Penn Treebank. This corpus
is an order of magnitude smaller than the one used by
Hindle and Rooth in their experiments, but it provides
considerably less noisy data, since attachment decisions
have been performed automatically by the Fidditch parser
[Hindle, 1983) and then corrected by hand.
A test set of 201 ambiguous prepositional phrase at-
tachment instances was set aside. After acquiring attach-
ment choices on these instances from a separate judge
(who used the full sentence context in each case), the test
set was reduced by eliminating sentences for which the
separate judge disagreed with the Treebank, leaving a test
set of 174 instances!&apos;
</bodyText>
<footnote confidence="0.963229666666667">
4/24- the 348 nouns appearing as part of the test set, 12 were not
covered by WordNet ; these were classified by default as members of
the WordNet class (ent ity
</footnote>
<page confidence="0.999375">
61
</page>
<bodyText confidence="0.998356714285714">
Lexical counts for relevant prepositional phrase at-
tachments (v,p,n2 and ril,p,n2) were extracted from the
parse trees in the corpus; in addition, by analogy with Hin-
dle and Rooth&apos;s training procedure, instances of verbs and
nouns that did not have a prepositional phrase attached
were counted as occurring with the &amp;quot;null prepositional
phrase.&amp;quot; A set of clean-up steps included reducing verbs
and nouns to their root forms, mapping to lowercase, sub-
stituting the word someone for nouns not in WordNet that
were part-of-speech-tagged as proper names, substituting
the word amount for the token % (this appeared as a head
noun in phrases such as rose 10 and expanding month
abbreviations such as Jan. to the full month name.
The results of the experiment are as follows:
</bodyText>
<sectionHeader confidence="0.669119" genericHeader="method">
LA CA COMBINED
</sectionHeader>
<bodyText confidence="0.893510875">
% Correct 816 77.6 2.2
When the individual strategies were constrained to an-
swer only when confident &gt; 2.1 for lexical associa-
tion, p &lt; .1 for conceptual association), they performed
as follows:
STRATEGY ANSWERED (%) ACCURACY (%)
FLA 44.3 92.8
67.2 84.6
The performance of lexical association in this experi-
ment is striking: despite the reduced size of the training
corpus in comparison to [Hindle and Rooth, 1991], per-
formance exceeds previous results — and although fewer
test cases produce confident predictions (as might be ex-
pected given generally lower counts), when the algorithm
is confident it performs very well indeed.
The performance of the conceptual association strat-
egy seems reasonable, though it is clearly overshadowed
by the performance of the lexical association strategy.
The tiny improvement on lexical association by the com-
bined strategy suggests that including the conceptual as-
sociation strategy may improve performance overall, but
further investigation is needed to determine whether such
a conclusion is warranted; the experiments described in
the following two sections bear on this issue.
</bodyText>
<subsectionHeader confidence="0.831541">
7.2. Experiment 2
</subsectionHeader>
<bodyText confidence="0.999462142857143">
Although the particular class-based strategy imple-
mented here might not provide great leaps in performance
— at least as judged on the basis of Experiment I —
one might expect that a strategy based upon a domain-
independent semantic taxonomy would provide a greater
degree of robustness, reducing dependence of the attach-
ment strategy on the training corpus.
We set out to test this supposition by considering
the performance of the various associational attachment
strategies when tested on data from a corpus other than
the one on which they were trained. First, we tested per-
formance on a test set drawn from the same genre. Of
the test cases drawn by Hindle and Rooth from the As-
sociated Press corpus, we took the first 200; eliminating
those sentences for which Hindle and Rooth&apos;s two human
judges could not agree on an attachment reduced the set
to 173. Several minor clean-up steps were taken to make
this test set consistent with our training data: if the object
of the preposition was a complementizer or other word
introducing a sentence (e.g. begin debate on whether),
it was replaced with the word something; proper names
(e.g. Bush) were replaced with someone; some numbers
were replaced with year or amount, (e.g. 1911 and 0, re-
spectively); and &amp;quot;compound&amp;quot; prepositions were replaced
by a &amp;quot;normal&amp;quot; preposition consistent with what appeared
in the full sentence (e.g. by_about was replaced with by
for the phrase outnumbered losers by about 6 to 5).
The results of the experiment are as follows:
</bodyText>
<sectionHeader confidence="0.667032" genericHeader="method">
IA CA COMBINED
</sectionHeader>
<bodyText confidence="0.958029777777778">
% Correct 69.9 72.3 72.8
When the individual strategies were constrained to an-
swer only when confident:
The conceptual association strategy, not being as de-
pendent on the specific lexical items in the training and
test sets, sustains a somewhat higher level of overall per-
formance, although once again the lexical association
strategy performs well when restricted to the relatively
small set of predictions that it can make with confidence.
</bodyText>
<subsectionHeader confidence="0.47005">
73. Experiment 3
</subsectionHeader>
<bodyText confidence="0.983648">
Wishing to pursue the paradigm of cross-corpus test-
ing further, we conducted a third experiment in which
the training set was extracted from the Penn Treebank&apos;s
parsed version of the Brown corpus [Francis and Kucera,
1982], testing on the Wall Street Journal test set of Ex-
periment 1.
The results of the experiment are as follows:
</bodyText>
<figure confidence="0.906733">
CA ComenIED
%Correct j 77.6 73.6 793
When the individual strategies were constrained to
answer only when confident:
STRATEGY
ANSWERED (q,)
ACCURACY (%) I
31.8 80.0
49.7 77.9
LA
CA
</figure>
<page confidence="0.944449">
853
35.6
LA
81.6
CA
59.2
</page>
<table confidence="0.664521666666667">
STRATEGY
ANSWERED (%) I ACCURACY (%)
LA
</table>
<page confidence="0.997689">
62
</page>
<bodyText confidence="0.999955714285714">
In this experiment it is surprising that all the strategies
perform as well as they do. However, the pattern of re-
sults leads us to conjecture that the conceptual association
strategy, taken in combination with the lexical associa-
tion strategy, may permit us to make more effective use of
general, corpus-independent semantic relationships than
does the lexical association strategy alone.
</bodyText>
<sectionHeader confidence="0.679923" genericHeader="method">
8. Qualitative Evaluation
</sectionHeader>
<bodyText confidence="0.975968861538461">
The overall performance of the conceptual association
strategy tends to be worse than that of lexical association,
and the combined strategy yields at best a marginal im-
provement. However, several comments are in order.
First, the results in the previous section demonstrate
that conceptual association is doing some work: when the
strategies are constrained to answer only when confident,
conceptual association achieves a 50-60% increase in
coverage over lexical association, at the cost of a 3-9%
decrease in accuracy.
Second, it is clear that class information is provid-
ing some measure of resistance to sparseness of data.
As mentioned earlier, adding the object of the preposi-
tion without using noun classes leads to hopelessly sparse
data— yet the performance of the conceptual association
strategy is far from hopeless. In addition, examination of
what the conceptual association strategy actually did on
specific examples shows that in many cases it is success-
fully compensating for sparse data.
(4) To keep his schedule on track, he flies two
personal secretaries in from Little Rock lo
augment his staff in Dallas,
For example, verb augment and preposition in never co-
occur in the WSJ training corpus, and neither do noun
staff and preposition in; as a result, the lexical association
strategy makes an incorrect choice for the ambiguous
verb phrase in (4). However, the conceptual association
strategy makes the correct decision on the basis of the
following classifications:
augment... S&apos; Sy
(gathering) in (dallas) 38.18 4534
(people) in (urban..area) 1200.21 28.46
(personnel) (region) 314.62 23.38
(personnel) in (geo._area) 106.05 26.80
(people) in (city) 1161.22 28.61
(personnel) in (locatzon) 3205.8 22.83
Third, mutual information appears to be a success-
ful way to select appropriate classifications for the direct
object, given a classification of the object of the prepo-
sition (see step 2 in Algorithm 1). For example, de-
spite the fact that staff belongs to 25 classes in WordNet
— including (musical...notation, 2 3 3 2 52 8) and
jrccl, 1 6 1 3 2 9 7), for instance — the classes to which
it assigned in the above table seem appropriate given the
context of (4).
Finally, it is clear that our method for combining
sources of evidence — the paired t-test in step 4 of Al-
gorithm 1 — is hurting performance in many instances
because (a) it gives equal weight to likely and unlikely
classifications of the object of the preposition, and (b) the
significance of the test is overestimated when the object
of the preposition belongs to many different classes.
(5) Goodrich&apos;s vinyl-products segment reported
operating projitfor the quarter of $30.1 mil-
lion.
For example. given the ambiguous attachment high-
lighted in (5), the contribution of the time-related
classifications of quarter ((t ime _per iod , 4 0 1 4 2 6 3),
(time, 9 8 1 9), etc.) is swamped by numerous other
classifications in which quarter is interpreted as a physi-
cal object (coin, animal part), a number (fraction, rational
number), a unit of weight (for measuring grain), and so
forth. As a result, the conceptual association strategy
comes up with the wrong attachment and identifies its
decision as a confident one.
</bodyText>
<sectionHeader confidence="0.997644" genericHeader="conclusions">
9. Conclusions
</sectionHeader>
<bodyText confidence="0.999985423076923">
The conceptual association strategy described here
leaves room for a number of improvements. The use
of mutual information as an association measure, and the
weighting of the mutual information score in order to bias
the computation in favor of large counts, warrant further
consideration — mutual information has been criticized
for, among other things, its poor behavior given low fre-
quencies, and an alternative measures of association may
prove better.
In addition, as noted in the previous section, com-
bining evidence using the paired t-test is problematic,
essentially because of word-sense ambiguity. One al-
ternative might be to perform sense disambiguation in
advance — the results of [Yarowsky, 1 9931 demonstrate
that a significant reduction in the number of possible
noun classifications is possible using only very limited
syntactic context, rather than global word co-occurrence
statistics. Another related alternative would be to select a
single best classification — for example, using the mea-
sure of selectional association proposed in [Resnik, 1993)
— rather than considering all possible classifications.
Another possibility to investigate is the incorporation
of structurally-based attachment strategies along with
lexical and conceptual association. Such a fusion of
structural and lexical preference strategies is suggested in
[Whittemore eral., 19901, and (Weischedel et aL, 1989)
</bodyText>
<page confidence="0.998155">
63
</page>
<bodyText confidence="0.999938954545455">
have found that a structural strategy (closest attach-
ment&amp;quot;) performs well in combination with a class-based
strategy, although they use a relatively small, domain-
specific taxonomy of classes and assume each word has
a pointer to a unique class.
Still another direction for future work involves the
application of similar techniques to other problems like
prepositional phrase attachment for which the resolu-
tion of ambiguities would seem to require some form
of semantic knowledge. The problems discussed in
[Church and Patil, 1982] — including ambiguous prepo-
sitional phrase attachment, noun-noun modification, and
coordination — would seem to form a natural class
of problems to investigate in this manner. Although
there will always be ambiguities that can be resolved
only by appeal to complex inferences or highly domain-
dependent facts, we believe the combination of domain-
independent, knowledge-based resources such as Word-
Net with Corpus-based statistics may provide the seman-
tic power necessary for solving many instances of such
problems, without the need for general reasoning about
world knowledge.
</bodyText>
<sectionHeader confidence="0.997243" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9978608125">
[Beckwith et at, 1991] Richard Beckwith, Christiane Fell-
baum, Derek Gross. and George Miller. WordNet: A
lexical database organized on psycholinguistic principles.
In Uri Zemik, editor, Lexical Acquisition: Exploiting On-
Line Resources to Build a Lexicon. pages 211-232. Erl-
baum, 1991.
[Brown et al., 1990] Peter F. Brown, Vincent J. Della Picini,
Peter V. deSouza. and Robert L. Mercer. Class-based
n-gram models of natural language. In Proceedings of
the IBM Natural Language ITL. pages 283-298. Paris,
France, March 1990.
[Church and Patil, 1982] Kenneth W. Church and Ramesh
Patil. Coping with syntactic ambiguity or how to put
the block in the box on the table. American Journal of
Computational Linguistics, 8(3-4):139-149, 1982.
[Church et at., 1991] Kenneth Church. William Gale. Patrick
Hanks, and Donald Hindle. Using statistics in lexical anal-
ysis. In Uri Zemik, editor, Lexical Acquisition: Exploit-
ing On-Line Resources to Build a Lexicon,pages 116-164.
Erlbaum, 1991.
[Dahlgren and McDowell, 1986) K. Dahlgren and). McDow-
ell. Using commonsense knowledge to disambiguate
prepositional phrase modifiers. In AAA1-86, pages 589-
593, 1986.
[Ford et aL, 1982) Marilyn Ford, Joan Bresnan, and Ronald
Kaplan. A competence-based theory of syntactic closure.
In Joan Bresnan, editor, The Mental Representation of
Granunaiical Relations. MIT Press, 1982.
[Francis and Kneen. 1982] W. Francis and H. Kucem. Fre-
quencyAnalysis of English Usage. Houghton Mifflin Co.:
New York. 1982.
[Frazier, 1979] L. Frazier. On comprehending Sentences: Syn-
tactic Parsing Strategies. PhD thesis, University of Mas-
sachusetts, 1979.
[Hearst and Church: in preparation] Marti A. Hearst and Ken-
neth W Church. An investigation of the use of lexi-
cal associations for prepositional phrase attactunent. (in
preparation).
[Hindle and Rooth, 1991] D. Hindle and M. Rooth. Structural
ambiguity and lexical relations. In Proceedings of the
29th Annual Meeting ofthe Association for Computational
Linguistics, June 1991. Berkeley, California.
[Hindle, 1983] Donald Hindle. User manual for Fidditch. a
deterministic parser. Technical memorandum 7590-142.
Naval Research Laboratory, 1983.
[Hobbs and Bear, 1990] Jerry R. Hobbs and John Bear. Two
principles of parse preference_ In Proceedings of 13th
COLING. pages 162-167. Helsinki, 1990.
[Jelinek and Mercer, 1980] Frederick Jelinek and Robert L.
Mercer. Interpolated estimation of Markov source pa-
rameters from sparse data. In Proceedings of the Work-
shop on Pattern Recognition in Practice, Amsterdam, The
Netherlands: North-Holland, May 1980.
[Jensen and Binot. 1987] Karen Jensen and Jean-Louis Binot.
Disambiguating prepositional phrase attachments by us-
ing on-line dictionary definitions. American Journal of
Computational Linguistics. I 3(3)1251-260, 1987.
[Katz. 1987] Slava M. Katz. Estimation of probabilities from
sparse data for the Ian gau ge model component of a speech
recognizer. IEEE Transactions on Acoustics. Speech and
Signal Processing. ASSP-35(3):400-401, March 1987.
[Kimball. 1973] John Kimball. Seven principles of surface
structure parsing in natural language. Cognition, 2:15-
47, 1973.
[Miller, 1990] George Miller. Wordnet: An on-line lexical
database. International Journal of Lexicography, 3(4),
1990. (Special Issue).
[Resnik. 1992] Philip Resnik. WordNet and distributional
analysis: A class-based approach to lexical discovery. in
AAA] Workshop on Statistically-based NLP Techniques,
San Jose, California. July 1992.
[Resnik. 1993] Philip Resnik. Semantic classes and syntactic
ambiguity. ARPA Workshop on Human Language Tech-
nology, March 1993. Princeton.
(Schubert, 1984] Lenhart Schubert. On parsing preferences.
In COLING-84, 1984.
[Weischedel et at., 1989] Ralph Weischedel, Marie Meteer,
Richard Schwartz, and Jeff Pahnucci. Coping with ambi-
guity and unknown words through probabilistic models.
ms., 1989.
[Whittemore a al.. 19901 Greg Whittemore, Kathleen Ferrara.
and Hans Brunner. Empirical study of predictive powers
of simple attachment schemes for post-modifier preposi-
tional phrases. In Proceedings of the 28th Annual Meeting
of the Association for Computational Linguistics, pages
23-30. 1990. Pittsburgh, Pennsylvania.
Milks el&apos; al.. 19851 Yorick Wilks, Xiuming Huang. and Dan
Pass. Syntax, preference and right attachment. InLICA1-
85. pages 779-784.1985.
[Woods et at. 1986] Anthony Woods, Paul Fletcher, and
Arthur Hughes. Statistics in Language Studies. Cam-
bridge Textbooks in Linguistics. Cambridge University
Press: Cambridge. England. 1986.
[Yarowsky. 1993) David Yarowsky. One sense per colloca-
tion. ARPA Workshop on Human Language Technology,
March 1993. Princeton.
</reference>
<page confidence="0.999419">
64
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000023">
<title confidence="0.999878">Structural Ambiguity and Conceptual Relations</title>
<author confidence="0.999983">Philip Resnik</author>
<affiliation confidence="0.9991225">Computer and Information Science University of Pennsylvania</affiliation>
<address confidence="0.998834">200 South 33rd Street Philadelphia, PA, 19104 USA</address>
<email confidence="0.999783">resnik@linc.cis.upenn.edu</email>
<abstract confidence="0.994226756097561">Lexical co-occurrence statistics are becoming widely used in the syntactic analysis of unconstrained text. However, analyses based solely on lexical relationships suffer from sparseof data: it is sometimes necessary to less informed model in order to reliably estimate statistical parameters. For example, the &amp;quot;lexical association&amp;quot; strategy for resolving ambiguous prepositional phrase attachments [Hindle and Rooth. takes into account only attachment site (a verb or its object) the preposition, ignoring the object of the preposition. We investigated an extension of the lexical association strategy to make use of noun class information, thus permitting a disambiguation strategy to take more information into account. Although in preliminary experiments the extended strategy did not yield improved performance over lexical association alone. analysis of the results suggests that the problem lies not in the noun class information, but rather in the multiplicity of classes available for each noun in the absence of sense disambiguation. This suggests several possible revisions of our proposal. 1. Preference Strategies phrase attachment is a of the structural ambiguity problems faced by natural language parsing systems. Most models of grammar will not constrain the analysis of such attachments in examples like (1): the grammar simply specifies that a preposiphrase such as computer theft attached in several ways, and leaves the problem of selecting the correct choice to some other process. (1) a. Eventually, Mr. Stoll was invited to both the CIA and NSA to brief high-ranking officers on computer theft. b. Eventually, Mr. Stoll was invited to both the CIA and NSA [to brief [high-ranking officers on computer theft]). c. Eventually, Mr. Stoll was invited to both the CIA and NSA [to brief [high-ranking officers] [on computer theft]]. As [Church and Pati1,1982] point out, the number of analyses given combinations of such &apos;all ways ambiguous&amp;quot;</abstract>
<title confidence="0.749194">grows rapidly even for sentences</title>
<author confidence="0.999638">Marti A Hearst</author>
<affiliation confidence="0.999963">Computer Science Division</affiliation>
<address confidence="0.987331">465 Evans fiall</address>
<affiliation confidence="0.987079">University of California, Berkeley</affiliation>
<address confidence="0.989412">Berkeley, CA 94720 USA</address>
<email confidence="0.992226">marti@cs.berkeley.edu</email>
<abstract confidence="0.999335707112971">length, so this other process important role to play. Discussions of sentence processing have focused primarily on structurally-based preference strategies such as right association and minimal attachment [Kimball, Frazier. 1979; Ford at, [Hobbs and Bear, while acknowledging the importance semanin attachment decisions, propose two syntactically-based attachment rules that are meant to be generalizations of those structural strategies. Others, however, have argued that syntactic considerations alone are insufficient for determining prepositional phrase attachments, suggesting instead that preference relationships among lexical items are the crucial factor. For example: [Wilks argue that the right attachment rules posited by [Frazier, 1979] are incorrect for phrases in general, and supply counterexamples. They further argue that lexical preferences alone as by [Ford at., are too simplistic, and suggest instacl the use of preference semantics. In the preference semantics framework, attachment relations of phrases are determined by comparing the preferences emanating from all the entities involved in the attachment, until the best mutual fit is found. Their CASSEX system represents the various meanings of the preposition in terms of (a) the preferred semantic class of the noun or verb that proceeds the (e.g., be, strike), the case of the (e.g., time, (c) the preferred semantic class of the head noun of prepositional phrase (e.g., event). difficult part of this method is the identification of preference relationships and particularly determinstrengths of the preferences and how should interact. (See also discussion in [Schubert, 1984].) • [Dahlgren and McDowell, 1986] also suggests using preferences based on hand-built knowledge about the prepositions and their objects, specifying a simset of rules than those of [Wilks al., 58 She argues that the knowledge is needed for understanding the text as well as for parsing it. Like CASSEX, this system requires considerable effort to provide hand-encoded preference information. • [Jensen and inot, 1987] resolve phrase attachments by using preferences obtained by applying a set of heuristic rules to dictionary definitions. The rules match against lexico-syntactic patterns in the definitions — for example, if conwith the sentence are a fish with a fork, the system evaluates separately the plausibility of two proposed constructs with fork fork on how well the dictionary supports each. By making use of on-line dictionaries, the authors hope to create a system that will scale up; however, they report no overall evaluation. empirical study by [Whittemore at,, supports the main premise of these proposals: they observe that in naturally-occurring data, lexical preferences (e.g., az, flight to) more reliable attachment predictions than structural strategies. Unfortunately, it seems clear that, outside of restricted domains, handencoding of preference rules will not suffice for unconstrained text. Information gleaned from dictionaries may provide a solution, but the problem of how to weight and combine preferences remains. 2. Lexical Association [Hindle and Rooth, 1990 offer an alternative method for discovering and using lexical attachment preferences, based on corpus-based lexical co-occurrence statistics. In this section, we briefly summarize their proposal and experimental results. An &amp;quot;instance&amp;quot; of ambiguous prepositional phrase attachment is taken to consist of a verb, its direct object, a preposition, and the object of the preposition. Furthermore, only the heads of the respective phrases are considered; so, for example, the ambiguous attachment in (1) be construed as the 4-tuple We will refer to its elements as v, nl, p, and n2, respectively. The attachment strategy is based on an assessment of how likely the preposition is, given each potential attachment site; that is, a comparison of the values Pr(plii1) Pr(plu). For (1), one would expect be greater than Pr(onl the intuition X on is more plausible as a verb phrase on Z as a noun phrase. Hindle and Rooth extracted their training data from a Associated Press A robust parser I Verbs and nouns are reduced to tiles root forms. hence officerrather (Hindle. 1983) was used to construct a table in which each row contains the head noun of each noun phrase, the verb (if the noun phrase was direct and the following preposition, any Attachment decisions for the training data in the table were then made using a heuristic procedure — for exit from, procedure will count as an instance of from than from, a prepositional phrase cannot be attached to a pronoun. Not all the data can be assigned with such certainty: ambiguous cases in the training data were handled either by using statistics collected from the unambiguous cases, by splitting the attachment between the noun and the verb, or by defaulting to attachment to the noun. Given an instance of ambiguous prepositional phrase attachment from the test set, the lexical association procedure for guessing attachments used the t-score [Church at., to assess the direction and significance of the difference between Pr(plul) and Pr(plv) t will positive, zero, or negative according to whether Pr(pl n1) is greater, equal to, or less than Pr(70), respectively, and its magnitude indicates the level of confidence in die significance of this difference. On a set of test sentences held out from the training data, the lexical association procedure made the correct attachment 78.3% of the time. For choices with a high level of confidence (magnitude oft greater than 2.1, about 70% of the time), correct attachments were made 84.5% of the time. 3. Prepositional Objects The lexical association strategy performs quite well, the fact that the object of preposition is ignored. However, Hindle and Rooth note that neglecting this information can hurt in some cases. For instance, the lexical association strategy is presented with exactly same in (2a) and (2b), and is therefore unable to distinguish them. (2) a. Britain reopened its embassy in December. b. Britain reopened its embassy in Teheran. [Hearst and Church, preparation] conducted a pilot study in which human subjects are asked to guess prepositional phrase attachments despite the omission of the direct object, the object of the preposition, or both. The results of this study, though preliminary, suggest that the object of the preposition contributes an amount of information comparable to that contributed by more important, for some prepositions, object of the preposition appears to be informative. Thus, there appears to be good reason to incorporate the object of the preposition in lexical association calculations. The difficulty, of course. is that the data are far too 59 to permit the most obvious extension. Attempts simply compare Pr(p, n2.1721) against Pr(p, n217.)) using [-score fail 4. Word Classes We are faced with a well-known tradeoff: increasing the number of words attended to by a statistical language model will in general tend to increase its accuracy, but doing so increases the number of probabilities to be estimated, leading to the need for larger (and often im- &apos;practically larger) sets of training data in order to obtain accurate estimates. One option is simply to pay attention to fewer words, as do Hindle and Rooth. Another possibility, however, is to reduce the number of parameters by grouping words into equivalence classes, as discussed, example, by [Brown al., [Resnik, 1992] discusses the use of word classes in discovering lexical relationships, demonstrating that [Beckwith al., Miller, 1990], a broadcoverage, hand-constructed lexical database, provides a reasonable foundation upon which to build class-based statistical algorithms. Here we briefly describe WordNet, and in the following section describe its use in resolving prepositional phrase attachment ambiguity. WordNet is a large lexical database organized as a set of word taxonomies, one for each of four parts of speech (noun, verb, adjective, and adverb). In the noun taxonomy, the only one used here, each word is mapped to a set of word classes, corresponding roughly to word senses, Miller al. term synonym sets. example, the is member of synonym sets papaper, report, theme], others. For notational convenience, we will refer to each synonym set by its first word, sometimes together with a example The classes in the taxonomy form the nodes of a semantic network, with links to superordinates, subordinates, antonyms, members, parts, etc. In this work only the superordinate/subordinate (i.e., Is-A) links are for example, a of , which is a subclass of 22003 60), so forth. the set of words subsumed by a class the set of all words that are a member of any subordinate class) as words(c), the frequency of a class estimated as follows: (1) nEwards(c) experiment was anempted using expected likelihood estimates, as in [Hindle and Rooth, 1991]. with data extracted from the Penn Trechack as described below. differ depending upon the version of WordNei used; the work described in this paper was done using version 1.2. Owing to multiple inheritance and word sense ambiguity, equation (1) represents only a coarse estimate— for example, each occurrence of a word contributes equally to the count of all classes of which it is a member. However, [Resnik, 1992] estimated class frequencies in a similar fashion with acceptable results. 5. Conceptual Association In what follows, we propose to extend Hindle and Rooth&apos;s lexical association method to take advantage of knowledge about word-class memberships, following a one might call association. a practical point of view, the use of word classes reduces the sparseness of the training data, permitting us to make use of the object of the preposition, and also decreases the sensitivity of the attachment strategy to the specifics of the training corpus. From a more philosophical point of view, using a strategy based on conceptual rather than lexical accords with our intuition at least in many cases, much of work done by lexical statistics is a result of the semantic relationships they indirectly encode. Our proposal for conceptual association is to calculate a measure of association using the classes to which the direct object and object of the preposition belong, and to select the attachment site for which the evidence of is strongest. The classes introduces two sources of ambiguity. The first, shared by lexical association, is word sense ambiguity: just as lexically. based methods conflate multiple senses of a word into the count of a single token, here each word may he mapped to many different classes in the WordNet taxonomy. Second, even for a single sense, a word may be classified at many levels of abstraction — for example, even interpreted solely as a physical object (rather than a monetary be categorized as a (money,3565439), so forth on to 11572). In our experiments, we adopted the simplest possible we consider of the nouns as a source of evidence about association, and combine these sources of evidence to reach a single attachment decision.</abstract>
<note confidence="0.859212">1. Given (v, ri2), Let Cl = I words(c)} C2 = ri2 words(c)}= I • • - For i from 1 to , = argmax 1(c; p, c2,i) Cl r2,i) 60 = tr, p, c2,i) For i from 1 to</note>
<abstract confidence="0.988167446153847">freq(ci,i, p, c) = freci(v,P, 4. Compute a paired samples t-test for a difference of means of S.. Let &amp;quot;confidence&amp;quot; be the of the test with of freedom. 5. Select attachment to nl or v according to whether t is positive or negative, respectively. Step 1 of the algorithm establishes the range of possible classifications for n1 and n2. For example, if the algorithm is trying to disambiguate But they foresee little substantial progress exports... word be classified alteras t 24 8913), (c omme r ce , 244 37 ) , 241055), 10212). In step 2, each candidate classification for n2 is held fixed, and a classification for n 1 is chosen that maximizes the association (as measured by mutual information) between the noun-attachment site and the prepositional phrase. In effect, this answers the question, &amp;quot;If we to categorize n2 in this way, what would best class to use for nl ?&amp;quot; This is done for each classification n2, yielding class-based interpretations for (nl,p,n2). ./r is the noun-attachment association score the ith interpretation. Correspondingly, there are interpretations ir for (v,p,n2). this point, each of the for n1 n2 one possible interpreof each of these interpretations provides associational evidence in favor of one attachment choice or the other. How are these sources of evidence to be combined? As a first effort, we have proceeded as follows. Each of the values for /r and /2&apos; are not equally reliable: values calculated using classes low in the taxonomy involve lower frequencies than those using higher-level classes. In an attempt to assign more credit to scores calculated using higher counts, we weight each of the mutual information scores by the corresponding trigram frequency — thus in step 3 the association score for noun-attachment calculated as the product of , P, c2,1) I. The corverb-attachment score is p, This us with a table following: foresee.. (situa&apos;zion) in (exp:rt) 67.4 39.8 (rise) in (commerce) 178.3 23.8 (advance) in (group_ar::. ion) 104.9 19.9 (advance) in (act 149.5 40.6 In step 4 the N different sources of evidence are combined: a t-test for the difference of the means is pertreating S&amp;quot; and as paired samples (see, e.g., al., 19861). step 5 the resulting value of t determines the choice of attachment site, as well as an estimate of how significant the difference is between the two alternatives. (For this example, t(3) = 3.57,p &lt; 0.05, yielding the correct choice of attachment.) 6. Combining Strategies In addition to evaluating the performance of the conceptual association strategy in isolation, it is natural to combine the predictions of the lexical and conceptual association strategies to make a single prediction. Although well-founded strategies for combining the predictions of multiple models do exist in the speech recognition literature [Jelinek and Mercer, 1980; Katz, 1987], we have chosen a simpler &amp;quot;hacking off&amp;quot; style procedure: 2. Given (v, n2), 1. Calculate an attachment decision using Algorithm 1. If significance &lt; 0.1, decision, 3. Otherwise, use lexical association. 7. Experimental Results 7.1. Experiment 1 An experiment was conducted to evaluate the performance of the lexical association, conceptual association, and combined strategies. The corpus used was a collecof parses from articles in the 1988-89 Street as part of the This corpus is an order of magnitude smaller than the one used by Hindle and Rooth in their experiments, but it provides less noisy attachment decisions have been performed automatically by the Fidditch parser [Hindle, 1983) and then corrected by hand. test set of 201 ambiguous prepositional phrase atwas set aside. After acquiring attachment choices on these instances from a separate judge (who used the full sentence context in each case), the test set was reduced by eliminating sentences for which the separate judge disagreed with the Treebank, leaving a test set of 174 instances!&apos; the 348 nouns as of the 12 were not covered by WordNet ; these were classified by default as members of the WordNet class (ent ity 61 Lexical counts for relevant prepositional phrase attachments (v,p,n2 and ril,p,n2) were extracted from the parse trees in the corpus; in addition, by analogy with Hindle and Rooth&apos;s training procedure, instances of verbs and nouns that did not have a prepositional phrase attached were counted as occurring with the &amp;quot;null prepositional phrase.&amp;quot; A set of clean-up steps included reducing verbs and nouns to their root forms, mapping to lowercase, subthe word nouns not in WordNet that were part-of-speech-tagged as proper names, substituting word the % (this appeared as a head in phrases such as 10 expanding such as the full month name. The results of the experiment are as follows: LA CA COMBINED % Correct 816 77.6 2.2 strategies were constrained to anonly when confident &gt; 2.1 for lexical tion, p &lt; .1 for conceptual association), they performed as follows: STRATEGY ANSWERED (%) ACCURACY (%) FLA 44.3 92.8 67.2 84.6 The performance of lexical association in this experiment is striking: despite the reduced size of the training corpus in comparison to [Hindle and Rooth, 1991], performance exceeds previous results — and although fewer test cases produce confident predictions (as might be expected given generally lower counts), when the algorithm is confident it performs very well indeed. The performance of the conceptual association strategy seems reasonable, though it is clearly overshadowed by the performance of the lexical association strategy. The tiny improvement on lexical association by the combined strategy suggests that including the conceptual association strategy may improve performance overall, but further investigation is needed to determine whether such a conclusion is warranted; the experiments described in the following two sections bear on this issue. 7.2. Experiment 2 Although the particular class-based strategy implehere might not provide great leaps — at least as judged on the basis of Experiment I — one might expect that a strategy based upon a domainindependent semantic taxonomy would provide a greater degree of robustness, reducing dependence of the attachment strategy on the training corpus. We set out to test this supposition by considering the performance of the various associational attachment when tested on data from a than the one on which they were trained. First, we tested performance on a test set drawn from the same genre. Of the test cases drawn by Hindle and Rooth from the Associated Press corpus, we took the first 200; eliminating those sentences for which Hindle and Rooth&apos;s two human could not agree on an attachment reduced the to 173. Several minor clean-up steps were taken to make this test set consistent with our training data: if the object of the preposition was a complementizer or other word a sentence (e.g. debate on replaced with the word names Bush) were replaced with numbers replaced with 1911 and 0, respectively); and &amp;quot;compound&amp;quot; prepositions were replaced by a &amp;quot;normal&amp;quot; preposition consistent with what appeared the full sentence (e.g. replaced with the phrase losers by about 6 to 5). The results of the experiment are as follows: % Correct 69.9 72.3 72.8 When the individual strategies were constrained to answer only when confident: The conceptual association strategy, not being as dependent on the specific lexical items in the training and test sets, sustains a somewhat higher level of overall performance, although once again the lexical association strategy performs well when restricted to the relatively small set of predictions that it can make with confidence. 73. Experiment 3 Wishing to pursue the paradigm of cross-corpus testing further, we conducted a third experiment in which the training set was extracted from the Penn Treebank&apos;s parsed version of the Brown corpus [Francis and Kucera, testing on the Street Journal set of Experiment 1. of the experiment are as follows: %Correct j 77.6 73.6 793 When the individual strategies were constrained to answer only when confident: STRATEGY (%) 31.8 80.0 49.7 77.9 LA CA 853 35.6 LA 81.6 CA 59.2 STRATEGY (%) (%) LA 62 In this experiment it is surprising that all the strategies perform as well as they do. However, the pattern of results leads us to conjecture that the conceptual association strategy, taken in combination with the lexical association strategy, may permit us to make more effective use of general, corpus-independent semantic relationships than does the lexical association strategy alone. 8. Qualitative Evaluation The overall performance of the conceptual association strategy tends to be worse than that of lexical association, and the combined strategy yields at best a marginal improvement. However, several comments are in order. First, the results in the previous section demonstrate that conceptual association is doing some work: when the strategies are constrained to answer only when confident, conceptual association achieves a 50-60% increase in coverage over lexical association, at the cost of a 3-9% decrease in accuracy. Second, it is clear that class information is providing some measure of resistance to sparseness of data. As mentioned earlier, adding the object of the preposinoun classes leads to hopelessly sparse data— yet the performance of the conceptual association strategy is far from hopeless. In addition, examination of what the conceptual association strategy actually did on specific examples shows that in many cases it is successfully compensating for sparse data. (4) To keep his schedule on track, he flies two personal secretaries in from Little Rock lo augment his staff in Dallas, example, verb preposition cooccur in the WSJ training corpus, and neither do noun preposition in; as a result, the lexical association strategy makes an incorrect choice for the ambiguous verb phrase in (4). However, the conceptual association strategy makes the correct decision on the basis of the following classifications: augment... S&apos; Sy (gathering) in (dallas) 38.18 4534 (people) in (urban..area) 1200.21 28.46 (personnel) (region) 314.62 23.38 (personnel) in (geo._area) 106.05 26.80 (people) in (city) 1161.22 28.61 (personnel) in (locatzon) 3205.8 22.83 Third, mutual information appears to be a successful way to select appropriate classifications for the direct given a classification of the object preposition (see step 2 in Algorithm 1). For example, dethe fact staff to 25 classes in WordNet 2 3 3 8) jrccl, 1 6 1 3 2 9 7), for instance — the classes to which it assigned in the above table seem appropriate given the context of (4). it is clear method for combining sources of evidence — the paired t-test in step 4 of Algorithm 1 — is hurting performance in many instances because (a) it gives equal weight to likely and unlikely classifications of the object of the preposition, and (b) the significance of the test is overestimated when the object of the preposition belongs to many different classes. Goodrich&apos;s vinyl-products segment projitfor the quarter $30.1 million. For example. given the ambiguous attachment highlighted in (5), the contribution of the time-related of ((t _per iod , 4 0 1 4 2 6 3), 8 1 9), etc.) is swamped by numerous other in which interpreted as a physiobject part), a number (fraction, rational number), a unit of weight (for measuring grain), and so result, the conceptual association strategy comes up with the wrong attachment and identifies its decision as a confident one. 9. Conclusions The conceptual association strategy described here leaves room for a number of improvements. The use of mutual information as an association measure, and the weighting of the mutual information score in order to bias the computation in favor of large counts, warrant further consideration — mutual information has been criticized other things, its poor behavior given low frequencies, and an alternative measures of association may prove better. In addition, as noted in the previous section, combining evidence using the paired t-test is problematic, essentially because of word-sense ambiguity. One alternative might be to perform sense disambiguation in advance — the results of [Yarowsky, 1 9931 demonstrate that a significant reduction in the number of possible noun classifications is possible using only very limited syntactic context, rather than global word co-occurrence statistics. Another related alternative would be to select a — for example, using the measure of selectional association proposed in [Resnik, 1993) — rather than considering all possible classifications. Another possibility to investigate is the incorporation of structurally-based attachment strategies along with lexical and conceptual association. Such a fusion of structural and lexical preference strategies is suggested in and (Weischedel et 63 found that a structural strategy attachwell in combination with a class-based strategy, although they use a relatively small, domainspecific taxonomy of classes and assume each word has a pointer to a unique class. Still another direction for future work involves the application of similar techniques to other problems like prepositional phrase attachment for which the resolution of ambiguities would seem to require some form of semantic knowledge. The problems discussed in [Church and Patil, 1982] — including ambiguous prepositional phrase attachment, noun-noun modification, and coordination — would seem to form a natural class of problems to investigate in this manner. Although there will always be ambiguities that can be resolved only by appeal to complex inferences or highly domaindependent facts, we believe the combination of domainresources such as Word- Net with Corpus-based statistics may provide the semanpower necessary for solving many instances of need for general reasoning about world knowledge. References at, Richard Beckwith, Christiane Fellbaum, Derek Gross. and George Miller. WordNet: A lexical database organized on psycholinguistic principles.</abstract>
<note confidence="0.898676">Uri Zemik, editor, Acquisition: Exploiting On- Resources to Build a Lexicon. 211-232. Erlbaum, 1991.</note>
<author confidence="0.666252">Robert L Mercer Class-based</author>
<note confidence="0.906507878787879">models of natural language. In of IBM Natural Language 283-298. Paris, France, March 1990. [Church and Patil, 1982] Kenneth W. Church and Ramesh Patil. Coping with syntactic ambiguity or how to put block in the box on the table. Journal of Linguistics, 1982. at., Kenneth Church. William Patrick Hanks, and Donald Hindle. Using statistics in lexical anal- In Uri Zemik, editor, Acquisition: Exploit- On-Line Resources to Build a Lexicon,pages Erlbaum, 1991. [Dahlgren and McDowell, 1986) K. Dahlgren and). McDowell. Using commonsense knowledge to disambiguate phrase modifiers. In 589- 593, 1986. aL, Marilyn Ford, Joan Bresnan, and Ronald Kaplan. A competence-based theory of syntactic closure. Joan Bresnan, editor, Mental Representation of Relations. Press, 1982. and Kneen. 1982] W. Francis and H. Kucem. Freof English Usage. Mifflin Co.: New York. 1982. 1979] L. Frazier. comprehending Sentences: Syn- Parsing Strategies. thesis, University of Mas- [Hearst and Church: in preparation] Marti A. Hearst and Kenneth W Church. An investigation of the use of lexical associations for prepositional phrase attactunent. (in preparation). [Hindle and Rooth, 1991] D. Hindle and M. Rooth. Structural and lexical relations. Proceedings of the 29th Annual Meeting ofthe Association for Computational 1991. Berkeley, California. [Hindle, 1983] Donald Hindle. User manual for Fidditch. a deterministic parser. Technical memorandum 7590-142. Naval Research Laboratory, 1983. [Hobbs and Bear, 1990] Jerry R. Hobbs and John Bear. Two of parse preference_ In of 13th 162-167. Helsinki, 1990. [Jelinek and Mercer, 1980] Frederick Jelinek and Robert L. Mercer. Interpolated estimation of Markov source pafrom sparse data. In of the Workon Pattern Recognition in Practice, The Netherlands: North-Holland, May 1980. [Jensen and Binot. 1987] Karen Jensen and Jean-Louis Binot. Disambiguating prepositional phrase attachments by uson-line dictionary definitions. Journal of Linguistics. I [Katz. 1987] Slava M. Katz. Estimation of probabilities from sparse data for the Ian gau ge model component of a speech Transactions on Acoustics. Speech and Processing. March 1987. [Kimball. 1973] John Kimball. Seven principles of surface parsing in natural Cognition, 2:15- 47, 1973. [Miller, 1990] George Miller. Wordnet: An on-line lexical Journal of Lexicography, 1990. (Special Issue). [Resnik. 1992] Philip Resnik. WordNet and distributional analysis: A class-based approach to lexical discovery. in AAA] Workshop on Statistically-based NLP Techniques, San Jose, California. July 1992. [Resnik. 1993] Philip Resnik. Semantic classes and syntactic ambiguity. ARPA Workshop on Human Language Technology, March 1993. Princeton. (Schubert, 1984] Lenhart Schubert. On parsing preferences.</note>
<title confidence="0.193415">at., Ralph Weischedel, Marie Meteer,</title>
<author confidence="0.508626">Coping with ambi-</author>
<abstract confidence="0.975299">guity and unknown words through probabilistic models. ms., 1989. al.. Whittemore, Kathleen Ferrara. and Hans Brunner. Empirical study of predictive powers of simple attachment schemes for post-modifier preposiphrases. In of the 28th Annual Meeting</abstract>
<affiliation confidence="0.74445">the Association for Computational Linguistics,</affiliation>
<address confidence="0.929799">23-30. 1990. Pittsburgh, Pennsylvania.</address>
<note confidence="0.80150725">al.. Yorick Wilks, Xiuming Huang. and Dan Syntax, preference and right attachment. 779-784.1985. at. Anthony Woods, Paul Fletcher, and Hughes. in Language Studies. Cambridge Textbooks in Linguistics. Cambridge University Press: Cambridge. England. 1986. [Yarowsky. 1993) David Yarowsky. One sense per colloca-</note>
<affiliation confidence="0.899744">tion. ARPA Workshop on Human Language Technology,</affiliation>
<address confidence="0.7927125">March 1993. Princeton. 64</address>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>George Miller</author>
</authors>
<title>WordNet: A lexical database organized on psycholinguistic principles.</title>
<date>1991</date>
<booktitle>In Uri Zemik, editor, Lexical Acquisition: Exploiting OnLine Resources to Build a Lexicon.</booktitle>
<pages>211--232</pages>
<publisher>Erlbaum,</publisher>
<marker>[Beckwith et at, 1991]</marker>
<rawString>Richard Beckwith, Christiane Fellbaum, Derek Gross. and George Miller. WordNet: A lexical database organized on psycholinguistic principles. In Uri Zemik, editor, Lexical Acquisition: Exploiting OnLine Resources to Build a Lexicon. pages 211-232. Erlbaum, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert L Mercer</author>
</authors>
<title>Class-based n-gram models of natural language.</title>
<date>1990</date>
<booktitle>In Proceedings of the IBM Natural Language ITL.</booktitle>
<pages>283--298</pages>
<location>Paris, France,</location>
<marker>[Brown et al., 1990]</marker>
<rawString>Peter F. Brown, Vincent J. Della Picini, Peter V. deSouza. and Robert L. Mercer. Class-based n-gram models of natural language. In Proceedings of the IBM Natural Language ITL. pages 283-298. Paris, France, March 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
<author>Ramesh Patil</author>
</authors>
<title>Coping with syntactic ambiguity or how to put the block in the box on the table.</title>
<date>1982</date>
<journal>American Journal of Computational Linguistics,</journal>
<pages>8--3</pages>
<marker>[Church and Patil, 1982]</marker>
<rawString>Kenneth W. Church and Ramesh Patil. Coping with syntactic ambiguity or how to put the block in the box on the table. American Journal of Computational Linguistics, 8(3-4):139-149, 1982.</rawString>
</citation>
<citation valid="false">
<authors>
<author>William Gale Patrick Hanks</author>
<author>Donald Hindle</author>
</authors>
<title>Using statistics in lexical analysis. In Uri Zemik, editor, Lexical Acquisition: Exploiting On-Line Resources to Build a Lexicon,pages 116-164. Erlbaum,</title>
<date>1991</date>
<booktitle>In AAA1-86,</booktitle>
<pages>589--593</pages>
<editor>K. Dahlgren and). McDowell.</editor>
<publisher>MIT Press,</publisher>
<marker>[Church et at., 1991]</marker>
<rawString>Kenneth Church. William Gale. Patrick Hanks, and Donald Hindle. Using statistics in lexical analysis. In Uri Zemik, editor, Lexical Acquisition: Exploiting On-Line Resources to Build a Lexicon,pages 116-164. Erlbaum, 1991. [Dahlgren and McDowell, 1986) K. Dahlgren and). McDowell. Using commonsense knowledge to disambiguate prepositional phrase modifiers. In AAA1-86, pages 589-593, 1986. [Ford et aL, 1982) Marilyn Ford, Joan Bresnan, and Ronald Kaplan. A competence-based theory of syntactic closure. In Joan Bresnan, editor, The Mental Representation of Granunaiical Relations. MIT Press, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Francis</author>
<author>H Kucem</author>
</authors>
<title>FrequencyAnalysis of English Usage.</title>
<date>1982</date>
<location>Houghton Mifflin Co.: New York.</location>
<marker>[Francis and Kneen. 1982]</marker>
<rawString>W. Francis and H. Kucem. FrequencyAnalysis of English Usage. Houghton Mifflin Co.: New York. 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Frazier</author>
</authors>
<title>On comprehending Sentences: Syntactic Parsing Strategies.</title>
<date>1979</date>
<tech>PhD thesis,</tech>
<institution>University of Massachusetts,</institution>
<marker>[Frazier, 1979]</marker>
<rawString>L. Frazier. On comprehending Sentences: Syntactic Parsing Strategies. PhD thesis, University of Massachusetts, 1979.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Marti A Hearst</author>
<author>Kenneth W Church</author>
</authors>
<title>An investigation of the use of lexical associations for prepositional phrase attactunent.</title>
<note>(in preparation).</note>
<marker>[Hearst and Church: in preparation]</marker>
<rawString>Marti A. Hearst and Kenneth W Church. An investigation of the use of lexical associations for prepositional phrase attactunent. (in preparation).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hindle</author>
<author>M Rooth</author>
</authors>
<title>Structural ambiguity and lexical relations.</title>
<date>1991</date>
<booktitle>In Proceedings of the 29th Annual Meeting ofthe Association for Computational Linguistics,</booktitle>
<location>Berkeley, California.</location>
<marker>[Hindle and Rooth, 1991]</marker>
<rawString>D. Hindle and M. Rooth. Structural ambiguity and lexical relations. In Proceedings of the 29th Annual Meeting ofthe Association for Computational Linguistics, June 1991. Berkeley, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Hindle</author>
</authors>
<title>User manual for Fidditch. a deterministic parser. Technical memorandum 7590-142.</title>
<date>1983</date>
<institution>Naval Research Laboratory,</institution>
<marker>[Hindle, 1983]</marker>
<rawString>Donald Hindle. User manual for Fidditch. a deterministic parser. Technical memorandum 7590-142. Naval Research Laboratory, 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
<author>John Bear</author>
</authors>
<title>Two principles of parse preference_</title>
<date>1990</date>
<booktitle>In Proceedings of 13th COLING.</booktitle>
<pages>162--167</pages>
<location>Helsinki,</location>
<marker>[Hobbs and Bear, 1990]</marker>
<rawString>Jerry R. Hobbs and John Bear. Two principles of parse preference_ In Proceedings of 13th COLING. pages 162-167. Helsinki, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frederick Jelinek</author>
<author>Robert L Mercer</author>
</authors>
<title>Interpolated estimation of Markov source parameters from sparse data.</title>
<date>1980</date>
<booktitle>In Proceedings of the Workshop on Pattern Recognition in Practice,</booktitle>
<location>Amsterdam, The Netherlands: North-Holland,</location>
<marker>[Jelinek and Mercer, 1980]</marker>
<rawString>Frederick Jelinek and Robert L. Mercer. Interpolated estimation of Markov source parameters from sparse data. In Proceedings of the Workshop on Pattern Recognition in Practice, Amsterdam, The Netherlands: North-Holland, May 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karen Jensen</author>
<author>Jean-Louis Binot</author>
</authors>
<title>Disambiguating prepositional phrase attachments by using on-line dictionary definitions.</title>
<date>1987</date>
<journal>American Journal of Computational Linguistics. I</journal>
<pages>3--3</pages>
<marker>[Jensen and Binot. 1987]</marker>
<rawString>Karen Jensen and Jean-Louis Binot. Disambiguating prepositional phrase attachments by using on-line dictionary definitions. American Journal of Computational Linguistics. I 3(3)1251-260, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slava M Katz</author>
</authors>
<title>Estimation of probabilities from sparse data for the Ian gau ge model component of a speech recognizer.</title>
<date>1987</date>
<journal>IEEE Transactions on Acoustics. Speech and Signal Processing.</journal>
<pages>35--3</pages>
<marker>[Katz. 1987]</marker>
<rawString>Slava M. Katz. Estimation of probabilities from sparse data for the Ian gau ge model component of a speech recognizer. IEEE Transactions on Acoustics. Speech and Signal Processing. ASSP-35(3):400-401, March 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Kimball</author>
</authors>
<title>Seven principles of surface structure parsing in natural language.</title>
<date>1973</date>
<journal>Cognition,</journal>
<pages>2--15</pages>
<marker>[Kimball. 1973]</marker>
<rawString>John Kimball. Seven principles of surface structure parsing in natural language. Cognition, 2:15-47, 1973.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Miller</author>
</authors>
<title>Wordnet: An on-line lexical database.</title>
<date>1990</date>
<journal>International Journal of Lexicography,</journal>
<volume>3</volume>
<issue>4</issue>
<note>(Special Issue).</note>
<marker>[Miller, 1990]</marker>
<rawString>George Miller. Wordnet: An on-line lexical database. International Journal of Lexicography, 3(4), 1990. (Special Issue).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>WordNet and distributional analysis: A class-based approach to lexical discovery.</title>
<date>1992</date>
<booktitle>in AAA] Workshop on Statistically-based NLP Techniques,</booktitle>
<location>San Jose, California.</location>
<marker>[Resnik. 1992]</marker>
<rawString>Philip Resnik. WordNet and distributional analysis: A class-based approach to lexical discovery. in AAA] Workshop on Statistically-based NLP Techniques, San Jose, California. July 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Semantic classes and syntactic ambiguity. ARPA Workshop on Human Language Technology,</title>
<date>1993</date>
<booktitle>In COLING-84,</booktitle>
<location>Princeton. (Schubert,</location>
<marker>[Resnik. 1993]</marker>
<rawString>Philip Resnik. Semantic classes and syntactic ambiguity. ARPA Workshop on Human Language Technology, March 1993. Princeton. (Schubert, 1984] Lenhart Schubert. On parsing preferences. In COLING-84, 1984.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Ralph Weischedel</author>
<author>Marie Meteer</author>
<author>Richard Schwartz</author>
<author>Jeff Pahnucci</author>
</authors>
<title>Coping with ambiguity and unknown words through probabilistic models. ms.,</title>
<date>1989</date>
<booktitle>In Proceedings of the 28th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>23--30</pages>
<location>Pittsburgh, Pennsylvania. Milks</location>
<marker>[Weischedel et at., 1989]</marker>
<rawString>Ralph Weischedel, Marie Meteer, Richard Schwartz, and Jeff Pahnucci. Coping with ambiguity and unknown words through probabilistic models. ms., 1989. [Whittemore a al.. 19901 Greg Whittemore, Kathleen Ferrara. and Hans Brunner. Empirical study of predictive powers of simple attachment schemes for post-modifier prepositional phrases. In Proceedings of the 28th Annual Meeting of the Association for Computational Linguistics, pages 23-30. 1990. Pittsburgh, Pennsylvania. Milks el&apos; al.. 19851 Yorick Wilks, Xiuming Huang. and Dan Pass. Syntax, preference and right attachment. InLICA1-85. pages 779-784.1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony Woods</author>
<author>Paul Fletcher</author>
<author>Arthur Hughes</author>
</authors>
<title>Statistics in Language Studies. Cambridge Textbooks in Linguistics.</title>
<date>1986</date>
<publisher>Cambridge University Press:</publisher>
<location>Cambridge. England.</location>
<marker>[Woods et at. 1986]</marker>
<rawString>Anthony Woods, Paul Fletcher, and Arthur Hughes. Statistics in Language Studies. Cambridge Textbooks in Linguistics. Cambridge University Press: Cambridge. England. 1986. [Yarowsky. 1993) David Yarowsky. One sense per collocation. ARPA Workshop on Human Language Technology, March 1993. Princeton.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>