<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002074">
<title confidence="0.996197">
Comparative News Summarization Using Linear Programming
</title>
<author confidence="0.99936">
Xiaojiang Huang Xiaojun Wan* Jianguo Xiao
</author>
<affiliation confidence="0.95812">
Institute of Computer Science and Technology, Peking University, Beijing 100871, China
Key Laboratory of Computational Linguistic (Peking University), MOE, China
</affiliation>
<email confidence="0.985314">
{huangxiaojiang, wanxiaojun, xiaojianguo}@icst.pku.edu.cn
</email>
<sectionHeader confidence="0.998537" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997671375">
Comparative News Summarization aims to
highlight the commonalities and differences
between two comparable news topics. In
this study, we propose a novel approach to
generating comparative news summaries. We
formulate the task as an optimization problem
of selecting proper sentences to maximize the
comparativeness within the summary and the
representativeness to both news topics. We
consider semantic-related cross-topic concept
pairs as comparative evidences, and con-
sider topic-related concepts as representative
evidences. The optimization problem is
addressed by using a linear programming
model. The experimental results demonstrate
the effectiveness of our proposed model.
</bodyText>
<sectionHeader confidence="0.999509" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.988169755102041">
Comparative News Summarization aims to highlight
the commonalities and differences between two
comparable news topics. It can help users to analyze
trends, draw lessons from the past, and gain insights
about similar situations. For example, by comparing
the information about mining accidents in Chile and
China, we can discover what leads to the different
endings and how to avoid those tragedies.
Comparative text mining has drawn much atten-
tion in recent years. The proposed works differ
in the domain of corpus, the source of comparison
and the representing form of results. So far, most
researches focus on comparing review opinions of
products (Liu et al., 2005; Jindal and Liu, 2006a;
*Corresponding author
Jindal and Liu, 2006b; Lerman and McDonald,
2009; Kim and Zhai, 2009). A reason is that the
aspects in reviews are easy to be extracted and the
comparisons have simple patterns, e.g. positive
vs. negative. A few other works have also
tried to compare facts and views in news article
(Zhai et al., 2004) and Blogs (Wang et al., 2009).
The comparative information can be extracted from
explicit comparative sentences (Jindal and Liu,
2006a; Jindal and Liu, 2006b; Huang et al., 2008),
or mined implicitly by matching up features of
objects in the same aspects (Zhai et al., 2004; Liu
et al., 2005; Kim and Zhai, 2009; Sun et al.,
2006). The comparisons can be represented by
charts (Liu et al., 2005), word clusters (Zhai et al.,
2004), key phrases(Sun et al., 2006), and summaries
which consist of pairs of sentences or text sections
(Kim and Zhai, 2009; Lerman and McDonald,
2009; Wang et al., 2009). Among these forms,
the comparative summary conveys rich information
with good readability, so it keeps attracting interest
in the research community. In general, document
summarization can be performed by extraction or
abstraction (Mani, 2001). Due to the difficulty
of natural sentence generation, most automatic
summarization systems are extraction-based. They
select salient sentences to maximize the objective
functions of generated summaries (Carbonell and
Goldstein, 1998; McDonald, 2007; Lerman and
McDonald, 2009; Kim and Zhai, 2009; Gillick et al.,
2009). The major difference between the traditional
summarization task and the comparative summa-
rization task is that traditional summarization task
places equal emphasis on all kinds of information in
</bodyText>
<page confidence="0.966211">
648
</page>
<note confidence="0.589144">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 648–653,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.9961958">
the source, while comparative summarization task
only focuses on the comparisons between objects.
News is one of the most important channels for
acquiring information. However, it is more difficult
to extract comparisons in news articles than in
reviews. The aspects are much diverse in news.
They can be the time of the events, the person
involved, the attitudes of participants, etc. These
aspects can be expressed explicitly or implicitly in
many ways. For example, “storm” and “rain” both
talk about “weather”, and thus they can form a
potential comparison. All these issues raise great
challenges to comparative summarization in the
news domain.
In this study, we propose a novel approach for
comparative news summarization. We consider
comparativeness and representativeness as well as
redundancy in an objective function, and solve the
optimization problem by using linear programming
to extract proper comparable sentences. More
specifically, we consider a pair of sentences
comparative if they share comparative concepts;
we also consider a sentence representative if it
contains important concepts about the topic. Thus
a good comparative summary contains important
comparative pairs, as well as important concepts
about individual topics. Experimental results
demonstrate the effectiveness of our model, which
outperforms the baseline systems in quality of
comparison identification and summarization.
</bodyText>
<sectionHeader confidence="0.970651" genericHeader="method">
2 Problem Definition
</sectionHeader>
<subsectionHeader confidence="0.959922">
2.1 Comparison
</subsectionHeader>
<bodyText confidence="0.994566952380953">
A comparison identifies the commonalities or
differences among objects. It basically consists
of four components: the comparee (i.e. what is
compared), the standard (i.e. to what the compare
is compared), the aspect (i.e. the scale on which
the comparee and standard are measured), and the
result (i.e. the predicate that describes the positions
of the comparee and standard). For example, “Chile
is richer than Haiti.” is a typical comparison, where
the comparee is “Chile”; the standard is “Haiti”; the
comparative aspect is wealth, which is implied by
“richer”; and the result is that Chile is superior to
Haiti.
A comparison can be expressed explicitly in a
comparative sentence, or be described implicitly
in a section of text which describes the individual
characteristics of each object point-by-point. For
example, the following text
Haiti is an extremely poor country.
Chile is a rich country.
also suggests that Chile is richer than Haiti.
</bodyText>
<subsectionHeader confidence="0.99618">
2.2 Comparative News Summarization
</subsectionHeader>
<bodyText confidence="0.999995866666667">
The task of comparative news summarization is to
briefly sum up the commonalities and differences
between two comparable news topics by using
human readable sentences. The summarization
system is given two collections of news articles,
each of which is related to a topic. The system
should find latent comparative aspects, and generate
descriptions of those aspects in a pairwise way, i.e.
including descriptions of two topics simultaneously
in each aspect. For example, when comparing
the earthquake in Haiti with the one in Chile,
the summary should contain the intensity of each
temblor, the damages in each disaster area, the
reactions of each government, etc.
Formally, let t1 and t2 be two comparable news
topics, and D1 and D2 be two collections of
articles about each topic respectively. The task of
comparative summarization is to generate a short
abstract which conveys the important comparisons
{&lt; t1i t21 r1i7 r2i &gt;}, where r1i and r2i are
descriptions about topic t1 and t2 in the same
latent aspect ai respectively. The summary can be
considered as a combination of two components,
each of which is related to a news topic. It can also
be subdivided into several sections, each of which
focuses on a major aspect. The comparisons should
have good quality, i.e., be clear and representative to
both topics. The coverage of comparisons should be
as wide as possible, which means the aspects should
not be redundant because of the length limit.
</bodyText>
<sectionHeader confidence="0.982219" genericHeader="method">
3 Proposed Approach
</sectionHeader>
<bodyText confidence="0.9999628">
It is natural to select the explicit comparative
sentences as comparative summary, because they
express comparison explicitly in good qualities.
However, they do not appear frequently in regular
news articles so that the coverage is limited. Instead,
</bodyText>
<page confidence="0.996286">
649
</page>
<bodyText confidence="0.983322732142857">
it is more feasible to extract individual descriptions
of each topic over the same aspects and then
generate comparisons.
To discover latent comparative aspects, we
consider a sentence as a bag of concepts, each of
which has an atom meaning. If two sentences have
same concepts in common, they are likely to discuss
the same aspect and thus they may be comparable
with each other. For example,
Lionel Messi named FIFA Word Player of
the Year 2010.
Cristiano Ronalo Crowned FIFA Word
Player of the Year 2009.
The two sentences compare on the “FIFA Word
Player of the Year”, which is contained in both
sentences. Furthermore, semantic related concepts
can also represent comparisons. For example,
“snow” and “sunny” can indicate a comparison
on “weather”; “alive” and “death” can imply a
comparison on “rescue result”. Thus the pairs
of semantic related concepts can be considered as
evidences of comparisons.
A comparative summary should contain as many
comparative evidences as possible. Besides, it
should convey important information in the original
documents. Since we model the text with a
collection of concept units, the summary should
contain as many important concepts as possible.
An important concept is likely to be mentioned
frequently in the documents, and thus we use the
frequency as a measure of a concept’s importance.
Obviously, the more accurate the extracted
concepts are, the better we can represent the
meaning of a text. However, it is not easy to extract
semantic concepts accurately. In this study, we
use words, named entities and bigrams to simply
represent concepts, and leave the more complex
concept extraction for future work.
Based on the above ideas, we can formulate
the summarization task as an optimization problem.
Formally, let Ci = {cij} be the set of concepts in the
document set Di, (i = 1, 2). Each concept cij has a
weight wij ∈ R. ocij ∈ {0, 1} is a binary variable
indicating whether the concept cij is presented in the
summary. A cross-topic concept pair &lt; c1j, c2k &gt;
has a weight ujk ∈ R that indicates whether it
implies a important comparison. opjk is a binary
variable indicating whether the pair is presented in
the summary. Then the objective function score of a
comparative summary can be estimated as follows:
The first component of the function estimates the
comparativeness within the summary and the second
component estimates the representativeness to both
topics. A ∈ [0, 1] is a factor that balances these two
factors. In this study, we set A = 0.55.
The weights of concepts are calculated as follows:
</bodyText>
<equation confidence="0.990332">
wij = tfij · idfij (2)
</equation>
<bodyText confidence="0.999936666666667">
where tfij is the term frequency of the concept cij
in the document set Di, and idfij is the inverse
document frequency calculated over a background
corpus.
The weights of concept pairs are calculated as
follows:
</bodyText>
<equation confidence="0.8625715">
{
(w1j + w2k)/2, if rel(c1j, c2k) &gt; T
0, otherwise
(3)
</equation>
<bodyText confidence="0.999374333333333">
where rel(c1j,c2k) is the semantic relevance be-
tween two concepts, and it is calculated using the
algorithms basing on WordNet (Pedersen et al.,
2004). If the relevance is higher than the threshold
T (0.2 in this study), then the concept pair is
considered as an evidence of comparison.
Note that a concept pair will not be presented in
the summary unless both the concepts are presented,
i.e.
</bodyText>
<equation confidence="0.9998315">
opjk ≤ oc1j (4)
opjk ≤ oc2k (5)
</equation>
<bodyText confidence="0.999983666666667">
In order to avoid bias towards the concepts which
have more related concepts, we only count the most
important relation of each concept, i.e.
</bodyText>
<equation confidence="0.982655">
∑ opjk ≤ 1, ∀j (6)
k
∑ opjk ≤ 1, ∀k (7)
j
</equation>
<bodyText confidence="0.999834">
The algorithm selects proper sentences to max-
imize the objective function. Formally, let Si =
</bodyText>
<equation confidence="0.9948265">
A ∑ |C1 |∑ |C2 |ujk ·opjk +(1−A) 2 ∑ |C� |wij · ocij (1)
j=1 k=1 ∑ j=1
i=1
ujk =
</equation>
<page confidence="0.962469">
650
</page>
<bodyText confidence="0.9971145">
{Sik} be the set of sentences in Di, ocSijk be
a binary variable indicating whether concept cij
occurs in sentence Sik, and oSik be a binary variable
indicating whether Sik is presented in the summary.
If Sik is selected in the summary, then all the
concepts in it are presented in the summary, i.e.
</bodyText>
<equation confidence="0.767503833333333">
ocij &gt; ocSijk · oSik,b1 &lt; j &lt; |Ci |(8)
Meanwhile, a concept will not be present in the
summary unless it is contained in some selected
sentences, i.e.
ocij &lt; ∑ Al ocSijk · oSik (9)
k=1
</equation>
<bodyText confidence="0.534525">
Finally, the summary should satisfy a length
constraint:
</bodyText>
<equation confidence="0.979309">
lik · oSik &lt; L (10)
</equation>
<bodyText confidence="0.99993475">
where lik is the length of sentence Sik, and L is the
maximal summary length.
The optimization of the defined objective function
under above constraints is an integer linear program-
ming (ILP) problem. Though the ILP problems
are generally NP-hard, considerable works have
been done and several software solutions have been
released to solve them efficiently.&apos;
</bodyText>
<sectionHeader confidence="0.999117" genericHeader="method">
4 Experiment
</sectionHeader>
<subsectionHeader confidence="0.857155">
4.1 Dataset
</subsectionHeader>
<bodyText confidence="0.9999935">
Because of the novelty of the comparative news
summarization task, there is no existing data set
for evaluating. We thus create our own. We first
choose five pairs of comparable topics, then retrieve
ten related news articles for each topic using the
Google News search engine. Finally we write the
comparative summary for each topic pair manually.
The topics are showed in table 1.
</bodyText>
<subsectionHeader confidence="0.960062">
4.2 Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.992211666666667">
We evaluate the models with following measures:
Comparison Precision / Recall / F-measure:
let aa and am be the numbers of all aspects
</bodyText>
<footnote confidence="0.8153745">
&apos;We use IBM ILOG CPLEX optimizer to solve the problem.
zhttp://news.google.com
</footnote>
<table confidence="0.999836625">
ID Topic 1 Topic 2
1 Haiti Earth quake Chile Earthquake
2 Chile Mining Acci- New Zealand Mining
dent Accident
3 Iraq Withdrawal Afghanistan
Withdrawal
4 Apple iPad 2 BlackBerry Playbook
5 2006 FIFA World Cup 2010 FIFA World Cup
</table>
<tableCaption confidence="0.999961">
Table 1: Comparable topic pairs in the dataset.
</tableCaption>
<bodyText confidence="0.998853571428571">
involved in the automatically generated summary
and manually written summary respectively; ca
be the number of human agreed comparative
aspects in the automatically generated summary.
The comparison precision (CP), comparison recall
(CR) and comparison F-measure (CF) are defined
as follows:
</bodyText>
<equation confidence="0.993565">
2 · CP · CR
� CF =
</equation>
<bodyText confidence="0.999375461538462">
ROUGE: the ROUGE is a widely used metric
in summarization evaluation. It measures summary
quality by counting overlapping units between the
candidate summary and the reference summary (Lin
and Hovy, 2003). In the experiment, we report
the f-measure values of ROUGE-1, ROUGE-2 and
ROUGE-SU4, which count overlapping unigrams,
bigrams and skip-4-grams respectively. To evaluate
whether the summary is related to both topics,
we also split each comparative summary into two
topic-related parts, evaluate them respectively, and
report the mean of the two ROUGE values (denoted
as MROUGE).
</bodyText>
<subsectionHeader confidence="0.999683">
4.3 Baseline Systems
</subsectionHeader>
<bodyText confidence="0.999359">
Non-Comparative Model (NCM): The
non-comparative model treats the task as a
traditional summarization problem and selects the
important sentences from each document collection.
The model is adapted from our approach by setting
A = 0 in the objection function 1.
Co-Ranking Model (CRM): The co-ranking
model makes use of the relations within each
topic and relations across the topics to reinforce
scores of the comparison related sentences. The
model is adapted from (Wan et al., 2007). The
</bodyText>
<page confidence="0.568829">
2
</page>
<figure confidence="0.902763375">
∑
i=1
∑ Al
k=1
ca ca
CP = � CR =
aa am
CP + CR
</figure>
<page confidence="0.995381">
651
</page>
<bodyText confidence="0.99897325">
SS, WW and SW relationships are replaced by
relationships between two sentences within each
topic and relationships between two sentences from
different topics.
</bodyText>
<subsectionHeader confidence="0.999325">
4.4 Experiment Results
</subsectionHeader>
<bodyText confidence="0.999987619047619">
We apply all the systems to generate comparative
summaries with a length limit of 200 words. The
evaluation results are shown in table 2. Compared
with baseline models, our linear programming based
comparative model (denoted as LPCM) achieves
best scores over all metrics. It is expected to find
that the NCM model does not perform well in this
task because it does not focus on the comparisons.
The CRM model utilizes the similarity between
two topics to enhance the score of comparison
related sentences. However, it does not guarantee
to choose pairwise sentences to form comparisons.
The LPCM model focus on both comparativeness
and representativeness at the same time, and thus
it achieves good performance on both comparison
extraction and summarization. Figure 1 shows
an example of comparative summary generated by
using the CLPM model. The summary describes
several comparisons between two FIFA World Cups
in 2006 and 2010. Most of the comparisons are clear
and representative.
</bodyText>
<sectionHeader confidence="0.993936" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999987583333333">
In this study, we propose a novel approach to
summing up the commonalities and differences
between two news topics. We formulate the
task as an optimization problem of selecting
sentences to maximize the score of comparative and
representative evidences. The experiment results
show that our model is effective in comparison
extraction and summarization.
In future work, we will utilize more semantic
information such as localized latent topics to help
capture comparative aspects, and use machine
learning technologies to tune weights of concepts.
</bodyText>
<sectionHeader confidence="0.999152" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.989509">
This work was supported by NSFC (60873155),
Beijing Nova Program (2008B03) and NCET
(NCET-08-0006).
</bodyText>
<table confidence="0.998743">
Model CP CR CF ROUGE-1 ROUGE-2 ROUGE-su4 MROUGE-1 MROUGE-2 MROUGE-su4
NCM 0.238 0.262 0.247 0.398 0.146 0.174 0.350 0.122 0.148
CRM 0.313 0.285 0.289 0.426 0.194 0.226 0.355 0.146 0.175
LPCM 0.359 0.419 0.386 0.427 0.205 0.234 0.380 0.171 0.192
</table>
<tableCaption confidence="0.990003">
Table 2: Evaluation results of systems
</tableCaption>
<bodyText confidence="0.671949733333333">
World Cup 2006 World Cup 2010
The 2006 Fifa World Cup drew to a close on Sunday Spain have won the 2010 FIFA World Cup South Africa
with Italy claiming their fourth crown after beating final, defeating Netherlands 1-0 with a wonderful goal
France in a penalty shoot-out. from Andres Iniesta deep into extra-time.
Zidane won the Golden Ball over Italians Fabio Uruguay star striker Diego Forlan won the Golden
Cannavaro and Andrea Pirlo. Ball Award as he was named the best player of the
tournament at the FIFA World Cup 2010 in South
Africa.
Lukas Podolski was named the inaugural Gillette Best German youngster Thomas Mueller got double delight
Young Player. after his side finished third in the tournament as he was
named Young Player of the World Cup
Germany striker Miroslav Klose was the Golden Shoe Among the winners were goalkeeper and captain Iker
winner for the tournament’s leading scorer. Casillas who won the Golden Glove Award.
England’s fans brought more colour than their team. Only four of the 212 matches played drew more that
40,000 fans.
</bodyText>
<figureCaption confidence="0.996205">
Figure 1: A sample comparative summary generated by using the LPCM model
</figureCaption>
<page confidence="0.99612">
652
</page>
<sectionHeader confidence="0.995466" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.994345211764706">
Jaime Carbonell and Jade Goldstein. 1998. The use of
MMR, diversity-based reranking for reordering docu-
ments and producing summaries. In Proceedings of
the 21st annual international ACM SIGIR conference
on Research and development in information retrieval,
pages 335–336. ACM.
Dan Gillick, Korbinian Riedhammer, Benoit Favre, and
Dilek Hakkani-Tur. 2009. A global optimization
framework for meeting summarization. In Proceed-
ings of the 2009 IEEE International Conference on
Acoustics, Speech and Signal Processing, ICASSP
’09, pages 4769–4772, Washington, DC, USA. IEEE
Computer Society.
Xiaojiang. Huang, Xiaojun. Wan, Jianwu. Yang, and
Jianguo. Xiao. 2008. Learning to Identify
Comparative Sentences in Chinese Text. PRICAI
2008: Trends in Artificial Intelligence, pages 187–198.
Nitin Jindal and Bing Liu. 2006a. Identifying compar-
ative sentences in text documents. In Proceedings of
the 29th annual international ACM SIGIR conference
on Research and development in information retrieval,
pages 244–251. ACM.
Nitin Jindal and Bing Liu. 2006b. Mining comparative
sentences and relations. In proceedings of the 21st
national conference on Artificial intelligence - Volume
2, pages 1331–1336. AAAI Press.
Hyun Duk Kim and ChengXiang Zhai. 2009. Generating
comparative summaries of contradictory opinions in
text. In Proceeding of the 18th ACM conference
on Information and knowledge management, pages
385–394. ACM.
Kevin Lerman and Ryan McDonald. 2009. Contrastive
summarization: an experiment with consumer reviews.
In Proceedings of Human Language Technologies:
The 2009 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics, Companion Volume: Short Papers, pages
113–116. Association for Computational Linguistics.
Chin-Yew Lin and Eduard Hovy. 2003. Automatic
evaluation of summaries using n-gram co-occurrence
statistics. In Proceedings of the 2003 Conference
of the North American Chapter of the Association
for Computational Linguistics on Human Language
Technology - Volume 1, NAACL ’03, pages 71–78,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Bing Liu, Minqing Hu, and Junsheng Cheng. 2005.
Opinion observer: analyzing and comparing opinions
on the Web. In Proceedings of the 14th international
conference on World Wide Web, pages 342–351. ACM.
Inderjeet Mani. 2001. Automatic summarization. Natu-
ral Language Processing. John Benjamins Publishing
Company.
Ryan McDonald. 2007. A study of global inference
algorithms in multi-document summarization. In
Proceedings of the 29th European conference on IR re-
search, ECIR’07, pages 557–564, Berlin, Heidelberg.
Springer-Verlag.
Ted Pedersen, Siddharth Patwardhan, and Jason Miche-
lizzi. 2004. WordNet:: Similarity: measuring the
relatedness of concepts. In Demonstration Papers at
HLT-NAACL 2004 on XX, pages 38–41. Association
for Computational Linguistics.
Jian-Tao Sun, Xuanhui Wang, Dou Shen, Hua-Jun Zeng,
and Zheng Chen. 2006. CWS: a comparative
web search system. In Proceedings of the 15th
international conference on World Wide Web, pages
467–476. ACM.
Xiaojun Wan, Jianwu Yang, and Jianguo Xiao. 2007.
Towards an iterative reinforcement approach for
simultaneous document summarization and keyword
extraction. In Proceedings of the 45th Annual Meeting
of the Association of Computational Linguistics, pages
552–559, Prague, Czech Republic, June. Association
for Computational Linguistics.
Dingding Wang, Shenghuo Zhu, Tao Li, and Yihong
Gong. 2009. Comparative document summarization
via discriminative sentence selection. In Proceeding
of the 18th ACM conference on Information and
knowledge management, pages 1963–1966. ACM.
ChengXiang Zhai, Atulya Velivelli, and Bei Yu. 2004.
A cross-collection mixture model for comparative text
mining. In Proceedings of the tenth ACM SIGKDD
international conference on Knowledge discovery and
data mining, pages 743–748. ACM.
</reference>
<page confidence="0.999261">
653
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.837815">
<title confidence="0.99975">Comparative News Summarization Using Linear Programming</title>
<author confidence="0.992898">Huang Xiaojun Jianguo Xiao</author>
<affiliation confidence="0.97258">Institute of Computer Science and Technology, Peking University, Beijing 100871, China</affiliation>
<address confidence="0.88421">Key Laboratory of Computational Linguistic (Peking University), MOE, China</address>
<email confidence="0.994137">wanxiaojun,</email>
<abstract confidence="0.998749882352941">Comparative News Summarization aims to highlight the commonalities and differences between two comparable news topics. In this study, we propose a novel approach to generating comparative news summaries. We formulate the task as an optimization problem of selecting proper sentences to maximize the comparativeness within the summary and the representativeness to both news topics. We consider semantic-related cross-topic concept pairs as comparative evidences, and consider topic-related concepts as representative evidences. The optimization problem is addressed by using a linear programming model. The experimental results demonstrate the effectiveness of our proposed model.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jaime Carbonell</author>
<author>Jade Goldstein</author>
</authors>
<title>The use of MMR, diversity-based reranking for reordering documents and producing summaries.</title>
<date>1998</date>
<booktitle>In Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>335--336</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="3115" citStr="Carbonell and Goldstein, 1998" startWordPosition="458" endWordPosition="461">n et al., 2006), and summaries which consist of pairs of sentences or text sections (Kim and Zhai, 2009; Lerman and McDonald, 2009; Wang et al., 2009). Among these forms, the comparative summary conveys rich information with good readability, so it keeps attracting interest in the research community. In general, document summarization can be performed by extraction or abstraction (Mani, 2001). Due to the difficulty of natural sentence generation, most automatic summarization systems are extraction-based. They select salient sentences to maximize the objective functions of generated summaries (Carbonell and Goldstein, 1998; McDonald, 2007; Lerman and McDonald, 2009; Kim and Zhai, 2009; Gillick et al., 2009). The major difference between the traditional summarization task and the comparative summarization task is that traditional summarization task places equal emphasis on all kinds of information in 648 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 648–653, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics the source, while comparative summarization task only focuses on the comparisons between objects. News is one of</context>
</contexts>
<marker>Carbonell, Goldstein, 1998</marker>
<rawString>Jaime Carbonell and Jade Goldstein. 1998. The use of MMR, diversity-based reranking for reordering documents and producing summaries. In Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval, pages 335–336. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Gillick</author>
<author>Korbinian Riedhammer</author>
<author>Benoit Favre</author>
<author>Dilek Hakkani-Tur</author>
</authors>
<title>A global optimization framework for meeting summarization.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP ’09,</booktitle>
<pages>4769--4772</pages>
<publisher>IEEE Computer Society.</publisher>
<location>Washington, DC, USA.</location>
<contexts>
<context position="3201" citStr="Gillick et al., 2009" startWordPosition="472" endWordPosition="475">hai, 2009; Lerman and McDonald, 2009; Wang et al., 2009). Among these forms, the comparative summary conveys rich information with good readability, so it keeps attracting interest in the research community. In general, document summarization can be performed by extraction or abstraction (Mani, 2001). Due to the difficulty of natural sentence generation, most automatic summarization systems are extraction-based. They select salient sentences to maximize the objective functions of generated summaries (Carbonell and Goldstein, 1998; McDonald, 2007; Lerman and McDonald, 2009; Kim and Zhai, 2009; Gillick et al., 2009). The major difference between the traditional summarization task and the comparative summarization task is that traditional summarization task places equal emphasis on all kinds of information in 648 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 648–653, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics the source, while comparative summarization task only focuses on the comparisons between objects. News is one of the most important channels for acquiring information. However, it is more difficult </context>
</contexts>
<marker>Gillick, Riedhammer, Favre, Hakkani-Tur, 2009</marker>
<rawString>Dan Gillick, Korbinian Riedhammer, Benoit Favre, and Dilek Hakkani-Tur. 2009. A global optimization framework for meeting summarization. In Proceedings of the 2009 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP ’09, pages 4769–4772, Washington, DC, USA. IEEE Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaojun Wan Huang</author>
<author>Jianwu Yang</author>
<author>Jianguo Xiao</author>
</authors>
<date>2008</date>
<booktitle>Learning to Identify Comparative Sentences in Chinese Text. PRICAI 2008: Trends in Artificial Intelligence,</booktitle>
<pages>187--198</pages>
<contexts>
<context position="2218" citStr="Huang et al., 2008" startWordPosition="320" endWordPosition="323">s. So far, most researches focus on comparing review opinions of products (Liu et al., 2005; Jindal and Liu, 2006a; *Corresponding author Jindal and Liu, 2006b; Lerman and McDonald, 2009; Kim and Zhai, 2009). A reason is that the aspects in reviews are easy to be extracted and the comparisons have simple patterns, e.g. positive vs. negative. A few other works have also tried to compare facts and views in news article (Zhai et al., 2004) and Blogs (Wang et al., 2009). The comparative information can be extracted from explicit comparative sentences (Jindal and Liu, 2006a; Jindal and Liu, 2006b; Huang et al., 2008), or mined implicitly by matching up features of objects in the same aspects (Zhai et al., 2004; Liu et al., 2005; Kim and Zhai, 2009; Sun et al., 2006). The comparisons can be represented by charts (Liu et al., 2005), word clusters (Zhai et al., 2004), key phrases(Sun et al., 2006), and summaries which consist of pairs of sentences or text sections (Kim and Zhai, 2009; Lerman and McDonald, 2009; Wang et al., 2009). Among these forms, the comparative summary conveys rich information with good readability, so it keeps attracting interest in the research community. In general, document summariza</context>
</contexts>
<marker>Huang, Yang, Xiao, 2008</marker>
<rawString>Xiaojiang. Huang, Xiaojun. Wan, Jianwu. Yang, and Jianguo. Xiao. 2008. Learning to Identify Comparative Sentences in Chinese Text. PRICAI 2008: Trends in Artificial Intelligence, pages 187–198.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Jindal</author>
<author>Bing Liu</author>
</authors>
<title>Identifying comparative sentences in text documents.</title>
<date>2006</date>
<booktitle>In Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>244--251</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="1712" citStr="Jindal and Liu, 2006" startWordPosition="236" endWordPosition="239">d differences between two comparable news topics. It can help users to analyze trends, draw lessons from the past, and gain insights about similar situations. For example, by comparing the information about mining accidents in Chile and China, we can discover what leads to the different endings and how to avoid those tragedies. Comparative text mining has drawn much attention in recent years. The proposed works differ in the domain of corpus, the source of comparison and the representing form of results. So far, most researches focus on comparing review opinions of products (Liu et al., 2005; Jindal and Liu, 2006a; *Corresponding author Jindal and Liu, 2006b; Lerman and McDonald, 2009; Kim and Zhai, 2009). A reason is that the aspects in reviews are easy to be extracted and the comparisons have simple patterns, e.g. positive vs. negative. A few other works have also tried to compare facts and views in news article (Zhai et al., 2004) and Blogs (Wang et al., 2009). The comparative information can be extracted from explicit comparative sentences (Jindal and Liu, 2006a; Jindal and Liu, 2006b; Huang et al., 2008), or mined implicitly by matching up features of objects in the same aspects (Zhai et al., 200</context>
</contexts>
<marker>Jindal, Liu, 2006</marker>
<rawString>Nitin Jindal and Bing Liu. 2006a. Identifying comparative sentences in text documents. In Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 244–251. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Jindal</author>
<author>Bing Liu</author>
</authors>
<title>Mining comparative sentences and relations.</title>
<date>2006</date>
<booktitle>In proceedings of the 21st national conference on Artificial intelligence -</booktitle>
<volume>2</volume>
<pages>1331--1336</pages>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="1712" citStr="Jindal and Liu, 2006" startWordPosition="236" endWordPosition="239">d differences between two comparable news topics. It can help users to analyze trends, draw lessons from the past, and gain insights about similar situations. For example, by comparing the information about mining accidents in Chile and China, we can discover what leads to the different endings and how to avoid those tragedies. Comparative text mining has drawn much attention in recent years. The proposed works differ in the domain of corpus, the source of comparison and the representing form of results. So far, most researches focus on comparing review opinions of products (Liu et al., 2005; Jindal and Liu, 2006a; *Corresponding author Jindal and Liu, 2006b; Lerman and McDonald, 2009; Kim and Zhai, 2009). A reason is that the aspects in reviews are easy to be extracted and the comparisons have simple patterns, e.g. positive vs. negative. A few other works have also tried to compare facts and views in news article (Zhai et al., 2004) and Blogs (Wang et al., 2009). The comparative information can be extracted from explicit comparative sentences (Jindal and Liu, 2006a; Jindal and Liu, 2006b; Huang et al., 2008), or mined implicitly by matching up features of objects in the same aspects (Zhai et al., 200</context>
</contexts>
<marker>Jindal, Liu, 2006</marker>
<rawString>Nitin Jindal and Bing Liu. 2006b. Mining comparative sentences and relations. In proceedings of the 21st national conference on Artificial intelligence - Volume 2, pages 1331–1336. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hyun Duk Kim</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Generating comparative summaries of contradictory opinions in text.</title>
<date>2009</date>
<booktitle>In Proceeding of the 18th ACM conference on Information and knowledge management,</booktitle>
<pages>385--394</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="1806" citStr="Kim and Zhai, 2009" startWordPosition="250" endWordPosition="253">sons from the past, and gain insights about similar situations. For example, by comparing the information about mining accidents in Chile and China, we can discover what leads to the different endings and how to avoid those tragedies. Comparative text mining has drawn much attention in recent years. The proposed works differ in the domain of corpus, the source of comparison and the representing form of results. So far, most researches focus on comparing review opinions of products (Liu et al., 2005; Jindal and Liu, 2006a; *Corresponding author Jindal and Liu, 2006b; Lerman and McDonald, 2009; Kim and Zhai, 2009). A reason is that the aspects in reviews are easy to be extracted and the comparisons have simple patterns, e.g. positive vs. negative. A few other works have also tried to compare facts and views in news article (Zhai et al., 2004) and Blogs (Wang et al., 2009). The comparative information can be extracted from explicit comparative sentences (Jindal and Liu, 2006a; Jindal and Liu, 2006b; Huang et al., 2008), or mined implicitly by matching up features of objects in the same aspects (Zhai et al., 2004; Liu et al., 2005; Kim and Zhai, 2009; Sun et al., 2006). The comparisons can be represented</context>
<context position="3178" citStr="Kim and Zhai, 2009" startWordPosition="468" endWordPosition="471"> sections (Kim and Zhai, 2009; Lerman and McDonald, 2009; Wang et al., 2009). Among these forms, the comparative summary conveys rich information with good readability, so it keeps attracting interest in the research community. In general, document summarization can be performed by extraction or abstraction (Mani, 2001). Due to the difficulty of natural sentence generation, most automatic summarization systems are extraction-based. They select salient sentences to maximize the objective functions of generated summaries (Carbonell and Goldstein, 1998; McDonald, 2007; Lerman and McDonald, 2009; Kim and Zhai, 2009; Gillick et al., 2009). The major difference between the traditional summarization task and the comparative summarization task is that traditional summarization task places equal emphasis on all kinds of information in 648 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 648–653, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics the source, while comparative summarization task only focuses on the comparisons between objects. News is one of the most important channels for acquiring information. However</context>
</contexts>
<marker>Kim, Zhai, 2009</marker>
<rawString>Hyun Duk Kim and ChengXiang Zhai. 2009. Generating comparative summaries of contradictory opinions in text. In Proceeding of the 18th ACM conference on Information and knowledge management, pages 385–394. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Lerman</author>
<author>Ryan McDonald</author>
</authors>
<title>Contrastive summarization: an experiment with consumer reviews.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers,</booktitle>
<pages>113--116</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1785" citStr="Lerman and McDonald, 2009" startWordPosition="246" endWordPosition="249">to analyze trends, draw lessons from the past, and gain insights about similar situations. For example, by comparing the information about mining accidents in Chile and China, we can discover what leads to the different endings and how to avoid those tragedies. Comparative text mining has drawn much attention in recent years. The proposed works differ in the domain of corpus, the source of comparison and the representing form of results. So far, most researches focus on comparing review opinions of products (Liu et al., 2005; Jindal and Liu, 2006a; *Corresponding author Jindal and Liu, 2006b; Lerman and McDonald, 2009; Kim and Zhai, 2009). A reason is that the aspects in reviews are easy to be extracted and the comparisons have simple patterns, e.g. positive vs. negative. A few other works have also tried to compare facts and views in news article (Zhai et al., 2004) and Blogs (Wang et al., 2009). The comparative information can be extracted from explicit comparative sentences (Jindal and Liu, 2006a; Jindal and Liu, 2006b; Huang et al., 2008), or mined implicitly by matching up features of objects in the same aspects (Zhai et al., 2004; Liu et al., 2005; Kim and Zhai, 2009; Sun et al., 2006). The compariso</context>
<context position="3158" citStr="Lerman and McDonald, 2009" startWordPosition="464" endWordPosition="467"> pairs of sentences or text sections (Kim and Zhai, 2009; Lerman and McDonald, 2009; Wang et al., 2009). Among these forms, the comparative summary conveys rich information with good readability, so it keeps attracting interest in the research community. In general, document summarization can be performed by extraction or abstraction (Mani, 2001). Due to the difficulty of natural sentence generation, most automatic summarization systems are extraction-based. They select salient sentences to maximize the objective functions of generated summaries (Carbonell and Goldstein, 1998; McDonald, 2007; Lerman and McDonald, 2009; Kim and Zhai, 2009; Gillick et al., 2009). The major difference between the traditional summarization task and the comparative summarization task is that traditional summarization task places equal emphasis on all kinds of information in 648 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 648–653, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics the source, while comparative summarization task only focuses on the comparisons between objects. News is one of the most important channels for acquiring </context>
</contexts>
<marker>Lerman, McDonald, 2009</marker>
<rawString>Kevin Lerman and Ryan McDonald. 2009. Contrastive summarization: an experiment with consumer reviews. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers, pages 113–116. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chin-Yew Lin</author>
<author>Eduard Hovy</author>
</authors>
<title>Automatic evaluation of summaries using n-gram co-occurrence statistics.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology - Volume 1, NAACL ’03,</booktitle>
<pages>71--78</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="13769" citStr="Lin and Hovy, 2003" startWordPosition="2198" endWordPosition="2201">erry Playbook 5 2006 FIFA World Cup 2010 FIFA World Cup Table 1: Comparable topic pairs in the dataset. involved in the automatically generated summary and manually written summary respectively; ca be the number of human agreed comparative aspects in the automatically generated summary. The comparison precision (CP), comparison recall (CR) and comparison F-measure (CF) are defined as follows: 2 · CP · CR � CF = ROUGE: the ROUGE is a widely used metric in summarization evaluation. It measures summary quality by counting overlapping units between the candidate summary and the reference summary (Lin and Hovy, 2003). In the experiment, we report the f-measure values of ROUGE-1, ROUGE-2 and ROUGE-SU4, which count overlapping unigrams, bigrams and skip-4-grams respectively. To evaluate whether the summary is related to both topics, we also split each comparative summary into two topic-related parts, evaluate them respectively, and report the mean of the two ROUGE values (denoted as MROUGE). 4.3 Baseline Systems Non-Comparative Model (NCM): The non-comparative model treats the task as a traditional summarization problem and selects the important sentences from each document collection. The model is adapted </context>
</contexts>
<marker>Lin, Hovy, 2003</marker>
<rawString>Chin-Yew Lin and Eduard Hovy. 2003. Automatic evaluation of summaries using n-gram co-occurrence statistics. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology - Volume 1, NAACL ’03, pages 71–78, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
<author>Minqing Hu</author>
<author>Junsheng Cheng</author>
</authors>
<title>Opinion observer: analyzing and comparing opinions on the Web.</title>
<date>2005</date>
<booktitle>In Proceedings of the 14th international conference on World Wide Web,</booktitle>
<pages>342--351</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="1690" citStr="Liu et al., 2005" startWordPosition="232" endWordPosition="235">e commonalities and differences between two comparable news topics. It can help users to analyze trends, draw lessons from the past, and gain insights about similar situations. For example, by comparing the information about mining accidents in Chile and China, we can discover what leads to the different endings and how to avoid those tragedies. Comparative text mining has drawn much attention in recent years. The proposed works differ in the domain of corpus, the source of comparison and the representing form of results. So far, most researches focus on comparing review opinions of products (Liu et al., 2005; Jindal and Liu, 2006a; *Corresponding author Jindal and Liu, 2006b; Lerman and McDonald, 2009; Kim and Zhai, 2009). A reason is that the aspects in reviews are easy to be extracted and the comparisons have simple patterns, e.g. positive vs. negative. A few other works have also tried to compare facts and views in news article (Zhai et al., 2004) and Blogs (Wang et al., 2009). The comparative information can be extracted from explicit comparative sentences (Jindal and Liu, 2006a; Jindal and Liu, 2006b; Huang et al., 2008), or mined implicitly by matching up features of objects in the same asp</context>
</contexts>
<marker>Liu, Hu, Cheng, 2005</marker>
<rawString>Bing Liu, Minqing Hu, and Junsheng Cheng. 2005. Opinion observer: analyzing and comparing opinions on the Web. In Proceedings of the 14th international conference on World Wide Web, pages 342–351. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjeet Mani</author>
</authors>
<title>Automatic summarization. Natural Language Processing.</title>
<date>2001</date>
<publisher>John Benjamins Publishing Company.</publisher>
<contexts>
<context position="2881" citStr="Mani, 2001" startWordPosition="430" endWordPosition="431">ects in the same aspects (Zhai et al., 2004; Liu et al., 2005; Kim and Zhai, 2009; Sun et al., 2006). The comparisons can be represented by charts (Liu et al., 2005), word clusters (Zhai et al., 2004), key phrases(Sun et al., 2006), and summaries which consist of pairs of sentences or text sections (Kim and Zhai, 2009; Lerman and McDonald, 2009; Wang et al., 2009). Among these forms, the comparative summary conveys rich information with good readability, so it keeps attracting interest in the research community. In general, document summarization can be performed by extraction or abstraction (Mani, 2001). Due to the difficulty of natural sentence generation, most automatic summarization systems are extraction-based. They select salient sentences to maximize the objective functions of generated summaries (Carbonell and Goldstein, 1998; McDonald, 2007; Lerman and McDonald, 2009; Kim and Zhai, 2009; Gillick et al., 2009). The major difference between the traditional summarization task and the comparative summarization task is that traditional summarization task places equal emphasis on all kinds of information in 648 Proceedings of the 49th Annual Meeting of the Association for Computational Lin</context>
</contexts>
<marker>Mani, 2001</marker>
<rawString>Inderjeet Mani. 2001. Automatic summarization. Natural Language Processing. John Benjamins Publishing Company.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
</authors>
<title>A study of global inference algorithms in multi-document summarization.</title>
<date>2007</date>
<booktitle>In Proceedings of the 29th European conference on IR research, ECIR’07,</booktitle>
<pages>557--564</pages>
<publisher>Springer-Verlag.</publisher>
<location>Berlin, Heidelberg.</location>
<contexts>
<context position="3131" citStr="McDonald, 2007" startWordPosition="462" endWordPosition="463">which consist of pairs of sentences or text sections (Kim and Zhai, 2009; Lerman and McDonald, 2009; Wang et al., 2009). Among these forms, the comparative summary conveys rich information with good readability, so it keeps attracting interest in the research community. In general, document summarization can be performed by extraction or abstraction (Mani, 2001). Due to the difficulty of natural sentence generation, most automatic summarization systems are extraction-based. They select salient sentences to maximize the objective functions of generated summaries (Carbonell and Goldstein, 1998; McDonald, 2007; Lerman and McDonald, 2009; Kim and Zhai, 2009; Gillick et al., 2009). The major difference between the traditional summarization task and the comparative summarization task is that traditional summarization task places equal emphasis on all kinds of information in 648 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 648–653, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics the source, while comparative summarization task only focuses on the comparisons between objects. News is one of the most import</context>
</contexts>
<marker>McDonald, 2007</marker>
<rawString>Ryan McDonald. 2007. A study of global inference algorithms in multi-document summarization. In Proceedings of the 29th European conference on IR research, ECIR’07, pages 557–564, Berlin, Heidelberg. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
<author>Siddharth Patwardhan</author>
<author>Jason Michelizzi</author>
</authors>
<title>WordNet:: Similarity: measuring the relatedness of concepts.</title>
<date>2004</date>
<booktitle>In Demonstration Papers at HLT-NAACL 2004 on XX,</booktitle>
<pages>38--41</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="10772" citStr="Pedersen et al., 2004" startWordPosition="1677" endWordPosition="1680">es the representativeness to both topics. A ∈ [0, 1] is a factor that balances these two factors. In this study, we set A = 0.55. The weights of concepts are calculated as follows: wij = tfij · idfij (2) where tfij is the term frequency of the concept cij in the document set Di, and idfij is the inverse document frequency calculated over a background corpus. The weights of concept pairs are calculated as follows: { (w1j + w2k)/2, if rel(c1j, c2k) &gt; T 0, otherwise (3) where rel(c1j,c2k) is the semantic relevance between two concepts, and it is calculated using the algorithms basing on WordNet (Pedersen et al., 2004). If the relevance is higher than the threshold T (0.2 in this study), then the concept pair is considered as an evidence of comparison. Note that a concept pair will not be presented in the summary unless both the concepts are presented, i.e. opjk ≤ oc1j (4) opjk ≤ oc2k (5) In order to avoid bias towards the concepts which have more related concepts, we only count the most important relation of each concept, i.e. ∑ opjk ≤ 1, ∀j (6) k ∑ opjk ≤ 1, ∀k (7) j The algorithm selects proper sentences to maximize the objective function. Formally, let Si = A ∑ |C1 |∑ |C2 |ujk ·opjk +(1−A) 2 ∑ |C� |wij </context>
</contexts>
<marker>Pedersen, Patwardhan, Michelizzi, 2004</marker>
<rawString>Ted Pedersen, Siddharth Patwardhan, and Jason Michelizzi. 2004. WordNet:: Similarity: measuring the relatedness of concepts. In Demonstration Papers at HLT-NAACL 2004 on XX, pages 38–41. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jian-Tao Sun</author>
<author>Xuanhui Wang</author>
<author>Dou Shen</author>
<author>Hua-Jun Zeng</author>
<author>Zheng Chen</author>
</authors>
<title>CWS: a comparative web search system.</title>
<date>2006</date>
<booktitle>In Proceedings of the 15th international conference on World Wide Web,</booktitle>
<pages>467--476</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2370" citStr="Sun et al., 2006" startWordPosition="349" endWordPosition="352">2006b; Lerman and McDonald, 2009; Kim and Zhai, 2009). A reason is that the aspects in reviews are easy to be extracted and the comparisons have simple patterns, e.g. positive vs. negative. A few other works have also tried to compare facts and views in news article (Zhai et al., 2004) and Blogs (Wang et al., 2009). The comparative information can be extracted from explicit comparative sentences (Jindal and Liu, 2006a; Jindal and Liu, 2006b; Huang et al., 2008), or mined implicitly by matching up features of objects in the same aspects (Zhai et al., 2004; Liu et al., 2005; Kim and Zhai, 2009; Sun et al., 2006). The comparisons can be represented by charts (Liu et al., 2005), word clusters (Zhai et al., 2004), key phrases(Sun et al., 2006), and summaries which consist of pairs of sentences or text sections (Kim and Zhai, 2009; Lerman and McDonald, 2009; Wang et al., 2009). Among these forms, the comparative summary conveys rich information with good readability, so it keeps attracting interest in the research community. In general, document summarization can be performed by extraction or abstraction (Mani, 2001). Due to the difficulty of natural sentence generation, most automatic summarization syst</context>
</contexts>
<marker>Sun, Wang, Shen, Zeng, Chen, 2006</marker>
<rawString>Jian-Tao Sun, Xuanhui Wang, Dou Shen, Hua-Jun Zeng, and Zheng Chen. 2006. CWS: a comparative web search system. In Proceedings of the 15th international conference on World Wide Web, pages 467–476. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaojun Wan</author>
<author>Jianwu Yang</author>
<author>Jianguo Xiao</author>
</authors>
<title>Towards an iterative reinforcement approach for simultaneous document summarization and keyword extraction.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>552--559</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="14656" citStr="Wan et al., 2007" startWordPosition="2333" endWordPosition="2336">ic-related parts, evaluate them respectively, and report the mean of the two ROUGE values (denoted as MROUGE). 4.3 Baseline Systems Non-Comparative Model (NCM): The non-comparative model treats the task as a traditional summarization problem and selects the important sentences from each document collection. The model is adapted from our approach by setting A = 0 in the objection function 1. Co-Ranking Model (CRM): The co-ranking model makes use of the relations within each topic and relations across the topics to reinforce scores of the comparison related sentences. The model is adapted from (Wan et al., 2007). The 2 ∑ i=1 ∑ Al k=1 ca ca CP = � CR = aa am CP + CR 651 SS, WW and SW relationships are replaced by relationships between two sentences within each topic and relationships between two sentences from different topics. 4.4 Experiment Results We apply all the systems to generate comparative summaries with a length limit of 200 words. The evaluation results are shown in table 2. Compared with baseline models, our linear programming based comparative model (denoted as LPCM) achieves best scores over all metrics. It is expected to find that the NCM model does not perform well in this task because</context>
</contexts>
<marker>Wan, Yang, Xiao, 2007</marker>
<rawString>Xiaojun Wan, Jianwu Yang, and Jianguo Xiao. 2007. Towards an iterative reinforcement approach for simultaneous document summarization and keyword extraction. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 552–559, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dingding Wang</author>
<author>Shenghuo Zhu</author>
<author>Tao Li</author>
<author>Yihong Gong</author>
</authors>
<title>Comparative document summarization via discriminative sentence selection.</title>
<date>2009</date>
<booktitle>In Proceeding of the 18th ACM conference on Information and knowledge management,</booktitle>
<pages>1963--1966</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2069" citStr="Wang et al., 2009" startWordPosition="298" endWordPosition="301">rawn much attention in recent years. The proposed works differ in the domain of corpus, the source of comparison and the representing form of results. So far, most researches focus on comparing review opinions of products (Liu et al., 2005; Jindal and Liu, 2006a; *Corresponding author Jindal and Liu, 2006b; Lerman and McDonald, 2009; Kim and Zhai, 2009). A reason is that the aspects in reviews are easy to be extracted and the comparisons have simple patterns, e.g. positive vs. negative. A few other works have also tried to compare facts and views in news article (Zhai et al., 2004) and Blogs (Wang et al., 2009). The comparative information can be extracted from explicit comparative sentences (Jindal and Liu, 2006a; Jindal and Liu, 2006b; Huang et al., 2008), or mined implicitly by matching up features of objects in the same aspects (Zhai et al., 2004; Liu et al., 2005; Kim and Zhai, 2009; Sun et al., 2006). The comparisons can be represented by charts (Liu et al., 2005), word clusters (Zhai et al., 2004), key phrases(Sun et al., 2006), and summaries which consist of pairs of sentences or text sections (Kim and Zhai, 2009; Lerman and McDonald, 2009; Wang et al., 2009). Among these forms, the comparat</context>
</contexts>
<marker>Wang, Zhu, Li, Gong, 2009</marker>
<rawString>Dingding Wang, Shenghuo Zhu, Tao Li, and Yihong Gong. 2009. Comparative document summarization via discriminative sentence selection. In Proceeding of the 18th ACM conference on Information and knowledge management, pages 1963–1966. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ChengXiang Zhai</author>
<author>Atulya Velivelli</author>
<author>Bei Yu</author>
</authors>
<title>A cross-collection mixture model for comparative text mining.</title>
<date>2004</date>
<booktitle>In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>743--748</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2039" citStr="Zhai et al., 2004" startWordPosition="292" endWordPosition="295"> Comparative text mining has drawn much attention in recent years. The proposed works differ in the domain of corpus, the source of comparison and the representing form of results. So far, most researches focus on comparing review opinions of products (Liu et al., 2005; Jindal and Liu, 2006a; *Corresponding author Jindal and Liu, 2006b; Lerman and McDonald, 2009; Kim and Zhai, 2009). A reason is that the aspects in reviews are easy to be extracted and the comparisons have simple patterns, e.g. positive vs. negative. A few other works have also tried to compare facts and views in news article (Zhai et al., 2004) and Blogs (Wang et al., 2009). The comparative information can be extracted from explicit comparative sentences (Jindal and Liu, 2006a; Jindal and Liu, 2006b; Huang et al., 2008), or mined implicitly by matching up features of objects in the same aspects (Zhai et al., 2004; Liu et al., 2005; Kim and Zhai, 2009; Sun et al., 2006). The comparisons can be represented by charts (Liu et al., 2005), word clusters (Zhai et al., 2004), key phrases(Sun et al., 2006), and summaries which consist of pairs of sentences or text sections (Kim and Zhai, 2009; Lerman and McDonald, 2009; Wang et al., 2009). A</context>
</contexts>
<marker>Zhai, Velivelli, Yu, 2004</marker>
<rawString>ChengXiang Zhai, Atulya Velivelli, and Bei Yu. 2004. A cross-collection mixture model for comparative text mining. In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 743–748. ACM.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>