<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000014">
<title confidence="0.994525">
Improved Syntactic Models for Parsing Speech with Repairs*
</title>
<author confidence="0.991864">
Tim Miller
</author>
<affiliation confidence="0.9976315">
Department of Computer Science and Engineering
University of Minnesota, Twin Cities
</affiliation>
<email confidence="0.99913">
tmill@cs.umn.edu
</email>
<sectionHeader confidence="0.998599" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999528">
This paper introduces three new syntactic
models for representing speech with repairs.
These models are developed to test the intu-
ition that the erroneous parts of speech repairs
(reparanda) are not generated or recognized as
such while occurring, but only after they have
been corrected. Thus, they are designed to
minimize the differences in grammar rule ap-
plications between fluent and disfluent speech
containing similar structure. The three models
considered in this paper are also designed to
isolate the mechanism of impact, by systemat-
ically exploring different variables.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.987689865384616">
Recent work in recognition of speech with repairs
has shown that syntactic cues to speech repair can
improve both overall parsing accuracy and detection
of repaired sections (Hale et al., 2006; Miller and
Schuler, 2008; Johnson and Charniak, 2004). These
techniques work by explictly modeling the structure
of speech repair, specifically the tendency of repairs
to follow unfinished constituents of the same cate-
gory. This is the essence of what was termed the
well-formedness rule by Willem Levelt (1983) in his
psycholinguistic studies of repair.
The work presented here uses the same motiva-
tions as those cited above (to be described in more
detail below), in that it attempts to model the syn-
tactic structure relating unfinished erroneous con-
Phis research was supported by NSF CAREER award
0447685. The views expressed are not necessarily endorsed by
the sponsors.
stituents to the repair of those constituents. How-
ever, this work attempts to improve on those mod-
els by focusing on the generative process used by a
speaker in creating the repair. This is done first by
eschewing any labels representing the presence of
an erroneous constituent while processing the text.
This modeling representation reflects the intuition
that speakers do not intend to generate erroneous
speech – they intend their speech to be fluent, or
a correction to an error, and can stop very quickly
when an error is noticed. This corresponds to Lev-
elt’s Main Interruption Rule, which states that a
speaker will “Stop the flow of speech immediately
upon detecting the occasion of repair.” Rather than
attempting to recognize a special syntactic category
called EDITED during the processing phase, this
work introduces the REPAIRED category to signal
the ending of a repaired section only.
The second part of the modeling framework is
the use of a right-corner transform on training data,
which converts phrase-structure trees into heavily
left-branching structures. This transformation has
been shown to represent the structure of unfinished
constituents like those seen in speech repair in a nat-
ural way, leading to improved detection of speech
repair (Miller and Schuler, 2008).
Combining these two modeling techniques in a
bottom-up parsing framework results in a parsing
architecture that is a reasonable approximation to
the sequential processing that must be done by the
human speech processor when recognizing spoken
language with repairs. This parser also recognizes
sentences containing speech repair with better accu-
racy than the previous models on which it is based.
</bodyText>
<page confidence="0.993446">
656
</page>
<note confidence="0.8905605">
Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 656–664,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.999124">
Therefore, these syntactic models hold promise for
integration into systems for processing of streaming
speech.
</bodyText>
<subsectionHeader confidence="0.967915">
1.1 Speech Repair Terminology
</subsectionHeader>
<bodyText confidence="0.999927454545455">
A speech repair occurs when a speaker decides to
interrupt the flow of speech and restart part or all
of an utterance. Typically speech repair structure
(Shriberg, 1994) is considered to contain a reparan-
dum, or the part of the utterance to be replaced, and
an alteration, which is meant to replace the reparan-
dum section. There are also frequently editing terms
(for example, ‘uh’ and ‘um’) between the reparan-
dum and alteration, which may be used to signal the
repair, or to indicate that the speaker is thinking, or
just to maintain control of the dialogue.
</bodyText>
<sectionHeader confidence="0.972751" genericHeader="related work">
1.2 Related Work
</sectionHeader>
<bodyText confidence="0.99993227027027">
This work is related to that of Hale et al.(2006) in
that it attempts to model the syntactic structure of
speech repair. In that paper speech repair detec-
tion accuracy was increased by explicitly account-
ing for the relation between reparanda category and
alteration category. This was done by so-called
“daughter annotation,” which expanded the set of
EDITED categories by appending the category be-
low the EDITED label to the end of the EDITED
label – for example, a noun phrase (NP) reparanda
would be of type EDITED-NP. In addition, this ap-
proach made edit detection easier by propagating the
-UNF label attached to the rightmost unfinished con-
stituent up to the EDITED label. These two changes
in combination allow the parser to better recognize
when a reparandum has occurred, and to make sib-
lings of reparanda and alterations with the same ba-
sic category label.
Another model of speech repair that explicitly
models the structure of speech repair is that of John-
son and Charniak (2004). That model has a differ-
ent approach than the context-free parsing approach
done in the present work. Instead, they run a tree-
adjoining grammar (TAG) parser which traces the
overlapping words and part-of-speech tags that oc-
cur in the reparandum and alteration of a speech re-
pair. This approach is highly accurate at detecting
speech repairs, and allows for downstream process-
ing of cleaned up text to be largely free of speech
repair, but due to its TAG component it may present
difficulties incorporating into an architecture that
operates on streaming text or speech.
This work is also similar in aim to a component of
the parsing and language modeling work of Roark
and Johnson (1999), which used right-binarization
in order to delay decision-making about constituents
as much as possible. For example, the rule
</bodyText>
<equation confidence="0.678721">
NP → DT NN
might be right-binarized as two rules:
NP → DT NP-DT
and
NP-DT → NN
</equation>
<bodyText confidence="0.999930258064516">
The result of this binarization is that when predicting
the noun phrase (NP) rule, a top-down parser is de-
laying making any commitments about the category
following the determiner (DT). This delay in predic-
tion means that the parser does not need to make
any predictions about whether the next word will
be, e.g., a common noun (NN), plural noun (NNS),
or proper noun (NNP), until it sees the actual next
word.
Similarly, the model presented in this work aims
to delay the decision to create a speech repair as
much as possible. This is done here by eliminating
the EDITED category (representing a reparandum)
during processing, replacing it with a REPAIRED
category which represents the alteration of a speech
repair, and by eliminating implicit cues about repair
happening before a decision to repair should be nec-
essary.
Finally, this work is most directly related to that
of Miller and Schuler (2008). In that work, the au-
thors used a right-corner transform to turn standard
phrase-structure trees into highly left-branching
trees with sub-tree category labels representing in-
complete but in-progress constituent structure. That
structure was shown to have desirable properties in
the representation of repair in syntax trees, and this
work leverages that insight, while attempting to im-
prove the input representation such that the right-
corner representation does not require the parser to
make any assumptions or decisions earlier than nec-
essary.
</bodyText>
<page confidence="0.998928">
657
</page>
<sectionHeader confidence="0.995814" genericHeader="method">
2 Syntactic Model
</sectionHeader>
<bodyText confidence="0.9997723">
This section will first describe the default represen-
tation scheme for speech repair in the Switchboard
corpus and the standard representation after applica-
tion of a right-corner transform, and then describe
why there are shortcomings in both of these repre-
sentations. Descriptions of several alternative mod-
els follow, with an explanation of how each of them
is meant to address the shortcomings seen in previ-
ous representations. These models are then evalu-
ated in Section 3.
</bodyText>
<subsectionHeader confidence="0.998127">
2.1 Standard Repair Annotation
</subsectionHeader>
<bodyText confidence="0.9998825">
The standard representation of speech repair in the
Switchboard corpus makes use of one new category
label (EDITED), to represent a reparandum, and a
new dash-tag (-UNF), representing the lowest unfin-
ished constituent in a phrase. An example tree with
both EDITED and -UNF tags is shown in Figure 1.
</bodyText>
<sectionHeader confidence="0.506571" genericHeader="method">
SBAR
</sectionHeader>
<figureCaption confidence="0.965517666666667">
Figure 1: A fragment of a standard phrase-structure tree
from the development set, containing both an EDITED
constituent and an -UNF tag.
</figureCaption>
<bodyText confidence="0.9993891">
ing to learn from this structure, for example a prob-
abilistic context-free grammar, will result in the rule
that a sentence (S) consists of a reparandum, a noun
phrase, and a verb phrase, which is an odd way of
thinking about both constituent structure and mean-
ing. A more intuitive understanding might be that a
sentence may consist of a noun phrase followed by a
verb phrase, and during the production of that rule,
an interruption may occur which causes the rule to
restart.
</bodyText>
<subsectionHeader confidence="0.994999">
2.2 Right-Corner Transform
</subsectionHeader>
<bodyText confidence="0.999790461538462">
The work described above by Miller and Schuler
(2008) uses a right-corner transform. This transform
turns right-branching structure into left-branching
structure, using category labels that use a “slash” no-
tation α/,y to represent an incomplete constituent of
type α “looking for” a constituent of type -y in order
to complete itself. Figure 2 shows the right-corner
transformed tree from above.
This transform first requires that trees be bina-
rized. This binarization is done in a similar way to
Johnson (1998) and Klein and Manning (2003).
Rewrite rules for the right-corner transform are as
follows, first flattening right-branching structure:1
</bodyText>
<figure confidence="0.993547548387097">
WHNP-2
S
DT
that
NP-SBJ
PRP
EDITED
S
NP-SBJ
PRP
you
VP-UNF
MD
could
PP-PRP
IN
for
you
MD
could
VB
use
NP
NN
landfill
VP
VP
⇒
A1/A2
A2/A3
A3
</figure>
<equation confidence="0.607237833333333">
(1)
A1
α1 A2
α2 A3
A1
α1 α2 a3
</equation>
<bodyText confidence="0.9999424">
This sentence contains a restarted sentence (S)
constituent, in which the speaker started by saying
“you could”, then decided to restart the phrase, in
this case without changing the first two words. One
important thing to notice is that the EDITED label
contains no information about the structure beneath
it. As a result, a parser trained on this default anno-
tation has no information about the attempted con-
stituent type, which, in the case of restarts would ob-
viously be beneficial. As described above, the work
by Hale et al. using daughter annotation was meant
to overcome this shortcoming.
Another shortcoming of this annotation scheme
to consider is that the EDITED tag is not meaning-
ful with respect to constituent structure. Attempt-
</bodyText>
<equation confidence="0.8959175">
a3
α2
</equation>
<bodyText confidence="0.885462666666667">
then replacing it with left-branching structure:
1Here, all Ai denote nonterminal symbols, and αi denote
subtrees ; the notation A1:α0 indicates a subtree α0 with la-
bel Al; and all rewrites are applied recursively, from leaves to
root. In trees containing repairs, the symbol ET represents any
number of editing terms and the sub-structure within them.
</bodyText>
<figure confidence="0.966135846153846">
α1
α2
⇒
A1/A2
A2/A3
... (2)
A1
α1 A2
A2/A3
. . .
A1
658
you
</figure>
<figureCaption confidence="0.81486">
Figure 2: Right-corner transformed tree fragment.
</figureCaption>
<figure confidence="0.99920532">
S/PP
IN
landfill
S/VP
VB
for
S/S
NP
could
S/VP
VP-UNF
S/S
··· WHNP
that
EDITED-S
NP
could
you
S
S/NP
NP
S/VP
MD
use
(3)
</figure>
<bodyText confidence="0.999948018181818">
This representation has interesting properties,
which work well for speech repair. First, the left-
branching structure of a repair results in reparanda
that only require one special repair rule application,
at the last word in the reparandum. Second, the ex-
plicit representation of incomplete constituents al-
lows many reparanda to seamlessly integrate with
the rest of the parse tree, with the EDITED label
essentially acting as an instruction to the parser to
maintain the current position in the unfinished con-
stituent. This subtle second point is illustrated in the
tree in Figure 2. After the EDITED section is de-
tected, it combines with a category label S/S to form
another sub-tree with category label S/S, essentially
acting as a null op in a state machine looking to com-
plete a phrase of type S.
This representation also contains problems, how-
ever. First, note that the (bottom-up) parser uses one
set of rules to combine the reparandum with the cur-
rent state of the recognition, and another set of rules
when combining the alteration with the previous in-
put. While it is a benefit of this approach that both
rule sets are made up of fluent speech rules, their
way of combining nonetheless requires an early pre-
monition of the repair to occur. If anything, the re-
pair should require special rule applications, but in
this representation it is still the case that the reparan-
dum looks different and the alteration looks “nor-
mal.”
A better model of repair from a recognition per-
spective would recognize the reparandum as flu-
ent, since they are recognized as such in real time,
and then, when noticing the repeated words, declare
these new words to be a repair section, and retroac-
tively declare the original start of the phrase to be
a reparandum. It is this conception of a recognition
model that forms part of the basis for a new syntactic
model of speech repair in Section 2.3.
A second problem with this representation is ev-
ident in certain multi-word repairs such as the one
in Figure 2 that require an extra right branch off of
the main left branching structure of the tree. As a
result, a multi-word reparandum structure requires
an extra unary rule application at the left-corner of
the sub-tree, in this case S/VP, relative to the inline
structure of the fluent version of that phrase. This
extra rule will often be nearly deterministic, but in
some cases it may not be, which would result essen-
tially in a penalty for starting speech repairs. This
may act to discourage short repairs and incentivize
longer reparanda, across which the penalty would
be amortized. This incentive is exactly backwards,
since reparanda tend to be quite short.
The next section will show how the two issues
mentioned above can be resolved by making mod-
</bodyText>
<equation confidence="0.885163571428571">
α2 A1/ A2:α1 α2
A1
A1/A2:α1 A2/A3
α3 ... ⇒
A1/A3
A1
α3 ...
</equation>
<page confidence="0.989081">
659
</page>
<bodyText confidence="0.9913615">
ifications to the original structure of trees containing
repairs.
</bodyText>
<subsectionHeader confidence="0.998921">
2.3 Modified Repair Annotation
</subsectionHeader>
<bodyText confidence="0.999966644444444">
The main model introduced in this paper works by
turning the original repair into a right-branching
structure as much as possible. As a result, the
right-corner transformed representation has very flat
structure, and, unlike the standard right-corner trans-
formed representation described above, does not re-
quire a second level of depth in the tree with differ-
ent rule applications. This can also be an important
consideration for speech, since there are parsers that
can operate in asymptotically linear time by using
bounded stacks, and flat tree structure minimizes the
amount of stack space required.
This model works by using an “interruption”
model for the way a repair begins. The interrup-
tion model works on restarted constituents, by mov-
ing the repaired constituent (the alteration) to be
the right-most child of the original EDITED con-
stituent. The EDITED label is then removed, and
a new REPAIRED label is added. This of course
makes the detection of EDITED sections possible
only retrospectively, by noting a REPAIRED section
of a certain syntactic category, and tracing back in
the tree to find the closest ancestor of the same cate-
gory.
This can be illustrated schematically by the fol-
lowing rewrite rule:
result of these transformations may appear odd, but
it is important to note that it is merely an intermedi-
ate stage between the “standard” representation with
an EDITED label, representing the post-recognition
understanding of the sentence, and the right-corner
representation in which recognition actually occurs.
This right-corner representation can be seen in Fig-
ure 2.3.
This representation is notable in that it looks ex-
actly the same after the first word of the repair
(‘you’) as the later incarnation of the same word in
the alteration. After the second word (‘could’), the
repair is initiated, and here a repair rule is initiated.
It should be noted, however, that strictly speaking
the only reason the REPAIRED category needs to
exist is to keep track of edits for the purpose of eval-
uating the parser. It serves only a processing pur-
pose, telling the parser to reset what it is looking for
in the incoming word stream.
</bodyText>
<figure confidence="0.999266314285715">
MD
PRP
WHSBAR
WHNP
DT
that
you
VP
REPAIRED-S
S
S
could
NP
could
you
PP
VB
MD
NP
PRP
VP
VP
Ap
cap
A2
A1:ca2
⇒
ET
. . .
EDITED
A1
ca1
use
IN
for
</figure>
<figureCaption confidence="0.749421">
Figure 3: REPAIRED-INT transformation
</figureCaption>
<figure confidence="0.9317368">
NP
NN
landfill
Ap
(4)
</figure>
<figureCaption confidence="0.6304495">
Figure 3 shows how the example tree from Fig-
ure 1 looks when transformed in this manner. The
</figureCaption>
<bodyText confidence="0.998690909090909">
The next model attempts to examine the im-
pact of two different factors in the REPAIRED-INT
representation above. That representation had the
side effect of creating special rules off of the alter-
ation (REPAIRED) node, and it is difficult to as-
sign praise or blame to the performance results of
that model without distinguishing the main modi-
fication from the side effects. This can be recti-
fied by proposing another model that similarly elim-
inates the EDITED label for reparanda, and uses
a new label REPAIRED for the alteration, but that
</bodyText>
<figure confidence="0.989140689655172">
ET
. . .
A1:ca2
A1
cap
ca1
A2
REPAIRED-A1
660
S WHSBAR
S
NP
WHNP
DT
that
REPAIRED-S
NP
VP
S
VP-UNF
PRP
MD
PRP
MD
VP
you
could
you
could
VB PP
S/VP MD use
S/VP
S/NP
VB
IN
for
NP
landfill
S/PP
S/REPAIRED-S
NP
could
use
you
MD
S/VP
S/S
WHNP
that
Figure 4: REPAIRED-INT + right-corner transformation
could
NP
you
IN
for
NP
NN
landfill
</figure>
<figureCaption confidence="0.6521515">
Figure 5: REPAIRED-BIN transformation
S
</figureCaption>
<bodyText confidence="0.999034777777778">
does not satisfy the desire to have reparanda occur
inline using the “normal” rule combinations. This
model does, however, still have special rules that
the REPAIRED label will generate. Thus, if this
model performs equally well (or equally as poorly)
as REPAIRED-INT, then it is likely due to the model
picking up strong signals about an alteration rule
set. This modification involves rewriting the origi-
nal phrase structure tree as follows:
</bodyText>
<figure confidence="0.9839355">
S/VP MD use
S/VP
S/NP
VB
IN
for
NP
landfill
S/PP
you
S/S
WHNP
that
S
S/VP
NP
VP-UNF
could
S/REPAIRED-S
NP
could
A1:α0
. . .
A0
A1
A1:α0 ET
. . .
(5)
REPAIRED-A1
A1:α1
you
Figure 6: REPAIRED-BIN + right-corner transformation
A0
ET
A1:α1 ⇒
EDITED
</figure>
<figureCaption confidence="0.866385666666667">
A tree with this annotation scheme can be seen in
Figure 5, and its right-corner counterpart is shown
in Figure 6.
</figureCaption>
<bodyText confidence="0.999026">
The final modification to examine acts effectively
as another control to the previous two annotation
schemes. The two modifications above are essen-
tially performing two operations, first acting to bina-
rize speech repairs by lumping a category of type X
with a category of type EDITED-X, and then explic-
itly marking the repair but not the reparandum. This
modification tests whether simply adding an extra
layer of structure can improve performance while re-
taining the standard speech repair annotation includ-
ing the EDITED category label. This modification
will be denoted EDITED-BIN.
EDITED-BIN trees are created using the follow-
ing rewrite rule:
</bodyText>
<page confidence="0.947497">
661
</page>
<figure confidence="0.7290215">
A0
EDITED ET A1:α1 ⇒
A0
A1
EDITED-A1 ET A1:α1
A1:α0 . . .
A1:α0 . . .
(6)
</figure>
<bodyText confidence="0.9987738">
After this transform, the tree would look identical
to the REPAIRED-BIN tree in Figure 5, except the
node labeled ‘REPAIRED-S’ is labeled ‘S’, and its
left sibling is labeled ‘EDITED-S’ instead of ‘S.’
An EDITED-BIN tree after right-corner transforma-
tions is shown in Figure 7. This explicit binariza-
tion of speech repairs may be effective in its own
right, because without it, a ‘brute force’ binariza-
tion must be done to format the tree before apply-
ing the right-corner transform, and that process in-
volves joining chains of categories with underscores
into right-branching super-categories. This process
can result in reparanda categories in unpredictable
places in the middle of lengthy super-categories,
making data sparse and less reliable.
</bodyText>
<figure confidence="0.899484">
S
S/VP MD use
you
</figure>
<figureCaption confidence="0.997134">
Figure 7: EDITED-BIN + right-corner transformation
</figureCaption>
<sectionHeader confidence="0.993217" genericHeader="evaluation">
3 Evaluation
</sectionHeader>
<bodyText confidence="0.981208072463768">
The evaluation of this model was performed using a
probabilistic CYK parser2. This parser operates in
a bottom-up fashion, building up constituent struc-
ture from the words it is given as input. This parsing
architecture is a good match for the structure gen-
erated by the right-corner transform because it does
not need to consider any categories related to speech
repair until the repaired section has been completed.
Moreover, the structure of the trees means that the
parser is also building up structure from left to right.
That mode of operation is useful for any model
which purports to be potentially extensible to speech
recognition or to model the human speech proces-
sor. In contrast, top-down parsers require exhaustive
searches, meaning that they need to explore interpre-
tations containing disfluency, even in the absence of
syntactic cues for its existence.
These experiments used the Switchboard corpus
(Godfrey et al., 1992), a syntactically-annotated cor-
pus of spontaneous dialogues between human inter-
locutors. This corpus is annotated for phrase struc-
ture in much the same way as the Penn Treebank
2The specific parser used is the Stanford parser described in
Klein and Manning(2003), but run in “vanilla PCFG” mode.
Wall Street Journal corpus, with the addition of sev-
eral speech-specific categories as described in Sec-
tion 2.1. For training, trees in sections 2 and 3 of
this corpus were transformed as described in Sec-
tion 2, and rule probabilities were estimated in the
usual way. For testing, trees in section 4, subsec-
tions 0 and 1, were used. Data from the tail end of
section 4 (subsections 3 and 4) was used during de-
velopment of this work.
Before doing any training or testing, all trees in
the data set were stripped of punctuation, empty
categories, typos, all categories representing repair
structure, and partial words – anything that would
be difficult or impossible to obtain reliably with
a speech recognizer. A baseline parser was then
trained and tested using the split described above,
achieving standard results as seen in the table be-
low. For a fair comparison to the evaluation in Hale
et al. (2006), the parser was given part-of-speech
tags along with each word as input. The structure
obtained by the parser was then in the right-corner
format. For standardized scoring, the right-corner
transform, binarization, and augmented repair anno-
tation were undone, so that comparison was done
against the nearly pristine test corpus. Several test
configurations were then evaluated, and compared
to three baseline approaches.
The two metrics used here are the standard Parse-
val F-measure, and Edit-finding F. The first takes the
F-score of labeled precision and recall of the non-
terminals in a hypothesized tree relative to the gold
standard tree. The second measure marks words in
the gold standard as edited if they are dominated by
a node labeled EDITED, and measures the F-score
of the hypothesized edited words relative to the gold
standard (recall in this case is percentage of actual
edited words that were hypothesized as edited, and
precision is percentage of hypothesized edited words
that were actually edited).
The first three lines in the table refer to baseline
approaches to compare against. “Plain” refers to a
configuration with no modifications other than the
removal of repair cues. The next result shown is a
reproducton of the results from Hale et al. (2006)
(described in section 1.2)3. The next line (“Standard
</bodyText>
<tableCaption confidence="0.797655333333333">
3The present work compares to the standard CYK parsing
result from that paper, and not the result from a heavily opti-
mized parser using lexicalization.
</tableCaption>
<figure confidence="0.99917215">
S/VP
S/NP
VB
IN
for
NP
landfill
S/PP
could
S/S
NP
S/S
WHNP
that
S/VP
NP
EDITED-S
VP-UNF
could
you
</figure>
<page confidence="0.972912">
662
</page>
<bodyText confidence="0.970700153846154">
Right Corner”) is a reproduction of the results from
Miller and Schuler (2008).
The following three lines contain the three ex-
perimental configurations. First, the configuration
denoted EDITED-BIN refers to the simple bina-
rized speech repair described in Section 2.3 (Equa-
tion 6). REPAIRED-BIN refers to the binarized
speech repair in which the labels are basically re-
versed from EDITED-BIN (Equation 5). Finally,
REPAIRED-INT refers to the speech repair type
where the REPAIRED category may be a child of
a non-identity category, representing an interruption
of the outermost desired constituent (Equation 4).
</bodyText>
<table confidence="0.997115142857143">
System Configuration Parseval-F Edited-F
Baseline 71.03 17.9
Hale et al. 68.47†† 37.9††
Standard Right Corner 71.21†† 30.6††
EDITED-BIN 69.77** †† 38.9** ††
REPAIRED-BIN 71.37* 31.6** ††
REPAIRED-INT 71.77** 39.2** ††
</table>
<tableCaption confidence="0.999354">
Table 1: Table of parsing results. Star (*) indicates sig-
</tableCaption>
<bodyText confidence="0.990714762711865">
nificance relative to the ‘Standard Right Corner’ baseline
(p &lt; 0.05), dagger (†) indicates significance relative to
the ‘Baseline’ labeled result (p &lt; 0.05). Double star and
dagger indicate highly significant results (p &lt; 0.001).
Significance results were obtained by perform-
ing a two-tailed paired Student’s t-test on both the
Parseval-F and Edit-F per-sentence results. This
methodology is not perfect, since it fails to account
for the ease of recognition of very short sentences
(which are common in a speech corpus like Switch-
board), and thus slightly underweights performance
on longer sentences. This is also the explanation
for the odd effect where the ‘REPAIRED-BIN’ and
‘REPAIRED-INT’ results achieve significance over
the ‘Standard Right Corner’ result, but not over the
‘Baseline’ result. However, the simplest alternative
– weighting each sentence by its length – is probably
worse, since it makes the distributions being com-
pared in the t-test broadly distributed collections of
unlike objects, and thus hard to interpret meaning-
fully.
These results show a statistically significant im-
provement over previous work in overall parsing ac-
curacy, and obvious (as well as statistically signif-
icant) gains in accuracy recognizing edited words
(reparanda) with a parser. The REPAIRED-INT
approach, which makes repair structure even more
highly left-branching than the standard right-corner
transform, proved to be the most accurate approach.
The superior performance according to the EDIT-
F metric by REPAIRED-INT over REPAIRED-BIN
suggests that the improvement of REPAIRED-INT
over a baseline is not due simply to a new category.
The EDITED-BIN approach, while lowering overall
accuracy slightly, does almost as well on EDITED-F
as REPAIRED-INT, despite having a very different
representation of repair. This suggests that there are
elements of repair that this modification recognizes
that the others do not. This possibility will be ex-
plored in future work.
Another note of interest regards the recovery of
reparanda in the REPAIRED-INT case. As men-
tioned in Section 2.3, the EDITED section can be
found by tracing upwards in the tree from a RE-
PAIRED node of a certain type, to find an non-
repaired ancestor of the same type. This makes an
assumption that repairs are always maximally local,
which probably does not hurt accuracy, since most
repairs actually are quite short. However, this as-
sumption is obviously not true in the general case,
since in Figure 3 for example, the repair could trace
all the way back to the S label at the root of the tree
in the case of a restarted sentence. It is even possible
that this implicit incentive to short repairs is respon-
sible for some of the accuracy gains by discounting
long repairs. In any case, future work will attempt to
maintain the motivation behind the REPAIRED-INT
modification while relaxing hard assumptions about
repair distance.
</bodyText>
<sectionHeader confidence="0.999575" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999497454545455">
This paper introduced three potential syntactic rep-
resentations for speech with repairs, based on the
idea that errors are not recognized as such until a
correction is begun. The main result is a new rep-
resentation, REPAIRED-INT, which, when trans-
formed via the right-corner transform, makes a very
attractive model for speech with repairs. This rep-
resentation leads to a parser that improves on other
parsing approaches in both overall parsing accu-
racy and accuracy recognizing words that have been
edited.
</bodyText>
<page confidence="0.998719">
663
</page>
<sectionHeader confidence="0.995856" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999869277777778">
John J. Godfrey, Edward C. Holliman, and Jane Mc-
Daniel. 1992. Switchboard: Telephone speech corpus
for research and development. In Proc. ICASSP, pages
517–520.
John Hale, Izhak Shafran, Lisa Yung, Bonnie Dorr, Mary
Harper, Anna Krasnyanskaya, Matthew Lease, Yang
Liu, Brian Roark, Matthew Snover, and Robin Stew-
art. 2006. PCFGs with syntactic and prosodic indica-
tors of speech repairs. In Proceedings of the 45th An-
nual Conference of the Association for Computational
Linguistics (COLING-ACL).
Mark Johnson and Eugene Charniak. 2004. A tag-based
noisy channel model of speech repairs. In Proceed-
ings of the 42nd Annual Meeting of the Association
for Computational Linguistics (ACL ’04), pages 33–
39, Barcelona, Spain.
Mark Johnson. 1998. PCFG models of linguistic tree
representation. Computational Linguistics, 24:613–
632.
Dan Klein and Christopher D. Manning. 2003. Accu-
rate unlexicalized parsing. In Proceedings of the 41st
Annual Meeting of the Association for Computational
Linguistics, pages 423–430.
Willem J.M. Levelt. 1983. Monitoring and self-repair in
speech. Cognition, 14:41–104.
Tim Miller and William Schuler. 2008. A unified syn-
tactic model for parsing fluent and disfluent speech. In
Proceedings of the 46th Annual Meeting of the Associ-
ation for Computational Linguistics (ACL ’08).
Brian Roark and Mark Johnson. 1999. Efficient proba-
bilistic top-down and left-corner parsing. In Proceed-
ings of the 37th Annual Meeting of the Association for
Computational Linguistics (ACL 99).
Elizabeth Shriberg. 1994. Preliminaries to a Theory of
Speech Disfluencies. Ph.D. thesis, University of Cali-
fornia at Berkeley.
</reference>
<page confidence="0.998128">
664
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.977949">
<title confidence="0.999335">Syntactic Models for Parsing Speech with</title>
<author confidence="0.997541">Tim</author>
<affiliation confidence="0.9984515">Department of Computer Science and University of Minnesota, Twin</affiliation>
<email confidence="0.99881">tmill@cs.umn.edu</email>
<abstract confidence="0.998937428571429">This paper introduces three new syntactic models for representing speech with repairs. These models are developed to test the intuition that the erroneous parts of speech repairs (reparanda) are not generated or recognized as such while occurring, but only after they have been corrected. Thus, they are designed to minimize the differences in grammar rule applications between fluent and disfluent speech containing similar structure. The three models considered in this paper are also designed to isolate the mechanism of impact, by systematically exploring different variables.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>John J Godfrey</author>
<author>Edward C Holliman</author>
<author>Jane McDaniel</author>
</authors>
<title>Switchboard: Telephone speech corpus for research and development.</title>
<date>1992</date>
<booktitle>In Proc. ICASSP,</booktitle>
<pages>517--520</pages>
<contexts>
<context position="20771" citStr="Godfrey et al., 1992" startWordPosition="3442" endWordPosition="3445">ed to consider any categories related to speech repair until the repaired section has been completed. Moreover, the structure of the trees means that the parser is also building up structure from left to right. That mode of operation is useful for any model which purports to be potentially extensible to speech recognition or to model the human speech processor. In contrast, top-down parsers require exhaustive searches, meaning that they need to explore interpretations containing disfluency, even in the absence of syntactic cues for its existence. These experiments used the Switchboard corpus (Godfrey et al., 1992), a syntactically-annotated corpus of spontaneous dialogues between human interlocutors. This corpus is annotated for phrase structure in much the same way as the Penn Treebank 2The specific parser used is the Stanford parser described in Klein and Manning(2003), but run in “vanilla PCFG” mode. Wall Street Journal corpus, with the addition of several speech-specific categories as described in Section 2.1. For training, trees in sections 2 and 3 of this corpus were transformed as described in Section 2, and rule probabilities were estimated in the usual way. For testing, trees in section 4, sub</context>
</contexts>
<marker>Godfrey, Holliman, McDaniel, 1992</marker>
<rawString>John J. Godfrey, Edward C. Holliman, and Jane McDaniel. 1992. Switchboard: Telephone speech corpus for research and development. In Proc. ICASSP, pages 517–520.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Hale</author>
<author>Izhak Shafran</author>
<author>Lisa Yung</author>
<author>Bonnie Dorr</author>
<author>Mary Harper</author>
<author>Anna Krasnyanskaya</author>
<author>Matthew Lease</author>
<author>Yang Liu</author>
<author>Brian Roark</author>
<author>Matthew Snover</author>
<author>Robin Stewart</author>
</authors>
<title>PCFGs with syntactic and prosodic indicators of speech repairs.</title>
<date>2006</date>
<booktitle>In Proceedings of the 45th Annual Conference of the Association for Computational Linguistics (COLING-ACL).</booktitle>
<contexts>
<context position="968" citStr="Hale et al., 2006" startWordPosition="140" endWordPosition="143">repairs (reparanda) are not generated or recognized as such while occurring, but only after they have been corrected. Thus, they are designed to minimize the differences in grammar rule applications between fluent and disfluent speech containing similar structure. The three models considered in this paper are also designed to isolate the mechanism of impact, by systematically exploring different variables. 1 Introduction Recent work in recognition of speech with repairs has shown that syntactic cues to speech repair can improve both overall parsing accuracy and detection of repaired sections (Hale et al., 2006; Miller and Schuler, 2008; Johnson and Charniak, 2004). These techniques work by explictly modeling the structure of speech repair, specifically the tendency of repairs to follow unfinished constituents of the same category. This is the essence of what was termed the well-formedness rule by Willem Levelt (1983) in his psycholinguistic studies of repair. The work presented here uses the same motivations as those cited above (to be described in more detail below), in that it attempts to model the syntactic structure relating unfinished erroneous conPhis research was supported by NSF CAREER awar</context>
<context position="21972" citStr="Hale et al. (2006)" startWordPosition="3645" endWordPosition="3648">in section 4, subsections 0 and 1, were used. Data from the tail end of section 4 (subsections 3 and 4) was used during development of this work. Before doing any training or testing, all trees in the data set were stripped of punctuation, empty categories, typos, all categories representing repair structure, and partial words – anything that would be difficult or impossible to obtain reliably with a speech recognizer. A baseline parser was then trained and tested using the split described above, achieving standard results as seen in the table below. For a fair comparison to the evaluation in Hale et al. (2006), the parser was given part-of-speech tags along with each word as input. The structure obtained by the parser was then in the right-corner format. For standardized scoring, the right-corner transform, binarization, and augmented repair annotation were undone, so that comparison was done against the nearly pristine test corpus. Several test configurations were then evaluated, and compared to three baseline approaches. The two metrics used here are the standard Parseval F-measure, and Edit-finding F. The first takes the F-score of labeled precision and recall of the nonterminals in a hypothesiz</context>
<context position="23247" citStr="Hale et al. (2006)" startWordPosition="3849" endWordPosition="3852">asure marks words in the gold standard as edited if they are dominated by a node labeled EDITED, and measures the F-score of the hypothesized edited words relative to the gold standard (recall in this case is percentage of actual edited words that were hypothesized as edited, and precision is percentage of hypothesized edited words that were actually edited). The first three lines in the table refer to baseline approaches to compare against. “Plain” refers to a configuration with no modifications other than the removal of repair cues. The next result shown is a reproducton of the results from Hale et al. (2006) (described in section 1.2)3. The next line (“Standard 3The present work compares to the standard CYK parsing result from that paper, and not the result from a heavily optimized parser using lexicalization. S/VP S/NP VB IN for NP landfill S/PP could S/S NP S/S WHNP that S/VP NP EDITED-S VP-UNF could you 662 Right Corner”) is a reproduction of the results from Miller and Schuler (2008). The following three lines contain the three experimental configurations. First, the configuration denoted EDITED-BIN refers to the simple binarized speech repair described in Section 2.3 (Equation 6). REPAIRED-B</context>
</contexts>
<marker>Hale, Shafran, Yung, Dorr, Harper, Krasnyanskaya, Lease, Liu, Roark, Snover, Stewart, 2006</marker>
<rawString>John Hale, Izhak Shafran, Lisa Yung, Bonnie Dorr, Mary Harper, Anna Krasnyanskaya, Matthew Lease, Yang Liu, Brian Roark, Matthew Snover, and Robin Stewart. 2006. PCFGs with syntactic and prosodic indicators of speech repairs. In Proceedings of the 45th Annual Conference of the Association for Computational Linguistics (COLING-ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
<author>Eugene Charniak</author>
</authors>
<title>A tag-based noisy channel model of speech repairs.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL ’04),</booktitle>
<pages>33--39</pages>
<location>Barcelona,</location>
<contexts>
<context position="1023" citStr="Johnson and Charniak, 2004" startWordPosition="148" endWordPosition="151">gnized as such while occurring, but only after they have been corrected. Thus, they are designed to minimize the differences in grammar rule applications between fluent and disfluent speech containing similar structure. The three models considered in this paper are also designed to isolate the mechanism of impact, by systematically exploring different variables. 1 Introduction Recent work in recognition of speech with repairs has shown that syntactic cues to speech repair can improve both overall parsing accuracy and detection of repaired sections (Hale et al., 2006; Miller and Schuler, 2008; Johnson and Charniak, 2004). These techniques work by explictly modeling the structure of speech repair, specifically the tendency of repairs to follow unfinished constituents of the same category. This is the essence of what was termed the well-formedness rule by Willem Levelt (1983) in his psycholinguistic studies of repair. The work presented here uses the same motivations as those cited above (to be described in more detail below), in that it attempts to model the syntactic structure relating unfinished erroneous conPhis research was supported by NSF CAREER award 0447685. The views expressed are not necessarily endo</context>
<context position="5240" citStr="Johnson and Charniak (2004)" startWordPosition="824" endWordPosition="828">gories by appending the category below the EDITED label to the end of the EDITED label – for example, a noun phrase (NP) reparanda would be of type EDITED-NP. In addition, this approach made edit detection easier by propagating the -UNF label attached to the rightmost unfinished constituent up to the EDITED label. These two changes in combination allow the parser to better recognize when a reparandum has occurred, and to make siblings of reparanda and alterations with the same basic category label. Another model of speech repair that explicitly models the structure of speech repair is that of Johnson and Charniak (2004). That model has a different approach than the context-free parsing approach done in the present work. Instead, they run a treeadjoining grammar (TAG) parser which traces the overlapping words and part-of-speech tags that occur in the reparandum and alteration of a speech repair. This approach is highly accurate at detecting speech repairs, and allows for downstream processing of cleaned up text to be largely free of speech repair, but due to its TAG component it may present difficulties incorporating into an architecture that operates on streaming text or speech. This work is also similar in </context>
</contexts>
<marker>Johnson, Charniak, 2004</marker>
<rawString>Mark Johnson and Eugene Charniak. 2004. A tag-based noisy channel model of speech repairs. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL ’04), pages 33– 39, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
</authors>
<title>PCFG models of linguistic tree representation.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<pages>632</pages>
<contexts>
<context position="9576" citStr="Johnson (1998)" startWordPosition="1536" endWordPosition="1537">n of that rule, an interruption may occur which causes the rule to restart. 2.2 Right-Corner Transform The work described above by Miller and Schuler (2008) uses a right-corner transform. This transform turns right-branching structure into left-branching structure, using category labels that use a “slash” notation α/,y to represent an incomplete constituent of type α “looking for” a constituent of type -y in order to complete itself. Figure 2 shows the right-corner transformed tree from above. This transform first requires that trees be binarized. This binarization is done in a similar way to Johnson (1998) and Klein and Manning (2003). Rewrite rules for the right-corner transform are as follows, first flattening right-branching structure:1 WHNP-2 S DT that NP-SBJ PRP EDITED S NP-SBJ PRP you VP-UNF MD could PP-PRP IN for you MD could VB use NP NN landfill VP VP ⇒ A1/A2 A2/A3 A3 (1) A1 α1 A2 α2 A3 A1 α1 α2 a3 This sentence contains a restarted sentence (S) constituent, in which the speaker started by saying “you could”, then decided to restart the phrase, in this case without changing the first two words. One important thing to notice is that the EDITED label contains no information about the str</context>
</contexts>
<marker>Johnson, 1998</marker>
<rawString>Mark Johnson. 1998. PCFG models of linguistic tree representation. Computational Linguistics, 24:613– 632.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>423--430</pages>
<contexts>
<context position="9605" citStr="Klein and Manning (2003)" startWordPosition="1539" endWordPosition="1542">interruption may occur which causes the rule to restart. 2.2 Right-Corner Transform The work described above by Miller and Schuler (2008) uses a right-corner transform. This transform turns right-branching structure into left-branching structure, using category labels that use a “slash” notation α/,y to represent an incomplete constituent of type α “looking for” a constituent of type -y in order to complete itself. Figure 2 shows the right-corner transformed tree from above. This transform first requires that trees be binarized. This binarization is done in a similar way to Johnson (1998) and Klein and Manning (2003). Rewrite rules for the right-corner transform are as follows, first flattening right-branching structure:1 WHNP-2 S DT that NP-SBJ PRP EDITED S NP-SBJ PRP you VP-UNF MD could PP-PRP IN for you MD could VB use NP NN landfill VP VP ⇒ A1/A2 A2/A3 A3 (1) A1 α1 A2 α2 A3 A1 α1 α2 a3 This sentence contains a restarted sentence (S) constituent, in which the speaker started by saying “you could”, then decided to restart the phrase, in this case without changing the first two words. One important thing to notice is that the EDITED label contains no information about the structure beneath it. As a resul</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 423–430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Willem J M Levelt</author>
</authors>
<title>Monitoring and self-repair in speech.</title>
<date>1983</date>
<journal>Cognition,</journal>
<pages>14--41</pages>
<contexts>
<context position="1281" citStr="Levelt (1983)" startWordPosition="190" endWordPosition="191">esigned to isolate the mechanism of impact, by systematically exploring different variables. 1 Introduction Recent work in recognition of speech with repairs has shown that syntactic cues to speech repair can improve both overall parsing accuracy and detection of repaired sections (Hale et al., 2006; Miller and Schuler, 2008; Johnson and Charniak, 2004). These techniques work by explictly modeling the structure of speech repair, specifically the tendency of repairs to follow unfinished constituents of the same category. This is the essence of what was termed the well-formedness rule by Willem Levelt (1983) in his psycholinguistic studies of repair. The work presented here uses the same motivations as those cited above (to be described in more detail below), in that it attempts to model the syntactic structure relating unfinished erroneous conPhis research was supported by NSF CAREER award 0447685. The views expressed are not necessarily endorsed by the sponsors. stituents to the repair of those constituents. However, this work attempts to improve on those models by focusing on the generative process used by a speaker in creating the repair. This is done first by eschewing any labels representin</context>
</contexts>
<marker>Levelt, 1983</marker>
<rawString>Willem J.M. Levelt. 1983. Monitoring and self-repair in speech. Cognition, 14:41–104.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Miller</author>
<author>William Schuler</author>
</authors>
<title>A unified syntactic model for parsing fluent and disfluent speech.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL ’08).</booktitle>
<contexts>
<context position="994" citStr="Miller and Schuler, 2008" startWordPosition="144" endWordPosition="147"> are not generated or recognized as such while occurring, but only after they have been corrected. Thus, they are designed to minimize the differences in grammar rule applications between fluent and disfluent speech containing similar structure. The three models considered in this paper are also designed to isolate the mechanism of impact, by systematically exploring different variables. 1 Introduction Recent work in recognition of speech with repairs has shown that syntactic cues to speech repair can improve both overall parsing accuracy and detection of repaired sections (Hale et al., 2006; Miller and Schuler, 2008; Johnson and Charniak, 2004). These techniques work by explictly modeling the structure of speech repair, specifically the tendency of repairs to follow unfinished constituents of the same category. This is the essence of what was termed the well-formedness rule by Willem Levelt (1983) in his psycholinguistic studies of repair. The work presented here uses the same motivations as those cited above (to be described in more detail below), in that it attempts to model the syntactic structure relating unfinished erroneous conPhis research was supported by NSF CAREER award 0447685. The views expre</context>
<context position="2935" citStr="Miller and Schuler, 2008" startWordPosition="452" endWordPosition="455">detecting the occasion of repair.” Rather than attempting to recognize a special syntactic category called EDITED during the processing phase, this work introduces the REPAIRED category to signal the ending of a repaired section only. The second part of the modeling framework is the use of a right-corner transform on training data, which converts phrase-structure trees into heavily left-branching structures. This transformation has been shown to represent the structure of unfinished constituents like those seen in speech repair in a natural way, leading to improved detection of speech repair (Miller and Schuler, 2008). Combining these two modeling techniques in a bottom-up parsing framework results in a parsing architecture that is a reasonable approximation to the sequential processing that must be done by the human speech processor when recognizing spoken language with repairs. This parser also recognizes sentences containing speech repair with better accuracy than the previous models on which it is based. 656 Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 656–664, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics There</context>
<context position="7039" citStr="Miller and Schuler (2008)" startWordPosition="1129" endWordPosition="1132">ether the next word will be, e.g., a common noun (NN), plural noun (NNS), or proper noun (NNP), until it sees the actual next word. Similarly, the model presented in this work aims to delay the decision to create a speech repair as much as possible. This is done here by eliminating the EDITED category (representing a reparandum) during processing, replacing it with a REPAIRED category which represents the alteration of a speech repair, and by eliminating implicit cues about repair happening before a decision to repair should be necessary. Finally, this work is most directly related to that of Miller and Schuler (2008). In that work, the authors used a right-corner transform to turn standard phrase-structure trees into highly left-branching trees with sub-tree category labels representing incomplete but in-progress constituent structure. That structure was shown to have desirable properties in the representation of repair in syntax trees, and this work leverages that insight, while attempting to improve the input representation such that the rightcorner representation does not require the parser to make any assumptions or decisions earlier than necessary. 657 2 Syntactic Model This section will first descri</context>
<context position="9118" citStr="Miller and Schuler (2008)" startWordPosition="1463" endWordPosition="1466">opment set, containing both an EDITED constituent and an -UNF tag. ing to learn from this structure, for example a probabilistic context-free grammar, will result in the rule that a sentence (S) consists of a reparandum, a noun phrase, and a verb phrase, which is an odd way of thinking about both constituent structure and meaning. A more intuitive understanding might be that a sentence may consist of a noun phrase followed by a verb phrase, and during the production of that rule, an interruption may occur which causes the rule to restart. 2.2 Right-Corner Transform The work described above by Miller and Schuler (2008) uses a right-corner transform. This transform turns right-branching structure into left-branching structure, using category labels that use a “slash” notation α/,y to represent an incomplete constituent of type α “looking for” a constituent of type -y in order to complete itself. Figure 2 shows the right-corner transformed tree from above. This transform first requires that trees be binarized. This binarization is done in a similar way to Johnson (1998) and Klein and Manning (2003). Rewrite rules for the right-corner transform are as follows, first flattening right-branching structure:1 WHNP-</context>
<context position="23634" citStr="Miller and Schuler (2008)" startWordPosition="3916" endWordPosition="3919">nes in the table refer to baseline approaches to compare against. “Plain” refers to a configuration with no modifications other than the removal of repair cues. The next result shown is a reproducton of the results from Hale et al. (2006) (described in section 1.2)3. The next line (“Standard 3The present work compares to the standard CYK parsing result from that paper, and not the result from a heavily optimized parser using lexicalization. S/VP S/NP VB IN for NP landfill S/PP could S/S NP S/S WHNP that S/VP NP EDITED-S VP-UNF could you 662 Right Corner”) is a reproduction of the results from Miller and Schuler (2008). The following three lines contain the three experimental configurations. First, the configuration denoted EDITED-BIN refers to the simple binarized speech repair described in Section 2.3 (Equation 6). REPAIRED-BIN refers to the binarized speech repair in which the labels are basically reversed from EDITED-BIN (Equation 5). Finally, REPAIRED-INT refers to the speech repair type where the REPAIRED category may be a child of a non-identity category, representing an interruption of the outermost desired constituent (Equation 4). System Configuration Parseval-F Edited-F Baseline 71.03 17.9 Hale e</context>
</contexts>
<marker>Miller, Schuler, 2008</marker>
<rawString>Tim Miller and William Schuler. 2008. A unified syntactic model for parsing fluent and disfluent speech. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL ’08).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Roark</author>
<author>Mark Johnson</author>
</authors>
<title>Efficient probabilistic top-down and left-corner parsing.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics (ACL 99).</booktitle>
<contexts>
<context position="5928" citStr="Roark and Johnson (1999)" startWordPosition="941" endWordPosition="944">ing approach done in the present work. Instead, they run a treeadjoining grammar (TAG) parser which traces the overlapping words and part-of-speech tags that occur in the reparandum and alteration of a speech repair. This approach is highly accurate at detecting speech repairs, and allows for downstream processing of cleaned up text to be largely free of speech repair, but due to its TAG component it may present difficulties incorporating into an architecture that operates on streaming text or speech. This work is also similar in aim to a component of the parsing and language modeling work of Roark and Johnson (1999), which used right-binarization in order to delay decision-making about constituents as much as possible. For example, the rule NP → DT NN might be right-binarized as two rules: NP → DT NP-DT and NP-DT → NN The result of this binarization is that when predicting the noun phrase (NP) rule, a top-down parser is delaying making any commitments about the category following the determiner (DT). This delay in prediction means that the parser does not need to make any predictions about whether the next word will be, e.g., a common noun (NN), plural noun (NNS), or proper noun (NNP), until it sees the </context>
</contexts>
<marker>Roark, Johnson, 1999</marker>
<rawString>Brian Roark and Mark Johnson. 1999. Efficient probabilistic top-down and left-corner parsing. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics (ACL 99).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elizabeth Shriberg</author>
</authors>
<title>Preliminaries to a Theory of Speech Disfluencies.</title>
<date>1994</date>
<tech>Ph.D. thesis,</tech>
<institution>University of California at Berkeley.</institution>
<contexts>
<context position="3841" citStr="Shriberg, 1994" startWordPosition="588" endWordPosition="589">izes sentences containing speech repair with better accuracy than the previous models on which it is based. 656 Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 656–664, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics Therefore, these syntactic models hold promise for integration into systems for processing of streaming speech. 1.1 Speech Repair Terminology A speech repair occurs when a speaker decides to interrupt the flow of speech and restart part or all of an utterance. Typically speech repair structure (Shriberg, 1994) is considered to contain a reparandum, or the part of the utterance to be replaced, and an alteration, which is meant to replace the reparandum section. There are also frequently editing terms (for example, ‘uh’ and ‘um’) between the reparandum and alteration, which may be used to signal the repair, or to indicate that the speaker is thinking, or just to maintain control of the dialogue. 1.2 Related Work This work is related to that of Hale et al.(2006) in that it attempts to model the syntactic structure of speech repair. In that paper speech repair detection accuracy was increased by explic</context>
</contexts>
<marker>Shriberg, 1994</marker>
<rawString>Elizabeth Shriberg. 1994. Preliminaries to a Theory of Speech Disfluencies. Ph.D. thesis, University of California at Berkeley.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>