<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000086">
<title confidence="0.9972655">
Optimal Reduction of Rule Length
in Linear Context-Free Rewriting Systems
</title>
<author confidence="0.999602">
Carlos G´omez-Rodriguez1, Marco Kuhlmann2, Giorgio Satta3 and David Weir4
</author>
<affiliation confidence="0.93022025">
1 Departamento de Computaci´on, Universidade da Coru˜na, Spain (cgomezr@udc.es)
2 Department of Linguistics and Philology, Uppsala University, Sweden (marco.kuhlmann@lingfil.uu.se)
3 Department of Information Engineering, University of Padua, Italy (satta@dei.unipd.it)
4 Department of Informatics, University of Sussex, United Kingdom (davidw@sussex.ac.uk)
</affiliation>
<sectionHeader confidence="0.994762" genericHeader="abstract">
Abstract
</sectionHeader>
<subsectionHeader confidence="0.501508">
Linear Context-free Rewriting Systems
</subsectionHeader>
<bodyText confidence="0.997939">
(LCFRS) is an expressive grammar formalism
with applications in syntax-based machine
translation. The parsing complexity of an
LCFRS is exponential in both the rank
of a production, defined as the number of
nonterminals on its right-hand side, and a
measure for the discontinuity of a phrase,
called fan-out. In this paper, we present
an algorithm that transforms an LCFRS
into a strongly equivalent form in which
all productions have rank at most 2, and
has minimal fan-out. Our results generalize
previous work on Synchronous Context-Free
Grammar, and are particularly relevant for
machine translation from or to languages that
require syntactic analyses with discontinuous
constituents.
</bodyText>
<sectionHeader confidence="0.999474" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999979666666667">
There is currently considerable interest in syntax-
based models for statistical machine translation that
are based on the extraction of a synchronous gram-
mar from a corpus of word-aligned parallel texts;
see for instance Chiang (2007) and the references
therein. One practical problem with this approach,
apart from the sheer number of the rules that result
from the extraction procedure, is that the parsing
complexity of all synchronous formalisms that we
are aware of is exponential in the rank of a rule,
defined as the number of nonterminals on the right-
hand side. Therefore, it is important that the rules
of the extracted grammar are transformed so as to
minimise this quantity. Not only is this beneficial in
terms of parsing complexity, but smaller rules can
also improve a translation model’s ability to gener-
alize to new data (Zhang et al., 2006).
Optimal algorithms exist for minimising the size
of rules in a Synchronous Context-Free Gram-
mar (SCFG) (Uno and Yagiura, 2000; Zhang et al.,
2008). However, the SCFG formalism is limited
to modelling word-to-word alignments in which a
single continuous phrase in the source language is
aligned with a single continuous phrase in the tar-
get language; as defined below, this amounts to
saying that SCFG have a fan-out of 2. This re-
striction appears to render SCFG empirically inad-
equate. In particular, Wellington et al. (2006) find
that the coverage of a translation model can increase
dramatically when one allows a bilingual phrase to
stretch out over three rather than two continuous
substrings. This observation is in line with empir-
ical studies in the context of dependency parsing,
where the need for formalisms with higher fan-out
has been observed even in standard, single language
texts (Kuhlmann and Nivre, 2006).
In this paper, we present an algorithm that com-
putes optimal decompositions of rules in the for-
malism of Linear Context-Free Rewriting Systems
(LCFRS) (Vijay-Shanker et al., 1987). LCFRS was
originally introduced as a generalization of sev-
eral so-called mildly context-sensitive grammar for-
malisms. In the context of machine translation,
LCFRS is an interesting generalization of SCFG be-
cause it does not restrict the fan-out to 2, allow-
ing productions with arbitrary fan-out (and arbitrary
rank). Given an LCFRS, our algorithm computes a
strongly equivalent grammar with rank 2 and min-
</bodyText>
<page confidence="0.977988">
539
</page>
<note confidence="0.890353">
Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 539–547,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.99994471875">
imal increase in fan-out.1 In this context, strong
equivalence means that the derivations of the orig-
inal grammar can be reconstructed using some sim-
ple homomorphism (c.f. Nijholt, 1980). Our contri-
bution is significant because the existing algorithms
for decomposing SCFG, based on Uno and Yagiura
(2000), cannot be applied to LCFRS, as they rely
on the crucial property that components of biphrases
are strictly separated in the generated string: Given a
pair of synchronized nonterminal symbols, the ma-
terial derived from the source nonterminal must pre-
cede the material derived from the target nontermi-
nal, or vice versa. The problem that we solve has
been previously addressed by Melamed et al. (2004),
but in contrast to our result, their algorithm does not
guarantee an optimal (minimal) increase in the fan-
out of the resulting grammar. However, this is essen-
tial for the practical applicability of the transformed
grammar, as the parsing complexity of LCFRS is ex-
ponential in both the rank and the fan-out.
Structure of the paper The remainder of the pa-
per is structured as follows. Section 2 introduces the
terminology and notation that we use for LCFRS.
In Section 3, we present the technical background
of our algorithm; the algorithm itself is discussed
in Section 4. Section 5 concludes the paper by dis-
cussing related work and open problems.
General notation The set of non-negative integers
is denoted by N. For i, j ∈ N, we write [i, j] to
denote the interval { k ∈ N  |i ≤ k ≤ j }, and use
[i] as a shorthand for [1, i]. Given an alphabet V , we
write V * for the set of all (finite) strings over V .
</bodyText>
<sectionHeader confidence="0.992323" genericHeader="introduction">
2 Preliminaries
</sectionHeader>
<bodyText confidence="0.999451666666667">
We briefly summarize the terminology and notation
that we adopt for LCFRS; for detailed definitions,
see Vijay-Shanker et al. (1987).
</bodyText>
<subsectionHeader confidence="0.997317">
2.1 Linear, non-erasing functions
</subsectionHeader>
<bodyText confidence="0.988494">
Let V be an alphabet. For natural numbers r ≥ 0
and f, f1, ... , fr ≥ 1, a function
</bodyText>
<equation confidence="0.803795">
g : (V*)fl × ··· × (V *)fr → (V *)f
</equation>
<footnote confidence="0.967385666666667">
1Rambow and Satta (1999) show that without increasing
fan-out it is not always possible to produce even weakly equiv-
alent grammars.
</footnote>
<bodyText confidence="0.603619333333333">
is called a linear, non-erasing function over V of
type f1 × · · · × fr → f, if it can be defined by an
equation of the form
</bodyText>
<equation confidence="0.80032">
g(hx1,1,...,x1,f1i, ... ,hxr,1, ..., xr,fri) = Qg ,
</equation>
<bodyText confidence="0.9999362">
where Qg = hαg,1, ... , αg,fi is an f-tuple of strings
over the variables on the left-hand side of the equa-
tion and symbols in V that contains exactly one oc-
currence of each variable. We call the value r the
rank of g, the value f its fan-out, and write ρ(g)
and co(g), respectively, to denote these quantities.
Note that, if we assume the variables on the left-
hand side of the defining equation of g to be named
according to the specific schema given above, then g
is uniquely determined by Qg.
</bodyText>
<subsectionHeader confidence="0.997153">
2.2 Linear context-free rewriting systems
</subsectionHeader>
<bodyText confidence="0.911878">
A linear context-free rewriting system (LCFRS)
is a construct G = (VN, VT, P, 5), where: VN is
an alphabet of nonterminal symbols in which each
symbol A ∈ VN is associated with a value co(A),
called its fan-out; VT is an alphabet of terminal
symbols; 5 ∈ N is a distinguished start symbol with
co(5) = 1; and P is a set of productions of the form
</bodyText>
<equation confidence="0.732851">
p : A → g(B1,B2, ... , Br) ,
</equation>
<bodyText confidence="0.999395894736842">
where A, B1, ... , Br ∈ VN, and g is a linear, non-
erasing function over the terminal alphabet VT of
type co(B1) × · · · × co(Br) → co(A). In a deriva-
tion of an LCFRS, the production p can be used to
transform a sequence of r tuples of strings, gener-
ated by the nonterminals B1, ... , Br, into a single
co(A)-tuple of strings, associated with the nonter-
minal A. The values ρ(g) and co(g) are called the
rank and fan-out of p, respectively, and we write
ρ(p) and co(p), respectively, to denote these quan-
tities. The rank and fan-out of G, written ρ(G)
and co(G), respectively, are the maximum rank and
fan-out among all of its productions. Given that
co(5) = 1, a derivation will associate 5 with a set of
one-component tuples of strings over VT; this forms
the string language generated by G.
Example 1 The following LCFRS generates the
string language { anbncndn  |n ∈ N}. We only
specify the set of productions; the remaining com-
</bodyText>
<page confidence="0.990246">
540
</page>
<bodyText confidence="0.989989">
ponents of the grammar are obvious from that.
</bodyText>
<equation confidence="0.9999">
S → g1(R) g1(hx1,1,x1,2i) = hx1,1x1,2i
R → g2(R) g2(hx1,1, x1,2i) = hax1,1b,cx1,2di
R → g3 g3 = hε, εi
</equation>
<bodyText confidence="0.999595666666667">
The functions g1 and g2 have rank 1; the function g3
has rank 0. The functions g2 and g3 have fan-out 2;
the function g1 has fan-out 1. ❑
</bodyText>
<sectionHeader confidence="0.971166" genericHeader="method">
3 Technical background
</sectionHeader>
<bodyText confidence="0.999978722222223">
The general idea behind our algorithm is to replace
each production of an LCFRS with a set of “shorter”
productions that jointly are equivalent to the original
production. Before formalizing this idea, we first in-
troduce a specialized representation for the produc-
tions of an LCFRS.
We distinguish between occurrences of symbols
within a string by exploiting two different notations.
Let α = a1a2 · · · an be a string. The occurrence ai
in α can be denoted by means of its position index
i ∈ [n], or else by means of its two (left and right)
endpoints, i −1 and i; here, the left (right) endpoint
denotes a boundary between occurrence ai and the
previous (subsequent) occurrence, or the beginning
(end) of the string α. Similarly, a substring ai · · · aj
of α with i ≤ j can be denoted by the positions
i, i + 1, ... , j of its occurrences, or else by means of
its left and right endpoints, i − 1 and j.
</bodyText>
<subsectionHeader confidence="0.996627">
3.1 Production representation
</subsectionHeader>
<bodyText confidence="0.785642">
For the remainder of this section, let us fix an
</bodyText>
<listItem confidence="0.788415">
LCFRS G = (VN, VT, P, S) and a production
p : A → g(B1, ... , Br) of G, with g defined as
in Section 2.1. We define
</listItem>
<equation confidence="0.990301666666667">
ϕ(g)
|p |= ϕ(g) + |αg,i|.
i=1
</equation>
<bodyText confidence="0.998714333333333">
Let $ be a fresh symbol that does not occur in G. We
define the characteristic string of the production p
as
</bodyText>
<equation confidence="0.986107">
σ(p) = αg,1$ ··· $αg,ϕ(g) ,
</equation>
<bodyText confidence="0.9715084">
and the variable string of p as the string σN(p) ob-
tained from σ(p) by removing all the occurrences of
symbols in VT.
Example 2 We will illustrate the concepts intro-
duced in this section using the concrete production
</bodyText>
<equation confidence="0.9789118">
p0 : A → g(B1, B2, B3), where
βg = hx1,1ax2,1x1,2, x3,1bx3,2i .
In this case, we have
σ(p0) = x1,1ax2,1x1,2$x3,1bx3,2 , and
σN(p0) = x1,1x2,1x1,2$x3,1x3,2 . ❑
</equation>
<bodyText confidence="0.987553142857143">
Let I be an index set, I ⊆ [r]. Consider the set B of
occurrences Bi in the right-hand side of p such that
i ∈ I.2 We define the position set of B, denoted
by ΠB, as the set of all positions 1 ≤ j ≤ |σN(p)|
such that the jth symbol in σN(p) is a variable of the
form xi,h, for i ∈ I and some h ≥ 1.
Example 3 Some position sets of p0 are
</bodyText>
<equation confidence="0.954371">
Π{B1} = {1, 3}, Π{B2} = {2}, Π{B3} = {5, 6} .
❑
</equation>
<bodyText confidence="0.99934975">
A position set ΠB can be uniquely expressed as the
union of f ≥ 1 intervals [l1 + 1, r1], ... , [lf + 1, rf]
such that ri−1 &lt; li for every 1 &lt; i ≤ f. Thus we
define the set of endpoints of ΠB as
</bodyText>
<equation confidence="0.866236">
ΔB = {lj  |j ∈ [f] } ∪ {rj  |j ∈ [f] } .
</equation>
<bodyText confidence="0.996465125">
The quantity f is called the fan-out of ΠB, writ-
ten ϕ(ΠB). Notice that the fan-out of a position set
Π{B} does not necessarily coincide with the fan-out
of the non-terminal B in the underlying LCFRS. A
set with 2f endpoints always corresponds to a posi-
tion set of fan-out f.
Example 4 For our running example, we have
Δ{B1} = {0,1, 2, 3}, Δ{B2} = {1, 2}, Δ{B3} =
{4, 6}. Consequently, the fan-out of Δ{B1} is 2, and
the fan-out of Δ{B2} and Δ{B3} is 1. Notice that the
fan-out of the non-terminal B3 is 2. ❑
We drop B from ΠB and ΔB whenever this set is
understood from the context or it is not relevant.
Given a set of endpoints Δ = {i1,... , i2f} with
i1 &lt; · · · &lt; i2f, we obtain its corresponding position
set by calculating the closure of Δ, defined as
</bodyText>
<equation confidence="0.94818">
[Δ] = Ufj=1[i2j−1 + 1, i2j] .
</equation>
<bodyText confidence="0.572484333333333">
2To avoid clutter in our examples, we abuse the notation by
not making an explicit distinction between nonterminals and oc-
currences of nonterminals in productions.
</bodyText>
<page confidence="0.987984">
541
</page>
<subsectionHeader confidence="0.99439">
3.2 Reductions
</subsectionHeader>
<bodyText confidence="0.999980166666667">
Assume that r &gt; 2. The reduction of p by the non-
terminal occurrences Br−1, Br is the ordered pair of
productions (p1, p2) that is defined as follows. Let
γ1, ... ,γn be the maximal substrings of σ(p) that
contain only variables xi,j with r— 1 G i G r and
terminal symbols, and at least one variable. Then
</bodyText>
<equation confidence="0.9957055">
p1 : A —* g1(B1,...,Br−2,X) and
p2 : X —* g2(Br−1, Br) ,
</equation>
<bodyText confidence="0.998324461538462">
where X is a fresh nonterminal symbol, the char-
acteristic string σ(p1) is the string obtained from
σ(p) by replacing each substring γi by the vari-
able xr−1,i, and the characteristic string σ(p2) is the
string γ1$ ··· $γn.
Note that the defining equations of neither g1
nor g2 are in the specific form discussed in Sec-
tion 2.1; however, they can be brought into this form
by a consistent renaming of the variables. We will
silently assume this renaming to take place.
Example 5 The reduction of p0 by the nonterminal
occurrences B2 and B3 has p1 : A —* g1(B1, X)
and p2 : X —* g2(B2, B3) with
</bodyText>
<equation confidence="0.9993095">
σ(p1) = x1,1x2,1x1,2$x2,2
σ(p2) = ax2,1$x3,1bx3,2
</equation>
<bodyText confidence="0.808981">
or, after renaming and in standard notation,
</bodyText>
<equation confidence="0.828796">
g1((x1,1, x1,2), (x2,1, x2,2)) = (x1,1x2,1x1,2, x2,2)
g2((x1,1), (x2,1, x2,2)) = (ax1,1,x2,1bx2,2) .✷
</equation>
<bodyText confidence="0.949049">
It is easy to check that a reduction provides us with a
pair of productions that are equivalent to the original
production p, in terms of generative capacity, since
</bodyText>
<equation confidence="0.988599">
g1(B1,...,Br−2,g2(Br−1,Br)) = g(B1,...,Br)
</equation>
<bodyText confidence="0.997233111111111">
for all tuples of strings generated from the nontermi-
nals B1, ... , Br, respectively. Note also that the fan-
out of production p1 equals the fan-out of p. How-
ever, the fan-out of p2 (the value n) may be greater
than the fan-out of p, depending on the way vari-
ables are arranged in σ(p). Thus, a reduction does
not necessarily preserve the fan-out of the original
production. In the worst case, the fan-out of p2 can
be as large as ϕ(Br−1) + ϕ(Br).
</bodyText>
<listItem confidence="0.99591125">
1: Function NAIVE-BINARIZATION(p)
2: result +— 0;
3: currentProd +— p;
4: while ρ(currentProd) &gt; 2 do
5: (p1,p2) +— any reduction of currentProd;
6: result +— result U p2;
7: currentProd +— p1;
8: return result U currentProd;
</listItem>
<figureCaption confidence="0.999876">
Figure 1: The naive algorithm
</figureCaption>
<bodyText confidence="0.9999715">
We have defined reductions only for the last two
occurrences of nonterminals in the right-hand side of
a production p. However, it is easy to see that we can
also define the concept for two arbitrary (not neces-
sarily adjacent) occurrences of nonterminals, at the
cost of making the notation more complicated.
</bodyText>
<sectionHeader confidence="0.996595" genericHeader="method">
4 The algorithm
</sectionHeader>
<bodyText confidence="0.999963285714286">
Let G be an LCFRS with ϕ(G) = f and ρ(G) = r,
and let f0 &gt; f be a target fan-out. We will now
present an algorithm that computes an equivalent
LCFRS G0 of fan-out at most f0 whose rank is at
most 2, if such an LCFRS exists in the first place.
The algorithm works by exhaustively reducing all
productions in G.
</bodyText>
<subsectionHeader confidence="0.982573">
4.1 Naive algorithm
</subsectionHeader>
<bodyText confidence="0.999901263157895">
Given an LCFRS production p, a naive algorithm
to compute an equivalent set of productions whose
rank is at most 2 is given in Figure 1. By ap-
plying this algorithm to all the productions in the
LCFRS G, we can obtain an equivalent LCFRS with
rank 2. We will call such an LCFRS a binarization
of G.
The fan-out of the obtained LCFRS will depend
on the nonterminals that we choose for the reduc-
tions in line 5. It is not difficult to see that, in the
worst case, the resulting fan-out can be as high as
Fr2] · f. This occurs when we choose Fr2] nonter-
minals with fan-out f that have associated variables
in the string σN(p) that do not occur at consecutive
positions.
The algorithm that we develop in Section 4.3 im-
proves on the naive algorithm in that it can be ex-
ploited to find a sequence of reductions that results
in a binarization of G that is optimal, i.e., leads to
</bodyText>
<page confidence="0.986396">
542
</page>
<bodyText confidence="0.9965835">
an LCFRS with minimal fan-out. The algorithm is
based on a technical concept called adjacency.
</bodyText>
<subsectionHeader confidence="0.960704">
4.2 Adjacency
</subsectionHeader>
<bodyText confidence="0.9998715">
Let p be some production in the LCFRS G, and let
Δ1, Δ2 be sets of endpoints, associated with some
sets of nonterminal occurrences in p. We say that Δ1
and Δ2 overlap if the intersection of their closures
is nonempty, that is, if [Δ1]∩[Δ2] =6 ∅. Overlapping
holds if and only if the associated sets of nontermi-
nal occurrences are not disjoint. If Δ1 and Δ2 do
not overlap, we define their merge as
</bodyText>
<equation confidence="0.768353">
⊕(Δ1, Δ2) = (Δ1 ∪ Δ2) \ (Δ1 ∩ Δ2) .
</equation>
<bodyText confidence="0.9395545">
It is easy to see that [⊕(Δ1, Δ2)] = [Δ1] ∪ [Δ2].
We say that Δ1 and Δ2 are adjacent for a given fan-
out f, written Δ1 ↔f Δ2, if Δ1 and Δ2 do not
overlap, and co([⊕(Δ1, Δ2)]) ≤ f.
Example 6 For the production p0 from Example 2,
we have ⊕(Δ{B1}, Δ{B2}) = {0, 3}, showing that
Δ{B1} ↔1 Δ{B2}. Similarly, we have
⊕(Δ{B1}, Δ{B3}) = {0, 1, 2, 3, 4, 6} ,
showing that Δ{B1} ↔3 Δ{B3}, but that neither
Δ{B1} ↔2 Δ{B3} nor Δ{B1} ↔1 Δ{B3} holds. ✷
</bodyText>
<subsectionHeader confidence="0.99248">
4.3 Bounded binarization algorithm
</subsectionHeader>
<bodyText confidence="0.9999277">
The adjacency-based binarization algorithm is given
in Figure 2. It starts with a working set contain-
ing the endpoint sets corresponding to each non-
terminal occurrence in the input production p. Re-
ductions of p are only explored for nonterminal oc-
currences whose endpoint sets are adjacent for the
target fan-out f0, since reductions not meeting this
constraint would produce productions with fan-out
greater than f0. Each reduction explored by the al-
gorithm produces a new endpoint set, associated to
the fresh nonterminal that it introduces, and this new
endpoint set is added to the working set and poten-
tially used in further reductions.
From the definition of the adjacency relation ↔f,
it follows that at lines 9 and 10 of BOUNDED-
BINARIZATION we only pick up reductions for p
that do not exceed the fan-out bound of f0. This
implies soundness for our algorithm. Completeness
means that the algorithm fails only if there exists no
binarization for p of fan-out not greater than f0. This
</bodyText>
<listItem confidence="0.960608529411765">
1: Function BOUNDED-BINARIZATION(p, f0)
2: workingSet ← ∅;
3: agenda ← ∅;
4: for all i from 1 to ρ(p) do
5: workingSet ← workingSet ∪ {Δ{Bi}};
6: agenda ← agenda ∪ {Δ{Bi}};
7: while agenda =6 ∅ do
8: Δ ← pop some endpoint set from agenda;
9: for all Δ1 ∈ workingSet with Δ1 ↔f, Δ do
10: Δ2 = ⊕(Δ, Δ1);
11: if Δ2 ∈/ workingSet then
12: workingSet ← workingSet ∪ {Δ2};
13: agenda ← agenda ∪ {Δ2};
14: if Δ{B1,B2,...,Bρ(p))} ∈ workingSet then
15: return true;
16: else
17: return false;
</listItem>
<figureCaption confidence="0.998523">
Figure 2: Algorithm to compute a bounded binarization
</figureCaption>
<bodyText confidence="0.99932168">
property is intuitive if one observes that our algo-
rithm is a specialization of standard algorithms for
the computation of the closure of binary relations.
A formal proof of this fact is rather long and te-
dious, and will not be reported here. We notice that
there is a very close similarity between algorithm
BOUNDED-BINARIZATION and the deduction pro-
cedure proposed by Shieber et al. (1995) for parsing.
We discuss this more at length in Section 5.
Note that we have expressed the algorithm as a
decision function that will return true if there exists
a binarization of p with fan-out not greater than f0,
and false otherwise. However, the algorithm can
easily be modified to return a reduction producing
such a binarization, by adding to each endpoint set
Δ ∈ workingSet two pointers to the adjacent end-
point sets that were used to obtain it. If the algorithm
is successful, the tree obtained by following these
pointers from the final endpoint set Δ{B1,...,Bρ(p)} ∈
workingSet gives us a tree of reductions that will
produce a binarization of p with fan-out not greater
than f0, where each node labeled with the set Δ{Bi}
corresponds to the nonterminal BZ, and nodes la-
beled with other endpoint sets correspond to the
fresh nonterminals created by the reductions.
</bodyText>
<page confidence="0.996533">
543
</page>
<subsectionHeader confidence="0.962898">
4.4 Implementation
</subsectionHeader>
<bodyText confidence="0.999990805555556">
In order to implement BOUNDED-BINARIZATION,
we can represent endpoint sets in a canonical way
as 2f0-tuples of integer positions in ascending order,
and with some special null value used to fill posi-
tions for endpoint sets with fan-out strictly smaller
than f0. We will assume that the concrete null value
is larger than any other integer.
We also need to provide some appropriate repre-
sentation for the set workingSet, in order to guar-
antee efficient performance for the membership test
and the insertion operation. Both operations can be
implemented in constant time if we represent work-
ingSet as an (2×f0)-dimensional table with Boolean
entries. Each dimension is indexed by values in
[0, n] plus our special null value; here n is the length
of the string σN(p), and thus n = O(|p|). However,
this has the disadvantage of using space Θ(n2f0),
even in case workingSet is sparse, and is affordable
only for quite small values of f0. Alternatively, we
can more compactly represent workingSet as a trie
data structure. This representation has size certainly
smaller than 2f0 × q, where q is the size of the set
workingSet. However, both membership and inser-
tion operations take now an amount of time O(2f0).
We now analyse the time complexity of algorithm
BOUNDED-BINARIZATION for inputs p and f0. We
first focus on the while-loop at lines 7 to 13. As
already observed, the number of possible endpoint
sets is bounded by O(n2f0). Furthermore, because
of the test at line 11, no endpoint set is ever inserted
into the agenda variable more than once in a sin-
gle run of the algorithm. We then conclude that our
while-loop cycles a number of times O(n2f0).
We now focus on the choice of the endpoint set
Δ1 in the inner for-loop at lines 9 to 13. Let us fix Δ
as in line 8. It is not difficult to see that any Δ1 with
</bodyText>
<equation confidence="0.9047422">
Δ1 ↔f0 Δ must satisfy
ϕ(Δ) + ϕ(Δ1) − |Δ ∩ Δ1 |≤ f0. (1)
Let I ⊆ Δ, and consider all endpoint sets Δ1 with
Δ ∩ Δ1 = I. Given (1), we also have
ϕ(Δ1) ≤ f0 + |I |− ϕ(Δ). (2)
</equation>
<bodyText confidence="0.9970935">
This means that, for each Δ coming out of the
agenda, at line 9 we can choose all endpoint sets Δ1
such that Δ1 ↔f0 Δ by performing the following
steps:
</bodyText>
<listItem confidence="0.903033">
• arbitrarily choose a set I ⊆ Δ;
• choose endpoints in set Δ1\I subject to (2);
• test whether Δ1 belongs to workingSet and
whether Δ, Δ1 do not overlap.
</listItem>
<bodyText confidence="0.8531388">
We claim that, in the above steps, the number
of involved endpoints does not exceed 3f0. To
see this, we observe that from (2) we can derive
|I |≥ ϕ(Δ) + ϕ(Δ1) − f0. The total number
of (distinct) endpoints in a single iteration step is
</bodyText>
<equation confidence="0.972716">
e = 2ϕ(Δ) + 2ϕ(Δ1) − |I|. Combining with the
above inequality we have
e ≤ 2ϕ(Δ) + 2ϕ(Δ1) − ϕ(Δ) − ϕ(Δ1) + f0
= ϕ(Δ) + ϕ(Δ1) + f0 ≤ 3f0 ,
</equation>
<bodyText confidence="0.99997295">
as claimed. Since each endpoint takes values in
the set [0, n], we have a total of O(n3f0) different
choices. For each such choice, we need to clas-
sify an endpoint as belonging to either Δ\I, Δ1\I,
or I. This amounts to an additional O(33f0) dif-
ferent choices. Overall, we have a total number of
O((3n)3f0) different choices. For each such choice,
the test for membership in workingSet for Δ1 takes
constant time in case we use a multi-dimensional ta-
ble, or else O(|p|) in case we use a trie. The ad-
jacency test and the merge operations can easily be
carried out in time O(|p|).
Putting all of the above observations together, and
using the already observed fact that n = O(|p|),
we can conclude that the total amount of time re-
quired by the while-loop at lines 7 to 13 is bounded
by O(|p |· (3|p|)3f0), both under the assumption that
workingSet is represented as a multi-dimensional ta-
ble or as a trie. This is also a bound on the running
time of the whole algorithm.
</bodyText>
<subsectionHeader confidence="0.995999">
4.5 Minimal binarization of a complete LCFRS
</subsectionHeader>
<bodyText confidence="0.999285">
The algorithm defined in Section 4.3 can be used
to binarize an LCFRS in such a way that each rule
in the resulting binarization has the minimum pos-
sible fan-out. This can be done by applying the
BOUNDED-BINARIZATION algorithm to each pro-
duction p, until we find the minimum value for the
</bodyText>
<page confidence="0.99228">
544
</page>
<listItem confidence="0.984830416666667">
1: Function MINIMAL-BINARIZATION(G)
2: pb = 0 {Set of binarized productions}
3: for all production p of G do
4: f&apos; = fan-out(p);
5: while not BOUNDED-BINARIZATION(p, f&apos;)
do
6: f&apos; = f&apos; + 1;
7: add result of BOUNDED-BINARIZATION(p,
f&apos;) to pb; {We obtain the tree from
BOUNDED-BINARIZATION as explained in
Section 4.3 and use it to binarize p}
8: return pb;
</listItem>
<figureCaption confidence="0.960243">
Figure 3: Minimal binarization by sequential search
</figureCaption>
<bodyText confidence="0.996900315789474">
bound f&apos; for which this algorithm finds a binariza-
tion. For a production with rank r and fan-out f,
we know that this optimal value of f&apos; must be in
the interval [f, Fr2] · f] because binarizing a pro-
duction cannot reduce its fan-out, and the NAIVE-
BINARIZATION algorithm seen in Section 4.1 can
binarize any production by increasing fan-out to
Fr] · f in the worst case.
2
The simplest way of finding out the optimal value
of f&apos; for each production is by a sequential search
starting with co(p) and going upwards, as in the algo-
rithm in Figure 3. Note that the upper bound Fr2] · f
that we have given for f&apos; guarantees that the while-
loop in this algorithm always terminates.
In the worst case, we may need f · (Fr2] − 1) + 1
executions of the BOUNDED-BINARIZATION algo-
rithm to find the optimal binarization of a production
in G. This complexity can be reduced by changing
the strategy to search for the optimal f&apos;: for exam-
ple, we can perform a binary search within the inter-
val [f, Fr2] · f],
rization in Llog(f ·(Fr2]−1)+1)]+1 executions of
BOUNDED-BINARIZATION. However, this will not
result in a practical improvement, since BOUNDED-
BINARIZATION is exponential in the value of f&apos; and
the binary search will require us to run it on val-
ues of f&apos; larger than the optimal in most cases. An
intermediate strategy between the two is to apply
exponential backoff to try the sequence of values
f −1+2i (for i = 0, 1, 2 ...). When we find the first
i such that BOUNDED-BINARIZATION does not fail,
if i &gt; 0, we apply the same strategy to the interval
[f−1+2i−1, f−2+2i], and we repeat this method to
shrink the interval until BOUNDED-BINARIZATION
does not fail for i = 0, giving us our optimal f&apos;.
With this strategy, the amount of executions of the
algorithm that we need in the worst case is
</bodyText>
<equation confidence="0.987538">
2(Flog(w)] + Flog(w)]2) + 1,
1
</equation>
<bodyText confidence="0.999481">
where w = f · (Fr2] − 1) + 1, but we avoid using
unnecessarily large values of f&apos;.
</bodyText>
<sectionHeader confidence="0.998502" genericHeader="conclusions">
5 Discussion
</sectionHeader>
<bodyText confidence="0.9999295">
To conclude this paper, we now discuss a number of
aspects of the results that we have presented, includ-
ing various other pieces of research that are particu-
larly relevant to this paper.
</bodyText>
<subsectionHeader confidence="0.995429">
5.1 The tradeoff between rank and fan-out
</subsectionHeader>
<bodyText confidence="0.9999868">
The algorithm introduced in this paper can be used
to transform an LCFRS into an equivalent form
with rank 2. This will result into a more effi-
ciently parsable LCFRS, since rank exponentially
affects parsing complexity. However, we must take
into account that parsing complexity is also influ-
enced by fan-out. Our algorithm guarantees a min-
imal increase in fan-out. In practical cases it seems
such an increase is quite small. For example, in
the context of dependency parsing, both G´omez-
Rodr´ıguez et al. (2009) and Kuhlmann and Satta
(2009) show that all the structures in several well-
known non-projective dependency treebanks are bi-
narizable without any increase in their fan-out.
More in general, it has been shown by Seki et al.
(1991) that parsing of LCFRS can be carried out in
time 0(n|pM|), where n is the length of the input
string and pM is the production in the grammar with
largest size.3 Thus, there may be cases in which one
has to find an optimal tradeoff between rank and fan-
out, in order to minimize the size of pM. This re-
quires some kind of Viterbi search over the space of
all possible binarizations, constructed as described
at the end of Subsection 4.3, for some appropriate
value of the fan-out f&apos;.
</bodyText>
<footnote confidence="0.8761895">
3The result has been shown for the formalism of multiple
context-free grammars (MCFG), but it also applies to LCFRS,
which are a special case of MCFG.
which lets us find the optimal bina-
</footnote>
<page confidence="0.968602">
545
</page>
<subsectionHeader confidence="0.991467">
5.2 Extension to general LCFRS
</subsectionHeader>
<bodyText confidence="0.999973266666667">
This paper has focussed on string-based LCFRS.
As discussed in Vijay-Shanker et al. (1987), LCFRS
provide a more general framework where the pro-
ductions are viewed as generating a set of abstract
derivation trees. These trees can be used to specify
how structures other than tuples of strings are com-
posed. For example, LCFRS derivation trees can be
used to specify how the elementary trees of a Tree
Adjoining Grammar can be composed to produced
derived tree. However, the results in this paper also
apply to non-string-based LCFRS, since by limit-
ing attention to the terminal string yield of whatever
structures are under consideration, the composition
operations can be defined using the string-based ver-
sion of LCFRS that is discussed here.
</bodyText>
<subsectionHeader confidence="0.989625">
5.3 Similar algorithmic techniques
</subsectionHeader>
<bodyText confidence="0.9999875">
The NAIVE-BINARIZATION algorithm given in Fig-
ure 1 is not novel to this paper: it is similar to
an algorithm developed in Melamed et al. (2004)
for generalized multitext grammars, a formalism
weakly equivalent to LCFRS that has been intro-
duced for syntax-based machine translation. How-
ever, the grammar produced by our algorithm has
optimal (minimal) fan-out. This is an important im-
provement over the result in (Melamed et al., 2004),
as this quantity enters into the parsing complexity
of both multitext grammars and LCFRS as an expo-
nential factor, and therefore must be kept as low as
possible to ensure practically viable parsing.
Rank reduction is also investigated in Nesson
et al. (2008) for synchronous tree-adjoining gram-
mars, a synchronous rewriting formalism based on
tree-adjoining grammars Joshi and Schabes (1992).
In this case the search space of possible reductions
is strongly restricted by the tree structures specified
by the formalism, resulting in simplified computa-
tion for the reduction algorithms. This feature is not
present in the case of LCFRS.
There is a close parallel between the technique
used in the MINIMAL-BINARIZATION algorithm
and deductive parsing techniques as proposed by
Shieber et al. (1995), that are usually implemented
by means of tabular methods. The idea of exploit-
ing tabular parsing in production factorization was
first expressed in Zhang et al. (2006). In fact, the
particular approach presented here has been used
to improve efficiency of parsing algorithms that use
discontinuous syntactic models, in particular, non-
projective dependency grammars, as discussed in
G´omez-Rodr´ıguez et al. (2009).
</bodyText>
<subsectionHeader confidence="0.986699">
5.4 Open problems
</subsectionHeader>
<bodyText confidence="0.999876277777778">
The bounded binarization algorithm that we have
presented has exponential run-time in the value of
the input fan-out bound f&apos;. It remains an open ques-
tion whether the bounded binarization problem for
LCFRS can be solved in deterministic polynomial
time. Even in the restricted case of f&apos; = cp(p), that
is, when no increase in the fan-out of the input pro-
duction is allowed, we do not know whether p can be
binarized using only deterministic polynomial time
in the value of p’s fan-out. However, our bounded
binarization algorithm shows that the latter problem
can be solved in polynomial time when the fan-out
of the input LCFRS is bounded by some constant.
Whether the bounded binarization problem can
be solved in polynomial time in the value of the
input bound f&apos; is also an open problem in the re-
stricted case of synchronous context-free grammars,
a special case of an LCFRS of fan-out two with
a strict separation between the two components of
each nonterminal in the right-hand side of a produc-
tion, as discussed in the introduction. An interesting
analysis of this restricted problem can be found in
Gildea and Stefankovic (2007).
Acknowledgements The work of Carlos G´omez-
Rodr´ıguez was funded by Ministerio de Educaci´on
y Ciencia and FEDER (HUM2007-66607-C04) and
Xunta de Galicia (PGIDIT07SIN005206PR, IN-
CITE08E1R104022ES, INCITE08ENA305025ES,
INCITE08PXIB302179PR and Rede Galega de
Procesamento da Linguaxe e Recuperaci´on de Infor-
maci´on). The work of Marco Kuhlmann was funded
by the Swedish Research Council. The work of
Giorgio Satta was supported by MIUR under project
PRIN No. 2007TJNZRE 002. We are grateful to an
anonymous reviewer for a very detailed review with
a number of particularly useful suggestions.
</bodyText>
<page confidence="0.99747">
546
</page>
<sectionHeader confidence="0.998317" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99966054117647">
David Chiang. 2007. Hierarchical phrase-
based translation. Computational Linguistics,
33(2):201–228.
Daniel Gildea and Daniel Stefankovic. 2007. Worst-
case synchronous grammar rules. In Human Lan-
guage Technologies 2007: The Conference of the
North American Chapter of the Association for
Computational Linguistics; Proceedings of the
Main Conference, pages 147–154. Association
for Computational Linguistics, Rochester, New
York.
Carlos G´omez-Rodr´ıguez, David J. Weir, and John
Carroll. 2009. Parsing mildly non-projective de-
pendency structures. In Twelfth Conference of the
European Chapter of the Association for Compu-
tational Linguistics (EACL). To appear.
A. K. Joshi and Y. Schabes. 1992. Tree adjoining
grammars and lexicalized grammars. In M. Nivat
and A. Podelsky, editors, Tree Automata and Lan-
guages. Elsevier, Amsterdam, The Netherlands.
Marco Kuhlmann and Joakim Nivre. 2006. Mildly
non-projective dependency structures. In 21st
International Conference on Computational Lin-
guistics and 44th Annual Meeting of the Asso-
ciation for Computational Linguistics (COLING-
ACL), Main Conference Poster Sessions, pages
507–514. Sydney, Australia.
Marco Kuhlmann and Giorgio Satta. 2009. Tree-
bank grammar techniques for non-projective de-
pendency parsing. In Twelfth Conference of the
European Chapter of the Association for Compu-
tational Linguistics (EACL). To appear.
I. Dan Melamed, Benjamin Wellington, and Gior-
gio Satta. 2004. Generalized multitext gram-
mars. In 42nd Annual Meeting of the Association
for Computational Linguistics (ACL), pages 661–
668. Barcelona, Spain.
Rebecca Nesson, Giorgio Satta, and Stuart M.
Shieber. 2008. Optimal k-arization of syn-
chronous tree-adjoining grammar. In Proceedings
of ACL-08: HLT, pages 604–612. Association for
Computational Linguistics, Columbus, Ohio.
A. Nijholt. 1980. Context-Free Grammars: Cov-
ers, Normal Forms, and Parsing, volume 93.
Springer-Verlag, Berlin, Germany.
Owen Rambow and Giorgio Satta. 1999. Indepen-
dent parallelism in finite copying parallel rewrit-
ing systems. Theoretical Computer Science,
223(1–2):87–120.
Hiroyuki Seki, Takashi Matsumura, Mamoru Fujii,
and Tadao Kasami. 1991. On Multiple Context-
Free Grammars. Theoretical Computer Science,
88(2):191–229.
Stuart M. Shieber, Yves Schabes, and Fernando
Pereira. 1995. Principles and implementation of
deductive parsing. Journal of Logic Program-
ming, 24(1–2):3–36.
Takeaki Uno and Mutsunori Yagiura. 2000. Fast al-
gorithms to enumerate all common intervals of
two permutations. Algorithmica, 26(2):290–309.
K. Vijay-Shanker, David J. Weir, and Aravind K.
Joshi. 1987. Characterizing structural descrip-
tions produced by various grammatical for-
malisms. In 25th Annual Meeting of the Associ-
ation for Computational Linguistics (ACL), pages
104–111. Stanford, CA, USA.
Benjamin Wellington, Sonjia Waxmonsky, and
I. Dan Melamed. 2006. Empirical lower bounds
on the complexity of translational equivalence. In
21st International Conference on Computational
Linguistics and 44th Annual Meeting of the Asso-
ciation for Computational Linguistics (COLING-
ACL), pages 977–984. Sydney, Australia.
Hao Zhang, Daniel Gildea, and David Chiang.
2008. Extracting synchronous grammar rules
from word-level alignments in linear time. In
22nd International Conference on Computational
Linguistics (Coling), pages 1081–1088. Manch-
ester, England, UK.
Hao Zhang, Liang Huang, Daniel Gildea, and Kevin
Knight. 2006. Synchronous binarization for ma-
chine translation. In Human Language Technol-
ogy Conference of the North American Chapter
of the Association for Computational Linguistics,
pages 256–263. New York, USA.
</reference>
<page confidence="0.997635">
547
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.365510">
<title confidence="0.9996115">Optimal Reduction of Rule in Linear Context-Free Rewriting Systems</title>
<author confidence="0.993964">Marco Giorgio</author>
<author confidence="0.993964">David</author>
<affiliation confidence="0.765087">de Computaci´on, Universidade da Spain of Linguistics and Philology, Uppsala University, Sweden</affiliation>
<address confidence="0.7122075">of Information Engineering, University of Padua, Italy of Informatics, University of Sussex, United Kingdom</address>
<abstract confidence="0.995316105263158">Linear Context-free Rewriting Systems (LCFRS) is an expressive grammar formalism with applications in syntax-based machine translation. The parsing complexity of an is exponential in both the of a production, defined as the number of nonterminals on its right-hand side, and a measure for the discontinuity of a phrase, In this paper, we present an algorithm that transforms an LCFRS into a strongly equivalent form in which productions have rank at most and has minimal fan-out. Our results generalize previous work on Synchronous Context-Free Grammar, and are particularly relevant for machine translation from or to languages that require syntactic analyses with discontinuous constituents.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical phrasebased translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="1491" citStr="Chiang (2007)" startWordPosition="203" endWordPosition="204">e present an algorithm that transforms an LCFRS into a strongly equivalent form in which all productions have rank at most 2, and has minimal fan-out. Our results generalize previous work on Synchronous Context-Free Grammar, and are particularly relevant for machine translation from or to languages that require syntactic analyses with discontinuous constituents. 1 Introduction There is currently considerable interest in syntaxbased models for statistical machine translation that are based on the extraction of a synchronous grammar from a corpus of word-aligned parallel texts; see for instance Chiang (2007) and the references therein. One practical problem with this approach, apart from the sheer number of the rules that result from the extraction procedure, is that the parsing complexity of all synchronous formalisms that we are aware of is exponential in the rank of a rule, defined as the number of nonterminals on the righthand side. Therefore, it is important that the rules of the extracted grammar are transformed so as to minimise this quantity. Not only is this beneficial in terms of parsing complexity, but smaller rules can also improve a translation model’s ability to generalize to new da</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>David Chiang. 2007. Hierarchical phrasebased translation. Computational Linguistics, 33(2):201–228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Daniel Stefankovic</author>
</authors>
<title>Worstcase synchronous grammar rules.</title>
<date>2007</date>
<booktitle>In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference,</booktitle>
<pages>147--154</pages>
<location>Rochester, New York.</location>
<contexts>
<context position="30419" citStr="Gildea and Stefankovic (2007)" startWordPosition="5432" endWordPosition="5435">binarization algorithm shows that the latter problem can be solved in polynomial time when the fan-out of the input LCFRS is bounded by some constant. Whether the bounded binarization problem can be solved in polynomial time in the value of the input bound f&apos; is also an open problem in the restricted case of synchronous context-free grammars, a special case of an LCFRS of fan-out two with a strict separation between the two components of each nonterminal in the right-hand side of a production, as discussed in the introduction. An interesting analysis of this restricted problem can be found in Gildea and Stefankovic (2007). Acknowledgements The work of Carlos G´omezRodr´ıguez was funded by Ministerio de Educaci´on y Ciencia and FEDER (HUM2007-66607-C04) and Xunta de Galicia (PGIDIT07SIN005206PR, INCITE08E1R104022ES, INCITE08ENA305025ES, INCITE08PXIB302179PR and Rede Galega de Procesamento da Linguaxe e Recuperaci´on de Informaci´on). The work of Marco Kuhlmann was funded by the Swedish Research Council. The work of Giorgio Satta was supported by MIUR under project PRIN No. 2007TJNZRE 002. We are grateful to an anonymous reviewer for a very detailed review with a number of particularly useful suggestions. 546 Re</context>
</contexts>
<marker>Gildea, Stefankovic, 2007</marker>
<rawString>Daniel Gildea and Daniel Stefankovic. 2007. Worstcase synchronous grammar rules. In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference, pages 147–154. Association for Computational Linguistics, Rochester, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlos G´omez-Rodr´ıguez</author>
<author>David J Weir</author>
<author>John Carroll</author>
</authors>
<title>Parsing mildly non-projective dependency structures.</title>
<date>2009</date>
<booktitle>In Twelfth Conference of the European Chapter of the Association for Computational Linguistics (EACL).</booktitle>
<note>To appear.</note>
<marker>G´omez-Rodr´ıguez, Weir, Carroll, 2009</marker>
<rawString>Carlos G´omez-Rodr´ıguez, David J. Weir, and John Carroll. 2009. Parsing mildly non-projective dependency structures. In Twelfth Conference of the European Chapter of the Association for Computational Linguistics (EACL). To appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Joshi</author>
<author>Y Schabes</author>
</authors>
<title>Tree adjoining grammars and lexicalized grammars.</title>
<date>1992</date>
<booktitle>Tree Automata and Languages.</booktitle>
<editor>In M. Nivat and A. Podelsky, editors,</editor>
<publisher>Elsevier,</publisher>
<location>Amsterdam, The Netherlands.</location>
<contexts>
<context position="28443" citStr="Joshi and Schabes (1992)" startWordPosition="5112" endWordPosition="5115">valent to LCFRS that has been introduced for syntax-based machine translation. However, the grammar produced by our algorithm has optimal (minimal) fan-out. This is an important improvement over the result in (Melamed et al., 2004), as this quantity enters into the parsing complexity of both multitext grammars and LCFRS as an exponential factor, and therefore must be kept as low as possible to ensure practically viable parsing. Rank reduction is also investigated in Nesson et al. (2008) for synchronous tree-adjoining grammars, a synchronous rewriting formalism based on tree-adjoining grammars Joshi and Schabes (1992). In this case the search space of possible reductions is strongly restricted by the tree structures specified by the formalism, resulting in simplified computation for the reduction algorithms. This feature is not present in the case of LCFRS. There is a close parallel between the technique used in the MINIMAL-BINARIZATION algorithm and deductive parsing techniques as proposed by Shieber et al. (1995), that are usually implemented by means of tabular methods. The idea of exploiting tabular parsing in production factorization was first expressed in Zhang et al. (2006). In fact, the particular </context>
</contexts>
<marker>Joshi, Schabes, 1992</marker>
<rawString>A. K. Joshi and Y. Schabes. 1992. Tree adjoining grammars and lexicalized grammars. In M. Nivat and A. Podelsky, editors, Tree Automata and Languages. Elsevier, Amsterdam, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Kuhlmann</author>
<author>Joakim Nivre</author>
</authors>
<title>Mildly non-projective dependency structures.</title>
<date>2006</date>
<booktitle>In 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (COLINGACL), Main Conference Poster Sessions,</booktitle>
<pages>507--514</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="3037" citStr="Kuhlmann and Nivre, 2006" startWordPosition="456" endWordPosition="459">th a single continuous phrase in the target language; as defined below, this amounts to saying that SCFG have a fan-out of 2. This restriction appears to render SCFG empirically inadequate. In particular, Wellington et al. (2006) find that the coverage of a translation model can increase dramatically when one allows a bilingual phrase to stretch out over three rather than two continuous substrings. This observation is in line with empirical studies in the context of dependency parsing, where the need for formalisms with higher fan-out has been observed even in standard, single language texts (Kuhlmann and Nivre, 2006). In this paper, we present an algorithm that computes optimal decompositions of rules in the formalism of Linear Context-Free Rewriting Systems (LCFRS) (Vijay-Shanker et al., 1987). LCFRS was originally introduced as a generalization of several so-called mildly context-sensitive grammar formalisms. In the context of machine translation, LCFRS is an interesting generalization of SCFG because it does not restrict the fan-out to 2, allowing productions with arbitrary fan-out (and arbitrary rank). Given an LCFRS, our algorithm computes a strongly equivalent grammar with rank 2 and min539 Human La</context>
</contexts>
<marker>Kuhlmann, Nivre, 2006</marker>
<rawString>Marco Kuhlmann and Joakim Nivre. 2006. Mildly non-projective dependency structures. In 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (COLINGACL), Main Conference Poster Sessions, pages 507–514. Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Kuhlmann</author>
<author>Giorgio Satta</author>
</authors>
<title>Treebank grammar techniques for non-projective dependency parsing.</title>
<date>2009</date>
<booktitle>In Twelfth Conference of the European Chapter of the Association for Computational Linguistics (EACL).</booktitle>
<note>To appear.</note>
<contexts>
<context position="25934" citStr="Kuhlmann and Satta (2009)" startWordPosition="4694" endWordPosition="4697">re particularly relevant to this paper. 5.1 The tradeoff between rank and fan-out The algorithm introduced in this paper can be used to transform an LCFRS into an equivalent form with rank 2. This will result into a more efficiently parsable LCFRS, since rank exponentially affects parsing complexity. However, we must take into account that parsing complexity is also influenced by fan-out. Our algorithm guarantees a minimal increase in fan-out. In practical cases it seems such an increase is quite small. For example, in the context of dependency parsing, both G´omezRodr´ıguez et al. (2009) and Kuhlmann and Satta (2009) show that all the structures in several wellknown non-projective dependency treebanks are binarizable without any increase in their fan-out. More in general, it has been shown by Seki et al. (1991) that parsing of LCFRS can be carried out in time 0(n|pM|), where n is the length of the input string and pM is the production in the grammar with largest size.3 Thus, there may be cases in which one has to find an optimal tradeoff between rank and fanout, in order to minimize the size of pM. This requires some kind of Viterbi search over the space of all possible binarizations, constructed as descr</context>
</contexts>
<marker>Kuhlmann, Satta, 2009</marker>
<rawString>Marco Kuhlmann and Giorgio Satta. 2009. Treebank grammar techniques for non-projective dependency parsing. In Twelfth Conference of the European Chapter of the Association for Computational Linguistics (EACL). To appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
<author>Benjamin Wellington</author>
<author>Giorgio Satta</author>
</authors>
<title>Generalized multitext grammars.</title>
<date>2004</date>
<booktitle>In 42nd Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>661--668</pages>
<location>Barcelona,</location>
<contexts>
<context position="4527" citStr="Melamed et al. (2004)" startWordPosition="687" endWordPosition="690">ions of the original grammar can be reconstructed using some simple homomorphism (c.f. Nijholt, 1980). Our contribution is significant because the existing algorithms for decomposing SCFG, based on Uno and Yagiura (2000), cannot be applied to LCFRS, as they rely on the crucial property that components of biphrases are strictly separated in the generated string: Given a pair of synchronized nonterminal symbols, the material derived from the source nonterminal must precede the material derived from the target nonterminal, or vice versa. The problem that we solve has been previously addressed by Melamed et al. (2004), but in contrast to our result, their algorithm does not guarantee an optimal (minimal) increase in the fanout of the resulting grammar. However, this is essential for the practical applicability of the transformed grammar, as the parsing complexity of LCFRS is exponential in both the rank and the fan-out. Structure of the paper The remainder of the paper is structured as follows. Section 2 introduces the terminology and notation that we use for LCFRS. In Section 3, we present the technical background of our algorithm; the algorithm itself is discussed in Section 4. Section 5 concludes the pa</context>
<context position="27759" citStr="Melamed et al. (2004)" startWordPosition="5007" endWordPosition="5010">sed. For example, LCFRS derivation trees can be used to specify how the elementary trees of a Tree Adjoining Grammar can be composed to produced derived tree. However, the results in this paper also apply to non-string-based LCFRS, since by limiting attention to the terminal string yield of whatever structures are under consideration, the composition operations can be defined using the string-based version of LCFRS that is discussed here. 5.3 Similar algorithmic techniques The NAIVE-BINARIZATION algorithm given in Figure 1 is not novel to this paper: it is similar to an algorithm developed in Melamed et al. (2004) for generalized multitext grammars, a formalism weakly equivalent to LCFRS that has been introduced for syntax-based machine translation. However, the grammar produced by our algorithm has optimal (minimal) fan-out. This is an important improvement over the result in (Melamed et al., 2004), as this quantity enters into the parsing complexity of both multitext grammars and LCFRS as an exponential factor, and therefore must be kept as low as possible to ensure practically viable parsing. Rank reduction is also investigated in Nesson et al. (2008) for synchronous tree-adjoining grammars, a synch</context>
</contexts>
<marker>Melamed, Wellington, Satta, 2004</marker>
<rawString>I. Dan Melamed, Benjamin Wellington, and Giorgio Satta. 2004. Generalized multitext grammars. In 42nd Annual Meeting of the Association for Computational Linguistics (ACL), pages 661– 668. Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Nesson</author>
<author>Giorgio Satta</author>
<author>Stuart M Shieber</author>
</authors>
<title>Optimal k-arization of synchronous tree-adjoining grammar.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>604--612</pages>
<location>Columbus, Ohio.</location>
<contexts>
<context position="28310" citStr="Nesson et al. (2008)" startWordPosition="5095" endWordPosition="5098">per: it is similar to an algorithm developed in Melamed et al. (2004) for generalized multitext grammars, a formalism weakly equivalent to LCFRS that has been introduced for syntax-based machine translation. However, the grammar produced by our algorithm has optimal (minimal) fan-out. This is an important improvement over the result in (Melamed et al., 2004), as this quantity enters into the parsing complexity of both multitext grammars and LCFRS as an exponential factor, and therefore must be kept as low as possible to ensure practically viable parsing. Rank reduction is also investigated in Nesson et al. (2008) for synchronous tree-adjoining grammars, a synchronous rewriting formalism based on tree-adjoining grammars Joshi and Schabes (1992). In this case the search space of possible reductions is strongly restricted by the tree structures specified by the formalism, resulting in simplified computation for the reduction algorithms. This feature is not present in the case of LCFRS. There is a close parallel between the technique used in the MINIMAL-BINARIZATION algorithm and deductive parsing techniques as proposed by Shieber et al. (1995), that are usually implemented by means of tabular methods. Th</context>
</contexts>
<marker>Nesson, Satta, Shieber, 2008</marker>
<rawString>Rebecca Nesson, Giorgio Satta, and Stuart M. Shieber. 2008. Optimal k-arization of synchronous tree-adjoining grammar. In Proceedings of ACL-08: HLT, pages 604–612. Association for Computational Linguistics, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Nijholt</author>
</authors>
<title>Context-Free Grammars: Covers, Normal Forms, and Parsing,</title>
<date>1980</date>
<volume>93</volume>
<publisher>Springer-Verlag,</publisher>
<location>Berlin, Germany.</location>
<contexts>
<context position="4007" citStr="Nijholt, 1980" startWordPosition="605" endWordPosition="606">resting generalization of SCFG because it does not restrict the fan-out to 2, allowing productions with arbitrary fan-out (and arbitrary rank). Given an LCFRS, our algorithm computes a strongly equivalent grammar with rank 2 and min539 Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 539–547, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics imal increase in fan-out.1 In this context, strong equivalence means that the derivations of the original grammar can be reconstructed using some simple homomorphism (c.f. Nijholt, 1980). Our contribution is significant because the existing algorithms for decomposing SCFG, based on Uno and Yagiura (2000), cannot be applied to LCFRS, as they rely on the crucial property that components of biphrases are strictly separated in the generated string: Given a pair of synchronized nonterminal symbols, the material derived from the source nonterminal must precede the material derived from the target nonterminal, or vice versa. The problem that we solve has been previously addressed by Melamed et al. (2004), but in contrast to our result, their algorithm does not guarantee an optimal (</context>
</contexts>
<marker>Nijholt, 1980</marker>
<rawString>A. Nijholt. 1980. Context-Free Grammars: Covers, Normal Forms, and Parsing, volume 93. Springer-Verlag, Berlin, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Owen Rambow</author>
<author>Giorgio Satta</author>
</authors>
<title>Independent parallelism in finite copying parallel rewriting systems.</title>
<date>1999</date>
<journal>Theoretical Computer Science,</journal>
<pages>223--1</pages>
<contexts>
<context position="5766" citStr="Rambow and Satta (1999)" startWordPosition="921" endWordPosition="924">g related work and open problems. General notation The set of non-negative integers is denoted by N. For i, j ∈ N, we write [i, j] to denote the interval { k ∈ N |i ≤ k ≤ j }, and use [i] as a shorthand for [1, i]. Given an alphabet V , we write V * for the set of all (finite) strings over V . 2 Preliminaries We briefly summarize the terminology and notation that we adopt for LCFRS; for detailed definitions, see Vijay-Shanker et al. (1987). 2.1 Linear, non-erasing functions Let V be an alphabet. For natural numbers r ≥ 0 and f, f1, ... , fr ≥ 1, a function g : (V*)fl × ··· × (V *)fr → (V *)f 1Rambow and Satta (1999) show that without increasing fan-out it is not always possible to produce even weakly equivalent grammars. is called a linear, non-erasing function over V of type f1 × · · · × fr → f, if it can be defined by an equation of the form g(hx1,1,...,x1,f1i, ... ,hxr,1, ..., xr,fri) = Qg , where Qg = hαg,1, ... , αg,fi is an f-tuple of strings over the variables on the left-hand side of the equation and symbols in V that contains exactly one occurrence of each variable. We call the value r the rank of g, the value f its fan-out, and write ρ(g) and co(g), respectively, to denote these quantities. Not</context>
</contexts>
<marker>Rambow, Satta, 1999</marker>
<rawString>Owen Rambow and Giorgio Satta. 1999. Independent parallelism in finite copying parallel rewriting systems. Theoretical Computer Science, 223(1–2):87–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroyuki Seki</author>
<author>Takashi Matsumura</author>
<author>Mamoru Fujii</author>
<author>Tadao Kasami</author>
</authors>
<title>On Multiple ContextFree Grammars.</title>
<date>1991</date>
<journal>Theoretical Computer Science,</journal>
<volume>88</volume>
<issue>2</issue>
<contexts>
<context position="26132" citStr="Seki et al. (1991)" startWordPosition="4727" endWordPosition="4730">ult into a more efficiently parsable LCFRS, since rank exponentially affects parsing complexity. However, we must take into account that parsing complexity is also influenced by fan-out. Our algorithm guarantees a minimal increase in fan-out. In practical cases it seems such an increase is quite small. For example, in the context of dependency parsing, both G´omezRodr´ıguez et al. (2009) and Kuhlmann and Satta (2009) show that all the structures in several wellknown non-projective dependency treebanks are binarizable without any increase in their fan-out. More in general, it has been shown by Seki et al. (1991) that parsing of LCFRS can be carried out in time 0(n|pM|), where n is the length of the input string and pM is the production in the grammar with largest size.3 Thus, there may be cases in which one has to find an optimal tradeoff between rank and fanout, in order to minimize the size of pM. This requires some kind of Viterbi search over the space of all possible binarizations, constructed as described at the end of Subsection 4.3, for some appropriate value of the fan-out f&apos;. 3The result has been shown for the formalism of multiple context-free grammars (MCFG), but it also applies to LCFRS, </context>
</contexts>
<marker>Seki, Matsumura, Fujii, Kasami, 1991</marker>
<rawString>Hiroyuki Seki, Takashi Matsumura, Mamoru Fujii, and Tadao Kasami. 1991. On Multiple ContextFree Grammars. Theoretical Computer Science, 88(2):191–229.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
<author>Yves Schabes</author>
<author>Fernando Pereira</author>
</authors>
<title>Principles and implementation of deductive parsing.</title>
<date>1995</date>
<journal>Journal of Logic Programming,</journal>
<pages>24--1</pages>
<contexts>
<context position="17969" citStr="Shieber et al. (1995)" startWordPosition="3242" endWordPosition="3245"> Δ2 ∈/ workingSet then 12: workingSet ← workingSet ∪ {Δ2}; 13: agenda ← agenda ∪ {Δ2}; 14: if Δ{B1,B2,...,Bρ(p))} ∈ workingSet then 15: return true; 16: else 17: return false; Figure 2: Algorithm to compute a bounded binarization property is intuitive if one observes that our algorithm is a specialization of standard algorithms for the computation of the closure of binary relations. A formal proof of this fact is rather long and tedious, and will not be reported here. We notice that there is a very close similarity between algorithm BOUNDED-BINARIZATION and the deduction procedure proposed by Shieber et al. (1995) for parsing. We discuss this more at length in Section 5. Note that we have expressed the algorithm as a decision function that will return true if there exists a binarization of p with fan-out not greater than f0, and false otherwise. However, the algorithm can easily be modified to return a reduction producing such a binarization, by adding to each endpoint set Δ ∈ workingSet two pointers to the adjacent endpoint sets that were used to obtain it. If the algorithm is successful, the tree obtained by following these pointers from the final endpoint set Δ{B1,...,Bρ(p)} ∈ workingSet gives us a </context>
<context position="28848" citStr="Shieber et al. (1995)" startWordPosition="5175" endWordPosition="5178">tically viable parsing. Rank reduction is also investigated in Nesson et al. (2008) for synchronous tree-adjoining grammars, a synchronous rewriting formalism based on tree-adjoining grammars Joshi and Schabes (1992). In this case the search space of possible reductions is strongly restricted by the tree structures specified by the formalism, resulting in simplified computation for the reduction algorithms. This feature is not present in the case of LCFRS. There is a close parallel between the technique used in the MINIMAL-BINARIZATION algorithm and deductive parsing techniques as proposed by Shieber et al. (1995), that are usually implemented by means of tabular methods. The idea of exploiting tabular parsing in production factorization was first expressed in Zhang et al. (2006). In fact, the particular approach presented here has been used to improve efficiency of parsing algorithms that use discontinuous syntactic models, in particular, nonprojective dependency grammars, as discussed in G´omez-Rodr´ıguez et al. (2009). 5.4 Open problems The bounded binarization algorithm that we have presented has exponential run-time in the value of the input fan-out bound f&apos;. It remains an open question whether th</context>
</contexts>
<marker>Shieber, Schabes, Pereira, 1995</marker>
<rawString>Stuart M. Shieber, Yves Schabes, and Fernando Pereira. 1995. Principles and implementation of deductive parsing. Journal of Logic Programming, 24(1–2):3–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takeaki Uno</author>
<author>Mutsunori Yagiura</author>
</authors>
<title>Fast algorithms to enumerate all common intervals of two permutations.</title>
<date>2000</date>
<journal>Algorithmica,</journal>
<volume>26</volume>
<issue>2</issue>
<contexts>
<context position="2241" citStr="Uno and Yagiura, 2000" startWordPosition="327" endWordPosition="330">the extraction procedure, is that the parsing complexity of all synchronous formalisms that we are aware of is exponential in the rank of a rule, defined as the number of nonterminals on the righthand side. Therefore, it is important that the rules of the extracted grammar are transformed so as to minimise this quantity. Not only is this beneficial in terms of parsing complexity, but smaller rules can also improve a translation model’s ability to generalize to new data (Zhang et al., 2006). Optimal algorithms exist for minimising the size of rules in a Synchronous Context-Free Grammar (SCFG) (Uno and Yagiura, 2000; Zhang et al., 2008). However, the SCFG formalism is limited to modelling word-to-word alignments in which a single continuous phrase in the source language is aligned with a single continuous phrase in the target language; as defined below, this amounts to saying that SCFG have a fan-out of 2. This restriction appears to render SCFG empirically inadequate. In particular, Wellington et al. (2006) find that the coverage of a translation model can increase dramatically when one allows a bilingual phrase to stretch out over three rather than two continuous substrings. This observation is in line</context>
<context position="4126" citStr="Uno and Yagiura (2000)" startWordPosition="621" endWordPosition="624">ry fan-out (and arbitrary rank). Given an LCFRS, our algorithm computes a strongly equivalent grammar with rank 2 and min539 Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 539–547, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics imal increase in fan-out.1 In this context, strong equivalence means that the derivations of the original grammar can be reconstructed using some simple homomorphism (c.f. Nijholt, 1980). Our contribution is significant because the existing algorithms for decomposing SCFG, based on Uno and Yagiura (2000), cannot be applied to LCFRS, as they rely on the crucial property that components of biphrases are strictly separated in the generated string: Given a pair of synchronized nonterminal symbols, the material derived from the source nonterminal must precede the material derived from the target nonterminal, or vice versa. The problem that we solve has been previously addressed by Melamed et al. (2004), but in contrast to our result, their algorithm does not guarantee an optimal (minimal) increase in the fanout of the resulting grammar. However, this is essential for the practical applicability of</context>
</contexts>
<marker>Uno, Yagiura, 2000</marker>
<rawString>Takeaki Uno and Mutsunori Yagiura. 2000. Fast algorithms to enumerate all common intervals of two permutations. Algorithmica, 26(2):290–309.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-Shanker</author>
<author>David J Weir</author>
<author>Aravind K Joshi</author>
</authors>
<title>Characterizing structural descriptions produced by various grammatical formalisms.</title>
<date>1987</date>
<booktitle>In 25th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>104--111</pages>
<location>Stanford, CA, USA.</location>
<contexts>
<context position="3218" citStr="Vijay-Shanker et al., 1987" startWordPosition="484" endWordPosition="487">nadequate. In particular, Wellington et al. (2006) find that the coverage of a translation model can increase dramatically when one allows a bilingual phrase to stretch out over three rather than two continuous substrings. This observation is in line with empirical studies in the context of dependency parsing, where the need for formalisms with higher fan-out has been observed even in standard, single language texts (Kuhlmann and Nivre, 2006). In this paper, we present an algorithm that computes optimal decompositions of rules in the formalism of Linear Context-Free Rewriting Systems (LCFRS) (Vijay-Shanker et al., 1987). LCFRS was originally introduced as a generalization of several so-called mildly context-sensitive grammar formalisms. In the context of machine translation, LCFRS is an interesting generalization of SCFG because it does not restrict the fan-out to 2, allowing productions with arbitrary fan-out (and arbitrary rank). Given an LCFRS, our algorithm computes a strongly equivalent grammar with rank 2 and min539 Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 539–547, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguisti</context>
<context position="5586" citStr="Vijay-Shanker et al. (1987)" startWordPosition="881" endWordPosition="884">on that we use for LCFRS. In Section 3, we present the technical background of our algorithm; the algorithm itself is discussed in Section 4. Section 5 concludes the paper by discussing related work and open problems. General notation The set of non-negative integers is denoted by N. For i, j ∈ N, we write [i, j] to denote the interval { k ∈ N |i ≤ k ≤ j }, and use [i] as a shorthand for [1, i]. Given an alphabet V , we write V * for the set of all (finite) strings over V . 2 Preliminaries We briefly summarize the terminology and notation that we adopt for LCFRS; for detailed definitions, see Vijay-Shanker et al. (1987). 2.1 Linear, non-erasing functions Let V be an alphabet. For natural numbers r ≥ 0 and f, f1, ... , fr ≥ 1, a function g : (V*)fl × ··· × (V *)fr → (V *)f 1Rambow and Satta (1999) show that without increasing fan-out it is not always possible to produce even weakly equivalent grammars. is called a linear, non-erasing function over V of type f1 × · · · × fr → f, if it can be defined by an equation of the form g(hx1,1,...,x1,f1i, ... ,hxr,1, ..., xr,fri) = Qg , where Qg = hαg,1, ... , αg,fi is an f-tuple of strings over the variables on the left-hand side of the equation and symbols in V that c</context>
<context position="26926" citStr="Vijay-Shanker et al. (1987)" startWordPosition="4870" endWordPosition="4873"> there may be cases in which one has to find an optimal tradeoff between rank and fanout, in order to minimize the size of pM. This requires some kind of Viterbi search over the space of all possible binarizations, constructed as described at the end of Subsection 4.3, for some appropriate value of the fan-out f&apos;. 3The result has been shown for the formalism of multiple context-free grammars (MCFG), but it also applies to LCFRS, which are a special case of MCFG. which lets us find the optimal bina545 5.2 Extension to general LCFRS This paper has focussed on string-based LCFRS. As discussed in Vijay-Shanker et al. (1987), LCFRS provide a more general framework where the productions are viewed as generating a set of abstract derivation trees. These trees can be used to specify how structures other than tuples of strings are composed. For example, LCFRS derivation trees can be used to specify how the elementary trees of a Tree Adjoining Grammar can be composed to produced derived tree. However, the results in this paper also apply to non-string-based LCFRS, since by limiting attention to the terminal string yield of whatever structures are under consideration, the composition operations can be defined using the</context>
</contexts>
<marker>Vijay-Shanker, Weir, Joshi, 1987</marker>
<rawString>K. Vijay-Shanker, David J. Weir, and Aravind K. Joshi. 1987. Characterizing structural descriptions produced by various grammatical formalisms. In 25th Annual Meeting of the Association for Computational Linguistics (ACL), pages 104–111. Stanford, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Wellington</author>
<author>Sonjia Waxmonsky</author>
<author>I Dan Melamed</author>
</authors>
<title>Empirical lower bounds on the complexity of translational equivalence.</title>
<date>2006</date>
<booktitle>In 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (COLINGACL),</booktitle>
<pages>977--984</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="2641" citStr="Wellington et al. (2006)" startWordPosition="393" endWordPosition="396">les can also improve a translation model’s ability to generalize to new data (Zhang et al., 2006). Optimal algorithms exist for minimising the size of rules in a Synchronous Context-Free Grammar (SCFG) (Uno and Yagiura, 2000; Zhang et al., 2008). However, the SCFG formalism is limited to modelling word-to-word alignments in which a single continuous phrase in the source language is aligned with a single continuous phrase in the target language; as defined below, this amounts to saying that SCFG have a fan-out of 2. This restriction appears to render SCFG empirically inadequate. In particular, Wellington et al. (2006) find that the coverage of a translation model can increase dramatically when one allows a bilingual phrase to stretch out over three rather than two continuous substrings. This observation is in line with empirical studies in the context of dependency parsing, where the need for formalisms with higher fan-out has been observed even in standard, single language texts (Kuhlmann and Nivre, 2006). In this paper, we present an algorithm that computes optimal decompositions of rules in the formalism of Linear Context-Free Rewriting Systems (LCFRS) (Vijay-Shanker et al., 1987). LCFRS was originally </context>
</contexts>
<marker>Wellington, Waxmonsky, Melamed, 2006</marker>
<rawString>Benjamin Wellington, Sonjia Waxmonsky, and I. Dan Melamed. 2006. Empirical lower bounds on the complexity of translational equivalence. In 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (COLINGACL), pages 977–984. Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hao Zhang</author>
<author>Daniel Gildea</author>
<author>David Chiang</author>
</authors>
<title>Extracting synchronous grammar rules from word-level alignments in linear time.</title>
<date>2008</date>
<booktitle>In 22nd International Conference on Computational Linguistics (Coling),</booktitle>
<pages>1081--1088</pages>
<location>Manchester, England, UK.</location>
<contexts>
<context position="2262" citStr="Zhang et al., 2008" startWordPosition="331" endWordPosition="334">e, is that the parsing complexity of all synchronous formalisms that we are aware of is exponential in the rank of a rule, defined as the number of nonterminals on the righthand side. Therefore, it is important that the rules of the extracted grammar are transformed so as to minimise this quantity. Not only is this beneficial in terms of parsing complexity, but smaller rules can also improve a translation model’s ability to generalize to new data (Zhang et al., 2006). Optimal algorithms exist for minimising the size of rules in a Synchronous Context-Free Grammar (SCFG) (Uno and Yagiura, 2000; Zhang et al., 2008). However, the SCFG formalism is limited to modelling word-to-word alignments in which a single continuous phrase in the source language is aligned with a single continuous phrase in the target language; as defined below, this amounts to saying that SCFG have a fan-out of 2. This restriction appears to render SCFG empirically inadequate. In particular, Wellington et al. (2006) find that the coverage of a translation model can increase dramatically when one allows a bilingual phrase to stretch out over three rather than two continuous substrings. This observation is in line with empirical studi</context>
</contexts>
<marker>Zhang, Gildea, Chiang, 2008</marker>
<rawString>Hao Zhang, Daniel Gildea, and David Chiang. 2008. Extracting synchronous grammar rules from word-level alignments in linear time. In 22nd International Conference on Computational Linguistics (Coling), pages 1081–1088. Manchester, England, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hao Zhang</author>
<author>Liang Huang</author>
<author>Daniel Gildea</author>
<author>Kevin Knight</author>
</authors>
<title>Synchronous binarization for machine translation.</title>
<date>2006</date>
<booktitle>In Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>256--263</pages>
<location>New York, USA.</location>
<contexts>
<context position="2114" citStr="Zhang et al., 2006" startWordPosition="307" endWordPosition="310"> the references therein. One practical problem with this approach, apart from the sheer number of the rules that result from the extraction procedure, is that the parsing complexity of all synchronous formalisms that we are aware of is exponential in the rank of a rule, defined as the number of nonterminals on the righthand side. Therefore, it is important that the rules of the extracted grammar are transformed so as to minimise this quantity. Not only is this beneficial in terms of parsing complexity, but smaller rules can also improve a translation model’s ability to generalize to new data (Zhang et al., 2006). Optimal algorithms exist for minimising the size of rules in a Synchronous Context-Free Grammar (SCFG) (Uno and Yagiura, 2000; Zhang et al., 2008). However, the SCFG formalism is limited to modelling word-to-word alignments in which a single continuous phrase in the source language is aligned with a single continuous phrase in the target language; as defined below, this amounts to saying that SCFG have a fan-out of 2. This restriction appears to render SCFG empirically inadequate. In particular, Wellington et al. (2006) find that the coverage of a translation model can increase dramatically </context>
<context position="29017" citStr="Zhang et al. (2006)" startWordPosition="5202" endWordPosition="5205">e-adjoining grammars Joshi and Schabes (1992). In this case the search space of possible reductions is strongly restricted by the tree structures specified by the formalism, resulting in simplified computation for the reduction algorithms. This feature is not present in the case of LCFRS. There is a close parallel between the technique used in the MINIMAL-BINARIZATION algorithm and deductive parsing techniques as proposed by Shieber et al. (1995), that are usually implemented by means of tabular methods. The idea of exploiting tabular parsing in production factorization was first expressed in Zhang et al. (2006). In fact, the particular approach presented here has been used to improve efficiency of parsing algorithms that use discontinuous syntactic models, in particular, nonprojective dependency grammars, as discussed in G´omez-Rodr´ıguez et al. (2009). 5.4 Open problems The bounded binarization algorithm that we have presented has exponential run-time in the value of the input fan-out bound f&apos;. It remains an open question whether the bounded binarization problem for LCFRS can be solved in deterministic polynomial time. Even in the restricted case of f&apos; = cp(p), that is, when no increase in the fan-</context>
</contexts>
<marker>Zhang, Huang, Gildea, Knight, 2006</marker>
<rawString>Hao Zhang, Liang Huang, Daniel Gildea, and Kevin Knight. 2006. Synchronous binarization for machine translation. In Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics, pages 256–263. New York, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>