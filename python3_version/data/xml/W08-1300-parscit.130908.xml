<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000008">
<note confidence="0.953145">
Coling 2008
</note>
<title confidence="0.874417166666667">
22nd International Conference on
Computational Linguistics
Proceedings of the workshop on
Cross-Framework and Cross-Domain
Parser Evaluation
Workshop chairs:
</title>
<author confidence="0.7508244">
Johan Bos, Edward Briscoe, Aoife Cahill, John Carroll, Stephen Clark,
Ann Copestake, Dan Flickinger, Josef van Genabith, Julia Hockenmaier,
Aravind Joshi, Ronald Kaplan, Tracy Holloway King, Sandra K¨ubler,
Dekang Lin, Jan Tore Lønning, Christopher Manning, Yusuke Miyao,
Joakim Nivre, Stephan Oepen, Kenji Sagae, Nianwen Xue, and Yi Zhang
</author>
<address confidence="0.4434245">
23 August 2008
Manchester, UK
</address>
<subsubsectionHeader confidence="0.077319">
c�2008 The Coling 2008 Organizing Committee
</subsubsectionHeader>
<bodyText confidence="0.2606378">
Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Nonported license
http://creativecommons.org/licenses/by-nc-sa/3.0/
Some rights reserved
Order copies of this and other Coling proceedings from:
Association for Computational Linguistics (ACL)
209 N. Eighth Street
Stroudsburg, PA 18360
USA
Tel: +1-570-476-8006
Fax: +1-570-476-0860
acl@aclweb.org
ISBN 978-1-905593-50-7
Design by Chimney Design, Brighton, UK
Production and manufacture by One Digital, Brighton, UK
ii
</bodyText>
<sectionHeader confidence="0.925865" genericHeader="abstract">
Introduction
</sectionHeader>
<bodyText confidence="0.997547253521127">
Broad-coverage parsing has come to a point where distinct approaches can offer (seemingly)
comparable performance: statistical parsers acquired from the Penn Treebank (PTB); data-driven
dependency parsers; ‘deep’ parsers trained off enriched treebanks (in linguistic frameworks like CCG,
HPSG, or LFG); and hybrid ‘deep’ parsers, employing hand-built grammars in, for example, HPSG,
LFG, or LTAG. Evaluation against trees in the Wall Street Journal (WSJ) section of the PTB has helped
advance parsing research over the course of the past decade. Despite some scepticism, the crisp and,
over time, stable task of maximizing ParsEval metrics (i.e. constituent labeling precision and recall)
over PTB trees has served as a dominating benchmark. However, modern treebank parsers still restrict
themselves to only a subset of PTB annotation; there is reason to worry about the idiosyncrasies of
this particular corpus; it remains unknown how much the ParsEval metric (or any intrinsic evaluation)
can inform NLP application developers; and PTB-style analyses leave a lot to be desired in terms of
linguistic information.
The Grammatical Relations (GR) scheme, inspired by Dependency Grammar, offers a level of
abstraction over specific syntactic analyses. It aims to capture the ‘gist’ of grammatical relations in a
fashion that avoids reference to a token linguistic theory. GR has recently been applied successfully
in a series of cross-framework parser evaluation studies. At the same time, rather little GR gold
standard data is available, and the GR scheme has been questioned for some of its design decisions.
More specifically, GR builds on a combination of syntactic and, albeit very limited, some semantic
information. Existing studies suggest that the GR gold standard can be both overly rich and overly
shallow in some respects. Furthermore, the mapping of ‘native’ parser outputs into GR introduces
noise, and it raises a number of theoretical and practical questions.
Gold standard representations at the level of propositional semantics have at times been proposed for
cross-framework parser evaluation, specifically where the parsing task is broadly construed as a tool
towards ‘text understanding’, i.e. where the parser is to provide all information that is grammaticalized
and contributing to interpretation. PropBank would seem a candidate gold standard, but to date very
few studies exist that report on the use of PropBank for parser evaluation. The reasons might be that
(at least some) parser developers believe that PropBank goes too far beyond the grammatical level to
serve for parser evaluation, and that starting from PTB structures may have led to some questionable
annotation decisions.
Finally, a complementary topic to cross-framework evaluation is the increasing demand for cross-
domain parser evaluation. At conferences in 2007, concerns were expressed about results that might
rely on particular properties of the WSJ PTB, and over idiosyncrasies of this specific sample of natural
language. For example, it remains a largely open question to what degree progress made in PTB
parsing can carry over to other genres and domains; a related question is on the fitness of some specific
approach (when measured in parser evaluation metrics) for actual NLP applications. In summary, it
may be necessary that the WSJ- and PTB-derived parser benchmarks be complemented by other gold
standards, both in terms of the selection of texts and target representations. And to further the adaptation
of parser evaluation to more languages, it will be important to carefully distill community experience
from ParsEval and GR evaluations.
iii
This workshop aims to bring together developers of broad-coverage parsers who are interested
in questions of target representations and cross-framework and cross-domain evaluation and
benchmarking. From informal discussions that the co-organizers had among themselves and with
colleagues, it seems evident that there is comparatively broad awareness of current issues in parser
evaluation, and a lively interest in detailed exchange of experience (and beliefs). Specifically, the
organizers have tried to attract representatives from diverse parsing approaches and frameworks,
ranging from ‘traditional’ treebank parsing, over data-driven dependency parsing, to parsing in specific
linguistic frameworks. For the latter class of parsers, in many frameworks there is a further sub-division
into groups pursuing ‘classic’ grammar engineering vs. ones who rely on grammar acquisition from
annotated corpora.
Quite likely for the first time in the history of these approaches, there now exist large, broad-coverage
parsing systems representing diverse traditions that can be applied to running text, often producing
comparable representations. In our view, these recent developments present a new opportunity for
re-energizing parser evaluation research. We sincerely wish this workshop will provide participants
with the opportunity for in-depth and cross-framework exchange of expertise and discussion of future
directions in parser evaluation.
A specific sub-goal of the workshop is to establish an improved shared knowledge among participants
of the strengths and weaknesses of extant annotation and evaluation schemes. In order to create a joint
focus for detailed discussion, the workshop preparation included a ‘lightweight’ shared task. For a
selection of 50 sentences (of which ten were considered obligatory, the rest optional) for which PTB,
GR, and PropBank (and other) annotations are available, contributors were invited to scrutinize existing
gold-standard representations contrastively, identify perceived deficiencies, and sketch what can be
done to address these. As an optional component, participants in the shared task were welcome to
include ‘native’, framework-specific output representations and actual results for a parsing system of
their choice (be it their own or not) in the contrastive study. In either case, submissions to the shared
task reflect on the nature of different representations, highlight which additional distinctions are made in
either scheme, and argue why these are useful (for some task) or unmotivated (in general). Of the eight
papers selected for presentation at the workshop, the following three were submissions to the shared
task, viz. those by Flickinger (page 17), Tateisi (page 24), and McConville and Dzikovska (page 51).
For further information on the workshop as a whole, its shared task, and some specific datasets used,
please see:
</bodyText>
<equation confidence="0.915513166666667">
✟
http://lingo.stanford.edu/events/08/pe/
L J
r
iv
Organizers:
</equation>
<affiliation confidence="0.991843476190476">
Johan Bos, University of Rome ‘La Sapienza’ (Italy)
Edward Briscoe, University of Cambridge (UK)
Aoife Cahill, University of Stuttgart (Germany)
John Carroll, University of Sussex (UK)
Stephen Clark, Oxford University (UK)
Ann Copestake, University of Cambridge (UK)
Dan Flickinger, Stanford University (USA)
Josef van Genabith, Dublin City University (Ireland)
Julia Hockenmaier, University of Illinois at Urbana-Champaign (USA)
Aravind Joshi, University of Pennsylvania (USA)
Ronald Kaplan, Powerset, Inc. (USA)
Tracy Holloway King, PARC (USA)
Sandra K¨ubler, Indiana University (USA)
Dekang Lin, Google Inc. (USA)
Jan Tore Lønning, University of Oslo (Norway)
Christopher Manning, Stanford University (USA)
Yusuke Miyao, University of Tokyo (Japan)
Joakim Nivre, V¨axj¨o and Uppsala Universities (Sweden)
Stephan Oepen, University of Oslo (Norway) and CSLI Stanford (USA)
Kenji Sagae, University of Southern California (USA)
Nianwen Xue, University of Colorado (USA)
</affiliation>
<address confidence="0.3873">
Yi Zhang, DFKI GmbH and Saarland University (Germany)
</address>
<page confidence="0.84382">
v
</page>
<tableCaption confidence="0.947891">
Table of Contents
</tableCaption>
<figure confidence="0.877262375">
The Stanford Typed Dependencies Representation
Marie-Catherine de Marneffe and Christopher D. Manning 1
Exploring an Auxiliary Distribution Based Approach to
Domain Adaptation of a Syntactic Disambiguation Model
Barbara Plank and Gertjan van Noord 9
Toward an Underspecifiable Corpus Annotation Scheme
Yuka Tateisi 17
Toward a Cross-Framework Parser Annotation Standard
Dan Flickinger 24
Parser Evaluation Across Frameworks without Format Conversion
Wai Lok Tam, Yo Sato, Yusuke Miyao, and Junichi Tsujii 29
Large Scale Production of Syntactic Annotations to Move Forward
Anne Vilnat, Gil Francopoulo, Olivier Hamon, Sylvain Loiseau, Patrick Paroubek, and
Eric Villemonte dela Clergerie 36
Constructing a Parser Evaluation Scheme
Laura Rimell and Stephen Clark 44
‘Deep’ Grammatical Relations for Semantic Interpretation
Mark McConville and Myroslava O. Dzikovska 51
vii
Conference Programme
Saturday, August 23, 2008
9:00–9:30 Workshop Motivation and Overview (Cahill, Oepen, et al.)
9:30–10:00 The Stanford Typed Dependencies Representation
Marie-Catherine de Marneffe and Christopher D. Manning
</figure>
<reference confidence="0.977033363636364">
10:00–10:30 Exploring an Auxiliary Distribution Based Approach to
Domain Adaptation of a Syntactic Disambiguation Model
Barbara Plank and Gertjan van Noord
10:30–11:00 Coffee Break
11:00–11:30 Toward an Underspecifiable Corpus Annotation Scheme
Yuka Tateisi
11:30–12:00 Toward a Cross-Framework Parser Annotation Standard
Dan Flickinger
12:00–12:30 Discussion
12:30–14:00 Lunch Break
14:00–14:30 Summary of CoNLL 2008 Shared Task (Nivre)
14:30–15:00 Parser Evaluation Across Frameworks without Format Conversion
Wai Lok Tam, Yo Sato, Yusuke Miyao and Junichi Tsujii
15:00–15:30 Large Scale Production of Syntactic Annotations to Move Forward
Anne Vilnat, Gil Francopoulo, Olivier Hamon, Sylvain Loiseau, Patrick Paroubek,
and Eric Villemonte de la Clergerie
15:30–16:00 Coffee Break
16:00–16:30 Constructing a Parser Evaluation Scheme
Laura Rimell and Stephen Clark
16:30–17:00 ‘Deep’ Grammatical Relations for Semantic Interpretation
Mark McConville and Myroslava O. Dzikovska
17:00–17:30 Discussion
</reference>
<page confidence="0.770635">
ix
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.025668">
<note confidence="0.887223">Coling 2008 22nd International Conference on Computational Linguistics Proceedings of the workshop on</note>
<title confidence="0.918393">Cross-Framework and Cross-Domain Parser Evaluation Workshop chairs:</title>
<author confidence="0.974299333333333">Johan Bos</author>
<author confidence="0.974299333333333">Edward Briscoe</author>
<author confidence="0.974299333333333">Aoife Cahill</author>
<author confidence="0.974299333333333">John Carroll</author>
<author confidence="0.974299333333333">Stephen Clark</author>
<author confidence="0.974299333333333">Ann Copestake</author>
<author confidence="0.974299333333333">Dan Flickinger</author>
<author confidence="0.974299333333333">Josef van_Genabith</author>
<author confidence="0.974299333333333">Julia Hockenmaier</author>
<author confidence="0.974299333333333">Aravind Joshi</author>
<author confidence="0.974299333333333">Ronald Kaplan</author>
<author confidence="0.974299333333333">Tracy Holloway King</author>
<author confidence="0.974299333333333">Sandra K¨ubler</author>
<affiliation confidence="0.706374">Dekang Lin, Jan Tore Lønning, Christopher Manning, Yusuke Miyao,</affiliation>
<address confidence="0.833689333333333">Joakim Nivre, Stephan Oepen, Kenji Sagae, Nianwen Xue, and Yi Zhang 23 August Manchester, UK</address>
<note confidence="0.9131415">The Coling 2008 Organizing Committee under the Commons Attribution-Noncommercial-Share Alike 3.0 Nonported</note>
<web confidence="0.956947">http://creativecommons.org/licenses/by-nc-sa/3.0/</web>
<title confidence="0.631054">Some rights reserved</title>
<author confidence="0.419535">Order copies of this</author>
<author confidence="0.419535">other Coling proceedings from</author>
<affiliation confidence="0.833001">Association for Computational Linguistics (ACL)</affiliation>
<address confidence="0.999161">209 N. Eighth Street Stroudsburg, PA 18360 USA</address>
<phone confidence="0.9992845">Tel: +1-570-476-8006 Fax: +1-570-476-0860</phone>
<email confidence="0.943624">acl@aclweb.org</email>
<note confidence="0.57340275">ISBN 978-1-905593-50-7 Design by Chimney Design, Brighton, UK Production and manufacture by One Digital, Brighton, UK ii</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>10:00–10:30 Exploring an Auxiliary Distribution Based Approach to Domain Adaptation of a Syntactic Disambiguation Model Barbara Plank and Gertjan van Noord</title>
<marker></marker>
<rawString>10:00–10:30 Exploring an Auxiliary Distribution Based Approach to Domain Adaptation of a Syntactic Disambiguation Model Barbara Plank and Gertjan van Noord</rawString>
</citation>
<citation valid="false">
<title>Break 11:00–11:30 Toward an Underspecifiable Corpus Annotation Scheme Yuka Tateisi</title>
<marker></marker>
<rawString>10:30–11:00 Coffee Break 11:00–11:30 Toward an Underspecifiable Corpus Annotation Scheme Yuka Tateisi</rawString>
</citation>
<citation valid="true">
<title>11:30–12:00 Toward a Cross-Framework Parser Annotation Standard Dan Flickinger 12:00–12:30</title>
<date>2008</date>
<booktitle>Discussion 12:30–14:00 Lunch Break 14:00–14:30 Summary of CoNLL</booktitle>
<note>Shared Task (Nivre)</note>
<marker>2008</marker>
<rawString>11:30–12:00 Toward a Cross-Framework Parser Annotation Standard Dan Flickinger 12:00–12:30 Discussion 12:30–14:00 Lunch Break 14:00–14:30 Summary of CoNLL 2008 Shared Task (Nivre)</rawString>
</citation>
<citation valid="false">
<title>14:30–15:00 Parser Evaluation Across Frameworks without Format Conversion Wai Lok Tam, Yo Sato, Yusuke Miyao and Junichi Tsujii 15:00–15:30 Large Scale Production of Syntactic Annotations to Move Forward Anne Vilnat, Gil Francopoulo, Olivier Hamon, Sylvain Loiseau, Patrick Paroubek, and Eric Villemonte de la Clergerie</title>
<marker></marker>
<rawString>14:30–15:00 Parser Evaluation Across Frameworks without Format Conversion Wai Lok Tam, Yo Sato, Yusuke Miyao and Junichi Tsujii 15:00–15:30 Large Scale Production of Syntactic Annotations to Move Forward Anne Vilnat, Gil Francopoulo, Olivier Hamon, Sylvain Loiseau, Patrick Paroubek, and Eric Villemonte de la Clergerie</rawString>
</citation>
<citation valid="false">
<title>Break 16:00–16:30 Constructing a Parser Evaluation Scheme Laura Rimell and</title>
<publisher>Stephen Clark</publisher>
<marker></marker>
<rawString>15:30–16:00 Coffee Break 16:00–16:30 Constructing a Parser Evaluation Scheme Laura Rimell and Stephen Clark</rawString>
</citation>
<citation valid="false">
<title>Grammatical Relations for Semantic Interpretation Mark McConville and Myroslava O. Dzikovska 17:00–17:30 Discussion</title>
<marker></marker>
<rawString>16:30–17:00 ‘Deep’ Grammatical Relations for Semantic Interpretation Mark McConville and Myroslava O. Dzikovska 17:00–17:30 Discussion</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>