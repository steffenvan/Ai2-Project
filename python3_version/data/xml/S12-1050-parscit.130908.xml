<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000149">
<title confidence="0.924458">
SemEval-2012 Task 5: Chinese Semantic Dependency Parsing
</title>
<author confidence="0.963418">
Wanxiang Che†, Meishan Zhang†, Yanqiu Shao‡, Ting Liu††Research Center for Social Computing and Information Retrieval
</author>
<affiliation confidence="0.964408">
Harbin Institute of Technology, China
</affiliation>
<email confidence="0.895489">
{car, mszhang, tliu}@ir.hit.edu.cn
</email>
<affiliation confidence="0.841005">
‡Beijing City University, China
</affiliation>
<email confidence="0.995575">
yqshao@bcu.edu.cn
</email>
<sectionHeader confidence="0.995604" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999916">
The paper presents the SemEval-2012 Shared
Task 5: Chinese Semantic Dependency Pars-
ing. The goal of this task is to identify the de-
pendency structure of Chinese sentences from
the semantic view. We firstly introduce the
motivation of providing Chinese semantic de-
pendency parsing task, and then describe the
task in detail including data preparation, data
format, task evaluation, and so on. Over ten
thousand sentences were labeled for partici-
pants to train and evaluate their systems. At
last, we briefly describe the submitted systems
and analyze these results.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999434272727273">
Semantic analysis is a long-term goal of Natural
Language Processing, and as such, has been re-
searched for several decades. A number of tasks
for encoding semantic information have been devel-
oped over the years, such as entity type recognition
and word sense disambiguation. Recently, sentence-
level semantics – in particular, semantic role label-
ing – has received increasing attention. However,
some problems concerning the semantic representa-
tion method used in semantic role labeling continue
to exist (Xue and Palmer, 2005).
</bodyText>
<listItem confidence="0.981152857142857">
1. Semantic role labeling only considers
predicate-argument relations and ignores
the semantic relations between a noun and its
modifier.
2. The meaning of semantic roles is related to spe-
cial predicates. Therefore, there are infinite se-
mantic roles to be learned, as the number of
</listItem>
<bodyText confidence="0.999529882352941">
predicates is not fixed. Although the Prop-
Bank (Xue and Palmer, 2003) normalizes these
semantic roles into certain symbols, such as
Arg0-Arg5, the same symbol can have different
semantic meanings when paired with different
predicates, and thus cannot be learned well.
Semantic dependency parsing is therefore pro-
posed to solve the two problems above for Chinese.
Firstly, the proposed method analyzes all the words’
semantic roles in a sentence and specifies the con-
crete semantic relation of each word pair. After-
ward, this work analyzes and summarizes all the
possible semantic roles, obtaining over 100 of them,
and then uses these semantic roles to specify the se-
mantic relation for each word pair.
Dependency parsing (K¨ubler et al., 2009) is based
on dependency grammar. It has several advantages,
such as concise formalization, easy comprehension,
high efficiency, and so on. Dependency parsing
has been studied intensively in recent decades, with
most related work focusing on syntactic structure.
Many research papers on Chinese linguistics demon-
strate the remarkable difference between semantics
and syntax (Jin, 2001; Zhou and Zhang, 2003).
Chinese is a meaning-combined language with very
flexible syntax, and semantics are more stable than
syntax. The word is the basic unit of semantics,
and the structure and meaning of a sentence consists
mainly of a series of semantic dependencies between
individual words (Li et al., 2003). Thus, a reason-
able endeavor is to exploit dependency parsing for
semantic analysis of Chinese languages. Figure 1
shows an example of Chinese semantic dependency
parsing.
</bodyText>
<page confidence="0.975877">
378
</page>
<note confidence="0.703544">
First Joint Conference on Lexical and Computational Semantics (*SEM), pages 378–384,
Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics
</note>
<figure confidence="0.551849">
root
</figure>
<figureCaption confidence="0.99581">
Figure 1: An example of Chinese Semantic Dependency Parsing.
</figureCaption>
<figure confidence="0.999002857142857">
WK
increasing
RN
prediction
X*
Fund
��
global
g0;;
organization
�
for
N
of
4�;VF
economy
Rfi
Monetary
ATS
turn down
rgIVTI
International
d-genetive
d-restrictive d-restrictive agent
d-restrictive
prep-depend
content
d-genetive d-domain aux-depend
</figure>
<figureCaption confidence="0.798193">
Figure 1 shows that Chinese semantic dependency
</figureCaption>
<bodyText confidence="0.88092475">
parsing looks very similar to traditional syntax-
dominated dependency parsing. Below is a compar-
ison between the two tasks, dealing with three main
points:
</bodyText>
<listItem confidence="0.9789336">
1. Semantic relations are more fine-grained than
syntactic ones: the syntactic subject can either
be the agent or experiencer, and the syntactic
object can be the content, patient, possession,
and so on. On the whole, the number of seman-
tic relations is at least twice that of syntactic
relations.
2. Semantic dependency parsing builds the depen-
dency structure of a sentence in terms of se-
mantics, and the word pairs of a dependency
should have a direct semantic relation. This
criterion determines many sizeable differences
between semantics and syntax, especially in
phrases formed by “XP+DEG”, “XP+DEV”
and prepositional phrases. For example, in “美
丽 的 &amp;国” (beautiful country), the head of
“美丽” (beautiful) is “&amp;国” (country) in se-
mantic dependency parsing, whereas the head
is “的” (de) in syntax dependency parsing.
3. Semantic relations are independent of position.
For example, in “空气 被 污 ” (the air is
contaminated) and “污 了空气” (contami-
nate the air), the patient “空气” (the air) can be
before or behind a predicate “污 ” (contami-
nate).
</listItem>
<bodyText confidence="0.998364">
The rest of the paper is organized as follows. Sec-
tion 2 gives a short overview of data annotation.
Section 3 focuses on the task description. Section
4 describes the participant systems. Section 5 com-
pares and analyzes the results. Finally, Section 6
concludes the paper.
</bodyText>
<sectionHeader confidence="0.966461" genericHeader="method">
2 Data Annotation
</sectionHeader>
<subsectionHeader confidence="0.983669">
2.1 Corpus Section
</subsectionHeader>
<bodyText confidence="0.999992153846154">
10,068 sentences were selected from the Penn Chi-
nese Treebank 6.01 (Xue et al., 2005) (1-121, 1001-
1078, 1100-1151) as the raw corpus from which to
create the Chinese Semantic Dependency Parsing
corpus. These sentences were chosen for the anno-
tation for three reasons. First, gold syntactic depen-
dency structures can be of great help in semantic de-
pendency annotation, as syntactic dependency arcs
are often consistent with semantic ones. Second, the
semantic role labels in PropBank2 can be very use-
ful in the present annotation work. Third, the gold
word segmentation and Part-Of-Speech can be used
as the annotation input in this work.
</bodyText>
<subsectionHeader confidence="0.999377">
2.2 Semantic Relations
</subsectionHeader>
<bodyText confidence="0.999988916666667">
The semantic relations in the prepared Chinese se-
mantic dependency parsing corpus came mostly
from HowNet3 (Dong and Dong, 2006), a fa-
mous Chinese semantic thesaurus. We also referred
to other sources. Aside from the relations from
HowNet, we defined two kinds of new relations: re-
verse relations and indirect relations. When a verb
modifies a noun, the relation between them is a re-
verse relation, and r-XXX is used to indicate this
kind of relation. For instance, in “打 篮球 的 小 93
孩” (the little boy who is playing basketball), the se-
mantic relation between the head word “93孩” (boy)
</bodyText>
<footnote confidence="0.999958">
1http://www.ldc.upenn.edu/Catalog/
catalogEntry.jsp?catalog\\Id=LDC2007T36
2http://verbs.colorado.edu/chinese/cpb/
3http://www.keenage.com/
</footnote>
<page confidence="0.998578">
379
</page>
<bodyText confidence="0.975846666666667">
and “打” (playing) is the r-agent. When a verbal
noun is the head word, the relation between it and
the modifier is the indirect relation j-XXX. For in-
stance, in “企业 管理” (business management), the
head word is “管理” (management) and the modifier
is “企业” (business), their relation is j-patient.
Finally, we defined 84 single-level semantic re-
lations. The number of multi-level semantic rela-
tions that actually appear in the labeled corpus in
this work is 39.
Table 1 summarizes all of the semantic relations
used for annotation.
</bodyText>
<subsectionHeader confidence="0.999797">
2.3 Annotation Flow
</subsectionHeader>
<bodyText confidence="0.9999065">
Our corpus annotation flow can be divided into the
following steps.
</bodyText>
<listItem confidence="0.974895461538462">
1. Conversion of the sentences’ constituent struc-
tures into dependency structures according to
a set of rules similar with those used by the
syntactic community to find the head of a
phrase (Collins, 1999).
2. Labeling of the semantic relations for each de-
pendency relation according to another set of
rules using the functional tags in the Penn Chi-
nese Treebank and the semantic roles in the
Chinese PropBank.
3. Six human annotators are asked to check and
adjust the structure and semantic relation errors
introduced in Step 2.
</listItem>
<bodyText confidence="0.948042444444444">
The first two steps were performed automatically
using rules. A high accuracy may be achieved with
dependency structures when semantic labels are not
considered. However, accuracy declines remarkably
when the semantic label is considered. Unlabeled
Attachment Score (UAS) and Labeled Attachment
Score (LAS) can be used to evaluate the perfor-
mance of the automatic conversion. Table 2 gives
the detailed results.
</bodyText>
<table confidence="0.6899">
UAS LAS
Conversion Result 90.53 57.38
</table>
<tableCaption confidence="0.998179">
Table 2: Accuracy after conversion from gold ProbBank.
</tableCaption>
<sectionHeader confidence="0.96172" genericHeader="method">
3 Task Description
</sectionHeader>
<subsectionHeader confidence="0.999211">
3.1 Corpus Statistics
</subsectionHeader>
<bodyText confidence="0.9992922">
We annotated 10,068 sentences from the Penn Chi-
nese TreeBank for Semantic Dependency Parsing,
and these sentences were divided into training, de-
velopment, and test sections. Table 3 gives the de-
tailed statistical information of the three sections.
</bodyText>
<table confidence="0.994328888888889">
Data Set CTB files # sent. # words.
1-10; 36-65;81-121; 8301
Training 1001-1078; 250311
1100-1119;
1126-1140
Devel 66-80; 1120-1125 534 15329
Test 11-35; 1141-1151 1233 34311
Total 1-121; 1001-1078 10068 299951
1100-1151
</table>
<tableCaption confidence="0.999779">
Table 3: Statistics of training, development and test data.
</tableCaption>
<subsectionHeader confidence="0.99892">
3.2 Data Format
</subsectionHeader>
<bodyText confidence="0.999991866666667">
The data format is identical to that of a syntactic de-
pendency parsing shared task. All the sentences are
in one text file, with each sentence separated by a
blank line. Each sentence consists of one or more to-
kens, and each token is represented on one line con-
sisting of 10 fields. Buchholz and Marsi (2006) pro-
vide more detailed information on the format. Fields
are separated from each other by a tab. Only five of
the 10 fields are used: token id, form, pos tagger,
head, and deprel. Head denotes the semantic depen-
dency of each word, and deprel denotes the corre-
sponding semantic relations of the dependency. In
the data, the lemma column is filled with the form
and the cpostag column with the postag. Figure 2
shows an example.
</bodyText>
<subsectionHeader confidence="0.996562">
3.3 Evaluation Method
</subsectionHeader>
<bodyText confidence="0.999896555555556">
LAS, which is a method widely used in syntactic
dependency parsing, is used to evaluate the perfor-
mance of the semantic dependency parsing system.
LAS is the proportion of “scoring” tokens assigned
to both the correct head and correct semantic depen-
dency relation. Punctuation is disregarded during
the evaluation process. UAS is another important
indicator, as it reflects the accuracy of the semantic
dependency structure.
</bodyText>
<page confidence="0.996609">
380
</page>
<table confidence="0.673451555555555">
Main Semantic Roles
Subject Roles agent, experiencer, causer, possessor, existent, whole, relevant
Object Roles isa, content, possession, patient, OfPart, beneficiary, contrast,
partner, basis, cause, cost, scope, concerning
Auxiliary Semantic Roles
Time Roles duration, TimeFin, TimeIni, time, TimeAdv
Location and State Roles LocationFin, LocationIni, LocationThru, StateFin, state,
StateIni, direction, distance, location
Others Verb Modifiers accompaniment, succeeding, frequency, instrument, material,
</table>
<bodyText confidence="0.591614">
means, angle, times, sequence, sequence-p, negation, degree,
modal, emphasis, manner, aspect, comment
</bodyText>
<subsectionHeader confidence="0.553128">
Attribute Roles
</subsectionHeader>
<bodyText confidence="0.977312">
Direct modifiers d-genetive, d-category, d-member, d-domain, d-quantity-p, d-
quantity, d-deno-p, d-deno, d-host, d-TimePhrase, d-LocPhrase,
d-InstPhrase, d-attribute, d-restrictive, d-material, d-content, d-
sequence, d-sequence-p, qp-mod
Verb Phrase r-{Main Semantic Roles}, eg: r-agent, r-patient, r-possessor
Verb Ellipsis c-{Main Semantic Roles}, eg: c-agent, c-content, c-patient
Noun as Predication j-{Main Semantic Roles}, eg: j-agent, j-patient, j-target
</bodyText>
<subsectionHeader confidence="0.807231">
Syntactic Roles and Others
</subsectionHeader>
<bodyText confidence="0.8454312">
Syntactic Roles s-cause, s-concession, s-condition, s-coordinate, s-or, s-
progression, s-besides, s-succession, s-purpose, s-measure, s-
abandonment, s-preference, s-summary, s-recount, s-concerning,
s-result
Others aux-depend, prep-depend, PU, ROOT
</bodyText>
<tableCaption confidence="0.986409">
Table 1: Semantic Relations defined for Chinese Semantic Dependency Parsing.
</tableCaption>
<figureCaption confidence="0.981033">
Figure 2: Data format of the Chinese Semantic Dependency Parsing corpus.
</figureCaption>
<figure confidence="0.9955715">
ID FORM LEMMA CPOS PPOS FEAT HEAD REL PHEAD PREL
1 钱其琛 钱其琛 NR NR 2 agent
2 % % VV VV 0 ROOT
3 香港 香港 NR NR 4 d-genetive
4 前 前 NN NN 7 s-coordinate
5 和 和 CC CC 7 aux-depend
6 台湾 台湾 NR NR 7 d-genetive
7 问题 问题 NN NN 2 content
</figure>
<page confidence="0.992777">
381
</page>
<sectionHeader confidence="0.979734" genericHeader="method">
4 Participating Systems
</sectionHeader>
<bodyText confidence="0.99964575">
Nine organizations were registered to participate in
the Chinese Semantic Dependency Parsing task. Fi-
nally, nine systems were received from five different
participating teams. These systems are as follows:
</bodyText>
<listItem confidence="0.590705">
1. Zhou Qiaoli-1, Zhou Qiaoli-2, Zhou Qiaoli-3
</listItem>
<bodyText confidence="0.968410121212121">
These three systems propose a divide-and-
conquer strategy for semantic dependency
parsing. The Semantic Role (SR) phrases are
identified (Cai et al., 2011) and then replaced
by their head or the SR of the head. The orig-
inal sentence is thus divided into two types of
parts that can be parsed separately. The first
type is SR phrase parsing, and the second in-
volves the replacement of SR phrases with ei-
ther their head or the SR of the head. Finally,
the paper takes a graph-based parser (Li et al.,
2011) as the semantic dependency parser for all
parts. These three systems differ in their phrase
identification strategies.
2. NJU-Parser-1, NJU-Parser-2
The NJU-Parser is based on the state-of-the-
art MSTParser (McDonald, 2006). NJU-Parser
applies three methods to enhance semantic de-
pendency parsing. First, sentences are split
into sub-sentences using commas and semi-
colons: (a) sentences are split using only com-
mas and semicolons, as in the primary sys-
tem, and (b) classifiers are used to determine
whether a comma or semicolon should be used
to split the sentence. Second, the last character
in a Chinese word is extracted as the lemma,
since it usually contains the main sense or se-
mantic class. Third, the multilevel-label is in-
troduced into the semantic relation, for exam-
ple, the r-{Main Semantic Roles}, with NJU-
Parser exploiting special strategies to handle it.
However, this third method does not show pos-
itive performance.
</bodyText>
<sectionHeader confidence="0.782636" genericHeader="method">
3. Zhijun Wu-1
</sectionHeader>
<bodyText confidence="0.997671277777778">
This system extends the second-order of the
MSTParser by adding third-order features, and
then applying this model to Chinese semantic
dependency parsing. In contrast to Koo and
Collins (2010) this system does not implement
the third-order model using dynamic program-
ming, as it requires O(n4) time. It first first ob-
tained the K-best results of second-order mod-
els and then added the third-order features into
the results.
4. ICT-1
The ICT semantic dependency parser employs
a system-combining strategy to obtain the de-
pendency structure and then uses the classifier
from Le Zhang’s Maximum Entropy Model-
ing Toolkit4 to predict the semantic relation for
each dependency. The system-combining strat-
egy involves three steps:
</bodyText>
<listItem confidence="0.960876333333333">
• Parsing each sentence using Nivre’s arc
standard, Nivre’s arc eager (Nivre and
Nilsson, 2005; Nivre, 2008), and Liang’s
dynamic algorithm (Huang and Sagae,
2010);
• Combining parses given by the three
parsers into a weighted directed graph;
• Using the Chu-Liu-Edmonds algorithm to
search for the final parse for each sen-
tence.
5. Giuseppe Attardi-SVM-1-R, Giuseppe Attardi-
SVM-1-rev
</listItem>
<bodyText confidence="0.9991615">
We didn’t receive the system description of
these two systems.
</bodyText>
<sectionHeader confidence="0.998192" genericHeader="evaluation">
5 Results &amp; Analysis
</sectionHeader>
<bodyText confidence="0.999959833333333">
LAS is the main evaluation metric in Chinese Se-
mantic Dependency Parsing, whereas UAS is the
secondary metric. Table 4 shows the results for these
two indicators in all participating systems.
As shown in Table 4, the Zhou Qiaoli-3 system
achieved the best results with LAS of 61.84. The
LAS values of top systems are very closely. We per-
formed significance tests5 for top six results. Table
5 shows the results , from which we can see that
the performances of top five results are comparative
(p &gt; 0.1) and the rank sixth system is significantly
(p &lt; 10−5) worse than top five results.
</bodyText>
<footnote confidence="0.9965655">
4http://homepages.inf.ed.ac.uk/s0450736/
maxenttoolkit.html
5http://www.cis.upenn.edu/˜dbikel/
download/compare.pl
</footnote>
<page confidence="0.98552">
382
</page>
<table confidence="0.985503">
NJU-Parser-2 NJU-Parser-1 Zhijun Wu-1 Zhou Qiaoli-1 Zhou Qiaoli-2
Zhou Qiaoli-3 ∼ ∼ ∼ ∼ &gt;
NJU-Parser-2 – ∼ ∼ ∼ &gt;
NJU-Parser-1 – – ∼ ∼ &gt;
Zhijun Wu-1 – – – ∼ &gt;
Zhou Qiaoli-1 – – – – &gt;
</table>
<tableCaption confidence="0.996465">
Table 5: Significance tests of the top five systems. ∼ denotes that the two systems are comparable (p &gt; 0.1), and &gt;
means the system of this row is significantly (p &lt; 10−5) better than the system of this column.
</tableCaption>
<table confidence="0.998858363636363">
System LAS UAS
Zhou Qiaoli-3 61.84 80.60
NJU-Parser-2 61.64 80.29
NJU-Parser-1 61.63 80.35
Zhijun Wu-1 61.58 80.64
Zhou Qiaoli-1 61.15 80.41
Zhou Qiaoli-2 57.55 78.55
ICT-1 56.31 73.20
Giuseppe Attardi-SVM-1-R 44.46 60.83
Giuseppe Attardi-SVM-1-rev 21.86 40.47
Average 54.22 72.82
</table>
<tableCaption confidence="0.99982">
Table 4: Results of the submitted systems.
</tableCaption>
<bodyText confidence="0.999788421052632">
The average LAS for all systems was 54.22.
Chinese Semantic Dependency Parsing performed
much more poorly than Chinese Syntactic Depen-
dency Parsing due to the increased complexity
brought about by the greater number of semantic re-
lations compared with syntactic relations, as well as
greater difficulty in classifying semantic relations.
In general, all the systems employed the tradi-
tional syntax-dominated dependency parsing frame-
works. Some new methods were proposed for
this task. Zhou Qiaoli’s systems first identified
the semantic role phrase in a sentence, and then
employed graph-based dependency parsing to ana-
lyze the semantic structure of the sentence. NJU-
Parser first split the sentence into sub-sentences,
then trained and parsed the sentence based on these
sub-sentences; this was shown to perform well. In
addition, ensemble models were also proposed to
solve the task using ICT systems.
</bodyText>
<sectionHeader confidence="0.999486" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999956818181818">
We described the Chinese Semantic Dependency
Parsing task for SemEval-2012, which is designed to
parse the semantic structures of Chinese sentences.
Nine results were submitted by five organizations,
with the best result garnering an LAS score of 61.84,
which is far below the performance of Chinese Syn-
tax. This demonstrates that further research on the
structure of Chinese Semantics is needed.
In the future, we will check and improve the anno-
tation standards while building a large, high-quality
corpus for further Chinese semantic research.
</bodyText>
<sectionHeader confidence="0.997474" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999949166666667">
We thank the anonymous reviewers for their help-
ful comments. This work was supported by Na-
tional Natural Science Foundation of China (NSFC)
via grant 61133012 and 61170144, and the Na-
tional “863” Leading Technology Research Project
via grant 2012AA011102.
</bodyText>
<sectionHeader confidence="0.998503" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997118736842105">
Sabine Buchholz and Erwin Marsi. 2006. Conll-x shared
task on multilingual dependency parsing. In Proceed-
ings of the Tenth Conference on Computational Nat-
ural Language Learning (CoNLL-X), pages 149–164,
New York City, June. Association for Computational
Linguistics.
Dongfeng Cai, Ling Zhang, Qiaoli Zhou, and Yue Zhao.
2011. A collocation based approach for prepositional
phrase identification. IEEE NLPKE.
Michael Collins. 1999. Head-Driven Statistical Models
for Natural Language Parsing. Ph.D. thesis, Pennsyl-
vania University.
Zhendong Dong and Qiang Dong. 2006. HownetAnd the
Computation of Meaning. World Scientific Publishing
Co., Inc., River Edge, NJ, USA.
Liang Huang and Kenji Sagae. 2010. Dynamic pro-
gramming for linear-time incremental parsing. In Pro-
ceedings of the 48th Annual Meeting of the Associa-
tion for Computational Linguistics, pages 1077–1086,
</reference>
<page confidence="0.990469">
383
</page>
<reference confidence="0.999577571428571">
Uppsala, Sweden, July. Association for Computational
Linguistics.
Guangjin Jin. 2001. Theory of modern Chinese verb se-
mantic computation. Beijing University Press.
Terry Koo and Michael Collins. 2010. Efficient third-
order dependency parsers. In Proceedings of the 48th
Annual Meeting of the ACL, number July, pages 1–11.
Sandra K¨ubler, Ryan McDonald, and Joakim Nivre.
2009. Dependency Parsing. In Synthesis Lectures on
Human Language Technologies.
Mingqin Li, Juanzi Li, Zhendong Dong, Zuoying Wang,
and Dajin Lu. 2003. Building a large chinese corpus
annotated with semantic dependency. In Proceedings
of the second SIGHAN workshop on Chinese language
processing - Volume 17, SIGHAN ’03, pages 84–91,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Zhenghua Li, Min Zhang, Wanxiang Che, Ting Liu, Wen-
liang Chen, and Haizhou Li. 2011. Joint models for
chinese pos tagging and dependency parsing. In Pro-
ceedings of the 2011 Conference on Empirical Meth-
ods in Natural Language Processing, pages 1180–
1191, Edinburgh, Scotland, UK., July. Association for
Computational Linguistics.
Ryan McDonald. 2006. Discriminative learning and
spanning tree algorithms for dependency parsing.
Ph.D. thesis, University of Pennsylvania.
Joakim Nivre and Jens Nilsson. 2005. Pseudo-projective
dependency parsing. In Proceedings of the 43rd An-
nual Meeting of the Association for Computational
Linguistics (ACL).
Joakim Nivre. 2008. Algorithms for deterministic incre-
mental dependency parsing. Computational Linguis-
tics, 34(4):513–553.
Nianwen Xue and Martha Palmer. 2003. Annotating
the propositions in the penn chinese treebank. In Pro-
ceedings of the Second SIGHAN Workshop on Chinese
Language Processing.
Nianwen Xue and Martha Palmer. 2005. Automatic se-
mantic role labeling for chinese verbs. In Proceedings
of the 19th International Joint Conference on Artificial
Intelligence.
Nianwen Xue, Fei Xia, Fu-Dong Chiou, and Martha
Palmer. 2005. The penn chinese treebank: Phrase
structure annotation of a large corpus. Natural Lan-
guage Engineering, 11(2):207–238.
Guoguang Zhou and Linlin Zhang. 2003. The theory
and method of modern Chinese grammar. Guangdong
Higher Education Press.
</reference>
<page confidence="0.998973">
384
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.452835">
<title confidence="0.934783">SemEval-2012 Task 5: Chinese Semantic Dependency Parsing Meishan Yanqiu Ting Center for Social Computing and Information</title>
<affiliation confidence="0.997113">Harbin Institute of Technology,</affiliation>
<email confidence="0.541675">mszhang,</email>
<affiliation confidence="0.997461">City University,</affiliation>
<email confidence="0.97038">yqshao@bcu.edu.cn</email>
<abstract confidence="0.999460857142857">The paper presents the SemEval-2012 Shared 5: Semantic Dependency Pars- The goal of this task is to identify the dependency structure of Chinese sentences from the semantic view. We firstly introduce the motivation of providing Chinese semantic dependency parsing task, and then describe the task in detail including data preparation, data format, task evaluation, and so on. Over ten thousand sentences were labeled for participants to train and evaluate their systems. At last, we briefly describe the submitted systems and analyze these results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>Conll-x shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLL-X),</booktitle>
<pages>149--164</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>New York City,</location>
<contexts>
<context position="9286" citStr="Buchholz and Marsi (2006)" startWordPosition="1444" endWordPosition="1447">the three sections. Data Set CTB files # sent. # words. 1-10; 36-65;81-121; 8301 Training 1001-1078; 250311 1100-1119; 1126-1140 Devel 66-80; 1120-1125 534 15329 Test 11-35; 1141-1151 1233 34311 Total 1-121; 1001-1078 10068 299951 1100-1151 Table 3: Statistics of training, development and test data. 3.2 Data Format The data format is identical to that of a syntactic dependency parsing shared task. All the sentences are in one text file, with each sentence separated by a blank line. Each sentence consists of one or more tokens, and each token is represented on one line consisting of 10 fields. Buchholz and Marsi (2006) provide more detailed information on the format. Fields are separated from each other by a tab. Only five of the 10 fields are used: token id, form, pos tagger, head, and deprel. Head denotes the semantic dependency of each word, and deprel denotes the corresponding semantic relations of the dependency. In the data, the lemma column is filled with the form and the cpostag column with the postag. Figure 2 shows an example. 3.3 Evaluation Method LAS, which is a method widely used in syntactic dependency parsing, is used to evaluate the performance of the semantic dependency parsing system. LAS </context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Sabine Buchholz and Erwin Marsi. 2006. Conll-x shared task on multilingual dependency parsing. In Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLL-X), pages 149–164, New York City, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dongfeng Cai</author>
<author>Ling Zhang</author>
<author>Qiaoli Zhou</author>
<author>Yue Zhao</author>
</authors>
<title>A collocation based approach for prepositional phrase identification.</title>
<date>2011</date>
<journal>IEEE NLPKE.</journal>
<contexts>
<context position="12330" citStr="Cai et al., 2011" startWordPosition="1884" endWordPosition="1887">EAD PREL 1 钱其琛 钱其琛 NR NR 2 agent 2 % % VV VV 0 ROOT 3 香港 香港 NR NR 4 d-genetive 4 前 前 NN NN 7 s-coordinate 5 和 和 CC CC 7 aux-depend 6 台湾 台湾 NR NR 7 d-genetive 7 问题 问题 NN NN 2 content 381 4 Participating Systems Nine organizations were registered to participate in the Chinese Semantic Dependency Parsing task. Finally, nine systems were received from five different participating teams. These systems are as follows: 1. Zhou Qiaoli-1, Zhou Qiaoli-2, Zhou Qiaoli-3 These three systems propose a divide-andconquer strategy for semantic dependency parsing. The Semantic Role (SR) phrases are identified (Cai et al., 2011) and then replaced by their head or the SR of the head. The original sentence is thus divided into two types of parts that can be parsed separately. The first type is SR phrase parsing, and the second involves the replacement of SR phrases with either their head or the SR of the head. Finally, the paper takes a graph-based parser (Li et al., 2011) as the semantic dependency parser for all parts. These three systems differ in their phrase identification strategies. 2. NJU-Parser-1, NJU-Parser-2 The NJU-Parser is based on the state-of-theart MSTParser (McDonald, 2006). NJU-Parser applies three m</context>
</contexts>
<marker>Cai, Zhang, Zhou, Zhao, 2011</marker>
<rawString>Dongfeng Cai, Ling Zhang, Qiaoli Zhou, and Yue Zhao. 2011. A collocation based approach for prepositional phrase identification. IEEE NLPKE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Head-Driven Statistical Models for Natural Language Parsing.</title>
<date>1999</date>
<tech>Ph.D. thesis,</tech>
<institution>Pennsylvania University.</institution>
<contexts>
<context position="7562" citStr="Collins, 1999" startWordPosition="1171" endWordPosition="1172">is “管理” (management) and the modifier is “企业” (business), their relation is j-patient. Finally, we defined 84 single-level semantic relations. The number of multi-level semantic relations that actually appear in the labeled corpus in this work is 39. Table 1 summarizes all of the semantic relations used for annotation. 2.3 Annotation Flow Our corpus annotation flow can be divided into the following steps. 1. Conversion of the sentences’ constituent structures into dependency structures according to a set of rules similar with those used by the syntactic community to find the head of a phrase (Collins, 1999). 2. Labeling of the semantic relations for each dependency relation according to another set of rules using the functional tags in the Penn Chinese Treebank and the semantic roles in the Chinese PropBank. 3. Six human annotators are asked to check and adjust the structure and semantic relation errors introduced in Step 2. The first two steps were performed automatically using rules. A high accuracy may be achieved with dependency structures when semantic labels are not considered. However, accuracy declines remarkably when the semantic label is considered. Unlabeled Attachment Score (UAS) and</context>
</contexts>
<marker>Collins, 1999</marker>
<rawString>Michael Collins. 1999. Head-Driven Statistical Models for Natural Language Parsing. Ph.D. thesis, Pennsylvania University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhendong Dong</author>
<author>Qiang Dong</author>
</authors>
<title>HownetAnd the Computation of Meaning.</title>
<date>2006</date>
<publisher>World Scientific Publishing Co., Inc.,</publisher>
<location>River Edge, NJ, USA.</location>
<contexts>
<context position="6141" citStr="Dong and Dong, 2006" startWordPosition="946" endWordPosition="949">antic Dependency Parsing corpus. These sentences were chosen for the annotation for three reasons. First, gold syntactic dependency structures can be of great help in semantic dependency annotation, as syntactic dependency arcs are often consistent with semantic ones. Second, the semantic role labels in PropBank2 can be very useful in the present annotation work. Third, the gold word segmentation and Part-Of-Speech can be used as the annotation input in this work. 2.2 Semantic Relations The semantic relations in the prepared Chinese semantic dependency parsing corpus came mostly from HowNet3 (Dong and Dong, 2006), a famous Chinese semantic thesaurus. We also referred to other sources. Aside from the relations from HowNet, we defined two kinds of new relations: reverse relations and indirect relations. When a verb modifies a noun, the relation between them is a reverse relation, and r-XXX is used to indicate this kind of relation. For instance, in “打 篮球 的 小 93 孩” (the little boy who is playing basketball), the semantic relation between the head word “93孩” (boy) 1http://www.ldc.upenn.edu/Catalog/ catalogEntry.jsp?catalog\\Id=LDC2007T36 2http://verbs.colorado.edu/chinese/cpb/ 3http://www.keenage.com/ 379</context>
</contexts>
<marker>Dong, Dong, 2006</marker>
<rawString>Zhendong Dong and Qiang Dong. 2006. HownetAnd the Computation of Meaning. World Scientific Publishing Co., Inc., River Edge, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Kenji Sagae</author>
</authors>
<title>Dynamic programming for linear-time incremental parsing.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1077--1086</pages>
<contexts>
<context position="14513" citStr="Huang and Sagae, 2010" startWordPosition="2239" endWordPosition="2242">amming, as it requires O(n4) time. It first first obtained the K-best results of second-order models and then added the third-order features into the results. 4. ICT-1 The ICT semantic dependency parser employs a system-combining strategy to obtain the dependency structure and then uses the classifier from Le Zhang’s Maximum Entropy Modeling Toolkit4 to predict the semantic relation for each dependency. The system-combining strategy involves three steps: • Parsing each sentence using Nivre’s arc standard, Nivre’s arc eager (Nivre and Nilsson, 2005; Nivre, 2008), and Liang’s dynamic algorithm (Huang and Sagae, 2010); • Combining parses given by the three parsers into a weighted directed graph; • Using the Chu-Liu-Edmonds algorithm to search for the final parse for each sentence. 5. Giuseppe Attardi-SVM-1-R, Giuseppe AttardiSVM-1-rev We didn’t receive the system description of these two systems. 5 Results &amp; Analysis LAS is the main evaluation metric in Chinese Semantic Dependency Parsing, whereas UAS is the secondary metric. Table 4 shows the results for these two indicators in all participating systems. As shown in Table 4, the Zhou Qiaoli-3 system achieved the best results with LAS of 61.84. The LAS val</context>
</contexts>
<marker>Huang, Sagae, 2010</marker>
<rawString>Liang Huang and Kenji Sagae. 2010. Dynamic programming for linear-time incremental parsing. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1077–1086,</rawString>
</citation>
<citation valid="false">
<institution>Uppsala, Sweden, July. Association for Computational Linguistics.</institution>
<marker></marker>
<rawString>Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guangjin Jin</author>
</authors>
<title>Theory of modern Chinese verb semantic computation.</title>
<date>2001</date>
<publisher>Beijing University Press.</publisher>
<contexts>
<context position="2824" citStr="Jin, 2001" startWordPosition="424" endWordPosition="425">, this work analyzes and summarizes all the possible semantic roles, obtaining over 100 of them, and then uses these semantic roles to specify the semantic relation for each word pair. Dependency parsing (K¨ubler et al., 2009) is based on dependency grammar. It has several advantages, such as concise formalization, easy comprehension, high efficiency, and so on. Dependency parsing has been studied intensively in recent decades, with most related work focusing on syntactic structure. Many research papers on Chinese linguistics demonstrate the remarkable difference between semantics and syntax (Jin, 2001; Zhou and Zhang, 2003). Chinese is a meaning-combined language with very flexible syntax, and semantics are more stable than syntax. The word is the basic unit of semantics, and the structure and meaning of a sentence consists mainly of a series of semantic dependencies between individual words (Li et al., 2003). Thus, a reasonable endeavor is to exploit dependency parsing for semantic analysis of Chinese languages. Figure 1 shows an example of Chinese semantic dependency parsing. 378 First Joint Conference on Lexical and Computational Semantics (*SEM), pages 378–384, Montr´eal, Canada, June </context>
</contexts>
<marker>Jin, 2001</marker>
<rawString>Guangjin Jin. 2001. Theory of modern Chinese verb semantic computation. Beijing University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Koo</author>
<author>Michael Collins</author>
</authors>
<title>Efficient thirdorder dependency parsers.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the ACL, number July,</booktitle>
<pages>1--11</pages>
<contexts>
<context position="13818" citStr="Koo and Collins (2010)" startWordPosition="2131" endWordPosition="2134"> semicolon should be used to split the sentence. Second, the last character in a Chinese word is extracted as the lemma, since it usually contains the main sense or semantic class. Third, the multilevel-label is introduced into the semantic relation, for example, the r-{Main Semantic Roles}, with NJUParser exploiting special strategies to handle it. However, this third method does not show positive performance. 3. Zhijun Wu-1 This system extends the second-order of the MSTParser by adding third-order features, and then applying this model to Chinese semantic dependency parsing. In contrast to Koo and Collins (2010) this system does not implement the third-order model using dynamic programming, as it requires O(n4) time. It first first obtained the K-best results of second-order models and then added the third-order features into the results. 4. ICT-1 The ICT semantic dependency parser employs a system-combining strategy to obtain the dependency structure and then uses the classifier from Le Zhang’s Maximum Entropy Modeling Toolkit4 to predict the semantic relation for each dependency. The system-combining strategy involves three steps: • Parsing each sentence using Nivre’s arc standard, Nivre’s arc eage</context>
</contexts>
<marker>Koo, Collins, 2010</marker>
<rawString>Terry Koo and Michael Collins. 2010. Efficient thirdorder dependency parsers. In Proceedings of the 48th Annual Meeting of the ACL, number July, pages 1–11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sandra K¨ubler</author>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Dependency Parsing. In Synthesis Lectures on Human Language Technologies.</title>
<date>2009</date>
<marker>K¨ubler, McDonald, Nivre, 2009</marker>
<rawString>Sandra K¨ubler, Ryan McDonald, and Joakim Nivre. 2009. Dependency Parsing. In Synthesis Lectures on Human Language Technologies.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mingqin Li</author>
<author>Juanzi Li</author>
<author>Zhendong Dong</author>
<author>Zuoying Wang</author>
<author>Dajin Lu</author>
</authors>
<title>Building a large chinese corpus annotated with semantic dependency.</title>
<date>2003</date>
<booktitle>In Proceedings of the second SIGHAN workshop on Chinese language processing - Volume 17, SIGHAN ’03,</booktitle>
<pages>84--91</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="3138" citStr="Li et al., 2003" startWordPosition="473" endWordPosition="476">lization, easy comprehension, high efficiency, and so on. Dependency parsing has been studied intensively in recent decades, with most related work focusing on syntactic structure. Many research papers on Chinese linguistics demonstrate the remarkable difference between semantics and syntax (Jin, 2001; Zhou and Zhang, 2003). Chinese is a meaning-combined language with very flexible syntax, and semantics are more stable than syntax. The word is the basic unit of semantics, and the structure and meaning of a sentence consists mainly of a series of semantic dependencies between individual words (Li et al., 2003). Thus, a reasonable endeavor is to exploit dependency parsing for semantic analysis of Chinese languages. Figure 1 shows an example of Chinese semantic dependency parsing. 378 First Joint Conference on Lexical and Computational Semantics (*SEM), pages 378–384, Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics root Figure 1: An example of Chinese Semantic Dependency Parsing. WK increasing RN prediction X* Fund �� global g0;; organization � for N of 4�;VF economy Rfi Monetary ATS turn down rgIVTI International d-genetive d-restrictive d-restrictive agent d-rest</context>
</contexts>
<marker>Li, Li, Dong, Wang, Lu, 2003</marker>
<rawString>Mingqin Li, Juanzi Li, Zhendong Dong, Zuoying Wang, and Dajin Lu. 2003. Building a large chinese corpus annotated with semantic dependency. In Proceedings of the second SIGHAN workshop on Chinese language processing - Volume 17, SIGHAN ’03, pages 84–91, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhenghua Li</author>
<author>Min Zhang</author>
<author>Wanxiang Che</author>
<author>Ting Liu</author>
<author>Wenliang Chen</author>
<author>Haizhou Li</author>
</authors>
<title>Joint models for chinese pos tagging and dependency parsing.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1180--1191</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Edinburgh, Scotland, UK.,</location>
<contexts>
<context position="12679" citStr="Li et al., 2011" startWordPosition="1952" endWordPosition="1955">five different participating teams. These systems are as follows: 1. Zhou Qiaoli-1, Zhou Qiaoli-2, Zhou Qiaoli-3 These three systems propose a divide-andconquer strategy for semantic dependency parsing. The Semantic Role (SR) phrases are identified (Cai et al., 2011) and then replaced by their head or the SR of the head. The original sentence is thus divided into two types of parts that can be parsed separately. The first type is SR phrase parsing, and the second involves the replacement of SR phrases with either their head or the SR of the head. Finally, the paper takes a graph-based parser (Li et al., 2011) as the semantic dependency parser for all parts. These three systems differ in their phrase identification strategies. 2. NJU-Parser-1, NJU-Parser-2 The NJU-Parser is based on the state-of-theart MSTParser (McDonald, 2006). NJU-Parser applies three methods to enhance semantic dependency parsing. First, sentences are split into sub-sentences using commas and semicolons: (a) sentences are split using only commas and semicolons, as in the primary system, and (b) classifiers are used to determine whether a comma or semicolon should be used to split the sentence. Second, the last character in a Ch</context>
</contexts>
<marker>Li, Zhang, Che, Liu, Chen, Li, 2011</marker>
<rawString>Zhenghua Li, Min Zhang, Wanxiang Che, Ting Liu, Wenliang Chen, and Haizhou Li. 2011. Joint models for chinese pos tagging and dependency parsing. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1180– 1191, Edinburgh, Scotland, UK., July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
</authors>
<title>Discriminative learning and spanning tree algorithms for dependency parsing.</title>
<date>2006</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="12902" citStr="McDonald, 2006" startWordPosition="1985" endWordPosition="1986">) phrases are identified (Cai et al., 2011) and then replaced by their head or the SR of the head. The original sentence is thus divided into two types of parts that can be parsed separately. The first type is SR phrase parsing, and the second involves the replacement of SR phrases with either their head or the SR of the head. Finally, the paper takes a graph-based parser (Li et al., 2011) as the semantic dependency parser for all parts. These three systems differ in their phrase identification strategies. 2. NJU-Parser-1, NJU-Parser-2 The NJU-Parser is based on the state-of-theart MSTParser (McDonald, 2006). NJU-Parser applies three methods to enhance semantic dependency parsing. First, sentences are split into sub-sentences using commas and semicolons: (a) sentences are split using only commas and semicolons, as in the primary system, and (b) classifiers are used to determine whether a comma or semicolon should be used to split the sentence. Second, the last character in a Chinese word is extracted as the lemma, since it usually contains the main sense or semantic class. Third, the multilevel-label is introduced into the semantic relation, for example, the r-{Main Semantic Roles}, with NJUParse</context>
</contexts>
<marker>McDonald, 2006</marker>
<rawString>Ryan McDonald. 2006. Discriminative learning and spanning tree algorithms for dependency parsing. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Jens Nilsson</author>
</authors>
<title>Pseudo-projective dependency parsing.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="14444" citStr="Nivre and Nilsson, 2005" startWordPosition="2229" endWordPosition="2232">is system does not implement the third-order model using dynamic programming, as it requires O(n4) time. It first first obtained the K-best results of second-order models and then added the third-order features into the results. 4. ICT-1 The ICT semantic dependency parser employs a system-combining strategy to obtain the dependency structure and then uses the classifier from Le Zhang’s Maximum Entropy Modeling Toolkit4 to predict the semantic relation for each dependency. The system-combining strategy involves three steps: • Parsing each sentence using Nivre’s arc standard, Nivre’s arc eager (Nivre and Nilsson, 2005; Nivre, 2008), and Liang’s dynamic algorithm (Huang and Sagae, 2010); • Combining parses given by the three parsers into a weighted directed graph; • Using the Chu-Liu-Edmonds algorithm to search for the final parse for each sentence. 5. Giuseppe Attardi-SVM-1-R, Giuseppe AttardiSVM-1-rev We didn’t receive the system description of these two systems. 5 Results &amp; Analysis LAS is the main evaluation metric in Chinese Semantic Dependency Parsing, whereas UAS is the secondary metric. Table 4 shows the results for these two indicators in all participating systems. As shown in Table 4, the Zhou Qia</context>
</contexts>
<marker>Nivre, Nilsson, 2005</marker>
<rawString>Joakim Nivre and Jens Nilsson. 2005. Pseudo-projective dependency parsing. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Algorithms for deterministic incremental dependency parsing.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>4</issue>
<contexts>
<context position="14458" citStr="Nivre, 2008" startWordPosition="2233" endWordPosition="2234">ent the third-order model using dynamic programming, as it requires O(n4) time. It first first obtained the K-best results of second-order models and then added the third-order features into the results. 4. ICT-1 The ICT semantic dependency parser employs a system-combining strategy to obtain the dependency structure and then uses the classifier from Le Zhang’s Maximum Entropy Modeling Toolkit4 to predict the semantic relation for each dependency. The system-combining strategy involves three steps: • Parsing each sentence using Nivre’s arc standard, Nivre’s arc eager (Nivre and Nilsson, 2005; Nivre, 2008), and Liang’s dynamic algorithm (Huang and Sagae, 2010); • Combining parses given by the three parsers into a weighted directed graph; • Using the Chu-Liu-Edmonds algorithm to search for the final parse for each sentence. 5. Giuseppe Attardi-SVM-1-R, Giuseppe AttardiSVM-1-rev We didn’t receive the system description of these two systems. 5 Results &amp; Analysis LAS is the main evaluation metric in Chinese Semantic Dependency Parsing, whereas UAS is the secondary metric. Table 4 shows the results for these two indicators in all participating systems. As shown in Table 4, the Zhou Qiaoli-3 system a</context>
</contexts>
<marker>Nivre, 2008</marker>
<rawString>Joakim Nivre. 2008. Algorithms for deterministic incremental dependency parsing. Computational Linguistics, 34(4):513–553.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Martha Palmer</author>
</authors>
<title>Annotating the propositions in the penn chinese treebank.</title>
<date>2003</date>
<booktitle>In Proceedings of the Second SIGHAN Workshop on Chinese Language Processing.</booktitle>
<contexts>
<context position="1766" citStr="Xue and Palmer, 2003" startWordPosition="261" endWordPosition="264"> disambiguation. Recently, sentencelevel semantics – in particular, semantic role labeling – has received increasing attention. However, some problems concerning the semantic representation method used in semantic role labeling continue to exist (Xue and Palmer, 2005). 1. Semantic role labeling only considers predicate-argument relations and ignores the semantic relations between a noun and its modifier. 2. The meaning of semantic roles is related to special predicates. Therefore, there are infinite semantic roles to be learned, as the number of predicates is not fixed. Although the PropBank (Xue and Palmer, 2003) normalizes these semantic roles into certain symbols, such as Arg0-Arg5, the same symbol can have different semantic meanings when paired with different predicates, and thus cannot be learned well. Semantic dependency parsing is therefore proposed to solve the two problems above for Chinese. Firstly, the proposed method analyzes all the words’ semantic roles in a sentence and specifies the concrete semantic relation of each word pair. Afterward, this work analyzes and summarizes all the possible semantic roles, obtaining over 100 of them, and then uses these semantic roles to specify the sema</context>
</contexts>
<marker>Xue, Palmer, 2003</marker>
<rawString>Nianwen Xue and Martha Palmer. 2003. Annotating the propositions in the penn chinese treebank. In Proceedings of the Second SIGHAN Workshop on Chinese Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Martha Palmer</author>
</authors>
<title>Automatic semantic role labeling for chinese verbs.</title>
<date>2005</date>
<booktitle>In Proceedings of the 19th International Joint Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="1413" citStr="Xue and Palmer, 2005" startWordPosition="204" endWordPosition="207">. At last, we briefly describe the submitted systems and analyze these results. 1 Introduction Semantic analysis is a long-term goal of Natural Language Processing, and as such, has been researched for several decades. A number of tasks for encoding semantic information have been developed over the years, such as entity type recognition and word sense disambiguation. Recently, sentencelevel semantics – in particular, semantic role labeling – has received increasing attention. However, some problems concerning the semantic representation method used in semantic role labeling continue to exist (Xue and Palmer, 2005). 1. Semantic role labeling only considers predicate-argument relations and ignores the semantic relations between a noun and its modifier. 2. The meaning of semantic roles is related to special predicates. Therefore, there are infinite semantic roles to be learned, as the number of predicates is not fixed. Although the PropBank (Xue and Palmer, 2003) normalizes these semantic roles into certain symbols, such as Arg0-Arg5, the same symbol can have different semantic meanings when paired with different predicates, and thus cannot be learned well. Semantic dependency parsing is therefore propose</context>
</contexts>
<marker>Xue, Palmer, 2005</marker>
<rawString>Nianwen Xue and Martha Palmer. 2005. Automatic semantic role labeling for chinese verbs. In Proceedings of the 19th International Joint Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Fei Xia</author>
<author>Fu-Dong Chiou</author>
<author>Martha Palmer</author>
</authors>
<title>The penn chinese treebank: Phrase structure annotation of a large corpus.</title>
<date>2005</date>
<journal>Natural Language Engineering,</journal>
<volume>11</volume>
<issue>2</issue>
<contexts>
<context position="5435" citStr="Xue et al., 2005" startWordPosition="834" endWordPosition="837"> 3. Semantic relations are independent of position. For example, in “空气 被 污 ” (the air is contaminated) and “污 了空气” (contaminate the air), the patient “空气” (the air) can be before or behind a predicate “污 ” (contaminate). The rest of the paper is organized as follows. Section 2 gives a short overview of data annotation. Section 3 focuses on the task description. Section 4 describes the participant systems. Section 5 compares and analyzes the results. Finally, Section 6 concludes the paper. 2 Data Annotation 2.1 Corpus Section 10,068 sentences were selected from the Penn Chinese Treebank 6.01 (Xue et al., 2005) (1-121, 1001- 1078, 1100-1151) as the raw corpus from which to create the Chinese Semantic Dependency Parsing corpus. These sentences were chosen for the annotation for three reasons. First, gold syntactic dependency structures can be of great help in semantic dependency annotation, as syntactic dependency arcs are often consistent with semantic ones. Second, the semantic role labels in PropBank2 can be very useful in the present annotation work. Third, the gold word segmentation and Part-Of-Speech can be used as the annotation input in this work. 2.2 Semantic Relations The semantic relations</context>
</contexts>
<marker>Xue, Xia, Chiou, Palmer, 2005</marker>
<rawString>Nianwen Xue, Fei Xia, Fu-Dong Chiou, and Martha Palmer. 2005. The penn chinese treebank: Phrase structure annotation of a large corpus. Natural Language Engineering, 11(2):207–238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guoguang Zhou</author>
<author>Linlin Zhang</author>
</authors>
<title>The theory and method of modern Chinese grammar. Guangdong</title>
<date>2003</date>
<publisher>Higher Education Press.</publisher>
<contexts>
<context position="2847" citStr="Zhou and Zhang, 2003" startWordPosition="426" endWordPosition="429"> analyzes and summarizes all the possible semantic roles, obtaining over 100 of them, and then uses these semantic roles to specify the semantic relation for each word pair. Dependency parsing (K¨ubler et al., 2009) is based on dependency grammar. It has several advantages, such as concise formalization, easy comprehension, high efficiency, and so on. Dependency parsing has been studied intensively in recent decades, with most related work focusing on syntactic structure. Many research papers on Chinese linguistics demonstrate the remarkable difference between semantics and syntax (Jin, 2001; Zhou and Zhang, 2003). Chinese is a meaning-combined language with very flexible syntax, and semantics are more stable than syntax. The word is the basic unit of semantics, and the structure and meaning of a sentence consists mainly of a series of semantic dependencies between individual words (Li et al., 2003). Thus, a reasonable endeavor is to exploit dependency parsing for semantic analysis of Chinese languages. Figure 1 shows an example of Chinese semantic dependency parsing. 378 First Joint Conference on Lexical and Computational Semantics (*SEM), pages 378–384, Montr´eal, Canada, June 7-8, 2012. c�2012 Assoc</context>
</contexts>
<marker>Zhou, Zhang, 2003</marker>
<rawString>Guoguang Zhou and Linlin Zhang. 2003. The theory and method of modern Chinese grammar. Guangdong Higher Education Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>