<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000004">
<note confidence="0.3789695">
AUTOMATED DETERMINATION OF SUBLANGUAGE SYNTACTIC USAGE
Ralph Grisizman and Ngo Thanh Nhan
</note>
<title confidence="0.498488727272727">
Courant Institute of Mathematical Sciences
New York University
New York, NY 10012
Elaine Marsh
Navy Center for Applied Research in Artificial Intelligence
Naval Research Laboratory
Washington, DC 20375
Lynette Hirschman
Research and Development Division
System Development Corporation / A Burroughs Company
Paoli, PA 19301
</title>
<sectionHeader confidence="0.966031" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9986914">
Sublanguages differ from each other, and from the &amp;quot;stan-
dard language&amp;quot;, in their syntactic, semantic, and
discourse properties. Understanding these differences is
important if we are to improve our ability to process
these sublanguages. We have developed a semi-
automatic procedure for identifying sublanguage syntactic
usage from a sample of text in the sublanguage. We
describe the results of applying this procedure to three
text samples: two sets of medical documents and a set of
equipment failure messages.
</bodyText>
<sectionHeader confidence="0.953586" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.977056481481482">
A sublanguage is the form of natural language used
by a community of specialists in discussing a restricted
domain. Sublanguages differ from each other, and from
the &amp;quot;standard language&amp;quot;, in their syntactic, semantic, and
discourse properties. We describe here some recent
work on (semi-)automatically determining the syntactic
properties of several sublanguages. This work is part of
a larger effort aimed at improving the techniques for
parsing sublanguages.
If we examine a variety of scientific and technical
sublanguages, we will encounter most of the constructs of
the standard language, plus a number of syntactic exten-
sions. For example, &amp;quot;report&amp;quot; sublanguages, such as are
used in medical summaries and equipment failure sum-
maries, include both full sentences and a number of frag-
ment forms [Marsh 1983]. Specific sublanguages differ
in their usage of these syntactic constructs [Kittredge
1982, Lehrberger 1982].
Identifying these differences is important in under-
standing how sublanguages differ from the language as a
whole. It also has immediate practical benefits, since it
allows us to trim our grammar to fit the specific sub-
language we are processing. This can significantly speed
up the analysis process and block some spurious
which would be obtained with a grammar of overly parses
d
coverage.
</bodyText>
<subsectionHeader confidence="0.904017">
Determining Syntactic Usage
</subsectionHeader>
<bodyText confidence="0.999942195121951">
Unfortunately, acquiring the data about syntactic
usage can be very tedious, inasmuch as it requires the
analysis of hundreds (or even thousands) of sentences for
each new sublanguage to be processed. We have there-
fore chosen to automate this process.
We are fortunate to have available to us a very
broad coverage English grammar, the Linguistic String
Grammar [Sager 19811, which has been extended to
include the sentence fragments of certain medical and
equipment failure reports [Marsh 1983]. The grammar
consists of a context-free component augmented by
procedural restrictions which capture various syntactic
and sublanguage semantic constraints. The context-free
component is stated in terms of grammatical categories
such as noun, tensed verb, and adjective.
To begin the analysis process, a sample corpus is
parsed using this grammar. The file of generated parses
is reviewed manually to eliminate incorrect parses. The
remaining parses are then fed to a program which counts
-- for eadi parse tree and cumulatively for the entire file
-- the number of times that each production in the
context-free component of the grammar was applied in
building the tree. This yields a &amp;quot;trimmed&amp;quot; context-free
grammar for the sublanguage (consisting of those pro-
ductions used one or more times), along with frequency
information on the various productions.
This process was initially applied to text samples
from two sublanguages. The first is a set of six patient
documents (including patient history, examination, and
plan of treatment). The second is a set of electrical
equipment failure reports called &amp;quot;CASREPs&amp;quot;, a class of
operational report used by the U. S. Navy [Froscher
1983]. The parse file for the patient documents had
correct parses for 236 sentences (and sentence frag-
ments); the file for the CASREPs had correct parses for
123 sentences. We have recently applied the process to a
third text sample, drawn from a sublanguage very similar
to the first: a set of five hospital &amp;quot;discharge summaries&amp;quot;,
which include patient histories, examinations, and sum-
maries of the course of treatment in the hospital. This
last sample included correct parses for 310 sentences.
</bodyText>
<page confidence="0.979698">
96
</page>
<sectionHeader confidence="0.925343" genericHeader="evaluation">
Results
</sectionHeader>
<bodyText confidence="0.999754857142857">
The trimmed grammars produced from the three
sublanguage text samples were of comparable size. The
grammar produced from the first set of patient docu-
ments contained 129 non-terminal symbols and 248 pro-
ductions; the grammar from the second set (the
&amp;quot;discharge summaries&amp;quot;) was slightly larger, with 134
non-terminals and 282 productions. The grammar for the
CASREP sublanguage was slightly smaller, with 124
non-terminals and =0 productions (this is probably a
reflection of the smaller size of the CASREP text sam-
ple). These figures compare with 255 non-terminal sym-
bols and 744 productions in the &amp;quot;medical records&amp;quot; gram-
mar used by the New York University Linguistic String
Project (the &amp;quot;medical records&amp;quot; grammar is the Linguistic
String Project English Grammar with extensions for sen-
tence fragments and other, sublanguage specific, con-
structs, and with a few options deleted).
Figures 1 and 2 show the cumulative growth in the
size of the trimmed grammars for the three sublanguages
as a function of the number of sentences in the sample.
In Figure 1 we plot the number of non-terminal symbols
in the grammar as a function of sample size; in Figure 2,
the number of productions in the grammar as a function
of sample size. Note that the curves for the two medical
sublanguages (curves A and B) have pretty much flat-
tened out toward the end, indicating that, by that point,
the trimmed gamma covers a very large fraction of the
sentences in the sublanguage. (Some of the jumps in the
growth curves for the medical grammars reflect the divi-
sion of the patient documents into sections (history, phy-
sical exam, lab tests, etc.) with different syntactic charac-
teristics. For the first few documents, when a new sec-
tion begins, constructs are encountered which did not
appear in prior sections, thus producing a jump in the
curve.)
The sublanguage grammars are substantially smaller
than the full English grammar, reflecting the more lim-
ited range of modifiers and complements in these sub-
languages. While the full grammar has 67 options for
sentence object, the sublanguage grammars have substan-
tially restricted usages: each of the three sublanguage
grammars has only 14 object options. Further, the gram-
mars greatly overlap, so that the three grammars com-
bined contain only 20 different object options. While
sentential complements of nouns are available in the full
grammar, there are no instances of such constructions in
either medical sublanguage, and only one instance in the
CASREP sublanguage. The range of modifiers is also
much restricted in the sublanguage grammars as com-
pared to the full grammar. 15 options for sentential
modifiers are available in the full grammar. These are
restricted to 9 in the first medical sample, 11 in the
second, and 8 in the equipment failure sublanguage.Similarly, the full English grammar has 21 options for
right modifiers of nouns; the sublanguage grammars had
fewer, 11 in the first medical sample, 10 in the second,
and 7 in the CASREP sublanguage. Here the sub-
language grammars overlap almost completely: only 12
different right modifiers of noun are represented in the
three grammars combined.
Among the options occurring in all the sublanguage
grammars, their relative frequency varies accordmg to
the domain of the text. For example, the frequency of
prepositional phrases as right modifiers of nouns (meas-
ured as instances per sentence or sentence fragment) was
0.36 and 0.46 for the two medical sam .les, as compared
to 0.77 for the CASREPs. More s. • • was the fre-
quency of noun phrases with nouns as ....• Oen of other
nouns: 0.20 and 0.32 for the two medical samples,
versus 0.80 for the CASREPs.
We reparsed some of the sentences from the first set
of medical documents with the trimmed grammar and, as
expected, observed a considerable speed-up. The
Linguistic String Parser uses a top-down parsing algo-
rithm with backtracking. Accordingly, for short, simple
sentences which require little backtracking there was only
a small gain in processing speed (about 25%). For long,
complex sentences, however, which require extensive
backtracking, the speed-up (by roughly a factor of 3) was
approximately proportional to the reduction in the
number of productions. In addition, the frequency of
bad parses decreased slightly (by &lt;3%) with the
trimmed grammar (because some of the bad parses
involved syntactic constructs which did not appear in any
correct parse in the sublanguage sample).
</bodyText>
<sectionHeader confidence="0.991286" genericHeader="discussions">
Discussion
</sectionHeader>
<bodyText confidence="0.98804015">
As natural language interfaces become more
mature, their portability -- the ability to move an inter-
face to a new domain and sublanguage -- is becoming
increasingly important. At a minimum, portability
requires us to isolate the domain dependent information
in a natural language system &apos;Grosz 1983, Grishman
19831. A more ambitious goal is to provide a discovery
procedure for this information -- a procedure which can
determine the domain dependent information from sam-
ple texts in the sublanguage. The techniques described
above provide a partial, semi-automatic discovery pro-
cedure for the syntactic usages of a sublanguage.* By
applying these techniques to a small sublanguage sample,
we can adapt a broad-coverage grammar to the syntax of
a particular sublanguage. Subsequent text from this sub-
language can then be processed more efficiently.
We are currently extending this work in two direc-
tions. For sentences with two or more parses which
satisfy both the syntactic and the sublanguage selections&apos;
(semantic) constraints, we intend to try using the fre-
quency information gathered for productions to select a
parse. We shall determine whether there is a correlation
in these cases between the correct parse and the parse
involving the more frequent syntactic constructs.**
Second, we are using a similar approach to develop a
discovery procedure for sublanguage selectional patterns.
We are collecting, from the same sublanguage samples,
statistics on the frequency of co-occurrence of particular
sublanguage (semantic) classes in subject-verb-object and
host-adjunct relations, and are using this data as input to
• Partial, because it cannot identify new extensions
to the base grammar; semi-automatic, because the
parses produced with the broad-coverage grammar
must be manually reviewed.
4&apos; Some small experiments of this type have been
done with a Japanese grammar [Nagao 1982] with
limited success. Because of the very different na-
ture of the grammar, however, it is not clear
whether this has any implications for our experi-
ments.
</bodyText>
<page confidence="0.998066">
97
</page>
<note confidence="0.791422777777778">
the grammar&apos;s sublanguage selectional restrictions.
Acknowledgement
This material is based upon work supported by the
National Science Foundation under Grants No. MCS-82-
02373 and MCS-82-02397.
References
[Froscher 19831 Froscher, J.; Grishman, R.; Bachenko,
J.; Marsh, E. &amp;quot;A linguistically motivated approach to
automated analysis of military messages.&amp;quot; To appear in
</note>
<reference confidence="0.892866066666667">
Proc. 1983 Conf. on Artificial Intelligence, Rochester, MI,
April, 1983.
[Grishman 1983] Grishman, R.; Hirschman, L.; Fried-
man, C. &amp;quot;Isolating domain dependencies in natural
language interfaces.&amp;quot; Proc. Conf. Applied Natural
Language Processing, 46-53, Assn. for Computational
Linguistics, 1983.
[Grosz 1983] Grosz, B. &amp;quot;TEAM: a transportable
natural-language interface system.&amp;quot; Proc. Conf. Applied
Natural Language Processing, 39-45, Assn. for Computa-
tional Linguistics, 1983.
[Kittredge 1982] Kittredge, R. &amp;quot;Variation and homo-
geneity of sublanguages. In Sublanguage: studies of
language in restricted semantic domains, ed. R. Kittredge
and J. Lehrberger. Berlin &amp; New York: Walter de
Gruyter; 1982.
[Lehrberger 1982] Lehrberger, J. &amp;quot;Automatic transla-
tion and the concept of sublanguage.&amp;quot; In Sublanguage:
studies of language in restricted semantic domains, ed. R.
Kittredge and J. Lehrberger. Berlin &amp; New York:
Walter de Gruyter; 1982.
[Marsh 1983] Marsh, E. &amp;quot;Utilizing domain-specific
information for processing compact text.&amp;quot; Proc. Conf.
Applied Natural Language Processing, 99-103, Assn. for
Computational Linguistics, 1983.
[Nagao 19821 Nagao, M.; Nakamura, J. &amp;quot;A parser
which learns the application order of rewriting rules.&amp;quot;
Proc. COLING 82, 253-258.
[Sager 19811 Sager, N. Natural Language Information Pro-
cessing. Reading, MA: Addison-Wesley; 1981.
</reference>
<page confidence="0.992927">
98
</page>
<figure confidence="0.979648105263158">
SENTENCES VS. NON-TERMINAL SYMBOLS
A:
....
130
120
110
100
0
70
60
50
40
30 0
140
20 40 60 60 100 120 140 160 1130 200 220 240
IC
SENTENCES VS. NON-TERMINRL SYMBOLS
....... • ..... 1 • 1 • 1 • .......
130
</figure>
<figureCaption confidence="0.574131">
Figure 1. Growth in the size of the grammar
as a function of the size of the text sample. X
= the number of sentences (and sentence frag-
ments) in the text sample; Y = the number of
non-terminal symbols in the context-free com-
ponent of the grammar
</figureCaption>
<figure confidence="0.953544594594595">
Graph A: first set of patient documents
Graph B: second set of patient documents
(&amp;quot;discharge summaries&amp;quot;)
Graph C: equipment failure messages
120
110
100
60
70
B
50
0 20 40 60 50 100 120 140 160 160 200 220 240 250 200 300 320
X
SENTENCES VS. NON-TERMINAL SYMBOLS
-
c
60 90 100 110 120 130
99
280 VS. PRODUCTIONS
240
220
200
180
180
140
/20
100
ea
ea
40 0 20 40 80 60 100 120 140 160 160 200 220 240
X
SENTENCES VS. PRODUCTIONS
300
100
SO
SO
0
</figure>
<figureCaption confidence="0.999122">
Figure 2. Growth in the size of the grammar
</figureCaption>
<bodyText confidence="0.5599134">
as a function of the size of the text sample. X
= the number of sentences (and sentence frag-
ments) in the text sample; Y=-- the number of
productions in the context-free component of
the grammar
</bodyText>
<figure confidence="0.98428478125">
Graph A: fust set of patient documents
Graph B: second set of patient documents
(&amp;quot;discharge summaries&amp;quot;)
Graph C: eq.WEPuipment s failure messages
(&amp;quot;C failure messages
B
SENTENCES VS. PRODUCTIONS
• 1 ....... ..
/
11111•111/1.11111 I I •
10 20 30 10 50 80 70 60 90 100 110 120 130
X
260
280-
240
220
200 -
-
180
160
140
120
180
ISO
140
I.. 120
100
60
80
4
20 40 60 BO 100 120 140 150 150 200 220 240 zaa 250 300 320
X
</figure>
<page confidence="0.650684">
100
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.586893">
<title confidence="0.996413">AUTOMATED DETERMINATION OF SUBLANGUAGE SYNTACTIC USAGE</title>
<author confidence="0.999062">Ralph Grisizman</author>
<author confidence="0.999062">Ngo Thanh Nhan</author>
<affiliation confidence="0.9787985">Courant Institute of Mathematical Sciences New York University</affiliation>
<address confidence="0.998931">New York, NY 10012</address>
<author confidence="0.671218">Elaine Marsh</author>
<affiliation confidence="0.9961305">Navy Center for Applied Research in Artificial Intelligence Naval Research Laboratory</affiliation>
<address confidence="0.990953">Washington, DC 20375</address>
<author confidence="0.995736">Lynette Hirschman</author>
<affiliation confidence="0.961224">Research and Development Division System Development Corporation / A Burroughs Company</affiliation>
<address confidence="0.99827">Paoli, PA 19301</address>
<abstract confidence="0.999728818181818">Sublanguages differ from each other, and from the &amp;quot;standard language&amp;quot;, in their syntactic, semantic, and discourse properties. Understanding these differences is important if we are to improve our ability to process these sublanguages. We have developed a semiautomatic procedure for identifying sublanguage syntactic usage from a sample of text in the sublanguage. We describe the results of applying this procedure to three text samples: two sets of medical documents and a set of equipment failure messages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Proc</author>
</authors>
<date>1983</date>
<booktitle>Conf. on Artificial Intelligence,</booktitle>
<location>Rochester, MI,</location>
<marker>Proc, 1983</marker>
<rawString> Proc. 1983 Conf. on Artificial Intelligence, Rochester, MI, April, 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Grishman</author>
<author>L Hirschman</author>
<author>C Friedman</author>
</authors>
<title>Isolating domain dependencies in natural language interfaces.&amp;quot;</title>
<date>1983</date>
<booktitle>Proc. Conf. Applied Natural Language Processing, 46-53, Assn. for Computational Linguistics,</booktitle>
<marker>[Grishman 1983]</marker>
<rawString>Grishman, R.; Hirschman, L.; Friedman, C. &amp;quot;Isolating domain dependencies in natural language interfaces.&amp;quot; Proc. Conf. Applied Natural Language Processing, 46-53, Assn. for Computational Linguistics, 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Grosz</author>
</authors>
<title>TEAM: a transportable natural-language interface system.&amp;quot;</title>
<date>1983</date>
<booktitle>Proc. Conf. Applied Natural Language Processing, 39-45, Assn. for Computational Linguistics,</booktitle>
<marker>[Grosz 1983]</marker>
<rawString>Grosz, B. &amp;quot;TEAM: a transportable natural-language interface system.&amp;quot; Proc. Conf. Applied Natural Language Processing, 39-45, Assn. for Computational Linguistics, 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Kittredge</author>
</authors>
<title>Variation and homogeneity of sublanguages. In Sublanguage: studies of language in restricted semantic domains,</title>
<date>1982</date>
<editor>ed. R. Kittredge and J. Lehrberger. Berlin &amp; New York: Walter de Gruyter;</editor>
<marker>[Kittredge 1982]</marker>
<rawString>Kittredge, R. &amp;quot;Variation and homogeneity of sublanguages. In Sublanguage: studies of language in restricted semantic domains, ed. R. Kittredge and J. Lehrberger. Berlin &amp; New York: Walter de Gruyter; 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lehrberger</author>
</authors>
<title>Automatic translation and the concept of sublanguage.&amp;quot; In Sublanguage: studies of language in restricted semantic domains,</title>
<date>1982</date>
<editor>ed. R. Kittredge and J. Lehrberger. Berlin &amp; New York: Walter de Gruyter;</editor>
<marker>[Lehrberger 1982]</marker>
<rawString>Lehrberger, J. &amp;quot;Automatic translation and the concept of sublanguage.&amp;quot; In Sublanguage: studies of language in restricted semantic domains, ed. R. Kittredge and J. Lehrberger. Berlin &amp; New York: Walter de Gruyter; 1982.</rawString>
</citation>
<citation valid="false">
<authors>
<author>E Marsh</author>
</authors>
<title>Utilizing domain-specific information for processing compact text.&amp;quot;</title>
<date>1983</date>
<journal>Nagao</journal>
<booktitle>Proc. Conf. Applied Natural Language Processing, 99-103, Assn. for Computational Linguistics,</booktitle>
<volume>19821</volume>
<pages>253--258</pages>
<publisher>Addison-Wesley;</publisher>
<location>Reading, MA:</location>
<marker>[Marsh 1983]</marker>
<rawString>Marsh, E. &amp;quot;Utilizing domain-specific information for processing compact text.&amp;quot; Proc. Conf. Applied Natural Language Processing, 99-103, Assn. for Computational Linguistics, 1983. [Nagao 19821 Nagao, M.; Nakamura, J. &amp;quot;A parser which learns the application order of rewriting rules.&amp;quot; Proc. COLING 82, 253-258. [Sager 19811 Sager, N. Natural Language Information Processing. Reading, MA: Addison-Wesley; 1981.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>