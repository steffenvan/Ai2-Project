<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.018994">
<title confidence="0.999247">
Anchor-Progression in Spatially Situated Discourse:
a Production Experiment
</title>
<author confidence="0.984648">
Hendrik Zender and Christopher Koppermann and Fai Greeve and Geert-Jan M. Kruijff
</author>
<affiliation confidence="0.849292">
Language Technology Lab
German Research Center for Artificial Intelligence (DFKI)
</affiliation>
<address confidence="0.601817">
Saarbr¨ucken, Germany
</address>
<email confidence="0.995127">
zender@dfki.de
</email>
<sectionHeader confidence="0.993808" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999818833333333">
The paper presents two models for produc-
ing and understanding situationally appro-
priate referring expressions (REs) during
a discourse about large-scale space. The
models are evaluated against an empirical
production experiment.
</bodyText>
<sectionHeader confidence="0.972558" genericHeader="categories and subject descriptors">
1 Introduction and Background
</sectionHeader>
<bodyText confidence="0.99994725">
For situated interaction, an intelligent system
needs methods for relating entities in the world,
its representation of the world, and the natural lan-
guage references exchanged with its user. Hu-
man natural language processing and algorithmic
approaches alike have been extensively studied
for application domains restricted to small visual
scenes and other small-scale surroundings. Still,
rather little research has addressed the specific is-
sues involved in establishing reference to entities
outside the currently visible scene. The challenge
that we address here is how the focus of attention
can shift over the course of a discourse if the do-
main is larger than the currently visible scene.
The generation of referring expressions (GRE)
has been viewed as an isolated problem, focussing
on efficient algorithms for determining which in-
formation from the domain must be incorporated
in a noun phrase (NP) such that this NP allows
the hearer to optimally understand which referent
is meant. The domains of such approaches usu-
ally consist of small, static domains or simple vi-
sual scenes. In their seminal work Dale and Reiter
(1995) present the Incremental Algorithm (IA) for
GRE. Recent extensions address some of its short-
comings, such as negated and disjoined properties
(van Deemter, 2002) and an account of salience for
generating contextually appropriate shorter REs
(Krahmer and Theune, 2002). Other, alternative
GRE algorithms exist (Horacek, 1997; Bateman,
1999; Krahmer et al., 2003). However, all these al-
gorithms rely on a given domain of discourse con-
stituting the current context (or focus of attention).
The task of the GRE algorithm is then to single out
the intended referent against the other members of
the context, which act as potential distractors. As
long as the domains are such closed-context sce-
narios, the intended referent is always in the cur-
rent focus. We address the challenge of producing
and understanding of references to entities that are
outside the current focus of attention, because they
have not been mentioned yet and are beyond the
currently observable scene.
Our approach relies on the dichotomy between
small-scale space and large-scale space for hu-
man spatial cognition. Large-scale space is “a
space which cannot be perceived at once; its global
structure must be derived from local observations
over time” (Kuipers, 1977). In everyday situa-
tions, an office environment, one’s house, or a uni-
versity campus are large-scale spaces. A table-top
or a part of an office are examples of small-scale
space. Despite large-scale space being not fully
observable, people can nevertheless have a rea-
sonably complete mental representation of, e.g.,
their domestic or work environments in their cog-
nitive maps. Details might be missing, and peo-
ple might be uncertain about particular things and
states of affairs that are known to change fre-
quently. Still, people regularly engage in a con-
versation about such an environment, making suc-
cessful references to spatially located entities.
It is generally assumed that humans adopt a par-
tially hierarchical representation of spatial orga-
nization (Stevens and Coupe, 1978; McNamara,
1986). The basic units of such a representation
are topological regions (i.e., more or less clearly
bounded spatial areas) (Hirtle and Jonides, 1985).
Paraboni et al. (2007) are among the few to ad-
dress the issue of generating references to entities
outside the immediate environment, and present
an algorithm for context determination in hierar-
</bodyText>
<figure confidence="0.8099255">
(a) Example for a hierarchical representation of space.
(b) Illustration of the TA principle: starting from the atten-
tional anchor (a), the smallest sub-hierarchy containing both
a and the intended referent (r) is formed incrementally.
</figure>
<figureCaption confidence="0.99991">
Figure 1: TA in a spatial hierarchy.
</figureCaption>
<bodyText confidence="0.99996808">
chically ordered domains. However, since it is
mainly targeted at producing textual references to
entities in written documents (e.g., figures and ta-
bles in book chapters), they do not address the
challenges of physical and perceptual situated-
ness. Large-scale space can be viewed as a hier-
archically ordered domain. To keep track of the
referential context in such a domain, in our previ-
ous work we propose the principle of topological
abstraction (TA, summarized in Fig. 1) for context
extension (Zender et al., 2009a), similar to Ances-
tral Search (Paraboni et al., 2007). In (Zender et
al., 2009b), we describe the integration of the ap-
proach in an NLP system for situated human-robot
dialogues and present two algorithms instantiating
the TA principle for GRE and resolving referring
expressions (RRE), respectively. It relies on two
parameters: the location of the intended referent
r, and the attentional anchor a. As discussed in
our previous works, for single utterances the an-
chor is the physical position where it is made (i.e.,
the utterance situation (Devlin, 2006)). Below, we
propose models for attentional anchor-progression
for longer discourses about large-scale space, and
evaluate them against real-world data.
</bodyText>
<sectionHeader confidence="0.984789" genericHeader="method">
2 The Models
</sectionHeader>
<bodyText confidence="0.999937125">
In order to account for the determination of the
attentional anchor a, we propose a model called
anchor-progression A. The model assumes that
each exophoric reference1 serves as attentional
anchor for the subsequent reference. It is based
on observations on “principles for anchoring re-
source situations” by Poesio (1993), where the ex-
pression of movement in the domain determines
</bodyText>
<footnote confidence="0.493444">
1This excludes pronouns as well as other descriptions that
pick up an existing referent from the linguistic context.
</footnote>
<bodyText confidence="0.999981777777778">
the updated current mutual focus of attention. a
and r are then passed to the TA algorithm. Taking
into account the verbal behavior observed in our
experiment, we also propose a refined model of
anchor-resetting R, where for each new turn (e.g.,
a new instruction), the anchor is re-set to the utter-
ance situation. R leads to the inclusion of naviga-
tional information for each first RE in a turn, thus
reassuring the hearer of the focus of attention.
</bodyText>
<sectionHeader confidence="0.985391" genericHeader="method">
3 The Experiment
</sectionHeader>
<bodyText confidence="0.998924475">
We are interested in the way the disambiguation
strategies change when producing REs during a
discourse about large-scale space versus discourse
about small-scale space. In our experiment, we
gathered a corpus of spoken instructions in two
different situations: small-scale space (SSS) and
large-scale space (LSS). We use the data to evalu-
ate the utility of the A and R models. We specifi-
cally evaluate them against the traditional (global)
model G in which the indented referent must be
singled out from all entities in the domain.
The cover story for the experiment was to
record spoken instructions to help improve a
speech recognition system for robots. The partici-
pants were asked to imagine an intelligent service
robot capable of understanding natural language
and familiar with its environment. The task of the
participants was to instruct the robot to clean up
a working space, i.e., a table-top (SSS) and an in-
door environment (LSS) by placing target objects
(cookies or balls) in boxes of the same color. The
use of color terms to identify objects was discour-
aged by telling the participants that the robot is un-
able to perceive color. The stimuli consisted of 8
corresponding scenes of the table-top and the do-
mestic setting (cf. Fig. 2). In order to preclude the
specific phenomena of collaborative, task-oriented
dialogue (cf., e.g., (Garrod and Pickering, 2004)),
the participants had to instruct an imaginary recip-
ient of orders. The choice of a robot was made to
rule out potential social implications when imag-
ining, e.g., talking to a child, a butler, or a friend.
The SSS scenes show a bird’s-eye view of the
table including the robot’s position (similar to (Fu-
nakoshi et al., 2004)). The way the objects are ar-
ranged allows to refer to their location with respect
to the corners of the table, with plates as additional
landmarks. The LSS scenes depict an indoor envi-
ronment with a corridor and, parallel to SSS, four
rooms with tables as landmarks. The scenes show
</bodyText>
<figure confidence="0.5344235">
old campus
new campus
building 1A ... building 3B building 2C building 3B ...
floor1 ... floor2
floor1 floor2
floor1
office1 ... office4
office1 kitchen ... office2 office5 helpdesk office3
</figure>
<tableCaption confidence="0.995559">
Table 1: Example from the small-scale (1–2) and large-scale space (3–4) scenes in Fig. 2.
</tableCaption>
<listItem confidence="0.901963444444444">
1. nimm [das pl¨atzchen unten links]mG,A , leg es [in die schachtel unten rechts auf dem teller]oG,A
‘take the cookie on the bottom left, put it into the bottom right box on the plate’
2. nimm [das pl¨atzchen unten rechts]mG,oA , leg es [in die schachtel oben links auf dem teller]mG,A
‘take the cookie on the bottom right, put it into the top left box on the plate’
3. geh [ins wohnzimmer]mG,A,R und nimm [den ball]uG,mA,R und bring ihn [ins arbeitszimmer]mG,A,R , leg ihn [in die
kiste auf dem tisch]uG,oA,R
‘go to the living room and take the ball and bring it to the study; put it into the box on the table’
4. und nimm [den ball]uG,R,mA und bring ihn [in die k¨uche]mG,A,R und leg ihn [in die kiste auf dem boden]uG,mA,R
‘and take the ball and bring it to the kitchen and put it into the box on the floor’
</listItem>
<figure confidence="0.8945655">
NbM1�Lmme. W
KuM1e M6eimimme.
(a) Small-scale space: squares represent small boxes, (b) Large-scale space: squares represent boxes placed on the
stars cookies, and white circles plates. floor or on a table, circles represent balls, rooms are labeled.
</figure>
<figureCaption confidence="0.999709">
Figure 2: Two stimuli scenes from the experiment.
</figureCaption>
<bodyText confidence="0.999849680851064">
the robot and the participant in the corridor.
In order to gather more comparable data we
opted for a within-participants approach. Each
person participated in the SSS treatment and in the
LSS treatment. To counterbalance potential carry-
over effects, half of the participants were shown
the treatments in inverse order, and the sequence
of the 8 scenes in each treatment was varied in a
principled way. In order to make the participants
produce multi-utterance discourses, they were re-
quired to refer to all target object pairs. The exact
wording of their instructions was up to them.
Participants were placed in front of a screen and
a microphone into which they spoke their orders
to the imaginary robot, followed by a self-paced
keyword after which the experimenter showed the
next scene. The experiment was conducted in Ger-
man and consisted of a pilot study (10 partici-
pants) and the main part (19 female and 14 male
students, aged 19–53, German native speakers).
The data of three participants who did not behave
according to the instructions was discarded. The
individual sessions took 20–35 min., and the par-
ticipants were paid for their efforts.
Using the UAM CorpusTool software, tran-
scriptions of the recorded spoken instructions
were annotated for occurrences of the linguistic
phenomenon we are interested in, i.e., REs. Sam-
ples were cross-checked by a second annotator.
REs were marked as shallow ‘refex’ segments,
i.e., complex NPs were not decomposed into their
constituents. Only definite NPs representing ex-
ophoric REs (cf. Sec. 2) qualify as ‘refex’ seg-
ments. If a turn contained an indefinite NP, the
whole turn was discarded. The ‘refex’ segments
were coded according to the amount of informa-
tion they contain, and under which disambigua-
tion model M ∈ {G, A, R} (R only for LSS)
they succeed in singling out the described refer-
ent. Following Engelhardt et al. (2006), we dis-
tinguish three types of semantic specificity. A RE
is an over-description with respect to M (overm)
if it contains redundant information, and it is an
under-description (underm) if it is ambiguous ac-
cording to M. Minimal descriptions (mints) con-
tain just enough information to uniquely identify
the referent. Table 1 shows annotated examples.
</bodyText>
<sectionHeader confidence="0.999974" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.9922355">
The collected corpus consists of 30 annotated ses-
sions with 2 treatments comprising 8 scenes with
4 turns. In total, it contains 4,589 annotated REs,
out of which only 83 are errors. Except for the
error rate calculation, we only consider non-error
‘refex’ segments as the universe. The SSS treat-
</bodyText>
<tableCaption confidence="0.942171">
Table 2: Mean frequencies (with standard deviation in italics) of minimal (min), over-descriptions
(over), and under-descriptions (under) with respect to the models (A, R, G) in both treatments.
</tableCaption>
<table confidence="0.941704">
overG overA overR minG minA minR underG underA underR
small-scale 13.94% 34.45% 78.90% 60.11% 7.16% 5.43%
space 15.85% 14.37% 17.66% 13.13% 12.07% 10.50%
large-scale 6.81% 34.75% 20.06 % 68.04% 64.55% 76.73% 25.16% 0.69% 3.21%
space 7.53% 12.13% 10.10% 17.87% 13.13% 10.66% 19.48% 1.72% 5.06%
</table>
<bodyText confidence="0.999927434782609">
ment contains 1,902 ‘refex’, with a mean number
of 63.4 and a std. dev. Q=1.98 per participant. This
corresponds to the expected number of 64 REs to
be uttered: 8 scenes × 4 target object pairs. The
LSS treatment contains 2,604 ‘refex’ with an aver-
age of 86.8 correct REs (Q=18.19) per participant.
As can be seen in Table 1 (3–4), this difference
is due to the participants’ referring to intermediate
waypoints in addition to the target objects. Table 2
summarizes the analysis of the annotated data.
Overall, the participants had no difficulties with
the experiment. The mean error rates are low in
both treatments: 1.78% (Q=3.36%) in SSS, and
1.80% (Q=2.98%) in LSS. A paired sample t-
test of both scores for each participant shows that
there is no significant difference between the error
rates in the treatments (p=0.985), supporting the
claim that both treatments were of equal difficulty.
Moreover, a MANOVA shows no significant effect
of treatment-order for the verbal behavior under
study, ruling out potential carry-over effects.
Production experiments always exhibit a con-
siderable variation between participants. When
modeling natural language processing systems,
one needs to take this into account. A GRE com-
ponent should produce REs that are easy to un-
derstand, i.e., ambiguities should be avoided and
over-descriptions should occur sparingly. A GRE
algorithm will always try to produce minimal de-
scriptions. The generation of an under-description
means a failure to construct an identifying RE,
while over-descriptions are usually the result of
a globally ‘bad’ incremental construction of the
generated REs (as is the case, e.g., in the IA). An
RRE component, on the other hand, should be able
to identify as many referents as possible by treat-
ing as few as possible REs as under-descriptions.
The analysis of the SSS data with respect to
G establishes the baseline for a comparison with
other experiments and GRE approaches. 13.9% of
the REs contain redundant information (overG),
compared to 21% in (Viethen and Dale, 2006). In
contrast, however, our SSS scenes did not provide
the possibility for producing more-than-minimal
REs for every target object, which might account
for the difference. underG REs occur with a fre-
quency of 7.2% in the SSS data. Because under-
descriptions result in the the hearer being unable to
reliably resolve the reference, this means that the
robot in our experiment cannot fulfill its task. This
might explain the difference to the 16% observed
in the task-independent study by Viethen and Dale
(2006). The significantly (p&lt;0.001) higher mean
frequency of minG than minA underpins that G
is an accurate model for the verbal behavior in
SSS. However, G does not fit the LSS data well.
An RRE algorithm with model G would fail to
resolve the intended referent in 1 out of 4 cases
(cf. underG in LSS). With only 0.7% underA
REs on average, A models the LSS data signifi-
cantly better (p&lt;0.001). Still, there is is a high
rate of overA REs. In comparison, R yields a
significantly (p&lt;0.001) lower amount of overR.
The mean frequency of underR is significantly
(p=0.010) higher than for underA, but still below
underG in the SSS data. With a mean frequency
of 76.7% minR, R models the data better than
both G and A. For the REs in LSS minR is in
the same range as minG for the REs in SSS.
</bodyText>
<sectionHeader confidence="0.999567" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999983">
Overall, the data exhibit a high mean frequency of
over-descriptions. However, since this means that
the human-produced REs contain more informa-
tion than minimally necessary, this does not nega-
tively affect the performance of an RRE algorithm.
For a GRE algorithm, however, a more cautious
approach might be desirable. In situated discourse
about LSS, we thus suggest that A is suitable for
the RRE task because it yields the least amount
of unresolvable under-descriptions. For the GRE
task R is more appropriate. It strikes a balance
between producing short descriptions and supple-
menting navigational information.
</bodyText>
<sectionHeader confidence="0.998622" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99925">
This work was supported by the EU Project CogX
(FP7-ICT-215181). Thanks to Mick O’Donnell
for his support with the UAM CorpusTool.
</bodyText>
<sectionHeader confidence="0.990205" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9994728">
John A. Bateman. 1999. Using aggregation for select-
ing content when generating referring expressions.
In Proceedings of the 37th annual meeting of the As-
sociation for Computational Linguistics on Compu-
tational Linguistics (ACL’99), pages 127–134, Mor-
ristown, NJ, USA.
Robert Dale and Ehud Reiter. 1995. Computational
interpretations of the Gricean Maxims in the gener-
ation of referring expressions. Cognitive Science,
19(2):233–263.
Keith Devlin. 2006. Situation theory and situation se-
mantics. In Dov M. Gabbay and John Woods, edi-
tors, Logic and the Modalities in the Twentieth Cen-
tury, volume 7 of Handbook of the History of Logic,
pages 601–664. Elsevier.
Paul E. Engelhardt, Karl G.D. Bailey, and Fernanda
Ferreira. 2006. Do speakers and listeners observe
the Gricean Maxim of Quantity? Journal of Mem-
ory and Language, 54(4):554–573.
Kotaro Funakoshi, Satoru Watanabe, Naoko Kuriyama,
and Takenobu Tokunaga. 2004. Generation of
relative referring expressions based on perceptual
grouping. In COLING ’04: Proceedings of the 20th
international conference on Computational Linguis-
tics, Morristown, NJ, USA.
Simon Garrod and Martin J. Pickering. 2004. Why is
conversation so easy? Trends in Cognitive Sciences,
8(1):8–11, January.
Stephen C. Hirtle and John Jonides. 1985. Evidence
for hierarchies in cognitive maps. Memory and Cog-
nition, 13:208–217.
Helmut Horacek. 1997. An algorithm for generating
referential descriptions with flexible interfaces. In
Proceedings of the 35th Annual Meeting of the As-
sociation for Computational Linguistics and Eighth
Conference of the European Chapter of the Associa-
tion for Computational Linguistics (ACL-97), pages
206–213, Morristown, NJ, USA.
Emiel Krahmer and Mari¨et Theune. 2002. Effi-
cient context-sensitive generation of referring ex-
pressions. In Kees van Deemter and R. Kibble, ed-
itors, Information Sharing: Givenness and Newness
in Language Processing, pages 223–264. CSLI Pub-
lications, Stanford, CA, USA.
Emiel Krahmer, Sebastiaan van Erk, and Andr´e Verleg.
2003. Graph-based generation of referring expres-
sions. Computational Linguistics, 29(1):53–72.
Benjamin Kuipers. 1977. Representing Knowledge of
Large-scale Space. PhD thesis, MIT-AI TR-418,
Massachusetts Institute of Technology, Cambridge,
MA, USA, May.
Timothy P. McNamara. 1986. Mental representations
of spatial relations. Cognitive Psychology, 18:87–
121.
Ivandr´e Paraboni, Kees van Deemter, and Judith Mas-
thoff. 2007. Generating referring expressions:
Making referents easy to identify. Computational
Linguistics, 33(2):229–254, June.
Massimo Poesio. 1993. A situation-theoretic formal-
ization of definite description interpretation in plan
elaboration dialogues. In Peter Aczel, David Israel,
Yasuhiro Katagiri, and Stanley Peters, editors, Sit-
uation Theory and its Applications Volume 3, CSLI
Lecture Notes No. 37, pages 339–374. Center for the
Study of Language and Information, Menlo Park,
CA, USA.
Albert Stevens and Patty Coupe. 1978. Distortions
in judged spatial relations. Cognitive Psychology,
10:422–437.
Kees van Deemter. 2002. Generating referring expres-
sions: boolean extensions of the incremental algo-
rithm. Computational Linguistics, 28(1):37–52.
Jette Viethen and Robert Dale. 2006. Algorithms
for generating referring expressions: Do they do
what people do? In Proceedings of the 4th Inter-
national Natural Language Generation Conference
(INLG 2006), pages 63–70, Sydney, Australia.
Hendrik Zender, Geert-Jan M. Kruijff, and Ivana
Kruijff-Korbayov´a. 2009a. A situated context
model for resolution and generation of referring ex-
pressions. In Proceedings of the 12th European
Workshop on Natural Language Generation (ENLG
2009), pages 126–129, Athens, Greece, March.
Hendrik Zender, Geert-Jan M. Kruijff, and Ivana
Kruijff-Korbayov´a. 2009b. Situated resolution
and generation of spatial referring expressions for
robotic assistants. In Proceedings of the Twenty-
First International Joint Conference on Artificial In-
telligence (IJCAI-09), pages 1604–1609, Pasadena,
CA, USA, July.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.325601">
<title confidence="0.966386">Anchor-Progression in Spatially Situated a Production Experiment</title>
<author confidence="0.696889">Zender Koppermann Greeve M</author>
<affiliation confidence="0.7305605">Language Technology German Research Center for Artificial Intelligence</affiliation>
<address confidence="0.413134">Saarbr¨ucken,</address>
<email confidence="0.992514">zender@dfki.de</email>
<abstract confidence="0.997878142857143">The paper presents two models for producing and understanding situationally appropriate referring expressions (REs) during a discourse about large-scale space. The models are evaluated against an empirical production experiment.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>John A Bateman</author>
</authors>
<title>Using aggregation for selecting content when generating referring expressions.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics (ACL’99),</booktitle>
<pages>127--134</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="2017" citStr="Bateman, 1999" startWordPosition="293" endWordPosition="294">omain must be incorporated in a noun phrase (NP) such that this NP allows the hearer to optimally understand which referent is meant. The domains of such approaches usually consist of small, static domains or simple visual scenes. In their seminal work Dale and Reiter (1995) present the Incremental Algorithm (IA) for GRE. Recent extensions address some of its shortcomings, such as negated and disjoined properties (van Deemter, 2002) and an account of salience for generating contextually appropriate shorter REs (Krahmer and Theune, 2002). Other, alternative GRE algorithms exist (Horacek, 1997; Bateman, 1999; Krahmer et al., 2003). However, all these algorithms rely on a given domain of discourse constituting the current context (or focus of attention). The task of the GRE algorithm is then to single out the intended referent against the other members of the context, which act as potential distractors. As long as the domains are such closed-context scenarios, the intended referent is always in the current focus. We address the challenge of producing and understanding of references to entities that are outside the current focus of attention, because they have not been mentioned yet and are beyond </context>
</contexts>
<marker>Bateman, 1999</marker>
<rawString>John A. Bateman. 1999. Using aggregation for selecting content when generating referring expressions. In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics (ACL’99), pages 127–134, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Dale</author>
<author>Ehud Reiter</author>
</authors>
<title>Computational interpretations of the Gricean Maxims in the generation of referring expressions.</title>
<date>1995</date>
<journal>Cognitive Science,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="1679" citStr="Dale and Reiter (1995)" startWordPosition="243" endWordPosition="246">tly visible scene. The challenge that we address here is how the focus of attention can shift over the course of a discourse if the domain is larger than the currently visible scene. The generation of referring expressions (GRE) has been viewed as an isolated problem, focussing on efficient algorithms for determining which information from the domain must be incorporated in a noun phrase (NP) such that this NP allows the hearer to optimally understand which referent is meant. The domains of such approaches usually consist of small, static domains or simple visual scenes. In their seminal work Dale and Reiter (1995) present the Incremental Algorithm (IA) for GRE. Recent extensions address some of its shortcomings, such as negated and disjoined properties (van Deemter, 2002) and an account of salience for generating contextually appropriate shorter REs (Krahmer and Theune, 2002). Other, alternative GRE algorithms exist (Horacek, 1997; Bateman, 1999; Krahmer et al., 2003). However, all these algorithms rely on a given domain of discourse constituting the current context (or focus of attention). The task of the GRE algorithm is then to single out the intended referent against the other members of the contex</context>
</contexts>
<marker>Dale, Reiter, 1995</marker>
<rawString>Robert Dale and Ehud Reiter. 1995. Computational interpretations of the Gricean Maxims in the generation of referring expressions. Cognitive Science, 19(2):233–263.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keith Devlin</author>
</authors>
<title>Situation theory and situation semantics.</title>
<date>2006</date>
<booktitle>Logic and the Modalities in the Twentieth Century,</booktitle>
<volume>7</volume>
<pages>601--664</pages>
<editor>In Dov M. Gabbay and John Woods, editors,</editor>
<publisher>Elsevier.</publisher>
<contexts>
<context position="5404" citStr="Devlin, 2006" startWordPosition="832" endWordPosition="833"> in Fig. 1) for context extension (Zender et al., 2009a), similar to Ancestral Search (Paraboni et al., 2007). In (Zender et al., 2009b), we describe the integration of the approach in an NLP system for situated human-robot dialogues and present two algorithms instantiating the TA principle for GRE and resolving referring expressions (RRE), respectively. It relies on two parameters: the location of the intended referent r, and the attentional anchor a. As discussed in our previous works, for single utterances the anchor is the physical position where it is made (i.e., the utterance situation (Devlin, 2006)). Below, we propose models for attentional anchor-progression for longer discourses about large-scale space, and evaluate them against real-world data. 2 The Models In order to account for the determination of the attentional anchor a, we propose a model called anchor-progression A. The model assumes that each exophoric reference1 serves as attentional anchor for the subsequent reference. It is based on observations on “principles for anchoring resource situations” by Poesio (1993), where the expression of movement in the domain determines 1This excludes pronouns as well as other descriptions</context>
</contexts>
<marker>Devlin, 2006</marker>
<rawString>Keith Devlin. 2006. Situation theory and situation semantics. In Dov M. Gabbay and John Woods, editors, Logic and the Modalities in the Twentieth Century, volume 7 of Handbook of the History of Logic, pages 601–664. Elsevier.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul E Engelhardt</author>
<author>Karl G D Bailey</author>
<author>Fernanda Ferreira</author>
</authors>
<title>Do speakers and listeners observe the Gricean Maxim of Quantity?</title>
<date>2006</date>
<journal>Journal of Memory and Language,</journal>
<volume>54</volume>
<issue>4</issue>
<contexts>
<context position="11800" citStr="Engelhardt et al. (2006)" startWordPosition="1897" endWordPosition="1900">urrences of the linguistic phenomenon we are interested in, i.e., REs. Samples were cross-checked by a second annotator. REs were marked as shallow ‘refex’ segments, i.e., complex NPs were not decomposed into their constituents. Only definite NPs representing exophoric REs (cf. Sec. 2) qualify as ‘refex’ segments. If a turn contained an indefinite NP, the whole turn was discarded. The ‘refex’ segments were coded according to the amount of information they contain, and under which disambiguation model M ∈ {G, A, R} (R only for LSS) they succeed in singling out the described referent. Following Engelhardt et al. (2006), we distinguish three types of semantic specificity. A RE is an over-description with respect to M (overm) if it contains redundant information, and it is an under-description (underm) if it is ambiguous according to M. Minimal descriptions (mints) contain just enough information to uniquely identify the referent. Table 1 shows annotated examples. 4 Results The collected corpus consists of 30 annotated sessions with 2 treatments comprising 8 scenes with 4 turns. In total, it contains 4,589 annotated REs, out of which only 83 are errors. Except for the error rate calculation, we only consider </context>
</contexts>
<marker>Engelhardt, Bailey, Ferreira, 2006</marker>
<rawString>Paul E. Engelhardt, Karl G.D. Bailey, and Fernanda Ferreira. 2006. Do speakers and listeners observe the Gricean Maxim of Quantity? Journal of Memory and Language, 54(4):554–573.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kotaro Funakoshi</author>
<author>Satoru Watanabe</author>
<author>Naoko Kuriyama</author>
<author>Takenobu Tokunaga</author>
</authors>
<title>Generation of relative referring expressions based on perceptual grouping.</title>
<date>2004</date>
<booktitle>In COLING ’04: Proceedings of the 20th international conference on Computational Linguistics,</booktitle>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="8238" citStr="Funakoshi et al., 2004" startWordPosition="1293" endWordPosition="1297">elling the participants that the robot is unable to perceive color. The stimuli consisted of 8 corresponding scenes of the table-top and the domestic setting (cf. Fig. 2). In order to preclude the specific phenomena of collaborative, task-oriented dialogue (cf., e.g., (Garrod and Pickering, 2004)), the participants had to instruct an imaginary recipient of orders. The choice of a robot was made to rule out potential social implications when imagining, e.g., talking to a child, a butler, or a friend. The SSS scenes show a bird’s-eye view of the table including the robot’s position (similar to (Funakoshi et al., 2004)). The way the objects are arranged allows to refer to their location with respect to the corners of the table, with plates as additional landmarks. The LSS scenes depict an indoor environment with a corridor and, parallel to SSS, four rooms with tables as landmarks. The scenes show old campus new campus building 1A ... building 3B building 2C building 3B ... floor1 ... floor2 floor1 floor2 floor1 office1 ... office4 office1 kitchen ... office2 office5 helpdesk office3 Table 1: Example from the small-scale (1–2) and large-scale space (3–4) scenes in Fig. 2. 1. nimm [das pl¨atzchen unten links]</context>
</contexts>
<marker>Funakoshi, Watanabe, Kuriyama, Tokunaga, 2004</marker>
<rawString>Kotaro Funakoshi, Satoru Watanabe, Naoko Kuriyama, and Takenobu Tokunaga. 2004. Generation of relative referring expressions based on perceptual grouping. In COLING ’04: Proceedings of the 20th international conference on Computational Linguistics, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simon Garrod</author>
<author>Martin J Pickering</author>
</authors>
<title>Why is conversation so easy? Trends in Cognitive Sciences,</title>
<date>2004</date>
<volume>8</volume>
<issue>1</issue>
<contexts>
<context position="7912" citStr="Garrod and Pickering, 2004" startWordPosition="1236" endWordPosition="1239">g natural language and familiar with its environment. The task of the participants was to instruct the robot to clean up a working space, i.e., a table-top (SSS) and an indoor environment (LSS) by placing target objects (cookies or balls) in boxes of the same color. The use of color terms to identify objects was discouraged by telling the participants that the robot is unable to perceive color. The stimuli consisted of 8 corresponding scenes of the table-top and the domestic setting (cf. Fig. 2). In order to preclude the specific phenomena of collaborative, task-oriented dialogue (cf., e.g., (Garrod and Pickering, 2004)), the participants had to instruct an imaginary recipient of orders. The choice of a robot was made to rule out potential social implications when imagining, e.g., talking to a child, a butler, or a friend. The SSS scenes show a bird’s-eye view of the table including the robot’s position (similar to (Funakoshi et al., 2004)). The way the objects are arranged allows to refer to their location with respect to the corners of the table, with plates as additional landmarks. The LSS scenes depict an indoor environment with a corridor and, parallel to SSS, four rooms with tables as landmarks. The sc</context>
</contexts>
<marker>Garrod, Pickering, 2004</marker>
<rawString>Simon Garrod and Martin J. Pickering. 2004. Why is conversation so easy? Trends in Cognitive Sciences, 8(1):8–11, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen C Hirtle</author>
<author>John Jonides</author>
</authors>
<title>Evidence for hierarchies in cognitive maps.</title>
<date>1985</date>
<journal>Memory and Cognition,</journal>
<pages>13--208</pages>
<contexts>
<context position="3858" citStr="Hirtle and Jonides, 1985" startWordPosition="584" endWordPosition="587">eir domestic or work environments in their cognitive maps. Details might be missing, and people might be uncertain about particular things and states of affairs that are known to change frequently. Still, people regularly engage in a conversation about such an environment, making successful references to spatially located entities. It is generally assumed that humans adopt a partially hierarchical representation of spatial organization (Stevens and Coupe, 1978; McNamara, 1986). The basic units of such a representation are topological regions (i.e., more or less clearly bounded spatial areas) (Hirtle and Jonides, 1985). Paraboni et al. (2007) are among the few to address the issue of generating references to entities outside the immediate environment, and present an algorithm for context determination in hierar(a) Example for a hierarchical representation of space. (b) Illustration of the TA principle: starting from the attentional anchor (a), the smallest sub-hierarchy containing both a and the intended referent (r) is formed incrementally. Figure 1: TA in a spatial hierarchy. chically ordered domains. However, since it is mainly targeted at producing textual references to entities in written documents (e.</context>
</contexts>
<marker>Hirtle, Jonides, 1985</marker>
<rawString>Stephen C. Hirtle and John Jonides. 1985. Evidence for hierarchies in cognitive maps. Memory and Cognition, 13:208–217.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Horacek</author>
</authors>
<title>An algorithm for generating referential descriptions with flexible interfaces.</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics and Eighth Conference of the European Chapter of the Association for Computational Linguistics (ACL-97),</booktitle>
<pages>206--213</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="2002" citStr="Horacek, 1997" startWordPosition="291" endWordPosition="292">tion from the domain must be incorporated in a noun phrase (NP) such that this NP allows the hearer to optimally understand which referent is meant. The domains of such approaches usually consist of small, static domains or simple visual scenes. In their seminal work Dale and Reiter (1995) present the Incremental Algorithm (IA) for GRE. Recent extensions address some of its shortcomings, such as negated and disjoined properties (van Deemter, 2002) and an account of salience for generating contextually appropriate shorter REs (Krahmer and Theune, 2002). Other, alternative GRE algorithms exist (Horacek, 1997; Bateman, 1999; Krahmer et al., 2003). However, all these algorithms rely on a given domain of discourse constituting the current context (or focus of attention). The task of the GRE algorithm is then to single out the intended referent against the other members of the context, which act as potential distractors. As long as the domains are such closed-context scenarios, the intended referent is always in the current focus. We address the challenge of producing and understanding of references to entities that are outside the current focus of attention, because they have not been mentioned yet </context>
</contexts>
<marker>Horacek, 1997</marker>
<rawString>Helmut Horacek. 1997. An algorithm for generating referential descriptions with flexible interfaces. In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics and Eighth Conference of the European Chapter of the Association for Computational Linguistics (ACL-97), pages 206–213, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emiel Krahmer</author>
<author>Mari¨et Theune</author>
</authors>
<title>Efficient context-sensitive generation of referring expressions.</title>
<date>2002</date>
<booktitle>Information Sharing: Givenness and Newness in Language Processing,</booktitle>
<pages>223--264</pages>
<editor>In Kees van Deemter and R. Kibble, editors,</editor>
<publisher>CSLI Publications,</publisher>
<location>Stanford, CA, USA.</location>
<contexts>
<context position="1946" citStr="Krahmer and Theune, 2002" startWordPosition="282" endWordPosition="285">lem, focussing on efficient algorithms for determining which information from the domain must be incorporated in a noun phrase (NP) such that this NP allows the hearer to optimally understand which referent is meant. The domains of such approaches usually consist of small, static domains or simple visual scenes. In their seminal work Dale and Reiter (1995) present the Incremental Algorithm (IA) for GRE. Recent extensions address some of its shortcomings, such as negated and disjoined properties (van Deemter, 2002) and an account of salience for generating contextually appropriate shorter REs (Krahmer and Theune, 2002). Other, alternative GRE algorithms exist (Horacek, 1997; Bateman, 1999; Krahmer et al., 2003). However, all these algorithms rely on a given domain of discourse constituting the current context (or focus of attention). The task of the GRE algorithm is then to single out the intended referent against the other members of the context, which act as potential distractors. As long as the domains are such closed-context scenarios, the intended referent is always in the current focus. We address the challenge of producing and understanding of references to entities that are outside the current focus</context>
</contexts>
<marker>Krahmer, Theune, 2002</marker>
<rawString>Emiel Krahmer and Mari¨et Theune. 2002. Efficient context-sensitive generation of referring expressions. In Kees van Deemter and R. Kibble, editors, Information Sharing: Givenness and Newness in Language Processing, pages 223–264. CSLI Publications, Stanford, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emiel Krahmer</author>
<author>Sebastiaan van Erk</author>
<author>Andr´e Verleg</author>
</authors>
<title>Graph-based generation of referring expressions.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<marker>Krahmer, van Erk, Verleg, 2003</marker>
<rawString>Emiel Krahmer, Sebastiaan van Erk, and Andr´e Verleg. 2003. Graph-based generation of referring expressions. Computational Linguistics, 29(1):53–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Kuipers</author>
</authors>
<title>Representing Knowledge of Large-scale Space.</title>
<date>1977</date>
<tech>PhD thesis, MIT-AI TR-418,</tech>
<institution>Massachusetts Institute of Technology,</institution>
<location>Cambridge, MA, USA,</location>
<contexts>
<context position="2915" citStr="Kuipers, 1977" startWordPosition="439" endWordPosition="440">ial distractors. As long as the domains are such closed-context scenarios, the intended referent is always in the current focus. We address the challenge of producing and understanding of references to entities that are outside the current focus of attention, because they have not been mentioned yet and are beyond the currently observable scene. Our approach relies on the dichotomy between small-scale space and large-scale space for human spatial cognition. Large-scale space is “a space which cannot be perceived at once; its global structure must be derived from local observations over time” (Kuipers, 1977). In everyday situations, an office environment, one’s house, or a university campus are large-scale spaces. A table-top or a part of an office are examples of small-scale space. Despite large-scale space being not fully observable, people can nevertheless have a reasonably complete mental representation of, e.g., their domestic or work environments in their cognitive maps. Details might be missing, and people might be uncertain about particular things and states of affairs that are known to change frequently. Still, people regularly engage in a conversation about such an environment, making s</context>
</contexts>
<marker>Kuipers, 1977</marker>
<rawString>Benjamin Kuipers. 1977. Representing Knowledge of Large-scale Space. PhD thesis, MIT-AI TR-418, Massachusetts Institute of Technology, Cambridge, MA, USA, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy P McNamara</author>
</authors>
<title>Mental representations of spatial relations.</title>
<date>1986</date>
<journal>Cognitive Psychology,</journal>
<volume>18</volume>
<pages>121</pages>
<contexts>
<context position="3714" citStr="McNamara, 1986" startWordPosition="564" endWordPosition="565">te large-scale space being not fully observable, people can nevertheless have a reasonably complete mental representation of, e.g., their domestic or work environments in their cognitive maps. Details might be missing, and people might be uncertain about particular things and states of affairs that are known to change frequently. Still, people regularly engage in a conversation about such an environment, making successful references to spatially located entities. It is generally assumed that humans adopt a partially hierarchical representation of spatial organization (Stevens and Coupe, 1978; McNamara, 1986). The basic units of such a representation are topological regions (i.e., more or less clearly bounded spatial areas) (Hirtle and Jonides, 1985). Paraboni et al. (2007) are among the few to address the issue of generating references to entities outside the immediate environment, and present an algorithm for context determination in hierar(a) Example for a hierarchical representation of space. (b) Illustration of the TA principle: starting from the attentional anchor (a), the smallest sub-hierarchy containing both a and the intended referent (r) is formed incrementally. Figure 1: TA in a spatia</context>
</contexts>
<marker>McNamara, 1986</marker>
<rawString>Timothy P. McNamara. 1986. Mental representations of spatial relations. Cognitive Psychology, 18:87– 121.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivandr´e Paraboni</author>
<author>Kees van Deemter</author>
<author>Judith Masthoff</author>
</authors>
<title>Generating referring expressions: Making referents easy to identify.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<marker>Paraboni, van Deemter, Masthoff, 2007</marker>
<rawString>Ivandr´e Paraboni, Kees van Deemter, and Judith Masthoff. 2007. Generating referring expressions: Making referents easy to identify. Computational Linguistics, 33(2):229–254, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimo Poesio</author>
</authors>
<title>A situation-theoretic formalization of definite description interpretation in plan elaboration dialogues.</title>
<date>1993</date>
<booktitle>Situation Theory and its Applications Volume 3, CSLI Lecture Notes No. 37,</booktitle>
<pages>339--374</pages>
<editor>In Peter Aczel, David Israel, Yasuhiro Katagiri, and Stanley Peters, editors,</editor>
<location>Menlo Park, CA, USA.</location>
<contexts>
<context position="5891" citStr="Poesio (1993)" startWordPosition="903" endWordPosition="904">orks, for single utterances the anchor is the physical position where it is made (i.e., the utterance situation (Devlin, 2006)). Below, we propose models for attentional anchor-progression for longer discourses about large-scale space, and evaluate them against real-world data. 2 The Models In order to account for the determination of the attentional anchor a, we propose a model called anchor-progression A. The model assumes that each exophoric reference1 serves as attentional anchor for the subsequent reference. It is based on observations on “principles for anchoring resource situations” by Poesio (1993), where the expression of movement in the domain determines 1This excludes pronouns as well as other descriptions that pick up an existing referent from the linguistic context. the updated current mutual focus of attention. a and r are then passed to the TA algorithm. Taking into account the verbal behavior observed in our experiment, we also propose a refined model of anchor-resetting R, where for each new turn (e.g., a new instruction), the anchor is re-set to the utterance situation. R leads to the inclusion of navigational information for each first RE in a turn, thus reassuring the hearer</context>
</contexts>
<marker>Poesio, 1993</marker>
<rawString>Massimo Poesio. 1993. A situation-theoretic formalization of definite description interpretation in plan elaboration dialogues. In Peter Aczel, David Israel, Yasuhiro Katagiri, and Stanley Peters, editors, Situation Theory and its Applications Volume 3, CSLI Lecture Notes No. 37, pages 339–374. Center for the Study of Language and Information, Menlo Park, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Albert Stevens</author>
<author>Patty Coupe</author>
</authors>
<title>Distortions in judged spatial relations. Cognitive Psychology,</title>
<date>1978</date>
<pages>10--422</pages>
<contexts>
<context position="3697" citStr="Stevens and Coupe, 1978" startWordPosition="560" endWordPosition="563"> small-scale space. Despite large-scale space being not fully observable, people can nevertheless have a reasonably complete mental representation of, e.g., their domestic or work environments in their cognitive maps. Details might be missing, and people might be uncertain about particular things and states of affairs that are known to change frequently. Still, people regularly engage in a conversation about such an environment, making successful references to spatially located entities. It is generally assumed that humans adopt a partially hierarchical representation of spatial organization (Stevens and Coupe, 1978; McNamara, 1986). The basic units of such a representation are topological regions (i.e., more or less clearly bounded spatial areas) (Hirtle and Jonides, 1985). Paraboni et al. (2007) are among the few to address the issue of generating references to entities outside the immediate environment, and present an algorithm for context determination in hierar(a) Example for a hierarchical representation of space. (b) Illustration of the TA principle: starting from the attentional anchor (a), the smallest sub-hierarchy containing both a and the intended referent (r) is formed incrementally. Figure </context>
</contexts>
<marker>Stevens, Coupe, 1978</marker>
<rawString>Albert Stevens and Patty Coupe. 1978. Distortions in judged spatial relations. Cognitive Psychology, 10:422–437.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kees van Deemter</author>
</authors>
<title>Generating referring expressions: boolean extensions of the incremental algorithm.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>1</issue>
<marker>van Deemter, 2002</marker>
<rawString>Kees van Deemter. 2002. Generating referring expressions: boolean extensions of the incremental algorithm. Computational Linguistics, 28(1):37–52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jette Viethen</author>
<author>Robert Dale</author>
</authors>
<title>Algorithms for generating referring expressions: Do they do what people do?</title>
<date>2006</date>
<booktitle>In Proceedings of the 4th International Natural Language Generation Conference (INLG</booktitle>
<pages>63--70</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="14986" citStr="Viethen and Dale, 2006" startWordPosition="2405" endWordPosition="2408">ons. The generation of an under-description means a failure to construct an identifying RE, while over-descriptions are usually the result of a globally ‘bad’ incremental construction of the generated REs (as is the case, e.g., in the IA). An RRE component, on the other hand, should be able to identify as many referents as possible by treating as few as possible REs as under-descriptions. The analysis of the SSS data with respect to G establishes the baseline for a comparison with other experiments and GRE approaches. 13.9% of the REs contain redundant information (overG), compared to 21% in (Viethen and Dale, 2006). In contrast, however, our SSS scenes did not provide the possibility for producing more-than-minimal REs for every target object, which might account for the difference. underG REs occur with a frequency of 7.2% in the SSS data. Because underdescriptions result in the the hearer being unable to reliably resolve the reference, this means that the robot in our experiment cannot fulfill its task. This might explain the difference to the 16% observed in the task-independent study by Viethen and Dale (2006). The significantly (p&lt;0.001) higher mean frequency of minG than minA underpins that G is a</context>
</contexts>
<marker>Viethen, Dale, 2006</marker>
<rawString>Jette Viethen and Robert Dale. 2006. Algorithms for generating referring expressions: Do they do what people do? In Proceedings of the 4th International Natural Language Generation Conference (INLG 2006), pages 63–70, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hendrik Zender</author>
<author>Geert-Jan M Kruijff</author>
<author>Ivana Kruijff-Korbayov´a</author>
</authors>
<title>A situated context model for resolution and generation of referring expressions.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th European Workshop on Natural Language Generation (ENLG</booktitle>
<pages>126--129</pages>
<location>Athens, Greece,</location>
<marker>Zender, Kruijff, Kruijff-Korbayov´a, 2009</marker>
<rawString>Hendrik Zender, Geert-Jan M. Kruijff, and Ivana Kruijff-Korbayov´a. 2009a. A situated context model for resolution and generation of referring expressions. In Proceedings of the 12th European Workshop on Natural Language Generation (ENLG 2009), pages 126–129, Athens, Greece, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hendrik Zender</author>
<author>Geert-Jan M Kruijff</author>
<author>Ivana Kruijff-Korbayov´a</author>
</authors>
<title>Situated resolution and generation of spatial referring expressions for robotic assistants.</title>
<date>2009</date>
<booktitle>In Proceedings of the TwentyFirst International Joint Conference on Artificial Intelligence (IJCAI-09),</booktitle>
<pages>1604--1609</pages>
<location>Pasadena, CA, USA,</location>
<marker>Zender, Kruijff, Kruijff-Korbayov´a, 2009</marker>
<rawString>Hendrik Zender, Geert-Jan M. Kruijff, and Ivana Kruijff-Korbayov´a. 2009b. Situated resolution and generation of spatial referring expressions for robotic assistants. In Proceedings of the TwentyFirst International Joint Conference on Artificial Intelligence (IJCAI-09), pages 1604–1609, Pasadena, CA, USA, July.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>