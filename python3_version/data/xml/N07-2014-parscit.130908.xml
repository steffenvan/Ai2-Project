<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.209614">
<title confidence="0.994516">
Arabic Diacritization through Full Morphological Tagging
</title>
<author confidence="0.997117">
Nizar Habash and Owen Rambow
</author>
<affiliation confidence="0.996627">
Center for Computational Learning Systems
Columbia University
</affiliation>
<address confidence="0.990213">
New York, NY 10115, USA
</address>
<email confidence="0.999854">
{habash,rambow}@cs.columbia.edu
</email>
<sectionHeader confidence="0.997403" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998386">
We present a diacritization system for
written Arabic which is based on a lexical
resource. It combines a tagger and a lex-
eme language model. It improves on the
best results reported in the literature.
</bodyText>
<sectionHeader confidence="0.999648" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999832769230769">
Arabic is written without certain orthographic sym-
bols, called diacritics, which represent among other
things short vowels.1 The restoration of diacritics
to written Arabic is an important processing step
for several natural language processing applications,
including training language models for automatic
speech recognition, text-to-speech generation, and
so on. For a discussion of the role of diacritiza-
tion, see (Maamouri et al., 2006). In this paper, we
present a new diacritization module that outperforms
the best previously published results, using a new
combination of techniques. A more detailed presen-
tation can be found in (Habash and Rambow 2007).
</bodyText>
<sectionHeader confidence="0.997201" genericHeader="method">
2 Diacritization in Arabic: Linguistic
Description
</sectionHeader>
<bodyText confidence="0.966728363636364">
Arabic script consists of two classes of symbols:
letters and diacritics. Letters are always written
whereas diacritics are optional: written Arabic can
be fully diacritized, it can have some diacritics (to
disambiguate certain words), or it can be entirely
undiacritized. There are three types of diacritics:
vowel, nunation, and shadda. Vowel diacritics rep-
resent Arabic’s three short vowels and the absence
of any vowel. The following are the four vowel-
diacritics exemplified in conjunction with the letter
b (we use Buckwalter transliteration): ba,
</bodyText>
<footnote confidence="0.9988936">
1This research was supported by the Defense Advanced Re-
search Projects Agency (DARPA) under Contract No. HR0011-
06-C-0023. Any opinions, findings and conclusions or recom-
mendations expressed in this paper are those of the authors and
do not necessarily reflect the views of DARPA.
</footnote>
<page confidence="0.993365">
53
</page>
<bodyText confidence="0.98213190625">
bu, bi and bo (no vowel). Nunation diacrit-
ics can only occur in word final positions in nomi-
nals (nouns, adjectives and adverbs). They represent
a short vowel followed by an n sound: 2 bF,
bN and bK. Nunation is an indicator of nominal
indefiniteness. Shadda is a consonant doubling dia-
critic: b—. The shadda can combine with vowel
or nunation diacritics: b—u or b—N. Addi-
tional diacritical marks in Arabic include the hamza,
which appears in conjunction with a small number
of letters (e.g., , ☛, , , ). Since most Arabic en-
codings do not consider the hamza a diacritic, but
rather a part of the letter (like the dot on the lower-
case Roman i or under the Arabic b: ), we do not
count it here as part of the diacritic set.
Functionally, diacritics can be split into two dif-
ferent kinds: lezemic diacritics and inflectional di-
acritics. Lexemic diacritics distinguish between two
lexemes.3 For example, the diacritization differ-
ence between the lexemes k4tib ’writer’ and
k4tab ‘to correspond’ distinguish between the
meanings of the word rather than their inflections.
Thus, there are lexemes that look alike when undia-
critized but are spelled differently when diacritized.
Note that there are also distinct lexemes that are al-
ways spelled the same way, even when diacritized –
their difference is only a difference in word sense.
Inflectional diacritics distinguish different in-
flected forms of the same lexeme. For instance,
the final diacritics in katabtu ‘I wrote’ and
katabta ‘you wrote’ distinguish the person of
the subject of the verb. We further distinguish be-
</bodyText>
<footnote confidence="0.974386285714286">
2Arabic orthography calls for adding a silent Alif (✗) in con-
junction with in words ending with a consonant.
3A lexeme is an abstraction over inflected wordforms which
groups together all those wordforms that differ only in terms
of one of the morphological categories such as number, gender,
aspect, or voice. The lemma is the distinguished word form
which serves as citation form.
</footnote>
<note confidence="0.6688835">
Proceedings of NAACL HLT 2007, Companion Volume, pages 53–56,
Rochester, NY, April 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.9921392">
tween two types of inflectional diacritics: variant
inflectional diacritics and invariant inflectional dia-
critics. The distinction is made with respect to two
morphosyntactic features: nominal case and verbal
mood. The variant inflectional diacritics need not al-
ways appear at the end of the word. For instance, the
variant inflectional diacritics at the penultimate po-
sitions of the following two words distinguish their
case: kAtibuhu ‘his writer [nominative]’ and
kAtibahu ‘his writer [accusative]’.
</bodyText>
<sectionHeader confidence="0.987799" genericHeader="method">
3 The MADA-D System
</sectionHeader>
<bodyText confidence="0.999862011363637">
In a previous publication, we described the Mor-
phological Analysis and Disambiguation of Ara-
bic (MADA) system (Habash and Rambow, 2005).
The basic approach used in MADA is inspired by
the work of Hajiˇc (2000) for tagging morphologi-
cally rich languages, which was extended to Ara-
bic independently by Hajiˇc et al. (2005). In this
approach, a set of taggers are trained for individ-
ual linguistic features which are components of the
full morphological tag (such as core part-of-speech,
tense, number, and so on). In Arabic, we have ca.
2,000 to 20,000 morphological tags, depending on
how we count. The Buckwalter Arabic Morpholog-
ical Analyzer (BAMA) (Buckwalter, 2004) is con-
sulted to produce a list of possible analyses for a
word. BAMA returns, given an undiacritized in-
flected word form, all possible morphological anal-
yses, including full diacritization for each analy-
sis. The results of the individual taggers are used
to choose among these possible analyses. The algo-
rithm we proposed in (Habash and Rambow, 2005)
for choosing the best BAMA analysis simply counts
the number of predicted values for the set of linguis-
tic features in each candidate analysis. Hajiˇc et al.
(2005), however, weigh the predicted values by their
probability or confidence measure. To our knowl-
edge, no results on diacritization have been previ-
ously reported using this particular approach to tag-
ging.4
In this paper, we extend our basic MADA sys-
tem in the following ways: First, we follow Hajiˇc
et al. (2005) in including case, mood, and nunation
4Smith et al. (2005) also use the Buckwalter Analyzer in
their Arabic morphological tagger, but then use a rather differ-
ent approach to choosing among the possible analyses. They
represent the possible analyses in a lattice, and a noisy channel
model to choose among them. We leave to future work how the
issue of diacritization can be integrated with their model.
as features, because of its importance to diacritiza-
tion. Second, we replace the YAMCHA (Kudo and
Matsumoto, 2003) implementation of Support Vec-
tor Machines (SVMs) with SVMTool (Gim´enez and
M`arquez, 2004) as our machine learning tool, for
reasons of speed, at the cost of a slight decrease in
accuracy. Like Hajiˇc et al. (2005), we do not use
Viterbi decoding. Finally, we introduce a specialized
module for resolving residual ambiguity after the ba-
sic tagging is done. We explain this module in detail
next. We train our classifiers on the exact training set
defined by Zitouni et al. (2006), a subpart of the third
segment of the Penn Arabic Treebank (Maamouri et
al., 2004) (“ATB3-Train”, 288,000 words). We also
(reluctantly) follow them in having a single set for
development and testing (“ATB3-Devtest”, 52,000
words), rather than separate development and test
sets (as is common), in order to be able to compare
our results to theirs.
Up until this point, MADA-D has narrowed the
list of possible analyses of a word (supplied by
BAMA) down to a small number. This number can
sometimes be greater than one for two reasons: first,
the way in which we use the output of the taggers
to choose among the analyses may yield a tie among
several analyses; second, there may be lexeme-based
diacritic ambiguity, and the morphological taggers
cannot disambiguate lexemic diacritization. To ad-
dress the residual ambiguity, we implemented a sec-
ond component. Ideally, this would be (or include) a
full word sense disambiguation (WSD) system, but
WSD is a hard problem. Instead, we approximate
WSD using standard n-gram language models. We
use two types of data for training: fully diacritized
word forms, and data in which we have replaced the
inflected word by the diacritized citation form of the
lexeme. Note that this procedure conflates lexemes
that differ only in meaning, not in diacritization, as
we are not actually interested in WSD for its own
sake in this paper. The training corpus is the same
corpus we use for the classifiers, ATB3-Train. This
means that the diacritization and the choice of lex-
eme are done by hand, but it also means that the
training set is quite small by the standards of lan-
guage models. We build an open-vocabulary lan-
guage model with Kneser-Ney smoothing using the
SRILM toolkit (Stolcke, 2002). We will call the re-
sulting language models XLM-n, where X is “D”
for the fully diacritized word forms, or “L” for the
lexeme citation forms, and n is the order of the n-
</bodyText>
<page confidence="0.991952">
54
</page>
<bodyText confidence="0.999949">
grams (n = 1, 2, 3). When all candidate tokens (di-
acritized word or lexeme citation form) are unknown
(out-of-vocabulary), the language model does not
actually make a choice among them. We then use a
diacritization unigram model, and then finally ran-
dom choice. In the case of a preceding DLM-n
model, this simply amounts to random choice, but
in the case of a preceding LLM-n model, the dia-
critization model may actually make a non-random
choice.
</bodyText>
<sectionHeader confidence="0.999972" genericHeader="method">
4 Related Work
</sectionHeader>
<bodyText confidence="0.999993973684211">
We review three approaches that are directly rele-
vant to us; we refer to the excellent literature review
in (Zitouni et al., 2006) for a general review. Vergyri
and Kirchhoff (2004) follow an approach similar to
ours in that they choose from the diacritizations pro-
posed by BAMA. However, they train a single tag-
ger using unannotated data and EM, which necessar-
ily leads to a lower performance. The most salient
difference, however, is that they are motivated by the
goal of improving automatic speech recognition, and
have an acoustic signal parallel to the undiacritized
text. All their experiments use acoustic models.
They show that WER for diacritization decreases by
nearly 50% (from 50%) when BAMA is added to the
acoustic information, but the tagger does not help. It
would be interesting to investigate ways of incorpo-
rating acoustic model information in our approach.
Ananthakrishnan et al. (2005) also work on dia-
critization with the goal of improving ASR. They
use a word-based language model (using both di-
acritized and undiacritized words in the context)
but back off to a character-based model for unseen
words. They consult BAMA to narrow possible di-
acritizations for unseen words, but BAMA does not
provide much improvement used in this manner.
Zitouni et al. (2006) use a maximum entropy clas-
sifier to assign a set of diacritics to the letters of
each word. They use the output of a tokenizer (seg-
menter) and a part-of-speech tagger (which presum-
ably tags the output of the tokenizer). They then use
segment n-grams, segment position of the character
being diacritized, the POS of the current segment,
along with lexical features, including letter and word
n-grams. Thus, while many of the same elements
are used in their and our work (word n-grams, fea-
tures related to morphological analysis), the basic
approach is quite different: while we have one pro-
cedure that chooses a correct analysis (including to-
</bodyText>
<table confidence="0.998777166666667">
Model All Diacritics Ignore Last
WER DER WER DER
Only-DLM-1 39.4 14.5 13.8 6.6
Tagger-DLM-1 15.9 5.3 6.2 2.5
Tagger-DLM-2 15.2 5.1 5.8 2.4
Tagger-DLM-3 15.1 5.0 5.7 2.4
Tagger-LLM-1 16.0 5.3 6.3 2.6
Tagger-LLM-2 15.0 4.9 5.6 2.2
Tagger-LLM-3 14.9 4.8 5.5 2.2
Only-LLM-3 35.5 10.8 8.8 3.6
Tagger-noLM 16.0 5.3 6.3 2.6
Zitouni 18.0 5.5 7.9 2.5
</table>
<figureCaption confidence="0.987747">
Figure 1: Diacritization Results (all followed by
</figureCaption>
<bodyText confidence="0.9888768">
single-choice-diac model); our best results are
shown in boldface; Only-DLM-1 is the baseline;
“Zitouni” is (Zitouni et al., 2006)
kenization, morphological tag, and diacritization),
they have a pipeline of processors. Furthermore, Zi-
touni et al. (2006) do not use a morphological lexi-
con. To our knowledge, their system is the best per-
forming currently, and we have set up our experi-
ments to allow us to compare our results directly to
their results.
</bodyText>
<sectionHeader confidence="0.999895" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.999938263157895">
There are several ways of defining metrics for dia-
critization. In order to assure maximal comparabil-
ity with the work of Zitouni et al. (2006), we adopt
their metric.5 We count all words, including num-
bers and punctuation. Each letter (or digit) in a word
is a potential host for a set of diacritics; we count
all diacritics on a single letter as a single binary
choice. So, for example, if we correctly predict a
shadda but get the vowel wrong, it counts as a wrong
choice. We approximate non-variant diacritization
by removing all diacritics from the final letter (Ig-
nore Last), while counting that letter in the evalua-
tion. We give diacritic error rate (DER) which tells
us for how many letters we incorrectly restored all
diacritics, and word error rate (WER), which tells
us how many words had at least one DER.
The results are shown in Figure 1. Going top
to bottom, we first see the baseline, Only-DLM-1,
which is simply a diacritization unigram model with
</bodyText>
<footnote confidence="0.980265">
5We thank Imed Zitouni (personal communication) for de-
tails on their evaluation.
</footnote>
<page confidence="0.998864">
55
</page>
<bodyText confidence="0.999989295454546">
random choice for unseen words. We then show the
results using the morphological tagger along with a
language model. We first show results for the dia-
critization model, with 1-, 2-, and 3-grams. As we
can see, the bigram language model helps slightly.
The next three lines are the three lexeme n-gram
models. Here we see that the unigram model per-
forms worse than the unigram diacritization model,
while the bigram and trigram models perform better
(the trigram lexeme model is our best result). We
interpret this as meaning that the lexeme model is
useful only when context is taken into account, be-
cause it is actually performing a rudimentary form of
WSD. We tease apart the contribution of the tagger
and of the language model with two further experi-
ments, in the next two lines: using just the lexeme
language model (trigrams), and running just the tag-
ger, followed by random choice. We can see that
the tagger alone does as well as the tagger with the
unigram lexeme model, while the lexeme model on
its own does much worse. However, as expected, the
lexeme model on its own for the Ignore Last measure
is much closer to the performance of the tagger on
its own. We conclude from this that the quite simple
lexeme model is in fact contributing to the correct
choice of the lexemic diacritics. Finally, we give the
results of Zitouni et al. (2006) on the last line, which
we understand to be the best published results cur-
rently. We see that we improve on their results in all
categories. We can see the effect of our different ap-
proaches to diacritization in the numbers: while for
WER we reduce the Zitouni et al error by 17.2%, the
DER error reduction is only 10.9%. This is because
we are choosing among complete diacritization op-
tions for white space-tokenized words, while Zitouni
et al. (2006) make choices for each diacritic. This
means that when we make a mistake, it may well
affect several diacritics at once, so that the diacritic
errors are concentrated in fewer words. This effect
is even stronger when we disregard the final letter
(30.4% reduction in WER versus 12.0% reduction
in DER), suggesting that singleton errors in words
tend to be in the final position (case, mood), as it is
often hard for the tagger to determine these features.
</bodyText>
<sectionHeader confidence="0.999596" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999977230769231">
We have shown that a diacritizer that uses a lexical
resource can outperform a highly optimized ad-hoc
diacritization system that draws on a large number
of features. We speculate that further work on WSD
could further improve our results. We also note the
issue of unknown words, which will affect our sys-
tem much more than that of (Zitouni et al., 2006).
It is possible to construct a combined system which
uses a lexicon, but backs off to a Zitouni-style sys-
tem for unknown words. However, a large portion
of the unknown words are in fact foreign words and
names, and it is not clear whether the models learned
handle such words well.
</bodyText>
<sectionHeader confidence="0.999433" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999730577777778">
S. Ananthakrishnan, S. Narayanan, and S. Bangalore. 2005.
Automatic diacritization of arabic transcripts for asr. In Pro-
ceedings ofICON-05, Kanpur, India.
T. Buckwalter. 2004. Buckwalter Arabic morphological ana-
lyzer version 2.0.
J. Gim´enez and L. M`arquez. 2004. Svmtool: A general pos
tagger generator based on support vector machines. In Pro-
ceedings ofLREC’04.
N. Habash and O. Rambow. 2005. Arabic tokenization, part-
of-speech tagging and morphological disambiguation in one
fell swoop. In Proceedings of (ACL’05).
N. Habash and O. Rambow. 2007. Arabic Diacritization
through Full Morphological Tagging: A Detailed Discus-
sion. Techncial Report, Center for Computational Learning
Systems, Columbia University.
Jan Hajiˇc, Otakar Smrˇz, Tim Buckwalter, and Hubert Jin. 2005.
Feature-based tagger of approximations of functional Arabic
morphology. In Proceedings of the Workshop on Treebanks
and Linguistic Theories (TLT), Barcelona, Spain.
Jan Hajiˇc. 2000. Morphological tagging: Data vs. dictionaries.
In Proceedings of (NAACL’00).
Taku Kudo and Yuji Matsumoto. 2003. Fast methods for
kernel-based text analysis. In Proceedings of (ACL’03).
Mohamed Maamouri, Ann Bies, and Tim Buckwalter. 2004.
The Penn Arabic Treebank: Building a large-scale annotated
arabic corpus. In NEMLAR Conference on Arabic Language
Resources and Tools, Cairo, Egypt.
Mohamed Maamouri, Ann Bies, and Seth Kulick. 2006. Di-
acritization: A challenge to arabic treebank annotation and
parsing. In Proceedings of the Conference of the Machine
Translation SIG of the British Computer Society.
Noah A. Smith, David A. Smith, and Roy W. Tromble. 2005.
Context-based morphological disambiguation with random
fields. In Proceedings of (EMNLP05).
Andreas Stolcke. 2002. SRILM - an Extensible Language
Modeling Toolkit. In Proceedings of the International Con-
ference on Spoken Language Processing (ICSLP).
Dimitra Vergyri and Katrin Kirchhoff. 2004. Automatic dia-
critization of arabic for acoustic modeling in speech recog-
nition. In COLING 2004 Workshop on Computational
Approaches to Arabic Script-based Languages, Geneva,
Switzerland.
Imed Zitouni, Jeffrey S. Sorensen, and Ruhi Sarikaya. 2006.
Maximum entropy based restoration of arabic diacritics. In
Proceedings ofACL’06.
</reference>
<page confidence="0.998416">
56
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.882555">
<title confidence="0.9998">Arabic Diacritization through Full Morphological Tagging</title>
<author confidence="0.992926">Nizar Habash</author>
<author confidence="0.992926">Owen</author>
<affiliation confidence="0.999767">Center for Computational Learning</affiliation>
<address confidence="0.9459435">Columbia New York, NY 10115,</address>
<abstract confidence="0.99934">We present a diacritization system for written Arabic which is based on a lexical resource. It combines a tagger and a lexeme language model. It improves on the best results reported in the literature.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Ananthakrishnan</author>
<author>S Narayanan</author>
<author>S Bangalore</author>
</authors>
<title>Automatic diacritization of arabic transcripts for asr.</title>
<date>2005</date>
<booktitle>In Proceedings ofICON-05, Kanpur,</booktitle>
<contexts>
<context position="10365" citStr="Ananthakrishnan et al. (2005)" startWordPosition="1676" endWordPosition="1679">. However, they train a single tagger using unannotated data and EM, which necessarily leads to a lower performance. The most salient difference, however, is that they are motivated by the goal of improving automatic speech recognition, and have an acoustic signal parallel to the undiacritized text. All their experiments use acoustic models. They show that WER for diacritization decreases by nearly 50% (from 50%) when BAMA is added to the acoustic information, but the tagger does not help. It would be interesting to investigate ways of incorporating acoustic model information in our approach. Ananthakrishnan et al. (2005) also work on diacritization with the goal of improving ASR. They use a word-based language model (using both diacritized and undiacritized words in the context) but back off to a character-based model for unseen words. They consult BAMA to narrow possible diacritizations for unseen words, but BAMA does not provide much improvement used in this manner. Zitouni et al. (2006) use a maximum entropy classifier to assign a set of diacritics to the letters of each word. They use the output of a tokenizer (segmenter) and a part-of-speech tagger (which presumably tags the output of the tokenizer). The</context>
</contexts>
<marker>Ananthakrishnan, Narayanan, Bangalore, 2005</marker>
<rawString>S. Ananthakrishnan, S. Narayanan, and S. Bangalore. 2005. Automatic diacritization of arabic transcripts for asr. In Proceedings ofICON-05, Kanpur, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Buckwalter</author>
</authors>
<title>Buckwalter Arabic morphological analyzer version 2.0.</title>
<date>2004</date>
<contexts>
<context position="5262" citStr="Buckwalter, 2004" startWordPosition="821" endWordPosition="822">ogical Analysis and Disambiguation of Arabic (MADA) system (Habash and Rambow, 2005). The basic approach used in MADA is inspired by the work of Hajiˇc (2000) for tagging morphologically rich languages, which was extended to Arabic independently by Hajiˇc et al. (2005). In this approach, a set of taggers are trained for individual linguistic features which are components of the full morphological tag (such as core part-of-speech, tense, number, and so on). In Arabic, we have ca. 2,000 to 20,000 morphological tags, depending on how we count. The Buckwalter Arabic Morphological Analyzer (BAMA) (Buckwalter, 2004) is consulted to produce a list of possible analyses for a word. BAMA returns, given an undiacritized inflected word form, all possible morphological analyses, including full diacritization for each analysis. The results of the individual taggers are used to choose among these possible analyses. The algorithm we proposed in (Habash and Rambow, 2005) for choosing the best BAMA analysis simply counts the number of predicted values for the set of linguistic features in each candidate analysis. Hajiˇc et al. (2005), however, weigh the predicted values by their probability or confidence measure. To</context>
</contexts>
<marker>Buckwalter, 2004</marker>
<rawString>T. Buckwalter. 2004. Buckwalter Arabic morphological analyzer version 2.0.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Gim´enez</author>
<author>L M`arquez</author>
</authors>
<title>Svmtool: A general pos tagger generator based on support vector machines.</title>
<date>2004</date>
<booktitle>In Proceedings ofLREC’04.</booktitle>
<marker>Gim´enez, M`arquez, 2004</marker>
<rawString>J. Gim´enez and L. M`arquez. 2004. Svmtool: A general pos tagger generator based on support vector machines. In Proceedings ofLREC’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Habash</author>
<author>O Rambow</author>
</authors>
<title>Arabic tokenization, partof-speech tagging and morphological disambiguation in one fell swoop.</title>
<date>2005</date>
<booktitle>In Proceedings of (ACL’05).</booktitle>
<contexts>
<context position="4729" citStr="Habash and Rambow, 2005" startWordPosition="732" endWordPosition="735">acritics: variant inflectional diacritics and invariant inflectional diacritics. The distinction is made with respect to two morphosyntactic features: nominal case and verbal mood. The variant inflectional diacritics need not always appear at the end of the word. For instance, the variant inflectional diacritics at the penultimate positions of the following two words distinguish their case: kAtibuhu ‘his writer [nominative]’ and kAtibahu ‘his writer [accusative]’. 3 The MADA-D System In a previous publication, we described the Morphological Analysis and Disambiguation of Arabic (MADA) system (Habash and Rambow, 2005). The basic approach used in MADA is inspired by the work of Hajiˇc (2000) for tagging morphologically rich languages, which was extended to Arabic independently by Hajiˇc et al. (2005). In this approach, a set of taggers are trained for individual linguistic features which are components of the full morphological tag (such as core part-of-speech, tense, number, and so on). In Arabic, we have ca. 2,000 to 20,000 morphological tags, depending on how we count. The Buckwalter Arabic Morphological Analyzer (BAMA) (Buckwalter, 2004) is consulted to produce a list of possible analyses for a word. BA</context>
</contexts>
<marker>Habash, Rambow, 2005</marker>
<rawString>N. Habash and O. Rambow. 2005. Arabic tokenization, partof-speech tagging and morphological disambiguation in one fell swoop. In Proceedings of (ACL’05).</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Habash</author>
<author>O Rambow</author>
</authors>
<title>Arabic Diacritization through Full Morphological Tagging: A Detailed Discussion.</title>
<date>2007</date>
<tech>Techncial Report,</tech>
<institution>Center for Computational Learning Systems, Columbia University.</institution>
<contexts>
<context position="1091" citStr="Habash and Rambow 2007" startWordPosition="155" endWordPosition="158">ographic symbols, called diacritics, which represent among other things short vowels.1 The restoration of diacritics to written Arabic is an important processing step for several natural language processing applications, including training language models for automatic speech recognition, text-to-speech generation, and so on. For a discussion of the role of diacritization, see (Maamouri et al., 2006). In this paper, we present a new diacritization module that outperforms the best previously published results, using a new combination of techniques. A more detailed presentation can be found in (Habash and Rambow 2007). 2 Diacritization in Arabic: Linguistic Description Arabic script consists of two classes of symbols: letters and diacritics. Letters are always written whereas diacritics are optional: written Arabic can be fully diacritized, it can have some diacritics (to disambiguate certain words), or it can be entirely undiacritized. There are three types of diacritics: vowel, nunation, and shadda. Vowel diacritics represent Arabic’s three short vowels and the absence of any vowel. The following are the four voweldiacritics exemplified in conjunction with the letter b (we use Buckwalter transliteration)</context>
</contexts>
<marker>Habash, Rambow, 2007</marker>
<rawString>N. Habash and O. Rambow. 2007. Arabic Diacritization through Full Morphological Tagging: A Detailed Discussion. Techncial Report, Center for Computational Learning Systems, Columbia University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
<author>Otakar Smrˇz</author>
<author>Tim Buckwalter</author>
<author>Hubert Jin</author>
</authors>
<title>Feature-based tagger of approximations of functional Arabic morphology.</title>
<date>2005</date>
<booktitle>In Proceedings of the Workshop on Treebanks and Linguistic Theories (TLT),</booktitle>
<location>Barcelona,</location>
<marker>Hajiˇc, Smrˇz, Buckwalter, Jin, 2005</marker>
<rawString>Jan Hajiˇc, Otakar Smrˇz, Tim Buckwalter, and Hubert Jin. 2005. Feature-based tagger of approximations of functional Arabic morphology. In Proceedings of the Workshop on Treebanks and Linguistic Theories (TLT), Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
</authors>
<title>Morphological tagging: Data vs. dictionaries.</title>
<date>2000</date>
<booktitle>In Proceedings of (NAACL’00).</booktitle>
<marker>Hajiˇc, 2000</marker>
<rawString>Jan Hajiˇc. 2000. Morphological tagging: Data vs. dictionaries. In Proceedings of (NAACL’00).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Fast methods for kernel-based text analysis.</title>
<date>2003</date>
<booktitle>In Proceedings of (ACL’03).</booktitle>
<contexts>
<context position="6606" citStr="Kudo and Matsumoto, 2003" startWordPosition="1042" endWordPosition="1045">In this paper, we extend our basic MADA system in the following ways: First, we follow Hajiˇc et al. (2005) in including case, mood, and nunation 4Smith et al. (2005) also use the Buckwalter Analyzer in their Arabic morphological tagger, but then use a rather different approach to choosing among the possible analyses. They represent the possible analyses in a lattice, and a noisy channel model to choose among them. We leave to future work how the issue of diacritization can be integrated with their model. as features, because of its importance to diacritization. Second, we replace the YAMCHA (Kudo and Matsumoto, 2003) implementation of Support Vector Machines (SVMs) with SVMTool (Gim´enez and M`arquez, 2004) as our machine learning tool, for reasons of speed, at the cost of a slight decrease in accuracy. Like Hajiˇc et al. (2005), we do not use Viterbi decoding. Finally, we introduce a specialized module for resolving residual ambiguity after the basic tagging is done. We explain this module in detail next. We train our classifiers on the exact training set defined by Zitouni et al. (2006), a subpart of the third segment of the Penn Arabic Treebank (Maamouri et al., 2004) (“ATB3-Train”, 288,000 words). We </context>
</contexts>
<marker>Kudo, Matsumoto, 2003</marker>
<rawString>Taku Kudo and Yuji Matsumoto. 2003. Fast methods for kernel-based text analysis. In Proceedings of (ACL’03).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohamed Maamouri</author>
<author>Ann Bies</author>
<author>Tim Buckwalter</author>
</authors>
<title>The Penn Arabic Treebank: Building a large-scale annotated arabic corpus.</title>
<date>2004</date>
<booktitle>In NEMLAR Conference on Arabic Language Resources and Tools,</booktitle>
<location>Cairo, Egypt.</location>
<contexts>
<context position="7171" citStr="Maamouri et al., 2004" startWordPosition="1138" endWordPosition="1141"> Second, we replace the YAMCHA (Kudo and Matsumoto, 2003) implementation of Support Vector Machines (SVMs) with SVMTool (Gim´enez and M`arquez, 2004) as our machine learning tool, for reasons of speed, at the cost of a slight decrease in accuracy. Like Hajiˇc et al. (2005), we do not use Viterbi decoding. Finally, we introduce a specialized module for resolving residual ambiguity after the basic tagging is done. We explain this module in detail next. We train our classifiers on the exact training set defined by Zitouni et al. (2006), a subpart of the third segment of the Penn Arabic Treebank (Maamouri et al., 2004) (“ATB3-Train”, 288,000 words). We also (reluctantly) follow them in having a single set for development and testing (“ATB3-Devtest”, 52,000 words), rather than separate development and test sets (as is common), in order to be able to compare our results to theirs. Up until this point, MADA-D has narrowed the list of possible analyses of a word (supplied by BAMA) down to a small number. This number can sometimes be greater than one for two reasons: first, the way in which we use the output of the taggers to choose among the analyses may yield a tie among several analyses; second, there may be </context>
</contexts>
<marker>Maamouri, Bies, Buckwalter, 2004</marker>
<rawString>Mohamed Maamouri, Ann Bies, and Tim Buckwalter. 2004. The Penn Arabic Treebank: Building a large-scale annotated arabic corpus. In NEMLAR Conference on Arabic Language Resources and Tools, Cairo, Egypt.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohamed Maamouri</author>
<author>Ann Bies</author>
<author>Seth Kulick</author>
</authors>
<title>Diacritization: A challenge to arabic treebank annotation and parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the Conference of the Machine Translation SIG of the British Computer Society.</booktitle>
<contexts>
<context position="871" citStr="Maamouri et al., 2006" startWordPosition="120" endWordPosition="123">or written Arabic which is based on a lexical resource. It combines a tagger and a lexeme language model. It improves on the best results reported in the literature. 1 Introduction Arabic is written without certain orthographic symbols, called diacritics, which represent among other things short vowels.1 The restoration of diacritics to written Arabic is an important processing step for several natural language processing applications, including training language models for automatic speech recognition, text-to-speech generation, and so on. For a discussion of the role of diacritization, see (Maamouri et al., 2006). In this paper, we present a new diacritization module that outperforms the best previously published results, using a new combination of techniques. A more detailed presentation can be found in (Habash and Rambow 2007). 2 Diacritization in Arabic: Linguistic Description Arabic script consists of two classes of symbols: letters and diacritics. Letters are always written whereas diacritics are optional: written Arabic can be fully diacritized, it can have some diacritics (to disambiguate certain words), or it can be entirely undiacritized. There are three types of diacritics: vowel, nunation, </context>
</contexts>
<marker>Maamouri, Bies, Kulick, 2006</marker>
<rawString>Mohamed Maamouri, Ann Bies, and Seth Kulick. 2006. Diacritization: A challenge to arabic treebank annotation and parsing. In Proceedings of the Conference of the Machine Translation SIG of the British Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noah A Smith</author>
<author>David A Smith</author>
<author>Roy W Tromble</author>
</authors>
<title>Context-based morphological disambiguation with random fields.</title>
<date>2005</date>
<booktitle>In Proceedings of (EMNLP05).</booktitle>
<contexts>
<context position="6147" citStr="Smith et al. (2005)" startWordPosition="967" endWordPosition="970">among these possible analyses. The algorithm we proposed in (Habash and Rambow, 2005) for choosing the best BAMA analysis simply counts the number of predicted values for the set of linguistic features in each candidate analysis. Hajiˇc et al. (2005), however, weigh the predicted values by their probability or confidence measure. To our knowledge, no results on diacritization have been previously reported using this particular approach to tagging.4 In this paper, we extend our basic MADA system in the following ways: First, we follow Hajiˇc et al. (2005) in including case, mood, and nunation 4Smith et al. (2005) also use the Buckwalter Analyzer in their Arabic morphological tagger, but then use a rather different approach to choosing among the possible analyses. They represent the possible analyses in a lattice, and a noisy channel model to choose among them. We leave to future work how the issue of diacritization can be integrated with their model. as features, because of its importance to diacritization. Second, we replace the YAMCHA (Kudo and Matsumoto, 2003) implementation of Support Vector Machines (SVMs) with SVMTool (Gim´enez and M`arquez, 2004) as our machine learning tool, for reasons of spe</context>
</contexts>
<marker>Smith, Smith, Tromble, 2005</marker>
<rawString>Noah A. Smith, David A. Smith, and Roy W. Tromble. 2005. Context-based morphological disambiguation with random fields. In Proceedings of (EMNLP05).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM - an Extensible Language Modeling Toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the International Conference on Spoken Language Processing (ICSLP).</booktitle>
<contexts>
<context position="8822" citStr="Stolcke, 2002" startWordPosition="1415" endWordPosition="1416">hich we have replaced the inflected word by the diacritized citation form of the lexeme. Note that this procedure conflates lexemes that differ only in meaning, not in diacritization, as we are not actually interested in WSD for its own sake in this paper. The training corpus is the same corpus we use for the classifiers, ATB3-Train. This means that the diacritization and the choice of lexeme are done by hand, but it also means that the training set is quite small by the standards of language models. We build an open-vocabulary language model with Kneser-Ney smoothing using the SRILM toolkit (Stolcke, 2002). We will call the resulting language models XLM-n, where X is “D” for the fully diacritized word forms, or “L” for the lexeme citation forms, and n is the order of the n54 grams (n = 1, 2, 3). When all candidate tokens (diacritized word or lexeme citation form) are unknown (out-of-vocabulary), the language model does not actually make a choice among them. We then use a diacritization unigram model, and then finally random choice. In the case of a preceding DLM-n model, this simply amounts to random choice, but in the case of a preceding LLM-n model, the diacritization model may actually make </context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM - an Extensible Language Modeling Toolkit. In Proceedings of the International Conference on Spoken Language Processing (ICSLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dimitra Vergyri</author>
<author>Katrin Kirchhoff</author>
</authors>
<title>Automatic diacritization of arabic for acoustic modeling in speech recognition.</title>
<date>2004</date>
<booktitle>In COLING 2004 Workshop on Computational Approaches to Arabic Script-based Languages,</booktitle>
<location>Geneva,</location>
<contexts>
<context position="9639" citStr="Vergyri and Kirchhoff (2004)" startWordPosition="1559" endWordPosition="1562"> 3). When all candidate tokens (diacritized word or lexeme citation form) are unknown (out-of-vocabulary), the language model does not actually make a choice among them. We then use a diacritization unigram model, and then finally random choice. In the case of a preceding DLM-n model, this simply amounts to random choice, but in the case of a preceding LLM-n model, the diacritization model may actually make a non-random choice. 4 Related Work We review three approaches that are directly relevant to us; we refer to the excellent literature review in (Zitouni et al., 2006) for a general review. Vergyri and Kirchhoff (2004) follow an approach similar to ours in that they choose from the diacritizations proposed by BAMA. However, they train a single tagger using unannotated data and EM, which necessarily leads to a lower performance. The most salient difference, however, is that they are motivated by the goal of improving automatic speech recognition, and have an acoustic signal parallel to the undiacritized text. All their experiments use acoustic models. They show that WER for diacritization decreases by nearly 50% (from 50%) when BAMA is added to the acoustic information, but the tagger does not help. It would</context>
</contexts>
<marker>Vergyri, Kirchhoff, 2004</marker>
<rawString>Dimitra Vergyri and Katrin Kirchhoff. 2004. Automatic diacritization of arabic for acoustic modeling in speech recognition. In COLING 2004 Workshop on Computational Approaches to Arabic Script-based Languages, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Imed Zitouni</author>
<author>Jeffrey S Sorensen</author>
<author>Ruhi Sarikaya</author>
</authors>
<title>Maximum entropy based restoration of arabic diacritics.</title>
<date>2006</date>
<booktitle>In Proceedings ofACL’06.</booktitle>
<contexts>
<context position="7087" citStr="Zitouni et al. (2006)" startWordPosition="1123" endWordPosition="1126">egrated with their model. as features, because of its importance to diacritization. Second, we replace the YAMCHA (Kudo and Matsumoto, 2003) implementation of Support Vector Machines (SVMs) with SVMTool (Gim´enez and M`arquez, 2004) as our machine learning tool, for reasons of speed, at the cost of a slight decrease in accuracy. Like Hajiˇc et al. (2005), we do not use Viterbi decoding. Finally, we introduce a specialized module for resolving residual ambiguity after the basic tagging is done. We explain this module in detail next. We train our classifiers on the exact training set defined by Zitouni et al. (2006), a subpart of the third segment of the Penn Arabic Treebank (Maamouri et al., 2004) (“ATB3-Train”, 288,000 words). We also (reluctantly) follow them in having a single set for development and testing (“ATB3-Devtest”, 52,000 words), rather than separate development and test sets (as is common), in order to be able to compare our results to theirs. Up until this point, MADA-D has narrowed the list of possible analyses of a word (supplied by BAMA) down to a small number. This number can sometimes be greater than one for two reasons: first, the way in which we use the output of the taggers to cho</context>
<context position="9588" citStr="Zitouni et al., 2006" startWordPosition="1551" endWordPosition="1554">d n is the order of the n54 grams (n = 1, 2, 3). When all candidate tokens (diacritized word or lexeme citation form) are unknown (out-of-vocabulary), the language model does not actually make a choice among them. We then use a diacritization unigram model, and then finally random choice. In the case of a preceding DLM-n model, this simply amounts to random choice, but in the case of a preceding LLM-n model, the diacritization model may actually make a non-random choice. 4 Related Work We review three approaches that are directly relevant to us; we refer to the excellent literature review in (Zitouni et al., 2006) for a general review. Vergyri and Kirchhoff (2004) follow an approach similar to ours in that they choose from the diacritizations proposed by BAMA. However, they train a single tagger using unannotated data and EM, which necessarily leads to a lower performance. The most salient difference, however, is that they are motivated by the goal of improving automatic speech recognition, and have an acoustic signal parallel to the undiacritized text. All their experiments use acoustic models. They show that WER for diacritization decreases by nearly 50% (from 50%) when BAMA is added to the acoustic </context>
<context position="11905" citStr="Zitouni et al., 2006" startWordPosition="1932" endWordPosition="1935">roach is quite different: while we have one procedure that chooses a correct analysis (including toModel All Diacritics Ignore Last WER DER WER DER Only-DLM-1 39.4 14.5 13.8 6.6 Tagger-DLM-1 15.9 5.3 6.2 2.5 Tagger-DLM-2 15.2 5.1 5.8 2.4 Tagger-DLM-3 15.1 5.0 5.7 2.4 Tagger-LLM-1 16.0 5.3 6.3 2.6 Tagger-LLM-2 15.0 4.9 5.6 2.2 Tagger-LLM-3 14.9 4.8 5.5 2.2 Only-LLM-3 35.5 10.8 8.8 3.6 Tagger-noLM 16.0 5.3 6.3 2.6 Zitouni 18.0 5.5 7.9 2.5 Figure 1: Diacritization Results (all followed by single-choice-diac model); our best results are shown in boldface; Only-DLM-1 is the baseline; “Zitouni” is (Zitouni et al., 2006) kenization, morphological tag, and diacritization), they have a pipeline of processors. Furthermore, Zitouni et al. (2006) do not use a morphological lexicon. To our knowledge, their system is the best performing currently, and we have set up our experiments to allow us to compare our results directly to their results. 5 Results There are several ways of defining metrics for diacritization. In order to assure maximal comparability with the work of Zitouni et al. (2006), we adopt their metric.5 We count all words, including numbers and punctuation. Each letter (or digit) in a word is a potenti</context>
<context position="14637" citStr="Zitouni et al. (2006)" startWordPosition="2409" endWordPosition="2412">with two further experiments, in the next two lines: using just the lexeme language model (trigrams), and running just the tagger, followed by random choice. We can see that the tagger alone does as well as the tagger with the unigram lexeme model, while the lexeme model on its own does much worse. However, as expected, the lexeme model on its own for the Ignore Last measure is much closer to the performance of the tagger on its own. We conclude from this that the quite simple lexeme model is in fact contributing to the correct choice of the lexemic diacritics. Finally, we give the results of Zitouni et al. (2006) on the last line, which we understand to be the best published results currently. We see that we improve on their results in all categories. We can see the effect of our different approaches to diacritization in the numbers: while for WER we reduce the Zitouni et al error by 17.2%, the DER error reduction is only 10.9%. This is because we are choosing among complete diacritization options for white space-tokenized words, while Zitouni et al. (2006) make choices for each diacritic. This means that when we make a mistake, it may well affect several diacritics at once, so that the diacritic erro</context>
</contexts>
<marker>Zitouni, Sorensen, Sarikaya, 2006</marker>
<rawString>Imed Zitouni, Jeffrey S. Sorensen, and Ruhi Sarikaya. 2006. Maximum entropy based restoration of arabic diacritics. In Proceedings ofACL’06.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>