<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.011736">
<note confidence="0.7172952">
DENORMALIZATION AND CROSS REFERENCING IN THEORETICAL LEXICOGRAPHY
Joseph E. Grimes
DMLL, Morrill Hall, Cornell University
Ithaca NY 14853 USA
Summer Institute of Linguistics
</note>
<address confidence="0.3961735">
7500 West Camp Wisdom Road
Dallas TX 75236 USA
</address>
<email confidence="0.349329">
ABSTRACT
</email>
<bodyText confidence="0.999495">
A computational vehicle for lexicography was
designed to keep to the constraints of meaning-
text theory: sets of lexical correlates, limits on
the form of definitions, and argument relations
similar to lexical-functional grammar.
Relational data bases look like a natural frame-
work for this. But linguists operate with a non-
normalized view. Mappings between semantic actants
and grammatical relations do not fit actant fields
uniquely. Lexical correlates and examples are poly-
valent, hence denormalized.
Cross referencing routines help the lexicogra-
pher work toward a closure state in which every
term of a definition traces back to zero level
terms defined extralinguistically or circularly.
Dummy entries produced from defining terms ensure
no trace is overlooked. Values of lexical corre-
lates lead to other word senses. Cross references
for glosses produce an indexed unilingual diction-
ary, the start of a fully bilingual one.
To assist field work a small structured editor
for a systematically denormalized data base was
implemented in PTP under RT-11; Mumps would now be
easier to implement on small machines. It allowed
fields to be repeated and nonatomic strings includ-
ed, and produced cross reference entries. It
served for a monograph on a language of Mexicoi
and for student projects from Africa and Asia.
</bodyText>
<sectionHeader confidence="0.725648" genericHeader="method">
I LEXICOGRAPHY
</sectionHeader>
<bodyText confidence="0.994128850746269">
Natural language dictionaries seem like obvious
candidates for information management in data base
form, at least until you try to do one. Then it ap-
pears as if the better the dictionary in terms of
lexicographic theory, the more awkward it is to
fit relational constraints. Vest pocket tourist
dictionaries are a snap; Webster&apos;s Collegiate and
parser dictionaries require careful thought; the
Mel&apos;chuk style of explanatory-combinatory diction-
ary forces us out of the strategies that work on
ordinary data bases.
In designing a tool to manage lexicographic
field work under the constraints of Mel&apos;chuk&apos;s
meaning-text model, the most fully specified one
available for detailed lexicography, I laid down
specifications in four areas. First, it must han-
dle all lexical correlates of the head word. Lex-
ical correlates relate to the head in ways that
have numerous parallels within the language. In
English, for example, we have nouns that denote
the doer of an action. Some, such as driver, writ-
er, builder, are morphologically transparent.
Others like pilot (from ay) and cook (from cook)
are not; yet they relate to the corresponding verbs
in the same way as the transparent ones do. Mel&apos; -
chuk and associates have identified about fifty
such types, or lexical functions, of which Si, the
habitual first substantive just illustrated, is
one.
These types appear to have analogous meanings in
different languages, though not all types are nec-
essarily used in every language, and the relative
popularity of each differs from one language to an-
other, as does the extent to which each is grammat-
icalized. For example, English has a rich vocabu-
lary of values for a relation called Magn (from
Latin magnus) that denotes the superlative degree
of its argument: Magn (sit) = tight, Magn (black)
= 1EL, pitch, coal, Mag-TI-Tleft) = hard, Magn (pIay)
= for all you&apos;re worth, and on and on. On the other
hand Huichol, a Uto-Aztecan language of Mexico I
have been working on since 1952, has no such vo-
cabulary; it uses the simple intensives yeme and
valicga for all this, and2picks up its lexical
richness in other areas.
Second, a theoretically sound definition uses
words that are themselves defined through as long
a chain as possible back to zero level words that
can be defined only in one of two ways: by accept-
ing that some definitions -- as few as possible --
may be circular, or by defining the zero level via
extralinguistic experiences. Some dictionaries de-
fine sweet circularly in terms of sugar and vice
versa; but one could also begin by passing the sug-
ar bowl and thus break the circularity. The tool
must help trace the use of defining words.
Third, the arguments in the semantic represen-
tation of a word have to relate explicitly to
grammatical elements like subjects and objects and
possessors: his projection of the budget and
1
NSF grant BNS-7906041 funded some of this work.
2 Huichol transcription follows Spanish except a
high back unrounded, &apos; glottal stop, &apos; high tone,
VV long syllable, rhythm break, x voiced retro-
flex alveopalatal fricative, r retroflex flap, cuV
labiovelar stop.
</bodyText>
<page confidence="0.998511">
38
</page>
<bodyText confidence="0.999969428571429">
please turn out the light each involve two argu-
ments to the main operative word (him and budget,
you and light), but the relationship is handled in
different grammatical frames.
Finally, the tool must run on the smallest,
most portable machine available, if necessary trad-
ing processing time for memory and external space.
</bodyText>
<sectionHeader confidence="0.96607" genericHeader="method">
II RELATIONS
</sectionHeader>
<bodyText confidence="0.999941979591838">
Relations were proposed by Codd and elaborated
on by Fagin, Ullman, and many others. They are un-
ordered sets of tuples, each of which contains an
ordered set of fields. Each field has a value tak-
en from a domain -- semantically, from a particu-
lar kind of information. In lexicography the tuples
correspond, not to entries in a dictionary, but to
subentries, each with a particular sense. Each
tuple contains fields for various aspects of the
form, meaning, meaning-to-form mapping, and use of
that sense.
For the update and retrieval operations defined
on relations to work right, the information stored
in a relation is normalized. Each field is restric-
ted to an atomic value; it says only one thing, not
a series of different things. No field appears more
than once in a tuple. Beyond these formal con-
straints are conceptual constraints based on the
fact that the information in some fields determines
what can be in other fields; Ullman spells out the
main kinds of such dependency.
It is possible, as Shu and associates show, to
normalize nearly any information structure by par-
titioning it into a set of normal form relations.
It can be presented to the user, however, in a view
that draws on all these relations but is not itself
in normal form.
Reconstituting a subentry from normal form
tuples was beyond the capacity of the equipment
that could be used in the field; it would have been
cripplingly slow. Before sealed Winchester disks
came out, floppies were unreliable in tropical hu-
midity where the work was to be done, and only
small digital tape cartridges were thoroughly reli-
able. So the organization had to be managed by se-
quential merges across a series of small (.25M)
tapes without random access.
The requirements of normal form came to be an
issue in three areas. First, the prosaic matter of
examples violates normal form. Nearly any field in
a dictionary can take any number of illustrative
examples.
Second, the actants or arguments at the level of
semantic representation that corresponds to the
definition are in a theoretical status that is not
yet clear. Mellchuk (1981) simply numbers the act-
ants in a way that allows them to map to gram-
matical relations in as general a way as possible.
Others, myself included, find recurring components
of definitions on the order of Fillmore&apos;s cases
(1968) that are at least as consistently motivated
as are the lexical functions, and that map as sets
of actants to sets of grammatical relations. Rather
than load the dice at this uncertain stage by des-
ignating either numbered or labeled actants as dis-
tinct field types, it furthers discussion to be
able to have Actant as a single field type that is
repeatable, and whose value in each instance is a
link between an actant number, a proposed case, and
even possibly a conceptual dependency category for
comparison (Schenk and Abelson, 1977.11-17).
Third, lexical correlates are inherently many-
to-one. For example, Huichol quii &apos;house&apos; in its
sense labeled 1.1 &apos;where a person lives&apos; has sever-
al antonyms: Ant (gun. 1.1) = taa.curta &apos;space in
front of a house&apos;, quii.ru`ga &apos;space behind a the
house&apos;, tei.cugrie &apos;space outside the fence&apos;, and
an adverbial use of taa.cuga &apos;outdoors&apos; (Grimes,
1981.88).
One could normalize the cases of all three
types. But both lexicographers and users expect the
information to be in nonnormal form. Furthermore,
we can make a realistic assumption that relational
operations on a field are satisfied when there is
one instance of that field that satisfies them.
This is probably fatal for joins like &amp;quot;get me the
Huichol word for &apos;travel&apos;, then merge its defini-
tion with the definitions of all other words whose
agent and patient are inherently coreferential and
involve motion&apos;. But that kind of capability is be-
yond a small implementation anyway; the lexicogra-
pher who makes that kind of pass needs a large
scale, fully normalized system. The kinds of selec-
tions one usually does can be aimed at any instance
of a field, and projections can produce all in-
stances of a field, quite happily for most work,
and at an order of magnitude lower cost.
The important thing is to denormalize systemat-
ically so that normal form can be recovered when
it is needed. Actants denormalize to fields repeat-
ed in a specified order. Examples denormalize to
strings of examples appended to whatever field
they illustrate. Lexical correlates denormalize to
strings of values of particular functions, as in
the antonym example just given. The functions them-
selves are ordered by a conventional list that
groups similar functions together (Grimes 1981.288-
291).
</bodyText>
<sectionHeader confidence="0.992366" genericHeader="method">
III CROSS REFERENCING
</sectionHeader>
<bodyText confidence="0.999979176470588">
To build a dictionary consistently along the
lines chosen, a computational tool needs to incor-
porate cross referencing. This means that for each
field that is built, dummy entries are created for
all or most of the words in the field.
For example, the definition for, &apos;opossum&apos;, ygu-
xu, includes clauses like caytiu.yuurime ficug&apos;aa
&apos;eats things that are not green&apos; and pile axi.m e -
se &apos;its tail is bare&apos;. From these notes are gener-
ated that guarantee that each word used in the def-
inition will ultimately either get defined itself
or will be tagged yuungitti mepiimulate &apos;everybody
knows it&apos; to identify it as a zero level form that
is undefinable. Each note tells what subentry its
own head word is taken out of, and what field;
this information is merged into a repeatable Notes
field in the new entry. Under the stem. yuuri B &apos;be
</bodyText>
<page confidence="0.998672">
39
</page>
<bodyText confidence="0.999987641975309">
alive, grow&apos; appears the note d (yeuxu) cayllu.riu -
rime pficua&apos;aa &apos;eats things that are not green&apos;.
This is a reminder to the lexicographer, first that
there needs to be an entry for yuuri in sense B,
and second that it needs to account at the very
least for the way that stem is used in the defini-
tion (d) field of the entry for yeuxu.
Cross referencing to guarantee full coverage of
all words that are used in definitions backs up a
theoretical claim about definitional closure: the
state where no matter how many words are added to
the dictionary, all the words used to define them
are themselves already defined, back to a finite
set of zero level defining vocabulary. There is no
claim-that such a set is the only one possible; on-
ly that at least one such set is ppssible. To reach
closure even on a single set is such an immense
task -- I spent eight months full time on Huichol
lexicography and didn&apos;t get even a twentieth of the
everyday vocabulary defined -- that it can be ap-
proached only by some such systematic means.
There are sets of conformable definitions that
share most parts of their definitions, yet are not
synonyms. Related species and groups of animals and
plants have conformable definitions that are large-
ly identical, but have differentiating parts as
well (Grimes 1980). The same is true of sets of
verbs like ca/tei &apos;be sitting somewhere&apos;, ve/&apos;u &apos;be
standing somewhere&apos;, ma/mane &apos;be spread out some-
where&apos;, and ca/he &apos;be laid out straight some-
where&apos; (the slash separatesunitary and multiple
reference stems), which all share as part of their
definitions Iee.ntireu.teevi X -sie cayupattlt8 xati. -
sie spend an extended time at X without changing
to another location&apos;, but differ regarding the
spatial orientation of what is at X. Cross refer-
encing of words in definitions helps identify
these cases.
Values of lexical functions are not always com-
pletely specified by the lexical function and the
head word, so they are always cross referenced to
create the opportunity for saying more about them.
Qui 1.1 &apos;house&apos; in the sense of &apos;habitation of hu-
mansiâ€”Nersus &apos;stable&apos; or &apos;lair&apos; or &apos;hangar&apos; 1.2
and &apos;ranch&apos; 1.3) is pretty well defined by the
function S2&apos; substantive of the second actant, plus
the head verb ca/tei l.2 &apos;live in a house&apos; (versus
&apos;be sitting somewhere&apos; ll and &apos;live in a locality&apos;
1.3). Nevertheless it hall fifteen lexical functions
of its own, including the antonym set given ear-
lier, and only one of those functions matches one
of the nine that are associated with ca/tei 1.2:
Si (ca/tei 1.2) = S2 (gun. 1.1) = quie.cgme &apos;inhab-
itant, householder&apos;.
Stepping outside the theoretical constraints of
lexicography proper, the same cross referencing
mechanism helps set up bilingual dictionaries. Def-
initions are always in the language of the entries,
but it is useful in many situations to gloss the
definitions in some language of scientific dis-
course or trade, then cross reference on the glos-
ses by adding a tag that puts the notes from them
into a separate section. I have done this both for
Spanish, the national language of the country where
Huichol is spoken, and for Latin, the language of
the Linnean names of life forms. What results is
not really a bilingual dictionary, because it ex-
plains nothing at all about the second or third
language -- no definitions, no mapping between
grammatical relations and actants, no lexical func-
tions for that language. It simply gives examples
of counterparts of glosses. As such, however, it is
no less useful than some bilingual dictionaries. To
be consistent, the entries on the second language
side would have to be as full as the first language
entries, and some mechanism would have to be intro-
duced for distinguishing translation equivalents
rather than just senses in each language. As it is,
cross referencing the glosses gives what is prop-
erly called an indexed unilingual dictionary as a
handy intermediate stage.
</bodyText>
<sectionHeader confidence="0.914302" genericHeader="method">
IV IMPLENENTATION
</sectionHeader>
<bodyText confidence="0.999957630434783">
Because of the field situation for which the
computational tool was required, it was implement-
ed first in 1979 on an 8080 microcomputer with 32K
of memoryi6d two 130K sequentially accessible tape
cartridges as an experimental package, later moved
to an LSI-11/2 under RT-ll with .25M tapes. The
language used was Simons&apos;s PTP (1984), designed
for perspicuous handling of linguistic data. Data
management as done record by record to maintain
integrity, but the normal form constraints on at-
omicity and singularity of fields were dropped.
Functions were implemented as subtypes of a single
field type, ordered with reference to a special
list.
Because dictionary users expect ordered records,
that constraint was added, with provision for map-
ping non-ASCII sort sequences to an ASCII sort key
that controlled merging.
Data entry and merging both put new instances
of fields after existing instances of the same
field, but this order of inclusion could be modi-
fied by the editor. Furthermore, multiple instances
of a field could be collapsed into a single non-
atomic value with separator symbols in it, or such
a string value could be returned to multiple in-
stances, both by the editor. Transformations be -
tween&apos;repeated fields, strings of atomic values,
and various normal forms were worked out with Gary
Simons but not implemented.
Cross referencing was done in two ways: automat-
ically for values of lexical functions, and by
means of tags written in while editing for any
field. Tags directed the processor to build a cross
reference note for a full word, prefix, stem, or
suffix, and to file it in the first, second, or
third language part. In every case the lexicogra-
pher had opportunity to edit in order to remove ir-
relevant material and to associate the correct name
form.
Besides the major project in Huichol, the system
was used by students for original lexicographic
work in Dinka of the Sudan, Korean, and Isnag of
the Philippines. If I were to rebuild the system
now, I would probably use the University of Cali-
fornia at Davis&apos;s CP/M version of Mumps on a port-
able Winchester machine in order to have total
</bodyText>
<page confidence="0.994415">
40
</page>
<bodyText confidence="0.999810333333333">
random access in portable form. The strategy of da-
ta management, however, would remain the same, as
it fits the application area well. I suspect, but
have not proved, that full normalization capability
provided by random access would still turn out un-
acceptably slow on a small machine.
</bodyText>
<sectionHeader confidence="0.554334" genericHeader="method">
V DISCUSSION
</sectionHeader>
<bodyText confidence="0.983417421052632">
Investigation of a language centers around four
collections of information that computationally
are like data bases: field notes, text collection
with glosses and translations, grammar, and dic-
tionary. The first two fit the relational para-
digm easily, and are especially useful when sup-
plemented with functions that display glosses in-
terlinearly.
The grammar and dictionary, however, require de-
normalization in order to handle multiple examples,
and dictionaries require the other kinds of denorm-
alization that are presented here. Ideally those
examples come out of the field notes and texts,
where they are discovered by an automatic parsing
component of the grammar that is used by the selec-
tion algorithm, and they are attached to the ap-
propriate spots in the grammar and dictionary by
relational join operations.
VI REFERENCES
</bodyText>
<reference confidence="0.959377452380952">
Codd, E. F. 1970. A relational model for large
shared data banks. Communications of the ACM
13:6.377-387.
Fagin, R. 1979. A normal form for relational data-
bases that is based on domains and keys. IBM
Research Report RJ 2520.
Fillmore, Charles J. 1968. The case for case. In
Emmon Bach and Robert T. Harms, eds., Univers-
als in linguistic theory, New York: Holt, Rine-
hart and Winston, 1-88.
Grimes, Joseph E. 1980. Huichol life form clas-
sification I: Animals. Anthropological Linguist-
ics 22:5.187-200. II: Plants. Anthropological
Linguistics 22:6.264-274.
. 1981. El huichol: apuntes sabre el 14xico
[Huichol: notes on the lexicon], with P. de la
Cruz, J. Carrillo, F. Diaz, R. Diaz, and A. de
la Rosa. ERIC document ED 210 901, microfiche.
Kaplan, Ronald M. and Joan Bresnan. 1982. Lexical-
functional grammar: a formal system for gram-
matical representation. In Joan Bresnan, ed.
The mental representation of grammatical rela-
tions, Cambridge: The MIT Press, 173-281.
Mellchuk, Igor A. 1981. Meaning-text models: a
recent trend in Soviet linguistics. Annual Re-
view of Anthropology 10:27-62.
, A. K. Zholkovsky, and Ju. D. Apresyan. in
press. Tolkovo-kombinatornyj slovar&apos; russkogo
jazyka (with English introduction). Vienna:
Wiener Slawistischer Almanach.
Schenk, Roger C. and Robert P. Abelson. 1977.
Scripts, plans, goals and understanding: an in-
quiry into human knowledge structures. Hillsdale
NJ: Lawrence Erlbaum Associates.
Simons, Gary F. 1984. Powerful ideas for text pro-
cessing. Dallas: Summer Institute of Linguist-
ics.
Ullman, Jeffrey D. 1980. Principles of database
systems. Rockville MD: Computer Science Press.
Wong, H. K. T. and N. C. Shu. 1980. An approach to
relational data base scheme design. IBM Computer
Science Research Report RJ 2688.
</reference>
<page confidence="0.999443">
41
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.049750">
<title confidence="0.998363">DENORMALIZATION AND CROSS REFERENCING IN THEORETICAL LEXICOGRAPHY</title>
<author confidence="0.999903">Joseph E Grimes</author>
<affiliation confidence="0.999196">DMLL, Morrill Hall, Cornell University</affiliation>
<address confidence="0.986475">Ithaca NY 14853 USA</address>
<affiliation confidence="0.988151">Summer Institute of Linguistics</affiliation>
<address confidence="0.977431">7500 West Camp Wisdom Road Dallas TX 75236 USA</address>
<abstract confidence="0.995526765013055">A computational vehicle for lexicography was designed to keep to the constraints of meaningtext theory: sets of lexical correlates, limits on the form of definitions, and argument relations similar to lexical-functional grammar. Relational data bases look like a natural framework for this. But linguists operate with a nonnormalized view. Mappings between semantic actants and grammatical relations do not fit actant fields uniquely. Lexical correlates and examples are polyvalent, hence denormalized. Cross referencing routines help the lexicographer work toward a closure state in which every term of a definition traces back to zero level terms defined extralinguistically or circularly. Dummy entries produced from defining terms ensure no trace is overlooked. Values of lexical correlates lead to other word senses. Cross references for glosses produce an indexed unilingual dictionary, the start of a fully bilingual one. To assist field work a small structured editor for a systematically denormalized data base was implemented in PTP under RT-11; Mumps would now be easier to implement on small machines. It allowed fields to be repeated and nonatomic strings included, and produced cross reference entries. It for a monograph on a language of and for student projects from Africa and Asia. I LEXICOGRAPHY Natural language dictionaries seem like obvious candidates for information management in data base form, at least until you try to do one. Then it appears as if the better the dictionary in terms of lexicographic theory, the more awkward it is to fit relational constraints. Vest pocket tourist dictionaries are a snap; Webster&apos;s Collegiate and parser dictionaries require careful thought; the Mel&apos;chuk style of explanatory-combinatory dictionary forces us out of the strategies that work on ordinary data bases. In designing a tool to manage lexicographic field work under the constraints of Mel&apos;chuk&apos;s meaning-text model, the most fully specified one available for detailed lexicography, I laid down specifications in four areas. First, it must handle all lexical correlates of the head word. Lexical correlates relate to the head in ways that have numerous parallels within the language. In English, for example, we have nouns that denote doer of an action. Some, such as driver,writbuilder,are morphologically transparent. like pilot(from ay) and cook (from cook) are not; yet they relate to the corresponding verbs in the same way as the transparent ones do. Mel&apos; chuk and associates have identified about fifty types, or lexical functions, of which the habitual first substantive just illustrated, is one. These types appear to have analogous meanings in different languages, though not all types are necessarily used in every language, and the relative popularity of each differs from one language to another, as does the extent to which each is grammaticalized. For example, English has a rich vocabuof values for a relation called Magn(from magnus)that denotes the superlative degree its argument: Magn (sit) = tight,Magn (black) 1EL, pitch,coal, = hard, Magn (pIay) for all you&apos;reworth, and on and on. On the other hand Huichol, a Uto-Aztecan language of Mexico I have been working on since 1952, has no such voit uses the simple intensives yemeand for all this, up its lexical richness in other areas. Second, a theoretically sound definition uses words that are themselves defined through as long a chain as possible back to zero level words that can be defined only in one of two ways: by accepting that some definitions -as few as possible -may be circular, or by defining the zero level via extralinguistic experiences. Some dictionaries desweet circularly in terms of sugarand vice versa; but one could also begin by passing the sugar bowl and thus break the circularity. The tool must help trace the use of defining words. Third, the arguments in the semantic representation of a word have to relate explicitly to grammatical elements like subjects and objects and his projectionof the budgetand 1 NSF grant BNS-7906041 funded some of this work. transcription follows Spanish except high back unrounded, &apos; glottal stop, &apos; high tone, VV long syllable, rhythm break, x voiced retroflex alveopalatal fricative, r retroflex flap, cuV labiovelar stop. 38 pleaseturn out the lighteach involve two arguto the main operative word (him and youand light),but the relationship is handled in different grammatical frames. Finally, the tool must run on the smallest, most portable machine available, if necessary trading processing time for memory and external space. II RELATIONS Relations were proposed by Codd and elaborated on by Fagin, Ullman, and many others. They are unordered sets of tuples, each of which contains an ordered set of fields. Each field has a value taken from a domain -semantically, from a particular kind of information. In lexicography the tuples correspond, not to entries in a dictionary, but to subentries, each with a particular sense. Each tuple contains fields for various aspects of the form, meaning, meaning-to-form mapping, and use of that sense. For the update and retrieval operations defined on relations to work right, the information stored in a relation is normalized. Each field is restricted to an atomic value; it says only one thing, not a series of different things. No field appears more than once in a tuple. Beyond these formal constraints are conceptual constraints based on the fact that the information in some fields determines what can be in other fields; Ullman spells out the main kinds of such dependency. It is possible, as Shu and associates show, to normalize nearly any information structure by partitioning it into a set of normal form relations. It can be presented to the user, however, in a view on all these relations but is not itself in normal form. Reconstituting a subentry from normal form tuples was beyond the capacity of the equipment that could be used in the field; it would have been cripplingly slow. Before sealed Winchester disks came out, floppies were unreliable in tropical humidity where the work was to be done, and only small digital tape cartridges were thoroughly reliable. So the organization had to be managed by sequential merges across a series of small (.25M) tapes without random access. The requirements of normal form came to be an issue in three areas. First, the prosaic matter of examples violates normal form. Nearly any field in a dictionary can take any number of illustrative examples. Second, the actants or arguments at the level of semantic representation that corresponds to the definition are in a theoretical status that is not clear. Mellchuk (1981) simply numbers the actin a way that allows them to map to matical relations in as general a way as possible. Others, myself included, find recurring components of definitions on the order of Fillmore&apos;s cases (1968) that are at least as consistently motivated as are the lexical functions, and that map as sets of actants to sets of grammatical relations. Rather than load the dice at this uncertain stage by designating either numbered or labeled actants as distinct field types, it furthers discussion to be able to have Actant as a single field type that is repeatable, and whose value in each instance is a link between an actant number, a proposed case, and even possibly a conceptual dependency category for comparison (Schenk and Abelson, 1977.11-17). Third, lexical correlates are inherently many- For example, Huichol quii&apos;house&apos; in its sense labeled 1.1 &apos;where a person lives&apos; has severantonyms: Ant (gun.1.1) = taa.curta&apos;space of a house&apos;, quii.ru`ga&apos;space behind a the tei.cugrie&apos;space outside the fence&apos;, and adverbial use of taa.cuga&apos;outdoors&apos; (Grimes, 1981.88). One could normalize the cases of all three types. But both lexicographers and users expect the information to be in nonnormal form. Furthermore, we can make a realistic assumption that relational operations on a field are satisfied when there is one instance of that field that satisfies them. This is probably fatal for joins like &amp;quot;get me the Huichol word for &apos;travel&apos;, then merge its definition with the definitions of all other words whose agent and patient are inherently coreferential and involve motion&apos;. But that kind of capability is beyond a small implementation anyway; the lexicographer who makes that kind of pass needs a large scale, fully normalized system. The kinds of selections one usually does can be aimed at any instance of a field, and projections can produce all instances of a field, quite happily for most work, and at an order of magnitude lower cost. The important thing is to denormalize systematically so that normal form can be recovered when it is needed. Actants denormalize to fields repeated in a specified order. Examples denormalize to strings of examples appended to whatever field they illustrate. Lexical correlates denormalize to strings of values of particular functions, as in the antonym example just given. The functions themselves are ordered by a conventional list that similar functions together (Grimes 1981.288- 291). III CROSS REFERENCING To build a dictionary consistently along the lines chosen, a computational tool needs to incorporate cross referencing. This means that for each field that is built, dummy entries are created for all or most of the words in the field. example, the definition &apos;opossum&apos;, yguincludes clauses like caytiu.yuurimeficug&apos;aa things that are not green&apos; and axi.m e se &apos;its tail is bare&apos;. From these notes are generated that guarantee that each word used in the definition will ultimately either get defined itself will be tagged mepiimulate&apos;everybody knows it&apos; to identify it as a zero level form that is undefinable. Each note tells what subentry its own head word is taken out of, and what field; this information is merged into a repeatable Notes in the new entry. Under the stem. yuuriB &apos;be 39 grow&apos; appears the note d cayllu.riupficua&apos;aa&apos;eats things that are not green&apos;. This is a reminder to the lexicographer, first that needs to be an entry for yuuriin sense B, and second that it needs to account at the very least for the way that stem is used in the defini- (d) field of the entry for yeuxu. Cross referencing to guarantee full coverage of all words that are used in definitions backs up a theoretical claim about definitional closure: the state where no matter how many words are added to the dictionary, all the words used to define them are themselves already defined, back to a finite set of zero level defining vocabulary. There is no claim-that such a set is the only one possible; only that at least one such set is ppssible. To reach closure even on a single set is such an immense task -- I spent eight months full time on Huichol lexicography and didn&apos;t get even a twentieth of the everyday vocabulary defined -that it can be approached only by some such systematic means. There are sets of conformable definitions that share most parts of their definitions, yet are not synonyms. Related species and groups of animals and plants have conformable definitions that are largely identical, but have differentiating parts as well (Grimes 1980). The same is true of sets of like ca/tei &apos;be sitting somewhere&apos;, ve/&apos;u&apos;be somewhere&apos;, ma/mane&apos;be spread out someand ca/he&apos;be laid out straight somewhere&apos; (the slash separatesunitary and multiple reference stems), which all share as part of their Iee.ntireu.teeviX -sie cayupattlt8xati. sie spend an extended time at X without changing to another location&apos;, but differ regarding the spatial orientation of what is at X. Cross referencing of words in definitions helps identify these cases. Values of lexical functions are not always completely specified by the lexical function and the head word, so they are always cross referenced to create the opportunity for saying more about them. Qui1.1 &apos;house&apos; in the sense of &apos;habitation of hu- &apos;stable&apos; or &apos;lair&apos; or &apos;hangar&apos; 1.2 and &apos;ranch&apos; 1.3) is pretty well defined by the of the second actant, plus head verb l.2&apos;live in a house&apos; (versus &apos;be sitting somewhere&apos; ll and &apos;live in a locality&apos; 1.3). Nevertheless it hall fifteen lexical functions of its own, including the antonym set given earlier, and only one of those functions matches one the nine that are associated with ca/tei1.2: (ca/tei1.2) = (gun.1.1) = quie.cgme&apos;inhabitant, householder&apos;. Stepping outside the theoretical constraints of lexicography proper, the same cross referencing mechanism helps set up bilingual dictionaries. Definitions are always in the language of the entries, but it is useful in many situations to gloss the definitions in some language of scientific discourse or trade, then cross reference on the glosses by adding a tag that puts the notes from them into a separate section. I have done this both for Spanish, the national language of the country where Huichol is spoken, and for Latin, the language of the Linnean names of life forms. What results is not really a bilingual dictionary, because it explains nothing at all about the second or third language -no definitions, no mapping between grammatical relations and actants, no lexical functions for that language. It simply gives examples counterparts of glosses. however, it is no less useful than some bilingual dictionaries. To be consistent, the entries on the second language side would have to be as full as the first language entries, and some mechanism would have to be introduced for distinguishing translation equivalents than just senses in each language. is, cross referencing the glosses gives what is properly called an indexed unilingual dictionary as a handy intermediate stage. IV IMPLENENTATION Because of the field situation for which the computational tool was required, it was implemented first in 1979 on an 8080 microcomputer with 32K of memoryi6d two 130K sequentially accessible tape cartridges as an experimental package, later moved an under RT-ll with .25M tapes. The language used was Simons&apos;s PTP (1984), designed for perspicuous handling of linguistic data. Data management as done record by record to maintain integrity, but the normal form constraints on atomicity and singularity of fields were dropped. Functions were implemented as subtypes of a single field type, ordered with reference to a special list. Because dictionary users expect ordered records, that constraint was added, with provision for mapsequences to an key that controlled merging. Data entry and merging both put new instances of fields after existing instances of the same field, but this order of inclusion could be modified by the editor. Furthermore, multiple instances of a field could be collapsed into a single nonatomic value with separator symbols in it, or such a string value could be returned to multiple instances, both by the editor. Transformations be tween&apos;repeated fields, strings of atomic values, and various normal forms were worked out with Gary Simons but not implemented. Cross referencing was done in two ways: automatically for values of lexical functions, and by means of tags written in while editing for any field. Tags directed the processor to build a cross reference note for a full word, prefix, stem, or suffix, and to file it in the first, second, or third language part. In every case the lexicographer had opportunity to edit in order to remove irrelevant material and to associate the correct name form. Besides the major project in Huichol, the system was used by students for original lexicographic work in Dinka of the Sudan, Korean, and Isnag of the Philippines. If I were to rebuild the system now, I would probably use the University of California at Davis&apos;s CP/M version of Mumps on a portable Winchester machine in order to have total 40 random access in portable form. The strategy of data management, however, would remain the same, as it fits the application area well. I suspect, but have not proved, that full normalization capability provided by random access would still turn out unacceptably slow on a small machine. V DISCUSSION Investigation of a language centers around four collections of information that computationally are like data bases: field notes, text collection with glosses and translations, grammar, and dictionary. The first two fit the relational paradigm easily, and are especially useful when supplemented with functions that display glosses interlinearly. The grammar and dictionary, however, require denormalization in order to handle multiple examples, and dictionaries require the other kinds of denormalization that are presented here. Ideally those examples come out of the field notes and texts, where they are discovered by an automatic parsing component of the grammar that is used by the selection algorithm, and they are attached to the appropriate spots in the grammar and dictionary by relational join operations. VI REFERENCES Codd, E. F. 1970. A relational model for large shared data banks. Communications of the ACM 13:6.377-387. Fagin, R. 1979. A normal form for relational databases that is based on domains and keys. IBM</abstract>
<note confidence="0.947471181818182">Research Report RJ 2520. Fillmore, Charles J. 1968. The case for case. In Emmon Bach and Robert T. Harms, eds., Universals in linguistic theory, New York: Holt, Rinehart and Winston, 1-88. Grimes, Joseph E. 1980. Huichol life form classification I: Animals. Anthropological Linguistics 22:5.187-200. II: Plants. Anthropological Linguistics 22:6.264-274. . 1981. El huichol: apuntes sabre el 14xico [Huichol: notes on the lexicon], with P. de la</note>
<author confidence="0.645172">J Carrillo Cruz</author>
<author confidence="0.645172">F Diaz</author>
<author confidence="0.645172">R Diaz</author>
<author confidence="0.645172">A de</author>
<note confidence="0.84098">la Rosa. ERIC document ED 210 901, microfiche. Kaplan, Ronald M. and Joan Bresnan. 1982. Lexicalfunctional grammar: a formal system for grammatical representation. In Joan Bresnan, ed. The mental representation of grammatical relations, Cambridge: The MIT Press, 173-281. Mellchuk, Igor A. 1981. Meaning-text models: a recent trend in Soviet linguistics. Annual Review of Anthropology 10:27-62. , A. K. Zholkovsky, and Ju. D. Apresyan. in press. Tolkovo-kombinatornyj slovar&apos; russkogo</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E F Codd</author>
</authors>
<title>A relational model for large shared data banks.</title>
<date>1970</date>
<journal>Communications of the ACM</journal>
<pages>13--6</pages>
<marker>Codd, 1970</marker>
<rawString>Codd, E. F. 1970. A relational model for large shared data banks. Communications of the ACM 13:6.377-387.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Fagin</author>
</authors>
<title>A normal form for relational databases that is based on domains and keys.</title>
<date>1979</date>
<journal>IBM Research Report RJ</journal>
<pages>2520</pages>
<marker>Fagin, 1979</marker>
<rawString>Fagin, R. 1979. A normal form for relational databases that is based on domains and keys. IBM Research Report RJ 2520.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles J Fillmore</author>
</authors>
<title>The case for case.</title>
<date>1968</date>
<booktitle>Universals in linguistic theory,</booktitle>
<pages>1--88</pages>
<editor>In Emmon Bach and Robert T. Harms, eds.,</editor>
<location>New York: Holt, Rinehart and Winston,</location>
<marker>Fillmore, 1968</marker>
<rawString>Fillmore, Charles J. 1968. The case for case. In Emmon Bach and Robert T. Harms, eds., Universals in linguistic theory, New York: Holt, Rinehart and Winston, 1-88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph E Grimes</author>
</authors>
<title>Huichol life form classification I: Animals. Anthropological Linguistics 22:5.187-200. II: Plants. Anthropological Linguistics</title>
<date>1980</date>
<pages>22--6</pages>
<contexts>
<context position="11744" citStr="Grimes 1980" startWordPosition="1970" endWordPosition="1971"> claim-that such a set is the only one possible; only that at least one such set is ppssible. To reach closure even on a single set is such an immense task -- I spent eight months full time on Huichol lexicography and didn&apos;t get even a twentieth of the everyday vocabulary defined -- that it can be approached only by some such systematic means. There are sets of conformable definitions that share most parts of their definitions, yet are not synonyms. Related species and groups of animals and plants have conformable definitions that are largely identical, but have differentiating parts as well (Grimes 1980). The same is true of sets of verbs like ca/tei &apos;be sitting somewhere&apos;, ve/&apos;u &apos;be standing somewhere&apos;, ma/mane &apos;be spread out somewhere&apos;, and ca/he &apos;be laid out straight somewhere&apos; (the slash separatesunitary and multiple reference stems), which all share as part of their definitions Iee.ntireu.teevi X -sie cayupattlt8 xati. - sie spend an extended time at X without changing to another location&apos;, but differ regarding the spatial orientation of what is at X. Cross referencing of words in definitions helps identify these cases. Values of lexical functions are not always completely specified by t</context>
</contexts>
<marker>Grimes, 1980</marker>
<rawString>Grimes, Joseph E. 1980. Huichol life form classification I: Animals. Anthropological Linguistics 22:5.187-200. II: Plants. Anthropological Linguistics 22:6.264-274.</rawString>
</citation>
<citation valid="true">
<title>El huichol: apuntes sabre el 14xico [Huichol: notes on the lexicon], with P. de la</title>
<date>1981</date>
<journal>ERIC document ED</journal>
<volume>210</volume>
<pages>901</pages>
<contexts>
<context position="7091" citStr="(1981)" startWordPosition="1173" endWordPosition="1173">humidity where the work was to be done, and only small digital tape cartridges were thoroughly reliable. So the organization had to be managed by sequential merges across a series of small (.25M) tapes without random access. The requirements of normal form came to be an issue in three areas. First, the prosaic matter of examples violates normal form. Nearly any field in a dictionary can take any number of illustrative examples. Second, the actants or arguments at the level of semantic representation that corresponds to the definition are in a theoretical status that is not yet clear. Mellchuk (1981) simply numbers the actants in a way that allows them to map to grammatical relations in as general a way as possible. Others, myself included, find recurring components of definitions on the order of Fillmore&apos;s cases (1968) that are at least as consistently motivated as are the lexical functions, and that map as sets of actants to sets of grammatical relations. Rather than load the dice at this uncertain stage by designating either numbered or labeled actants as distinct field types, it furthers discussion to be able to have Actant as a single field type that is repeatable, and whose value in</context>
</contexts>
<marker>1981</marker>
<rawString>. 1981. El huichol: apuntes sabre el 14xico [Huichol: notes on the lexicon], with P. de la Cruz, J. Carrillo, F. Diaz, R. Diaz, and A. de la Rosa. ERIC document ED 210 901, microfiche.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald M Kaplan</author>
<author>Joan Bresnan</author>
</authors>
<title>Lexicalfunctional grammar: a formal system for grammatical representation.</title>
<date>1982</date>
<pages>173--281</pages>
<editor>In Joan Bresnan, ed.</editor>
<publisher>The MIT Press,</publisher>
<location>Cambridge:</location>
<marker>Kaplan, Bresnan, 1982</marker>
<rawString>Kaplan, Ronald M. and Joan Bresnan. 1982. Lexicalfunctional grammar: a formal system for grammatical representation. In Joan Bresnan, ed. The mental representation of grammatical relations, Cambridge: The MIT Press, 173-281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Igor A Mellchuk</author>
</authors>
<title>Meaning-text models: a recent trend in Soviet linguistics.</title>
<date>1981</date>
<journal>Annual Review of Anthropology</journal>
<pages>10--27</pages>
<contexts>
<context position="7091" citStr="Mellchuk (1981)" startWordPosition="1172" endWordPosition="1173">tropical humidity where the work was to be done, and only small digital tape cartridges were thoroughly reliable. So the organization had to be managed by sequential merges across a series of small (.25M) tapes without random access. The requirements of normal form came to be an issue in three areas. First, the prosaic matter of examples violates normal form. Nearly any field in a dictionary can take any number of illustrative examples. Second, the actants or arguments at the level of semantic representation that corresponds to the definition are in a theoretical status that is not yet clear. Mellchuk (1981) simply numbers the actants in a way that allows them to map to grammatical relations in as general a way as possible. Others, myself included, find recurring components of definitions on the order of Fillmore&apos;s cases (1968) that are at least as consistently motivated as are the lexical functions, and that map as sets of actants to sets of grammatical relations. Rather than load the dice at this uncertain stage by designating either numbered or labeled actants as distinct field types, it furthers discussion to be able to have Actant as a single field type that is repeatable, and whose value in</context>
</contexts>
<marker>Mellchuk, 1981</marker>
<rawString>Mellchuk, Igor A. 1981. Meaning-text models: a recent trend in Soviet linguistics. Annual Review of Anthropology 10:27-62.</rawString>
</citation>
<citation valid="false">
<authors>
<author>D Apresyan</author>
</authors>
<title>in press. Tolkovo-kombinatornyj slovar&apos; russkogo jazyka (with English introduction). Vienna: Wiener Slawistischer Almanach.</title>
<marker>Apresyan, </marker>
<rawString>, A. K. Zholkovsky, and Ju. D. Apresyan. in press. Tolkovo-kombinatornyj slovar&apos; russkogo jazyka (with English introduction). Vienna: Wiener Slawistischer Almanach.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger C Schenk</author>
<author>Robert P Abelson</author>
</authors>
<title>Scripts, plans, goals and understanding: an inquiry into human knowledge structures. Hillsdale NJ: Lawrence Erlbaum Associates.</title>
<date>1977</date>
<contexts>
<context position="7850" citStr="Schenk and Abelson, 1977" startWordPosition="1301" endWordPosition="1304">ncluded, find recurring components of definitions on the order of Fillmore&apos;s cases (1968) that are at least as consistently motivated as are the lexical functions, and that map as sets of actants to sets of grammatical relations. Rather than load the dice at this uncertain stage by designating either numbered or labeled actants as distinct field types, it furthers discussion to be able to have Actant as a single field type that is repeatable, and whose value in each instance is a link between an actant number, a proposed case, and even possibly a conceptual dependency category for comparison (Schenk and Abelson, 1977.11-17). Third, lexical correlates are inherently manyto-one. For example, Huichol quii &apos;house&apos; in its sense labeled 1.1 &apos;where a person lives&apos; has several antonyms: Ant (gun. 1.1) = taa.curta &apos;space in front of a house&apos;, quii.ru`ga &apos;space behind a the house&apos;, tei.cugrie &apos;space outside the fence&apos;, and an adverbial use of taa.cuga &apos;outdoors&apos; (Grimes, 1981.88). One could normalize the cases of all three types. But both lexicographers and users expect the information to be in nonnormal form. Furthermore, we can make a realistic assumption that relational operations on a field are satisfied when t</context>
</contexts>
<marker>Schenk, Abelson, 1977</marker>
<rawString>Schenk, Roger C. and Robert P. Abelson. 1977. Scripts, plans, goals and understanding: an inquiry into human knowledge structures. Hillsdale NJ: Lawrence Erlbaum Associates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gary F Simons</author>
</authors>
<title>Powerful ideas for text processing. Dallas: Summer Institute of Linguistics.</title>
<date>1984</date>
<marker>Simons, 1984</marker>
<rawString>Simons, Gary F. 1984. Powerful ideas for text processing. Dallas: Summer Institute of Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey D Ullman</author>
</authors>
<title>Principles of database systems.</title>
<date>1980</date>
<publisher>Computer Science Press.</publisher>
<location>Rockville MD:</location>
<marker>Ullman, 1980</marker>
<rawString>Ullman, Jeffrey D. 1980. Principles of database systems. Rockville MD: Computer Science Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H K T Wong</author>
<author>N C Shu</author>
</authors>
<title>An approach to relational data base scheme design.</title>
<date>1980</date>
<journal>IBM Computer Science Research Report RJ</journal>
<pages>2688</pages>
<marker>Wong, Shu, 1980</marker>
<rawString>Wong, H. K. T. and N. C. Shu. 1980. An approach to relational data base scheme design. IBM Computer Science Research Report RJ 2688.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>