<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000952">
<title confidence="0.999700333333334">
Text Alignment in the Real World: Improving Alignments of Noisy
Translations Using Common Lexical Features, String Matching Strategies
and N-Gram Comparisons&apos;
</title>
<author confidence="0.995463">
Mark W. Davis, Ted E. Dunning and William C. Ogden
</author>
<affiliation confidence="0.879722">
Computing Research Laboratory
New Mexico State University
</affiliation>
<address confidence="0.781551333333333">
Box 30001/3CRL
Las Cruces, New Mexico
USA
</address>
<email confidence="0.984998">
{ madavis,ted,ogden } @crl.nmsu.edu
</email>
<sectionHeader confidence="0.995274" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999800130434783">
Alignment methods based on byte-length
comparisons of alignment blocks have been
remarkably successful for aligning good
translations from legislative transcriptions.
For noisy translations in which the parallel
text of a document has significant structural
differences, byte-alignment methods often
do not perform well. The Pan American
Health Organization (PAHO) corpus is a
series of articles that were first translated by
machine methods and then improved by pro-
fessional translators. Many of the Spanish
PAHO texts do not share formatting conven-
tions with the corresponding English docu-
ments, refer to tables in stylistically different
ways and contain extraneous information. A
method based on a dynamic programming
framework, but using a decision criterion
derived from a combination of byte-length
ratio measures, hard matching of numbers,
string comparisons and n-gram co-occur-
rence matching substantially improves the
performance of the alignment process.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998276102040817">
Given texts in two languages that are to some degree
translations of one another, an alignment of the texts
associates sentences, paragraphs or phrases in one
document with their translations in the other. Success-
ful approaches to alignment can be divided into two
primary types: those that use comparisons of lexical
elements between the documents (Wu, 1994; Chen
1993; Catizone, Russell and Warwick, 1989), and
&apos;This research was funded under DoD Contract
#MDA 904-94-C-E086
those that use a statistical decision process derived
from byte-length ratios between alignment blocks
(Wu, 1994; Church, 1993; Gale and Church, 1991).
Methods vary for the former approach, but in the lat-
ter approach, a dynamic programming framework is
used to sequentially align blocks as the alignment pro-
cess proceeds. Under this model, blocks are compared
only with nearby blocks as the alignment proceeds,
substantially reducing the computational overhead
[0(n2) « 0(n!)] of the alignment process.
In the primary literature on alignment, the texts are
typically well-behaved. In byte-length ratio
approaches, the presence of long stretches of blocks
that have roughly similar lengths can be problematic,
and some improvement can be achieved by augment-
ing the byte-length measure by scores derived from
lexical feature matching (Wu, 1994). When combined
with radical formatting departures between docu-
ments that often arise in text translations, the difficul-
ties of producing good alignments are exacerbated by
the presence of untranslated segments, textual rear-
rangements and other problematic text features. The
dynamic programming framework makes long runs of
segments that have no translation in their parallel text
difficult to ignore because the limited window size
prevents passing over those segments to reach appro-
priate areas of the document further downstream.
Taken together, these difficulties can be catastrophic
to the alignment process. Our experience shows that
the fraction of correct alignments can drop to less than
5%.
Noisy translations of this sort do reflect human
error and the preferences of translators, and they are
probably much more prevalent than alignment work
on legislative transcriptions has indicated. The pur-
pose of this research was to ascertain what types of
information contained in a document could be used to
improve the alignment process, while not making
gross assumptions about the source text format con-
</bodyText>
<page confidence="0.998998">
67
</page>
<bodyText confidence="0.9998153">
ventions and peculiarities. The Pan American Health
Organization (PAHO) corpus was used as a test cor-
pus for evaluating the performance of the modified
alignment algorithm. The PAHO texts are a series of
documents on Latin American health issues and our
test segment consisted of 180 documents that ranged
from 20 to 3825 lines in length. From these docu-
ments, several of the more problematic texts were
hand aligned for analysis and comparison with the
results of automatic alignment methods.
</bodyText>
<sectionHeader confidence="0.940678" genericHeader="introduction">
2 A General Approach
</sectionHeader>
<bodyText confidence="0.99004309375">
The byte-length ratio methods are very general in that
they rely only upon a heuristic segmentation proce-
dure to divide a text into sentence-level chunks.
Although determining sentence boundaries can be
problematic across languages, simple assumptions
appear to work well even for comparisons between
European and Oriental languages, primarily because
the segmentation heuristic is uniformly applied to
each document and therefore an &amp;quot;undersegmented&amp;quot;
section can combine together to match with single
blocks in the opposite language as necessary.
Less general would be a method that relied on deep
analysis of the source texts to determine appropriate
boundaries for alignment blocks. A model that
accounted for all of the formatting discrepancies,
comparative rescalings of sentence or phrase length
due to the economy of the language expression, and
other properties that may define a corpus, will not
necessarily be appropriate to other corpora or to text
in general.
We chose to remain as general as possible with our
investigations of alignment methods. In particular, the
heuristics for text segmentation regarded periods fol-
lowed by a space, a newline (paragraph boundaries)
or a tab as a sentence boundary for both English and
Spanish texts (Figure 1). Multiple periods separated
by spaces were ignored for alignment segmentation to
the
Region in 1990, summarizing the information obtained
from the
Governments in response to the questionnaire sent to them
annually.
</bodyText>
<sectionHeader confidence="0.652623" genericHeader="method">
INTRODUCCION
</sectionHeader>
<bodyText confidence="0.775910333333333">
La situacion de la malaria en el mundo se refiere a 1989,
ha sido tomada de publicaciones de la Organizacion Mun-
dial de la
</bodyText>
<figure confidence="0.9192959375">
Salud.
SITUACIN DE LA MALARIA EN EL MUNDO
Poblacion en riesgo
Más del 40% de la poblacion mundial, o sea, ms de
2,000
millones de personas, permanecen expuestas a diversos gra-
dos de
riesgo de malaria en unos 100 paises o tenitorios (Mapa 1).
XXXV Meeting
Washington, D.C.
• XLM Meeting
It describes the situation of malaria in
El presents documento es el XXXIX Informe sabre la
Situacidn
de Is Malaria ue ublica la OPS
comt■ rt5
</figure>
<figureCaption confidence="0.972683">
Figure 1: Sample English and Spanish texts with contiguous grey areas indicating alignment
blocks.
</figureCaption>
<page confidence="0.998621">
68
</page>
<bodyText confidence="0.9919655">
allow for ellipsis. This approach did not, therefore,
regard many abbreviations as a unique class of tex-
tual event. The end result was an extremely simplis-
tic segmentation.
</bodyText>
<sectionHeader confidence="0.983349" genericHeader="method">
3 The PAHO Corpus: Noisy,
</sectionHeader>
<subsectionHeader confidence="0.683407">
Problematic Texts
</subsectionHeader>
<bodyText confidence="0.999484096774193">
The PAHO texts serve as an important counter-
part to our translator&apos;s workstation, Norm (Ogden,
1993). During the translation process, translators
can access many different resources including a
variety of on-line dictionaries, reference works and
parallel texts. The parallel texts include examples
of translations that different translators have com-
piled in the past and serve as a series of examples of
how to translate words and phrases for a particular
context. The PAHO texts also serve as a basis for
our multi-lingual information retrieval system
(Davis and Dunning, 1995; Dunning and Davis,
1993a, 1993b). The need for robust strategies to
process and align large parallel corpora automati-
cally is therefore a critical component of our ongo-
ing research.
In the PAHO corpus, many of the texts are well-
behaved, with similar tokenization at the bound-
aries delineating paragraphs. But some are
extremely noisy, with added text in the English or
Spanish document that lacks a counterpart in the
parallel document. Formatting conventions differ in
many cases, with multiple periods delimiting con-
tents listings in one, while spaces serve a similar
role in the other, or tables and reference formats dif-
fering between the two texts. Another formatting
problem is the addition of significant runs of
whitespace and newlines that simply do not occur
in the parallel text. The document pair shown in
Figure 1 is representative of the quality of the
PAHO texts.
</bodyText>
<sectionHeader confidence="0.998112" genericHeader="method">
4 Features and Alignment
</sectionHeader>
<bodyText confidence="0.99977255">
One of the most striking features of English-Span-
ish translations is the fact that native English speak-
ers with little knowledge of Spanish appear able to
identify parallel texts with remarkable accuracy.
The reason appears to be the large number of cog-
nate terms that Spanish and English translations
share, especially technical terms, and other lexical
features such as numbers and proper names that
may appear with similar placement and frequency
across two parallel texts. The work by Simard, Fos-
ter and Isabelle (1993) as well as Church (1993)
demonstrated that cognate-matching strategies can
be highly effective in aligning text. Native English
speakers with limited Spanish appear to be capable of
aligning even noisy texts like many of the PAHO doc-
uments, with difficulty causing a decrease in speed of
alignment, rather than decreased accuracy of the
alignment. From these observations, we examined
five different sources of information for alignment
discrimination:
</bodyText>
<listItem confidence="0.9999252">
• Byte-length ratios
• Unordered character n-gram comparisons
• Simple ordered string-matching
• Number matching
• Bilingual-dictionary translations
</listItem>
<bodyText confidence="0.9998894">
The analyses of each of these information sources are
presented in sections 5.1 through 5.5.
For each method, a hand-aligned document from
PAHO corpus that was problematic for byte-ratio
methods was used for evaluation, first for comparing
the method&apos;s score distribution between random
blocks and the hand-aligned set, then for performing
realignments of the documents. The document was
quite long for the PAHO set, containing about 1400
lines of text and 360 alignment blocks in the English
document and 1000 lines and 297 blocks in the Span-
ish text. In these particular documents, the English
text had nearly 400 lines of extraneous data abutted to
the end of it that was not in the Spanish document,
increasing the error potential for byte-length methods.
</bodyText>
<sectionHeader confidence="0.978018" genericHeader="method">
5 Improving Alignments
</sectionHeader>
<bodyText confidence="0.998387086956522">
We used a modified and extended version of Gale and
Church&apos;s byte-ratio algorithm (1991) as a basis for an
improved alignment algorithm. The standard algo-
rithm derives a penalty from a ratio of the byte lengths
of two potential aligned blocks and augments the pen-
alty with a factor based on the frequency of matches
between blocks in one language that equate to a block
or blocks in the second language. The byte-ratio pen-
alty is the measurement-conditioned or a posteriori
probability of a match while the frequency of block
matches gives the a priori probability of the same
match. Our version of the basic algorithm differs in
the mechanics of memory management (we use skip-
lists to improve performance of the dynamic program-
ming, for example), includes both positive and nega-
tive information about the probability of a given
match and fuses multiple sources of information for
evaluating alignment probabilities.
For two documents, DI and D2, consisting of n and
m alignment blocks, respectively, ai,. and bi , an
alignment, A, is a set consisting of
p pairs. For compactness, we will
write this as p .
</bodyText>
<page confidence="0.991343">
69
</page>
<table confidence="0.792961857142857">
P (AID 1, D2) =II P ((xi 1&lt;-&gt; 181, 82, ..., 8,) (Eq 1)
13 E A (Eq 2)
P 82, kla p) P (ae, 1&amp;quot; I3j,p) (Eq 3)
P I3j, pl8 1, 82, ..., 8d -
P(81, &amp;quot; &amp;quot; 8/c)
P 82, ***, / &lt;-4 131, p) P (ai, &amp;quot; i3j,p)
P (81,52, ..., kla P ((xi, [3j, + P (81, 82, ..., Sk (ai,1&lt;-&gt; f3j, p)) P(-_(a 14--&gt; (31,p) )
</table>
<equation confidence="0.950423">
P 82, • • •, &amp;quot; fkIP 8k1 ai,i&amp;quot; Pi, p) (Eq 4)
(Eq 5)
(Eq 6)
(Eq 7)
(Eq 8)
= log P(8k IcL, -*13.p)
152 = log [P ( &lt;--&gt; p) P p) + P (8 ((x p P ( ( a i
193 = log P(ai, &lt;-&gt; 13j, p)
arg max P(AID 1, D2) = 1-151 +152-153
A p) e A k
</equation>
<figureCaption confidence="0.998501">
Figure 2. Equations.
</figureCaption>
<bodyText confidence="0.645819875">
Following the Gale and Church approach, we
choose an alignment that maximizes the probability
over all possible alignments:
arg max [P(A ID p D2)]
A
If we assume that the probabilities of individually
aligned block pairs in an alignment are independent,
the above equation becomes:
</bodyText>
<equation confidence="0.9281065">
P (A(D p D2) IJ P (ao 13j, pID p D2)
(a,, E A
</equation>
<bodyText confidence="0.990592975">
Further assuming that the individual probabilities of
aligning two blocks, P ( &lt;-&gt; I3j, pID 1, D2) , are
dependent on features in the text described by a series
of feature scores, 8i , the above equations expands
into Equation 1 in figure 2.
Now, for each of the feature scoring functions, the a
posteriori probabilities can be calculated from Bayes&apos;
Rule as shown in Equation 2, Figure 2 which, given
an approximation of the joint a posteriori probabili-
ties by assuming independence, produces Equation 3,
Figure 2.
Note that the term in the denominator of Equation 3
reflects both the statistics of the positive and negative
information for the alignment. In Gale and Church&apos;s
original work, the denominator term was assumed to
be a constant over the range of 8 , and therefore could
be safely ignored during the maximization of proba-
bilities over the alignment set. In reality, this assump-
tion is true only in the case of a uniform distribution
of P (a 414-&gt; and is perhaps not even true
in that case due to the scaling properties of the loga-
rithm when the maximization problem above is con-
verted to a minimization problem (below).
In any case, the probability of a given value of 8
occurring is not merely dependent on the probability
of that score in the hand-aligned set, but is dependent
on the comparative probabilities of the score for the
hand aligned set and a set of randomly chosen align-
ment blocks. Clearly, if a value of 8 is equally likely
for both the hand aligned and random sets, then the
measurement cannot contribute to the decision pro-
cess. Equation3 presents a very general approach to
the fusion of multiple sources of information about
alignment probabilities. Each of the sources contrib-
utes to the overall probability of an alignment, but is
in turn scaled by the total probability of a given score
occurring over the entire set of possible alignments.
We can convert the maximization of probabilities
into a minimization of penalties taking the negative
logarithm of Equation 2 and substituting Equation 3,
</bodyText>
<page confidence="0.990151">
70
</page>
<bodyText confidence="0.999900454545455">
where *1 , *2 and *3 are as given in figure 2, Equa-
tions 5, 6 and 7. Equation 8 in the same figure is the
result.
The feature functions, 6k, are derived from esti-
mates of the probability of byte length differences,
number matching score probabilities and string match
score probabilities in our approach.
The Bayesian prior, P (a1&lt;--&gt; p) , can be esti-
mated as per Gale and Church (1991) by assuming
that it is equal to the frequency of distinct n-m
matches in the training set.
</bodyText>
<subsectionHeader confidence="0.933229">
5.1 Byte-length Ratios, Si
</subsectionHeader>
<bodyText confidence="0.998904">
The probability of an alignment based on byte-length
ratios is P(81I / 4-&gt; p) = P(81 (1(a d, 1031, p))) ,
where ) is the byte-length function. The distribu-
tion is assumed to be a Gaussian random variable
derived from the block length differences in the hand
aligned set. Following Gale and Church (1991), the
slope of the average of the length differences
describes the average number of Spanish characters
generated per English character. Assuming that the
distribution is approximately Gaussian, we can nor-
malize it to mean 0 and variance 1, resulting in:
</bodyText>
<equation confidence="0.919995">
/(13. ) - 1(a )c
81(/(a)&apos; /(13J,P)) -
,[1(oci , da2
</equation>
<bodyText confidence="0.997177666666666">
where c = )/1(ai. )).-- 0.99 and cr2 = 0.16 is the
observed variance. The histogram in Figure 3a shows
the actual distribution of the hand-aligned data set.
The shape of the histogram is approximately Gauss-
ian. The distribution of the corresponding random
segments in shown in Figure 3b. Note that the distri-
bution of the random set has significantly higher stan-
dard deviation than the corresponding hand aligned
set. This diagram, as well as Figure 4 for the n-gram
approach on the following page, indicate the statisti-
cal quality of the information provided by the scores.
Good sources of information would produce a marked
difference between the two distributions. For compar-
atively poor sources of information, the distributions
would show little or no differences.
</bodyText>
<subsectionHeader confidence="0.979427">
5.2 4-gram Matching, 52
</subsectionHeader>
<bodyText confidence="0.994743230769231">
Cognates in English and Spanish often have short
runs of letters in common. A measure that counts the
number of matching n- grams in two strings is an
unordered comparison of similarities within the
strings. In this way, runs of letters in common
between cognate terms are measured. We used an effi-
cient n-gram matching algorithm that requires a sin-
gle scan of each string, followed by two sorts and a
linear-time list comparison to count matches. The
resulting score was normalized by the total number of
n-grams between the strings. Formally, for two strings
e le2....ep and 5]52••5q&apos; the n-gram match count, Kn, is
given by:
</bodyText>
<equation confidence="0.9358275">
n pq i&lt;p j&lt;q
K -1 m(e.e. +1...e i+ s jsi+1...si„)
</equation>
<bodyText confidence="0.9996678">
where m() is the matching function. The function,
m(), is equal to 1 only for equivalent n-grams, else it
is O.
We chose to use 4-gram scores for the alignment
algorithm, 82= K4. The distributions of the 4-gram
</bodyText>
<subsectionHeader confidence="0.390572">
Distribution of Byte-length Ratio Scores for the Hand Aligned Set
</subsectionHeader>
<figure confidence="0.998083741935484">
70.00
65,00
60.00
55,00
50,00
45.00
40,00
35.00
30.00
25,00
20.00
15.00
10.00
5.00
Distribution of Byte-length Ratios for the Randomly Aligned Set
110.00 ,
100.00
90.00
80.00
70.00
60.00
50.00
40.00
30.00
20.00
10.00
0.00
0.00 500.00
-40.00 -20.00 0.00
81 81
(a) (b)
</figure>
<figureCaption confidence="0.999956">
Figure 3. Distribution of 51 for (a) hand aligned and (b) randomly aligned blocks
</figureCaption>
<page confidence="0.917984">
71
</page>
<figure confidence="0.998801">
(a) (b)
</figure>
<figureCaption confidence="0.9426">
Figure 4. 4-gram matching score distributions, 82 , for (a) hand aligned and (b) randomly aligned
blocks.
</figureCaption>
<figure confidence="0.995833870967742">
t•-■
90.00
80.00
70.00
60.00
50.00
40.00
30.00
20.00
10.00
0.00
150.00
0.00
50.00 100.00
8 x 103
0.00 20.00 40.00
826 103
Distribution of 4-Gram Match Scores for Hand Aligned Set
55.00
50.00
45.00
40.00
35.00
&apos;:cra
30.00
25.00
20.00
15.00
10.00
5.00
Distribution of 4-Gram Match Scores for the Random Set
</figure>
<bodyText confidence="0.999695875">
counts were computed for both the hand-aligned and
random alignment blocks. Figure 4 shows the result-
ing distributions. The results suggest that, on the
whole, the use of n-gram methods should be consid-
ered for improving alignments that contain lexically
similar cognates. Being unordered comparisons, how-
ever, they cannot exploit any intrinsic sequencing of
lexical elements.
</bodyText>
<subsectionHeader confidence="0.964785">
5.3 Ordered String Comparisons, 83
</subsectionHeader>
<bodyText confidence="0.99974075">
The value of unordered comparisons like the n-gram
matching may be enhanced by ordered comparisons.
An ordered comparison can reduce the noise associ-
ated with matching unrelated n-grams at opposite
ends of parallel alignment blocks. We chose to evalu-
ate a simple string-matching scheme as a possible
method for improving alignment performance. The
scheme compares the two alignment blocks character-
by-character, skipping over sections in one block that
do not match in the opposite, thus primarily penaliz-
ing the inclusion of dissimilar text segments in either
block. The resulting sum of the matches is scaled by
the sum of the lengths of the two blocks. In compari-
son with the random block scoring, the distribution of
the hand aligned data set had a greater number of
matches with high string-match scores.
</bodyText>
<subsectionHeader confidence="0.962093">
5.4 Number Matching, 84
</subsectionHeader>
<bodyText confidence="0.999983375">
The PAHO texts are distinguished by a number of tex-
tual features, especially the fact that they are all in
some way related to Latin American health issues.
The preponderance of the documents are technical
reports on epidemiology, proceedings from meetings
and conferences, and compendiums of resources and
citations. Within these documents, numbers occur
regularly. The string-matching technique suggested
that if a class of lexical distinction could be matched
directly, the alignments might be significantly
improved. Numbers are sufficiently general that we
felt we were not violating the spirit of the restriction
on generality by using a number-matching scheme.
For each alignment block pair, the number match-
ing algorithm extracted all numbers. The total number
of exact matches between the number sets from each
alignment block was then normalized by the sizes of
both sets of numbers. This approach has several draw-
backs, such as the differences in the format of num-
bers between Spanish and English. In Spanish, for
example, commas are used instead of decimal points.
These distinctions were ignored, however, to preserve
the generality of the algorithm. This generality will
potentially extend to other languages, including Asi-
atic languages, which tend to use Arabic numerals to
represent numbers. The distributions of both the hand
and random block scoring both showed a substantial
mass of very low scores.
It should be noted that numbers are simply a special
case of cognates and certainly contribute to the n-
gram scores. Adding in number matching strategies
therefore only enhances the n-gram results.
</bodyText>
<subsectionHeader confidence="0.993897">
5.5 Translation Residues
</subsectionHeader>
<bodyText confidence="0.9998865">
Despite the fact that non-Spanish speakers can often
achieve success at aligning English documents with
Spanish texts, the added knowledge of someone with
both Spanish and English language understanding is
an added benefit and should facilitate alignment. To
evaluate the role of translation-based alignment scor-
</bodyText>
<page confidence="0.998982">
72
</page>
<tableCaption confidence="0.999928">
Table 1. Performance comparisons between byte-length ratio methods and the improved algorithm.
</tableCaption>
<table confidence="0.996739">
Byte-length Ratio Method Improved Method
#HAND #FOUND #CORRECT #HAND #FOUND #CORRECT
Document! 281 196 65 281 222 138
Document 2 787 440 3 787 614 553
</table>
<bodyText confidence="0.996767333333333">
ing, the Collins Spanish-English and English-Spanish
bilingual dictionaries were used to produce a score
equal to the residue from a translation attempt of the
terms in potential aligning blocks.
Given a set of English terms, ei, Spanish terms, sj,
from two blocks, the translation operation, T(l), gen-
erates a set of terms in the opposite language by stem-
ming each term and retrieving the terms that the
stemmed word translates to in Collins. The residue, R,
is then a penalty equal to the (normalized) number of
terms in each translation set that do not have a match
in the opposite translation set:
</bodyText>
<equation confidence="0.918904333333333">
IIT(Ik) n 1 di
R= 1 EI&apos;l&apos;Tod U tkli
k&amp;quot;
</equation>
<bodyText confidence="0.999992863636364">
In comparison test, the distributions of scores
between random Spanish blocks and English blocks,
and between the hand-aligned sets, were surprisingly
similar, making a statistical discrimination of proper
alignments difficult. We believe that dictionary-based
discrimination performs poorly primarily due to the
noisy nature of the dictionary we used. It was initially
thought that subsenses and usage patterns for each
term would be an aid to discrimination by providing a
stronger basis for matches between true parallel
blocks. The added terms beyond the critical primary
sense in the dictionary had high hit rates with usage
terms throughout the dictionary. The result was a
noisy translation set that robbed the residue measure
of discriminatory power. The results discouraged us
from including the R measure in the error function for
the dynamic programming system, although we sus-
pect that improved dictionaries may ultimately pro-
vide better discrimination. It may also be possible to
apply a kill list to the dictionary to reduce the number
of high frequency terms in each definition, increasing
the relevancy of the overall residue measure.
</bodyText>
<sectionHeader confidence="0.998989" genericHeader="method">
6 Implementation
</sectionHeader>
<bodyText confidence="0.999996318181818">
The fact that our formulation of the alignment proba-
bility for two blocks is dependent on both the positive
and negative information about the alignment proba-
bility means that the probability density functions can
be used directly in the algorithm. Specifically, the dis-
tributions shown in Figures 3 and 4, as well as the dis-
tributions for ordered string comparisons and number
comparisons, were loaded into the algorithm as histo-
grams. During the dynamic programming operation,
probability scores were determined by direct look-up
of the 8 scores in the appropriate histogram, with
some weighted averaging performed for values
between the boundaries of the histogram bars for
smoothing. This approach eliminated the necessity of
estimating a distribution function for the rather non-
Gaussian functions that are assumed to underlay the
experimental data. Using this approach, the byte-
length ratios could be simplified by not assuming a
Gaussian-like distribution and directly using the his-
tograms of byte-length probabilities. For comparison,
however, we chose to use the Gale and Church deriva-
tion without modifying 81 .
</bodyText>
<sectionHeader confidence="0.998544" genericHeader="evaluation">
7 Performance
</sectionHeader>
<bodyText confidence="0.999769153846154">
Table 1 shows the performance of the original align-
ment algorithm compared to the improved algorithm.
The results are for two documents. #HAND is the
number of alignment blocks found in the hand aligned
set. #FOUND is the number of alignment blocks
found by the algorithms. Values of #FOUND lower
than the value of #HAND indicates that alignment
blocks that contain multiple segments have been
found by the algorithm (e.g., a 3-3 match has sup-
planted three 1-1 matches). #CORRECT is the num-
ber of the found blocks which exactly match blocks in
the hand aligned set. Note that the number of exact
matches is a conservative estimate of the number of
</bodyText>
<page confidence="0.996083">
73
</page>
<bodyText confidence="0.999948142857143">
acceptable alignments, as different translators may,
for example, differ about whether a 2-2 match can
take the place of two 1-1 matches and still be consid-
ered aligned.
In general, the performance of the improved align-
ment algorithm was very good, improving the hit
rates from 23% to 49% on Document 1 and from
0.00381% to 70% on Document 2. The abysmal per-
formance of the byte-length method on Document 2
can be attributed to the massive amounts of header
information, significant added whitespace and incon-
sistent table and list formats that occurred in one doc-
ument but not the other. The algorithm encountered
only 1 hit (the document start) in the first quarter of
the document. The training texts for these runs were
the texts themselves, and therefore the results must be
reviewed with care. The statistics of just two docu-
ments, applied directly to those two documents for
evaluation does not necessarily provide a direct esti-
mate of the same statistics to a broader spectrum of
documents.
</bodyText>
<sectionHeader confidence="0.999636" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.999992818181818">
In the real world, poor-quality translations are com-
mon due to the preferences of individual translators,
lack of formal format guidelines for translations and
outright mistakes. Our method combines four feature
scores into a simple measure of the probability of two
textual segments aligning. The algorithm is fairly
general in that all of the feature scores used are more
or less applicable to a wide range of Spanish and
English translations and are also applicable to a
degree to other European languages. It is further
likely that the methods we used can improve align-
ments between many non-European languages by
exploiting the increasingly common English phrases
and Arabic number occurrences in professional and
public communications throughout the world.
Our alignment algorithm presents a new formula-
tion of Bayesian methods combined with a direct
approach to data fusion for multiple sources of infor-
mation. This approach should work well with a wide
range of data sources, including direct comparisons of
co-occurrence probabilities for specific classes of lex-
ical elements.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999723458333334">
CATIZONE, ROBERTA, GRAHAM RUSSELL &amp;
SUSAN WARWICK. 1989. Deriving Translation Data
from Bilingual Texts. In Proceedings of the First
International Acquisition Workshop, Detroit, MI.
CHEN, STANLEY F. 1993. Aligning Sentences in
Bilingual Corpora Using Lexical Information. In Pro-
ceedings of the 31st Annual Conference of the Associ-
ation of Computational Linguistics, 9-16, Columbus,
OH.
CHURCH, KENNETH W. 1993. Char-align: A Pro-
gram for Aligning Parallel Texts at the Character
Level. In Proceedings of the 31st Annual Conference
of the Association of Computational Linguistics, 1-8,
Columbus, OH.
DAVIS, MARK W. &amp; TED E. DUNNING. 1995.
Query Translation using Evolutionary Programming
for Multi-lingual Information Retrieval. To appear in
Proceedings of the Fourth Annual Conference on
Evolutionary Programming, San Diego, CA.
DUNNING, TED E. &amp; MARK W. DAVIS. 1993a. A
Single Language Evaluation of a Multi-Lingual Text
Retrieval System. NIST Special Publication 500-207:
The First Text Retrieval Conference (TREC-1), D.K.
Harman, Ed., Computer Systems Laboratory, NIST.
DUNNING, TED E. &amp; MARK W. DAVIS. 1993b.
Multi-Lingual Information Retrieval. Memoranda in
Computer and Cognitive Science, MCCS-93-252,
Computing Research Laboratory, New Mexico State
University.
GALE, WILLIAM A. &amp; KENNETH W. CHURCH.
1991. A Program for Aligning Sentences in Bilingual
Corpora. In Proceedings of the 29th Annual Confer-
ence of the Association of Computational Linguistics,
177-184, Berkeley, CA.
OGDEN, WILLIAM C. 1993. Norm - A System for
Translators. Demonstration at ARPA Workshop on
Human Language Technology, Merill-Lynch Confer-
ence Center, Plainsboro, NJ.
SIMARD, M., G. FOSTER &amp; P. ISABELLE. 1992.
Using Cognates to Align Sentences in Bilingual Cor-
pora. Fourth International Conference on Theoretical
and Methodological Issues in Machine Translation.
Montreal Canada.
Wu, DEKA!. 1994. Aligning a Parallel English-Chi-
nese Corpus Statistically with Lexical Criteria. In
Proceedings of the 32nd Annual Conference of the
Association for Computational Linguistics, 80-87,
Las Cruces, NM.
</reference>
<page confidence="0.999132">
74
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.784769">
<title confidence="0.996057666666667">Text Alignment in the Real World: Improving Alignments of Noisy Translations Using Common Lexical Features, String Matching Strategies and N-Gram Comparisons&apos;</title>
<author confidence="0.999955">Mark W Davis</author>
<author confidence="0.999955">Ted E Dunning</author>
<author confidence="0.999955">William C Ogden</author>
<affiliation confidence="0.999702">Computing Research Laboratory New Mexico State University</affiliation>
<address confidence="0.924009">30001/3CRL Las Cruces, New Mexico USA</address>
<email confidence="0.989415">madavis@crl.nmsu.edu</email>
<email confidence="0.989415">ted@crl.nmsu.edu</email>
<email confidence="0.989415">ogden@crl.nmsu.edu</email>
<abstract confidence="0.999814583333333">Alignment methods based on byte-length comparisons of alignment blocks have been remarkably successful for aligning good translations from legislative transcriptions. For noisy translations in which the parallel text of a document has significant structural differences, byte-alignment methods often do not perform well. The Pan American Health Organization (PAHO) corpus is a series of articles that were first translated by machine methods and then improved by professional translators. Many of the Spanish PAHO texts do not share formatting conventions with the corresponding English documents, refer to tables in stylistically different ways and contain extraneous information. A method based on a dynamic programming framework, but using a decision criterion derived from a combination of byte-length ratio measures, hard matching of numbers, comparisons and co-occurrence matching substantially improves the performance of the alignment process.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>ROBERTA CATIZONE</author>
<author>GRAHAM RUSSELL</author>
<author>SUSAN WARWICK</author>
</authors>
<title>Deriving Translation Data from Bilingual Texts.</title>
<date>1989</date>
<booktitle>In Proceedings of the First International Acquisition Workshop,</booktitle>
<location>Detroit, MI.</location>
<marker>CATIZONE, RUSSELL, WARWICK, 1989</marker>
<rawString>CATIZONE, ROBERTA, GRAHAM RUSSELL &amp; SUSAN WARWICK. 1989. Deriving Translation Data from Bilingual Texts. In Proceedings of the First International Acquisition Workshop, Detroit, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>STANLEY F CHEN</author>
</authors>
<title>Aligning Sentences in Bilingual Corpora Using Lexical Information.</title>
<date>1993</date>
<booktitle>In Proceedings of the 31st Annual Conference of the Association of Computational Linguistics,</booktitle>
<pages>9--16</pages>
<location>Columbus, OH.</location>
<marker>CHEN, 1993</marker>
<rawString>CHEN, STANLEY F. 1993. Aligning Sentences in Bilingual Corpora Using Lexical Information. In Proceedings of the 31st Annual Conference of the Association of Computational Linguistics, 9-16, Columbus, OH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>KENNETH W CHURCH</author>
</authors>
<title>Char-align: A Program for Aligning Parallel Texts at the Character Level.</title>
<date>1993</date>
<booktitle>In Proceedings of the 31st Annual Conference of the Association of Computational Linguistics,</booktitle>
<pages>1--8</pages>
<location>Columbus, OH.</location>
<marker>CHURCH, 1993</marker>
<rawString>CHURCH, KENNETH W. 1993. Char-align: A Program for Aligning Parallel Texts at the Character Level. In Proceedings of the 31st Annual Conference of the Association of Computational Linguistics, 1-8, Columbus, OH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>MARK W DAVIS</author>
<author>TED E DUNNING</author>
</authors>
<title>Query Translation using Evolutionary Programming for Multi-lingual Information Retrieval.</title>
<date>1995</date>
<booktitle>Proceedings of the Fourth Annual Conference on Evolutionary Programming,</booktitle>
<location>San Diego, CA.</location>
<note>To appear in</note>
<marker>DAVIS, DUNNING, 1995</marker>
<rawString>DAVIS, MARK W. &amp; TED E. DUNNING. 1995. Query Translation using Evolutionary Programming for Multi-lingual Information Retrieval. To appear in Proceedings of the Fourth Annual Conference on Evolutionary Programming, San Diego, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>TED E DUNNING</author>
<author>MARK W DAVIS</author>
</authors>
<title>A Single Language Evaluation of a Multi-Lingual Text Retrieval System.</title>
<date>1993</date>
<journal>NIST Special Publication</journal>
<booktitle>The First Text Retrieval Conference (TREC-1),</booktitle>
<pages>500--207</pages>
<institution>Computer Systems Laboratory, NIST.</institution>
<marker>DUNNING, DAVIS, 1993</marker>
<rawString>DUNNING, TED E. &amp; MARK W. DAVIS. 1993a. A Single Language Evaluation of a Multi-Lingual Text Retrieval System. NIST Special Publication 500-207: The First Text Retrieval Conference (TREC-1), D.K. Harman, Ed., Computer Systems Laboratory, NIST.</rawString>
</citation>
<citation valid="true">
<authors>
<author>TED E DUNNING</author>
<author>MARK W DAVIS</author>
</authors>
<date>1993</date>
<booktitle>Multi-Lingual Information Retrieval. Memoranda in Computer and Cognitive Science,</booktitle>
<pages>93--252</pages>
<institution>Computing Research Laboratory, New Mexico State University.</institution>
<marker>DUNNING, DAVIS, 1993</marker>
<rawString>DUNNING, TED E. &amp; MARK W. DAVIS. 1993b. Multi-Lingual Information Retrieval. Memoranda in Computer and Cognitive Science, MCCS-93-252, Computing Research Laboratory, New Mexico State University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>WILLIAM A GALE</author>
<author>KENNETH W CHURCH</author>
</authors>
<title>A Program for Aligning Sentences in Bilingual Corpora.</title>
<date>1991</date>
<booktitle>In Proceedings of the 29th Annual Conference of the Association of Computational Linguistics,</booktitle>
<pages>177--184</pages>
<location>Berkeley, CA.</location>
<marker>GALE, CHURCH, 1991</marker>
<rawString>GALE, WILLIAM A. &amp; KENNETH W. CHURCH. 1991. A Program for Aligning Sentences in Bilingual Corpora. In Proceedings of the 29th Annual Conference of the Association of Computational Linguistics, 177-184, Berkeley, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>WILLIAM C OGDEN</author>
</authors>
<title>Norm - A System for Translators. Demonstration at</title>
<date>1993</date>
<booktitle>ARPA Workshop on Human Language Technology, Merill-Lynch Conference</booktitle>
<location>Center, Plainsboro, NJ.</location>
<marker>OGDEN, 1993</marker>
<rawString>OGDEN, WILLIAM C. 1993. Norm - A System for Translators. Demonstration at ARPA Workshop on Human Language Technology, Merill-Lynch Conference Center, Plainsboro, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M SIMARD</author>
<author>G FOSTER</author>
<author>P ISABELLE</author>
</authors>
<title>Using Cognates to Align Sentences in Bilingual Corpora.</title>
<date>1992</date>
<booktitle>Fourth International Conference on Theoretical and Methodological Issues in Machine Translation.</booktitle>
<location>Montreal</location>
<marker>SIMARD, FOSTER, ISABELLE, 1992</marker>
<rawString>SIMARD, M., G. FOSTER &amp; P. ISABELLE. 1992. Using Cognates to Align Sentences in Bilingual Corpora. Fourth International Conference on Theoretical and Methodological Issues in Machine Translation. Montreal Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>DEKA Wu</author>
</authors>
<title>Aligning a Parallel English-Chinese Corpus Statistically with Lexical Criteria.</title>
<date>1994</date>
<booktitle>In Proceedings of the 32nd Annual Conference of the Association for Computational Linguistics,</booktitle>
<pages>80--87</pages>
<location>Las Cruces, NM.</location>
<contexts>
<context position="1694" citStr="Wu, 1994" startWordPosition="244" endWordPosition="245">, but using a decision criterion derived from a combination of byte-length ratio measures, hard matching of numbers, string comparisons and n-gram co-occurrence matching substantially improves the performance of the alignment process. 1 Introduction Given texts in two languages that are to some degree translations of one another, an alignment of the texts associates sentences, paragraphs or phrases in one document with their translations in the other. Successful approaches to alignment can be divided into two primary types: those that use comparisons of lexical elements between the documents (Wu, 1994; Chen 1993; Catizone, Russell and Warwick, 1989), and &apos;This research was funded under DoD Contract #MDA 904-94-C-E086 those that use a statistical decision process derived from byte-length ratios between alignment blocks (Wu, 1994; Church, 1993; Gale and Church, 1991). Methods vary for the former approach, but in the latter approach, a dynamic programming framework is used to sequentially align blocks as the alignment process proceeds. Under this model, blocks are compared only with nearby blocks as the alignment proceeds, substantially reducing the computational overhead [0(n2) « 0(n!)] of t</context>
</contexts>
<marker>Wu, 1994</marker>
<rawString>Wu, DEKA!. 1994. Aligning a Parallel English-Chinese Corpus Statistically with Lexical Criteria. In Proceedings of the 32nd Annual Conference of the Association for Computational Linguistics, 80-87, Las Cruces, NM.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>