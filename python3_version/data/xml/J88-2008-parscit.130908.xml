<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007201">
<note confidence="0.635504">
Book Reviews Memory and Context for Language Interpretation
</note>
<bodyText confidence="0.955206157894737">
that the only objective of the book is description of
linguistic phenomena. It is difficult to imagine practical
application of the theory in natural-language processing
systems. Although the book was not aimed at present-
ing practical applications, a short chapter on this topic
could dispel the doubts of a reader studying this type of
problem for the first time. Furthermore, the addition of
an index would have facilitated the reader in returning
to certain issues or unmemorized definitions.
Still, this book is one of the more interesting recent
publications on the application of logic in natural-
language description. Reading it will inspire further
research on the logical structure of natural language,
and is highly recommended.
Leonard Bolc is the editor of several collections of papers on
various aspects of natural-language systems, including the
recent Natural-language parsing systems (Springer-Verlag).
His address is: Instytut Podstaw Informatyka, Polskiej Aka-
demii Nauk, PKiN, pok. 1050, 00-901 Warszawa, Poland.
</bodyText>
<sectionHeader confidence="0.988057" genericHeader="method">
MEMORY AND CONTEXT FOR LANGUAGE
INTERPRETATION
(STUDIES IN NATURAL-LANGUAGE PROCESSING)
</sectionHeader>
<subsectionHeader confidence="0.713389">
Hiyan Alshawi
</subsectionHeader>
<affiliation confidence="0.743455">
(SRI International, Cambridge, England)
Cambridge, England: Cambridge University Press,
</affiliation>
<figure confidence="0.802666">
1987, ix + 188 pp.
ISBN 0-521-34059-4, $29.95 (hb) (20% discount to
ACL members)
Reviewed by
Jean-Pierre Corriveau
University of Toronto and
Bell-Northern Research
</figure>
<bodyText confidence="0.993356025862069">
This book is a reorganization of a 1983 doctoral thesis.
It seems little effort has been spent to take into account
the impressive amount of research in text comprehen-
sion since 1983. Indeed, the reference section lists only
five post-1983 entries. Nevertheless the book is very
relevant to the field of computational linguistics: it
constitutes an archetype of the assumptions, strategies,
and limitations faced by anyone attempting to imple-
ment a text-processing tool.
This relatively short book (188 pages, double-spaced)
is divided into two parts. The first, comprising four
chapters, overviews the model, which is then detailed in
the second part. The first chapter introduces the basic
assumptions and goals of the thesis; the research fo-
cuses on memory mechanisms, not inferencing or rea-
soning. The author states that the work is carried out in
terms of automatic natural-language processing (NLP)
and thus that he will avoid claims and suggestions about
human language processing. Indeed, the title is some-
what misleading: the use of the word &amp;quot;memory&amp;quot; in the
dissertation has little to do with human memory. In
essence, the thesis describes marker-passing algorithms
used to select between possible candidates for disam-
biguation. The algorithms search for candidates in a
database and choose between them according to the
current context, which simply constrains memory re-
trieval. The system, called Capture, was designed not
only for text processing but also to process collections
of English paragraphs and produce an output incorpo-
rable into a conventional database.
The second chapter overviews the representational
scheme and algorithms developed by the author. The
knowledge base is constructed out of two types of
assertions: specializations (IS-A declarations) and corre-
spondences, which take the form role Cl of owner D1 is
a role-specialization of role C2 whose owner is D2.
These types of assertions can carry further information
about the relationships between their arguments. This
information is encoded as a list of flags given as an
additional argument to the assertion. The author re-
marks that &amp;quot;the motivation for the choice of flags that
were defined for the memory formalism is simply that
these seem to be useful, in practice, for stating infor-
mation at the level of this kind of formalism&amp;quot;. Context
is represented by a collection of context factors, each of
which contributes activation to a particular set of mem-
ory entities (i.e., to the &amp;quot;objects&amp;quot; referred to in the
assertions). There are seven major types of context
factor, including recency, syntactic emphasis, deixis,
and a priori subject area. These are essentially static
rules that define how activation is managed for each
memory entity involved during comprehension. The
rules are applied for disambiguation and for defining the
focus space; that is, the set of most &amp;quot;activated&amp;quot; mem-
ory entities. In the remainder of the chapter, Alshawi
discusses his standard marker-passing model.
The third chapter addresses the problem of interpre-
tation. The author tackles noun phrase (NP) reference
interpretation, compound NPs, possessive NPs, with-
PPs, and word-sense disambiguation. Conditionals, ne-
gation, and &amp;quot;phenomena going beyond memory mech-
anisms&amp;quot; (e.g., modality and metaphor) are not handled.
The algorithms are simple to understand but often lack
proper motivation. In the fourth chapter, Alshawi dis-
cusses related research as of 1983. In particular, the
author acknowledges the strong influence of Fahlman&apos;s
work on marker-passing, and of Grosz&apos;s notion of global
focus.
The second part starts on page 76. In the rest of the
book, Alshawi details the ideas of the first part (see
summary table, p. 94) and elaborates on the Capture
feature that creates a relational database as the result of
text processing. The author concludes with a chapter on
the complexity of techniques for efficient retrieval from
a database, a topic too often ignored in NLP models.
I said above that this book is, in my opinion, an
archetype of the NLP thesis in computational linguis-
tics. The first appendix, which lists some of the 30 short
texts processed by Capture, confirms this: the examples
Computational Linguistics, Volume 14, Number 2, June 1988 75
Book Reviews From Text to Speech: The MITalk System
are incredibly artificial! As with several other Al sys-
tems, one gets the distinct impression that the data is
fitted to the software! Alshawi is looking for the algo-
rithms that produce the optimal interpretation of a text.
How can he justify these algorithms when he discards
psychology and neurophysiology? What constitutes the
optimal interpretation of a text? These questions are left
unanswered. What remains is the implementation of a
solution to some specific problems considered in a
vacuum. The dissertation presents the advantages and
limitations of a particular solution; several other solu-
tions to these problems have been suggested. Each
author compares his model to the others but the relative
vacuity of it all persists. Suspiciously, all models share
the same basic flaws (e.g., simplistic model of memory,
and absence of mechanisms for the subsequent correc-
tion of an erroneous interpretation). By dissociating
NLP, with its cartesian quest for optimal interpretation
algorithms, from man, his language, his formidable
ability to understand and to misunderstand and to not
understand, computational linguists seem to have cre-
ated the ultimate field of study, one where partial
solutions are taken to intrinsically hold the promise of
an eventual complete and correct solution to the prob-
lem of linguistic understanding. I reject the notion of the
&amp;quot;optimal interpretation&amp;quot; of a text and, after reading
Alshawi&apos;s book, I am left with the bitter taste of an
interesting yet very artificial Lisp program.
Jean-Pierre Corriveau is a doctoral candidate in the Depart-
ment of Computer Science, University of Toronto, working
on a psychologically valid model of schematic memory for
text understanding. He is also a member of the Exploratory
Tools group of Bell-Northern Research, Ottawa. Corriveau&apos;s
address is: 748 Parkdale Ave., Ottawa, Canada KlY 1J9.
Email: jpierre @ ai.toronto. edu.
</bodyText>
<sectionHeader confidence="0.919191" genericHeader="method">
FROM TEXT TO SPEECH: THE MITALK SYSTEM
(CAMBRIDGE STUDIES IN SPEECH SCIENCE AND
COMMUNICATION)
</sectionHeader>
<reference confidence="0.867441285714286">
Jonathan Allen; M. Sharon Hunnicutt; and Dennis
Klatt, with Robert C. Armstrong and David Pisoni
(Respectively: MIT; Royal Institute of Technology,
Stockholm, Sweden; MIT; MIT; Indiana
University)
Cambridge, England: Cambridge University Press,
1987, xi + 216 pp.
</reference>
<figure confidence="0.602525333333333">
ISBN 0-521-30641-8, $29.95 (hb)
Reviewed by
Matti Karjalainen
</figure>
<affiliation confidence="0.748841">
Helsinki University of Technology
</affiliation>
<bodyText confidence="0.999857193548387">
Speech processing and computational linguistics have
traditionally been disciplines separated by different
approaches and methodologies. The continuous nature
of speech signals is not easily interfaced to the discrete
units and symbolic processing of linguistic and concep-
tual levels. One of the successful contributions in com-
bining language and speech aspects is MITalk, a speech-
synthesis system developed at MIT to convert English
text to speech signals. The book From text to speech:
The MITalk system is a detailed documentation of the
principles that have resulted from a research effort that
has lasted more than two decades.
The MITalk project has influenced the theory and
practice of speech synthesis to a large extent. Several
commercial synthesizers draw their origin from MITalk
and many research groups around the world have
benefited from its underlying principles, even those
involved in languages as different as Finnish—in the
case of the reviewer. The MITalk synthesizer is re-
garded as a reference point in this field and this system-
atically written book on it is highly welcome.
The writers do not attempt to give a comprehensive
review of different approaches and implementations
available in speech synthesis. (For this, see Klatt 1987.)
Instead, they build their own theoretical framework by
a thorough description of the MITalk implementation
principles. The book is divided into parts in the same
way as the synthesis process of MITalk itself. The
book, as well as the text-to-speech synthesis, starts
from the analysis of the text input. Text pre-processing
is followed by morphological analysis. The extensive
morph lexicon contributes significantly to the high
quality of the synthesis process. A phrase-level parser is
used with rules for morphophonemics and stress modi-
fication. The application of ordered phonological rules
to letter-to-sound conversion and lexical stress con-
cludes the text-analysis part of the text-to-speech proc-
ess.
The synthesis part of MITalk contains a phonological
component, a prosodic component including a funda-
mental frequency generator, a phonetic component (all
the time approaching a continuous-time representa-
tion)—and finally a formant synthesizer (called the
Klatt synthesizer) to produce the continuous speech
signal. The rest of the book discusses some pragmatic
aspects like measures of intelligibility of the synthetic
speech.
This book is primarily of interest to those who are
active in speech research and synthesizer development.
However, especially the first half of the book might
draw remarkable attention from the point of view of
computational linguistics. Most chapters are easy to
read (a possible exception is the formant-synthesizer
section). One weakness of the book is that it took too
many years to publish after the most intensive phases of
the research work. There are also too few ideas to be
found from an artificial-intelligence perspective even
though the rule-based processing in speech synthesis
could be improved by modern knowledge-based meth-
ods. The main message of the book to computational
linguistics is perhaps threefold. First, that a close rela-
tionship to speech processing exists; second, it should
</bodyText>
<page confidence="0.792068">
76 Computational Linguistics, Volume 14, Number 2, June 1988
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000627">
<title confidence="0.990255">Book Reviews Memory and Context for Language Interpretation</title>
<abstract confidence="0.989204055555555">that the only objective of the book is description of linguistic phenomena. It is difficult to imagine practical application of the theory in natural-language processing systems. Although the book was not aimed at presenting practical applications, a short chapter on this topic could dispel the doubts of a reader studying this type of problem for the first time. Furthermore, the addition of an index would have facilitated the reader in returning to certain issues or unmemorized definitions. Still, this book is one of the more interesting recent publications on the application of logic in naturallanguage description. Reading it will inspire further research on the logical structure of natural language, and is highly recommended. Bolc the editor of several collections of papers on various aspects of natural-language systems, including the parsing systems His address is: Instytut Podstaw Informatyka, Polskiej Aka-</abstract>
<address confidence="0.310232">demii Nauk, PKiN, pok. 1050, 00-901 Warszawa, Poland.</address>
<title confidence="0.965737">MEMORY AND CONTEXT FOR LANGUAGE INTERPRETATION (STUDIES IN NATURAL-LANGUAGE PROCESSING)</title>
<author confidence="0.985214">Hiyan Alshawi</author>
<affiliation confidence="0.8756075">(SRI International, Cambridge, England) Cambridge, England: Cambridge University Press,</affiliation>
<address confidence="0.719704">1987, ix + 188 pp.</address>
<note confidence="0.985096333333333">ISBN 0-521-34059-4, $29.95 (hb) (20% discount to ACL members) Reviewed by</note>
<author confidence="0.99198">Jean-Pierre Corriveau</author>
<affiliation confidence="0.857368">University of Toronto and Bell-Northern Research</affiliation>
<abstract confidence="0.987495301724138">This book is a reorganization of a 1983 doctoral thesis. It seems little effort has been spent to take into account the impressive amount of research in text comprehension since 1983. Indeed, the reference section lists only five post-1983 entries. Nevertheless the book is very relevant to the field of computational linguistics: it constitutes an archetype of the assumptions, strategies, and limitations faced by anyone attempting to implement a text-processing tool. This relatively short book (188 pages, double-spaced) is divided into two parts. The first, comprising four chapters, overviews the model, which is then detailed in the second part. The first chapter introduces the basic assumptions and goals of the thesis; the research focuses on memory mechanisms, not inferencing or reasoning. The author states that the work is carried out in terms of automatic natural-language processing (NLP) and thus that he will avoid claims and suggestions about human language processing. Indeed, the title is somewhat misleading: the use of the word &amp;quot;memory&amp;quot; in the dissertation has little to do with human memory. In essence, the thesis describes marker-passing algorithms used to select between possible candidates for disambiguation. The algorithms search for candidates in a database and choose between them according to the current context, which simply constrains memory re- The system, called designed not only for text processing but also to process collections of English paragraphs and produce an output incorporable into a conventional database. The second chapter overviews the representational scheme and algorithms developed by the author. The knowledge base is constructed out of two types of declarations) and corretake the form Cl of owner D1 is a role-specialization of role C2 whose owner is D2. These types of assertions can carry further information about the relationships between their arguments. This information is encoded as a list of flags given as an additional argument to the assertion. The author remarks that &amp;quot;the motivation for the choice of flags that were defined for the memory formalism is simply that these seem to be useful, in practice, for stating information at the level of this kind of formalism&amp;quot;. Context is represented by a collection of context factors, each of which contributes activation to a particular set of memory entities (i.e., to the &amp;quot;objects&amp;quot; referred to in the assertions). There are seven major types of context factor, including recency, syntactic emphasis, deixis, and a priori subject area. These are essentially static rules that define how activation is managed for each memory entity involved during comprehension. The rules are applied for disambiguation and for defining the focus space; that is, the set of most &amp;quot;activated&amp;quot; memory entities. In the remainder of the chapter, Alshawi discusses his standard marker-passing model. The third chapter addresses the problem of interpretation. The author tackles noun phrase (NP) reference compound NPs, possessive NPs, with- PPs, and word-sense disambiguation. Conditionals, negation, and &amp;quot;phenomena going beyond memory mechanisms&amp;quot; (e.g., modality and metaphor) are not handled. The algorithms are simple to understand but often lack proper motivation. In the fourth chapter, Alshawi discusses related research as of 1983. In particular, the author acknowledges the strong influence of Fahlman&apos;s on marker-passing, and of Grosz&apos;s notion of focus. The second part starts on page 76. In the rest of the book, Alshawi details the ideas of the first part (see summary table, p. 94) and elaborates on the Capture feature that creates a relational database as the result of text processing. The author concludes with a chapter on the complexity of techniques for efficient retrieval from a database, a topic too often ignored in NLP models. I said above that this book is, in my opinion, an archetype of the NLP thesis in computational linguistics. The first appendix, which lists some of the 30 short texts processed by Capture, confirms this: the examples Computational Linguistics, Volume 14, Number 2, June 1988 75 Book Reviews From Text to Speech: The MITalk System are incredibly artificial! As with several other Al systems, one gets the distinct impression that the data is fitted to the software! Alshawi is looking for the algorithms that produce the optimal interpretation of a text. How can he justify these algorithms when he discards psychology and neurophysiology? What constitutes the optimal interpretation of a text? These questions are left unanswered. What remains is the implementation of a solution to some specific problems considered in a vacuum. The dissertation presents the advantages and limitations of a particular solution; several other solutions to these problems have been suggested. Each author compares his model to the others but the relative vacuity of it all persists. Suspiciously, all models share the same basic flaws (e.g., simplistic model of memory, and absence of mechanisms for the subsequent correction of an erroneous interpretation). By dissociating NLP, with its cartesian quest for optimal interpretation algorithms, from man, his language, his formidable ability to understand and to misunderstand and to not understand, computational linguists seem to have created the ultimate field of study, one where partial solutions are taken to intrinsically hold the promise of an eventual complete and correct solution to the problem of linguistic understanding. I reject the notion of the &amp;quot;optimal interpretation&amp;quot; of a text and, after reading book, left with the bitter taste of an interesting yet very artificial Lisp program. Corriveau a doctoral candidate in the Department of Computer Science, University of Toronto, working on a psychologically valid model of schematic memory for text understanding. He is also a member of the Exploratory Tools group of Bell-Northern Research, Ottawa. Corriveau&apos;s address is: 748 Parkdale Ave., Ottawa, Canada KlY 1J9. Email: jpierre @ ai.toronto. edu.</abstract>
<affiliation confidence="0.475131">FROM TEXT TO SPEECH: THE MITALK SYSTEM (CAMBRIDGE STUDIES IN SPEECH SCIENCE AND</affiliation>
<title confidence="0.388854">COMMUNICATION</title>
<author confidence="0.6344515">Jonathan Allen</author>
<author confidence="0.6344515">M Sharon Hunnicutt</author>
<author confidence="0.6344515">Dennis Klatt</author>
<author confidence="0.6344515">with Robert C Armstrong</author>
<author confidence="0.6344515">David Pisoni</author>
<affiliation confidence="0.964668">Respectively: MIT; Royal Institute of Technology,</affiliation>
<address confidence="0.920055">Stockholm, Sweden; MIT; MIT; Indiana</address>
<affiliation confidence="0.7569995">University) Cambridge, England: Cambridge University Press,</affiliation>
<address confidence="0.846435">1987, xi + 216 pp.</address>
<note confidence="0.9787595">ISBN 0-521-30641-8, $29.95 (hb) Reviewed by</note>
<author confidence="0.999223">Matti Karjalainen</author>
<affiliation confidence="0.999263">Helsinki University of Technology</affiliation>
<abstract confidence="0.998011870967742">Speech processing and computational linguistics have traditionally been disciplines separated by different approaches and methodologies. The continuous nature of speech signals is not easily interfaced to the discrete units and symbolic processing of linguistic and conceptual levels. One of the successful contributions in comlanguage and speech aspects is speechsynthesis system developed at MIT to convert English to speech signals. The book text to speech: MITalk system a detailed documentation of the principles that have resulted from a research effort that has lasted more than two decades. The MITalk project has influenced the theory and practice of speech synthesis to a large extent. Several commercial synthesizers draw their origin from MITalk and many research groups around the world have benefited from its underlying principles, even those involved in languages as different as Finnish—in the case of the reviewer. The MITalk synthesizer is regarded as a reference point in this field and this systematically written book on it is highly welcome. The writers do not attempt to give a comprehensive review of different approaches and implementations available in speech synthesis. (For this, see Klatt 1987.) Instead, they build their own theoretical framework by a thorough description of the MITalk implementation principles. The book is divided into parts in the same way as the synthesis process of MITalk itself. The book, as well as the text-to-speech synthesis, starts from the analysis of the text input. Text pre-processing is followed by morphological analysis. The extensive morph lexicon contributes significantly to the high quality of the synthesis process. A phrase-level parser is used with rules for morphophonemics and stress modification. The application of ordered phonological rules to letter-to-sound conversion and lexical stress concludes the text-analysis part of the text-to-speech process. The synthesis part of MITalk contains a phonological component, a prosodic component including a fundamental frequency generator, a phonetic component (all the time approaching a continuous-time representation)—and finally a formant synthesizer (called the Klatt synthesizer) to produce the continuous speech signal. The rest of the book discusses some pragmatic aspects like measures of intelligibility of the synthetic speech. This book is primarily of interest to those who are active in speech research and synthesizer development. However, especially the first half of the book might draw remarkable attention from the point of view of computational linguistics. Most chapters are easy to read (a possible exception is the formant-synthesizer section). One weakness of the book is that it took too many years to publish after the most intensive phases of the research work. There are also too few ideas to be found from an artificial-intelligence perspective even though the rule-based processing in speech synthesis could be improved by modern knowledge-based methods. The main message of the book to computational linguistics is perhaps threefold. First, that a close relationship to speech processing exists; second, it should</abstract>
<date confidence="0.393401">76 Computational Linguistics, Volume 14, Number 2, June 1988</date>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Jonathan Allen</author>
<author>M Sharon Hunnicutt</author>
<author>Dennis Klatt</author>
<author>with Robert C Armstrong</author>
<author>David Pisoni</author>
</authors>
<marker>Allen, Hunnicutt, Klatt, Armstrong, Pisoni, </marker>
<rawString>Jonathan Allen; M. Sharon Hunnicutt; and Dennis Klatt, with Robert C. Armstrong and David Pisoni</rawString>
</citation>
<citation valid="false">
<institution>Royal Institute of Technology, Stockholm, Sweden; MIT; MIT; Indiana University</institution>
<marker></marker>
<rawString>(Respectively: MIT; Royal Institute of Technology, Stockholm, Sweden; MIT; MIT; Indiana University)</rawString>
</citation>
<citation valid="true">
<authors>
<author>England Cambridge</author>
</authors>
<date>1987</date>
<journal>xi +</journal>
<volume>216</volume>
<pages>pp.</pages>
<publisher>Cambridge University Press,</publisher>
<marker>Cambridge, 1987</marker>
<rawString>Cambridge, England: Cambridge University Press, 1987, xi + 216 pp.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>