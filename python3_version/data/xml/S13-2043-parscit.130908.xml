<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.010219">
<title confidence="0.9945885">
DAEBAK!: Peripheral Diversity for Multilingual Word Sense
Disambiguation
</title>
<author confidence="0.997164">
Steve L. Manion
</author>
<affiliation confidence="0.903474">
University of Canterbury
Christchurch, New Zealand
steve.manion
</affiliation>
<email confidence="0.978976">
@pg.canterbury.ac.nz
</email>
<author confidence="0.976149">
Raazesh Sainudiin
</author>
<affiliation confidence="0.910407">
University of Canterbury
Christchurch, New Zealand
r.sainudiin
</affiliation>
<email confidence="0.988402">
@math.canterbury.ac.nz
</email>
<sectionHeader confidence="0.99854" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999134933333333">
We introduce Peripheral Diversity (PD) as a
knowledge-based approach to achieve multi-
lingual Word Sense Disambiguation (WSD).
PD exploits the frequency and diverse use
of word senses in semantic subgraphs de-
rived from larger sense inventories such as
BabelNet, Wikipedia, and WordNet in order
to achieve WSD. PD’s f-measure scores for
SemEval 2013 Task 12 outperform the Most
Frequent Sense (MFS) baseline for two of
the five languages: English, French, German,
Italian, and Spanish. Despite PD remain-
ing under-developed and under-explored, it
demonstrates that it is robust, competitive, and
encourages development.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999964657894737">
By reading out aloud “A minute is a minute divi-
sion of time” (Nelson, 1976), we can easily make
the distinction between the two senses of the homo-
graph minute. For a machine this is a complex task
known as Word Sense Disambiguation (WSD). Task
12 of SemEval 2013 (Navigli et al., 2013) calls for a
language-independent solution to WSD that utilises
a multilingual sense inventory.
Supervised approaches to WSD have dominated
for some time now (M`arquez et al., 2007). Homo-
graphs such as minute are effortlessly disambiguated
and more polysemous words such as bar or line
can also be disambiguated with reasonable compe-
tence (Agirre and Edmonds, 2007). However our ap-
proach is purely knowledge-based and employs se-
mantic graphs. This allows us to avoid the notorious
predicament Gale et al. (1992) name the information
bottleneck, in which supervised approaches fail to be
portable across alternative languages and domains
if the annotated corpora do not exist. Conversely,
knowledge-based approaches for WSD are usually
applicable to all words in unrestricted text (Mihal-
cea, 2007). It is this innate scalability that moti-
vates us to pursue knowledge-based approaches. Re-
gardless of whether sense inventories can maintain
knowledge-richness as they grow, their continued re-
finement by contributors is directly beneficial.
Knowledge-based approaches that employ se-
mantic graphs increasingly rival leading supervised
approaches to WSD. They can beat a Random or
LESK (Lesk, 1986) baseline (see Mihalcea (2005),
Navigli and Lapata (2007), Sinha and Mihalcea
(2007), Navigli and Lapata (2010)) and can com-
pete with or even beat the Most Frequent Sense
(MFS) baseline in certain contexts which is by no
means an easy task (see Navigli et al. (2007), Eneko
Agirre and Aitor Soroa (2009), Navigli and Ponzetto
(2012a)).
</bodyText>
<sectionHeader confidence="0.99523" genericHeader="introduction">
2 Methodology
</sectionHeader>
<bodyText confidence="0.99984375">
PD is a framework for knowledge-based WSD ap-
proaches that employ semantic graphs. However be-
fore we can elaborate we must first cover the funda-
mental resources it is built upon.
</bodyText>
<subsectionHeader confidence="0.993132">
2.1 Fundamental Resource Definitions
2.1.1 Lemma Sequences
</subsectionHeader>
<bodyText confidence="0.995778">
At a glance across the text of any language, we ab-
sorb meaning and new information through its lexi-
cal composition. Depending on the length of text
</bodyText>
<page confidence="0.905533">
250
</page>
<bodyText confidence="0.994505965517242">
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 250–254, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics
we are reading, we could interpret it as one of many
structural subsequences of writing such as a para-
graph, excerpt, quote, verse, sentence, among many
others. Let W = (wa, ..., wb) be this subsequence of
words, which we will utilise as a sliding window for
PD. Again let W = (w1,..., wm) be the larger body
of text of length m, such as a book, newspaper, or
corpus of text, that our sliding window of length b−a
moves through.
In SemEval Task 12 on Multilingual Word Sense
Disambiguation all words are lemmatised, which is
the process of unifying the different inflected forms
of a word so they can be analysed as a consolidated
lemma (or headword). Therefore words (or lexemes)
such as runs and ran are all mapped to their unifying
lemma run1.
To express this, let `w : W —* L be a many-
to-one mapping from the sequence of words W to
the sequence of lemmas L, in which (wa, ..., wb) H
(`wa, ...,`wb) = (`a, ..., `b). To give an example
from the test data set2, the word sequence W = (And,
it, ’s, nothing, that, runs, afoul, of, ethics, rules,
.) maps to the lemma sequence L = (and, it, be,
nothing, that, run, afoul, of, ethic, rule, .). In or-
der to complete this SemEval task we disambiguate
a large sequence of lemmas L = (`1, ..., `m), via our
lemma-based sliding window L = (`a, ..., `b).
</bodyText>
<subsectionHeader confidence="0.795734">
2.1.2 Synsets
</subsectionHeader>
<bodyText confidence="0.9997335">
Each lemma `i E L may refer up to k senses in
S(`i) = {si,1, si,2, ..., si,k} = S. Furthermore each
sense si,j E S maps to a set of unique concepts in
the human lexicon. To clarify let us consider one
of the earliest examples of modern ambiguity taken
from Bar-Hillel’s (1960) critique of Machine Trans-
lation: W = (The, box, was, in, the, pen, .). The
sense of pen could be either a) a certain writing uten-
sil or b) an enclosure where small children can play,
therefore {senclosure, sutensil} C S(`pen) = S. Humans
can easily resolve the ambiguity between the pos-
sible senses of pen by accessing their own internal
lexicon and knowledge of the world they have built
up over time.
In the same vein, when accessing sense invento-
ries such as BabelNet, WordNet (Fellbaum, 1998),
</bodyText>
<footnote confidence="0.985986666666667">
1While all words are lemmatised, this task strictly focuses
on the WSD of noun phrases.
2This is sentence d010.s014 in the English test data set.
</footnote>
<bodyText confidence="0.999620571428572">
and Wikipedia which are discrete representations of
the human lexicon, we refer to each sense si,j E S
as a synset. Depending on the sense inventory the
synset belongs to, it may contain alternative or trans-
lated lexicalisations, glosses, links to other semantic
resources, among a collection of semantically de-
fined relations to other synsets.
</bodyText>
<subsectionHeader confidence="0.876989">
2.1.3 Subgraphs
</subsectionHeader>
<bodyText confidence="0.999897894736842">
PD makes use of subgraphs derived from a di-
rected graph 9 = (V, £) that can be crafted from
a sense inventory, such as BabelNet, WordNet, or
Wikipedia. We construct subgraphs using the Babel-
Net API which accesses BabelNet3 and Babel synset
paths4 indexed into Apache Lucene5 to ensure speed
of subgraph construction. This process is described
in Navigli and Ponzetto (2012a) and demonstrated
in Navigli and Ponzetto (2012b). Our formalisation
of subgraphs is adapted into our own notation from
the original papers of Navigli and Lapata (2007) and
Navigli and Lapata (2010). We refer the reader to
these listed sources if they desire an extensive ex-
planation of our subgraph construction as we have
built PD on top of the same code base therefore we
do not deviate from it.
For a given lemma sequence L = (`i, ..., `n) and
directed graph 9 = (V, £) we construct our sub-
graph 9L = (VL, £L) in two steps:
</bodyText>
<listItem confidence="0.99155925">
1. Initialize VL := Uni=1 S(`i) and £L := 0.
2. For each node v E VL, we perform a depth-
first search (DFS) of 9, such that, every time
we encounter a node v&apos; E VL (v&apos; =� v) along a
path v, v1, ..., vk, v&apos; of length G L in 9, we add
all intermediate nodes and edges on the path
from v to v&apos;, i.e., VL := VL U {v1, ..., vk} and
£L := £L U {{v, v1}, ..., {vk, v&apos;}}.
</listItem>
<subsectionHeader confidence="0.999795">
2.2 Interpretation of Problem
</subsectionHeader>
<bodyText confidence="0.99985125">
For the lemmatisation of any word wi H `i :
wi E W, `i E L, we must estimate the most ap-
propriate synset si,* E S(`i) = {si,1, si,2, ..., si,k}.
Our system associates a PD score φ(si,j) for each
</bodyText>
<footnote confidence="0.99948">
3BabelNet 1.1.1 API &amp; Sense Inventory - http://lcl.
uniroma1.it/babelnet/download.jsp
4BabelNet 1.0.1 Paths - http://lcl.uniroma1.it/
babelnet/data/babelnet_paths.tar.bz2
5Apache Lucene - http://lucene.apache.org
</footnote>
<page confidence="0.994899">
251
</page>
<bodyText confidence="0.999944666666667">
si,j ∈ S(`i) by taking GL as input. We estimate
si,*, the most appropriate sense for `i, by ˆsi,* =
arg maxsi,�ES(`i) φ(si,j). It’s worth noting here that
GL ensures the estimation of ˆsi,* is not an indepen-
dent scoring rule, since GL embodies the context sur-
rounding `i via our sliding lemma-based window L.
</bodyText>
<subsectionHeader confidence="0.994977">
2.3 Peripheral Diversity Framework
</subsectionHeader>
<bodyText confidence="0.996198">
PD is built on the following two ideas that are ex-
plained in the following subsections:
</bodyText>
<listItem confidence="0.95754725">
1. For a subgraph derived from one lone lemma
`i, in which no other lemmas can provide con-
text, the synset si,j ∈ G`i that has the largest
and most semantically diverse set of peripheral
synset nodes is assumed to be the MFS for `i.
2. For a larger subgraph derived from a sliding
lemma window L, in which other lemmas can
provide context, the synset si,j ∈ GL that ob-
serves the largest increase in size and semantic
diversity of its peripheral synset nodes is esti-
mated to be si,*, the most appropriate synset for
lemma `i.
</listItem>
<bodyText confidence="0.964785">
Therefore PD is merely a framework that exploits
these two assumptions. Now we will go through the
process of estimating si,* for a given lemma `i.
</bodyText>
<subsectionHeader confidence="0.595701">
2.3.1 Pairwise Semantic Dissimilarity
</subsectionHeader>
<bodyText confidence="0.986722846153846">
First, for each synset si,j ∈ S, we need to acquire
a set of its peripheral synsets. We do this by travel-
ling a depth of up to d (stopping if the path ends),
then adding the synset we reach to our set of periph-
eral synsets P&lt;d = {sj,1, sj,2, ..., sj,k0}.
Next for every pair of synsets v and v&apos; that are
not direct neighbours in P&lt;d such that v =6 v&apos;,
we calculate their Pairwise Semantic Dissimilarity
(PSD) δ(v, v&apos;) which we require for a synset’s
PD score. To generate our results for this task we
have used the complement to Cosine Similarity,
commonly known as the Cosine Distance as our
PSD measure:
</bodyText>
<equation confidence="0.960315">
δ(v, v&apos;) =
� �
|O(v)nO(v0)|
1 − if |O(v)||O(v&apos;) |=6 0
√|O(v)|√|O(v0) |,
1, otherwise,
</equation>
<bodyText confidence="0.996034666666667">
where O(v) is the outgoing (out-neighbouring)
synsets for v ∈ P&lt;d, and |O(v) |denotes the number
of elements in O(v).
</bodyText>
<subsectionHeader confidence="0.768289">
2.3.2 Peripheral Diversity Score
</subsectionHeader>
<bodyText confidence="0.9999002">
Once we have PSD scores for every permitted
pairing of v and v&apos;, we have a number of ways to
generate our φ(si,j) values. To generate our results
for this task, we chose to score synsets on the sum
of their minimum PSD values, which is expressed
</bodyText>
<equation confidence="0.902312666666667">
formally below:
E
φ(si,j) =
</equation>
<bodyText confidence="0.985059666666667">
The idea is that this summing over the peripheral
synsets in P&lt;d(si,j) accounts for how frequently
synset si,j is used, then each increment in size is
weighted by a peripheral synset’s minimumal PSD
across all synsets in P&lt;d(si,j). Therefore periph-
eral set size and semantic diversity are rewarded
simultaneously by φ. To conclude, the final esti-
mated synset sequence for a given lemma sequence
(`1, ..., `m) based on φ is (ˆs1,*, ˆs2,*, ..., ˆsm,*).
</bodyText>
<subsubsectionHeader confidence="0.591965">
2.3.3 Strategies, Parameters, &amp; Filters
</subsubsectionHeader>
<bodyText confidence="0.999426722222222">
Wikipedia’s Did You Mean? We account for de-
viations and errors in spelling to ensure lemmas
have the best chance of being mapped to a synset.
Absent synsets in subgraph GL will naturally de-
grade system output. Therefore if `i 7→ ∅,
we make an HTTP call to Wikipedia’s Did you
mean? and parse the response for any alternative
spellings. For example in the test data set6 the
misspelt lemma: “feu de la rampe” is corrected to
“feux de la rampe”.
Custom Back-off Strategy As back-off strate-
gies7 have proved useful in (Navigli and Ponzetto,
2012a) and (Navigli et al., 2007), we designed our
own back-off strategy. In the event our system pro-
vides a null result, the Babel synset si,j ∈ S(`i) =
S with the most senses associated with it will be
chosen with preference to its region in BabelNet
such that WIKIWN &gt;- WN &gt;- WIKI.
</bodyText>
<footnote confidence="0.981706">
6Found in sentence d001.s002.t005 in the French test
data set.
7In the event the WSD technique fails to provide an answer,
a back-off strategy provides one for the system to output.
</footnote>
<equation confidence="0.5419514">
{
min
v0=/=v
vEP≤d(si,7) v0EP≤d(si,�)
δ(v, v&apos;)
</equation>
<page confidence="0.992068">
252
</page>
<bodyText confidence="0.999353923076923">
Input Parameters We set our sliding window
length (b − a) to encompass 5 sentences at a time, in
which the step size is also 5 sentences. For subgraph
construction the maximum length L = 3. Finally we
set our peripheral search depth d = 3.
Filters For the purposes of reproducibility only
we briefly mention two filters we apply to our sub-
graphs that ship with the BabelNet API. We re-
move WordNet contributed domain relations with
the ILLEGAL POINTERS filter and apply the
SENSE SHIFTS filter. For more information on
these filters we suggest the reader consult the Ba-
belNet API documentation.
</bodyText>
<sectionHeader confidence="0.999825" genericHeader="method">
3 Results &amp; Discussion
</sectionHeader>
<subsectionHeader confidence="0.991866">
3.1 Results of SemEval Submission
</subsectionHeader>
<table confidence="0.999166428571429">
Language DAEBAK! MFSBaseline +/-
DE German 59.10 68.60 -9.50
EN English 60.40 65.60 -5.20
ES Spanish 60.00 64.40 -4.40
FR French 53.80 50.10 +3.70
IT Italian 61.30 57.20 +4.10
Mean 58.92 61.18 -2.26
</table>
<tableCaption confidence="0.999893">
Table 1: DAEBAK! vs MFS Baseline on BabelNet
</tableCaption>
<bodyText confidence="0.9993100625">
As can be seen in Table 1, the results of our single
submission were varied and competitive. The worst
result was for German in which our system fell be-
hind the MFS baseline by a margin of 9.50. Again
for French and Italian we exceeded the MFS base-
line by a margin of 3.70 and 4.10 respectively. Our
Daebak back-off strategy contributed anywhere be-
tween 1.12% (for French) to 2.70% (for Spanish) in
our results, which means our system outputs a re-
sult without the need for a back-off strategy at least
97.30% of the time. Overall our system was slightly
outperformed by the MFS baseline by a margin of
2.26. Overall PD demonstrated to be robust across
a range of European languages. With these prelimi-
nary results this surely warrants further investigation
of what can be achieved with PD.
</bodyText>
<subsectionHeader confidence="0.999114">
3.2 Exploratory Results
</subsectionHeader>
<bodyText confidence="0.997508166666667">
The authors observed some inconsistencies in the
task answer keys across different languages as Ta-
ble 2 illustrates. For each Babel synset ID found in
the answer key, we record where its original source
synsets are from, be it Wikipedia (WIKI), WordNet
(WN), or both (WIKIWN).
</bodyText>
<table confidence="0.999776166666667">
Language WIKI WN WIKIWN
DE German 43.42% 5.02% 51.55%
EN English 10.36% 32.11% 57.53%
ES Spanish 30.65% 5.40% 63.94%
FR French 40.81% 6.55% 52.64%
IT Italian 38.80% 7.33% 53.87%
</table>
<tableCaption confidence="0.99853">
Table 2: BabelNet Answer Key Breakdown
</tableCaption>
<bodyText confidence="0.999909166666667">
This is not a critical observation but rather an
empirical enlightenment on the varied mechanics
of different languages and the amount of devel-
opment/translation effort that has gone into the
contributing subparts of BabelNet: Wikipedia and
WordNet. The heterogeneity of hybrid sense inven-
tories such as BabelNet creates new obstacles for
WSD, as seen in (Medelyan et al., 2013) it is diffi-
cult to create a disambiguation policy in this context.
Future work we would like to undertake would be to
investigate the heterogenous nature of BabelNet and
how this affects various WSD methods.
</bodyText>
<sectionHeader confidence="0.999073" genericHeader="method">
4 Conclusion &amp; Future Directions
</sectionHeader>
<bodyText confidence="0.9999315">
To conclude PD has demonstrated in its early stages
that it can perform well and even outperform the
MFS baselines in certain experimental contexts.
Furthermore it leaves a lot left to be explored in
terms of what this approach is capable of via adjust-
ing subgraph filters, strategies, and input parameters
across both heterogenous and homogenous semantic
graphs.
</bodyText>
<sectionHeader confidence="0.998318" genericHeader="evaluation">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.8856145">
This research was completed with the help of the
Korean Foundation Graduate Studies Fellowship8.
</bodyText>
<sectionHeader confidence="0.999805" genericHeader="conclusions">
5 Resources
</sectionHeader>
<bodyText confidence="0.9625785">
The code base for this work can be found in the near
future at http://www.stevemanion.com/.
</bodyText>
<footnote confidence="0.9912525">
8KF Graduate Studies Fellowship - http://www.kf.
or.kr/eng/01_sks/sks_fel_sfb01.asp
</footnote>
<page confidence="0.99806">
253
</page>
<sectionHeader confidence="0.993758" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998727">
Eneko Agirre and Philip Edmonds. 2007. Introduction.
Word Sense Disambiguation Algorithms and Applica-
tions, Chapter 1:1-28. Springer, New York.
Eneko Agirre and Aitor Soroa. 2009. Personaliz-
ing PageRank for Word Sense Disambiguation. In
Proceedings of the 12th Conference of the European
Chapter of the ACL, April:33–41. Association for
Computational Linguistics.
Yehoshua Bar-Hillel. 1960. The Present Status of Au-
tomatic Translation of Languages. Advances in Com-
puters, 1:91–163.
Christiane Fellbaum. 1998, ed. WordNet: An Electronic
Lexical Database., Cambridge, MA: MIT Press.
William A Gale, Kenneth W Church, David Yarowsky.
1992. A Method for Disambiguating Word Senses in a
Large Corpus. Computers and the Humanities, 26(5–
6):415–439.
Michael Lesk. 1986. Automatic Sense Disambiguation
Using Machine Readable Dictionaries: How to Tell
a Pine Cone from an Ice Cream Cone. Proceedings
of the 5th Annual International Conference on System
Documentation., 24–26. ACM.
Llus M`arquez, Gerard Escudero, David Martinez, Ger-
man Rigau. 2007. Supervised Corpus-Based Meth-
ods for WSD. Word Sense Disambiguation Algorithms
and Applications, Chapter 7:167-216. Springer, New
York.
Rada Mihalcea. 2005. Unsupervised Large-Vocabulary
Word Sense Disambiguation with Graph-based Algo-
rithms for Sequence Data Labeling. Proceedings of
the conference on Human Language Technology and
Empirical Methods in Natural Language Processing,
411-418. Association for Computational Linguistics.
Rada Mihalcea. 2007. Knowledge-Based Methods
for WSD. Word Sense Disambiguation Algorithms
and Applications, Chapter 5:107–131. Springer, New
York.
Alyona Medelyan, Steve Manion, Jeen Broekstra, Anna
Divoli, Anna-lan Huang, and Ian H Witten. 2013.
Constructing a Focused Taxonomy from a Document
Collection Extended Semantic Web Conference, (Ac-
cepted, in press)
Roberto Navigli and Mirella Lapata. 2007. Graph con-
nectivity measures for unsupervised word sense dis-
ambiguation. IJCAI’07 Proceedings of the 20th In-
ternational Joint Conference on Artifical Intelligence,
1683–1688.
Roberto Navigli, Kenneth C Litkowski, and Orin Har-
graves. 2007. SemEval-2007 Task 07: Coarse-
Grained English All-Words Task. In Proceedings of
the 4th International Workshop on Semantic Evalua-
tions, 30–35.
Roberto Navigli and Mirella Lapata. 2010. An Experi-
mental Study of Graph Connectivity for Unsupervised
Word Sense Disambiguation. IEEE transactions on
pattern analysis and machine intelligence, 32(4):678–
692.
Roberto Navigli and Simone Paolo Ponzetto. 2012. Ba-
belNet: The automatic construction, evaluation and
application of a wide-coverage multilingual semantic
network. Artificial Intelligence, 193:217–250.
Roberto Navigli and Simone Paolo Ponzetto. 2012. Mul-
tilingual WSD with Just a Few Lines of Code: the Ba-
belNet API. In Proceedings of the 50th Annual Meet-
ing of the Association for Computational Linguistics,
67–72.
Roberto Navigli, David Jurgens, and Daniele Vannella.
2013. SemEval-2013 Task 12: Multilingual Word
Sense Disambiguation. Proceedings of the 7th Inter-
national Workshop on Semantic Evaluation (SemEval
2013), in conjunction with the Second Joint Confer-
ence on Lexical and Computational Semantcis (*SEM
2013).
Frederic Nelson. 1976. Homographs American Speech,
51(3):296–297.
Ravi Sinha and Rada Mihalcea. 2007. Unsupervised
Graph-based Word Sense Disambiguation Using Mea-
sures of Word Semantic Similarity. Proceedings of
IEEE International Conference on Semantic Comput-
ing.
</reference>
<page confidence="0.99862">
254
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.588022">
<title confidence="0.9990395">DAEBAK!: Peripheral Diversity for Multilingual Word Sense Disambiguation</title>
<author confidence="0.999479">L Steve</author>
<affiliation confidence="0.999864">University of</affiliation>
<address confidence="0.965834">Christchurch, New</address>
<email confidence="0.971568">@pg.canterbury.ac.nz</email>
<author confidence="0.695406">Raazesh</author>
<affiliation confidence="0.999301">University of</affiliation>
<address confidence="0.968901">Christchurch, New</address>
<email confidence="0.982155">@math.canterbury.ac.nz</email>
<abstract confidence="0.99613175">We introduce Peripheral Diversity (PD) as a knowledge-based approach to achieve multilingual Word Sense Disambiguation (WSD). PD exploits the frequency and diverse use of word senses in semantic subgraphs derived from larger sense inventories such as BabelNet, Wikipedia, and WordNet in order achieve WSD. PD’s scores for SemEval 2013 Task 12 outperform the Most Frequent Sense (MFS) baseline for two of the five languages: English, French, German, Italian, and Spanish. Despite PD remaining under-developed and under-explored, it demonstrates that it is robust, competitive, and encourages development.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Philip Edmonds</author>
</authors>
<title>Introduction. Word Sense Disambiguation Algorithms and Applications, Chapter 1:1-28.</title>
<date>2007</date>
<publisher>Springer,</publisher>
<location>New York.</location>
<contexts>
<context position="1569" citStr="Agirre and Edmonds, 2007" startWordPosition="228" endWordPosition="231">inute is a minute division of time” (Nelson, 1976), we can easily make the distinction between the two senses of the homograph minute. For a machine this is a complex task known as Word Sense Disambiguation (WSD). Task 12 of SemEval 2013 (Navigli et al., 2013) calls for a language-independent solution to WSD that utilises a multilingual sense inventory. Supervised approaches to WSD have dominated for some time now (M`arquez et al., 2007). Homographs such as minute are effortlessly disambiguated and more polysemous words such as bar or line can also be disambiguated with reasonable competence (Agirre and Edmonds, 2007). However our approach is purely knowledge-based and employs semantic graphs. This allows us to avoid the notorious predicament Gale et al. (1992) name the information bottleneck, in which supervised approaches fail to be portable across alternative languages and domains if the annotated corpora do not exist. Conversely, knowledge-based approaches for WSD are usually applicable to all words in unrestricted text (Mihalcea, 2007). It is this innate scalability that motivates us to pursue knowledge-based approaches. Regardless of whether sense inventories can maintain knowledge-richness as they g</context>
</contexts>
<marker>Agirre, Edmonds, 2007</marker>
<rawString>Eneko Agirre and Philip Edmonds. 2007. Introduction. Word Sense Disambiguation Algorithms and Applications, Chapter 1:1-28. Springer, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Aitor Soroa</author>
</authors>
<title>Personalizing PageRank for Word Sense Disambiguation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the ACL, April:33–41. Association for Computational Linguistics.</booktitle>
<marker>Agirre, Soroa, 2009</marker>
<rawString>Eneko Agirre and Aitor Soroa. 2009. Personalizing PageRank for Word Sense Disambiguation. In Proceedings of the 12th Conference of the European Chapter of the ACL, April:33–41. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yehoshua Bar-Hillel</author>
</authors>
<title>The Present Status of Automatic Translation of Languages.</title>
<date>1960</date>
<booktitle>Advances in Computers,</booktitle>
<pages>1--91</pages>
<marker>Bar-Hillel, 1960</marker>
<rawString>Yehoshua Bar-Hillel. 1960. The Present Status of Automatic Translation of Languages. Advances in Computers, 1:91–163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<date>1998</date>
<booktitle>WordNet: An Electronic Lexical Database.,</booktitle>
<editor>ed.</editor>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA:</location>
<contexts>
<context position="5470" citStr="Fellbaum, 1998" startWordPosition="897" endWordPosition="898">an lexicon. To clarify let us consider one of the earliest examples of modern ambiguity taken from Bar-Hillel’s (1960) critique of Machine Translation: W = (The, box, was, in, the, pen, .). The sense of pen could be either a) a certain writing utensil or b) an enclosure where small children can play, therefore {senclosure, sutensil} C S(`pen) = S. Humans can easily resolve the ambiguity between the possible senses of pen by accessing their own internal lexicon and knowledge of the world they have built up over time. In the same vein, when accessing sense inventories such as BabelNet, WordNet (Fellbaum, 1998), 1While all words are lemmatised, this task strictly focuses on the WSD of noun phrases. 2This is sentence d010.s014 in the English test data set. and Wikipedia which are discrete representations of the human lexicon, we refer to each sense si,j E S as a synset. Depending on the sense inventory the synset belongs to, it may contain alternative or translated lexicalisations, glosses, links to other semantic resources, among a collection of semantically defined relations to other synsets. 2.1.3 Subgraphs PD makes use of subgraphs derived from a directed graph 9 = (V, £) that can be crafted from</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998, ed. WordNet: An Electronic Lexical Database., Cambridge, MA: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Gale</author>
<author>Kenneth W Church</author>
<author>David Yarowsky</author>
</authors>
<title>A Method for Disambiguating Word Senses in a Large Corpus. Computers and the Humanities,</title>
<date>1992</date>
<volume>26</volume>
<issue>5</issue>
<pages>6--415</pages>
<contexts>
<context position="1715" citStr="Gale et al. (1992)" startWordPosition="252" endWordPosition="255"> is a complex task known as Word Sense Disambiguation (WSD). Task 12 of SemEval 2013 (Navigli et al., 2013) calls for a language-independent solution to WSD that utilises a multilingual sense inventory. Supervised approaches to WSD have dominated for some time now (M`arquez et al., 2007). Homographs such as minute are effortlessly disambiguated and more polysemous words such as bar or line can also be disambiguated with reasonable competence (Agirre and Edmonds, 2007). However our approach is purely knowledge-based and employs semantic graphs. This allows us to avoid the notorious predicament Gale et al. (1992) name the information bottleneck, in which supervised approaches fail to be portable across alternative languages and domains if the annotated corpora do not exist. Conversely, knowledge-based approaches for WSD are usually applicable to all words in unrestricted text (Mihalcea, 2007). It is this innate scalability that motivates us to pursue knowledge-based approaches. Regardless of whether sense inventories can maintain knowledge-richness as they grow, their continued refinement by contributors is directly beneficial. Knowledge-based approaches that employ semantic graphs increasingly rival </context>
</contexts>
<marker>Gale, Church, Yarowsky, 1992</marker>
<rawString>William A Gale, Kenneth W Church, David Yarowsky. 1992. A Method for Disambiguating Word Senses in a Large Corpus. Computers and the Humanities, 26(5– 6):415–439.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Lesk</author>
</authors>
<title>Automatic Sense Disambiguation Using Machine Readable Dictionaries: How to Tell a Pine Cone from an Ice Cream Cone.</title>
<date>1986</date>
<booktitle>Proceedings of the 5th Annual International Conference on System Documentation.,</booktitle>
<pages>24--26</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2396" citStr="Lesk, 1986" startWordPosition="352" endWordPosition="353">to be portable across alternative languages and domains if the annotated corpora do not exist. Conversely, knowledge-based approaches for WSD are usually applicable to all words in unrestricted text (Mihalcea, 2007). It is this innate scalability that motivates us to pursue knowledge-based approaches. Regardless of whether sense inventories can maintain knowledge-richness as they grow, their continued refinement by contributors is directly beneficial. Knowledge-based approaches that employ semantic graphs increasingly rival leading supervised approaches to WSD. They can beat a Random or LESK (Lesk, 1986) baseline (see Mihalcea (2005), Navigli and Lapata (2007), Sinha and Mihalcea (2007), Navigli and Lapata (2010)) and can compete with or even beat the Most Frequent Sense (MFS) baseline in certain contexts which is by no means an easy task (see Navigli et al. (2007), Eneko Agirre and Aitor Soroa (2009), Navigli and Ponzetto (2012a)). 2 Methodology PD is a framework for knowledge-based WSD approaches that employ semantic graphs. However before we can elaborate we must first cover the fundamental resources it is built upon. 2.1 Fundamental Resource Definitions 2.1.1 Lemma Sequences At a glance a</context>
</contexts>
<marker>Lesk, 1986</marker>
<rawString>Michael Lesk. 1986. Automatic Sense Disambiguation Using Machine Readable Dictionaries: How to Tell a Pine Cone from an Ice Cream Cone. Proceedings of the 5th Annual International Conference on System Documentation., 24–26. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Llus M`arquez</author>
<author>Gerard Escudero</author>
<author>David Martinez</author>
<author>German Rigau</author>
</authors>
<title>Supervised Corpus-Based Methods for WSD. Word Sense Disambiguation Algorithms and Applications, Chapter 7:167-216.</title>
<date>2007</date>
<publisher>Springer,</publisher>
<location>New York.</location>
<marker>M`arquez, Escudero, Martinez, Rigau, 2007</marker>
<rawString>Llus M`arquez, Gerard Escudero, David Martinez, German Rigau. 2007. Supervised Corpus-Based Methods for WSD. Word Sense Disambiguation Algorithms and Applications, Chapter 7:167-216. Springer, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
</authors>
<title>Unsupervised Large-Vocabulary Word Sense Disambiguation with Graph-based Algorithms for Sequence Data Labeling.</title>
<date>2005</date>
<booktitle>Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing,</booktitle>
<pages>411--418</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="2426" citStr="Mihalcea (2005)" startWordPosition="356" endWordPosition="357">rnative languages and domains if the annotated corpora do not exist. Conversely, knowledge-based approaches for WSD are usually applicable to all words in unrestricted text (Mihalcea, 2007). It is this innate scalability that motivates us to pursue knowledge-based approaches. Regardless of whether sense inventories can maintain knowledge-richness as they grow, their continued refinement by contributors is directly beneficial. Knowledge-based approaches that employ semantic graphs increasingly rival leading supervised approaches to WSD. They can beat a Random or LESK (Lesk, 1986) baseline (see Mihalcea (2005), Navigli and Lapata (2007), Sinha and Mihalcea (2007), Navigli and Lapata (2010)) and can compete with or even beat the Most Frequent Sense (MFS) baseline in certain contexts which is by no means an easy task (see Navigli et al. (2007), Eneko Agirre and Aitor Soroa (2009), Navigli and Ponzetto (2012a)). 2 Methodology PD is a framework for knowledge-based WSD approaches that employ semantic graphs. However before we can elaborate we must first cover the fundamental resources it is built upon. 2.1 Fundamental Resource Definitions 2.1.1 Lemma Sequences At a glance across the text of any language</context>
</contexts>
<marker>Mihalcea, 2005</marker>
<rawString>Rada Mihalcea. 2005. Unsupervised Large-Vocabulary Word Sense Disambiguation with Graph-based Algorithms for Sequence Data Labeling. Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, 411-418. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
</authors>
<title>Knowledge-Based Methods for WSD. Word Sense Disambiguation Algorithms and Applications, Chapter 5:107–131.</title>
<date>2007</date>
<publisher>Springer,</publisher>
<location>New York.</location>
<contexts>
<context position="2000" citStr="Mihalcea, 2007" startWordPosition="294" endWordPosition="296">. Homographs such as minute are effortlessly disambiguated and more polysemous words such as bar or line can also be disambiguated with reasonable competence (Agirre and Edmonds, 2007). However our approach is purely knowledge-based and employs semantic graphs. This allows us to avoid the notorious predicament Gale et al. (1992) name the information bottleneck, in which supervised approaches fail to be portable across alternative languages and domains if the annotated corpora do not exist. Conversely, knowledge-based approaches for WSD are usually applicable to all words in unrestricted text (Mihalcea, 2007). It is this innate scalability that motivates us to pursue knowledge-based approaches. Regardless of whether sense inventories can maintain knowledge-richness as they grow, their continued refinement by contributors is directly beneficial. Knowledge-based approaches that employ semantic graphs increasingly rival leading supervised approaches to WSD. They can beat a Random or LESK (Lesk, 1986) baseline (see Mihalcea (2005), Navigli and Lapata (2007), Sinha and Mihalcea (2007), Navigli and Lapata (2010)) and can compete with or even beat the Most Frequent Sense (MFS) baseline in certain context</context>
</contexts>
<marker>Mihalcea, 2007</marker>
<rawString>Rada Mihalcea. 2007. Knowledge-Based Methods for WSD. Word Sense Disambiguation Algorithms and Applications, Chapter 5:107–131. Springer, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alyona Medelyan</author>
<author>Steve Manion</author>
<author>Jeen Broekstra</author>
<author>Anna Divoli</author>
<author>Anna-lan Huang</author>
<author>Ian H Witten</author>
</authors>
<title>Constructing a Focused Taxonomy from a Document Collection Extended Semantic Web Conference, (Accepted,</title>
<date>2013</date>
<note>in press</note>
<contexts>
<context position="14074" citStr="Medelyan et al., 2013" startWordPosition="2405" endWordPosition="2408">et (WN), or both (WIKIWN). Language WIKI WN WIKIWN DE German 43.42% 5.02% 51.55% EN English 10.36% 32.11% 57.53% ES Spanish 30.65% 5.40% 63.94% FR French 40.81% 6.55% 52.64% IT Italian 38.80% 7.33% 53.87% Table 2: BabelNet Answer Key Breakdown This is not a critical observation but rather an empirical enlightenment on the varied mechanics of different languages and the amount of development/translation effort that has gone into the contributing subparts of BabelNet: Wikipedia and WordNet. The heterogeneity of hybrid sense inventories such as BabelNet creates new obstacles for WSD, as seen in (Medelyan et al., 2013) it is difficult to create a disambiguation policy in this context. Future work we would like to undertake would be to investigate the heterogenous nature of BabelNet and how this affects various WSD methods. 4 Conclusion &amp; Future Directions To conclude PD has demonstrated in its early stages that it can perform well and even outperform the MFS baselines in certain experimental contexts. Furthermore it leaves a lot left to be explored in terms of what this approach is capable of via adjusting subgraph filters, strategies, and input parameters across both heterogenous and homogenous semantic gr</context>
</contexts>
<marker>Medelyan, Manion, Broekstra, Divoli, Huang, Witten, 2013</marker>
<rawString>Alyona Medelyan, Steve Manion, Jeen Broekstra, Anna Divoli, Anna-lan Huang, and Ian H Witten. 2013. Constructing a Focused Taxonomy from a Document Collection Extended Semantic Web Conference, (Accepted, in press)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Mirella Lapata</author>
</authors>
<title>Graph connectivity measures for unsupervised word sense disambiguation.</title>
<date>2007</date>
<booktitle>IJCAI’07 Proceedings of the 20th International Joint Conference on Artifical Intelligence,</booktitle>
<pages>1683--1688</pages>
<contexts>
<context position="2453" citStr="Navigli and Lapata (2007)" startWordPosition="358" endWordPosition="361"> and domains if the annotated corpora do not exist. Conversely, knowledge-based approaches for WSD are usually applicable to all words in unrestricted text (Mihalcea, 2007). It is this innate scalability that motivates us to pursue knowledge-based approaches. Regardless of whether sense inventories can maintain knowledge-richness as they grow, their continued refinement by contributors is directly beneficial. Knowledge-based approaches that employ semantic graphs increasingly rival leading supervised approaches to WSD. They can beat a Random or LESK (Lesk, 1986) baseline (see Mihalcea (2005), Navigli and Lapata (2007), Sinha and Mihalcea (2007), Navigli and Lapata (2010)) and can compete with or even beat the Most Frequent Sense (MFS) baseline in certain contexts which is by no means an easy task (see Navigli et al. (2007), Eneko Agirre and Aitor Soroa (2009), Navigli and Ponzetto (2012a)). 2 Methodology PD is a framework for knowledge-based WSD approaches that employ semantic graphs. However before we can elaborate we must first cover the fundamental resources it is built upon. 2.1 Fundamental Resource Definitions 2.1.1 Lemma Sequences At a glance across the text of any language, we absorb meaning and new</context>
<context position="6521" citStr="Navigli and Lapata (2007)" startWordPosition="1066" endWordPosition="1069">g a collection of semantically defined relations to other synsets. 2.1.3 Subgraphs PD makes use of subgraphs derived from a directed graph 9 = (V, £) that can be crafted from a sense inventory, such as BabelNet, WordNet, or Wikipedia. We construct subgraphs using the BabelNet API which accesses BabelNet3 and Babel synset paths4 indexed into Apache Lucene5 to ensure speed of subgraph construction. This process is described in Navigli and Ponzetto (2012a) and demonstrated in Navigli and Ponzetto (2012b). Our formalisation of subgraphs is adapted into our own notation from the original papers of Navigli and Lapata (2007) and Navigli and Lapata (2010). We refer the reader to these listed sources if they desire an extensive explanation of our subgraph construction as we have built PD on top of the same code base therefore we do not deviate from it. For a given lemma sequence L = (`i, ..., `n) and directed graph 9 = (V, £) we construct our subgraph 9L = (VL, £L) in two steps: 1. Initialize VL := Uni=1 S(`i) and £L := 0. 2. For each node v E VL, we perform a depthfirst search (DFS) of 9, such that, every time we encounter a node v&apos; E VL (v&apos; =� v) along a path v, v1, ..., vk, v&apos; of length G L in 9, we add all inte</context>
</contexts>
<marker>Navigli, Lapata, 2007</marker>
<rawString>Roberto Navigli and Mirella Lapata. 2007. Graph connectivity measures for unsupervised word sense disambiguation. IJCAI’07 Proceedings of the 20th International Joint Conference on Artifical Intelligence, 1683–1688.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Kenneth C Litkowski</author>
<author>Orin Hargraves</author>
</authors>
<title>SemEval-2007 Task 07: CoarseGrained English All-Words Task.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations,</booktitle>
<pages>30--35</pages>
<contexts>
<context position="2662" citStr="Navigli et al. (2007)" startWordPosition="396" endWordPosition="399">vates us to pursue knowledge-based approaches. Regardless of whether sense inventories can maintain knowledge-richness as they grow, their continued refinement by contributors is directly beneficial. Knowledge-based approaches that employ semantic graphs increasingly rival leading supervised approaches to WSD. They can beat a Random or LESK (Lesk, 1986) baseline (see Mihalcea (2005), Navigli and Lapata (2007), Sinha and Mihalcea (2007), Navigli and Lapata (2010)) and can compete with or even beat the Most Frequent Sense (MFS) baseline in certain contexts which is by no means an easy task (see Navigli et al. (2007), Eneko Agirre and Aitor Soroa (2009), Navigli and Ponzetto (2012a)). 2 Methodology PD is a framework for knowledge-based WSD approaches that employ semantic graphs. However before we can elaborate we must first cover the fundamental resources it is built upon. 2.1 Fundamental Resource Definitions 2.1.1 Lemma Sequences At a glance across the text of any language, we absorb meaning and new information through its lexical composition. Depending on the length of text 250 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Eva</context>
<context position="11008" citStr="Navigli et al., 2007" startWordPosition="1881" endWordPosition="1884">, ˆsm,*). 2.3.3 Strategies, Parameters, &amp; Filters Wikipedia’s Did You Mean? We account for deviations and errors in spelling to ensure lemmas have the best chance of being mapped to a synset. Absent synsets in subgraph GL will naturally degrade system output. Therefore if `i 7→ ∅, we make an HTTP call to Wikipedia’s Did you mean? and parse the response for any alternative spellings. For example in the test data set6 the misspelt lemma: “feu de la rampe” is corrected to “feux de la rampe”. Custom Back-off Strategy As back-off strategies7 have proved useful in (Navigli and Ponzetto, 2012a) and (Navigli et al., 2007), we designed our own back-off strategy. In the event our system provides a null result, the Babel synset si,j ∈ S(`i) = S with the most senses associated with it will be chosen with preference to its region in BabelNet such that WIKIWN &gt;- WN &gt;- WIKI. 6Found in sentence d001.s002.t005 in the French test data set. 7In the event the WSD technique fails to provide an answer, a back-off strategy provides one for the system to output. { min v0=/=v vEP≤d(si,7) v0EP≤d(si,�) δ(v, v&apos;) 252 Input Parameters We set our sliding window length (b − a) to encompass 5 sentences at a time, in which the step siz</context>
</contexts>
<marker>Navigli, Litkowski, Hargraves, 2007</marker>
<rawString>Roberto Navigli, Kenneth C Litkowski, and Orin Hargraves. 2007. SemEval-2007 Task 07: CoarseGrained English All-Words Task. In Proceedings of the 4th International Workshop on Semantic Evaluations, 30–35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Mirella Lapata</author>
</authors>
<title>An Experimental Study of Graph Connectivity for Unsupervised Word Sense Disambiguation.</title>
<date>2010</date>
<booktitle>IEEE transactions on pattern analysis and machine intelligence,</booktitle>
<volume>32</volume>
<issue>4</issue>
<pages>692</pages>
<contexts>
<context position="2507" citStr="Navigli and Lapata (2010)" startWordPosition="366" endWordPosition="369">nversely, knowledge-based approaches for WSD are usually applicable to all words in unrestricted text (Mihalcea, 2007). It is this innate scalability that motivates us to pursue knowledge-based approaches. Regardless of whether sense inventories can maintain knowledge-richness as they grow, their continued refinement by contributors is directly beneficial. Knowledge-based approaches that employ semantic graphs increasingly rival leading supervised approaches to WSD. They can beat a Random or LESK (Lesk, 1986) baseline (see Mihalcea (2005), Navigli and Lapata (2007), Sinha and Mihalcea (2007), Navigli and Lapata (2010)) and can compete with or even beat the Most Frequent Sense (MFS) baseline in certain contexts which is by no means an easy task (see Navigli et al. (2007), Eneko Agirre and Aitor Soroa (2009), Navigli and Ponzetto (2012a)). 2 Methodology PD is a framework for knowledge-based WSD approaches that employ semantic graphs. However before we can elaborate we must first cover the fundamental resources it is built upon. 2.1 Fundamental Resource Definitions 2.1.1 Lemma Sequences At a glance across the text of any language, we absorb meaning and new information through its lexical composition. Dependin</context>
<context position="6551" citStr="Navigli and Lapata (2010)" startWordPosition="1071" endWordPosition="1074"> defined relations to other synsets. 2.1.3 Subgraphs PD makes use of subgraphs derived from a directed graph 9 = (V, £) that can be crafted from a sense inventory, such as BabelNet, WordNet, or Wikipedia. We construct subgraphs using the BabelNet API which accesses BabelNet3 and Babel synset paths4 indexed into Apache Lucene5 to ensure speed of subgraph construction. This process is described in Navigli and Ponzetto (2012a) and demonstrated in Navigli and Ponzetto (2012b). Our formalisation of subgraphs is adapted into our own notation from the original papers of Navigli and Lapata (2007) and Navigli and Lapata (2010). We refer the reader to these listed sources if they desire an extensive explanation of our subgraph construction as we have built PD on top of the same code base therefore we do not deviate from it. For a given lemma sequence L = (`i, ..., `n) and directed graph 9 = (V, £) we construct our subgraph 9L = (VL, £L) in two steps: 1. Initialize VL := Uni=1 S(`i) and £L := 0. 2. For each node v E VL, we perform a depthfirst search (DFS) of 9, such that, every time we encounter a node v&apos; E VL (v&apos; =� v) along a path v, v1, ..., vk, v&apos; of length G L in 9, we add all intermediate nodes and edges on th</context>
</contexts>
<marker>Navigli, Lapata, 2010</marker>
<rawString>Roberto Navigli and Mirella Lapata. 2010. An Experimental Study of Graph Connectivity for Unsupervised Word Sense Disambiguation. IEEE transactions on pattern analysis and machine intelligence, 32(4):678– 692.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network.</title>
<date>2012</date>
<journal>Artificial Intelligence,</journal>
<pages>193--217</pages>
<contexts>
<context position="2727" citStr="Navigli and Ponzetto (2012" startWordPosition="406" endWordPosition="409"> whether sense inventories can maintain knowledge-richness as they grow, their continued refinement by contributors is directly beneficial. Knowledge-based approaches that employ semantic graphs increasingly rival leading supervised approaches to WSD. They can beat a Random or LESK (Lesk, 1986) baseline (see Mihalcea (2005), Navigli and Lapata (2007), Sinha and Mihalcea (2007), Navigli and Lapata (2010)) and can compete with or even beat the Most Frequent Sense (MFS) baseline in certain contexts which is by no means an easy task (see Navigli et al. (2007), Eneko Agirre and Aitor Soroa (2009), Navigli and Ponzetto (2012a)). 2 Methodology PD is a framework for knowledge-based WSD approaches that employ semantic graphs. However before we can elaborate we must first cover the fundamental resources it is built upon. 2.1 Fundamental Resource Definitions 2.1.1 Lemma Sequences At a glance across the text of any language, we absorb meaning and new information through its lexical composition. Depending on the length of text 250 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 250–254, Atlanta, Georgia, June 14-</context>
<context position="6351" citStr="Navigli and Ponzetto (2012" startWordPosition="1040" endWordPosition="1043"> synset. Depending on the sense inventory the synset belongs to, it may contain alternative or translated lexicalisations, glosses, links to other semantic resources, among a collection of semantically defined relations to other synsets. 2.1.3 Subgraphs PD makes use of subgraphs derived from a directed graph 9 = (V, £) that can be crafted from a sense inventory, such as BabelNet, WordNet, or Wikipedia. We construct subgraphs using the BabelNet API which accesses BabelNet3 and Babel synset paths4 indexed into Apache Lucene5 to ensure speed of subgraph construction. This process is described in Navigli and Ponzetto (2012a) and demonstrated in Navigli and Ponzetto (2012b). Our formalisation of subgraphs is adapted into our own notation from the original papers of Navigli and Lapata (2007) and Navigli and Lapata (2010). We refer the reader to these listed sources if they desire an extensive explanation of our subgraph construction as we have built PD on top of the same code base therefore we do not deviate from it. For a given lemma sequence L = (`i, ..., `n) and directed graph 9 = (V, £) we construct our subgraph 9L = (VL, £L) in two steps: 1. Initialize VL := Uni=1 S(`i) and £L := 0. 2. For each node v E VL, </context>
<context position="10979" citStr="Navigli and Ponzetto, 2012" startWordPosition="1876" endWordPosition="1879">) based on φ is (ˆs1,*, ˆs2,*, ..., ˆsm,*). 2.3.3 Strategies, Parameters, &amp; Filters Wikipedia’s Did You Mean? We account for deviations and errors in spelling to ensure lemmas have the best chance of being mapped to a synset. Absent synsets in subgraph GL will naturally degrade system output. Therefore if `i 7→ ∅, we make an HTTP call to Wikipedia’s Did you mean? and parse the response for any alternative spellings. For example in the test data set6 the misspelt lemma: “feu de la rampe” is corrected to “feux de la rampe”. Custom Back-off Strategy As back-off strategies7 have proved useful in (Navigli and Ponzetto, 2012a) and (Navigli et al., 2007), we designed our own back-off strategy. In the event our system provides a null result, the Babel synset si,j ∈ S(`i) = S with the most senses associated with it will be chosen with preference to its region in BabelNet such that WIKIWN &gt;- WN &gt;- WIKI. 6Found in sentence d001.s002.t005 in the French test data set. 7In the event the WSD technique fails to provide an answer, a back-off strategy provides one for the system to output. { min v0=/=v vEP≤d(si,7) v0EP≤d(si,�) δ(v, v&apos;) 252 Input Parameters We set our sliding window length (b − a) to encompass 5 sentences at </context>
</contexts>
<marker>Navigli, Ponzetto, 2012</marker>
<rawString>Roberto Navigli and Simone Paolo Ponzetto. 2012. BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network. Artificial Intelligence, 193:217–250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>Multilingual WSD with Just a Few Lines of Code: the BabelNet API.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>67--72</pages>
<contexts>
<context position="2727" citStr="Navigli and Ponzetto (2012" startWordPosition="406" endWordPosition="409"> whether sense inventories can maintain knowledge-richness as they grow, their continued refinement by contributors is directly beneficial. Knowledge-based approaches that employ semantic graphs increasingly rival leading supervised approaches to WSD. They can beat a Random or LESK (Lesk, 1986) baseline (see Mihalcea (2005), Navigli and Lapata (2007), Sinha and Mihalcea (2007), Navigli and Lapata (2010)) and can compete with or even beat the Most Frequent Sense (MFS) baseline in certain contexts which is by no means an easy task (see Navigli et al. (2007), Eneko Agirre and Aitor Soroa (2009), Navigli and Ponzetto (2012a)). 2 Methodology PD is a framework for knowledge-based WSD approaches that employ semantic graphs. However before we can elaborate we must first cover the fundamental resources it is built upon. 2.1 Fundamental Resource Definitions 2.1.1 Lemma Sequences At a glance across the text of any language, we absorb meaning and new information through its lexical composition. Depending on the length of text 250 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 250–254, Atlanta, Georgia, June 14-</context>
<context position="6351" citStr="Navigli and Ponzetto (2012" startWordPosition="1040" endWordPosition="1043"> synset. Depending on the sense inventory the synset belongs to, it may contain alternative or translated lexicalisations, glosses, links to other semantic resources, among a collection of semantically defined relations to other synsets. 2.1.3 Subgraphs PD makes use of subgraphs derived from a directed graph 9 = (V, £) that can be crafted from a sense inventory, such as BabelNet, WordNet, or Wikipedia. We construct subgraphs using the BabelNet API which accesses BabelNet3 and Babel synset paths4 indexed into Apache Lucene5 to ensure speed of subgraph construction. This process is described in Navigli and Ponzetto (2012a) and demonstrated in Navigli and Ponzetto (2012b). Our formalisation of subgraphs is adapted into our own notation from the original papers of Navigli and Lapata (2007) and Navigli and Lapata (2010). We refer the reader to these listed sources if they desire an extensive explanation of our subgraph construction as we have built PD on top of the same code base therefore we do not deviate from it. For a given lemma sequence L = (`i, ..., `n) and directed graph 9 = (V, £) we construct our subgraph 9L = (VL, £L) in two steps: 1. Initialize VL := Uni=1 S(`i) and £L := 0. 2. For each node v E VL, </context>
<context position="10979" citStr="Navigli and Ponzetto, 2012" startWordPosition="1876" endWordPosition="1879">) based on φ is (ˆs1,*, ˆs2,*, ..., ˆsm,*). 2.3.3 Strategies, Parameters, &amp; Filters Wikipedia’s Did You Mean? We account for deviations and errors in spelling to ensure lemmas have the best chance of being mapped to a synset. Absent synsets in subgraph GL will naturally degrade system output. Therefore if `i 7→ ∅, we make an HTTP call to Wikipedia’s Did you mean? and parse the response for any alternative spellings. For example in the test data set6 the misspelt lemma: “feu de la rampe” is corrected to “feux de la rampe”. Custom Back-off Strategy As back-off strategies7 have proved useful in (Navigli and Ponzetto, 2012a) and (Navigli et al., 2007), we designed our own back-off strategy. In the event our system provides a null result, the Babel synset si,j ∈ S(`i) = S with the most senses associated with it will be chosen with preference to its region in BabelNet such that WIKIWN &gt;- WN &gt;- WIKI. 6Found in sentence d001.s002.t005 in the French test data set. 7In the event the WSD technique fails to provide an answer, a back-off strategy provides one for the system to output. { min v0=/=v vEP≤d(si,7) v0EP≤d(si,�) δ(v, v&apos;) 252 Input Parameters We set our sliding window length (b − a) to encompass 5 sentences at </context>
</contexts>
<marker>Navigli, Ponzetto, 2012</marker>
<rawString>Roberto Navigli and Simone Paolo Ponzetto. 2012. Multilingual WSD with Just a Few Lines of Code: the BabelNet API. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, 67–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>David Jurgens</author>
<author>Daniele Vannella</author>
</authors>
<title>SemEval-2013 Task 12: Multilingual Word Sense Disambiguation.</title>
<date>2013</date>
<booktitle>Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval 2013), in conjunction with the Second Joint Conference on Lexical and Computational Semantcis (*SEM</booktitle>
<contexts>
<context position="1204" citStr="Navigli et al., 2013" startWordPosition="172" endWordPosition="175">achieve WSD. PD’s f-measure scores for SemEval 2013 Task 12 outperform the Most Frequent Sense (MFS) baseline for two of the five languages: English, French, German, Italian, and Spanish. Despite PD remaining under-developed and under-explored, it demonstrates that it is robust, competitive, and encourages development. 1 Introduction By reading out aloud “A minute is a minute division of time” (Nelson, 1976), we can easily make the distinction between the two senses of the homograph minute. For a machine this is a complex task known as Word Sense Disambiguation (WSD). Task 12 of SemEval 2013 (Navigli et al., 2013) calls for a language-independent solution to WSD that utilises a multilingual sense inventory. Supervised approaches to WSD have dominated for some time now (M`arquez et al., 2007). Homographs such as minute are effortlessly disambiguated and more polysemous words such as bar or line can also be disambiguated with reasonable competence (Agirre and Edmonds, 2007). However our approach is purely knowledge-based and employs semantic graphs. This allows us to avoid the notorious predicament Gale et al. (1992) name the information bottleneck, in which supervised approaches fail to be portable acro</context>
</contexts>
<marker>Navigli, Jurgens, Vannella, 2013</marker>
<rawString>Roberto Navigli, David Jurgens, and Daniele Vannella. 2013. SemEval-2013 Task 12: Multilingual Word Sense Disambiguation. Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval 2013), in conjunction with the Second Joint Conference on Lexical and Computational Semantcis (*SEM 2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frederic Nelson</author>
</authors>
<date>1976</date>
<journal>Homographs American Speech,</journal>
<volume>51</volume>
<issue>3</issue>
<contexts>
<context position="994" citStr="Nelson, 1976" startWordPosition="136" endWordPosition="137">ord Sense Disambiguation (WSD). PD exploits the frequency and diverse use of word senses in semantic subgraphs derived from larger sense inventories such as BabelNet, Wikipedia, and WordNet in order to achieve WSD. PD’s f-measure scores for SemEval 2013 Task 12 outperform the Most Frequent Sense (MFS) baseline for two of the five languages: English, French, German, Italian, and Spanish. Despite PD remaining under-developed and under-explored, it demonstrates that it is robust, competitive, and encourages development. 1 Introduction By reading out aloud “A minute is a minute division of time” (Nelson, 1976), we can easily make the distinction between the two senses of the homograph minute. For a machine this is a complex task known as Word Sense Disambiguation (WSD). Task 12 of SemEval 2013 (Navigli et al., 2013) calls for a language-independent solution to WSD that utilises a multilingual sense inventory. Supervised approaches to WSD have dominated for some time now (M`arquez et al., 2007). Homographs such as minute are effortlessly disambiguated and more polysemous words such as bar or line can also be disambiguated with reasonable competence (Agirre and Edmonds, 2007). However our approach is</context>
</contexts>
<marker>Nelson, 1976</marker>
<rawString>Frederic Nelson. 1976. Homographs American Speech, 51(3):296–297.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ravi Sinha</author>
<author>Rada Mihalcea</author>
</authors>
<title>Unsupervised Graph-based Word Sense Disambiguation Using Measures of Word Semantic Similarity.</title>
<date>2007</date>
<booktitle>Proceedings of IEEE International Conference on Semantic Computing.</booktitle>
<contexts>
<context position="2480" citStr="Sinha and Mihalcea (2007)" startWordPosition="362" endWordPosition="365">ed corpora do not exist. Conversely, knowledge-based approaches for WSD are usually applicable to all words in unrestricted text (Mihalcea, 2007). It is this innate scalability that motivates us to pursue knowledge-based approaches. Regardless of whether sense inventories can maintain knowledge-richness as they grow, their continued refinement by contributors is directly beneficial. Knowledge-based approaches that employ semantic graphs increasingly rival leading supervised approaches to WSD. They can beat a Random or LESK (Lesk, 1986) baseline (see Mihalcea (2005), Navigli and Lapata (2007), Sinha and Mihalcea (2007), Navigli and Lapata (2010)) and can compete with or even beat the Most Frequent Sense (MFS) baseline in certain contexts which is by no means an easy task (see Navigli et al. (2007), Eneko Agirre and Aitor Soroa (2009), Navigli and Ponzetto (2012a)). 2 Methodology PD is a framework for knowledge-based WSD approaches that employ semantic graphs. However before we can elaborate we must first cover the fundamental resources it is built upon. 2.1 Fundamental Resource Definitions 2.1.1 Lemma Sequences At a glance across the text of any language, we absorb meaning and new information through its le</context>
</contexts>
<marker>Sinha, Mihalcea, 2007</marker>
<rawString>Ravi Sinha and Rada Mihalcea. 2007. Unsupervised Graph-based Word Sense Disambiguation Using Measures of Word Semantic Similarity. Proceedings of IEEE International Conference on Semantic Computing.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>