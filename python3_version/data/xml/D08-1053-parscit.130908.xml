<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9879415">
Improved Sentence Alignment on Parallel Web Pages Using a
Stochastic Tree Alignment Model
</title>
<author confidence="0.995991">
Lei Shi
</author>
<affiliation confidence="0.992324">
Microsoft Research Asia
</affiliation>
<address confidence="0.9935965">
5F Sigma Center, 49 Zhichun Road, Beijing
100190, P. R. China
</address>
<email confidence="0.996315">
leishi@microsoft.com
</email>
<author confidence="0.964567">
Ming Zhou
</author>
<affiliation confidence="0.970997">
Microsoft Research Asia
</affiliation>
<address confidence="0.9929925">
5F Sigma Center, 49 Zhichun Road, Beijing
100190, P. R. China
</address>
<email confidence="0.998778">
mingzhou@microsoft.com
</email>
<sectionHeader confidence="0.989544" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999985523809524">
Parallel web pages are important source
of training data for statistical machine
translation. In this paper, we present a
new approach to sentence alignment on
parallel web pages. Parallel web pages
tend to have parallel structures,and the
structural correspondence can be indica-
tive information for identifying parallel
sentences. In our approach, the web page
is represented as a tree, and a stochastic
tree alignment model is used to exploit
the structural correspondence for sentence
alignment. Experiments show that this
method significantly enhances alignment
accuracy and robustness for parallel web
pages which are much more diverse and
noisy than standard parallel corpora such
as â€œHansardâ€. With improved sentence
alignment performance, web mining sys-
tems are able to acquire parallel sentences
of higher quality from the web.
</bodyText>
<sectionHeader confidence="0.996385" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.985630041666667">
Sentence-aligned parallel bilingual corpora have
been essential resources for statistical machine
translation (Brown et al. 1993), and many other
multi-lingual natural language processing applica-
tions. The task of aligning parallel sentences has
received considerable attention since the renais-
sance of data driven machine translation in late
1980s.
During the past decades, a number of methods
have been proposed to address the sentence align-
ment problem. Although excellent performance
was reported on clean corpora, they are less robust
with presence of noise. A recent study by (Singh
and Husain 2005) completed a systematic evalua-
tion on different sentence aligners under various
conditions. Their experiments showed that the per-
formance of sentence aligners are sensitive to
properties of the text, such as format complexity
(presence of elements other than text), structural
distance (a scale from literal to free translation),
the amount of noise (text deletions or preprocess-
ing errors) and typological distance between lan-
guages. Their performance varies on different type
of texts and they all demonstrate marked perfor-
mance degradation over noisy data. The results
suggest that there is currently no universal solution
to sentence alignment under all conditions, and
different methods should be applied to different
types of texts.
In this paper, we specifically address sentence
alignment on parallel web pages. It has come to
attention with the increasing trend of acquiring
large-scale parallel data from the web. Currently,
large-scale parallel data are not readily available
for most language pairs and domains. But due to a
sharply increasing number of bilingual web sites,
web mining shows great promise as a solution to
this knowledge bottleneck problem. Many systems
(Ma 1999; Chen 2000; Yang 2002; Resnik 2003;
Chen 2004) have been developed to discover paral-
lel web pages, and sentence aligners are used to
extract parallel sentences from the mined web cor-
pora. Sentence alignment performance on parallel
web pages, therefore, becomes an increasingly im-
portant issue for large-scale high-quality parallel
data acquisition.
Compared with clean parallel corpora such as
&amp;quot;Hansard&amp;quot; (Brown et al. 1993), which consists of
</bodyText>
<page confidence="0.954928">
505
</page>
<note confidence="0.9627785">
Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 505â€“513,
Honolulu, October 2008.cï¿½2008 Association for Computational Linguistics
</note>
<bodyText confidence="0.998769047619048">
French-English translations of political debates in
the Canadian parliament, texts from the web are far
more diverse and noisy. They are from many dif-
ferent domains and of various genres. Their trans-
lation may be non-literal or written in disparate
language pairs. Noise is abundant with frequent
insertions, deletions or non-translations. And there
are many very short sentences of 1-3 words. Due
to the characteristics of web corpora, direct appli-
cation of conventional alignment methods without
exploiting additional web document information
acts as useful information to constrain the scope of
search for parallel sentences.
The paper is organized as follows: In section 2,
we briefly survey previous approaches to sentence
alignment. In section 3, we present the stochastic
tree alignment model, including parameter estima-
tion and decoding. Then in section 4, we describe
how to use the tree alignment model in sentence
alignment. Benchmarks are shown in section 5,
and the paper is concluded in section 6.
</bodyText>
<figureCaption confidence="0.99893">
Figure 1. Example of parallel web pages
</figureCaption>
<bodyText confidence="0.9969845625">
yields unsatisfactory alignment results.
Our approach to this problem is to make use of
the structural parallelism between parallel web
pages. Structural parallelism is the phenomenon,
that when representing the same content in two
different languages, authors have a very strong
tendency to use the same document structure. As is
shown in Figure 1, sentences located in similar
position on both pages are more likely to be trans-
lations. Hence, correspondence in the web page
structure is an informative indication of parallel
sentences. In our approach, the web page is
represented as a tree, and a stochastic tree align-
ment model is used to find the most probable
alignment of the tree pair based on their structure
and the texts in tree nodes. The tree alignment then
</bodyText>
<sectionHeader confidence="0.950846" genericHeader="method">
2 Sentence Alignment Models
</sectionHeader>
<bodyText confidence="0.999795571428572">
Sentence alignment methods can be categorized
into three major categories: the length-based, lex-
icon-based and hybrid method which combines the
length-based model and lexicon-based model as
complement to each other.
The length model was based on the intuition that
the length of a translated sentence is likely to be
similar to that of the source sentence. (Brown et. at.
1991) used word count as the sentence length,
whereas (Gale and Church 1993) used character
count. Dynamic programming is used to search the
optimal sentence alignment. Both algorithms have
achieved remarkably good results for language
pairs like English-French and English-German
</bodyText>
<page confidence="0.99678">
506
</page>
<bodyText confidence="0.999746074074074">
with an error rate of 4% on average. But they are
not robust with respect to non-literal translations,
deletions and disparate language pairs.
Unlike the length-based model, which totally
ignores word identity, lexicon-based methods use
lexical information to align parallel sentences.
Kayâ€™s (Kay and Roscheisen 1993) approach is
based on the idea that words that are translations of
each other will have similar distribution in source
and target texts. By adopting the IBM model 1,
(Chen 1993) used word translation probabilities,
which he showed gives better accuracy than the
sentence length based method. Melamed (Me-
lamed 1996) rather used word correspondence
from a different perspective as geometric corres-
pondence for sentence alignment.
The hybrid method combines the length model
with the lexical method. (Simard and Plamondon
1996) used a two-pass approach, where the first
pass performs length-based alignment at the cha-
racter level as in (Gale and Church 1993) and the
second pass uses IBM Model 1, following (Chen
1993). Mooreâ€™s (Moore 2002) approach is similar
to Simardâ€™s. The difference is that Moore used the
data obtained in the first pass to train the IBM
model in the second pass, so that his approach does
not require a priori knowledge about the language
pair. Instead of using a two-pass approach, (Zhao
and Vogel 2002) combines the length model and
the IBM model 1 in a unified framework under a
maximum likelihood criterion. To make it more
robust on noisy text, they developed a background
model to handle text deletions.
To further improve sentence alignment accuracy
and robustness, methods that make use of addi-
tional language or corpus specific information
were developed. In Brown and Churchâ€™s length-
based aligner, they assume prior alignment on
some corpus specific anchor points to constrain
and keep the Viterbi search on track. (Wu 1994)
implemented a length-based model for Chinese-
English with language specific lexical clues to im-
prove accuracy. (Simard et al. 1992) used cognates,
which only exists in closely related language pairs.
(Chuang and Yeh 2005) exploited the statistically
ordered matching of punctuation marks in two lan-
guages to achieve high accuracy sentence align-
ment. In their web parallel data mining system,
(Chen and Nie 2000) used HTML tags in the same
way as cognates in (Simard et al. 1992) for align-
ing Chinese-English parallel sentences. Tree based
alignment models have been successfully applied
in machine translation (Wu 1997, Yamada &amp;
Knight 2001, Gildea 2003).
</bodyText>
<sectionHeader confidence="0.895777" genericHeader="method">
3 The Stochastic Tree Alignment Model
</sectionHeader>
<bodyText confidence="0.9999818125">
The structure of the HTML document is recursive,
with HTML markup tags embedded within other
markup tags. While converting an HTML docu-
ment into the tree representation, such hierarchical
order is maintained. Each node of the tree is la-
beled with their corresponding HTML tag (e.g.
body, title, img etc.) and in labeling tree nodes,
only markup tags are used and attribute value pairs
are dropped. Among all markup tags in the HTML
file, those of our most interest are tags containing
content text, which is what we want to align. These
tags are those surrounding a text chunk or have the
attribute of â€œALTâ€. Comments, scripts and style
specifications are not regarded as content text and
hence are eliminated. Figure 2 illustrates the tree
representation of an example HTML document.
</bodyText>
<figure confidence="0.997425333333333">
&lt;html&gt;
&lt;head&gt;&lt;title&gt;text1&lt;/title&gt;&lt;/head&gt;
&lt;body&gt;
&lt;a href=â€.htmlâ€&gt;text2&lt;/a&gt;
&lt;div&gt; ... &lt;/div&gt;
&lt;img src=â€.jpgâ€,alt=text3&gt;
&lt;/body&gt;
&lt;/html&gt;
html
</figure>
<figureCaption confidence="0.893973">
Figure. 2 An example HTML document and its
tree representation
</figureCaption>
<subsectionHeader confidence="0.997579">
3.1 Tree Alignment Model
</subsectionHeader>
<bodyText confidence="0.999938916666667">
Given two trees, the tree alignment is the non-
directional alignments of their nodes. A node in
one tree can be aligned with at most one node in
the other tree. It is valid for a node to be aligned
with nothing (NULL) and such case is regarded as
node deletion in tree alignment. To comply with
the tree hierarchical structure, we constrain that the
alignments keep the tree hierarchy invariant i.e. if
node A is aligned with node B, then the children of
A are either deleted or aligned with the children of
B. Besides, to simplify the model training and de-
coding, the tree alignment model also keeps the
</bodyText>
<figure confidence="0.992958555555556">
head body
title
#text1
a
#text2
div
Img
#text3
. . .
</figure>
<page confidence="0.977667">
507
</page>
<bodyText confidence="0.953845714285714">
sequential order invariant, i.e. if node A is aligned
with node B, then the left sibling nodes of A cannot
be aligned with the right sibling nodes of B.
The stochastic tree alignment model assigns
probabilities to tree alignments, based on the par-
ticular configuration of the alignment and model
parameters. Then, the decoder is able to find the
most probable (optimal) alignment of two trees. To
facilitate the presentation of the tree alignment
model, the following symbols are introduced: giv-
en a HTML document D, ğ‘‡ğ· denotes the corres-
ponding tree; ğ‘ğ‘–ğ· denotes the ith node of ğ‘‡ğ· ,
ğ·
and ğ‘‡ğ‘– denotes the sub-tree rooted at ğ‘ğ‘–ğ· . Espe-
</bodyText>
<equation confidence="0.687274">
cially, ğ‘‡ 1ğ· ğ·
</equation>
<bodyText confidence="0.997083096774194">
is the root of the tree ğ‘‡ğ·. ğ‘‡[ğ‘–,ğ‘—] denotes
the forest consisting of the sub-trees rooted at sibl-
ing nodes from ğ‘‡ğ‘–ğ· to ğ‘‡ğ‘—ğ·. ğ‘ğ‘–ğ·. ğ‘¡ denotes the text in
the node ğ‘ğ‘–ğ· , and ğ‘ğ‘–ğ·. ğ‘¡ denotes the label (i.e.
HTML tag) of the node ğ‘ğ‘–ğ·; ğ‘ğ‘–ğ·. ğ¶ğ‘– denotes the jth
child of the node ğ‘ğ‘–ğ·; ğ‘ğ‘–ğ·. ğ¶[ğ‘š,ğ‘›] denotes the con-
secutive sequence of ğ‘ğ‘–ğ· â€™s children nodes from
ğ‘ğ‘–ğ·. ğ¶ğ‘š to ğ‘ğ‘–ğ·. ğ¶ğ‘›; the sub-tree rooted at ğ‘ğ‘–ğ·. ğ¶ğ‘– is
represented as ğ‘ğ‘–ğ·. ğ¶ğ‘‡ğ‘– and the forest of the sub-
trees rooted at ğ‘ğ‘–ğ· â€™s children is represented as
ğ‘ğ‘–ğ·. ğ¶ğ¹. To accommodate node deletion, NULL is
introduced to denote the empty node. Finally, the
tree alignment is referred as A.
Given two HTML documents F (in French) and
E (in English) represented as trees ğ‘‡ğ¹ and ğ‘‡ğ¸, the
tree alignment task is defined as finding the align-
ment A that maximizes the conditional
probability Pr(ğ´|ğ‘‡ğ¹,ğ‘‡ğ¸) . Based on the Bayesâ€™
Rule, Pr(ğ´|ğ‘‡ğ¹,ğ‘‡ğ¸) âˆ Pr(ğ‘‡ğ¹,ğ‘‡ğ¸|ğ´)Pr(ğ´) , where
Pr(ğ‘‡ ğ¹,ğ‘‡ğ¸|ğ´) is the probability of synchronously
generating ğ‘‡ ğ¹ and ğ‘‡ ğ¸ given the alignment A, and
Pr(ğ´) is the prior knowledge of the tree alignment.
To simplify computation, we assume a uniform
prior probability Pr(ğ´). Hence, the tree alignment
task is to find the A that maximizes the synchron-
ous probability Pr(ğ‘‡ ğ¹, ğ‘‡ ğ¸ |ğ´).
Based on the hierarchical structure of the tree, in
order to facilitate the presentation and computation
of the tree alignment probabilistic model, the fol-
lowing alignment probabilities are defined in a hie-
rarchically recursive manner:
</bodyText>
<listItem confidence="0.9240982">
Pr(ğ‘‡ğ‘šğ¹, ğ‘‡ğ‘–ğ¸ |ğ´): The probability of synchronously
generating sub-tree pair {ğ‘‡ğ‘šğ¹,ğ‘‡ğ‘–ğ¸} given the align-
ment A;
Pr(ğ‘ğ‘šğ¹, ğ‘ğ‘–ğ¸ |ğ´): The probability of synchronously
generating node pair {ğ‘ğ‘šğ¹, ğ‘ğ‘–ğ¸};
</listItem>
<equation confidence="0.952328666666667">
Pr(ğ‘‡[ğ‘š,ğ‘›]
ğ¹, ğ‘‡[ğ‘–,ğ‘—]
ğ¸ |ğ´): The probability of synchron-
ously generating forest pairs {ğ‘‡[ğ‘š,ğ‘›]
ğ¹ , ğ‘‡[ğ‘–,ğ‘—]
ğ¸ } given
</equation>
<bodyText confidence="0.922415555555556">
the alignment A.
From the definition, the tree pair generative
probability Pr(ğ‘‡ ğ¹, ğ‘‡ ğ¸ |ğ´) equals to the root sub-
tree pair generative probability Pr(ğ‘‡1ğ¹ , ğ‘‡1ğ¸ |ğ´). The
alignment of the sub-tree pair ğ‘‡ğ‘— ğ¹ and ğ‘‡ ğ‘–ğ¸ may have
the following configurations, based on which the
tree pair generative probability Pr(ğ‘‡ğ‘—ğ¹,ğ‘‡ğ‘–ğ¸|ğ´) can
be calculated:
ğ¹
</bodyText>
<listItem confidence="0.958817333333333">
(1) If ğ‘ğ‘š is aligned with ğ‘ğ‘–ğ¸, and the children of
ğ‘ğ‘šğ¹ are aligned with children of ğ‘ğ‘–ğ¸ (as is
shown in Fig. 3a), then we have
</listItem>
<equation confidence="0.823257">
Pr.ğ‘‡ğ‘šğ¹,ğ‘‡ğ‘–ğ¸/ğ´0 = Pr(ğ‘ğ‘šğ¹,ğ‘ğ‘–ğ¸)Pr(ğ‘ğ‘šğ¹.ğ¶ğ¹,ğ‘ğ‘–ğ¸.ğ¶ğ¹|ğ´)
</equation>
<listItem confidence="0.940276666666667">
(2) If ğ‘ğ‘šğ¹ is deleted, and the children of ğ‘ğ‘šğ¹ is
aligned with ğ‘ğ‘–ğ¸ (as shown in Fig. 3b), then we
have
</listItem>
<equation confidence="0.787323">
Pr.ğ‘‡ğ‘šğ¹,ğ‘‡ğ‘–ğ¸/ğ´0 = Pr(ğ‘ğ‘šğ¹|ğ‘ğ‘ˆğ¿ğ¿)Pr(ğ‘ğ‘šğ¹.ğ¶ğ¹,ğ‘‡ğ‘–ğ¸|ğ´)
</equation>
<listItem confidence="0.997515">
(3) If ğ‘ğ‘–ğ¸is deleted, and ğ‘ğ‘šğ¹ is aligned with child-
ren of ğ‘ğ‘–ğ¸ (as shown in Fig. 3c), then we have
</listItem>
<equation confidence="0.661187">
Pr(ğ‘‡ğ‘šğ¹,ğ‘‡ğ‘–ğ¸|ğ´) = Pr(ğ‘‡ğ‘šğ¹,ğ‘ğ‘–ğ¸.ğ¶ğ¹|ğ´)Pr(ğ‘ğ‘–ğ¸ |ğ‘ğ‘ˆğ¿ğ¿)
Figure. 3
</equation>
<bodyText confidence="0.9172926">
The above equations involve forest pair generative
probabilities. The alignment of the forest
ğ‘‡[ğ‘š,ğ‘›] ğ¹and ğ‘‡[ğ‘– ,ğ‘— ] ğ¸ may have the following configura-
tions, based on which their forest pair generative
probability Pr(ğ‘‡[ğ‘š,ğ‘›]
</bodyText>
<figure confidence="0.978028">
ğ¹,ğ‘‡[ğ‘–,ğ‘—] ğ¸|ğ´) can be calculated:
(a)
NULL
TF
m
TF
m
TF
m
NULL
TE
TE
i
TiE
i
</figure>
<page confidence="0.389585">
508
</page>
<equation confidence="0.82617535483871">
ğ¹
(4) If ğ‘‡ğ‘š ğ¹ is aligned with ğ‘‡ğ‘– ğ¸ , and ğ‘‡[ğ‘š+1,ğ‘›] is
aligned with ğ‘‡[ğ‘–+1,ğ‘—]
ğ¸ (as is shown in Fig. 4a),
then
Pr.ğ‘‡[ğ‘š,ğ‘›]
ğ¹, ğ‘‡[ğ‘–,ğ‘—] ğ¸/ğ´0
ğ¹
= Pr(ğ‘‡ğ‘š ğ¹, ğ‘‡ğ‘– ğ¸|ğ´)Pr(ğ‘‡[ğ‘š+1,ğ‘›], ğ‘‡[ğ‘–+1,ğ‘—]
ğ¸ |ğ´)
(5) If ğ‘ğ‘šğ¹ is deleted, and the forest rooted at ğ‘ğ‘šğ¹â€™s
children ğ‘ğ‘šğ¹. ğ¶ğ¹ is combined with ğ‘‡[ğ‘š+1,ğ‘›]
ğ¹ for
alignment with ğ‘‡[ğ‘–,ğ‘—]
ğ¸ , then
Pr.ğ‘‡[ğ‘š,ğ‘›]
ğ¹, ğ‘‡[ğ‘–,ğ‘—] ğ¸/ğ´0
ğ¹
= Pr(ğ‘ğ‘š ğ¹ |ğ‘ğ‘ˆğ¿ğ¿)Pr(ğ‘ğ‘š ğ¹ . ğ¶ğ¹ ğ‘‡[ğ‘š+1,ğ‘›] , ğ‘‡[ğ‘–,ğ‘—]
ğ¸ |ğ´)
(6) If ğ‘ğ‘–ğ¸ is deleted, and the forest rooted at ğ‘ğ‘–ğ¸â€™s
children ğ‘ğ‘–ğ¸. ğ¶ğ¹ is combined with ğ‘‡[ğ‘–,ğ‘—]
ğ¸ for
alignment with ğ‘‡[ğ‘š,ğ‘›]
ğ¹ , then
Pr.ğ‘‡[ğ‘š,ğ‘›]
ğ¹,ğ‘‡[ğ‘–,ğ‘—] ğ¸/ğ´0
= Pr(ğ‘ğ‘–ğ¸ |ğ‘ğ‘ˆğ¿ğ¿)Pr(ğ‘‡[ğ‘š,ğ‘›]
ğ¹, ğ‘ğ‘šğ¹. ğ¶ğ¹ ğ‘‡[ğ‘–+1,ğ‘—]
ğ¸ |ğ´)
Figure. 4
</equation>
<bodyText confidence="0.977949">
Finally, the node pair probability is modeled
as Pr(ğ‘ğ‘šğ¹, ğ‘ğ‘–ğ¸) = Pr(ğ‘ğ‘šğ¹. ğ‘¡, ğ‘ğ‘–ğ¸. ğ‘¡)Pr(ğ‘ğ‘šğ¹.ğ‘™, ğ‘ğ‘–ğ¸. ğ‘™) ,
where Pr(ğ‘ğ‘šğ¹. ğ‘¡, ğ‘ğ‘–ğ¸. ğ‘¡) is the generative probability
of the translationally equivalent text chunks
ğ¹
in ğ‘ğ‘š and ğ‘ğ‘–ğ¸, and Pr(ğ‘ğ‘šğ¹.ğ‘™, ğ‘ğ‘–ğ¸. ğ‘™) is their HTML
tag pair probability. The text chunk generative
probability Pr(ğ‘ğ‘šğ¹. ğ‘¡, ğ‘ğ‘–ğ¸. ğ‘¡) can be modeled in a
variety of ways. The conventional length-based,
lexicon-based or hybrid methods used for sentence
alignment can be applied here. In the next sub-
section, we focus on how to estimate the tag pair
probability Pr(ğ‘ğ‘šğ¹.ğ‘™, ğ‘ğ‘–ğ¸. ğ‘™) from a set of parallel
web pages. We expect pairs of the same or similar
HTML tags to have high probabilities and the
probabilities for pairs of disparate tags to be low.
</bodyText>
<subsectionHeader confidence="0.913337">
3.2 Parameter Estimation Using Expectation-
</subsectionHeader>
<bodyText confidence="0.954550153846154">
Maximization
One way to estimate the tag pair generative proba-
bility Pr(ğ‘™,ğ‘™â€²) is to manually align nodes between
parallel trees, and use the manually aligned trees as
the training data for maximum likelihood estima-
tion. However, this is a time-consuming and error-
prone procedure. Instead, the Expectation Maximi-
zation (EM) (Dempster, Laird and Rubin 1977)
algorithm is used to estimate the
parameters Pr(ğ‘™,ğ‘™â€²) on 5615 manually verified
parallel web page pairs from 45 different bilingual
web sites. The parameter estimation proceeds as
follows:
</bodyText>
<listItem confidence="0.9988582">
1. Start with initial parameter values.
2. Expectation: estimate count ::::::: (ğ‘™,ğ‘™â€²) which is
the expectation of aligning tag l with l&apos;.
3. Maximization: update the parameters based
to maximum likelihood estimation
</listItem>
<equation confidence="0.985614428571428">
P4l, l&apos; ï€©ï€½ countl, l&apos;ï€© and
ïƒ¥ countl, l&apos;ï€©
l &apos;
Pr(l NULL)
ï€½ ïƒ¥ [ counKNULL, /ï€©ï€« countï€¨/, NUL Lï€©]
countï€¨ NUL L, lï€©ï€« countï€¨ l, NUL Lï€©
l &apos;
</equation>
<listItem confidence="0.510956">
4. Repeat step 2 and 3 until the parameters
stabilize
</listItem>
<bodyText confidence="0.857922666666667">
In step 2, count:::::::(ğ‘™,ğ‘™â€²) is the expected count of l
being aligned with l&apos; in the training corpus. By
definition, count:::::::(ğ‘™,ğ‘™â€²) is calculated as
</bodyText>
<equation confidence="0.996322">
count:::::::(ğ‘™,ğ‘™â€²) = ; Pr(ğ´|ğ‘‡ğ¹ , ğ‘‡ğ¸)count(ğ‘™,ğ‘™â€²)
ğ´
</equation>
<bodyText confidence="0.999902285714286">
where count(ğ‘™,ğ‘™â€²) is the number of occurrence of l
being aligned with lâ€™ in the tree alignment A.
To efficiently compute count:::::::(ğ‘™,ğ‘™â€²) without
enumerating the exponential number of Aâ€™s in the
above equation, we extended the inside-outside
algorithm presented in (Lari and Young, 1990).
The inside probability ğ›¼(ğ‘ğ‘—ğ¹, ğ‘ğ‘–ğ¸) is defined as the
</bodyText>
<figure confidence="0.93003552">
(a)
TF
m
TF T[Fmï€«1 ,n]
m
T[F
m, n]
NULL
TmF.CF
TF
[mï€«1 ,n]
NULL
TiE
E
Ti 1 ,j ]
TE
i
.CF
T[E
iï€«1 ,
E
T[i,j ]
T[E
iï€«
j ]
</figure>
<page confidence="0.990373">
509
</page>
<bodyText confidence="0.9582805">
probability of generating sub-tree pair {ğ‘‡ğ‘— ğ¹, ğ‘‡ğ‘–ğ¸}
when ğ‘ğ‘–ğ¸ is aligned with ğ‘ğ‘—ğ¹. It is estimated as:
</bodyText>
<equation confidence="0.96676325">
ï¡ , ï€½ Pr , ï¡ . , .
ï€¨N N ï€© ï€¨ N N ï€© ï€¨N CF N CFï€©
F E F E F E
m i m i m i
</equation>
<bodyText confidence="0.996546">
where ğ›¼(ğ‘ğ‘šğ¹. ğ¶ğ¹, ğ‘ğ‘–ğ¸. ğ¶ğ¹) is the inside probability
for the forest pair (ğ‘ğ‘šğ¹. ğ¶ğ¹, ğ‘ğ‘–ğ¸. ğ¶ğ¹)
</bodyText>
<equation confidence="0.988981">
F
ï€¨ ï€© ï€½ ïƒ¥ ï€¨ N CF N CF A
E
ï¡ . , .
N CF N CF
F E Pr . , . ï€© .
m i m i
A
</equation>
<bodyText confidence="0.999870285714286">
The inside probability can be estimated recursively
according to the various alignment configurations
presented in Figure 3 and Figure 4. The outside
probability ğ›½ (ğ‘ğ‘—ğ¹, ğ‘ğ‘–ğ¸) is defined as the probability
of generating the part of ğ‘‡ ğ¸ and ğ‘‡ ğ¹ excluding the
sub-trees ğ‘‡ğ‘—ğ¹and ğ‘‡ğ‘– ğ¸, when ğ‘ğ‘–ğ¸ is aligned with ğ‘ğ‘— ğ¹.
It is estimated as:
</bodyText>
<equation confidence="0.9969085">
ï¢ï€¨Nm,N [,8ï€¨amq,a vï€©
p q
,
ï€¨ ï€¨ ï€© ï€¨ ï€©
a LCF N a LCF N
F F E E
ï‚´ï¡ . , . ï€©
m q
, m i p
, i
ï€¨ ï€¨ ï€© ï€¨ ï€©
a RCF N a RCF N
F F E E
ï‚´ ï¡ . , . ï€©
m q
, m i p
, i
ï‚´ ïƒ• Pr(amF k  |NUL L)ïƒ•
,
k q
ï€¼ k p
ï€¼
</equation>
<bodyText confidence="0.941952833333333">
where ğ‘ğ‘š,ğ‘
ğ¹ is the qth ancestor of ğ‘ğ‘šğ¹, and ğ‘ğ‘–,ğ‘ğ¸ is
the pth ancestor of ğ‘ğ‘–ğ¸. ğ‘ğ‘š,ğ‘˜
ğ¹ (ğ‘˜ &lt; ğ‘) is an ancestor
of ğ‘ğ‘šğ¹ and a decedent of ğ‘ğ‘š,ğ‘
ğ¹ . Similarly ğ‘ğ‘–,ğ‘˜ğ¸ (ğ‘˜ &lt;
ğ‘ is an ancestor of ğ‘ğ‘–ğ¸, and a decedent of ğ‘ğ‘–,ğ‘ğ¸.
a.LCF(N) is the forest rooted at a and to the left of
N, and a.RCF(N). a.RCF(N) is the forest rooted as
a and to the right of N. Once inside and outside
probabilities are computed, the expected counts
can be calculated as
</bodyText>
<equation confidence="0.998418666666667">
countï€¨l,!ï€©ï€½ïƒ¥ ïƒ¥ï¡ï€¨NM, NE ï€¨Nm, NEï€©
Pr(T, T)
F E
</equation>
<bodyText confidence="0.9999215">
where Pr(ğ‘‡ğ¹,ğ‘‡ğ¸) is the generative probability of
the tree pair {ğ‘‡ ğ¹, ğ‘‡ğ¸} over all possible alignment
configurations. Pr(ğ‘‡ğ¹,ğ‘‡ğ¸) can be estimated using
dynamic programming techniques that will be pre-
sented in the next sub-section. Furthermore, the
expected count of tag deletion is estimated as:
</bodyText>
<equation confidence="0.9104805">
count:::::::(ğ‘™, ğ‘ğ‘ˆğ¿ğ¿) = ; count(ğ‘™, ğ‘™â€²) âˆ’ ;count:::::::(ğ‘™, ğ‘™â€²)
ğ‘– ğ‘–â‰ ğ‘ğ‘ˆğ¿ğ¿
count:::::::(ğ‘ğ‘ˆğ¿ğ¿, ğ‘™) = ; count(ğ‘™â€², ğ‘™) âˆ’ ;count:::::::(ğ‘™â€², ğ‘™)
ğ‘– ğ‘–â‰ ğ‘ğ‘ˆğ¿ğ¿
</equation>
<subsectionHeader confidence="0.978402">
3.3 Dynamic Programming for Decoding
</subsectionHeader>
<bodyText confidence="0.998063619047619">
An intuitive way to find the optimal tree alignment
is to enumerate all alignments and pick the one
with the highest probability. But it is intractable
since the total number of alignments is exponential.
Based on the observation that if two trees are op-
timally aligned, the alignment of their sub-trees
must also be optimal, dynamic programming can
be applied to find the optimal tree alignment using
that of the sub-trees in a bottom-up manner. That is
we first compute the optimal alignment probabili-
ties of small trees and use them to compute that of
the bigger tree by trying different alignment confi-
gurations. This procedure is recursive until the op-
timal alignment probability of the whole tree is
obtained. The following is the pseudo-code of the
bottom-up decoding algorithm:
for i=|ğ‘‡ğ¸ |to 1 (bottom-up) {
for j=|ğ‘‡ğ¹  |to 1 (bottom-up) {
Select and store optimal alignments of their children fo-
rests ğ‘‡ğ‘šğ¹. CF and ğ‘‡ğ‘–ğ¸. CF by testing configurations 4-6;
Select and store the optimal alignment of the sub-tree
</bodyText>
<equation confidence="0.438662">
ğ¸
</equation>
<bodyText confidence="0.9414105">
pair ğ‘‡ğ‘š ğ¹ and ğ‘‡ğ‘– by testing configurations 1-3;
Store the optimal configuration}}
where |ğ‘‡ğ¹ |and |ğ‘‡ğ¸ |are the number of nodes in
ğ‘‡ğ¹ and ğ‘‡ğ¸. The decoding algorithm finds the op-
timal alignment and its probability for every sub-
trees and forests. By replacing the selection opera-
tion with summing probabilities of all configura-
tions, the sub-tree pair generative probability
Pr(ğ‘‡ğ¹,ğ‘‡ğ¸) can be calculated along the way. The
worst-case time complexity of the algorithm
</bodyText>
<listItem confidence="0.4953602">
is ğ‘‚(|ğ‘‡ğ¹||ğ‘‡ğ¸|.ğ‘‘ğ‘’ğ‘”ğ‘Ÿ(ğ‘‡ğ¹) + ğ‘‘ğ‘’ğ‘”ğ‘Ÿ(ğ‘‡ğ¸)02) , where
the degree of a tree is defined as the largest degree
of its nodes.
4 Sentence Alignment with Tree Align-
ment Model
</listItem>
<bodyText confidence="0.999867181818182">
Since the tree alignment model aligns parallel web
pages at the tree node level instead of the sentence
level, we integrate the tree alignment model with
the sentence alignment model in a cascaded mode,
in which the whole sentence alignment process is
divided into two steps. In the first step, the tree
alignment decoder finds the optimal alignment of
the two trees. Nodes having texts should be aligned
with nodes containing their translations. Then in
the second step, the conventional sentence aligner
is used to align sentences within text chunks in the
</bodyText>
<equation confidence="0.954938">
Pr( |
a NULL
E )]
i k
,
ï» ï½
T T i
F E E
, N l
. ï€½
N l l
F ï€½
m .
l &apos;
</equation>
<page confidence="0.960587">
510
</page>
<bodyText confidence="0.999804375">
aligned nodes. In this step, various sentence align-
ment models can be applied, including the length-
based model, the lexicon-based model and the hy-
brid model. Language or corpus specific informa-
tion may also be used to further improve sentence
alignment accuracy. The tree alignment acts as
constraints that confine the scope of the search of
sentence aligners.
</bodyText>
<sectionHeader confidence="0.996221" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.998228961538461">
To evaluate the effectiveness of exploiting web
page document structure with the tree alignment
model for improving sentence alignment accuracy,
we compared the performance of three types of
sentence alignment methods on parallel web pages.
The first type is to simply discard web page
layout information. Web pages are converted to
plain texts, and HTML tags are removed prior to
performing sentence alignment. The second type is
the baseline method of using web page document
information. Instead of exploiting full HTML doc-
ument structure, it follows Chenâ€™s approach (Chen
and Nie 2000) which uses HTML tags in the same
way as cognates used in (Simard et al. 1992). The
third type is the combination of tree alignment
model and conventional sentence models.
computer and literature. By manual annotation,
9,824 parallel sentence pairs are found. All sen-
tence aligners run through the test parallel web
pages, and each extracts a set of sentence pairs that
it regards as parallel. The output pairs are matched
with the annotated parallel sentences from the test
corpus. Only exact matches of the sentence pairs
are counted as correct.
Our evaluation metrics are precision (P), recall
(R) and F-measure (F) defined as:
</bodyText>
<table confidence="0.525164428571429">
# of correctly aligned sentence pairs
# of total output pairs
# of correctly aligned sentence pairs
# of true parallel pairs
R
P R
ï¿½
</table>
<bodyText confidence="0.999220166666667">
Based on the results in table 1, we can see that
both Type 2 and Type 3 aligners outperform con-
ventional sentence alignment models. Leveraging
HTML document information can enhance sen-
tence alignment quality. Especially, by using the
tree alignment model, Type 3 aligners achieve a
</bodyText>
<table confidence="0.760262666666667">
P=
R=
F
*
*
2
P
Length Lexicon Hybrid
P R F P R F P R F
Type I 85.6% 72.8% 78.7% 83.1% 75.2% 78.9% 87.3% 76.4% 81.5%
Type II 86.3% 74.8% 80.1% 85.7% 77.0% 81.1% 88.1% 78.6% 83.1%
Type III 93.2% 79.3% 85.7% 92.9% 80.4% 86.2% 94.3% 83.1% 88.3%
</table>
<tableCaption confidence="0.999945">
Table 1. Performance comparison between different types of sentence alignment methods
</tableCaption>
<bodyText confidence="0.9998641875">
Each type of the web page sentence aligner
makes use of three conventional sentence align-
ment models, one is the length based model fol-
lowing (Brown 1991), one is the lexicon based
model following (Chen 1993), and the other one is
the hybrid model presented in (Zhao 2002). To be
fair in performance comparisons, the text genera-
tive probability Pr(NF. t, NE. t) in tree node
alignment is modeled in accordance with that in
the sentence alignment model. All these sentence
aligners are implemented to handle sentence bead
types of â€œ1-0â€, â€œ0-1â€,â€œ1-1â€, â€œ1-2â€,â€1-3â€,â€2-1â€ and
â€œ3-1â€.
The test corpus is 150 parallel web page pairs
randomly drawn from 20 Chinese-English bilin-
gual web sites on topics related to politics, sports,
significant increase of around 7% on both preci-
sion and recall. Compared with the tree alignment
model, the improvement by the Type 2 aligners is
marginal. A reason for this is that the tree align-
ment model not only exploits HTML tag similari-
ties as in the Type 2 method, but also takes into
account location of texts. In the tree alignment
model, texts at similar locations in the tree hierar-
chical structure are more probable to be transla-
tions than those in disparate locations, even though
they all have the same tag.
We also evaluate the performance of the tree
aligner. Since sentence alignment is performed
within the text chunks of aligned nodes, tree
alignment accuracy is very important for correct
sentence alignment. We measure the alignment
</bodyText>
<page confidence="0.990583">
511
</page>
<bodyText confidence="0.997594">
accuracy on all nodes as well as that specifically
on text nodes on the test corpus. The evaluation
result is shown in table 2.
</bodyText>
<table confidence="0.944507333333333">
total correct accuracy
all node alignment 18492 17966 97.2%
text node alignment 3646 3577 98.1%
</table>
<tableCaption confidence="0.99937">
Table 2. Tree Alignment Metrics
</tableCaption>
<bodyText confidence="0.999886125">
Benchmarks in Table 2 show that the tree
alignment model yields very reliable results with
high accuracy in aligning both text nodes and non-
text nodes. After an analysis on text node align-
ment errors, we find that 79.7% of them have texts
of very short length (no more than 4 words), which
may not contain sufficient information to be identi-
fied as parallel.
</bodyText>
<sectionHeader confidence="0.999309" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999981421052632">
In this paper, we present a new approach to sen-
tence alignment on parallel web pages. Due to the
diversity and noisy nature of web corpora, a sto-
chastic tree alignment model is employed to ex-
ploit document structure in parallel web pages as
useful information for identifying parallel sen-
tences. The tree alignment model can be combined
with various conventional sentence alignment
models to extract parallel sentences from parallel
web pages. Experimental results show that exploit-
ing structural parallelism inherent in parallel web
pages provides superior alignment performance
over conventional sentence alignment methods and
significant improvement (around 7% in both preci-
sion and recall) is achieved by using the stochastic
tree alignment model. With improved sentence
alignment performance, web parallel data mining
systems are able to acquire parallel sentences of
higher quality and quantity from the web.
</bodyText>
<sectionHeader confidence="0.994235" genericHeader="references">
References:
</sectionHeader>
<reference confidence="0.999408068965517">
Brown, P. F., J. C. Lai and R. L. Mercer. 1991. Aligning
Sentences in Parallel Corpora. Proceedings of ACL
1991.
Brown, P. E., S. A. D. Pietra, V. J. D. Pietra, and R. L.
Mercer. 1993. The Mathematics of Statistical Ma-
chine Translation: Parameter Estimation, Computa-
tional Linguistics V19(2), 1993
Chen Jisong., Chau R. and C.-H. Yeh. 2004. Discover-
ing Parallel Text from the World Wide Web, Proceed-
ings of the second workshop on Australasian Infor-
mation Security, Data Mining and Web Intelligence,
and Software Internationalization.
Chen Jiang and Nie Jianyun. 2000. Automatic construc-
tion of parallel English-Chinese corpus for cross-
language information retrieval. Proceedings of the
sixth conference on applied natural language
processing
Chen Stanley. 1993. Aligning Sentences in Bilingual
Corpora Using Lexical Information. Proceedings of
ACL 1993
Chuang T.C. and Yeh.K.C. 2005. Aligning Parallel Bi-
lingual Corpora Statistically with Punctuation Crite-
ria. Computational Linguistics and Chinese Lan-
guage Processing. Vol. 10, 2005, pp. 95-122
Dempster, A., Laird, N., and Rubin, D. 1977. Maximum
likelihood from incomplete data via the EM algo-
rithm. Journal of the Royal Statistical Society, Series
B, 39(1):1â€“38.
Gale W. A. and K. Church. 1993. A Program for Align-
ing Sentences in Parallel Corpora, Computational
Linguistics, 19(1):75â€”102
Gildea. D. 2003. Loosely Tree-Based Alignment for
Machine Translation. In Proceedings of ACL 2003
Kay Martin and Roscheisen Martin 1993. Text Transla-
tion Alignment. Computational Linguistics
19(1):121--142.
Lari K. and S. J. Young. 1990. The estimation of sto-
chastic context free grammars using the Inside-
Outside algorithm, Computer Speech and Language,
4:35â€”56
Ma, Xiaoyi and M. Liberman. 1999. Bits: A Method for
Bilingual Text Search over the Web. Proceedings of
Machine Translation Summit VII.
Melamed. I. Dan. 1996. A Geometric Approach to
Mapping Bitext Correspondence. Proceedings of
EMNLP 96
Moore Robert. C. 2002. Fast and Accurate Sentence
Alignment of Bilingual Corpora. Proceedings of 5th
Conference of the Association for Machine Transla-
tion in the Americas, pp. 135-244
Resnik, P. and N.A. Smith. 2003. The Web as a Parallel
Corpus.Computational Linguistics, 29(3)
Simard, M. and Plamondon, P. 1996 Bilingual Sentence
Alignment: Balancing Robustness and Accuracy.
Proceedings of AMTA-96, Canada.
Simard, M., Foster, G. and Isabelle, P. 1992, Using
Cognates to Align Sentences in Bilingual Corpora.
Proceedings of the Fourth International Conference
</reference>
<page confidence="0.971092">
512
</page>
<reference confidence="0.984296045454545">
on Theoretical and Methodological Issues in Ma-
chine translation (TMI92)
Singh, A. K. and Husain, S. (2005). Comparison, selec-
tion and use of sentence alignment algorithms for
new language pairs. Proceedings of the ACL Work-
shop on Building and Using Parallel Texts.
Wu. Dekai. 1994. Aligning a parallel English-Chinese
corpus statistically with lexical criterias. Proceedings
of ACL 1994.
Wu. Dekai. â€œStochastic Inversion Transduction Gram-
mar and Bilingual Parsing of Parallel Corporaâ€
Computational Linguistics, 23(3):374(1997)
Yamada H. and Knight K. 2001 A Syntax based statis-
tical translation model. In Proceedings of ACL-01
Yang C. C., and Li K. W., Mining English/Chinese Pa-
rallel Documents from the World Wide Web, Pro-
ceedings of the International World Wide Web Con-
ference, Honolulu, Hawaii, 2002.
Zhao Bin. and Stephan. Vogel. 2002. Adaptive Parallel
Sentences Mining From Web Bilingual News Collec-
tion. 2002 IEEE International Conference on Data
Mining. 745-748
</reference>
<page confidence="0.998843">
513
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.001211">
<title confidence="0.813652">on</title>
<affiliation confidence="0.963954">Microsoft Research</affiliation>
<address confidence="0.8216985">5F Sigma Center, 49 Zhichun Road, 100190, P. R.</address>
<email confidence="0.999541">leishi@microsoft.com</email>
<author confidence="0.896431">Ming</author>
<affiliation confidence="0.998133">Microsoft Research</affiliation>
<address confidence="0.820838">5F Sigma Center, 49 Zhichun Road, 100190, P. R.</address>
<email confidence="0.997539">mingzhou@microsoft.com</email>
<abstract confidence="0.991750046623797">Parallel web pages are important source of training data for statistical machine translation. In this paper, we present a new approach to sentence alignment on parallel web pages. Parallel web pages to have parallel the structural correspondence can be indicative information for identifying parallel sentences. In our approach, the web page is represented as a tree, and a stochastic tree alignment model is used to exploit the structural correspondence for sentence alignment. Experiments show that this method significantly enhances alignment accuracy and robustness for parallel web pages which are much more diverse and noisy than standard parallel corpora such as â€œHansardâ€. With improved sentence alignment performance, web mining systems are able to acquire parallel sentences of higher quality from the web. Sentence-aligned parallel bilingual corpora have been essential resources for statistical machine translation (Brown et al. 1993), and many other multi-lingual natural language processing applications. The task of aligning parallel sentences has received considerable attention since the renaissance of data driven machine translation in late 1980s. During the past decades, a number of methods have been proposed to address the sentence alignment problem. Although excellent performance was reported on clean corpora, they are less robust with presence of noise. A recent study by (Singh and Husain 2005) completed a systematic evaluation on different sentence aligners under various conditions. Their experiments showed that the performance of sentence aligners are sensitive to properties of the text, such as format complexity (presence of elements other than text), structural distance (a scale from literal to free translation), the amount of noise (text deletions or preprocessing errors) and typological distance between languages. Their performance varies on different type of texts and they all demonstrate marked performance degradation over noisy data. The results suggest that there is currently no universal solution to sentence alignment under all conditions, and different methods should be applied to different types of texts. In this paper, we specifically address sentence alignment on parallel web pages. It has come to attention with the increasing trend of acquiring large-scale parallel data from the web. Currently, large-scale parallel data are not readily available for most language pairs and domains. But due to a sharply increasing number of bilingual web sites, web mining shows great promise as a solution to this knowledge bottleneck problem. Many systems (Ma 1999; Chen 2000; Yang 2002; Resnik 2003; Chen 2004) have been developed to discover parallel web pages, and sentence aligners are used to extract parallel sentences from the mined web corpora. Sentence alignment performance on parallel web pages, therefore, becomes an increasingly important issue for large-scale high-quality parallel data acquisition. Compared with clean parallel corpora such as &amp;quot;Hansard&amp;quot; (Brown et al. 1993), which consists of 505 of the 2008 Conference on Empirical Methods in Natural Language pages 505â€“513, October Association for Computational Linguistics French-English translations of political debates in the Canadian parliament, texts from the web are far more diverse and noisy. They are from many different domains and of various genres. Their translation may be non-literal or written in disparate language pairs. Noise is abundant with frequent insertions, deletions or non-translations. And there are many very short sentences of 1-3 words. Due to the characteristics of web corpora, direct application of conventional alignment methods without exploiting additional web document information acts as useful information to constrain the scope of search for parallel sentences. The paper is organized as follows: In section 2, we briefly survey previous approaches to sentence alignment. In section 3, we present the stochastic tree alignment model, including parameter estimation and decoding. Then in section 4, we describe how to use the tree alignment model in sentence alignment. Benchmarks are shown in section 5, and the paper is concluded in section 6. Figure 1. Example of parallel web pages yields unsatisfactory alignment results. Our approach to this problem is to make use of the structural parallelism between parallel web pages. Structural parallelism is the phenomenon, that when representing the same content in two different languages, authors have a very strong tendency to use the same document structure. As is shown in Figure 1, sentences located in similar position on both pages are more likely to be translations. Hence, correspondence in the web page structure is an informative indication of parallel sentences. In our approach, the web page is represented as a tree, and a stochastic tree alignment model is used to find the most probable alignment of the tree pair based on their structure and the texts in tree nodes. The tree alignment then Sentence alignment methods can be categorized into three major categories: the length-based, lexicon-based and hybrid method which combines the length-based model and lexicon-based model as complement to each other. The length model was based on the intuition that the length of a translated sentence is likely to be similar to that of the source sentence. (Brown et. at. 1991) used word count as the sentence length, whereas (Gale and Church 1993) used character count. Dynamic programming is used to search the optimal sentence alignment. Both algorithms have achieved remarkably good results for language pairs like English-French and English-German 506 with an error rate of 4% on average. But they are not robust with respect to non-literal translations, deletions and disparate language pairs. Unlike the length-based model, which totally ignores word identity, lexicon-based methods use lexical information to align parallel sentences. and Roscheisen 1993) approach is based on the idea that words that are translations of each other will have similar distribution in source and target texts. By adopting the IBM model 1, (Chen 1993) used word translation probabilities, which he showed gives better accuracy than the sentence length based method. Melamed (Melamed 1996) rather used word correspondence from a different perspective as geometric correspondence for sentence alignment. The hybrid method combines the length model with the lexical method. (Simard and Plamondon 1996) used a two-pass approach, where the first pass performs length-based alignment at the character level as in (Gale and Church 1993) and the second pass uses IBM Model 1, following (Chen 2002) approach is similar to Simardâ€™s. The difference is that Moore used the data obtained in the first pass to train the IBM model in the second pass, so that his approach does not require a priori knowledge about the language pair. Instead of using a two-pass approach, (Zhao and Vogel 2002) combines the length model and the IBM model 1 in a unified framework under a maximum likelihood criterion. To make it more robust on noisy text, they developed a background model to handle text deletions. To further improve sentence alignment accuracy and robustness, methods that make use of additional language or corpus specific information developed. In Brown lengthbased aligner, they assume prior alignment on some corpus specific anchor points to constrain and keep the Viterbi search on track. (Wu 1994) implemented a length-based model for Chinese- English with language specific lexical clues to improve accuracy. (Simard et al. 1992) used cognates, which only exists in closely related language pairs. (Chuang and Yeh 2005) exploited the statistically ordered matching of punctuation marks in two languages to achieve high accuracy sentence alignment. In their web parallel data mining system, (Chen and Nie 2000) used HTML tags in the same way as cognates in (Simard et al. 1992) for aligning Chinese-English parallel sentences. Tree based alignment models have been successfully applied in machine translation (Wu 1997, Yamada &amp; Knight 2001, Gildea 2003). The structure of the HTML document is recursive, with HTML markup tags embedded within other markup tags. While converting an HTML document into the tree representation, such hierarchical order is maintained. Each node of the tree is lawith their corresponding HTML tag and in labeling tree nodes, only markup tags are used and attribute value pairs are dropped. Among all markup tags in the HTML file, those of our most interest are tags containing content text, which is what we want to align. These tags are those surrounding a text chunk or have the attribute of â€œALTâ€. Comments, scripts and style specifications are not regarded as content text and hence are eliminated. Figure 2 illustrates the tree representation of an example HTML document. &lt;html&gt; &lt;head&gt;&lt;title&gt;text1&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;/body&gt; &lt;/html&gt; html Figure. 2 An example HTML document and tree representation Given two trees, the tree alignment is the nondirectional alignments of their nodes. A node in one tree can be aligned with at most one node in the other tree. It is valid for a node to be aligned nothing and such case is regarded as node deletion in tree alignment. To comply with the tree hierarchical structure, we constrain that the keep the tree hierarchy invariant aligned with node then the children of either deleted or aligned with the children of Besides, to simplify the model training and decoding, the tree alignment model also keeps the head body div . . . 507 order invariant, node aligned node then the left sibling nodes of aligned with the right sibling nodes of The stochastic tree alignment model assigns probabilities to tree alignments, based on the particular configuration of the alignment and model parameters. Then, the decoder is able to find the most probable (optimal) alignment of two trees. To facilitate the presentation of the tree alignment model, the following symbols are introduced: giva HTML document D, the correstree; the node of ğ· the sub-tree rooted at Espe- ğ· the root of the tree the forest consisting of the sub-trees rooted at siblnodes from the text in node and the label tag) of the node the of the node the consequence of children nodes from the sub-tree rooted at as the forest of the subrooted at children is represented To accommodate node deletion, introduced to denote the empty node. Finally, the alignment is referred as two HTML documents French) and English) represented as trees the tree alignment task is defined as finding the alignmaximizes the conditional Based on the Bayesâ€™ where the probability of synchronously the alignment the prior knowledge of the tree alignment. To simplify computation, we assume a uniform probability Hence, the tree alignment is to find the maximizes the synchronprobability Based on the hierarchical structure of the tree, in order to facilitate the presentation and computation of the tree alignment probabilistic model, the following alignment probabilities are defined in a hierarchically recursive manner: The probability of synchronously sub-tree pair the align- The probability of synchronously node pair The probability of synchrongenerating forest pairs alignment From the definition, the tree pair generative to the root subpair generative probability , The of the sub-tree pair ğ¹ have the following configurations, based on which the pair generative probability be calculated: ğ¹ If aligned with and the children of aligned with children of is shown in Fig. 3a), then we have If deleted, and the children of with shown in Fig. 3b), then we have If deleted, and aligned with childof shown in Fig. 3c), then we have Figure. 3 The above equations involve forest pair generative probabilities. The alignment of the forest ,ğ‘— have the following configurations, based on which their forest pair generative be calculated: (a) NULL m m m NULL i i 508 ğ¹ If ğ¹ aligned with ğ¸ and with is shown in Fig. 4a), then ğ¹ If deleted, and the forest rooted at combined with with then ğ¹ ğ¹ ğ¹ If deleted, and the forest rooted at combined with with then Figure. 4 Finally, the node pair probability is modeled the generative probability of the translationally equivalent text chunks ğ¹ and their HTML tag pair probability. The text chunk generative be modeled in a variety of ways. The conventional length-based, lexicon-based or hybrid methods used for sentence can be applied here. In the next subsection, we focus on how to estimate the tag pair a set of parallel web pages. We expect pairs of the same or similar HTML tags to have high probabilities and the probabilities for pairs of disparate tags to be low. Maximization One way to estimate the tag pair generative probato manually align nodes between parallel trees, and use the manually aligned trees as the training data for maximum likelihood estimation. However, this is a time-consuming and errorprone procedure. Instead, the Expectation Maximization (EM) (Dempster, Laird and Rubin 1977) algorithm is used to estimate the 5615 manually verified parallel web page pairs from 45 different bilingual web sites. The parameter estimation proceeds as follows: 1. Start with initial parameter values. Expectation: estimate is expectation of aligning tag 3. Maximization: update the parameters based to maximum likelihood estimation 4. Repeat step 2 and 3 until the parameters stabilize step 2, the expected count of aligned with in the training corpus. By calculated as ğ´ the number of occurrence of aligned with the tree alignment efficiently compute enumerating the exponential number of Aâ€™s in the above equation, we extended the inside-outside algorithm presented in (Lari and Young, 1990). inside probability defined as the (a) m ,n] m m, n] NULL ,n] NULL E 1 ,j ] i .CF , ] j ] 509 of generating sub-tree pair aligned with It is estimated as: , , . N ï€¨ N CF N F E F E F E m i m i m i the inside probability the forest pair F ï€© CF N CF A E , . N CF N CF EPr . , . m i m i A The inside probability can be estimated recursively according to the various alignment configurations presented in Figure 3 and Figure 4. The outside defined as the probability generating the part of the when aligned with It is estimated as: p q , ï€¨ ï€¨ ï€© ï€¨ ï€© a LCF N a LCF N F F E E , . m q i p ï€¨ ï€¨ ï€© ï€¨ ï€© a RCF N a RCF N F F E E , . m q i p , ï€¼ the ancestor of and ancestor of an ancestor a decedent of Similarly an ancestor of and a decedent of the forest rooted at to the left of and the forest rooted as to the right of Once inside and outside probabilities are computed, the expected counts can be calculated as F E the generative probability of tree pair all possible alignment be estimated using dynamic programming techniques that will be presented in the next sub-section. Furthermore, the expected count of tag deletion is estimated as: âˆ’ ğ‘– ğ‘–â‰ ğ‘ğ‘ˆğ¿ğ¿ âˆ’ ğ‘– ğ‘–â‰ ğ‘ğ‘ˆğ¿ğ¿ for An intuitive way to find the optimal tree alignment is to enumerate all alignments and pick the one with the highest probability. But it is intractable since the total number of alignments is exponential. Based on the observation that if two trees are optimally aligned, the alignment of their sub-trees must also be optimal, dynamic programming can be applied to find the optimal tree alignment using that of the sub-trees in a bottom-up manner. That is we first compute the optimal alignment probabilities of small trees and use them to compute that of the bigger tree by trying different alignment configurations. This procedure is recursive until the optimal alignment probability of the whole tree is obtained. The following is the pseudo-code of the bottom-up decoding algorithm: 1 (bottom-up) {  |1 (bottom-up) { Select and store optimal alignments of their children fo- CF CF testing configurations 4-6; Select and store the optimal alignment of the sub-tree ğ¸ ğ¹ testing configurations 1-3; Store the optimal configuration}} the number of nodes in The decoding algorithm finds the optimal alignment and its probability for every subtrees and forests. By replacing the selection operation with summing probabilities of all configurations, the sub-tree pair generative probability be calculated along the way. The worst-case time complexity of the algorithm the degree of a tree is defined as the largest degree of its nodes. with Align- Since the tree alignment model aligns parallel web pages at the tree node level instead of the sentence level, we integrate the tree alignment model with the sentence alignment model in a cascaded mode, in which the whole sentence alignment process is divided into two steps. In the first step, the tree alignment decoder finds the optimal alignment of the two trees. Nodes having texts should be aligned with nodes containing their translations. Then in the second step, the conventional sentence aligner is used to align sentences within text chunks in the Pr( | a NULL E)] , ï» ï½ T F E E l N l l 510 aligned nodes. In this step, various sentence alignment models can be applied, including the lengthbased model, the lexicon-based model and the hybrid model. Language or corpus specific information may also be used to further improve sentence alignment accuracy. The tree alignment acts as constraints that confine the scope of the search of sentence aligners. 5 Evaluation To evaluate the effectiveness of exploiting web page document structure with the tree alignment model for improving sentence alignment accuracy, we compared the performance of three types of sentence alignment methods on parallel web pages. The first type is to simply discard web page layout information. Web pages are converted to plain texts, and HTML tags are removed prior to performing sentence alignment. The second type is the baseline method of using web page document information. Instead of exploiting full HTML docstructure, it follows approach and Nie 2000) which uses HTML tags in the same way as cognates used in (Simard et al. 1992). The third type is the combination of tree alignment model and conventional sentence models. computer and literature. By manual annotation, 9,824 parallel sentence pairs are found. All sentence aligners run through the test parallel web pages, and each extracts a set of sentence pairs that it regards as parallel. The output pairs are matched with the annotated parallel sentences from the test corpus. Only exact matches of the sentence pairs are counted as correct. Our evaluation metrics are precision (P), recall (R) and F-measure (F) defined as: R P R ï¿½ Based on the results in table 1, we can see that both Type 2 and Type 3 aligners outperform conventional sentence alignment models. Leveraging HTML document information can enhance sentence alignment quality. Especially, by using the tree alignment model, Type 3 aligners achieve a F * * 2 P Length Lexicon Hybrid P R F P R F P R F Type I 85.6% 72.8% 78.7% 83.1% 75.2% 78.9% 87.3% 76.4% 81.5% Type II 86.3% 74.8% 80.1% 85.7% 77.0% 81.1% 88.1% 78.6% 83.1% Type III 93.2% 79.3% 85.7% 92.9% 80.4% 86.2% 94.3% 83.1% 88.3% Table 1. Performance comparison between different types of sentence alignment methods Each type of the web page sentence aligner makes use of three conventional sentence alignment models, one is the length based model following (Brown 1991), one is the lexicon based model following (Chen 1993), and the other one is the hybrid model presented in (Zhao 2002). To be fair in performance comparisons, the text generaprobability tree node alignment is modeled in accordance with that in the sentence alignment model. All these sentence aligners are implemented to handle sentence bead of â€œ1-0â€, â€œ0-1â€,â€œ1-1â€, and â€œ3-1â€. The test corpus is 150 parallel web page pairs randomly drawn from 20 Chinese-English bilingual web sites on topics related to politics, sports, significant increase of around 7% on both precision and recall. Compared with the tree alignment model, the improvement by the Type 2 aligners is marginal. A reason for this is that the tree alignment model not only exploits HTML tag similarities as in the Type 2 method, but also takes into account location of texts. In the tree alignment model, texts at similar locations in the tree hierarchical structure are more probable to be translations than those in disparate locations, even though they all have the same tag. We also evaluate the performance of the tree aligner. Since sentence alignment is performed within the text chunks of aligned nodes, tree alignment accuracy is very important for correct sentence alignment. We measure the alignment 511 accuracy on all nodes as well as that specifically on text nodes on the test corpus. The evaluation result is shown in table 2. total correct accuracy all node alignment 18492 17966 97.2% text node alignment 3646 3577 98.1% Table 2. Tree Alignment Metrics Benchmarks in Table 2 show that the tree alignment model yields very reliable results with high accuracy in aligning both text nodes and nontext nodes. After an analysis on text node alignment errors, we find that 79.7% of them have texts of very short length (no more than 4 words), which may not contain sufficient information to be identified as parallel. In this paper, we present a new approach to sentence alignment on parallel web pages. Due to the diversity and noisy nature of web corpora, a stochastic tree alignment model is employed to exploit document structure in parallel web pages as useful information for identifying parallel sentences. The tree alignment model can be combined with various conventional sentence alignment models to extract parallel sentences from parallel web pages. Experimental results show that exploiting structural parallelism inherent in parallel web pages provides superior alignment performance over conventional sentence alignment methods and significant improvement (around 7% in both precision and recall) is achieved by using the stochastic tree alignment model. With improved sentence alignment performance, web parallel data mining systems are able to acquire parallel sentences of higher quality and quantity from the web.</abstract>
<note confidence="0.863795807692308">P. F., J. C. Lai and R. L. Mercer. 1991. Corpora. of ACL 1991. Brown, P. E., S. A. D. Pietra, V. J. D. Pietra, and R. L. 1993. Ma- Computational Linguistics V19(2), 1993 Jisong., Chau R. and C.-H. Yeh. 2004. Proceedof the second workshop on Australasian Information Security, Data Mining and Web Intelligence, and Software Internationalization. Jiang and Nie Jianyun. 2000. of the sixth conference on applied natural language processing Stanley. 1993. Bilingual of ACL 1993 T.C. and Yeh.K.C. 2005. Bi- Corpora Linguistics and Chinese Language Processing. Vol. 10, 2005, pp. 95-122 A., Laird, N., and Rubin, D. 1977. via algoof the Royal Statistical Society, Series B, 39(1):1â€“38. W. A. and K. Church. 1993. Program Align- Computational Linguistics, 19(1):75â€”102 D. 2003. Proceedings of ACL 2003 Martin and Roscheisen Martin 1993. Linguistics 19(1):121--142. K. and S. J. Young. 1990. Speech and Language, 4:35â€”56 Xiaoyi and M. Liberman. 1999. A of Machine Translation Summit VII. I. Dan. 1996. of EMNLP 96 Robert. C. 2002. Corpora. of 5th Conference of the Association for Machine Translation in the Americas, pp. 135-244 P. and N.A. Smith. 2003. Linguistics, 29(3) M. and Plamondon, P. 1996 Proceedings of AMTA-96, Canada. M., Foster, G. and Isabelle, P. 1992, Align Bilingual Corpora. Proceedings of the Fourth International Conference 512 on Theoretical and Methodological Issues in Machine translation (TMI92) A. K. and Husain, S. (2005). and of the ACL Workshop on Building and Using Parallel Texts. Dekai. 1994. a of ACL 1994. Dekai. Gramand Bilingual Computational Linguistics, 23(3):374(1997) H. and Knight K. 2001 In Proceedings of ACL-01 C. C., and Li K. W., Pa- Proceedings of the International World Wide Web Conference, Honolulu, Hawaii, 2002. Bin. and Stephan. Vogel. 2002. From Bilingual IEEE International Conference on Data Mining. 745-748 513</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>J C Lai</author>
<author>R L Mercer</author>
</authors>
<title>Aligning Sentences in Parallel Corpora.</title>
<date>1991</date>
<booktitle>Proceedings of ACL</booktitle>
<marker>Brown, Lai, Mercer, 1991</marker>
<rawString>Brown, P. F., J. C. Lai and R. L. Mercer. 1991. Aligning Sentences in Parallel Corpora. Proceedings of ACL 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P E Brown</author>
<author>S A D Pietra</author>
<author>V J D Pietra</author>
<author>R L Mercer</author>
</authors>
<date>1993</date>
<journal>The Mathematics of Statistical Machine Translation: Parameter Estimation, Computational Linguistics</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="1314" citStr="Brown et al. 1993" startWordPosition="187" endWordPosition="190">s represented as a tree, and a stochastic tree alignment model is used to exploit the structural correspondence for sentence alignment. Experiments show that this method significantly enhances alignment accuracy and robustness for parallel web pages which are much more diverse and noisy than standard parallel corpora such as â€œHansardâ€. With improved sentence alignment performance, web mining systems are able to acquire parallel sentences of higher quality from the web. 1 Introduction Sentence-aligned parallel bilingual corpora have been essential resources for statistical machine translation (Brown et al. 1993), and many other multi-lingual natural language processing applications. The task of aligning parallel sentences has received considerable attention since the renaissance of data driven machine translation in late 1980s. During the past decades, a number of methods have been proposed to address the sentence alignment problem. Although excellent performance was reported on clean corpora, they are less robust with presence of noise. A recent study by (Singh and Husain 2005) completed a systematic evaluation on different sentence aligners under various conditions. Their experiments showed that th</context>
<context position="3405" citStr="Brown et al. 1993" startWordPosition="505" endWordPosition="508">anguage pairs and domains. But due to a sharply increasing number of bilingual web sites, web mining shows great promise as a solution to this knowledge bottleneck problem. Many systems (Ma 1999; Chen 2000; Yang 2002; Resnik 2003; Chen 2004) have been developed to discover parallel web pages, and sentence aligners are used to extract parallel sentences from the mined web corpora. Sentence alignment performance on parallel web pages, therefore, becomes an increasingly important issue for large-scale high-quality parallel data acquisition. Compared with clean parallel corpora such as &amp;quot;Hansard&amp;quot; (Brown et al. 1993), which consists of 505 Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 505â€“513, Honolulu, October 2008.cï¿½2008 Association for Computational Linguistics French-English translations of political debates in the Canadian parliament, texts from the web are far more diverse and noisy. They are from many different domains and of various genres. Their translation may be non-literal or written in disparate language pairs. Noise is abundant with frequent insertions, deletions or non-translations. And there are many very short sentences of 1-3 words. Due to </context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Brown, P. E., S. A. D. Pietra, V. J. D. Pietra, and R. L. Mercer. 1993. The Mathematics of Statistical Machine Translation: Parameter Estimation, Computational Linguistics V19(2), 1993</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen Jisong</author>
<author>R Chau</author>
<author>C-H Yeh</author>
</authors>
<title>Discovering Parallel Text from the World Wide Web,</title>
<date>2004</date>
<booktitle>Proceedings of the second workshop on Australasian Information Security, Data Mining and Web Intelligence, and Software Internationalization.</booktitle>
<marker>Jisong, Chau, Yeh, 2004</marker>
<rawString>Chen Jisong., Chau R. and C.-H. Yeh. 2004. Discovering Parallel Text from the World Wide Web, Proceedings of the second workshop on Australasian Information Security, Data Mining and Web Intelligence, and Software Internationalization.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen Jiang</author>
<author>Nie Jianyun</author>
</authors>
<title>Automatic construction of parallel English-Chinese corpus for crosslanguage information retrieval.</title>
<date>2000</date>
<booktitle>Proceedings of the sixth conference on applied natural language processing</booktitle>
<marker>Jiang, Jianyun, 2000</marker>
<rawString>Chen Jiang and Nie Jianyun. 2000. Automatic construction of parallel English-Chinese corpus for crosslanguage information retrieval. Proceedings of the sixth conference on applied natural language processing</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen Stanley</author>
</authors>
<title>Aligning Sentences in Bilingual Corpora Using Lexical Information.</title>
<date>1993</date>
<booktitle>Proceedings of ACL</booktitle>
<marker>Stanley, 1993</marker>
<rawString>Chen Stanley. 1993. Aligning Sentences in Bilingual Corpora Using Lexical Information. Proceedings of ACL 1993</rawString>
</citation>
<citation valid="true">
<authors>
<author>T C Chuang</author>
<author>K C Yeh</author>
</authors>
<title>Aligning Parallel Bilingual Corpora Statistically with Punctuation Criteria.</title>
<date>2005</date>
<journal>Computational Linguistics and Chinese Language Processing.</journal>
<volume>10</volume>
<pages>95--122</pages>
<contexts>
<context position="8205" citStr="Chuang and Yeh 2005" startWordPosition="1258" endWordPosition="1261">on noisy text, they developed a background model to handle text deletions. To further improve sentence alignment accuracy and robustness, methods that make use of additional language or corpus specific information were developed. In Brown and Churchâ€™s lengthbased aligner, they assume prior alignment on some corpus specific anchor points to constrain and keep the Viterbi search on track. (Wu 1994) implemented a length-based model for ChineseEnglish with language specific lexical clues to improve accuracy. (Simard et al. 1992) used cognates, which only exists in closely related language pairs. (Chuang and Yeh 2005) exploited the statistically ordered matching of punctuation marks in two languages to achieve high accuracy sentence alignment. In their web parallel data mining system, (Chen and Nie 2000) used HTML tags in the same way as cognates in (Simard et al. 1992) for aligning Chinese-English parallel sentences. Tree based alignment models have been successfully applied in machine translation (Wu 1997, Yamada &amp; Knight 2001, Gildea 2003). 3 The Stochastic Tree Alignment Model The structure of the HTML document is recursive, with HTML markup tags embedded within other markup tags. While converting an H</context>
</contexts>
<marker>Chuang, Yeh, 2005</marker>
<rawString>Chuang T.C. and Yeh.K.C. 2005. Aligning Parallel Bilingual Corpora Statistically with Punctuation Criteria. Computational Linguistics and Chinese Language Processing. Vol. 10, 2005, pp. 95-122</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Dempster</author>
<author>N Laird</author>
<author>D Rubin</author>
</authors>
<title>Maximum likelihood from incomplete data via the EM algorithm.</title>
<date>1977</date>
<journal>Journal of the Royal Statistical Society, Series B,</journal>
<volume>39</volume>
<issue>1</issue>
<marker>Dempster, Laird, Rubin, 1977</marker>
<rawString>Dempster, A., Laird, N., and Rubin, D. 1977. Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society, Series B, 39(1):1â€“38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Gale</author>
<author>K Church</author>
</authors>
<title>A Program for Aligning Sentences in Parallel Corpora,</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="5903" citStr="Gale and Church 1993" startWordPosition="897" endWordPosition="900">model is used to find the most probable alignment of the tree pair based on their structure and the texts in tree nodes. The tree alignment then 2 Sentence Alignment Models Sentence alignment methods can be categorized into three major categories: the length-based, lexicon-based and hybrid method which combines the length-based model and lexicon-based model as complement to each other. The length model was based on the intuition that the length of a translated sentence is likely to be similar to that of the source sentence. (Brown et. at. 1991) used word count as the sentence length, whereas (Gale and Church 1993) used character count. Dynamic programming is used to search the optimal sentence alignment. Both algorithms have achieved remarkably good results for language pairs like English-French and English-German 506 with an error rate of 4% on average. But they are not robust with respect to non-literal translations, deletions and disparate language pairs. Unlike the length-based model, which totally ignores word identity, lexicon-based methods use lexical information to align parallel sentences. Kayâ€™s (Kay and Roscheisen 1993) approach is based on the idea that words that are translations of each ot</context>
</contexts>
<marker>Gale, Church, 1993</marker>
<rawString>Gale W. A. and K. Church. 1993. A Program for Aligning Sentences in Parallel Corpora, Computational Linguistics, 19(1):75â€”102</rawString>
</citation>
<citation valid="true">
<authors>
<author>D</author>
</authors>
<title>Loosely Tree-Based Alignment for Machine Translation.</title>
<date>2003</date>
<booktitle>In Proceedings of ACL</booktitle>
<marker>D, 2003</marker>
<rawString>Gildea. D. 2003. Loosely Tree-Based Alignment for Machine Translation. In Proceedings of ACL 2003</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kay Martin</author>
<author>Roscheisen Martin</author>
</authors>
<title>Text Translation Alignment.</title>
<date>1993</date>
<journal>Computational Linguistics</journal>
<volume>19</volume>
<issue>1</issue>
<marker>Martin, Martin, 1993</marker>
<rawString>Kay Martin and Roscheisen Martin 1993. Text Translation Alignment. Computational Linguistics 19(1):121--142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Lari</author>
<author>S J Young</author>
</authors>
<title>The estimation of stochastic context free grammars using the InsideOutside algorithm, Computer Speech and Language,</title>
<date>1990</date>
<pages>4--35</pages>
<contexts>
<context position="16738" citStr="Lari and Young, 1990" startWordPosition="2721" endWordPosition="2724"> [ counKNULL, / count/, NUL L] count NUL L, l count l, NUL L l &apos; 4. Repeat step 2 and 3 until the parameters stabilize In step 2, count:::::::(ğ‘™,ğ‘™â€²) is the expected count of l being aligned with l&apos; in the training corpus. By definition, count:::::::(ğ‘™,ğ‘™â€²) is calculated as count:::::::(ğ‘™,ğ‘™â€²) = ; Pr(ğ´|ğ‘‡ğ¹ , ğ‘‡ğ¸)count(ğ‘™,ğ‘™â€²) ğ´ where count(ğ‘™,ğ‘™â€²) is the number of occurrence of l being aligned with lâ€™ in the tree alignment A. To efficiently compute count:::::::(ğ‘™,ğ‘™â€²) without enumerating the exponential number of Aâ€™s in the above equation, we extended the inside-outside algorithm presented in (Lari and Young, 1990). The inside probability ğ›¼(ğ‘ğ‘—ğ¹, ğ‘ğ‘–ğ¸) is defined as the (a) TF m TF T[Fm1 ,n] m T[F m, n] NULL TmF.CF TF [m1 ,n] NULL TiE E Ti 1 ,j ] TE i .CF T[E i1 , E T[i,j ] T[E i j ] 509 probability of generating sub-tree pair {ğ‘‡ğ‘— ğ¹, ğ‘‡ğ‘–ğ¸} when ğ‘ğ‘–ğ¸ is aligned with ğ‘ğ‘—ğ¹. It is estimated as:  ,  Pr ,  . , . N N   N N  N CF N CF F E F E F E m i m i m i where ğ›¼(ğ‘ğ‘šğ¹. ğ¶ğ¹, ğ‘ğ‘–ğ¸. ğ¶ğ¹) is the inside probability for the forest pair (ğ‘ğ‘šğ¹. ğ¶ğ¹, ğ‘ğ‘–ğ¸. ğ¶ğ¹) F      N CF N CF A E  . , . N CF N CF F E Pr . , .  . m i m i A The inside probability can be estimated recursively according to the various alignment </context>
</contexts>
<marker>Lari, Young, 1990</marker>
<rawString>Lari K. and S. J. Young. 1990. The estimation of stochastic context free grammars using the InsideOutside algorithm, Computer Speech and Language, 4:35â€”56</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoyi Ma</author>
<author>M Liberman</author>
</authors>
<title>Bits: A Method for Bilingual Text Search over the Web.</title>
<date>1999</date>
<booktitle>Proceedings of Machine Translation Summit VII.</booktitle>
<marker>Ma, Liberman, 1999</marker>
<rawString>Ma, Xiaoyi and M. Liberman. 1999. Bits: A Method for Bilingual Text Search over the Web. Proceedings of Machine Translation Summit VII.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan</author>
</authors>
<title>A Geometric Approach to Mapping Bitext Correspondence.</title>
<date>1996</date>
<booktitle>Proceedings of EMNLP 96</booktitle>
<marker>Dan, 1996</marker>
<rawString>Melamed. I. Dan. 1996. A Geometric Approach to Mapping Bitext Correspondence. Proceedings of EMNLP 96</rawString>
</citation>
<citation valid="true">
<authors>
<author>C</author>
</authors>
<title>Fast and Accurate Sentence Alignment of Bilingual Corpora.</title>
<date>2002</date>
<booktitle>Proceedings of 5th Conference of the Association for Machine Translation in the Americas,</booktitle>
<pages>135--244</pages>
<marker>C, 2002</marker>
<rawString>Moore Robert. C. 2002. Fast and Accurate Sentence Alignment of Bilingual Corpora. Proceedings of 5th Conference of the Association for Machine Translation in the Americas, pp. 135-244</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Resnik</author>
<author>N A Smith</author>
</authors>
<title>The Web as a Parallel Corpus.Computational Linguistics,</title>
<date>2003</date>
<volume>29</volume>
<issue>3</issue>
<marker>Resnik, Smith, 2003</marker>
<rawString>Resnik, P. and N.A. Smith. 2003. The Web as a Parallel Corpus.Computational Linguistics, 29(3)</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Simard</author>
<author>P Plamondon</author>
</authors>
<title>Bilingual Sentence Alignment: Balancing Robustness and Accuracy.</title>
<date>1996</date>
<booktitle>Proceedings of AMTA-96,</booktitle>
<contexts>
<context position="6953" citStr="Simard and Plamondon 1996" startWordPosition="1052" endWordPosition="1055">con-based methods use lexical information to align parallel sentences. Kayâ€™s (Kay and Roscheisen 1993) approach is based on the idea that words that are translations of each other will have similar distribution in source and target texts. By adopting the IBM model 1, (Chen 1993) used word translation probabilities, which he showed gives better accuracy than the sentence length based method. Melamed (Melamed 1996) rather used word correspondence from a different perspective as geometric correspondence for sentence alignment. The hybrid method combines the length model with the lexical method. (Simard and Plamondon 1996) used a two-pass approach, where the first pass performs length-based alignment at the character level as in (Gale and Church 1993) and the second pass uses IBM Model 1, following (Chen 1993). Mooreâ€™s (Moore 2002) approach is similar to Simardâ€™s. The difference is that Moore used the data obtained in the first pass to train the IBM model in the second pass, so that his approach does not require a priori knowledge about the language pair. Instead of using a two-pass approach, (Zhao and Vogel 2002) combines the length model and the IBM model 1 in a unified framework under a maximum likelihood cr</context>
</contexts>
<marker>Simard, Plamondon, 1996</marker>
<rawString>Simard, M. and Plamondon, P. 1996 Bilingual Sentence Alignment: Balancing Robustness and Accuracy. Proceedings of AMTA-96, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Simard</author>
<author>G Foster</author>
<author>P Isabelle</author>
</authors>
<title>Using Cognates to Align Sentences in Bilingual Corpora.</title>
<date>1992</date>
<booktitle>Proceedings of the Fourth International Conference on Theoretical and Methodological Issues in Machine translation (TMI92)</booktitle>
<contexts>
<context position="8115" citStr="Simard et al. 1992" startWordPosition="1244" endWordPosition="1247">el 1 in a unified framework under a maximum likelihood criterion. To make it more robust on noisy text, they developed a background model to handle text deletions. To further improve sentence alignment accuracy and robustness, methods that make use of additional language or corpus specific information were developed. In Brown and Churchâ€™s lengthbased aligner, they assume prior alignment on some corpus specific anchor points to constrain and keep the Viterbi search on track. (Wu 1994) implemented a length-based model for ChineseEnglish with language specific lexical clues to improve accuracy. (Simard et al. 1992) used cognates, which only exists in closely related language pairs. (Chuang and Yeh 2005) exploited the statistically ordered matching of punctuation marks in two languages to achieve high accuracy sentence alignment. In their web parallel data mining system, (Chen and Nie 2000) used HTML tags in the same way as cognates in (Simard et al. 1992) for aligning Chinese-English parallel sentences. Tree based alignment models have been successfully applied in machine translation (Wu 1997, Yamada &amp; Knight 2001, Gildea 2003). 3 The Stochastic Tree Alignment Model The structure of the HTML document is</context>
<context position="22031" citStr="Simard et al. 1992" startWordPosition="3738" endWordPosition="3741">page document structure with the tree alignment model for improving sentence alignment accuracy, we compared the performance of three types of sentence alignment methods on parallel web pages. The first type is to simply discard web page layout information. Web pages are converted to plain texts, and HTML tags are removed prior to performing sentence alignment. The second type is the baseline method of using web page document information. Instead of exploiting full HTML document structure, it follows Chenâ€™s approach (Chen and Nie 2000) which uses HTML tags in the same way as cognates used in (Simard et al. 1992). The third type is the combination of tree alignment model and conventional sentence models. computer and literature. By manual annotation, 9,824 parallel sentence pairs are found. All sentence aligners run through the test parallel web pages, and each extracts a set of sentence pairs that it regards as parallel. The output pairs are matched with the annotated parallel sentences from the test corpus. Only exact matches of the sentence pairs are counted as correct. Our evaluation metrics are precision (P), recall (R) and F-measure (F) defined as: # of correctly aligned sentence pairs # of tota</context>
</contexts>
<marker>Simard, Foster, Isabelle, 1992</marker>
<rawString>Simard, M., Foster, G. and Isabelle, P. 1992, Using Cognates to Align Sentences in Bilingual Corpora. Proceedings of the Fourth International Conference on Theoretical and Methodological Issues in Machine translation (TMI92)</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Singh</author>
<author>S Husain</author>
</authors>
<title>Comparison, selection and use of sentence alignment algorithms for new language pairs.</title>
<date>2005</date>
<booktitle>Proceedings of the ACL Workshop on Building and Using Parallel Texts.</booktitle>
<contexts>
<context position="1790" citStr="Singh and Husain 2005" startWordPosition="260" endWordPosition="263">. 1 Introduction Sentence-aligned parallel bilingual corpora have been essential resources for statistical machine translation (Brown et al. 1993), and many other multi-lingual natural language processing applications. The task of aligning parallel sentences has received considerable attention since the renaissance of data driven machine translation in late 1980s. During the past decades, a number of methods have been proposed to address the sentence alignment problem. Although excellent performance was reported on clean corpora, they are less robust with presence of noise. A recent study by (Singh and Husain 2005) completed a systematic evaluation on different sentence aligners under various conditions. Their experiments showed that the performance of sentence aligners are sensitive to properties of the text, such as format complexity (presence of elements other than text), structural distance (a scale from literal to free translation), the amount of noise (text deletions or preprocessing errors) and typological distance between languages. Their performance varies on different type of texts and they all demonstrate marked performance degradation over noisy data. The results suggest that there is curren</context>
</contexts>
<marker>Singh, Husain, 2005</marker>
<rawString>Singh, A. K. and Husain, S. (2005). Comparison, selection and use of sentence alignment algorithms for new language pairs. Proceedings of the ACL Workshop on Building and Using Parallel Texts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai</author>
</authors>
<title>Aligning a parallel English-Chinese corpus statistically with lexical criterias.</title>
<date>1994</date>
<booktitle>Proceedings of ACL</booktitle>
<marker>Dekai, 1994</marker>
<rawString>Wu. Dekai. 1994. Aligning a parallel English-Chinese corpus statistically with lexical criterias. Proceedings of ACL 1994.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Dekai</author>
</authors>
<title>Stochastic Inversion Transduction Grammar and Bilingual Parsing</title>
<journal>of Parallel Corporaâ€ Computational Linguistics,</journal>
<volume>23</volume>
<issue>3</issue>
<marker>Dekai, </marker>
<rawString>Wu. Dekai. â€œStochastic Inversion Transduction Grammar and Bilingual Parsing of Parallel Corporaâ€ Computational Linguistics, 23(3):374(1997)</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Yamada</author>
<author>K Knight</author>
</authors>
<title>A Syntax based statistical translation model.</title>
<date>2001</date>
<booktitle>In Proceedings of ACL-01</booktitle>
<contexts>
<context position="8624" citStr="Yamada &amp; Knight 2001" startWordPosition="1325" endWordPosition="1328">h-based model for ChineseEnglish with language specific lexical clues to improve accuracy. (Simard et al. 1992) used cognates, which only exists in closely related language pairs. (Chuang and Yeh 2005) exploited the statistically ordered matching of punctuation marks in two languages to achieve high accuracy sentence alignment. In their web parallel data mining system, (Chen and Nie 2000) used HTML tags in the same way as cognates in (Simard et al. 1992) for aligning Chinese-English parallel sentences. Tree based alignment models have been successfully applied in machine translation (Wu 1997, Yamada &amp; Knight 2001, Gildea 2003). 3 The Stochastic Tree Alignment Model The structure of the HTML document is recursive, with HTML markup tags embedded within other markup tags. While converting an HTML document into the tree representation, such hierarchical order is maintained. Each node of the tree is labeled with their corresponding HTML tag (e.g. body, title, img etc.) and in labeling tree nodes, only markup tags are used and attribute value pairs are dropped. Among all markup tags in the HTML file, those of our most interest are tags containing content text, which is what we want to align. These tags are </context>
</contexts>
<marker>Yamada, Knight, 2001</marker>
<rawString>Yamada H. and Knight K. 2001 A Syntax based statistical translation model. In Proceedings of ACL-01</rawString>
</citation>
<citation valid="true">
<authors>
<author>C C Yang</author>
<author>K W Li</author>
</authors>
<title>Mining English/Chinese Parallel Documents from the World Wide Web,</title>
<date>2002</date>
<booktitle>Proceedings of the International World Wide Web Conference,</booktitle>
<location>Honolulu, Hawaii,</location>
<marker>Yang, Li, 2002</marker>
<rawString>Yang C. C., and Li K. W., Mining English/Chinese Parallel Documents from the World Wide Web, Proceedings of the International World Wide Web Conference, Honolulu, Hawaii, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Vogel</author>
</authors>
<title>Adaptive Parallel Sentences Mining From Web Bilingual News Collection.</title>
<date>2002</date>
<booktitle>IEEE International Conference on Data Mining.</booktitle>
<pages>745--748</pages>
<contexts>
<context position="7454" citStr="Vogel 2002" startWordPosition="1141" endWordPosition="1142">ce alignment. The hybrid method combines the length model with the lexical method. (Simard and Plamondon 1996) used a two-pass approach, where the first pass performs length-based alignment at the character level as in (Gale and Church 1993) and the second pass uses IBM Model 1, following (Chen 1993). Mooreâ€™s (Moore 2002) approach is similar to Simardâ€™s. The difference is that Moore used the data obtained in the first pass to train the IBM model in the second pass, so that his approach does not require a priori knowledge about the language pair. Instead of using a two-pass approach, (Zhao and Vogel 2002) combines the length model and the IBM model 1 in a unified framework under a maximum likelihood criterion. To make it more robust on noisy text, they developed a background model to handle text deletions. To further improve sentence alignment accuracy and robustness, methods that make use of additional language or corpus specific information were developed. In Brown and Churchâ€™s lengthbased aligner, they assume prior alignment on some corpus specific anchor points to constrain and keep the Viterbi search on track. (Wu 1994) implemented a length-based model for ChineseEnglish with language spe</context>
</contexts>
<marker>Vogel, 2002</marker>
<rawString>Zhao Bin. and Stephan. Vogel. 2002. Adaptive Parallel Sentences Mining From Web Bilingual News Collection. 2002 IEEE International Conference on Data Mining. 745-748</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>