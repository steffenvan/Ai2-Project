<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000005">
<title confidence="0.9977125">
Using Morphology and Syntax Together
in Unsupervised Learning
</title>
<author confidence="0.997147">
Yu Hu and Irina Matveeva
</author>
<affiliation confidence="0.999198">
Department of
Computer Science
The University of Chicago
</affiliation>
<address confidence="0.676675">
Chicago IL 60637
</address>
<email confidence="0.784173">
yuhu@cs.uchicago.edu
matveeva
@uchicago.edu
</email>
<author confidence="0.995137">
John Goldsmith
</author>
<affiliation confidence="0.998975333333333">
Departments of Linguistics and
Computer Science
The University of Chicago
</affiliation>
<address confidence="0.5166435">
Chicago IL 60637
ja-goldsmith
</address>
<email confidence="0.996784">
@uchicago.edu
</email>
<author confidence="0.985871">
Colin Sprague
</author>
<affiliation confidence="0.995364">
Department of Linguistics
The University of Chicago
</affiliation>
<address confidence="0.6077105">
Chicago IL 60637
sprague
</address>
<email confidence="0.997137">
@uchicago.edu
</email>
<sectionHeader confidence="0.996615" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99987">
Unsupervised learning of grammar is a
problem that can be important in many
areas ranging from text preprocessing
for information retrieval and
classification to machine translation.
We describe an MDL based grammar
of a language that contains morphology
and lexical categories. We use an
unsupervised learner of morphology to
bootstrap the acquisition of lexical
categories and use these two learning
processes iteratively to help and
constrain each other. To be able to do
so, we need to make our existing
morphological analysis less fine
grained. We present an algorithm for
collapsing morphological classes
(signatures) by using syntactic context.
Our experiments demonstrate that this
collapse preserves the relation between
morphology and lexical categories
within new signatures, and thereby
minimizes the description length of the
model.
</bodyText>
<sectionHeader confidence="0.999165" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999931658536585">
Our long term goal is the development of
methods which will allow one to produce
optimal analyses from arbitrary natural language
corpora, where by optimization we understand
an MDL (minimum description length;
Rissanen, 1989) interpretation of the term: an
optimal analysis is one which finds a grammar
which simultaneously minimizes grammar
length and data compression length. Our specific
and primary focus is on morphology, and on
how knowledge of morphology can be a useful
step towards a more complete knowledge of a
language’s linguistic structure.
Our strategy is based on the following
observation: knowing the rightmost suffix of a
word is very useful information in inferring (or
guessing) a word’s part of speech (POS), but due
to the ambiguity of many suffixes, it is even
better to know both a word’s suffix and the
range of other suffixes that the word’s stem
appears with elsewhere, i.e., its signature. As we
will see below, this conjunction of “better”
information is what we call the signature
transform, and in this paper, we explore how
knowledge of signature transform can be merged
with knowledge of the context vector to draw
conclusions about morphology and syntax.
In the distant future, we would like to be able
to use the signature transform in a general
process of grammar induction, but that day is
not here; we therefore test our experiments by
seeing how well we are able to predict POS as
assigned by an available tagger (TreeTagger;
Schmid 1994). In particular, we wish to decrease
the uncertainty of a word’s POS through the
morphological analysis described here. This
decrease of uncertainty will enter into our
calculation through an increase in the
probability assigned to our test corpus once the
corpus has been augmented with TreeTagger
assigned POS tags. But to be clear on our
</bodyText>
<page confidence="0.944079">
20
</page>
<note confidence="0.9944175">
Proceedings of the Second Workshop on Psychocomputational Models of Human Language Acquisition, pages 20–27,
Ann Arbor, June 2005. c�2005 Association for Computational Linguistics
</note>
<bodyText confidence="0.999981111111111">
process: we analyze a completely raw text
morphologically, and use the POS tags from
TreeTagger only to evaluate the signature
transforms that we generate.
We assume without argument here that any
adequate natural language grammar will contain
a lexicon which includes both lexical stems
which are specified for morphological
properties, such as the specific affixes with
which they may occur, and affixes associated
with lexical categories. We also explicitly note
that many affixes are homophonous: they are
pronounced (or written) identically, but have
different morphological or syntactic
characteristics, such as the English plural –s and
the verbal 3rd person singular present –s.
We focus initially on unsupervised learning
of morphology for three reasons: first, because
we already have a quite successful unsupervised
morphological learner; second, the final suffix of
a word is typically the strongest single indicator
of its syntactic category; and third, analysis of a
word into a stem T plus suffix F allows us
(given our knowledge that the suffix F is a
stronger indicator of category than the stem T)
to collapse many distinct stems into a single
cover symbol for purposes of analysis,
simplifying our task, as we shall see.1 We
eschew the use of linguistic resources with hand-
(i.e., human-)assigned morphological infor-
mation in order for this work to contribute,
eventually, to a better theoretical understanding
of human language acquisition.
We present in this paper an algorithm that
modifies the output of the morphology analyzer
by combining redundant signatures. Since we
ultimately want to use signatures and signature
transforms to learn syntactic categories, we
developed an algorithm that uses the syntactic
contextual information. We evaluate the changes
to the morphological analysis from the
standpoint of efficient and adequate
representation of lexical categories. This paper
presents a test conducted on English, and thus
can only be considered a preliminary step in the
</bodyText>
<footnote confidence="0.920133333333333">
1 See Higgins 2002 for a study similar in some ways;
Higgins uses morphology as a bootstrap heuristic in one
experimental set-up. This paper is heavily indebted to prior
work on unsupervised learning of position categories such
as Brown et al 1992, Schütze 1997, Higgins 2002, and
others cited there.
</footnote>
<bodyText confidence="0.999597933333333">
eventually development of a language-
independent tool for grammar induction based
on morphology. Nonetheless, the concepts that
motivate the process are language-independent,
and we are optimistic that similar results would
be found in tests based on texts from other
languages.
In section 2 we discuss the notion of
signature and signature transform, and section 3
present a more explicit formulation of the
general problem. In section 4 we present our
algorithm for signature collapse. Section 5
describes the experiments we ran to test the
signature collapsing algorithm, and section 6
presents and discusses our results.
</bodyText>
<sectionHeader confidence="0.956216" genericHeader="introduction">
2 Signatures and signature transforms
</sectionHeader>
<bodyText confidence="0.999943303030303">
We employ the unsupervised learning of
morphology developed by Goldsmith
(Goldsmith, 2001). Regrettably, some of the
discussion below depends rather heavily on
material presented there, but we attempt to
summarize the major points here.
Two critical terms that we employ in this
analysis are signature and signature transform.
A signature found in a given corpus is a pair of
lists: a stem-list and a suffix-list (or in the
appropriate context, a prefix-list). By definition
of signature 6, the concatenation of every stem
in the stem-list of 6 with every suffix in the
suffix-list of 6 is found in the corpus, and a
morphological analysis of a corpus can be
viewed as a set of signatures that uniquely
analyze each word in the corpus. For example, a
corpus of English that includes the words jump,
jumps, jumped, jumping, walk, walks, walked,
and walking might include the signature 61
whose stem list is { jump, walk } and whose
suffix list is { Ø, ed, ing , s }. For convenience,
we label a signature with the concatenation of its
suffixes separated by period ‘.’. On such an
analysis, the word jump is analyzed as belonging
to the signature 0.ed.ing.s, and it bears the
suffix Ø. We say, then, that the signature
transform of jump is 0.ed.ing.s_ 0, just as the
signature transform of jumping is
0.ed.ing.s_ing; in general, the signature
transform of a word W, when W is morpho-
logically analyzed as stem T followed by suffix
F, associated with signature 6, is defined as 6_F.
</bodyText>
<page confidence="0.998464">
21
</page>
<bodyText confidence="0.999983773584906">
In many of the experiments described below,
we use a corpus in which all words whose
frequency rank is greater than 200 have been
replaced by their signature transforms. This
move is motivated by the observation that high
frequency words in natural languages tend to
have syntactic distributions poorly predictable
by any feature other than their specific identity,
whereas the distribution properties of lower
frequency words (which we take to be words
whose frequency rank is 200 or below) are better
predicted by category membership.
In many cases, there is a natural connection
between a signature transform and a lexical
category. Our ultimate goal is to exploit this in
the larger context of grammar induction. For
example, consider the signature Ø.er.ly, which
occurs with stems such as strong and weak; in
fact, words whose signature transform is
Ø.er.ly_ Ø are adjectives, those whose signature
transform is Ø.er.ly_er are comparative
adjectives, and those whose signature transform
is Ø.er.ly_ly are adverbs.
The connection is not perfect, however.
Consider the signature Ø.ed.ing.s and its four
signature transforms. While most words whose
σ -transform is Ø.ed.ing.s_s are verbs (indeed,
3rd person singular present tense verbs, as in he
walks funny), many are in fact plural nouns (e.g.,
walks in He permitted four walks in the eighth
inning is a plural noun). We will refer to this
problem as the signature purity problem–it is
essentially the reflex of the ambiguity of
suffixes.
In addition, many 3rd person singular present
tense verbs are associated with other signature
transforms, such as Ø.ing.s_s, Ø.ed.s_s, and so
forth; we will refer to this as the signature-
collapsing problem, because all other things
being equal, we would like to collapse certain
signatures, such as Ø.ed.ing.s and Ø.ed.ing,
since a stem that is associated with the latter
signature could have appeared in the corpus with
an -s suffix; removing the Ø.ed.ing signature and
reassigning its stems to the Ø.ed.ing.s signature
will in general give us a better linguistic analysis
of the corpus, one that can be better used in the
problem of lexical category induction. This is
the reflex of the familiar data sparsity concern.2
Since we ultimately want to use signatures
and signature transforms to learn syntactic
categories, we base the similarity measure
between the signatures on the context.
</bodyText>
<sectionHeader confidence="0.9630155" genericHeader="method">
3 A more abstract statement of the
problem
</sectionHeader>
<bodyText confidence="0.999978142857143">
A minimum description length (MDL) analysis
is especially appropriate for machine learning of
linguistic analysis because simultaneously it
puts a premium both on analytical simplicity and
on goodness of fit between the model and the
data (Rissanen 1989).
We will present first the mathematical
statement of the MDL model of the morphology,
in (1), following the analysis in Goldsmith
(2001), followed by a description of the meaning
of the terms of the expressions, and then present
the modified version which includes additional
terms regarding part of speech (POS)
information, in (2) and (3).
</bodyText>
<equation confidence="0.8140025">
(1) Morphology
a. Grammar g =
b. Length(g) =
⎡ [ ]
W 1
∑ ⎢ log σ + ∑ log
t T set ofstems
∈ = ⎣ [ ( )]
t 0≤&lt;
i|t |freq t[i]
⎡ [ ] ⎤
σ [W] ⎥⎦
+ ∑ f∑⎣log [σ ∩ f] +log [f]
σ∈Σ∈σ
</equation>
<bodyText confidence="0.998307125">
2 The signature-collapsing problem has another side to it as
well. An initial morphological analysis of English will
typically give rise to a morphological analysis of words
such as move, moves, moved, moving with a signature
whose stems include mov and whose affixes are e.ed.es.ing.
A successful solution to the signature-collapsing problem
will collapse Ø.ed.ing.s with e.ed.es.ing, noting that Ø — e,
ed —ed, es — s, and ing — ing in an obvious sense.
</bodyText>
<equation confidence="0.947636583333334">
arg min Length(g) log prob(Data  |g)]
[ −
g∈
G
⎤
⎥
⎦
+ ∑ ∑
log
f F set of affixes 0 i  |f  |freq f [ i ]
∈ = ≤ &lt;
1
22
c. log prob(Data  |g) =
⎡log ( )
prob σ ⎤
⎢ ⎥
∑+ log (  |)
prob t σ
⎢ ⎥
w Data
∈
w=t+ f,σ ⎣+ log prob(f  |t, σ)]
Equation (1a) states that our goal is to find
</equation>
<bodyText confidence="0.9975995625">
the (morphological) grammar that
simultaneously minimizes the sum of its own
length and the compressed length of the data it
analyzes, while (1b) specifies the grammar
length (or model length) as the sum of the
lengths of the links between the major
components of the morphology: the list of letters
(or phonemes) comprising the morphemes, the
morphemes (stems and affixes), and the
signatures. We use square brackets “[.]” to
denote the token counts in a corpus containing a
given morpheme or word. The first line of (1b)
expresses the notion that each stem consists of a
pointer to its signature and a list of pointers to
the letters that comprise it; σ(t) is the signature
associated with stem t, and we take its
</bodyText>
<equation confidence="0.973400333333333">
[ ( )]
σ t , the empirical count of
[W]
</equation>
<bodyText confidence="0.9991523125">
the words associated with σ(t) divided by the
total count of words in the data. The second line
expresses the idea that the morphology contains
a list of affixes, each of which contains a list of
pointers to the letters that comprise it. The third
line of (1b) expresses the notion that a signature
consists of a list of pointers to the component
affixes. (1c) expresses the compressed length of
each word in the data.3
We now consider extending this model to
include part of speech labeling, as sketched in
(2). The principal innovation in (2) is the
addition of part of speech tags; each affix is
associated with one or more POS tags. As we
3 We do not sum over all occurrences of a word in the
corpus; we count the compressed length of each word type
found in the corpus. This decision was made based on the
observation that the (compressed length of the) data term
grows much faster than the length of the grammar as the
corpus gets large, and the loss in ability of the model to
predict word frequencies overwhelms any increase in
model simplicity when we count word tokens in the data
terms. We recognize the departure from the traditional
understanding of MDL here, and assume the responsibility
to explain this in a future publication.
have seen, a path from a particular signature σ to
a particular affix f constitutes what we have
called a particular signature transform σ_f ; and
we condition the probabilities of the POS tags in
the data on the preceding signature
transformation. As a result, our final model takes
the form in (3).
</bodyText>
<equation confidence="0.943345928571429">
(3)
a. Grammar g =
argmin[Length(g) log (  |)]
− prob Data g
g G
∈
b. Length(g) =
⎡ [ ] ⎤
W 1 ⎥
∑ ⎢ log σ +∑log ⎦
[ ( )]
t T set ofstems
∈ = ⎣ t 0≤i&lt;|t |freqt i
[ ]
</equation>
<bodyText confidence="0.999877">
The differences between the models are
found in the added final term in (3b), which
specifies the information required to predict, or
specify, the part of speech given the signature
</bodyText>
<figure confidence="0.722973521739131">
(2)
Stems
t1
t2
t3
tn
...
Signatures
σm
σ1
σ2
...
Affixes
f1
f2
f3
fk
...
POSs
π1
π2
π3
πl
...
∑∑
σ∈Σ f∈σ
c. log prob(Data  |g) =
⎡log ( ) log (  |)
prob σ + prob t σ ⎤
⎥
⎥
⎦⎥
+
⎢
∑log (  |, )
⎢ + prob f t σ
w Data
∈ = + ,
+ log prob(π |σ, f)
w t f
log
π∈ Π [f ∩ σ ∩ π
log
∑
[]
σ ∩ f
[ ]
σ
[ ]
∩ σ
f
+
log
[ ]
W +
[ ]
f
]
⎤
⎥
⎥
⎥
⎥⎦
+ ∑ ∑
log
f F set of affixes 0 i  |f  |freq f [ i ]
∈ = ≤ &lt;
1
probability to be
</figure>
<page confidence="0.994788">
23
</page>
<bodyText confidence="0.999751666666667">
transform, and the corresponding term in the
corpus compression expression (3c).
The model in (3) implicitly assumes that the
true POSs are known; in a more complete
model, the POSs play a direct role in assigning a
higher probability to the corpus (and hence a
smaller compressed size to the data). In the
context of such a model, an MDL-based learning
device searches for the best assignment of POS
tags over all possible assignments. Instead of
doing that in this paper, we employ the
TreeTagger (Schmid, 1994) based tags (see
section 5 below), and make the working
assumption that optimization of description
length over all signature-analyses and POS tags
can be approximated by optimization over all
signature-analyses, given the POS tags provided
by TreeTagger.
</bodyText>
<sectionHeader confidence="0.976275" genericHeader="method">
4 The collapsing of signatures
</sectionHeader>
<bodyText confidence="0.995225717948718">
We describe in this section our proposed
algorithm, using context vectors to collapse
signatures together, composed of a sequence of
operations, all but the first of which may be
familiar to the reader:
Replacement of words by signature-
transforms: The input to our algorithm for
collapsing signatures is a modified version of
the corpus which integrates the (unsupervised)
morphological analyses in the following way.
First of all, we leave unchanged the 200 most
frequent words (word types). Next, we replace
words belonging to the K most reliable
signatures (where K=50 in these experiments)
by their associated signature transforms, and we
in effect ignore all other words, by replacing
them by a distinguished “dummy” symbol. In
the following, we refer to our high frequency
words and signature transforms together as
elements—so an element is any member of the
transformed corpus other than the “dummy”.
Context vectors based on mutual
information: By reading through the corpus, we
populate both left and right context vectors for
each element (=signature-transform and high-
frequency word) by observing the elements that
occur adjacent to it. The feature indicating the
appearance of a particular word on the left is
always kept distinct from the feature indicating
the appearance of the same word on the right.
The features in a context vector are thus
associated with the members of the element
vocabulary (and indeed, each member of the
element vocabulary occurs as two features: one
on the left, one on the right). We assign the
value of each feature y of x’s context vector as
the pointwise mutual information of the
corresponding element pair (x, y), defined as
pr x y .
</bodyText>
<equation confidence="0.727558">
( , )
</equation>
<bodyText confidence="0.996728365853659">
Simplifying context vectors with “idf”: In
addition, because of the high dimensionality of
the context vector and the fact that some features
are more representative than others, we trim the
original context vector. For each context vector,
we sort features by their values, and then keep
the top N (in general, we set N to 10) by setting
these values to 1, and all others to 0. However,
in this resulting simplified context vector, not all
features do equally good jobs of distinguishing
syntactical categories. As Wicentowski (2002)
does in a similar context, we assign a weight
w fi to each feature fi in a fashion parallel to
inverse document frequency (idf; see Sparck
#total distinct elements .
log
# elements this feature appears in
We view these as the diagonal elements of a
matrix M (that is, mi,i = wfi ). We then check the
similarity between two simplified context
vectors by computing the weighted sum of the
dot product of them. That is, given two
simplified context vectors c and d, their
similarity is defined as cTMd. If this value is
larger than a threshold 0 that is set as one
parameter, we deem these two context vectors to
be similar. Then we determine the similarity
between elements by checking whether both left
and right simplified context vectors of them are
similar (i.e., their weighted dot products exceed
a threshold 0). In the experiments we describe
below, we explore four settings 0 for this
threshold: 0.8 (the most “liberal” in allowing
greater signature transform collapse, and hence
greater signature collapse), 1.0, 1.2, and 1.5.
Calculate signature similarity: To avoid
considering many unnecessary pairs of
signatures, we narrow the candidates into
signature pairs in which the suffixes of one
constitute a subset of suffixes of the other, and
we set a limit to the permissible difference in the
</bodyText>
<figure confidence="0.522634">
( )
y
pr(x)pr
log
Jones 1973), or
</figure>
<page confidence="0.996586">
24
</page>
<bodyText confidence="0.999939352941177">
lengths of the signatures in the collapsed pairs,
so that the difference in number of affixes
cannot exceed 2. For each such pair, if all
corresponding signature transforms are similar
in the sense defined in the preceding paragraph,
we deem the two signatures to be similar.
Signature graph: Finally, we construct a
signature graph, in which each signature is
represented as a vertex, and an edge is drawn
between two signatures iff they are similar, as
just defined. In this graph, we find a number of
cliques, each of which, we believe, indicates a
cluster of signatures which should be collapsed.
If a signature is a member of two or more
cliques, then it is assigned to the largest clique
(i.e., the one containing the largest number of
signatures).4
</bodyText>
<sectionHeader confidence="0.998964" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999317158730159">
We obtain the morphological analysis of the
Brown corpus (Kučera and Francis, 1967) using
the Linguistica software (http://linguistica.
uchicago.edu), and we use the TreeTagger to
assign a Penn TreeBank-style part-of-speech tag
to each token in the corpus. We then carry out
our experiment using the Brown corpus
modified in the way we described above. Thus,
for each token of the Brown corpus that our
morphology analyzer analyzed, we have the
following information: its stem, its signature
4 Our parameters are by design restrictive, so
that we declare only few signatures to be similar,
and therefore the cliques that we find in the
graph are relatively small. One way to enlarge
the size of collapsed signatures would be to
loosen the similarity criterion. This, however,
introduces too many new edges in the signatures
graph, leading in turn to spurious collapses of
signatures. We take a different approach, and
apply our algorithms iteratively. The idea is that
if in the first iteration, two cliques did not have
enough edges between their elements to become
a single new signature, they may be more
strongly connected in the second iteration if
many of their elements are sufficiently similar.
On the other hand, cliques that were dissimilar
in the first iteration remain weakly connected in
the second.
(i.e., the signature to which the stem is
assigned), the suffix which the stem attains in
this occurrence of the word (hence, the
signature-transform), and the POS tag. For
example, the token polymeric is analyzed into
the stem polymer and the suffix ic, the stem is
assigned to the signature Ø.ic.s, and thus this
particular token has the signature transform
Ø.ic.s_ic. Furthermore, it was assigned POS-tag
JJ, so that we have the following entry:
“polymeric JJ Ø.ic.s_ic”.
Before performing signature collapsing, we
calculate the description length of the
morphology and the compressed length of the
words that our algorithm analyzes and call it
baseline description length (DL0).
Now we apply our signature collapsing
algorithm under several different parameter
settings for the similarity threshold θ, and
calculate the description length DLθ of the
resulting morphological and lexical analysis
using (3). We know that the smaller the set of
signatures, the smaller is the cost of the model.
However, a signature collapse that combines
signatures with different distributions over the
lexical categories will result in a high cost of the
data term (3c). The goal was therefore to find a
method of collapsing signatures such that the
reduction in the model cost will be higher than
the increase in the compressed length of the data
so that the total cost will decrease.
As noted above, we perform this operation
iteratively, and refer to the description length of
the ith iteration, using a threshold θ, as θ
</bodyText>
<sectionHeader confidence="0.824238" genericHeader="method">
DL iter=i .
</sectionHeader>
<bodyText confidence="0.980185916666667">
We used random collapsing in our
experiments to ensure the expected relationship
between appropriate collapses and description
length. For each signature collapsing, we created
a parallel situation in which the number of
signatures collapsed is the same, but their choice
is random. We calculate the description length
θ
using this “random” analysis as DLrandom . We
predict that this random collapsing will not
produce an improvement in the total description
length.
</bodyText>
<page confidence="0.997412">
25
</page>
<sectionHeader confidence="0.999408" genericHeader="conclusions">
6 Results and discussion
</sectionHeader>
<bodyText confidence="0.999847083333333">
Table 1 presents the description length, broken
into its component terms (see (3)), for the
baseline case and the alternative analyses
resulting from our algorithm. The table shows
the total description length of the model, as well
as the individual terms: the signature term
DL(6), the suffix term DL(F), the lexical
categories term, DL(P), total morphology,
DL(M), and the compressed length of the data,
DL(D). We present results for two iterations for
four threshold values (0=0.8,1.0,1.2,1.5) using
our collapsing algorithm.
</bodyText>
<equation confidence="0.319958">
0
</equation>
<bodyText confidence="0.814004333333333">
Table 2 presents DLrandom derived from the
random collapsing, in a fashion parallel to Table
1. We show the results for only one iteration of
random collapsing, since the first iteration
already shows a substantial increase in
description length.
</bodyText>
<figureCaption confidence="0.720907">
Figure 1 and Figure 2 present graphically the
total description length from Tables 1 and 2
respectively. The reader will see that all
Figure 1 Comparison of DL, 2 iterations and 4
threshold values
</figureCaption>
<bodyText confidence="0.999940636363636">
collapsing of signatures leads to a shortening of
the description length of the morphology per se,
and an increase in the compressed length of the
data. This is an inevitable formal consequence of
the MDL-style model used here. The empirical
question that we care about is whether the
combined description length increases or
decreases, and what we find is that when
collapsing the signatures in the way that we
propose to do, the combined description length
decreases, leading us to conclude that this is,
overall, a superior linguistic description of the
data. On the other hand, when signatures are
collapsed randomly, the combined description
length increases. This makes sense; randomly
decreasing the formal simplicity of the
grammatical description should not improve the
overall analysis. Only an increase in the formal
simplicity of a grammar that is grammatically
sensible should have this property. Since our
goal is to develop an algorithm that is
completely data-driven and can operate in an
</bodyText>
<figureCaption confidence="0.866823">
Figure 2 Comparison of DLs with random
collapse of signatures (see text)
</figureCaption>
<figure confidence="0.981545807692308">
366,000
365,500
365,000
364,500
364,000
363,500
363,000
362,500
0=0.8 0=1
DL0
Comparison of DL
DL1 DL2
0=1.2 0=1.5
DL
368,000
367,500
367,000
366,500
366,000
365,500
365,000
364,500
364,000
0=0.8 0=1 0=1.2 0=1.5
Comparison of randomly collapsing DL
DLA Drandom
</figure>
<table confidence="0.6252405">
DL0 8=0.8 0=0.8 0=1.0 0=1.0 0=1.2 0=1.2 0=1.5 0=1.5
DLiter=1 DLiter=2 DLiter=1 DLiter=2 DLiter=1 DLiter=2 DLiter=1 DLiter=2
#6 50 41 35 41 34 44 42 46 45
DL(6) 47,630 45,343 42,939 45,242 43,046 44,897 44,355 46,172 45,780
DL(F) 160 156 156 153 143 158 147 163 164
DL(P) 2,246 2,087 1,968 2,084 1,934 2,158 2,094 2,209 2,182
DL(M) 50,218 47,768 45,244 47,659 45,304 47,395 46,777 48,724 48,306
DL(D) 315,165 316,562 318,687 316,615 318,172 316,971 317,323 315,910 316,251
Total 365,383 364,330 363,931 364,275 363,476 364,367 364,101 364,635 364,558
DL
</table>
<tableCaption confidence="0.9634135">
Table 1. DL and its individual components for baseline and the resulting cases when collapsing
signatures using our algorithm.
</tableCaption>
<page confidence="0.942675">
26
</page>
<table confidence="0.99938">
DL0 θ=0. 8 θ=1 .0 θ=1 .2 θ=1 .5
DLrandom DLrandom DLrandom DLrandom
#6 50 41 41 44 46
DL(6) 47,630 44,892 45,126 45,788 46,780
DL(F) 160 201 198 187 177
DL(P) 2,246 2,193 2,195 2,212 2,223
DL(M) 50,218 47,468 47,700 48,369 49,362
DL(D) 315,165 320,200 319,551 318,537 316,874
Total DL 365,383 367,669 367,252 366,907 366,237
</table>
<tableCaption confidence="0.994407">
Table 2. DL and its individual components for baseline and the
resulting cases when collapsing signatures randomly.
</tableCaption>
<bodyText confidence="0.998681387096774">
unsupervised fashion, we take this evidence as
supporting the appropriateness of our algorithm as
a means of collapsing signatures in a
grammatically and empirically reasonable way.
We conclude that the collapsing of signatures
on the basis of similarity of context vectors of
signature transforms (in a space consisting of high
frequency words and signature transforms)
provides us with a useful and significant step
towards solving the signature collapsing problem.
In the context of the broader project, we will be
able to use signature transforms as a more effective
means for projecting lexical categories in an
unsupervised way.
As Table 1 shows, we achieve up to 30%
decrease in the number of signatures through our
proposed collapse. We are currently exploring
ways to increase this value through powers of the
adjacency matrix of the signature graph.
In other work in progress, we explore the
equally important signature purity problem in
graph theoretic terms: we split ambiguous
signature transforms into separate categories when
we can determine that the edges connecting left-
context features and right-context features can be
resolved into two sets (corresponding to the
distinct categories of the transform) whose left-
features have no (or little) overlap and whose right
features have no (or little) overlap. We employ the
notion of minimum cut of a weighted graph to
detect this situation.
</bodyText>
<sectionHeader confidence="0.998775" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999732">
Brown, Peter F., Vincent J. Della Pietra, Peter V.
deSouza, Jennifer C. Lai, and Robert L. Mercer.
1992. Class-based n-gram models of natural
language. Computational Linguistics, 18(4): 467-
479.
Goldsmith, John. 2001. Unsupervised learning of the
morphology of a natural language. Computational
Linguistics, 27(2): 153-198.
Higgins, Derrick. 2002. A Multi-modular Approach to
Model Selection in Statistical NLP. University of
Chicago Ph.D. thesis.
Schmid, Helmut. 1994. Probabilistic part-of-speech
tagging using decision trees.. International
Conference on New Methods in Language
Processing
Kucera, Henry and W. Nelson Francis. 1967.
Computational Analysis of Present-day American
English. Brown University Press.
Rissanen, Jorma. 1989. Stochastic Complexity in
Statistical Inquiry. Singapore: World Scientific.
Schütze, Hinrich. 1997. Ambiguity Resolution in
Language Learning. CSLI Publications. Stanford
CA.
Sparck Jones, Karen. 1973. Index term weighting.
Information Storage and Retrieval 9:619-33.
Wicentowski, Richard. 2002. Modeling and Learning
Multilingual Inflectional Morphology in a Minimally
Supervised Framework. Johns Hopkins University
Ph.D. thesis.
</reference>
<page confidence="0.998806">
27
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.368572">
<title confidence="0.9996215">Using Morphology and Syntax in Unsupervised Learning</title>
<author confidence="0.982119">Hu</author>
<affiliation confidence="0.993913333333333">Department Computer The University of</affiliation>
<address confidence="0.887736">Chicago IL 60637</address>
<email confidence="0.997819">@uchicago.edu</email>
<author confidence="0.624392">John</author>
<affiliation confidence="0.986882666666667">Departments of Linguistics Computer The University of</affiliation>
<address confidence="0.88245">Chicago IL 60637</address>
<email confidence="0.999015">@uchicago.edu</email>
<author confidence="0.904269">Colin</author>
<affiliation confidence="0.9955625">Department of The University of</affiliation>
<address confidence="0.887141">Chicago IL 60637</address>
<email confidence="0.998892">@uchicago.edu</email>
<abstract confidence="0.99910288">Unsupervised learning of grammar is a problem that can be important in many areas ranging from text preprocessing for information retrieval and classification to machine translation. We describe an MDL based grammar of a language that contains morphology and lexical categories. We use an unsupervised learner of morphology to bootstrap the acquisition of lexical categories and use these two learning processes iteratively to help and constrain each other. To be able to do so, we need to make our existing morphological analysis less fine grained. We present an algorithm for collapsing morphological classes (signatures) by using syntactic context. Our experiments demonstrate that this collapse preserves the relation between morphology and lexical categories within new signatures, and thereby minimizes the description length of the model.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Vincent J Della Pietra</author>
<author>Peter V deSouza</author>
<author>Jennifer C Lai</author>
<author>Robert L Mercer</author>
</authors>
<title>Class-based n-gram models of natural language.</title>
<date>1992</date>
<journal>Computational Linguistics,</journal>
<volume>18</volume>
<issue>4</issue>
<pages>467--479</pages>
<contexts>
<context position="5566" citStr="Brown et al 1992" startWordPosition="852" endWordPosition="855">gnature transforms to learn syntactic categories, we developed an algorithm that uses the syntactic contextual information. We evaluate the changes to the morphological analysis from the standpoint of efficient and adequate representation of lexical categories. This paper presents a test conducted on English, and thus can only be considered a preliminary step in the 1 See Higgins 2002 for a study similar in some ways; Higgins uses morphology as a bootstrap heuristic in one experimental set-up. This paper is heavily indebted to prior work on unsupervised learning of position categories such as Brown et al 1992, Schütze 1997, Higgins 2002, and others cited there. eventually development of a languageindependent tool for grammar induction based on morphology. Nonetheless, the concepts that motivate the process are language-independent, and we are optimistic that similar results would be found in tests based on texts from other languages. In section 2 we discuss the notion of signature and signature transform, and section 3 present a more explicit formulation of the general problem. In section 4 we present our algorithm for signature collapse. Section 5 describes the experiments we ran to test the sign</context>
</contexts>
<marker>Brown, Pietra, deSouza, Lai, Mercer, 1992</marker>
<rawString>Brown, Peter F., Vincent J. Della Pietra, Peter V. deSouza, Jennifer C. Lai, and Robert L. Mercer. 1992. Class-based n-gram models of natural language. Computational Linguistics, 18(4): 467-479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Goldsmith</author>
</authors>
<title>Unsupervised learning of the morphology of a natural language.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>2</issue>
<pages>153--198</pages>
<contexts>
<context position="6372" citStr="Goldsmith, 2001" startWordPosition="974" endWordPosition="975">the process are language-independent, and we are optimistic that similar results would be found in tests based on texts from other languages. In section 2 we discuss the notion of signature and signature transform, and section 3 present a more explicit formulation of the general problem. In section 4 we present our algorithm for signature collapse. Section 5 describes the experiments we ran to test the signature collapsing algorithm, and section 6 presents and discusses our results. 2 Signatures and signature transforms We employ the unsupervised learning of morphology developed by Goldsmith (Goldsmith, 2001). Regrettably, some of the discussion below depends rather heavily on material presented there, but we attempt to summarize the major points here. Two critical terms that we employ in this analysis are signature and signature transform. A signature found in a given corpus is a pair of lists: a stem-list and a suffix-list (or in the appropriate context, a prefix-list). By definition of signature 6, the concatenation of every stem in the stem-list of 6 with every suffix in the suffix-list of 6 is found in the corpus, and a morphological analysis of a corpus can be viewed as a set of signatures t</context>
<context position="10583" citStr="Goldsmith (2001)" startWordPosition="1665" endWordPosition="1666">ty concern.2 Since we ultimately want to use signatures and signature transforms to learn syntactic categories, we base the similarity measure between the signatures on the context. 3 A more abstract statement of the problem A minimum description length (MDL) analysis is especially appropriate for machine learning of linguistic analysis because simultaneously it puts a premium both on analytical simplicity and on goodness of fit between the model and the data (Rissanen 1989). We will present first the mathematical statement of the MDL model of the morphology, in (1), following the analysis in Goldsmith (2001), followed by a description of the meaning of the terms of the expressions, and then present the modified version which includes additional terms regarding part of speech (POS) information, in (2) and (3). (1) Morphology a. Grammar g = b. Length(g) = ⎡ [ ] W 1 ∑ ⎢ log σ + ∑ log t T set ofstems ∈ = ⎣ [ ( )] t 0≤&lt; i|t |freq t[i] ⎡ [ ] ⎤ σ [W] ⎥⎦ + ∑ f∑⎣log [σ ∩ f] +log [f] σ∈Σ∈σ 2 The signature-collapsing problem has another side to it as well. An initial morphological analysis of English will typically give rise to a morphological analysis of words such as move, moves, moved, moving with a sign</context>
</contexts>
<marker>Goldsmith, 2001</marker>
<rawString>Goldsmith, John. 2001. Unsupervised learning of the morphology of a natural language. Computational Linguistics, 27(2): 153-198.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Derrick Higgins</author>
</authors>
<title>A Multi-modular Approach to Model Selection in Statistical NLP.</title>
<date>2002</date>
<institution>University of Chicago</institution>
<note>Ph.D. thesis.</note>
<contexts>
<context position="5337" citStr="Higgins 2002" startWordPosition="816" endWordPosition="817">tical understanding of human language acquisition. We present in this paper an algorithm that modifies the output of the morphology analyzer by combining redundant signatures. Since we ultimately want to use signatures and signature transforms to learn syntactic categories, we developed an algorithm that uses the syntactic contextual information. We evaluate the changes to the morphological analysis from the standpoint of efficient and adequate representation of lexical categories. This paper presents a test conducted on English, and thus can only be considered a preliminary step in the 1 See Higgins 2002 for a study similar in some ways; Higgins uses morphology as a bootstrap heuristic in one experimental set-up. This paper is heavily indebted to prior work on unsupervised learning of position categories such as Brown et al 1992, Schütze 1997, Higgins 2002, and others cited there. eventually development of a languageindependent tool for grammar induction based on morphology. Nonetheless, the concepts that motivate the process are language-independent, and we are optimistic that similar results would be found in tests based on texts from other languages. In section 2 we discuss the notion of s</context>
</contexts>
<marker>Higgins, 2002</marker>
<rawString>Higgins, Derrick. 2002. A Multi-modular Approach to Model Selection in Statistical NLP. University of Chicago Ph.D. thesis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees..</title>
<date>1994</date>
<booktitle>International Conference on New Methods in Language Processing</booktitle>
<contexts>
<context position="2792" citStr="Schmid 1994" startWordPosition="427" endWordPosition="428">’s stem appears with elsewhere, i.e., its signature. As we will see below, this conjunction of “better” information is what we call the signature transform, and in this paper, we explore how knowledge of signature transform can be merged with knowledge of the context vector to draw conclusions about morphology and syntax. In the distant future, we would like to be able to use the signature transform in a general process of grammar induction, but that day is not here; we therefore test our experiments by seeing how well we are able to predict POS as assigned by an available tagger (TreeTagger; Schmid 1994). In particular, we wish to decrease the uncertainty of a word’s POS through the morphological analysis described here. This decrease of uncertainty will enter into our calculation through an increase in the probability assigned to our test corpus once the corpus has been augmented with TreeTagger assigned POS tags. But to be clear on our 20 Proceedings of the Second Workshop on Psychocomputational Models of Human Language Acquisition, pages 20–27, Ann Arbor, June 2005. c�2005 Association for Computational Linguistics process: we analyze a completely raw text morphologically, and use the POS t</context>
<context position="15261" citStr="Schmid, 1994" startWordPosition="2613" endWordPosition="2614">[ ] f ] ⎤ ⎥ ⎥ ⎥ ⎥⎦ + ∑ ∑ log f F set of affixes 0 i |f |freq f [ i ] ∈ = ≤ &lt; 1 probability to be 23 transform, and the corresponding term in the corpus compression expression (3c). The model in (3) implicitly assumes that the true POSs are known; in a more complete model, the POSs play a direct role in assigning a higher probability to the corpus (and hence a smaller compressed size to the data). In the context of such a model, an MDL-based learning device searches for the best assignment of POS tags over all possible assignments. Instead of doing that in this paper, we employ the TreeTagger (Schmid, 1994) based tags (see section 5 below), and make the working assumption that optimization of description length over all signature-analyses and POS tags can be approximated by optimization over all signature-analyses, given the POS tags provided by TreeTagger. 4 The collapsing of signatures We describe in this section our proposed algorithm, using context vectors to collapse signatures together, composed of a sequence of operations, all but the first of which may be familiar to the reader: Replacement of words by signaturetransforms: The input to our algorithm for collapsing signatures is a modifie</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Schmid, Helmut. 1994. Probabilistic part-of-speech tagging using decision trees.. International Conference on New Methods in Language Processing</rawString>
</citation>
<citation valid="true">
<authors>
<author>Henry Kucera</author>
<author>W Nelson Francis</author>
</authors>
<title>Computational Analysis of Present-day American English.</title>
<date>1967</date>
<publisher>Brown University Press.</publisher>
<marker>Kucera, Francis, 1967</marker>
<rawString>Kucera, Henry and W. Nelson Francis. 1967. Computational Analysis of Present-day American English. Brown University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jorma Rissanen</author>
</authors>
<date>1989</date>
<booktitle>Stochastic Complexity in Statistical Inquiry. Singapore: World Scientific.</booktitle>
<contexts>
<context position="1539" citStr="Rissanen, 1989" startWordPosition="217" endWordPosition="218">do so, we need to make our existing morphological analysis less fine grained. We present an algorithm for collapsing morphological classes (signatures) by using syntactic context. Our experiments demonstrate that this collapse preserves the relation between morphology and lexical categories within new signatures, and thereby minimizes the description length of the model. 1 Introduction Our long term goal is the development of methods which will allow one to produce optimal analyses from arbitrary natural language corpora, where by optimization we understand an MDL (minimum description length; Rissanen, 1989) interpretation of the term: an optimal analysis is one which finds a grammar which simultaneously minimizes grammar length and data compression length. Our specific and primary focus is on morphology, and on how knowledge of morphology can be a useful step towards a more complete knowledge of a language’s linguistic structure. Our strategy is based on the following observation: knowing the rightmost suffix of a word is very useful information in inferring (or guessing) a word’s part of speech (POS), but due to the ambiguity of many suffixes, it is even better to know both a word’s suffix and </context>
<context position="10446" citStr="Rissanen 1989" startWordPosition="1643" endWordPosition="1644">of the corpus, one that can be better used in the problem of lexical category induction. This is the reflex of the familiar data sparsity concern.2 Since we ultimately want to use signatures and signature transforms to learn syntactic categories, we base the similarity measure between the signatures on the context. 3 A more abstract statement of the problem A minimum description length (MDL) analysis is especially appropriate for machine learning of linguistic analysis because simultaneously it puts a premium both on analytical simplicity and on goodness of fit between the model and the data (Rissanen 1989). We will present first the mathematical statement of the MDL model of the morphology, in (1), following the analysis in Goldsmith (2001), followed by a description of the meaning of the terms of the expressions, and then present the modified version which includes additional terms regarding part of speech (POS) information, in (2) and (3). (1) Morphology a. Grammar g = b. Length(g) = ⎡ [ ] W 1 ∑ ⎢ log σ + ∑ log t T set ofstems ∈ = ⎣ [ ( )] t 0≤&lt; i|t |freq t[i] ⎡ [ ] ⎤ σ [W] ⎥⎦ + ∑ f∑⎣log [σ ∩ f] +log [f] σ∈Σ∈σ 2 The signature-collapsing problem has another side to it as well. An initial morph</context>
</contexts>
<marker>Rissanen, 1989</marker>
<rawString>Rissanen, Jorma. 1989. Stochastic Complexity in Statistical Inquiry. Singapore: World Scientific.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Schütze</author>
</authors>
<title>Ambiguity Resolution in Language Learning.</title>
<date>1997</date>
<publisher>CSLI Publications.</publisher>
<location>Stanford CA.</location>
<contexts>
<context position="5580" citStr="Schütze 1997" startWordPosition="856" endWordPosition="857"> to learn syntactic categories, we developed an algorithm that uses the syntactic contextual information. We evaluate the changes to the morphological analysis from the standpoint of efficient and adequate representation of lexical categories. This paper presents a test conducted on English, and thus can only be considered a preliminary step in the 1 See Higgins 2002 for a study similar in some ways; Higgins uses morphology as a bootstrap heuristic in one experimental set-up. This paper is heavily indebted to prior work on unsupervised learning of position categories such as Brown et al 1992, Schütze 1997, Higgins 2002, and others cited there. eventually development of a languageindependent tool for grammar induction based on morphology. Nonetheless, the concepts that motivate the process are language-independent, and we are optimistic that similar results would be found in tests based on texts from other languages. In section 2 we discuss the notion of signature and signature transform, and section 3 present a more explicit formulation of the general problem. In section 4 we present our algorithm for signature collapse. Section 5 describes the experiments we ran to test the signature collapsi</context>
</contexts>
<marker>Schütze, 1997</marker>
<rawString>Schütze, Hinrich. 1997. Ambiguity Resolution in Language Learning. CSLI Publications. Stanford CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sparck Jones</author>
<author>Karen</author>
</authors>
<title>Index term weighting.</title>
<date>1973</date>
<journal>Information Storage and Retrieval</journal>
<pages>9--619</pages>
<marker>Jones, Karen, 1973</marker>
<rawString>Sparck Jones, Karen. 1973. Index term weighting. Information Storage and Retrieval 9:619-33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Wicentowski</author>
</authors>
<title>Modeling and Learning Multilingual Inflectional Morphology in a Minimally Supervised Framework. Johns Hopkins University Ph.D.</title>
<date>2002</date>
<tech>thesis.</tech>
<contexts>
<context position="17771" citStr="Wicentowski (2002)" startWordPosition="3020" endWordPosition="3021">ual information of the corresponding element pair (x, y), defined as pr x y . ( , ) Simplifying context vectors with “idf”: In addition, because of the high dimensionality of the context vector and the fact that some features are more representative than others, we trim the original context vector. For each context vector, we sort features by their values, and then keep the top N (in general, we set N to 10) by setting these values to 1, and all others to 0. However, in this resulting simplified context vector, not all features do equally good jobs of distinguishing syntactical categories. As Wicentowski (2002) does in a similar context, we assign a weight w fi to each feature fi in a fashion parallel to inverse document frequency (idf; see Sparck #total distinct elements . log # elements this feature appears in We view these as the diagonal elements of a matrix M (that is, mi,i = wfi ). We then check the similarity between two simplified context vectors by computing the weighted sum of the dot product of them. That is, given two simplified context vectors c and d, their similarity is defined as cTMd. If this value is larger than a threshold 0 that is set as one parameter, we deem these two context </context>
</contexts>
<marker>Wicentowski, 2002</marker>
<rawString>Wicentowski, Richard. 2002. Modeling and Learning Multilingual Inflectional Morphology in a Minimally Supervised Framework. Johns Hopkins University Ph.D. thesis.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>