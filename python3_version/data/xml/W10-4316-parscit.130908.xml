<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000040">
<title confidence="0.941758">
Utilizing Review Summarization in a Spoken Recommendation System
</title>
<author confidence="0.730889">
Jingjing Liu, Stephanie Seneff and Victor Zue
</author>
<affiliation confidence="0.337186">
MIT Computer Science &amp; Artificial Intelligence Laboratory
Cambridge, U.S.A.
</affiliation>
<email confidence="0.997915">
{jingl,seneff,zue}@csail.mit.edu
</email>
<sectionHeader confidence="0.997477" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.979299857142857">
In this paper we present a framework for spoken rec-
ommendation systems. To provide reliable recom-
mendations to users, we incorporate a review summa-
rization technique which extracts informative opinion
summaries from grass-roots users‘ reviews. The dia-
logue system then utilizes these review summaries to
support both quality-based opinion inquiry and fea-
ture-specific entity search. We propose a probabilistic
language generation approach to automatically creat-
ing recommendations in spoken natural language
from the text-based opinion summaries. A user study
in the restaurant domain shows that the proposed ap-
proaches can effectively generate reliable and helpful
recommendations in human-computer conversations.
</bodyText>
<sectionHeader confidence="0.999501" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.996500619047619">
Spoken dialogue systems are presently available
for many purposes, such as flight reservations
(Seneff and Polifroni, 2000), telephone calls
routing (Gorin et al., 1997), and subway lookup
(Johnston et al., 2002). Recently, we have been
exploring a next generation of intelligent dia-
logue systems, which can behave like a human
agent and provide proactive assistance and selec-
tive recommendations (e.g., highly-rated restau-
rants or hotels) to users.
To enhance dialogue systems with intelligent
services, we have to let the system &amp;quot;grow&amp;quot; relia-
ble knowledge and intelligence. Luckily, there
has recently been an explosive growth in the
availability of public review sites (e.g., yelp.com,
tripadvisor.com, etc.) which make a perfect re-
source for gathering collective opinions. In this
paper, we will explore how to utilize summaries
of public reviews to automatically generate rec-
ommendation-type conversations in spoken dia-
logue systems. An example of a conversation
</bodyText>
<figureCaption confidence="0.882282">
with our recommendation system is shown in
Figure 1.
</figureCaption>
<bodyText confidence="0.929595928571428">
U: Are there any American restaurants in Brighton?
S: There are 61 American restaurants in Brighton. All of
the rated restaurants have good or excellent ambiance.
Many are on Washington Street, Commonwealth Avenue
and Market Street.
U: Show me the ones that have nice ambiance.
S: I found 4 entries. Devlin&apos;s Restaurant and Bar is per-
fect for romantic date, Stockyard Restaurant has friendly
atmosphere, Tasca Tapas Restaurant has excellent ambi-
ance, and Wings Express has friendly vibes.
U: Which one has good martinis?
S: Devlin&apos;s Restaurant and Bar serves American food. It
has wonderful martinis, good wine, great fish. It is perfect
for romantic date. Great place.
</bodyText>
<figureCaption confidence="0.962315">
Figure 1. A real conversation with our recom-
mendation dialogue system in the restaurant do-
main (`U‘ is the user and `S‘ is the system).
</figureCaption>
<sectionHeader confidence="0.988255" genericHeader="method">
2 Dialogue Management
</sectionHeader>
<bodyText confidence="0.999917230769231">
In our previous work (Liu and Seneff, 2009; Liu
et al., 2010) we proposed an approach to extract-
ing representative phrases and creating aspect
ratings from public reviews. An example of an
enhanced database entry in the restaurant domain
is shown in Figure 2. Here, we use these &amp;quot;sum-
mary lists&amp;quot; (e.g., &amp;quot;:food&amp;quot;, &amp;quot;:atmosphere&amp;quot;) as well
as aspect ratings (e.g., &amp;quot;:food_rating&amp;quot;) to address
two types of recommendation inquires: &amp;quot;feature-
specific&amp;quot; (e.g., asking for a restaurant that serves
good martinis or authentic seafood spaghetti),
and &amp;quot;quality-based&amp;quot; (e.g., looking for restaurants
with good food quality or nice ambiance).
</bodyText>
<footnote confidence="0.365880777777778">
{q restaurant
:name &amp;quot;devlin‘s restaurant and bar&amp;quot;
:atmosphere (&amp;quot;romantic date&amp;quot; &amp;quot;elegant decor&amp;quot;)
:place (&amp;quot;great place&amp;quot;)
:food (&amp;quot;wonderful martinis&amp;quot; &amp;quot;good wine&amp;quot; &amp;quot;great fish&amp;quot;)
:atmosphere—rating &amp;quot;4.2&amp;quot;
:place—rating &amp;quot;4.2&amp;quot;
:food—rating &amp;quot;4.3&amp;quot;
:specialty (&amp;quot;martinis&amp;quot; &amp;quot;wine&amp;quot; &amp;quot;fish&amp;quot;) }
</footnote>
<figureCaption confidence="0.998677">
Figure 2. A database entry in our system.
</figureCaption>
<affiliation confidence="0.6695465">
Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 83–86,
The University of Tokyo, September 24-25, 2010. p@c 2010 Association for Computational Linguistics
</affiliation>
<page confidence="0.999424">
83
</page>
<subsectionHeader confidence="0.988383">
2.1 Feature-specific Entity Search
</subsectionHeader>
<bodyText confidence="0.990298277777778">
To allow the system to identify feature-related
topics in users‘ queries, we modify the context-
free grammar in our linguistic parser by includ-
ing feature-specific topics (e.g., nouns in the
summary lists) as a word class. When a feature-
specific query utterance is submitted by a user
(as exemplified in Figure 3), our linguistic parser
will generate a hierarchical structure for the ut-
terance, which encodes the syntactic and seman-
tic structure of the utterance and, especially,
identifies the feature-related topics. A feature-
specific key-value pair (e.g., &amp;quot;specialty: marti-
nis&amp;quot;) is then created from the hierarchical parsing
structure, with which the system can filter the
database and retrieve the entities that satisfy the
constraints.
&amp;quot;Are there any restaurants in Brighton that
have good martinis?&amp;quot;
</bodyText>
<equation confidence="0.902146">
&amp;quot;topic: restaurant, city: Brighton,
specialty: martinis&amp;quot;
:specialty = “martinis&amp;quot; :city = &amp;quot;Brighton&amp;quot;
:entity_type = &amp;quot;restaurant&amp;quot;
</equation>
<figureCaption confidence="0.996832">
Figure 3. Procedure of feature-specific search.
</figureCaption>
<subsectionHeader confidence="0.998126">
2.2 Quality-based Entity Search
</subsectionHeader>
<bodyText confidence="0.952279172413793">
For quality-based questions, however, similar
keyword search is problematic, as the quality of
entities has variants of expressions. The assess-
ment of different degrees of sentiment in various
expressional words is very subjective, which
makes the quality-based search a hard problem.
To identify the strength of sentiment in quali-
ty-based queries, a promising solution is to map
textual expressions to scalable numerical scores.
In previous work (Liu and Seneff, 2009), we
proposed a method for calculating a sentiment
score for each opinion-expressing adjective or
adverb (e.g., `bad‘: 1.5, `good‘: 3.5, `great‘: 4.0,
on a scale of 1 to 5). Here, we make use of these
sentiment scores and convert the original key-
value pair to numerical values (e.g., &amp;quot;great food&amp;quot;
 &amp;quot;food_rating: 4.0&amp;quot; as exemplified in Figure
4). In this way, the sentiment expressions can be
easily converted to scalable numerical key-value
pairs, which will be used for filtering the data-
base by &amp;quot;aspect ratings&amp;quot; of entities. As exempli-
fied in Figure 4, all the entities in the required
range of aspect rating (i.e., &amp;quot;:food_rating &gt;_ 4.0&amp;quot;)
can be retrieved (e.g., the entity in Figure 2 with
&amp;quot;food_rating = 4.3&amp;quot;).
&amp;quot;Show me some american restaurants with
great food&amp;quot;
&amp;quot;topic: restaurant, cuisine: american,
property: food, quality: great&amp;quot;
</bodyText>
<figure confidence="0.578716">
&amp;quot;topic: restaurant, cuisine: american,
food_rating: 4.0&amp;quot;
Database :food_rating &gt; “4.0” :cuisine = &amp;quot;american&amp;quot;
filters :entity_type = &amp;quot;restaurant&amp;quot;
</figure>
<figureCaption confidence="0.993078">
Figure 4. Procedure of qualitative entity search.
</figureCaption>
<sectionHeader confidence="0.947517" genericHeader="method">
3 Probabilistic Language Generation
</sectionHeader>
<bodyText confidence="0.999934756097561">
After corresponding entities are retrieved from
the database based on the user‘s query, the lan-
guage generation component will create recom-
mendations by expanding the summary lists of
the retrieved database entries into natural lan-
guage utterances.
Most spoken dialogue systems use predefined
templates to generate responses. However, man-
ually defining templates for each specific linguis-
tic pattern is tedious and non-scalable. For ex-
ample, given a restaurant with &amp;quot;nice jazz music,
best breakfast spot, great vibes&amp;quot;, three templates
have to be edited for three different topics (e.g.,
&amp;quot;&lt;restaurant&gt; plays &lt;adjective&gt; music&amp;quot;; &amp;quot;&lt;res-
taurant&gt; is &lt;adjective&gt; breakfast spot&amp;quot;; &amp;quot;&lt;restau-
rant&gt; has &lt;adjective&gt; vibes&amp;quot;). To avoid the hu-
man effort involved in the task, corpus-based
approaches (Oh and Rudnicky, 2000; Rambow et
al., 2001) have been developed for more efficient
language generation. In this paper, we propose a
corpus-based probabilistic approach which can
automatically learn the linguistic patterns (e.g.,
predicate-topic relationships) from a corpus and
generate natural sentences by probabilistically
selecting the best-matching pattern for each top-
ic.
The proposed approach consists of three stag-
es: 1) plant seed topics in the context-free gram-
mar; 2) identify semantic structures associated
with the seeds; 3) extract association pairs of lin-
guistic patterns and the seeds, and calculate the
probability of each association pair.
First, we extract all the nouns and noun
phrases that occur in the review summaries as the
seeds. As aforementioned, our context-free
grammar can parse each sentence into a hierar-
chical structure. We modify the grammar such
that, when parsing a sentence which contains one
of these seed topics, the parser can identify the
seed as an &amp;quot;active&amp;quot; topic (e.g., &amp;quot;vibes&amp;quot;, &amp;quot;jazz mu-
sic&amp;quot;, and &amp;quot;breakfast spot&amp;quot;).
</bodyText>
<figure confidence="0.9980972">
Utterance
Key-value
pairs
Database
filters
Utterance
Key-value
pairs
Converted
k-v pairs
</figure>
<page confidence="0.989973">
84
</page>
<bodyText confidence="0.999904136363636">
The second stage is to automatically identify
all the linguistic patterns associated with each
seed. To do so, we use a large corpus as the re-
source pool and parse each sentence in the cor-
pus for linguistic analysis. We modify our parser
such that, in a preprocessing step, the predicate
and clause structures that are semantically related
to the seeds will be assigned with identifiable
tags. For example, if the subject or the comple-
ment of the clause (or the object of the predicate)
is an &amp;quot;active&amp;quot; topic (i.e., a seed), an &amp;quot;active&amp;quot; tag
will be automatically assigned to the clause (or
the predicate). In this way, when examining syn-
tactic hierarchy of each sentence in the corpus,
the system can encode all the linguistic patterns
of clauses or predicate-topic relationships associ-
ated with the seeds with &amp;quot;active&amp;quot; tags.
Based on these tags, association pairs of &amp;quot;ac-
tive&amp;quot; linguistic patterns and &amp;quot;active&amp;quot; topics can
be extracted automatically. For each seed topic,
we calculate the probability of its co-occurrence
with each of its associated patterns by:
</bodyText>
<equation confidence="0.996143333333333">
count(pattern�, seedk)
prob(pattern |seedk) _ (1)
Zicount(patterni, seedk)
</equation>
<bodyText confidence="0.99960485">
where seedk is a seed topic, and patterni is
every linguistic pattern associated with seedk .
The probability of pattern for seedk is the
percentage of the co-occurrences of pattern
and seedk among all the occurrences of seedk
in the corpus. This is similar to a bigram lan-
guage model. A major difference is that the lin-
guistic pattern is not necessarily the word adja-
cent to the seed. It can be a long distance from
the seed with strong semantic dependencies, and
it can be a semantic chunk of multiple words.
The long distance semantic relationships are cap-
tured by our linguistic parser and its hierarchical
encoding structure; thus, it is more reliable than
pure co-occurrence statistics or bigrams. Figure 5
shows some probabilities learned from a review
corpus. For example, &amp;quot;is&amp;quot; has the highest proba-
bility (0.57) among all the predicates that co-
occur with &amp;quot;breakfast spot&amp;quot;; while &amp;quot;have&amp;quot; is the
best-match for &amp;quot;jazz music&amp;quot;.
</bodyText>
<figureCaption confidence="0.8758224">
Association pair Constituent Prob.
&amp;quot;at&amp;quot; : &amp;quot;breakfast spot&amp;quot; PP 0.07
&amp;quot;is&amp;quot; : &amp;quot;breakfast spot&amp;quot; Clause 0.57
&amp;quot;for&amp;quot; : &amp;quot;breakfast spot&amp;quot; PP 0.14
&amp;quot;love&amp;quot; : &amp;quot;jazz music&amp;quot; VP 0.08
&amp;quot;have&amp;quot; : &amp;quot;jazz music&amp;quot; VP 0.23
&amp;quot;enjoy&amp;quot;: &amp;quot;jazz music&amp;quot; VP 0.08
Figure 5. Partial table of probabilities of associa-
tion pairs (VP: verb phrase; PP: preposition
phrase).
</figureCaption>
<bodyText confidence="0.999987">
Given these probabilities, we can define pat-
tern selection algorithms (e.g., always select the
pattern with the highest probability for each top-
ic; or rotates among different patterns from high
to low probabilities), and generate response ut-
terances based on the selected patterns. The only
domain-dependent part of this approach is the
selection of the seeds. The other steps all depend
on generic linguistic structures and are domain-
independent. Thus, this probabilistic method can
be easily applied to generic domains for custom-
izing language generation.
</bodyText>
<sectionHeader confidence="0.999708" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999874410256411">
A web-based multimodal spoken dialogue sys-
tem, CityBrowser (Gruenstein and Seneff, 2007),
developed in our group, can provide users with
information about various landmarks such as the
address of a museum, or the opening hours of a
restaurant. To evaluate our proposed approaches,
we enhanced the system with a review-summary
database generated from a review corpus that we
harvested from a review publishing web site
(www.citysearch.com), which contains 137,569
reviews on 24,043 restaurants.
We utilize the platform of Amazon Mechani-
cal Turk (AMT) to conduct a series of user stud-
ies. To understand what types of queries the sys-
tem might potentially be handling, we first con-
ducted an AMT task by collecting restaurant in-
quiries from general users. Through this AMT
task, 250 sentences were collected and a set of
generic templates encoding the language patterns
of these sentences was carefully extracted. Then
10,000 sentences were automatically created
from these templates for language model training
for the speech recognizer.
To evaluate the quality of recommendations,
we presented the system to real users via custom-
ized AMT API (McGraw et al., 2010) and gave
each subject a set of assignments to fulfill. Each
assignment is a scenario of finding a particular
restaurant, as shown in Figure 6. The user can
talk to the system via a microphone and ask for
restaurant recommendations.
We also gave each user a questionnaire for a
subjective evaluation and asked them to rate the
system on different aspects. Through this AMT
task we collected 58 sessions containing 270 ut-
terances (4.6 utterances per session on average)
and 34 surveys. The length of the utterances var-
ies significantly, from &amp;quot;Thank you&amp;quot; to &amp;quot;Restau-
rants along Brattle Street in Cambridge with nice
</bodyText>
<page confidence="0.998669">
85
</page>
<bodyText confidence="0.4643115">
cocktails.&amp;quot; The average number of words per
utterance is 5.3.
</bodyText>
<figureCaption confidence="0.9317545">
Figure 6. Interface of our system in an AMT as-
signment.
</figureCaption>
<bodyText confidence="0.999969736842105">
Among all the 58 sessions, 51 were success-
fully fulfilled, i.e., in 87.9% of the cases the sys-
tem provided helpful recommendations upon the
user‘s request and the user was satisfied with the
recommendations. Among those seven failed
cases, one was due to loud background noise,
two were due to users‘ operation errors (e.g.,
clicking &amp;quot;DONE&amp;quot; before finishing the scenario),
and four were due to recognition performance.
The user ratings in the 34 questionnaires are
shown in Figure 7. On a scale of 0 (the center) to
5 (the edge), the average rating is 3.6 on the eas-
iness of the system, 4.4 on the helpfulness of the
recommendations, and 4.1 on the naturalness of
the system response. These numbers indicate that
the system is very helpful at providing recom-
mendation upon users‘ inquiries, and the re-
sponse from the system is present in a natural
way that people could easily understand.
</bodyText>
<figureCaption confidence="0.826369">
Figure 7. Users‘ ratings from the questionnaires.
</figureCaption>
<bodyText confidence="0.999904285714286">
The lower rating of ease of use is partially due
to recognition errors. For example, a user asked
for &amp;quot;pancakes&amp;quot;, and the system recommended
&amp;quot;pizza places&amp;quot; to him. In some audio clips rec-
orded, the background noise is relatively high.
This may be due to the fact that some AMT
workers work from home, where it can be noisy.
</bodyText>
<sectionHeader confidence="0.999415" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999703666666667">
In this paper we present a framework for incor-
porating review summarization into spoken rec-
ommendation systems. We proposed a set of en-
tity search methods as well as a probabilistic lan-
guage generation approach to automatically cre-
ate natural recommendations in human-computer
conversations from review summaries. A user
study in the restaurant domain shows that the
proposed approaches can make the dialogue sys-
tem provide reliable recommendations and can
help general users effectively.
Future work will focus on: 1) improving the
system based on users‘ feedback; and 2) apply-
ing the review-based approaches to dialogue sys-
tems in other domains.
</bodyText>
<sectionHeader confidence="0.998367" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.981147">
This research is supported by Quanta Computers,
Inc. through the T-Party project.
</bodyText>
<sectionHeader confidence="0.998893" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999625566666667">
Gorin, A., Riccardi, G., and Wright, J. H. 1997. How
May I Help You? Speech Communications. Vol.
23, pp. 113 – 127.
Gruenstein, A. and Seneff, S. 2007. Releasing a Mul-
timodal Dialogue System into the Wild: User Sup-
port Mechanisms. In Proc. the 8th SIGdial Work-
shop on Discourse and Dialogue, pp. 111—119.
Johnston, M., Bangalore, S., Vasireddy, G., Stent, A.,
Ehlen, P., Walker, M., Whittaker, S., Maloor, P.
2002. MATCH: An Architecture for Multimodal
Dialogue Systems. In Proc. ACL, pp. 376 – 383.
Liu, J. and Seneff, S. 2009. Review sentiment scoring
via a parse-and-paraphrase paradigm, In Proc.
EMNLP, Vol. 1.
Liu, J., Seneff, S. and Zue, V. 2010. Dialogue-
Oriented Review Summary Generation for Spoken
Dialogue Recommendation Systems. In Proc.
NAACL-HLT.
McGraw, I., Lee, C., Hetherington, L., Seneff, S.,
Glass, J. 2010. Collecting Voices from the Cloud.
In Proc. LREC.
Oh, A.H. and Rudnicky, A.I. 2000. Stochastic Lan-
guage Generation for Spoken Dialogue Systems. In
Proc. of ANLP-NAACL, pp. 27-32.
Rambow, O., Bangalore, S., Walker, M. 2001. Natu-
ral Language Generation in Dialog Systems. In
Proc. Human language technology research.
Seneff, S. and Polifroni, J. 2000. Dialogue Manage-
ment in the Mercury Flight Reservation System. In
Proc. Dialogue Workshop, ANLP-NAACL.
</reference>
<figure confidence="0.96334625">
27
26
28
25
29
24
30
23
32333
31
22
21
20
19
4
54
3
2
0
1
18
1
2 3
17
16
4
15
5
7
8
9
10
11
12
13
14
6
Ease of use
Helpfulness
Naturalness
</figure>
<page confidence="0.913427">
86
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.970156">
<title confidence="0.999859">Utilizing Review Summarization in a Spoken Recommendation System</title>
<author confidence="0.998483">Jingjing Liu</author>
<author confidence="0.998483">Stephanie Seneff</author>
<author confidence="0.998483">Victor Zue</author>
<affiliation confidence="0.99953">MIT Computer Science &amp; Artificial Intelligence</affiliation>
<address confidence="0.983388">Cambridge, U.S.A.</address>
<email confidence="0.999801">jingl@csail.mit.edu</email>
<email confidence="0.999801">seneff@csail.mit.edu</email>
<email confidence="0.999801">zue@csail.mit.edu</email>
<abstract confidence="0.999227933333333">In this paper we present a framework for spoken recommendation systems. To provide reliable recommendations to users, we incorporate a review summarization technique which extracts informative opinion from grass-roots The dialogue system then utilizes these review summaries to both inquiry and feasearch. We propose a probabilistic language generation approach to automatically creating recommendations in spoken natural language from the text-based opinion summaries. A user study in the restaurant domain shows that the proposed approaches can effectively generate reliable and helpful recommendations in human-computer conversations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Gorin</author>
<author>G Riccardi</author>
<author>J H Wright</author>
</authors>
<title>How May I Help You?</title>
<date>1997</date>
<journal>Speech Communications.</journal>
<volume>23</volume>
<pages>113--127</pages>
<contexts>
<context position="1128" citStr="Gorin et al., 1997" startWordPosition="147" endWordPosition="150">ese review summaries to support both quality-based opinion inquiry and feature-specific entity search. We propose a probabilistic language generation approach to automatically creating recommendations in spoken natural language from the text-based opinion summaries. A user study in the restaurant domain shows that the proposed approaches can effectively generate reliable and helpful recommendations in human-computer conversations. 1 Introduction Spoken dialogue systems are presently available for many purposes, such as flight reservations (Seneff and Polifroni, 2000), telephone calls routing (Gorin et al., 1997), and subway lookup (Johnston et al., 2002). Recently, we have been exploring a next generation of intelligent dialogue systems, which can behave like a human agent and provide proactive assistance and selective recommendations (e.g., highly-rated restaurants or hotels) to users. To enhance dialogue systems with intelligent services, we have to let the system &amp;quot;grow&amp;quot; reliable knowledge and intelligence. Luckily, there has recently been an explosive growth in the availability of public review sites (e.g., yelp.com, tripadvisor.com, etc.) which make a perfect resource for gathering collective opi</context>
</contexts>
<marker>Gorin, Riccardi, Wright, 1997</marker>
<rawString>Gorin, A., Riccardi, G., and Wright, J. H. 1997. How May I Help You? Speech Communications. Vol. 23, pp. 113 – 127.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Gruenstein</author>
<author>S Seneff</author>
</authors>
<title>Releasing a Multimodal Dialogue System into the Wild: User Support Mechanisms.</title>
<date>2007</date>
<booktitle>In Proc. the 8th SIGdial Workshop on Discourse and Dialogue,</booktitle>
<pages>111--119</pages>
<contexts>
<context position="11557" citStr="Gruenstein and Seneff, 2007" startWordPosition="1754" endWordPosition="1757">n define pattern selection algorithms (e.g., always select the pattern with the highest probability for each topic; or rotates among different patterns from high to low probabilities), and generate response utterances based on the selected patterns. The only domain-dependent part of this approach is the selection of the seeds. The other steps all depend on generic linguistic structures and are domainindependent. Thus, this probabilistic method can be easily applied to generic domains for customizing language generation. 4 Experiments A web-based multimodal spoken dialogue system, CityBrowser (Gruenstein and Seneff, 2007), developed in our group, can provide users with information about various landmarks such as the address of a museum, or the opening hours of a restaurant. To evaluate our proposed approaches, we enhanced the system with a review-summary database generated from a review corpus that we harvested from a review publishing web site (www.citysearch.com), which contains 137,569 reviews on 24,043 restaurants. We utilize the platform of Amazon Mechanical Turk (AMT) to conduct a series of user studies. To understand what types of queries the system might potentially be handling, we first conducted an A</context>
</contexts>
<marker>Gruenstein, Seneff, 2007</marker>
<rawString>Gruenstein, A. and Seneff, S. 2007. Releasing a Multimodal Dialogue System into the Wild: User Support Mechanisms. In Proc. the 8th SIGdial Workshop on Discourse and Dialogue, pp. 111—119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Johnston</author>
<author>S Bangalore</author>
<author>G Vasireddy</author>
<author>A Stent</author>
<author>P Ehlen</author>
<author>M Walker</author>
<author>S Whittaker</author>
<author>P Maloor</author>
</authors>
<title>MATCH: An Architecture for Multimodal Dialogue Systems.</title>
<date>2002</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>376--383</pages>
<contexts>
<context position="1171" citStr="Johnston et al., 2002" startWordPosition="154" endWordPosition="157">lity-based opinion inquiry and feature-specific entity search. We propose a probabilistic language generation approach to automatically creating recommendations in spoken natural language from the text-based opinion summaries. A user study in the restaurant domain shows that the proposed approaches can effectively generate reliable and helpful recommendations in human-computer conversations. 1 Introduction Spoken dialogue systems are presently available for many purposes, such as flight reservations (Seneff and Polifroni, 2000), telephone calls routing (Gorin et al., 1997), and subway lookup (Johnston et al., 2002). Recently, we have been exploring a next generation of intelligent dialogue systems, which can behave like a human agent and provide proactive assistance and selective recommendations (e.g., highly-rated restaurants or hotels) to users. To enhance dialogue systems with intelligent services, we have to let the system &amp;quot;grow&amp;quot; reliable knowledge and intelligence. Luckily, there has recently been an explosive growth in the availability of public review sites (e.g., yelp.com, tripadvisor.com, etc.) which make a perfect resource for gathering collective opinions. In this paper, we will explore how t</context>
</contexts>
<marker>Johnston, Bangalore, Vasireddy, Stent, Ehlen, Walker, Whittaker, Maloor, 2002</marker>
<rawString>Johnston, M., Bangalore, S., Vasireddy, G., Stent, A., Ehlen, P., Walker, M., Whittaker, S., Maloor, P. 2002. MATCH: An Architecture for Multimodal Dialogue Systems. In Proc. ACL, pp. 376 – 383.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Liu</author>
<author>S Seneff</author>
</authors>
<title>Review sentiment scoring via a parse-and-paraphrase paradigm,</title>
<date>2009</date>
<booktitle>In Proc. EMNLP,</booktitle>
<volume>1</volume>
<contexts>
<context position="2849" citStr="Liu and Seneff, 2009" startWordPosition="420" endWordPosition="423">es that have nice ambiance. S: I found 4 entries. Devlin&apos;s Restaurant and Bar is perfect for romantic date, Stockyard Restaurant has friendly atmosphere, Tasca Tapas Restaurant has excellent ambiance, and Wings Express has friendly vibes. U: Which one has good martinis? S: Devlin&apos;s Restaurant and Bar serves American food. It has wonderful martinis, good wine, great fish. It is perfect for romantic date. Great place. Figure 1. A real conversation with our recommendation dialogue system in the restaurant domain (`U‘ is the user and `S‘ is the system). 2 Dialogue Management In our previous work (Liu and Seneff, 2009; Liu et al., 2010) we proposed an approach to extracting representative phrases and creating aspect ratings from public reviews. An example of an enhanced database entry in the restaurant domain is shown in Figure 2. Here, we use these &amp;quot;summary lists&amp;quot; (e.g., &amp;quot;:food&amp;quot;, &amp;quot;:atmosphere&amp;quot;) as well as aspect ratings (e.g., &amp;quot;:food_rating&amp;quot;) to address two types of recommendation inquires: &amp;quot;featurespecific&amp;quot; (e.g., asking for a restaurant that serves good martinis or authentic seafood spaghetti), and &amp;quot;quality-based&amp;quot; (e.g., looking for restaurants with good food quality or nice ambiance). {q restaurant :na</context>
<context position="5493" citStr="Liu and Seneff, 2009" startWordPosition="805" endWordPosition="808"> :specialty = “martinis&amp;quot; :city = &amp;quot;Brighton&amp;quot; :entity_type = &amp;quot;restaurant&amp;quot; Figure 3. Procedure of feature-specific search. 2.2 Quality-based Entity Search For quality-based questions, however, similar keyword search is problematic, as the quality of entities has variants of expressions. The assessment of different degrees of sentiment in various expressional words is very subjective, which makes the quality-based search a hard problem. To identify the strength of sentiment in quality-based queries, a promising solution is to map textual expressions to scalable numerical scores. In previous work (Liu and Seneff, 2009), we proposed a method for calculating a sentiment score for each opinion-expressing adjective or adverb (e.g., `bad‘: 1.5, `good‘: 3.5, `great‘: 4.0, on a scale of 1 to 5). Here, we make use of these sentiment scores and convert the original keyvalue pair to numerical values (e.g., &amp;quot;great food&amp;quot;  &amp;quot;food_rating: 4.0&amp;quot; as exemplified in Figure 4). In this way, the sentiment expressions can be easily converted to scalable numerical key-value pairs, which will be used for filtering the database by &amp;quot;aspect ratings&amp;quot; of entities. As exemplified in Figure 4, all the entities in the required range of as</context>
</contexts>
<marker>Liu, Seneff, 2009</marker>
<rawString>Liu, J. and Seneff, S. 2009. Review sentiment scoring via a parse-and-paraphrase paradigm, In Proc. EMNLP, Vol. 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Liu</author>
<author>S Seneff</author>
<author>V Zue</author>
</authors>
<title>DialogueOriented Review Summary Generation for Spoken Dialogue Recommendation Systems.</title>
<date>2010</date>
<booktitle>In Proc. NAACL-HLT.</booktitle>
<contexts>
<context position="2868" citStr="Liu et al., 2010" startWordPosition="424" endWordPosition="427">ance. S: I found 4 entries. Devlin&apos;s Restaurant and Bar is perfect for romantic date, Stockyard Restaurant has friendly atmosphere, Tasca Tapas Restaurant has excellent ambiance, and Wings Express has friendly vibes. U: Which one has good martinis? S: Devlin&apos;s Restaurant and Bar serves American food. It has wonderful martinis, good wine, great fish. It is perfect for romantic date. Great place. Figure 1. A real conversation with our recommendation dialogue system in the restaurant domain (`U‘ is the user and `S‘ is the system). 2 Dialogue Management In our previous work (Liu and Seneff, 2009; Liu et al., 2010) we proposed an approach to extracting representative phrases and creating aspect ratings from public reviews. An example of an enhanced database entry in the restaurant domain is shown in Figure 2. Here, we use these &amp;quot;summary lists&amp;quot; (e.g., &amp;quot;:food&amp;quot;, &amp;quot;:atmosphere&amp;quot;) as well as aspect ratings (e.g., &amp;quot;:food_rating&amp;quot;) to address two types of recommendation inquires: &amp;quot;featurespecific&amp;quot; (e.g., asking for a restaurant that serves good martinis or authentic seafood spaghetti), and &amp;quot;quality-based&amp;quot; (e.g., looking for restaurants with good food quality or nice ambiance). {q restaurant :name &amp;quot;devlin‘s restau</context>
</contexts>
<marker>Liu, Seneff, Zue, 2010</marker>
<rawString>Liu, J., Seneff, S. and Zue, V. 2010. DialogueOriented Review Summary Generation for Spoken Dialogue Recommendation Systems. In Proc. NAACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I McGraw</author>
<author>C Lee</author>
<author>L Hetherington</author>
<author>S Seneff</author>
<author>J Glass</author>
</authors>
<title>Collecting Voices from the Cloud. In</title>
<date>2010</date>
<booktitle>Proc. LREC.</booktitle>
<contexts>
<context position="12629" citStr="McGraw et al., 2010" startWordPosition="1924" endWordPosition="1927">urk (AMT) to conduct a series of user studies. To understand what types of queries the system might potentially be handling, we first conducted an AMT task by collecting restaurant inquiries from general users. Through this AMT task, 250 sentences were collected and a set of generic templates encoding the language patterns of these sentences was carefully extracted. Then 10,000 sentences were automatically created from these templates for language model training for the speech recognizer. To evaluate the quality of recommendations, we presented the system to real users via customized AMT API (McGraw et al., 2010) and gave each subject a set of assignments to fulfill. Each assignment is a scenario of finding a particular restaurant, as shown in Figure 6. The user can talk to the system via a microphone and ask for restaurant recommendations. We also gave each user a questionnaire for a subjective evaluation and asked them to rate the system on different aspects. Through this AMT task we collected 58 sessions containing 270 utterances (4.6 utterances per session on average) and 34 surveys. The length of the utterances varies significantly, from &amp;quot;Thank you&amp;quot; to &amp;quot;Restaurants along Brattle Street in Cambrid</context>
</contexts>
<marker>McGraw, Lee, Hetherington, Seneff, Glass, 2010</marker>
<rawString>McGraw, I., Lee, C., Hetherington, L., Seneff, S., Glass, J. 2010. Collecting Voices from the Cloud. In Proc. LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A H Oh</author>
<author>A I Rudnicky</author>
</authors>
<title>Stochastic Language Generation for Spoken Dialogue Systems.</title>
<date>2000</date>
<booktitle>In Proc. of ANLP-NAACL,</booktitle>
<pages>27--32</pages>
<contexts>
<context position="7369" citStr="Oh and Rudnicky, 2000" startWordPosition="1088" endWordPosition="1091">he retrieved database entries into natural language utterances. Most spoken dialogue systems use predefined templates to generate responses. However, manually defining templates for each specific linguistic pattern is tedious and non-scalable. For example, given a restaurant with &amp;quot;nice jazz music, best breakfast spot, great vibes&amp;quot;, three templates have to be edited for three different topics (e.g., &amp;quot;&lt;restaurant&gt; plays &lt;adjective&gt; music&amp;quot;; &amp;quot;&lt;restaurant&gt; is &lt;adjective&gt; breakfast spot&amp;quot;; &amp;quot;&lt;restaurant&gt; has &lt;adjective&gt; vibes&amp;quot;). To avoid the human effort involved in the task, corpus-based approaches (Oh and Rudnicky, 2000; Rambow et al., 2001) have been developed for more efficient language generation. In this paper, we propose a corpus-based probabilistic approach which can automatically learn the linguistic patterns (e.g., predicate-topic relationships) from a corpus and generate natural sentences by probabilistically selecting the best-matching pattern for each topic. The proposed approach consists of three stages: 1) plant seed topics in the context-free grammar; 2) identify semantic structures associated with the seeds; 3) extract association pairs of linguistic patterns and the seeds, and calculate the p</context>
</contexts>
<marker>Oh, Rudnicky, 2000</marker>
<rawString>Oh, A.H. and Rudnicky, A.I. 2000. Stochastic Language Generation for Spoken Dialogue Systems. In Proc. of ANLP-NAACL, pp. 27-32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Rambow</author>
<author>S Bangalore</author>
<author>M Walker</author>
</authors>
<title>Natural Language Generation in Dialog Systems.</title>
<date>2001</date>
<booktitle>In Proc. Human language technology research.</booktitle>
<contexts>
<context position="7391" citStr="Rambow et al., 2001" startWordPosition="1092" endWordPosition="1095">ntries into natural language utterances. Most spoken dialogue systems use predefined templates to generate responses. However, manually defining templates for each specific linguistic pattern is tedious and non-scalable. For example, given a restaurant with &amp;quot;nice jazz music, best breakfast spot, great vibes&amp;quot;, three templates have to be edited for three different topics (e.g., &amp;quot;&lt;restaurant&gt; plays &lt;adjective&gt; music&amp;quot;; &amp;quot;&lt;restaurant&gt; is &lt;adjective&gt; breakfast spot&amp;quot;; &amp;quot;&lt;restaurant&gt; has &lt;adjective&gt; vibes&amp;quot;). To avoid the human effort involved in the task, corpus-based approaches (Oh and Rudnicky, 2000; Rambow et al., 2001) have been developed for more efficient language generation. In this paper, we propose a corpus-based probabilistic approach which can automatically learn the linguistic patterns (e.g., predicate-topic relationships) from a corpus and generate natural sentences by probabilistically selecting the best-matching pattern for each topic. The proposed approach consists of three stages: 1) plant seed topics in the context-free grammar; 2) identify semantic structures associated with the seeds; 3) extract association pairs of linguistic patterns and the seeds, and calculate the probability of each ass</context>
</contexts>
<marker>Rambow, Bangalore, Walker, 2001</marker>
<rawString>Rambow, O., Bangalore, S., Walker, M. 2001. Natural Language Generation in Dialog Systems. In Proc. Human language technology research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Seneff</author>
<author>J Polifroni</author>
</authors>
<title>Dialogue Management in the Mercury Flight Reservation System. In</title>
<date>2000</date>
<booktitle>Proc. Dialogue Workshop,</booktitle>
<location>ANLP-NAACL.</location>
<contexts>
<context position="1082" citStr="Seneff and Polifroni, 2000" startWordPosition="140" endWordPosition="143">s users‘ reviews. The dialogue system then utilizes these review summaries to support both quality-based opinion inquiry and feature-specific entity search. We propose a probabilistic language generation approach to automatically creating recommendations in spoken natural language from the text-based opinion summaries. A user study in the restaurant domain shows that the proposed approaches can effectively generate reliable and helpful recommendations in human-computer conversations. 1 Introduction Spoken dialogue systems are presently available for many purposes, such as flight reservations (Seneff and Polifroni, 2000), telephone calls routing (Gorin et al., 1997), and subway lookup (Johnston et al., 2002). Recently, we have been exploring a next generation of intelligent dialogue systems, which can behave like a human agent and provide proactive assistance and selective recommendations (e.g., highly-rated restaurants or hotels) to users. To enhance dialogue systems with intelligent services, we have to let the system &amp;quot;grow&amp;quot; reliable knowledge and intelligence. Luckily, there has recently been an explosive growth in the availability of public review sites (e.g., yelp.com, tripadvisor.com, etc.) which make a</context>
</contexts>
<marker>Seneff, Polifroni, 2000</marker>
<rawString>Seneff, S. and Polifroni, J. 2000. Dialogue Management in the Mercury Flight Reservation System. In Proc. Dialogue Workshop, ANLP-NAACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>