<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.982381">
The detection and representation
of ambiguities of intension and description
</title>
<author confidence="0.978139">
Brenda Fawcett and Graeme Hirst
</author>
<affiliation confidence="0.909900333333333">
Department of Computer Science
University of Toronto
Toronto, Ontario
</affiliation>
<address confidence="0.480893">
CANADA M5S 1A4
</address>
<sectionHeader confidence="0.989202" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999960473684211">
Ambiguities related to intension and their consequent
inference failures are a diverse group, both syntacti-
cally and semantically. One particular kind of ambi-
guity that has received little attention so far is
whether it is the speaker or the third party to whom
a description in an opaque third-party attitude
report should be attributed. The different readings
lead to different inferences in a system modeling the
beliefs of external agents.
We propose that a unified approach to the
representation of the alternative readings of
intension-related ambiguities can be based on the
notion of a descriptor that is evaluated with respect
to intensionality, the beliefs of agents, and a time of
application. We describe such a representation, built
on a standard modal logic, and show how it may be
used in conjunction with a knowledge base of back-
ground assumptions to license restricted substitution
of equals in opaque contexts.
</bodyText>
<sectionHeader confidence="0.998938" genericHeader="keywords">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999782666666667">
Certain problems of ambiguity and inference failure
in opaque contexts are well known, opaque contexts
being those in which an expression can denote its
intension or underlying concept rather than any par-
ticular extension or instance. For example, (1)
admits two readings:
</bodyText>
<listItem confidence="0.5498985">
(1) Nadia is advertising for a penguin with whom she
could have a long-term meaningful relationship.
</listItem>
<bodyText confidence="0.7549245">
On the transparent (or extensional or de re) reading,
there is some particular penguin that Nadia is after:
</bodyText>
<listItem confidence="0.7693205">
(2) Nadia is advertising for a penguin with whom she
could have a long-term meaningful relationship,
whom she met at a singles bar last week and fell
madly in love with, but lost the phone number of.
</listItem>
<bodyText confidence="0.8750445">
On the opaque (or intensional or de dicto) reading,
Nadia wants any entity that meets her criteria:
</bodyText>
<listItem confidence="0.722191333333333">
(3) Nadia is advertising for any penguin with whom
she could have a long-term meaningful relation-
ship.
</listItem>
<bodyText confidence="0.883476666666667">
On this reading, the rule of existential generalization
fails; that is, we cannot infer from (3), as we could
from (2), that:
</bodyText>
<listItem confidence="0.7896735">
(4) There exists a penguin with whom Nadia could
have a long-term meaningful relationship.
</listItem>
<bodyText confidence="0.919127">
Another rule of inference that fails in opaque con-
texts is substitution of equals; (5) and (6) do not per-
mit the conclusion (7):
</bodyText>
<listItem confidence="0.973573">
(5) Nadia believes that the number of penguins cam-
paigning for Greenpeace is twenty-two.
(6) The number of penguins campaigning for Green-
peace is forty-eight.
(7) Therefore, Nadia believes that forty-eight is
twenty-two.
</listItem>
<bodyText confidence="0.9996179">
Although these facts are familiar, little research
has been done on how a practical NLU system can
detect and resolve intensional ambiguities (which can
occur in many constructions besides the &apos;standard&apos;
examples; see Fodor 1980, Fawcett 1985), and con-
trol its inference accordingly. The same is true of
certain other complications of opaque contexts that
are of special relevance to systems that use explicit
representations of knowledge and belief. In particu-
lar, the interaction between intensional ambiguities
</bodyText>
<page confidence="0.996271">
192
</page>
<bodyText confidence="0.999459">
and the beliefs of agents has not been studied. The
present work is a first step towards rectifying this.
</bodyText>
<sectionHeader confidence="0.881714" genericHeader="introduction">
2. Attributing descriptions
</sectionHeader>
<bodyText confidence="0.9997576">
Previous linguistic systems that dealt with opaque
contexts, such as that of Montague (1973), have
taken a God&apos;s-eye view, in the sense that the speaker
and listener are assumed to have perfect knowledge,
as are, in certain ways, the people of whom they
speak. No account is taken of the limits of the
knowledge or beliefs of the agents involved.
To see that beliefs are a complicating factor, con-
sider the following sentence, usually considered to be
two ways ambiguous — transparent or opaque:
</bodyText>
<listItem confidence="0.689331">
(8) Nadia wants a dog like Ross&apos;s.
</listItem>
<bodyText confidence="0.997761">
These ambiguities, however, cross with an ambiguity
as to which agent the description a dog like Ross&apos;s is
to be attributed: to the speaker, or to Nadia (the
agent of the verb of the sentence). This gives a total
of four possible readings. To see the four cases, con-
sider the following situations, all of which can be
summarized by (8):
</bodyText>
<listItem confidence="0.772190333333333">
(9) Transparent reading, agent&apos;s description:
Nadia sees a dog in the pet store window. &amp;quot;I&apos;d
like that dog,&amp;quot; she says, &amp;quot;It&apos;s just like Ross&apos;s.&amp;quot;
The speaker of (8), who need not be familiar with
Ross&apos;s dog, reports this.
(10) Transparent reading, speaker&apos;s description:
</listItem>
<bodyText confidence="0.9983526">
Nadia sees an animal in the pet store window.
&amp;quot;I&apos;d like that,&amp;quot; she says. Nadia is not aware of
it, but the animal is a dog just like the one Ross
owns. The speaker of (8), however, knows Ross&apos;s
dog (and believes that the listener also does).
</bodyText>
<listItem confidence="0.768566">
(11) Opaque reading, agent&apos;s description:
Nadia feels that her life will be incomplete until
she obtains a dog. &amp;quot;And the dog that would be
perfect for me,&amp;quot; she says, &amp;quot;Is one just like the one
that Ross has.&amp;quot; The speaker of (8), not neces-
sarily familiar with Ross&apos;s dog, reports this
(12) Opaque reading, speaker&apos;s description:
</listItem>
<bodyText confidence="0.951322227272727">
Nadia feels that her life will be incomplete until
she obtains a pet. &amp;quot;And the pet that would be
perfect for me,&amp;quot; she says, &amp;quot;Is a big white shaggy
dog, with hair over its eyes.&amp;quot; Nadia is not aware
of it, but Ross owns a dog just like the one she
desires. The speaker of (8), however, knows
Ross&apos;s dog (and believes that the listener also
does).
The agent&apos;s-description readings permit the inference
that Nadia believes that she (either intensionally or
extensionally) wants a dog like Ross&apos;s; the other
readings do not. Making the distinction is thus cru-
cial for any system that reasons about the beliefs of
other agents, such systems being an area of much
current concern in artificial intelligence (e.g.,
Levesque 1983, Fagin and Halpern 1985).
Another complicating factor is the time at which
a description is to be applied. The above readings
assumed that this was the time of the utterance.
The intensional readings, however could be referring
to the dog that Ross will get or (not included in the
examples below) once had:
</bodyText>
<listItem confidence="0.987086">
(13) Opaque reading, agent&apos;s description, future appli-
cation:
</listItem>
<bodyText confidence="0.968365">
Nadia has heard that Ross will buy a dog. Want-
ing one herself, and trusting Ross&apos;s taste in can-
ines, she resolves to buy whatever kind he buys.
</bodyText>
<listItem confidence="0.9893955">
(14) Opaque reading, speaker&apos;s description, future
application:
</listItem>
<bodyText confidence="0.997510384615385">
Nadia finds English sheepdogs attractive, but
none are available. She therefore intends to pur-
chase some other suitably sized dog and spend
her weekend gluing long shaggy hair onto it.
Nadia is not aware of it, but Ross owns a dog
just like the one she wants to end up with. The
speaker, knowing Ross&apos;s dog, can describe Nadia&apos;s
desire as that of having an object that will at
some future time be describable as a dog like
Ross&apos;s.
The description in an intensional reading may also
be used to refer to different entities at different
times.
</bodyText>
<listItem confidence="0.9896835">
(15) Opaque reading, agent&apos;s description, repeated
application:
</listItem>
<bodyText confidence="0.989754111111111">
Ross buys a new type of dog every year or so.
Desperately wanting to keep up with canine
fashion, Nadia declares her intent to copy him.
Whatever dog Ross has at any given time, Nadia
wants to have the same kind.
We have not been able to find an example in which
repeated application of the speaker&apos;s description
gives a natural reading. Extensional readings always
seem to refer to the present time.2 Thus, there are at
</bodyText>
<footnote confidence="0.9924104">
21t may be objected that an extensional future-application reading
is also possible. This would be like (14), except that Nadia has
some particular dog in mind for the cosmetic alterations. If we al-
low Nadia to use this method repeatedly upon a particular dog,
then an extensional reading corresponding to (15) would be
</footnote>
<page confidence="0.996728">
193
</page>
<bodyText confidence="0.573113">
least seven readings for Nadia wants a dog like Nadia is dressed like.
</bodyText>
<equation confidence="0.613682">
Ross&apos;s.3 (22) It is possible that a creature from outer space
</equation>
<bodyText confidence="0.768836">
could interrupt your lecture at the most incon-
venient moment.
</bodyText>
<sectionHeader confidence="0.825387" genericHeader="method">
3. Other intensional ambiguities and
inference failures
</sectionHeader>
<bodyText confidence="0.999728666666666">
There are other kinds of intension-related inference
failures besides those mentioned in the previous sec-
tions. For example, some opaque contexts forbid
inferences from postmodifier deletion, while others
permit it. Both readings of (16) entail the less
specific (17) (which preserves the ambiguity of (16)):
</bodyText>
<listItem confidence="0.984804">
(16) Nadia is advertising for a penguin that she hasn&apos;t
already met.
(17) Nadia is advertising for a penguin.
However, the same cannot be done with (18):
(18) Nadia would hate for there to be a penguin that
she hasn&apos;t already met.
(19) 4)Nadia would hate for there to be a penguin.4
</listItem>
<bodyText confidence="0.992217">
The examples above have all involved explicit or
implicit propositional attitudes and such contexts are
apparently necessary for ambiguities of attribution of
description and the associated possible inference
failure and for problems of postmodifier deletion.
However, there are many other kinds of context in
which other intension-related ambiguities and infer-
ence failures can occur. For example, existential
generalization can also fail in contexts of similarity
and possibility:
</bodyText>
<listItem confidence="0.8994655">
(20) Nadia is dressed like a creature from outer space.
(21) There is a creature from outer space whom
</listItem>
<bodyText confidence="0.986771222222222">
derived. That is, Nadia wants her particular dog to once or re-
peatedly become like Ross&apos;s dog. However, we don&apos;t see these
readings as distinct from (14) and (15); Nadia&apos;s desire is clearly to-
wards the goal of having a dog that matches a particular descrip-
tion, rather than towards that of owning a particular dog.
3Hofstadter, Clossman, and Meredith (1982) analyze a similar sen-
tence for the case where the speaker and the agent are the same, /
want the fastest car in the world, and derive five readings where
we predict four. However, their two extensional readings are
identical in our analysis, as they differ only in how many separate
descriptions the agent has for the entity.
4This example is based on one of Fodor&apos;s (1980: 188). Fodor
claims that postmodifier deletion is never valid in an opaque con-
text; as example (17) shows, this claim is too strong. The problem
in (19) seems to be that would hate means wants not, and the dele-
tion is invalid in the scope of a negation.
(23) There is a creature from outer space who could
possibly interrupt your lecture at the most incon-
venient moment.
The kind of semantic irregularities that we are
discussing are thus found in a large and syntactically
diverse set of linguistic constructs. (See Fawcett
(1985) for a long list, with discussion and examples.)
Many seem to display idiosyncratic semantic features
that could necessitate a broad range of operators in a
representation, destroying any apparent homogeneity
of the class. It is our suggestion, however, that these
constructs can be processed in a uniform way. We
argue that the diversity among the constructs can be
accounted for by evaluating descriptors according to
intensionality, agents, time, and states of affairs.
Introducing the concept of a descriptor preserves the
homogeneity of the class, while the dimensions along
which descriptors may vary provide enough detail to
differentiate among the particular semantics of the
constructs.
</bodyText>
<sectionHeader confidence="0.797334" genericHeader="method">
4. The descriptor representation
</sectionHeader>
<bodyText confidence="0.9999843">
In this section we introduce a representation
designed to capture the different possible readings of
opaque constructions. In developing the representa-
tion, we have tried to move away from previous
approaches to intensionality, such as that of Mon-
tague (1973), which use truth conditions and mean-
ing postulates, and which take no account of the
beliefs or knowledge of agents. Influenced by recent
work on situation semantics (Barwise and Perry
1983, Lesperance 1986) and belief logics, we have
aimed for a more &apos;common-sense&apos; approach.
In the representation, we take an intension to be
a finite representation of those properties that
characterize membership in a class, and by a descrip-
tor we mean a non-empty subset of the elements of
an intension (in practice, often identical to the com-
plete intension). A descriptor provides access either
to the intension of which it is a part or to its exten-
sion. This eliminates the need of explicitly listing all
the known properties of an entity; only properties
</bodyText>
<page confidence="0.993976">
194
</page>
<bodyText confidence="0.983801541666667">
relevant to the discourse situation are mentioned.
The representation is described in detail in
Fawcett (1985); below we give a short description of
the main points, and some examples of its use.
The representation is based on conventional tem-
poral modal logic. The general form of a completed
sentential clause is a proposition of the form
(term-list) &lt;predication&gt;.
The term-list, which can be empty, contains all the
quantified terms except those which are opaque with
respect to agents or time; the predication expresses
the main relation among the various entities referred
to. The intention is that the term-list provides the
information to identify referents in the knowledge
base, and the main predication asserts new informa-
tion to be added to it. Usually the argument posi-
tions of the predication will be filled by bound vari-
ables or constants, introduced previously in the
term-list. However, within temporal operator or
agent scopes, argument positions may instead con-
tain quantified terms. Term-list-predicate pairs may
be nested inside of one another.
Quantified terms arise from noun phrases. They
have the general form
</bodyText>
<equation confidence="0.652506">
(Det X: R(X))
</equation>
<bodyText confidence="0.998044411764706">
where Det is a quantifier corresponding to the expli-
cit or implicit determiner of the noun phrase, X is
the variable introduced, and R(X) indicates restric-
tions on X. In the examples below, we restrict our-
selves to only three quantifiers — indef, def, and
label, introduced by indefinite descriptions, definite
descriptions, and proper nouns respectively.5
To this formalism, we add the following:
The agent scope marker ^.
This marker can apply to a formula or term to
indicate that any embedded descriptors must be
evaluated with respect to the beliefs of the agents
involved (that is, mentioned so far) at the point
where the scope of ^ begins. The speaker is
assumed to always be available as an agent, and
descriptors outside the scope of ^ are attributed
only to the speaker.
</bodyText>
<footnote confidence="0.88684975">
5For simplicity, we treat names as extensional in our examples.
However, there is nothing to prevent an opaque treatment, in
which the different agents are thinking of different individuals
with the same name.
</footnote>
<table confidence="0.357971">
• The intensional abstractor int-abs.
The formula
</table>
<bodyText confidence="0.981055333333333">
int-abs (C, (Quant Var : Description))
asserts that the quantified term Var is to have an
intensional referent (i.e., an individual or universal
concept), which is returned in C. If C is subse-
quently used, then its referent is a universal (gen-
eric) concept, which we do not discuss in this paper;
see Fawcett (1985) for details. If Var is used
instead, then the referent is an individual concept.
(Without int-abs, use of Var refers to an extension.)
</bodyText>
<listItem confidence="0.979533">
• Descriptors.
</listItem>
<bodyText confidence="0.998340566666667">
The notation [d X1 indicates that the properties d
are being used as a descriptor of entity X Thus its
intensionality, time of application, and agent must
be considered. (Variables over such descriptors are
permitted, so we can manipulate them indepen-
dently of the entities to which they might refer.)
Thus, opacity with respect to agents and opacity
with respect to time are both treated as scope ambi-
guities, while intensionality is marked as a binary
distinction. In general, all quantified terms are left-
extraposed to the outermost term list. Those
quantified terms marked as intensionally ambiguous
may be prefixed by int-abs. Those quantified terms
originating within the scope of the agent scope
marker ^ may remain inside its scope and be
evaluated relative to the agents available at that
point. Similarly, those quantified terms originating
in the scope of the temporal operators F and P
(future and past) may stay inside their scope, thus
indicating a future or past application of the descrip-
tor.
The following example shows the representations
of the first four readings of (8) (i.e., those with the
description applied at the time of the utterance), and
an extensional counterpart. (In the examples, the
quantifier indef corresponds to the English deter-
miner a, and the quantifier label is used for proper
nouns. The structure of the descriptor dog-like-
Ross&apos;s, orthogonal to our concerns here, is not
shown.)
</bodyText>
<listItem confidence="0.356774">
(24) Transparent reading, agent&apos;s description:
</listItem>
<bodyText confidence="0.709151">
There is a dog Nadia wants, and she describes it
as being like Ross&apos;s dog.
</bodyText>
<equation confidence="0.4890385">
(label Y: Nadia)
&lt;want Y, (indef X: [dog-like-ross&apos;s X])&gt;
</equation>
<page confidence="0.917125">
195
</page>
<figure confidence="0.3757184375">
(25) Transparent reading, speaker&apos;s description:
There is a dog Nadia wants, and the speaker
describes it as being like Ross&apos;s dog.
(label Y: Nadia)
(indef X: [dog-like-ross&apos;s XI)
&lt;want Y, &amp;quot;X&gt;
(26) Opaque reading, agent&apos;s description:
Nadia wants something she describes as being a
dog like Ross&apos;s.
(label Y: Nadia)
&lt;want Y,
int-abs (C, (indef X: [dog-like-ross&apos;s XID&gt;
(27) Opaque reading, speaker&apos;s description:
Nadia wants something that the speaker describes
as being a dog like Ross&apos;s.
(label Y: Nadia)
</figure>
<figureCaption confidence="0.4869865">
int-abs (C, (indef X: [dog-like-ross&apos;s X]))
&lt;wants Y, ^X&gt;
</figureCaption>
<bodyText confidence="0.99898425">
Note that the fourth reading has no representation in
a conventional first-order modal language. For com-
parison, here is a non-opaque sentence of the same
structure.
</bodyText>
<equation confidence="0.9838455">
(28) Nadia buys a dog like Ross&apos;s.
(label Y: Nadia)
(indef X: [dog-like-ross&apos;s
&lt;buy Y, X&gt;
</equation>
<bodyText confidence="0.999035714285714">
Within the scopes of the opaque operators F, P,
and ^, special checks must be made before standard
inference rules can apply.6 We do ne&apos;, assume that all
arguments are intensional; we favour a policy
towards intensional scopes of &amp;quot;introduce when
required&amp;quot; to minimize the amount of extra process-
ing needed. Our use of the symbol is quite
different from that of Montague. For Montague, &amp;quot;x
denotes an object that is intensional. We instead use
this notation to delimit the agent scope of an opaque
construct; descriptors in x are potentially ascribed to
any of the agents preceding the ^ marker.
Our approach to determiners is a compromise
between other common approaches. The first, com-
mon in computational linguistics, is to represent
determiners by three-place quantifiers of the general
°This is analogous to the restricted rules that Montague presents
for substitution of identicals and lambda conversion in his inten-
sional logic (Dowty, Wall, and Peters 1981: 165). We seek a more
flexible scheme that, rather than prohibiting inference, restricts its
use to certain special cases.
</bodyText>
<equation confidence="0.6930835">
form
det (x, R(x), P(x))
</equation>
<bodyText confidence="0.99883678125">
where x is the variable introduced, R is the restric-
tion on the variable, and P is the new predication on
the variable. This reflects observations of Moore
(1981) and others that determiners rarely have a
direct correlation with the existential and universal
quantifiers of first-order logic. In many of the mean-
ing representations used with logic grammars (Dahl
(1981), for example), determiners provide the basic
structure of the meaning representation formula.
The determiners are translated into quantifiers and
are all left-extraposed (to be later scoped relative to
one another on the basis of some reasonably simple
set of rules). As a result, the main predication of a
clause will always be nested in the rightmost predica-
tion position.
Another approach focuses more on the main verbs
by first translating them into predicates, and subse-
quently finding appropriate fillers for their arguments
that contain the necessary quantifiers. However, this
does not allow a convenient way to represent relative
scoping ambiguities. Montague combines the two
approaches. All quantifiers introduce two predicates:
a restriction predicate and a main predication as in
XR XP (Bx (R{x} AND P{x})),
which translates the determiner a.
Our approach is a compromise. Quantified terms
consist of a variable and restriction, but do not
incorporate the main predication. All quantified
terms (except those that are opaque with respect to
time or agent) are left-extraposed and assimilated
into a single list structure followed by a single main
predication.
</bodyText>
<sectionHeader confidence="0.533873" genericHeader="method">
5. Substitution of equals
</sectionHeader>
<bodyText confidence="0.999980625">
Given our descriptor logic, we can now turn to the
question of when substitution-of-equals inferences
can and can&apos;t be made.
The failure of substitution of equivalent phrases
appears to be a gradable notion; the degree of substi-
tution allowed varies with the type of construct
under consideration. We can think of a scale of sub-
stitutivity, with the lower bound being a strictly de
</bodyText>
<page confidence="0.998027">
196
</page>
<bodyText confidence="0.999352833333333">
dicto reading in which no substitutions are permitted
and the upper bound a strictly de re reading in
which co-extensional phrases can be substituted in
any context.
For example, sentences that refer directly to the
form of the expression admit no substitution:
</bodyText>
<listItem confidence="0.90387">
(29) The Big Bopper was so called because of his size
and occupation.
(30) The Big Bopper was J. P. Richardson.
(31) J. P. Richardson was so called because of his
size and occupation.
</listItem>
<bodyText confidence="0.998857285714286">
In sentences of propositional attitude, certain
descriptors can be substituted for, provided the con-
tent of the proposition, relative to the speaker and
the hearer, is not affected. It is easy to recognize
such cases, but not always easy to specify what exact
criteria determine terms that are interchangeable.
Consider:
</bodyText>
<listItem confidence="0.990798333333333">
(32) Nadia thinks that the Queen of England is a
lovely lady.
(33) Nadia thinks that Queen Elizabeth is a lovely
lady.
(34) Nadia thinks that the titular head of the Church
of England is a lovely lady.
</listItem>
<bodyText confidence="0.995365615384615">
The assumption is that since the filler of the role
Queen of England is not likely to change within the
time of the conversation and the speaker, the hearer,
and Nadia are all aware of who fills that role, it is
acceptable to substitute the filler for the role and
vice versa. Thus, sentence (33) can be inferred from
(32). But to substitute the phrase the titular head of
the Church of England, as in (34), seems to attribute
more knowledge to Nadia than was in the original
statement.
The problem of substitution in opaque contexts
stems from the failure to recognize how descriptors
relate, and not, as in classical logical approaches,
from the failure of expressions to be &amp;quot;co-
intensional&amp;quot;. The emphasis should be on identifying
the relation between descriptors with respect to
appropriate agents rather than on co-intensionality
alone; in most cases co-intensionality is too strong a
condition for substitution. Rather, the background
assumptions of the discourse determine whether a
substitution of one descriptor for another is
permitted.
A typical substitution replaces the target descrip-
tor, dl, with an equivalent descriptor, d2, from the
background assumptions, but otherwise preserves the
form of the target sentence, i.e.,
</bodyText>
<equation confidence="0.678459">
RESULT --= TARGET [d//c/21.7
</equation>
<bodyText confidence="0.999935416666667">
To see whether a descriptor substitution is valid in
an opaque context, three factors must be checked in
the following order: the intensionality of the descrip-
tor, the time of reference of the descriptor, and the
agents of the descriptor. We must establish the
&amp;quot;level&amp;quot; of each factor in the target sentence and
then determine whether the background assumptions
authorize substitutions at that level. That is, we
must relate the intensionality, time, and agent of the
descriptor equivalence asserted in the background
assumptions to those of the target descriptor, and
then assert the intensionality, time, and agent of the
descriptors in the resulting clause (after any substitu-
tions).
The background assumptions will have already
been derived from earlier input (in a manner
described by Fawcett 1985, section 5.5) and assimi-
lated into the system&apos;s general knowledge base. In
order to compare descriptors in the target to descrip-
tors in the background assumptions, we extract the
relevant aspects from the representation of each, and
express them explicitly by the use of the following
descriptor predicates, which can then be used to
query the knowledge base.
</bodyText>
<listItem confidence="0.8220782">
• desc (a, e, dl).
Ascribes a particular descriptor to an individual;
&amp;quot;agent a would use the descriptor dl to describe the
entity e&amp;quot;.
• label (a, c, name).
</listItem>
<bodyText confidence="0.953128">
Indicates that the label name is known by agent a
to be a label for the (individual) constant c.
</bodyText>
<listItem confidence="0.813724">
• time (t, e,
</listItem>
<bodyText confidence="0.998103">
Asserts that descriptor dl describes entity e at
time t.
As an example, consider the four readings of this
sentence in which the description is applied at the
time of utterance:
</bodyText>
<footnote confidence="0.9527165">
7Not all substitutions are of this form; see Fawcett 1985, section
5.4.
</footnote>
<page confidence="0.986918">
197
</page>
<figure confidence="0.83230075">
(35) Nadia wants the fastest car in the world.
(i) Extensional reading, speaker&apos;s description:
(label Y: Nadia)
(clef X: [few XI) &lt;want Y, ^X&gt;
(a) Intensional reading, speaker&apos;s description:
(label Y: Nadia)
int-abs (C, (def X: [fcw XI)) &lt;want Y, ^X&gt;
(iii) Extensional reading, agent&apos;s description:
</figure>
<reference confidence="0.6787088">
(label Y: Nadia)
&lt;want Y, ^ (clef X: [few X])&gt;
(iv) Intensional reading, agent&apos;s description:
(label Y: Nadia)
&lt;want Y, &apos;int-abs (C, (del X: [few X1D&gt;
</reference>
<bodyText confidence="0.932386571428571">
(fcw stands for the descriptor fastest-car-in-the-
world.)
Table I lists some different possible background
assumptions. We will show the different effects of
each. Background assumption I asserts the co-
extensionality of the descriptors fastest car in the
world and Ross&apos;s Jaguar 800, while assumption II
asserts co-intensionality of the descriptors. Assump-
tions III and IV express the same equivalences, and,
additionally, knowledge of them is also attributed to
Nadia.
When the beliefs of agents (other than the
listener) are not involved, the following rule licenses
certain substitutions of equivalents: •
</bodyText>
<listItem confidence="0.551924">
• If the target descriptor is intensional8 then co-
</listItem>
<bodyText confidence="0.9947096">
intensional or definitionally equivalent descriptors in
the background assumptions may be substituted.
Background assumptions I and II thus allow substitu-
tions in readings (1) and (ii), as shown in table H.
(For simplicity, the quantifier
</bodyText>
<equation confidence="0.354593">
(label Y: Nadia)
</equation>
<bodyText confidence="0.994666285714286">
is omitted from each example.)
When attribution of descriptions is involved, as in
readings (iii) and (iv) of (35), we must determine
whether the other agents are (believed by the listener
to be) aware of the equivalence. The general rule for
substituting descriptors which are ambiguous with
respect to descriptive content is this:
</bodyText>
<listItem confidence="0.619931">
• If the assertion of descriptor equivalence in the
background assumptions in the listener&apos;s knowledge
base is part of the knowledge base of the agent to
</listItem>
<footnote confidence="0.9142935">
8In this rule, the descriptor must not be generic. Rules for gener-
ics (universal concepts) are described in Fawcett 1985, section 5.4.
</footnote>
<table confidence="0.692140461538461">
TABLE I
BACKGROUND ASSUMPTIONS
The fastest car in the world is Ross&apos;s Jaguar 300.
II The fastest car in the world (always) is a Jaguar 300.
III Nadia believes that the fastest car in the world is
Ross&apos;s Jaguar 300.
IV Nadia believes that the fastest car in the world is
a Jaguar 300.
TABLE II
SUBSTITUTIONAL INFERENCES
Nadia wants Ross&apos;s Jaguar 300.
(clef X: [ross&apos;s-jag300 .X1) &lt;wants Y, ^X&gt;
Nadia wants a Jaguar 300.
(def X: [jag300 X]) &lt;wants Y, ^X&gt;
No substitution possible.
Nadia wants a Jaguar 300.
int-abs(C, (def X: [jag300 X]))
&lt;wants Y, ^X&gt;
Nadia wants Ross&apos;s Jaguar 300.
&lt;wants Y, ^ (clef X: [ross&apos;s-jag300 X])&gt;
Nadia wants a Jaguar 300.
&lt;wants Y, ^ (indef X: [jag300 XD&gt;
No substitution possible.
Nadia wants some Jaguar 300.
&lt;wants Y,
int-abs (C, (indef X: [jag300 X]))&gt;
</table>
<bodyText confidence="0.997743846153846">
whom the target descriptor is ascribed, then the
descriptor can be substituted in the target. The
resulting clause will have the substituted descriptor
attributed to the same agents as the descriptor in
the original target.
Reading (iii) requires a co-extensional descriptor that
Nadia is aware of. Background assumptions III and
IV both provide such a descriptor. Reading (iv) also
requires a descriptor that Nadia is aware of, but it
must be co-intensional with the target descriptor;
only assumption IV provides such a descriptor which
can then be substituted. The results are shown in
table II.
</bodyText>
<equation confidence="0.936292833333333">
+ I
(1) + II
(iii) + III
+ IV
(iv) + III
(iv) + IV
</equation>
<page confidence="0.991753">
198
</page>
<note confidence="0.61529675">
awareness, and limited reasoning: Preliminary report.&amp;quot;
Proceedings of the Ninth International Joint Confer-
ence on Artificial Intelligence, Los Angeles, August
1985. 491-501.
</note>
<bodyText confidence="0.992369666666667">
Substitution rules for other intensional constructs,
and details of interactions between rules, can be
found in Fawcett (1985, section 5.4).
</bodyText>
<sectionHeader confidence="0.998776" genericHeader="method">
6. Implementation
</sectionHeader>
<bodyText confidence="0.9985684">
We have implemented a prototype system that incor-
porates the ideas discussed above. The system is
written in Prolog, and is built on top of Popowich&apos;s
SAUMER formalism for syntactic and semantic rules
(Popowich 1984, 1985).
</bodyText>
<sectionHeader confidence="0.861436" genericHeader="conclusions">
7. Plans and goals
</sectionHeader>
<bodyText confidence="0.999968727272727">
Now that we have looked at the problem of detect-
ing these ambiguities and representing the possible
readings, the next step is to study how the ambigui-
ties may be resolved, and what factors influence the
preference for one reading over another. We expect
that in most cases pragmatic factors will be central,
although there may be default preferences in some
constructions. In addition, another member of our
group, Diane Horton, is studying the interaction
between agents&apos; descriptions and the presuppositions
of a sentence (Horton 1986).
</bodyText>
<sectionHeader confidence="0.973149" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999395555555556">
This paper is based on thesis work by the first author
under the supervision of the second, who also wrote the
paper. The authors acknowledge helpful discussions with
each other, Diane Horton, and Hector Levesque, and finan-
cial support from IBM, the Natural Sciences and Engineer-
ing Research Council of Canada, and the University of
Toronto. They are also grateful to Nick Cercone and Fred
Popowich for making the SAUMER system available to
them.
</bodyText>
<sectionHeader confidence="0.993786" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999925586206897">
BARWISE, Jon and PERRY, John (1983). Situations and
attitudes. Cambridge, MA: The MIT Press / Bradford
Books, 1983.
DAEL, Veronica (1981). &amp;quot;Translating Spanish into logic
through logic.&amp;quot; American journal of computational
linguistics, 7(3), 149-164.
DOWTY, David R; WALL, Robert E; and PETERS, Stanley
(1981). Introduction to Montague semantics (Synthese
language library 11). Dordrecht: D. Reidel, 1981.
FAGIN, Ronald and HALPERN, Joseph Y (1985). &amp;quot;Belief,
FAWCETT, Brenda (1985). The representation of ambiguity
in opaque constructs. MSc thesis, published as techni-
cal report CSR1-178, Department of Computer Science
University of Toronto, October 1985.
FODOR, Janet Dean (1980). Semantics: Theories of mean-
ing in generative grammar (The language and thought
series). Cambridge, Mass.: Harvard University Press,
1980.
HOFSTADTER, Douglas R; CLOSSMAN, Gary A; and
MEREDITH, Marsha J (1982). &amp;quot;&apos;Shakespeare&apos;s plays
weren&apos;t written by him, but by someone else of the
same name.&apos; An essay on intensionality and frame-
based knowledge representation.&amp;quot; Bloomington, Indi-
ana: Indiana University Linguistics Club, November
1982.
HORTON, Diane (1986). Incorporating agents&apos; beliefs in a
model of presupposition, MSc thesis, Department of
Computer Science, University of Toronto, forthcoming
(June 1986).
LESPERANCE, Yves (1986). &amp;quot;Toward a computational
interpretation of situation semantics.&amp;quot; Computational
intelligence, 2(1), February 1986.
LEVESQUE, Hector (1983). &amp;quot;A logic of implicit and explicit
belief.&amp;quot; Proceedings of the National Conference on
Artificial Intelligence (AAAI-88), Washington, D.C.,
August 1983, 198-202.
MONTAGUE, Richard (1973). &amp;quot;The proper treatment of
quantification in ordinary English.&amp;quot; (11 In: Hintikka,
Kaarlo Jaakko Juhani; Moravcsik, Julius Matthew Emil
and Suppes, Patrick Colonel (editors). Approaches to
natural language: Proceedings of the 1970 Stanford
Workshop on Grammar and Semantics. Dordrecht: D.
Reidel, 1973. 221-242. (2] In: Thomason, Richard
Hunt (editor). Formal Philosophy: Selected Papers of
Richard Montague. New Haven: Yale University Press,
1974. 247-270.
MOORE, Robert C (1981). &amp;quot;Problems in logical form.&amp;quot;
Proceedings of the 19th Annual Meeting, Association
for Computational Linguistics, Stanford, June 1981,
117-124.
POPOWICH, Fred (1984). &amp;quot;SAUMER: Sentence analysis using
metarules.&amp;quot; Technical report 84-2, Laboratory for Com-
puter and Communications Research, Simon Fraser
University, Burnaby, B.C., Canada. August 1984.
POPOWICH, Fred (1985). &amp;quot;The SAUMER user&apos;s manual.&amp;quot;
Technical report 85-4, Laboratory for Computer and
Communications Research, Simon Fraser University,
Burnaby, B.C., Canada. March 1985.
</reference>
<page confidence="0.998913">
199
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.869269">
<title confidence="0.9986545">The detection and representation of ambiguities of intension and description</title>
<author confidence="0.999979">Brenda Fawcett</author>
<author confidence="0.999979">Graeme Hirst</author>
<affiliation confidence="0.9999835">Department of Computer Science University of Toronto</affiliation>
<address confidence="0.944156">Toronto, Ontario CANADA M5S 1A4</address>
<abstract confidence="0.99895725">Ambiguities related to intension and their consequent inference failures are a diverse group, both syntactically and semantically. One particular kind of ambiguity that has received little attention so far is whether it is the speaker or the third party to whom a description in an opaque third-party attitude report should be attributed. The different readings lead to different inferences in a system modeling the beliefs of external agents. We propose that a unified approach to the representation of the alternative readings of intension-related ambiguities can be based on the of a is evaluated with respect to intensionality, the beliefs of agents, and a time of application. We describe such a representation, built on a standard modal logic, and show how it may be used in conjunction with a knowledge base of background assumptions to license restricted substitution of equals in opaque contexts.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Y</author>
</authors>
<title>clef X: [few X])&gt; (iv) Intensional reading, agent&apos;s description: (label Y: Nadia) Y, &apos;int-abs (C, (del X: [few X1D&gt;</title>
<marker>Y, </marker>
<rawString>(label Y: Nadia) &lt;want Y, ^ (clef X: [few X])&gt; (iv) Intensional reading, agent&apos;s description: (label Y: Nadia) &lt;want Y, &apos;int-abs (C, (del X: [few X1D&gt;</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon BARWISE</author>
<author>John PERRY</author>
</authors>
<title>Situations and attitudes.</title>
<date>1983</date>
<publisher>The MIT Press / Bradford Books,</publisher>
<location>Cambridge, MA:</location>
<marker>BARWISE, PERRY, 1983</marker>
<rawString>BARWISE, Jon and PERRY, John (1983). Situations and attitudes. Cambridge, MA: The MIT Press / Bradford Books, 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veronica DAEL</author>
</authors>
<title>Translating Spanish into logic through logic.&amp;quot;</title>
<date>1981</date>
<journal>American journal of computational linguistics,</journal>
<volume>7</volume>
<issue>3</issue>
<pages>149--164</pages>
<marker>DAEL, 1981</marker>
<rawString>DAEL, Veronica (1981). &amp;quot;Translating Spanish into logic through logic.&amp;quot; American journal of computational linguistics, 7(3), 149-164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David R DOWTY</author>
<author>Robert E WALL</author>
<author>Stanley PETERS</author>
</authors>
<title>Introduction to Montague semantics (Synthese language library 11).</title>
<date>1981</date>
<location>Dordrecht: D. Reidel,</location>
<marker>DOWTY, WALL, PETERS, 1981</marker>
<rawString>DOWTY, David R; WALL, Robert E; and PETERS, Stanley (1981). Introduction to Montague semantics (Synthese language library 11). Dordrecht: D. Reidel, 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald FAGIN</author>
<author>Joseph Y HALPERN</author>
</authors>
<date>1985</date>
<note>Belief,</note>
<marker>FAGIN, HALPERN, 1985</marker>
<rawString>FAGIN, Ronald and HALPERN, Joseph Y (1985). &amp;quot;Belief,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brenda FAWCETT</author>
</authors>
<title>The representation of ambiguity in opaque constructs. MSc thesis, published as technical</title>
<date>1985</date>
<tech>report CSR1-178,</tech>
<institution>Department of Computer Science University of Toronto,</institution>
<marker>FAWCETT, 1985</marker>
<rawString>FAWCETT, Brenda (1985). The representation of ambiguity in opaque constructs. MSc thesis, published as technical report CSR1-178, Department of Computer Science University of Toronto, October 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janet Dean FODOR</author>
</authors>
<title>Semantics: Theories of meaning in generative grammar (The language and thought series).</title>
<date>1980</date>
<publisher>Harvard University Press,</publisher>
<location>Cambridge, Mass.:</location>
<marker>FODOR, 1980</marker>
<rawString>FODOR, Janet Dean (1980). Semantics: Theories of meaning in generative grammar (The language and thought series). Cambridge, Mass.: Harvard University Press, 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas R HOFSTADTER</author>
<author>Gary A CLOSSMAN</author>
<author>Marsha J MEREDITH</author>
</authors>
<title>Shakespeare&apos;s plays weren&apos;t written by him, but by someone else of the same name.&apos; An essay on intensionality and framebased knowledge representation.&amp;quot;</title>
<date>1982</date>
<institution>Indiana University Linguistics Club,</institution>
<location>Bloomington, Indiana:</location>
<marker>HOFSTADTER, CLOSSMAN, MEREDITH, 1982</marker>
<rawString>HOFSTADTER, Douglas R; CLOSSMAN, Gary A; and MEREDITH, Marsha J (1982). &amp;quot;&apos;Shakespeare&apos;s plays weren&apos;t written by him, but by someone else of the same name.&apos; An essay on intensionality and framebased knowledge representation.&amp;quot; Bloomington, Indiana: Indiana University Linguistics Club, November 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diane HORTON</author>
</authors>
<title>Incorporating agents&apos; beliefs in a model of presupposition, MSc thesis,</title>
<date>1986</date>
<institution>Department of Computer Science, University of Toronto, forthcoming</institution>
<marker>HORTON, 1986</marker>
<rawString>HORTON, Diane (1986). Incorporating agents&apos; beliefs in a model of presupposition, MSc thesis, Department of Computer Science, University of Toronto, forthcoming (June 1986).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves LESPERANCE</author>
</authors>
<title>Toward a computational interpretation of situation semantics.&amp;quot;</title>
<date>1986</date>
<journal>Computational intelligence,</journal>
<volume>2</volume>
<issue>1</issue>
<marker>LESPERANCE, 1986</marker>
<rawString>LESPERANCE, Yves (1986). &amp;quot;Toward a computational interpretation of situation semantics.&amp;quot; Computational intelligence, 2(1), February 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hector LEVESQUE</author>
</authors>
<title>A logic of implicit and explicit belief.&amp;quot;</title>
<date>1983</date>
<booktitle>Proceedings of the National Conference on Artificial Intelligence (AAAI-88),</booktitle>
<pages>198--202</pages>
<location>Washington, D.C.,</location>
<marker>LEVESQUE, 1983</marker>
<rawString>LEVESQUE, Hector (1983). &amp;quot;A logic of implicit and explicit belief.&amp;quot; Proceedings of the National Conference on Artificial Intelligence (AAAI-88), Washington, D.C., August 1983, 198-202.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Richard MONTAGUE</author>
</authors>
<title>The proper treatment of quantification in ordinary English.&amp;quot; (11 In: Hintikka, Kaarlo Jaakko Juhani; Moravcsik, Julius Matthew Emil and Suppes, Patrick Colonel (editors). Approaches to natural language:</title>
<date>1973</date>
<booktitle>Proceedings of the 1970 Stanford Workshop on Grammar and Semantics.</booktitle>
<pages>221--242</pages>
<editor>D. Reidel,</editor>
<publisher>Yale University Press,</publisher>
<location>Dordrecht:</location>
<marker>MONTAGUE, 1973</marker>
<rawString>MONTAGUE, Richard (1973). &amp;quot;The proper treatment of quantification in ordinary English.&amp;quot; (11 In: Hintikka, Kaarlo Jaakko Juhani; Moravcsik, Julius Matthew Emil and Suppes, Patrick Colonel (editors). Approaches to natural language: Proceedings of the 1970 Stanford Workshop on Grammar and Semantics. Dordrecht: D. Reidel, 1973. 221-242. (2] In: Thomason, Richard Hunt (editor). Formal Philosophy: Selected Papers of Richard Montague. New Haven: Yale University Press, 1974. 247-270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C MOORE</author>
</authors>
<title>Problems in logical form.&amp;quot;</title>
<date>1981</date>
<booktitle>Proceedings of the 19th Annual Meeting, Association for Computational Linguistics,</booktitle>
<pages>117--124</pages>
<location>Stanford,</location>
<marker>MOORE, 1981</marker>
<rawString>MOORE, Robert C (1981). &amp;quot;Problems in logical form.&amp;quot; Proceedings of the 19th Annual Meeting, Association for Computational Linguistics, Stanford, June 1981, 117-124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fred POPOWICH</author>
</authors>
<title>SAUMER: Sentence analysis using metarules.&amp;quot;</title>
<date>1984</date>
<tech>Technical report 84-2,</tech>
<institution>Laboratory for Computer and Communications Research, Simon Fraser University,</institution>
<location>Burnaby, B.C., Canada.</location>
<marker>POPOWICH, 1984</marker>
<rawString>POPOWICH, Fred (1984). &amp;quot;SAUMER: Sentence analysis using metarules.&amp;quot; Technical report 84-2, Laboratory for Computer and Communications Research, Simon Fraser University, Burnaby, B.C., Canada. August 1984.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fred POPOWICH</author>
</authors>
<title>The SAUMER user&apos;s manual.&amp;quot;</title>
<date>1985</date>
<tech>Technical report 85-4,</tech>
<institution>Laboratory for Computer and Communications Research, Simon Fraser University,</institution>
<location>Burnaby, B.C., Canada.</location>
<marker>POPOWICH, 1985</marker>
<rawString>POPOWICH, Fred (1985). &amp;quot;The SAUMER user&apos;s manual.&amp;quot; Technical report 85-4, Laboratory for Computer and Communications Research, Simon Fraser University, Burnaby, B.C., Canada. March 1985.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>