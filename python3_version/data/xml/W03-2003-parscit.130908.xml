<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000055">
<title confidence="0.988855">
Overview of Patent Retrieval Task at NTCIR-3
</title>
<author confidence="0.988318">
Makoto Iwayama Atsushi Fujii Noriko Kando Akihiko Takano
</author>
<affiliation confidence="0.803713">
Tokyo Institute of University of Tsukuba/Japan National Institute of National Institute of
Technology/Hitachi Ltd. Science and Technology Corp. Informatics Informatics
</affiliation>
<email confidence="0.886686">
iwayama@crl.hitachi.co.jp fujii@slis.tsukuba.ac.jp kando@nii.ac.jp aki@acm.org
</email>
<sectionHeader confidence="0.996005" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999428846153846">
We describe the overview of patent re-
trieval task at NTCIR-3. The main task was
the technical survey task, where participants
tried to retrieve relevant patents to news ar-
ticles. In this paper, we introduce the task
design, the patent collections, the character-
istics of the submitted systems, and the re-
sults overview. We also arranged the free-
styled task, where participants could try
anything they want as far as the patent col-
lections were used. We describe the brief
summaries of the proposals submitted to the
free-styled task.
</bodyText>
<sectionHeader confidence="0.999518" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99998386440678">
In the field of information retrieval, there have
been held successive evaluation workshops, such
as TREC [8], CREF [1], and NTCIR [5], to build
and utilize various kinds of test collections. In the
Third NTCIR Workshop (NTCIR-3), which was
held from June 2001 to December 2003, a serious
effort was first made in the “Patent Retrieval Task”
to explore information retrieval targeting patent
documents.
The goal of Patent Retrieval Task is to provide
test collections for enhancing research on patent
information processing, from patent retrieval to
patent mining. Although there exist many com-
mercial patent retrieval systems and services, pat-
ent retrieval has not been paid much attention in
the research field of information retrieval. One of
the reasons is the lack of test collection on patent.
TREC used patent documents as a part of the
document collections, but there was no treatment
specially applied to the patent collection.
In SIGIR2000, the first workshop on patent re-
trieval was held [4] and there were many fruitful
discussions on the current status and future direc-
tions of patent retrieval. The workshop convinced
us that there was the need of test collections spe-
cifically for patents.
We then asked for PATOLIS Co. [7] to provide
patent collections for the patent retrieval task. Con-
sequently, we could release three kinds of patent
collections; those were two years’ Japanese full
texts, five years’ Japanese abstracts, and five
years’ English abstracts. At the same time, we
could fortunately have cooperation with JIPA (Ja-
pan Intellectual Property Association) [3] in creat-
ing search topics and assessing the relevance.
Since each member of JIPA belongs to the intellec-
tual property division in her/his company, they are
all experts in patent searching. All the above
contributions enabled us to kick off the first
evaluation workshop designed for patent
information processing.
There are various phases and aspects in patent
information processing. For example, various
kinds of users (researchers, patent searchers, busi-
ness managers, and so on) search patents for vari-
ous purposes (technical survey, finding conflicting
applications, buying/selling patents, and so on).
Corresponding to each situation, an appropriate
search model should be developed. The standard of
the relevance judgments may also depend on each
situation. In some cases, retrieving relevant patents
is not enough but further analysis on the retrieved
patents might be necessary. For example, creating
a patent map of a product would clarify the patent
relations between the techniques used to make the
product. Cross-lingual patent retrieval is also im-
portant when applying patents to foreign countries.
All of these are within scope of our project and this
task was the first step toward our goal.
</bodyText>
<sectionHeader confidence="0.973292" genericHeader="introduction">
2 Task Design
</sectionHeader>
<bodyText confidence="0.999214">
In this workshop, we focused on a simple task of
technical survey. End-users we assumed in the task
were novice users, for example, business managers.
The major reason of adopting such general task
was that we could only use the two years’ full texts
that were not enough for trying more patent-
oriented task like finding conflicting applications
from patents.
</bodyText>
<figureCaption confidence="0.99939">
Figure 1: Scenario of technology survey
</figureCaption>
<bodyText confidence="0.999897675">
To fit the task to a real situation, we used Japa-
nese news articles as the original sources of search
topics, so the task was conducting cross-database
retrieval, searching patents by news articles. The
task assumed the following situation that is de-
picted in Figure 1. When a business manager looks
through news articles and is interested in one of
them, she/he clips it out and asks a searcher to find
related patents to the clipping. The manager passes
the clipping to the searcher along with her/his
memorandum, and this clipping with memorandum
became the search topic in this task. The memo-
randum helps the searcher to have the exact infor-
mation need the manager has, when the clipping
contains non-relevant topics or the clipping has
little description on the information need. Task
participants played the role of the searcher and
tried to retrieve relevant patents to the clipping.
Since the purpose of the searching was technical
survey, the claim part in patent was not treated
specifically in assessing the relevance. Patent
documents were treated as if those were technical
papers.
Cross-database retrieval itself is so general that
techniques investigated in the task can be applied
to various combinations of databases. This is an-
other purpose of the task.
We prepared search topics in four languages,
Japanese, English, Korean, and Chinese (both tra-
ditional and simplified). Participants could try
cross-lingual patent retrieval by using one of the
non-Japanese topics. Unfortunately, only two
groups submitted cross-lingual results and both of
them used English topics.
In addition to the technical survey task ex-
plained so far, we arranged the optional task,
where participants could try anything they want as
far as they used the patent collections provided.
One of the purposes of this free-styled task is to
explore next official tasks.
</bodyText>
<sectionHeader confidence="0.862362" genericHeader="method">
3 Characteristics of Patent Applications
</sectionHeader>
<bodyText confidence="0.9886345">
In this section, we briefly review the characteristics
of patent applications (patent documents).
</bodyText>
<listItem confidence="0.999366214285715">
• There are structures, for example, claims,
purposes, effects, and embodiments of the
invention.
• Although the claim part is the most impor-
tant in patent, it is written in an unusual style
especially for Japanese patent; all the sub-
topics are written in single sentence.
• To enlarge the scope of invention, vague or
general terms are often used in claims.
• Patents include much technical terminology.
Applicants may define and use their original
terms not used in other patents.
• There are large variations in length. The
longest patent in our collections contains
about 30,000 Japanese words!
• The search models would be significantly
different between industries, for example,
between chemical / pharmaceutical indus-
tries and computers / machinery / electric
industries.
• Classification exists. IPC (International Pat-
ent Classification) is the most popular one.
• The criterion of evaluation depends on the
purpose of searching. For example, high re-
call is required for finding conflicting appli-
cations.
• In some industries, images are important to
judge the relevance.
</listItem>
<bodyText confidence="0.999859222222222">
Our task focused on few of the above character-
istics. We treated patent documents as technical
documents rather than legal statements, so we did
not distinguish between the claim part and the oth-
ers in assessing the relevance. High recall was not
necessary, so we used the standard averaged preci-
sion to evaluate the results. Few groups used struc-
tures and classifications. Images were not included
in the patent collections provided.
</bodyText>
<sectionHeader confidence="0.968219" genericHeader="method">
4 Patent Collections
</sectionHeader>
<listItem confidence="0.970066625">
PATOLIS Co. provided and we released the fol-
lowing patent collections.
• kkh: Publication of unexamined patent ap-
plications (1998, 1999) (in Japanese)
• jsh: JAPIO Patent Abstracts (1995–1999)
(in Japanese)
• paj: Patent Abstracts Japan (1995– 1999) (in
English)
</listItem>
<bodyText confidence="0.906710058823529">
“Kkh” contains full texts of unexamined patent
applications in Japanese. Images were eliminated.
“Jsh” contains human edited abstracts in Japanese.
Although all the texts in “kkh” have the abstracts
written by the applicants, experts in JAPIO (Japan
Patent Information Organization) [2] short-
ened/lengthened about half of them to fit the length
within about 400 Japanese characters. They also
normalized technical terms if necessary. “Paj” is
English translation of “jsh”.
kkh: (98,99)
Publication of
unexamined patent
applications
(in Japanese)
modification of the original abstracts by
human experts (JAPIO)
</bodyText>
<table confidence="0.716337333333333">
jsh: (95-99) paj: (95-99)
JAPIO Patent Patent Abstracts
Abstracts Japan
(in Japanese) (in English)
translation by
human experts
</table>
<figureCaption confidence="0.931672">
Figure 2: Relationships between the patent col-
</figureCaption>
<bodyText confidence="0.962894833333333">
lections
Figure 2 shows the relationships between these
three collections. Here, we see parallel relations,
for example, full texts vs. abstracts, original ab-
stracts vs. edited abstracts, and Japanese abstracts
vs. English abstracts. Researchers can use these
parallel collections for various purposes, for exam-
ple, finding rules of abstracting, creating a term
normalization dictionary, acquiring translation
knowledge, and so on.
Table 1 summarizes the characteristics of the
three collections.
</bodyText>
<table confidence="0.997097">
kkh jsh paj
Type Full text Abstract Abstract
Language Japanese Japanese English
Years 98,99 95-99 95-99
Number of 697,262 1,706,154 1,701,339
documents
Bytes 18139M 1883M 2711M
</table>
<tableCaption confidence="0.999878">
Table 1: Characteristics of the patent collections
</tableCaption>
<sectionHeader confidence="0.990923" genericHeader="method">
5 Topics
</sectionHeader>
<bodyText confidence="0.999809903225807">
JIPA members created topics, six for the dry run
and 25 for the formal run. Since the topics for the
dry run were substantially revised after the dry run,
we decided to re-use those in the formal run. In
consequence, we had the total 31 topics for the
formal run.
Figure 3 is an example of the topics in English
and Table 2 shows the explanations of the fields in
the topics. In our task, &lt;ARTICLE&gt; and
&lt;SUPPLEMENT&gt; correspond to the news clipping
and the memorandum respectively.
The topics also contain &lt;DESCRIPTION&gt; and
&lt;NARRATIVE&gt; fields we are familiar with. Since
many NTCIR tasks already have the results for
using &lt;DESCRIPTION&gt; and &lt;NARRATIVE&gt;
fields, we can compare our results of using these
fields with the results of other tasks.
Along with the grade of relevance (i.e., “A”,
“B”, “C”, or “D”), each judged patent has a mark
(“S”, “J”, or “U”) representing the origin from
which the patent was retrieved. Table 3 explains
about the marks. For example, a document with
“BJ” means that the document was judged as “par-
tially relevant” (i.e. “B-“) and only found by ex-
perts in their preliminary search (i.e., “-J”).
Here, note that all the submitted runs contrib-
uted to collecting the “S” patents, but only the top
30 patents for each run were used. Note also that
we can restore the patent set retrieved by the man-
ual search (i.e., “PJ” set) by collecting “J” and “U”
patents.
</bodyText>
<figure confidence="0.877843307692308">
&lt;PURPOSE&gt;technology survey&lt;/PURPOSE&gt;
&lt;TITLE&gt;Device to judge relative merits by comparing
codes such as barcodes with each other&lt;/TITLE&gt;
&lt;ARTICLE&gt;
&lt;A-DOC&gt;
&lt;A-DOCNO&gt;JA-981031179&lt;/A-DOCNO&gt;
&lt;A-LANG&gt;JA&lt;/A-LANG&gt;
&lt;A-SECTION&gt;Society&lt;/A-SECTION&gt;
&lt;A-AE&gt;No&lt;/A-AE&gt;
&lt;A-WORDS&gt;189&lt;/A-WORDS&gt;
&lt;A-HEADLINE&gt;BANDAIlost a lawsuit for piracy filed by
EPOCH at TokyoDistrict Court&lt;/A-HEADLINE&gt;
&lt;A-DATE&gt;1998-10-31&lt;/A-DATE&gt;
</figure>
<figureCaption confidence="0.8249278">
&lt;A-TEXT&gt;In settlement of the lawsuit filed by EPOCH
INC., the toy manufacturer, against BANDAI CO., LTD. As
compensation of 264 million for damages for infringement
of a card game patent, the Tokyo District Court ordered
BANDAI to pay about 114 million on the 30th. The presid-
ing judge,Mr. Yoshiyuki Mori, indicated that some func-
tions including key operation for the &amp;quot;Super Barcode
Wars&amp;quot; mini game machine manufactured and sold by BANDAI
CO., LTD. in July, 1992 to March, 1993 fell under the
&amp;quot;technical rangeof a patent licensed to EPOCH
</figureCaption>
<figure confidence="0.812310666666667">
INC.&amp;quot;.&lt;/A-TEXT&gt;
&lt;/A-DOC&gt;
&lt;/ARTICLE&gt;
</figure>
<figureCaption confidence="0.7720795625">
&lt;SUPPLEMENT&gt;Determinationof victory or defeat by com-
paring each other&apos;s values based on codes from barcode
readings doesnot conflictwith the patent.&lt;/SUPPLEMENT&gt;
&lt;DESCRIPTION&gt;What kindof devices determinesleaders or
victors by reading several codes such as barcodes and
comparing the values correspondingto these
codes?&lt;/DESCRIPTION&gt;
&lt;NARRATIVE&gt;&amp;quot;Super Barcode Wars&amp;quot; is a type of mini game
machine where recorded barcodes are read in cards fea-
turing characters and the game proceedsin semi-real
time by operating offence and defense keys. Sample codes
include barcodes and magneticcodes, but shall not be
defined as limited only to these.&lt;/NARRATIVE&gt;
&lt;CONCEPT&gt;Sign, barcode, code,superiority or inferior-
ity, victory or defeat, comparison, judgment&lt;/CONCEPT&gt;
&lt;PI&gt;PATENT-KKH-G-H01-333373&lt;/PI&gt;
</figureCaption>
<figure confidence="0.83241">
&lt;/TOPIC&gt;
</figure>
<figureCaption confidence="0.998422">
Figure 3: Example of the topics
</figureCaption>
<table confidence="0.9991535">
Field Explanation
&lt;LANG&gt; Language code
&lt;PURPOSE&gt; Purpose of search
&lt;TITLE&gt; Concise representation
of search topic
&lt;ARTICLE&gt; MAINICHI news article
in NTCIR format
&lt;SUPPLEMENT&gt; Supplemental informa-
tion of news article
&lt;DESCRIPTION&gt; Short description of
search topic
&lt;NARRATIVE&gt; Long description of
search topic
&lt;CONCEPT&gt; List of keywords
&lt;PI&gt; Original patents of news
article
</table>
<tableCaption confidence="0.999747">
Table 2: Explanations of the fields in topics
</tableCaption>
<sectionHeader confidence="0.99853" genericHeader="method">
6 Results Overview
</sectionHeader>
<subsectionHeader confidence="0.605255">
6.1 Participants
</subsectionHeader>
<bodyText confidence="0.999912705882353">
Eight groups submitted the 36 runs. One group
submitted runs only for pooling. We briefly de-
scribe the characteristics of each group. Refer to
the proceedings of Patent Retrieval Task [6] for
each detail.
LAPIN: This group focused on the “term distil-
lation” in cross-database retrieval, where the dif-
ference between the term frequency in source
database and that in target database was integrated
into the overall term weighting.
SRGDU: This group tried several pseudo rele-
vance feedback methods in the context of patent
retrieval. The proposed method using Taylor for-
mula was compared with the traditional Rocchio
method.
daikyo: This group made long gram-based in-
dex from the patent collections. Compared with the
traditional gram-based indexing, proposed method
produce more compact index.
DTEC: This group searched various kinds of
abstracts rather than full texts, and compared the
effectiveness of those. The abstracts were JAPIO
patent abstracts and the combinations of “title”,
“applicant’s abstract”, and “claims”. Manual and
automatic runs were compared.
DOVE: This group also submitted manual and
automatic runs. In the manual runs, non-relevant
passages in &lt;ARTICLE&gt; were eliminated manu-
ally.
IFLAB: This group evaluated their cross-
lingual IR system PRIME through several mono-
lingual runs. They also evaluated their translation
extraction method by using Japanese-US patent
families, which were not provided in this task.
brkly: This group submitted both monolingual
and cross-lingual runs. In the cross-lingual runs,
words in English topics were translated into Japa-
nese words by using English-Japanese dictionary
automatically created by the aligned bilingual cor-
pus (i.e., “paj” and “jsh”). Their method of creating
the dictionary is based on word co-occurrence with
the association measure.
sics: This group also submitted cross-lingual
runs, where they automatically created a cross-
lingual thesaurus form the aligned bilingual corpus,
“paj” and “jsh”, and used the thesaurus for word-
based query translation. The Random Indexing
vector-space technique was used to extract the
cross-lingual thesaurus. Note that, in both the
“sics” and the “brkly” groups, there was no mem-
ber who understands Japanese.
</bodyText>
<subsectionHeader confidence="0.999652">
6.2 Recall/Precision
</subsectionHeader>
<bodyText confidence="0.999993">
The recall/precision graphs of the mandatory runs
are shown in Figure 4, and those of the optional
runs in Figure 5. In each figure, there are both re-
sults for the strict relevance (“A”) and the relaxed
relevance (“A” + “B”). For each run in the figures,
brief system description is specified; the descrip-
tion includes the searching mode (automatic or
manual), the topic fields used in query construction,
and the topic language.
</bodyText>
<subsectionHeader confidence="0.981632">
6.3 Topic-by-topic Results
</subsectionHeader>
<bodyText confidence="0.999835857142857">
Figure 6 shows the median of the average preci-
sions for each topic. Figure 7 shows the breakdown
of the relevance judgments. Detailed analysis on
each topic will be given by JIPA, where it will be
discussed about the reasons why systems could not
find some patents human experts found and vise
versa.
</bodyText>
<subsectionHeader confidence="0.747084">
6.4 Recall of the relevant patents retrieved in
the preliminary human search
</subsectionHeader>
<bodyText confidence="0.999294">
Figure 8 shows the recall of the relevant patents
retrieved in the preliminary human search. In the
process of making pool, we used only the top 30
documents for each run. Here, we extracted more
documents from each run and investigated how
many human retrieving relevant patents could be
covered by the systems.
</bodyText>
<sectionHeader confidence="0.964185" genericHeader="method">
7 Optional (Free-styled) Task
</sectionHeader>
<bodyText confidence="0.9997638">
The following two groups applied to the optional
task. Refer to the proceedings of Patent Retrieval
Task [6] for each detail.
CRL: This group investigated the method of
extracting various rules from the existing align-
ments in patents. The “diff” command of UNIX
was used to find the alignments between JAPIO
patent abstracts and the original abstracts by appli-
cants, between claims and embodiments, and be-
tween different claims in an application.
TIT: This group focused on the unusual style of
Japanese claims, and tried to automatically struc-
ture the claims to raise the readability of claims.
Rhetorical structure analysis was applied for this
purpose.
</bodyText>
<sectionHeader confidence="0.903852" genericHeader="method">
8 Summary and Future Directions
</sectionHeader>
<bodyText confidence="0.99993425">
In this paper, we described the overview of patent
retrieval task at NTCIR-3. We are planning to con-
tinue our effort for the next patent retrieval task
along with the following directions.
</bodyText>
<listItem confidence="0.99348175">
• Longer range of years will be covered.
• Purpose of search would shift to more real
one, for example, searching conflicting ap-
plications.
</listItem>
<sectionHeader confidence="0.974432" genericHeader="method">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999904857142857">
We are grateful to PATOLIS Co. for providing the
patent collections of this task. We also thank all the
members of JIPA who created the topics and as-
sessed the relevance. Without their expertise in
patent, this task would not be realized. Lastly, we
thank all the participants for their contributions to
this task.
</bodyText>
<sectionHeader confidence="0.94296" genericHeader="method">
References
</sectionHeader>
<listItem confidence="0.86305245">
[1] CLEF (Cross Language Evaluation Forum)
(http://clef.iei.pi.cnr.it/)
[2] JAPIO (Japan Patent Information Organization)
(http://www.japio.or.jp/)
[3] JIPA (Japan Intellectual Property Association)
(http://www.jipa.or.jp/)
[4] ACM-SIGIR Workshop on Patent Retrieval, or-
ganized by Mun-Kew Leong and Noriko Kando,
2000.
(http://research.nii.ac.jp/ntcir/sigir2000ws/)
[5] NTCIR (NII-NACSIS Test Collection for IR Sys-
tems)
(http://research.nii.ac.jp/ntcir/index-en.html)
[6] Proceedings of the Third NTCIR Workshop on
Research in Information Retrieval, Automatic Text
Summarization and Question Answering, 2003.
[7] PATOLIS Co.
(http://www.patolis.co.jp/e-index.html)
[8] TREC (Text Retrieval Conference)
(http://trec.nist.gov/)
</listItem>
<figure confidence="0.998450333333333">
A, mandatory
precision
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
A: auto
M: manual
E: English topics
LAPIN4(A)
DTEC1(M)
DOVE4(M)
brklypat1(A)
daikyo(M)
SRGDU5(A)
IFLAB6(A)
brklypat3(A,E)
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
recall
A+B, mandatory
precision
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
A: auto
M: manual
E: English topics
LAPIN4(A)
DOVE4(M)
DTEC1(M)
daikyo(M)
brklypat1(A)
SRGDU3(A)
IFLAB6(A)
brklypat3(A,E)
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
recall
</figure>
<figureCaption confidence="0.999459">
Figure 4: Recall/Precision of mandatory runs
</figureCaption>
<figure confidence="0.999178189655173">
A, optional
recall
A+B, optional
recall
LAPIN1(A,TDNC)
brklypat2(A,DN)
DOVE3(A,DN)
DOVE2(A,D)
SRGDU6(A,DN)
IFLAB2(A,D)
IFLAB3(A,DN)
IFLAB7(A,T)
brklypat4(A,DN,E)
A: auto
M: manual
T: TITLE
D: DESCRIPTION
N: NARRATIVE
C: CONCEPT
E: English Topics
LAPIN1(A,TDNC)
DOVE3(A,DN)
brklypat2(A,DN)
DOVE2(A,D)
IFLAB2(A,D)
SRGDU4(A,DN)
IFLAB4(A,DN)
IFLAB7(A,T)
brklypat4(A,DN,E)
A: auto
M: manual
T: TITLE
D: DESCRIPTION
N: NARRATIVE
C: CONCEPT
E: English Topics
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
precision
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
precision
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
</figure>
<figureCaption confidence="0.999433">
Figure 5: Recall/Precision of optional runs
</figureCaption>
<figure confidence="0.999296933333333">
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
A
A+B
number of documents
median of average precisions
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31
topic ID
</figure>
<figureCaption confidence="0.998438">
Figure 6: Median of average precisions (all runs)
</figureCaption>
<figure confidence="0.7362602">
450
400
350
300
250
200
150
100
50
0
</figure>
<sectionHeader confidence="0.407054" genericHeader="method">
BS
AS
BJ
AJ
BU
AU
</sectionHeader>
<table confidence="0.90888">
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31
BS 1 34 44 2 15 43 9 29 7 3 6 15 0 6 2 2 15 5 4 0 1 0 1 7 15 17 26 0 0 1 16
AS 0 5 27 2 0 0 55 0 1 0 1 57 6 37 0 2 0 6 9 1 0 1 1 10 49 11 5 35 0 5 15
BJ 10 7 2 2 2 0 9 42 10 3 0 47 22 2 8 4 9 36 0 5 0 0 2 33 3 16 18 3 0 2 19
AJ 4 0 0 0 0 0 23 10 17 11 1 173 12 10 1 1 2 11 0 0 2 4 2 108 12 6 7 7 0 1 16
BU 7 13 4 4 6 0 5 33 7 4 3 29 5 10 3 1 8 18 2 1 1 0 4 16 6 16 38 7 5 7 4
AU 22 13 6 10 15 12 27 23 18 15 4 101 22 17 5 15 5 17 36 4 8 4 4 72 49 12 19 40 6 3 16
topic ID
</table>
<figureCaption confidence="0.999845">
Figure 7: Breakdown of relevance judgments
</figureCaption>
<figure confidence="0.997986785714286">
Recall of AJ+AU
1
0.9
0.8
0.7
0.6
recall 0.5 all
0.4 mandatory
0.3 mandatory (auto)
0.2
0.1
0
0 100 200 300 400 500 600 700 800 900 1000
ranking
Recall of AJ+AU+BJ+BU
recall 1 all
0.9 mandatory
0.8 mandatory (auto)
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0 100 200 300 400 500 600 700 800 900 1000
ranking
</figure>
<figureCaption confidence="0.999914">
Figure 8: Recall of the relevant patents retrieved in the preliminary human search
</figureCaption>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.201028">
<title confidence="0.612799">Overview of Patent Retrieval Task at NTCIR-3</title>
<author confidence="0.663842">Makoto Iwayama Atsushi Fujii Noriko Kando Akihiko Takano</author>
<affiliation confidence="0.7291935">Tokyo Institute of University of Tsukuba/Japan National Institute of National Institute of Technology/Hitachi Ltd. Science and Technology Corp. Informatics Informatics</affiliation>
<email confidence="0.436273">iwayama@crl.hitachi.co.jpfujii@slis.tsukuba.ac.jpkando@nii.ac.jpaki@acm.org</email>
<abstract confidence="0.998296714285714">We describe the overview of patent retrieval task at NTCIR-3. The main task was the technical survey task, where participants tried to retrieve relevant patents to news articles. In this paper, we introduce the task design, the patent collections, the characteristics of the submitted systems, and the results overview. We also arranged the freestyled task, where participants could try anything they want as far as the patent collections were used. We describe the brief summaries of the proposals submitted to the free-styled task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>