<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.022420">
<title confidence="0.9990855">
A Local Tree Alignment-based Soft Pattern Matching Approach for
Information Extraction
</title>
<author confidence="0.999504">
Seokhwan Kim, Minwoo Jeong, and Gary Geunbae Lee
</author>
<affiliation confidence="0.9999645">
Department of Computer Science and Engineering
Pohang University of Science and Technology
</affiliation>
<address confidence="0.981851">
San 31, Hyoja-dong, Nam-gu, Pohang, 790-784, Korea
</address>
<email confidence="0.997731">
{megaup, stardust, gblee}@postech.ac.kr
</email>
<sectionHeader confidence="0.995635" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997485">
This paper presents a new soft pattern match-
ing method which aims to improve the recall
with minimized precision loss in information
extraction tasks. Our approach is based on a
local tree alignment algorithm, and an effec-
tive strategy for controlling flexibility of the
pattern matching will be presented. The ex-
perimental results show that the method can
significantly improve the information extrac-
tion performance.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999981418181819">
The goal of information extraction (IE) is to ex-
tract structured information from unstructured natu-
ral language documents. Pattern induction to gener-
ate extraction patterns from a number of training in-
stances is one of the most widely applied approaches
for IE.
A number of pattern induction approaches have
recently been researched based on the dependency
analysis (Yangarber, 2003) (Sudo et al., 2001)
(Greenwood and Stevenson, 2006) (Sudo et al.,
2003). The natural language texts in training in-
stances are parsed by dependency analyzer and con-
verted into dependency trees. Each subtree of a de-
pendency tree is considered as a candidate of ex-
traction patterns. An extraction pattern is gener-
ated by selecting the subtree which indicates the de-
pendency relationships of each labeled slot value
in the training instance and agrees on the selec-
tion criteria defined by each pattern representation
model. A number of dependency tree-based pat-
tern representation models have been proposed. The
predicate-argument (SVO) model allows subtrees
containing only a verb and its direct subject and
object as extraction pattern candidates (Yangarber,
2003). The chain model represents extraction pat-
terns as a chain-shaped path from each target slot
value to the root node of the dependency tree (Sudo
et al., 2001). A couple of chain model patterns shar-
ing the same verb are linked to each other and con-
struct a linked-chain model pattern (Greenwood and
Stevenson, 2006). The subtree model considers all
subtrees as pattern candidates (Sudo et al., 2003).
Regardless of the applied pattern representation
model, the methods have concentrated on extracting
only exactly equivalent subtrees of test instances to
the extraction patterns, which we call hard pattern
matching. While the hard pattern matching policy
is helpful to improve the precision of the extracted
results, it can cause the low recall problem. In or-
der to tackle this problem, a number of soft pattern
matching approaches which aim to improve recall
with minimized precision loss have been applied to
the linear vector pattern models by introducing a
probabilistic model (Xiao et al., 2004) or a sequence
alignment algorithm (Kim et al., 2008).
In this paper, we propose an alternative soft
pattern matching method for IE based on a local
tree alignment algorithm. While other soft pattern
matching approaches have been able to handle the
matching among linear vector instances with fea-
tures from tree structures only, our method aims to
directly solve the low recall problem of tree-to-tree
pattern matching by introducing the local tree align-
ment algorithm which is widely used in bioinformat-
ics to analyze RNA secondary structures. Moreover,
</bodyText>
<page confidence="0.985939">
169
</page>
<note confidence="0.2769375">
Proceedings of NAACL HLT 2009: Short Papers, pages 169–172,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<figure confidence="0.936934">
(a) Example pattern
</figure>
<figureCaption confidence="0.9767745">
Figure 1: An example of local alignment-based tree pat-
tern matching
</figureCaption>
<bodyText confidence="0.997366666666667">
we present an effective policy for controlling degree
of flexibility in the pattern matching by setting the
optimal threshold values for each extracted pattern.
</bodyText>
<sectionHeader confidence="0.993694" genericHeader="introduction">
2 Methods
</sectionHeader>
<bodyText confidence="0.97183825">
The low recall problem of information extraction
based on hard pattern matching is caused by lack
of flexibility in pattern matching. For example, the
tree pattern in Figure 1(a) cannot be matched with
the tree in Figure 1(b) by considering only exactly
equivalent subtrees, because the first tree has an ad-
ditional root node ’said’ which is not in the second
one. However, the matching between two trees can
be performed by omitting just a node as shown in
Figure 1(c).
In order to improve and control the degree of flex-
ibility in tree pattern matching, we have adopted a
local tree alignment approach as the pattern match-
ing method instead of hard pattern matching strat-
egy. The local tree alignment problem is to find the
most similar subtree between two trees.
We have adopted the Hochsmann algorithm
(Hochsmann et al., 2003) which is a local tree align-
ment algorithm used in bioinformatics to analyze
RNA secondary structures. The goal of the Hochs-
mann algorithm is to find the local closed forest
alignment which maximizes the similarity score for
ordered trees. The algorithm can be implemented
by a dynamic programming approach which solves a
problem based on the previous results of its subprob-
lems. The main problem of Hochsmann algorithm
is to compute the similarity score between two sub-
forests according to the defined order from the sin-
gle node level to the entire tree level. The similarity
score is defined based on three tree edit operations
which are insertion, deletion, and replacement (Tai,
1979). For each pair of subforests, the maximum
similarity score among three edit operations is com-
puted, and the kind and the position of performed
edit operations are recorded.
The adaptation of Hochsmann algorithm to the IE
problem is performed by redefining the Q-function,
the similarity score function between two nodes, as
follows:
Q(v, w) = { 1 if lnk(v)=lnk(w),
and lbl(v)=lbl(w),
Q(p(w),p(v)) iflbl(v)=&lt;SLOT&gt;,
0 otherwise.
where v and w are nodes to be compared, lnk(v) is
the link label of v, lbl(v) is the node label of v, and
p(v) denotes a parent node of v. While general local
tree alignment problems consider only node labels
to compute the node-level similarities, our method
considers not only node labels, but also link labels to
the head node, because the class of link to the head
node is important as the node label itself for depen-
dency trees. Moreover, the method should consider
the alignment of slot value nodes in the tree patterns
for adopting information extraction tasks. If the pat-
tern node v is a kind of slot value nodes, the similar-
ity score between v and w is inherited from parents
of both nodes.
After computing for all pairs of subforests, the
optimal alignment is obtained by trace-back based
on the recorded information of edit operation which
maximizes the similarity score for each subforest
pair. On the optimal alignment, the target node
aligned to a slot value node on the pattern is regarded
as an argument candidate of the extraction. Each ex-
</bodyText>
<listItem confidence="0.644863">
(b) Dependency Tree of the example sentence
(c) Local alignment-based tree pattern matching
</listItem>
<page confidence="0.973815">
170
</page>
<bodyText confidence="0.986018">
traction candidate has its confidence score which is
computed from the alignment score, defined as:
</bodyText>
<equation confidence="0.5125285">
S(TPTN, TTGT)
score(TPTN, TTGT) = |TPTN|
</equation>
<bodyText confidence="0.999855384615385">
where |T |denotes the total number of nodes in tree
T and S(T1, T2) is the similarity score of both trees
computed by Hochsmann algorithm.
Only the extraction candidates with alignment
score larger than the given threshold value, θ, are
accepted and regarded as extraction results. For the
simplest approach, the same threshold value, θ, can
be applied to all the patterns. However, we assumed
that each pattern has its own optimal threshold value
as its own confidence score, which is different from
other patterns’ threshold values. The optimal thresh-
old value θi and the confidence score confi for the
pattern Pi are defined as:
</bodyText>
<equation confidence="0.97599">
{evalfscore (Dtrain, Pi, θ)}
confi = max {evalfscore (Dtrain, Pi, θ)}
0.s&lt;0&lt;1.0
</equation>
<bodyText confidence="0.9999855">
where evalfscore(D, P, θ) is the evaluation result in
F-score of the extraction for the data set D using the
pattern P with the threshold value θ. For each pat-
tern, the threshold value which maximizes the eval-
uation result in F-score for the training data set and
the maximum evaluation result in F-score are as-
signed as the optimal threshold value and the con-
fidence score for the pattern respectively.
</bodyText>
<sectionHeader confidence="0.998892" genericHeader="method">
3 Experiment
</sectionHeader>
<bodyText confidence="0.9999314">
In order to evaluate the effectiveness of our method,
we performed an experiment for the scenario tem-
plate extraction task on the management succession
domain in MUC-6. The task aims to extract sce-
nario template instances which consist of person-in,
person-out, position, organization slot values from
news articles about management succession events.
We used a modified version of the MUC-6 corpus
including 599 training documents and 100 test doc-
uments described by Soderland (1999). While the
scenario templates on the original MUC-6 corpus
are labeled on each document, this version has sce-
nario templates for each sentence.
All the sentences in both training and test
documents were converted into dependency trees
</bodyText>
<figureCaption confidence="0.9910915">
Figure 2: Comparison of soft pattern matching strategy
with the hard pattern matching
</figureCaption>
<bodyText confidence="0.999857366666667">
by Berkeley Parser1 and LTH Constituent-to-
Dependency Conversion Tool2. From the depen-
dency trees and scenario templates on the training
data, we constructed pattern candidate sets for four
types of pattern representation models which are
SVO, chain, linked-chain, and subtree models. For
each pattern candidate, corresponding confidence
score and optimal threshold value were computed.
The pattern candidates for each pattern represen-
tation model were arranged in descending order of
confidence score. According to the arranged order,
each pattern was matched with test documents and
the extracted results were accumulated. Extracted
templates for test documents are evaluated by com-
paring with the answer templates on the test corpus.
The curves in Figure 2 show the relative perfor-
mance of the pattern matching strategies for each
pattern representation model. The results suggest
that soft pattern matching strategy with optimal
threshold values requires less number of patterns
for the performance saturation than the hard pat-
tern matching strategy for all pattern models except
the SVO model. For the SVO model, the result of
soft pattern matching strategy is equivalent to that
of hard pattern matching strategy. It is because most
of patterns represented in SVO model are relatively
shorter than those represented in other models.
In order to evaluate the flexibility controlling
strategy, we compared the result of optimally de-
termined threshold values with the cases of using
</bodyText>
<footnote confidence="0.9994585">
1http://nlp.cs.berkeley.edu/pages/Parsing.html
2http://nlp.cs.lth.se/pennconverter/
</footnote>
<figure confidence="0.995976045454546">
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
Proportion of Patterns Used
F-score
0.45
0.35
0.25
0.15
0.05
0.4
0.3
0.2
0.1
0
SOFT(SUBTREE)
SOFT(LINKED)
SOFT(CHAIN)
HARD(LINKED)
HARD(CHAIN)
HARD(SUBTREE)
SOFT/HARD(SVO)
θi = arg max
0.s&lt;0&lt;1.0
</figure>
<page confidence="0.984717">
171
</page>
<table confidence="0.999671142857143">
θ SVO Chain Linked-Chain Subtree
P R F P R F P R F P R F
0.7 32.1 18.0 23.1 27.6 55.0 36.8 26.8 57.0 36.4 26.6 58.0 36.5
0.8 32.1 18.0 23.1 43.8 35.0 38.8 43.4 36.0 39.3 44.7 34.0 38.6
0.9 32.1 18.0 23.1 45.2 33.0 38.1 43.8 35.0 38.9 45.2 33.0 38.2
1.0 (hard) 32.1 18.0 23.1 45.2 33.0 38.1 43.8 35.0 38.9 45.2 33.0 38.2
optimal 32.1 18.0 23.1 36.0 49.0 41.5 40.7 48.0 44.0 43.0 46.0 44.4
</table>
<tableCaption confidence="0.999872">
Table 1: Experimental Results
</tableCaption>
<bodyText confidence="0.999631714285714">
various fixed threshold values. Table 1 represents
the final results for all pattern representation mod-
els and threshold values. For the SVO model, all
the results are equivalent regardless of the thresh-
old strategy because of extremely short length of the
patterns. For the other pattern models, precisions are
increased and recalls are decreased by increasing the
threshold. The maximum performances in F-score
are achieved by our optimal threshold determining
strategy for all pattern representation models. The
experimental results of our method show the better
recall than the cases of hard pattern matching and
controlled precision than the cases of extremely soft
pattern matching.
</bodyText>
<sectionHeader confidence="0.999375" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999983388888889">
We presented a local tree alignment based soft pat-
tern matching approach for information extraction.
The softness of the pattern matching method is con-
trolled by the threshold value of the alignment score.
The optimal threshold values are determined by self-
evaluation on the training data. Experimental results
indicate that our soft pattern matching approach is
helpful to improve the pattern coverage and our
threshold learning strategy is effective to reduce the
precision loss followed by the soft pattern matching
method.
The goal of local tree alignment algorithm is to
measure the structural similarity between two trees.
It is similar to the kernel functions in the tree kernel
method which is another widely applied approach to
solve the IE problems. In the future, we plan to in-
corporate our alignment-based soft pattern matching
method into the tree kernel method for IE.
</bodyText>
<sectionHeader confidence="0.998282" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.997634">
This work was supported by the Korea Science and
Engineering Foundation(KOSEF) grant funded by
the Korea government(MEST) (No. R01-2008-000-
20651-0)
</bodyText>
<sectionHeader confidence="0.999227" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999676696969697">
Mark A. Greenwood and Mark Stevenson. 2006. Im-
proving semi-supervised acquisition of relation extrac-
tion patterns. In Proceedings of Workshop on Informa-
tion Extraction Beyond The Document, pp. 29–35.
Matthias Hochsmann, Thomas Toller, Robert Giegerich,
and Stefan Kurtz. 2003. Local similarity in rna sec-
ondary structures. In Proceedings of the IEEE Com-
puter Society Bioinformatics Conference , pp. 159–68.
Seokhwan Kim, Minwoo Jeong, and Gary Geunbae
Lee. 2008. An alignment-based pattern representa-
tion model for information extraction. In Proceedings
of the ACM SIGIR ’08, pp. 875–876.
Stephen Soderland. 1999. Learning information extrac-
tion rules for semi-structured and free text. Machine
Learning, 34(1):233–272.
Kiyoshi Sudo, Satoshi Sekine, and Ralph Grishman.
2001. Automatic pattern acquisition for japanese in-
formation extraction. In Proceedings of the first inter-
national conference on Human language technology
research, pp. 1–7.
Kiyoshi Sudo, Satoshi Sekine, and Ralph Grishman.
2003. An improved extraction pattern representation
model for automatic ie pattern acquisition. In Pro-
ceedings of the ACL ’03, pp. 224–231.
Kuo-Chung Tai. 1979. The tree-to-tree correction prob-
lem. Journal of the ACM (JACM), 26(3):422–433.
Jing Xiao, Tat-Seng Chua, and Hang Cui. 2004. Cas-
cading use of soft and hard matching pattern rules
for weakly supervised information extraction. In Pro-
ceedings of COLING ’04, pp. 542–548.
Roman Yangarber. 2003. Counter-training in discovery
of semantic patterns. In Proceedings of the ACL ’03,
pp. 343–350.
</reference>
<page confidence="0.99788">
172
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.946640">
<title confidence="0.9998">A Local Tree Alignment-based Soft Pattern Matching Approach Information Extraction</title>
<author confidence="0.999624">Seokhwan Kim</author>
<author confidence="0.999624">Minwoo Jeong</author>
<author confidence="0.999624">Gary Geunbae</author>
<affiliation confidence="0.999958">Department of Computer Science and Pohang University of Science and</affiliation>
<address confidence="0.989882">San 31, Hyoja-dong, Nam-gu, Pohang, 790-784,</address>
<email confidence="0.988349">stardust,</email>
<abstract confidence="0.997079636363636">This paper presents a new soft pattern matching method which aims to improve the recall with minimized precision loss in information extraction tasks. Our approach is based on a local tree alignment algorithm, and an effective strategy for controlling flexibility of the pattern matching will be presented. The experimental results show that the method can significantly improve the information extraction performance.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Mark A Greenwood</author>
<author>Mark Stevenson</author>
</authors>
<title>Improving semi-supervised acquisition of relation extraction patterns.</title>
<date>2006</date>
<booktitle>In Proceedings of Workshop on Information Extraction Beyond The Document,</booktitle>
<pages>29--35</pages>
<contexts>
<context position="1196" citStr="Greenwood and Stevenson, 2006" startWordPosition="172" endWordPosition="175"> controlling flexibility of the pattern matching will be presented. The experimental results show that the method can significantly improve the information extraction performance. 1 Introduction The goal of information extraction (IE) is to extract structured information from unstructured natural language documents. Pattern induction to generate extraction patterns from a number of training instances is one of the most widely applied approaches for IE. A number of pattern induction approaches have recently been researched based on the dependency analysis (Yangarber, 2003) (Sudo et al., 2001) (Greenwood and Stevenson, 2006) (Sudo et al., 2003). The natural language texts in training instances are parsed by dependency analyzer and converted into dependency trees. Each subtree of a dependency tree is considered as a candidate of extraction patterns. An extraction pattern is generated by selecting the subtree which indicates the dependency relationships of each labeled slot value in the training instance and agrees on the selection criteria defined by each pattern representation model. A number of dependency tree-based pattern representation models have been proposed. The predicate-argument (SVO) model allows subtr</context>
</contexts>
<marker>Greenwood, Stevenson, 2006</marker>
<rawString>Mark A. Greenwood and Mark Stevenson. 2006. Improving semi-supervised acquisition of relation extraction patterns. In Proceedings of Workshop on Information Extraction Beyond The Document, pp. 29–35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthias Hochsmann</author>
<author>Thomas Toller</author>
<author>Robert Giegerich</author>
<author>Stefan Kurtz</author>
</authors>
<title>Local similarity in rna secondary structures.</title>
<date>2003</date>
<booktitle>In Proceedings of the IEEE Computer Society Bioinformatics Conference ,</booktitle>
<pages>159--68</pages>
<contexts>
<context position="4694" citStr="Hochsmann et al., 2003" startWordPosition="734" endWordPosition="737">tree in Figure 1(b) by considering only exactly equivalent subtrees, because the first tree has an additional root node ’said’ which is not in the second one. However, the matching between two trees can be performed by omitting just a node as shown in Figure 1(c). In order to improve and control the degree of flexibility in tree pattern matching, we have adopted a local tree alignment approach as the pattern matching method instead of hard pattern matching strategy. The local tree alignment problem is to find the most similar subtree between two trees. We have adopted the Hochsmann algorithm (Hochsmann et al., 2003) which is a local tree alignment algorithm used in bioinformatics to analyze RNA secondary structures. The goal of the Hochsmann algorithm is to find the local closed forest alignment which maximizes the similarity score for ordered trees. The algorithm can be implemented by a dynamic programming approach which solves a problem based on the previous results of its subproblems. The main problem of Hochsmann algorithm is to compute the similarity score between two subforests according to the defined order from the single node level to the entire tree level. The similarity score is defined based </context>
</contexts>
<marker>Hochsmann, Toller, Giegerich, Kurtz, 2003</marker>
<rawString>Matthias Hochsmann, Thomas Toller, Robert Giegerich, and Stefan Kurtz. 2003. Local similarity in rna secondary structures. In Proceedings of the IEEE Computer Society Bioinformatics Conference , pp. 159–68.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seokhwan Kim</author>
<author>Minwoo Jeong</author>
<author>Gary Geunbae Lee</author>
</authors>
<title>An alignment-based pattern representation model for information extraction.</title>
<date>2008</date>
<booktitle>In Proceedings of the ACM SIGIR ’08,</booktitle>
<pages>875--876</pages>
<contexts>
<context position="2961" citStr="Kim et al., 2008" startWordPosition="454" endWordPosition="457">presentation model, the methods have concentrated on extracting only exactly equivalent subtrees of test instances to the extraction patterns, which we call hard pattern matching. While the hard pattern matching policy is helpful to improve the precision of the extracted results, it can cause the low recall problem. In order to tackle this problem, a number of soft pattern matching approaches which aim to improve recall with minimized precision loss have been applied to the linear vector pattern models by introducing a probabilistic model (Xiao et al., 2004) or a sequence alignment algorithm (Kim et al., 2008). In this paper, we propose an alternative soft pattern matching method for IE based on a local tree alignment algorithm. While other soft pattern matching approaches have been able to handle the matching among linear vector instances with features from tree structures only, our method aims to directly solve the low recall problem of tree-to-tree pattern matching by introducing the local tree alignment algorithm which is widely used in bioinformatics to analyze RNA secondary structures. Moreover, 169 Proceedings of NAACL HLT 2009: Short Papers, pages 169–172, Boulder, Colorado, June 2009. c�20</context>
</contexts>
<marker>Kim, Jeong, Lee, 2008</marker>
<rawString>Seokhwan Kim, Minwoo Jeong, and Gary Geunbae Lee. 2008. An alignment-based pattern representation model for information extraction. In Proceedings of the ACM SIGIR ’08, pp. 875–876.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Soderland</author>
</authors>
<title>Learning information extraction rules for semi-structured and free text.</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<volume>34</volume>
<issue>1</issue>
<contexts>
<context position="8716" citStr="Soderland (1999)" startWordPosition="1400" endWordPosition="1401">n result in F-score are assigned as the optimal threshold value and the confidence score for the pattern respectively. 3 Experiment In order to evaluate the effectiveness of our method, we performed an experiment for the scenario template extraction task on the management succession domain in MUC-6. The task aims to extract scenario template instances which consist of person-in, person-out, position, organization slot values from news articles about management succession events. We used a modified version of the MUC-6 corpus including 599 training documents and 100 test documents described by Soderland (1999). While the scenario templates on the original MUC-6 corpus are labeled on each document, this version has scenario templates for each sentence. All the sentences in both training and test documents were converted into dependency trees Figure 2: Comparison of soft pattern matching strategy with the hard pattern matching by Berkeley Parser1 and LTH Constituent-toDependency Conversion Tool2. From the dependency trees and scenario templates on the training data, we constructed pattern candidate sets for four types of pattern representation models which are SVO, chain, linked-chain, and subtree mo</context>
</contexts>
<marker>Soderland, 1999</marker>
<rawString>Stephen Soderland. 1999. Learning information extraction rules for semi-structured and free text. Machine Learning, 34(1):233–272.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kiyoshi Sudo</author>
<author>Satoshi Sekine</author>
<author>Ralph Grishman</author>
</authors>
<title>Automatic pattern acquisition for japanese information extraction.</title>
<date>2001</date>
<booktitle>In Proceedings of the first international conference on Human language technology research,</booktitle>
<pages>1--7</pages>
<contexts>
<context position="1164" citStr="Sudo et al., 2001" startWordPosition="168" endWordPosition="171">fective strategy for controlling flexibility of the pattern matching will be presented. The experimental results show that the method can significantly improve the information extraction performance. 1 Introduction The goal of information extraction (IE) is to extract structured information from unstructured natural language documents. Pattern induction to generate extraction patterns from a number of training instances is one of the most widely applied approaches for IE. A number of pattern induction approaches have recently been researched based on the dependency analysis (Yangarber, 2003) (Sudo et al., 2001) (Greenwood and Stevenson, 2006) (Sudo et al., 2003). The natural language texts in training instances are parsed by dependency analyzer and converted into dependency trees. Each subtree of a dependency tree is considered as a candidate of extraction patterns. An extraction pattern is generated by selecting the subtree which indicates the dependency relationships of each labeled slot value in the training instance and agrees on the selection criteria defined by each pattern representation model. A number of dependency tree-based pattern representation models have been proposed. The predicate-a</context>
</contexts>
<marker>Sudo, Sekine, Grishman, 2001</marker>
<rawString>Kiyoshi Sudo, Satoshi Sekine, and Ralph Grishman. 2001. Automatic pattern acquisition for japanese information extraction. In Proceedings of the first international conference on Human language technology research, pp. 1–7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kiyoshi Sudo</author>
<author>Satoshi Sekine</author>
<author>Ralph Grishman</author>
</authors>
<title>An improved extraction pattern representation model for automatic ie pattern acquisition.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL ’03,</booktitle>
<pages>224--231</pages>
<contexts>
<context position="1216" citStr="Sudo et al., 2003" startWordPosition="176" endWordPosition="179">pattern matching will be presented. The experimental results show that the method can significantly improve the information extraction performance. 1 Introduction The goal of information extraction (IE) is to extract structured information from unstructured natural language documents. Pattern induction to generate extraction patterns from a number of training instances is one of the most widely applied approaches for IE. A number of pattern induction approaches have recently been researched based on the dependency analysis (Yangarber, 2003) (Sudo et al., 2001) (Greenwood and Stevenson, 2006) (Sudo et al., 2003). The natural language texts in training instances are parsed by dependency analyzer and converted into dependency trees. Each subtree of a dependency tree is considered as a candidate of extraction patterns. An extraction pattern is generated by selecting the subtree which indicates the dependency relationships of each labeled slot value in the training instance and agrees on the selection criteria defined by each pattern representation model. A number of dependency tree-based pattern representation models have been proposed. The predicate-argument (SVO) model allows subtrees containing only </context>
</contexts>
<marker>Sudo, Sekine, Grishman, 2003</marker>
<rawString>Kiyoshi Sudo, Satoshi Sekine, and Ralph Grishman. 2003. An improved extraction pattern representation model for automatic ie pattern acquisition. In Proceedings of the ACL ’03, pp. 224–231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuo-Chung Tai</author>
</authors>
<title>The tree-to-tree correction problem.</title>
<date>1979</date>
<journal>Journal of the ACM (JACM),</journal>
<volume>26</volume>
<issue>3</issue>
<contexts>
<context position="5382" citStr="Tai, 1979" startWordPosition="849" endWordPosition="850">NA secondary structures. The goal of the Hochsmann algorithm is to find the local closed forest alignment which maximizes the similarity score for ordered trees. The algorithm can be implemented by a dynamic programming approach which solves a problem based on the previous results of its subproblems. The main problem of Hochsmann algorithm is to compute the similarity score between two subforests according to the defined order from the single node level to the entire tree level. The similarity score is defined based on three tree edit operations which are insertion, deletion, and replacement (Tai, 1979). For each pair of subforests, the maximum similarity score among three edit operations is computed, and the kind and the position of performed edit operations are recorded. The adaptation of Hochsmann algorithm to the IE problem is performed by redefining the Q-function, the similarity score function between two nodes, as follows: Q(v, w) = { 1 if lnk(v)=lnk(w), and lbl(v)=lbl(w), Q(p(w),p(v)) iflbl(v)=&lt;SLOT&gt;, 0 otherwise. where v and w are nodes to be compared, lnk(v) is the link label of v, lbl(v) is the node label of v, and p(v) denotes a parent node of v. While general local tree alignmen</context>
</contexts>
<marker>Tai, 1979</marker>
<rawString>Kuo-Chung Tai. 1979. The tree-to-tree correction problem. Journal of the ACM (JACM), 26(3):422–433.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jing Xiao</author>
<author>Tat-Seng Chua</author>
<author>Hang Cui</author>
</authors>
<title>Cascading use of soft and hard matching pattern rules for weakly supervised information extraction.</title>
<date>2004</date>
<booktitle>In Proceedings of COLING ’04,</booktitle>
<pages>542--548</pages>
<contexts>
<context position="2908" citStr="Xiao et al., 2004" startWordPosition="445" endWordPosition="448">do et al., 2003). Regardless of the applied pattern representation model, the methods have concentrated on extracting only exactly equivalent subtrees of test instances to the extraction patterns, which we call hard pattern matching. While the hard pattern matching policy is helpful to improve the precision of the extracted results, it can cause the low recall problem. In order to tackle this problem, a number of soft pattern matching approaches which aim to improve recall with minimized precision loss have been applied to the linear vector pattern models by introducing a probabilistic model (Xiao et al., 2004) or a sequence alignment algorithm (Kim et al., 2008). In this paper, we propose an alternative soft pattern matching method for IE based on a local tree alignment algorithm. While other soft pattern matching approaches have been able to handle the matching among linear vector instances with features from tree structures only, our method aims to directly solve the low recall problem of tree-to-tree pattern matching by introducing the local tree alignment algorithm which is widely used in bioinformatics to analyze RNA secondary structures. Moreover, 169 Proceedings of NAACL HLT 2009: Short Pape</context>
</contexts>
<marker>Xiao, Chua, Cui, 2004</marker>
<rawString>Jing Xiao, Tat-Seng Chua, and Hang Cui. 2004. Cascading use of soft and hard matching pattern rules for weakly supervised information extraction. In Proceedings of COLING ’04, pp. 542–548.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roman Yangarber</author>
</authors>
<title>Counter-training in discovery of semantic patterns.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL ’03,</booktitle>
<pages>343--350</pages>
<contexts>
<context position="1144" citStr="Yangarber, 2003" startWordPosition="166" endWordPosition="167">gorithm, and an effective strategy for controlling flexibility of the pattern matching will be presented. The experimental results show that the method can significantly improve the information extraction performance. 1 Introduction The goal of information extraction (IE) is to extract structured information from unstructured natural language documents. Pattern induction to generate extraction patterns from a number of training instances is one of the most widely applied approaches for IE. A number of pattern induction approaches have recently been researched based on the dependency analysis (Yangarber, 2003) (Sudo et al., 2001) (Greenwood and Stevenson, 2006) (Sudo et al., 2003). The natural language texts in training instances are parsed by dependency analyzer and converted into dependency trees. Each subtree of a dependency tree is considered as a candidate of extraction patterns. An extraction pattern is generated by selecting the subtree which indicates the dependency relationships of each labeled slot value in the training instance and agrees on the selection criteria defined by each pattern representation model. A number of dependency tree-based pattern representation models have been propo</context>
</contexts>
<marker>Yangarber, 2003</marker>
<rawString>Roman Yangarber. 2003. Counter-training in discovery of semantic patterns. In Proceedings of the ACL ’03, pp. 343–350.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>