<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000071">
<title confidence="0.9946515">
Using subcategorization knowledge to improve case prediction
for translation to German
</title>
<author confidence="0.966687">
Marion Weller&apos; Alexander Fraser&apos; Sabine Schulte im Walde&apos;
</author>
<affiliation confidence="0.670644">
&apos;Institut f¨ur Maschinelle &apos;Centrum f¨ur Informations-
</affiliation>
<address confidence="0.5844805">
Sprachverarbeitung und Sprachverarbeitung
Universit¨at Stuttgart Ludwig-Maximilians-Universit¨at M¨unchen
</address>
<email confidence="0.991044">
{wellermn|schulte}@ims.uni-stuttgart.de fraser@cis.uni-muenchen.de
</email>
<sectionHeader confidence="0.993717" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999958916666667">
This paper demonstrates the need and im-
pact of subcategorization information for
SMT. We combine (i) features on source-
side syntactic subcategorization and (ii)
an external knowledge base with quantita-
tive, dependency-based information about
target-side subcategorization frames. A
manual evaluation of an English-to-
German translation task shows that the
subcategorization information has a posi-
tive impact on translation quality through
better prediction of case.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999974156862745">
When translating from a morphologically poor
language to a morphologically rich language we
are faced with two major problems: (i) the rich-
ness of the target-language morphology causes
data sparsity problems, and (ii) information about
morphological features on the target side is not
sufficiently contained in the source language mor-
phology.
We address these two problems using a two-
step procedure. We first replace inflected forms
by their stems or lemmas: building a translation
system on a stemmed representation of the target
side leads to a simpler translation task, and the
morphological information contained in the source
and target language parts of the translation model
is more balanced. In the second step, the stemmed
output of the translation is then inflected: the mor-
phological features are predicted, and the inflected
forms are generated using the stem and predicted
morphological features.
In this paper, we focus on improving case pre-
diction for noun phrases (NPs) in German trans-
lations. The NP feature case is extremely dif-
ficult to predict in German: while the NP fea-
tures gender and number are part of the stem or
can be derived from the source-side input, respec-
tively, the prediction of case requires information
about the subcategorization of the entire clause.
This is due to German being a less configurational
language than English, which encodes grammati-
cal relations (e.g. subject-hood, object-hood, etc.)
through the position of constituents. German sen-
tences exhibit a freer constituent order, and thus
case is an important indicator of the grammatical
functions of noun phrases. Correct case predic-
tion is a crucial factor for the adequacy of SMT
output, cf. the example in table 1 providing an
erroneously inflected output (this is taken from a
baseline “simple inflection prediction” system, cf.
section 5.2). The translation of the English input
sentence in terms of stems is perfectly acceptable;
after the inflection step, however, the translation
of NP4 ongoing military actions represents a geni-
tive modifier of the subject NP&apos;, instead of a direct
object NP of the verb anordnen (to order). The
meaning is thus why the government of the ongo-
ing military actions ordered, which has only one
NP and is completely wrong.
The translation in table 1 needs verb subcatego-
rization information. This is demonstrated by the
invented examples (1) and (2):
</bodyText>
<listItem confidence="0.881059">
(1) [Der Mitarbeiter]NPnom hat [den Bericht]NPacc [dem
Kollegen]NPdat gegeben.
</listItem>
<bodyText confidence="0.6774105">
[The employee]NPnom gave [his colleague]NPdat [the
report]NPacc
</bodyText>
<listItem confidence="0.8292475">
(2) [Der Mitarbeiter]NPnom hat [dem Bericht]NPdat [des
Kollegen]NPgen zugestimmt.
</listItem>
<bodyText confidence="0.9127275">
[The employee]NPnom agreed [on the report]PP [of
his colleague]PP
Both inflected sentences rely on the stem sequence
[d Mitarbeiter] [d Bericht] [d Kollege] (verb),
so the case assignment can only be determined by
the verb: While geben ( to give) has a strong pref-
erence for selecting a ditransitive subcategoriza-
tion frame1, including an agentive subject (nomi-
</bodyText>
<footnote confidence="0.927916">
1A ditransitive verb takes a subject and two objects.
</footnote>
<page confidence="0.952496">
593
</page>
<note confidence="0.633455">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 593–603,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
input [why]1 [the government]2 [ordered]3 [the ongoing military actions]4
output stemmed [warum]1 [d Regierung]2 [d anhaltend milit¨arisch Aktion]4 [angeordnet]3
inflected [warum]1 [die Regierung]2 [der anhaltenden milit¨arischen Aktionen]4 [angeordnet]3
</note>
<tableCaption confidence="0.980232">
Table 1: Example for case confusion in SMT output when using a simple prediction system.
</tableCaption>
<bodyText confidence="0.999382333333333">
native case), a benefactive (dative case) and a pa-
tient (accusative case), zustimmen (to agree) has
a strong preference for only selecting an agentive
subject (nominative case) and an indirect object
theme (dative case). So in the latter case the NP
[d Kollege] cannot receive case from the verb and
is instead the genitive modifier of the dative NP.
While for examples (1) and (2) knowledge
about the syntactic verb subcategorization func-
tions is sufficient to correctly predict the NP cases,
examples (3) to (6) require subcategorization in-
formation at the syntax-semantic interface.
</bodyText>
<listItem confidence="0.994146125">
(3) [Der Mitarbeiter]NPnom hat [dem Kollegen]NPdat
[den Bericht]NPacc gegeben.
(4) [Der Mitarbeiter]NPnom hat [den Bericht]NPacc [dem
Kollegen]NPdat gegeben.
(5) [Dem Kollegen]NPdat hat [der Mitarbeiter]NPnom
[den Bericht]NPacc gegeben.
(6) [Den Bericht]NPacc hat [der Mitarbeiter]NPnom [dem
Kollegen]NPdat gegeben.
</listItem>
<bodyText confidence="0.999974444444445">
In all four examples, the verb and the participat-
ing noun phrases Mitarbeiter (employee), Kollege
(colleague) and Bericht (report) are identical, and
the noun phrases are assigned the same case. How-
ever, given that the stemmed output of the trans-
lation does not tell us anything about case fea-
tures, in order to predict the appropriate cases of
the three noun phrases, we either rely on ordering
heuristics (such that the nominative NP is more
likely to be in the beginning of the sentence (the
German Vorfeld) than the accusative or dative NP,
even though all three of these would be grammati-
cal), or we need fine-grained subcategorization in-
formation beyond pure syntax. For example, both
Mitarbeiter and Kollege would satisfy the agentive
subject role of the verb geben better than Bericht,
and Bericht is more likely to be the patient of
geben.
The contribution of this paper is to improve the
prediction of case in our SMT system by imple-
menting and combining two alternative routes to
integrate subcategorization information from the
syntax-semantic interface: (i) We regard the trans-
lation as a function of the source language in-
put, and project the syntactic functions of the En-
glish nouns to their German translations in the
SMT output. This subcategorization model is nec-
essary when there are several plausible solutions
for the syntactic functions of a noun in combina-
tion with a verb. For example, both Mitarbeiter
and Kollege are plausible subjects and direct ob-
jects of the verb geben, so the information about
these nouns’ roles in the input sentence allows
for disambiguation. (ii) The case of an NP is de-
rived from an external knowledge base comprising
quantitative, dependency-based information about
German verb subcategorization frames and noun
modification. The verb subcategorization infor-
mation is not restricted to syntactic noun func-
tions but models association strength for verb–
noun pairs with regard to the entire subcatego-
rization frame plus the syntactic functions of the
nouns. For example, the database can tell us that
while the verb geben is very likely to subcatego-
rize a ditransitive frame, the verb zustimmen is
very likely to subcategorize only a direct object,
next to the obligatory subject (subcat frame pre-
diction). Furthermore, we can retrieve the infor-
mation that the noun Bericht is less likely to ap-
pear as subject of geben than the nouns Mitar-
beiter and Kollege (verb–noun subcat case pre-
diction). And we can look up that the noun Aktion
is very unlikely to be a genitive modification of
Regierung (cf. table 1), while Kollege is a plausi-
ble genitive modification of Bericht (noun–noun
modification case prediction, cf. example (2)).
In summary, model (i) applies when there are no
obvious preferences concerning verb–noun sub-
categorization or noun–noun modification. Model
(ii) predicts case relying on the subcategoriza-
tion and modification preferences. The combina-
tion of our two models approaches a simplified
level of semantic role definition but only relies on
dependency information that is considerably eas-
ier and cheaper to define and obtain than a very
high quality semantic parser and/or a corpus an-
notated with semantic role information. Integrat-
ing semantic role information into SMT has been
demonstrated by various researchers to improve
translation quality (cf. Wu and Fung (2009a), Wu
and Fung (2009b), Liu and Gildea (2008), Liu
and Gildea (2010)). Our approach is in line with
</bodyText>
<page confidence="0.997317">
594
</page>
<bodyText confidence="0.9999055">
Wu and Fung (2009b) who demonstrated that on
the one hand 84% of verb syntactic functions in
a 50-sentence test corpus projected from Chinese
to English, and that on the other hand about 15%
of the subjects were not translated into subjects,
but their semantic roles were preserved across lan-
guage. These two findings correspond to the ex-
pected uses of our models (i) and (ii), respectively.
</bodyText>
<sectionHeader confidence="0.968002" genericHeader="method">
2 Previous work
</sectionHeader>
<listItem confidence="0.591365923076923">
Previous work has already introduced the idea of
generating inflected forms as a post-processing
step for a translation system that has been
stripped of (most) target-language-specific fea-
tures. Toutanova et al. (2008) and Jeong et al.
(2010) built translation systems that predict in-
flected word forms based on a large array of mor-
phological and syntactic features, obtained from
both source and target side. Kholy and Habash
(2012) and Green and DeNero (2012) work on En-
glish to Arabic translation and model gender, num-
ber and definiteness, focusing primarily on im-
proving fluency.
</listItem>
<bodyText confidence="0.999885088235294">
Fraser et al. (2012) used a phrase-based system
to transfer stems and generated inflected forms
based on the stems and their morphological fea-
tures. For case prediction, they trained a CRF with
access to lemmas and POS-tags within a given
window. We re-implemented the system by Fraser
et al. as a hierarchical machine translation system
using a string-to-tree setup. In contrast to the flat
phrase-based setting of Fraser et al. (2012), syn-
tactic trees on the SMT output allow us to work
with verb–noun structures, which are relevant for
case prediction. While the CRF used for case pre-
diction in Fraser et al. (2012) has access to lexi-
cal information, it is limited to a certain window
size and has no direct information about the rela-
tion of verb–noun pairs occurring in the sentence.
Using a window of a limited size is particularly
problematic for German, as there can be large gaps
between the verb and its subcategorized nouns; in-
troducing information about the relation of verbs
and nouns helps to bridge such gaps. Furthermore,
that model was not able to make effective use of
source-side features.
One of the objectives of using an inflection
prediction model is morphologically well-formed
output. Kirchhoff et al. (2012) evaluated user re-
actions to different error types in machine trans-
lation and came to the result that morphological
well-formedness has only a marginal impact on
the comprehensibility of SMT output in the case
of English-Spanish translation. As already dis-
cussed, German case is essential to the meaning
of the sentence, so this result will not hold for Ger-
man output.
</bodyText>
<sectionHeader confidence="0.945319" genericHeader="method">
3 Translation pipeline
</sectionHeader>
<bodyText confidence="0.999868444444444">
This section presents an overview of our two-step
translation process. In the first step, English in-
put is translated to German stems. In the sec-
ond step, morphological features are predicted and
inflected forms are generated based on the word
stems and the morphological features. In subsec-
tions 3.1 to 3.4, we present the simple version of
the inflection prediction system; our new features
are described in sections 4.2 and 4.3.
</bodyText>
<subsectionHeader confidence="0.999482">
3.1 Stemmed representation/feature markup
</subsectionHeader>
<bodyText confidence="0.999986129032258">
We first parse the German side of the parallel
training data with BitPar (Schmid, 2004). This
maps each surface form appearing in normal text
to a stem and morphological features (case, gen-
der, number). We use this representation to create
the stemmed representation for training the trans-
lation model. With the exception of stem-markup
(discussed below), all morphological features are
removed from the stemmed representation. The
stem markup is used as part of the input to the fea-
ture prediction; the basic idea is that the given fea-
ture values are picked up by the prediction model
and then propagated over the phrase.
Nouns, as the head of NPs and PPs, are anno-
tated with gender and number. We consider gen-
der as part of the stem, whereas the value for num-
ber is derived from the source-side: if marked for
number, singular/plural nouns are distinguished
during word alignment and then translated accord-
ingly. Prepositions are also annotated with case;
many prepositions are restricted to only one case,
some are ambiguous and allow for either dative
or accusative. Other words which are subject to
feature prediction (e.g. adjectives, articles) are re-
duced to their stems with no feature markup, as
are all remaining words. As sole exception, we
keep the inflected forms of verbs (verbal inflec-
tion is not modelled). In addition to the transla-
tion model, the target-side language model, as well
as the reference data for parameter tuning use this
representation.
</bodyText>
<page confidence="0.991756">
595
</page>
<subsectionHeader confidence="0.999703">
3.2 Building a stemmed translation model
</subsectionHeader>
<bodyText confidence="0.991717086956522">
We use a hierarchical translation system. Instead
of translating phrases, a hierarchical system ex-
tracts translation rules (Galley et al., 2004) which
allow the decoder to provide a tree spanning over
the translated sentence. In order to avoid sparsity
during rule extraction, we use a string-to-tree
setup, where only the target-side part of the data
is parsed. Translation rules are of the following
form:
[X]1 allows [X]2 [NP]1 [NP]2 erlaubt
[X]1 allows [X]2 [NP]1 erlaubt [NP]2
This example illustrates how rules can cover the
different word ordering possibilities in German.
PP nodes are annotated with their respective
case, as well as with the lemma of the preposition
they contain. In our experiments, this enriched an-
notation has small improvements over the simpler
setting with only head categories (details omit-
ted). This outcome, in particular that adding the
lemma of the preposition to the PP node helps to
improve translation quality, has been observed be-
fore in tree restructuring work for improving trans-
lation (Huang and Knight, 2006).
</bodyText>
<subsectionHeader confidence="0.9336525">
3.3 Feature prediction and generation of
inflected forms
</subsectionHeader>
<bodyText confidence="0.99999705">
In this section we discuss our focus, which is pre-
diction of case, but also the prediction of num-
ber, gender and strong/weak adjectival inflection.
The latter feature is German-specific; its values2
(strong/weak) depend on the combination of the
other features, as well as on the type of determiner
(e.g. definite/indefinite/none).
Morphological features are predicted on four
separate CRF models, one for each feature. The
models for case, number and gender are indepen-
dent of another, whereas the model for adjecti-
val inflection requires information about these fea-
tures, and is thus the last one to be computed, tak-
ing the output of the 3 other models as part of its
input. In contrast, the adjectival inflection model
in Fraser et al. (2012) is independent from the
other features. Each model has access to stems,
POS-tags and the feature to be modelled within a
window of four positions to the right and the left
of the current position3.
</bodyText>
<footnote confidence="0.9808326">
2Note that the values for strong/weak inflection are not
always the same over the phrase, but follow a certain pattern
depending on the settings of case, number and gender.
3Preliminary experiments showed that larger windows do
not improve translation quality.
</footnote>
<bodyText confidence="0.99993921875">
Table 2 illustrates the different steps of the in-
flection process: the markup (number and gender
on nouns) in the stemmed output of the SMT sys-
tem is part of the input to the respective feature
prediction. For gender and number, the values
given on the stems of the nouns are then propa-
gated over the phrase. While the case of prepo-
sitional phrases is determined by the case annota-
tion on prepositions, the case of nominal phrases
is computed only based on the respective contexts.
After predicting all morphological features, the in-
formation required to generate inflected forms is
complete: based on the stems and the features, we
use the morphological tool SMOR (Schmid et al.,
2004) for the generation of inflected forms.
One general problem with feature-prediction is
that the ill-formed SMT output is not well repre-
sented by the training data which consists of well-
formed sentences. This problem was also men-
tioned by Stymne and Cancedda (2011) and Kholy
and Habash (2012). They deal with this problem
by translating the training data and annotating it
with the respective features, and then adding this
new data set to the original training data. As
this method comes with its own problems, such as
transferring the morphological annotation to not
necessarily isomorphically translated text, we do
not use translated data as part of the training data.
Instead, we limit the power of the CRF model
through experimenting with the removal of fea-
tures, until we had a system that was robust to this
problem.
</bodyText>
<subsectionHeader confidence="0.99925">
3.4 Dealing with word formation issues
</subsectionHeader>
<bodyText confidence="0.999958363636364">
To reduce data sparsity, we split portmanteau
prepositions. Portmanteaus are compounds of
prepositions and articles, e.g. zur = zu der (to the).
Being components of nominal phrases, they have
to agree in all morphological features with the rest
of the phrase. As only some combinations of arti-
cles and prepositions can form a portmanteau, the
decision of whether to merge prepositions and ar-
ticles is made after feature prediction. Since our
focus is case prediction, we do not do special mod-
elling of German compounds.
</bodyText>
<sectionHeader confidence="0.874453" genericHeader="method">
4 Using subcategorization information
</sectionHeader>
<bodyText confidence="0.99995025">
Within the area of (automatic) lexical acquisition,
the definition of lexical verb information has been
a major focus, because verbs play a central role
for the structure and the meaning of sentences and
</bodyText>
<page confidence="0.995586">
596
</page>
<table confidence="0.9983656">
SMT output predicted features inflected forms gloss
beeinflussen&lt;VVFIN&gt; – beeinflussen influence
d&lt;ART&gt; Fem.Acc.Sg.St die the
politisch&lt;ADJ&gt; Fem.Acc.Sg.Wk politische political
Stabilit¨at&lt;NN&gt;&lt;Fem&gt;&lt;Sg&gt; Fem.Acc.Sg.Wk Stabilitit stability
</table>
<tableCaption confidence="0.999323">
Table 2: Overview of the inflection process: the stem markup is highlighted in the SMT output.
</tableCaption>
<bodyText confidence="0.981623894736842">
discourse. On the one hand, this has led to a range
of manually or semi-automatically developed lex-
ical resources focusing on verb information, such
as the Levin classes (Levin, 1993), VerbNet (Kip-
per Schuler, 2006), FrameNet4 (Fillmore et al.,
2003), and PropBank (Palmer et al., 2005). On the
other hand, we find automatic approaches to the
induction of verb subcategorization information at
the syntax-semantics interface for a large num-
ber of languages, e.g. Briscoe and Carroll (1997)
for English; Sarkar and Zeman (2000) for Czech;
Schulte im Walde (2002a) for German; Messiant
(2008) for French. This basic kind of verb knowl-
edge has been shown to be useful in many NLP
tasks such as information extraction (Surdeanu et
al., 2003; Venturi1 et al., 2009), parsing (Carroll et
al., 1998; Carroll and Fang, 2004) and word sense
disambiguation (Kohomban and Lee, 2005; Mc-
Carthy et al., 2007).
</bodyText>
<subsectionHeader confidence="0.997046">
4.1 Extracting subcategorization information
</subsectionHeader>
<bodyText confidence="0.999979777777778">
As described in the introductory section, we make
use of two5 major kinds of subcategorization in-
formation. Verb–noun tuples referring to spe-
cific syntactic functions within verb subcatego-
rization (verb–noun subcat case prediction) are
integrated with an associated probability for ac-
cusative (direct object), dative (indirect object)
and nominative (subject).6 Further to the sub-
ject and object noun phrases, the subcategoriza-
tion information provides quantitative triples for
verb–preposition–noun pairs, thus predicting the
case of NPs within prepositional phrases (we do
this only when the prepositions are ambiguious,
i.e., they could subcategorize either a dative or
an accusative NP). In addition to modelling sub-
categorization information, it is also important to
differentiate between subcategorized noun phrases
(such as object or subject), and noun phrases
</bodyText>
<footnote confidence="0.99269925">
4Even though the FrameNets approach does not only in-
clude knowledge about verbal predicates, the actual lexicons
are skewed towards verb behaviour.
5The third kind of information, subcat frame prediction
is implicit, since verb–noun tuples rely on specific frames.
6Genitive objects can also occur in German verb subcate-
gorization frames, but this is extremely rare and verb-specific
and thus not considered in our model.
</footnote>
<table confidence="0.99973525">
V-SUBJ V-OBJAcc V-OBJDat
EP 454,350 332,847 53,711
HGC 712,717 329,830 160,377
Both 1,089,492 607,541 206,764
</table>
<tableCaption confidence="0.954862">
Table 3: Number of verb-noun types extracted
from Europarl (EP) and newspaper data (HGC).
</tableCaption>
<bodyText confidence="0.998712866666667">
that modify nouns (noun–noun modification case
prediction). Typically, these NP modifiers are
genitive NPs. To this end, we integrate noun-
nounGen tuples with their respective frequencies.
These preferences for a certain function (i.e. sub-
ject, object or modifier) are passed on to the sys-
tem at the level of nouns and integrated into the
CRF through the derived probabilities.
The tuples and triples are obtained from
dependency-parsed data by extracting all occur-
rences of the respective relations; table 3 gives an
overview of the number of extracted tuple types.
For the subcategorization information, the verb-
noun tuples (verb-subject, verb-objectA,,, verb-
objectDat) are then grouped as follows:
</bodyText>
<subsectionHeader confidence="0.484642">
tuple gloss Acc Dat Nom
</subsectionHeader>
<bodyText confidence="0.969734476190476">
SchemaN folgenV pattern follow 0 322 19
We compute the probabilities for the verb-noun tu-
ple to occur in the respective functions based on
the relative frequencies. In the case of SchemaN
folgenV , we find that the function of Schema as da-
tive object is predominant (to follow a pattern), but
it can also occur in the subject position (the pat-
tern follows). The fact that two functions are pos-
sible for this noun are reflected in their probabili-
ties. The probabilities are discretized into 5 buck-
ets (Bp=0, B0&lt;p&lt;0.25, B0.25&lt;p&lt;0.5, B0.5&lt;p&lt;0.75,
B0.75&lt;p&lt;1). In contrast, noun modification in
noun-nounGen construction is represented by co-
occurrence frequencies.7
7The frequencies are bucketed to the powers of ten, i.e.
f = 1, 2 &lt; f &lt; 10, 11 &lt; f &lt; 100 , etc. and also f = 0:
this representation allows for a more fine-grained distinction
in the low-to-mid frequency range, providing a good basis
for the decision of whether a given noun-noun pair is a true
noun-nounGen structure or just a random co-occurrence of
two nouns.
</bodyText>
<page confidence="0.979358">
597
</page>
<table confidence="0.998866818181818">
Gloss Stem Tag Acc Dat Nom Verb Gen N1 Gold
1 companies Unternehmen&lt;NN&gt; NN 0.00 0.00 1.00 erhalten – – Nom
2 should sollten&lt;VVFIN&gt; VVFIN – – – – – – –
3 financial finanziell&lt;ADJ&gt; ADJ – – – – – – Acc
4 funding Mittel&lt;NN&gt; NN 1.00 0.00 0.00 erhalten – – Acc
5 for f¨ur APPR&lt;Acc&gt; PRP – – – – – – –
6 the d&lt;ART&gt; ART – – – – – – Acc
7 introduction Einf¨uhrung&lt;NN&gt; NN – – – – – – Acc
8 new neu&lt;ADJ&gt; ADJ – – – – – – Gen
9 technologies Technologie&lt;NN&gt; NN – – – – 100 Einf¨uhrung&lt;NN&gt; Gen
10 obtain erhalten&lt;VVINF&gt; VVINF – – – – – – –
</table>
<tableCaption confidence="0.9786605">
Table 4: Adding subcategorization information into SMT output. (EN input: companies should obtain
financial funding for the introduction of new technologies). On the right, the correct labels are given.
</tableCaption>
<subsectionHeader confidence="0.980052">
4.2 Integrating subcategorization knowledge
</subsectionHeader>
<bodyText confidence="0.999939297297297">
There are two possibilities to integrate subcat-
egorization information into the case prediction
model: (i) It can be integrated into the data set
using the tree-structure provided by the decoder.
Here, verb-noun tuples are extracted from VP and
S structures, and then the probabilities for the dif-
ferent functions are looked up. Similarly, for two
adjacent NPs, the occurrence frequencies of the
respective two nouns are looked up in the list of
noun-nounGen constructions. (ii) The subcatego-
rization information can be integrated based on
the verb-noun tuples obtained by using tuples ob-
tained from source-side dependencies.
The classification task of the CRF consists in
predicting a sequence of labels: case values for
NPs/PPs or no value otherwise, cf. table 4. The
model has access to the basic features stem and
tag, as well as the new features based on subcat-
egorizaion information (explained below), using
unigrams within a window of up to four positions
to the right and the left of the current position, as
well as bigrams and trigrams for stems and tags
(current item + left and/or right item).
An example for integrating subcategorization
features is given in table 4. The first word Un-
ternehmen (companies) is annotated as subject of
erhalten (obtain) with probability 1, and Mittel
(funding) is annotated as direct object of erhal-
ten with probability 1. The word Technologie
(technology) has been marked as a candidate for
a genitive in a noun-nounGen construction8; the
co-occurrence frequency of the tuple Einf¨uhrung-
Technologie (introduction - technology) lies in the
bucket 11...100.
In addition to the probability/frequency of the
respective functions, we also provide the CRF
with bigrams containing the two parts of the tuple,
</bodyText>
<footnote confidence="0.9960445">
8There is no annotation on Einf¨uhrung as the preposition
f¨ur is always in accusative case.
</footnote>
<figure confidence="0.962531222222222">
DE stemmed output derived features
warum&lt;PWAV&gt;
die&lt;ART&gt;
Regierung&lt;NN&gt;&lt;Sg&gt;&lt;Fem&gt; SUBJ V:anordnen
die&lt;ART&gt;
anhaltend&lt;ADJ&gt;
militärisch&lt;ADJ&gt;
Aktion&lt;NN&gt;&lt;Pl&gt;&lt;Fem&gt; OBJ V:anordnen
angeordnet&lt;VVFIN&gt;
</figure>
<figureCaption confidence="0.9924405">
Figure 1: Deriving features from dependency-
parsed English data via the word alignment.
</figureCaption>
<bodyText confidence="0.9968991875">
i.e. verb+noun or the two nouns of possible noun-
nounGen constructions. As can be seen in the ex-
ample in table 4, the subject (line 1) and the verb
(line 10) are far apart from each other. By pro-
viding the parts of the tuple as unigrams, bigrams
or trigrams to the CRF, all relevant information
is available: verb, noun and the probabilities for
the potential functions of the noun in the sentence.
In addition to bridging the long distance between
verbs and subcategorized nouns, a very common
problem for German, this type of precise informa-
tion also helps to close the gap between the well-
formed training data and the broken SMT-output
as it replaces to a certain extent the target-language
context information (n-grams of stems or lemmas
within a small window).
</bodyText>
<subsectionHeader confidence="0.998544">
4.3 Integrating source-side features
</subsectionHeader>
<bodyText confidence="0.998349153846154">
For predicting case in SMT output, information
about an NP’s function in the input sentence is
essential. Syntax-semantic functions can be iso-
morphic (e.g., English subjects and objects may
have the same function in a German translation),
but this is not necessarily the case. Despite this,
an important advantage of integrating source-side
features is that the well-formed source-side text
can be reliably parsed, whereas SMT output is of-
ten disfluent and cannot be reliably parsed.
The English features are obtained from
dependency-parsed data (Choi and Palmer, 2012).
The relevant annotation of the parser is transferred
</bodyText>
<figure confidence="0.999046636363636">
EN input
why
the
government
ordered
the
ongoing
military
actions
SUBJ
OBJ
</figure>
<page confidence="0.993104">
598
</page>
<bodyText confidence="0.999938333333333">
to the SMT output via word alignment. We focus
on English subjects, direct objects and noun-of-
noun structures (often equivalent to noun-nounGen
phrases on the German side): these structures
are generally likely to correspond to each other
within source and target language. In contrast
to the subcategorization-based information, the
difference between well-formed training data and
disfluent SMT output tends to work to our benefit
here: while the parallel sentences of the training
data were manually translated with the objective
to produce good target-language sentences, the
syntactic structures of the source and target
sentences are often diverging. In contrast, the
SMT system often produces more isomorphic
translations, which is helpful for annotating
source-side features on the target language.
Figure 1 shows the process of integrating
source-side features: for each German noun that
is aligned with an English noun labelled as subject
or direct object, this annotation is transferred to the
target-side. Using the English dependency struc-
tures, the verb subcategorizing the respective noun
is identified, and via the alignment, the equivalent
German verb is obtained. Similarly, candidates for
noun-nounGen structures are identified by extract-
ing and aligning English noun-of-noun phrases.
</bodyText>
<sectionHeader confidence="0.971526" genericHeader="evaluation">
5 Experiments and evaluation
</sectionHeader>
<bodyText confidence="0.99997475">
In this section, we present experiments using dif-
ferent feature combinations. We also present a
manual evaluation of our best system which shows
that the new features improve translation quality.
</bodyText>
<subsectionHeader confidence="0.990707">
5.1 Data and experimental setup
</subsectionHeader>
<bodyText confidence="0.962764633333333">
We use the hierarchical translation system that
comes with the Moses SMT-package and GIZA++
to compute the word alignment, using the “grow-
diag-final-and” heuristics. The rule table was
computed with the default parameter setting for
GHKM extraction (Galley et al., 2004) in the im-
plementation by Williams and Koehn (2012).
Our training data contains 1,485,059 parallel
sentences9; the German part of the parallel data
is used as the target-side language model. The dev
and test sets (1025/1026 lines) are wmt-2009-a/b.
For predicting the grammatical features, we
used the Wapiti Toolkit (Lavergne et al., 2010).10
9English/German data released for the 2009 ACL Work-
shop on Machine Translation shared task.
10To eliminate irrelevant features, we use L1 regulariza-
We train four CRFs on data prepared as shown
in section 3. The corpora used for the extrac-
tion of subcategorization tuples were Europarl and
German newspaper data (200 million words). We
choose this particular data combination in order to
provide data that matches the training data, as well
as to add new data of the test set’s domain (news).
The German part of Europarl was dependency-
parsed with Bohnet (2010), and subcategorization
information was extracted as described in Scheible
et al. (2013); the newspaper data (HGC - Huge
German Corpus) was parsed with Schmid (2000),
and subcategorization information was extracted
as described in Schulte im Walde (2002b).
</bodyText>
<subsectionHeader confidence="0.673862">
5.2 Results
</subsectionHeader>
<bodyText confidence="0.9857995">
We report results of two types of systems (ta-
ble 5): first, a regular translation system built on
surface forms (i.e., normal text) and second, four
inflection prediction systems. The first inflection
prediction system (1) uses a simple case predic-
tion model, whereas the remaining systems are
enriched with (2) subcategorization information
(cf. section 4.2), (3) source-side features (cf. sec-
tion 4.3), and (4) both source-side features and
subcategorization information. In (2) and (4), the
subcategorization information was included using
tuples obtained from source-side dependencies11.
The simple prediction system corresponds to that
presented in section 3; for all inflection predic-
tion systems, the same SMT output and models for
number, gender and strong/weak inflection were
used; thus the only difference with the simple pre-
diction system is the model for case prediction.
We present three types of evaluation: BLEU
scores (Papineni et al., 2001), prediction accuracy
on clean data and a manual evaluation of the best
system in section 5.3.
Table 5 gives results in case-insensitive BLEU.
While the inflection prediction systems (1-4) are
significantly12 better than the surface-form sys-
tem (0), the different versions of the inflection sys-
tems are not distinguishable in terms of BLEU;
however, our manual evaluation shows that the
new features have a positive impact on translation
quality.
tion; the regularization parameter is optimized on held out
data.
</bodyText>
<footnote confidence="0.99582">
11Using tuples extracted from the target-side parse tree
(produced by the decoder) results in a BLEU score of 14.00.
12We used Kevin Gimpel’s implementation of pairwise
bootstrap resampling with 1000 samples.
</footnote>
<page confidence="0.990355">
599
</page>
<table confidence="0.998941">
0 1 2 3 4
surface simple subcat. features source-side source-side
system prediction (tuples from EN side) features + subcat. featues
BLEU 13.43 14.02 14.05 14.10 14.17
Clean – 85.05% 85.65% 85.61% 85.81%
</table>
<tableCaption confidence="0.999792">
Table 5: Results of the simple prediction vs. three systems enriched with extra features.
</tableCaption>
<bodyText confidence="0.99996194117647">
One problem with using BLEU as an evalua-
tion metric is that it is a precision-oriented met-
ric and tends to reward fluency rather than ade-
quacy (see (Wu and Fung, 2009a; Liu and Gildea,
2010)). As we are working on improving ade-
quacy, this will not be fully reflected by BLEU.
Furthermore, not all components of an NP do nec-
essarily change their inflection with a new case
value; it might happen that the only indicator for
the case of an NP is the determiner: er sieht [den
alten Mann]NPacc (he sees the old man) vs. er
folgt [dem alten Mann]NPdat (he follows the old
man). While the case marking of NPs is essential
for comprehensibility, one changed word per noun
phrase is hardly enough to be reflected by BLEU.
An alternative to study the effectiveness of the
case prediction model is to evaluate the prediction
accuracy on parsed clean data, i.e. not on SMT
output. In this case, we measure (using the dev
set) how often the case of an NP is predicted cor-
rectly13. In all cases, the prediction accuracy is
better for the enriched systems. This shows that
the additional features improve the model, but also
that a gain in prediction accuracy on clean data is
not necessarily related to a gain in BLEU. We ob-
served that the more complex the model, the less
robust it is to differences between the test data
and the training data. Related to this problem,
we observed that high-order n-gram POS/lemma-
based features in the simple prediction (sequences
of lemmas and tags) are given too much weight in
training and thus make it difficult for the new fea-
tures to have a larger impact, so we restricted the
n-gram order of this type of feature to trigrams.
</bodyText>
<subsectionHeader confidence="0.999534">
5.3 Manual evaluation of the best system
</subsectionHeader>
<bodyText confidence="0.999917">
In order to provide a better understanding of the
impact of the presented features, in particular to
see whether there is an improvement in adequacy,
we carried out a manual evaluation comparing sys-
</bodyText>
<footnote confidence="0.5275934">
13The numbers in table 5 are artificially high and downplay
the difference as they also include cases which are very easy
to predict, such as nouns in PPs where only one value for case
is possible. We measure how many case labels were correctly
predicted, not correct inflected forms.
</footnote>
<table confidence="0.998939888888889">
enriched simple equal
preferred preferred
(a) person 1 23 11 12
person 2 21 8 17
person 3 26 11 9
(b) person 1 23 5 18
person 2 21 11 14
person 3 29 8 9
(c) agreement 17 2 6
</table>
<tableCaption confidence="0.958633">
Table 6: Manual evaluation of 46 sentences: with-
</tableCaption>
<listItem confidence="0.73521">
out (a) and with (b) access to EN input, and the
annotators’ agreement in the second part (c).
</listItem>
<bodyText confidence="0.99975425">
tem (4) with the simple prediction system (1).
From the set of different sentences between the
simple prediction system and the enriched system
(144 of 1026), we evaluated those where the En-
glish input sentence was between 8 and 25 words
long (46 sentences in total). We specifically re-
stricted the test set in order to provide sentences
which are less difficult to annotate, as longer sen-
tences are often very disfluent and too hard to rate.
Most of the sentences in the evaluation set differ
only in the realization of one NP. For comparing
the two systems, the sentences were presented in
random order to 3 native speakers of German.
The evaluation consists of two parts: first, the
participants were asked to decide which sentence
is better without being given the English input
(this measures fluency). In the second part, they
should to mark that sentence which better repro-
duces the content of the English input sentence
(this measures adequacy). The test set is the same
for both tasks, the only difference being that the
English input is given in the second part. The re-
sults are given in table 6. Summarizing we can
say that the participants prefer the enriched sys-
tem over the simple system in both parts; there is a
high agreement (17 cases) in decisions over those
sentences which were rated as enriched better.
When looking at the pairwise inter-annotator
agreement for the task of annotating the test-set
with the 3 possible labels enriched preferred, sim-
ple preferred and no preference, we find that the
annotators P1 and P2 have a substantial agreement
</bodyText>
<page confidence="0.98916">
600
</page>
<table confidence="0.999649133333333">
1 input hundreds of policemen were on alert, and [a helicopter]Subj circled the area with searchlights .
simple
enriched
Hunderte von Polizisten auf Trab , und [einen Helikopter]Acc eingekreist das Gebiet mit searchlights.
Hunderte von Polizisten auf Trab , und [ein Helikopter]Nom eingekreist das Gebiet mit searchlights .
2 input while 38 %percent put [their trust]Obj in viktor orb´an .
simple
enriched
w¨ahrend 38 % [ihres Vertrauens]Ge,,, schenken in Viktor Orb´an .
w¨ahrend 38 % [ihr Vertrauen]Acc schenken in Viktor Orb´an .
3 input more than $ 100 billion will enter [the monetary markets]Obj by means of public sales.
simple
enriched
mehr als 100 Milliarden Dollar werden durch ¨offentlichen Verkauf [der Geldm¨arkte]Ge,,, treten .
mehr als 100 Milliarden Dollar werden durch ¨offentlichen Verkauf [die Geldm¨arkte]Acc treten .
</table>
<tableCaption confidence="0.999768">
Table 7: Output from the simple system (1) and the enriched system (4).
</tableCaption>
<bodyText confidence="0.999973105263158">
in terms of Kappa (n = 0.6184), whereas the agree-
ment of P3 with P1/P2 respectively leads to lower
scores (n = 0.4467 and n = 0.3596). However, the
annotators tend to agree well on sentences with
the label enriched preferred, but largely disagree
on sentences labelled as either simple preferred or
no preference. The number of decisions where all
three annotators agree on a label when given the
English input is listed in table 6(c): for example,
only two sentences were given the label baseline is
better by all three annotators. This outcome shows
how difficult it is to rate disfluent SMT output. For
evaluating the case prediction system, the distinc-
tion between enriched preferred and enriched dis-
preferred is the most important question to answer.
Redefining the annotation task to annotating only
two values by grouping the labels simple preferred
and no preference into one annotation possibility
leads to n = 0.7391, n = 0.4048 and n = 0.5652.
</bodyText>
<subsectionHeader confidence="0.872176">
5.4 Examples
</subsectionHeader>
<bodyText confidence="0.99971496969697">
Table 7 shows some examples for output from the
simple system and the system using source-side
and subcategorization features. In the first sen-
tence, the subject NP a helicopter was inflected
as a direct object in the simple system, but as a
subject in the enriched system, which was pre-
ferred by all three annotators. In the second sen-
tence, the NP their trust, i.e. a direct object of put,
was incorrectly predicted as genitive-modifier of
38 % (i.e. 38 % of their trust) in the simple sys-
tem. The enriched system made use of the prefer-
ence for accusative for the pair Vertrauen schenken
(place trust), correctly inflecting this NP as di-
rect object. Interestingly, only two annotators pre-
ferred the enriched system, whereas one was unde-
cided. The third sentence illustrates how difficult
it is to rate case marking on disfluent SMT output:
there are two possibilities to translate enter the
money market; the direct equivalent of the English
phrase (den GeldmarktA, betreten), or via the use
of a prepositional phrase (auf den GeldmarktA,
treten: “to step into the money market”). The
SMT-output contains a mix of both, i.e. the verb
treten (instead of betreten), but without the prepo-
sition, which cannot lead to a fully correct inflec-
tion. While the inflection of the simple system (a
genitive construction meaning the public sales of
the money market) is definitely wrong, the inflec-
tion obtained in the enriched system is not use-
ful either, due to the structure of the translation14.
This difficulty is also reflected by the annotators,
who gave twice the label no preference and once
the label enriched better.
</bodyText>
<sectionHeader confidence="0.999233" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999980642857143">
We illustrated the necessity of using external
knowledge sources like subcategorization infor-
mation for modelling case for English to Ger-
man translation. We presented a translation sys-
tem making use of a subcategorization database
together with source-side features. Our method
is language-independent with regard to the source
language; furthermore, no language-specific high-
quality semantic annotation is needed for the tar-
get language, but the data required to model the
subcategorization preferences can be obtained us-
ing standard NLP techniques. We showed in a
manual evaluation that the proposed features have
a positive impact on translation quality.
</bodyText>
<sectionHeader confidence="0.994957" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.937376777777778">
This work was funded by the DFG Research
Project Distributional Approaches to Semantic Re-
latedness (Marion Weller), the DFG Heisenberg
Fellowship SCHU-2580/1-1 (Sabine Schulte im
Walde), as well as by the Deutsche Forschungsge-
meinschaft grant Models of Morphosyntax for Sta-
tistical Machine Translation (Alexander Fraser).
14Furthermore, with treten being polysemous, die
Geldm¨arkte treten can also mean to kick the money markets.
</bodyText>
<page confidence="0.997625">
601
</page>
<sectionHeader confidence="0.986251" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999402644859813">
Bernd Bohnet. 2010. Top Accuracy and Fast Depen-
dency Parsing is not a Contradiction. In Proceed-
ings of the 23rd International Conference on Com-
putational Linguistics (COLING) 2010, pages 89–
97, Beijing, August.
Ted Briscoe and John Carroll. 1997. Automatic Ex-
traction of Subcategorization from Corpora. In Pro-
ceedings of the 5th ACL Conference on Applied Nat-
ural Language Processing, pages 356–363, Wash-
ington, DC.
John Carroll and Alex C. Fang. 2004. The Auto-
matic Acquisition of Verb Subcategorisations and
their Impact on the Performance of an HPSG Parser.
In Proceedings of the 1st International Joint Confer-
ence on Natural Language Processing, pages 107–
114, Sanya City, China.
John Carroll, Guido Minnen, and Ted Briscoe. 1998.
Can Subcategorisation Probabilities Help a Sta-
tistical Parser? In Proceedings of the 6th
ACL/SIGDAT Workshop on Very Large Corpora,
Montreal, Canada.
Jinho D. Choi and Martha Palmer. 2012. Getting the
Most out of Transition-Based Dependency Parsing.
In Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics: Human
Language Technologies.
Charles J. Fillmore, Christopher R. Johnson, and
Miriam R.L. Petruck. 2003. Background to
FrameNet. International Journal of Lexicography,
16:235–250.
Alexander Fraser, Marion Weller, Aoife Cahill, and Fa-
bienne Cap. 2012. Modeling Inflection and Word-
Formation in SMT. In Proceedings of the the Euro-
pean Chapter of the Association for Computational
Linguistics (EACL), Avignon, France.
Michel Galley, Mark Hopkins, Kevin Knight, and
Daniel Marcu. 2004. What’s in a Translation Rule?
In Proceedings of the Human Language Technology
and North American Association for Computational
Linguistics Conference (HLT-NAACL).
Spence Green and John DeNero. 2012. A Class-
Based Agreement Model for Generating Accurately
Inflected Translations. pages 146–155.
Bryant Huang and Kevin Knight. 2006. Relabel-
ing Syntax Trees to Improve Syntax-Based Machine
Translation Quality. In Proceedings of the Hu-
man Language Technology Conference of the North
American Chapter of the ACL.
Minwoo Jeong, Kristina Toutanova, Hisami Suzuki,
and Chris Quirk. 2010. A Discriminative Lexicon
Model for Complex Morphology. In Proceedings of
the Ninth Conference of the Association for Machine
Translation in the Americas (AMTA 2010).
Ahmed El Kholy and Nizar Habash. 2012. Translate,
Predict or Generate: Modeling Rich Morphology in
Statistical Machine Translation. In European Asso-
ciation for Machine Translation.
Karin Kipper Schuler. 2006. VerbNet: A Broad-
Coverage, Comprehensive Verb Lexicon. Ph.D. the-
sis, University of Pennsylvania, Computer and In-
formation Science.
Katrin Kirchhoff, Daniel Capurro, and Anne Turner.
2012. Evaluating User Preferences in Machine
Translation Using Conjoint Analysis. In European
Association for Machine Translation.
Upali S. Kohomban and Wee Sun Lee. 2005. Learning
Semantic Classes for Word Sense Disambiguation.
In Proceedings of the 43rd Annual Meeting on Asso-
ciation for Computational Linguistics, pages 34–41,
Ann Arbor, MI.
Thomas Lavergne, Olivier Capp´e, and Franc¸ois Yvon.
2010. Practical very large scale CRFs. In Proceed-
ings the 48th Annual Meeting of the Association for
Computational Linguistics (ACL), pages 504–513.
Association for Computational Linguistics, July.
Beth Levin. 1993. English Verb Classes and Alterna-
tions. The University of Chicago Press.
Ding Liu and Daniel Gildea. 2008. Improved Tree-
to-String Transducers for Machine Translation. In
ACL Workshop on Statistical Machine Translation.
Ding Liu and Daniel Gildea. 2010. Semantic Role
Features for Machine Translation. In Proceedings
of the 23rd International Conference on Computa-
tional Linguistics (COLING) 2010.
Diana McCarthy, Rob Koeling, Julie Weeds, and John
Carroll. 2007. Unsupervised Acquisition of Pre-
dominant Word Senses. Computational Linguistics,
33(4):553–590.
C´edric Messiant. 2008. A Subcategorization Acqui-
sition System for French Verbs. In Proceedings of
the Student Research Workshop at the 46th Annual
Meeting of the Association for Computational Lin-
guistics, pages 55–60, Columbus, OH.
Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005. The Proposition Bank: An annotated Re-
source of Semantic Roles. Computational Linguis-
tics, 31(1):71–106.
Kishore A. Papineni, Salim Roukos, Todd Ward, and
Wei-Jing Zhu. 2001. BLEU: a Method for Auto-
matic Evaluation of Machine Translation. Technical
Report RC22176 (W0109-022), IBM Research Di-
vision, Thomas J. Watson Research Center.
Anoop Sarkar and Daniel Zeman. 2000. Automatic
Extraction of Subcategorization Frames for Czech.
In Proceedings of the 18th International Conference
on Computational Linguistics, Saarbr¨ucken, Ger-
many.
</reference>
<page confidence="0.978617">
602
</page>
<reference confidence="0.999786647058823">
Silke Scheible, Sabine Schulte im Walde, Marion
Weller, and Max Kisselew. 2013. A Compact but
Linguistically Detailed Database for German Verb
Subcategorisation relying on Dependency Parses
from a Web Corpus. In Proceedings of the 8th Web
as Corpus Workshop, Lancaster, UK. To appear.
Helmut Schmid, Arne Fitschen, and Ulrich Heid.
2004. SMOR: a German Computational Morphol-
ogy Covering Derivation, Composition, and Inflec-
tion. In Proceedings of the Fourth International
Conference on Language Resources and Evaluation
(LREC).
Helmut Schmid. 2000. LoPar: Design and Imple-
mentation. Arbeitspapiere des Sonderforschungs-
bereichs 340 ‘Linguistic Theory and the Foun-
dations of Computational Linguistics’ 149, Insti-
tut f¨ur Maschinelle Sprachverarbeitung, Universit¨at
Stuttgart.
Helmut Schmid. 2004. Efficient Parsing of Highly
Ambiguous Context-Free Grammars with Bit Vec-
tors.
Sabine Schulte im Walde. 2002a. A Subcategorisa-
tion Lexicon for German Verbs induced from a Lex-
icalised PCFG. In Proceedings of the 3rd Confer-
ence on Language Resources and Evaluation, vol-
ume IV, pages 1351–1357, Las Palmas de Gran Ca-
naria, Spain.
Sabine Schulte im Walde. 2002b. A Subcategorisa-
tion Lexicon for German Verbs induced from a Lex-
icalised PCFG. In Proceedings of the 3rd Confer-
ence on Language Resources and Evaluation, vol-
ume IV, pages 1351–1357, Las Palmas de Gran Ca-
naria, Spain.
Sara Stymne and Nicola Cancedda. 2011. Productive
Generation of Compound Words in Statistical Ma-
chine Translation. In Proceedings of the Sixth Work-
shop on Machine Translation.
Mihai Surdeanu, Sanda Harabagiu, John Williams, and
Paul Aarseth. 2003. Using Predicate-Argument
Structures for Information Extraction. In Proceed-
ings of the 41st Annual Meeting of the Association
for Computational Linguistics, pages 8–15, Sap-
poro, Japan.
Kristina Toutanova, Hisami Suzuki, and Achim Ruopp.
2008. Applying Morphology Generation Models to
Machine Translation. In Proceedings of the 46th An-
nual Meeting of the Association for Computational
Linguistics (ACL): Human Language Technologies.
Giulia Venturi1, Simonetta Montemagni, Simone
Marchi, Yutaka Sasaki, Paul Thompson, John Mc-
Naught, and Sophia Ananiadou. 2009. Bootstrap-
ping a Verb Lexicon for Biomedical Information
Extraction. In Alexander Gelbukh, editor, Linguis-
tics and Intelligent Text Processing, pages 137–148.
Springer, Heidelberg.
Philip Williams and Phillipp Koehn. 2012. GHKM-
Rule Extraction and Scope-3 Parsing in Moses. In
Proceedings of the 7th Workshop on Statistical Ma-
chine Translation, ACL.
Dekai Wu and Pascale Fung. 2009a. Can Semantic
Role Labeling Improve SMT? In Proceedings of the
13th Annual Conference of the European Associa-
tion for Machine Translation (EAMT).
Dekai Wu and Pascale Fung. 2009b. Semantic Roles
for SMT: A Hybrid two-pass Model. In Proceed-
ings of the North American Chapter of the Associa-
tion for Computational Linguistics and Human Lan-
guage Technologies Conference (NAACL-HLT).
</reference>
<page confidence="0.999122">
603
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.577264">
<title confidence="0.8719082">Using subcategorization knowledge to improve case for translation to German Schulte im f¨ur Maschinelle f¨ur Informations- Sprachverarbeitung und Sprachverarbeitung</title>
<author confidence="0.783146">Universit¨at Stuttgart Ludwig-Maximilians-Universit¨at M¨unchen</author>
<email confidence="0.99159">fraser@cis.uni-muenchen.de</email>
<abstract confidence="0.999543615384616">This paper demonstrates the need and impact of subcategorization information for SMT. We combine (i) features on sourceside syntactic subcategorization and (ii) an external knowledge base with quantitative, dependency-based information about target-side subcategorization frames. A manual evaluation of an English-to- German translation task shows that the subcategorization information has a positive impact on translation quality through better prediction of case.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Bernd Bohnet</author>
</authors>
<title>Top Accuracy and Fast Dependency Parsing is not a Contradiction.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (COLING)</booktitle>
<pages>89--97</pages>
<location>Beijing,</location>
<contexts>
<context position="29650" citStr="Bohnet (2010)" startWordPosition="4672" endWordPosition="4673">we used the Wapiti Toolkit (Lavergne et al., 2010).10 9English/German data released for the 2009 ACL Workshop on Machine Translation shared task. 10To eliminate irrelevant features, we use L1 regularizaWe train four CRFs on data prepared as shown in section 3. The corpora used for the extraction of subcategorization tuples were Europarl and German newspaper data (200 million words). We choose this particular data combination in order to provide data that matches the training data, as well as to add new data of the test set’s domain (news). The German part of Europarl was dependencyparsed with Bohnet (2010), and subcategorization information was extracted as described in Scheible et al. (2013); the newspaper data (HGC - Huge German Corpus) was parsed with Schmid (2000), and subcategorization information was extracted as described in Schulte im Walde (2002b). 5.2 Results We report results of two types of systems (table 5): first, a regular translation system built on surface forms (i.e., normal text) and second, four inflection prediction systems. The first inflection prediction system (1) uses a simple case prediction model, whereas the remaining systems are enriched with (2) subcategorization i</context>
</contexts>
<marker>Bohnet, 2010</marker>
<rawString>Bernd Bohnet. 2010. Top Accuracy and Fast Dependency Parsing is not a Contradiction. In Proceedings of the 23rd International Conference on Computational Linguistics (COLING) 2010, pages 89– 97, Beijing, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
</authors>
<title>Automatic Extraction of Subcategorization from Corpora.</title>
<date>1997</date>
<booktitle>In Proceedings of the 5th ACL Conference on Applied Natural Language Processing,</booktitle>
<pages>356--363</pages>
<location>Washington, DC.</location>
<contexts>
<context position="18831" citStr="Briscoe and Carroll (1997)" startWordPosition="2956" endWordPosition="2959">m&gt;&lt;Sg&gt; Fem.Acc.Sg.Wk Stabilitit stability Table 2: Overview of the inflection process: the stem markup is highlighted in the SMT output. discourse. On the one hand, this has led to a range of manually or semi-automatically developed lexical resources focusing on verb information, such as the Levin classes (Levin, 1993), VerbNet (Kipper Schuler, 2006), FrameNet4 (Fillmore et al., 2003), and PropBank (Palmer et al., 2005). On the other hand, we find automatic approaches to the induction of verb subcategorization information at the syntax-semantics interface for a large number of languages, e.g. Briscoe and Carroll (1997) for English; Sarkar and Zeman (2000) for Czech; Schulte im Walde (2002a) for German; Messiant (2008) for French. This basic kind of verb knowledge has been shown to be useful in many NLP tasks such as information extraction (Surdeanu et al., 2003; Venturi1 et al., 2009), parsing (Carroll et al., 1998; Carroll and Fang, 2004) and word sense disambiguation (Kohomban and Lee, 2005; McCarthy et al., 2007). 4.1 Extracting subcategorization information As described in the introductory section, we make use of two5 major kinds of subcategorization information. Verb–noun tuples referring to specific s</context>
</contexts>
<marker>Briscoe, Carroll, 1997</marker>
<rawString>Ted Briscoe and John Carroll. 1997. Automatic Extraction of Subcategorization from Corpora. In Proceedings of the 5th ACL Conference on Applied Natural Language Processing, pages 356–363, Washington, DC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
<author>Alex C Fang</author>
</authors>
<title>The Automatic Acquisition of Verb Subcategorisations and their Impact on the Performance of an HPSG Parser.</title>
<date>2004</date>
<booktitle>In Proceedings of the 1st International Joint Conference on Natural Language Processing,</booktitle>
<pages>107--114</pages>
<location>Sanya City, China.</location>
<contexts>
<context position="19158" citStr="Carroll and Fang, 2004" startWordPosition="3012" endWordPosition="3015">(Kipper Schuler, 2006), FrameNet4 (Fillmore et al., 2003), and PropBank (Palmer et al., 2005). On the other hand, we find automatic approaches to the induction of verb subcategorization information at the syntax-semantics interface for a large number of languages, e.g. Briscoe and Carroll (1997) for English; Sarkar and Zeman (2000) for Czech; Schulte im Walde (2002a) for German; Messiant (2008) for French. This basic kind of verb knowledge has been shown to be useful in many NLP tasks such as information extraction (Surdeanu et al., 2003; Venturi1 et al., 2009), parsing (Carroll et al., 1998; Carroll and Fang, 2004) and word sense disambiguation (Kohomban and Lee, 2005; McCarthy et al., 2007). 4.1 Extracting subcategorization information As described in the introductory section, we make use of two5 major kinds of subcategorization information. Verb–noun tuples referring to specific syntactic functions within verb subcategorization (verb–noun subcat case prediction) are integrated with an associated probability for accusative (direct object), dative (indirect object) and nominative (subject).6 Further to the subject and object noun phrases, the subcategorization information provides quantitative triples f</context>
</contexts>
<marker>Carroll, Fang, 2004</marker>
<rawString>John Carroll and Alex C. Fang. 2004. The Automatic Acquisition of Verb Subcategorisations and their Impact on the Performance of an HPSG Parser. In Proceedings of the 1st International Joint Conference on Natural Language Processing, pages 107– 114, Sanya City, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
<author>Guido Minnen</author>
<author>Ted Briscoe</author>
</authors>
<title>Can Subcategorisation Probabilities Help a Statistical Parser?</title>
<date>1998</date>
<booktitle>In Proceedings of the 6th ACL/SIGDAT Workshop on Very Large Corpora,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="19133" citStr="Carroll et al., 1998" startWordPosition="3008" endWordPosition="3011">Levin, 1993), VerbNet (Kipper Schuler, 2006), FrameNet4 (Fillmore et al., 2003), and PropBank (Palmer et al., 2005). On the other hand, we find automatic approaches to the induction of verb subcategorization information at the syntax-semantics interface for a large number of languages, e.g. Briscoe and Carroll (1997) for English; Sarkar and Zeman (2000) for Czech; Schulte im Walde (2002a) for German; Messiant (2008) for French. This basic kind of verb knowledge has been shown to be useful in many NLP tasks such as information extraction (Surdeanu et al., 2003; Venturi1 et al., 2009), parsing (Carroll et al., 1998; Carroll and Fang, 2004) and word sense disambiguation (Kohomban and Lee, 2005; McCarthy et al., 2007). 4.1 Extracting subcategorization information As described in the introductory section, we make use of two5 major kinds of subcategorization information. Verb–noun tuples referring to specific syntactic functions within verb subcategorization (verb–noun subcat case prediction) are integrated with an associated probability for accusative (direct object), dative (indirect object) and nominative (subject).6 Further to the subject and object noun phrases, the subcategorization information provid</context>
</contexts>
<marker>Carroll, Minnen, Briscoe, 1998</marker>
<rawString>John Carroll, Guido Minnen, and Ted Briscoe. 1998. Can Subcategorisation Probabilities Help a Statistical Parser? In Proceedings of the 6th ACL/SIGDAT Workshop on Very Large Corpora, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinho D Choi</author>
<author>Martha Palmer</author>
</authors>
<title>Getting the Most out of Transition-Based Dependency Parsing.</title>
<date>2012</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association</booktitle>
<contexts>
<context position="26783" citStr="Choi and Palmer, 2012" startWordPosition="4234" endWordPosition="4237"> small window). 4.3 Integrating source-side features For predicting case in SMT output, information about an NP’s function in the input sentence is essential. Syntax-semantic functions can be isomorphic (e.g., English subjects and objects may have the same function in a German translation), but this is not necessarily the case. Despite this, an important advantage of integrating source-side features is that the well-formed source-side text can be reliably parsed, whereas SMT output is often disfluent and cannot be reliably parsed. The English features are obtained from dependency-parsed data (Choi and Palmer, 2012). The relevant annotation of the parser is transferred EN input why the government ordered the ongoing military actions SUBJ OBJ 598 to the SMT output via word alignment. We focus on English subjects, direct objects and noun-ofnoun structures (often equivalent to noun-nounGen phrases on the German side): these structures are generally likely to correspond to each other within source and target language. In contrast to the subcategorization-based information, the difference between well-formed training data and disfluent SMT output tends to work to our benefit here: while the parallel sentences</context>
</contexts>
<marker>Choi, Palmer, 2012</marker>
<rawString>Jinho D. Choi and Martha Palmer. 2012. Getting the Most out of Transition-Based Dependency Parsing. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles J Fillmore</author>
<author>Christopher R Johnson</author>
<author>Miriam R L Petruck</author>
</authors>
<title>Background to FrameNet.</title>
<date>2003</date>
<journal>International Journal of Lexicography,</journal>
<pages>16--235</pages>
<contexts>
<context position="18592" citStr="Fillmore et al., 2003" startWordPosition="2919" endWordPosition="2922">ure and the meaning of sentences and 596 SMT output predicted features inflected forms gloss beeinflussen&lt;VVFIN&gt; – beeinflussen influence d&lt;ART&gt; Fem.Acc.Sg.St die the politisch&lt;ADJ&gt; Fem.Acc.Sg.Wk politische political Stabilit¨at&lt;NN&gt;&lt;Fem&gt;&lt;Sg&gt; Fem.Acc.Sg.Wk Stabilitit stability Table 2: Overview of the inflection process: the stem markup is highlighted in the SMT output. discourse. On the one hand, this has led to a range of manually or semi-automatically developed lexical resources focusing on verb information, such as the Levin classes (Levin, 1993), VerbNet (Kipper Schuler, 2006), FrameNet4 (Fillmore et al., 2003), and PropBank (Palmer et al., 2005). On the other hand, we find automatic approaches to the induction of verb subcategorization information at the syntax-semantics interface for a large number of languages, e.g. Briscoe and Carroll (1997) for English; Sarkar and Zeman (2000) for Czech; Schulte im Walde (2002a) for German; Messiant (2008) for French. This basic kind of verb knowledge has been shown to be useful in many NLP tasks such as information extraction (Surdeanu et al., 2003; Venturi1 et al., 2009), parsing (Carroll et al., 1998; Carroll and Fang, 2004) and word sense disambiguation (Ko</context>
</contexts>
<marker>Fillmore, Johnson, Petruck, 2003</marker>
<rawString>Charles J. Fillmore, Christopher R. Johnson, and Miriam R.L. Petruck. 2003. Background to FrameNet. International Journal of Lexicography, 16:235–250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Fraser</author>
<author>Marion Weller</author>
<author>Aoife Cahill</author>
<author>Fabienne Cap</author>
</authors>
<title>Modeling Inflection and WordFormation in SMT.</title>
<date>2012</date>
<booktitle>In Proceedings of the the European Chapter of the Association for Computational Linguistics (EACL),</booktitle>
<location>Avignon, France.</location>
<contexts>
<context position="9787" citStr="Fraser et al. (2012)" startWordPosition="1493" endWordPosition="1496">2 Previous work Previous work has already introduced the idea of generating inflected forms as a post-processing step for a translation system that has been stripped of (most) target-language-specific features. Toutanova et al. (2008) and Jeong et al. (2010) built translation systems that predict inflected word forms based on a large array of morphological and syntactic features, obtained from both source and target side. Kholy and Habash (2012) and Green and DeNero (2012) work on English to Arabic translation and model gender, number and definiteness, focusing primarily on improving fluency. Fraser et al. (2012) used a phrase-based system to transfer stems and generated inflected forms based on the stems and their morphological features. For case prediction, they trained a CRF with access to lemmas and POS-tags within a given window. We re-implemented the system by Fraser et al. as a hierarchical machine translation system using a string-to-tree setup. In contrast to the flat phrase-based setting of Fraser et al. (2012), syntactic trees on the SMT output allow us to work with verb–noun structures, which are relevant for case prediction. While the CRF used for case prediction in Fraser et al. (2012) h</context>
<context position="15235" citStr="Fraser et al. (2012)" startWordPosition="2381" endWordPosition="2384">adjectival inflection. The latter feature is German-specific; its values2 (strong/weak) depend on the combination of the other features, as well as on the type of determiner (e.g. definite/indefinite/none). Morphological features are predicted on four separate CRF models, one for each feature. The models for case, number and gender are independent of another, whereas the model for adjectival inflection requires information about these features, and is thus the last one to be computed, taking the output of the 3 other models as part of its input. In contrast, the adjectival inflection model in Fraser et al. (2012) is independent from the other features. Each model has access to stems, POS-tags and the feature to be modelled within a window of four positions to the right and the left of the current position3. 2Note that the values for strong/weak inflection are not always the same over the phrase, but follow a certain pattern depending on the settings of case, number and gender. 3Preliminary experiments showed that larger windows do not improve translation quality. Table 2 illustrates the different steps of the inflection process: the markup (number and gender on nouns) in the stemmed output of the SMT </context>
</contexts>
<marker>Fraser, Weller, Cahill, Cap, 2012</marker>
<rawString>Alexander Fraser, Marion Weller, Aoife Cahill, and Fabienne Cap. 2012. Modeling Inflection and WordFormation in SMT. In Proceedings of the the European Chapter of the Association for Computational Linguistics (EACL), Avignon, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Mark Hopkins</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>What’s in a Translation Rule?</title>
<date>2004</date>
<booktitle>In Proceedings of the Human Language Technology and North American Association for Computational Linguistics Conference (HLT-NAACL).</booktitle>
<contexts>
<context position="13523" citStr="Galley et al., 2004" startWordPosition="2104" endWordPosition="2107">for either dative or accusative. Other words which are subject to feature prediction (e.g. adjectives, articles) are reduced to their stems with no feature markup, as are all remaining words. As sole exception, we keep the inflected forms of verbs (verbal inflection is not modelled). In addition to the translation model, the target-side language model, as well as the reference data for parameter tuning use this representation. 595 3.2 Building a stemmed translation model We use a hierarchical translation system. Instead of translating phrases, a hierarchical system extracts translation rules (Galley et al., 2004) which allow the decoder to provide a tree spanning over the translated sentence. In order to avoid sparsity during rule extraction, we use a string-to-tree setup, where only the target-side part of the data is parsed. Translation rules are of the following form: [X]1 allows [X]2 [NP]1 [NP]2 erlaubt [X]1 allows [X]2 [NP]1 erlaubt [NP]2 This example illustrates how rules can cover the different word ordering possibilities in German. PP nodes are annotated with their respective case, as well as with the lemma of the preposition they contain. In our experiments, this enriched annotation has small</context>
<context position="28747" citStr="Galley et al., 2004" startWordPosition="4524" endWordPosition="4527">n-nounGen structures are identified by extracting and aligning English noun-of-noun phrases. 5 Experiments and evaluation In this section, we present experiments using different feature combinations. We also present a manual evaluation of our best system which shows that the new features improve translation quality. 5.1 Data and experimental setup We use the hierarchical translation system that comes with the Moses SMT-package and GIZA++ to compute the word alignment, using the “growdiag-final-and” heuristics. The rule table was computed with the default parameter setting for GHKM extraction (Galley et al., 2004) in the implementation by Williams and Koehn (2012). Our training data contains 1,485,059 parallel sentences9; the German part of the parallel data is used as the target-side language model. The dev and test sets (1025/1026 lines) are wmt-2009-a/b. For predicting the grammatical features, we used the Wapiti Toolkit (Lavergne et al., 2010).10 9English/German data released for the 2009 ACL Workshop on Machine Translation shared task. 10To eliminate irrelevant features, we use L1 regularizaWe train four CRFs on data prepared as shown in section 3. The corpora used for the extraction of subcategor</context>
</contexts>
<marker>Galley, Hopkins, Knight, Marcu, 2004</marker>
<rawString>Michel Galley, Mark Hopkins, Kevin Knight, and Daniel Marcu. 2004. What’s in a Translation Rule? In Proceedings of the Human Language Technology and North American Association for Computational Linguistics Conference (HLT-NAACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Spence Green</author>
<author>John DeNero</author>
</authors>
<title>A ClassBased Agreement Model for Generating Accurately Inflected Translations.</title>
<date>2012</date>
<pages>146--155</pages>
<contexts>
<context position="9644" citStr="Green and DeNero (2012)" startWordPosition="1469" endWordPosition="1472">their semantic roles were preserved across language. These two findings correspond to the expected uses of our models (i) and (ii), respectively. 2 Previous work Previous work has already introduced the idea of generating inflected forms as a post-processing step for a translation system that has been stripped of (most) target-language-specific features. Toutanova et al. (2008) and Jeong et al. (2010) built translation systems that predict inflected word forms based on a large array of morphological and syntactic features, obtained from both source and target side. Kholy and Habash (2012) and Green and DeNero (2012) work on English to Arabic translation and model gender, number and definiteness, focusing primarily on improving fluency. Fraser et al. (2012) used a phrase-based system to transfer stems and generated inflected forms based on the stems and their morphological features. For case prediction, they trained a CRF with access to lemmas and POS-tags within a given window. We re-implemented the system by Fraser et al. as a hierarchical machine translation system using a string-to-tree setup. In contrast to the flat phrase-based setting of Fraser et al. (2012), syntactic trees on the SMT output allow</context>
</contexts>
<marker>Green, DeNero, 2012</marker>
<rawString>Spence Green and John DeNero. 2012. A ClassBased Agreement Model for Generating Accurately Inflected Translations. pages 146–155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bryant Huang</author>
<author>Kevin Knight</author>
</authors>
<title>Relabeling Syntax Trees to Improve Syntax-Based Machine Translation Quality.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL.</booktitle>
<contexts>
<context position="14431" citStr="Huang and Knight, 2006" startWordPosition="2250" endWordPosition="2253">1 [NP]2 erlaubt [X]1 allows [X]2 [NP]1 erlaubt [NP]2 This example illustrates how rules can cover the different word ordering possibilities in German. PP nodes are annotated with their respective case, as well as with the lemma of the preposition they contain. In our experiments, this enriched annotation has small improvements over the simpler setting with only head categories (details omitted). This outcome, in particular that adding the lemma of the preposition to the PP node helps to improve translation quality, has been observed before in tree restructuring work for improving translation (Huang and Knight, 2006). 3.3 Feature prediction and generation of inflected forms In this section we discuss our focus, which is prediction of case, but also the prediction of number, gender and strong/weak adjectival inflection. The latter feature is German-specific; its values2 (strong/weak) depend on the combination of the other features, as well as on the type of determiner (e.g. definite/indefinite/none). Morphological features are predicted on four separate CRF models, one for each feature. The models for case, number and gender are independent of another, whereas the model for adjectival inflection requires i</context>
</contexts>
<marker>Huang, Knight, 2006</marker>
<rawString>Bryant Huang and Kevin Knight. 2006. Relabeling Syntax Trees to Improve Syntax-Based Machine Translation Quality. In Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minwoo Jeong</author>
<author>Kristina Toutanova</author>
<author>Hisami Suzuki</author>
<author>Chris Quirk</author>
</authors>
<title>A Discriminative Lexicon Model for Complex Morphology.</title>
<date>2010</date>
<booktitle>In Proceedings of the Ninth Conference of the Association for Machine Translation in the Americas (AMTA</booktitle>
<contexts>
<context position="9425" citStr="Jeong et al. (2010)" startWordPosition="1433" endWordPosition="1436">rated that on the one hand 84% of verb syntactic functions in a 50-sentence test corpus projected from Chinese to English, and that on the other hand about 15% of the subjects were not translated into subjects, but their semantic roles were preserved across language. These two findings correspond to the expected uses of our models (i) and (ii), respectively. 2 Previous work Previous work has already introduced the idea of generating inflected forms as a post-processing step for a translation system that has been stripped of (most) target-language-specific features. Toutanova et al. (2008) and Jeong et al. (2010) built translation systems that predict inflected word forms based on a large array of morphological and syntactic features, obtained from both source and target side. Kholy and Habash (2012) and Green and DeNero (2012) work on English to Arabic translation and model gender, number and definiteness, focusing primarily on improving fluency. Fraser et al. (2012) used a phrase-based system to transfer stems and generated inflected forms based on the stems and their morphological features. For case prediction, they trained a CRF with access to lemmas and POS-tags within a given window. We re-imple</context>
</contexts>
<marker>Jeong, Toutanova, Suzuki, Quirk, 2010</marker>
<rawString>Minwoo Jeong, Kristina Toutanova, Hisami Suzuki, and Chris Quirk. 2010. A Discriminative Lexicon Model for Complex Morphology. In Proceedings of the Ninth Conference of the Association for Machine Translation in the Americas (AMTA 2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ahmed El Kholy</author>
<author>Nizar Habash</author>
</authors>
<title>Translate, Predict or Generate: Modeling Rich Morphology in Statistical Machine Translation. In European Association for Machine Translation.</title>
<date>2012</date>
<marker>El Kholy, Habash, 2012</marker>
<rawString>Ahmed El Kholy and Nizar Habash. 2012. Translate, Predict or Generate: Modeling Rich Morphology in Statistical Machine Translation. In European Association for Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin Kipper Schuler</author>
</authors>
<title>VerbNet: A BroadCoverage, Comprehensive Verb Lexicon.</title>
<date>2006</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania, Computer and Information Science.</institution>
<contexts>
<context position="18557" citStr="Schuler, 2006" startWordPosition="2916" endWordPosition="2917">central role for the structure and the meaning of sentences and 596 SMT output predicted features inflected forms gloss beeinflussen&lt;VVFIN&gt; – beeinflussen influence d&lt;ART&gt; Fem.Acc.Sg.St die the politisch&lt;ADJ&gt; Fem.Acc.Sg.Wk politische political Stabilit¨at&lt;NN&gt;&lt;Fem&gt;&lt;Sg&gt; Fem.Acc.Sg.Wk Stabilitit stability Table 2: Overview of the inflection process: the stem markup is highlighted in the SMT output. discourse. On the one hand, this has led to a range of manually or semi-automatically developed lexical resources focusing on verb information, such as the Levin classes (Levin, 1993), VerbNet (Kipper Schuler, 2006), FrameNet4 (Fillmore et al., 2003), and PropBank (Palmer et al., 2005). On the other hand, we find automatic approaches to the induction of verb subcategorization information at the syntax-semantics interface for a large number of languages, e.g. Briscoe and Carroll (1997) for English; Sarkar and Zeman (2000) for Czech; Schulte im Walde (2002a) for German; Messiant (2008) for French. This basic kind of verb knowledge has been shown to be useful in many NLP tasks such as information extraction (Surdeanu et al., 2003; Venturi1 et al., 2009), parsing (Carroll et al., 1998; Carroll and Fang, 2004</context>
</contexts>
<marker>Schuler, 2006</marker>
<rawString>Karin Kipper Schuler. 2006. VerbNet: A BroadCoverage, Comprehensive Verb Lexicon. Ph.D. thesis, University of Pennsylvania, Computer and Information Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Kirchhoff</author>
<author>Daniel Capurro</author>
<author>Anne Turner</author>
</authors>
<title>Evaluating User Preferences in Machine Translation Using Conjoint Analysis.</title>
<date>2012</date>
<booktitle>In European Association for Machine Translation.</booktitle>
<contexts>
<context position="10999" citStr="Kirchhoff et al. (2012)" startWordPosition="1694" endWordPosition="1697">l. (2012) has access to lexical information, it is limited to a certain window size and has no direct information about the relation of verb–noun pairs occurring in the sentence. Using a window of a limited size is particularly problematic for German, as there can be large gaps between the verb and its subcategorized nouns; introducing information about the relation of verbs and nouns helps to bridge such gaps. Furthermore, that model was not able to make effective use of source-side features. One of the objectives of using an inflection prediction model is morphologically well-formed output. Kirchhoff et al. (2012) evaluated user reactions to different error types in machine translation and came to the result that morphological well-formedness has only a marginal impact on the comprehensibility of SMT output in the case of English-Spanish translation. As already discussed, German case is essential to the meaning of the sentence, so this result will not hold for German output. 3 Translation pipeline This section presents an overview of our two-step translation process. In the first step, English input is translated to German stems. In the second step, morphological features are predicted and inflected fo</context>
</contexts>
<marker>Kirchhoff, Capurro, Turner, 2012</marker>
<rawString>Katrin Kirchhoff, Daniel Capurro, and Anne Turner. 2012. Evaluating User Preferences in Machine Translation Using Conjoint Analysis. In European Association for Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Upali S Kohomban</author>
<author>Wee Sun Lee</author>
</authors>
<title>Learning Semantic Classes for Word Sense Disambiguation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>34--41</pages>
<location>Ann Arbor, MI.</location>
<contexts>
<context position="19212" citStr="Kohomban and Lee, 2005" startWordPosition="3020" endWordPosition="3023">3), and PropBank (Palmer et al., 2005). On the other hand, we find automatic approaches to the induction of verb subcategorization information at the syntax-semantics interface for a large number of languages, e.g. Briscoe and Carroll (1997) for English; Sarkar and Zeman (2000) for Czech; Schulte im Walde (2002a) for German; Messiant (2008) for French. This basic kind of verb knowledge has been shown to be useful in many NLP tasks such as information extraction (Surdeanu et al., 2003; Venturi1 et al., 2009), parsing (Carroll et al., 1998; Carroll and Fang, 2004) and word sense disambiguation (Kohomban and Lee, 2005; McCarthy et al., 2007). 4.1 Extracting subcategorization information As described in the introductory section, we make use of two5 major kinds of subcategorization information. Verb–noun tuples referring to specific syntactic functions within verb subcategorization (verb–noun subcat case prediction) are integrated with an associated probability for accusative (direct object), dative (indirect object) and nominative (subject).6 Further to the subject and object noun phrases, the subcategorization information provides quantitative triples for verb–preposition–noun pairs, thus predicting the ca</context>
</contexts>
<marker>Kohomban, Lee, 2005</marker>
<rawString>Upali S. Kohomban and Wee Sun Lee. 2005. Learning Semantic Classes for Word Sense Disambiguation. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 34–41, Ann Arbor, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Lavergne</author>
<author>Olivier Capp´e</author>
<author>Franc¸ois Yvon</author>
</authors>
<title>Practical very large scale CRFs.</title>
<date>2010</date>
<booktitle>In Proceedings the 48th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>504--513</pages>
<marker>Lavergne, Capp´e, Yvon, 2010</marker>
<rawString>Thomas Lavergne, Olivier Capp´e, and Franc¸ois Yvon. 2010. Practical very large scale CRFs. In Proceedings the 48th Annual Meeting of the Association for Computational Linguistics (ACL), pages 504–513. Association for Computational Linguistics, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beth Levin</author>
</authors>
<title>English Verb Classes and Alternations.</title>
<date>1993</date>
<publisher>The University of Chicago Press.</publisher>
<contexts>
<context position="18525" citStr="Levin, 1993" startWordPosition="2911" endWordPosition="2912">r focus, because verbs play a central role for the structure and the meaning of sentences and 596 SMT output predicted features inflected forms gloss beeinflussen&lt;VVFIN&gt; – beeinflussen influence d&lt;ART&gt; Fem.Acc.Sg.St die the politisch&lt;ADJ&gt; Fem.Acc.Sg.Wk politische political Stabilit¨at&lt;NN&gt;&lt;Fem&gt;&lt;Sg&gt; Fem.Acc.Sg.Wk Stabilitit stability Table 2: Overview of the inflection process: the stem markup is highlighted in the SMT output. discourse. On the one hand, this has led to a range of manually or semi-automatically developed lexical resources focusing on verb information, such as the Levin classes (Levin, 1993), VerbNet (Kipper Schuler, 2006), FrameNet4 (Fillmore et al., 2003), and PropBank (Palmer et al., 2005). On the other hand, we find automatic approaches to the induction of verb subcategorization information at the syntax-semantics interface for a large number of languages, e.g. Briscoe and Carroll (1997) for English; Sarkar and Zeman (2000) for Czech; Schulte im Walde (2002a) for German; Messiant (2008) for French. This basic kind of verb knowledge has been shown to be useful in many NLP tasks such as information extraction (Surdeanu et al., 2003; Venturi1 et al., 2009), parsing (Carroll et a</context>
</contexts>
<marker>Levin, 1993</marker>
<rawString>Beth Levin. 1993. English Verb Classes and Alternations. The University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ding Liu</author>
<author>Daniel Gildea</author>
</authors>
<title>Improved Treeto-String Transducers for Machine Translation.</title>
<date>2008</date>
<booktitle>In ACL Workshop on Statistical Machine Translation.</booktitle>
<contexts>
<context position="8716" citStr="Liu and Gildea (2008)" startWordPosition="1315" endWordPosition="1318">un subcategorization or noun–noun modification. Model (ii) predicts case relying on the subcategorization and modification preferences. The combination of our two models approaches a simplified level of semantic role definition but only relies on dependency information that is considerably easier and cheaper to define and obtain than a very high quality semantic parser and/or a corpus annotated with semantic role information. Integrating semantic role information into SMT has been demonstrated by various researchers to improve translation quality (cf. Wu and Fung (2009a), Wu and Fung (2009b), Liu and Gildea (2008), Liu and Gildea (2010)). Our approach is in line with 594 Wu and Fung (2009b) who demonstrated that on the one hand 84% of verb syntactic functions in a 50-sentence test corpus projected from Chinese to English, and that on the other hand about 15% of the subjects were not translated into subjects, but their semantic roles were preserved across language. These two findings correspond to the expected uses of our models (i) and (ii), respectively. 2 Previous work Previous work has already introduced the idea of generating inflected forms as a post-processing step for a translation system that h</context>
</contexts>
<marker>Liu, Gildea, 2008</marker>
<rawString>Ding Liu and Daniel Gildea. 2008. Improved Treeto-String Transducers for Machine Translation. In ACL Workshop on Statistical Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ding Liu</author>
<author>Daniel Gildea</author>
</authors>
<title>Semantic Role Features for Machine Translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (COLING)</booktitle>
<contexts>
<context position="8739" citStr="Liu and Gildea (2010)" startWordPosition="1319" endWordPosition="1322"> noun–noun modification. Model (ii) predicts case relying on the subcategorization and modification preferences. The combination of our two models approaches a simplified level of semantic role definition but only relies on dependency information that is considerably easier and cheaper to define and obtain than a very high quality semantic parser and/or a corpus annotated with semantic role information. Integrating semantic role information into SMT has been demonstrated by various researchers to improve translation quality (cf. Wu and Fung (2009a), Wu and Fung (2009b), Liu and Gildea (2008), Liu and Gildea (2010)). Our approach is in line with 594 Wu and Fung (2009b) who demonstrated that on the one hand 84% of verb syntactic functions in a 50-sentence test corpus projected from Chinese to English, and that on the other hand about 15% of the subjects were not translated into subjects, but their semantic roles were preserved across language. These two findings correspond to the expected uses of our models (i) and (ii), respectively. 2 Previous work Previous work has already introduced the idea of generating inflected forms as a post-processing step for a translation system that has been stripped of (mo</context>
<context position="32087" citStr="Liu and Gildea, 2010" startWordPosition="5047" endWordPosition="5050">coder) results in a BLEU score of 14.00. 12We used Kevin Gimpel’s implementation of pairwise bootstrap resampling with 1000 samples. 599 0 1 2 3 4 surface simple subcat. features source-side source-side system prediction (tuples from EN side) features + subcat. featues BLEU 13.43 14.02 14.05 14.10 14.17 Clean – 85.05% 85.65% 85.61% 85.81% Table 5: Results of the simple prediction vs. three systems enriched with extra features. One problem with using BLEU as an evaluation metric is that it is a precision-oriented metric and tends to reward fluency rather than adequacy (see (Wu and Fung, 2009a; Liu and Gildea, 2010)). As we are working on improving adequacy, this will not be fully reflected by BLEU. Furthermore, not all components of an NP do necessarily change their inflection with a new case value; it might happen that the only indicator for the case of an NP is the determiner: er sieht [den alten Mann]NPacc (he sees the old man) vs. er folgt [dem alten Mann]NPdat (he follows the old man). While the case marking of NPs is essential for comprehensibility, one changed word per noun phrase is hardly enough to be reflected by BLEU. An alternative to study the effectiveness of the case prediction model is t</context>
</contexts>
<marker>Liu, Gildea, 2010</marker>
<rawString>Ding Liu and Daniel Gildea. 2010. Semantic Role Features for Machine Translation. In Proceedings of the 23rd International Conference on Computational Linguistics (COLING) 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Rob Koeling</author>
<author>Julie Weeds</author>
<author>John Carroll</author>
</authors>
<title>Unsupervised Acquisition of Predominant Word Senses.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>4</issue>
<contexts>
<context position="19236" citStr="McCarthy et al., 2007" startWordPosition="3024" endWordPosition="3028"> et al., 2005). On the other hand, we find automatic approaches to the induction of verb subcategorization information at the syntax-semantics interface for a large number of languages, e.g. Briscoe and Carroll (1997) for English; Sarkar and Zeman (2000) for Czech; Schulte im Walde (2002a) for German; Messiant (2008) for French. This basic kind of verb knowledge has been shown to be useful in many NLP tasks such as information extraction (Surdeanu et al., 2003; Venturi1 et al., 2009), parsing (Carroll et al., 1998; Carroll and Fang, 2004) and word sense disambiguation (Kohomban and Lee, 2005; McCarthy et al., 2007). 4.1 Extracting subcategorization information As described in the introductory section, we make use of two5 major kinds of subcategorization information. Verb–noun tuples referring to specific syntactic functions within verb subcategorization (verb–noun subcat case prediction) are integrated with an associated probability for accusative (direct object), dative (indirect object) and nominative (subject).6 Further to the subject and object noun phrases, the subcategorization information provides quantitative triples for verb–preposition–noun pairs, thus predicting the case of NPs within preposi</context>
</contexts>
<marker>McCarthy, Koeling, Weeds, Carroll, 2007</marker>
<rawString>Diana McCarthy, Rob Koeling, Julie Weeds, and John Carroll. 2007. Unsupervised Acquisition of Predominant Word Senses. Computational Linguistics, 33(4):553–590.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C´edric Messiant</author>
</authors>
<title>A Subcategorization Acquisition System for French Verbs.</title>
<date>2008</date>
<booktitle>In Proceedings of the Student Research Workshop at the 46th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>55--60</pages>
<location>Columbus, OH.</location>
<contexts>
<context position="18932" citStr="Messiant (2008)" startWordPosition="2974" endWordPosition="2975">ghted in the SMT output. discourse. On the one hand, this has led to a range of manually or semi-automatically developed lexical resources focusing on verb information, such as the Levin classes (Levin, 1993), VerbNet (Kipper Schuler, 2006), FrameNet4 (Fillmore et al., 2003), and PropBank (Palmer et al., 2005). On the other hand, we find automatic approaches to the induction of verb subcategorization information at the syntax-semantics interface for a large number of languages, e.g. Briscoe and Carroll (1997) for English; Sarkar and Zeman (2000) for Czech; Schulte im Walde (2002a) for German; Messiant (2008) for French. This basic kind of verb knowledge has been shown to be useful in many NLP tasks such as information extraction (Surdeanu et al., 2003; Venturi1 et al., 2009), parsing (Carroll et al., 1998; Carroll and Fang, 2004) and word sense disambiguation (Kohomban and Lee, 2005; McCarthy et al., 2007). 4.1 Extracting subcategorization information As described in the introductory section, we make use of two5 major kinds of subcategorization information. Verb–noun tuples referring to specific syntactic functions within verb subcategorization (verb–noun subcat case prediction) are integrated wi</context>
</contexts>
<marker>Messiant, 2008</marker>
<rawString>C´edric Messiant. 2008. A Subcategorization Acquisition System for French Verbs. In Proceedings of the Student Research Workshop at the 46th Annual Meeting of the Association for Computational Linguistics, pages 55–60, Columbus, OH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Daniel Gildea</author>
<author>Paul Kingsbury</author>
</authors>
<title>The Proposition Bank: An annotated Resource of Semantic Roles.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="18628" citStr="Palmer et al., 2005" startWordPosition="2925" endWordPosition="2928">96 SMT output predicted features inflected forms gloss beeinflussen&lt;VVFIN&gt; – beeinflussen influence d&lt;ART&gt; Fem.Acc.Sg.St die the politisch&lt;ADJ&gt; Fem.Acc.Sg.Wk politische political Stabilit¨at&lt;NN&gt;&lt;Fem&gt;&lt;Sg&gt; Fem.Acc.Sg.Wk Stabilitit stability Table 2: Overview of the inflection process: the stem markup is highlighted in the SMT output. discourse. On the one hand, this has led to a range of manually or semi-automatically developed lexical resources focusing on verb information, such as the Levin classes (Levin, 1993), VerbNet (Kipper Schuler, 2006), FrameNet4 (Fillmore et al., 2003), and PropBank (Palmer et al., 2005). On the other hand, we find automatic approaches to the induction of verb subcategorization information at the syntax-semantics interface for a large number of languages, e.g. Briscoe and Carroll (1997) for English; Sarkar and Zeman (2000) for Czech; Schulte im Walde (2002a) for German; Messiant (2008) for French. This basic kind of verb knowledge has been shown to be useful in many NLP tasks such as information extraction (Surdeanu et al., 2003; Venturi1 et al., 2009), parsing (Carroll et al., 1998; Carroll and Fang, 2004) and word sense disambiguation (Kohomban and Lee, 2005; McCarthy et al</context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>Martha Palmer, Daniel Gildea, and Paul Kingsbury. 2005. The Proposition Bank: An annotated Resource of Semantic Roles. Computational Linguistics, 31(1):71–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore A Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei-Jing Zhu</author>
</authors>
<title>BLEU: a Method for Automatic Evaluation of Machine Translation.</title>
<date>2001</date>
<journal>IBM Research Division, Thomas J. Watson Research Center.</journal>
<tech>Technical Report RC22176 (W0109-022),</tech>
<contexts>
<context position="30877" citStr="Papineni et al., 2001" startWordPosition="4853" endWordPosition="4856">ation (cf. section 4.2), (3) source-side features (cf. section 4.3), and (4) both source-side features and subcategorization information. In (2) and (4), the subcategorization information was included using tuples obtained from source-side dependencies11. The simple prediction system corresponds to that presented in section 3; for all inflection prediction systems, the same SMT output and models for number, gender and strong/weak inflection were used; thus the only difference with the simple prediction system is the model for case prediction. We present three types of evaluation: BLEU scores (Papineni et al., 2001), prediction accuracy on clean data and a manual evaluation of the best system in section 5.3. Table 5 gives results in case-insensitive BLEU. While the inflection prediction systems (1-4) are significantly12 better than the surface-form system (0), the different versions of the inflection systems are not distinguishable in terms of BLEU; however, our manual evaluation shows that the new features have a positive impact on translation quality. tion; the regularization parameter is optimized on held out data. 11Using tuples extracted from the target-side parse tree (produced by the decoder) resu</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2001</marker>
<rawString>Kishore A. Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2001. BLEU: a Method for Automatic Evaluation of Machine Translation. Technical Report RC22176 (W0109-022), IBM Research Division, Thomas J. Watson Research Center.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anoop Sarkar</author>
<author>Daniel Zeman</author>
</authors>
<title>Automatic Extraction of Subcategorization Frames for Czech.</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th International Conference on Computational Linguistics, Saarbr¨ucken,</booktitle>
<location>Germany.</location>
<contexts>
<context position="18868" citStr="Sarkar and Zeman (2000)" startWordPosition="2962" endWordPosition="2965">y Table 2: Overview of the inflection process: the stem markup is highlighted in the SMT output. discourse. On the one hand, this has led to a range of manually or semi-automatically developed lexical resources focusing on verb information, such as the Levin classes (Levin, 1993), VerbNet (Kipper Schuler, 2006), FrameNet4 (Fillmore et al., 2003), and PropBank (Palmer et al., 2005). On the other hand, we find automatic approaches to the induction of verb subcategorization information at the syntax-semantics interface for a large number of languages, e.g. Briscoe and Carroll (1997) for English; Sarkar and Zeman (2000) for Czech; Schulte im Walde (2002a) for German; Messiant (2008) for French. This basic kind of verb knowledge has been shown to be useful in many NLP tasks such as information extraction (Surdeanu et al., 2003; Venturi1 et al., 2009), parsing (Carroll et al., 1998; Carroll and Fang, 2004) and word sense disambiguation (Kohomban and Lee, 2005; McCarthy et al., 2007). 4.1 Extracting subcategorization information As described in the introductory section, we make use of two5 major kinds of subcategorization information. Verb–noun tuples referring to specific syntactic functions within verb subcat</context>
</contexts>
<marker>Sarkar, Zeman, 2000</marker>
<rawString>Anoop Sarkar and Daniel Zeman. 2000. Automatic Extraction of Subcategorization Frames for Czech. In Proceedings of the 18th International Conference on Computational Linguistics, Saarbr¨ucken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Silke Scheible</author>
<author>Sabine Schulte im Walde</author>
<author>Marion Weller</author>
<author>Max Kisselew</author>
</authors>
<title>A Compact but Linguistically Detailed Database for German Verb Subcategorisation relying on Dependency Parses from a Web Corpus.</title>
<date>2013</date>
<booktitle>In Proceedings of the 8th Web as Corpus Workshop,</booktitle>
<location>Lancaster, UK.</location>
<note>To appear.</note>
<contexts>
<context position="29738" citStr="Scheible et al. (2013)" startWordPosition="4682" endWordPosition="4685">ased for the 2009 ACL Workshop on Machine Translation shared task. 10To eliminate irrelevant features, we use L1 regularizaWe train four CRFs on data prepared as shown in section 3. The corpora used for the extraction of subcategorization tuples were Europarl and German newspaper data (200 million words). We choose this particular data combination in order to provide data that matches the training data, as well as to add new data of the test set’s domain (news). The German part of Europarl was dependencyparsed with Bohnet (2010), and subcategorization information was extracted as described in Scheible et al. (2013); the newspaper data (HGC - Huge German Corpus) was parsed with Schmid (2000), and subcategorization information was extracted as described in Schulte im Walde (2002b). 5.2 Results We report results of two types of systems (table 5): first, a regular translation system built on surface forms (i.e., normal text) and second, four inflection prediction systems. The first inflection prediction system (1) uses a simple case prediction model, whereas the remaining systems are enriched with (2) subcategorization information (cf. section 4.2), (3) source-side features (cf. section 4.3), and (4) both s</context>
</contexts>
<marker>Scheible, Walde, Weller, Kisselew, 2013</marker>
<rawString>Silke Scheible, Sabine Schulte im Walde, Marion Weller, and Max Kisselew. 2013. A Compact but Linguistically Detailed Database for German Verb Subcategorisation relying on Dependency Parses from a Web Corpus. In Proceedings of the 8th Web as Corpus Workshop, Lancaster, UK. To appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
<author>Arne Fitschen</author>
<author>Ulrich Heid</author>
</authors>
<title>SMOR: a German Computational Morphology Covering Derivation, Composition, and Inflection.</title>
<date>2004</date>
<booktitle>In Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC).</booktitle>
<contexts>
<context position="16381" citStr="Schmid et al., 2004" startWordPosition="2574" endWordPosition="2577"> the markup (number and gender on nouns) in the stemmed output of the SMT system is part of the input to the respective feature prediction. For gender and number, the values given on the stems of the nouns are then propagated over the phrase. While the case of prepositional phrases is determined by the case annotation on prepositions, the case of nominal phrases is computed only based on the respective contexts. After predicting all morphological features, the information required to generate inflected forms is complete: based on the stems and the features, we use the morphological tool SMOR (Schmid et al., 2004) for the generation of inflected forms. One general problem with feature-prediction is that the ill-formed SMT output is not well represented by the training data which consists of wellformed sentences. This problem was also mentioned by Stymne and Cancedda (2011) and Kholy and Habash (2012). They deal with this problem by translating the training data and annotating it with the respective features, and then adding this new data set to the original training data. As this method comes with its own problems, such as transferring the morphological annotation to not necessarily isomorphically tran</context>
</contexts>
<marker>Schmid, Fitschen, Heid, 2004</marker>
<rawString>Helmut Schmid, Arne Fitschen, and Ulrich Heid. 2004. SMOR: a German Computational Morphology Covering Derivation, Composition, and Inflection. In Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>LoPar: Design and Implementation.</title>
<date>2000</date>
<booktitle>Arbeitspapiere des Sonderforschungsbereichs 340 ‘Linguistic Theory and the Foundations of Computational Linguistics’ 149, Institut f¨ur Maschinelle Sprachverarbeitung,</booktitle>
<location>Universit¨at Stuttgart.</location>
<contexts>
<context position="29815" citStr="Schmid (2000)" startWordPosition="4697" endWordPosition="4698">levant features, we use L1 regularizaWe train four CRFs on data prepared as shown in section 3. The corpora used for the extraction of subcategorization tuples were Europarl and German newspaper data (200 million words). We choose this particular data combination in order to provide data that matches the training data, as well as to add new data of the test set’s domain (news). The German part of Europarl was dependencyparsed with Bohnet (2010), and subcategorization information was extracted as described in Scheible et al. (2013); the newspaper data (HGC - Huge German Corpus) was parsed with Schmid (2000), and subcategorization information was extracted as described in Schulte im Walde (2002b). 5.2 Results We report results of two types of systems (table 5): first, a regular translation system built on surface forms (i.e., normal text) and second, four inflection prediction systems. The first inflection prediction system (1) uses a simple case prediction model, whereas the remaining systems are enriched with (2) subcategorization information (cf. section 4.2), (3) source-side features (cf. section 4.3), and (4) both source-side features and subcategorization information. In (2) and (4), the su</context>
</contexts>
<marker>Schmid, 2000</marker>
<rawString>Helmut Schmid. 2000. LoPar: Design and Implementation. Arbeitspapiere des Sonderforschungsbereichs 340 ‘Linguistic Theory and the Foundations of Computational Linguistics’ 149, Institut f¨ur Maschinelle Sprachverarbeitung, Universit¨at Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Efficient Parsing of Highly Ambiguous Context-Free Grammars with Bit Vectors.</title>
<date>2004</date>
<contexts>
<context position="11952" citStr="Schmid, 2004" startWordPosition="1850" endWordPosition="1851"> not hold for German output. 3 Translation pipeline This section presents an overview of our two-step translation process. In the first step, English input is translated to German stems. In the second step, morphological features are predicted and inflected forms are generated based on the word stems and the morphological features. In subsections 3.1 to 3.4, we present the simple version of the inflection prediction system; our new features are described in sections 4.2 and 4.3. 3.1 Stemmed representation/feature markup We first parse the German side of the parallel training data with BitPar (Schmid, 2004). This maps each surface form appearing in normal text to a stem and morphological features (case, gender, number). We use this representation to create the stemmed representation for training the translation model. With the exception of stem-markup (discussed below), all morphological features are removed from the stemmed representation. The stem markup is used as part of the input to the feature prediction; the basic idea is that the given feature values are picked up by the prediction model and then propagated over the phrase. Nouns, as the head of NPs and PPs, are annotated with gender and</context>
</contexts>
<marker>Schmid, 2004</marker>
<rawString>Helmut Schmid. 2004. Efficient Parsing of Highly Ambiguous Context-Free Grammars with Bit Vectors.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Schulte im Walde</author>
</authors>
<title>A Subcategorisation Lexicon for German Verbs induced from a Lexicalised PCFG.</title>
<date>2002</date>
<booktitle>In Proceedings of the 3rd Conference on Language Resources and Evaluation, volume IV,</booktitle>
<pages>1351--1357</pages>
<contexts>
<context position="18902" citStr="Walde (2002" startWordPosition="2970" endWordPosition="2971"> the stem markup is highlighted in the SMT output. discourse. On the one hand, this has led to a range of manually or semi-automatically developed lexical resources focusing on verb information, such as the Levin classes (Levin, 1993), VerbNet (Kipper Schuler, 2006), FrameNet4 (Fillmore et al., 2003), and PropBank (Palmer et al., 2005). On the other hand, we find automatic approaches to the induction of verb subcategorization information at the syntax-semantics interface for a large number of languages, e.g. Briscoe and Carroll (1997) for English; Sarkar and Zeman (2000) for Czech; Schulte im Walde (2002a) for German; Messiant (2008) for French. This basic kind of verb knowledge has been shown to be useful in many NLP tasks such as information extraction (Surdeanu et al., 2003; Venturi1 et al., 2009), parsing (Carroll et al., 1998; Carroll and Fang, 2004) and word sense disambiguation (Kohomban and Lee, 2005; McCarthy et al., 2007). 4.1 Extracting subcategorization information As described in the introductory section, we make use of two5 major kinds of subcategorization information. Verb–noun tuples referring to specific syntactic functions within verb subcategorization (verb–noun subcat case</context>
<context position="29903" citStr="Walde (2002" startWordPosition="4709" endWordPosition="4710">on 3. The corpora used for the extraction of subcategorization tuples were Europarl and German newspaper data (200 million words). We choose this particular data combination in order to provide data that matches the training data, as well as to add new data of the test set’s domain (news). The German part of Europarl was dependencyparsed with Bohnet (2010), and subcategorization information was extracted as described in Scheible et al. (2013); the newspaper data (HGC - Huge German Corpus) was parsed with Schmid (2000), and subcategorization information was extracted as described in Schulte im Walde (2002b). 5.2 Results We report results of two types of systems (table 5): first, a regular translation system built on surface forms (i.e., normal text) and second, four inflection prediction systems. The first inflection prediction system (1) uses a simple case prediction model, whereas the remaining systems are enriched with (2) subcategorization information (cf. section 4.2), (3) source-side features (cf. section 4.3), and (4) both source-side features and subcategorization information. In (2) and (4), the subcategorization information was included using tuples obtained from source-side dependen</context>
</contexts>
<marker>Walde, 2002</marker>
<rawString>Sabine Schulte im Walde. 2002a. A Subcategorisation Lexicon for German Verbs induced from a Lexicalised PCFG. In Proceedings of the 3rd Conference on Language Resources and Evaluation, volume IV, pages 1351–1357, Las Palmas de Gran Canaria, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Schulte im Walde</author>
</authors>
<title>A Subcategorisation Lexicon for German Verbs induced from a Lexicalised PCFG.</title>
<date>2002</date>
<booktitle>In Proceedings of the 3rd Conference on Language Resources and Evaluation, volume IV,</booktitle>
<pages>1351--1357</pages>
<contexts>
<context position="18902" citStr="Walde (2002" startWordPosition="2970" endWordPosition="2971"> the stem markup is highlighted in the SMT output. discourse. On the one hand, this has led to a range of manually or semi-automatically developed lexical resources focusing on verb information, such as the Levin classes (Levin, 1993), VerbNet (Kipper Schuler, 2006), FrameNet4 (Fillmore et al., 2003), and PropBank (Palmer et al., 2005). On the other hand, we find automatic approaches to the induction of verb subcategorization information at the syntax-semantics interface for a large number of languages, e.g. Briscoe and Carroll (1997) for English; Sarkar and Zeman (2000) for Czech; Schulte im Walde (2002a) for German; Messiant (2008) for French. This basic kind of verb knowledge has been shown to be useful in many NLP tasks such as information extraction (Surdeanu et al., 2003; Venturi1 et al., 2009), parsing (Carroll et al., 1998; Carroll and Fang, 2004) and word sense disambiguation (Kohomban and Lee, 2005; McCarthy et al., 2007). 4.1 Extracting subcategorization information As described in the introductory section, we make use of two5 major kinds of subcategorization information. Verb–noun tuples referring to specific syntactic functions within verb subcategorization (verb–noun subcat case</context>
<context position="29903" citStr="Walde (2002" startWordPosition="4709" endWordPosition="4710">on 3. The corpora used for the extraction of subcategorization tuples were Europarl and German newspaper data (200 million words). We choose this particular data combination in order to provide data that matches the training data, as well as to add new data of the test set’s domain (news). The German part of Europarl was dependencyparsed with Bohnet (2010), and subcategorization information was extracted as described in Scheible et al. (2013); the newspaper data (HGC - Huge German Corpus) was parsed with Schmid (2000), and subcategorization information was extracted as described in Schulte im Walde (2002b). 5.2 Results We report results of two types of systems (table 5): first, a regular translation system built on surface forms (i.e., normal text) and second, four inflection prediction systems. The first inflection prediction system (1) uses a simple case prediction model, whereas the remaining systems are enriched with (2) subcategorization information (cf. section 4.2), (3) source-side features (cf. section 4.3), and (4) both source-side features and subcategorization information. In (2) and (4), the subcategorization information was included using tuples obtained from source-side dependen</context>
</contexts>
<marker>Walde, 2002</marker>
<rawString>Sabine Schulte im Walde. 2002b. A Subcategorisation Lexicon for German Verbs induced from a Lexicalised PCFG. In Proceedings of the 3rd Conference on Language Resources and Evaluation, volume IV, pages 1351–1357, Las Palmas de Gran Canaria, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Stymne</author>
<author>Nicola Cancedda</author>
</authors>
<title>Productive Generation of Compound Words in Statistical Machine Translation.</title>
<date>2011</date>
<booktitle>In Proceedings of the Sixth Workshop on Machine Translation.</booktitle>
<contexts>
<context position="16645" citStr="Stymne and Cancedda (2011)" startWordPosition="2617" endWordPosition="2620">of prepositional phrases is determined by the case annotation on prepositions, the case of nominal phrases is computed only based on the respective contexts. After predicting all morphological features, the information required to generate inflected forms is complete: based on the stems and the features, we use the morphological tool SMOR (Schmid et al., 2004) for the generation of inflected forms. One general problem with feature-prediction is that the ill-formed SMT output is not well represented by the training data which consists of wellformed sentences. This problem was also mentioned by Stymne and Cancedda (2011) and Kholy and Habash (2012). They deal with this problem by translating the training data and annotating it with the respective features, and then adding this new data set to the original training data. As this method comes with its own problems, such as transferring the morphological annotation to not necessarily isomorphically translated text, we do not use translated data as part of the training data. Instead, we limit the power of the CRF model through experimenting with the removal of features, until we had a system that was robust to this problem. 3.4 Dealing with word formation issues </context>
</contexts>
<marker>Stymne, Cancedda, 2011</marker>
<rawString>Sara Stymne and Nicola Cancedda. 2011. Productive Generation of Compound Words in Statistical Machine Translation. In Proceedings of the Sixth Workshop on Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Sanda Harabagiu</author>
<author>John Williams</author>
<author>Paul Aarseth</author>
</authors>
<title>Using Predicate-Argument Structures for Information Extraction.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>8--15</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="19078" citStr="Surdeanu et al., 2003" startWordPosition="2999" endWordPosition="3002">ocusing on verb information, such as the Levin classes (Levin, 1993), VerbNet (Kipper Schuler, 2006), FrameNet4 (Fillmore et al., 2003), and PropBank (Palmer et al., 2005). On the other hand, we find automatic approaches to the induction of verb subcategorization information at the syntax-semantics interface for a large number of languages, e.g. Briscoe and Carroll (1997) for English; Sarkar and Zeman (2000) for Czech; Schulte im Walde (2002a) for German; Messiant (2008) for French. This basic kind of verb knowledge has been shown to be useful in many NLP tasks such as information extraction (Surdeanu et al., 2003; Venturi1 et al., 2009), parsing (Carroll et al., 1998; Carroll and Fang, 2004) and word sense disambiguation (Kohomban and Lee, 2005; McCarthy et al., 2007). 4.1 Extracting subcategorization information As described in the introductory section, we make use of two5 major kinds of subcategorization information. Verb–noun tuples referring to specific syntactic functions within verb subcategorization (verb–noun subcat case prediction) are integrated with an associated probability for accusative (direct object), dative (indirect object) and nominative (subject).6 Further to the subject and object</context>
</contexts>
<marker>Surdeanu, Harabagiu, Williams, Aarseth, 2003</marker>
<rawString>Mihai Surdeanu, Sanda Harabagiu, John Williams, and Paul Aarseth. 2003. Using Predicate-Argument Structures for Information Extraction. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 8–15, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Hisami Suzuki</author>
<author>Achim Ruopp</author>
</authors>
<title>Applying Morphology Generation Models to Machine Translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL): Human Language Technologies.</booktitle>
<contexts>
<context position="9401" citStr="Toutanova et al. (2008)" startWordPosition="1428" endWordPosition="1431">and Fung (2009b) who demonstrated that on the one hand 84% of verb syntactic functions in a 50-sentence test corpus projected from Chinese to English, and that on the other hand about 15% of the subjects were not translated into subjects, but their semantic roles were preserved across language. These two findings correspond to the expected uses of our models (i) and (ii), respectively. 2 Previous work Previous work has already introduced the idea of generating inflected forms as a post-processing step for a translation system that has been stripped of (most) target-language-specific features. Toutanova et al. (2008) and Jeong et al. (2010) built translation systems that predict inflected word forms based on a large array of morphological and syntactic features, obtained from both source and target side. Kholy and Habash (2012) and Green and DeNero (2012) work on English to Arabic translation and model gender, number and definiteness, focusing primarily on improving fluency. Fraser et al. (2012) used a phrase-based system to transfer stems and generated inflected forms based on the stems and their morphological features. For case prediction, they trained a CRF with access to lemmas and POS-tags within a g</context>
</contexts>
<marker>Toutanova, Suzuki, Ruopp, 2008</marker>
<rawString>Kristina Toutanova, Hisami Suzuki, and Achim Ruopp. 2008. Applying Morphology Generation Models to Machine Translation. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL): Human Language Technologies.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giulia Venturi1</author>
<author>Simonetta Montemagni</author>
<author>Simone Marchi</author>
<author>Yutaka Sasaki</author>
<author>Paul Thompson</author>
<author>John McNaught</author>
<author>Sophia Ananiadou</author>
</authors>
<title>Bootstrapping a Verb Lexicon for Biomedical Information Extraction.</title>
<date>2009</date>
<booktitle>Linguistics and Intelligent Text Processing,</booktitle>
<pages>137--148</pages>
<editor>In Alexander Gelbukh, editor,</editor>
<publisher>Springer,</publisher>
<location>Heidelberg.</location>
<marker>Venturi1, Montemagni, Marchi, Sasaki, Thompson, McNaught, Ananiadou, 2009</marker>
<rawString>Giulia Venturi1, Simonetta Montemagni, Simone Marchi, Yutaka Sasaki, Paul Thompson, John McNaught, and Sophia Ananiadou. 2009. Bootstrapping a Verb Lexicon for Biomedical Information Extraction. In Alexander Gelbukh, editor, Linguistics and Intelligent Text Processing, pages 137–148. Springer, Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Williams</author>
<author>Phillipp Koehn</author>
</authors>
<title>GHKMRule Extraction and Scope-3 Parsing in Moses.</title>
<date>2012</date>
<booktitle>In Proceedings of the 7th Workshop on Statistical Machine Translation, ACL.</booktitle>
<contexts>
<context position="28798" citStr="Williams and Koehn (2012)" startWordPosition="4533" endWordPosition="4536">ing and aligning English noun-of-noun phrases. 5 Experiments and evaluation In this section, we present experiments using different feature combinations. We also present a manual evaluation of our best system which shows that the new features improve translation quality. 5.1 Data and experimental setup We use the hierarchical translation system that comes with the Moses SMT-package and GIZA++ to compute the word alignment, using the “growdiag-final-and” heuristics. The rule table was computed with the default parameter setting for GHKM extraction (Galley et al., 2004) in the implementation by Williams and Koehn (2012). Our training data contains 1,485,059 parallel sentences9; the German part of the parallel data is used as the target-side language model. The dev and test sets (1025/1026 lines) are wmt-2009-a/b. For predicting the grammatical features, we used the Wapiti Toolkit (Lavergne et al., 2010).10 9English/German data released for the 2009 ACL Workshop on Machine Translation shared task. 10To eliminate irrelevant features, we use L1 regularizaWe train four CRFs on data prepared as shown in section 3. The corpora used for the extraction of subcategorization tuples were Europarl and German newspaper d</context>
</contexts>
<marker>Williams, Koehn, 2012</marker>
<rawString>Philip Williams and Phillipp Koehn. 2012. GHKMRule Extraction and Scope-3 Parsing in Moses. In Proceedings of the 7th Workshop on Statistical Machine Translation, ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
<author>Pascale Fung</author>
</authors>
<title>Can Semantic Role Labeling Improve SMT?</title>
<date>2009</date>
<booktitle>In Proceedings of the 13th Annual Conference of the European Association for Machine Translation (EAMT).</booktitle>
<contexts>
<context position="8670" citStr="Wu and Fung (2009" startWordPosition="1307" endWordPosition="1310"> no obvious preferences concerning verb–noun subcategorization or noun–noun modification. Model (ii) predicts case relying on the subcategorization and modification preferences. The combination of our two models approaches a simplified level of semantic role definition but only relies on dependency information that is considerably easier and cheaper to define and obtain than a very high quality semantic parser and/or a corpus annotated with semantic role information. Integrating semantic role information into SMT has been demonstrated by various researchers to improve translation quality (cf. Wu and Fung (2009a), Wu and Fung (2009b), Liu and Gildea (2008), Liu and Gildea (2010)). Our approach is in line with 594 Wu and Fung (2009b) who demonstrated that on the one hand 84% of verb syntactic functions in a 50-sentence test corpus projected from Chinese to English, and that on the other hand about 15% of the subjects were not translated into subjects, but their semantic roles were preserved across language. These two findings correspond to the expected uses of our models (i) and (ii), respectively. 2 Previous work Previous work has already introduced the idea of generating inflected forms as a post-p</context>
<context position="32063" citStr="Wu and Fung, 2009" startWordPosition="5043" endWordPosition="5046"> (produced by the decoder) results in a BLEU score of 14.00. 12We used Kevin Gimpel’s implementation of pairwise bootstrap resampling with 1000 samples. 599 0 1 2 3 4 surface simple subcat. features source-side source-side system prediction (tuples from EN side) features + subcat. featues BLEU 13.43 14.02 14.05 14.10 14.17 Clean – 85.05% 85.65% 85.61% 85.81% Table 5: Results of the simple prediction vs. three systems enriched with extra features. One problem with using BLEU as an evaluation metric is that it is a precision-oriented metric and tends to reward fluency rather than adequacy (see (Wu and Fung, 2009a; Liu and Gildea, 2010)). As we are working on improving adequacy, this will not be fully reflected by BLEU. Furthermore, not all components of an NP do necessarily change their inflection with a new case value; it might happen that the only indicator for the case of an NP is the determiner: er sieht [den alten Mann]NPacc (he sees the old man) vs. er folgt [dem alten Mann]NPdat (he follows the old man). While the case marking of NPs is essential for comprehensibility, one changed word per noun phrase is hardly enough to be reflected by BLEU. An alternative to study the effectiveness of the ca</context>
</contexts>
<marker>Wu, Fung, 2009</marker>
<rawString>Dekai Wu and Pascale Fung. 2009a. Can Semantic Role Labeling Improve SMT? In Proceedings of the 13th Annual Conference of the European Association for Machine Translation (EAMT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
<author>Pascale Fung</author>
</authors>
<title>Semantic Roles for SMT: A Hybrid two-pass Model.</title>
<date>2009</date>
<booktitle>In Proceedings of the North American Chapter of the Association for Computational Linguistics and Human Language Technologies Conference (NAACL-HLT).</booktitle>
<contexts>
<context position="8670" citStr="Wu and Fung (2009" startWordPosition="1307" endWordPosition="1310"> no obvious preferences concerning verb–noun subcategorization or noun–noun modification. Model (ii) predicts case relying on the subcategorization and modification preferences. The combination of our two models approaches a simplified level of semantic role definition but only relies on dependency information that is considerably easier and cheaper to define and obtain than a very high quality semantic parser and/or a corpus annotated with semantic role information. Integrating semantic role information into SMT has been demonstrated by various researchers to improve translation quality (cf. Wu and Fung (2009a), Wu and Fung (2009b), Liu and Gildea (2008), Liu and Gildea (2010)). Our approach is in line with 594 Wu and Fung (2009b) who demonstrated that on the one hand 84% of verb syntactic functions in a 50-sentence test corpus projected from Chinese to English, and that on the other hand about 15% of the subjects were not translated into subjects, but their semantic roles were preserved across language. These two findings correspond to the expected uses of our models (i) and (ii), respectively. 2 Previous work Previous work has already introduced the idea of generating inflected forms as a post-p</context>
<context position="32063" citStr="Wu and Fung, 2009" startWordPosition="5043" endWordPosition="5046"> (produced by the decoder) results in a BLEU score of 14.00. 12We used Kevin Gimpel’s implementation of pairwise bootstrap resampling with 1000 samples. 599 0 1 2 3 4 surface simple subcat. features source-side source-side system prediction (tuples from EN side) features + subcat. featues BLEU 13.43 14.02 14.05 14.10 14.17 Clean – 85.05% 85.65% 85.61% 85.81% Table 5: Results of the simple prediction vs. three systems enriched with extra features. One problem with using BLEU as an evaluation metric is that it is a precision-oriented metric and tends to reward fluency rather than adequacy (see (Wu and Fung, 2009a; Liu and Gildea, 2010)). As we are working on improving adequacy, this will not be fully reflected by BLEU. Furthermore, not all components of an NP do necessarily change their inflection with a new case value; it might happen that the only indicator for the case of an NP is the determiner: er sieht [den alten Mann]NPacc (he sees the old man) vs. er folgt [dem alten Mann]NPdat (he follows the old man). While the case marking of NPs is essential for comprehensibility, one changed word per noun phrase is hardly enough to be reflected by BLEU. An alternative to study the effectiveness of the ca</context>
</contexts>
<marker>Wu, Fung, 2009</marker>
<rawString>Dekai Wu and Pascale Fung. 2009b. Semantic Roles for SMT: A Hybrid two-pass Model. In Proceedings of the North American Chapter of the Association for Computational Linguistics and Human Language Technologies Conference (NAACL-HLT).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>