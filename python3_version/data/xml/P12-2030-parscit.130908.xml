<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003595">
<title confidence="0.98335">
Humor as Circuits in Semantic Networks
</title>
<author confidence="0.99677">
Igor Labutov Hod Lipson
</author>
<affiliation confidence="0.999301">
Cornell University Cornell University
</affiliation>
<email confidence="0.99821">
iil4@cornell.edu hod.lipson@cornell.edu
</email>
<sectionHeader confidence="0.995623" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999659588235294">
This work presents a first step to a general im-
plementation of the Semantic-Script Theory
of Humor (SSTH). Of the scarce amount of
research in computational humor, no research
had focused on humor generation beyond sim-
ple puns and punning riddles. We propose
an algorithm for mining simple humorous
scripts from a semantic network (Concept-
Net) by specifically searching for dual scripts
that jointly maximize overlap and incongruity
metrics in line with Raskin’s Semantic-Script
Theory of Humor. Initial results show that a
more relaxed constraint of this form is capable
of generating humor of deeper semantic con-
tent than wordplay riddles. We evaluate the
said metrics through a user-assessed quality of
the generated two-liners.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999922466666667">
While of significant interest in linguistics and phi-
losophy, humor had received less attention in the
computational domain. And of that work, most re-
cent is predominately focused on humor recognition.
See (Ritchie, 2001) for a good review. In this pa-
per we focus on the problem of humor generation.
While humor/sarcasm recognition merits direct ap-
plication to the areas such as information retrieval
(Friedland and Allan, 2008), sentiment classifica-
tion (Mihalcea and Strapparava, 2006), and human-
computer interaction (Nijholt et al., 2003), the ap-
plication of humor generation is not any less sig-
nificant. First, a good generative model of humor
has the potential to outperform current discrimina-
tive models for humor recognition. Thus, ability to
</bodyText>
<figureCaption confidence="0.999377">
Figure 1: Semantic circuit
</figureCaption>
<bodyText confidence="0.999942947368421">
generate humor will potentially lead to better humor
detection. Second, a computational model that con-
forms to the verbal theory of humor is an accessi-
ble avenue for verifying the psycholinguistic theory.
In this paper we take the Semantic Script Theory
of Humor (SSTH) (Attardo and Raskin, 1991) - a
widely accepted theory of verbal humor and build a
generative model that conforms to it.
Much of the existing work in humor generation
had focused on puns and punning riddles - hu-
mor that is centered around wordplay. And while
more recent of such implementations (Hempelmann
et al., 2006) take a knowledge-based approach that
is rooted in the linguistic theory (SSTH), the con-
straint, nevertheless, significantly limits the poten-
tial of SSTH. To our knowledge, our work is the first
attempt to instantiate the theory at the fundamental
level, without imposing constraints on phonological
similarity, or a restricted set of domain oppositions.
</bodyText>
<page confidence="0.975608">
150
</page>
<note confidence="0.7818535">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 150–155,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<subsectionHeader confidence="0.993399">
1.1 Semantic Script Theory of Humor
</subsectionHeader>
<bodyText confidence="0.997592833333333">
The Semantic Script Theory of Humor (SSTH) pro-
vides machinery to formalize the structure of most
types of verbal humor (Ruch et al., 1993). SSTH
posits an existence of two underlying scripts, one of
which is more obvious than the other. To be humor-
ous, the underlying scripts must satisfy two condi-
tions: overlap and incongruity. In the setup phase of
the joke, instances of the two scripts are presented
in a way that does not give away the less obvious
script (due to their overlap). In the punchline (res-
olution), a trigger expression forces the audience
to switch their interpretation to the alternate (less
likely) script. The alternate script must differ sig-
nificantly in meaning (be incongruent with the first
script) for the switch to have a humorous effect. An
example below illustrates this idea (S1 is the obvi-
ous script, and S2 is the alternate script. Bracketed
phrases are labeled with the associated script).
</bodyText>
<equation confidence="0.53128625">
“Is the [doctor]S1 at home?”the [patient]S1 asked in his
[bronchial]S1 [whisper]S2. “No,”the [doctor’s]S1 [young and pretty
wife]S2 [whispered]S2 in reply.
[“Come right in.”]S2 (Raskin, 1985)
</equation>
<sectionHeader confidence="0.999322" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9999745">
Of the early prototypes of pun-generators, JAPE
(Binsted and Ritchie, 1994), and its successor,
STANDUP (Ritchie et al., 2007), produced ques-
tion/answer punning riddles from general non-
humorous lexicon. While humor in the generated
puns could be explained by SSTH, the SSTH model
itself was not employed in the process of generation.
Recent work of Hempelmann (2006) comes closer
to utilizing SSTH. While still focused on generating
puns, they do so by explicitly defining and applying
script opposition (SO) using ontological semantics.
Of the more successful pun generators are systems
that exploit lexical resources. HAHAcronym (Stock
and Strapparava, 2002), a system for generating hu-
morous acronyms, for example, utilizes WordNet-
Domains to select phonologically similar concepts
from semantically disparate domains. While the de-
gree of humor sophistication from the above systems
varies with the sophistication of the method (lexi-
cal resources, surface realizers), they all, without ex-
ception, rely on phonological constraints to produce
script opposition, whereas a phonological constraint
is just one of the many ways to generate script op-
position.
</bodyText>
<sectionHeader confidence="0.945714" genericHeader="method">
3 System overview
</sectionHeader>
<bodyText confidence="0.999905258064516">
ConceptNet (Liu and Singh, 2004) lends itself as an
ideal ontological resource for script generation. As a
network that connects everyday concepts and events
with a set of causal and spatial relationships, the re-
lational structure of ConceptNet parallels the struc-
ture of the fabula model of story generation - namely
the General Transition Network (GTN) (Swartjes
and Theune, 2006). As such, we hypothesize that
there exist paths within the ConceptNet graph that
can be represented as feasible scripts in the sur-
face form. Moreover, multiple paths between two
given nodes represent overlapping scripts - a nec-
essary condition for verbal humor in SSTH. Given
a semantic network hypergraph G = (V, G) where
V E Concepts, G E Relations, we hypothesize
that it is possible to search for script-pairs as seman-
tic circuits that can be converted to a surface form
of the Question/Answer format. We define a circuit
as two paths from root A that terminate at a common
node B. Our approach is composed of three stages -
(1) we build a script model (SM) that captures likely
transitions between concepts in a surface-realizable
sequence, (2) The script model (SM) is then em-
ployed to generate a set of feasible circuits from a
user-specified root node through spreading activa-
tion, producing a set of ranked scripts. (3) Ranked
scripts are converted to surface form by aligning a
subset of its concepts to natural language templates
of the Question/Answer form. Alignment is per-
formed through a scoring heuristic which greedily
optimizes for incongruity of the surface form.
</bodyText>
<subsectionHeader confidence="0.996064">
3.1 Script model
</subsectionHeader>
<bodyText confidence="0.999771">
We model a script as a first order Markov chain of
relations between concepts. Given a seed concept,
depth-first search is performed starting from the root
concept, considering all directed paths terminating
at the same node as candidates for feasible script
pairs. Most of the found semantic circuits, however,
</bodyText>
<page confidence="0.992187">
151
</page>
<bodyText confidence="0.9999855625">
do not yield a meaningful surface form and need
to be pruned. Feasible circuits are learned in a su-
pervised way, where binary labels assign each can-
didate circuit one of the two classes {feasible,
infeasible} (we used 8 seed concepts, with 300
generated circuits for each concept). Learned tran-
sition probabilities are capable of capturing primi-
tive stories with events, consequences, as well as
appropriate qualifiers of certainty, time, size, loca-
tion. Given a chain of concepts S (from hereon re-
ferred to as a script) c1, c2...cn, we obtain its likeli-
hood Pr(S) = 11 Pr(rij|rjk), where rij and rjk are
directed relations joining concepts &lt; ci, cj &gt;, and
&lt; cj, ck &gt; respectively, and the conditionals are
computed from the maximum likelihood estimate of
the training data.
</bodyText>
<subsectionHeader confidence="0.999948">
3.2 Semantic overlap and spreading activation
</subsectionHeader>
<bodyText confidence="0.9994932">
While the script model is able to capture seman-
tically meaningful transitions in a single script, it
does not capture inter-script measures such as over-
lap and incongruity. We employ a modified form
of spreading activation with fan-out and path con-
straints to find semantic circuits while maximizing
their semantic overlap. Activation starts at the user-
specified root concept and radiates along outgoing
edges. Edge pairs are weighted with their respective
transition probabilities Pr(rij|rjk) and a decay fac-
tor γ &lt; 1 to penalize for long scripts. An additional
fan-out constraint penalizes nodes with a large num-
ber of outgoing edges (concepts that are too gen-
eral to be interesting). The weight of a current node
w(ci) is given by:
</bodyText>
<equation confidence="0.99048">
Pr(rij  |rjk)γw(C) (1)
 |h-t (ci)  |l j
</equation>
<bodyText confidence="0.961103666666667">
Termination condition is satisfied when the activa-
tion weights fall below a threshold (loop checking
is performed to prevent feedback). Upon termina-
tion, nodes are ranked by their activation weight, and
for each node above a specified rank, a set of paths
(scripts) Sk E S is scored according to:.
</bodyText>
<equation confidence="0.985154">
φk = |Sk |log γ + E |Sk |log Prk(ri+1|ri) (2)
i
</equation>
<bodyText confidence="0.8173125">
where φk is decay-weighted log-likelihood of script
Sk in a given circuit and |Sk |is the length of script
</bodyText>
<figureCaption confidence="0.9820425">
Figure 2: Question(Q) and Answer(A) concepts within
the semantic circuit. Areas C, and C2 represent differ-
ent semantic clusters. Note that the answer(A) concept is
chosen from a different cluster than the question concepts
</figureCaption>
<bodyText confidence="0.9988692">
Sk (number of nodes in the kth chain). A set of
scripts S with the highest scores in the highest rank-
ing circuits represent scripts that are likely to be fea-
sible and display a significant amount of semantic
overlap within the circuit.
</bodyText>
<subsectionHeader confidence="0.985507">
3.3 Incongruity and surface realization
</subsectionHeader>
<bodyText confidence="0.959711857142857">
The task is to select a script pair {Si, Sj i =� j} E
S x S and a set of concepts C E Si U Sj that will
align with some surface template, while maximiz-
ing inter-script incongruity. As a measure of con-
cept incongruity, we hierarchically cluster the entire
ConceptNet using a Fast Community Detection al-
gorithm (Clauset et al., 2004). We observe that clus-
ters are generated for related concepts, such as reli-
gion, marriage, computers. Each template presents
up to two concepts {c1 E Si, c2 E Sj i =� j} in the
question sentence (Q in Figure 2), and one concept
c3 E Si U Sj in the answer sentence (A in Figure
2). The motivation of this approach is that the two
concepts in the question are selected from two dif-
ferent scripts but from the same cluster, while the an-
swer concept is selected from one of the two scripts
and from a different cluster. The effect the generated
two-liner produces is that of a setup and resolution
(punchline), where the question intentionally sets up
two parallel and compatible scripts, and the answer
triggers the script switch. Below are the top-ranking
two-liners as rated by a group of fifteen subjects
(testing details in the next section). Each concept
is indicated in brackets and labeled with the script
from which the concept had originated:
Why does the [priest]root [kneel]S1 in
[church]S2? Because the [priest]root
wants to [propose woman]S1
</bodyText>
<equation confidence="0.3436765">
C,
S,
Q
A
Q
S2
Q
C2
Ew(ci) = E
ckEfin(cj) cjEfin(ci)
</equation>
<page confidence="0.782808">
152
</page>
<table confidence="0.664266727272727">
Why does the [priest]root [drink 100 Nonsense
coffee]S1 and [believe god]S2?
Because the [priest]root wants to
[wake up]S1
% (N=15) 80 Non-
60 humorous
40 Humorous
Hilarious
Why is the [computer]root [hot]S1 in 20
[mit]S2? Because [mit]S2 is [hell]S2 0
Baseline SM SM+CC Human
</table>
<footnote confidence="0.346806333333333">
Why is the [computer]root in
[hospital]S1? Because the
[computer]root has [virus]S2
</footnote>
<sectionHeader confidence="0.99916" genericHeader="method">
4 Results
</sectionHeader>
<bodyText confidence="0.987596625">
We evaluate the generated two-liners by presenting
them as human-generated to remove possible bias.
Fifteen subjects (N = 15, 12 male, 3 female - grad-
uate students in Mechanical Engineering and Com-
puter Science departments) were presented 48 high-
est ranking two-liners, and were asked to rate each
joke on the scale of 1 to 4 according to four cat-
egories: hilarious (4), humorous (3), not humor-
ous (2), nonsense(1). Each two-liner was generated
from one of the three root categories (12 two-liners
in each): priest, woman, computer, robot, and to
normalize against individual humor biases, human-
made two-liners were mixed in in the same cate-
gories. Two-liners generated by three different al-
gorithms were evaluated by each subject:
Script model + Concept clustering (SM+CC)
Both script opposition and incongruity are
favored through spreading activation and
concept clustering.
Script model only (SM) No concept clustering is
employed. Adherence of scripts to the script
model is ensured through spreading activation.
Baseline Loops are generated from a user-specified
root using depth first search. Loops are pruned
only to satisfy surface templates.
We compare the average scores between the two-
liners generated using both the script model and con-
cept clustering (SM+CC) (MEAN=1.95, STD=0.27)
and the baseline (MEAN=1.06, STD=0.58). We
observe that SM+CC algorithm yields significantly
higher-scoring two-liners (one-sided t-test) with
95% confidence.
</bodyText>
<figureCaption confidence="0.990249">
Figure 3: Human blind evaluation of generated two-liners
</figureCaption>
<bodyText confidence="0.999986105263158">
We observe that the fraction of non-humorous and
nonsensical two-liners generated is still significant.
Many non-humorous (but semantically sound) two-
liners were formed due to erroneous labels on the
concept clusters. While clustering provides a fun-
damental way to generate incongruity, noise in the
ConceptNet often leads of cluster overfitting, and as-
signs related concepts into separate clusters.
Nonsensical two-liners are primarily due to the in-
consistencies in POS with relation types within the
ConceptNet. Because our surface form templates
assume a part of speech, or a phrase type from the
ConceptNet specification, erroneous entries produce
nonsensical results. We partially address the prob-
lem by pruning low-scoring concepts (ConceptNet
features a SCORE attribute reflecting the number of
user votes for the concept), and all terminal nodes
from consideration (nodes that are not expanded by
users often indicate weak relationships).
</bodyText>
<sectionHeader confidence="0.998294" genericHeader="method">
5 Future Work
</sectionHeader>
<bodyText confidence="0.999860384615384">
Through observation of the generated semantic
paths, we note that more complex narratives, beyond
questions/answer forms can be produced from the
ConceptNet. Relaxing the rigid template constraint
of the surface realizer will allow for more diverse
types of generated humor. To mitigate the fragility
of concept clustering, we are augmenting the Con-
ceptNet with additional resources that provide do-
main knowledge. Resources such as SenticNet
(WordNet-Affect aligned with ConceptNet) (Cam-
bria et al., 2010b), and WordNet-Domains (Kolte
and Bhirud, 2008) are both viable avenues for robust
concept clustering and incongruity generation.
</bodyText>
<page confidence="0.999083">
153
</page>
<sectionHeader confidence="0.919114" genericHeader="conclusions">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.999778">
This paper is for my Babishan - the most important
person in my life.
Huge thanks to Max Kelner - those everyday teas at
Mattins and continuous inspiration.
This work was supported in part by NSF CDI Grant
ECCS 0941561. The content of this paper is solely
the responsibility of the authors and does not neces-
sarily represent the official views of the sponsoring
organizations.
</bodyText>
<sectionHeader confidence="0.998493" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999561428571428">
S. Attardo and V. Raskin. 1991. Script theory revis (it)
ed: Joke similarity and joke representation model. Hu-
mor: International Journal of Humor Research; Hu-
mor: International Journal of Humor Research.
K. Binsted and G. Ritchie. 1994. A symbolic description
of punning riddles and its computer implementation.
Arxiv preprint cmp-lg/9406021.
K. Binsted, A. Nijholt, O. Stock, C. Strapparava,
G. Ritchie, R. Manurung, H. Pain, A. Waller, and
D. O’Mara. 2006. Computational humor. Intelligent
Systems, IEEE, 21(2):59–69.
K. Binsted. 1996. Machine humour: An implemented
model of puns.
E. Cambria, A. Hussain, C. Havasi, and C. Eckl. 2010a.
Senticspace: visualizing opinions and sentiments in
a multi-dimensional vector space. Knowledge-Based
and Intelligent Information and Engineering Systems,
pages 385–393.
E. Cambria, R. Speer, C. Havasi, and A. Hussain. 2010b.
Senticnet: A publicly available semantic resource for
opinion mining. In Proceedings of the 2010 AAAI Fall
Symposium Series on Commonsense Knowledge.
A. Clauset, M.E.J. Newman, and C. Moore. 2004. Find-
ing community structure in very large networks. Phys-
ical review E, 70(6):066111.
F. Crestani. 1997. Retrieving documents by constrained
spreading activation on automatically constructed hy-
pertexts. In EUFIT 97-5th European Congress on In-
telligent Techniques and Soft Computing. Germany.
Citeseer.
L. Friedland and J. Allan. 2008. Joke retrieval: recogniz-
ing the same joke told differently. In Proceeding of the
17th ACM conference on Information and knowledge
management, pages 883–892. ACM.
C.F. Hempelmann, V. Raskin, and K.E. Triezenberg.
2006. Computer, tell me a joke... but please make it
funny: Computational humor with ontological seman-
tics. In Proceedings of the Nineteenth International
Florida Artificial Intelligence Research Society Con-
ference, Melbourne Beach, Florida, USA, May 11, vol-
ume 13, pages 746–751.
S.G. Kolte and S.G. Bhirud. 2008. Word sense disam-
biguation using wordnet domains. In Emerging Trends
in Engineering and Technology, 2008. ICETET’08.
First International Conference on, pages 1187–1191.
IEEE.
H. Liu and P. Singh. 2004. Conceptneta practical com-
monsense reasoning tool-kit. BT technology journal,
22(4):211–226.
R. Mihalcea and C. Strapparava. 2006. Learning to laugh
(automatically): Computational models for humor
recognition. Computational Intelligence, 22(2):126–
142.
M.E.J. Newman. 2006. Modularity and community
structure in networks. Proceedings of the National
Academy of Sciences, 103(23):8577–8582.
A. Nijholt, O. Stock, A. Dix, and J. Morkes. 2003. Hu-
mor modeling in the interface. In CHI’03 extended ab-
stracts on Human factors in computing systems, pages
1050–1051. ACM.
V. Raskin. 1998. The sense of humor and the truth. The
Sense of Humor. Explorations of a Personality Char-
acteristic, Berlin: Mouton De Gruyter, pages 95–108.
G. Ritchie, R. Manurung, H. Pain, A. Waller, R. Black,
and D. OMara. 2007. A practical application of com-
putational humour. In Proceedings of the 4th. Inter-
national Joint Workshop on Computational Creativity,
London, UK.
G. Ritchie. 2001. Current directions in computational
humour. Artificial Intelligence Review, 16(2):119–
135.
W. Ruch, S. Attardo, and V. Raskin. 1993. Toward an
empirical verification of the general theory of verbal
humor. Humor: International Journal of Humor Re-
search; Humor: International Journal of Humor Re-
search.
J. Savoy. 1992. Bayesian inference networks and spread-
ing activation in hypertext systems. Information pro-
cessing &amp; management, 28(3):389–406.
S. Spagnola and C. Lagoze. 2011. Edge dependent
pathway scoring for calculating semantic similarity in
conceptnet. In Proceedings of the Ninth International
Conference on Computational Semantics, pages 385–
389. Association for Computational Linguistics.
O. Stock and C. Strapparava. 2002. Hahacronym:
Humorous agents for humorous acronyms. Stock,
Oliviero, Carlo Strapparava, and Anton Nijholt. Eds,
pages 125–135.
I. Swartjes and M. Theune. 2006. A fabula model for
emergent narrative. Technologies for Interactive Digi-
tal Storytelling and Entertainment, pages 49–60.
</reference>
<page confidence="0.99746">
154
</page>
<reference confidence="0.999690230769231">
J.M. Taylor and L.J. Mazlack. 2004. Humorous word-
play recognition. In Systems, Man and Cybernetics,
2004 IEEE International Conference on, volume 4,
pages 3306–3311. IEEE.
J. Taylor and L. Mazlack. 2005. Toward computational
recognition of humorous intent. In Proceedings of
Cognitive Science Conference, pages 2166–2171.
J.M. Taylor. 2009. Computational detection of humor: A
dream or a nightmare? the ontological semantics ap-
proach. In Proceedings of the 2009 IEEE/WIC/ACM
International Joint Conference on Web Intelligence
and Intelligent Agent Technology-Volume 03, pages
429–432. IEEE Computer Society.
</reference>
<page confidence="0.999013">
155
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.967371">
<title confidence="0.999567">Humor as Circuits in Semantic Networks</title>
<author confidence="0.992206">Igor Labutov Hod Lipson</author>
<affiliation confidence="0.999986">Cornell University Cornell University</affiliation>
<email confidence="0.995361">iil4@cornell.eduhod.lipson@cornell.edu</email>
<abstract confidence="0.998602555555556">This work presents a first step to a general implementation of the Semantic-Script Theory of Humor (SSTH). Of the scarce amount of research in computational humor, no research had focused on humor generation beyond simple puns and punning riddles. We propose an algorithm for mining simple humorous scripts from a semantic network (Concept- Net) by specifically searching for dual scripts that jointly maximize overlap and incongruity metrics in line with Raskin’s Semantic-Script Theory of Humor. Initial results show that a more relaxed constraint of this form is capable of generating humor of deeper semantic content than wordplay riddles. We evaluate the said metrics through a user-assessed quality of the generated two-liners.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Attardo</author>
<author>V Raskin</author>
</authors>
<title>Script theory revis (it) ed: Joke similarity and joke representation model.</title>
<date>1991</date>
<journal>Humor: International Journal of Humor Research; Humor: International Journal of Humor Research.</journal>
<contexts>
<context position="1969" citStr="Attardo and Raskin, 1991" startWordPosition="298" endWordPosition="301">cation (Mihalcea and Strapparava, 2006), and humancomputer interaction (Nijholt et al., 2003), the application of humor generation is not any less significant. First, a good generative model of humor has the potential to outperform current discriminative models for humor recognition. Thus, ability to Figure 1: Semantic circuit generate humor will potentially lead to better humor detection. Second, a computational model that conforms to the verbal theory of humor is an accessible avenue for verifying the psycholinguistic theory. In this paper we take the Semantic Script Theory of Humor (SSTH) (Attardo and Raskin, 1991) - a widely accepted theory of verbal humor and build a generative model that conforms to it. Much of the existing work in humor generation had focused on puns and punning riddles - humor that is centered around wordplay. And while more recent of such implementations (Hempelmann et al., 2006) take a knowledge-based approach that is rooted in the linguistic theory (SSTH), the constraint, nevertheless, significantly limits the potential of SSTH. To our knowledge, our work is the first attempt to instantiate the theory at the fundamental level, without imposing constraints on phonological similar</context>
</contexts>
<marker>Attardo, Raskin, 1991</marker>
<rawString>S. Attardo and V. Raskin. 1991. Script theory revis (it) ed: Joke similarity and joke representation model. Humor: International Journal of Humor Research; Humor: International Journal of Humor Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Binsted</author>
<author>G Ritchie</author>
</authors>
<title>A symbolic description of punning riddles and its computer implementation. Arxiv preprint cmp-lg/9406021.</title>
<date>1994</date>
<contexts>
<context position="4057" citStr="Binsted and Ritchie, 1994" startWordPosition="630" endWordPosition="633">retation to the alternate (less likely) script. The alternate script must differ significantly in meaning (be incongruent with the first script) for the switch to have a humorous effect. An example below illustrates this idea (S1 is the obvious script, and S2 is the alternate script. Bracketed phrases are labeled with the associated script). “Is the [doctor]S1 at home?”the [patient]S1 asked in his [bronchial]S1 [whisper]S2. “No,”the [doctor’s]S1 [young and pretty wife]S2 [whispered]S2 in reply. [“Come right in.”]S2 (Raskin, 1985) 2 Related Work Of the early prototypes of pun-generators, JAPE (Binsted and Ritchie, 1994), and its successor, STANDUP (Ritchie et al., 2007), produced question/answer punning riddles from general nonhumorous lexicon. While humor in the generated puns could be explained by SSTH, the SSTH model itself was not employed in the process of generation. Recent work of Hempelmann (2006) comes closer to utilizing SSTH. While still focused on generating puns, they do so by explicitly defining and applying script opposition (SO) using ontological semantics. Of the more successful pun generators are systems that exploit lexical resources. HAHAcronym (Stock and Strapparava, 2002), a system for </context>
</contexts>
<marker>Binsted, Ritchie, 1994</marker>
<rawString>K. Binsted and G. Ritchie. 1994. A symbolic description of punning riddles and its computer implementation. Arxiv preprint cmp-lg/9406021.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Binsted</author>
<author>A Nijholt</author>
<author>O Stock</author>
<author>C Strapparava</author>
<author>G Ritchie</author>
<author>R Manurung</author>
<author>H Pain</author>
<author>A Waller</author>
<author>D O’Mara</author>
</authors>
<date>2006</date>
<booktitle>Computational humor. Intelligent Systems, IEEE,</booktitle>
<pages>21--2</pages>
<marker>Binsted, Nijholt, Stock, Strapparava, Ritchie, Manurung, Pain, Waller, O’Mara, 2006</marker>
<rawString>K. Binsted, A. Nijholt, O. Stock, C. Strapparava, G. Ritchie, R. Manurung, H. Pain, A. Waller, and D. O’Mara. 2006. Computational humor. Intelligent Systems, IEEE, 21(2):59–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Binsted</author>
</authors>
<title>Machine humour: An implemented model of puns.</title>
<date>1996</date>
<marker>Binsted, 1996</marker>
<rawString>K. Binsted. 1996. Machine humour: An implemented model of puns.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Cambria</author>
<author>A Hussain</author>
<author>C Havasi</author>
<author>C Eckl</author>
</authors>
<title>Senticspace: visualizing opinions and sentiments in a multi-dimensional vector space. Knowledge-Based and Intelligent Information and Engineering Systems,</title>
<date>2010</date>
<pages>385--393</pages>
<marker>Cambria, Hussain, Havasi, Eckl, 2010</marker>
<rawString>E. Cambria, A. Hussain, C. Havasi, and C. Eckl. 2010a. Senticspace: visualizing opinions and sentiments in a multi-dimensional vector space. Knowledge-Based and Intelligent Information and Engineering Systems, pages 385–393.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Cambria</author>
<author>R Speer</author>
<author>C Havasi</author>
<author>A Hussain</author>
</authors>
<title>Senticnet: A publicly available semantic resource for opinion mining.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 AAAI Fall Symposium Series on Commonsense Knowledge.</booktitle>
<marker>Cambria, Speer, Havasi, Hussain, 2010</marker>
<rawString>E. Cambria, R. Speer, C. Havasi, and A. Hussain. 2010b. Senticnet: A publicly available semantic resource for opinion mining. In Proceedings of the 2010 AAAI Fall Symposium Series on Commonsense Knowledge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Clauset</author>
<author>M E J Newman</author>
<author>C Moore</author>
</authors>
<title>Finding community structure in very large networks. Physical review E,</title>
<date>2004</date>
<contexts>
<context position="9931" citStr="Clauset et al., 2004" startWordPosition="1596" endWordPosition="1599">tion concepts Sk (number of nodes in the kth chain). A set of scripts S with the highest scores in the highest ranking circuits represent scripts that are likely to be feasible and display a significant amount of semantic overlap within the circuit. 3.3 Incongruity and surface realization The task is to select a script pair {Si, Sj i =� j} E S x S and a set of concepts C E Si U Sj that will align with some surface template, while maximizing inter-script incongruity. As a measure of concept incongruity, we hierarchically cluster the entire ConceptNet using a Fast Community Detection algorithm (Clauset et al., 2004). We observe that clusters are generated for related concepts, such as religion, marriage, computers. Each template presents up to two concepts {c1 E Si, c2 E Sj i =� j} in the question sentence (Q in Figure 2), and one concept c3 E Si U Sj in the answer sentence (A in Figure 2). The motivation of this approach is that the two concepts in the question are selected from two different scripts but from the same cluster, while the answer concept is selected from one of the two scripts and from a different cluster. The effect the generated two-liner produces is that of a setup and resolution (punch</context>
</contexts>
<marker>Clauset, Newman, Moore, 2004</marker>
<rawString>A. Clauset, M.E.J. Newman, and C. Moore. 2004. Finding community structure in very large networks. Physical review E, 70(6):066111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Crestani</author>
</authors>
<title>Retrieving documents by constrained spreading activation on automatically constructed hypertexts.</title>
<date>1997</date>
<booktitle>In EUFIT 97-5th European Congress on Intelligent Techniques and Soft Computing.</booktitle>
<location>Germany. Citeseer.</location>
<marker>Crestani, 1997</marker>
<rawString>F. Crestani. 1997. Retrieving documents by constrained spreading activation on automatically constructed hypertexts. In EUFIT 97-5th European Congress on Intelligent Techniques and Soft Computing. Germany. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Friedland</author>
<author>J Allan</author>
</authors>
<title>Joke retrieval: recognizing the same joke told differently.</title>
<date>2008</date>
<booktitle>In Proceeding of the 17th ACM conference on Information and knowledge management,</booktitle>
<pages>883--892</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="1324" citStr="Friedland and Allan, 2008" startWordPosition="197" endWordPosition="200">of this form is capable of generating humor of deeper semantic content than wordplay riddles. We evaluate the said metrics through a user-assessed quality of the generated two-liners. 1 Introduction While of significant interest in linguistics and philosophy, humor had received less attention in the computational domain. And of that work, most recent is predominately focused on humor recognition. See (Ritchie, 2001) for a good review. In this paper we focus on the problem of humor generation. While humor/sarcasm recognition merits direct application to the areas such as information retrieval (Friedland and Allan, 2008), sentiment classification (Mihalcea and Strapparava, 2006), and humancomputer interaction (Nijholt et al., 2003), the application of humor generation is not any less significant. First, a good generative model of humor has the potential to outperform current discriminative models for humor recognition. Thus, ability to Figure 1: Semantic circuit generate humor will potentially lead to better humor detection. Second, a computational model that conforms to the verbal theory of humor is an accessible avenue for verifying the psycholinguistic theory. In this paper we take the Semantic Script Theo</context>
</contexts>
<marker>Friedland, Allan, 2008</marker>
<rawString>L. Friedland and J. Allan. 2008. Joke retrieval: recognizing the same joke told differently. In Proceeding of the 17th ACM conference on Information and knowledge management, pages 883–892. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C F Hempelmann</author>
<author>V Raskin</author>
<author>K E Triezenberg</author>
</authors>
<title>Computer, tell me a joke... but please make it funny: Computational humor with ontological semantics.</title>
<date>2006</date>
<booktitle>In Proceedings of the Nineteenth International</booktitle>
<contexts>
<context position="2262" citStr="Hempelmann et al., 2006" startWordPosition="349" endWordPosition="352">lity to Figure 1: Semantic circuit generate humor will potentially lead to better humor detection. Second, a computational model that conforms to the verbal theory of humor is an accessible avenue for verifying the psycholinguistic theory. In this paper we take the Semantic Script Theory of Humor (SSTH) (Attardo and Raskin, 1991) - a widely accepted theory of verbal humor and build a generative model that conforms to it. Much of the existing work in humor generation had focused on puns and punning riddles - humor that is centered around wordplay. And while more recent of such implementations (Hempelmann et al., 2006) take a knowledge-based approach that is rooted in the linguistic theory (SSTH), the constraint, nevertheless, significantly limits the potential of SSTH. To our knowledge, our work is the first attempt to instantiate the theory at the fundamental level, without imposing constraints on phonological similarity, or a restricted set of domain oppositions. 150 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 150–155, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics 1.1 Semantic Script Theory of Humor The Semanti</context>
</contexts>
<marker>Hempelmann, Raskin, Triezenberg, 2006</marker>
<rawString>C.F. Hempelmann, V. Raskin, and K.E. Triezenberg. 2006. Computer, tell me a joke... but please make it funny: Computational humor with ontological semantics. In Proceedings of the Nineteenth International</rawString>
</citation>
<citation valid="true">
<authors>
<author>Florida Artificial</author>
</authors>
<title>Intelligence Research Society Conference,</title>
<date></date>
<volume>11</volume>
<pages>746--751</pages>
<location>Melbourne Beach, Florida, USA,</location>
<marker>Artificial, </marker>
<rawString>Florida Artificial Intelligence Research Society Conference, Melbourne Beach, Florida, USA, May 11, volume 13, pages 746–751.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S G Kolte</author>
<author>S G Bhirud</author>
</authors>
<title>Word sense disambiguation using wordnet domains.</title>
<date>2008</date>
<booktitle>In Emerging Trends in Engineering and Technology,</booktitle>
<pages>1187--1191</pages>
<publisher>IEEE.</publisher>
<marker>Kolte, Bhirud, 2008</marker>
<rawString>S.G. Kolte and S.G. Bhirud. 2008. Word sense disambiguation using wordnet domains. In Emerging Trends in Engineering and Technology, 2008. ICETET’08. First International Conference on, pages 1187–1191. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Liu</author>
<author>P Singh</author>
</authors>
<title>Conceptneta practical commonsense reasoning tool-kit.</title>
<date>2004</date>
<booktitle>BT technology journal,</booktitle>
<pages>22--4</pages>
<contexts>
<context position="5188" citStr="Liu and Singh, 2004" startWordPosition="799" endWordPosition="802">s that exploit lexical resources. HAHAcronym (Stock and Strapparava, 2002), a system for generating humorous acronyms, for example, utilizes WordNetDomains to select phonologically similar concepts from semantically disparate domains. While the degree of humor sophistication from the above systems varies with the sophistication of the method (lexical resources, surface realizers), they all, without exception, rely on phonological constraints to produce script opposition, whereas a phonological constraint is just one of the many ways to generate script opposition. 3 System overview ConceptNet (Liu and Singh, 2004) lends itself as an ideal ontological resource for script generation. As a network that connects everyday concepts and events with a set of causal and spatial relationships, the relational structure of ConceptNet parallels the structure of the fabula model of story generation - namely the General Transition Network (GTN) (Swartjes and Theune, 2006). As such, we hypothesize that there exist paths within the ConceptNet graph that can be represented as feasible scripts in the surface form. Moreover, multiple paths between two given nodes represent overlapping scripts - a necessary condition for v</context>
</contexts>
<marker>Liu, Singh, 2004</marker>
<rawString>H. Liu and P. Singh. 2004. Conceptneta practical commonsense reasoning tool-kit. BT technology journal, 22(4):211–226.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>C Strapparava</author>
</authors>
<title>Learning to laugh (automatically): Computational models for humor recognition.</title>
<date>2006</date>
<journal>Computational Intelligence,</journal>
<volume>22</volume>
<issue>2</issue>
<pages>142</pages>
<contexts>
<context position="1383" citStr="Mihalcea and Strapparava, 2006" startWordPosition="204" endWordPosition="207">semantic content than wordplay riddles. We evaluate the said metrics through a user-assessed quality of the generated two-liners. 1 Introduction While of significant interest in linguistics and philosophy, humor had received less attention in the computational domain. And of that work, most recent is predominately focused on humor recognition. See (Ritchie, 2001) for a good review. In this paper we focus on the problem of humor generation. While humor/sarcasm recognition merits direct application to the areas such as information retrieval (Friedland and Allan, 2008), sentiment classification (Mihalcea and Strapparava, 2006), and humancomputer interaction (Nijholt et al., 2003), the application of humor generation is not any less significant. First, a good generative model of humor has the potential to outperform current discriminative models for humor recognition. Thus, ability to Figure 1: Semantic circuit generate humor will potentially lead to better humor detection. Second, a computational model that conforms to the verbal theory of humor is an accessible avenue for verifying the psycholinguistic theory. In this paper we take the Semantic Script Theory of Humor (SSTH) (Attardo and Raskin, 1991) - a widely ac</context>
</contexts>
<marker>Mihalcea, Strapparava, 2006</marker>
<rawString>R. Mihalcea and C. Strapparava. 2006. Learning to laugh (automatically): Computational models for humor recognition. Computational Intelligence, 22(2):126– 142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M E J Newman</author>
</authors>
<title>Modularity and community structure in networks.</title>
<date>2006</date>
<booktitle>Proceedings of the National Academy of Sciences,</booktitle>
<pages>103--23</pages>
<marker>Newman, 2006</marker>
<rawString>M.E.J. Newman. 2006. Modularity and community structure in networks. Proceedings of the National Academy of Sciences, 103(23):8577–8582.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Nijholt</author>
<author>O Stock</author>
<author>A Dix</author>
<author>J Morkes</author>
</authors>
<title>Humor modeling in the interface.</title>
<date>2003</date>
<booktitle>In CHI’03 extended abstracts on Human factors in computing systems,</booktitle>
<pages>1050--1051</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="1437" citStr="Nijholt et al., 2003" startWordPosition="212" endWordPosition="215">rics through a user-assessed quality of the generated two-liners. 1 Introduction While of significant interest in linguistics and philosophy, humor had received less attention in the computational domain. And of that work, most recent is predominately focused on humor recognition. See (Ritchie, 2001) for a good review. In this paper we focus on the problem of humor generation. While humor/sarcasm recognition merits direct application to the areas such as information retrieval (Friedland and Allan, 2008), sentiment classification (Mihalcea and Strapparava, 2006), and humancomputer interaction (Nijholt et al., 2003), the application of humor generation is not any less significant. First, a good generative model of humor has the potential to outperform current discriminative models for humor recognition. Thus, ability to Figure 1: Semantic circuit generate humor will potentially lead to better humor detection. Second, a computational model that conforms to the verbal theory of humor is an accessible avenue for verifying the psycholinguistic theory. In this paper we take the Semantic Script Theory of Humor (SSTH) (Attardo and Raskin, 1991) - a widely accepted theory of verbal humor and build a generative m</context>
</contexts>
<marker>Nijholt, Stock, Dix, Morkes, 2003</marker>
<rawString>A. Nijholt, O. Stock, A. Dix, and J. Morkes. 2003. Humor modeling in the interface. In CHI’03 extended abstracts on Human factors in computing systems, pages 1050–1051. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Raskin</author>
</authors>
<title>The sense of humor and the truth. The Sense of Humor. Explorations of a Personality Characteristic, Berlin: Mouton De Gruyter,</title>
<date>1998</date>
<pages>95--108</pages>
<marker>Raskin, 1998</marker>
<rawString>V. Raskin. 1998. The sense of humor and the truth. The Sense of Humor. Explorations of a Personality Characteristic, Berlin: Mouton De Gruyter, pages 95–108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Ritchie</author>
<author>R Manurung</author>
<author>H Pain</author>
<author>A Waller</author>
<author>R Black</author>
<author>D OMara</author>
</authors>
<title>A practical application of computational humour.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th. International Joint Workshop on Computational Creativity,</booktitle>
<location>London, UK.</location>
<contexts>
<context position="4108" citStr="Ritchie et al., 2007" startWordPosition="638" endWordPosition="641">rnate script must differ significantly in meaning (be incongruent with the first script) for the switch to have a humorous effect. An example below illustrates this idea (S1 is the obvious script, and S2 is the alternate script. Bracketed phrases are labeled with the associated script). “Is the [doctor]S1 at home?”the [patient]S1 asked in his [bronchial]S1 [whisper]S2. “No,”the [doctor’s]S1 [young and pretty wife]S2 [whispered]S2 in reply. [“Come right in.”]S2 (Raskin, 1985) 2 Related Work Of the early prototypes of pun-generators, JAPE (Binsted and Ritchie, 1994), and its successor, STANDUP (Ritchie et al., 2007), produced question/answer punning riddles from general nonhumorous lexicon. While humor in the generated puns could be explained by SSTH, the SSTH model itself was not employed in the process of generation. Recent work of Hempelmann (2006) comes closer to utilizing SSTH. While still focused on generating puns, they do so by explicitly defining and applying script opposition (SO) using ontological semantics. Of the more successful pun generators are systems that exploit lexical resources. HAHAcronym (Stock and Strapparava, 2002), a system for generating humorous acronyms, for example, utilizes</context>
</contexts>
<marker>Ritchie, Manurung, Pain, Waller, Black, OMara, 2007</marker>
<rawString>G. Ritchie, R. Manurung, H. Pain, A. Waller, R. Black, and D. OMara. 2007. A practical application of computational humour. In Proceedings of the 4th. International Joint Workshop on Computational Creativity, London, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Ritchie</author>
</authors>
<title>Current directions in computational humour.</title>
<date>2001</date>
<journal>Artificial Intelligence Review,</journal>
<volume>16</volume>
<issue>2</issue>
<pages>135</pages>
<contexts>
<context position="1117" citStr="Ritchie, 2001" startWordPosition="165" endWordPosition="166">ically searching for dual scripts that jointly maximize overlap and incongruity metrics in line with Raskin’s Semantic-Script Theory of Humor. Initial results show that a more relaxed constraint of this form is capable of generating humor of deeper semantic content than wordplay riddles. We evaluate the said metrics through a user-assessed quality of the generated two-liners. 1 Introduction While of significant interest in linguistics and philosophy, humor had received less attention in the computational domain. And of that work, most recent is predominately focused on humor recognition. See (Ritchie, 2001) for a good review. In this paper we focus on the problem of humor generation. While humor/sarcasm recognition merits direct application to the areas such as information retrieval (Friedland and Allan, 2008), sentiment classification (Mihalcea and Strapparava, 2006), and humancomputer interaction (Nijholt et al., 2003), the application of humor generation is not any less significant. First, a good generative model of humor has the potential to outperform current discriminative models for humor recognition. Thus, ability to Figure 1: Semantic circuit generate humor will potentially lead to bett</context>
</contexts>
<marker>Ritchie, 2001</marker>
<rawString>G. Ritchie. 2001. Current directions in computational humour. Artificial Intelligence Review, 16(2):119– 135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Ruch</author>
<author>S Attardo</author>
<author>V Raskin</author>
</authors>
<title>Toward an empirical verification of the general theory of verbal humor.</title>
<date>1993</date>
<journal>Humor: International Journal of Humor Research; Humor: International Journal of Humor Research.</journal>
<contexts>
<context position="2989" citStr="Ruch et al., 1993" startWordPosition="459" endWordPosition="462">, significantly limits the potential of SSTH. To our knowledge, our work is the first attempt to instantiate the theory at the fundamental level, without imposing constraints on phonological similarity, or a restricted set of domain oppositions. 150 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 150–155, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics 1.1 Semantic Script Theory of Humor The Semantic Script Theory of Humor (SSTH) provides machinery to formalize the structure of most types of verbal humor (Ruch et al., 1993). SSTH posits an existence of two underlying scripts, one of which is more obvious than the other. To be humorous, the underlying scripts must satisfy two conditions: overlap and incongruity. In the setup phase of the joke, instances of the two scripts are presented in a way that does not give away the less obvious script (due to their overlap). In the punchline (resolution), a trigger expression forces the audience to switch their interpretation to the alternate (less likely) script. The alternate script must differ significantly in meaning (be incongruent with the first script) for the switc</context>
</contexts>
<marker>Ruch, Attardo, Raskin, 1993</marker>
<rawString>W. Ruch, S. Attardo, and V. Raskin. 1993. Toward an empirical verification of the general theory of verbal humor. Humor: International Journal of Humor Research; Humor: International Journal of Humor Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Savoy</author>
</authors>
<title>Bayesian inference networks and spreading activation in hypertext systems.</title>
<date>1992</date>
<journal>Information processing &amp; management,</journal>
<volume>28</volume>
<issue>3</issue>
<marker>Savoy, 1992</marker>
<rawString>J. Savoy. 1992. Bayesian inference networks and spreading activation in hypertext systems. Information processing &amp; management, 28(3):389–406.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Spagnola</author>
<author>C Lagoze</author>
</authors>
<title>Edge dependent pathway scoring for calculating semantic similarity in conceptnet.</title>
<date>2011</date>
<booktitle>In Proceedings of the Ninth International Conference on Computational Semantics,</booktitle>
<pages>385--389</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Spagnola, Lagoze, 2011</marker>
<rawString>S. Spagnola and C. Lagoze. 2011. Edge dependent pathway scoring for calculating semantic similarity in conceptnet. In Proceedings of the Ninth International Conference on Computational Semantics, pages 385– 389. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Stock</author>
<author>C Strapparava</author>
</authors>
<title>Hahacronym: Humorous agents for humorous acronyms.</title>
<date>2002</date>
<journal>Stock, Oliviero, Carlo Strapparava, and Anton Nijholt. Eds,</journal>
<pages>125--135</pages>
<contexts>
<context position="4642" citStr="Stock and Strapparava, 2002" startWordPosition="718" endWordPosition="721">enerators, JAPE (Binsted and Ritchie, 1994), and its successor, STANDUP (Ritchie et al., 2007), produced question/answer punning riddles from general nonhumorous lexicon. While humor in the generated puns could be explained by SSTH, the SSTH model itself was not employed in the process of generation. Recent work of Hempelmann (2006) comes closer to utilizing SSTH. While still focused on generating puns, they do so by explicitly defining and applying script opposition (SO) using ontological semantics. Of the more successful pun generators are systems that exploit lexical resources. HAHAcronym (Stock and Strapparava, 2002), a system for generating humorous acronyms, for example, utilizes WordNetDomains to select phonologically similar concepts from semantically disparate domains. While the degree of humor sophistication from the above systems varies with the sophistication of the method (lexical resources, surface realizers), they all, without exception, rely on phonological constraints to produce script opposition, whereas a phonological constraint is just one of the many ways to generate script opposition. 3 System overview ConceptNet (Liu and Singh, 2004) lends itself as an ideal ontological resource for scr</context>
</contexts>
<marker>Stock, Strapparava, 2002</marker>
<rawString>O. Stock and C. Strapparava. 2002. Hahacronym: Humorous agents for humorous acronyms. Stock, Oliviero, Carlo Strapparava, and Anton Nijholt. Eds, pages 125–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Swartjes</author>
<author>M Theune</author>
</authors>
<title>A fabula model for emergent narrative. Technologies for Interactive Digital Storytelling and Entertainment,</title>
<date>2006</date>
<pages>49--60</pages>
<contexts>
<context position="5538" citStr="Swartjes and Theune, 2006" startWordPosition="854" endWordPosition="857">(lexical resources, surface realizers), they all, without exception, rely on phonological constraints to produce script opposition, whereas a phonological constraint is just one of the many ways to generate script opposition. 3 System overview ConceptNet (Liu and Singh, 2004) lends itself as an ideal ontological resource for script generation. As a network that connects everyday concepts and events with a set of causal and spatial relationships, the relational structure of ConceptNet parallels the structure of the fabula model of story generation - namely the General Transition Network (GTN) (Swartjes and Theune, 2006). As such, we hypothesize that there exist paths within the ConceptNet graph that can be represented as feasible scripts in the surface form. Moreover, multiple paths between two given nodes represent overlapping scripts - a necessary condition for verbal humor in SSTH. Given a semantic network hypergraph G = (V, G) where V E Concepts, G E Relations, we hypothesize that it is possible to search for script-pairs as semantic circuits that can be converted to a surface form of the Question/Answer format. We define a circuit as two paths from root A that terminate at a common node B. Our approach </context>
</contexts>
<marker>Swartjes, Theune, 2006</marker>
<rawString>I. Swartjes and M. Theune. 2006. A fabula model for emergent narrative. Technologies for Interactive Digital Storytelling and Entertainment, pages 49–60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Taylor</author>
<author>L J Mazlack</author>
</authors>
<title>Humorous wordplay recognition. In Systems, Man and Cybernetics,</title>
<date>2004</date>
<booktitle>IEEE International Conference on,</booktitle>
<volume>4</volume>
<pages>3306--3311</pages>
<publisher>IEEE.</publisher>
<marker>Taylor, Mazlack, 2004</marker>
<rawString>J.M. Taylor and L.J. Mazlack. 2004. Humorous wordplay recognition. In Systems, Man and Cybernetics, 2004 IEEE International Conference on, volume 4, pages 3306–3311. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Taylor</author>
<author>L Mazlack</author>
</authors>
<title>Toward computational recognition of humorous intent.</title>
<date>2005</date>
<booktitle>In Proceedings of Cognitive Science Conference,</booktitle>
<pages>2166--2171</pages>
<marker>Taylor, Mazlack, 2005</marker>
<rawString>J. Taylor and L. Mazlack. 2005. Toward computational recognition of humorous intent. In Proceedings of Cognitive Science Conference, pages 2166–2171.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Taylor</author>
</authors>
<title>Computational detection of humor: A dream or a nightmare? the ontological semantics approach.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology-Volume 03,</booktitle>
<pages>429--432</pages>
<publisher>IEEE Computer Society.</publisher>
<marker>Taylor, 2009</marker>
<rawString>J.M. Taylor. 2009. Computational detection of humor: A dream or a nightmare? the ontological semantics approach. In Proceedings of the 2009 IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology-Volume 03, pages 429–432. IEEE Computer Society.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>