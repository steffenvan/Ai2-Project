<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.059248">
<note confidence="0.291696">
Book Reviews
</note>
<title confidence="0.956627">
Lexicon Development for Speech and Language Processing
</title>
<author confidence="0.72803">
Frank Van Eynde and Dafydd Gibbon (editors)
</author>
<affiliation confidence="0.85069">
(University of Leuven and University of Bielefeld)
Dordrecht: Kluwer Academic
</affiliation>
<bodyText confidence="0.7800026">
Publishers (Text, speech and language
technology series, edited by Nancy Ide
and Jean Veronis, volume 12), 2000,
xi+298 pp; hardbound, ISBN
0-7923-6368-X, $128.00, £79.00, €109.00
</bodyText>
<footnote confidence="0.752103">
Reviewed by
Ken Litkowski
CL Research
</footnote>
<bodyText confidence="0.999820428571429">
As a computational lexicologist with little background in speech technology, I ap-
proached this book as an opportunity to gain a basic understanding of how lexicons
are used in speech and to see whether semantically oriented lexicons from my work
could bring something to this field. The first objective was met, but the second was
not. This book arose from the 1997 Fifth European Summer School on Language and
Speech Communication under the auspices of the European Language and Speech
Network (ELSNET) and is the report of nine of the ten lectures. The book offers a
&amp;quot;survey of methods and techniques for structuring, acquiring and maintaining lexical
resources for speech and language processing&amp;quot; (p. ix).
As part of my first objective, I learned that speech technology is greatly hampered
by limitations on the size of the lexicon that can be handled efficiently in real systems.
The amount of data is overwhelmed by the need to use signal data in analog or digital
form. The speech community has to resort to and develop many tricks for working
with the prodigious amount of data. This book provides an appropriate overview
of the complexity of the problems and will serve well as background reading in an
introductory computational linguistics course. Each of the papers is well referenced,
with the authors providing their (important) guides to further details.
The organization of the book is not optimal, however. It consists of an overview,
two papers on lexical formalisms, two research papers, three database papers, and a
final research paper. Logically, the database papers should be first, followed by the
research papers, the lexical formalisms, and finally the overview. The quality of the
papers and the editing is high; the contributors clearly worked to turn their lectures
into readable form. I will present comments based on the logical order, rather than the
physical order.
Christoph Draxler (&amp;quot;Speech databases,&amp;quot; Chapter 6) provides an overview of what
kind of database technology is required in speech technology, albeit with little reference
to the lexicon. This paper shows the impressive range of speech material, describing
recording mechanisms and annotation levels. Silvia Quazza and Henk van den Heuvel
(&amp;quot;The use of lexica in text-to-speech systems,&amp;quot; Chapter 7) outline practical steps for
putting together the components of a text-to-speech system and for building the lexi-
con, showing quite well where the lexicon comes into play. This chapter has the most
detailed information about what lexical information is used in speech systems and
how. Martine Adda-Decker and Lori Lamel (&amp;quot;The use of lexica in automatic speech
recognition,&amp;quot; Chapter 8) carry us through the design and development of the lexical
information used in recognition, describing what is required of the lexicon for de-
</bodyText>
<page confidence="0.994615">
457
</page>
<note confidence="0.643441">
Computational Linguistics Volume 27, Number 3
</note>
<bodyText confidence="0.997699139534884">
coding speech. It is here that the size of the lexicon evinces the complexities and is
likely the place where ingenious (semantic) solutions are most needed for recognizers
to &amp;quot;understand&amp;quot; speech. These three papers provide the backbone of the book.
The three research papers represent examples of ongoing research; all are pre-
sented quite well, giving the reader a sense of active problems. Walter Daelemans and
Gert Durieux (&amp;quot;Inductive lexica,&amp;quot; Chapter 4) describe their work on inducing regular-
ities implicit in phonological lexical representations using &amp;quot;memory-based learning&amp;quot;
machine learning techniques. The methods followed are clearly laid out, providing
an introduction to the authors&apos; research, which may be followed via their references.
The other two research papers do not have a close tie to speech. R. Harald Baayen,
Robert Schreuder, and Richard Sproat (&amp;quot;Morphology in the mental lexicon: A compu-
tational model for visual word recognition,&amp;quot; Chapter 9) present investigations on the
relative time of lexical processing for morphologically complex words; such research
may eventually help in the design of computational lexicons for speech processing,
via activation of potentially matching lexical candidates. Gregory Grefenstette, Anne
Schiller, and Salah Ait-Mokhtar (&amp;quot;Recognizing Lexical Patterns in Text&amp;quot;, Chapter 5)
provide an introduction to finite-state automata for recognizing compound noun pat-
terns in building a lexicon; in addition to its introductory pedagogic value, the paper
describes a fully developed system.
Gosse Bouma, Frank Van Eynde, and Dan Flickinger (&amp;quot;Constraint-based lexica,&amp;quot;
Chapter 2) provide an introduction to the HPSG formalism. Although the presentation
is clear, there is no tie to speech or to speech systems. Lynne Cahill, Julie Carson-
Berndsen, and Gerald Gazdar (&amp;quot;Phonology-based lexical knowledge representation,&amp;quot;
Chapter 3) present a tutorial on the DATR formalism, valuable in itself, but more
importantly they demonstrate how this formalism can be used for phonetic or phono-
logical representations. There are 34 &amp;quot;exercises&amp;quot; in the tutorial; however, these may
not be as useful in the book as they would have been in the summer school.
The introduction and overview to the book (&amp;quot;Computational lexicography,&amp;quot; by
Dafydd Gibbon), which needs to be read both first and again after reading the other
chapters, brings together the papers in the volume under the author&apos;s development of
an &amp;quot;integrated lexical sign model.&amp;quot; This is a little forced, but useful for providing an
overview of the lexicon in speech processing. However, there is a strong element of
Unix hacking, without a comprehensive view of traditional computational lexicology
and no reference to computational lexicography as may be practiced by dictionary
publishers (e.g., corpus evidence).
As to the second objective stated above, the incorporation of semantics into speech
seems a long way off. However, the dialogue can begin.
Ken Litkowski is a computational lexicologist with CL Research (http://www.clres.com). He is cur-
rently performing computational lexicography tasks for dictionary publishers and performing
computational lexicology research on how computational lexicons from machine-readable dictio-
naries and thesauruses can be used in NLP applications, including word-sense disambiguation
and question answering. Litkowski&apos;s address is: CL Research, 9208 Gue Road, Damascus, MD
20872; e-mail: ken@clres.com.
</bodyText>
<page confidence="0.997216">
458
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.108358">
<title confidence="0.998046">Book Reviews Lexicon Development for Speech and Language Processing</title>
<author confidence="0.999782">Frank Van_Eynde</author>
<author confidence="0.999782">Dafydd Gibbon</author>
<affiliation confidence="0.9266445">(University of Leuven and University of Bielefeld) Dordrecht: Kluwer Academic</affiliation>
<note confidence="0.461412333333333">Publishers (Text, speech and language technology series, edited by Nancy Ide and Jean Veronis, volume 12), 2000, xi+298 pp; hardbound, ISBN 0-7923-6368-X, $128.00, £79.00, €109.00 Reviewed by</note>
<author confidence="0.999484">Ken Litkowski</author>
<affiliation confidence="0.99329">CL Research</affiliation>
<abstract confidence="0.986975066666667">As a computational lexicologist with little background in speech technology, I approached this book as an opportunity to gain a basic understanding of how lexicons are used in speech and to see whether semantically oriented lexicons from my work could bring something to this field. The first objective was met, but the second was not. This book arose from the 1997 Fifth European Summer School on Language and Speech Communication under the auspices of the European Language and Speech Network (ELSNET) and is the report of nine of the ten lectures. The book offers a &amp;quot;survey of methods and techniques for structuring, acquiring and maintaining lexical resources for speech and language processing&amp;quot; (p. ix). part of my first objective, that speech technology is greatly hampered by limitations on the size of the lexicon that can be handled efficiently in real systems. The amount of data is overwhelmed by the need to use signal data in analog or digital form. The speech community has to resort to and develop many tricks for working with the prodigious amount of data. This book provides an appropriate overview of the complexity of the problems and will serve well as background reading in an introductory computational linguistics course. Each of the papers is well referenced, with the authors providing their (important) guides to further details. The organization of the book is not optimal, however. It consists of an overview, two papers on lexical formalisms, two research papers, three database papers, and a final research paper. Logically, the database papers should be first, followed by the research papers, the lexical formalisms, and finally the overview. The quality of the papers and the editing is high; the contributors clearly worked to turn their lectures into readable form. I will present comments based on the logical order, rather than the physical order. Christoph Draxler (&amp;quot;Speech databases,&amp;quot; Chapter 6) provides an overview of what kind of database technology is required in speech technology, albeit with little reference to the lexicon. This paper shows the impressive range of speech material, describing recording mechanisms and annotation levels. Silvia Quazza and Henk van den Heuvel (&amp;quot;The use of lexica in text-to-speech systems,&amp;quot; Chapter 7) outline practical steps for putting together the components of a text-to-speech system and for building the lexicon, showing quite well where the lexicon comes into play. This chapter has the most detailed information about what lexical information is used in speech systems and how. Martine Adda-Decker and Lori Lamel (&amp;quot;The use of lexica in automatic speech recognition,&amp;quot; Chapter 8) carry us through the design and development of the lexical used in recognition, describing what is required of the lexicon for de- 457 Computational Linguistics Volume 27, Number 3 coding speech. It is here that the size of the lexicon evinces the complexities and is likely the place where ingenious (semantic) solutions are most needed for recognizers to &amp;quot;understand&amp;quot; speech. These three papers provide the backbone of the book. The three research papers represent examples of ongoing research; all are presented quite well, giving the reader a sense of active problems. Walter Daelemans and Gert Durieux (&amp;quot;Inductive lexica,&amp;quot; Chapter 4) describe their work on inducing regularities implicit in phonological lexical representations using &amp;quot;memory-based learning&amp;quot; machine learning techniques. The methods followed are clearly laid out, providing</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>