<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.207475">
<title confidence="0.998621">
Biomedical Event Detection using Rules,
Conditional Random Fields and Parse Tree Distances
</title>
<author confidence="0.976128">
Farzaneh Sarafraz*, James Eales*, Reza Mohammadi&apos;, Jonathan Dickerson*,
David Robertson*, Goran Nenadic*
</author>
<affiliation confidence="0.998439666666667">
*School of Computer Science, University of Manchester
*Faulty of Life Sciences, University of Manchester
&apos;Dept. of Mathematics and Computer Science, Sharif University of Technology
</affiliation>
<email confidence="0.993352">
sarafraf@cs.man.ac.uk, g.nenadic@manchester.ac.uk
</email>
<sectionHeader confidence="0.993849" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999670684210526">
This paper reports on a system developed for
the BioNLP&apos;09 shared task on detection and
characterisation of biomedical events. Event
triggers and types were recognised using a
conditional random field classifier and a set of
rules, while event participants were identified
using a rule-based system that relied on rela-
tive distances between candidate entities and
the trigger in the associated parse tree. The re-
sults on previously unseen test data were en-
couraging: for non-regulatory events, the F-
score was almost 50% (with precision above
60%), with the overall F-score of around 30%
(49% precision). The performance on more
complex regulatory events was poor
(F-measure of 7%). Among the 24 teams
submitting the test results, our results were
ranked 12th for the overall F-score and 8th for
the F-score of non-regulation events.
</bodyText>
<sectionHeader confidence="0.998987" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999977454545455">
The aim of the BioNLP&apos;09 shared task 1 was to
characterise molecular events being reported in a
Medline abstract by identifying the textual trigger,
event type and participating entities (Kim et al.
2009). Nine event types were considered: gene
expression, transcription, protein catabolism, lo-
calisation, phosporylation, binding, regulation,
positive regulation, and negative regulation. De-
pending on the event type, the task included the
identification of either one (for the first five event
types mentioned above) or more (e.g. for binding)
participating proteins. Information requested for
regulatory events was more complex: in addition to
one theme (a protein or another event), these
events could also have a cause (a protein or an-
other event) that needed to be identified.
The organisers have distributed a training
dataset of 800 abstracts, with gene and gene prod-
uct mentions pre-annotated in text. In addition, a
development set (150 abstracts) was provided to
assess the quality of the extractions during the
training and development phases.
</bodyText>
<sectionHeader confidence="0.996009" genericHeader="method">
2 Methods
</sectionHeader>
<bodyText confidence="0.973965">
The system developed for the challenge consists of
three main modules: (1) event trigger and type de-
tection, (2) event participant detection, and
(3) post-processing of the results.
</bodyText>
<subsectionHeader confidence="0.999812">
2.1 Event Trigger and Type Detection
</subsectionHeader>
<bodyText confidence="0.999453666666667">
Our view of the event trigger and type detection
subtask was that each token in a sentence needed
to be tagged either as a trigger for one of the nine
event types, or as a non-trigger/event token. We
therefore decided to identify event types and trig-
gers in a single step by training a conditional ran-
dom field (CRF) classifier that assigned one of ten
(nine types plus non-trigger) tags to each token.
CRFs have been shown to be particularly suitable
for tagging sequential data such as natural lan-
guage text, because they take into account features
and tags of neighbouring tokens when evaluating
the probability of a tag for a given token.
Tokens and their part-of-speech (POS) tags
were recognised using the Genia Tagger (Tsuruoka
et al. 2005). Each stemmed token was represented
using a feature vector consisting of the following
features:
</bodyText>
<listItem confidence="0.9948696">
• A binary feature indicating whether the to-
ken is a protein;
• A binary feature indicating whether the to-
ken is a known protein-protein interaction
word (we used a pre-complied dictionary of
</listItem>
<page confidence="0.99478">
115
</page>
<note confidence="0.756336">
Proceedings of the Workshop on BioNLP: Shared Task, pages 115–118,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.9419755">
such words collected from previous studies
(Fu et al. 2008; Yang et al. 2008);
</bodyText>
<listItem confidence="0.991932833333333">
• The token&apos;s POS tag;
• The log-frequencies of the token being a
trigger for each event type in the training
data (nine features);
• The number of proteins in the given sen-
tence.
</listItem>
<bodyText confidence="0.999317666666667">
Other features (e.g. separating the known inter-
action words according to the nine event types)
were explored during the development phase, but
were not included in the final feature list since they
increased the sparseness of the data and did not
improve the overall results. The CRF parameters
were adjusted for maximum performance, includ-
ing the choice of training algorithms, the number
of training steps, the size of the window within
which the tokens can affect any certain token, and
the number of training abstracts used in each train-
ing step. It was interesting to notice that there were
no significant improvements in the performance
after training on 100, 400 or 800 abstracts from the
training set (data not shown).
</bodyText>
<subsectionHeader confidence="0.999736">
2.2 Locating Event Themes
</subsectionHeader>
<bodyText confidence="0.980407352941176">
After detecting potential triggers and associated
event types, the next task was to locate possible
participants (i.e. ‘themes’ and ‘causes’) for each
event. It was obvious that participants did not have
to be the nearest to the trigger on the surface level,
so our approach was based on distances within the
parse trees associated with the sentences contain-
ing candidate events. Parse tree distances have
been studied previously in clustering and automatic
translation tasks (Emms 2008), so we hypothesised
that we could use them to identify the most likely
participants. The training data was analysed for the
proximities between the triggers and the (correct)
event participants in the parse tree of the sentence.1
Figure 1 gives a detailed density function of these
distances (ignoring non-protein nodes). The analy-
sis showed that a theme was usually amongst the
nearest proteins to the trigger in terms of parse tree
distances: for example, in 60% of all single theme
events (e.g. localisation, phosphorylation) the cor-
rect protein participant was the trigger’s nearest or
second nearest protein in the parse tree. A further
1 The parse trees were produced by the GDep parser (Sagae
and Tsujii, 2007) and supplied by the challenge organisers.
analysis demonstrated that it was more likely for a
theme to appear in the sub-tree of the correspond-
ing trigger, with 70% of all single theme events
having a theme which appeared in the sub-tree of
the trigger. Furthermore, specific analyses of the
parse trees associated to the binding events (which
can have more than one theme) suggested a linear
relationship between the parse tree distance and
binding event participant number (participant1 is
the nearest, participant2 is the second nearest, etc.).
</bodyText>
<figureCaption confidence="0.998485333333333">
Figure 1: Probability density function of the distance
between the trigger and the theme in the parse tree
(ignoring the tokens that are not proteins)
</figureCaption>
<bodyText confidence="0.9998384">
We used this distributional analysis (derived
from the training data) to design a rule-based
method for the identification of participating
themes. The rules were manually derived for each
of the nine event classes, by defining:
</bodyText>
<listItem confidence="0.996230875">
• a threshold for the maximum distance to the
trigger in the sub-tree for the given event
type;
• a threshold for the difference between the
maximum distance in the whole tree and the
given sub-tree for the given event type;
• the number of nearest proteins to be re-
ported for each trigger.
</listItem>
<bodyText confidence="0.9996625">
All entities that satisfied a distance-based rule
for a given trigger were selected as the correspond-
ing theme(s). For example, if the event type is
binding, then up to the second closest protein in the
sub-tree, and the first closest protein in the rest of
the tree are reported as themes.
</bodyText>
<page confidence="0.995659">
116
</page>
<bodyText confidence="0.997562296296296">
Figure 2 provides an example of the method ap-
plied to a sentence with multiple events. Regulates
and secretion are correctly identified as triggers for
a regulation and a localization event in the first
phase. Using the rules for localization, the themes
for two localization events are correctly recognised
as proteins T2 and T3, whereas T1 was ignored
since it did not appear in the trigger&apos;s sub-tree.
Engineering and applying rules for non-
regulatory events was relatively straightforward.
However, regulatory events can have different
kinds of participants (a protein or an event). In the
case of an event, we were trying to locate the near-
est trigger for the event (being regulated) in the
parse tree. For example, in Figure 2, the nearest
option to the regulation trigger (secretion) was the
trigger of the two localization events, and both
events should be (correctly) reported as the themes
of two regulation events. Therefore, we require a
number of recursions in the application of the rules
to represent higher-order regulatory dependences.
For the purposes of this challenge, only regulations
up to the second “order” were detected, allowing
other events to act as themes and causes as well as
proteins. Attempts to find more complicated regu-
latory events using this method resulted in a de-
creased precision and/or F-score.
</bodyText>
<subsectionHeader confidence="0.999845">
2.3 Post-processing Event Profiles
</subsectionHeader>
<bodyText confidence="0.999947380952381">
The performance of the first two phases was
studied on the development dataset: we noted a
number of false-positive and false-negative results
that were mostly due to a set of recurring triggers.
We therefore decided to perform a post-processing
step to improve the identification of event triggers
and associated types. In the first step (improving
the event trigger and type detection), the output of
the CRF was overridden in cases where the triggers
appeared in a list of negatively discriminated trig-
ger words which was collected after the manual
analysis of the false positive results on the training
and development data. Similarly, in cases where
the CRF missed a highly indicative trigger (from a
manually collected set) for a given event type, the
trigger was added as part of post-processing. In the
latter case, the sentence was then processed for the
event theme detection (as described in 2.2).
In the second step of the pre-processing phase,
we forced highly indicative regulation triggers (if
not previously identified) to be associated with an
</bodyText>
<figureCaption confidence="0.962887">
Figure 2: The parse tree of sentence Monocyte tethering
by P-selectin regulates monocyte chemotactic protein-1
and tumor necrosis factor-alpha secretion. The triggers
are shown in boxes, and the entities are numbered.
</figureCaption>
<bodyText confidence="0.9998689">
event by assigning proteins appearing in the sen-
tence to them, even when no protein in the sen-
tence satisfied the theme or cause criteria described
in Section 2.2. This was aimed at improving the
extremely low recall for regulatory events.
Finally, since triggers could consist of more than
one consecutive token, a set of simple rules were
applied to remove typical false-negative constitu-
ents identified by the CRF as part of triggers (e.g.
sometimes linking words appeared within triggers).
</bodyText>
<sectionHeader confidence="0.998952" genericHeader="evaluation">
3 Results and discussion
</sectionHeader>
<bodyText confidence="0.999993476190476">
The task 1 assessment was based on the output of
the system when applied to the test dataset of 260
previously unseen abstracts. An event was counted
as a true positive if its type, trigger and all partici-
pants had been correctly identified. The overall F-
score for our system was 30.35% with 48.61% pre-
cision (approximate span matching, see Table 1).
The best performing event types were phosphory-
lation (the best F-score and the best recall) and
gene expression (the best precision with a reasona-
bly good F-measure). While the results for non-
regulatory events were encouraging, they were low
for regulatory events. Among the 24 teams submit-
ting the test results, our results were ranked 12th for
the overall F-score and 8th for the F-score of non-
regulation events.
A preliminary analysis of the results was per-
formed on the development data (as the test data is
not available), which had around 5% higher overall
F-score than the test data (9% for non-regulation
events, see Table 2 for details).
</bodyText>
<page confidence="0.993376">
117
</page>
<table confidence="0.999369769230769">
Event Class #Gold R P F-score
Localisation 174 44.83 53.06 48.60
Binding 347 12.68 40.37 19.30
Gene expression 722 52.63 69.34 59.84
Transcription 137 15.33 67.74 25.00
Protein catabolism 14 42.86 50.00 46.15
Phosphorylation 135 78.52 53.81 63.86
Non-reg total 1529 41.53 60.82 49.36
Regulation 291 3.09 19.15 5.33
Positive regulation 983 1.12 8.87 1.99
Neg. regulation 379 12.4 20.52 15.46
Regulatory total 1653 4.05 16.75 6.53
All total 3182 22.06 48.61 30.35
</table>
<tableCaption confidence="0.993569333333333">
Table 1: Evaluation of the test data (260 abstracts),
(approximate span matching; #Gold = the number of
examples in the gold standard)
</tableCaption>
<bodyText confidence="0.9999655">
In order to assess the effects of different steps
in our approach, we evaluated the performance of
the event trigger and event participant detection
steps separately. The results presented in Table 3
indicated that the performance of the CRF module
was not much better than the overall performance
of the system (an F-score of 43% vs. 35%), sug-
gesting that the CRF part was mostly responsible
for the errors, by both missing triggers and falsely
reporting them. This was particularly the case with
non-regulatory events (even for binding). Con-
versely, when considering only those events whose
triggers were correctly identified, their participants
were also correctly recognised in most cases.
Overall, the analysis suggested that the parse tree
distance method performed reasonable well, de-
spite a reduction in recall of approximately 12%.
There are a number of possibilities for im-
provements. We believe applying the CRF model
in two stages would be a better approach to detect
</bodyText>
<table confidence="0.9985845">
Event Class #Gold R P F-score
Localisation 40 77.50 47.69 59.05
Binding 180 33.33 54.55 41.38
Gene expression 282 76.60 58.54 66.36
Transcription 68 58.82 18.60 28.27
Protein catabolism 19 84.21 88.89 86.49
Phosphorylation 40 97.50 81.25 88.64
Non-reg total 629 63.91 48.73 55.30
Regulation 138 13.04 62.07 21.56
Positive regulation 462 13.85 54.24 22.07
Neg. regulation 153 29.41 45.92 35.86
All total 1382 38.28 49.44 43.15
</table>
<tableCaption confidence="0.997266">
Table 3: Trigger-only evaluation of the development data
</tableCaption>
<table confidence="0.999773692307692">
Event Class #Gold R P F-score
Localisation 53 67.92 46.75 55.38
Binding 312 21.47 63.81 32.13
Gene expression 356 64.61 76.33 69.98
Transcription 82 53.66 89.80 67.18
Protein catabolism 21 90.48 67.86 77.55
Phosphorylation 47 91.49 53.09 67.19
Non-reg total 871 50.4 68.44 58.05
Regulation 172 5.23 33.33 9.05
Positive regulation 632 3.48 21.36 5.99
Neg. regulation 201 9.45 15.08 11.62
Regulatory total 1005 4.98 19.53 7.93
All total 1876 26.07 54.46 35.26
</table>
<tableCaption confidence="0.999812">
Table 2: Evaluation of the development data (150 abstracts)
</tableCaption>
<bodyText confidence="0.984430125">
(approximate span matching; #Gold as in Table 1)
events: first identify triggers and then link them to
event classes. In addition, the rules employed for
determining themes need to be more specific to
reflect both event type and grammatical structure.
In the case of regulatory events, however, signifi-
cantly better results were noticed in the trigger de-
tection part when compared to the overall scores,
indicating that it was difficult to identify regulatory
participants, as any of those participants could be
either a protein or another event.
Overall, the results achieved by our system
suggest that combining parse tree results, rules and
CRFs is a promising approach for the identification
of non-regulatory events in the literature, while
more work would be needed for regulatory events.
</bodyText>
<sectionHeader confidence="0.999145" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997275411764706">
Emms M. 2008. Tree-distance and some other Variants
of evalb. Proc. of LREC 2008, pp 1373-1379.
Fu W. et al. 2008. Human Immunodeficiency Virus type
1, Human protein interaction database at NCBI, Nu-
cleic Acid Research 2008, D417-D422
Kim JD et al. 2009. Overview of BioNLP&apos;09 Shared
Task on Event Extraction, Proc. of BioNLP NAACL
2009 Workshop (to appear)
Sagae K, Tsujii J. 2007. Dependency Parsing and Do-
main Adaptation with LR Models and Parser Ensem-
bles. Proc. of the CoNLL 2007 Shared Task, 1044-50
Tsuruoka Y. et al. 2005. Developing a Robust Part of-
Speech Tagger for Biomedical Text. Advances in In-
formatics, 382–392.
Yang H. et al. 2008. Identification of Transcription Fac-
tor Contexts in Literature using Machine Learning
Approaches. BMC Bioinformatics, Vol. 9(3):S11.
</reference>
<page confidence="0.996151">
118
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.701560">
<title confidence="0.9992755">Biomedical Event Detection using Conditional Random Fields and Parse Tree Distances</title>
<author confidence="0.916129">James Reza Jonathan Goran</author>
<degree confidence="0.933393">of Computer Science, University of of Life Sciences, University of of Mathematics and Computer Science, Sharif University of</degree>
<email confidence="0.963043">sarafraf@cs.man.ac.uk,g.nenadic@manchester.ac.uk</email>
<abstract confidence="0.999325">This paper reports on a system developed for the BioNLP&apos;09 shared task on detection and characterisation of biomedical events. Event triggers and types were recognised using a conditional random field classifier and a set of rules, while event participants were identified using a rule-based system that relied on relative distances between candidate entities and the trigger in the associated parse tree. The results on previously unseen test data were encouraging: for non-regulatory events, the Fscore was almost 50% (with precision above 60%), with the overall F-score of around 30% (49% precision). The performance on more complex regulatory events was poor (F-measure of 7%). Among the 24 teams submitting the test results, our results were for the overall F-score and for the F-score of non-regulation events.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Emms</author>
</authors>
<title>Tree-distance and some other Variants of evalb.</title>
<date>2008</date>
<booktitle>Proc. of LREC</booktitle>
<pages>1373--1379</pages>
<contexts>
<context position="5254" citStr="Emms 2008" startWordPosition="823" endWordPosition="824"> performance after training on 100, 400 or 800 abstracts from the training set (data not shown). 2.2 Locating Event Themes After detecting potential triggers and associated event types, the next task was to locate possible participants (i.e. ‘themes’ and ‘causes’) for each event. It was obvious that participants did not have to be the nearest to the trigger on the surface level, so our approach was based on distances within the parse trees associated with the sentences containing candidate events. Parse tree distances have been studied previously in clustering and automatic translation tasks (Emms 2008), so we hypothesised that we could use them to identify the most likely participants. The training data was analysed for the proximities between the triggers and the (correct) event participants in the parse tree of the sentence.1 Figure 1 gives a detailed density function of these distances (ignoring non-protein nodes). The analysis showed that a theme was usually amongst the nearest proteins to the trigger in terms of parse tree distances: for example, in 60% of all single theme events (e.g. localisation, phosphorylation) the correct protein participant was the trigger’s nearest or second ne</context>
</contexts>
<marker>Emms, 2008</marker>
<rawString>Emms M. 2008. Tree-distance and some other Variants of evalb. Proc. of LREC 2008, pp 1373-1379.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Fu</author>
</authors>
<title>Human Immunodeficiency Virus type 1, Human protein interaction database at NCBI, Nucleic Acid Research</title>
<date>2008</date>
<pages>417--422</pages>
<marker>Fu, 2008</marker>
<rawString>Fu W. et al. 2008. Human Immunodeficiency Virus type 1, Human protein interaction database at NCBI, Nucleic Acid Research 2008, D417-D422</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kim JD</author>
</authors>
<date>2009</date>
<booktitle>Overview of BioNLP&apos;09 Shared Task on Event Extraction, Proc. of BioNLP NAACL</booktitle>
<note>Workshop (to appear)</note>
<marker>JD, 2009</marker>
<rawString>Kim JD et al. 2009. Overview of BioNLP&apos;09 Shared Task on Event Extraction, Proc. of BioNLP NAACL 2009 Workshop (to appear)</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sagae</author>
<author>J Tsujii</author>
</authors>
<title>Dependency Parsing and Domain Adaptation with LR Models and Parser Ensembles.</title>
<date>2007</date>
<booktitle>Proc. of the CoNLL</booktitle>
<pages>1044--50</pages>
<contexts>
<context position="5972" citStr="Sagae and Tsujii, 2007" startWordPosition="938" endWordPosition="941">ing data was analysed for the proximities between the triggers and the (correct) event participants in the parse tree of the sentence.1 Figure 1 gives a detailed density function of these distances (ignoring non-protein nodes). The analysis showed that a theme was usually amongst the nearest proteins to the trigger in terms of parse tree distances: for example, in 60% of all single theme events (e.g. localisation, phosphorylation) the correct protein participant was the trigger’s nearest or second nearest protein in the parse tree. A further 1 The parse trees were produced by the GDep parser (Sagae and Tsujii, 2007) and supplied by the challenge organisers. analysis demonstrated that it was more likely for a theme to appear in the sub-tree of the corresponding trigger, with 70% of all single theme events having a theme which appeared in the sub-tree of the trigger. Furthermore, specific analyses of the parse trees associated to the binding events (which can have more than one theme) suggested a linear relationship between the parse tree distance and binding event participant number (participant1 is the nearest, participant2 is the second nearest, etc.). Figure 1: Probability density function of the dista</context>
</contexts>
<marker>Sagae, Tsujii, 2007</marker>
<rawString>Sagae K, Tsujii J. 2007. Dependency Parsing and Domain Adaptation with LR Models and Parser Ensembles. Proc. of the CoNLL 2007 Shared Task, 1044-50</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Tsuruoka</author>
</authors>
<title>Developing a Robust Part ofSpeech Tagger for Biomedical Text.</title>
<date>2005</date>
<booktitle>Advances in Informatics,</booktitle>
<pages>382--392</pages>
<marker>Tsuruoka, 2005</marker>
<rawString>Tsuruoka Y. et al. 2005. Developing a Robust Part ofSpeech Tagger for Biomedical Text. Advances in Informatics, 382–392.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Yang</author>
</authors>
<title>Identification of Transcription Factor Contexts in Literature using Machine Learning Approaches.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<volume>9</volume>
<issue>3</issue>
<marker>Yang, 2008</marker>
<rawString>Yang H. et al. 2008. Identification of Transcription Factor Contexts in Literature using Machine Learning Approaches. BMC Bioinformatics, Vol. 9(3):S11.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>