<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000017">
<title confidence="0.993244">
Improving Chinese Semantic Role Labeling with Rich Syntactic Features
</title>
<author confidence="0.99524">
Weiwei Sun*
</author>
<affiliation confidence="0.8630005">
Department of Computational Linguistics, Saarland University
German Research Center for Artificial Intelligence (DFKI)
</affiliation>
<address confidence="0.665811">
D-66123, Saarbr¨ucken, Germany
</address>
<email confidence="0.996735">
wsun@coli.uni-saarland.de
</email>
<sectionHeader confidence="0.993859" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9996884">
Developing features has been shown cru-
cial to advancing the state-of-the-art in Se-
mantic Role Labeling (SRL). To improve
Chinese SRL, we propose a set of ad-
ditional features, some of which are de-
signed to better capture structural infor-
mation. Our system achieves 93.49 F-
measure, a significant improvement over
the best reported performance 92.0. We
are further concerned with the effect
of parsing in Chinese SRL. We empiri-
cally analyze the two-fold effect, grouping
words into constituents and providing syn-
tactic information. We also give some pre-
liminary linguistic explanations.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.995145702702703">
Previous work on Chinese Semantic Role La-
beling (SRL) mainly focused on how to imple-
ment SRL methods which are successful on En-
glish. Similar to English, parsing is a standard
pre-processing for Chinese SRL. Many features
are extracted to represent constituents in the input
parses (Sun and Jurafsky, 2004; Xue, 2008; Ding
and Chang, 2008). By using these features, se-
mantic classifiers are trained to predict whether a
constituent fills a semantic role. Developing fea-
tures that capture the right kind of information en-
coded in the input parses has been shown crucial
to advancing the state-of-the-art. Though there
has been some work on feature design in Chinese
SRL, information encoded in the syntactic trees is
not fully exploited and requires more research ef-
fort. In this paper, we propose a set of additional
The work was partially completed while this author was
at Peking University.
features, some of which are designed to better cap-
ture structural information of sub-trees in a given
parse. With help of these new features, our sys-
tem achieves 93.49 F-measure with hand-crafted
parses. Comparison with the best reported results,
92.0 (Xue, 2008), shows that these features yield a
significant improvement of the state-of-the-art.
We further analyze the effect of syntactic pars-
ing in Chinese SRL. The main effect of parsing
in SRL is two-fold. First, grouping words into
constituents, parsing helps to find argument candi-
dates. Second, parsers provide semantic classifiers
plenty of syntactic information, not to only recog-
nize arguments from all candidate constituents but
also to classify their detailed semantic types. We
empirically analyze each effect in turn. We also
give some preliminary linguistic explanations for
the phenomena.
</bodyText>
<sectionHeader confidence="0.979322" genericHeader="method">
2 Chinese SRL
</sectionHeader>
<bodyText confidence="0.999562611111111">
The Chinese PropBank (CPB) is a semantic anno-
tation for the syntactic trees of the Chinese Tree-
Bank (CTB). The arguments of a predicate are la-
beled with a contiguous sequence of integers, in
the form of AN (N is a natural number); the ad-
juncts are annotated as such with the label AM
followed by a secondary tag that represents the se-
mantic classification of the adjunct. The assign-
ment of semantic roles is illustrated in Figure 1,
where the predicate is the verb “调查/investigate”.
E.g., the NP “事故原因/the cause of the accident”
is labeled as A1, meaning that it is the Patient.
In previous research, SRL methods that are suc-
cessful on English are adopted to resolve Chinese
SRL (Sun and Jurafsky, 2004; Xue, 2008; Ding
and Chang, 2008, 2009; Sun et al., 2009; Sun,
2010). Xue (2008) produced complete and sys-
tematic research on full parsing based methods.
</bodyText>
<page confidence="0.959996">
168
</page>
<note confidence="0.7521315">
Proceedings of the ACL 2010 Conference Short Papers, pages 168–172,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<table confidence="0.916653615384615">
IP
���������������������������������
A0 VP
NP ����������������������
������������
AM-TMP AM-MNR VP ����������������������
NN ADVP ADVP Rel A1
警方 AD AD VV NP
police ������������
正在 详细 调查 NN NN
now thoroughly investigate
事故 原因
accident cause
</table>
<figureCaption confidence="0.9212475">
Figure 1: An example sentence: The police are
thoroughly investigating the cause of the accident.
</figureCaption>
<bodyText confidence="0.999624842105263">
Their method divided SRL into three sub-tasks: 1)
pruning with a heuristic rule, 2) Argument Identi-
fication (AI) to recognize arguments, and 3) Se-
mantic Role Classification (SRC) to predict se-
mantic types. The main two sub-tasks, AI and
SRC, are formulated as two classification prob-
lems. Ding and Chang (2008) divided SRC into
two sub-tasks in sequence: Each argument should
first be determined whether it is a core argument or
an adjunct, and then be classified into fine-grained
categories. However, delicately designed features
are more important and our experiments suggest
that by using rich features, a better SRC solver
can be directly trained without using hierarchical
architecture. There are also some attempts at re-
laxing the necessity of using full syntactic parses,
and semantic chunking methods have been intro-
duced by (Sun et al., 2009; Sun, 2010; Ding and
Chang, 2009).
</bodyText>
<subsectionHeader confidence="0.997381">
2.1 Our System
</subsectionHeader>
<bodyText confidence="0.999976923076923">
We implement a three-stage (i.e. pruning, AI and
SRC) SRL system. In the pruning step, our sys-
tem keeps all constituents (except punctuations)
that c-command1 current predicate in focus as ar-
gument candidates. In the AI step, a lot of syntac-
tic features are extracted to distinguish argument
and non-argument. In other words, a binary classi-
fier is trained to classify each argument candidate
as either an argument or not. Finally, a multi-class
classifier is trained to label each argument recog-
nized in the former stage with a specific semantic
role label. In both AI and SRC, the main job is to
select strong syntactic features.
</bodyText>
<footnote confidence="0.543557">
1See (Sun et al., 2008) for detailed definition.
</footnote>
<sectionHeader confidence="0.996751" genericHeader="method">
3 Features
</sectionHeader>
<bodyText confidence="0.9998473125">
A majority of features used in our system are a
combination of features described in (Xue, 2008;
Ding and Chang, 2008) as well as the word for-
mation and coarse frame features introduced in
(Sun et al., 2009), the c-command thread fea-
tures proposed in (Sun et al., 2008). We give
a brief description of features used in previous
work, but explain new features in details. For
more information, readers can refer to relevant
papers and our source codes2 that are well com-
mented. To conveniently illustrate, we denote
a candidate constituent ck with a fixed context
wi−1[ckwi...wh...wj]wj+1, where wh is the head
word of ck, and denote predicate in focus with
a context wv−2wv−1wvwv+1wv+2, where wv is the
predicate in focus.
</bodyText>
<subsectionHeader confidence="0.996754">
3.1 Baseline Features
</subsectionHeader>
<bodyText confidence="0.999598875">
The following features are introduced in previous
Chinese SRL systems. We use them as baseline.
Word content of wv, wh, wi, wj and wi+wj;
POS tag of wv, wh. subcategorization frame, verb
class of wv; position, phrase type ck, path from ck
to wv (from (Xue, 2008; Ding and Chang, 2008))
First character, last character and word length
of wv, first character+length, last character+word
length, first character+position, last charac-
ter+position, coarse frame, frame+wv, frame+left
character, frame+verb class, frame+ck (from (Sun
et al., 2009)).
Head word POS, head word of PP phrases, cat-
egory of ck’s lift and right siblings, CFG rewrite
rule that expands ck and ck’s parent (from (Ding
and Chang, 2008)).
</bodyText>
<subsectionHeader confidence="0.999587">
3.2 New Word Features
</subsectionHeader>
<bodyText confidence="0.9796055">
We introduce some new features which can be
extracted without syntactic structure. We denote
them as word features. They include:
Word content of wv−1, wv+1, wi−1 and wj+1;
POS tag of wv−1, wv+1, wv−2, wv+2, wi−1, wi, wj,
wj+1, wi+2 and wj−2.
Length of ck: how many words are there in ck.
Word before “LC”: If the POS of wj is “LC”
(localizer), we use wj−1 and its POS tag as two
new features.
NT: Does ck contain a word with POS “NT”
(temporal noun)?
</bodyText>
<footnote confidence="0.9975625">
2Available at http://code.google.com/p/
csrler/.
</footnote>
<page confidence="0.991497">
169
</page>
<bodyText confidence="0.560557">
Combination features: wz’s POS+wk’s POS,
w&amp;quot;+Position
</bodyText>
<subsectionHeader confidence="0.987715">
3.3 New Syntactic Features
</subsectionHeader>
<bodyText confidence="0.761664166666667">
Taking complex syntax trees as inputs, the clas-
sifiers should characterize their structural proper-
ties. We put forward a number of new features to
encode the structural information.
Category of ck’s parent; head word and POS of
head word of parent, left sibling and right sibling
of ck.
Lexicalized Rewrite rules: Conjuction of
rewrite rule and head word of its corresponding
RHS. These features of candidate (lrw-c) and its
parent (lrw-p) are used. For example, this lrw-
c feature of the NP “事#原Q” in Figure 1 is
</bodyText>
<equation confidence="0.439419">
NP --� NN + NN(原Q).
</equation>
<bodyText confidence="0.922866428571428">
Partial Path: Path from the ck or w&amp;quot; to the low-
est common ancestor of ck and w&amp;quot;. One path fea-
ture, hence, is divided into left path and right path.
Clustered Path: We use the manually created
clusters (see (Sun and Sui, 2009)) of categories of
all nodes in the path (cpath) and right path.
C-commander thread between ck and w&amp;quot; (cct):
(proposed by (Sun et al., 2008)). For example, this
feature of the NP “警方” in Figure 1 is NP +
ADV P + ADV P + V V .
Head Trace: The sequential container of the
head down upon the phrase (from (Sun and Sui,
2009)). We design two kinds of traces (htr-p, htr-
w): one uses POS of the head word; the other uses
the head word word itself. E.g., the head word of
事#原Q is “原Q” therefore these feature of this
NP are NPINN and NPI原Q.
Combination features: verb class+ck, wh+w&amp;quot;,
wh+Position, wh+w&amp;quot;+Position, path+w&amp;quot;,
wh+right path, w&amp;quot;+left path, frame+w&amp;quot;+wh,
and w&amp;quot;+cct.
</bodyText>
<sectionHeader confidence="0.997358" genericHeader="evaluation">
4 Experiments and Analysis
</sectionHeader>
<subsectionHeader confidence="0.942928">
4.1 Experimental Setting
</subsectionHeader>
<bodyText confidence="0.99994465">
To facilitate comparison with previous work, we
use CPB 1.0 and CTB 5.0, the same data set-
ting with (Xue, 2008). The data is divided into
three parts: files from 081 to 899 are used as
training set; files from 041 to 080 as develop-
ment set; files from 001 to 040, and 900 to 931
as test set. Nearly all previous research on con-
stituency based SRL evaluation use this setting,
also including (Ding and Chang, 2008, 2009; Sun
et al., 2009; Sun, 2010). All parsing and SRL ex-
periments use this data setting. To resolve clas-
sification problems, we use a linear SVM classi-
fier SVMlin3, along with One-Vs-All approach for
multi-class classification. To evaluate SRL with
automatic parsing, we use a state-of-the-art parser,
Bikel parser4 (Bikel, 2004). We use gold segmen-
tation and POS as input to the Bikel parser and
use it parsing results as input to our SRL system.
The overall LP/LR/F performance of Bikel parser
is 79.98%/82.95%/81.43.
</bodyText>
<subsectionHeader confidence="0.995108">
4.2 Overall Performance
</subsectionHeader>
<bodyText confidence="0.999865888888889">
Table 1 summarizes precision, recall and F-
measure of AI, SRC and the whole task (AI+SRC)
of our system respectively. The forth line is
the best published SRC performance reported in
(Ding and Chang, 2008), and the sixth line is the
best SRL performance reported in (Xue, 2008).
Other lines show the performance of our system.
These results indicate a significant improvement
over previous systems due to the new features.
</bodyText>
<table confidence="0.999714666666667">
Test P(%) R(%) F/A
AI 98.56 97.91 98.24
SRC - - - - 95.04
(Ding and Chang, 2008) - - - - 94.68
AI + SRC 93.80 93.18 93.49
(Xue, 2008) 93.0 91.0 92.0
</table>
<tableCaption confidence="0.986632">
Table 1: SRL performance on the test data with
gold standard parses.
</tableCaption>
<subsectionHeader confidence="0.987665">
4.3 Two-fold Effect of Parsing in SRL
</subsectionHeader>
<bodyText confidence="0.99999">
The effect of parsing in SRL is two-fold. On the
one hand, SRL systems should group words as ar-
gument candidates, which are also constituents in
a given sentence. Full parsing provides bound-
ary information of all constituents. As arguments
should c-command the predicate, a full parser can
further prune a majority of useless constituents. In
other words, parsing can effectively supply SRL
with argument candidates. Unfortunately, it is
very hard to rightly produce full parses for Chi-
nese text. On the other hand, given a constituent,
SRL systems should identify whether it is an argu-
ment and further predict detailed semantic types if
</bodyText>
<footnote confidence="0.98667575">
3http://people.cs.uchicago.edu/
-vikass/svmlin.html
4http://www.cis.upenn.edu/-dbikel/
software.html
</footnote>
<page confidence="0.983033">
170
</page>
<table confidence="0.999471571428571">
Task Parser Bracket Feat P(%) R(%) F/A
AI - - Gold W 82.44 86.78 84.55
CTB Gold W+S 98.69 98.11 98.40
Bikel Bikel W+S 77.54 71.62 74.46
SRC - - Gold W - - - - 93.93
CTB Gold W+S - - - - 95.80
Bikel Gold W+S - - - - 92.62
</table>
<tableCaption confidence="0.699022333333333">
Table 2: Classification perfromance on develop-
ment data. In the Feat column, W means word
features; W+S means word and syntactic feautres.
</tableCaption>
<bodyText confidence="0.993232333333333">
it is an argument. For the two classification prob-
lems, parsing can provide complex syntactic infor-
mation such as path features.
</bodyText>
<subsubsectionHeader confidence="0.652633">
4.3.1 The Effect of Parsing in AI
</subsubsectionHeader>
<bodyText confidence="0.9999833">
In AI, full parsing is very important for both
grouping words and classification. Table 2 sum-
marizes relative experimental results. Line 2 is the
AI performance when gold candidate boundaries
and word features are used; Line 3 is the perfor-
mance with additional syntactic features. Line 4
shows the performance by using automatic parses
generated by Bikel parser. We can see that: 1)
word features only cannot train good classifiers to
identify arguments; 2) it is very easy to recognize
arguments with good enough syntactic parses; 3)
there is a severe performance decline when auto-
matic parses are used. The third observation is a
similar conclusion in English SRL. However this
problem in Chinese is much more serious due to
the state-of-the-art of Chinese parsing.
Information theoretic criteria are popular cri-
teria in variable selection (Guyon and Elisse-
eff, 2003). This paper uses empirical mutual
information between each variable and the tar-
</bodyText>
<equation confidence="0.800735">
get, I(X, Y ) = &amp;;cX,ycY p(x, y) log p(�,y)
p(�)p(y), to
</equation>
<bodyText confidence="0.9999638">
roughly rank the importance of features. Table 3
shows the ten most useful features in AI. We can
see that the most important features all based on
full parsing information. Nine of these top 10 use-
ful features are our new features.
</bodyText>
<footnote confidence="0.646409666666667">
Rank Feature
2 1 wh+w&amp;quot;+Position
3 htr-w
5 path
7 cpath
9 path+w&amp;quot;
</footnote>
<tableCaption confidence="0.9448565">
Table 3: Top 10 useful features for AI. t means
word features.
</tableCaption>
<subsectionHeader confidence="0.623112">
4.3.2 The Effect of Parsing in SRC
</subsectionHeader>
<bodyText confidence="0.999941166666667">
The second block in Table 2 summarizes the SRC
performance with gold argument boundaries. Line
5 is the accuracy when word features are used;
Line 6 is the accuracy when additional syntactic
features are added; The last row is the accuracy
when syntactic features used are extracted from
automatic parses (Bikel+Gold). We can see that
different from AI, word features only can train
reasonable good semantic classifiers. The com-
parison between Line 5 and 7 suggests that with
parsing errors, automatic parsed syntactic features
cause noise to the semantic role classifiers.
</bodyText>
<subsectionHeader confidence="0.497037">
4.4 Why Word Features Are Effective for
SRC?
</subsectionHeader>
<tableCaption confidence="0.90134">
Table 4: Top 10 useful features for SRC.
</tableCaption>
<bodyText confidence="0.99906975">
Table 4 shows the ten most useful features in
SRC. We can see that two of these ten features
are word features (denoted by t). Namely, word
features play a more important role in SRC than
in AI. Though the other eight features are based
on full parsing, four of them (denoted by t) use
the head word which can be well approximated
by word features, according to some language spe-
cific properties. The head rules described in (Sun
and Jurafsky, 2004) are very popular in Chinese
parsing research, such as in (Duan et al., 2007;
Zhang and Clark, 2008). From these head rules,
we can see that head words of most phrases in
Chinese are located at the first or the last position.
We implement these rules on Chinese Tree Bank
and find that 84.12% 5 nodes realize their heads as
either their first or last word. Head position sug-
gests that boundary words are good approximation
of head word features. If head words have good
approximation word features, then it is not strange
that the four features denoted by t can be effec-
tively represented by word features. Similar with
feature effect in AI, most of most useful features
in SRC are our new features.
</bodyText>
<footnote confidence="0.853551">
5This statistics excludes all empty categories in CTB.
</footnote>
<figure confidence="0.992085388888889">
1 w&amp;quot; cct
Rank Feature
4 htr-p
6 t wh+w&amp;quot;
8 cct
10 lrw-p
Rank Feature
1 $frame+wh+w&amp;quot;
3 twh+w&amp;quot;
5 lrw-p
7 lrw-c
9 tframe+w&amp;quot;
Rank Feature
2 $wh+w&amp;quot;+position
4 w&amp;quot;+cct
6 twi+wj
8 twh+Postion
10 htr-p
</figure>
<page confidence="0.989252">
171
</page>
<sectionHeader confidence="0.997586" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999980888888889">
This paper proposes an additional set of features
to improve Chinese SRL. These new features yield
a significant improvement over the best published
performance. We further analyze the effect of
parsing in Chinese SRL, and linguistically explain
some phenomena. We found that (1) full syntactic
information playes an essential role only in AI and
that (2) due to the head word position distribution,
SRC is easy to resolve in Chinese SRL.
</bodyText>
<sectionHeader confidence="0.997386" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9995494">
The author is funded both by German Academic
Exchange Service (DAAD) and German Research
Center for Artificial Intelligence (DFKI).
The author would like to thank the anonymous
reviewers for their helpful comments.
</bodyText>
<sectionHeader confidence="0.995306" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.964257555555556">
Daniel M. Bikel. 2004. A distributional analysis
of a lexicalized statistical parsing model. In
Dekang Lin and Dekai Wu, editors, Proceed-
ings of EMNLP 2004, pages 182–189. Associa-
tion for Computational Linguistics, Barcelona,
Spain.
Weiwei Ding and Baobao Chang. 2008. Improv-
ing Chinese semantic role classification with hi-
erarchical feature selection strategy. In Pro-
ceedings of the EMNLP 2008, pages 324–
333. Association for Computational Linguis-
tics, Honolulu, Hawaii.
Weiwei Ding and Baobao Chang. 2009. Fast se-
mantic role labeling for Chinese based on se-
mantic chunking. In ICCPOL ’09: Proceed-
ings of the 22nd International Conference on
Computer Processing of Oriental Languages.
Language Technology for the Knowledge-
based Economy, pages 79–90. Springer-Verlag,
Berlin, Heidelberg.
Xiangyu Duan, Jun Zhao, and Bo Xu. 2007.
Probabilistic models for action-based Chinese
dependency parsing. In ECML ’07: Pro-
ceedings of the 18th European conference on
Machine Learning, pages 559–566. Springer-
Verlag, Berlin, Heidelberg.
Isabelle Guyon and Andr´e Elisseeff. 2003. An
introduction to variable and feature selec-
tion. Journal of Machine Learning Research,
3:1157–1182.
Honglin Sun and Daniel Jurafsky. 2004. Shallow
semantc parsing of Chinese. In Daniel Marcu
Susan Dumais and Salim Roukos, editors, HLT-
NAACL 2004: Main Proceedings.
Weiwei Sun. 2010. Semantics-driven shallow
parsing for Chinese semantic role labeling. In
Proceedings of the ACL 2010.
Weiwei Sun and Zhifang Sui. 2009. Chinese func-
tion tag labeling. In Proceedings of the 23rd
Pacific Asia Conference on Language, Informa-
tion and Computation. Hong Kong.
Weiwei Sun, Zhifang Sui, and Haifeng Wang.
2008. Prediction of maximal projection for se-
mantic role labeling. In Proceedings of the
22nd International Conference on Computa-
tional Linguistics.
Weiwei Sun, Zhifang Sui, Meng Wang, and Xin
Wang. 2009. Chinese semantic role labeling
with shallow parsing. In Proceedings of the
2009 Conference on Empirical Methods in Nat-
ural Language Processing, pages 1475–1483.
Association for Computational Linguistics, Sin-
gapore.
Nianwen Xue. 2008. Labeling Chinese predi-
cates with semantic roles. Comput. Linguist.,
34(2):225–255.
Yue Zhang and Stephen Clark. 2008. A tale of two
parsers: Investigating and combining graph-
based and transition-based dependency parsing.
In Proceedings of the 2008 Conference on Em-
pirical Methods in Natural Language Process-
ing, pages 562–571. Association for Computa-
tional Linguistics, Honolulu, Hawaii.
</reference>
<page confidence="0.997882">
172
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.913532">
<title confidence="0.962551">Improving Chinese Semantic Role Labeling with Rich Syntactic Features</title>
<affiliation confidence="0.984056">Department of Computational Linguistics, Saarland University German Research Center for Artificial Intelligence (DFKI)</affiliation>
<address confidence="0.997291">D-66123, Saarbr¨ucken, Germany</address>
<email confidence="0.999494">wsun@coli.uni-saarland.de</email>
<abstract confidence="0.99889175">Developing features has been shown crucial to advancing the state-of-the-art in Semantic Role Labeling (SRL). To improve Chinese SRL, we propose a set of additional features, some of which are designed to better capture structural information. Our system achieves 93.49 Fmeasure, a significant improvement over the best reported performance 92.0. We are further concerned with the effect of parsing in Chinese SRL. We empirically analyze the two-fold effect, grouping words into constituents and providing syntactic information. We also give some preliminary linguistic explanations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Daniel M Bikel</author>
</authors>
<title>A distributional analysis of a lexicalized statistical parsing model.</title>
<date>2004</date>
<booktitle>In Dekang Lin and Dekai Wu, editors, Proceedings of EMNLP 2004,</booktitle>
<pages>182--189</pages>
<location>Barcelona, Spain.</location>
<contexts>
<context position="9858" citStr="Bikel, 2004" startWordPosition="1621" endWordPosition="1622">into three parts: files from 081 to 899 are used as training set; files from 041 to 080 as development set; files from 001 to 040, and 900 to 931 as test set. Nearly all previous research on constituency based SRL evaluation use this setting, also including (Ding and Chang, 2008, 2009; Sun et al., 2009; Sun, 2010). All parsing and SRL experiments use this data setting. To resolve classification problems, we use a linear SVM classifier SVMlin3, along with One-Vs-All approach for multi-class classification. To evaluate SRL with automatic parsing, we use a state-of-the-art parser, Bikel parser4 (Bikel, 2004). We use gold segmentation and POS as input to the Bikel parser and use it parsing results as input to our SRL system. The overall LP/LR/F performance of Bikel parser is 79.98%/82.95%/81.43. 4.2 Overall Performance Table 1 summarizes precision, recall and Fmeasure of AI, SRC and the whole task (AI+SRC) of our system respectively. The forth line is the best published SRC performance reported in (Ding and Chang, 2008), and the sixth line is the best SRL performance reported in (Xue, 2008). Other lines show the performance of our system. These results indicate a significant improvement over previ</context>
</contexts>
<marker>Bikel, 2004</marker>
<rawString>Daniel M. Bikel. 2004. A distributional analysis of a lexicalized statistical parsing model. In Dekang Lin and Dekai Wu, editors, Proceedings of EMNLP 2004, pages 182–189. Association for Computational Linguistics, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weiwei Ding</author>
<author>Baobao Chang</author>
</authors>
<title>Improving Chinese semantic role classification with hierarchical feature selection strategy.</title>
<date>2008</date>
<booktitle>In Proceedings of the EMNLP</booktitle>
<pages>324--333</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics,</institution>
<location>Honolulu, Hawaii.</location>
<contexts>
<context position="1205" citStr="Ding and Chang, 2008" startWordPosition="175" endWordPosition="178">st reported performance 92.0. We are further concerned with the effect of parsing in Chinese SRL. We empirically analyze the two-fold effect, grouping words into constituents and providing syntactic information. We also give some preliminary linguistic explanations. 1 Introduction Previous work on Chinese Semantic Role Labeling (SRL) mainly focused on how to implement SRL methods which are successful on English. Similar to English, parsing is a standard pre-processing for Chinese SRL. Many features are extracted to represent constituents in the input parses (Sun and Jurafsky, 2004; Xue, 2008; Ding and Chang, 2008). By using these features, semantic classifiers are trained to predict whether a constituent fills a semantic role. Developing features that capture the right kind of information encoded in the input parses has been shown crucial to advancing the state-of-the-art. Though there has been some work on feature design in Chinese SRL, information encoded in the syntactic trees is not fully exploited and requires more research effort. In this paper, we propose a set of additional The work was partially completed while this author was at Peking University. features, some of which are designed to bette</context>
<context position="3366" citStr="Ding and Chang, 2008" startWordPosition="530" endWordPosition="533">ments of a predicate are labeled with a contiguous sequence of integers, in the form of AN (N is a natural number); the adjuncts are annotated as such with the label AM followed by a secondary tag that represents the semantic classification of the adjunct. The assignment of semantic roles is illustrated in Figure 1, where the predicate is the verb “调查/investigate”. E.g., the NP “事故原因/the cause of the accident” is labeled as A1, meaning that it is the Patient. In previous research, SRL methods that are successful on English are adopted to resolve Chinese SRL (Sun and Jurafsky, 2004; Xue, 2008; Ding and Chang, 2008, 2009; Sun et al., 2009; Sun, 2010). Xue (2008) produced complete and systematic research on full parsing based methods. 168 Proceedings of the ACL 2010 Conference Short Papers, pages 168–172, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics IP ��������������������������������� A0 VP NP ���������������������� ������������ AM-TMP AM-MNR VP ���������������������� NN ADVP ADVP Rel A1 警方 AD AD VV NP police ������������ 正在 详细 调查 NN NN now thoroughly investigate 事故 原因 accident cause Figure 1: An example sentence: The police are thoroughly investigating the cause of</context>
<context position="5693" citStr="Ding and Chang, 2008" startWordPosition="903" endWordPosition="906">argument candidates. In the AI step, a lot of syntactic features are extracted to distinguish argument and non-argument. In other words, a binary classifier is trained to classify each argument candidate as either an argument or not. Finally, a multi-class classifier is trained to label each argument recognized in the former stage with a specific semantic role label. In both AI and SRC, the main job is to select strong syntactic features. 1See (Sun et al., 2008) for detailed definition. 3 Features A majority of features used in our system are a combination of features described in (Xue, 2008; Ding and Chang, 2008) as well as the word formation and coarse frame features introduced in (Sun et al., 2009), the c-command thread features proposed in (Sun et al., 2008). We give a brief description of features used in previous work, but explain new features in details. For more information, readers can refer to relevant papers and our source codes2 that are well commented. To conveniently illustrate, we denote a candidate constituent ck with a fixed context wi−1[ckwi...wh...wj]wj+1, where wh is the head word of ck, and denote predicate in focus with a context wv−2wv−1wvwv+1wv+2, where wv is the predicate in fo</context>
<context position="7023" citStr="Ding and Chang, 2008" startWordPosition="1120" endWordPosition="1123"> as baseline. Word content of wv, wh, wi, wj and wi+wj; POS tag of wv, wh. subcategorization frame, verb class of wv; position, phrase type ck, path from ck to wv (from (Xue, 2008; Ding and Chang, 2008)) First character, last character and word length of wv, first character+length, last character+word length, first character+position, last character+position, coarse frame, frame+wv, frame+left character, frame+verb class, frame+ck (from (Sun et al., 2009)). Head word POS, head word of PP phrases, category of ck’s lift and right siblings, CFG rewrite rule that expands ck and ck’s parent (from (Ding and Chang, 2008)). 3.2 New Word Features We introduce some new features which can be extracted without syntactic structure. We denote them as word features. They include: Word content of wv−1, wv+1, wi−1 and wj+1; POS tag of wv−1, wv+1, wv−2, wv+2, wi−1, wi, wj, wj+1, wi+2 and wj−2. Length of ck: how many words are there in ck. Word before “LC”: If the POS of wj is “LC” (localizer), we use wj−1 and its POS tag as two new features. NT: Does ck contain a word with POS “NT” (temporal noun)? 2Available at http://code.google.com/p/ csrler/. 169 Combination features: wz’s POS+wk’s POS, w&amp;quot;+Position 3.3 New Syntactic</context>
<context position="9525" citStr="Ding and Chang, 2008" startWordPosition="1567" endWordPosition="1570">re NPINN and NPI原Q. Combination features: verb class+ck, wh+w&amp;quot;, wh+Position, wh+w&amp;quot;+Position, path+w&amp;quot;, wh+right path, w&amp;quot;+left path, frame+w&amp;quot;+wh, and w&amp;quot;+cct. 4 Experiments and Analysis 4.1 Experimental Setting To facilitate comparison with previous work, we use CPB 1.0 and CTB 5.0, the same data setting with (Xue, 2008). The data is divided into three parts: files from 081 to 899 are used as training set; files from 041 to 080 as development set; files from 001 to 040, and 900 to 931 as test set. Nearly all previous research on constituency based SRL evaluation use this setting, also including (Ding and Chang, 2008, 2009; Sun et al., 2009; Sun, 2010). All parsing and SRL experiments use this data setting. To resolve classification problems, we use a linear SVM classifier SVMlin3, along with One-Vs-All approach for multi-class classification. To evaluate SRL with automatic parsing, we use a state-of-the-art parser, Bikel parser4 (Bikel, 2004). We use gold segmentation and POS as input to the Bikel parser and use it parsing results as input to our SRL system. The overall LP/LR/F performance of Bikel parser is 79.98%/82.95%/81.43. 4.2 Overall Performance Table 1 summarizes precision, recall and Fmeasure of</context>
</contexts>
<marker>Ding, Chang, 2008</marker>
<rawString>Weiwei Ding and Baobao Chang. 2008. Improving Chinese semantic role classification with hierarchical feature selection strategy. In Proceedings of the EMNLP 2008, pages 324– 333. Association for Computational Linguistics, Honolulu, Hawaii.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weiwei Ding</author>
<author>Baobao Chang</author>
</authors>
<title>Fast semantic role labeling for Chinese based on semantic chunking.</title>
<date>2009</date>
<booktitle>In ICCPOL ’09: Proceedings of the 22nd International Conference on Computer Processing of Oriental Languages. Language Technology for the Knowledgebased Economy,</booktitle>
<pages>79--90</pages>
<publisher>Springer-Verlag,</publisher>
<location>Berlin, Heidelberg.</location>
<contexts>
<context position="4866" citStr="Ding and Chang, 2009" startWordPosition="763" endWordPosition="766">classification problems. Ding and Chang (2008) divided SRC into two sub-tasks in sequence: Each argument should first be determined whether it is a core argument or an adjunct, and then be classified into fine-grained categories. However, delicately designed features are more important and our experiments suggest that by using rich features, a better SRC solver can be directly trained without using hierarchical architecture. There are also some attempts at relaxing the necessity of using full syntactic parses, and semantic chunking methods have been introduced by (Sun et al., 2009; Sun, 2010; Ding and Chang, 2009). 2.1 Our System We implement a three-stage (i.e. pruning, AI and SRC) SRL system. In the pruning step, our system keeps all constituents (except punctuations) that c-command1 current predicate in focus as argument candidates. In the AI step, a lot of syntactic features are extracted to distinguish argument and non-argument. In other words, a binary classifier is trained to classify each argument candidate as either an argument or not. Finally, a multi-class classifier is trained to label each argument recognized in the former stage with a specific semantic role label. In both AI and SRC, the </context>
</contexts>
<marker>Ding, Chang, 2009</marker>
<rawString>Weiwei Ding and Baobao Chang. 2009. Fast semantic role labeling for Chinese based on semantic chunking. In ICCPOL ’09: Proceedings of the 22nd International Conference on Computer Processing of Oriental Languages. Language Technology for the Knowledgebased Economy, pages 79–90. Springer-Verlag, Berlin, Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiangyu Duan</author>
<author>Jun Zhao</author>
<author>Bo Xu</author>
</authors>
<title>Probabilistic models for action-based Chinese dependency parsing.</title>
<date>2007</date>
<booktitle>In ECML ’07: Proceedings of the 18th European conference on Machine Learning,</booktitle>
<pages>559--566</pages>
<publisher>SpringerVerlag,</publisher>
<location>Berlin, Heidelberg.</location>
<contexts>
<context position="14605" citStr="Duan et al., 2007" startWordPosition="2431" endWordPosition="2434">iers. 4.4 Why Word Features Are Effective for SRC? Table 4: Top 10 useful features for SRC. Table 4 shows the ten most useful features in SRC. We can see that two of these ten features are word features (denoted by t). Namely, word features play a more important role in SRC than in AI. Though the other eight features are based on full parsing, four of them (denoted by t) use the head word which can be well approximated by word features, according to some language specific properties. The head rules described in (Sun and Jurafsky, 2004) are very popular in Chinese parsing research, such as in (Duan et al., 2007; Zhang and Clark, 2008). From these head rules, we can see that head words of most phrases in Chinese are located at the first or the last position. We implement these rules on Chinese Tree Bank and find that 84.12% 5 nodes realize their heads as either their first or last word. Head position suggests that boundary words are good approximation of head word features. If head words have good approximation word features, then it is not strange that the four features denoted by t can be effectively represented by word features. Similar with feature effect in AI, most of most useful features in SR</context>
</contexts>
<marker>Duan, Zhao, Xu, 2007</marker>
<rawString>Xiangyu Duan, Jun Zhao, and Bo Xu. 2007. Probabilistic models for action-based Chinese dependency parsing. In ECML ’07: Proceedings of the 18th European conference on Machine Learning, pages 559–566. SpringerVerlag, Berlin, Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Isabelle Guyon</author>
<author>Andr´e Elisseeff</author>
</authors>
<title>An introduction to variable and feature selection.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--1157</pages>
<contexts>
<context position="12887" citStr="Guyon and Elisseeff, 2003" startWordPosition="2129" endWordPosition="2133">e with additional syntactic features. Line 4 shows the performance by using automatic parses generated by Bikel parser. We can see that: 1) word features only cannot train good classifiers to identify arguments; 2) it is very easy to recognize arguments with good enough syntactic parses; 3) there is a severe performance decline when automatic parses are used. The third observation is a similar conclusion in English SRL. However this problem in Chinese is much more serious due to the state-of-the-art of Chinese parsing. Information theoretic criteria are popular criteria in variable selection (Guyon and Elisseeff, 2003). This paper uses empirical mutual information between each variable and the target, I(X, Y ) = &amp;;cX,ycY p(x, y) log p(�,y) p(�)p(y), to roughly rank the importance of features. Table 3 shows the ten most useful features in AI. We can see that the most important features all based on full parsing information. Nine of these top 10 useful features are our new features. Rank Feature 2 1 wh+w&amp;quot;+Position 3 htr-w 5 path 7 cpath 9 path+w&amp;quot; Table 3: Top 10 useful features for AI. t means word features. 4.3.2 The Effect of Parsing in SRC The second block in Table 2 summarizes the SRC performance with gol</context>
</contexts>
<marker>Guyon, Elisseeff, 2003</marker>
<rawString>Isabelle Guyon and Andr´e Elisseeff. 2003. An introduction to variable and feature selection. Journal of Machine Learning Research, 3:1157–1182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Honglin Sun</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Shallow semantc parsing of Chinese.</title>
<date>2004</date>
<booktitle>In Daniel Marcu Susan Dumais and Salim Roukos, editors, HLTNAACL 2004: Main Proceedings.</booktitle>
<contexts>
<context position="1171" citStr="Sun and Jurafsky, 2004" startWordPosition="169" endWordPosition="172">significant improvement over the best reported performance 92.0. We are further concerned with the effect of parsing in Chinese SRL. We empirically analyze the two-fold effect, grouping words into constituents and providing syntactic information. We also give some preliminary linguistic explanations. 1 Introduction Previous work on Chinese Semantic Role Labeling (SRL) mainly focused on how to implement SRL methods which are successful on English. Similar to English, parsing is a standard pre-processing for Chinese SRL. Many features are extracted to represent constituents in the input parses (Sun and Jurafsky, 2004; Xue, 2008; Ding and Chang, 2008). By using these features, semantic classifiers are trained to predict whether a constituent fills a semantic role. Developing features that capture the right kind of information encoded in the input parses has been shown crucial to advancing the state-of-the-art. Though there has been some work on feature design in Chinese SRL, information encoded in the syntactic trees is not fully exploited and requires more research effort. In this paper, we propose a set of additional The work was partially completed while this author was at Peking University. features, s</context>
<context position="3333" citStr="Sun and Jurafsky, 2004" startWordPosition="524" endWordPosition="527">he Chinese TreeBank (CTB). The arguments of a predicate are labeled with a contiguous sequence of integers, in the form of AN (N is a natural number); the adjuncts are annotated as such with the label AM followed by a secondary tag that represents the semantic classification of the adjunct. The assignment of semantic roles is illustrated in Figure 1, where the predicate is the verb “调查/investigate”. E.g., the NP “事故原因/the cause of the accident” is labeled as A1, meaning that it is the Patient. In previous research, SRL methods that are successful on English are adopted to resolve Chinese SRL (Sun and Jurafsky, 2004; Xue, 2008; Ding and Chang, 2008, 2009; Sun et al., 2009; Sun, 2010). Xue (2008) produced complete and systematic research on full parsing based methods. 168 Proceedings of the ACL 2010 Conference Short Papers, pages 168–172, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics IP ��������������������������������� A0 VP NP ���������������������� ������������ AM-TMP AM-MNR VP ���������������������� NN ADVP ADVP Rel A1 警方 AD AD VV NP police ������������ 正在 详细 调查 NN NN now thoroughly investigate 事故 原因 accident cause Figure 1: An example sentence: The police are thor</context>
<context position="14529" citStr="Sun and Jurafsky, 2004" startWordPosition="2417" endWordPosition="2420">rors, automatic parsed syntactic features cause noise to the semantic role classifiers. 4.4 Why Word Features Are Effective for SRC? Table 4: Top 10 useful features for SRC. Table 4 shows the ten most useful features in SRC. We can see that two of these ten features are word features (denoted by t). Namely, word features play a more important role in SRC than in AI. Though the other eight features are based on full parsing, four of them (denoted by t) use the head word which can be well approximated by word features, according to some language specific properties. The head rules described in (Sun and Jurafsky, 2004) are very popular in Chinese parsing research, such as in (Duan et al., 2007; Zhang and Clark, 2008). From these head rules, we can see that head words of most phrases in Chinese are located at the first or the last position. We implement these rules on Chinese Tree Bank and find that 84.12% 5 nodes realize their heads as either their first or last word. Head position suggests that boundary words are good approximation of head word features. If head words have good approximation word features, then it is not strange that the four features denoted by t can be effectively represented by word fea</context>
</contexts>
<marker>Sun, Jurafsky, 2004</marker>
<rawString>Honglin Sun and Daniel Jurafsky. 2004. Shallow semantc parsing of Chinese. In Daniel Marcu Susan Dumais and Salim Roukos, editors, HLTNAACL 2004: Main Proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weiwei Sun</author>
</authors>
<title>Semantics-driven shallow parsing for Chinese semantic role labeling.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL</booktitle>
<contexts>
<context position="3402" citStr="Sun, 2010" startWordPosition="539" endWordPosition="540">uous sequence of integers, in the form of AN (N is a natural number); the adjuncts are annotated as such with the label AM followed by a secondary tag that represents the semantic classification of the adjunct. The assignment of semantic roles is illustrated in Figure 1, where the predicate is the verb “调查/investigate”. E.g., the NP “事故原因/the cause of the accident” is labeled as A1, meaning that it is the Patient. In previous research, SRL methods that are successful on English are adopted to resolve Chinese SRL (Sun and Jurafsky, 2004; Xue, 2008; Ding and Chang, 2008, 2009; Sun et al., 2009; Sun, 2010). Xue (2008) produced complete and systematic research on full parsing based methods. 168 Proceedings of the ACL 2010 Conference Short Papers, pages 168–172, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics IP ��������������������������������� A0 VP NP ���������������������� ������������ AM-TMP AM-MNR VP ���������������������� NN ADVP ADVP Rel A1 警方 AD AD VV NP police ������������ 正在 详细 调查 NN NN now thoroughly investigate 事故 原因 accident cause Figure 1: An example sentence: The police are thoroughly investigating the cause of the accident. Their method divided </context>
<context position="4843" citStr="Sun, 2010" startWordPosition="761" endWordPosition="762">ted as two classification problems. Ding and Chang (2008) divided SRC into two sub-tasks in sequence: Each argument should first be determined whether it is a core argument or an adjunct, and then be classified into fine-grained categories. However, delicately designed features are more important and our experiments suggest that by using rich features, a better SRC solver can be directly trained without using hierarchical architecture. There are also some attempts at relaxing the necessity of using full syntactic parses, and semantic chunking methods have been introduced by (Sun et al., 2009; Sun, 2010; Ding and Chang, 2009). 2.1 Our System We implement a three-stage (i.e. pruning, AI and SRC) SRL system. In the pruning step, our system keeps all constituents (except punctuations) that c-command1 current predicate in focus as argument candidates. In the AI step, a lot of syntactic features are extracted to distinguish argument and non-argument. In other words, a binary classifier is trained to classify each argument candidate as either an argument or not. Finally, a multi-class classifier is trained to label each argument recognized in the former stage with a specific semantic role label. I</context>
<context position="9561" citStr="Sun, 2010" startWordPosition="1576" endWordPosition="1577"> class+ck, wh+w&amp;quot;, wh+Position, wh+w&amp;quot;+Position, path+w&amp;quot;, wh+right path, w&amp;quot;+left path, frame+w&amp;quot;+wh, and w&amp;quot;+cct. 4 Experiments and Analysis 4.1 Experimental Setting To facilitate comparison with previous work, we use CPB 1.0 and CTB 5.0, the same data setting with (Xue, 2008). The data is divided into three parts: files from 081 to 899 are used as training set; files from 041 to 080 as development set; files from 001 to 040, and 900 to 931 as test set. Nearly all previous research on constituency based SRL evaluation use this setting, also including (Ding and Chang, 2008, 2009; Sun et al., 2009; Sun, 2010). All parsing and SRL experiments use this data setting. To resolve classification problems, we use a linear SVM classifier SVMlin3, along with One-Vs-All approach for multi-class classification. To evaluate SRL with automatic parsing, we use a state-of-the-art parser, Bikel parser4 (Bikel, 2004). We use gold segmentation and POS as input to the Bikel parser and use it parsing results as input to our SRL system. The overall LP/LR/F performance of Bikel parser is 79.98%/82.95%/81.43. 4.2 Overall Performance Table 1 summarizes precision, recall and Fmeasure of AI, SRC and the whole task (AI+SRC)</context>
</contexts>
<marker>Sun, 2010</marker>
<rawString>Weiwei Sun. 2010. Semantics-driven shallow parsing for Chinese semantic role labeling. In Proceedings of the ACL 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weiwei Sun</author>
<author>Zhifang Sui</author>
</authors>
<title>Chinese function tag labeling.</title>
<date>2009</date>
<booktitle>In Proceedings of the 23rd Pacific Asia Conference on Language, Information and Computation. Hong Kong.</booktitle>
<contexts>
<context position="8391" citStr="Sun and Sui, 2009" startWordPosition="1360" endWordPosition="1363">res to encode the structural information. Category of ck’s parent; head word and POS of head word of parent, left sibling and right sibling of ck. Lexicalized Rewrite rules: Conjuction of rewrite rule and head word of its corresponding RHS. These features of candidate (lrw-c) and its parent (lrw-p) are used. For example, this lrwc feature of the NP “事#原Q” in Figure 1 is NP --� NN + NN(原Q). Partial Path: Path from the ck or w&amp;quot; to the lowest common ancestor of ck and w&amp;quot;. One path feature, hence, is divided into left path and right path. Clustered Path: We use the manually created clusters (see (Sun and Sui, 2009)) of categories of all nodes in the path (cpath) and right path. C-commander thread between ck and w&amp;quot; (cct): (proposed by (Sun et al., 2008)). For example, this feature of the NP “警方” in Figure 1 is NP + ADV P + ADV P + V V . Head Trace: The sequential container of the head down upon the phrase (from (Sun and Sui, 2009)). We design two kinds of traces (htr-p, htrw): one uses POS of the head word; the other uses the head word word itself. E.g., the head word of 事#原Q is “原Q” therefore these feature of this NP are NPINN and NPI原Q. Combination features: verb class+ck, wh+w&amp;quot;, wh+Position, wh+w&amp;quot;+Pos</context>
</contexts>
<marker>Sun, Sui, 2009</marker>
<rawString>Weiwei Sun and Zhifang Sui. 2009. Chinese function tag labeling. In Proceedings of the 23rd Pacific Asia Conference on Language, Information and Computation. Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weiwei Sun</author>
<author>Zhifang Sui</author>
<author>Haifeng Wang</author>
</authors>
<title>Prediction of maximal projection for semantic role labeling.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="5538" citStr="Sun et al., 2008" startWordPosition="877" endWordPosition="880">ng, AI and SRC) SRL system. In the pruning step, our system keeps all constituents (except punctuations) that c-command1 current predicate in focus as argument candidates. In the AI step, a lot of syntactic features are extracted to distinguish argument and non-argument. In other words, a binary classifier is trained to classify each argument candidate as either an argument or not. Finally, a multi-class classifier is trained to label each argument recognized in the former stage with a specific semantic role label. In both AI and SRC, the main job is to select strong syntactic features. 1See (Sun et al., 2008) for detailed definition. 3 Features A majority of features used in our system are a combination of features described in (Xue, 2008; Ding and Chang, 2008) as well as the word formation and coarse frame features introduced in (Sun et al., 2009), the c-command thread features proposed in (Sun et al., 2008). We give a brief description of features used in previous work, but explain new features in details. For more information, readers can refer to relevant papers and our source codes2 that are well commented. To conveniently illustrate, we denote a candidate constituent ck with a fixed context </context>
<context position="8531" citStr="Sun et al., 2008" startWordPosition="1385" endWordPosition="1388">f ck. Lexicalized Rewrite rules: Conjuction of rewrite rule and head word of its corresponding RHS. These features of candidate (lrw-c) and its parent (lrw-p) are used. For example, this lrwc feature of the NP “事#原Q” in Figure 1 is NP --� NN + NN(原Q). Partial Path: Path from the ck or w&amp;quot; to the lowest common ancestor of ck and w&amp;quot;. One path feature, hence, is divided into left path and right path. Clustered Path: We use the manually created clusters (see (Sun and Sui, 2009)) of categories of all nodes in the path (cpath) and right path. C-commander thread between ck and w&amp;quot; (cct): (proposed by (Sun et al., 2008)). For example, this feature of the NP “警方” in Figure 1 is NP + ADV P + ADV P + V V . Head Trace: The sequential container of the head down upon the phrase (from (Sun and Sui, 2009)). We design two kinds of traces (htr-p, htrw): one uses POS of the head word; the other uses the head word word itself. E.g., the head word of 事#原Q is “原Q” therefore these feature of this NP are NPINN and NPI原Q. Combination features: verb class+ck, wh+w&amp;quot;, wh+Position, wh+w&amp;quot;+Position, path+w&amp;quot;, wh+right path, w&amp;quot;+left path, frame+w&amp;quot;+wh, and w&amp;quot;+cct. 4 Experiments and Analysis 4.1 Experimental Setting To facilitate comp</context>
</contexts>
<marker>Sun, Sui, Wang, 2008</marker>
<rawString>Weiwei Sun, Zhifang Sui, and Haifeng Wang. 2008. Prediction of maximal projection for semantic role labeling. In Proceedings of the 22nd International Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weiwei Sun</author>
<author>Zhifang Sui</author>
<author>Meng Wang</author>
<author>Xin Wang</author>
</authors>
<title>Chinese semantic role labeling with shallow parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1475--1483</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics, Singapore.</institution>
<contexts>
<context position="3390" citStr="Sun et al., 2009" startWordPosition="535" endWordPosition="538">eled with a contiguous sequence of integers, in the form of AN (N is a natural number); the adjuncts are annotated as such with the label AM followed by a secondary tag that represents the semantic classification of the adjunct. The assignment of semantic roles is illustrated in Figure 1, where the predicate is the verb “调查/investigate”. E.g., the NP “事故原因/the cause of the accident” is labeled as A1, meaning that it is the Patient. In previous research, SRL methods that are successful on English are adopted to resolve Chinese SRL (Sun and Jurafsky, 2004; Xue, 2008; Ding and Chang, 2008, 2009; Sun et al., 2009; Sun, 2010). Xue (2008) produced complete and systematic research on full parsing based methods. 168 Proceedings of the ACL 2010 Conference Short Papers, pages 168–172, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics IP ��������������������������������� A0 VP NP ���������������������� ������������ AM-TMP AM-MNR VP ���������������������� NN ADVP ADVP Rel A1 警方 AD AD VV NP police ������������ 正在 详细 调查 NN NN now thoroughly investigate 事故 原因 accident cause Figure 1: An example sentence: The police are thoroughly investigating the cause of the accident. Their met</context>
<context position="4832" citStr="Sun et al., 2009" startWordPosition="757" endWordPosition="760">d SRC, are formulated as two classification problems. Ding and Chang (2008) divided SRC into two sub-tasks in sequence: Each argument should first be determined whether it is a core argument or an adjunct, and then be classified into fine-grained categories. However, delicately designed features are more important and our experiments suggest that by using rich features, a better SRC solver can be directly trained without using hierarchical architecture. There are also some attempts at relaxing the necessity of using full syntactic parses, and semantic chunking methods have been introduced by (Sun et al., 2009; Sun, 2010; Ding and Chang, 2009). 2.1 Our System We implement a three-stage (i.e. pruning, AI and SRC) SRL system. In the pruning step, our system keeps all constituents (except punctuations) that c-command1 current predicate in focus as argument candidates. In the AI step, a lot of syntactic features are extracted to distinguish argument and non-argument. In other words, a binary classifier is trained to classify each argument candidate as either an argument or not. Finally, a multi-class classifier is trained to label each argument recognized in the former stage with a specific semantic ro</context>
<context position="6861" citStr="Sun et al., 2009" startWordPosition="1090" endWordPosition="1093">−2wv−1wvwv+1wv+2, where wv is the predicate in focus. 3.1 Baseline Features The following features are introduced in previous Chinese SRL systems. We use them as baseline. Word content of wv, wh, wi, wj and wi+wj; POS tag of wv, wh. subcategorization frame, verb class of wv; position, phrase type ck, path from ck to wv (from (Xue, 2008; Ding and Chang, 2008)) First character, last character and word length of wv, first character+length, last character+word length, first character+position, last character+position, coarse frame, frame+wv, frame+left character, frame+verb class, frame+ck (from (Sun et al., 2009)). Head word POS, head word of PP phrases, category of ck’s lift and right siblings, CFG rewrite rule that expands ck and ck’s parent (from (Ding and Chang, 2008)). 3.2 New Word Features We introduce some new features which can be extracted without syntactic structure. We denote them as word features. They include: Word content of wv−1, wv+1, wi−1 and wj+1; POS tag of wv−1, wv+1, wv−2, wv+2, wi−1, wi, wj, wj+1, wi+2 and wj−2. Length of ck: how many words are there in ck. Word before “LC”: If the POS of wj is “LC” (localizer), we use wj−1 and its POS tag as two new features. NT: Does ck contain</context>
<context position="9549" citStr="Sun et al., 2009" startWordPosition="1572" endWordPosition="1575">ion features: verb class+ck, wh+w&amp;quot;, wh+Position, wh+w&amp;quot;+Position, path+w&amp;quot;, wh+right path, w&amp;quot;+left path, frame+w&amp;quot;+wh, and w&amp;quot;+cct. 4 Experiments and Analysis 4.1 Experimental Setting To facilitate comparison with previous work, we use CPB 1.0 and CTB 5.0, the same data setting with (Xue, 2008). The data is divided into three parts: files from 081 to 899 are used as training set; files from 041 to 080 as development set; files from 001 to 040, and 900 to 931 as test set. Nearly all previous research on constituency based SRL evaluation use this setting, also including (Ding and Chang, 2008, 2009; Sun et al., 2009; Sun, 2010). All parsing and SRL experiments use this data setting. To resolve classification problems, we use a linear SVM classifier SVMlin3, along with One-Vs-All approach for multi-class classification. To evaluate SRL with automatic parsing, we use a state-of-the-art parser, Bikel parser4 (Bikel, 2004). We use gold segmentation and POS as input to the Bikel parser and use it parsing results as input to our SRL system. The overall LP/LR/F performance of Bikel parser is 79.98%/82.95%/81.43. 4.2 Overall Performance Table 1 summarizes precision, recall and Fmeasure of AI, SRC and the whole t</context>
</contexts>
<marker>Sun, Sui, Wang, Wang, 2009</marker>
<rawString>Weiwei Sun, Zhifang Sui, Meng Wang, and Xin Wang. 2009. Chinese semantic role labeling with shallow parsing. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1475–1483. Association for Computational Linguistics, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
</authors>
<title>Labeling Chinese predicates with semantic roles.</title>
<date>2008</date>
<journal>Comput. Linguist.,</journal>
<volume>34</volume>
<issue>2</issue>
<contexts>
<context position="1182" citStr="Xue, 2008" startWordPosition="173" endWordPosition="174">over the best reported performance 92.0. We are further concerned with the effect of parsing in Chinese SRL. We empirically analyze the two-fold effect, grouping words into constituents and providing syntactic information. We also give some preliminary linguistic explanations. 1 Introduction Previous work on Chinese Semantic Role Labeling (SRL) mainly focused on how to implement SRL methods which are successful on English. Similar to English, parsing is a standard pre-processing for Chinese SRL. Many features are extracted to represent constituents in the input parses (Sun and Jurafsky, 2004; Xue, 2008; Ding and Chang, 2008). By using these features, semantic classifiers are trained to predict whether a constituent fills a semantic role. Developing features that capture the right kind of information encoded in the input parses has been shown crucial to advancing the state-of-the-art. Though there has been some work on feature design in Chinese SRL, information encoded in the syntactic trees is not fully exploited and requires more research effort. In this paper, we propose a set of additional The work was partially completed while this author was at Peking University. features, some of whic</context>
<context position="3344" citStr="Xue, 2008" startWordPosition="528" endWordPosition="529">). The arguments of a predicate are labeled with a contiguous sequence of integers, in the form of AN (N is a natural number); the adjuncts are annotated as such with the label AM followed by a secondary tag that represents the semantic classification of the adjunct. The assignment of semantic roles is illustrated in Figure 1, where the predicate is the verb “调查/investigate”. E.g., the NP “事故原因/the cause of the accident” is labeled as A1, meaning that it is the Patient. In previous research, SRL methods that are successful on English are adopted to resolve Chinese SRL (Sun and Jurafsky, 2004; Xue, 2008; Ding and Chang, 2008, 2009; Sun et al., 2009; Sun, 2010). Xue (2008) produced complete and systematic research on full parsing based methods. 168 Proceedings of the ACL 2010 Conference Short Papers, pages 168–172, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics IP ��������������������������������� A0 VP NP ���������������������� ������������ AM-TMP AM-MNR VP ���������������������� NN ADVP ADVP Rel A1 警方 AD AD VV NP police ������������ 正在 详细 调查 NN NN now thoroughly investigate 事故 原因 accident cause Figure 1: An example sentence: The police are thoroughly inve</context>
<context position="5670" citStr="Xue, 2008" startWordPosition="901" endWordPosition="902">n focus as argument candidates. In the AI step, a lot of syntactic features are extracted to distinguish argument and non-argument. In other words, a binary classifier is trained to classify each argument candidate as either an argument or not. Finally, a multi-class classifier is trained to label each argument recognized in the former stage with a specific semantic role label. In both AI and SRC, the main job is to select strong syntactic features. 1See (Sun et al., 2008) for detailed definition. 3 Features A majority of features used in our system are a combination of features described in (Xue, 2008; Ding and Chang, 2008) as well as the word formation and coarse frame features introduced in (Sun et al., 2009), the c-command thread features proposed in (Sun et al., 2008). We give a brief description of features used in previous work, but explain new features in details. For more information, readers can refer to relevant papers and our source codes2 that are well commented. To conveniently illustrate, we denote a candidate constituent ck with a fixed context wi−1[ckwi...wh...wj]wj+1, where wh is the head word of ck, and denote predicate in focus with a context wv−2wv−1wvwv+1wv+2, where wv</context>
<context position="9224" citStr="Xue, 2008" startWordPosition="1512" endWordPosition="1513"> . Head Trace: The sequential container of the head down upon the phrase (from (Sun and Sui, 2009)). We design two kinds of traces (htr-p, htrw): one uses POS of the head word; the other uses the head word word itself. E.g., the head word of 事#原Q is “原Q” therefore these feature of this NP are NPINN and NPI原Q. Combination features: verb class+ck, wh+w&amp;quot;, wh+Position, wh+w&amp;quot;+Position, path+w&amp;quot;, wh+right path, w&amp;quot;+left path, frame+w&amp;quot;+wh, and w&amp;quot;+cct. 4 Experiments and Analysis 4.1 Experimental Setting To facilitate comparison with previous work, we use CPB 1.0 and CTB 5.0, the same data setting with (Xue, 2008). The data is divided into three parts: files from 081 to 899 are used as training set; files from 041 to 080 as development set; files from 001 to 040, and 900 to 931 as test set. Nearly all previous research on constituency based SRL evaluation use this setting, also including (Ding and Chang, 2008, 2009; Sun et al., 2009; Sun, 2010). All parsing and SRL experiments use this data setting. To resolve classification problems, we use a linear SVM classifier SVMlin3, along with One-Vs-All approach for multi-class classification. To evaluate SRL with automatic parsing, we use a state-of-the-art p</context>
<context position="10628" citStr="Xue, 2008" startWordPosition="1758" endWordPosition="1759">parser is 79.98%/82.95%/81.43. 4.2 Overall Performance Table 1 summarizes precision, recall and Fmeasure of AI, SRC and the whole task (AI+SRC) of our system respectively. The forth line is the best published SRC performance reported in (Ding and Chang, 2008), and the sixth line is the best SRL performance reported in (Xue, 2008). Other lines show the performance of our system. These results indicate a significant improvement over previous systems due to the new features. Test P(%) R(%) F/A AI 98.56 97.91 98.24 SRC - - - - 95.04 (Ding and Chang, 2008) - - - - 94.68 AI + SRC 93.80 93.18 93.49 (Xue, 2008) 93.0 91.0 92.0 Table 1: SRL performance on the test data with gold standard parses. 4.3 Two-fold Effect of Parsing in SRL The effect of parsing in SRL is two-fold. On the one hand, SRL systems should group words as argument candidates, which are also constituents in a given sentence. Full parsing provides boundary information of all constituents. As arguments should c-command the predicate, a full parser can further prune a majority of useless constituents. In other words, parsing can effectively supply SRL with argument candidates. Unfortunately, it is very hard to rightly produce full parse</context>
</contexts>
<marker>Xue, 2008</marker>
<rawString>Nianwen Xue. 2008. Labeling Chinese predicates with semantic roles. Comput. Linguist., 34(2):225–255.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Stephen Clark</author>
</authors>
<title>A tale of two parsers: Investigating and combining graphbased and transition-based dependency parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>562--571</pages>
<location>Honolulu, Hawaii.</location>
<contexts>
<context position="14629" citStr="Zhang and Clark, 2008" startWordPosition="2435" endWordPosition="2438">Features Are Effective for SRC? Table 4: Top 10 useful features for SRC. Table 4 shows the ten most useful features in SRC. We can see that two of these ten features are word features (denoted by t). Namely, word features play a more important role in SRC than in AI. Though the other eight features are based on full parsing, four of them (denoted by t) use the head word which can be well approximated by word features, according to some language specific properties. The head rules described in (Sun and Jurafsky, 2004) are very popular in Chinese parsing research, such as in (Duan et al., 2007; Zhang and Clark, 2008). From these head rules, we can see that head words of most phrases in Chinese are located at the first or the last position. We implement these rules on Chinese Tree Bank and find that 84.12% 5 nodes realize their heads as either their first or last word. Head position suggests that boundary words are good approximation of head word features. If head words have good approximation word features, then it is not strange that the four features denoted by t can be effectively represented by word features. Similar with feature effect in AI, most of most useful features in SRC are our new features. </context>
</contexts>
<marker>Zhang, Clark, 2008</marker>
<rawString>Yue Zhang and Stephen Clark. 2008. A tale of two parsers: Investigating and combining graphbased and transition-based dependency parsing. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 562–571. Association for Computational Linguistics, Honolulu, Hawaii.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>