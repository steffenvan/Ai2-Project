<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000017">
<title confidence="0.995878">
Dynamic Programming Matching for Large Scale Information Retrieval
</title>
<author confidence="0.985406">
Eiko Yamamoto
</author>
<affiliation confidence="0.978449">
Communications Research Laboratory, Kyoto Japan
</affiliation>
<email confidence="0.987959">
eiko@crl.go.jp
</email>
<author confidence="0.757914">
Masahiro Kishida Yoshinori Takenami
</author>
<affiliation confidence="0.695211">
Sumitomo Electric Information Systems Co., Ltd., Osaka Japan
</affiliation>
<email confidence="0.995231">
{kishida-masahiro, takenami-yoshinori}@sei.co.jp
</email>
<author confidence="0.999184">
Yoshiyuki Takeda Kyoji Umemura
</author>
<affiliation confidence="0.999938">
Toyohashi University of Technology, Aichi Japan
</affiliation>
<email confidence="0.998299">
{take@ss.ics, umemura@tutics}.tut.ac.jp
</email>
<sectionHeader confidence="0.995643" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.996476461538462">
Though dynamic programming matching
can carry out approximate string matching
when there may be deletions or insertions
in a document, its effectiveness and
efficiency are usually too poor to use it for
large-scale information retrieval. In this
paper, we propose a method of dynamic
programming matching for information
retrieval. This method is as effective as a
conventional information retrieval system,
even though it is capable of approximate
matching. It is also as efficient as a
conventional system.
</bodyText>
<keyword confidence="0.7456685">
Keywords: Dynamic programming,
Corpus-based, Japanese.
</keyword>
<sectionHeader confidence="0.998995" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999966166666667">
The dynamic programming method is well-known
for its ability to calculate the edit distance between
strings. The method can also be applied to informa-
tion retrieval. Dynamic programming matching can
measure the similarity between documents, even if
there are partial deletions or insertions. However,
there are two problems in applying this method to
information retrieval. One problem is search effec-
tiveness. It is poor because dynamic programming
matching lacks an adequate weighting schema. The
second problem is computational efficiency. Also,
lack of an adequate indexing schema means that dy-
namic programming matching usually has to process
the entire document.
Yamamoto et al. proposed a method of dynamic
programming matching with acceptable search ef-
fectiveness (Yamamoto et al., 2000; Yamamoto,
Takeda, and Umemura, 2003). They report that
the effectiveness of dynamic programming match-
ing improves by introducing an IDF (Inverse Doc-
ument Frequency) weighting schema for all strings
that contribute similarity. They calculate matching
weights not only for words but also for all strings.
Although they report that effectiveness is improved,
the speed of their method is slower than that of
conventional dynamic programming matching, and
much slower than that of a typical information re-
trieval system.
In this paper, we aim to improve the retrieval ef-
ficiency of the dynamic programming method while
keeping its search effectiveness. From a mathemat-
ical point of view, we have only changed the defini-
tion of the weighting. The mathematical structure of
similarity remains the same as that of the dynamic
programming method proposed by (Yamamoto et
al., 2000; Yamamoto, Takeda, and Umemura, 2003).
Although it has the same definition, the new weight-
ing method makes it possible to build a more effi-
cient information retrieval system by creating the in-
dex in advance. To our surprise, we have observed
that our proposed method is not only more efficient
but also more effective.
</bodyText>
<sectionHeader confidence="0.864289" genericHeader="method">
2 Similarities Based on Dynamic
</sectionHeader>
<subsectionHeader confidence="0.544607">
Programming Matching
</subsectionHeader>
<bodyText confidence="0.999879611111111">
In this section, we introduce several similarities
proposed by (Yamamoto et al., 2000; Yamamoto,
Takeda, and Umemura, 2003). All of them are a
form of dynamic programming matching. These
similarities include translation of the edit distance.
This distance has been described by several authors.
We have adopted Korfhage’s definition: ‘the edit
distance is the minimum number of edit operations,
such as insertion and deletion, which are required to
map one string into the other’ (Korfhage, 1997).
There are three related similarities. The first is dy-
namic programming matching, which is simply con-
version of the edit distance. The second similarity
is an extension of the first similarity, introducing a
character weighting for each contributing character.
The third and proposed similarity is an extension of
the second one, using string weight instead of char-
acter weight.
</bodyText>
<subsectionHeader confidence="0.948153">
2.1 Dynamic Programming Matching
</subsectionHeader>
<bodyText confidence="0.999984">
As stated above, dynamic programming (DP)
matching is a conversion of edit distance. We call
this similarity SIM1. While the edit distance (ED) is
a measure of difference, counting different charac-
ters between two strings, SIM1 is a measure of sim-
ilarity, counting matching characters between two
strings. ED and SIM1 are defined as follows:
</bodyText>
<subsectionHeader confidence="0.487067">
Definition 2.1 Edit Distance (Korfhage, 1997)
</subsectionHeader>
<bodyText confidence="0.9809685">
Let α and Q be strings, x and y be a character, and
“” be empty string.
</bodyText>
<listItem confidence="0.9983982">
• If both strings are empty then
ED(“”, “”) = 0.0
• If x =� y then
ED(x, y) = 1.0
• If their first characters are the same then
</listItem>
<equation confidence="0.994473333333333">
ED(xα, xQ) =
MIN(ED(α, xQ), ED(xα, Q),
ED(α, Q) + 1.0)
</equation>
<listItem confidence="0.754125">
• Otherwise
</listItem>
<equation confidence="0.8460745">
ED(xα, yQ) =
MIN(ED(α, yQ), ED(xα, Q),
ED(α, Q))
Definition 2.2 SIM1
</equation>
<bodyText confidence="0.952653">
Let α and Q be strings, x and y be a character, and
“” be empty string.
</bodyText>
<listItem confidence="0.999458">
• If both strings are empty then
SIM1(“”, “”) = 0.0
• If x =� y then
SIM1(x, y) = 0.0
• If their first characters are the same then
</listItem>
<equation confidence="0.905450333333333">
SIM1(xα, xQ) =
MAX(SIM1(α, xQ), SIM1(xα, Q),
SIM1(α, Q) + 1.0)
</equation>
<listItem confidence="0.585137">
• Otherwise
</listItem>
<equation confidence="0.957747333333333">
SIM1(xα, yQ) =
MAX(SIM1(α, yQ), SIM1(xα, Q),
SIM1(α, Q))
</equation>
<subsectionHeader confidence="0.991551">
2.2 Character Weight DP Similarity
</subsectionHeader>
<bodyText confidence="0.999985352941176">
SIM1 adds 1.0 to the similarity between two strings
for every matching character, and this value is con-
stant for all the time. Our assumption for the new
function is that different characters make different
contributions. For example, in Japanese informa-
tion retrieval, Hiragana characters are usually used
for functional words and make a different contribu-
tion than Kanji characters, which are usually used
for content words. Thus, it is natural to assign a dif-
ferent similarity weight according to the nature of
the character. The below method of defining Charac-
ter Weight DP Similarity adds not 1.0 but a specific
weight depending on the matching character. We
call this similarity SIM2. It resembles Ukkonen’s
Enhanced Dynamic Programming ASM (Approxi-
mate String Matching) (Berghel and Roach, 1996).
The weight is expressed by a function called Score.
</bodyText>
<equation confidence="0.923184">
SIM2 is defined as follows:
Definition 2.3 SIM2
</equation>
<bodyText confidence="0.980646">
Let α and Q be strings, x and y be a character, and
“” be empty string.
</bodyText>
<listItem confidence="0.978555888888889">
• If both strings are empty then
SIM2(“”, “”) = 0.0
• If x =� y then
SIM2(x, y) = 0.0
• If their first characters are the same then
SIM2(xα, xQ) =
MAX(SIM2(α, xQ), SIM2(xα, Q),
SIM2(α, Q) + Score(x))
• Otherwise
</listItem>
<construct confidence="0.499813666666667">
SIM2(xα, yQ) =
MAX(SIM2(α, yQ), SIM2(xα, Q),
SIM2(α, Q))
</construct>
<subsectionHeader confidence="0.994846">
2.3 String Weight DP Similarity
</subsectionHeader>
<bodyText confidence="0.984686434782609">
DP procedure usually considers just a single char-
acter at a time, but since some long substrings can
receive good scores, it is natural to consider all pre-
fixes of the longest common prefix, not just the next
character.
While SIM2 uses a character weight whenever a
character matches between strings, a single char-
acter may not be enough. In some cases, even
when each character has a low weight, the string
as a whole may be a good clue for information re-
trieval. For example, ”chirimenjyako” is a Japanese
word that could be a retrieval key word. This word,
which means ”boiled and dried baby sardines,” con-
sists only of Hiragana characters ”chi-ri-me-n-jya-
ko” but each character would make a small contri-
bution in SIM2.
The proposed similarity is called String Weight
DP Similarity, which is a generalization of SIM2.
We call this similarity SIM3. It considers the weight
of all matching strings and is defined as follows:
Definition 2.4 SIM3
Let α and Q be strings, x and y be a character, and
“” be empty string.
</bodyText>
<listItem confidence="0.8990515">
• If both strings are empty then
SIM3(“”, “”) = Score(“”) = 0.0
• Otherwise
SIM3(α, Q) =
</listItem>
<equation confidence="0.997148666666667">
MAX(SIM3s(α, Q), SIM3g(α, Q))
– SIM3s(ξα, ξQ) =
MAX(Score(-y) + SIM3(δα, δQ))
</equation>
<bodyText confidence="0.8538825">
where ξ(= -yδ) is the maximum length
string matching from the first character.
</bodyText>
<equation confidence="0.769481333333333">
– SIM3g(xα, yQ) =
MAX(SIM3(α, yQ), SIM3(xα, Q),
SIM3(α, Q))
</equation>
<subsectionHeader confidence="0.998182">
2.4 Weighting Function
</subsectionHeader>
<bodyText confidence="0.982551857142857">
Yamamoto et al. have used IDF (Inverse Document
Frequency) as a weight for each string. The weight
is computed using a Score function as follows:
Definition 2.5 Yamamoto et al.’s Score function
Let ξ be string, df(ξ) the frequency of documents
including ξ in the document set for retrieval, and N
be the number of documents in the set.
</bodyText>
<equation confidence="0.979072">
Score(ξ) = IDF(ξ) = −log(df(ξ)/N)
</equation>
<bodyText confidence="0.999993384615385">
The standard one-character-at-a-time DP method
assumes that long matches cannot receive exception-
ally good scores. In other words, it regards Score(ξ)
as 0 if the length of ξ is greater than one. If the
Score function obeys the inequality, Score(δ-y) &lt;
Score(δ) + Score(-y) for all substrings δ and -y,
the best path would consist of a sequence of sin-
gle characters, and we would not need to consider
long phrases. However, we are proposing a different
Score function. It sometimes assigns good scores to
long phrases, and therefore SIM2 has to be extended
into SIM3 to establish a DP procedure that considers
more than just one character at a time.
</bodyText>
<sectionHeader confidence="0.979932" genericHeader="method">
3 Proposed Weighting Function
</sectionHeader>
<bodyText confidence="0.999982777777778">
Although SIM3, as shown in Section 2.3, has rea-
sonable effectiveness, its computation is harder than
that of the edit distance, and much harder than that
of the similarity used in a conventional information
retrieval system. In this paper, we have modified
the weighting function so that it keeps its effective-
ness while improving efficiency. To achieve this im-
provement, we use the SIM3 with the same defini-
tion but with a different score function.
</bodyText>
<subsectionHeader confidence="0.996506">
3.1 Proposed String Weighting
</subsectionHeader>
<bodyText confidence="0.999995071428571">
We reduce the computational cost by limiting strings
that have positive scores. First, we select bigrams as
such strings. In other words, we assign a score of
zero if the length of the string does not equal to 2.
Several language systems use Kanji characters (e.g.
Chinese and Japanese), and bigram is an effective
indexing unit for information retrieval for these lan-
guage systems (Ogawa and Matsuda, 1997). In addi-
tion, we may assume that the contribution of a longer
string is approximated by the total bigram weight-
ing. We have also restricted our attention to infre-
quent bigrams. Thus, we have restricted the weight-
ing function Score as follows, where K is the num-
ber decided by the given query.
</bodyText>
<listItem confidence="0.998103666666667">
• If string length is 2 and cf(ξ) &lt; K then
Score(ξ) = −log(df(ξ)/N)
• Otherwise Score(”) = 0.0
</listItem>
<subsectionHeader confidence="0.999436">
3.2 Using a Suffix Array for Indexing
</subsectionHeader>
<bodyText confidence="0.857320363636364">
Since we have restricted the number of match-
ing strings, and all the matching strings appear in
a query, we can collect all the positions of such
strings. To make it possible, we need some index-
ing in advance. We have used a suffix array for this
index. Below we summarize our proposed algorithm
using a suffix array:
I. Make a suffix array of the document set.
II. For each query,
A. Make a set of substrings consisting of two
characters (bigram).
</bodyText>
<listItem confidence="0.902121">
B. For a given number n, extract the total n of
less frequent bigrams, calculating corpus
frequency.
C. For each bigram from step B,
i. Record all positions in which the bi-
gram appears in the query and docu-
ment set,
ii. Record all documents that contain the
bigram.
D. For each document recorded,
i. Compute the similarity between the
query and the document with SIM3,
using the recorded position of the cor-
responding bigram.
ii. Assign the similarity to the document.
</listItem>
<bodyText confidence="0.998310142857143">
E. Extract the most similar 1000 documents
from the recorded documents as a retrieval
result for the query.
We call the retrieval method described above Fast
Dynamic Programming (FDP). In general, retrieval
systems use indexes to find documents. FDP also
uses an index as a usual method. However, unlike
conventional methods, FDP requires information not
only on the document identification but also on the
position of bigrams.
Manber and Myers proposed a data structure
called “suffix array.” (Manber and Myers, 1993)
Figure 1 shows an example of suffix array. Each
suffix is expressed by one integer corresponding to
its position. We use this suffix array to find out the
position of selected bigrams. A suffix array can be
created in O(Nlog(N)) time because we need to
sort all suffixes in alphabetical order. We can get
the position of any string in O(log(N)) time by a
binary search of suffixes and by then obtaining its
corresponding position.
</bodyText>
<sectionHeader confidence="0.99897" genericHeader="method">
4 Experiment
</sectionHeader>
<bodyText confidence="0.956733333333333">
In the experiment, we compared the proposed FDP
method with SIM1, SIM2, and SIM3, which were
described in Section 2. We measured three values:
</bodyText>
<figureCaption confidence="0.99966">
Figure 1: Suffix Array
</figureCaption>
<bodyText confidence="0.998872294117647">
search effectiveness, memory usage, and execution
time.
We used the NTCIR1 collection (NTCIR Project,
1999). This collection consists of 83 retrieval topics
and roughly 330,000 documents of Japanese tech-
nical abstracts. The 83 topics include 30 training
topics (topic01-30); the rest are for testing (topic31-
83). The testing topics were more difficult than the
training topics. Each topic contains five parts, “TI-
TLE”, “DESCRIPTION”, “NARRATIVE”, “CON-
CEPT”, and “FIELD.” We retrieved using “DE-
SCRIPTION,” which is retrieval query and a short
sentence.
All the experiments reported in this section were
conducted using a dual AMD Athlon MP 1900+
with 3GB of physical memory, running TurboLinux
7.0.
</bodyText>
<subsectionHeader confidence="0.997376">
4.1 Search Effectiveness
</subsectionHeader>
<bodyText confidence="0.998974545454545">
The proposed FDP method restricts the number of
bigrams that can contribute to string matching. That
is, only a small number of strings are considered. It
was not clear whether FDP maintains its effective-
ness like SIM3. To verify it, we compared the effec-
tiveness of FDP with that of SIM1, SIM2, and SIM3.
We also needed to know how the effectiveness might
vary by the number of bigrams. We set number n
at 5, 10, 15, 20, 30, 50, and 500. They were named
FDP5, FDP10, FDP15, FDP20, FDP30, FDP50, and
FDP500, respectively.
</bodyText>
<tableCaption confidence="0.881056">
Table 1: Statistical Significant Test for difference of MAP (α = 0.005, v = 83 − 1)
</tableCaption>
<equation confidence="0.9856694">
SIM2 SIM3 FDP5 FDP10 FDP15 FDP20 FDP30 FDP50 FDP500
SIM1 &lt;&lt; &lt;&lt; &lt;&lt; &lt;&lt; &lt;&lt; &lt;&lt; &lt;&lt; &lt;&lt; &lt;&lt;
SIM2 &lt;&lt; = &lt; &lt;&lt; &lt;&lt; &lt;&lt; &lt;&lt; &lt;&lt;
SIM3 = = &lt; &lt;&lt; &lt;&lt; &lt;&lt; &lt;&lt;
FDP5 = &lt;&lt; &lt;&lt; &lt;&lt; &lt;&lt; &lt;&lt;
FDP10 = &lt;&lt; &lt; &lt; &lt;
FDP15 &lt; = = =
FDP20 = = =
FDP30 = =
FDP50 =
</equation>
<tableCaption confidence="0.653058">
Table 2: Search Effectiveness for Topic01-30 Table 3: Search Effectiveness for Topic31-83
</tableCaption>
<table confidence="0.981261">
Method 11 pt. average R-precision Method 11 pt. average R-precision
SIM1 0.1349 0.1790 SIM1 0.0545 0.0845
SIM2 0.1948 0.2296 SIM2 0.1245 0.1596
SIM3 0.2691 0.3024 SIM3 0.1807 0.2083
FDP5 0.2547 0.2649 FDP5 0.1277 0.1505
FDP10 0.2948 0.3089 FDP10 0.1766 0.2013
FDP15 0.3109 0.3446 FDP15 0.2144 0.2280
FDP20 0.3207 0.3574 FDP20 0.2398 0.2621
FDP30 0.3176 0.3421 FDP30 0.2353 0.2485
FDP50 0.3131 0.3377 FDP50 0.2354 0.2488
FDP500 0.3172 0.3419 FDP500 0.2350 0.2477
</table>
<bodyText confidence="0.999948153846154">
The NTCIR1 collection also contains a relevance
judgment. We obtained the 11-point average pre-
cision and R-precision using standard tools called
TRECEVAL. And we tested about statistical signif-
icance for difference of MAP (Mean Average Preci-
sion) (Kishida et al., 2002).
Tables 2 and 3 show the search effectiveness for
all methods. We found that FDP20 is the most ef-
fective. Table 1 shows the results of one-sided t-test
for difference of MAP ¯xi − ¯yi, where ¯xi and ¯yi are
MAP of i-th method in the first row and MAP of
i-th method in the first column, respectively. The
level of significance α is 0.005 and the degree of
freedom v is 83 − 1. The Symbols &lt;&lt;, &lt;, = rep-
resent ”much less than α”, ”less than α, and ”not
less than α”, respectively. We found that except for
FDP5 and FDP10, the other FDPs are significantly
more effective than SIM3 at a level of significance
0.005. In additional, this shows that FDP30, FDP50,
and FDP500 are not significantly more effective than
FDP20. These have demonstrated our proposed FDP
method maintains its effectiveness, even though the
strings that contribute similarity are restricted to a
small number of bigrams. Also, it is interesting that
the FDP with 20 bigrams is significantly more effec-
tive than the one with many more bigrams.
</bodyText>
<subsectionHeader confidence="0.998248">
4.2 Memory Usage
</subsectionHeader>
<bodyText confidence="0.999856714285714">
The proposed method needs to record all the posi-
tions considered bigrams. A memory area is there-
fore required to hold position information; in the
worst case, the memory size required is the prod-
uct of the number of documents and the number of
substrings in a query. This means the memory re-
quirement could be very large. However, using FDP,
we have found that the amount of memory requested
is of a reasonable size.
In other words, the size of the memory area is the
total sum of collection frequency for all strings that
contribute similarity. We examined the amount of
memory used by comparison for the total sum of col-
lection frequency.
</bodyText>
<figure confidence="0.996754666666667">
Total Collection Frequency
100000000
80000000
60000000
40000000
20000000
0
AllNgram
20sigram
Allsigram
1 6 11 16 21 26 31 36 41 46 51 56 61 66 71 76 81
Query
</figure>
<figureCaption confidence="0.966068">
Figure 2: Memory Usage (Total Number of Collection Frequency for Each String)
</figureCaption>
<figure confidence="0.684628">
Query
</figure>
<figureCaption confidence="0.992654">
Figure 3: Memory Usage for Different Number of Restricted Bigrams
</figureCaption>
<figure confidence="0.998792071428572">
1 6 11 16 21 26 31 36 41 46 51 56 61 66 71 76 81
Total Collection Frequency
4500000
4000000
3500000
3000000
2500000
2000000
1500000
1000000
500000
0
20sigram
Allsigram
</figure>
<bodyText confidence="0.983605086956522">
Figure 2 shows the total sum of collection fre-
quency for three kinds of string sets. In the fig-
ure, AllNgram is for sets of all substrings consid-
ered by SIM3, AllBigram is for sets of all bigrams,
and 20Bigram is for sets of 20 bigrams considered
by FDP20. The field surrounded by the plot line
and the horizontal axis represents the total sum of
collection frequency. As the figure shows, AllBi-
gram and 20Bigram occupy a much smaller field
than AllNgram. This means the memory require-
ment of FDP is much smaller than that of SIM3.
This result shows that FDP is possible to efficiently
perform large-scale information retrieval on a com-
puter with a reasonable amount of memory.
Figure 3 shows enlarged graphs of AllBigram and
20Bigram from Figure 2. The figure shows that
20Bigram equals AllBigram for most queries, but
not always. However, as shown in Table 2 and Ta-
ble 3, FDP20 actually has the highest precision in all
FDPs. This means that considering more bigrams is
not necessarily an advantage. Probably, by choosing
substrings with a high contribution, we manage to
get rid of noisy strings.
</bodyText>
<subsectionHeader confidence="0.995396">
4.3 Execution Time
</subsectionHeader>
<bodyText confidence="0.999986047619048">
We measured execution time under the same con-
ditions as described in Section 4.1. Notice we im-
plemented SIM1, SIM2, and SIM3 in C language.
On the other hand, FDP is implemented in Java
(JDK1.3.1.04). When we noted the time required
to make a suffix array, we found that FDP took 1.5
times as long as SIM in Figure 4. Thus, for the same
algorithm, the execution speed of Java is generally
slower than that of C language.
Figures 5 and 6 show the time taken to retrieve
for each topic01-30 and topic31-83. In the figures,
the vertical axis is the number of documents, and the
horizontal axis is the execution time. We found that
all SIMs took much longer than FDPs. This demon-
strates that our algorithm in Section 3 sharply im-
proves execution speed. Moreover, we found that
execution time did not increase exponentially even
if the candidate documents for retrieval increased;
instead, the retrieval collection becomes larger and
larger. This suggests that FDP is an effective DP
technique for large-scale information retrieval.
</bodyText>
<sectionHeader confidence="0.999968" genericHeader="evaluation">
5 Related Work
</sectionHeader>
<bodyText confidence="0.99997644">
Our proposed technique is a type of DP matching.
The most typical application of DP matching is gene
information research, because DP is effective for
gene information matching. However, this system
has a very slow processing speed.
In recent years, advances in this field of re-
search have meant that high-speed systems have
been required for gene information retrieval. A
high-speed gene information retrieval system called
BLAST was developed (Setubal and Meidanis,
2001). BLAST has achieved higher processing
speed by using heuristics that specify characteristic
gene arrangements, rather than using DP matching.
In contrast, we have managed to achieve fast match-
ing using the DP technique.
Moreover, in music information retrieval, an error
in copying a tune corresponds to a deficit (deletion)
and insertion of data. For this reason, a music search
engine has been built based on the DP technique (Hu
and Dannenberg, 2002). Since there is a great deal
of music information available these days, scalabil-
ity is also an important problem for music informa-
tion retrieval systems. Our proposed DP method is
scalable and can cope with deficits. It therefore has
potential applications in music information retrieval.
</bodyText>
<sectionHeader confidence="0.999326" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999854">
In this study, we proposed a DP matching method
for large-scale information retrieval. To improve
its efficiency, this method selects the strings that
contribute more to retrieval. This selection process
reduces the memory requirement and frequency of
memory access. We conclude that our method is
suitable for large-scale information retrieval where
approximate matching is required.
</bodyText>
<sectionHeader confidence="0.953764" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.9502275">
This work was supported in The 21st Century COE
Program ”Intelligent Human Sensing,” from the
Ministry of Education, Culture, Sports, Science, and
Technology.
</bodyText>
<sectionHeader confidence="0.997639" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9995629375">
Hal Berghel and David Roach. 1996. An extension of
Ukkonen’s enhanced dynamic programming ASM al-
gorithm. Journal ofACMTOIS, 4(1):94–106.
Kazuaki Kishida, Makoto Iwayama, and Koji Eguchi.
2002. Methodology and Pragmatics of Retrieval Ex-
periments at NTCIR Workshop. Pre-meeting Lecture
at the NTCIR-3 Workshop.
Ning Hu and Roger B. Dannenberg. 2002. Comparison
of Melodic Database Retrieval Techniques Using Sung
Queries. Proceedings ofJCDL 2002, 301–307.
Robert R. Korfhage. 1997. Information Storage and
Retrieval. WILEY COMPUTER PUBLISHING, 291—
303.
Udi Manber and Gene Myers. 1993. Suffix arrays: a
new method for on-line string searches. SIAMJournal
of Computing, 22(5):935–948.
NTCIR Project. http://research.nii.ac.jp/ntcir/.
Yasushi Ogawa and Toru Matsuda. 1997. Overlapping
statistical word indexing: A new indexing method for
Japanese text. Proceedings of SIGIR97, 226–234.
Joao Carlos Setubal and Joao Meidanis. 2001.
Introduction to Computational Molecular Biology.
BrooksCole Publishing Company.
Eiko Yamamoto, Mikio Yamamoto, Kyoji Umemura, and
Kenneth W. Church. 2000. Dynamic Prgramming:
A Method for Taking Advantage of Technical Ter-
minology in Japanese Documents. Proceedings of
IRAL2000, 125–131.
Eiko Yamamoto, Yoshiyuki Takeda, and Kyoji Umemura.
2003. An IR Similarity Measure which is Tolerant
for Morphological Variation. Journal of Natural Lan-
guage Processing, 10(1):63–80. (in Japanese).
</reference>
<figure confidence="0.998495035714286">
Making Time [sec]
10000
1000
100
10
1
10.31
7.93
23.24
17.31 23.37
SIM
FDP
50.68
81.12
57.63
151.05
108.17
272.29 354.78
185.42
263.57
561.57
391.11 541.42
698.15 856.31
788.54 1031.59
1279.31 1530.43
1512.88
5000 10000 20000 30000 50000 80000 100000 150000 200000 250000 300000 all
The Number of Documents
</figure>
<figureCaption confidence="0.996277">
Figure 4: Suffix Array Generation Time
</figureCaption>
<figure confidence="0.931014">
5000 10000 20000 30000 50000 80000 100000 150000 200000 250000 300000 all
The Number of Documents
</figure>
<figureCaption confidence="0.999347">
Figure 5: Execution Time for Topic01-30
</figureCaption>
<note confidence="0.557368">
The Number of Documents
</note>
<figureCaption confidence="0.9997">
Figure 6: Execution Time for Topic31-83
</figureCaption>
<figure confidence="0.990750533333333">
10000
Eaecusion Time [sec] 1000
100
10
1
SIM1 SIM2 SIM3 FDP5 FDP10
FDP15 FDP20 FDP30 FDP50
Eaecusion Time [sec] 1000
100
10
1
10000
SIM1 SIM2 SIM3 FDP5 FDP10
FDP15 FDP20 FDP30 FDP50
5000 10000 20000 30000 50000 80000 100000 150000 200000 250000 300000 all
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.094583">
<title confidence="0.960052">Dynamic Programming Matching for Large Scale Information Retrieval Eiko Communications Research Laboratory, Kyoto</title>
<author confidence="0.791269333333333">Masahiro Kishida Yoshinori Sumitomo Electric Information Systems Co</author>
<author confidence="0.791269333333333">Osaka Yoshiyuki Takeda Kyoji Ltd</author>
<affiliation confidence="0.974987">Toyohashi University of Technology, Aichi</affiliation>
<abstract confidence="0.956935133333333">Though dynamic programming matching can carry out approximate string matching when there may be deletions or insertions in a document, its effectiveness and efficiency are usually too poor to use it for large-scale information retrieval. In this paper, we propose a method of dynamic programming matching for information retrieval. This method is as effective as a conventional information retrieval system, even though it is capable of approximate matching. It is also as efficient as a conventional system. programming,</abstract>
<address confidence="0.421617">Corpus-based, Japanese.</address>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Hal Berghel</author>
<author>David Roach</author>
</authors>
<title>An extension of Ukkonen’s enhanced dynamic programming ASM algorithm.</title>
<date>1996</date>
<journal>Journal ofACMTOIS,</journal>
<pages>4--1</pages>
<contexts>
<context position="5844" citStr="Berghel and Roach, 1996" startWordPosition="912" endWordPosition="915">nt characters make different contributions. For example, in Japanese information retrieval, Hiragana characters are usually used for functional words and make a different contribution than Kanji characters, which are usually used for content words. Thus, it is natural to assign a different similarity weight according to the nature of the character. The below method of defining Character Weight DP Similarity adds not 1.0 but a specific weight depending on the matching character. We call this similarity SIM2. It resembles Ukkonen’s Enhanced Dynamic Programming ASM (Approximate String Matching) (Berghel and Roach, 1996). The weight is expressed by a function called Score. SIM2 is defined as follows: Definition 2.3 SIM2 Let α and Q be strings, x and y be a character, and “” be empty string. • If both strings are empty then SIM2(“”, “”) = 0.0 • If x =� y then SIM2(x, y) = 0.0 • If their first characters are the same then SIM2(xα, xQ) = MAX(SIM2(α, xQ), SIM2(xα, Q), SIM2(α, Q) + Score(x)) • Otherwise SIM2(xα, yQ) = MAX(SIM2(α, yQ), SIM2(xα, Q), SIM2(α, Q)) 2.3 String Weight DP Similarity DP procedure usually considers just a single character at a time, but since some long substrings can receive good scores, it </context>
</contexts>
<marker>Berghel, Roach, 1996</marker>
<rawString>Hal Berghel and David Roach. 1996. An extension of Ukkonen’s enhanced dynamic programming ASM algorithm. Journal ofACMTOIS, 4(1):94–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kazuaki Kishida</author>
<author>Makoto Iwayama</author>
<author>Koji Eguchi</author>
</authors>
<date>2002</date>
<booktitle>Methodology and Pragmatics of Retrieval Experiments at NTCIR Workshop. Pre-meeting Lecture at the NTCIR-3 Workshop.</booktitle>
<contexts>
<context position="14446" citStr="Kishida et al., 2002" startWordPosition="2399" endWordPosition="2402"> 0.1948 0.2296 SIM2 0.1245 0.1596 SIM3 0.2691 0.3024 SIM3 0.1807 0.2083 FDP5 0.2547 0.2649 FDP5 0.1277 0.1505 FDP10 0.2948 0.3089 FDP10 0.1766 0.2013 FDP15 0.3109 0.3446 FDP15 0.2144 0.2280 FDP20 0.3207 0.3574 FDP20 0.2398 0.2621 FDP30 0.3176 0.3421 FDP30 0.2353 0.2485 FDP50 0.3131 0.3377 FDP50 0.2354 0.2488 FDP500 0.3172 0.3419 FDP500 0.2350 0.2477 The NTCIR1 collection also contains a relevance judgment. We obtained the 11-point average precision and R-precision using standard tools called TRECEVAL. And we tested about statistical significance for difference of MAP (Mean Average Precision) (Kishida et al., 2002). Tables 2 and 3 show the search effectiveness for all methods. We found that FDP20 is the most effective. Table 1 shows the results of one-sided t-test for difference of MAP ¯xi − ¯yi, where ¯xi and ¯yi are MAP of i-th method in the first row and MAP of i-th method in the first column, respectively. The level of significance α is 0.005 and the degree of freedom v is 83 − 1. The Symbols &lt;&lt;, &lt;, = represent ”much less than α”, ”less than α, and ”not less than α”, respectively. We found that except for FDP5 and FDP10, the other FDPs are significantly more effective than SIM3 at a level of signifi</context>
</contexts>
<marker>Kishida, Iwayama, Eguchi, 2002</marker>
<rawString>Kazuaki Kishida, Makoto Iwayama, and Koji Eguchi. 2002. Methodology and Pragmatics of Retrieval Experiments at NTCIR Workshop. Pre-meeting Lecture at the NTCIR-3 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ning Hu</author>
<author>Roger B Dannenberg</author>
</authors>
<title>Comparison of Melodic Database Retrieval Techniques Using Sung Queries.</title>
<date>2002</date>
<booktitle>Proceedings ofJCDL 2002,</booktitle>
<pages>301--307</pages>
<contexts>
<context position="19682" citStr="Hu and Dannenberg, 2002" startWordPosition="3299" endWordPosition="3302">gh-speed systems have been required for gene information retrieval. A high-speed gene information retrieval system called BLAST was developed (Setubal and Meidanis, 2001). BLAST has achieved higher processing speed by using heuristics that specify characteristic gene arrangements, rather than using DP matching. In contrast, we have managed to achieve fast matching using the DP technique. Moreover, in music information retrieval, an error in copying a tune corresponds to a deficit (deletion) and insertion of data. For this reason, a music search engine has been built based on the DP technique (Hu and Dannenberg, 2002). Since there is a great deal of music information available these days, scalability is also an important problem for music information retrieval systems. Our proposed DP method is scalable and can cope with deficits. It therefore has potential applications in music information retrieval. 6 Conclusion In this study, we proposed a DP matching method for large-scale information retrieval. To improve its efficiency, this method selects the strings that contribute more to retrieval. This selection process reduces the memory requirement and frequency of memory access. We conclude that our method is</context>
</contexts>
<marker>Hu, Dannenberg, 2002</marker>
<rawString>Ning Hu and Roger B. Dannenberg. 2002. Comparison of Melodic Database Retrieval Techniques Using Sung Queries. Proceedings ofJCDL 2002, 301–307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert R Korfhage</author>
</authors>
<date>1997</date>
<journal>Information Storage and Retrieval. WILEY COMPUTER PUBLISHING,</journal>
<volume>291</volume>
<pages>303</pages>
<contexts>
<context position="3534" citStr="Korfhage, 1997" startWordPosition="517" endWordPosition="518">oposed method is not only more efficient but also more effective. 2 Similarities Based on Dynamic Programming Matching In this section, we introduce several similarities proposed by (Yamamoto et al., 2000; Yamamoto, Takeda, and Umemura, 2003). All of them are a form of dynamic programming matching. These similarities include translation of the edit distance. This distance has been described by several authors. We have adopted Korfhage’s definition: ‘the edit distance is the minimum number of edit operations, such as insertion and deletion, which are required to map one string into the other’ (Korfhage, 1997). There are three related similarities. The first is dynamic programming matching, which is simply conversion of the edit distance. The second similarity is an extension of the first similarity, introducing a character weighting for each contributing character. The third and proposed similarity is an extension of the second one, using string weight instead of character weight. 2.1 Dynamic Programming Matching As stated above, dynamic programming (DP) matching is a conversion of edit distance. We call this similarity SIM1. While the edit distance (ED) is a measure of difference, counting differ</context>
</contexts>
<marker>Korfhage, 1997</marker>
<rawString>Robert R. Korfhage. 1997. Information Storage and Retrieval. WILEY COMPUTER PUBLISHING, 291— 303.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Udi Manber</author>
<author>Gene Myers</author>
</authors>
<title>Suffix arrays: a new method for on-line string searches.</title>
<date>1993</date>
<journal>SIAMJournal of Computing,</journal>
<volume>22</volume>
<issue>5</issue>
<note>NTCIR Project. http://research.nii.ac.jp/ntcir/.</note>
<contexts>
<context position="11466" citStr="Manber and Myers, 1993" startWordPosition="1888" endWordPosition="1891">IM3, using the recorded position of the corresponding bigram. ii. Assign the similarity to the document. E. Extract the most similar 1000 documents from the recorded documents as a retrieval result for the query. We call the retrieval method described above Fast Dynamic Programming (FDP). In general, retrieval systems use indexes to find documents. FDP also uses an index as a usual method. However, unlike conventional methods, FDP requires information not only on the document identification but also on the position of bigrams. Manber and Myers proposed a data structure called “suffix array.” (Manber and Myers, 1993) Figure 1 shows an example of suffix array. Each suffix is expressed by one integer corresponding to its position. We use this suffix array to find out the position of selected bigrams. A suffix array can be created in O(Nlog(N)) time because we need to sort all suffixes in alphabetical order. We can get the position of any string in O(log(N)) time by a binary search of suffixes and by then obtaining its corresponding position. 4 Experiment In the experiment, we compared the proposed FDP method with SIM1, SIM2, and SIM3, which were described in Section 2. We measured three values: Figure 1: Su</context>
</contexts>
<marker>Manber, Myers, 1993</marker>
<rawString>Udi Manber and Gene Myers. 1993. Suffix arrays: a new method for on-line string searches. SIAMJournal of Computing, 22(5):935–948. NTCIR Project. http://research.nii.ac.jp/ntcir/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yasushi Ogawa</author>
<author>Toru Matsuda</author>
</authors>
<title>Overlapping statistical word indexing: A new indexing method for Japanese text.</title>
<date>1997</date>
<booktitle>Proceedings of SIGIR97,</booktitle>
<pages>226--234</pages>
<contexts>
<context position="9603" citStr="Ogawa and Matsuda, 1997" startWordPosition="1564" endWordPosition="1567">ighting function so that it keeps its effectiveness while improving efficiency. To achieve this improvement, we use the SIM3 with the same definition but with a different score function. 3.1 Proposed String Weighting We reduce the computational cost by limiting strings that have positive scores. First, we select bigrams as such strings. In other words, we assign a score of zero if the length of the string does not equal to 2. Several language systems use Kanji characters (e.g. Chinese and Japanese), and bigram is an effective indexing unit for information retrieval for these language systems (Ogawa and Matsuda, 1997). In addition, we may assume that the contribution of a longer string is approximated by the total bigram weighting. We have also restricted our attention to infrequent bigrams. Thus, we have restricted the weighting function Score as follows, where K is the number decided by the given query. • If string length is 2 and cf(ξ) &lt; K then Score(ξ) = −log(df(ξ)/N) • Otherwise Score(”) = 0.0 3.2 Using a Suffix Array for Indexing Since we have restricted the number of matching strings, and all the matching strings appear in a query, we can collect all the positions of such strings. To make it possibl</context>
</contexts>
<marker>Ogawa, Matsuda, 1997</marker>
<rawString>Yasushi Ogawa and Toru Matsuda. 1997. Overlapping statistical word indexing: A new indexing method for Japanese text. Proceedings of SIGIR97, 226–234.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joao Carlos</author>
</authors>
<title>Setubal and Joao Meidanis.</title>
<date>2001</date>
<publisher>BrooksCole Publishing Company.</publisher>
<marker>Carlos, 2001</marker>
<rawString>Joao Carlos Setubal and Joao Meidanis. 2001. Introduction to Computational Molecular Biology. BrooksCole Publishing Company.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eiko Yamamoto</author>
<author>Mikio Yamamoto</author>
<author>Kyoji Umemura</author>
<author>Kenneth W Church</author>
</authors>
<title>Dynamic Prgramming: A Method for Taking Advantage of Technical Terminology in Japanese Documents.</title>
<date>2000</date>
<booktitle>Proceedings of IRAL2000,</booktitle>
<pages>125--131</pages>
<contexts>
<context position="1791" citStr="Yamamoto et al., 2000" startWordPosition="241" endWordPosition="244"> programming matching can measure the similarity between documents, even if there are partial deletions or insertions. However, there are two problems in applying this method to information retrieval. One problem is search effectiveness. It is poor because dynamic programming matching lacks an adequate weighting schema. The second problem is computational efficiency. Also, lack of an adequate indexing schema means that dynamic programming matching usually has to process the entire document. Yamamoto et al. proposed a method of dynamic programming matching with acceptable search effectiveness (Yamamoto et al., 2000; Yamamoto, Takeda, and Umemura, 2003). They report that the effectiveness of dynamic programming matching improves by introducing an IDF (Inverse Document Frequency) weighting schema for all strings that contribute similarity. They calculate matching weights not only for words but also for all strings. Although they report that effectiveness is improved, the speed of their method is slower than that of conventional dynamic programming matching, and much slower than that of a typical information retrieval system. In this paper, we aim to improve the retrieval efficiency of the dynamic programm</context>
<context position="3123" citStr="Yamamoto et al., 2000" startWordPosition="452" endWordPosition="455">definition of the weighting. The mathematical structure of similarity remains the same as that of the dynamic programming method proposed by (Yamamoto et al., 2000; Yamamoto, Takeda, and Umemura, 2003). Although it has the same definition, the new weighting method makes it possible to build a more efficient information retrieval system by creating the index in advance. To our surprise, we have observed that our proposed method is not only more efficient but also more effective. 2 Similarities Based on Dynamic Programming Matching In this section, we introduce several similarities proposed by (Yamamoto et al., 2000; Yamamoto, Takeda, and Umemura, 2003). All of them are a form of dynamic programming matching. These similarities include translation of the edit distance. This distance has been described by several authors. We have adopted Korfhage’s definition: ‘the edit distance is the minimum number of edit operations, such as insertion and deletion, which are required to map one string into the other’ (Korfhage, 1997). There are three related similarities. The first is dynamic programming matching, which is simply conversion of the edit distance. The second similarity is an extension of the first simila</context>
</contexts>
<marker>Yamamoto, Yamamoto, Umemura, Church, 2000</marker>
<rawString>Eiko Yamamoto, Mikio Yamamoto, Kyoji Umemura, and Kenneth W. Church. 2000. Dynamic Prgramming: A Method for Taking Advantage of Technical Terminology in Japanese Documents. Proceedings of IRAL2000, 125–131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eiko Yamamoto</author>
<author>Yoshiyuki Takeda</author>
<author>Kyoji Umemura</author>
</authors>
<title>An IR Similarity Measure which is Tolerant for Morphological Variation.</title>
<date>2003</date>
<journal>Journal of Natural Language Processing,</journal>
<volume>10</volume>
<issue>1</issue>
<note>(in Japanese).</note>
<contexts>
<context position="1828" citStr="Yamamoto, Takeda, and Umemura, 2003" startWordPosition="245" endWordPosition="249">an measure the similarity between documents, even if there are partial deletions or insertions. However, there are two problems in applying this method to information retrieval. One problem is search effectiveness. It is poor because dynamic programming matching lacks an adequate weighting schema. The second problem is computational efficiency. Also, lack of an adequate indexing schema means that dynamic programming matching usually has to process the entire document. Yamamoto et al. proposed a method of dynamic programming matching with acceptable search effectiveness (Yamamoto et al., 2000; Yamamoto, Takeda, and Umemura, 2003). They report that the effectiveness of dynamic programming matching improves by introducing an IDF (Inverse Document Frequency) weighting schema for all strings that contribute similarity. They calculate matching weights not only for words but also for all strings. Although they report that effectiveness is improved, the speed of their method is slower than that of conventional dynamic programming matching, and much slower than that of a typical information retrieval system. In this paper, we aim to improve the retrieval efficiency of the dynamic programming method while keeping its search e</context>
<context position="3160" citStr="Yamamoto, Takeda, and Umemura, 2003" startWordPosition="456" endWordPosition="460">ting. The mathematical structure of similarity remains the same as that of the dynamic programming method proposed by (Yamamoto et al., 2000; Yamamoto, Takeda, and Umemura, 2003). Although it has the same definition, the new weighting method makes it possible to build a more efficient information retrieval system by creating the index in advance. To our surprise, we have observed that our proposed method is not only more efficient but also more effective. 2 Similarities Based on Dynamic Programming Matching In this section, we introduce several similarities proposed by (Yamamoto et al., 2000; Yamamoto, Takeda, and Umemura, 2003). All of them are a form of dynamic programming matching. These similarities include translation of the edit distance. This distance has been described by several authors. We have adopted Korfhage’s definition: ‘the edit distance is the minimum number of edit operations, such as insertion and deletion, which are required to map one string into the other’ (Korfhage, 1997). There are three related similarities. The first is dynamic programming matching, which is simply conversion of the edit distance. The second similarity is an extension of the first similarity, introducing a character weighti</context>
</contexts>
<marker>Yamamoto, Takeda, Umemura, 2003</marker>
<rawString>Eiko Yamamoto, Yoshiyuki Takeda, and Kyoji Umemura. 2003. An IR Similarity Measure which is Tolerant for Morphological Variation. Journal of Natural Language Processing, 10(1):63–80. (in Japanese).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>