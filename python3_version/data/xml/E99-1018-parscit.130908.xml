<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.824918">
Proceedings of EACL &apos;99
</note>
<title confidence="0.842352">
POS Disambiguation and Unknown Word Guessing with
Decision Trees
Giorgos S. Orphanos
</title>
<author confidence="0.588397">
Computer Engineering &amp; Informatics Dept.
</author>
<affiliation confidence="0.903969333333333">
and Computer Technology Institute
University of Patras
26500 Rion, Patras, Greece
</affiliation>
<email confidence="0.930686">
georfan@cti.gr
</email>
<author confidence="0.534305">
Dimitris N. Christodoulakis
</author>
<affiliation confidence="0.80038975">
Computer Engineering &amp; Informatics Dept.
and Computer Technology Institute
University of Patras
26500 Rion, Patras, Greece
</affiliation>
<email confidence="0.959088">
dxri@cti.gx
</email>
<sectionHeader confidence="0.995217" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999813333333333">
This paper presents a decision-tree
approach to the problems of part-of-
speech disambiguation and unknown
word guessing as they appear in Modem
Greek, a highly inflectional language. The
learning procedure is tag-set independent
and reflects the linguistic reasoning on the
specific problems. The decision trees
induced are combined with a high-
coverage lexicon to form a tagger that
achieves 93,5% overall disambiguation
accuracy.
</bodyText>
<sectionHeader confidence="0.998985" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999918370370371">
Part-of-speech (POS) taggers are software
devices that aim to assign unambiguous
morphosyntactic tags to words of electronic
texts. Although the hardest part of the tagging
process is performed by a computational
lexicon, a POS tagger cannot solely consist of a
lexicon due to: (i) morphosyntactic ambiguity
(e.g., &apos;love&apos; as verb or noun) and (ii) the
existence of unknown words (e.g., proper nouns,
place names, compounds, etc.). When the
lexicon can assure high coverage, unknown
word guessing can be viewed as a decision taken
upon the POS of open-class words (i.e., Noun,
Verb, Adjective, Adverb or Participle).
Towards the disambiguation of POS tags,
two main approaches have been followed. On
one hand, according to the linguistic approach,
experts encode handcrafted rules or constraints
based on abstractions derived from language
paradigms (usually with the aid of corpora)
(Green and Rubin, 1971; Voutilainen 1995). On
the other hand, according to the data-driven
approach, a frequency-based language model is
acquired from corpora and has the forms of n-
grams (Church, 1988; Cutting et al., 1992), rules
(Hindle, 1989; Brill, 1995), decision trees
(Cardie, 1994; Daelemans et al., 1996) or neural
networks (Schmid, 1994).
In order to increase their robustness, most
POS taggers include a guesser, which tries to
extract the POS of words not present in the
lexicon. As a common strategy, POS guessers
examine the endings of unknown words (Cutting
et al. 1992) along with their capitalization, or
consider the distribution of unknown words over
specific parts-of-speech (Weischedel et al.,
1993). More sophisticated guessers further
examine the prefixes of unknown words
(Mikheev, 1996) and the categories of
contextual tokens (Brill, 1995; Daelemans et al.,
1996).
This paper presents a POS tagger for Modern
Greek (M. Greek), a highly inflectional
language, and focuses on a data-driven approach
for the induction of decision trees used as
disambiguation/guessing devices. Based on a
high-coverage&apos; lexicon, we prepared a tagged
corpus capable of showing off the behavior of
all POS ambiguity schemes present in M. Greek
(e.g., Pronoun-Clitic-Article, Pronoun-Clitic,
Adjective-Adverb, Verb-Noun, etc.), as well as
the characteristics of unknown words.
Consequently, we used the corpus for the
induction of decision trees, which, along with
</bodyText>
<footnote confidence="0.969633">
At present, the lexicon is capable of assigning full
morphosyntactic attributes (i.e., POS, Number,
Gender, Case, Person, Tense, Voice, Mood) to
—870.000 Greek word-forms.
</footnote>
<page confidence="0.987461">
134
</page>
<note confidence="0.525857">
Proceedings of EACL &apos;99
</note>
<bodyText confidence="0.999506333333333">
the lexicon, are integrated into a robust POS
tagger for M. Greek texts.
The disambiguating methodology followed is
highly influenced by the Memory-Based Tagger
(MBT) presented in (Daelemans et al., 1996).
Our main contribution is the successful
application of the decision-tree methodology to
M. Greek with three improvements/custom-
izations: (i) injection of linguistic bias to the
learning procedure, (ii) formation of tag-set
independent training patterns, and (iii) handling
of set-valued features.
</bodyText>
<sectionHeader confidence="0.947711" genericHeader="method">
2 Tagger Architecture
</sectionHeader>
<figureCaption confidence="0.8725505">
Figure 1 illustrates the functional components of
the tagger and the order of processing:
</figureCaption>
<figure confidence="0.9562925">
Raw Text
Tagged Text words with one tag
</figure>
<figureCaption confidence="0.999874">
Figure 1. Tagger Architecture
</figureCaption>
<bodyText confidence="0.999872777777778">
Raw text passes through the Tokenizer, where it
is converted to a stream of tokens. Non-word
tokens (e.g., punctuation marks, numbers, dates,
etc.) are resolved by the Tokenizer and receive a
tag corresponding to their category. Word tokens
are looked-up in the Lexicon and those found
receive one or more tags. Words with more than
one tags and those not found in the Lexicon pass
through the Disambiguator/Guesser, where the
contextually appropriate tag is decided/guessed.
The Disambiguator/Guesser is a &apos;forest&apos; of
decision trees, one tree for each ambiguity
scheme present in M. Greek and one tree for
unknown word guessing. When a word with two
or more tags appears, its ambiguity scheme is
identified. Then, the corresponding decision tree
is selected, which is traversed according to the
values of morphosyntactic features extracted
from contextual tags. This traversal returns the
contextually appropriate POS. The ambiguity is
resolved by eliminating the tag(s) with different
POS than the one returned by the decision tree.
The POS of an unknown word is guessed by
traversing the decision tree for unknown words,
which examines contextual features along with
the word ending and capitalization and returns
an open-class POS.
</bodyText>
<sectionHeader confidence="0.973281" genericHeader="method">
3 Training Sets
</sectionHeader>
<bodyText confidence="0.993652875">
For the study and resolution of lexical ambiguity
in M. Greek, we set up a corpus of 137.765
tokens (7.624 sentences), collecting sentences
from student writings, literature, newspapers,
and technical, financial and sports magazines.
We made sure to adequately cover all POS
ambiguity schemes present in M. Greek, without
showing preference to any scheme, so as to have
an objective view to the problem. Subsequently,
we tokenized the corpus and inserted it into a
database and let the lexicon assign a
morphosyntactic tag to each word-token. We did
not use any specific tag-set; instead, we let the
lexicon assign to each known word all
morphosyntactic attributes available. Table 1
shows a sample sentence after this initial tagging
(symbolic names appearing in the tags are
explained in Appendix A).
words
with
more
than
one
gs
</bodyText>
<tableCaption confidence="0.999693">
Table 1. An example-sentence from the tagged corpus
</tableCaption>
<table confidence="0.973744454545455">
Sentence Token Token Aufoniatie Tag (aisigned thelexicon) Manual,
,
2638 1 Ot The Art (MscFemSg1Nom)
2638 2 cumarnjactg answers Vrb ( i_sg1ActPstsjv + _s_sglActFutrnd) +
Nnn( j&apos;emPlrNomAccVoc)
2638 3 TOD of Prn( — C— MscNtrSngGen) + Cit + Art (MscNtrSngGen) Art
2638 4 K. Mr. Abr
2638 5 rIana&amp;ntoukoo Papadopoulos &amp;quot;nu&amp;quot; Cap Nnn + Vrb + Adj + Pcp + Adv Nnn
2638 6 itrav were Vrb(_C_SgliirIcInd)
2638 7 acupcic clear Adj (MscFemPlrNomAccVoc)
2638 8
</table>
<page confidence="0.857672">
135
</page>
<tableCaption confidence="0.6793745">
Proceedings of EACL &apos;99
Table 2. A fragment from the training set Verb-Noun
</tableCaption>
<equation confidence="0.86448375">
Example
agl+1
1 Adj(FemSg1NomAcc)
Adj(FemSg1NomAcc)
Nnn + Vrb + Adj +
+ Adv
Prn(_A_SglGenAcc)
Pps
5 Art(FemPlrAcc)
Pc1
Pc1
Adj(FemSg1NomAcc)
10 Pcl + Adv
yrb( B_Sg1PntActImv) +
Nnn(iemSg1NomAccVoc)
Vrb( C_Sg1PntFcsActIndSjv) +
Nnn(iemSg1NomAccVoc)
Pcp Vrb(_B_Sg1FutPstActIndSjv) +
Nnn(FemPlrNomAccVoc)
+ Vrb( B_Sg1FutPstActIndSjv) +
nn
N(RtrSg1P1rNomGenAccVoc)
Vrb( B_SglFutPstActIndSjv) +
Nnn(iemPlrNomAccVoc)
yrb(Ji Sg1PntFcsFutPstActIndSjv)
Nnn(RscSg1Nom)
Vrb(_B_Sg1FutPstActIndSjv) +
Nnn(FemPlrNomAccVoc)
yrb( B_Sg1FutPstActIndSjv) +
Nnn(RtrSg1P1rNomGenAccVoc)
1.1
Vtb( C_Sg1PntFcsActIndSjv) +
Nnn(iemSg1NomAccVoc)
Vrb(_B_Sg1PntFcsFutPstActInasjv)
4 Nnn(MscSg1Nom)
Vrb •
Vrb
Prn( C_FemSglGen) + Cit +
Art(iemSglGen)
Nnn(NtrSg1NomAccVoc)
;nn
Adj(FemSg1NomAccVoc) Vrb
Prn( C MscNtrSglGen) + at! Nnn
+ Ari-(RscNtrSglGen)
Prn(_A_SglGenAcc) + pps Vrb
Vrb(_C_PlrPntFcsActIndSjv)l
Art(MscSglAcc +
OtrSg1NomAcc)
</equation>
<bodyText confidence="0.999596714285714">
To words with POS ambiguity (e.g., tokens #2
and #3 in Table 1) we manually assigned their
contextually appropriate POS. To unknown
words (e.g., token #5 in Table 1), which by
default received a disjunct of open-class POS
labels, we manually assigned their real POS and
declared explicitly their inflectional ending.
At a next phase, for all words relative to a
specific ambiguity scheme or for all unknown
words, we collected from the tagged corpus their
automatically and manually assigned tags along
with the automatically assigned tags of their
neighboring tokens. This way, we created a
training set for each ambiguity scheme and a
training set for unknown words. Table 2 shows a
10-example fragment from the training set for
the ambiguity scheme Verb-Noun. For reasons
of space, Table 2 shows the tags of only the
previous (column Tagi_l) and next (column
Tagi4.1) tokens in the neighborhood of an
ambiguous word, whereas more contextual tags
actually comprise a training example. A training
example also includes the manually assigned tag
(column Manual Tagi) along with the
automatically assigned tag2 (column Tagi) of the
ambiguous word. One can notice that some
contextual tags are missing (e.g., Tagi_i of
Example 7; the ambiguous word is the first in
the sentence), or some contextual tags may
exhibit POS ambiguity (e.g., Tagi+i of Example
1), an incident implying that the learner must
learn from incomplete/ambiguous examples,
since this is the case in real texts.
If we consider that a tag encodes 1 to 5
morphosyntactic features, each feature taking
one or a disjunction of 2 to 11 values, then the
total number of different tags counts up to
several hundreds&apos;. This fact prohibits the feeding
of the training algorithms with patterns that have
the form: (ragi, Tagi_b Tagi, Manual_Tagi),
which is the case for similar systems that learn
POS disambiguation (e.g., Daelemans et al.,
1996). On the other hand, it would be inefficient
(yielding to information loss) to generate a
simplified tag-set in order to reduce its size. The
&apos;what the training patterns should look like&apos;
bottleneck was surpassed by assuming a set of
functions that extract from a tag the value(s) of
specific features, e.g.:
</bodyText>
<equation confidence="0.7046465">
Gender(Art (mscSglAcc + NtrSg1NomAcc) ) =
Msc + Ntr
</equation>
<bodyText confidence="0.998376">
With the help of these functions, the training
examples shown in Table 2 are interpreted to
patterns that look like:
</bodyText>
<footnote confidence="0.67635875">
(POS(Tag1_2), POS(Tagi_1), Gender(Tagi), POS(Tag1+1),
Gender(Tag1+1), Manual_Tag,),
2 In case the learner needs to use morphosyntactic 3 The words of the corpus received from the lexicon
information of the word being disambiguated. 690 different tags having the form shown in Table 2.
</footnote>
<page confidence="0.995809">
136
</page>
<bodyText confidence="0.990062608695652">
Proceedings of EACL &apos;99
that is, a sequence of feature-values extracted
from the previous/current/next tags along with
the manually assigned POS label.
Due to this transformation, two issues
automatically arise: (a) A feature-extracting
function may return more than one feature value
(as in the Gender(...) example); consequently,
the training algorithm should be capable of
handling set-valued features. (b) A feature-
extracting function may return no value, e.g.
Gender(vrb (_C_PlrPntActIndSj v) ) = None,
thus we added an extra value —the value None—
to each feature.
To summarize, the training material we
prepared consists of: (a) a set of training
examples for each ambiguity scheme and a set
of training examples for unknown words&apos;, and
(b) a set of features accompanying each
example-set, denoting which features (extracted
from the tags of training examples) will
participate in the training procedure. This
configuration offers the following advantages:
</bodyText>
<listItem confidence="0.986185333333333">
1. A training set is examined only for the
features that are relative to the
corresponding ambiguity scheme, thus
addressing its idiosyncratic needs.
2. What features are included to each feature-
set depends on the linguistic reasoning on
the specific ambiguity scheme, introducing
this way linguistic bias to the learner.
3. The learning is tag-set independent, since it
is based on specific features and not on the
entire tags.
4. The learning of a particular ambiguity
</listItem>
<bodyText confidence="0.66057875">
scheme can be fine-tuned by including new
features or excluding existing features from
its feature-set, without affecting the learning
of the other ambiguity schemes.
</bodyText>
<sectionHeader confidence="0.997806" genericHeader="method">
4 Decision Trees
</sectionHeader>
<subsectionHeader confidence="0.982727">
4.1 Tree Induction
</subsectionHeader>
<bodyText confidence="0.9976965">
In the previous section, we stated the use of
linguistic reasoning for the selection of feature-
</bodyText>
<note confidence="0.308332">
4 e.g.: Gender = (Masculine, Feminine, Neuter, None).
</note>
<footnote confidence="0.609371">
5 The training examples for unknown words, except
contextual tags, also include the capitalization feature
and the suffixes of unknown words.
</footnote>
<bodyText confidence="0.99943548">
sets suitable to the idiosyncratic properties of the
corresponding ambiguity schemes.
Formally speaking, let FS be the feature-set
attached to a training set TS. The algorithm used
to transform TS into a decision tree belongs to
the TDIDT (Top Down Induction of Decision
Trees) family (Quinlan, 1986). Based on the
divide and conquer principle, it selects the best
Fbest feature from FS, partitions TS according to
the values of Fb„t and repeats the procedure for
each partition excluding Fbest from FS,
continuing recursively until all (or the majority
of) examples in a partition belong to the same
class C or no more features are left in FS.
During each step, in order to find the feature
that makes the best prediction of class labels and
use it to partition the training set, we select the
feature with the highest gain ratio, an
information-based quantity introduced by
Quinlan (1986). The gain ratio metric is
computed as follows:
Assume a training set TS with patterns
belonging to one of the classes C1, C2, .. • Ck•
The average information needed to identify the
class of a pattern in TS is:
</bodyText>
<equation confidence="0.983807666666667">
E freq(Cj, TS) freq(Cj, TS)
info(TS) = x log2 (
j.i ITS ITSI
</equation>
<bodyText confidence="0.994155">
Now consider that TS is partitioned into TS1,
TS2, ... TS., according to the values of a feature
F from FS. The average information needed to
identify the class of a pattern in the partitioned
TS is:
</bodyText>
<equation confidence="0.828803">
TS; I
x info(TSi )
info F (TS) =i1
I TS I
split info(F)
</equation>
<bodyText confidence="0.997066">
Split info is a necessary normalizing factor, since
gain favors features with many values, and
represents the potential information generated by
dividing TS into n subsets:
</bodyText>
<equation confidence="0.996201166666667">
I TS •
split info(F)=_tT L x log 2 k--)
, I \
i =1 I TS I I TS I
The quantity:
gain(F) = info(TS) - info F (TS)
</equation>
<bodyText confidence="0.9979285">
measures the information relevant to
classification that is gained by partitioning TS
in accordance with the feature F. Gain ratio is a
normalized version of information gain:
</bodyText>
<equation confidence="0.7484885">
gain(F)
gain ratio(F) =
</equation>
<page confidence="0.871588">
137
</page>
<bodyText confidence="0.973146384615385">
Proceedings of EACL &apos;99
Taking into consideration the formula that
computes the gain ratio, we notice that the best
feature is the one that presents the minimum
entropy in predicting the class labels of the
training set, provided the information of the
feature is not split over its values.
The recursive algorithm for the decision tree
induction is shown in Figure 2. Its parameters
are: a node N, a training set TS and a feature set
FS. Each node constructed, in a top-down left-
to-right fashion, contains a default class label C
(which characterizes the path constructed so
far) and if it is a non-terminal node it also
contains a feature F from FS according to
which further branching takes place. Every
value v; of the feature F tested at a non-terminal
node is accompanied by a pattern subset TS;
(i.e., the subset of patterns containing the value
v;). If two or more values of F are found in a
training pattern (set-valued feature), the training
pattern is directed to all corresponding
branches. The algorithm is initialized with a
root node, the entire training set and the entire
feature set. The root node contains a dummy6
feature and a blank class label.
</bodyText>
<figure confidence="0.996362958333333">
InduceTree( Node N , TrainingSet IS, FeatureSet FS)
Begin
For each value v, of the feature F tested by node N Do
Begin
Create the subset TS; and assign it to vi;
If TS; is empty Then continue; /* goto For./
If all patterns in TS; belong to the same class C Then
Create under v; a leaf node N&apos; with label C;
Else
Begin
Find the most frequent class C in TS;;
If FS is empty Then
Create under v; a leaf node N&apos; with label C;
Else
Begin
Find the feature F&apos; with the highest gain ratio;
Create under v; a non-terminal node N&apos; with
label C and set N&apos; to test F&apos;;
Create the feature subset FS&apos; = FS —
InduceTree( N&apos; TS; , FS&apos;);
End
End
End
End
</figure>
<figureCaption confidence="0.999919">
Figure 2. Tree-Induction Algorithm
</figureCaption>
<page confidence="0.632227">
6 The dummy feature contains the sole value None.
</page>
<subsectionHeader confidence="0.986362">
4.2 Tree Traversal
</subsectionHeader>
<bodyText confidence="0.999542">
Each tree node, as already mentioned, contains a
class label that represents the &apos;decision&apos; being
made by the specific node. Moreover, when a
node is not a leaf, it also contains an ordered list
of values corresponding to a particular feature
tested by the node. Each value is the origin of a
subtree hanging under the non-terminal node.
The tree is traversed from the root to the leaves.
Each non-terminal node tests one after the other
its feature-values over the testing pattern. When
a value is found, the traversal continues through
the subtree hanging under that value. If none of
the values is found or the current node is a leaf,
the traversal is finished and the node&apos;s class
label is returned. For the needs of the POS
disambiguation/guessing problem, tree nodes
contain POS labels and test morphosyntactic
features. Figure 3 illustrates the tree-traversal
algorithm, via which disambiguation/guessing is
performed. The lexical and/or contextual
features of an ambiguous/unknown word
constitute a testing pattern, which, along with
the root of the decision tree corresponding to the
specific ambiguity scheme, are passed to the
tree-traversal algorithm.
</bodyText>
<figure confidence="0.892865545454546">
ClassLabel TraverseTree( Node N , TestingPattem P)
Begin
If N is a non-terminal node Then
For each value vi of the feature F tested by N Do
If I/1 is the value of F in P Then
Begin
N&apos; = the node hanging under vi;
Return TraverseTree( N&apos; , P );
End
Return the class label of N;
End
</figure>
<figureCaption confidence="0.997791">
Figure 3. Tree-Traversal Algorithm
</figureCaption>
<subsectionHeader confidence="0.947152">
4.3 Subtree Ordering
</subsectionHeader>
<bodyText confidence="0.9998614">
The tree-traversal algorithm of Figure 3 can be
directly implemented by representing the
decision tree as nested if-statements (see
Appendix B), where each block of code
following an if-statement corresponds to a
subtree. When an if-statement succeeds, the
control is transferred to the inner block and,
since there is no backtracking, no other feature-
values of the same level are tested. To classify a
pattern with a set-valued feature, only one value
</bodyText>
<page confidence="0.9944">
138
</page>
<bodyText confidence="0.93921075">
Proceedings of EACL &apos;99
from the set steers the traversal; the value that is
tested first. A fair policy suggests to test first the
most important (probable) value, or,
equivalently, to test first the value that leads to
the subtree that gathered more training patterns
than sibling subtrees. This policy can be
incarnated in the tree-traversal algorithm if we
previously sort the list of feature-values tested
by each non-terminal node, according to the
algorithm of Figure 4, which is initialized with
the root of the tree.
</bodyText>
<figure confidence="0.994317">
OrderSubtrees( Node N)
Begin
If N is a non-terminal node Then
Begin
Sort the feature-values and sub-trees of node N
according to the number of training patterns each
sub-tree obtained;
For each child node N&apos; under node N Do
OrderSubtrees( N&apos;);
End
End
</figure>
<figureCaption confidence="0.999844">
Figure 4. Subtree-Ordering Algorithm
</figureCaption>
<bodyText confidence="0.99984">
This ordering has a nice side-effect: it
increases the classification speed, as the most
probable paths are ranked first in the decision
tree.
</bodyText>
<subsectionHeader confidence="0.997764">
4.4 Tree Compaction
</subsectionHeader>
<bodyText confidence="0.9995467">
A tree induced by the algorithm of Figure 2 may
contain many redundant paths from root to
leaves; paths where, from a node and forward,
the same decision is made. The tree-traversal
definitely speeds up by eliminating the tails of
the paths that do not alter the decisions taken
thus far. This compaction does not affect the
performance of the decision tree. Figure 5
illustrates the tree-compaction algorithm, which
is initialized with the root of the tree.
</bodyText>
<figure confidence="0.997979944444444">
CompactTree( Node N)
Begin
For each child node N&apos; under node N Do
Begin
If N&apos; is a leaf node Then
Begin
If N&apos; has the same class label with N Then
Delete N&apos;;
End
Else
Begin
CompactTree( N&apos;);
If N&apos; is now a leaf node And
has the same class label with N Then
Delete N&apos;;
End
End
End
</figure>
<figureCaption confidence="0.999821">
Figure 5. Tree-Compaction Algorithm
</figureCaption>
<tableCaption confidence="0.994858">
Table 3. Statistics and Evaluation Measurements
</tableCaption>
<table confidence="0.999872782608695">
(1) (2) (3) %erioi -
% occurrence % contribution • %error decisiOn trees
in the carpus to POS most frequent
ambiguity POS
POS Ambiguity Schemes
Pronoun-Article 7,13 34,19 14,5 1,96
Pronoun-Article-Clitic 4,70 22,54 39,1 4,85
Pronoun-Preposition 2,14 10,26 12,2 1,35
Adjective-Adverb 1,53 7,33 31,1 13,4
Pronoun-Clitic 1,41 6,76 38,0 5,78
Preposition-Particle-Conjunction 1,024,8920,8 8,94
_ ,
Verb-Noun 0,52 _ 2,49_ 12,1 6,93
Adjective-Adverb-Noun 0,51_ 2,44 51,0 30,4
Adjective-Noun 0,46_ 2,20 38,2 18,2
Particle-Conjunction 0,39_ 1,87 1,38 1,38
Adverb-Conjunction 0,36 1,72 22,8 18,1
Pronoun-Adverb 0,34. 1,63 4,31 4,31
Verb-Adverb 0,06 0,28 16,8 1,99
Other 0,29 1,39 30,1 12,3
Total POS Ambiguity 20,85 24,1 5,48
Unknown Words 2,53 38,6 15,8
Totals 23,38 25,6 6,61
</table>
<page confidence="0.903705">
139
</page>
<note confidence="0.475484">
Proceedings of EACL &apos;99
</note>
<sectionHeader confidence="0.983063" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.99987532">
To evaluate our approach, we first partitioned
the datasets described in Section 3 into training
and testing sets according to the 10-fold cross-
validation method7. Then, (a) we found the most
frequent POS in each training set and (b) we
induced a decision tree from each training set.
Consequently, we resolved the ambiguity of the
testing sets with two methods: (a) we assigned
the most frequent POS acquired from the
corresponding training sets and (b) we used the
induced decision trees.
Table 3 concentrates the results of our
experiments. In detail: Column (1) shows in
what percentage the ambiguity schemes and the
unknown words occur in the corpus. The total
problematic word-tokens in the corpus are
23,38%. Column (2) shows in what percentage
each ambiguity scheme contributes to the total
POS ambiguity. Column (3) shows the error
rates of method (a). Column (4) shows the error
rates of method (b).
To compute the total POS disambiguation
error rates of the two methods (24,1% and
5,48% respectively) we used the contribution
percentages shown in column (2).
</bodyText>
<sectionHeader confidence="0.99875" genericHeader="conclusions">
6 Discussion and Future Goals
</sectionHeader>
<bodyText confidence="0.970994395833333">
We have shown a uniform approach to the dual
problem of POS disambiguation and unknown
word guessing as it appears in M. Greek,
reinforcing the argument that &amp;quot;machine-learning
researchers should become more interested in
NLP as an application area&amp;quot; (Daelemans et al.,
1997). As a general remark, we argue that the
linguistic approach has good performance when
the knowledge or the behavior of a language can
be defined explicitly (by means of lexicons,
syntactic grammars, etc.), whereas empirical
(corpus-based statistical) learning should apply
when exceptions, complex interaction or
ambiguity arise. In addition, there is always the
opportunity to bias empirical learning with
linguistically motivated parameters, so as to
7 In this method, a dataset is partitioned 10 times into
90% training material and 10% testing material.
Average accuracy provides a reliable estimate of the
generalization accuracy.
meet the needs of the specific language problem.
Based on these statements, we combined a high-
coverage lexicon and a set of empirically
induced decision trees into a POS tagger
achieving —5,5% error rate for POS
disambiguation and —16% error rate for
unknown word guessing.
The decision-tree approach outperforms both
the naive approach of assigning the most
frequent POS, as well as the —20% error rate
obtained by the n-gram tagger for M. Greek
presented in (Dermatas and Koldcinalcis, 1995).
Comparing our tree-induction algorithm and
IGTREE, the algorithm used in MBT
(Daelemans et al., 1996), their main difference
is that IGTREE produces oblivious decision
trees by supplying an a priori ordered list of best
features instead of re-computing the best feature
during each branching, which is our case. After
applying IGTREE to the datasets described in
Section 3, we measured similar performance
(-7% error rate for disambiguation and —17%
for guessing). Intuitively, the global search for
best features performed by IGTREE has similar
results to the local searches over the fragmented
datasets performed by our algorithm.
Our goals hereafter aim to cover the
following:
</bodyText>
<listItem confidence="0.969179">
• Improve the POS tagging results by: a)
finding the optimal feature set for each
ambiguity scheme and b) increasing the
lexicon coverage.
• Analyze why IGTREE is still so robust
when, obviously, it is built on less
information.
• Apply the same approach to resolve Gender,
Case, Number, etc. ambiguity and to guess
such attributes for unknown words.
</listItem>
<sectionHeader confidence="0.997977" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9914038">
Brill E. (1995). Transformation-Based Error-Driven
Learning and Natural Language Processing: A
Case Study in Part of Speech Tagging.
Computational Linguistics, 21(4), 543-565.
Cardie C. (1994). Domain-Specific Knowledge
Acquisition for Conceptual Sentence Analysis.
Ph.D. Thesis, University of Massachusetts,
Amherst, MA.
Church K. (1988). A Stochastic parts program and
noun phrase parser for unrestricted text. In
</reference>
<page confidence="0.989069">
140
</page>
<reference confidence="0.990835214953271">
Proceedings of EACL &apos;99
Proceedings of 2nd Conference on Applied Natural
Language Processing, Austin, Texas.
Cutting D., Kupiec J., Pederson J. and Sibun P.
(1992). A practical part-of-speech tagger. In
Proceedings of 3rd Conference on Applied Natural
Language Processing, Trento, Italy.
Daelemans W., Zavrel J., Berck P. and Gillis S.
(1996). MBT: A memory-based part of speech
tagger generator. In Proceedings of 4th Workshop
on Very Large Corpora, ACL SIGDAT, 14-27.
Daelemans W., Van den Bosch A. and Weijters A.
(1997). Empirical Learning of Natural Language
Processing Tasks. In W. Daelemans, A. Van den
Bosch, and A. Weijters (eds.) Workshop Notes of
the ECML/Mlnet Workshop on Empirical Learning
of Natural Language Processing Tasks, Prague, 1-
10.
Dermatas E. and Koldcinalds G. (1995). Automatic
Stochastic Tagging of Natural Language Texts.
Computational Linguistics, 21(2), 137-163.
Greene B. and Rubin G. (1971). Automated
grammatical tagging of English. Department of
Linguistics, Brown University.
Hindle D. (1989). Acquiring disambiguation rules
from text. In Proceedings of ACL &apos;89.
Quinlan J. R. (1986). Induction of Decision Trees.
Machine Learning, 1, 81-106.
Milcheev A. (1996). Learning Part-of-Speech
Guessing Rules from Lexicon: Extension to Non-
Concatenative Operations. In Proceedings of
COLING &apos;96.
Schmid H. (1994) Part-of-speech tagging with neural
networks. In Proceedings of COLING &apos;94.
Voutilainen A. (1995). A syntax-based part-of-speech
analyser. In Proceedings of EA CL &apos;95.
Weischedel R., Meteer M., Schwartz R., Ramshaw L.
and Pahnucci J. (1993). Coping with ambiguity and
unknown words through probabilistic models.
Computational Linguistics, 19(2), 359-382.
Appendix A: Feature Values/Shortcuts
Part-Of-Speech = (Article/Art, Noun/Nnn, Adjective/Adj,
Pronoun/Pm, VerbNrb, Participle/Pcp, Adverb/Adv,
Conjunction/Cnj, Preposition/Pps, Particle/Pd, Clitic/Clt)
Number = {Singular/Sng, Plural/Plu}
Gender = {Masculine/Msc, Feminine/Fern, Neuter/Ntr}
Case = {Nominative/Nom, Genitive/Gen, Dative/Dat,
Accusative/Acc, Vocative/Voc}
Person = {First/_A_, Second/_B_, Third/_C_}
Tense = {Present/Pnt, Future/Fut, Future Perfect/Fpt, Future
Continuous/Fcs, Past/Pst, Present Perfect/Pnp, Past
Perfect/Psp}
Voice = {Active/Act, Passive/Psv}
Mood = {Indicative/Ind, Imperative/Imv, Subjanctive/Sjv}
Capitalization = {Capital/Cap}
Appendix B: A decision tree for the
scheme Adverb-Adjective
&apos;disamb_AdvAdj.c. file, automatically generated from a
training corpus */
#include &amp;quot;../tagger/tagger.h&amp;quot;
int disamb AdvAdj(void *TL) r TL means &apos;Token List&apos; */
if(POS(TL, -1, Vrb)) r-1: previous token */
if(POS(TL, 1, Nnn)) return Adj; r+1: next token */
else return Adv;
else if(POS(TL, -1, Pm))
if(POS(TL, 1, None)) return Adv;
else if(POS(TL, 1, Pps)) return Adv;
else if(POS(TL, 1, Pcp)) retum Adv;
else return Adj;
else if(POS(TL, -1, Art)) return Adj;
else if(POS(TL, -1, None))
if(POS(TL, 1, Nnn)) return Adj;
else return Adv;
else if(POS(TL, -1, Cnj))
if(POS(TL, 1, Nnn)) return Adj;
else return Adv;
else if(POS(TL, -1, Adv))
if(POS(TL, 1, Nnn)) return Adj;
else if(POS(TL, 1, Adv)) return Adj;
else return Adv;
else if(POS(TL, -1, Adj))
if(POS(TL, 1, Cnj)) return Adv;
else if(POS(TL, 1, Pcp)) return Adv;
else return Adj;
else if(POS(TL, -1, Nnn))
if(POS(TL, 1, Nnn)) return Adj;
else if(POS(TL, 1, Exc)) return Adj;
else return Adv;
else if(POS(TL, -1, Pps))
if(POS(TL, 1, Pm)) return Adv;
else if(POS(TL, 1, None)) return Adv;
else if(POS(TL, 1, Art)) return Adv;
else if(POS(TL, 1, Pd)) return Adv;
else if(POS(TL, 1, Clt)) return Adv;
else if(POS(TL, 1, Vrb)) return Adv;
else if(POS(TL, 1, Pps)) return Adv;
else if(POS(TL, 1, Pcp)) return Adv;
else return Adj;
else if(POS(TL, -1, PO)
if(POS(TL, 1, Nnn)) return Adj;
else if(POS(TL, 1, Adj)) return Adj;
else return Adv;
else if(POS(TL, -1, Pcp))
if(POS(TL, 1, Nnn)) return Adj;
else if(POS(TL, 1, Vrb)) return Adj;
else return Adv;
else return Adv;
</reference>
<page confidence="0.998252">
141
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.509225">
<note confidence="0.720169">Proceedings of EACL &apos;99</note>
<title confidence="0.997647">POS Disambiguation and Unknown Word Guessing with Decision Trees</title>
<author confidence="0.999509">Giorgos S Orphanos</author>
<affiliation confidence="0.999336333333333">Computer Engineering &amp; Informatics Dept. and Computer Technology Institute University of Patras</affiliation>
<address confidence="0.999959">26500 Rion, Patras, Greece</address>
<email confidence="0.991544">georfan@cti.gr</email>
<author confidence="0.789878">Dimitris N Christodoulakis</author>
<affiliation confidence="0.998867666666667">Computer Engineering &amp; Informatics Dept. and Computer Technology Institute University of Patras</affiliation>
<address confidence="0.99997">26500 Rion, Patras, Greece</address>
<email confidence="0.99305">dxri@cti.gx</email>
<abstract confidence="0.993693153846154">This paper presents a decision-tree approach to the problems of part-ofspeech disambiguation and unknown word guessing as they appear in Modem Greek, a highly inflectional language. The learning procedure is tag-set independent and reflects the linguistic reasoning on the specific problems. The decision trees induced are combined with a highcoverage lexicon to form a tagger that achieves 93,5% overall disambiguation accuracy.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>Transformation-Based Error-Driven Learning and Natural Language Processing: A Case Study in Part of Speech Tagging.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>4</issue>
<pages>543--565</pages>
<contexts>
<context position="2005" citStr="Brill, 1995" startWordPosition="293" endWordPosition="294"> upon the POS of open-class words (i.e., Noun, Verb, Adjective, Adverb or Participle). Towards the disambiguation of POS tags, two main approaches have been followed. On one hand, according to the linguistic approach, experts encode handcrafted rules or constraints based on abstractions derived from language paradigms (usually with the aid of corpora) (Green and Rubin, 1971; Voutilainen 1995). On the other hand, according to the data-driven approach, a frequency-based language model is acquired from corpora and has the forms of ngrams (Church, 1988; Cutting et al., 1992), rules (Hindle, 1989; Brill, 1995), decision trees (Cardie, 1994; Daelemans et al., 1996) or neural networks (Schmid, 1994). In order to increase their robustness, most POS taggers include a guesser, which tries to extract the POS of words not present in the lexicon. As a common strategy, POS guessers examine the endings of unknown words (Cutting et al. 1992) along with their capitalization, or consider the distribution of unknown words over specific parts-of-speech (Weischedel et al., 1993). More sophisticated guessers further examine the prefixes of unknown words (Mikheev, 1996) and the categories of contextual tokens (Brill</context>
</contexts>
<marker>Brill, 1995</marker>
<rawString>Brill E. (1995). Transformation-Based Error-Driven Learning and Natural Language Processing: A Case Study in Part of Speech Tagging. Computational Linguistics, 21(4), 543-565.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Cardie</author>
</authors>
<title>Domain-Specific Knowledge Acquisition for Conceptual Sentence Analysis.</title>
<date>1994</date>
<tech>Ph.D. Thesis,</tech>
<institution>University of Massachusetts,</institution>
<location>Amherst, MA.</location>
<contexts>
<context position="2035" citStr="Cardie, 1994" startWordPosition="297" endWordPosition="298">rds (i.e., Noun, Verb, Adjective, Adverb or Participle). Towards the disambiguation of POS tags, two main approaches have been followed. On one hand, according to the linguistic approach, experts encode handcrafted rules or constraints based on abstractions derived from language paradigms (usually with the aid of corpora) (Green and Rubin, 1971; Voutilainen 1995). On the other hand, according to the data-driven approach, a frequency-based language model is acquired from corpora and has the forms of ngrams (Church, 1988; Cutting et al., 1992), rules (Hindle, 1989; Brill, 1995), decision trees (Cardie, 1994; Daelemans et al., 1996) or neural networks (Schmid, 1994). In order to increase their robustness, most POS taggers include a guesser, which tries to extract the POS of words not present in the lexicon. As a common strategy, POS guessers examine the endings of unknown words (Cutting et al. 1992) along with their capitalization, or consider the distribution of unknown words over specific parts-of-speech (Weischedel et al., 1993). More sophisticated guessers further examine the prefixes of unknown words (Mikheev, 1996) and the categories of contextual tokens (Brill, 1995; Daelemans et al., 1996</context>
</contexts>
<marker>Cardie, 1994</marker>
<rawString>Cardie C. (1994). Domain-Specific Knowledge Acquisition for Conceptual Sentence Analysis. Ph.D. Thesis, University of Massachusetts, Amherst, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Church</author>
</authors>
<title>A Stochastic parts program and noun phrase parser for unrestricted text.</title>
<date>1988</date>
<booktitle>In Proceedings of EACL &apos;99 Proceedings of 2nd Conference on Applied Natural Language Processing,</booktitle>
<location>Austin, Texas.</location>
<contexts>
<context position="1947" citStr="Church, 1988" startWordPosition="284" endWordPosition="285">e, unknown word guessing can be viewed as a decision taken upon the POS of open-class words (i.e., Noun, Verb, Adjective, Adverb or Participle). Towards the disambiguation of POS tags, two main approaches have been followed. On one hand, according to the linguistic approach, experts encode handcrafted rules or constraints based on abstractions derived from language paradigms (usually with the aid of corpora) (Green and Rubin, 1971; Voutilainen 1995). On the other hand, according to the data-driven approach, a frequency-based language model is acquired from corpora and has the forms of ngrams (Church, 1988; Cutting et al., 1992), rules (Hindle, 1989; Brill, 1995), decision trees (Cardie, 1994; Daelemans et al., 1996) or neural networks (Schmid, 1994). In order to increase their robustness, most POS taggers include a guesser, which tries to extract the POS of words not present in the lexicon. As a common strategy, POS guessers examine the endings of unknown words (Cutting et al. 1992) along with their capitalization, or consider the distribution of unknown words over specific parts-of-speech (Weischedel et al., 1993). More sophisticated guessers further examine the prefixes of unknown words (Mik</context>
</contexts>
<marker>Church, 1988</marker>
<rawString>Church K. (1988). A Stochastic parts program and noun phrase parser for unrestricted text. In Proceedings of EACL &apos;99 Proceedings of 2nd Conference on Applied Natural Language Processing, Austin, Texas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Cutting</author>
<author>J Kupiec</author>
<author>J Pederson</author>
<author>P Sibun</author>
</authors>
<title>A practical part-of-speech tagger.</title>
<date>1992</date>
<booktitle>In Proceedings of 3rd Conference on Applied Natural Language Processing,</booktitle>
<location>Trento, Italy.</location>
<contexts>
<context position="1970" citStr="Cutting et al., 1992" startWordPosition="286" endWordPosition="289">d guessing can be viewed as a decision taken upon the POS of open-class words (i.e., Noun, Verb, Adjective, Adverb or Participle). Towards the disambiguation of POS tags, two main approaches have been followed. On one hand, according to the linguistic approach, experts encode handcrafted rules or constraints based on abstractions derived from language paradigms (usually with the aid of corpora) (Green and Rubin, 1971; Voutilainen 1995). On the other hand, according to the data-driven approach, a frequency-based language model is acquired from corpora and has the forms of ngrams (Church, 1988; Cutting et al., 1992), rules (Hindle, 1989; Brill, 1995), decision trees (Cardie, 1994; Daelemans et al., 1996) or neural networks (Schmid, 1994). In order to increase their robustness, most POS taggers include a guesser, which tries to extract the POS of words not present in the lexicon. As a common strategy, POS guessers examine the endings of unknown words (Cutting et al. 1992) along with their capitalization, or consider the distribution of unknown words over specific parts-of-speech (Weischedel et al., 1993). More sophisticated guessers further examine the prefixes of unknown words (Mikheev, 1996) and the cat</context>
</contexts>
<marker>Cutting, Kupiec, Pederson, Sibun, 1992</marker>
<rawString>Cutting D., Kupiec J., Pederson J. and Sibun P. (1992). A practical part-of-speech tagger. In Proceedings of 3rd Conference on Applied Natural Language Processing, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Daelemans</author>
<author>J Zavrel</author>
<author>P Berck</author>
<author>S Gillis</author>
</authors>
<title>MBT: A memory-based part of speech tagger generator.</title>
<date>1996</date>
<booktitle>In Proceedings of 4th Workshop on Very Large Corpora, ACL SIGDAT,</booktitle>
<pages>14--27</pages>
<contexts>
<context position="2060" citStr="Daelemans et al., 1996" startWordPosition="299" endWordPosition="302">n, Verb, Adjective, Adverb or Participle). Towards the disambiguation of POS tags, two main approaches have been followed. On one hand, according to the linguistic approach, experts encode handcrafted rules or constraints based on abstractions derived from language paradigms (usually with the aid of corpora) (Green and Rubin, 1971; Voutilainen 1995). On the other hand, according to the data-driven approach, a frequency-based language model is acquired from corpora and has the forms of ngrams (Church, 1988; Cutting et al., 1992), rules (Hindle, 1989; Brill, 1995), decision trees (Cardie, 1994; Daelemans et al., 1996) or neural networks (Schmid, 1994). In order to increase their robustness, most POS taggers include a guesser, which tries to extract the POS of words not present in the lexicon. As a common strategy, POS guessers examine the endings of unknown words (Cutting et al. 1992) along with their capitalization, or consider the distribution of unknown words over specific parts-of-speech (Weischedel et al., 1993). More sophisticated guessers further examine the prefixes of unknown words (Mikheev, 1996) and the categories of contextual tokens (Brill, 1995; Daelemans et al., 1996). This paper presents a </context>
<context position="3619" citStr="Daelemans et al., 1996" startWordPosition="531" endWordPosition="534">e.g., Pronoun-Clitic-Article, Pronoun-Clitic, Adjective-Adverb, Verb-Noun, etc.), as well as the characteristics of unknown words. Consequently, we used the corpus for the induction of decision trees, which, along with At present, the lexicon is capable of assigning full morphosyntactic attributes (i.e., POS, Number, Gender, Case, Person, Tense, Voice, Mood) to —870.000 Greek word-forms. 134 Proceedings of EACL &apos;99 the lexicon, are integrated into a robust POS tagger for M. Greek texts. The disambiguating methodology followed is highly influenced by the Memory-Based Tagger (MBT) presented in (Daelemans et al., 1996). Our main contribution is the successful application of the decision-tree methodology to M. Greek with three improvements/customizations: (i) injection of linguistic bias to the learning procedure, (ii) formation of tag-set independent training patterns, and (iii) handling of set-valued features. 2 Tagger Architecture Figure 1 illustrates the functional components of the tagger and the order of processing: Raw Text Tagged Text words with one tag Figure 1. Tagger Architecture Raw text passes through the Tokenizer, where it is converted to a stream of tokens. Non-word tokens (e.g., punctuation </context>
<context position="9573" citStr="Daelemans et al., 1996" startWordPosition="1430" endWordPosition="1433">some contextual tags may exhibit POS ambiguity (e.g., Tagi+i of Example 1), an incident implying that the learner must learn from incomplete/ambiguous examples, since this is the case in real texts. If we consider that a tag encodes 1 to 5 morphosyntactic features, each feature taking one or a disjunction of 2 to 11 values, then the total number of different tags counts up to several hundreds&apos;. This fact prohibits the feeding of the training algorithms with patterns that have the form: (ragi, Tagi_b Tagi, Manual_Tagi), which is the case for similar systems that learn POS disambiguation (e.g., Daelemans et al., 1996). On the other hand, it would be inefficient (yielding to information loss) to generate a simplified tag-set in order to reduce its size. The &apos;what the training patterns should look like&apos; bottleneck was surpassed by assuming a set of functions that extract from a tag the value(s) of specific features, e.g.: Gender(Art (mscSglAcc + NtrSg1NomAcc) ) = Msc + Ntr With the help of these functions, the training examples shown in Table 2 are interpreted to patterns that look like: (POS(Tag1_2), POS(Tagi_1), Gender(Tagi), POS(Tag1+1), Gender(Tag1+1), Manual_Tag,), 2 In case the learner needs to use mor</context>
<context position="23259" citStr="Daelemans et al., 1996" startWordPosition="3695" endWordPosition="3698">e generalization accuracy. meet the needs of the specific language problem. Based on these statements, we combined a highcoverage lexicon and a set of empirically induced decision trees into a POS tagger achieving —5,5% error rate for POS disambiguation and —16% error rate for unknown word guessing. The decision-tree approach outperforms both the naive approach of assigning the most frequent POS, as well as the —20% error rate obtained by the n-gram tagger for M. Greek presented in (Dermatas and Koldcinalcis, 1995). Comparing our tree-induction algorithm and IGTREE, the algorithm used in MBT (Daelemans et al., 1996), their main difference is that IGTREE produces oblivious decision trees by supplying an a priori ordered list of best features instead of re-computing the best feature during each branching, which is our case. After applying IGTREE to the datasets described in Section 3, we measured similar performance (-7% error rate for disambiguation and —17% for guessing). Intuitively, the global search for best features performed by IGTREE has similar results to the local searches over the fragmented datasets performed by our algorithm. Our goals hereafter aim to cover the following: • Improve the POS ta</context>
</contexts>
<marker>Daelemans, Zavrel, Berck, Gillis, 1996</marker>
<rawString>Daelemans W., Zavrel J., Berck P. and Gillis S. (1996). MBT: A memory-based part of speech tagger generator. In Proceedings of 4th Workshop on Very Large Corpora, ACL SIGDAT, 14-27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Daelemans</author>
<author>A Van den Bosch</author>
<author>A Weijters</author>
</authors>
<title>Empirical Learning of Natural Language Processing Tasks.</title>
<date>1997</date>
<booktitle>Workshop Notes of the ECML/Mlnet Workshop on Empirical Learning of Natural Language Processing Tasks, Prague,</booktitle>
<pages>1--10</pages>
<editor>In W. Daelemans, A. Van den Bosch, and A. Weijters (eds.)</editor>
<marker>Daelemans, Van den Bosch, Weijters, 1997</marker>
<rawString>Daelemans W., Van den Bosch A. and Weijters A. (1997). Empirical Learning of Natural Language Processing Tasks. In W. Daelemans, A. Van den Bosch, and A. Weijters (eds.) Workshop Notes of the ECML/Mlnet Workshop on Empirical Learning of Natural Language Processing Tasks, Prague, 1-10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Dermatas</author>
<author>G Koldcinalds</author>
</authors>
<title>Automatic Stochastic Tagging of Natural Language Texts.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>2</issue>
<pages>137--163</pages>
<marker>Dermatas, Koldcinalds, 1995</marker>
<rawString>Dermatas E. and Koldcinalds G. (1995). Automatic Stochastic Tagging of Natural Language Texts. Computational Linguistics, 21(2), 137-163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Greene</author>
<author>G Rubin</author>
</authors>
<title>Automated grammatical tagging of English.</title>
<date>1971</date>
<institution>Department of Linguistics, Brown University.</institution>
<marker>Greene, Rubin, 1971</marker>
<rawString>Greene B. and Rubin G. (1971). Automated grammatical tagging of English. Department of Linguistics, Brown University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hindle</author>
</authors>
<title>Acquiring disambiguation rules from text.</title>
<date>1989</date>
<booktitle>In Proceedings of ACL &apos;89.</booktitle>
<contexts>
<context position="1991" citStr="Hindle, 1989" startWordPosition="291" endWordPosition="292">decision taken upon the POS of open-class words (i.e., Noun, Verb, Adjective, Adverb or Participle). Towards the disambiguation of POS tags, two main approaches have been followed. On one hand, according to the linguistic approach, experts encode handcrafted rules or constraints based on abstractions derived from language paradigms (usually with the aid of corpora) (Green and Rubin, 1971; Voutilainen 1995). On the other hand, according to the data-driven approach, a frequency-based language model is acquired from corpora and has the forms of ngrams (Church, 1988; Cutting et al., 1992), rules (Hindle, 1989; Brill, 1995), decision trees (Cardie, 1994; Daelemans et al., 1996) or neural networks (Schmid, 1994). In order to increase their robustness, most POS taggers include a guesser, which tries to extract the POS of words not present in the lexicon. As a common strategy, POS guessers examine the endings of unknown words (Cutting et al. 1992) along with their capitalization, or consider the distribution of unknown words over specific parts-of-speech (Weischedel et al., 1993). More sophisticated guessers further examine the prefixes of unknown words (Mikheev, 1996) and the categories of contextual</context>
</contexts>
<marker>Hindle, 1989</marker>
<rawString>Hindle D. (1989). Acquiring disambiguation rules from text. In Proceedings of ACL &apos;89.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Quinlan</author>
</authors>
<title>Induction of Decision Trees.</title>
<date>1986</date>
<booktitle>Machine Learning,</booktitle>
<volume>1</volume>
<pages>81--106</pages>
<contexts>
<context position="12569" citStr="Quinlan, 1986" startWordPosition="1896" endWordPosition="1897">ees 4.1 Tree Induction In the previous section, we stated the use of linguistic reasoning for the selection of feature4 e.g.: Gender = (Masculine, Feminine, Neuter, None). 5 The training examples for unknown words, except contextual tags, also include the capitalization feature and the suffixes of unknown words. sets suitable to the idiosyncratic properties of the corresponding ambiguity schemes. Formally speaking, let FS be the feature-set attached to a training set TS. The algorithm used to transform TS into a decision tree belongs to the TDIDT (Top Down Induction of Decision Trees) family (Quinlan, 1986). Based on the divide and conquer principle, it selects the best Fbest feature from FS, partitions TS according to the values of Fb„t and repeats the procedure for each partition excluding Fbest from FS, continuing recursively until all (or the majority of) examples in a partition belong to the same class C or no more features are left in FS. During each step, in order to find the feature that makes the best prediction of class labels and use it to partition the training set, we select the feature with the highest gain ratio, an information-based quantity introduced by Quinlan (1986). The gain</context>
</contexts>
<marker>Quinlan, 1986</marker>
<rawString>Quinlan J. R. (1986). Induction of Decision Trees. Machine Learning, 1, 81-106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Milcheev</author>
</authors>
<title>Learning Part-of-Speech Guessing Rules from Lexicon: Extension to NonConcatenative Operations.</title>
<date>1996</date>
<booktitle>In Proceedings of COLING &apos;96.</booktitle>
<marker>Milcheev, 1996</marker>
<rawString>Milcheev A. (1996). Learning Part-of-Speech Guessing Rules from Lexicon: Extension to NonConcatenative Operations. In Proceedings of COLING &apos;96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schmid</author>
</authors>
<title>Part-of-speech tagging with neural networks.</title>
<date>1994</date>
<booktitle>In Proceedings of COLING &apos;94.</booktitle>
<contexts>
<context position="2094" citStr="Schmid, 1994" startWordPosition="306" endWordPosition="307">owards the disambiguation of POS tags, two main approaches have been followed. On one hand, according to the linguistic approach, experts encode handcrafted rules or constraints based on abstractions derived from language paradigms (usually with the aid of corpora) (Green and Rubin, 1971; Voutilainen 1995). On the other hand, according to the data-driven approach, a frequency-based language model is acquired from corpora and has the forms of ngrams (Church, 1988; Cutting et al., 1992), rules (Hindle, 1989; Brill, 1995), decision trees (Cardie, 1994; Daelemans et al., 1996) or neural networks (Schmid, 1994). In order to increase their robustness, most POS taggers include a guesser, which tries to extract the POS of words not present in the lexicon. As a common strategy, POS guessers examine the endings of unknown words (Cutting et al. 1992) along with their capitalization, or consider the distribution of unknown words over specific parts-of-speech (Weischedel et al., 1993). More sophisticated guessers further examine the prefixes of unknown words (Mikheev, 1996) and the categories of contextual tokens (Brill, 1995; Daelemans et al., 1996). This paper presents a POS tagger for Modern Greek (M. Gr</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Schmid H. (1994) Part-of-speech tagging with neural networks. In Proceedings of COLING &apos;94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Voutilainen</author>
</authors>
<title>A syntax-based part-of-speech analyser.</title>
<date>1995</date>
<booktitle>In Proceedings of EA CL &apos;95.</booktitle>
<contexts>
<context position="1788" citStr="Voutilainen 1995" startWordPosition="258" endWordPosition="259"> (e.g., &apos;love&apos; as verb or noun) and (ii) the existence of unknown words (e.g., proper nouns, place names, compounds, etc.). When the lexicon can assure high coverage, unknown word guessing can be viewed as a decision taken upon the POS of open-class words (i.e., Noun, Verb, Adjective, Adverb or Participle). Towards the disambiguation of POS tags, two main approaches have been followed. On one hand, according to the linguistic approach, experts encode handcrafted rules or constraints based on abstractions derived from language paradigms (usually with the aid of corpora) (Green and Rubin, 1971; Voutilainen 1995). On the other hand, according to the data-driven approach, a frequency-based language model is acquired from corpora and has the forms of ngrams (Church, 1988; Cutting et al., 1992), rules (Hindle, 1989; Brill, 1995), decision trees (Cardie, 1994; Daelemans et al., 1996) or neural networks (Schmid, 1994). In order to increase their robustness, most POS taggers include a guesser, which tries to extract the POS of words not present in the lexicon. As a common strategy, POS guessers examine the endings of unknown words (Cutting et al. 1992) along with their capitalization, or consider the distri</context>
</contexts>
<marker>Voutilainen, 1995</marker>
<rawString>Voutilainen A. (1995). A syntax-based part-of-speech analyser. In Proceedings of EA CL &apos;95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Weischedel</author>
<author>M Meteer</author>
<author>R Schwartz</author>
<author>L Ramshaw</author>
<author>J Pahnucci</author>
</authors>
<title>Coping with ambiguity and unknown words through probabilistic models.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<pages>359--382</pages>
<contexts>
<context position="2467" citStr="Weischedel et al., 1993" startWordPosition="363" endWordPosition="366">ach, a frequency-based language model is acquired from corpora and has the forms of ngrams (Church, 1988; Cutting et al., 1992), rules (Hindle, 1989; Brill, 1995), decision trees (Cardie, 1994; Daelemans et al., 1996) or neural networks (Schmid, 1994). In order to increase their robustness, most POS taggers include a guesser, which tries to extract the POS of words not present in the lexicon. As a common strategy, POS guessers examine the endings of unknown words (Cutting et al. 1992) along with their capitalization, or consider the distribution of unknown words over specific parts-of-speech (Weischedel et al., 1993). More sophisticated guessers further examine the prefixes of unknown words (Mikheev, 1996) and the categories of contextual tokens (Brill, 1995; Daelemans et al., 1996). This paper presents a POS tagger for Modern Greek (M. Greek), a highly inflectional language, and focuses on a data-driven approach for the induction of decision trees used as disambiguation/guessing devices. Based on a high-coverage&apos; lexicon, we prepared a tagged corpus capable of showing off the behavior of all POS ambiguity schemes present in M. Greek (e.g., Pronoun-Clitic-Article, Pronoun-Clitic, Adjective-Adverb, Verb-No</context>
</contexts>
<marker>Weischedel, Meteer, Schwartz, Ramshaw, Pahnucci, 1993</marker>
<rawString>Weischedel R., Meteer M., Schwartz R., Ramshaw L. and Pahnucci J. (1993). Coping with ambiguity and unknown words through probabilistic models. Computational Linguistics, 19(2), 359-382.</rawString>
</citation>
<citation valid="false">
<authors>
<author>A Appendix</author>
</authors>
<title>Feature Values/Shortcuts Part-Of-Speech =</title>
<journal>(Article/Art, Noun/Nnn, Adjective/Adj, Pronoun/Pm, VerbNrb, Participle/Pcp, Adverb/Adv, Conjunction/Cnj, Preposition/Pps, Particle/Pd, Clitic/Clt) Number = {Singular/Sng, Plural/Plu}</journal>
<marker>Appendix, </marker>
<rawString>Appendix A: Feature Values/Shortcuts Part-Of-Speech = (Article/Art, Noun/Nnn, Adjective/Adj, Pronoun/Pm, VerbNrb, Participle/Pcp, Adverb/Adv, Conjunction/Cnj, Preposition/Pps, Particle/Pd, Clitic/Clt) Number = {Singular/Sng, Plural/Plu}</rawString>
</citation>
<citation valid="false">
<authors>
<author>Gender MasculineMsc</author>
<author>FeminineFern</author>
</authors>
<journal>Neuter/Ntr} Case = {Nominative/Nom, Genitive/Gen, Dative/Dat, Accusative/Acc, Vocative/Voc} Person = {First/_A_, Second/_B_, Third/_C_}</journal>
<marker>MasculineMsc, FeminineFern, </marker>
<rawString>Gender = {Masculine/Msc, Feminine/Fern, Neuter/Ntr} Case = {Nominative/Nom, Genitive/Gen, Dative/Dat, Accusative/Acc, Vocative/Voc} Person = {First/_A_, Second/_B_, Third/_C_}</rawString>
</citation>
<citation valid="false">
<authors>
<author>Tense PresentPnt</author>
<author>FutureFut</author>
</authors>
<title>Future Perfect/Fpt, Future Continuous/Fcs,</title>
<tech>Past/Pst, Present Perfect/Pnp, Past Perfect/Psp</tech>
<marker>PresentPnt, FutureFut, </marker>
<rawString>Tense = {Present/Pnt, Future/Fut, Future Perfect/Fpt, Future Continuous/Fcs, Past/Pst, Present Perfect/Pnp, Past Perfect/Psp}</rawString>
</citation>
<citation valid="false">
<authors>
<author>Voice ActiveAct</author>
</authors>
<journal>Passive/Psv} Mood = {Indicative/Ind, Imperative/Imv, Subjanctive/Sjv} Capitalization = {Capital/Cap}</journal>
<marker>ActiveAct, </marker>
<rawString>Voice = {Active/Act, Passive/Psv} Mood = {Indicative/Ind, Imperative/Imv, Subjanctive/Sjv} Capitalization = {Capital/Cap}</rawString>
</citation>
<citation valid="false">
<authors>
<author>B Appendix</author>
</authors>
<title>A decision tree for the scheme Adverb-Adjective &apos;disamb_AdvAdj.c. file, automatically generated from a training corpus */ #include &amp;quot;../tagger/tagger.h&amp;quot; int disamb AdvAdj(void *TL) r TL means &apos;Token List&apos; */ if(POS(TL, -1, Vrb)) r-1: previous token */ if(POS(TL, 1, Nnn)) return Adj; r+1: next token */ else return Adv; else if(POS(TL, -1, Pm)) if(POS(TL, 1, None)) return Adv; else if(POS(TL, 1, Pps)) return Adv; else if(POS(TL, 1, Pcp)) retum Adv; else return Adj; else if(POS(TL, -1, Art)) return Adj; else if(POS(TL, -1, None)) if(POS(TL, 1, Nnn)) return Adj; else return Adv; else if(POS(TL, -1, Cnj)) if(POS(TL, 1, Nnn)) return Adj; else return Adv; else if(POS(TL, -1, Adv)) if(POS(TL, 1, Nnn)) return Adj; else if(POS(TL, 1, Adv)) return Adj; else return Adv; else if(POS(TL, -1,</title>
<booktitle>Adj)) if(POS(TL, 1, Cnj)) return Adv; else if(POS(TL, 1, Pcp)) return Adv; else return Adj; else if(POS(TL, -1, Nnn)) if(POS(TL, 1, Nnn)) return Adj; else if(POS(TL, 1, Exc)) return Adj; else return Adv; else if(POS(TL, -1, Pps)) if(POS(TL, 1, Pm)) return Adv; else if(POS(TL, 1, None)) return Adv; else if(POS(TL, 1, Art)) return Adv; else if(POS(TL, 1, Pd)) return Adv; else if(POS(TL, 1, Clt)) return Adv; else if(POS(TL, 1, Vrb)) return Adv; else if(POS(TL, 1, Pps)) return Adv; else if(POS(TL, 1, Pcp)) return Adv; else return Adj; else if(POS(TL, -1, PO) if(POS(TL,</booktitle>
<volume>1</volume>
<marker>Appendix, </marker>
<rawString>Appendix B: A decision tree for the scheme Adverb-Adjective &apos;disamb_AdvAdj.c. file, automatically generated from a training corpus */ #include &amp;quot;../tagger/tagger.h&amp;quot; int disamb AdvAdj(void *TL) r TL means &apos;Token List&apos; */ if(POS(TL, -1, Vrb)) r-1: previous token */ if(POS(TL, 1, Nnn)) return Adj; r+1: next token */ else return Adv; else if(POS(TL, -1, Pm)) if(POS(TL, 1, None)) return Adv; else if(POS(TL, 1, Pps)) return Adv; else if(POS(TL, 1, Pcp)) retum Adv; else return Adj; else if(POS(TL, -1, Art)) return Adj; else if(POS(TL, -1, None)) if(POS(TL, 1, Nnn)) return Adj; else return Adv; else if(POS(TL, -1, Cnj)) if(POS(TL, 1, Nnn)) return Adj; else return Adv; else if(POS(TL, -1, Adv)) if(POS(TL, 1, Nnn)) return Adj; else if(POS(TL, 1, Adv)) return Adj; else return Adv; else if(POS(TL, -1, Adj)) if(POS(TL, 1, Cnj)) return Adv; else if(POS(TL, 1, Pcp)) return Adv; else return Adj; else if(POS(TL, -1, Nnn)) if(POS(TL, 1, Nnn)) return Adj; else if(POS(TL, 1, Exc)) return Adj; else return Adv; else if(POS(TL, -1, Pps)) if(POS(TL, 1, Pm)) return Adv; else if(POS(TL, 1, None)) return Adv; else if(POS(TL, 1, Art)) return Adv; else if(POS(TL, 1, Pd)) return Adv; else if(POS(TL, 1, Clt)) return Adv; else if(POS(TL, 1, Vrb)) return Adv; else if(POS(TL, 1, Pps)) return Adv; else if(POS(TL, 1, Pcp)) return Adv; else return Adj; else if(POS(TL, -1, PO) if(POS(TL, 1, Nnn)) return Adj; else if(POS(TL, 1, Adj)) return Adj; else return Adv; else if(POS(TL, -1, Pcp)) if(POS(TL, 1, Nnn)) return Adj; else if(POS(TL, 1, Vrb)) return Adj; else return Adv; else return Adv;</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>