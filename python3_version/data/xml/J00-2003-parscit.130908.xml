<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9997865">
A Multistrategy Approach to Improving
Pronunciation by Analogy
</title>
<author confidence="0.999908">
Yannick Marchand* Robert I. Dampert
</author>
<affiliation confidence="0.999373">
University of Southampton University of Southampton
</affiliation>
<bodyText confidence="0.976166105263158">
Pronunciation by analogy (PbA) is a data-driven method for relating letters to sound, with
potential application to next-generation text-to-speech systems. This paper extends previous
work on PbA in several directions. First, we have included &amp;quot;full&amp;quot; pattern matching between
input letter string and dictionary entries, as well as including lexical stress in letter-to-phoneme
conversion. Second, we have extended the method to phoneme-to-letter conversion. Third, and
most important, we have experimented with multiple, different strategies for scoring the candidate
pronunciations. Individual scores for each strategy are obtained on the basis of rank and either
multiplied or summed to produce a final, overall score. Five strategies have been studied and results
obtained from all 31 possible combinations. The two combination methods perform comparably,
with the product rule only very marginally superior to the sum rule. Nonparametric statistical
analysis reveals that performance improves as more strategies are included in the combination:
this trend is very highly significant (p &lt; 0.0005). Accordingly for letter-to-phoneme conversion,
best results are obtained when all five strategies are combined: word accuracy is raised to 65.5%
relative to 61.7% for our best previous result and 63.0% for the best-performing single strategy.
These improvements are very highly significant (p — 0 and p -- 0.00011 respectively). Similar
results were found for phoneme-to-letter and letter-to-stress conversion, although the former was
an easier problem for PbA than letter-to-phoneme conversion and the latter was harder. The main
sources of error for the multistrategy approach are very similar to those for the best single strategy,
and mostly involve vowel letters and phonemes.
</bodyText>
<sectionHeader confidence="0.992138" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999733727272727">
Text-to-phoneme conversion is a problem of some practical importance. Possibly the
major application is speech synthesis from text, where we need to convert the text
input (i.e., letter string) to something much closer to a representation of the corre-
sponding sound sequence (e.g., phoneme string). A further important application is
speech recognition, where we may wish to add a new word (specified by its spelling)
to the vocabulary of a recognition system. This requires that the system has some idea
of the &amp;quot;ideal&amp;quot; pronunciation—or phonemic baseform (Lucassen and Mercer 1984)—of
the word. Also, in recognition we have a requirement to perform the inverse mapping,
i.e., for conversion from phonemes to text. Perhaps the techniques employed for the
forward mapping can also be applied &amp;quot;in reverse&amp;quot; for phoneme-to-text conversion.
Yet another reason for being interested in the problem of automatic phonemization is
</bodyText>
<affiliation confidence="0.814274">
* Image, Speech and Intelligent Systems (ISIS) Research Group, Department of Electronics and Computer
Science, University of Southampton, Southampton S017 1BJ, UK. E-mail: ym@ecs.soton.ac.uk
t Image, Speech and Intelligent Systems (ISIS) Research Group, Department of Electronics and Computer
Science, University of Southampton, Southampton S017 1BJ, UK. E-mail: rid@ecs.soton.ac.uk
</affiliation>
<note confidence="0.913154">
C) 2000 Association for Computational Linguistics
Computational Linguistics Volume 26, Number 2
</note>
<bodyText confidence="0.999770882352941">
that (literate) humans are able to read aloud, so that systems that can pronounce print
serve as models of human cognitive performance.
Modern text-to-speech (TTS) systems use lookup in a large dictionary or lexicon
(we use the terms interchangeably) as the primary strategy to determine the pronunci-
ation of input words. However, it is not possible to list exhaustively all the words of a
language, so a secondary or backup strategy is required for the automatic phonemiza-
tion of words not in the system dictionary. The latter are mostly (but not exclusively)
proper names, acronyms, and neologisms. At this stage of our work, we concentrate
on English and assume that any such missing words are dictionary-like with respect
to their spelling and pronunciation, as will probably be the case for many neologisms.
Even if the missing words are dictionary-like, automatic determination of pronun-
ciation is a hard problem for languages like English and French (van den Bosch et al.
1994). In fact, English is notorious for the lack of regularity in its spelling-to-sound cor-
respondence. That is, it has a deep orthography (Coltheart 1978; Liberman et al. 1980;
Sampson 1985) as opposed to the shallow orthography of, for example, Serbo-Croatian
(Turvey, Feldman, and Lukatela 1984). To a large extent, this reflects the many complex
historical influences on the spelling system (Venezky 1965; Scragg 1975; Carney 1994).
Indeed, Abercrombie (1981, 209) describes English orthography as &amp;quot;one of the least
successful applications of the Roman alphabet.&amp;quot; We use 26 letters in English orthogra-
phy yet about 45-55 phonemes in specifying pronunciation. It follows that the relation
between letters and phonemes cannot be simply one-to-one. For instance, the letter c
is pronounced /s/ in cider but /k/ in cat. On the other hand, the /k/ sound of kitten
is written with a letter k. Nor is this lack of invariance between letters and phonemes
the only problem. There is no strict correspondence between the number of letters
and the number of phonemes in English words. Letter combinations (ch, gh, 11, ea) fre-
quently act as a functional spelling unit (Coltheart 1984)—or grapheme—signaling a
single phoneme. Thus, the combination ough is pronounced /Af/ in enough, while ph is
pronounced as the single phoneme /f/ in phase. However, ph in uphill is pronounced
as two phonemes, !ph!. Usually, there are fewer phonemes than letters but there are
exceptions, e.g., (six, /sIks/). Pronunciation can depend upon word class (e.g., con-
vict, subject). English also has noncontiguous markings (Wijk 1966; Venezky 1970) as,
for instance, when the letter e is added to (mad, /mad/) to make (made, !meld!), also
spelled maid! The final e is not sounded; rather it indicates that the vowel is length-
ened or dipthongized. Such markings can be quite complex, or long-range, as when
the suffix y is added to photograph or telegraph to yield photography or telegraphy, re-
spectively. As a final comment, although not considered further here, English contains
many proper nouns (place names, surnames) that display idiosyncratic pronuncia-
tions, and loan words from other languages that conform to a different set of (partial)
regularities. These further complicate the problem.
This paper is concerned with an analogical approach to letter-to-sound conversion
and related string rewriting problems. Specifically, we aim to improve the performance
of pronunciation by analogy (PbA) by information fusion, an approach to automated
reasoning that seeks to utilize multiple sources of information in reaching a decision—
in this case, a decision about the pronunciation of a word. The remainder of this
paper is organized as follows: In the next section, we contrast traditional rule-based
and more modern data-driven approaches (e.g., analogical reasoning) to language
processing tasks, such as text-to-phoneme conversion. In Section 3, we describe the
original (PRONOUNCE) PbA system of Dedina and Nusbaum (1986) in some detail as
this forms the basis for the later work. Section 4 reviews our own work in this area.
Next, in Section 5, we make some motivating remarks about information fusion and its
use in computational linguistics in general. In Section 6, we present in some detail the
</bodyText>
<page confidence="0.99679">
196
</page>
<note confidence="0.972604">
Marchand and Damper Improving Pronunciation by Analogy
</note>
<bodyText confidence="0.99975">
multistrategy (or fusion) approach to PbA that enables us to obtain clear performance
improvements, as described in Section 7. Finally, conclusions are drawn and directions
for future studies are proposed in Section 8.
</bodyText>
<sectionHeader confidence="0.736308" genericHeader="keywords">
2. Rule-based and Data-driven Conversion
</sectionHeader>
<bodyText confidence="0.973743486486487">
Given the problems described above, how is it possible to perform automatic phone-
mization at all? It is generally believed that the problem is largely soluble provided
sufficient context is available. For example, the substring ough is pronounced /o2.3/
when its left context is th in the word although, /u/ when its left context is thr in the
word through, and /Af/ when its left context is en in the word enough: in each case,
the right context is the word delimiter symbol. In view of this, context-dependent
rewrite rules have been a popular formalism for the backup pronunciation strategy
in TTS systems. The form of the rules, strongly inspired by concepts from generative
phonology (Chomsky and Halle 1968, 14), is:
A [B]C D (1)
which states that the letter substring B with left context A and right context C receives
the pronunciation (i.e., phoneme substring) D. Such rules can also be straightforwardly
cast in the IF. . . THEN form commonly featured in high-level programming languages
and employed in expert, knowledge-based systems technology. They also constitute
a formal model of universal computation (Post 1943). Conventionally, these rules are
specified by an expert linguist, conversant with the sound and spelling systems of the
language of concern. Typical letter-to-sound rule sets are those described by Ainsworth
(1973), McIlroy (1973), Elovitz et al. (1976), Hurmicutt (1976), and Divay and Vitale
(1997).
Because of the complexities of English spelling-to-sound correspondence detailed
in the previous section, more than one rule generally applies at each stage of tran-
scription. The potential conflicts that arise are resolved by maintaining the rules in a
set of sublists, grouped by (initial) letter and with each sublist ordered by specificity.
Typically, the most specific rule is at the top and most general at the bottom. In the
Elovitz et al. rules, for instance, transcription is a one-pass, left-to-right process. For
the particular target letter (i.e., the initial letter of the substring currently under con-
sideration), the appropriate sublist is searched from top to bottom until a match is
found. This rule is then fired (i.e., the corresponding D substring is right-concatenated
to the evolving output string), the linear search terminated, and the next untranscribed
letter taken as the target. The last rule in each sublist is a context-independent default
for the target letter, which is fired in the case that no other, more specific rule applies.
We refer to the mapping between B and D in Equation (1) as a correspondence.
Given a set of correspondences, we can align text with its pronunciation. For ex-
ample, consider the word (make, /meIk/). A possible alignment (which uses the null
phoneme—see below) is:
a
el
</bodyText>
<page confidence="0.985823">
197
</page>
<note confidence="0.87443">
Computational Linguistics Volume 26, Number 2
</note>
<bodyText confidence="0.992478326530612">
It should be obvious, however, that it is all but impossible to specify a canonical
set of correspondences for words of English on which all experts could agree. For
instance, why should we use the single-letter correspondences a /eI/, k /k/,
and e /–/ as above, rather than the composite ake /elk/, which captures the
noncontiguous marking by the final e? Of course, alignment and correspondences are
at the heart of the rule-based methodology.
So, although the context-dependent rule formalism has been vastly influential—
from both theoretical linguistic and practical system implementation perspectives—it
does have its problems. From a practical point of view, the task of manually writing
such a set of rules, deciding the rule order so as to resolve conflicts appropriately,
maintaining the rules as mispronunciations are discovered, etc., is very considerable
and requires an expert depth of knowledge of the specific language. For these reasons,
and especially to ease the problem of creating a TTS system for a new language,
more recent attention has focused on the application of automatic techniques based
on machine learning from large corpora—see Damper (1995) for a comprehensive
review, van den Bosch (1997) for more recent discussion, and Dietterich (1997) for an
accessible review of the underpinning machine learning methodologies.
The rule-based approach has also been challenged from a more theoretical point
of view. For instance, Jones (1996, 1) describes the goal of his book Analogical Natural
Language Processing as:
to challenge the currently predominant assumption in the field of nat-
ural language processing that the representation of language should be
done within the rule-based paradigm alone. For historical reasons, this
traditional position is largely the result of the influence of Chomsky
and his efforts to define language in terms of formal mathematics....
The contrasting view, taken here, is that language is not something
that can be described in a neat and tidy way.
This is also the perspective adopted here.
It is also conceivable that data-driven techniques can actually outperform tradi-
tional rules. However, this possibility is not usually given much credence. For instance,
Divay and Vitale (1997) recently wrote: &amp;quot;To our knowledge, learning algorithms, al-
though promising, have not (yet) reached the level of rule sets developed by hu-
mans&amp;quot; (p. 520). Dutoit (1997) takes this further, stating &amp;quot;such training-based strategies
are often assumed to exhibit much more intelligence than they do in practice, as re-
vealed by their poor transcription scores&amp;quot; (p. 115, note 14).
Pronunciation by analogy (PbA) is a data-driven technique for the automatic
phonemization of text, originally proposed as a model of reading, e.g., by Glushko
(1979) and Kay and Marcel (1981). It was first proposed for ITS applications over a
decade ago by Dedina and Nusbaum (1986, 1991). See also the work of Byrd and
Chodorow (1985), which considers computer-based pronunciation by analogy but
does not mention the possible application to text-to-speech synthesis. As detailed
by Damper (1995) and Damper and Eastmond (1997), PbA shares many similarities
with the artificial intelligence paradigms variously called case-based, memory-based,
or instance-based reasoning as applied to letter-to-phoneme conversion (Stanfill and
Waltz 1986; Lehnert 1987; Stanfill 1987, 1988; Golding 1991; Golding and Rosenbloom
1991; van den Bosch and Daelemans 1993).
PbA exploits the phonological knowledge implicitly contained in a dictionary of
words and their corresponding pronunciations. The underlying idea is that a pro-
nunciation for an unknown word is derived by matching substrings of the input to
</bodyText>
<page confidence="0.99775">
198
</page>
<note confidence="0.747013">
Marchand and Damper Improving Pronunciation by Analogy
</note>
<bodyText confidence="0.999609512820513">
substrings of known, lexical words, hypothesizing a partial pronunciation for each
matched substring from the phonological knowledge, and assembling the partial pro-
nunciations. Although initially it attracted little attention from workers in speech syn-
thesis, several groups around the world are now trying to develop the approach as a
backup to dictionary matching.
In spite of opinions to the contrary expressed in the literature (see above), there is
accumulating evidence that PbA easily outperforms linguistic rewrite rules (Damper
and Eastmond 1996, 1997; Yvon 1996; Bagshaw 1998). More recently, Damper et al.
(1999) conducted a careful performance evaluation of four techniques for letter-to-
sound conversion: rules, backpropagation neural networks (Sejnowski and Rosenberg
1987; McCulloch, Bedworth, and Bridle 1987), PbA and the IB1-IG method based on
information gain weighting (Daelemans, van den Bosch, and Weijters 1997; van den
Bosch 1997). Results showed PbA to be the best of the techniques evaluated by a signif-
icant margin. Although one obviously cannot say from a limited evaluation with just
three competitors that PbA is the best method available, it is clearly worthy of serious
consideration and further development. This paper marks a stage of that development.
As a psychological (or theoretical) model, PbA is &amp;quot;seriously underspecified&amp;quot; so
that the implementor wishing to use analogy within the pronunciation component of
a TTS system &amp;quot;faces detailed choices which can only be resolved by trial and error&amp;quot;
(Damper and Eastmond 1997, 1). The impact of implementational choices on perfor-
mance has been studied by Sullivan and Damper (1993), Damper and Eastmond (1996,
1997), and Yvon (1996, 1997). One important dimension on which implementations
vary is the strategy used to score the candidate pronunciations that PbA produces.
By and large, these investigators have sought the single best pronunciation strategy.
However, the range of choices is wide, so that some rather different implementations
with different performance can be produced, yet these are all (in some sense) pro-
nunciation by analogy. This raises the possibility, which forms the main focus of this
paper, that different multiple PbA strategies—whose outputs are combined to give the
final pronunciation—might be used to good effect. If the different strategies make dif-
ferent errors, then it is conceivable that such a multistrategy approach can produce
a lower error rate than even the best single strategy. Indeed, it may be that a strat-
egy with a poor performance by itself can make a positive overall contribution to
high-accuracy pronunciation derivation when used in concert with other strategies. It
can be viewed as a &amp;quot;specialist&amp;quot; within a committee of experts (e.g., Jacobs et al. 1991;
Dietterich 1997): most often its opinion is invalid, but occasionally—for inputs within
its sphere of expertise—it produces the correct answer when the other &amp;quot;generalist&amp;quot;
strategies do not. There is currently much interest in the topic of information fusion
in a wide variety of application settings. This work can be seen as a specific instance
of information fusion.
</bodyText>
<sectionHeader confidence="0.819142" genericHeader="introduction">
3. Dedina and Nusbaum&apos;s System
</sectionHeader>
<bodyText confidence="0.998485">
The results reported here were obtained using an extended and improved version of
PRONOUNCE, the Dedina and Nusbaum (D&amp;N) system, which we now describe.
</bodyText>
<subsectionHeader confidence="0.997488">
3.1 Principles
</subsectionHeader>
<bodyText confidence="0.9997242">
The basic PRONOUNCE system consists of four components: the lexical database; the
matcher, which compares the target input to all the words in the database; the pronun-
ciation lattice (a data structure representing possible pronunciations); and the decision
function, which selects the &amp;quot;best&amp;quot; pronunciation among the set of possible ones. Re-
flecting PbA&apos;s origins as an empirical, psychological model, this selection is heuristic
</bodyText>
<page confidence="0.992377">
199
</page>
<figure confidence="0.988386">
Computational Linguistics Volume 26, Number 2
AN ECDO T E
ot -
</figure>
<figureCaption confidence="0.93967225">
Figure 1
Simplified pronunciation lattice for the word anecdote. For clarity, only a subset of the arcs is
shown. Full pattern matching is used as described in Section 3.2. Phoneme symbols are those
employed by Sejnowski and Rosenberg.
</figureCaption>
<bodyText confidence="0.973833">
rather than being based (like certain other approaches to automatic pronunciation) on
any statistical model.
</bodyText>
<subsubsectionHeader confidence="0.692558">
3.1.1 Pattern Matching. The input word is first compared to words listed in the lexicon
</subsubsectionHeader>
<bodyText confidence="0.990729612903226">
(Webster&apos;s Pocket Dictionary) and substrings common to both are identified. For a given
dictionary entry, the process starts with the input string and the dictionary entry left-
aligned. Substrings sharing contiguous, common letters in matching positions in the
two strings are then found. Information about these matching letter substrings—and
their corresponding phoneme substrings in the dictionary entry under consideration—
is entered into the input string&apos;s pronunciation lattice as detailed below. (Note that this
requires the letters and phonemes of each word in the lexicon to have been previously
aligned in one-to-one fashion.) The shorter of the two strings is then shifted right by
one letter and the matching process repeated. This continues until the two strings
are right-aligned, i.e., the number of right shifts is equal to the difference in length
between the two strings. This process can be alternatively seen as a matching between
substrings of the incoming word &amp;quot;segmented in all possible ways&amp;quot; (Kay and Marcel
1981, 401) and the entries in the lexicon.
3.1.2 Pronunciation Lattice. Matched substrings, together with their corresponding
phonemic mappings as found in the lexicon, are used to build the pronunciation
lattice for the input string. A node of the lattice represents a matched letter, L,, at
some position, i, in the input. The node is labeled with its position index i and with the
phoneme that corresponds to L, in the matched substring, P,,, say, for the mth matched
substring. An arc is placed from node i to node j if there is a matched substring
starting with L, and ending with LI. The arc is labeled with the phonemes intermediate
between Pun and Pln, in the phoneme part of the matched substring. Additionally, arcs
are labeled with a &amp;quot;frequency&amp;quot; count (see below), which is incremented by one each
time that substring (with that pronunciation) is matched during the pass through the
lexicon.
Figure 1 shows an example pronunciation lattice for the word anecdote. For clarity,
the lattice has been simplified to show only a subset of the arcs. This word suffers
from the so-called silence problem whereby PbA fails to produce any pronunciation,
because there is no complete path through the lattice (see next page). In the case
illustrated, there is no cd —4 /kd/ mapping in the dictionary other than in the word
anecdote itself. Hence, in view of the leave-one-out testing strategy (see next page),
there will never be an arc between nodes (/k/,4) and (/d/,5).
</bodyText>
<page confidence="0.993809">
200
</page>
<note confidence="0.772967">
Marchand and Damper Improving Pronunciation by Analogy
</note>
<bodyText confidence="0.978437214285714">
3.1.3 Decision Function. A possible pronunciation for the input string then corre-
sponds to a complete path through its lattice, with the output string assembled by con-
catenating the phoneme labels on the nodes/arcs in the order that they are traversed.
(Different paths can, of course, correspond to the same pronunciation.) Scoring of can-
didate pronunciation uses two heuristics in PRONOUNCE. If there is a unique shortest
path, then the pronunciation corresponding to this path is taken as the output. If there
are tied shortest paths, then the pronunciation corresponding to the best-scoring of
these is taken as the output. In D&amp;N&apos;s original work, the score used is the sum of
arc &amp;quot;frequencies&amp;quot; (Dedina and Nusbaum&apos;s term, and nothing to do with frequency
of usage in written or spoken communication) obtained by counting the number of
times the corresponding substring matches between the input and the entire lexicon.
The scoring heuristics are one obvious dimension on which different versions of PbA
can vary. In the following, when we refer to a multistrategy approach to PbA, it is
principally the use of multiple scoring strategies which is at issue.
</bodyText>
<subsectionHeader confidence="0.99966">
3.2 Appraisal
</subsectionHeader>
<bodyText confidence="0.999939076923077">
PRONOUNCE was evaluated on just 70 monosyllabic pseudowords—a subset of those
previously used in reading studies by Glushko (1979). Such a test is largely irrelevant
to TTS applications: the test set is not representative of general English, either in
the small number of words used or their length. Also, D&amp;N&apos;s claimed results on
this pseudoword test set have proved impossible to replicate (Damper and Eastmond
1996, 1997; Yvon 1996; Bagshaw 1998). In addition, no consideration is given to the
case where no complete path through the lattice exists (the silence problem mentioned
earlier).
D&amp;N&apos;s pattern matching (when building the pronunciation lattice) is a &amp;quot;partial&amp;quot;
one. That is, as explained in section 3.1.1, the process starts with the leftmost letter of
the input string and of the current dictionary entry aligned and continues until the two
are right-aligned. They give (on page 59) the example of the input word blope matching
to the lexical entry sloping. At the first iteration, the initial b of blope aligns with the
initial s of sloping, and the common substring lop is extracted. The process terminates
at the third iteration, when the final e of blope aligns with the final g of sloping: there are
no common substrings in this case. There seems to be no essential reason for starting
and discontinuing matching at these points. That is, we could shift and match over
the range of all possible overlaps—starting with the final e of blope aligned with the
initial s of sloping, and terminating with the initial b of the former aligned with the
final g of the latter. We call this &amp;quot;full&amp;quot; as opposed to &amp;quot;partial&amp;quot; matching. (Note that the
simplified pronunciation lattice depicted in Figure 1 was obtained using full pattern
matching.)
One conceivable objection to partial pattern matching is that some morphemes
can act both as prefix and suffix (e.g., someBODY and BODY guard). From this point
of view, full matching seems worth consideration. A linguistic justification for the full
method is that affixation is often implicated in the creation of new words.
</bodyText>
<sectionHeader confidence="0.743902" genericHeader="method">
4. Previous Work and Extensions
</sectionHeader>
<bodyText confidence="0.999878">
In this section, we briefly review our previous work on a single-strategy approach
to PbA (Damper and Eastmond 1996, 1997). The basic purpose of the earlier work
was to reimplement D&amp;N&apos;s system but to improve the scoring heuristic used to find
the best path through the pronunciation lattice. To have a more realistic and relevant
evaluation on a large corpus of real words, as opposed to a small set of pseudowords,
we adopted the methodology of removing each word in turn from the lexicon and
</bodyText>
<page confidence="0.978107">
201
</page>
<note confidence="0.421732">
Computational Linguistics Volume 26, Number 2
</note>
<bodyText confidence="0.9950755">
deriving a pronunciation by analogy with the remaining words. In the terminology of
machine learning, this is called leave-one-out or n-fold cross validation (Daelemans,
van den Bosch, and Weijters 1997; van den Bosch 1997) where n is here the size of the
dictionary. PbA has been used in this work to solve three string-mapping problems
of importance in speech technology: letter-to-phoneme translation, phoneme-to-letter
translation, and letter-to-stress conversion.
</bodyText>
<subsectionHeader confidence="0.998681">
4.1 Lexical Database
</subsectionHeader>
<bodyText confidence="0.899842322580645">
The lexical database on which the analogy process is based is the 20,009 words of Web-
ster&apos;s Pocket Dictionary (1974 edition), manually aligned by Sejnowski and Rosenberg
(S&amp;R) (1987) for training their NETtalk neural network. The database is publicly avail-
able via the World Wide Web from URL: ftp://syr-ftp.eng.cam.ac.uk/pub/comp.speech
/dictionaries/. It has data arranged in columns:
aardvark a-rdvark 1 &lt; &lt; &lt; &gt; 2 &lt;&lt;
aback xb@k- 0 &gt; 1 «
abacus @bxkxs 1 &lt; 0 &gt; 0 &lt;
abaft xb@ft 0 &gt; 1 «
etc.
Here the second column is the pronunciation, expressed in the phoneme symbols listed
in S&amp;R&apos;s Appendix A, pp. 161-162. (In this paper, we retain the use of S&amp;R&apos;s phonetic
symbols rather than transliterating to the symbols recommended by the International
Phonetic Association. We do so to maintain consistency with S&amp;R&apos;s publicly available
lexicon.) The phoneme inventory is of size 52, and has the advantage (for computer
implementation) that all symbols are single characters from the ASCII set. The &amp;quot;—&amp;quot;
symbol is the null phoneme, introduced to give a strict one-to-one alignment between
letters and phonemes to satisfy the training requirements of NETtalk. The third column
encodes the syllable boundaries for the words and their corresponding stress patterns.
According to S&amp;R (Appendix A):
1 denotes syllable boundary (right)
2 /I syllable boundary (left)
If primary stress
/I secondary stress
tertiary stress
Stress is associated with vowel letters and arrows with consonants. The arrows point
towards the stress nuclei and change direction at syllable boundaries. To this extent,
&amp;quot;syllable boundary (right/left)&amp;quot; as above is a misnomer on the part of S&amp;R: indeed, this
information is not adequate by itself to place syllable boundaries, which we will denote
&amp;quot;I&amp;quot;. We can, however, infer four rules (or regular expressions) to identify syllable
boundaries:
</bodyText>
<listItem confidence="0.80731325">
R1: [&lt;&gt;] [&lt; I &gt;1
R2: [&lt; digit] = [&lt; I digit]
R3: [digit &gt;1 = [digit I &gt;1
R4: [digit digit] = [digit I digit]
</listItem>
<bodyText confidence="0.66653475">
These have subsequently been confirmed as correct by Sejnowski and Rosenberg (per-
sonal communications).
Table 1 gives some examples of syllable boundaries and decoded &amp;quot;digit stress&amp;quot;
patterns obtained using these rules (last row). By digit stress, we mean that the same
</bodyText>
<page confidence="0.994608">
202
</page>
<note confidence="0.903926">
Marchand and Damper Improving Pronunciation by Analogy
</note>
<tableCaption confidence="0.997621">
Table 1
</tableCaption>
<table confidence="0.7207186">
Examples of stress and syllabification patterns.
Word abbreviate abecedarian actuarial
Stress pattern 0 &lt;» 1 &gt; 02 « 2 &gt; 0 &gt; 0 &gt; 1 &lt; 00 &lt; 2 &lt;&gt; 01 &lt; 00 &lt;
Syllabification ablbrelvilate albelceldarlilan acItularlilal
Digit stress 0011111001222 2100100111110100 2210011110100
</table>
<bodyText confidence="0.999861">
stress-level code (one of 1, 2, or 0) is given to all letters—vowels and consonants—
within a syllable. There are no &amp;quot;&gt;&amp;quot; or &amp;quot;&lt;&amp;quot; codes in the digit stress pattern.
For letter-to-phoneme conversion, homonyms (413 entries) and the two one-letter
words i and o were removed from the original NETtalk corpus to leave 19,594 en-
tries. (The one-letter word a is absent from Webster&apos;s dictionary.) We do not, of
course, contest the importance of homonyms in general. Here, however, we focus on
the (sub)problem of pronouncing isolated word forms. The assumption is that there
will be another, extended process in the future that handles sentence-level pronun-
ciation. Excluding homonyms keeps the problem tractable and means that we can
have meaningful scores. We did not want the same spelling to have different &amp;quot;correct&amp;quot;
pronunciations, otherwise we have to decide which to consider correct or accept any
of them. How do we make this decision? (Indeed, this was one of the problems in
scoring Glushko&apos;s pseudowords as pronounced by D&amp;N&apos;s system.) To apply the anal-
ogy method to phoneme-to-letter conversion, we have again used the NETtalk corpus.
In this case, on the same logic as above, homophones (463 entries) and one-phoneme
pronunciations (/A/ and /o/ in S&amp;R&apos;s notation) were removed from this corpus. This
left 19,544 pronunciations. Finally, we have used analogy to map letters to digit-stress
patterns.
</bodyText>
<subsectionHeader confidence="0.999858">
4.2 Best Preliminary Results
</subsectionHeader>
<bodyText confidence="0.999982625">
Preliminary results were obtained using a single scoring strategy in order to provide a
baseline for comparison with the multistrategy approach to be described shortly. The
best results (Table 2) for the three conversions—letter-to-phoneme, phoneme-to-letter,
and letter-to-stress—were obtained by full pattern matching and using a weighted
total product (TP) scoring. The latter is similar to Damper and Eastmond&apos;s TP score
(Damper and Eastmond 1997), i.e., the sum of the product of the arc frequencies for all
shortest paths giving the same pronunciation. In this case, however, each contribution
to the total product is weighted by the number of letters associated with each arc.
</bodyText>
<tableCaption confidence="0.699892">
Table 2
</tableCaption>
<bodyText confidence="0.99877225">
Best single-strategy results (% correct) for the three conversion
problems studied: letter-to-phoneme, phoneme-to-letter, and
letter-to-stress. These were obtained by full pattern matching and
using a weighted total product (TP) scoring.
</bodyText>
<footnote confidence="0.626869">
Letter-to-phoneme Phoneme-to-letter Letter-to-stress
Words Letters Pronunciations Phonemes Words Letters
61.7 91.6 74.4 94.6 54.6 75.0
</footnote>
<page confidence="0.990666">
203
</page>
<note confidence="0.428142">
Computational Linguistics Volume 26, Number 2
</note>
<bodyText confidence="0.999474777777778">
The percentage of words in which both pronunciation and stress are correct was
41.8%. By use of a very simple strategy for silence avoidance, the results for letter-
to-phoneme conversion were marginally increased from 61.7% to 61.9% words correct
and from 91.6% to 91.8% phonemes correct. The strategy adopted was simply to add
a (null-labeled) arc in the case that there was no complete path through the pronunci-
ation lattice, and a single break occurred between adjacent nodes. This corresponds to
concatenation of two otherwise complete word fragments. These best results should
be compared with 60.7% words correct and 91.2% phonemes correct, as previously
obtained by Damper and Eastmond (1997, Table 2).
</bodyText>
<sectionHeader confidence="0.718649" genericHeader="method">
5. Information Fusion in Computational Linguistics
</sectionHeader>
<bodyText confidence="0.99991444">
In the introduction, we stated that our multistrategy approach is a special case of
information (or data) fusion. What precisely is this? According to Hall and Llinas
(1997, 7-8):
The most fundamental characterization of... fusion involves a hierar-
chical transformation between observed ... parameters (provided by
multiple sources as input) and a decision or inference.
In principle, &amp;quot;fusion provides significant advantages over single source data&amp;quot; in-
cluding &amp;quot;the statistical advantage gained by combining same-source data (e.g., obtain-
ing an improved estimate . .. via redundant observations)&amp;quot; (p. 6). However, dangers in-
clude &amp;quot;the attempt to combine accurate (i.e., good) data with inaccurate or biased data,
especially if the uncertainties or variances of the data are unknown&amp;quot; (p. 8). Methods
of information fusion include &amp;quot;voting methods, Bayesian inference, Dempster-Shafer &apos;s
method, generalized evidence processing theory, and various ad hoc techniques&amp;quot; (Hall
1992, 135).
Clearly, the above characterization is very wide ranging. Consequently, fusion has
been applied to a wide variety of pattern recognition and decision theoretic problems—
using a plethora of theories, techniques, and tools—including some applications in
computational linguistics (e.g., Brill and Wu 1998; van Halteren, Zavrel, and Daelemans
1998) and speech technology (e.g., Bowles and Damper 1989; Romary and Pierre11989).
According to Abbott (1999, 290), &amp;quot;While the reasons [that] combining models works so
well are not rigorously understood, there is ample evidence that improvements over
single models are typical.... A strong case can be made for combining models across
algorithm families as a means of providing uncorrelated output estimates.&amp;quot; Our purpose
in this paper is to study and exploit such fusion by model (or strategy) combination
as a way of achieving performance gains in PbA.
</bodyText>
<sectionHeader confidence="0.625532" genericHeader="method">
6. Multiple Strategies for PbA
</sectionHeader>
<bodyText confidence="0.9999375">
We have experimented with five different scoring strategies, used singly and in combi-
nation, in an attempt to improve the performance of PbA. The chosen strategies are by
no means exhaustive, nor do we make any claim that they represent the &amp;quot;best&amp;quot; choices.
Mostly, they were intuitively appealing measures that had different motivations, cho-
sen in the hope that this would produce uncorrelated outputs (see quote from Abbott
above). Also, in view of the remarks of Hall and Llinas about the potential dangers
of fusion/combination, we chose deliberately to include some very simple strategies
indeed, to see if they harmed performance.
</bodyText>
<page confidence="0.989145">
204
</page>
<figure confidence="0.9018455">
Marchand and Damper Improving Pronunciation by Analogy
L ONGE V I TY
</figure>
<figureCaption confidence="0.995195">
Figure 2
</figureCaption>
<bodyText confidence="0.99796025">
Example pronunciation lattice for the word longevity. For simplicity, only arcs contributing to
the shortest (length-3) paths are shown and null arc labels are omitted. Phoneme symbols are
those employed by Sejnowski and Rosenberg.
In the following, full pattern matching has been used exclusively.
</bodyText>
<subsectionHeader confidence="0.999761">
6.1 Pronunciation Candidates
</subsectionHeader>
<bodyText confidence="0.9534042">
Formally, the pronunciation lattice for a word can be seen as a set of N candidate
pronunciations (corresponding to tied, shortest paths) with some features:
r(W,) = {C1,. , . . , CN} is the lattice for the word W, with CIE [LN]
denoting the candidates.
CI is a 3-tuple (F), D1, 1)1) where:
Fj = • • • , fn } represents the set of arc frequencies along the
jth candidate path (length n).
Di = {d1, . , dk,. , dn} represents the &amp;quot;path structure,&amp;quot; i.e., the
difference of the position index (within the word) of the nodes
at either end of the kth arc.
= . pm, , pi} is the set of pronunciation candidates
with pm&apos;s from the set of phonemes (52 in our case) and 1 is the
length of the pronunciation. (Within the NETtalk corpus,
primarily because of the use of the null phoneme, words and
their pronunciations all have the same length).
For example, for the pronunciation lattice given in Figure 2 for the word longevity,
we have the six candidate pronunciations shown in Table 3, along with their arc fre-
quencies and path structures. Of course, candidate pronunciations are not necessarily
distinct: different shortest paths can obviously correspond to the same phoneme string.
In this example, the correct pronunciation is that corresponding to Candidates 4 and 6.
</bodyText>
<subsectionHeader confidence="0.999838">
6.2 Combining Scores
</subsectionHeader>
<bodyText confidence="0.973934">
According to Hall and Llinas (1997, 8), &amp;quot;observational data may be combined or fused
at a variety of levels.&amp;quot; Since each of our strategies operates on the same basic data
</bodyText>
<page confidence="0.992291">
205
</page>
<table confidence="0.462322">
Computational Linguistics Volume 26, Number 2
</table>
<tableCaption confidence="0.952977333333333">
Table 3
Candidate pronunciations for the word longevity. The correct
pronunciation is that corresponding to Candidates 4 and 6.
</tableCaption>
<table confidence="0.964081428571429">
Candidate Pronunciation Arc Frequencies Path Structure
1 /1cGgEvxti/ {1,11,2} {4, 1, 5}
2 /1cGg-vxti/ {1, 24, 22} {5,1,4}
3 /1cGg-vIti/ {1, 2, 2} {5, 2, 3}
4 /lanJEvxti/ {2, 9, 2} {3, 2, 5}
5 /lonJEvxti/ {1, 9, 2} {3, 2, 5}
6 /lanjEvxti/ {2, 80, 2} {4,1,5}
</table>
<bodyText confidence="0.970575190476191">
structure—the pronunciation lattice—the most obvious kind of fusion, and that em-
ployed here, is combination at the level of the final decision. In principle, fusion at this
level is able to cope with the so-called common currency problem, whereby different
sources of information produce incommensurate data of different types to which dif-
ferent physical units of measurement apply. Suppose, for instance, that combination
is by a weighted summation in which the weights are learned from the data: in this
case, the weights act to emphasize some measures while de-emphasizing others. Here,
we use the rank of a pronunciation among the competing candidates as the basis of a
weighting, or common currency.
From a computational point of view, the main idea is to attribute points to each
candidate for each scoring strategy. The number of points given to a candidate for
scoring strategy si is inversely related to its rank order on the basis of si. Thus, the
total number of points (T) awarded for each strategy is:
T(N) = r=1 N(N + 1)
2
where N is the number of candidate pronunciations (N = 6 in our longevity example,
so that T(6) = 21).
Let cand(Rs,) express the number of candidates that have the rank R for the scor-
ing strategy si so that cand(Rs,) &gt; 1 if there are ties, otherwise cand(R) 1. Then
P(CI, Rs,), the number of points awarded to the candidate CI thanks to its rank on the
basis of strategy s„ is:
</bodyText>
<equation confidence="0.9723505">
R. -Rand (Rs,)-1
(N — i +1)
P(Ci, R5,)
cand(Rs,)
</equation>
<bodyText confidence="0.997933">
Recently, Kittler et al. (1998) have considered the relative merits of several combi-
nation rules for decision-level fusion from a theoretical and experimental perspective.
The rules compared were sum, product, max, min, and majority. Of these, the sum
and product rules generally performed best. In view of this, these are the rules used
here.
For the sum rule, the final score for a candidate pronunciation, FS(c), is simply
taken as the sum of the different numbers of points won for each of the S strategies.
</bodyText>
<page confidence="0.989362">
206
</page>
<subsectionHeader confidence="0.270476">
Marchand and Damper Improving Pronunciation by Analogy
</subsectionHeader>
<bodyText confidence="0.555554">
Since not all strategies are necessarily included:
</bodyText>
<equation confidence="0.996899">
FS(Ci) = 8s,P(Ci, .1Z5,) (4)
</equation>
<bodyText confidence="0.99362">
and for the product rule:
</bodyText>
<equation confidence="0.9988715">
FS (Ci ) = H 6s; P(Ci, + (1 - (5)
i=1
</equation>
<bodyText confidence="0.999771333333333">
where 6s, is the Kronecker delta, which is 1 if strategy s, is included in the combined
score and 0 otherwise. Finally, the pronunciation corresponding to the candidate that
obtains the best final score is chosen.
</bodyText>
<subsectionHeader confidence="0.999959">
6.3 Scoring Strategies
</subsectionHeader>
<bodyText confidence="0.9999596">
Five different strategies have been used in deriving an overall pronunciation. In the
following, we list each strategy, define it, and give the result (in a table below the
formal definition) of applying the strategy to the six candidate pronunciations of the
example word longevity (Table 3). For each strategy, points are awarded as determined
by Equation (3) and total 21 in accordance with Equation (2).
</bodyText>
<subsectionHeader confidence="0.519041">
Strategy 1
</subsectionHeader>
<bodyText confidence="0.991964">
This is the product of the arc frequencies (PF) along the shortest path.
</bodyText>
<equation confidence="0.596377">
PF(Ci)
</equation>
<bodyText confidence="0.700352">
The candidate scoring the maximum PF() value is given rank 1.
</bodyText>
<table confidence="0.92504225">
Candidate 1 2 3 4 5 6
Score, PF() 22 528 4 36 18 320
Rank 4 1 6 3 5 2
Points 3 6 1 4 2 5
</table>
<subsectionHeader confidence="0.546227">
Strategy 2
</subsectionHeader>
<bodyText confidence="0.950662">
The standard deviation of the values associated with the path structure (SDPS).
</bodyText>
<equation confidence="0.713215">
SDPS(Ci) =\
</equation>
<page confidence="0.955117">
207
</page>
<table confidence="0.572463">
Computational Linguistics Volume 26, Number 2
where
Edi
d= i=1
The candidate scoring the minimum SDPS() value is given rank 1.
Candidate 1 2 3 4 5 6
Score, SDPS() 1.7 1.7 1.2 1.2 1.2 1.7
Rank 4 4 1 1 1 4
Points 2 2 5 5 5 2
</table>
<bodyText confidence="0.934837333333333">
Strategy 3
The frequency of the same pronunciation (FSP), i.e., the number of occurrences of the
same pronunciation within the (tied) shortest paths.
</bodyText>
<equation confidence="0.906352">
FSP(Ci) = cand{pilPi = Pk}
with
</equation>
<bodyText confidence="0.671963">
j k and k E [1, N].
The candidate scoring the maximum FSP() value is given rank 1.
</bodyText>
<table confidence="0.9100235">
Candidate 1 2 3 4 5 6
Score, FSP() 1 1 1 2 1 2
Rank 3 3 3 1 3 1
Points 2.5 2.5 2.5 5.5 2.5 5.5
</table>
<bodyText confidence="0.787674">
Strategy 4
The number of different symbols (NDS) between a pronunciation candidate CI and
the other candidates.
</bodyText>
<equation confidence="0.987236333333333">
n N
NDS(Ci) = op], Pk,)
i=1 Ic=1
</equation>
<bodyText confidence="0.6666335">
where b() is the Kronecker delta, which is 1 if pronunciations Pi and Pk differ in posi-
tion i and is 0 otherwise. Table 4 illustrates the computation of NDS() for Candidate 1
(/1cGgEvxti/).
The candidate scoring the minimum NDS() value is given rank 1.
Candidate 1 2 3 4 5 6
Score, NDS( ) 12 14 18 13 14 13
Rank 1 4 6 2 4 2
Points 6 2.5 1 4.5 2.5 4.5
Strategy 5
Weak link (WL), i.e., the minimum of the arc frequencies.
</bodyText>
<equation confidence="0.646654">
WL(Cj) = minifil ie [1,n]
</equation>
<page confidence="0.9679">
208
</page>
<note confidence="0.889775">
Marchand and Damper Improving Pronunciation by Analogy
</note>
<tableCaption confidence="0.991494">
Table 4
</tableCaption>
<bodyText confidence="0.674572">
Illustration of the computation of NDS() for the candidate
pronunciation /1cGgEvxti/ of longevity. Phonemes which are
not equal to those of the target pronunciation are entered in
bold.
</bodyText>
<table confidence="0.998905230769231">
Candidate 1 1 cGgEv x t i
1 c G g - v x t i
Other candidates 1 c G g -v I t i
to be compared 1 a n J Evx t i
with Candidate 1 1 o n J Evx t i
1 a n J Evx t i
Differences at position i 0 3 3 3 2 0 1 0 0
Score, NDS() 12
The candidate scoring the maximum WL( ) value is given rank 1.
Candidate 1 2 3 4 5 6
Score, WL( ) 1 1 1 2 1 2
Rank 3 3 3 1 3 1
Points 2.5 2.5 2.5 5.5 2.5 5.5
</table>
<bodyText confidence="0.9571665">
We now consider the results of using these five strategies for scoring the shortest
paths both singly and combined in all possible combinations.
</bodyText>
<sectionHeader confidence="0.97372" genericHeader="method">
7. Results
</sectionHeader>
<bodyText confidence="0.984445">
In this section, we first detail some characteristics of the shortest paths through the
pronunciation lattices (since these affect the attainable performance) before demon-
strating that the combination strategy produces statistically significant improvements.
It is largely immaterial if we use the sum or the product rule. Finally, the distribution
of errors for the best-performing combination of scores is analyzed in order to set
priorities for future research in improving PbA.
7.1 Characteristics of the Shortest Paths
Since we are focusing in this work on D&amp;N&apos;s second heuristic (disambiguating tied
shortest paths), it makes sense to investigate the limits set by tacit acceptance of D&amp;N&apos;s
first heuristic—which gives primacy to the shortest path. Table 5 shows some statistics
related to the shortest paths for the three different conversion problems studied.
The minimal percentage indicates the lower bound on words-correct performance
that obtains when the second heuristic is irrelevant, i.e., when all the shortest paths
through the lattice give the identical, correct pronunciation. On the other hand, the
maximal percentage indicates the upper bound that obtains when the second heuristic
always chooses the correct candidate, i.e., there is at least one correct pronunciation
among the shortest paths. Overall, these statistics indicate that there is considerable
scope to improve the second heuristic, since the upper bound of 85.1% words correct
for letter-to-phoneme conversion, for instance, is vastly superior to our previous best
value of 61.9% and to the figure of 64.0% obtained by Yvon (1996) on the same lexi-
con using multiple unbounded overlapping chunks as the nodes of the pronunciation
lattice. They also suggest (in line with our intuitions) that letter-to-phoneme conver-
</bodyText>
<page confidence="0.992704">
209
</page>
<table confidence="0.456945">
Computational Linguistics Volume 26, Number 2
</table>
<tableCaption confidence="0.984197">
Table 5
</tableCaption>
<bodyText confidence="0.6405945">
Statistics describing the occurrence of correct pronunciations among the shortest paths of
the pronunciation lattices for all the words in the lexicon.
</bodyText>
<table confidence="0.9984208">
Type of Minimal Maximal Mean Candidates Mean Good Candidates
Conversion Percentage Percentage per Word per Word
Letter-phoneme 15.3 85.1 7.9 2.2
Phoneme-letter 31.0 89.1 5.9 2.3
Letter-stress 11.6 78.2 7.5 2.0
</table>
<bodyText confidence="0.9529065">
sion is harder than phoneme-to-letter conversion, and that lexical stress assignment is
harder still.
</bodyText>
<sectionHeader confidence="0.514111" genericHeader="evaluation">
7.2 Results for Different Combinations of Strategy
</sectionHeader>
<bodyText confidence="0.999953863636364">
We have obtained results for all possible combinations of the strategies, for each of the
three mapping problems. Since there are five strategies, the number of combinations
is (25 - 1) = 31. The various combinations are denoted as a five-bit code where 1 at
position i indicates that strategy s, was included in the combination (i.e., 6s, = 1 in
Equations (4) and (5)) and a 0 indicates that it was not. Thus, as an example, the code
00100 indicates that Strategy 3 (FSP) was used alone.
Table 6 gives an example of the use of the combination 11010 and product rule in
deriving a pronunciation for the word longevity using the product rule of combination.
The points that contribute to the final score are shown in bold. Note that the winner
(Candidate 4) gives the correct pronunciation in this case. When the sum rule is used,
the correct pronunciations (Candidates 4 and 6) tie with a final score of 13.5.
Table 7 shows the results of letter-to-phoneme conversion for the 31 possible com-
binations of scoring strategy using both the product and sum rules. The average across
the 31 combinations was 62.42% words correct for the product rule compared to 62.30%
for the sum rule. This difference is not significant (on the basis of Equation (6) below).
Since the product rule gave numerically higher values, however, we continue to use
it for the remainder of this paper.
Tables 8, 9, and 10 show the results obtained with all possible combinations of
strategies for the three conversion problems using the product rule. Consider first
the results for letter-to-phoneme conversion (Table 8). The last two columns show the
rank according to the number of strategies included in the final score (Rank(C)) and
the rank according to word accuracy (Rank(W)). Let us hypothesize that these two
</bodyText>
<tableCaption confidence="0.91568">
Table 6
Example of multistrategy scoring for the word longevity
using the 11010 combination and product rule.
</tableCaption>
<figure confidence="0.909027875">
Candidate PF SDPS FSP NDS WL Final Score
1 3 2 2.5 6 2.5 36
2 6 2 2.5 2.5 2.5 30
3 1 5 2.5 1 2.5 5
4 4 5 5.5 4.5 5.5 90
5 2 5 2.5 2.5 2.5 25
6 5 2 5.5 4.5 5.5 45
Winner: Candidate 4 (/lan)Evxti/)
</figure>
<page confidence="0.992371">
210
</page>
<note confidence="0.933996">
Marchand and Damper Improving Pronunciation by Analogy
</note>
<tableCaption confidence="0.997967">
Table 7
</tableCaption>
<table confidence="0.986269942857143">
Results of letter-to-phoneme conversion for the 31 possible combinations of
scoring strategy using the product and sum rules.
Product rule Sum rule
Combination Words (%) Phonemes (%) Words (%) Phonemes (%)
00001 57.7 90.8 57.7 90.5
00010 61.3 91.7 61.3 91.7
00011 63.3 92.1 63.2 92.1
00100 63.0 91.7 63.0 91.7
00101 65.3 92.2 65.1 92.2
00110 63.2 91.9 63.1 91.9
00111 64.9 92.2 65.0 92.3
01000 48.2 88.4 48.2 88.4
01001 56.7 90.4 57.0 90.5
01010 61.5 91.7 61.5 91.7
01011 63.2 92.0 63.1 91.0
01100 62.7 91.6 62.8 91.6
01101 64.7 92.1 64.6 92.1
01110 63.0 91.9 63.0 91.9
01111 64.7 92.2 64.9 92.2
10000 59.2 91.0 59.2 91.0
10001 59.0 91.2 59.1 91.2
10010 63.6 92.1 63.6 92.1
10011 63.6 92.2 63.4 92.1
10100 65.2 92.2 65.1 92.2
10101 65.3 92.3 64.9 92.2
10110 64.8 92.2 64.8 92.3
10111 65.4 92.4 65.4 92.4
11000 58.6 91.1 58.6 91.1
11001 59.0 91.2 59.2 91.2
11010 63.6 92.2 63.6 92.2
11011 63.4 92.2 63.2 92.1
11100 65.4 92.3 65.3 92.3
11101 64.9 92.3 64.7 92.2
11110 65.2 92.3 65.1 92.3
11111 65.5 92.4 65.5 92.4
</table>
<bodyText confidence="0.998645166666667">
ranks are not positively correlated. That is, our null hypothesis is that performance
(in terms of word accuracy) does not increase as more scoring strategies s, for candi-
date pronunciation Cj are included in the final score FS(CI). However, the Spearman
rank correlation coefficient rs (Siegel 1956, 202-213) is computed here as 0.6657, with
degrees of freedom df = (31 - 2) = 29. For df &gt; 10, the significance of this result can
be tested as:
</bodyText>
<equation confidence="0.972388333333333">
t = rs df
= 4.8041
1 -
</equation>
<bodyText confidence="0.9977022">
This value is very highly significant (p &lt; 0.0005, one-tailed test). Hence, we reject the
null hypothesis and conclude that performance improves as more scores are included
in the combination. Note that this test is nonparametric, and makes a minimum of
assumptions about the data-only that they are ordinal and so can be meaningfully
ranked.
</bodyText>
<page confidence="0.997682">
211
</page>
<note confidence="0.533532">
Computational Linguistics Volume 26, Number 2
</note>
<tableCaption confidence="0.978475142857143">
Table 8
Results of letter-to-phoneme conversion for the 31 possible
combinations of scoring strategy using the product rule. Rank(C) is
the rank of the result according to the number of strategies (in the
range 1 to 5) included in the final score. Rank(W) is the rank of the
result according to word accuracy. The Spearman rank correlation
coefficient I-, is 0.6657, which is very highly significant.
</tableCaption>
<table confidence="0.99994684375">
Combination Words (%) Phonemes (%) Rank(C) Rank(W)
00001 57.7 90.8 29 29
00010 61.3 91.7 29 24
00011 63.3 92.1 21.5 17
00100 63.0 91.7 29 20.5
00101 65.3 92.2 21.5 4.5
00110 63.2 91.9 21.5 18.5
00111 64.9 92.2 11.5 8.5
01000 48.2 88.4 29 31
01001 56.7 90.4 21.5 30
01010 61.5 91.7 21.5 23
01011 63.2 92.0 11.5 18.5
01100 62.7 91.6 21.5 22
01101 64.7 92.1 11.5 11.5
01110 63.0 91.9 11.5 20.5
01111 64.7 92.2 4 11.5
10000 59.2 91.0 29 25
10001 59.0 91.2 21.5 26.5
10010 63.6 92.1 21.5 14
10011 63.6 92.2 11.5 14
10100 65.2 92.2 21.5 6.5
10101 65.3 92.3 11.5 4.5
10110 64.8 92.2 11.5 10
10111 65.4 92.4 11.5 2.5
11000 58.6 91.1 21.5 28
11001 59.0 91.2 11.5 26.5
11010 63.6 92.2 11.5 14
11011 63.4 92.2 4 16
11100 65.4 92.3 11.5 2.5
11101 64.9 92.3 4 8.5
11110 65.2 92.3 4 6.5
11111 65.5 92.4 1 1
</table>
<bodyText confidence="0.999482307692308">
Having shown that there is a very highly significant positive correlation between
the number of strategies deployed and the obtained word accuracy, we next ask if
the obtained improvement is significant. (This is to take account of the possibility that
the difference between two combination strategies ranked at positions i and (i + k)
is not significant.) To answer this, we note that only two outcomes are possible for
the translation of each word: either the pronunciation is correct or it is not. Thus, the
sampling distribution of the word accuracies listed in the second column of Table 8
is binomial and, hence, we can use a binomial test (Siegel 1956, 36-42) to determine
the significance of differences between them. Since the number of trials (i.e., word
translations) is very large (-20,000), we can use the normal approximation to the
binomial distribution.
Let us first ask if the best letter-to-phoneme conversion result here (65.5% word ac-
curacy for combination 11111) is significantly better than the previous best, preliminary
</bodyText>
<page confidence="0.99676">
212
</page>
<note confidence="0.823863">
Marchand and Damper Improving Pronunciation by Analogy
</note>
<bodyText confidence="0.724943">
value of 61.7%. The appropriate statistic is (Siegel 1956, 41):
</bodyText>
<equation confidence="0.685881333333333">
= (x + 0.5) — NP (6)
z
VNPQ
</equation>
<bodyText confidence="0.9999836875">
where N =- 19,594 words, P =- 0.617, Q = (1 — P) = 0.383, x = 19,594 x 0.655 and the
+0.5 term (correction for the fact that the binomial distribution is discrete while the
normal distribution is continuous) can be ignored, giving z = 10.9. The (one-tailed)
probability that this value could have been obtained by chance is effectively zero (un-
tabulated in Siegel&apos;s Table A [ID. 247]). In fact, the critical value for the 1% significance
level is z =- 2.33, which equates to a word accuracy of approximately 64.7%. It follows
that even the best single-strategy result (63.0% for combination 00100 using Strategy 3
only) is significantly poorer than the multistrategy result using all five scoring strate-
gies.
Actually, given its simplicity, it is remarkable that Strategy 3 (frequency of the
same pronunciation, FSP) used alone performs as well as it does. It was included
partly to test the effect of including what were felt to be oversimplistic strategies! Yet
it is superior to the previous best result of 61.7% using the weighted TP score, and
the superiority is very highly significant (z = 3.7, p = 0.00011). In fact, for all three
mapping problems, Strategies 1 (PF) and 3 are always implicated in results of rank
less than 3, indicating their importance in obtaining high performance.
Turning to phoneme-to-letter conversion (Table 9), the Spearman rank correlation
coefficient was 0.6375, which again is very highly significant (t = 4.456, p &lt; 0.0005,
df = 29, one-tailed test). Hence, as before, performance improves as more scoring
strategies are deployed. The critical z value of 2.33 for the 1% significance level equates
to a word accuracy of 74.7% relative to the best obtained word accuracy of 75.4% for
combination 10101. Hence, the best result is significantly better than either the previous
best value (74.4%) or the best single-strategy result (73.5% for combination 10000).
For letter-to-stress conversion (Table 10), the Spearman rank correlation coefficient
was 0.7411 (t = 5.944, p &lt; 0.0005, df = 29, one-tailed test) so that, once again, perfor-
mance improves as more scoring strategies are deployed. The critical z value of 2.33
for the 1% significance level equates to a word accuracy of 58.0% relative to the best
obtained word accuracy of 58.8% for combination 11100. Hence, the best result is sig-
nificantly better than either the previous best value (54.6%) or the best single-strategy
result (53.4% for combination 00100).
Finally, the percentage of words in which both pronunciation and stress are correct
increases from 41.8% to 46.3%.
</bodyText>
<subsectionHeader confidence="0.933263">
7.3 Analysis of Errors
</subsectionHeader>
<bodyText confidence="0.999362916666667">
Table 11 identifies the main sources of error for letter-to-phoneme conversion using
the 11111 combination strategy. Table 11(a) indicates, in rank order, the 10 letters in
the input that were most often mapped to an incorrect phoneme. The commonest
problem is mispronunciation of letter e, which produces 21.2% of the total errors. To
some extent, this is a natural consequence of the high frequency of this letter in English:
as indicated in the Proportion column, letter e accounts for 11.0% of the total corpus.
Even so, the ratio of errors to occurrences is almost 2, while it actually exceeds 2 for
letters a and o. It is clear, as other workers have found, that the vowel letters are vastly
more difficult to translate than are the consonant letters.
Table 11(b) ranks the 10 commonest incorrect phonemes in the system&apos;s output.
The schwa vowel accounts for 20.8% of errors in this case. Again, this partially reflects
the extremely common occurrence of this phoneme.
</bodyText>
<page confidence="0.998532">
213
</page>
<note confidence="0.606336">
Computational Linguistics Volume 26, Number 2
</note>
<tableCaption confidence="0.804145571428571">
Table 9
Results of phoneme-to-letter conversion for the 31 possible
combinations of scoring strategy using the product rule. Rank(C) is
the rank of the result according to the number of strategies (in the
range 1 to 5) included in the final score. Rank(W) is the rank of the
result according to word accuracy. The Spearman rank correlation
coefficient rs is 0.6375, which is very highly significant.
</tableCaption>
<table confidence="0.99988725">
Combinations Words (&amp;quot;Yo) Phonemes (%) Rank(C) Rank(W)
00001 69.1 93.6 29 29
00010 71.6 94.2 29 27
00011 73.3 94.4 21.5 18
00100 72.2 94.2 29 22.5
00101 74.0 94.5 21.5 13
00110 72.3 94.2 21.5 21
00111 73.9 94.5 11.5 14
01000 61.6 92.1 29 31
01001 68.2 93.4 21.5 30
01010 71.5 94.1 21.5 28
01011 73.1 94.4 11.5 19
01100 72.0 94.1 21.5 24
01101 73.7 94.4 11.5 15.5
01110 72.2 94.2 11.5 22.5
01111 73.7 94.4 4 15.5
10000 73.5 94.4 29 17
10001 72.7 94.3 21.5 20
10010 74.3 94.6 21.5 10.5
10011 74.7 94.7 11.5 8
10100 75.1 94.7 21.5 2.5
10101 75.4 94.7 11.5 1
10110 74.8 94.6 11.5 6
10111 75.1 94.7 4 2.5
11000 71.7 94.0 21.5 26
11001 71.8 94.1 11.5 25
11010 74.3 94.6 11.5 10.5
11011 74.2 94.5 4 12
11100 75.0 94.6 11.5 4.5
11101 74.7 94.6 4 8
11110 74.7 94.6 4 8
11111 75.0 94.7 1 4.5
</table>
<bodyText confidence="0.999900222222222">
Finally, Table 11(c) shows the 10 phonemes in the correct pronunciation that most
often received a wrong translation. These are the same 10 phonemes as for Table 11(b),
but in slightly different rank order. Once more, it is clear that vowel errors vastly
outnumber consonant errors overall. The null phoneme is also problematic.
This pattern of errors is very close to that for the preliminary results. We have
exactly the same 10 main letters/phonemes responsible for errors in each column with
only minor changes in their rank order. These similarities suggest that these particular
errors are persistent-even structural-and will cause problems for other translation
schemes as well as PbA.
</bodyText>
<sectionHeader confidence="0.657373" genericHeader="conclusions">
8. Conclusions
</sectionHeader>
<bodyText confidence="0.9298445">
We have extended previous work in pronunciation by analogy (PbA) principally by
experimenting with multiple strategies for producing pronunciations. The combina-
</bodyText>
<page confidence="0.998013">
214
</page>
<note confidence="0.955609">
Marchand and Damper Improving Pronunciation by Analogy
</note>
<tableCaption confidence="0.987918">
Table 10
</tableCaption>
<bodyText confidence="0.930069333333333">
Results of letter-to-stress conversion for the 31 possible combinations
of scoring strategy using the product rule. Rank(C) is the rank of the
result according to the number of strategies (in the range 1 to 5)
included in the final score. Rank(W) is the rank of the result
according to word accuracy. The Spearman rank correlation
coefficient r s is 0.7411, which is very highly significant.
</bodyText>
<table confidence="0.9998115">
Combinations Words (%) Phonemes (%) Rank(W) Rank(W)
00001 52.7 74.9 29 26
00010 49.2 74.4 29 30
00011 53.6 75.7 21.5 23.5
00100 53.4 73.9 29 25
00101 57.7 76.3 21.5 4
00110 53.8 74.8 21.5 21.5
00111 56.2 75.9 11.5 11
01000 39.4 67.5 29 31
01001 52.2 74.4 21.5 27
01010 50.5 74.5 21.5 29
01011 53.9 75.8 11.5 20
01100 53.8 74.2 21.5 21.5
01101 57.1 76.1 11.5 7.5
01110 54.2 75.0 11.5 18
01111 56.2 75.9 4 11
10000 51.6 73.7 29 28
10001 54.1 75.3 21.5 19
10010 53.6 75.4 11.5 23.5
10011 55.2 76.0 21.5 14
10100 57.4 75.9 21.5 6
10101 58.2 76.6 11.5 3
10110 56.2 75.8 11.5 11
10111 57.1 76.3 4 7.5
11000 54.5 75.9 21.5 17
11001 54.6 76.1 11.5 16
11010 55.0 76.3 11.5 15
11011 55.8 76.7 4 13
11100 58.8 77.0 11.5 1
11101 58.6 77.2 4 2
11110 57.0 76.4 4 9
11111 57.5 76.7 1 5
</table>
<bodyText confidence="0.998425642857143">
tion of different scoring strategies for the shortest paths in the pronunciation lat-
tice has been shown to deliver statistically significant improvements: a best result of
65.5% words correct has been obtained for letter-to-phoneme conversion using approx-
imately 20,000 manually aligned words of Webster&apos;s Pocket Dictionary. This compares
with a figure of 63.0% for the best-performing single-scoring strategy (frequency of
the same pronunciation, FSP) and 61.7% for our best preliminary result. Examination
of the pronunciation lattices, however, reveals that the upper bound on performance
of a method based on selecting among shortest paths is 85.1%, so that there is scope
for further improvement yet.
The way of combining scores is simply by summation or multiplication of a points
score awarded on the basis of a pronunciation&apos;s rank. The product rule of combination
is found to perform only very marginally better than the sum rule: the difference is
not significant. We have not yet expended much effort in determining exactly which
scores should be used. To this end, a preliminary analysis of errors has been done. This
</bodyText>
<page confidence="0.997882">
215
</page>
<note confidence="0.591863">
Computational Linguistics Volume 26, Number 2
</note>
<tableCaption confidence="0.97035">
Table 11
</tableCaption>
<table confidence="0.995759810810811">
Main factors responsible for errors in letter-to-phoneme mapping.
(a) Letters most often mapped to an incorrect phoneme
Letter Errors CYO Proportion (%)
e 21.2 11.0
a 20.9 9.0
o 16.1 6.9
i 14.1 8.8
u 7.0 3.8
r 3.8 7.5
/ 2.7 5.5
s 2.7 5.3
n 2.5 6.8
t 1.8 7.7
(b) Phonemes most commonly wrong in the output
Phoneme Errors (°/0) Proportion (%)
/x/ 20.8 8.0
/I/ 9.6 5.0
/-/ 7.7 14.7
/E/ 7.5 2.5
7@/ 7.2 2.8
/a/ 5.4 1.9
/i/ 4.8 3.0
/e/ 4.1 1.8
/o/ 3.5 1.5
/A/ 3.0 1.1
(c) Phonemes of the correct translation most commonly mispronounced
Phoneme Errors (°/0) Proportion (°70)
/x/ 22.4 8.1
/-/ 9.9 14.8
/I/ 7.7 4.8
/a/ 6.3 1.9
6.0 2.4
5.7 3.1
5.3 2.7
4.2 1.8
/o/ 3.6 1.5
/A/ 3.5 1.2
</table>
<bodyText confidence="0.9995485">
reveals that (in common with other approaches to letter-to-sound conversion, such as
linguistic rules), the translation of vowel letters is especially problematic. Future work
should therefore attempt to find scoring methods and combination techniques that
deal effectively with the vowels.
We have also studied the related problems of mapping phonemes to letters and
letters to lexical stress, which are also important in speech technology Our results
show that the former problem is easier than letter-to-phoneme conversion while the
latter is harder-at least, when attacked by the method of analogy. Once again, how-
ever, the multistrategy approach has the potential to deliver significant performance
gains.
</bodyText>
<page confidence="0.997789">
216
</page>
<note confidence="0.964678">
Marchand and Damper Improving Pronunciation by Analogy
</note>
<sectionHeader confidence="0.977817" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.93103575">
This work was funded by the UK Economic
and Social Research Council via research
grant R000235487: &amp;quot;Speech Synthesis by
Analogy.&amp;quot;
</bodyText>
<sectionHeader confidence="0.987767" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99536418018018">
Abbott, Dean W. 1999. Combining models
to improve classifier accuracy and
robustness. In Proceedings of Second
International Conference on Information
Fusion, Fusion &apos;99, Volume I,
pages 289-295, Sunnyvale, CA.
Abercrombie, David. 1981. Extending the
Roman alphabet: Some orthographic
experiments of the past four centuries. In
Ronald E. Asher and Eugenie J. A.
Henderson, editors, Towards a History of
Phonetics, pages 207-224. Edinburgh
University Press, Edinburgh, UK.
Ainsworth, William A. 1973. A system for
converting English text into speech. IEEE
Transactions on Audio and
Electroacoustics AU-21, pages 288-290.
Bagshaw, Paul C. 1998. Phonemic
transcription by analogy in text-to-speech
synthesis: Novel word pronunciation and
lexicon compression. Computer Speech and
Language, 12:119-142.
Bowles, Richard L. and Robert I. Damper.
1989. Application of Dempster-Shafer
theory of evidence to improved-accuracy,
isolated-word recognition. In Proceedings
of Eurospeech &apos;89, Volume 2, pages 384-387,
Paris.
Brill, Eric and Jun Wu. 1998. Classifier
combination for improved lexical
disambiguation. In COLING-ACL &apos;98: 36th
Annual Meeting of the Association for
Computational Linguistics and the 17th
International Conference on Computational
Linguistics, pages 191-195, Montreal,
Canada.
Byrd, Roy J. and Martin S. Chodorow. 1985.
Using an on-line dictionary to find
rhyming words and pronunciations for
unknown words. In Proceedings of the 23rd
Meeting, pages 277-283, Chicago, IL.
Association for Computational Linguistics.
Carney, Edward. 1994. A Survey of English
Spelling. Routledge, London, UK.
Chomsky, Noam and Morris Halle. 1968.
The Sound Pattern of English. Harper and
Row, New York.
Coltheart, Max. 1978. Lexical access in
simple reading tasks. In G. Underwood,
editor, Strategies of Information Processing.
Academic Press, New York,
pages 151-216.
Coltheart, Max. 1984. Writing systems and
reading disorders. In L. Henderson,
editor, Orthographies and Reading.
Lawrence Erlbaum Associates, London,
UK, pages 67-79.
Daelemans, Walter, Antal van den Bosch,
and Ton Weijters. 1997. IGTree: Using
trees for compression and classification in
lazy learning algorithms. Artificial
Intelligence Review, 11:407-423.
Damper, Robert I. 1995. Self-learning and
connectionist approaches to text-phoneme
conversion. In Joe Levy,
Dimitrios Bairaktaris, John Bullinaria, and
Paul Cairns, editors, Connectionist Models
of Memory and Language. UCL Press,
London, UK, pages 117-144.
Damper, Robert I. and John F. G. Eastmond.
1996. Pronouncing text by analogy. In
Proceedings of the 16th International
Conference on Computational Linguistics,
Volume 2, pages 268-273, Copenhagen,
Denmark.
Damper, Robert I. and John F. G. Eastmond.
1997. Pronunciation by analogy: Impact of
implementational choices on performance.
Language and Speech, 40(1):1-23.
Damper, Robert I., Yannick Marchand,
Martin J. Adamson, and Kjell Gustafson.
1999. Evaluating the pronunciation
component of text-to-speech systems for
English: A performance comparison of
different approaches. Computer Speech and
Language, 13(2):155-176.
Dedina, Michael J. and Howard C.
Nusbaum. 1986. PRONOUNCE: A program
for pronunciation by analogy. Speech
Research Laboratory Progress Report
No. 12, Indiana University, Bloomington,
IN.
Dedina, Michael J. and Howard C.
Nusbaum. 1991. PRONOUNCE: A program
for pronunciation by analogy. Computer
Speech and Language, 5:55-64.
Dietterich, Thomas G. 1997. Machine
learning research: Four current directions.
Al Magazine, 18(4):97-136.
Divay, Michel and Anthony J. Vitale. 1997.
Algorithms for grapheme-phoneme
translation for English and French:
Applications for database searches and
speech synthesis. Computational
Linguistics, 23(4):495-523.
Dutoit, Thierry. 1997. Introduction to
Text-to-Speech Synthesis. Kluwer,
Dordrecht, The Netherlands.
Elovitz, Honey S., Rodney Johnson,
Astrid McHugh, and John E. Shore. 1976.
Letter-to-sound rules for automatic
</reference>
<page confidence="0.991235">
217
</page>
<note confidence="0.640603">
Computational Linguistics Volume 26, Number 2
</note>
<reference confidence="0.997869672131147">
translation of English text to phonetics.
IEEE Transactions on Acoustics, Speech and
Signal Processing ASSP-24, pages 446-459.
Glushko, Robert J. 1979. The organization
and activation of orthographic knowledge
in reading aloud. Journal of Experimental
Psychology: Human Perception and
Performance, 5:674-691.
Golding, Andrew R. 1991. Pronouncing
Names by a Combination of Case-Based and
Rule-Based Reasoning. Ph. D. thesis,
Stanford University, CA.
Golding, Andrew R. and Paul S.
Rosenbloom. 1991. Improving rule-based
systems through case-based reasoning. In
Proceedings of the American Association for
Artificial Intelligence Conference, AAAI-91,
pages 21-27, Anaheim, CA.
Hall, David L. 1992. Mathematical Techniques
in Multisensor Data Fusion. Artech House,
Boston, MA.
Hall, David L. and James Llinas. 1997. An
introduction to multisensor data fusion.
Proceedings of the IEEE, 85(1):6-23.
Hunnicutt, Sheri. 1976. Phonological rules
for a text-to-speech system. American
Journal of Computational Linguistics
Microfiche, 57:1-72.
Jacobs, Robert A., Michael I. Jordan, Steven
J. Nowlan, and Geoffrey E. Hinton. 1991.
Adaptive mixtures of local experts. Neural
Computation, 3:79-87.
Jones, Daniel. 1996. Analogical Natural
Language Processing. UCL Press, London,
UK.
Kay, Janice and Anthony Marcel. 1981. One
process, not two, in reading aloud:
Lexical analogies do the work of
non-lexical rules. Quarterly Journal of
Experimental Psychology, 33A:397-413.
Kittler, Josef, Mohammad Hatef, Robert
P. W. Duirt, and Jiri Matas. 1998. On
combining classifiers. IEEE Transactions on
Pattern Analysis and Machine Intelligence,
20(3):226-239.
Lehnert, Wendy G. 1987. Case-based
problem solving with a large knowledge
base of learned cases. In Proceedings of the
6th National Conference on Artificial
Intelligence, AAAI-87, pages 301-306,
Seattle, WA.
Liberman, Isabelle, Alvin M. Liberman,
Ignatius Mattingly, and Donald
Shankweiler. 1980. Orthography and the
beginning reader. In James F. Kavanagh
and Richard L. Venezky, editors,
Orthography, Reading and Dyslexia.
University Park Press, Baltimore, OH,
pages 137-153.
Lucassen, John M. and Robert L. Mercer.
1984. An information theoretic approach
to the automatic determination of
phonemic baseforms. In Proceedings of the
International Conference on Acoustics, Speech
and Signal Processing, ICASSP-84,
pages 42.5.1-42.5.4, San Diego, CA.
McCulloch, Neil, Mark Bedworth, and
John Bridle. 1987. NETspeak-A
re-implementation of NETtalk. Computer
Speech and Language, 2:289-301.
McIlroy, M. Douglas. 1973. Synthetic English
Speech by Rule. Computer Science
Technical Report No. 14, Bell Telephone
Laboratories.
Post, Emil. 1943. Formal reductions of the
general combinatorial problem. American
Journal of Mathematics, 65:197-268.
Romary, Laurent and Jean-Marie Pierrel.
1989. The use of the Dempster-Shafer rule
in the lexical component of a
man-machine oral dialogue system.
Speech Communication, 8(2):159-176.
Sampson, Geoffrey. 1985. Writing Systems.
Hutchinson, London, UK.
Scragg, David G. 1975. A History of English
Spelling. Manchester University Press,
Manchester, UK.
Sejnowski, Terrence J. and Charles R.
Rosenberg. 1987. Parallel networks that
learn to pronounce English text. Complex
Systems, 1:145-168.
Siegel, Sidney. 1956. Nonparametric Statistics
for the Behavioral Sciences. McGraw-Hill
Kogakusha, Tokyo, Japan.
Stanfill, Craig and David Waltz. 1986.
Toward memory-based reasoning.
Communications of the ACM,
29(12):1213-1228.
Stanfill, Craig W. 1987. Memory-based
reasoning applied to English
pronunciation. In Proceedings of the 6th
National Conference on Artificial Intelligence,
AAAI-87, pages 577-581, Seattle, WA.
Stanfill, Craig W. 1988. Learning to read:
A memory-based model. In Proceedings of
the Case-Based Reasoning Workshop,
pages 406-413, Clearwater Beach, FL.
Sullivan, Kirk P. H. and Robert I. Damper.
1993. Novel-word pronunciation:
A cross-language study. Speech
Communication, 13:441-452.
Turvey, Michael T., Laurie Beth Feldman,
and Georgije Lukatela. 1984. The
Serbo-Croatian orthography constrains
the reader to a phonologically analytic
strategy. In Leslie Henderson, editor,
Orthographies and Reading. Lawrence
Erlbaum Associates, London, UK,
pages 81-89.
van den Bosch, Antal. 1997. Learning to
Pronounce Written Words: A Study in
Inductive Language Learning. Ph. D. thesis,
</reference>
<page confidence="0.990121">
218
</page>
<note confidence="0.83144">
Marchand and Damper Improving Pronunciation by Analogy
</note>
<reference confidence="0.998770680851064">
University of Maastricht, The
Netherlands.
van den Bosch, Antal, Alain Content,
Walter Daelemans, and Beatrice De
Gelder. 1994. Measuring the complexity
of writing systems. Journal of Quantitative
Linguistics, 1(3):178-188.
van den Bosch, Antal and Walter
Daelemans. 1993. Data-oriented methods
for grapheme-to-phoneme conversion. In
Proceedings of the 6th Conference of the
European Chapter of the Association for
Computational Linguistics, pages 45-53,
Utrecht, The Netherlands.
van Halteren, Hans, Jakub Zavrel, and
Walter Daelemans. 1998. Improving data
driven wordclass tagging by system
combination. In COLING-ACL &apos;98: 36th
Annual Meeting of the Association for
Computational Linguistics and the 17th
International Conference on Computational
Linguistics, pages 491-497, Montreal,
Canada.
Venezky, Richard L. 1965. A Study of English
Spelling-to-Sound Correspondences on
Historical Principles. Ann Arbor Press, Ann
Arbor, MI.
Venezky, Richard L. 1970. The Structure of
English Orthography. Mouton, The Hague,
The Netherlands.
Wijk, Axel. 1966. Rules of Pronunciation of the
English Language. Oxford University Press,
Oxford, UK.
Yvon, Francois. 1996. Grapheme-to-
phoneme conversion using multiple
unbounded overlapping chunks. In
Proceedings of the Conference on New Methods
in Natural Language Processing, NeMLaP &apos;96,
pages 218-228, Ankara, Turkey.
Yvon, Francois. 1997. Paradigmatic cascades:
A linguistically sound model of
pronunciation by analogy. In Proceedings
of the 35th Annual Meeting of the Association
for Computational Linguistics and the 8th
Conference of the European Chapter of the
Association for Computational Linguistics,
pages 429-435, Madrid, Spain.
</reference>
<page confidence="0.999215">
219
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.892475">
<title confidence="0.9954345">A Multistrategy Approach to Improving Pronunciation by Analogy</title>
<author confidence="0.998888">Yannick Marchand Robert I Dampert</author>
<affiliation confidence="0.998778">University of Southampton University of Southampton</affiliation>
<abstract confidence="0.994777473684211">Pronunciation by analogy (PbA) is a data-driven method for relating letters to sound, with potential application to next-generation text-to-speech systems. This paper extends previous work on PbA in several directions. First, we have included &amp;quot;full&amp;quot; pattern matching between input letter string and dictionary entries, as well as including lexical stress in letter-to-phoneme conversion. Second, we have extended the method to phoneme-to-letter conversion. Third, and most important, we have experimented with multiple, different strategies for scoring the candidate pronunciations. Individual scores for each strategy are obtained on the basis of rank and either multiplied or summed to produce a final, overall score. Five strategies have been studied and results obtained from all 31 possible combinations. The two combination methods perform comparably, with the product rule only very marginally superior to the sum rule. Nonparametric statistical analysis reveals that performance improves as more strategies are included in the combination: trend is very highly significant (p &lt; for letter-to-phoneme conversion, best results are obtained when all five strategies are combined: word accuracy is raised to 65.5% relative to 61.7% for our best previous result and 63.0% for the best-performing single strategy. improvements are very highly significant (p — p -- Similar results were found for phoneme-to-letter and letter-to-stress conversion, although the former was an easier problem for PbA than letter-to-phoneme conversion and the latter was harder. The main sources of error for the multistrategy approach are very similar to those for the best single strategy, and mostly involve vowel letters and phonemes.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Dean W Abbott</author>
</authors>
<title>Combining models to improve classifier accuracy and robustness.</title>
<date>1999</date>
<booktitle>In Proceedings of Second International Conference on Information Fusion, Fusion &apos;99, Volume I,</booktitle>
<pages>289--295</pages>
<location>Sunnyvale, CA.</location>
<contexts>
<context position="32990" citStr="Abbott (1999" startWordPosition="5124" endWordPosition="5125"> include &amp;quot;voting methods, Bayesian inference, Dempster-Shafer &apos;s method, generalized evidence processing theory, and various ad hoc techniques&amp;quot; (Hall 1992, 135). Clearly, the above characterization is very wide ranging. Consequently, fusion has been applied to a wide variety of pattern recognition and decision theoretic problems— using a plethora of theories, techniques, and tools—including some applications in computational linguistics (e.g., Brill and Wu 1998; van Halteren, Zavrel, and Daelemans 1998) and speech technology (e.g., Bowles and Damper 1989; Romary and Pierre11989). According to Abbott (1999, 290), &amp;quot;While the reasons [that] combining models works so well are not rigorously understood, there is ample evidence that improvements over single models are typical.... A strong case can be made for combining models across algorithm families as a means of providing uncorrelated output estimates.&amp;quot; Our purpose in this paper is to study and exploit such fusion by model (or strategy) combination as a way of achieving performance gains in PbA. 6. Multiple Strategies for PbA We have experimented with five different scoring strategies, used singly and in combination, in an attempt to improve the </context>
</contexts>
<marker>Abbott, 1999</marker>
<rawString>Abbott, Dean W. 1999. Combining models to improve classifier accuracy and robustness. In Proceedings of Second International Conference on Information Fusion, Fusion &apos;99, Volume I, pages 289-295, Sunnyvale, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Abercrombie</author>
</authors>
<title>Extending the Roman alphabet: Some orthographic experiments of the past four centuries.</title>
<date>1981</date>
<booktitle>Towards a History of Phonetics,</booktitle>
<pages>207--224</pages>
<editor>In Ronald E. Asher and Eugenie J. A. Henderson, editors,</editor>
<publisher>Edinburgh University Press,</publisher>
<location>Edinburgh, UK.</location>
<contexts>
<context position="4789" citStr="Abercrombie (1981" startWordPosition="706" endWordPosition="707">missing words are dictionary-like, automatic determination of pronunciation is a hard problem for languages like English and French (van den Bosch et al. 1994). In fact, English is notorious for the lack of regularity in its spelling-to-sound correspondence. That is, it has a deep orthography (Coltheart 1978; Liberman et al. 1980; Sampson 1985) as opposed to the shallow orthography of, for example, Serbo-Croatian (Turvey, Feldman, and Lukatela 1984). To a large extent, this reflects the many complex historical influences on the spelling system (Venezky 1965; Scragg 1975; Carney 1994). Indeed, Abercrombie (1981, 209) describes English orthography as &amp;quot;one of the least successful applications of the Roman alphabet.&amp;quot; We use 26 letters in English orthography yet about 45-55 phonemes in specifying pronunciation. It follows that the relation between letters and phonemes cannot be simply one-to-one. For instance, the letter c is pronounced /s/ in cider but /k/ in cat. On the other hand, the /k/ sound of kitten is written with a letter k. Nor is this lack of invariance between letters and phonemes the only problem. There is no strict correspondence between the number of letters and the number of phonemes in</context>
</contexts>
<marker>Abercrombie, 1981</marker>
<rawString>Abercrombie, David. 1981. Extending the Roman alphabet: Some orthographic experiments of the past four centuries. In Ronald E. Asher and Eugenie J. A. Henderson, editors, Towards a History of Phonetics, pages 207-224. Edinburgh University Press, Edinburgh, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Ainsworth</author>
</authors>
<title>A system for converting English text into speech.</title>
<date>1973</date>
<booktitle>IEEE Transactions on Audio and Electroacoustics AU-21,</booktitle>
<pages>288--290</pages>
<contexts>
<context position="9270" citStr="Ainsworth (1973)" startWordPosition="1415" endWordPosition="1416"> D (1) which states that the letter substring B with left context A and right context C receives the pronunciation (i.e., phoneme substring) D. Such rules can also be straightforwardly cast in the IF. . . THEN form commonly featured in high-level programming languages and employed in expert, knowledge-based systems technology. They also constitute a formal model of universal computation (Post 1943). Conventionally, these rules are specified by an expert linguist, conversant with the sound and spelling systems of the language of concern. Typical letter-to-sound rule sets are those described by Ainsworth (1973), McIlroy (1973), Elovitz et al. (1976), Hurmicutt (1976), and Divay and Vitale (1997). Because of the complexities of English spelling-to-sound correspondence detailed in the previous section, more than one rule generally applies at each stage of transcription. The potential conflicts that arise are resolved by maintaining the rules in a set of sublists, grouped by (initial) letter and with each sublist ordered by specificity. Typically, the most specific rule is at the top and most general at the bottom. In the Elovitz et al. rules, for instance, transcription is a one-pass, left-to-right pr</context>
</contexts>
<marker>Ainsworth, 1973</marker>
<rawString>Ainsworth, William A. 1973. A system for converting English text into speech. IEEE Transactions on Audio and Electroacoustics AU-21, pages 288-290.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul C Bagshaw</author>
</authors>
<title>Phonemic transcription by analogy in text-to-speech synthesis: Novel word pronunciation and lexicon compression.</title>
<date>1998</date>
<journal>Computer Speech and Language,</journal>
<pages>12--119</pages>
<contexts>
<context position="15096" citStr="Bagshaw 1998" startWordPosition="2311" endWordPosition="2312">g Pronunciation by Analogy substrings of known, lexical words, hypothesizing a partial pronunciation for each matched substring from the phonological knowledge, and assembling the partial pronunciations. Although initially it attracted little attention from workers in speech synthesis, several groups around the world are now trying to develop the approach as a backup to dictionary matching. In spite of opinions to the contrary expressed in the literature (see above), there is accumulating evidence that PbA easily outperforms linguistic rewrite rules (Damper and Eastmond 1996, 1997; Yvon 1996; Bagshaw 1998). More recently, Damper et al. (1999) conducted a careful performance evaluation of four techniques for letter-tosound conversion: rules, backpropagation neural networks (Sejnowski and Rosenberg 1987; McCulloch, Bedworth, and Bridle 1987), PbA and the IB1-IG method based on information gain weighting (Daelemans, van den Bosch, and Weijters 1997; van den Bosch 1997). Results showed PbA to be the best of the techniques evaluated by a significant margin. Although one obviously cannot say from a limited evaluation with just three competitors that PbA is the best method available, it is clearly wor</context>
<context position="22986" citStr="Bagshaw 1998" startWordPosition="3561" endWordPosition="3562">vary. In the following, when we refer to a multistrategy approach to PbA, it is principally the use of multiple scoring strategies which is at issue. 3.2 Appraisal PRONOUNCE was evaluated on just 70 monosyllabic pseudowords—a subset of those previously used in reading studies by Glushko (1979). Such a test is largely irrelevant to TTS applications: the test set is not representative of general English, either in the small number of words used or their length. Also, D&amp;N&apos;s claimed results on this pseudoword test set have proved impossible to replicate (Damper and Eastmond 1996, 1997; Yvon 1996; Bagshaw 1998). In addition, no consideration is given to the case where no complete path through the lattice exists (the silence problem mentioned earlier). D&amp;N&apos;s pattern matching (when building the pronunciation lattice) is a &amp;quot;partial&amp;quot; one. That is, as explained in section 3.1.1, the process starts with the leftmost letter of the input string and of the current dictionary entry aligned and continues until the two are right-aligned. They give (on page 59) the example of the input word blope matching to the lexical entry sloping. At the first iteration, the initial b of blope aligns with the initial s of sl</context>
</contexts>
<marker>Bagshaw, 1998</marker>
<rawString>Bagshaw, Paul C. 1998. Phonemic transcription by analogy in text-to-speech synthesis: Novel word pronunciation and lexicon compression. Computer Speech and Language, 12:119-142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard L Bowles</author>
<author>Robert I Damper</author>
</authors>
<title>Application of Dempster-Shafer theory of evidence to improved-accuracy, isolated-word recognition.</title>
<date>1989</date>
<booktitle>In Proceedings of Eurospeech &apos;89,</booktitle>
<volume>2</volume>
<pages>384--387</pages>
<location>Paris.</location>
<contexts>
<context position="32938" citStr="Bowles and Damper 1989" startWordPosition="5115" endWordPosition="5118">of the data are unknown&amp;quot; (p. 8). Methods of information fusion include &amp;quot;voting methods, Bayesian inference, Dempster-Shafer &apos;s method, generalized evidence processing theory, and various ad hoc techniques&amp;quot; (Hall 1992, 135). Clearly, the above characterization is very wide ranging. Consequently, fusion has been applied to a wide variety of pattern recognition and decision theoretic problems— using a plethora of theories, techniques, and tools—including some applications in computational linguistics (e.g., Brill and Wu 1998; van Halteren, Zavrel, and Daelemans 1998) and speech technology (e.g., Bowles and Damper 1989; Romary and Pierre11989). According to Abbott (1999, 290), &amp;quot;While the reasons [that] combining models works so well are not rigorously understood, there is ample evidence that improvements over single models are typical.... A strong case can be made for combining models across algorithm families as a means of providing uncorrelated output estimates.&amp;quot; Our purpose in this paper is to study and exploit such fusion by model (or strategy) combination as a way of achieving performance gains in PbA. 6. Multiple Strategies for PbA We have experimented with five different scoring strategies, used sing</context>
</contexts>
<marker>Bowles, Damper, 1989</marker>
<rawString>Bowles, Richard L. and Robert I. Damper. 1989. Application of Dempster-Shafer theory of evidence to improved-accuracy, isolated-word recognition. In Proceedings of Eurospeech &apos;89, Volume 2, pages 384-387, Paris.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
<author>Jun Wu</author>
</authors>
<title>Classifier combination for improved lexical disambiguation.</title>
<date>1998</date>
<booktitle>In COLING-ACL &apos;98: 36th Annual Meeting of the Association for Computational Linguistics and the 17th International Conference on Computational Linguistics,</booktitle>
<pages>191--195</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="32843" citStr="Brill and Wu 1998" startWordPosition="5101" endWordPosition="5104">, good) data with inaccurate or biased data, especially if the uncertainties or variances of the data are unknown&amp;quot; (p. 8). Methods of information fusion include &amp;quot;voting methods, Bayesian inference, Dempster-Shafer &apos;s method, generalized evidence processing theory, and various ad hoc techniques&amp;quot; (Hall 1992, 135). Clearly, the above characterization is very wide ranging. Consequently, fusion has been applied to a wide variety of pattern recognition and decision theoretic problems— using a plethora of theories, techniques, and tools—including some applications in computational linguistics (e.g., Brill and Wu 1998; van Halteren, Zavrel, and Daelemans 1998) and speech technology (e.g., Bowles and Damper 1989; Romary and Pierre11989). According to Abbott (1999, 290), &amp;quot;While the reasons [that] combining models works so well are not rigorously understood, there is ample evidence that improvements over single models are typical.... A strong case can be made for combining models across algorithm families as a means of providing uncorrelated output estimates.&amp;quot; Our purpose in this paper is to study and exploit such fusion by model (or strategy) combination as a way of achieving performance gains in PbA. 6. Mul</context>
</contexts>
<marker>Brill, Wu, 1998</marker>
<rawString>Brill, Eric and Jun Wu. 1998. Classifier combination for improved lexical disambiguation. In COLING-ACL &apos;98: 36th Annual Meeting of the Association for Computational Linguistics and the 17th International Conference on Computational Linguistics, pages 191-195, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roy J Byrd</author>
<author>Martin S Chodorow</author>
</authors>
<title>Using an on-line dictionary to find rhyming words and pronunciations for unknown words.</title>
<date>1985</date>
<booktitle>In Proceedings of the 23rd Meeting,</booktitle>
<pages>277--283</pages>
<publisher>Association for</publisher>
<institution>Computational Linguistics.</institution>
<location>Chicago, IL.</location>
<contexts>
<context position="13692" citStr="Byrd and Chodorow (1985)" startWordPosition="2110" endWordPosition="2113">t (yet) reached the level of rule sets developed by humans&amp;quot; (p. 520). Dutoit (1997) takes this further, stating &amp;quot;such training-based strategies are often assumed to exhibit much more intelligence than they do in practice, as revealed by their poor transcription scores&amp;quot; (p. 115, note 14). Pronunciation by analogy (PbA) is a data-driven technique for the automatic phonemization of text, originally proposed as a model of reading, e.g., by Glushko (1979) and Kay and Marcel (1981). It was first proposed for ITS applications over a decade ago by Dedina and Nusbaum (1986, 1991). See also the work of Byrd and Chodorow (1985), which considers computer-based pronunciation by analogy but does not mention the possible application to text-to-speech synthesis. As detailed by Damper (1995) and Damper and Eastmond (1997), PbA shares many similarities with the artificial intelligence paradigms variously called case-based, memory-based, or instance-based reasoning as applied to letter-to-phoneme conversion (Stanfill and Waltz 1986; Lehnert 1987; Stanfill 1987, 1988; Golding 1991; Golding and Rosenbloom 1991; van den Bosch and Daelemans 1993). PbA exploits the phonological knowledge implicitly contained in a dictionary of w</context>
</contexts>
<marker>Byrd, Chodorow, 1985</marker>
<rawString>Byrd, Roy J. and Martin S. Chodorow. 1985. Using an on-line dictionary to find rhyming words and pronunciations for unknown words. In Proceedings of the 23rd Meeting, pages 277-283, Chicago, IL. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Carney</author>
</authors>
<title>A Survey of English Spelling.</title>
<date>1994</date>
<location>Routledge, London, UK.</location>
<contexts>
<context position="4762" citStr="Carney 1994" startWordPosition="703" endWordPosition="704">ologisms. Even if the missing words are dictionary-like, automatic determination of pronunciation is a hard problem for languages like English and French (van den Bosch et al. 1994). In fact, English is notorious for the lack of regularity in its spelling-to-sound correspondence. That is, it has a deep orthography (Coltheart 1978; Liberman et al. 1980; Sampson 1985) as opposed to the shallow orthography of, for example, Serbo-Croatian (Turvey, Feldman, and Lukatela 1984). To a large extent, this reflects the many complex historical influences on the spelling system (Venezky 1965; Scragg 1975; Carney 1994). Indeed, Abercrombie (1981, 209) describes English orthography as &amp;quot;one of the least successful applications of the Roman alphabet.&amp;quot; We use 26 letters in English orthography yet about 45-55 phonemes in specifying pronunciation. It follows that the relation between letters and phonemes cannot be simply one-to-one. For instance, the letter c is pronounced /s/ in cider but /k/ in cat. On the other hand, the /k/ sound of kitten is written with a letter k. Nor is this lack of invariance between letters and phonemes the only problem. There is no strict correspondence between the number of letters an</context>
</contexts>
<marker>Carney, 1994</marker>
<rawString>Carney, Edward. 1994. A Survey of English Spelling. Routledge, London, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noam Chomsky</author>
<author>Morris Halle</author>
</authors>
<title>The Sound Pattern of English. Harper and Row,</title>
<date>1968</date>
<location>New York.</location>
<contexts>
<context position="8637" citStr="Chomsky and Halle 1968" startWordPosition="1316" endWordPosition="1319">at all? It is generally believed that the problem is largely soluble provided sufficient context is available. For example, the substring ough is pronounced /o2.3/ when its left context is th in the word although, /u/ when its left context is thr in the word through, and /Af/ when its left context is en in the word enough: in each case, the right context is the word delimiter symbol. In view of this, context-dependent rewrite rules have been a popular formalism for the backup pronunciation strategy in TTS systems. The form of the rules, strongly inspired by concepts from generative phonology (Chomsky and Halle 1968, 14), is: A [B]C D (1) which states that the letter substring B with left context A and right context C receives the pronunciation (i.e., phoneme substring) D. Such rules can also be straightforwardly cast in the IF. . . THEN form commonly featured in high-level programming languages and employed in expert, knowledge-based systems technology. They also constitute a formal model of universal computation (Post 1943). Conventionally, these rules are specified by an expert linguist, conversant with the sound and spelling systems of the language of concern. Typical letter-to-sound rule sets are th</context>
</contexts>
<marker>Chomsky, Halle, 1968</marker>
<rawString>Chomsky, Noam and Morris Halle. 1968. The Sound Pattern of English. Harper and Row, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Max Coltheart</author>
</authors>
<title>Lexical access in simple reading tasks.</title>
<date>1978</date>
<booktitle>Strategies of Information Processing.</booktitle>
<pages>151--216</pages>
<editor>In G. Underwood, editor,</editor>
<publisher>Academic Press,</publisher>
<location>New York,</location>
<contexts>
<context position="4481" citStr="Coltheart 1978" startWordPosition="661" endWordPosition="662"> latter are mostly (but not exclusively) proper names, acronyms, and neologisms. At this stage of our work, we concentrate on English and assume that any such missing words are dictionary-like with respect to their spelling and pronunciation, as will probably be the case for many neologisms. Even if the missing words are dictionary-like, automatic determination of pronunciation is a hard problem for languages like English and French (van den Bosch et al. 1994). In fact, English is notorious for the lack of regularity in its spelling-to-sound correspondence. That is, it has a deep orthography (Coltheart 1978; Liberman et al. 1980; Sampson 1985) as opposed to the shallow orthography of, for example, Serbo-Croatian (Turvey, Feldman, and Lukatela 1984). To a large extent, this reflects the many complex historical influences on the spelling system (Venezky 1965; Scragg 1975; Carney 1994). Indeed, Abercrombie (1981, 209) describes English orthography as &amp;quot;one of the least successful applications of the Roman alphabet.&amp;quot; We use 26 letters in English orthography yet about 45-55 phonemes in specifying pronunciation. It follows that the relation between letters and phonemes cannot be simply one-to-one. For </context>
</contexts>
<marker>Coltheart, 1978</marker>
<rawString>Coltheart, Max. 1978. Lexical access in simple reading tasks. In G. Underwood, editor, Strategies of Information Processing. Academic Press, New York, pages 151-216.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Max Coltheart</author>
</authors>
<title>Writing systems and reading disorders.</title>
<date>1984</date>
<booktitle>Orthographies and Reading.</booktitle>
<editor>In L. Henderson, editor,</editor>
<contexts>
<context position="5503" citStr="Coltheart 1984" startWordPosition="825" endWordPosition="826">abet.&amp;quot; We use 26 letters in English orthography yet about 45-55 phonemes in specifying pronunciation. It follows that the relation between letters and phonemes cannot be simply one-to-one. For instance, the letter c is pronounced /s/ in cider but /k/ in cat. On the other hand, the /k/ sound of kitten is written with a letter k. Nor is this lack of invariance between letters and phonemes the only problem. There is no strict correspondence between the number of letters and the number of phonemes in English words. Letter combinations (ch, gh, 11, ea) frequently act as a functional spelling unit (Coltheart 1984)—or grapheme—signaling a single phoneme. Thus, the combination ough is pronounced /Af/ in enough, while ph is pronounced as the single phoneme /f/ in phase. However, ph in uphill is pronounced as two phonemes, !ph!. Usually, there are fewer phonemes than letters but there are exceptions, e.g., (six, /sIks/). Pronunciation can depend upon word class (e.g., convict, subject). English also has noncontiguous markings (Wijk 1966; Venezky 1970) as, for instance, when the letter e is added to (mad, /mad/) to make (made, !meld!), also spelled maid! The final e is not sounded; rather it indicates that </context>
</contexts>
<marker>Coltheart, 1984</marker>
<rawString>Coltheart, Max. 1984. Writing systems and reading disorders. In L. Henderson, editor, Orthographies and Reading.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Lawrence</author>
</authors>
<title>Erlbaum Associates,</title>
<pages>67--79</pages>
<location>London, UK,</location>
<marker>Lawrence, </marker>
<rawString>Lawrence Erlbaum Associates, London, UK, pages 67-79.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Daelemans</author>
<author>Antal van den Bosch</author>
<author>Ton Weijters</author>
</authors>
<title>IGTree: Using trees for compression and classification in lazy learning algorithms.</title>
<date>1997</date>
<journal>Artificial Intelligence Review,</journal>
<pages>11--407</pages>
<marker>Daelemans, van den Bosch, Weijters, 1997</marker>
<rawString>Daelemans, Walter, Antal van den Bosch, and Ton Weijters. 1997. IGTree: Using trees for compression and classification in lazy learning algorithms. Artificial Intelligence Review, 11:407-423.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert I Damper</author>
</authors>
<title>Self-learning and connectionist approaches to text-phoneme conversion.</title>
<date>1995</date>
<booktitle>In Joe Levy,</booktitle>
<contexts>
<context position="11912" citStr="Damper (1995)" startWordPosition="1833" endWordPosition="1834"> practical system implementation perspectives—it does have its problems. From a practical point of view, the task of manually writing such a set of rules, deciding the rule order so as to resolve conflicts appropriately, maintaining the rules as mispronunciations are discovered, etc., is very considerable and requires an expert depth of knowledge of the specific language. For these reasons, and especially to ease the problem of creating a TTS system for a new language, more recent attention has focused on the application of automatic techniques based on machine learning from large corpora—see Damper (1995) for a comprehensive review, van den Bosch (1997) for more recent discussion, and Dietterich (1997) for an accessible review of the underpinning machine learning methodologies. The rule-based approach has also been challenged from a more theoretical point of view. For instance, Jones (1996, 1) describes the goal of his book Analogical Natural Language Processing as: to challenge the currently predominant assumption in the field of natural language processing that the representation of language should be done within the rule-based paradigm alone. For historical reasons, this traditional positio</context>
<context position="13853" citStr="Damper (1995)" startWordPosition="2133" endWordPosition="2134"> much more intelligence than they do in practice, as revealed by their poor transcription scores&amp;quot; (p. 115, note 14). Pronunciation by analogy (PbA) is a data-driven technique for the automatic phonemization of text, originally proposed as a model of reading, e.g., by Glushko (1979) and Kay and Marcel (1981). It was first proposed for ITS applications over a decade ago by Dedina and Nusbaum (1986, 1991). See also the work of Byrd and Chodorow (1985), which considers computer-based pronunciation by analogy but does not mention the possible application to text-to-speech synthesis. As detailed by Damper (1995) and Damper and Eastmond (1997), PbA shares many similarities with the artificial intelligence paradigms variously called case-based, memory-based, or instance-based reasoning as applied to letter-to-phoneme conversion (Stanfill and Waltz 1986; Lehnert 1987; Stanfill 1987, 1988; Golding 1991; Golding and Rosenbloom 1991; van den Bosch and Daelemans 1993). PbA exploits the phonological knowledge implicitly contained in a dictionary of words and their corresponding pronunciations. The underlying idea is that a pronunciation for an unknown word is derived by matching substrings of the input to 19</context>
</contexts>
<marker>Damper, 1995</marker>
<rawString>Damper, Robert I. 1995. Self-learning and connectionist approaches to text-phoneme conversion. In Joe Levy,</rawString>
</citation>
<citation valid="false">
<booktitle>Connectionist Models of Memory and Language.</booktitle>
<pages>117--144</pages>
<editor>Dimitrios Bairaktaris, John Bullinaria, and Paul Cairns, editors,</editor>
<publisher>UCL Press,</publisher>
<location>London, UK,</location>
<marker></marker>
<rawString>Dimitrios Bairaktaris, John Bullinaria, and Paul Cairns, editors, Connectionist Models of Memory and Language. UCL Press, London, UK, pages 117-144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert I Damper</author>
<author>John F G Eastmond</author>
</authors>
<title>Pronouncing text by analogy.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics,</booktitle>
<volume>2</volume>
<pages>268--273</pages>
<location>Copenhagen, Denmark.</location>
<contexts>
<context position="15064" citStr="Damper and Eastmond 1996" startWordPosition="2304" endWordPosition="2307">e input to 198 Marchand and Damper Improving Pronunciation by Analogy substrings of known, lexical words, hypothesizing a partial pronunciation for each matched substring from the phonological knowledge, and assembling the partial pronunciations. Although initially it attracted little attention from workers in speech synthesis, several groups around the world are now trying to develop the approach as a backup to dictionary matching. In spite of opinions to the contrary expressed in the literature (see above), there is accumulating evidence that PbA easily outperforms linguistic rewrite rules (Damper and Eastmond 1996, 1997; Yvon 1996; Bagshaw 1998). More recently, Damper et al. (1999) conducted a careful performance evaluation of four techniques for letter-tosound conversion: rules, backpropagation neural networks (Sejnowski and Rosenberg 1987; McCulloch, Bedworth, and Bridle 1987), PbA and the IB1-IG method based on information gain weighting (Daelemans, van den Bosch, and Weijters 1997; van den Bosch 1997). Results showed PbA to be the best of the techniques evaluated by a significant margin. Although one obviously cannot say from a limited evaluation with just three competitors that PbA is the best met</context>
<context position="22954" citStr="Damper and Eastmond 1996" startWordPosition="3554" endWordPosition="3557">ion on which different versions of PbA can vary. In the following, when we refer to a multistrategy approach to PbA, it is principally the use of multiple scoring strategies which is at issue. 3.2 Appraisal PRONOUNCE was evaluated on just 70 monosyllabic pseudowords—a subset of those previously used in reading studies by Glushko (1979). Such a test is largely irrelevant to TTS applications: the test set is not representative of general English, either in the small number of words used or their length. Also, D&amp;N&apos;s claimed results on this pseudoword test set have proved impossible to replicate (Damper and Eastmond 1996, 1997; Yvon 1996; Bagshaw 1998). In addition, no consideration is given to the case where no complete path through the lattice exists (the silence problem mentioned earlier). D&amp;N&apos;s pattern matching (when building the pronunciation lattice) is a &amp;quot;partial&amp;quot; one. That is, as explained in section 3.1.1, the process starts with the leftmost letter of the input string and of the current dictionary entry aligned and continues until the two are right-aligned. They give (on page 59) the example of the input word blope matching to the lexical entry sloping. At the first iteration, the initial b of blope</context>
<context position="24761" citStr="Damper and Eastmond 1996" startWordPosition="3854" endWordPosition="3857">ull&amp;quot; as opposed to &amp;quot;partial&amp;quot; matching. (Note that the simplified pronunciation lattice depicted in Figure 1 was obtained using full pattern matching.) One conceivable objection to partial pattern matching is that some morphemes can act both as prefix and suffix (e.g., someBODY and BODY guard). From this point of view, full matching seems worth consideration. A linguistic justification for the full method is that affixation is often implicated in the creation of new words. 4. Previous Work and Extensions In this section, we briefly review our previous work on a single-strategy approach to PbA (Damper and Eastmond 1996, 1997). The basic purpose of the earlier work was to reimplement D&amp;N&apos;s system but to improve the scoring heuristic used to find the best path through the pronunciation lattice. To have a more realistic and relevant evaluation on a large corpus of real words, as opposed to a small set of pseudowords, we adopted the methodology of removing each word in turn from the lexicon and 201 Computational Linguistics Volume 26, Number 2 deriving a pronunciation by analogy with the remaining words. In the terminology of machine learning, this is called leave-one-out or n-fold cross validation (Daelemans, </context>
</contexts>
<marker>Damper, Eastmond, 1996</marker>
<rawString>Damper, Robert I. and John F. G. Eastmond. 1996. Pronouncing text by analogy. In Proceedings of the 16th International Conference on Computational Linguistics, Volume 2, pages 268-273, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert I Damper</author>
<author>John F G Eastmond</author>
</authors>
<title>Pronunciation by analogy: Impact of implementational choices on performance. Language and Speech,</title>
<date>1997</date>
<pages>40--1</pages>
<contexts>
<context position="13884" citStr="Damper and Eastmond (1997)" startWordPosition="2136" endWordPosition="2139">gence than they do in practice, as revealed by their poor transcription scores&amp;quot; (p. 115, note 14). Pronunciation by analogy (PbA) is a data-driven technique for the automatic phonemization of text, originally proposed as a model of reading, e.g., by Glushko (1979) and Kay and Marcel (1981). It was first proposed for ITS applications over a decade ago by Dedina and Nusbaum (1986, 1991). See also the work of Byrd and Chodorow (1985), which considers computer-based pronunciation by analogy but does not mention the possible application to text-to-speech synthesis. As detailed by Damper (1995) and Damper and Eastmond (1997), PbA shares many similarities with the artificial intelligence paradigms variously called case-based, memory-based, or instance-based reasoning as applied to letter-to-phoneme conversion (Stanfill and Waltz 1986; Lehnert 1987; Stanfill 1987, 1988; Golding 1991; Golding and Rosenbloom 1991; van den Bosch and Daelemans 1993). PbA exploits the phonological knowledge implicitly contained in a dictionary of words and their corresponding pronunciations. The underlying idea is that a pronunciation for an unknown word is derived by matching substrings of the input to 198 Marchand and Damper Improving</context>
<context position="16067" citStr="Damper and Eastmond 1997" startWordPosition="2457" endWordPosition="2460"> van den Bosch 1997). Results showed PbA to be the best of the techniques evaluated by a significant margin. Although one obviously cannot say from a limited evaluation with just three competitors that PbA is the best method available, it is clearly worthy of serious consideration and further development. This paper marks a stage of that development. As a psychological (or theoretical) model, PbA is &amp;quot;seriously underspecified&amp;quot; so that the implementor wishing to use analogy within the pronunciation component of a TTS system &amp;quot;faces detailed choices which can only be resolved by trial and error&amp;quot; (Damper and Eastmond 1997, 1). The impact of implementational choices on performance has been studied by Sullivan and Damper (1993), Damper and Eastmond (1996, 1997), and Yvon (1996, 1997). One important dimension on which implementations vary is the strategy used to score the candidate pronunciations that PbA produces. By and large, these investigators have sought the single best pronunciation strategy. However, the range of choices is wide, so that some rather different implementations with different performance can be produced, yet these are all (in some sense) pronunciation by analogy. This raises the possibility,</context>
<context position="30135" citStr="Damper and Eastmond 1997" startWordPosition="4706" endWordPosition="4709">notation) were removed from this corpus. This left 19,544 pronunciations. Finally, we have used analogy to map letters to digit-stress patterns. 4.2 Best Preliminary Results Preliminary results were obtained using a single scoring strategy in order to provide a baseline for comparison with the multistrategy approach to be described shortly. The best results (Table 2) for the three conversions—letter-to-phoneme, phoneme-to-letter, and letter-to-stress—were obtained by full pattern matching and using a weighted total product (TP) scoring. The latter is similar to Damper and Eastmond&apos;s TP score (Damper and Eastmond 1997), i.e., the sum of the product of the arc frequencies for all shortest paths giving the same pronunciation. In this case, however, each contribution to the total product is weighted by the number of letters associated with each arc. Table 2 Best single-strategy results (% correct) for the three conversion problems studied: letter-to-phoneme, phoneme-to-letter, and letter-to-stress. These were obtained by full pattern matching and using a weighted total product (TP) scoring. Letter-to-phoneme Phoneme-to-letter Letter-to-stress Words Letters Pronunciations Phonemes Words Letters 61.7 91.6 74.4 9</context>
<context position="31496" citStr="Damper and Eastmond (1997" startWordPosition="4909" endWordPosition="4912">ct was 41.8%. By use of a very simple strategy for silence avoidance, the results for letterto-phoneme conversion were marginally increased from 61.7% to 61.9% words correct and from 91.6% to 91.8% phonemes correct. The strategy adopted was simply to add a (null-labeled) arc in the case that there was no complete path through the pronunciation lattice, and a single break occurred between adjacent nodes. This corresponds to concatenation of two otherwise complete word fragments. These best results should be compared with 60.7% words correct and 91.2% phonemes correct, as previously obtained by Damper and Eastmond (1997, Table 2). 5. Information Fusion in Computational Linguistics In the introduction, we stated that our multistrategy approach is a special case of information (or data) fusion. What precisely is this? According to Hall and Llinas (1997, 7-8): The most fundamental characterization of... fusion involves a hierarchical transformation between observed ... parameters (provided by multiple sources as input) and a decision or inference. In principle, &amp;quot;fusion provides significant advantages over single source data&amp;quot; including &amp;quot;the statistical advantage gained by combining same-source data (e.g., obtain</context>
</contexts>
<marker>Damper, Eastmond, 1997</marker>
<rawString>Damper, Robert I. and John F. G. Eastmond. 1997. Pronunciation by analogy: Impact of implementational choices on performance. Language and Speech, 40(1):1-23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert I Damper</author>
<author>Yannick Marchand</author>
<author>Martin J Adamson</author>
<author>Kjell Gustafson</author>
</authors>
<title>Evaluating the pronunciation component of text-to-speech systems for English: A performance comparison of different approaches.</title>
<date>1999</date>
<journal>Computer Speech and Language,</journal>
<pages>13--2</pages>
<contexts>
<context position="15133" citStr="Damper et al. (1999)" startWordPosition="2315" endWordPosition="2318">strings of known, lexical words, hypothesizing a partial pronunciation for each matched substring from the phonological knowledge, and assembling the partial pronunciations. Although initially it attracted little attention from workers in speech synthesis, several groups around the world are now trying to develop the approach as a backup to dictionary matching. In spite of opinions to the contrary expressed in the literature (see above), there is accumulating evidence that PbA easily outperforms linguistic rewrite rules (Damper and Eastmond 1996, 1997; Yvon 1996; Bagshaw 1998). More recently, Damper et al. (1999) conducted a careful performance evaluation of four techniques for letter-tosound conversion: rules, backpropagation neural networks (Sejnowski and Rosenberg 1987; McCulloch, Bedworth, and Bridle 1987), PbA and the IB1-IG method based on information gain weighting (Daelemans, van den Bosch, and Weijters 1997; van den Bosch 1997). Results showed PbA to be the best of the techniques evaluated by a significant margin. Although one obviously cannot say from a limited evaluation with just three competitors that PbA is the best method available, it is clearly worthy of serious consideration and furt</context>
</contexts>
<marker>Damper, Marchand, Adamson, Gustafson, 1999</marker>
<rawString>Damper, Robert I., Yannick Marchand, Martin J. Adamson, and Kjell Gustafson. 1999. Evaluating the pronunciation component of text-to-speech systems for English: A performance comparison of different approaches. Computer Speech and Language, 13(2):155-176.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Michael J Dedina</author>
<author>C Howard</author>
</authors>
<marker>Dedina, Howard, </marker>
<rawString>Dedina, Michael J. and Howard C.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nusbaum</author>
</authors>
<title>PRONOUNCE: A program for pronunciation by analogy.</title>
<date>1986</date>
<tech>Report No. 12,</tech>
<institution>Speech Research Laboratory Progress</institution>
<location>Bloomington, IN.</location>
<contexts>
<context position="7327" citStr="Nusbaum (1986)" startWordPosition="1103" endWordPosition="1104">s. Specifically, we aim to improve the performance of pronunciation by analogy (PbA) by information fusion, an approach to automated reasoning that seeks to utilize multiple sources of information in reaching a decision— in this case, a decision about the pronunciation of a word. The remainder of this paper is organized as follows: In the next section, we contrast traditional rule-based and more modern data-driven approaches (e.g., analogical reasoning) to language processing tasks, such as text-to-phoneme conversion. In Section 3, we describe the original (PRONOUNCE) PbA system of Dedina and Nusbaum (1986) in some detail as this forms the basis for the later work. Section 4 reviews our own work in this area. Next, in Section 5, we make some motivating remarks about information fusion and its use in computational linguistics in general. In Section 6, we present in some detail the 196 Marchand and Damper Improving Pronunciation by Analogy multistrategy (or fusion) approach to PbA that enables us to obtain clear performance improvements, as described in Section 7. Finally, conclusions are drawn and directions for future studies are proposed in Section 8. 2. Rule-based and Data-driven Conversion Gi</context>
<context position="13638" citStr="Nusbaum (1986" startWordPosition="2102" endWordPosition="2103">ing algorithms, although promising, have not (yet) reached the level of rule sets developed by humans&amp;quot; (p. 520). Dutoit (1997) takes this further, stating &amp;quot;such training-based strategies are often assumed to exhibit much more intelligence than they do in practice, as revealed by their poor transcription scores&amp;quot; (p. 115, note 14). Pronunciation by analogy (PbA) is a data-driven technique for the automatic phonemization of text, originally proposed as a model of reading, e.g., by Glushko (1979) and Kay and Marcel (1981). It was first proposed for ITS applications over a decade ago by Dedina and Nusbaum (1986, 1991). See also the work of Byrd and Chodorow (1985), which considers computer-based pronunciation by analogy but does not mention the possible application to text-to-speech synthesis. As detailed by Damper (1995) and Damper and Eastmond (1997), PbA shares many similarities with the artificial intelligence paradigms variously called case-based, memory-based, or instance-based reasoning as applied to letter-to-phoneme conversion (Stanfill and Waltz 1986; Lehnert 1987; Stanfill 1987, 1988; Golding 1991; Golding and Rosenbloom 1991; van den Bosch and Daelemans 1993). PbA exploits the phonologic</context>
</contexts>
<marker>Nusbaum, 1986</marker>
<rawString>Nusbaum. 1986. PRONOUNCE: A program for pronunciation by analogy. Speech Research Laboratory Progress Report No. 12, Indiana University, Bloomington, IN.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael J Dedina</author>
<author>Howard C Nusbaum</author>
</authors>
<title>PRONOUNCE: A program for pronunciation by analogy.</title>
<date>1991</date>
<journal>Computer Speech and Language,</journal>
<pages>5--55</pages>
<marker>Dedina, Nusbaum, 1991</marker>
<rawString>Dedina, Michael J. and Howard C. Nusbaum. 1991. PRONOUNCE: A program for pronunciation by analogy. Computer Speech and Language, 5:55-64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas G Dietterich</author>
</authors>
<title>Machine learning research: Four current directions.</title>
<date>1997</date>
<journal>Al Magazine,</journal>
<pages>18--4</pages>
<contexts>
<context position="12011" citStr="Dietterich (1997)" startWordPosition="1848" endWordPosition="1849"> of view, the task of manually writing such a set of rules, deciding the rule order so as to resolve conflicts appropriately, maintaining the rules as mispronunciations are discovered, etc., is very considerable and requires an expert depth of knowledge of the specific language. For these reasons, and especially to ease the problem of creating a TTS system for a new language, more recent attention has focused on the application of automatic techniques based on machine learning from large corpora—see Damper (1995) for a comprehensive review, van den Bosch (1997) for more recent discussion, and Dietterich (1997) for an accessible review of the underpinning machine learning methodologies. The rule-based approach has also been challenged from a more theoretical point of view. For instance, Jones (1996, 1) describes the goal of his book Analogical Natural Language Processing as: to challenge the currently predominant assumption in the field of natural language processing that the representation of language should be done within the rule-based paradigm alone. For historical reasons, this traditional position is largely the result of the influence of Chomsky and his efforts to define language in terms of </context>
<context position="17317" citStr="Dietterich 1997" startWordPosition="2655" endWordPosition="2656">s paper, that different multiple PbA strategies—whose outputs are combined to give the final pronunciation—might be used to good effect. If the different strategies make different errors, then it is conceivable that such a multistrategy approach can produce a lower error rate than even the best single strategy. Indeed, it may be that a strategy with a poor performance by itself can make a positive overall contribution to high-accuracy pronunciation derivation when used in concert with other strategies. It can be viewed as a &amp;quot;specialist&amp;quot; within a committee of experts (e.g., Jacobs et al. 1991; Dietterich 1997): most often its opinion is invalid, but occasionally—for inputs within its sphere of expertise—it produces the correct answer when the other &amp;quot;generalist&amp;quot; strategies do not. There is currently much interest in the topic of information fusion in a wide variety of application settings. This work can be seen as a specific instance of information fusion. 3. Dedina and Nusbaum&apos;s System The results reported here were obtained using an extended and improved version of PRONOUNCE, the Dedina and Nusbaum (D&amp;N) system, which we now describe. 3.1 Principles The basic PRONOUNCE system consists of four comp</context>
</contexts>
<marker>Dietterich, 1997</marker>
<rawString>Dietterich, Thomas G. 1997. Machine learning research: Four current directions. Al Magazine, 18(4):97-136.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Divay</author>
<author>Anthony J Vitale</author>
</authors>
<title>Algorithms for grapheme-phoneme translation for English and French: Applications for database searches and speech synthesis.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<pages>23--4</pages>
<contexts>
<context position="9356" citStr="Divay and Vitale (1997)" startWordPosition="1426" endWordPosition="1429">ontext C receives the pronunciation (i.e., phoneme substring) D. Such rules can also be straightforwardly cast in the IF. . . THEN form commonly featured in high-level programming languages and employed in expert, knowledge-based systems technology. They also constitute a formal model of universal computation (Post 1943). Conventionally, these rules are specified by an expert linguist, conversant with the sound and spelling systems of the language of concern. Typical letter-to-sound rule sets are those described by Ainsworth (1973), McIlroy (1973), Elovitz et al. (1976), Hurmicutt (1976), and Divay and Vitale (1997). Because of the complexities of English spelling-to-sound correspondence detailed in the previous section, more than one rule generally applies at each stage of transcription. The potential conflicts that arise are resolved by maintaining the rules in a set of sublists, grouped by (initial) letter and with each sublist ordered by specificity. Typically, the most specific rule is at the top and most general at the bottom. In the Elovitz et al. rules, for instance, transcription is a one-pass, left-to-right process. For the particular target letter (i.e., the initial letter of the substring cur</context>
<context position="12984" citStr="Divay and Vitale (1997)" startWordPosition="1995" endWordPosition="1998">ge processing that the representation of language should be done within the rule-based paradigm alone. For historical reasons, this traditional position is largely the result of the influence of Chomsky and his efforts to define language in terms of formal mathematics.... The contrasting view, taken here, is that language is not something that can be described in a neat and tidy way. This is also the perspective adopted here. It is also conceivable that data-driven techniques can actually outperform traditional rules. However, this possibility is not usually given much credence. For instance, Divay and Vitale (1997) recently wrote: &amp;quot;To our knowledge, learning algorithms, although promising, have not (yet) reached the level of rule sets developed by humans&amp;quot; (p. 520). Dutoit (1997) takes this further, stating &amp;quot;such training-based strategies are often assumed to exhibit much more intelligence than they do in practice, as revealed by their poor transcription scores&amp;quot; (p. 115, note 14). Pronunciation by analogy (PbA) is a data-driven technique for the automatic phonemization of text, originally proposed as a model of reading, e.g., by Glushko (1979) and Kay and Marcel (1981). It was first proposed for ITS appl</context>
</contexts>
<marker>Divay, Vitale, 1997</marker>
<rawString>Divay, Michel and Anthony J. Vitale. 1997. Algorithms for grapheme-phoneme translation for English and French: Applications for database searches and speech synthesis. Computational Linguistics, 23(4):495-523.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thierry Dutoit</author>
</authors>
<title>Introduction to Text-to-Speech Synthesis.</title>
<date>1997</date>
<publisher>Kluwer,</publisher>
<location>Dordrecht, The Netherlands.</location>
<contexts>
<context position="13151" citStr="Dutoit (1997)" startWordPosition="2024" endWordPosition="2025"> the influence of Chomsky and his efforts to define language in terms of formal mathematics.... The contrasting view, taken here, is that language is not something that can be described in a neat and tidy way. This is also the perspective adopted here. It is also conceivable that data-driven techniques can actually outperform traditional rules. However, this possibility is not usually given much credence. For instance, Divay and Vitale (1997) recently wrote: &amp;quot;To our knowledge, learning algorithms, although promising, have not (yet) reached the level of rule sets developed by humans&amp;quot; (p. 520). Dutoit (1997) takes this further, stating &amp;quot;such training-based strategies are often assumed to exhibit much more intelligence than they do in practice, as revealed by their poor transcription scores&amp;quot; (p. 115, note 14). Pronunciation by analogy (PbA) is a data-driven technique for the automatic phonemization of text, originally proposed as a model of reading, e.g., by Glushko (1979) and Kay and Marcel (1981). It was first proposed for ITS applications over a decade ago by Dedina and Nusbaum (1986, 1991). See also the work of Byrd and Chodorow (1985), which considers computer-based pronunciation by analogy b</context>
</contexts>
<marker>Dutoit, 1997</marker>
<rawString>Dutoit, Thierry. 1997. Introduction to Text-to-Speech Synthesis. Kluwer, Dordrecht, The Netherlands.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Honey S Elovitz</author>
<author>Rodney Johnson</author>
</authors>
<marker>Elovitz, Johnson, </marker>
<rawString>Elovitz, Honey S., Rodney Johnson,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Astrid McHugh</author>
<author>John E Shore</author>
</authors>
<title>Letter-to-sound rules for automatic translation of English text to phonetics.</title>
<date>1976</date>
<booktitle>IEEE Transactions on Acoustics, Speech and Signal Processing ASSP-24,</booktitle>
<pages>446--459</pages>
<marker>McHugh, Shore, 1976</marker>
<rawString>Astrid McHugh, and John E. Shore. 1976. Letter-to-sound rules for automatic translation of English text to phonetics. IEEE Transactions on Acoustics, Speech and Signal Processing ASSP-24, pages 446-459.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert J Glushko</author>
</authors>
<title>The organization and activation of orthographic knowledge in reading aloud.</title>
<date>1979</date>
<journal>Journal of Experimental Psychology: Human Perception and Performance,</journal>
<pages>5--674</pages>
<contexts>
<context position="13522" citStr="Glushko (1979)" startWordPosition="2081" endWordPosition="2082">ty is not usually given much credence. For instance, Divay and Vitale (1997) recently wrote: &amp;quot;To our knowledge, learning algorithms, although promising, have not (yet) reached the level of rule sets developed by humans&amp;quot; (p. 520). Dutoit (1997) takes this further, stating &amp;quot;such training-based strategies are often assumed to exhibit much more intelligence than they do in practice, as revealed by their poor transcription scores&amp;quot; (p. 115, note 14). Pronunciation by analogy (PbA) is a data-driven technique for the automatic phonemization of text, originally proposed as a model of reading, e.g., by Glushko (1979) and Kay and Marcel (1981). It was first proposed for ITS applications over a decade ago by Dedina and Nusbaum (1986, 1991). See also the work of Byrd and Chodorow (1985), which considers computer-based pronunciation by analogy but does not mention the possible application to text-to-speech synthesis. As detailed by Damper (1995) and Damper and Eastmond (1997), PbA shares many similarities with the artificial intelligence paradigms variously called case-based, memory-based, or instance-based reasoning as applied to letter-to-phoneme conversion (Stanfill and Waltz 1986; Lehnert 1987; Stanfill 1</context>
<context position="22667" citStr="Glushko (1979)" startWordPosition="3509" endWordPosition="3510">ncies&amp;quot; (Dedina and Nusbaum&apos;s term, and nothing to do with frequency of usage in written or spoken communication) obtained by counting the number of times the corresponding substring matches between the input and the entire lexicon. The scoring heuristics are one obvious dimension on which different versions of PbA can vary. In the following, when we refer to a multistrategy approach to PbA, it is principally the use of multiple scoring strategies which is at issue. 3.2 Appraisal PRONOUNCE was evaluated on just 70 monosyllabic pseudowords—a subset of those previously used in reading studies by Glushko (1979). Such a test is largely irrelevant to TTS applications: the test set is not representative of general English, either in the small number of words used or their length. Also, D&amp;N&apos;s claimed results on this pseudoword test set have proved impossible to replicate (Damper and Eastmond 1996, 1997; Yvon 1996; Bagshaw 1998). In addition, no consideration is given to the case where no complete path through the lattice exists (the silence problem mentioned earlier). D&amp;N&apos;s pattern matching (when building the pronunciation lattice) is a &amp;quot;partial&amp;quot; one. That is, as explained in section 3.1.1, the process </context>
</contexts>
<marker>Glushko, 1979</marker>
<rawString>Glushko, Robert J. 1979. The organization and activation of orthographic knowledge in reading aloud. Journal of Experimental Psychology: Human Perception and Performance, 5:674-691.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew R Golding</author>
</authors>
<title>Pronouncing Names by a Combination of Case-Based and Rule-Based Reasoning.</title>
<date>1991</date>
<tech>Ph. D. thesis,</tech>
<institution>Stanford University, CA.</institution>
<contexts>
<context position="14145" citStr="Golding 1991" startWordPosition="2170" endWordPosition="2171">d Marcel (1981). It was first proposed for ITS applications over a decade ago by Dedina and Nusbaum (1986, 1991). See also the work of Byrd and Chodorow (1985), which considers computer-based pronunciation by analogy but does not mention the possible application to text-to-speech synthesis. As detailed by Damper (1995) and Damper and Eastmond (1997), PbA shares many similarities with the artificial intelligence paradigms variously called case-based, memory-based, or instance-based reasoning as applied to letter-to-phoneme conversion (Stanfill and Waltz 1986; Lehnert 1987; Stanfill 1987, 1988; Golding 1991; Golding and Rosenbloom 1991; van den Bosch and Daelemans 1993). PbA exploits the phonological knowledge implicitly contained in a dictionary of words and their corresponding pronunciations. The underlying idea is that a pronunciation for an unknown word is derived by matching substrings of the input to 198 Marchand and Damper Improving Pronunciation by Analogy substrings of known, lexical words, hypothesizing a partial pronunciation for each matched substring from the phonological knowledge, and assembling the partial pronunciations. Although initially it attracted little attention from work</context>
</contexts>
<marker>Golding, 1991</marker>
<rawString>Golding, Andrew R. 1991. Pronouncing Names by a Combination of Case-Based and Rule-Based Reasoning. Ph. D. thesis, Stanford University, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew R Golding</author>
<author>Paul S Rosenbloom</author>
</authors>
<title>Improving rule-based systems through case-based reasoning.</title>
<date>1991</date>
<booktitle>In Proceedings of the American Association for Artificial Intelligence Conference, AAAI-91,</booktitle>
<pages>21--27</pages>
<location>Anaheim, CA.</location>
<contexts>
<context position="14174" citStr="Golding and Rosenbloom 1991" startWordPosition="2172" endWordPosition="2175">). It was first proposed for ITS applications over a decade ago by Dedina and Nusbaum (1986, 1991). See also the work of Byrd and Chodorow (1985), which considers computer-based pronunciation by analogy but does not mention the possible application to text-to-speech synthesis. As detailed by Damper (1995) and Damper and Eastmond (1997), PbA shares many similarities with the artificial intelligence paradigms variously called case-based, memory-based, or instance-based reasoning as applied to letter-to-phoneme conversion (Stanfill and Waltz 1986; Lehnert 1987; Stanfill 1987, 1988; Golding 1991; Golding and Rosenbloom 1991; van den Bosch and Daelemans 1993). PbA exploits the phonological knowledge implicitly contained in a dictionary of words and their corresponding pronunciations. The underlying idea is that a pronunciation for an unknown word is derived by matching substrings of the input to 198 Marchand and Damper Improving Pronunciation by Analogy substrings of known, lexical words, hypothesizing a partial pronunciation for each matched substring from the phonological knowledge, and assembling the partial pronunciations. Although initially it attracted little attention from workers in speech synthesis, seve</context>
</contexts>
<marker>Golding, Rosenbloom, 1991</marker>
<rawString>Golding, Andrew R. and Paul S. Rosenbloom. 1991. Improving rule-based systems through case-based reasoning. In Proceedings of the American Association for Artificial Intelligence Conference, AAAI-91, pages 21-27, Anaheim, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David L Hall</author>
</authors>
<title>Mathematical Techniques in Multisensor Data Fusion. Artech House,</title>
<date>1992</date>
<location>Boston, MA.</location>
<contexts>
<context position="32532" citStr="Hall 1992" startWordPosition="5060" endWordPosition="5061">rence. In principle, &amp;quot;fusion provides significant advantages over single source data&amp;quot; including &amp;quot;the statistical advantage gained by combining same-source data (e.g., obtaining an improved estimate . .. via redundant observations)&amp;quot; (p. 6). However, dangers include &amp;quot;the attempt to combine accurate (i.e., good) data with inaccurate or biased data, especially if the uncertainties or variances of the data are unknown&amp;quot; (p. 8). Methods of information fusion include &amp;quot;voting methods, Bayesian inference, Dempster-Shafer &apos;s method, generalized evidence processing theory, and various ad hoc techniques&amp;quot; (Hall 1992, 135). Clearly, the above characterization is very wide ranging. Consequently, fusion has been applied to a wide variety of pattern recognition and decision theoretic problems— using a plethora of theories, techniques, and tools—including some applications in computational linguistics (e.g., Brill and Wu 1998; van Halteren, Zavrel, and Daelemans 1998) and speech technology (e.g., Bowles and Damper 1989; Romary and Pierre11989). According to Abbott (1999, 290), &amp;quot;While the reasons [that] combining models works so well are not rigorously understood, there is ample evidence that improvements over</context>
</contexts>
<marker>Hall, 1992</marker>
<rawString>Hall, David L. 1992. Mathematical Techniques in Multisensor Data Fusion. Artech House, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David L Hall</author>
<author>James Llinas</author>
</authors>
<title>An introduction to multisensor data fusion.</title>
<date>1997</date>
<booktitle>Proceedings of the IEEE,</booktitle>
<pages>85--1</pages>
<contexts>
<context position="31731" citStr="Hall and Llinas (1997" startWordPosition="4945" endWordPosition="4948">s simply to add a (null-labeled) arc in the case that there was no complete path through the pronunciation lattice, and a single break occurred between adjacent nodes. This corresponds to concatenation of two otherwise complete word fragments. These best results should be compared with 60.7% words correct and 91.2% phonemes correct, as previously obtained by Damper and Eastmond (1997, Table 2). 5. Information Fusion in Computational Linguistics In the introduction, we stated that our multistrategy approach is a special case of information (or data) fusion. What precisely is this? According to Hall and Llinas (1997, 7-8): The most fundamental characterization of... fusion involves a hierarchical transformation between observed ... parameters (provided by multiple sources as input) and a decision or inference. In principle, &amp;quot;fusion provides significant advantages over single source data&amp;quot; including &amp;quot;the statistical advantage gained by combining same-source data (e.g., obtaining an improved estimate . .. via redundant observations)&amp;quot; (p. 6). However, dangers include &amp;quot;the attempt to combine accurate (i.e., good) data with inaccurate or biased data, especially if the uncertainties or variances of the data are</context>
<context position="35832" citStr="Hall and Llinas (1997" startWordPosition="5595" endWordPosition="5598">(Within the NETtalk corpus, primarily because of the use of the null phoneme, words and their pronunciations all have the same length). For example, for the pronunciation lattice given in Figure 2 for the word longevity, we have the six candidate pronunciations shown in Table 3, along with their arc frequencies and path structures. Of course, candidate pronunciations are not necessarily distinct: different shortest paths can obviously correspond to the same phoneme string. In this example, the correct pronunciation is that corresponding to Candidates 4 and 6. 6.2 Combining Scores According to Hall and Llinas (1997, 8), &amp;quot;observational data may be combined or fused at a variety of levels.&amp;quot; Since each of our strategies operates on the same basic data 205 Computational Linguistics Volume 26, Number 2 Table 3 Candidate pronunciations for the word longevity. The correct pronunciation is that corresponding to Candidates 4 and 6. Candidate Pronunciation Arc Frequencies Path Structure 1 /1cGgEvxti/ {1,11,2} {4, 1, 5} 2 /1cGg-vxti/ {1, 24, 22} {5,1,4} 3 /1cGg-vIti/ {1, 2, 2} {5, 2, 3} 4 /lanJEvxti/ {2, 9, 2} {3, 2, 5} 5 /lonJEvxti/ {1, 9, 2} {3, 2, 5} 6 /lanjEvxti/ {2, 80, 2} {4,1,5} structure—the pronunciation </context>
</contexts>
<marker>Hall, Llinas, 1997</marker>
<rawString>Hall, David L. and James Llinas. 1997. An introduction to multisensor data fusion. Proceedings of the IEEE, 85(1):6-23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sheri Hunnicutt</author>
</authors>
<title>Phonological rules for a text-to-speech system.</title>
<date>1976</date>
<journal>American Journal of Computational Linguistics Microfiche,</journal>
<pages>57--1</pages>
<marker>Hunnicutt, 1976</marker>
<rawString>Hunnicutt, Sheri. 1976. Phonological rules for a text-to-speech system. American Journal of Computational Linguistics Microfiche, 57:1-72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert A Jacobs</author>
<author>Michael I Jordan</author>
<author>Steven J Nowlan</author>
<author>Geoffrey E Hinton</author>
</authors>
<title>Adaptive mixtures of local experts.</title>
<date>1991</date>
<journal>Neural Computation,</journal>
<pages>3--79</pages>
<contexts>
<context position="17299" citStr="Jacobs et al. 1991" startWordPosition="2651" endWordPosition="2654">he main focus of this paper, that different multiple PbA strategies—whose outputs are combined to give the final pronunciation—might be used to good effect. If the different strategies make different errors, then it is conceivable that such a multistrategy approach can produce a lower error rate than even the best single strategy. Indeed, it may be that a strategy with a poor performance by itself can make a positive overall contribution to high-accuracy pronunciation derivation when used in concert with other strategies. It can be viewed as a &amp;quot;specialist&amp;quot; within a committee of experts (e.g., Jacobs et al. 1991; Dietterich 1997): most often its opinion is invalid, but occasionally—for inputs within its sphere of expertise—it produces the correct answer when the other &amp;quot;generalist&amp;quot; strategies do not. There is currently much interest in the topic of information fusion in a wide variety of application settings. This work can be seen as a specific instance of information fusion. 3. Dedina and Nusbaum&apos;s System The results reported here were obtained using an extended and improved version of PRONOUNCE, the Dedina and Nusbaum (D&amp;N) system, which we now describe. 3.1 Principles The basic PRONOUNCE system con</context>
</contexts>
<marker>Jacobs, Jordan, Nowlan, Hinton, 1991</marker>
<rawString>Jacobs, Robert A., Michael I. Jordan, Steven J. Nowlan, and Geoffrey E. Hinton. 1991. Adaptive mixtures of local experts. Neural Computation, 3:79-87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Jones</author>
</authors>
<title>Analogical Natural Language Processing.</title>
<date>1996</date>
<publisher>UCL Press,</publisher>
<location>London, UK.</location>
<contexts>
<context position="12202" citStr="Jones (1996" startWordPosition="1876" endWordPosition="1877">y considerable and requires an expert depth of knowledge of the specific language. For these reasons, and especially to ease the problem of creating a TTS system for a new language, more recent attention has focused on the application of automatic techniques based on machine learning from large corpora—see Damper (1995) for a comprehensive review, van den Bosch (1997) for more recent discussion, and Dietterich (1997) for an accessible review of the underpinning machine learning methodologies. The rule-based approach has also been challenged from a more theoretical point of view. For instance, Jones (1996, 1) describes the goal of his book Analogical Natural Language Processing as: to challenge the currently predominant assumption in the field of natural language processing that the representation of language should be done within the rule-based paradigm alone. For historical reasons, this traditional position is largely the result of the influence of Chomsky and his efforts to define language in terms of formal mathematics.... The contrasting view, taken here, is that language is not something that can be described in a neat and tidy way. This is also the perspective adopted here. It is also </context>
</contexts>
<marker>Jones, 1996</marker>
<rawString>Jones, Daniel. 1996. Analogical Natural Language Processing. UCL Press, London, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janice Kay</author>
<author>Anthony Marcel</author>
</authors>
<title>One process, not two, in reading aloud: Lexical analogies do the work of non-lexical rules.</title>
<date>1981</date>
<journal>Quarterly Journal of Experimental Psychology,</journal>
<pages>33--397</pages>
<contexts>
<context position="13548" citStr="Kay and Marcel (1981)" startWordPosition="2084" endWordPosition="2087">iven much credence. For instance, Divay and Vitale (1997) recently wrote: &amp;quot;To our knowledge, learning algorithms, although promising, have not (yet) reached the level of rule sets developed by humans&amp;quot; (p. 520). Dutoit (1997) takes this further, stating &amp;quot;such training-based strategies are often assumed to exhibit much more intelligence than they do in practice, as revealed by their poor transcription scores&amp;quot; (p. 115, note 14). Pronunciation by analogy (PbA) is a data-driven technique for the automatic phonemization of text, originally proposed as a model of reading, e.g., by Glushko (1979) and Kay and Marcel (1981). It was first proposed for ITS applications over a decade ago by Dedina and Nusbaum (1986, 1991). See also the work of Byrd and Chodorow (1985), which considers computer-based pronunciation by analogy but does not mention the possible application to text-to-speech synthesis. As detailed by Damper (1995) and Damper and Eastmond (1997), PbA shares many similarities with the artificial intelligence paradigms variously called case-based, memory-based, or instance-based reasoning as applied to letter-to-phoneme conversion (Stanfill and Waltz 1986; Lehnert 1987; Stanfill 1987, 1988; Golding 1991; G</context>
<context position="19834" citStr="Kay and Marcel 1981" startWordPosition="3042" endWordPosition="3045">deration— is entered into the input string&apos;s pronunciation lattice as detailed below. (Note that this requires the letters and phonemes of each word in the lexicon to have been previously aligned in one-to-one fashion.) The shorter of the two strings is then shifted right by one letter and the matching process repeated. This continues until the two strings are right-aligned, i.e., the number of right shifts is equal to the difference in length between the two strings. This process can be alternatively seen as a matching between substrings of the incoming word &amp;quot;segmented in all possible ways&amp;quot; (Kay and Marcel 1981, 401) and the entries in the lexicon. 3.1.2 Pronunciation Lattice. Matched substrings, together with their corresponding phonemic mappings as found in the lexicon, are used to build the pronunciation lattice for the input string. A node of the lattice represents a matched letter, L,, at some position, i, in the input. The node is labeled with its position index i and with the phoneme that corresponds to L, in the matched substring, P,,, say, for the mth matched substring. An arc is placed from node i to node j if there is a matched substring starting with L, and ending with LI. The arc is lab</context>
</contexts>
<marker>Kay, Marcel, 1981</marker>
<rawString>Kay, Janice and Anthony Marcel. 1981. One process, not two, in reading aloud: Lexical analogies do the work of non-lexical rules. Quarterly Journal of Experimental Psychology, 33A:397-413.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Josef Kittler</author>
<author>Mohammad Hatef</author>
<author>Robert P W Duirt</author>
<author>Jiri Matas</author>
</authors>
<title>On combining classifiers.</title>
<date>1998</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<pages>20--3</pages>
<contexts>
<context position="37899" citStr="Kittler et al. (1998)" startWordPosition="5955" endWordPosition="5958">ng strategy si is inversely related to its rank order on the basis of si. Thus, the total number of points (T) awarded for each strategy is: T(N) = r=1 N(N + 1) 2 where N is the number of candidate pronunciations (N = 6 in our longevity example, so that T(6) = 21). Let cand(Rs,) express the number of candidates that have the rank R for the scoring strategy si so that cand(Rs,) &gt; 1 if there are ties, otherwise cand(R) 1. Then P(CI, Rs,), the number of points awarded to the candidate CI thanks to its rank on the basis of strategy s„ is: R. -Rand (Rs,)-1 (N — i +1) P(Ci, R5,) cand(Rs,) Recently, Kittler et al. (1998) have considered the relative merits of several combination rules for decision-level fusion from a theoretical and experimental perspective. The rules compared were sum, product, max, min, and majority. Of these, the sum and product rules generally performed best. In view of this, these are the rules used here. For the sum rule, the final score for a candidate pronunciation, FS(c), is simply taken as the sum of the different numbers of points won for each of the S strategies. 206 Marchand and Damper Improving Pronunciation by Analogy Since not all strategies are necessarily included: FS(Ci) = </context>
</contexts>
<marker>Kittler, Hatef, Duirt, Matas, 1998</marker>
<rawString>Kittler, Josef, Mohammad Hatef, Robert P. W. Duirt, and Jiri Matas. 1998. On combining classifiers. IEEE Transactions on Pattern Analysis and Machine Intelligence, 20(3):226-239.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wendy G Lehnert</author>
</authors>
<title>Case-based problem solving with a large knowledge base of learned cases.</title>
<date>1987</date>
<booktitle>In Proceedings of the 6th National Conference on Artificial Intelligence, AAAI-87,</booktitle>
<pages>301--306</pages>
<location>Seattle, WA.</location>
<contexts>
<context position="14110" citStr="Lehnert 1987" startWordPosition="2165" endWordPosition="2166"> e.g., by Glushko (1979) and Kay and Marcel (1981). It was first proposed for ITS applications over a decade ago by Dedina and Nusbaum (1986, 1991). See also the work of Byrd and Chodorow (1985), which considers computer-based pronunciation by analogy but does not mention the possible application to text-to-speech synthesis. As detailed by Damper (1995) and Damper and Eastmond (1997), PbA shares many similarities with the artificial intelligence paradigms variously called case-based, memory-based, or instance-based reasoning as applied to letter-to-phoneme conversion (Stanfill and Waltz 1986; Lehnert 1987; Stanfill 1987, 1988; Golding 1991; Golding and Rosenbloom 1991; van den Bosch and Daelemans 1993). PbA exploits the phonological knowledge implicitly contained in a dictionary of words and their corresponding pronunciations. The underlying idea is that a pronunciation for an unknown word is derived by matching substrings of the input to 198 Marchand and Damper Improving Pronunciation by Analogy substrings of known, lexical words, hypothesizing a partial pronunciation for each matched substring from the phonological knowledge, and assembling the partial pronunciations. Although initially it a</context>
</contexts>
<marker>Lehnert, 1987</marker>
<rawString>Lehnert, Wendy G. 1987. Case-based problem solving with a large knowledge base of learned cases. In Proceedings of the 6th National Conference on Artificial Intelligence, AAAI-87, pages 301-306, Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Isabelle Liberman</author>
<author>Alvin M Liberman</author>
<author>Ignatius Mattingly</author>
<author>Donald Shankweiler</author>
</authors>
<title>Orthography and the beginning reader.</title>
<date>1980</date>
<pages>137--153</pages>
<editor>In James F. Kavanagh and Richard L. Venezky, editors,</editor>
<publisher>University Park Press,</publisher>
<location>Baltimore, OH,</location>
<contexts>
<context position="4503" citStr="Liberman et al. 1980" startWordPosition="663" endWordPosition="666">ly (but not exclusively) proper names, acronyms, and neologisms. At this stage of our work, we concentrate on English and assume that any such missing words are dictionary-like with respect to their spelling and pronunciation, as will probably be the case for many neologisms. Even if the missing words are dictionary-like, automatic determination of pronunciation is a hard problem for languages like English and French (van den Bosch et al. 1994). In fact, English is notorious for the lack of regularity in its spelling-to-sound correspondence. That is, it has a deep orthography (Coltheart 1978; Liberman et al. 1980; Sampson 1985) as opposed to the shallow orthography of, for example, Serbo-Croatian (Turvey, Feldman, and Lukatela 1984). To a large extent, this reflects the many complex historical influences on the spelling system (Venezky 1965; Scragg 1975; Carney 1994). Indeed, Abercrombie (1981, 209) describes English orthography as &amp;quot;one of the least successful applications of the Roman alphabet.&amp;quot; We use 26 letters in English orthography yet about 45-55 phonemes in specifying pronunciation. It follows that the relation between letters and phonemes cannot be simply one-to-one. For instance, the letter c</context>
</contexts>
<marker>Liberman, Liberman, Mattingly, Shankweiler, 1980</marker>
<rawString>Liberman, Isabelle, Alvin M. Liberman, Ignatius Mattingly, and Donald Shankweiler. 1980. Orthography and the beginning reader. In James F. Kavanagh and Richard L. Venezky, editors, Orthography, Reading and Dyslexia. University Park Press, Baltimore, OH, pages 137-153.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John M Lucassen</author>
<author>Robert L Mercer</author>
</authors>
<title>An information theoretic approach to the automatic determination of phonemic baseforms.</title>
<date>1984</date>
<booktitle>In Proceedings of the International Conference on Acoustics, Speech and Signal Processing, ICASSP-84,</booktitle>
<pages>42--5</pages>
<location>San Diego, CA.</location>
<contexts>
<context position="2529" citStr="Lucassen and Mercer 1984" startWordPosition="364" endWordPosition="367">vowel letters and phonemes. 1. Introduction Text-to-phoneme conversion is a problem of some practical importance. Possibly the major application is speech synthesis from text, where we need to convert the text input (i.e., letter string) to something much closer to a representation of the corresponding sound sequence (e.g., phoneme string). A further important application is speech recognition, where we may wish to add a new word (specified by its spelling) to the vocabulary of a recognition system. This requires that the system has some idea of the &amp;quot;ideal&amp;quot; pronunciation—or phonemic baseform (Lucassen and Mercer 1984)—of the word. Also, in recognition we have a requirement to perform the inverse mapping, i.e., for conversion from phonemes to text. Perhaps the techniques employed for the forward mapping can also be applied &amp;quot;in reverse&amp;quot; for phoneme-to-text conversion. Yet another reason for being interested in the problem of automatic phonemization is * Image, Speech and Intelligent Systems (ISIS) Research Group, Department of Electronics and Computer Science, University of Southampton, Southampton S017 1BJ, UK. E-mail: ym@ecs.soton.ac.uk t Image, Speech and Intelligent Systems (ISIS) Research Group, Departm</context>
</contexts>
<marker>Lucassen, Mercer, 1984</marker>
<rawString>Lucassen, John M. and Robert L. Mercer. 1984. An information theoretic approach to the automatic determination of phonemic baseforms. In Proceedings of the International Conference on Acoustics, Speech and Signal Processing, ICASSP-84, pages 42.5.1-42.5.4, San Diego, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Neil McCulloch</author>
<author>Mark Bedworth</author>
<author>John Bridle</author>
</authors>
<title>NETspeak-A re-implementation of NETtalk.</title>
<date>1987</date>
<journal>Computer Speech and Language,</journal>
<pages>2--289</pages>
<marker>McCulloch, Bedworth, Bridle, 1987</marker>
<rawString>McCulloch, Neil, Mark Bedworth, and John Bridle. 1987. NETspeak-A re-implementation of NETtalk. Computer Speech and Language, 2:289-301.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Douglas McIlroy</author>
</authors>
<title>Synthetic English Speech by Rule. Computer Science</title>
<date>1973</date>
<tech>Technical Report No. 14,</tech>
<institution>Bell Telephone Laboratories.</institution>
<contexts>
<context position="9286" citStr="McIlroy (1973)" startWordPosition="1417" endWordPosition="1418">s that the letter substring B with left context A and right context C receives the pronunciation (i.e., phoneme substring) D. Such rules can also be straightforwardly cast in the IF. . . THEN form commonly featured in high-level programming languages and employed in expert, knowledge-based systems technology. They also constitute a formal model of universal computation (Post 1943). Conventionally, these rules are specified by an expert linguist, conversant with the sound and spelling systems of the language of concern. Typical letter-to-sound rule sets are those described by Ainsworth (1973), McIlroy (1973), Elovitz et al. (1976), Hurmicutt (1976), and Divay and Vitale (1997). Because of the complexities of English spelling-to-sound correspondence detailed in the previous section, more than one rule generally applies at each stage of transcription. The potential conflicts that arise are resolved by maintaining the rules in a set of sublists, grouped by (initial) letter and with each sublist ordered by specificity. Typically, the most specific rule is at the top and most general at the bottom. In the Elovitz et al. rules, for instance, transcription is a one-pass, left-to-right process. For the p</context>
</contexts>
<marker>McIlroy, 1973</marker>
<rawString>McIlroy, M. Douglas. 1973. Synthetic English Speech by Rule. Computer Science Technical Report No. 14, Bell Telephone Laboratories.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emil Post</author>
</authors>
<title>Formal reductions of the general combinatorial problem.</title>
<date>1943</date>
<journal>American Journal of Mathematics,</journal>
<pages>65--197</pages>
<contexts>
<context position="9055" citStr="Post 1943" startWordPosition="1384" endWordPosition="1385">rules have been a popular formalism for the backup pronunciation strategy in TTS systems. The form of the rules, strongly inspired by concepts from generative phonology (Chomsky and Halle 1968, 14), is: A [B]C D (1) which states that the letter substring B with left context A and right context C receives the pronunciation (i.e., phoneme substring) D. Such rules can also be straightforwardly cast in the IF. . . THEN form commonly featured in high-level programming languages and employed in expert, knowledge-based systems technology. They also constitute a formal model of universal computation (Post 1943). Conventionally, these rules are specified by an expert linguist, conversant with the sound and spelling systems of the language of concern. Typical letter-to-sound rule sets are those described by Ainsworth (1973), McIlroy (1973), Elovitz et al. (1976), Hurmicutt (1976), and Divay and Vitale (1997). Because of the complexities of English spelling-to-sound correspondence detailed in the previous section, more than one rule generally applies at each stage of transcription. The potential conflicts that arise are resolved by maintaining the rules in a set of sublists, grouped by (initial) letter</context>
</contexts>
<marker>Post, 1943</marker>
<rawString>Post, Emil. 1943. Formal reductions of the general combinatorial problem. American Journal of Mathematics, 65:197-268.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laurent Romary</author>
<author>Jean-Marie Pierrel</author>
</authors>
<title>The use of the Dempster-Shafer rule in the lexical component of a man-machine oral dialogue system.</title>
<date>1989</date>
<journal>Speech Communication,</journal>
<pages>8--2</pages>
<marker>Romary, Pierrel, 1989</marker>
<rawString>Romary, Laurent and Jean-Marie Pierrel. 1989. The use of the Dempster-Shafer rule in the lexical component of a man-machine oral dialogue system. Speech Communication, 8(2):159-176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey Sampson</author>
</authors>
<title>Writing Systems.</title>
<date>1985</date>
<location>Hutchinson, London, UK.</location>
<contexts>
<context position="4518" citStr="Sampson 1985" startWordPosition="667" endWordPosition="668">y) proper names, acronyms, and neologisms. At this stage of our work, we concentrate on English and assume that any such missing words are dictionary-like with respect to their spelling and pronunciation, as will probably be the case for many neologisms. Even if the missing words are dictionary-like, automatic determination of pronunciation is a hard problem for languages like English and French (van den Bosch et al. 1994). In fact, English is notorious for the lack of regularity in its spelling-to-sound correspondence. That is, it has a deep orthography (Coltheart 1978; Liberman et al. 1980; Sampson 1985) as opposed to the shallow orthography of, for example, Serbo-Croatian (Turvey, Feldman, and Lukatela 1984). To a large extent, this reflects the many complex historical influences on the spelling system (Venezky 1965; Scragg 1975; Carney 1994). Indeed, Abercrombie (1981, 209) describes English orthography as &amp;quot;one of the least successful applications of the Roman alphabet.&amp;quot; We use 26 letters in English orthography yet about 45-55 phonemes in specifying pronunciation. It follows that the relation between letters and phonemes cannot be simply one-to-one. For instance, the letter c is pronounced </context>
</contexts>
<marker>Sampson, 1985</marker>
<rawString>Sampson, Geoffrey. 1985. Writing Systems. Hutchinson, London, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David G Scragg</author>
</authors>
<title>A History of English Spelling.</title>
<date>1975</date>
<publisher>Manchester University Press,</publisher>
<location>Manchester, UK.</location>
<contexts>
<context position="4748" citStr="Scragg 1975" startWordPosition="701" endWordPosition="702">e for many neologisms. Even if the missing words are dictionary-like, automatic determination of pronunciation is a hard problem for languages like English and French (van den Bosch et al. 1994). In fact, English is notorious for the lack of regularity in its spelling-to-sound correspondence. That is, it has a deep orthography (Coltheart 1978; Liberman et al. 1980; Sampson 1985) as opposed to the shallow orthography of, for example, Serbo-Croatian (Turvey, Feldman, and Lukatela 1984). To a large extent, this reflects the many complex historical influences on the spelling system (Venezky 1965; Scragg 1975; Carney 1994). Indeed, Abercrombie (1981, 209) describes English orthography as &amp;quot;one of the least successful applications of the Roman alphabet.&amp;quot; We use 26 letters in English orthography yet about 45-55 phonemes in specifying pronunciation. It follows that the relation between letters and phonemes cannot be simply one-to-one. For instance, the letter c is pronounced /s/ in cider but /k/ in cat. On the other hand, the /k/ sound of kitten is written with a letter k. Nor is this lack of invariance between letters and phonemes the only problem. There is no strict correspondence between the number</context>
</contexts>
<marker>Scragg, 1975</marker>
<rawString>Scragg, David G. 1975. A History of English Spelling. Manchester University Press, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terrence J Sejnowski</author>
<author>Charles R Rosenberg</author>
</authors>
<title>Parallel networks that learn to pronounce English text.</title>
<date>1987</date>
<journal>Complex Systems,</journal>
<pages>1--145</pages>
<contexts>
<context position="15295" citStr="Sejnowski and Rosenberg 1987" startWordPosition="2335" endWordPosition="2338">ial pronunciations. Although initially it attracted little attention from workers in speech synthesis, several groups around the world are now trying to develop the approach as a backup to dictionary matching. In spite of opinions to the contrary expressed in the literature (see above), there is accumulating evidence that PbA easily outperforms linguistic rewrite rules (Damper and Eastmond 1996, 1997; Yvon 1996; Bagshaw 1998). More recently, Damper et al. (1999) conducted a careful performance evaluation of four techniques for letter-tosound conversion: rules, backpropagation neural networks (Sejnowski and Rosenberg 1987; McCulloch, Bedworth, and Bridle 1987), PbA and the IB1-IG method based on information gain weighting (Daelemans, van den Bosch, and Weijters 1997; van den Bosch 1997). Results showed PbA to be the best of the techniques evaluated by a significant margin. Although one obviously cannot say from a limited evaluation with just three competitors that PbA is the best method available, it is clearly worthy of serious consideration and further development. This paper marks a stage of that development. As a psychological (or theoretical) model, PbA is &amp;quot;seriously underspecified&amp;quot; so that the implemento</context>
</contexts>
<marker>Sejnowski, Rosenberg, 1987</marker>
<rawString>Sejnowski, Terrence J. and Charles R. Rosenberg. 1987. Parallel networks that learn to pronounce English text. Complex Systems, 1:145-168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sidney Siegel</author>
</authors>
<title>Nonparametric Statistics for the Behavioral Sciences. McGraw-Hill Kogakusha,</title>
<date>1956</date>
<location>Tokyo, Japan.</location>
<contexts>
<context position="47384" citStr="Siegel 1956" startWordPosition="7641" endWordPosition="7642">10100 65.2 92.2 65.1 92.2 10101 65.3 92.3 64.9 92.2 10110 64.8 92.2 64.8 92.3 10111 65.4 92.4 65.4 92.4 11000 58.6 91.1 58.6 91.1 11001 59.0 91.2 59.2 91.2 11010 63.6 92.2 63.6 92.2 11011 63.4 92.2 63.2 92.1 11100 65.4 92.3 65.3 92.3 11101 64.9 92.3 64.7 92.2 11110 65.2 92.3 65.1 92.3 11111 65.5 92.4 65.5 92.4 ranks are not positively correlated. That is, our null hypothesis is that performance (in terms of word accuracy) does not increase as more scoring strategies s, for candidate pronunciation Cj are included in the final score FS(CI). However, the Spearman rank correlation coefficient rs (Siegel 1956, 202-213) is computed here as 0.6657, with degrees of freedom df = (31 - 2) = 29. For df &gt; 10, the significance of this result can be tested as: t = rs df = 4.8041 1 - This value is very highly significant (p &lt; 0.0005, one-tailed test). Hence, we reject the null hypothesis and conclude that performance improves as more scores are included in the combination. Note that this test is nonparametric, and makes a minimum of assumptions about the data-only that they are ordinal and so can be meaningfully ranked. 211 Computational Linguistics Volume 26, Number 2 Table 8 Results of letter-to-phoneme c</context>
<context position="49799" citStr="Siegel 1956" startWordPosition="8080" endWordPosition="8081">cant positive correlation between the number of strategies deployed and the obtained word accuracy, we next ask if the obtained improvement is significant. (This is to take account of the possibility that the difference between two combination strategies ranked at positions i and (i + k) is not significant.) To answer this, we note that only two outcomes are possible for the translation of each word: either the pronunciation is correct or it is not. Thus, the sampling distribution of the word accuracies listed in the second column of Table 8 is binomial and, hence, we can use a binomial test (Siegel 1956, 36-42) to determine the significance of differences between them. Since the number of trials (i.e., word translations) is very large (-20,000), we can use the normal approximation to the binomial distribution. Let us first ask if the best letter-to-phoneme conversion result here (65.5% word accuracy for combination 11111) is significantly better than the previous best, preliminary 212 Marchand and Damper Improving Pronunciation by Analogy value of 61.7%. The appropriate statistic is (Siegel 1956, 41): = (x + 0.5) — NP (6) z VNPQ where N =- 19,594 words, P =- 0.617, Q = (1 — P) = 0.383, x = 1</context>
</contexts>
<marker>Siegel, 1956</marker>
<rawString>Siegel, Sidney. 1956. Nonparametric Statistics for the Behavioral Sciences. McGraw-Hill Kogakusha, Tokyo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Craig Stanfill</author>
<author>David Waltz</author>
</authors>
<title>Toward memory-based reasoning.</title>
<date>1986</date>
<journal>Communications of the ACM,</journal>
<pages>29--12</pages>
<contexts>
<context position="14096" citStr="Stanfill and Waltz 1986" startWordPosition="2161" endWordPosition="2164">ed as a model of reading, e.g., by Glushko (1979) and Kay and Marcel (1981). It was first proposed for ITS applications over a decade ago by Dedina and Nusbaum (1986, 1991). See also the work of Byrd and Chodorow (1985), which considers computer-based pronunciation by analogy but does not mention the possible application to text-to-speech synthesis. As detailed by Damper (1995) and Damper and Eastmond (1997), PbA shares many similarities with the artificial intelligence paradigms variously called case-based, memory-based, or instance-based reasoning as applied to letter-to-phoneme conversion (Stanfill and Waltz 1986; Lehnert 1987; Stanfill 1987, 1988; Golding 1991; Golding and Rosenbloom 1991; van den Bosch and Daelemans 1993). PbA exploits the phonological knowledge implicitly contained in a dictionary of words and their corresponding pronunciations. The underlying idea is that a pronunciation for an unknown word is derived by matching substrings of the input to 198 Marchand and Damper Improving Pronunciation by Analogy substrings of known, lexical words, hypothesizing a partial pronunciation for each matched substring from the phonological knowledge, and assembling the partial pronunciations. Although </context>
</contexts>
<marker>Stanfill, Waltz, 1986</marker>
<rawString>Stanfill, Craig and David Waltz. 1986. Toward memory-based reasoning. Communications of the ACM, 29(12):1213-1228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Craig W Stanfill</author>
</authors>
<title>Memory-based reasoning applied to English pronunciation.</title>
<date>1987</date>
<booktitle>In Proceedings of the 6th National Conference on Artificial Intelligence, AAAI-87,</booktitle>
<pages>577--581</pages>
<location>Seattle, WA.</location>
<contexts>
<context position="14125" citStr="Stanfill 1987" startWordPosition="2167" endWordPosition="2168">hko (1979) and Kay and Marcel (1981). It was first proposed for ITS applications over a decade ago by Dedina and Nusbaum (1986, 1991). See also the work of Byrd and Chodorow (1985), which considers computer-based pronunciation by analogy but does not mention the possible application to text-to-speech synthesis. As detailed by Damper (1995) and Damper and Eastmond (1997), PbA shares many similarities with the artificial intelligence paradigms variously called case-based, memory-based, or instance-based reasoning as applied to letter-to-phoneme conversion (Stanfill and Waltz 1986; Lehnert 1987; Stanfill 1987, 1988; Golding 1991; Golding and Rosenbloom 1991; van den Bosch and Daelemans 1993). PbA exploits the phonological knowledge implicitly contained in a dictionary of words and their corresponding pronunciations. The underlying idea is that a pronunciation for an unknown word is derived by matching substrings of the input to 198 Marchand and Damper Improving Pronunciation by Analogy substrings of known, lexical words, hypothesizing a partial pronunciation for each matched substring from the phonological knowledge, and assembling the partial pronunciations. Although initially it attracted little</context>
</contexts>
<marker>Stanfill, 1987</marker>
<rawString>Stanfill, Craig W. 1987. Memory-based reasoning applied to English pronunciation. In Proceedings of the 6th National Conference on Artificial Intelligence, AAAI-87, pages 577-581, Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Craig W Stanfill</author>
</authors>
<title>Learning to read: A memory-based model.</title>
<date>1988</date>
<booktitle>In Proceedings of the Case-Based Reasoning Workshop,</booktitle>
<pages>406--413</pages>
<location>Clearwater Beach, FL.</location>
<marker>Stanfill, 1988</marker>
<rawString>Stanfill, Craig W. 1988. Learning to read: A memory-based model. In Proceedings of the Case-Based Reasoning Workshop, pages 406-413, Clearwater Beach, FL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kirk P H Sullivan</author>
<author>Robert I Damper</author>
</authors>
<title>Novel-word pronunciation: A cross-language study.</title>
<date>1993</date>
<journal>Speech Communication,</journal>
<pages>13--441</pages>
<contexts>
<context position="16173" citStr="Sullivan and Damper (1993)" startWordPosition="2474" endWordPosition="2477">gin. Although one obviously cannot say from a limited evaluation with just three competitors that PbA is the best method available, it is clearly worthy of serious consideration and further development. This paper marks a stage of that development. As a psychological (or theoretical) model, PbA is &amp;quot;seriously underspecified&amp;quot; so that the implementor wishing to use analogy within the pronunciation component of a TTS system &amp;quot;faces detailed choices which can only be resolved by trial and error&amp;quot; (Damper and Eastmond 1997, 1). The impact of implementational choices on performance has been studied by Sullivan and Damper (1993), Damper and Eastmond (1996, 1997), and Yvon (1996, 1997). One important dimension on which implementations vary is the strategy used to score the candidate pronunciations that PbA produces. By and large, these investigators have sought the single best pronunciation strategy. However, the range of choices is wide, so that some rather different implementations with different performance can be produced, yet these are all (in some sense) pronunciation by analogy. This raises the possibility, which forms the main focus of this paper, that different multiple PbA strategies—whose outputs are combin</context>
</contexts>
<marker>Sullivan, Damper, 1993</marker>
<rawString>Sullivan, Kirk P. H. and Robert I. Damper. 1993. Novel-word pronunciation: A cross-language study. Speech Communication, 13:441-452.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael T Turvey</author>
<author>Laurie Beth Feldman</author>
<author>Georgije Lukatela</author>
</authors>
<title>The Serbo-Croatian orthography constrains the reader to a phonologically analytic strategy.</title>
<date>1984</date>
<booktitle>Orthographies and Reading. Lawrence Erlbaum Associates,</booktitle>
<pages>81--89</pages>
<editor>In Leslie Henderson, editor,</editor>
<location>London, UK,</location>
<marker>Turvey, Feldman, Lukatela, 1984</marker>
<rawString>Turvey, Michael T., Laurie Beth Feldman, and Georgije Lukatela. 1984. The Serbo-Croatian orthography constrains the reader to a phonologically analytic strategy. In Leslie Henderson, editor, Orthographies and Reading. Lawrence Erlbaum Associates, London, UK, pages 81-89.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antal van den Bosch</author>
</authors>
<title>Learning to Pronounce Written Words: A Study in Inductive Language Learning.</title>
<date>1997</date>
<tech>Ph. D. thesis,</tech>
<institution>University of Maastricht, The Netherlands.</institution>
<marker>van den Bosch, 1997</marker>
<rawString>van den Bosch, Antal. 1997. Learning to Pronounce Written Words: A Study in Inductive Language Learning. Ph. D. thesis, University of Maastricht, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antal van den Bosch</author>
<author>Alain Content</author>
<author>Walter Daelemans</author>
<author>Beatrice De Gelder</author>
</authors>
<title>Measuring the complexity of writing systems.</title>
<date>1994</date>
<journal>Journal of Quantitative Linguistics,</journal>
<pages>1--3</pages>
<marker>van den Bosch, Content, Daelemans, De Gelder, 1994</marker>
<rawString>van den Bosch, Antal, Alain Content, Walter Daelemans, and Beatrice De Gelder. 1994. Measuring the complexity of writing systems. Journal of Quantitative Linguistics, 1(3):178-188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antal van den Bosch</author>
<author>Walter Daelemans</author>
</authors>
<title>Data-oriented methods for grapheme-to-phoneme conversion.</title>
<date>1993</date>
<booktitle>In Proceedings of the 6th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>45--53</pages>
<location>Utrecht, The Netherlands.</location>
<marker>van den Bosch, Daelemans, 1993</marker>
<rawString>van den Bosch, Antal and Walter Daelemans. 1993. Data-oriented methods for grapheme-to-phoneme conversion. In Proceedings of the 6th Conference of the European Chapter of the Association for Computational Linguistics, pages 45-53, Utrecht, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans van Halteren</author>
<author>Jakub Zavrel</author>
<author>Walter Daelemans</author>
</authors>
<title>Improving data driven wordclass tagging by system combination.</title>
<date>1998</date>
<booktitle>In COLING-ACL &apos;98: 36th Annual Meeting of the Association for Computational Linguistics and the 17th International Conference on Computational Linguistics,</booktitle>
<pages>491--497</pages>
<location>Montreal, Canada.</location>
<marker>van Halteren, Zavrel, Daelemans, 1998</marker>
<rawString>van Halteren, Hans, Jakub Zavrel, and Walter Daelemans. 1998. Improving data driven wordclass tagging by system combination. In COLING-ACL &apos;98: 36th Annual Meeting of the Association for Computational Linguistics and the 17th International Conference on Computational Linguistics, pages 491-497, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard L Venezky</author>
</authors>
<title>A Study of English Spelling-to-Sound Correspondences on Historical Principles.</title>
<date>1965</date>
<publisher>Ann Arbor Press,</publisher>
<location>Ann Arbor, MI.</location>
<contexts>
<context position="4735" citStr="Venezky 1965" startWordPosition="699" endWordPosition="700">bly be the case for many neologisms. Even if the missing words are dictionary-like, automatic determination of pronunciation is a hard problem for languages like English and French (van den Bosch et al. 1994). In fact, English is notorious for the lack of regularity in its spelling-to-sound correspondence. That is, it has a deep orthography (Coltheart 1978; Liberman et al. 1980; Sampson 1985) as opposed to the shallow orthography of, for example, Serbo-Croatian (Turvey, Feldman, and Lukatela 1984). To a large extent, this reflects the many complex historical influences on the spelling system (Venezky 1965; Scragg 1975; Carney 1994). Indeed, Abercrombie (1981, 209) describes English orthography as &amp;quot;one of the least successful applications of the Roman alphabet.&amp;quot; We use 26 letters in English orthography yet about 45-55 phonemes in specifying pronunciation. It follows that the relation between letters and phonemes cannot be simply one-to-one. For instance, the letter c is pronounced /s/ in cider but /k/ in cat. On the other hand, the /k/ sound of kitten is written with a letter k. Nor is this lack of invariance between letters and phonemes the only problem. There is no strict correspondence betwe</context>
</contexts>
<marker>Venezky, 1965</marker>
<rawString>Venezky, Richard L. 1965. A Study of English Spelling-to-Sound Correspondences on Historical Principles. Ann Arbor Press, Ann Arbor, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard L Venezky</author>
</authors>
<title>The Structure of English Orthography. Mouton, The Hague, The Netherlands.</title>
<date>1970</date>
<contexts>
<context position="5945" citStr="Venezky 1970" startWordPosition="892" endWordPosition="893">tween the number of letters and the number of phonemes in English words. Letter combinations (ch, gh, 11, ea) frequently act as a functional spelling unit (Coltheart 1984)—or grapheme—signaling a single phoneme. Thus, the combination ough is pronounced /Af/ in enough, while ph is pronounced as the single phoneme /f/ in phase. However, ph in uphill is pronounced as two phonemes, !ph!. Usually, there are fewer phonemes than letters but there are exceptions, e.g., (six, /sIks/). Pronunciation can depend upon word class (e.g., convict, subject). English also has noncontiguous markings (Wijk 1966; Venezky 1970) as, for instance, when the letter e is added to (mad, /mad/) to make (made, !meld!), also spelled maid! The final e is not sounded; rather it indicates that the vowel is lengthened or dipthongized. Such markings can be quite complex, or long-range, as when the suffix y is added to photograph or telegraph to yield photography or telegraphy, respectively. As a final comment, although not considered further here, English contains many proper nouns (place names, surnames) that display idiosyncratic pronunciations, and loan words from other languages that conform to a different set of (partial) re</context>
</contexts>
<marker>Venezky, 1970</marker>
<rawString>Venezky, Richard L. 1970. The Structure of English Orthography. Mouton, The Hague, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Axel Wijk</author>
</authors>
<title>Rules of Pronunciation of the English Language.</title>
<date>1966</date>
<publisher>Oxford University Press,</publisher>
<location>Oxford, UK.</location>
<contexts>
<context position="5930" citStr="Wijk 1966" startWordPosition="890" endWordPosition="891">pondence between the number of letters and the number of phonemes in English words. Letter combinations (ch, gh, 11, ea) frequently act as a functional spelling unit (Coltheart 1984)—or grapheme—signaling a single phoneme. Thus, the combination ough is pronounced /Af/ in enough, while ph is pronounced as the single phoneme /f/ in phase. However, ph in uphill is pronounced as two phonemes, !ph!. Usually, there are fewer phonemes than letters but there are exceptions, e.g., (six, /sIks/). Pronunciation can depend upon word class (e.g., convict, subject). English also has noncontiguous markings (Wijk 1966; Venezky 1970) as, for instance, when the letter e is added to (mad, /mad/) to make (made, !meld!), also spelled maid! The final e is not sounded; rather it indicates that the vowel is lengthened or dipthongized. Such markings can be quite complex, or long-range, as when the suffix y is added to photograph or telegraph to yield photography or telegraphy, respectively. As a final comment, although not considered further here, English contains many proper nouns (place names, surnames) that display idiosyncratic pronunciations, and loan words from other languages that conform to a different set </context>
</contexts>
<marker>Wijk, 1966</marker>
<rawString>Wijk, Axel. 1966. Rules of Pronunciation of the English Language. Oxford University Press, Oxford, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francois Yvon</author>
</authors>
<title>Grapheme-tophoneme conversion using multiple unbounded overlapping chunks.</title>
<date>1996</date>
<booktitle>In Proceedings of the Conference on New Methods in Natural Language Processing, NeMLaP &apos;96,</booktitle>
<pages>218--228</pages>
<location>Ankara, Turkey.</location>
<contexts>
<context position="15081" citStr="Yvon 1996" startWordPosition="2309" endWordPosition="2310">er Improving Pronunciation by Analogy substrings of known, lexical words, hypothesizing a partial pronunciation for each matched substring from the phonological knowledge, and assembling the partial pronunciations. Although initially it attracted little attention from workers in speech synthesis, several groups around the world are now trying to develop the approach as a backup to dictionary matching. In spite of opinions to the contrary expressed in the literature (see above), there is accumulating evidence that PbA easily outperforms linguistic rewrite rules (Damper and Eastmond 1996, 1997; Yvon 1996; Bagshaw 1998). More recently, Damper et al. (1999) conducted a careful performance evaluation of four techniques for letter-tosound conversion: rules, backpropagation neural networks (Sejnowski and Rosenberg 1987; McCulloch, Bedworth, and Bridle 1987), PbA and the IB1-IG method based on information gain weighting (Daelemans, van den Bosch, and Weijters 1997; van den Bosch 1997). Results showed PbA to be the best of the techniques evaluated by a significant margin. Although one obviously cannot say from a limited evaluation with just three competitors that PbA is the best method available, it</context>
<context position="22971" citStr="Yvon 1996" startWordPosition="3559" endWordPosition="3560">of PbA can vary. In the following, when we refer to a multistrategy approach to PbA, it is principally the use of multiple scoring strategies which is at issue. 3.2 Appraisal PRONOUNCE was evaluated on just 70 monosyllabic pseudowords—a subset of those previously used in reading studies by Glushko (1979). Such a test is largely irrelevant to TTS applications: the test set is not representative of general English, either in the small number of words used or their length. Also, D&amp;N&apos;s claimed results on this pseudoword test set have proved impossible to replicate (Damper and Eastmond 1996, 1997; Yvon 1996; Bagshaw 1998). In addition, no consideration is given to the case where no complete path through the lattice exists (the silence problem mentioned earlier). D&amp;N&apos;s pattern matching (when building the pronunciation lattice) is a &amp;quot;partial&amp;quot; one. That is, as explained in section 3.1.1, the process starts with the leftmost letter of the input string and of the current dictionary entry aligned and continues until the two are right-aligned. They give (on page 59) the example of the input word blope matching to the lexical entry sloping. At the first iteration, the initial b of blope aligns with the </context>
<context position="43153" citStr="Yvon (1996)" startWordPosition="6911" endWordPosition="6912">when all the shortest paths through the lattice give the identical, correct pronunciation. On the other hand, the maximal percentage indicates the upper bound that obtains when the second heuristic always chooses the correct candidate, i.e., there is at least one correct pronunciation among the shortest paths. Overall, these statistics indicate that there is considerable scope to improve the second heuristic, since the upper bound of 85.1% words correct for letter-to-phoneme conversion, for instance, is vastly superior to our previous best value of 61.9% and to the figure of 64.0% obtained by Yvon (1996) on the same lexicon using multiple unbounded overlapping chunks as the nodes of the pronunciation lattice. They also suggest (in line with our intuitions) that letter-to-phoneme conver209 Computational Linguistics Volume 26, Number 2 Table 5 Statistics describing the occurrence of correct pronunciations among the shortest paths of the pronunciation lattices for all the words in the lexicon. Type of Minimal Maximal Mean Candidates Mean Good Candidates Conversion Percentage Percentage per Word per Word Letter-phoneme 15.3 85.1 7.9 2.2 Phoneme-letter 31.0 89.1 5.9 2.3 Letter-stress 11.6 78.2 7.5</context>
</contexts>
<marker>Yvon, 1996</marker>
<rawString>Yvon, Francois. 1996. Grapheme-tophoneme conversion using multiple unbounded overlapping chunks. In Proceedings of the Conference on New Methods in Natural Language Processing, NeMLaP &apos;96, pages 218-228, Ankara, Turkey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francois Yvon</author>
</authors>
<title>Paradigmatic cascades: A linguistically sound model of pronunciation by analogy.</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics and the 8th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>429--435</pages>
<location>Madrid,</location>
<marker>Yvon, 1997</marker>
<rawString>Yvon, Francois. 1997. Paradigmatic cascades: A linguistically sound model of pronunciation by analogy. In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics and the 8th Conference of the European Chapter of the Association for Computational Linguistics, pages 429-435, Madrid, Spain.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>