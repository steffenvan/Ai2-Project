<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004332">
<title confidence="0.997132">
Identifying Perspectives at the Document and Sentence Levels Using
Statistical Models
</title>
<author confidence="0.989221">
Wei-Hao Lin*
</author>
<affiliation confidence="0.801129666666667">
Language Technologies Institute
Carnegie Mellon University
Pittsburgh, PA 15213 U.S.A.
</affiliation>
<email confidence="0.996704">
whlin@cs.cmu.edu
</email>
<sectionHeader confidence="0.993869" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99960925">
In this paper we investigate the problem of
identifying the perspective from which a
document was written. By perspective we
mean a point of view, for example, from
the perspective of Democrats or Repub-
licans. Can computers learn to identify
the perspective of a document? Further-
more, can computers identify which sen-
tences in a document strongly convey a
particular perspective? We develop sta-
tistical models to capture how perspec-
tives are expressed at the document and
sentence levels, and evaluate the proposed
models on a collection of articles on the
Israeli-Palestinian conflict. The results
show that the statistical models can suc-
cessfully learn how perspectives are re-
flected in word usage and identify the per-
spective of a document with very high ac-
curacy.
</bodyText>
<sectionHeader confidence="0.99914" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998241">
In this paper we investigate the problem of auto-
matically identifying the perspective from which a
document was written. By perspective, we mean
“subjective evaluation of relative significance, a
point-of-view.” For example, documents about the
Palestinian-Israeli conflict may appear to be about
the same topic, but reveal different perspectives:
</bodyText>
<footnote confidence="0.793519">
This is joint work with Theresa Wilson, Janyce Wiebe, and
Alexander Hauptmann, and supported by the Advanced Re-
search and Development Activity (ARDA) under contract num-
ber NBCHC040037.
</footnote>
<bodyText confidence="0.784056523809524">
(1) The inadvertent killing by Israeli forces of
Palestinian civilians – usually in the course of
shooting at Palestinian terrorists – is
considered no different at the moral and ethical
level than the deliberate targeting of Israeli
civilians by Palestinian suicide bombers.
(2) In the first weeks of the Intifada, for example,
Palestinian public protests and civilian
demonstrations were answered brutally by
Israel, which killed tens of unarmed protesters.
Example 1 is written from a Israeli perspective; Ex-
ample 2 is written from a Palestinian perspective .
We aim to address a research question: can comput-
ers learn to identify the perspective of a document
given a training corpus of documents that are writ-
ten from different perspectives?
When an issue is discussed from different per-
spectives, not every sentence in a document strongly
reflects the perspective the author possesses. For ex-
ample, the following sentences are written by one
Palestinian and one Israeli:
</bodyText>
<listItem confidence="0.9642348">
(3) The Rhodes agreements of 1949 set them as
the ceasefire lines between Israel and the Arab
states.
(4) The green line was drawn up at the Rhodes
Armistice talks in 1948-49.
</listItem>
<bodyText confidence="0.943415333333333">
Example 3 and 4 both factually introduce the back-
ground of the issue of the “green line” without
expressing explicit perspectives. Can computers
automatically discriminate between sentences that
strongly express a perspective and sentences that
only reflect shared background information?
</bodyText>
<page confidence="0.956583">
227
</page>
<note confidence="0.8682945">
Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 227–230,
New York, June 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999916916666667">
A system that can automatically identify the per-
spective from which a document written will be a
highly desirable tool for people analyzing huge col-
lections of documents from different perspectives.
An intelligence analyst regularly monitors the po-
sitions that foreign countries take on political and
diplomatic issues. A media analyst frequently sur-
veys broadcast news, newspapers, and web blogs for
different viewpoints. What these analysts need in
common is that they would like to find evidence of
strong statements of differing perspectives, while ig-
noring statements without strong perspectives as less
interesting.
In this paper we approach the problem of learning
perspectives in a statistical learning framework. We
develop statistical models to learn how perspectives
are reflected in word usage, and evaluate the models
by measuring how accurately they can predict the
perspectives of unseen documents. Lacking anno-
tation on how strongly individual sentences convey
a particular perspective in our corpus poses a chal-
lenge on learning sentence-level perspectives. We
propose a novel statistical model, Latent Sentence
Perspective Model, to address the problem.
</bodyText>
<sectionHeader confidence="0.999287" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999521391304348">
Identifying the perspective from which a document
is written is a subtask in the growing area of auto-
matic opinion recognition and extraction. Subjec-
tive language is used to express opinions, emotions,
and sentiments. So far research in automatic opinion
recognition has primarily addressed learning sub-
jective language (Wiebe et al., 2004; Riloff et al.,
2003; Riloff and Wiebe, 2003), identifying opinion-
ated documents (Yu and Hatzivassiloglou, 2003) and
sentences (Yu and Hatzivassiloglou, 2003; Riloff et
al., 2003; Riloff and Wiebe, 2003), and discriminat-
ing between positive and negative language (Yu and
Hatzivassiloglou, 2003; Turney and Littman, 2003;
Pang et al., 2002; Dave et al., 2003; Nasukawa and
Yi, 2003; Morinaga et al., 2002).
Although by its very nature we expect much of
the language of presenting a perspective or point-
of-view to be subjective, labeling a document or a
sentence as subjective is not enough to identify the
perspective from which it is written. Moreover, the
ideology and beliefs authors possess are often ex-
pressed in ways more than conspicuous positive or
negative language toward specific targets.
</bodyText>
<sectionHeader confidence="0.989759" genericHeader="method">
3 Corpus
</sectionHeader>
<bodyText confidence="0.999926625">
Our corpus consists of articles published on the
bitterlemons website1. The website is set up
to “contribute to mutual understanding [between
Palestinians and Israels] through the open exchange
of ideas”. Every week an issue about Israeli-
Palestinian conflict is selected for discussion, for
example, “Disengagement: unilateral or coordi-
nated?”, and a Palestinian editor and an Israeli edi-
tor contribute a article addressing the issue. In ad-
dition, the Israeli and Palestinian editors invite or
interview one Israeli and one Palestinian to express
their views, resulting in a total of four articles in a
weekly edition.
We evaluate the subjectivity of each sentence us-
ing the patterns automatically extracted from foreign
news documents (Riloff and Wiebe, 2003), and find
that 65.6% of Palestinian sentences and 66.2% of Is-
raeli sentences are classified as subjective. The high
but almost equivalent percentages of subjective sen-
tences from two perspectives supports our observa-
tion in Section 2 that perspective is largely expressed
in subjective language but subjectivity ratio is not
necessarily indicative of the perspective of a docu-
ment.
</bodyText>
<sectionHeader confidence="0.99511" genericHeader="method">
4 Statistical Modeling of Perspectives
</sectionHeader>
<bodyText confidence="0.999902625">
We approach the problem of learning perspectives in
a statistical learning framework. Denote a training
corpus as pairs of documents Wn and their perspec-
tives labels Dn, n = 1, ... , N, N is the total number
of documents in the corpus. Given a new document
W with a unknown document perspective �
tifying its perspective is to calculate the following
conditional probability,
</bodyText>
<equation confidence="0.994635">
P(�D|�W,{Dn,Wn}n1) (5)
</equation>
<bodyText confidence="0.988413333333333">
We are interested in how strongly each sentence in
the document convey perspective. Denote the inten-
sity of the m-th sentence of the n-th document as a
binary random variable 5m,n, m = 1, ... , Mn, Mn
is the total number of sentences of the n-th docu-
ment. Evaluating how strongly a sentence conveys
</bodyText>
<footnote confidence="0.987927">
1http://www.bitterlemons.org
</footnote>
<table confidence="0.452805">
D, iden-
</table>
<page confidence="0.978614">
228
</page>
<bodyText confidence="0.9360845">
a particular perspective is to calculate the following
conditional probability,
</bodyText>
<equation confidence="0.9635785">
Pn,Wn}n 1)
(Sm,n|{D (6)
</equation>
<subsectionHeader confidence="0.988101">
4.1 Document Perspective Models
</subsectionHeader>
<bodyText confidence="0.9985005">
The process of generating documents from a partic-
ular perspective is modeled as follows,
</bodyText>
<equation confidence="0.9986345">
π — Beta(απ, βπ)
θ — Dirichlet(αθ)
Dn — Binomial(1, π)
Wn — Multinomial(Ln, θd)
</equation>
<bodyText confidence="0.999205142857143">
The model is known as naive Bayes models (NB),
which has been widely used for NLP tasks such as
text categorization (Lewis, 1998). To calculate (5)
under NB in a full Bayesian manner is, however,
complicated, and alternatively we employ Markov
Chain Monte Carlo (MCMC) methods to simulate
samples from the posterior distributions.
</bodyText>
<subsectionHeader confidence="0.997714">
4.2 Latent Sentence Perspective Models
</subsectionHeader>
<bodyText confidence="0.999954">
We introduce a new binary random variables, S, to
model how strongly a perspective is expressed at
the sentence level. The value of S is either s1 or
s0, where s1 means the sentence is written strongly
from a perspective, and s0 is not. The whole gener-
ative process is modeled as follows,
</bodyText>
<equation confidence="0.9999545">
π — Beta(απ, βπ)
τ — Beta(ατ, βτ)
θ — Dirichlet(αθ)
Dn — Binomial(1, π)
Sm,n — Binomial(1, τ)
Wm,n — Multinomial(Lm,n, θ)
</equation>
<bodyText confidence="0.999855272727273">
π and θ carry the same semantics as those in NB.
S is naturally modeled as a binary variable, where
τ is the parameter of S and represents how likely
a perspective is strongly expressed at the sentence
given on the overall document perspective. We call
this model Latent Sentence Perspective Models
(LSPM), because S is never directly observed in ei-
ther training or testing documents and need to be in-
ferred. To calculate (6) under LSPM is difficult. We
again resort to MCMC methods to simulate samples
from the posterior distributions.
</bodyText>
<sectionHeader confidence="0.999201" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.878770533333333">
5.1 Identifying Perspectives at the Document
Level
To objectively evaluate how well naive Bayes mod-
els (NB) learn to identify perspectives expressed
at the document level, we train NB against on the
bitterlemons corpus, and evaluate how accu-
rately NB predicts the perspective of a unseen doc-
ument as either Palestinian or Israeli in ten-fold
cross-validation manner. The average classification
accuracy over 10 folds is reported. We compare
three different models, including NB with two dif-
ferent inference methods and Support Vector Ma-
chines (SVM) (Cristianini and Shawe-Taylor, 2000).
NB-B uses full Bayesian inference and NB-M uses
Maximum a posteriori (MAP) .
</bodyText>
<table confidence="0.999075125">
Model Data Set Accuracy Reduction
Baseline 0.5
SVM Editors 0.9724
NB-M Editors 0.9895 61%
NB-B Editors 0.9909 67%
SVM Guests 0.8621
NB-M Guests 0.8789 12%
NB-B Guests 0.8859 17%
</table>
<tableCaption confidence="0.9148205">
Table 1: Results of Identifying Perspectives at the
Document Level
</tableCaption>
<bodyText confidence="0.999353">
The results in Table 1 show that both NB and
SVM perform surprisingly well on both Editors and
Guests subsets of the bitterlemons corpus. We
also see that NBs further reduce classification er-
rors even though SVM already achieves high accu-
racy. By considering the full posterior distribution
NB-B further improves on NB-M, which performs
only point estimation. The results strongly suggest
that the word choices made by authors, either con-
sciously or subconsciously, reflect much of their po-
litical perspectives.
</bodyText>
<subsectionHeader confidence="0.9161975">
5.2 Identifying Perspectives at the Sentence
Level
</subsectionHeader>
<bodyText confidence="0.99997875">
In addition to identify the perspectives of a doc-
ument, we are interested in which sentences in
the document strongly convey perspectives. Al-
though the posterior probability that a sentence
</bodyText>
<page confidence="0.996313">
229
</page>
<bodyText confidence="0.9997319">
covey strongly perspectives in (6) is of our inter-
est, we can not directly evaluate their quality due to
the lack of golden truth at the sentence level. Alter-
natively we evaluate how accurately LSPM predicts
the perspective of a document, in the same way of
evaluating SVM and NB in the previous section. If
LSPM does not achieve similar identification accu-
racy after modeling sentence-level information, we
will doubt the quality of predictions on how strongly
a sentence convey perspective made by LSPM.
</bodyText>
<table confidence="0.999138875">
Model Training Testing Accuracy
Baseline 0.5
NB-M Guest Editor 0.9327
NB-B Guest Editor 0.9346
LSPM Guest Editor 0.9493
NB-M Editors Guests 0.8485
NB-B Editors Guests 0.8585
LSPM Guest Editor 0.8699
</table>
<tableCaption confidence="0.963387">
Table 2: Results of Perspective Identification at the
Sentence Level
</tableCaption>
<bodyText confidence="0.999785368421052">
The experimental results in Table 2 show that the
LSPM achieves similarly or even slightly better ac-
curacy than those of NBs, which is very encourag-
ing and suggests that the proposed LSPM closely
match how perspectives are expressed at the docu-
ment and sentence levels. If one does not explic-
itly model the uncertainty at the sentence level, one
can train NB directly against the sentences to clas-
sify a sentence into Palestinian or Israeli perspec-
tive. We obtain the accuracy of 0.7529, which is
much lower than the accuracy previously achieved
at the document level. Therefore identifying per-
spective at the sentence level is much harder than
at that the document level, and the high accuracy
of identifying document-level perspectives suggests
that LPSM closely captures the perspectives ex-
pressed at the document and sentence levels, given
individual sentences are very short and much less in-
formative about overall perspective.
</bodyText>
<sectionHeader confidence="0.978113" genericHeader="conclusions">
6 Summary of Contributions
</sectionHeader>
<bodyText confidence="0.99945225">
In this paper we study the problem of learning
to identify the perspective from which a text was
written at the document and sentence levels. We
show that perspectives are expressed in word us-
age, and statistical learning algorithms such as SVM
and naive Bayes models can successfully uncover
the word patterns chosen by authors from differ-
ent perspectives. Furthermore, we develop a novel
statistical model to infer how strongly a sentence
convey perspective without any labels. By intro-
ducing latent variables, Latent Sentence Perspective
Models are shown to capture well how perspectives
are reflected at the document and sentence levels.
The proposed statistical models can help analysts
sift through a large collection of documents written
from different perspectives. The unique sentence-
level perspective modeling can automatically iden-
tify sentences that are strongly representative of the
perspective of interest, and we plan to manually
evaluate their quality in the future work.
</bodyText>
<sectionHeader confidence="0.999395" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999502114285714">
Nello Cristianini and John Shawe-Taylor. 2000. An Introduction to Support Vec-
tor Machines and Other Kernel-based Learning Methods. Cambridge Univer-
sity Press.
Kushal Dave, Steve Lawrence, and David M. Pennock. 2003. Mining the
peanut gallery: Opinion extraction and semantic classification of product re-
views. In Proceedings of the 12th International World Wide Web Conference
(WWW2003).
David D. Lewis. 1998. Naive (Bayes) at forty: The independence assumption in
information retrieval. In Proceedings of the European Conference on Machine
Learning (ECML).
S. Morinaga, K. Yamanishi, K. Tateishi, and T. Fukushima. 2002. Mining product
reputations on the web. In Proceedings of the 2002 ACM SIGKDD Interna-
tional Conference on Knowledge Discovery and Data Mining.
T. Nasukawa and J. Yi. 2003. Sentiment analysis: Capturing favorability using
natural language processing. In Proceedings of the 2nd International Confer-
ence on Knowledge Capture (K-CAP 2003).
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? Senti-
ment classification using machine learning techniques. In Proceedings of the
Conference on Empirical Methods in Natural Language Processing (EMNLP-
2002).
Ellen Riloff and Janyce Wiebe. 2003. Learning extraction patterns for subjec-
tive expressions. In Proceedings of the Conference on Empirical Methods in
Natural Language Processing (EMNLP-2003).
Ellen Riloff, Janyce Wiebe, and Theresa Wilson. 2003. Learning subjective nouns
using extraction pattern bootstrapping. In Proceedings of the 7th Conference
on Natural Language Learning (CoNLL-2003).
Peter Turney and Michael L. Littman. 2003. Measuring praise and criticism:
Inference of semantic orientation from association. ACM Transactions on
Information Systems (TOIS), 21(4):315–346.
Janyce Wiebe, Theresa Wilson, Rebecca Bruce, Matthew Bell, and Melanie Mar-
tin. 2004. Learning subjective language. Computational Linguistics, 30(3).
Hong Yu and Vasileios Hatzivassiloglou. 2003. Towards answering opinion ques-
tions: Separating facts from opinions and identifying the polarity of opinion
sentences. In Proceedings of the Conference on Empirical Methods in Natural
Language Processing (EMNLP-2003).
</reference>
<page confidence="0.997037">
230
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.542492">
<title confidence="0.911163333333333">Identifying Perspectives at the Document and Sentence Levels Statistical Models Language Technologies</title>
<affiliation confidence="0.966241">Carnegie Mellon</affiliation>
<address confidence="0.996977">Pittsburgh, PA 15213</address>
<email confidence="0.998713">whlin@cs.cmu.edu</email>
<abstract confidence="0.987700333333333">In this paper we investigate the problem of identifying the perspective from which a document was written. By perspective we mean a point of view, for example, from the perspective of Democrats or Republicans. Can computers learn to identify the perspective of a document? Furthermore, can computers identify which sentences in a document strongly convey a particular perspective? We develop statistical models to capture how perspectives are expressed at the document and sentence levels, and evaluate the proposed models on a collection of articles on the Israeli-Palestinian conflict. The results show that the statistical models can successfully learn how perspectives are reflected in word usage and identify the perspective of a document with very high accuracy.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Nello Cristianini</author>
<author>John Shawe-Taylor</author>
</authors>
<title>An Introduction to Support Vector Machines and Other Kernel-based Learning Methods.</title>
<date>2000</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="9635" citStr="Cristianini and Shawe-Taylor, 2000" startWordPosition="1504" endWordPosition="1507">s from the posterior distributions. 5 Experiments 5.1 Identifying Perspectives at the Document Level To objectively evaluate how well naive Bayes models (NB) learn to identify perspectives expressed at the document level, we train NB against on the bitterlemons corpus, and evaluate how accurately NB predicts the perspective of a unseen document as either Palestinian or Israeli in ten-fold cross-validation manner. The average classification accuracy over 10 folds is reported. We compare three different models, including NB with two different inference methods and Support Vector Machines (SVM) (Cristianini and Shawe-Taylor, 2000). NB-B uses full Bayesian inference and NB-M uses Maximum a posteriori (MAP) . Model Data Set Accuracy Reduction Baseline 0.5 SVM Editors 0.9724 NB-M Editors 0.9895 61% NB-B Editors 0.9909 67% SVM Guests 0.8621 NB-M Guests 0.8789 12% NB-B Guests 0.8859 17% Table 1: Results of Identifying Perspectives at the Document Level The results in Table 1 show that both NB and SVM perform surprisingly well on both Editors and Guests subsets of the bitterlemons corpus. We also see that NBs further reduce classification errors even though SVM already achieves high accuracy. By considering the full posterio</context>
</contexts>
<marker>Cristianini, Shawe-Taylor, 2000</marker>
<rawString>Nello Cristianini and John Shawe-Taylor. 2000. An Introduction to Support Vector Machines and Other Kernel-based Learning Methods. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kushal Dave</author>
<author>Steve Lawrence</author>
<author>David M Pennock</author>
</authors>
<title>Mining the peanut gallery: Opinion extraction and semantic classification of product reviews.</title>
<date>2003</date>
<booktitle>In Proceedings of the 12th International World Wide Web Conference (WWW2003).</booktitle>
<contexts>
<context position="5042" citStr="Dave et al., 2003" startWordPosition="761" endWordPosition="764"> growing area of automatic opinion recognition and extraction. Subjective language is used to express opinions, emotions, and sentiments. So far research in automatic opinion recognition has primarily addressed learning subjective language (Wiebe et al., 2004; Riloff et al., 2003; Riloff and Wiebe, 2003), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Yu and Hatzivassiloglou, 2003; Riloff et al., 2003; Riloff and Wiebe, 2003), and discriminating between positive and negative language (Yu and Hatzivassiloglou, 2003; Turney and Littman, 2003; Pang et al., 2002; Dave et al., 2003; Nasukawa and Yi, 2003; Morinaga et al., 2002). Although by its very nature we expect much of the language of presenting a perspective or pointof-view to be subjective, labeling a document or a sentence as subjective is not enough to identify the perspective from which it is written. Moreover, the ideology and beliefs authors possess are often expressed in ways more than conspicuous positive or negative language toward specific targets. 3 Corpus Our corpus consists of articles published on the bitterlemons website1. The website is set up to “contribute to mutual understanding [between Palesti</context>
</contexts>
<marker>Dave, Lawrence, Pennock, 2003</marker>
<rawString>Kushal Dave, Steve Lawrence, and David M. Pennock. 2003. Mining the peanut gallery: Opinion extraction and semantic classification of product reviews. In Proceedings of the 12th International World Wide Web Conference (WWW2003).</rawString>
</citation>
<citation valid="true">
<authors>
<author>David D Lewis</author>
</authors>
<title>Naive (Bayes) at forty: The independence assumption in information retrieval.</title>
<date>1998</date>
<booktitle>In Proceedings of the European Conference on Machine Learning (ECML).</booktitle>
<contexts>
<context position="7847" citStr="Lewis, 1998" startWordPosition="1212" endWordPosition="1213">ndom variable 5m,n, m = 1, ... , Mn, Mn is the total number of sentences of the n-th document. Evaluating how strongly a sentence conveys 1http://www.bitterlemons.org D, iden228 a particular perspective is to calculate the following conditional probability, Pn,Wn}n 1) (Sm,n|{D (6) 4.1 Document Perspective Models The process of generating documents from a particular perspective is modeled as follows, π — Beta(απ, βπ) θ — Dirichlet(αθ) Dn — Binomial(1, π) Wn — Multinomial(Ln, θd) The model is known as naive Bayes models (NB), which has been widely used for NLP tasks such as text categorization (Lewis, 1998). To calculate (5) under NB in a full Bayesian manner is, however, complicated, and alternatively we employ Markov Chain Monte Carlo (MCMC) methods to simulate samples from the posterior distributions. 4.2 Latent Sentence Perspective Models We introduce a new binary random variables, S, to model how strongly a perspective is expressed at the sentence level. The value of S is either s1 or s0, where s1 means the sentence is written strongly from a perspective, and s0 is not. The whole generative process is modeled as follows, π — Beta(απ, βπ) τ — Beta(ατ, βτ) θ — Dirichlet(αθ) Dn — Binomial(1, π</context>
</contexts>
<marker>Lewis, 1998</marker>
<rawString>David D. Lewis. 1998. Naive (Bayes) at forty: The independence assumption in information retrieval. In Proceedings of the European Conference on Machine Learning (ECML).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Morinaga</author>
<author>K Yamanishi</author>
<author>K Tateishi</author>
<author>T Fukushima</author>
</authors>
<title>Mining product reputations on the web.</title>
<date>2002</date>
<booktitle>In Proceedings of the 2002 ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.</booktitle>
<contexts>
<context position="5089" citStr="Morinaga et al., 2002" startWordPosition="769" endWordPosition="772">tion and extraction. Subjective language is used to express opinions, emotions, and sentiments. So far research in automatic opinion recognition has primarily addressed learning subjective language (Wiebe et al., 2004; Riloff et al., 2003; Riloff and Wiebe, 2003), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Yu and Hatzivassiloglou, 2003; Riloff et al., 2003; Riloff and Wiebe, 2003), and discriminating between positive and negative language (Yu and Hatzivassiloglou, 2003; Turney and Littman, 2003; Pang et al., 2002; Dave et al., 2003; Nasukawa and Yi, 2003; Morinaga et al., 2002). Although by its very nature we expect much of the language of presenting a perspective or pointof-view to be subjective, labeling a document or a sentence as subjective is not enough to identify the perspective from which it is written. Moreover, the ideology and beliefs authors possess are often expressed in ways more than conspicuous positive or negative language toward specific targets. 3 Corpus Our corpus consists of articles published on the bitterlemons website1. The website is set up to “contribute to mutual understanding [between Palestinians and Israels] through the open exchange of</context>
</contexts>
<marker>Morinaga, Yamanishi, Tateishi, Fukushima, 2002</marker>
<rawString>S. Morinaga, K. Yamanishi, K. Tateishi, and T. Fukushima. 2002. Mining product reputations on the web. In Proceedings of the 2002 ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Nasukawa</author>
<author>J Yi</author>
</authors>
<title>Sentiment analysis: Capturing favorability using natural language processing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2nd International Conference on Knowledge Capture (K-CAP</booktitle>
<contexts>
<context position="5065" citStr="Nasukawa and Yi, 2003" startWordPosition="765" endWordPosition="768">tomatic opinion recognition and extraction. Subjective language is used to express opinions, emotions, and sentiments. So far research in automatic opinion recognition has primarily addressed learning subjective language (Wiebe et al., 2004; Riloff et al., 2003; Riloff and Wiebe, 2003), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Yu and Hatzivassiloglou, 2003; Riloff et al., 2003; Riloff and Wiebe, 2003), and discriminating between positive and negative language (Yu and Hatzivassiloglou, 2003; Turney and Littman, 2003; Pang et al., 2002; Dave et al., 2003; Nasukawa and Yi, 2003; Morinaga et al., 2002). Although by its very nature we expect much of the language of presenting a perspective or pointof-view to be subjective, labeling a document or a sentence as subjective is not enough to identify the perspective from which it is written. Moreover, the ideology and beliefs authors possess are often expressed in ways more than conspicuous positive or negative language toward specific targets. 3 Corpus Our corpus consists of articles published on the bitterlemons website1. The website is set up to “contribute to mutual understanding [between Palestinians and Israels] thro</context>
</contexts>
<marker>Nasukawa, Yi, 2003</marker>
<rawString>T. Nasukawa and J. Yi. 2003. Sentiment analysis: Capturing favorability using natural language processing. In Proceedings of the 2nd International Conference on Knowledge Capture (K-CAP 2003).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up? Sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP2002).</booktitle>
<contexts>
<context position="5023" citStr="Pang et al., 2002" startWordPosition="757" endWordPosition="760">is a subtask in the growing area of automatic opinion recognition and extraction. Subjective language is used to express opinions, emotions, and sentiments. So far research in automatic opinion recognition has primarily addressed learning subjective language (Wiebe et al., 2004; Riloff et al., 2003; Riloff and Wiebe, 2003), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Yu and Hatzivassiloglou, 2003; Riloff et al., 2003; Riloff and Wiebe, 2003), and discriminating between positive and negative language (Yu and Hatzivassiloglou, 2003; Turney and Littman, 2003; Pang et al., 2002; Dave et al., 2003; Nasukawa and Yi, 2003; Morinaga et al., 2002). Although by its very nature we expect much of the language of presenting a perspective or pointof-view to be subjective, labeling a document or a sentence as subjective is not enough to identify the perspective from which it is written. Moreover, the ideology and beliefs authors possess are often expressed in ways more than conspicuous positive or negative language toward specific targets. 3 Corpus Our corpus consists of articles published on the bitterlemons website1. The website is set up to “contribute to mutual understandi</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? Sentiment classification using machine learning techniques. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP2002).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Janyce Wiebe</author>
</authors>
<title>Learning extraction patterns for subjective expressions.</title>
<date>2003</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2003).</booktitle>
<contexts>
<context position="4730" citStr="Riloff and Wiebe, 2003" startWordPosition="715" endWordPosition="718">individual sentences convey a particular perspective in our corpus poses a challenge on learning sentence-level perspectives. We propose a novel statistical model, Latent Sentence Perspective Model, to address the problem. 2 Related Work Identifying the perspective from which a document is written is a subtask in the growing area of automatic opinion recognition and extraction. Subjective language is used to express opinions, emotions, and sentiments. So far research in automatic opinion recognition has primarily addressed learning subjective language (Wiebe et al., 2004; Riloff et al., 2003; Riloff and Wiebe, 2003), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Yu and Hatzivassiloglou, 2003; Riloff et al., 2003; Riloff and Wiebe, 2003), and discriminating between positive and negative language (Yu and Hatzivassiloglou, 2003; Turney and Littman, 2003; Pang et al., 2002; Dave et al., 2003; Nasukawa and Yi, 2003; Morinaga et al., 2002). Although by its very nature we expect much of the language of presenting a perspective or pointof-view to be subjective, labeling a document or a sentence as subjective is not enough to identify the perspective from which it is written. Mo</context>
<context position="6253" citStr="Riloff and Wiebe, 2003" startWordPosition="951" endWordPosition="954">ween Palestinians and Israels] through the open exchange of ideas”. Every week an issue about IsraeliPalestinian conflict is selected for discussion, for example, “Disengagement: unilateral or coordinated?”, and a Palestinian editor and an Israeli editor contribute a article addressing the issue. In addition, the Israeli and Palestinian editors invite or interview one Israeli and one Palestinian to express their views, resulting in a total of four articles in a weekly edition. We evaluate the subjectivity of each sentence using the patterns automatically extracted from foreign news documents (Riloff and Wiebe, 2003), and find that 65.6% of Palestinian sentences and 66.2% of Israeli sentences are classified as subjective. The high but almost equivalent percentages of subjective sentences from two perspectives supports our observation in Section 2 that perspective is largely expressed in subjective language but subjectivity ratio is not necessarily indicative of the perspective of a document. 4 Statistical Modeling of Perspectives We approach the problem of learning perspectives in a statistical learning framework. Denote a training corpus as pairs of documents Wn and their perspectives labels Dn, n = 1, .</context>
</contexts>
<marker>Riloff, Wiebe, 2003</marker>
<rawString>Ellen Riloff and Janyce Wiebe. 2003. Learning extraction patterns for subjective expressions. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2003).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Janyce Wiebe</author>
<author>Theresa Wilson</author>
</authors>
<title>Learning subjective nouns using extraction pattern bootstrapping.</title>
<date>2003</date>
<booktitle>In Proceedings of the 7th Conference on Natural Language Learning (CoNLL-2003).</booktitle>
<contexts>
<context position="4705" citStr="Riloff et al., 2003" startWordPosition="711" endWordPosition="714">tion on how strongly individual sentences convey a particular perspective in our corpus poses a challenge on learning sentence-level perspectives. We propose a novel statistical model, Latent Sentence Perspective Model, to address the problem. 2 Related Work Identifying the perspective from which a document is written is a subtask in the growing area of automatic opinion recognition and extraction. Subjective language is used to express opinions, emotions, and sentiments. So far research in automatic opinion recognition has primarily addressed learning subjective language (Wiebe et al., 2004; Riloff et al., 2003; Riloff and Wiebe, 2003), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Yu and Hatzivassiloglou, 2003; Riloff et al., 2003; Riloff and Wiebe, 2003), and discriminating between positive and negative language (Yu and Hatzivassiloglou, 2003; Turney and Littman, 2003; Pang et al., 2002; Dave et al., 2003; Nasukawa and Yi, 2003; Morinaga et al., 2002). Although by its very nature we expect much of the language of presenting a perspective or pointof-view to be subjective, labeling a document or a sentence as subjective is not enough to identify the perspective fro</context>
</contexts>
<marker>Riloff, Wiebe, Wilson, 2003</marker>
<rawString>Ellen Riloff, Janyce Wiebe, and Theresa Wilson. 2003. Learning subjective nouns using extraction pattern bootstrapping. In Proceedings of the 7th Conference on Natural Language Learning (CoNLL-2003).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Turney</author>
<author>Michael L Littman</author>
</authors>
<title>Measuring praise and criticism: Inference of semantic orientation from association.</title>
<date>2003</date>
<journal>ACM Transactions on Information Systems (TOIS),</journal>
<volume>21</volume>
<issue>4</issue>
<contexts>
<context position="5004" citStr="Turney and Littman, 2003" startWordPosition="753" endWordPosition="756">ich a document is written is a subtask in the growing area of automatic opinion recognition and extraction. Subjective language is used to express opinions, emotions, and sentiments. So far research in automatic opinion recognition has primarily addressed learning subjective language (Wiebe et al., 2004; Riloff et al., 2003; Riloff and Wiebe, 2003), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Yu and Hatzivassiloglou, 2003; Riloff et al., 2003; Riloff and Wiebe, 2003), and discriminating between positive and negative language (Yu and Hatzivassiloglou, 2003; Turney and Littman, 2003; Pang et al., 2002; Dave et al., 2003; Nasukawa and Yi, 2003; Morinaga et al., 2002). Although by its very nature we expect much of the language of presenting a perspective or pointof-view to be subjective, labeling a document or a sentence as subjective is not enough to identify the perspective from which it is written. Moreover, the ideology and beliefs authors possess are often expressed in ways more than conspicuous positive or negative language toward specific targets. 3 Corpus Our corpus consists of articles published on the bitterlemons website1. The website is set up to “contribute to</context>
</contexts>
<marker>Turney, Littman, 2003</marker>
<rawString>Peter Turney and Michael L. Littman. 2003. Measuring praise and criticism: Inference of semantic orientation from association. ACM Transactions on Information Systems (TOIS), 21(4):315–346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Theresa Wilson</author>
<author>Rebecca Bruce</author>
<author>Matthew Bell</author>
<author>Melanie Martin</author>
</authors>
<title>Learning subjective language.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>3</issue>
<contexts>
<context position="4684" citStr="Wiebe et al., 2004" startWordPosition="707" endWordPosition="710">ents. Lacking annotation on how strongly individual sentences convey a particular perspective in our corpus poses a challenge on learning sentence-level perspectives. We propose a novel statistical model, Latent Sentence Perspective Model, to address the problem. 2 Related Work Identifying the perspective from which a document is written is a subtask in the growing area of automatic opinion recognition and extraction. Subjective language is used to express opinions, emotions, and sentiments. So far research in automatic opinion recognition has primarily addressed learning subjective language (Wiebe et al., 2004; Riloff et al., 2003; Riloff and Wiebe, 2003), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Yu and Hatzivassiloglou, 2003; Riloff et al., 2003; Riloff and Wiebe, 2003), and discriminating between positive and negative language (Yu and Hatzivassiloglou, 2003; Turney and Littman, 2003; Pang et al., 2002; Dave et al., 2003; Nasukawa and Yi, 2003; Morinaga et al., 2002). Although by its very nature we expect much of the language of presenting a perspective or pointof-view to be subjective, labeling a document or a sentence as subjective is not enough to identif</context>
</contexts>
<marker>Wiebe, Wilson, Bruce, Bell, Martin, 2004</marker>
<rawString>Janyce Wiebe, Theresa Wilson, Rebecca Bruce, Matthew Bell, and Melanie Martin. 2004. Learning subjective language. Computational Linguistics, 30(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hong Yu</author>
<author>Vasileios Hatzivassiloglou</author>
</authors>
<title>Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences.</title>
<date>2003</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2003).</booktitle>
<contexts>
<context position="4797" citStr="Yu and Hatzivassiloglou, 2003" startWordPosition="723" endWordPosition="726">corpus poses a challenge on learning sentence-level perspectives. We propose a novel statistical model, Latent Sentence Perspective Model, to address the problem. 2 Related Work Identifying the perspective from which a document is written is a subtask in the growing area of automatic opinion recognition and extraction. Subjective language is used to express opinions, emotions, and sentiments. So far research in automatic opinion recognition has primarily addressed learning subjective language (Wiebe et al., 2004; Riloff et al., 2003; Riloff and Wiebe, 2003), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Yu and Hatzivassiloglou, 2003; Riloff et al., 2003; Riloff and Wiebe, 2003), and discriminating between positive and negative language (Yu and Hatzivassiloglou, 2003; Turney and Littman, 2003; Pang et al., 2002; Dave et al., 2003; Nasukawa and Yi, 2003; Morinaga et al., 2002). Although by its very nature we expect much of the language of presenting a perspective or pointof-view to be subjective, labeling a document or a sentence as subjective is not enough to identify the perspective from which it is written. Moreover, the ideology and beliefs authors possess are often expresse</context>
</contexts>
<marker>Yu, Hatzivassiloglou, 2003</marker>
<rawString>Hong Yu and Vasileios Hatzivassiloglou. 2003. Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2003).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>