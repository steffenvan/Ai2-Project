<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000340">
<title confidence="0.99893">
Identifying Opinion Holders and Targets with Dependency Parser in
Chinese News Texts
</title>
<author confidence="0.99779">
Bin Lu
</author>
<affiliation confidence="0.98816725">
Department of Chinese, Translation and Linguistics &amp;
Language Information Sciences Research Centre
City University of Hong Kong
Kowloon, Hong Kong
</affiliation>
<email confidence="0.983085">
lubin2010@gmail.com
</email>
<sectionHeader confidence="0.997237" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999829916666667">
In this paper, we propose to identify
opinion holders and targets with
dependency parser in Chinese news texts,
i.e. to identify opinion holders by means of
reporting verbs and to identify opinion
targets by considering both opinion holders
and opinion-bearing words. The
experiments with NTCIR-7 MOAT’s
Chinese test data show that our approach
provides better performance than the
baselines and most systems reported at
NTCIR-7.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999923458333333">
In recent years, sentiment analysis, which mines
opinions from information sources such as news,
blogs and product reviews, has drawn much
attention in the NLP field (Hatzivassiloglou and
McKeown, 1997; Pang et al., 2002; Turney, 2002;
Hu and Liu, 2004).
An opinion expressed in a text involves different
components, including opinion expression, opinion
holder and target (Wilson and Wiebe, 2003).
Opinion holder is usually an entity that holds an
opinion, and opinion target is what the opinion is
about (Kim and Hovy, 2006). Although there have
been research on identifying opinion holders and
targets in English product reviews and news texts,
little work has been reported on similar tasks
involving Chinese news texts.
In this study, we investigate how dependency
parsing can be used to help the task on opinion
holder/target identification in Chinese news texts.
Three possible contributions from this study are: 1)
we propose that the existence of reporting verbs is
a very important feature for identifying opinion
holders in news texts, which has not been clearly
indicated; 2) we argue that the identification of
</bodyText>
<page confidence="0.989772">
46
</page>
<bodyText confidence="0.999806714285714">
opinion targets should not be done alone without
considering opinion holders, because opinion
holders are much easier to be identified in news
texts and the identified holders are quite useful for
the identification of the associated targets. Our
approach shows encouraging performance on
opinion holder/target identification, and the results
are much better than the baseline results and most
results reported in NTCIR-7 (Seki et al., 2008).
The paper is organized as follows. Sec. 2
introduces related work. Sec. 3 gives the linguistic
analysis of opinion holder/target. The proposed
approach is described in Sec. 4, followed by the
experiments in Sec. 5. Lastly we conclude in Sec. 6.
</bodyText>
<sectionHeader confidence="0.999926" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99975">
Although document-level sentiment analysis
(Turney, 2002; Pang et al., 2002) can provide the
overall polarity of the whole text, it fails to detect
the holders and targets of the sentiment in texts.
</bodyText>
<subsectionHeader confidence="0.959649">
2.1 Opinion Holders/ Target Identification
</subsectionHeader>
<bodyText confidence="0.9990648">
For opinion mining of product reviews, opinion
holder identification is usually omitted under the
assumption that opinion holder is the review writer;
and opinion targets are limited to the product
discussed and its features (Hu and Liu, 2004). But
in news texts, opinion holders/targets are more
diverse: all named entities and noun phrases can be
opinion holders; while opinion targets could be
noun phrases, verb phrases or even clauses (Kim
and Hovy, 2006; Ruppenhofer et al. 2008).
</bodyText>
<listItem confidence="0.75406425">
Bethard et al. (2004) identify opinion
propositions and their holders by semantic parsing
techniques. Choi et al. (2005) and Kim and Hovy
(2005) identify only opinion holders on the MPQA
corpus (Wilson and Wiebe, 2003). Kim and Hovy
(2006) proposed to map the semantic frames of
FrameNet into opinion holder and target for only
adjectives and verbs. Kim et al. (2008) proposed to
</listItem>
<subsectionHeader confidence="0.4269205">
Proceedings of the NAACL HLT 2010 Student Research Workshop, pages 46–51,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</subsectionHeader>
<bodyText confidence="0.999757666666667">
use syntactic structures for target identification
without considering opinion holders. Stoyanov and
Cardie (2008) define opinion topic and target and
treat the task as a co-reference resolution problem.
For the identification of opinion holders/targets
in Chinese, there were several reports at NTCIR-7
(Seki et al., 2008). Xu et al. (2008) proposed to use
some heuristic rules for opinion holder/target
identification. Ku et al. (2008) treated opinion
holder identification as a binary classification
problem of determining if a word was a part of an
opinion holder.
</bodyText>
<subsectionHeader confidence="0.99964">
2.2 Chinese Dependency Parsing
</subsectionHeader>
<bodyText confidence="0.99661375">
Dependency structures represent all sentence
relationships uniformly as typed dependency
relations between pairs of words. Some major
dependency relations for Chinese (Ma et al., 2004)
include tiN (Subject-Verb, SBV), M动 (Verb-Object,
VOB), ZrP(Attributive-Noun, ATT), &amp;CA (Quantifier,
QUN) and It A 结 41 (Independent structure, IS).
Consider the following Chinese sentence:
</bodyText>
<equation confidence="0.990093">
a) 俄國 外長 伊凡諾夫 說,北約 東向
張是 “ 邁向 錯誤 的 方向 ” 。
</equation>
<bodyText confidence="0.995469333333333">
Russian Foreign Minister Ivanov said that
NATO&apos;s eastward expansion was &amp;quot;Towards the
wrong direction.&amp;quot;
Its dependency tree is shown in Figure1. Its head
is the verb 說 (said), whose subject and object are
respectively 俄国外长伊凡诺夫 (Russian Foreign
Minister Ivanov) and the embedded clause 北約東
向擴張是“邁向錯誤的方向” (NATO&apos;s eastward
expansion was &amp;quot;towards the wrong direction.&amp;quot;).
</bodyText>
<sectionHeader confidence="0.974712" genericHeader="method">
3 Linguistic Analysis of Opinions
</sectionHeader>
<bodyText confidence="0.972639571428571">
The opinions in news text may be explicitly
mentioned or be expressed indirectly by the types
of words and the style of language (Wilson and
Wiebe, 2003). Two kinds of lexical clues are
exploited here for opinion holder/target
identification:
Reporting verbs: verbs indicating speech
events;
Opinion-bearing Words: words or phrases
containing polarity (i.e. positive, negative or
neutral).
In sentence a) above, the reporting verb 說 (said)
indicates a speech event expressing an opinion
given by the holder AW ,4长 9W诺--k (Russian
Foreign Minister Ivanov). Meanwhile, the opinion-
bearing word 錯 誤 (wrong) shows negative
attitude towards the target 北 約 東 向 擴 張
(NATO&apos;s eastward expansion).
Therefore, we assume that a large proportion of
holders are governed by such reporting verbs,
while targets are usually governed by opinion-
bearing words/phrases.
Opinion holders are usually named entities,
including, but not limited to, person names (e.g. 經
濟學家歐爾/economist Ol), organization names
(e.g. 英 國 政 府 /UK government), and personal
titles (e.g. 經 濟 學 家 /the economist). Opinion
holders can also be common noun phrases, such as
廠商 (companies), 兩千名學生 (two thousand
students). Pronouns1 can also be opinion holders,
e.g. 他 (he), 他們 (they), 我(I). Opinion targets are
more abstract and diverse, and could be agents,
concrete objects, actions, events or even abstract
ideas. In addition to noun phrases, opinion targets
could also be verb phrases or embedded clauses.
</bodyText>
<sectionHeader confidence="0.98072" genericHeader="method">
4 Identifying Opinion Holders/Targets
</sectionHeader>
<bodyText confidence="0.9966015">
In this section, we introduce our approach of
identifying opinion holders/targets. We use the
dependency parser in the HIT LTP package
(http://ir.hit.edu.cn/) to get the dependency
relations of the simplified Chinese sentences
converted from the traditional Chinese ones.
</bodyText>
<subsectionHeader confidence="0.997771">
4.1 Lexical Resources
</subsectionHeader>
<bodyText confidence="0.9996181875">
The reporting verbs were firstly collected from the
Chinese sample data of NTCIR-6 OAPT (Seki et
al., 2007) in which the OPINION_OPR tag was
used to mark them. We then use HowNet,
WordNet and Tongyici Cilin to extend the
reporting verbs from 68 to 308 words through
manual synonym search. Some frequently used
reporting verbs include 說(say), �T(express), 32,
,(think), etc. Some of the reporting verbs could
also convey opinions, such as #L 9T (criticize), �
� (condemn), �%- (praise), etc.
For opinion-bearing words/phrases, we use The
Lexicon of Chinese Positive Words (Shi and Zhu,
2006) and The Lexicon of Chinese Negative Words
(Yang and Zhu, 2006), which consist of 5046
positive items and 3499 negative ones, respectively.
</bodyText>
<footnote confidence="0.936817">
1 The resolution of the anaphor or co-reference has not been
dealt with yet, i.e. the identified holders of the sentence are
assumed to be in the same form as it appears in the sentence.
</footnote>
<page confidence="0.999025">
47
</page>
<figureCaption confidence="0.999618">
Figure 1. Dependency Tree for Sentence a)
</figureCaption>
<subsectionHeader confidence="0.997807">
4.2 Chinese Sentence Preprocessing (SP)
</subsectionHeader>
<bodyText confidence="0.9999864">
To enhance the robustness of the dependency
parser, named entities are first recognized with a
traditional Chinese word segmentation tool with
access to the very large LIVAC dictionary
(http://www.livac.org) collected from Chinese
news published in Hong Kong and Taiwan. The
identified named entities, as well as the collected
reporting verbs and opinion-bearing words are
added to the user dictionary of the HIT LTP
package to help parsing.
Before parsing, the parentheses enclosing only
English words or numbers are removed in
sentences, because the parser cannot properly
process the parentheses which may greatly
influence the parsing result.
</bodyText>
<subsectionHeader confidence="0.871202666666667">
4.3 Identifying Opinion Holders with
Reporting Verbs
4.3.1 Holder Candidate Generation
</subsectionHeader>
<bodyText confidence="0.999803833333333">
Two hypotheses are used to identify opinion
holders in opinionated sentences: 1) the subject of
reporting verbs will be the opinion holders; 2) if no
reporting verb is found, the author could be the
opinion holder. In addition to the two hypotheses
above, the following heuristic rules (HR) are used:
</bodyText>
<listItem confidence="0.730844">
1) Other words having relations with reporting
verbs
</listItem>
<bodyText confidence="0.9221798">
If the subject of reporting verbs is not found in
the sentence, we will find the word having
relationship of ATT, VOB or IS with the reporting
verbs, because sometimes the parser may wrongly
marked the subject as other relations.
</bodyText>
<listItem confidence="0.95731">
2) Colon processing in Headlines
</listItem>
<bodyText confidence="0.949237666666667">
If no reporting verbs are found in news
headlines, we just pick up the noun before the
colon as the target candidate in the headlines
because the author usually replaces the reporting
verb with a colon due to length limitation. E.g. in
the headline 摩 根 : 經 濟 成 長 熄 火 (Morgan:
Economic growth has been shut down), the noun
摩 根 (Morgan) before colon is chosen as the
opinion holder.
</bodyText>
<listItem confidence="0.938855">
3) Holder in the previous sentence
</listItem>
<bodyText confidence="0.999452833333333">
If no opinion holder is found in the current
clause and one holder candidate is found in the
previous clause, we just choose the opinion holder
of the previous clause as the holder candidate,
because an opinion holder may express several
ideas through consecutive sentences or clauses.
</bodyText>
<subsubsectionHeader confidence="0.474326">
4.3.2 Holder Candidate Expansion (EP)
</subsubsectionHeader>
<bodyText confidence="0.999898">
Through the procedure of candidate generation, we
may find a holder candidate containing only one
single word. But the holder may be a word
sequence instead of a single word. Thus we further
expand the holder candidates from the core head
word by the following rules:
</bodyText>
<listItem confidence="0.73913">
1) Attributive modifier (ATT)
</listItem>
<bodyText confidence="0.984410714285714">
E.g. in sentence a) mentioned in Sec. 2.2, the
subject of the reporting verb 說 (said) is 伊凡諾夫
(Ivanov), which has the attributive noun 外 長
(Foreign Minister) modified further by an
attributive noun 俄國(Russia). Therefore, the final
extended opinion holder would be 外長伊凡諾夫
(Russian Foreign Minister Ivanov).
</bodyText>
<listItem confidence="0.602751">
2) Quantifier modifier and 和/及 (and/or)
</listItem>
<bodyText confidence="0.9982329">
E.g. the quantifier modifier 部分(some) in the
noun phrase 部分亞洲國家 (some Asian countries)
should be part of the opinion holder. Sometime, we
need to extend the holder across 和/及(and/or), e.g.
蘇哈托和另外兩名軍方將領 (Suharto and two
other army generals).
Furthermore, time nouns, numbers and words
only containing one Chinese character (except for
pronouns) are removed from the candidates, as
they are unlikely to be opinion holders.
</bodyText>
<sectionHeader confidence="0.5401385" genericHeader="method">
4.4 Identifying Opinion Targets with
Opinion-bearing Words
</sectionHeader>
<page confidence="0.990486">
48
</page>
<bodyText confidence="0.920822833333333">
Here we propose to use automatically identified
reporting verbs and opinion holders to help opinion
target identification. The heuristic rules (HR) are
as follows.
1) If a candidate of opinion holder is
automatically identified with a reporting verb in an
opinionated sentence, we will try to find the
subject in the embedded clause as the target
candidate by the following two steps: a) Find the
subject of the object verb of the reporting verb. E.g.
in sentence a) in Sec. 2.2, the opinion target 北約
東向擴張 (NATO&apos;s eastward expansion) is the
subject of the verb 是 (was) in the embedded
clause which is in turn the object of the reporting
verb 說 (said); b) If no target candidate is found in
step a, we try to find after the reporting verb the
subject whose parent is an opinion-bearing word as
the target candidate.
</bodyText>
<listItem confidence="0.933306111111111">
2) If no target candidate is found in step 1, and
no opinion holder is found in the sentence, we find
the subject of the sentence as the target candidate,
because the author may be the opinion holder and
the target could be the subject of the sentence.
3) If still no target candidate is found in step 2,
we find the object in the sentence as the target
because the object could be the opinion target in
case there is no subject and no opinion holder.
</listItem>
<bodyText confidence="0.987195">
Target candidate expansion (EP) is similar to
holder candidate expansion described in Sec. 4.3.2.
If an opinion target is in the opinion holder
candidates (we call it holder conflict, HC), we
remove it from the target candidates, and then try
to find another using the above procedure.
</bodyText>
<sectionHeader confidence="0.999642" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.99988375">
We use the traditional Chinese test data in NTCIR-
7 MOAT (Seki et al., 2008) for our experiments.
Out of 4465 sentences, 2174 are annotated as
opinionated by the lenient standard, and the
opinion holders of some opinionated sentences are
marked as POST_AUTHOR denoting the author of
the news article. We use the final list given by the
organizers as the gold standard.
</bodyText>
<subsectionHeader confidence="0.703189">
Baselines for opinion holder identification:
</subsectionHeader>
<bodyText confidence="0.998768">
Baseline 1: We just use the subject of reporting
verbs as the opinion holder, without sentence
preprocessing described in Sec. 4.2 and any
heuristic rules introduced in Sec. 4.3.1.
Baseline 2: We also implement the CRF model
for detecting opinion holders (Choi et al., 2006) by
using CRF++. The training data is the NTCIR-6
Chinese test data. The labels used by CRF
comprise Holder, Parent of Holder, None (not
holder or parent) and the features for each word in
our implementation include: basic features (i.e.
word, POS-tag, whether the word itself is a
reporting verb or not), dependency features (i.e.
parent word, POS-tag of its parent, dependency
relation with its parent, whether its parent is a
reporting verb) and semantic features (i.e. WSD
entry in Tongyici Cilin, WSD entry of its parent).
</bodyText>
<subsectionHeader confidence="0.842692">
Baseline for opinion target identification:
</subsectionHeader>
<bodyText confidence="0.999481571428572">
Baseline 1: we try to find the subject or object of
opinion-bearing words as the targets. If both a
subject and an object are found, we just simply
choose the subject as the target.
We evaluate performance using 3 measures:
exact match (EM), head match (HM), and partial
match (PM), similar to Choi et al. (2006). We use
three evaluation metrics: recall (Rec), precision
(Pre), and F1. For opinion holder identification, we
consider two cases: 1) all opinionated sentences; 2)
only the opinionated sentences whose opinion
holders do not contain POST_AUTHOR. The
metric ALL_Pre reported below is the precision in
case 1 which is the same with recall and F1.
</bodyText>
<sectionHeader confidence="0.869468" genericHeader="evaluation">
5.1 Results for Opinion Holder Identification
</sectionHeader>
<bodyText confidence="0.981718">
The results for holder identification are shown in
Table 1, from which we can observe that our
proposed approach significantly outperforms the
two baseline methods, including the unsupervised
baseline 1 and the supervised baseline 2.
</bodyText>
<table confidence="0.999777">
ALL_Pre Pre Rec F1
Baseline1 EM 52.4 46.8 31.6 37.8
HM 67.1 80.2 54.2 64.7
PM 72.1 89.3 60.4 72.0
Baseline2 EM 45.5 34.7 18.1 23.8
(CRF)
HM 55.2 63.6 33.1 43.6
PM 55.6 64.9 33.8 44.4
Our EM 69.8 74.4 63.6 68.5
Approach
HM 72.5 79.2 67.7 73.0
PM 75.7 85.1 72.7 78.4
</table>
<tableCaption confidence="0.99865">
Table 1. Results for Opinion Holders
</tableCaption>
<bodyText confidence="0.993030571428571">
Unexpectedly, even the unsupervised baseline 1
achieves better performance than baseline 2 (the
CRF-based method). The possible reasons are: 1)
the training data is not large enough to cover the
cases in the test data, resulting in low recall of the
CRF model; 2) the features used by the CRF model
could be refined to improve the performance.
</bodyText>
<page confidence="0.998754">
49
</page>
<bodyText confidence="0.993405142857143">
Here we also evaluate the influences of the
following three factors on the performance:
sentences preprocessing (SP) in Sec. 4.2, holder
expansion (EP) in Sec. 4.3.2 and the heuristic rules
(HR) in Sec. 4.3.1. The results are shown in Figure
2 for different combinations, in which BL refers to
baseline 1.
</bodyText>
<figureCaption confidence="0.936404">
Figure 2. Influences of Factors on Opinion Holders
</figureCaption>
<bodyText confidence="0.999423666666667">
From Figure 2, we can observe that: 1) All three
factors have positive effects on performance
compared to baseline 1, and our approach by
integrating all factors achieves the best
performance; 2) SP improve the performance in
terms of all three metrics, showing that SP
including named entity recognition and parenthesis
removing are useful for holder identification; 3)
The major improvement of EP lies in EM, showing
that the main contribution of EP is to get the exact
opinion holders by expanding the core head noun;
4) SP+EP+HR improves the performance in terms
of all three metrics compared with SP+HR,
showing the heuristic rules are useful to improve
the performance.
</bodyText>
<subsectionHeader confidence="0.770178">
5.2 Results for Opinion Target Identification
</subsectionHeader>
<bodyText confidence="0.9948705">
The results for opinion target identification are
shown in Table 2, from which we can observe that
our proposed approach significantly outperforms
the baseline method.
</bodyText>
<table confidence="0.999776">
Pre Rec F1
Baseline 1 EM 11.1 9.2 10.1
HM 24.0 19.9 21.8
PM 39.4 32.7 35.8
Our EM 29.3 28.5 28.9
Approach HM 38.4 38.0 38.2
PM 59.3 58.7 59.0
</table>
<tableCaption confidence="0.999385">
Table 2. Results for Opinion Targets
</tableCaption>
<bodyText confidence="0.999616">
We also investigate the influences of the
following four factors on the performance:
sentence preprocessing (SP) in Sec. 4.2, target
expansion (EP) in Sec. 4.4, holder conflict (HC),
the heuristic rules (HR) proposed in Sec. 4.4. The
F1s for EM, HM and PM are shown in Figure 3, in
which BL refers to baseline 1.
</bodyText>
<figureCaption confidence="0.72151">
Figure 3. Influences of Factors on Opinion Targets
</figureCaption>
<bodyText confidence="0.999563857142857">
From Figure 3, we can observe that: 1) All four
factors have positive effects on performance
compared to the baseline, and our approach
integrating all the factors achieves the best
performance; 2) EP significantly improves F1 of
EM without much improvement on F1 of HM or
PM, showing that EP’s major contribution lies in
exact match; 3) The major contribution of HC is
the improvement of F1s of HM and PM, showing
the automatically identified opinion holders are
quite helpful for finding opinion targets; 4)
SP+EP+HC improves the performance in terms of
all three metrics; and our approach further
improves the performance by adding HR.
</bodyText>
<subsectionHeader confidence="0.978599">
5.3 Discussion
</subsectionHeader>
<bodyText confidence="0.999946210526316">
Here we compare our results with those reported at
NTCIR-7 MOAT traditional Chinese test (Seki et
al., 2008). Without considering the errors in the
previous step, the highest F1s for opinion holder
analysis reported by the four participants were
respectively 82.5%, 59.9%, 50.3% and 59.5%, and
the highest F1s for target reported by the three
participants were respectively 60.6%, 2.1% and
3.6%. Compared to the results at NTCIR-7, our
performances on both opinion holder identification
in Table 1 and that on target identification in Table
2 seem quite encouraging even by the EM metrics.
Consider the evaluation for opinion
holders/targets was semi-automatic at NTCIR-7.
We should note that although the generated
standard had been supplemented by the
participants’ submissions, some correct answers
may still be missing, especially for targets since
only three teams participated in the target
</bodyText>
<figure confidence="0.986091828571429">
45
40
85
80
75
70
65
60
55
50
35
F1
BL BL+SP BL+EP BL+SP+EP Our Approach
(BL+SP+EP+HR)
Influence of Factors
Approaches
EM
HM
PM
68
48
28
58
38
18
8
F1
BL BL+SP BL+EP BL+HC BL+SP
+EP+HC
Influence of Factors
Approaches
Our Approach
EM
HM
PM
</figure>
<page confidence="0.989677">
50
</page>
<bodyText confidence="0.9999686">
identification task and the recalls were not high.
Thus the performance reported in Table 1 and 2
may be underestimated.
Here we also give an estimate on the
percentages of opinionated sentences containing
both opinion holders and at least one reporting
verb in NTCIR-6 and NTCIR-7’s traditional
Chinese test data, which are respectively 94.5%
and 83.9%. The high percentages show that
reporting verbs are very common in news report.
</bodyText>
<sectionHeader confidence="0.998068" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999974590909091">
In this paper, we investigate the problem of
identifying opinion holders/targets in opinionated
sentences of Chinese news texts based on Chinese
dependency parser, reporting verbs and opinion-
bearing words. Our proposed approach shows
encouraging performance on opinion holder/target
identification with the NTCIR-7’s traditional
Chinese test data, and outperforms most systems
reported at NTCIR-7 and the baseline methods
including the CRF-based model.
The proposed approach is highly dependent on
dependency parser, and we would like to further
investigate machine learning approaches (including
the CRF model) by treating dependency structures
as one of the linguistic features, which could be
more robust to parsing errors. Opinion targets are
more difficult to be identified than opinion holders,
and deserve more attention in the NLP field, and
we also would extend the targets to verb phrases
and embedded clauses in addition to noun phrases.
To explore the effectiveness of our approach with
English data such as MPQA is another direction.
</bodyText>
<sectionHeader confidence="0.998021" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999886">
We acknowledge the help of our colleagues
(Professor Benjamin K. Tsou and Mr. Jiang Tao).
</bodyText>
<sectionHeader confidence="0.997351" genericHeader="references">
Reference
</sectionHeader>
<reference confidence="0.999890492537314">
Steven Bethard, Hong Yu, Ashley Thornton, Vasileios
Hatzivassiloglou, and Dan Jurafsky. 2004. Automatic
Extraction of Opinion Propositions and their Holders,
AAAI Spring Symposium on Exploring Attitude and
Affect in Text: Theories and Applications.
Yejin Choi, Claire Cardie, Ellen Riloff, and Siddharth
Patwardhan. 2005. Identifying sources of opinions
with conditional random fields and extraction
patterns. In Proc. of HLT/EMNLP-05.
Vasileios Hatzivassiloglou and Kathleen McKeown.
1997. Predicting the Semantic Orientation of
Adjectives. In Proc. of ACL-97. 174-181.
Minqing Hu and Bing Liu. 2004. Mining Opinion
Features in Customer Reviews. In Proc. of AAAI-04.
Soo-Min Kim and Eduard Hovy. 2005. Identifying
Opinion Holders for Question Answering in Opinion
Texts, In Proc. of AAAI-05 Workshop on Question
Answering in Restricted Domains. Pittsburgh, PA.
Soo-Min Kim and Eduard Hovy. 2006. Extracting
opinions, opinion holders, and topics expressed in
online news media text, In Proc. of ACL Workshop
on Sentiment and Subjectivity in Text.
Youngho Kim, Seongchan Kim, and Sung-Hyon
Myaeng. 2008. Extracting Topic-related Opinions
and their Targets in NTCIR-7, Proc. of NTCIR-7
Workshop, Tokyo, Japan.
Lun-Wei Ku, I-Chien Liu, Chia-Ying Lee, Kuan-hua
Chen and Hsin-Hsi Chen. 2008. Sentence-Level
Opinion Analysis by CopeOpi in NTCIR-7. In Proc.
of NTCIR-7 Workshop. Tokyo, Japan.
Jinshan Ma, Yu Zhang, Ting Liu and Sheng Li. 2004. A
statistical dependency parser of Chinese under small
training data. IJCNLP-04 Workshop: Beyond shallow
analyses - Formalisms and statistical modeling for
deep analyses.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up? Sentiment classification using
machine learning techniques. In Proc. of EMNLP-02.
Josef Ruppenhofer, Swapna Somasundaran, Janyce
Wiebe. 2008. Finding the Sources and Targets of
Subjective Expressions. In Proc. of LREC 2008.
Yohei Seki, David Kirk Evans, Lun-Wei Ku, and et al.
2007. Overview of Opinion Analysis Pilot Task at
NTCIR-6. Proc. of the NTCIR-6 Workshop.
Yohei Seki, David Kirk Evans, Lun-Wei Ku, and et al.
2008. Overview of Multilingual Opinion Analysis
Task at NTCIR-7. Proc. of the NTCIR-7 Workshop.
Japan. 2008. 12.
Jilin Shi and Yinggui Zhu. 2006. The Lexicon of
Chinese Positive Words (* p7 p7 A ). Sichuan
Lexicon Press.
Veselin Stoyanov and Claire Cardie. 2008. Topic
Identification for Fine-Grained Opinion Analysis. In
Proc. of COLING-08.
Peter D. Turney. 2002. Thumbs up or thumbs down?
Semantic orientation applied to unsupervised
classification of reviews, In Proc. of ACL-02.
Theresa Wilson and Janyce Wiebe. 2003. Annotating
opinions in the world press. Proc. of the 4th ACL
SIGdial Workshop on Discourse and Dialogue
(SIGdial-03).
Ruifeng Xu, Kam-Fai Wong and Yunqing Xia. 2008.
Coarse-Fine Opinion Mining - WIA in NTCIR-7
MOAT Task. Proc. of the 7th NTCIR Workshop.
Ling Yang and Yinggui Zhu. 2006. The Lexicon of
Chinese Negative Words (0- p7p7A ). Sichuan
Lexicon Press.
</reference>
<page confidence="0.99912">
51
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.475617">
<title confidence="0.997186">Identifying Opinion Holders and Targets with Dependency Parser Chinese News Texts</title>
<author confidence="0.962185">Bin</author>
<affiliation confidence="0.995937">Department of Chinese, Translation and Linguistics Language Information Sciences Research City University of Hong</affiliation>
<address confidence="0.864099">Kowloon, Hong</address>
<email confidence="0.998433">lubin2010@gmail.com</email>
<abstract confidence="0.963716384615385">In this paper, we propose to identify opinion holders and targets with dependency parser in Chinese news texts, i.e. to identify opinion holders by means of reporting verbs and to identify opinion targets by considering both opinion holders and opinion-bearing words. The experiments with NTCIR-7 MOAT’s Chinese test data show that our approach provides better performance than the baselines and most systems reported at NTCIR-7.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven Bethard</author>
<author>Hong Yu</author>
<author>Ashley Thornton</author>
<author>Vasileios Hatzivassiloglou</author>
<author>Dan Jurafsky</author>
</authors>
<date>2004</date>
<booktitle>Automatic Extraction of Opinion Propositions and their Holders, AAAI Spring Symposium on Exploring Attitude and Affect in Text: Theories and Applications.</booktitle>
<contexts>
<context position="3293" citStr="Bethard et al. (2004)" startWordPosition="505" endWordPosition="508">it fails to detect the holders and targets of the sentiment in texts. 2.1 Opinion Holders/ Target Identification For opinion mining of product reviews, opinion holder identification is usually omitted under the assumption that opinion holder is the review writer; and opinion targets are limited to the product discussed and its features (Hu and Liu, 2004). But in news texts, opinion holders/targets are more diverse: all named entities and noun phrases can be opinion holders; while opinion targets could be noun phrases, verb phrases or even clauses (Kim and Hovy, 2006; Ruppenhofer et al. 2008). Bethard et al. (2004) identify opinion propositions and their holders by semantic parsing techniques. Choi et al. (2005) and Kim and Hovy (2005) identify only opinion holders on the MPQA corpus (Wilson and Wiebe, 2003). Kim and Hovy (2006) proposed to map the semantic frames of FrameNet into opinion holder and target for only adjectives and verbs. Kim et al. (2008) proposed to Proceedings of the NAACL HLT 2010 Student Research Workshop, pages 46–51, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics use syntactic structures for target identification without considering opinion hol</context>
</contexts>
<marker>Bethard, Yu, Thornton, Hatzivassiloglou, Jurafsky, 2004</marker>
<rawString>Steven Bethard, Hong Yu, Ashley Thornton, Vasileios Hatzivassiloglou, and Dan Jurafsky. 2004. Automatic Extraction of Opinion Propositions and their Holders, AAAI Spring Symposium on Exploring Attitude and Affect in Text: Theories and Applications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yejin Choi</author>
<author>Claire Cardie</author>
<author>Ellen Riloff</author>
<author>Siddharth Patwardhan</author>
</authors>
<title>Identifying sources of opinions with conditional random fields and extraction patterns.</title>
<date>2005</date>
<booktitle>In Proc. of HLT/EMNLP-05.</booktitle>
<contexts>
<context position="3392" citStr="Choi et al. (2005)" startWordPosition="519" endWordPosition="522">tification For opinion mining of product reviews, opinion holder identification is usually omitted under the assumption that opinion holder is the review writer; and opinion targets are limited to the product discussed and its features (Hu and Liu, 2004). But in news texts, opinion holders/targets are more diverse: all named entities and noun phrases can be opinion holders; while opinion targets could be noun phrases, verb phrases or even clauses (Kim and Hovy, 2006; Ruppenhofer et al. 2008). Bethard et al. (2004) identify opinion propositions and their holders by semantic parsing techniques. Choi et al. (2005) and Kim and Hovy (2005) identify only opinion holders on the MPQA corpus (Wilson and Wiebe, 2003). Kim and Hovy (2006) proposed to map the semantic frames of FrameNet into opinion holder and target for only adjectives and verbs. Kim et al. (2008) proposed to Proceedings of the NAACL HLT 2010 Student Research Workshop, pages 46–51, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics use syntactic structures for target identification without considering opinion holders. Stoyanov and Cardie (2008) define opinion topic and target and treat the task as a co-referen</context>
</contexts>
<marker>Choi, Cardie, Riloff, Patwardhan, 2005</marker>
<rawString>Yejin Choi, Claire Cardie, Ellen Riloff, and Siddharth Patwardhan. 2005. Identifying sources of opinions with conditional random fields and extraction patterns. In Proc. of HLT/EMNLP-05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Hatzivassiloglou</author>
<author>Kathleen McKeown</author>
</authors>
<title>Predicting the Semantic Orientation of Adjectives.</title>
<date>1997</date>
<booktitle>In Proc. of ACL-97.</booktitle>
<pages>174--181</pages>
<contexts>
<context position="914" citStr="Hatzivassiloglou and McKeown, 1997" startWordPosition="129" endWordPosition="132">r, we propose to identify opinion holders and targets with dependency parser in Chinese news texts, i.e. to identify opinion holders by means of reporting verbs and to identify opinion targets by considering both opinion holders and opinion-bearing words. The experiments with NTCIR-7 MOAT’s Chinese test data show that our approach provides better performance than the baselines and most systems reported at NTCIR-7. 1 Introduction In recent years, sentiment analysis, which mines opinions from information sources such as news, blogs and product reviews, has drawn much attention in the NLP field (Hatzivassiloglou and McKeown, 1997; Pang et al., 2002; Turney, 2002; Hu and Liu, 2004). An opinion expressed in a text involves different components, including opinion expression, opinion holder and target (Wilson and Wiebe, 2003). Opinion holder is usually an entity that holds an opinion, and opinion target is what the opinion is about (Kim and Hovy, 2006). Although there have been research on identifying opinion holders and targets in English product reviews and news texts, little work has been reported on similar tasks involving Chinese news texts. In this study, we investigate how dependency parsing can be used to help the</context>
</contexts>
<marker>Hatzivassiloglou, McKeown, 1997</marker>
<rawString>Vasileios Hatzivassiloglou and Kathleen McKeown. 1997. Predicting the Semantic Orientation of Adjectives. In Proc. of ACL-97. 174-181.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining Opinion Features in Customer Reviews.</title>
<date>2004</date>
<booktitle>In Proc. of AAAI-04.</booktitle>
<contexts>
<context position="966" citStr="Hu and Liu, 2004" startWordPosition="139" endWordPosition="142"> parser in Chinese news texts, i.e. to identify opinion holders by means of reporting verbs and to identify opinion targets by considering both opinion holders and opinion-bearing words. The experiments with NTCIR-7 MOAT’s Chinese test data show that our approach provides better performance than the baselines and most systems reported at NTCIR-7. 1 Introduction In recent years, sentiment analysis, which mines opinions from information sources such as news, blogs and product reviews, has drawn much attention in the NLP field (Hatzivassiloglou and McKeown, 1997; Pang et al., 2002; Turney, 2002; Hu and Liu, 2004). An opinion expressed in a text involves different components, including opinion expression, opinion holder and target (Wilson and Wiebe, 2003). Opinion holder is usually an entity that holds an opinion, and opinion target is what the opinion is about (Kim and Hovy, 2006). Although there have been research on identifying opinion holders and targets in English product reviews and news texts, little work has been reported on similar tasks involving Chinese news texts. In this study, we investigate how dependency parsing can be used to help the task on opinion holder/target identification in Chi</context>
<context position="3028" citStr="Hu and Liu, 2004" startWordPosition="462" endWordPosition="465">. The proposed approach is described in Sec. 4, followed by the experiments in Sec. 5. Lastly we conclude in Sec. 6. 2 Related Work Although document-level sentiment analysis (Turney, 2002; Pang et al., 2002) can provide the overall polarity of the whole text, it fails to detect the holders and targets of the sentiment in texts. 2.1 Opinion Holders/ Target Identification For opinion mining of product reviews, opinion holder identification is usually omitted under the assumption that opinion holder is the review writer; and opinion targets are limited to the product discussed and its features (Hu and Liu, 2004). But in news texts, opinion holders/targets are more diverse: all named entities and noun phrases can be opinion holders; while opinion targets could be noun phrases, verb phrases or even clauses (Kim and Hovy, 2006; Ruppenhofer et al. 2008). Bethard et al. (2004) identify opinion propositions and their holders by semantic parsing techniques. Choi et al. (2005) and Kim and Hovy (2005) identify only opinion holders on the MPQA corpus (Wilson and Wiebe, 2003). Kim and Hovy (2006) proposed to map the semantic frames of FrameNet into opinion holder and target for only adjectives and verbs. Kim et</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining Opinion Features in Customer Reviews. In Proc. of AAAI-04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soo-Min Kim</author>
<author>Eduard Hovy</author>
</authors>
<title>Identifying Opinion Holders for Question Answering in Opinion Texts,</title>
<date>2005</date>
<booktitle>In Proc. of AAAI-05 Workshop on Question Answering in Restricted Domains.</booktitle>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="3416" citStr="Kim and Hovy (2005)" startWordPosition="524" endWordPosition="527">mining of product reviews, opinion holder identification is usually omitted under the assumption that opinion holder is the review writer; and opinion targets are limited to the product discussed and its features (Hu and Liu, 2004). But in news texts, opinion holders/targets are more diverse: all named entities and noun phrases can be opinion holders; while opinion targets could be noun phrases, verb phrases or even clauses (Kim and Hovy, 2006; Ruppenhofer et al. 2008). Bethard et al. (2004) identify opinion propositions and their holders by semantic parsing techniques. Choi et al. (2005) and Kim and Hovy (2005) identify only opinion holders on the MPQA corpus (Wilson and Wiebe, 2003). Kim and Hovy (2006) proposed to map the semantic frames of FrameNet into opinion holder and target for only adjectives and verbs. Kim et al. (2008) proposed to Proceedings of the NAACL HLT 2010 Student Research Workshop, pages 46–51, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics use syntactic structures for target identification without considering opinion holders. Stoyanov and Cardie (2008) define opinion topic and target and treat the task as a co-reference resolution problem. F</context>
</contexts>
<marker>Kim, Hovy, 2005</marker>
<rawString>Soo-Min Kim and Eduard Hovy. 2005. Identifying Opinion Holders for Question Answering in Opinion Texts, In Proc. of AAAI-05 Workshop on Question Answering in Restricted Domains. Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soo-Min Kim</author>
<author>Eduard Hovy</author>
</authors>
<title>Extracting opinions, opinion holders, and topics expressed in online news media text,</title>
<date>2006</date>
<booktitle>In Proc. of ACL Workshop on Sentiment and Subjectivity in Text.</booktitle>
<contexts>
<context position="1239" citStr="Kim and Hovy, 2006" startWordPosition="182" endWordPosition="185">s better performance than the baselines and most systems reported at NTCIR-7. 1 Introduction In recent years, sentiment analysis, which mines opinions from information sources such as news, blogs and product reviews, has drawn much attention in the NLP field (Hatzivassiloglou and McKeown, 1997; Pang et al., 2002; Turney, 2002; Hu and Liu, 2004). An opinion expressed in a text involves different components, including opinion expression, opinion holder and target (Wilson and Wiebe, 2003). Opinion holder is usually an entity that holds an opinion, and opinion target is what the opinion is about (Kim and Hovy, 2006). Although there have been research on identifying opinion holders and targets in English product reviews and news texts, little work has been reported on similar tasks involving Chinese news texts. In this study, we investigate how dependency parsing can be used to help the task on opinion holder/target identification in Chinese news texts. Three possible contributions from this study are: 1) we propose that the existence of reporting verbs is a very important feature for identifying opinion holders in news texts, which has not been clearly indicated; 2) we argue that the identification of 46</context>
<context position="3244" citStr="Kim and Hovy, 2006" startWordPosition="497" endWordPosition="500">ovide the overall polarity of the whole text, it fails to detect the holders and targets of the sentiment in texts. 2.1 Opinion Holders/ Target Identification For opinion mining of product reviews, opinion holder identification is usually omitted under the assumption that opinion holder is the review writer; and opinion targets are limited to the product discussed and its features (Hu and Liu, 2004). But in news texts, opinion holders/targets are more diverse: all named entities and noun phrases can be opinion holders; while opinion targets could be noun phrases, verb phrases or even clauses (Kim and Hovy, 2006; Ruppenhofer et al. 2008). Bethard et al. (2004) identify opinion propositions and their holders by semantic parsing techniques. Choi et al. (2005) and Kim and Hovy (2005) identify only opinion holders on the MPQA corpus (Wilson and Wiebe, 2003). Kim and Hovy (2006) proposed to map the semantic frames of FrameNet into opinion holder and target for only adjectives and verbs. Kim et al. (2008) proposed to Proceedings of the NAACL HLT 2010 Student Research Workshop, pages 46–51, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics use syntactic structures for targ</context>
</contexts>
<marker>Kim, Hovy, 2006</marker>
<rawString>Soo-Min Kim and Eduard Hovy. 2006. Extracting opinions, opinion holders, and topics expressed in online news media text, In Proc. of ACL Workshop on Sentiment and Subjectivity in Text.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Youngho Kim</author>
<author>Seongchan Kim</author>
<author>Sung-Hyon Myaeng</author>
</authors>
<title>Extracting Topic-related Opinions and their Targets in</title>
<date>2008</date>
<booktitle>NTCIR-7, Proc. of NTCIR-7 Workshop,</booktitle>
<location>Tokyo, Japan.</location>
<contexts>
<context position="3639" citStr="Kim et al. (2008)" startWordPosition="562" endWordPosition="565"> 2004). But in news texts, opinion holders/targets are more diverse: all named entities and noun phrases can be opinion holders; while opinion targets could be noun phrases, verb phrases or even clauses (Kim and Hovy, 2006; Ruppenhofer et al. 2008). Bethard et al. (2004) identify opinion propositions and their holders by semantic parsing techniques. Choi et al. (2005) and Kim and Hovy (2005) identify only opinion holders on the MPQA corpus (Wilson and Wiebe, 2003). Kim and Hovy (2006) proposed to map the semantic frames of FrameNet into opinion holder and target for only adjectives and verbs. Kim et al. (2008) proposed to Proceedings of the NAACL HLT 2010 Student Research Workshop, pages 46–51, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics use syntactic structures for target identification without considering opinion holders. Stoyanov and Cardie (2008) define opinion topic and target and treat the task as a co-reference resolution problem. For the identification of opinion holders/targets in Chinese, there were several reports at NTCIR-7 (Seki et al., 2008). Xu et al. (2008) proposed to use some heuristic rules for opinion holder/target identification. Ku et a</context>
</contexts>
<marker>Kim, Kim, Myaeng, 2008</marker>
<rawString>Youngho Kim, Seongchan Kim, and Sung-Hyon Myaeng. 2008. Extracting Topic-related Opinions and their Targets in NTCIR-7, Proc. of NTCIR-7 Workshop, Tokyo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lun-Wei Ku</author>
<author>I-Chien Liu</author>
<author>Chia-Ying Lee</author>
<author>Kuan-hua Chen</author>
<author>Hsin-Hsi Chen</author>
</authors>
<title>Sentence-Level Opinion Analysis by CopeOpi in NTCIR-7.</title>
<date>2008</date>
<booktitle>In Proc. of NTCIR-7 Workshop.</booktitle>
<location>Tokyo, Japan.</location>
<contexts>
<context position="4248" citStr="Ku et al. (2008)" startWordPosition="649" endWordPosition="652"> (2008) proposed to Proceedings of the NAACL HLT 2010 Student Research Workshop, pages 46–51, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics use syntactic structures for target identification without considering opinion holders. Stoyanov and Cardie (2008) define opinion topic and target and treat the task as a co-reference resolution problem. For the identification of opinion holders/targets in Chinese, there were several reports at NTCIR-7 (Seki et al., 2008). Xu et al. (2008) proposed to use some heuristic rules for opinion holder/target identification. Ku et al. (2008) treated opinion holder identification as a binary classification problem of determining if a word was a part of an opinion holder. 2.2 Chinese Dependency Parsing Dependency structures represent all sentence relationships uniformly as typed dependency relations between pairs of words. Some major dependency relations for Chinese (Ma et al., 2004) include tiN (Subject-Verb, SBV), M动 (Verb-Object, VOB), ZrP(Attributive-Noun, ATT), &amp;CA (Quantifier, QUN) and It A 结 41 (Independent structure, IS). Consider the following Chinese sentence: a) 俄國 外長 伊凡諾夫 說,北約 東向 張是 “ 邁向 錯誤 的 方向 ” 。 Russian Foreign Mini</context>
</contexts>
<marker>Ku, Liu, Lee, Chen, Chen, 2008</marker>
<rawString>Lun-Wei Ku, I-Chien Liu, Chia-Ying Lee, Kuan-hua Chen and Hsin-Hsi Chen. 2008. Sentence-Level Opinion Analysis by CopeOpi in NTCIR-7. In Proc. of NTCIR-7 Workshop. Tokyo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinshan Ma</author>
<author>Yu Zhang</author>
<author>Ting Liu</author>
<author>Sheng Li</author>
</authors>
<title>A statistical dependency parser of Chinese under small training data. IJCNLP-04 Workshop: Beyond shallow analyses - Formalisms and statistical modeling for deep analyses.</title>
<date>2004</date>
<contexts>
<context position="4595" citStr="Ma et al., 2004" startWordPosition="699" endWordPosition="702"> a co-reference resolution problem. For the identification of opinion holders/targets in Chinese, there were several reports at NTCIR-7 (Seki et al., 2008). Xu et al. (2008) proposed to use some heuristic rules for opinion holder/target identification. Ku et al. (2008) treated opinion holder identification as a binary classification problem of determining if a word was a part of an opinion holder. 2.2 Chinese Dependency Parsing Dependency structures represent all sentence relationships uniformly as typed dependency relations between pairs of words. Some major dependency relations for Chinese (Ma et al., 2004) include tiN (Subject-Verb, SBV), M动 (Verb-Object, VOB), ZrP(Attributive-Noun, ATT), &amp;CA (Quantifier, QUN) and It A 结 41 (Independent structure, IS). Consider the following Chinese sentence: a) 俄國 外長 伊凡諾夫 說,北約 東向 張是 “ 邁向 錯誤 的 方向 ” 。 Russian Foreign Minister Ivanov said that NATO&apos;s eastward expansion was &amp;quot;Towards the wrong direction.&amp;quot; Its dependency tree is shown in Figure1. Its head is the verb 說 (said), whose subject and object are respectively 俄国外长伊凡诺夫 (Russian Foreign Minister Ivanov) and the embedded clause 北約東 向擴張是“邁向錯誤的方向” (NATO&apos;s eastward expansion was &amp;quot;towards the wrong direction.&amp;quot;). 3</context>
</contexts>
<marker>Ma, Zhang, Liu, Li, 2004</marker>
<rawString>Jinshan Ma, Yu Zhang, Ting Liu and Sheng Li. 2004. A statistical dependency parser of Chinese under small training data. IJCNLP-04 Workshop: Beyond shallow analyses - Formalisms and statistical modeling for deep analyses.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up? Sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proc. of EMNLP-02.</booktitle>
<contexts>
<context position="933" citStr="Pang et al., 2002" startWordPosition="133" endWordPosition="136">lders and targets with dependency parser in Chinese news texts, i.e. to identify opinion holders by means of reporting verbs and to identify opinion targets by considering both opinion holders and opinion-bearing words. The experiments with NTCIR-7 MOAT’s Chinese test data show that our approach provides better performance than the baselines and most systems reported at NTCIR-7. 1 Introduction In recent years, sentiment analysis, which mines opinions from information sources such as news, blogs and product reviews, has drawn much attention in the NLP field (Hatzivassiloglou and McKeown, 1997; Pang et al., 2002; Turney, 2002; Hu and Liu, 2004). An opinion expressed in a text involves different components, including opinion expression, opinion holder and target (Wilson and Wiebe, 2003). Opinion holder is usually an entity that holds an opinion, and opinion target is what the opinion is about (Kim and Hovy, 2006). Although there have been research on identifying opinion holders and targets in English product reviews and news texts, little work has been reported on similar tasks involving Chinese news texts. In this study, we investigate how dependency parsing can be used to help the task on opinion ho</context>
<context position="2619" citStr="Pang et al., 2002" startWordPosition="397" endWordPosition="400">tified holders are quite useful for the identification of the associated targets. Our approach shows encouraging performance on opinion holder/target identification, and the results are much better than the baseline results and most results reported in NTCIR-7 (Seki et al., 2008). The paper is organized as follows. Sec. 2 introduces related work. Sec. 3 gives the linguistic analysis of opinion holder/target. The proposed approach is described in Sec. 4, followed by the experiments in Sec. 5. Lastly we conclude in Sec. 6. 2 Related Work Although document-level sentiment analysis (Turney, 2002; Pang et al., 2002) can provide the overall polarity of the whole text, it fails to detect the holders and targets of the sentiment in texts. 2.1 Opinion Holders/ Target Identification For opinion mining of product reviews, opinion holder identification is usually omitted under the assumption that opinion holder is the review writer; and opinion targets are limited to the product discussed and its features (Hu and Liu, 2004). But in news texts, opinion holders/targets are more diverse: all named entities and noun phrases can be opinion holders; while opinion targets could be noun phrases, verb phrases or even cl</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? Sentiment classification using machine learning techniques. In Proc. of EMNLP-02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Josef Ruppenhofer</author>
<author>Swapna Somasundaran</author>
<author>Janyce Wiebe</author>
</authors>
<title>Finding the Sources and Targets of Subjective Expressions.</title>
<date>2008</date>
<booktitle>In Proc. of LREC</booktitle>
<contexts>
<context position="3270" citStr="Ruppenhofer et al. 2008" startWordPosition="501" endWordPosition="504">larity of the whole text, it fails to detect the holders and targets of the sentiment in texts. 2.1 Opinion Holders/ Target Identification For opinion mining of product reviews, opinion holder identification is usually omitted under the assumption that opinion holder is the review writer; and opinion targets are limited to the product discussed and its features (Hu and Liu, 2004). But in news texts, opinion holders/targets are more diverse: all named entities and noun phrases can be opinion holders; while opinion targets could be noun phrases, verb phrases or even clauses (Kim and Hovy, 2006; Ruppenhofer et al. 2008). Bethard et al. (2004) identify opinion propositions and their holders by semantic parsing techniques. Choi et al. (2005) and Kim and Hovy (2005) identify only opinion holders on the MPQA corpus (Wilson and Wiebe, 2003). Kim and Hovy (2006) proposed to map the semantic frames of FrameNet into opinion holder and target for only adjectives and verbs. Kim et al. (2008) proposed to Proceedings of the NAACL HLT 2010 Student Research Workshop, pages 46–51, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics use syntactic structures for target identification without </context>
</contexts>
<marker>Ruppenhofer, Somasundaran, Wiebe, 2008</marker>
<rawString>Josef Ruppenhofer, Swapna Somasundaran, Janyce Wiebe. 2008. Finding the Sources and Targets of Subjective Expressions. In Proc. of LREC 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yohei Seki</author>
<author>David Kirk Evans</author>
<author>Lun-Wei Ku</author>
</authors>
<date>2007</date>
<booktitle>Overview of Opinion Analysis Pilot Task at NTCIR-6. Proc. of the NTCIR-6 Workshop.</booktitle>
<contexts>
<context position="7126" citStr="Seki et al., 2007" startWordPosition="1088" endWordPosition="1091">verse, and could be agents, concrete objects, actions, events or even abstract ideas. In addition to noun phrases, opinion targets could also be verb phrases or embedded clauses. 4 Identifying Opinion Holders/Targets In this section, we introduce our approach of identifying opinion holders/targets. We use the dependency parser in the HIT LTP package (http://ir.hit.edu.cn/) to get the dependency relations of the simplified Chinese sentences converted from the traditional Chinese ones. 4.1 Lexical Resources The reporting verbs were firstly collected from the Chinese sample data of NTCIR-6 OAPT (Seki et al., 2007) in which the OPINION_OPR tag was used to mark them. We then use HowNet, WordNet and Tongyici Cilin to extend the reporting verbs from 68 to 308 words through manual synonym search. Some frequently used reporting verbs include 說(say), �T(express), 32, ,(think), etc. Some of the reporting verbs could also convey opinions, such as #L 9T (criticize), � � (condemn), �%- (praise), etc. For opinion-bearing words/phrases, we use The Lexicon of Chinese Positive Words (Shi and Zhu, 2006) and The Lexicon of Chinese Negative Words (Yang and Zhu, 2006), which consist of 5046 positive items and 3499 negati</context>
</contexts>
<marker>Seki, Evans, Ku, 2007</marker>
<rawString>Yohei Seki, David Kirk Evans, Lun-Wei Ku, and et al. 2007. Overview of Opinion Analysis Pilot Task at NTCIR-6. Proc. of the NTCIR-6 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yohei Seki</author>
<author>David Kirk Evans</author>
<author>Lun-Wei Ku</author>
</authors>
<date>2008</date>
<booktitle>Overview of Multilingual Opinion Analysis Task at NTCIR-7. Proc. of the NTCIR-7 Workshop.</booktitle>
<pages>12</pages>
<contexts>
<context position="2281" citStr="Seki et al., 2008" startWordPosition="343" endWordPosition="346">ce of reporting verbs is a very important feature for identifying opinion holders in news texts, which has not been clearly indicated; 2) we argue that the identification of 46 opinion targets should not be done alone without considering opinion holders, because opinion holders are much easier to be identified in news texts and the identified holders are quite useful for the identification of the associated targets. Our approach shows encouraging performance on opinion holder/target identification, and the results are much better than the baseline results and most results reported in NTCIR-7 (Seki et al., 2008). The paper is organized as follows. Sec. 2 introduces related work. Sec. 3 gives the linguistic analysis of opinion holder/target. The proposed approach is described in Sec. 4, followed by the experiments in Sec. 5. Lastly we conclude in Sec. 6. 2 Related Work Although document-level sentiment analysis (Turney, 2002; Pang et al., 2002) can provide the overall polarity of the whole text, it fails to detect the holders and targets of the sentiment in texts. 2.1 Opinion Holders/ Target Identification For opinion mining of product reviews, opinion holder identification is usually omitted under th</context>
<context position="4134" citStr="Seki et al., 2008" startWordPosition="631" endWordPosition="634">osed to map the semantic frames of FrameNet into opinion holder and target for only adjectives and verbs. Kim et al. (2008) proposed to Proceedings of the NAACL HLT 2010 Student Research Workshop, pages 46–51, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics use syntactic structures for target identification without considering opinion holders. Stoyanov and Cardie (2008) define opinion topic and target and treat the task as a co-reference resolution problem. For the identification of opinion holders/targets in Chinese, there were several reports at NTCIR-7 (Seki et al., 2008). Xu et al. (2008) proposed to use some heuristic rules for opinion holder/target identification. Ku et al. (2008) treated opinion holder identification as a binary classification problem of determining if a word was a part of an opinion holder. 2.2 Chinese Dependency Parsing Dependency structures represent all sentence relationships uniformly as typed dependency relations between pairs of words. Some major dependency relations for Chinese (Ma et al., 2004) include tiN (Subject-Verb, SBV), M动 (Verb-Object, VOB), ZrP(Attributive-Noun, ATT), &amp;CA (Quantifier, QUN) and It A 结 41 (Independent struc</context>
<context position="12882" citStr="Seki et al., 2008" startWordPosition="2047" endWordPosition="2050">arget could be the subject of the sentence. 3) If still no target candidate is found in step 2, we find the object in the sentence as the target because the object could be the opinion target in case there is no subject and no opinion holder. Target candidate expansion (EP) is similar to holder candidate expansion described in Sec. 4.3.2. If an opinion target is in the opinion holder candidates (we call it holder conflict, HC), we remove it from the target candidates, and then try to find another using the above procedure. 5 Experiments We use the traditional Chinese test data in NTCIR7 MOAT (Seki et al., 2008) for our experiments. Out of 4465 sentences, 2174 are annotated as opinionated by the lenient standard, and the opinion holders of some opinionated sentences are marked as POST_AUTHOR denoting the author of the news article. We use the final list given by the organizers as the gold standard. Baselines for opinion holder identification: Baseline 1: We just use the subject of reporting verbs as the opinion holder, without sentence preprocessing described in Sec. 4.2 and any heuristic rules introduced in Sec. 4.3.1. Baseline 2: We also implement the CRF model for detecting opinion holders (Choi e</context>
<context position="18204" citStr="Seki et al., 2008" startWordPosition="2932" endWordPosition="2935">ing all the factors achieves the best performance; 2) EP significantly improves F1 of EM without much improvement on F1 of HM or PM, showing that EP’s major contribution lies in exact match; 3) The major contribution of HC is the improvement of F1s of HM and PM, showing the automatically identified opinion holders are quite helpful for finding opinion targets; 4) SP+EP+HC improves the performance in terms of all three metrics; and our approach further improves the performance by adding HR. 5.3 Discussion Here we compare our results with those reported at NTCIR-7 MOAT traditional Chinese test (Seki et al., 2008). Without considering the errors in the previous step, the highest F1s for opinion holder analysis reported by the four participants were respectively 82.5%, 59.9%, 50.3% and 59.5%, and the highest F1s for target reported by the three participants were respectively 60.6%, 2.1% and 3.6%. Compared to the results at NTCIR-7, our performances on both opinion holder identification in Table 1 and that on target identification in Table 2 seem quite encouraging even by the EM metrics. Consider the evaluation for opinion holders/targets was semi-automatic at NTCIR-7. We should note that although the ge</context>
</contexts>
<marker>Seki, Evans, Ku, 2008</marker>
<rawString>Yohei Seki, David Kirk Evans, Lun-Wei Ku, and et al. 2008. Overview of Multilingual Opinion Analysis Task at NTCIR-7. Proc. of the NTCIR-7 Workshop. Japan. 2008. 12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jilin Shi</author>
<author>Yinggui Zhu</author>
</authors>
<date>2006</date>
<booktitle>The Lexicon of Chinese Positive Words (* p7 p7 A ).</booktitle>
<publisher>Sichuan Lexicon Press.</publisher>
<contexts>
<context position="7609" citStr="Shi and Zhu, 2006" startWordPosition="1166" endWordPosition="1169">ones. 4.1 Lexical Resources The reporting verbs were firstly collected from the Chinese sample data of NTCIR-6 OAPT (Seki et al., 2007) in which the OPINION_OPR tag was used to mark them. We then use HowNet, WordNet and Tongyici Cilin to extend the reporting verbs from 68 to 308 words through manual synonym search. Some frequently used reporting verbs include 說(say), �T(express), 32, ,(think), etc. Some of the reporting verbs could also convey opinions, such as #L 9T (criticize), � � (condemn), �%- (praise), etc. For opinion-bearing words/phrases, we use The Lexicon of Chinese Positive Words (Shi and Zhu, 2006) and The Lexicon of Chinese Negative Words (Yang and Zhu, 2006), which consist of 5046 positive items and 3499 negative ones, respectively. 1 The resolution of the anaphor or co-reference has not been dealt with yet, i.e. the identified holders of the sentence are assumed to be in the same form as it appears in the sentence. 47 Figure 1. Dependency Tree for Sentence a) 4.2 Chinese Sentence Preprocessing (SP) To enhance the robustness of the dependency parser, named entities are first recognized with a traditional Chinese word segmentation tool with access to the very large LIVAC dictionary (ht</context>
</contexts>
<marker>Shi, Zhu, 2006</marker>
<rawString>Jilin Shi and Yinggui Zhu. 2006. The Lexicon of Chinese Positive Words (* p7 p7 A ). Sichuan Lexicon Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veselin Stoyanov</author>
<author>Claire Cardie</author>
</authors>
<title>Topic Identification for Fine-Grained Opinion Analysis.</title>
<date>2008</date>
<booktitle>In Proc. of COLING-08.</booktitle>
<contexts>
<context position="3925" citStr="Stoyanov and Cardie (2008)" startWordPosition="599" endWordPosition="602">ify opinion propositions and their holders by semantic parsing techniques. Choi et al. (2005) and Kim and Hovy (2005) identify only opinion holders on the MPQA corpus (Wilson and Wiebe, 2003). Kim and Hovy (2006) proposed to map the semantic frames of FrameNet into opinion holder and target for only adjectives and verbs. Kim et al. (2008) proposed to Proceedings of the NAACL HLT 2010 Student Research Workshop, pages 46–51, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics use syntactic structures for target identification without considering opinion holders. Stoyanov and Cardie (2008) define opinion topic and target and treat the task as a co-reference resolution problem. For the identification of opinion holders/targets in Chinese, there were several reports at NTCIR-7 (Seki et al., 2008). Xu et al. (2008) proposed to use some heuristic rules for opinion holder/target identification. Ku et al. (2008) treated opinion holder identification as a binary classification problem of determining if a word was a part of an opinion holder. 2.2 Chinese Dependency Parsing Dependency structures represent all sentence relationships uniformly as typed dependency relations between pairs o</context>
</contexts>
<marker>Stoyanov, Cardie, 2008</marker>
<rawString>Veselin Stoyanov and Claire Cardie. 2008. Topic Identification for Fine-Grained Opinion Analysis. In Proc. of COLING-08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Thumbs up or thumbs down? Semantic orientation applied to unsupervised classification of reviews,</title>
<date>2002</date>
<booktitle>In Proc. of ACL-02.</booktitle>
<contexts>
<context position="947" citStr="Turney, 2002" startWordPosition="137" endWordPosition="138">ith dependency parser in Chinese news texts, i.e. to identify opinion holders by means of reporting verbs and to identify opinion targets by considering both opinion holders and opinion-bearing words. The experiments with NTCIR-7 MOAT’s Chinese test data show that our approach provides better performance than the baselines and most systems reported at NTCIR-7. 1 Introduction In recent years, sentiment analysis, which mines opinions from information sources such as news, blogs and product reviews, has drawn much attention in the NLP field (Hatzivassiloglou and McKeown, 1997; Pang et al., 2002; Turney, 2002; Hu and Liu, 2004). An opinion expressed in a text involves different components, including opinion expression, opinion holder and target (Wilson and Wiebe, 2003). Opinion holder is usually an entity that holds an opinion, and opinion target is what the opinion is about (Kim and Hovy, 2006). Although there have been research on identifying opinion holders and targets in English product reviews and news texts, little work has been reported on similar tasks involving Chinese news texts. In this study, we investigate how dependency parsing can be used to help the task on opinion holder/target id</context>
<context position="2599" citStr="Turney, 2002" startWordPosition="395" endWordPosition="396">s and the identified holders are quite useful for the identification of the associated targets. Our approach shows encouraging performance on opinion holder/target identification, and the results are much better than the baseline results and most results reported in NTCIR-7 (Seki et al., 2008). The paper is organized as follows. Sec. 2 introduces related work. Sec. 3 gives the linguistic analysis of opinion holder/target. The proposed approach is described in Sec. 4, followed by the experiments in Sec. 5. Lastly we conclude in Sec. 6. 2 Related Work Although document-level sentiment analysis (Turney, 2002; Pang et al., 2002) can provide the overall polarity of the whole text, it fails to detect the holders and targets of the sentiment in texts. 2.1 Opinion Holders/ Target Identification For opinion mining of product reviews, opinion holder identification is usually omitted under the assumption that opinion holder is the review writer; and opinion targets are limited to the product discussed and its features (Hu and Liu, 2004). But in news texts, opinion holders/targets are more diverse: all named entities and noun phrases can be opinion holders; while opinion targets could be noun phrases, ver</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>Peter D. Turney. 2002. Thumbs up or thumbs down? Semantic orientation applied to unsupervised classification of reviews, In Proc. of ACL-02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
</authors>
<title>Annotating opinions in the world press.</title>
<date>2003</date>
<booktitle>Proc. of the 4th ACL SIGdial Workshop on Discourse and Dialogue (SIGdial-03).</booktitle>
<contexts>
<context position="1110" citStr="Wilson and Wiebe, 2003" startWordPosition="159" endWordPosition="162"> both opinion holders and opinion-bearing words. The experiments with NTCIR-7 MOAT’s Chinese test data show that our approach provides better performance than the baselines and most systems reported at NTCIR-7. 1 Introduction In recent years, sentiment analysis, which mines opinions from information sources such as news, blogs and product reviews, has drawn much attention in the NLP field (Hatzivassiloglou and McKeown, 1997; Pang et al., 2002; Turney, 2002; Hu and Liu, 2004). An opinion expressed in a text involves different components, including opinion expression, opinion holder and target (Wilson and Wiebe, 2003). Opinion holder is usually an entity that holds an opinion, and opinion target is what the opinion is about (Kim and Hovy, 2006). Although there have been research on identifying opinion holders and targets in English product reviews and news texts, little work has been reported on similar tasks involving Chinese news texts. In this study, we investigate how dependency parsing can be used to help the task on opinion holder/target identification in Chinese news texts. Three possible contributions from this study are: 1) we propose that the existence of reporting verbs is a very important featu</context>
<context position="3490" citStr="Wilson and Wiebe, 2003" startWordPosition="536" endWordPosition="539">itted under the assumption that opinion holder is the review writer; and opinion targets are limited to the product discussed and its features (Hu and Liu, 2004). But in news texts, opinion holders/targets are more diverse: all named entities and noun phrases can be opinion holders; while opinion targets could be noun phrases, verb phrases or even clauses (Kim and Hovy, 2006; Ruppenhofer et al. 2008). Bethard et al. (2004) identify opinion propositions and their holders by semantic parsing techniques. Choi et al. (2005) and Kim and Hovy (2005) identify only opinion holders on the MPQA corpus (Wilson and Wiebe, 2003). Kim and Hovy (2006) proposed to map the semantic frames of FrameNet into opinion holder and target for only adjectives and verbs. Kim et al. (2008) proposed to Proceedings of the NAACL HLT 2010 Student Research Workshop, pages 46–51, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics use syntactic structures for target identification without considering opinion holders. Stoyanov and Cardie (2008) define opinion topic and target and treat the task as a co-reference resolution problem. For the identification of opinion holders/targets in Chinese, there were se</context>
<context position="5381" citStr="Wilson and Wiebe, 2003" startWordPosition="823" endWordPosition="826">following Chinese sentence: a) 俄國 外長 伊凡諾夫 說,北約 東向 張是 “ 邁向 錯誤 的 方向 ” 。 Russian Foreign Minister Ivanov said that NATO&apos;s eastward expansion was &amp;quot;Towards the wrong direction.&amp;quot; Its dependency tree is shown in Figure1. Its head is the verb 說 (said), whose subject and object are respectively 俄国外长伊凡诺夫 (Russian Foreign Minister Ivanov) and the embedded clause 北約東 向擴張是“邁向錯誤的方向” (NATO&apos;s eastward expansion was &amp;quot;towards the wrong direction.&amp;quot;). 3 Linguistic Analysis of Opinions The opinions in news text may be explicitly mentioned or be expressed indirectly by the types of words and the style of language (Wilson and Wiebe, 2003). Two kinds of lexical clues are exploited here for opinion holder/target identification: Reporting verbs: verbs indicating speech events; Opinion-bearing Words: words or phrases containing polarity (i.e. positive, negative or neutral). In sentence a) above, the reporting verb 說 (said) indicates a speech event expressing an opinion given by the holder AW ,4长 9W诺--k (Russian Foreign Minister Ivanov). Meanwhile, the opinionbearing word 錯 誤 (wrong) shows negative attitude towards the target 北 約 東 向 擴 張 (NATO&apos;s eastward expansion). Therefore, we assume that a large proportion of holders are govern</context>
</contexts>
<marker>Wilson, Wiebe, 2003</marker>
<rawString>Theresa Wilson and Janyce Wiebe. 2003. Annotating opinions in the world press. Proc. of the 4th ACL SIGdial Workshop on Discourse and Dialogue (SIGdial-03).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruifeng Xu</author>
</authors>
<title>Kam-Fai Wong and Yunqing Xia.</title>
<date>2008</date>
<booktitle>Coarse-Fine Opinion Mining - WIA in NTCIR-7 MOAT Task. Proc. of the 7th NTCIR Workshop.</booktitle>
<marker>Xu, 2008</marker>
<rawString>Ruifeng Xu, Kam-Fai Wong and Yunqing Xia. 2008. Coarse-Fine Opinion Mining - WIA in NTCIR-7 MOAT Task. Proc. of the 7th NTCIR Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ling Yang</author>
<author>Yinggui Zhu</author>
</authors>
<title>The Lexicon of Chinese Negative Words (0- p7p7A ).</title>
<date>2006</date>
<publisher>Sichuan Lexicon Press.</publisher>
<contexts>
<context position="7672" citStr="Yang and Zhu, 2006" startWordPosition="1177" endWordPosition="1180">ollected from the Chinese sample data of NTCIR-6 OAPT (Seki et al., 2007) in which the OPINION_OPR tag was used to mark them. We then use HowNet, WordNet and Tongyici Cilin to extend the reporting verbs from 68 to 308 words through manual synonym search. Some frequently used reporting verbs include 說(say), �T(express), 32, ,(think), etc. Some of the reporting verbs could also convey opinions, such as #L 9T (criticize), � � (condemn), �%- (praise), etc. For opinion-bearing words/phrases, we use The Lexicon of Chinese Positive Words (Shi and Zhu, 2006) and The Lexicon of Chinese Negative Words (Yang and Zhu, 2006), which consist of 5046 positive items and 3499 negative ones, respectively. 1 The resolution of the anaphor or co-reference has not been dealt with yet, i.e. the identified holders of the sentence are assumed to be in the same form as it appears in the sentence. 47 Figure 1. Dependency Tree for Sentence a) 4.2 Chinese Sentence Preprocessing (SP) To enhance the robustness of the dependency parser, named entities are first recognized with a traditional Chinese word segmentation tool with access to the very large LIVAC dictionary (http://www.livac.org) collected from Chinese news published in Ho</context>
</contexts>
<marker>Yang, Zhu, 2006</marker>
<rawString>Ling Yang and Yinggui Zhu. 2006. The Lexicon of Chinese Negative Words (0- p7p7A ). Sichuan Lexicon Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>