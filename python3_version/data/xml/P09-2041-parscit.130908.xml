<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004649">
<title confidence="0.985681">
Automatic Satire Detection: Are You Having a Laugh?
</title>
<author confidence="0.979489">
Clint Burfoot
</author>
<affiliation confidence="0.773441666666667">
CSSE
University of Melbourne
VIC 3010 Australia
</affiliation>
<email confidence="0.994431">
cburfoot@csse.unimelb.edu.au
</email>
<author confidence="0.919852">
Timothy Baldwin
</author>
<affiliation confidence="0.729527333333333">
CSSE
University of Melbourne
VIC 3010 Australia
</affiliation>
<email confidence="0.996963">
tim@csse.unimelb.edu.au
</email>
<sectionHeader confidence="0.993855" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999961">
We introduce the novel task of determin-
ing whether a newswire article is “true”
or satirical. We experiment with SVMs,
feature scaling, and a number of lexical
and semantic feature types, and achieve
promising results over the task.
</bodyText>
<sectionHeader confidence="0.999268" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.956813267857143">
This paper describes a method for filtering satirical
news articles from true newswire documents. We
define a satirical article as one which deliberately
exposes real-world individuals, organisations and
events to ridicule.
Satirical news articles tend to mimic true
newswire articles, incorporating irony and non se-
quitur in an attempt to provide humorous insight.
An example excerpt is:
Bank Of England Governor Mervyn King is a
Queen, Says Fed Chairman Ben Bernanke
During last night’s appearance on the Amer-
ican David Letterman Show, Fed Chairman
Ben Bernanke let slip that Bank of England
(BOE) Governor, Mervyn King, enjoys wearing
women’s clothing.
Contrast this with a snippet of a true newswire ar-
ticle:
Delegates prepare for Cairo conference amid
tight security
Delegates from 156 countries began preparatory
talks here Saturday ahead of the official opening
of the UN World Population Conference amid
tight security.
The basis for our claim that the first document is
satirical is surprisingly subtle in nature, and relates
to the absurdity of the suggestion that a prominent
figure would expose another prominent figure as
a cross dresser, the implausibility of this story ap-
pearing in a reputable news source, and the pun on
the name (King being a Queen).
Satire classification is a novel task to compu-
tational linguistics. It is somewhat similar to the
more widely-researched text classification tasks of
spam filtering (Androutsopoulos et al., 2000) and
sentiment classification (Pang and Lee, 2008), in
that: (a) it is a binary classification task, and (b)
it is an intrinsically semantic task, i.e. satire news
articles are recognisable as such through interpre-
tation and cross-comparison to world knowledge
about the entities involved. Similarly to spam fil-
tering and sentiment classification, a key ques-
tion asked in this research is whether it is possi-
ble to perform the task on the basis of simple lex-
ical features of various types. That is, is it pos-
sible to automatically detect satire without access
to the complex inferencing and real-world knowl-
edge that humans make use of.
The primary contributions of this research are as
follows: (1) we introduce a novel task to the arena
of computational linguistics and machine learning,
and make available a standardised dataset for re-
search on satire detection; and (2) we develop a
method which is adept at identifying satire based
on simple bag-of-words features, and further ex-
tend it to include richer features.
</bodyText>
<sectionHeader confidence="0.980706" genericHeader="introduction">
2 Corpus
</sectionHeader>
<bodyText confidence="0.999439916666667">
Our satire corpus consists of a total of 4000
newswire documents and 233 satire news articles,
split into fixed training and test sets as detailed in
Table 1. The newswire documents were randomly
sampled from the English Gigaword Corpus. The
satire documents were selected to relate closely
to at least one of the newswire documents by:
(1) randomly selecting a newswire document; (2)
hand-picking a key individual, institution or event
from the selected document, and using it to for-
mulate a phrasal query (e.g. Bill Clinton); (3) us-
ing the query to issue a site-restricted query to the
</bodyText>
<page confidence="0.977508">
161
</page>
<note confidence="0.971989">
Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 161–164,
Suntec, Singapore, 4 August 2009. c�2009 ACL and AFNLP
</note>
<table confidence="0.993755333333333">
Training Test Total
TRUE 2505 1495 4000
SATIRE 133 100 233
</table>
<tableCaption confidence="0.999877">
Table 1: Corpus statistics
</tableCaption>
<bodyText confidence="0.999951709677419">
Google search engine;&apos; and (4) manually filtering
out “non-newsy”, irrelevant and overly-offensive
documents from the top-10 returned documents
(i.e. documents not containing satire news articles,
or containing satire articles which were not rel-
evant to the original query). All newswire and
satire documents were then converted to plain text
of consistent format using lynx, and all content
other than the title and body of the article was
manually removed (including web page menus,
and header and footer data). Finally, all documents
were manually post-edited to remove references to
the source (e.g. AP or Onion), formatting quirks
specific to a particular source (e.g. all caps in the
title), and any textual metadata which was indica-
tive of the document source (e.g. editorial notes,
dates and locations). This was all in an effort to
prevent classifiers from accessing superficial fea-
tures which are reliable indicators of the document
source and hence trivialise the satire detection pro-
cess.
It is important to note that the number of satiri-
cal news articles in the corpus is significantly less
than the number of true newswire articles. This
reflects an impressionistic view of the web: there
is far more true news content than satirical news
content.
The corpus is novel to this research,
and is publicly available for download at
http://www.csse.unimelb.edu.au/
research/lt/resources/satire/.
</bodyText>
<sectionHeader confidence="0.997519" genericHeader="method">
3 Method
</sectionHeader>
<subsectionHeader confidence="0.99996">
3.1 Standard text classification approach
</subsectionHeader>
<bodyText confidence="0.9998282">
We take our starting point from topic-based text
classification (Dumais et al., 1998; Joachims,
1998) and sentiment classification (Turney, 2002;
Pang and Lee, 2008). State-of-the-art results in
both fields have been achieved using support vec-
</bodyText>
<construct confidence="0.651498666666667">
&apos;The sites queried were satirewire.com,
theonion.com, newsgroper.com, thespoof.
com, brokennewz.com, thetoque.com,
bbspot.com, neowhig.org, humorfeed.com,
satiricalmuslim.com, yunews.com,
newsbiscuit.com.
</construct>
<bodyText confidence="0.994100666666667">
tor machines (SVMs) and bag-of-words features.
We supplement the bag-of-words model with fea-
ture weighting, using the two methods described
below.
Binary feature weights: Under this scheme
all features are given the same weight, regard-
less of how many times they appear in each arti-
cle. The topic and sentiment classification exam-
ples cited found binary features gave better perfor-
mance than other alternatives.
Bi-normal separation feature scaling: BNS
(Forman, 2008) has been shown to outperform
other established feature representation schemes
on a wide range of text classification tasks. This
superiority is especially pronounced for collec-
tions with a low proportion of positive class in-
stances. Under BNS, features are allocated a
weight according to the formula:
</bodyText>
<equation confidence="0.829009">
|F−&apos;(tpr) − F−&apos;(fpr)|
</equation>
<bodyText confidence="0.99984755">
where F−&apos; is the inverse normal cumulative dis-
tribution function, tpr is the true positive rate
(P(feature|positive class)) and fpr is the false pos-
itive rate (P(feature|negative class)).
BNS produces the highest weights for features
that are strongly correlated with either the nega-
tive or positive class. Features that occur evenly
across the training instances are given the lowest
weight. This behaviour is particularly helpful for
features that correlate with the negative class in
a negatively-skewed classification task, so in our
case BNS should assist the classifier in making use
of features that identify true articles.
SVM classification is performed with SVMlight
(Joachims, 1999) using a linear kernel and the de-
fault parameter settings. Tokens are case folded;
currency amounts (e.g. $2.50), abbreviations (e.g.
U.S.A.), and punctuation sequences (e.g. a
comma, or a closing quote mark followed by a pe-
riod) are treated as separate features.
</bodyText>
<subsectionHeader confidence="0.995975">
3.2 Targeted lexical features
</subsectionHeader>
<bodyText confidence="0.999902">
This section describe three types of features in-
tended to embody characteristics of satire news
documents.
Headline features: Most of the articles in the
corpus have a headline as their first line. To a hu-
man reader, the vast majority of the satire docu-
ments in our corpus are immediately recognisable
as such from the headline alone, suggesting that
our classifiers may get something out of having the
</bodyText>
<page confidence="0.990986">
162
</page>
<bodyText confidence="0.996433078947368">
headline contents explicitly identified in the fea-
ture vector. To this end, we add an additional fea-
ture for each unigram appearing on the first line
of an article. In this way the heading tokens are
represented twice: once in the overall set of uni-
grams in the article, and once in the set of heading
unigrams.
Profanity: true news articles very occasionally
include a verbal quote which contains offensive
language, but in practically all other cases it is in-
cumbent on journalists and editors to keep their
language “clean”. A review of the corpus shows
that this is not the case with satirical news, which
occasionally uses profanity as a humorous device.
Let P be a binary feature indicating whether
or not an article contains profanity, as determined
by the Regexp::Common::profanity Perl
module.2
Slang: As with profanity, it is intuitively true
that true news articles tend to avoid slang. An im-
pressionistic review of the corpus suggests that in-
formal language is much more common to satirical
articles. We measure the informality of an article
as:
where T is the set of unigram tokens in the article
and s is a function taking the value 1 if the token
has a dictionary definition marked as slang and 0
if it does not.
It is important to note that this measure of “in-
formality” is approximate at best. We do not at-
tempt, e.g., to disambiguate the sense of individ-
ual word terms to tell whether the slang sense of
a word is the one intended. Rather, we simply
check to see if each word has a slang usage in Wik-
tionary.3
A continuous feature is set to the value of i for
each article. Discrete features highi and lowi are
set as:
</bodyText>
<equation confidence="0.960383">
highi def J 1 v &gt; i + 2σ;
l(((0
lowi def I 1 v &lt; i − 2σ;
(I = 0
</equation>
<bodyText confidence="0.9998485">
where ¯i and σ are, respectively, the mean and stan-
dard deviation of i across all articles.
</bodyText>
<footnote confidence="0.999882">
2http://search.cpan.org/perldoc?
Regexp::Common::profanity
3http://www.wiktionary.org
</footnote>
<subsectionHeader confidence="0.995376">
3.3 Semantic validity
</subsectionHeader>
<bodyText confidence="0.987606">
Lexical approaches are clearly inadequate if we
assume that good satirical news articles tend to
emulate real news in tone, style, and content.
What is needed is an approach that captures the
document semantics.
One common device in satire news articles is
absurdity, in terms of describing well-known indi-
viduals in unfamiliar settings which parody their
viewpoints or public profile. We attempt to cap-
ture this via validity, in the form of the relative fre-
quency of the particular combination of key partic-
ipants reported in the story. Our method identifies
the named entities in a given document and queries
the web for the conjunction of those entities. Our
expectation is that true news stories will have been
reported in various forums, and hence the number
of web documents which include the same com-
bination of entities will be higher than with satire
documents.
To implement this method, we first use the
Stanford Named Entity Recognizer4 (Finkel et al.,
2005) to identify the set of person and organisation
entities, E, from each article in the corpus.
From this, we estimate the validity of the com-
bination of entities in the article as:
v(E) def = |g(E)|
where g is the set of matching documents returned
by Google using a conjunctive query. We antici-
pate that v will have two potentially useful prop-
erties: (1) it will be relatively lower when E in-
cludes made-up entity names such as Hitler Com-
memoration Institute, found in one satirical corpus
article; and (2) it will be relatively lower when E
contains unusual combinations of entities such as,
for example, those in the satirical article beginning
Missing Brazilian balloonist Padre spotted strad-
dling Pink Floyd flying pig.
We include both a continuous representation of
v for each article, in the form of log(v(E)), and
discrete variants of the feature, based on the same
methodology as for highi and lowi.
</bodyText>
<sectionHeader confidence="0.999929" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.999798666666667">
The results for our classifiers over the satire cor-
pus are shown in Table 2. The baseline is a naive
classifier that assigns all instances to the positive
</bodyText>
<footnote confidence="0.925728">
4http://nlp.stanford.edu/software/
CRF-NER.shtml
</footnote>
<equation confidence="0.9091698">
∑
s(t)
|T |t∈T
def 1
i=
</equation>
<page confidence="0.996702">
163
</page>
<table confidence="0.9997394">
(“article⇒SATIRE?”) P R F
all-positive baseline 0.063 1.000 0.118
BIN 0.943 0.500 0.654
BIN+lex 0.945 0.520 0.671
BIN+val 0.943 0.500 0.654
BIN+all 0.945 0.520 0.671
BNS 0.944 0.670 0.784
BNS+lex 0.957 0.660 0.781
BNS+val 0.945 0.690 0.798
BNS+all 0.958 0.680 0.795
</table>
<tableCaption confidence="0.964436">
Table 2: Results for satire detection (P = preci-
</tableCaption>
<bodyText confidence="0.999115861111111">
sion, R = recall, and F = F-score) for binary un-
igram features (BIN) and BNS unigram features
(BNS), optionally using lexical (lex), validity (val)
or combined lexical and validity (all) features
class (i.e. SATIRE). An SVM classifier with simple
binary unigram word features provides a standard
text classification benchmark.
All of the classifiers easily outperform the base-
line. This is to be expected given the low pro-
portion of positive instances in the corpus. The
benchmark classifier has very good precision, but
recall of only 0.500. Adding the heading, slang,
and profanity features provides a small improve-
ment in both precision and recall.
Moving to BNS feature scaling keeps the very
high precision and increases the recall to 0.670.
Adding in the heading, slang and profanity lexical
features (“+lex”) actually decreases the F-score
slightly, but adding the validity features (“+val”)
provides a near 2 point F-score increase, resulting
in the best overall F-score of 0.798.
All of the BNS scores achieve statistically
significant improvements over the benchmark in
terms of F-score (using approximate randomisa-
tion, p &lt; 0.05). The 1-2% gains given by adding
in the various feature types are not statistically sig-
nificant due to the small number of satire instances
concerned.
All of the classifiers achieve very high precision
and considerably lower recall. Error analysis sug-
gests that the reason for the lower recall is subtler
satire articles, which require detailed knowledge
of the individuals to be fully appreciated as satire.
While they are not perfect, however, the classi-
fiers achieve remarkably high performance given
the superficiality of the features used.
</bodyText>
<sectionHeader confidence="0.986596" genericHeader="conclusions">
5 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.999991142857143">
This paper has introduced a novel task to computa-
tional linguistics and machine learning: determin-
ing whether a newswire article is “true” or satiri-
cal. We found that the combination of SVMs with
BNS feature scaling achieves high precision and
lower recall, and that the inclusion of the notion of
“validity” achieves the best overall F-score.
</bodyText>
<sectionHeader confidence="0.999186" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999838571428572">
Ion Androutsopoulos, John Koutsias, Konstantinos V.
Chandrinos, George Paliouras, and Constantine D.
Spyropoulos. 2000. An evaluation of Naive
Bayesian anti-spam filtering. In Proceedings of the
11th European Conference on Machine Learning,
pages 9–17, Barcelona, Spain.
Susan Dumais, John Platt, David Heckerman, and
Mehran Sahami. 1998. Inductive learning algo-
rithms and representations for text categorization.
In Proceedings of the Seventh International Confer-
ence on Information and Knowledge Management,
pages 148–155, New York, USA.
Jenny Rose Finkel, Trond Grenager, and Christopher
Manning. 2005. Incorporating non-local informa-
tion into information extraction systems by Gibbs
sampling. In Proceedings of the 43rd Annual Meet-
ing of the Association for Computational Linguistics
(ACL’05), pages 363–370, Ann Arbor, USA.
George Forman. 2008. BNS scaling: An improved
representation over TF-IDF for SVM text classifi-
cation. In Proceedings of the 17th International
Conference on Information and Knowledge Man-
agement, pages 263–270, Napa Valley, USA.
Thorsten Joachims. 1998. Text categorization with
support vector machines: learning with many rele-
vant features. In Proceedings of the 10th European
Conference on Machine Learning, pages 137–142,
Chemnitz, Germany.
Thorsten Joachims. 1999. Making large-scale sup-
port vector machine learning practical. In Bernhard
Sch¨olkopf, Christopher J. C. Burges, and Alexan-
der J. Smola, editors, Advances in Kernel Meth-
ods: Support Vector Learning, pages 169–184. MIT
Press, Cambridge, USA.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Foundations and Trends in In-
formation Retrieval, 2(1–2):1–135.
Peter Turney. 2002. Thumbs up or thumbs down? se-
mantic orientation applied to unsupervised classifi-
cation of reviews. In Proceedings of 40th Annual
Meeting of the Association for Computational Lin-
guistics, pages 417–424, Philadelphia, USA.
</reference>
<page confidence="0.99852">
164
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.882013">
<title confidence="0.99945">Automatic Satire Detection: Are You Having a Laugh?</title>
<author confidence="0.998211">Clint Burfoot</author>
<affiliation confidence="0.99205">CSSE University of Melbourne</affiliation>
<address confidence="0.967178">VIC 3010 Australia</address>
<email confidence="0.997199">cburfoot@csse.unimelb.edu.au</email>
<author confidence="0.999856">Timothy Baldwin</author>
<affiliation confidence="0.983637">CSSE University of Melbourne</affiliation>
<address confidence="0.968184">VIC 3010 Australia</address>
<email confidence="0.99871">tim@csse.unimelb.edu.au</email>
<abstract confidence="0.999303">We introduce the novel task of determining whether a newswire article is “true” or satirical. We experiment with SVMs, feature scaling, and a number of lexical and semantic feature types, and achieve promising results over the task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ion Androutsopoulos</author>
<author>John Koutsias</author>
<author>Konstantinos V Chandrinos</author>
<author>George Paliouras</author>
<author>Constantine D Spyropoulos</author>
</authors>
<title>An evaluation of Naive Bayesian anti-spam filtering.</title>
<date>2000</date>
<booktitle>In Proceedings of the 11th European Conference on Machine Learning,</booktitle>
<pages>9--17</pages>
<location>Barcelona,</location>
<contexts>
<context position="1952" citStr="Androutsopoulos et al., 2000" startWordPosition="294" endWordPosition="297">day ahead of the official opening of the UN World Population Conference amid tight security. The basis for our claim that the first document is satirical is surprisingly subtle in nature, and relates to the absurdity of the suggestion that a prominent figure would expose another prominent figure as a cross dresser, the implausibility of this story appearing in a reputable news source, and the pun on the name (King being a Queen). Satire classification is a novel task to computational linguistics. It is somewhat similar to the more widely-researched text classification tasks of spam filtering (Androutsopoulos et al., 2000) and sentiment classification (Pang and Lee, 2008), in that: (a) it is a binary classification task, and (b) it is an intrinsically semantic task, i.e. satire news articles are recognisable as such through interpretation and cross-comparison to world knowledge about the entities involved. Similarly to spam filtering and sentiment classification, a key question asked in this research is whether it is possible to perform the task on the basis of simple lexical features of various types. That is, is it possible to automatically detect satire without access to the complex inferencing and real-worl</context>
</contexts>
<marker>Androutsopoulos, Koutsias, Chandrinos, Paliouras, Spyropoulos, 2000</marker>
<rawString>Ion Androutsopoulos, John Koutsias, Konstantinos V. Chandrinos, George Paliouras, and Constantine D. Spyropoulos. 2000. An evaluation of Naive Bayesian anti-spam filtering. In Proceedings of the 11th European Conference on Machine Learning, pages 9–17, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan Dumais</author>
<author>John Platt</author>
<author>David Heckerman</author>
<author>Mehran Sahami</author>
</authors>
<title>Inductive learning algorithms and representations for text categorization.</title>
<date>1998</date>
<booktitle>In Proceedings of the Seventh International Conference on Information and Knowledge Management,</booktitle>
<pages>148--155</pages>
<location>New York, USA.</location>
<contexts>
<context position="5329" citStr="Dumais et al., 1998" startWordPosition="833" endWordPosition="836">ators of the document source and hence trivialise the satire detection process. It is important to note that the number of satirical news articles in the corpus is significantly less than the number of true newswire articles. This reflects an impressionistic view of the web: there is far more true news content than satirical news content. The corpus is novel to this research, and is publicly available for download at http://www.csse.unimelb.edu.au/ research/lt/resources/satire/. 3 Method 3.1 Standard text classification approach We take our starting point from topic-based text classification (Dumais et al., 1998; Joachims, 1998) and sentiment classification (Turney, 2002; Pang and Lee, 2008). State-of-the-art results in both fields have been achieved using support vec&apos;The sites queried were satirewire.com, theonion.com, newsgroper.com, thespoof. com, brokennewz.com, thetoque.com, bbspot.com, neowhig.org, humorfeed.com, satiricalmuslim.com, yunews.com, newsbiscuit.com. tor machines (SVMs) and bag-of-words features. We supplement the bag-of-words model with feature weighting, using the two methods described below. Binary feature weights: Under this scheme all features are given the same weight, regardl</context>
</contexts>
<marker>Dumais, Platt, Heckerman, Sahami, 1998</marker>
<rawString>Susan Dumais, John Platt, David Heckerman, and Mehran Sahami. 1998. Inductive learning algorithms and representations for text categorization. In Proceedings of the Seventh International Conference on Information and Knowledge Management, pages 148–155, New York, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Trond Grenager</author>
<author>Christopher Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by Gibbs sampling.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>363--370</pages>
<location>Ann Arbor, USA.</location>
<contexts>
<context position="10750" citStr="Finkel et al., 2005" startWordPosition="1709" endWordPosition="1712"> their viewpoints or public profile. We attempt to capture this via validity, in the form of the relative frequency of the particular combination of key participants reported in the story. Our method identifies the named entities in a given document and queries the web for the conjunction of those entities. Our expectation is that true news stories will have been reported in various forums, and hence the number of web documents which include the same combination of entities will be higher than with satire documents. To implement this method, we first use the Stanford Named Entity Recognizer4 (Finkel et al., 2005) to identify the set of person and organisation entities, E, from each article in the corpus. From this, we estimate the validity of the combination of entities in the article as: v(E) def = |g(E)| where g is the set of matching documents returned by Google using a conjunctive query. We anticipate that v will have two potentially useful properties: (1) it will be relatively lower when E includes made-up entity names such as Hitler Commemoration Institute, found in one satirical corpus article; and (2) it will be relatively lower when E contains unusual combinations of entities such as, for exa</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Jenny Rose Finkel, Trond Grenager, and Christopher Manning. 2005. Incorporating non-local information into information extraction systems by Gibbs sampling. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 363–370, Ann Arbor, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Forman</author>
</authors>
<title>BNS scaling: An improved representation over TF-IDF for SVM text classification.</title>
<date>2008</date>
<booktitle>In Proceedings of the 17th International Conference on Information and Knowledge Management,</booktitle>
<pages>263--270</pages>
<location>Napa Valley, USA.</location>
<contexts>
<context position="6161" citStr="Forman, 2008" startWordPosition="945" endWordPosition="946">oper.com, thespoof. com, brokennewz.com, thetoque.com, bbspot.com, neowhig.org, humorfeed.com, satiricalmuslim.com, yunews.com, newsbiscuit.com. tor machines (SVMs) and bag-of-words features. We supplement the bag-of-words model with feature weighting, using the two methods described below. Binary feature weights: Under this scheme all features are given the same weight, regardless of how many times they appear in each article. The topic and sentiment classification examples cited found binary features gave better performance than other alternatives. Bi-normal separation feature scaling: BNS (Forman, 2008) has been shown to outperform other established feature representation schemes on a wide range of text classification tasks. This superiority is especially pronounced for collections with a low proportion of positive class instances. Under BNS, features are allocated a weight according to the formula: |F−&apos;(tpr) − F−&apos;(fpr)| where F−&apos; is the inverse normal cumulative distribution function, tpr is the true positive rate (P(feature|positive class)) and fpr is the false positive rate (P(feature|negative class)). BNS produces the highest weights for features that are strongly correlated with either </context>
</contexts>
<marker>Forman, 2008</marker>
<rawString>George Forman. 2008. BNS scaling: An improved representation over TF-IDF for SVM text classification. In Proceedings of the 17th International Conference on Information and Knowledge Management, pages 263–270, Napa Valley, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Text categorization with support vector machines: learning with many relevant features.</title>
<date>1998</date>
<booktitle>In Proceedings of the 10th European Conference on Machine Learning,</booktitle>
<pages>137--142</pages>
<location>Chemnitz, Germany.</location>
<contexts>
<context position="5346" citStr="Joachims, 1998" startWordPosition="837" endWordPosition="838"> source and hence trivialise the satire detection process. It is important to note that the number of satirical news articles in the corpus is significantly less than the number of true newswire articles. This reflects an impressionistic view of the web: there is far more true news content than satirical news content. The corpus is novel to this research, and is publicly available for download at http://www.csse.unimelb.edu.au/ research/lt/resources/satire/. 3 Method 3.1 Standard text classification approach We take our starting point from topic-based text classification (Dumais et al., 1998; Joachims, 1998) and sentiment classification (Turney, 2002; Pang and Lee, 2008). State-of-the-art results in both fields have been achieved using support vec&apos;The sites queried were satirewire.com, theonion.com, newsgroper.com, thespoof. com, brokennewz.com, thetoque.com, bbspot.com, neowhig.org, humorfeed.com, satiricalmuslim.com, yunews.com, newsbiscuit.com. tor machines (SVMs) and bag-of-words features. We supplement the bag-of-words model with feature weighting, using the two methods described below. Binary feature weights: Under this scheme all features are given the same weight, regardless of how many t</context>
</contexts>
<marker>Joachims, 1998</marker>
<rawString>Thorsten Joachims. 1998. Text categorization with support vector machines: learning with many relevant features. In Proceedings of the 10th European Conference on Machine Learning, pages 137–142, Chemnitz, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Making large-scale support vector machine learning practical.</title>
<date>1999</date>
<booktitle>Advances in Kernel Methods: Support Vector Learning,</booktitle>
<pages>169--184</pages>
<editor>In Bernhard Sch¨olkopf, Christopher J. C. Burges, and Alexander J. Smola, editors,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, USA.</location>
<contexts>
<context position="7179" citStr="Joachims, 1999" startWordPosition="1098" endWordPosition="1099">rue positive rate (P(feature|positive class)) and fpr is the false positive rate (P(feature|negative class)). BNS produces the highest weights for features that are strongly correlated with either the negative or positive class. Features that occur evenly across the training instances are given the lowest weight. This behaviour is particularly helpful for features that correlate with the negative class in a negatively-skewed classification task, so in our case BNS should assist the classifier in making use of features that identify true articles. SVM classification is performed with SVMlight (Joachims, 1999) using a linear kernel and the default parameter settings. Tokens are case folded; currency amounts (e.g. $2.50), abbreviations (e.g. U.S.A.), and punctuation sequences (e.g. a comma, or a closing quote mark followed by a period) are treated as separate features. 3.2 Targeted lexical features This section describe three types of features intended to embody characteristics of satire news documents. Headline features: Most of the articles in the corpus have a headline as their first line. To a human reader, the vast majority of the satire documents in our corpus are immediately recognisable as s</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>Thorsten Joachims. 1999. Making large-scale support vector machine learning practical. In Bernhard Sch¨olkopf, Christopher J. C. Burges, and Alexander J. Smola, editors, Advances in Kernel Methods: Support Vector Learning, pages 169–184. MIT Press, Cambridge, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<booktitle>Foundations and Trends in Information Retrieval,</booktitle>
<pages>2--1</pages>
<contexts>
<context position="2002" citStr="Pang and Lee, 2008" startWordPosition="301" endWordPosition="304"> Conference amid tight security. The basis for our claim that the first document is satirical is surprisingly subtle in nature, and relates to the absurdity of the suggestion that a prominent figure would expose another prominent figure as a cross dresser, the implausibility of this story appearing in a reputable news source, and the pun on the name (King being a Queen). Satire classification is a novel task to computational linguistics. It is somewhat similar to the more widely-researched text classification tasks of spam filtering (Androutsopoulos et al., 2000) and sentiment classification (Pang and Lee, 2008), in that: (a) it is a binary classification task, and (b) it is an intrinsically semantic task, i.e. satire news articles are recognisable as such through interpretation and cross-comparison to world knowledge about the entities involved. Similarly to spam filtering and sentiment classification, a key question asked in this research is whether it is possible to perform the task on the basis of simple lexical features of various types. That is, is it possible to automatically detect satire without access to the complex inferencing and real-world knowledge that humans make use of. The primary c</context>
<context position="5410" citStr="Pang and Lee, 2008" startWordPosition="844" endWordPosition="847">t is important to note that the number of satirical news articles in the corpus is significantly less than the number of true newswire articles. This reflects an impressionistic view of the web: there is far more true news content than satirical news content. The corpus is novel to this research, and is publicly available for download at http://www.csse.unimelb.edu.au/ research/lt/resources/satire/. 3 Method 3.1 Standard text classification approach We take our starting point from topic-based text classification (Dumais et al., 1998; Joachims, 1998) and sentiment classification (Turney, 2002; Pang and Lee, 2008). State-of-the-art results in both fields have been achieved using support vec&apos;The sites queried were satirewire.com, theonion.com, newsgroper.com, thespoof. com, brokennewz.com, thetoque.com, bbspot.com, neowhig.org, humorfeed.com, satiricalmuslim.com, yunews.com, newsbiscuit.com. tor machines (SVMs) and bag-of-words features. We supplement the bag-of-words model with feature weighting, using the two methods described below. Binary feature weights: Under this scheme all features are given the same weight, regardless of how many times they appear in each article. The topic and sentiment classi</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval, 2(1–2):1–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Turney</author>
</authors>
<title>Thumbs up or thumbs down? semantic orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>417--424</pages>
<location>Philadelphia, USA.</location>
<contexts>
<context position="5389" citStr="Turney, 2002" startWordPosition="842" endWordPosition="843">ion process. It is important to note that the number of satirical news articles in the corpus is significantly less than the number of true newswire articles. This reflects an impressionistic view of the web: there is far more true news content than satirical news content. The corpus is novel to this research, and is publicly available for download at http://www.csse.unimelb.edu.au/ research/lt/resources/satire/. 3 Method 3.1 Standard text classification approach We take our starting point from topic-based text classification (Dumais et al., 1998; Joachims, 1998) and sentiment classification (Turney, 2002; Pang and Lee, 2008). State-of-the-art results in both fields have been achieved using support vec&apos;The sites queried were satirewire.com, theonion.com, newsgroper.com, thespoof. com, brokennewz.com, thetoque.com, bbspot.com, neowhig.org, humorfeed.com, satiricalmuslim.com, yunews.com, newsbiscuit.com. tor machines (SVMs) and bag-of-words features. We supplement the bag-of-words model with feature weighting, using the two methods described below. Binary feature weights: Under this scheme all features are given the same weight, regardless of how many times they appear in each article. The topic</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>Peter Turney. 2002. Thumbs up or thumbs down? semantic orientation applied to unsupervised classification of reviews. In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics, pages 417–424, Philadelphia, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>