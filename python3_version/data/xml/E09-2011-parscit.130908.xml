<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000777">
<title confidence="0.998022">
Parsing, Projecting &amp; Prototypes: Repurposing
Linguistic Data on the Web
</title>
<author confidence="0.977248">
William D. Lewis
</author>
<affiliation confidence="0.947151">
Microsoft Research
</affiliation>
<address confidence="0.971057">
Redmond, WA 98052
</address>
<email confidence="0.997969">
wilewis@microsoft.com
</email>
<sectionHeader confidence="0.99956" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999547">
Until very recently, most NLP tasks (e.g., parsing, tag-
ging, etc.) have been confined to a very limited number
of languages, the so-called majority languages. Now,
as the field moves into the era of developing tools for
Resource Poor Languages (RPLs)—a vast majority of
the world’s 7,000 languages are resource poor—the
discipline is confronted not only with the algorithmic
challenges of limited data, but also the sheer difficulty
of locating data in the first place. In this demo, we
present a resource which taps the large body of linguis-
tically annotated data on the Web, data which can be re-
purposed for NLP tasks. Because the field of linguistics
has as its mandate the study of human language—in
fact, the study of all human languages—and has whole-
heartedly embraced the Web as a means for dissemi-
nating linguistic knowledge, the consequence is that a
large quantity of analyzed language data can be found
on the Web. In many cases, the data is richly annotated
and exists for many languages for which there would
otherwise be very limited annotated data. The resource,
the Online Database of INterlinear text (ODIN), makes
this data available and provides additional annotation
and structure, making the resource useful to the Com-
putational Linguistic audience.
In this paper, after a brief discussion of the previous
work on ODIN, we report our recent work on extend-
ing ODIN by applying machine learning methods to
the task of data extraction and language identification,
and on using ODIN to “discover” linguistic knowledge.
Then we outline a plan for the demo presentation.
</bodyText>
<sectionHeader confidence="0.9904865" genericHeader="keywords">
2 Background and Previous work on
ODIN
</sectionHeader>
<bodyText confidence="0.999845833333333">
ODIN is a collection of Interlinear Glossed Text (IGT)
harvested from scholarly documents. In this section,
we describe the original ODIN system (Lewis, 2006),
and the IGT enrichment algorithm (Xia and Lewis,
2007). These serve as the starting point for our current
work, which will be discussed in the next section.
</bodyText>
<subsectionHeader confidence="0.738414">
2.1 Interlinear Glossed Text (IGT)
</subsectionHeader>
<bodyText confidence="0.999936">
In recent years, a large part of linguistic scholarly dis-
course has migrated to the Web, whether it be in the
form of papers informally posted to scholars’ websites,
</bodyText>
<subsectionHeader confidence="0.612736">
Fei Xia
</subsectionHeader>
<bodyText confidence="0.791584777777778">
University of Washington
Seattle, WA 98195
fxia@u.washington.edu
or electronic editions of highly respected journals. In-
cluded in many papers are snippets of language data
that are included as part of this linguistic discourse.
The language data is often represented as Interlinear
Glossed Text (IGT), an example of which is shown in
(1).
</bodyText>
<listItem confidence="0.66893">
(1) Rhoddodd yr athro lyfr i’r bachgen ddoe
</listItem>
<bodyText confidence="0.926068777777778">
gave-3sg the teacher book to-the boy yesterday
“The teacher gave a book to the boy yesterday”
(Bailyn, 2001)
The canonical form of an IGT consists of three lines:
a language line for the language in question, a gloss
line that contains a word-by-word or morpheme-by-
morpheme gloss, and a translation line, usually in En-
glish. The grammatical annotations such as 3sg on the
gloss line are called grams.
</bodyText>
<subsectionHeader confidence="0.998846">
2.2 The Original ODIN System
</subsectionHeader>
<bodyText confidence="0.887759954545454">
ODIN was built in three steps. First, linguistic docu-
ments that may contain instances of IGT are harvested
from the Web using metacrawls. Metacrawling in-
volves throwing queries against an existing search en-
gine, such as Google and Live Search.
Second, IGT instances in the retrieved documents
are identified using regular expression “templates”, ef-
fectively looking for text that resembles IGT. An exam-
ple RegEx template is shown in (2), which matches any
three-line instance (e.g., the IGT instance in (1)) such
that the first line starts with an example number (e.g.,
(1)) and the third line starts with a quotation mark.
(2) \s*\(\d+\).*\n
\s*.*\n
\s*\[‘’&amp;quot;].*\n
The third step is to determine the language of the
language line in an IGT instance. Our original work in
language ID relied on TextCat, an implementation of
(Cavnar and Trenkle, 1994).
As of January 2008 (the time we started our current
work), ODIN had 41,581 instances of IGT for 731 lan-
guages extracted from nearly 3,000 documents.1
</bodyText>
<footnote confidence="0.72050375">
1For a thorough discussion about how ODIN was origi-
nally constructed, see (Lewis, 2006).
Proceedings of the EACL 2009 Demonstrations Session, pages 41–44,
Athens, Greece, 3 April 2009. c�2009 Association for Computational Linguistics
</footnote>
<page confidence="0.999093">
41
</page>
<subsectionHeader confidence="0.997287">
2.3 Enriching IGT data
</subsectionHeader>
<bodyText confidence="0.999994928571428">
Since the language line in IGT data does not come with
annotations (e.g., POS tags, phrase structures), Xia and
Lewis (2007) proposed to enrich the original IGT and
then extract syntactic information (e.g., context-free
rules) to bootstrap NLP tools such as POS taggers and
parsers. The enrichment algorithm has three steps: (1)
parse the English translation with an English parser, (2)
align the language line and the English translation via
the gloss line, and (3) project syntactic structure from
English to the language line. The algorithm was tested
on 538 IGTs from seven languages and the word align-
ment accuracy was 94.1% and projection accuracy (i.e.,
the percentage of correct links in the projected depen-
dency structures) was 81.5%.
</bodyText>
<sectionHeader confidence="0.988491" genericHeader="method">
3 Our recent work
</sectionHeader>
<bodyText confidence="0.999867">
We extend the previous work in three areas: (1) im-
proving IGT detection and language identification, (2)
testing the usefulness of the enriched IGT by answer-
ing typological questions, and (3) enhancing ODIN’s
search facility by allowing structural and “construc-
tion” searches.2
</bodyText>
<subsectionHeader confidence="0.993245">
3.1 IGT detection
</subsectionHeader>
<bodyText confidence="0.99998008">
The canonical form of IGT, as presented in Section 2.1,
consists of three parts and each part is on a single line.
However, many IGT instances, 53.6% of instances in
ODIN, do not follow the canonical format for various
reasons. For instance, some IGT instances are missing
gloss or translation lines as they can be recovered from
context (e.g., other neighboring examples or the text
surrounding the instance); other IGT instances have
multiple translations or language lines (e.g., one part in
the native script, and another in a Latin transliteration).
Because of the irregular structure of IGT instances,
the regular expression templates used in the original
ODIN system performed poorly. We apply machine
learning methods to the task. In particular, we treat the
IGT detection task as a sequence labeling problem: we
train a classifier to tag each line with a pre-defined tag
set,3 use the learner to tag new documents, and con-
vert the best tag sequence into a span sequence. When
trained on 41 documents (with 1573 IGT instances) and
tested on 10 documents (with 447 instances), the F-
score for exact match (i.e., two spans match iff they
are identical) is 88.4%, and for partial match (i.e., two
spans match iff they overlap) is 95.4%.4 In comparison,
the F-score of the RegEx approach on the same test set
is 51.4% for exact match and 74.6% for partial match.
</bodyText>
<footnote confidence="0.981825125">
2By constructions, we mean linguistically salient con-
structions, such as actives, passives, relative clauses, inverted
word orders, etc., in particular those we feel would be of the
most benefit to linguists and computational linguists alike.
3The tagset extends the standard BIO tagging scheme.
4The result is produced by a Maximum Entropy learner.
The results by SVM and CRF learners are similar. The details
were reported in (Xia and Lewis, 2008).
</footnote>
<tableCaption confidence="0.8336835">
Table 1: The language distribution of the IGTs in
ODIN
</tableCaption>
<table confidence="0.999892625">
Range of # of # of IGT % of IGT
IGT instances languages instances instances
&gt; 10000 3 36,691 19.39
1000-9999 37 97,158 51.34
100-999 122 40,260 21.27
10-99 326 12,822 6.78
1-9 838 2,313 1.22
total 1326 189,244 100
</table>
<subsectionHeader confidence="0.991181">
3.2 Language ID
</subsectionHeader>
<bodyText confidence="0.9999842">
The language ID task here is very different from a typ-
ical language ID task. For instance, the number of lan-
guages in ODIN is more than a thousand and could po-
tentially reach several thousand as more data is added.
Furthermore, for most languages in ODIN, our training
data contains few to no instances of IGT. Because of
these properties, applying existing language ID algo-
rithms to the task does not produce satisfactory results.
As IGTs are part of a document, there are often
various cues in the document (e.g., language names)
that can help predict the language ID of the IGT in-
stances. We designed a new algorithm that treats the
language ID task as a pronoun resolution task, where
IGT instances are “pronouns”, language names are “an-
tecedents”, and finding the language name of an IGT
is the same as linking a pronoun (i.e., the IGT) to its
antecedent (i.e., the language name). The algorithm
outperforms existing, general-purpose language iden-
tification algorithms significantly. The detail of the al-
gorithm and experimental results is described in (Xia et
al., 2009).
Running the new IGT detection on the original three
thousand ODIN documents, the number of IGT in-
stances increases from 41,581 to 189,244. We then ran
the new language ID algorithm on the IGTs, and Table
1 shows the language distribution of the IGTs in ODIN
according to the output of the algorithm. For instance,
the third row says that 122 languages each have 100 to
999 IGT instances, and the 40,260 instances in this bin
account for 21.27% of all instances in ODIN.5
</bodyText>
<subsectionHeader confidence="0.999687">
3.3 Answering typological questions
</subsectionHeader>
<bodyText confidence="0.999744">
Linguistic typology is the study of the classification
of languages, where a typology is an organization of
languages by an enumerated list of logically possible
types, most often identified by one or more structural
features. One of the most well known and well studied
typological types, or parameters, is that of canonical
word order, made famous by Joseph Greenberg (Green-
berg, 1963).
</bodyText>
<footnote confidence="0.516879333333333">
5Some IGTs are marked by the authors of the crawled
documents as ungrammatical (usually with an asterisk “*”
at the beginning of the language line). Those IGTs are kept
in ODIN too because they could be useful to other linguists,
the same reason that they were included in the original docu-
ments.
</footnote>
<page confidence="0.998711">
42
</page>
<bodyText confidence="0.9996085">
In (Lewis and Xia, 2008), we described a means
for automatically discovering the answers to a number
of computationally salient typological questions, such
as the canonical order of constituents (e.g., sentential
word order, order of constituents in noun phrases) or
the existence of particular constituents in a language
(e.g., definite or indefinite determiners). In these ex-
periments, we tested not only the potential of IGT to
provide knowledge that could be useful to NLP, but
also for IGT to overcome biases inherent to the op-
portunistic nature of its collection: (1) What we call
the IGT-bias, that is, the bias produced by the fact that
IGT examples are used by authors to demonstrate a par-
ticular fact about a language, causing the collection of
IGT for a language to suffer from a potential lack of
representativeness. (2) What we call the English-bias,
an English-centrism in the examples brought on by the
fact that most IGT examples provide a translation in
English, which can potentially affect subsequent en-
richment of IGT data, such as through structural pro-
jection. In one experiment, we automatically found the
answer to the canonical word order question for about
100 languages, and the accuracy was 99% for all the
languages with at least 40 IGT instances.6 In another
experiment, our system answered 13 typological ques-
tions for 10 languages with an accuracy of 90%. The
discovered knowledge can then be used for subsequent
grammar and tool development work.
The knowledge we capture in IGT instances—both
the native annotations provided by the linguists them-
selves, as well as the answers to a variety of typological
questions discovered in IGT—we use to populate lan-
guage profiles. These profiles are a recent addition to
the ODIN site, and are available for those languages
where sufficient data exists. Following is an example
profile:
</bodyText>
<figure confidence="0.997272846153846">
&lt;Profile&gt;
&lt;language code=&amp;quot;WBP&amp;quot;&gt;Warlpiri&lt;/language&gt;
&lt;ontologyNamespace prefix=&amp;quot;gold&amp;quot;&gt;
http://linguistic-ontology.org/gold.owl#
&lt;/ontologyNamespace&gt;
&lt;feature=&amp;quot;word_order&amp;quot;&gt;&lt;value&gt;SVO&lt;/value&gt;&lt;/feature&gt;
&lt;feature=&amp;quot;det_order&amp;quot;&gt;&lt;value&gt;DT-NN&lt;/value&gt;&lt;/feature&gt;
&lt;feature=&amp;quot;case&amp;quot;&gt;
&lt;value&gt;gold:DativeCase&lt;/value&gt;
&lt;value&gt;gold:ErgativeCase&lt;/value&gt;
&lt;value&gt;gold:NominativeCase&lt;/value&gt;
. . .
&lt;/Profile&gt;
</figure>
<subsectionHeader confidence="0.9496395">
3.4 Enhancing ODIN’s Value to Computational
Linguistics: Search and Language Profiles
</subsectionHeader>
<bodyText confidence="0.9986198">
ODIN provides a variety of ways to search across its
data, in particular, search by language name or code,
language family, and even by annotations and their re-
lated concepts. Once data is discovered that fits the
particular pattern that a user is interested in, he/she can
</bodyText>
<footnote confidence="0.990191">
6Some IGT instances are not sentences and therefore are
not useful for answering this question. Further, those in-
stances marked as ungrammatical (usually with an asterisk
“*”) are ignored for this and all the typological questions.
</footnote>
<bodyText confidence="0.999502272727273">
either display the data (where sufficient citation infor-
mation exists and where the data is relatively clean) or
locate documents in which the data exists. Additional
search facilities allow users to search across poten-
tially linguistically salient structures and return results
in the form of language profiles. Although language
profiles are by no means complete—they are subject
to the availability of data to fill in the answers within
the profiles—they provide a summary of automatically
available knowledge about that language as found in
IGT (or enriched IGT).
</bodyText>
<sectionHeader confidence="0.981617" genericHeader="method">
4 The Demo Presentation
</sectionHeader>
<bodyText confidence="0.999932285714286">
Our focus in this demonstration will be on the query
features of ODIN. In addition, however, we will also
give some background on how ODIN was built, show
how we see the data in ODIN being used by both the
linguistic and NLP communities, and present the kind
of information available in language profiles. The fol-
lowing is our plan for the demo:
</bodyText>
<listItem confidence="0.9998058">
• Very brief discussion on the methods used to build
ODIN (as discussed in Section 2.2, 3.1, and 3.2)
• An overview of the IGT enrichment algorithm (as
discussed in Section 2.3).
• A presentation of ODIN’s search facility and
</listItem>
<bodyText confidence="0.891039">
the results that can be returned, in partic-
ular language profiles (as discussed in Sec-
tion 3.3-3.4). ODIN’s current website is
http://uakari.ling.washington.edu/odin. Users
can also search ODIN using the OLAC7 search
interfaces at the LDC8 and LinguistList.9 Some
search examples are given below.
</bodyText>
<subsectionHeader confidence="0.987675">
4.1 Example 1: Search by Language Name
</subsectionHeader>
<bodyText confidence="0.999993461538461">
The opening screen for ODIN allows the user to search
the ODIN database by clicking a specific language
name in the left-hand frame, or by typing all or part
of a name (finding closest matches). Once a language
is selected, our search tool will list all the documents
that have data for the language in question. The user
can then click on any of those documents, and search
tool will return the IGT instances found in those doc-
uments. Following linguistic custom and fair use re-
strictions, only instances of data that have citations are
displayed. An example is shown in Figure 1. Search by
language and name is by far the most popular search in
ODIN, given the hundreds of queries executed per day.
</bodyText>
<sectionHeader confidence="0.5908095" genericHeader="method">
4.2 Example 2: Search by Linguistic
Constructions
</sectionHeader>
<bodyText confidence="0.9983705">
This type of query looks either at enriched data in the
English translation, or at the projected structures in the
</bodyText>
<footnote confidence="0.9155022">
7Open Language Archives Community
8http://www.language-archives.org/tools/search/
9LinguistList has graciously offered to host ODIN, and it
is being migrated to http://odin.linguistlist.org. Completion
of this migration is expected sometime in April 2009.
</footnote>
<page confidence="0.999593">
43
</page>
<figureCaption confidence="0.999741">
Figure 1: IGT instances in a document
</figureCaption>
<bodyText confidence="0.998744125">
target language data. Figure 2 shows the list of linguis-
tic constructions that are currently covered.
Suppose the user clicks on “Word Order: VSO”,
the search tool will retrieve all the languages in ODIN
that have VSO order according to the PCFGs extracted
from the projected phrase structures (Figure 3). The
user can then click on the Data link for any language in
the list to retrieve the IGT instances in that language.
</bodyText>
<figureCaption confidence="0.7717645">
Figure 2: List of linguistic constructions that are cur-
rently supported
</figureCaption>
<sectionHeader confidence="0.998618" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9999221">
In this paper, we briefly discussed our work on im-
proving the ODIN system, testing the usefulness of
the ODIN data for linguistic study, and enhancing the
search facility. While IGT data collected off the Web is
inherently noisy, we show that even a sample size of 40
IGT instances is large enough to ensure 99% accuracy
in predicting Word Order. In the future, we plan to con-
tinue our efforts to collect more data for ODIN, in order
to make it a more useful resource to the linguistic and
computational linguistic audiences. Likewise, we will
</bodyText>
<figureCaption confidence="0.994686">
Figure 3: Languages in ODIN Determined to be VSO
</figureCaption>
<bodyText confidence="0.9997622">
further extend the search interface to allow more so-
phisticated queries that tap the full breadth of languages
that exist in ODIN, and give users greater access to the
enriched annotations and projected structures that can
be found only in ODIN.
</bodyText>
<sectionHeader confidence="0.999429" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999259055555556">
John Frederick Bailyn. 2001. Inversion, Dislocation and Op-
tionality in Russian. In Gerhild Zybatow, editor, Current
Issues in Formal Slavic Linguistics.
W. B. Cavnar and J. M. Trenkle. 1994. N-gram-based text
categorization. In Proceedings of Third Annual Sympo-
sium on Document Analysis and Information Retrieval,
pages 161–175, Las Vegas, April.
Joseph H. Greenberg. 1963. Some universals of grammar
with particular reference to the order of meaningful el-
ements. In Joseph H. Greenberg, editor, Universals of
Language, pages 73–113. MIT Press, Cambridge, Mas-
sachusetts.
William D. Lewis and Fei Xia. 2008. Automatically Identi-
fying Computationally Relevant Typological Features. In
Proceedings of The Third International Joint Conference
on Natural Language Processing (IJCNLP), Hyderabad,
January.
William D. Lewis. 2006. ODIN: A Model for Adapting and
Enriching Legacy Infrastructure. In Proceedings of the e-
Humanities Workshop, Amsterdam. Held in cooperation
with e-Science 2006: 2nd IEEE International Conference
on e-Science and Grid Computing.
Fei Xia and William D. Lewis. 2007. Multilingual struc-
tural projection across interlinearized text. In Proceedings
of the North American Association of Computational Lin-
guistics (NAACL) conference.
Fei Xia and William D. Lewis. 2008. Repurposing Theoret-
ical Linguistic Data for Tool Development and Search. In
Proceedings of The Third International Joint Conference
on Natural Language Processing (IJCNLP), Hyderabad,
January.
Fei Xia, William D. Lewis, and Hoifung Poon. 2009. Lan-
guage ID in the Context of Harvesting Language Data off
the Web. In Proceedings of The 12th Conference of the Eu-
ropean Chapter of the Association of Computational Lin-
guistics (EACL), Athens, Greece, April.
</reference>
<page confidence="0.999292">
44
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.860513">
<title confidence="0.939492">Parsing, Projecting &amp; Prototypes: Repurposing Linguistic Data on the Web</title>
<author confidence="0.996991">William D Lewis</author>
<affiliation confidence="0.999888">Microsoft Research</affiliation>
<address confidence="0.999868">Redmond, WA 98052</address>
<email confidence="0.979457">wilewis@microsoft.com</email>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>John Frederick Bailyn</author>
</authors>
<date>2001</date>
<booktitle>Inversion, Dislocation and Optionality in Russian. In Gerhild Zybatow, editor, Current Issues in Formal Slavic Linguistics.</booktitle>
<contexts>
<context position="2806" citStr="Bailyn, 2001" startWordPosition="452" endWordPosition="453">y discourse has migrated to the Web, whether it be in the form of papers informally posted to scholars’ websites, Fei Xia University of Washington Seattle, WA 98195 fxia@u.washington.edu or electronic editions of highly respected journals. Included in many papers are snippets of language data that are included as part of this linguistic discourse. The language data is often represented as Interlinear Glossed Text (IGT), an example of which is shown in (1). (1) Rhoddodd yr athro lyfr i’r bachgen ddoe gave-3sg the teacher book to-the boy yesterday “The teacher gave a book to the boy yesterday” (Bailyn, 2001) The canonical form of an IGT consists of three lines: a language line for the language in question, a gloss line that contains a word-by-word or morpheme-bymorpheme gloss, and a translation line, usually in English. The grammatical annotations such as 3sg on the gloss line are called grams. 2.2 The Original ODIN System ODIN was built in three steps. First, linguistic documents that may contain instances of IGT are harvested from the Web using metacrawls. Metacrawling involves throwing queries against an existing search engine, such as Google and Live Search. Second, IGT instances in the retri</context>
</contexts>
<marker>Bailyn, 2001</marker>
<rawString>John Frederick Bailyn. 2001. Inversion, Dislocation and Optionality in Russian. In Gerhild Zybatow, editor, Current Issues in Formal Slavic Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W B Cavnar</author>
<author>J M Trenkle</author>
</authors>
<title>N-gram-based text categorization.</title>
<date>1994</date>
<booktitle>In Proceedings of Third Annual Symposium on Document Analysis and Information Retrieval,</booktitle>
<pages>161--175</pages>
<location>Las Vegas,</location>
<contexts>
<context position="3977" citStr="Cavnar and Trenkle, 1994" startWordPosition="643" endWordPosition="646">le and Live Search. Second, IGT instances in the retrieved documents are identified using regular expression “templates”, effectively looking for text that resembles IGT. An example RegEx template is shown in (2), which matches any three-line instance (e.g., the IGT instance in (1)) such that the first line starts with an example number (e.g., (1)) and the third line starts with a quotation mark. (2) \s*\(\d+\).*\n \s*.*\n \s*\[‘’&amp;quot;].*\n The third step is to determine the language of the language line in an IGT instance. Our original work in language ID relied on TextCat, an implementation of (Cavnar and Trenkle, 1994). As of January 2008 (the time we started our current work), ODIN had 41,581 instances of IGT for 731 languages extracted from nearly 3,000 documents.1 1For a thorough discussion about how ODIN was originally constructed, see (Lewis, 2006). Proceedings of the EACL 2009 Demonstrations Session, pages 41–44, Athens, Greece, 3 April 2009. c�2009 Association for Computational Linguistics 41 2.3 Enriching IGT data Since the language line in IGT data does not come with annotations (e.g., POS tags, phrase structures), Xia and Lewis (2007) proposed to enrich the original IGT and then extract syntactic </context>
</contexts>
<marker>Cavnar, Trenkle, 1994</marker>
<rawString>W. B. Cavnar and J. M. Trenkle. 1994. N-gram-based text categorization. In Proceedings of Third Annual Symposium on Document Analysis and Information Retrieval, pages 161–175, Las Vegas, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph H Greenberg</author>
</authors>
<title>Some universals of grammar with particular reference to the order of meaningful elements.</title>
<date>1963</date>
<booktitle>Universals of Language,</booktitle>
<pages>73--113</pages>
<editor>In Joseph H. Greenberg, editor,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="9521" citStr="Greenberg, 1963" startWordPosition="1562" endWordPosition="1564">put of the algorithm. For instance, the third row says that 122 languages each have 100 to 999 IGT instances, and the 40,260 instances in this bin account for 21.27% of all instances in ODIN.5 3.3 Answering typological questions Linguistic typology is the study of the classification of languages, where a typology is an organization of languages by an enumerated list of logically possible types, most often identified by one or more structural features. One of the most well known and well studied typological types, or parameters, is that of canonical word order, made famous by Joseph Greenberg (Greenberg, 1963). 5Some IGTs are marked by the authors of the crawled documents as ungrammatical (usually with an asterisk “*” at the beginning of the language line). Those IGTs are kept in ODIN too because they could be useful to other linguists, the same reason that they were included in the original documents. 42 In (Lewis and Xia, 2008), we described a means for automatically discovering the answers to a number of computationally salient typological questions, such as the canonical order of constituents (e.g., sentential word order, order of constituents in noun phrases) or the existence of particular con</context>
</contexts>
<marker>Greenberg, 1963</marker>
<rawString>Joseph H. Greenberg. 1963. Some universals of grammar with particular reference to the order of meaningful elements. In Joseph H. Greenberg, editor, Universals of Language, pages 73–113. MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William D Lewis</author>
<author>Fei Xia</author>
</authors>
<title>Automatically Identifying Computationally Relevant Typological Features.</title>
<date>2008</date>
<booktitle>In Proceedings of The Third International Joint Conference on Natural Language Processing (IJCNLP),</booktitle>
<location>Hyderabad,</location>
<contexts>
<context position="9847" citStr="Lewis and Xia, 2008" startWordPosition="1619" endWordPosition="1622">rganization of languages by an enumerated list of logically possible types, most often identified by one or more structural features. One of the most well known and well studied typological types, or parameters, is that of canonical word order, made famous by Joseph Greenberg (Greenberg, 1963). 5Some IGTs are marked by the authors of the crawled documents as ungrammatical (usually with an asterisk “*” at the beginning of the language line). Those IGTs are kept in ODIN too because they could be useful to other linguists, the same reason that they were included in the original documents. 42 In (Lewis and Xia, 2008), we described a means for automatically discovering the answers to a number of computationally salient typological questions, such as the canonical order of constituents (e.g., sentential word order, order of constituents in noun phrases) or the existence of particular constituents in a language (e.g., definite or indefinite determiners). In these experiments, we tested not only the potential of IGT to provide knowledge that could be useful to NLP, but also for IGT to overcome biases inherent to the opportunistic nature of its collection: (1) What we call the IGT-bias, that is, the bias produ</context>
</contexts>
<marker>Lewis, Xia, 2008</marker>
<rawString>William D. Lewis and Fei Xia. 2008. Automatically Identifying Computationally Relevant Typological Features. In Proceedings of The Third International Joint Conference on Natural Language Processing (IJCNLP), Hyderabad, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William D Lewis</author>
</authors>
<title>ODIN: A Model for Adapting and Enriching Legacy Infrastructure.</title>
<date>2006</date>
<booktitle>In Proceedings of the eHumanities Workshop,</booktitle>
<location>Amsterdam. Held</location>
<contexts>
<context position="1947" citStr="Lewis, 2006" startWordPosition="311" endWordPosition="312">onal annotation and structure, making the resource useful to the Computational Linguistic audience. In this paper, after a brief discussion of the previous work on ODIN, we report our recent work on extending ODIN by applying machine learning methods to the task of data extraction and language identification, and on using ODIN to “discover” linguistic knowledge. Then we outline a plan for the demo presentation. 2 Background and Previous work on ODIN ODIN is a collection of Interlinear Glossed Text (IGT) harvested from scholarly documents. In this section, we describe the original ODIN system (Lewis, 2006), and the IGT enrichment algorithm (Xia and Lewis, 2007). These serve as the starting point for our current work, which will be discussed in the next section. 2.1 Interlinear Glossed Text (IGT) In recent years, a large part of linguistic scholarly discourse has migrated to the Web, whether it be in the form of papers informally posted to scholars’ websites, Fei Xia University of Washington Seattle, WA 98195 fxia@u.washington.edu or electronic editions of highly respected journals. Included in many papers are snippets of language data that are included as part of this linguistic discourse. The </context>
<context position="4216" citStr="Lewis, 2006" startWordPosition="685" endWordPosition="686">(e.g., the IGT instance in (1)) such that the first line starts with an example number (e.g., (1)) and the third line starts with a quotation mark. (2) \s*\(\d+\).*\n \s*.*\n \s*\[‘’&amp;quot;].*\n The third step is to determine the language of the language line in an IGT instance. Our original work in language ID relied on TextCat, an implementation of (Cavnar and Trenkle, 1994). As of January 2008 (the time we started our current work), ODIN had 41,581 instances of IGT for 731 languages extracted from nearly 3,000 documents.1 1For a thorough discussion about how ODIN was originally constructed, see (Lewis, 2006). Proceedings of the EACL 2009 Demonstrations Session, pages 41–44, Athens, Greece, 3 April 2009. c�2009 Association for Computational Linguistics 41 2.3 Enriching IGT data Since the language line in IGT data does not come with annotations (e.g., POS tags, phrase structures), Xia and Lewis (2007) proposed to enrich the original IGT and then extract syntactic information (e.g., context-free rules) to bootstrap NLP tools such as POS taggers and parsers. The enrichment algorithm has three steps: (1) parse the English translation with an English parser, (2) align the language line and the English </context>
</contexts>
<marker>Lewis, 2006</marker>
<rawString>William D. Lewis. 2006. ODIN: A Model for Adapting and Enriching Legacy Infrastructure. In Proceedings of the eHumanities Workshop, Amsterdam. Held in cooperation with e-Science 2006: 2nd IEEE International Conference on e-Science and Grid Computing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Xia</author>
<author>William D Lewis</author>
</authors>
<title>Multilingual structural projection across interlinearized text.</title>
<date>2007</date>
<booktitle>In Proceedings of the North American Association of Computational Linguistics (NAACL) conference.</booktitle>
<contexts>
<context position="2003" citStr="Xia and Lewis, 2007" startWordPosition="318" endWordPosition="321">ce useful to the Computational Linguistic audience. In this paper, after a brief discussion of the previous work on ODIN, we report our recent work on extending ODIN by applying machine learning methods to the task of data extraction and language identification, and on using ODIN to “discover” linguistic knowledge. Then we outline a plan for the demo presentation. 2 Background and Previous work on ODIN ODIN is a collection of Interlinear Glossed Text (IGT) harvested from scholarly documents. In this section, we describe the original ODIN system (Lewis, 2006), and the IGT enrichment algorithm (Xia and Lewis, 2007). These serve as the starting point for our current work, which will be discussed in the next section. 2.1 Interlinear Glossed Text (IGT) In recent years, a large part of linguistic scholarly discourse has migrated to the Web, whether it be in the form of papers informally posted to scholars’ websites, Fei Xia University of Washington Seattle, WA 98195 fxia@u.washington.edu or electronic editions of highly respected journals. Included in many papers are snippets of language data that are included as part of this linguistic discourse. The language data is often represented as Interlinear Glosse</context>
<context position="4513" citStr="Xia and Lewis (2007)" startWordPosition="728" endWordPosition="731">rk in language ID relied on TextCat, an implementation of (Cavnar and Trenkle, 1994). As of January 2008 (the time we started our current work), ODIN had 41,581 instances of IGT for 731 languages extracted from nearly 3,000 documents.1 1For a thorough discussion about how ODIN was originally constructed, see (Lewis, 2006). Proceedings of the EACL 2009 Demonstrations Session, pages 41–44, Athens, Greece, 3 April 2009. c�2009 Association for Computational Linguistics 41 2.3 Enriching IGT data Since the language line in IGT data does not come with annotations (e.g., POS tags, phrase structures), Xia and Lewis (2007) proposed to enrich the original IGT and then extract syntactic information (e.g., context-free rules) to bootstrap NLP tools such as POS taggers and parsers. The enrichment algorithm has three steps: (1) parse the English translation with an English parser, (2) align the language line and the English translation via the gloss line, and (3) project syntactic structure from English to the language line. The algorithm was tested on 538 IGTs from seven languages and the word alignment accuracy was 94.1% and projection accuracy (i.e., the percentage of correct links in the projected dependency str</context>
</contexts>
<marker>Xia, Lewis, 2007</marker>
<rawString>Fei Xia and William D. Lewis. 2007. Multilingual structural projection across interlinearized text. In Proceedings of the North American Association of Computational Linguistics (NAACL) conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Xia</author>
<author>William D Lewis</author>
</authors>
<title>Repurposing Theoretical Linguistic Data for Tool Development and Search.</title>
<date>2008</date>
<booktitle>In Proceedings of The Third International Joint Conference on Natural Language Processing (IJCNLP),</booktitle>
<location>Hyderabad,</location>
<contexts>
<context position="7262" citStr="Xia and Lewis, 2008" startWordPosition="1176" endWordPosition="1179">, two spans match iff they overlap) is 95.4%.4 In comparison, the F-score of the RegEx approach on the same test set is 51.4% for exact match and 74.6% for partial match. 2By constructions, we mean linguistically salient constructions, such as actives, passives, relative clauses, inverted word orders, etc., in particular those we feel would be of the most benefit to linguists and computational linguists alike. 3The tagset extends the standard BIO tagging scheme. 4The result is produced by a Maximum Entropy learner. The results by SVM and CRF learners are similar. The details were reported in (Xia and Lewis, 2008). Table 1: The language distribution of the IGTs in ODIN Range of # of # of IGT % of IGT IGT instances languages instances instances &gt; 10000 3 36,691 19.39 1000-9999 37 97,158 51.34 100-999 122 40,260 21.27 10-99 326 12,822 6.78 1-9 838 2,313 1.22 total 1326 189,244 100 3.2 Language ID The language ID task here is very different from a typical language ID task. For instance, the number of languages in ODIN is more than a thousand and could potentially reach several thousand as more data is added. Furthermore, for most languages in ODIN, our training data contains few to no instances of IGT. Be</context>
</contexts>
<marker>Xia, Lewis, 2008</marker>
<rawString>Fei Xia and William D. Lewis. 2008. Repurposing Theoretical Linguistic Data for Tool Development and Search. In Proceedings of The Third International Joint Conference on Natural Language Processing (IJCNLP), Hyderabad, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Xia</author>
<author>William D Lewis</author>
<author>Hoifung Poon</author>
</authors>
<title>Language ID in the Context of Harvesting Language Data off the Web. In</title>
<date>2009</date>
<booktitle>Proceedings of The 12th Conference of the European Chapter of the Association of Computational Linguistics (EACL),</booktitle>
<location>Athens, Greece,</location>
<contexts>
<context position="8625" citStr="Xia et al., 2009" startWordPosition="1411" endWordPosition="1414">ent, there are often various cues in the document (e.g., language names) that can help predict the language ID of the IGT instances. We designed a new algorithm that treats the language ID task as a pronoun resolution task, where IGT instances are “pronouns”, language names are “antecedents”, and finding the language name of an IGT is the same as linking a pronoun (i.e., the IGT) to its antecedent (i.e., the language name). The algorithm outperforms existing, general-purpose language identification algorithms significantly. The detail of the algorithm and experimental results is described in (Xia et al., 2009). Running the new IGT detection on the original three thousand ODIN documents, the number of IGT instances increases from 41,581 to 189,244. We then ran the new language ID algorithm on the IGTs, and Table 1 shows the language distribution of the IGTs in ODIN according to the output of the algorithm. For instance, the third row says that 122 languages each have 100 to 999 IGT instances, and the 40,260 instances in this bin account for 21.27% of all instances in ODIN.5 3.3 Answering typological questions Linguistic typology is the study of the classification of languages, where a typology is an</context>
</contexts>
<marker>Xia, Lewis, Poon, 2009</marker>
<rawString>Fei Xia, William D. Lewis, and Hoifung Poon. 2009. Language ID in the Context of Harvesting Language Data off the Web. In Proceedings of The 12th Conference of the European Chapter of the Association of Computational Linguistics (EACL), Athens, Greece, April.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>