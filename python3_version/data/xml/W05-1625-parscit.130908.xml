<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000103">
<title confidence="0.996799">
Answer Generation with Temporal Data Integration
</title>
<author confidence="0.775679">
V´eronique Moriceau
</author>
<affiliation confidence="0.522803">
Universit´e Paul Sabatier - IRIT
</affiliation>
<address confidence="0.846469">
31062 Toulouse cedex 09, France
</address>
<email confidence="0.997733">
moriceau@irit.fr
</email>
<sectionHeader confidence="0.995609" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999725">
In this paper, we propose an approach for con-
tent determination and surface generation of an-
swers in a question-answering system on the web.
The content determination is based on a coherence
rate which takes into account coherence with other
potential answers. Answer generation is made
through the use of classical techniques and tem-
plates and is based on a certainty degree.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999973333333333">
Search engines on the web and most of existing question-
answering systems provide the user with either a set of hyper-
links or web page extracts containing answer(s) to a question.
As provenance information (defined in [McGuinness et al.,
2004] e.g., source, date, author, etc.) is rather difficult to ob-
tain, we assume that all web pages are equally reliable. Then,
the problem the system has to solve is to generate an answer
to a question even if several possible answers are selected
by the extraction engine. For this purpose, we propose to
integrate, according to certain criteria, the different possible
answers in order to generate a single coherent answer which
take into account the diversity of answers (which can be re-
dundant, incomplete, inconsistent, etc.).
As our framework is WEBCOOP [Benamara, 2004], a co-
operative question-answering system on the web, our goal is
to generate answers in natural language which explain how
confident of the answer the user can be.
In this paper, we focus on aspects of content determination
and on the generation of answers in natural language. In the
following sections, we first present the main difficulties and a
general typology of integration mechanisms. Then we anal-
yse the content determination process in the case of answers
of type date. Finally, we present briefly a few elements about
generation of integrated answers and evaluation.
</bodyText>
<sectionHeader confidence="0.993909" genericHeader="introduction">
2 Motivations
</sectionHeader>
<bodyText confidence="0.999504">
When a user submits a question to a classical search engine
or question-answering system, he may obtain a set of poten-
tial answers which may be incoherent to some degree: we
mean by incoherent, answers that are a priori contradictory
but which can be in fact equivalent, complementary, etc. In
this case, the user may be unsastisfied because he does not
know which answer among those proposed is the correct one.
In the following sections, we present related works and a
general typology of relations between candidate answers.
</bodyText>
<sectionHeader confidence="0.891531" genericHeader="method">
2.1 Related works
</sectionHeader>
<bodyText confidence="0.999503894736842">
Most of existing systems on the web produce a set of an-
swers to a question in the form of hyperlinks or page extracts,
ranked according to a relevance score (for example, COGEX
[Moldovan et al., 2003]). Other systems also define relation-
ships between web page extracts or texts containing possi-
ble answers ([Harabagiu et al., 2004], [Radev et al., 1998]).
For example, [Webber et al., 2002] defines 4 relationships be-
tween possible answers:
equivalence: equivalent answers which entail mutually,
inclusion: one-way entailment of answers,
aggregation: answers that are mutually consistent but
not entailing, and that can be replaced by their conjunc-
tion,
alternative: answers that are inconsistent or alternatives
and that can be replaced by their disjunction.
Most of question-answering systems generate answers
which take into account neither information given by all can-
didate answers nor their inconsistency. This is the point we
focus on in the following section.
</bodyText>
<subsectionHeader confidence="0.996878">
2.2 A general typology of integration mechanisms
</subsectionHeader>
<bodyText confidence="0.999919555555556">
To better characterise our problem, we collected, via Google
or QRISTAL [QRISTAL], a corpus of around 100 question-
answer pairs in French that reflect different inconsistency
problems. We first assume that all candidate answers are po-
tentially correct. The corpus analysis enables us to define a
general typology of relations between answers. For each rela-
tion defined in [Webber et al., 2002], we identify integration
mechanisms in order to generate answers which take into ac-
count characteristics of all candidate answers.
</bodyText>
<sectionHeader confidence="0.880083" genericHeader="method">
Inclusion
</sectionHeader>
<bodyText confidence="0.969853076923077">
The inclusion relation exists if a candidate answer entails an-
other answer (for example, between concepts of candidate an-
swers linked in an ontology by the is-a or part-of relations).
For example, in Brittany and in France are correct an-
swers to the question Where is Brest? and Brittany is a part
of France. The content determination stage consists here in
choosing which answer will be proposed to the user - the
more specific, the more generic or all answers. This can be
guided by a user model, taking into account his knowledge.
Equivalence
Candidate answers which are linked by an equivalence rela-
tion are consistent and entail mutually. The corpus analysis
allows us to identify two main types of equivalence:
</bodyText>
<listItem confidence="0.963511">
(1) Lexical equivalence: synonymy, metonymy, para-
</listItem>
<bodyText confidence="0.976309666666667">
phrases, proportional series, use of acronyms or foreign
languages. For example, to the question Who killed John
Lennon?, Mark Chapman, the murderer of John Lennon and
John Lennon’s killer Mark Chapman are equivalent answers.
(2) Equivalence with inference: in a number of cases, some
common knowledge, inferences or calculation are necessary
to detect equivalence relations. For example, The A320 is 21
and The A320 has been created in 1984 are equivalent an-
swers to the question How old is the Airbus A320?.
</bodyText>
<sectionHeader confidence="0.752017" genericHeader="method">
Aggregation
</sectionHeader>
<bodyText confidence="0.954410692307692">
The aggregation relation defines a set of consistent answers
when the question accepts several different ones. In this case,
all candidate answers are potentially correct and can be inte-
grated in the form of a conjunction of all these answers. For
example, an answer to the question Where is Disneyland? can
be in Tokyo, Paris, Hong-Kong and Los Angeles.
If answers are numerical values, the integrated answer can
be given in the form of an interval, average or comparison.
Alternative
The alternative relation defines a set of inconsistent answers.
In the case of questions expecting a unique answer, only one
answer among candidates is correct. On the contrary, all can-
didates can be correct answers.
</bodyText>
<listItem confidence="0.881349347826087">
(1) A simple solution is to propose a disjunction of
candidate answers. For example, if the question When does
autumn begin? has the candidate answers Autumn begin on
September 21st and Autumn begins on September 20th, an
answer such as Autumn begins on either September 20th or
September 21st can be proposed.
(2) If candidate answers have common characteristics, it is
possible to integrate them according to these characteristics.
For example, the question When does the French music
festival take place? has the following answers June 1st 1982,
June 21st 1983, ..., June 21st 2004. Here, the extraction en-
gine selects pages containing the dates of all music festivals.
These candidate answers have day and month in common.
Consequently, an answer such as The French music festival
takes place every June 21st can be proposed.
(3) As for the aggregation relation, numerical values
can be integrated in the form of an interval, average or
comparison. For example, if the question How far is Paris
from Toulouse? has the candidate answers 713 km, 678
km and 681 km, answers such as Paris is at about 690 km
from Toulouse (average) or The distance between Paris
and Toulouse is between 678 and 713 km (interval) can be
proposed.
</listItem>
<bodyText confidence="0.99486">
In the following sections, we focus on the content deter-
mination and generation of candidate answers of type date
linked by an aggregation or alternative relation, the most
common ones.
</bodyText>
<sectionHeader confidence="0.945407" genericHeader="method">
3 Content determination
</sectionHeader>
<bodyText confidence="0.99997636">
The problem we focus on in this section is the problem of
content determination when several answers to a question of
type date are selected. We consider that candidate answers
can be in the form of date or temporal interval. A date is
defined as a vector which allows the temporal localisation of
an event. Some values of vectors can be underspecified: only
relevant values for the expected information are explicit (year,
hour, etc.). Then, an interval is a couple of dates, i.e. vectors
defining a date of beginning and a date of end.
As answers selected by the extraction engine are often in
different forms (dates or intervals or both), a first step consists
in standardizing data:
all candidate answers are in the form of an interval: this
means that a date will be in the form of an interval hav-
ing the same date of beginning and of end,
some candidate answers may be incomplete: for ex-
ample, year or date of end is missing, etc. In some
cases, unification with other candidate answers is pos-
sible. Otherwise, incomplete answers are omitted,
from the semantic point of view, all candidate answers
must be in the same system of temporal reference (for
example, because of possible different time zones).
Once all candidate answers have been standardized, aber-
rant answers are filtered out by applying classical statistical
methods. Then, the answer selection process can be applied.
</bodyText>
<subsectionHeader confidence="0.999447">
3.1 Answer selection process
</subsectionHeader>
<bodyText confidence="0.990340541666666">
Our goal is to select, among several candidate answers, the
best answer considered as the one which is the most coherent
with other answers. For this purpose, we define a coherence
rate of answers.
Let us assume that there are N candidate answers coming
from N different web pages. We consider that each candi-
date answer is a temporal interval where is the
date of beginning and the date of end of the event. Let
with be these N candidate an-
swers.
In terms of interval, we consider that the most coherent
answer is the interval which intersects the greatest number
of candidate intervals. For example, in Figure 1, we have 3
candidate answers and . They form 4 sub-intervals:
, ,and .
The interval we consider as the most coherent is
because its occurrence frequency is 3 (i.e. the number of
times it intersects the candidate answers is 3).
In order to define sub-intervals, we need to have the
bounds of the N candidate intervals. Let ,
1 N, be the set of ordered bounds of the N intervals and
let , 1 2N. Consequently, a sub-interval is in the
form of .
We now define as the occurrence frequency of the
</bodyText>
<figureCaption confidence="0.997227">
Figure 1: Sub-intervals
</figureCaption>
<bodyText confidence="0.987713466666667">
interval , i.e. the number of times intersects the N
candidate answers:
Then, the coherence rate assigned to each sub-interval
is a weighting of the occurrence frequency by the
number of candidate answers:
Selecting the interval having the highest coherence rate
is not sufficient. The answer must also have a relevant
duration. For this purpose, we construct new intervals based
on previous sub-intervals: these new ones must have a
relevant duration, at least equal to the average duration of
the N candidate answers. Let be the average duration
of candidate answers.
Then, we construct a coherent answer set composed of in-
tervals satisfying a constraint duration to which we assigned
a new coherence rate. This new rate is the average of the
coherence rates of sub-intervals composing the new one. So,
the coherent answer set is defined as:
Once this coherent answer set has been obtained, there is
still to check if the expected answer/event is a unique or an
iterative event. We consider that an event is iterative if there is
a great number of intervals of that are distant in time. Let
be the minimum time between the end of an interval and
the beginning of the following one. Let be the minimum
number of intervals that have to be distant from the others
(the parameters and depends on data granularity). Then,
an event is iterative if:
At this stage, there are two possibilities:
either the event is unique: the answer set is com-
posed of intervals of having the highest coherence
rate:
</bodyText>
<equation confidence="0.6407255">
-
1 2N-1,
</equation>
<bodyText confidence="0.999481727272727">
or the event is iterative: there may be some temporal
constraints due to the question: for example, the ques-
tion expects an event in the past or in the future, an event
in a particular year, etc. Let be the set of intervals of
satisfying the question constraints. Then, is the
set of answers/intervals (having the highest coherence
rate) which can be proposed to the user:
In this section, we proposed a method for content deter-
mination based on coherence rate in the case of answers of
type date and in particular of type interval. In the following
section, we apply this method to an example.
</bodyText>
<subsectionHeader confidence="0.991927">
3.2 Example
</subsectionHeader>
<bodyText confidence="0.999915333333333">
Let us suppose that the question When did Hugo hurricane
take place? is submitted to a question-answering system. The
following table presents the candidate answers:
</bodyText>
<table confidence="0.764866166666667">
Question When did Hugo hurricane take place?
September 16th, 1989
Candidate September 1989, from 10 to 22
Answers September 16th, 1989
September 17th, 1989
from 10th to 25th September, 1989
September 16th, 1989
September 16th, 1989
from 16th to 22nd September, 1989
September 1989, from 10 to 25
September 16th, 1989
September 16th, 1989
</table>
<bodyText confidence="0.999576066666667">
The following table presents the 11 candidate answers in
the form of interval and their respective duration (number of
days):
Question When did Hugo hurricane take place?
= [16 -9- 1989,16 -9- 1989], = 1
Candidate = [10 -9- 1989,22 -9- 1989], = 12
Answers = [16 -9- 1989,16 -9- 1989], = 1
= [17 -9- 1989,17 -9- 1989], = 1
= [10 -9- 1989,25 -9- 1989], = 15
= [16 -9- 1989,16 -9- 1989], = 1
= [16 -9- 1989,16 -9- 1989], = 1
= [16 -9- 1989,22 -9- 1989], = 6
= [10 -9- 1989,25 -9- 1989], = 15
= [16 -9- 1989,16 -9- 1989], = 1
= [16 -9- 1989,16 -9- 1989], = 1
</bodyText>
<figure confidence="0.796133222222222">
such as +
-
1 2N-1,
The ordered set of interval bounds is for example: coherence rate:
Consequently, we have (cf. Figure 2):
10-9-1989, 16-9-1989,
16-9-1989, 17-9-1989,
17-9-1989, 22-9-1989,
25-9-1989,
</figure>
<figureCaption confidence="0.999868">
Figure 2: 11 candidate answers
</figureCaption>
<bodyText confidence="0.9980896">
The coherence rates of each sub-interval are:
The average duration of candidate answers is 5 days. Now,
we construct the answer set with sub-intervals having a
duration between 5 and 6 days and we assign to them a new
Consequently, the intervals satisfying the average duration
are:
The event is non-iterative since every interval of is
contiguous to the following one. So, the answer is the
interval of having the highest coherence rate:
i.e. from September,10th to 16nd 1989.
</bodyText>
<sectionHeader confidence="0.990891" genericHeader="method">
4 Answer generation
</sectionHeader>
<bodyText confidence="0.999027153846154">
Once the most coherent answer has been elaborated, it has to
be generated in natural language. Our strategy is to couple
classical NLG techniques with generation templates.
As our framework is the cooperative system WEBCOOP, the
answer proposed to the user has to explain why this answer
has been selected. The idea is to introduce possibility degrees
to explain to the user how confident of the answer he can be.
For this purpose, we define a certainty degree of answers
which depends on several parameters:
the number of candidate answers ( ): if and the co-
herence rate of the selected answer are high, then this
means that there were not many contradictions among
candidate answers and that the answer is more certain
(as is already taken into account in the coherence rate,
only this rate is a sufficient parameter),
if the difference between the best coherence rate and
the second best one is high, then this means that the se-
lected answer is more certain.
Consequently, we define the certainty degree of the an-
swer as:
and where is the
best coherence rate and the second best one.
As and , the more tends towards
1, the more the answer is certain. Thus, we define
generation schemas for each type of answer depending on this
certainty degree. We distinguish 3 main cases:
</bodyText>
<listItem confidence="0.682608444444444">
(1) either , i.e. no answer has been selected. The
idea is to select the candidate answer which has the highest
coherence rate even if its duration is not appropriate but the
generated answer has to explain that this answer is not sure,
(2) or , i.e. the selected answer is certain,
(3) or , then the generated answer has to take into
account. If is low, the coherence rate of the selected an-
swer is very close to other rates: in this case, several answers
are potentially correct and can be proposed to the user.
</listItem>
<bodyText confidence="0.999664875">
The idea is to generate answers with different certainty de-
grees depending on: we choose to express this degree by
the use of adverbs. For this purpose, we define a lexicalisa-
tion function lex which lexicalises the selected answers and a
function lexD which lexicalises. The Table 1 presents the
different generation schemas ( is the selected answer and
the answer having the coherence rate the closest to ).
Underlined fragments are predefined texts.
</bodyText>
<table confidence="0.729850909090909">
case (1) subject lexD( , min) verb lex(A, Reg)
case (2) subject verb lex(A, Reg)
case (3) is high:
subject lexD( ,) verb lex(A, Reg)
is low: and are proposed
if is a date:
subject lexD( ,) verb lex(A, Reg)
or lex(A, Reg)
if is an interval:
subject lexD( , ) verb lex(A, Reg)
but lexD( , plus) lex(A, Reg)
</table>
<tableCaption confidence="0.998967">
Table 1: Generation schemas
</tableCaption>
<bodyText confidence="0.8880725">
Adverb intensity is represented by the following propor-
tional serie (cf. Figure 3):
</bodyText>
<figureCaption confidence="0.995648">
Figure 3: Adverb intensity
</figureCaption>
<bodyText confidence="0.969018">
Consequently, if is high, it will be lexicalised by an ad-
verb of high intensity. The second argument of the function
( or ) forces the function to lexicalise as
an adverb of lower or higher intensity than the one that would
have been used normally (case (1) and (3)).
The function has 2 arguments: the answers that have
to be generated and indicating if the event is regular or
not. Indeed, if an iterative event is regular, i.e. happens at
regular intervals (i.e. the parameter is always the same for
all answers of ), then generalisation can be made on com-
mon characteristics. For example, if = 1 year, a possible
generalisation is: X takes place every year on ....
Example 1
To the question When was Chomsky born?, the only potential
answer and its respective coherence rate is ([07-12-1928, 07-
12-1928], 1). Its certainty degree is: .
We are in case (2) so the generated answer is in the form:
subject verb lex(A, Reg).
The answer is not a regular event. Consequently, the answer
in natural language is:
Chomsky was born on December, 7th 1928.
Example 2
To the question In which year did D. Tutu receive the Nobel
Peace Prize?, the potential answers and their respective co-
herence rate are: (1931, 0.08), (1984, 0.87) and (1986, 0.04).
The answer (1984, 0.87) is selected because it has the highest
coherence rate and its certainty degree is:
We are in case (3) with a high ( ) so the generated
answer is in the form:
subject lexD( , ) verb lex(A, Reg).
The answer is not a regular event and its certainty degree is
high so the adverb intensity has to be high. Consequently, the
answer in natural language is:
D. Tutu probably received the Nobel Peace Prize in 1984.
Example 3
To the question When did the American Civil War take
place?, the potential answers and their respective coherence
rate are:
- ([01-01-1861, 09-04-1865], 0.29),
- ([12-04-1861, 09-04-1865], 0.32),
- ([17-04-1861, 09-04-1865], 0.33).
The answer ([17-04-1861, 09-04-1865], 0.33) is selected
because it has the highest coherence rate and its certainty
degree is:
We are in case (3) with a low ( ) and the answer
is an interval so the generated answer is in the form:
subject lexD( , ) verb lex(A, Reg) but
lexD( , plus) lex(A, Reg),
with = [01-01-1861, 09-04-1865] (since all other answers
have a quasi-similar coherence rate, is the interval includ-
ing all the others). The answer is not a regular event and its
certainty degree is very low so the adverb intensity has to be
very low. Consequently, the answer in natural language is:
The American Civil War possibly took place from 1861 to
April, 9th 1865 but most possibly from April, 17th 1861 to
April, 9th 1865.
In this paper, we did not detail the lexicalisation of dates
but classical lexicalisation and aggregation techniques are
applied for example to group common characteristics (from
September, 10th to 22th instead of from September, 10th to
September, 22th, etc).
</bodyText>
<sectionHeader confidence="0.999336" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.999696083333333">
We evaluate our approach by applying our answer selection
method to 72 questions expecting an answer of type date.
Among these questions, 36 questions expected an answer of
type date and 36 expected an temporal interval.
These 72 questions were submitted to QRISTAL. Applying
our answer selection process (called Cont.Det. in the follow-
ing tables), we distinguish several cases: either the proposed
answer is correct, or it is incorrect or the proposed answer is
included in the interval defining the exact date of the event or
the answer is incomplete. We note ”impossible” cases when it
is impossible to select an answer (when all candidate answers
have the same occurrence frequency).
</bodyText>
<figureCaption confidence="0.998878">
Figure 4: Evaluation on 72 questions
</figureCaption>
<bodyText confidence="0.999911055555556">
We compare the results of our content determination
method not only to QRISTAL’s results but also to the results
obtained by a ”most frequent answer” method. Our approach
obtains better results on questions expecting an answer of
type temporal interval and particularly on questions about it-
erative events (for example, When does the nextX take place?
When did the first Y happen?, ...). This is partly due to the
fact that a ”most frequent answer” method, for example, is
not able to solve temporal references.
Among the ”incorrect” answers, most errors can be ex-
plained by the fact that some incorrect candidate answers
introduce a bias in the calculation of the average duration.
A way to solve this problem is to eliminate some candidate
answers by analysing in more depth their contexts of occur-
rence. Linguistic information and semantic knowledge about
answer concepts may allow to determine if a candidate an-
swer selected by QRISTAL is appropriate or not, incomplete,
etc.
</bodyText>
<sectionHeader confidence="0.99949" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999927083333333">
In this paper, we presented an approach for content deter-
mination, based on a coherence rate, and surface genera-
tion, based on a certainty degree of answers in a question-
answering system on the web. Several future directions are
obviously considered:
analyse in more depth of the contexts of occurrence of
candidate answers in order to filter out incorrect answers
or to precise some of them. This analysis will avoid hav-
ing answers which introduce a bias in calculations,
evaluation of the quality of answers in natural language:
are adverbs sufficient to explain the certainty degree of
the answer?.
</bodyText>
<sectionHeader confidence="0.999109" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9997024">
[Benamara, 2004] F. Benamara. WEBCOOP: un syst`eme
question-r´eponse coop´eratifsur le Web. PhD Thesis, Uni-
versit´e Paul Sabatier, Toulouse, 2004.
[Chalendar et al., 2002] G. de Chalendar, T. Delmas, F.
Elkateb, O. Ferret, B. Grau, M. Hurault-Plantet, G. Il-
louz, L. Monceaux, I. Robba, A. Vilnat. The Question-
Answering system QALC at LIMSI, Experiments in using
Web and WordNet. In Proceedings of TREC 11, 2002.
[Harabagiu et al., 2004] S. Harabagiu, F. Lacatusu. Strate-
gies for Advanced Question Answering. In Proceedings
of the Workshop on Pragmatics of Question Answering
at HLT-NAACL 2004.
[McGuinness et al., 2004] D.L. McGuinness, P. Pinheiro da
Silva. Trusting Answers on the Web. New Directions in
Question-Answering, chapter 22, Mark T. Maybury (ed),
AAAI/MIT Press, 2004.
[Moldovan et al., 2003] D. Moldovan, C. Clark, S.
Harabagiu, S. Maiorano. COGEX: A Logic Prover
for Question Answering. In Proceedings of HLT-NAACL
2003.
[Radev et al., 1998] D.R. Radev, K.R. McKeown. Generat-
ing Natural Language Summaries from Multiple On-Line
Sources. Computational Linguistics, vol. 24, issue 3 -
Natural Language Generation, pp. 469 - 500, 1998.
[Webber et al. 2002] B. Webber, C. Gardent, J. Bos. Position
statement: Inference in Question Answering. In Proceed-
ings of LREC, 2002.
[QRISTAL] Question-R´eponse Int´egrant un Syst`eme de
Traitement Automatique des Langues. www.qristal.fr,
Synapse D´eveloppement, 2004.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.546023">
<title confidence="0.987037">Answer Generation with Temporal Data Integration</title>
<author confidence="0.750562">V´eronique</author>
<affiliation confidence="0.779933">Universit´e Paul Sabatier -</affiliation>
<address confidence="0.906394">31062 Toulouse cedex 09,</address>
<email confidence="0.994024">moriceau@irit.fr</email>
<abstract confidence="0.980529666666667">In this paper, we propose an approach for content determination and surface generation of answers in a question-answering system on the web. content determination is based on a takes into account coherence with other potential answers. Answer generation is made through the use of classical techniques and temand is based on a</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>F Benamara</author>
</authors>
<title>WEBCOOP: un syst`eme question-r´eponse coop´eratifsur le Web. PhD Thesis, Universit´e Paul Sabatier,</title>
<date>2004</date>
<location>Toulouse,</location>
<marker>[Benamara, 2004]</marker>
<rawString>F. Benamara. WEBCOOP: un syst`eme question-r´eponse coop´eratifsur le Web. PhD Thesis, Universit´e Paul Sabatier, Toulouse, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G de Chalendar</author>
<author>T Delmas</author>
<author>F Elkateb</author>
<author>O Ferret</author>
<author>B Grau</author>
<author>M Hurault-Plantet</author>
<author>G Illouz</author>
<author>L Monceaux</author>
<author>I Robba</author>
<author>A Vilnat</author>
</authors>
<title>The QuestionAnswering system QALC at LIMSI, Experiments in using Web and WordNet.</title>
<date>2002</date>
<booktitle>In Proceedings of TREC 11,</booktitle>
<marker>[Chalendar et al., 2002]</marker>
<rawString>G. de Chalendar, T. Delmas, F. Elkateb, O. Ferret, B. Grau, M. Hurault-Plantet, G. Illouz, L. Monceaux, I. Robba, A. Vilnat. The QuestionAnswering system QALC at LIMSI, Experiments in using Web and WordNet. In Proceedings of TREC 11, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Harabagiu</author>
<author>F Lacatusu</author>
</authors>
<title>Strategies for Advanced Question Answering.</title>
<date>2004</date>
<booktitle>In Proceedings of the Workshop on Pragmatics of Question Answering at HLT-NAACL</booktitle>
<marker>[Harabagiu et al., 2004]</marker>
<rawString>S. Harabagiu, F. Lacatusu. Strategies for Advanced Question Answering. In Proceedings of the Workshop on Pragmatics of Question Answering at HLT-NAACL 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D L McGuinness</author>
<author>P Pinheiro da Silva</author>
</authors>
<title>Trusting Answers on the Web. New Directions</title>
<date>2004</date>
<publisher>AAAI/MIT Press,</publisher>
<note>in Question-Answering, chapter 22, Mark</note>
<marker>[McGuinness et al., 2004]</marker>
<rawString>D.L. McGuinness, P. Pinheiro da Silva. Trusting Answers on the Web. New Directions in Question-Answering, chapter 22, Mark T. Maybury (ed), AAAI/MIT Press, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Moldovan</author>
<author>C Clark</author>
<author>S Harabagiu</author>
<author>S Maiorano</author>
</authors>
<title>COGEX: A Logic Prover for Question Answering.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL</booktitle>
<marker>[Moldovan et al., 2003]</marker>
<rawString>D. Moldovan, C. Clark, S. Harabagiu, S. Maiorano. COGEX: A Logic Prover for Question Answering. In Proceedings of HLT-NAACL 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D R Radev</author>
<author>K R McKeown</author>
</authors>
<title>Generating Natural Language Summaries from Multiple On-Line Sources.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<pages>469--500</pages>
<marker>[Radev et al., 1998]</marker>
<rawString>D.R. Radev, K.R. McKeown. Generating Natural Language Summaries from Multiple On-Line Sources. Computational Linguistics, vol. 24, issue 3 -Natural Language Generation, pp. 469 - 500, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Webber</author>
<author>C Gardent</author>
<author>J Bos</author>
</authors>
<title>Position statement: Inference in Question Answering.</title>
<date>2002</date>
<booktitle>In Proceedings of LREC,</booktitle>
<marker>[Webber et al. 2002]</marker>
<rawString>B. Webber, C. Gardent, J. Bos. Position statement: Inference in Question Answering. In Proceedings of LREC, 2002.</rawString>
</citation>
<citation valid="true">
<date>2004</date>
<booktitle>Question-R´eponse Int´egrant un Syst`eme de Traitement Automatique des Langues. www.qristal.fr, Synapse D´eveloppement,</booktitle>
<contexts>
<context position="3604" citStr="[QRISTAL]" startWordPosition="572" endWordPosition="572">ually, inclusion: one-way entailment of answers, aggregation: answers that are mutually consistent but not entailing, and that can be replaced by their conjunction, alternative: answers that are inconsistent or alternatives and that can be replaced by their disjunction. Most of question-answering systems generate answers which take into account neither information given by all candidate answers nor their inconsistency. This is the point we focus on in the following section. 2.2 A general typology of integration mechanisms To better characterise our problem, we collected, via Google or QRISTAL [QRISTAL], a corpus of around 100 questionanswer pairs in French that reflect different inconsistency problems. We first assume that all candidate answers are potentially correct. The corpus analysis enables us to define a general typology of relations between answers. For each relation defined in [Webber et al., 2002], we identify integration mechanisms in order to generate answers which take into account characteristics of all candidate answers. Inclusion The inclusion relation exists if a candidate answer entails another answer (for example, between concepts of candidate answers linked in an ontolog</context>
</contexts>
<marker>[QRISTAL]</marker>
<rawString>Question-R´eponse Int´egrant un Syst`eme de Traitement Automatique des Langues. www.qristal.fr, Synapse D´eveloppement, 2004.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>