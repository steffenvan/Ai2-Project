<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.104875">
<title confidence="0.999445">
A Syllable Based Word Recognition Model
for Korean Noun Extraction
</title>
<author confidence="0.986423">
Do-Gil Lee and Hae-Chang Rim Heui-Seok Lim
</author>
<affiliation confidence="0.998122">
Dept. of Computer Science &amp; Engineering Dept. of Information &amp; Communications
Korea University Chonan University
</affiliation>
<address confidence="0.972381">
1, 5-ka, Anam-dong, Seongbuk-ku 115 AnSeo-dong
Seoul 136-701, Korea CheonAn 330-704, Korea
</address>
<email confidence="0.999669">
{dglee, rim}@nlp.korea.ac.kr limhs@infocom.chonan.ac.kr
</email>
<sectionHeader confidence="0.998603" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999955107142857">
Noun extraction is very important for
many NLP applications such as informa-
tion retrieval, automatic text classification,
and information extraction. Most of the
previous Korean noun extraction systems
use a morphological analyzer or a Part-
of-Speech (POS) tagger. Therefore, they
require much of the linguistic knowledge
such as morpheme dictionaries and rules
(e.g. morphosyntactic rules and morpho-
logical rules).
This paper proposes a new noun extrac-
tion method that uses the syllable based
word recognition model. It finds the
most probable syllable-tag sequence of
the input sentence by using automatically
acquired statistical information from the
POS tagged corpus and extracts nouns by
detecting word boundaries. Furthermore,
it does not require any labor for construct-
ing and maintaining linguistic knowledge.
We have performed various experiments
with a wide range of variables influenc-
ing the performance. The experimental
results show that without morphological
analysis or POS tagging, the proposed
method achieves comparable performance
with the previous methods.
</bodyText>
<sectionHeader confidence="0.999479" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.992401888888889">
Noun extraction is a process to find every noun in
a document (Lee et al., 2001). In Korean, Nouns
are used as the most important terms (features) that
express the document in NLP applications such as
information retrieval, document categorization, text
summarization, information extraction, and etc.
Korean is a highly agglutinative language and
nouns are included in Eojeols. An Eojeol is a sur-
face level form consisting of more than one com-
bined morpheme. Therefore, morphological anal-
ysis or POS tagging is required to extract Korean
nouns.
The previous Korean noun extraction methods are
classified into two categories: morphological analy-
sis based method (Kim and Seo, 1999; Lee et al.,
1999a; An, 1999) and POS tagging based method
(Shim et al., 1999; Kwon et al., 1999). The mor-
phological analysis based method tries to generate
all possible interpretations for a given Eojeol by
implementing a morphological analyzer or a sim-
pler method using lexical dictionaries. It may over-
generate or extract inaccurate nouns due to lexical
ambiguity and shows a low precision rate. Although
several studies have been proposed to reduce the
over-generated results of the morphological analy-
sis by using exclusive information (Lim et al., 1995;
Lee et al., 2001), they cannot completely resolve the
ambiguity.
The POS tagging based method chooses the most
probable analysis among the results produced by the
morphological analyzer. Due to the resolution of the
ambiguities, it can obtain relatively accurate results.
But it also suffers from errors not only produced by a
POS tagger but also triggered by the preceding mor-
phological analyzer.
Furthermore, both methods have serious deficien-
</bodyText>
<figure confidence="0.996764052631579">
`(neun)
MT(Cheol-Su)
`(neun)
MT(Cheol-Su)
z(deul)
z(eul)
5E!(bo)
(ass)
Q(da)
morpheme
14o�(sa-lam)
MT`(Cheol-Su-neun)
14o�zz(sa-lam-deul-eul)
WQ(bwass-da)
WQ(bwass-da)
eojeol
word
14ofa(sa-lam-deul)
z(eul)
</figure>
<figureCaption confidence="0.999997">
Figure 1: Constitution of the sentence “ TL At&apos;-������ -�kut(Cheol-Su saw the persons)”
</figureCaption>
<bodyText confidence="0.999806482758621">
cies in that they require considerable manual la-
bor to construct and maintain linguistic knowledge
and suffer from the unknown word problem. If
a morphological analyzer fails to recognize an un-
known noun in an unknown Eojeol, the POS tagger
would never extract the unknown noun. Although
the morphological analyzer properly recognizes the
unknown noun, it would not be extracted due to the
sparse data problem.
This paper proposes a new noun extraction
method that uses a syllable based word recognition
model. The proposed method does not require labor
for constructing and maintaining linguistic knowl-
edge and it can also alleviate the unknown word
problem or the sparse data problem. It finds the most
probable syllable-tag sequence of the input sentence
by using statistical information and extracts nouns
by detecting the word boundaries. The statistical in-
formation is automatically acquired from a POS an-
notated corpus and the word boundary can be de-
tected by using an additional tag to represent the
boundary of a word.
This paper is organized as follows. In Section 2,
the notion of word is defined. Section 3 presents
the syllable based word recognition model. Section
4 describes the method of constructing the training
data from existing POS tagged corpora. Section 5
discusses experimental results. Finally, Section 6
concludes the paper.
</bodyText>
<sectionHeader confidence="0.957507" genericHeader="method">
2 A new definition of word
</sectionHeader>
<bodyText confidence="0.999881260869565">
Korean spacing unit is an Eojeol, which is delimited
by whitespace, as with word in English. In Korean,
an Eojeol is made up of one or more words, and a
word is made up of one or more morphemes. Figure
1 represents the relationships among morphemes,
words, and Eojeols with an example sentence. Syl-
lables are delimited by a hyphen in the figure.
All of the previous noun extraction methods re-
gard a morpheme as a processing unit. In order to
extract nouns, nouns in a given Eojeol should be
segmented. To do this, the morphological analysis
has been used, but it requires complicated processes
because of the surface forms caused by various mor-
phological phenomena such as irregular conjugation
of verbs, contraction, and elision. Most of the mor-
phological phenomena occur at the inside of a mor-
pheme or the boundaries between morphemes, not a
word. We have also observed that a noun belongs to
a morpheme as well as a word. Thus, we do not have
to do morphological analysis in the noun extraction
point of view.
In Korean linguistics, a word is defined as a mor-
pheme or a sequence of morphemes that can be used
independently. Even though a postposition is not
used independently, it is regarded as a word because
it is easily segmented from the preceding word. This
definition is rather vague for computational process-
ing. If we follow the definition of the word in lin-
guistics, it would be difficult to analyze a word like
the morphological analysis. For this reason, we de-
fine a different notion of a word.
According to our definition of a word, each un-
inflected morpheme or a sequence of successive
inflected morphemes is regarded as an individual
word. 1 By virtue of the new definition of a word,
we need not consider mismatches between the sur-
face level form and the lexical level one in recogniz-
ing words.
The example sentence “�������� ~~p��TH��� ���
L}(Cheol-Su saw the persons)” represented in Fig-
ure 1 includes six words such as “�T(Cheol-Su)”,
“L(neun)”, “A}p(sa-lam)”, “ (deul)”, “9(eul)”,
and “Y-L}(bwass-da)”. Unlike the Korean linguis-
tics, a noun suffix such as “Li:](nim)”, “!(deul)”, or
“�11�(jeog)” is also regarded as a word because it is
an uninflected morpheme.
</bodyText>
<sectionHeader confidence="0.965252" genericHeader="method">
3 Syllable based word recognition model
</sectionHeader>
<bodyText confidence="0.9994342">
A Korean syllable consists of an obligatory onset
(initial-grapheme, consonant), an obligatory peak
(nuclear grapheme, vowel), and an optional coda
(final-grapheme, consonant). In theory, the number
of syllables that can be used in Korean is the same as
the number of every combination of the graphemes.
2 Fortunately, only a fixed number of syllables is
frequently used in practice. 3 The amount of in-
formation that a Korean syllable has is larger than
that of an alphabet in English. In addition, there are
particular characteristics in Korean syllables. The
fact that words do not start with certain syllables
is one of such examples. Several attempts have
been made to use characteristics of Korean sylla-
bles. Kang (1995) used syllable information to re-
duce the over-generated results in analyzing conju-
gated forms of verbs. Syllable statistics have been
also used for automatic word spacing (Shim, 1996;
Kang and Woo, 2001; Lee et al., 2002).
The syllable based word recognition model is rep-
resented as a function P like the following equations.
It is to find the most probable syllable-tag sequence
t1,n = t1, t2, ..., tn, for a given sentence S consist-
ing of a sequence of n syllables Cl,n = C1, C2, ..., Cn.
1Korean morphemes can be classified into two types: un-
inflected morphemes having fixed word forms (such as noun,
unconjugated adjective, postposition, adverb, interjection, etc.)
and inflected morphemes having conjugated word forms (such
as a morpheme with declined or conjugated endings, predicative
postposition, etc.)
211, 172(= 19 x 21 x 28) of pure Korean syllables are pos-
sible
3Actually, 2, 457 of syllables are used in the training data,
including Korean characters and non-Korean characters (e.g. al-
phabets, digits, Chinese characters, symbols).
</bodyText>
<equation confidence="0.9987365">
P(C1,n) �ef P(t1,n I C1,n) (1)
� argmax
tl,n
n
� argmax P(ti I ti-1)P(Ci I ti)(2)
tl,n i=1
</equation>
<bodyText confidence="0.998581909090909">
Two Markov assumptions are applied in Equation
2. One is that the probability of a current syllable tag
ti conditionally depends on only the previous sylla-
ble tag. The other is that the probability of a cur-
rent syllable si conditionally depends on the current
tag. In order to reflect word spacing information in
Equation 2, which is very useful in Korean POS tag-
ging, Equation 2 is changed to Equation 3 which can
consider the word spacing information by calculat-
ing the transition probabilities like the equation used
in Kim et al. (1998).
</bodyText>
<equation confidence="0.992586666666667">
n
P(C1,n) = argmax P(ti I ti-1, h)P(Ci I ti) (3)
tl,n i=1
</equation>
<bodyText confidence="0.991848954545455">
In the equation, h becomes zero if the transition oc-
curs in the inside of an Eojeol; otherwise h is one.
Word boundaries can be detected by an additional
tag. This method has been used in some tasks such
as text chunking and named entity recognition to
represent a boundary of an element (e.g. individual
phrase or named entity). There are several possi-
ble representation schemes to do this. The simplest
one is the BIO representation scheme (Ramshaw and
Marcus, 1995), where a “B” denotes the first item of
an element and an “I” any non-initial item, and a
syllable with tag “O” is not a part of any element.
Because every syllable corresponds to one syllable
tag, “O” is not used in our task. The representation
schemes used in this paper are described in detail in
Section 4.
The probabilities in Equation 3 are estimated by
the maximum likelihood estimator (MLE) using rel-
ative frequencies in the training data. 4
The most probable sequence of syllable tags in a
sentence (a sequence of syllables) can be efficiently
computed by using the Viterbi algorithm.
</bodyText>
<footnote confidence="0.855556666666667">
4Since the MLE suffers from zero probability, to avoid zero
probability, we just assign a very low value such as 1.0x10-&apos;00
for an unseen event in the training data.
</footnote>
<tableCaption confidence="0.998199">
Table 1: Examples of syllable tagging by BI, BIS, IE, and IES representation schemes
</tableCaption>
<table confidence="0.99990675862069">
surface level lexical level BI BIS IE IES
(syllable) (morpheme/POS tag)
~~~(yak) 01e(yak-sok)/nc B-nc B-nc I-nc I-nc
y (sok) I-nc I-nc E-nc E-nc
� �(jang) ~~(so) B-nc B-nc I-nc I-nc
o1�(in) �����(jang-so)/nc I-nc I-nc E-nc E-nc
of(i)/co+ L (n)/etm B-co etm S-co etm E-co etm S-co etm
,�l(Sin) ~~(ho) B-nc B-nc I-nc I-nc
4(la) ~~~~~~~~~~(Sin-la-ho-tel)/nc I-nc I-nc I-nc I-nc
(tel) I-nc I-nc I-nc I-nc
I-nc I-nc E-nc E-nc
(keo) (keo-pi-syob)/nc B-nc B-nc I-nc I-nc
(pi) °ll(e)/jc I-nc I-nc I-nc I-nc
(syob) I-nc I-nc E-nc E-nc
Oil(e) B-jc S-jc E-jc S-jc
;11(Jai) ���(Ok) B-nc B-nc I-nc I-nc
01(i) �����(Jai-Ok)/nc I-nc I-nc E-nc E-nc
01(i)/jc B-jc S-jc E-jc S-jc
�1(meon) �����(meon-jeo)/mag B-mag B-mag I-mag I-mag
��(jeo) I-mag I-mag E-mag E-mag
4(wa) °(o)/pv+0}(a)/ec B-pv ec S-pv ec E-pv ec S-pv ec
;71(gi) ������(gi-da-li)/pv+��(go)/ec B-pv ec B-pv ec I-pv ec I-pv ec
4(da) I-pv ec I-pv ec I-pv ec I-pv ec
��(li) I-pv ec I-pv ec I-pv ec I-pv ec
7(go) I-pv ec I-pv ec E-pv ec E-pv ec
�(iss) O�(iss)/px+%(eoss)/ep+V+(da)/ef B-px ef B-px ef I-px ef I-px ef
%(eoss) ./s I-px ef I-px ef I-px ef I-px ef
4(da) I-px ef I-px ef E-px ef E-px ef
. B-s S-s E-s S-s
</table>
<bodyText confidence="0.997884">
Given a sequence of syllables and syllable tags,
it is straightforward to obtain the corresponding se-
quence of words and word tags. Among the words
recognized through this process, we can extract
nouns by just selecting words tagged as nouns. 5
</bodyText>
<sectionHeader confidence="0.894153" genericHeader="method">
4 Constructing training data
</sectionHeader>
<bodyText confidence="0.998207583333333">
Our model is a supervised learning approach, so it
requires a training data. Because the existing Korean
POS tagged corpora are annotated by a morpheme
level, we cannot use them as a training data without
converting the data suitable for the word recognition
model. The corpus can be modified through the fol-
lowing steps:
Step 1 For a given Eojeol, segment word bound-
aries and assign word tags to each word.
Step 2 For each separated word, assign the word tag
to each syllable in the word according to one of
the representations.
</bodyText>
<footnote confidence="0.929257666666667">
5For the purpose of noun extraction, we only select com-
mon nouns here (tagged as “nc” or “NC”) among other kinds of
nouns.
</footnote>
<bodyText confidence="0.9961522">
In step 1, word boundaries are identified by using
the information of an uninflected morpheme and a
sequence of successive inflected morphemes. An
uninflected morpheme becomes one word and its
tag is assigned to the morpheme’s tag. Successive
inflected morphemes form a word and the combined
form of the first and the last morpheme’s tag repre-
sents its tag. For example, the morpheme-unit POS
tagged form of the Eojeol “�,t L}(gass-eoss-da)”
is “7}(ga)/pv+5�(ass)/ep+V(eoss)/ep+L}(da)/ef”,
and all of them are inflected morphemes. Hence,
the Eojeol “�,t L}(gass-eoss-da)” becomes one
word and its tag is represented as “pv ef” by using
the first morpheme’s tag (“pv”) and the last one’s
(“ef”).
In step 2, a syllable tag is assigned to each of syl-
lables forming a word. The syllable tag should ex-
press not only POS tag but also the boundary of the
word. In order to detect the word boundaries, we use
the following four representation schemes:
BI representation scheme Assign “B” tag to the
first syllable of a word, and “I” tag to the others.
BIS representation scheme Assign “S” tag to a
syllable which forms a word, and other tags
(“B” and “I”) are the same as “BI” represen-
tation scheme.
IE representation scheme Assign “E” tag to the
last syllable of a word, and “I” tag to the others.
IES representation scheme Assign “S” tag to a
syllable which forms a word, and other tags
(“I” and “E”) are the same as “IE” represen-
tation scheme.
Table 1 shows an example of assigning word tag
by syllable unit to the morpheme unit POS tagged
corpus.
</bodyText>
<tableCaption confidence="0.977914">
Table 2: Description of Tagset 2 and Tagset 3
</tableCaption>
<figureCaption confidence="0.945838178571429">
Tag Description Tagset 2 Tagset 3
symbol s S
foreign word f F
common noun nc NC
bound noun nb NB
pronoun np NP
numeral nn NN
verb pv V
adjective pa A
auxiliary predicate px VX
copula co CO
general adverb mag MA
conjunctive adverb maj
adnoun mm MM
interjection ii IC
prefix xp XPN
noun-derivational suffix xsn XSN
verb-derivational suffix xsv XSV
adjective-derivational suffix xsm
case particle jc J
auxilary particle jx
conjunctive particle jj
adnominal case particle jm
prefinal ending ep EP
final ending ef EF
conjunctive ending ec EC
nominalizing ending etn ETN
adnominalizing ending etm ETM
</figureCaption>
<sectionHeader confidence="0.999625" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.988515">
5.1 Experimental environment
</subsectionHeader>
<bodyText confidence="0.999892042553192">
We used ETRI POS tagged corpus of 288,269
Eojoels for testing and the 21st Century Sejong
Project’s POS tagged corpus (Sejong corpus, for
short) for training. The Sejong corpus consists of
three different corpora acquired from 1999 to 2001.
The Sejong corpus of 1999 consists of 1.5 million
Eojeols and other two corpora have 2 million Eo-
jeols respectively. The evaluation measures for the
noun extraction task are recall, precision, and F-
measure. They measure the performance by docu-
ment and are averaged over all the test documents.
This is because noun extractors are usually used in
the fields of applications such as information re-
trieval (IR) and document categorization. We also
consider the frequency of nouns; that is, if the noun
frequency is not considered, a noun occurring twice
or more in a document is treated as other nouns oc-
curring once. From IR point of view, this takes into
account of the fact that even if a noun is extracted
just once as an index term, the document including
the term can also be retrieved.
The performance considerably depends on the
following factors: the representation schemes for
word boundary detection, the tagset, the amount of
training data, and the difference between training
data and test data.
First, we compare four different representation
schemes (BI, BIS, IE, IES) in word boundary de-
tection as explained in Section 4. We try to use the
following three kinds of tagsets in order to select the
most optimal tagset through the experiments:
Tagset 1 Simply use two tags (e.g. noun and non-
noun). This is intended to examine the syllable
characteristics; that is, which syllables tend to
belong to nouns or not.
Tagset 2 Use the tagset used in the training data
without modification. ETRI tagset used for
training is relatively smaller than that of other
tagsets. This tagset is changeable according to
the POS tagged corpus used in training.
Tagset 3 Use a simplified tagset for the purpose of
noun extraction. This tagset is simplified by
combining postpositions, adverbs, and verbal
suffixes into one tag, respectively. This tagset is
always fixed even in a different training corpus.
Tagset 2 used in Section 5.2 and Tagset 3 are rep-
resented in Table 2.
</bodyText>
<subsectionHeader confidence="0.990447">
5.2 Experimental results with similar data
</subsectionHeader>
<bodyText confidence="0.999239">
We divided the test data into ten parts. The perfor-
mances of the model are measured by averaging over
</bodyText>
<tableCaption confidence="0.99817">
Table 3: Experimental results of the ten-fold cross validation
</tableCaption>
<table confidence="0.998367928571429">
without considering frequency with considering frequency
Precision Recall F-measure Precision Recall F-measure
BI-1 72.37 83.61 77.58 74.61 82.47 78.34
BI-2 85.99 92.30 89.03 88.96 90.42 89.69
BI-3 84.85 91.20 87.90 87.56 89.55 88.54
BIS-1 78.50 83.53 80.93 80.36 83.99 82.13
BIS-2 88.15 92.34 90.19 90.65 91.58 91.11
BIS-3 86.92 91.07 88.94 89.27 90.62 89.94
IE-1 73.21 81.38 77.07 75.11 81.04 77.96
IE-2 85.12 91.54 88.21 88.37 90.34 89.34
IE-3 83.28 89.70 86.37 86.54 88.80 87.65
IES-1 78.07 82.69 80.31 79.54 83.08 81.27
IES-2 87.30 92.18 89.67 90.05 91.48 90.76
IES-3 85.80 90.79 88.22 88.46 90.47 89.45
</table>
<figureCaption confidence="0.98729575">
Figure 2: Changes of F-measure according to tagsets
and representation schemes
Figure 3: Changes of F-measure according to the
size of training data
</figureCaption>
<bodyText confidence="0.998630888888889">
the ten test sets in the 10-fold cross-validation exper-
iment. Table 3 shows experimental results according
to each representation scheme and tagset. In the first
column, each number denotes the tagset used. When
it comes to the issue of frequency, the cases of con-
sidering frequency are better for precision but worse
for recall, and better for F-measure. The representa-
tion schemes using single syllable information (e.g.
“BIS”, “IES”) are better than other representation
schemes (e.g. “BI”, “IE”). Contrary to our expec-
tation, the results of Tagset 2 consistently outper-
form other tagsets. The results of Tagset 1 are not
as good as other tagsets because of the lack of the
syntactic context. Nevertheless, the results reflect
the usefulness of the syllable based processing. The
changes of the F-measure according to the tagsets
and the representation schemes reflecting frequency
are shown in Figure 2.
</bodyText>
<subsectionHeader confidence="0.985503">
5.3 Experimental results with different data
</subsectionHeader>
<bodyText confidence="0.9996649">
To show the influence of the difference between the
training data and the test data, we have performed
the experiments on the Sejong corpus as a training
data and the entire ETRI corpus as a test data. Table
4 shows the experimental results on all of the three
training data. Although more training data are used
in this experiment, the results of Table 3 shows bet-
ter outcomes. Like other POS tagging models, this
indicates that our model is dependent on the text do-
main.
</bodyText>
<tableCaption confidence="0.996953">
Table 4: Experimental results of Sejong corpus (from 1999 to 2001)
</tableCaption>
<table confidence="0.999392571428571">
without considering frequency with considering frequency
Precision Recall F-measure Precision Recall F-measure
BI-1 71.91 83.92 77.45 73.57 82.95 77.98
BI-2 85.38 89.96 87.61 87.19 88.26 87.72
BI-3 83.36 89.17 86.17 85.12 87.39 86.24
BIS-1 76.77 82.60 79.58 78.40 83.16 80.71
BIS-2 87.66 90.41 89.01 88.75 89.75 89.25
BIS-3 86.02 88.89 87.43 87.10 88.41 87.75
IE-1 70.82 79.97 75.12 72.67 79.64 75.99
IE-2 84.18 89.23 86.63 85.99 87.83 86.90
IE-3 82.01 87.67 84.74 83.79 86.57 85.16
IES-1 76.19 81.84 78.91 77.31 82.32 79.74
IES-2 86.41 89.33 87.85 87.66 88.75 88.20
IES-3 84.45 88.28 86.33 85.89 87.96 86.91
</table>
<tableCaption confidence="0.989902">
Table 5: Performances of other systems
</tableCaption>
<table confidence="0.9949932">
without considering frequency with considering frequency
Precision Recall F-measure Precision Recall F-measure
NE2001 84.08 91.34 87.56 87.02 89.86 88.42
KOMA 60.10 93.12 73.06 58.07 93.67 71.70
HanTag 90.54 88.68 89.60 91.77 88.58 90.15
</table>
<bodyText confidence="0.999473">
Figure 3 shows the changes of the F-measure ac-
cording to the size of the training data. In this fig-
ure, “99-2000” means 1999 corpus and 2000 cor-
pus are used, and “99-2001” means all corpora are
used as the training data. The more training data are
used, the better performance we obtained. However,
the improvement is insignificant in considering the
amount of increase of the training data.
Results reported by Lee et al. (2001) are pre-
sented in Table 5. The experiments were performed
on the same condition as that of our experiments.
NE2001, which is a system designed only to extract
nouns, improves efficiency of the general morpho-
logical analyzer by using positive and negative in-
formation about occurrences of nouns. KOMA (Lee
et al., 1999b) is a general-purpose morphological an-
alyzer. HanTag (Kim et al., 1998) is a POS tagger,
which takes the result of KOMA as input. Accord-
ing to Table 5, HanTag, which is a POS tagger, is an
optimal tool in performing noun extraction in terms
of the precision and the F-measure. Although the
best performance of our proposed model (BIS-2) is
worse than HanTag, it is better than NE2001 and
KOMA.
</bodyText>
<subsectionHeader confidence="0.949275">
5.4 Limitation
</subsectionHeader>
<bodyText confidence="0.999967833333333">
As mentioned earlier, we assume that morphologi-
cal variations do not occur at any inflected words.
However, some exceptions might occur in a col-
loquial text. For example, the lexical level forms
of two Eojeols “4(ddai)+L(neun)” and “��7N(go-
gai)+���(leul)” are changed into the surface level
forms by contractions such as “Il(ddain)” and “-!L
���(go-gail)”, respectively. Our models alone cannot
deal with these cases. Such exceptions, however, are
very rare. 6 In these experiments, we do not perform
any post-processing step to deal with such excep-
tions.
</bodyText>
<sectionHeader confidence="0.999499" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.998267567567568">
We have presented a word recognition model for ex-
tracting nouns. While the previous noun extraction
6Actually, about 0.145% of nouns in the test data belong to
these cases.
methods require morphological analysis or POS tag-
ging, our noun extraction method only uses the syl-
lable information without using any additional mor-
phological analyzer. This means that our method
does not require any dictionary or linguistic knowl-
edge. Therefore, without manual labor to construct
and maintain those resources, our method can ex-
tract nouns by using only the statistics, which can be
automatically extracted from a POS tagged corpus.
The previous noun extraction methods take a mor-
pheme as a processing unit, but we take a new notion
of word as a processing unit by considering the fact
that nouns belong to uninflected morphemes in Ko-
rean. By virtue of the new definition of a word, we
need not consider mismatches between the surface
level form and the lexical level one in recognizing
words.
We have performed various experiments with a
wide range of variables influencing the performance
such as the representation schemes for the word
boundary detection, the tag set, the amount of train-
ing data, and the difference between the training data
and the test data. Without morphological analysis or
POS tagging, the proposed method achieves compa-
rable performance compared with the previous ones.
In the future, we plan to extend the context to im-
prove the performance.
Although the word recognition model is designed
to extract nouns in this paper, the model itself is
meaningful and it can be applied to other fields such
as language modeling and automatic word spacing.
Furthermore, our study make some contributions in
the area of POS tagging research.
</bodyText>
<sectionHeader confidence="0.999473" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999761857142857">
D.-U. An. 1999. A noun extractor using connectivity
information. In Proceedings of the Morphological An-
alyzer and Tagger Evaluation Contest (MATEC 99),
pages 173–178.
S.-S. Kang and C.-W. Woo. 2001. Automatic segmenta-
tion of words using syllable bigram statistics. In Pro-
ceedings of the 6th Natural Language Processing Pa-
cific Rim Symposium, pages 729–732.
S.-S. Kang. 1995. Morphological analysis of Korean ir-
regular verbs using syllable characteristics. Journal of
the Korea Information Science Society, 22(10):1480–
1487.
N.-C. Kim and Y.-H. Seo. 1999. A Korean morpho-
logical analyzer CBKMA and a index word extractor
CBKMA/IX. In Proceedings of the MATEC 99, pages
50–59.
J.-D. Kim, H.-S. Lim, S.-Z. Lee, and H.-C. Rim. 1998.
Twoply hidden Markov model: A Korean pos tagging
model based on morpheme-unit with word-unit con-
text. Computer Processing of Oriental Languages,
11(3):277–290.
O.-W. Kwon, M.-Y. Chung, D.-W. Ryu, M.-K. Lee, and
J.-H. Lee. 1999. Korean morphological analyzer and
part-of-speech tagger based on CYK algorithm using
syllable information. In Proceedings of the MATEC
99.
J.-Y. Lee, B.-H. Shin, K.-J. Lee, J.-E. Kim, and S.-
G. Ahn. 1999a. Noun extractor based on a multi-
purpose Korean morphological engine implemented
with COM. In Proceedings of the MATEC 99, pages
167–172.
S.-Z. Lee, B.-R. Park, J.-D. Kim, W.-H. Ryu, D.-G. Lee,
and H.-C. Rim. 1999b. A predictive morphological
analyzer, a part-of-speech tagger based on joint inde-
pendence model, and a fast noun extractor. In Pro-
ceedings of the MATEC 99, pages 145–150.
D.-G. Lee, S.-Z. Lee, and H.-C. Rim. 2001. An effi-
cient method for Korean noun extraction using noun
occurrence characteristics. In Proceedings of the 6th
Natural Language Processing Pacific Rim Symposium,
pages 237–244.
D.-G. Lee, S.-Z. Lee, H.-C. Rim, and H.-S. Lim. 2002.
Automatic word spacing using hidden Markov model
for refining Korean text corpora. In Proceedings of
the 3rd Workshop on Asian Language Resources and
International Standardization, pages 51–57.
H.-S. Lim, S.-Z. Lee, and H.-C. Rim. 1995. An ef-
ficient Korean mophological analysis using exclusive
information. In Proceedings of the 1995 International
Conference on Computer Processing of Oriental Lan-
guages, pages 225–258.
Lance A. Ramshaw and Mitchell P. Marcus. 1995. Text
chunking using transformation-based learning. In Pro-
ceedings of the Third Workshop on Very Large Cor-
pora, pages 82–94.
J.-H. Shim, J.-S. Kim, J.-W. Cha, and G.-B. Lee. 1999.
Robust part-of-speech tagger using statistical and rule-
based approach. In Proceedings of the MATEC 99,
pages 60–75.
K.-S. Shim. 1996. Automated word-segmentation for
Korean using mutual information of syllables. Journal
of the Korea Information Science Society, 23(9):991–
1000.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.881033">
<title confidence="0.9930635">A Syllable Based Word Recognition Model for Korean Noun Extraction</title>
<author confidence="0.999066">Lee Rim Heui-Seok Lim</author>
<affiliation confidence="0.999916">Dept. of Computer Science &amp; Engineering Dept. of Information &amp; Communications Korea University Chonan University</affiliation>
<address confidence="0.9467145">1, 5-ka, Anam-dong, Seongbuk-ku 115 AnSeo-dong Seoul 136-701, Korea CheonAn 330-704, Korea</address>
<email confidence="0.986701">limhs@infocom.chonan.ac.kr</email>
<abstract confidence="0.999764482758621">Noun extraction is very important for many NLP applications such as information retrieval, automatic text classification, and information extraction. Most of the previous Korean noun extraction systems use a morphological analyzer or a Partof-Speech (POS) tagger. Therefore, they require much of the linguistic knowledge such as morpheme dictionaries and rules (e.g. morphosyntactic rules and morphological rules). This paper proposes a new noun extraction method that uses the syllable based word recognition model. It finds the most probable syllable-tag sequence of the input sentence by using automatically acquired statistical information from the POS tagged corpus and extracts nouns by detecting word boundaries. Furthermore, it does not require any labor for constructing and maintaining linguistic knowledge. We have performed various experiments with a wide range of variables influencing the performance. The experimental results show that without morphological analysis or POS tagging, the proposed method achieves comparable performance with the previous methods.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D-U An</author>
</authors>
<title>A noun extractor using connectivity information.</title>
<date>1999</date>
<booktitle>In Proceedings of the Morphological Analyzer and Tagger Evaluation Contest (MATEC 99),</booktitle>
<pages>173--178</pages>
<contexts>
<context position="2181" citStr="An, 1999" startWordPosition="316" endWordPosition="317">e used as the most important terms (features) that express the document in NLP applications such as information retrieval, document categorization, text summarization, information extraction, and etc. Korean is a highly agglutinative language and nouns are included in Eojeols. An Eojeol is a surface level form consisting of more than one combined morpheme. Therefore, morphological analysis or POS tagging is required to extract Korean nouns. The previous Korean noun extraction methods are classified into two categories: morphological analysis based method (Kim and Seo, 1999; Lee et al., 1999a; An, 1999) and POS tagging based method (Shim et al., 1999; Kwon et al., 1999). The morphological analysis based method tries to generate all possible interpretations for a given Eojeol by implementing a morphological analyzer or a simpler method using lexical dictionaries. It may overgenerate or extract inaccurate nouns due to lexical ambiguity and shows a low precision rate. Although several studies have been proposed to reduce the over-generated results of the morphological analysis by using exclusive information (Lim et al., 1995; Lee et al., 2001), they cannot completely resolve the ambiguity. The </context>
</contexts>
<marker>An, 1999</marker>
<rawString>D.-U. An. 1999. A noun extractor using connectivity information. In Proceedings of the Morphological Analyzer and Tagger Evaluation Contest (MATEC 99), pages 173–178.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S-S Kang</author>
<author>C-W Woo</author>
</authors>
<title>Automatic segmentation of words using syllable bigram statistics.</title>
<date>2001</date>
<booktitle>In Proceedings of the 6th Natural Language Processing Pacific Rim Symposium,</booktitle>
<pages>729--732</pages>
<contexts>
<context position="7982" citStr="Kang and Woo, 2001" startWordPosition="1251" endWordPosition="1254">tunately, only a fixed number of syllables is frequently used in practice. 3 The amount of information that a Korean syllable has is larger than that of an alphabet in English. In addition, there are particular characteristics in Korean syllables. The fact that words do not start with certain syllables is one of such examples. Several attempts have been made to use characteristics of Korean syllables. Kang (1995) used syllable information to reduce the over-generated results in analyzing conjugated forms of verbs. Syllable statistics have been also used for automatic word spacing (Shim, 1996; Kang and Woo, 2001; Lee et al., 2002). The syllable based word recognition model is represented as a function P like the following equations. It is to find the most probable syllable-tag sequence t1,n = t1, t2, ..., tn, for a given sentence S consisting of a sequence of n syllables Cl,n = C1, C2, ..., Cn. 1Korean morphemes can be classified into two types: uninflected morphemes having fixed word forms (such as noun, unconjugated adjective, postposition, adverb, interjection, etc.) and inflected morphemes having conjugated word forms (such as a morpheme with declined or conjugated endings, predicative postpositi</context>
</contexts>
<marker>Kang, Woo, 2001</marker>
<rawString>S.-S. Kang and C.-W. Woo. 2001. Automatic segmentation of words using syllable bigram statistics. In Proceedings of the 6th Natural Language Processing Pacific Rim Symposium, pages 729–732.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S-S Kang</author>
</authors>
<title>Morphological analysis of Korean irregular verbs using syllable characteristics.</title>
<date>1995</date>
<journal>Journal of the Korea Information Science Society,</journal>
<volume>22</volume>
<issue>10</issue>
<pages>1487</pages>
<contexts>
<context position="7780" citStr="Kang (1995)" startWordPosition="1221" endWordPosition="1222">eme, vowel), and an optional coda (final-grapheme, consonant). In theory, the number of syllables that can be used in Korean is the same as the number of every combination of the graphemes. 2 Fortunately, only a fixed number of syllables is frequently used in practice. 3 The amount of information that a Korean syllable has is larger than that of an alphabet in English. In addition, there are particular characteristics in Korean syllables. The fact that words do not start with certain syllables is one of such examples. Several attempts have been made to use characteristics of Korean syllables. Kang (1995) used syllable information to reduce the over-generated results in analyzing conjugated forms of verbs. Syllable statistics have been also used for automatic word spacing (Shim, 1996; Kang and Woo, 2001; Lee et al., 2002). The syllable based word recognition model is represented as a function P like the following equations. It is to find the most probable syllable-tag sequence t1,n = t1, t2, ..., tn, for a given sentence S consisting of a sequence of n syllables Cl,n = C1, C2, ..., Cn. 1Korean morphemes can be classified into two types: uninflected morphemes having fixed word forms (such as no</context>
</contexts>
<marker>Kang, 1995</marker>
<rawString>S.-S. Kang. 1995. Morphological analysis of Korean irregular verbs using syllable characteristics. Journal of the Korea Information Science Society, 22(10):1480– 1487.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N-C Kim</author>
<author>Y-H Seo</author>
</authors>
<title>A Korean morphological analyzer CBKMA and a index word extractor CBKMA/IX.</title>
<date>1999</date>
<booktitle>In Proceedings of the MATEC 99,</booktitle>
<pages>50--59</pages>
<contexts>
<context position="2151" citStr="Kim and Seo, 1999" startWordPosition="308" endWordPosition="311">Lee et al., 2001). In Korean, Nouns are used as the most important terms (features) that express the document in NLP applications such as information retrieval, document categorization, text summarization, information extraction, and etc. Korean is a highly agglutinative language and nouns are included in Eojeols. An Eojeol is a surface level form consisting of more than one combined morpheme. Therefore, morphological analysis or POS tagging is required to extract Korean nouns. The previous Korean noun extraction methods are classified into two categories: morphological analysis based method (Kim and Seo, 1999; Lee et al., 1999a; An, 1999) and POS tagging based method (Shim et al., 1999; Kwon et al., 1999). The morphological analysis based method tries to generate all possible interpretations for a given Eojeol by implementing a morphological analyzer or a simpler method using lexical dictionaries. It may overgenerate or extract inaccurate nouns due to lexical ambiguity and shows a low precision rate. Although several studies have been proposed to reduce the over-generated results of the morphological analysis by using exclusive information (Lim et al., 1995; Lee et al., 2001), they cannot complete</context>
</contexts>
<marker>Kim, Seo, 1999</marker>
<rawString>N.-C. Kim and Y.-H. Seo. 1999. A Korean morphological analyzer CBKMA and a index word extractor CBKMA/IX. In Proceedings of the MATEC 99, pages 50–59.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J-D Kim</author>
<author>H-S Lim</author>
<author>S-Z Lee</author>
<author>H-C Rim</author>
</authors>
<title>Twoply hidden Markov model: A Korean pos tagging model based on morpheme-unit with word-unit context.</title>
<date>1998</date>
<booktitle>Computer Processing of Oriental Languages,</booktitle>
<volume>11</volume>
<issue>3</issue>
<contexts>
<context position="9457" citStr="Kim et al. (1998)" startWordPosition="1500" endWordPosition="1503">t1,n I C1,n) (1) � argmax tl,n n � argmax P(ti I ti-1)P(Ci I ti)(2) tl,n i=1 Two Markov assumptions are applied in Equation 2. One is that the probability of a current syllable tag ti conditionally depends on only the previous syllable tag. The other is that the probability of a current syllable si conditionally depends on the current tag. In order to reflect word spacing information in Equation 2, which is very useful in Korean POS tagging, Equation 2 is changed to Equation 3 which can consider the word spacing information by calculating the transition probabilities like the equation used in Kim et al. (1998). n P(C1,n) = argmax P(ti I ti-1, h)P(Ci I ti) (3) tl,n i=1 In the equation, h becomes zero if the transition occurs in the inside of an Eojeol; otherwise h is one. Word boundaries can be detected by an additional tag. This method has been used in some tasks such as text chunking and named entity recognition to represent a boundary of an element (e.g. individual phrase or named entity). There are several possible representation schemes to do this. The simplest one is the BIO representation scheme (Ramshaw and Marcus, 1995), where a “B” denotes the first item of an element and an “I” any non-in</context>
<context position="21516" citStr="Kim et al., 1998" startWordPosition="3525" endWordPosition="3528">the training data. The more training data are used, the better performance we obtained. However, the improvement is insignificant in considering the amount of increase of the training data. Results reported by Lee et al. (2001) are presented in Table 5. The experiments were performed on the same condition as that of our experiments. NE2001, which is a system designed only to extract nouns, improves efficiency of the general morphological analyzer by using positive and negative information about occurrences of nouns. KOMA (Lee et al., 1999b) is a general-purpose morphological analyzer. HanTag (Kim et al., 1998) is a POS tagger, which takes the result of KOMA as input. According to Table 5, HanTag, which is a POS tagger, is an optimal tool in performing noun extraction in terms of the precision and the F-measure. Although the best performance of our proposed model (BIS-2) is worse than HanTag, it is better than NE2001 and KOMA. 5.4 Limitation As mentioned earlier, we assume that morphological variations do not occur at any inflected words. However, some exceptions might occur in a colloquial text. For example, the lexical level forms of two Eojeols “4(ddai)+L(neun)” and “��7N(gogai)+���(leul)” are ch</context>
</contexts>
<marker>Kim, Lim, Lee, Rim, 1998</marker>
<rawString>J.-D. Kim, H.-S. Lim, S.-Z. Lee, and H.-C. Rim. 1998. Twoply hidden Markov model: A Korean pos tagging model based on morpheme-unit with word-unit context. Computer Processing of Oriental Languages, 11(3):277–290.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O-W Kwon</author>
<author>M-Y Chung</author>
<author>D-W Ryu</author>
<author>M-K Lee</author>
<author>J-H Lee</author>
</authors>
<title>Korean morphological analyzer and part-of-speech tagger based on CYK algorithm using syllable information.</title>
<date>1999</date>
<booktitle>In Proceedings of the MATEC 99.</booktitle>
<contexts>
<context position="2249" citStr="Kwon et al., 1999" startWordPosition="327" endWordPosition="330">the document in NLP applications such as information retrieval, document categorization, text summarization, information extraction, and etc. Korean is a highly agglutinative language and nouns are included in Eojeols. An Eojeol is a surface level form consisting of more than one combined morpheme. Therefore, morphological analysis or POS tagging is required to extract Korean nouns. The previous Korean noun extraction methods are classified into two categories: morphological analysis based method (Kim and Seo, 1999; Lee et al., 1999a; An, 1999) and POS tagging based method (Shim et al., 1999; Kwon et al., 1999). The morphological analysis based method tries to generate all possible interpretations for a given Eojeol by implementing a morphological analyzer or a simpler method using lexical dictionaries. It may overgenerate or extract inaccurate nouns due to lexical ambiguity and shows a low precision rate. Although several studies have been proposed to reduce the over-generated results of the morphological analysis by using exclusive information (Lim et al., 1995; Lee et al., 2001), they cannot completely resolve the ambiguity. The POS tagging based method chooses the most probable analysis among th</context>
</contexts>
<marker>Kwon, Chung, Ryu, Lee, Lee, 1999</marker>
<rawString>O.-W. Kwon, M.-Y. Chung, D.-W. Ryu, M.-K. Lee, and J.-H. Lee. 1999. Korean morphological analyzer and part-of-speech tagger based on CYK algorithm using syllable information. In Proceedings of the MATEC 99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J-Y Lee</author>
<author>B-H Shin</author>
<author>K-J Lee</author>
<author>J-E Kim</author>
<author>S-G Ahn</author>
</authors>
<title>Noun extractor based on a multipurpose Korean morphological engine implemented with COM.</title>
<date>1999</date>
<booktitle>In Proceedings of the MATEC 99,</booktitle>
<pages>167--172</pages>
<contexts>
<context position="2169" citStr="Lee et al., 1999" startWordPosition="312" endWordPosition="315">In Korean, Nouns are used as the most important terms (features) that express the document in NLP applications such as information retrieval, document categorization, text summarization, information extraction, and etc. Korean is a highly agglutinative language and nouns are included in Eojeols. An Eojeol is a surface level form consisting of more than one combined morpheme. Therefore, morphological analysis or POS tagging is required to extract Korean nouns. The previous Korean noun extraction methods are classified into two categories: morphological analysis based method (Kim and Seo, 1999; Lee et al., 1999a; An, 1999) and POS tagging based method (Shim et al., 1999; Kwon et al., 1999). The morphological analysis based method tries to generate all possible interpretations for a given Eojeol by implementing a morphological analyzer or a simpler method using lexical dictionaries. It may overgenerate or extract inaccurate nouns due to lexical ambiguity and shows a low precision rate. Although several studies have been proposed to reduce the over-generated results of the morphological analysis by using exclusive information (Lim et al., 1995; Lee et al., 2001), they cannot completely resolve the amb</context>
<context position="21443" citStr="Lee et al., 1999" startWordPosition="3514" endWordPosition="3517">s and 2000 corpus are used, and “99-2001” means all corpora are used as the training data. The more training data are used, the better performance we obtained. However, the improvement is insignificant in considering the amount of increase of the training data. Results reported by Lee et al. (2001) are presented in Table 5. The experiments were performed on the same condition as that of our experiments. NE2001, which is a system designed only to extract nouns, improves efficiency of the general morphological analyzer by using positive and negative information about occurrences of nouns. KOMA (Lee et al., 1999b) is a general-purpose morphological analyzer. HanTag (Kim et al., 1998) is a POS tagger, which takes the result of KOMA as input. According to Table 5, HanTag, which is a POS tagger, is an optimal tool in performing noun extraction in terms of the precision and the F-measure. Although the best performance of our proposed model (BIS-2) is worse than HanTag, it is better than NE2001 and KOMA. 5.4 Limitation As mentioned earlier, we assume that morphological variations do not occur at any inflected words. However, some exceptions might occur in a colloquial text. For example, the lexical level </context>
</contexts>
<marker>Lee, Shin, Lee, Kim, Ahn, 1999</marker>
<rawString>J.-Y. Lee, B.-H. Shin, K.-J. Lee, J.-E. Kim, and S.-G. Ahn. 1999a. Noun extractor based on a multipurpose Korean morphological engine implemented with COM. In Proceedings of the MATEC 99, pages 167–172.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S-Z Lee</author>
<author>B-R Park</author>
<author>J-D Kim</author>
<author>W-H Ryu</author>
<author>D-G Lee</author>
<author>H-C Rim</author>
</authors>
<title>A predictive morphological analyzer, a part-of-speech tagger based on joint independence model, and a fast noun extractor.</title>
<date>1999</date>
<booktitle>In Proceedings of the MATEC 99,</booktitle>
<pages>145--150</pages>
<contexts>
<context position="2169" citStr="Lee et al., 1999" startWordPosition="312" endWordPosition="315">In Korean, Nouns are used as the most important terms (features) that express the document in NLP applications such as information retrieval, document categorization, text summarization, information extraction, and etc. Korean is a highly agglutinative language and nouns are included in Eojeols. An Eojeol is a surface level form consisting of more than one combined morpheme. Therefore, morphological analysis or POS tagging is required to extract Korean nouns. The previous Korean noun extraction methods are classified into two categories: morphological analysis based method (Kim and Seo, 1999; Lee et al., 1999a; An, 1999) and POS tagging based method (Shim et al., 1999; Kwon et al., 1999). The morphological analysis based method tries to generate all possible interpretations for a given Eojeol by implementing a morphological analyzer or a simpler method using lexical dictionaries. It may overgenerate or extract inaccurate nouns due to lexical ambiguity and shows a low precision rate. Although several studies have been proposed to reduce the over-generated results of the morphological analysis by using exclusive information (Lim et al., 1995; Lee et al., 2001), they cannot completely resolve the amb</context>
<context position="21443" citStr="Lee et al., 1999" startWordPosition="3514" endWordPosition="3517">s and 2000 corpus are used, and “99-2001” means all corpora are used as the training data. The more training data are used, the better performance we obtained. However, the improvement is insignificant in considering the amount of increase of the training data. Results reported by Lee et al. (2001) are presented in Table 5. The experiments were performed on the same condition as that of our experiments. NE2001, which is a system designed only to extract nouns, improves efficiency of the general morphological analyzer by using positive and negative information about occurrences of nouns. KOMA (Lee et al., 1999b) is a general-purpose morphological analyzer. HanTag (Kim et al., 1998) is a POS tagger, which takes the result of KOMA as input. According to Table 5, HanTag, which is a POS tagger, is an optimal tool in performing noun extraction in terms of the precision and the F-measure. Although the best performance of our proposed model (BIS-2) is worse than HanTag, it is better than NE2001 and KOMA. 5.4 Limitation As mentioned earlier, we assume that morphological variations do not occur at any inflected words. However, some exceptions might occur in a colloquial text. For example, the lexical level </context>
</contexts>
<marker>Lee, Park, Kim, Ryu, Lee, Rim, 1999</marker>
<rawString>S.-Z. Lee, B.-R. Park, J.-D. Kim, W.-H. Ryu, D.-G. Lee, and H.-C. Rim. 1999b. A predictive morphological analyzer, a part-of-speech tagger based on joint independence model, and a fast noun extractor. In Proceedings of the MATEC 99, pages 145–150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D-G Lee</author>
<author>S-Z Lee</author>
<author>H-C Rim</author>
</authors>
<title>An efficient method for Korean noun extraction using noun occurrence characteristics.</title>
<date>2001</date>
<booktitle>In Proceedings of the 6th Natural Language Processing Pacific Rim Symposium,</booktitle>
<pages>237--244</pages>
<contexts>
<context position="1551" citStr="Lee et al., 2001" startWordPosition="217" endWordPosition="220">g sequence of the input sentence by using automatically acquired statistical information from the POS tagged corpus and extracts nouns by detecting word boundaries. Furthermore, it does not require any labor for constructing and maintaining linguistic knowledge. We have performed various experiments with a wide range of variables influencing the performance. The experimental results show that without morphological analysis or POS tagging, the proposed method achieves comparable performance with the previous methods. 1 Introduction Noun extraction is a process to find every noun in a document (Lee et al., 2001). In Korean, Nouns are used as the most important terms (features) that express the document in NLP applications such as information retrieval, document categorization, text summarization, information extraction, and etc. Korean is a highly agglutinative language and nouns are included in Eojeols. An Eojeol is a surface level form consisting of more than one combined morpheme. Therefore, morphological analysis or POS tagging is required to extract Korean nouns. The previous Korean noun extraction methods are classified into two categories: morphological analysis based method (Kim and Seo, 1999</context>
<context position="21126" citStr="Lee et al. (2001)" startWordPosition="3461" endWordPosition="3464">quency Precision Recall F-measure Precision Recall F-measure NE2001 84.08 91.34 87.56 87.02 89.86 88.42 KOMA 60.10 93.12 73.06 58.07 93.67 71.70 HanTag 90.54 88.68 89.60 91.77 88.58 90.15 Figure 3 shows the changes of the F-measure according to the size of the training data. In this figure, “99-2000” means 1999 corpus and 2000 corpus are used, and “99-2001” means all corpora are used as the training data. The more training data are used, the better performance we obtained. However, the improvement is insignificant in considering the amount of increase of the training data. Results reported by Lee et al. (2001) are presented in Table 5. The experiments were performed on the same condition as that of our experiments. NE2001, which is a system designed only to extract nouns, improves efficiency of the general morphological analyzer by using positive and negative information about occurrences of nouns. KOMA (Lee et al., 1999b) is a general-purpose morphological analyzer. HanTag (Kim et al., 1998) is a POS tagger, which takes the result of KOMA as input. According to Table 5, HanTag, which is a POS tagger, is an optimal tool in performing noun extraction in terms of the precision and the F-measure. Alth</context>
</contexts>
<marker>Lee, Lee, Rim, 2001</marker>
<rawString>D.-G. Lee, S.-Z. Lee, and H.-C. Rim. 2001. An efficient method for Korean noun extraction using noun occurrence characteristics. In Proceedings of the 6th Natural Language Processing Pacific Rim Symposium, pages 237–244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D-G Lee</author>
<author>S-Z Lee</author>
<author>H-C Rim</author>
<author>H-S Lim</author>
</authors>
<title>Automatic word spacing using hidden Markov model for refining Korean text corpora.</title>
<date>2002</date>
<booktitle>In Proceedings of the 3rd Workshop on Asian Language Resources and International Standardization,</booktitle>
<pages>51--57</pages>
<contexts>
<context position="8001" citStr="Lee et al., 2002" startWordPosition="1255" endWordPosition="1258">ed number of syllables is frequently used in practice. 3 The amount of information that a Korean syllable has is larger than that of an alphabet in English. In addition, there are particular characteristics in Korean syllables. The fact that words do not start with certain syllables is one of such examples. Several attempts have been made to use characteristics of Korean syllables. Kang (1995) used syllable information to reduce the over-generated results in analyzing conjugated forms of verbs. Syllable statistics have been also used for automatic word spacing (Shim, 1996; Kang and Woo, 2001; Lee et al., 2002). The syllable based word recognition model is represented as a function P like the following equations. It is to find the most probable syllable-tag sequence t1,n = t1, t2, ..., tn, for a given sentence S consisting of a sequence of n syllables Cl,n = C1, C2, ..., Cn. 1Korean morphemes can be classified into two types: uninflected morphemes having fixed word forms (such as noun, unconjugated adjective, postposition, adverb, interjection, etc.) and inflected morphemes having conjugated word forms (such as a morpheme with declined or conjugated endings, predicative postposition, etc.) 211, 172(</context>
</contexts>
<marker>Lee, Lee, Rim, Lim, 2002</marker>
<rawString>D.-G. Lee, S.-Z. Lee, H.-C. Rim, and H.-S. Lim. 2002. Automatic word spacing using hidden Markov model for refining Korean text corpora. In Proceedings of the 3rd Workshop on Asian Language Resources and International Standardization, pages 51–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H-S Lim</author>
<author>S-Z Lee</author>
<author>H-C Rim</author>
</authors>
<title>An efficient Korean mophological analysis using exclusive information.</title>
<date>1995</date>
<booktitle>In Proceedings of the 1995 International Conference on Computer Processing of Oriental Languages,</booktitle>
<pages>225--258</pages>
<contexts>
<context position="2710" citStr="Lim et al., 1995" startWordPosition="398" endWordPosition="401">s: morphological analysis based method (Kim and Seo, 1999; Lee et al., 1999a; An, 1999) and POS tagging based method (Shim et al., 1999; Kwon et al., 1999). The morphological analysis based method tries to generate all possible interpretations for a given Eojeol by implementing a morphological analyzer or a simpler method using lexical dictionaries. It may overgenerate or extract inaccurate nouns due to lexical ambiguity and shows a low precision rate. Although several studies have been proposed to reduce the over-generated results of the morphological analysis by using exclusive information (Lim et al., 1995; Lee et al., 2001), they cannot completely resolve the ambiguity. The POS tagging based method chooses the most probable analysis among the results produced by the morphological analyzer. Due to the resolution of the ambiguities, it can obtain relatively accurate results. But it also suffers from errors not only produced by a POS tagger but also triggered by the preceding morphological analyzer. Furthermore, both methods have serious deficien`(neun) MT(Cheol-Su) `(neun) MT(Cheol-Su) z(deul) z(eul) 5E!(bo) (ass) Q(da) morpheme 14o�(sa-lam) MT`(Cheol-Su-neun) 14o�zz(sa-lam-deul-eul) WQ(bwass-da</context>
</contexts>
<marker>Lim, Lee, Rim, 1995</marker>
<rawString>H.-S. Lim, S.-Z. Lee, and H.-C. Rim. 1995. An efficient Korean mophological analysis using exclusive information. In Proceedings of the 1995 International Conference on Computer Processing of Oriental Languages, pages 225–258.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lance A Ramshaw</author>
<author>Mitchell P Marcus</author>
</authors>
<title>Text chunking using transformation-based learning.</title>
<date>1995</date>
<booktitle>In Proceedings of the Third Workshop on Very Large Corpora,</booktitle>
<pages>82--94</pages>
<contexts>
<context position="9985" citStr="Ramshaw and Marcus, 1995" startWordPosition="1594" endWordPosition="1597">formation by calculating the transition probabilities like the equation used in Kim et al. (1998). n P(C1,n) = argmax P(ti I ti-1, h)P(Ci I ti) (3) tl,n i=1 In the equation, h becomes zero if the transition occurs in the inside of an Eojeol; otherwise h is one. Word boundaries can be detected by an additional tag. This method has been used in some tasks such as text chunking and named entity recognition to represent a boundary of an element (e.g. individual phrase or named entity). There are several possible representation schemes to do this. The simplest one is the BIO representation scheme (Ramshaw and Marcus, 1995), where a “B” denotes the first item of an element and an “I” any non-initial item, and a syllable with tag “O” is not a part of any element. Because every syllable corresponds to one syllable tag, “O” is not used in our task. The representation schemes used in this paper are described in detail in Section 4. The probabilities in Equation 3 are estimated by the maximum likelihood estimator (MLE) using relative frequencies in the training data. 4 The most probable sequence of syllable tags in a sentence (a sequence of syllables) can be efficiently computed by using the Viterbi algorithm. 4Since</context>
</contexts>
<marker>Ramshaw, Marcus, 1995</marker>
<rawString>Lance A. Ramshaw and Mitchell P. Marcus. 1995. Text chunking using transformation-based learning. In Proceedings of the Third Workshop on Very Large Corpora, pages 82–94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J-H Shim</author>
<author>J-S Kim</author>
<author>J-W Cha</author>
<author>G-B Lee</author>
</authors>
<title>Robust part-of-speech tagger using statistical and rulebased approach.</title>
<date>1999</date>
<booktitle>In Proceedings of the MATEC 99,</booktitle>
<pages>60--75</pages>
<contexts>
<context position="2229" citStr="Shim et al., 1999" startWordPosition="323" endWordPosition="326">ures) that express the document in NLP applications such as information retrieval, document categorization, text summarization, information extraction, and etc. Korean is a highly agglutinative language and nouns are included in Eojeols. An Eojeol is a surface level form consisting of more than one combined morpheme. Therefore, morphological analysis or POS tagging is required to extract Korean nouns. The previous Korean noun extraction methods are classified into two categories: morphological analysis based method (Kim and Seo, 1999; Lee et al., 1999a; An, 1999) and POS tagging based method (Shim et al., 1999; Kwon et al., 1999). The morphological analysis based method tries to generate all possible interpretations for a given Eojeol by implementing a morphological analyzer or a simpler method using lexical dictionaries. It may overgenerate or extract inaccurate nouns due to lexical ambiguity and shows a low precision rate. Although several studies have been proposed to reduce the over-generated results of the morphological analysis by using exclusive information (Lim et al., 1995; Lee et al., 2001), they cannot completely resolve the ambiguity. The POS tagging based method chooses the most probab</context>
</contexts>
<marker>Shim, Kim, Cha, Lee, 1999</marker>
<rawString>J.-H. Shim, J.-S. Kim, J.-W. Cha, and G.-B. Lee. 1999. Robust part-of-speech tagger using statistical and rulebased approach. In Proceedings of the MATEC 99, pages 60–75.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K-S Shim</author>
</authors>
<title>Automated word-segmentation for Korean using mutual information of syllables.</title>
<date>1996</date>
<journal>Journal of the Korea Information Science Society,</journal>
<volume>23</volume>
<issue>9</issue>
<pages>1000</pages>
<contexts>
<context position="7962" citStr="Shim, 1996" startWordPosition="1249" endWordPosition="1250">hemes. 2 Fortunately, only a fixed number of syllables is frequently used in practice. 3 The amount of information that a Korean syllable has is larger than that of an alphabet in English. In addition, there are particular characteristics in Korean syllables. The fact that words do not start with certain syllables is one of such examples. Several attempts have been made to use characteristics of Korean syllables. Kang (1995) used syllable information to reduce the over-generated results in analyzing conjugated forms of verbs. Syllable statistics have been also used for automatic word spacing (Shim, 1996; Kang and Woo, 2001; Lee et al., 2002). The syllable based word recognition model is represented as a function P like the following equations. It is to find the most probable syllable-tag sequence t1,n = t1, t2, ..., tn, for a given sentence S consisting of a sequence of n syllables Cl,n = C1, C2, ..., Cn. 1Korean morphemes can be classified into two types: uninflected morphemes having fixed word forms (such as noun, unconjugated adjective, postposition, adverb, interjection, etc.) and inflected morphemes having conjugated word forms (such as a morpheme with declined or conjugated endings, pr</context>
</contexts>
<marker>Shim, 1996</marker>
<rawString>K.-S. Shim. 1996. Automated word-segmentation for Korean using mutual information of syllables. Journal of the Korea Information Science Society, 23(9):991– 1000.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>