<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.998451">
On the String Translations Produced by Multi
Bottom–Up Tree Transducers
</title>
<author confidence="0.99968">
Daniel Gildea*
</author>
<affiliation confidence="0.996356">
University of Rochester
</affiliation>
<bodyText confidence="0.5269505">
Tree transducers are defined as relations between trees, but in syntax-based machine translation,
we are ultimately concerned with the relations between the strings at the yields of the input and
output trees. We examine the formal power of Multi Bottom-Up Tree Transducers from this point
of view.
</bodyText>
<sectionHeader confidence="0.995661" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999954923076923">
Many current approaches to syntax-based statistical machine translation fall under
the theoretical framework of synchronous tree substitution grammars (STSGs). Tree
substitution grammars (TSGs) generalize context-free grammars (CFGs) in that each
rule expands a nonterminal to produce an arbitrarily large tree fragment, rather than
a fragment of depth one as in a CFG. Synchronous TSGs generate tree fragments in
the source and target languages in parallel, with each rule producing a tree fragment
in either language. Systems such as that of Galley et al. (2006) extract STSG rules from
parallel bilingual text that has been automatically parsed in one language, and the STSG
nonterminals correspond to nonterminals in these parse trees. Chiang’s (2007) Hiero
system produces simpler STSGs with a single nonterminal.
STSGs have the advantage that they can naturally express many re-ordering and
restructuring operations necessary for machine translation (MT). They have the dis-
advantage, however, that they are not closed under composition (Maletti et al. 2009).
Therefore, if one wishes to construct an MT system as a pipeline of STSG operations, the
result may not be expressible as an STSG. Recently, Maletti (2010) has argued that multi
bottom–up tree transducers (MBOTs) (Lilin 1981; Arnold and Dauchet 1982; Engelfriet,
Lilin, and Maletti 2009) provide a useful representation for natural language processing
applications because they generalize STSGs, but have the added advantage of being
closed under composition. MBOTs generalize traditional bottom–up tree transducers in
that they allow transducer states to pass more than one output subtree up to subsequent
transducer operations. The number of subtrees taken by a state is called its rank. MBOTs
are linear and non-deleting; that is, operations cannot copy or delete arbitrarily large
tree fragments.
Although STSGs and MBOTs both perform operations on trees, it is important to
note that, in MT, we are primarily interested in translational relations between strings.
Tree operations such as those provided by STSGs are ultimately tools to translate a string
</bodyText>
<note confidence="0.955343">
* Computer Science Department, University of Rochester, Rochester NY 14627.
</note>
<email confidence="0.915137">
E-mail: gildea@cs.rochester.edu.
</email>
<note confidence="0.92618525">
Submission received: 3 May 2011; revised submission received:1 October 2011; accepted for publication:
28 October 2011.
© 2012 Association for Computational Linguistics
Computational Linguistics Volume 38, Number 3
</note>
<bodyText confidence="0.999940022222222">
in one natural language into a string in another. Whereas MBOTs originate in the tree
transducer literature and are defined to take a tree as input, MT systems such as those
of Galley et al. (2006) and Chiang (2007) find a parse of the source language sentence
as part of the translation process, and the decoding algorithm, introduced by Yamada
and Knight (2002), has more in common with CYK parsing than with simulating a tree
transducer.
In this article, we investigate the power of MBOTs, and of compositions of STSGs
in particular, in terms of the set of string translations that they generate. We relate
MBOTs and compositions of STSGs to existing grammatical formalisms defined on
strings through five main results, which we outline subsequently. The first four results
serve to situate general MBOTs among string formalisms, and the fifth result addresses
MBOTs resulting from compositions of STSGs in particular.
Our first result is that the translations produced by MBOTs are a subset of those
produced by linear context-free rewriting systems (LCFRSs) (Vijay-Shankar, Weir, and
Joshi 1987). LCFRS provides a very general framework that subsumes CFG, tree ad-
joining grammar (TAG; Joshi, Levy, and Takahashi 1975; Joshi and Schabes 1997), and
more complex systems, as well as synchronous context-free grammar (SCFG) (Aho and
Ullman 1972) and synchronous tree adjoining grammar (STAG) (Shieber and Schabes
1990; Schabes and Shieber 1994) in the context of translation. LCFRS allows gram-
mar nonterminals to generate more than one span in the final string; the number of
spans produced by an LCFRS nonterminal corresponds to the rank of an MBOT state.
Our second result states that the translations produced by MBOTs are equivalent to
a specific restricted form of LCFRS, which we call 1-m-LCFRS. From the construction
relating MBOTs and 1-m-LCFRSs follow results about the source and target sides of the
translations produced by MBOTs. In particular, our third result is that the translations
produced by MBOTs are context-free within the source language, and hence are strictly
less powerful than LCFRSs. This implies that MBOTs are not as general as STAGs, for
example. Similarly, MBOTs are not as general as the generalized multitext grammars
proposed for machine translation by Melamed (2003), which retain the full power of
LCFRSs in each language (Melamed, Satta, and Wellington 2004). Our fourth result
is that the output of an MBOT, when viewed as a string language, does retain the
full power of LCFRSs. This fact is mentioned by Engelfriet, Lilin, and Maletti (2009,
page 586), although no explicit construction is given.
Our final result specifically addresses the string translations that result from com-
positions of STSGs, with the goal of better understanding the complexity of using such
compositions in machine translation systems. We show that the translations produced
by compositions of STSGs are more powerful than those produced by single STSGs,
or, equivalently, by SCFGs. Although it is known that STSGs are not closed under
composition, the proofs used previously in the literature rely on differences in tree
structure, and do not generate string translations that cannot be generated by STSG.
Our result implies that current approaches to machine translation decoding will need
to be extended to handle arbitrary compositions of STSGs.
We now turn to give definitions of MBOTs and LCFRSs in the next section, before
presenting our results on general MBOTs in Section 3, and our result on compositions
of STSGs in Section 4.
</bodyText>
<sectionHeader confidence="0.991355" genericHeader="keywords">
2. Preliminaries
</sectionHeader>
<bodyText confidence="0.9998395">
A ranked alphabet is an alphabet where each symbol has an integer rank, denoting the
number of children the symbol takes in a tree. TΣ denotes the set of trees constructed
</bodyText>
<page confidence="0.995512">
674
</page>
<note confidence="0.7918">
Gildea On the String Translations Produced by Multi Bottom–Up Tree Transducers
</note>
<bodyText confidence="0.999198">
from ranked alphabet E. We use parentheses to write trees: for example, a(b,c,d) is an
element of TE if a is an element of E with rank 3, and b, c, and d are elements of E with
rank 0. Similarly, given a ranked alphabet E and a set X, E(X) denotes the set of trees
consisting of a single symbol of E of rank k dominating a sequence of k elements from
X. We use TE(X) to denote the set of arbitrarily sized trees constructed from ranked
alphabet E having items from set X at some leaf positions. That is, TE(X) is the smallest
set such that X C TE(X) and u(t1, ... , tk) E TE(X) if u is an element of E with rank k, and
t1, ... , tk E TE(X). A multi bottom–up tree transducer (MBOT) (Lilin 1981; Arnold and
Dauchet 1982; Engelfriet, Lilin, and Maletti 2009; Maletti 2010) is a system (S, E, ∆, F, R)
where:
</bodyText>
<listItem confidence="0.92026875">
• S, E, and ∆ are ranked alphabets of states, input symbols, and output
symbols, respectively.
• F C S is a set of accepting states.
• R is a finite set of rules l -+ r where, using a set of variables X,
l E TE(S(X)), and r E S(To(X)) such that:
– every x E X that occurs in l occurs exactly once in r and vice versa,
and
– l E� S(X) or r E� S(X).
</listItem>
<bodyText confidence="0.999875521739131">
One step in an MBOT transduction is performed by rewriting a local tree fragment as
specified by one of the rules in R. We replace the fragment l with r, copying the subtree
under each variable in l to the location of the corresponding variable in r. Transducer
rules apply bottom–up from the leaves of the input tree, as shown in Figure 1, and must
terminate in an accepting state. We use underlined symbols for the transducer states,
in order to distinguish them from the symbols of the input and output alphabets.
We define a translation to be a set of string pairs, and we define the yield of an
MBOT M to be the set of string pairs (s, t) such that there exist: a tree s&apos; E TE having s
as its yield, a tree t&apos; E To having t as its yield, and a transduction from s&apos; to t&apos; that is
accepted by M. We refer to s as the source side and t as the target side of the translation.
We use the notation source(T) to denote the set of source strings of a translation T,
source(T) = Is I (s, t) E T}, and we use the notation target(T) to denote the set of target
strings. We use the notation yield(MBOT) to denote the set of translations produced
by the set of all MBOTs.
A linear context-free rewriting system (LCFRS) is defined as a system
(VN, VT, P, S), where VN is a set of nonterminal symbols, VT is a set of terminal symbols,
P is a set of productions, and S E VN is a distinguished start symbol. Associated with
each nonterminal B is a fan-out y(B), which tells how many spans B covers in the final
string. Productions p E P take the form: p : A -+ g(B1, B2,.. . , Br), where A, B1,. . . , Br E
VN, and g is a function g : (VT)ϕ(B1) x · · · x (VT)ϕ(Br) -+ (VT)ϕ(A), which specifies how
to assemble the Ei=1 y(Bi) spans of the righthand side nonterminals into the y(A)
spans of the lefthand side nonterminal. The function g must be linear and non-erasing,
which means that if we write
</bodyText>
<equation confidence="0.856965">
g((x1,1,...,x1,ϕ(B1)), ... ,(xr,1,...,xr,ϕ(Br))) = (t1,...,tϕ(A))
</equation>
<bodyText confidence="0.99931775">
the tuple of strings (t1, ... , tϕ(A)) on the right-hand side contains each variable xi,j from
the left-hand side exactly once, and may also contain terminals from VT. The process
of generating a string from an LCFRS grammar consists of first choosing, top–down, a
production to expand each nonterminal, and then, bottom–up, applying the functions
</bodyText>
<page confidence="0.995209">
675
</page>
<figure confidence="0.870552">
Computational Linguistics Volume 38, Number 3
</figure>
<figureCaption confidence="0.992506">
Figure 1
</figureCaption>
<bodyText confidence="0.97303475">
Step-by-step example of an MBOT tree transduction. The left column shows the transducer rule
applied at each step; only the last rule contains variables, whereas the others contain alphabet
symbols of rank zero at their leaves. State VPQ has rank two, and states NP and S have rank one.
associated with each production to build the string. We refer to the tree induced by top–
down nonterminal expansions of an LCFRS as the derivation tree, or sometimes simply
as a derivation.
As an example of how the LCFRS framework subsumes grammatical formalisms
such as CFG, consider the following CFG:
</bodyText>
<figure confidence="0.902609">
S AB
A a
B b
</figure>
<bodyText confidence="0.588892">
This grammar corresponds to the following grammar in LCFRS notation:
</bodyText>
<equation confidence="0.880689333333333">
S gS(A,B) gS((sA),(sB)) = (sAsB)
A gA() gA() = (a)
B gB() gB() = (b)
</equation>
<bodyText confidence="0.9992804">
Here, all nonterminals have fan-out one, reflected in the fact that all tuples defining
the productions’ functions contain just one string. Just as CFG is equivalent to LCFRS
with fan-out 1, SCFG and TAG can be represented as LCFRS with fan-out 2. Higher
values of fan-out allow strictly more powerful grammars (Rambow and Satta 1999).
Polynomial-time parsing is possible for any fixed LCFRS grammar, but the degree of
</bodyText>
<page confidence="0.99364">
676
</page>
<bodyText confidence="0.9544568">
Gildea On the String Translations Produced by Multi Bottom–Up Tree Transducers
the polynomial depends on the grammar. Parsing general LCFRS grammars, where the
grammar is considered part of the input, is NP-complete (Satta 1992).
Following Melamed, Satta, and Wellington (2004), we represent translation in
LCFRS by using a special symbol # to separate the strings of the two languages. Our
LCFRS grammars will only generate strings of the form s#t, where s and t are strings
not containing the symbol #, and we will identify s as the source string and t as the
target string. We use the notation trans(LCFRS) to denote the set of translations that
can be produced by taking the string language of some LCFRS and splitting each string
into a pair at the location of the # symbol.
</bodyText>
<sectionHeader confidence="0.578345" genericHeader="introduction">
3. Translations Produced by General MBOTs
</sectionHeader>
<bodyText confidence="0.983471523809524">
In this section, we relate the yield of general MBOTs to string rewriting systems.
To begin, we show that the translation produced by any MBOT is also produced
by an LCFRS by giving a straightforward construction for converting MBOT rules to
LCFRS rules.
We first consider MBOT rules having only variables, as opposed to alphabet
symbols of rank zero, at their leaves. For an MBOT rule l -+ r with l E TE(S(X)), let
S1, S2, ... , Sk be the sequence of states appearing from left to right immediately above
the leaves of l. Without loss of generality, we will name the variables such that xi,j is the
jth child of the ith state, Si, and the sequence of variables at the leaves of l, read from
left to right, is: x1,1, . . . , x1,d(S1), . . . , xk,1, . . . , xk,d(Sk), where d(Si) is the rank of state Si.
Let S0 be the state symbol at the root of the right-hand-side (r.h.s.) tree r E S(T∆(X)).
Let π and µ be functions such that xπ(1),µ(1),xπ(2),µ(2),...,xπ(n),µ(n) is the sequence
of variables at the leaves of r read from left to right. We will call this sequence the yield
of r. Finally, let p(i) for 1 &lt; i &lt; d(S0) be the position in the yield of r of the rightmost
leaf of S0’s ith child. Thus, for all i, 1 &lt; p(i) &lt; n.
Given this notation, the LCFRS rule corresponding to the MBOT rule l -+ r is
constructed as S0 -+ g(S1, S2, ... , Sk). The LCFRS nonterminal Si has fan-out equal
to the corresponding MBOT state’s rank plus one: ϕ(Si) = d(Si) + 1. This is because
the LCFRS nonterminal has one span in the source language, and d(Si) spans in
the target language of the translation. The combination function for the LCFRS rule
S0 -+ g(S1, S2,... , Sk) is:
</bodyText>
<equation confidence="0.999443">
g((e1,f1,1, ... ,f1,d(S1)), ... , (ek,fk,1, ... ,fk,d(Sk))) =
( e1 ··· ek, fπ(1),µ(1) ··· fπ(p(1)),µ(p(1)),
fπ(p(1)+1),µ(p(1)+1) ··· fπ(p(2)),µ(p(2)),
. . . ,
fπ(p(d(S0)−1)+1),µ(p(d(S0)−1)+1) ··· fπ(p(d(S0))),µ(p(d(S0)) )
</equation>
<bodyText confidence="0.947054375">
Here we use ei for the variables in the LCFRS rule corresponding to spans in the input
tree of the MBOT, and fi,j for variables corresponding to the output tree. The pattern in
which these spans fit together is specified by the functions π and µ that were read off of
the MBOT rule.
Examples of the conversion of an MBOT rule to an LCFRS rule are shown in
Figure 2. The first example shows an MBOT rule derived from an STSG rule, in this
case converting SVO (as in English) to VSO (as in Arabic) word order. The states of
an MBOT rule derived from an STSG rule always have rank 1. In the resulting LCFRS
</bodyText>
<page confidence="0.989959">
677
</page>
<note confidence="0.295296">
Computational Linguistics Volume 38, Number 3
</note>
<bodyText confidence="0.999890642857143">
rule, this means that every nonterminal in the grammar has fan-out 2, corresponding
to one span in the source language string and one span in the target language string of
the translation. This is what we would expect, given that, in terms of the translations
produced, STSG is equivalent to SCFG (because the internal tree structure of the rules is
irrelevant), and SCFG falls within the class of LCFRS grammars of fan-out 2. Figure 2b
shows a more general example, where the states of the MBOT rule have rank &gt; 1.
Now we extend this construction to handle tree symbols of rank zero, which corre-
spond to terminal symbols in the LCFRS. Let α0 be the sequence of rank zero symbols
appearing at the leaves of l to the left of x1,1, and let αi for 1 &lt; i &lt; k be the sequence of
rank zero symbols to the right of xi,d(Si), and to the left of xi+1,1 if i &lt; k. Let βi,j be the
sequence of symbols of rank zero at the leaves of r appearing in the subtree under the
ith child of S0 after the jth variable in this subtree and before the j + 1th variable, with
βi,0 being to the left of the first variable, and βi,p(i) being to the right of the last variable.
We can add these sequences of terminal symbols to the LCFRS rule as follows:
</bodyText>
<equation confidence="0.999471333333333">
g((e1,f1,1, ... ,f1,d(S1)), ... , (ek,fk,1,... ,fk,d(Sk))) =
( α0e1α1 ··· ekαk,
β1,0fπ(1),µ(1)β1,1 ···fπ(p(1)),µ(p(1))β1,p(1),
β2,0fπ(p(1)+1),µ(p(1)+1)β2,1 ···fπ(p(2)),µ(p(2))β2,p(2),
. . . ,
βd(S0),0fπ(p(d(S0)−1)+1),µ(p(d(S0)−1)+1)βd(S0),1 ··· fπ(p(d(S0))),µ(p(d(S0))βd(S0),p(d(S0)) )
</equation>
<bodyText confidence="0.994520666666667">
An example of this conversion is shown in Figure 3. In this example, α1 = of, β1,1 = 的,
all other α and β values are the empty string, and d(S0) = 1. We refer to the LCFRS rule
constructed from MBOT rule l -+ r as pl→r.
</bodyText>
<figureCaption confidence="0.741341">
Figure 2
</figureCaption>
<bodyText confidence="0.54155">
Examples of the conversion of an MBOT rule to an LCFRS rule.
</bodyText>
<page confidence="0.967324">
678
</page>
<note confidence="0.602258">
Gildea On the String Translations Produced by Multi Bottom–Up Tree Transducers
</note>
<figureCaption confidence="0.772874">
Figure 3
</figureCaption>
<bodyText confidence="0.9751">
Conversion of an MBOT rule with symbols of rank zero to an LCFRS production with terminals.
Finally, we add a start rule rule S -+ g(Si), g((e,f)) = (e#f) for each Si E F to gener-
ate all final states Si of the MBOT from the start symbol S of the LCFRS.
We now show that the language of the LCFRS constructed from a given MBOT is
identical to the yield of the MBOT. We represent MBOT transductions as derivation
trees, where each node is labeled with an MBOT rule, and each node’s children are
the rules used to produce the subtrees matched by any variables in the rule. We can
construct an LCFRS derivation tree by simply relabeling each node with the LCFRS rule
constructed from the node’s MBOT rule. Because, in the MBOT derivation tree, each
node has children which produce the states required by the the MBOT rule’s left-hand
side (l.h.s.), it also holds that, in the LCFRS derivation tree, each node has as its children
rules which expand the set of nonterminals appearing in the parent’s r.h.s. Therefore
the LCFRS tree constitutes a valid derivation.
Given the mapping from MBOT derivations to LCFRS derivations, the following
lemma relates the strings produced by the derivations:
Lemma 1
Let TMBOT be an MBOT derivation tree with I as its input tree and O as its output tree,
and construct TLCFRS by mapping each node nMBOT in TMBOT to a node nLCFRS labeled
with the LCFRS production constructed from the rule at nMBOT. Let (t0, t1, ... , tk) be the
string tuple returned by the LCFRS combination function at any node nLCFRS in TLCFRS.
The string t0 contains the yield of the node of I at which the MBOT rule at the node of
TMBOT corresponding to nLCFRS was applied. Furthermore, the strings t1, ... , tk contain
the k yields of the k MBOT output subtrees (subtrees of O) that are found as children
of the root (state symbol) of the MBOT rule’s right-hand side.
</bodyText>
<subsectionHeader confidence="0.566795">
Proof
</subsectionHeader>
<bodyText confidence="0.999974333333333">
When we apply the LCFRS combination functions to build the string produced by the
LCFRS derivation, the sequence of function applications corresponds exactly to the
bottom–up application of MBOT rules to the input tree. Let us refer to the tuple returned
by one LCFRS combination function g as (t0, t1, ... , tk). An MBOT rule applying at the
bottom of the input tree cannot contain any variables, and for MBOT rules of this type,
our construction produces an LCFRS rule with a combination function of the form:
</bodyText>
<equation confidence="0.975955">
g() = (α0, R1,0,..., Rk,0)
</equation>
<bodyText confidence="0.9994195">
taking no arguments and returning string constants equal to the yield of the MBOT
rule’s l.h.s, and the sequence of yields of the k subtrees under the r.h.s.’s root. Now we
consider how further rules in the LCFRS derivation make use of the tuple (t0, t1, ... , tk).
Our LCFRS combination functions always concatenate the first elements of the input
</bodyText>
<page confidence="0.988765">
679
</page>
<note confidence="0.284238">
Computational Linguistics Volume 38, Number 3
</note>
<bodyText confidence="0.999856083333333">
tuple in order, adding any terminals present in the portion of the input tree matched
by the MBOT’s l.h.s. Thus the combination functions maintain the property that the
first element in the resulting tuple, t0, contains the yield of the subtree of the input
tree where the corresponding MBOT rule applied. The combination functions combine
the remaining elements in their input tuples in the same order given by the MBOT
rule’s r.h.s., again adding any terminals added to the output tree by the MBOT rule.
Thus, at each step, the strings t1, ... , tk returned by LCFRS combination functions
contain the k yields of the k MBOT output subtrees found as children of the root (state
symbol) of the MBOT rule’s r.h.s. By induction, the lemma holds at each node in the
derivation tree. ■
The correspondence between LCFRS string tuples and MBOT tree yields gives us
our first result:
</bodyText>
<equation confidence="0.758940666666667">
Theorem 1
yield(MBOT) C trans(LCFRS).
Proof
</equation>
<bodyText confidence="0.983828">
From a given MBOT, construct an LCFRS as described previously. For any transduction
of the MBOT, from Lemma 1, there exists an LCFRS derivation which produces a string
consisting of the yield of the MBOT’s input and output trees joined by the # symbol. In
the other direction, we note that any valid derivation of the LCFRS corresponds to an
MBOT transduction on some input tree; this input tree can be constructed by assembling
the left-hand sides of the MBOT rules from which the LCFRS rules of the LCFRS
derivation were originally constructed. Because there is a one-to-one correspondence
between LCFRS and MBOT derivations, the translation produced by the LCFRS and
the yield of the MBOT are identical.
Because we can construct an LCFRS generating the same translation as the yield of
any given MBOT, we see that yield(MBOT) C trans(LCFRS). ■
The translations produced by MBOTs are equivalent to the translations produced
by a certain restricted class of LCFRS grammars, which we now specify precisely.
Theorem 2
The class of translations yield(MBOT) is equivalent to yield(1-m-LCFRS), where 1-m-
LCFRS is defined to be the class of LCFRS grammars where each rule either is a start
rule of the form S -+ g(Si), g((e,f)) = (e#f), or meets both of the following conditions:
</bodyText>
<listItem confidence="0.9777695">
• The combination function keeps the two sides of the translation separate.
That is, it must be possible to write
</listItem>
<equation confidence="0.944355666666667">
g((e1,f1,1, ... ,f1,ϕ1), ... , (er,fr,1, ...,fr,ϕr))
as
g1((e1),..., (er)) + g2((f1,1,... ,f1,ϕ1),..., (fr,1,...,fr,ϕr))
</equation>
<bodyText confidence="0.993208">
where + represents tuple concatenation, for some functions g1 and g2.
</bodyText>
<listItem confidence="0.52599">
• The function g1 returns a tuple of length 1.
</listItem>
<page confidence="0.949175">
680
</page>
<bodyText confidence="0.542011">
Gildea On the String Translations Produced by Multi Bottom–Up Tree Transducers
</bodyText>
<subsectionHeader confidence="0.807219">
Proof
</subsectionHeader>
<bodyText confidence="0.9998655">
Our construction for transforming an MBOT to an LCFRS produces LCFRS grammars
satisfying the given constraints, so yield(MBOT) ⊂ trans(1-m-LCFRS).
To show the other direction, we will construct an MBOT from a 1-m-LCFRS. For
each 1-m-LCFRS rule of the form
</bodyText>
<equation confidence="0.9992768">
S → g(B1, ... , Br)
g((e1,f1,1, ... ,f1,ϕ1), ... , (er,fr,1, . .. ,fr,ϕr)) =
g1((e1), ..., (er)) + g2((f1,1, ... ,f1,ϕ1), ..., (fr,1, ... ,fr,ϕr))
g1(�e1�,..., �er�) = �α0e1 ··· αr−1erαr�
g2(~ f1,1,...,f1,ϕ1�,...,�fr,1,...,fr,ϕr�) = (t1,1 ··· t1,n1, ..., tm,1 ··· tm,nm)
</equation>
<bodyText confidence="0.8947595">
where each αi is a string of terminals, and each symbol ti,j is either a variable fi,,j,, or a
single terminal, we construct the MBOT rule:
</bodyText>
<equation confidence="0.997957727272727">
S → S
fr,1 ... fr,ϕ(Br)
f1,1 ... f1,ϕ(B1)
α0 B1
··· αr−1 Br
αr
t1,1 ··· t1,n1
tm,1 ··· tm,nm
S1
Sm
· · ·
</equation>
<bodyText confidence="0.999329692307692">
By the same reasoning used for our construction of LCFRS grammars from MBOTs,
there is a one-to-one correspondence between derivation trees of the 1-m-LCFRS and the
constructed MBOT, and the yield strings also correspond at each node in the derivation
trees. Therefore, yield(1-m-LCFRS) ⊂ yield(MBOT).
Because we have containment in both directions, yield(MBOT) = trans(1-m-
LCFRS). ■
We now move on to consider the languages formed by the source and target
projections of MBOT translations.
Grammars of the class 1-m-LCFRS have the property that, for any nonterminal A
(other than the start symbol S) having fan-out ϕ(A), one span is always realized in the
source string (to the left of the # separator), and ϕ(A) − 1 spans are always realized
in the target language (to the right of the separator). This property is introduced by
the start rules S → g(Si), g((e,f)) = (e#f) and is maintained by all further productions
because of the condition on 1-m-LCFRS that the combination function must keep the
two sides of translation separate. For a 1-m-LCFRS rule constructed from an MBOT,
we define the rule’s source language projection to be the rule obtained by discarding
all the target language spans, as well as the separator symbol # in the case of the start
productions. The definition of 1-m-LCFRS guarantees that the combination function
returning a rule’s l.h.s. source span needs to have only the r.h.s. source spans available
as arguments.
For an LCFRS G, we define L(G) to be the language produced by G. We define
source(G) to be the LCFRS obtained by projecting each rule in G. Because more than
one rule may have the same projection, we label the rules of source(G) with their origin
rule, preserving a one-to-one correspondence between rules in the two grammars. Sim-
ilarly, we obtain a rule’s target language projection by discarding the source language
spans, and define target(G) to be the resulting grammar.
</bodyText>
<page confidence="0.978134">
681
</page>
<figure confidence="0.5364785">
Computational Linguistics Volume 38, Number 3
Lemma 2
</figure>
<bodyText confidence="0.9177055">
For an LCFRS G constructed from an MBOT M by the given construction, L(source(G)) =
source(trans(M)), and L(target(G)) = target(trans(M)).
</bodyText>
<subsectionHeader confidence="0.400297">
Proof
</subsectionHeader>
<bodyText confidence="0.999825857142857">
There is a valid derivation tree in the source language projection for each valid deriva-
tion tree in the full LCFRS, because for any expansion rewriting a nonterminal of fan-
out y(A) in the full grammar, we can apply the projected rule to the corresponding
nonterminal of fan-out 1 in the projected derivation. In the other direction, for any
expansion in a derivation of the source projection, a nonterminal of fan-out y(A) will
be available for expansion in the corresponding derivation of the full LCFRS. Because
there is a one-to-one correspondence between derivations in the full LCFRS and its
source projection, the language generated by the source projection is the source of the
translation generated by the original LCFRS. By the same reasoning, there is a one-to-
one correspondence between derivations in the target projection and the full LCFRS,
and the language produced by the target projection is the target side of the translation
of the full LCFRS. ■
Lemma 2 implies that it is safe to evaluate the power of the source and target
projections of the LCFRS independently. This fact leads to our next result.
</bodyText>
<equation confidence="0.718602">
Theorem 3
yield(MBOT) C trans(LCFRS).
Proof
</equation>
<bodyText confidence="0.978752">
In the LCFRS generated by our construction, all nonterminals have fan-out 1 in the
source side of the translation. Therefore, the source side of the translation is a context-
free language, and an MBOT cannot represent the following translation:
{(anbncndn, anbncndn)  |n &gt; 1}
which is produced by an STAG (Shieber and Schabes 1990; Schabes and Shieber 1994).
Because STAG is a type of LCFRS, yield(MBOT) C trans(LCFRS). ■
Although the source side of the translation produced by an MBOT must be a
context-free language, we now show that the target side can be any language produced
by an LCFRS.
</bodyText>
<equation confidence="0.679668666666667">
Theorem 4
target(yield(MBOT)) = LCFRS
Proof
</equation>
<bodyText confidence="0.999628333333333">
Given an input LCFRS, we can construct an MBOT whose target side corresponds to
the rules in the original LCFRS, and whose source simply accepts derivation trees of the
LCFRS. To make this precise, given an LCFRS rule in the general form:
</bodyText>
<equation confidence="0.9996185">
S -+ g(B1,...,Br)
g((x1,1,...,x1,ϕ(B1)),...,(x1,1,...,x1,ϕ(Br))) = (t1,1 ··· t1,n1, ..., tϕ(S),1 ··· tϕ(S),nϕ(S))
</equation>
<page confidence="0.964258">
682
</page>
<note confidence="0.489735">
Gildea On the String Translations Produced by Multi Bottom–Up Tree Transducers
</note>
<bodyText confidence="0.999081">
where each symbol ti j is either some variable xi, j, or a terminal from the alphabet of
the LCFRS, we construct the MBOT rule:
</bodyText>
<equation confidence="0.997382666666667">
S -+ S
B1 · · ·Br S1 ··· Sy(S)
x1,1 ... x1,y(B1) xr,1 ... xr,y(Br) t1,1 ··· t1,n1 ty(S),1 ··· ty(S),nϕ(S)
</equation>
<bodyText confidence="0.999980857142857">
where the MBOT’s input alphabet contains a symbol S for each LCFRS nonterminal S,
and the MBOT’s output alphabet contains y(S) symbols Si for each LCFRS nontermi-
nal S. This construction for converting an LCFRS to an MBOT shows that LCFRS C
target(yield(MBOT)).
Given our earlier construction for generating the target projection of the LCFRS
derived from an MBOT, we know that target(yield(MBOT)) C LCFRS. Combining these
two facts yields the theorem. ■
</bodyText>
<sectionHeader confidence="0.721266" genericHeader="method">
4. Composition of STSGs
</sectionHeader>
<bodyText confidence="0.999929722222222">
Maletti et al. (2009) discuss the composition of extended top–down tree transducers,
which are equivalent to STSGs, as shown by Maletti (2010). They show that this for-
malism is not closed under composition in terms of the tree transformations that are
possible. In this article, we focus on the string yields of the formalisms under discussion,
and from this point of view we now examine the question of whether the yield of the
composition of two STSGs is itself the yield of an STSG in general. It is important to
note that, although we focus on the yield of the composition, in our notion of STSG
composition, the tree structure output by the first STSG still serves as input to the
second STSG.
Maletti et al. (2009) give two tree transformations as counterexamples to the compo-
sitionality of STSG, shown in Figure 4. From the point of view of string yield, both of the
transformations are equivalent to an STSG rule that simply copies the three variables
with no re-ordering. Thus, these counterexamples are not sufficient to show that the
yield of the composition of two STSGs is not the yield of an STSG.
We now present two STSGs, shown in MBOT notation in Figures 5 and 6, whose
composition is not a translation produced by an STSG. The essence of this counterex-
ample, explained in more detail subsequently, is that rules from the two STSGs apply
in an overlapping manner to unboundedly long sequences, as in the example of Arnold
</bodyText>
<figureCaption confidence="0.706037">
Figure 4
</figureCaption>
<bodyText confidence="0.4743935">
Examples of tree transformations not contained in STSG, from Maletti et al. (2009). Here Gn
denotes a unary chain of G’s of arbitrary length.
</bodyText>
<page confidence="0.97986">
683
</page>
<figure confidence="0.809933">
Computational Linguistics Volume 38, Number 3
</figure>
<figureCaption confidence="0.8052095">
Figure 5
First MBOT in composition.
</figureCaption>
<bodyText confidence="0.99298475">
and Dauchet (1982, section 3.4). To this approach we add a re-ordering pattern which
results in a translation that we will show not to be possible with STSG.
The heart of each MBOT is the first rule, which reverses the order of adjacent
sequences of c’s and d’s. The MBOT of Figure 5 generates the translation:
</bodyText>
<equation confidence="0.78504">
J(a[cn2i−1dn2i]e i=1a, a[dn2icn2i−1]E1a)  |ni &gt; 1,$ &gt; 1}
</equation>
<bodyText confidence="0.999973833333333">
where f is the number of times the first rule of the transducer is applied, and the notation
[xi]ni=1 indicates the string concatenation x1x2 · · · xn. Here we have 2f repeated sequences
of characters c and d, each occurring ni times, with each integer ni for 1 &lt; i &lt; 2f varying
freely.
The second MBOT reverses sequences of c’s and d’s in a pattern that is offset by one
from the pattern of the first MBOT. It produces the translation:
</bodyText>
<equation confidence="0.9904685">
J(adn1[cn2idn2i+1]E−1cn21a, adn1[dn2i+1cn2i]E−1cn2Qa)  |ni &gt; 1,$ &gt; 1}
i=1 i=1 —
</equation>
<bodyText confidence="0.619152">
When we compose the two MBOTs, the yield of the resulting transducer is the
translation:
</bodyText>
<equation confidence="0.891236">
Tcrisscross = ∞ T~ (1)
U crisscross
</equation>
<page confidence="0.7870205">
E=1
684
</page>
<bodyText confidence="0.727359">
Gildea On the String Translations Produced by Multi Bottom–Up Tree Transducers
where
</bodyText>
<equation confidence="0.9836775">
TEcrisscross = {(a[cn2i−1dn2i]E i=1a, adn2[dn2i+2cn2i−1]E−1
i=1 cn2e−1a)  |ni ≥ 1} (2)
</equation>
<figure confidence="0.896386625">
A visualization of the alignment pattern of this translation is shown in Figure 7. We
will show that Tcrisscross cannot be produced by any SCFG.
We define an SCFG to be a system (V, E, ∆, P, S) where V is a set of nonterminals,
E and ∆ are the terminal alphabets of the source and target language respectively,
S E V is a distinguished start symbol, and P is a set of productions of the following
general form:
1 n π(1) π(n)
X0 → X11 Xn , Xπ(1) ··· Xπ(n)
</figure>
<figureCaption confidence="0.715080666666667">
Figure 6
Second MBOT in composition.
Figure 7
</figureCaption>
<bodyText confidence="0.797646">
Translation resulting from MBOT composition with f = 8.
</bodyText>
<page confidence="0.990912">
685
</page>
<note confidence="0.489045">
Computational Linguistics Volume 38, Number 3
</note>
<bodyText confidence="0.999983">
where π is a permutation of length n, and the variables Xi for 0 &lt; i &lt; n range over
nonterminal symbols (for example, X1 and X2 may both stand for nonterminal A).
In SCFG productions, the l.h.s. nonterminal rewrites into a string of terminals and
nonterminals in both the source and target languages, and pairs of r.h.s. nonterminals
that are linked by the same superscript index must be further rewritten by the same
rule.
In terms of string translations, STSGs and SCFGs are equivalent, because any SCFG
is also an STSG with rules of depth 1, and any STSG can be converted to an SCFG with
the same string translation by simply removing the internal tree nodes in each rule. We
will adopt SCFG terminology for our proof because the internal structure of STSG rules
is not relevant to our result.
For a fixed value of f, the translation T&apos;crisscross can be produced by an SCFG of
rank 2f, shown in Figure 8, because one rule can produce 2f nonterminals arranged
in the permutation of Figure 7. (In the context of SCFGs, rank refers to the maxi-
mum number of nonterminals on the r.h.s. of a rule.) We will show that strings of
this form cannot be produced by any SCFG of rank less than 2f. Intuitively, factoring
the alignment pattern of Figure 7 into smaller SCFG rules would require identifying
subsequences in the two languages that are consistently aligned to one another, and, as
can be seen from the figure, no such subsequences exist. Because f can be unboundedly
large in our translation, the translation cannot be produced by any SCFG of fixed
rank.
We will assume, without loss of generality, that any SCFG is written in a normal
form such that each rule’s r.h.s. either contains only terminals in each language, or
contains only nonterminals. An SCFG can be transformed into this normal form by
applying the following procedure to each rule:
</bodyText>
<listItem confidence="0.971125888888889">
1. Associate each sequence of terminals with the preceding nonterminal, or
the following nonterminal in the case of initial terminals.
2. Replace each group consisting of a nonterminal and its associated
terminals with a fresh nonterminal A, and add a rule rewriting A as the
group in source and target. (Nonterminals with no associated terminals
may be left intact.)
3. In each rule created in the previous step, replace each sequence of
terminals with another fresh nonterminal B, and add a rule rewriting B as
the terminal sequence in source and target.
</listItem>
<figureCaption confidence="0.95269425">
Figure 9 shows an example of this grammar transformation. Because we do not change
the rank of existing rules, and we add rules of rank no greater than 3, the transformation
does not increase the rank of any grammar having rank at least 3.
Figure 8
</figureCaption>
<bodyText confidence="0.611097">
An SCFG producing translation T&apos;crisscross for fixed P.
</bodyText>
<page confidence="0.990401">
686
</page>
<note confidence="0.82589">
Gildea On the String Translations Produced by Multi Bottom–Up Tree Transducers
</note>
<figureCaption confidence="0.988456">
Figure 9
Conversion of grammar (a) to normal form (b) in which each rule has only nonterminals or only
terminals on the r.h.s.
Figure 10
An SCFG derivation produced by applying each rule in Figure 9b once, in the order given in
Figure 9b. Indices of linked nonterminals are renumbered after each step to be monotonically
increasing in the English side of the derivation. The preterminal permutation of the derivation,
(3,2,1), is the sequence of indices on the Chinese side in the last step before any terminals are
produced.
</figureCaption>
<bodyText confidence="0.986921789473684">
In an SCFG derivation, nonterminals in either language are linked as shown in Fig-
ure 10. We restrict derivations to apply rules producing terminals after applying all
other rules. We refer to nonterminals at the last step in which the sentential form
consists exclusively of nonterminals as preterminals, and we refer to a pair of linked
preterminals as an aligned preterminal pair. Assuming that aligned preterminal pairs
are indexed consecutively in the source side of the sentential form, we refer to the
sequence of indices in the target side as the preterminal permutation of a derivation.
For example, the preterminal permutation of the derivation in Figure 10 is (3,2,1). The
permutation of any sentential form of an SCFG of rank r can be produced by composing
permutations of length no greater than r, by induction over the length of the derivation.
Thus, while the permutation (3,2,1) of our example can be produced by composing
permutations of length 2, the preterminal permutation (2,4,1,3) can never be produced
by an SCFG of rank 2 (Wu 1997). In fact, this restriction also applies to subsequences of
the preterminal permutation.
Lemma 3
Let π be a preterminal permutation produced by an SCFG derivation containing rules
of maximum rank r, and let πe be a permutation obtained from π by removing some
elements and renumbering the remaining elements with a strictly increasing function.
Then πe falls within the class of compositions of permutations of length r.
</bodyText>
<subsectionHeader confidence="0.409066">
Proof
</subsectionHeader>
<bodyText confidence="0.999802833333333">
From each rule in the derivation producing preterminal permutation π, construct a new
rule by removing any nonterminals whose indices were removed from π. The resulting
sequence of rules produces preterminal permutation πe and contains rules of rank no
greater than r. ■
As an example of Lemma 3, removing any element from the permutation (3,2,1) results
in the permutation (2,1), which can still (trivially) be produced by an SCFG of rank 2.
</bodyText>
<page confidence="0.989727">
687
</page>
<note confidence="0.488822">
Computational Linguistics Volume 38, Number 3
</note>
<bodyText confidence="0.980904">
We will make use of another general fact about SCFGs, which we derive by ap-
plying Ogden’s Lemma (Ogden 1968), a generalized pumping lemma for context-free
languages, to the source language of an SCFG.
</bodyText>
<subsectionHeader confidence="0.891273">
Lemma 4 (Ogden’s Lemma)
</subsectionHeader>
<bodyText confidence="0.852678">
For each context-free grammar G = (V, E, P, S) there is an integer k such that for any
word ξ in L(G), if any k or more distinct positions in ξ are designated as distinguished,
then there is some A in V and there are words α, β, γ, δ, and µ in E∗ such that:
</bodyText>
<listItem confidence="0.996266428571429">
• S =&gt;∗ αAµ =&gt;∗ αβAδµ =&gt;∗ αβγδµ = ξ, and hence αβmγδmµ E L(G)
for all m &gt; 0.
• γ contains at least one of the distinguished positions.
• Either α and β both contain distinguished positions, or δ and µ both
contain distinguished positions.
• βγδ contains at most k distinguished positions.
Ogden’s lemma can be extended as follows to apply to SCFGs.
</listItem>
<subsectionHeader confidence="0.65556">
Lemma 5
</subsectionHeader>
<bodyText confidence="0.75626925">
For each SCFG G = (V, E, ∆, P, S) having source alphabet E and target alphabet ∆, there
is an integer k such that for any string pair (ξ, ξ&apos;) in L(G), if any k or more distinct
positions in ξ are designated as distinguished, then there is some A in V and there are
words α, β, γ, δ, and µ in E∗ and α�, β&apos;, γ&apos;, δ&apos;, and µ~ in ∆∗ such that:
</bodyText>
<listItem confidence="0.999803428571428">
• (S 1 , S 1 ) =&gt;∗ (αA 1 µ, α&apos;A 1 µ&apos;) =&gt;∗ (αβA 1 δµ, α&apos;β&apos;A 1 δ1µ�) =&gt;∗
(αβγδµ, α&apos;β&apos;γ&apos;δ&apos;µ�) = (ξ, ξ% and hence
(αβmγδmµ, α&apos;(β&apos;)mγ&apos;(δ&apos;)mµ&apos;) E L(G) for all m &gt; 0.
• γ contains at least one of the distinguished positions.
• Either α and β both contain distinguished positions, or δ and µ both
contain distinguished positions.
• βγδ contains at most k distinguished positions.
</listItem>
<bodyText confidence="0.7376485">
Note that there are no guarantees on the form of α�, β&apos;, γ&apos;, δ&apos;, and µ�, and indeed these
may all be the empty string.
</bodyText>
<subsectionHeader confidence="0.952335">
Proof
</subsectionHeader>
<bodyText confidence="0.997928714285714">
There must exist some sequence of rules in the source projection of G which licenses the
derivation A =&gt;∗ βAδ. If we write the jth rule in this sequence as Aj -+ νj, there must
exist a synchronous rule in G of the form Aj -+ νj, ν� that rewrites the same nontermi-
nal. Thus G licenses a synchronous derivation (A 1 , A 1 ) =&gt;∗ (βA 1 δ, β&apos;A 1 δ&apos;) for some
β&apos; and δ&apos;. Similarly, the source derivation S =&gt;∗ αAµ has a synchronous counterpart
(S 1 , S 1 ) =&gt;∗ (αA 1 µ, α A 1 µ�) for some α&apos; and µ�, and the source derivation A =&gt; γ has
a synchronous counterpart (A 1 , A 1 ) =&gt; (γ, γ&apos;) for some γ&apos;. Because the synchronous
</bodyText>
<page confidence="0.990957">
688
</page>
<note confidence="0.592345">
Gildea On the String Translations Produced by Multi Bottom–Up Tree Transducers
</note>
<bodyText confidence="0.9983395">
derivation (A 1 , A 1 ) =&gt;∗ (βA 1 δ, β&apos;A 1 δ&apos;) can be repeated any number of times, the
string pairs
</bodyText>
<equation confidence="0.922336">
(αβmγδmµ, α�(β�)mγ,(δ�)mµ�) (3)
</equation>
<bodyText confidence="0.962700583333333">
are generated by the SCFG for all m &gt; 0. The further conditions on α, β, γ, δ, and µ
follow directly from Ogden’s Lemma. ■
We refer to a substring arising from a term cni or dni in the definition of Trisscross
(Equation (2)) as a run. In order to distinguish runs, we refer the run arising from cni or
dni as the ith run. We refer to the pair (cni, cni) or (dni, dni) consisting of the ith run in
the source and target strings as the ith aligned run. We now use Lemma 5 to show that
aligned runs must be generated from aligned preterminal pairs.
Lemma 6
Assume that some SCFG G&apos; generates the translation T�crisscross for some fixed f. There
exists a constant k such that, in any derivation of grammar G&apos; having each ni &gt; k, for any
i, 1 &lt; i &lt; 2f, there exists at least one aligned preterminal pair among the subsequences
of source and target preterminals generating the ith aligned run.
</bodyText>
<subsectionHeader confidence="0.586094">
Proof
</subsectionHeader>
<bodyText confidence="0.957338461538461">
We consider a source string ξ, (ξ,ξ&apos;) E T,isscross, such that the length ni of each run
is greater than the constant k of Lemma 5. For a fixed i, 1 &lt; i &lt; 2f, we consider the
distinguished positions to be all and only the terminals in the ith run. This implies that
the run can be pumped to be arbitrarily long; indeed, this follows from the definition of
the language itself.
Because our distinguished positions are within the ith run, and because Lemma 5
guarantees that either α, β, and γ all contain distinguished positions or γ, δ, and µ
all contain distinguished positions, we are guaranteed that either β or δ lies entirely
within the ith run. Consider the case where β lies within the run. We must consider
three possibilities for the location of δ in the string:
Case 1. The string δ also lies entirely within the ith run.
Case 2. The string δ contains substrings of more than one run. This cannot occur, because
pumped strings of the form αβmγδmµ would contain more than 2f runs, which is not
allowed under the definition of T�crisscross.
Case 3. The string δ lies entirely within the jth run, where j # i. The strings αβmγδmµ
have the same form as αβγδµ, with the exception that the ith and jth runs are extended
from lengths ni and nj to some greater lengths nl and n�. By the definition of T�crisscross,
for each source string, only one target string is permitted. For string pairs of the form of
Equation (3) to belong to T�crisscross, β&apos; and δ&apos; must lie within the ith and jth aligned runs
in the target side. Because the permutation of Figure 7 cannot be decomposed, there
must exist some k such that the kth aligned run lies between the ith and jth aligned
runs in one side of the translation, and outside the ith and jth aligned runs in the other
side of the translation. If this were not the case, we would be able to decompose the
permutation by factoring out the subsequence between the ith and jth runs on both
sides of the translation. Consider the case where the kth aligned run lies between the ith
and jth aligned runs in the source side, and therefore is a substring of γ in the source,
</bodyText>
<page confidence="0.995689">
689
</page>
<note confidence="0.59332">
Computational Linguistics Volume 38, Number 3
</note>
<bodyText confidence="0.972476958333333">
and a substring of either α&apos; or µ~ in the target. We apply Lemma 5 a second time, with
all terminals of the kth run as the distinguished positions, to the derivation (A, A) =&gt;∗
(γ, γ&apos;) by taking A as the start symbol of the grammar. This implies that there exist ˆβ,
ˆγ, ˆδ, ˆβ�, ˆγ�, and ˆδ&apos; such that
(ξ, ξ�) =(αβ βˆγˆˆδδµ, α&apos;β&apos;ˆβ ˆγ&apos;ˆδ&apos;δ&apos;µ�)
and all strings
(αβmˆβnγˆˆδnδmµ, α�(β�)m( ˆβ�)n ˆγ�( ˆδ�)n(δ�)mµ�)
are members of the translation T�crisscross. Either βˆ or δˆ is a substring of source side of
the kth aligned run, so the kth aligned run can be pumped to be arbitrarily long in
the source without changing its length in the target. This contradicts the definition of
Tcrisscross. Similarly, the case where the kth aligned run lies between β&apos; and δ&apos; in the
target leads to a contradiction. Thus the assumption that j =� i must be false.
Because Cases 2 and 3 are impossible, δ must lie entirely within the ith run. Simi-
larly, in the case where δ contains distinguished positions, β must lie within the ith run.
Thus both β and δ always lie entirely within the ith aligned run.
Because the β and δ lie within the ith aligned run, the strings αβmγδmµ have the
same form as αβγδµ, with the exception that the ith run is extended from length ni to
some greater length nl. For the pairs of Equation (3) to be members of the translation,
β&apos; and δ&apos; must be substrings of the ith aligned run in the target. Because βmγδm and
(β�)mγ�(δ�)m were derived from the same nonterminal, the two sequences of pretermi-
nals generating these two strings consist of aligned preterminal pairs. Because both
βmγδm and (β&apos;)mγ&apos;(δ&apos;)m are substrings of the ith aligned run, we have at least one
aligned preterminal pair among the source and target preterminal sequences generating
the ith aligned run. ■
</bodyText>
<subsectionHeader confidence="0.939478">
Lemma 7
</subsectionHeader>
<bodyText confidence="0.999924666666667">
Assume that some SCFG G&apos; generates the translation T�crisscross for some fixed f. There
exists a constant k such that, if (ξ, ξ&apos;) is a string pair generated by G&apos; having each ni &gt; k,
any derivation of (ξ, ξ&apos;) with grammar G&apos; must contain a rule of rank at least 2f.
</bodyText>
<subsectionHeader confidence="0.963842">
Proof
</subsectionHeader>
<bodyText confidence="0.999791333333333">
Because the choice of i in Lemma 6 was arbitrary, each aligned run must contain at least
one aligned preterminal pair. If we select one such preterminal pair from each run, the
associated permutation is that of Figure 7. This permutation cannot be decomposed, so,
by Lemma 3, it cannot be generated by an SCFG derivation containing only rules of
rank less than 2f. ■
We will use one more general fact about SCFGs to prove our main result.
</bodyText>
<subsectionHeader confidence="0.77133">
Lemma 8
</subsectionHeader>
<bodyText confidence="0.999210333333333">
Let G be an SCFG and let T = L(G) be the translation it produces. Let F be a finite state
machine, and let R = L(F) be the regular language it accepts. Let T&apos; be the translation
derived by intersecting the source strings of T with R
</bodyText>
<equation confidence="0.778877">
T&apos;={(s,t)  |(s,t)ET,sER}
</equation>
<page confidence="0.968341">
690
</page>
<note confidence="0.546563">
Gildea On the String Translations Produced by Multi Bottom–Up Tree Transducers
</note>
<bodyText confidence="0.91210125">
Then there exists an SCFG G&apos; such that T&apos; = L(G&apos;).
Proof
Let V be the nonterminal set of G, and let S be the state set of F. Construct the SCFG G&apos;
with nonterminal set V × S × S by applying the construction of Bar-Hillel, Perles, and
Shamir (1961) for intersection of a CFG and finite state machine to the source side of
each rule in G. ■
Now we are ready for our main result.
Theorem 5
SCFG = yield(STSG) C yield(STSG;STSG), where the semicolon denotes composition.
Proof
Assume that some SCFG G generates Tcrisscross. Note that TEcrisscross is the result of inter-
secting the source of Tcrisscross with the regular language a[c+d+]Ea. By Lemma 8, we can
construct an SCFG GE generating TEcrisscross. By Lemma 7, for each f, GE has rank at least
2f. The intersection construction does not increase the rank of the grammar, so G has
rank at least 2f. Because f is unbounded in the definition of Tcrisscross, and because any
SCFG has a finite maximum rank, Tcrisscross cannot be produced by any SCFG. ■
</bodyText>
<subsectionHeader confidence="0.924238">
4.1 Implications for Machine Translation
</subsectionHeader>
<bodyText confidence="0.999975777777778">
The ability of MBOTs to represent the composition of STSGs is given as a motivation for
the MBOT formalism by Maletti (2010), but this raises the issue of whether synchronous
parsing and machine translation decoding can be undertaken efficiently for MBOTs
resulting from the composition of STSGs.
In discussing the complexity of synchronous parsing problems, we distinguish
the case where the grammar is considered part of the input, and the case where the
grammar is fixed, and only the source and target strings are considered part of the input.
For SCFGs, synchronous parsing is NP-complete when the grammar is considered part
of the input and can have arbitrary rank. For any fixed grammar, however, synchronous
parsing is possible in time polynomial in the lengths of the source and target strings,
with the degree of the polynomial depending on the rank of the fixed SCFG (Satta and
Peserico 2005). Because MBOTs subsume SCFGs, the problem of recognizing whether a
string pair belongs to the translation produced by an arbitrary MBOT, when the MBOT
is considered part of the input, is also NP-complete.
Given our construction for converting an MBOT to an LCFRS, we can use standard
LCFRS tabular parsing techniques to determine whether a given string pair belongs
to the translation defined by the yield of a fixed MBOT. As with arbitrary-rank SCFG,
LCFRS parsing is polynomial in the length of the input string pair, but the degree of the
polynomial depends on the complexity of the MBOT. To be precise, the degree of the
polynomial for LCFRS parsing is Eri=0 y(Si) (Seki et al. 1991), which yields Eri=0(1 +
d(Si)) when applied to MBOTs.
If we restrict ourselves to MBOTs that are derived from the composition of STSGs,
synchronous parsing is NP-complete if the STSGs to compose are part of the input,
because a single STSG suffices. For a composition of fixed STSGs, we obtain a fixed
MBOT, and polynomial time parsing is possible. Theorem 5 indicates that we cannot
apply SCFG parsing techniques off the shelf, but rather that we must implement some
type of more general parsing system. Either of the STSGs used in our proof of Theorem 5
</bodyText>
<page confidence="0.991095">
691
</page>
<note confidence="0.563569">
Computational Linguistics Volume 38, Number 3
</note>
<bodyText confidence="0.999700782608696">
can be binarized and synchronously parsed in time O(n6), but tabular parsing for the
LCFRS resulting from composition has higher complexity. Thus, composing STSGs
generally increases the complexity of synchronous parsing.
The problem of language-model–integrated decoding with synchronous grammars
is closely related to that of synchronous parsing; both problems can be seen as inter-
secting the grammar with a fixed source-language string and a finite-state machine
constraining the target-language string. The widely used decoding algorithms for SCFG
(Yamada and Knight 2002; Zollmann and Venugopal 2006; Huang et al. 2009) search
for the highest-scoring translation when combining scores from a weighted SCFG and
a weighted finite-state language model. As with SCFG, language-model–integrated
decoding for weighted MBOTs can be performed by adding n-gram language model
state to each candidate target language span. This, as with synchronous parsing, gives
an algorithm which is polynomial in the length of the input sentence for a fixed MBOT,
but with an exponent that depends on the complexity of the MBOT. Furthermore,
Theorem 5 indicates that SCFG-based decoding techniques cannot be applied off the
shelf to compositions of STSGs, and that composition of STSGs in general increases
decoding complexity.
Finally, we note that finding the highest-scoring translation without incorporating
a language model is equivalent to parsing with the source or target projection of the
MBOT used to model translation. For the source language of the MBOT, this implies
time O(n3) because the problem reduces to CFG parsing. For the target language of
the MBOT, this implies polynomial-time parsing, where the degree of the polynomial
depends on the MBOT, as a result of Theorem 4.
</bodyText>
<sectionHeader confidence="0.997365" genericHeader="method">
5. Conclusion
</sectionHeader>
<bodyText confidence="0.999978466666667">
MBOTs are desirable for natural language processing applications because they are
closed under composition and can be used to represent sequences of transforma-
tions of the type performed by STSGs. However, the string translations produced
by MBOTs representing compositions of STSGs are strictly more powerful than the
string translations produced by STSGs, which are equivalent to the translations pro-
duced by SCFGs. From the point of view of machine translation, because parsing
with general LCFRS is NP-complete, restrictions on the power of MBOTs will be
necessary in order to achieve polynomial–time algorithms for synchronous parsing
and language-model–integrated decoding. Our result on the string translations pro-
duced by compositions of STSGs implies that algorithms for SCFG-based synchronous
parsing or language-model-integrated decoding cannot be applied directly to these
problems, and that composing STSGs generally increases the complexity of these prob-
lems. Developing parsing algorithms specific to compositions of STSGs, as well as
possible restrictions on the STSGs to be composed, presents an interesting area for
future work.
</bodyText>
<sectionHeader confidence="0.618925" genericHeader="method">
Acknowledgments References
</sectionHeader>
<bodyText confidence="0.997996166666667">
We are grateful for extensive feedback Aho, Albert V. and Jeffery D. Ullman. 1972.
on earlier versions of this work from The Theory of Parsing, Translation, and
Giorgio Satta, Andreas Maletti, Adam Compiling, volume 1. Prentice-Hall,
Purtee, and three anonymous reviewers. Englewood Cliffs, NJ.
This work was partially funded by NSF Arnold, Andr´e and Max Dauchet. 1982.
grant IIS-0910611. Morphismes et bimorphismes
</bodyText>
<page confidence="0.984432">
692
</page>
<note confidence="0.889913">
Gildea On the String Translations Produced by Multi Bottom–Up Tree Transducers
</note>
<reference confidence="0.999477691666667">
d’arbres. Theoretical Computer Science,
20:33–93.
Bar-Hillel, Y., M. Perles, and E. Shamir.
1961. On formal properties of simple
phrase structure grammars. Zeitschrift
f¨ur Phonetik, Sprachwissenschaft und
Kommunikationsforschung, 14:143–172.
Reprinted in Y. Bar-Hillel. 1964. Language
and Information: Selected Essays on their
Theory and Application, Addison-Wesley,
Boston, MA, pages 116–150.
Chiang, David. 2007. Hierarchical
phrase-based translation. Computational
Linguistics, 33(2):201–228.
Engelfriet, J., E. Lilin, and A. Maletti.
2009. Extended multi bottom–up
tree transducers. Acta Informatica,
46(8):561–590.
Galley, Michel, Jonathan Graehl, Kevin
Knight, Daniel Marcu, Steve DeNeefe,
Wei Wang, and Ignacio Thayer. 2006.
Scalable inference and training of
context-rich syntactic translation models.
In Proceedings of the International Conference
on Computational Linguistics/Association for
Computational Linguistics (COLING/
ACL-06), pages 961–968, Sydney.
Huang, Liang, Hao Zhang, Daniel Gildea,
and Kevin Knight. 2009. Binarization of
synchronous context-free grammars.
Computational Linguistics, 35(4):559–595.
Joshi, A. K., L. S. Levy, and M. Takahashi.
1975. Tree adjunct grammars. Journal of
Computer and System Sciences, 10:136–163.
Joshi, A. K. and Y. Schabes. 1997.
Tree-adjoining grammars. In G. Rozenberg
and A. Salomaa, editors, Handbook of
Formal Languages, volume 3. Springer,
Berlin, pages 69–124.
Lilin, Eric. 1981. Propri´et´es de clˆoture d’une
extension de transducteurs d’arbres
d´eterministes. In CAAP, volume 112 of
LNCS. Springer, Berlin, pages 280–289.
Maletti, Andreas. 2010. Why synchronous
tree substitution grammars? In Proceedings
of the 2010 Meeting of the North American
Chapter of the Association for Computational
Linguistics (NAACL-10), pages 876–884,
Los Angeles, CA.
Maletti, Andreas, Jonathan Graehl, Mark
Hopkins, and Kevin Knight. 2009. The
power of extended top–down tree
transducers. SIAM Journal on Computing,
39:410–430.
Melamed, I. Dan. 2003. Multitext grammars
and synchronous parsers. In Proceedings
of the 2003 Meeting of the North American
Chapter of the Association for Computational
Linguistics (NAACL-03), pages 158–165,
Edmonton.
Melamed, I. Dan, Giorgio Satta, and
Ben Wellington. 2004. Generalized
multitext grammars. In Proceedings of the
42nd Annual Conference of the Association
for Computational Linguistics (ACL-04),
pages 661–668, Barcelona.
Ogden, William F. 1968. A helpful result for
proving inherent ambiguity. Mathematical
Systems Theory, 2(3):191–194.
Rambow, Owen and Giorgio Satta. 1999.
Independent parallelism in finite copying
parallel rewriting systems. Theoretical
Computer Science, 223(1-2):87–120.
Satta, Giorgio. 1992. Recognition of Linear
Context-Free Rewriting Systems. In
Proceedings of the 30th Annual Conference of
the Association for Computational Linguistics
(ACL-92), pages 89–95, Newark, DE.
Satta, Giorgio and Enoch Peserico. 2005.
Some computational complexity results for
synchronous context-free grammars. In
Proceedings of Human Language Technology
Conference and Conference on Empirical
Methods in Natural Language Processing
(HLT/EMNLP), pages 803–810, Vancouver.
Schabes, Yves and Stuart M. Shieber. 1994.
An alternative conception of tree-adjoining
derivation. Computational Linguistics,
20:91–124.
Seki, H., T. Matsumura, M. Fujii, and
T. Kasami. 1991. On multiple context-free
grammars. Theoretical Computer Science,
88:191–229.
Shieber, Stuart and Yves Schabes. 1990.
Synchronous tree-adjoining grammars.
In Proceedings of the 13th International
Conference on Computational Linguistics
(COLING-90), volume III, pages 253–258,
Helsinki.
Vijay-Shankar, K., D. L. Weir, and A. K.
Joshi.1987. Characterizing structural
descriptions produced by various
grammatical formalisms. In Proceedings of
the 25th Annual Conference of the Association
for Computational Linguistics (ACL-87),
pages 104–111, Stanford, CA.
Wu, Dekai. 1997. Stochastic inversion
transduction grammars and bilingual
parsing of parallel corpora. Computational
Linguistics, 23(3):377–403.
Yamada, Kenji and Kevin Knight. 2002. A
decoder for syntax-based statistical MT. In
Proceedings of the 40th Annual Conference of
the Association for Computational Linguistics
(ACL-02), pages 303–310, Philadelphia, PA.
Zollmann, Andreas and Ashish Venugopal.
2006. Syntax augmented machine
translation via chart parsing. In Proceedings
of the Workshop on Statistical Machine
Translation, pages 138–141, New York, NY.
</reference>
<page confidence="0.999133">
693
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.523679">
<title confidence="0.8096375">On the String Translations Produced by Multi Bottom–Up Tree Transducers</title>
<affiliation confidence="0.918342">University of Rochester</affiliation>
<abstract confidence="0.9910025">Tree transducers are defined as relations between trees, but in syntax-based machine translation, we are ultimately concerned with the relations between the strings at the yields of the input and output trees. We examine the formal power of Multi Bottom-Up Tree Transducers from this point of view.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>d’arbres</author>
</authors>
<journal>Theoretical Computer Science,</journal>
<pages>20--33</pages>
<marker>d’arbres, </marker>
<rawString>d’arbres. Theoretical Computer Science, 20:33–93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Bar-Hillel</author>
<author>M Perles</author>
<author>E Shamir</author>
</authors>
<title>On formal properties of simple phrase structure grammars. Zeitschrift f¨ur Phonetik, Sprachwissenschaft und Kommunikationsforschung,</title>
<date>1961</date>
<pages>14--143</pages>
<publisher>Addison-Wesley,</publisher>
<location>Boston, MA,</location>
<note>Reprinted in</note>
<marker>Bar-Hillel, Perles, Shamir, 1961</marker>
<rawString>Bar-Hillel, Y., M. Perles, and E. Shamir. 1961. On formal properties of simple phrase structure grammars. Zeitschrift f¨ur Phonetik, Sprachwissenschaft und Kommunikationsforschung, 14:143–172. Reprinted in Y. Bar-Hillel. 1964. Language and Information: Selected Essays on their Theory and Application, Addison-Wesley, Boston, MA, pages 116–150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="3090" citStr="Chiang (2007)" startWordPosition="460" endWordPosition="461">uch as those provided by STSGs are ultimately tools to translate a string * Computer Science Department, University of Rochester, Rochester NY 14627. E-mail: gildea@cs.rochester.edu. Submission received: 3 May 2011; revised submission received:1 October 2011; accepted for publication: 28 October 2011. © 2012 Association for Computational Linguistics Computational Linguistics Volume 38, Number 3 in one natural language into a string in another. Whereas MBOTs originate in the tree transducer literature and are defined to take a tree as input, MT systems such as those of Galley et al. (2006) and Chiang (2007) find a parse of the source language sentence as part of the translation process, and the decoding algorithm, introduced by Yamada and Knight (2002), has more in common with CYK parsing than with simulating a tree transducer. In this article, we investigate the power of MBOTs, and of compositions of STSGs in particular, in terms of the set of string translations that they generate. We relate MBOTs and compositions of STSGs to existing grammatical formalisms defined on strings through five main results, which we outline subsequently. The first four results serve to situate general MBOTs among s</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>Chiang, David. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33(2):201–228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Engelfriet</author>
<author>E Lilin</author>
<author>A Maletti</author>
</authors>
<title>Extended multi bottom–up tree transducers.</title>
<date>2009</date>
<journal>Acta Informatica,</journal>
<volume>46</volume>
<issue>8</issue>
<marker>Engelfriet, Lilin, Maletti, 2009</marker>
<rawString>Engelfriet, J., E. Lilin, and A. Maletti. 2009. Extended multi bottom–up tree transducers. Acta Informatica, 46(8):561–590.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Jonathan Graehl</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
<author>Steve DeNeefe</author>
<author>Wei Wang</author>
<author>Ignacio Thayer</author>
</authors>
<title>Scalable inference and training of context-rich syntactic translation models.</title>
<date>2006</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics/Association for Computational Linguistics (COLING/ ACL-06),</booktitle>
<pages>961--968</pages>
<location>Sydney.</location>
<contexts>
<context position="990" citStr="Galley et al. (2006)" startWordPosition="144" endWordPosition="147">ee Transducers from this point of view. 1. Introduction Many current approaches to syntax-based statistical machine translation fall under the theoretical framework of synchronous tree substitution grammars (STSGs). Tree substitution grammars (TSGs) generalize context-free grammars (CFGs) in that each rule expands a nonterminal to produce an arbitrarily large tree fragment, rather than a fragment of depth one as in a CFG. Synchronous TSGs generate tree fragments in the source and target languages in parallel, with each rule producing a tree fragment in either language. Systems such as that of Galley et al. (2006) extract STSG rules from parallel bilingual text that has been automatically parsed in one language, and the STSG nonterminals correspond to nonterminals in these parse trees. Chiang’s (2007) Hiero system produces simpler STSGs with a single nonterminal. STSGs have the advantage that they can naturally express many re-ordering and restructuring operations necessary for machine translation (MT). They have the disadvantage, however, that they are not closed under composition (Maletti et al. 2009). Therefore, if one wishes to construct an MT system as a pipeline of STSG operations, the result may</context>
<context position="3072" citStr="Galley et al. (2006)" startWordPosition="455" endWordPosition="458">trings. Tree operations such as those provided by STSGs are ultimately tools to translate a string * Computer Science Department, University of Rochester, Rochester NY 14627. E-mail: gildea@cs.rochester.edu. Submission received: 3 May 2011; revised submission received:1 October 2011; accepted for publication: 28 October 2011. © 2012 Association for Computational Linguistics Computational Linguistics Volume 38, Number 3 in one natural language into a string in another. Whereas MBOTs originate in the tree transducer literature and are defined to take a tree as input, MT systems such as those of Galley et al. (2006) and Chiang (2007) find a parse of the source language sentence as part of the translation process, and the decoding algorithm, introduced by Yamada and Knight (2002), has more in common with CYK parsing than with simulating a tree transducer. In this article, we investigate the power of MBOTs, and of compositions of STSGs in particular, in terms of the set of string translations that they generate. We relate MBOTs and compositions of STSGs to existing grammatical formalisms defined on strings through five main results, which we outline subsequently. The first four results serve to situate gen</context>
</contexts>
<marker>Galley, Graehl, Knight, Marcu, DeNeefe, Wang, Thayer, 2006</marker>
<rawString>Galley, Michel, Jonathan Graehl, Kevin Knight, Daniel Marcu, Steve DeNeefe, Wei Wang, and Ignacio Thayer. 2006. Scalable inference and training of context-rich syntactic translation models. In Proceedings of the International Conference on Computational Linguistics/Association for Computational Linguistics (COLING/ ACL-06), pages 961–968, Sydney.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Hao Zhang</author>
<author>Daniel Gildea</author>
<author>Kevin Knight</author>
</authors>
<title>Binarization of synchronous context-free grammars.</title>
<date>2009</date>
<journal>Computational Linguistics,</journal>
<volume>35</volume>
<issue>4</issue>
<contexts>
<context position="48980" citStr="Huang et al. 2009" startWordPosition="8519" endWordPosition="8522"> binarized and synchronously parsed in time O(n6), but tabular parsing for the LCFRS resulting from composition has higher complexity. Thus, composing STSGs generally increases the complexity of synchronous parsing. The problem of language-model–integrated decoding with synchronous grammars is closely related to that of synchronous parsing; both problems can be seen as intersecting the grammar with a fixed source-language string and a finite-state machine constraining the target-language string. The widely used decoding algorithms for SCFG (Yamada and Knight 2002; Zollmann and Venugopal 2006; Huang et al. 2009) search for the highest-scoring translation when combining scores from a weighted SCFG and a weighted finite-state language model. As with SCFG, language-model–integrated decoding for weighted MBOTs can be performed by adding n-gram language model state to each candidate target language span. This, as with synchronous parsing, gives an algorithm which is polynomial in the length of the input sentence for a fixed MBOT, but with an exponent that depends on the complexity of the MBOT. Furthermore, Theorem 5 indicates that SCFG-based decoding techniques cannot be applied off the shelf to compositi</context>
</contexts>
<marker>Huang, Zhang, Gildea, Knight, 2009</marker>
<rawString>Huang, Liang, Hao Zhang, Daniel Gildea, and Kevin Knight. 2009. Binarization of synchronous context-free grammars. Computational Linguistics, 35(4):559–595.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Joshi</author>
<author>L S Levy</author>
<author>M Takahashi</author>
</authors>
<title>Tree adjunct grammars.</title>
<date>1975</date>
<journal>Journal of Computer and System Sciences,</journal>
<pages>10--136</pages>
<marker>Joshi, Levy, Takahashi, 1975</marker>
<rawString>Joshi, A. K., L. S. Levy, and M. Takahashi. 1975. Tree adjunct grammars. Journal of Computer and System Sciences, 10:136–163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Joshi</author>
<author>Y Schabes</author>
</authors>
<title>Tree-adjoining grammars.</title>
<date>1997</date>
<booktitle>Handbook of Formal Languages,</booktitle>
<volume>3</volume>
<pages>69--124</pages>
<editor>In G. Rozenberg and A. Salomaa, editors,</editor>
<publisher>Springer,</publisher>
<location>Berlin,</location>
<contexts>
<context position="4121" citStr="Joshi and Schabes 1997" startWordPosition="619" endWordPosition="622">positions of STSGs to existing grammatical formalisms defined on strings through five main results, which we outline subsequently. The first four results serve to situate general MBOTs among string formalisms, and the fifth result addresses MBOTs resulting from compositions of STSGs in particular. Our first result is that the translations produced by MBOTs are a subset of those produced by linear context-free rewriting systems (LCFRSs) (Vijay-Shankar, Weir, and Joshi 1987). LCFRS provides a very general framework that subsumes CFG, tree adjoining grammar (TAG; Joshi, Levy, and Takahashi 1975; Joshi and Schabes 1997), and more complex systems, as well as synchronous context-free grammar (SCFG) (Aho and Ullman 1972) and synchronous tree adjoining grammar (STAG) (Shieber and Schabes 1990; Schabes and Shieber 1994) in the context of translation. LCFRS allows grammar nonterminals to generate more than one span in the final string; the number of spans produced by an LCFRS nonterminal corresponds to the rank of an MBOT state. Our second result states that the translations produced by MBOTs are equivalent to a specific restricted form of LCFRS, which we call 1-m-LCFRS. From the construction relating MBOTs and 1-</context>
</contexts>
<marker>Joshi, Schabes, 1997</marker>
<rawString>Joshi, A. K. and Y. Schabes. 1997. Tree-adjoining grammars. In G. Rozenberg and A. Salomaa, editors, Handbook of Formal Languages, volume 3. Springer, Berlin, pages 69–124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Lilin</author>
</authors>
<title>Propri´et´es de clˆoture d’une extension de transducteurs d’arbres d´eterministes.</title>
<date>1981</date>
<booktitle>In CAAP,</booktitle>
<volume>112</volume>
<pages>280--289</pages>
<publisher>Springer,</publisher>
<location>Berlin,</location>
<contexts>
<context position="1715" citStr="Lilin 1981" startWordPosition="256" endWordPosition="257">onterminals correspond to nonterminals in these parse trees. Chiang’s (2007) Hiero system produces simpler STSGs with a single nonterminal. STSGs have the advantage that they can naturally express many re-ordering and restructuring operations necessary for machine translation (MT). They have the disadvantage, however, that they are not closed under composition (Maletti et al. 2009). Therefore, if one wishes to construct an MT system as a pipeline of STSG operations, the result may not be expressible as an STSG. Recently, Maletti (2010) has argued that multi bottom–up tree transducers (MBOTs) (Lilin 1981; Arnold and Dauchet 1982; Engelfriet, Lilin, and Maletti 2009) provide a useful representation for natural language processing applications because they generalize STSGs, but have the added advantage of being closed under composition. MBOTs generalize traditional bottom–up tree transducers in that they allow transducer states to pass more than one output subtree up to subsequent transducer operations. The number of subtrees taken by a state is called its rank. MBOTs are linear and non-deleting; that is, operations cannot copy or delete arbitrarily large tree fragments. Although STSGs and MBOT</context>
<context position="7397" citStr="Lilin 1981" startWordPosition="1176" endWordPosition="1177"> an element of TE if a is an element of E with rank 3, and b, c, and d are elements of E with rank 0. Similarly, given a ranked alphabet E and a set X, E(X) denotes the set of trees consisting of a single symbol of E of rank k dominating a sequence of k elements from X. We use TE(X) to denote the set of arbitrarily sized trees constructed from ranked alphabet E having items from set X at some leaf positions. That is, TE(X) is the smallest set such that X C TE(X) and u(t1, ... , tk) E TE(X) if u is an element of E with rank k, and t1, ... , tk E TE(X). A multi bottom–up tree transducer (MBOT) (Lilin 1981; Arnold and Dauchet 1982; Engelfriet, Lilin, and Maletti 2009; Maletti 2010) is a system (S, E, ∆, F, R) where: • S, E, and ∆ are ranked alphabets of states, input symbols, and output symbols, respectively. • F C S is a set of accepting states. • R is a finite set of rules l -+ r where, using a set of variables X, l E TE(S(X)), and r E S(To(X)) such that: – every x E X that occurs in l occurs exactly once in r and vice versa, and – l E� S(X) or r E� S(X). One step in an MBOT transduction is performed by rewriting a local tree fragment as specified by one of the rules in R. We replace the frag</context>
</contexts>
<marker>Lilin, 1981</marker>
<rawString>Lilin, Eric. 1981. Propri´et´es de clˆoture d’une extension de transducteurs d’arbres d´eterministes. In CAAP, volume 112 of LNCS. Springer, Berlin, pages 280–289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Maletti</author>
</authors>
<title>Why synchronous tree substitution grammars?</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL-10),</booktitle>
<pages>876--884</pages>
<location>Los Angeles, CA.</location>
<contexts>
<context position="1646" citStr="Maletti (2010)" startWordPosition="246" endWordPosition="247">l text that has been automatically parsed in one language, and the STSG nonterminals correspond to nonterminals in these parse trees. Chiang’s (2007) Hiero system produces simpler STSGs with a single nonterminal. STSGs have the advantage that they can naturally express many re-ordering and restructuring operations necessary for machine translation (MT). They have the disadvantage, however, that they are not closed under composition (Maletti et al. 2009). Therefore, if one wishes to construct an MT system as a pipeline of STSG operations, the result may not be expressible as an STSG. Recently, Maletti (2010) has argued that multi bottom–up tree transducers (MBOTs) (Lilin 1981; Arnold and Dauchet 1982; Engelfriet, Lilin, and Maletti 2009) provide a useful representation for natural language processing applications because they generalize STSGs, but have the added advantage of being closed under composition. MBOTs generalize traditional bottom–up tree transducers in that they allow transducer states to pass more than one output subtree up to subsequent transducer operations. The number of subtrees taken by a state is called its rank. MBOTs are linear and non-deleting; that is, operations cannot cop</context>
<context position="7474" citStr="Maletti 2010" startWordPosition="1187" endWordPosition="1188"> elements of E with rank 0. Similarly, given a ranked alphabet E and a set X, E(X) denotes the set of trees consisting of a single symbol of E of rank k dominating a sequence of k elements from X. We use TE(X) to denote the set of arbitrarily sized trees constructed from ranked alphabet E having items from set X at some leaf positions. That is, TE(X) is the smallest set such that X C TE(X) and u(t1, ... , tk) E TE(X) if u is an element of E with rank k, and t1, ... , tk E TE(X). A multi bottom–up tree transducer (MBOT) (Lilin 1981; Arnold and Dauchet 1982; Engelfriet, Lilin, and Maletti 2009; Maletti 2010) is a system (S, E, ∆, F, R) where: • S, E, and ∆ are ranked alphabets of states, input symbols, and output symbols, respectively. • F C S is a set of accepting states. • R is a finite set of rules l -+ r where, using a set of variables X, l E TE(S(X)), and r E S(To(X)) such that: – every x E X that occurs in l occurs exactly once in r and vice versa, and – l E� S(X) or r E� S(X). One step in an MBOT transduction is performed by rewriting a local tree fragment as specified by one of the rules in R. We replace the fragment l with r, copying the subtree under each variable in l to the location o</context>
<context position="28071" citStr="Maletti (2010)" startWordPosition="4795" endWordPosition="4796">the MBOT’s input alphabet contains a symbol S for each LCFRS nonterminal S, and the MBOT’s output alphabet contains y(S) symbols Si for each LCFRS nonterminal S. This construction for converting an LCFRS to an MBOT shows that LCFRS C target(yield(MBOT)). Given our earlier construction for generating the target projection of the LCFRS derived from an MBOT, we know that target(yield(MBOT)) C LCFRS. Combining these two facts yields the theorem. ■ 4. Composition of STSGs Maletti et al. (2009) discuss the composition of extended top–down tree transducers, which are equivalent to STSGs, as shown by Maletti (2010). They show that this formalism is not closed under composition in terms of the tree transformations that are possible. In this article, we focus on the string yields of the formalisms under discussion, and from this point of view we now examine the question of whether the yield of the composition of two STSGs is itself the yield of an STSG in general. It is important to note that, although we focus on the yield of the composition, in our notion of STSG composition, the tree structure output by the first STSG still serves as input to the second STSG. Maletti et al. (2009) give two tree transfo</context>
<context position="46282" citStr="Maletti (2010)" startWordPosition="8086" endWordPosition="8087">sult of intersecting the source of Tcrisscross with the regular language a[c+d+]Ea. By Lemma 8, we can construct an SCFG GE generating TEcrisscross. By Lemma 7, for each f, GE has rank at least 2f. The intersection construction does not increase the rank of the grammar, so G has rank at least 2f. Because f is unbounded in the definition of Tcrisscross, and because any SCFG has a finite maximum rank, Tcrisscross cannot be produced by any SCFG. ■ 4.1 Implications for Machine Translation The ability of MBOTs to represent the composition of STSGs is given as a motivation for the MBOT formalism by Maletti (2010), but this raises the issue of whether synchronous parsing and machine translation decoding can be undertaken efficiently for MBOTs resulting from the composition of STSGs. In discussing the complexity of synchronous parsing problems, we distinguish the case where the grammar is considered part of the input, and the case where the grammar is fixed, and only the source and target strings are considered part of the input. For SCFGs, synchronous parsing is NP-complete when the grammar is considered part of the input and can have arbitrary rank. For any fixed grammar, however, synchronous parsing </context>
</contexts>
<marker>Maletti, 2010</marker>
<rawString>Maletti, Andreas. 2010. Why synchronous tree substitution grammars? In Proceedings of the 2010 Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL-10), pages 876–884, Los Angeles, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Maletti</author>
<author>Jonathan Graehl</author>
<author>Mark Hopkins</author>
<author>Kevin Knight</author>
</authors>
<title>The power of extended top–down tree transducers.</title>
<date>2009</date>
<journal>SIAM Journal on Computing,</journal>
<pages>39--410</pages>
<contexts>
<context position="1489" citStr="Maletti et al. 2009" startWordPosition="217" endWordPosition="220">es in parallel, with each rule producing a tree fragment in either language. Systems such as that of Galley et al. (2006) extract STSG rules from parallel bilingual text that has been automatically parsed in one language, and the STSG nonterminals correspond to nonterminals in these parse trees. Chiang’s (2007) Hiero system produces simpler STSGs with a single nonterminal. STSGs have the advantage that they can naturally express many re-ordering and restructuring operations necessary for machine translation (MT). They have the disadvantage, however, that they are not closed under composition (Maletti et al. 2009). Therefore, if one wishes to construct an MT system as a pipeline of STSG operations, the result may not be expressible as an STSG. Recently, Maletti (2010) has argued that multi bottom–up tree transducers (MBOTs) (Lilin 1981; Arnold and Dauchet 1982; Engelfriet, Lilin, and Maletti 2009) provide a useful representation for natural language processing applications because they generalize STSGs, but have the added advantage of being closed under composition. MBOTs generalize traditional bottom–up tree transducers in that they allow transducer states to pass more than one output subtree up to su</context>
<context position="27950" citStr="Maletti et al. (2009)" startWordPosition="4775" endWordPosition="4778"> the MBOT rule: S -+ S B1 · · ·Br S1 ··· Sy(S) x1,1 ... x1,y(B1) xr,1 ... xr,y(Br) t1,1 ··· t1,n1 ty(S),1 ··· ty(S),nϕ(S) where the MBOT’s input alphabet contains a symbol S for each LCFRS nonterminal S, and the MBOT’s output alphabet contains y(S) symbols Si for each LCFRS nonterminal S. This construction for converting an LCFRS to an MBOT shows that LCFRS C target(yield(MBOT)). Given our earlier construction for generating the target projection of the LCFRS derived from an MBOT, we know that target(yield(MBOT)) C LCFRS. Combining these two facts yields the theorem. ■ 4. Composition of STSGs Maletti et al. (2009) discuss the composition of extended top–down tree transducers, which are equivalent to STSGs, as shown by Maletti (2010). They show that this formalism is not closed under composition in terms of the tree transformations that are possible. In this article, we focus on the string yields of the formalisms under discussion, and from this point of view we now examine the question of whether the yield of the composition of two STSGs is itself the yield of an STSG in general. It is important to note that, although we focus on the yield of the composition, in our notion of STSG composition, the tree</context>
<context position="29459" citStr="Maletti et al. (2009)" startWordPosition="5037" endWordPosition="5040">n STSG rule that simply copies the three variables with no re-ordering. Thus, these counterexamples are not sufficient to show that the yield of the composition of two STSGs is not the yield of an STSG. We now present two STSGs, shown in MBOT notation in Figures 5 and 6, whose composition is not a translation produced by an STSG. The essence of this counterexample, explained in more detail subsequently, is that rules from the two STSGs apply in an overlapping manner to unboundedly long sequences, as in the example of Arnold Figure 4 Examples of tree transformations not contained in STSG, from Maletti et al. (2009). Here Gn denotes a unary chain of G’s of arbitrary length. 683 Computational Linguistics Volume 38, Number 3 Figure 5 First MBOT in composition. and Dauchet (1982, section 3.4). To this approach we add a re-ordering pattern which results in a translation that we will show not to be possible with STSG. The heart of each MBOT is the first rule, which reverses the order of adjacent sequences of c’s and d’s. The MBOT of Figure 5 generates the translation: J(a[cn2i−1dn2i]e i=1a, a[dn2icn2i−1]E1a) |ni &gt; 1,$ &gt; 1} where f is the number of times the first rule of the transducer is applied, and the not</context>
</contexts>
<marker>Maletti, Graehl, Hopkins, Knight, 2009</marker>
<rawString>Maletti, Andreas, Jonathan Graehl, Mark Hopkins, and Kevin Knight. 2009. The power of extended top–down tree transducers. SIAM Journal on Computing, 39:410–430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>Multitext grammars and synchronous parsers.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL-03),</booktitle>
<pages>158--165</pages>
<location>Edmonton.</location>
<contexts>
<context position="5178" citStr="Melamed (2003)" startWordPosition="787" endWordPosition="788">he translations produced by MBOTs are equivalent to a specific restricted form of LCFRS, which we call 1-m-LCFRS. From the construction relating MBOTs and 1-m-LCFRSs follow results about the source and target sides of the translations produced by MBOTs. In particular, our third result is that the translations produced by MBOTs are context-free within the source language, and hence are strictly less powerful than LCFRSs. This implies that MBOTs are not as general as STAGs, for example. Similarly, MBOTs are not as general as the generalized multitext grammars proposed for machine translation by Melamed (2003), which retain the full power of LCFRSs in each language (Melamed, Satta, and Wellington 2004). Our fourth result is that the output of an MBOT, when viewed as a string language, does retain the full power of LCFRSs. This fact is mentioned by Engelfriet, Lilin, and Maletti (2009, page 586), although no explicit construction is given. Our final result specifically addresses the string translations that result from compositions of STSGs, with the goal of better understanding the complexity of using such compositions in machine translation systems. We show that the translations produced by compos</context>
</contexts>
<marker>Melamed, 2003</marker>
<rawString>Melamed, I. Dan. 2003. Multitext grammars and synchronous parsers. In Proceedings of the 2003 Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL-03), pages 158–165, Edmonton.</rawString>
</citation>
<citation valid="false">
<authors>
<author>I Dan Melamed</author>
</authors>
<location>Giorgio Satta, and</location>
<marker>Melamed, </marker>
<rawString>Melamed, I. Dan, Giorgio Satta, and</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Wellington</author>
</authors>
<title>Generalized multitext grammars.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Conference of the Association for Computational Linguistics (ACL-04),</booktitle>
<pages>661--668</pages>
<location>Barcelona.</location>
<contexts>
<context position="5272" citStr="Wellington 2004" startWordPosition="802" endWordPosition="803">ch we call 1-m-LCFRS. From the construction relating MBOTs and 1-m-LCFRSs follow results about the source and target sides of the translations produced by MBOTs. In particular, our third result is that the translations produced by MBOTs are context-free within the source language, and hence are strictly less powerful than LCFRSs. This implies that MBOTs are not as general as STAGs, for example. Similarly, MBOTs are not as general as the generalized multitext grammars proposed for machine translation by Melamed (2003), which retain the full power of LCFRSs in each language (Melamed, Satta, and Wellington 2004). Our fourth result is that the output of an MBOT, when viewed as a string language, does retain the full power of LCFRSs. This fact is mentioned by Engelfriet, Lilin, and Maletti (2009, page 586), although no explicit construction is given. Our final result specifically addresses the string translations that result from compositions of STSGs, with the goal of better understanding the complexity of using such compositions in machine translation systems. We show that the translations produced by compositions of STSGs are more powerful than those produced by single STSGs, or, equivalently, by SC</context>
<context position="11658" citStr="Wellington (2004)" startWordPosition="1956" endWordPosition="1957">ning the productions’ functions contain just one string. Just as CFG is equivalent to LCFRS with fan-out 1, SCFG and TAG can be represented as LCFRS with fan-out 2. Higher values of fan-out allow strictly more powerful grammars (Rambow and Satta 1999). Polynomial-time parsing is possible for any fixed LCFRS grammar, but the degree of 676 Gildea On the String Translations Produced by Multi Bottom–Up Tree Transducers the polynomial depends on the grammar. Parsing general LCFRS grammars, where the grammar is considered part of the input, is NP-complete (Satta 1992). Following Melamed, Satta, and Wellington (2004), we represent translation in LCFRS by using a special symbol # to separate the strings of the two languages. Our LCFRS grammars will only generate strings of the form s#t, where s and t are strings not containing the symbol #, and we will identify s as the source string and t as the target string. We use the notation trans(LCFRS) to denote the set of translations that can be produced by taking the string language of some LCFRS and splitting each string into a pair at the location of the # symbol. 3. Translations Produced by General MBOTs In this section, we relate the yield of general MBOTs t</context>
</contexts>
<marker>Wellington, 2004</marker>
<rawString>Ben Wellington. 2004. Generalized multitext grammars. In Proceedings of the 42nd Annual Conference of the Association for Computational Linguistics (ACL-04), pages 661–668, Barcelona.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William F Ogden</author>
</authors>
<title>A helpful result for proving inherent ambiguity.</title>
<date>1968</date>
<booktitle>Mathematical Systems Theory,</booktitle>
<pages>2--3</pages>
<contexts>
<context position="36803" citStr="Ogden 1968" startWordPosition="6296" endWordPosition="6297"> r. Proof From each rule in the derivation producing preterminal permutation π, construct a new rule by removing any nonterminals whose indices were removed from π. The resulting sequence of rules produces preterminal permutation πe and contains rules of rank no greater than r. ■ As an example of Lemma 3, removing any element from the permutation (3,2,1) results in the permutation (2,1), which can still (trivially) be produced by an SCFG of rank 2. 687 Computational Linguistics Volume 38, Number 3 We will make use of another general fact about SCFGs, which we derive by applying Ogden’s Lemma (Ogden 1968), a generalized pumping lemma for context-free languages, to the source language of an SCFG. Lemma 4 (Ogden’s Lemma) For each context-free grammar G = (V, E, P, S) there is an integer k such that for any word ξ in L(G), if any k or more distinct positions in ξ are designated as distinguished, then there is some A in V and there are words α, β, γ, δ, and µ in E∗ such that: • S =&gt;∗ αAµ =&gt;∗ αβAδµ =&gt;∗ αβγδµ = ξ, and hence αβmγδmµ E L(G) for all m &gt; 0. • γ contains at least one of the distinguished positions. • Either α and β both contain distinguished positions, or δ and µ both contain distinguish</context>
</contexts>
<marker>Ogden, 1968</marker>
<rawString>Ogden, William F. 1968. A helpful result for proving inherent ambiguity. Mathematical Systems Theory, 2(3):191–194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Owen Rambow</author>
<author>Giorgio Satta</author>
</authors>
<title>Independent parallelism in finite copying parallel rewriting systems.</title>
<date>1999</date>
<journal>Theoretical Computer Science,</journal>
<pages>223--1</pages>
<contexts>
<context position="11292" citStr="Rambow and Satta 1999" startWordPosition="1900" endWordPosition="1903">imply as a derivation. As an example of how the LCFRS framework subsumes grammatical formalisms such as CFG, consider the following CFG: S AB A a B b This grammar corresponds to the following grammar in LCFRS notation: S gS(A,B) gS((sA),(sB)) = (sAsB) A gA() gA() = (a) B gB() gB() = (b) Here, all nonterminals have fan-out one, reflected in the fact that all tuples defining the productions’ functions contain just one string. Just as CFG is equivalent to LCFRS with fan-out 1, SCFG and TAG can be represented as LCFRS with fan-out 2. Higher values of fan-out allow strictly more powerful grammars (Rambow and Satta 1999). Polynomial-time parsing is possible for any fixed LCFRS grammar, but the degree of 676 Gildea On the String Translations Produced by Multi Bottom–Up Tree Transducers the polynomial depends on the grammar. Parsing general LCFRS grammars, where the grammar is considered part of the input, is NP-complete (Satta 1992). Following Melamed, Satta, and Wellington (2004), we represent translation in LCFRS by using a special symbol # to separate the strings of the two languages. Our LCFRS grammars will only generate strings of the form s#t, where s and t are strings not containing the symbol #, and we</context>
</contexts>
<marker>Rambow, Satta, 1999</marker>
<rawString>Rambow, Owen and Giorgio Satta. 1999. Independent parallelism in finite copying parallel rewriting systems. Theoretical Computer Science, 223(1-2):87–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giorgio Satta</author>
</authors>
<title>Recognition of Linear Context-Free Rewriting Systems.</title>
<date>1992</date>
<booktitle>In Proceedings of the 30th Annual Conference of the Association for Computational Linguistics (ACL-92),</booktitle>
<pages>89--95</pages>
<location>Newark, DE.</location>
<contexts>
<context position="11609" citStr="Satta 1992" startWordPosition="1950" endWordPosition="1951"> reflected in the fact that all tuples defining the productions’ functions contain just one string. Just as CFG is equivalent to LCFRS with fan-out 1, SCFG and TAG can be represented as LCFRS with fan-out 2. Higher values of fan-out allow strictly more powerful grammars (Rambow and Satta 1999). Polynomial-time parsing is possible for any fixed LCFRS grammar, but the degree of 676 Gildea On the String Translations Produced by Multi Bottom–Up Tree Transducers the polynomial depends on the grammar. Parsing general LCFRS grammars, where the grammar is considered part of the input, is NP-complete (Satta 1992). Following Melamed, Satta, and Wellington (2004), we represent translation in LCFRS by using a special symbol # to separate the strings of the two languages. Our LCFRS grammars will only generate strings of the form s#t, where s and t are strings not containing the symbol #, and we will identify s as the source string and t as the target string. We use the notation trans(LCFRS) to denote the set of translations that can be produced by taking the string language of some LCFRS and splitting each string into a pair at the location of the # symbol. 3. Translations Produced by General MBOTs In thi</context>
</contexts>
<marker>Satta, 1992</marker>
<rawString>Satta, Giorgio. 1992. Recognition of Linear Context-Free Rewriting Systems. In Proceedings of the 30th Annual Conference of the Association for Computational Linguistics (ACL-92), pages 89–95, Newark, DE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giorgio Satta</author>
<author>Enoch Peserico</author>
</authors>
<title>Some computational complexity results for synchronous context-free grammars.</title>
<date>2005</date>
<booktitle>In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP),</booktitle>
<pages>803--810</pages>
<location>Vancouver.</location>
<contexts>
<context position="47061" citStr="Satta and Peserico 2005" startWordPosition="8210" endWordPosition="8213">osition of STSGs. In discussing the complexity of synchronous parsing problems, we distinguish the case where the grammar is considered part of the input, and the case where the grammar is fixed, and only the source and target strings are considered part of the input. For SCFGs, synchronous parsing is NP-complete when the grammar is considered part of the input and can have arbitrary rank. For any fixed grammar, however, synchronous parsing is possible in time polynomial in the lengths of the source and target strings, with the degree of the polynomial depending on the rank of the fixed SCFG (Satta and Peserico 2005). Because MBOTs subsume SCFGs, the problem of recognizing whether a string pair belongs to the translation produced by an arbitrary MBOT, when the MBOT is considered part of the input, is also NP-complete. Given our construction for converting an MBOT to an LCFRS, we can use standard LCFRS tabular parsing techniques to determine whether a given string pair belongs to the translation defined by the yield of a fixed MBOT. As with arbitrary-rank SCFG, LCFRS parsing is polynomial in the length of the input string pair, but the degree of the polynomial depends on the complexity of the MBOT. To be p</context>
</contexts>
<marker>Satta, Peserico, 2005</marker>
<rawString>Satta, Giorgio and Enoch Peserico. 2005. Some computational complexity results for synchronous context-free grammars. In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP), pages 803–810, Vancouver.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Schabes</author>
<author>Stuart M Shieber</author>
</authors>
<title>An alternative conception of tree-adjoining derivation.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<pages>20--91</pages>
<contexts>
<context position="4320" citStr="Schabes and Shieber 1994" startWordPosition="648" endWordPosition="651"> formalisms, and the fifth result addresses MBOTs resulting from compositions of STSGs in particular. Our first result is that the translations produced by MBOTs are a subset of those produced by linear context-free rewriting systems (LCFRSs) (Vijay-Shankar, Weir, and Joshi 1987). LCFRS provides a very general framework that subsumes CFG, tree adjoining grammar (TAG; Joshi, Levy, and Takahashi 1975; Joshi and Schabes 1997), and more complex systems, as well as synchronous context-free grammar (SCFG) (Aho and Ullman 1972) and synchronous tree adjoining grammar (STAG) (Shieber and Schabes 1990; Schabes and Shieber 1994) in the context of translation. LCFRS allows grammar nonterminals to generate more than one span in the final string; the number of spans produced by an LCFRS nonterminal corresponds to the rank of an MBOT state. Our second result states that the translations produced by MBOTs are equivalent to a specific restricted form of LCFRS, which we call 1-m-LCFRS. From the construction relating MBOTs and 1-m-LCFRSs follow results about the source and target sides of the translations produced by MBOTs. In particular, our third result is that the translations produced by MBOTs are context-free within the</context>
<context position="26500" citStr="Schabes and Shieber 1994" startWordPosition="4533" endWordPosition="4536"> projection is the target side of the translation of the full LCFRS. ■ Lemma 2 implies that it is safe to evaluate the power of the source and target projections of the LCFRS independently. This fact leads to our next result. Theorem 3 yield(MBOT) C trans(LCFRS). Proof In the LCFRS generated by our construction, all nonterminals have fan-out 1 in the source side of the translation. Therefore, the source side of the translation is a contextfree language, and an MBOT cannot represent the following translation: {(anbncndn, anbncndn) |n &gt; 1} which is produced by an STAG (Shieber and Schabes 1990; Schabes and Shieber 1994). Because STAG is a type of LCFRS, yield(MBOT) C trans(LCFRS). ■ Although the source side of the translation produced by an MBOT must be a context-free language, we now show that the target side can be any language produced by an LCFRS. Theorem 4 target(yield(MBOT)) = LCFRS Proof Given an input LCFRS, we can construct an MBOT whose target side corresponds to the rules in the original LCFRS, and whose source simply accepts derivation trees of the LCFRS. To make this precise, given an LCFRS rule in the general form: S -+ g(B1,...,Br) g((x1,1,...,x1,ϕ(B1)),...,(x1,1,...,x1,ϕ(Br))) = (t1,1 ··· t1,</context>
</contexts>
<marker>Schabes, Shieber, 1994</marker>
<rawString>Schabes, Yves and Stuart M. Shieber. 1994. An alternative conception of tree-adjoining derivation. Computational Linguistics, 20:91–124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Seki</author>
<author>T Matsumura</author>
<author>M Fujii</author>
<author>T Kasami</author>
</authors>
<title>On multiple context-free grammars.</title>
<date>1991</date>
<journal>Theoretical Computer Science,</journal>
<pages>88--191</pages>
<contexts>
<context position="47749" citStr="Seki et al. 1991" startWordPosition="8327" endWordPosition="8330">ing pair belongs to the translation produced by an arbitrary MBOT, when the MBOT is considered part of the input, is also NP-complete. Given our construction for converting an MBOT to an LCFRS, we can use standard LCFRS tabular parsing techniques to determine whether a given string pair belongs to the translation defined by the yield of a fixed MBOT. As with arbitrary-rank SCFG, LCFRS parsing is polynomial in the length of the input string pair, but the degree of the polynomial depends on the complexity of the MBOT. To be precise, the degree of the polynomial for LCFRS parsing is Eri=0 y(Si) (Seki et al. 1991), which yields Eri=0(1 + d(Si)) when applied to MBOTs. If we restrict ourselves to MBOTs that are derived from the composition of STSGs, synchronous parsing is NP-complete if the STSGs to compose are part of the input, because a single STSG suffices. For a composition of fixed STSGs, we obtain a fixed MBOT, and polynomial time parsing is possible. Theorem 5 indicates that we cannot apply SCFG parsing techniques off the shelf, but rather that we must implement some type of more general parsing system. Either of the STSGs used in our proof of Theorem 5 691 Computational Linguistics Volume 38, Nu</context>
</contexts>
<marker>Seki, Matsumura, Fujii, Kasami, 1991</marker>
<rawString>Seki, H., T. Matsumura, M. Fujii, and T. Kasami. 1991. On multiple context-free grammars. Theoretical Computer Science, 88:191–229.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Shieber</author>
<author>Yves Schabes</author>
</authors>
<title>Synchronous tree-adjoining grammars.</title>
<date>1990</date>
<booktitle>In Proceedings of the 13th International Conference on Computational Linguistics (COLING-90), volume III,</booktitle>
<pages>253--258</pages>
<location>Helsinki.</location>
<contexts>
<context position="4293" citStr="Shieber and Schabes 1990" startWordPosition="644" endWordPosition="647">general MBOTs among string formalisms, and the fifth result addresses MBOTs resulting from compositions of STSGs in particular. Our first result is that the translations produced by MBOTs are a subset of those produced by linear context-free rewriting systems (LCFRSs) (Vijay-Shankar, Weir, and Joshi 1987). LCFRS provides a very general framework that subsumes CFG, tree adjoining grammar (TAG; Joshi, Levy, and Takahashi 1975; Joshi and Schabes 1997), and more complex systems, as well as synchronous context-free grammar (SCFG) (Aho and Ullman 1972) and synchronous tree adjoining grammar (STAG) (Shieber and Schabes 1990; Schabes and Shieber 1994) in the context of translation. LCFRS allows grammar nonterminals to generate more than one span in the final string; the number of spans produced by an LCFRS nonterminal corresponds to the rank of an MBOT state. Our second result states that the translations produced by MBOTs are equivalent to a specific restricted form of LCFRS, which we call 1-m-LCFRS. From the construction relating MBOTs and 1-m-LCFRSs follow results about the source and target sides of the translations produced by MBOTs. In particular, our third result is that the translations produced by MBOTs </context>
<context position="26473" citStr="Shieber and Schabes 1990" startWordPosition="4529" endWordPosition="4532">age produced by the target projection is the target side of the translation of the full LCFRS. ■ Lemma 2 implies that it is safe to evaluate the power of the source and target projections of the LCFRS independently. This fact leads to our next result. Theorem 3 yield(MBOT) C trans(LCFRS). Proof In the LCFRS generated by our construction, all nonterminals have fan-out 1 in the source side of the translation. Therefore, the source side of the translation is a contextfree language, and an MBOT cannot represent the following translation: {(anbncndn, anbncndn) |n &gt; 1} which is produced by an STAG (Shieber and Schabes 1990; Schabes and Shieber 1994). Because STAG is a type of LCFRS, yield(MBOT) C trans(LCFRS). ■ Although the source side of the translation produced by an MBOT must be a context-free language, we now show that the target side can be any language produced by an LCFRS. Theorem 4 target(yield(MBOT)) = LCFRS Proof Given an input LCFRS, we can construct an MBOT whose target side corresponds to the rules in the original LCFRS, and whose source simply accepts derivation trees of the LCFRS. To make this precise, given an LCFRS rule in the general form: S -+ g(B1,...,Br) g((x1,1,...,x1,ϕ(B1)),...,(x1,1,...</context>
</contexts>
<marker>Shieber, Schabes, 1990</marker>
<rawString>Shieber, Stuart and Yves Schabes. 1990. Synchronous tree-adjoining grammars. In Proceedings of the 13th International Conference on Computational Linguistics (COLING-90), volume III, pages 253–258, Helsinki.</rawString>
</citation>
<citation valid="false">
<authors>
<author>K Vijay-Shankar</author>
<author>D L Weir</author>
<author>A K Joshi 1987</author>
</authors>
<title>Characterizing structural descriptions produced by various grammatical formalisms.</title>
<booktitle>In Proceedings of the 25th Annual Conference of the Association for Computational Linguistics (ACL-87),</booktitle>
<pages>104--111</pages>
<location>Stanford, CA.</location>
<marker>Vijay-Shankar, Weir, 1987, </marker>
<rawString>Vijay-Shankar, K., D. L. Weir, and A. K. Joshi.1987. Characterizing structural descriptions produced by various grammatical formalisms. In Proceedings of the 25th Annual Conference of the Association for Computational Linguistics (ACL-87), pages 104–111, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>3</issue>
<contexts>
<context position="35775" citStr="Wu 1997" startWordPosition="6128" endWordPosition="6129">ly in the source side of the sentential form, we refer to the sequence of indices in the target side as the preterminal permutation of a derivation. For example, the preterminal permutation of the derivation in Figure 10 is (3,2,1). The permutation of any sentential form of an SCFG of rank r can be produced by composing permutations of length no greater than r, by induction over the length of the derivation. Thus, while the permutation (3,2,1) of our example can be produced by composing permutations of length 2, the preterminal permutation (2,4,1,3) can never be produced by an SCFG of rank 2 (Wu 1997). In fact, this restriction also applies to subsequences of the preterminal permutation. Lemma 3 Let π be a preterminal permutation produced by an SCFG derivation containing rules of maximum rank r, and let πe be a permutation obtained from π by removing some elements and renumbering the remaining elements with a strictly increasing function. Then πe falls within the class of compositions of permutations of length r. Proof From each rule in the derivation producing preterminal permutation π, construct a new rule by removing any nonterminals whose indices were removed from π. The resulting sequ</context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>Wu, Dekai. 1997. Stochastic inversion transduction grammars and bilingual parsing of parallel corpora. Computational Linguistics, 23(3):377–403.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Yamada</author>
<author>Kevin Knight</author>
</authors>
<title>A decoder for syntax-based statistical MT.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Conference of the Association for Computational Linguistics (ACL-02),</booktitle>
<pages>303--310</pages>
<location>Philadelphia, PA.</location>
<contexts>
<context position="3238" citStr="Yamada and Knight (2002)" startWordPosition="482" endWordPosition="485">er NY 14627. E-mail: gildea@cs.rochester.edu. Submission received: 3 May 2011; revised submission received:1 October 2011; accepted for publication: 28 October 2011. © 2012 Association for Computational Linguistics Computational Linguistics Volume 38, Number 3 in one natural language into a string in another. Whereas MBOTs originate in the tree transducer literature and are defined to take a tree as input, MT systems such as those of Galley et al. (2006) and Chiang (2007) find a parse of the source language sentence as part of the translation process, and the decoding algorithm, introduced by Yamada and Knight (2002), has more in common with CYK parsing than with simulating a tree transducer. In this article, we investigate the power of MBOTs, and of compositions of STSGs in particular, in terms of the set of string translations that they generate. We relate MBOTs and compositions of STSGs to existing grammatical formalisms defined on strings through five main results, which we outline subsequently. The first four results serve to situate general MBOTs among string formalisms, and the fifth result addresses MBOTs resulting from compositions of STSGs in particular. Our first result is that the translations</context>
<context position="48931" citStr="Yamada and Knight 2002" startWordPosition="8511" endWordPosition="8514"> Computational Linguistics Volume 38, Number 3 can be binarized and synchronously parsed in time O(n6), but tabular parsing for the LCFRS resulting from composition has higher complexity. Thus, composing STSGs generally increases the complexity of synchronous parsing. The problem of language-model–integrated decoding with synchronous grammars is closely related to that of synchronous parsing; both problems can be seen as intersecting the grammar with a fixed source-language string and a finite-state machine constraining the target-language string. The widely used decoding algorithms for SCFG (Yamada and Knight 2002; Zollmann and Venugopal 2006; Huang et al. 2009) search for the highest-scoring translation when combining scores from a weighted SCFG and a weighted finite-state language model. As with SCFG, language-model–integrated decoding for weighted MBOTs can be performed by adding n-gram language model state to each candidate target language span. This, as with synchronous parsing, gives an algorithm which is polynomial in the length of the input sentence for a fixed MBOT, but with an exponent that depends on the complexity of the MBOT. Furthermore, Theorem 5 indicates that SCFG-based decoding techni</context>
</contexts>
<marker>Yamada, Knight, 2002</marker>
<rawString>Yamada, Kenji and Kevin Knight. 2002. A decoder for syntax-based statistical MT. In Proceedings of the 40th Annual Conference of the Association for Computational Linguistics (ACL-02), pages 303–310, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Zollmann</author>
<author>Ashish Venugopal</author>
</authors>
<title>Syntax augmented machine translation via chart parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the Workshop on Statistical Machine Translation,</booktitle>
<pages>138--141</pages>
<location>New York, NY.</location>
<contexts>
<context position="48960" citStr="Zollmann and Venugopal 2006" startWordPosition="8515" endWordPosition="8518">cs Volume 38, Number 3 can be binarized and synchronously parsed in time O(n6), but tabular parsing for the LCFRS resulting from composition has higher complexity. Thus, composing STSGs generally increases the complexity of synchronous parsing. The problem of language-model–integrated decoding with synchronous grammars is closely related to that of synchronous parsing; both problems can be seen as intersecting the grammar with a fixed source-language string and a finite-state machine constraining the target-language string. The widely used decoding algorithms for SCFG (Yamada and Knight 2002; Zollmann and Venugopal 2006; Huang et al. 2009) search for the highest-scoring translation when combining scores from a weighted SCFG and a weighted finite-state language model. As with SCFG, language-model–integrated decoding for weighted MBOTs can be performed by adding n-gram language model state to each candidate target language span. This, as with synchronous parsing, gives an algorithm which is polynomial in the length of the input sentence for a fixed MBOT, but with an exponent that depends on the complexity of the MBOT. Furthermore, Theorem 5 indicates that SCFG-based decoding techniques cannot be applied off th</context>
</contexts>
<marker>Zollmann, Venugopal, 2006</marker>
<rawString>Zollmann, Andreas and Ashish Venugopal. 2006. Syntax augmented machine translation via chart parsing. In Proceedings of the Workshop on Statistical Machine Translation, pages 138–141, New York, NY.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>