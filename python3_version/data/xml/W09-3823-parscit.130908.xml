<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001748">
<title confidence="0.988415">
Guessing the Grammatical Function of a Non-Root F-Structure in LFG
</title>
<author confidence="0.980135">
Anton Bryl
</author>
<affiliation confidence="0.739124">
CNGL,
Dublin City University,
Dublin 9, Ireland
</affiliation>
<note confidence="0.541805">
Josef van Genabith
CNGL,
Dublin City University,
Dublin 9, Ireland
</note>
<author confidence="0.766856">
Yvette Graham
</author>
<affiliation confidence="0.8211205">
NCLT,
Dublin City University,
</affiliation>
<address confidence="0.802149">
Dublin 9, Ireland
</address>
<email confidence="0.94556">
{abryl,josef,ygraham}@computing.dcu.ie
</email>
<figure confidence="0.962010315789474">
Abstract
PRED ‘adopt’
PERS 3
NUM sg
PRED ‘resolution’
SPEC f2[ DET fg [PRED ‘the’] �
⎡
PERS 3
SUBJ fq ⎣NUM sg
PRED ‘Parliament’
⎡
⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎣
⎤
⎦⎥⎥⎥
⎤
⎦⎥⎥⎥⎥⎥⎥⎥
⎡
⎢ ⎢ ⎢ ⎣
UNKNOWN f1
</figure>
<bodyText confidence="0.984656">
Lexical-Functional Grammar (Kaplan and
Bresnan, 1982) f-structures are bilexical
labelled dependency representations. We
show that the Naive Bayes classifier is able
to guess missing grammatical function la-
bels (i.e. bilexical dependency labels) with
reasonably high accuracy (82–91%). In
the experiments we use f-structure parser
output for English and German Europarl
data, automatically “broken” by replacing
grammatical function labels with a generic
UNKNOWN label and asking the classifier
to restore the label.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99959356">
The task of labeling unlabelled dependencies, a
sub-task of dependency parsing task, can occur
in transfer-based machine translation (when only
an inexact match can be found in the training
data for the given SL fragment) or in parsing
where the system produces fragmented output. In
such cases it is often reasonably straightforward
to guess which fragments are dependent on which
other fragments (e.g. in transfer-based MT). What
is harder to guess are the labels of the dependen-
cies connecting the fragments.
In this paper we systematically investigate the
labelling task by automatically deleting function
labels from Lexical-Functional Grammar-based
parser output for German and English Europarl
data, and then restoring them using a Naive Bayes
classifier trained on attribute names and attribute
values of the f-structure fragments. We achieve
82% (German) to 91% (English) accuracy for both
single and multiple missing function labels.
The paper is organized as follows: in Section 2
we define the problem and the proposed solution
more formally. Section 3 details the experimental
evaluations, and in Section 4 we present our con-
clusions.
</bodyText>
<figureCaption confidence="0.544425333333333">
Figure 1: Example of a “broken” f-structure (sim-
plified). The sentence is ‘Parliament adopted the
resolution.’ The missing function of f1 is OBJ.
</figureCaption>
<sectionHeader confidence="0.9402625" genericHeader="keywords">
2 Guessing Unknown Grammatical
Functions
</sectionHeader>
<bodyText confidence="0.999920653846154">
Let us introduce some useful definitions. By de-
pendent f-structure of the parent f-structure fP we
mean an f-structure fd which bears a grammati-
cal function within fP, or belongs to a set which
bears a grammatical function within fP. E.g., in
Figure 1 f2 is a dependent f-structure of f1. In this
paper we will not distinguish between these two
situations, but simply refer to multiple f-structures
bearing the same function within the same parent
for set-valued grammatical functions. C(0, fP)
denotes the number of dependent f-structures of
fP which bear the grammatical function 0 in fP
(either directly or as members of a set).
Let us formalize the simple case when the gram-
matical function of only one dependent f-structure
is missing. Let FP be the set of f-structures which
have a dependent f-structure with an UNKNOWN la-
bel instead of the grammatical function. Let Φ be
the set of all grammatical functions of the given
grammar. We need a guessing function G : FP →
Φ, such that G(fP) is a meaningful replacement
for the UNKNOWN label in fP. As the set Φ is fi-
nite, the problem is evidently a classification task.
F-structures are characterized by attributes
some of which potentially carry information about
the f-structure’s grammatical function, even if
</bodyText>
<page confidence="0.966038">
146
</page>
<note confidence="0.3437415">
Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 146–149,
Paris, October 2009. c�2009 Association for Computational Linguistics
</note>
<table confidence="0.998094">
Language N-GF N-DEP AVG-DEP MIN-DEP MAX-DEP
English 24 9724 1.57 1 5
German 39 10910 1.55 1 5
</table>
<tableCaption confidence="0.998416">
Table 1: Data used in the evaluation. N-GF is the number of different grammatical functions occurring
</tableCaption>
<bodyText confidence="0.999650296296296">
in the dataset. N-DEP is the number of dependent f-structures in the test set. AVG-DEP, MIN-DEP,
MAX-DEP is the average, min. and max. number of dependant structures per parent in the test set.
we observe these attributes completely separately
from each other. For example, it seems likely
that an f-structure with an ATYPE attribute is an
ADJUNCT, while an f-structure which has CASE
is probably a SUBJ or an OBJ. Given this, Naive
Bayes appears to be a promising solution here. Be-
low we describe a way to adapt this classifier to the
problem of grammatical function guessing.
Let ΦP C Φ be the set of grammatical functions
which are already present in fP. Let E = {ξ1..ξn}
be the set of features, and let X = {x1..xn} be
the values of these features for the f-structure fd
for which the function should be guessed. Then
the answer φd is chosen as follows:
let us consider a situation when the functions are
to be guessed for two dependent f-structures of
the same parent f-structure, OBJ being the correct
answer for the first and SUBJ for the second. If
the guesser returns SUBJ for the first of the two,
this answer will not only be incorrect, but also de-
crease the probability of the correct answer for the
second by decreasing MP (SUBJ) in Equation (1).
This suggests that in such cases maximization of
the joint probability of the values of all the miss-
ing functions may be a better choice.
</bodyText>
<sectionHeader confidence="0.9982" genericHeader="method">
3 Experimental Evaluation
</sectionHeader>
<bodyText confidence="0.9996588">
φd = arg max p(φ)MP(φ) �n )p(ξi = xi|φ) (1) We present two experiments which assess the ac-
φ∈Φ i=1 curacy of the proposed approach and compare dif-
ferent variants of it in order to select the best, and
an additional one which assesses the usefulness of
the approach for practical machine translation.
</bodyText>
<equation confidence="0.9964">
MP (�) — { P(ot(O, fis)&gt; 1), if φ ∈ ΦP (2)
</equation>
<bodyText confidence="0.999984956521739">
where the probabilities are estimated from the
training data. Equation (2) states that if φ is al-
ready present in the parent f-structure, the proba-
bility of φ being set-valued is considered.
We propose two ways of building the feature
set E. First, it is possible to consider the pres-
ence/absence of each particular attribute in fd as
a binary feature. Second, it is possible to con-
sider atomic attribute values as features as well.
To give a motivating example, in many languages
the value of CASE is extremely informative when
distinguishing objects from subjects. We use only
those atomic attribute values which do not rep-
resent words. E.g., NUM, PRED or NUM=sg are
features, while PRED=‘resolution’ is not a
feature. This distinction prevents the feature set
from growing too large and thus the probability
estimates from being too inaccurate.
If grammatical functions are missing for sev-
eral dependent f-structures, it is possible to use
the same approach, guessing the missing func-
tions one by one. In general, however, these de-
cisions will not be independent. To illustrate this,
</bodyText>
<subsectionHeader confidence="0.99977">
3.1 Data Used in the Evaluation
</subsectionHeader>
<bodyText confidence="0.999944652173913">
For our experiments we used sentences from
the German-English part of the Europarl cor-
pus (Koehn, 2005) parsed into f-structures with
the XLE parser (Kaplan et al., 2002) using En-
glish (Riezler et al., 2002) and German (Butt et
al., 2002) LFGs. We parsed only sentences of
length 5–15 words. For the first two experiments,
we picked 2000 sentences for training and 1000
for testing for both languages. We ignored robust-
ness features (FIRST, REST), functions related to
c-structure constraints (MOTHER, LEFT SISTER,
etc.), and TOPIC. Of the remaining functions, we
considered only those occurring in the PREDs-
only part of f-structure. If a dependent f-structure
has multiple functions within the same parent f-
structure, only the first function occurring in the
description is considered. This does not unduely
influence the results, as the grammatical function
of an f-structure, after exclusion of TOPIC, carries
multiple labels in only about 2% of the cases in the
English data and about 1% in the German data. In
Table 1 we provide some useful statistics to help
the reader interpret the results of the experiments.
</bodyText>
<page confidence="0.990502">
147
</page>
<table confidence="0.999886">
Language MF NB-CASE NB-N NB-N&amp;V
English 36.3% 56.7% 85.6% 91.6%
German 23.4% 51.0% 74.8% 82.5%
</table>
<tableCaption confidence="0.995408">
Table 2: Experiment 1: Guessing a Single Miss-
</tableCaption>
<bodyText confidence="0.964622666666667">
ing Grammatical Function. MF is the pick-most-
frequent classifier. NB-CASE is Naive Bayes
(NB) with only CASE values used as features. NB-
N is NB with only attribute names used as fea-
tures. NB-N&amp;V is NB with both attribute names
and atomic attribute values used as features.
</bodyText>
<subsectionHeader confidence="0.9997195">
3.2 Experiment 1: Guessing a Single Missing
Grammatical Function
</subsectionHeader>
<bodyText confidence="0.997764105263158">
The goal of this experiment is to evaluate the ac-
curacy of the Bayesian guesser in the case when
the grammatical function is unknown only for one
dependent f-structure, and to assess whether the
inclusion of attribute values into the feature set
improves the results, and whether attributes other
than CASE are useful.
Procedure. As a baseline, we used a pick-most-
frequent algorithm MF which considers only the
function’s prior probability and the presence of
this function in the parent (returning to Equations
(1) and (2), MF is in fact Naive Bayes with an
empty feature set Ξ). The guesser was evaluated
in three variants: NB-CASE with the feature set
formed only from the values of CASE attributes
(if the f-structure has no CASE feature, the classi-
fier degenerates to MF), NB-N with the feature set
formed only from attribute names, and NB-N&amp;V
with the feature set formed from both attribute
names and values. All grammatical functions in
the test set were used as test cases. At each step in
the evaluation, one function was removed and then
guessed by each algorithm. For both languages the
test set was split into 10 non-intersecting subsets
with approximately equal numbers of grammati-
cal functions in each, and the values obtained for
the 10 subsets were further used to assess the sta-
tistical significance of the differences in the results
with the paired Student’s t-test.
Results. Table 2 presents the results. For both
English and German all the three versions of the
classifier clearly outperform the baseline, and even
the advantage of NB-CASE over the baseline is
statistically significant at the 0.5% level for both
languages. However, NB-CASE performs much
worse than NB-N and NB-N&amp;V (their advantage
over NB-CASE is statistically significant at the
0.5% level for both languages), confirming that
</bodyText>
<table confidence="0.999558333333333">
Language MF NB-S NB-J
English 22.0% 90.4% 91.2%
German 17.1% 81.4% 82.1%
</table>
<tableCaption confidence="0.998646">
Table 3: Experiment 2: Guessing Multiple Miss-
</tableCaption>
<bodyText confidence="0.983670785714286">
ing Functions. MF is the pick-most-frequent clas-
sifier. NB-S and NB-J are one-by-one and join-
probability-based Naive Bayesian guessers.
CASE is not the only feature which is useful in
our task. The increase in accuracy brought about
by including the atomic attribute values into the
feature space is visible and significant at the same
level. The increase is somewhat more pronounced
for German than for English. For English the in-
clusion of attribute values into the feature space
affects primarily the accuracy of SUBJ vs. OBJ
decisions. For German, the accuracy notably in-
creases for telling SUBJ, OBJ and ADJ-GEN from
one another.
</bodyText>
<subsectionHeader confidence="0.999637">
3.3 Experiment 2: Guessing Multiple
Missing Grammatical Functions
</subsectionHeader>
<bodyText confidence="0.999989275862069">
The goal of this experiment is to assess the accu-
racy of the Bayesian guesser for multiple miss-
ing grammatical functions within one parent f-
structure, and to compare the accuracy of one-
by-one vs. joint-probability-based guessing. Our
evaluation procedure models the extreme case
when the functions are unknown for all the depen-
dent f-structures of a particular parent.
Procedure. As a baseline, we use the same al-
gorithm MF as in Experiment 1, applied to the
missing grammatical functions one by one. Two
Bayesian guessers are evaluated, NB-S guessing
the missing grammatical functions one by one, and
NB-J guessing them all at once by maximizing
the joint probability of the values. Both Bayesian
guessers use attribute names and values as fea-
tures. All grammatical functions in the test set
were used as test cases. At each step of the ex-
periment, the grammatical functions of all the de-
pendent f-structures of a particular parent were
removed simultaneously, and then guessed with
each of the algorithms considered in this experi-
ment. Statistical significance was assessed in the
same way as in Experiment 1.
Results. Table 3 presents the accuracy scores.
The one-by-one guesser and the joint-probability-
based guesser perform nearly equally well, result-
ing in accuracy levels very close to those obtained
in Experiment 1 for f-structures with a single
</bodyText>
<page confidence="0.996255">
148
</page>
<bodyText confidence="0.99997">
missing function. Joint-probability-based guess-
ing achieves an advantage which is statistically
significant at the 0.5% level for both languages
but is not exceeding 1% absolute improvement.
For both languages errors typically occur in distin-
guishing OBJ vs. SUBJ and ADJUNCT vs. MOD,
and additionally in XCOMP vs. OBJ for English.
</bodyText>
<subsectionHeader confidence="0.9759445">
3.3.1 Experiment 3: Postprocessing the
Output of an MT Decoder
</subsectionHeader>
<bodyText confidence="0.9999735">
The goal of this experiment is to see how the
method influences the results of an SMT system.
Procedure. For this experiment we use the Sulis
SMT system (Graham et al., 2009), and a decoder,
which selects the transfer rules by maximizing the
source-to-target probability of the complete trans-
lation. Such a decoder, though simple, allows us
to create a realistic environment for evaluation.
From the f-structures produced by the decoder,
candidate sentences are generated with XLE, and
then the one best translation is selected for each
sentence using a language model. The function
guesser is used to postprocess the output of the
decoder before sentence generation. In the ex-
periment, the function guesser uses both attribute
names and values to make a guess. Guessing of
multiple missing functions is performed one-by-
one, as joint guessing complicates the algorithm
and leads to a very small improvement in accuracy.
The function guesser is trained on 3000 sentences,
which are a subset of the set used for inducing the
transfer rules. The overall MT system is evaluated
both with and without function guessing on 500
held-out sentences, and the quality of the transla-
tion is measured using the BLEU metric (Papineni
et al., 2002). We also calculate the number of sen-
tences for which the generator output is unempty.
Results. The system without function guesser
produced results for 364 sentences out of 500,
with BLEU score equal to 5.69%; with function
guesser the number of successfully generated sen-
tences increases to 433, with BLEU improving to
6.95%. Thus, the absolute increase of BLEU score
brought about by the guesser is 1.24%. This sug-
gests that the algorithm succeeds on real data and
is useful in grammar-based machine translation.
</bodyText>
<sectionHeader confidence="0.99967" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999496636363636">
In this paper we addressed the problem of restor-
ing unknown grammatical functions in automati-
cally generated f-structures. We proposed to view
this problem as a classification task and to solve
it with the Naive Bayes classifier, using the names
and the values of the attributes of the dependent
f-structure to construct the feature set.
The approach was evaluated on English and
German data, and showed reasonable accuracy,
restoring the missing functions correctly in about
91% of the cases for English and about 82% for
German. It is tempting to interpret the differences
in accuracy for English and German as reflecting
the complexity of grammatical function assign-
ment for the two languages. It is not clear, how-
ever, whether the differences are due to differences
in the grammars or in the underlying data.
The experiments reported here use LFG-type
representations. However, nothing much in the
method is specific to LFG, and therefore we are
confident that our method also applies to other
dependency-based representations.
</bodyText>
<sectionHeader confidence="0.999506" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998977666666667">
The research presented here was supported by Sci-
ence Foundation Ireland grant 07/CE2/I1142 un-
der the CNGL CSET programme.
</bodyText>
<sectionHeader confidence="0.999444" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999386153846154">
M. Butt, H. Dyvik, T. H. King, H. Masuichi, and
C. Rohrer. 2002. The parallel grammar project.
In COLING’02, Workshop on Grammar Engineer-
ing and Evaluation.
Y. Graham, A. Bryl, and J. van Genabith. 2009. F-
structure transfer-based statistical machine transla-
tion. In LFG’09 (To Appear).
R. Kaplan and J. Bresnan. 1982. Lexical functional
grammar, a formal system for grammatical represe-
nation. The Mental Representation of Grammatical
Relations, pages 173–281.
R. M. Kaplan, T. H. King, and J. T. Maxwell III. 2002.
Adapting existing grammars: the XLE experience.
In COLING’02, Workshop on Grammar Engineer-
ing and Evaluation.
P. Koehn. 2005. Europarl: A parallel corpus for sta-
tistical machine translation. In MT Summit X, pages
79–86.
K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002.
BLEU: a method for automatic evaluation of ma-
chine translation. In ACL’02, pages 311–318.
S. Riezler, T. H. King, R. M. Kaplan, R. Crouch,
J. T. Maxwell III, and M. Johnson. 2002. Pars-
ing the wall street journal using a lexical-functional
grammar and discriminative estimation techniques.
In ACL’02, pages 271–278.
</reference>
<page confidence="0.998973">
149
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.263196">
<title confidence="0.999903">Guessing the Grammatical Function of a Non-Root F-Structure in LFG</title>
<author confidence="0.954126">Anton</author>
<affiliation confidence="0.976261">Dublin City</affiliation>
<address confidence="0.982953">Dublin 9, Ireland</address>
<author confidence="0.984348">Josef van</author>
<affiliation confidence="0.808797">Dublin City</affiliation>
<address confidence="0.807553">Dublin 9, Ireland</address>
<affiliation confidence="0.7006455">Yvette Dublin City</affiliation>
<address confidence="0.957128">Dublin 9, Ireland</address>
<abstract confidence="0.997303935483871">PRED ‘adopt’ PERS 3 NUM sg PRED ‘resolution’ ‘the’] ⎡ PERS 3 sg PRED ‘Parliament’ ⎡ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎣ ⎤ ⎦⎥⎥⎥ ⎤ ⎦⎥⎥⎥⎥⎥⎥⎥ ⎡ ⎢ ⎢ ⎢ ⎣ Lexical-Functional Grammar (Kaplan and Bresnan, 1982) f-structures are bilexical labelled dependency representations. We show that the Naive Bayes classifier is able to guess missing grammatical function labels (i.e. bilexical dependency labels) with reasonably high accuracy (82–91%). In the experiments we use f-structure parser output for English and German Europarl data, automatically “broken” by replacing grammatical function labels with a generic and asking the classifier to restore the label.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Butt</author>
<author>H Dyvik</author>
<author>T H King</author>
<author>H Masuichi</author>
<author>C Rohrer</author>
</authors>
<title>The parallel grammar project.</title>
<date>2002</date>
<booktitle>In COLING’02, Workshop on Grammar Engineering and Evaluation.</booktitle>
<contexts>
<context position="7100" citStr="Butt et al., 2002" startWordPosition="1170" endWordPosition="1173">revents the feature set from growing too large and thus the probability estimates from being too inaccurate. If grammatical functions are missing for several dependent f-structures, it is possible to use the same approach, guessing the missing functions one by one. In general, however, these decisions will not be independent. To illustrate this, 3.1 Data Used in the Evaluation For our experiments we used sentences from the German-English part of the Europarl corpus (Koehn, 2005) parsed into f-structures with the XLE parser (Kaplan et al., 2002) using English (Riezler et al., 2002) and German (Butt et al., 2002) LFGs. We parsed only sentences of length 5–15 words. For the first two experiments, we picked 2000 sentences for training and 1000 for testing for both languages. We ignored robustness features (FIRST, REST), functions related to c-structure constraints (MOTHER, LEFT SISTER, etc.), and TOPIC. Of the remaining functions, we considered only those occurring in the PREDsonly part of f-structure. If a dependent f-structure has multiple functions within the same parent fstructure, only the first function occurring in the description is considered. This does not unduely influence the results, as the</context>
</contexts>
<marker>Butt, Dyvik, King, Masuichi, Rohrer, 2002</marker>
<rawString>M. Butt, H. Dyvik, T. H. King, H. Masuichi, and C. Rohrer. 2002. The parallel grammar project. In COLING’02, Workshop on Grammar Engineering and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Graham</author>
<author>A Bryl</author>
<author>J van Genabith</author>
</authors>
<title>Fstructure transfer-based statistical machine translation.</title>
<date>2009</date>
<booktitle>In LFG’09 (To Appear).</booktitle>
<marker>Graham, Bryl, van Genabith, 2009</marker>
<rawString>Y. Graham, A. Bryl, and J. van Genabith. 2009. Fstructure transfer-based statistical machine translation. In LFG’09 (To Appear).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Kaplan</author>
<author>J Bresnan</author>
</authors>
<title>Lexical functional grammar, a formal system for grammatical represenation. The Mental Representation of Grammatical Relations,</title>
<date>1982</date>
<pages>173--281</pages>
<marker>Kaplan, Bresnan, 1982</marker>
<rawString>R. Kaplan and J. Bresnan. 1982. Lexical functional grammar, a formal system for grammatical represenation. The Mental Representation of Grammatical Relations, pages 173–281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M Kaplan</author>
<author>T H King</author>
<author>J T Maxwell</author>
</authors>
<title>Adapting existing grammars: the XLE experience.</title>
<date>2002</date>
<booktitle>In COLING’02, Workshop on Grammar Engineering and Evaluation.</booktitle>
<contexts>
<context position="7032" citStr="Kaplan et al., 2002" startWordPosition="1157" endWordPosition="1160">features, while PRED=‘resolution’ is not a feature. This distinction prevents the feature set from growing too large and thus the probability estimates from being too inaccurate. If grammatical functions are missing for several dependent f-structures, it is possible to use the same approach, guessing the missing functions one by one. In general, however, these decisions will not be independent. To illustrate this, 3.1 Data Used in the Evaluation For our experiments we used sentences from the German-English part of the Europarl corpus (Koehn, 2005) parsed into f-structures with the XLE parser (Kaplan et al., 2002) using English (Riezler et al., 2002) and German (Butt et al., 2002) LFGs. We parsed only sentences of length 5–15 words. For the first two experiments, we picked 2000 sentences for training and 1000 for testing for both languages. We ignored robustness features (FIRST, REST), functions related to c-structure constraints (MOTHER, LEFT SISTER, etc.), and TOPIC. Of the remaining functions, we considered only those occurring in the PREDsonly part of f-structure. If a dependent f-structure has multiple functions within the same parent fstructure, only the first function occurring in the descriptio</context>
</contexts>
<marker>Kaplan, King, Maxwell, 2002</marker>
<rawString>R. M. Kaplan, T. H. King, and J. T. Maxwell III. 2002. Adapting existing grammars: the XLE experience. In COLING’02, Workshop on Grammar Engineering and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In MT Summit X,</booktitle>
<pages>79--86</pages>
<contexts>
<context position="6965" citStr="Koehn, 2005" startWordPosition="1148" endWordPosition="1149">hich do not represent words. E.g., NUM, PRED or NUM=sg are features, while PRED=‘resolution’ is not a feature. This distinction prevents the feature set from growing too large and thus the probability estimates from being too inaccurate. If grammatical functions are missing for several dependent f-structures, it is possible to use the same approach, guessing the missing functions one by one. In general, however, these decisions will not be independent. To illustrate this, 3.1 Data Used in the Evaluation For our experiments we used sentences from the German-English part of the Europarl corpus (Koehn, 2005) parsed into f-structures with the XLE parser (Kaplan et al., 2002) using English (Riezler et al., 2002) and German (Butt et al., 2002) LFGs. We parsed only sentences of length 5–15 words. For the first two experiments, we picked 2000 sentences for training and 1000 for testing for both languages. We ignored robustness features (FIRST, REST), functions related to c-structure constraints (MOTHER, LEFT SISTER, etc.), and TOPIC. Of the remaining functions, we considered only those occurring in the PREDsonly part of f-structure. If a dependent f-structure has multiple functions within the same par</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>P. Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In MT Summit X, pages 79–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In ACL’02,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="14085" citStr="Papineni et al., 2002" startWordPosition="2302" endWordPosition="2305">ss the output of the decoder before sentence generation. In the experiment, the function guesser uses both attribute names and values to make a guess. Guessing of multiple missing functions is performed one-byone, as joint guessing complicates the algorithm and leads to a very small improvement in accuracy. The function guesser is trained on 3000 sentences, which are a subset of the set used for inducing the transfer rules. The overall MT system is evaluated both with and without function guessing on 500 held-out sentences, and the quality of the translation is measured using the BLEU metric (Papineni et al., 2002). We also calculate the number of sentences for which the generator output is unempty. Results. The system without function guesser produced results for 364 sentences out of 500, with BLEU score equal to 5.69%; with function guesser the number of successfully generated sentences increases to 433, with BLEU improving to 6.95%. Thus, the absolute increase of BLEU score brought about by the guesser is 1.24%. This suggests that the algorithm succeeds on real data and is useful in grammar-based machine translation. 4 Conclusion In this paper we addressed the problem of restoring unknown grammatical</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In ACL’02, pages 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Riezler</author>
<author>T H King</author>
<author>R M Kaplan</author>
<author>R Crouch</author>
<author>J T Maxwell</author>
<author>M Johnson</author>
</authors>
<title>Parsing the wall street journal using a lexical-functional grammar and discriminative estimation techniques.</title>
<date>2002</date>
<booktitle>In ACL’02,</booktitle>
<pages>271--278</pages>
<contexts>
<context position="7069" citStr="Riezler et al., 2002" startWordPosition="1164" endWordPosition="1167"> not a feature. This distinction prevents the feature set from growing too large and thus the probability estimates from being too inaccurate. If grammatical functions are missing for several dependent f-structures, it is possible to use the same approach, guessing the missing functions one by one. In general, however, these decisions will not be independent. To illustrate this, 3.1 Data Used in the Evaluation For our experiments we used sentences from the German-English part of the Europarl corpus (Koehn, 2005) parsed into f-structures with the XLE parser (Kaplan et al., 2002) using English (Riezler et al., 2002) and German (Butt et al., 2002) LFGs. We parsed only sentences of length 5–15 words. For the first two experiments, we picked 2000 sentences for training and 1000 for testing for both languages. We ignored robustness features (FIRST, REST), functions related to c-structure constraints (MOTHER, LEFT SISTER, etc.), and TOPIC. Of the remaining functions, we considered only those occurring in the PREDsonly part of f-structure. If a dependent f-structure has multiple functions within the same parent fstructure, only the first function occurring in the description is considered. This does not unduel</context>
</contexts>
<marker>Riezler, King, Kaplan, Crouch, Maxwell, Johnson, 2002</marker>
<rawString>S. Riezler, T. H. King, R. M. Kaplan, R. Crouch, J. T. Maxwell III, and M. Johnson. 2002. Parsing the wall street journal using a lexical-functional grammar and discriminative estimation techniques. In ACL’02, pages 271–278.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>