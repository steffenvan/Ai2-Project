<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.210626">
<title confidence="0.85629">
Fast and Accurate Unlexicalized Parsing via Structural Annotations
</title>
<author confidence="0.925318">
Maximilian Schlund, Michael Luttenberger, and Javier Esparza
</author>
<affiliation confidence="0.772825">
Institut f¨ur Informatik
Technische Universit¨at M¨unchen
</affiliation>
<address confidence="0.7760375">
Boltzmannstraße 3
D-85748 Garching
</address>
<email confidence="0.997908">
{schlund,luttenbe,esparza}@model.in.tum.de
</email>
<sectionHeader confidence="0.997353" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999988266666667">
We suggest a new annotation scheme for
unlexicalized PCFGs that is inspired by
formal language theory and only depends
on the structure of the parse trees. We
evaluate this scheme on the T¨uBa-D/Z
treebank w.r.t. several metrics and show
that it improves both parsing accuracy and
parsing speed considerably. We also show
that our strategy can be fruitfully com-
bined with known ones like parent annota-
tion to achieve accuracies of over 90% la-
beled F1 and leaf-ancestor score. Despite
increasing the size of the grammar, our
annotation allows for parsing more than
twice as fast as the PCFG baseline.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999953566666667">
As shown by (Klein and Manning, 2003), un-
lexicalized PCFGs can achieve high parsing ac-
curacies when training trees are annotated with
additional information. An annotation basically
amounts to splitting each nonterminal into sev-
eral subcategories, which can even be derived
automatically (Petrov et al., 2006; Petrov and
Klein, 2007). Currently used annotation strate-
gies, e.g. parent annotation (Johnson, 1998) or se-
lectively splitting special nonterminals (e.g. mark-
ing relative clauses) as in (Schiehlen, 2004), are
mostly linguistically motivated (with the excep-
tion of the above mentioned automatic approach).
In this paper we study new heuristics motivated
by formal language theory for improving the pars-
ing accuracy of unlexicalized PCFGs by means of
refining the nonterminals of the grammar: One
heuristic splits a nonterminal X into a family of
nonterminals (Xd)d∈D based on the notion of the
dimension (also Horton-Strahler number) of a tree
(Strahler, 1952; Esparza et al., 2007; Esparza et
al., 2014).
The dimension of a rooted tree t is defined as the
height of the highest perfect binary tree1 we can
obtain from t by pruning subtrees and contracting
edges.2
A result of (Flajolet et al., 1979) shows that
the dimension characterizes the minimal amount
of memory that is required to traverse a tree. So,
intuitively, parse trees of high dimension should
indicate an unnaturally complex sentence structure
requiring the reader to remember too many incom-
plete dependent clauses in the course of reading
the sentence. Section 2 corroborates experimen-
tally that, indeed, parse trees of natural language
have small dimension.
Since dimension is a meaningful measure of
complexity and parse trees have low dimension,
we conjectured that annotating nonterminals with
the dimension of the subtree rooted at them could
improve parsing accuracy (see Fig. 1 for an il-
lustration). Section 5 shows that this is indeed
the case: The combination of the dimension an-
notation and the well known parent annotation
technique leads to absolute improvements of more
than 5% F1, 7–8% leaf-ancestor score, and a rela-
tive reduction of the number of crossing brackets
of over 25% compared to a plain PCFG baseline.
At the same time, quite surprisingly, parsing speed
more than doubles.
It could be argued that any other graph theo-
retical measure for the complexity of a tree could
lead to similar results. For this reason we have
also considered annotating nonterminals with the
height of the subtree rooted at them (the height is
the most basic measure related to trees). Our ex-
periments show that height annotation is also ben-
eficial but further refinement via parent annotation
yields less improvements than for the dimension
annotation.
</bodyText>
<footnote confidence="0.999551333333333">
1A binary tree of height h is perfect if it has 2h leaves.
2In other words, the dimension of t is the height of the
highest perfect binary tree which is a minor of t.
</footnote>
<page confidence="0.914552">
164
</page>
<note confidence="0.847449">
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 164–168,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<equation confidence="0.802253">
SIMPX-3
MF-2
NX-2
NX-1
NN-
</equation>
<page confidence="0.985551">
165
</page>
<bodyText confidence="0.999959">
ning, 2003). For evaluation we used the built in
evalb, leaf-ancestor, and crossing brackets metrics
provided by the Stanford parser. Is is important to
note that all our experiments use gold tags from
the treebank3 which had the pleasant side effect
that no parse failures were encountered. All exper-
iments were carried out on a machine with an Intel
i7 2.7 GHz CPU and 8 GB RAM and took about
one week to run4. Our scripts and raw data can be
obtained freely from https://github.com/
mschlund/nlp-newton.
</bodyText>
<subsectionHeader confidence="0.987869">
4.2 Randomization
</subsectionHeader>
<bodyText confidence="0.999970142857143">
We decided to sample our training- and test-data
randomly from the treebank several times inde-
pendently for each annotation strategy under test.
This enables us to give more precise estimations
of parsing accuracy (Section 5) and to assess their
variability (cf. Figure 2). For each sample size N
from {5k, 10k, 20k, ... , 70k} we selected a ran-
dom sample of size N from the set of all 75408
trees in the treebank. The first 90% of this sample
was used as training set and the remaining 10% as
test set. We then evaluated each of our six anno-
tation methods on this same training/test set. The
whole process was repeated ten times each, yield-
ing 480 experiments altogether. For each experi-
ment we evaluated parsing accuracy according to
three evaluation measures as well as the parsing
speed and the size of the derived grammar. Each
of these numbers was then averaged over the ten
random trials. To ensure perfect reproducibility
we saved the seeds we used to seed the random
generator.
</bodyText>
<subsectionHeader confidence="0.99801">
4.3 Evaluation Measures
</subsectionHeader>
<bodyText confidence="0.99919825">
To thoroughly assess the performance of our anno-
tation schemes we not only report the usual con-
stituency measures (labeled precision/recall/F1
and crossing brackets) proposed originally by
(Abney et al., 1991) but also calculate leaf-
ancestor scores (LA) proposed by (Sampson,
2000) since it has been argued that LA-scores de-
scribe the informal notion of a “good” parse better
than the usual constituency measures. This is es-
pecially relevant for comparing parsing accuracy
over different treebanks (Rehbein and Van Gen-
abith, 2007a; Rehbein and van Genabith, 2007b).
</bodyText>
<footnote confidence="0.9973665">
3This is unrealistic of course, but is used for comparability
with other work like (Rafferty and Manning, 2008).
4We only used a single core, since memory turned out to
be the main bottleneck.
</footnote>
<sectionHeader confidence="0.999775" genericHeader="introduction">
5 Results
</sectionHeader>
<bodyText confidence="0.9999865">
Our results are collected in Table 5. We measured
a baseline accuracy of 84.8% labeled F1-score
for a plain PCFG without any annotations, lower
than the 88% reported by (Rafferty and Manning,
2008) on a previous release of the T¨uBa-D/Z tree-
bank (comprising only 20k sentences of length at
most 40). However, the absolute improvements
we found using annotations are consistent with
their work, e.g. our experiments show an abso-
lute increase of 3.4% when using parent annota-
tion while (Rafferty and Manning, 2008) report a
3.1% increase. We suspect that the differences are
largely suspect to the different data: considering
sentences up to length 40, our experiments yield
scores that are 1% higher. To explain all remain-
ing differences we plan to replicate their setup.
</bodyText>
<subsectionHeader confidence="0.99465">
5.1 Impact of Annotations
</subsectionHeader>
<bodyText confidence="0.99997925">
All three annotation methods (w.r.t. parent, dimen-
sion, height which we will abbreviate by PA, DA,
HA for convenience) lead to comparable improve-
ments w.r.t. constituency measures with small ad-
vantages for the two structural annotations. LA-
evaluation on the other hand shows that HA and
DA have a clear advantage of 3% over PA.
Quite surprisingly, both DA and HA can be
fruitfully combined with parent annotation im-
proving F1 further by almost 2% and LA-metrics
by 1–2% as well. However, the height+parent
combination cannot compete with the dimen-
sion+parent method. One reason for this might be
the significant increase in grammar size and result-
ing data-sparseness problems, although our learn-
ing curves (cf. Figure 2) suggest that lack of train-
ing data is not an issue.
Altogether, the DA+PA combination is the most
precise one w.r.t. all metrics. It provides abso-
lute increases of 5.6% labeled F1 and 7.4–8.4%
LA-score and offers a relative reduction of cross-
ing brackets by 27%. This is especially relevant
since according to (Manning and Sch¨utze, 1999) a
high number of crossing brackets is often consid-
ered “particularly dire”. Finally, this combination
leads to a 60% increase in the number of exactly
parsed sentences, significantly more than for the
other methods.
</bodyText>
<subsectionHeader confidence="0.999488">
5.2 Parsing Speed
</subsectionHeader>
<bodyText confidence="0.9984215">
We further study to what extent the three heuris-
tics increase the size of the grammar and the time
</bodyText>
<page confidence="0.997863">
166
</page>
<table confidence="0.99984325">
Annotation |G |Speed f stderr evalb Leaf-Ancestor Crossing brackets
Fl exact LA (s) LA (c) # CB zero CB
Plain 21009 1.74 f 0.04 84.8 24.4 84.0 79.7 1.17 58.5
Parent 34192 1.07 f 0.01 88.2 31.8 86.6 82.9 1.07 61.8
Height 76096 3.06 f 0.03 88.7 33.7 89.8 86.2 0.93 65.2
Height+parent 130827 2.20 f 0.04 89.2 36.8 90.8 87.0 0.95 65.4
Dim 49798 6.02 f 0.10 88.5 31.8 89.7 86.1 0.90 64.9
Dim+parent 84947 4.04 f 0.07 90.4 39.1 91.4 88.1 0.85 67.2
</table>
<tableCaption confidence="0.96071">
Table 2: Average grammar sizes, parsing speed, and parsing accuracies according to various metrics (for
</tableCaption>
<figureCaption confidence="0.98382175">
the 70k samples only, i.e. on 7000 test trees). All numbers are averaged over 10 independent random
samples. |G |denotes the number of rules in the grammar, parsing speed is measured in sentences per
second. LA scores are reported as sentence-level (s) and corpus-level (c) averages, respectively. All
accuracies reported in % (except # CB – the average number of crossing brackets per sentence).
Figure 2: Learning curves for different annotation
strategies. Average F1 with standard deviation for
random samples of various sizes (10 independent
samples each).
</figureCaption>
<bodyText confidence="0.999950631578947">
needed to parse a sentence. As expected all three
annotations increase the size of the grammar con-
siderably (PA by 60%, DA by almost 140%, and
HA by 260%). Surprisingly, our experiments did
not show a direct influence of the grammar size
on the average time needed to parse a tree: While
parsing speed for PA drops by about 40%, DA and
HA actually lead to significant speedups over the
baseline (factor 3.4 for DA and 1.7 for HA). For
the combination of dimension and parent annota-
tion the gain in speed is less pronounced but still
a factor of 2.3. One possible explanation is the
fact that (for a grammar in CNF) a nonterminal of
dimension d can only be produced either by com-
bining one of dimension d with one of dimension
strictly less than d or by two of dimension exactly
d −1. Since the dimensions involved are typically
very small (cf. Table 1) this may restrict the search
space significantly.
</bodyText>
<sectionHeader confidence="0.999561" genericHeader="acknowledgments">
6 Discussion
</sectionHeader>
<bodyText confidence="0.99999475">
We have described a new and simple yet effec-
tive annotation strategy to split nonterminals based
on the purely graph-theoretic concept of tree di-
mension. We show that annotating nonterminals
with either their dimension or their height gives
accuracies that lie beyond parent annotation. Fur-
thermore dimension and parent annotation in com-
bination yield even higher accuracies (90.4% la-
beled F1 and 91.4% LA-score on a sentence-
level). Lastly, one of the most surprising findings
is that, despite considerable growth of grammar
size, parsing is significantly faster.
</bodyText>
<subsectionHeader confidence="0.979824">
6.1 Future Work
</subsectionHeader>
<bodyText confidence="0.99997865">
We are currently experimenting with other tree-
banks like the SPMRL dataset (Seddah et al.,
2013) which contains various “morphologically
rich” languages (cf. Table 1). Although we cannot
possibly expect to match the accuracies achieved
by highly optimized lexicalized parsers with our
simple annotation strategy alone, we are confident
that our results transfer to other languages. A logi-
cal next step is to integrate our annotation methods
into current parsing frameworks.
Since our annotations increase the size of
the grammar significantly, horizontal markoviza-
tion and more careful, selective dimension/height-
splits (i.e. only carry out “profitable” splits) seem
promising to avoid problems of data-sparsity – in
particular if one wants to use further state-splitting
techniques that are more linguistically motivated.
Finally, we are interested in understanding the
parsing speedup incurred by dimension/height-
annotations and to provide a theoretical analysis.
</bodyText>
<figure confidence="0.998627545454545">
0 1 2 3 4 5 6 7
Sample size ·104
Labeled Fl score in %
90
88
86
84
82
plain PCFG Parent
Dim Dim+Parent
Height Height+Parent
</figure>
<page confidence="0.985496">
167
</page>
<sectionHeader confidence="0.982273" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999835431578948">
S. Abney, S. Flickenger, C. Gdaniec, C. Grishman,
P. Harrison, D. Hindle, R. Ingria, F. Jelinek, J. Kla-
vans, M. Liberman, M. Marcus, S. Roukos, B. San-
torini, and T. Strzalkowski. 1991. Procedure for
Quantitatively Comparing the Syntactic Coverage of
English Grammars. In E. Black, editor, Proceedings
of the Workshop on Speech and Natural Language,
HLT ’91, pages 306–311, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Javier Esparza, Stefan Kiefer, and Michael Lutten-
berger. 2007. An Extension of Newton’s Method to
ω-Continuous Semirings. In Developments in Lan-
guage Theory, volume 4588 of LNCS, pages 157–
168. Springer.
Javier Esparza, Michael Luttenberger, and Maximilian
Schlund. 2014. A Brief History of Strahler Num-
bers. In Language and Automata Theory and Appli-
cations, volume 8370 of Lecture Notes in Computer
Science, pages 1–13. Springer International Publish-
ing.
Philippe Flajolet, Jean-Claude Raoult, and Jean
Vuillemin. 1979. The Number of Registers Re-
quired for Evaluating Arithmetic Expressions. The-
oretical Computer Science, 9:99–125.
Mark Johnson. 1998. PCFG Models of Linguistic
Tree Representations. Computational Linguistics,
24(4):613–632.
Dan Klein and Christopher D. Manning. 2003. Ac-
curate Unlexicalized Parsing. In Proceedings of the
41st Annual Meeting on Association for Computa-
tional Linguistics - Volume 1, ACL ’03, pages 423–
430, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
Edward Loper and Steven Bird. 2002. NLTK: The
Natural Language Toolkit. In Proceedings of the
ACL-02 Workshop on Effective tools and methodolo-
gies for teaching natural language processing and
computational linguistics-Volume 1, pages 63–70.
Association for Computational Linguistics.
Christopher D. Manning and Hinrich Sch¨utze. 1999.
Foundations of statistical natural language process-
ing, volume 999. MIT Press.
Slav Petrov and Dan Klein. 2007. Improved Inference
for Unlexicalized Parsing. In HLT-NAACL, pages
404–411.
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan
Klein. 2006. Learning Accurate, Compact, and
Interpretable Tree Annotation. In Proceedings of
the 21st International Conference on Computational
Linguistics and the 44th annual meeting of the Asso-
ciation for Computational Linguistics, pages 433–
440. Association for Computational Linguistics.
Anna N. Rafferty and Christopher D. Manning. 2008.
Parsing Three German Treebanks: Lexicalized and
Unlexicalized Baselines. In Proceedings of the
Workshop on Parsing German, PaGe ’08, pages 40–
46, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
Ines Rehbein and Josef Van Genabith. 2007a. Eval-
uating Evaluation Measures. In NODALIDA, pages
372–379.
Ines Rehbein and Josef van Genabith. 2007b. Tree-
bank Annotation Schemes and Parser Evaluation for
German. In EMNLP-CoNLL, pages 630–639.
Geoffrey Sampson. 2000. A Proposal for Improving
the Measurement of Parse Accuracy. International
Journal of Corpus Linguistics, 5(1):53–68.
Michael Schiehlen. 2004. Annotation strategies for
probabilistic parsing in german. In Proceedings of
the 20th international conference on Computational
Linguistics, COLING ’04, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Djam´e Seddah, Reut Tsarfaty, Sandra K¨ubler, Marie
Candito, Jinho D. Choi, Rich´ard Farkas, Jen-
nifer Foster, Iakes Goenaga, Koldo Gojenola, Yoav
Goldberg, Spence Green, Nizar Habash, Marco
Kuhlmann, Wolfgang Maier, Joakim Nivre, Adam
Przepiorkowski, Ryan Roth, Wolfgang Seeker, Yan-
nick Versley, Veronika Vincze, Marcin Woli´nski,
Alina Wr´oblewska, and Eric Villemonte de la
Cl´ergerie. 2013. Overview of the SPMRL 2013
Shared Task: A Cross-Framework Evaluation of
Parsing Morphologically Rich Languages. In Pro-
ceedings of the 4th Workshop on Statistical Parsing
of Morphologically Rich Languages: Shared Task,
Seattle, WA.
Arthur N. Strahler. 1952. Hypsometric (Area-
Altitude) Analysis of Erosional Topology. Bulletin
of the Geological Society of America, 63(11):1117–
1142.
Heike Telljohann, Erhard W. Hinrichs, Sandra K¨ubler,
Heike Zinsmeister, and Kathrin Beck. 2003. Style-
book for the T¨ubingen Treebank of Written German
(T¨uBa-D/Z). Seminar f¨ur Sprachwissenschaft, Uni-
versit¨at T¨ubingen, Germany.
</reference>
<page confidence="0.997302">
168
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.505903">
<title confidence="0.999962">Fast and Accurate Unlexicalized Parsing via Structural Annotations</title>
<author confidence="0.993215">Maximilian Schlund</author>
<author confidence="0.993215">Michael Luttenberger</author>
<author confidence="0.993215">Javier</author>
<affiliation confidence="0.840495333333333">Institut f¨ur Technische Universit¨at Boltzmannstraße</affiliation>
<address confidence="0.623605">D-85748</address>
<abstract confidence="0.9964840625">We suggest a new annotation scheme for unlexicalized PCFGs that is inspired by formal language theory and only depends on the structure of the parse trees. We evaluate this scheme on the T¨uBa-D/Z treebank w.r.t. several metrics and show that it improves both parsing accuracy and parsing speed considerably. We also show that our strategy can be fruitfully combined with known ones like parent annotation to achieve accuracies of over 90% laleaf-ancestor score. Despite increasing the size of the grammar, our annotation allows for parsing more than twice as fast as the PCFG baseline.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>S Abney</author>
<author>S Flickenger</author>
<author>C Gdaniec</author>
<author>C Grishman</author>
<author>P Harrison</author>
<author>D Hindle</author>
<author>R Ingria</author>
<author>F Jelinek</author>
</authors>
<date>1991</date>
<booktitle>Procedure for Quantitatively Comparing the Syntactic Coverage of English Grammars. In</booktitle>
<pages>306--311</pages>
<editor>J. Klavans, M. Liberman, M. Marcus, S. Roukos, B. Santorini, and</editor>
<publisher>Association for Computational Linguistics.</publisher>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="5775" citStr="Abney et al., 1991" startWordPosition="923" endWordPosition="926">ocess was repeated ten times each, yielding 480 experiments altogether. For each experiment we evaluated parsing accuracy according to three evaluation measures as well as the parsing speed and the size of the derived grammar. Each of these numbers was then averaged over the ten random trials. To ensure perfect reproducibility we saved the seeds we used to seed the random generator. 4.3 Evaluation Measures To thoroughly assess the performance of our annotation schemes we not only report the usual constituency measures (labeled precision/recall/F1 and crossing brackets) proposed originally by (Abney et al., 1991) but also calculate leafancestor scores (LA) proposed by (Sampson, 2000) since it has been argued that LA-scores describe the informal notion of a “good” parse better than the usual constituency measures. This is especially relevant for comparing parsing accuracy over different treebanks (Rehbein and Van Genabith, 2007a; Rehbein and van Genabith, 2007b). 3This is unrealistic of course, but is used for comparability with other work like (Rafferty and Manning, 2008). 4We only used a single core, since memory turned out to be the main bottleneck. 5 Results Our results are collected in Table 5. We</context>
</contexts>
<marker>Abney, Flickenger, Gdaniec, Grishman, Harrison, Hindle, Ingria, Jelinek, 1991</marker>
<rawString>S. Abney, S. Flickenger, C. Gdaniec, C. Grishman, P. Harrison, D. Hindle, R. Ingria, F. Jelinek, J. Klavans, M. Liberman, M. Marcus, S. Roukos, B. Santorini, and T. Strzalkowski. 1991. Procedure for Quantitatively Comparing the Syntactic Coverage of English Grammars. In E. Black, editor, Proceedings of the Workshop on Speech and Natural Language, HLT ’91, pages 306–311, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Javier Esparza</author>
<author>Stefan Kiefer</author>
<author>Michael Luttenberger</author>
</authors>
<title>An Extension of Newton’s Method to ω-Continuous Semirings.</title>
<date>2007</date>
<booktitle>In Developments in Language Theory,</booktitle>
<volume>4588</volume>
<pages>157--168</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="1878" citStr="Esparza et al., 2007" startWordPosition="275" endWordPosition="278">s, e.g. parent annotation (Johnson, 1998) or selectively splitting special nonterminals (e.g. marking relative clauses) as in (Schiehlen, 2004), are mostly linguistically motivated (with the exception of the above mentioned automatic approach). In this paper we study new heuristics motivated by formal language theory for improving the parsing accuracy of unlexicalized PCFGs by means of refining the nonterminals of the grammar: One heuristic splits a nonterminal X into a family of nonterminals (Xd)d∈D based on the notion of the dimension (also Horton-Strahler number) of a tree (Strahler, 1952; Esparza et al., 2007; Esparza et al., 2014). The dimension of a rooted tree t is defined as the height of the highest perfect binary tree1 we can obtain from t by pruning subtrees and contracting edges.2 A result of (Flajolet et al., 1979) shows that the dimension characterizes the minimal amount of memory that is required to traverse a tree. So, intuitively, parse trees of high dimension should indicate an unnaturally complex sentence structure requiring the reader to remember too many incomplete dependent clauses in the course of reading the sentence. Section 2 corroborates experimentally that, indeed, parse tr</context>
</contexts>
<marker>Esparza, Kiefer, Luttenberger, 2007</marker>
<rawString>Javier Esparza, Stefan Kiefer, and Michael Luttenberger. 2007. An Extension of Newton’s Method to ω-Continuous Semirings. In Developments in Language Theory, volume 4588 of LNCS, pages 157– 168. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Javier Esparza</author>
<author>Michael Luttenberger</author>
<author>Maximilian Schlund</author>
</authors>
<title>A Brief History of Strahler Numbers.</title>
<date>2014</date>
<booktitle>In Language and Automata Theory and Applications,</booktitle>
<volume>8370</volume>
<pages>1--13</pages>
<publisher>Springer International Publishing.</publisher>
<contexts>
<context position="1901" citStr="Esparza et al., 2014" startWordPosition="279" endWordPosition="282">ion (Johnson, 1998) or selectively splitting special nonterminals (e.g. marking relative clauses) as in (Schiehlen, 2004), are mostly linguistically motivated (with the exception of the above mentioned automatic approach). In this paper we study new heuristics motivated by formal language theory for improving the parsing accuracy of unlexicalized PCFGs by means of refining the nonterminals of the grammar: One heuristic splits a nonterminal X into a family of nonterminals (Xd)d∈D based on the notion of the dimension (also Horton-Strahler number) of a tree (Strahler, 1952; Esparza et al., 2007; Esparza et al., 2014). The dimension of a rooted tree t is defined as the height of the highest perfect binary tree1 we can obtain from t by pruning subtrees and contracting edges.2 A result of (Flajolet et al., 1979) shows that the dimension characterizes the minimal amount of memory that is required to traverse a tree. So, intuitively, parse trees of high dimension should indicate an unnaturally complex sentence structure requiring the reader to remember too many incomplete dependent clauses in the course of reading the sentence. Section 2 corroborates experimentally that, indeed, parse trees of natural language</context>
</contexts>
<marker>Esparza, Luttenberger, Schlund, 2014</marker>
<rawString>Javier Esparza, Michael Luttenberger, and Maximilian Schlund. 2014. A Brief History of Strahler Numbers. In Language and Automata Theory and Applications, volume 8370 of Lecture Notes in Computer Science, pages 1–13. Springer International Publishing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philippe Flajolet</author>
<author>Jean-Claude Raoult</author>
<author>Jean Vuillemin</author>
</authors>
<title>The Number of Registers Required for Evaluating Arithmetic Expressions. Theoretical Computer Science,</title>
<date>1979</date>
<pages>9--99</pages>
<contexts>
<context position="2097" citStr="Flajolet et al., 1979" startWordPosition="315" endWordPosition="318">tioned automatic approach). In this paper we study new heuristics motivated by formal language theory for improving the parsing accuracy of unlexicalized PCFGs by means of refining the nonterminals of the grammar: One heuristic splits a nonterminal X into a family of nonterminals (Xd)d∈D based on the notion of the dimension (also Horton-Strahler number) of a tree (Strahler, 1952; Esparza et al., 2007; Esparza et al., 2014). The dimension of a rooted tree t is defined as the height of the highest perfect binary tree1 we can obtain from t by pruning subtrees and contracting edges.2 A result of (Flajolet et al., 1979) shows that the dimension characterizes the minimal amount of memory that is required to traverse a tree. So, intuitively, parse trees of high dimension should indicate an unnaturally complex sentence structure requiring the reader to remember too many incomplete dependent clauses in the course of reading the sentence. Section 2 corroborates experimentally that, indeed, parse trees of natural language have small dimension. Since dimension is a meaningful measure of complexity and parse trees have low dimension, we conjectured that annotating nonterminals with the dimension of the subtree roote</context>
</contexts>
<marker>Flajolet, Raoult, Vuillemin, 1979</marker>
<rawString>Philippe Flajolet, Jean-Claude Raoult, and Jean Vuillemin. 1979. The Number of Registers Required for Evaluating Arithmetic Expressions. Theoretical Computer Science, 9:99–125.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
</authors>
<title>PCFG Models of Linguistic Tree Representations.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>4</issue>
<contexts>
<context position="1299" citStr="Johnson, 1998" startWordPosition="187" endWordPosition="188">ieve accuracies of over 90% labeled F1 and leaf-ancestor score. Despite increasing the size of the grammar, our annotation allows for parsing more than twice as fast as the PCFG baseline. 1 Introduction As shown by (Klein and Manning, 2003), unlexicalized PCFGs can achieve high parsing accuracies when training trees are annotated with additional information. An annotation basically amounts to splitting each nonterminal into several subcategories, which can even be derived automatically (Petrov et al., 2006; Petrov and Klein, 2007). Currently used annotation strategies, e.g. parent annotation (Johnson, 1998) or selectively splitting special nonterminals (e.g. marking relative clauses) as in (Schiehlen, 2004), are mostly linguistically motivated (with the exception of the above mentioned automatic approach). In this paper we study new heuristics motivated by formal language theory for improving the parsing accuracy of unlexicalized PCFGs by means of refining the nonterminals of the grammar: One heuristic splits a nonterminal X into a family of nonterminals (Xd)d∈D based on the notion of the dimension (also Horton-Strahler number) of a tree (Strahler, 1952; Esparza et al., 2007; Esparza et al., 201</context>
</contexts>
<marker>Johnson, 1998</marker>
<rawString>Mark Johnson. 1998. PCFG Models of Linguistic Tree Representations. Computational Linguistics, 24(4):613–632.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate Unlexicalized Parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1, ACL ’03,</booktitle>
<pages>423--430</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="925" citStr="Klein and Manning, 2003" startWordPosition="132" endWordPosition="135">scheme for unlexicalized PCFGs that is inspired by formal language theory and only depends on the structure of the parse trees. We evaluate this scheme on the T¨uBa-D/Z treebank w.r.t. several metrics and show that it improves both parsing accuracy and parsing speed considerably. We also show that our strategy can be fruitfully combined with known ones like parent annotation to achieve accuracies of over 90% labeled F1 and leaf-ancestor score. Despite increasing the size of the grammar, our annotation allows for parsing more than twice as fast as the PCFG baseline. 1 Introduction As shown by (Klein and Manning, 2003), unlexicalized PCFGs can achieve high parsing accuracies when training trees are annotated with additional information. An annotation basically amounts to splitting each nonterminal into several subcategories, which can even be derived automatically (Petrov et al., 2006; Petrov and Klein, 2007). Currently used annotation strategies, e.g. parent annotation (Johnson, 1998) or selectively splitting special nonterminals (e.g. marking relative clauses) as in (Schiehlen, 2004), are mostly linguistically motivated (with the exception of the above mentioned automatic approach). In this paper we study</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate Unlexicalized Parsing. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1, ACL ’03, pages 423– 430, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Loper</author>
<author>Steven Bird</author>
</authors>
<title>NLTK: The Natural Language Toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 Workshop on Effective tools and methodologies for teaching natural language processing and computational linguistics-Volume 1,</booktitle>
<pages>63--70</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Loper, Bird, 2002</marker>
<rawString>Edward Loper and Steven Bird. 2002. NLTK: The Natural Language Toolkit. In Proceedings of the ACL-02 Workshop on Effective tools and methodologies for teaching natural language processing and computational linguistics-Volume 1, pages 63–70. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Foundations of statistical natural language processing, volume 999.</title>
<date>1999</date>
<publisher>MIT Press.</publisher>
<marker>Manning, Sch¨utze, 1999</marker>
<rawString>Christopher D. Manning and Hinrich Sch¨utze. 1999. Foundations of statistical natural language processing, volume 999. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dan Klein</author>
</authors>
<title>Improved Inference for Unlexicalized Parsing. In</title>
<date>2007</date>
<booktitle>HLT-NAACL,</booktitle>
<pages>404--411</pages>
<contexts>
<context position="1221" citStr="Petrov and Klein, 2007" startWordPosition="175" endWordPosition="178">t our strategy can be fruitfully combined with known ones like parent annotation to achieve accuracies of over 90% labeled F1 and leaf-ancestor score. Despite increasing the size of the grammar, our annotation allows for parsing more than twice as fast as the PCFG baseline. 1 Introduction As shown by (Klein and Manning, 2003), unlexicalized PCFGs can achieve high parsing accuracies when training trees are annotated with additional information. An annotation basically amounts to splitting each nonterminal into several subcategories, which can even be derived automatically (Petrov et al., 2006; Petrov and Klein, 2007). Currently used annotation strategies, e.g. parent annotation (Johnson, 1998) or selectively splitting special nonterminals (e.g. marking relative clauses) as in (Schiehlen, 2004), are mostly linguistically motivated (with the exception of the above mentioned automatic approach). In this paper we study new heuristics motivated by formal language theory for improving the parsing accuracy of unlexicalized PCFGs by means of refining the nonterminals of the grammar: One heuristic splits a nonterminal X into a family of nonterminals (Xd)d∈D based on the notion of the dimension (also Horton-Strahle</context>
</contexts>
<marker>Petrov, Klein, 2007</marker>
<rawString>Slav Petrov and Dan Klein. 2007. Improved Inference for Unlexicalized Parsing. In HLT-NAACL, pages 404–411.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Leon Barrett</author>
<author>Romain Thibaux</author>
<author>Dan Klein</author>
</authors>
<title>Learning Accurate, Compact, and Interpretable Tree Annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>433--440</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1196" citStr="Petrov et al., 2006" startWordPosition="171" endWordPosition="174">bly. We also show that our strategy can be fruitfully combined with known ones like parent annotation to achieve accuracies of over 90% labeled F1 and leaf-ancestor score. Despite increasing the size of the grammar, our annotation allows for parsing more than twice as fast as the PCFG baseline. 1 Introduction As shown by (Klein and Manning, 2003), unlexicalized PCFGs can achieve high parsing accuracies when training trees are annotated with additional information. An annotation basically amounts to splitting each nonterminal into several subcategories, which can even be derived automatically (Petrov et al., 2006; Petrov and Klein, 2007). Currently used annotation strategies, e.g. parent annotation (Johnson, 1998) or selectively splitting special nonterminals (e.g. marking relative clauses) as in (Schiehlen, 2004), are mostly linguistically motivated (with the exception of the above mentioned automatic approach). In this paper we study new heuristics motivated by formal language theory for improving the parsing accuracy of unlexicalized PCFGs by means of refining the nonterminals of the grammar: One heuristic splits a nonterminal X into a family of nonterminals (Xd)d∈D based on the notion of the dimen</context>
</contexts>
<marker>Petrov, Barrett, Thibaux, Klein, 2006</marker>
<rawString>Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. 2006. Learning Accurate, Compact, and Interpretable Tree Annotation. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 433– 440. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna N Rafferty</author>
<author>Christopher D Manning</author>
</authors>
<title>Parsing Three German Treebanks: Lexicalized and Unlexicalized Baselines.</title>
<date>2008</date>
<booktitle>In Proceedings of the Workshop on Parsing German, PaGe ’08,</booktitle>
<pages>40--46</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="6243" citStr="Rafferty and Manning, 2008" startWordPosition="997" endWordPosition="1000">tion schemes we not only report the usual constituency measures (labeled precision/recall/F1 and crossing brackets) proposed originally by (Abney et al., 1991) but also calculate leafancestor scores (LA) proposed by (Sampson, 2000) since it has been argued that LA-scores describe the informal notion of a “good” parse better than the usual constituency measures. This is especially relevant for comparing parsing accuracy over different treebanks (Rehbein and Van Genabith, 2007a; Rehbein and van Genabith, 2007b). 3This is unrealistic of course, but is used for comparability with other work like (Rafferty and Manning, 2008). 4We only used a single core, since memory turned out to be the main bottleneck. 5 Results Our results are collected in Table 5. We measured a baseline accuracy of 84.8% labeled F1-score for a plain PCFG without any annotations, lower than the 88% reported by (Rafferty and Manning, 2008) on a previous release of the T¨uBa-D/Z treebank (comprising only 20k sentences of length at most 40). However, the absolute improvements we found using annotations are consistent with their work, e.g. our experiments show an absolute increase of 3.4% when using parent annotation while (Rafferty and Manning, 2</context>
</contexts>
<marker>Rafferty, Manning, 2008</marker>
<rawString>Anna N. Rafferty and Christopher D. Manning. 2008. Parsing Three German Treebanks: Lexicalized and Unlexicalized Baselines. In Proceedings of the Workshop on Parsing German, PaGe ’08, pages 40– 46, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ines Rehbein</author>
<author>Josef Van Genabith</author>
</authors>
<title>Evaluating Evaluation Measures. In</title>
<date>2007</date>
<booktitle>NODALIDA,</booktitle>
<pages>372--379</pages>
<marker>Rehbein, Van Genabith, 2007</marker>
<rawString>Ines Rehbein and Josef Van Genabith. 2007a. Evaluating Evaluation Measures. In NODALIDA, pages 372–379.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ines Rehbein</author>
<author>Josef van Genabith</author>
</authors>
<title>Treebank Annotation Schemes and Parser Evaluation for German. In EMNLP-CoNLL,</title>
<date>2007</date>
<pages>630--639</pages>
<marker>Rehbein, van Genabith, 2007</marker>
<rawString>Ines Rehbein and Josef van Genabith. 2007b. Treebank Annotation Schemes and Parser Evaluation for German. In EMNLP-CoNLL, pages 630–639.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey Sampson</author>
</authors>
<title>A Proposal for Improving the Measurement of Parse Accuracy.</title>
<date>2000</date>
<journal>International Journal of Corpus Linguistics,</journal>
<volume>5</volume>
<issue>1</issue>
<contexts>
<context position="5847" citStr="Sampson, 2000" startWordPosition="936" endWordPosition="937">ach experiment we evaluated parsing accuracy according to three evaluation measures as well as the parsing speed and the size of the derived grammar. Each of these numbers was then averaged over the ten random trials. To ensure perfect reproducibility we saved the seeds we used to seed the random generator. 4.3 Evaluation Measures To thoroughly assess the performance of our annotation schemes we not only report the usual constituency measures (labeled precision/recall/F1 and crossing brackets) proposed originally by (Abney et al., 1991) but also calculate leafancestor scores (LA) proposed by (Sampson, 2000) since it has been argued that LA-scores describe the informal notion of a “good” parse better than the usual constituency measures. This is especially relevant for comparing parsing accuracy over different treebanks (Rehbein and Van Genabith, 2007a; Rehbein and van Genabith, 2007b). 3This is unrealistic of course, but is used for comparability with other work like (Rafferty and Manning, 2008). 4We only used a single core, since memory turned out to be the main bottleneck. 5 Results Our results are collected in Table 5. We measured a baseline accuracy of 84.8% labeled F1-score for a plain PCFG</context>
</contexts>
<marker>Sampson, 2000</marker>
<rawString>Geoffrey Sampson. 2000. A Proposal for Improving the Measurement of Parse Accuracy. International Journal of Corpus Linguistics, 5(1):53–68.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Schiehlen</author>
</authors>
<title>Annotation strategies for probabilistic parsing in german.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th international conference on Computational Linguistics, COLING ’04,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1401" citStr="Schiehlen, 2004" startWordPosition="202" endWordPosition="203">rammar, our annotation allows for parsing more than twice as fast as the PCFG baseline. 1 Introduction As shown by (Klein and Manning, 2003), unlexicalized PCFGs can achieve high parsing accuracies when training trees are annotated with additional information. An annotation basically amounts to splitting each nonterminal into several subcategories, which can even be derived automatically (Petrov et al., 2006; Petrov and Klein, 2007). Currently used annotation strategies, e.g. parent annotation (Johnson, 1998) or selectively splitting special nonterminals (e.g. marking relative clauses) as in (Schiehlen, 2004), are mostly linguistically motivated (with the exception of the above mentioned automatic approach). In this paper we study new heuristics motivated by formal language theory for improving the parsing accuracy of unlexicalized PCFGs by means of refining the nonterminals of the grammar: One heuristic splits a nonterminal X into a family of nonterminals (Xd)d∈D based on the notion of the dimension (also Horton-Strahler number) of a tree (Strahler, 1952; Esparza et al., 2007; Esparza et al., 2014). The dimension of a rooted tree t is defined as the height of the highest perfect binary tree1 we c</context>
</contexts>
<marker>Schiehlen, 2004</marker>
<rawString>Michael Schiehlen. 2004. Annotation strategies for probabilistic parsing in german. In Proceedings of the 20th international conference on Computational Linguistics, COLING ’04, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Djam´e Seddah</author>
<author>Reut Tsarfaty</author>
<author>Sandra K¨ubler</author>
<author>Marie Candito</author>
<author>Jinho D Choi</author>
<author>Rich´ard Farkas</author>
<author>Jennifer Foster</author>
</authors>
<title>Iakes Goenaga, Koldo Gojenola, Yoav Goldberg, Spence Green, Nizar Habash, Marco Kuhlmann, Wolfgang Maier, Joakim Nivre, Adam Przepiorkowski, Ryan Roth, Wolfgang Seeker, Yannick Versley, Veronika Vincze, Marcin Woli´nski, Alina Wr´oblewska, and Eric Villemonte de la Cl´ergerie.</title>
<date>2013</date>
<journal>Overview of the SPMRL</journal>
<booktitle>In Proceedings of the 4th Workshop on Statistical Parsing of Morphologically Rich Languages: Shared Task,</booktitle>
<location>Seattle, WA.</location>
<marker>Seddah, Tsarfaty, K¨ubler, Candito, Choi, Farkas, Foster, 2013</marker>
<rawString>Djam´e Seddah, Reut Tsarfaty, Sandra K¨ubler, Marie Candito, Jinho D. Choi, Rich´ard Farkas, Jennifer Foster, Iakes Goenaga, Koldo Gojenola, Yoav Goldberg, Spence Green, Nizar Habash, Marco Kuhlmann, Wolfgang Maier, Joakim Nivre, Adam Przepiorkowski, Ryan Roth, Wolfgang Seeker, Yannick Versley, Veronika Vincze, Marcin Woli´nski, Alina Wr´oblewska, and Eric Villemonte de la Cl´ergerie. 2013. Overview of the SPMRL 2013 Shared Task: A Cross-Framework Evaluation of Parsing Morphologically Rich Languages. In Proceedings of the 4th Workshop on Statistical Parsing of Morphologically Rich Languages: Shared Task, Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arthur N Strahler</author>
</authors>
<title>Hypsometric (AreaAltitude) Analysis of Erosional Topology.</title>
<date>1952</date>
<journal>Bulletin of the Geological Society of America,</journal>
<volume>63</volume>
<issue>11</issue>
<pages>1142</pages>
<contexts>
<context position="1856" citStr="Strahler, 1952" startWordPosition="273" endWordPosition="274">tation strategies, e.g. parent annotation (Johnson, 1998) or selectively splitting special nonterminals (e.g. marking relative clauses) as in (Schiehlen, 2004), are mostly linguistically motivated (with the exception of the above mentioned automatic approach). In this paper we study new heuristics motivated by formal language theory for improving the parsing accuracy of unlexicalized PCFGs by means of refining the nonterminals of the grammar: One heuristic splits a nonterminal X into a family of nonterminals (Xd)d∈D based on the notion of the dimension (also Horton-Strahler number) of a tree (Strahler, 1952; Esparza et al., 2007; Esparza et al., 2014). The dimension of a rooted tree t is defined as the height of the highest perfect binary tree1 we can obtain from t by pruning subtrees and contracting edges.2 A result of (Flajolet et al., 1979) shows that the dimension characterizes the minimal amount of memory that is required to traverse a tree. So, intuitively, parse trees of high dimension should indicate an unnaturally complex sentence structure requiring the reader to remember too many incomplete dependent clauses in the course of reading the sentence. Section 2 corroborates experimentally </context>
</contexts>
<marker>Strahler, 1952</marker>
<rawString>Arthur N. Strahler. 1952. Hypsometric (AreaAltitude) Analysis of Erosional Topology. Bulletin of the Geological Society of America, 63(11):1117– 1142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heike Telljohann</author>
<author>Erhard W Hinrichs</author>
<author>Sandra K¨ubler</author>
<author>Heike Zinsmeister</author>
<author>Kathrin Beck</author>
</authors>
<title>Stylebook for the T¨ubingen Treebank of Written German (T¨uBa-D/Z). Seminar f¨ur Sprachwissenschaft,</title>
<date>2003</date>
<location>Universit¨at T¨ubingen, Germany.</location>
<marker>Telljohann, Hinrichs, K¨ubler, Zinsmeister, Beck, 2003</marker>
<rawString>Heike Telljohann, Erhard W. Hinrichs, Sandra K¨ubler, Heike Zinsmeister, and Kathrin Beck. 2003. Stylebook for the T¨ubingen Treebank of Written German (T¨uBa-D/Z). Seminar f¨ur Sprachwissenschaft, Universit¨at T¨ubingen, Germany.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>