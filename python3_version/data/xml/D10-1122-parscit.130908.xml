<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000005">
<title confidence="0.991851">
Hashing-based Approaches to Spelling Correction of Personal Names
</title>
<author confidence="0.989239">
Raghavendra Udupa
</author>
<affiliation confidence="0.856731">
Microsoft Research India
Bangalore, India
</affiliation>
<email confidence="0.98607">
raghavu@microsoft.com
</email>
<author confidence="0.98076">
Shaishav Kumar
</author>
<affiliation confidence="0.852672">
Microsoft Research India
Bangalore, India
</affiliation>
<email confidence="0.99289">
v-shaisk@microsoft.com
</email>
<sectionHeader confidence="0.99857" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99998625">
We propose two hashing-based solutions to
the problem of fast and effective personal
names spelling correction in People Search
applications. The key idea behind our meth-
ods is to learn hash functions that map similar
names to similar (and compact) binary code-
words. The two methods differ in the data
they use for learning the hash functions - the
first method uses a set of names in a given lan-
guage/script whereas the second uses a set of
bilingual names. We show that both methods
give excellent retrieval performance in com-
parison to several baselines on two lists of
misspelled personal names. More over, the
method that uses bilingual data for learning
hash functions gives the best performance.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999951">
Over the last few years, People Search has emerged
as an important search service. Unlike general Web
Search and Enterprise Search where users search for
information on a wide range of topics including peo-
ple, products, news, events, etc., People Search is
about people. Hence, personal names are used pre-
dominantly as queries in People Search. As in gen-
eral Web Search, a good percentage of queries in
People Search is misspelled. Naturally, spelling cor-
rection of misspelled personal names plays a very
important role in not only reducing the time and ef-
fort needed by users to find people they are search-
ing for but also in ensuring good user experience.
Spelling errors in personal names are of a differ-
ent nature compared to those in general text. Long
before People Search became widely popular, re-
searchers working on the problem of personal name
matching had recognized the human tendency to be
inexact in recollecting names from the memory and
specifying them. A study of personal names in
hospital databases found that only 39% of the er-
rors in the names were single typographical errors
(Friedman and Sideli, 1992)1. Further, multiple and
long distance typographical errors (Gregzorz Kon-
drak for Grzegorz Kondrak), phonetic errors (as in
Erik Bryl for Eric Brill), cognitive errors (as in Sil-
via Cucerzan for Silviu Cucerzan) and word substi-
tutions (as in Rob Moore for Bob Moore) are ob-
served relatively more frequently in personal names
compared to general text.
In addition to within-the-word errors, People
Search queries are plagued by errors that are not
usually seen in general text. The study by Fried-
man and Sideli discovered that 36% of the errors
were due to addition or deletion of a word (as in
Ricardo Baeza for Ricardo Baeza-Yates) (Friedman
and Sideli, 1992). Although word addition and dele-
tion generally do not come under the purview of
spelling correction, in People Search they are im-
portant and need to be addressed.
Standard approaches to general purpose spelling
correction are not well-suited for correcting mis-
spelled personal names. As pointed out by
(Cucerzan and Brill, 2004), these approaches ei-
ther try to correct individual words (and will fail to
correct Him Clijsters to Kim Clijsters) or employ
features based on relatively wide context windows
</bodyText>
<footnote confidence="0.9426285">
1In contrast, 80% of misspelled words in general text are due
to single typographical errors as found by (Damerau, 1964).
</footnote>
<page confidence="0.807003">
1256
</page>
<note confidence="0.819122">
Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1256–1265,
MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999937934782609">
which are not available for queries in Web Search
and People Search. Spelling correction techniques
meant for general purpose web-queries require large
volumes of training data in the form of query logs
for learning the error models (Cucerzan and Brill,
2004), (Ahmad and Kondrak, 2005). However,
query logs are not available in some applications
(e.g. Email address book search). Further, un-
like general purpose web-queries where word order
often matters, in People Search word order is lax
(e.g. I might search for either Kristina Toutanova or
Toutanova Kristina). Therefore, spelling correction
techniques that rely crucially on bigram and higher
order language models will fail on queries with a dif-
ferent word order than what is observed in the query
log.
Unlike general purpose Web Search where it is
not reasonable to assume the availability of a high-
coverage trusted lexicon, People Search typically
employs large authoritative name directories. For
instance, if one is searching for a friend on Face-
book, the correct spelling of the friend’s name exists
in the Facebook people directory2 (assuming that the
friend is a registered user of Facebook at the time of
the search). Similarly, if one is searching for a con-
tact in Enterprise address book, the correct spelling
of the contact is part of the address book. In fact,
even in Web Search, broad-coverage name directo-
ries are available in the form of Wikipedia, IMDB,
etc. The availability of large authoritative name di-
rectories that serve as the source of trusted spellings
of names throws open the possibility of correcting
misspelled personal names with the help of name
matching techniques (Pfeifer et al., 1996), (Chris-
ten, 2006), (Navarro et al., 2003). However, the best
of the name matching techniques can at best work
with a few thousand names to give acceptable re-
sponse time and accuracy. They do not scale up to
the needs of People Search applications where the
directories can have millions of names.
In this work, we develop hashing-based name
similarity search techniques and employ them for
spelling correction of personal names. The motiva-
tion for using hashing as a building block of spelling
correction is the following: given a query, we want
to return the global best match in the name directory
</bodyText>
<footnote confidence="0.842864">
2http://www.facebook.com/directory/people/
</footnote>
<bodyText confidence="0.978192">
that exceeds a similarity threshold. As matching the
query with the names in the directory is a time con-
suming task especially for large name directories,
we solve the search problem in two stages:
</bodyText>
<listItem confidence="0.9960955">
• NAME BUCKETING: For each token of the
query, we do an approximate nearest neighbor
search of the name tokens of the directory and
produce a list of candidates, i.e., tokens that are
approximate matches of the query token. Using
the list of candidate tokens, we extract the list
of candidate names which contain at least one
approximately matching token.
• NAME MATCHING: We do a rigorous match-
ing of the query with candidate names.
</listItem>
<bodyText confidence="0.9963837">
Clearly, our success in finding the right name sug-
gestion for the query in the NAME MATCHING
stage depends crucially on our success in getting
the right name suggestion in the list of candidates
produced by the NAME BUCKETING stage search.
Therefore, we need a name similarity search tech-
nique that can ensure very high recall without pro-
ducing too many candidates. Hashing is best suited
for this task of fast and approximate name match-
ing. We hash the query tokens as well as directory
tokens into d bit binary codes. With binary codes,
finding approximate matches for a query token is as
easy as finding all the database tokens that are at a
Hamming distance of r or less from the query token
in the binary code representation (Shakhnarovich et
al., 2008), (Weiss et al., 2008). When the binary
codes are compact, this search can be done in a frac-
tion of a second on directories containing millions
of names on a simple processor.
Our contributions are:
</bodyText>
<listItem confidence="0.969189454545454">
• We develop a novel data-driven technique for
learning hash functions for mapping similar
names to similar binary codes using a set of
names in a given language/script (i.e. monolin-
gual data). We formulate the problem of learn-
ing hash functions as an optmization problem
whose relaxation can be solved as a generalized
Eigenvalue problem. (Section 2.1).
• We show that hash functions can also be learnt
using bilingual data in the form of name equiv-
alents in two languages. We formulate the
</listItem>
<page confidence="0.991469">
1257
</page>
<bodyText confidence="0.999950727272727">
where Id is an identity matrix of size d x d.
Note that the second constraint helps us avoid the
trap of mapping all names to the same codeword and
thereby making the Hamming error zero while satis-
fying the first and last constraints.
It can be shown that the above minimization prob-
lem is NP-hard even for 1-bit codewords (Weiss et
al., 2008). Further, the optimal solution gives code-
words only for the names in the training data. As we
want f to be defined for all s, we address the out-of-
sample extension problem by relaxing f as follows5:
</bodyText>
<equation confidence="0.982773">
fR (s) = ATo (s) = (aT1 o (s) , ... , aTd � (s))T (1)
</equation>
<bodyText confidence="0.99980725">
where A = [a1, ... , ad] E Rd1xd is a rank d matrix
(d &lt; d1).
After the linear relaxation (Equation 1), the first
constraint simply means that the data be centered,
i.e., have zero mean. We center Φ by subtracting the
mean of Φ from every 0 (s) E Φ to get ˆΦ.
Subsequent to the above relaxation, we get the
following optimization problem:
</bodyText>
<equation confidence="0.998736333333333">
minimize : Tr AT ˆΦLˆΦT A (2)
s.t.: (3)
AT ˆΦˆΦT A = P2Id (4)
</equation>
<bodyText confidence="0.998371666666667">
where L is the graph Laplacian for the similarity ma-
trix W defined by the pairwise similarities w (s, s&apos;).
The minimization problem can be transformed
into a generalized Eigenvalue problem and solved
efficiently using either Cholesky factorization or QZ
algorithm (Golub and Van Loan, 1996):
</bodyText>
<equation confidence="0.829958">
ˆΦLˆΦT A = ˆΦˆΦT AΛ (5)
</equation>
<bodyText confidence="0.9459755">
where Λ is a d x d diagonal matrix.
Once A has been estimated from the training data,
the codeword of a name s can be produced by bina-
rizing each coordinate of fR (s):
</bodyText>
<equation confidence="0.9633965">
f (s) = (sgn (aT1 o (s)) , ... ,sgn (aTd o (s)))T
(6)
</equation>
<bodyText confidence="0.95957148">
where sgn(u) = 1 if u &gt; 0 and −1 otherwise for all
u E R.
5In contrast to our approach, Spectral Hashing, a well-
known hashing technique, makes the unrealistic assumption
that the training data is sampled from a multidimensional uni-
form distribution to address the out-of-sample extension prob-
lem (Weiss et al., 2008).
problem of learning hash functions as an opt-
mization problem whose relaxation can be
solved using Canonical Correlation Analysis.
(Section 2.2)
• We develop new similarity measures for match-
ing names (Section 3.1).
• We evaluate the two methods systematically
and compare our performance against multiple
baselines. (Section 5).
2 Learning Hash Functions
In this section, we develop two techniques for learn-
ing hash functions using names as training data. In
the first approach, we use monolingual data consist-
ing of names in a language whereas in the second we
use bilingual name pairs. In both techniques, the key
idea is the same: we learn hash functions that map
similar names in the training data to similar code-
words.
</bodyText>
<subsectionHeader confidence="0.456396">
2.1 M-HASH: Learning with Monolingual
Names Data
</subsectionHeader>
<bodyText confidence="0.997398">
Let (s, s&apos;) be a pair of names and w (s, s&apos;) be their
similarity3. We are given a set of name pairs T =
{(s, s&apos;)} as the training data. Let 0 (s) E Rd1 be the
feature representation of s. We want to learn a hash
function f that maps each name to a d bit codeword:
f : s H {−1,1}d. We also want the Hamming dis-
tance of the codeword of s to the codeword of s&apos; be
small when w (s, s&apos;) is large. Further, we want each
bit of the codewords to be either 1 or −1 with equal
probablity and the successive bits of the codewords
to be uncorrelated. Thus we arrive at the following
optimization problem4:
</bodyText>
<equation confidence="0.85966375">
Xminimize: w (s,s&apos;) IIf(s) − f (s&apos;)112
(s,s0)ET
s.t. :
X f (s) = 0
s�(s,s0)ET
X f (s) f (s)T = P2Id
s�(s,s0)ET
f (s), f (s&apos;) E {−1,1}d
</equation>
<footnote confidence="0.9808485">
3We used 1− length normalized Edit Distance between s
and s0 as w (s, s0).
4Note that the Hamming distance of a codeword y to another
codeword y0 is 14 Ily − y0ll2.
</footnote>
<page confidence="0.992039">
1258
</page>
<bodyText confidence="0.99994">
In the reminder of this work, we call the system
that uses the hash function learnt from monolingual
data as M-HASH.
</bodyText>
<subsectionHeader confidence="0.983106">
2.2 B-HASH: Learning with Bilingual Names
Data
</subsectionHeader>
<bodyText confidence="0.999511357142857">
Let (s, t) be a pair of name s and its transliteration
equivalent t in a different language/script. We are
given the set T = {(s, t)} as the training data. Let
0 (s) E Rd1 (and resp. 0 (t) E Rd2) be the feature
representation of s (and resp. t). We want to learn
a pair of hash functions f, g that map names to d bit
codewords: f : s H {−1,1}d, g : t H {−1,1}d.
We also want the Hamming distance of the code-
word of a name to the codeword of its transliteration
be small. As in Section 2.1, we want each bit of the
codewords to be either 1 or −1 with equal probablity
and the successive bits of the codewords to be uncor-
related. Thus we arrive at the following optimization
problem:
</bodyText>
<equation confidence="0.9964195">
�minimize : 11f (s) − g (t)112
(s,t)ET
s.t. :
� f (s) = 0
s:(s,t)ET
� g (t) = 0
t:(s,t)ET
� f (s) f (s)T = P2Id
s:(s,t)ET
� g (t) g (t)T = P2Id
t:(s,t)ES
f (s) , g (t) E {−1,1}d
</equation>
<bodyText confidence="0.998841">
where Id is an identity matrix of size d x d.
As we want f (and resp. g) to be defined for all s
(and resp. t), we relax f (and resp. g) as follows:
</bodyText>
<equation confidence="0.999318">
fR (s) = ATo (s) (7)
gR (t) = BTo (s) (8)
</equation>
<bodyText confidence="0.999942">
where A = [a1, ... , ad] E Rd1xd and B =
[b1, ... , bd] E Rd2xd are rank d matrices.
As before, we center Φ and Ψ to get Φˆ and Ψˆ re-
spectively. Thus, we get the following optimization
</bodyText>
<equation confidence="0.948680285714286">
problem:
� �
minimize : Tr H A, B; ˆΦ, Ψˆ (9)
s.t. : (10)
AT ˆΦˆΦTA = P2Id (11)
BT ΨˆˆΨTB = P2Id (12)
( ) ( ) ( )T.
</equation>
<bodyText confidence="0.905459666666667">
where H A, B; ˆΦ, Ψˆ = AT Φˆ − BT Ψˆ AT Φˆ − BT Ψˆ
The minimization problem can be solved as a gen-
eralized Eigenvalue problem:
</bodyText>
<equation confidence="0.999957">
ΦˆˆΨTB = ˆΦˆΦTAΛ (13)
ˆΨˆΦTA = ΨˆˆΨTBΛ (14)
</equation>
<bodyText confidence="0.999736">
where Λ is a d x d diagonal matrix. Further, Equa-
tions 13 and 14 find the canonical coefficients of Φˆ
and Ψˆ (Hardoon et al., 2004).
As with monolingual learning, we get the code-
word of s by binarizing the coordinates of fR (s)6:
</bodyText>
<equation confidence="0.985912">
f (s) = (sgn (aT1 � (s)) , ... ,sgn (aTd O(s)��T
(15)
</equation>
<bodyText confidence="0.999856333333333">
In the reminder of this work, we call the system
that uses the hash function learnt from bilingual data
as B-HASH.
</bodyText>
<sectionHeader confidence="0.976832" genericHeader="introduction">
3 Similarity Score
</sectionHeader>
<bodyText confidence="0.999898">
In this section, we develop new techniques for com-
puting the similarity of names at token level as well
as a whole. We will use these techniques in the
NAME MATCHING stage of our algorithm (Sec-
tion 4.2.1).
</bodyText>
<subsectionHeader confidence="0.997994">
3.1 Token-level Similarity
</subsectionHeader>
<bodyText confidence="0.997969333333333">
We use a logistic function over multiple distance
measures to compute the similarity between name
tokens s and s&apos;:
</bodyText>
<equation confidence="0.927215">
K (s, s&apos;) = 1 + e− Ei αidi(s,s�). ( )
116
</equation>
<bodyText confidence="0.9774455">
While a variety of distance measures can be
employed in Equation 16, two obvious choices
</bodyText>
<footnote confidence="0.889978">
6As a biproduct of bilingual learning, we can hash names in
the second language using g:
</footnote>
<equation confidence="0.998559333333333">
( ( ) ( ))
g (t) = sgn bT 1 � (t) , . . . , sgn bT � � (t)
T
</equation>
<page confidence="0.939508">
1259
</page>
<bodyText confidence="0.999905375">
are the normalized Damerau-Levenshtein edit dis-
tance between s and s&apos; and the Hamming dis-
tance between the codewords of s and s&apos; (=
kf (s) − f (s&apos;)k). In our experiments, we found that
the continuous relaxation kfR (s) − fR (s&apos;)k was
better than kf (s) − f (s&apos;)k and hence we used it
with Damerau-Levenshtein edit distance. We esti-
mated α1 and α2 using a small held out set.
</bodyText>
<subsectionHeader confidence="0.999779">
3.2 Multi-token Name Similarity
</subsectionHeader>
<bodyText confidence="0.9801382">
Let Q = s1s2 ... sI and D = s&apos;1s&apos;2 ... s&apos;� be two
multi-token names. To compute the similarity be-
tween Q and D, we first form a weighted bipartite
graph with a node for each si and a node for each s&apos;
� and set edge weight to K si, s&apos;. We then compute
</bodyText>
<equation confidence="0.516532">
3)
</equation>
<bodyText confidence="0.871513333333333">
the weight (Kmax) of the maximum weighted match-
ing7 in this graph. The similarity between Q and D
is then computed as
</bodyText>
<sectionHeader confidence="0.986792" genericHeader="method">
4 Spelling Correction using Hashing
</sectionHeader>
<bodyText confidence="0.999754666666667">
In this section, we describe our algorithm for
spelling correction using hashing as a building
block.
</bodyText>
<subsectionHeader confidence="0.993592">
4.1 Indexing the Name Directory
</subsectionHeader>
<bodyText confidence="0.9999695">
Given a name directory, we break each name into its
constituent tokens and form a set of distinct name to-
kens. Using the name tokens and the original names,
we build an inverted index which, for each name to-
ken, lists all the names that have the token as a con-
stituent. Further, we hash each name token into a d
bit codeword as described in Equation 6 (and resp.
Equation 15) when using the hash function learnt on
monolingual data (and resp. bilingual data) and store
in a hash table.
</bodyText>
<subsectionHeader confidence="0.997142">
4.2 Querying the Name Directory
</subsectionHeader>
<bodyText confidence="0.8396645">
Querying is done in two stages:
NAME BUCKETING and NAME MATCHING.
</bodyText>
<footnote confidence="0.971233666666667">
7In practice, a maximal matching computed using a greedy
approach suffices since many of the edges in the bipartite graph
have low weight.
</footnote>
<subsubsectionHeader confidence="0.838123">
4.2.1 Name Bucketing
</subsubsectionHeader>
<bodyText confidence="0.999782111111111">
Given a query Q = s1s2 ... sI, we hash each si
into a codeword yi and retrieve all codewords in the
hash table that are at a Hamming distance of r or
less from yi. We rank the name tokens thus retrieved
using the token level similarity score of Section 3.1
and retain only the top 100. Using the top tokens, we
get all names which contain any of the name tokens
as a constituent to form the pool of candidates C for
the NAME MATCHING stage.
</bodyText>
<subsubsectionHeader confidence="0.884956">
4.2.2 Name Matching
</subsubsectionHeader>
<bodyText confidence="0.999388">
First we find the best match for a query Q in the
set of candidates C as follows:
</bodyText>
<equation confidence="0.8487966">
D* = argmax K (Q, D) . (18)
DEC
Next we suggest D* as the correction for Q if
K (Q, D*) exceeds a certain empirically determined
threshold.
</equation>
<sectionHeader confidence="0.998442" genericHeader="method">
5 Experiments and Results
</sectionHeader>
<bodyText confidence="0.9999854">
We now discuss the experiments we conducted to
study the retrieval performance of the two hashing-
based approaches developed in the previous sec-
tions. Apart from evaluating the systems on test sets
using different name directories, we were interested
in comparing our systems with several baselines, un-
derstanding the effect of some of the choices we
made (e.g. training data size, conjugate language)
and comparative analysis of retrieval performance
on queries of different complexity.
</bodyText>
<subsectionHeader confidence="0.976037">
5.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.9997885">
We tested the proposed hashing-based spelling cor-
rection algorithms on two test sets:
</bodyText>
<listItem confidence="0.999447444444444">
• DUMBTIONARY: 1231 misspellings of var-
ious names from Dumbtionary8 and a name
directory consisting of about 550,000 names
gleaned from the English Wikipedia. Each of
the misspellings had a correct spelling in the
name directory.
• INTRANET: 200 misspellings of employees
taken from the search logs of the intranet
of a large organization and a name directory
</listItem>
<footnote confidence="0.81794">
8http://www.dumbtionary.com
</footnote>
<equation confidence="0.996759">
K (Q, D) =
|I − J + 1|. (17)
Kmax
</equation>
<page confidence="0.805394">
1260
</page>
<bodyText confidence="0.983827555555556">
consisting of about 150, 000 employee names.
Each of the misspellings had a correct spelling
in the name directory.
Table 1 shows the average edit distance of a mis-
spelling from the correct name. Compared to
DUMBTIONARY, the misspellings in INTRANET
are more severe as the relatively high edit distance
indicates. Thus, INTRANET represents very hard
cases for spelling correction.
</bodyText>
<table confidence="0.999648666666667">
Test Set Average Std. Dev.
DUMBTIONARY 1.39 0.76
INTRANET 2.33 1.60
</table>
<tableCaption confidence="0.987013">
Table 1: Edit distance of a misspelling from the correct
name.
</tableCaption>
<subsubsectionHeader confidence="0.596722">
5.1.1 Training
</subsubsectionHeader>
<bodyText confidence="0.997610785714286">
For M-HASH, we used 30,000 single token
names in English (sampled from the list of names
in the Internet Movie Database9) as training data
and for B-HASH we used 14,941 parallel single to-
ken names in English-Hindi 10. Each name was
represented as a feature vector over character bi-
grams. Thus, the name token Klein has the bigrams
{·k, kl, le, ei, in, n·} as the features.
We learnt the hash functions from the training
data by solving the generalized Eigenvalue problems
of Sections 2.1 and 2.2. For both M-HASH and B-
HASH we used the top 32 Eigenvectors to form the
hash function resulting in a 32 bit representation for
every name token11.
</bodyText>
<subsubsectionHeader confidence="0.960352">
5.1.2 Performance Metric
</subsubsectionHeader>
<bodyText confidence="0.999925666666667">
We measured the performance of all the systems
using Precision@1, the fraction of names for which
a correct spelling was suggested at Rank 1.
</bodyText>
<subsectionHeader confidence="0.659359">
5.1.3 Baselines
</subsectionHeader>
<bodyText confidence="0.9992385">
The baselines are two popular search engines
(S1 and S2), Double Metaphone (DM), a widely
</bodyText>
<footnote confidence="0.714684285714286">
9http://www.imdb.com
10We obtained the names from the organizers
of NEWS2009 workshop (http://www.acl-ijcnlp-
2009.org/workshops/NEWS2009/pages/sharedtask.html).
11We experimented with codewords of various lengths and
found that the 32 bit representation gave the best tradeoff be-
tween retrieval accuracy and speed.
</footnote>
<bodyText confidence="0.9997305">
used phonetic search algorithm (Philips, 2000) and
BM25, a very popular Information Retrieval algo-
rithm (Manning et al., 2008). To use BM25 algo-
rithm for spelling correction, we represented each
name as a bag of bigrams and set the parameters K
and b to 2 and 0.75 respectively.
</bodyText>
<sectionHeader confidence="0.6203625" genericHeader="method">
5.2 Results
5.2.1 DUMBTIONARY
</sectionHeader>
<bodyText confidence="0.996313888888889">
Table 2 compares the results of the hashing-based
systems with the baselines on DUMBTIONARY. As
the misspellings in DUMBTIONARY are relatively
easier to correct, all the systems give reasonably
good retrieval results. Nevertheless, the results of
M-HASH and B-HASH are substantially better than
the baselines. M-HASH reduced the error over the
best baseline (S1) by 13.04% whereas B-HASH re-
duced by 46.17% (Table 6).
</bodyText>
<table confidence="0.780756">
M-HASH B-HASH S1 S2 DM BM25
87.93 92.53 86.12 79.33 78.95 84.70
</table>
<tableCaption confidence="0.9822595">
Table 2: Precision@1 of the various systems on DUMB-
TIONARY.
</tableCaption>
<bodyText confidence="0.9990351">
To get a deeper understanding of the retrieval per-
formance of the various systems, we studied queries
of varying complexity of misspelling. Table 3 com-
pares the results of our systems with S1 for queries
that are at various edit distances from the correct
names. We observe that M-HASH and B-HASH are
better than S1 in dealing with relatively less severe
misspellings. More interestingly, B-HASH is con-
sistently and significantly better than S1 even when
the misspellings are severe.
</bodyText>
<table confidence="0.999313">
Distance M-HASH B-HASH S1
1 96.18 96.55 89.59
2 81.79 87.42 75.76
3 44.07 67.80 59.65
4 21.05 31.58 29.42
5 0.00 37.50 0.00
</table>
<tableCaption confidence="0.994343">
Table 3: Precision@1 for queries at various edit distances
on DUMBTIONARY.
</tableCaption>
<sectionHeader confidence="0.840882" genericHeader="method">
5.2.2 INTRANET
</sectionHeader>
<bodyText confidence="0.9974245">
For INTRANET, search engines could not be used
as baselines and therefore we compare our systems
</bodyText>
<page confidence="0.978859">
1261
</page>
<bodyText confidence="0.991277714285714">
with Double Metaphone and BM25 in Table 4. We
observe that both M-HASH and B-HASH give sign-
ficantly better retrieval results than the baselines. M-
HASH reduced the error by 36.20% over Double
Metaphone whereas B-HASH reduced it by 51.73%.
Relative to BM25, M-HASH reduced the error by
31.87% whereas B-HASH reduced it by 48.44%.
</bodyText>
<table confidence="0.990555">
M-HASH B-HASH DM BM25
70.65 77.79 54.00 56.92
</table>
<tableCaption confidence="0.993767">
Table 4: Precision@1 of the various systems on IN-
TRANET.
</tableCaption>
<bodyText confidence="0.997614">
Table 5 shows the results of our systems for
queries that are at various edit distances from the
correct names. We observe that the retrieval results
for each category of queries are consistent with the
results on DUMBTIONARY. As before, B-HASH
gives signficantly better results than M-HASH.
</bodyText>
<table confidence="0.964551166666667">
Distance M-HASH B-HASH
1 82.76 87.93
2 57.14 72.86
3 34.29 65.71
4 38.46 53.85
5 6.67 26.67
</table>
<tableCaption confidence="0.968034">
Table 5: Precision@1 for queries at various edit distances
on INTRANET.
</tableCaption>
<table confidence="0.999111">
Test Set M-HASH B-HASH
DUMBTIONARY 13.04 46.17
INTRANET 36.20 51.73
</table>
<tableCaption confidence="0.9880775">
Table 6: Percentage error reduction over the best base-
line.
</tableCaption>
<subsectionHeader confidence="0.886059">
5.2.3 Effect of Training Data Size
</subsectionHeader>
<bodyText confidence="0.998686235294118">
As both M-HASH and B-HASH are data driven
systems, the effect of training data size on retrieval
performance is important to study. Table 7 com-
pares the results for systems trained with various
amounts of training data on DUMBTIONARY. B-
HASH trained with just 1000 name pairs gives
95.5% of the performance of B-HASH trained with
15000 name pairs. Similarly, M-HASH trained with
1000 names gives 98.5% of the performance of
M-HASH trained with 30000 name pairs. This is
probably because the spelling mistakes in DUMB-
TIONARY are relatively easy to correct.
Table 8 shows the results on INTRANET. We see
that increase in the size of training data brings sub-
stantial returns for B-HASH. In contrast, M-HASH
gives the best results at 5000 and does not seem to
benefit from additional training data.
</bodyText>
<table confidence="0.99843">
Size M-HASH B-HASH
1000 86.60 88.34
5000 87.36 91.13
10000 86.96 92.53
15000 87.19 92.20
30000 87.93 -
</table>
<tableCaption confidence="0.942453">
Table 7: Precision@1 on DUMBTIONARY as a function
of training data size.
</tableCaption>
<table confidence="0.999721">
Size M-HASH B-HASH
1000 66.04 66.03
5000 70.65 72.67
10000 68.09 75.26
15000 68.60 77.79
30000 65.40 -
</table>
<tableCaption confidence="0.9960615">
Table 8: Precision@1 on INTRANET as a function of
training data size.
</tableCaption>
<subsectionHeader confidence="0.942975">
5.2.4 Effect of Conjugate Language
</subsectionHeader>
<bodyText confidence="0.999947529411765">
In Sections 5.2.1 and 5.2.2, we saw that bilingual
data gives substantially better results than monolin-
gual data. In the experiments with bilingual data,
we used English-Hindi data for training B-HASH.
A natural question to ask is what happens when we
use someother language, say Hebrew or Russian or
Tamil, instead of Hindi. In other words, does the
retrieval performance, on an average, vary substan-
tially with the conjugate language?
Table 9 compares the results on DUMB-
TIONARY when B-HASH was trained using
English-Hindi, English-Hebrew, English-Russian,
and English-Tamil data. We see that the retrieval
results are good despite the differences in the script
and language. Clearly, the source language (English
in our experiments) benefits from being paired with
any target language. However, some languages seem
</bodyText>
<page confidence="0.986576">
1262
</page>
<bodyText confidence="0.999526222222222">
to give substantially better results than others when
used as the conjugate language. For instance, Hindi
as a conjugate for English seems to be better than
Tamil. At the time of writing this paper, we do not
know the reason for this behavior. We believe that a
combination of factors including feature representa-
tion, training data, and language-specific confusion
matrix need to be studied in greater depth to say any-
thing conclusively about conjugate languages.
</bodyText>
<table confidence="0.9989302">
Conjugate DUMBTIONARY INTRANET
Hindi 92.53 77.79
Hebrew 91.30 71.68
Russian 89.42 64.94
Tamil 90.48 69.12
</table>
<tableCaption confidence="0.9903795">
Table 9: Precision@1 of B-HASH for various conjugate
languages.
</tableCaption>
<subsectionHeader confidence="0.552067">
5.2.5 Error Analysis
</subsectionHeader>
<bodyText confidence="0.998052777777778">
We looked at cases where either M-HASH or
B-HASH (or both) failed to suggest the correct
spelling. It turns out that in the DUMBTIONARY
test set, for 81 misspelled names, both M-HASH and
B-HASH failed to suggest the correct name at rank
1. Similarly, in the case of INTRANET test set, both
M-HASH and B-HASH failed to suggest the correct
name at rank 1 for 47 queries. This suggests that
queries that are difficult for one system are also in
general difficult for the other system. However, B-
HASH was able to suggest correct names for some
of the queries where M-HASH failed. In fact, in the
INTRANET test set, whenever B-HASH failed, M-
HASH also failed. And interestingly, in the DUMB-
TIONARY test set, the average edit distance of the
query and the correct name for the cases where M-
HASH failed to get the correct name in top 10 while
B-HASH got it at rank 1 was 2.96. This could be be-
cause M-HASH attempts to map names with smaller
edit distances to similar codewords.
Table 10 shows some interesting cases we found
during error analysis. For the first query, M-HASH
suggested the correct name whereas B-HASH did
not. For the second query, both M-HASH and B-
HASH suggested the correct name. And for the third
query, B-HASH suggested the correct name whereas
M-HASH did not.
</bodyText>
<table confidence="0.93356275">
Query M-HASH B-HASH
John Tiler John Tyler John Tilley
Ddear Dragba Didear Drogba Didear Drogba
James Pol James Poe James Polk
</table>
<tableCaption confidence="0.998044">
Table 10: Error Analysis.
</tableCaption>
<subsectionHeader confidence="0.993632">
5.3 Query Response Time
</subsectionHeader>
<bodyText confidence="0.99981928">
The average query response time is a measure of
the speed of a system and is an important factor
in real deployments of a Spelling Correction sys-
tem. Ideally, one would like the average query re-
sponse time to be as small as possible. However, in
practice, average query response time is not only a
function of the algorithm’s computational complex-
ity but also the computational infrastructure support-
ing the system. In our expriments, we used a sin-
gle threaded implementation of M-HASH and B-
HASH on an Intel Xeon processor (2.86 GHz). Ta-
ble 11 shows the average query response time. We
note that M-HASH is substantially slower than B-
HASH. This is because the number of collisions
in the NAME BUCKETING stage is higher for M-
HASH.
We would like to point out that both
NAME BUCKETING and NAME MATCHING
stages can be multi-threaded on a multi-core ma-
chine and the query response time can be decreased
by an order easily. Further, the memory footprint
of the system is very small and the codewords
require 4.1 MB for the employees name directory
(150,000 names) and 13.8 MB for the Wikipedia
name directory (550,000 names).
</bodyText>
<table confidence="0.999233333333333">
Test Set MHASH BHASH
DUMBTIONARY 190 87
INTRANET 148 75
</table>
<tableCaption confidence="0.974395">
Table 11: Average response time in milliseconds (single
threaded system running on 2.86 GHz Intel Xeon Proces-
sor).
</tableCaption>
<sectionHeader confidence="0.999966" genericHeader="related work">
6 Related Work
</sectionHeader>
<bodyText confidence="0.99779">
Spelling correction of written text is a well stud-
ied problem (Kukich, 1996), (Jurafsky and Mar-
tin, 2008). The first approach to spelling correc-
</bodyText>
<page confidence="0.891092">
1263
</page>
<bodyText confidence="0.999988177419355">
tion made use of a lexicon to correct out-of-lexicon
terms by finding the closest in-lexicon word (Dam-
erau, 1964). The similarity between a misspelled
word and an in-lexicon word was measured using
Edit Distance (Jurafsky and Martin, 2008). The next
class of approaches applied the noisy channel model
to correct single word spelling errors (Kernighan et
al., 1990), (Brill and Moore, 2000). A major flaw of
single word spelling correction algorithms is they do
not make use of the context of the word in correcting
the errors. The next stream of approaches explored
ways of exploiting the word’s context (Golding and
Roth, 1996), (Cucerzan and Brill, 2004). Recently,
several works have leveraged the Web for improved
spelling correction (Chen et al., 2007),(Islam and
Inkpen, 2009), (Whitelaw et al., 2009). Spelling cor-
rection algorithms targeted for web-search queries
have been developed making use of query logs and
click-thru data (Cucerzan and Brill, 2004), (Ah-
mad and Kondrak, 2005), (Sun et al., 2010). None
of these approaches focus exclusively on correcting
name misspellings.
Name matching techniques have been studied in
the context of database record deduplication, text
mining, and information retrieval (Christen, 2006),
(Pfeifer et al., 1996). Most techniques use one or
more measures of phonetic similarity and/or string
similarity. The popular phonetic similarity-based
techniques are Soundex, Phonix, and Metaphone
(Pfeifer et al., 1996). Some of the string similarity-
based techniques employ Damerau-Levenshtein edit
distance, Jaro distance or Winkler distance (Chris-
ten, 2006). Data driven approaches for learning edit
distance have also been proposed (Ristad and Yiani-
los, 1996). Most of these techniques either give poor
retrieval performance on large name directories or
do not scale.
Hashing techniques for similarity search is also a
well studied problem (Shakhnarovich et al., 2008).
Locality Sensitive Hashing (LSH) is a theoretically
grounded data-oblivious approach for using random
projections to define the hash functions for data ob-
jects with a single view (Charikar, 2002), (Andoni
and Indyk, 2006). Although LSH guarantees that
asymptotically the Hamming distance between the
codewords approaches the Euclidean distance be-
tween the data objects, it is known to produce long
codewords making it practically inefficient. Re-
cently data-aware approaches that employ Machine
Learning techniques to learn hash functions have
been proposed and shown to be a lot more effective
than LSH on both synthetic and real data. Semantic
Hashing employs Restricted Boltzmann Machine to
produce more compact codes than LSH (Salakhutdi-
nov and Hinton, 2009). Spectral Hashing formalizes
the requirements for a good code and relates them to
the problem of balanced graph partitioning which is
known to be NP hard (Weiss et al., 2008). To give
a practical algorithm for hashing, Spectral Hashing
assumes that the data are sampled from a multidi-
mensional uniform distribution and solves a relaxed
partitioning problem.
</bodyText>
<sectionHeader confidence="0.999656" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999969838709677">
We developed two hashing-based techniques for
spelling correction of person names in People
Search applications.To the best of our knowledge,
these are the first techniques that focus exclusively
on correcting spelling mistakes in person names.
Our approach has several advantages over other
spelling correction techniques. Firstly, we do not
suggest incorrect suggestions for valid queries un-
like (Cucerzan and Brill, 2004). Further, as we sug-
gest spellings from only authoritative name direc-
tories, the suggestions are always well formed and
coherent. Secondly, we do not require query logs
and other resources that are not easily available un-
like (Cucerzan and Brill, 2004), (Ahmad and Kon-
drak, 2005). Neither do we require pairs of mis-
spelled names and their correct spellings for learn-
ing the error model unlike (Brill and Moore, 2000)
or large-coverage general purpose lexicon for unlike
(Cucerzan and Brill, 2004) or pronunciation dictio-
naries unlike (Toutanova and Moore, 2002). Thirdly,
we correct the query as a whole unlike (Ahmad and
Kondrak, 2005) and can handle word order changes
unlike (Cucerzan and Brill, 2004). Fourthly, we
do not iteratively process misspelled name unlike
(Cucerzan and Brill, 2004). Fifthly, we handle large
name directories efficiently unlike the spectrum of
name matching techniques discussed in (Pfeifer et
al., 1996). Finally, our training data requirement is
relatively small.
As future work, we would like to explore the pos-
sibility of learning hash functions using 1) bilingual
</bodyText>
<page confidence="0.976236">
1264
</page>
<bodyText confidence="0.9990985">
and monolingual data together and 2) multiple con-
jugate languages.
</bodyText>
<sectionHeader confidence="0.998417" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999928806122449">
Farooq Ahmad and Grzegorz Kondrak. 2005. Learn-
ing a spelling error model from search query logs. In
HLT ’05: Proceedings of the conference on Human
Language Technology and Empirical Methods in Nat-
ural Language Processing, pages 955–962, Morris-
town, NJ, USA. Association for Computational Lin-
guistics.
Alexandr Andoni and Piotr Indyk. 2006. Near-optimal
hashing algorithms for approximate nearest neighbor
in high dimensions. In FOCS, pages 459–468.
Rahul Bhagat and Eduard H. Hovy. 2007. Phonetic mod-
els for generating spelling variants. In IJCAI, pages
1570–1575.
Mikhail Bilenko, Raymond J. Mooney, William W. Co-
hen, Pradeep D. Ravikumar, and Stephen E. Fienberg.
2003. Adaptive name matching in information inte-
gration. IEEE Intelligent Systems, 18(5):16–23.
E. Brill and R. Moore. 2000. An improved error model
for noisy channel spelling correction. In Proceedings
of ACL ’00, pages 286–293.
Moses Charikar. 2002. Similarity estimation techniques
from rounding algorithms. In STOC, pages 380–388.
Qing Chen, Mu Li, and Ming Zhou. 2007. Improving
query spelling correction using web search results. In
EMNLP-CoNLL, pages 181–189.
P. Christen. 2006. A comparison of personal name
matching: techniques and practical issues. Techni-
cal Report TR-CS-06-02, Dept. of Computer Science,
ANU, Canberra.
William W. Cohen, Pradeep D. Ravikumar, and
Stephen E. Fienberg. 2003. A comparison of string
distance metrics for name-matching tasks. In IIWeb,
pages 73–78.
S Cucerzan and E. Brill. 2004. Spelling correction as an
iterative process that exploits the collective knowledge
of web users. In Proceedings of EMNLP ’04, pages
293–300.
F.J. Damerau. 1964. A technique for computer detection
and correction of spelling errors. Communications of
ACM, 7(3):171–176.
C. Friedman and R. Sideli. 1992. Tolerating spelling
errors during patient validation. Computers and
Biomedical Research, 25:486–509.
Andrew R. Golding and Dan Roth. 1996. Applying win-
now to context-sensitive spelling correction. CoRR,
cmp-lg/9607024.
Gene H. Golub and Charles F. Van Loan. 1996. Matrix
Computations. Johns Hopkins University Press, Balti-
more, MD, 3rd edition.
David R. Hardoon, S´andor Szedm´ak, and John Shawe-
Taylor. 2004. Canonical correlation analysis: An
overview with application to learning methods. Neu-
ral Computation, 16(12):2639–2664.
Aminul Islam and Diana Inkpen. 2009. Real-word
spelling correction using google web 1tn-gram data
set. In CIKM, pages 1689–1692.
D. Jurafsky and J.H. Martin. 2008. Speech and Lan-
guage Processing. Prentice-Hall.
Mark D. Kernighan, Kenneth W. Church, and William A.
Gale. 1990. A spelling correction program based on a
noisy channel model. In COLING, pages 205–210.
K. Kukich. 1996. Techniques for automatically correct-
ing words in a text. Computing Surveys, 24(4):377–
439.
Christopher D. Manning, Prabhakar Raghavan, and Hin-
rich Schtze. 2008. Introduction to Information Re-
trieval. Cambridge University Press.
G. Navarro, R. Baeza-Yates, and J. Azevedo-Arcoverde.
2003. Matchsimile: a flexible approximate matching
tool for searching proper names. Journal of the Amer-
ican Society for Information Science and Technology,
54(1):3–15.
U. Pfeifer, T. Poersch, and N. Fuhr. 1996. Retrieval ef-
fectiveness of proper name search methods. Informa-
tion Processing and Management, 32(6):667–679.
L. Philips. 2000. The double metaphone search algo-
rithm. C/C++ Users Journal.
Eric Sven Ristad and Peter N. Yianilos. 1996. Learning
string edit distance. CoRR, cmp-lg/9610005.
Ruslan Salakhutdinov and Geoffrey E. Hinton. 2009. Se-
mantic hashing. Int. J. Approx. Reasoning, 50(7):969–
978.
Gregory Shakhnarovich, Trevor Darrell, and Piotr In-
dyk. 2008. Nearest-neighbor methods in learning
and vision. IEEE Transactions on Neural Networks,
19(2):377–377.
Xu Sun, Jianfeng Gao, Daniel Micol, and Chris Quirk.
2010. Learning phrase-based spelling error models
from clickthrough data. In Proceedings of ACL 2010.
K. Toutanova and R. Moore. 2002. Pronounciation mod-
eling for improved spelling correction. In Proceedings
of ACL ’02, pages 141–151.
Yair Weiss, Antonio B. Torralba, and Robert Fergus.
2008. Spectral hashing. In NIPS, pages 1753–1760.
Casey Whitelaw, Ben Hutchinson, Grace Chung, and Ged
Ellis. 2009. Using the web for language independent
spellchecking and autocorrection. In EMNLP, pages
890–899.
</reference>
<page confidence="0.991155">
1265
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.193211">
<title confidence="0.997462">Hashing-based Approaches to Spelling Correction of Personal Names</title>
<author confidence="0.904185">Raghavendra</author>
<affiliation confidence="0.999144">Microsoft Research</affiliation>
<address confidence="0.516793">Bangalore,</address>
<email confidence="0.999759">raghavu@microsoft.com</email>
<author confidence="0.804444">Shaishav</author>
<affiliation confidence="0.7620335">Microsoft Research Bangalore,</affiliation>
<email confidence="0.999719">v-shaisk@microsoft.com</email>
<abstract confidence="0.998849823529412">We propose two hashing-based solutions to the problem of fast and effective personal names spelling correction in People Search applications. The key idea behind our methods is to learn hash functions that map similar names to similar (and compact) binary codewords. The two methods differ in the data they use for learning the hash functions the first method uses a set of names in a given language/script whereas the second uses a set of bilingual names. We show that both methods give excellent retrieval performance in comparison to several baselines on two lists of misspelled personal names. More over, the method that uses bilingual data for learning hash functions gives the best performance.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Farooq Ahmad</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Learning a spelling error model from search query logs.</title>
<date>2005</date>
<booktitle>In HLT ’05: Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing,</booktitle>
<pages>955--962</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="3856" citStr="Ahmad and Kondrak, 2005" startWordPosition="611" endWordPosition="614">text windows 1In contrast, 80% of misspelled words in general text are due to single typographical errors as found by (Damerau, 1964). 1256 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1256–1265, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics which are not available for queries in Web Search and People Search. Spelling correction techniques meant for general purpose web-queries require large volumes of training data in the form of query logs for learning the error models (Cucerzan and Brill, 2004), (Ahmad and Kondrak, 2005). However, query logs are not available in some applications (e.g. Email address book search). Further, unlike general purpose web-queries where word order often matters, in People Search word order is lax (e.g. I might search for either Kristina Toutanova or Toutanova Kristina). Therefore, spelling correction techniques that rely crucially on bigram and higher order language models will fail on queries with a different word order than what is observed in the query log. Unlike general purpose Web Search where it is not reasonable to assume the availability of a highcoverage trusted lexicon, Pe</context>
<context position="28677" citStr="Ahmad and Kondrak, 2005" startWordPosition="4981" endWordPosition="4985">(Brill and Moore, 2000). A major flaw of single word spelling correction algorithms is they do not make use of the context of the word in correcting the errors. The next stream of approaches explored ways of exploiting the word’s context (Golding and Roth, 1996), (Cucerzan and Brill, 2004). Recently, several works have leveraged the Web for improved spelling correction (Chen et al., 2007),(Islam and Inkpen, 2009), (Whitelaw et al., 2009). Spelling correction algorithms targeted for web-search queries have been developed making use of query logs and click-thru data (Cucerzan and Brill, 2004), (Ahmad and Kondrak, 2005), (Sun et al., 2010). None of these approaches focus exclusively on correcting name misspellings. Name matching techniques have been studied in the context of database record deduplication, text mining, and information retrieval (Christen, 2006), (Pfeifer et al., 1996). Most techniques use one or more measures of phonetic similarity and/or string similarity. The popular phonetic similarity-based techniques are Soundex, Phonix, and Metaphone (Pfeifer et al., 1996). Some of the string similaritybased techniques employ Damerau-Levenshtein edit distance, Jaro distance or Winkler distance (Christen</context>
<context position="31435" citStr="Ahmad and Kondrak, 2005" startWordPosition="5393" endWordPosition="5397">es in People Search applications.To the best of our knowledge, these are the first techniques that focus exclusively on correcting spelling mistakes in person names. Our approach has several advantages over other spelling correction techniques. Firstly, we do not suggest incorrect suggestions for valid queries unlike (Cucerzan and Brill, 2004). Further, as we suggest spellings from only authoritative name directories, the suggestions are always well formed and coherent. Secondly, we do not require query logs and other resources that are not easily available unlike (Cucerzan and Brill, 2004), (Ahmad and Kondrak, 2005). Neither do we require pairs of misspelled names and their correct spellings for learning the error model unlike (Brill and Moore, 2000) or large-coverage general purpose lexicon for unlike (Cucerzan and Brill, 2004) or pronunciation dictionaries unlike (Toutanova and Moore, 2002). Thirdly, we correct the query as a whole unlike (Ahmad and Kondrak, 2005) and can handle word order changes unlike (Cucerzan and Brill, 2004). Fourthly, we do not iteratively process misspelled name unlike (Cucerzan and Brill, 2004). Fifthly, we handle large name directories efficiently unlike the spectrum of name </context>
</contexts>
<marker>Ahmad, Kondrak, 2005</marker>
<rawString>Farooq Ahmad and Grzegorz Kondrak. 2005. Learning a spelling error model from search query logs. In HLT ’05: Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, pages 955–962, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandr Andoni</author>
<author>Piotr Indyk</author>
</authors>
<title>Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions. In FOCS,</title>
<date>2006</date>
<pages>459--468</pages>
<contexts>
<context position="29819" citStr="Andoni and Indyk, 2006" startWordPosition="5147" endWordPosition="5150">oy Damerau-Levenshtein edit distance, Jaro distance or Winkler distance (Christen, 2006). Data driven approaches for learning edit distance have also been proposed (Ristad and Yianilos, 1996). Most of these techniques either give poor retrieval performance on large name directories or do not scale. Hashing techniques for similarity search is also a well studied problem (Shakhnarovich et al., 2008). Locality Sensitive Hashing (LSH) is a theoretically grounded data-oblivious approach for using random projections to define the hash functions for data objects with a single view (Charikar, 2002), (Andoni and Indyk, 2006). Although LSH guarantees that asymptotically the Hamming distance between the codewords approaches the Euclidean distance between the data objects, it is known to produce long codewords making it practically inefficient. Recently data-aware approaches that employ Machine Learning techniques to learn hash functions have been proposed and shown to be a lot more effective than LSH on both synthetic and real data. Semantic Hashing employs Restricted Boltzmann Machine to produce more compact codes than LSH (Salakhutdinov and Hinton, 2009). Spectral Hashing formalizes the requirements for a good co</context>
</contexts>
<marker>Andoni, Indyk, 2006</marker>
<rawString>Alexandr Andoni and Piotr Indyk. 2006. Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions. In FOCS, pages 459–468.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rahul Bhagat</author>
<author>Eduard H Hovy</author>
</authors>
<title>Phonetic models for generating spelling variants.</title>
<date>2007</date>
<booktitle>In IJCAI,</booktitle>
<pages>1570--1575</pages>
<marker>Bhagat, Hovy, 2007</marker>
<rawString>Rahul Bhagat and Eduard H. Hovy. 2007. Phonetic models for generating spelling variants. In IJCAI, pages 1570–1575.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mikhail Bilenko</author>
<author>Raymond J Mooney</author>
<author>William W Cohen</author>
<author>Pradeep D Ravikumar</author>
<author>Stephen E Fienberg</author>
</authors>
<title>Adaptive name matching in information integration.</title>
<date>2003</date>
<journal>IEEE Intelligent Systems,</journal>
<volume>18</volume>
<issue>5</issue>
<marker>Bilenko, Mooney, Cohen, Ravikumar, Fienberg, 2003</marker>
<rawString>Mikhail Bilenko, Raymond J. Mooney, William W. Cohen, Pradeep D. Ravikumar, and Stephen E. Fienberg. 2003. Adaptive name matching in information integration. IEEE Intelligent Systems, 18(5):16–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
<author>R Moore</author>
</authors>
<title>An improved error model for noisy channel spelling correction.</title>
<date>2000</date>
<booktitle>In Proceedings of ACL ’00,</booktitle>
<pages>286--293</pages>
<contexts>
<context position="28076" citStr="Brill and Moore, 2000" startWordPosition="4887" endWordPosition="4890"> (single threaded system running on 2.86 GHz Intel Xeon Processor). 6 Related Work Spelling correction of written text is a well studied problem (Kukich, 1996), (Jurafsky and Martin, 2008). The first approach to spelling correc1263 tion made use of a lexicon to correct out-of-lexicon terms by finding the closest in-lexicon word (Damerau, 1964). The similarity between a misspelled word and an in-lexicon word was measured using Edit Distance (Jurafsky and Martin, 2008). The next class of approaches applied the noisy channel model to correct single word spelling errors (Kernighan et al., 1990), (Brill and Moore, 2000). A major flaw of single word spelling correction algorithms is they do not make use of the context of the word in correcting the errors. The next stream of approaches explored ways of exploiting the word’s context (Golding and Roth, 1996), (Cucerzan and Brill, 2004). Recently, several works have leveraged the Web for improved spelling correction (Chen et al., 2007),(Islam and Inkpen, 2009), (Whitelaw et al., 2009). Spelling correction algorithms targeted for web-search queries have been developed making use of query logs and click-thru data (Cucerzan and Brill, 2004), (Ahmad and Kondrak, 2005</context>
<context position="31572" citStr="Brill and Moore, 2000" startWordPosition="5418" endWordPosition="5421"> mistakes in person names. Our approach has several advantages over other spelling correction techniques. Firstly, we do not suggest incorrect suggestions for valid queries unlike (Cucerzan and Brill, 2004). Further, as we suggest spellings from only authoritative name directories, the suggestions are always well formed and coherent. Secondly, we do not require query logs and other resources that are not easily available unlike (Cucerzan and Brill, 2004), (Ahmad and Kondrak, 2005). Neither do we require pairs of misspelled names and their correct spellings for learning the error model unlike (Brill and Moore, 2000) or large-coverage general purpose lexicon for unlike (Cucerzan and Brill, 2004) or pronunciation dictionaries unlike (Toutanova and Moore, 2002). Thirdly, we correct the query as a whole unlike (Ahmad and Kondrak, 2005) and can handle word order changes unlike (Cucerzan and Brill, 2004). Fourthly, we do not iteratively process misspelled name unlike (Cucerzan and Brill, 2004). Fifthly, we handle large name directories efficiently unlike the spectrum of name matching techniques discussed in (Pfeifer et al., 1996). Finally, our training data requirement is relatively small. As future work, we w</context>
</contexts>
<marker>Brill, Moore, 2000</marker>
<rawString>E. Brill and R. Moore. 2000. An improved error model for noisy channel spelling correction. In Proceedings of ACL ’00, pages 286–293.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Moses Charikar</author>
</authors>
<title>Similarity estimation techniques from rounding algorithms.</title>
<date>2002</date>
<booktitle>In STOC,</booktitle>
<pages>380--388</pages>
<contexts>
<context position="29793" citStr="Charikar, 2002" startWordPosition="5145" endWordPosition="5146">ed techniques employ Damerau-Levenshtein edit distance, Jaro distance or Winkler distance (Christen, 2006). Data driven approaches for learning edit distance have also been proposed (Ristad and Yianilos, 1996). Most of these techniques either give poor retrieval performance on large name directories or do not scale. Hashing techniques for similarity search is also a well studied problem (Shakhnarovich et al., 2008). Locality Sensitive Hashing (LSH) is a theoretically grounded data-oblivious approach for using random projections to define the hash functions for data objects with a single view (Charikar, 2002), (Andoni and Indyk, 2006). Although LSH guarantees that asymptotically the Hamming distance between the codewords approaches the Euclidean distance between the data objects, it is known to produce long codewords making it practically inefficient. Recently data-aware approaches that employ Machine Learning techniques to learn hash functions have been proposed and shown to be a lot more effective than LSH on both synthetic and real data. Semantic Hashing employs Restricted Boltzmann Machine to produce more compact codes than LSH (Salakhutdinov and Hinton, 2009). Spectral Hashing formalizes the </context>
</contexts>
<marker>Charikar, 2002</marker>
<rawString>Moses Charikar. 2002. Similarity estimation techniques from rounding algorithms. In STOC, pages 380–388.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qing Chen</author>
<author>Mu Li</author>
<author>Ming Zhou</author>
</authors>
<title>Improving query spelling correction using web search results. In EMNLP-CoNLL,</title>
<date>2007</date>
<pages>181--189</pages>
<contexts>
<context position="28444" citStr="Chen et al., 2007" startWordPosition="4947" endWordPosition="4950">misspelled word and an in-lexicon word was measured using Edit Distance (Jurafsky and Martin, 2008). The next class of approaches applied the noisy channel model to correct single word spelling errors (Kernighan et al., 1990), (Brill and Moore, 2000). A major flaw of single word spelling correction algorithms is they do not make use of the context of the word in correcting the errors. The next stream of approaches explored ways of exploiting the word’s context (Golding and Roth, 1996), (Cucerzan and Brill, 2004). Recently, several works have leveraged the Web for improved spelling correction (Chen et al., 2007),(Islam and Inkpen, 2009), (Whitelaw et al., 2009). Spelling correction algorithms targeted for web-search queries have been developed making use of query logs and click-thru data (Cucerzan and Brill, 2004), (Ahmad and Kondrak, 2005), (Sun et al., 2010). None of these approaches focus exclusively on correcting name misspellings. Name matching techniques have been studied in the context of database record deduplication, text mining, and information retrieval (Christen, 2006), (Pfeifer et al., 1996). Most techniques use one or more measures of phonetic similarity and/or string similarity. The po</context>
</contexts>
<marker>Chen, Li, Zhou, 2007</marker>
<rawString>Qing Chen, Mu Li, and Ming Zhou. 2007. Improving query spelling correction using web search results. In EMNLP-CoNLL, pages 181–189.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Christen</author>
</authors>
<title>A comparison of personal name matching: techniques and practical issues.</title>
<date>2006</date>
<tech>Technical Report TR-CS-06-02,</tech>
<institution>Dept. of Computer Science,</institution>
<location>ANU, Canberra.</location>
<contexts>
<context position="5266" citStr="Christen, 2006" startWordPosition="841" endWordPosition="843">ople directory2 (assuming that the friend is a registered user of Facebook at the time of the search). Similarly, if one is searching for a contact in Enterprise address book, the correct spelling of the contact is part of the address book. In fact, even in Web Search, broad-coverage name directories are available in the form of Wikipedia, IMDB, etc. The availability of large authoritative name directories that serve as the source of trusted spellings of names throws open the possibility of correcting misspelled personal names with the help of name matching techniques (Pfeifer et al., 1996), (Christen, 2006), (Navarro et al., 2003). However, the best of the name matching techniques can at best work with a few thousand names to give acceptable response time and accuracy. They do not scale up to the needs of People Search applications where the directories can have millions of names. In this work, we develop hashing-based name similarity search techniques and employ them for spelling correction of personal names. The motivation for using hashing as a building block of spelling correction is the following: given a query, we want to return the global best match in the name directory 2http://www.faceb</context>
<context position="28922" citStr="Christen, 2006" startWordPosition="5018" endWordPosition="5019">h, 1996), (Cucerzan and Brill, 2004). Recently, several works have leveraged the Web for improved spelling correction (Chen et al., 2007),(Islam and Inkpen, 2009), (Whitelaw et al., 2009). Spelling correction algorithms targeted for web-search queries have been developed making use of query logs and click-thru data (Cucerzan and Brill, 2004), (Ahmad and Kondrak, 2005), (Sun et al., 2010). None of these approaches focus exclusively on correcting name misspellings. Name matching techniques have been studied in the context of database record deduplication, text mining, and information retrieval (Christen, 2006), (Pfeifer et al., 1996). Most techniques use one or more measures of phonetic similarity and/or string similarity. The popular phonetic similarity-based techniques are Soundex, Phonix, and Metaphone (Pfeifer et al., 1996). Some of the string similaritybased techniques employ Damerau-Levenshtein edit distance, Jaro distance or Winkler distance (Christen, 2006). Data driven approaches for learning edit distance have also been proposed (Ristad and Yianilos, 1996). Most of these techniques either give poor retrieval performance on large name directories or do not scale. Hashing techniques for sim</context>
</contexts>
<marker>Christen, 2006</marker>
<rawString>P. Christen. 2006. A comparison of personal name matching: techniques and practical issues. Technical Report TR-CS-06-02, Dept. of Computer Science, ANU, Canberra.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William W Cohen</author>
<author>Pradeep D Ravikumar</author>
<author>Stephen E Fienberg</author>
</authors>
<title>A comparison of string distance metrics for name-matching tasks. In IIWeb,</title>
<date>2003</date>
<pages>73--78</pages>
<marker>Cohen, Ravikumar, Fienberg, 2003</marker>
<rawString>William W. Cohen, Pradeep D. Ravikumar, and Stephen E. Fienberg. 2003. A comparison of string distance metrics for name-matching tasks. In IIWeb, pages 73–78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Cucerzan</author>
<author>E Brill</author>
</authors>
<title>Spelling correction as an iterative process that exploits the collective knowledge of web users.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP ’04,</booktitle>
<pages>293--300</pages>
<contexts>
<context position="3069" citStr="Cucerzan and Brill, 2004" startWordPosition="492" endWordPosition="495">o within-the-word errors, People Search queries are plagued by errors that are not usually seen in general text. The study by Friedman and Sideli discovered that 36% of the errors were due to addition or deletion of a word (as in Ricardo Baeza for Ricardo Baeza-Yates) (Friedman and Sideli, 1992). Although word addition and deletion generally do not come under the purview of spelling correction, in People Search they are important and need to be addressed. Standard approaches to general purpose spelling correction are not well-suited for correcting misspelled personal names. As pointed out by (Cucerzan and Brill, 2004), these approaches either try to correct individual words (and will fail to correct Him Clijsters to Kim Clijsters) or employ features based on relatively wide context windows 1In contrast, 80% of misspelled words in general text are due to single typographical errors as found by (Damerau, 1964). 1256 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1256–1265, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics which are not available for queries in Web Search and People Search. Spelling correction techniques</context>
<context position="28343" citStr="Cucerzan and Brill, 2004" startWordPosition="4932" endWordPosition="4935">rrect out-of-lexicon terms by finding the closest in-lexicon word (Damerau, 1964). The similarity between a misspelled word and an in-lexicon word was measured using Edit Distance (Jurafsky and Martin, 2008). The next class of approaches applied the noisy channel model to correct single word spelling errors (Kernighan et al., 1990), (Brill and Moore, 2000). A major flaw of single word spelling correction algorithms is they do not make use of the context of the word in correcting the errors. The next stream of approaches explored ways of exploiting the word’s context (Golding and Roth, 1996), (Cucerzan and Brill, 2004). Recently, several works have leveraged the Web for improved spelling correction (Chen et al., 2007),(Islam and Inkpen, 2009), (Whitelaw et al., 2009). Spelling correction algorithms targeted for web-search queries have been developed making use of query logs and click-thru data (Cucerzan and Brill, 2004), (Ahmad and Kondrak, 2005), (Sun et al., 2010). None of these approaches focus exclusively on correcting name misspellings. Name matching techniques have been studied in the context of database record deduplication, text mining, and information retrieval (Christen, 2006), (Pfeifer et al., 19</context>
<context position="31156" citStr="Cucerzan and Brill, 2004" startWordPosition="5348" endWordPosition="5351">08). To give a practical algorithm for hashing, Spectral Hashing assumes that the data are sampled from a multidimensional uniform distribution and solves a relaxed partitioning problem. 7 Conclusions We developed two hashing-based techniques for spelling correction of person names in People Search applications.To the best of our knowledge, these are the first techniques that focus exclusively on correcting spelling mistakes in person names. Our approach has several advantages over other spelling correction techniques. Firstly, we do not suggest incorrect suggestions for valid queries unlike (Cucerzan and Brill, 2004). Further, as we suggest spellings from only authoritative name directories, the suggestions are always well formed and coherent. Secondly, we do not require query logs and other resources that are not easily available unlike (Cucerzan and Brill, 2004), (Ahmad and Kondrak, 2005). Neither do we require pairs of misspelled names and their correct spellings for learning the error model unlike (Brill and Moore, 2000) or large-coverage general purpose lexicon for unlike (Cucerzan and Brill, 2004) or pronunciation dictionaries unlike (Toutanova and Moore, 2002). Thirdly, we correct the query as a wh</context>
</contexts>
<marker>Cucerzan, Brill, 2004</marker>
<rawString>S Cucerzan and E. Brill. 2004. Spelling correction as an iterative process that exploits the collective knowledge of web users. In Proceedings of EMNLP ’04, pages 293–300.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Damerau</author>
</authors>
<title>A technique for computer detection and correction of spelling errors.</title>
<date>1964</date>
<journal>Communications of ACM,</journal>
<volume>7</volume>
<issue>3</issue>
<contexts>
<context position="3365" citStr="Damerau, 1964" startWordPosition="542" endWordPosition="543">word addition and deletion generally do not come under the purview of spelling correction, in People Search they are important and need to be addressed. Standard approaches to general purpose spelling correction are not well-suited for correcting misspelled personal names. As pointed out by (Cucerzan and Brill, 2004), these approaches either try to correct individual words (and will fail to correct Him Clijsters to Kim Clijsters) or employ features based on relatively wide context windows 1In contrast, 80% of misspelled words in general text are due to single typographical errors as found by (Damerau, 1964). 1256 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1256–1265, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics which are not available for queries in Web Search and People Search. Spelling correction techniques meant for general purpose web-queries require large volumes of training data in the form of query logs for learning the error models (Cucerzan and Brill, 2004), (Ahmad and Kondrak, 2005). However, query logs are not available in some applications (e.g. Email address book search). Further, unlik</context>
<context position="27799" citStr="Damerau, 1964" startWordPosition="4845" endWordPosition="4847"> system is very small and the codewords require 4.1 MB for the employees name directory (150,000 names) and 13.8 MB for the Wikipedia name directory (550,000 names). Test Set MHASH BHASH DUMBTIONARY 190 87 INTRANET 148 75 Table 11: Average response time in milliseconds (single threaded system running on 2.86 GHz Intel Xeon Processor). 6 Related Work Spelling correction of written text is a well studied problem (Kukich, 1996), (Jurafsky and Martin, 2008). The first approach to spelling correc1263 tion made use of a lexicon to correct out-of-lexicon terms by finding the closest in-lexicon word (Damerau, 1964). The similarity between a misspelled word and an in-lexicon word was measured using Edit Distance (Jurafsky and Martin, 2008). The next class of approaches applied the noisy channel model to correct single word spelling errors (Kernighan et al., 1990), (Brill and Moore, 2000). A major flaw of single word spelling correction algorithms is they do not make use of the context of the word in correcting the errors. The next stream of approaches explored ways of exploiting the word’s context (Golding and Roth, 1996), (Cucerzan and Brill, 2004). Recently, several works have leveraged the Web for imp</context>
</contexts>
<marker>Damerau, 1964</marker>
<rawString>F.J. Damerau. 1964. A technique for computer detection and correction of spelling errors. Communications of ACM, 7(3):171–176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Friedman</author>
<author>R Sideli</author>
</authors>
<title>Tolerating spelling errors during patient validation.</title>
<date>1992</date>
<booktitle>Computers and Biomedical Research,</booktitle>
<pages>25--486</pages>
<contexts>
<context position="2080" citStr="Friedman and Sideli, 1992" startWordPosition="331" endWordPosition="334"> very important role in not only reducing the time and effort needed by users to find people they are searching for but also in ensuring good user experience. Spelling errors in personal names are of a different nature compared to those in general text. Long before People Search became widely popular, researchers working on the problem of personal name matching had recognized the human tendency to be inexact in recollecting names from the memory and specifying them. A study of personal names in hospital databases found that only 39% of the errors in the names were single typographical errors (Friedman and Sideli, 1992)1. Further, multiple and long distance typographical errors (Gregzorz Kondrak for Grzegorz Kondrak), phonetic errors (as in Erik Bryl for Eric Brill), cognitive errors (as in Silvia Cucerzan for Silviu Cucerzan) and word substitutions (as in Rob Moore for Bob Moore) are observed relatively more frequently in personal names compared to general text. In addition to within-the-word errors, People Search queries are plagued by errors that are not usually seen in general text. The study by Friedman and Sideli discovered that 36% of the errors were due to addition or deletion of a word (as in Ricard</context>
</contexts>
<marker>Friedman, Sideli, 1992</marker>
<rawString>C. Friedman and R. Sideli. 1992. Tolerating spelling errors during patient validation. Computers and Biomedical Research, 25:486–509.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew R Golding</author>
<author>Dan Roth</author>
</authors>
<title>Applying winnow to context-sensitive spelling correction.</title>
<date>1996</date>
<location>CoRR, cmp-lg/9607024.</location>
<contexts>
<context position="28315" citStr="Golding and Roth, 1996" startWordPosition="4928" endWordPosition="4931">ade use of a lexicon to correct out-of-lexicon terms by finding the closest in-lexicon word (Damerau, 1964). The similarity between a misspelled word and an in-lexicon word was measured using Edit Distance (Jurafsky and Martin, 2008). The next class of approaches applied the noisy channel model to correct single word spelling errors (Kernighan et al., 1990), (Brill and Moore, 2000). A major flaw of single word spelling correction algorithms is they do not make use of the context of the word in correcting the errors. The next stream of approaches explored ways of exploiting the word’s context (Golding and Roth, 1996), (Cucerzan and Brill, 2004). Recently, several works have leveraged the Web for improved spelling correction (Chen et al., 2007),(Islam and Inkpen, 2009), (Whitelaw et al., 2009). Spelling correction algorithms targeted for web-search queries have been developed making use of query logs and click-thru data (Cucerzan and Brill, 2004), (Ahmad and Kondrak, 2005), (Sun et al., 2010). None of these approaches focus exclusively on correcting name misspellings. Name matching techniques have been studied in the context of database record deduplication, text mining, and information retrieval (Christen</context>
</contexts>
<marker>Golding, Roth, 1996</marker>
<rawString>Andrew R. Golding and Dan Roth. 1996. Applying winnow to context-sensitive spelling correction. CoRR, cmp-lg/9607024.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gene H Golub</author>
<author>Charles F Van Loan</author>
</authors>
<title>Matrix Computations.</title>
<date>1996</date>
<publisher>Johns Hopkins University Press,</publisher>
<location>Baltimore, MD,</location>
<note>3rd edition.</note>
<marker>Golub, Van Loan, 1996</marker>
<rawString>Gene H. Golub and Charles F. Van Loan. 1996. Matrix Computations. Johns Hopkins University Press, Baltimore, MD, 3rd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David R Hardoon</author>
<author>S´andor Szedm´ak</author>
<author>John ShaweTaylor</author>
</authors>
<title>Canonical correlation analysis: An overview with application to learning methods.</title>
<date>2004</date>
<journal>Neural Computation,</journal>
<volume>16</volume>
<issue>12</issue>
<marker>Hardoon, Szedm´ak, ShaweTaylor, 2004</marker>
<rawString>David R. Hardoon, S´andor Szedm´ak, and John ShaweTaylor. 2004. Canonical correlation analysis: An overview with application to learning methods. Neural Computation, 16(12):2639–2664.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aminul Islam</author>
<author>Diana Inkpen</author>
</authors>
<title>Real-word spelling correction using google web 1tn-gram data set.</title>
<date>2009</date>
<booktitle>In CIKM,</booktitle>
<pages>1689--1692</pages>
<contexts>
<context position="28469" citStr="Islam and Inkpen, 2009" startWordPosition="4950" endWordPosition="4953">an in-lexicon word was measured using Edit Distance (Jurafsky and Martin, 2008). The next class of approaches applied the noisy channel model to correct single word spelling errors (Kernighan et al., 1990), (Brill and Moore, 2000). A major flaw of single word spelling correction algorithms is they do not make use of the context of the word in correcting the errors. The next stream of approaches explored ways of exploiting the word’s context (Golding and Roth, 1996), (Cucerzan and Brill, 2004). Recently, several works have leveraged the Web for improved spelling correction (Chen et al., 2007),(Islam and Inkpen, 2009), (Whitelaw et al., 2009). Spelling correction algorithms targeted for web-search queries have been developed making use of query logs and click-thru data (Cucerzan and Brill, 2004), (Ahmad and Kondrak, 2005), (Sun et al., 2010). None of these approaches focus exclusively on correcting name misspellings. Name matching techniques have been studied in the context of database record deduplication, text mining, and information retrieval (Christen, 2006), (Pfeifer et al., 1996). Most techniques use one or more measures of phonetic similarity and/or string similarity. The popular phonetic similarity</context>
</contexts>
<marker>Islam, Inkpen, 2009</marker>
<rawString>Aminul Islam and Diana Inkpen. 2009. Real-word spelling correction using google web 1tn-gram data set. In CIKM, pages 1689–1692.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Jurafsky</author>
<author>J H Martin</author>
</authors>
<title>Speech and Language Processing.</title>
<date>2008</date>
<publisher>Prentice-Hall.</publisher>
<contexts>
<context position="27642" citStr="Jurafsky and Martin, 2008" startWordPosition="4817" endWordPosition="4821"> NAME MATCHING stages can be multi-threaded on a multi-core machine and the query response time can be decreased by an order easily. Further, the memory footprint of the system is very small and the codewords require 4.1 MB for the employees name directory (150,000 names) and 13.8 MB for the Wikipedia name directory (550,000 names). Test Set MHASH BHASH DUMBTIONARY 190 87 INTRANET 148 75 Table 11: Average response time in milliseconds (single threaded system running on 2.86 GHz Intel Xeon Processor). 6 Related Work Spelling correction of written text is a well studied problem (Kukich, 1996), (Jurafsky and Martin, 2008). The first approach to spelling correc1263 tion made use of a lexicon to correct out-of-lexicon terms by finding the closest in-lexicon word (Damerau, 1964). The similarity between a misspelled word and an in-lexicon word was measured using Edit Distance (Jurafsky and Martin, 2008). The next class of approaches applied the noisy channel model to correct single word spelling errors (Kernighan et al., 1990), (Brill and Moore, 2000). A major flaw of single word spelling correction algorithms is they do not make use of the context of the word in correcting the errors. The next stream of approache</context>
</contexts>
<marker>Jurafsky, Martin, 2008</marker>
<rawString>D. Jurafsky and J.H. Martin. 2008. Speech and Language Processing. Prentice-Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark D Kernighan</author>
<author>Kenneth W Church</author>
<author>William A Gale</author>
</authors>
<title>A spelling correction program based on a noisy channel model.</title>
<date>1990</date>
<booktitle>In COLING,</booktitle>
<pages>205--210</pages>
<contexts>
<context position="28051" citStr="Kernighan et al., 1990" startWordPosition="4883" endWordPosition="4886">ponse time in milliseconds (single threaded system running on 2.86 GHz Intel Xeon Processor). 6 Related Work Spelling correction of written text is a well studied problem (Kukich, 1996), (Jurafsky and Martin, 2008). The first approach to spelling correc1263 tion made use of a lexicon to correct out-of-lexicon terms by finding the closest in-lexicon word (Damerau, 1964). The similarity between a misspelled word and an in-lexicon word was measured using Edit Distance (Jurafsky and Martin, 2008). The next class of approaches applied the noisy channel model to correct single word spelling errors (Kernighan et al., 1990), (Brill and Moore, 2000). A major flaw of single word spelling correction algorithms is they do not make use of the context of the word in correcting the errors. The next stream of approaches explored ways of exploiting the word’s context (Golding and Roth, 1996), (Cucerzan and Brill, 2004). Recently, several works have leveraged the Web for improved spelling correction (Chen et al., 2007),(Islam and Inkpen, 2009), (Whitelaw et al., 2009). Spelling correction algorithms targeted for web-search queries have been developed making use of query logs and click-thru data (Cucerzan and Brill, 2004),</context>
</contexts>
<marker>Kernighan, Church, Gale, 1990</marker>
<rawString>Mark D. Kernighan, Kenneth W. Church, and William A. Gale. 1990. A spelling correction program based on a noisy channel model. In COLING, pages 205–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Kukich</author>
</authors>
<title>Techniques for automatically correcting words in a text.</title>
<date>1996</date>
<journal>Computing Surveys,</journal>
<volume>24</volume>
<issue>4</issue>
<pages>439</pages>
<contexts>
<context position="27613" citStr="Kukich, 1996" startWordPosition="4815" endWordPosition="4816">ME BUCKETING and NAME MATCHING stages can be multi-threaded on a multi-core machine and the query response time can be decreased by an order easily. Further, the memory footprint of the system is very small and the codewords require 4.1 MB for the employees name directory (150,000 names) and 13.8 MB for the Wikipedia name directory (550,000 names). Test Set MHASH BHASH DUMBTIONARY 190 87 INTRANET 148 75 Table 11: Average response time in milliseconds (single threaded system running on 2.86 GHz Intel Xeon Processor). 6 Related Work Spelling correction of written text is a well studied problem (Kukich, 1996), (Jurafsky and Martin, 2008). The first approach to spelling correc1263 tion made use of a lexicon to correct out-of-lexicon terms by finding the closest in-lexicon word (Damerau, 1964). The similarity between a misspelled word and an in-lexicon word was measured using Edit Distance (Jurafsky and Martin, 2008). The next class of approaches applied the noisy channel model to correct single word spelling errors (Kernighan et al., 1990), (Brill and Moore, 2000). A major flaw of single word spelling correction algorithms is they do not make use of the context of the word in correcting the errors.</context>
</contexts>
<marker>Kukich, 1996</marker>
<rawString>K. Kukich. 1996. Techniques for automatically correcting words in a text. Computing Surveys, 24(4):377– 439.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Prabhakar Raghavan</author>
<author>Hinrich Schtze</author>
</authors>
<title>Introduction to Information Retrieval.</title>
<date>2008</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="19551" citStr="Manning et al., 2008" startWordPosition="3462" endWordPosition="3465">he fraction of names for which a correct spelling was suggested at Rank 1. 5.1.3 Baselines The baselines are two popular search engines (S1 and S2), Double Metaphone (DM), a widely 9http://www.imdb.com 10We obtained the names from the organizers of NEWS2009 workshop (http://www.acl-ijcnlp2009.org/workshops/NEWS2009/pages/sharedtask.html). 11We experimented with codewords of various lengths and found that the 32 bit representation gave the best tradeoff between retrieval accuracy and speed. used phonetic search algorithm (Philips, 2000) and BM25, a very popular Information Retrieval algorithm (Manning et al., 2008). To use BM25 algorithm for spelling correction, we represented each name as a bag of bigrams and set the parameters K and b to 2 and 0.75 respectively. 5.2 Results 5.2.1 DUMBTIONARY Table 2 compares the results of the hashing-based systems with the baselines on DUMBTIONARY. As the misspellings in DUMBTIONARY are relatively easier to correct, all the systems give reasonably good retrieval results. Nevertheless, the results of M-HASH and B-HASH are substantially better than the baselines. M-HASH reduced the error over the best baseline (S1) by 13.04% whereas B-HASH reduced by 46.17% (Table 6). </context>
</contexts>
<marker>Manning, Raghavan, Schtze, 2008</marker>
<rawString>Christopher D. Manning, Prabhakar Raghavan, and Hinrich Schtze. 2008. Introduction to Information Retrieval. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Navarro</author>
<author>R Baeza-Yates</author>
<author>J Azevedo-Arcoverde</author>
</authors>
<title>Matchsimile: a flexible approximate matching tool for searching proper names.</title>
<date>2003</date>
<journal>Journal of the American Society for Information Science and Technology,</journal>
<volume>54</volume>
<issue>1</issue>
<contexts>
<context position="5290" citStr="Navarro et al., 2003" startWordPosition="844" endWordPosition="847">ssuming that the friend is a registered user of Facebook at the time of the search). Similarly, if one is searching for a contact in Enterprise address book, the correct spelling of the contact is part of the address book. In fact, even in Web Search, broad-coverage name directories are available in the form of Wikipedia, IMDB, etc. The availability of large authoritative name directories that serve as the source of trusted spellings of names throws open the possibility of correcting misspelled personal names with the help of name matching techniques (Pfeifer et al., 1996), (Christen, 2006), (Navarro et al., 2003). However, the best of the name matching techniques can at best work with a few thousand names to give acceptable response time and accuracy. They do not scale up to the needs of People Search applications where the directories can have millions of names. In this work, we develop hashing-based name similarity search techniques and employ them for spelling correction of personal names. The motivation for using hashing as a building block of spelling correction is the following: given a query, we want to return the global best match in the name directory 2http://www.facebook.com/directory/people</context>
</contexts>
<marker>Navarro, Baeza-Yates, Azevedo-Arcoverde, 2003</marker>
<rawString>G. Navarro, R. Baeza-Yates, and J. Azevedo-Arcoverde. 2003. Matchsimile: a flexible approximate matching tool for searching proper names. Journal of the American Society for Information Science and Technology, 54(1):3–15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Pfeifer</author>
<author>T Poersch</author>
<author>N Fuhr</author>
</authors>
<title>Retrieval effectiveness of proper name search methods.</title>
<date>1996</date>
<booktitle>Information Processing and Management,</booktitle>
<volume>32</volume>
<issue>6</issue>
<contexts>
<context position="5248" citStr="Pfeifer et al., 1996" startWordPosition="837" endWordPosition="840">xists in the Facebook people directory2 (assuming that the friend is a registered user of Facebook at the time of the search). Similarly, if one is searching for a contact in Enterprise address book, the correct spelling of the contact is part of the address book. In fact, even in Web Search, broad-coverage name directories are available in the form of Wikipedia, IMDB, etc. The availability of large authoritative name directories that serve as the source of trusted spellings of names throws open the possibility of correcting misspelled personal names with the help of name matching techniques (Pfeifer et al., 1996), (Christen, 2006), (Navarro et al., 2003). However, the best of the name matching techniques can at best work with a few thousand names to give acceptable response time and accuracy. They do not scale up to the needs of People Search applications where the directories can have millions of names. In this work, we develop hashing-based name similarity search techniques and employ them for spelling correction of personal names. The motivation for using hashing as a building block of spelling correction is the following: given a query, we want to return the global best match in the name directory</context>
<context position="28946" citStr="Pfeifer et al., 1996" startWordPosition="5020" endWordPosition="5023">n and Brill, 2004). Recently, several works have leveraged the Web for improved spelling correction (Chen et al., 2007),(Islam and Inkpen, 2009), (Whitelaw et al., 2009). Spelling correction algorithms targeted for web-search queries have been developed making use of query logs and click-thru data (Cucerzan and Brill, 2004), (Ahmad and Kondrak, 2005), (Sun et al., 2010). None of these approaches focus exclusively on correcting name misspellings. Name matching techniques have been studied in the context of database record deduplication, text mining, and information retrieval (Christen, 2006), (Pfeifer et al., 1996). Most techniques use one or more measures of phonetic similarity and/or string similarity. The popular phonetic similarity-based techniques are Soundex, Phonix, and Metaphone (Pfeifer et al., 1996). Some of the string similaritybased techniques employ Damerau-Levenshtein edit distance, Jaro distance or Winkler distance (Christen, 2006). Data driven approaches for learning edit distance have also been proposed (Ristad and Yianilos, 1996). Most of these techniques either give poor retrieval performance on large name directories or do not scale. Hashing techniques for similarity search is also a</context>
</contexts>
<marker>Pfeifer, Poersch, Fuhr, 1996</marker>
<rawString>U. Pfeifer, T. Poersch, and N. Fuhr. 1996. Retrieval effectiveness of proper name search methods. Information Processing and Management, 32(6):667–679.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Philips</author>
</authors>
<title>The double metaphone search algorithm.</title>
<date>2000</date>
<journal>C/C++ Users Journal.</journal>
<contexts>
<context position="19471" citStr="Philips, 2000" startWordPosition="3451" endWordPosition="3452">etric We measured the performance of all the systems using Precision@1, the fraction of names for which a correct spelling was suggested at Rank 1. 5.1.3 Baselines The baselines are two popular search engines (S1 and S2), Double Metaphone (DM), a widely 9http://www.imdb.com 10We obtained the names from the organizers of NEWS2009 workshop (http://www.acl-ijcnlp2009.org/workshops/NEWS2009/pages/sharedtask.html). 11We experimented with codewords of various lengths and found that the 32 bit representation gave the best tradeoff between retrieval accuracy and speed. used phonetic search algorithm (Philips, 2000) and BM25, a very popular Information Retrieval algorithm (Manning et al., 2008). To use BM25 algorithm for spelling correction, we represented each name as a bag of bigrams and set the parameters K and b to 2 and 0.75 respectively. 5.2 Results 5.2.1 DUMBTIONARY Table 2 compares the results of the hashing-based systems with the baselines on DUMBTIONARY. As the misspellings in DUMBTIONARY are relatively easier to correct, all the systems give reasonably good retrieval results. Nevertheless, the results of M-HASH and B-HASH are substantially better than the baselines. M-HASH reduced the error ov</context>
</contexts>
<marker>Philips, 2000</marker>
<rawString>L. Philips. 2000. The double metaphone search algorithm. C/C++ Users Journal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Sven Ristad</author>
<author>Peter N Yianilos</author>
</authors>
<date>1996</date>
<note>Learning string edit distance. CoRR, cmp-lg/9610005.</note>
<contexts>
<context position="29387" citStr="Ristad and Yianilos, 1996" startWordPosition="5081" endWordPosition="5085">misspellings. Name matching techniques have been studied in the context of database record deduplication, text mining, and information retrieval (Christen, 2006), (Pfeifer et al., 1996). Most techniques use one or more measures of phonetic similarity and/or string similarity. The popular phonetic similarity-based techniques are Soundex, Phonix, and Metaphone (Pfeifer et al., 1996). Some of the string similaritybased techniques employ Damerau-Levenshtein edit distance, Jaro distance or Winkler distance (Christen, 2006). Data driven approaches for learning edit distance have also been proposed (Ristad and Yianilos, 1996). Most of these techniques either give poor retrieval performance on large name directories or do not scale. Hashing techniques for similarity search is also a well studied problem (Shakhnarovich et al., 2008). Locality Sensitive Hashing (LSH) is a theoretically grounded data-oblivious approach for using random projections to define the hash functions for data objects with a single view (Charikar, 2002), (Andoni and Indyk, 2006). Although LSH guarantees that asymptotically the Hamming distance between the codewords approaches the Euclidean distance between the data objects, it is known to prod</context>
</contexts>
<marker>Ristad, Yianilos, 1996</marker>
<rawString>Eric Sven Ristad and Peter N. Yianilos. 1996. Learning string edit distance. CoRR, cmp-lg/9610005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruslan Salakhutdinov</author>
<author>Geoffrey E Hinton</author>
</authors>
<title>Semantic hashing.</title>
<date>2009</date>
<journal>Int. J. Approx. Reasoning,</journal>
<volume>50</volume>
<issue>7</issue>
<pages>978</pages>
<contexts>
<context position="30359" citStr="Salakhutdinov and Hinton, 2009" startWordPosition="5227" endWordPosition="5231">sh functions for data objects with a single view (Charikar, 2002), (Andoni and Indyk, 2006). Although LSH guarantees that asymptotically the Hamming distance between the codewords approaches the Euclidean distance between the data objects, it is known to produce long codewords making it practically inefficient. Recently data-aware approaches that employ Machine Learning techniques to learn hash functions have been proposed and shown to be a lot more effective than LSH on both synthetic and real data. Semantic Hashing employs Restricted Boltzmann Machine to produce more compact codes than LSH (Salakhutdinov and Hinton, 2009). Spectral Hashing formalizes the requirements for a good code and relates them to the problem of balanced graph partitioning which is known to be NP hard (Weiss et al., 2008). To give a practical algorithm for hashing, Spectral Hashing assumes that the data are sampled from a multidimensional uniform distribution and solves a relaxed partitioning problem. 7 Conclusions We developed two hashing-based techniques for spelling correction of person names in People Search applications.To the best of our knowledge, these are the first techniques that focus exclusively on correcting spelling mistakes</context>
</contexts>
<marker>Salakhutdinov, Hinton, 2009</marker>
<rawString>Ruslan Salakhutdinov and Geoffrey E. Hinton. 2009. Semantic hashing. Int. J. Approx. Reasoning, 50(7):969– 978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory Shakhnarovich</author>
<author>Trevor Darrell</author>
<author>Piotr Indyk</author>
</authors>
<title>Nearest-neighbor methods in learning and vision.</title>
<date>2008</date>
<journal>IEEE Transactions on Neural Networks,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="7282" citStr="Shakhnarovich et al., 2008" startWordPosition="1182" endWordPosition="1185"> in getting the right name suggestion in the list of candidates produced by the NAME BUCKETING stage search. Therefore, we need a name similarity search technique that can ensure very high recall without producing too many candidates. Hashing is best suited for this task of fast and approximate name matching. We hash the query tokens as well as directory tokens into d bit binary codes. With binary codes, finding approximate matches for a query token is as easy as finding all the database tokens that are at a Hamming distance of r or less from the query token in the binary code representation (Shakhnarovich et al., 2008), (Weiss et al., 2008). When the binary codes are compact, this search can be done in a fraction of a second on directories containing millions of names on a simple processor. Our contributions are: • We develop a novel data-driven technique for learning hash functions for mapping similar names to similar binary codes using a set of names in a given language/script (i.e. monolingual data). We formulate the problem of learning hash functions as an optmization problem whose relaxation can be solved as a generalized Eigenvalue problem. (Section 2.1). • We show that hash functions can also be lear</context>
<context position="29596" citStr="Shakhnarovich et al., 2008" startWordPosition="5114" endWordPosition="5117">ne or more measures of phonetic similarity and/or string similarity. The popular phonetic similarity-based techniques are Soundex, Phonix, and Metaphone (Pfeifer et al., 1996). Some of the string similaritybased techniques employ Damerau-Levenshtein edit distance, Jaro distance or Winkler distance (Christen, 2006). Data driven approaches for learning edit distance have also been proposed (Ristad and Yianilos, 1996). Most of these techniques either give poor retrieval performance on large name directories or do not scale. Hashing techniques for similarity search is also a well studied problem (Shakhnarovich et al., 2008). Locality Sensitive Hashing (LSH) is a theoretically grounded data-oblivious approach for using random projections to define the hash functions for data objects with a single view (Charikar, 2002), (Andoni and Indyk, 2006). Although LSH guarantees that asymptotically the Hamming distance between the codewords approaches the Euclidean distance between the data objects, it is known to produce long codewords making it practically inefficient. Recently data-aware approaches that employ Machine Learning techniques to learn hash functions have been proposed and shown to be a lot more effective than</context>
</contexts>
<marker>Shakhnarovich, Darrell, Indyk, 2008</marker>
<rawString>Gregory Shakhnarovich, Trevor Darrell, and Piotr Indyk. 2008. Nearest-neighbor methods in learning and vision. IEEE Transactions on Neural Networks, 19(2):377–377.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xu Sun</author>
<author>Jianfeng Gao</author>
<author>Daniel Micol</author>
<author>Chris Quirk</author>
</authors>
<title>Learning phrase-based spelling error models from clickthrough data.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context position="28697" citStr="Sun et al., 2010" startWordPosition="4986" endWordPosition="4989">major flaw of single word spelling correction algorithms is they do not make use of the context of the word in correcting the errors. The next stream of approaches explored ways of exploiting the word’s context (Golding and Roth, 1996), (Cucerzan and Brill, 2004). Recently, several works have leveraged the Web for improved spelling correction (Chen et al., 2007),(Islam and Inkpen, 2009), (Whitelaw et al., 2009). Spelling correction algorithms targeted for web-search queries have been developed making use of query logs and click-thru data (Cucerzan and Brill, 2004), (Ahmad and Kondrak, 2005), (Sun et al., 2010). None of these approaches focus exclusively on correcting name misspellings. Name matching techniques have been studied in the context of database record deduplication, text mining, and information retrieval (Christen, 2006), (Pfeifer et al., 1996). Most techniques use one or more measures of phonetic similarity and/or string similarity. The popular phonetic similarity-based techniques are Soundex, Phonix, and Metaphone (Pfeifer et al., 1996). Some of the string similaritybased techniques employ Damerau-Levenshtein edit distance, Jaro distance or Winkler distance (Christen, 2006). Data driven</context>
</contexts>
<marker>Sun, Gao, Micol, Quirk, 2010</marker>
<rawString>Xu Sun, Jianfeng Gao, Daniel Micol, and Chris Quirk. 2010. Learning phrase-based spelling error models from clickthrough data. In Proceedings of ACL 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Toutanova</author>
<author>R Moore</author>
</authors>
<title>Pronounciation modeling for improved spelling correction.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL ’02,</booktitle>
<pages>141--151</pages>
<contexts>
<context position="31717" citStr="Toutanova and Moore, 2002" startWordPosition="5438" endWordPosition="5441">t suggestions for valid queries unlike (Cucerzan and Brill, 2004). Further, as we suggest spellings from only authoritative name directories, the suggestions are always well formed and coherent. Secondly, we do not require query logs and other resources that are not easily available unlike (Cucerzan and Brill, 2004), (Ahmad and Kondrak, 2005). Neither do we require pairs of misspelled names and their correct spellings for learning the error model unlike (Brill and Moore, 2000) or large-coverage general purpose lexicon for unlike (Cucerzan and Brill, 2004) or pronunciation dictionaries unlike (Toutanova and Moore, 2002). Thirdly, we correct the query as a whole unlike (Ahmad and Kondrak, 2005) and can handle word order changes unlike (Cucerzan and Brill, 2004). Fourthly, we do not iteratively process misspelled name unlike (Cucerzan and Brill, 2004). Fifthly, we handle large name directories efficiently unlike the spectrum of name matching techniques discussed in (Pfeifer et al., 1996). Finally, our training data requirement is relatively small. As future work, we would like to explore the possibility of learning hash functions using 1) bilingual 1264 and monolingual data together and 2) multiple conjugate l</context>
</contexts>
<marker>Toutanova, Moore, 2002</marker>
<rawString>K. Toutanova and R. Moore. 2002. Pronounciation modeling for improved spelling correction. In Proceedings of ACL ’02, pages 141–151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yair Weiss</author>
<author>Antonio B Torralba</author>
<author>Robert Fergus</author>
</authors>
<title>Spectral hashing.</title>
<date>2008</date>
<booktitle>In NIPS,</booktitle>
<pages>1753--1760</pages>
<contexts>
<context position="7304" citStr="Weiss et al., 2008" startWordPosition="1186" endWordPosition="1189">gestion in the list of candidates produced by the NAME BUCKETING stage search. Therefore, we need a name similarity search technique that can ensure very high recall without producing too many candidates. Hashing is best suited for this task of fast and approximate name matching. We hash the query tokens as well as directory tokens into d bit binary codes. With binary codes, finding approximate matches for a query token is as easy as finding all the database tokens that are at a Hamming distance of r or less from the query token in the binary code representation (Shakhnarovich et al., 2008), (Weiss et al., 2008). When the binary codes are compact, this search can be done in a fraction of a second on directories containing millions of names on a simple processor. Our contributions are: • We develop a novel data-driven technique for learning hash functions for mapping similar names to similar binary codes using a set of names in a given language/script (i.e. monolingual data). We formulate the problem of learning hash functions as an optmization problem whose relaxation can be solved as a generalized Eigenvalue problem. (Section 2.1). • We show that hash functions can also be learnt using bilingual dat</context>
<context position="9830" citStr="Weiss et al., 2008" startWordPosition="1655" endWordPosition="1658">actorization or QZ algorithm (Golub and Van Loan, 1996): ˆΦLˆΦT A = ˆΦˆΦT AΛ (5) where Λ is a d x d diagonal matrix. Once A has been estimated from the training data, the codeword of a name s can be produced by binarizing each coordinate of fR (s): f (s) = (sgn (aT1 o (s)) , ... ,sgn (aTd o (s)))T (6) where sgn(u) = 1 if u &gt; 0 and −1 otherwise for all u E R. 5In contrast to our approach, Spectral Hashing, a wellknown hashing technique, makes the unrealistic assumption that the training data is sampled from a multidimensional uniform distribution to address the out-of-sample extension problem (Weiss et al., 2008). problem of learning hash functions as an optmization problem whose relaxation can be solved using Canonical Correlation Analysis. (Section 2.2) • We develop new similarity measures for matching names (Section 3.1). • We evaluate the two methods systematically and compare our performance against multiple baselines. (Section 5). 2 Learning Hash Functions In this section, we develop two techniques for learning hash functions using names as training data. In the first approach, we use monolingual data consisting of names in a language whereas in the second we use bilingual name pairs. In both te</context>
<context position="30534" citStr="Weiss et al., 2008" startWordPosition="5258" endWordPosition="5261">hes the Euclidean distance between the data objects, it is known to produce long codewords making it practically inefficient. Recently data-aware approaches that employ Machine Learning techniques to learn hash functions have been proposed and shown to be a lot more effective than LSH on both synthetic and real data. Semantic Hashing employs Restricted Boltzmann Machine to produce more compact codes than LSH (Salakhutdinov and Hinton, 2009). Spectral Hashing formalizes the requirements for a good code and relates them to the problem of balanced graph partitioning which is known to be NP hard (Weiss et al., 2008). To give a practical algorithm for hashing, Spectral Hashing assumes that the data are sampled from a multidimensional uniform distribution and solves a relaxed partitioning problem. 7 Conclusions We developed two hashing-based techniques for spelling correction of person names in People Search applications.To the best of our knowledge, these are the first techniques that focus exclusively on correcting spelling mistakes in person names. Our approach has several advantages over other spelling correction techniques. Firstly, we do not suggest incorrect suggestions for valid queries unlike (Cuc</context>
</contexts>
<marker>Weiss, Torralba, Fergus, 2008</marker>
<rawString>Yair Weiss, Antonio B. Torralba, and Robert Fergus. 2008. Spectral hashing. In NIPS, pages 1753–1760.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Casey Whitelaw</author>
<author>Ben Hutchinson</author>
<author>Grace Chung</author>
<author>Ged Ellis</author>
</authors>
<title>Using the web for language independent spellchecking and autocorrection.</title>
<date>2009</date>
<booktitle>In EMNLP,</booktitle>
<pages>890--899</pages>
<contexts>
<context position="28494" citStr="Whitelaw et al., 2009" startWordPosition="4954" endWordPosition="4957">sured using Edit Distance (Jurafsky and Martin, 2008). The next class of approaches applied the noisy channel model to correct single word spelling errors (Kernighan et al., 1990), (Brill and Moore, 2000). A major flaw of single word spelling correction algorithms is they do not make use of the context of the word in correcting the errors. The next stream of approaches explored ways of exploiting the word’s context (Golding and Roth, 1996), (Cucerzan and Brill, 2004). Recently, several works have leveraged the Web for improved spelling correction (Chen et al., 2007),(Islam and Inkpen, 2009), (Whitelaw et al., 2009). Spelling correction algorithms targeted for web-search queries have been developed making use of query logs and click-thru data (Cucerzan and Brill, 2004), (Ahmad and Kondrak, 2005), (Sun et al., 2010). None of these approaches focus exclusively on correcting name misspellings. Name matching techniques have been studied in the context of database record deduplication, text mining, and information retrieval (Christen, 2006), (Pfeifer et al., 1996). Most techniques use one or more measures of phonetic similarity and/or string similarity. The popular phonetic similarity-based techniques are Sou</context>
</contexts>
<marker>Whitelaw, Hutchinson, Chung, Ellis, 2009</marker>
<rawString>Casey Whitelaw, Ben Hutchinson, Grace Chung, and Ged Ellis. 2009. Using the web for language independent spellchecking and autocorrection. In EMNLP, pages 890–899.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>