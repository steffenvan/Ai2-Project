<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000004">
<title confidence="0.997483">
Relation Extraction Using Label Propagation Based Semi-supervised
Learning
</title>
<author confidence="0.984133">
Jinxiu Chen&apos; Donghong Ji&apos; Chew Lim Tan&apos; Zhengyu Niu&apos;
</author>
<affiliation confidence="0.961716">
&apos;Institute for Infocomm Research &apos;Department of Computer Science
</affiliation>
<address confidence="0.888265">
21 Heng Mui Keng Terrace National University of Singapore
119613 Singapore 117543 Singapore
</address>
<email confidence="0.985324">
{jinxiu,dhji,zniu}@i2r.a-star.edu.sg tancl@comp.nus.edu.sg
</email>
<sectionHeader confidence="0.982314" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998607">
Shortage of manually labeled data is an
obstacle to supervised relation extraction
methods. In this paper we investigate a
graph based semi-supervised learning al-
gorithm, a label propagation (LP) algo-
rithm, for relation extraction. It represents
labeled and unlabeled examples and their
distances as the nodes and the weights of
edges of a graph, and tries to obtain a la-
beling function to satisfy two constraints:
</bodyText>
<listItem confidence="0.9118225">
1) it should be fixed on the labeled nodes,
2) it should be smooth on the whole graph.
Experiment results on the ACE corpus
showed that this LP algorithm achieves
better performance than SVM when only
very few labeled examples are available,
and it also performs better than bootstrap-
ping for the relation extraction task.
</listItem>
<sectionHeader confidence="0.989499" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.97960275">
Relation extraction is the task of detecting and
classifying relationships between two entities from
text. Many machine learning methods have been
proposed to address this problem, e.g., supervised
</bodyText>
<note confidence="0.821238833333333">
learning algorithms (Miller et al., 2000; Zelenko et
al., 2002; Culotta and Soresen, 2004; Kambhatla,
2004; Zhou et al., 2005), semi-supervised learn-
ing algorithms (Brin, 1998; Agichtein and Gravano,
2000; Zhang, 2004), and unsupervised learning al-
gorithms (Hasegawa et al., 2004).
</note>
<bodyText confidence="0.999589432432432">
Supervised methods for relation extraction per-
form well on the ACE Data, but they require a large
amount of manually labeled relation instances. Un-
supervised methods do not need the definition of
relation types and manually labeled data, but they
cannot detect relations between entity pairs and its
result cannot be directly used in many NLP tasks
since there is no relation type label attached to
each instance in clustering result. Considering both
the availability of a large amount of untagged cor-
pora and direct usage of extracted relations, semi-
supervised learning methods has received great at-
tention.
DIPRE (Dual Iterative Pattern Relation Expan-
sion) (Brin, 1998) is a bootstrapping-based sys-
tem that used a pattern matching system as clas-
sifier to exploit the duality between sets of pat-
terns and relations. Snowball (Agichtein and Gra-
vano, 2000) is another system that used bootstrap-
ping techniques for extracting relations from un-
structured text. Snowball shares much in common
with DIPRE, including the employment of the boot-
strapping framework as well as the use of pattern
matching to extract new candidate relations. The
third system approaches relation classification prob-
lem with bootstrapping on top of SVM, proposed by
Zhang (2004). This system focuses on the ACE sub-
problem, RDC, and extracts various lexical and syn-
tactic features for the classification task. However,
Zhang (2004)’s method doesn’t actually “detect” re-
laitons but only performs relation classification be-
tween two entities given that they are known to be
related.
Bootstrapping works by iteratively classifying un-
labeled examples and adding confidently classified
examples into labeled data using a model learned
from augmented labeled data in previous iteration. It
</bodyText>
<page confidence="0.479173">
129
</page>
<note confidence="0.8538775">
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 129–136,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.997519181818182">
can be found that the affinity information among un-
labeled examples is not fully explored in this boot-
strapping process.
Recently a promising family of semi-supervised
learning algorithm is introduced, which can effec-
tively combine unlabeled data with labeled data in
learning process by exploiting manifold structure
(cluster structure) in data (Belkin and Niyogi, 2002;
Blum and Chawla, 2001; Blum et al., 2004; Zhu
and Ghahramani, 2002; Zhu et al., 2003). These
graph-based semi-supervised methods usually de-
fine a graph where the nodes represent labeled and
unlabeled examples in a dataset, and edges (may be
weighted) reflect the similarity of examples. Then
one wants a labeling function to satisfy two con-
straints at the same time: 1) it should be close to the
given labels on the labeled nodes, and 2) it should be
smooth on the whole graph. This can be expressed
in a regularization framework where the first term
is a loss function, and the second term is a regu-
larizer. These methods differ from traditional semi-
supervised learning methods in that they use graph
structure to smooth the labeling function.
To the best of our knowledge, no work has been
done on using graph based semi-supervised learning
algorithms for relation extraction. Here we inves-
tigate a label propagation algorithm (LP) (Zhu and
Ghahramani, 2002) for relation extraction task. This
algorithm works by representing labeled and unla-
beled examples as vertices in a connected graph,
then propagating the label information from any ver-
tex to nearby vertices through weighted edges itera-
tively, finally inferring the labels of unlabeled exam-
ples after the propagation process converges. In this
paper we focus on the ACE RDC task1.
The rest of this paper is organized as follows. Sec-
tion 2 presents related work. Section 3 formulates
relation extraction problem in the context of semi-
supervised learning and describes our proposed ap-
proach. Then we provide experimental results of our
proposed method and compare with a popular su-
pervised learning algorithm (SVM) and bootstrap-
ping algorithm in Section 4. Finally we conclude
our work in section 5.
</bodyText>
<listItem confidence="0.40192">
1 http://www.ldc.upenn.edu/Projects/ACE/, Three tasks of
ACE program: Entity Detection and Tracking (EDT), Rela-
tion Detection and Characterization (RDC), and Event Detec-
tion and Characterization (EDC)
</listItem>
<sectionHeader confidence="0.922129" genericHeader="method">
2 The Proposed Method
</sectionHeader>
<subsectionHeader confidence="0.982659">
2.1 Problem Definition
</subsectionHeader>
<bodyText confidence="0.99823825">
The problem of relation extraction is to assign an ap-
propriate relation type to an occurrence of two entity
pairs in a given context. It can be represented as fol-
lows:
</bodyText>
<equation confidence="0.997974">
R — (Cpre, e1, Cmid, e2, Cpost) (1)
</equation>
<bodyText confidence="0.99996176">
where e1 and e2 denote the entity mentions, and
Cpre,Cmid,and Cpost are the contexts before, be-
tween and after the entity mention pairs. In this pa-
per, we set the mid-context window as the words be-
tween the two entity mentions and the pre- and post-
context as up to two words before and after the cor-
responding entity mention.
Let X = {xi}ni=1 be a set of contexts of occur-
rences of all the entity mention pairs, where xi rep-
resents the contexts of the i-th occurrence, and n is
the total number of occurrences. The first l exam-
ples (or contexts) are labeled as yg ( yg E {rj}Rj=1,
rj denotes relation type and R is the total number of
relation types). The remaining u(u = n — l) exam-
ples are unlabeled.
Intuitively, if two occurrences of entity mention
pairs have the similarity context, they tend to hold
the same relation type. Based on the assumption, we
define a graph where the vertices represent the con-
texts of labeled and unlabeled occurrences of entity
mention pairs, and the edge between any two ver-
tices xi and xj is weighted so that the closer the ver-
tices in some distance measure, the larger the weight
associated with this edge. Hence, the weights are de-
fined as follows:
</bodyText>
<equation confidence="0.997449">
s2 ij
α2 ) (2)
</equation>
<bodyText confidence="0.9999156">
where sij is the similarity between xi and xj calcu-
lated by some similarity measures, e.g., cosine sim-
ilarity, and α is used to scale the weights. In this
paper, we set α as the average similarity between la-
beled examples from different classes.
</bodyText>
<subsectionHeader confidence="0.999597">
2.2 A Label Propagation Algorithm
</subsectionHeader>
<bodyText confidence="0.99952275">
In the LP algorithm, the label information of any
vertex in a graph is propagated to nearby vertices
through weighted edges until a global stable stage is
achieved. Larger edge weights allow labels to travel
</bodyText>
<equation confidence="0.8391485">
Wij = exp(—
130
</equation>
<bodyText confidence="0.987729421052632">
through easier. Thus the closer the examples are, the
more likely they have similar labels.
We define soft label as a vector that is a proba-
bilistic distribution over all the classes. In the la-
bel propagation process, the soft label of each initial
labeled example is clamped in each iteration to re-
plenish label sources from these labeled data. Thus
the labeled data act like sources to push out labels
through unlabeled data. With this push from la-
beled examples, the class boundaries will be pushed
through edges with large weights and settle in gaps
along edges with small weights. Hopefully, the val-
ues of Wij across different classes would be as small
as possible and the values of Wij within the same
class would be as large as possible. This will make
label propagation to stay within the same class. This
label propagation process will make the labeling
function smooth on the graph.
Define an n x n probabilistic transition matrix T
</bodyText>
<equation confidence="0.993435">
Tij = P(j , i) = nwij (3)
�k=1 wkj
</equation>
<bodyText confidence="0.999956666666667">
where Tij is the probability to jump from vertex xj
to vertex xi. We define a n x R label matrix Y ,
where Yij representing the probabilities of vertex yi
to have the label rj.
Then the label propagation algorithm consists the
following main steps:
</bodyText>
<listItem confidence="0.8900465">
Step1 : Initialization
• Set the iteration index t = 0;
• Let Y 0 be the initial soft labels attached to
each vertex, where Y0
</listItem>
<equation confidence="0.432106">
ij = 1 if yi is label rj
</equation>
<bodyText confidence="0.71849">
and 0 otherwise.
</bodyText>
<listItem confidence="0.7079115">
• Let YL0 be the top l rows of Y0 and YU0
be the remaining u rows. YL0 is consistent
</listItem>
<bodyText confidence="0.962065111111111">
with the labeling in labeled data and the
initialization of YU0 can be arbitrary.
Step 2 : Propagate the labels of any vertex to
nearby vertices by Yt+1 = TYt , where
T is the row-normalized matrix of T, i.e.
Tij = Tij/ Ek Tik, which can maintain the
class probability interpretation.
Step 3 : Clamp the labeled data, that is, replace the
top l row of Yt+1 with Y0L.
</bodyText>
<equation confidence="0.742796333333333">
Step 4 : Repeat from step 2 until Y converges.
Step 5 : Assign xh(l + 1 &lt; h &lt; n) with a label:
yh = argmaxjYhj. — —
</equation>
<bodyText confidence="0.998088">
The above algorithm can ensure that the labeled
data YL never changes since it is clamped in Step 3.
Actually we are interested in only YU. This algo-
rithm has been shown to converge to a unique solu-
tion YU = limt,,,,, YUt = (I − �Tuu)�
and Ghahramani, 2002). Here, Tuu and Tul are ac-
quired by splitting matrix T after the l-th row and
the l-th column into 4 sub-matrices. And I is u x u
identity matrix. We can see that the initialization of
YU0 in this solution is not important, since YU0 does
�YU.
</bodyText>
<sectionHeader confidence="0.990299" genericHeader="method">
3 Experiments and Results
</sectionHeader>
<subsectionHeader confidence="0.998485">
3.1 Feature Set
</subsectionHeader>
<bodyText confidence="0.998700454545455">
Following (Zhang, 2004), we used lexical and syn-
tactic features in the contexts of entity pairs, which
are extracted and computed from the parse trees de-
rived from Charniak Parser (Charniak, 1999) and the
Chunklink script 2 written by Sabine Buchholz from
Tilburg University.
Words: Surface tokens of the two entities and
words in the three contexts.
Entity Type: the entity type of both entity men-
tions, which can be PERSON, ORGANIZA-
TION, FACILITY, LOCATION and GPE.
</bodyText>
<listItem confidence="0.9917286">
POS features: Part-Of-Speech tags corresponding
to all tokens in the two entities and words in
the three contexts.
Chunking features: This category of features are
extracted from the chunklink representation,
which includes:
• Chunk tag information of the two enti-
ties and words in the three contexts. The
“0” tag means that the word is not in any
chunk. The “I-XP” tag means that this
word is inside an XP chunk. The “B-XP”
by default means that the word is at the
beginning of an XP chunk.
• Grammatical function of the two enti-
ties and words in the three contexts. The
</listItem>
<figure confidence="0.694159">
2Software available at http://ilk.uvt.nl/∼sabine/chunklink/
1 PulYL0(Zhu
not affect the estimation of
131
</figure>
<bodyText confidence="0.999800333333333">
last word in each chunk is its head, and
the function of the head is the function of
the whole chunk. “NP-SBJ” means a NP
chunk as the subject of the sentence. The
other words in a chunk that are not the
head have “NOFUNC” as their function.
</bodyText>
<listItem confidence="0.9905458">
• IOB-chains of the heads of the two enti-
ties. So-called IOB-chain, noting the syn-
tactic categories of all the constituents on
the path from the root node to this leaf
node of tree.
</listItem>
<bodyText confidence="0.999028333333333">
The position information is also specified in the
description of each feature above. For example,
word features with position information include:
</bodyText>
<listItem confidence="0.896357272727273">
1) WE1 (WE2): all words in e1 (e2)
2) WHE1 (WHE2): head word of e1 (e2)
3) WMNULL: no words in Cmid
4) WMFL: the only word in Cmid
5) WMF, WML, WM2, WM3, ...: first word, last
word, second word, third word, ...in Cmid when at
least two words in Cmid
6) WEL1, WEL2, ...: first word, second word, ...
before e1
7) WER1, WER2, ...: first word, second word, ...
after e2
</listItem>
<bodyText confidence="0.9999644">
We combine the above lexical and syntactic features
with their position information in the contexts to
form context vectors. Before that, we filter out low
frequency features which appeared only once in the
dataset.
</bodyText>
<subsectionHeader confidence="0.998434">
3.2 Similarity Measures
</subsectionHeader>
<bodyText confidence="0.999916785714286">
The similarity sib between two occurrences of entity
pairs is important to the performance of the LP al-
gorithm. In this paper, we investigated two similar-
ity measures, cosine similarity measure and Jensen-
Shannon (JS) divergence (Lin, 1991). Cosine sim-
ilarity is commonly used semantic distance, which
measures the angle between two feature vectors. JS
divergence has ever been used as distance measure
for document clustering, which outperforms cosine
similarity based document clustering (Slonim et al.,
2002). JS divergence measures the distance between
two probability distributions if feature vector is con-
sidered as probability distribution over features. JS
divergence is defined as follows:
</bodyText>
<tableCaption confidence="0.93134">
Table 1: Frequency of Relation SubTypes in the ACE training
and devtest corpus.
</tableCaption>
<table confidence="0.99991412">
Type SubType Training Devtest
ROLE General-Staff 550 149
Management 677 122
Citizen-Of 127 24
Founder 11 5
Owner 146 15
Affiliate-Partner 111 15
Member 460 145
Client 67 13
Other 15 7
PART Part-Of 490 103
Subsidiary 85 19
Other 2 1
AT Located 975 192
Based-In 187 64
Residence 154 54
SOC Other-Professional 195 25
Other-Personal 60 10
Parent 68 24
Spouse 21 4
Associate 49 7
Other-Relative 23 10
Sibling 7 4
GrandParent 6 1
NEAR Relative-Location 88 32
</table>
<equation confidence="0.953166833333333">
1
JS(q, r) = 2 [DKL(qll�p) + DKL(rllp)] (4)
q(y)(log q(y)) (5)
Ay)
r(y)(log r(y)
�p(y)) (6)
</equation>
<bodyText confidence="0.99960975">
where p = 12(q + r) and JS(q, r) represents JS
divergence between probability distribution q(y) and
r(y) (y is a random variable), which is defined in
terms of KL-divergence.
</bodyText>
<subsectionHeader confidence="0.981628">
3.3 Experimental Evaluation
3.3.1 Experiment Setup
</subsectionHeader>
<bodyText confidence="0.9999325">
We evaluated this label propagation based rela-
tion extraction method for relation subtype detection
and characterization task on the official ACE 2003
corpus. It contains 519 files from sources including
broadcast, newswire, and newspaper. We dealt with
only intra-sentence explicit relations and assumed
that all entities have been detected beforehand in the
EDT sub-task of ACE. Table 1 lists the types and
subtypes of relations for the ACE Relation Detection
and Characterization (RDC) task, along with their
</bodyText>
<equation confidence="0.9814875">
DKL(qllp) = �
�
DKL(rllp) =
�
</equation>
<page confidence="0.870158">
132
</page>
<tableCaption confidence="0.9518785">
Table 2: The Performance of SVM and LP algorithm with different sizes of labeled data for relation detection on relation subtypes.
The LP algorithm is run with two similarity measures: cosine similarity and JS divergence.
</tableCaption>
<table confidence="0.999899125">
SVM LPCosine LPJS
Percentage P R F P R F P R F
1% 35.9 32.6 34.4 58.3 56.1 57.1 58.5 58.7 58.5
10% 51.3 41.5 45.9 64.5 57.5 60.7 64.6 62.0 63.2
25% 67.1 52.9 59.1 68.7 59.0 63.4 68.9 63.7 66.1
50% 74.0 57.8 64.9 69.9 61.8 65.6 70.1 64.1 66.9
75% 77.6 59.4 67.2 71.8 63.4 67.3 72.4 64.8 68.3
100% 79.8 62.9 70.3 73.9 66.9 70.2 74.2 68.2 71.1
</table>
<tableCaption confidence="0.9912315">
Table 3: The performance of SVM and LP algorithm with different sizes of labeled data for relation detection and classification
on relation subtypes. The LP algorithm is run with two similarity measures: cosine similarity and JS divergence.
</tableCaption>
<table confidence="0.9997245">
SVM LPCosine LPJS
Percentage P R F P R F P R F
1% 31.6 26.1 28.6 39.6 37.5 38.5 40.1 38.0 39.0
10% 39.1 32.7 35.6 45.9 39.6 42.5 46.2 41.6 43.7
25% 49.8 35.0 41.1 51.0 44.5 47.3 52.3 46.0 48.9
50% 52.5 41.3 46.2 54.1 48.6 51.2 54.9 50.8 52.7
75% 58.7 46.7 52.0 56.0 52.0 53.9 56.1 52.6 54.3
100% 60.8 48.9 54.2 56.2 52.3 54.1 56.3 52.9 54.6
</table>
<bodyText confidence="0.998955111111111">
frequency of occurrence in the ACE training set and
test set. We constructed labeled data by randomly
sampling some examples from ACE training data
and additionally sampling examples with the same
size from the pool of unrelated entity pairs for the
“NONE” class. We used the remaining examples in
the ACE training set and the whole ACE test set as
unlabeled data. The testing set was used for final
evaluation.
</bodyText>
<subsectionHeader confidence="0.561818">
3.3.2 LP vs. SVM
</subsectionHeader>
<bodyText confidence="0.998517826086957">
Support Vector Machine (SVM) is a state of the
art technique for relation extraction task. In this ex-
periment, we use LIBSVM tool 3 with linear kernel
function.
For comparison between SVM and LP, we ran
SVM and LP with different sizes of labeled data
and evaluate their performance on unlabeled data
using precision, recall and F-measure. Firstly, we
ran SVM or LP algorithm to detect possible rela-
tions from unlabeled data. If an entity mention pair
is classified not to the “NONE” class but to the other
24 subtype classes, then it has a relation. Then con-
struct labeled datasets with different sampling set
size l, including 1%×Ntrain, 10%×Ntrain, 25%×
Ntrain, 50%×Ntrain, 75%×Ntrain, 100%×Ntrain
(Ntrain is the number of examples in the ACE train-
3LIBSVM: a library for support vector machines. Soft-
ware available at http://www.csie.ntu.edu.tw/∼cjlin/libsvm.
ing set). If any relation subtype was absent from the
sampled labeled set, we redid the sampling. For each
size, we performed 20 trials and calculated average
scores on test set over these 20 random trials.
Table 2 reports the performance of SVM and LP
with different sizes of labled data for relation detec-
tion task. We used the same sampled labeled data in
LP as the training data for SVM model.
From Table 2, we see that both LPCosine and
LPJs achieve higher Recall than SVM. Specifically,
with small labeled dataset (percentage of labeled
data ≤ 25%), the performance improvement by LP
is significant. When the percentage of labeled data
increases from 50% to 100%, LPCosine is still com-
parable to SVM in F-measure while LPJs achieves
slightly better F-measure than SVM. On the other
hand, LPJs consistently outperforms LP
Table 3 reports the performance of relation clas-
sification by using SVM and LP with different sizes
of labled data. And the performance describes the
average values of Precision, Recall and F-measure
over major relation subtypes.
From Table 3, we see that LPCosine and LPJs out-
perform SVM by F-measure in almost all settings
of labeled data, which is due to the increase of Re-
call. With smaller labeled dataset (percentage of la-
beled data ≤ 50%), the gap between LP and SVM
is larger. When the percentage of labeled data in-
</bodyText>
<figure confidence="0.997681933333333">
Cosine.
133
0.55
0.45
0.35
0.25
0.6
0.5
0.4
0.3
SVM
LP_Cosine
LP_JS
1% 10% 25% 50% 75% 100%
Percentage of Labeled Examples
</figure>
<figureCaption confidence="0.9842345">
Figure 1: Comparison of the performance of SVM
and LP with different sizes of labeled data
</figureCaption>
<figure confidence="0.959137225">
1.5
1
0.5
0
-0.5
-1
-1.5
-2
-9 -2 -1 0 1 2
(a)
1.5
1
0.5
0
-0.5
-1
-1.5
-2
-� -2 -1 0 1 2
M
1.5
1
0.5
0
-0.5
-1
-1.5
-2
-� -2 -1 0 1 2
(b)
1.5
1
0.5
0
-0.5
-1
-1.5
-2
-� -2 -1 0 1 2
(d)
</figure>
<bodyText confidence="0.999876222222222">
creases from 75% to 100%, the performance of LP
algorithm is still comparable to SVM. On the other
hand, the LP algorithm based on JS divergence con-
sistently outperforms the LP algorithm based on Co-
sine similarity. Figure 1 visualizes the accuracy of
three algorithms.
As shown in Figure 1, the gap between SVM
curve and LPjs curves is large when the percentage
of labeled data is relatively low.
</bodyText>
<subsectionHeader confidence="0.981336">
3.3.3 An Example
</subsectionHeader>
<bodyText confidence="0.995046615384615">
In Figure 2, we selected 25 instances in train-
ing set and 15 instances in test set from the ACE
corpus,which covered five relation types. Using
Isomap tool 4, the 40 instances with 229 feature di-
mensions are visualized in a two-dimensional space
as the figure. We randomly sampled only one la-
beled example for each relation type from the 25
training examples as labeled data. Figure 2(a) and
2(b) show the initial state and ground truth result re-
spectively. Figure 2(c) reports the classification re-
sult on test set by SVM (accuracy = 415 = 26.7%),
and Figure 2(d) gives the classification result on both
training set and test set by LP (accuracy = 11
</bodyText>
<equation confidence="0.7889235">
15 =
73.3%).
</equation>
<bodyText confidence="0.999802285714286">
Comparing Figure 2(b) and Figure 2(c), we find
that many examples are misclassified from class o
to other class symbols. This may be caused that
SVMs method ignores the intrinsic structure in data.
For Figure 2(d), the labels of unlabeled examples
are determined not only by nearby labeled examples,
but also by nearby unlabeled examples, so using LP
</bodyText>
<footnote confidence="0.955985">
4The tool is available at http://isomap.stanford.edu/.
</footnote>
<figureCaption confidence="0.869512">
Figure 2: An example: comparison of SVM and LP
</figureCaption>
<bodyText confidence="0.974494375">
algorithm on a data set from ACE corpus. o and
A denote the unlabeled examples in training set and
test set respectively, and other symbols (o, x, ❑, +
and V) represent the labeled examples with respec-
tive relation type sampled from training set.
strategy achieves better performance than the local
consistency based SVM strategy when the size of
labeled data is quite small.
</bodyText>
<subsectionHeader confidence="0.578413">
3.3.4 LP vs. Bootstrapping
</subsectionHeader>
<bodyText confidence="0.999933071428572">
In (Zhang, 2004), they perform relation classifi-
cation on ACE corpus with bootstrapping on top of
SVM. To compare with their proposed Bootstrapped
SVM algorithm, we use the same feature stream set-
ting and randomly selected 100 instances from the
training data as the size of initial labeled data.
Table 4 lists the performance of the bootstrapped
SVM method from (Zhang, 2004) and LP method
with 100 seed labeled examples for relation type
classification task. We can see that LP algorithm
outperforms the bootstrapped SVM algorithm on
four relation type classification tasks, and perform
comparably on the relation ”SOC” classification
task.
</bodyText>
<sectionHeader confidence="0.999534" genericHeader="method">
4 Discussion
</sectionHeader>
<bodyText confidence="0.9996715">
In this paper,we have investigated a graph-based
semi-supervised learning approach for relation ex-
traction problem. Experimental results showed that
the LP algorithm performs better than SVM and
</bodyText>
<page confidence="0.905419">
134
</page>
<tableCaption confidence="0.993807">
Table 4: Comparison of the performance of the bootstrapped SVM method from (Zhang, 2004) and LP method with 100 seed
labeled examples for relation type classification task.
</tableCaption>
<table confidence="0.990517">
Relation type
ROLE
PART
AT
SOC
NEAR
Bootstrapping LPJS
P R F P R F
78.5 69.7 73.8 81.0 74.7 77.7
65.6 34.1 44.9 70.1 41.6 52.2
61.0 84.8 70.9 74.2 79.1 76.6
47.0 57.4 51.7 45.0 59.1 51.0
� � � 13.7 12.5 13.0
</table>
<tableCaption confidence="0.997858">
Table 5: Comparison of the performance of previous methods on ACE RDC task.
</tableCaption>
<table confidence="0.992693428571429">
Relation Dectection Relation Detection and Classification
on Types on Subtypes
Method P R F P R F P R F
Culotta and Soresen (2004) Tree kernel based 81.2 51.8 63.2 67.1 35.0 45.8 - - -
Kambhatla (2004) Feature based, Maxi- - - - - - - 63.5 45.2 52.8
mum Entropy
Zhou et al. (2005) Feature based,SVM 84.8 66.7 74.7 77.2 60.7 68.0 63.1 49.5 55.5
</table>
<bodyText confidence="0.994905714285714">
bootstrapping. We have some findings from these
results:
The LP based relation extraction method can use
the graph structure to smooth the labels of unlabeled
examples. Therefore, the labels of unlabeled exam-
ples are determined not only by the nearby labeled
examples, but also by nearby unlabeled examples.
For supervised methods, e.g., SVM, very few la-
beled examples are not enough to reveal the struc-
ture of each class. Therefore they can not perform
well, since the classification hyperplane was learned
only from few labeled data and the coherent struc-
ture in unlabeled data was not explored when in-
ferring class boundary. Hence, our LP-based semi-
supervised method achieves better performance on
both relation detection and classification when only
few labeled data is available. Bootstrapping
Currently most of works on the RDC task of
ACE focused on supervised learning methods Cu-
lotta and Soresen (2004; Kambhatla (2004; Zhou
et al. (2005). Table 5 lists a comparison on re-
lation detection and classification of these meth-
ods. Zhou et al. (2005) reported the best result as
63.1%/49.5%/55.5% in Precision/Recall/F-measure
on the relation subtype classification using feature
based method, which outperforms tree kernel based
method by Culotta and Soresen (2004). Compared
with Zhou et al.’s method, the performance of LP al-
gorithm is slightly lower. It may be due to that we
used a much simpler feature set. Our work in this
paper focuses on the investigation of a graph based
semi-supervised learning algorithm for relation ex-
traction. In the future, we would like to use more ef-
fective feature sets Zhou et al. (2005) or kernel based
similarity measure with LP for relation extraction.
</bodyText>
<sectionHeader confidence="0.976861" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.99998325">
This paper approaches the problem of semi-
supervised relation extraction using a label propaga-
tion algorithm. It represents labeled and unlabeled
examples and their distances as the nodes and the
weights of edges of a graph, and tries to obtain a
labeling function to satisfy two constraints: 1) it
should be fixed on the labeled nodes, 2) it should
be smooth on the whole graph. In the classifica-
tion process, the labels of unlabeled examples are
determined not only by nearby labeled examples,
but also by nearby unlabeled examples. Our exper-
imental results demonstrated that this graph based
algorithm can achieve better performance than SVM
when only very few labeled examples are available,
and also outperforms the bootstrapping method for
relation extraction task.
In the future, we would like to investigate more
effective feature set or use feature selection to im-
prove the performance of this graph-based semi-
supervised relation extraction method.
</bodyText>
<page confidence="0.913803">
135
</page>
<sectionHeader confidence="0.99495" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999858527777778">
Agichtein E. and Gravano L.. 2000. Snowball: Ex-
tracting Relations from large Plain-Text Collections,
In Proceedings of the 5th ACM International Confer-
ence on Digital Libraries (ACMDL’00).
Belkin M. and Niyogi P.. 2002. Using Manifold Struc-
ture for Partially Labeled Classification. Advances in
Neural Infomation Processing Systems 15.
Blum A. and Chawla S. 2001. Learning from Labeled
and Unlabeled Data Using Graph Mincuts. In Pro-
ceedings of the 18th International Conference on Ma-
chine Learning.
Blum A., Lafferty J., Rwebangira R. and Reddy R. 2004.
Semi-Supervised Learning Using Randomized Min-
cuts. In Proceedings of the 21th International Confer-
ence on Machine Learning..
Brin Sergey. 1998. Extracting patterns and relations
from world wide web. In Proceedings of WebDB Work-
shop at 6th International Conference on Extending
Database Technology (WebDB’98). pages 172-183.
Charniak E. 1999. A Maximum-entropy-inspired parser.
Technical Report CS-99-12. Computer Science De-
partment, Brown University.
Culotta A. and Soresen J. 2004. Dependency tree kernels
for relation extraction, In Proceedings of 42th Annual
Meeting of the Association for Computational Linguis-
tics. 21-26 July 2004. Barcelona, Spain.
Hasegawa T., Sekine S. and Grishman R. 2004. Dis-
covering Relations among Named Entities from Large
Corpora, In Proceeding of Conference ACL2004.
Barcelona, Spain.
Kambhatla N. 2004. Combining lexical, syntactic and
semantic features with Maximum Entropy Models for
extracting relations, In Proceedings of 42th Annual
Meeting of the Association for Computational Linguis-
tics.. 21-26 July 2004. Barcelona, Spain.
Lin J. 1991. Divergence Measures Based on the Shan-
non Entropy. IEEE Transactions on Information The-
ory. Vol 37, No.1, 145-150.
Miller S.,Fox H.,Ramshaw L. and Weischedel R. 2000.
A novel use ofstatistical parsing to extract information
from text. In Proceedings of 6th Applied Natural Lan-
guage Processing Conference 29 April-4 may 2000,
Seattle USA.
Slonim, N., Friedman, N., and Tishby, N. 2002. Un-
supervised Document Classification Using Sequential
Information Maximization. In Proceedings of the 25th
Annual International ACM SIGIR Conference on Re-
search and Development in Information Retrieval.
Yarowsky D. 1995. Unsupervised Word Sense Disam-
biguation Rivaling Supervised Methods. In Proceed-
ings of the 33rd Annual Meeting of the Association for
Computational Linguistics. pp.189-196.
Zelenko D., Aone C. and Richardella A. 2002. Ker-
nel Methods for Relation Extraction, Proceedings of
the Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP). Philadelphia.
Zhang Zhu. 2004. Weakly-supervised relation classifi-
cation for Information Extraction, In Proceedings of
ACM 13th conference on Information and Knowledge
Management (CIKM’2004). 8-13 Nov 2004. Wash-
ington D.C.,USA.
Zhou GuoDong, Su Jian, Zhang Jie and Zhang min.
2005. Exploring Various Knowledge in Relation Ex-
traction. In Proceedings of 43th Annual Meeting of the
Association for Computational Linguistics. USA.
Zhu Xiaojin and Ghahramani Zoubin. 2002. Learning
from Labeled and Unlabeled Data with Label Propa-
gation. CMU CALD tech report CMU-CALD-02-107.
Zhu Xiaojin, Ghahramani Zoubin, and Lafferty J. 2003.
Semi-Supervised Learning Using Gaussian Fields and
Harmonic Functions. In Proceedings of the 20th Inter-
national Conference on Machine Learning.
</reference>
<page confidence="0.946658">
136
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.752442">
<title confidence="0.999652">Relation Extraction Using Label Propagation Based Semi-supervised Learning</title>
<author confidence="0.925012">Lim</author>
<affiliation confidence="0.990054">for Infocomm Research of Computer Science</affiliation>
<address confidence="0.921853">21 Heng Mui Keng Terrace National University of Singapore 119613 Singapore 117543 Singapore</address>
<email confidence="0.996688">tancl@comp.nus.edu.sg</email>
<abstract confidence="0.998257578947368">Shortage of manually labeled data is an obstacle to supervised relation extraction methods. In this paper we investigate a graph based semi-supervised learning algorithm, a label propagation (LP) algorithm, for relation extraction. It represents labeled and unlabeled examples and their distances as the nodes and the weights of edges of a graph, and tries to obtain a labeling function to satisfy two constraints: 1) it should be fixed on the labeled nodes, 2) it should be smooth on the whole graph. Experiment results on the ACE corpus showed that this LP algorithm achieves better performance than SVM when only very few labeled examples are available, and it also performs better than bootstrapping for the relation extraction task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Agichtein</author>
<author>L Gravano</author>
</authors>
<title>Snowball: Extracting Relations from large Plain-Text Collections,</title>
<date>2000</date>
<booktitle>In Proceedings of the 5th ACM International Conference on Digital Libraries (ACMDL’00).</booktitle>
<contexts>
<context position="1508" citStr="Agichtein and Gravano, 2000" startWordPosition="218" endWordPosition="221">ACE corpus showed that this LP algorithm achieves better performance than SVM when only very few labeled examples are available, and it also performs better than bootstrapping for the relation extraction task. 1 Introduction Relation extraction is the task of detecting and classifying relationships between two entities from text. Many machine learning methods have been proposed to address this problem, e.g., supervised learning algorithms (Miller et al., 2000; Zelenko et al., 2002; Culotta and Soresen, 2004; Kambhatla, 2004; Zhou et al., 2005), semi-supervised learning algorithms (Brin, 1998; Agichtein and Gravano, 2000; Zhang, 2004), and unsupervised learning algorithms (Hasegawa et al., 2004). Supervised methods for relation extraction perform well on the ACE Data, but they require a large amount of manually labeled relation instances. Unsupervised methods do not need the definition of relation types and manually labeled data, but they cannot detect relations between entity pairs and its result cannot be directly used in many NLP tasks since there is no relation type label attached to each instance in clustering result. Considering both the availability of a large amount of untagged corpora and direct usag</context>
</contexts>
<marker>Agichtein, Gravano, 2000</marker>
<rawString>Agichtein E. and Gravano L.. 2000. Snowball: Extracting Relations from large Plain-Text Collections, In Proceedings of the 5th ACM International Conference on Digital Libraries (ACMDL’00).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Belkin</author>
<author>P Niyogi</author>
</authors>
<title>Using Manifold Structure for Partially Labeled Classification.</title>
<date>2002</date>
<booktitle>Advances in Neural Infomation Processing Systems 15.</booktitle>
<contexts>
<context position="3913" citStr="Belkin and Niyogi, 2002" startWordPosition="585" endWordPosition="588">om augmented labeled data in previous iteration. It 129 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 129–136, Sydney, July 2006. c�2006 Association for Computational Linguistics can be found that the affinity information among unlabeled examples is not fully explored in this bootstrapping process. Recently a promising family of semi-supervised learning algorithm is introduced, which can effectively combine unlabeled data with labeled data in learning process by exploiting manifold structure (cluster structure) in data (Belkin and Niyogi, 2002; Blum and Chawla, 2001; Blum et al., 2004; Zhu and Ghahramani, 2002; Zhu et al., 2003). These graph-based semi-supervised methods usually define a graph where the nodes represent labeled and unlabeled examples in a dataset, and edges (may be weighted) reflect the similarity of examples. Then one wants a labeling function to satisfy two constraints at the same time: 1) it should be close to the given labels on the labeled nodes, and 2) it should be smooth on the whole graph. This can be expressed in a regularization framework where the first term is a loss function, and the second term is a re</context>
</contexts>
<marker>Belkin, Niyogi, 2002</marker>
<rawString>Belkin M. and Niyogi P.. 2002. Using Manifold Structure for Partially Labeled Classification. Advances in Neural Infomation Processing Systems 15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Blum</author>
<author>S Chawla</author>
</authors>
<title>Learning from Labeled and Unlabeled Data Using Graph Mincuts.</title>
<date>2001</date>
<booktitle>In Proceedings of the 18th International Conference on Machine Learning.</booktitle>
<contexts>
<context position="3936" citStr="Blum and Chawla, 2001" startWordPosition="589" endWordPosition="592"> in previous iteration. It 129 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 129–136, Sydney, July 2006. c�2006 Association for Computational Linguistics can be found that the affinity information among unlabeled examples is not fully explored in this bootstrapping process. Recently a promising family of semi-supervised learning algorithm is introduced, which can effectively combine unlabeled data with labeled data in learning process by exploiting manifold structure (cluster structure) in data (Belkin and Niyogi, 2002; Blum and Chawla, 2001; Blum et al., 2004; Zhu and Ghahramani, 2002; Zhu et al., 2003). These graph-based semi-supervised methods usually define a graph where the nodes represent labeled and unlabeled examples in a dataset, and edges (may be weighted) reflect the similarity of examples. Then one wants a labeling function to satisfy two constraints at the same time: 1) it should be close to the given labels on the labeled nodes, and 2) it should be smooth on the whole graph. This can be expressed in a regularization framework where the first term is a loss function, and the second term is a regularizer. These method</context>
</contexts>
<marker>Blum, Chawla, 2001</marker>
<rawString>Blum A. and Chawla S. 2001. Learning from Labeled and Unlabeled Data Using Graph Mincuts. In Proceedings of the 18th International Conference on Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Blum</author>
<author>J Lafferty</author>
<author>R Rwebangira</author>
<author>R Reddy</author>
</authors>
<title>Semi-Supervised Learning Using Randomized Mincuts.</title>
<date>2004</date>
<booktitle>In Proceedings of the 21th International Conference on Machine Learning..</booktitle>
<contexts>
<context position="3955" citStr="Blum et al., 2004" startWordPosition="593" endWordPosition="596"> It 129 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 129–136, Sydney, July 2006. c�2006 Association for Computational Linguistics can be found that the affinity information among unlabeled examples is not fully explored in this bootstrapping process. Recently a promising family of semi-supervised learning algorithm is introduced, which can effectively combine unlabeled data with labeled data in learning process by exploiting manifold structure (cluster structure) in data (Belkin and Niyogi, 2002; Blum and Chawla, 2001; Blum et al., 2004; Zhu and Ghahramani, 2002; Zhu et al., 2003). These graph-based semi-supervised methods usually define a graph where the nodes represent labeled and unlabeled examples in a dataset, and edges (may be weighted) reflect the similarity of examples. Then one wants a labeling function to satisfy two constraints at the same time: 1) it should be close to the given labels on the labeled nodes, and 2) it should be smooth on the whole graph. This can be expressed in a regularization framework where the first term is a loss function, and the second term is a regularizer. These methods differ from tradi</context>
</contexts>
<marker>Blum, Lafferty, Rwebangira, Reddy, 2004</marker>
<rawString>Blum A., Lafferty J., Rwebangira R. and Reddy R. 2004. Semi-Supervised Learning Using Randomized Mincuts. In Proceedings of the 21th International Conference on Machine Learning..</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brin Sergey</author>
</authors>
<title>Extracting patterns and relations from world wide web.</title>
<date>1998</date>
<booktitle>In Proceedings of WebDB Workshop at 6th International Conference on Extending Database Technology (WebDB’98).</booktitle>
<pages>172--183</pages>
<marker>Sergey, 1998</marker>
<rawString>Brin Sergey. 1998. Extracting patterns and relations from world wide web. In Proceedings of WebDB Workshop at 6th International Conference on Extending Database Technology (WebDB’98). pages 172-183.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
</authors>
<title>A Maximum-entropy-inspired parser.</title>
<date>1999</date>
<tech>Technical Report CS-99-12.</tech>
<institution>Computer Science Department, Brown University.</institution>
<contexts>
<context position="10531" citStr="Charniak, 1999" startWordPosition="1773" endWordPosition="1774">ted in only YU. This algorithm has been shown to converge to a unique solution YU = limt,,,,, YUt = (I − �Tuu)� and Ghahramani, 2002). Here, Tuu and Tul are acquired by splitting matrix T after the l-th row and the l-th column into 4 sub-matrices. And I is u x u identity matrix. We can see that the initialization of YU0 in this solution is not important, since YU0 does �YU. 3 Experiments and Results 3.1 Feature Set Following (Zhang, 2004), we used lexical and syntactic features in the contexts of entity pairs, which are extracted and computed from the parse trees derived from Charniak Parser (Charniak, 1999) and the Chunklink script 2 written by Sabine Buchholz from Tilburg University. Words: Surface tokens of the two entities and words in the three contexts. Entity Type: the entity type of both entity mentions, which can be PERSON, ORGANIZATION, FACILITY, LOCATION and GPE. POS features: Part-Of-Speech tags corresponding to all tokens in the two entities and words in the three contexts. Chunking features: This category of features are extracted from the chunklink representation, which includes: • Chunk tag information of the two entities and words in the three contexts. The “0” tag means that the</context>
</contexts>
<marker>Charniak, 1999</marker>
<rawString>Charniak E. 1999. A Maximum-entropy-inspired parser. Technical Report CS-99-12. Computer Science Department, Brown University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Culotta</author>
<author>J Soresen</author>
</authors>
<title>Dependency tree kernels for relation extraction,</title>
<date>2004</date>
<booktitle>In Proceedings of 42th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<pages>21--26</pages>
<location>Barcelona,</location>
<contexts>
<context position="1393" citStr="Culotta and Soresen, 2004" startWordPosition="202" endWordPosition="205">1) it should be fixed on the labeled nodes, 2) it should be smooth on the whole graph. Experiment results on the ACE corpus showed that this LP algorithm achieves better performance than SVM when only very few labeled examples are available, and it also performs better than bootstrapping for the relation extraction task. 1 Introduction Relation extraction is the task of detecting and classifying relationships between two entities from text. Many machine learning methods have been proposed to address this problem, e.g., supervised learning algorithms (Miller et al., 2000; Zelenko et al., 2002; Culotta and Soresen, 2004; Kambhatla, 2004; Zhou et al., 2005), semi-supervised learning algorithms (Brin, 1998; Agichtein and Gravano, 2000; Zhang, 2004), and unsupervised learning algorithms (Hasegawa et al., 2004). Supervised methods for relation extraction perform well on the ACE Data, but they require a large amount of manually labeled relation instances. Unsupervised methods do not need the definition of relation types and manually labeled data, but they cannot detect relations between entity pairs and its result cannot be directly used in many NLP tasks since there is no relation type label attached to each ins</context>
<context position="22317" citStr="Culotta and Soresen (2004)" startWordPosition="3812" endWordPosition="3815">rithm performs better than SVM and 134 Table 4: Comparison of the performance of the bootstrapped SVM method from (Zhang, 2004) and LP method with 100 seed labeled examples for relation type classification task. Relation type ROLE PART AT SOC NEAR Bootstrapping LPJS P R F P R F 78.5 69.7 73.8 81.0 74.7 77.7 65.6 34.1 44.9 70.1 41.6 52.2 61.0 84.8 70.9 74.2 79.1 76.6 47.0 57.4 51.7 45.0 59.1 51.0 � � � 13.7 12.5 13.0 Table 5: Comparison of the performance of previous methods on ACE RDC task. Relation Dectection Relation Detection and Classification on Types on Subtypes Method P R F P R F P R F Culotta and Soresen (2004) Tree kernel based 81.2 51.8 63.2 67.1 35.0 45.8 - - - Kambhatla (2004) Feature based, Maxi- - - - - - - 63.5 45.2 52.8 mum Entropy Zhou et al. (2005) Feature based,SVM 84.8 66.7 74.7 77.2 60.7 68.0 63.1 49.5 55.5 bootstrapping. We have some findings from these results: The LP based relation extraction method can use the graph structure to smooth the labels of unlabeled examples. Therefore, the labels of unlabeled examples are determined not only by the nearby labeled examples, but also by nearby unlabeled examples. For supervised methods, e.g., SVM, very few labeled examples are not enough to</context>
<context position="23800" citStr="Culotta and Soresen (2004)" startWordPosition="4053" endWordPosition="4056">ased semisupervised method achieves better performance on both relation detection and classification when only few labeled data is available. Bootstrapping Currently most of works on the RDC task of ACE focused on supervised learning methods Culotta and Soresen (2004; Kambhatla (2004; Zhou et al. (2005). Table 5 lists a comparison on relation detection and classification of these methods. Zhou et al. (2005) reported the best result as 63.1%/49.5%/55.5% in Precision/Recall/F-measure on the relation subtype classification using feature based method, which outperforms tree kernel based method by Culotta and Soresen (2004). Compared with Zhou et al.’s method, the performance of LP algorithm is slightly lower. It may be due to that we used a much simpler feature set. Our work in this paper focuses on the investigation of a graph based semi-supervised learning algorithm for relation extraction. In the future, we would like to use more effective feature sets Zhou et al. (2005) or kernel based similarity measure with LP for relation extraction. 5 Conclusion and Future Work This paper approaches the problem of semisupervised relation extraction using a label propagation algorithm. It represents labeled and unlabeled</context>
</contexts>
<marker>Culotta, Soresen, 2004</marker>
<rawString>Culotta A. and Soresen J. 2004. Dependency tree kernels for relation extraction, In Proceedings of 42th Annual Meeting of the Association for Computational Linguistics. 21-26 July 2004. Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Hasegawa</author>
<author>S Sekine</author>
<author>R Grishman</author>
</authors>
<title>Discovering Relations among Named Entities from Large Corpora,</title>
<date>2004</date>
<booktitle>In Proceeding of Conference ACL2004.</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="1584" citStr="Hasegawa et al., 2004" startWordPosition="229" endWordPosition="232">n only very few labeled examples are available, and it also performs better than bootstrapping for the relation extraction task. 1 Introduction Relation extraction is the task of detecting and classifying relationships between two entities from text. Many machine learning methods have been proposed to address this problem, e.g., supervised learning algorithms (Miller et al., 2000; Zelenko et al., 2002; Culotta and Soresen, 2004; Kambhatla, 2004; Zhou et al., 2005), semi-supervised learning algorithms (Brin, 1998; Agichtein and Gravano, 2000; Zhang, 2004), and unsupervised learning algorithms (Hasegawa et al., 2004). Supervised methods for relation extraction perform well on the ACE Data, but they require a large amount of manually labeled relation instances. Unsupervised methods do not need the definition of relation types and manually labeled data, but they cannot detect relations between entity pairs and its result cannot be directly used in many NLP tasks since there is no relation type label attached to each instance in clustering result. Considering both the availability of a large amount of untagged corpora and direct usage of extracted relations, semisupervised learning methods has received great</context>
</contexts>
<marker>Hasegawa, Sekine, Grishman, 2004</marker>
<rawString>Hasegawa T., Sekine S. and Grishman R. 2004. Discovering Relations among Named Entities from Large Corpora, In Proceeding of Conference ACL2004. Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Kambhatla</author>
</authors>
<title>Combining lexical, syntactic and semantic features with Maximum Entropy Models for extracting relations,</title>
<date>2004</date>
<booktitle>In Proceedings of 42th Annual Meeting of the Association for Computational Linguistics..</booktitle>
<pages>21--26</pages>
<location>Barcelona,</location>
<contexts>
<context position="1410" citStr="Kambhatla, 2004" startWordPosition="206" endWordPosition="207">e labeled nodes, 2) it should be smooth on the whole graph. Experiment results on the ACE corpus showed that this LP algorithm achieves better performance than SVM when only very few labeled examples are available, and it also performs better than bootstrapping for the relation extraction task. 1 Introduction Relation extraction is the task of detecting and classifying relationships between two entities from text. Many machine learning methods have been proposed to address this problem, e.g., supervised learning algorithms (Miller et al., 2000; Zelenko et al., 2002; Culotta and Soresen, 2004; Kambhatla, 2004; Zhou et al., 2005), semi-supervised learning algorithms (Brin, 1998; Agichtein and Gravano, 2000; Zhang, 2004), and unsupervised learning algorithms (Hasegawa et al., 2004). Supervised methods for relation extraction perform well on the ACE Data, but they require a large amount of manually labeled relation instances. Unsupervised methods do not need the definition of relation types and manually labeled data, but they cannot detect relations between entity pairs and its result cannot be directly used in many NLP tasks since there is no relation type label attached to each instance in clusteri</context>
<context position="22388" citStr="Kambhatla (2004)" startWordPosition="3828" endWordPosition="3829">the bootstrapped SVM method from (Zhang, 2004) and LP method with 100 seed labeled examples for relation type classification task. Relation type ROLE PART AT SOC NEAR Bootstrapping LPJS P R F P R F 78.5 69.7 73.8 81.0 74.7 77.7 65.6 34.1 44.9 70.1 41.6 52.2 61.0 84.8 70.9 74.2 79.1 76.6 47.0 57.4 51.7 45.0 59.1 51.0 � � � 13.7 12.5 13.0 Table 5: Comparison of the performance of previous methods on ACE RDC task. Relation Dectection Relation Detection and Classification on Types on Subtypes Method P R F P R F P R F Culotta and Soresen (2004) Tree kernel based 81.2 51.8 63.2 67.1 35.0 45.8 - - - Kambhatla (2004) Feature based, Maxi- - - - - - - 63.5 45.2 52.8 mum Entropy Zhou et al. (2005) Feature based,SVM 84.8 66.7 74.7 77.2 60.7 68.0 63.1 49.5 55.5 bootstrapping. We have some findings from these results: The LP based relation extraction method can use the graph structure to smooth the labels of unlabeled examples. Therefore, the labels of unlabeled examples are determined not only by the nearby labeled examples, but also by nearby unlabeled examples. For supervised methods, e.g., SVM, very few labeled examples are not enough to reveal the structure of each class. Therefore they can not perform wel</context>
</contexts>
<marker>Kambhatla, 2004</marker>
<rawString>Kambhatla N. 2004. Combining lexical, syntactic and semantic features with Maximum Entropy Models for extracting relations, In Proceedings of 42th Annual Meeting of the Association for Computational Linguistics.. 21-26 July 2004. Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lin</author>
</authors>
<title>Divergence Measures Based on the Shannon Entropy.</title>
<date>1991</date>
<journal>IEEE Transactions on Information Theory. Vol</journal>
<volume>37</volume>
<pages>145--150</pages>
<contexts>
<context position="12898" citStr="Lin, 1991" startWordPosition="2184" endWordPosition="2185">words in Cmid 6) WEL1, WEL2, ...: first word, second word, ... before e1 7) WER1, WER2, ...: first word, second word, ... after e2 We combine the above lexical and syntactic features with their position information in the contexts to form context vectors. Before that, we filter out low frequency features which appeared only once in the dataset. 3.2 Similarity Measures The similarity sib between two occurrences of entity pairs is important to the performance of the LP algorithm. In this paper, we investigated two similarity measures, cosine similarity measure and JensenShannon (JS) divergence (Lin, 1991). Cosine similarity is commonly used semantic distance, which measures the angle between two feature vectors. JS divergence has ever been used as distance measure for document clustering, which outperforms cosine similarity based document clustering (Slonim et al., 2002). JS divergence measures the distance between two probability distributions if feature vector is considered as probability distribution over features. JS divergence is defined as follows: Table 1: Frequency of Relation SubTypes in the ACE training and devtest corpus. Type SubType Training Devtest ROLE General-Staff 550 149 Mana</context>
</contexts>
<marker>Lin, 1991</marker>
<rawString>Lin J. 1991. Divergence Measures Based on the Shannon Entropy. IEEE Transactions on Information Theory. Vol 37, No.1, 145-150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Miller</author>
<author>H Fox</author>
<author>L Ramshaw</author>
<author>R Weischedel</author>
</authors>
<title>A novel use ofstatistical parsing to extract information from text.</title>
<date>2000</date>
<booktitle>In Proceedings of 6th Applied Natural Language Processing Conference 29 April-4</booktitle>
<location>Seattle USA.</location>
<contexts>
<context position="1344" citStr="Miller et al., 2000" startWordPosition="194" endWordPosition="197">eling function to satisfy two constraints: 1) it should be fixed on the labeled nodes, 2) it should be smooth on the whole graph. Experiment results on the ACE corpus showed that this LP algorithm achieves better performance than SVM when only very few labeled examples are available, and it also performs better than bootstrapping for the relation extraction task. 1 Introduction Relation extraction is the task of detecting and classifying relationships between two entities from text. Many machine learning methods have been proposed to address this problem, e.g., supervised learning algorithms (Miller et al., 2000; Zelenko et al., 2002; Culotta and Soresen, 2004; Kambhatla, 2004; Zhou et al., 2005), semi-supervised learning algorithms (Brin, 1998; Agichtein and Gravano, 2000; Zhang, 2004), and unsupervised learning algorithms (Hasegawa et al., 2004). Supervised methods for relation extraction perform well on the ACE Data, but they require a large amount of manually labeled relation instances. Unsupervised methods do not need the definition of relation types and manually labeled data, but they cannot detect relations between entity pairs and its result cannot be directly used in many NLP tasks since the</context>
</contexts>
<marker>Miller, Fox, Ramshaw, Weischedel, 2000</marker>
<rawString>Miller S.,Fox H.,Ramshaw L. and Weischedel R. 2000. A novel use ofstatistical parsing to extract information from text. In Proceedings of 6th Applied Natural Language Processing Conference 29 April-4 may 2000, Seattle USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Slonim</author>
<author>N Friedman</author>
<author>N Tishby</author>
</authors>
<title>Unsupervised Document Classification Using Sequential Information Maximization.</title>
<date>2002</date>
<booktitle>In Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval.</booktitle>
<contexts>
<context position="13169" citStr="Slonim et al., 2002" startWordPosition="2221" endWordPosition="2224">e that, we filter out low frequency features which appeared only once in the dataset. 3.2 Similarity Measures The similarity sib between two occurrences of entity pairs is important to the performance of the LP algorithm. In this paper, we investigated two similarity measures, cosine similarity measure and JensenShannon (JS) divergence (Lin, 1991). Cosine similarity is commonly used semantic distance, which measures the angle between two feature vectors. JS divergence has ever been used as distance measure for document clustering, which outperforms cosine similarity based document clustering (Slonim et al., 2002). JS divergence measures the distance between two probability distributions if feature vector is considered as probability distribution over features. JS divergence is defined as follows: Table 1: Frequency of Relation SubTypes in the ACE training and devtest corpus. Type SubType Training Devtest ROLE General-Staff 550 149 Management 677 122 Citizen-Of 127 24 Founder 11 5 Owner 146 15 Affiliate-Partner 111 15 Member 460 145 Client 67 13 Other 15 7 PART Part-Of 490 103 Subsidiary 85 19 Other 2 1 AT Located 975 192 Based-In 187 64 Residence 154 54 SOC Other-Professional 195 25 Other-Personal 60 </context>
</contexts>
<marker>Slonim, Friedman, Tishby, 2002</marker>
<rawString>Slonim, N., Friedman, N., and Tishby, N. 2002. Unsupervised Document Classification Using Sequential Information Maximization. In Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>Unsupervised Word Sense Disambiguation Rivaling Supervised Methods.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics.</booktitle>
<pages>189--196</pages>
<marker>Yarowsky, 1995</marker>
<rawString>Yarowsky D. 1995. Unsupervised Word Sense Disambiguation Rivaling Supervised Methods. In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics. pp.189-196.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Zelenko</author>
<author>C Aone</author>
<author>A Richardella</author>
</authors>
<title>Kernel Methods for Relation Extraction,</title>
<date>2002</date>
<booktitle>Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<location>Philadelphia.</location>
<contexts>
<context position="1366" citStr="Zelenko et al., 2002" startWordPosition="198" endWordPosition="201">isfy two constraints: 1) it should be fixed on the labeled nodes, 2) it should be smooth on the whole graph. Experiment results on the ACE corpus showed that this LP algorithm achieves better performance than SVM when only very few labeled examples are available, and it also performs better than bootstrapping for the relation extraction task. 1 Introduction Relation extraction is the task of detecting and classifying relationships between two entities from text. Many machine learning methods have been proposed to address this problem, e.g., supervised learning algorithms (Miller et al., 2000; Zelenko et al., 2002; Culotta and Soresen, 2004; Kambhatla, 2004; Zhou et al., 2005), semi-supervised learning algorithms (Brin, 1998; Agichtein and Gravano, 2000; Zhang, 2004), and unsupervised learning algorithms (Hasegawa et al., 2004). Supervised methods for relation extraction perform well on the ACE Data, but they require a large amount of manually labeled relation instances. Unsupervised methods do not need the definition of relation types and manually labeled data, but they cannot detect relations between entity pairs and its result cannot be directly used in many NLP tasks since there is no relation type</context>
</contexts>
<marker>Zelenko, Aone, Richardella, 2002</marker>
<rawString>Zelenko D., Aone C. and Richardella A. 2002. Kernel Methods for Relation Extraction, Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP). Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhang Zhu</author>
</authors>
<title>Weakly-supervised relation classification for Information Extraction,</title>
<date>2004</date>
<booktitle>In Proceedings of ACM 13th conference on Information and Knowledge Management (CIKM’2004).</booktitle>
<pages>8--13</pages>
<location>Washington D.C.,USA.</location>
<marker>Zhu, 2004</marker>
<rawString>Zhang Zhu. 2004. Weakly-supervised relation classification for Information Extraction, In Proceedings of ACM 13th conference on Information and Knowledge Management (CIKM’2004). 8-13 Nov 2004. Washington D.C.,USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhou GuoDong</author>
<author>Su Jian</author>
<author>Zhang Jie</author>
<author>Zhang min</author>
</authors>
<title>Exploring Various Knowledge in Relation Extraction.</title>
<date>2005</date>
<booktitle>In Proceedings of 43th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<location>USA.</location>
<marker>GuoDong, Jian, Jie, min, 2005</marker>
<rawString>Zhou GuoDong, Su Jian, Zhang Jie and Zhang min. 2005. Exploring Various Knowledge in Relation Extraction. In Proceedings of 43th Annual Meeting of the Association for Computational Linguistics. USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhu Xiaojin</author>
<author>Ghahramani Zoubin</author>
</authors>
<date>2002</date>
<booktitle>Learning from Labeled and Unlabeled Data with Label Propagation. CMU CALD tech report</booktitle>
<pages>02--107</pages>
<marker>Xiaojin, Zoubin, 2002</marker>
<rawString>Zhu Xiaojin and Ghahramani Zoubin. 2002. Learning from Labeled and Unlabeled Data with Label Propagation. CMU CALD tech report CMU-CALD-02-107.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhu Xiaojin</author>
<author>Ghahramani Zoubin</author>
<author>J Lafferty</author>
</authors>
<title>Semi-Supervised Learning Using Gaussian Fields and Harmonic Functions.</title>
<date>2003</date>
<booktitle>In Proceedings of the 20th International Conference on Machine Learning.</booktitle>
<marker>Xiaojin, Zoubin, Lafferty, 2003</marker>
<rawString>Zhu Xiaojin, Ghahramani Zoubin, and Lafferty J. 2003. Semi-Supervised Learning Using Gaussian Fields and Harmonic Functions. In Proceedings of the 20th International Conference on Machine Learning.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>