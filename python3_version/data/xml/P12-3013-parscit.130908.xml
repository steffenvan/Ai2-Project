<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.039035">
<title confidence="0.9941925">
BIUTEE: A Modular Open-Source System for Recognizing Textual
Entailment
</title>
<author confidence="0.996571">
Asher Stern
</author>
<affiliation confidence="0.989893">
Computer Science Department
Bar-Ilan University
</affiliation>
<address confidence="0.688814">
Ramat-Gan 52900, Israel
</address>
<email confidence="0.992742">
astern7@gmail.com
</email>
<author confidence="0.988596">
Ido Dagan
</author>
<affiliation confidence="0.988645">
Computer Science Department
Bar-Ilan University
</affiliation>
<address confidence="0.690524">
Ramat-Gan 52900, Israel
</address>
<email confidence="0.997166">
dagan@cs.biu.ac.il
</email>
<sectionHeader confidence="0.995619" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999535894736842">
This paper introduces BIUTEE1, an open-
source system for recognizing textual entail-
ment. Its main advantages are its ability to uti-
lize various types of knowledge resources, and
its extensibility by which new knowledge re-
sources and inference components can be eas-
ily integrated. These abilities make BIUTEE
an appealing RTE system for two research
communities: (1) researchers of end applica-
tions, that can benefit from generic textual in-
ference, and (2) RTE researchers, who can in-
tegrate their novel algorithms and knowledge
resources into our system, saving the time and
effort of developing a complete RTE system
from scratch. Notable assistance for these re-
searchers is provided by a visual tracing tool,
by which researchers can refine and “debug”
their knowledge resources and inference com-
ponents.
</bodyText>
<sectionHeader confidence="0.999109" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998193454545454">
Recognizing Textual Entailment (RTE) is the task of
identifying, given two text fragments, whether one
of them can be inferred from the other (Dagan et al.,
2006). This task generalizes a common problem that
arises in many tasks at the semantic level of NLP.
For example, in Information Extraction (IE), a sys-
tem may be given a template with variables (e.g., “X
is employed by Y”) and has to find text fragments
from which this template, with variables replaced
by proper entities, can be inferred. In Summariza-
tion, a good summary should be inferred from the
</bodyText>
<footnote confidence="0.971085">
1www.cs.biu.ac.il/˜nlp/downloads/biutee
</footnote>
<page confidence="0.995715">
73
</page>
<bodyText confidence="0.999808727272727">
given text, and, in addition, should not contain du-
plicated information, i.e., sentences which can be in-
ferred from other sentences in the summary. Detect-
ing these inferences can be performed by an RTE
system.
Since first introduced, several approaches have
been proposed for this task, ranging from shallow
lexical similarity methods (e.g., (Clark and Har-
rison, 2010; MacKinlay and Baldwin, 2009)), to
complex linguistically-motivated methods, which
incorporate extensive linguistic analysis (syntactic
parsing, coreference resolution, semantic role la-
belling, etc.) and a rich inventory of linguistic and
world-knowledge resources (e.g., (Iftene, 2008; de
Salvo Braz et al., 2005; Bar-Haim et al., 2007)).
Building such complex systems requires substantial
development efforts, which might become a barrier
for new-comers to RTE research. Thus, flexible and
extensible publicly available RTE systems are ex-
pected to significantly facilitate research in this field.
More concretely, two major research communities
would benefit from a publicly available RTE system:
</bodyText>
<listItem confidence="0.998875727272727">
1. Higher-level application developers, who
would use an RTE system to solve inference
tasks in their application. RTE systems for
this type of researchers should be adaptable
for the application specific data: they should
be configurable, trainable, and extensible
with inference knowledge that captures
application-specific phenomena.
2. Researchers in the RTE community, that would
not need to build a complete RTE system for
their research. Rather, they may integrate
</listItem>
<note confidence="0.4171465">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 73–78,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999966636363636">
their novel research components into an ex-
isting open-source system. Such research ef-
forts might include developing knowledge re-
sources, developing inference components for
specific phenomena such as temporal infer-
ence, or extending RTE to different languages.
A flexible and extensible RTE system is ex-
pected to encourage researchers to create and
share their textual-inference components. A
good example from another research area is the
Moses system for Statistical Machine Transla-
tion (SMT) (Koehn et al., 2007), which pro-
vides the core SMT components while being
extended with new research components by a
large scientific community.
Yet, until now rather few and quite limited RTE
systems were made publicly available. Moreover,
these systems are restricted in the types of knowl-
edge resources which they can utilize, and in the
scope of their inference algorithms. For example,
EDITS2 (Kouylekov and Negri, 2010) is a distance-
based RTE system, which can exploit only lexical
knowledge resources. NutCracker3 (Bos and Mark-
ert, 2005) is a system based on logical represen-
tation and automatic theorem proving, but utilizes
only WordNet (Fellbaum, 1998) as a lexical knowl-
edge resource.
Therefore, we provide our open-source textual-
entailment system, BIUTEE. Our system provides
state-of-the-art linguistic analysis tools and exploits
various types of manually built and automatically
acquired knowledge resources, including lexical,
lexical-syntactic and syntactic rewrite rules. Fur-
thermore, the system components, including pre-
processing utilities, knowledge resources, and even
the steps of the inference algorithm, are modu-
lar, and can be replaced or extended easily with
new components. Extensibility and flexibility are
also supported by a plug-in mechanism, by which
new inference components can be integrated with-
out changing existing code.
Notable support for researchers is provided by a
visual tracing tool, Tracer, which visualizes every
step of the inference process as shown in Figures 2
</bodyText>
<footnote confidence="0.984868666666667">
2http://edits.fbk.eu/
3http://svn.ask.it.usyd.edu.au/trac/
candc/wiki/nutcracker
</footnote>
<bodyText confidence="0.910775">
and 3. We will use this tool to illustrate various in-
ference components in the demonstration session.
</bodyText>
<sectionHeader confidence="0.922188" genericHeader="method">
2 System Description
</sectionHeader>
<subsectionHeader confidence="0.890595">
2.1 Inference algorithm
</subsectionHeader>
<bodyText confidence="0.999537261904762">
In this section we provide a high level description of
the inference components. Further details of the al-
gorithmic components appear in references provided
throughout this section.
BIUTEE follows the transformation based
paradigm, which recognizes textual entailment
by converting the text into the hypothesis via a
sequence of transformations. Such a sequence is
often referred to as a proof, and is performed, in our
system, over the syntactic representation of the text
- the text’s parse tree(s). A transformation modifies
a given parse tree, resulting in a generation of a
new parse tree, which can be further modified by
subsequent transformations.
Consider, for example, the following text-
hypothesis pair:
Text:... Obasanjo invited him to step down as president
... and accept political asylum in Nigeria.
Hypothesis: Charles G. Taylor was offered asylum in
Nigeria.
This text-hypothesis pair requires two major
transformations: (1) substituting “him” by “Charles
G. Taylor” via a coreference substitution to an ear-
lier mention in the text, and (2) inferring that if “X
accept Y” then “X was offered Y”.
BIUTEE allows many types of transformations,
by which any hypothesis can be proven from any
text. Given a T-H pair, the system finds a proof
which generates H from T, and estimates the proof
validity. The system returns a score which indicates
how likely it is that the obtained proof is valid, i.e.,
the transformations along the proof preserve entail-
ment from the meaning of T.
The main type of transformations is application of
entailment-rules (Bar-Haim et al., 2007). An entail-
ment rule is composed of two sub-trees, termed left-
hand-side and right-hand-side, and is applied on a
parse-tree fragment that matches its left-hand-side,
by substituting the left-hand-side with the right-
hand-side. This formalism is simple yet power-
ful, and captures many types of knowledge. The
simplest type of rules is lexical rules, like car —*
</bodyText>
<page confidence="0.993546">
74
</page>
<bodyText confidence="0.999880046511628">
vehicle. More complicated rules capture the en-
tailment relation between predicate-argument struc-
tures, like X accept Y —* X was offered
Y. Entailment rules can also encode syntactic
phenomena like the semantic equivalence of ac-
tive and passive structures (X Verb[active]
Y —* Y is Verb[passive] by X). Various
knowledge resources, represented as entailment
rules, are freely available in BIUTEE’s web-site. The
complete formalism of entailment rules, adopted by
our system, is described in (Bar-Haim et al., 2007).
Coreference relations are utilized via coreference-
substitution transformations: one mention of an en-
tity is replaced by another mention of the same en-
tity, based on coreference relations. In the above ex-
ample the system could apply such a transformation
to substitute “him” with “Charles G. Taylor”.
Since applications of entailment rules and coref-
erence substitutions are yet, in most cases, insuffi-
cient in transforming T into H, our system allows
on-the-fly transformations. These transformations
include insertions of missing nodes, flipping parts-
of-speech, moving sub-trees, etc. (see (Stern and
Dagan, 2011) for a complete list of these transforma-
tions). Since these transformations are not justified
by given knowledge resources, we use linguistically-
motivated features to estimate their validity. For ex-
ample, for on-the-fly lexical insertions we consider
as features the named-entity annotation of the in-
serted word, and its probability estimation according
to a unigram language model, which yields lower
costs for more frequent words.
Given a (T,H) pair, the system applies a search
algorithm (Stern et al., 2012) to find a proof O =
(o1,o2,... on) that transforms T into H. For each
proof step oi the system calculates a cost c(oi). This
cost is defined as follows: the system uses a weight-
vector w, which is learned in the training phase. In
addition, each transformation oi is represented by a
feature vector f(oi) which characterizes the trans-
formation. The cost c(oi) is defined as w · f(oi).
The proof cost is defined as the sum of the costs of
the transformations from which it is composed, i.e.:
</bodyText>
<equation confidence="0.9338395">
n n n
c(O) °_ c(oi) = w · f(oi) = w · f(oi)
i=1 i=1 i=1
(1)
</equation>
<bodyText confidence="0.980749">
If the proof cost is below a threshold b, then the sys-
tem concludes that T entails H. The complete de-
scription of the cost model, as well as the method
for learning the parameters w and b is described in
(Stern and Dagan, 2011).
</bodyText>
<subsectionHeader confidence="0.996249">
2.2 System flow
</subsectionHeader>
<bodyText confidence="0.999972452380952">
The BIUTEE system flow (Figure 1) starts with pre-
processing of the text and the hypothesis. BIUTEE
provides state-of-the-art pre-processing utilities:
Easy-First parser (Goldberg and Elhadad, 2010),
Stanford named-entity-recognizer (Finkel et al.,
2005) and ArkRef coreference resolver (Haghighi
and Klein, 2009), as well as utilities for sentence-
splitting and numerical-normalizations. In addition,
BIUTEE supports integration of users’ own utilities
by simply implementing the appropriate interfaces.
Entailment recognition begins with a global pro-
cessing phase in which inference related computa-
tions that are not part of the proof are performed.
Annotating the negation indicators and their scope
in the text and hypothesis is an example of such cal-
culation. Next, the system constructs a proof which
is a sequence of transformations that transform the
text into the hypothesis. Finding such a proof is a
sequential process, conducted by the search algo-
rithm. In each step of the proof construction the sys-
tem examines all possible transformations that can
be applied, generates new trees by applying selected
transformations, and calculates their costs by con-
structing appropriate feature-vectors for them.
New types of transformations can be added to
BIUTEE by a plug-in mechanism, without the need
to change the code. For example, imagine that a
researcher applies BIUTEE on the medical domain.
There might be some well-known domain knowl-
edge and rules that every medical person knows.
Integrating them is directly supported by the plug-in
mechanism. A plug-in is a piece of code which im-
plements a few interfaces that detect which transfor-
mations can be applied, apply them, and construct
appropriate feature-vectors for each applied trans-
formation. In addition, a plug-in can perform com-
putations for the global processing phase.
Eventually, the search algorithm finds a (approx-
imately) lowest cost proof. This cost is normalized
as a score between 0 and 1, and returned as output.
Training the cost model parameters w and b
(see subsection 2.1) is performed by a linear learn-
</bodyText>
<page confidence="0.998545">
75
</page>
<figureCaption confidence="0.998315">
Figure 1: System architecture
</figureCaption>
<table confidence="0.9923195">
RTE Median Best BIUTEE
challenge
RTE-6 33.72 48.01 49.09
RTE-7 39.89 48.00 42.93
</table>
<tableCaption confidence="0.82865275">
Table 1: Performance (F1) of BIUTEE on RTE chal-
lenges, compared to other systems participated in these
challenges. Median and Best indicate the median score
and the highest score of all submissions, respectively.
</tableCaption>
<bodyText confidence="0.99962">
ing algorithm, as described in (Stern and Dagan,
2011). We use a Logistic-Regression learning algo-
rithm, but, similar to other components, alternative
learning-algorithms can be integrated easily by im-
plementing an appropriate interface.
</bodyText>
<subsectionHeader confidence="0.998312">
2.3 Experimental results
</subsectionHeader>
<bodyText confidence="0.9895326">
BIUTEE’s performance on the last two RTE chal-
lenges (Bentivogli et al., 2011; Bentivogli et al.,
2010) is presented in Table 1: BIUTEE is better than
the median of all submitted results, and in RTE-6 it
outperforms all other systems.
</bodyText>
<sectionHeader confidence="0.977441" genericHeader="method">
3 Visual Tracing Tool
</sectionHeader>
<bodyText confidence="0.999918125">
As a complex system, the final score provided as
output, as well as the system’s detailed logging in-
formation, do not expose all the decisions and cal-
culations performed by the system. In particular,
they do not show all the potential transformations
that could have been applied, but were rejected by
the search algorithm. However, such information is
crucial for researchers, who need to observe the us-
age and the potential impact of each component of
the system.
We address this need by providing an interactive
visual tracing tool, Tracer, which presents detailed
information on each proof step, including potential
steps that were not included in the final proof. In the
demo session, we will use the visual tracing tool to
illustrate all of BIUTEE’s components4.
</bodyText>
<subsectionHeader confidence="0.996596">
3.1 Modes
</subsectionHeader>
<bodyText confidence="0.999992235294118">
Tracer provides two modes for tracing proof con-
struction: automatic mode and manual mode. In au-
tomatic mode, shown in Figure 2, the tool presents
the complete process of inference, as conducted by
the system’s search: the parse trees, the proof steps,
the cost of each step and the final score. For each
transformation the tool presents the parse tree before
and after applying the transformation, highlighting
the impact of this transformation. In manual mode,
the user can invoke specific transformations pro-
actively, including transformations rejected by the
search algorithm for the eventual proof. As shown in
Figure 3, the tool provides a list of transformations
that match the given parse-tree, from which the user
chooses and applies a single transformation at each
step. Similar to automatic mode, their impact on the
parse tree is shown visually.
</bodyText>
<subsectionHeader confidence="0.999805">
3.2 Use cases
</subsectionHeader>
<bodyText confidence="0.999974">
Developers of knowledge resources, as well as other
types of transformations, can be aided by Tracer as
follows. Applying an entailment rule is a process
of first matching the rule’s left-hand-side to the text
parse-tree (or to any tree along the proof), and then
substituting it by the rule’s right-hand-side. To test a
</bodyText>
<footnote confidence="0.981185">
4Our demonstration requirements are a large screen and In-
ternet connection.
</footnote>
<page confidence="0.97413">
76
</page>
<figureCaption confidence="0.998231333333333">
Figure 2: Entailment Rule application visualized in tracing tool. The upper pane displays the parse-tree generated by
applying the rule. The rule description is the first transformation (printed in bold) of the proof, shown in the lower
pane. It is followed by transformations 2 and 3, which are syntactic rewrite rules.
</figureCaption>
<bodyText confidence="0.99996968">
rule, the user can provide a text for which it is sup-
posed to match, examine the list of potential trans-
formations that can be performed on the text’s parse
tree, as in Figure 3, and verify that the examined
rule has been matched as expected. Next, the user
can apply the rule, visually examine its impact on
the parse-tree, as in Figure 2, and validate that it op-
erates as intended with no side-effects.
The complete inference process depends on the
parameters learned in the training phase, as well as
on the search algorithm which looks for lowest-cost
proof from T to H. Researchers investigating these
algorithmic components can be assisted by the trac-
ing tool as well. For a given (T,H) pair, the auto-
matic mode provides the complete proof found by
the system. Then, in the manual mode the researcher
can try to construct alternative proofs. If a proof
with lower cost can be constructed manually it im-
plies a limitation of the search algorithm. On the
other hand, if the user can manually construct a bet-
ter linguistically motivated proof, but it turns out that
this proof has higher cost than the one found by the
system, it implies a limitation of the learning phase
which may be caused either by a limitation of the
learning method, or due to insufficient training data.
</bodyText>
<sectionHeader confidence="0.999592" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.998450111111111">
In this paper we described BIUTEE, an open-source
textual-inference system, and suggested it as a re-
search platform in this field. We highlighted key
advantages of BIUTEE, which directly support re-
searchers’ work: (a) modularity and extensibility,
(b) a plug-in mechanism, (c) utilization of entail-
ment rules, which can capture diverse types of
knowledge, and (d) a visual tracing tool, which vi-
sualizes all the details of the inference process.
</bodyText>
<sectionHeader confidence="0.998303" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.990236">
This work was partially supported by the Israel
Science Foundation grant 1112/08, the PASCAL-
</bodyText>
<page confidence="0.997744">
77
</page>
<figureCaption confidence="0.9911915">
Figure 3: List of available transformations, provided by Tracer in the manual mode. The user can manually choose
and apply each of these transformations, and observe their impact on the parse-tree.
</figureCaption>
<bodyText confidence="0.8819952">
2 Network of Excellence of the European Com-
munity FP7-ICT-2007-1-216886, and the Euro-
pean Community’s Seventh Framework Programme
(FP7/2007-2013) under grant agreement no. 287923
(EXCITEMENT).
</bodyText>
<sectionHeader confidence="0.997607" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999852322033898">
Roy Bar-Haim, Ido Dagan, Iddo Greental, and Eyal
Shnarch. 2007. Semantic inference at the lexical-
syntactic level. In Proceedings of AAAI.
Luisa Bentivogli, Peter Clark, Ido Dagan, Hoa Dang, and
Danilo Giampiccolo. 2010. The sixth pascal recog-
nizing textual entailment challenge. In Proceedings of
TAC.
Luisa Bentivogli, Peter Clark, Ido Dagan, Hoa Dang, and
Danilo Giampiccolo. 2011. The seventh pascal recog-
nizing textual entailment challenge. In Proceedings of
TAC.
Johan Bos and Katja Markert. 2005. Recognising textual
entailment with logical inference. In Proceedings of
EMNLP.
Peter Clark and Phil Harrison. 2010. Blue-lite: a
knowledge-based lexical entailment system for rte6.
In Proceedings of TAC.
Ido Dagan, Oren Glickman, and Bernardo Magnini.
2006. The pascal recognising textual entailment chal-
lenge. In Quionero-Candela, J.; Dagan, I.; Magnini,
B.; d’Alch-Buc, F. (Eds.) Machine Learning Chal-
lenges. Lecture Notes in Computer Science.
Rodrigo de Salvo Braz, Roxana Girju, Vasin Pun-
yakanok, Dan Roth, and Mark Sammons. 2005. An
inference model for semantic entailment in natural lan-
guage. In Proceedings of AAAI.
Christiane Fellbaum, editor. 1998. WordNet An Elec-
tronic Lexical Database. The MIT Press, May.
Jenny Rose Finkel, Trond Grenager, and Christopher
Manning. 2005. Incorporating non-local information
into information extraction systems by gibbs sampling.
In Proceedings ofACL.
Yoav Goldberg and Michael Elhadad. 2010. An effi-
cient algorithm for easy-first non-directional depen-
dency parsing. In Proceedings of NAACL.
Aria Haghighi and Dan Klein. 2009. Simple coreference
resolution with rich syntactic and semantic features. In
Proceedings of EMNLP.
Adrian Iftene. 2008. Uaic participation at rte4. In Pro-
ceedings of TAC.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondrej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: Open source
toolkit for statistical machine translation. In Proceed-
ings of ACL.
Milen Kouylekov and Matteo Negri. 2010. An open-
source package for recognizing textual entailment. In
Proceedings of ACL Demo.
Andrew MacKinlay and Timothy Baldwin. 2009. A
baseline approach to the rte5 search pilot. In Proceed-
ings of TAC.
Asher Stern and Ido Dagan. 2011. A confidence model
for syntactically-motivated entailment proofs. In Pro-
ceedings of RANLP.
Asher Stern, Roni Stern, Ido Dagan, and Ariel Felner.
2012. Efficient search for transformation-based infer-
ence. In Proceedings of ACL.
</reference>
<page confidence="0.998827">
78
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.199002">
<title confidence="0.985838">A Modular Open-Source System for Recognizing Textual Entailment</title>
<author confidence="0.987324">Asher</author>
<affiliation confidence="0.86241">Computer Science Bar-Ilan</affiliation>
<address confidence="0.714129">Ramat-Gan 52900,</address>
<email confidence="0.997197">astern7@gmail.com</email>
<author confidence="0.477934">Ido</author>
<affiliation confidence="0.911276">Computer Science Bar-Ilan</affiliation>
<address confidence="0.903307">Ramat-Gan 52900,</address>
<email confidence="0.998365">dagan@cs.biu.ac.il</email>
<abstract confidence="0.99172255">paper introduces an opensource system for recognizing textual entailment. Its main advantages are its ability to utilize various types of knowledge resources, and its extensibility by which new knowledge resources and inference components can be easintegrated. These abilities make an appealing RTE system for two research communities: (1) researchers of end applications, that can benefit from generic textual inference, and (2) RTE researchers, who can integrate their novel algorithms and knowledge resources into our system, saving the time and effort of developing a complete RTE system from scratch. Notable assistance for these researchers is provided by a visual tracing tool, by which researchers can refine and “debug” their knowledge resources and inference components.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Roy Bar-Haim</author>
</authors>
<title>Ido Dagan, Iddo Greental, and Eyal Shnarch.</title>
<date>2007</date>
<booktitle>In Proceedings of AAAI.</booktitle>
<marker>Bar-Haim, 2007</marker>
<rawString>Roy Bar-Haim, Ido Dagan, Iddo Greental, and Eyal Shnarch. 2007. Semantic inference at the lexicalsyntactic level. In Proceedings of AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luisa Bentivogli</author>
<author>Peter Clark</author>
<author>Ido Dagan</author>
<author>Hoa Dang</author>
<author>Danilo Giampiccolo</author>
</authors>
<title>The sixth pascal recognizing textual entailment challenge.</title>
<date>2010</date>
<booktitle>In Proceedings of TAC.</booktitle>
<contexts>
<context position="12831" citStr="Bentivogli et al., 2010" startWordPosition="1965" endWordPosition="1968">E-6 33.72 48.01 49.09 RTE-7 39.89 48.00 42.93 Table 1: Performance (F1) of BIUTEE on RTE challenges, compared to other systems participated in these challenges. Median and Best indicate the median score and the highest score of all submissions, respectively. ing algorithm, as described in (Stern and Dagan, 2011). We use a Logistic-Regression learning algorithm, but, similar to other components, alternative learning-algorithms can be integrated easily by implementing an appropriate interface. 2.3 Experimental results BIUTEE’s performance on the last two RTE challenges (Bentivogli et al., 2011; Bentivogli et al., 2010) is presented in Table 1: BIUTEE is better than the median of all submitted results, and in RTE-6 it outperforms all other systems. 3 Visual Tracing Tool As a complex system, the final score provided as output, as well as the system’s detailed logging information, do not expose all the decisions and calculations performed by the system. In particular, they do not show all the potential transformations that could have been applied, but were rejected by the search algorithm. However, such information is crucial for researchers, who need to observe the usage and the potential impact of each compo</context>
</contexts>
<marker>Bentivogli, Clark, Dagan, Dang, Giampiccolo, 2010</marker>
<rawString>Luisa Bentivogli, Peter Clark, Ido Dagan, Hoa Dang, and Danilo Giampiccolo. 2010. The sixth pascal recognizing textual entailment challenge. In Proceedings of TAC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luisa Bentivogli</author>
<author>Peter Clark</author>
<author>Ido Dagan</author>
<author>Hoa Dang</author>
<author>Danilo Giampiccolo</author>
</authors>
<title>The seventh pascal recognizing textual entailment challenge.</title>
<date>2011</date>
<booktitle>In Proceedings of TAC.</booktitle>
<contexts>
<context position="12805" citStr="Bentivogli et al., 2011" startWordPosition="1961" endWordPosition="1964"> Best BIUTEE challenge RTE-6 33.72 48.01 49.09 RTE-7 39.89 48.00 42.93 Table 1: Performance (F1) of BIUTEE on RTE challenges, compared to other systems participated in these challenges. Median and Best indicate the median score and the highest score of all submissions, respectively. ing algorithm, as described in (Stern and Dagan, 2011). We use a Logistic-Regression learning algorithm, but, similar to other components, alternative learning-algorithms can be integrated easily by implementing an appropriate interface. 2.3 Experimental results BIUTEE’s performance on the last two RTE challenges (Bentivogli et al., 2011; Bentivogli et al., 2010) is presented in Table 1: BIUTEE is better than the median of all submitted results, and in RTE-6 it outperforms all other systems. 3 Visual Tracing Tool As a complex system, the final score provided as output, as well as the system’s detailed logging information, do not expose all the decisions and calculations performed by the system. In particular, they do not show all the potential transformations that could have been applied, but were rejected by the search algorithm. However, such information is crucial for researchers, who need to observe the usage and the pote</context>
</contexts>
<marker>Bentivogli, Clark, Dagan, Dang, Giampiccolo, 2011</marker>
<rawString>Luisa Bentivogli, Peter Clark, Ido Dagan, Hoa Dang, and Danilo Giampiccolo. 2011. The seventh pascal recognizing textual entailment challenge. In Proceedings of TAC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bos</author>
<author>Katja Markert</author>
</authors>
<title>Recognising textual entailment with logical inference.</title>
<date>2005</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="4477" citStr="Bos and Markert, 2005" startWordPosition="661" endWordPosition="665">er research area is the Moses system for Statistical Machine Translation (SMT) (Koehn et al., 2007), which provides the core SMT components while being extended with new research components by a large scientific community. Yet, until now rather few and quite limited RTE systems were made publicly available. Moreover, these systems are restricted in the types of knowledge resources which they can utilize, and in the scope of their inference algorithms. For example, EDITS2 (Kouylekov and Negri, 2010) is a distancebased RTE system, which can exploit only lexical knowledge resources. NutCracker3 (Bos and Markert, 2005) is a system based on logical representation and automatic theorem proving, but utilizes only WordNet (Fellbaum, 1998) as a lexical knowledge resource. Therefore, we provide our open-source textualentailment system, BIUTEE. Our system provides state-of-the-art linguistic analysis tools and exploits various types of manually built and automatically acquired knowledge resources, including lexical, lexical-syntactic and syntactic rewrite rules. Furthermore, the system components, including preprocessing utilities, knowledge resources, and even the steps of the inference algorithm, are modular, an</context>
</contexts>
<marker>Bos, Markert, 2005</marker>
<rawString>Johan Bos and Katja Markert. 2005. Recognising textual entailment with logical inference. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Clark</author>
<author>Phil Harrison</author>
</authors>
<title>Blue-lite: a knowledge-based lexical entailment system for rte6.</title>
<date>2010</date>
<booktitle>In Proceedings of TAC.</booktitle>
<contexts>
<context position="2075" citStr="Clark and Harrison, 2010" startWordPosition="312" endWordPosition="316">ables (e.g., “X is employed by Y”) and has to find text fragments from which this template, with variables replaced by proper entities, can be inferred. In Summarization, a good summary should be inferred from the 1www.cs.biu.ac.il/˜nlp/downloads/biutee 73 given text, and, in addition, should not contain duplicated information, i.e., sentences which can be inferred from other sentences in the summary. Detecting these inferences can be performed by an RTE system. Since first introduced, several approaches have been proposed for this task, ranging from shallow lexical similarity methods (e.g., (Clark and Harrison, 2010; MacKinlay and Baldwin, 2009)), to complex linguistically-motivated methods, which incorporate extensive linguistic analysis (syntactic parsing, coreference resolution, semantic role labelling, etc.) and a rich inventory of linguistic and world-knowledge resources (e.g., (Iftene, 2008; de Salvo Braz et al., 2005; Bar-Haim et al., 2007)). Building such complex systems requires substantial development efforts, which might become a barrier for new-comers to RTE research. Thus, flexible and extensible publicly available RTE systems are expected to significantly facilitate research in this field. </context>
</contexts>
<marker>Clark, Harrison, 2010</marker>
<rawString>Peter Clark and Phil Harrison. 2010. Blue-lite: a knowledge-based lexical entailment system for rte6. In Proceedings of TAC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Oren Glickman</author>
<author>Bernardo Magnini</author>
</authors>
<title>The pascal recognising textual entailment challenge.</title>
<date>2006</date>
<journal>In Quionero-Candela, J.; Dagan, I.; Magnini, B.; d’Alch-Buc, F. (Eds.) Machine Learning Challenges. Lecture Notes in Computer Science.</journal>
<contexts>
<context position="1267" citStr="Dagan et al., 2006" startWordPosition="184" endWordPosition="187"> researchers of end applications, that can benefit from generic textual inference, and (2) RTE researchers, who can integrate their novel algorithms and knowledge resources into our system, saving the time and effort of developing a complete RTE system from scratch. Notable assistance for these researchers is provided by a visual tracing tool, by which researchers can refine and “debug” their knowledge resources and inference components. 1 Introduction Recognizing Textual Entailment (RTE) is the task of identifying, given two text fragments, whether one of them can be inferred from the other (Dagan et al., 2006). This task generalizes a common problem that arises in many tasks at the semantic level of NLP. For example, in Information Extraction (IE), a system may be given a template with variables (e.g., “X is employed by Y”) and has to find text fragments from which this template, with variables replaced by proper entities, can be inferred. In Summarization, a good summary should be inferred from the 1www.cs.biu.ac.il/˜nlp/downloads/biutee 73 given text, and, in addition, should not contain duplicated information, i.e., sentences which can be inferred from other sentences in the summary. Detecting t</context>
</contexts>
<marker>Dagan, Glickman, Magnini, 2006</marker>
<rawString>Ido Dagan, Oren Glickman, and Bernardo Magnini. 2006. The pascal recognising textual entailment challenge. In Quionero-Candela, J.; Dagan, I.; Magnini, B.; d’Alch-Buc, F. (Eds.) Machine Learning Challenges. Lecture Notes in Computer Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rodrigo de Salvo Braz</author>
<author>Roxana Girju</author>
<author>Vasin Punyakanok</author>
<author>Dan Roth</author>
<author>Mark Sammons</author>
</authors>
<title>An inference model for semantic entailment in natural language.</title>
<date>2005</date>
<booktitle>In Proceedings of AAAI.</booktitle>
<contexts>
<context position="2389" citStr="Braz et al., 2005" startWordPosition="353" endWordPosition="356">rmation, i.e., sentences which can be inferred from other sentences in the summary. Detecting these inferences can be performed by an RTE system. Since first introduced, several approaches have been proposed for this task, ranging from shallow lexical similarity methods (e.g., (Clark and Harrison, 2010; MacKinlay and Baldwin, 2009)), to complex linguistically-motivated methods, which incorporate extensive linguistic analysis (syntactic parsing, coreference resolution, semantic role labelling, etc.) and a rich inventory of linguistic and world-knowledge resources (e.g., (Iftene, 2008; de Salvo Braz et al., 2005; Bar-Haim et al., 2007)). Building such complex systems requires substantial development efforts, which might become a barrier for new-comers to RTE research. Thus, flexible and extensible publicly available RTE systems are expected to significantly facilitate research in this field. More concretely, two major research communities would benefit from a publicly available RTE system: 1. Higher-level application developers, who would use an RTE system to solve inference tasks in their application. RTE systems for this type of researchers should be adaptable for the application specific data: the</context>
</contexts>
<marker>Braz, Girju, Punyakanok, Roth, Sammons, 2005</marker>
<rawString>Rodrigo de Salvo Braz, Roxana Girju, Vasin Punyakanok, Dan Roth, and Mark Sammons. 2005. An inference model for semantic entailment in natural language. In Proceedings of AAAI.</rawString>
</citation>
<citation valid="true">
<title>WordNet An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>The MIT Press,</publisher>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet An Electronic Lexical Database. The MIT Press, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Trond Grenager</author>
<author>Christopher Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by gibbs sampling.</title>
<date>2005</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="10307" citStr="Finkel et al., 2005" startWordPosition="1573" endWordPosition="1576">costs of the transformations from which it is composed, i.e.: n n n c(O) °_ c(oi) = w · f(oi) = w · f(oi) i=1 i=1 i=1 (1) If the proof cost is below a threshold b, then the system concludes that T entails H. The complete description of the cost model, as well as the method for learning the parameters w and b is described in (Stern and Dagan, 2011). 2.2 System flow The BIUTEE system flow (Figure 1) starts with preprocessing of the text and the hypothesis. BIUTEE provides state-of-the-art pre-processing utilities: Easy-First parser (Goldberg and Elhadad, 2010), Stanford named-entity-recognizer (Finkel et al., 2005) and ArkRef coreference resolver (Haghighi and Klein, 2009), as well as utilities for sentencesplitting and numerical-normalizations. In addition, BIUTEE supports integration of users’ own utilities by simply implementing the appropriate interfaces. Entailment recognition begins with a global processing phase in which inference related computations that are not part of the proof are performed. Annotating the negation indicators and their scope in the text and hypothesis is an example of such calculation. Next, the system constructs a proof which is a sequence of transformations that transform </context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Jenny Rose Finkel, Trond Grenager, and Christopher Manning. 2005. Incorporating non-local information into information extraction systems by gibbs sampling. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Goldberg</author>
<author>Michael Elhadad</author>
</authors>
<title>An efficient algorithm for easy-first non-directional dependency parsing.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL.</booktitle>
<contexts>
<context position="10251" citStr="Goldberg and Elhadad, 2010" startWordPosition="1567" endWordPosition="1570">ined as w · f(oi). The proof cost is defined as the sum of the costs of the transformations from which it is composed, i.e.: n n n c(O) °_ c(oi) = w · f(oi) = w · f(oi) i=1 i=1 i=1 (1) If the proof cost is below a threshold b, then the system concludes that T entails H. The complete description of the cost model, as well as the method for learning the parameters w and b is described in (Stern and Dagan, 2011). 2.2 System flow The BIUTEE system flow (Figure 1) starts with preprocessing of the text and the hypothesis. BIUTEE provides state-of-the-art pre-processing utilities: Easy-First parser (Goldberg and Elhadad, 2010), Stanford named-entity-recognizer (Finkel et al., 2005) and ArkRef coreference resolver (Haghighi and Klein, 2009), as well as utilities for sentencesplitting and numerical-normalizations. In addition, BIUTEE supports integration of users’ own utilities by simply implementing the appropriate interfaces. Entailment recognition begins with a global processing phase in which inference related computations that are not part of the proof are performed. Annotating the negation indicators and their scope in the text and hypothesis is an example of such calculation. Next, the system constructs a proo</context>
</contexts>
<marker>Goldberg, Elhadad, 2010</marker>
<rawString>Yoav Goldberg and Michael Elhadad. 2010. An efficient algorithm for easy-first non-directional dependency parsing. In Proceedings of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Dan Klein</author>
</authors>
<title>Simple coreference resolution with rich syntactic and semantic features.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="10366" citStr="Haghighi and Klein, 2009" startWordPosition="1581" endWordPosition="1584">, i.e.: n n n c(O) °_ c(oi) = w · f(oi) = w · f(oi) i=1 i=1 i=1 (1) If the proof cost is below a threshold b, then the system concludes that T entails H. The complete description of the cost model, as well as the method for learning the parameters w and b is described in (Stern and Dagan, 2011). 2.2 System flow The BIUTEE system flow (Figure 1) starts with preprocessing of the text and the hypothesis. BIUTEE provides state-of-the-art pre-processing utilities: Easy-First parser (Goldberg and Elhadad, 2010), Stanford named-entity-recognizer (Finkel et al., 2005) and ArkRef coreference resolver (Haghighi and Klein, 2009), as well as utilities for sentencesplitting and numerical-normalizations. In addition, BIUTEE supports integration of users’ own utilities by simply implementing the appropriate interfaces. Entailment recognition begins with a global processing phase in which inference related computations that are not part of the proof are performed. Annotating the negation indicators and their scope in the text and hypothesis is an example of such calculation. Next, the system constructs a proof which is a sequence of transformations that transform the text into the hypothesis. Finding such a proof is a seq</context>
</contexts>
<marker>Haghighi, Klein, 2009</marker>
<rawString>Aria Haghighi and Dan Klein. 2009. Simple coreference resolution with rich syntactic and semantic features. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adrian Iftene</author>
</authors>
<title>Uaic participation at rte4.</title>
<date>2008</date>
<booktitle>In Proceedings of TAC.</booktitle>
<contexts>
<context position="2361" citStr="Iftene, 2008" startWordPosition="349" endWordPosition="350">contain duplicated information, i.e., sentences which can be inferred from other sentences in the summary. Detecting these inferences can be performed by an RTE system. Since first introduced, several approaches have been proposed for this task, ranging from shallow lexical similarity methods (e.g., (Clark and Harrison, 2010; MacKinlay and Baldwin, 2009)), to complex linguistically-motivated methods, which incorporate extensive linguistic analysis (syntactic parsing, coreference resolution, semantic role labelling, etc.) and a rich inventory of linguistic and world-knowledge resources (e.g., (Iftene, 2008; de Salvo Braz et al., 2005; Bar-Haim et al., 2007)). Building such complex systems requires substantial development efforts, which might become a barrier for new-comers to RTE research. Thus, flexible and extensible publicly available RTE systems are expected to significantly facilitate research in this field. More concretely, two major research communities would benefit from a publicly available RTE system: 1. Higher-level application developers, who would use an RTE system to solve inference tasks in their application. RTE systems for this type of researchers should be adaptable for the ap</context>
</contexts>
<marker>Iftene, 2008</marker>
<rawString>Adrian Iftene. 2008. Uaic participation at rte4. In Proceedings of TAC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL.</booktitle>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra</location>
<contexts>
<context position="3954" citStr="Koehn et al., 2007" startWordPosition="579" endWordPosition="582"> pages 73–78, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics their novel research components into an existing open-source system. Such research efforts might include developing knowledge resources, developing inference components for specific phenomena such as temporal inference, or extending RTE to different languages. A flexible and extensible RTE system is expected to encourage researchers to create and share their textual-inference components. A good example from another research area is the Moses system for Statistical Machine Translation (SMT) (Koehn et al., 2007), which provides the core SMT components while being extended with new research components by a large scientific community. Yet, until now rather few and quite limited RTE systems were made publicly available. Moreover, these systems are restricted in the types of knowledge resources which they can utilize, and in the scope of their inference algorithms. For example, EDITS2 (Kouylekov and Negri, 2010) is a distancebased RTE system, which can exploit only lexical knowledge resources. NutCracker3 (Bos and Markert, 2005) is a system based on logical representation and automatic theorem proving, b</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Milen Kouylekov</author>
<author>Matteo Negri</author>
</authors>
<title>An opensource package for recognizing textual entailment.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL Demo.</booktitle>
<contexts>
<context position="4358" citStr="Kouylekov and Negri, 2010" startWordPosition="643" endWordPosition="646">stem is expected to encourage researchers to create and share their textual-inference components. A good example from another research area is the Moses system for Statistical Machine Translation (SMT) (Koehn et al., 2007), which provides the core SMT components while being extended with new research components by a large scientific community. Yet, until now rather few and quite limited RTE systems were made publicly available. Moreover, these systems are restricted in the types of knowledge resources which they can utilize, and in the scope of their inference algorithms. For example, EDITS2 (Kouylekov and Negri, 2010) is a distancebased RTE system, which can exploit only lexical knowledge resources. NutCracker3 (Bos and Markert, 2005) is a system based on logical representation and automatic theorem proving, but utilizes only WordNet (Fellbaum, 1998) as a lexical knowledge resource. Therefore, we provide our open-source textualentailment system, BIUTEE. Our system provides state-of-the-art linguistic analysis tools and exploits various types of manually built and automatically acquired knowledge resources, including lexical, lexical-syntactic and syntactic rewrite rules. Furthermore, the system components,</context>
</contexts>
<marker>Kouylekov, Negri, 2010</marker>
<rawString>Milen Kouylekov and Matteo Negri. 2010. An opensource package for recognizing textual entailment. In Proceedings of ACL Demo.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew MacKinlay</author>
<author>Timothy Baldwin</author>
</authors>
<title>A baseline approach to the rte5 search pilot.</title>
<date>2009</date>
<booktitle>In Proceedings of TAC.</booktitle>
<contexts>
<context position="2105" citStr="MacKinlay and Baldwin, 2009" startWordPosition="317" endWordPosition="320">d by Y”) and has to find text fragments from which this template, with variables replaced by proper entities, can be inferred. In Summarization, a good summary should be inferred from the 1www.cs.biu.ac.il/˜nlp/downloads/biutee 73 given text, and, in addition, should not contain duplicated information, i.e., sentences which can be inferred from other sentences in the summary. Detecting these inferences can be performed by an RTE system. Since first introduced, several approaches have been proposed for this task, ranging from shallow lexical similarity methods (e.g., (Clark and Harrison, 2010; MacKinlay and Baldwin, 2009)), to complex linguistically-motivated methods, which incorporate extensive linguistic analysis (syntactic parsing, coreference resolution, semantic role labelling, etc.) and a rich inventory of linguistic and world-knowledge resources (e.g., (Iftene, 2008; de Salvo Braz et al., 2005; Bar-Haim et al., 2007)). Building such complex systems requires substantial development efforts, which might become a barrier for new-comers to RTE research. Thus, flexible and extensible publicly available RTE systems are expected to significantly facilitate research in this field. More concretely, two major res</context>
</contexts>
<marker>MacKinlay, Baldwin, 2009</marker>
<rawString>Andrew MacKinlay and Timothy Baldwin. 2009. A baseline approach to the rte5 search pilot. In Proceedings of TAC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Asher Stern</author>
<author>Ido Dagan</author>
</authors>
<title>A confidence model for syntactically-motivated entailment proofs.</title>
<date>2011</date>
<booktitle>In Proceedings of RANLP.</booktitle>
<contexts>
<context position="8747" citStr="Stern and Dagan, 2011" startWordPosition="1306" endWordPosition="1309">, 2007). Coreference relations are utilized via coreferencesubstitution transformations: one mention of an entity is replaced by another mention of the same entity, based on coreference relations. In the above example the system could apply such a transformation to substitute “him” with “Charles G. Taylor”. Since applications of entailment rules and coreference substitutions are yet, in most cases, insufficient in transforming T into H, our system allows on-the-fly transformations. These transformations include insertions of missing nodes, flipping partsof-speech, moving sub-trees, etc. (see (Stern and Dagan, 2011) for a complete list of these transformations). Since these transformations are not justified by given knowledge resources, we use linguisticallymotivated features to estimate their validity. For example, for on-the-fly lexical insertions we consider as features the named-entity annotation of the inserted word, and its probability estimation according to a unigram language model, which yields lower costs for more frequent words. Given a (T,H) pair, the system applies a search algorithm (Stern et al., 2012) to find a proof O = (o1,o2,... on) that transforms T into H. For each proof step oi the </context>
<context position="10036" citStr="Stern and Dagan, 2011" startWordPosition="1537" endWordPosition="1540">e system uses a weightvector w, which is learned in the training phase. In addition, each transformation oi is represented by a feature vector f(oi) which characterizes the transformation. The cost c(oi) is defined as w · f(oi). The proof cost is defined as the sum of the costs of the transformations from which it is composed, i.e.: n n n c(O) °_ c(oi) = w · f(oi) = w · f(oi) i=1 i=1 i=1 (1) If the proof cost is below a threshold b, then the system concludes that T entails H. The complete description of the cost model, as well as the method for learning the parameters w and b is described in (Stern and Dagan, 2011). 2.2 System flow The BIUTEE system flow (Figure 1) starts with preprocessing of the text and the hypothesis. BIUTEE provides state-of-the-art pre-processing utilities: Easy-First parser (Goldberg and Elhadad, 2010), Stanford named-entity-recognizer (Finkel et al., 2005) and ArkRef coreference resolver (Haghighi and Klein, 2009), as well as utilities for sentencesplitting and numerical-normalizations. In addition, BIUTEE supports integration of users’ own utilities by simply implementing the appropriate interfaces. Entailment recognition begins with a global processing phase in which inference</context>
<context position="12520" citStr="Stern and Dagan, 2011" startWordPosition="1921" endWordPosition="1924">ually, the search algorithm finds a (approximately) lowest cost proof. This cost is normalized as a score between 0 and 1, and returned as output. Training the cost model parameters w and b (see subsection 2.1) is performed by a linear learn75 Figure 1: System architecture RTE Median Best BIUTEE challenge RTE-6 33.72 48.01 49.09 RTE-7 39.89 48.00 42.93 Table 1: Performance (F1) of BIUTEE on RTE challenges, compared to other systems participated in these challenges. Median and Best indicate the median score and the highest score of all submissions, respectively. ing algorithm, as described in (Stern and Dagan, 2011). We use a Logistic-Regression learning algorithm, but, similar to other components, alternative learning-algorithms can be integrated easily by implementing an appropriate interface. 2.3 Experimental results BIUTEE’s performance on the last two RTE challenges (Bentivogli et al., 2011; Bentivogli et al., 2010) is presented in Table 1: BIUTEE is better than the median of all submitted results, and in RTE-6 it outperforms all other systems. 3 Visual Tracing Tool As a complex system, the final score provided as output, as well as the system’s detailed logging information, do not expose all the de</context>
</contexts>
<marker>Stern, Dagan, 2011</marker>
<rawString>Asher Stern and Ido Dagan. 2011. A confidence model for syntactically-motivated entailment proofs. In Proceedings of RANLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Asher Stern</author>
<author>Roni Stern</author>
<author>Ido Dagan</author>
<author>Ariel Felner</author>
</authors>
<title>Efficient search for transformation-based inference.</title>
<date>2012</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="9258" citStr="Stern et al., 2012" startWordPosition="1384" endWordPosition="1387">de insertions of missing nodes, flipping partsof-speech, moving sub-trees, etc. (see (Stern and Dagan, 2011) for a complete list of these transformations). Since these transformations are not justified by given knowledge resources, we use linguisticallymotivated features to estimate their validity. For example, for on-the-fly lexical insertions we consider as features the named-entity annotation of the inserted word, and its probability estimation according to a unigram language model, which yields lower costs for more frequent words. Given a (T,H) pair, the system applies a search algorithm (Stern et al., 2012) to find a proof O = (o1,o2,... on) that transforms T into H. For each proof step oi the system calculates a cost c(oi). This cost is defined as follows: the system uses a weightvector w, which is learned in the training phase. In addition, each transformation oi is represented by a feature vector f(oi) which characterizes the transformation. The cost c(oi) is defined as w · f(oi). The proof cost is defined as the sum of the costs of the transformations from which it is composed, i.e.: n n n c(O) °_ c(oi) = w · f(oi) = w · f(oi) i=1 i=1 i=1 (1) If the proof cost is below a threshold b, then th</context>
</contexts>
<marker>Stern, Stern, Dagan, Felner, 2012</marker>
<rawString>Asher Stern, Roni Stern, Ido Dagan, and Ariel Felner. 2012. Efficient search for transformation-based inference. In Proceedings of ACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>