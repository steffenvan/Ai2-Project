<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9945625">
k-valued Non-Associative Lambek Categorial Grammars
are not Learnable from Strings
</title>
<author confidence="0.739506">
Denis B´echet
</author>
<affiliation confidence="0.34157">
INRIA, IRISA
</affiliation>
<address confidence="0.4152045">
Campus Universitaire de Beaulieu
Avenue du G´en´eral Leclerc
35042 Rennes Cedex
France
</address>
<email confidence="0.984059">
Denis.Bechet@irisa.fr
</email>
<author confidence="0.656916">
Annie Foret
</author>
<affiliation confidence="0.552947">
Universit´e de Rennes1, IRISA
</affiliation>
<address confidence="0.50716425">
Campus Universitaire de Beaulieu
Avenue du G´en´eral Leclerc
35042 Rennes Cedex
France
</address>
<email confidence="0.994465">
Annie.Foret@irisa.fr
</email>
<sectionHeader confidence="0.998543" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999921583333333">
This paper is concerned with learning cat-
egorial grammars in Gold’s model. In
contrast to k-valued classical categorial
grammars, k-valued Lambek grammars
are not learnable from strings. This re-
sult was shown for several variants but
the question was left open for the weak-
est one, the non-associative variant NL.
We show that the class of rigid and k-
valued NL grammars is unlearnable from
strings, for each k; this result is obtained
by a specific construction of a limit point
in the considered class, that does not use
product operator.
Another interest of our construction is that
it provides limit points for the whole hier-
archy of Lambek grammars, including the
recent pregroup grammars.
Such a result aims at clarifying the pos-
sible directions for future learning algo-
rithms: it expresses the difficulty of learn-
ing categorial grammars from strings and
the need for an adequate structure on ex-
amples.
</bodyText>
<sectionHeader confidence="0.999503" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999767372881356">
Categorial grammars (Bar-Hillel, 1953) and Lam-
bek grammars (Lambek, 1958; Lambek, 1961) have
been studied in the field of natural language process-
ing. They are well adapted to learning perspectives
since they are completely lexicalized and an actual
way of research is to determine the sub-classes of
such grammars that remain learnable in the sense of
Gold (Gold, 1967).
We recall that learning here consists to define an
algorithm on a finite set of sentences that converge
to obtain a grammar in the class that generates the
examples. Let G be a class of grammars, that we
wish to learn from positive examples. Formally, let
L(G) denote the language associated with grammar
G, and let V be a given alphabet, a learning algorith-
m is a function O from finite sets of words in V* to
G, such that for all G E G with L(G) =&lt; ei &gt;iEN
there exists a grammar G&apos; E G and there exists no E
N such that: bn &gt; no O({ei, ... , en}) = G&apos; E G
with L(G&apos;) = L(G).
After pessimistic unlearnability results in (Gold,
1967), learnability of non trivial classes has been
proved in (Angluin, 1980) and (Shinohara, 1990).
Recent works from (Kanazawa, 1998) and (Nicolas,
1999) following (Buszkowski and Penn, 1990) have
answered the problem for different sub-classes of
classical categorial grammars (we recall that the w-
hole class of classical categorial grammars is equiv-
alent to context free grammars; the same holds for
the class of Lambek grammars (Pentus, 1993) that is
thus not learnable in Gold’s model).
The extension of such results for Lambek gram-
mars is an interesting challenge that is addressed by
works on logic types from (Dudau-Sofronie et al.,
2001) (these grammars enjoy a direct link with Mon-
tague semantics), learning from structures in (Re-
tor and Bonato, september 2001), complexity results
from (Florˆencio, 2002) or unlearnability results from
(Foret and Le Nir, 2002a; Foret and Le Nir, 2002b);
this result was shown for several variants but the
question was left open for the basic variant, the non-
associative variant NL.
In this paper, we consider the following question:
is the non-associative variant NL of k-valued Lam-
bek grammars learnable from strings; we answer by
constructing a limit point for this class. Our con-
struction is in some sense more complex than those
for the other systems since they do not directly trans-
late as limit point in the more restricted system NL.
The paper is organized as follows. Section 2
gives some background knowledge on three main
aspects: Lambek categorial grammars ; learning in
Gold’s model ; Lambek pregroup grammars that we
use later as models in some proofs. Section 3 then
presents our main result on NL (NL denotes non-
associative Lambek grammars not allowing empty
sequence): after a construction overview, we dis-
cuss some corollaries and then provide the details
of proof. Section 4 concludes.
</bodyText>
<sectionHeader confidence="0.998132" genericHeader="introduction">
2 Background
</sectionHeader>
<subsectionHeader confidence="0.998611">
2.1 Categorial Grammars
</subsectionHeader>
<bodyText confidence="0.92171965">
The reader not familiar with Lambek Calculus and
its non-associative version will find nice presenta-
tion in the first ones written by Lambek (Lambek,
1958; Lambek, 1961) or more recently in (Kandul-
ski, 1988; Aarts and Trautwein, 1995; Buszkowski,
1997; Moortgat, 1997; de Groote, 1999; de Groote
and Lamarche, 2002).
The types Tp, or formulas, are generated
from a set of primitive types Pr, or atom-
ic formulas by three binary connectives “ / ”
(over), “ \ ” (under) and “•” (product): Tp ::=
Pr  |Tp \ Tp  |Tp / Tp  |Tp •Tp. As a logical sys-
tem, we use a Gentzen-style sequent presentation. A
sequent   A is composed of a sequence of for-
mulas  which is the antecedent configuration and a
succedent formula A.
Let  be a fixed alphabet. A categorial grammar
over  is a finite relation G between  and Tp. If
&lt; c, A &gt; G, we say that G assigns A to c, and we
write G : c  A.
</bodyText>
<subsubsectionHeader confidence="0.59571">
2.1.1 Lambek Derivation L
</subsubsectionHeader>
<bodyText confidence="0.984370333333333">
The relation L is the smallest relation  between
Tp+ and Tp, such that for all ,   Tp+, ,  
Tp and for all A, B, C  Tp:
</bodyText>
<equation confidence="0.987685454545455">
, A,   C   A
(Cut)
, ,  C
  A , B,   C
/L
, B / A, ,   C
  A ,B,  C
\L
,,A \ B,  C
, A, B,  C
,A • B,  C ,   A • B
</equation>
<bodyText confidence="0.9993225">
We write L for the Lambek calculus with empty
antecedents (left part of the sequent).
</bodyText>
<subsubsectionHeader confidence="0.533924">
2.1.2 Non-associative Lambek Derivation NL
</subsubsectionHeader>
<bodyText confidence="0.9984897">
In the Gentzen presentation, the derivability rela-
tion of NL holds between a term in S and a formula
in Tp, where the term language is S ::= Tp|(S, S).
Terms in S are also called G-terms. A sequent is a
pair (, A)  S × Tp. The notation [] repre-
sents a G-term with a distinguished occurrence of 
(with the same position in premise and conclusion
of a rule). The relation NL is the smallest relation
 between S and Tp, such that for all ,   S and
for all A, B, C  Tp:
</bodyText>
<equation confidence="0.931806333333333">
[A]  C   A
(Cut)
[]  C
  A [B]  C
/L
[(B / A,)]  C
  A [B]  C
\L
[(, A \ B)]  C
  A   B
•R
(, )  (A • B)
</equation>
<bodyText confidence="0.992049">
We write NL for the non-associative Lambek
calculus with empty antecedents (left part of the se-
quent).
</bodyText>
<figure confidence="0.9752679">
A  A (Id)
,A  B
/R
  B / A
A,  B
\R
  A \ B
  A   B
•L
•R
A  A (Id)
(, A)  B
/R
  B / A
(A, )  B
\R
  A \ B
[(A, B)]  C •L
[A • B]  C
2.1.3 Notes
</figure>
<bodyText confidence="0.9734672">
Cut elimination. We recall that cut rule can be e-
liminated in L and NL: every derivable sequent
has a cut-free derivation.
Type order. The order ord(A) of a type A of L or
NL is defined by:
</bodyText>
<equation confidence="0.8609892">
ord(A) = 0 if A is a primitive type
ord(C1 / C2) = max(ord(C1), ord(C2) + 1)
ord(C1 \ C2) = max(ord(C1) + 1, ord(C2))
ord(C1 • C2) = max(ord(C1), ord(C2))
2.1.4 Language.
</equation>
<bodyText confidence="0.951476416666667">
Let G be a categorial grammar over . G gen-
erates a string c1 ... cn  + iff there are types
A1,... , An  Tp such that: G : ci  Ai (1  i 
n) and A1,... ,An L S. The language of G,
written LL(G) is the set of strings generated by G.
We define similarly LL(G), LNL(G) and LNL(G)
replacing L by L, NL and NL in the sequent
where the types are parenthesized in some way.
2.1.5 Notation.
In some sections, we may write simply  instead
of L, L, NL or NL . We may simply write
L(G) accordingly.
</bodyText>
<subsectionHeader confidence="0.543211">
2.1.6 Rigid and k-valued Grammars.
</subsectionHeader>
<bodyText confidence="0.9988738">
Categorial grammars that assign at most k types
to each symbol in the alphabet are called k-valued
grammars; 1-valued grammars are also called rigid
grammars.
Example 1 Let 1 = {John, Mary, likes} and let
Pr = {S, N} for sentences and nouns respectively.
Let G1 = {John  N, Mary  N, likes 
N \ (S / N)}. We get (John likes Mary) 
LNL(G1) since ((N, N \ (S / N)), N) NL S.
G1 is a rigid (or 1-valued) grammar.
</bodyText>
<subsectionHeader confidence="0.99975">
2.2 Learning and Limit Points
</subsectionHeader>
<bodyText confidence="0.999828">
We now recall some useful definitions and known
properties on learning.
</bodyText>
<subsubsectionHeader confidence="0.663428">
2.2.1 Limit Points
</subsubsectionHeader>
<bodyText confidence="0.804211">
A class CL of languages has a limit point iff there
exists an infinite sequence &lt; Ln &gt;nEN of lan-
guages in CL and a language L  CL such that:
L0 C L1 ... C ... CLnC... and L=UnENLn
(L is a limit point of CL).
</bodyText>
<subsubsectionHeader confidence="0.645223">
2.2.2 Limit Points Imply Unlearnability
</subsubsectionHeader>
<bodyText confidence="0.999972">
The following property is important for our pur-
pose. If the languages of the grammars in a class G
have a limit point then the class G is unlearnable. 1
</bodyText>
<subsectionHeader confidence="0.999094">
2.3 Some Useful Models
</subsectionHeader>
<bodyText confidence="0.9999885">
For ease of proof, in next section we use two kinds
of models that we now recall: free groups and pre-
groups introduced recently by (Lambek, 1999) as an
alternative of existing type grammars.
</bodyText>
<subsectionHeader confidence="0.788207">
2.3.1 Free Group Interpretation.
</subsectionHeader>
<bodyText confidence="0.996185">
Let FG denote the free group with generators Pr,
operation · and with neutral element 1. We associate
with each formula C of L or NL, an element in FG
written [C] as follows:
</bodyText>
<equation confidence="0.99804425">
[A] = A if A is a primitive type
[C1 \ C2] = [C1]−1 ·[C2]
[C1 / C2] = [C1] · [C2]−1
[C1 • C2] = [C1] · [C2]
</equation>
<bodyText confidence="0.905457666666667">
We extend the notation to sequents by: [C1, C2, ... , Cn] = [C1] · [C2] · ··· · [Cn]
The following property states that FG is a model for
L (hence for NL): if  L C then [] =FG [C]
</bodyText>
<subsectionHeader confidence="0.814464">
2.3.2 Free Pregroup Interpretation
</subsectionHeader>
<bodyText confidence="0.909838222222222">
Pregroup. A pregroup is a structure (P, 
, ·, l, r,1) such that (P,, ·,1) is a partially ordered
monoid2 and l, r are two unary operations on P
that satisfy for all a  P ala  1  aal and
aar  1  ara.
Free pregroup. Let (P,) be an ordered set of
primitive types, P( ) = {p(i)  |p  P, i  Z} is
the set of atomic types and T(P,&lt;) = (P( )�� =
{p(i1)
</bodyText>
<equation confidence="0.988088">
1 · · · p(in)
</equation>
<bodyText confidence="0.9055095">
n |0  k  n,pk  P and ik  Z}
is the set of types. For X and Y  T(P,&lt;), X  Y
iif this relation is deductible in the following system
where p, q  P, n, k  Z and X, Y, Z  T(P,&lt;):
</bodyText>
<footnote confidence="0.813356">
1This implies that the class has infinite elasticity. A class
</footnote>
<construct confidence="0.620276875">
CL of languages has infinite elasticity iff 3 &lt; ei &gt;iN
sentences 3 &lt; Li &gt;iN languages in CL `di E N :
ei E� Li and fe1,... , en} C Ln+1 .
2We briefly recall that a monoid is a structure &lt; M, ·, 1 &gt;,
such that · is associative and has a neutral element 1 (`dx E
M : 1 · x = x · 1 = x). A partially ordered monoid is a
monoid M, ·, 1) with a partial order &lt; that satisfies `da, b, c:
a &lt; b =�. c · a &lt; c · b and a · c &lt; b · c.
</construct>
<equation confidence="0.977088666666667">
X &lt; Y Y &lt; Z
X &lt; X (Id)
X &lt; Z
(INDL) (INDR)
Xq(k)Y &lt; Z X &lt; Y q(k)Z
q &lt; p if k is even, and p &lt; q if k is odd
</equation>
<bodyText confidence="0.947398538461538">
This construction, proposed by Buskowski, de-
fines a pregroup that extends &lt; on primitive types
P to T(P,&lt;),.
Cut elimination. As for L and NL, cut rule can be
eliminated: every derivable inequality has a cut-free
derivation.
Simple free pregroup. A simple free pregroup is
a free pregroup where the order on primitive type is
equality.
Free pregroup interpretation. Let FP denotes
the simple free pregroup with Pr as primitive types.
We associate with each formula C of L or NL, an
element in FP written [C] as follows:
</bodyText>
<equation confidence="0.98256525">
[A] = A if A is a primitive type
[C1 \ C2] = [C1]r[C2]
[C1 / C2] = [C1][C2]l
[C1 • C2] = [C1][C2]
</equation>
<bodyText confidence="0.97818675">
We extend the notation to sequents by:
[A1,... , An] = [A1] ··· [An]
The following property states that FP is a model for
L (hence for NL): if  �_L C then [] &lt;FP [C].
</bodyText>
<sectionHeader confidence="0.999388" genericHeader="method">
3 Limit Point Construction
</sectionHeader>
<subsectionHeader confidence="0.999997">
3.1 Method overview and remarks
</subsectionHeader>
<bodyText confidence="0.8316562">
Form of grammars. We define grammars Gn
where A, B, Dn and En are complex types and S
is the main type of each grammar:
Gn = {a H A / B; b H Dn; c H En \ S}
Some key points.
</bodyText>
<listItem confidence="0.777293">
• We prove that {akbc  |0 &lt; k &lt; n} C_ L(Gn)
using the following properties:
</listItem>
<footnote confidence="0.895735666666667">
3Left and right adjoints are defined by (p(n))l = p(n−1),
(p(n))r = p(n+1), (XY )l = Y lXl and (XY )r = Y rXr. We
write p for p(0).
</footnote>
<table confidence="0.551467625">
B A (but AVB)
(A / B, Dn+1) �- Dn
Dn En
En En+1
we get:
bc E L(Gn) since Dn �- En
if w E L(Gn) then aw E L(Gn+1) since
(A / B, Dn+1) �- Dn �- En �- En+1
</table>
<listItem confidence="0.99111575">
• The condition A V B is crucial for strict-
ness of language inclusion. In particular:
(A / B, A) I f A, where A = D0
• This construction is in some sense more com-
plex than those for the other systems (Foret and
Le Nir, 2002a; Foret and Le Nir, 2002b) since
they do not directly translate as limit points in
the more restricted system NL.
</listItem>
<subsectionHeader confidence="0.970146">
3.2 Definition and Main Results
Definitions of Rigid grammars Gn and G*
</subsectionHeader>
<bodyText confidence="0.6883535">
Definition 1 Let p, q, S, three primitive types. We
define:
</bodyText>
<equation confidence="0.9650715">
A = D0 = E0 = q / (p \ q)
B = p
Dn+1 = (A / B) \ Dn
En+1 = (A / A) \ En
{ aHA/B=(q/(p\q))/p
bHDn
c H En \ S
Let G* = {a H (p / p) b H p c H (p \ S)}
</equation>
<bodyText confidence="0.4736225">
Main Properties
Proposition 1 (language description)
</bodyText>
<listItem confidence="0.737700666666667">
• L(Gn) = {akbc  |0 &lt; k &lt; n}
• L(G*) = {akbc  |0 &lt; k}.
From this construction we get a limit point and the
following result.
Proposition 2 (NL-non-learnability) The class of
languages of rigid (or k-valued for an arbitrary
k) non-associative Lambek grammars (not allowing
empty sequence and without product) admits a limit
point; the class ofrigid (or k-valuedfor an arbitrary
k) non-associative Lambek grammars (not allowing
empty sequence and without product) is not learn-
able from strings.
</listItem>
<figure confidence="0.855975132352941">
XY&lt;Z
Xp(n)p(n+1)Y &lt; Z (AL)
Xp(k)Y &lt; Z
X &lt; Y Z
X &lt; Yp(n+1)p(n)Z (AR)
X &lt; Yp(k)Z
(Cut)
Let Gn =
}
((a · · · (a(a
b)) · · · )c) and prove the following se-
A) ··· ),··· ),
((A / B) \ ··· \ ((A / B) \
A) ··· ) \ S)) NL S
((A / A) \ ··· \ ((A / A) \
� 1� �
pprqqr
� 1� �
k n
Proof: Suppose n(w)  S, using pregroups
[n(w)]  S. We can write w = akbakcak for
some k, k&apos;, k&apos;&apos;, such that:
[n(w)] = qqlppl
�
1� �
qqlp qqlppl
� 1� �
k
prqqrS qqlppl
�
1� �
k
ppr
�1��
n
 S
p ppl
�1��
k
prS ppl
�1��
k
3.3 Details of proof for Gn
Lemma
{akbc  |0  k  n}  L(Gn)
Proof: It is relatively easy to see that for 0 
k  n, akbc  L(Gn). We have to consider
1�
k
quent in NL:
(a···(a
[x / (y \ x)] = [x]([y]r[x])l = [x][x]l[y]
[x / (x \ x)] = [x]([x]r[x])l = [x][x]l[x] = [x]
Thus, we get:
[A] = [D0] = [E0] = [q / (p \ q)] = qqlp
[B] = p
[A / B] = [A][B]l = qqlppl
[Dn+1] = [(A / B)]r[Dn] = pprqqr
�
1� �
n+1
[En+1] = [(A / A) \ En] = [A][A]lqqlp = qqlp
qqlp
n
c
� � 1
n
Models of NL
</figure>
<bodyText confidence="0.739888142857143">
For the converse, (for technical reasons and to
ease proofs) we use both free group and free pre-
group models of NL since a sequent is valid in NL
only if its interpretation is valid in both models.
Translation in free groups
The free group translation for the types of Gn is:
[p] = p, [q] = q, [S] = S
</bodyText>
<equation confidence="0.967171272727273">
[x / y] = [x] · [y]−1
[x \ y] = [x]−1 · [y]
[x • y] = [x] · [y]
Type-raising disappears by translation:
[x / (y \ x)] = [x]· ([y]−1 ·[x])−1 = [y]
Thus, we get:
[A] = [D0] = [E0] = [q / (p \ q)] = p
[B] = p
[A / B] = [A] · [B]−1 = pp−1 = 1
[Dn+1] = [(A / B) \ Dn] = [Dn] = [D0] = p
[En+1] = [(A / A) \ En] = [En] = [E0] = p
</equation>
<bodyText confidence="0.696983666666667">
Translation in free pregroups
The free pregroup translation for the types of Gn is:
[p] = p, [q] = q, [S] = S
</bodyText>
<equation confidence="0.97130175">
[x \ y] = [x]r[y]
[y / x] = [y][x]l
[x • y] = [x][y]
Type-raising translation:
</equation>
<bodyText confidence="0.917398875">
Proof: Let n denote the type assignment by the
rigid grammar Gn. Suppose n(w)  S, using free
groups [n(w)] = S;
- This entails that w has exactly one occurrence of
c (since [n(c)] = p−1S and the other type images
are either 1 or p)
- Then, this entails that w has exactly one occur-
rence of b on the left of the occurrence of c (since
</bodyText>
<equation confidence="0.876633666666667">
[n(c)] = p−1S, [n(b)] = p and [n(a)] = 1)
Lemma
L(Gn)  {akbc  |0  k}
For q = 1, we get ppl
�1��
k
</equation>
<bodyText confidence="0.900895">
and it yields p ppl
</bodyText>
<equation confidence="0.5342935">
�1��
k
</equation>
<bodyText confidence="0.993491">
We now discuss possible deductions (note that
pplppl ··· ppl = ppl):
</bodyText>
<listItem confidence="0.9430622">
• if k&apos; and k&apos;&apos; = 0: ppplprSppl  S impossible.
• if k&apos; = 0 and k&apos;&apos; = 0: ppplprS  S impossible.
• if k&apos; = 0 and k&apos;&apos; = 0: pprSppl  S impossible.
• if k&apos; = k&apos;&apos; = 0: w  {akbc  |0  k}
(Final) Lemma
</listItem>
<equation confidence="0.85887625">
L(Gn)  {akbc  |0  k  n}
� �� 1
prS ppl
�1��
k
 S.
( ((A / B), ... , ((A / B),
1�
k
b
� � 1
Lemma
L(Gn)  {akbakcak; 0  k, 0  k&apos;,0  k&apos;&apos;}
Proof: Suppose n(w) S S, using pregroups
[n(w)] &lt; S. We can write w = akbc for some
k, such that :
[n(w)] = qqlppl

 
k
</equation>
<bodyText confidence="0.9495555">
We use the following property (its proof is in Ap-
pendix A) that entails that 0 &lt; k &lt; n.
</bodyText>
<equation confidence="0.767281">
(Auxiliary) Lemma:
if (1) X, Y, qqlp, prqqr, S &lt; S
where X E {ppl, qql} and Y E {qqr, ppr}
 (2) nbalt(Xqql) &lt; nbalt(qqrY )
then
(2bis) nbalt(Xppl) &lt; nbalt(pprY)
</equation>
<bodyText confidence="0.999832666666667">
where nbalt counts the alternations of p’s and
q’s sequences (forgetting/dropping their expo-
nents).
</bodyText>
<subsectionHeader confidence="0.997452">
3.4 Details of proof for G
</subsectionHeader>
<bodyText confidence="0.823199">
Lemma
</bodyText>
<equation confidence="0.904979">
{akbc  |0 &lt; k} C L(G)
Proof: As with Gn, it is relatively easy to see that
for k &gt; 0, akbc E L(G). We have to consider
((a • • • (a(a b)) • • • )c) and prove the following se-

k
quent in NL:
(((p / p), . . . , ((p / p),
   p) ... ),(p \ S)) SNL S
k
Lemma
L(G) C {akbc  |0 &lt; k}
</equation>
<bodyText confidence="0.999266571428571">
Proof: Like for w E Gn, due to free groups, a
word of L(G) has exactly one occurrence of c and
one occurrence of b on the left of c (since [(c)] =
p−&apos;S, [(b)] = p and [(a)] = 1).
Suppose w = akbak�cak&amp;quot; a similar discussion as
for Gn in pregroups, gives k = k = 0, hence the
result
</bodyText>
<subsectionHeader confidence="0.997465">
3.5 Non-learnability of a Hierarchy of Systems
</subsectionHeader>
<bodyText confidence="0.874902727272727">
An interest point of this construction: It provides a
limit point for the whole hierarchy of Lambek gram-
mars, and pregroup grammars.
Limit point for pregroups
The translation [] of Gn gives a limit point for the
simple free pregroup since for i E {*, 0, 1, 2,... }:
i(w) SNL S iff w E LNL(Gi) by definition;
i(w) SNL S implies [i(w)] &lt; S by models;
[i(w)] &lt; S implies w E LNL(Gi) from above.
Limit point for NL
The same grammars and languages work since for
</bodyText>
<equation confidence="0.82356475">
i E {*, 0, 1, 2,... }:
i(w) SNL S iff [i(w)] &lt; S from above;
i(w) SNL S implies i(w) SNLo S by hierarchy ;
i(w) SNLo S implies [i(w)] &lt; S by models.
</equation>
<bodyText confidence="0.9305135">
Limit point for L and L
The same grammars and languages work since for
</bodyText>
<equation confidence="0.9647322">
i E {*, 0, 1, 2,... } :
i(w) SNL S iff [i(w)] &lt; S from above;
i(w) SNL S implies i(w) SL S using hierarchy ;
i(w) SL S implies i(w) SLo S using hierarchy ;
i(w) SLo S implies [i(w)] &lt; S by models.
</equation>
<bodyText confidence="0.6954585">
To summarize: w E LNL(Gi) iff [i(w)] &lt; S iff
w E LNLo(Gi) iff w E LL(Gi) iff w E LL(Gi)
</bodyText>
<sectionHeader confidence="0.985014" genericHeader="method">
4 Conclusion and Remarks
</sectionHeader>
<bodyText confidence="0.9999119">
Lambek grammars. We have shown that with-
out empty sequence, non-associative Lambek rigid
grammars are not learnable from strings. With this
result, the whole landscape of Lambek-like rigid
grammars (or k-valued for an arbitrary k) is now de-
scribed as for the learnability question (from strings,
in Gold’s model).
Non-learnability for subclasses. Our construct is
of order 5 and does not use the product operator.
Thus, we have the following corollaries:
</bodyText>
<listItem confidence="0.9950695">
• Restricted connectives: k-valued NL, NL, L and
L grammars without product are not learnable
from strings.
• Restricted type order:
</listItem>
<bodyText confidence="0.992648625">
- k-valued NL, NL, L and L grammars (with-
out product) with types not greater than or-
der 5 are not learnable from strings4.
- k-valued free pregroup grammars with type-
s not greater than order 1 are not learnable
from strings5.
The learnability question may still be raised for NL
grammars of order lower than 5.
</bodyText>
<footnote confidence="0.869217">
4Even less for some systems. For example in Lo, all En
collapse to A
5The order of a type pi1
1 · · · pikk is the maximum of the ab-
solute value of the exponents: max(|i1|, ... , |ik|).
</footnote>
<table confidence="0.41051775">
pprqqr qqlpprqqrS

 
n
</table>
<bodyText confidence="0.997620095238095">
Special learnable subclasses. Note that howev-
er, we get specific learnable subclasses of k-valued
grammars when we consider NL, NLO, L or Lo
without product and we bind the order of types in
grammars to be not greater than 1. This holds for all
variants of Lambek grammars as a corollary of the
equivalence between generation in classical catego-
rial grammars and in Lambek systems for grammars
with such product-free types (Buszkowski, 2001).
Restriction on types. An interesting perspective
for learnability results might be to introduce reason-
able restrictions on types. From what we have seen,
the order of type alone (order 1 excepted) does not
seem to be an appropriate measure in that context.
Structured examples. These results also indicate
the necessity of using structured examples as input
of learning algorithms. What intermediate structure
should then be taken as a good alternative between
insufficient structures (strings) and linguistic unreal-
istic structures (full proof tree structures) remains an
interesting challenge.
</bodyText>
<sectionHeader confidence="0.999156" genericHeader="method">
References
</sectionHeader>
<reference confidence="0.999714720930233">
E. Aarts and K. Trautwein. 1995. Non-associative Lam-
bek categorial grammar in polynomial time. Mathe-
matical Logic Quaterly, 41:476–484.
Dana Angluin. 1980. Inductive inference of formal lan-
guages from positive data. Information and Control,
45:117–135.
Y. Bar-Hillel. 1953. A quasi arithmetical notation for
syntactic description. Language, 29:47–58.
Wojciech Buszkowski and Gerald Penn. 1990. Categori-
al grammars determined from linguistic data by unifi-
cation. Studia Logica, 49:431–454.
W. Buszkowski. 1997. Mathematical linguistics and
proof theory. In van Benthem and ter Meulen (van
Benthem and ter Meulen, 1997), chapter 12, pages
683–736.
Wojciech Buszkowski. 2001. Lambek grammars based
on pregroups. In Philippe de Groote, Glyn Morill, and
Christian Retor´e, editors, Logical aspects of computa-
tional linguistics: 4th International Conference, LACL
2001, Le Croisic, France, June 2001, volume 2099.
Springer-Verlag.
Philippe de Groote and Franc¸ois Lamarche. 2002. Clas-
sical non-associative lambek calculus. Studia Logica,
71.1 (2).
Philippe de Groote. 1999. Non-associative Lambek cal-
culus in polynomial time. In 8th Workshop on theo-
rem proving with analytic tableaux and related meth-
ods, number 1617 in Lecture Notes in Artificial Intel-
ligence. Springer-Verlag, March.
Dudau-Sofronie, Tellier, and Tommasi. 2001. Learning
categorial grammars from semantic types. In 13th Am-
sterdam Colloquium.
C. Costa Florˆencio. 2002. Consistent Identification in
the Limit of the Class k-valued is NP-hard. In LACL.
Annie Foret and Yannick Le Nir. 2002a. Lambek rigid
grammars are not learnable from strings. In COL-
ING’2002, 19th International Conference on Compu-
tational Linguistics, Taipei, Taiwan.
Annie Foret and Yannick Le Nir. 2002b. On limit points
for some variants of rigid lambek grammars. In IC-
GI’2002, the 6th International Colloquium on Gram-
matical Inference, number 2484 in Lecture Notes in
Artificial Intelligence. Springer-Verlag.
E.M. Gold. 1967. Language identification in the limit.
Information and control, 10:447–474.
Makoto Kanazawa. 1998. Learnable classes of catego-
rial grammars. Studies in Logic, Language and In-
formation. FoLLI &amp; CSLI. distributed by Cambridge
University Press.
Maciej Kandulski. 1988. The non-associative lambek
calculus. In W. Marciszewski W. Buszkowski and
J. Van Bentem, editors, Categorial Grammar, pages
141–152. Benjamins, Amsterdam.
Joachim Lambek. 1958. The mathematics of sentence
structure. American mathematical monthly, 65:154–
169.
Joachim Lambek. 1961. On the calculus of syntactic
types. In Roman Jakobson, editor, Structure of lan-
guage and its mathematical aspects, pages 166–178.
American Mathematical Society.
J. Lambek. 1999. Type grammars revisited. In Alain
Lecomte, Franc¸ois Lamarche, and Guy Perrier, ed-
itors, Logical aspects of computational linguistics:
Second International Conference, LACL ’97, Nancy,
France, September 22–24, 1997; selected papers, vol-
ume 1582. Springer-Verlag.
Michael Moortgat. 1997. Categorial type logic. In
van Benthem and ter Meulen (van Benthem and ter
Meulen, 1997), chapter 2, pages 93–177.
Jacques Nicolas. 1999. Grammatical inference as u-
nification. Rapport de Recherche RR-3632, INRIA.
http://www.inria.fr/RRRT/publications-eng.html.
Mati Pentus. 1993. Lambek grammars are context-free.
In Logic in Computer Science. IEEE Computer Soci-
ety Press.
Christian Retor´e and Roberto Bonato. september
2001. Learning rigid lambek grammars and minimal-
ist grammars from struc tured sentences. Third work-
shop on Learning Language in Logic, Strasbourg.
T. Shinohara. 1990. Inductive inference from positive
data is powerful. In The 1990 Workshop on Compu-
tational Learning Theory, pages 97–110, San Mateo,
California. Morgan Kaufmann.
J. van Benthem and A. ter Meulen, editors. 1997. Hand-
book ofLogic and Language. North-Holland Elsevier,
Amsterdam.
</reference>
<sectionHeader confidence="0.489878" genericHeader="method">
Appendix A. Proof of Auxiliary Lemma
</sectionHeader>
<figure confidence="0.401066833333333">
(Auxiliary) Lemma:
if (1) XY qqlpprqqrS &lt; S
where X E {ppl, qql} and Y E {qqr, ppr}
�(2) nbalt(Xqql) &lt; nbalt(qqrY )
then
(2bis) nbalt(Xppl) &lt; nbalt(pprY)
</figure>
<bodyText confidence="0.990926">
where nbalt counts the alternations of p’s and
q’s sequences (forgetting/dropping their expo-
nents).
Proof: By induction on derivations in Gentzen
style presentation of free pregroups (without Cut).
Suppose XYZS &lt; S
</bodyText>
<equation confidence="0.9039755">
{ X E {ppl, qql}
Y E {qqr,ppr}
Z E {(qqlpprqqr), (qqlqqr), (qqr), 1}
� nbalt(Xqql) &lt; nbalt(qqrY )
We show that
nbalt(Xppl) &lt; nbalt(pprY)
</equation>
<bodyText confidence="0.997879">
The last inference rule can only be (AL)
</bodyText>
<listItem confidence="0.801218">
• Case (AL) on X: The antecedent is similar with
</listItem>
<bodyText confidence="0.9385118">
X instead of X, where X is obtained from X by
insertion (in fact inserting qlq in the middle of qql
as the replacement of qql with qqlqql or similarly
with p instead of q).
- By such an insertion: (i) nbalt(Xqql) =
nbalt(Xqql) (similar for p).
- By induction hypothesis: (ii) nbalt(Xqql) &lt;
nbalt(qqrY ) (similar for p).
- Therefore from (i) (ii): nbalt(Xqql) &lt;
nbalt(qqrY ) (similar for p).
</bodyText>
<listItem confidence="0.900979875">
• Case (AL) on Y : The antecedent is XY ZS &lt;
S where Y is obtained from Y  by inser-
tion (in fact insertion of ppr or qqr), such
that Y  E {ppr, qqr}. Therefore the induc-
tion applies nbalt(Xqql) &lt; nbalt(qqrY ) and
nbalt(qqrY ) &gt; nbalt(qqrY ) (similar for p)
hence the result.
• Case (AL) on Z ( Z non empty):
</listItem>
<equation confidence="0.81762">
- if Z = (qqlpprqqr) the antecedent is
XY ZS &lt; S, where Z = qqlqqr.
</equation>
<bodyText confidence="0.909716333333333">
- if Z = (qqlqqr) the antecedent is XY ZS &lt;
S, where Z = qqr ;
- if Z = (qqr) the antecedent is XY ZS &lt; S,
where Z = c.
In all three cases the hypothesis applies to XY Z
and gives the relationship between X and Y .
</bodyText>
<listItem confidence="0.7640155">
• case (AL) between X and Y : Either X = Xqql
and Y = qqrY  or X = Xppl and Y = pprY .
</listItem>
<bodyText confidence="0.732594">
In the q case, the last inference step is the intro-
duction of qlq:
</bodyText>
<equation confidence="0.8487415">
X&amp;quot;qqrY &amp;quot;ZSS
Xqql
1. Y �
X
</equation>
<bodyText confidence="0.99961">
We now detail the q case. The antecedent can be
rewritten as XY ZS &lt; S and we have: (i)
</bodyText>
<equation confidence="0.981812473684211">
nbalt(Xqql) = nbalt(Xqqlqql)
= nbalt(Xqql)
nbalt(Xppl) = nbalt(Xqqlppl)
= 1 + nbalt(Xqql)
nbalt(qqrY ) = nbalt(qqrqqrY )
= nbalt(qqrY )
nbalt(pprY) = nbalt(pprqqrY )
= 1 + nbalt(qqrY )
We can apply the induction hypothesis to
XY ZS &lt; S and get (ii):
nbalt(Xqql) &lt; nbalt(qqrY )
Finally from (i) (ii) and the induction hypothesis:
nbalt(Xqql) = nbalt(Xqql)
&lt; nbalt(qqrY )
nbalt(Xppl) = 1 + nbalt(Xqql)
&lt; 1 + nbalt(qqrY )
= 1 + nbalt(qqrqqrY )
= 1 + nbalt(qqrY )
= nbalt(pprY)
</equation>
<bodyText confidence="0.971411">
The second case with p instead of q is similar.
where
</bodyText>
<figure confidence="0.8661635">
g
qr Y Y;
Y
ZSS
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.094861">
<title confidence="0.9993545">Non-Associative Lambek Categorial Grammars are not Learnable from Strings</title>
<author confidence="0.995048">Denis B´echet</author>
<affiliation confidence="0.927616">INRIA, IRISA Campus Universitaire de Beaulieu</affiliation>
<address confidence="0.719724666666667">Avenue du G´en´eral Leclerc 35042 Rennes Cedex France</address>
<email confidence="0.474776">Denis.Bechet@irisa.fr</email>
<author confidence="0.839582">Annie Foret</author>
<affiliation confidence="0.8305835">Universit´e de Rennes1, IRISA Campus Universitaire de Beaulieu</affiliation>
<address confidence="0.784510333333333">Avenue du G´en´eral Leclerc 35042 Rennes Cedex France</address>
<email confidence="0.857553">Annie.Foret@irisa.fr</email>
<abstract confidence="0.99410032">This paper is concerned with learning categorial grammars in Gold’s model. In to classical categorial Lambek grammars are not learnable from strings. This result was shown for several variants but the question was left open for the weakone, the non-associative variant show that the class of rigid and is unlearnable from for each this result is obtained by a specific construction of a limit point in the considered class, that does not use product operator. Another interest of our construction is that it provides limit points for the whole hierarchy of Lambek grammars, including the recent pregroup grammars. Such a result aims at clarifying the possible directions for future learning algorithms: it expresses the difficulty of learning categorial grammars from strings and the need for an adequate structure on examples.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Aarts</author>
<author>K Trautwein</author>
</authors>
<title>Non-associative Lambek categorial grammar in polynomial time.</title>
<date>1995</date>
<booktitle>Mathematical Logic Quaterly,</booktitle>
<pages>41--476</pages>
<contexts>
<context position="4421" citStr="Aarts and Trautwein, 1995" startWordPosition="724" endWordPosition="727">ategorial grammars ; learning in Gold’s model ; Lambek pregroup grammars that we use later as models in some proofs. Section 3 then presents our main result on NL (NL denotes nonassociative Lambek grammars not allowing empty sequence): after a construction overview, we discuss some corollaries and then provide the details of proof. Section 4 concludes. 2 Background 2.1 Categorial Grammars The reader not familiar with Lambek Calculus and its non-associative version will find nice presentation in the first ones written by Lambek (Lambek, 1958; Lambek, 1961) or more recently in (Kandulski, 1988; Aarts and Trautwein, 1995; Buszkowski, 1997; Moortgat, 1997; de Groote, 1999; de Groote and Lamarche, 2002). The types Tp, or formulas, are generated from a set of primitive types Pr, or atomic formulas by three binary connectives “ / ” (over), “ \ ” (under) and “•” (product): Tp ::= Pr |Tp \ Tp |Tp / Tp |Tp •Tp. As a logical system, we use a Gentzen-style sequent presentation. A sequent   A is composed of a sequence of formulas  which is the antecedent configuration and a succedent formula A. Let  be a fixed alphabet. A categorial grammar over  is a finite relation G between  and Tp. If &lt; c, A &gt; G, we say that</context>
</contexts>
<marker>Aarts, Trautwein, 1995</marker>
<rawString>E. Aarts and K. Trautwein. 1995. Non-associative Lambek categorial grammar in polynomial time. Mathematical Logic Quaterly, 41:476–484.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dana Angluin</author>
</authors>
<title>Inductive inference of formal languages from positive data. Information and Control,</title>
<date>1980</date>
<pages>45--117</pages>
<contexts>
<context position="2379" citStr="Angluin, 1980" startWordPosition="395" endWordPosition="396">at converge to obtain a grammar in the class that generates the examples. Let G be a class of grammars, that we wish to learn from positive examples. Formally, let L(G) denote the language associated with grammar G, and let V be a given alphabet, a learning algorithm is a function O from finite sets of words in V* to G, such that for all G E G with L(G) =&lt; ei &gt;iEN there exists a grammar G&apos; E G and there exists no E N such that: bn &gt; no O({ei, ... , en}) = G&apos; E G with L(G&apos;) = L(G). After pessimistic unlearnability results in (Gold, 1967), learnability of non trivial classes has been proved in (Angluin, 1980) and (Shinohara, 1990). Recent works from (Kanazawa, 1998) and (Nicolas, 1999) following (Buszkowski and Penn, 1990) have answered the problem for different sub-classes of classical categorial grammars (we recall that the whole class of classical categorial grammars is equivalent to context free grammars; the same holds for the class of Lambek grammars (Pentus, 1993) that is thus not learnable in Gold’s model). The extension of such results for Lambek grammars is an interesting challenge that is addressed by works on logic types from (Dudau-Sofronie et al., 2001) (these grammars enjoy a direct</context>
</contexts>
<marker>Angluin, 1980</marker>
<rawString>Dana Angluin. 1980. Inductive inference of formal languages from positive data. Information and Control, 45:117–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Bar-Hillel</author>
</authors>
<title>A quasi arithmetical notation for syntactic description.</title>
<date>1953</date>
<journal>Language,</journal>
<pages>29--47</pages>
<contexts>
<context position="1339" citStr="Bar-Hillel, 1953" startWordPosition="202" endWordPosition="203">d and kvalued NL grammars is unlearnable from strings, for each k; this result is obtained by a specific construction of a limit point in the considered class, that does not use product operator. Another interest of our construction is that it provides limit points for the whole hierarchy of Lambek grammars, including the recent pregroup grammars. Such a result aims at clarifying the possible directions for future learning algorithms: it expresses the difficulty of learning categorial grammars from strings and the need for an adequate structure on examples. 1 Introduction Categorial grammars (Bar-Hillel, 1953) and Lambek grammars (Lambek, 1958; Lambek, 1961) have been studied in the field of natural language processing. They are well adapted to learning perspectives since they are completely lexicalized and an actual way of research is to determine the sub-classes of such grammars that remain learnable in the sense of Gold (Gold, 1967). We recall that learning here consists to define an algorithm on a finite set of sentences that converge to obtain a grammar in the class that generates the examples. Let G be a class of grammars, that we wish to learn from positive examples. Formally, let L(G) denot</context>
</contexts>
<marker>Bar-Hillel, 1953</marker>
<rawString>Y. Bar-Hillel. 1953. A quasi arithmetical notation for syntactic description. Language, 29:47–58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wojciech Buszkowski</author>
<author>Gerald Penn</author>
</authors>
<title>Categorial grammars determined from linguistic data by unification. Studia Logica,</title>
<date>1990</date>
<pages>49--431</pages>
<contexts>
<context position="2495" citStr="Buszkowski and Penn, 1990" startWordPosition="409" endWordPosition="412">that we wish to learn from positive examples. Formally, let L(G) denote the language associated with grammar G, and let V be a given alphabet, a learning algorithm is a function O from finite sets of words in V* to G, such that for all G E G with L(G) =&lt; ei &gt;iEN there exists a grammar G&apos; E G and there exists no E N such that: bn &gt; no O({ei, ... , en}) = G&apos; E G with L(G&apos;) = L(G). After pessimistic unlearnability results in (Gold, 1967), learnability of non trivial classes has been proved in (Angluin, 1980) and (Shinohara, 1990). Recent works from (Kanazawa, 1998) and (Nicolas, 1999) following (Buszkowski and Penn, 1990) have answered the problem for different sub-classes of classical categorial grammars (we recall that the whole class of classical categorial grammars is equivalent to context free grammars; the same holds for the class of Lambek grammars (Pentus, 1993) that is thus not learnable in Gold’s model). The extension of such results for Lambek grammars is an interesting challenge that is addressed by works on logic types from (Dudau-Sofronie et al., 2001) (these grammars enjoy a direct link with Montague semantics), learning from structures in (Retor and Bonato, september 2001), complexity results f</context>
</contexts>
<marker>Buszkowski, Penn, 1990</marker>
<rawString>Wojciech Buszkowski and Gerald Penn. 1990. Categorial grammars determined from linguistic data by unification. Studia Logica, 49:431–454.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Buszkowski</author>
</authors>
<title>Mathematical linguistics and proof theory.</title>
<date>1997</date>
<booktitle>In van Benthem and ter Meulen (van Benthem and ter Meulen,</booktitle>
<pages>683--736</pages>
<contexts>
<context position="4439" citStr="Buszkowski, 1997" startWordPosition="728" endWordPosition="729">ng in Gold’s model ; Lambek pregroup grammars that we use later as models in some proofs. Section 3 then presents our main result on NL (NL denotes nonassociative Lambek grammars not allowing empty sequence): after a construction overview, we discuss some corollaries and then provide the details of proof. Section 4 concludes. 2 Background 2.1 Categorial Grammars The reader not familiar with Lambek Calculus and its non-associative version will find nice presentation in the first ones written by Lambek (Lambek, 1958; Lambek, 1961) or more recently in (Kandulski, 1988; Aarts and Trautwein, 1995; Buszkowski, 1997; Moortgat, 1997; de Groote, 1999; de Groote and Lamarche, 2002). The types Tp, or formulas, are generated from a set of primitive types Pr, or atomic formulas by three binary connectives “ / ” (over), “ \ ” (under) and “•” (product): Tp ::= Pr |Tp \ Tp |Tp / Tp |Tp •Tp. As a logical system, we use a Gentzen-style sequent presentation. A sequent   A is composed of a sequence of formulas  which is the antecedent configuration and a succedent formula A. Let  be a fixed alphabet. A categorial grammar over  is a finite relation G between  and Tp. If &lt; c, A &gt; G, we say that G assigns A to c,</context>
</contexts>
<marker>Buszkowski, 1997</marker>
<rawString>W. Buszkowski. 1997. Mathematical linguistics and proof theory. In van Benthem and ter Meulen (van Benthem and ter Meulen, 1997), chapter 12, pages 683–736.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wojciech Buszkowski</author>
</authors>
<title>Lambek grammars based on pregroups.</title>
<date>2001</date>
<booktitle>Logical aspects of computational linguistics: 4th International Conference, LACL 2001, Le Croisic,</booktitle>
<volume>volume</volume>
<editor>In Philippe de Groote, Glyn Morill, and Christian Retor´e, editors,</editor>
<publisher>Springer-Verlag.</publisher>
<location>France,</location>
<contexts>
<context position="19069" citStr="Buszkowski, 2001" startWordPosition="3914" endWordPosition="3915">mple in Lo, all En collapse to A 5The order of a type pi1 1 · · · pikk is the maximum of the absolute value of the exponents: max(|i1|, ... , |ik|). pprqqr qqlpprqqrS    n Special learnable subclasses. Note that however, we get specific learnable subclasses of k-valued grammars when we consider NL, NLO, L or Lo without product and we bind the order of types in grammars to be not greater than 1. This holds for all variants of Lambek grammars as a corollary of the equivalence between generation in classical categorial grammars and in Lambek systems for grammars with such product-free types (Buszkowski, 2001). Restriction on types. An interesting perspective for learnability results might be to introduce reasonable restrictions on types. From what we have seen, the order of type alone (order 1 excepted) does not seem to be an appropriate measure in that context. Structured examples. These results also indicate the necessity of using structured examples as input of learning algorithms. What intermediate structure should then be taken as a good alternative between insufficient structures (strings) and linguistic unrealistic structures (full proof tree structures) remains an interesting challenge. Re</context>
</contexts>
<marker>Buszkowski, 2001</marker>
<rawString>Wojciech Buszkowski. 2001. Lambek grammars based on pregroups. In Philippe de Groote, Glyn Morill, and Christian Retor´e, editors, Logical aspects of computational linguistics: 4th International Conference, LACL 2001, Le Croisic, France, June 2001, volume 2099. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philippe de Groote</author>
<author>Franc¸ois Lamarche</author>
</authors>
<title>Classical non-associative lambek calculus.</title>
<date>2002</date>
<journal>Studia Logica,</journal>
<volume>1</volume>
<issue>2</issue>
<marker>de Groote, Lamarche, 2002</marker>
<rawString>Philippe de Groote and Franc¸ois Lamarche. 2002. Classical non-associative lambek calculus. Studia Logica, 71.1 (2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philippe de Groote</author>
</authors>
<title>Non-associative Lambek calculus in polynomial time.</title>
<date>1999</date>
<booktitle>In 8th Workshop on theorem proving with analytic tableaux and related methods, number 1617 in Lecture Notes in Artificial Intelligence.</booktitle>
<publisher>Springer-Verlag,</publisher>
<marker>de Groote, 1999</marker>
<rawString>Philippe de Groote. 1999. Non-associative Lambek calculus in polynomial time. In 8th Workshop on theorem proving with analytic tableaux and related methods, number 1617 in Lecture Notes in Artificial Intelligence. Springer-Verlag, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tellier Dudau-Sofronie</author>
<author>Tommasi</author>
</authors>
<title>Learning categorial grammars from semantic types.</title>
<date>2001</date>
<booktitle>In 13th Amsterdam Colloquium.</booktitle>
<marker>Dudau-Sofronie, Tommasi, 2001</marker>
<rawString>Dudau-Sofronie, Tellier, and Tommasi. 2001. Learning categorial grammars from semantic types. In 13th Amsterdam Colloquium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Costa Florˆencio</author>
</authors>
<title>Consistent Identification in the Limit of the Class k-valued is NP-hard.</title>
<date>2002</date>
<booktitle>In LACL.</booktitle>
<marker>Florˆencio, 2002</marker>
<rawString>C. Costa Florˆencio. 2002. Consistent Identification in the Limit of the Class k-valued is NP-hard. In LACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Annie Foret</author>
<author>Yannick Le Nir</author>
</authors>
<title>Lambek rigid grammars are not learnable from strings.</title>
<date>2002</date>
<booktitle>In COLING’2002, 19th International Conference on Computational Linguistics,</booktitle>
<location>Taipei, Taiwan.</location>
<marker>Foret, Le Nir, 2002</marker>
<rawString>Annie Foret and Yannick Le Nir. 2002a. Lambek rigid grammars are not learnable from strings. In COLING’2002, 19th International Conference on Computational Linguistics, Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Annie Foret</author>
<author>Yannick Le Nir</author>
</authors>
<title>On limit points for some variants of rigid lambek grammars.</title>
<date>2002</date>
<booktitle>In ICGI’2002, the 6th International Colloquium on Grammatical Inference, number 2484 in Lecture Notes in Artificial Intelligence.</booktitle>
<publisher>Springer-Verlag.</publisher>
<marker>Foret, Le Nir, 2002</marker>
<rawString>Annie Foret and Yannick Le Nir. 2002b. On limit points for some variants of rigid lambek grammars. In ICGI’2002, the 6th International Colloquium on Grammatical Inference, number 2484 in Lecture Notes in Artificial Intelligence. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E M Gold</author>
</authors>
<title>Language identification in the limit. Information and control,</title>
<date>1967</date>
<pages>10--447</pages>
<contexts>
<context position="1671" citStr="Gold, 1967" startWordPosition="257" endWordPosition="258">p grammars. Such a result aims at clarifying the possible directions for future learning algorithms: it expresses the difficulty of learning categorial grammars from strings and the need for an adequate structure on examples. 1 Introduction Categorial grammars (Bar-Hillel, 1953) and Lambek grammars (Lambek, 1958; Lambek, 1961) have been studied in the field of natural language processing. They are well adapted to learning perspectives since they are completely lexicalized and an actual way of research is to determine the sub-classes of such grammars that remain learnable in the sense of Gold (Gold, 1967). We recall that learning here consists to define an algorithm on a finite set of sentences that converge to obtain a grammar in the class that generates the examples. Let G be a class of grammars, that we wish to learn from positive examples. Formally, let L(G) denote the language associated with grammar G, and let V be a given alphabet, a learning algorithm is a function O from finite sets of words in V* to G, such that for all G E G with L(G) =&lt; ei &gt;iEN there exists a grammar G&apos; E G and there exists no E N such that: bn &gt; no O({ei, ... , en}) = G&apos; E G with L(G&apos;) = L(G). After pessimistic un</context>
</contexts>
<marker>Gold, 1967</marker>
<rawString>E.M. Gold. 1967. Language identification in the limit. Information and control, 10:447–474.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Makoto Kanazawa</author>
</authors>
<title>Learnable classes of categorial grammars. Studies in Logic, Language and Information. FoLLI &amp; CSLI. distributed by Cambridge</title>
<date>1998</date>
<publisher>University Press.</publisher>
<contexts>
<context position="2437" citStr="Kanazawa, 1998" startWordPosition="403" endWordPosition="404">es the examples. Let G be a class of grammars, that we wish to learn from positive examples. Formally, let L(G) denote the language associated with grammar G, and let V be a given alphabet, a learning algorithm is a function O from finite sets of words in V* to G, such that for all G E G with L(G) =&lt; ei &gt;iEN there exists a grammar G&apos; E G and there exists no E N such that: bn &gt; no O({ei, ... , en}) = G&apos; E G with L(G&apos;) = L(G). After pessimistic unlearnability results in (Gold, 1967), learnability of non trivial classes has been proved in (Angluin, 1980) and (Shinohara, 1990). Recent works from (Kanazawa, 1998) and (Nicolas, 1999) following (Buszkowski and Penn, 1990) have answered the problem for different sub-classes of classical categorial grammars (we recall that the whole class of classical categorial grammars is equivalent to context free grammars; the same holds for the class of Lambek grammars (Pentus, 1993) that is thus not learnable in Gold’s model). The extension of such results for Lambek grammars is an interesting challenge that is addressed by works on logic types from (Dudau-Sofronie et al., 2001) (these grammars enjoy a direct link with Montague semantics), learning from structures i</context>
</contexts>
<marker>Kanazawa, 1998</marker>
<rawString>Makoto Kanazawa. 1998. Learnable classes of categorial grammars. Studies in Logic, Language and Information. FoLLI &amp; CSLI. distributed by Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maciej Kandulski</author>
</authors>
<title>The non-associative lambek calculus.</title>
<date>1988</date>
<booktitle>Categorial Grammar,</booktitle>
<pages>141--152</pages>
<editor>In W. Marciszewski W. Buszkowski and J. Van Bentem, editors,</editor>
<publisher>Benjamins,</publisher>
<location>Amsterdam.</location>
<contexts>
<context position="4394" citStr="Kandulski, 1988" startWordPosition="721" endWordPosition="723">aspects: Lambek categorial grammars ; learning in Gold’s model ; Lambek pregroup grammars that we use later as models in some proofs. Section 3 then presents our main result on NL (NL denotes nonassociative Lambek grammars not allowing empty sequence): after a construction overview, we discuss some corollaries and then provide the details of proof. Section 4 concludes. 2 Background 2.1 Categorial Grammars The reader not familiar with Lambek Calculus and its non-associative version will find nice presentation in the first ones written by Lambek (Lambek, 1958; Lambek, 1961) or more recently in (Kandulski, 1988; Aarts and Trautwein, 1995; Buszkowski, 1997; Moortgat, 1997; de Groote, 1999; de Groote and Lamarche, 2002). The types Tp, or formulas, are generated from a set of primitive types Pr, or atomic formulas by three binary connectives “ / ” (over), “ \ ” (under) and “•” (product): Tp ::= Pr |Tp \ Tp |Tp / Tp |Tp •Tp. As a logical system, we use a Gentzen-style sequent presentation. A sequent   A is composed of a sequence of formulas  which is the antecedent configuration and a succedent formula A. Let  be a fixed alphabet. A categorial grammar over  is a finite relation G between  and Tp. </context>
</contexts>
<marker>Kandulski, 1988</marker>
<rawString>Maciej Kandulski. 1988. The non-associative lambek calculus. In W. Marciszewski W. Buszkowski and J. Van Bentem, editors, Categorial Grammar, pages 141–152. Benjamins, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joachim Lambek</author>
</authors>
<title>The mathematics of sentence structure. American mathematical monthly,</title>
<date>1958</date>
<pages>65--154</pages>
<contexts>
<context position="1373" citStr="Lambek, 1958" startWordPosition="208" endWordPosition="209">e from strings, for each k; this result is obtained by a specific construction of a limit point in the considered class, that does not use product operator. Another interest of our construction is that it provides limit points for the whole hierarchy of Lambek grammars, including the recent pregroup grammars. Such a result aims at clarifying the possible directions for future learning algorithms: it expresses the difficulty of learning categorial grammars from strings and the need for an adequate structure on examples. 1 Introduction Categorial grammars (Bar-Hillel, 1953) and Lambek grammars (Lambek, 1958; Lambek, 1961) have been studied in the field of natural language processing. They are well adapted to learning perspectives since they are completely lexicalized and an actual way of research is to determine the sub-classes of such grammars that remain learnable in the sense of Gold (Gold, 1967). We recall that learning here consists to define an algorithm on a finite set of sentences that converge to obtain a grammar in the class that generates the examples. Let G be a class of grammars, that we wish to learn from positive examples. Formally, let L(G) denote the language associated with gra</context>
<context position="4342" citStr="Lambek, 1958" startWordPosition="713" endWordPosition="714"> 2 gives some background knowledge on three main aspects: Lambek categorial grammars ; learning in Gold’s model ; Lambek pregroup grammars that we use later as models in some proofs. Section 3 then presents our main result on NL (NL denotes nonassociative Lambek grammars not allowing empty sequence): after a construction overview, we discuss some corollaries and then provide the details of proof. Section 4 concludes. 2 Background 2.1 Categorial Grammars The reader not familiar with Lambek Calculus and its non-associative version will find nice presentation in the first ones written by Lambek (Lambek, 1958; Lambek, 1961) or more recently in (Kandulski, 1988; Aarts and Trautwein, 1995; Buszkowski, 1997; Moortgat, 1997; de Groote, 1999; de Groote and Lamarche, 2002). The types Tp, or formulas, are generated from a set of primitive types Pr, or atomic formulas by three binary connectives “ / ” (over), “ \ ” (under) and “•” (product): Tp ::= Pr |Tp \ Tp |Tp / Tp |Tp •Tp. As a logical system, we use a Gentzen-style sequent presentation. A sequent   A is composed of a sequence of formulas  which is the antecedent configuration and a succedent formula A. Let  be a fixed alphabet. A categorial gram</context>
</contexts>
<marker>Lambek, 1958</marker>
<rawString>Joachim Lambek. 1958. The mathematics of sentence structure. American mathematical monthly, 65:154– 169.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joachim Lambek</author>
</authors>
<title>On the calculus of syntactic types.</title>
<date>1961</date>
<booktitle>Structure of language and its mathematical aspects,</booktitle>
<pages>166--178</pages>
<editor>In Roman Jakobson, editor,</editor>
<publisher>American Mathematical Society.</publisher>
<contexts>
<context position="1388" citStr="Lambek, 1961" startWordPosition="210" endWordPosition="211">, for each k; this result is obtained by a specific construction of a limit point in the considered class, that does not use product operator. Another interest of our construction is that it provides limit points for the whole hierarchy of Lambek grammars, including the recent pregroup grammars. Such a result aims at clarifying the possible directions for future learning algorithms: it expresses the difficulty of learning categorial grammars from strings and the need for an adequate structure on examples. 1 Introduction Categorial grammars (Bar-Hillel, 1953) and Lambek grammars (Lambek, 1958; Lambek, 1961) have been studied in the field of natural language processing. They are well adapted to learning perspectives since they are completely lexicalized and an actual way of research is to determine the sub-classes of such grammars that remain learnable in the sense of Gold (Gold, 1967). We recall that learning here consists to define an algorithm on a finite set of sentences that converge to obtain a grammar in the class that generates the examples. Let G be a class of grammars, that we wish to learn from positive examples. Formally, let L(G) denote the language associated with grammar G, and let</context>
<context position="4357" citStr="Lambek, 1961" startWordPosition="715" endWordPosition="716">background knowledge on three main aspects: Lambek categorial grammars ; learning in Gold’s model ; Lambek pregroup grammars that we use later as models in some proofs. Section 3 then presents our main result on NL (NL denotes nonassociative Lambek grammars not allowing empty sequence): after a construction overview, we discuss some corollaries and then provide the details of proof. Section 4 concludes. 2 Background 2.1 Categorial Grammars The reader not familiar with Lambek Calculus and its non-associative version will find nice presentation in the first ones written by Lambek (Lambek, 1958; Lambek, 1961) or more recently in (Kandulski, 1988; Aarts and Trautwein, 1995; Buszkowski, 1997; Moortgat, 1997; de Groote, 1999; de Groote and Lamarche, 2002). The types Tp, or formulas, are generated from a set of primitive types Pr, or atomic formulas by three binary connectives “ / ” (over), “ \ ” (under) and “•” (product): Tp ::= Pr |Tp \ Tp |Tp / Tp |Tp •Tp. As a logical system, we use a Gentzen-style sequent presentation. A sequent   A is composed of a sequence of formulas  which is the antecedent configuration and a succedent formula A. Let  be a fixed alphabet. A categorial grammar over  is a</context>
</contexts>
<marker>Lambek, 1961</marker>
<rawString>Joachim Lambek. 1961. On the calculus of syntactic types. In Roman Jakobson, editor, Structure of language and its mathematical aspects, pages 166–178. American Mathematical Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lambek</author>
</authors>
<title>Type grammars revisited.</title>
<date>1999</date>
<booktitle>Logical aspects of computational linguistics: Second International Conference, LACL ’97,</booktitle>
<editor>In Alain Lecomte, Franc¸ois Lamarche, and Guy Perrier, editors,</editor>
<publisher>Springer-Verlag.</publisher>
<location>Nancy, France,</location>
<contexts>
<context position="8419" citStr="Lambek, 1999" startWordPosition="1603" endWordPosition="1604">properties on learning. 2.2.1 Limit Points A class CL of languages has a limit point iff there exists an infinite sequence &lt; Ln &gt;nEN of languages in CL and a language L  CL such that: L0 C L1 ... C ... CLnC... and L=UnENLn (L is a limit point of CL). 2.2.2 Limit Points Imply Unlearnability The following property is important for our purpose. If the languages of the grammars in a class G have a limit point then the class G is unlearnable. 1 2.3 Some Useful Models For ease of proof, in next section we use two kinds of models that we now recall: free groups and pregroups introduced recently by (Lambek, 1999) as an alternative of existing type grammars. 2.3.1 Free Group Interpretation. Let FG denote the free group with generators Pr, operation · and with neutral element 1. We associate with each formula C of L or NL, an element in FG written [C] as follows: [A] = A if A is a primitive type [C1 \ C2] = [C1]−1 ·[C2] [C1 / C2] = [C1] · [C2]−1 [C1 • C2] = [C1] · [C2] We extend the notation to sequents by: [C1, C2, ... , Cn] = [C1] · [C2] · ··· · [Cn] The following property states that FG is a model for L (hence for NL): if  L C then [] =FG [C] 2.3.2 Free Pregroup Interpretation Pregroup. A pregroup</context>
</contexts>
<marker>Lambek, 1999</marker>
<rawString>J. Lambek. 1999. Type grammars revisited. In Alain Lecomte, Franc¸ois Lamarche, and Guy Perrier, editors, Logical aspects of computational linguistics: Second International Conference, LACL ’97, Nancy, France, September 22–24, 1997; selected papers, volume 1582. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Moortgat</author>
</authors>
<title>Categorial type logic.</title>
<date>1997</date>
<booktitle>In van Benthem and ter Meulen (van Benthem and ter Meulen,</booktitle>
<pages>93--177</pages>
<contexts>
<context position="4455" citStr="Moortgat, 1997" startWordPosition="730" endWordPosition="731"> ; Lambek pregroup grammars that we use later as models in some proofs. Section 3 then presents our main result on NL (NL denotes nonassociative Lambek grammars not allowing empty sequence): after a construction overview, we discuss some corollaries and then provide the details of proof. Section 4 concludes. 2 Background 2.1 Categorial Grammars The reader not familiar with Lambek Calculus and its non-associative version will find nice presentation in the first ones written by Lambek (Lambek, 1958; Lambek, 1961) or more recently in (Kandulski, 1988; Aarts and Trautwein, 1995; Buszkowski, 1997; Moortgat, 1997; de Groote, 1999; de Groote and Lamarche, 2002). The types Tp, or formulas, are generated from a set of primitive types Pr, or atomic formulas by three binary connectives “ / ” (over), “ \ ” (under) and “•” (product): Tp ::= Pr |Tp \ Tp |Tp / Tp |Tp •Tp. As a logical system, we use a Gentzen-style sequent presentation. A sequent   A is composed of a sequence of formulas  which is the antecedent configuration and a succedent formula A. Let  be a fixed alphabet. A categorial grammar over  is a finite relation G between  and Tp. If &lt; c, A &gt; G, we say that G assigns A to c, and we write G </context>
</contexts>
<marker>Moortgat, 1997</marker>
<rawString>Michael Moortgat. 1997. Categorial type logic. In van Benthem and ter Meulen (van Benthem and ter Meulen, 1997), chapter 2, pages 93–177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacques Nicolas</author>
</authors>
<title>Grammatical inference as unification.</title>
<date>1999</date>
<booktitle>Rapport de Recherche RR-3632, INRIA. http://www.inria.fr/RRRT/publications-eng.html.</booktitle>
<contexts>
<context position="2457" citStr="Nicolas, 1999" startWordPosition="406" endWordPosition="407">G be a class of grammars, that we wish to learn from positive examples. Formally, let L(G) denote the language associated with grammar G, and let V be a given alphabet, a learning algorithm is a function O from finite sets of words in V* to G, such that for all G E G with L(G) =&lt; ei &gt;iEN there exists a grammar G&apos; E G and there exists no E N such that: bn &gt; no O({ei, ... , en}) = G&apos; E G with L(G&apos;) = L(G). After pessimistic unlearnability results in (Gold, 1967), learnability of non trivial classes has been proved in (Angluin, 1980) and (Shinohara, 1990). Recent works from (Kanazawa, 1998) and (Nicolas, 1999) following (Buszkowski and Penn, 1990) have answered the problem for different sub-classes of classical categorial grammars (we recall that the whole class of classical categorial grammars is equivalent to context free grammars; the same holds for the class of Lambek grammars (Pentus, 1993) that is thus not learnable in Gold’s model). The extension of such results for Lambek grammars is an interesting challenge that is addressed by works on logic types from (Dudau-Sofronie et al., 2001) (these grammars enjoy a direct link with Montague semantics), learning from structures in (Retor and Bonato,</context>
</contexts>
<marker>Nicolas, 1999</marker>
<rawString>Jacques Nicolas. 1999. Grammatical inference as unification. Rapport de Recherche RR-3632, INRIA. http://www.inria.fr/RRRT/publications-eng.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mati Pentus</author>
</authors>
<title>Lambek grammars are context-free.</title>
<date>1993</date>
<booktitle>In Logic in Computer Science.</booktitle>
<publisher>IEEE Computer Society Press.</publisher>
<contexts>
<context position="2748" citStr="Pentus, 1993" startWordPosition="451" endWordPosition="452">re exists a grammar G&apos; E G and there exists no E N such that: bn &gt; no O({ei, ... , en}) = G&apos; E G with L(G&apos;) = L(G). After pessimistic unlearnability results in (Gold, 1967), learnability of non trivial classes has been proved in (Angluin, 1980) and (Shinohara, 1990). Recent works from (Kanazawa, 1998) and (Nicolas, 1999) following (Buszkowski and Penn, 1990) have answered the problem for different sub-classes of classical categorial grammars (we recall that the whole class of classical categorial grammars is equivalent to context free grammars; the same holds for the class of Lambek grammars (Pentus, 1993) that is thus not learnable in Gold’s model). The extension of such results for Lambek grammars is an interesting challenge that is addressed by works on logic types from (Dudau-Sofronie et al., 2001) (these grammars enjoy a direct link with Montague semantics), learning from structures in (Retor and Bonato, september 2001), complexity results from (Florˆencio, 2002) or unlearnability results from (Foret and Le Nir, 2002a; Foret and Le Nir, 2002b); this result was shown for several variants but the question was left open for the basic variant, the nonassociative variant NL. In this paper, we c</context>
</contexts>
<marker>Pentus, 1993</marker>
<rawString>Mati Pentus. 1993. Lambek grammars are context-free. In Logic in Computer Science. IEEE Computer Society Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Retor´e</author>
<author>Roberto Bonato</author>
</authors>
<title>Learning rigid lambek grammars and minimalist grammars from struc tured sentences. Third workshop on Learning Language in Logic,</title>
<date>2001</date>
<location>Strasbourg.</location>
<marker>Retor´e, Bonato, 2001</marker>
<rawString>Christian Retor´e and Roberto Bonato. september 2001. Learning rigid lambek grammars and minimalist grammars from struc tured sentences. Third workshop on Learning Language in Logic, Strasbourg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Shinohara</author>
</authors>
<title>Inductive inference from positive data is powerful.</title>
<date>1990</date>
<booktitle>In The 1990 Workshop on Computational Learning Theory,</booktitle>
<pages>97--110</pages>
<publisher>Morgan Kaufmann.</publisher>
<location>San Mateo, California.</location>
<contexts>
<context position="2401" citStr="Shinohara, 1990" startWordPosition="398" endWordPosition="399">n a grammar in the class that generates the examples. Let G be a class of grammars, that we wish to learn from positive examples. Formally, let L(G) denote the language associated with grammar G, and let V be a given alphabet, a learning algorithm is a function O from finite sets of words in V* to G, such that for all G E G with L(G) =&lt; ei &gt;iEN there exists a grammar G&apos; E G and there exists no E N such that: bn &gt; no O({ei, ... , en}) = G&apos; E G with L(G&apos;) = L(G). After pessimistic unlearnability results in (Gold, 1967), learnability of non trivial classes has been proved in (Angluin, 1980) and (Shinohara, 1990). Recent works from (Kanazawa, 1998) and (Nicolas, 1999) following (Buszkowski and Penn, 1990) have answered the problem for different sub-classes of classical categorial grammars (we recall that the whole class of classical categorial grammars is equivalent to context free grammars; the same holds for the class of Lambek grammars (Pentus, 1993) that is thus not learnable in Gold’s model). The extension of such results for Lambek grammars is an interesting challenge that is addressed by works on logic types from (Dudau-Sofronie et al., 2001) (these grammars enjoy a direct link with Montague se</context>
</contexts>
<marker>Shinohara, 1990</marker>
<rawString>T. Shinohara. 1990. Inductive inference from positive data is powerful. In The 1990 Workshop on Computational Learning Theory, pages 97–110, San Mateo, California. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<date>1997</date>
<booktitle>Handbook ofLogic and Language.</booktitle>
<editor>J. van Benthem and A. ter Meulen, editors.</editor>
<publisher>North-Holland Elsevier,</publisher>
<location>Amsterdam.</location>
<marker>1997</marker>
<rawString>J. van Benthem and A. ter Meulen, editors. 1997. Handbook ofLogic and Language. North-Holland Elsevier, Amsterdam.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>