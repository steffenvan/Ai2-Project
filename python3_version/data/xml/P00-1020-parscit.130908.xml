<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001107">
<title confidence="0.997952">
An Empirical Study of the Influence of Argument Conciseness on
Argument Effectiveness
</title>
<author confidence="0.966283">
Giuseppe Carenini
</author>
<affiliation confidence="0.940097333333333">
Intelligent Systems Program
University of Pittsburgh,
Pittsburgh, PA 15260, USA
</affiliation>
<email confidence="0.991514">
carenini@cs.pitt.edu
</email>
<author confidence="0.964162">
Johanna D. Moore
</author>
<affiliation confidence="0.946492">
The Human Communication Research Centre,
University of Edinburgh,
2 Buccleuch Place, Edinburgh EH8 9LW, UK.
</affiliation>
<email confidence="0.991058">
jmoore@cogsci.ed.ac.uk
</email>
<sectionHeader confidence="0.99376" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9993299">
We have developed a system that generates
evaluative arguments that are tailored to the
user, properly arranged and concise. We have
also developed an evaluation framework in
which the effectiveness of evaluative arguments
can be measured with real users. This paper
presents the results of a formal experiment we
have performed in our framework to verify the
influence of argument conciseness on argument
effectiveness
</bodyText>
<sectionHeader confidence="0.998798" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999970703703704">
Empirical methods are critical to gauge the
scalability and robustness of proposed
approaches, to assess progress and to stimulate
new research questions. In the field of natural
language generation, empirical evaluation has
only recently become a top research priority
(Dale, Eugenio et al. 1998). Some empirical
work has been done to evaluate models for
generating descriptions of objects and processes
from a knowledge base (Lester and Porter March
1997), text summaries of quantitative data
(Robin and McKeown 1996), descriptions of
plans (Young to appear) and concise causal
arguments (McConachy, Korb et al. 1998).
However, little attention has been paid to the
evaluation of systems generating evaluative
arguments, communicative acts that attempt to
affect the addressee’s attitudes (i.e. evaluative
tendencies typically phrased in terms of like and
dislike or favor and disfavor).
The ability to generate evaluative arguments is
critical in an increasing number of online
systems that serve as personal assistants,
advisors, or shopping assistants1. For instance, a
shopping assistant may need to compare two
similar products and argue why its current user
should like one more than the other.
</bodyText>
<footnote confidence="0.950773">
1 See for instance www.activebuyersguide.com
</footnote>
<bodyText confidence="0.999923181818182">
In the remainder of the paper, we first describe a
computational framework for generating
evaluative arguments at different levels of
conciseness. Then, we present an evaluation
framework in which the effectiveness of
evaluative arguments can be measured with real
users. Next, we describe the design of an
experiment we ran within the framework to
verify the influence of argument conciseness on
argument effectiveness. We conclude with a
discussion of the experiment’s results.
</bodyText>
<sectionHeader confidence="0.6056375" genericHeader="method">
2 Generating concise evaluative
arguments
</sectionHeader>
<bodyText confidence="0.99525368">
Often an argument cannot mention all the
available evidence, usually for the sake of
brevity. According to argumentation theory, the
selection of what evidence to mention in an
argument should be based on a measure of the
evidence strength of support (or opposition) to
the main claim of the argument (Mayberry and
Golden 1996). Furthermore, argumentation
theory suggests that for evaluative arguments the
measure of evidence strength should be based on
a model of the intended reader’s values and
preferences.
Following argumentation theory, we have
designed an argumentative strategy for
generating evaluative arguments that are
properly arranged and concise (Carenini and
Moore 2000). In our strategy, we assume that
the reader’s values and preferences are
represented as an additive multiattribute value
function (AMVF), a conceptualization based on
multiattribute utility theory (MAUT)(Clemen
1996). This allows us to adopt and extend a
measure of evidence strength proposed in
previous work on explaining decision theoretic
advice based on an AMVF (Klein1994).
</bodyText>
<figureCaption confidence="0.884983">
Figure 1 Sample additive multiattribute value function (AMVF)
</figureCaption>
<bodyText confidence="0.999966333333333">
The argumentation strategy has been
implemented as part of a complete argument
generator. Other modules of the generator
include a microplanner, which performs
aggregation, pronominalization and makes
decisions about cue phrases and scalar
adjectives, along with a sentence realizer, which
extends previous work on realizing evaluative
statements (Elhadad 1995).
</bodyText>
<subsectionHeader confidence="0.997676">
2.1 Background on AMVF
</subsectionHeader>
<bodyText confidence="0.918903035714286">
An AMVF is a model of a person’s values and
preferences with respect to entities in a certain
class. It comprises a value tree and a set of
component value functions, one for each
primitive attribute of the entity. A value tree is a
decomposition of the value of an entity into a
hierarchy of aspects of the entity2, in which the
leaves correspond to the entity primitive
attributes (see Figure 1 for a simple value tree in
the real estate domain). The arcs of the tree are
weighted to represent the importance of the
value of an objective in contributing to the value
of its parent in the tree (e.g., in Figure 1 location
is more than twice as important as size in
determining the value of a house). Note that the
sum of the weights at each level is equal to 1. A
component value function for an attribute
expresses the preferability of each attribute
value as a number in the [0,1] interval. For
instance, in Figure 1 neighborhood n2 has
preferability 0.3, and a distance-from-park of 1
mile has preferability (1 - (1/5 * 1))=0.8).
2 In decision theory these aspects are called
objectives. For consistency with previous work, we
will follow this terminology in the remainder of the
paper.
Formally, an AMVF predicts the value v(e) of
an entity e as follows:
</bodyText>
<equation confidence="0.992041">
v(e) = v(x1,...,xn) = Ewi vi(xi), where
- (x1,...,xn) is the vector of attribute values for an
entity e
</equation>
<bodyText confidence="0.9986405">
- Vattribute i, vi is the component value function,
which maps the least preferable xi to 0, the most
preferable to 1, and the other xi to values in [0,1]
- wi is the weight for attribute i, with 0&lt;_ wi &lt;_ 1
and Ewi =1
- wi is equal to the product of all the weights
from the root of the value tree to the attribute i
A function vo(e) can also be defined for each
objective. When applied to an entity, this
function returns the value of the entity with
respect to that objective. For instance, assuming
the value tree shown in Figure 1, we have:
</bodyText>
<equation confidence="0.9756725">
vLocation (e) =
= (0.4* vNeighborhood (e)) + (0. 6 *
</equation>
<bodyText confidence="0.999804">
Thus, given someone’s AMVF, it is possible to
compute how valuable an entity is to that
individual. Furthermore, it is possible to
compute how valuable any objective (i.e., any
aspect of that entity) is for that person. All of
these values are expressed as a number in the
interval [0,1].
</bodyText>
<subsectionHeader confidence="0.998575">
2.2 A measure of evidence strength
</subsectionHeader>
<bodyText confidence="0.999644833333333">
Given an AMVF for a user applied to an entity
(e.g., a house), it is possible to define a precise
measure of an objective strength in determining
the evaluation of its parent objective for that
entity. This measure is proportional to two
factors: (A) the weight of the objective
</bodyText>
<equation confidence="0.901757">
( ))
e
vDist from park
− −
</equation>
<figureCaption confidence="0.925926">
Figure 2 Sample population of objectives
represented by dots and ordered by their
compellingness
</figureCaption>
<bodyText confidence="0.999019428571429">
(which is by itself a measure of importance), (B)
a factor that increases equally for high and low
values of the objective, because an objective can
be important either because it is liked a lot or
because it is disliked a lot. We call this measure
s-compellingness and provide the following
definition:
</bodyText>
<equation confidence="0.96889">
s-compellingness(o, e, refo) = (A)∗ (B) =
= w(o,refo)∗ max[[vo(e)]; [1 – vo(e)]], where
− o is an objective, e is an entity, refo is an
</equation>
<bodyText confidence="0.912412">
ancestor of o in the value tree
− w(o,refo) is the product of the weights of all
the links from o to refo
− vo is the component value function for leaf
objectives (i.e., attributes), and it is the
recursive evaluation over children(o) for
nonleaf objectives
Given a measure of an objective&apos;s strength, a
predicate indicating whether an objective should
be included in an argument (i.e., worth
mentioning) can be defined as follows:
s-notably-compelling?(o,opop,e, refo) ≡
s-compellingness(o, e, refo)&gt;μ x+kσx , where
− o, e, and refo are defined as in the previous
Def; opop is an objective population (e.g.,
siblings(o)), and opop&gt;2
</bodyText>
<equation confidence="0.978519333333333">
− p∈ opop; x∈X = s-compellingness(p, e,
refo)
− μ x is the mean of X, σx is the standard
</equation>
<bodyText confidence="0.99954475">
deviation and k is a user-defined constant
Similar measures for the comparison of two
entities are defined and extensively discussed in
(Klein 1994).
</bodyText>
<subsectionHeader confidence="0.99378">
2.3 The constant k
</subsectionHeader>
<bodyText confidence="0.94499456">
In the definition of s-notably-compelling?, the
constant k determines the lower bound of s-
compellingness for an objective to be included
in an argument. As shown in Figure 2, for k=0
only objectives with s-compellingness greater
Figure 3 Arguments about the same house,
tailored to the same subject but with k ranging
from 1 to –1
than the average s-compellingness in a
population are included in the argument (4 in the
sample population). For higher positive values
of k less objectives are included (only 2, when
k=1), and the opposite happens for negative
values (8 objectives are included, when k=-1).
Therefore, by setting the constant k to different
values, it is possible to control in a principled
way how many objectives (i.e., pieces of
evidence) are included in an argument, thus
controlling the degree of conciseness of the
generated arguments.
Figure 3 clearly illustrates this point by showing
seven arguments generated by our argument
generator in the real-estate domain. These
arguments are about the same house, tailored to
the same subject, for k ranging from 1 to –1.
</bodyText>
<sectionHeader confidence="0.958651" genericHeader="method">
3 The evaluation framework
</sectionHeader>
<bodyText confidence="0.99993275">
In order to evaluate different aspects of the
argument generator, we have developed an
evaluation framework based on the task efficacy
evaluation method. This method allows
</bodyText>
<equation confidence="0.9883365">
−δ
μ +δ
aompellingness
k = 0
k =1
k = -1
</equation>
<figureCaption confidence="0.818073">
Figure 4 The evaluation framework architecture
</figureCaption>
<bodyText confidence="0.999921739130435">
the experimenter to evaluate a generation model
by measuring the effects of its output on user’s
behaviors, beliefs and attitudes in the context of
a task.
Aiming at general results, we chose a rather
basic and frequent task that has been extensively
studied in decision analysis: the selection of a
subset of preferred objects (e.g., houses) out of a
set of possible alternatives. In the evaluation
framework that we have developed, the user
performs this task by using a computer
environment (shown in Figure 5) that supports
interactive data exploration and analysis (IDEA)
(Roth, Chuah et al. 1997). The IDEA
environment provides the user with a set of
powerful visualization and direct manipulation
techniques that facilitate the user’s autonomous
exploration of the set of alternatives and the
selection of the preferred alternatives.
Let’s examine now how an argument generator
can be evaluated in the context of the selection
task, by going through the architecture of the
evaluation framework.
</bodyText>
<subsectionHeader confidence="0.99769">
3.1 The evaluation framework architecture
</subsectionHeader>
<bodyText confidence="0.986141861111111">
Figure 4 shows the architecture of the evaluation
framework. The framework consists of three
main sub-systems: the IDEA system, a User
Model Refiner and the Argument Generator. The
framework assumes that a model of the user’s
preferences (an AMVF) has been previously
acquired from the user, to assure a reliable initial
model.
At the onset, the user is assigned the task to
select from the dataset the four most preferred
alternatives and to place them in a Hot List (see
Figure 5, upper right corner) ordered by
preference. The IDEA system supports the user
in this task (Figure 4 (1)). As the interaction
unfolds, all user actions are monitored and
collected in the User’s Action History (Figure 4
(2a)). Whenever the user feels that the task is
accomplished, the ordered list of preferred
alternatives is saved as her Preliminary Decision
(Figure 4 (2b)). After that, this list, the User’s
Action History and the initial Model of User’s
Preferences are analysed by the User Model
Refiner (Figure 4 (3)) to produce a Refined
Model of the User’s Preferences (Figure 4 (4)).
At this point, the stage is set for argument
generation. Given the Refined Model of the
User’s Preferences, the Argument Generator
produces an evaluative argument tailored to the
model (Figure 4 (5-6)), which is presented to the
user by the IDEA system (Figure 4 (7)).The
argument goal is to introduce a new alternative
(not included in the dataset initially presented to
the user) and to persuade the user that the
alternative is worth being considered. The new
alternative is designed on the fly to be preferable
for the user given her preference model.
</bodyText>
<figure confidence="0.991018333333333">
NewHouse 3-26
3-26
HotList
</figure>
<figureCaption confidence="0.999578">
Figure 5 The IDEA environment display at the end of the interaction
</figureCaption>
<bodyText confidence="0.988313386363637">
All the information about the new alternative is
also presented graphically. Once the argument is
presented, the user may (a) decide immediately
to introduce the new alternative in her Hot List,
or (b) decide to further explore the dataset,
possibly making changes to the Hot List adding
the new instance to the Hot List, or (c) do
nothing. Figure 5 shows the display at the end of
the interaction, when the user, after reading the
argument, has decided to introduce the new
alternative in the Hot List first position (Figure
5, top right).
Whenever the user decides to stop exploring and
is satisfied with her final selections, measures
related to argument’s effectiveness can be
assessed (Figure 4 (8)). These measures are
obtained either from the record of the user
interaction with the system or from user self-
reports in a final questionnaire (see Figure 6 for
an example of self-report) and include:
- Measures of behavioral intentions and attitude
change: (a) whether or not the user adopts the
new proposed alternative, (b) in which position
in the Hot List she places it and (c) how much
she likes the new alternative and the other
objects in the Hot List.
- A measure of the user’s confidence that she has
selected the best for her in the set of alternatives.
- A measure of argument effectiveness derived
by explicitly questioning the user at the end of
the interaction about the rationale for her
decision (Olso and Zanna 1991). This can
provide valuable information on what aspects of
the argument were more influential (i.e., better
understood and accepted by the user).
- An additional measure of argument
effectiveness is to explicitly ask the user at the
end of the interaction to judge the argument with
respect to several dimensions of quality, such as
content, organization, writing style and
convincigness. However, evaluations based on
a) How would you judge the houses in your Hot List?
The more you like the house the closer you should
put a cross to “good choice”
</bodyText>
<figure confidence="0.968384375">
1st house
bad choice : _:_ :_ :_ :_ :_ :_ :_ : : good choice
2nd house
bad choice : _:_ :_ :_ :_ :_ :_ :_ : : good choice
3rd house
bad choice : _:_ :_ :_ :_ :_ :_ :_ : : good choice
4th house
bad choice : _:_ :_ :_ :_ :_ :_ :_ : : good choice
</figure>
<figureCaption confidence="0.999949666666667">
Figure 6 Self -report on user’s satisfaction with
houses in the HotList
Figure 7 Hypotheses on experiment outcomes
</figureCaption>
<bodyText confidence="0.999396307692308">
judgements along these dimensions are clearly
weaker than evaluations measuring actual
behavioural and attitudinal changes (Olso and
Zanna 1991).
To summarize, the evaluation framework just
described supports users in performing a
realistic task at their own pace by interacting
with an IDEA system. In the context of this task,
an evaluative argument is generated and
measurements related to its effectiveness can be
performed.
We now discuss an experiment that we have
performed within the evaluation framework
</bodyText>
<sectionHeader confidence="0.993544" genericHeader="method">
4 The Experiment
</sectionHeader>
<bodyText confidence="0.999370523076923">
The argument generator has been designed to
facilitate testing the effectiveness of different
aspects of the generation process. The
experimenter can easily control whether the
generator tailors the argument to the current
user, the degree of conciseness of the argument
(by varying k as explained in Section 2.3), and
what microplanning tasks the generator
performs. In the experiment described here, we
focused on studying the influence of argument
conciseness on argument effectiveness. A
parallel experiment about the influence of
tailoring is described elsewhere.
We followed a between-subjects design with
three experimental conditions:
No-Argument - subjects are simply informed that
a new house came on the market.
Tailored-Concise - subjects are presented with
an evaluation of the new house tailored to their
preferences and at a level of conciseness that we
hypothesize to be optimal. To start our
investigation, we assume that an effective
argument (in our domain) should contain
slightly more than half of the available evidence.
By running the generator with different values
for k on the user models of the pilot subjects, we
found that this corresponds to k=-0.3. In fact,
with k=-0.3 the arguments contained on average
10 pieces of evidence out of the 19 available.
Tailored-Verbose - subjects are presented with
an evaluation of the new house tailored to their
preferences, but at a level of conciseness that we
hypothesize to be too low (k=-1, which
corresponds on average, in our analysis of the
pilot subjects, to 16 pieces of evidence out of the
possible 19).
In the three conditions, all the information about
the new house is also presented graphically, so
that no information is hidden from the subject.
Our hypotheses on the outcomes of the
experiment are summarized in Figure 7. We
expect arguments generated for the Tailored-
Concise condition to be more effective than
arguments generated for the Tailored-Verbose
condition. We also expect the Tailored-Concise
condition to be somewhat better than the No-
Argument condition, but to a lesser extent,
because subjects, in the absence of any
argument, may spend more time further
exploring the dataset, thus reaching a more
informed and balanced decision. Finally, we do
not have strong hypotheses on comparisons of
argument effectiveness between the No-
Argument and Tailored-Verbose conditions.
The experiment is organized in two phases. In
the first phase, the subject fills out a
questionnaire on the Web. The questionnaire
implements a method form decision theory to
acquire an AMVF model of the subject’s
preferences (Edwards and Barron 1994). In the
second phase of the experiment, to control for
possible confounding variables (including
subject’s argumentativeness (Infante and Rancer
1982), need for cognition (Cacioppo, Petty et al.
1983), intelligence and self-esteem), the subject
</bodyText>
<figure confidence="0.968671368421053">
&gt;&gt;
Tailored
Concise
?
Tailored
Verbose
No-Argument
&gt;
a) How would you judge the houses in your Hot List?
The more you like the house the closer you should
put a cross to “good choice”
1st house
bad choice : __:__:__:__ :__:__:__:X :__: good choice
2nd house(New house)
bad choice : __:__:__:__ :__:__:X :__:__: good choice
3rd house
bad choice : __:__:__:__ :__:__:X :__:__: good choice
4th house
bad choice : __:__:__:__ :X :__:__:__:__: good choice
</figure>
<figureCaption confidence="0.990194">
Figure 8 Sample filled-out self-report on user’s
satisfaction with houses in the Hot List3
</figureCaption>
<bodyText confidence="0.9991782">
is randomly assigned to one of the three
conditions.
Then, the subject interacts with the evaluation
framework and at the end of the interaction
measures of the argument effectiveness are
collected, as described in Section 3.1.
After running the experiment with 8 pilot
subjects to refine and improve the experimental
procedure, we ran a formal experiment involving
30 subjects, 10 in each experimental condition.
</bodyText>
<sectionHeader confidence="0.996445" genericHeader="evaluation">
5 Experiment Results
</sectionHeader>
<subsectionHeader confidence="0.998776">
5.1 A precise measure of satisfaction
</subsectionHeader>
<bodyText confidence="0.9591088">
According to literature on persuasion, the most
important measures of arguments effectiveness
are the ones of behavioral intentions and attitude
change. As explained in Section 3.1, in our
framework such measures include (a) whether or
not the user adopts the new proposed alternative,
(b) in which position in the Hot List she places
it, (c) how much she likes the proposed new
alternative and the other objects in the Hot List.
Measures (a) and (b) are obtained from the
record of the user interaction with the system,
whereas measures in (c) are obtained from user
self-reports.
A closer analysis of the above measures
indicates that the measures in (c) are simply a
more precise version of measures (a) and (b). In
fact, not only they assess the same information
as measures (a) and (b), namely a preference
ranking among the new alternative and the
objects in the Hot List, but they also offer two
additional critical advantages:
3 If the subject does not adopt the new house, she is
asked to express her satisfaction with the new house
in an additional self-report.
(i) Self-reports allow a subject to express
differences in satisfaction more precisely than
by ranking. For instance, in the self-report
shown in Figure 8, the subject was able to
specify that the first house in the Hot List was
only one space (unit of satisfaction) better then
the house preceding it in the ranking, while the
third house was two spaces better than the house
preceding it.
(ii) Self-reports do not force subjects to express
a total order between the houses. For instance, in
Figure 8 the subject was allowed to express that
the second and the third house in the Hot List
were equally good for her.
Furthermore, measures of satisfaction obtained
through self-reports can be combined in a single,
statistically sound measure that concisely
express how much the subject liked the new
house with respect to the other houses in the Hot
List. This measure is the z-score of the subject’s
self-reported satisfaction with the new house,
with respect to the self-reported satisfaction with
the houses in the Hot List. A z-score is a
normalized distance in standard deviation units
of a measure xi from the mean of a population X.
Formally:
xie X; z-score( xi ,X) = [xi - µ (X)] / σ(X)
For instance, the satisfaction z-score for the new
instance, given the sample self-reports shown in
Figure 8, would be:
[7 - µ ({8,7,7,5})] / σ({8,7,7,5}) = 0.2
The satisfaction z-score precisely and concisely
integrates all the measures of behavioral
intentions and attitude change. We have used
satisfaction z-scores as our primary measure of
argument effectiveness.
</bodyText>
<subsectionHeader confidence="0.628397">
5.2 Results
</subsectionHeader>
<bodyText confidence="0.960775521739131">
As shown in Figure 9, the satisfaction z-scores
obtained in the experiment confirmed our
hypotheses. Arguments generated for the
Tailored-Concise condition were significantly
more effective than arguments generated for
Tailored-Verbose condition. The Tailored-
Concise condition was also significantly better
than the No-Argument condition, but to a lesser
extent. Logs of the interactions suggest that this
happened because subjects in the No-Argument
condition spent significantly more time further
exploring the dataset. Finally, there was no
significant difference in argument effectiveness
Figure 9 Results for satisfaction z-scores. The
average z-scores for the three conditions are
shown in the grey boxes and the p-values are
reported beside the links
between the No-Argument and Tailored-
Verbose conditions.
With respect to the other measures of argument
effectiveness mentioned in Section 3.1, we have
not found any significant differences among the
experimental conditions.
</bodyText>
<sectionHeader confidence="0.998493" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999952125">
Argumentation theory indicates that effective
arguments should be concise, presenting only
pertinent and cogent information. However,
argumentation theory does not tell us what is the
most effective degree of conciseness. As a
preliminary attempt to answer this question for
evaluative arguments, we have compared in a
formal experiment the effectiveness of
arguments generated by our argument generator
at two different levels of conciseness. The
experiment results show that arguments
generated at the more concise level are
significantly better than arguments generated at
the more verbose level. However, further
experiments are needed to determine what is the
optimal level of conciseness.
</bodyText>
<sectionHeader confidence="0.997532" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.987499166666667">
Our thanks go to the members of the Autobrief
project: S. Roth, N. Green, S. Kerpedjiev and J.
Mattis. We also thank C. Conati for comments
on drafts of this paper. This work was supported
by grant number DAA-1593K0005 from the
Advanced Research Projects Agency (ARPA).
</bodyText>
<sectionHeader confidence="0.996889" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998724178571428">
Cacioppo, J. T., R. E. Petty, et al. (1983). “Effects of
Need for Cognition on Message Evaluation, Recall,
and Persuasion.” Journal of Personality and Social
Psychology 45(4): 805-818.
Carenini, G. and J. Moore (2000). A Strategy for
Generating Evaluative Arguments. International
Conference on Natural Language Generation,
Mitzpe Ramon, Israel.
Clemen, R. T. (1996). Making Hard Decisions: an
introduction to decision analysis. Belmont,
California, Duxbury Press.
Dale, R., B. d. Eugenio, et al. (1998). “Introduction to
the Special Issue on Natural Language
Generation.” Computational Linguistics 24(3):
345-353.
Edwards, W. and F. H. Barron (1994). “SMARTS
and SMARTER: Improved Simple Methods for
Multi-attribute Utility Measurements.”
Organizational Behavior and Human Decision
Processes 60: 306-325.
Elhadad, M. (1995). “Using argumentation in text
generation.” Journal of Pragmatics 24: 189-220.
Infante, D. A. and A. S. Rancer (1982). “A
Conceptualization and Measure of
Argumentativeness.” Journal of Personality
Assessment 46: 72-80.
Klein, D. (1994). Decision Analytic Intelligent
Systems: Automated Explanation and Knowledge
Acquisition, Lawrence Erlbaum Associates.
Lester, J. C. and B. W. Porter (March 1997).
“Developing and Empirically Evaluating Robust
Explanation Generators: The KNIGHT
Experiments.” Computational Linguistics 23(1):
65-101.
Mayberry, K. J. and R. E. Golden (1996). For
Argument&apos;s Sake: A Guide to Writing Effective
Arguments, Harper Collins, College Publisher.
McConachy, R., K. B. Korb, et al. (1998). Deciding
What Not to Say: An Attentional-Probabilistic
Approach to Argument Presentation. Cognitive
Science Conference.
Olso, J. M. and M. P. Zanna (1991). Attitudes and
beliefs ; Attitude change and attitude-behavior
consistency. Social Psychology. R. M. Baron and
W. G. Graziano.
Robin, J. and K. McKeown (1996). “Empirically
Designing and Evaluating a New Revision-Based
Model for Summary Generation.” Artificial
Intelligence journal 85: 135-179.
Roth, S. F., M. C. Chuah, et al. (1997). Towards an
Information Visualization Workspace: Combining
Multiple Means of Expression. Human-Computer
Interaction Journal.
Young, M. R. “Using Grice&apos;s Maxim of Quantity to
Select the Content of Plan Descriptions.” Artificial
Intelligence Journal, to appear.
</reference>
<figure confidence="0.999329846153846">
0.02 &gt;&gt;
Tailored
Concise
0.88
&gt;
0.03
?
0.31
Tailored
Verbose
0.05
No-Argument
0.25
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.786989">
<title confidence="0.996099">An Empirical Study of the Influence of Argument Conciseness on Argument Effectiveness</title>
<author confidence="0.998339">Giuseppe Carenini</author>
<affiliation confidence="0.999391">Intelligent Systems Program University of Pittsburgh,</affiliation>
<address confidence="0.998858">Pittsburgh, PA 15260, USA</address>
<email confidence="0.999335">carenini@cs.pitt.edu</email>
<author confidence="0.998904">Johanna D Moore</author>
<affiliation confidence="0.995844">The Human Communication Research Centre, University of Edinburgh,</affiliation>
<address confidence="0.963872">2 Buccleuch Place, Edinburgh EH8 9LW, UK.</address>
<email confidence="0.998894">jmoore@cogsci.ed.ac.uk</email>
<abstract confidence="0.9999309">We have developed a system that generates evaluative arguments that are tailored to the user, properly arranged and concise. We have also developed an evaluation framework in which the effectiveness of evaluative arguments can be measured with real users. This paper presents the results of a formal experiment we have performed in our framework to verify the influence of argument conciseness on argument</abstract>
<intro confidence="0.835781">effectiveness</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J T Cacioppo</author>
<author>R E Petty</author>
</authors>
<date>1983</date>
<journal>Effects of Need for Cognition on Message Evaluation, Recall, and Persuasion.” Journal of Personality and Social Psychology</journal>
<volume>45</volume>
<issue>4</issue>
<pages>805--818</pages>
<marker>Cacioppo, Petty, 1983</marker>
<rawString>Cacioppo, J. T., R. E. Petty, et al. (1983). “Effects of Need for Cognition on Message Evaluation, Recall, and Persuasion.” Journal of Personality and Social Psychology 45(4): 805-818.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Carenini</author>
<author>J Moore</author>
</authors>
<title>A Strategy for Generating Evaluative Arguments.</title>
<date>2000</date>
<booktitle>International Conference on Natural Language Generation,</booktitle>
<location>Mitzpe Ramon,</location>
<contexts>
<context position="3253" citStr="Carenini and Moore 2000" startWordPosition="472" endWordPosition="475">sually for the sake of brevity. According to argumentation theory, the selection of what evidence to mention in an argument should be based on a measure of the evidence strength of support (or opposition) to the main claim of the argument (Mayberry and Golden 1996). Furthermore, argumentation theory suggests that for evaluative arguments the measure of evidence strength should be based on a model of the intended reader’s values and preferences. Following argumentation theory, we have designed an argumentative strategy for generating evaluative arguments that are properly arranged and concise (Carenini and Moore 2000). In our strategy, we assume that the reader’s values and preferences are represented as an additive multiattribute value function (AMVF), a conceptualization based on multiattribute utility theory (MAUT)(Clemen 1996). This allows us to adopt and extend a measure of evidence strength proposed in previous work on explaining decision theoretic advice based on an AMVF (Klein1994). Figure 1 Sample additive multiattribute value function (AMVF) The argumentation strategy has been implemented as part of a complete argument generator. Other modules of the generator include a microplanner, which perfor</context>
</contexts>
<marker>Carenini, Moore, 2000</marker>
<rawString>Carenini, G. and J. Moore (2000). A Strategy for Generating Evaluative Arguments. International Conference on Natural Language Generation, Mitzpe Ramon, Israel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R T Clemen</author>
</authors>
<title>Making Hard Decisions: an introduction to decision analysis.</title>
<date>1996</date>
<publisher>Press.</publisher>
<location>Belmont, California, Duxbury</location>
<contexts>
<context position="3470" citStr="Clemen 1996" startWordPosition="503" endWordPosition="504"> argument (Mayberry and Golden 1996). Furthermore, argumentation theory suggests that for evaluative arguments the measure of evidence strength should be based on a model of the intended reader’s values and preferences. Following argumentation theory, we have designed an argumentative strategy for generating evaluative arguments that are properly arranged and concise (Carenini and Moore 2000). In our strategy, we assume that the reader’s values and preferences are represented as an additive multiattribute value function (AMVF), a conceptualization based on multiattribute utility theory (MAUT)(Clemen 1996). This allows us to adopt and extend a measure of evidence strength proposed in previous work on explaining decision theoretic advice based on an AMVF (Klein1994). Figure 1 Sample additive multiattribute value function (AMVF) The argumentation strategy has been implemented as part of a complete argument generator. Other modules of the generator include a microplanner, which performs aggregation, pronominalization and makes decisions about cue phrases and scalar adjectives, along with a sentence realizer, which extends previous work on realizing evaluative statements (Elhadad 1995). 2.1 Backgro</context>
</contexts>
<marker>Clemen, 1996</marker>
<rawString>Clemen, R. T. (1996). Making Hard Decisions: an introduction to decision analysis. Belmont, California, Duxbury Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Dale</author>
<author>B d Eugenio</author>
</authors>
<date>1998</date>
<journal>Introduction to the Special Issue on Natural Language Generation.” Computational Linguistics</journal>
<volume>24</volume>
<issue>3</issue>
<pages>345--353</pages>
<marker>Dale, Eugenio, 1998</marker>
<rawString>Dale, R., B. d. Eugenio, et al. (1998). “Introduction to the Special Issue on Natural Language Generation.” Computational Linguistics 24(3): 345-353.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Edwards</author>
<author>F H Barron</author>
</authors>
<date>1994</date>
<booktitle>SMARTS and SMARTER: Improved Simple Methods for Multi-attribute Utility Measurements.” Organizational Behavior and Human Decision Processes</booktitle>
<volume>60</volume>
<pages>306--325</pages>
<contexts>
<context position="17753" citStr="Edwards and Barron 1994" startWordPosition="2895" endWordPosition="2898">on to be somewhat better than the NoArgument condition, but to a lesser extent, because subjects, in the absence of any argument, may spend more time further exploring the dataset, thus reaching a more informed and balanced decision. Finally, we do not have strong hypotheses on comparisons of argument effectiveness between the NoArgument and Tailored-Verbose conditions. The experiment is organized in two phases. In the first phase, the subject fills out a questionnaire on the Web. The questionnaire implements a method form decision theory to acquire an AMVF model of the subject’s preferences (Edwards and Barron 1994). In the second phase of the experiment, to control for possible confounding variables (including subject’s argumentativeness (Infante and Rancer 1982), need for cognition (Cacioppo, Petty et al. 1983), intelligence and self-esteem), the subject &gt;&gt; Tailored Concise ? Tailored Verbose No-Argument &gt; a) How would you judge the houses in your Hot List? The more you like the house the closer you should put a cross to “good choice” 1st house bad choice : __:__:__:__ :__:__:__:X :__: good choice 2nd house(New house) bad choice : __:__:__:__ :__:__:X :__:__: good choice 3rd house bad choice : __:__:__</context>
</contexts>
<marker>Edwards, Barron, 1994</marker>
<rawString>Edwards, W. and F. H. Barron (1994). “SMARTS and SMARTER: Improved Simple Methods for Multi-attribute Utility Measurements.” Organizational Behavior and Human Decision Processes 60: 306-325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Elhadad</author>
</authors>
<title>Using argumentation in text generation.”</title>
<date>1995</date>
<journal>Journal of Pragmatics</journal>
<volume>24</volume>
<pages>189--220</pages>
<contexts>
<context position="4057" citStr="Elhadad 1995" startWordPosition="586" endWordPosition="587">theory (MAUT)(Clemen 1996). This allows us to adopt and extend a measure of evidence strength proposed in previous work on explaining decision theoretic advice based on an AMVF (Klein1994). Figure 1 Sample additive multiattribute value function (AMVF) The argumentation strategy has been implemented as part of a complete argument generator. Other modules of the generator include a microplanner, which performs aggregation, pronominalization and makes decisions about cue phrases and scalar adjectives, along with a sentence realizer, which extends previous work on realizing evaluative statements (Elhadad 1995). 2.1 Background on AMVF An AMVF is a model of a person’s values and preferences with respect to entities in a certain class. It comprises a value tree and a set of component value functions, one for each primitive attribute of the entity. A value tree is a decomposition of the value of an entity into a hierarchy of aspects of the entity2, in which the leaves correspond to the entity primitive attributes (see Figure 1 for a simple value tree in the real estate domain). The arcs of the tree are weighted to represent the importance of the value of an objective in contributing to the value of its</context>
</contexts>
<marker>Elhadad, 1995</marker>
<rawString>Elhadad, M. (1995). “Using argumentation in text generation.” Journal of Pragmatics 24: 189-220.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D A Infante</author>
<author>A S Rancer</author>
</authors>
<date>1982</date>
<journal>A Conceptualization and Measure of Argumentativeness.” Journal of Personality Assessment</journal>
<volume>46</volume>
<pages>72--80</pages>
<contexts>
<context position="17904" citStr="Infante and Rancer 1982" startWordPosition="2915" endWordPosition="2918">urther exploring the dataset, thus reaching a more informed and balanced decision. Finally, we do not have strong hypotheses on comparisons of argument effectiveness between the NoArgument and Tailored-Verbose conditions. The experiment is organized in two phases. In the first phase, the subject fills out a questionnaire on the Web. The questionnaire implements a method form decision theory to acquire an AMVF model of the subject’s preferences (Edwards and Barron 1994). In the second phase of the experiment, to control for possible confounding variables (including subject’s argumentativeness (Infante and Rancer 1982), need for cognition (Cacioppo, Petty et al. 1983), intelligence and self-esteem), the subject &gt;&gt; Tailored Concise ? Tailored Verbose No-Argument &gt; a) How would you judge the houses in your Hot List? The more you like the house the closer you should put a cross to “good choice” 1st house bad choice : __:__:__:__ :__:__:__:X :__: good choice 2nd house(New house) bad choice : __:__:__:__ :__:__:X :__:__: good choice 3rd house bad choice : __:__:__:__ :__:__:X :__:__: good choice 4th house bad choice : __:__:__:__ :X :__:__:__:__: good choice Figure 8 Sample filled-out self-report on user’s satis</context>
</contexts>
<marker>Infante, Rancer, 1982</marker>
<rawString>Infante, D. A. and A. S. Rancer (1982). “A Conceptualization and Measure of Argumentativeness.” Journal of Personality Assessment 46: 72-80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Klein</author>
</authors>
<title>Decision Analytic Intelligent Systems: Automated Explanation and Knowledge Acquisition, Lawrence Erlbaum Associates.</title>
<date>1994</date>
<contexts>
<context position="8089" citStr="Klein 1994" startWordPosition="1305" endWordPosition="1306">measure of an objective&apos;s strength, a predicate indicating whether an objective should be included in an argument (i.e., worth mentioning) can be defined as follows: s-notably-compelling?(o,opop,e, refo) ≡ s-compellingness(o, e, refo)&gt;μ x+kσx , where − o, e, and refo are defined as in the previous Def; opop is an objective population (e.g., siblings(o)), and opop&gt;2 − p∈ opop; x∈X = s-compellingness(p, e, refo) − μ x is the mean of X, σx is the standard deviation and k is a user-defined constant Similar measures for the comparison of two entities are defined and extensively discussed in (Klein 1994). 2.3 The constant k In the definition of s-notably-compelling?, the constant k determines the lower bound of scompellingness for an objective to be included in an argument. As shown in Figure 2, for k=0 only objectives with s-compellingness greater Figure 3 Arguments about the same house, tailored to the same subject but with k ranging from 1 to –1 than the average s-compellingness in a population are included in the argument (4 in the sample population). For higher positive values of k less objectives are included (only 2, when k=1), and the opposite happens for negative values (8 objectives</context>
</contexts>
<marker>Klein, 1994</marker>
<rawString>Klein, D. (1994). Decision Analytic Intelligent Systems: Automated Explanation and Knowledge Acquisition, Lawrence Erlbaum Associates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J C Lester</author>
<author>B W Porter</author>
</authors>
<title>Developing and Empirically Evaluating Robust Explanation Generators:</title>
<date>1997</date>
<journal>The KNIGHT Experiments.” Computational Linguistics</journal>
<volume>23</volume>
<issue>1</issue>
<pages>65--101</pages>
<marker>Lester, Porter, 1997</marker>
<rawString>Lester, J. C. and B. W. Porter (March 1997). “Developing and Empirically Evaluating Robust Explanation Generators: The KNIGHT Experiments.” Computational Linguistics 23(1): 65-101.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K J Mayberry</author>
<author>R E Golden</author>
</authors>
<title>For Argument&apos;s Sake: A Guide to Writing Effective Arguments, Harper Collins,</title>
<date>1996</date>
<publisher>College Publisher.</publisher>
<contexts>
<context position="2894" citStr="Mayberry and Golden 1996" startWordPosition="423" endWordPosition="426">tive arguments can be measured with real users. Next, we describe the design of an experiment we ran within the framework to verify the influence of argument conciseness on argument effectiveness. We conclude with a discussion of the experiment’s results. 2 Generating concise evaluative arguments Often an argument cannot mention all the available evidence, usually for the sake of brevity. According to argumentation theory, the selection of what evidence to mention in an argument should be based on a measure of the evidence strength of support (or opposition) to the main claim of the argument (Mayberry and Golden 1996). Furthermore, argumentation theory suggests that for evaluative arguments the measure of evidence strength should be based on a model of the intended reader’s values and preferences. Following argumentation theory, we have designed an argumentative strategy for generating evaluative arguments that are properly arranged and concise (Carenini and Moore 2000). In our strategy, we assume that the reader’s values and preferences are represented as an additive multiattribute value function (AMVF), a conceptualization based on multiattribute utility theory (MAUT)(Clemen 1996). This allows us to adop</context>
</contexts>
<marker>Mayberry, Golden, 1996</marker>
<rawString>Mayberry, K. J. and R. E. Golden (1996). For Argument&apos;s Sake: A Guide to Writing Effective Arguments, Harper Collins, College Publisher.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McConachy</author>
<author>K B Korb</author>
</authors>
<title>Deciding What Not to Say: An Attentional-Probabilistic Approach to Argument Presentation. Cognitive Science Conference.</title>
<date>1998</date>
<marker>McConachy, Korb, 1998</marker>
<rawString>McConachy, R., K. B. Korb, et al. (1998). Deciding What Not to Say: An Attentional-Probabilistic Approach to Argument Presentation. Cognitive Science Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Olso</author>
<author>M P Zanna</author>
</authors>
<title>Attitudes and beliefs ; Attitude change and attitude-behavior consistency.</title>
<date>1991</date>
<journal>Social</journal>
<contexts>
<context position="13695" citStr="Olso and Zanna 1991" startWordPosition="2232" endWordPosition="2235">rts in a final questionnaire (see Figure 6 for an example of self-report) and include: - Measures of behavioral intentions and attitude change: (a) whether or not the user adopts the new proposed alternative, (b) in which position in the Hot List she places it and (c) how much she likes the new alternative and the other objects in the Hot List. - A measure of the user’s confidence that she has selected the best for her in the set of alternatives. - A measure of argument effectiveness derived by explicitly questioning the user at the end of the interaction about the rationale for her decision (Olso and Zanna 1991). This can provide valuable information on what aspects of the argument were more influential (i.e., better understood and accepted by the user). - An additional measure of argument effectiveness is to explicitly ask the user at the end of the interaction to judge the argument with respect to several dimensions of quality, such as content, organization, writing style and convincigness. However, evaluations based on a) How would you judge the houses in your Hot List? The more you like the house the closer you should put a cross to “good choice” 1st house bad choice : _:_ :_ :_ :_ :_ :_ :_ : : g</context>
</contexts>
<marker>Olso, Zanna, 1991</marker>
<rawString>Olso, J. M. and M. P. Zanna (1991). Attitudes and beliefs ; Attitude change and attitude-behavior consistency. Social Psychology. R. M. Baron and W. G. Graziano.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Robin</author>
<author>K McKeown</author>
</authors>
<title>Empirically Designing and Evaluating a New Revision-Based Model for Summary Generation.”</title>
<date>1996</date>
<journal>Artificial Intelligence journal</journal>
<volume>85</volume>
<pages>135--179</pages>
<contexts>
<context position="1316" citStr="Robin and McKeown 1996" startWordPosition="185" endWordPosition="188"> our framework to verify the influence of argument conciseness on argument effectiveness 1 Introduction Empirical methods are critical to gauge the scalability and robustness of proposed approaches, to assess progress and to stimulate new research questions. In the field of natural language generation, empirical evaluation has only recently become a top research priority (Dale, Eugenio et al. 1998). Some empirical work has been done to evaluate models for generating descriptions of objects and processes from a knowledge base (Lester and Porter March 1997), text summaries of quantitative data (Robin and McKeown 1996), descriptions of plans (Young to appear) and concise causal arguments (McConachy, Korb et al. 1998). However, little attention has been paid to the evaluation of systems generating evaluative arguments, communicative acts that attempt to affect the addressee’s attitudes (i.e. evaluative tendencies typically phrased in terms of like and dislike or favor and disfavor). The ability to generate evaluative arguments is critical in an increasing number of online systems that serve as personal assistants, advisors, or shopping assistants1. For instance, a shopping assistant may need to compare two s</context>
</contexts>
<marker>Robin, McKeown, 1996</marker>
<rawString>Robin, J. and K. McKeown (1996). “Empirically Designing and Evaluating a New Revision-Based Model for Summary Generation.” Artificial Intelligence journal 85: 135-179.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S F Roth</author>
<author>M C Chuah</author>
</authors>
<title>Towards an Information Visualization Workspace: Combining Multiple Means of Expression. Human-Computer Interaction Journal.</title>
<date>1997</date>
<marker>Roth, Chuah, 1997</marker>
<rawString>Roth, S. F., M. C. Chuah, et al. (1997). Towards an Information Visualization Workspace: Combining Multiple Means of Expression. Human-Computer Interaction Journal.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M R Young</author>
</authors>
<title>Using Grice&apos;s Maxim of Quantity to Select the</title>
<journal>Content of Plan Descriptions.” Artificial Intelligence Journal,</journal>
<note>to appear.</note>
<marker>Young, </marker>
<rawString>Young, M. R. “Using Grice&apos;s Maxim of Quantity to Select the Content of Plan Descriptions.” Artificial Intelligence Journal, to appear.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>