<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000089">
<title confidence="0.993737">
Parsing preferences with Lexicalized Tree Adjoining Grammars:
exploiting the derivation tree
</title>
<author confidence="0.863601">
Alexandra KINYON
</author>
<affiliation confidence="0.622767">
TALANA
</affiliation>
<address confidence="0.6167085">
Universite Paris 7, case 7003,
2p1Jussieu 75005 Paris France
</address>
<email confidence="0.476406">
Alexandra .Kinyon@linguist. jussieu fr
</email>
<sectionHeader confidence="0.510597" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999332272727273">
Since Kimball (73) parsing preference
principles such as &amp;quot;Right association&amp;quot;
(RA) and &amp;quot;Minimal attachment&amp;quot; (MA) are
often formulated with respect to
constituent trees. We present 3 preference
principles based on &amp;quot;derivation trees&amp;quot;
Within the framework of LTAGs. We
argue they remedy some shortcomings of
the former approaches and account for
widely accepted heuristics (e.g.
argument/modifier, idioms...).
</bodyText>
<sectionHeader confidence="0.958225" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.96782504">
The inherent characteristics of LTAGs (i.e.
lexicalization, adjunction, an extended domain of
locality and &amp;quot;mildly-context sensitive&amp;quot; power)
makes it attractive to Natural Language
Processing : LTAGs are parsable in polynomial
time and allow an elegant and
psycholinguistically plausible representation of
natural language&apos;. Large coverage grammars
were developed for English (Xtag group (95))
and French (Abeille (91)). Unfortunately, &amp;quot;large&amp;quot;
grammars yield high ambiguity rates : Doran &amp;
al. (94) report 7.46 parses / sentence on a WSJ
corpus of 18730 sentences using a wide coverage
English grammar. Srinivas &amp; al. (95) formulate
domain independent heuristics to rank parses.
But this approach is practical, English-oriented,
not explicitly linked to psycholinguistic results,
and does not fully exploit &amp;quot;derivation&amp;quot;
&apos; e.g. Frank (92) discusses the psycholinguistic
relevance of adjunction for Children Language
Acquisition, Joshi (90) discusses psycholinguistic
results on crossed and serial dependencies.
information. In this paper, we present 3
disambiguation principles which exploit
derivation trees.
</bodyText>
<sectionHeader confidence="0.795272" genericHeader="method">
1. Brief presentation of LTAGs
</sectionHeader>
<bodyText confidence="0.993913133333333">
A LTAG consists of a finite set of
elementary trees of finite depth. Each
elementary tree must «anchor» one or more
lexical item(s). The principal anchor is called
«head», other anchors are called «co-heads». All
leaves in elementary trees are either «anchor»,
«foot node» (noted *) or «substitution node»
(noted 4). These trees are of 2 types : auxiliary
or initia12. A tree has at most 1 foot-node, such a
tree is an auxiliary tree. Trees that are not
auxiliary are initial. Elementary trees combine
with 2 operations : substitution and adjunction.
Substitution is compulsory and is used essentially
for arguments (subject, verb and noun
complements). It consists in replacing in a tree
(elementary or not) a node marked for
substitution with an initial tree that has a root of
same category. Adjunction is optional (although
it can be forbidden or made compulsory using
specific constraints) and deals essentially with
detertniners, modifiers, auxiliaries, modals,
raising verbs (e.g. seem). It consists in inserting
in a tree in place of a node X an auxiliary tree
with a root of same category. The descendants of
X then become the descendants of the foot node
of the auxiliary tree. Contrary to context-free
rewriting rules, the history of derivation must be
made explicit since the same derived tree can be
obtained using different derivations. This is why
parsing LTAGs yields a derivation tree, from
</bodyText>
<footnote confidence="0.910969">
2 Traditionally initial trees are called (x, and
auxiliary trees /3
</footnote>
<page confidence="0.998171">
585
</page>
<bodyText confidence="0.985181833333333">
which a derived tree (i.e. constituent tree) can be
obtained. (Figure 1)3 . Branches in a derivation
tree are unordered.
Moreover, linguistic constraints on the well-
formedness of elementary trees have been
formulated:
</bodyText>
<listItem confidence="0.998445285714286">
• Predicate Argument Cooccurence Principle :
there must be a leaf node for each realized
argument of the head of an elementary tree.
• Semantic consistency : No elementary tree is
semantically void
• Semantic minimality : an elementary tree
corresponds at most to one semantic unit
</listItem>
<sectionHeader confidence="0.743076" genericHeader="method">
2. Former results on parsing preferences
</sectionHeader>
<bodyText confidence="0.9930724">
A vast literature addresses parsing preferences.
Structural approaches introduced 2 principles:
RA accounts for the preferred reading of the
ambiguous sentence (a) : &amp;quot;yesterday&amp;quot; attaches to
&amp;quot;left&amp;quot; and not to &amp;quot;said&amp;quot; (Kimball (73)).
</bodyText>
<listItem confidence="0.560995">
MA accounts for the preferred reading of (b) :
&amp;quot;for Sue&amp;quot; attaches to &amp;quot;bought&amp;quot; and not to
&amp;quot;flowers&amp;quot; (Frazier &amp; Fodor (78))
(a) Tom said that Joe left yesterday
(b)Tom bought the flowers for Sue
</listItem>
<bodyText confidence="0.995343382352941">
These structural principles have been criticized
though : Among other things, the interaction
between these principles is unclear. This type of
approach lacks provision for integration with
semantics and/or pragmatics (Schubert (84)),
does not clearly establish the distinction between
arguments and modifiers (Ferreira &amp; Clifton
(86)) and is English-biased : evidence against RA
has been found for Spanish (Cuetos &amp; Mitchell
(88)) and Dutch (Brysbaert &amp; Mitchell (96)).
Some parsing preferences are widely accepted,
though:
The idiomatic interpretation of a sentence is
favored over its literal interpretation (Gibbs &amp;
Nayak (89)).
Arguments are preferred over modifiers (Abney
(89), Britt &amp; al. (92)).
Additionally, lexical factors (e.g. frequency of
subcategorization for a given verb) have been
shown to influence parsing preferences (Hindle &amp;
Rooth (93)).
It is striking that these three most consensual
types of syntactic preferences turn out to be
difficult to formalize by resorting only to
&amp;quot;constituent trees&amp;quot; , but easy to formalize in
terms of LTAGs.
Before explaining our approach, we must
underline that the examples4 presented later on
are not necessarily counter-examples to RA and
or MA, but just illustrations : our goal is not to
further criticize RA and MA, but to show that
problems linked to these &amp;quot;traditional&amp;quot; structural
approaches do not automatically condemn all
structural approaches.
</bodyText>
<sectionHeader confidence="0.881707" genericHeader="method">
3 Three preference principles based on
derivation trees
</sectionHeader>
<bodyText confidence="0.999474444444444">
For sake of brevity, we will not develop the
importance of &amp;quot;lexical factors&amp;quot;, but just note that
LTAGs are obviously well suited to represent
that type of preferences because of strong
lexicalization5.
To account for the &amp;quot;idiomatic&amp;quot; vs &amp;quot;literal&amp;quot;, and
for the &amp;quot;argument&amp;quot; vs &amp;quot;modifier&amp;quot; preferences, we
formulate three parsing preference principles
based on the shape of derivation trees:
</bodyText>
<listItem confidence="0.9967592">
1. Prefer the derivation tree with the fewer
number of nodes
2. Prefer to attach an ct-tree low 6
3. Prefer the derivation tree with the fewer
number of fl-tree nodes
</listItem>
<bodyText confidence="0.969446769230769">
Principle 1 takes precedence over principle 2 and
principle 2 takes precedence over principle 3.
3 Our examples follow linguistic analyses presented
in (Abeille (91)), except that we substitute sentential
complements when no extraction occurs. Thus we
use no VP node and no Wh nor NP traces. But this
has no incidence on the application of our preference
principles.
4 These examples are kept simple on purpose, for
sake of clarity.
5 Also, &amp;quot;lexical preferences&amp;quot; and &amp;quot;structural
preferences&amp;quot; are not necessarily antagonistic and can
both be used for practical purpose.
</bodyText>
<footnote confidence="0.651648">
6 By low we mean &amp;quot;as far as possible from the root&amp;quot;.
</footnote>
<page confidence="0.994732">
586
</page>
<subsectionHeader confidence="0.988803">
3.1 What these principles account for
</subsectionHeader>
<bodyText confidence="0.999418125">
Principle 1 accounts for the preference
&amp;quot;idiomatic&amp;quot; over &amp;quot;literal&amp;quot;: In LTAGs, all the set
elements of an idiomatic expression are present in
a single elementary tree. Figure 1 shows the 2
derivation trees obtained when parsing
&amp;quot;Yesterday John kicked the bucket&amp;quot;. The
preferred one (i.e. idiomatic interpretation) has
fewer nodes.
</bodyText>
<figure confidence="0.969700573529412">
13-yesterday a-John
Adv S* John
Yesterday
a-John 13-the al-Organizer a-Demonstration
11%1
Det N* Organizer Demonstration
The
al-suspects a2-Organizer
NI* V N14. Organizer PP
Suspects a2-suspects of
Prep NI*
a-bucket -the
Det
The
Bucket
John
a-kicked
NOw V N1 &apos;l&apos;
kicked
a-kicked-the-bucket
NO w V
kicked Det N
I I
the bucket
NOL V N1+ PP
Suspects Prep pay
of
Elementary trees for
&amp;quot;Yesterday John kicked the bucket&amp;quot;
Elementary trees for
&amp;quot;John suspects the organizer of the demonstration&amp;quot;
N/r
a-kicked-the-bucket
a-John 13-yesterday
&apos;Preferred derivation tree
&amp;quot;NZ
a-kicked
a-John a-bucket 13-yesterday
(3-the
IDispreferred derivation tree
al-suspects a2-suspects
a-John a2 anizer a-John al-Or anizer a-Demonstration
13-the a-Demonstration 13-the 13-the
0 -the
Preferred derivation tree Dispreferred derivation tree
Adv
Yesterday V
John kicked Det N
the bucket
Both derivation trees yield the same derived tree
FIGURE 17
Illustration of Principle 1
7 In derivation trees, plain lines indicate an
adjunction, dotted lines a substitution.
V N N V N PP
I I I I /■
John suspects Bei N John Suspects Det N Prep N
7.\ / /■,
The Organizer pp The Organizer of Det N
I
the demonstration
Prep
Corresponding derived trees
of Det N
I I
the demonstration
FIGURE 2
Illustration of Principle 2
</figure>
<page confidence="0.984787">
587
</page>
<bodyText confidence="0.939599111111111">
for French (Abeille &amp; Candito (99)). We kept
the1074 grammatical ones (i.e. noted &amp;quot;1&amp;quot; in the
TSNLP terminology) of category S or augmented
to S (excluding coordination ) that were accepted.
A human picked one or more &amp;quot;correct&amp;quot;
derivations for each sentence parsed&apos;. Principle 1,
and then Principles 1 &amp; 2 were applied on the
derivation trees to eliminate some derivations.
Table 1 shows the results obtained.
</bodyText>
<table confidence="0.999827740740741">
Before After After
applying applying applying
principles principle1 principles
1 &amp; 2
Total # of 1074 1074 1074
sentences
Total # of 3057 2474 2334
derivations
# of 1070 1055 1054
sentences (99.6 %) (98.2 %) (98.1 %)
with at
least 1
correct
parse
# of 537 427 424
ambiguous
sentences
# of non 537 647 650
ambiguous
sentences
# of n.a. 89 86
partially
clisambigua
ted
sentences
# ofparses 2.85 2.3 2.17
/ sentence
</table>
<tableCaption confidence="0.569034">
TABLE 1 : results for TSNLP
</tableCaption>
<subsectionHeader confidence="0.994966">
4.1 Comments on the results
</subsectionHeader>
<bodyText confidence="0.889035636363636">
After disambiguating with principles 1 and 2, the
proportion of sentences with at least one parse
judged correct by a human only marginally
decreased while the average number of parses per
More than one derivation was deemed &amp;quot;correct&amp;quot;
when non spurious ambiguity remained in modifier
attachment (e.g. He saw the man with a telescope)
sentence went down from 2.85 to 2.17 (i.e. —24
%).
Since &amp;quot;strict modifier attachment&amp;quot; is orthogonal
to our concern, a sentence such as (f) still yields
5 derivations, partly because of spurious
ambiguity, partly because of adverbial
attachment (i.e. &amp;quot;hier&amp;quot; attached to S or to V).
09 11 a travaille hier (He worked yesterday)
Therefore most sentences aren&apos;t disambiguated by
principles 1 or 2, especially those anchoring an
intransitive verb. For sentences that are affected
by at least one of these two principles, the
average number of parses per sentence goes
down from 6.76 to 2.94 after applying both
principles (i.e. — 56.5 %). (Table 2).
</bodyText>
<table confidence="0.991524071428571">
Before After After
applying applying applying
principles principle principles
1 1 &amp; 2
# of 189 189 189
sentences
affected by
at least one
principle
# of 1279 696 556
derivations
# of 6.77 3.68 2.94
parses/sent
ence
</table>
<tableCaption confidence="0.8175265">
TABLE 2 : Results for sentences affected by
at least one Principle
</tableCaption>
<subsectionHeader confidence="0.9741275">
4.2 The gap between theory and
practice
</subsectionHeader>
<bodyText confidence="0.999187538461538">
Surprisingly, Principle 1 was used in only one
case to prefer an idiomatic interpretation, but
proved very useful in preferring arguments over
modifiers : derivation trees with arguments often
have fewer nodes because of co-heads. For
instance it systematically favored the attachment
of &amp;quot;by&amp;quot; phrases as passive with agent.
Principle 2 favored lower attachment of
arguments as in (g) but proved useful only in
conjunction with Principle 1 : it provided further
disambiguation by selecting derivation trees
among those with an equally low number of
nodes.
</bodyText>
<page confidence="0.995538">
588
</page>
<bodyText confidence="0.996728">
Principle 2 says to attach an argument low (e.g.
to the direct object of the main verb) rather than
high (e.g. to the verb). In (el), &amp;quot;of the
demonstration&amp;quot; attaches to &amp;quot;organizer&amp;quot; rather
than to &amp;quot;suspect&amp;quot;, while in (c2) &amp;quot;of the crime&amp;quot; can
only attach to the verb. Figure 2 shows how
principle 2 yields the preferred derivation tree for
sentence (c1). Similarly, in sentence (d1) &amp;quot;to
whom&amp;quot; attaches to &amp;quot;say&amp;quot; rather than to &amp;quot;give&amp;quot;,
while in (d2) it attaches to &amp;quot;give&amp;quot; since &amp;quot;think&amp;quot;
can not take a PP complement. This agrees with
psycholinguistic results such as &amp;quot;filled gap
effects&amp;quot; (Crain &amp; Fodor (85)).
</bodyText>
<listItem confidence="0.958012428571429">
(cl) John suspects the organizer of the
demonstration
(c2) John suspects Bill of the crime
(d1) To whom does Mary say that John
gives flowers.
(d2) To whom does Mary think that John
gives flowers.
</listItem>
<bodyText confidence="0.975848181818182">
Principle 3 prefers arguments over modifiers.
Figure 3 shows that principle 3 predicts the
preferred derivation tree for (e) : &amp;quot;to be honest&amp;quot;
argument of &amp;quot;prefer&amp;quot;, ruling out &amp;quot;to be honest&amp;quot; as
sentence modifier (i.e. &amp;quot;To be honest, he prefers
his daughter&amp;quot;).
(e) John prefers his daughter to be honest.
These three principles aim at attaching arguments
as accurately as possible and do not deal with
&amp;quot;strict&amp;quot; modifier attachment for the following
reasons:
</bodyText>
<listItem confidence="0.987379777777778">
• There is a lack of agreement concerning the
validity of preferences principles for
&amp;quot;modifier attachment&amp;quot;
• Principle 3, which deals the most with
modifier attachment, turned out the least
conclusive when confronted to empirical data
• We wanted to evaluate how attaching
arguments correctly affects ambiguity, all
other factors remaining unchanged.
</listItem>
<sectionHeader confidence="0.93037" genericHeader="method">
4 Some results
</sectionHeader>
<bodyText confidence="0.90922375">
French sentences from the test suite developed in
the TSNLP project (Estival &amp; Lehman (96))
were originally parsed using Xtag with a domain
independent wide-coverage grammar
</bodyText>
<figure confidence="0.999197317073171">
al-Prefer
NO+ V NI+ Vinf+
Prefers
a2-Prefer
NO+ V N1+
Prefers
13-Be
S* Prep Vinf&apos;
to V Adj+
Be
a-Be
Vinf
Prep Vinf&apos;
to V Adj+
Be
Elementary trees
&amp;quot;John prefers his daughter to be honest&amp;quot;
I—a-John
N N N dj
I /N Ai
John daughter Det N* Honest
I
His
a-daughter 0-his a-honest
al-Prefer a2-Prefer
a-John a-daughter a-Be a-John a-daughter -Be
13-his a-honest 13-his a-honest
&apos;Preferred derivation tree Dispreferred derivation tree
NV N Vinf
I l AN
S Prep Vinf&apos;
/N I
Be Honest His Daughter
Corresponding derived trees
FIGURE 3
Illustration of Principle 3
John Prefers pet N Prep Vinf&apos;
/1
his daughter to V Ad John Prefers Det N be honest
?N V N To V Ad
\----•■•
</figure>
<page confidence="0.717326">
589
</page>
<construct confidence="0.341788333333333">
(g)- L&apos;ingenieur obtient 1&apos;accord de l&apos;entreprise
(The engineer obtains the agreement of the
company/from the company)
</construct>
<bodyText confidence="0.9849215">
Principle 3 did not prove as useful as the two
others : first, it aims at favoring arguments over
modifiers, but these cases were already handled
by Principle I (again because of co-heads).
Second, it consistently made wrong predictions
in cases of lexical ambiguity (e.g it favored &amp;quot;etre&amp;quot;
as a copula rather than as an auxiliary, although
the auxiliary is much more common in French.).
Therefore we have postponed testing it until
further refinement is found.
</bodyText>
<sectionHeader confidence="0.999643" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999928157894737">
We have presented three application-independent,
domain-independent and language-independent
disambiguation principles formulated in terms of
derivation trees within the framework of LTAGs.
But since they are straightforward to implement,
these principles can be used for parse ranking
applications or integrated into a parser to reduce
non determinism. Preliminary results are
encouraging as to the soundness of at least two of
these principles. Further work will focus on
testing these principles on larger corpora (e.g. Le
Monde) as well as on other languages, refining
them for practical purposes (e.g. addition of
frequency information and principles for
modifiers attachment). Since it is the first time to
our knowledge that parsing preferences are
formulated in terms of derivation trees, it would
also be interesting to see how this could be
adapted to dependency-based parsing.
</bodyText>
<sectionHeader confidence="0.999447" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999648423728813">
Abeille A. (1991) Une grammaire lexicalisee
d&apos;arbres adjoints pour le francais. PhD
dissertation.. Universite Paris 7.
Abeilld A., Candito M.H. (1999) F7&apos;AG : A LTAG
for French. In Tree Adjoining Grammars. Abeille,
Rambow(eds). CSLI, Stanford.
Abney S. (1989) A computational model of human
parsing. Journal of psycholinguistic Research, 18,
129-144.
Britt M, Perfetti C., Garrod S, Rayner K. (1992)
Parsing and discourse : Context effects and their
limits. Journal of memory and language, 31, 293-
314.
Brysbaert M., Mitchell D.C. (1996) Modifier
Attachment in sentence parsing : Evidence from
Dutch. Quarterly journal of experimental
psychology, 49a, 664-695.
Crain S., Fodor J.D. (1985) How can grammars help
parsers? In Natural language parsing..
94-127. D. Dowty, L. Karthmen, A. Zwicky (eds).
Cambridge University Press.
Cuetos F., Mitchell D.C. (1988) Cross linguistic
differences in parsing: restrictions on the use of
the Late Closure strategy in Spanish. Cognition,
30,73-105.
Doran C., Egedi D., Hockey B.A., Srinivas B.,
Zakiel M. (1994) Xtag System- a wide coverage
grammar for English. COLING&apos;94. Kyoto. Japan.
Estival D., Lehman S (1997) TSNLP: des jeux de
phrases test pour le TALN, TAL 38:1, 115-172
Ferreira F. Clifton C. (1986) The independence of
syntactic processing. Journal of Memory and
Language, 25,348-368,
Frank R. (1992) Syntactic Locality and Tree
Adjoining Grammar : Grammatical Acquisition
and Processing Perspectives. PhD dissertation.
University of Pennsylvania.
Frazier L, Fodor J.D. (1978) &amp;quot;The sausage machine&amp;quot;
: a new two stage parsing model. Cognition 6.
Gibbs R., Nayak (1989) Psycholinguistic studies on
the syntactic behaviour of idioms. Cognitive
Psychology, 21, 100-138.
Hindle D. Rooth M. (1993) Structural ambiguity and
lexical relations. Computational Linguistics, 19,
pp.103-120.
Joshi A. (1990) Processing crossed and serial
dependencies: an automaton perspective on the
psycholinguistic results. Language and cognitive
processes, 5:1, 1-27.
Kimball J. (1973) Seven principles of surface
structure parsing in natural language. Cognition
2.
Schubert L. (1984). On parsing preferences.
COLING&apos;84, Stanford. 247-250.
Srinivas B., Doran C., Kulick S. (1995) Heuristics
and Parse Ranking. 4&apos;11 international workshop on
Parsing Technologies.. Prag. Czech Republic.
Xtag group (1995) A LTAG for English. Technical
Report IRCS 95-03. University of Pennsylvania.
</reference>
<page confidence="0.997333">
590
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.188368">
<title confidence="0.9983625">Parsing preferences with Lexicalized Tree Adjoining Grammars: exploiting the derivation tree</title>
<author confidence="0.999765">Alexandra KINYON</author>
<affiliation confidence="0.705987">TALANA Universite Paris 7, case 7003,</affiliation>
<address confidence="0.682669">2p1Jussieu 75005 Paris France</address>
<author confidence="0.819546">jussieu fr</author>
<abstract confidence="0.953069333333333">Since Kimball (73) parsing preference principles such as &amp;quot;Right association&amp;quot; (RA) and &amp;quot;Minimal attachment&amp;quot; (MA) are often formulated with respect to constituent trees. We present 3 preference principles based on &amp;quot;derivation trees&amp;quot; Within the framework of LTAGs. We argue they remedy some shortcomings of the former approaches and account for widely accepted heuristics (e.g. argument/modifier, idioms...).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Abeille</author>
</authors>
<title>Une grammaire lexicalisee d&apos;arbres adjoints pour le francais.</title>
<date>1991</date>
<tech>PhD dissertation..</tech>
<institution>Universite Paris</institution>
<marker>Abeille, 1991</marker>
<rawString>Abeille A. (1991) Une grammaire lexicalisee d&apos;arbres adjoints pour le francais. PhD dissertation.. Universite Paris 7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Abeilld</author>
<author>M H Candito</author>
</authors>
<title>F7&apos;AG : A LTAG for French. In Tree Adjoining Grammars. Abeille,</title>
<date>1999</date>
<location>Rambow(eds). CSLI, Stanford.</location>
<marker>Abeilld, Candito, 1999</marker>
<rawString>Abeilld A., Candito M.H. (1999) F7&apos;AG : A LTAG for French. In Tree Adjoining Grammars. Abeille, Rambow(eds). CSLI, Stanford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Abney</author>
</authors>
<title>A computational model of human parsing.</title>
<date>1989</date>
<journal>Journal of psycholinguistic Research,</journal>
<volume>18</volume>
<pages>129--144</pages>
<marker>Abney, 1989</marker>
<rawString>Abney S. (1989) A computational model of human parsing. Journal of psycholinguistic Research, 18, 129-144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Britt</author>
<author>C Perfetti</author>
<author>S Garrod</author>
<author>K Rayner</author>
</authors>
<title>Parsing and discourse : Context effects and their limits.</title>
<date>1992</date>
<journal>Journal of memory and language,</journal>
<volume>31</volume>
<pages>293--314</pages>
<marker>Britt, Perfetti, Garrod, Rayner, 1992</marker>
<rawString>Britt M, Perfetti C., Garrod S, Rayner K. (1992) Parsing and discourse : Context effects and their limits. Journal of memory and language, 31, 293-314.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Brysbaert</author>
<author>D C Mitchell</author>
</authors>
<title>Modifier Attachment in sentence parsing : Evidence from Dutch. Quarterly journal of experimental psychology,</title>
<date>1996</date>
<pages>49--664</pages>
<marker>Brysbaert, Mitchell, 1996</marker>
<rawString>Brysbaert M., Mitchell D.C. (1996) Modifier Attachment in sentence parsing : Evidence from Dutch. Quarterly journal of experimental psychology, 49a, 664-695.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Crain</author>
<author>J D Fodor</author>
</authors>
<title>How can grammars help parsers?</title>
<date>1985</date>
<booktitle>In Natural language</booktitle>
<pages>94--127</pages>
<publisher>Cambridge University Press.</publisher>
<marker>Crain, Fodor, 1985</marker>
<rawString>Crain S., Fodor J.D. (1985) How can grammars help parsers? In Natural language parsing.. 94-127. D. Dowty, L. Karthmen, A. Zwicky (eds). Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Cuetos</author>
<author>D C Mitchell</author>
</authors>
<title>Cross linguistic differences in parsing: restrictions on the use of the Late Closure strategy in Spanish.</title>
<date>1988</date>
<journal>Cognition,</journal>
<pages>30--73</pages>
<marker>Cuetos, Mitchell, 1988</marker>
<rawString>Cuetos F., Mitchell D.C. (1988) Cross linguistic differences in parsing: restrictions on the use of the Late Closure strategy in Spanish. Cognition, 30,73-105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Doran</author>
<author>D Egedi</author>
<author>B A Hockey</author>
<author>B Srinivas</author>
<author>M Zakiel</author>
</authors>
<title>Xtag System- a wide coverage grammar for English.</title>
<date>1994</date>
<tech>COLING&apos;94. Kyoto. Japan.</tech>
<marker>Doran, Egedi, Hockey, Srinivas, Zakiel, 1994</marker>
<rawString>Doran C., Egedi D., Hockey B.A., Srinivas B., Zakiel M. (1994) Xtag System- a wide coverage grammar for English. COLING&apos;94. Kyoto. Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Estival</author>
<author>S Lehman</author>
</authors>
<title>TSNLP: des jeux de phrases test pour le TALN,</title>
<date>1997</date>
<journal>TAL</journal>
<volume>38</volume>
<pages>115--172</pages>
<marker>Estival, Lehman, 1997</marker>
<rawString>Estival D., Lehman S (1997) TSNLP: des jeux de phrases test pour le TALN, TAL 38:1, 115-172</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ferreira F Clifton C</author>
</authors>
<title>The independence of syntactic processing.</title>
<date>1986</date>
<journal>Journal of Memory and Language,</journal>
<pages>25--348</pages>
<marker>C, 1986</marker>
<rawString>Ferreira F. Clifton C. (1986) The independence of syntactic processing. Journal of Memory and Language, 25,348-368,</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Frank</author>
</authors>
<title>Syntactic Locality and Tree Adjoining Grammar : Grammatical Acquisition and Processing Perspectives. PhD dissertation.</title>
<date>1992</date>
<institution>University of Pennsylvania.</institution>
<marker>Frank, 1992</marker>
<rawString>Frank R. (1992) Syntactic Locality and Tree Adjoining Grammar : Grammatical Acquisition and Processing Perspectives. PhD dissertation. University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Frazier</author>
<author>J D Fodor</author>
</authors>
<title>The sausage machine&amp;quot; : a new two stage parsing model.</title>
<date>1978</date>
<journal>Cognition</journal>
<volume>6</volume>
<marker>Frazier, Fodor, 1978</marker>
<rawString>Frazier L, Fodor J.D. (1978) &amp;quot;The sausage machine&amp;quot; : a new two stage parsing model. Cognition 6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Gibbs</author>
<author>Nayak</author>
</authors>
<title>Psycholinguistic studies on the syntactic behaviour of idioms.</title>
<date>1989</date>
<journal>Cognitive Psychology,</journal>
<volume>21</volume>
<pages>100--138</pages>
<marker>Gibbs, Nayak, 1989</marker>
<rawString>Gibbs R., Nayak (1989) Psycholinguistic studies on the syntactic behaviour of idioms. Cognitive Psychology, 21, 100-138.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hindle D Rooth M</author>
</authors>
<title>Structural ambiguity and lexical relations.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<pages>103--120</pages>
<marker>M, 1993</marker>
<rawString>Hindle D. Rooth M. (1993) Structural ambiguity and lexical relations. Computational Linguistics, 19, pp.103-120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Joshi</author>
</authors>
<title>Processing crossed and serial dependencies: an automaton perspective on the psycholinguistic results. Language and cognitive processes,</title>
<date>1990</date>
<volume>5</volume>
<pages>1--27</pages>
<marker>Joshi, 1990</marker>
<rawString>Joshi A. (1990) Processing crossed and serial dependencies: an automaton perspective on the psycholinguistic results. Language and cognitive processes, 5:1, 1-27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kimball</author>
</authors>
<title>Seven principles of surface structure parsing in natural language.</title>
<date>1973</date>
<journal>Cognition</journal>
<volume>2</volume>
<marker>Kimball, 1973</marker>
<rawString>Kimball J. (1973) Seven principles of surface structure parsing in natural language. Cognition 2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Schubert</author>
</authors>
<title>On parsing preferences.</title>
<date>1984</date>
<pages>84--247</pages>
<marker>Schubert, 1984</marker>
<rawString>Schubert L. (1984). On parsing preferences. COLING&apos;84, Stanford. 247-250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Srinivas</author>
<author>C Doran</author>
<author>S Kulick</author>
</authors>
<date>1995</date>
<booktitle>Heuristics and Parse Ranking. 4&apos;11 international workshop on Parsing Technologies..</booktitle>
<location>Prag. Czech Republic.</location>
<marker>Srinivas, Doran, Kulick, 1995</marker>
<rawString>Srinivas B., Doran C., Kulick S. (1995) Heuristics and Parse Ranking. 4&apos;11 international workshop on Parsing Technologies.. Prag. Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xtag group</author>
</authors>
<title>A LTAG for English.</title>
<date>1995</date>
<tech>Technical Report IRCS 95-03.</tech>
<institution>University of Pennsylvania.</institution>
<marker>group, 1995</marker>
<rawString>Xtag group (1995) A LTAG for English. Technical Report IRCS 95-03. University of Pennsylvania.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>