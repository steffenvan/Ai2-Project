<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.628817">
A TOOL FOR INVESTIGATING THE SYNONYMY RELATION
IN A SENSE DISAMBIGUATED THESAURUS
Martin S. Chodorow
IBM T.J. Watson Research Center
</note>
<author confidence="0.79926">
Yorktown Heights, New York 10598
</author>
<affiliation confidence="0.8485355">
and
Department of Psychology, 1-hinter College of CUNY
</affiliation>
<address confidence="0.626092">
New York, New York 10021
</address>
<author confidence="0.559702">
Yael Ravin
</author>
<affiliation confidence="0.4565535">
IBM T.J. Watson Research Center
Yorktown Heights, New York 10598
</affiliation>
<author confidence="0.77087">
Howard E. Sachar
</author>
<affiliation confidence="0.7057005">
IBM Data Systems Division
White Plains, New York 10601
</affiliation>
<sectionHeader confidence="0.976665" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999647875">
This paper describes an exploration of the
implicit synonymy relationship expressed by
synonym lists in an on-line thesaurus. A series
of automatic steps was taken to properly con-
strain this relationship. The resulting groupings
of semantically related word senses are believed
to constitute a useful tool for natural language
processing and for work in lexicography.
</bodyText>
<sectionHeader confidence="0.910977" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.995689775510204">
The importance of semantic processing of
natural language i:, generally acknowledged
(Grishman 1986) and needs no justification.
Work on applications such as information re-
trieval or machine translation has consistently
focused on semantic analysis. A wide range of
models has been suggested, based on semantic
networks, on fuzzy logic, on conceptual de-
pendencies and more. Common to all these
models, however, is the researchers&apos; reliance
on hand-built semantic databases. These da-
tabases tend to be rather limited in scope and
often restricted to narrow domains. If the
process of constructing them remains manual,
broad-coverage semantic analysis by comput-
ers will be severely handicapped for quite a
long time. It is our goal, therefore, to explore
automatic and semi-automatic ways of con-
structing these semantic databases, through the
manipulation of machine-readable semantic
sources. In this paper, we concentrate on
heuristics for the automatic manipulation of
synonyms found in an on-line thesaurus.
First, we should clarify what we mean by
&amp;quot;synonyms&amp;quot;. The definition of synonymy and
the existence of synonyms have long been de-
bated in linguistics. Some believe it is impos-
sible to capture meaning, not even of the most
concrete terms in natural language. Conse-
quently, it is impossible to define synonymy
or to identify synonymous terms (Quine 1960).
Others believe it is possible to give full seman-
tic representations of meaning and therefore to
define synonymy formally and to identify true
synonyms (Katz and Fodor 1963). According
to this view, synonymy is a relationship of
sameness of meaning between words, which is
defined as the identity of their semantic rep-
resentations.
We have chosen an operational approach
to synonymy: The synonyms of a headword w
are whatever words are listed in the entry for
w in an on-line version of The New Collins
Thesaurus (1984) (CT)) According to the au-
thors, &amp;quot;...no synonym is entered unless it is
fully substitutable for the headword in a sensi-
We have stored CT as a DAM file (Byrd, et al., 1986) with 16,794 keyed records containing a total of 287,136 syn-
onym tokens. It has been supplemented with part-of-speech information from the tJDICT computerized lexicon
system (Byrd, 1986).
</bodyText>
<page confidence="0.997674">
144
</page>
<bodyText confidence="0.999720586206897">
ble English sentence&amp;quot; (Collins 1984:v). This
may suggest that each entry (i.e., a headword
and its synonym list) contains all and only
words that are closely related semantically. But
the same synonyms appear in several lists, and
headwords are themselves synonyms of other
headwords, so that the lists in CT are implic-
itly interconnected. We seek algorithms to
process all the words that are interconnected
in the thesaurus into sets which share crucial
semantic features.
In the first section of this paper, we char-
acterize the properties of the CT intercon-
nections that we discovered in our
manipulation of the CT links. Because of the
asymmetric and intransitive nature of these
links, our main difficulty has been to devise
proper means of control to keep the computed
sets of words closely related in meaning. In the
second section, we describe our first control
measure - our manipulation of senses of words
rather than of words themselves. In the third
section, we describe automatic ways of pruning
the semantic trees we obtain. In the final sec-
tion, we illustrate how this work can benefit
various natural language applications by pro-
viding automatic access to semantically related
word senses and an automatic means for
measuring semantic distance.
</bodyText>
<subsectionHeader confidence="0.921259">
Properties of CT-synonyms
</subsectionHeader>
<bodyText confidence="0.999432">
In the context of CT, a strong criterion for
defining a set of words which share crucial se-
mantic features is a criterion which requires
every member of the set to be a synonym of
every other member. The words in such a set
would exhibit symmetric and transitive links.
There are 27 sets of words in CT which are
symmetric and transitive. Within the context
of the thesaurus, these may be considered to
have identical meaning. 26 out of the 27 are
word pairs - the 27th is a triple - and all have
a single sense and a unique part of speech.&apos;
These sets are given below.
Most of the synonymy links in CT are mark-
edly different from these. 62% are asymmetric
(e.g., part has department as a synonym, but
department does not have part); and 65% are
non-transitive (e.g., part has piece as a syno-
nym; piece has chunk as a synonym; but part
does not have chunk as a synonym).3 This
asymmetry and non-transitivity have been
noted by others (Dewdney 1987). Thus, in or-
der to obtain semantic sets for most of the
words in the thesaurus, symmetry and transi-
tivity are too strict. An algorithm which per-
mits asymmetric and non-transitive links must
be developed. (See Warnesson 1985 for a dif-
ferent approach.)
According to the substitutability definition
of synonymy adopted by Collins, links should
always be symmetric since if it is possible to
substitute b for a in a &amp;quot;sensible&amp;quot; English con-
text, then it is always possible to reintroduce a
</bodyText>
<figure confidence="0.96426425925926">
allocate
aphorism
astonishing
at times
bystander
cemetery
congratulate
eatable
entomb
everybody
exactitude
greetings
insomnia
lozenge
myopic
naught
perk
permeable
piddling
podium
prizefighter
prizefighting
saw
slattern
testy
triad
weal
</figure>
<equation confidence="0.96379025">
= allot
= apothegm
= astounding
= from_time_to_time
= eyewitness
= necropolis
= felicitate
= edible
= inter
= everyone
= exactness
= regards
= sleeplessness
= pastille
= near-sighted
= nought
= perquisite
= porous
piffling
= rostrum
= pugilist
= pugilism
= saying
= slut
= tetchy
= trinity
= = trio
welt
</equation>
<bodyText confidence="0.557781">
It should be noted that CT&apos;s vocabulary is limited. Thus, it does not contain the verb &amp;quot;perk&amp;quot; or the noun &amp;quot;saw&amp;quot; as
an instrument of cutting. The list of transitive and symmetric sets will vary with the size of the on-line source.
</bodyText>
<footnote confidence="0.942552666666667">
3 The percentage of non-transitive links does not include synonyms which have no entries in CT (see footnote 4); nor
does it include synonyms which could not be disambiguated (see the section on sense disambiguation). Thus 65% is
a conservative estimate.
</footnote>
<page confidence="0.998554">
145
</page>
<bodyText confidence="0.999744506666667">
into that context as a substitution for b. Nev-
ertheless, we have found at least five different
sources of asymmetry. 23% of the total
CT-synonyms are either phrases or rare and
colloquial words, which do not appear as main
entries in the thesaurus, such as dwelling place
(a synonym of abode) and digs (a synonym of
quarters).4 About 68%5 of the remaining
asymmetries appear to be mere oversights on
the part of the lexicographers. For example,
assembly has throng listed as a synonym of one
of its senses, but throng does not list assembly
as a synonym, although it does give
assemblage, congregation, multitude, and other
related words. Many of these omissions seem
to be due to the fact that rare, very formal or
metaphoric words tend not to be offered as
synonyms. This may explain why conversant,
familiar and informed, for example, are listed
as synonyms of cognizant, while cognizant is
not listed as their synonym. 18% are instances
of hypernymy (the superordinate relation).
For example, book lists manual as a synonym,
but manual does not list book; instead special
types of books such as handbook are given.
This is because book is really a hypernym (not
a synonym) of manual. llypernym links are
truly asymmetric in nature.
Two other sources account for the remain-
ing asymmetries: 8% of the asymmetric cases
result when a central sense of one word is
synonymous with a very peripheral sense of
another. One sense of say lists add, as in &amp;quot;lie
added that he would do the demonstration.&amp;quot;
The entry for add does not however contain
this peripheral sense and deals only with the
arithmetic add. Finally, 6% are due to vo-
cabulary inconsistencies. For example, record
has annals, archives and diary as synonyms;
whereas annals and archives have the plural
records; and diary has the phrase daily record.
We believe that the CT-synonyms are non-
transitive for many of these same reasons.
Is it possible to reach any noun in CT by
following the synonym links to and from any
other noun? The answer is NO, but almost.
Computing the transitive closure over the syn-
onyms of the noun house, where we include
the words listed in the entry for house and the
words whose entries list house as a synonym,
produces a grouping containing 89% of all the
nouns in CT. Obviously, with such a large
number of words, it is not surprising that most
bear little semantic relation to the root node.
The computational tool we have used for
computing the transitive closure over
synonymy is a program known as SPROUT.
It was originally used (Chodorow, et al., 1985)
to generate taxonomic trees from the hyponym
relation as extracted from Webster&apos;s Seventh
Collegiate Dictionary (Merriam 1963).
SPROUT starts with a root node and retrieves
from a designated file (in this case, a DAM file)
the words that bear the given relation to the
root. These words are the first-level
descendents (daughters) of the root. SPROUT
then applies recursively to each of the daughter
nodes, generating their daughters, etc. In this
way, the tree is generated in a breadth-first
fashion. The process is complete when the
only nodes that remain open are either termi-
nals (i.e., nodes that have no daughters) or
nodes that appear earlier in the tree, indicating
a cyclic structure. The house tree reached clo-
sure at the 11th level.
</bodyText>
<subsectionHeader confidence="0.90175">
Sense Disambiguation
</subsectionHeader>
<bodyText confidence="0.934189333333333">
Perhaps the diversity in meaning encount-
ered in the sprout of house came from consid-
ering nodes to he words. Words are, of course,
polysemous, so a better choice might be word
senses. The CT-entry of house is given below.
The numbers 1-6 indicate six different senses.
I. abode, building, domicile, dwelling,
edifice, habitation, home, homestead,
residence
</bodyText>
<listItem confidence="0.97589375">
2. family, household, menage
3. ancestry, clan, dynasty, family tree,
kindred, line, lineage, race, tribe
4. business, company, concern,
establishment, firm, organization, outfit
(*Informal), partnership
5. Commons, legislative body, parliament
6. hotel, inn, public house, tavern
</listItem>
<footnote confidence="0.747501">
4 We had to ignore these words in our subsequent manipulation of the CT-entries because they had no synonym lists.
Thus, the total number of synonyms available for processing is 221,957.
5 The following percentages were computed on the basis of fifty random entries.
</footnote>
<page confidence="0.99735">
146
</page>
<bodyText confidence="0.999829294117647">
The synonyms listed for each sense are not
separated into their senses. Consequently,
simply following the synonyms of house I will
not solve the problem unless each of the syn-
onyms for it (abode, ..., residence) is marked
with its appropriate sense. We have tried two
automatic methods of sense marking (i.e. sense
disambiguation): disambiguation by symmetry
and disambiguation by intersection.
In a dictionary-style thesaurus such as CT,
an entry A may have word B listed as a syno-
nym of its nth sense, and entry B may have
word A listed as a synonym of its mth sense.
We can mark B in entry A as the mth sense
of B, and A in entry B as the nth sense of A.
An example of this type of one-to-one map-
ping in CT is given below.
</bodyText>
<listItem confidence="0.9858064">
dense (adj) 1. ... condensed ... solid ....
2. ... dull ... stupid ...
dull (adj) 1. dense .... stupid ....
2. ... callous ... unsympathetic
7. drab ... muted.
</listItem>
<bodyText confidence="0.999924595744681">
Here, sense 1 of dull is synonymous with sense
2 of dense. 37% of the 287,000 synonym to-
kens show this type of symmetry. Of course,
there are also mappings of the one-to-many
variety (for example, only the first sense of
feeble has faint as its synonym, whereas both
senses 1 and 2 of faint have feeble), but they
account for only .5% of the tokens. By this
method of disambiguation-by-symmetry, we
could automatically mark the senses of all
synonyms in one-to-one and one-to-many re-
lations. The third type of mapping, many-to-
many, accounts for just .5% of the total, but
it poses a problem for the strategy outlined
above. This can best be seen by considering
an example. Senses 1 and 2 of institution list
establishment as a synonym, and senses 1 and
2 of establishment list institution. Is sense 1 of
institution synonymous with sense 1 of estab-
lishment or with sense 2? The distribution of
the terms institution and establishment cannot
answer the question.
The problem of many-to-many mappings
and the large percentage of asymmetric
CT-synonyms led us to another method.
Consider again the case of dense and dull.
Evidence for linking sense 2 of dense with
sense 1 of dull comes from the symmetric dis-
tribution of the two words in the entries.
There is however another piece of evidence for
linking sense 2 of dense with sense 1 of dull,
and that is the co-occurrence of the word stu-
pid in their synonym lists. Thus, the inter-
sections of synonym lists serve as the basis for
an automatic disambiguation of the many-to-
many mappings, and, for that matter, for the
disambiguation of the whole CT. This is sim-
ilar to Lesk&apos;s suggestion for disambiguating
hypemyms (Lesk 1986). The intersection
method disambiguated more entries than the
symmetry method, but it, too, left a certain
percentage of ambiguous words. In some
cases, the intersection of two words was null.
For example: successful and victorious are
symmetric synonyms but none of their other
synonyms are shared. Their entries are given
below.&apos;
</bodyText>
<equation confidence="0.922689461538462">
SUCCESSFUL:
&gt; &gt; Oacknowledged$ at_the_top_of the_tree$99
best-selling$99 booming$99 efficacious$
favourable$ flourishing$0 fortunate$1.2
fruitful$3 lucky$1 lucrative$0
moneymaking$0 out_infront$99 paying$99
profitable$1 prosperous$1 rewarding$0
thriving$0 top$ unbeaten$1 victorious$
wealthy$0
VICTORIOUS:
&gt; &gt; Ochampion$ conquering$99 first$
prizewinning$99 successful$
triumphant$0 vanquishing$99 winning$2
</equation>
<bodyText confidence="0.501943823529412">
In other cases, there was a tie. For example,
ripe2 has equal-size intersections with both
perfect I and perfect4. In their following en-
tries, ties are indicated by a pair of numbers
joined by a period.
PERFECT:
&gt; &gt; labsolute$1 complete$1.3 completed$99
consummate$2 entire$1.3 finished$2 full$1
out-and-out$ sheer$2 unadulterated$99
unalloyed $99 unmitigated$2 utter$99 whole$1
&gt; &gt; 4accomplished$2 adept$1 experienced$1
expert$2 finished$1 masterly$0 polished$
practised$ skilful$0 skilled$0
RIPE:
&gt; &gt; 2accomplished$1 complete$2 finished$
in_readiness$ perfect$1.4 prepared $ 1
ready$ I
</bodyText>
<page confidence="0.715679">
6 The number following the dollar sign indicates the sense number. No number indicates that the intersection is null
</page>
<bodyText confidence="0.9254835">
and therefore a sense number was not picked up. 99 indicates that the word has no entry in CT and consequently
no sense numbers. 0 means that there was only one sense given in the entry.
</bodyText>
<page confidence="0.950516">
147
</page>
<bodyText confidence="0.6771829">
(*BritishSlang), stony-broke (*BritishSlang)
2. deficient, exiguous, inadequate,
incomplete, insufficient, lacking, meagre,
miserable, niggardly, pitiable, reduced,
scanty, skimpy, slight, sparse, straitened
3. below par, faulty, feeble, inferior,
low-grade, mediocre, rotten (*Informal),
rubbishy, second-rate, shabby, shoddy,
sorry, substandard, unsatisfactory,
valueless, weak, worthless
</bodyText>
<figureCaption confidence="0.589383625">
4. bad, bare, barren, depleted, exhausted,
fruitless, impoverished, infertile, sterile,
unfruitful, unproductive
5. hapless, ill-fated, luckless, miserable,
pathetic, pitiable, unfortunate, unhappy,
unlucky, wretched
6. humble, insignificant, lowly, mean,
modest, paltry, plain, trivial
</figureCaption>
<bodyText confidence="0.999032333333334">
The symmetry method linked feeble2 with
poor3, whereas the intersection method linked
feeble2 with poor2. The remaining 4 cases
were somewhat clearer. In 3, the intersection
method performed better; in one, the symme-
try method was superior. To conclude, the
best disambiguation algorithm would be a
combination of the two methods. We are cur-
rently studying more cases where the methods
disagree in order to determine how they should
be combined. In the following, though, we rely
on disambiguation by intersection.
No disambiguation resulted in either of these
cases. The results obtained with each method
are shown in the following table:
</bodyText>
<table confidence="0.9994481">
by symmetry:
sense disambiguated: 103,648 (46.7%)
ties: 1,662 ( 0.7%)
remainder: 116,647 (52.5%)
Total number of synonyms
available for processing: 221,957
by intersection:
sense disambiguated: 179,126 (80.7%)
ties: 6,029 ( 2.7%)
remainder: 36,802 (16.6%)
</table>
<tableCaption confidence="0.679243">
Total number of synonyms
available for processing: 221,957
</tableCaption>
<figureCaption confidence="0.988789">
Figure I. Disambiguation Results
</figureCaption>
<bodyText confidence="0.982368571428571">
The quantitative advantage of the inter-
section method is evident. To determine the
qualitative difference, we studied cases where
the symmetry and the intersection methods
conflicted. We compared fifty randomly se-
lected entries. Of the approximately 900 syno-
nyms listed in the entries, 337 were
disambiguated by both methods. Of these,
there were 33 pairs for which the two methods
disagreed. 20 were symmetric ties,
disambiguated by the intersection method. 5
were intersection ties, disambiguated by the
symmetry method. The remaining 8 were given
to two human reviewers. In 3 out of the 8, the
reviewers could not determine which of the
methods provided better disambiguation, as
shown in the following example.
FEEBLE:
I. debilitated, delicate, doddering, effete,
enervated, enfeebled, etiolated, exhausted,
failing, faint, frail, infirm, languid,
powerless, puny, shilpit (*Scottish),
sickly, weak, weakened
2. flat, flimsy, inadequate, incompetent,
indecisive, ineffective, ineffectual,
inefficient, insignificant, insufficient,
lame, paltry, poor, slight, tame, thin,
unconvincing, weak
POOR:
1. badly off, broke (*Informal), destitute,
hard up (*Informal), impecunious,
impoverished, indigent, in need, in want,
necessitous, needy, on one&apos;s beam-ends, on
one&apos;s uppers, on the rocks, penniless,
penurious, poverty-stricken, skint
</bodyText>
<page confidence="0.957402">
7 As before, sense numbers follow the dollar sign.
</page>
<bodyText confidence="0.988040411764706">
Transitivity
After numbering each token in CT by sense
and disambiguating senses, we sprouted from
the first sense of house. Each node in the new
sprout is not a word anymore, but a specific
(numbered) sense of a word. Words not
disambiguated by the intersection method were
ignored in the new sprout. Sense
disambiguation did not significantly improve
the results of the sprout. The sprouting closure
of house! contains 85% of the total number
of noun senses in CT.
Using senses instead of words, we recom-
puted the number of sets which are symmetric
and transitive (see section on CT-properties
above) and found 86. Given below are some
of the new sets.7
</bodyText>
<page confidence="0.905205833333333">
adhesive$2
beak$1
conservatory$0
draw$11
gjade$3
g,rouch$2
</page>
<bodyText confidence="0.836646833333333">
= glue$1 = paste$1
= bill$5
= hothouse$1
= tie$7
= gradient$0
= grouse$2 = grumble$3
</bodyText>
<page confidence="0.909533">
148
</page>
<bodyText confidence="0.90809247368421">
myopic$0
poison$1
spectator$0
well-off$2
wolf$2
= near-sighted$0
= venom$1
= witness$1
= well-to-do $0
= womanizer$0
= short-sightedlibtal noun senses in CT. Closure was reached
at the 4th level. The first following list in-
cludes most of the nodes that were rejected by
the pruning method. The second list includes
most of the nodes that were accepted.&apos;
Why is sense disambiguation so ineffective
in restricting the number of nodes encountered
in sprouting? Consider for example the
thesaurus separation into senses for building:
</bodyText>
<listItem confidence="0.97504125">
1. domicile, dwelling, edifice, fabric,
house, pile, structure
2. architecture, construction, erection,
fabricating, raising
</listItem>
<bodyText confidence="0.996043">
Sense 2 is a mixture of the act of building, the
object built, and its design. This indicates that
poor sense separation in CT is responsible for
spuriously related word senses. We feel that a
reliable indication of poor sense separation in
CT might be an intersection of two synonyms
which is of the size 1. For example, the inter-
section of building2 and erectionl contains
only construction.
</bodyText>
<listItem confidence="0.901754">
Erection:
1. assembly, building, construction,
creation, elevation, establishment,
fabrication, manufacture
2. building, construction, edifice, pile,
structure
</listItem>
<bodyText confidence="0.99942516">
By ignoring CT links with intersections of size
1 we were able to eliminate some of the prob-
lematic senses and reduce the sprout to include
only 76% of the total CT-nouns, as opposed
to the previous 85%.
In an attempt to maintain semantic con-
tent, we have explored automatically pruning
the sprout tree when a semantically irrelevant
branch is generated. Before any CT-synonym
is accepted as a node of the tree, its
descendents are checked against the immediate
descendents of the root node. If their inter-
section is not null, the node is accepted into
the sprout tree. We have experimented with a
few variations: choosing either the daughters
or both daughters and granddaughters of either
the root node or the branch node. We have
also varied the size of the intersection. A
promising scheme involves checking the
daughters of each node against the daughters
and granddaughters of the root, discarding
nodes whose intersection is of size I. When
pruned this way, the sprout tree of housel
reached transitive closure with a total of 173
noun senses, which constitute 1.4% of the
</bodyText>
<equation confidence="0.9049216875">
2-home$3 2-fabric$2 3-barracks$0
3-assembly$2 3-composition$1 3-erection$1
3-fabrication$1 3-figure$3 3-form$7
3-formation$2 3-shape$1
3-design$4 3-malce$12 3-making$1
3-manufacture$3 3-mould$2 3-organization$1
3-production$1 3-house $2 3-point$2
3-orientation$1 3-quarter$1 4-chamber$1
4-framework$0 4-system$1 4-anatomy$2
4-build$4 4-hull$1 4-physique$0
4-rack$1 4-skeleton$0 4-arrangement$1
4-configuration$0 4-format$0
4-organization$2 4-architecture$2
4-tum$17 4-conformation$0
4-constitution$2 4-method$2
4-entourage$2 4-field$3 4-aspect$2
0-house $1 1-abode$0 1-building$1
1-domicile$0 1-dwelling$0 1-edifice $0
1-habitation$1 1-home$1 1-residence$1
1-address$1 1-establishment$4 1-place$5
1-seat$4 2-lodging$0 2-quarters$0
2-lodgings$0 2-mansion$0 2-pile$4
2-structure $2 2-construction$1
2-erection $2 2-household$1 2-pad $4
2-location$0 2-situation$1
2-whereabouts$0 3-accommodation$2
3-billet$1 3-apartment$0 3-frame$4
3-make-up$2 3-structure$1 3-bearings$0
3-locale$0 3-place$1 3-position$1
3-site$1 3-spot$2 3-emplacement$1
3-locality$2 3-seat$2 3-setting$0
3-station$1 3-environment$0 3-scene$2
</equation>
<sectionHeader confidence="0.388503" genericHeader="method">
Applications
</sectionHeader>
<bodyText confidence="0.949548733333333">
One way in which sprout trees of syno-
nyms may prove to be useful is in measuring
the semantic distance between words. It is
possible, for example, to sprout from two dif-
ferent root nodes until their trees intersect, that
is, until they have a common node, which,
with further sprouting, will become a common
branch. We believe that a common node in-
dicates a common semantic aspect and that an
algorithm for measuring semantic distance be-
tween words can be formulated on the basis
of the common nodes of their trees. Intuitively,
the algorithm will depend on the number of
8 The number preceding the word indicates the level on which it was encountered in the tree. The number following
the dollar sign indicates its sense number.
</bodyText>
<page confidence="0.997344">
149
</page>
<bodyText confidence="0.972242837837838">
common branches and on the level at which
they occur in the respective trees. Here we are
taking a somewhat simple view in considering
only the first common node encountered. Our
SYNCHAIN program produces simultane-
ously two sprout trees from two root nodes.
After all words on a level are encountered in
the two trees, the program checks whether the
trees intersect. It stops when a common node
is encountered. The user specifies the two root
nodes and the level to which the trees should
be sprouted. The program provides a common
node, if one was encountered. This is illus-
trated in the two following examples:
synchain apartment$0 house$1 3
apartment$0 -&gt; place$5 &lt;- house$1
synchain apartment$0 suit$5 3
chain could not be constructed
In the first example, the apartment$0 tree and
the house$1 tree intersect on their first level.
Both have placeS5 as their daughter. In the
second example, the apartment$0 tree and the
suitS5 tree (in the meaning of garment) do not
intersect as far as the third level. This suggests
that the word senses of the first pair are much
closer in meaning than those of the second.
This distinction can assist in the analysis
of natural language text (for purposes of
translation, text critiquing •and others), by
providing semantic information to a syntactic
parser. In particular, we have in mind a parser
such as the PLNLP English Parser, PEG
(Jensen 1986), which cannot resolve cases of
syntactic ambiguity on its own. Consider the
following pair of sentences with their PLNLP
analyses:
the man visited the apartment in the house.
</bodyText>
<sectionHeader confidence="0.897134444444445" genericHeader="method">
DECL NP DET ADJ* &amp;quot;the&amp;quot;
NOUN* &amp;quot;man&amp;quot;
VERB* &amp;quot;visited&amp;quot;
NP DET ADJ* &amp;quot;the&amp;quot;
NOUN* &amp;quot;apartment&amp;quot;
PP PREP &amp;quot;in&amp;quot;
DET ADJ* &amp;quot;the&amp;quot;
NOUN* &amp;quot;house&amp;quot;
PUNC &amp;quot;.&amp;quot;
</sectionHeader>
<figureCaption confidence="0.991">
Figure 2. Parse Tree I
</figureCaption>
<figure confidence="0.386307166666667">
the man visited the apartment in a white suit.
DECL NP DET ADJ* &amp;quot;the&amp;quot;
NOUN* &amp;quot;man&amp;quot;
VERB1* &amp;quot;visited&amp;quot;
NP DET ADJ* &amp;quot;the&amp;quot;
NOUN* &amp;quot;apartment&amp;quot;
</figure>
<sectionHeader confidence="0.5439998" genericHeader="method">
PP PREP &amp;quot;in&amp;quot;
DET ADJ* &amp;quot;a&amp;quot;
AJP ADJ* &amp;quot;white&amp;quot;
NOUN* &amp;quot;suit&amp;quot;
PUNC &amp;quot;.&amp;quot;
</sectionHeader>
<figureCaption confidence="0.983179">
Figure 3, Parse Tree 2
</figureCaption>
<bodyText confidence="0.889047466666667">
PEG produces similar analyses for the two
sentences, where the prepositional phrases are
attached to the closest head, that is, to the
noun apartment. A question mark indicates an
alternate attachment to the verb visited. Se-
mantic information is needed to resolve the
attachment ambiguity (Jensen and Binot
1986). Our measure of semantic distance can
determine the proper attachment in this case.
If the two nouns are semantically close, the
attachment displayed by PEG is the more
plausible one. If the two nouns are seman-
tically distant, the alternate attachment is more
plausible.
An automatic measure of semantic distance
can assist information retrieval systems as well.
One can conceive of a system which will re-
trieve documents containing synonyms of
the key word by first searching for a very re-
strictive set of synonyms (first-level synonyms
perhaps). If not enough documents are re-
trieved, words that are more distant seman-
tically can be searched for as well. Another
application for which a sprouted synonym tree
is ireful is third-generation on-line dictionary
systems (Neff, et al., 1988). Among other
things, these systems display synonyms to us-
ers who are editing natural language texts. The
list of synonyms presented by the system can
be arranged according to the semantic distance
between the word interrogated and the words
on the synonym list. It should be noted, how-
ever, that for this application, words need to
be arranged according to additional parameters
as well. Synonyms that are polysemous or rare
may be poor substitution candidates in a gen-
eral text.
Finally, we are now investigating the pos-
sible use of our tools by lexicographers who
wish to update and revise an existing on-line
thesaurus. Easy access to asymmetric links, to
synonyms with very small intersecting lists, to
lists of words that are pruned from sprout
trees, and to any other sorted information that
we can provide automatically should make the
</bodyText>
<page confidence="0.991276">
150
</page>
<bodyText confidence="0.9997298">
work of lexicographers much more easily
manageable. Our goal is to develop a tool that
will automatically locate all different types of
inconsistencies and oversights in the thesaurus
(Ravin, et al., in preparation).
</bodyText>
<sectionHeader confidence="0.638318" genericHeader="conclusions">
Conclusion
</sectionHeader>
<bodyText confidence="0.999963923076923">
We have explored the nature of the implicit
synonym links in CT and have found it com-
plex but promisingly rich. Our goal is to con-
tinue to improve the automatic extraction of
information from this source, until we form
acceptable sets of semantically related words.
These sets will have to satisfy both human
intuitions about meaning and some more the-
oretic linguistic criteria. To these sets, we will
add information from other on-line sources.
This direction of research seems promising as
a first step towards the automatic organization
of meaning.
</bodyText>
<sectionHeader confidence="0.998984" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.999625847457627">
Byrd. R. J. (1986), &amp;quot;Dictionary Systems for
Office Practice,&amp;quot; Proceedings of the Grosseto
Workshop &amp;quot;On Automating the Lexicon&amp;quot;. Also
available as IBM Research Report RC 11872.
Byrd, R. J., G Neumann, and K. S. B.
Andersson (1986) &amp;quot;DAM - A Dictionary Ac-
cess Method,&amp;quot; IBM Research Report.
Chodorow, M. S., R. J. Byrd, and G. E.
Heidom (1985) &amp;quot;Extracting Semantic Hierar-
chies from a Large On-line Dictionary,&amp;quot; Pro-
ceedings of the Association for Computational
Linguistics, 299-304.
Collins (1984) The New Collins Thesaurus,
Collins Publishers, Glasgow.
Dewdney, A. K. (1987) &apos;Word ladders and a
tower of Babel lead to computational heights
defying assault,&amp;quot; Scientific American, August
1987, 108-111.
Grislunan, R. (1986) Computational
Linguistics, Cambridge University Press,
Cambridge.
Jensen, Karen (1986) &amp;quot;PEG 1986: A Broad-
coverage Computational Syntax of English,&amp;quot;
Unpublished paper.
Jensen, Karen and Jean-Louis Binot (1987)
&amp;quot;Disambiguating Prepositional Phrase Attach-
ments by Using On-Line Dictionary Defi-
nitions,&amp;quot; to appear in Computational
Linguistics, special issue on the lexicon. Also
available as IBM Research Report RC 12148.
Katz, J. and J. Fodor (1963) &amp;quot;The Structure
of a Semantic Theory,&amp;quot; Language, 34,
2:170-210
Lesk, M. (1986) &amp;quot;Automatic sense
disambiguation using machine-readable dic-
tionaries: How to tell a pine cone from an ice
cream cone,&amp;quot; Proceedings of 1986 SIGDOC
Conference, Canada.
Marcotorchino, F. (1986) &amp;quot;Maximal Associ-
ation Theory&amp;quot;, in Classification as a Tool for
Research, W. Gaul and M. Schader, eds.,
North holland.
Merriam (1963) Webster&apos;s Seventh New
Collegiate Dictionary, G. &amp; C. Merriam,
Springfield, Massachusetts.
Neff, M. S., R. J. Byrd, and 0. A. Rizk (1988),
&amp;quot;Creating and Querying Lexical Data Bases,&amp;quot;
ACL Second Conference on Applied Natural
Language Processing.
Quine, W. (1960) Word and Object, MIT
Press, Cambridge, Massachusetts.
Ravin, Y., M. Chodorow, and II. Sachar (in
preparation) &amp;quot;Tools for lexicographers revising
an on-line thesaurus.&amp;quot;
Wamesson, I. (1985) &amp;quot;Optimization of Se-
mantic Relations by Data Aggregation Tech-
niques,&amp;quot; Journal of Applied Stochastic Models
and Data Analysis, 1,2 (December), J. Wiley,
New York.
</reference>
<page confidence="0.998341">
151
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.141934">
<title confidence="0.9987045">A TOOL FOR INVESTIGATING THE SYNONYMY RELATION IN A SENSE DISAMBIGUATED THESAURUS</title>
<author confidence="0.999968">Martin S Chodorow</author>
<affiliation confidence="0.999626">T.J. Research Center</affiliation>
<address confidence="0.801582">Yorktown Heights, New York 10598</address>
<affiliation confidence="0.8282925">and Department of Psychology, 1-hinter College of CUNY</affiliation>
<address confidence="0.966248">New York, New York 10021</address>
<author confidence="0.761316">Yael Ravin</author>
<affiliation confidence="0.999404">T.J. Research Center</affiliation>
<address confidence="0.979978">Yorktown Heights, New York 10598</address>
<author confidence="0.998753">Howard E Sachar</author>
<affiliation confidence="0.986859">Systems Division</affiliation>
<address confidence="0.423572">White Plains, New York 10601</address>
<abstract confidence="0.996276222222222">paper describes an exploration the implicit synonymy relationship expressed by synonym lists in an on-line thesaurus. A series of automatic steps was taken to properly constrain this relationship. The resulting groupings of semantically related word senses are believed to constitute a useful tool for natural language processing and for work in lexicography.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R J</author>
</authors>
<title>Dictionary Systems for Office Practice,&amp;quot;</title>
<date>1986</date>
<booktitle>Proceedings of the Grosseto Workshop &amp;quot;On Automating the Lexicon&amp;quot;. Also available as IBM Research Report RC</booktitle>
<pages>11872</pages>
<marker>J, 1986</marker>
<rawString>Byrd. R. J. (1986), &amp;quot;Dictionary Systems for Office Practice,&amp;quot; Proceedings of the Grosseto Workshop &amp;quot;On Automating the Lexicon&amp;quot;. Also available as IBM Research Report RC 11872.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R J Byrd</author>
<author>G Neumann</author>
<author>K S B Andersson</author>
</authors>
<title>DAM - A Dictionary Access Method,&amp;quot;</title>
<date>1986</date>
<journal>IBM Research Report.</journal>
<contexts>
<context position="2835" citStr="Byrd, et al., 1986" startWordPosition="444" endWordPosition="447"> meaning and therefore to define synonymy formally and to identify true synonyms (Katz and Fodor 1963). According to this view, synonymy is a relationship of sameness of meaning between words, which is defined as the identity of their semantic representations. We have chosen an operational approach to synonymy: The synonyms of a headword w are whatever words are listed in the entry for w in an on-line version of The New Collins Thesaurus (1984) (CT)) According to the authors, &amp;quot;...no synonym is entered unless it is fully substitutable for the headword in a sensiWe have stored CT as a DAM file (Byrd, et al., 1986) with 16,794 keyed records containing a total of 287,136 synonym tokens. It has been supplemented with part-of-speech information from the tJDICT computerized lexicon system (Byrd, 1986). 144 ble English sentence&amp;quot; (Collins 1984:v). This may suggest that each entry (i.e., a headword and its synonym list) contains all and only words that are closely related semantically. But the same synonyms appear in several lists, and headwords are themselves synonyms of other headwords, so that the lists in CT are implicitly interconnected. We seek algorithms to process all the words that are interconnected </context>
</contexts>
<marker>Byrd, Neumann, Andersson, 1986</marker>
<rawString>Byrd, R. J., G Neumann, and K. S. B. Andersson (1986) &amp;quot;DAM - A Dictionary Access Method,&amp;quot; IBM Research Report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M S Chodorow</author>
<author>R J Byrd</author>
<author>G E</author>
</authors>
<title>Heidom</title>
<date>1985</date>
<booktitle>Proceedings of the Association for Computational Linguistics,</booktitle>
<pages>299--304</pages>
<contexts>
<context position="9322" citStr="Chodorow, et al., 1985" startWordPosition="1545" endWordPosition="1548">in CT by following the synonym links to and from any other noun? The answer is NO, but almost. Computing the transitive closure over the synonyms of the noun house, where we include the words listed in the entry for house and the words whose entries list house as a synonym, produces a grouping containing 89% of all the nouns in CT. Obviously, with such a large number of words, it is not surprising that most bear little semantic relation to the root node. The computational tool we have used for computing the transitive closure over synonymy is a program known as SPROUT. It was originally used (Chodorow, et al., 1985) to generate taxonomic trees from the hyponym relation as extracted from Webster&apos;s Seventh Collegiate Dictionary (Merriam 1963). SPROUT starts with a root node and retrieves from a designated file (in this case, a DAM file) the words that bear the given relation to the root. These words are the first-level descendents (daughters) of the root. SPROUT then applies recursively to each of the daughter nodes, generating their daughters, etc. In this way, the tree is generated in a breadth-first fashion. The process is complete when the only nodes that remain open are either terminals (i.e., nodes t</context>
</contexts>
<marker>Chodorow, Byrd, E, 1985</marker>
<rawString>Chodorow, M. S., R. J. Byrd, and G. E. Heidom (1985) &amp;quot;Extracting Semantic Hierarchies from a Large On-line Dictionary,&amp;quot; Proceedings of the Association for Computational Linguistics, 299-304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Collins</author>
</authors>
<title>The New Collins Thesaurus,</title>
<date>1984</date>
<publisher>Collins Publishers,</publisher>
<location>Glasgow.</location>
<contexts>
<context position="3062" citStr="Collins 1984" startWordPosition="479" endWordPosition="480"> semantic representations. We have chosen an operational approach to synonymy: The synonyms of a headword w are whatever words are listed in the entry for w in an on-line version of The New Collins Thesaurus (1984) (CT)) According to the authors, &amp;quot;...no synonym is entered unless it is fully substitutable for the headword in a sensiWe have stored CT as a DAM file (Byrd, et al., 1986) with 16,794 keyed records containing a total of 287,136 synonym tokens. It has been supplemented with part-of-speech information from the tJDICT computerized lexicon system (Byrd, 1986). 144 ble English sentence&amp;quot; (Collins 1984:v). This may suggest that each entry (i.e., a headword and its synonym list) contains all and only words that are closely related semantically. But the same synonyms appear in several lists, and headwords are themselves synonyms of other headwords, so that the lists in CT are implicitly interconnected. We seek algorithms to process all the words that are interconnected in the thesaurus into sets which share crucial semantic features. In the first section of this paper, we characterize the properties of the CT interconnections that we discovered in our manipulation of the CT links. Because of </context>
</contexts>
<marker>Collins, 1984</marker>
<rawString>Collins (1984) The New Collins Thesaurus, Collins Publishers, Glasgow.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Dewdney</author>
</authors>
<title>Word ladders and a tower of Babel lead to computational heights defying assault,&amp;quot; Scientific American,</title>
<date>1987</date>
<pages>108--111</pages>
<contexts>
<context position="5261" citStr="Dewdney 1987" startWordPosition="858" endWordPosition="859">ve. Within the context of the thesaurus, these may be considered to have identical meaning. 26 out of the 27 are word pairs - the 27th is a triple - and all have a single sense and a unique part of speech.&apos; These sets are given below. Most of the synonymy links in CT are markedly different from these. 62% are asymmetric (e.g., part has department as a synonym, but department does not have part); and 65% are non-transitive (e.g., part has piece as a synonym; piece has chunk as a synonym; but part does not have chunk as a synonym).3 This asymmetry and non-transitivity have been noted by others (Dewdney 1987). Thus, in order to obtain semantic sets for most of the words in the thesaurus, symmetry and transitivity are too strict. An algorithm which permits asymmetric and non-transitive links must be developed. (See Warnesson 1985 for a different approach.) According to the substitutability definition of synonymy adopted by Collins, links should always be symmetric since if it is possible to substitute b for a in a &amp;quot;sensible&amp;quot; English context, then it is always possible to reintroduce a allocate aphorism astonishing at times bystander cemetery congratulate eatable entomb everybody exactitude greeting</context>
</contexts>
<marker>Dewdney, 1987</marker>
<rawString>Dewdney, A. K. (1987) &apos;Word ladders and a tower of Babel lead to computational heights defying assault,&amp;quot; Scientific American, August 1987, 108-111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Grislunan</author>
</authors>
<title>Computational Linguistics,</title>
<date>1986</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<marker>Grislunan, 1986</marker>
<rawString>Grislunan, R. (1986) Computational Linguistics, Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karen Jensen</author>
</authors>
<title>PEG 1986: A Broadcoverage Computational Syntax of English,&amp;quot;</title>
<date>1986</date>
<note>Unpublished paper.</note>
<contexts>
<context position="24590" citStr="Jensen 1986" startWordPosition="3862" endWordPosition="3863">ee and the house$1 tree intersect on their first level. Both have placeS5 as their daughter. In the second example, the apartment$0 tree and the suitS5 tree (in the meaning of garment) do not intersect as far as the third level. This suggests that the word senses of the first pair are much closer in meaning than those of the second. This distinction can assist in the analysis of natural language text (for purposes of translation, text critiquing •and others), by providing semantic information to a syntactic parser. In particular, we have in mind a parser such as the PLNLP English Parser, PEG (Jensen 1986), which cannot resolve cases of syntactic ambiguity on its own. Consider the following pair of sentences with their PLNLP analyses: the man visited the apartment in the house. DECL NP DET ADJ* &amp;quot;the&amp;quot; NOUN* &amp;quot;man&amp;quot; VERB* &amp;quot;visited&amp;quot; NP DET ADJ* &amp;quot;the&amp;quot; NOUN* &amp;quot;apartment&amp;quot; PP PREP &amp;quot;in&amp;quot; DET ADJ* &amp;quot;the&amp;quot; NOUN* &amp;quot;house&amp;quot; PUNC &amp;quot;.&amp;quot; Figure 2. Parse Tree I the man visited the apartment in a white suit. DECL NP DET ADJ* &amp;quot;the&amp;quot; NOUN* &amp;quot;man&amp;quot; VERB1* &amp;quot;visited&amp;quot; NP DET ADJ* &amp;quot;the&amp;quot; NOUN* &amp;quot;apartment&amp;quot; PP PREP &amp;quot;in&amp;quot; DET ADJ* &amp;quot;a&amp;quot; AJP ADJ* &amp;quot;white&amp;quot; NOUN* &amp;quot;suit&amp;quot; PUNC &amp;quot;.&amp;quot; Figure 3, Parse Tree 2 PEG produces similar analyses for the tw</context>
</contexts>
<marker>Jensen, 1986</marker>
<rawString>Jensen, Karen (1986) &amp;quot;PEG 1986: A Broadcoverage Computational Syntax of English,&amp;quot; Unpublished paper.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karen Jensen</author>
<author>Jean-Louis Binot</author>
</authors>
<title>Disambiguating Prepositional Phrase Attachments by Using On-Line Dictionary Definitions,&amp;quot; to appear</title>
<date>1987</date>
<booktitle>in Computational Linguistics, special issue on the lexicon. Also available as IBM Research Report RC</booktitle>
<pages>12148</pages>
<marker>Jensen, Binot, 1987</marker>
<rawString>Jensen, Karen and Jean-Louis Binot (1987) &amp;quot;Disambiguating Prepositional Phrase Attachments by Using On-Line Dictionary Definitions,&amp;quot; to appear in Computational Linguistics, special issue on the lexicon. Also available as IBM Research Report RC 12148.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Katz</author>
<author>J Fodor</author>
</authors>
<title>The Structure of a Semantic Theory,&amp;quot;</title>
<date>1963</date>
<journal>Language,</journal>
<volume>34</volume>
<pages>2--170</pages>
<contexts>
<context position="2318" citStr="Katz and Fodor 1963" startWordPosition="352" endWordPosition="355">entrate on heuristics for the automatic manipulation of synonyms found in an on-line thesaurus. First, we should clarify what we mean by &amp;quot;synonyms&amp;quot;. The definition of synonymy and the existence of synonyms have long been debated in linguistics. Some believe it is impossible to capture meaning, not even of the most concrete terms in natural language. Consequently, it is impossible to define synonymy or to identify synonymous terms (Quine 1960). Others believe it is possible to give full semantic representations of meaning and therefore to define synonymy formally and to identify true synonyms (Katz and Fodor 1963). According to this view, synonymy is a relationship of sameness of meaning between words, which is defined as the identity of their semantic representations. We have chosen an operational approach to synonymy: The synonyms of a headword w are whatever words are listed in the entry for w in an on-line version of The New Collins Thesaurus (1984) (CT)) According to the authors, &amp;quot;...no synonym is entered unless it is fully substitutable for the headword in a sensiWe have stored CT as a DAM file (Byrd, et al., 1986) with 16,794 keyed records containing a total of 287,136 synonym tokens. It has bee</context>
</contexts>
<marker>Katz, Fodor, 1963</marker>
<rawString>Katz, J. and J. Fodor (1963) &amp;quot;The Structure of a Semantic Theory,&amp;quot; Language, 34, 2:170-210</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Lesk</author>
</authors>
<title>Automatic sense disambiguation using machine-readable dictionaries: How to tell a pine cone from an ice cream cone,&amp;quot;</title>
<date>1986</date>
<booktitle>Proceedings of 1986 SIGDOC Conference,</booktitle>
<contexts>
<context position="13560" citStr="Lesk 1986" startWordPosition="2269" endWordPosition="2270">er method. Consider again the case of dense and dull. Evidence for linking sense 2 of dense with sense 1 of dull comes from the symmetric distribution of the two words in the entries. There is however another piece of evidence for linking sense 2 of dense with sense 1 of dull, and that is the co-occurrence of the word stupid in their synonym lists. Thus, the intersections of synonym lists serve as the basis for an automatic disambiguation of the many-tomany mappings, and, for that matter, for the disambiguation of the whole CT. This is similar to Lesk&apos;s suggestion for disambiguating hypemyms (Lesk 1986). The intersection method disambiguated more entries than the symmetry method, but it, too, left a certain percentage of ambiguous words. In some cases, the intersection of two words was null. For example: successful and victorious are symmetric synonyms but none of their other synonyms are shared. Their entries are given below.&apos; SUCCESSFUL: &gt; &gt; Oacknowledged$ at_the_top_of the_tree$99 best-selling$99 booming$99 efficacious$ favourable$ flourishing$0 fortunate$1.2 fruitful$3 lucky$1 lucrative$0 moneymaking$0 out_infront$99 paying$99 profitable$1 prosperous$1 rewarding$0 thriving$0 top$ unbeate</context>
</contexts>
<marker>Lesk, 1986</marker>
<rawString>Lesk, M. (1986) &amp;quot;Automatic sense disambiguation using machine-readable dictionaries: How to tell a pine cone from an ice cream cone,&amp;quot; Proceedings of 1986 SIGDOC Conference, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Marcotorchino</author>
</authors>
<title>Maximal Association Theory&amp;quot;, in Classification as a Tool</title>
<date>1986</date>
<editor>for Research, W. Gaul and M. Schader, eds., North holland.</editor>
<marker>Marcotorchino, 1986</marker>
<rawString>Marcotorchino, F. (1986) &amp;quot;Maximal Association Theory&amp;quot;, in Classification as a Tool for Research, W. Gaul and M. Schader, eds., North holland.</rawString>
</citation>
<citation valid="true">
<title>Webster&apos;s Seventh New Collegiate Dictionary,</title>
<date>1963</date>
<journal>G. &amp; C.</journal>
<location>Merriam</location>
<marker>1963</marker>
<rawString>Merriam (1963) Webster&apos;s Seventh New Collegiate Dictionary, G. &amp; C. Merriam, Springfield, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M S Neff</author>
<author>R J Byrd</author>
</authors>
<title>Creating and Querying Lexical Data Bases,&amp;quot;</title>
<date>1988</date>
<booktitle>ACL Second Conference on Applied Natural Language Processing.</booktitle>
<marker>Neff, Byrd, 1988</marker>
<rawString>Neff, M. S., R. J. Byrd, and 0. A. Rizk (1988), &amp;quot;Creating and Querying Lexical Data Bases,&amp;quot; ACL Second Conference on Applied Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Quine</author>
</authors>
<title>Word and Object,</title>
<date>1960</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="2144" citStr="Quine 1960" startWordPosition="326" endWordPosition="327">ore automatic and semi-automatic ways of constructing these semantic databases, through the manipulation of machine-readable semantic sources. In this paper, we concentrate on heuristics for the automatic manipulation of synonyms found in an on-line thesaurus. First, we should clarify what we mean by &amp;quot;synonyms&amp;quot;. The definition of synonymy and the existence of synonyms have long been debated in linguistics. Some believe it is impossible to capture meaning, not even of the most concrete terms in natural language. Consequently, it is impossible to define synonymy or to identify synonymous terms (Quine 1960). Others believe it is possible to give full semantic representations of meaning and therefore to define synonymy formally and to identify true synonyms (Katz and Fodor 1963). According to this view, synonymy is a relationship of sameness of meaning between words, which is defined as the identity of their semantic representations. We have chosen an operational approach to synonymy: The synonyms of a headword w are whatever words are listed in the entry for w in an on-line version of The New Collins Thesaurus (1984) (CT)) According to the authors, &amp;quot;...no synonym is entered unless it is fully su</context>
</contexts>
<marker>Quine, 1960</marker>
<rawString>Quine, W. (1960) Word and Object, MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Y Ravin</author>
<author>M Chodorow</author>
</authors>
<title>Sachar (in preparation) &amp;quot;Tools for lexicographers revising an on-line thesaurus.&amp;quot;</title>
<marker>Ravin, Chodorow, </marker>
<rawString>Ravin, Y., M. Chodorow, and II. Sachar (in preparation) &amp;quot;Tools for lexicographers revising an on-line thesaurus.&amp;quot;</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Wamesson</author>
</authors>
<title>Optimization of Semantic Relations by Data Aggregation Techniques,&amp;quot;</title>
<date>1985</date>
<journal>Journal of Applied Stochastic Models and Data Analysis,</journal>
<volume>1</volume>
<publisher>J. Wiley,</publisher>
<location>New York.</location>
<marker>Wamesson, 1985</marker>
<rawString>Wamesson, I. (1985) &amp;quot;Optimization of Semantic Relations by Data Aggregation Techniques,&amp;quot; Journal of Applied Stochastic Models and Data Analysis, 1,2 (December), J. Wiley, New York.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>