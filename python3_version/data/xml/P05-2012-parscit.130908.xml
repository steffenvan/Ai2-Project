<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000092">
<title confidence="0.851108666666667">
Phrase Linguistic Classification and Generalization for Improving Statistical
Machine Translation
Adri`a de Gispert
</title>
<author confidence="0.432152">
TALP Research Center
Universitat Polit`ecnica de Catalunya (UPC)
</author>
<affiliation confidence="0.493127">
Barcelona
</affiliation>
<email confidence="0.995115">
agispert@gps.tsc.upc.es
</email>
<sectionHeader confidence="0.998562" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999837071428572">
In this paper a method to incorporate lin-
guistic information regarding single-word
and compound verbs is proposed, as a
first step towards an SMT model based
on linguistically-classified phrases. By
substituting these verb structures by the
base form of the head verb, we achieve
a better statistical word alignment perfor-
mance, and are able to better estimate the
translation model and generalize to unseen
verb forms during translation. Preliminary
experiments for the English - Spanish lan-
guage pair are performed, and future re-
search lines are detailed.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9998420625">
Since its revival in the beginning of the 1990s, statis-
tical machine translation (SMT) has shown promis-
ing results in several evaluation campaigns. From
original word-based models, results were further im-
proved by the appearance of phrase-based transla-
tion models.
However, many SMT systems still ignore any
morphological analysis and work at the surface level
of word forms. For highly-inflected languages, such
as German or Spanish (or any language of the Ro-
mance family) this poses severe limitations both in
training from parallel corpora, as well as in produc-
ing a correct translation of an input sentence.
This lack of linguistic knowledge in SMT forces
the translation model to learn different transla-
tion probability distributions for all inflected forms
of nouns, adjectives or verbs (’vengo’, ’vienes’,
’viene’, etc.), and this suffers from usual data sparse-
ness. Despite the recent efforts in the community to
provide models with this kind of information (see
Section 6 for details on related previous work), re-
sults are yet to be encouraging.
In this paper we address the incorporation of
morphological and shallow syntactic information re-
garding verbs and compound verbs, as a first step
towards an SMT model based on linguistically-
classified phrases. With the use of POS-tags and
lemmas, we detect verb structures (with or without
personal pronoun, single-word or compound with
auxiliaries) and substitute them by the base form&apos;
of the head verb. This leads to an improved statisti-
cal word alignment performance, and has the advan-
tages of improving the translation model and gen-
eralizing to unseen verb forms, during translation.
Experiments for the English - Spanish language pair
are performed.
The organization of the paper is as follows. Sec-
tion 2 describes the rationale of this classification
strategy, discussing the advantages and difficulties
of such an approach. Section 3 gives details of
the implementation for verbs and compound verbs,
whereas section 4 shows the experimental setting
used to evaluate the quality of the alignments. Sec-
tion 5 explains the current point of our research, as
well as both our most-immediate to-do tasks and our
medium and long-term experimentation lines. Fi-
nally, sections 6 and 7 discuss related works that can
be found in literature and conclude, respectively.
</bodyText>
<footnote confidence="0.8320905">
&apos;The terms ’base form’ or ’lemma’ will be used equivalently
in this text.
</footnote>
<page confidence="0.986857">
67
</page>
<note confidence="0.652401">
Proceedings of the ACL Student Research Workshop, pages 67–72,
</note>
<page confidence="0.365036">
Ann Arbor, Michigan, June 2005. c�2005 Association for Computational Linguistics
</page>
<bodyText confidence="0.420131">
(
</bodyText>
<sectionHeader confidence="0.931113" genericHeader="method">
2 Morphosyntactic classification of
translation units
</sectionHeader>
<bodyText confidence="0.999984151515152">
State-of-the-art SMT systems use a log-linear com-
bination of models to decide the best-scoring tar-
get sentence given a source sentence. Among
these models, the basic ones are a translation model
Pr(e|f) and a target language model Pr(e), which
can be complemented by reordering models (if the
language pairs presents very long alignments in
training), word penalty to avoid favoring short sen-
tences, class-based target-language models, etc (Och
and Ney, 2004).
The translation model is based on phrases; we
have a table of the probabilities of translating a cer-
tain source phrase fj into a certain target phrase
Ek. Several strategies to compute these probabili-
ties have been proposed (Zens et al., 2004; Crego et
al., 2004), but none of them takes into account the
fact that, when it comes to translation, many differ-
ent inflected forms of words share the same transla-
tion. Furthermore, they try to model the probability
of translating certain phrases that contain just aux-
iliary words that are not directly relevant in trans-
lation, but play a secondary role. These words are
a consequence of the syntax of each language, and
should be dealt with accordingly.
For examples, consider the probability of translat-
ing ’in the’ into a phrase in Spanish, which does not
make much sense in isolation (without knowing the
following meaning-bearing noun), or the modal verb
’will’, when Spanish future verb forms are written
without any auxiliary.
Given these two problems, we propose a classifi-
cation scheme based on the base form of the phrase
head, which is explained next.
</bodyText>
<subsectionHeader confidence="0.99937">
2.1 Translation with classified phrases
</subsectionHeader>
<bodyText confidence="0.99946975">
Assuming we translate from f to e, and defining ei,
�fj a certain source phrase and a target phrases (se-
quences of contiguous words), the phrase translation
model Pr(ei |fj) can be decomposed as:
</bodyText>
<equation confidence="0.9957495">
E Pr(Ei|T, �fj)Pr(�Ei |�Fj, �fj)Pr(�Fj, �fj) (1)
T
</equation>
<bodyText confidence="0.9973948">
where �Ei, Fj are the generalized classes of the
source and target phrases, respectively, and T =
�Ei, Fj) is the pair of source and target classes used,
which we call Tuple. In our current implementation,
we consider a classification of phrases that is:
</bodyText>
<listItem confidence="0.997769857142857">
• Linguistic, ie. based on linguistic knowledge
• Unambiguous, ie. given a source phrase there
is only one class (if any)
• Incomplete, ie. not all phrases are classified,
but only the ones we are interested in
• Monolingual, ie. it runs for every language in-
dependently
</listItem>
<bodyText confidence="0.999487">
The second condition implies Pr( F� |f) = 1,
leading to the following expression:
</bodyText>
<equation confidence="0.985406">
Pr(�ei |fj) = Pr(�Ei |�Fj)Pr(Ei|T, �fj) (2)
</equation>
<bodyText confidence="0.999972571428571">
where we have just two terms, namely a standard
phrase translation model based on the classified
parallel data, and an instance model assigning a
probability to each target instance given the source
class and the source instance. The latter helps us
choose among target words in combination with the
language model.
</bodyText>
<subsectionHeader confidence="0.995538">
2.2 Advantages
</subsectionHeader>
<bodyText confidence="0.9998646875">
This strategy has three advantages:
Better alignment. By reducing the number of
words to be considered during first word alignment
(auxiliary words in the classes disappear and no
inflected forms used), we lessen the data sparseness
problem and can obtain a better word alignment.
In a secondary step, one can learn word alignment
relationships inside aligned classes by realigning
them as a separate corpus, if that is desired.
Improvement of translation probabilities. By
considering many different phrases as different
instances of a single phrase class, we reduce the size
of our phrase-based (now class-based) translation
model and increase the number of occurrences of
each unit, producing a model Pr( &amp; F�) with less
perplexity.
</bodyText>
<page confidence="0.996703">
68
</page>
<bodyText confidence="0.999831166666667">
Generalizing power. Phrases not occurring in
the training data can still be classified into a class,
and therefore be assigned a probability in the trans-
lation model. The new difficulty that rises is how to
produce the target phrase from the target class and
the source phrase, if this was not seen in training.
</bodyText>
<subsectionHeader confidence="0.989696">
2.3 Difficulties
</subsectionHeader>
<bodyText confidence="0.999624625">
Two main difficulties2 are associated with this
strategy, which will hopefully lead to improved
translation performance if tackled conveniently.
Instance probability. On the one hand, when a
phrase of the test sentence is classified to a class,
and then translated, how do we produce the instance
of the target class given the tuple T and the source
instance? This problem is mathematically expressed
by the need to model the term of the Pr(˜ez|T, ˜fj) in
Equation 2.
At the moment, we learn this model from relative
frequency across all tuples that share the same
source phrase, dividing the times we see the pair
( ˜fj,˜ez) in the training by the times we see ˜fj.
Unseen instances. To produce a target instance
f˜ given the tuple T and an unseen ˜e, our idea is to
combine both the information of verb forms seen in
training and off-the-shelf knowledge for generation.
A translation memory can be built with all the seen
pairs of instances with their inflectional affixes
separated from base forms.
For example, suppose we translate from English
to Spanish and see the tuple T=(V[go],V[ir]) in
training, with the following instances:
</bodyText>
<table confidence="0.568970833333333">
I will go ir´e
PRP(1S) will VB VB 1S F
you will go iris
PRP(2S) will VB VB 2S F
you will go vas
PRP(2S) will VB VB 2S P
</table>
<tableCaption confidence="0.534602">
2A third difficulty is the classification task itself, but we take
it for granted that this is performed by an independent system
based on other knowledge sources, and therefore out of scope
here.
</tableCaption>
<bodyText confidence="0.999784153846154">
where the second row is the analyzed form in terms
of person (1S: 1st singular, 2S: 2nd singular and
so on) and tense (VB: infinitive and P: present, F:
future). From these we can build a generalized rule
independent of the person ’ PRP(X) will VB ’ that
would enable us to translate ’we will go’ to two
different alternatives (present and future form):
we will go VB 1P F
we will go VB 1P P
These alternatives can be weighted according to
the times we have seen each case in training. An un-
ambiguous form generator produces the forms ’ire-
mos’ and ’vamos’ for the two Spanish translations.
</bodyText>
<sectionHeader confidence="0.996139" genericHeader="method">
3 Classifying Verb Forms
</sectionHeader>
<bodyText confidence="0.99963525">
As mentioned above, our first and basic implemen-
tation deals with verbs, which are classified unam-
biguously before alignment in training and before
translating a test.
</bodyText>
<subsectionHeader confidence="0.998834">
3.1 Rules used
</subsectionHeader>
<bodyText confidence="0.999985357142857">
We perform a knowledge-based detection of verbs
using deterministic automata that implement a few
simple rules based on word forms, POS-tags and
word lemmas, and map the resulting expression to
the lemma of the head verb (see Figure 1 for some
rules and examples of detected verbs). This is done
both in the English and the Spanish side, and before
word alignment.
Note that we detect verbs containing adverbs and
negations (underlined in Figure 1), which are or-
dered before the verb to improve word alignment
with Spanish, but once aligned they are reordered
back to their original position inside the detected
verb, representing the real instance of this verb.
</bodyText>
<sectionHeader confidence="0.999874" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999563">
In this section we present experiments with the
Spanish-English parallel corpus developed in the
framework of the LC-STAR project. This corpus
consists of transcriptions of spontaneously spoken
dialogues in the tourist information, appointment
scheduling and travel planning domain. Therefore,
sentences often lack correct syntactic structure. Pre-
processing includes:
</bodyText>
<page confidence="0.997665">
69
</page>
<figureCaption confidence="0.99948">
Figure 1: Some verb phrase detection rules and detected forms in English.
</figureCaption>
<equation confidence="0.987608555555556">
PP {+RB) +V❑
V(L=do) {+not) +PP {+RB) +V❑
V(L=be) {+not) +PP❑
PP +V(L=be) {+RB) +VG❑
V(L=be) {+not) +PP {+RB) +VG❑
PP + MD(L=will/would/...) {+RB) +V❑
MD(L=will/would/...) {+not) +PP {+RB) +V❑
PP + V(L=have) {+RB) {+been) +V{G)❑
V(L=have) {+not) +PP {+RB) {+been) +V{G)❑
</equation>
<figure confidence="0.844181769230769">
Examples:❑
leaves❑
do you have❑
did you come❑
he has ❑not❑attended❑
have you ❑ever❑been❑
I will have❑
she is going to be❑
we would arrive❑
PP: Personal Pronoun❑
V / MD / VG / RB: Verb / Modal / Gerund ❑/ Adverb (PennTree Bank POS)❑
L: Lemma (or base form)❑
{ ) / ( ): optionality / instantiation❑
</figure>
<listItem confidence="0.9976701">
• Normalization of contracted forms for English
(ie. wouldn’t = would not, we’ve = we have)
• English POS-tagging using freely-available
TnT tagger (Brants, 2000), and lemmatization
using wnmorph, included in the WordNet pack-
age (Miller et al., 1991).
• Spanish POS-tagging using FreeLing analysis
tool (Carreras et al., 2004). This software also
generates a lemma or base form for each input
word.
</listItem>
<subsectionHeader confidence="0.966447">
4.1 Parallel corpus statistics
</subsectionHeader>
<bodyText confidence="0.924469">
Table 1 shows the statistics of the data used, where
each column shows number of sentences, number of
words, vocabulary, and mean length of a sentence,
respectively.
Train set
</bodyText>
<table confidence="0.990526">
English 29998 419113 5940 14.0
Spanish 388788 9791 13.0
Test set
English 500 7412 963 14.8
Spanish 6899 1280 13.8
</table>
<tableCaption confidence="0.99974">
Table 1: LC-Star English-Spanish Parallel corpus.
</tableCaption>
<bodyText confidence="0.99981">
There are 116 unseen words in the Spanish test
set (1.7% of all words), and 48 unseen words in the
English set (0.7% of all words), an expected big dif-
ference given the much more inflectional nature of
the Spanish language.
</bodyText>
<subsectionHeader confidence="0.990352">
4.2 Verb Phrase Detection/Classification
</subsectionHeader>
<bodyText confidence="0.907845666666667">
Table 2 shows the number of detected verbs using
the detection rules presented in section 3.1, and the
number of different lemmas they map to. For the test
set, the percentage of unseen verb forms and lemmas
are also shown.
Train set
</bodyText>
<table confidence="0.7385396">
English 56419 768
Spanish 54460 911
Test set
English 1076 5.2% 146 4.7%
Spanish 1061 5.6% 171 4.7%
</table>
<tableCaption confidence="0.976848">
Table 2: Detected verb forms in corpus.
</tableCaption>
<bodyText confidence="0.9999538">
In average, detected English verbs contain 1.81
words, whereas Spanish verbs contain 1.08 words.
This is explained by the fact that we are including
the personal pronouns in English and modals for fu-
ture, conditionals and other verb tenses.
</bodyText>
<subsectionHeader confidence="0.997589">
4.3 Word alignment results
</subsectionHeader>
<bodyText confidence="0.999776111111111">
In order to assess the quality of the word alignment,
we randomly selected from the training corpus 350
sentences, and a manual gold standard alignment
has been done with the criterion of Sure and Pos-
sible links, in order to compute Alignment Error
Rate (AER) as described in (Och and Ney, 2000) and
widely used in literature, together with appropriately
redefined Recall and Precision measures. Mathe-
matically, they can be expressed thus:
</bodyText>
<figure confidence="0.6388655">
sent. words vocab. Lmean
verbs unseen lemmas unseen
JA n SJ JA n PJ
recall
</figure>
<equation confidence="0.751604">
= JSJ� precision = JAJ
AER = 1 _ JA n SJ + JA n PJ
JAJ + JSJ
</equation>
<page confidence="0.984916">
70
</page>
<bodyText confidence="0.999733235294118">
where A is the hypothesis alignment and S is the
set of Sure links in the gold standard reference, and
P includes the set of Possible and Sure links in the
gold standard reference.
We have aligned our data using GIZA++ (Och,
2003) from English to Spanish and vice versa (per-
forming 5 iterations of model IBM1 and HMM, and
3 iterations of models IBM3 and IBM4), and have
evaluated two symmetrization strategies, namely the
union and the intersection, the union always rating
the best. Table 3 compares the result when aligning
words (current baseline), and when aligning classi-
fied verb phrases. In this case, after the alignment
we substitute the class for the original verb form and
each new word gets the same links the class had. Of
course, adverbs and negations are kept apart from
the verb and have separate links.
</bodyText>
<table confidence="0.995751">
Recall Precision AER
baseline 74.14 86.31 20.07
with class. verbs 76.45 89.06 17.37
</table>
<tableCaption confidence="0.999964">
Table 3: Results in statistical alignment.
</tableCaption>
<bodyText confidence="0.992166">
Results show a significant improvement in AER,
which proves that verbal inflected forms and auxil-
iaries do harm alignment performance in absence of
the proposed classification.
</bodyText>
<subsectionHeader confidence="0.998957">
4.4 Translation results
</subsectionHeader>
<bodyText confidence="0.999652">
We have integrated our classification strategy in an
SMT system which implements:
</bodyText>
<listItem confidence="0.997041666666667">
• Pr(ei |fk) as a tuples language model (Ngram),
as done in (Crego et al., 2004)
•
</listItem>
<bodyText confidence="0.956532357142857">
Pr(e) as a standard Ngram language model us-
ing SRILM toolkit (Stolcke, 2002)
Parameters have been optimised for BLEU score
in a 350 sentences development set. Three refer-
ences are available for both development and test
sets. Table 4 presents a comparison of English to
Spanish translation results of the baseline system
and the configuration with classification (without
dealing with unseen instances). Results are promis-
ing, as we achieve a significant mWER error re-
duction, while still leaving about 5.6 % of the verb
forms in the test without translation. Therefore, we
expect a further improvement with the treatment of
unseen instances.
</bodyText>
<table confidence="0.925815">
mWER BLEU
baseline 23.16 0.671
with class. verbs 22.22 0.686
</table>
<tableCaption confidence="0.999825">
Table 4: Results in English to Spanish translation.
</tableCaption>
<sectionHeader confidence="0.888588" genericHeader="method">
5 Ongoing and future research
</sectionHeader>
<bodyText confidence="0.999793769230769">
Ongoing research is mainly focused on developing
an appropriate generalization technique for unseen
instances and evaluating its impact in translation
quality.
Later, we expect to run experiments with a much
bigger parallel corpus such as the European Parlia-
ment corpus, in order to evaluate the improvement
due to morphological information for different sizes
of the training data. Advanced methods to compute
Pr(Ei|T, fj) should also be tested (based on source
and target contextual features).
The next step will be to extend the approach to
other potential classes such as:
</bodyText>
<listItem confidence="0.9512558125">
• Nouns and adjectives. A straightforward strat-
egy would classify all nouns and adjectives to
their base form, reducing sparseness.
• Simple Noun phrases. Noun phrases with or
without article (determiner), and with or with-
out preposition, could also be classified to the
base form of the head noun, leading to a fur-
ther reduction of the data sparseness, in a sub-
sequent stage. In this case, expressions like at
night, the night, nights or during
the night would all be mapped to the class
’night’.
• Temporal and numeric expressions. As they are
usually tackled in a preprocessing stage in cur-
rent SMT systems, we did not deal with them
here.
</listItem>
<bodyText confidence="0.999558833333333">
More on a long-term basis, ambiguous linguistic
classification could also be allowed and included in
the translation model. For this, incorporating statis-
tical classification tools (chunkers, shallow parsers,
phrase detectors, etc.) should be considered, and
evaluated against the current implementation.
</bodyText>
<page confidence="0.99815">
71
</page>
<sectionHeader confidence="0.999966" genericHeader="related work">
6 Related Work
</sectionHeader>
<bodyText confidence="0.99996537037037">
The approach to deal with inflected forms presented
in (Ueffing and Ney, 2003) is similar in that it also
tackles verbs in an English – Spanish task. How-
ever, whereas the authors join personal pronouns
and auxiliaries to form extended English units and
do not transform the Spanish side, leading to an in-
creased English vocabulary, our proposal aims at re-
ducing both vocabularies by mapping all different
verb forms to the base form of the head verb.
An improvement in translation using IBM model
1 in an Arabic – English task can be found in (Lee,
2004). From a processed Arabic text with all pre-
fixes and suffixes separated, the author determines
which of them should be linked back to the word
and which should not. However, no mapping to base
forms is performed, and plurals are still different
words than singulars.
In (Nießen and Ney, 2004) hierarchical lexicon
models including base form and POS information
for translation from German into English are intro-
duced, among other morphology-based data trans-
formations. Finally, the same pair of languages is
used in (Corston-Oliver and Gamon, 2004), where
the inflectional normalization leads to improvements
in the perplexity of IBM translation models and re-
duces alignment errors. However, compound verbs
are not mentioned.
</bodyText>
<sectionHeader confidence="0.9995" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.9999078">
A proposal of linguistically classifying translation
phrases to improve statistical machine translation
performance has been presented. This classification
allows for a better translation modeling and a gen-
eralization to unseen forms. A preliminary imple-
mentation detecting verbs in an English – Spanish
task has been presented. Experiments show a sig-
nificant improvement in word alignment, and in pre-
liminary translation results. Ongoing and future re-
search lines are discussed.
</bodyText>
<sectionHeader confidence="0.999635" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99977962">
T. Brants. 2000. TnT – a statistical part-of-speech tag-
ger. In Proc. of the Sixth Applied Natural Language
Processing (ANLP-2000), Seattle, WA.
Freeling: An open-source suite of language analyzers.
4th Int. Conf. on Language Resources and Evaluation,
LREC’04, May.
S. Corston-Oliver and M. Gamon. 2004. Normalizing
german and english inflectional morphology to im-
prove statistical word alignment. Proc. of the 6th
Conf. of the Association for Machine Translation in
the Americas, pages 48–57, October.
J.M. Crego, J. Mari˜no, and A. de Gispert. 2004. Finite-
state-based and phrase-based statistical machine trans-
lation. Proc. of the 8th Int. Conf. on Spoken Language
Processing, ICSLP’04, pages 37–40, October.
Y.S. Lee. 2004. Morphological analysis for statistical
machine translation. In Daniel Marcu Susan Dumais
and Salim Roukos, editors, HLT-NAACL 2004: Short
Papers, pages 57–60, Boston, Massachusetts, USA,
May. Association for Computational Linguistics.
G.A. Miller, R. Beckwith, C. Fellbaum, D. Gross,
K. Miller, and R. Tengi. 1991. Five papers on word-
net. Special Issue ofInternational Journal ofLexicog-
raphy, 3(4):235–312.
S. Nießen and H. Ney. 2004. Statistical machine trans-
lation with scarce resources using morpho-syntactic
information. Computational Linguistics, 30(2):181–
204, June.
F.J. Och and H. Ney. 2000. Improved statistical align-
ment models. 38th Annual Meeting of the Association
for Computational Linguistics, pages 440–447, Octo-
ber.
F.J. Och and H. Ney. 2004. The alignment template
approach to statistical machine translation. Compu-
tational Linguistics, 30(4):417–449, December.
F.J. Och. 2003. Giza++ software. http://www-
i6.informatik.rwth-aachen.de/˜och/ soft-
ware/giza++.html.
A. Stolcke. 2002. Srilm - an extensible language mod-
eling toolkit. Proc. of the 7th Int. Conf. on Spoken
Language Processing, ICSLP’02, September.
N. Ueffing and H. Ney. 2003. Using pos information for
smt into morphologically rich languages. 10th Conf.
of the European Chapter of the Association for Com-
putational Linguistics, pages 347–354, April.
R. Zens, F.J. Och, and H. Ney. 2004. Improvements
in phrase-based statistical machine translation. Proc.
of the Human Language Technology Conference, HLT-
NAACL’2004, pages 257–264, May.
X. Carreras, I. Chao, L. Padr´o, and M. Padr´o. 2004.
</reference>
<page confidence="0.998719">
72
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.919368">
<title confidence="0.9984515">Phrase Linguistic Classification and Generalization for Improving Statistical Machine Translation</title>
<author confidence="0.980832">Adri`a de_Gispert</author>
<affiliation confidence="0.9996515">TALP Research Center Universitat Polit`ecnica de Catalunya (UPC)</affiliation>
<address confidence="0.963145">Barcelona</address>
<email confidence="0.989742">agispert@gps.tsc.upc.es</email>
<abstract confidence="0.998999">In this paper a method to incorporate linguistic information regarding single-word and compound verbs is proposed, as a first step towards an SMT model based on linguistically-classified phrases. By substituting these verb structures by the base form of the head verb, we achieve a better statistical word alignment performance, and are able to better estimate the translation model and generalize to unseen verb forms during translation. Preliminary experiments for the English - Spanish language pair are performed, and future research lines are detailed.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>T Brants</author>
</authors>
<title>TnT – a statistical part-of-speech tagger.</title>
<date>2000</date>
<booktitle>In Proc. of the Sixth Applied Natural Language Processing (ANLP-2000),</booktitle>
<location>Seattle, WA.</location>
<contexts>
<context position="11406" citStr="Brants, 2000" startWordPosition="1852" endWordPosition="1853"> + MD(L=will/would/...) {+RB) +V❑ MD(L=will/would/...) {+not) +PP {+RB) +V❑ PP + V(L=have) {+RB) {+been) +V{G)❑ V(L=have) {+not) +PP {+RB) {+been) +V{G)❑ Examples:❑ leaves❑ do you have❑ did you come❑ he has ❑not❑attended❑ have you ❑ever❑been❑ I will have❑ she is going to be❑ we would arrive❑ PP: Personal Pronoun❑ V / MD / VG / RB: Verb / Modal / Gerund ❑/ Adverb (PennTree Bank POS)❑ L: Lemma (or base form)❑ { ) / ( ): optionality / instantiation❑ • Normalization of contracted forms for English (ie. wouldn’t = would not, we’ve = we have) • English POS-tagging using freely-available TnT tagger (Brants, 2000), and lemmatization using wnmorph, included in the WordNet package (Miller et al., 1991). • Spanish POS-tagging using FreeLing analysis tool (Carreras et al., 2004). This software also generates a lemma or base form for each input word. 4.1 Parallel corpus statistics Table 1 shows the statistics of the data used, where each column shows number of sentences, number of words, vocabulary, and mean length of a sentence, respectively. Train set English 29998 419113 5940 14.0 Spanish 388788 9791 13.0 Test set English 500 7412 963 14.8 Spanish 6899 1280 13.8 Table 1: LC-Star English-Spanish Parallel </context>
</contexts>
<marker>Brants, 2000</marker>
<rawString>T. Brants. 2000. TnT – a statistical part-of-speech tagger. In Proc. of the Sixth Applied Natural Language Processing (ANLP-2000), Seattle, WA.</rawString>
</citation>
<citation valid="true">
<title>Freeling: An open-source suite of language analyzers.</title>
<date></date>
<booktitle>4th Int. Conf. on Language Resources and Evaluation, LREC’04,</booktitle>
<marker></marker>
<rawString>Freeling: An open-source suite of language analyzers. 4th Int. Conf. on Language Resources and Evaluation, LREC’04, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Corston-Oliver</author>
<author>M Gamon</author>
</authors>
<title>Normalizing german and english inflectional morphology to improve statistical word alignment.</title>
<date>2004</date>
<booktitle>Proc. of the 6th Conf. of the Association for Machine Translation in the Americas,</booktitle>
<pages>48--57</pages>
<contexts>
<context position="18243" citStr="Corston-Oliver and Gamon, 2004" startWordPosition="2984" endWordPosition="2987">anslation using IBM model 1 in an Arabic – English task can be found in (Lee, 2004). From a processed Arabic text with all prefixes and suffixes separated, the author determines which of them should be linked back to the word and which should not. However, no mapping to base forms is performed, and plurals are still different words than singulars. In (Nießen and Ney, 2004) hierarchical lexicon models including base form and POS information for translation from German into English are introduced, among other morphology-based data transformations. Finally, the same pair of languages is used in (Corston-Oliver and Gamon, 2004), where the inflectional normalization leads to improvements in the perplexity of IBM translation models and reduces alignment errors. However, compound verbs are not mentioned. 7 Conclusion A proposal of linguistically classifying translation phrases to improve statistical machine translation performance has been presented. This classification allows for a better translation modeling and a generalization to unseen forms. A preliminary implementation detecting verbs in an English – Spanish task has been presented. Experiments show a significant improvement in word alignment, and in preliminary</context>
</contexts>
<marker>Corston-Oliver, Gamon, 2004</marker>
<rawString>S. Corston-Oliver and M. Gamon. 2004. Normalizing german and english inflectional morphology to improve statistical word alignment. Proc. of the 6th Conf. of the Association for Machine Translation in the Americas, pages 48–57, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Crego</author>
<author>J Mari˜no</author>
<author>A de Gispert</author>
</authors>
<title>Finitestate-based and phrase-based statistical machine translation.</title>
<date>2004</date>
<booktitle>Proc. of the 8th Int. Conf. on Spoken Language Processing, ICSLP’04,</booktitle>
<pages>37--40</pages>
<marker>Crego, Mari˜no, de Gispert, 2004</marker>
<rawString>J.M. Crego, J. Mari˜no, and A. de Gispert. 2004. Finitestate-based and phrase-based statistical machine translation. Proc. of the 8th Int. Conf. on Spoken Language Processing, ICSLP’04, pages 37–40, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y S Lee</author>
</authors>
<title>Morphological analysis for statistical machine translation.</title>
<date>2004</date>
<booktitle>HLT-NAACL 2004: Short Papers,</booktitle>
<pages>57--60</pages>
<editor>In Daniel Marcu Susan Dumais and Salim Roukos, editors,</editor>
<publisher>Association for Computational Linguistics.</publisher>
<location>Boston, Massachusetts, USA,</location>
<contexts>
<context position="17695" citStr="Lee, 2004" startWordPosition="2899" endWordPosition="2900">d against the current implementation. 71 6 Related Work The approach to deal with inflected forms presented in (Ueffing and Ney, 2003) is similar in that it also tackles verbs in an English – Spanish task. However, whereas the authors join personal pronouns and auxiliaries to form extended English units and do not transform the Spanish side, leading to an increased English vocabulary, our proposal aims at reducing both vocabularies by mapping all different verb forms to the base form of the head verb. An improvement in translation using IBM model 1 in an Arabic – English task can be found in (Lee, 2004). From a processed Arabic text with all prefixes and suffixes separated, the author determines which of them should be linked back to the word and which should not. However, no mapping to base forms is performed, and plurals are still different words than singulars. In (Nießen and Ney, 2004) hierarchical lexicon models including base form and POS information for translation from German into English are introduced, among other morphology-based data transformations. Finally, the same pair of languages is used in (Corston-Oliver and Gamon, 2004), where the inflectional normalization leads to impr</context>
</contexts>
<marker>Lee, 2004</marker>
<rawString>Y.S. Lee. 2004. Morphological analysis for statistical machine translation. In Daniel Marcu Susan Dumais and Salim Roukos, editors, HLT-NAACL 2004: Short Papers, pages 57–60, Boston, Massachusetts, USA, May. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Miller</author>
<author>R Beckwith</author>
<author>C Fellbaum</author>
<author>D Gross</author>
<author>K Miller</author>
<author>R Tengi</author>
</authors>
<title>Five papers on wordnet.</title>
<date>1991</date>
<booktitle>Special Issue ofInternational Journal ofLexicography,</booktitle>
<pages>3--4</pages>
<contexts>
<context position="11494" citStr="Miller et al., 1991" startWordPosition="1864" endWordPosition="1867">V(L=have) {+RB) {+been) +V{G)❑ V(L=have) {+not) +PP {+RB) {+been) +V{G)❑ Examples:❑ leaves❑ do you have❑ did you come❑ he has ❑not❑attended❑ have you ❑ever❑been❑ I will have❑ she is going to be❑ we would arrive❑ PP: Personal Pronoun❑ V / MD / VG / RB: Verb / Modal / Gerund ❑/ Adverb (PennTree Bank POS)❑ L: Lemma (or base form)❑ { ) / ( ): optionality / instantiation❑ • Normalization of contracted forms for English (ie. wouldn’t = would not, we’ve = we have) • English POS-tagging using freely-available TnT tagger (Brants, 2000), and lemmatization using wnmorph, included in the WordNet package (Miller et al., 1991). • Spanish POS-tagging using FreeLing analysis tool (Carreras et al., 2004). This software also generates a lemma or base form for each input word. 4.1 Parallel corpus statistics Table 1 shows the statistics of the data used, where each column shows number of sentences, number of words, vocabulary, and mean length of a sentence, respectively. Train set English 29998 419113 5940 14.0 Spanish 388788 9791 13.0 Test set English 500 7412 963 14.8 Spanish 6899 1280 13.8 Table 1: LC-Star English-Spanish Parallel corpus. There are 116 unseen words in the Spanish test set (1.7% of all words), and 48 u</context>
</contexts>
<marker>Miller, Beckwith, Fellbaum, Gross, Miller, Tengi, 1991</marker>
<rawString>G.A. Miller, R. Beckwith, C. Fellbaum, D. Gross, K. Miller, and R. Tengi. 1991. Five papers on wordnet. Special Issue ofInternational Journal ofLexicography, 3(4):235–312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Nießen</author>
<author>H Ney</author>
</authors>
<title>Statistical machine translation with scarce resources using morpho-syntactic information.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>2</issue>
<pages>204</pages>
<contexts>
<context position="17987" citStr="Nießen and Ney, 2004" startWordPosition="2947" endWordPosition="2950"> extended English units and do not transform the Spanish side, leading to an increased English vocabulary, our proposal aims at reducing both vocabularies by mapping all different verb forms to the base form of the head verb. An improvement in translation using IBM model 1 in an Arabic – English task can be found in (Lee, 2004). From a processed Arabic text with all prefixes and suffixes separated, the author determines which of them should be linked back to the word and which should not. However, no mapping to base forms is performed, and plurals are still different words than singulars. In (Nießen and Ney, 2004) hierarchical lexicon models including base form and POS information for translation from German into English are introduced, among other morphology-based data transformations. Finally, the same pair of languages is used in (Corston-Oliver and Gamon, 2004), where the inflectional normalization leads to improvements in the perplexity of IBM translation models and reduces alignment errors. However, compound verbs are not mentioned. 7 Conclusion A proposal of linguistically classifying translation phrases to improve statistical machine translation performance has been presented. This classificati</context>
</contexts>
<marker>Nießen, Ney, 2004</marker>
<rawString>S. Nießen and H. Ney. 2004. Statistical machine translation with scarce resources using morpho-syntactic information. Computational Linguistics, 30(2):181– 204, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>Improved statistical alignment models.</title>
<date>2000</date>
<booktitle>38th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>440--447</pages>
<contexts>
<context position="13215" citStr="Och and Ney, 2000" startWordPosition="2154" endWordPosition="2157"> 5.6% 171 4.7% Table 2: Detected verb forms in corpus. In average, detected English verbs contain 1.81 words, whereas Spanish verbs contain 1.08 words. This is explained by the fact that we are including the personal pronouns in English and modals for future, conditionals and other verb tenses. 4.3 Word alignment results In order to assess the quality of the word alignment, we randomly selected from the training corpus 350 sentences, and a manual gold standard alignment has been done with the criterion of Sure and Possible links, in order to compute Alignment Error Rate (AER) as described in (Och and Ney, 2000) and widely used in literature, together with appropriately redefined Recall and Precision measures. Mathematically, they can be expressed thus: sent. words vocab. Lmean verbs unseen lemmas unseen JA n SJ JA n PJ recall = JSJ� precision = JAJ AER = 1 _ JA n SJ + JA n PJ JAJ + JSJ 70 where A is the hypothesis alignment and S is the set of Sure links in the gold standard reference, and P includes the set of Possible and Sure links in the gold standard reference. We have aligned our data using GIZA++ (Och, 2003) from English to Spanish and vice versa (performing 5 iterations of model IBM1 and HMM</context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>F.J. Och and H. Ney. 2000. Improved statistical alignment models. 38th Annual Meeting of the Association for Computational Linguistics, pages 440–447, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>The alignment template approach to statistical machine translation.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>4</issue>
<contexts>
<context position="3854" citStr="Och and Ney, 2004" startWordPosition="587" endWordPosition="590">orkshop, pages 67–72, Ann Arbor, Michigan, June 2005. c�2005 Association for Computational Linguistics ( 2 Morphosyntactic classification of translation units State-of-the-art SMT systems use a log-linear combination of models to decide the best-scoring target sentence given a source sentence. Among these models, the basic ones are a translation model Pr(e|f) and a target language model Pr(e), which can be complemented by reordering models (if the language pairs presents very long alignments in training), word penalty to avoid favoring short sentences, class-based target-language models, etc (Och and Ney, 2004). The translation model is based on phrases; we have a table of the probabilities of translating a certain source phrase fj into a certain target phrase Ek. Several strategies to compute these probabilities have been proposed (Zens et al., 2004; Crego et al., 2004), but none of them takes into account the fact that, when it comes to translation, many different inflected forms of words share the same translation. Furthermore, they try to model the probability of translating certain phrases that contain just auxiliary words that are not directly relevant in translation, but play a secondary role</context>
</contexts>
<marker>Och, Ney, 2004</marker>
<rawString>F.J. Och and H. Ney. 2004. The alignment template approach to statistical machine translation. Computational Linguistics, 30(4):417–449, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
</authors>
<date>2003</date>
<note>Giza++ software. http://wwwi6.informatik.rwth-aachen.de/˜och/ software/giza++.html.</note>
<contexts>
<context position="13729" citStr="Och, 2003" startWordPosition="2254" endWordPosition="2255">ssible links, in order to compute Alignment Error Rate (AER) as described in (Och and Ney, 2000) and widely used in literature, together with appropriately redefined Recall and Precision measures. Mathematically, they can be expressed thus: sent. words vocab. Lmean verbs unseen lemmas unseen JA n SJ JA n PJ recall = JSJ� precision = JAJ AER = 1 _ JA n SJ + JA n PJ JAJ + JSJ 70 where A is the hypothesis alignment and S is the set of Sure links in the gold standard reference, and P includes the set of Possible and Sure links in the gold standard reference. We have aligned our data using GIZA++ (Och, 2003) from English to Spanish and vice versa (performing 5 iterations of model IBM1 and HMM, and 3 iterations of models IBM3 and IBM4), and have evaluated two symmetrization strategies, namely the union and the intersection, the union always rating the best. Table 3 compares the result when aligning words (current baseline), and when aligning classified verb phrases. In this case, after the alignment we substitute the class for the original verb form and each new word gets the same links the class had. Of course, adverbs and negations are kept apart from the verb and have separate links. Recall Pre</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>F.J. Och. 2003. Giza++ software. http://wwwi6.informatik.rwth-aachen.de/˜och/ software/giza++.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
</authors>
<title>Srilm - an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>Proc. of the 7th Int. Conf. on Spoken Language Processing, ICSLP’02,</booktitle>
<contexts>
<context position="14888" citStr="Stolcke, 2002" startWordPosition="2444" endWordPosition="2445">apart from the verb and have separate links. Recall Precision AER baseline 74.14 86.31 20.07 with class. verbs 76.45 89.06 17.37 Table 3: Results in statistical alignment. Results show a significant improvement in AER, which proves that verbal inflected forms and auxiliaries do harm alignment performance in absence of the proposed classification. 4.4 Translation results We have integrated our classification strategy in an SMT system which implements: • Pr(ei |fk) as a tuples language model (Ngram), as done in (Crego et al., 2004) • Pr(e) as a standard Ngram language model using SRILM toolkit (Stolcke, 2002) Parameters have been optimised for BLEU score in a 350 sentences development set. Three references are available for both development and test sets. Table 4 presents a comparison of English to Spanish translation results of the baseline system and the configuration with classification (without dealing with unseen instances). Results are promising, as we achieve a significant mWER error reduction, while still leaving about 5.6 % of the verb forms in the test without translation. Therefore, we expect a further improvement with the treatment of unseen instances. mWER BLEU baseline 23.16 0.671 wi</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>A. Stolcke. 2002. Srilm - an extensible language modeling toolkit. Proc. of the 7th Int. Conf. on Spoken Language Processing, ICSLP’02, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ueffing</author>
<author>H Ney</author>
</authors>
<title>Using pos information for smt into morphologically rich languages.</title>
<date>2003</date>
<booktitle>10th Conf. of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>347--354</pages>
<contexts>
<context position="17219" citStr="Ueffing and Ney, 2003" startWordPosition="2812" endWordPosition="2815">night, nights or during the night would all be mapped to the class ’night’. • Temporal and numeric expressions. As they are usually tackled in a preprocessing stage in current SMT systems, we did not deal with them here. More on a long-term basis, ambiguous linguistic classification could also be allowed and included in the translation model. For this, incorporating statistical classification tools (chunkers, shallow parsers, phrase detectors, etc.) should be considered, and evaluated against the current implementation. 71 6 Related Work The approach to deal with inflected forms presented in (Ueffing and Ney, 2003) is similar in that it also tackles verbs in an English – Spanish task. However, whereas the authors join personal pronouns and auxiliaries to form extended English units and do not transform the Spanish side, leading to an increased English vocabulary, our proposal aims at reducing both vocabularies by mapping all different verb forms to the base form of the head verb. An improvement in translation using IBM model 1 in an Arabic – English task can be found in (Lee, 2004). From a processed Arabic text with all prefixes and suffixes separated, the author determines which of them should be linke</context>
</contexts>
<marker>Ueffing, Ney, 2003</marker>
<rawString>N. Ueffing and H. Ney. 2003. Using pos information for smt into morphologically rich languages. 10th Conf. of the European Chapter of the Association for Computational Linguistics, pages 347–354, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Zens</author>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>Improvements in phrase-based statistical machine translation.</title>
<date>2004</date>
<booktitle>Proc. of the Human Language Technology Conference, HLTNAACL’2004,</booktitle>
<pages>257--264</pages>
<contexts>
<context position="4098" citStr="Zens et al., 2004" startWordPosition="629" endWordPosition="632">-scoring target sentence given a source sentence. Among these models, the basic ones are a translation model Pr(e|f) and a target language model Pr(e), which can be complemented by reordering models (if the language pairs presents very long alignments in training), word penalty to avoid favoring short sentences, class-based target-language models, etc (Och and Ney, 2004). The translation model is based on phrases; we have a table of the probabilities of translating a certain source phrase fj into a certain target phrase Ek. Several strategies to compute these probabilities have been proposed (Zens et al., 2004; Crego et al., 2004), but none of them takes into account the fact that, when it comes to translation, many different inflected forms of words share the same translation. Furthermore, they try to model the probability of translating certain phrases that contain just auxiliary words that are not directly relevant in translation, but play a secondary role. These words are a consequence of the syntax of each language, and should be dealt with accordingly. For examples, consider the probability of translating ’in the’ into a phrase in Spanish, which does not make much sense in isolation (without </context>
</contexts>
<marker>Zens, Och, Ney, 2004</marker>
<rawString>R. Zens, F.J. Och, and H. Ney. 2004. Improvements in phrase-based statistical machine translation. Proc. of the Human Language Technology Conference, HLTNAACL’2004, pages 257–264, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Carreras</author>
<author>I Chao</author>
<author>L Padr´o</author>
<author>M Padr´o</author>
</authors>
<date>2004</date>
<marker>Carreras, Chao, Padr´o, Padr´o, 2004</marker>
<rawString>X. Carreras, I. Chao, L. Padr´o, and M. Padr´o. 2004.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>