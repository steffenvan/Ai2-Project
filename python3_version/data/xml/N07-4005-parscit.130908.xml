<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.128691">
<title confidence="0.949113">
Automatic Segmentation and Summarization of Meeting Speech
</title>
<author confidence="0.9794425">
Gabriel Murray, Pei-Yun Hsueh, Simon Tucker
Jonathan Kilgour, Jean Carletta, Johanna Moore, Steve Renals
</author>
<affiliation confidence="0.886691">
University of Edinburgh
Edinburgh, Scotland
</affiliation>
<email confidence="0.997061">
❢gabriel.murray,p.hsueh❣@ed.ac.uk
</email>
<sectionHeader confidence="0.998731" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999940222222222">
AMI Meeting Facilitator is a system that per-
forms topic segmentation and extractive sum-
marisation. It consists of three components: (1)
a segmenter that divides a meeting into a num-
ber of locally coherent segments, (2) a summa-
rizer that selects the most important utterances
from the meeting transcripts. and (3) a com-
pression component that removes the less im-
portant words from each utterance based on the
degree of compression the user specified. The
goal of the AMI Meeting Facilitator is two-fold:
first, we want to provide sufficient visual aids for
users to interpret what is going on in a recorded
meeting; second, we want to support the devel-
opment of downstream information retrieval and
information extraction modules with the infor-
mation about the topics and summaries in meet-
ing segments.
</bodyText>
<sectionHeader confidence="0.955515" genericHeader="categories and subject descriptors">
2 Component Description
</sectionHeader>
<subsectionHeader confidence="0.950704">
2.1 Segmentation
</subsectionHeader>
<bodyText confidence="0.999894428571429">
The AMI Meeting Segmenter is trained using a
set of 50 meetings that are seperate from the in-
put meeting. We first extract features from the
audio and video recording of the input meeting
in order to train the Maximum Entropy (Max-
Ent) models for classifying topic boundaries and
non-topic boundaries. Then we test each utter-
ance in the input meeting on the Segmenter to
see if it is a topic boundary or not. The features
we use include the following five categories: (1)
Conversational Feature: These include a set
of seven conversational features, including the
amount of overlapping speech, the amount of
silence between speaker segments, the level of
similarity of speaker activity, the number of cue
words, and the predictions of LCSEG (i.e., the
lexical cohesion statistics, the estimated poste-
rior probability, the predicted class). (2) Lex-
ical Feature: Each spurt is represented as a
vector space of uni-grams, wherein a vector is 1
or 0 depending on whether the cue word appears
in the spurt. (3) Prosodic Feature: These
include dialogue-act (DA) rate-of-speech, max-
imum F0 of the DA, mean energy of the DA,
amount of silence in the DA, precedent and sub-
sequent pauses, and duration of the DA. (4)
Motion Feature: These include the average
magnitude of speaker movements, which is mea-
sured by the number of pixels changed, over the
frames of 40 ms within the spurt. (5) Contex-
tual Feature: These include the dialogue act
types and the speaker role (e.g., project man-
ager, marketing expert). In the dialogue act an-
notations, each dialogue act is classified as one
of the 15 types.
</bodyText>
<subsectionHeader confidence="0.978225">
2.2 Summarization
</subsectionHeader>
<bodyText confidence="0.983917375">
The AMI summarizer is trained using a set of
98 scenario meetings. We train a support vec-
tor machine (SVM) on these meetings, using 26
features relating to the following categories: (1)
Prosodic Features: These include dialogue-
act (DA) rate-of-speech, maximum F0 of the
DA, mean energy of the DA, amount of silence
in the DA, precedent and subsequent pauses,
</bodyText>
<page confidence="0.95735">
9
</page>
<author confidence="0.235928">
NAACL HLT Demonstration Program, pages 9–10,
</author>
<affiliation confidence="0.730693">
Rochester, New York, USA, April 2007. c�2007 Association for Computational Linguistics
</affiliation>
<bodyText confidence="0.999957739130435">
and duration of the DA. (2) Speaker Fea-
tures: These features relate to how dominant
the speaker is in the meeting as a whole, and
they include percentage of the total dialogue
acts which each speaker utters, percentage of
total words which speaker utters, and amount
of time in meeting that each person is speak-
ing. (3) Structural Features: These features
include the DA position in the meeting, and the
DA position in the speaker&apos;s turn. (4) Term
Weighting Features: We use two types of
term weighting: tf.idf, which is based on words
that are frequent in the meeting but rare across
a set of other meetings or documents, and a sec-
ond weighting feature which relates to how word
usage varies between the four meeting partici-
pants.
After training the SVM, we test on each meet-
ing of the 20 meeting test set in turn, ranking
the dialogue acts from most probable to least
probable in terms of being extract-worthy. Such
a ranking allows the user to create a summary
of whatever length she desires.
</bodyText>
<subsectionHeader confidence="0.970897">
2.3 Compression
</subsectionHeader>
<bodyText confidence="0.9999715">
Each dialogue act has its constituent words
scored using tf.idf, and as the user compresses
the meeting to a greater degree the browser
gradually removes the less important words from
each dialogue act, leaving only the most infor-
mative material of the meeting.
</bodyText>
<sectionHeader confidence="0.999664" genericHeader="related work">
3 Related Work
</sectionHeader>
<bodyText confidence="0.99996564">
Previous work has explored the effect of lexi-
cal cohesion and conversational features on char-
acterizing topic boundaries, following Galley et
al.(2003). In previous work, we have also studied
the problem of predicting topic boundaries at
different levels of granularity and showed that a
supervised classification approach performs bet-
ter on predicting a coarser level of topic segmen-
tation (Hsueh et al., 2006).
The amount of work being done on speech
summarization has accelerated in recent years.
Maskey and Hirschberg(September 2005) have
explored speech summarization in the domain
of Broadcast News data, finding that combin-
ing prosodic, lexical and structural features yield
the best results. On the ICSI meeting corpus,
Murray et al.(September 2005) compared apply-
ing text summarization approaches to feature-
based approaches including prosodic features,
while Galley(2006) used skip-chain Conditional
Random Fields to model pragmatic dependen-
cies between meeting utterances, and ranked
meeting dialogue acts using a combination or
prosodic, lexical, discourse and structural fea-
tures.
</bodyText>
<sectionHeader confidence="0.995793" genericHeader="conclusions">
4 acknowledgement
</sectionHeader>
<bodyText confidence="0.988147">
This work was supported by the European
Union 6th FWP IST Integrated Project AMI
(Augmented Multi- party Interaction, FP6-
506811)
</bodyText>
<sectionHeader confidence="0.996596" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9996488">
M. Galley, K. McKeown, E. Fosler-Lussier, and
H. Jing. 2003. Discourse segmentation of multi-
party conversation. In Proceedings of the 41st An-
nual Meeting of the Association for Computational
Linguistics.
M. Galley. 2006. A skip-chain conditional ran-
dom field for ranking meeting utterances by im-
portance. In Proceedings of EMNLP-06, Sydney,
Australia.
P. Hsueh, J. Moore, and S. Renals. 2006. Automatic
segmentation of multiparty dialogue. In the Pro-
ceedings of the 11th Conference of the European
Chapter of the Association for Computational Lin-
guistics.
S. Maskey and J. Hirschberg. September 2005. Com-
paring lexial, acoustic/prosodic, discourse and
structural features for speech summarization. In
Proceedings of the 9th European Conference on
Speech Communication and Technology, Lisbon,
Portugal.
G. Murray, S. Renals, and J. Carletta. Septem-
ber 2005. Extractive summarization of meeting
recordings. In Proceedings of the 9th European
Conference on Speech Communication and Tech-
nology, Lisbon, Portugal.
</reference>
<page confidence="0.9978">
10
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.476231">
<title confidence="0.999868">Automatic Segmentation and Summarization of Meeting Speech</title>
<author confidence="0.9737165">Gabriel Murray</author>
<author confidence="0.9737165">Pei-Yun Hsueh</author>
<author confidence="0.9737165">Simon Jonathan Kilgour</author>
<author confidence="0.9737165">Jean Carletta</author>
<author confidence="0.9737165">Johanna Moore</author>
<author confidence="0.9737165">Steve</author>
<affiliation confidence="0.999736">University of</affiliation>
<address confidence="0.502704">Edinburgh,</address>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Galley</author>
<author>K McKeown</author>
<author>E Fosler-Lussier</author>
<author>H Jing</author>
</authors>
<title>Discourse segmentation of multiparty conversation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics.</booktitle>
<marker>Galley, McKeown, Fosler-Lussier, Jing, 2003</marker>
<rawString>M. Galley, K. McKeown, E. Fosler-Lussier, and H. Jing. 2003. Discourse segmentation of multiparty conversation. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Galley</author>
</authors>
<title>A skip-chain conditional random field for ranking meeting utterances by importance.</title>
<date>2006</date>
<booktitle>In Proceedings of EMNLP-06,</booktitle>
<location>Sydney, Australia.</location>
<marker>Galley, 2006</marker>
<rawString>M. Galley. 2006. A skip-chain conditional random field for ranking meeting utterances by importance. In Proceedings of EMNLP-06, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Hsueh</author>
<author>J Moore</author>
<author>S Renals</author>
</authors>
<title>Automatic segmentation of multiparty dialogue.</title>
<date>2006</date>
<booktitle>In the Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="4899" citStr="Hsueh et al., 2006" startWordPosition="799" endWordPosition="802">as the user compresses the meeting to a greater degree the browser gradually removes the less important words from each dialogue act, leaving only the most informative material of the meeting. 3 Related Work Previous work has explored the effect of lexical cohesion and conversational features on characterizing topic boundaries, following Galley et al.(2003). In previous work, we have also studied the problem of predicting topic boundaries at different levels of granularity and showed that a supervised classification approach performs better on predicting a coarser level of topic segmentation (Hsueh et al., 2006). The amount of work being done on speech summarization has accelerated in recent years. Maskey and Hirschberg(September 2005) have explored speech summarization in the domain of Broadcast News data, finding that combining prosodic, lexical and structural features yield the best results. On the ICSI meeting corpus, Murray et al.(September 2005) compared applying text summarization approaches to featurebased approaches including prosodic features, while Galley(2006) used skip-chain Conditional Random Fields to model pragmatic dependencies between meeting utterances, and ranked meeting dialogue </context>
</contexts>
<marker>Hsueh, Moore, Renals, 2006</marker>
<rawString>P. Hsueh, J. Moore, and S. Renals. 2006. Automatic segmentation of multiparty dialogue. In the Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Maskey</author>
<author>J Hirschberg</author>
</authors>
<title>Comparing lexial, acoustic/prosodic, discourse and structural features for speech summarization.</title>
<date>2005</date>
<booktitle>In Proceedings of the 9th European Conference on Speech Communication and Technology,</booktitle>
<location>Lisbon, Portugal.</location>
<marker>Maskey, Hirschberg, 2005</marker>
<rawString>S. Maskey and J. Hirschberg. September 2005. Comparing lexial, acoustic/prosodic, discourse and structural features for speech summarization. In Proceedings of the 9th European Conference on Speech Communication and Technology, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Murray</author>
<author>S Renals</author>
<author>J Carletta</author>
</authors>
<title>Extractive summarization of meeting recordings.</title>
<date>2005</date>
<booktitle>In Proceedings of the 9th European Conference on Speech Communication and Technology,</booktitle>
<location>Lisbon, Portugal.</location>
<marker>Murray, Renals, Carletta, 2005</marker>
<rawString>G. Murray, S. Renals, and J. Carletta. September 2005. Extractive summarization of meeting recordings. In Proceedings of the 9th European Conference on Speech Communication and Technology, Lisbon, Portugal.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>