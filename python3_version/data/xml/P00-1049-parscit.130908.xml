<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000023">
<title confidence="0.987618">
Synchronous Morphological Analysis of Grapheme and
Phoneme for Japanese OCR
</title>
<author confidence="0.878654">
Masaaki Nagata
</author>
<affiliation confidence="0.47272">
NTT Cyber Space Laboratories
</affiliation>
<address confidence="0.788863">
1-1 Hikarinooka, Yokosuka-shi,
Kanagawa 239-0847, Japan
</address>
<email confidence="0.809513">
nagataOnttnly.isl.ntt.co.jp
</email>
<sectionHeader confidence="0.963474" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999353125">
We developed a novel language
model for Japanese based on
grapheme-phoneme tuples, which
is one order of magnitude smaller
than word-based models. We also
developed an alignment algorithm
of graphemes and phonemes for
both ordinary text and OCR out-
put. We show, by experiment, that
the combination of the grapheme-
phoneme tuple ngram model and
the grapheme-phoneme alignment
algorithm significantly improve
character recognition accuracy
if both grapheme and phoneme
representations are given.
</bodyText>
<sectionHeader confidence="0.996334" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998500777777778">
In this paper, we present an alignment algo-
rithm of kanji (Chinese character, grapheme)
and kana (syllabary, phoneme) representa-
tions of the same content, and its application
for recognizing handwritten characters of per-
sonal names.
Even for native Japanese, sometimes it
is very difficult to read Japanese personal
names, because there are about 7,000 Chinese
characters, and each character has several dif-
ferent readings.
Therefore, it is common practice to write a
person&apos;s name in both kanji and kana when
submitting formal documents, such as appli-
cation forms and questionnaires, as illustrated
in Figure 1. This use of a certain amount of
redundancy helps an operator avoid mistakes
in the data entry process. Therefore, it is very
</bodyText>
<table confidence="0.889269">
79- 7 Y 7 .-- 1-
reading last name in kana &apos;Fukuzawa&apos; first name in kana &apos;Yukichi&apos;
144 F&apos;Fa R ,--.A.
name last name in kanji &apos;Fukuzawa&apos; al N n
first name in kanji &apos;Yukichi&apos;
</table>
<figureCaption confidence="0.73324175">
Figure 1: An (artificial) example of how a
Japanese person&apos;s name is written in both
kanji (Chinese character, grapheme) and kana
(syllabary, phoneme).
</figureCaption>
<bodyText confidence="0.999796638888889">
likely that it could also be used to help com-
puters reduce the number of character recog-
nition errors they make.
There is an enormous need for making the
personal name (and address) entry process
automatic, especially in government, banks,
credit card companies, market research com-
panies, etc. However, current Japanese hand-
writing character recognition technology is
not reliable enough for this task. Character
recognition accuracy is now around 90% for
good quality documents, and around 70% for
noisy documents such as FAX output.
Most of the recent research on the applica-
tion of statistical language models to charac-
ter recognition in Japanese uses either char-
acter ngram models or word ngram mod-
els (Konno and Hongo, 1993; Araki et al.,
1994; Mori et al., 1996; Nagata, 1996; Na-
gata, 1998). These techniques require, at
least, a context of a couple of characters
to judge whether a character candidate is
good. Therefore, they cannot be applied to
the name recognition task because Japanese
first and last names are usually only from one
to three characters long (typically two char-
acters).
In this paper, we present a novel language
model that is based on grapheme-phoneme
tuples (a pair of kanji and kana representa-
tion). We also present an aligning algorithm
of graphemes and phonemes both for ordinary
text and OCR output. By experiment, we
show that the language model and the align-
ment algorithm can significantly improve the
overall recognition accuracy.
</bodyText>
<sectionHeader confidence="0.940885" genericHeader="introduction">
2 Grapheme-Phoneme Alignment
</sectionHeader>
<subsectionHeader confidence="0.62611">
of Japanese
</subsectionHeader>
<bodyText confidence="0.955604636363637">
We define grapheme-phoneme alignment of
Japanese as the segmenting of a grapheme se-
quence (kanji representation) into minimum
uncompositional units, each having a cor-
responding subsequence in the phoneme se-
quence (kana representation), and the align-
ing of each unit to the corresponding subse-
quence.
For example, let graphemes and phonemes
of a family name &amp;quot;Fukuzawa&amp;quot; be giR and
7 9. The output of grapheme-phoneme
alignment is two grapheme-phoneme tuples,
4/ 7 and iR/-929, where the left and right
side of &apos;/&apos; indicate graphemes and phonemes,
respectively.
Most grapheme-phoneme correspondence
in Japanese is one-to-many like the above
example. By one-to-many, we mean that
one grapheme corresponds to more than zero
phonemes. However, one-to-zero, zero-to-
one, many-to-many, and crossover correspon-
dences are possible, as illustrated below.
</bodyText>
<listItem confidence="0.963101714285714">
• one-to-zero:
t/q5
• zero-to-one:
.75/i
• many-to-many:
• crossover:
9 47X AK
</listItem>
<bodyText confidence="0.999445339285715">
Many-to-many correspondence results from
semantic translation of the Chinese word to
Japanese. This semantic translation could re-
sult in a crossover correspondence because the
word order of Chinese and Japanese is differ-
ent, as in the last example above. But for
simplicity (and since it is very rare), we will
treat such a case as a many-to-many corre-
spondence.
The advantage of using grapheme-phoneme
tuples as basic units for the language model
is their compactness, which makes the model
one order of magnitude smaller than word-
based models.
Table 1 shows the number of word to-
kens, word types, grapheme-phoneme tokens,
and grapheme-phoneme types in a Japanese
telephone directory of about 45,000,000 res-
idential subscribers. This data was origi-
nally made for an automatic telephone di-
rectory assistance system (Higashida, 1994).
For directory assistance use, grapheme (kanji)
and phoneme (kana) representations of names
were manually aligned. Considering the
fact that Japan has a total population of
120,000,000 people, this is a fairly large and
extensive sample of Japanese personal names.
Selecting names (including both first names
and last names) that appeared at least 5
times results in a name list of 301K words,
which covers more than 98% of the entire sub-
scribers. But about the same coverage can be
obtained by only 21K grapheme-phoneme tu-
ples.
The problem with the language model
based on grapheme-phoneme tuples lies in its
ambiguity. In Japanese, each Chinese char-
acter usually has two different readings: one
comes from its Chinese pronunciation (on-
yomi), and the other comes from its semantic
translation to Japanese (kun-yomi). However,
it is common for one Chinese character to
have several different Chinese-origin readings
because of (a) pronunciation differences that
developed with the passage of time, and (b)
regional pronunciation differences in China.
It is also common for one Chinese character
to have several different Japanese-origin read-
ings because of its semantic ambiguity.
As a result, both grapheme-to-phoneme
and phoneme-to-grapheme conversions are
very ambiguous. Moreover, in general, char-
acter readings for personal names are more
ambiguous than those for ordinary text be-
cause there are a lot of readings that are
used exclusively for personal names. Table 2
</bodyText>
<tableCaption confidence="0.997285">
Table 1: Distribution of words and grapheme-phoneme tuples in a Japanese telephone directory
</tableCaption>
<table confidence="0.9996608">
word tokens word types g-p tokens g-p types
&gt;=10 88.7M 97.6% 196K 14.8% 174M 97.0% 15K 16.7%
&gt;=5 89.3M 98.4% 301K 22.6% 176M 97.8% 21K 23.4%
&gt;=2 90.1M 99.1% 594K 44.8% 177M 98.8% 40K 44.4%
all 90.8M 1,327K 179M 90K
</table>
<tableCaption confidence="0.996771">
Table 2: Comparison of Grapheme-to-
</tableCaption>
<bodyText confidence="0.98668662962963">
Phoneme and Phoneme-to-Grapheme Ambi-
guity in personal names (telephone directory)
and ordinary text (free kanji dictionary)
directory dictionary
max ave max ave
G-to-P 258 10.9 36 3.2
P-to-G 1110 12.1 306 6.2
We call P(G, P) the language model, and
P (G1 , P) the OCR model. We con-
sider a language model based on smallest
grapheme-phoneme tuples. P(G, P) is ap-
proximated by the bigram model of a tuple
of a grapheme pi and a phoneme qi as fol-
lows, where &lt;bos&gt; and &lt;eos&gt; represent the
beginning and end of the sequence.
shows the maximum and average ambigu-
ity of grapheme-to-phoneme and phoneme-to-
grapheme correspondences in the telephone
directory. For comparison, the same numbers
in a public domain Japanese kanji dictionary
(KANJIDIC)1 are also shown to give a rough
estimate of ambiguity in ordinary text. Ta-
ble 2 shows that personal name readings are
significantly more ambiguous than ordinary
text readings, and that phoneme-to-grapheme
mapping is more ambiguous than grapheme-
to-phoneme mapping.
</bodyText>
<sectionHeader confidence="0.9967175" genericHeader="method">
3 The Language Model and the
OCR Model
</sectionHeader>
<subsectionHeader confidence="0.997001">
3.1 Language Model
</subsectionHeader>
<bodyText confidence="0.939311111111111">
We formulate the alignment of graphemes
and phonemes for OCR output in the noisy
channel paradigm. Let input graphemes and
phonemes be G and P, OCR output be G&apos;
and P&apos;. The task is finding the most proba-
ble graphemes G and phonemes P that max-
imize P(G, PIG&apos;, Pi). By using Bayes&apos; rule,
we obtain:
arg max P(G, P&apos;)
</bodyText>
<equation confidence="0.98678475">
G ,P
arg max P (G&apos; , P)P(G P) (1)
G
lftp://ftp.cc.monash.edu.au/pub/nihongo/
P(G, P(M., 1&lt;bos&gt;) P P
P(&lt;eos&gt;1.q„,,p,.) (2)
The bigram probabilities P(gi,pil
igi-1, Pi-1)
</equation>
<bodyText confidence="0.999848583333333">
are estimated from the counts in the cor-
responding events in a corpus that is ei-
ther manually or automatically aligned. The
bigram probability of unknown tuples (not
found in the dictionary) is estimated from
their unigram probability by linear interpo-
lation. The unigram probability of unknown
tuples is estimated as the product of length
probability P(19, lp), grapheme spelling prob-
ability P (g), and grapheme phoneme proba-
bility P(p), where /9 and lp are the length of
a grapheme g and a phoneme p.
</bodyText>
<equation confidence="0.974124">
P(g,p) P (19, 1p)P (g)P (p) (3)
</equation>
<bodyText confidence="0.999588">
We use empirical distribution learned from
training data for length probability P(/9, /p).
We approximate grapheme spelling probabil-
ity P(g) by zerogram model (uniform dis-
tribution) because virtually any combination
of characters could be a legitimate Japanese
name:
</bodyText>
<equation confidence="0.999519333333333">
P (g) H P ( cgi ) = 1 / C9 lig (4)
j=1
(6,P) =
</equation>
<bodyText confidence="0.999515857142857">
where cg j is the individual character in
grapheme sequence, and 1C91 is the character
set size of graphemes.
We approximate phoneme spelling proba-
bility P(p) by bigram model because there
are certain phonetic constraints in phoneme
sequences.
</bodyText>
<equation confidence="0.9929845">
P(p) P (cpil&lt;bos&gt;)1177:72&apos; P (cpi
P(&lt;eos&gt;lePn) (5)
</equation>
<bodyText confidence="0.954869">
where cpi is the individual character in a
phoneme sequence.
</bodyText>
<subsectionHeader confidence="0.640233">
3.2 OCR Model
</subsectionHeader>
<bodyText confidence="0.9999508">
For the OCR model, we assume that
graphemes and phonemes are independently
recognized, and that each character is also in-
dependently recognized within the graphemes
and phonemes.
</bodyText>
<equation confidence="0.999919666666667">
P(Gi,PIG,P) = P(GG)P(PP)
= 1II P(c.vilegi)wf,
iP P(cp/JlepJ) (6)
</equation>
<bodyText confidence="0.881784928571429">
Ideally, the probability that an input
character ci will be recognized as an out-
put character cj should be estimated em-
pirically. However, since there are 6879
graphemes (kanji) and 87 phonemes (kana)
in the Japanese character set, JIS X 0208, it
is impossible to estimate the probability em-
pirically due to data sparseness. Therefore,
we approximate it based on two parameters:
the accuracy of the first candidate p1 and the
cumulative accuracy of all candidates pn.
if ei is the first candidate
else if ei is among the candidates
otherwise
</bodyText>
<equation confidence="0.868803">
(7)
</equation>
<bodyText confidence="0.9989996">
where n is the number of candidates for the
character, and ICI is the character set size.
In this OCR model, regardless of the in-
put and output character pairs, the first can-
didate is always assigned the probability pl.
For candidates other than the first candidate,
the remaining cumulative accuracy pn — p1
is distributed uniformly. For characters not
among the candidates, the remaining proba-
bility mass 1 — pn is distributed uniformly.
</bodyText>
<table confidence="0.930769476190476">
1 T0,0 f&lt;bos&gt;1
2 .750,0(&lt;bos&gt;) &lt;— 1
3 for sx = 0 to ig do
3 for s, = 0 to lp do
4 foreach (gi_i,pi-i) E Tsx do
5 for tx = +1 to Ig do
6 for t, = 8, +1 to lp do
7 = (egts:,ePt4,)
8 if (gi , pi ) Ttx,t, then
9 U {(gi,p0}
10 Otx,ty(gi, pi) &lt;— 0
11 endif
12 if ((ha, -1)
&gt; 95tx,t, (gi , pi)) then
13 Otx,t, (gi, pi) &lt;—
14 endif
12 end
12 end
13 end
14 end
15 end
</table>
<figureCaption confidence="0.957473">
Figure 2: Grapheme-phoneme alignment
algorithm (two-dimensional morphological
analysis algorithm)
</figureCaption>
<sectionHeader confidence="0.9817485" genericHeader="method">
4 Grapheme-Phoneme Alignment
Algorithm
</sectionHeader>
<subsectionHeader confidence="0.998777">
4.1 Ordinary Text (a Pair of Strings)
</subsectionHeader>
<bodyText confidence="0.999692684210526">
First, we describe a Japanese grapheme-
phoneme alignment algorithm for ordinary
text, where its input is a pair of graphemes
and phonemes. Although the algorithm does
not identify word boundaries or parts of
speech, we call this alignment task &amp;quot;syn-
chronous morphological analysis&amp;quot; because
grapheme-phoneme tuples in Japanese per-
sonal names can be thought of as a minimal
compositional unit that has a certain mean-
ing, which is the technical definition of mor-
phemes. Moreover, the algorithm is a two-
dimensional extension of a Japanese morpho-
logical analysis algorithm (Nagata, 1994).
Let input graphemes and phonemes be G =
cg1 cm., and P = cpi cpi p, where cg and
cp are individual graphemes and phonemes.
In order to find a sequence of grapheme-
phoneme tuples al ni
</bodyText>
<listItem confidence="0.94925675">
• • • ,gn,Pn that maxi-
mizes P(G , P) described in Equation (2), we
use two-dimensional dynamic programming,
as shown in Figure 2.
</listItem>
<bodyText confidence="0.98303">
In Figure 2, TT,y is a table that holds
grapheme-phoneme tuples ending at position
</bodyText>
<equation confidence="0.520286">
P(ei lei)
</equation>
<bodyText confidence="0.90537375">
(x, y). Or,y (g,,p,) holds the maximum prob-
ability of grapheme-phoneme tuple sequences
starting from (0, 0) and ending at (x, y) whose
final tuple is (g,, p7).
The algorithm starts from (0, 0) which
corresponds to the beginning of graphemes
and phonemes, and proceeds toward the end
of graphemes and phonemes (/9, /p), charac-
ter by character, for both graphemes and
phonemes. At every point (x, y) in the region
0 &lt; x &lt;19,0 &lt; y &lt; lp, this algorithm updates
the maximum probability for the subsequence
of grapheme-phoneme tuples OT,y (g7, p7) (line
12 and 13 in Figure 2). Thus, at (/9, /p), we
can obtain a sequence of tuples that maxi-
mizes P(G,P).
</bodyText>
<figure confidence="0.979666583333333">
(4,7)
2
0117,-
&lt;T7N0
24
7-9-9
(1 2 4
/
7100
24
MR/ 4P9
&lt;T700.&gt;
</figure>
<figureCaption confidence="0.95622325">
Figure 3: A snapshot of the grapheme-
phoneme alignment for ordinary text
Figure 3 is a snapshot of the grapheme-
phoneme alignment, where the input
</figureCaption>
<bodyText confidence="0.99380141025641">
graphemes and phonemes are 4&apos; and
7 -92 9 and the current point is
(2,4). There are four grapheme-phoneme
tuples ending here, and three tuples starting
here. All combinations of these tuples are
searched, and the maximum probabilities
up to the ending point of each tuples are
updated.
4.2 OCR output (a Pair of Character
Matrices)
Next, we describe a grapheme-phoneme align-
ment algorithm for OCR output. We assume
there are no segmentation errors in the OCR
output, which in practical terms means that
the form has a grid for each character. In this
case, we call the OCR output character ma-
trix, in which each character has a list of sev-
eral candidates ordered by their certainties.
In fact, it is not difficult to extend the align-
ment algorithm to handle a character lattice,
which is a data structure that considers the
possibility of segmentation errors. However,
we limited the input to a character matrix
because we don&apos;t know how to make an OCR
model that takes segmentation errors into ac-
count.
The alignment algorithm for OCR output
is basically the same as shown in Figure 2.
However, since there are sometimes no cor-
rect characters among the candidates, we in-
troduce an approximate match between the
grapheme-phoneme tuples in the dictionary
and those in the character matrix (Here, we
define a substring of a character matrix as a
substring that is formed by selecting one char-
acter from each candidate list).
At each point (x, y), first, we retrieve
grapheme-phoneme tuples using graphemes
as keys:
</bodyText>
<listItem confidence="0.9969797">
1. List all tuples in the dictionary whose
graphemes are a substring in the char-
acter matrix of graphemes starting from
x.
2. Compute the minimum edit distance of
their phonemes and substrings in the
character matrix of phonemes starting
from y.
3. Filter those tuples by edit distance and
frequency.
</listItem>
<bodyText confidence="0.9954367">
As a threshold of edit distance, we filtered
out tuples whose edit distance of phonemes
is more than or equal to 1,12, except when
/p = 1. Note if /p = 1, edit distance cannot
be used for filtering because it is either 0 or 1.
Thus, we sorted the tuples by frequencies and
selected the top 5 tuples. These thresholds
were determined through experiments.
We then retrieve grapheme-phoneme tuples
using phonemes as keys:
</bodyText>
<footnote confidence="0.573387">
1. List all tuples in the dictionary whose
phonemes are a substring in the charac-
ter matrix of graphemes starting from y.
</footnote>
<figure confidence="0.996138285714286">
0
(0
4
IA
7100
4
7100
</figure>
<listItem confidence="0.9946245">
2. Compute the minimum edit distance of
their graphemes and substrings in the
character matrix of graphemes starting
from x.
3. Filter those tuples by edit distance and
frequency.
</listItem>
<bodyText confidence="0.997381">
We also set the thresholds of edit distance
and frequency of graphemes as /9/2 and 5.
Finally, for unknown tuples, we list all com-
binations of the prefixes of the first candidates
of graphemes starting from x and those of
phonemes starting from y, if they are not al-
ready listed by the above approximate match.
</bodyText>
<figureCaption confidence="0.98477">
Figure 4: A snapshot of grapheme-phoneme
alignment for OCR output
</figureCaption>
<bodyText confidence="0.873815941176471">
Figure 4 is a snapshot of grapheme-
phoneme alignment for OCR output.
For each character position of the input
graphemes 4&apos; and input phonemes 7
-92 9 two recognition candidates
are presented. Note there are three types of
grapheme-phoneme tuples: exactly matched,
approximately matched, and unknown. For
example, from (2,4) to (3, 5), the tuple
is generated because both grapheme rtj and
phoneme are in the matrix. From (2, 4) to
(3,6), the tuple is generated because
phoneme is in the matrix, and the
tuple is highly frequent. Also from (2, 4) to
(3,6), an unknown tuple rti/ -3-- is generated
because rti and are the prefixes of the
first candidates of graphemes and phonemes.
</bodyText>
<sectionHeader confidence="0.986705" genericHeader="evaluation">
5 Experiment
</sectionHeader>
<subsectionHeader confidence="0.999342">
5.1 Training and Test Data
</subsectionHeader>
<bodyText confidence="0.99998985">
We used a Japanese name list of 1.3M words,
which was originally made for an automatic
telephone directory of about 45,000,000 res-
idential subscribers (Higashida, 1994). Al-
though the grapheme-phoneme alignment of
the name list was manually done, because
of the enormous amount of data in the tele-
phone directory, grapheme-phoneme align-
ment of lower frequency names is slightly
noisy. Therefore, we filtered out names which
appeared no more than five times in the
Japanese telephone directory.
This resulted in a name list of 301K words,
which covers more than 98% of the entire sub-
scribers. As shown in Table 1, there are 176M
grapheme-phoneme tuple tokens in the name
list, and there are 21K different grapheme-
phoneme tuple types. We used 90% of the
name list of 301K words for training, and non-
overlapping 1000 names (words) for testing.
</bodyText>
<subsectionHeader confidence="0.8119095">
5.2 Grapheme-Phoneme Alignment
Accuracy for Ordinary Text
</subsectionHeader>
<bodyText confidence="0.99999347826087">
Other than the grapheme-phoneme align-
ment model trained from manually aligned
data, we made an alignment model which
is bootstrapped from a public domain
Japanese grapheme-to-phoneme dictionary
(KANJIDIC). We call the former a supervised
model, and the latter an unsupervised model.
As shown in Table 2, KANJIDIC has 3.2
readings for each Chinese character on the av-
erage. To make an alignment model, we con-
sider the dictionary itself as a corpus, that is,
we assign a uniform probability to all possi-
ble grapheme-phoneme tuples. The sum of
the probabilities of unknown tuples is esti-
mated by the Witten-Bell method (Witten
and Bell, 1991), and redistributed based on
the unknown tuple model, Equation (3).
Table 3 shows the grapheme-phoneme
alignment accuracies of the supervised and
unsupervised model. It was expected that the
supervised model would achieve a very high
grapheme-phoneme alignment accuracy. Sur-
prisingly, however, the unsupervised model
</bodyText>
<figure confidence="0.983271">
(2, /1)
(°&apos; °)1
0 WR 1 2 ,=ti 3 ••
tsg,
Error Correction Accuracy
1
0.95
Character Recognition Accuracy (After NLP)
0.9
0.85
0.8
0.75
0.7
0.65
First Rank Accuracy
Cumulative Accuracy
Grapheme (G-P aligned)
Phoneme (G-P aligned)
Grapheme (G only)
Phoneme (P only)
0.6
0.55
0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95
Character Recognition Accuracy (Before NLP)
</figure>
<bodyText confidence="0.99986730952381">
grapheme to phoneme conversion, in partic-
ular, using finite state techniques. However,
they dealt with either grapheme-to-phoneme
conversion or phoneme-to-grapheme conver-
sion (one is input and the other is out-
put), while we are working on synchronous
analysis of graphemes and phonemes (both
grarphemes and phonemes are inputs and
their alignments are output). Thus, there is
little relevance between these.
As far as the authors know, the only pa-
per that addresses the issue of grapheme-
phoneme alignment accuracy in Japanese is
one by Baldwin and Tanaka (1999). They re-
ported 98.29% accuracy for general vocabu-
lary words taken from a Japanese dictionary,
by using an alignment model based on a score
similar to TF-IDF, and an incremental unsu-
pervised learning algorithm. It is very dif-
ficult to compare their results with ours be-
cause of the differences in the training and
test data used. However, since we assume, in
general, the name task is significantly more
difficult than the general vocabulary task, we
consider our result of 99.6% recall by super-
vised model and 98.6% recall by unsupervised
model to have greater significance than their
results.
Nagata (1998) proposed a Japanese OCR
error correction method using word-based
language model and character shape sim-
ilarity. Compared with our simple OCR
model Equation (6), their model can sort cor-
rection candidates with the same edit dis-
tance based on character shape similarity.
This would be a very effective way to filter
out grapheme-phoneme tuples retrieved from
phonemes as keys in approximate match-
ing, since phoneme-to-grapheme conversion is
more ambiguous. Thus, we are considering
implementing their OCR model as a subject
for future work.
</bodyText>
<sectionHeader confidence="0.991741" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999995545454546">
We developed a novel language model based
on grapheme-phoneme tuples, which is one
order of magnitude smaller than word-based
models. We also developed an alignment al-
gorithm of graphemes and phonemes for both
ordinary text and OCR output. By using the
language model and the alignment algorithm,
we were able to significantly improve char-
acter recognition accuracy if both grapheme
and phoneme representations of the input are
given at the same time.
</bodyText>
<sectionHeader confidence="0.96588" genericHeader="acknowledgments">
Acknowledgment
</sectionHeader>
<bodyText confidence="0.99979575">
This research was done while the author was
visiting at AT&amp;T Labs. I wish to thank Ken
Church and other members at AT&amp;T Labs for
their helpful comments and discussions.
</bodyText>
<sectionHeader confidence="0.998506" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999487675">
Tetsuo Araki, Satoru Ikehara, Nobuyuki Tsukahara,
and Yasunori Komatsu. 1994. An evaluation to de-
tect and correct erroneous characters wrongly sub-
stituted, deleted and inserted in Japanese and En-
glish sentences using Markov models. In COLING-
94, pages 187 193.
Timothy Baldwin and Hozumi Tanaka. 1999. The
applications of unsupervised learning to Japanese
grapheme-phoneme alignment. In ACL&apos;99 Work-
shop on Unsupervised Learning in Natural Lan-
guage Processing, pages 9 16.
Masanobu Higashida. 1994. A fully automated di-
rectory assistance service that accommodates de-
generated keyword input via telephones. In Pacific
Telecommunication Conference, pages 167 174.
Akiko Konno and Yasuo Hongo. 1993. Postprocessing
algorithm based on the probabilistic and seman-
tic method for Japanese OCR. In Proceedings of
ICDAR-93, pages 646 649.
Hiroki Mori, Hirotomo Aso, and Shozo Makin°. 1996.
Robust n-gram model of Japanese character and
its application to document recognition. IEICE
Transactions on Information and Systems, E79-
D(5):471 476.
Masaaki Nagata. 1994. A stochastic Japanese mor-
phological analyzer using a forward-dp backward-
a* n-best search algorithm. In COLING-94, pages
201 207.
Masaaki Nagata. 1996. Context-based spelling cor-
rection for Japanese OCR. In COLING-96, pages
806 811.
Masaaki Nagata. 1998. Japanese OCR error correc-
tion using character shape similarity and statistical
language model. In COLING-ACL&apos;98, pages 922
928.
Ian H. Witten and Timothy C. Bell. 1991. The zero-
frequency problem: Estimating the probabilities of
novel events in adaptive text compression. IEEE
Transaction on Information Theory, 37(4):1085
1094.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.955142">
<title confidence="0.9986505">Synchronous Morphological Analysis of Grapheme and Phoneme for Japanese OCR</title>
<author confidence="0.998904">Masaaki Nagata</author>
<affiliation confidence="0.995415">Space Laboratories</affiliation>
<address confidence="0.9926115">1-1 Hikarinooka, Yokosuka-shi, Kanagawa 239-0847, Japan</address>
<email confidence="0.975847">nagataOnttnly.isl.ntt.co.jp</email>
<abstract confidence="0.999882647058823">We developed a novel language model for Japanese based on which is one order of magnitude smaller than word-based models. We also developed an alignment algorithm of graphemes and phonemes for both ordinary text and OCR output. We show, by experiment, that the combination of the graphemephoneme tuple ngram model and the grapheme-phoneme alignment algorithm significantly improve character recognition accuracy if both grapheme and phoneme representations are given.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Tetsuo Araki</author>
<author>Satoru Ikehara</author>
<author>Nobuyuki Tsukahara</author>
<author>Yasunori Komatsu</author>
</authors>
<title>An evaluation to detect and correct erroneous characters wrongly substituted, deleted and inserted in Japanese and English sentences using Markov models.</title>
<date>1994</date>
<booktitle>In COLING94,</booktitle>
<pages>187--193</pages>
<contexts>
<context position="2533" citStr="Araki et al., 1994" startWordPosition="391" endWordPosition="394">us need for making the personal name (and address) entry process automatic, especially in government, banks, credit card companies, market research companies, etc. However, current Japanese handwriting character recognition technology is not reliable enough for this task. Character recognition accuracy is now around 90% for good quality documents, and around 70% for noisy documents such as FAX output. Most of the recent research on the application of statistical language models to character recognition in Japanese uses either character ngram models or word ngram models (Konno and Hongo, 1993; Araki et al., 1994; Mori et al., 1996; Nagata, 1996; Nagata, 1998). These techniques require, at least, a context of a couple of characters to judge whether a character candidate is good. Therefore, they cannot be applied to the name recognition task because Japanese first and last names are usually only from one to three characters long (typically two characters). In this paper, we present a novel language model that is based on grapheme-phoneme tuples (a pair of kanji and kana representation). We also present an aligning algorithm of graphemes and phonemes both for ordinary text and OCR output. By experiment,</context>
</contexts>
<marker>Araki, Ikehara, Tsukahara, Komatsu, 1994</marker>
<rawString>Tetsuo Araki, Satoru Ikehara, Nobuyuki Tsukahara, and Yasunori Komatsu. 1994. An evaluation to detect and correct erroneous characters wrongly substituted, deleted and inserted in Japanese and English sentences using Markov models. In COLING94, pages 187 193.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Hozumi Tanaka</author>
</authors>
<title>The applications of unsupervised learning to Japanese grapheme-phoneme alignment.</title>
<date>1999</date>
<booktitle>In ACL&apos;99 Workshop on Unsupervised Learning in Natural Language Processing,</booktitle>
<pages>9--16</pages>
<contexts>
<context position="19660" citStr="Baldwin and Tanaka (1999)" startWordPosition="3244" endWordPosition="3247">5 0.8 0.85 0.9 0.95 Character Recognition Accuracy (Before NLP) grapheme to phoneme conversion, in particular, using finite state techniques. However, they dealt with either grapheme-to-phoneme conversion or phoneme-to-grapheme conversion (one is input and the other is output), while we are working on synchronous analysis of graphemes and phonemes (both grarphemes and phonemes are inputs and their alignments are output). Thus, there is little relevance between these. As far as the authors know, the only paper that addresses the issue of graphemephoneme alignment accuracy in Japanese is one by Baldwin and Tanaka (1999). They reported 98.29% accuracy for general vocabulary words taken from a Japanese dictionary, by using an alignment model based on a score similar to TF-IDF, and an incremental unsupervised learning algorithm. It is very difficult to compare their results with ours because of the differences in the training and test data used. However, since we assume, in general, the name task is significantly more difficult than the general vocabulary task, we consider our result of 99.6% recall by supervised model and 98.6% recall by unsupervised model to have greater significance than their results. Nagat</context>
</contexts>
<marker>Baldwin, Tanaka, 1999</marker>
<rawString>Timothy Baldwin and Hozumi Tanaka. 1999. The applications of unsupervised learning to Japanese grapheme-phoneme alignment. In ACL&apos;99 Workshop on Unsupervised Learning in Natural Language Processing, pages 9 16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masanobu Higashida</author>
</authors>
<title>A fully automated directory assistance service that accommodates degenerated keyword input via telephones.</title>
<date>1994</date>
<booktitle>In Pacific Telecommunication Conference,</booktitle>
<pages>167--174</pages>
<contexts>
<context position="5049" citStr="Higashida, 1994" startWordPosition="785" endWordPosition="786">fferent, as in the last example above. But for simplicity (and since it is very rare), we will treat such a case as a many-to-many correspondence. The advantage of using grapheme-phoneme tuples as basic units for the language model is their compactness, which makes the model one order of magnitude smaller than wordbased models. Table 1 shows the number of word tokens, word types, grapheme-phoneme tokens, and grapheme-phoneme types in a Japanese telephone directory of about 45,000,000 residential subscribers. This data was originally made for an automatic telephone directory assistance system (Higashida, 1994). For directory assistance use, grapheme (kanji) and phoneme (kana) representations of names were manually aligned. Considering the fact that Japan has a total population of 120,000,000 people, this is a fairly large and extensive sample of Japanese personal names. Selecting names (including both first names and last names) that appeared at least 5 times results in a name list of 301K words, which covers more than 98% of the entire subscribers. But about the same coverage can be obtained by only 21K grapheme-phoneme tuples. The problem with the language model based on grapheme-phoneme tuples l</context>
<context position="17056" citStr="Higashida, 1994" startWordPosition="2828" endWordPosition="2829">mately matched, and unknown. For example, from (2,4) to (3, 5), the tuple is generated because both grapheme rtj and phoneme are in the matrix. From (2, 4) to (3,6), the tuple is generated because phoneme is in the matrix, and the tuple is highly frequent. Also from (2, 4) to (3,6), an unknown tuple rti/ -3-- is generated because rti and are the prefixes of the first candidates of graphemes and phonemes. 5 Experiment 5.1 Training and Test Data We used a Japanese name list of 1.3M words, which was originally made for an automatic telephone directory of about 45,000,000 residential subscribers (Higashida, 1994). Although the grapheme-phoneme alignment of the name list was manually done, because of the enormous amount of data in the telephone directory, grapheme-phoneme alignment of lower frequency names is slightly noisy. Therefore, we filtered out names which appeared no more than five times in the Japanese telephone directory. This resulted in a name list of 301K words, which covers more than 98% of the entire subscribers. As shown in Table 1, there are 176M grapheme-phoneme tuple tokens in the name list, and there are 21K different graphemephoneme tuple types. We used 90% of the name list of 301K</context>
</contexts>
<marker>Higashida, 1994</marker>
<rawString>Masanobu Higashida. 1994. A fully automated directory assistance service that accommodates degenerated keyword input via telephones. In Pacific Telecommunication Conference, pages 167 174.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Akiko Konno</author>
<author>Yasuo Hongo</author>
</authors>
<title>Postprocessing algorithm based on the probabilistic and semantic method for Japanese OCR.</title>
<date>1993</date>
<booktitle>In Proceedings of ICDAR-93,</booktitle>
<pages>646--649</pages>
<contexts>
<context position="2513" citStr="Konno and Hongo, 1993" startWordPosition="387" endWordPosition="390">ake. There is an enormous need for making the personal name (and address) entry process automatic, especially in government, banks, credit card companies, market research companies, etc. However, current Japanese handwriting character recognition technology is not reliable enough for this task. Character recognition accuracy is now around 90% for good quality documents, and around 70% for noisy documents such as FAX output. Most of the recent research on the application of statistical language models to character recognition in Japanese uses either character ngram models or word ngram models (Konno and Hongo, 1993; Araki et al., 1994; Mori et al., 1996; Nagata, 1996; Nagata, 1998). These techniques require, at least, a context of a couple of characters to judge whether a character candidate is good. Therefore, they cannot be applied to the name recognition task because Japanese first and last names are usually only from one to three characters long (typically two characters). In this paper, we present a novel language model that is based on grapheme-phoneme tuples (a pair of kanji and kana representation). We also present an aligning algorithm of graphemes and phonemes both for ordinary text and OCR ou</context>
</contexts>
<marker>Konno, Hongo, 1993</marker>
<rawString>Akiko Konno and Yasuo Hongo. 1993. Postprocessing algorithm based on the probabilistic and semantic method for Japanese OCR. In Proceedings of ICDAR-93, pages 646 649.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroki Mori</author>
<author>Hirotomo Aso</author>
<author>Shozo Makin°</author>
</authors>
<title>Robust n-gram model of Japanese character and its application to document recognition.</title>
<date>1996</date>
<journal>IEICE Transactions on Information and Systems,</journal>
<volume>79</volume>
<pages>476</pages>
<marker>Mori, Aso, Makin°, 1996</marker>
<rawString>Hiroki Mori, Hirotomo Aso, and Shozo Makin°. 1996. Robust n-gram model of Japanese character and its application to document recognition. IEICE Transactions on Information and Systems, E79-D(5):471 476.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masaaki Nagata</author>
</authors>
<title>A stochastic Japanese morphological analyzer using a forward-dp backwarda* n-best search algorithm.</title>
<date>1994</date>
<booktitle>In COLING-94,</booktitle>
<pages>201--207</pages>
<contexts>
<context position="11971" citStr="Nagata, 1994" startWordPosition="1941" endWordPosition="1942">rdinary Text (a Pair of Strings) First, we describe a Japanese graphemephoneme alignment algorithm for ordinary text, where its input is a pair of graphemes and phonemes. Although the algorithm does not identify word boundaries or parts of speech, we call this alignment task &amp;quot;synchronous morphological analysis&amp;quot; because grapheme-phoneme tuples in Japanese personal names can be thought of as a minimal compositional unit that has a certain meaning, which is the technical definition of morphemes. Moreover, the algorithm is a twodimensional extension of a Japanese morphological analysis algorithm (Nagata, 1994). Let input graphemes and phonemes be G = cg1 cm., and P = cpi cpi p, where cg and cp are individual graphemes and phonemes. In order to find a sequence of graphemephoneme tuples al ni • • • ,gn,Pn that maximizes P(G , P) described in Equation (2), we use two-dimensional dynamic programming, as shown in Figure 2. In Figure 2, TT,y is a table that holds grapheme-phoneme tuples ending at position P(ei lei) (x, y). Or,y (g,,p,) holds the maximum probability of grapheme-phoneme tuple sequences starting from (0, 0) and ending at (x, y) whose final tuple is (g,, p7). The algorithm starts from (0, 0)</context>
</contexts>
<marker>Nagata, 1994</marker>
<rawString>Masaaki Nagata. 1994. A stochastic Japanese morphological analyzer using a forward-dp backwarda* n-best search algorithm. In COLING-94, pages 201 207.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masaaki Nagata</author>
</authors>
<title>Context-based spelling correction for Japanese OCR. In</title>
<date>1996</date>
<booktitle>COLING-96,</booktitle>
<pages>806--811</pages>
<contexts>
<context position="2566" citStr="Nagata, 1996" startWordPosition="399" endWordPosition="400">nd address) entry process automatic, especially in government, banks, credit card companies, market research companies, etc. However, current Japanese handwriting character recognition technology is not reliable enough for this task. Character recognition accuracy is now around 90% for good quality documents, and around 70% for noisy documents such as FAX output. Most of the recent research on the application of statistical language models to character recognition in Japanese uses either character ngram models or word ngram models (Konno and Hongo, 1993; Araki et al., 1994; Mori et al., 1996; Nagata, 1996; Nagata, 1998). These techniques require, at least, a context of a couple of characters to judge whether a character candidate is good. Therefore, they cannot be applied to the name recognition task because Japanese first and last names are usually only from one to three characters long (typically two characters). In this paper, we present a novel language model that is based on grapheme-phoneme tuples (a pair of kanji and kana representation). We also present an aligning algorithm of graphemes and phonemes both for ordinary text and OCR output. By experiment, we show that the language model </context>
</contexts>
<marker>Nagata, 1996</marker>
<rawString>Masaaki Nagata. 1996. Context-based spelling correction for Japanese OCR. In COLING-96, pages 806 811.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masaaki Nagata</author>
</authors>
<title>Japanese OCR error correction using character shape similarity and statistical language model.</title>
<date>1998</date>
<booktitle>In COLING-ACL&apos;98,</booktitle>
<pages>922--928</pages>
<contexts>
<context position="2581" citStr="Nagata, 1998" startWordPosition="401" endWordPosition="403">try process automatic, especially in government, banks, credit card companies, market research companies, etc. However, current Japanese handwriting character recognition technology is not reliable enough for this task. Character recognition accuracy is now around 90% for good quality documents, and around 70% for noisy documents such as FAX output. Most of the recent research on the application of statistical language models to character recognition in Japanese uses either character ngram models or word ngram models (Konno and Hongo, 1993; Araki et al., 1994; Mori et al., 1996; Nagata, 1996; Nagata, 1998). These techniques require, at least, a context of a couple of characters to judge whether a character candidate is good. Therefore, they cannot be applied to the name recognition task because Japanese first and last names are usually only from one to three characters long (typically two characters). In this paper, we present a novel language model that is based on grapheme-phoneme tuples (a pair of kanji and kana representation). We also present an aligning algorithm of graphemes and phonemes both for ordinary text and OCR output. By experiment, we show that the language model and the alignme</context>
<context position="20268" citStr="Nagata (1998)" startWordPosition="3347" endWordPosition="3348">1999). They reported 98.29% accuracy for general vocabulary words taken from a Japanese dictionary, by using an alignment model based on a score similar to TF-IDF, and an incremental unsupervised learning algorithm. It is very difficult to compare their results with ours because of the differences in the training and test data used. However, since we assume, in general, the name task is significantly more difficult than the general vocabulary task, we consider our result of 99.6% recall by supervised model and 98.6% recall by unsupervised model to have greater significance than their results. Nagata (1998) proposed a Japanese OCR error correction method using word-based language model and character shape similarity. Compared with our simple OCR model Equation (6), their model can sort correction candidates with the same edit distance based on character shape similarity. This would be a very effective way to filter out grapheme-phoneme tuples retrieved from phonemes as keys in approximate matching, since phoneme-to-grapheme conversion is more ambiguous. Thus, we are considering implementing their OCR model as a subject for future work. 7 Conclusion We developed a novel language model based on gr</context>
</contexts>
<marker>Nagata, 1998</marker>
<rawString>Masaaki Nagata. 1998. Japanese OCR error correction using character shape similarity and statistical language model. In COLING-ACL&apos;98, pages 922 928.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian H Witten</author>
<author>Timothy C Bell</author>
</authors>
<title>The zerofrequency problem: Estimating the probabilities of novel events in adaptive text compression.</title>
<date>1991</date>
<journal>IEEE Transaction on Information Theory,</journal>
<volume>37</volume>
<issue>4</issue>
<pages>1094</pages>
<contexts>
<context position="18425" citStr="Witten and Bell, 1991" startWordPosition="3051" endWordPosition="3054">apheme-phoneme alignment model trained from manually aligned data, we made an alignment model which is bootstrapped from a public domain Japanese grapheme-to-phoneme dictionary (KANJIDIC). We call the former a supervised model, and the latter an unsupervised model. As shown in Table 2, KANJIDIC has 3.2 readings for each Chinese character on the average. To make an alignment model, we consider the dictionary itself as a corpus, that is, we assign a uniform probability to all possible grapheme-phoneme tuples. The sum of the probabilities of unknown tuples is estimated by the Witten-Bell method (Witten and Bell, 1991), and redistributed based on the unknown tuple model, Equation (3). Table 3 shows the grapheme-phoneme alignment accuracies of the supervised and unsupervised model. It was expected that the supervised model would achieve a very high grapheme-phoneme alignment accuracy. Surprisingly, however, the unsupervised model (2, /1) (°&apos; °)1 0 WR 1 2 ,=ti 3 •• tsg, Error Correction Accuracy 1 0.95 Character Recognition Accuracy (After NLP) 0.9 0.85 0.8 0.75 0.7 0.65 First Rank Accuracy Cumulative Accuracy Grapheme (G-P aligned) Phoneme (G-P aligned) Grapheme (G only) Phoneme (P only) 0.6 0.55 0.55 0.6 0.</context>
</contexts>
<marker>Witten, Bell, 1991</marker>
<rawString>Ian H. Witten and Timothy C. Bell. 1991. The zerofrequency problem: Estimating the probabilities of novel events in adaptive text compression. IEEE Transaction on Information Theory, 37(4):1085 1094.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>