<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.743607">
DATR AS A LEXICAL COMPONENT FOR PATR
</title>
<author confidence="0.712404">
James Kilbury, Petra Naerger, Ingrid Renz
</author>
<bodyText confidence="0.390421">
Seminar fur Allgemeine Sprachwissenschaft
Heinrich-Heine-Universitat DUsseldorf
Universitatsstralle 1
D-4000 Dusseldorf 1
</bodyText>
<affiliation confidence="0.714449">
Federal Republic of Germany
</affiliation>
<address confidence="0.548266">
e-mail: kilbury@ddOrud8 Lbitnet
naerger@ddOrud8 Lbitnet
renz@ddOrud8 Lbitnet
</address>
<email confidence="0.506139">
ABSTRACT
</email>
<bodyText confidence="0.999789888888889">
The representation of lexical entries
requires special means which basic PATR sys-
tems do not include. The language DATR,
however, can be used to define an inheritance
network serving as the lexical component. The
integration of such a module into an existing
PATR system leads to various problems which
are discussed together with possible solutions
in this paper.
</bodyText>
<sectionHeader confidence="0.97817" genericHeader="abstract">
1 MOTIVATION
</sectionHeader>
<bodyText confidence="0.999960823529412">
In the project &amp;quot;Simulation of Lexical
Acquisition&amp;quot; (SIMLEX) unification is used to
create new lexical entries through the monoto-
nic accumulation of contextual grammatical
information during parsing. The system which
we implemented for this purpose is a variant of
PATR as described in (Shieber, 1986).
Besides collecting the appropriate infor-
mation for an unknown word, i.e. a lexeme not
already specified in the given lexicon, the cre-
ation of its new lexical entry is a major goal.
In this context questions about the nature of
lexical information, the structuring, and the
representation of this information must be an-
swered. The present paper is mainly concerned
with the structuring and representation of infor-
mation in lexical entries.
</bodyText>
<sectionHeader confidence="0.9997115" genericHeader="keywords">
2 REPRESENTATION OF LEXICAL
INFORMATION
</sectionHeader>
<bodyText confidence="0.987189358974359">
We assume that certain conditions must
be met by an adequate representation of lexical
information. The most important of these is that
it captures linguistic generalizations, which
means that associated information is represented
together or bundled. One advantage of this
bundled information is its reusability, which
allows redundancy to be reduced. The represen-
tation of lexical information should enable us
to express a further kind of generalization,
namely the relations between regularity, sub-
regularity, and irregularity. Furthermore, the
representation has to be computationally tracta-
ble and -- possibly with the addition of &amp;quot;syntac-
tic sugar&amp;quot; -- more or less readable for human
users.
The formalism of PATR offers two
possible means of representing lexical informa-
tion. First of all, the information can be encod-
ed in feature structures directly. Except for
computational tractability, none of the other
criteria are met. The second facility consists of
macros or templates which assemble the lin-
guistic information so that it can be reused in
various places in the lexicon. This meets the
most important of the above-mentioned condi-
tions and reduces redundancy. But the encoded
information is inherited monotonically, i.e. only
regularities can be expressed. In order to struc-
ture lexical information adequately, other rela-
tions like subregularities and exceptions should
also be expressible.
Macros fail to achieve this, whereas
default inheritance networks are well-suited for
the purpose. In the following section we give
an overview of one such network formalism
which was primarily designed for representing
lexical information.
- 137 -
</bodyText>
<sectionHeader confidence="0.955737" genericHeader="method">
3 OVERVIEW OF DATR
</sectionHeader>
<bodyText confidence="0.978474434782609">
DATR (described in detail by Evans/
Gazdar, 1989a; 1989b; 1990) is a declarative
language for the definition of semantic net-
works which allows for defaults as well as
multiple inheritance. Its general properties are
non-monotonicity, functionality, and determinis-
tic search.
A DATR theory (or network descrip-
tion) is a set of axioms (or expressions) which
are related to each other by references. Togeth-
er they define a hierarchical structure, a net.
Both regularities and exceptions can be ex-
pressed, regularities using default inheritance,
and exceptions, overriding.
DATR axioms consist of node-path
pairs associated with a right-hand side. This
can be a value (atomic or list), or an evaluable
DATR expression if the value is to be inherit-
ed from another node, path, or node-path pair.
The following DATR theory comprising three
node definitions&apos; encodes familiar linguistic
information to illustrate some relevant DATR
features:
</bodyText>
<equation confidence="0.90104">
(1)
</equation>
<construct confidence="0.743097">
LEXICAL: &lt;syn major bar&gt; = zero.
NOUN: &lt;&gt;== LEXICAL
&lt;syn major nv n&gt; == yes
&lt;syn major nv v&gt; == no.
ADJ: &lt;&gt; == LEXICAL
&lt;syn major nv n&gt; == NOUN
&lt;syn major nv v&gt; ==
&lt;syn major nv n&gt;.
</construct>
<bodyText confidence="0.897205125">
The represented information can be
retrieved with special DATR queries. These
also consist of a node-path pair, whose evalua-
tion returns the value sought. With the above
DATR description the following examples show
sensible DATR queries and their corresponding
values:
(2)
</bodyText>
<construct confidence="0.715133692307692">
NOUN:&lt;syn major nv n&gt;?
yes (atomic value)
NOUN:&lt;syn major nv v&gt;?
no (atomic value)
NOUN:&lt;syn major tar&gt; ?
zero (inherited from node LEXICAL)
ADJ:&lt;syn major nv n&gt;?
yes (inherited from node NOUN)
ADJ:&lt;syn major nv. v&gt;?
yes (inherited from node NOUN via path
&lt;syn major nv n&gt; in node ADJ)
ADJ:&lt;syn major bar&gt; ?
zero (inherited from node LEXICAL)
</construct>
<bodyText confidence="0.999326777777778">
Seven inference rules and a default
mechanism are given for the evaluation of
DATR queries. Their precise semantics and
properties are described in (Evans/Gazdar,
1989b; 1990).
A major feature of DATR is its distinc-
tion between global and local inheritance. In
the above example only local inheritance is
involved, but global inheritance plays a crucial
role in one of the later examples. Variables
constitute an additional device available in
DATR but are assumed to have the status of
abbreviations.
Despite their syntactic similarities,
DATR and PATR differ completely in their
semantics, so that there is no obvious way of
relating the two formalisms to each other. Some
approaches are discussed in the next section.
</bodyText>
<sectionHeader confidence="0.99909" genericHeader="method">
4 RELATING DATR AND PATR
</sectionHeader>
<bodyText confidence="0.999866833333333">
A PATR system needs to have the
lexical information it uses encoded in feature
structures consisting of attribute-value pairs.
The lexical information represented in the
DATR theory above (1) would appear as fol-
lows when stated in feature structures:
</bodyText>
<equation confidence="0.744122">
- 138 -
(3)
</equation>
<bodyText confidence="0.9839875">
information specific to NO:
The question that arises is how to relate
DATR and PATR so that the hierarchically
structured lexical information in DATR can be
made available in PATR-usable feature struc-
tures.
</bodyText>
<subsectionHeader confidence="0.990671">
4.1 A DATR-PATR INTERFACE
</subsectionHeader>
<bodyText confidence="0.999961722222222">
The first idea that one might have is to
exploit the syntactic similarities between the
two formalisms and encode the lexical informa-
tion in a DATR description like (1). In this way
a DATR axiom like NOUN: &lt;syn major nv n&gt;
== yes would be directly equivalent to the path
equation &lt;NOUN .syn major nv n&gt; = yes in
PATR, where the node name in DATR corre-
sponds to the variable name for a feature struc-
ture in PATR. Although this looks reasonable,
one major problem arises: You must know
exactly the path you want to query, i.e. all its
attributes and their precise order. If such a
query is posed, the answer will be the atomic
value yielded by the DATR evaluation.
Such an approach requires an interface
with the following functions: Queries that the
grammar writer has stated explicitly have to be
passed on to DATR. Every query together with
the resulting value has to be transformed into
a PATR path equation (that partially describes
a feature structure) and passed on to the PATR
system. What is most disturbing about this
strategy is the fact that for every distinct PATR
path you have to know the corresponding
DATR query. It is tempting to think one could
simply check which paths are defmed for a
given node, but this doesn&apos;t work because of
inheritance: the entire network is potentially
relevant. So in effect all the PATR structures
except the atomic values have to be defined
twice: once in the DATR statements and once
in the queries. This redundancy cannot be elim-
inated unless types for the feature structure are
declared which are consulted in formulating the
queries.
</bodyText>
<subsectionHeader confidence="0.67258">
4.2 USING DATR OUTPUT DIRECTLY
</subsectionHeader>
<bodyText confidence="0.997264041666667">
A completely different approach is to
formulate a DATR theory which gives the
lexical information in a PATR-usable format
(i.e. a feature structure) as the result of the
evaluation of a DATR query. Thus, the DATR
description reflects the hierarchical structure of
the lexical information and consequently meets
one of the main requirements for an adequate
representation that cannot be met by a simple
PATR formalism. The resulting feature struc-
tures include all the information necessary for
PATR but neglect the inheritance structure,
although the latter is involved in their construc-
tion (i.e. the evaluation of queries). There are
various DATR-programming techniques that
realize these ideas. Three examples will N:
presented here which cover the lexical informkt-
don encoded in (1).
The first technique, which is illustrated
in (4)2, uses global inheritance (represented
with double quotation marks) to store the no
at which the query originates. This also allows
other information in the global node to frt
accessed.
</bodyText>
<figure confidence="0.973610142857143">
bar: zero
{n: yes
ran
v: no
syn: major:
information specific to ADJO:
bar: zero
syn: major: fly: in: yes
yes
- 139 -
(4)
SYNTAX: == ( [ syn [ &amp;quot;&lt;synpaths&gt;&amp;quot; 1]).
MAJOR: &lt;&gt;== SYNTAX
&lt;synpaths&gt; ==
( maj [&lt;majpaths&gt;&apos; ] ).
NV: c== MAJOR
&lt;majpaths&gt; ==
( nv [ n &amp;quot;&lt;n&gt;&amp;quot; , v &amp;quot;&lt;v&gt;&amp;quot; ]).
NOUN: &lt;&gt;== NV
&lt;n&gt; == yes
&lt;v&gt; == no.
ADJ: &lt;&gt;== NV
&lt;n&gt; == yes
&lt;v&gt; == yes.
BAR: &lt;&gt;== MAJOR
&lt;majpaths&gt; == ( bar &apos;:&apos; &amp;quot;&lt;bar&gt;&amp;quot; ).
BARO: &lt;&gt;== BAR
&lt;bar&gt; = zero.
</figure>
<bodyText confidence="0.999238738095238">
This DATR theory makes it possible to
get the feature structure associated with the
node NOUN, i.e. the evaluation of the DATR
query NOUN:&lt;&gt;.
To evaluate this DATR query the nodes
NV, MAJOR, and SYNTAX are visited. In the
node SYNTAX part of the corresponding feature
specification is constructed and the evaluable
path &lt;synpaths&gt; refers back to the original
node NOUN. Then the query NOUN:
&lt;synpaths&gt; is evaluated in the same way up to
the node MAJOR, where the next part of the
feature structure is built and the evaluable path
&lt;majpaths&gt; refers again to the global node
NOUN. At the end of the evaluation the feature
structure [synlmajInv: (n:yes,v:no] j]] emer-
ges.
Lexical entries defined with the DATR
network above have the form FROG: &lt;&gt; ==
(&amp;quot;NOUN&amp;quot; &amp;quot;BARD&amp;quot;), which means intuitively
that the lexeme frog is an nO. Given the net-
work in (4), the value of the query FROG:&lt;&gt;
will inherit the information of the global nodes
NOUN and BARO. Thus, the global environ-
ment is changed in the course of the evaluation.
As a declarative language, DATR is
independent of the procedural evaluation strate-
gies embodied in particular DATR-implementa-
tions. Nevertheless, DATR theories like (4)
may themselves reflect different evaluation
strategies (just as different search strategies
may be implemented in pure PROLOG, inde-
pendently of the particular PROLOG implemen-
tation).
The evaluation strategy in (4) can be
described as top-down depth-first and is rather
costly because of the cyclic returns to the glob-
al nodes. A more efficient strategy is illustrated
in (5). This DATR description embodies a
breadth-first search and uses variables (desig-
nated by the prefix $) instead of changing the
global environment.
</bodyText>
<figure confidence="0.992243">
(5)
SYNTAX: &lt;$NV $BAR&gt;
( [ syn [ MAJOR:&lt;$NV $BAR&gt; ] ] ).
MAJOR: &lt;$NV $BAR&gt;
( maj [ NV:&lt;$NV&gt; , BAR:&lt;$BAR&gt; ] ).
NV: &lt;$NV&gt;
( nv [ N:&lt;$NV&gt; , V:4NV&gt; ] ).
N: &lt;$NV&gt; == ( n N VAL:&lt;$NV&gt; ).
V: &lt;$NV&gt; == ( v V_VAL:&lt;$NV&gt; ).
N_VAL: &lt;noun&gt; == yes
&lt;adj&gt; = yes
&lt;&gt;== no.
V_VAL: &lt;verb&gt; = yes
&lt;adj&gt; = yes
== no.
BAR: &lt;$BAR&gt; =--
( bar &apos;:&apos; BAR_VAL:&lt;$BAR&gt; ).
BAR_VAL: &lt;barO&gt; == zero
&lt;barl&gt; == one
&lt;bar2&gt; == two.
</figure>
<bodyText confidence="0.992146606060606">
Here an appropriate query would be
SYNTAX: &lt;noun barO&gt;. At the origin of the
query the outer layer of the feature structure is
already constructed. The rest of the feature
structure results from evaluating MAJOR:&lt;$NV
$BAR&gt;, where $NV is instantiated with noun
and $BAR with bar() as in the original query.
We then obtain the feature structure
[syn:ftnapinv:[n:yes,v:nobbar:zerojjj as the
result of the evaluation. Unlike the network in
(4), it is not possible to ask for just a part of
this feature structure: Neither the information
about the N/V-scheme nor the information
about the bar level can be queried separately.
An entry for the lexeme frog given the
network (5) would have the fonn FROG:&lt;&gt;
== SYNTAX:&lt;noun barO&gt;, which of course
also means that the lexeme frog is an nO. But
this time the information is inherited from the
- 140 -
This third approach forms the base for
our current lexicon. Some of the related issues
are raised in the next section.
node SYNTAX, where the value provides the
frame for the resulting PATR feature structure.
Apart from the differing DATR tech-
niques employed, the resulting feature struc-
tures for a lexical entry also differ slightly.
While the first is nearer to a set of PATR paths
which has to be collapsed into a single feature
structure, the second has exactly the form re-
quired by the PATR system we use.
The third technique is illustrated in (6).
</bodyText>
<table confidence="0.805536947368421">
(6)
SYNTAX: &lt;&gt;== ( syn [ MAJOR ] ).
MAJOR: &lt;&gt; == ( maj [ NV , BAR ] ).
NV: &lt;&gt;==(nv&apos;:&apos;[N,V]).
BAR: == ( bar &apos;:&apos; &amp;quot;&lt;bar&gt;&amp;quot; ).
N: &lt;&gt;== ( n &apos;:&apos; &lt;value &amp;quot;&lt;cat&gt;&amp;quot;&gt; )
&lt;value nO&gt; == yes
&lt;value adjO&gt; = yes
&lt;value&gt; == no.
V: == ( v &apos;:&apos; &lt;value &amp;quot;&lt;cai&gt;&amp;quot;&gt; )
&lt;value vO&gt; == yes
&lt;value adjO&gt; = yes
&lt;value&gt; == no.
LEXICAL: &lt;&gt;== ( [ SYNTAX 1)
&lt;bar&gt; = zero.
NOUN: &lt;&gt;== LEXICAL
&lt;cat&gt; == no.
ADJ: &lt;&gt;== LEXICAL
&lt;cat&gt; == adj0.
</table>
<bodyText confidence="0.9850823">
An appropriate query for this DATR
theory would be NOUN :&lt;&gt;, the value of which
is (syn: [maj In:yes,v: no] ,bar:zeron . The
evaluation of this query is similar to the one in
(5) in that the value of SYNTAX:&lt;&gt; constitutes
the frame of the resulting PATR-usable feature
structure. Unlike (5), no variables are used;
instead, information from the global node is
used via global path inheritance to specify the
values. Notice that whereas with (4) the global
node is changed, it remains unchanged during
the evaluations with (6).
The advantages of (6) are obvious.
Since neither variables nor global nodes are
used, fewer DATR facilities are involved. Nev-
ertheless, the required PATR feature structures
can be defined. For example, the lexical entry
for frog would be FROG : &lt;&gt;==NOUN, where
the noun-specific information is inherited from
NOUN.
</bodyText>
<sectionHeader confidence="0.998879" genericHeader="method">
5 THE DATR LEXICON
</sectionHeader>
<bodyText confidence="0.983473272727273">
It has been shown above that DATR
theories can serve as a lexicon for a PATR
system where the lexemes are represented as
DATR nodes and the returned values of queries
are the corresponding feature structures. In a
lexicon which is formulated as in (6), apart
from the lexical nodes (i.e. nodes like FROG
which define lexemes) two other kinds of nodes
can be distinguished: nodes like SYNTAX or
NV, which correspond to PATR attributes, and
nodes like NOUN or LEXICAL, which represent
a kind of type information (see Pollard/Sag,
1987). The lexemes inherit this information
through reference to the type nodes, while the
lexeme-specific information is associated direct-
ly with the lexical nodes.
There are several differences between
these three kinds of nodes. Whereas it is appro-
priate to pose a query like FROG :&lt;&gt; or
NOUN x&gt;, such queries make no sense for
nodes like SYNTAX. In this respect lexemes and
types are related.
Another property distinguishes lexical
nodes from type nodes. The latter are hierarchi-
cally structured, while the former are unstruc-
tured in the sense that they refer to types but
not to other lexemes. The structuring of the
type nodes reflects the above mentioned regu-
larities as well as irregularities.
The following DATR theory is a lexi-
con fragment for a possible classification of
intransitive verbs in German. Regular verbs
(e.g. schlafen &apos;sleep&apos;) take a nominative subject
and inherit all type-specific information from
the node INTRANS_VERB. One exception am
verbs with expletive subject (e.g. re gnen &apos;rain&apos;),
another those with nonnominative (accusative
or dative) subject (e.g. darsten &apos;suffer from
thirst&apos; with accusative). These verbs refer to the
types nodes INTRANS_VERB EXPL and IN-
TRANS VERB ACC, respectively. The latter
types inherit from the node IIVTRANS_VERB
but override some of its information.
- 141 -
</bodyText>
<sectionHeader confidence="0.9136205" genericHeader="method">
6 CONCLUDING REMARKS
REFERENCES
</sectionHeader>
<reference confidence="0.929093125">
Daelemans, Walter / Gazdar, Gerald
(eds.) (1990) Proc. of the Workshop on Inheri-
tance in Natural Language Processing. ITK
Tilburg, The Netherlands.
Evans, Roger / Gazdar, Gerald (1989a)
Inference in DATR. In Proc. of the 4th Confer-
ence of the European Chapter of the Associa-
tion for Computational Linguistics, 66-71.
</reference>
<figure confidence="0.995937375">
(7) VERB
INTRANS_VERB: &lt;cat subject&gt; = n2
LN&apos;IRANS_VERB_EXPL: &lt;case subject&gt; =-- nominative
INTRANS_VERB_ACC: &lt;status subject&gt; =-- norm.
&lt;&gt;== INTRANS_VERB
&lt;status subject&gt; = expletive.
&lt;&gt;== INTRANS_VERB
&lt;case subject&gt; =-- accusative.
</figure>
<bodyText confidence="0.999977470588235">
We have seen that it is possible to
formulate the lexicon of a PATR system as a
DATR theory. That is, given a lexical entry in
DATR, a corresponding feature structure can be
derived. A system postulating new entries for
unknown words on the basis of contextual
information during parsing (Kilbury, 1990)
must be able to convert a given feature struc-
ture into a corresponding lexical entry in DATR
so that the new lexeme is located and integrated
in the lexical network. To solve this problem
the concept of type nodes can be exploited.
A fmal difficulty involves certain
PATR-specific devices like disjunctions and
reentrancies for which no obvious DATR facili-
ties are available. At present we still have only
ad hoc solutions to these problems.
</bodyText>
<sectionHeader confidence="0.991022" genericHeader="conclusions">
FOOTNOTES
</sectionHeader>
<reference confidence="0.983018625">
1. NOUN: o== LEXICAL
&lt;syn major nv n&gt; == yes.
abbreviates
NOUN: o== LEXICAL
NOUN: &lt;syn major nv n&gt; == yes.
2. The colons in single quotes, the commas, and the square
brackets are DATR atoms, not part of the language itselfin
contrast, the parentheses of DATR enclose a list value.
</reference>
<sectionHeader confidence="0.832608" genericHeader="acknowledgments">
ACKNOWLEDGEMENTS
</sectionHeader>
<reference confidence="0.964447129032258">
The research project SINLLEX is supported by
the DFG under grant number Ki 374/1. The
authors are indebted to the participants of the
Workshop on Inheritance, Tilburg 1990.
Evans, Roger, / Gazdar, Gerald (1989b)
The Semantics of DATR. In A. Cohn (ed.)
AISB89, Proc. of the 7th Conference of the
Society for the Study of Artificial Intelligence
and Simulation of Behaviour, 79-87. London:
Pitman.
Evans, Roger / Gazdar, Gerald (eds.)
(1990) The DATR Papers: February 1990 (=
Cognitive Science Research Paper 139). School
of Cognitive and Computing Sciences, Univer-
sity of Sussex, Brighton, England.
Gazdar, Gerald (1987) Linguistic appli-
cation of default inheritance mechanisms. In
Peter J. Whitelock et al. (eds.) Linguistic Theo-
ry and Computer Applications, 37-67. London:
Academic Press.
Kilbury, James (1990) Simulation of
Lexical Acquisition. In Proc. of ALLC-ACH 90:
The New Medium, 129-130. University of
Siegen, FRG.
Pollard, Carl / Sag, Ivan (1987) Infor-
mation-Based Syntax and Semantics, I: Funda-
mentals. Stanford, Calif.: CSLI.
Shieber, Stuart M. (1986) An Introduc-
tion to Unification-Based Approaches to Gram-
mar. Stanford, Calif.: CSLI.
- 142 -
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000275">
<title confidence="0.997915">DATR AS A LEXICAL COMPONENT FOR PATR</title>
<author confidence="0.990498">James Kilbury</author>
<author confidence="0.990498">Petra Naerger</author>
<author confidence="0.990498">Ingrid Renz</author>
<abstract confidence="0.992265879069768">Seminar fur Allgemeine Sprachwissenschaft Heinrich-Heine-Universitat DUsseldorf Universitatsstralle 1 D-4000 Dusseldorf 1 Federal Republic of Germany Lbitnet naerger@ddOrud8 Lbitnet renz@ddOrud8 Lbitnet ABSTRACT The representation of lexical entries requires special means which basic PATR systems do not include. The language DATR, however, can be used to define an inheritance network serving as the lexical component. The integration of such a module into an existing PATR system leads to various problems which are discussed together with possible solutions in this paper. 1 MOTIVATION In the project &amp;quot;Simulation of Lexical Acquisition&amp;quot; (SIMLEX) unification is used to create new lexical entries through the monotonic accumulation of contextual grammatical information during parsing. The system which we implemented for this purpose is a variant of PATR as described in (Shieber, 1986). Besides collecting the appropriate information for an unknown word, i.e. a lexeme not already specified in the given lexicon, the creation of its new lexical entry is a major goal. In this context questions about the nature of lexical information, the structuring, and the representation of this information must be answered. The present paper is mainly concerned with the structuring and representation of information in lexical entries. 2 REPRESENTATION OF LEXICAL INFORMATION We assume that certain conditions must be met by an adequate representation of lexical information. The most important of these is that it captures linguistic generalizations, which means that associated information is represented together or bundled. One advantage of this bundled information is its reusability, which allows redundancy to be reduced. The representation of lexical information should enable us to express a further kind of generalization, namely the relations between regularity, subregularity, and irregularity. Furthermore, the representation has to be computationally tractable and -possibly with the addition of &amp;quot;syntactic sugar&amp;quot; -more or less readable for human users. The formalism of PATR offers two possible means of representing lexical information. First of all, the information can be encoded in feature structures directly. Except for computational tractability, none of the other criteria are met. The second facility consists of macros or templates which assemble the linguistic information so that it can be reused in various places in the lexicon. This meets the most important of the above-mentioned conditions and reduces redundancy. But the encoded information is inherited monotonically, i.e. only regularities can be expressed. In order to structure lexical information adequately, other relations like subregularities and exceptions should also be expressible. Macros fail to achieve this, whereas default inheritance networks are well-suited for the purpose. In the following section we give an overview of one such network formalism which was primarily designed for representing lexical information. - 137 - 3 OVERVIEW OF DATR DATR (described in detail by Evans/ Gazdar, 1989a; 1989b; 1990) is a declarative language for the definition of semantic networks which allows for defaults as well as multiple inheritance. Its general properties are non-monotonicity, functionality, and deterministic search. DATR network descripis a set of expressions) which related to each other by references. Together they define a hierarchical structure, a net. Both regularities and exceptions can be expressed, regularities using default inheritance, and exceptions, overriding. axioms consist of with a right-hand side. This be a or list), or an DATR expression if the value is to be inherited from another node, path, or node-path pair. The following DATR theory comprising three definitions&apos; familiar linguistic information to illustrate some relevant DATR features: (1) LEXICAL: &lt;syn major bar&gt; = zero. NOUN: &lt;&gt;== LEXICAL &lt;syn major nv n&gt; == yes nv v&gt; == no. ADJ: &lt;&gt; == LEXICAL &lt;syn major nv n&gt; == NOUN &lt;syn major nv v&gt; == &lt;syn major nv n&gt;. The represented information can be retrieved with special DATR queries. These also consist of a node-path pair, whose evaluation returns the value sought. With the above DATR description the following examples show sensible DATR queries and their corresponding values: (2) NOUN:&lt;syn major nv n&gt;? yes (atomic value) NOUN:&lt;syn major nv v&gt;? no (atomic value) NOUN:&lt;syn major tar&gt; ? from node LEXICAL) ADJ:&lt;syn major nv n&gt;? yes (inherited from node NOUN) ADJ:&lt;syn major nv. v&gt;? yes (inherited from node NOUN via path &lt;syn major nv n&gt; in node ADJ) ADJ:&lt;syn major bar&gt; ? zero (inherited from node LEXICAL) Seven inference rules and a default mechanism are given for the evaluation of DATR queries. Their precise semantics and properties are described in (Evans/Gazdar, 1989b; 1990). A major feature of DATR is its distincbetween In the above example only local inheritance is involved, but global inheritance plays a crucial role in one of the later examples. Variables constitute an additional device available in DATR but are assumed to have the status of abbreviations. Despite their syntactic similarities, DATR and PATR differ completely in their semantics, so that there is no obvious way of relating the two formalisms to each other. Some approaches are discussed in the next section. 4 RELATING DATR AND PATR A PATR system needs to have the lexical information it uses encoded in feature structures consisting of attribute-value pairs. The lexical information represented in the DATR theory above (1) would appear as follows when stated in feature structures: - 138 - (3) information specific to NO: The question that arises is how to relate DATR and PATR so that the hierarchically structured lexical information in DATR can be made available in PATR-usable feature structures. 4.1 A DATR-PATR INTERFACE The first idea that one might have is to exploit the syntactic similarities between the two formalisms and encode the lexical information in a DATR description like (1). In this way DATR axiom like &lt;syn major nv n&gt; yes be directly equivalent to the path .syn major nv n&gt; = yes PATR, where the node name in DATR corresponds to the variable name for a feature structure in PATR. Although this looks reasonable, one major problem arises: You must know exactly the path you want to query, i.e. all its attributes and their precise order. If such a query is posed, the answer will be the atomic value yielded by the DATR evaluation. Such an approach requires an interface with the following functions: Queries that the grammar writer has stated explicitly have to be passed on to DATR. Every query together with the resulting value has to be transformed into a PATR path equation (that partially describes a feature structure) and passed on to the PATR system. What is most disturbing about this strategy is the fact that for every distinct PATR path you have to know the corresponding DATR query. It is tempting to think one could check which paths are defmed for given node, but this doesn&apos;t work because of inheritance: the entire network is potentially relevant. So in effect all the PATR structures except the atomic values have to be defined twice: once in the DATR statements and once in the queries. This redundancy cannot be eliminated unless types for the feature structure are declared which are consulted in formulating the queries. 4.2 USING DATR OUTPUT DIRECTLY A completely different approach is to formulate a DATR theory which gives the lexical information in a PATR-usable format (i.e. a feature structure) as the result of the evaluation of a DATR query. Thus, the DATR reflects the of the lexical information and consequently meets one of the main requirements for an adequate representation that cannot be met by a simple PATR formalism. The resulting feature structures include all the information necessary for but neglect the although the latter is involved in their construction (i.e. the evaluation of queries). There are various DATR-programming techniques that realize these ideas. Three examples will N: presented here which cover the lexical informktdon encoded in (1). The first technique, which is illustrated uses inheritance with double quotation marks) to store the no at which the query originates. This also allows other information in the global node to frt accessed. bar: zero {n: yes ran v: no information specific to ADJO: bar: zero in: yes yes - 139 - (4) SYNTAX: == ( [ syn [ &amp;quot;&lt;synpaths&gt;&amp;quot; 1]). MAJOR: &lt;&gt;== SYNTAX &lt;synpaths&gt; == ( maj [&lt;majpaths&gt;&apos; ] ). NV: c== MAJOR &lt;majpaths&gt; == ( nv [ n &amp;quot;&lt;n&gt;&amp;quot; , v &amp;quot;&lt;v&gt;&amp;quot; ]). NOUN: &lt;&gt;== NV &lt;n&gt; == yes &lt;v&gt; == no. ADJ: &lt;&gt;== NV &lt;n&gt; == yes &lt;v&gt; == yes. BAR: &lt;&gt;== MAJOR &lt;majpaths&gt; == ( bar &apos;:&apos; &amp;quot;&lt;bar&gt;&amp;quot; ). BARO: &lt;&gt;== BAR &lt;bar&gt; = zero. This DATR theory makes it possible to get the feature structure associated with the the evaluation of the DATR To evaluate this DATR query the nodes MAJOR, visited. In the of the corresponding feature specification is constructed and the evaluable back to the original the query evaluated in the same way up to node the next part of the feature structure is built and the evaluable path again to the global node the end of the evaluation the feature (n:yes,v:no] j]] emerges. Lexical entries defined with the DATR above have the form &lt;&gt; == &amp;quot;BARD&amp;quot;), means intuitively the lexeme is an nO. the netin (4), the value of the query will inherit the information of the global nodes the global environment is changed in the course of the evaluation. As a declarative language, DATR is independent of the procedural evaluation strategies embodied in particular DATR-implementations. Nevertheless, DATR theories like (4) may themselves reflect different evaluation strategies (just as different search strategies may be implemented in pure PROLOG, independently of the particular PROLOG implementation). The evaluation strategy in (4) can be as depth-first is rather costly because of the cyclic returns to the global nodes. A more efficient strategy is illustrated in (5). This DATR description embodies a and uses variables (designated by the prefix $) instead of changing the global environment. (5) SYNTAX: &lt;$NV $BAR&gt; ( [ syn [ MAJOR:&lt;$NV $BAR&gt; ] ] ). MAJOR: &lt;$NV $BAR&gt; ( maj [ NV:&lt;$NV&gt; , BAR:&lt;$BAR&gt; ] ). NV: &lt;$NV&gt; ( nv [ N:&lt;$NV&gt; , V:4NV&gt; ] ). N: &lt;$NV&gt; == ( n N VAL:&lt;$NV&gt; ). V: &lt;$NV&gt; == ( v V_VAL:&lt;$NV&gt; ). N_VAL: &lt;noun&gt; == yes &lt;adj&gt; = yes &lt;&gt;== no. V_VAL: &lt;verb&gt; = yes &lt;adj&gt; = yes == no. BAR: &lt;$BAR&gt; =-- ( bar &apos;:&apos; BAR_VAL:&lt;$BAR&gt; ). BAR_VAL: &lt;barO&gt; == zero &lt;barl&gt; == one &lt;bar2&gt; == two. Here an appropriate query would be &lt;noun barO&gt;. the origin of the query the outer layer of the feature structure is already constructed. The rest of the feature results from evaluating instantiated with as the original query. We then obtain the feature structure the result of the evaluation. Unlike the network in (4), it is not possible to ask for just a part of this feature structure: Neither the information about the N/V-scheme nor the information about the bar level can be queried separately. entry for the lexeme the (5) would have the fonn SYNTAX:&lt;noun barO&gt;, of course means that the lexeme is an nO. this time the information is inherited from the 140 This third approach forms the base for our current lexicon. Some of the related issues are raised in the next section. the value provides the frame for the resulting PATR feature structure. Apart from the differing DATR techniques employed, the resulting feature structures for a lexical entry also differ slightly. While the first is nearer to a set of PATR paths which has to be collapsed into a single feature structure, the second has exactly the form required by the PATR system we use. The third technique is illustrated in (6). (6) SYNTAX: &lt;&gt;== ( syn [ MAJOR ] ). MAJOR: &lt;&gt; == ( maj [ NV , BAR ] ). NV: &lt;&gt;==(nv&apos;:&apos;[N,V]). BAR: == ( bar &apos;:&apos; &amp;quot;&lt;bar&gt;&amp;quot; ). N: &lt;&gt;== ( n &apos;:&apos; &lt;value &amp;quot;&lt;cat&gt;&amp;quot;&gt; ) &lt;value nO&gt; == yes adjO&gt; = &lt;value&gt; == no. V: == ( v &apos;:&apos; &lt;value &amp;quot;&lt;cai&gt;&amp;quot;&gt; ) &lt;value vO&gt; == yes &lt;value adjO&gt; = yes &lt;value&gt; == no. LEXICAL: &lt;&gt;== ( [ SYNTAX 1) &lt;bar&gt; = zero. NOUN: &lt;&gt;== LEXICAL &lt;cat&gt; == no. ADJ: &lt;&gt;== LEXICAL &lt;cat&gt; == adj0. An appropriate query for this DATR would be :&lt;&gt;, value of which [maj In:yes,v: no] ,bar:zeron . The evaluation of this query is similar to the one in in that the value of the frame of the resulting PATR-usable feature structure. Unlike (5), no variables are used; instead, information from the global node is via global to specify the values. Notice that whereas with (4) the global node is changed, it remains unchanged during the evaluations with (6). The advantages of (6) are obvious. Since neither variables nor global nodes are used, fewer DATR facilities are involved. Nevertheless, the required PATR feature structures can be defined. For example, the lexical entry be : &lt;&gt;==NOUN, the noun-specific information is inherited from NOUN. 5 THE DATR LEXICON It has been shown above that DATR theories can serve as a lexicon for a PATR system where the lexemes are represented as DATR nodes and the returned values of queries are the corresponding feature structures. In a lexicon which is formulated as in (6), apart the lexical nodes (i.e. nodes like which define lexemes) two other kinds of nodes be distinguished: nodes like correspond to PATR attributes, and like represent a kind of type information (see Pollard/Sag, 1987). The lexemes inherit this information through reference to the type nodes, while the lexeme-specific information is associated directly with the lexical nodes. There are several differences between these three kinds of nodes. Whereas it is approto pose a query like :&lt;&gt; x&gt;, queries make no sense for like this respect lexemes and types are related. Another property distinguishes lexical nodes from type nodes. The latter are hierarchically structured, while the former are unstructured in the sense that they refer to types but not to other lexemes. The structuring of the type nodes reflects the above mentioned regularities as well as irregularities. The following DATR theory is a lexicon fragment for a possible classification of intransitive verbs in German. Regular verbs take a nominative subject and inherit all type-specific information from node exception am with expletive subject (e.g. gnen &apos;rain&apos;), another those with nonnominative (accusative dative) subject (e.g. from thirst&apos; with accusative). These verbs refer to the nodes EXPL IN- VERB ACC, The latter inherit from the node but override some of its information.</abstract>
<note confidence="0.45419125">141 - 6 CONCLUDING REMARKS REFERENCES Daelemans, Walter / Gazdar, Gerald (1990) of the Workshop on Inheriin Natural Language Processing. Tilburg, The Netherlands. Evans, Roger / Gazdar, Gerald (1989a)</note>
<abstract confidence="0.92473293939394">in DATR. In of the 4th Conference of the European Chapter of the Associafor Computational Linguistics, (7) VERB INTRANS_VERB: &lt;cat subject&gt; = n2 LN&apos;IRANS_VERB_EXPL: INTRANS_VERB_ACC: &lt;case subject&gt; =-nominative &lt;status subject&gt; =-norm. &lt;&gt;== INTRANS_VERB &lt;status subject&gt; = expletive. &lt;&gt;== INTRANS_VERB &lt;case subject&gt; =-accusative. We have seen that it is possible to formulate the lexicon of a PATR system as a DATR theory. That is, given a lexical entry in DATR, a corresponding feature structure can be derived. A system postulating new entries for unknown words on the basis of contextual information during parsing (Kilbury, 1990) must be able to convert a given feature structure into a corresponding lexical entry in DATR so that the new lexeme is located and integrated in the lexical network. To solve this problem the concept of type nodes can be exploited. A fmal difficulty involves certain PATR-specific devices like disjunctions and reentrancies for which no obvious DATR facilities are available. At present we still have only hoc to these problems. FOOTNOTES 1. NOUN: o== LEXICAL &lt;syn major nv n&gt; == yes. abbreviates NOUN: o== LEXICAL NOUN: &lt;syn major nv n&gt; == yes. 2. The colons in single quotes, the commas, and the square brackets are DATR atoms, not part of the language itselfin the parentheses of DATR enclose a ACKNOWLEDGEMENTS</abstract>
<note confidence="0.937882153846154">The research project SINLLEX is supported by the DFG under grant number Ki 374/1. The authors are indebted to the participants of the Workshop on Inheritance, Tilburg 1990. Evans, Roger, / Gazdar, Gerald (1989b) The Semantics of DATR. In A. Cohn (ed.) AISB89, Proc. of the 7th Conference of the Society for the Study of Artificial Intelligence Simulation of Behaviour, London: Pitman. Evans, Roger / Gazdar, Gerald (eds.) DATR Papers: February 1990 (= Science Research Paper School</note>
<affiliation confidence="0.9186965">of Cognitive and Computing Sciences, University of Sussex, Brighton, England.</affiliation>
<address confidence="0.861381">Gazdar, Gerald (1987) Linguistic appli-</address>
<title confidence="0.567664">cation of default inheritance mechanisms. In</title>
<author confidence="0.780666">J Whitelock</author>
<affiliation confidence="0.8723795">and Computer Applications, London: Academic Press.</affiliation>
<address confidence="0.648129">Kilbury, James (1990) Simulation of</address>
<note confidence="0.9471425">Acquisition. In of ALLC-ACH 90: New Medium, University of Siegen, FRG. Carl / Sag, Ivan (1987) Infor- Syntax and Semantics, Funda- Calif.: CSLI. Stuart M. (1986) Introduction to Unification-Based Approaches to Gram- Calif.: CSLI. - 142 -</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<date>1990</date>
<booktitle>Proc. of the Workshop on Inheritance in Natural Language Processing. ITK</booktitle>
<editor>Daelemans, Walter / Gazdar, Gerald (eds.)</editor>
<location>Tilburg, The Netherlands.</location>
<marker>1990</marker>
<rawString>Daelemans, Walter / Gazdar, Gerald (eds.) (1990) Proc. of the Workshop on Inheritance in Natural Language Processing. ITK Tilburg, The Netherlands.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Roger Gazdar Evans</author>
</authors>
<title>Gerald (1989a) Inference in DATR.</title>
<booktitle>In Proc. of the 4th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>66--71</pages>
<marker>Evans, </marker>
<rawString>Evans, Roger / Gazdar, Gerald (1989a) Inference in DATR. In Proc. of the 4th Conference of the European Chapter of the Association for Computational Linguistics, 66-71.</rawString>
</citation>
<citation valid="false">
<authors>
<author>NOUN</author>
</authors>
<title>o== LEXICAL major nv n&gt; == yes. abbreviates</title>
<marker>NOUN, </marker>
<rawString>1. NOUN: o== LEXICAL &lt;syn major nv n&gt; == yes. abbreviates</rawString>
</citation>
<citation valid="true">
<authors>
<author>NOUN o LEXICAL NOUN</author>
</authors>
<title>major nv n&gt; == yes. 2. The colons in single quotes, the commas, and the square brackets are DATR atoms, not part of the language itselfin contrast, the parentheses of DATR enclose a list value. The research project SINLLEX is supported by the DFG under grant number Ki 374/1. The authors are indebted to the participants of the Workshop on Inheritance,</title>
<date>1990</date>
<location>Tilburg</location>
<marker>NOUN, 1990</marker>
<rawString>NOUN: o== LEXICAL NOUN: &lt;syn major nv n&gt; == yes. 2. The colons in single quotes, the commas, and the square brackets are DATR atoms, not part of the language itselfin contrast, the parentheses of DATR enclose a list value. The research project SINLLEX is supported by the DFG under grant number Ki 374/1. The authors are indebted to the participants of the Workshop on Inheritance, Tilburg 1990.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Roger Evans</author>
<author>Gazdar</author>
</authors>
<title>Gerald (1989b) The Semantics of DATR.</title>
<booktitle>AISB89, Proc. of the 7th Conference of the Society for the Study of Artificial Intelligence and Simulation of Behaviour,</booktitle>
<pages>79--87</pages>
<editor>In A. Cohn (ed.)</editor>
<publisher>Pitman.</publisher>
<location>London:</location>
<marker>Evans, Gazdar, </marker>
<rawString>Evans, Roger, / Gazdar, Gerald (1989b) The Semantics of DATR. In A. Cohn (ed.) AISB89, Proc. of the 7th Conference of the Society for the Study of Artificial Intelligence and Simulation of Behaviour, 79-87. London: Pitman.</rawString>
</citation>
<citation valid="true">
<date>1990</date>
<booktitle>The DATR Papers: February 1990 (= Cognitive Science Research Paper 139). School of Cognitive and Computing Sciences, University of Sussex,</booktitle>
<editor>Evans, Roger / Gazdar, Gerald (eds.)</editor>
<location>Brighton, England.</location>
<marker>1990</marker>
<rawString>Evans, Roger / Gazdar, Gerald (eds.) (1990) The DATR Papers: February 1990 (= Cognitive Science Research Paper 139). School of Cognitive and Computing Sciences, University of Sussex, Brighton, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerald Gazdar</author>
</authors>
<title>Linguistic application of default inheritance mechanisms.</title>
<date>1987</date>
<booktitle>Linguistic Theory and Computer Applications,</booktitle>
<pages>37--67</pages>
<editor>In Peter J. Whitelock et al. (eds.)</editor>
<publisher>Academic Press.</publisher>
<location>London:</location>
<marker>Gazdar, 1987</marker>
<rawString>Gazdar, Gerald (1987) Linguistic application of default inheritance mechanisms. In Peter J. Whitelock et al. (eds.) Linguistic Theory and Computer Applications, 37-67. London: Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Kilbury</author>
</authors>
<title>Simulation of Lexical Acquisition.</title>
<date>1990</date>
<booktitle>In Proc. of ALLC-ACH 90: The New Medium,</booktitle>
<pages>129--130</pages>
<institution>University of Siegen, FRG.</institution>
<marker>Kilbury, 1990</marker>
<rawString>Kilbury, James (1990) Simulation of Lexical Acquisition. In Proc. of ALLC-ACH 90: The New Medium, 129-130. University of Siegen, FRG.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Sag Pollard</author>
<author>Ivan</author>
</authors>
<title>Information-Based Syntax and Semantics, I: Fundamentals.</title>
<date>1987</date>
<publisher>CSLI.</publisher>
<location>Stanford, Calif.:</location>
<marker>Pollard, Ivan, 1987</marker>
<rawString>Pollard, Carl / Sag, Ivan (1987) Information-Based Syntax and Semantics, I: Fundamentals. Stanford, Calif.: CSLI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
</authors>
<title>An Introduction to Unification-Based Approaches to Grammar.</title>
<date>1986</date>
<publisher>CSLI.</publisher>
<location>Stanford, Calif.:</location>
<contexts>
<context position="993" citStr="Shieber, 1986" startWordPosition="139" endWordPosition="140">ch basic PATR systems do not include. The language DATR, however, can be used to define an inheritance network serving as the lexical component. The integration of such a module into an existing PATR system leads to various problems which are discussed together with possible solutions in this paper. 1 MOTIVATION In the project &amp;quot;Simulation of Lexical Acquisition&amp;quot; (SIMLEX) unification is used to create new lexical entries through the monotonic accumulation of contextual grammatical information during parsing. The system which we implemented for this purpose is a variant of PATR as described in (Shieber, 1986). Besides collecting the appropriate information for an unknown word, i.e. a lexeme not already specified in the given lexicon, the creation of its new lexical entry is a major goal. In this context questions about the nature of lexical information, the structuring, and the representation of this information must be answered. The present paper is mainly concerned with the structuring and representation of information in lexical entries. 2 REPRESENTATION OF LEXICAL INFORMATION We assume that certain conditions must be met by an adequate representation of lexical information. The most important </context>
</contexts>
<marker>Shieber, 1986</marker>
<rawString>Shieber, Stuart M. (1986) An Introduction to Unification-Based Approaches to Grammar. Stanford, Calif.: CSLI.</rawString>
</citation>
<citation valid="false">
<pages>142</pages>
<marker></marker>
<rawString>- 142 -</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>