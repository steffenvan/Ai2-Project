<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.984221">
Efficient extraction of grammatical relations
</title>
<author confidence="0.997509">
Rebecca Watson, John Carroll and Ted Briscoe
</author>
<affiliation confidence="0.855591333333333">
Computer Laboratory, University of Cambridge, Cambridge, CB3 OFD, UK
firstname.lastname@cl.cam.ac.uk
Department of Informatics, University of Sussex, Brighton BN1 9QH, UK
</affiliation>
<email confidence="0.990095">
J.A.Carroll@sussex.ac.uk
</email>
<sectionHeader confidence="0.982729" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999982875">
We present a novel approach for applying
the Inside-Outside Algorithm to a packed
parse forest produced by a unification-
based parser. The approach allows a node
in the forest to be assigned multiple inside
and outside probabilities, enabling a set of
‘weighted GRs’ to be computed directly
from the forest. The approach improves
on previous work which either loses effi-
ciency by unpacking the parse forest be-
fore extracting weighted GRs, or places
extra constraints on which nodes can be
packed, leading to less compact forests.
Our experiments demonstrate substantial
increases in parser accuracy and through-
put for weighted GR output.
</bodyText>
<sectionHeader confidence="0.995132" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999789725490196">
RASP is a robust statistical analysis system for
English developed by Briscoe and Carroll (2002).
It contains a syntactic parser which can output
analyses in a number of formats, including (n-
best) syntactic trees, robust minimal recursion se-
mantics (Copestake, 2003), grammatical relations
(GRs), and weighted GRs. The weighted GRs for
a sentence comprise the set of grammatical relations
in all parses licensed for that sentence, each GR is
weighted based on the probabilities of the parses
in which it occurs. This weight is normalised to
fall within the range 0,1 where indicates that
all parses contain the GR. Therefore, high precision
GR sets can be determined by thresholding on the
GR weight (Carroll and Briscoe, 2002). Carroll and
Briscoe compute weighted GRs by first unpacking
all parses or the n-best subset from the parse forest.
Hence, this approach is either (a) inefficient (and for
some examples impracticable) if a large number of
parses are licensed by the grammar, or (b) inaccu-
rate if the number of parses unpacked is less than
the number licensed by the grammar.
In this paper, we show how to obviate the need
to trade off efficiency and accuracy by extracting
weighted GRs directly from the parse forest us-
ing a dynamic programming approach based on the
Inside-Outside algorithm (IOA) (Baker, 1979; Lari
and Young, 1990). This approach enables efficient
calculation of weighted GRs over all parses and sub-
stantially improves the throughput and memory us-
age of the parser. Since the parser is unification-
based, we also modify the parsing algorithm so that
local ambiguity packing is based on feature structure
equivalence rather than subsumption.
Similar dynamic programming techniques that
are variants of the IOA have been applied for re-
lated tasks, such as parse selection (Johnson, 2001;
Schmid and Rooth, 2001; Geman and Johnson,
2002; Miyao and Tsujii, 2002; Kaplan et al., 2004;
Taskar et al., 2004). The approach we take is similar
to Schmid and Rooth’s (2001) adaptation of the al-
gorithm, where ‘expected governors’ (similar to our
‘GR specifications’) are determined for each tree,
and alternative nodes in the parse forest have the
same lexical head. Initially, they create a packed
parse forest and during a second pass the parse forest
nodes are split if multiple lexical heads occur. The
IOA is applied over this split data structure. Simi-
larly, Clark and Curran (2004) alter their packing al-
gorithm so that nodes in the packed chart have the
same semantic head and ‘unfilled’ GRs. Our ap-
</bodyText>
<page confidence="0.332472">
160
</page>
<note confidence="0.873615">
Proceedings of the Ninth International Workshop on Parsing Technologies (IWPT), pages 160–170,
Vancouver, October 2005. c�2005 Association for Computational Linguistics
</note>
<bodyText confidence="0.999880206896552">
proach is novel in that while calculating inside prob-
abilities we allow any node in the parse forest to
have multiple semantic heads.
Clark and Curran (2004) apply Miyao and Tsu-
jii’s (2002) dynamic programming approach to de-
termine weighted GRs. They outline an alterna-
tive parse selection method based on the resulting
weighted GRs: select the (consistent) GR set with
the highest average weighted GR score. We apply
this parse selection approach and achieve 3.01% rel-
ative reduction in error. Further, the GR set output
by this approach is a consistent set whereas the high
precision GR sets outlined in (Carroll and Briscoe,
2002) are neither consistent nor coherent.
The remainder of this paper is organised as fol-
lows: Section 2 gives details of the RASP sys-
tem that are relevant to this work. Section 3 de-
scribes our test suite and experimental environment.
Changes required to the current parse forest cre-
ation algorithm are discussed in Section 4, while
Section 5 outlines our dynamic programming ap-
proach for extracting weighted GRs (EWG). Sec-
tion 6 presents experimental results showing (a) im-
proved efficiency achieved by EWG, (b) increased
upper bounds of precision and recall achieved us-
ing EWG, and (c) increased accuracy achieved by
a parse selection algorithm that would otherwise be
too inefficient to consider. Finally, Section 7 out-
lines our conclusions and future lines of research.
</bodyText>
<sectionHeader confidence="0.970177" genericHeader="method">
2 The RASP System
</sectionHeader>
<bodyText confidence="0.999664222222222">
RASP is based on a pipelined modular architec-
ture in which text is pre-processed by a series of
components including sentence boundary detection,
tokenisation, part of speech tagging, named entity
recognition and morphological analysis, before be-
ing passed to a statistical parser1. A brief overview
of relevant aspects of syntactic processing in RASP
is given below; for full details of system compo-
nents, see Briscoe and Carroll (1995; 2002; 2005)2.
</bodyText>
<footnote confidence="0.4932746">
1Processing times given in this paper do not include these
pre-processing stages, since they take negligible time compared
with parsing.
2RASP is freely available for research use; visit
http://www.informatics.susx.ac.uk/research/nlp/rasp/
</footnote>
<subsectionHeader confidence="0.995797">
2.1 The Grammar
</subsectionHeader>
<bodyText confidence="0.999969444444444">
Briscoe and Carroll (2005) describe the (manually-
written) feature-based unification grammar and the
rule-to-rule mapping from local trees to GRs. The
mapping specifies for each grammar rule the seman-
tic head(s) of the rule (henceforth, head), and one or
more GRs that should be output (optionally depend-
ing on feature values instantiated at parse time). For
example, Figure 1 shows a grammar rule analysing a
verb phrase followed by a prepositional phrase mod-
ifier. The rule identifies the first daughter (1) as the
semantic head, and specifies that one of five possi-
ble GRs is to be output, depending on the value of
the PSUBCAT syntactic feature; so, for example, if the
feature has the value NP, then the relation is ncmod
(non-clausal modifier), with slots filled by the se-
mantic heads of the first and second daughters (the 1
and 2 arguments).
Before parsing, a context free backbone is derived
automatically from the grammar, and an LALR(1)
parse table is computed from this backbone (Carroll,
1993, describes the procedure in detail). Probabili-
ties are associated with actions in the parse table,
by training on around 4K sentences from the Su-
sanne corpus (Sampson, 1995), each sentence hav-
ing been semi-automatically converted from a tree-
bank bracketing to a tree conforming to the unifica-
tion grammar (Briscoe and Carroll, 1995).
</bodyText>
<subsectionHeader confidence="0.998636">
2.2 The Parse Forest
</subsectionHeader>
<bodyText confidence="0.99997105882353">
When parsing, the LALR table action probabilities
are used to assign a score to each newly derived
(sub-)analysis. Additionally, on each reduce ac-
tion (i.e. complete application of a rule), the rule’s
daughters are unified with the sequence of sub-
analyses being consumed. If unification fails then
the reduce action is aborted. Local ambiguity pack-
ing (packing, henceforth) is performed on the ba-
sis of feature structure subsumption. Thus, the
parser builds and returns a compact structure that ef-
ficiently represents all parses licensed by the gram-
mar: the parse forest. Since unification often fails
it is not possible to apply beam or best first search
strategies during construction of the parse forest;
statistically high scoring paths often end up in unifi-
cation failure. Hence, the parse forest represents all
parses licensed by the grammar.
</bodyText>
<equation confidence="0.991159272727273">
161
V1/vp : V1[MOD +] --&gt; H1 P2[ADJ -, WH -] :
_pp
1 :
2 = [PSUBCAT NP], (ncmod1 2) :
_
2 = [PSUBCAT NONE], (ncmod prt 1 2) :
2 = [PSUBCAT (VP, VPINF, VPING, VPPRT, AP)], (xmod 1 2) :
_
2 = [PSUBCAT (SFIN, SINF, SING)], (cmod _ 1 2) :
2 = [PSUBCAT PP], (pmod 1 2).
</equation>
<figureCaption confidence="0.871531">
Figure 1: Example grammar rule, showing the rule name and syntactic specification (on the first line),
</figureCaption>
<bodyText confidence="0.950761892857143">
identification of daughter 1 as the semantic head (second line), and possible GR outputs depending on the
parse-time value of the PSUBCAT feature of daughter 2 (subsequent lines).
Figure 2 shows a simplified parse forest contain-
ing three parses generated for the following pre-
processed text3:
in II the AT park NN1
The GR specifications shown are instantiated based
on the values of syntactic features at daughter nodes,
as discussed in Section 2.1 above. For example, the
V1/vp pp sub-analysis (towards the left hand side of
the Figure) contains the instantiated GR specifica-
tion 1, (ncmod 1 2) since its second daughter has
the value NP for its PSUBCAT feature.
Henceforth, we will use the term ‘node’ to refer to
data structures in our parse forest corresponding to a
rule instantiation: a sub-analysis resulting from ap-
plication of a reduce action. Back pointers are stored
in nodes, indicating which daughters were used to
create the sub-analysis. These pointers provide a
means to traverse the parse forest during subsequent
processing stages. A ‘packed node’ is a node rep-
resenting a sub-analysis that is subsumed by, and
hence packed into, another node. Packing is consid-
ered for nodes only if they are produced in the same
LR state and represent sub-analyses with the same
word span. A parse forest can have a number of root
nodes, each one dominating analyses spanning the
whole sentence with the specified top category.
</bodyText>
<subsectionHeader confidence="0.998397">
2.3 Parser Output
</subsectionHeader>
<bodyText confidence="0.999585">
From the parse forest, RASP unpacks the ‘n-best’4
syntactic trees using a depth-first beam search (Car-
roll, 1993). There are a number of types of analysis
</bodyText>
<footnote confidence="0.9216112">
3The part of speech tagger uses a subset of the Lancaster
CLAWS2 tagset – http://www.comp.lancs.ac.uk/computing/research/
ucrel/claws2tags.html
4This number is specified by the user, and represents the
maximal number of parses to be unpacked.
</footnote>
<bodyText confidence="0.998748918918919">
output available, including syntactic tree, grammati-
cal relations (GRs) and robust minimal recursion se-
mantics (RMRS). Each of these is computed from
the n-best trees.
Another output possibility is weighted GRs (Car-
roll and Briscoe, 2002); this is the unique set of GRs
from the n-best GRs, each GR weighted according
to the sum of the probabilities of the parses in which
it occurs. Therefore, a number of processing stages
determine this output: unpacking the n-best syntac-
tic trees, determining the corresponding n-best GR
sets and finding the unique set of GRs and corre-
sponding weights.
The GRs for each parse are computed from the
set of GR specifications at each node, passing the
(semantic) head of each sub-analysis up to the next
higher level in the parse tree (beginning from word
nodes). GR specifications for nodes (which, if re-
quired, have been instantiated based on the features
of daughter nodes) are referred to as ‘unfilled’ un-
til the slots containing numbers are ‘filled’ with the
corresponding heads of daughter nodes. For exam-
ple, the grammar rule named NP/det n has the un-
filled GR specification 2, (det 2 1) . Therefore, if
an NP/det n local tree has two daughters with heads
the and cat respectively, the resulting filled GR spec-
ification will be cat, (det cat the) , i.e. the head of
the local tree is cat and the GR output is (det cat the).
Figure 3 illustrates the n-best GRs and the
corresponding (non-normalised and normalised)
weighted GRs for the sentence I saw the man in
the park. The corresponding parse forest for this
example is shown in Figure 2. Weights on the
GRs are normalised probabilities representing the
weighted proportion of parses in which the GR
occurs. This weighting is in practice calculated
as the sum of parse probabilities for parses con-
</bodyText>
<figure confidence="0.9947814625">
I PPIS1 see+ed VVD the AT man NN1
162
_
s
o
T�n^� h
no p
p
c
ana
e
nr u t
-
163
P1/p_np
-3.5908418
&lt;1&gt;
PP/p1
-3.7718313
y
&lt;2,(det 2 1)&gt; &lt;1,(ncmod _ 1 2)&gt; &lt;1&gt;
-0.026328932 -4.0527596
T/txt-sc1/- S/np_vp
*packed*
r G l
V1/v_np
&lt;2,(ncsubj 2 1)&gt;
ca
V1/vp_pp
-2.788875 -1.5990183
&lt;1,(ncmod _ 1 2)&gt; &lt;1,(dobj 1 2)&gt;
*packed*
hi hd dca
-
/
-
1
-0.47560894
Vl/v np pp
rd71
-3.195716
&lt;1,(iobj 1 3)&gt;
H
o
I PPIS1
_
od re wi
91.
4 7 .
ti
V1/v np
h t
�
PP/p1
-4.6176632e-4 -0.006716030
NP/det_n N
-0.39 1 1 1 29 - 1
-3.5908418
&lt;2,(d et 2 1)&gt;
&lt;1&gt;
PP/p1
see+ed_VVD the_AT
-3.8319092
&lt;1,(dobj 1 2)&gt;
P1/p_np
&lt;
-3.2382972
&lt;1,(dobj 1 2)&gt;
NP/det n N1/n1_pp1
ns,
m
&lt;1,(dobj 1 2)&gt;
in_II
P1/p_np
&lt;1,(dobj 1 2)&gt;
the35 .
-3.8319092 -0.0064182742
-3.5908418
-2.7551124
-3.8319092
</figure>
<bodyText confidence="0.988616285714286">
taining the specific GR, normalised by the sum
of all parse probabilities. For example, the GR
(iobj see+ed in) is in one parse with probability
, the non-normalised score. The sum of
all parse probabilities is . Therefore,
the normalised probability (and final weight) of the
GR is 5.
</bodyText>
<sectionHeader confidence="0.972992" genericHeader="method">
3 Data and Methods
</sectionHeader>
<bodyText confidence="0.999661588235294">
King et al. (2003) outline the development of the
PARC 700 Dependency Bank (henceforth, Dep-
Bank), a gold-standard set of relational dependen-
cies for 700 sentences (originally from the Wall
Street Journal) drawn at random from Section 23 of
the Penn Treebank. Briscoe and Carroll (2005) ex-
tended DepBank with a set of gold-standard RASP
GRs that we use to measure parser accuracy.
We use the same 560 sentence subset from the
DepBank utilised by Kaplan et al. (2004) in their
study of parser accuracy and efficiency. All exper-
imental results are obtained using this test suite on
an AMD Opteron 2.5GHz CPU with 1GB of Ram
on a 64 bit version of Linux. The parser’s output is
evaluated using a relational dependency evaluation
scheme (Carroll et al., 1998; Lin, 1998) and stan-
dard evaluation measures: precision, recall and F .
</bodyText>
<sectionHeader confidence="0.983806" genericHeader="method">
4 Local Ambiguity Packing
</sectionHeader>
<bodyText confidence="0.988636303030303">
Oepen and Carroll (2000) note that when using
subsumption-based packing with a unification-based
grammar, the parse forest may implicitly represent
some parses that are not actually licensed by the
grammar; these will have values for one or more
features that are locally but not globally consistent.
This is not a problem when computing GRs from
trees that have already been unpacked, since the rel-
evant unifications will have been checked during the
unpacking process, and will have caused the affected
trees to be filtered out. Unification fails for at least
one packed tree in approximately 10% of the sen-
tences in the test suite. However, such inconsistent
5As we are dealing with log probabilities, summation and
subtraction of these probabilities is not straightforward. Mul-
tiplication of probabilities X and Y, with log probabilities x
and y respectively is determined using the formula
, division using , summation using
and subtraction using
.
trees are a problem for any approach to probabil-
ity computation over the parse forest that is based
on the Inside-Outside algorithm (IOA). For our ef-
ficient weighted GR extraction technique we there-
fore modify the parsing algorithm so that packing is
based on feature structure equality rather than sub-
sumption.
Oepen and Carroll give definitions and implemen-
tation details for subsumption and equality opera-
tions, which we adopt. In the experiments below,
we refer to versions of the parser with subsumption
and equality based packing as SUB-PACKING and
EQ-PACKING respectively.
</bodyText>
<sectionHeader confidence="0.92344" genericHeader="method">
5 Extracting Weighted GRs
</sectionHeader>
<bodyText confidence="0.999944444444444">
Parse forest unpacking consumes larger amounts of
CPU time and memory as the number of parses
to unpack (n-best) increases. Carroll and Briscoe
(2002) demonstrate that increasing the size of the n-
best list increases the upper bound on precision (i.e.
when low-weighted GRs are filtered out). Therefore,
if practicable, it is preferable to include all possible
parses when calculating weighted GRs. We describe
below a dynamic programming approach (EWG)
based on the IOA to efficiently extract weighted
GRs directly from the parse forest. EWG calcu-
lates weighted GRs over all parses represented in the
parse forest.
Inside and outside probabilities are analogous to
the forward and backward probabilities of markov
model algorithms. The inside probability repre-
sents the probability of all possible sub-analyses of a
node. Conversely, the outside probability represents
the probability of all analyses for which the node is
a sub-analysis.
The IOA is ideal for our task, as the product of
inside and outside probabilities for a sub-analysis
constitutes part of the sum for the non-normalised
weight of each GR (arising from the GR specifi-
cation in the sub-analysis). Further, we can apply
the sum of inside probabilities for each root-node, to
normalise the weighted GRs.
</bodyText>
<subsectionHeader confidence="0.952996">
5.1 Implementation
</subsectionHeader>
<bodyText confidence="0.982958">
Three processing stages are required to determine
weighted GRs over the parse forest, calculating
(1) filled GRs and corresponding inside probabili-
</bodyText>
<page confidence="0.516484">
164
</page>
<table confidence="0.936131621621622">
N−BEST GRS (NON NORMALISED) WEIGHTED GRS
parse (log) probability:−28.056154
(ncsubj see+ed I j(iobj see+ed in)
(dobj see+ed man)
(dobj in park)
(det park the)
(det man the)
parse (log) probability:−29.11871
(ncsubj see+ed I j(ncmod _ see+ed in)
(dobj in park)
(det park the)
(dobj see+ed man)
(det man the)
parse (log) probability:−35.159805
(ncsubj see+ed I j(dobj see+ed man)
(det man the)
(ncmod _ man in)
(dobj in park)
(det park the)
−28.0201 (ncsubj see+ed_VVD I_PPIS1 _)
−35.1598 (ncmod _ man_NN1 in_II)
−28.0201 (det park_NN1 the_AT)
−29.1187 (ncmod _ see+ed_VVD in_II)
−28.0562 (iobj see+ed_VVD in_II)
−28.0201 (dobj see+ed_VVD man_NN1)
−28.0201 (dobj in_II park_NN1)
−28.0201 (det man_NN1 the_AT)
(NORMALISED) WEIGHTED GRS
1.0 (det park the)
1.0 (det man the)
1.0 (dobj see+ed man)
1.0 (dobj in park)
0.920314 (iobj see+ed in)
7.249102e−8 (ncmod _ man in)
7.968584e−2 (ncmod _ see+ed in)
1.0 (ncsubj see+ed I j
Total Probability (log−sum of all parses): −28.0200896
</table>
<figureCaption confidence="0.989757">
Figure 3: The n-best GRs, and non-normalised/normalised weighted GRs determined from three parses for
</figureCaption>
<bodyText confidence="0.566576333333333">
the sentence I saw the man in the park. Parse probabilities and non-normalised weights are shown as log
probabilities. Weights and parse probabilities are shown with differing precision, however RASP stores all
probabilities in log (base 10) form with double float precision.
</bodyText>
<page confidence="0.840661">
165
</page>
<bodyText confidence="0.99988625">
ties, (2) outside (and non-normalised) probabilities
of weighted GRs, and (3) normalised probabilities
of weighted GRs.6 The first two processing stages
are covered in detail in the following sections, while
the final stage simply entails normalising the prob-
abilities by dividing each weight by the sum of all
the parse probabilities (the sum of root-nodes’ in-
side probabilities).
</bodyText>
<subsubsectionHeader confidence="0.653443">
5.1.1 Inside probability and GR
</subsubsectionHeader>
<bodyText confidence="0.957439909090909">
To determine inside probabilities over the nodes in
the parse forest, we need to propagate the head and
corresponding inside probability upwards after fill-
ing the node’s GR specification. The inside proba-
bility of node is usually calculated over the parse
forest by multiplying the inside probability of the
node’s daughters and the probability of the
node itself (i.e. the probability of the shift or reduce
action that caused the node to be created). There-
fore, if a node has daughters and , then the
inside probability is calculated using:
</bodyText>
<equation confidence="0.922514">
(1)
</equation>
<bodyText confidence="0.975249538461539">
However, packed nodes each correspond to an al-
ternative filled GR specification. Inside probabilities
for these GR specifications need to be combined. If
packed analyses occur in node then the inside
probability of node is:
(2)
Further, the alternative GR specifications may not
necessarily specify the same head as the node’s GR
specification and multiple heads may be passed up
by the node. Hence, the summation in equation 2
needs to be conditioned on the possible heads of a
node , where is the inside probability
of each head for node :
</bodyText>
<equation confidence="0.635297">
(3)
</equation>
<bodyText confidence="0.97081296">
When multiple heads are passed up by daughter
nodes, multiple filled GR specifications are found for
the node. We create one filled GR specification for
6Note that the IOA is not applied iteratively; a single pass
only is required.
each possible combination of daughters’ heads7. For
example, consider the case where a node has daugh-
ters and with semantic heads dog, cat and
an respectively. Here, we need to fill the GR spec-
ification 2, (det 2 1) with two sets of daughters’
heads: dog, (det dog an) and cat, (det cat an) .
As a node can have multiple filled GR specifica-
tions , we alter equation 3 to:
(4)
Here, (the inside probability of filled GR spec-
ification ) is determined by multiplying the inside
probabilities of daughters’ heads (that filled the GR
specification) and the reduce probability of the node
itself, i.e. using a modification of equation 1. Re-
turning to the previous example, the inside proba-
bilities of dog, (det dog an) and cat, (det cat an)
will be equal to the reduce probability of the node
multiplied by (a) the inside probability of head an,
and (b) the inside probabilities of the heads dog and
cat, respectively.
Hence, (a) calculation of inside probabilities takes
into account multiple semantic heads, and (b) GR
specifications are filled using every possible com-
bination of daughters’ heads. Each node is pro-
cessed in full as follows:
Process each of the node’s packed nodes to
determine the packed node’s list of filled GR
specifications and corresponding inside proba-
bilities.
Process the node , with daughters :
– Instantiate ’s GR specifications based on
features of .
– Process each daughter in to determine
a list of possible semantic heads and cor-
responding inside probabilities for each.
– Fill the GR specification of with each
possible combination of daughters’ heads.
7The same word can appear as a head for more than one
daughter of a node. This occurs if competing analyses have
daughters with different word spans and, therefore, particular
words can be considered in the span of either daughter. As the
grammar permits both pre- and post- modifiers, it is possible
for words in the ‘overlapping’ span to be passed up as heads for
both daughters. Therefore, semantic heads are not combined
unless they are different words.
</bodyText>
<page confidence="0.857208">
166
</page>
<bodyText confidence="0.984282">
Calculate the inside probability of each
filled GR specification.
Combine the alternative filled GR specifica-
tions of and , determining the list of unique
semantic heads and corresponding inside prob-
abilities using equation 4.
For each node, we propagate up a set of data struc-
tures that each contain one possible head and
corresponding inside probability. At word nodes, we
simply return the word and the reduce score of the
word as the semantic head and inside probability, re-
spectively. Back pointers are also included to store
the list of alternative filled GR specifications and
corresponding inside probabilities, the reduce score
for the node and the daughters’ data structures (used
to fill the GR specifications).
</bodyText>
<subsubsectionHeader confidence="0.708385">
5.1.2 Outside probability determination
</subsubsectionHeader>
<bodyText confidence="0.9628981875">
After the inside probabilities have been computed
(bottom-up) the resulting data structure at the root-
node is traversed to compute outside probabilities.
The data structure created is split into alternative se-
mantic heads for each node and, therefore, traversal
to determine outside probabilities is relatively triv-
ial: the outside probability of a filled GR specifica-
tion is equal to the outside probability of the corre-
sponding unique head of the node. Therefore, once
we have created the new data structure, outside prob-
abilities for each node can be determined over this
structure in the regular fashion.
We calculate the outside probabilities (top-down)
and, when we find filled GR specifications, we in-
crementally store the non-normalised weight of each
GR. Each data structure for head , with outside
probability , is processed in full as follows:
– Let and calculate the probability
.
– Add to the (non-normalised) probabil-
ity for (in a hash table).
– Process the data structure for each child
head in , . That is, the daughters’
heads that filled the GR specification (re-
sulting in ). For each
Calculate the outside probability of
(using the reduce probability of the
node , stored in the data structure
):
(5)
Queue the data structure and corre-
sponding outside probability .8
</bodyText>
<sectionHeader confidence="0.994801" genericHeader="method">
6 Experimentation
</sectionHeader>
<subsectionHeader confidence="0.999379">
6.1 Efficiency and Accuracy
</subsectionHeader>
<bodyText confidence="0.99872827027027">
The dynamic programming algorithm outlined in
Section 5, EWG, provides an efficient and accurate
method of determining weighted GRs directly from
the parse forest. Figures 5 and 6 compare the ef-
ficiency of EWG to the EQ-PACKING and SUB-
PACKING methods in terms of CPU time and mem-
ory, respectively9. Note that EWG applies equality-
based packing to ensure only parses licensed by the
grammar are considered (see Section 4).
As the maximum number of (n-best) parses in-
creases, EQ-PACKING requires more time and
memory than SUB-PACKING. However, if we com-
pare these systems with an n-best value of 1, the dif-
ference in time and memory is negligible, suggest-
ing that it is the unpacking stage which is responsi-
ble for the decreased throughput. For EWG we are
forced to use equality-based packing, but these re-
sults suggest that using equality is not hurting the
throughput of EWG.
Both figures illustrate that the time and memory
required by EWG are static because the algorithm
considers all parses represented in the parse forest
regardless of the value of n-best specified. There-
fore, the ‘cross-over points’ are of particular inter-
est: at which n-best value is EWG’s efficiency the
same as that of the current system? This value is
8We apply a breadth first search (FIFO queue) to minimise
multiple processing of shared data structures. If an outside
probability is determined for a data structure already queued,
then the probability is appended to the queued item. The steps
are modified to enable multiple outside probabilities, i.e. sum-
mation over each outside probability when calculating and
.
9CPU time and memory usage are as reported using the
time function in Allegro Common Lisp 7.0 and do not include
system start-up overheads or the time required for garbage col-
lection.
</bodyText>
<equation confidence="0.5186645">
Process each of the GR specifications .
For each :
of ,
:
</equation>
<page confidence="0.428592">
167
</page>
<bodyText confidence="0.994360875">
approximately 580 and 100 for time and memory,
respectively (comparing EWG to EQ-PACKING).
Given that there are on average around 9000 parses
per sentence in the test suite, these results indicate
a substantial improvement in both efficiency and ac-
curacy for weighted GR calculation. However, the
median number of parses per sentence is around 50,
suggesting that large parse numbers for a small sub-
set of the test suite are skewing the arithmetic mean.
Therefore, the complexity of this subset will signif-
icantly decrease throughput and EWG will improve
efficiency for these sentences more so than for oth-
ers.
The general relationship between sentence length
and number of parses suggests that the EWG will
be more beneficial for longer sentences. Figure 4
shows the distribution of number of parses over sen-
tence length. The figure illustrates that the number
of parses can not be reliably predicted from sentence
length. Considering the cross-over points for time
and memory, the number of sentences with more
than 580 and 100 parses were 216 and 276, respec-
tively. Thus, the EWG out-performs the current al-
gorithm for around half of the sentences in the data
set. The relative gain achieved reflects that a sub-
set of sentences can significantly decrease through-
put. Hence, the EWG is expected to improve the
efficiency if a) longer sentences are present in the
data set and b) n-best is set to a value greater than
the cross-over point(s).
Upper bounds on precision and recall can be de-
termined using weight thresholds over the GRs of
1.0 and 0.0, respectivelylo. Upper bounds of pre-
cision and recall provided by EWG are 79.57 and
82.02, respectively, giving an F upper bound of
81.22%. However, considering the top 100 parses
only, we achieve upper bounds on precision and re-
call of 78.77% and 81.18% respectively, resulting
in an F upper bound of 79.96%. Therefore, using
EWG, we are able to achieve a relative increase of
6.29% for the F upper bound on the task. Similarly,
Carroll and Briscoe (2002) demonstrate (on an ear-
lier, different test suite) that increasing the number
of parses (n-best) from 100 to 1000 increases preci-
sion of weighted GR sets from 89.59% to 90.24%,
10In fact, in these experiments we use a threshold of
(with ) instead of a threshold of to reduce the
influence of very low ranked parses.
</bodyText>
<figure confidence="0.882774">
0 10 20 30 40 50 60 70
Sentence Length
</figure>
<figureCaption confidence="0.804924">
Figure 4: Scatter graph of number of parses to sen-
tence length (one point per sentence). The cross-
over points are illustrated for time and memory. The
maximum number of parses shown is 1000, points
plotted at 1000 correspond to equal to or greater than
1000 parses.
</figureCaption>
<figure confidence="0.9604165">
0 100 200 300 400 500 600 700 800 900 1000
Maximum number of parses (n−best)
</figure>
<figureCaption confidence="0.720383333333333">
Figure 5: Comparison of total CPU time required
by the different versions of the parsing system for
calculation of weighted GRs over the n-best parses.
</figureCaption>
<figure confidence="0.999604105263158">
Memory Cross−Over
Time Cross−Over
Time (sec)
2500
2000
1500
1000
500
0
SUB−PACKING
EQ−PACKING
EWG
Number of Parses &gt; 1000
750
500
250
168
0 100 200 300 400 500 600 700 800 900 1000
Maximum number of parses (n−best)
</figure>
<figureCaption confidence="0.997674">
Figure 6: Comparison of total memory required by
</figureCaption>
<bodyText confidence="0.937915625">
the different versions of the system for calculation
of weighted GRs over the n-best parses.
a relative error reduction (RER) of 6.8%. There-
fore, EWG achieves a substantial improvement in
both efficiency and accuracy for weighted GR cal-
culation; providing increased precision for thresh-
olded GR sets and an increased F upper bound on
the task.
</bodyText>
<subsectionHeader confidence="0.998486">
6.2 Parse Selection
</subsectionHeader>
<bodyText confidence="0.999988911764706">
Section 6.1 illustrated the increased level of effi-
ciency achieved by EWG compared to the current
system’s method for calculating weighted GRs. This
section briefly considers a parse selection algorithm
using EWG that would otherwise be too inefficient
to apply.
Clark and Curran (2004) determine weighted GRs
directly from a packed chart using Miyao and Tsu-
jii’s (2002) dynamic programming algorithm. They
outline a parse selection algorithm which maximises
the expected recall of dependencies by selecting the
n-best GR set with the highest average GR score
based on the weights from the weighted GRs. We
can apply this parse selection algorithm in two ways:
either (a) re-rank the n-best GR sets based on the av-
erage weight of GRs and select the highest ranking
set, or (b) apply a simple variant of the Viterbi algo-
rithm to select the GR set with the highest average
weighted score over the data structure built during
EWG. The latter approach, based on the parse selec-
tion algorithm in Clark and Curran (2004), takes into
account all possible parses and effectively re-ranks
all parses using weights output by EWG. These ap-
proaches will be referred to as RE-RANK (over the
top 1000 parses) and BEST-AVG, respectively.
The GR set corresponding to the system’s top
parse achieves an F of 71.24%. By applying BEST-
AVG and RE-RANK parse selection, we achieve a
relative error reduction of 3.01% and 0.90%, respec-
tively. Therefore, BEST-AVG achieves higher accu-
racy and is more efficient than RE-RANK. It is also
worth noting that these parse selection schemes are
able to output a consistent set of GRs unlike the set
corresponding to high precision GR output.
</bodyText>
<sectionHeader confidence="0.998729" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.9989007">
We have described a dynamic programming ap-
proach based on the Inside Outside Algorithm for
producing weighted grammatical relation output di-
rectly from a unification-based parse forest. In an
evaluation on a standard test suite the approach
achieves substantial improvements in accuracy and
parser throughput over a previous implementation.
The approach is novel as it allows multiple heads
(and inside probabilities) per parse forest node in-
stead of manipulating the parse forest so that each
node represents only a single head.
We intend to extend this work to develop more
sophisticated parse selection schemes based on
weighted GR output. Re-ranking the n-best GR sets
results in a consistent but not necessarily a coher-
ent set of GRs. Given the increased upper bound on
precision for the high precision GR output, we hope
to boost the corresponding recall measure by deter-
mining a consistent and coherent set of GRs from the
weighted GR set.
</bodyText>
<sectionHeader confidence="0.990328" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999769714285714">
This work is in part funded by the Overseas Re-
search Students Awards Scheme and the Poynton
Scholarship appointed by the Cambridge Australia
Trust in collaboration with the Cambridge Common-
wealth Trust. We would like to thank four anony-
mous reviewers who provided many useful sugges-
tions for improvement.
</bodyText>
<figure confidence="0.970807466666667">
40
20
90
70
60
50
30
80
10
0
SUB−PACKING
EQ−PACKING
EWG
Memory (GB)
169
</figure>
<sectionHeader confidence="0.935616" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999817674157303">
J. K. Baker. 1979. Trainable grammars for speech recog-
nition. In D. Klatt and J. Wolf, editors, Speech Com-
munications Papers for the 97th Meeting of the Acous-
tical Society ofAmerica, pages 557–550.
Ted Briscoe and John Carroll. 1995. Developing
and evaluating a probabilistic LR parser of part-of-
speech and punctuation labels. In Proceedings of the
ACL/SIGPARSE 4th International Workshop on Pars-
ing Technologies, pages 48–58, Prague / Karlovy Vary,
Czech Republic.
Ted Briscoe and John Carroll. 2002. Robust accurate
statistical annotation of general text. In Proceedings
of the Conference on Language Resources and Evalu-
ation (LREC2002), pages 1499–1504, Palmas, Canary
Islands, May.
Ted Briscoe and John Carroll. 2005. Evaluating
the speed and accuracy of an unlexicalized statistical
parser on the PARC Depbank. Under review.
John Carroll and Ted Briscoe. 2002. High precision ex-
traction of grammatical relations. In Proceedings of
the 19th International Conference on Computational
Linguistics, Taipei, Taiwan.
John Carroll, Ted Briscoe, and Antonio Sanfilippo. 1998.
Parser evaluation: a survey and a new proposal. In
Proceedings of the 1st International Conference on
Language Resources and Evaluation, pages 447–454,
Granada.
John Carroll. 1993. Practical unification-based parsing
of natural language. Ph.D. thesis, Computer Labora-
tory, University of Cambridge. Technical Report No.
314.
Stephen Clark and James Curran. 2004. Parsing the
WSJ using CCG and log-linear models. In Pro-
ceedings of the 42nd Annual Meeting of the Associ-
ation for Computational Linguistics, pages 104–111,
Barcelona, Spain.
Ann Copestake. 2003. Report on the design of RMRS.
DeepThought Project Deliverable D1.1a, University of
Cambridge, UK.
Stuart Geman and Mark Johnson. 2002. Dynamic
programming for parsing and estimation of stochas-
tic unification-based grammars. In Proceedings of the
40th Annual Meeting of the Association for Computa-
tional Linguistics (ACL), Philadelphia, PA.
Mark Johnson. 2001. Joint and conditional estimation
of tagging and parsing models. In Proceedings of the
39th Annual Meeting of the Association for Computa-
tional Linguistics (ACL), Toulouse, France, July.
Ronald Kaplan, Stephen Riezler, Tracy King, John
Maxwell, Alexander Vasserman, and Richard Crouch.
2004. Speed and accuracy in shallow and deep
stochastic parsing. In Proceedings of the Human
Language Technology conference / North American
chapter of the Association for Computational Lin-
guistics annual meeting, pages 97–113, Boston, Mas-
sachusetts, May.
Tracy King, Richard Crouch, Stephen Riezler, Mary Dal-
rymple, and Ronald Kaplan. 2003. The PARC700
Dependency Bank. In Proceedings of the 4th Interna-
tional Workshop on Linguistically Interpreted Corpora
(LINC-03).
Karim Lari and Steve Young. 1990. The estimation
of stochastic context-free grammars using the Inside-
Outside algorithm. Computer Speech and Language,
2(4):35–56.
Dekang Lin. 1998. Dependency-based evaluation of
MINIPAR. In Proceedings of the Workshop on The
Evaluation of Parsing Systems at the 1st International
Conference on Language Resources and Evaluation,
Granada, Spain.
Yusuke Miyao and Jun’ichi Tsujii. 2002. Maximum en-
tropy estimation for feature forests. In Proceedings
of the Human Language Technology Conference, San
Diego, California, March.
Stephan Oepen and John Carroll. 2000. Ambiguity pack-
ing in constraint-based parsing - practical results. In
Proceedings of the North American Chapter of the
Association for Computational Linguistics (NAACL),
pages 162–169, Seattle, WA.
Geoffrey Sampson. 1995. English for the Computer.
Oxford University Press.
Helmut Schmid and Mats Rooth. 2001. Parse forest
computation of expected governors. In Proceedings of
the 39th Annual Meeting of the Association for Com-
putational Linguistics, pages 458–465.
Ben Taskar, Dan Klein, Michael Collins, Daphne Koller,
and Christopher Manning. 2004. Max-margin pars-
ing. In Proceedings of the Conference on Empirical
Methods in Natural Language Processing.
</reference>
<page confidence="0.885091">
170
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.784790">
<title confidence="0.999468">Efficient extraction of grammatical relations</title>
<author confidence="0.999927">Rebecca Watson</author>
<author confidence="0.999927">John Carroll</author>
<author confidence="0.999927">Ted Briscoe</author>
<affiliation confidence="0.992867">Computer Laboratory, University of Cambridge, Cambridge, CB3 OFD,</affiliation>
<email confidence="0.998698">firstname.lastname@cl.cam.ac.uk</email>
<affiliation confidence="0.947424">Department of Informatics, University of Sussex, Brighton BN1 9QH,</affiliation>
<email confidence="0.996471">J.A.Carroll@sussex.ac.uk</email>
<abstract confidence="0.990018529411765">We present a novel approach for applying the Inside-Outside Algorithm to a packed parse forest produced by a unificationbased parser. The approach allows a node in the forest to be assigned multiple inside and outside probabilities, enabling a set of ‘weighted GRs’ to be computed directly from the forest. The approach improves on previous work which either loses efficiency by unpacking the parse forest before extracting weighted GRs, or places extra constraints on which nodes can be packed, leading to less compact forests. Our experiments demonstrate substantial increases in parser accuracy and throughput for weighted GR output.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J K Baker</author>
</authors>
<title>Trainable grammars for speech recognition.</title>
<date>1979</date>
<booktitle>Speech Communications Papers for the 97th Meeting of the Acoustical Society ofAmerica,</booktitle>
<pages>557--550</pages>
<editor>In D. Klatt and J. Wolf, editors,</editor>
<contexts>
<context position="2269" citStr="Baker, 1979" startWordPosition="352" endWordPosition="353">nd Briscoe, 2002). Carroll and Briscoe compute weighted GRs by first unpacking all parses or the n-best subset from the parse forest. Hence, this approach is either (a) inefficient (and for some examples impracticable) if a large number of parses are licensed by the grammar, or (b) inaccurate if the number of parses unpacked is less than the number licensed by the grammar. In this paper, we show how to obviate the need to trade off efficiency and accuracy by extracting weighted GRs directly from the parse forest using a dynamic programming approach based on the Inside-Outside algorithm (IOA) (Baker, 1979; Lari and Young, 1990). This approach enables efficient calculation of weighted GRs over all parses and substantially improves the throughput and memory usage of the parser. Since the parser is unificationbased, we also modify the parsing algorithm so that local ambiguity packing is based on feature structure equivalence rather than subsumption. Similar dynamic programming techniques that are variants of the IOA have been applied for related tasks, such as parse selection (Johnson, 2001; Schmid and Rooth, 2001; Geman and Johnson, 2002; Miyao and Tsujii, 2002; Kaplan et al., 2004; Taskar et al</context>
</contexts>
<marker>Baker, 1979</marker>
<rawString>J. K. Baker. 1979. Trainable grammars for speech recognition. In D. Klatt and J. Wolf, editors, Speech Communications Papers for the 97th Meeting of the Acoustical Society ofAmerica, pages 557–550.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
</authors>
<title>Developing and evaluating a probabilistic LR parser of part-ofspeech and punctuation labels.</title>
<date>1995</date>
<booktitle>In Proceedings of the ACL/SIGPARSE 4th International Workshop on Parsing Technologies,</booktitle>
<pages>48--58</pages>
<location>Prague / Karlovy Vary, Czech Republic.</location>
<contexts>
<context position="5503" citStr="Briscoe and Carroll (1995" startWordPosition="871" endWordPosition="874">acy achieved by a parse selection algorithm that would otherwise be too inefficient to consider. Finally, Section 7 outlines our conclusions and future lines of research. 2 The RASP System RASP is based on a pipelined modular architecture in which text is pre-processed by a series of components including sentence boundary detection, tokenisation, part of speech tagging, named entity recognition and morphological analysis, before being passed to a statistical parser1. A brief overview of relevant aspects of syntactic processing in RASP is given below; for full details of system components, see Briscoe and Carroll (1995; 2002; 2005)2. 1Processing times given in this paper do not include these pre-processing stages, since they take negligible time compared with parsing. 2RASP is freely available for research use; visit http://www.informatics.susx.ac.uk/research/nlp/rasp/ 2.1 The Grammar Briscoe and Carroll (2005) describe the (manuallywritten) feature-based unification grammar and the rule-to-rule mapping from local trees to GRs. The mapping specifies for each grammar rule the semantic head(s) of the rule (henceforth, head), and one or more GRs that should be output (optionally depending on feature values ins</context>
<context position="7112" citStr="Briscoe and Carroll, 1995" startWordPosition="1125" endWordPosition="1128">ation is ncmod (non-clausal modifier), with slots filled by the semantic heads of the first and second daughters (the 1 and 2 arguments). Before parsing, a context free backbone is derived automatically from the grammar, and an LALR(1) parse table is computed from this backbone (Carroll, 1993, describes the procedure in detail). Probabilities are associated with actions in the parse table, by training on around 4K sentences from the Susanne corpus (Sampson, 1995), each sentence having been semi-automatically converted from a treebank bracketing to a tree conforming to the unification grammar (Briscoe and Carroll, 1995). 2.2 The Parse Forest When parsing, the LALR table action probabilities are used to assign a score to each newly derived (sub-)analysis. Additionally, on each reduce action (i.e. complete application of a rule), the rule’s daughters are unified with the sequence of subanalyses being consumed. If unification fails then the reduce action is aborted. Local ambiguity packing (packing, henceforth) is performed on the basis of feature structure subsumption. Thus, the parser builds and returns a compact structure that efficiently represents all parses licensed by the grammar: the parse forest. Since</context>
</contexts>
<marker>Briscoe, Carroll, 1995</marker>
<rawString>Ted Briscoe and John Carroll. 1995. Developing and evaluating a probabilistic LR parser of part-ofspeech and punctuation labels. In Proceedings of the ACL/SIGPARSE 4th International Workshop on Parsing Technologies, pages 48–58, Prague / Karlovy Vary, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
</authors>
<title>Robust accurate statistical annotation of general text.</title>
<date>2002</date>
<booktitle>In Proceedings of the Conference on Language Resources and Evaluation (LREC2002),</booktitle>
<pages>1499--1504</pages>
<location>Palmas, Canary Islands,</location>
<contexts>
<context position="1044" citStr="Briscoe and Carroll (2002)" startWordPosition="148" endWordPosition="151">sed parser. The approach allows a node in the forest to be assigned multiple inside and outside probabilities, enabling a set of ‘weighted GRs’ to be computed directly from the forest. The approach improves on previous work which either loses efficiency by unpacking the parse forest before extracting weighted GRs, or places extra constraints on which nodes can be packed, leading to less compact forests. Our experiments demonstrate substantial increases in parser accuracy and throughput for weighted GR output. 1 Introduction RASP is a robust statistical analysis system for English developed by Briscoe and Carroll (2002). It contains a syntactic parser which can output analyses in a number of formats, including (nbest) syntactic trees, robust minimal recursion semantics (Copestake, 2003), grammatical relations (GRs), and weighted GRs. The weighted GRs for a sentence comprise the set of grammatical relations in all parses licensed for that sentence, each GR is weighted based on the probabilities of the parses in which it occurs. This weight is normalised to fall within the range 0,1 where indicates that all parses contain the GR. Therefore, high precision GR sets can be determined by thresholding on the GR wei</context>
</contexts>
<marker>Briscoe, Carroll, 2002</marker>
<rawString>Ted Briscoe and John Carroll. 2002. Robust accurate statistical annotation of general text. In Proceedings of the Conference on Language Resources and Evaluation (LREC2002), pages 1499–1504, Palmas, Canary Islands, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
</authors>
<title>Evaluating the speed and accuracy of an unlexicalized statistical parser on the PARC Depbank. Under review.</title>
<date>2005</date>
<contexts>
<context position="5801" citStr="Briscoe and Carroll (2005)" startWordPosition="909" endWordPosition="912">ncluding sentence boundary detection, tokenisation, part of speech tagging, named entity recognition and morphological analysis, before being passed to a statistical parser1. A brief overview of relevant aspects of syntactic processing in RASP is given below; for full details of system components, see Briscoe and Carroll (1995; 2002; 2005)2. 1Processing times given in this paper do not include these pre-processing stages, since they take negligible time compared with parsing. 2RASP is freely available for research use; visit http://www.informatics.susx.ac.uk/research/nlp/rasp/ 2.1 The Grammar Briscoe and Carroll (2005) describe the (manuallywritten) feature-based unification grammar and the rule-to-rule mapping from local trees to GRs. The mapping specifies for each grammar rule the semantic head(s) of the rule (henceforth, head), and one or more GRs that should be output (optionally depending on feature values instantiated at parse time). For example, Figure 1 shows a grammar rule analysing a verb phrase followed by a prepositional phrase modifier. The rule identifies the first daughter (1) as the semantic head, and specifies that one of five possible GRs is to be output, depending on the value of the PSUB</context>
<context position="13333" citStr="Briscoe and Carroll (2005)" startWordPosition="2195" endWordPosition="2198">42 -3.5908418 -2.7551124 -3.8319092 taining the specific GR, normalised by the sum of all parse probabilities. For example, the GR (iobj see+ed in) is in one parse with probability , the non-normalised score. The sum of all parse probabilities is . Therefore, the normalised probability (and final weight) of the GR is 5. 3 Data and Methods King et al. (2003) outline the development of the PARC 700 Dependency Bank (henceforth, DepBank), a gold-standard set of relational dependencies for 700 sentences (originally from the Wall Street Journal) drawn at random from Section 23 of the Penn Treebank. Briscoe and Carroll (2005) extended DepBank with a set of gold-standard RASP GRs that we use to measure parser accuracy. We use the same 560 sentence subset from the DepBank utilised by Kaplan et al. (2004) in their study of parser accuracy and efficiency. All experimental results are obtained using this test suite on an AMD Opteron 2.5GHz CPU with 1GB of Ram on a 64 bit version of Linux. The parser’s output is evaluated using a relational dependency evaluation scheme (Carroll et al., 1998; Lin, 1998) and standard evaluation measures: precision, recall and F . 4 Local Ambiguity Packing Oepen and Carroll (2000) note tha</context>
</contexts>
<marker>Briscoe, Carroll, 2005</marker>
<rawString>Ted Briscoe and John Carroll. 2005. Evaluating the speed and accuracy of an unlexicalized statistical parser on the PARC Depbank. Under review.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
<author>Ted Briscoe</author>
</authors>
<title>High precision extraction of grammatical relations.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Computational Linguistics,</booktitle>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="1675" citStr="Carroll and Briscoe, 2002" startWordPosition="250" endWordPosition="253">contains a syntactic parser which can output analyses in a number of formats, including (nbest) syntactic trees, robust minimal recursion semantics (Copestake, 2003), grammatical relations (GRs), and weighted GRs. The weighted GRs for a sentence comprise the set of grammatical relations in all parses licensed for that sentence, each GR is weighted based on the probabilities of the parses in which it occurs. This weight is normalised to fall within the range 0,1 where indicates that all parses contain the GR. Therefore, high precision GR sets can be determined by thresholding on the GR weight (Carroll and Briscoe, 2002). Carroll and Briscoe compute weighted GRs by first unpacking all parses or the n-best subset from the parse forest. Hence, this approach is either (a) inefficient (and for some examples impracticable) if a large number of parses are licensed by the grammar, or (b) inaccurate if the number of parses unpacked is less than the number licensed by the grammar. In this paper, we show how to obviate the need to trade off efficiency and accuracy by extracting weighted GRs directly from the parse forest using a dynamic programming approach based on the Inside-Outside algorithm (IOA) (Baker, 1979; Lari</context>
<context position="4279" citStr="Carroll and Briscoe, 2002" startWordPosition="674" endWordPosition="677">is novel in that while calculating inside probabilities we allow any node in the parse forest to have multiple semantic heads. Clark and Curran (2004) apply Miyao and Tsujii’s (2002) dynamic programming approach to determine weighted GRs. They outline an alternative parse selection method based on the resulting weighted GRs: select the (consistent) GR set with the highest average weighted GR score. We apply this parse selection approach and achieve 3.01% relative reduction in error. Further, the GR set output by this approach is a consistent set whereas the high precision GR sets outlined in (Carroll and Briscoe, 2002) are neither consistent nor coherent. The remainder of this paper is organised as follows: Section 2 gives details of the RASP system that are relevant to this work. Section 3 describes our test suite and experimental environment. Changes required to the current parse forest creation algorithm are discussed in Section 4, while Section 5 outlines our dynamic programming approach for extracting weighted GRs (EWG). Section 6 presents experimental results showing (a) improved efficiency achieved by EWG, (b) increased upper bounds of precision and recall achieved using EWG, and (c) increased accura</context>
<context position="10437" citStr="Carroll and Briscoe, 2002" startWordPosition="1677" endWordPosition="1681">arse forest, RASP unpacks the ‘n-best’4 syntactic trees using a depth-first beam search (Carroll, 1993). There are a number of types of analysis 3The part of speech tagger uses a subset of the Lancaster CLAWS2 tagset – http://www.comp.lancs.ac.uk/computing/research/ ucrel/claws2tags.html 4This number is specified by the user, and represents the maximal number of parses to be unpacked. output available, including syntactic tree, grammatical relations (GRs) and robust minimal recursion semantics (RMRS). Each of these is computed from the n-best trees. Another output possibility is weighted GRs (Carroll and Briscoe, 2002); this is the unique set of GRs from the n-best GRs, each GR weighted according to the sum of the probabilities of the parses in which it occurs. Therefore, a number of processing stages determine this output: unpacking the n-best syntactic trees, determining the corresponding n-best GR sets and finding the unique set of GRs and corresponding weights. The GRs for each parse are computed from the set of GR specifications at each node, passing the (semantic) head of each sub-analysis up to the next higher level in the parse tree (beginning from word nodes). GR specifications for nodes (which, if</context>
<context position="15610" citStr="Carroll and Briscoe (2002)" startWordPosition="2565" endWordPosition="2568">m (IOA). For our efficient weighted GR extraction technique we therefore modify the parsing algorithm so that packing is based on feature structure equality rather than subsumption. Oepen and Carroll give definitions and implementation details for subsumption and equality operations, which we adopt. In the experiments below, we refer to versions of the parser with subsumption and equality based packing as SUB-PACKING and EQ-PACKING respectively. 5 Extracting Weighted GRs Parse forest unpacking consumes larger amounts of CPU time and memory as the number of parses to unpack (n-best) increases. Carroll and Briscoe (2002) demonstrate that increasing the size of the nbest list increases the upper bound on precision (i.e. when low-weighted GRs are filtered out). Therefore, if practicable, it is preferable to include all possible parses when calculating weighted GRs. We describe below a dynamic programming approach (EWG) based on the IOA to efficiently extract weighted GRs directly from the parse forest. EWG calculates weighted GRs over all parses represented in the parse forest. Inside and outside probabilities are analogous to the forward and backward probabilities of markov model algorithms. The inside probabi</context>
<context position="27988" citStr="Carroll and Briscoe (2002)" startWordPosition="4594" endWordPosition="4597">n-best is set to a value greater than the cross-over point(s). Upper bounds on precision and recall can be determined using weight thresholds over the GRs of 1.0 and 0.0, respectivelylo. Upper bounds of precision and recall provided by EWG are 79.57 and 82.02, respectively, giving an F upper bound of 81.22%. However, considering the top 100 parses only, we achieve upper bounds on precision and recall of 78.77% and 81.18% respectively, resulting in an F upper bound of 79.96%. Therefore, using EWG, we are able to achieve a relative increase of 6.29% for the F upper bound on the task. Similarly, Carroll and Briscoe (2002) demonstrate (on an earlier, different test suite) that increasing the number of parses (n-best) from 100 to 1000 increases precision of weighted GR sets from 89.59% to 90.24%, 10In fact, in these experiments we use a threshold of (with ) instead of a threshold of to reduce the influence of very low ranked parses. 0 10 20 30 40 50 60 70 Sentence Length Figure 4: Scatter graph of number of parses to sentence length (one point per sentence). The crossover points are illustrated for time and memory. The maximum number of parses shown is 1000, points plotted at 1000 correspond to equal to or great</context>
</contexts>
<marker>Carroll, Briscoe, 2002</marker>
<rawString>John Carroll and Ted Briscoe. 2002. High precision extraction of grammatical relations. In Proceedings of the 19th International Conference on Computational Linguistics, Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
<author>Ted Briscoe</author>
<author>Antonio Sanfilippo</author>
</authors>
<title>Parser evaluation: a survey and a new proposal.</title>
<date>1998</date>
<booktitle>In Proceedings of the 1st International Conference on Language Resources and Evaluation,</booktitle>
<pages>447--454</pages>
<location>Granada.</location>
<contexts>
<context position="13801" citStr="Carroll et al., 1998" startWordPosition="2278" endWordPosition="2281">ependencies for 700 sentences (originally from the Wall Street Journal) drawn at random from Section 23 of the Penn Treebank. Briscoe and Carroll (2005) extended DepBank with a set of gold-standard RASP GRs that we use to measure parser accuracy. We use the same 560 sentence subset from the DepBank utilised by Kaplan et al. (2004) in their study of parser accuracy and efficiency. All experimental results are obtained using this test suite on an AMD Opteron 2.5GHz CPU with 1GB of Ram on a 64 bit version of Linux. The parser’s output is evaluated using a relational dependency evaluation scheme (Carroll et al., 1998; Lin, 1998) and standard evaluation measures: precision, recall and F . 4 Local Ambiguity Packing Oepen and Carroll (2000) note that when using subsumption-based packing with a unification-based grammar, the parse forest may implicitly represent some parses that are not actually licensed by the grammar; these will have values for one or more features that are locally but not globally consistent. This is not a problem when computing GRs from trees that have already been unpacked, since the relevant unifications will have been checked during the unpacking process, and will have caused the affec</context>
</contexts>
<marker>Carroll, Briscoe, Sanfilippo, 1998</marker>
<rawString>John Carroll, Ted Briscoe, and Antonio Sanfilippo. 1998. Parser evaluation: a survey and a new proposal. In Proceedings of the 1st International Conference on Language Resources and Evaluation, pages 447–454, Granada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
</authors>
<title>Practical unification-based parsing of natural language.</title>
<date>1993</date>
<tech>Ph.D. thesis,</tech>
<institution>Computer Laboratory, University of Cambridge.</institution>
<contexts>
<context position="6779" citStr="Carroll, 1993" startWordPosition="1074" endWordPosition="1075"> rule analysing a verb phrase followed by a prepositional phrase modifier. The rule identifies the first daughter (1) as the semantic head, and specifies that one of five possible GRs is to be output, depending on the value of the PSUBCAT syntactic feature; so, for example, if the feature has the value NP, then the relation is ncmod (non-clausal modifier), with slots filled by the semantic heads of the first and second daughters (the 1 and 2 arguments). Before parsing, a context free backbone is derived automatically from the grammar, and an LALR(1) parse table is computed from this backbone (Carroll, 1993, describes the procedure in detail). Probabilities are associated with actions in the parse table, by training on around 4K sentences from the Susanne corpus (Sampson, 1995), each sentence having been semi-automatically converted from a treebank bracketing to a tree conforming to the unification grammar (Briscoe and Carroll, 1995). 2.2 The Parse Forest When parsing, the LALR table action probabilities are used to assign a score to each newly derived (sub-)analysis. Additionally, on each reduce action (i.e. complete application of a rule), the rule’s daughters are unified with the sequence of </context>
<context position="9914" citStr="Carroll, 1993" startWordPosition="1602" endWordPosition="1604">sis. These pointers provide a means to traverse the parse forest during subsequent processing stages. A ‘packed node’ is a node representing a sub-analysis that is subsumed by, and hence packed into, another node. Packing is considered for nodes only if they are produced in the same LR state and represent sub-analyses with the same word span. A parse forest can have a number of root nodes, each one dominating analyses spanning the whole sentence with the specified top category. 2.3 Parser Output From the parse forest, RASP unpacks the ‘n-best’4 syntactic trees using a depth-first beam search (Carroll, 1993). There are a number of types of analysis 3The part of speech tagger uses a subset of the Lancaster CLAWS2 tagset – http://www.comp.lancs.ac.uk/computing/research/ ucrel/claws2tags.html 4This number is specified by the user, and represents the maximal number of parses to be unpacked. output available, including syntactic tree, grammatical relations (GRs) and robust minimal recursion semantics (RMRS). Each of these is computed from the n-best trees. Another output possibility is weighted GRs (Carroll and Briscoe, 2002); this is the unique set of GRs from the n-best GRs, each GR weighted accordi</context>
</contexts>
<marker>Carroll, 1993</marker>
<rawString>John Carroll. 1993. Practical unification-based parsing of natural language. Ph.D. thesis, Computer Laboratory, University of Cambridge. Technical Report No. 314.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>James Curran</author>
</authors>
<title>Parsing the WSJ using CCG and log-linear models.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>104--111</pages>
<location>Barcelona,</location>
<contexts>
<context position="3354" citStr="Clark and Curran (2004)" startWordPosition="526" endWordPosition="529">parse selection (Johnson, 2001; Schmid and Rooth, 2001; Geman and Johnson, 2002; Miyao and Tsujii, 2002; Kaplan et al., 2004; Taskar et al., 2004). The approach we take is similar to Schmid and Rooth’s (2001) adaptation of the algorithm, where ‘expected governors’ (similar to our ‘GR specifications’) are determined for each tree, and alternative nodes in the parse forest have the same lexical head. Initially, they create a packed parse forest and during a second pass the parse forest nodes are split if multiple lexical heads occur. The IOA is applied over this split data structure. Similarly, Clark and Curran (2004) alter their packing algorithm so that nodes in the packed chart have the same semantic head and ‘unfilled’ GRs. Our ap160 Proceedings of the Ninth International Workshop on Parsing Technologies (IWPT), pages 160–170, Vancouver, October 2005. c�2005 Association for Computational Linguistics proach is novel in that while calculating inside probabilities we allow any node in the parse forest to have multiple semantic heads. Clark and Curran (2004) apply Miyao and Tsujii’s (2002) dynamic programming approach to determine weighted GRs. They outline an alternative parse selection method based on th</context>
<context position="29752" citStr="Clark and Curran (2004)" startWordPosition="4899" endWordPosition="4902">he system for calculation of weighted GRs over the n-best parses. a relative error reduction (RER) of 6.8%. Therefore, EWG achieves a substantial improvement in both efficiency and accuracy for weighted GR calculation; providing increased precision for thresholded GR sets and an increased F upper bound on the task. 6.2 Parse Selection Section 6.1 illustrated the increased level of efficiency achieved by EWG compared to the current system’s method for calculating weighted GRs. This section briefly considers a parse selection algorithm using EWG that would otherwise be too inefficient to apply. Clark and Curran (2004) determine weighted GRs directly from a packed chart using Miyao and Tsujii’s (2002) dynamic programming algorithm. They outline a parse selection algorithm which maximises the expected recall of dependencies by selecting the n-best GR set with the highest average GR score based on the weights from the weighted GRs. We can apply this parse selection algorithm in two ways: either (a) re-rank the n-best GR sets based on the average weight of GRs and select the highest ranking set, or (b) apply a simple variant of the Viterbi algorithm to select the GR set with the highest average weighted score </context>
</contexts>
<marker>Clark, Curran, 2004</marker>
<rawString>Stephen Clark and James Curran. 2004. Parsing the WSJ using CCG and log-linear models. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics, pages 104–111, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
</authors>
<title>Report on the design of RMRS. DeepThought Project Deliverable D1.1a,</title>
<date>2003</date>
<institution>University of Cambridge, UK.</institution>
<contexts>
<context position="1214" citStr="Copestake, 2003" startWordPosition="176" endWordPosition="177">est. The approach improves on previous work which either loses efficiency by unpacking the parse forest before extracting weighted GRs, or places extra constraints on which nodes can be packed, leading to less compact forests. Our experiments demonstrate substantial increases in parser accuracy and throughput for weighted GR output. 1 Introduction RASP is a robust statistical analysis system for English developed by Briscoe and Carroll (2002). It contains a syntactic parser which can output analyses in a number of formats, including (nbest) syntactic trees, robust minimal recursion semantics (Copestake, 2003), grammatical relations (GRs), and weighted GRs. The weighted GRs for a sentence comprise the set of grammatical relations in all parses licensed for that sentence, each GR is weighted based on the probabilities of the parses in which it occurs. This weight is normalised to fall within the range 0,1 where indicates that all parses contain the GR. Therefore, high precision GR sets can be determined by thresholding on the GR weight (Carroll and Briscoe, 2002). Carroll and Briscoe compute weighted GRs by first unpacking all parses or the n-best subset from the parse forest. Hence, this approach i</context>
</contexts>
<marker>Copestake, 2003</marker>
<rawString>Ann Copestake. 2003. Report on the design of RMRS. DeepThought Project Deliverable D1.1a, University of Cambridge, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Geman</author>
<author>Mark Johnson</author>
</authors>
<title>Dynamic programming for parsing and estimation of stochastic unification-based grammars.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<location>Philadelphia, PA.</location>
<contexts>
<context position="2810" citStr="Geman and Johnson, 2002" startWordPosition="435" endWordPosition="438">amic programming approach based on the Inside-Outside algorithm (IOA) (Baker, 1979; Lari and Young, 1990). This approach enables efficient calculation of weighted GRs over all parses and substantially improves the throughput and memory usage of the parser. Since the parser is unificationbased, we also modify the parsing algorithm so that local ambiguity packing is based on feature structure equivalence rather than subsumption. Similar dynamic programming techniques that are variants of the IOA have been applied for related tasks, such as parse selection (Johnson, 2001; Schmid and Rooth, 2001; Geman and Johnson, 2002; Miyao and Tsujii, 2002; Kaplan et al., 2004; Taskar et al., 2004). The approach we take is similar to Schmid and Rooth’s (2001) adaptation of the algorithm, where ‘expected governors’ (similar to our ‘GR specifications’) are determined for each tree, and alternative nodes in the parse forest have the same lexical head. Initially, they create a packed parse forest and during a second pass the parse forest nodes are split if multiple lexical heads occur. The IOA is applied over this split data structure. Similarly, Clark and Curran (2004) alter their packing algorithm so that nodes in the pack</context>
</contexts>
<marker>Geman, Johnson, 2002</marker>
<rawString>Stuart Geman and Mark Johnson. 2002. Dynamic programming for parsing and estimation of stochastic unification-based grammars. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL), Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
</authors>
<title>Joint and conditional estimation of tagging and parsing models.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<location>Toulouse, France,</location>
<contexts>
<context position="2761" citStr="Johnson, 2001" startWordPosition="429" endWordPosition="430">ectly from the parse forest using a dynamic programming approach based on the Inside-Outside algorithm (IOA) (Baker, 1979; Lari and Young, 1990). This approach enables efficient calculation of weighted GRs over all parses and substantially improves the throughput and memory usage of the parser. Since the parser is unificationbased, we also modify the parsing algorithm so that local ambiguity packing is based on feature structure equivalence rather than subsumption. Similar dynamic programming techniques that are variants of the IOA have been applied for related tasks, such as parse selection (Johnson, 2001; Schmid and Rooth, 2001; Geman and Johnson, 2002; Miyao and Tsujii, 2002; Kaplan et al., 2004; Taskar et al., 2004). The approach we take is similar to Schmid and Rooth’s (2001) adaptation of the algorithm, where ‘expected governors’ (similar to our ‘GR specifications’) are determined for each tree, and alternative nodes in the parse forest have the same lexical head. Initially, they create a packed parse forest and during a second pass the parse forest nodes are split if multiple lexical heads occur. The IOA is applied over this split data structure. Similarly, Clark and Curran (2004) alter </context>
</contexts>
<marker>Johnson, 2001</marker>
<rawString>Mark Johnson. 2001. Joint and conditional estimation of tagging and parsing models. In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics (ACL), Toulouse, France, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald Kaplan</author>
<author>Stephen Riezler</author>
<author>Tracy King</author>
<author>John Maxwell</author>
<author>Alexander Vasserman</author>
<author>Richard Crouch</author>
</authors>
<title>Speed and accuracy in shallow and deep stochastic parsing.</title>
<date>2004</date>
<booktitle>In Proceedings of the Human Language Technology conference / North American chapter of the Association for Computational Linguistics annual meeting,</booktitle>
<pages>97--113</pages>
<location>Boston, Massachusetts,</location>
<contexts>
<context position="2855" citStr="Kaplan et al., 2004" startWordPosition="443" endWordPosition="446">side algorithm (IOA) (Baker, 1979; Lari and Young, 1990). This approach enables efficient calculation of weighted GRs over all parses and substantially improves the throughput and memory usage of the parser. Since the parser is unificationbased, we also modify the parsing algorithm so that local ambiguity packing is based on feature structure equivalence rather than subsumption. Similar dynamic programming techniques that are variants of the IOA have been applied for related tasks, such as parse selection (Johnson, 2001; Schmid and Rooth, 2001; Geman and Johnson, 2002; Miyao and Tsujii, 2002; Kaplan et al., 2004; Taskar et al., 2004). The approach we take is similar to Schmid and Rooth’s (2001) adaptation of the algorithm, where ‘expected governors’ (similar to our ‘GR specifications’) are determined for each tree, and alternative nodes in the parse forest have the same lexical head. Initially, they create a packed parse forest and during a second pass the parse forest nodes are split if multiple lexical heads occur. The IOA is applied over this split data structure. Similarly, Clark and Curran (2004) alter their packing algorithm so that nodes in the packed chart have the same semantic head and ‘unf</context>
<context position="13513" citStr="Kaplan et al. (2004)" startWordPosition="2228" endWordPosition="2231"> non-normalised score. The sum of all parse probabilities is . Therefore, the normalised probability (and final weight) of the GR is 5. 3 Data and Methods King et al. (2003) outline the development of the PARC 700 Dependency Bank (henceforth, DepBank), a gold-standard set of relational dependencies for 700 sentences (originally from the Wall Street Journal) drawn at random from Section 23 of the Penn Treebank. Briscoe and Carroll (2005) extended DepBank with a set of gold-standard RASP GRs that we use to measure parser accuracy. We use the same 560 sentence subset from the DepBank utilised by Kaplan et al. (2004) in their study of parser accuracy and efficiency. All experimental results are obtained using this test suite on an AMD Opteron 2.5GHz CPU with 1GB of Ram on a 64 bit version of Linux. The parser’s output is evaluated using a relational dependency evaluation scheme (Carroll et al., 1998; Lin, 1998) and standard evaluation measures: precision, recall and F . 4 Local Ambiguity Packing Oepen and Carroll (2000) note that when using subsumption-based packing with a unification-based grammar, the parse forest may implicitly represent some parses that are not actually licensed by the grammar; these </context>
</contexts>
<marker>Kaplan, Riezler, King, Maxwell, Vasserman, Crouch, 2004</marker>
<rawString>Ronald Kaplan, Stephen Riezler, Tracy King, John Maxwell, Alexander Vasserman, and Richard Crouch. 2004. Speed and accuracy in shallow and deep stochastic parsing. In Proceedings of the Human Language Technology conference / North American chapter of the Association for Computational Linguistics annual meeting, pages 97–113, Boston, Massachusetts, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tracy King</author>
<author>Richard Crouch</author>
<author>Stephen Riezler</author>
<author>Mary Dalrymple</author>
<author>Ronald Kaplan</author>
</authors>
<title>The PARC700 Dependency Bank.</title>
<date>2003</date>
<booktitle>In Proceedings of the 4th International Workshop on Linguistically Interpreted Corpora (LINC-03).</booktitle>
<contexts>
<context position="13066" citStr="King et al. (2003)" startWordPosition="2153" endWordPosition="2156"> -0.006716030 NP/det_n N -0.39 1 1 1 29 - 1 -3.5908418 &lt;2,(d et 2 1)&gt; &lt;1&gt; PP/p1 see+ed_VVD the_AT -3.8319092 &lt;1,(dobj 1 2)&gt; P1/p_np &lt; -3.2382972 &lt;1,(dobj 1 2)&gt; NP/det n N1/n1_pp1 ns, m &lt;1,(dobj 1 2)&gt; in_II P1/p_np &lt;1,(dobj 1 2)&gt; the35 . -3.8319092 -0.0064182742 -3.5908418 -2.7551124 -3.8319092 taining the specific GR, normalised by the sum of all parse probabilities. For example, the GR (iobj see+ed in) is in one parse with probability , the non-normalised score. The sum of all parse probabilities is . Therefore, the normalised probability (and final weight) of the GR is 5. 3 Data and Methods King et al. (2003) outline the development of the PARC 700 Dependency Bank (henceforth, DepBank), a gold-standard set of relational dependencies for 700 sentences (originally from the Wall Street Journal) drawn at random from Section 23 of the Penn Treebank. Briscoe and Carroll (2005) extended DepBank with a set of gold-standard RASP GRs that we use to measure parser accuracy. We use the same 560 sentence subset from the DepBank utilised by Kaplan et al. (2004) in their study of parser accuracy and efficiency. All experimental results are obtained using this test suite on an AMD Opteron 2.5GHz CPU with 1GB of R</context>
</contexts>
<marker>King, Crouch, Riezler, Dalrymple, Kaplan, 2003</marker>
<rawString>Tracy King, Richard Crouch, Stephen Riezler, Mary Dalrymple, and Ronald Kaplan. 2003. The PARC700 Dependency Bank. In Proceedings of the 4th International Workshop on Linguistically Interpreted Corpora (LINC-03).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karim Lari</author>
<author>Steve Young</author>
</authors>
<title>The estimation of stochastic context-free grammars using the InsideOutside algorithm.</title>
<date>1990</date>
<journal>Computer Speech and Language,</journal>
<volume>2</volume>
<issue>4</issue>
<contexts>
<context position="2292" citStr="Lari and Young, 1990" startWordPosition="354" endWordPosition="357">002). Carroll and Briscoe compute weighted GRs by first unpacking all parses or the n-best subset from the parse forest. Hence, this approach is either (a) inefficient (and for some examples impracticable) if a large number of parses are licensed by the grammar, or (b) inaccurate if the number of parses unpacked is less than the number licensed by the grammar. In this paper, we show how to obviate the need to trade off efficiency and accuracy by extracting weighted GRs directly from the parse forest using a dynamic programming approach based on the Inside-Outside algorithm (IOA) (Baker, 1979; Lari and Young, 1990). This approach enables efficient calculation of weighted GRs over all parses and substantially improves the throughput and memory usage of the parser. Since the parser is unificationbased, we also modify the parsing algorithm so that local ambiguity packing is based on feature structure equivalence rather than subsumption. Similar dynamic programming techniques that are variants of the IOA have been applied for related tasks, such as parse selection (Johnson, 2001; Schmid and Rooth, 2001; Geman and Johnson, 2002; Miyao and Tsujii, 2002; Kaplan et al., 2004; Taskar et al., 2004). The approach </context>
</contexts>
<marker>Lari, Young, 1990</marker>
<rawString>Karim Lari and Steve Young. 1990. The estimation of stochastic context-free grammars using the InsideOutside algorithm. Computer Speech and Language, 2(4):35–56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Dependency-based evaluation of MINIPAR.</title>
<date>1998</date>
<booktitle>In Proceedings of the Workshop on The Evaluation of Parsing Systems at the 1st International Conference on Language Resources and Evaluation,</booktitle>
<location>Granada,</location>
<contexts>
<context position="13813" citStr="Lin, 1998" startWordPosition="2282" endWordPosition="2283">ntences (originally from the Wall Street Journal) drawn at random from Section 23 of the Penn Treebank. Briscoe and Carroll (2005) extended DepBank with a set of gold-standard RASP GRs that we use to measure parser accuracy. We use the same 560 sentence subset from the DepBank utilised by Kaplan et al. (2004) in their study of parser accuracy and efficiency. All experimental results are obtained using this test suite on an AMD Opteron 2.5GHz CPU with 1GB of Ram on a 64 bit version of Linux. The parser’s output is evaluated using a relational dependency evaluation scheme (Carroll et al., 1998; Lin, 1998) and standard evaluation measures: precision, recall and F . 4 Local Ambiguity Packing Oepen and Carroll (2000) note that when using subsumption-based packing with a unification-based grammar, the parse forest may implicitly represent some parses that are not actually licensed by the grammar; these will have values for one or more features that are locally but not globally consistent. This is not a problem when computing GRs from trees that have already been unpacked, since the relevant unifications will have been checked during the unpacking process, and will have caused the affected trees to</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Dependency-based evaluation of MINIPAR. In Proceedings of the Workshop on The Evaluation of Parsing Systems at the 1st International Conference on Language Resources and Evaluation, Granada, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Miyao</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Maximum entropy estimation for feature forests.</title>
<date>2002</date>
<booktitle>In Proceedings of the Human Language Technology Conference,</booktitle>
<location>San Diego, California,</location>
<contexts>
<context position="2834" citStr="Miyao and Tsujii, 2002" startWordPosition="439" endWordPosition="442"> based on the Inside-Outside algorithm (IOA) (Baker, 1979; Lari and Young, 1990). This approach enables efficient calculation of weighted GRs over all parses and substantially improves the throughput and memory usage of the parser. Since the parser is unificationbased, we also modify the parsing algorithm so that local ambiguity packing is based on feature structure equivalence rather than subsumption. Similar dynamic programming techniques that are variants of the IOA have been applied for related tasks, such as parse selection (Johnson, 2001; Schmid and Rooth, 2001; Geman and Johnson, 2002; Miyao and Tsujii, 2002; Kaplan et al., 2004; Taskar et al., 2004). The approach we take is similar to Schmid and Rooth’s (2001) adaptation of the algorithm, where ‘expected governors’ (similar to our ‘GR specifications’) are determined for each tree, and alternative nodes in the parse forest have the same lexical head. Initially, they create a packed parse forest and during a second pass the parse forest nodes are split if multiple lexical heads occur. The IOA is applied over this split data structure. Similarly, Clark and Curran (2004) alter their packing algorithm so that nodes in the packed chart have the same s</context>
</contexts>
<marker>Miyao, Tsujii, 2002</marker>
<rawString>Yusuke Miyao and Jun’ichi Tsujii. 2002. Maximum entropy estimation for feature forests. In Proceedings of the Human Language Technology Conference, San Diego, California, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Oepen</author>
<author>John Carroll</author>
</authors>
<title>Ambiguity packing in constraint-based parsing - practical results.</title>
<date>2000</date>
<booktitle>In Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL),</booktitle>
<pages>162--169</pages>
<location>Seattle, WA.</location>
<contexts>
<context position="13924" citStr="Oepen and Carroll (2000)" startWordPosition="2298" endWordPosition="2301">ebank. Briscoe and Carroll (2005) extended DepBank with a set of gold-standard RASP GRs that we use to measure parser accuracy. We use the same 560 sentence subset from the DepBank utilised by Kaplan et al. (2004) in their study of parser accuracy and efficiency. All experimental results are obtained using this test suite on an AMD Opteron 2.5GHz CPU with 1GB of Ram on a 64 bit version of Linux. The parser’s output is evaluated using a relational dependency evaluation scheme (Carroll et al., 1998; Lin, 1998) and standard evaluation measures: precision, recall and F . 4 Local Ambiguity Packing Oepen and Carroll (2000) note that when using subsumption-based packing with a unification-based grammar, the parse forest may implicitly represent some parses that are not actually licensed by the grammar; these will have values for one or more features that are locally but not globally consistent. This is not a problem when computing GRs from trees that have already been unpacked, since the relevant unifications will have been checked during the unpacking process, and will have caused the affected trees to be filtered out. Unification fails for at least one packed tree in approximately 10% of the sentences in the t</context>
</contexts>
<marker>Oepen, Carroll, 2000</marker>
<rawString>Stephan Oepen and John Carroll. 2000. Ambiguity packing in constraint-based parsing - practical results. In Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL), pages 162–169, Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey Sampson</author>
</authors>
<title>English for the Computer.</title>
<date>1995</date>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="6953" citStr="Sampson, 1995" startWordPosition="1102" endWordPosition="1103">ssible GRs is to be output, depending on the value of the PSUBCAT syntactic feature; so, for example, if the feature has the value NP, then the relation is ncmod (non-clausal modifier), with slots filled by the semantic heads of the first and second daughters (the 1 and 2 arguments). Before parsing, a context free backbone is derived automatically from the grammar, and an LALR(1) parse table is computed from this backbone (Carroll, 1993, describes the procedure in detail). Probabilities are associated with actions in the parse table, by training on around 4K sentences from the Susanne corpus (Sampson, 1995), each sentence having been semi-automatically converted from a treebank bracketing to a tree conforming to the unification grammar (Briscoe and Carroll, 1995). 2.2 The Parse Forest When parsing, the LALR table action probabilities are used to assign a score to each newly derived (sub-)analysis. Additionally, on each reduce action (i.e. complete application of a rule), the rule’s daughters are unified with the sequence of subanalyses being consumed. If unification fails then the reduce action is aborted. Local ambiguity packing (packing, henceforth) is performed on the basis of feature structu</context>
</contexts>
<marker>Sampson, 1995</marker>
<rawString>Geoffrey Sampson. 1995. English for the Computer. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
<author>Mats Rooth</author>
</authors>
<title>Parse forest computation of expected governors.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>458--465</pages>
<contexts>
<context position="2785" citStr="Schmid and Rooth, 2001" startWordPosition="431" endWordPosition="434">parse forest using a dynamic programming approach based on the Inside-Outside algorithm (IOA) (Baker, 1979; Lari and Young, 1990). This approach enables efficient calculation of weighted GRs over all parses and substantially improves the throughput and memory usage of the parser. Since the parser is unificationbased, we also modify the parsing algorithm so that local ambiguity packing is based on feature structure equivalence rather than subsumption. Similar dynamic programming techniques that are variants of the IOA have been applied for related tasks, such as parse selection (Johnson, 2001; Schmid and Rooth, 2001; Geman and Johnson, 2002; Miyao and Tsujii, 2002; Kaplan et al., 2004; Taskar et al., 2004). The approach we take is similar to Schmid and Rooth’s (2001) adaptation of the algorithm, where ‘expected governors’ (similar to our ‘GR specifications’) are determined for each tree, and alternative nodes in the parse forest have the same lexical head. Initially, they create a packed parse forest and during a second pass the parse forest nodes are split if multiple lexical heads occur. The IOA is applied over this split data structure. Similarly, Clark and Curran (2004) alter their packing algorithm </context>
</contexts>
<marker>Schmid, Rooth, 2001</marker>
<rawString>Helmut Schmid and Mats Rooth. 2001. Parse forest computation of expected governors. In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics, pages 458–465.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Taskar</author>
<author>Dan Klein</author>
<author>Michael Collins</author>
<author>Daphne Koller</author>
<author>Christopher Manning</author>
</authors>
<title>Max-margin parsing.</title>
<date>2004</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="2877" citStr="Taskar et al., 2004" startWordPosition="447" endWordPosition="450">(Baker, 1979; Lari and Young, 1990). This approach enables efficient calculation of weighted GRs over all parses and substantially improves the throughput and memory usage of the parser. Since the parser is unificationbased, we also modify the parsing algorithm so that local ambiguity packing is based on feature structure equivalence rather than subsumption. Similar dynamic programming techniques that are variants of the IOA have been applied for related tasks, such as parse selection (Johnson, 2001; Schmid and Rooth, 2001; Geman and Johnson, 2002; Miyao and Tsujii, 2002; Kaplan et al., 2004; Taskar et al., 2004). The approach we take is similar to Schmid and Rooth’s (2001) adaptation of the algorithm, where ‘expected governors’ (similar to our ‘GR specifications’) are determined for each tree, and alternative nodes in the parse forest have the same lexical head. Initially, they create a packed parse forest and during a second pass the parse forest nodes are split if multiple lexical heads occur. The IOA is applied over this split data structure. Similarly, Clark and Curran (2004) alter their packing algorithm so that nodes in the packed chart have the same semantic head and ‘unfilled’ GRs. Our ap160 </context>
</contexts>
<marker>Taskar, Klein, Collins, Koller, Manning, 2004</marker>
<rawString>Ben Taskar, Dan Klein, Michael Collins, Daphne Koller, and Christopher Manning. 2004. Max-margin parsing. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>